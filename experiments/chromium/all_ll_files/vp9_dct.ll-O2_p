; ModuleID = '../../third_party/libvpx/source/libvpx/vp9/encoder/vp9_dct.c'
source_filename = "../../third_party/libvpx/source/libvpx/vp9/encoder/vp9_dct.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%struct.transform_2d = type { void (i32*, i32*)*, void (i32*, i32*)* }

@FHT_4 = internal unnamed_addr constant [4 x %struct.transform_2d] [%struct.transform_2d { void (i32*, i32*)* @fdct4, void (i32*, i32*)* @fdct4 }, %struct.transform_2d { void (i32*, i32*)* @fadst4, void (i32*, i32*)* @fdct4 }, %struct.transform_2d { void (i32*, i32*)* @fdct4, void (i32*, i32*)* @fadst4 }, %struct.transform_2d { void (i32*, i32*)* @fadst4, void (i32*, i32*)* @fadst4 }], align 16
@FHT_8 = internal unnamed_addr constant [4 x %struct.transform_2d] [%struct.transform_2d { void (i32*, i32*)* @fdct8, void (i32*, i32*)* @fdct8 }, %struct.transform_2d { void (i32*, i32*)* @fadst8, void (i32*, i32*)* @fdct8 }, %struct.transform_2d { void (i32*, i32*)* @fdct8, void (i32*, i32*)* @fadst8 }, %struct.transform_2d { void (i32*, i32*)* @fadst8, void (i32*, i32*)* @fadst8 }], align 16
@FHT_16 = internal unnamed_addr constant [4 x %struct.transform_2d] [%struct.transform_2d { void (i32*, i32*)* @fdct16, void (i32*, i32*)* @fdct16 }, %struct.transform_2d { void (i32*, i32*)* @fadst16, void (i32*, i32*)* @fdct16 }, %struct.transform_2d { void (i32*, i32*)* @fdct16, void (i32*, i32*)* @fadst16 }, %struct.transform_2d { void (i32*, i32*)* @fadst16, void (i32*, i32*)* @fadst16 }], align 16

; Function Attrs: nounwind ssp uwtable
define hidden void @vp9_fht4x4_c(i16*, i32*, i32, i32) local_unnamed_addr #0 {
  %5 = alloca [16 x i32], align 16
  %6 = alloca [4 x i32], align 16
  %7 = bitcast [4 x i32]* %6 to i8*
  %8 = alloca <4 x i32>, align 16
  %9 = icmp eq i32 %3, 0
  br i1 %9, label %10, label %11

10:                                               ; preds = %4
  tail call void @vpx_fdct4x4_c(i16* %0, i32* %1, i32 %2) #4
  br label %99

11:                                               ; preds = %4
  %12 = bitcast [16 x i32]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %12) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %12, i8 -86, i64 64, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %7) #4
  %13 = getelementptr inbounds [4 x i32], [4 x i32]* %6, i64 0, i64 0
  %14 = getelementptr inbounds [4 x i32], [4 x i32]* %6, i64 0, i64 1
  %15 = getelementptr inbounds [4 x i32], [4 x i32]* %6, i64 0, i64 2
  %16 = getelementptr inbounds [4 x i32], [4 x i32]* %6, i64 0, i64 3
  %17 = bitcast <4 x i32>* %8 to i8*
  %18 = bitcast [4 x i32]* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %18, i8 -86, i64 16, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %17) #4
  %19 = getelementptr inbounds <4 x i32>, <4 x i32>* %8, i64 0, i64 0
  %20 = getelementptr inbounds <4 x i32>, <4 x i32>* %8, i64 0, i64 1
  %21 = getelementptr inbounds <4 x i32>, <4 x i32>* %8, i64 0, i64 2
  %22 = getelementptr inbounds <4 x i32>, <4 x i32>* %8, i64 0, i64 3
  %23 = sext i32 %3 to i64
  %24 = getelementptr inbounds [4 x %struct.transform_2d], [4 x %struct.transform_2d]* @FHT_4, i64 0, i64 %23, i32 0
  %25 = bitcast <4 x i32>* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %25, i8 -86, i64 16, i1 false)
  %26 = load void (i32*, i32*)*, void (i32*, i32*)** %24, align 16
  %27 = getelementptr inbounds [4 x %struct.transform_2d], [4 x %struct.transform_2d]* @FHT_4, i64 0, i64 %23, i32 1
  %28 = load void (i32*, i32*)*, void (i32*, i32*)** %27, align 8
  %29 = sext i32 %2 to i64
  %30 = shl nsw i64 %29, 1
  %31 = mul nsw i64 %29, 3
  br label %32

32:                                               ; preds = %58, %11
  %33 = phi i64 [ 0, %11 ], [ %70, %58 ]
  %34 = getelementptr inbounds i16, i16* %0, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = sext i16 %35 to i32
  %37 = shl nsw i32 %36, 4
  store i32 %37, i32* %13, align 16
  %38 = add nsw i64 %33, %29
  %39 = getelementptr inbounds i16, i16* %0, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = sext i16 %40 to i32
  %42 = shl nsw i32 %41, 4
  store i32 %42, i32* %14, align 4
  %43 = add nsw i64 %30, %33
  %44 = getelementptr inbounds i16, i16* %0, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = sext i16 %45 to i32
  %47 = shl nsw i32 %46, 4
  store i32 %47, i32* %15, align 8
  %48 = add nsw i64 %31, %33
  %49 = getelementptr inbounds i16, i16* %0, i64 %48
  %50 = load i16, i16* %49, align 2
  %51 = sext i16 %50 to i32
  %52 = shl nsw i32 %51, 4
  store i32 %52, i32* %16, align 4
  %53 = icmp ne i64 %33, 0
  %54 = icmp eq i16 %35, 0
  %55 = or i1 %53, %54
  br i1 %55, label %58, label %56

56:                                               ; preds = %32
  %57 = or i32 %37, 1
  store i32 %57, i32* %13, align 16
  br label %58

58:                                               ; preds = %32, %56
  call void %26(i32* nonnull %13, i32* nonnull %19) #4
  %59 = load i32, i32* %19, align 16
  %60 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 %33
  store i32 %59, i32* %60, align 4
  %61 = load i32, i32* %20, align 4
  %62 = add nuw nsw i64 %33, 4
  %63 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 %62
  store i32 %61, i32* %63, align 4
  %64 = load i32, i32* %21, align 8
  %65 = add nuw nsw i64 %33, 8
  %66 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 %65
  store i32 %64, i32* %66, align 4
  %67 = load i32, i32* %22, align 4
  %68 = add nuw nsw i64 %33, 12
  %69 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 %68
  store i32 %67, i32* %69, align 4
  %70 = add nuw nsw i64 %33, 1
  %71 = icmp eq i64 %70, 4
  br i1 %71, label %72, label %32

72:                                               ; preds = %58
  %73 = bitcast [16 x i32]* %5 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %7, i8* nonnull align 16 %73, i64 16, i1 false)
  call void %28(i32* nonnull %13, i32* nonnull %19) #4
  %74 = load <4 x i32>, <4 x i32>* %8, align 16
  %75 = add nsw <4 x i32> %74, <i32 1, i32 1, i32 1, i32 1>
  %76 = ashr <4 x i32> %75, <i32 2, i32 2, i32 2, i32 2>
  %77 = bitcast i32* %1 to <4 x i32>*
  store <4 x i32> %76, <4 x i32>* %77, align 4
  %78 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 4
  %79 = bitcast i32* %78 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %7, i8* align 16 %79, i64 16, i1 false)
  call void %28(i32* nonnull %13, i32* nonnull %19) #4
  %80 = getelementptr inbounds i32, i32* %1, i64 4
  %81 = load <4 x i32>, <4 x i32>* %8, align 16
  %82 = add nsw <4 x i32> %81, <i32 1, i32 1, i32 1, i32 1>
  %83 = ashr <4 x i32> %82, <i32 2, i32 2, i32 2, i32 2>
  %84 = bitcast i32* %80 to <4 x i32>*
  store <4 x i32> %83, <4 x i32>* %84, align 4
  %85 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 8
  %86 = bitcast i32* %85 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %7, i8* align 16 %86, i64 16, i1 false)
  call void %28(i32* nonnull %13, i32* nonnull %19) #4
  %87 = getelementptr inbounds i32, i32* %1, i64 8
  %88 = load <4 x i32>, <4 x i32>* %8, align 16
  %89 = add nsw <4 x i32> %88, <i32 1, i32 1, i32 1, i32 1>
  %90 = ashr <4 x i32> %89, <i32 2, i32 2, i32 2, i32 2>
  %91 = bitcast i32* %87 to <4 x i32>*
  store <4 x i32> %90, <4 x i32>* %91, align 4
  %92 = getelementptr inbounds [16 x i32], [16 x i32]* %5, i64 0, i64 12
  %93 = bitcast i32* %92 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %7, i8* align 16 %93, i64 16, i1 false)
  call void %28(i32* nonnull %13, i32* nonnull %19) #4
  %94 = getelementptr inbounds i32, i32* %1, i64 12
  %95 = load <4 x i32>, <4 x i32>* %8, align 16
  %96 = add nsw <4 x i32> %95, <i32 1, i32 1, i32 1, i32 1>
  %97 = ashr <4 x i32> %96, <i32 2, i32 2, i32 2, i32 2>
  %98 = bitcast i32* %94 to <4 x i32>*
  store <4 x i32> %97, <4 x i32>* %98, align 4
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %17) #4
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %7) #4
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %12) #4
  br label %99

99:                                               ; preds = %72, %10
  ret void
}

declare void @vpx_fdct4x4_c(i16*, i32*, i32) local_unnamed_addr #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #2

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #2

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #2

; Function Attrs: nounwind ssp uwtable
define hidden void @vp9_fht8x8_c(i16*, i32*, i32, i32) local_unnamed_addr #0 {
  %5 = alloca [64 x i32], align 16
  %6 = alloca [8 x i32], align 16
  %7 = bitcast [8 x i32]* %6 to i8*
  %8 = alloca [8 x i32], align 16
  %9 = icmp eq i32 %3, 0
  br i1 %9, label %10, label %11

10:                                               ; preds = %4
  tail call void @vpx_fdct8x8_c(i16* %0, i32* %1, i32 %2) #4
  br label %134

11:                                               ; preds = %4
  %12 = bitcast [64 x i32]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %12) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %12, i8 -86, i64 256, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %7) #4
  %13 = getelementptr inbounds [8 x i32], [8 x i32]* %6, i64 0, i64 0
  %14 = getelementptr inbounds [8 x i32], [8 x i32]* %6, i64 0, i64 1
  %15 = getelementptr inbounds [8 x i32], [8 x i32]* %6, i64 0, i64 2
  %16 = getelementptr inbounds [8 x i32], [8 x i32]* %6, i64 0, i64 3
  %17 = getelementptr inbounds [8 x i32], [8 x i32]* %6, i64 0, i64 4
  %18 = getelementptr inbounds [8 x i32], [8 x i32]* %6, i64 0, i64 5
  %19 = getelementptr inbounds [8 x i32], [8 x i32]* %6, i64 0, i64 6
  %20 = getelementptr inbounds [8 x i32], [8 x i32]* %6, i64 0, i64 7
  %21 = bitcast [8 x i32]* %8 to i8*
  %22 = bitcast [8 x i32]* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 32, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %21) #4
  %23 = getelementptr inbounds [8 x i32], [8 x i32]* %8, i64 0, i64 0
  %24 = getelementptr inbounds [8 x i32], [8 x i32]* %8, i64 0, i64 1
  %25 = getelementptr inbounds [8 x i32], [8 x i32]* %8, i64 0, i64 2
  %26 = getelementptr inbounds [8 x i32], [8 x i32]* %8, i64 0, i64 3
  %27 = getelementptr inbounds [8 x i32], [8 x i32]* %8, i64 0, i64 4
  %28 = getelementptr inbounds [8 x i32], [8 x i32]* %8, i64 0, i64 5
  %29 = getelementptr inbounds [8 x i32], [8 x i32]* %8, i64 0, i64 6
  %30 = getelementptr inbounds [8 x i32], [8 x i32]* %8, i64 0, i64 7
  %31 = sext i32 %3 to i64
  %32 = getelementptr inbounds [4 x %struct.transform_2d], [4 x %struct.transform_2d]* @FHT_8, i64 0, i64 %31, i32 0
  %33 = bitcast [8 x i32]* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %33, i8 -86, i64 32, i1 false)
  %34 = load void (i32*, i32*)*, void (i32*, i32*)** %32, align 16
  %35 = getelementptr inbounds [4 x %struct.transform_2d], [4 x %struct.transform_2d]* @FHT_8, i64 0, i64 %31, i32 1
  %36 = load void (i32*, i32*)*, void (i32*, i32*)** %35, align 8
  %37 = sext i32 %2 to i64
  %38 = shl nsw i64 %37, 1
  %39 = mul nsw i64 %37, 3
  %40 = shl nsw i64 %37, 2
  %41 = mul nsw i64 %37, 5
  %42 = mul nsw i64 %37, 6
  %43 = mul nsw i64 %37, 7
  br label %44

44:                                               ; preds = %44, %11
  %45 = phi i64 [ 0, %11 ], [ %108, %44 ]
  %46 = getelementptr inbounds i16, i16* %0, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = sext i16 %47 to i32
  %49 = shl nsw i32 %48, 2
  store i32 %49, i32* %13, align 16
  %50 = add nsw i64 %45, %37
  %51 = getelementptr inbounds i16, i16* %0, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = sext i16 %52 to i32
  %54 = shl nsw i32 %53, 2
  store i32 %54, i32* %14, align 4
  %55 = add nsw i64 %38, %45
  %56 = getelementptr inbounds i16, i16* %0, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = sext i16 %57 to i32
  %59 = shl nsw i32 %58, 2
  store i32 %59, i32* %15, align 8
  %60 = add nsw i64 %39, %45
  %61 = getelementptr inbounds i16, i16* %0, i64 %60
  %62 = load i16, i16* %61, align 2
  %63 = sext i16 %62 to i32
  %64 = shl nsw i32 %63, 2
  store i32 %64, i32* %16, align 4
  %65 = add nsw i64 %40, %45
  %66 = getelementptr inbounds i16, i16* %0, i64 %65
  %67 = load i16, i16* %66, align 2
  %68 = sext i16 %67 to i32
  %69 = shl nsw i32 %68, 2
  store i32 %69, i32* %17, align 16
  %70 = add nsw i64 %41, %45
  %71 = getelementptr inbounds i16, i16* %0, i64 %70
  %72 = load i16, i16* %71, align 2
  %73 = sext i16 %72 to i32
  %74 = shl nsw i32 %73, 2
  store i32 %74, i32* %18, align 4
  %75 = add nsw i64 %42, %45
  %76 = getelementptr inbounds i16, i16* %0, i64 %75
  %77 = load i16, i16* %76, align 2
  %78 = sext i16 %77 to i32
  %79 = shl nsw i32 %78, 2
  store i32 %79, i32* %19, align 8
  %80 = add nsw i64 %43, %45
  %81 = getelementptr inbounds i16, i16* %0, i64 %80
  %82 = load i16, i16* %81, align 2
  %83 = sext i16 %82 to i32
  %84 = shl nsw i32 %83, 2
  store i32 %84, i32* %20, align 4
  call void %34(i32* nonnull %13, i32* nonnull %23) #4
  %85 = load i32, i32* %23, align 16
  %86 = getelementptr inbounds [64 x i32], [64 x i32]* %5, i64 0, i64 %45
  store i32 %85, i32* %86, align 4
  %87 = load i32, i32* %24, align 4
  %88 = add nuw nsw i64 %45, 8
  %89 = getelementptr inbounds [64 x i32], [64 x i32]* %5, i64 0, i64 %88
  store i32 %87, i32* %89, align 4
  %90 = load i32, i32* %25, align 8
  %91 = add nuw nsw i64 %45, 16
  %92 = getelementptr inbounds [64 x i32], [64 x i32]* %5, i64 0, i64 %91
  store i32 %90, i32* %92, align 4
  %93 = load i32, i32* %26, align 4
  %94 = add nuw nsw i64 %45, 24
  %95 = getelementptr inbounds [64 x i32], [64 x i32]* %5, i64 0, i64 %94
  store i32 %93, i32* %95, align 4
  %96 = load i32, i32* %27, align 16
  %97 = add nuw nsw i64 %45, 32
  %98 = getelementptr inbounds [64 x i32], [64 x i32]* %5, i64 0, i64 %97
  store i32 %96, i32* %98, align 4
  %99 = load i32, i32* %28, align 4
  %100 = add nuw nsw i64 %45, 40
  %101 = getelementptr inbounds [64 x i32], [64 x i32]* %5, i64 0, i64 %100
  store i32 %99, i32* %101, align 4
  %102 = load i32, i32* %29, align 8
  %103 = add nuw nsw i64 %45, 48
  %104 = getelementptr inbounds [64 x i32], [64 x i32]* %5, i64 0, i64 %103
  store i32 %102, i32* %104, align 4
  %105 = load i32, i32* %30, align 4
  %106 = add nuw nsw i64 %45, 56
  %107 = getelementptr inbounds [64 x i32], [64 x i32]* %5, i64 0, i64 %106
  store i32 %105, i32* %107, align 4
  %108 = add nuw nsw i64 %45, 1
  %109 = icmp eq i64 %108, 8
  br i1 %109, label %110, label %44

110:                                              ; preds = %44
  %111 = bitcast [8 x i32]* %8 to <4 x i32>*
  %112 = bitcast i32* %27 to <4 x i32>*
  br label %113

113:                                              ; preds = %110, %113
  %114 = phi i64 [ %131, %113 ], [ 0, %110 ]
  %115 = shl i64 %114, 3
  %116 = getelementptr [64 x i32], [64 x i32]* %5, i64 0, i64 %115
  %117 = bitcast i32* %116 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %7, i8* align 16 %117, i64 32, i1 false)
  call void %36(i32* nonnull %13, i32* nonnull %23) #4
  %118 = getelementptr inbounds i32, i32* %1, i64 %115
  %119 = load <4 x i32>, <4 x i32>* %111, align 16
  %120 = lshr <4 x i32> %119, <i32 31, i32 31, i32 31, i32 31>
  %121 = add nsw <4 x i32> %120, %119
  %122 = ashr <4 x i32> %121, <i32 1, i32 1, i32 1, i32 1>
  %123 = bitcast i32* %118 to <4 x i32>*
  store <4 x i32> %122, <4 x i32>* %123, align 4
  %124 = or i64 %115, 4
  %125 = getelementptr inbounds i32, i32* %1, i64 %124
  %126 = load <4 x i32>, <4 x i32>* %112, align 16
  %127 = lshr <4 x i32> %126, <i32 31, i32 31, i32 31, i32 31>
  %128 = add nsw <4 x i32> %127, %126
  %129 = ashr <4 x i32> %128, <i32 1, i32 1, i32 1, i32 1>
  %130 = bitcast i32* %125 to <4 x i32>*
  store <4 x i32> %129, <4 x i32>* %130, align 4
  %131 = add nuw nsw i64 %114, 1
  %132 = icmp eq i64 %131, 8
  br i1 %132, label %133, label %113

133:                                              ; preds = %113
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %21) #4
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %7) #4
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %12) #4
  br label %134

134:                                              ; preds = %133, %10
  ret void
}

declare void @vpx_fdct8x8_c(i16*, i32*, i32) local_unnamed_addr #1

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @vp9_fwht4x4_c(i16* nocapture readonly, i32* nocapture, i32) local_unnamed_addr #3 {
  %4 = sext i32 %2 to i64
  %5 = shl nsw i32 %2, 1
  %6 = sext i32 %5 to i64
  %7 = mul nsw i32 %2, 3
  %8 = sext i32 %7 to i64
  %9 = load i16, i16* %0, align 2
  %10 = sext i16 %9 to i64
  %11 = getelementptr inbounds i16, i16* %0, i64 %4
  %12 = load i16, i16* %11, align 2
  %13 = sext i16 %12 to i64
  %14 = getelementptr inbounds i16, i16* %0, i64 %6
  %15 = load i16, i16* %14, align 2
  %16 = sext i16 %15 to i64
  %17 = getelementptr inbounds i16, i16* %0, i64 %8
  %18 = load i16, i16* %17, align 2
  %19 = sext i16 %18 to i64
  %20 = add nsw i64 %13, %10
  %21 = sub nsw i64 %19, %16
  %22 = sub nsw i64 %20, %21
  %23 = ashr i64 %22, 1
  %24 = sub nsw i64 %23, %13
  %25 = sub nsw i64 %23, %16
  %26 = sub nsw i64 %20, %25
  %27 = add nsw i64 %24, %21
  %28 = trunc i64 %26 to i32
  store i32 %28, i32* %1, align 4
  %29 = trunc i64 %25 to i32
  %30 = getelementptr inbounds i32, i32* %1, i64 4
  store i32 %29, i32* %30, align 4
  %31 = trunc i64 %27 to i32
  %32 = getelementptr inbounds i32, i32* %1, i64 8
  store i32 %31, i32* %32, align 4
  %33 = trunc i64 %24 to i32
  %34 = getelementptr inbounds i32, i32* %1, i64 12
  store i32 %33, i32* %34, align 4
  %35 = getelementptr inbounds i16, i16* %0, i64 1
  %36 = getelementptr inbounds i32, i32* %1, i64 1
  %37 = load i16, i16* %35, align 2
  %38 = sext i16 %37 to i64
  %39 = getelementptr inbounds i16, i16* %35, i64 %4
  %40 = load i16, i16* %39, align 2
  %41 = sext i16 %40 to i64
  %42 = getelementptr inbounds i16, i16* %35, i64 %6
  %43 = load i16, i16* %42, align 2
  %44 = sext i16 %43 to i64
  %45 = getelementptr inbounds i16, i16* %35, i64 %8
  %46 = load i16, i16* %45, align 2
  %47 = sext i16 %46 to i64
  %48 = add nsw i64 %41, %38
  %49 = sub nsw i64 %47, %44
  %50 = sub nsw i64 %48, %49
  %51 = ashr i64 %50, 1
  %52 = sub nsw i64 %51, %41
  %53 = sub nsw i64 %51, %44
  %54 = sub nsw i64 %48, %53
  %55 = add nsw i64 %52, %49
  %56 = trunc i64 %54 to i32
  store i32 %56, i32* %36, align 4
  %57 = trunc i64 %53 to i32
  %58 = getelementptr inbounds i32, i32* %1, i64 5
  store i32 %57, i32* %58, align 4
  %59 = trunc i64 %55 to i32
  %60 = getelementptr inbounds i32, i32* %1, i64 9
  store i32 %59, i32* %60, align 4
  %61 = trunc i64 %52 to i32
  %62 = getelementptr inbounds i32, i32* %1, i64 13
  store i32 %61, i32* %62, align 4
  %63 = getelementptr inbounds i16, i16* %0, i64 2
  %64 = getelementptr inbounds i32, i32* %1, i64 2
  %65 = load i16, i16* %63, align 2
  %66 = sext i16 %65 to i64
  %67 = getelementptr inbounds i16, i16* %63, i64 %4
  %68 = load i16, i16* %67, align 2
  %69 = sext i16 %68 to i64
  %70 = getelementptr inbounds i16, i16* %63, i64 %6
  %71 = load i16, i16* %70, align 2
  %72 = sext i16 %71 to i64
  %73 = getelementptr inbounds i16, i16* %63, i64 %8
  %74 = load i16, i16* %73, align 2
  %75 = sext i16 %74 to i64
  %76 = add nsw i64 %69, %66
  %77 = sub nsw i64 %75, %72
  %78 = sub nsw i64 %76, %77
  %79 = ashr i64 %78, 1
  %80 = sub nsw i64 %79, %69
  %81 = sub nsw i64 %79, %72
  %82 = sub nsw i64 %76, %81
  %83 = add nsw i64 %80, %77
  %84 = trunc i64 %82 to i32
  store i32 %84, i32* %64, align 4
  %85 = trunc i64 %81 to i32
  %86 = getelementptr inbounds i32, i32* %1, i64 6
  store i32 %85, i32* %86, align 4
  %87 = trunc i64 %83 to i32
  %88 = getelementptr inbounds i32, i32* %1, i64 10
  store i32 %87, i32* %88, align 4
  %89 = trunc i64 %80 to i32
  %90 = getelementptr inbounds i32, i32* %1, i64 14
  store i32 %89, i32* %90, align 4
  %91 = getelementptr inbounds i16, i16* %0, i64 3
  %92 = load i16, i16* %91, align 2
  %93 = sext i16 %92 to i64
  %94 = getelementptr inbounds i16, i16* %91, i64 %4
  %95 = load i16, i16* %94, align 2
  %96 = sext i16 %95 to i64
  %97 = getelementptr inbounds i16, i16* %91, i64 %6
  %98 = load i16, i16* %97, align 2
  %99 = sext i16 %98 to i64
  %100 = getelementptr inbounds i16, i16* %91, i64 %8
  %101 = load i16, i16* %100, align 2
  %102 = sext i16 %101 to i64
  %103 = add nsw i64 %96, %93
  %104 = sub nsw i64 %102, %99
  %105 = sub nsw i64 %103, %104
  %106 = ashr i64 %105, 1
  %107 = sub nsw i64 %106, %96
  %108 = sub nsw i64 %106, %99
  %109 = sub nsw i64 %103, %108
  %110 = add nsw i64 %107, %104
  %111 = trunc i64 %107 to i32
  %112 = getelementptr inbounds i32, i32* %1, i64 15
  store i32 %111, i32* %112, align 4
  %113 = load i32, i32* %1, align 4
  %114 = sext i32 %113 to i64
  %115 = getelementptr inbounds i32, i32* %1, i64 2
  %116 = getelementptr inbounds i32, i32* %1, i64 3
  %117 = add nsw i64 %54, %114
  %118 = sub nsw i64 %109, %82
  %119 = sub nsw i64 %117, %118
  %120 = ashr i64 %119, 1
  %121 = sub nsw i64 %120, %54
  %122 = sub nsw i64 %120, %82
  %123 = sub nsw i64 %117, %122
  %124 = add nsw i64 %121, %118
  %125 = trunc i64 %123 to i32
  %126 = shl i32 %125, 2
  store i32 %126, i32* %1, align 4
  %127 = trunc i64 %122 to i32
  %128 = shl i32 %127, 2
  store i32 %128, i32* %36, align 4
  %129 = trunc i64 %124 to i32
  %130 = shl i32 %129, 2
  store i32 %130, i32* %115, align 4
  %131 = load i32, i32* %30, align 4
  %132 = sext i32 %131 to i64
  %133 = getelementptr inbounds i32, i32* %1, i64 5
  %134 = load i32, i32* %133, align 4
  %135 = sext i32 %134 to i64
  %136 = getelementptr inbounds i32, i32* %1, i64 7
  %137 = add nsw i64 %135, %132
  %138 = sub nsw i64 %108, %81
  %139 = sub nsw i64 %137, %138
  %140 = ashr i64 %139, 1
  %141 = sub nsw i64 %140, %135
  %142 = sub nsw i64 %140, %81
  %143 = sub nsw i64 %137, %142
  %144 = add nsw i64 %141, %138
  %145 = insertelement <4 x i64> undef, i64 %121, i32 0
  %146 = insertelement <4 x i64> %145, i64 %143, i32 1
  %147 = insertelement <4 x i64> %146, i64 %142, i32 2
  %148 = insertelement <4 x i64> %147, i64 %144, i32 3
  %149 = trunc <4 x i64> %148 to <4 x i32>
  %150 = shl <4 x i32> %149, <i32 2, i32 2, i32 2, i32 2>
  %151 = bitcast i32* %116 to <4 x i32>*
  store <4 x i32> %150, <4 x i32>* %151, align 4
  %152 = getelementptr inbounds i32, i32* %1, i64 8
  %153 = load i32, i32* %152, align 4
  %154 = sext i32 %153 to i64
  %155 = getelementptr inbounds i32, i32* %1, i64 9
  %156 = load i32, i32* %155, align 4
  %157 = sext i32 %156 to i64
  %158 = getelementptr inbounds i32, i32* %1, i64 11
  %159 = add nsw i64 %157, %154
  %160 = sub nsw i64 %110, %83
  %161 = sub nsw i64 %159, %160
  %162 = ashr i64 %161, 1
  %163 = sub nsw i64 %162, %157
  %164 = sub nsw i64 %162, %83
  %165 = sub nsw i64 %159, %164
  %166 = add nsw i64 %163, %160
  %167 = insertelement <4 x i64> undef, i64 %141, i32 0
  %168 = insertelement <4 x i64> %167, i64 %165, i32 1
  %169 = insertelement <4 x i64> %168, i64 %164, i32 2
  %170 = insertelement <4 x i64> %169, i64 %166, i32 3
  %171 = trunc <4 x i64> %170 to <4 x i32>
  %172 = shl <4 x i32> %171, <i32 2, i32 2, i32 2, i32 2>
  %173 = bitcast i32* %136 to <4 x i32>*
  store <4 x i32> %172, <4 x i32>* %173, align 4
  %174 = getelementptr inbounds i32, i32* %1, i64 12
  %175 = load i32, i32* %174, align 4
  %176 = sext i32 %175 to i64
  %177 = getelementptr inbounds i32, i32* %1, i64 13
  %178 = load i32, i32* %177, align 4
  %179 = sext i32 %178 to i64
  %180 = getelementptr inbounds i32, i32* %1, i64 14
  %181 = load i32, i32* %180, align 4
  %182 = sext i32 %181 to i64
  %183 = getelementptr inbounds i32, i32* %1, i64 15
  %184 = add nsw i64 %179, %176
  %185 = sub nsw i64 %107, %182
  %186 = sub nsw i64 %184, %185
  %187 = ashr i64 %186, 1
  %188 = sub nsw i64 %187, %179
  %189 = sub nsw i64 %187, %182
  %190 = sub nsw i64 %184, %189
  %191 = add nsw i64 %188, %185
  %192 = insertelement <4 x i64> undef, i64 %163, i32 0
  %193 = insertelement <4 x i64> %192, i64 %190, i32 1
  %194 = insertelement <4 x i64> %193, i64 %189, i32 2
  %195 = insertelement <4 x i64> %194, i64 %191, i32 3
  %196 = trunc <4 x i64> %195 to <4 x i32>
  %197 = shl <4 x i32> %196, <i32 2, i32 2, i32 2, i32 2>
  %198 = bitcast i32* %158 to <4 x i32>*
  store <4 x i32> %197, <4 x i32>* %198, align 4
  %199 = trunc i64 %188 to i32
  %200 = shl i32 %199, 2
  store i32 %200, i32* %183, align 4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vp9_fht16x16_c(i16*, i32*, i32, i32) local_unnamed_addr #0 {
  %5 = alloca [256 x i32], align 16
  %6 = alloca [16 x i32], align 16
  %7 = bitcast [16 x i32]* %6 to i8*
  %8 = alloca [16 x i32], align 16
  %9 = bitcast [16 x i32]* %8 to i8*
  %10 = icmp eq i32 %3, 0
  br i1 %10, label %11, label %12

11:                                               ; preds = %4
  tail call void @vpx_fdct16x16_c(i16* %0, i32* %1, i32 %2) #4
  br label %168

12:                                               ; preds = %4
  %13 = bitcast [256 x i32]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %13) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 1024, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %7) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 -86, i64 64, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 64, i1 false)
  %14 = sext i32 %3 to i64
  %15 = getelementptr inbounds [4 x %struct.transform_2d], [4 x %struct.transform_2d]* @FHT_16, i64 0, i64 %14, i32 0
  %16 = load void (i32*, i32*)*, void (i32*, i32*)** %15, align 16
  %17 = getelementptr inbounds [4 x %struct.transform_2d], [4 x %struct.transform_2d]* @FHT_16, i64 0, i64 %14, i32 1
  %18 = load void (i32*, i32*)*, void (i32*, i32*)** %17, align 8
  %19 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 0
  %20 = getelementptr inbounds [16 x i32], [16 x i32]* %8, i64 0, i64 0
  %21 = sext i32 %2 to i64
  %22 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 1
  %23 = shl nsw i64 %21, 1
  %24 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 2
  %25 = mul nsw i64 %21, 3
  %26 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 3
  %27 = shl nsw i64 %21, 2
  %28 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 4
  %29 = mul nsw i64 %21, 5
  %30 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 5
  %31 = mul nsw i64 %21, 6
  %32 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 6
  %33 = mul nsw i64 %21, 7
  %34 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 7
  %35 = shl nsw i64 %21, 3
  %36 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 8
  %37 = mul nsw i64 %21, 9
  %38 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 9
  %39 = mul nsw i64 %21, 10
  %40 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 10
  %41 = mul nsw i64 %21, 11
  %42 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 11
  %43 = mul nsw i64 %21, 12
  %44 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 12
  %45 = mul nsw i64 %21, 13
  %46 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 13
  %47 = mul nsw i64 %21, 14
  %48 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 14
  %49 = mul nsw i64 %21, 15
  %50 = getelementptr inbounds [16 x i32], [16 x i32]* %6, i64 0, i64 15
  br label %51

51:                                               ; preds = %155, %12
  %52 = phi i64 [ 0, %12 ], [ %156, %155 ]
  %53 = getelementptr inbounds i16, i16* %0, i64 %52
  %54 = load i16, i16* %53, align 2
  %55 = sext i16 %54 to i32
  %56 = shl nsw i32 %55, 2
  store i32 %56, i32* %19, align 16
  %57 = add nsw i64 %52, %21
  %58 = getelementptr inbounds i16, i16* %0, i64 %57
  %59 = load i16, i16* %58, align 2
  %60 = sext i16 %59 to i32
  %61 = shl nsw i32 %60, 2
  store i32 %61, i32* %22, align 4
  %62 = add nsw i64 %23, %52
  %63 = getelementptr inbounds i16, i16* %0, i64 %62
  %64 = load i16, i16* %63, align 2
  %65 = sext i16 %64 to i32
  %66 = shl nsw i32 %65, 2
  store i32 %66, i32* %24, align 8
  %67 = add nsw i64 %25, %52
  %68 = getelementptr inbounds i16, i16* %0, i64 %67
  %69 = load i16, i16* %68, align 2
  %70 = sext i16 %69 to i32
  %71 = shl nsw i32 %70, 2
  store i32 %71, i32* %26, align 4
  %72 = add nsw i64 %27, %52
  %73 = getelementptr inbounds i16, i16* %0, i64 %72
  %74 = load i16, i16* %73, align 2
  %75 = sext i16 %74 to i32
  %76 = shl nsw i32 %75, 2
  store i32 %76, i32* %28, align 16
  %77 = add nsw i64 %29, %52
  %78 = getelementptr inbounds i16, i16* %0, i64 %77
  %79 = load i16, i16* %78, align 2
  %80 = sext i16 %79 to i32
  %81 = shl nsw i32 %80, 2
  store i32 %81, i32* %30, align 4
  %82 = add nsw i64 %31, %52
  %83 = getelementptr inbounds i16, i16* %0, i64 %82
  %84 = load i16, i16* %83, align 2
  %85 = sext i16 %84 to i32
  %86 = shl nsw i32 %85, 2
  store i32 %86, i32* %32, align 8
  %87 = add nsw i64 %33, %52
  %88 = getelementptr inbounds i16, i16* %0, i64 %87
  %89 = load i16, i16* %88, align 2
  %90 = sext i16 %89 to i32
  %91 = shl nsw i32 %90, 2
  store i32 %91, i32* %34, align 4
  %92 = add nsw i64 %35, %52
  %93 = getelementptr inbounds i16, i16* %0, i64 %92
  %94 = load i16, i16* %93, align 2
  %95 = sext i16 %94 to i32
  %96 = shl nsw i32 %95, 2
  store i32 %96, i32* %36, align 16
  %97 = add nsw i64 %37, %52
  %98 = getelementptr inbounds i16, i16* %0, i64 %97
  %99 = load i16, i16* %98, align 2
  %100 = sext i16 %99 to i32
  %101 = shl nsw i32 %100, 2
  store i32 %101, i32* %38, align 4
  %102 = add nsw i64 %39, %52
  %103 = getelementptr inbounds i16, i16* %0, i64 %102
  %104 = load i16, i16* %103, align 2
  %105 = sext i16 %104 to i32
  %106 = shl nsw i32 %105, 2
  store i32 %106, i32* %40, align 8
  %107 = add nsw i64 %41, %52
  %108 = getelementptr inbounds i16, i16* %0, i64 %107
  %109 = load i16, i16* %108, align 2
  %110 = sext i16 %109 to i32
  %111 = shl nsw i32 %110, 2
  store i32 %111, i32* %42, align 4
  %112 = add nsw i64 %43, %52
  %113 = getelementptr inbounds i16, i16* %0, i64 %112
  %114 = load i16, i16* %113, align 2
  %115 = sext i16 %114 to i32
  %116 = shl nsw i32 %115, 2
  store i32 %116, i32* %44, align 16
  %117 = add nsw i64 %45, %52
  %118 = getelementptr inbounds i16, i16* %0, i64 %117
  %119 = load i16, i16* %118, align 2
  %120 = sext i16 %119 to i32
  %121 = shl nsw i32 %120, 2
  store i32 %121, i32* %46, align 4
  %122 = add nsw i64 %47, %52
  %123 = getelementptr inbounds i16, i16* %0, i64 %122
  %124 = load i16, i16* %123, align 2
  %125 = sext i16 %124 to i32
  %126 = shl nsw i32 %125, 2
  store i32 %126, i32* %48, align 8
  %127 = add nsw i64 %49, %52
  %128 = getelementptr inbounds i16, i16* %0, i64 %127
  %129 = load i16, i16* %128, align 2
  %130 = sext i16 %129 to i32
  %131 = shl nsw i32 %130, 2
  store i32 %131, i32* %50, align 4
  call void %16(i32* nonnull %19, i32* nonnull %20) #4
  br label %132

132:                                              ; preds = %132, %51
  %133 = phi i64 [ 0, %51 ], [ %153, %132 ]
  %134 = getelementptr inbounds [16 x i32], [16 x i32]* %8, i64 0, i64 %133
  %135 = load i32, i32* %134, align 8
  %136 = add nsw i32 %135, 1
  %137 = lshr i32 %135, 31
  %138 = add nsw i32 %136, %137
  %139 = ashr i32 %138, 2
  %140 = shl i64 %133, 4
  %141 = add nuw nsw i64 %140, %52
  %142 = getelementptr inbounds [256 x i32], [256 x i32]* %5, i64 0, i64 %141
  store i32 %139, i32* %142, align 4
  %143 = or i64 %133, 1
  %144 = getelementptr inbounds [16 x i32], [16 x i32]* %8, i64 0, i64 %143
  %145 = load i32, i32* %144, align 4
  %146 = add nsw i32 %145, 1
  %147 = lshr i32 %145, 31
  %148 = add nsw i32 %146, %147
  %149 = ashr i32 %148, 2
  %150 = shl i64 %143, 4
  %151 = add nuw nsw i64 %150, %52
  %152 = getelementptr inbounds [256 x i32], [256 x i32]* %5, i64 0, i64 %151
  store i32 %149, i32* %152, align 4
  %153 = add nuw nsw i64 %133, 2
  %154 = icmp eq i64 %153, 16
  br i1 %154, label %155, label %132

155:                                              ; preds = %132
  %156 = add nuw nsw i64 %52, 1
  %157 = icmp eq i64 %156, 16
  br i1 %157, label %158, label %51

158:                                              ; preds = %155, %158
  %159 = phi i64 [ %165, %158 ], [ 0, %155 ]
  %160 = shl nuw nsw i64 %159, 4
  %161 = getelementptr i32, i32* %1, i64 %160
  %162 = bitcast i32* %161 to i8*
  %163 = getelementptr [256 x i32], [256 x i32]* %5, i64 0, i64 %160
  %164 = bitcast i32* %163 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %7, i8* align 16 %164, i64 64, i1 false)
  call void %18(i32* nonnull %19, i32* nonnull %20) #4
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %162, i8* nonnull align 16 %9, i64 64, i1 false)
  %165 = add nuw nsw i64 %159, 1
  %166 = icmp eq i64 %165, 16
  br i1 %166, label %167, label %158

167:                                              ; preds = %158
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %9) #4
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %7) #4
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %13) #4
  br label %168

168:                                              ; preds = %167, %11
  ret void
}

declare void @vpx_fdct16x16_c(i16*, i32*, i32) local_unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define hidden void @vp9_highbd_fht4x4_c(i16*, i32*, i32, i32) local_unnamed_addr #0 {
  tail call void @vp9_fht4x4_c(i16* %0, i32* %1, i32 %2, i32 %3)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vp9_highbd_fht8x8_c(i16*, i32*, i32, i32) local_unnamed_addr #0 {
  tail call void @vp9_fht8x8_c(i16* %0, i32* %1, i32 %2, i32 %3)
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @vp9_highbd_fwht4x4_c(i16* nocapture readonly, i32* nocapture, i32) local_unnamed_addr #3 {
  tail call void @vp9_fwht4x4_c(i16* %0, i32* %1, i32 %2)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vp9_highbd_fht16x16_c(i16*, i32*, i32, i32) local_unnamed_addr #0 {
  tail call void @vp9_fht16x16_c(i16* %0, i32* %1, i32 %2, i32 %3)
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @fdct4(i32* nocapture readonly, i32* nocapture) #3 {
  %3 = load i32, i32* %0, align 4
  %4 = getelementptr inbounds i32, i32* %0, i64 3
  %5 = load i32, i32* %4, align 4
  %6 = add nsw i32 %5, %3
  %7 = sext i32 %6 to i64
  %8 = getelementptr inbounds i32, i32* %0, i64 1
  %9 = load i32, i32* %8, align 4
  %10 = getelementptr inbounds i32, i32* %0, i64 2
  %11 = load i32, i32* %10, align 4
  %12 = add nsw i32 %11, %9
  %13 = sext i32 %12 to i64
  %14 = sub nsw i32 %9, %11
  %15 = sext i32 %14 to i64
  %16 = sub nsw i32 %3, %5
  %17 = sext i32 %16 to i64
  %18 = add nsw i64 %13, %7
  %19 = mul nsw i64 %18, 11585
  %20 = sub nsw i64 %7, %13
  %21 = mul nsw i64 %20, 11585
  %22 = add nsw i64 %19, 8192
  %23 = lshr i64 %22, 14
  %24 = trunc i64 %23 to i32
  store i32 %24, i32* %1, align 4
  %25 = add nsw i64 %21, 8192
  %26 = lshr i64 %25, 14
  %27 = trunc i64 %26 to i32
  %28 = getelementptr inbounds i32, i32* %1, i64 2
  store i32 %27, i32* %28, align 4
  %29 = mul nsw i64 %15, 6270
  %30 = mul nsw i64 %17, 15137
  %31 = mul nsw i64 %15, -15137
  %32 = mul nsw i64 %17, 6270
  %33 = add nsw i64 %30, 8192
  %34 = add nsw i64 %33, %29
  %35 = lshr i64 %34, 14
  %36 = trunc i64 %35 to i32
  %37 = getelementptr inbounds i32, i32* %1, i64 1
  store i32 %36, i32* %37, align 4
  %38 = add nsw i64 %32, 8192
  %39 = add nsw i64 %38, %31
  %40 = lshr i64 %39, 14
  %41 = trunc i64 %40 to i32
  %42 = getelementptr inbounds i32, i32* %1, i64 3
  store i32 %41, i32* %42, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @fadst4(i32* nocapture readonly, i32* nocapture) #3 {
  %3 = load i32, i32* %0, align 4
  %4 = sext i32 %3 to i64
  %5 = getelementptr inbounds i32, i32* %0, i64 1
  %6 = load i32, i32* %5, align 4
  %7 = sext i32 %6 to i64
  %8 = getelementptr inbounds i32, i32* %0, i64 2
  %9 = load i32, i32* %8, align 4
  %10 = getelementptr inbounds i32, i32* %0, i64 3
  %11 = load i32, i32* %10, align 4
  %12 = sext i32 %11 to i64
  %13 = or i32 %6, %3
  %14 = or i32 %13, %9
  %15 = or i32 %14, %11
  %16 = icmp eq i32 %15, 0
  br i1 %16, label %17, label %18

17:                                               ; preds = %2
  store i32 0, i32* %1, align 4
  br label %49

18:                                               ; preds = %2
  %19 = sext i32 %9 to i64
  %20 = mul nsw i64 %4, 5283
  %21 = mul nsw i64 %4, 15212
  %22 = mul nsw i64 %7, 9929
  %23 = mul nsw i64 %19, 13377
  %24 = mul nsw i64 %12, 15212
  %25 = mul nsw i64 %12, 9929
  %26 = add nsw i64 %7, %4
  %27 = sub nsw i64 %26, %12
  %28 = add nsw i64 %22, %20
  %29 = add nsw i64 %28, %24
  %30 = mul nsw i64 %27, 13377
  %31 = mul nsw i64 %7, -5283
  %32 = add nsw i64 %31, %21
  %33 = add nsw i64 %32, %25
  %34 = add nsw i64 %23, 8192
  %35 = add nsw i64 %34, %29
  %36 = lshr i64 %35, 14
  %37 = trunc i64 %36 to i32
  store i32 %37, i32* %1, align 4
  %38 = add nsw i64 %30, 8192
  %39 = lshr i64 %38, 14
  %40 = trunc i64 %39 to i32
  %41 = sub nsw i64 8192, %23
  %42 = add nsw i64 %41, %33
  %43 = lshr i64 %42, 14
  %44 = trunc i64 %43 to i32
  %45 = sub nsw i64 %34, %29
  %46 = add nsw i64 %45, %33
  %47 = lshr i64 %46, 14
  %48 = trunc i64 %47 to i32
  br label %49

49:                                               ; preds = %18, %17
  %50 = phi i32 [ %40, %18 ], [ 0, %17 ]
  %51 = phi i32 [ %44, %18 ], [ 0, %17 ]
  %52 = phi i32 [ %48, %18 ], [ 0, %17 ]
  %53 = getelementptr inbounds i32, i32* %1, i64 1
  store i32 %50, i32* %53, align 4
  %54 = getelementptr inbounds i32, i32* %1, i64 2
  store i32 %51, i32* %54, align 4
  %55 = getelementptr inbounds i32, i32* %1, i64 3
  store i32 %52, i32* %55, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @fdct8(i32* nocapture readonly, i32* nocapture) #3 {
  %3 = load i32, i32* %0, align 4
  %4 = getelementptr inbounds i32, i32* %0, i64 7
  %5 = load i32, i32* %4, align 4
  %6 = add nsw i32 %5, %3
  %7 = sext i32 %6 to i64
  %8 = getelementptr inbounds i32, i32* %0, i64 1
  %9 = load i32, i32* %8, align 4
  %10 = getelementptr inbounds i32, i32* %0, i64 6
  %11 = load i32, i32* %10, align 4
  %12 = add nsw i32 %11, %9
  %13 = sext i32 %12 to i64
  %14 = getelementptr inbounds i32, i32* %0, i64 2
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds i32, i32* %0, i64 5
  %17 = load i32, i32* %16, align 4
  %18 = add nsw i32 %17, %15
  %19 = sext i32 %18 to i64
  %20 = getelementptr inbounds i32, i32* %0, i64 3
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds i32, i32* %0, i64 4
  %23 = load i32, i32* %22, align 4
  %24 = add nsw i32 %23, %21
  %25 = sext i32 %24 to i64
  %26 = sub nsw i32 %21, %23
  %27 = sext i32 %26 to i64
  %28 = sub nsw i32 %15, %17
  %29 = sext i32 %28 to i64
  %30 = sub nsw i32 %9, %11
  %31 = sext i32 %30 to i64
  %32 = sub nsw i32 %3, %5
  %33 = sext i32 %32 to i64
  %34 = add nsw i64 %25, %7
  %35 = add nsw i64 %19, %13
  %36 = sub nsw i64 %13, %19
  %37 = sub nsw i64 %7, %25
  %38 = add nsw i64 %34, %35
  %39 = mul nsw i64 %38, 11585
  %40 = sub nsw i64 %34, %35
  %41 = mul nsw i64 %40, 11585
  %42 = mul nsw i64 %36, 6270
  %43 = mul nsw i64 %37, 15137
  %44 = mul nsw i64 %36, -15137
  %45 = mul nsw i64 %37, 6270
  %46 = add nsw i64 %39, 8192
  %47 = lshr i64 %46, 14
  %48 = trunc i64 %47 to i32
  store i32 %48, i32* %1, align 4
  %49 = add nsw i64 %42, 8192
  %50 = add nsw i64 %49, %43
  %51 = lshr i64 %50, 14
  %52 = trunc i64 %51 to i32
  %53 = getelementptr inbounds i32, i32* %1, i64 2
  store i32 %52, i32* %53, align 4
  %54 = add nsw i64 %41, 8192
  %55 = lshr i64 %54, 14
  %56 = trunc i64 %55 to i32
  %57 = getelementptr inbounds i32, i32* %1, i64 4
  store i32 %56, i32* %57, align 4
  %58 = add nsw i64 %44, 8192
  %59 = add nsw i64 %58, %45
  %60 = lshr i64 %59, 14
  %61 = trunc i64 %60 to i32
  %62 = getelementptr inbounds i32, i32* %1, i64 6
  store i32 %61, i32* %62, align 4
  %63 = sub nsw i64 %31, %29
  %64 = mul nsw i64 %63, 11585
  %65 = add nsw i64 %29, %31
  %66 = mul nsw i64 %65, 11585
  %67 = add nsw i64 %64, 8192
  %68 = lshr i64 %67, 14
  %69 = shl i64 %68, 32
  %70 = ashr exact i64 %69, 32
  %71 = add nsw i64 %66, 8192
  %72 = lshr i64 %71, 14
  %73 = shl i64 %72, 32
  %74 = ashr exact i64 %73, 32
  %75 = add nsw i64 %70, %27
  %76 = sub nsw i64 %27, %70
  %77 = sub nsw i64 %33, %74
  %78 = add nsw i64 %74, %33
  %79 = mul nsw i64 %75, 3196
  %80 = mul nsw i64 %78, 16069
  %81 = mul nsw i64 %76, 13623
  %82 = mul nsw i64 %77, 9102
  %83 = mul nsw i64 %77, 13623
  %84 = mul nsw i64 %76, -9102
  %85 = mul nsw i64 %78, 3196
  %86 = mul nsw i64 %75, -16069
  %87 = add nsw i64 %80, 8192
  %88 = add nsw i64 %87, %79
  %89 = lshr i64 %88, 14
  %90 = trunc i64 %89 to i32
  %91 = getelementptr inbounds i32, i32* %1, i64 1
  store i32 %90, i32* %91, align 4
  %92 = add nsw i64 %84, 8192
  %93 = add nsw i64 %92, %83
  %94 = lshr i64 %93, 14
  %95 = trunc i64 %94 to i32
  %96 = getelementptr inbounds i32, i32* %1, i64 3
  store i32 %95, i32* %96, align 4
  %97 = add nsw i64 %82, 8192
  %98 = add nsw i64 %97, %81
  %99 = lshr i64 %98, 14
  %100 = trunc i64 %99 to i32
  %101 = getelementptr inbounds i32, i32* %1, i64 5
  store i32 %100, i32* %101, align 4
  %102 = add nsw i64 %86, 8192
  %103 = add nsw i64 %102, %85
  %104 = lshr i64 %103, 14
  %105 = trunc i64 %104 to i32
  %106 = getelementptr inbounds i32, i32* %1, i64 7
  store i32 %105, i32* %106, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @fadst8(i32* nocapture readonly, i32* nocapture) #3 {
  %3 = getelementptr inbounds i32, i32* %0, i64 7
  %4 = load i32, i32* %3, align 4
  %5 = sext i32 %4 to i64
  %6 = load i32, i32* %0, align 4
  %7 = sext i32 %6 to i64
  %8 = getelementptr inbounds i32, i32* %0, i64 5
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i32, i32* %0, i64 2
  %12 = load i32, i32* %11, align 4
  %13 = sext i32 %12 to i64
  %14 = getelementptr inbounds i32, i32* %0, i64 3
  %15 = load i32, i32* %14, align 4
  %16 = sext i32 %15 to i64
  %17 = getelementptr inbounds i32, i32* %0, i64 4
  %18 = load i32, i32* %17, align 4
  %19 = sext i32 %18 to i64
  %20 = getelementptr inbounds i32, i32* %0, i64 1
  %21 = load i32, i32* %20, align 4
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %0, i64 6
  %24 = load i32, i32* %23, align 4
  %25 = sext i32 %24 to i64
  %26 = mul nsw i64 %5, 16305
  %27 = mul nsw i64 %7, 1606
  %28 = add nsw i64 %27, %26
  %29 = mul nsw i64 %5, 1606
  %30 = mul nsw i64 %7, -16305
  %31 = add nsw i64 %30, %29
  %32 = mul nsw i64 %10, 14449
  %33 = mul nsw i64 %13, 7723
  %34 = add nsw i64 %33, %32
  %35 = mul nsw i64 %10, 7723
  %36 = mul nsw i64 %13, -14449
  %37 = add nsw i64 %36, %35
  %38 = mul nsw i64 %16, 10394
  %39 = mul nsw i64 %19, 12665
  %40 = add nsw i64 %39, %38
  %41 = mul nsw i64 %16, 12665
  %42 = mul nsw i64 %19, -10394
  %43 = add nsw i64 %42, %41
  %44 = mul nsw i64 %22, 4756
  %45 = mul nsw i64 %25, 15679
  %46 = add nsw i64 %45, %44
  %47 = mul nsw i64 %22, 15679
  %48 = mul nsw i64 %25, -4756
  %49 = add nsw i64 %48, %47
  %50 = add nsw i64 %28, 8192
  %51 = add nsw i64 %50, %40
  %52 = ashr i64 %51, 14
  %53 = add nsw i64 %31, 8192
  %54 = add nsw i64 %53, %43
  %55 = ashr i64 %54, 14
  %56 = add nsw i64 %34, 8192
  %57 = add nsw i64 %56, %46
  %58 = ashr i64 %57, 14
  %59 = add nsw i64 %37, 8192
  %60 = add nsw i64 %59, %49
  %61 = ashr i64 %60, 14
  %62 = sub nsw i64 %50, %40
  %63 = ashr i64 %62, 14
  %64 = sub nsw i64 %53, %43
  %65 = ashr i64 %64, 14
  %66 = sub nsw i64 %56, %46
  %67 = ashr i64 %66, 14
  %68 = sub nsw i64 %59, %49
  %69 = ashr i64 %68, 14
  %70 = mul nsw i64 %63, 15137
  %71 = mul nsw i64 %65, 6270
  %72 = add nsw i64 %70, %71
  %73 = mul nsw i64 %63, 6270
  %74 = mul nsw i64 %65, -15137
  %75 = add nsw i64 %73, %74
  %76 = mul nsw i64 %67, -6270
  %77 = mul nsw i64 %69, 15137
  %78 = add nsw i64 %76, %77
  %79 = mul nsw i64 %67, 15137
  %80 = mul nsw i64 %69, 6270
  %81 = add nsw i64 %79, %80
  %82 = add nsw i64 %58, %52
  %83 = add nsw i64 %61, %55
  %84 = sub nsw i64 %52, %58
  %85 = sub nsw i64 %55, %61
  %86 = add nsw i64 %72, 8192
  %87 = add nsw i64 %86, %78
  %88 = lshr i64 %87, 14
  %89 = add nsw i64 %75, 8192
  %90 = add nsw i64 %89, %81
  %91 = lshr i64 %90, 14
  %92 = sub nsw i64 %86, %78
  %93 = ashr i64 %92, 14
  %94 = sub nsw i64 %89, %81
  %95 = ashr i64 %94, 14
  %96 = add nsw i64 %84, %85
  %97 = mul nsw i64 %96, 11585
  %98 = sub nsw i64 %84, %85
  %99 = mul nsw i64 %98, 11585
  %100 = add nsw i64 %93, %95
  %101 = mul nsw i64 %100, 11585
  %102 = sub nsw i64 %93, %95
  %103 = mul nsw i64 %102, 11585
  %104 = add nsw i64 %97, 8192
  %105 = lshr i64 %104, 14
  %106 = add nsw i64 %99, 8192
  %107 = lshr i64 %106, 14
  %108 = add nsw i64 %101, 8192
  %109 = lshr i64 %108, 14
  %110 = add nsw i64 %103, 8192
  %111 = lshr i64 %110, 14
  %112 = trunc i64 %82 to i32
  store i32 %112, i32* %1, align 4
  %113 = trunc i64 %88 to i32
  %114 = sub i32 0, %113
  %115 = getelementptr inbounds i32, i32* %1, i64 1
  store i32 %114, i32* %115, align 4
  %116 = trunc i64 %109 to i32
  %117 = getelementptr inbounds i32, i32* %1, i64 2
  store i32 %116, i32* %117, align 4
  %118 = trunc i64 %105 to i32
  %119 = sub i32 0, %118
  %120 = getelementptr inbounds i32, i32* %1, i64 3
  store i32 %119, i32* %120, align 4
  %121 = trunc i64 %107 to i32
  %122 = getelementptr inbounds i32, i32* %1, i64 4
  store i32 %121, i32* %122, align 4
  %123 = trunc i64 %111 to i32
  %124 = sub i32 0, %123
  %125 = getelementptr inbounds i32, i32* %1, i64 5
  store i32 %124, i32* %125, align 4
  %126 = trunc i64 %91 to i32
  %127 = getelementptr inbounds i32, i32* %1, i64 6
  store i32 %126, i32* %127, align 4
  %128 = trunc i64 %83 to i32
  %129 = sub i32 0, %128
  %130 = getelementptr inbounds i32, i32* %1, i64 7
  store i32 %129, i32* %130, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @fdct16(i32* nocapture readonly, i32* nocapture) #3 {
  %3 = load i32, i32* %0, align 4
  %4 = getelementptr inbounds i32, i32* %0, i64 15
  %5 = load i32, i32* %4, align 4
  %6 = add nsw i32 %5, %3
  %7 = sext i32 %6 to i64
  %8 = getelementptr inbounds i32, i32* %0, i64 1
  %9 = load i32, i32* %8, align 4
  %10 = getelementptr inbounds i32, i32* %0, i64 14
  %11 = load i32, i32* %10, align 4
  %12 = add nsw i32 %11, %9
  %13 = sext i32 %12 to i64
  %14 = getelementptr inbounds i32, i32* %0, i64 2
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds i32, i32* %0, i64 13
  %17 = load i32, i32* %16, align 4
  %18 = add nsw i32 %17, %15
  %19 = sext i32 %18 to i64
  %20 = getelementptr inbounds i32, i32* %0, i64 3
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds i32, i32* %0, i64 12
  %23 = load i32, i32* %22, align 4
  %24 = add nsw i32 %23, %21
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i32, i32* %0, i64 4
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds i32, i32* %0, i64 11
  %29 = load i32, i32* %28, align 4
  %30 = add nsw i32 %29, %27
  %31 = sext i32 %30 to i64
  %32 = getelementptr inbounds i32, i32* %0, i64 5
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds i32, i32* %0, i64 10
  %35 = load i32, i32* %34, align 4
  %36 = add nsw i32 %35, %33
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds i32, i32* %0, i64 6
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds i32, i32* %0, i64 9
  %41 = load i32, i32* %40, align 4
  %42 = add nsw i32 %41, %39
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i32, i32* %0, i64 7
  %45 = load i32, i32* %44, align 4
  %46 = getelementptr inbounds i32, i32* %0, i64 8
  %47 = load i32, i32* %46, align 4
  %48 = add nsw i32 %47, %45
  %49 = sext i32 %48 to i64
  %50 = sub nsw i32 %45, %47
  %51 = sext i32 %50 to i64
  %52 = sub nsw i32 %39, %41
  %53 = sext i32 %52 to i64
  %54 = sub nsw i32 %33, %35
  %55 = sext i32 %54 to i64
  %56 = sub nsw i32 %27, %29
  %57 = sext i32 %56 to i64
  %58 = sub nsw i32 %21, %23
  %59 = sext i32 %58 to i64
  %60 = sub nsw i32 %15, %17
  %61 = sext i32 %60 to i64
  %62 = sub nsw i32 %9, %11
  %63 = sext i32 %62 to i64
  %64 = sub nsw i32 %3, %5
  %65 = sext i32 %64 to i64
  %66 = add nsw i64 %49, %7
  %67 = add nsw i64 %43, %13
  %68 = add nsw i64 %37, %19
  %69 = add nsw i64 %31, %25
  %70 = sub nsw i64 %25, %31
  %71 = sub nsw i64 %19, %37
  %72 = sub nsw i64 %13, %43
  %73 = sub nsw i64 %7, %49
  %74 = add nsw i64 %66, %69
  %75 = add nsw i64 %67, %68
  %76 = sub nsw i64 %67, %68
  %77 = sub nsw i64 %66, %69
  %78 = add nsw i64 %74, %75
  %79 = mul nsw i64 %78, 11585
  %80 = sub nsw i64 %74, %75
  %81 = mul nsw i64 %80, 11585
  %82 = mul nsw i64 %77, 15137
  %83 = mul nsw i64 %76, 6270
  %84 = mul nsw i64 %77, 6270
  %85 = mul nsw i64 %76, -15137
  %86 = add nsw i64 %79, 8192
  %87 = lshr i64 %86, 14
  %88 = trunc i64 %87 to i32
  store i32 %88, i32* %1, align 4
  %89 = add nsw i64 %83, 8192
  %90 = add nsw i64 %89, %82
  %91 = lshr i64 %90, 14
  %92 = trunc i64 %91 to i32
  %93 = getelementptr inbounds i32, i32* %1, i64 4
  store i32 %92, i32* %93, align 4
  %94 = add nsw i64 %81, 8192
  %95 = lshr i64 %94, 14
  %96 = trunc i64 %95 to i32
  %97 = getelementptr inbounds i32, i32* %1, i64 8
  store i32 %96, i32* %97, align 4
  %98 = add nsw i64 %85, 8192
  %99 = add nsw i64 %98, %84
  %100 = lshr i64 %99, 14
  %101 = trunc i64 %100 to i32
  %102 = getelementptr inbounds i32, i32* %1, i64 12
  store i32 %101, i32* %102, align 4
  %103 = sub nsw i64 %72, %71
  %104 = mul nsw i64 %103, 11585
  %105 = add nsw i64 %72, %71
  %106 = mul nsw i64 %105, 11585
  %107 = add nsw i64 %104, 8192
  %108 = ashr i64 %107, 14
  %109 = add nsw i64 %106, 8192
  %110 = ashr i64 %109, 14
  %111 = add nsw i64 %108, %70
  %112 = sub nsw i64 %70, %108
  %113 = sub nsw i64 %73, %110
  %114 = add nsw i64 %110, %73
  %115 = mul nsw i64 %111, 3196
  %116 = mul nsw i64 %114, 16069
  %117 = mul nsw i64 %112, 13623
  %118 = mul nsw i64 %113, 9102
  %119 = mul nsw i64 %113, 13623
  %120 = mul nsw i64 %112, -9102
  %121 = mul nsw i64 %114, 3196
  %122 = mul nsw i64 %111, -16069
  %123 = add nsw i64 %116, 8192
  %124 = add nsw i64 %123, %115
  %125 = lshr i64 %124, 14
  %126 = trunc i64 %125 to i32
  %127 = getelementptr inbounds i32, i32* %1, i64 2
  store i32 %126, i32* %127, align 4
  %128 = add nsw i64 %120, 8192
  %129 = add nsw i64 %128, %119
  %130 = lshr i64 %129, 14
  %131 = trunc i64 %130 to i32
  %132 = getelementptr inbounds i32, i32* %1, i64 6
  store i32 %131, i32* %132, align 4
  %133 = add nsw i64 %118, 8192
  %134 = add nsw i64 %133, %117
  %135 = lshr i64 %134, 14
  %136 = trunc i64 %135 to i32
  %137 = getelementptr inbounds i32, i32* %1, i64 10
  store i32 %136, i32* %137, align 4
  %138 = add nsw i64 %122, 8192
  %139 = add nsw i64 %138, %121
  %140 = lshr i64 %139, 14
  %141 = trunc i64 %140 to i32
  %142 = getelementptr inbounds i32, i32* %1, i64 14
  store i32 %141, i32* %142, align 4
  %143 = sub nsw i64 %61, %55
  %144 = mul nsw i64 %143, 11585
  %145 = sub nsw i64 %59, %57
  %146 = mul nsw i64 %145, 11585
  %147 = add nsw i64 %144, 8192
  %148 = ashr i64 %147, 14
  %149 = add nsw i64 %146, 8192
  %150 = ashr i64 %149, 14
  %151 = add nsw i64 %57, %59
  %152 = mul nsw i64 %151, 11585
  %153 = add nsw i64 %55, %61
  %154 = mul nsw i64 %153, 11585
  %155 = add nsw i64 %152, 8192
  %156 = ashr i64 %155, 14
  %157 = add nsw i64 %154, 8192
  %158 = ashr i64 %157, 14
  %159 = add nsw i64 %150, %51
  %160 = add nsw i64 %148, %53
  %161 = sub nsw i64 %53, %148
  %162 = sub nsw i64 %51, %150
  %163 = sub nsw i64 %65, %156
  %164 = sub nsw i64 %63, %158
  %165 = add nsw i64 %158, %63
  %166 = add nsw i64 %156, %65
  %167 = mul nsw i64 %160, -15137
  %168 = mul nsw i64 %165, 6270
  %169 = mul nsw i64 %161, 6270
  %170 = mul nsw i64 %164, 15137
  %171 = add nsw i64 %168, 8192
  %172 = add nsw i64 %171, %167
  %173 = ashr i64 %172, 14
  %174 = add nsw i64 %170, 8192
  %175 = add nsw i64 %174, %169
  %176 = ashr i64 %175, 14
  %177 = mul nsw i64 %161, 15137
  %178 = mul nsw i64 %164, -6270
  %179 = mul nsw i64 %160, 6270
  %180 = mul nsw i64 %165, 15137
  %181 = add nsw i64 %178, 8192
  %182 = add nsw i64 %181, %177
  %183 = ashr i64 %182, 14
  %184 = add nsw i64 %180, 8192
  %185 = add nsw i64 %184, %179
  %186 = ashr i64 %185, 14
  %187 = add nsw i64 %173, %159
  %188 = sub nsw i64 %159, %173
  %189 = add nsw i64 %176, %162
  %190 = sub nsw i64 %162, %176
  %191 = sub nsw i64 %163, %183
  %192 = add nsw i64 %183, %163
  %193 = sub nsw i64 %166, %186
  %194 = add nsw i64 %186, %166
  %195 = mul nsw i64 %187, 1606
  %196 = mul nsw i64 %194, 16305
  %197 = mul nsw i64 %188, 12665
  %198 = mul nsw i64 %193, 10394
  %199 = add nsw i64 %196, 8192
  %200 = add nsw i64 %199, %195
  %201 = lshr i64 %200, 14
  %202 = trunc i64 %201 to i32
  %203 = getelementptr inbounds i32, i32* %1, i64 1
  store i32 %202, i32* %203, align 4
  %204 = add nsw i64 %198, 8192
  %205 = add nsw i64 %204, %197
  %206 = lshr i64 %205, 14
  %207 = trunc i64 %206 to i32
  %208 = getelementptr inbounds i32, i32* %1, i64 9
  store i32 %207, i32* %208, align 4
  %209 = mul nsw i64 %189, 7723
  %210 = mul nsw i64 %192, 14449
  %211 = mul nsw i64 %190, 15679
  %212 = mul nsw i64 %191, 4756
  %213 = add nsw i64 %210, 8192
  %214 = add nsw i64 %213, %209
  %215 = lshr i64 %214, 14
  %216 = trunc i64 %215 to i32
  %217 = getelementptr inbounds i32, i32* %1, i64 5
  store i32 %216, i32* %217, align 4
  %218 = add nsw i64 %212, 8192
  %219 = add nsw i64 %218, %211
  %220 = lshr i64 %219, 14
  %221 = trunc i64 %220 to i32
  %222 = getelementptr inbounds i32, i32* %1, i64 13
  store i32 %221, i32* %222, align 4
  %223 = mul nsw i64 %190, -4756
  %224 = mul nsw i64 %191, 15679
  %225 = mul nsw i64 %189, -14449
  %226 = mul nsw i64 %192, 7723
  %227 = add nsw i64 %224, 8192
  %228 = add nsw i64 %227, %223
  %229 = lshr i64 %228, 14
  %230 = trunc i64 %229 to i32
  %231 = getelementptr inbounds i32, i32* %1, i64 3
  store i32 %230, i32* %231, align 4
  %232 = add nsw i64 %226, 8192
  %233 = add nsw i64 %232, %225
  %234 = lshr i64 %233, 14
  %235 = trunc i64 %234 to i32
  %236 = getelementptr inbounds i32, i32* %1, i64 11
  store i32 %235, i32* %236, align 4
  %237 = mul nsw i64 %188, -10394
  %238 = mul nsw i64 %193, 12665
  %239 = mul nsw i64 %187, -16305
  %240 = mul nsw i64 %194, 1606
  %241 = add nsw i64 %238, 8192
  %242 = add nsw i64 %241, %237
  %243 = lshr i64 %242, 14
  %244 = trunc i64 %243 to i32
  %245 = getelementptr inbounds i32, i32* %1, i64 7
  store i32 %244, i32* %245, align 4
  %246 = add nsw i64 %240, 8192
  %247 = add nsw i64 %246, %239
  %248 = lshr i64 %247, 14
  %249 = trunc i64 %248 to i32
  %250 = getelementptr inbounds i32, i32* %1, i64 15
  store i32 %249, i32* %250, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @fadst16(i32* nocapture readonly, i32* nocapture) #3 {
  %3 = getelementptr inbounds i32, i32* %0, i64 15
  %4 = load i32, i32* %3, align 4
  %5 = sext i32 %4 to i64
  %6 = load i32, i32* %0, align 4
  %7 = sext i32 %6 to i64
  %8 = getelementptr inbounds i32, i32* %0, i64 13
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i32, i32* %0, i64 2
  %12 = load i32, i32* %11, align 4
  %13 = sext i32 %12 to i64
  %14 = getelementptr inbounds i32, i32* %0, i64 11
  %15 = load i32, i32* %14, align 4
  %16 = sext i32 %15 to i64
  %17 = getelementptr inbounds i32, i32* %0, i64 4
  %18 = load i32, i32* %17, align 4
  %19 = sext i32 %18 to i64
  %20 = getelementptr inbounds i32, i32* %0, i64 9
  %21 = load i32, i32* %20, align 4
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %0, i64 6
  %24 = load i32, i32* %23, align 4
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i32, i32* %0, i64 7
  %27 = load i32, i32* %26, align 4
  %28 = sext i32 %27 to i64
  %29 = getelementptr inbounds i32, i32* %0, i64 8
  %30 = load i32, i32* %29, align 4
  %31 = sext i32 %30 to i64
  %32 = getelementptr inbounds i32, i32* %0, i64 5
  %33 = load i32, i32* %32, align 4
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds i32, i32* %0, i64 10
  %36 = load i32, i32* %35, align 4
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds i32, i32* %0, i64 3
  %39 = load i32, i32* %38, align 4
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds i32, i32* %0, i64 12
  %42 = load i32, i32* %41, align 4
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i32, i32* %0, i64 1
  %45 = load i32, i32* %44, align 4
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds i32, i32* %0, i64 14
  %48 = load i32, i32* %47, align 4
  %49 = sext i32 %48 to i64
  %50 = mul nsw i64 %5, 16364
  %51 = mul nsw i64 %7, 804
  %52 = add nsw i64 %51, %50
  %53 = mul nsw i64 %5, 804
  %54 = mul nsw i64 %7, -16364
  %55 = add nsw i64 %54, %53
  %56 = mul nsw i64 %10, 15893
  %57 = mul nsw i64 %13, 3981
  %58 = add nsw i64 %57, %56
  %59 = mul nsw i64 %10, 3981
  %60 = mul nsw i64 %13, -15893
  %61 = add nsw i64 %60, %59
  %62 = mul nsw i64 %16, 14811
  %63 = mul nsw i64 %19, 7005
  %64 = add nsw i64 %63, %62
  %65 = mul nsw i64 %16, 7005
  %66 = mul nsw i64 %19, -14811
  %67 = add nsw i64 %66, %65
  %68 = mul nsw i64 %22, 13160
  %69 = mul nsw i64 %25, 9760
  %70 = add nsw i64 %69, %68
  %71 = mul nsw i64 %22, 9760
  %72 = mul nsw i64 %25, -13160
  %73 = add nsw i64 %72, %71
  %74 = mul nsw i64 %28, 11003
  %75 = mul nsw i64 %31, 12140
  %76 = add nsw i64 %75, %74
  %77 = mul nsw i64 %28, 12140
  %78 = mul nsw i64 %31, -11003
  %79 = add nsw i64 %78, %77
  %80 = mul nsw i64 %34, 8423
  %81 = mul nsw i64 %37, 14053
  %82 = add nsw i64 %81, %80
  %83 = mul nsw i64 %34, 14053
  %84 = mul nsw i64 %37, -8423
  %85 = add nsw i64 %84, %83
  %86 = mul nsw i64 %40, 5520
  %87 = mul nsw i64 %43, 15426
  %88 = add nsw i64 %87, %86
  %89 = mul nsw i64 %40, 15426
  %90 = mul nsw i64 %43, -5520
  %91 = add nsw i64 %90, %89
  %92 = mul nsw i64 %46, 2404
  %93 = mul nsw i64 %49, 16207
  %94 = add nsw i64 %93, %92
  %95 = mul nsw i64 %46, 16207
  %96 = mul nsw i64 %49, -2404
  %97 = add nsw i64 %96, %95
  %98 = add nsw i64 %52, 8192
  %99 = add nsw i64 %98, %76
  %100 = ashr i64 %99, 14
  %101 = add nsw i64 %55, 8192
  %102 = add nsw i64 %101, %79
  %103 = ashr i64 %102, 14
  %104 = add nsw i64 %58, 8192
  %105 = add nsw i64 %104, %82
  %106 = ashr i64 %105, 14
  %107 = add nsw i64 %61, 8192
  %108 = add nsw i64 %107, %85
  %109 = ashr i64 %108, 14
  %110 = add nsw i64 %64, 8192
  %111 = add nsw i64 %110, %88
  %112 = ashr i64 %111, 14
  %113 = add nsw i64 %67, 8192
  %114 = add nsw i64 %113, %91
  %115 = ashr i64 %114, 14
  %116 = add nsw i64 %70, 8192
  %117 = add nsw i64 %116, %94
  %118 = ashr i64 %117, 14
  %119 = add nsw i64 %73, 8192
  %120 = add nsw i64 %119, %97
  %121 = ashr i64 %120, 14
  %122 = sub nsw i64 %98, %76
  %123 = ashr i64 %122, 14
  %124 = sub nsw i64 %101, %79
  %125 = ashr i64 %124, 14
  %126 = sub nsw i64 %104, %82
  %127 = ashr i64 %126, 14
  %128 = sub nsw i64 %107, %85
  %129 = ashr i64 %128, 14
  %130 = sub nsw i64 %110, %88
  %131 = ashr i64 %130, 14
  %132 = sub nsw i64 %113, %91
  %133 = ashr i64 %132, 14
  %134 = sub nsw i64 %116, %94
  %135 = ashr i64 %134, 14
  %136 = sub nsw i64 %119, %97
  %137 = ashr i64 %136, 14
  %138 = mul nsw i64 %123, 16069
  %139 = mul nsw i64 %125, 3196
  %140 = add nsw i64 %138, %139
  %141 = mul nsw i64 %123, 3196
  %142 = mul nsw i64 %125, -16069
  %143 = add nsw i64 %141, %142
  %144 = mul nsw i64 %127, 9102
  %145 = mul nsw i64 %129, 13623
  %146 = add nsw i64 %144, %145
  %147 = mul nsw i64 %127, 13623
  %148 = mul nsw i64 %129, -9102
  %149 = add nsw i64 %147, %148
  %150 = mul nsw i64 %131, -3196
  %151 = mul nsw i64 %133, 16069
  %152 = add nsw i64 %150, %151
  %153 = mul nsw i64 %131, 16069
  %154 = mul nsw i64 %133, 3196
  %155 = add nsw i64 %153, %154
  %156 = mul nsw i64 %135, -13623
  %157 = mul nsw i64 %137, 9102
  %158 = add nsw i64 %156, %157
  %159 = mul nsw i64 %135, 9102
  %160 = mul nsw i64 %137, 13623
  %161 = add nsw i64 %159, %160
  %162 = add nsw i64 %112, %100
  %163 = add nsw i64 %115, %103
  %164 = add nsw i64 %118, %106
  %165 = add nsw i64 %121, %109
  %166 = sub nsw i64 %100, %112
  %167 = sub nsw i64 %103, %115
  %168 = sub nsw i64 %106, %118
  %169 = sub nsw i64 %109, %121
  %170 = add nsw i64 %140, 8192
  %171 = add nsw i64 %170, %152
  %172 = ashr i64 %171, 14
  %173 = add nsw i64 %143, 8192
  %174 = add nsw i64 %173, %155
  %175 = ashr i64 %174, 14
  %176 = add nsw i64 %146, 8192
  %177 = add nsw i64 %176, %158
  %178 = ashr i64 %177, 14
  %179 = add nsw i64 %149, 8192
  %180 = add nsw i64 %179, %161
  %181 = ashr i64 %180, 14
  %182 = sub nsw i64 %170, %152
  %183 = ashr i64 %182, 14
  %184 = sub nsw i64 %173, %155
  %185 = ashr i64 %184, 14
  %186 = sub nsw i64 %176, %158
  %187 = ashr i64 %186, 14
  %188 = sub nsw i64 %179, %161
  %189 = ashr i64 %188, 14
  %190 = mul nsw i64 %166, 15137
  %191 = mul nsw i64 %167, 6270
  %192 = add nsw i64 %190, %191
  %193 = mul nsw i64 %166, 6270
  %194 = mul i64 %167, -15137
  %195 = add nsw i64 %193, %194
  %196 = mul i64 %168, -6270
  %197 = mul nsw i64 %169, 15137
  %198 = add nsw i64 %196, %197
  %199 = mul nsw i64 %168, 15137
  %200 = mul nsw i64 %169, 6270
  %201 = add nsw i64 %199, %200
  %202 = mul nsw i64 %183, 15137
  %203 = mul nsw i64 %185, 6270
  %204 = add nsw i64 %202, %203
  %205 = mul nsw i64 %183, 6270
  %206 = mul i64 %185, -15137
  %207 = add nsw i64 %205, %206
  %208 = mul nsw i64 %187, -6270
  %209 = mul nsw i64 %189, 15137
  %210 = add nsw i64 %208, %209
  %211 = mul nsw i64 %187, 15137
  %212 = mul nsw i64 %189, 6270
  %213 = add nsw i64 %211, %212
  %214 = add nsw i64 %164, %162
  %215 = add nsw i64 %165, %163
  %216 = sub nsw i64 %162, %164
  %217 = sub nsw i64 %163, %165
  %218 = add nsw i64 %192, 8192
  %219 = add nsw i64 %218, %198
  %220 = lshr i64 %219, 14
  %221 = add nsw i64 %195, 8192
  %222 = add nsw i64 %221, %201
  %223 = lshr i64 %222, 14
  %224 = sub nsw i64 %218, %198
  %225 = ashr i64 %224, 14
  %226 = sub nsw i64 %221, %201
  %227 = ashr i64 %226, 14
  %228 = add nsw i64 %178, %172
  %229 = add nsw i64 %181, %175
  %230 = sub nsw i64 %172, %178
  %231 = sub nsw i64 %175, %181
  %232 = add nsw i64 %204, 8192
  %233 = add nsw i64 %232, %210
  %234 = lshr i64 %233, 14
  %235 = add nsw i64 %207, 8192
  %236 = add nsw i64 %235, %213
  %237 = lshr i64 %236, 14
  %238 = sub nsw i64 %232, %210
  %239 = ashr i64 %238, 14
  %240 = sub nsw i64 %235, %213
  %241 = ashr i64 %240, 14
  %242 = add nsw i64 %216, %217
  %243 = mul nsw i64 %242, -11585
  %244 = sub nsw i64 %216, %217
  %245 = mul nsw i64 %244, 11585
  %246 = add nsw i64 %225, %227
  %247 = mul nsw i64 %246, 11585
  %248 = sub nsw i64 %227, %225
  %249 = mul nsw i64 %248, 11585
  %250 = add nsw i64 %230, %231
  %251 = mul nsw i64 %250, 11585
  %252 = sub nsw i64 %231, %230
  %253 = mul nsw i64 %252, 11585
  %254 = add nsw i64 %239, %241
  %255 = mul nsw i64 %254, -11585
  %256 = sub nsw i64 %239, %241
  %257 = mul nsw i64 %256, 11585
  %258 = add nsw i64 %243, 8192
  %259 = lshr i64 %258, 14
  %260 = add nsw i64 %245, 8192
  %261 = lshr i64 %260, 14
  %262 = add nsw i64 %247, 8192
  %263 = lshr i64 %262, 14
  %264 = add nsw i64 %249, 8192
  %265 = lshr i64 %264, 14
  %266 = add nsw i64 %251, 8192
  %267 = lshr i64 %266, 14
  %268 = add nsw i64 %253, 8192
  %269 = lshr i64 %268, 14
  %270 = add nsw i64 %255, 8192
  %271 = lshr i64 %270, 14
  %272 = add nsw i64 %257, 8192
  %273 = lshr i64 %272, 14
  %274 = trunc i64 %214 to i32
  store i32 %274, i32* %1, align 4
  %275 = trunc i64 %228 to i32
  %276 = sub i32 0, %275
  %277 = getelementptr inbounds i32, i32* %1, i64 1
  store i32 %276, i32* %277, align 4
  %278 = trunc i64 %234 to i32
  %279 = getelementptr inbounds i32, i32* %1, i64 2
  store i32 %278, i32* %279, align 4
  %280 = trunc i64 %220 to i32
  %281 = sub i32 0, %280
  %282 = getelementptr inbounds i32, i32* %1, i64 3
  store i32 %281, i32* %282, align 4
  %283 = trunc i64 %263 to i32
  %284 = getelementptr inbounds i32, i32* %1, i64 4
  store i32 %283, i32* %284, align 4
  %285 = trunc i64 %271 to i32
  %286 = getelementptr inbounds i32, i32* %1, i64 5
  store i32 %285, i32* %286, align 4
  %287 = trunc i64 %267 to i32
  %288 = getelementptr inbounds i32, i32* %1, i64 6
  store i32 %287, i32* %288, align 4
  %289 = trunc i64 %259 to i32
  %290 = getelementptr inbounds i32, i32* %1, i64 7
  store i32 %289, i32* %290, align 4
  %291 = trunc i64 %261 to i32
  %292 = getelementptr inbounds i32, i32* %1, i64 8
  store i32 %291, i32* %292, align 4
  %293 = trunc i64 %269 to i32
  %294 = getelementptr inbounds i32, i32* %1, i64 9
  store i32 %293, i32* %294, align 4
  %295 = trunc i64 %273 to i32
  %296 = getelementptr inbounds i32, i32* %1, i64 10
  store i32 %295, i32* %296, align 4
  %297 = trunc i64 %265 to i32
  %298 = getelementptr inbounds i32, i32* %1, i64 11
  store i32 %297, i32* %298, align 4
  %299 = trunc i64 %223 to i32
  %300 = getelementptr inbounds i32, i32* %1, i64 12
  store i32 %299, i32* %300, align 4
  %301 = trunc i64 %237 to i32
  %302 = sub i32 0, %301
  %303 = getelementptr inbounds i32, i32* %1, i64 13
  store i32 %302, i32* %303, align 4
  %304 = trunc i64 %229 to i32
  %305 = getelementptr inbounds i32, i32* %1, i64 14
  store i32 %304, i32* %305, align 4
  %306 = trunc i64 %215 to i32
  %307 = sub i32 0, %306
  %308 = getelementptr inbounds i32, i32* %1, i64 15
  store i32 %307, i32* %308, align 4
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #2

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { argmemonly nounwind }
attributes #3 = { nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
