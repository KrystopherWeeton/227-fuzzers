; ModuleID = '../../third_party/swiftshader/src/Vulkan/VkTimelineSemaphore.cpp'
source_filename = "../../third_party/swiftshader/src/Vulkan/VkTimelineSemaphore.cpp"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"class.marl::Allocator" = type { i32 (...)** }
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__atomic_base.38" }
%"struct.std::__1::__atomic_base.38" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i32 }
%"struct.std::__1::__function::__policy" = type { i8* (i8*)*, void (i8*)*, i8, %"class.std::type_info"* }
%"class.std::type_info" = type { i32 (...)**, i8* }
%"class.vk::TimelineSemaphore" = type { %"class.vk::Semaphore", %"class.std::__1::shared_ptr" }
%"class.vk::Semaphore" = type { i32 (...)**, i32, %"class.marl::mutex" }
%"class.marl::mutex" = type { %"class.std::__1::mutex" }
%"class.std::__1::mutex" = type { %union.pthread_mutex_t }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"class.std::__1::shared_ptr" = type { %"struct.vk::TimelineSemaphore::Shared"*, %"class.std::__1::__shared_weak_count"* }
%"struct.vk::TimelineSemaphore::Shared" = type <{ %"class.marl::mutex", %"class.marl::ConditionVariable", i64, %"class.marl::containers::vector", %"class.std::__1::map", i32, [4 x i8] }>
%"class.marl::ConditionVariable" = type { %"class.marl::mutex", %"class.marl::containers::list", %"class.std::__1::condition_variable", %"struct.std::__1::atomic", %"struct.std::__1::atomic" }
%"class.marl::containers::list" = type { %"class.marl::Allocator"*, i64, i64, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* }
%"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain" = type { %"struct.marl::Allocation", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* }
%"struct.marl::Allocation" = type { i8*, %"struct.marl::Allocation::Request" }
%"struct.marl::Allocation::Request" = type <{ i64, i64, i8, i8, [6 x i8] }>
%"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry" = type { %"class.marl::Scheduler::Fiber"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* }
%"class.marl::Scheduler::Fiber" = type <{ i32, [4 x i8], %"class.std::__1::unique_ptr", %"class.marl::Scheduler::Worker"*, i32, [4 x i8] }>
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair.44" }
%"class.std::__1::__compressed_pair.44" = type { %"struct.std::__1::__compressed_pair_elem.45", %"struct.std::__1::__compressed_pair_elem.46" }
%"struct.std::__1::__compressed_pair_elem.45" = type { %"class.marl::OSFiber"* }
%"class.marl::OSFiber" = type opaque
%"struct.std::__1::__compressed_pair_elem.46" = type { %"struct.marl::Allocator::Deleter" }
%"struct.marl::Allocator::Deleter" = type { %"class.marl::Allocator"*, i64 }
%"class.marl::Scheduler::Worker" = type <{ i32, i32, %"class.marl::Scheduler"*, %"class.std::__1::unique_ptr.71", %"class.marl::Scheduler::Fiber"*, %"class.marl::Thread", %"struct.marl::Scheduler::Worker::Work", %"class.std::__1::unordered_set", %"class.marl::containers::vector.154", %"class.marl::Scheduler::Worker::FastRnd", i8, [7 x i8] }>
%"class.marl::Scheduler" = type { %"struct.marl::Scheduler::Config", %"struct.std::__1::array", %"struct.std::__1::atomic.48", %"struct.std::__1::atomic.48", %"struct.std::__1::array.53", %"struct.marl::Scheduler::SingleThreadedWorkers" }
%"struct.marl::Scheduler::Config" = type { %"struct.marl::Scheduler::Config::WorkerThread", %"class.marl::Allocator"*, i64 }
%"struct.marl::Scheduler::Config::WorkerThread" = type { i32, %"class.std::__1::function", %"class.std::__1::shared_ptr.47" }
%"class.std::__1::function" = type { %"class.std::__1::__function::__policy_func" }
%"class.std::__1::__function::__policy_func" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker", %"struct.std::__1::__function::__policy"* }
%"union.std::__1::__function::__policy_storage" = type { i8*, [8 x i8] }
%"struct.std::__1::__function::__policy_invoker" = type { void (%"union.std::__1::__function::__policy_storage"*, i32)* }
%"class.std::__1::shared_ptr.47" = type { %"class.marl::Thread::Affinity::Policy"*, %"class.std::__1::__shared_weak_count"* }
%"class.marl::Thread::Affinity::Policy" = type { i32 (...)** }
%"struct.std::__1::array" = type { [8 x %"struct.std::__1::atomic"] }
%"struct.std::__1::atomic.48" = type { %"struct.std::__1::__atomic_base.49" }
%"struct.std::__1::__atomic_base.49" = type { %"struct.std::__1::__atomic_base.50" }
%"struct.std::__1::__atomic_base.50" = type { %"struct.std::__1::__cxx_atomic_impl.51" }
%"struct.std::__1::__cxx_atomic_impl.51" = type { %"struct.std::__1::__cxx_atomic_base_impl.52" }
%"struct.std::__1::__cxx_atomic_base_impl.52" = type { i32 }
%"struct.std::__1::array.53" = type { [256 x %"class.marl::Scheduler::Worker"*] }
%"struct.marl::Scheduler::SingleThreadedWorkers" = type { %"class.marl::mutex", %"class.std::__1::condition_variable", %"class.std::__1::unordered_map" }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr.54", %"class.std::__1::__compressed_pair.60", %"class.std::__1::__compressed_pair.64", %"class.std::__1::__compressed_pair.67", [4 x i8] }>
%"class.std::__1::unique_ptr.54" = type { %"class.std::__1::__compressed_pair.55" }
%"class.std::__1::__compressed_pair.55" = type { %"struct.std::__1::__compressed_pair_elem.56", %"struct.std::__1::__compressed_pair_elem.57" }
%"struct.std::__1::__compressed_pair_elem.56" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.57" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.58" }
%"class.std::__1::__compressed_pair.58" = type { %"struct.std::__1::__compressed_pair_elem.41", %"struct.std::__1::__compressed_pair_elem.59" }
%"struct.std::__1::__compressed_pair_elem.41" = type { i64 }
%"struct.std::__1::__compressed_pair_elem.59" = type { %"struct.marl::StlAllocator" }
%"struct.marl::StlAllocator" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.60" = type { %"struct.std::__1::__compressed_pair_elem.61", %"struct.std::__1::__compressed_pair_elem.62" }
%"struct.std::__1::__compressed_pair_elem.61" = type { %"struct.std::__1::__hash_node_base" }
%"struct.std::__1::__compressed_pair_elem.62" = type { %"struct.marl::StlAllocator.63" }
%"struct.marl::StlAllocator.63" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.64" = type { %"struct.std::__1::__compressed_pair_elem.41" }
%"class.std::__1::__compressed_pair.67" = type { %"struct.std::__1::__compressed_pair_elem.68" }
%"struct.std::__1::__compressed_pair_elem.68" = type { float }
%"class.std::__1::unique_ptr.71" = type { %"class.std::__1::__compressed_pair.72" }
%"class.std::__1::__compressed_pair.72" = type { %"struct.std::__1::__compressed_pair_elem.73", %"struct.std::__1::__compressed_pair_elem.46" }
%"struct.std::__1::__compressed_pair_elem.73" = type { %"class.marl::Scheduler::Fiber"* }
%"class.marl::Thread" = type { %"class.marl::Thread::Impl"* }
%"class.marl::Thread::Impl" = type opaque
%"struct.marl::Scheduler::Worker::Work" = type { %"struct.std::__1::atomic.74", i64, %"class.std::__1::deque", %"class.std::__1::deque.91", %"struct.marl::Scheduler::WaitingFibers", i8, %"class.std::__1::condition_variable", %"class.marl::mutex" }
%"struct.std::__1::atomic.74" = type { %"struct.std::__1::__atomic_base.75" }
%"struct.std::__1::__atomic_base.75" = type { %"struct.std::__1::__atomic_base.76" }
%"struct.std::__1::__atomic_base.76" = type { %"struct.std::__1::__cxx_atomic_impl.77" }
%"struct.std::__1::__cxx_atomic_impl.77" = type { %"struct.std::__1::__cxx_atomic_base_impl.78" }
%"struct.std::__1::__cxx_atomic_base_impl.78" = type { i64 }
%"class.std::__1::deque" = type { %"class.std::__1::__deque_base" }
%"class.std::__1::__deque_base" = type { %"struct.std::__1::__split_buffer", i64, %"class.std::__1::__compressed_pair.88" }
%"struct.std::__1::__split_buffer" = type { %"class.marl::Task"**, %"class.marl::Task"**, %"class.marl::Task"**, %"class.std::__1::__compressed_pair.84" }
%"class.marl::Task" = type <{ %"class.std::__1::function.79", i32, [4 x i8] }>
%"class.std::__1::function.79" = type { %"class.std::__1::__function::__policy_func.82" }
%"class.std::__1::__function::__policy_func.82" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker.83", %"struct.std::__1::__function::__policy"* }
%"struct.std::__1::__function::__policy_invoker.83" = type { void (%"union.std::__1::__function::__policy_storage"*)* }
%"class.std::__1::__compressed_pair.84" = type { %"struct.std::__1::__compressed_pair_elem.85", %"struct.std::__1::__compressed_pair_elem.86" }
%"struct.std::__1::__compressed_pair_elem.85" = type { %"class.marl::Task"** }
%"struct.std::__1::__compressed_pair_elem.86" = type { %"struct.marl::StlAllocator.87" }
%"struct.marl::StlAllocator.87" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.88" = type { %"struct.std::__1::__compressed_pair_elem.41", %"struct.std::__1::__compressed_pair_elem.89" }
%"struct.std::__1::__compressed_pair_elem.89" = type { %"struct.marl::StlAllocator.90" }
%"struct.marl::StlAllocator.90" = type { %"class.marl::Allocator"* }
%"class.std::__1::deque.91" = type { %"class.std::__1::__deque_base.92" }
%"class.std::__1::__deque_base.92" = type { %"struct.std::__1::__split_buffer.93", i64, %"class.std::__1::__compressed_pair.98" }
%"struct.std::__1::__split_buffer.93" = type { %"class.marl::Scheduler::Fiber"***, %"class.marl::Scheduler::Fiber"***, %"class.marl::Scheduler::Fiber"***, %"class.std::__1::__compressed_pair.94" }
%"class.std::__1::__compressed_pair.94" = type { %"struct.std::__1::__compressed_pair_elem.95", %"struct.std::__1::__compressed_pair_elem.96" }
%"struct.std::__1::__compressed_pair_elem.95" = type { %"class.marl::Scheduler::Fiber"*** }
%"struct.std::__1::__compressed_pair_elem.96" = type { %"struct.marl::StlAllocator.97" }
%"struct.marl::StlAllocator.97" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.98" = type { %"struct.std::__1::__compressed_pair_elem.41", %"struct.std::__1::__compressed_pair_elem.99" }
%"struct.std::__1::__compressed_pair_elem.99" = type { %"struct.marl::StlAllocator.100" }
%"struct.marl::StlAllocator.100" = type { %"class.marl::Allocator"* }
%"struct.marl::Scheduler::WaitingFibers" = type { %"class.std::__1::set", %"class.std::__1::unordered_map.109" }
%"class.std::__1::set" = type { %"class.std::__1::__tree.101" }
%"class.std::__1::__tree.101" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.102", %"class.std::__1::__compressed_pair.105" }
%"class.std::__1::__tree_end_node" = type { %"class.std::__1::__tree_node_base"* }
%"class.std::__1::__tree_node_base" = type <{ %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_end_node"*, i8, [7 x i8] }>
%"class.std::__1::__compressed_pair.102" = type { %"struct.std::__1::__compressed_pair_elem", %"struct.std::__1::__compressed_pair_elem.103" }
%"struct.std::__1::__compressed_pair_elem" = type { %"class.std::__1::__tree_end_node" }
%"struct.std::__1::__compressed_pair_elem.103" = type { %"struct.marl::StlAllocator.104" }
%"struct.marl::StlAllocator.104" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.105" = type { %"struct.std::__1::__compressed_pair_elem.41" }
%"class.std::__1::unordered_map.109" = type { %"class.std::__1::__hash_table.110" }
%"class.std::__1::__hash_table.110" = type <{ %"class.std::__1::unique_ptr.111", %"class.std::__1::__compressed_pair.120", %"class.std::__1::__compressed_pair.124", %"class.std::__1::__compressed_pair.129", [4 x i8] }>
%"class.std::__1::unique_ptr.111" = type { %"class.std::__1::__compressed_pair.112" }
%"class.std::__1::__compressed_pair.112" = type { %"struct.std::__1::__compressed_pair_elem.113", %"struct.std::__1::__compressed_pair_elem.115" }
%"struct.std::__1::__compressed_pair_elem.113" = type { %"struct.std::__1::__hash_node_base.114"** }
%"struct.std::__1::__hash_node_base.114" = type { %"struct.std::__1::__hash_node_base.114"* }
%"struct.std::__1::__compressed_pair_elem.115" = type { %"class.std::__1::__bucket_list_deallocator.116" }
%"class.std::__1::__bucket_list_deallocator.116" = type { %"class.std::__1::__compressed_pair.117" }
%"class.std::__1::__compressed_pair.117" = type { %"struct.std::__1::__compressed_pair_elem.41", %"struct.std::__1::__compressed_pair_elem.118" }
%"struct.std::__1::__compressed_pair_elem.118" = type { %"struct.marl::StlAllocator.119" }
%"struct.marl::StlAllocator.119" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.120" = type { %"struct.std::__1::__compressed_pair_elem.121", %"struct.std::__1::__compressed_pair_elem.122" }
%"struct.std::__1::__compressed_pair_elem.121" = type { %"struct.std::__1::__hash_node_base.114" }
%"struct.std::__1::__compressed_pair_elem.122" = type { %"struct.marl::StlAllocator.123" }
%"struct.marl::StlAllocator.123" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.124" = type { %"struct.std::__1::__compressed_pair_elem.41" }
%"class.std::__1::__compressed_pair.129" = type { %"struct.std::__1::__compressed_pair_elem.68" }
%"class.std::__1::unordered_set" = type { %"class.std::__1::__hash_table.135" }
%"class.std::__1::__hash_table.135" = type <{ %"class.std::__1::unique_ptr.136", %"class.std::__1::__compressed_pair.145", %"class.std::__1::__compressed_pair.149", %"class.std::__1::__compressed_pair.151", [4 x i8] }>
%"class.std::__1::unique_ptr.136" = type { %"class.std::__1::__compressed_pair.137" }
%"class.std::__1::__compressed_pair.137" = type { %"struct.std::__1::__compressed_pair_elem.138", %"struct.std::__1::__compressed_pair_elem.140" }
%"struct.std::__1::__compressed_pair_elem.138" = type { %"struct.std::__1::__hash_node_base.139"** }
%"struct.std::__1::__hash_node_base.139" = type { %"struct.std::__1::__hash_node_base.139"* }
%"struct.std::__1::__compressed_pair_elem.140" = type { %"class.std::__1::__bucket_list_deallocator.141" }
%"class.std::__1::__bucket_list_deallocator.141" = type { %"class.std::__1::__compressed_pair.142" }
%"class.std::__1::__compressed_pair.142" = type { %"struct.std::__1::__compressed_pair_elem.41", %"struct.std::__1::__compressed_pair_elem.143" }
%"struct.std::__1::__compressed_pair_elem.143" = type { %"struct.marl::StlAllocator.144" }
%"struct.marl::StlAllocator.144" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.145" = type { %"struct.std::__1::__compressed_pair_elem.146", %"struct.std::__1::__compressed_pair_elem.147" }
%"struct.std::__1::__compressed_pair_elem.146" = type { %"struct.std::__1::__hash_node_base.139" }
%"struct.std::__1::__compressed_pair_elem.147" = type { %"struct.marl::StlAllocator.148" }
%"struct.marl::StlAllocator.148" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.149" = type { %"struct.std::__1::__compressed_pair_elem.41" }
%"class.std::__1::__compressed_pair.151" = type { %"struct.std::__1::__compressed_pair_elem.68" }
%"class.marl::containers::vector.154" = type { %"class.marl::Allocator"*, i64, i64, [16 x %"struct.marl::aligned_storage<24, 8>::type"], %"struct.marl::aligned_storage<24, 8>::type"*, %"struct.marl::Allocation" }
%"struct.marl::aligned_storage<24, 8>::type" = type { [24 x i8] }
%"class.marl::Scheduler::Worker::FastRnd" = type { i64 }
%"class.std::__1::condition_variable" = type { %union.pthread_cond_t }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon, %union.anon.36, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon = type { i64 }
%union.anon.36 = type { i64 }
%"class.marl::containers::vector" = type { %"class.marl::Allocator"*, i64, i64, [1 x %"struct.marl::aligned_storage<16, 8>::type"], %"struct.marl::aligned_storage<16, 8>::type"*, %"struct.marl::Allocation" }
%"struct.marl::aligned_storage<16, 8>::type" = type { [16 x i8] }
%"class.std::__1::map" = type { %"class.std::__1::__tree" }
%"class.std::__1::__tree" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair", %"class.std::__1::__compressed_pair.40" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"class.std::__1::__compressed_pair.40" = type { %"struct.std::__1::__compressed_pair_elem.41" }
%"class.std::__1::__shared_weak_count" = type { %"class.std::__1::__shared_count", i64 }
%"class.std::__1::__shared_count" = type { i32 (...)**, i64 }
%struct.VkSemaphoreCreateInfo = type { i32, i8*, i32 }
%struct.VkAllocationCallbacks = type { i8*, i8* (i8*, i64, i64, i32)*, i8* (i8*, i8*, i64, i64, i32)*, void (i8*, i8*)*, void (i8*, i64, i32, i32)*, void (i8*, i64, i32, i32)* }
%class.VkNonDispatchableHandle = type { i64 }
%class.VkNonDispatchableHandle.0 = type { i64 }
%class.VkNonDispatchableHandle.1 = type { i64 }
%class.VkNonDispatchableHandle.2 = type { i64 }
%class.VkNonDispatchableHandle.3 = type { i64 }
%class.VkNonDispatchableHandle.4 = type { i64 }
%class.VkNonDispatchableHandle.5 = type { i64 }
%class.VkNonDispatchableHandle.6 = type { i64 }
%class.VkNonDispatchableHandle.7 = type { i64 }
%class.VkNonDispatchableHandle.8 = type { i64 }
%class.VkNonDispatchableHandle.9 = type { i64 }
%class.VkNonDispatchableHandle.10 = type { i64 }
%class.VkNonDispatchableHandle.11 = type { i64 }
%class.VkNonDispatchableHandle.12 = type { i64 }
%class.VkNonDispatchableHandle.13 = type { i64 }
%class.VkNonDispatchableHandle.14 = type { i64 }
%class.VkNonDispatchableHandle.15 = type { i64 }
%class.VkNonDispatchableHandle.16 = type { i64 }
%class.VkNonDispatchableHandle.17 = type { i64 }
%class.VkNonDispatchableHandle.18 = type { i64 }
%class.VkNonDispatchableHandle.19 = type { i64 }
%class.VkNonDispatchableHandle.20 = type { i64 }
%class.VkNonDispatchableHandle.21 = type { i64 }
%class.VkNonDispatchableHandle.22 = type { i64 }
%class.VkNonDispatchableHandle.23 = type { i64 }
%class.VkNonDispatchableHandle.24 = type { i64 }
%class.VkNonDispatchableHandle.25 = type { i64 }
%class.VkNonDispatchableHandle.26 = type { i64 }
%class.VkNonDispatchableHandle.27 = type { i64 }
%class.VkNonDispatchableHandle.28 = type { i64 }
%class.VkNonDispatchableHandle.29 = type { i64 }
%class.VkNonDispatchableHandle.30 = type { i64 }
%class.VkNonDispatchableHandle.31 = type { i64 }
%class.VkNonDispatchableHandle.32 = type { i64 }
%class.VkNonDispatchableHandle.33 = type { i64 }
%class.VkNonDispatchableHandle.34 = type { i64 }
%class.VkNonDispatchableHandle.35 = type { i64 }
%"struct.vk::SemaphoreCreateInfo" = type { i8, i32, i32, i64 }
%"class.std::__1::__tree_node" = type { %"class.std::__1::__tree_node_base.base", %"struct.std::__1::__value_type" }
%"class.std::__1::__tree_node_base.base" = type <{ %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_end_node"*, i8 }>
%"struct.std::__1::__value_type" = type { %"struct.std::__1::pair" }
%"struct.std::__1::pair" = type { i32, i64 }
%"class.std::__1::function.164" = type { %"class.std::__1::__function::__policy_func.167" }
%"class.std::__1::__function::__policy_func.167" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker.168", %"struct.std::__1::__function::__policy"* }
%"struct.std::__1::__function::__policy_invoker.168" = type { i1 (%"union.std::__1::__function::__policy_storage"*)* }
%"class.marl::lock" = type { %"class.std::__1::unique_lock" }
%"class.std::__1::unique_lock" = type <{ %"class.std::__1::mutex"*, i8, [7 x i8] }>
%"struct.std::__1::pair.43" = type { i32, i64 }
%"class.std::__1::__shared_ptr_pointer" = type { %"class.std::__1::__shared_weak_count", %"class.std::__1::__compressed_pair.155" }
%"class.std::__1::__compressed_pair.155" = type { %"struct.std::__1::__compressed_pair_elem.156" }
%"struct.std::__1::__compressed_pair_elem.156" = type { %"class.std::__1::__compressed_pair.157" }
%"class.std::__1::__compressed_pair.157" = type { %"struct.std::__1::__compressed_pair_elem.158", %"struct.std::__1::__compressed_pair_elem.46" }
%"struct.std::__1::__compressed_pair_elem.158" = type { %"struct.vk::TimelineSemaphore::Shared"* }

$_ZNK23VkNonDispatchableHandleIP10VkBuffer_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP10VkBuffer_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkImage_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkImage_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkSemaphore_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkSemaphore_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkFence_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkFence_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkDeviceMemory_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkDeviceMemory_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkEvent_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkEvent_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkQueryPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkQueryPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkBufferView_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkBufferView_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkImageView_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkImageView_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkShaderModule_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkShaderModule_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkPipelineCache_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkPipelineCache_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkPipelineLayout_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkPipelineLayout_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP12VkPipeline_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP12VkPipeline_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkRenderPass_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkRenderPass_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP11VkSampler_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP11VkSampler_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkDescriptorSet_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkDescriptorSet_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkDescriptorPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkDescriptorPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkFramebuffer_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkFramebuffer_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkCommandPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkCommandPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkSurfaceKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkSurfaceKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkSwapchainKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkSwapchainKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkDisplayKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkDisplayKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkCuModuleNVX_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkCuModuleNVX_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEaSEm = comdat any

$_ZNSt3__110shared_ptrIN2vk17TimelineSemaphore6SharedEED2Ev = comdat any

$_ZN4marl10containers6vectorINSt3__110shared_ptrIN2vk17TimelineSemaphore6SharedEEELi1EE9push_backERKS7_ = comdat any

$_ZN2vk17TimelineSemaphoreD2Ev = comdat any

$_ZN2vk17TimelineSemaphoreD0Ev = comdat any

$_ZNSt3__120__shared_ptr_pointerIPN2vk17TimelineSemaphore6SharedEN4marl9Allocator7DeleterENS_9allocatorIS3_EEED0Ev = comdat any

$_ZNSt3__120__shared_ptr_pointerIPN2vk17TimelineSemaphore6SharedEN4marl9Allocator7DeleterENS_9allocatorIS3_EEE16__on_zero_sharedEv = comdat any

$_ZNSt3__120__shared_ptr_pointerIPN2vk17TimelineSemaphore6SharedEN4marl9Allocator7DeleterENS_9allocatorIS3_EEE21__on_zero_shared_weakEv = comdat any

$_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE7destroyEPNS_11__tree_nodeIS2_PvEE = comdat any

$_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE30__emplace_hint_unique_key_argsIiJNS_4pairIimEEEEENSB_INS_15__tree_iteratorIS2_PNS_11__tree_nodeIS2_PvEElEEbEENS_21__tree_const_iteratorIS2_SH_lEERKT_DpOT0_ = comdat any

$_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE12__find_equalIiEERPNS_16__tree_node_baseIPvEENS_21__tree_const_iteratorIS2_PNS_11__tree_nodeIS2_SC_EElEERPNS_15__tree_end_nodeISE_EESF_RKT_ = comdat any

$_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE16__insert_node_atEPNS_15__tree_end_nodeIPNS_16__tree_node_baseIPvEEEERSE_SE_ = comdat any

$_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE12__find_equalIiEERPNS_16__tree_node_baseIPvEERPNS_15__tree_end_nodeISE_EERKT_ = comdat any

$_ZNSt3__127__tree_balance_after_insertIPNS_16__tree_node_baseIPvEEEEvT_S5_ = comdat any

$_ZTVNSt3__120__shared_ptr_pointerIPN2vk17TimelineSemaphore6SharedEN4marl9Allocator7DeleterENS_9allocatorIS3_EEEE = comdat any

@_ZTVN2vk17TimelineSemaphoreE = hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.vk::TimelineSemaphore"*)* @_ZN2vk17TimelineSemaphoreD2Ev to i8*), i8* bitcast (void (%"class.vk::TimelineSemaphore"*)* @_ZN2vk17TimelineSemaphoreD0Ev to i8*), i8* bitcast (void (%"class.vk::TimelineSemaphore"*, %struct.VkAllocationCallbacks*)* @_ZN2vk17TimelineSemaphore7destroyEPK21VkAllocationCallbacks to i8*)] }, align 8
@_ZN4marl9Allocator7DefaultE = external local_unnamed_addr global %"class.marl::Allocator"*, align 8
@_ZN2vk17TimelineSemaphore6Shared6nextIdE = hidden global %"struct.std::__1::atomic" zeroinitializer, align 4
@_ZTVNSt3__120__shared_ptr_pointerIPN2vk17TimelineSemaphore6SharedEN4marl9Allocator7DeleterENS_9allocatorIS3_EEEE = linkonce_odr hidden unnamed_addr constant { [7 x i8*] } { [7 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.std::__1::__shared_weak_count"*)* @_ZNSt3__119__shared_weak_countD2Ev to i8*), i8* bitcast (void (%"class.std::__1::__shared_ptr_pointer"*)* @_ZNSt3__120__shared_ptr_pointerIPN2vk17TimelineSemaphore6SharedEN4marl9Allocator7DeleterENS_9allocatorIS3_EEED0Ev to i8*), i8* bitcast (void (%"class.std::__1::__shared_ptr_pointer"*)* @_ZNSt3__120__shared_ptr_pointerIPN2vk17TimelineSemaphore6SharedEN4marl9Allocator7DeleterENS_9allocatorIS3_EEE16__on_zero_sharedEv to i8*), i8* bitcast (i8* (%"class.std::__1::__shared_weak_count"*, %"class.std::type_info"*)* @_ZNKSt3__119__shared_weak_count13__get_deleterERKSt9type_info to i8*), i8* bitcast (void (%"class.std::__1::__shared_ptr_pointer"*)* @_ZNSt3__120__shared_ptr_pointerIPN2vk17TimelineSemaphore6SharedEN4marl9Allocator7DeleterENS_9allocatorIS3_EEE21__on_zero_shared_weakEv to i8*)] }, comdat, align 8
@"_ZZNSt3__110__function8__policy15__choose_policyINS0_20__default_alloc_funcIZN2vk17TimelineSemaphore6Shared4waitEmE3$_0FbvEEEEEPKS1_NS_17integral_constantIbLb1EEEE9__policy_" = internal constant %"struct.std::__1::__function::__policy" zeroinitializer, align 8

@_ZN2vk17TimelineSemaphoreC1EPK21VkSemaphoreCreateInfoPvPK21VkAllocationCallbacks = hidden unnamed_addr alias void (%"class.vk::TimelineSemaphore"*, %struct.VkSemaphoreCreateInfo*, i8*, %struct.VkAllocationCallbacks*), void (%"class.vk::TimelineSemaphore"*, %struct.VkSemaphoreCreateInfo*, i8*, %struct.VkAllocationCallbacks*)* @_ZN2vk17TimelineSemaphoreC2EPK21VkSemaphoreCreateInfoPvPK21VkAllocationCallbacks
@_ZN2vk17TimelineSemaphoreC1Ev = hidden unnamed_addr alias void (%"class.vk::TimelineSemaphore"*), void (%"class.vk::TimelineSemaphore"*)* @_ZN2vk17TimelineSemaphoreC2Ev
@_ZN2vk17TimelineSemaphore6SharedC1EPN4marl9AllocatorEm = hidden unnamed_addr alias void (%"struct.vk::TimelineSemaphore::Shared"*, %"class.marl::Allocator"*, i64), void (%"struct.vk::TimelineSemaphore::Shared"*, %"class.marl::Allocator"*, i64)* @_ZN2vk17TimelineSemaphore6SharedC2EPN4marl9AllocatorEm

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP10VkBuffer_TEcvPvEv(%class.VkNonDispatchableHandle*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP10VkBuffer_TEaSEm(%class.VkNonDispatchableHandle*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle, %class.VkNonDispatchableHandle* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkImage_TEcvPvEv(%class.VkNonDispatchableHandle.0*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.0* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkImage_TEaSEm(%class.VkNonDispatchableHandle.0*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.0, %class.VkNonDispatchableHandle.0* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkSemaphore_TEcvPvEv(%class.VkNonDispatchableHandle.1*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.1* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkSemaphore_TEaSEm(%class.VkNonDispatchableHandle.1*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.1, %class.VkNonDispatchableHandle.1* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkFence_TEcvPvEv(%class.VkNonDispatchableHandle.2*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.2* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkFence_TEaSEm(%class.VkNonDispatchableHandle.2*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.2, %class.VkNonDispatchableHandle.2* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkDeviceMemory_TEcvPvEv(%class.VkNonDispatchableHandle.3*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.3* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkDeviceMemory_TEaSEm(%class.VkNonDispatchableHandle.3*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.3, %class.VkNonDispatchableHandle.3* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkEvent_TEcvPvEv(%class.VkNonDispatchableHandle.4*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.4* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkEvent_TEaSEm(%class.VkNonDispatchableHandle.4*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.4, %class.VkNonDispatchableHandle.4* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkQueryPool_TEcvPvEv(%class.VkNonDispatchableHandle.5*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.5* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkQueryPool_TEaSEm(%class.VkNonDispatchableHandle.5*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.5, %class.VkNonDispatchableHandle.5* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkBufferView_TEcvPvEv(%class.VkNonDispatchableHandle.6*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.6* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkBufferView_TEaSEm(%class.VkNonDispatchableHandle.6*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.6, %class.VkNonDispatchableHandle.6* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkImageView_TEcvPvEv(%class.VkNonDispatchableHandle.7*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.7* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkImageView_TEaSEm(%class.VkNonDispatchableHandle.7*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.7, %class.VkNonDispatchableHandle.7* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkShaderModule_TEcvPvEv(%class.VkNonDispatchableHandle.8*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.8* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkShaderModule_TEaSEm(%class.VkNonDispatchableHandle.8*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.8, %class.VkNonDispatchableHandle.8* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkPipelineCache_TEcvPvEv(%class.VkNonDispatchableHandle.9*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.9* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkPipelineCache_TEaSEm(%class.VkNonDispatchableHandle.9*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.9, %class.VkNonDispatchableHandle.9* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkPipelineLayout_TEcvPvEv(%class.VkNonDispatchableHandle.10*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.10* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkPipelineLayout_TEaSEm(%class.VkNonDispatchableHandle.10*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.10, %class.VkNonDispatchableHandle.10* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP12VkPipeline_TEcvPvEv(%class.VkNonDispatchableHandle.11*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.11* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP12VkPipeline_TEaSEm(%class.VkNonDispatchableHandle.11*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.11, %class.VkNonDispatchableHandle.11* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkRenderPass_TEcvPvEv(%class.VkNonDispatchableHandle.12*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.12* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkRenderPass_TEaSEm(%class.VkNonDispatchableHandle.12*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.12, %class.VkNonDispatchableHandle.12* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEcvPvEv(%class.VkNonDispatchableHandle.13*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.13* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEaSEm(%class.VkNonDispatchableHandle.13*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.13, %class.VkNonDispatchableHandle.13* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP11VkSampler_TEcvPvEv(%class.VkNonDispatchableHandle.14*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.14* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP11VkSampler_TEaSEm(%class.VkNonDispatchableHandle.14*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.14, %class.VkNonDispatchableHandle.14* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkDescriptorSet_TEcvPvEv(%class.VkNonDispatchableHandle.15*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.15* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkDescriptorSet_TEaSEm(%class.VkNonDispatchableHandle.15*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.15, %class.VkNonDispatchableHandle.15* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkDescriptorPool_TEcvPvEv(%class.VkNonDispatchableHandle.16*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.16* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkDescriptorPool_TEaSEm(%class.VkNonDispatchableHandle.16*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.16, %class.VkNonDispatchableHandle.16* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkFramebuffer_TEcvPvEv(%class.VkNonDispatchableHandle.17*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.17* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkFramebuffer_TEaSEm(%class.VkNonDispatchableHandle.17*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.17, %class.VkNonDispatchableHandle.17* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkCommandPool_TEcvPvEv(%class.VkNonDispatchableHandle.18*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.18* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkCommandPool_TEaSEm(%class.VkNonDispatchableHandle.18*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.18, %class.VkNonDispatchableHandle.18* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEcvPvEv(%class.VkNonDispatchableHandle.19*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.19* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEaSEm(%class.VkNonDispatchableHandle.19*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.19, %class.VkNonDispatchableHandle.19* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEcvPvEv(%class.VkNonDispatchableHandle.20*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.20* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEaSEm(%class.VkNonDispatchableHandle.20*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.20, %class.VkNonDispatchableHandle.20* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkSurfaceKHR_TEcvPvEv(%class.VkNonDispatchableHandle.21*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.21* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkSurfaceKHR_TEaSEm(%class.VkNonDispatchableHandle.21*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.21, %class.VkNonDispatchableHandle.21* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkSwapchainKHR_TEcvPvEv(%class.VkNonDispatchableHandle.22*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.22* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkSwapchainKHR_TEaSEm(%class.VkNonDispatchableHandle.22*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.22, %class.VkNonDispatchableHandle.22* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkDisplayKHR_TEcvPvEv(%class.VkNonDispatchableHandle.23*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.23* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkDisplayKHR_TEaSEm(%class.VkNonDispatchableHandle.23*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.23, %class.VkNonDispatchableHandle.23* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEcvPvEv(%class.VkNonDispatchableHandle.24*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.24* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEaSEm(%class.VkNonDispatchableHandle.24*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.24, %class.VkNonDispatchableHandle.24* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEcvPvEv(%class.VkNonDispatchableHandle.25*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.25* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEaSEm(%class.VkNonDispatchableHandle.25*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.25, %class.VkNonDispatchableHandle.25* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEcvPvEv(%class.VkNonDispatchableHandle.26*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.26* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEaSEm(%class.VkNonDispatchableHandle.26*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.26, %class.VkNonDispatchableHandle.26* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkCuModuleNVX_TEcvPvEv(%class.VkNonDispatchableHandle.27*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.27* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkCuModuleNVX_TEaSEm(%class.VkNonDispatchableHandle.27*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.27, %class.VkNonDispatchableHandle.27* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEcvPvEv(%class.VkNonDispatchableHandle.28*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.28* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEaSEm(%class.VkNonDispatchableHandle.28*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.28, %class.VkNonDispatchableHandle.28* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEcvPvEv(%class.VkNonDispatchableHandle.29*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.29* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEaSEm(%class.VkNonDispatchableHandle.29*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.29, %class.VkNonDispatchableHandle.29* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEcvPvEv(%class.VkNonDispatchableHandle.30*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.30* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEaSEm(%class.VkNonDispatchableHandle.30*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.30, %class.VkNonDispatchableHandle.30* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEcvPvEv(%class.VkNonDispatchableHandle.31*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.31* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEaSEm(%class.VkNonDispatchableHandle.31*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.31, %class.VkNonDispatchableHandle.31* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEcvPvEv(%class.VkNonDispatchableHandle.32*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.32* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEaSEm(%class.VkNonDispatchableHandle.32*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.32, %class.VkNonDispatchableHandle.32* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEcvPvEv(%class.VkNonDispatchableHandle.33*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.33* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEaSEm(%class.VkNonDispatchableHandle.33*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.33, %class.VkNonDispatchableHandle.33* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEcvPvEv(%class.VkNonDispatchableHandle.34*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.34* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEaSEm(%class.VkNonDispatchableHandle.34*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.34, %class.VkNonDispatchableHandle.34* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEcvPvEv(%class.VkNonDispatchableHandle.35*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.35* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEaSEm(%class.VkNonDispatchableHandle.35*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.35, %class.VkNonDispatchableHandle.35* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk17TimelineSemaphoreC2EPK21VkSemaphoreCreateInfoPvPK21VkAllocationCallbacks(%"class.vk::TimelineSemaphore"*, %struct.VkSemaphoreCreateInfo*, i8* nocapture readnone, %struct.VkAllocationCallbacks* nocapture readnone) unnamed_addr #0 align 2 {
  %5 = alloca %"struct.marl::Allocation::Request", align 16
  %6 = alloca %"struct.marl::Allocation", align 8
  %7 = alloca %"struct.vk::SemaphoreCreateInfo", align 8
  %8 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 0
  tail call void @_ZN2vk9SemaphoreC2E15VkSemaphoreType(%"class.vk::Semaphore"* %8, i32 1) #9
  %9 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN2vk17TimelineSemaphoreE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %9, align 8
  %10 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 1
  %11 = bitcast %"class.std::__1::shared_ptr"* %10 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %11, i8 0, i64 16, i1 false) #10
  %12 = getelementptr inbounds %"struct.vk::SemaphoreCreateInfo", %"struct.vk::SemaphoreCreateInfo"* %7, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %12) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %12, i8 -86, i64 24, i1 false)
  call void @_ZN2vk19SemaphoreCreateInfoC1EPK21VkSemaphoreCreateInfo(%"struct.vk::SemaphoreCreateInfo"* nonnull %7, %struct.VkSemaphoreCreateInfo* %1) #9
  %13 = getelementptr inbounds %"struct.vk::SemaphoreCreateInfo", %"struct.vk::SemaphoreCreateInfo"* %7, i64 0, i32 2
  %14 = load i32, i32* %13, align 8
  %15 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 0, i32 1
  store i32 %14, i32* %15, align 8
  %16 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** @_ZN4marl9Allocator7DefaultE, align 8
  %17 = getelementptr inbounds %"struct.vk::SemaphoreCreateInfo", %"struct.vk::SemaphoreCreateInfo"* %7, i64 0, i32 3
  %18 = bitcast %"struct.marl::Allocation::Request"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %18) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %18, i8 -86, i64 24, i1 false) #10
  %19 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %5, i64 0, i32 2
  %20 = bitcast i8* %19 to i16*
  store i16 512, i16* %20, align 16
  %21 = bitcast %"struct.marl::Allocation::Request"* %5 to <2 x i64>*
  store <2 x i64> <i64 304, i64 8>, <2 x i64>* %21, align 16
  %22 = bitcast %"struct.marl::Allocation"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %22) #10
  %23 = bitcast %"class.marl::Allocator"* %16 to void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)***
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %22, i8 -86, i64 32, i1 false) #10
  %24 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)**, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*** %23, align 8
  %25 = getelementptr inbounds void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %24, i64 2
  %26 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %25, align 8
  call void %26(%"struct.marl::Allocation"* nonnull sret %6, %"class.marl::Allocator"* %16, %"struct.marl::Allocation::Request"* nonnull dereferenceable(24) %5) #9
  %27 = bitcast %"struct.marl::Allocation"* %6 to %"struct.vk::TimelineSemaphore::Shared"**
  %28 = load %"struct.vk::TimelineSemaphore::Shared"*, %"struct.vk::TimelineSemaphore::Shared"** %27, align 8
  %29 = load i64, i64* bitcast (%"class.marl::Allocator"** @_ZN4marl9Allocator7DefaultE to i64*), align 8
  %30 = load i64, i64* %17, align 8
  %31 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %28, i64 0, i32 1, i32 1, i32 0
  %32 = bitcast %"struct.vk::TimelineSemaphore::Shared"* %28 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %32, i8 0, i64 80, i1 false) #10
  %33 = bitcast %"class.marl::Allocator"** %31 to i64*
  store i64 %29, i64* %33, align 8
  %34 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %28, i64 0, i32 1, i32 1, i32 1
  %35 = bitcast i64* %34 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %35, i8 0, i64 96, i1 false) #10
  %36 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %28, i64 0, i32 2
  store i64 %30, i64* %36, align 8
  %37 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %28, i64 0, i32 3
  %38 = load i64, i64* bitcast (%"class.marl::Allocator"** @_ZN4marl9Allocator7DefaultE to i64*), align 8
  %39 = bitcast %"class.marl::containers::vector"* %37 to i64*
  store i64 %38, i64* %39, align 8
  %40 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %28, i64 0, i32 3, i32 1
  %41 = bitcast i64* %40 to <2 x i64>*
  store <2 x i64> <i64 0, i64 1>, <2 x i64>* %41, align 8
  %42 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %28, i64 0, i32 3, i32 4
  %43 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %28, i64 0, i32 3, i32 3, i64 0
  store %"struct.marl::aligned_storage<16, 8>::type"* %43, %"struct.marl::aligned_storage<16, 8>::type"** %42, align 8
  %44 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %28, i64 0, i32 3, i32 5
  %45 = bitcast %"struct.marl::Allocation"* %44 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %45, i8 0, i64 26, i1 false) #10
  %46 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %28, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0
  %47 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %28, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0
  %48 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %28, i64 0, i32 4, i32 0, i32 0
  %49 = bitcast %"class.std::__1::__tree_node_base"** %46 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %49, i8 0, i64 16, i1 false) #10
  store %"class.std::__1::__tree_end_node"* %47, %"class.std::__1::__tree_end_node"** %48, align 8
  %50 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %28, i64 0, i32 5
  %51 = atomicrmw add i32* getelementptr inbounds (%"struct.std::__1::atomic", %"struct.std::__1::atomic"* @_ZN2vk17TimelineSemaphore6Shared6nextIdE, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0), i32 1 seq_cst
  store i32 %51, i32* %50, align 8
  %52 = bitcast %"struct.marl::Allocation"* %6 to i64*
  %53 = load i64, i64* %52, align 8
  %54 = call i8* @_Znwm(i64 48) #11
  %55 = bitcast i8* %54 to i32 (...)***
  %56 = getelementptr inbounds i8, i8* %54, i64 8
  call void @llvm.memset.p0i8.i64(i8* align 8 %56, i8 0, i64 16, i1 false) #10
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVNSt3__120__shared_ptr_pointerIPN2vk17TimelineSemaphore6SharedEN4marl9Allocator7DeleterENS_9allocatorIS3_EEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %55, align 8
  %57 = getelementptr inbounds i8, i8* %54, i64 24
  %58 = bitcast i8* %57 to i64*
  store i64 %53, i64* %58, align 8
  %59 = getelementptr inbounds i8, i8* %54, i64 32
  %60 = bitcast i8* %59 to %"class.marl::Allocator"**
  store %"class.marl::Allocator"* %16, %"class.marl::Allocator"** %60, align 8
  %61 = getelementptr inbounds i8, i8* %54, i64 40
  %62 = bitcast i8* %61 to i64*
  store i64 1, i64* %62, align 8
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %22) #10
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %18) #10
  %63 = ptrtoint i8* %54 to i64
  %64 = bitcast %"class.std::__1::shared_ptr"* %10 to i64*
  store i64 %53, i64* %64, align 8
  %65 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 1, i32 1
  %66 = bitcast %"class.std::__1::__shared_weak_count"** %65 to i64*
  %67 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %65, align 8
  store i64 %63, i64* %66, align 8
  %68 = icmp eq %"class.std::__1::__shared_weak_count"* %67, null
  br i1 %68, label %79, label %69

69:                                               ; preds = %4
  %70 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %67, i64 0, i32 0, i32 1
  %71 = atomicrmw add i64* %70, i64 -1 acq_rel
  %72 = icmp eq i64 %71, 0
  br i1 %72, label %73, label %79

73:                                               ; preds = %69
  %74 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %67, i64 0, i32 0
  %75 = bitcast %"class.std::__1::__shared_weak_count"* %67 to void (%"class.std::__1::__shared_count"*)***
  %76 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %75, align 8
  %77 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %76, i64 2
  %78 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %77, align 8
  call void %78(%"class.std::__1::__shared_count"* %74) #9
  call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %67) #9
  br label %79

79:                                               ; preds = %73, %69, %4
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %12) #10
  ret void
}

; Function Attrs: optsize
declare void @_ZN2vk9SemaphoreC2E15VkSemaphoreType(%"class.vk::Semaphore"*, i32) unnamed_addr #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #2

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #2

; Function Attrs: optsize
declare void @_ZN2vk19SemaphoreCreateInfoC1EPK21VkSemaphoreCreateInfo(%"struct.vk::SemaphoreCreateInfo"*, %struct.VkSemaphoreCreateInfo*) unnamed_addr #1

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__110shared_ptrIN2vk17TimelineSemaphore6SharedEED2Ev(%"class.std::__1::shared_ptr"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %0, i64 0, i32 1
  %3 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %2, align 8
  %4 = icmp eq %"class.std::__1::__shared_weak_count"* %3, null
  br i1 %4, label %15, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %3, i64 0, i32 0, i32 1
  %7 = atomicrmw add i64* %6, i64 -1 acq_rel
  %8 = icmp eq i64 %7, 0
  br i1 %8, label %9, label %15

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %3, i64 0, i32 0
  %11 = bitcast %"class.std::__1::__shared_weak_count"* %3 to void (%"class.std::__1::__shared_count"*)***
  %12 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %11, align 8
  %13 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %12, i64 2
  %14 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %13, align 8
  tail call void %14(%"class.std::__1::__shared_count"* %10) #9
  tail call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %3) #9
  br label %15

15:                                               ; preds = %9, %5, %1
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #2

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk17TimelineSemaphoreC2Ev(%"class.vk::TimelineSemaphore"*) unnamed_addr #0 align 2 {
  %2 = alloca %"struct.marl::Allocation::Request", align 16
  %3 = alloca %"struct.marl::Allocation", align 8
  %4 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 0
  tail call void @_ZN2vk9SemaphoreC2E15VkSemaphoreType(%"class.vk::Semaphore"* %4, i32 1) #9
  %5 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN2vk17TimelineSemaphoreE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %5, align 8
  %6 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 1
  %7 = bitcast %"class.std::__1::shared_ptr"* %6 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %7, i8 0, i64 16, i1 false) #10
  %8 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 0, i32 1
  store i32 1, i32* %8, align 8
  %9 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** @_ZN4marl9Allocator7DefaultE, align 8
  %10 = bitcast %"struct.marl::Allocation::Request"* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %10) #10
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 -86, i64 24, i1 false) #10
  %11 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %2, i64 0, i32 2
  %12 = bitcast i8* %11 to i16*
  store i16 512, i16* %12, align 16
  %13 = bitcast %"struct.marl::Allocation::Request"* %2 to <2 x i64>*
  store <2 x i64> <i64 304, i64 8>, <2 x i64>* %13, align 16
  %14 = bitcast %"struct.marl::Allocation"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %14) #10
  %15 = bitcast %"class.marl::Allocator"* %9 to void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)***
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %14, i8 -86, i64 32, i1 false) #10
  %16 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)**, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*** %15, align 8
  %17 = getelementptr inbounds void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %16, i64 2
  %18 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %17, align 8
  call void %18(%"struct.marl::Allocation"* nonnull sret %3, %"class.marl::Allocator"* %9, %"struct.marl::Allocation::Request"* nonnull dereferenceable(24) %2) #9
  %19 = bitcast %"struct.marl::Allocation"* %3 to %"struct.vk::TimelineSemaphore::Shared"**
  %20 = load %"struct.vk::TimelineSemaphore::Shared"*, %"struct.vk::TimelineSemaphore::Shared"** %19, align 8
  %21 = load i64, i64* bitcast (%"class.marl::Allocator"** @_ZN4marl9Allocator7DefaultE to i64*), align 8
  %22 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %20, i64 0, i32 1, i32 1, i32 0
  %23 = bitcast %"struct.vk::TimelineSemaphore::Shared"* %20 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %23, i8 0, i64 80, i1 false) #10
  %24 = bitcast %"class.marl::Allocator"** %22 to i64*
  store i64 %21, i64* %24, align 8
  %25 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %20, i64 0, i32 1, i32 1, i32 1
  %26 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %20, i64 0, i32 3
  %27 = bitcast i64* %25 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %27, i8 0, i64 104, i1 false)
  %28 = load i64, i64* bitcast (%"class.marl::Allocator"** @_ZN4marl9Allocator7DefaultE to i64*), align 8
  %29 = bitcast %"class.marl::containers::vector"* %26 to i64*
  store i64 %28, i64* %29, align 8
  %30 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %20, i64 0, i32 3, i32 1
  %31 = bitcast i64* %30 to <2 x i64>*
  store <2 x i64> <i64 0, i64 1>, <2 x i64>* %31, align 8
  %32 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %20, i64 0, i32 3, i32 4
  %33 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %20, i64 0, i32 3, i32 3, i64 0
  store %"struct.marl::aligned_storage<16, 8>::type"* %33, %"struct.marl::aligned_storage<16, 8>::type"** %32, align 8
  %34 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %20, i64 0, i32 3, i32 5
  %35 = bitcast %"struct.marl::Allocation"* %34 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %35, i8 0, i64 26, i1 false) #10
  %36 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %20, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0
  %37 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %20, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0
  %38 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %20, i64 0, i32 4, i32 0, i32 0
  %39 = bitcast %"class.std::__1::__tree_node_base"** %36 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %39, i8 0, i64 16, i1 false) #10
  store %"class.std::__1::__tree_end_node"* %37, %"class.std::__1::__tree_end_node"** %38, align 8
  %40 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %20, i64 0, i32 5
  %41 = atomicrmw add i32* getelementptr inbounds (%"struct.std::__1::atomic", %"struct.std::__1::atomic"* @_ZN2vk17TimelineSemaphore6Shared6nextIdE, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0), i32 1 seq_cst
  store i32 %41, i32* %40, align 8
  %42 = bitcast %"struct.marl::Allocation"* %3 to i64*
  %43 = load i64, i64* %42, align 8
  %44 = call i8* @_Znwm(i64 48) #11
  %45 = bitcast i8* %44 to i32 (...)***
  %46 = getelementptr inbounds i8, i8* %44, i64 8
  call void @llvm.memset.p0i8.i64(i8* align 8 %46, i8 0, i64 16, i1 false) #10
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVNSt3__120__shared_ptr_pointerIPN2vk17TimelineSemaphore6SharedEN4marl9Allocator7DeleterENS_9allocatorIS3_EEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %45, align 8
  %47 = getelementptr inbounds i8, i8* %44, i64 24
  %48 = bitcast i8* %47 to i64*
  store i64 %43, i64* %48, align 8
  %49 = getelementptr inbounds i8, i8* %44, i64 32
  %50 = bitcast i8* %49 to %"class.marl::Allocator"**
  store %"class.marl::Allocator"* %9, %"class.marl::Allocator"** %50, align 8
  %51 = getelementptr inbounds i8, i8* %44, i64 40
  %52 = bitcast i8* %51 to i64*
  store i64 1, i64* %52, align 8
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %14) #10
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %10) #10
  %53 = ptrtoint i8* %44 to i64
  %54 = bitcast %"class.std::__1::shared_ptr"* %6 to i64*
  store i64 %43, i64* %54, align 8
  %55 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 1, i32 1
  %56 = bitcast %"class.std::__1::__shared_weak_count"** %55 to i64*
  %57 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %55, align 8
  store i64 %53, i64* %56, align 8
  %58 = icmp eq %"class.std::__1::__shared_weak_count"* %57, null
  br i1 %58, label %69, label %59

59:                                               ; preds = %1
  %60 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %57, i64 0, i32 0, i32 1
  %61 = atomicrmw add i64* %60, i64 -1 acq_rel
  %62 = icmp eq i64 %61, 0
  br i1 %62, label %63, label %69

63:                                               ; preds = %59
  %64 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %57, i64 0, i32 0
  %65 = bitcast %"class.std::__1::__shared_weak_count"* %57 to void (%"class.std::__1::__shared_count"*)***
  %66 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %65, align 8
  %67 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %66, i64 2
  %68 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %67, align 8
  call void %68(%"class.std::__1::__shared_count"* %64) #9
  call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %57) #9
  br label %69

69:                                               ; preds = %63, %59, %1
  ret void
}

; Function Attrs: norecurse nounwind optsize readnone ssp uwtable
define hidden i64 @_ZN2vk17TimelineSemaphore29ComputeRequiredAllocationSizeEPK21VkSemaphoreCreateInfo(%struct.VkSemaphoreCreateInfo* nocapture readnone) local_unnamed_addr #3 align 2 {
  ret i64 0
}

; Function Attrs: norecurse nounwind optsize readnone ssp uwtable
define hidden void @_ZN2vk17TimelineSemaphore7destroyEPK21VkAllocationCallbacks(%"class.vk::TimelineSemaphore"* nocapture, %struct.VkAllocationCallbacks* nocapture) unnamed_addr #3 align 2 {
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk17TimelineSemaphore6signalEm(%"class.vk::TimelineSemaphore"* nocapture readonly, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 1, i32 0
  %4 = load %"struct.vk::TimelineSemaphore::Shared"*, %"struct.vk::TimelineSemaphore::Shared"** %3, align 8
  tail call void @_ZN2vk17TimelineSemaphore6Shared6signalEm(%"struct.vk::TimelineSemaphore::Shared"* %4, i64 %1) #12
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk17TimelineSemaphore6Shared6signalEm(%"struct.vk::TimelineSemaphore::Shared"*, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %3) #9
  %4 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 2
  %5 = load i64, i64* %4, align 8
  %6 = icmp ult i64 %5, %1
  br i1 %6, label %7, label %67

7:                                                ; preds = %2
  store i64 %1, i64* %4, align 8
  %8 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %9 = load atomic i32, i32* %8 seq_cst, align 4
  %10 = icmp eq i32 %9, 0
  br i1 %10, label %29, label %11

11:                                               ; preds = %7
  %12 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %12) #9
  %13 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 1, i32 5
  %14 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %13, align 8
  %15 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %14, null
  br i1 %15, label %16, label %20

16:                                               ; preds = %20, %11
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %12) #9
  %17 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %18 = load atomic i32, i32* %17 seq_cst, align 4
  %19 = icmp sgt i32 %18, 0
  br i1 %19, label %27, label %29

20:                                               ; preds = %11, %20
  %21 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* [ %25, %20 ], [ %14, %11 ]
  %22 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %21, i64 0, i32 0
  %23 = load %"class.marl::Scheduler::Fiber"*, %"class.marl::Scheduler::Fiber"** %22, align 8
  tail call void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"* %23) #9
  %24 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %21, i64 0, i32 1
  %25 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %24, align 8
  %26 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %25, null
  br i1 %26, label %16, label %20

27:                                               ; preds = %16
  %28 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variable10notify_allEv(%"class.std::__1::condition_variable"* %28) #9
  br label %29

29:                                               ; preds = %7, %16, %27
  %30 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 3, i32 4
  %31 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %30 to %"class.std::__1::shared_ptr"**
  %32 = load %"class.std::__1::shared_ptr"*, %"class.std::__1::shared_ptr"** %31, align 8
  %33 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 3, i32 1
  %34 = load i64, i64* %33, align 8
  %35 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %32, i64 %34
  %36 = icmp eq i64 %34, 0
  br i1 %36, label %67, label %37

37:                                               ; preds = %29
  %38 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 5
  br label %39

39:                                               ; preds = %37, %64
  %40 = phi %"class.std::__1::shared_ptr"* [ %32, %37 ], [ %65, %64 ]
  %41 = bitcast %"class.std::__1::shared_ptr"* %40 to i64*
  %42 = load i64, i64* %41, align 8
  %43 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %40, i64 0, i32 1
  %44 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %43, align 8
  %45 = icmp eq %"class.std::__1::__shared_weak_count"* %44, null
  br i1 %45, label %60, label %46

46:                                               ; preds = %39
  %47 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %44, i64 0, i32 0, i32 1
  %48 = atomicrmw add i64* %47, i64 1 monotonic
  %49 = inttoptr i64 %42 to %"struct.vk::TimelineSemaphore::Shared"*
  %50 = load i32, i32* %38, align 8
  %51 = load i64, i64* %4, align 8
  tail call void @_ZN2vk17TimelineSemaphore6Shared6signalEim(%"struct.vk::TimelineSemaphore::Shared"* %49, i32 %50, i64 %51) #12
  %52 = atomicrmw add i64* %47, i64 -1 acq_rel
  %53 = icmp eq i64 %52, 0
  br i1 %53, label %54, label %64

54:                                               ; preds = %46
  %55 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %44, i64 0, i32 0
  %56 = bitcast %"class.std::__1::__shared_weak_count"* %44 to void (%"class.std::__1::__shared_count"*)***
  %57 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %56, align 8
  %58 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %57, i64 2
  %59 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %58, align 8
  tail call void %59(%"class.std::__1::__shared_count"* %55) #9
  tail call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %44) #9
  br label %64

60:                                               ; preds = %39
  %61 = inttoptr i64 %42 to %"struct.vk::TimelineSemaphore::Shared"*
  %62 = load i32, i32* %38, align 8
  %63 = load i64, i64* %4, align 8
  tail call void @_ZN2vk17TimelineSemaphore6Shared6signalEim(%"struct.vk::TimelineSemaphore::Shared"* %61, i32 %62, i64 %63) #12
  br label %64

64:                                               ; preds = %60, %46, %54
  %65 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %40, i64 1
  %66 = icmp eq %"class.std::__1::shared_ptr"* %65, %35
  br i1 %66, label %67, label %39

67:                                               ; preds = %64, %29, %2
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %3) #9
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk17TimelineSemaphore6Shared6signalEim(%"struct.vk::TimelineSemaphore::Shared"*, i32, i64) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %4) #9
  %5 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 4
  %6 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0
  %7 = bitcast %"class.std::__1::__tree_end_node"* %6 to %"class.std::__1::__tree_node"**
  %8 = load %"class.std::__1::__tree_node"*, %"class.std::__1::__tree_node"** %7, align 8
  %9 = icmp eq %"class.std::__1::__tree_node"* %8, null
  br i1 %9, label %106, label %10

10:                                               ; preds = %3, %10
  %11 = phi %"class.std::__1::__tree_end_node"* [ %21, %10 ], [ %6, %3 ]
  %12 = phi %"class.std::__1::__tree_node"* [ %22, %10 ], [ %8, %3 ]
  %13 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %12, i64 0, i32 1, i32 0, i32 0
  %14 = load i32, i32* %13, align 4
  %15 = icmp slt i32 %14, %1
  %16 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %12, i64 0, i32 0, i32 1
  %17 = bitcast %"class.std::__1::__tree_node_base"** %16 to %"class.std::__1::__tree_node"**
  %18 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %12, i64 0, i32 0, i32 0
  %19 = bitcast %"class.std::__1::__tree_node"* %12 to %"class.std::__1::__tree_node"**
  %20 = select i1 %15, %"class.std::__1::__tree_node"** %17, %"class.std::__1::__tree_node"** %19
  %21 = select i1 %15, %"class.std::__1::__tree_end_node"* %11, %"class.std::__1::__tree_end_node"* %18
  %22 = load %"class.std::__1::__tree_node"*, %"class.std::__1::__tree_node"** %20, align 8
  %23 = icmp eq %"class.std::__1::__tree_node"* %22, null
  br i1 %23, label %24, label %10

24:                                               ; preds = %10
  %25 = icmp eq %"class.std::__1::__tree_end_node"* %21, %6
  br i1 %25, label %106, label %26

26:                                               ; preds = %24
  %27 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %21, i64 4
  %28 = bitcast %"class.std::__1::__tree_end_node"* %27 to i32*
  %29 = load i32, i32* %28, align 4
  %30 = icmp sgt i32 %29, %1
  br i1 %30, label %106, label %31

31:                                               ; preds = %26
  %32 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 2
  %33 = load i64, i64* %32, align 8
  %34 = icmp eq i64 %33, 0
  %35 = icmp ne %"class.std::__1::__tree_end_node"* %21, %6
  %36 = and i1 %35, %34
  br i1 %36, label %37, label %106

37:                                               ; preds = %31
  %38 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %21, i64 5
  %39 = bitcast %"class.std::__1::__tree_end_node"* %38 to i64*
  %40 = load i64, i64* %39, align 8
  %41 = icmp eq i64 %40, %2
  br i1 %41, label %42, label %106

42:                                               ; preds = %37
  %43 = getelementptr inbounds %"class.std::__1::map", %"class.std::__1::map"* %5, i64 0, i32 0
  tail call void @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE7destroyEPNS_11__tree_nodeIS2_PvEE(%"class.std::__1::__tree"* %43, %"class.std::__1::__tree_node"* nonnull %8) #9
  %44 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 4, i32 0, i32 2, i32 0, i32 0
  store i64 0, i64* %44, align 8
  %45 = getelementptr inbounds %"class.std::__1::map", %"class.std::__1::map"* %5, i64 0, i32 0, i32 0
  store %"class.std::__1::__tree_end_node"* %6, %"class.std::__1::__tree_end_node"** %45, align 8
  %46 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %6, i64 0, i32 0
  store %"class.std::__1::__tree_node_base"* null, %"class.std::__1::__tree_node_base"** %46, align 8
  store i64 1, i64* %32, align 8
  %47 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %48 = load atomic i32, i32* %47 seq_cst, align 4
  %49 = icmp eq i32 %48, 0
  br i1 %49, label %68, label %50

50:                                               ; preds = %42
  %51 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %51) #9
  %52 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 1, i32 5
  %53 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %52, align 8
  %54 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %53, null
  br i1 %54, label %55, label %59

55:                                               ; preds = %59, %50
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %51) #9
  %56 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %57 = load atomic i32, i32* %56 seq_cst, align 4
  %58 = icmp sgt i32 %57, 0
  br i1 %58, label %66, label %68

59:                                               ; preds = %50, %59
  %60 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* [ %64, %59 ], [ %53, %50 ]
  %61 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %60, i64 0, i32 0
  %62 = load %"class.marl::Scheduler::Fiber"*, %"class.marl::Scheduler::Fiber"** %61, align 8
  tail call void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"* %62) #9
  %63 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %60, i64 0, i32 1
  %64 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %63, align 8
  %65 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %64, null
  br i1 %65, label %55, label %59

66:                                               ; preds = %55
  %67 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variable10notify_allEv(%"class.std::__1::condition_variable"* %67) #9
  br label %68

68:                                               ; preds = %42, %55, %66
  %69 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 3, i32 4
  %70 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %69 to %"class.std::__1::shared_ptr"**
  %71 = load %"class.std::__1::shared_ptr"*, %"class.std::__1::shared_ptr"** %70, align 8
  %72 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 3, i32 1
  %73 = load i64, i64* %72, align 8
  %74 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %71, i64 %73
  %75 = icmp eq i64 %73, 0
  br i1 %75, label %106, label %76

76:                                               ; preds = %68
  %77 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 5
  br label %78

78:                                               ; preds = %76, %103
  %79 = phi %"class.std::__1::shared_ptr"* [ %71, %76 ], [ %104, %103 ]
  %80 = bitcast %"class.std::__1::shared_ptr"* %79 to i64*
  %81 = load i64, i64* %80, align 8
  %82 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %79, i64 0, i32 1
  %83 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %82, align 8
  %84 = icmp eq %"class.std::__1::__shared_weak_count"* %83, null
  br i1 %84, label %99, label %85

85:                                               ; preds = %78
  %86 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %83, i64 0, i32 0, i32 1
  %87 = atomicrmw add i64* %86, i64 1 monotonic
  %88 = inttoptr i64 %81 to %"struct.vk::TimelineSemaphore::Shared"*
  %89 = load i32, i32* %77, align 8
  %90 = load i64, i64* %32, align 8
  tail call void @_ZN2vk17TimelineSemaphore6Shared6signalEim(%"struct.vk::TimelineSemaphore::Shared"* %88, i32 %89, i64 %90) #12
  %91 = atomicrmw add i64* %86, i64 -1 acq_rel
  %92 = icmp eq i64 %91, 0
  br i1 %92, label %93, label %103

93:                                               ; preds = %85
  %94 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %83, i64 0, i32 0
  %95 = bitcast %"class.std::__1::__shared_weak_count"* %83 to void (%"class.std::__1::__shared_count"*)***
  %96 = load void (%"class.std::__1::__shared_count"*)**, void (%"class.std::__1::__shared_count"*)*** %95, align 8
  %97 = getelementptr inbounds void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %96, i64 2
  %98 = load void (%"class.std::__1::__shared_count"*)*, void (%"class.std::__1::__shared_count"*)** %97, align 8
  tail call void %98(%"class.std::__1::__shared_count"* %94) #9
  tail call void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"* nonnull %83) #9
  br label %103

99:                                               ; preds = %78
  %100 = inttoptr i64 %81 to %"struct.vk::TimelineSemaphore::Shared"*
  %101 = load i32, i32* %77, align 8
  %102 = load i64, i64* %32, align 8
  tail call void @_ZN2vk17TimelineSemaphore6Shared6signalEim(%"struct.vk::TimelineSemaphore::Shared"* %100, i32 %101, i64 %102) #12
  br label %103

103:                                              ; preds = %99, %85, %93
  %104 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %79, i64 1
  %105 = icmp eq %"class.std::__1::shared_ptr"* %104, %74
  br i1 %105, label %106, label %78

106:                                              ; preds = %103, %26, %24, %3, %68, %31, %37
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %4) #9
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk17TimelineSemaphore4waitEm(%"class.vk::TimelineSemaphore"* nocapture readonly, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 1, i32 0
  %4 = load %"struct.vk::TimelineSemaphore::Shared"*, %"struct.vk::TimelineSemaphore::Shared"** %3, align 8
  tail call void @_ZN2vk17TimelineSemaphore6Shared4waitEm(%"struct.vk::TimelineSemaphore::Shared"* %4, i64 %1) #12
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk17TimelineSemaphore6Shared4waitEm(%"struct.vk::TimelineSemaphore::Shared"*, i64) local_unnamed_addr #0 align 2 {
  %3 = alloca %"struct.marl::Allocation::Request", align 8
  %4 = alloca %"struct.marl::Allocation", align 8
  %5 = alloca %"class.std::__1::function.164", align 8
  %6 = alloca i64, align 8
  %7 = alloca %"class.marl::lock", align 8
  store i64 %1, i64* %6, align 8
  %8 = bitcast %"class.marl::lock"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %8) #10
  %9 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %7, i64 0, i32 0, i32 0
  %10 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %7, i64 0, i32 0, i32 1
  %11 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 0, i32 0
  %12 = bitcast %"class.marl::lock"* %7 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %12, i8 -86, i64 16, i1 false)
  store %"class.std::__1::mutex"* %11, %"class.std::__1::mutex"** %9, align 8
  store i8 1, i8* %10, align 8
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %11) #9
  %13 = ptrtoint %"struct.vk::TimelineSemaphore::Shared"* %0 to i64
  %14 = ptrtoint i64* %6 to i64
  %15 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 2
  %16 = load i64, i64* %15, align 8
  %17 = icmp eq i64 %16, %1
  br i1 %17, label %175, label %18

18:                                               ; preds = %2
  %19 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
  %20 = atomicrmw add i32* %19, i32 1 seq_cst
  %21 = call %"class.marl::Scheduler::Fiber"* @_ZN4marl9Scheduler5Fiber7currentEv() #9
  %22 = ptrtoint %"class.marl::Scheduler::Fiber"* %21 to i64
  %23 = icmp eq %"class.marl::Scheduler::Fiber"* %21, null
  br i1 %23, label %157, label %24

24:                                               ; preds = %18
  %25 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 0, i32 0
  call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %25) #9
  %26 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 1, i32 4
  %27 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %26, align 8
  %28 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %27, null
  br i1 %28, label %31, label %29

29:                                               ; preds = %24
  %30 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %26 to i64*
  br label %80

31:                                               ; preds = %24
  %32 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 1, i32 2
  %33 = load i64, i64* %32, align 8
  %34 = icmp ugt i64 %33, 8
  %35 = select i1 %34, i64 %33, i64 8
  %36 = mul i64 %35, 24
  %37 = add i64 %36, 40
  %38 = bitcast %"struct.marl::Allocation::Request"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %38) #10
  %39 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %3, i64 0, i32 0
  %40 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %3, i64 0, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %38, i8 -86, i64 24, i1 false) #10
  %41 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %3, i64 0, i32 2
  %42 = bitcast i8* %41 to i16*
  store i16 1024, i16* %42, align 8
  store i64 %37, i64* %39, align 8
  store i64 8, i64* %40, align 8
  %43 = bitcast %"struct.marl::Allocation"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %43) #10
  %44 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 1, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %43, i8 -86, i64 32, i1 false) #10
  %45 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %44, align 8
  %46 = bitcast %"class.marl::Allocator"* %45 to void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)***
  %47 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)**, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*** %46, align 8
  %48 = getelementptr inbounds void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %47, i64 2
  %49 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %48, align 8
  call void %49(%"struct.marl::Allocation"* nonnull sret %4, %"class.marl::Allocator"* %45, %"struct.marl::Allocation::Request"* nonnull dereferenceable(24) %3) #9
  %50 = bitcast %"struct.marl::Allocation"* %4 to %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"**
  %51 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %50, align 8
  %52 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %26 to i64*
  br label %53

53:                                               ; preds = %64, %31
  %54 = phi i64 [ 0, %31 ], [ %65, %64 ]
  %55 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %51, i64 %54
  %56 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %51, i64 %54, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* null, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %56, align 8
  %57 = load i64, i64* %52, align 8
  %58 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %51, i64 %54, i32 1
  %59 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %58 to i64*
  store i64 %57, i64* %59, align 8
  %60 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %26, align 8
  %61 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %60, null
  br i1 %61, label %64, label %62

62:                                               ; preds = %53
  %63 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %60, i64 0, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %55, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %63, align 8
  br label %64

64:                                               ; preds = %62, %53
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %55, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %26, align 8
  %65 = add nuw i64 %54, 1
  %66 = icmp eq i64 %65, %35
  br i1 %66, label %67, label %53

67:                                               ; preds = %64
  %68 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %4, i64 0, i32 0
  %69 = load i8*, i8** %68, align 8
  %70 = getelementptr inbounds i8, i8* %69, i64 %36
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %70, i8* nonnull align 8 %43, i64 32, i1 false) #10
  %71 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 1, i32 3
  %72 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %71 to i64*
  %73 = load i64, i64* %72, align 8
  %74 = getelementptr inbounds i8, i8* %70, i64 32
  %75 = bitcast i8* %74 to i64*
  store i64 %73, i64* %75, align 8
  %76 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %71 to i8**
  store i8* %70, i8** %76, align 8
  %77 = load i64, i64* %32, align 8
  %78 = add i64 %77, %35
  store i64 %78, i64* %32, align 8
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %43) #10
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %38) #10
  %79 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %26, align 8
  br label %80

80:                                               ; preds = %67, %29
  %81 = phi i64* [ %30, %29 ], [ %52, %67 ]
  %82 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* [ %27, %29 ], [ %79, %67 ]
  %83 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %82, i64 0, i32 1
  %84 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %83 to i64*
  %85 = load i64, i64* %84, align 8
  store i64 %85, i64* %81, align 8
  %86 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %82, i64 0, i32 2
  %87 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %86, align 8
  %88 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %87, null
  br i1 %88, label %93, label %89

89:                                               ; preds = %80
  %90 = load i64, i64* %84, align 8
  %91 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %87, i64 0, i32 1
  %92 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %91 to i64*
  store i64 %90, i64* %92, align 8
  br label %93

93:                                               ; preds = %89, %80
  %94 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %83, align 8
  %95 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %94, null
  br i1 %95, label %101, label %96

96:                                               ; preds = %93
  %97 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %86 to i64*
  %98 = load i64, i64* %97, align 8
  %99 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %94, i64 0, i32 2
  %100 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %99 to i64*
  store i64 %98, i64* %100, align 8
  br label %101

101:                                              ; preds = %96, %93
  %102 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %83 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %102, i8 0, i64 16, i1 false) #10
  %103 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 1, i32 5
  %104 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %103, align 8
  %105 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %104, null
  br i1 %105, label %109, label %106

106:                                              ; preds = %101
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %104, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %83, align 8
  %107 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %103, align 8
  %108 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %107, i64 0, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %82, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %108, align 8
  br label %109

109:                                              ; preds = %106, %101
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %82, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %103, align 8
  %110 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %82 to i64*
  store i64 %22, i64* %110, align 8
  %111 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 1, i32 1
  %112 = load i64, i64* %111, align 8
  %113 = add i64 %112, 1
  store i64 %113, i64* %111, align 8
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %25) #9
  %114 = bitcast %"class.std::__1::function.164"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %114) #10
  %115 = getelementptr inbounds %"class.std::__1::function.164", %"class.std::__1::function.164"* %5, i64 0, i32 0, i32 1, i32 0
  %116 = getelementptr inbounds %"class.std::__1::function.164", %"class.std::__1::function.164"* %5, i64 0, i32 0, i32 2
  store i1 (%"union.std::__1::__function::__policy_storage"*)* @"_ZNSt3__110__function16__policy_invokerIFbvEE11__call_implINS0_20__default_alloc_funcIZN2vk17TimelineSemaphore6Shared4waitEmE3$_0S2_EEEEbPKNS0_16__policy_storageE", i1 (%"union.std::__1::__function::__policy_storage"*)** %115, align 8
  store %"struct.std::__1::__function::__policy"* @"_ZZNSt3__110__function8__policy15__choose_policyINS0_20__default_alloc_funcIZN2vk17TimelineSemaphore6Shared4waitEmE3$_0FbvEEEEEPKS1_NS_17integral_constantIbLb1EEEE9__policy_", %"struct.std::__1::__function::__policy"** %116, align 8
  %117 = bitcast %"class.std::__1::function.164"* %5 to i64*
  store i64 %13, i64* %117, align 8
  %118 = getelementptr inbounds %"class.std::__1::function.164", %"class.std::__1::function.164"* %5, i64 0, i32 0, i32 0, i32 1
  %119 = bitcast [8 x i8]* %118 to i64*
  store i64 %14, i64* %119, align 8
  call void @_ZN4marl9Scheduler5Fiber4waitERNS_4lockERKNSt3__18functionIFbvEEE(%"class.marl::Scheduler::Fiber"* nonnull %21, %"class.marl::lock"* nonnull dereferenceable(16) %7, %"class.std::__1::function.164"* nonnull dereferenceable(32) %5) #9
  %120 = load %"struct.std::__1::__function::__policy"*, %"struct.std::__1::__function::__policy"** %116, align 8
  %121 = getelementptr inbounds %"struct.std::__1::__function::__policy", %"struct.std::__1::__function::__policy"* %120, i64 0, i32 1
  %122 = load void (i8*)*, void (i8*)** %121, align 8
  %123 = icmp eq void (i8*)* %122, null
  br i1 %123, label %127, label %124

124:                                              ; preds = %109
  %125 = getelementptr inbounds %"class.std::__1::function.164", %"class.std::__1::function.164"* %5, i64 0, i32 0, i32 0, i32 0
  %126 = load i8*, i8** %125, align 8
  call void %122(i8* %126) #9
  br label %127

127:                                              ; preds = %124, %109
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %114) #10
  call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %25) #9
  %128 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %103, align 8
  %129 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %128, %82
  br i1 %129, label %130, label %133

130:                                              ; preds = %127
  %131 = load i64, i64* %84, align 8
  %132 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %103 to i64*
  store i64 %131, i64* %132, align 8
  br label %133

133:                                              ; preds = %130, %127
  %134 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %86, align 8
  %135 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %134, null
  br i1 %135, label %140, label %136

136:                                              ; preds = %133
  %137 = load i64, i64* %84, align 8
  %138 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %134, i64 0, i32 1
  %139 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %138 to i64*
  store i64 %137, i64* %139, align 8
  br label %140

140:                                              ; preds = %136, %133
  %141 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %83, align 8
  %142 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %141, null
  br i1 %142, label %148, label %143

143:                                              ; preds = %140
  %144 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %86 to i64*
  %145 = load i64, i64* %144, align 8
  %146 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %141, i64 0, i32 2
  %147 = bitcast %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %146 to i64*
  store i64 %145, i64* %147, align 8
  br label %148

148:                                              ; preds = %143, %140
  call void @llvm.memset.p0i8.i64(i8* align 8 %102, i8 0, i64 16, i1 false) #10
  %149 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %26, align 8
  %150 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %149, null
  br i1 %150, label %154, label %151

151:                                              ; preds = %148
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %149, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %83, align 8
  %152 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %26, align 8
  %153 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %152, i64 0, i32 2
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %82, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %153, align 8
  br label %154

154:                                              ; preds = %151, %148
  store %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %82, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %26, align 8
  %155 = load i64, i64* %111, align 8
  %156 = add i64 %155, -1
  store i64 %156, i64* %111, align 8
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %25) #9
  br label %171

157:                                              ; preds = %18
  %158 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0
  %159 = atomicrmw add i32* %158, i32 1 seq_cst
  %160 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 2
  %161 = getelementptr inbounds %"class.marl::lock", %"class.marl::lock"* %7, i64 0, i32 0
  %162 = load i64, i64* %15, align 8
  %163 = load i64, i64* %6, align 8
  %164 = icmp eq i64 %162, %163
  br i1 %164, label %169, label %165

165:                                              ; preds = %157, %165
  call void @_ZNSt3__118condition_variable4waitERNS_11unique_lockINS_5mutexEEE(%"class.std::__1::condition_variable"* %160, %"class.std::__1::unique_lock"* nonnull dereferenceable(16) %161) #9
  %166 = load i64, i64* %15, align 8
  %167 = load i64, i64* %6, align 8
  %168 = icmp eq i64 %166, %167
  br i1 %168, label %169, label %165

169:                                              ; preds = %165, %157
  %170 = atomicrmw sub i32* %158, i32 1 seq_cst
  br label %171

171:                                              ; preds = %154, %169
  %172 = atomicrmw sub i32* %19, i32 1 seq_cst
  %173 = load i8, i8* %10, align 8, !range !2
  %174 = icmp eq i8 %173, 0
  br i1 %174, label %177, label %175

175:                                              ; preds = %2, %171
  %176 = load %"class.std::__1::mutex"*, %"class.std::__1::mutex"** %9, align 8
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %176) #9
  br label %177

177:                                              ; preds = %171, %175
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %8) #10
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden i64 @_ZN2vk17TimelineSemaphore15getCounterValueEv(%"class.vk::TimelineSemaphore"* nocapture readonly) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 1, i32 0
  %3 = load %"struct.vk::TimelineSemaphore::Shared"*, %"struct.vk::TimelineSemaphore::Shared"** %2, align 8
  %4 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %3, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %4) #9
  %5 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %3, i64 0, i32 2
  %6 = load i64, i64* %5, align 8
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %4) #9
  ret i64 %6
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden i64 @_ZN2vk17TimelineSemaphore6Shared15getCounterValueEv(%"struct.vk::TimelineSemaphore::Shared"*) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %2) #9
  %3 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 2
  %4 = load i64, i64* %3, align 8
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %2) #9
  ret i64 %4
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk17TimelineSemaphore6SharedC2EPN4marl9AllocatorEm(%"struct.vk::TimelineSemaphore::Shared"*, %"class.marl::Allocator"*, i64) unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 1, i32 0
  %5 = bitcast %"struct.vk::TimelineSemaphore::Shared"* %0 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %5, i8 0, i64 80, i1 false)
  store %"class.marl::Allocator"* %1, %"class.marl::Allocator"** %4, align 8
  %6 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 1, i32 1, i32 1
  %7 = bitcast i64* %6 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %7, i8 0, i64 96, i1 false) #10
  %8 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 2
  store i64 %2, i64* %8, align 8
  %9 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 3
  %10 = load i64, i64* bitcast (%"class.marl::Allocator"** @_ZN4marl9Allocator7DefaultE to i64*), align 8
  %11 = bitcast %"class.marl::containers::vector"* %9 to i64*
  store i64 %10, i64* %11, align 8
  %12 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 3, i32 1
  %13 = bitcast i64* %12 to <2 x i64>*
  store <2 x i64> <i64 0, i64 1>, <2 x i64>* %13, align 8
  %14 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 3, i32 4
  %15 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 3, i32 3, i64 0
  store %"struct.marl::aligned_storage<16, 8>::type"* %15, %"struct.marl::aligned_storage<16, 8>::type"** %14, align 8
  %16 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 3, i32 5
  %17 = bitcast %"struct.marl::Allocation"* %16 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %17, i8 0, i64 26, i1 false) #10
  %18 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0
  %19 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0
  %20 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 4, i32 0, i32 0
  %21 = bitcast %"class.std::__1::__tree_node_base"** %18 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %21, i8 0, i64 16, i1 false) #10
  store %"class.std::__1::__tree_end_node"* %19, %"class.std::__1::__tree_end_node"** %20, align 8
  %22 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 5
  %23 = atomicrmw add i32* getelementptr inbounds (%"struct.std::__1::atomic", %"struct.std::__1::atomic"* @_ZN2vk17TimelineSemaphore6Shared6nextIdE, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0), i32 1 seq_cst
  store i32 %23, i32* %22, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk17TimelineSemaphore12addDependentERS0_m(%"class.vk::TimelineSemaphore"* nocapture readonly, %"class.vk::TimelineSemaphore"* dereferenceable(72), i64) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 1, i32 0
  %5 = load %"struct.vk::TimelineSemaphore::Shared"*, %"struct.vk::TimelineSemaphore::Shared"** %4, align 8
  %6 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %5, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %6) #9
  %7 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %5, i64 0, i32 3
  %8 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %1, i64 0, i32 1
  tail call void @_ZN4marl10containers6vectorINSt3__110shared_ptrIN2vk17TimelineSemaphore6SharedEEELi1EE9push_backERKS7_(%"class.marl::containers::vector"* %7, %"class.std::__1::shared_ptr"* dereferenceable(16) %8) #9
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %6) #9
  %9 = load %"struct.vk::TimelineSemaphore::Shared"*, %"struct.vk::TimelineSemaphore::Shared"** %4, align 8
  %10 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %9, i64 0, i32 5
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %1, i64 0, i32 1, i32 0
  %13 = load %"struct.vk::TimelineSemaphore::Shared"*, %"struct.vk::TimelineSemaphore::Shared"** %12, align 8
  tail call void @_ZN2vk17TimelineSemaphore6Shared13addDependencyEim(%"struct.vk::TimelineSemaphore::Shared"* %13, i32 %11, i64 %2) #9
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk17TimelineSemaphore6Shared12addDependentERS0_(%"struct.vk::TimelineSemaphore::Shared"*, %"class.vk::TimelineSemaphore"* dereferenceable(72)) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %3) #9
  %4 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 3
  %5 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %1, i64 0, i32 1
  tail call void @_ZN4marl10containers6vectorINSt3__110shared_ptrIN2vk17TimelineSemaphore6SharedEEELi1EE9push_backERKS7_(%"class.marl::containers::vector"* %4, %"class.std::__1::shared_ptr"* dereferenceable(16) %5) #12
  tail call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %3) #9
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk17TimelineSemaphore13addDependencyEim(%"class.vk::TimelineSemaphore"* nocapture readonly, i32, i64) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 1, i32 0
  %5 = load %"struct.vk::TimelineSemaphore::Shared"*, %"struct.vk::TimelineSemaphore::Shared"** %4, align 8
  tail call void @_ZN2vk17TimelineSemaphore6Shared13addDependencyEim(%"struct.vk::TimelineSemaphore::Shared"* %5, i32 %1, i64 %2) #12
  ret void
}

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN4marl10containers6vectorINSt3__110shared_ptrIN2vk17TimelineSemaphore6SharedEEELi1EE9push_backERKS7_(%"class.marl::containers::vector"*, %"class.std::__1::shared_ptr"* dereferenceable(16)) local_unnamed_addr #4 comdat align 2 {
  %3 = alloca %"struct.marl::Allocation::Request", align 8
  %4 = alloca %"struct.marl::Allocation", align 8
  %5 = getelementptr inbounds %"class.marl::containers::vector", %"class.marl::containers::vector"* %0, i64 0, i32 1
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 1
  %8 = getelementptr inbounds %"class.marl::containers::vector", %"class.marl::containers::vector"* %0, i64 0, i32 2
  %9 = load i64, i64* %8, align 8
  %10 = icmp ult i64 %9, %7
  br i1 %10, label %15, label %11

11:                                               ; preds = %2
  %12 = getelementptr inbounds %"class.marl::containers::vector", %"class.marl::containers::vector"* %0, i64 0, i32 4
  %13 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %12 to %"class.std::__1::shared_ptr"**
  %14 = load %"class.std::__1::shared_ptr"*, %"class.std::__1::shared_ptr"** %13, align 8
  br label %85

15:                                               ; preds = %2
  %16 = shl i64 %7, 1
  %17 = icmp ugt i64 %16, 8
  %18 = select i1 %17, i64 %16, i64 8
  store i64 %18, i64* %8, align 8
  %19 = bitcast %"struct.marl::Allocation::Request"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %19) #10
  %20 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %3, i64 0, i32 0
  %21 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %3, i64 0, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %19, i8 -86, i64 24, i1 false) #10
  %22 = getelementptr inbounds %"struct.marl::Allocation::Request", %"struct.marl::Allocation::Request"* %3, i64 0, i32 2
  %23 = bitcast i8* %22 to i16*
  store i16 768, i16* %23, align 8
  %24 = shl i64 %18, 4
  store i64 %24, i64* %20, align 8
  store i64 8, i64* %21, align 8
  %25 = bitcast %"struct.marl::Allocation"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %25) #10
  %26 = getelementptr inbounds %"class.marl::containers::vector", %"class.marl::containers::vector"* %0, i64 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %25, i8 -86, i64 32, i1 false) #10
  %27 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %26, align 8
  %28 = bitcast %"class.marl::Allocator"* %27 to void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)***
  %29 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)**, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*** %28, align 8
  %30 = getelementptr inbounds void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %29, i64 2
  %31 = load void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)*, void (%"struct.marl::Allocation"*, %"class.marl::Allocator"*, %"struct.marl::Allocation::Request"*)** %30, align 8
  call void %31(%"struct.marl::Allocation"* nonnull sret %4, %"class.marl::Allocator"* %27, %"struct.marl::Allocation::Request"* nonnull dereferenceable(24) %3) #9
  %32 = bitcast %"struct.marl::Allocation"* %4 to %"struct.marl::aligned_storage<16, 8>::type"**
  %33 = load %"struct.marl::aligned_storage<16, 8>::type"*, %"struct.marl::aligned_storage<16, 8>::type"** %32, align 8
  %34 = load i64, i64* %5, align 8
  %35 = icmp eq i64 %34, 0
  br i1 %35, label %41, label %36

36:                                               ; preds = %15
  %37 = getelementptr inbounds %"class.marl::containers::vector", %"class.marl::containers::vector"* %0, i64 0, i32 4
  %38 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %37 to %"class.std::__1::shared_ptr"**
  br label %68

39:                                               ; preds = %68
  %40 = icmp eq i64 %83, 0
  br i1 %40, label %41, label %47

41:                                               ; preds = %47, %39, %15
  %42 = phi i64 [ 0, %39 ], [ 0, %15 ], [ %52, %47 ]
  %43 = getelementptr inbounds %"class.marl::containers::vector", %"class.marl::containers::vector"* %0, i64 0, i32 5
  %44 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %43, i64 0, i32 0
  %45 = load i8*, i8** %44, align 8
  %46 = icmp eq i8* %45, null
  br i1 %46, label %63, label %54

47:                                               ; preds = %39, %47
  %48 = phi i64 [ %51, %47 ], [ 0, %39 ]
  %49 = load %"class.std::__1::shared_ptr"*, %"class.std::__1::shared_ptr"** %38, align 8
  %50 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %49, i64 %48
  call void @_ZNSt3__110shared_ptrIN2vk17TimelineSemaphore6SharedEED2Ev(%"class.std::__1::shared_ptr"* %50) #9
  %51 = add nuw i64 %48, 1
  %52 = load i64, i64* %5, align 8
  %53 = icmp ult i64 %51, %52
  br i1 %53, label %47, label %41

54:                                               ; preds = %41
  %55 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %26, align 8
  %56 = bitcast %"class.marl::Allocator"* %55 to void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)***
  %57 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)**, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*** %56, align 8
  %58 = getelementptr inbounds void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %57, i64 3
  %59 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %58, align 8
  call void %59(%"class.marl::Allocator"* %55, %"struct.marl::Allocation"* dereferenceable(32) %43) #9
  %60 = getelementptr inbounds %"class.marl::containers::vector", %"class.marl::containers::vector"* %0, i64 0, i32 4
  %61 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %60 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %61, i8 0, i64 34, i1 false) #10
  %62 = load i64, i64* %5, align 8
  br label %63

63:                                               ; preds = %54, %41
  %64 = phi i64 [ %62, %54 ], [ %42, %41 ]
  %65 = getelementptr inbounds %"class.marl::containers::vector", %"class.marl::containers::vector"* %0, i64 0, i32 4
  store %"struct.marl::aligned_storage<16, 8>::type"* %33, %"struct.marl::aligned_storage<16, 8>::type"** %65, align 8
  %66 = bitcast %"struct.marl::Allocation"* %43 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %66, i8* nonnull align 8 %25, i64 32, i1 false) #10
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %25) #10
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %19) #10
  %67 = bitcast %"struct.marl::aligned_storage<16, 8>::type"* %33 to %"class.std::__1::shared_ptr"*
  br label %85

68:                                               ; preds = %68, %36
  %69 = phi i64 [ 0, %36 ], [ %82, %68 ]
  %70 = getelementptr inbounds %"struct.marl::aligned_storage<16, 8>::type", %"struct.marl::aligned_storage<16, 8>::type"* %33, i64 %69
  %71 = load %"class.std::__1::shared_ptr"*, %"class.std::__1::shared_ptr"** %38, align 8
  %72 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %71, i64 %69
  %73 = bitcast %"class.std::__1::shared_ptr"* %72 to i64*
  %74 = load i64, i64* %73, align 8
  %75 = bitcast %"struct.marl::aligned_storage<16, 8>::type"* %70 to i64*
  store i64 %74, i64* %75, align 8
  %76 = getelementptr inbounds %"struct.marl::aligned_storage<16, 8>::type", %"struct.marl::aligned_storage<16, 8>::type"* %33, i64 %69, i32 0, i64 8
  %77 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %71, i64 %69, i32 1
  %78 = bitcast %"class.std::__1::__shared_weak_count"** %77 to i64*
  %79 = load i64, i64* %78, align 8
  %80 = bitcast i8* %76 to i64*
  store i64 %79, i64* %80, align 8
  %81 = bitcast %"class.std::__1::shared_ptr"* %72 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %81, i8 0, i64 16, i1 false) #10
  %82 = add nuw i64 %69, 1
  %83 = load i64, i64* %5, align 8
  %84 = icmp ult i64 %82, %83
  br i1 %84, label %68, label %39

85:                                               ; preds = %11, %63
  %86 = phi i64 [ %6, %11 ], [ %64, %63 ]
  %87 = phi %"class.std::__1::shared_ptr"* [ %14, %11 ], [ %67, %63 ]
  %88 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %87, i64 %86
  %89 = bitcast %"class.std::__1::shared_ptr"* %1 to i64*
  %90 = load i64, i64* %89, align 8
  %91 = bitcast %"class.std::__1::shared_ptr"* %88 to i64*
  store i64 %90, i64* %91, align 8
  %92 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %87, i64 %86, i32 1
  %93 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %1, i64 0, i32 1
  %94 = load %"class.std::__1::__shared_weak_count"*, %"class.std::__1::__shared_weak_count"** %93, align 8
  store %"class.std::__1::__shared_weak_count"* %94, %"class.std::__1::__shared_weak_count"** %92, align 8
  %95 = icmp eq %"class.std::__1::__shared_weak_count"* %94, null
  br i1 %95, label %99, label %96

96:                                               ; preds = %85
  %97 = getelementptr inbounds %"class.std::__1::__shared_weak_count", %"class.std::__1::__shared_weak_count"* %94, i64 0, i32 0, i32 1
  %98 = atomicrmw add i64* %97, i64 1 monotonic
  br label %99

99:                                               ; preds = %85, %96
  %100 = load i64, i64* %5, align 8
  %101 = add i64 %100, 1
  store i64 %101, i64* %5, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk17TimelineSemaphore6Shared13addDependencyEim(%"struct.vk::TimelineSemaphore::Shared"*, i32, i64) local_unnamed_addr #0 align 2 {
  %4 = alloca %"struct.std::__1::pair.43", align 8
  %5 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 0, i32 0
  tail call void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"* %5) #9
  %6 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0
  %7 = bitcast %"class.std::__1::__tree_end_node"* %6 to %"class.std::__1::__tree_node"**
  %8 = load %"class.std::__1::__tree_node"*, %"class.std::__1::__tree_node"** %7, align 8
  %9 = icmp eq %"class.std::__1::__tree_node"* %8, null
  br i1 %9, label %31, label %10

10:                                               ; preds = %3, %10
  %11 = phi %"class.std::__1::__tree_end_node"* [ %21, %10 ], [ %6, %3 ]
  %12 = phi %"class.std::__1::__tree_node"* [ %22, %10 ], [ %8, %3 ]
  %13 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %12, i64 0, i32 1, i32 0, i32 0
  %14 = load i32, i32* %13, align 4
  %15 = icmp slt i32 %14, %1
  %16 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %12, i64 0, i32 0, i32 1
  %17 = bitcast %"class.std::__1::__tree_node_base"** %16 to %"class.std::__1::__tree_node"**
  %18 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %12, i64 0, i32 0, i32 0
  %19 = bitcast %"class.std::__1::__tree_node"* %12 to %"class.std::__1::__tree_node"**
  %20 = select i1 %15, %"class.std::__1::__tree_node"** %17, %"class.std::__1::__tree_node"** %19
  %21 = select i1 %15, %"class.std::__1::__tree_end_node"* %11, %"class.std::__1::__tree_end_node"* %18
  %22 = load %"class.std::__1::__tree_node"*, %"class.std::__1::__tree_node"** %20, align 8
  %23 = icmp eq %"class.std::__1::__tree_node"* %22, null
  br i1 %23, label %24, label %10

24:                                               ; preds = %10
  %25 = icmp eq %"class.std::__1::__tree_end_node"* %21, %6
  br i1 %25, label %31, label %26

26:                                               ; preds = %24
  %27 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %21, i64 4
  %28 = bitcast %"class.std::__1::__tree_end_node"* %27 to i32*
  %29 = load i32, i32* %28, align 4
  %30 = icmp sgt i32 %29, %1
  br i1 %30, label %31, label %32

31:                                               ; preds = %26, %24, %3
  br label %32

32:                                               ; preds = %26, %31
  %33 = phi %"class.std::__1::__tree_end_node"* [ %6, %31 ], [ %21, %26 ]
  %34 = bitcast %"struct.std::__1::pair.43"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %34) #10
  %35 = getelementptr inbounds %"struct.std::__1::pair.43", %"struct.std::__1::pair.43"* %4, i64 0, i32 0
  store i32 %1, i32* %35, align 8
  %36 = getelementptr inbounds %"struct.std::__1::pair.43", %"struct.std::__1::pair.43"* %4, i64 0, i32 1
  store i64 %2, i64* %36, align 8
  %37 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %0, i64 0, i32 4, i32 0
  %38 = call { %"class.std::__1::__tree_end_node"*, i8 } @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE30__emplace_hint_unique_key_argsIiJNS_4pairIimEEEEENSB_INS_15__tree_iteratorIS2_PNS_11__tree_nodeIS2_PvEElEEbEENS_21__tree_const_iteratorIS2_SH_lEERKT_DpOT0_(%"class.std::__1::__tree"* %37, %"class.std::__1::__tree_end_node"* %33, i32* nonnull dereferenceable(4) %35, %"struct.std::__1::pair.43"* nonnull dereferenceable(16) %4) #9
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %34) #10
  call void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"* %5) #9
  ret void
}

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN2vk17TimelineSemaphoreD2Ev(%"class.vk::TimelineSemaphore"*) unnamed_addr #4 comdat align 2 {
  %2 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN2vk17TimelineSemaphoreE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 1
  tail call void @_ZNSt3__110shared_ptrIN2vk17TimelineSemaphore6SharedEED2Ev(%"class.std::__1::shared_ptr"* %3) #9
  ret void
}

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZN2vk17TimelineSemaphoreD0Ev(%"class.vk::TimelineSemaphore"*) unnamed_addr #4 comdat align 2 {
  %2 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN2vk17TimelineSemaphoreE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %"class.vk::TimelineSemaphore", %"class.vk::TimelineSemaphore"* %0, i64 0, i32 1
  tail call void @_ZNSt3__110shared_ptrIN2vk17TimelineSemaphore6SharedEED2Ev(%"class.std::__1::shared_ptr"* %3) #9
  %4 = bitcast %"class.vk::TimelineSemaphore"* %0 to i8*
  tail call void @_ZdlPv(i8* %4) #11
  ret void
}

; Function Attrs: optsize
declare void @_ZNSt3__15mutex4lockEv(%"class.std::__1::mutex"*) local_unnamed_addr #1

; Function Attrs: optsize
declare void @_ZN4marl9Scheduler5Fiber6notifyEv(%"class.marl::Scheduler::Fiber"*) local_unnamed_addr #1

; Function Attrs: nounwind optsize
declare void @_ZNSt3__118condition_variable10notify_allEv(%"class.std::__1::condition_variable"*) local_unnamed_addr #5

; Function Attrs: nounwind optsize
declare void @_ZNSt3__15mutex6unlockEv(%"class.std::__1::mutex"*) local_unnamed_addr #5

; Function Attrs: nobuiltin nounwind optsize
declare void @_ZdlPv(i8*) local_unnamed_addr #6

; Function Attrs: nounwind optsize
declare void @_ZNSt3__119__shared_weak_count14__release_weakEv(%"class.std::__1::__shared_weak_count"*) local_unnamed_addr #5

; Function Attrs: nobuiltin nofree optsize
declare noalias nonnull i8* @_Znwm(i64) local_unnamed_addr #7

; Function Attrs: nounwind optsize
declare void @_ZNSt3__119__shared_weak_countD2Ev(%"class.std::__1::__shared_weak_count"*) unnamed_addr #5

; Function Attrs: inlinehint nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_pointerIPN2vk17TimelineSemaphore6SharedEN4marl9Allocator7DeleterENS_9allocatorIS3_EEED0Ev(%"class.std::__1::__shared_ptr_pointer"*) unnamed_addr #4 comdat align 2 {
  %2 = getelementptr inbounds %"class.std::__1::__shared_ptr_pointer", %"class.std::__1::__shared_ptr_pointer"* %0, i64 0, i32 0
  tail call void @_ZNSt3__119__shared_weak_countD2Ev(%"class.std::__1::__shared_weak_count"* %2) #9
  %3 = bitcast %"class.std::__1::__shared_ptr_pointer"* %0 to i8*
  tail call void @_ZdlPv(i8* %3) #11
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_pointerIPN2vk17TimelineSemaphore6SharedEN4marl9Allocator7DeleterENS_9allocatorIS3_EEE16__on_zero_sharedEv(%"class.std::__1::__shared_ptr_pointer"*) unnamed_addr #0 comdat align 2 {
  %2 = alloca %"struct.marl::Allocation", align 8
  %3 = getelementptr inbounds %"class.std::__1::__shared_ptr_pointer", %"class.std::__1::__shared_ptr_pointer"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0
  %4 = load %"struct.vk::TimelineSemaphore::Shared"*, %"struct.vk::TimelineSemaphore::Shared"** %3, align 8
  %5 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %4, i64 0, i32 4, i32 0
  %6 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %4, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0
  %7 = bitcast %"class.std::__1::__tree_end_node"* %6 to %"class.std::__1::__tree_node"**
  %8 = load %"class.std::__1::__tree_node"*, %"class.std::__1::__tree_node"** %7, align 8
  tail call void @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE7destroyEPNS_11__tree_nodeIS2_PvEE(%"class.std::__1::__tree"* %5, %"class.std::__1::__tree_node"* %8) #9
  %9 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %4, i64 0, i32 3, i32 1
  %10 = load i64, i64* %9, align 8
  %11 = icmp eq i64 %10, 0
  br i1 %11, label %15, label %12

12:                                               ; preds = %1
  %13 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %4, i64 0, i32 3, i32 4
  %14 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %13 to %"class.std::__1::shared_ptr"**
  br label %20

15:                                               ; preds = %20, %1
  %16 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %4, i64 0, i32 3, i32 5
  %17 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %16, i64 0, i32 0
  %18 = load i8*, i8** %17, align 8
  %19 = icmp eq i8* %18, null
  br i1 %19, label %36, label %27

20:                                               ; preds = %20, %12
  %21 = phi i64 [ 0, %12 ], [ %24, %20 ]
  %22 = load %"class.std::__1::shared_ptr"*, %"class.std::__1::shared_ptr"** %14, align 8
  %23 = getelementptr inbounds %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr"* %22, i64 %21
  tail call void @_ZNSt3__110shared_ptrIN2vk17TimelineSemaphore6SharedEED2Ev(%"class.std::__1::shared_ptr"* %23) #9
  %24 = add nuw i64 %21, 1
  %25 = load i64, i64* %9, align 8
  %26 = icmp ult i64 %24, %25
  br i1 %26, label %20, label %15

27:                                               ; preds = %15
  %28 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %4, i64 0, i32 3, i32 0
  %29 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %28, align 8
  %30 = bitcast %"class.marl::Allocator"* %29 to void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)***
  %31 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)**, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*** %30, align 8
  %32 = getelementptr inbounds void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %31, i64 3
  %33 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %32, align 8
  tail call void %33(%"class.marl::Allocator"* %29, %"struct.marl::Allocation"* dereferenceable(32) %16) #9
  %34 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %4, i64 0, i32 3, i32 4
  %35 = bitcast %"struct.marl::aligned_storage<16, 8>::type"** %34 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %35, i8 0, i64 34, i1 false) #10
  br label %36

36:                                               ; preds = %27, %15
  %37 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %4, i64 0, i32 1, i32 2
  tail call void @_ZNSt3__118condition_variableD1Ev(%"class.std::__1::condition_variable"* %37) #9
  %38 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %4, i64 0, i32 1, i32 1, i32 5
  br label %39

39:                                               ; preds = %39, %36
  %40 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** [ %38, %36 ], [ %43, %39 ]
  %41 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"** %40, align 8
  %42 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %41, null
  %43 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* %41, i64 0, i32 1
  br i1 %42, label %44, label %39

44:                                               ; preds = %39
  %45 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %4, i64 0, i32 1, i32 1, i32 3
  %46 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %45, align 8
  %47 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %46, null
  br i1 %47, label %61, label %48

48:                                               ; preds = %44
  %49 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %4, i64 0, i32 1, i32 1, i32 0
  br label %50

50:                                               ; preds = %50, %48
  %51 = phi %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* [ %46, %48 ], [ %53, %50 ]
  %52 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %51, i64 0, i32 1
  %53 = load %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"** %52, align 8
  %54 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %49, align 8
  %55 = getelementptr inbounds %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %51, i64 0, i32 0
  %56 = bitcast %"class.marl::Allocator"* %54 to void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)***
  %57 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)**, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*** %56, align 8
  %58 = getelementptr inbounds void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %57, i64 3
  %59 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %58, align 8
  tail call void %59(%"class.marl::Allocator"* %54, %"struct.marl::Allocation"* dereferenceable(32) %55) #9
  %60 = icmp eq %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* %53, null
  br i1 %60, label %61, label %50

61:                                               ; preds = %50, %44
  %62 = bitcast %"struct.marl::Allocation"* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %62) #10
  %63 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %2, i64 0, i32 1, i32 0
  %64 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %2, i64 0, i32 1, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %62, i8 -86, i64 32, i1 false) #10
  %65 = getelementptr inbounds %"struct.marl::Allocation", %"struct.marl::Allocation"* %2, i64 0, i32 1, i32 2
  %66 = bitcast i8* %65 to i16*
  store i16 512, i16* %66, align 8
  %67 = bitcast %"struct.marl::Allocation"* %2 to %"struct.vk::TimelineSemaphore::Shared"**
  store %"struct.vk::TimelineSemaphore::Shared"* %4, %"struct.vk::TimelineSemaphore::Shared"** %67, align 8
  %68 = getelementptr inbounds %"class.std::__1::__shared_ptr_pointer", %"class.std::__1::__shared_ptr_pointer"* %0, i64 0, i32 1, i32 0, i32 0, i32 1, i32 0, i32 1
  %69 = load i64, i64* %68, align 8
  %70 = mul i64 %69, 304
  store i64 %70, i64* %63, align 8
  store i64 8, i64* %64, align 8
  %71 = getelementptr inbounds %"class.std::__1::__shared_ptr_pointer", %"class.std::__1::__shared_ptr_pointer"* %0, i64 0, i32 1, i32 0, i32 0, i32 1, i32 0, i32 0
  %72 = load %"class.marl::Allocator"*, %"class.marl::Allocator"** %71, align 8
  %73 = bitcast %"class.marl::Allocator"* %72 to void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)***
  %74 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)**, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*** %73, align 8
  %75 = getelementptr inbounds void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %74, i64 3
  %76 = load void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)*, void (%"class.marl::Allocator"*, %"struct.marl::Allocation"*)** %75, align 8
  call void %76(%"class.marl::Allocator"* %72, %"struct.marl::Allocation"* nonnull dereferenceable(32) %2) #9
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %62) #10
  ret void
}

; Function Attrs: nounwind optsize
declare i8* @_ZNKSt3__119__shared_weak_count13__get_deleterERKSt9type_info(%"class.std::__1::__shared_weak_count"*, %"class.std::type_info"* dereferenceable(16)) unnamed_addr #5

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__120__shared_ptr_pointerIPN2vk17TimelineSemaphore6SharedEN4marl9Allocator7DeleterENS_9allocatorIS3_EEE21__on_zero_shared_weakEv(%"class.std::__1::__shared_ptr_pointer"*) unnamed_addr #0 comdat align 2 {
  %2 = bitcast %"class.std::__1::__shared_ptr_pointer"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #11
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE7destroyEPNS_11__tree_nodeIS2_PvEE(%"class.std::__1::__tree"*, %"class.std::__1::__tree_node"*) local_unnamed_addr #0 comdat align 2 {
  %3 = icmp eq %"class.std::__1::__tree_node"* %1, null
  br i1 %3, label %11, label %4

4:                                                ; preds = %2
  %5 = bitcast %"class.std::__1::__tree_node"* %1 to %"class.std::__1::__tree_node"**
  %6 = load %"class.std::__1::__tree_node"*, %"class.std::__1::__tree_node"** %5, align 8
  tail call void @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE7destroyEPNS_11__tree_nodeIS2_PvEE(%"class.std::__1::__tree"* %0, %"class.std::__1::__tree_node"* %6) #9
  %7 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %1, i64 0, i32 0, i32 1
  %8 = bitcast %"class.std::__1::__tree_node_base"** %7 to %"class.std::__1::__tree_node"**
  %9 = load %"class.std::__1::__tree_node"*, %"class.std::__1::__tree_node"** %8, align 8
  tail call void @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE7destroyEPNS_11__tree_nodeIS2_PvEE(%"class.std::__1::__tree"* %0, %"class.std::__1::__tree_node"* %9) #9
  %10 = bitcast %"class.std::__1::__tree_node"* %1 to i8*
  tail call void @_ZdlPv(i8* %10) #11
  ret void

11:                                               ; preds = %2
  ret void
}

; Function Attrs: nounwind optsize
declare void @_ZNSt3__118condition_variableD1Ev(%"class.std::__1::condition_variable"*) unnamed_addr #5

; Function Attrs: optsize
declare %"class.marl::Scheduler::Fiber"* @_ZN4marl9Scheduler5Fiber7currentEv() local_unnamed_addr #1

; Function Attrs: optsize
declare void @_ZN4marl9Scheduler5Fiber4waitERNS_4lockERKNSt3__18functionIFbvEEE(%"class.marl::Scheduler::Fiber"*, %"class.marl::lock"* dereferenceable(16), %"class.std::__1::function.164"* dereferenceable(32)) local_unnamed_addr #1

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define internal zeroext i1 @"_ZNSt3__110__function16__policy_invokerIFbvEE11__call_implINS0_20__default_alloc_funcIZN2vk17TimelineSemaphore6Shared4waitEmE3$_0S2_EEEEbPKNS0_16__policy_storageE"(%"union.std::__1::__function::__policy_storage"* nocapture readonly) #8 align 2 {
  %2 = bitcast %"union.std::__1::__function::__policy_storage"* %0 to %"struct.vk::TimelineSemaphore::Shared"**
  %3 = load %"struct.vk::TimelineSemaphore::Shared"*, %"struct.vk::TimelineSemaphore::Shared"** %2, align 8
  %4 = getelementptr inbounds %"struct.vk::TimelineSemaphore::Shared", %"struct.vk::TimelineSemaphore::Shared"* %3, i64 0, i32 2
  %5 = load i64, i64* %4, align 8
  %6 = getelementptr inbounds %"union.std::__1::__function::__policy_storage", %"union.std::__1::__function::__policy_storage"* %0, i64 0, i32 1
  %7 = bitcast [8 x i8]* %6 to i64**
  %8 = load i64*, i64** %7, align 8
  %9 = load i64, i64* %8, align 8
  %10 = icmp eq i64 %5, %9
  ret i1 %10
}

; Function Attrs: nounwind optsize
declare void @_ZNSt3__118condition_variable4waitERNS_11unique_lockINS_5mutexEEE(%"class.std::__1::condition_variable"*, %"class.std::__1::unique_lock"* dereferenceable(16)) local_unnamed_addr #5

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden { %"class.std::__1::__tree_end_node"*, i8 } @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE30__emplace_hint_unique_key_argsIiJNS_4pairIimEEEEENSB_INS_15__tree_iteratorIS2_PNS_11__tree_nodeIS2_PvEElEEbEENS_21__tree_const_iteratorIS2_SH_lEERKT_DpOT0_(%"class.std::__1::__tree"*, %"class.std::__1::__tree_end_node"*, i32* dereferenceable(4), %"struct.std::__1::pair.43"* dereferenceable(16)) local_unnamed_addr #0 comdat align 2 {
  %5 = alloca %"class.std::__1::__tree_end_node"*, align 8
  %6 = alloca %"class.std::__1::__tree_node_base"*, align 8
  %7 = bitcast %"class.std::__1::__tree_end_node"** %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %7) #10
  store %"class.std::__1::__tree_end_node"* inttoptr (i64 -6148914691236517206 to %"class.std::__1::__tree_end_node"*), %"class.std::__1::__tree_end_node"** %5, align 8
  %8 = bitcast %"class.std::__1::__tree_node_base"** %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %8) #10
  store %"class.std::__1::__tree_node_base"* inttoptr (i64 -6148914691236517206 to %"class.std::__1::__tree_node_base"*), %"class.std::__1::__tree_node_base"** %6, align 8
  %9 = call dereferenceable(8) %"class.std::__1::__tree_node_base"** @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE12__find_equalIiEERPNS_16__tree_node_baseIPvEENS_21__tree_const_iteratorIS2_PNS_11__tree_nodeIS2_SC_EElEERPNS_15__tree_end_nodeISE_EESF_RKT_(%"class.std::__1::__tree"* %0, %"class.std::__1::__tree_end_node"* %1, %"class.std::__1::__tree_end_node"** nonnull dereferenceable(8) %5, %"class.std::__1::__tree_node_base"** nonnull dereferenceable(8) %6, i32* dereferenceable(4) %2) #12
  %10 = bitcast %"class.std::__1::__tree_node_base"** %9 to %"class.std::__1::__tree_node"**
  %11 = load %"class.std::__1::__tree_node"*, %"class.std::__1::__tree_node"** %10, align 8
  %12 = icmp eq %"class.std::__1::__tree_node"* %11, null
  br i1 %12, label %13, label %26

13:                                               ; preds = %4
  %14 = call i8* @_Znwm(i64 48) #11, !noalias !3
  %15 = getelementptr inbounds i8, i8* %14, i64 32
  %16 = bitcast i8* %15 to i32*
  %17 = getelementptr inbounds %"struct.std::__1::pair.43", %"struct.std::__1::pair.43"* %3, i64 0, i32 0
  %18 = load i32, i32* %17, align 4, !noalias !3
  store i32 %18, i32* %16, align 8, !noalias !3
  %19 = getelementptr inbounds i8, i8* %14, i64 40
  %20 = bitcast i8* %19 to i64*
  %21 = getelementptr inbounds %"struct.std::__1::pair.43", %"struct.std::__1::pair.43"* %3, i64 0, i32 1
  %22 = load i64, i64* %21, align 8, !noalias !3
  store i64 %22, i64* %20, align 8, !noalias !3
  %23 = load %"class.std::__1::__tree_end_node"*, %"class.std::__1::__tree_end_node"** %5, align 8
  %24 = bitcast i8* %14 to %"class.std::__1::__tree_node"*
  %25 = bitcast i8* %14 to %"class.std::__1::__tree_node_base"*
  call void @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE16__insert_node_atEPNS_15__tree_end_nodeIPNS_16__tree_node_baseIPvEEEERSE_SE_(%"class.std::__1::__tree"* %0, %"class.std::__1::__tree_end_node"* %23, %"class.std::__1::__tree_node_base"** dereferenceable(8) %9, %"class.std::__1::__tree_node_base"* nonnull %25) #9
  br label %26

26:                                               ; preds = %13, %4
  %27 = phi i8 [ 1, %13 ], [ 0, %4 ]
  %28 = phi %"class.std::__1::__tree_node"* [ %24, %13 ], [ %11, %4 ]
  %29 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %28, i64 0, i32 0, i32 0
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %8) #10
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %7) #10
  %30 = insertvalue { %"class.std::__1::__tree_end_node"*, i8 } undef, %"class.std::__1::__tree_end_node"* %29, 0
  %31 = insertvalue { %"class.std::__1::__tree_end_node"*, i8 } %30, i8 %27, 1
  ret { %"class.std::__1::__tree_end_node"*, i8 } %31
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden dereferenceable(8) %"class.std::__1::__tree_node_base"** @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE12__find_equalIiEERPNS_16__tree_node_baseIPvEENS_21__tree_const_iteratorIS2_PNS_11__tree_nodeIS2_SC_EElEERPNS_15__tree_end_nodeISE_EESF_RKT_(%"class.std::__1::__tree"*, %"class.std::__1::__tree_end_node"*, %"class.std::__1::__tree_end_node"** dereferenceable(8), %"class.std::__1::__tree_node_base"** dereferenceable(8), i32* dereferenceable(4)) local_unnamed_addr #0 comdat align 2 {
  %6 = ptrtoint %"class.std::__1::__tree_end_node"* %1 to i64
  %7 = getelementptr inbounds %"class.std::__1::__tree", %"class.std::__1::__tree"* %0, i64 0, i32 1, i32 0, i32 0
  %8 = icmp eq %"class.std::__1::__tree_end_node"* %7, %1
  br i1 %8, label %15, label %9

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %1, i64 4
  %11 = bitcast %"class.std::__1::__tree_end_node"* %10 to i32*
  %12 = load i32, i32* %4, align 4
  %13 = load i32, i32* %11, align 4
  %14 = icmp slt i32 %12, %13
  br i1 %14, label %15, label %58

15:                                               ; preds = %5, %9
  %16 = getelementptr inbounds %"class.std::__1::__tree", %"class.std::__1::__tree"* %0, i64 0, i32 0
  %17 = load %"class.std::__1::__tree_end_node"*, %"class.std::__1::__tree_end_node"** %16, align 8
  %18 = icmp eq %"class.std::__1::__tree_end_node"* %17, %1
  %19 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %1, i64 0, i32 0
  %20 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %19, align 8
  br i1 %18, label %47, label %21

21:                                               ; preds = %15
  %22 = icmp eq %"class.std::__1::__tree_node_base"* %20, null
  br i1 %22, label %28, label %23

23:                                               ; preds = %21, %23
  %24 = phi %"class.std::__1::__tree_node_base"* [ %26, %23 ], [ %20, %21 ]
  %25 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %24, i64 0, i32 1
  %26 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %25, align 8
  %27 = icmp eq %"class.std::__1::__tree_node_base"* %26, null
  br i1 %27, label %39, label %23

28:                                               ; preds = %21, %28
  %29 = phi %"class.std::__1::__tree_end_node"* [ %33, %28 ], [ %1, %21 ]
  %30 = bitcast %"class.std::__1::__tree_end_node"* %29 to %"class.std::__1::__tree_node_base"*
  %31 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %29, i64 2
  %32 = bitcast %"class.std::__1::__tree_end_node"* %31 to %"class.std::__1::__tree_end_node"**
  %33 = load %"class.std::__1::__tree_end_node"*, %"class.std::__1::__tree_end_node"** %32, align 8
  %34 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %33, i64 0, i32 0
  %35 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %34, align 8
  %36 = icmp eq %"class.std::__1::__tree_node_base"* %35, %30
  br i1 %36, label %28, label %37

37:                                               ; preds = %28
  %38 = bitcast %"class.std::__1::__tree_end_node"* %33 to %"class.std::__1::__tree_node_base"*
  br label %39

39:                                               ; preds = %23, %37
  %40 = phi %"class.std::__1::__tree_node_base"* [ %38, %37 ], [ %24, %23 ]
  %41 = ptrtoint %"class.std::__1::__tree_node_base"* %40 to i64
  %42 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %40, i64 1
  %43 = bitcast %"class.std::__1::__tree_node_base"* %42 to i32*
  %44 = load i32, i32* %43, align 4
  %45 = load i32, i32* %4, align 4
  %46 = icmp slt i32 %44, %45
  br i1 %46, label %47, label %56

47:                                               ; preds = %15, %39
  %48 = phi i64 [ %41, %39 ], [ %6, %15 ]
  %49 = icmp eq %"class.std::__1::__tree_node_base"* %20, null
  br i1 %49, label %50, label %52

50:                                               ; preds = %47
  %51 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %1, i64 0, i32 0
  store %"class.std::__1::__tree_end_node"* %1, %"class.std::__1::__tree_end_node"** %2, align 8
  br label %106

52:                                               ; preds = %47
  %53 = bitcast %"class.std::__1::__tree_end_node"** %2 to i64*
  store i64 %48, i64* %53, align 8
  %54 = inttoptr i64 %48 to %"class.std::__1::__tree_node_base"*
  %55 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %54, i64 0, i32 1
  br label %106

56:                                               ; preds = %39
  %57 = tail call dereferenceable(8) %"class.std::__1::__tree_node_base"** @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE12__find_equalIiEERPNS_16__tree_node_baseIPvEERPNS_15__tree_end_nodeISE_EERKT_(%"class.std::__1::__tree"* %0, %"class.std::__1::__tree_end_node"** dereferenceable(8) %2, i32* dereferenceable(4) %4) #12
  br label %106

58:                                               ; preds = %9
  %59 = icmp slt i32 %13, %12
  br i1 %59, label %60, label %103

60:                                               ; preds = %58
  %61 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %1, i64 1, i32 0
  %62 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %61, align 8
  %63 = icmp eq %"class.std::__1::__tree_node_base"* %62, null
  br i1 %63, label %64, label %72

64:                                               ; preds = %60
  %65 = bitcast %"class.std::__1::__tree_end_node"* %1 to %"class.std::__1::__tree_node_base"*
  %66 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %1, i64 2
  %67 = bitcast %"class.std::__1::__tree_end_node"* %66 to %"class.std::__1::__tree_end_node"**
  %68 = load %"class.std::__1::__tree_end_node"*, %"class.std::__1::__tree_end_node"** %67, align 8
  %69 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %68, i64 0, i32 0
  %70 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %69, align 8
  %71 = icmp eq %"class.std::__1::__tree_node_base"* %70, %65
  br i1 %71, label %88, label %79

72:                                               ; preds = %60, %72
  %73 = phi %"class.std::__1::__tree_node_base"* [ %75, %72 ], [ %62, %60 ]
  %74 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %73, i64 0, i32 0, i32 0
  %75 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %74, align 8
  %76 = icmp eq %"class.std::__1::__tree_node_base"* %75, null
  br i1 %76, label %77, label %72

77:                                               ; preds = %72
  %78 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %73, i64 0, i32 0
  br label %88

79:                                               ; preds = %64, %79
  %80 = phi %"class.std::__1::__tree_end_node"** [ %83, %79 ], [ %67, %64 ]
  %81 = bitcast %"class.std::__1::__tree_end_node"** %80 to %"class.std::__1::__tree_node_base"**
  %82 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %81, align 8
  %83 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %82, i64 0, i32 2
  %84 = load %"class.std::__1::__tree_end_node"*, %"class.std::__1::__tree_end_node"** %83, align 8
  %85 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %84, i64 0, i32 0
  %86 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %85, align 8
  %87 = icmp eq %"class.std::__1::__tree_node_base"* %86, %82
  br i1 %87, label %88, label %79

88:                                               ; preds = %79, %64, %77
  %89 = phi %"class.std::__1::__tree_end_node"* [ %78, %77 ], [ %68, %64 ], [ %84, %79 ]
  %90 = icmp eq %"class.std::__1::__tree_end_node"* %89, %7
  br i1 %90, label %96, label %91

91:                                               ; preds = %88
  %92 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %89, i64 4
  %93 = bitcast %"class.std::__1::__tree_end_node"* %92 to i32*
  %94 = load i32, i32* %93, align 4
  %95 = icmp slt i32 %12, %94
  br i1 %95, label %96, label %101

96:                                               ; preds = %88, %91
  br i1 %63, label %97, label %99

97:                                               ; preds = %96
  %98 = bitcast %"class.std::__1::__tree_end_node"** %2 to i64*
  store i64 %6, i64* %98, align 8
  br label %106

99:                                               ; preds = %96
  store %"class.std::__1::__tree_end_node"* %89, %"class.std::__1::__tree_end_node"** %2, align 8
  %100 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %89, i64 0, i32 0
  br label %106

101:                                              ; preds = %91
  %102 = tail call dereferenceable(8) %"class.std::__1::__tree_node_base"** @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE12__find_equalIiEERPNS_16__tree_node_baseIPvEERPNS_15__tree_end_nodeISE_EERKT_(%"class.std::__1::__tree"* %0, %"class.std::__1::__tree_end_node"** dereferenceable(8) %2, i32* dereferenceable(4) %4) #12
  br label %106

103:                                              ; preds = %58
  %104 = bitcast %"class.std::__1::__tree_end_node"** %2 to i64*
  store i64 %6, i64* %104, align 8
  %105 = bitcast %"class.std::__1::__tree_node_base"** %3 to i64*
  store i64 %6, i64* %105, align 8
  br label %106

106:                                              ; preds = %97, %99, %101, %50, %52, %56, %103
  %107 = phi %"class.std::__1::__tree_node_base"** [ %3, %103 ], [ %51, %50 ], [ %55, %52 ], [ %57, %56 ], [ %61, %97 ], [ %100, %99 ], [ %102, %101 ]
  ret %"class.std::__1::__tree_node_base"** %107
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE16__insert_node_atEPNS_15__tree_end_nodeIPNS_16__tree_node_baseIPvEEEERSE_SE_(%"class.std::__1::__tree"*, %"class.std::__1::__tree_end_node"*, %"class.std::__1::__tree_node_base"** dereferenceable(8), %"class.std::__1::__tree_node_base"*) local_unnamed_addr #0 comdat align 2 {
  %5 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %3, i64 0, i32 2
  %6 = bitcast %"class.std::__1::__tree_node_base"* %3 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %6, i8 0, i64 16, i1 false)
  store %"class.std::__1::__tree_end_node"* %1, %"class.std::__1::__tree_end_node"** %5, align 8
  store %"class.std::__1::__tree_node_base"* %3, %"class.std::__1::__tree_node_base"** %2, align 8
  %7 = getelementptr inbounds %"class.std::__1::__tree", %"class.std::__1::__tree"* %0, i64 0, i32 0
  %8 = load %"class.std::__1::__tree_end_node"*, %"class.std::__1::__tree_end_node"** %7, align 8
  %9 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %8, i64 0, i32 0
  %10 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %9, align 8
  %11 = icmp eq %"class.std::__1::__tree_node_base"* %10, null
  br i1 %11, label %16, label %12

12:                                               ; preds = %4
  %13 = ptrtoint %"class.std::__1::__tree_node_base"* %10 to i64
  %14 = bitcast %"class.std::__1::__tree"* %0 to i64*
  store i64 %13, i64* %14, align 8
  %15 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %2, align 8
  br label %16

16:                                               ; preds = %4, %12
  %17 = phi %"class.std::__1::__tree_node_base"* [ %3, %4 ], [ %15, %12 ]
  %18 = getelementptr inbounds %"class.std::__1::__tree", %"class.std::__1::__tree"* %0, i64 0, i32 1, i32 0, i32 0, i32 0
  %19 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %18, align 8
  tail call void @_ZNSt3__127__tree_balance_after_insertIPNS_16__tree_node_baseIPvEEEEvT_S5_(%"class.std::__1::__tree_node_base"* %19, %"class.std::__1::__tree_node_base"* %17) #9
  %20 = getelementptr inbounds %"class.std::__1::__tree", %"class.std::__1::__tree"* %0, i64 0, i32 2, i32 0, i32 0
  %21 = load i64, i64* %20, align 8
  %22 = add i64 %21, 1
  store i64 %22, i64* %20, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden dereferenceable(8) %"class.std::__1::__tree_node_base"** @_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE12__find_equalIiEERPNS_16__tree_node_baseIPvEERPNS_15__tree_end_nodeISE_EERKT_(%"class.std::__1::__tree"*, %"class.std::__1::__tree_end_node"** dereferenceable(8), i32* dereferenceable(4)) local_unnamed_addr #0 comdat align 2 {
  %4 = getelementptr inbounds %"class.std::__1::__tree", %"class.std::__1::__tree"* %0, i64 0, i32 1, i32 0, i32 0
  %5 = bitcast %"class.std::__1::__tree_end_node"* %4 to %"class.std::__1::__tree_node"**
  %6 = load %"class.std::__1::__tree_node"*, %"class.std::__1::__tree_node"** %5, align 8
  %7 = icmp eq %"class.std::__1::__tree_node"* %6, null
  br i1 %7, label %37, label %8

8:                                                ; preds = %3
  %9 = getelementptr inbounds %"class.std::__1::__tree", %"class.std::__1::__tree"* %0, i64 0, i32 1, i32 0, i32 0, i32 0
  %10 = load i32, i32* %2, align 4
  br label %11

11:                                               ; preds = %8, %33
  %12 = phi %"class.std::__1::__tree_node"* [ %36, %33 ], [ %6, %8 ]
  %13 = phi %"class.std::__1::__tree_node_base"** [ %35, %33 ], [ %9, %8 ]
  %14 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %12, i64 0, i32 1, i32 0, i32 0
  %15 = load i32, i32* %14, align 4
  %16 = icmp slt i32 %10, %15
  br i1 %16, label %17, label %23

17:                                               ; preds = %11
  %18 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %12, i64 0, i32 0, i32 0, i32 0
  %19 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %18, align 8
  %20 = icmp eq %"class.std::__1::__tree_node_base"* %19, null
  br i1 %20, label %21, label %33

21:                                               ; preds = %17
  %22 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %12, i64 0, i32 0, i32 0
  store %"class.std::__1::__tree_end_node"* %22, %"class.std::__1::__tree_end_node"** %1, align 8
  br label %39

23:                                               ; preds = %11
  %24 = icmp slt i32 %15, %10
  br i1 %24, label %25, label %31

25:                                               ; preds = %23
  %26 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %12, i64 0, i32 0, i32 1
  %27 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %26, align 8
  %28 = icmp eq %"class.std::__1::__tree_node_base"* %27, null
  br i1 %28, label %29, label %33

29:                                               ; preds = %25
  %30 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %12, i64 0, i32 0, i32 0
  store %"class.std::__1::__tree_end_node"* %30, %"class.std::__1::__tree_end_node"** %1, align 8
  br label %39

31:                                               ; preds = %23
  %32 = getelementptr inbounds %"class.std::__1::__tree_node", %"class.std::__1::__tree_node"* %12, i64 0, i32 0, i32 0
  store %"class.std::__1::__tree_end_node"* %32, %"class.std::__1::__tree_end_node"** %1, align 8
  br label %39

33:                                               ; preds = %25, %17
  %34 = phi %"class.std::__1::__tree_node_base"* [ %19, %17 ], [ %27, %25 ]
  %35 = phi %"class.std::__1::__tree_node_base"** [ %18, %17 ], [ %26, %25 ]
  %36 = bitcast %"class.std::__1::__tree_node_base"* %34 to %"class.std::__1::__tree_node"*
  br label %11

37:                                               ; preds = %3
  store %"class.std::__1::__tree_end_node"* %4, %"class.std::__1::__tree_end_node"** %1, align 8
  %38 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %4, i64 0, i32 0
  br label %39

39:                                               ; preds = %37, %31, %29, %21
  %40 = phi %"class.std::__1::__tree_node_base"** [ %18, %21 ], [ %26, %29 ], [ %13, %31 ], [ %38, %37 ]
  ret %"class.std::__1::__tree_node_base"** %40
}

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__127__tree_balance_after_insertIPNS_16__tree_node_baseIPvEEEEvT_S5_(%"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"*) local_unnamed_addr #0 comdat {
  %3 = icmp eq %"class.std::__1::__tree_node_base"* %1, %0
  %4 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %1, i64 0, i32 3
  %5 = zext i1 %3 to i8
  store i8 %5, i8* %4, align 8
  br i1 %3, label %156, label %6

6:                                                ; preds = %2, %149
  %7 = phi %"class.std::__1::__tree_node_base"* [ %20, %149 ], [ %1, %2 ]
  %8 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %7, i64 0, i32 2
  %9 = bitcast %"class.std::__1::__tree_end_node"** %8 to %"class.std::__1::__tree_node_base"**
  %10 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %9, align 8
  %11 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %10, i64 0, i32 3
  %12 = load i8, i8* %11, align 8, !range !2
  %13 = icmp eq i8 %12, 0
  br i1 %13, label %14, label %156

14:                                               ; preds = %6
  %15 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %10, i64 0, i32 2
  %16 = load %"class.std::__1::__tree_end_node"*, %"class.std::__1::__tree_end_node"** %15, align 8
  %17 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %16, i64 0, i32 0
  %18 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %17, align 8
  %19 = icmp eq %"class.std::__1::__tree_node_base"* %18, %10
  %20 = bitcast %"class.std::__1::__tree_end_node"* %16 to %"class.std::__1::__tree_node_base"*
  br i1 %19, label %21, label %87

21:                                               ; preds = %14
  %22 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %16, i64 1, i32 0
  %23 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %22, align 8
  %24 = icmp eq %"class.std::__1::__tree_node_base"* %23, null
  br i1 %24, label %29, label %25

25:                                               ; preds = %21
  %26 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %23, i64 0, i32 3
  %27 = load i8, i8* %26, align 8, !range !2
  %28 = icmp eq i8 %27, 0
  br i1 %28, label %149, label %29

29:                                               ; preds = %25, %21
  %30 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %10, i64 0, i32 2
  %31 = bitcast %"class.std::__1::__tree_end_node"* %16 to %"class.std::__1::__tree_node_base"*
  %32 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %10, i64 0, i32 0, i32 0
  %33 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %32, align 8
  %34 = icmp eq %"class.std::__1::__tree_node_base"* %33, %7
  br i1 %34, label %61, label %35

35:                                               ; preds = %29
  %36 = ptrtoint %"class.std::__1::__tree_end_node"* %16 to i64
  %37 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %10, i64 0, i32 1
  %38 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %37, align 8
  %39 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %38, i64 0, i32 0, i32 0
  %40 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %39, align 8
  store %"class.std::__1::__tree_node_base"* %40, %"class.std::__1::__tree_node_base"** %37, align 8
  %41 = icmp eq %"class.std::__1::__tree_node_base"* %40, null
  br i1 %41, label %47, label %42

42:                                               ; preds = %35
  %43 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %10, i64 0, i32 0
  %44 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %40, i64 0, i32 2
  store %"class.std::__1::__tree_end_node"* %43, %"class.std::__1::__tree_end_node"** %44, align 8
  %45 = bitcast %"class.std::__1::__tree_end_node"** %30 to i64*
  %46 = load i64, i64* %45, align 8
  br label %47

47:                                               ; preds = %35, %42
  %48 = phi i64 [ %46, %42 ], [ %36, %35 ]
  %49 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %38, i64 0, i32 2
  %50 = bitcast %"class.std::__1::__tree_end_node"** %49 to i64*
  store i64 %48, i64* %50, align 8
  %51 = load %"class.std::__1::__tree_end_node"*, %"class.std::__1::__tree_end_node"** %30, align 8
  %52 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %51, i64 0, i32 0
  %53 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %52, align 8
  %54 = icmp eq %"class.std::__1::__tree_node_base"* %53, %10
  %55 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %51, i64 1, i32 0
  %56 = select i1 %54, %"class.std::__1::__tree_node_base"** %52, %"class.std::__1::__tree_node_base"** %55
  store %"class.std::__1::__tree_node_base"* %38, %"class.std::__1::__tree_node_base"** %56, align 8
  store %"class.std::__1::__tree_node_base"* %10, %"class.std::__1::__tree_node_base"** %39, align 8
  %57 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %38, i64 0, i32 0
  store %"class.std::__1::__tree_end_node"* %57, %"class.std::__1::__tree_end_node"** %30, align 8
  %58 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %38, i64 0, i32 2
  %59 = bitcast %"class.std::__1::__tree_end_node"** %58 to %"class.std::__1::__tree_node_base"**
  %60 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %59, align 8
  br label %61

61:                                               ; preds = %47, %29
  %62 = phi %"class.std::__1::__tree_node_base"* [ %31, %29 ], [ %60, %47 ]
  %63 = phi %"class.std::__1::__tree_node_base"* [ %10, %29 ], [ %38, %47 ]
  %64 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %63, i64 0, i32 3
  store i8 1, i8* %64, align 8
  %65 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %62, i64 0, i32 3
  store i8 0, i8* %65, align 8
  %66 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %62, i64 0, i32 0, i32 0
  %67 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %66, align 8
  %68 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %67, i64 0, i32 1
  %69 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %68, align 8
  store %"class.std::__1::__tree_node_base"* %69, %"class.std::__1::__tree_node_base"** %66, align 8
  %70 = icmp eq %"class.std::__1::__tree_node_base"* %69, null
  br i1 %70, label %74, label %71

71:                                               ; preds = %61
  %72 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %62, i64 0, i32 0
  %73 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %69, i64 0, i32 2
  store %"class.std::__1::__tree_end_node"* %72, %"class.std::__1::__tree_end_node"** %73, align 8
  br label %74

74:                                               ; preds = %71, %61
  %75 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %62, i64 0, i32 2
  %76 = bitcast %"class.std::__1::__tree_end_node"** %75 to i64*
  %77 = load i64, i64* %76, align 8
  %78 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %67, i64 0, i32 2
  %79 = bitcast %"class.std::__1::__tree_end_node"** %78 to i64*
  store i64 %77, i64* %79, align 8
  %80 = load %"class.std::__1::__tree_end_node"*, %"class.std::__1::__tree_end_node"** %75, align 8
  %81 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %80, i64 0, i32 0
  %82 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %81, align 8
  %83 = icmp eq %"class.std::__1::__tree_node_base"* %82, %62
  %84 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %80, i64 1, i32 0
  %85 = select i1 %83, %"class.std::__1::__tree_node_base"** %81, %"class.std::__1::__tree_node_base"** %84
  store %"class.std::__1::__tree_node_base"* %67, %"class.std::__1::__tree_node_base"** %85, align 8
  store %"class.std::__1::__tree_node_base"* %62, %"class.std::__1::__tree_node_base"** %68, align 8
  %86 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %67, i64 0, i32 0
  store %"class.std::__1::__tree_end_node"* %86, %"class.std::__1::__tree_end_node"** %75, align 8
  br label %156

87:                                               ; preds = %14
  %88 = icmp eq %"class.std::__1::__tree_node_base"* %18, null
  br i1 %88, label %93, label %89

89:                                               ; preds = %87
  %90 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %18, i64 0, i32 3
  %91 = load i8, i8* %90, align 8, !range !2
  %92 = icmp eq i8 %91, 0
  br i1 %92, label %149, label %93

93:                                               ; preds = %89, %87
  %94 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %10, i64 0, i32 2
  %95 = bitcast %"class.std::__1::__tree_end_node"* %16 to %"class.std::__1::__tree_node_base"*
  %96 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %10, i64 0, i32 0, i32 0
  %97 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %96, align 8
  %98 = icmp eq %"class.std::__1::__tree_node_base"* %97, %7
  br i1 %98, label %99, label %123

99:                                               ; preds = %93
  %100 = ptrtoint %"class.std::__1::__tree_end_node"* %16 to i64
  %101 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %10, i64 0, i32 0, i32 0
  %102 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %7, i64 0, i32 1
  %103 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %102, align 8
  store %"class.std::__1::__tree_node_base"* %103, %"class.std::__1::__tree_node_base"** %101, align 8
  %104 = icmp eq %"class.std::__1::__tree_node_base"* %103, null
  br i1 %104, label %110, label %105

105:                                              ; preds = %99
  %106 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %10, i64 0, i32 0
  %107 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %103, i64 0, i32 2
  store %"class.std::__1::__tree_end_node"* %106, %"class.std::__1::__tree_end_node"** %107, align 8
  %108 = bitcast %"class.std::__1::__tree_end_node"** %94 to i64*
  %109 = load i64, i64* %108, align 8
  br label %110

110:                                              ; preds = %99, %105
  %111 = phi i64 [ %109, %105 ], [ %100, %99 ]
  %112 = bitcast %"class.std::__1::__tree_end_node"** %8 to i64*
  store i64 %111, i64* %112, align 8
  %113 = load %"class.std::__1::__tree_end_node"*, %"class.std::__1::__tree_end_node"** %94, align 8
  %114 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %113, i64 0, i32 0
  %115 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %114, align 8
  %116 = icmp eq %"class.std::__1::__tree_node_base"* %115, %10
  %117 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %113, i64 1, i32 0
  %118 = select i1 %116, %"class.std::__1::__tree_node_base"** %114, %"class.std::__1::__tree_node_base"** %117
  store %"class.std::__1::__tree_node_base"* %7, %"class.std::__1::__tree_node_base"** %118, align 8
  store %"class.std::__1::__tree_node_base"* %10, %"class.std::__1::__tree_node_base"** %102, align 8
  %119 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %7, i64 0, i32 0
  store %"class.std::__1::__tree_end_node"* %119, %"class.std::__1::__tree_end_node"** %94, align 8
  %120 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %7, i64 0, i32 2
  %121 = bitcast %"class.std::__1::__tree_end_node"** %120 to %"class.std::__1::__tree_node_base"**
  %122 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %121, align 8
  br label %123

123:                                              ; preds = %93, %110
  %124 = phi %"class.std::__1::__tree_node_base"* [ %122, %110 ], [ %95, %93 ]
  %125 = phi %"class.std::__1::__tree_node_base"* [ %7, %110 ], [ %10, %93 ]
  %126 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %125, i64 0, i32 3
  store i8 1, i8* %126, align 8
  %127 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %124, i64 0, i32 3
  store i8 0, i8* %127, align 8
  %128 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %124, i64 0, i32 1
  %129 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %128, align 8
  %130 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %129, i64 0, i32 0, i32 0
  %131 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %130, align 8
  store %"class.std::__1::__tree_node_base"* %131, %"class.std::__1::__tree_node_base"** %128, align 8
  %132 = icmp eq %"class.std::__1::__tree_node_base"* %131, null
  br i1 %132, label %136, label %133

133:                                              ; preds = %123
  %134 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %124, i64 0, i32 0
  %135 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %131, i64 0, i32 2
  store %"class.std::__1::__tree_end_node"* %134, %"class.std::__1::__tree_end_node"** %135, align 8
  br label %136

136:                                              ; preds = %133, %123
  %137 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %124, i64 0, i32 2
  %138 = bitcast %"class.std::__1::__tree_end_node"** %137 to i64*
  %139 = load i64, i64* %138, align 8
  %140 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %129, i64 0, i32 2
  %141 = bitcast %"class.std::__1::__tree_end_node"** %140 to i64*
  store i64 %139, i64* %141, align 8
  %142 = load %"class.std::__1::__tree_end_node"*, %"class.std::__1::__tree_end_node"** %137, align 8
  %143 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %142, i64 0, i32 0
  %144 = load %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_node_base"** %143, align 8
  %145 = icmp eq %"class.std::__1::__tree_node_base"* %144, %124
  %146 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %142, i64 1, i32 0
  %147 = select i1 %145, %"class.std::__1::__tree_node_base"** %143, %"class.std::__1::__tree_node_base"** %146
  store %"class.std::__1::__tree_node_base"* %129, %"class.std::__1::__tree_node_base"** %147, align 8
  store %"class.std::__1::__tree_node_base"* %124, %"class.std::__1::__tree_node_base"** %130, align 8
  %148 = getelementptr inbounds %"class.std::__1::__tree_node_base", %"class.std::__1::__tree_node_base"* %129, i64 0, i32 0
  store %"class.std::__1::__tree_end_node"* %148, %"class.std::__1::__tree_end_node"** %137, align 8
  br label %156

149:                                              ; preds = %89, %25
  %150 = phi i8* [ %26, %25 ], [ %90, %89 ]
  store i8 1, i8* %11, align 8
  %151 = icmp eq %"class.std::__1::__tree_node_base"* %20, %0
  %152 = getelementptr inbounds %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_end_node"* %16, i64 3
  %153 = bitcast %"class.std::__1::__tree_end_node"* %152 to i8*
  %154 = zext i1 %151 to i8
  store i8 %154, i8* %153, align 8
  store i8 1, i8* %150, align 8
  %155 = icmp eq %"class.std::__1::__tree_node_base"* %20, %0
  br i1 %155, label %156, label %6

156:                                              ; preds = %6, %149, %2, %136, %74
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #2

attributes #0 = { nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { argmemonly nounwind }
attributes #3 = { norecurse nounwind optsize readnone ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { inlinehint nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nounwind optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nobuiltin nounwind optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { nobuiltin nofree optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { norecurse nounwind optsize readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { nounwind optsize }
attributes #10 = { nounwind }
attributes #11 = { builtin nounwind optsize }
attributes #12 = { optsize }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i8 0, i8 2}
!3 = !{!4}
!4 = distinct !{!4, !5, !"_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE16__construct_nodeIJNS_4pairIimEEEEENS_10unique_ptrINS_11__tree_nodeIS2_PvEENS_22__tree_node_destructorINS7_ISG_EEEEEEDpOT_: argument 0"}
!5 = distinct !{!5, !"_ZNSt3__16__treeINS_12__value_typeIimEENS_19__map_value_compareIiS2_NS_4lessIiEELb1EEENS_9allocatorIS2_EEE16__construct_nodeIJNS_4pairIimEEEEENS_10unique_ptrINS_11__tree_nodeIS2_PvEENS_22__tree_node_destructorINS7_ISG_EEEEEEDpOT_"}
