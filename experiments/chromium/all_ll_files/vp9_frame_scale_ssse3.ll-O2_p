; ModuleID = '../../third_party/libvpx/source/libvpx/vp9/encoder/x86/vp9_frame_scale_ssse3.c'
source_filename = "../../third_party/libvpx/source/libvpx/vp9/encoder/x86/vp9_frame_scale_ssse3.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.yv12_buffer_config = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i8*, i8*, i8*, i8*, i8*, i64, i32, i64, i32, i32, i32, i32, i32, i32, i32, i32, i32 }

@vp9_filter_kernels = external local_unnamed_addr global [5 x [8 x i16]*], align 16
@scale_plane_4_to_3_general.shuffle_filter_funcs = internal unnamed_addr constant [2 x void (i16*, <2 x i64>*)*] [void (i16*, <2 x i64>*)* @shuffle_filter_ssse3, void (i16*, <2 x i64>*)* @shuffle_filter_odd_ssse3], align 16
@scale_plane_4_to_3_general.convolve8_funcs = internal unnamed_addr constant [2 x <2 x i64> (<2 x i64>*, <2 x i64>*)*] [<2 x i64> (<2 x i64>*, <2 x i64>*)* @convolve8_8_even_offset_ssse3, <2 x i64> (<2 x i64>*, <2 x i64>*)* @convolve8_8_odd_offset_ssse3], align 16

; Function Attrs: nounwind ssp uwtable
define hidden void @vp9_scale_and_extend_frame_ssse3(%struct.yv12_buffer_config*, %struct.yv12_buffer_config*, i8 zeroext, i32) local_unnamed_addr #0 {
  %5 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 2
  %6 = load i32, i32* %5, align 8
  %7 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 3
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 2
  %10 = load i32, i32* %9, align 8
  %11 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 3
  %12 = load i32, i32* %11, align 4
  %13 = sdiv i32 %10, 2
  %14 = sdiv i32 %12, 2
  %15 = shl nsw i32 %10, 1
  %16 = icmp eq i32 %15, %6
  %17 = shl nsw i32 %12, 1
  %18 = icmp eq i32 %17, %8
  %19 = and i1 %16, %18
  br i1 %19, label %20, label %510

20:                                               ; preds = %4
  %21 = icmp eq i32 %3, 0
  br i1 %21, label %22, label %254

22:                                               ; preds = %20
  %23 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 13
  %24 = load i8*, i8** %23, align 8
  %25 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 4
  %26 = load i32, i32* %25, align 8
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 13
  %29 = load i8*, i8** %28, align 8
  %30 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 4
  %31 = load i32, i32* %30, align 8
  %32 = sext i32 %31 to i64
  %33 = add nsw i32 %10, 15
  %34 = and i32 %33, -16
  %35 = sext i32 %34 to i64
  %36 = sub nsw i64 %27, %35
  %37 = shl nsw i64 %36, 1
  %38 = sub nsw i64 %32, %35
  %39 = add nsw i32 %34, -16
  %40 = and i32 %39, 16
  %41 = icmp eq i32 %40, 0
  %42 = add nsw i32 %34, -16
  %43 = icmp eq i32 %39, 0
  br label %44

44:                                               ; preds = %94, %22
  %45 = phi i8* [ %29, %22 ], [ %98, %94 ]
  %46 = phi i32 [ %12, %22 ], [ %99, %94 ]
  %47 = phi i8* [ %24, %22 ], [ %97, %94 ]
  br i1 %41, label %48, label %60

48:                                               ; preds = %44
  %49 = bitcast i8* %47 to <8 x i16>*
  %50 = load <8 x i16>, <8 x i16>* %49, align 1
  %51 = getelementptr inbounds i8, i8* %47, i64 16
  %52 = bitcast i8* %51 to <8 x i16>*
  %53 = load <8 x i16>, <8 x i16>* %52, align 1
  %54 = and <8 x i16> %50, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %55 = and <8 x i16> %53, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %56 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> %55) #9
  %57 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %56, <16 x i8>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %47, i64 32
  %59 = getelementptr inbounds i8, i8* %45, i64 16
  br label %60

60:                                               ; preds = %48, %44
  %61 = phi i8* [ %58, %48 ], [ undef, %44 ]
  %62 = phi i8* [ %59, %48 ], [ undef, %44 ]
  %63 = phi i8* [ %59, %48 ], [ %45, %44 ]
  %64 = phi i32 [ %42, %48 ], [ %34, %44 ]
  %65 = phi i8* [ %58, %48 ], [ %47, %44 ]
  br i1 %43, label %94, label %66

66:                                               ; preds = %60, %66
  %67 = phi i8* [ %91, %66 ], [ %63, %60 ]
  %68 = phi i32 [ %92, %66 ], [ %64, %60 ]
  %69 = phi i8* [ %90, %66 ], [ %65, %60 ]
  %70 = bitcast i8* %69 to <8 x i16>*
  %71 = load <8 x i16>, <8 x i16>* %70, align 1
  %72 = getelementptr inbounds i8, i8* %69, i64 16
  %73 = bitcast i8* %72 to <8 x i16>*
  %74 = load <8 x i16>, <8 x i16>* %73, align 1
  %75 = and <8 x i16> %71, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %76 = and <8 x i16> %74, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %77 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %75, <8 x i16> %76) #9
  %78 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %77, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %69, i64 32
  %80 = getelementptr inbounds i8, i8* %67, i64 16
  %81 = bitcast i8* %79 to <8 x i16>*
  %82 = load <8 x i16>, <8 x i16>* %81, align 1
  %83 = getelementptr inbounds i8, i8* %69, i64 48
  %84 = bitcast i8* %83 to <8 x i16>*
  %85 = load <8 x i16>, <8 x i16>* %84, align 1
  %86 = and <8 x i16> %82, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %87 = and <8 x i16> %85, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %88 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %86, <8 x i16> %87) #9
  %89 = bitcast i8* %80 to <16 x i8>*
  store <16 x i8> %88, <16 x i8>* %89, align 1
  %90 = getelementptr inbounds i8, i8* %69, i64 64
  %91 = getelementptr inbounds i8, i8* %67, i64 32
  %92 = add nsw i32 %68, -32
  %93 = icmp eq i32 %92, 0
  br i1 %93, label %94, label %66

94:                                               ; preds = %66, %60
  %95 = phi i8* [ %61, %60 ], [ %90, %66 ]
  %96 = phi i8* [ %62, %60 ], [ %91, %66 ]
  %97 = getelementptr inbounds i8, i8* %95, i64 %37
  %98 = getelementptr inbounds i8, i8* %96, i64 %38
  %99 = add nsw i32 %46, -1
  %100 = icmp eq i32 %99, 0
  br i1 %100, label %101, label %44

101:                                              ; preds = %94
  %102 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 14
  %103 = load i8*, i8** %102, align 8
  %104 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 9
  %105 = load i32, i32* %104, align 4
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 14
  %108 = load i8*, i8** %107, align 8
  %109 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 9
  %110 = load i32, i32* %109, align 4
  %111 = sext i32 %110 to i64
  %112 = add nsw i32 %13, 15
  %113 = and i32 %112, -16
  %114 = sext i32 %113 to i64
  %115 = sub nsw i64 %106, %114
  %116 = shl nsw i64 %115, 1
  %117 = sub nsw i64 %111, %114
  %118 = add nsw i32 %113, -16
  %119 = and i32 %118, 16
  %120 = icmp eq i32 %119, 0
  %121 = add nsw i32 %113, -16
  %122 = icmp eq i32 %118, 0
  br label %123

123:                                              ; preds = %173, %101
  %124 = phi i8* [ %108, %101 ], [ %177, %173 ]
  %125 = phi i32 [ %14, %101 ], [ %178, %173 ]
  %126 = phi i8* [ %103, %101 ], [ %176, %173 ]
  br i1 %120, label %127, label %139

127:                                              ; preds = %123
  %128 = bitcast i8* %126 to <8 x i16>*
  %129 = load <8 x i16>, <8 x i16>* %128, align 1
  %130 = getelementptr inbounds i8, i8* %126, i64 16
  %131 = bitcast i8* %130 to <8 x i16>*
  %132 = load <8 x i16>, <8 x i16>* %131, align 1
  %133 = and <8 x i16> %129, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %134 = and <8 x i16> %132, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %133, <8 x i16> %134) #9
  %136 = bitcast i8* %124 to <16 x i8>*
  store <16 x i8> %135, <16 x i8>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %126, i64 32
  %138 = getelementptr inbounds i8, i8* %124, i64 16
  br label %139

139:                                              ; preds = %127, %123
  %140 = phi i8* [ %137, %127 ], [ undef, %123 ]
  %141 = phi i8* [ %138, %127 ], [ undef, %123 ]
  %142 = phi i8* [ %138, %127 ], [ %124, %123 ]
  %143 = phi i32 [ %121, %127 ], [ %113, %123 ]
  %144 = phi i8* [ %137, %127 ], [ %126, %123 ]
  br i1 %122, label %173, label %145

145:                                              ; preds = %139, %145
  %146 = phi i8* [ %170, %145 ], [ %142, %139 ]
  %147 = phi i32 [ %171, %145 ], [ %143, %139 ]
  %148 = phi i8* [ %169, %145 ], [ %144, %139 ]
  %149 = bitcast i8* %148 to <8 x i16>*
  %150 = load <8 x i16>, <8 x i16>* %149, align 1
  %151 = getelementptr inbounds i8, i8* %148, i64 16
  %152 = bitcast i8* %151 to <8 x i16>*
  %153 = load <8 x i16>, <8 x i16>* %152, align 1
  %154 = and <8 x i16> %150, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %155 = and <8 x i16> %153, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %156 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %154, <8 x i16> %155) #9
  %157 = bitcast i8* %146 to <16 x i8>*
  store <16 x i8> %156, <16 x i8>* %157, align 1
  %158 = getelementptr inbounds i8, i8* %148, i64 32
  %159 = getelementptr inbounds i8, i8* %146, i64 16
  %160 = bitcast i8* %158 to <8 x i16>*
  %161 = load <8 x i16>, <8 x i16>* %160, align 1
  %162 = getelementptr inbounds i8, i8* %148, i64 48
  %163 = bitcast i8* %162 to <8 x i16>*
  %164 = load <8 x i16>, <8 x i16>* %163, align 1
  %165 = and <8 x i16> %161, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %166 = and <8 x i16> %164, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %167 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %165, <8 x i16> %166) #9
  %168 = bitcast i8* %159 to <16 x i8>*
  store <16 x i8> %167, <16 x i8>* %168, align 1
  %169 = getelementptr inbounds i8, i8* %148, i64 64
  %170 = getelementptr inbounds i8, i8* %146, i64 32
  %171 = add nsw i32 %147, -32
  %172 = icmp eq i32 %171, 0
  br i1 %172, label %173, label %145

173:                                              ; preds = %145, %139
  %174 = phi i8* [ %140, %139 ], [ %169, %145 ]
  %175 = phi i8* [ %141, %139 ], [ %170, %145 ]
  %176 = getelementptr inbounds i8, i8* %174, i64 %116
  %177 = getelementptr inbounds i8, i8* %175, i64 %117
  %178 = add nsw i32 %125, -1
  %179 = icmp eq i32 %178, 0
  br i1 %179, label %180, label %123

180:                                              ; preds = %173
  %181 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 15
  %182 = load i8*, i8** %181, align 8
  %183 = load i32, i32* %104, align 4
  %184 = sext i32 %183 to i64
  %185 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 15
  %186 = load i8*, i8** %185, align 8
  %187 = load i32, i32* %109, align 4
  %188 = sext i32 %187 to i64
  %189 = sub nsw i64 %184, %114
  %190 = shl nsw i64 %189, 1
  %191 = sub nsw i64 %188, %114
  %192 = add nsw i32 %113, -16
  %193 = and i32 %192, 16
  %194 = icmp eq i32 %193, 0
  %195 = add nsw i32 %113, -16
  %196 = icmp eq i32 %192, 0
  br label %197

197:                                              ; preds = %247, %180
  %198 = phi i8* [ %186, %180 ], [ %251, %247 ]
  %199 = phi i32 [ %14, %180 ], [ %252, %247 ]
  %200 = phi i8* [ %182, %180 ], [ %250, %247 ]
  br i1 %194, label %201, label %213

201:                                              ; preds = %197
  %202 = bitcast i8* %200 to <8 x i16>*
  %203 = load <8 x i16>, <8 x i16>* %202, align 1
  %204 = getelementptr inbounds i8, i8* %200, i64 16
  %205 = bitcast i8* %204 to <8 x i16>*
  %206 = load <8 x i16>, <8 x i16>* %205, align 1
  %207 = and <8 x i16> %203, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %208 = and <8 x i16> %206, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %209 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %207, <8 x i16> %208) #9
  %210 = bitcast i8* %198 to <16 x i8>*
  store <16 x i8> %209, <16 x i8>* %210, align 1
  %211 = getelementptr inbounds i8, i8* %200, i64 32
  %212 = getelementptr inbounds i8, i8* %198, i64 16
  br label %213

213:                                              ; preds = %201, %197
  %214 = phi i8* [ %211, %201 ], [ undef, %197 ]
  %215 = phi i8* [ %212, %201 ], [ undef, %197 ]
  %216 = phi i8* [ %212, %201 ], [ %198, %197 ]
  %217 = phi i32 [ %195, %201 ], [ %113, %197 ]
  %218 = phi i8* [ %211, %201 ], [ %200, %197 ]
  br i1 %196, label %247, label %219

219:                                              ; preds = %213, %219
  %220 = phi i8* [ %244, %219 ], [ %216, %213 ]
  %221 = phi i32 [ %245, %219 ], [ %217, %213 ]
  %222 = phi i8* [ %243, %219 ], [ %218, %213 ]
  %223 = bitcast i8* %222 to <8 x i16>*
  %224 = load <8 x i16>, <8 x i16>* %223, align 1
  %225 = getelementptr inbounds i8, i8* %222, i64 16
  %226 = bitcast i8* %225 to <8 x i16>*
  %227 = load <8 x i16>, <8 x i16>* %226, align 1
  %228 = and <8 x i16> %224, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %229 = and <8 x i16> %227, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %230 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %228, <8 x i16> %229) #9
  %231 = bitcast i8* %220 to <16 x i8>*
  store <16 x i8> %230, <16 x i8>* %231, align 1
  %232 = getelementptr inbounds i8, i8* %222, i64 32
  %233 = getelementptr inbounds i8, i8* %220, i64 16
  %234 = bitcast i8* %232 to <8 x i16>*
  %235 = load <8 x i16>, <8 x i16>* %234, align 1
  %236 = getelementptr inbounds i8, i8* %222, i64 48
  %237 = bitcast i8* %236 to <8 x i16>*
  %238 = load <8 x i16>, <8 x i16>* %237, align 1
  %239 = and <8 x i16> %235, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %240 = and <8 x i16> %238, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %241 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %239, <8 x i16> %240) #9
  %242 = bitcast i8* %233 to <16 x i8>*
  store <16 x i8> %241, <16 x i8>* %242, align 1
  %243 = getelementptr inbounds i8, i8* %222, i64 64
  %244 = getelementptr inbounds i8, i8* %220, i64 32
  %245 = add nsw i32 %221, -32
  %246 = icmp eq i32 %245, 0
  br i1 %246, label %247, label %219

247:                                              ; preds = %219, %213
  %248 = phi i8* [ %214, %213 ], [ %243, %219 ]
  %249 = phi i8* [ %215, %213 ], [ %244, %219 ]
  %250 = getelementptr inbounds i8, i8* %248, i64 %190
  %251 = getelementptr inbounds i8, i8* %249, i64 %191
  %252 = add nsw i32 %199, -1
  %253 = icmp eq i32 %252, 0
  br i1 %253, label %1169, label %197

254:                                              ; preds = %20
  %255 = icmp eq i8 %2, 3
  br i1 %255, label %256, label %469

256:                                              ; preds = %254
  %257 = load [8 x i16]*, [8 x i16]** getelementptr inbounds ([5 x [8 x i16]*], [5 x [8 x i16]*]* @vp9_filter_kernels, i64 0, i64 3), align 8
  %258 = sext i32 %3 to i64
  %259 = getelementptr inbounds [8 x i16], [8 x i16]* %257, i64 %258, i64 3
  %260 = load i16, i16* %259, align 2
  %261 = getelementptr inbounds [8 x i16], [8 x i16]* %257, i64 %258, i64 4
  %262 = load i16, i16* %261, align 2
  %263 = shl i16 %262, 8
  %264 = or i16 %263, %260
  %265 = insertelement <8 x i16> undef, i16 %264, i32 0
  %266 = shufflevector <8 x i16> %265, <8 x i16> undef, <8 x i32> zeroinitializer
  %267 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 13
  %268 = load i8*, i8** %267, align 8
  %269 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 4
  %270 = load i32, i32* %269, align 8
  %271 = sext i32 %270 to i64
  %272 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 13
  %273 = load i8*, i8** %272, align 8
  %274 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 4
  %275 = load i32, i32* %274, align 8
  %276 = sext i32 %275 to i64
  %277 = add nsw i32 %10, 15
  %278 = and i32 %277, -16
  %279 = sext i32 %278 to i64
  %280 = sub nsw i64 %271, %279
  %281 = shl nsw i64 %280, 1
  %282 = bitcast <8 x i16> %266 to <16 x i8>
  %283 = sub nsw i64 %276, %279
  br label %284

284:                                              ; preds = %331, %256
  %285 = phi i32 [ %12, %256 ], [ %334, %331 ]
  %286 = phi i8* [ %273, %256 ], [ %333, %331 ]
  %287 = phi i8* [ %268, %256 ], [ %332, %331 ]
  br label %288

288:                                              ; preds = %288, %284
  %289 = phi i32 [ %278, %284 ], [ %329, %288 ]
  %290 = phi i8* [ %286, %284 ], [ %328, %288 ]
  %291 = phi i8* [ %287, %284 ], [ %327, %288 ]
  %292 = bitcast i8* %291 to <16 x i8>*
  %293 = load <16 x i8>, <16 x i8>* %292, align 1
  %294 = getelementptr inbounds i8, i8* %291, i64 16
  %295 = bitcast i8* %294 to <16 x i8>*
  %296 = load <16 x i8>, <16 x i8>* %295, align 1
  %297 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %293, <16 x i8> %282) #9
  %298 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %296, <16 x i8> %282) #9
  %299 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %297, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %300 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %298, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %301 = ashr <8 x i16> %299, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %302 = ashr <8 x i16> %300, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %303 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %301, <8 x i16> %302) #9
  %304 = getelementptr inbounds i8, i8* %291, i64 %271
  %305 = bitcast i8* %304 to <16 x i8>*
  %306 = load <16 x i8>, <16 x i8>* %305, align 1
  %307 = getelementptr inbounds i8, i8* %304, i64 16
  %308 = bitcast i8* %307 to <16 x i8>*
  %309 = load <16 x i8>, <16 x i8>* %308, align 1
  %310 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %306, <16 x i8> %282) #9
  %311 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %309, <16 x i8> %282) #9
  %312 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %310, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %313 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %311, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %314 = ashr <8 x i16> %312, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %315 = ashr <8 x i16> %313, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %316 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %314, <8 x i16> %315) #9
  %317 = shufflevector <16 x i8> %303, <16 x i8> %316, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %318 = shufflevector <16 x i8> %303, <16 x i8> %316, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %319 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %317, <16 x i8> %282) #9
  %320 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %318, <16 x i8> %282) #9
  %321 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %319, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %322 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %320, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %323 = ashr <8 x i16> %321, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %324 = ashr <8 x i16> %322, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %325 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %323, <8 x i16> %324) #9
  %326 = bitcast i8* %290 to <16 x i8>*
  store <16 x i8> %325, <16 x i8>* %326, align 1
  %327 = getelementptr inbounds i8, i8* %291, i64 32
  %328 = getelementptr inbounds i8, i8* %290, i64 16
  %329 = add nsw i32 %289, -16
  %330 = icmp eq i32 %329, 0
  br i1 %330, label %331, label %288

331:                                              ; preds = %288
  %332 = getelementptr inbounds i8, i8* %327, i64 %281
  %333 = getelementptr inbounds i8, i8* %328, i64 %283
  %334 = add nsw i32 %285, -1
  %335 = icmp eq i32 %334, 0
  br i1 %335, label %336, label %284

336:                                              ; preds = %331
  %337 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 14
  %338 = load i8*, i8** %337, align 8
  %339 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 9
  %340 = load i32, i32* %339, align 4
  %341 = sext i32 %340 to i64
  %342 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 14
  %343 = load i8*, i8** %342, align 8
  %344 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 9
  %345 = load i32, i32* %344, align 4
  %346 = sext i32 %345 to i64
  %347 = add nsw i32 %13, 15
  %348 = and i32 %347, -16
  %349 = sext i32 %348 to i64
  %350 = sub nsw i64 %341, %349
  %351 = shl nsw i64 %350, 1
  %352 = sub nsw i64 %346, %349
  br label %353

353:                                              ; preds = %400, %336
  %354 = phi i32 [ %14, %336 ], [ %403, %400 ]
  %355 = phi i8* [ %343, %336 ], [ %402, %400 ]
  %356 = phi i8* [ %338, %336 ], [ %401, %400 ]
  br label %357

357:                                              ; preds = %357, %353
  %358 = phi i32 [ %348, %353 ], [ %398, %357 ]
  %359 = phi i8* [ %355, %353 ], [ %397, %357 ]
  %360 = phi i8* [ %356, %353 ], [ %396, %357 ]
  %361 = bitcast i8* %360 to <16 x i8>*
  %362 = load <16 x i8>, <16 x i8>* %361, align 1
  %363 = getelementptr inbounds i8, i8* %360, i64 16
  %364 = bitcast i8* %363 to <16 x i8>*
  %365 = load <16 x i8>, <16 x i8>* %364, align 1
  %366 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %362, <16 x i8> %282) #9
  %367 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %365, <16 x i8> %282) #9
  %368 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %366, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %369 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %367, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %370 = ashr <8 x i16> %368, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %371 = ashr <8 x i16> %369, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %372 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %370, <8 x i16> %371) #9
  %373 = getelementptr inbounds i8, i8* %360, i64 %341
  %374 = bitcast i8* %373 to <16 x i8>*
  %375 = load <16 x i8>, <16 x i8>* %374, align 1
  %376 = getelementptr inbounds i8, i8* %373, i64 16
  %377 = bitcast i8* %376 to <16 x i8>*
  %378 = load <16 x i8>, <16 x i8>* %377, align 1
  %379 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %375, <16 x i8> %282) #9
  %380 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %378, <16 x i8> %282) #9
  %381 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %379, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %382 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %380, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %383 = ashr <8 x i16> %381, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %384 = ashr <8 x i16> %382, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %385 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %383, <8 x i16> %384) #9
  %386 = shufflevector <16 x i8> %372, <16 x i8> %385, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %387 = shufflevector <16 x i8> %372, <16 x i8> %385, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %388 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %386, <16 x i8> %282) #9
  %389 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %387, <16 x i8> %282) #9
  %390 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %388, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %391 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %389, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %392 = ashr <8 x i16> %390, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %393 = ashr <8 x i16> %391, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %394 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %392, <8 x i16> %393) #9
  %395 = bitcast i8* %359 to <16 x i8>*
  store <16 x i8> %394, <16 x i8>* %395, align 1
  %396 = getelementptr inbounds i8, i8* %360, i64 32
  %397 = getelementptr inbounds i8, i8* %359, i64 16
  %398 = add nsw i32 %358, -16
  %399 = icmp eq i32 %398, 0
  br i1 %399, label %400, label %357

400:                                              ; preds = %357
  %401 = getelementptr inbounds i8, i8* %396, i64 %351
  %402 = getelementptr inbounds i8, i8* %397, i64 %352
  %403 = add nsw i32 %354, -1
  %404 = icmp eq i32 %403, 0
  br i1 %404, label %405, label %353

405:                                              ; preds = %400
  %406 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 15
  %407 = load i8*, i8** %406, align 8
  %408 = load i32, i32* %339, align 4
  %409 = sext i32 %408 to i64
  %410 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 15
  %411 = load i8*, i8** %410, align 8
  %412 = load i32, i32* %344, align 4
  %413 = sext i32 %412 to i64
  %414 = sub nsw i64 %409, %349
  %415 = shl nsw i64 %414, 1
  %416 = sub nsw i64 %413, %349
  br label %417

417:                                              ; preds = %464, %405
  %418 = phi i32 [ %14, %405 ], [ %467, %464 ]
  %419 = phi i8* [ %411, %405 ], [ %466, %464 ]
  %420 = phi i8* [ %407, %405 ], [ %465, %464 ]
  br label %421

421:                                              ; preds = %421, %417
  %422 = phi i32 [ %348, %417 ], [ %462, %421 ]
  %423 = phi i8* [ %419, %417 ], [ %461, %421 ]
  %424 = phi i8* [ %420, %417 ], [ %460, %421 ]
  %425 = bitcast i8* %424 to <16 x i8>*
  %426 = load <16 x i8>, <16 x i8>* %425, align 1
  %427 = getelementptr inbounds i8, i8* %424, i64 16
  %428 = bitcast i8* %427 to <16 x i8>*
  %429 = load <16 x i8>, <16 x i8>* %428, align 1
  %430 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %426, <16 x i8> %282) #9
  %431 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %429, <16 x i8> %282) #9
  %432 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %430, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %433 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %431, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %434 = ashr <8 x i16> %432, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %435 = ashr <8 x i16> %433, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %436 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %434, <8 x i16> %435) #9
  %437 = getelementptr inbounds i8, i8* %424, i64 %409
  %438 = bitcast i8* %437 to <16 x i8>*
  %439 = load <16 x i8>, <16 x i8>* %438, align 1
  %440 = getelementptr inbounds i8, i8* %437, i64 16
  %441 = bitcast i8* %440 to <16 x i8>*
  %442 = load <16 x i8>, <16 x i8>* %441, align 1
  %443 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %439, <16 x i8> %282) #9
  %444 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %442, <16 x i8> %282) #9
  %445 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %443, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %446 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %444, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %447 = ashr <8 x i16> %445, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %448 = ashr <8 x i16> %446, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %449 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %447, <8 x i16> %448) #9
  %450 = shufflevector <16 x i8> %436, <16 x i8> %449, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %451 = shufflevector <16 x i8> %436, <16 x i8> %449, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %452 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %450, <16 x i8> %282) #9
  %453 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %451, <16 x i8> %282) #9
  %454 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %452, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %455 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %453, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %456 = ashr <8 x i16> %454, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %457 = ashr <8 x i16> %455, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %458 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %456, <8 x i16> %457) #9
  %459 = bitcast i8* %423 to <16 x i8>*
  store <16 x i8> %458, <16 x i8>* %459, align 1
  %460 = getelementptr inbounds i8, i8* %424, i64 32
  %461 = getelementptr inbounds i8, i8* %423, i64 16
  %462 = add nsw i32 %422, -16
  %463 = icmp eq i32 %462, 0
  br i1 %463, label %464, label %421

464:                                              ; preds = %421
  %465 = getelementptr inbounds i8, i8* %460, i64 %415
  %466 = getelementptr inbounds i8, i8* %461, i64 %416
  %467 = add nsw i32 %418, -1
  %468 = icmp eq i32 %467, 0
  br i1 %468, label %1169, label %417

469:                                              ; preds = %254
  %470 = add nsw i32 %10, 3
  %471 = and i32 %470, -4
  %472 = add nsw i32 %8, 13
  %473 = and i32 %472, -8
  %474 = mul nsw i32 %473, %471
  %475 = sext i32 %474 to i64
  %476 = tail call noalias i8* @malloc(i64 %475) #9
  %477 = icmp eq i8* %476, null
  br i1 %477, label %1170, label %478

478:                                              ; preds = %469
  %479 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 13
  %480 = load i8*, i8** %479, align 8
  %481 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 4
  %482 = load i32, i32* %481, align 8
  %483 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 13
  %484 = load i8*, i8** %483, align 8
  %485 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 4
  %486 = load i32, i32* %485, align 8
  %487 = zext i8 %2 to i64
  %488 = getelementptr inbounds [5 x [8 x i16]*], [5 x [8 x i16]*]* @vp9_filter_kernels, i64 0, i64 %487
  %489 = load [8 x i16]*, [8 x i16]** %488, align 8
  %490 = sext i32 %3 to i64
  %491 = getelementptr inbounds [8 x i16], [8 x i16]* %489, i64 %490, i64 0
  tail call fastcc void @scale_plane_2_to_1_general(i8* %480, i32 %482, i8* %484, i32 %486, i32 %10, i32 %12, i16* %491, i8* nonnull %476)
  %492 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 14
  %493 = load i8*, i8** %492, align 8
  %494 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 9
  %495 = load i32, i32* %494, align 4
  %496 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 14
  %497 = load i8*, i8** %496, align 8
  %498 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 9
  %499 = load i32, i32* %498, align 4
  %500 = load [8 x i16]*, [8 x i16]** %488, align 8
  %501 = getelementptr inbounds [8 x i16], [8 x i16]* %500, i64 %490, i64 0
  tail call fastcc void @scale_plane_2_to_1_general(i8* %493, i32 %495, i8* %497, i32 %499, i32 %13, i32 %14, i16* %501, i8* nonnull %476)
  %502 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 15
  %503 = load i8*, i8** %502, align 8
  %504 = load i32, i32* %494, align 4
  %505 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 15
  %506 = load i8*, i8** %505, align 8
  %507 = load i32, i32* %498, align 4
  %508 = load [8 x i16]*, [8 x i16]** %488, align 8
  %509 = getelementptr inbounds [8 x i16], [8 x i16]* %508, i64 %490, i64 0
  tail call fastcc void @scale_plane_2_to_1_general(i8* %503, i32 %504, i8* %506, i32 %507, i32 %13, i32 %14, i16* %509, i8* nonnull %476)
  tail call void @free(i8* nonnull %476) #9
  br label %1169

510:                                              ; preds = %4
  %511 = shl nsw i32 %10, 2
  %512 = icmp eq i32 %511, %6
  %513 = shl nsw i32 %12, 2
  %514 = icmp eq i32 %513, %8
  %515 = and i1 %512, %514
  br i1 %515, label %516, label %1061

516:                                              ; preds = %510
  %517 = icmp eq i32 %3, 0
  br i1 %517, label %518, label %678

518:                                              ; preds = %516
  %519 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 13
  %520 = load i8*, i8** %519, align 8
  %521 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 4
  %522 = load i32, i32* %521, align 8
  %523 = sext i32 %522 to i64
  %524 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 13
  %525 = load i8*, i8** %524, align 8
  %526 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 4
  %527 = load i32, i32* %526, align 8
  %528 = sext i32 %527 to i64
  %529 = add nsw i32 %10, 15
  %530 = and i32 %529, -16
  %531 = sext i32 %530 to i64
  %532 = sub nsw i64 %523, %531
  %533 = shl nsw i64 %532, 2
  %534 = sub nsw i64 %528, %531
  br label %535

535:                                              ; preds = %568, %518
  %536 = phi i32 [ %12, %518 ], [ %571, %568 ]
  %537 = phi i8* [ %525, %518 ], [ %570, %568 ]
  %538 = phi i8* [ %520, %518 ], [ %569, %568 ]
  br label %539

539:                                              ; preds = %539, %535
  %540 = phi i32 [ %530, %535 ], [ %566, %539 ]
  %541 = phi i8* [ %537, %535 ], [ %565, %539 ]
  %542 = phi i8* [ %538, %535 ], [ %564, %539 ]
  %543 = bitcast i8* %542 to <8 x i16>*
  %544 = load <8 x i16>, <8 x i16>* %543, align 1
  %545 = getelementptr inbounds i8, i8* %542, i64 16
  %546 = bitcast i8* %545 to <8 x i16>*
  %547 = load <8 x i16>, <8 x i16>* %546, align 1
  %548 = and <8 x i16> %544, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %549 = and <8 x i16> %547, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %550 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %548, <8 x i16> %549) #9
  %551 = getelementptr inbounds i8, i8* %542, i64 32
  %552 = bitcast i8* %551 to <8 x i16>*
  %553 = load <8 x i16>, <8 x i16>* %552, align 1
  %554 = getelementptr inbounds i8, i8* %542, i64 48
  %555 = bitcast i8* %554 to <8 x i16>*
  %556 = load <8 x i16>, <8 x i16>* %555, align 1
  %557 = and <8 x i16> %553, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %558 = and <8 x i16> %556, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %559 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %557, <8 x i16> %558) #9
  %560 = bitcast <16 x i8> %550 to <8 x i16>
  %561 = bitcast <16 x i8> %559 to <8 x i16>
  %562 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %560, <8 x i16> %561) #9
  %563 = bitcast i8* %541 to <16 x i8>*
  store <16 x i8> %562, <16 x i8>* %563, align 1
  %564 = getelementptr inbounds i8, i8* %542, i64 64
  %565 = getelementptr inbounds i8, i8* %541, i64 16
  %566 = add nsw i32 %540, -16
  %567 = icmp eq i32 %566, 0
  br i1 %567, label %568, label %539

568:                                              ; preds = %539
  %569 = getelementptr inbounds i8, i8* %564, i64 %533
  %570 = getelementptr inbounds i8, i8* %565, i64 %534
  %571 = add nsw i32 %536, -1
  %572 = icmp eq i32 %571, 0
  br i1 %572, label %573, label %535

573:                                              ; preds = %568
  %574 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 14
  %575 = load i8*, i8** %574, align 8
  %576 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 9
  %577 = load i32, i32* %576, align 4
  %578 = sext i32 %577 to i64
  %579 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 14
  %580 = load i8*, i8** %579, align 8
  %581 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 9
  %582 = load i32, i32* %581, align 4
  %583 = sext i32 %582 to i64
  %584 = add nsw i32 %13, 15
  %585 = and i32 %584, -16
  %586 = sext i32 %585 to i64
  %587 = sub nsw i64 %578, %586
  %588 = shl nsw i64 %587, 2
  %589 = sub nsw i64 %583, %586
  br label %590

590:                                              ; preds = %623, %573
  %591 = phi i32 [ %14, %573 ], [ %626, %623 ]
  %592 = phi i8* [ %580, %573 ], [ %625, %623 ]
  %593 = phi i8* [ %575, %573 ], [ %624, %623 ]
  br label %594

594:                                              ; preds = %594, %590
  %595 = phi i32 [ %585, %590 ], [ %621, %594 ]
  %596 = phi i8* [ %592, %590 ], [ %620, %594 ]
  %597 = phi i8* [ %593, %590 ], [ %619, %594 ]
  %598 = bitcast i8* %597 to <8 x i16>*
  %599 = load <8 x i16>, <8 x i16>* %598, align 1
  %600 = getelementptr inbounds i8, i8* %597, i64 16
  %601 = bitcast i8* %600 to <8 x i16>*
  %602 = load <8 x i16>, <8 x i16>* %601, align 1
  %603 = and <8 x i16> %599, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %604 = and <8 x i16> %602, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %605 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %603, <8 x i16> %604) #9
  %606 = getelementptr inbounds i8, i8* %597, i64 32
  %607 = bitcast i8* %606 to <8 x i16>*
  %608 = load <8 x i16>, <8 x i16>* %607, align 1
  %609 = getelementptr inbounds i8, i8* %597, i64 48
  %610 = bitcast i8* %609 to <8 x i16>*
  %611 = load <8 x i16>, <8 x i16>* %610, align 1
  %612 = and <8 x i16> %608, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %613 = and <8 x i16> %611, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %614 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %612, <8 x i16> %613) #9
  %615 = bitcast <16 x i8> %605 to <8 x i16>
  %616 = bitcast <16 x i8> %614 to <8 x i16>
  %617 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %615, <8 x i16> %616) #9
  %618 = bitcast i8* %596 to <16 x i8>*
  store <16 x i8> %617, <16 x i8>* %618, align 1
  %619 = getelementptr inbounds i8, i8* %597, i64 64
  %620 = getelementptr inbounds i8, i8* %596, i64 16
  %621 = add nsw i32 %595, -16
  %622 = icmp eq i32 %621, 0
  br i1 %622, label %623, label %594

623:                                              ; preds = %594
  %624 = getelementptr inbounds i8, i8* %619, i64 %588
  %625 = getelementptr inbounds i8, i8* %620, i64 %589
  %626 = add nsw i32 %591, -1
  %627 = icmp eq i32 %626, 0
  br i1 %627, label %628, label %590

628:                                              ; preds = %623
  %629 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 15
  %630 = load i8*, i8** %629, align 8
  %631 = load i32, i32* %576, align 4
  %632 = sext i32 %631 to i64
  %633 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 15
  %634 = load i8*, i8** %633, align 8
  %635 = load i32, i32* %581, align 4
  %636 = sext i32 %635 to i64
  %637 = sub nsw i64 %632, %586
  %638 = shl nsw i64 %637, 2
  %639 = sub nsw i64 %636, %586
  br label %640

640:                                              ; preds = %673, %628
  %641 = phi i32 [ %14, %628 ], [ %676, %673 ]
  %642 = phi i8* [ %634, %628 ], [ %675, %673 ]
  %643 = phi i8* [ %630, %628 ], [ %674, %673 ]
  br label %644

644:                                              ; preds = %644, %640
  %645 = phi i32 [ %585, %640 ], [ %671, %644 ]
  %646 = phi i8* [ %642, %640 ], [ %670, %644 ]
  %647 = phi i8* [ %643, %640 ], [ %669, %644 ]
  %648 = bitcast i8* %647 to <8 x i16>*
  %649 = load <8 x i16>, <8 x i16>* %648, align 1
  %650 = getelementptr inbounds i8, i8* %647, i64 16
  %651 = bitcast i8* %650 to <8 x i16>*
  %652 = load <8 x i16>, <8 x i16>* %651, align 1
  %653 = and <8 x i16> %649, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %654 = and <8 x i16> %652, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %655 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %653, <8 x i16> %654) #9
  %656 = getelementptr inbounds i8, i8* %647, i64 32
  %657 = bitcast i8* %656 to <8 x i16>*
  %658 = load <8 x i16>, <8 x i16>* %657, align 1
  %659 = getelementptr inbounds i8, i8* %647, i64 48
  %660 = bitcast i8* %659 to <8 x i16>*
  %661 = load <8 x i16>, <8 x i16>* %660, align 1
  %662 = and <8 x i16> %658, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %663 = and <8 x i16> %661, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %664 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %662, <8 x i16> %663) #9
  %665 = bitcast <16 x i8> %655 to <8 x i16>
  %666 = bitcast <16 x i8> %664 to <8 x i16>
  %667 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %665, <8 x i16> %666) #9
  %668 = bitcast i8* %646 to <16 x i8>*
  store <16 x i8> %667, <16 x i8>* %668, align 1
  %669 = getelementptr inbounds i8, i8* %647, i64 64
  %670 = getelementptr inbounds i8, i8* %646, i64 16
  %671 = add nsw i32 %645, -16
  %672 = icmp eq i32 %671, 0
  br i1 %672, label %673, label %644

673:                                              ; preds = %644
  %674 = getelementptr inbounds i8, i8* %669, i64 %638
  %675 = getelementptr inbounds i8, i8* %670, i64 %639
  %676 = add nsw i32 %641, -1
  %677 = icmp eq i32 %676, 0
  br i1 %677, label %1169, label %640

678:                                              ; preds = %516
  %679 = icmp eq i8 %2, 3
  br i1 %679, label %680, label %1019

680:                                              ; preds = %678
  %681 = load [8 x i16]*, [8 x i16]** getelementptr inbounds ([5 x [8 x i16]*], [5 x [8 x i16]*]* @vp9_filter_kernels, i64 0, i64 3), align 8
  %682 = sext i32 %3 to i64
  %683 = getelementptr inbounds [8 x i16], [8 x i16]* %681, i64 %682, i64 3
  %684 = load i16, i16* %683, align 2
  %685 = getelementptr inbounds [8 x i16], [8 x i16]* %681, i64 %682, i64 4
  %686 = load i16, i16* %685, align 2
  %687 = shl i16 %686, 8
  %688 = or i16 %687, %684
  %689 = insertelement <8 x i16> undef, i16 %688, i32 0
  %690 = shufflevector <8 x i16> %689, <8 x i16> undef, <8 x i32> zeroinitializer
  %691 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 13
  %692 = load i8*, i8** %691, align 8
  %693 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 4
  %694 = load i32, i32* %693, align 8
  %695 = sext i32 %694 to i64
  %696 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 13
  %697 = load i8*, i8** %696, align 8
  %698 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 4
  %699 = load i32, i32* %698, align 8
  %700 = sext i32 %699 to i64
  %701 = add nsw i32 %10, 15
  %702 = and i32 %701, -16
  %703 = sext i32 %702 to i64
  %704 = sub nsw i64 %695, %703
  %705 = shl nsw i64 %704, 2
  %706 = bitcast <8 x i16> %690 to <16 x i8>
  %707 = sub nsw i64 %700, %703
  br label %708

708:                                              ; preds = %797, %680
  %709 = phi i8* [ %697, %680 ], [ %799, %797 ]
  %710 = phi i8* [ %692, %680 ], [ %798, %797 ]
  %711 = phi i32 [ %12, %680 ], [ %800, %797 ]
  br label %712

712:                                              ; preds = %712, %708
  %713 = phi i8* [ %709, %708 ], [ %794, %712 ]
  %714 = phi i8* [ %710, %708 ], [ %793, %712 ]
  %715 = phi i32 [ %702, %708 ], [ %795, %712 ]
  %716 = bitcast i8* %714 to <8 x i16>*
  %717 = load <8 x i16>, <8 x i16>* %716, align 1
  %718 = getelementptr inbounds i8, i8* %714, i64 16
  %719 = bitcast i8* %718 to <8 x i16>*
  %720 = load <8 x i16>, <8 x i16>* %719, align 1
  %721 = getelementptr inbounds i8, i8* %714, i64 32
  %722 = bitcast i8* %721 to <8 x i16>*
  %723 = load <8 x i16>, <8 x i16>* %722, align 1
  %724 = getelementptr inbounds i8, i8* %714, i64 48
  %725 = bitcast i8* %724 to <8 x i16>*
  %726 = load <8 x i16>, <8 x i16>* %725, align 1
  %727 = getelementptr inbounds i8, i8* %714, i64 %695
  %728 = bitcast i8* %727 to <8 x i16>*
  %729 = load <8 x i16>, <8 x i16>* %728, align 1
  %730 = getelementptr inbounds i8, i8* %727, i64 16
  %731 = bitcast i8* %730 to <8 x i16>*
  %732 = load <8 x i16>, <8 x i16>* %731, align 1
  %733 = getelementptr inbounds i8, i8* %727, i64 32
  %734 = bitcast i8* %733 to <8 x i16>*
  %735 = load <8 x i16>, <8 x i16>* %734, align 1
  %736 = getelementptr inbounds i8, i8* %727, i64 48
  %737 = bitcast i8* %736 to <8 x i16>*
  %738 = load <8 x i16>, <8 x i16>* %737, align 1
  %739 = shufflevector <8 x i16> %717, <8 x i16> %729, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %740 = shufflevector <8 x i16> %717, <8 x i16> %729, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %741 = shufflevector <8 x i16> %720, <8 x i16> %732, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %742 = shufflevector <8 x i16> %720, <8 x i16> %732, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %743 = shufflevector <8 x i16> %723, <8 x i16> %735, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %744 = shufflevector <8 x i16> %723, <8 x i16> %735, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %745 = shufflevector <8 x i16> %726, <8 x i16> %738, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %746 = shufflevector <8 x i16> %726, <8 x i16> %738, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %747 = bitcast <8 x i16> %739 to <4 x i32>
  %748 = bitcast <8 x i16> %740 to <4 x i32>
  %749 = shufflevector <4 x i32> %747, <4 x i32> %748, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %750 = shufflevector <4 x i32> %747, <4 x i32> %748, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %751 = bitcast <8 x i16> %741 to <4 x i32>
  %752 = bitcast <8 x i16> %742 to <4 x i32>
  %753 = shufflevector <4 x i32> %751, <4 x i32> %752, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %754 = shufflevector <4 x i32> %751, <4 x i32> %752, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %755 = bitcast <8 x i16> %743 to <4 x i32>
  %756 = bitcast <8 x i16> %744 to <4 x i32>
  %757 = shufflevector <4 x i32> %755, <4 x i32> %756, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %758 = shufflevector <4 x i32> %755, <4 x i32> %756, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %759 = bitcast <8 x i16> %745 to <4 x i32>
  %760 = bitcast <8 x i16> %746 to <4 x i32>
  %761 = shufflevector <4 x i32> %759, <4 x i32> %760, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %762 = shufflevector <4 x i32> %759, <4 x i32> %760, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %763 = shufflevector <4 x i32> %749, <4 x i32> %750, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %764 = shufflevector <4 x i32> %753, <4 x i32> %754, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %765 = shufflevector <4 x i32> %757, <4 x i32> %758, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %766 = shufflevector <4 x i32> %761, <4 x i32> %762, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %767 = bitcast <4 x i32> %763 to <16 x i8>
  %768 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %767, <16 x i8> %706) #9
  %769 = bitcast <4 x i32> %764 to <16 x i8>
  %770 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %769, <16 x i8> %706) #9
  %771 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %768, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %772 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %770, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %773 = ashr <8 x i16> %771, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %774 = ashr <8 x i16> %772, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %775 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %773, <8 x i16> %774) #9
  %776 = bitcast <4 x i32> %765 to <16 x i8>
  %777 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %776, <16 x i8> %706) #9
  %778 = bitcast <4 x i32> %766 to <16 x i8>
  %779 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %778, <16 x i8> %706) #9
  %780 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %777, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %781 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %779, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %782 = ashr <8 x i16> %780, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %783 = ashr <8 x i16> %781, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %784 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %782, <8 x i16> %783) #9
  %785 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %775, <16 x i8> %706) #9
  %786 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %784, <16 x i8> %706) #9
  %787 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %785, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %788 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %786, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %789 = ashr <8 x i16> %787, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %790 = ashr <8 x i16> %788, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %791 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %789, <8 x i16> %790) #9
  %792 = bitcast i8* %713 to <16 x i8>*
  store <16 x i8> %791, <16 x i8>* %792, align 1
  %793 = getelementptr inbounds i8, i8* %714, i64 64
  %794 = getelementptr inbounds i8, i8* %713, i64 16
  %795 = add nsw i32 %715, -16
  %796 = icmp eq i32 %795, 0
  br i1 %796, label %797, label %712

797:                                              ; preds = %712
  %798 = getelementptr inbounds i8, i8* %793, i64 %705
  %799 = getelementptr inbounds i8, i8* %794, i64 %707
  %800 = add nsw i32 %711, -1
  %801 = icmp eq i32 %800, 0
  br i1 %801, label %802, label %708

802:                                              ; preds = %797
  %803 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 14
  %804 = load i8*, i8** %803, align 8
  %805 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 9
  %806 = load i32, i32* %805, align 4
  %807 = sext i32 %806 to i64
  %808 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 14
  %809 = load i8*, i8** %808, align 8
  %810 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 9
  %811 = load i32, i32* %810, align 4
  %812 = sext i32 %811 to i64
  %813 = add nsw i32 %13, 15
  %814 = and i32 %813, -16
  %815 = sext i32 %814 to i64
  %816 = sub nsw i64 %807, %815
  %817 = shl nsw i64 %816, 2
  %818 = sub nsw i64 %812, %815
  br label %819

819:                                              ; preds = %908, %802
  %820 = phi i8* [ %809, %802 ], [ %910, %908 ]
  %821 = phi i8* [ %804, %802 ], [ %909, %908 ]
  %822 = phi i32 [ %14, %802 ], [ %911, %908 ]
  br label %823

823:                                              ; preds = %823, %819
  %824 = phi i8* [ %820, %819 ], [ %905, %823 ]
  %825 = phi i8* [ %821, %819 ], [ %904, %823 ]
  %826 = phi i32 [ %814, %819 ], [ %906, %823 ]
  %827 = bitcast i8* %825 to <8 x i16>*
  %828 = load <8 x i16>, <8 x i16>* %827, align 1
  %829 = getelementptr inbounds i8, i8* %825, i64 16
  %830 = bitcast i8* %829 to <8 x i16>*
  %831 = load <8 x i16>, <8 x i16>* %830, align 1
  %832 = getelementptr inbounds i8, i8* %825, i64 32
  %833 = bitcast i8* %832 to <8 x i16>*
  %834 = load <8 x i16>, <8 x i16>* %833, align 1
  %835 = getelementptr inbounds i8, i8* %825, i64 48
  %836 = bitcast i8* %835 to <8 x i16>*
  %837 = load <8 x i16>, <8 x i16>* %836, align 1
  %838 = getelementptr inbounds i8, i8* %825, i64 %807
  %839 = bitcast i8* %838 to <8 x i16>*
  %840 = load <8 x i16>, <8 x i16>* %839, align 1
  %841 = getelementptr inbounds i8, i8* %838, i64 16
  %842 = bitcast i8* %841 to <8 x i16>*
  %843 = load <8 x i16>, <8 x i16>* %842, align 1
  %844 = getelementptr inbounds i8, i8* %838, i64 32
  %845 = bitcast i8* %844 to <8 x i16>*
  %846 = load <8 x i16>, <8 x i16>* %845, align 1
  %847 = getelementptr inbounds i8, i8* %838, i64 48
  %848 = bitcast i8* %847 to <8 x i16>*
  %849 = load <8 x i16>, <8 x i16>* %848, align 1
  %850 = shufflevector <8 x i16> %828, <8 x i16> %840, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %851 = shufflevector <8 x i16> %828, <8 x i16> %840, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %852 = shufflevector <8 x i16> %831, <8 x i16> %843, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %853 = shufflevector <8 x i16> %831, <8 x i16> %843, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %854 = shufflevector <8 x i16> %834, <8 x i16> %846, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %855 = shufflevector <8 x i16> %834, <8 x i16> %846, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %856 = shufflevector <8 x i16> %837, <8 x i16> %849, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %857 = shufflevector <8 x i16> %837, <8 x i16> %849, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %858 = bitcast <8 x i16> %850 to <4 x i32>
  %859 = bitcast <8 x i16> %851 to <4 x i32>
  %860 = shufflevector <4 x i32> %858, <4 x i32> %859, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %861 = shufflevector <4 x i32> %858, <4 x i32> %859, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %862 = bitcast <8 x i16> %852 to <4 x i32>
  %863 = bitcast <8 x i16> %853 to <4 x i32>
  %864 = shufflevector <4 x i32> %862, <4 x i32> %863, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %865 = shufflevector <4 x i32> %862, <4 x i32> %863, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %866 = bitcast <8 x i16> %854 to <4 x i32>
  %867 = bitcast <8 x i16> %855 to <4 x i32>
  %868 = shufflevector <4 x i32> %866, <4 x i32> %867, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %869 = shufflevector <4 x i32> %866, <4 x i32> %867, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %870 = bitcast <8 x i16> %856 to <4 x i32>
  %871 = bitcast <8 x i16> %857 to <4 x i32>
  %872 = shufflevector <4 x i32> %870, <4 x i32> %871, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %873 = shufflevector <4 x i32> %870, <4 x i32> %871, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %874 = shufflevector <4 x i32> %860, <4 x i32> %861, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %875 = shufflevector <4 x i32> %864, <4 x i32> %865, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %876 = shufflevector <4 x i32> %868, <4 x i32> %869, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %877 = shufflevector <4 x i32> %872, <4 x i32> %873, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %878 = bitcast <4 x i32> %874 to <16 x i8>
  %879 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %878, <16 x i8> %706) #9
  %880 = bitcast <4 x i32> %875 to <16 x i8>
  %881 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %880, <16 x i8> %706) #9
  %882 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %879, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %883 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %881, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %884 = ashr <8 x i16> %882, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %885 = ashr <8 x i16> %883, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %886 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %884, <8 x i16> %885) #9
  %887 = bitcast <4 x i32> %876 to <16 x i8>
  %888 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %887, <16 x i8> %706) #9
  %889 = bitcast <4 x i32> %877 to <16 x i8>
  %890 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %889, <16 x i8> %706) #9
  %891 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %888, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %892 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %890, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %893 = ashr <8 x i16> %891, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %894 = ashr <8 x i16> %892, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %895 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %893, <8 x i16> %894) #9
  %896 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %886, <16 x i8> %706) #9
  %897 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %895, <16 x i8> %706) #9
  %898 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %896, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %899 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %897, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %900 = ashr <8 x i16> %898, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %901 = ashr <8 x i16> %899, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %902 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %900, <8 x i16> %901) #9
  %903 = bitcast i8* %824 to <16 x i8>*
  store <16 x i8> %902, <16 x i8>* %903, align 1
  %904 = getelementptr inbounds i8, i8* %825, i64 64
  %905 = getelementptr inbounds i8, i8* %824, i64 16
  %906 = add nsw i32 %826, -16
  %907 = icmp eq i32 %906, 0
  br i1 %907, label %908, label %823

908:                                              ; preds = %823
  %909 = getelementptr inbounds i8, i8* %904, i64 %817
  %910 = getelementptr inbounds i8, i8* %905, i64 %818
  %911 = add nsw i32 %822, -1
  %912 = icmp eq i32 %911, 0
  br i1 %912, label %913, label %819

913:                                              ; preds = %908
  %914 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 15
  %915 = load i8*, i8** %914, align 8
  %916 = load i32, i32* %805, align 4
  %917 = sext i32 %916 to i64
  %918 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 15
  %919 = load i8*, i8** %918, align 8
  %920 = load i32, i32* %810, align 4
  %921 = sext i32 %920 to i64
  %922 = sub nsw i64 %917, %815
  %923 = shl nsw i64 %922, 2
  %924 = sub nsw i64 %921, %815
  br label %925

925:                                              ; preds = %1014, %913
  %926 = phi i8* [ %919, %913 ], [ %1016, %1014 ]
  %927 = phi i8* [ %915, %913 ], [ %1015, %1014 ]
  %928 = phi i32 [ %14, %913 ], [ %1017, %1014 ]
  br label %929

929:                                              ; preds = %929, %925
  %930 = phi i8* [ %926, %925 ], [ %1011, %929 ]
  %931 = phi i8* [ %927, %925 ], [ %1010, %929 ]
  %932 = phi i32 [ %814, %925 ], [ %1012, %929 ]
  %933 = bitcast i8* %931 to <8 x i16>*
  %934 = load <8 x i16>, <8 x i16>* %933, align 1
  %935 = getelementptr inbounds i8, i8* %931, i64 16
  %936 = bitcast i8* %935 to <8 x i16>*
  %937 = load <8 x i16>, <8 x i16>* %936, align 1
  %938 = getelementptr inbounds i8, i8* %931, i64 32
  %939 = bitcast i8* %938 to <8 x i16>*
  %940 = load <8 x i16>, <8 x i16>* %939, align 1
  %941 = getelementptr inbounds i8, i8* %931, i64 48
  %942 = bitcast i8* %941 to <8 x i16>*
  %943 = load <8 x i16>, <8 x i16>* %942, align 1
  %944 = getelementptr inbounds i8, i8* %931, i64 %917
  %945 = bitcast i8* %944 to <8 x i16>*
  %946 = load <8 x i16>, <8 x i16>* %945, align 1
  %947 = getelementptr inbounds i8, i8* %944, i64 16
  %948 = bitcast i8* %947 to <8 x i16>*
  %949 = load <8 x i16>, <8 x i16>* %948, align 1
  %950 = getelementptr inbounds i8, i8* %944, i64 32
  %951 = bitcast i8* %950 to <8 x i16>*
  %952 = load <8 x i16>, <8 x i16>* %951, align 1
  %953 = getelementptr inbounds i8, i8* %944, i64 48
  %954 = bitcast i8* %953 to <8 x i16>*
  %955 = load <8 x i16>, <8 x i16>* %954, align 1
  %956 = shufflevector <8 x i16> %934, <8 x i16> %946, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %957 = shufflevector <8 x i16> %934, <8 x i16> %946, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %958 = shufflevector <8 x i16> %937, <8 x i16> %949, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %959 = shufflevector <8 x i16> %937, <8 x i16> %949, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %960 = shufflevector <8 x i16> %940, <8 x i16> %952, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %961 = shufflevector <8 x i16> %940, <8 x i16> %952, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %962 = shufflevector <8 x i16> %943, <8 x i16> %955, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %963 = shufflevector <8 x i16> %943, <8 x i16> %955, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %964 = bitcast <8 x i16> %956 to <4 x i32>
  %965 = bitcast <8 x i16> %957 to <4 x i32>
  %966 = shufflevector <4 x i32> %964, <4 x i32> %965, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %967 = shufflevector <4 x i32> %964, <4 x i32> %965, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %968 = bitcast <8 x i16> %958 to <4 x i32>
  %969 = bitcast <8 x i16> %959 to <4 x i32>
  %970 = shufflevector <4 x i32> %968, <4 x i32> %969, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %971 = shufflevector <4 x i32> %968, <4 x i32> %969, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %972 = bitcast <8 x i16> %960 to <4 x i32>
  %973 = bitcast <8 x i16> %961 to <4 x i32>
  %974 = shufflevector <4 x i32> %972, <4 x i32> %973, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %975 = shufflevector <4 x i32> %972, <4 x i32> %973, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %976 = bitcast <8 x i16> %962 to <4 x i32>
  %977 = bitcast <8 x i16> %963 to <4 x i32>
  %978 = shufflevector <4 x i32> %976, <4 x i32> %977, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %979 = shufflevector <4 x i32> %976, <4 x i32> %977, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %980 = shufflevector <4 x i32> %966, <4 x i32> %967, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %981 = shufflevector <4 x i32> %970, <4 x i32> %971, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %982 = shufflevector <4 x i32> %974, <4 x i32> %975, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %983 = shufflevector <4 x i32> %978, <4 x i32> %979, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %984 = bitcast <4 x i32> %980 to <16 x i8>
  %985 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %984, <16 x i8> %706) #9
  %986 = bitcast <4 x i32> %981 to <16 x i8>
  %987 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %986, <16 x i8> %706) #9
  %988 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %985, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %989 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %987, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %990 = ashr <8 x i16> %988, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %991 = ashr <8 x i16> %989, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %992 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %990, <8 x i16> %991) #9
  %993 = bitcast <4 x i32> %982 to <16 x i8>
  %994 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %993, <16 x i8> %706) #9
  %995 = bitcast <4 x i32> %983 to <16 x i8>
  %996 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %995, <16 x i8> %706) #9
  %997 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %994, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %998 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %996, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %999 = ashr <8 x i16> %997, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1000 = ashr <8 x i16> %998, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1001 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %999, <8 x i16> %1000) #9
  %1002 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %992, <16 x i8> %706) #9
  %1003 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1001, <16 x i8> %706) #9
  %1004 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1002, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %1005 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1003, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %1006 = ashr <8 x i16> %1004, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1007 = ashr <8 x i16> %1005, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1008 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1006, <8 x i16> %1007) #9
  %1009 = bitcast i8* %930 to <16 x i8>*
  store <16 x i8> %1008, <16 x i8>* %1009, align 1
  %1010 = getelementptr inbounds i8, i8* %931, i64 64
  %1011 = getelementptr inbounds i8, i8* %930, i64 16
  %1012 = add nsw i32 %932, -16
  %1013 = icmp eq i32 %1012, 0
  br i1 %1013, label %1014, label %929

1014:                                             ; preds = %929
  %1015 = getelementptr inbounds i8, i8* %1010, i64 %923
  %1016 = getelementptr inbounds i8, i8* %1011, i64 %924
  %1017 = add nsw i32 %928, -1
  %1018 = icmp eq i32 %1017, 0
  br i1 %1018, label %1169, label %925

1019:                                             ; preds = %678
  %1020 = add nsw i32 %10, 1
  %1021 = and i32 %1020, -2
  %1022 = add nsw i32 %8, 13
  %1023 = and i32 %1022, -8
  %1024 = mul nsw i32 %1023, %1021
  %1025 = add nsw i32 %1024, 16
  %1026 = sext i32 %1025 to i64
  %1027 = tail call noalias i8* @malloc(i64 %1026) #9
  %1028 = icmp eq i8* %1027, null
  br i1 %1028, label %1170, label %1029

1029:                                             ; preds = %1019
  %1030 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 13
  %1031 = load i8*, i8** %1030, align 8
  %1032 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 4
  %1033 = load i32, i32* %1032, align 8
  %1034 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 13
  %1035 = load i8*, i8** %1034, align 8
  %1036 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 4
  %1037 = load i32, i32* %1036, align 8
  %1038 = zext i8 %2 to i64
  %1039 = getelementptr inbounds [5 x [8 x i16]*], [5 x [8 x i16]*]* @vp9_filter_kernels, i64 0, i64 %1038
  %1040 = load [8 x i16]*, [8 x i16]** %1039, align 8
  %1041 = sext i32 %3 to i64
  %1042 = getelementptr inbounds [8 x i16], [8 x i16]* %1040, i64 %1041, i64 0
  tail call fastcc void @scale_plane_4_to_1_general(i8* %1031, i32 %1033, i8* %1035, i32 %1037, i32 %10, i32 %12, i16* %1042, i8* nonnull %1027)
  %1043 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 14
  %1044 = load i8*, i8** %1043, align 8
  %1045 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 9
  %1046 = load i32, i32* %1045, align 4
  %1047 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 14
  %1048 = load i8*, i8** %1047, align 8
  %1049 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 9
  %1050 = load i32, i32* %1049, align 4
  %1051 = load [8 x i16]*, [8 x i16]** %1039, align 8
  %1052 = getelementptr inbounds [8 x i16], [8 x i16]* %1051, i64 %1041, i64 0
  tail call fastcc void @scale_plane_4_to_1_general(i8* %1044, i32 %1046, i8* %1048, i32 %1050, i32 %13, i32 %14, i16* %1052, i8* nonnull %1027)
  %1053 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 15
  %1054 = load i8*, i8** %1053, align 8
  %1055 = load i32, i32* %1045, align 4
  %1056 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 15
  %1057 = load i8*, i8** %1056, align 8
  %1058 = load i32, i32* %1049, align 4
  %1059 = load [8 x i16]*, [8 x i16]** %1039, align 8
  %1060 = getelementptr inbounds [8 x i16], [8 x i16]* %1059, i64 %1041, i64 0
  tail call fastcc void @scale_plane_4_to_1_general(i8* %1054, i32 %1055, i8* %1057, i32 %1058, i32 %13, i32 %14, i16* %1060, i8* nonnull %1027)
  tail call void @free(i8* nonnull %1027) #9
  br label %1169

1061:                                             ; preds = %510
  %1062 = mul nsw i32 %6, 3
  %1063 = icmp eq i32 %511, %1062
  br i1 %1063, label %1064, label %1115

1064:                                             ; preds = %1061
  %1065 = shl nsw i32 %12, 2
  %1066 = mul nsw i32 %8, 3
  %1067 = icmp eq i32 %1065, %1066
  br i1 %1067, label %1068, label %1115

1068:                                             ; preds = %1064
  %1069 = add nsw i32 %10, 5
  %1070 = srem i32 %1069, 6
  %1071 = sub nsw i32 %1069, %1070
  %1072 = add nsw i32 %1071, 2
  %1073 = add nsw i32 %10, 7
  %1074 = and i32 %1073, -8
  %1075 = sdiv i32 %1065, 3
  %1076 = add nsw i32 %1075, 14
  %1077 = and i32 %1076, -8
  %1078 = icmp sgt i32 %1074, %1072
  %1079 = sub nsw i32 %1074, %1072
  %1080 = shl nsw i32 %1079, 1
  %1081 = select i1 %1078, i32 %1080, i32 0
  %1082 = mul nsw i32 %1077, %1072
  %1083 = add nsw i32 %1081, %1082
  %1084 = sext i32 %1083 to i64
  %1085 = tail call noalias i8* @malloc(i64 %1084) #9
  %1086 = icmp eq i8* %1085, null
  br i1 %1086, label %1170, label %1087

1087:                                             ; preds = %1068
  %1088 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 13
  %1089 = load i8*, i8** %1088, align 8
  %1090 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 4
  %1091 = load i32, i32* %1090, align 8
  %1092 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 13
  %1093 = load i8*, i8** %1092, align 8
  %1094 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 4
  %1095 = load i32, i32* %1094, align 8
  %1096 = zext i8 %2 to i64
  %1097 = getelementptr inbounds [5 x [8 x i16]*], [5 x [8 x i16]*]* @vp9_filter_kernels, i64 0, i64 %1096
  %1098 = load [8 x i16]*, [8 x i16]** %1097, align 8
  tail call fastcc void @scale_plane_4_to_3_general(i8* %1089, i32 %1091, i8* %1093, i32 %1095, i32 %10, i32 %12, [8 x i16]* %1098, i32 %3, i8* nonnull %1085)
  %1099 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 14
  %1100 = load i8*, i8** %1099, align 8
  %1101 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 9
  %1102 = load i32, i32* %1101, align 4
  %1103 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 14
  %1104 = load i8*, i8** %1103, align 8
  %1105 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 9
  %1106 = load i32, i32* %1105, align 4
  %1107 = load [8 x i16]*, [8 x i16]** %1097, align 8
  tail call fastcc void @scale_plane_4_to_3_general(i8* %1100, i32 %1102, i8* %1104, i32 %1106, i32 %13, i32 %14, [8 x i16]* %1107, i32 %3, i8* nonnull %1085)
  %1108 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 15
  %1109 = load i8*, i8** %1108, align 8
  %1110 = load i32, i32* %1101, align 4
  %1111 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 15
  %1112 = load i8*, i8** %1111, align 8
  %1113 = load i32, i32* %1105, align 4
  %1114 = load [8 x i16]*, [8 x i16]** %1097, align 8
  tail call fastcc void @scale_plane_4_to_3_general(i8* %1109, i32 %1110, i8* %1112, i32 %1113, i32 %13, i32 %14, [8 x i16]* %1114, i32 %3, i8* nonnull %1085)
  tail call void @free(i8* nonnull %1085) #9
  br label %1169

1115:                                             ; preds = %1064, %1061
  %1116 = shl nsw i32 %6, 1
  %1117 = icmp eq i32 %10, %1116
  br i1 %1117, label %1118, label %1170

1118:                                             ; preds = %1115
  %1119 = shl nsw i32 %8, 1
  %1120 = icmp eq i32 %12, %1119
  %1121 = icmp eq i32 %3, 0
  %1122 = and i1 %1121, %1120
  br i1 %1122, label %1123, label %1170

1123:                                             ; preds = %1118
  %1124 = shl i32 %6, 3
  %1125 = add i32 %1124, 56
  %1126 = and i32 %1125, -64
  %1127 = sext i32 %1126 to i64
  %1128 = tail call noalias i8* @malloc(i64 %1127) #9
  %1129 = icmp eq i8* %1128, null
  br i1 %1129, label %1170, label %1130

1130:                                             ; preds = %1123
  %1131 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 13
  %1132 = load i8*, i8** %1131, align 8
  %1133 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 4
  %1134 = load i32, i32* %1133, align 8
  %1135 = sext i32 %1134 to i64
  %1136 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 13
  %1137 = load i8*, i8** %1136, align 8
  %1138 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 4
  %1139 = load i32, i32* %1138, align 8
  %1140 = sext i32 %1139 to i64
  %1141 = zext i8 %2 to i64
  %1142 = getelementptr inbounds [5 x [8 x i16]*], [5 x [8 x i16]*]* @vp9_filter_kernels, i64 0, i64 %1141
  %1143 = load [8 x i16]*, [8 x i16]** %1142, align 8
  %1144 = getelementptr inbounds [8 x i16], [8 x i16]* %1143, i64 8, i64 0
  tail call fastcc void @scale_plane_1_to_2_phase_0(i8* %1132, i64 %1135, i8* %1137, i64 %1140, i32 %6, i32 %8, i16* %1144, i8* nonnull %1128)
  %1145 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 14
  %1146 = load i8*, i8** %1145, align 8
  %1147 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 9
  %1148 = load i32, i32* %1147, align 4
  %1149 = sext i32 %1148 to i64
  %1150 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 14
  %1151 = load i8*, i8** %1150, align 8
  %1152 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 9
  %1153 = load i32, i32* %1152, align 4
  %1154 = sext i32 %1153 to i64
  %1155 = sdiv i32 %6, 2
  %1156 = sdiv i32 %8, 2
  %1157 = load [8 x i16]*, [8 x i16]** %1142, align 8
  %1158 = getelementptr inbounds [8 x i16], [8 x i16]* %1157, i64 8, i64 0
  tail call fastcc void @scale_plane_1_to_2_phase_0(i8* %1146, i64 %1149, i8* %1151, i64 %1154, i32 %1155, i32 %1156, i16* %1158, i8* nonnull %1128)
  %1159 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 15
  %1160 = load i8*, i8** %1159, align 8
  %1161 = load i32, i32* %1147, align 4
  %1162 = sext i32 %1161 to i64
  %1163 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 15
  %1164 = load i8*, i8** %1163, align 8
  %1165 = load i32, i32* %1152, align 4
  %1166 = sext i32 %1165 to i64
  %1167 = load [8 x i16]*, [8 x i16]** %1142, align 8
  %1168 = getelementptr inbounds [8 x i16], [8 x i16]* %1167, i64 8, i64 0
  tail call fastcc void @scale_plane_1_to_2_phase_0(i8* %1160, i64 %1162, i8* %1164, i64 %1166, i32 %1155, i32 %1156, i16* %1168, i8* nonnull %1128)
  tail call void @free(i8* nonnull %1128) #9
  br label %1169

1169:                                             ; preds = %1014, %673, %464, %247, %478, %1029, %1087, %1130
  tail call void @vpx_extend_frame_borders_c(%struct.yv12_buffer_config* %1) #9
  br label %1171

1170:                                             ; preds = %1118, %1115, %469, %1019, %1068, %1123
  tail call void @vp9_scale_and_extend_frame_c(%struct.yv12_buffer_config* %0, %struct.yv12_buffer_config* %1, i8 zeroext %2, i32 %3) #9
  br label %1171

1171:                                             ; preds = %1170, %1169
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nofree nounwind
declare noalias i8* @malloc(i64) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @scale_plane_2_to_1_general(i8* nocapture readonly, i32, i8* nocapture, i32, i32, i32, i16* nocapture readonly, i8* nocapture) unnamed_addr #0 {
  %9 = add nsw i32 %4, 3
  %10 = and i32 %9, -4
  %11 = add nsw i32 %4, 7
  %12 = shl i32 %5, 1
  %13 = add nsw i32 %12, 13
  %14 = and i32 %13, -8
  %15 = add nsw i32 %5, 3
  %16 = bitcast i16* %6 to <16 x i8>*
  %17 = load <16 x i8>, <16 x i8>* %16, align 16
  %18 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2>
  %19 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6>
  %20 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10>
  %21 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14>
  %22 = mul i32 %1, -3
  %23 = add i32 %22, -5
  %24 = sext i32 %23 to i64
  %25 = getelementptr inbounds i8, i8* %0, i64 %24
  %26 = shl nsw i32 %1, 3
  %27 = shl nsw i32 %10, 1
  %28 = sub nsw i32 %26, %27
  %29 = sext i32 %28 to i64
  %30 = sext i32 %1 to i64
  %31 = shl nsw i64 %30, 1
  %32 = mul nsw i64 %30, 3
  %33 = shl nsw i64 %30, 2
  %34 = sext i32 %27 to i64
  %35 = shl nsw i64 %34, 1
  %36 = mul nsw i64 %34, 3
  %37 = mul nsw i32 %10, 6
  %38 = sext i32 %37 to i64
  br label %39

39:                                               ; preds = %240, %8
  %40 = phi i8* [ %25, %8 ], [ %241, %240 ]
  %41 = phi i32 [ %14, %8 ], [ %243, %240 ]
  %42 = phi i8* [ %7, %8 ], [ %242, %240 ]
  %43 = getelementptr inbounds i8, i8* %40, i64 2
  %44 = bitcast i8* %43 to i64*
  %45 = load i64, i64* %44, align 1
  %46 = insertelement <2 x i64> undef, i64 %45, i32 0
  %47 = getelementptr inbounds i8, i8* %43, i64 %30
  %48 = bitcast i8* %47 to i64*
  %49 = load i64, i64* %48, align 1
  %50 = insertelement <2 x i64> undef, i64 %49, i32 0
  %51 = getelementptr inbounds i8, i8* %43, i64 %31
  %52 = bitcast i8* %51 to i64*
  %53 = load i64, i64* %52, align 1
  %54 = insertelement <2 x i64> undef, i64 %53, i32 0
  %55 = getelementptr inbounds i8, i8* %43, i64 %32
  %56 = bitcast i8* %55 to i64*
  %57 = load i64, i64* %56, align 1
  %58 = insertelement <2 x i64> undef, i64 %57, i32 0
  %59 = getelementptr inbounds i8, i8* %43, i64 %33
  %60 = bitcast i8* %59 to i64*
  %61 = load i64, i64* %60, align 1
  %62 = insertelement <2 x i64> undef, i64 %61, i32 0
  %63 = getelementptr inbounds i8, i8* %59, i64 %30
  %64 = bitcast i8* %63 to i64*
  %65 = load i64, i64* %64, align 1
  %66 = insertelement <2 x i64> undef, i64 %65, i32 0
  %67 = getelementptr inbounds i8, i8* %59, i64 %31
  %68 = bitcast i8* %67 to i64*
  %69 = load i64, i64* %68, align 1
  %70 = insertelement <2 x i64> undef, i64 %69, i32 0
  %71 = getelementptr inbounds i8, i8* %59, i64 %32
  %72 = bitcast i8* %71 to i64*
  %73 = load i64, i64* %72, align 1
  %74 = insertelement <2 x i64> undef, i64 %73, i32 0
  %75 = bitcast <2 x i64> %46 to <8 x i16>
  %76 = bitcast <2 x i64> %50 to <8 x i16>
  %77 = shufflevector <8 x i16> %75, <8 x i16> %76, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %78 = bitcast <2 x i64> %54 to <8 x i16>
  %79 = bitcast <2 x i64> %58 to <8 x i16>
  %80 = shufflevector <8 x i16> %78, <8 x i16> %79, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %81 = bitcast <2 x i64> %62 to <8 x i16>
  %82 = bitcast <2 x i64> %66 to <8 x i16>
  %83 = shufflevector <8 x i16> %81, <8 x i16> %82, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %84 = bitcast <2 x i64> %70 to <8 x i16>
  %85 = bitcast <2 x i64> %74 to <8 x i16>
  %86 = shufflevector <8 x i16> %84, <8 x i16> %85, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %87 = bitcast <8 x i16> %77 to <4 x i32>
  %88 = bitcast <8 x i16> %80 to <4 x i32>
  %89 = shufflevector <4 x i32> %87, <4 x i32> %88, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %90 = bitcast <4 x i32> %89 to <2 x i64>
  %91 = bitcast <8 x i16> %83 to <4 x i32>
  %92 = bitcast <8 x i16> %86 to <4 x i32>
  %93 = shufflevector <4 x i32> %91, <4 x i32> %92, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %94 = bitcast <4 x i32> %93 to <2 x i64>
  %95 = shufflevector <4 x i32> %87, <4 x i32> %88, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %96 = bitcast <4 x i32> %95 to <2 x i64>
  %97 = shufflevector <4 x i32> %91, <4 x i32> %92, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %98 = bitcast <4 x i32> %97 to <2 x i64>
  %99 = shufflevector <2 x i64> %90, <2 x i64> %94, <2 x i32> <i32 0, i32 2>
  %100 = shufflevector <2 x i64> %90, <2 x i64> %94, <2 x i32> <i32 1, i32 3>
  %101 = shufflevector <2 x i64> %96, <2 x i64> %98, <2 x i32> <i32 0, i32 2>
  br label %102

102:                                              ; preds = %102, %39
  %103 = phi <2 x i64> [ %101, %39 ], [ %168, %102 ]
  %104 = phi <2 x i64> [ %100, %39 ], [ %167, %102 ]
  %105 = phi <2 x i64> [ %99, %39 ], [ %166, %102 ]
  %106 = phi i8* [ %40, %39 ], [ %109, %102 ]
  %107 = phi i32 [ %10, %39 ], [ %238, %102 ]
  %108 = phi i8* [ %42, %39 ], [ %237, %102 ]
  %109 = getelementptr inbounds i8, i8* %106, i64 8
  %110 = bitcast i8* %109 to i64*
  %111 = load i64, i64* %110, align 1
  %112 = insertelement <2 x i64> undef, i64 %111, i32 0
  %113 = getelementptr inbounds i8, i8* %109, i64 %30
  %114 = bitcast i8* %113 to i64*
  %115 = load i64, i64* %114, align 1
  %116 = insertelement <2 x i64> undef, i64 %115, i32 0
  %117 = getelementptr inbounds i8, i8* %109, i64 %31
  %118 = bitcast i8* %117 to i64*
  %119 = load i64, i64* %118, align 1
  %120 = insertelement <2 x i64> undef, i64 %119, i32 0
  %121 = getelementptr inbounds i8, i8* %109, i64 %32
  %122 = bitcast i8* %121 to i64*
  %123 = load i64, i64* %122, align 1
  %124 = insertelement <2 x i64> undef, i64 %123, i32 0
  %125 = getelementptr inbounds i8, i8* %109, i64 %33
  %126 = bitcast i8* %125 to i64*
  %127 = load i64, i64* %126, align 1
  %128 = insertelement <2 x i64> undef, i64 %127, i32 0
  %129 = getelementptr inbounds i8, i8* %125, i64 %30
  %130 = bitcast i8* %129 to i64*
  %131 = load i64, i64* %130, align 1
  %132 = insertelement <2 x i64> undef, i64 %131, i32 0
  %133 = getelementptr inbounds i8, i8* %125, i64 %31
  %134 = bitcast i8* %133 to i64*
  %135 = load i64, i64* %134, align 1
  %136 = insertelement <2 x i64> undef, i64 %135, i32 0
  %137 = getelementptr inbounds i8, i8* %125, i64 %32
  %138 = bitcast i8* %137 to i64*
  %139 = load i64, i64* %138, align 1
  %140 = insertelement <2 x i64> undef, i64 %139, i32 0
  %141 = bitcast <2 x i64> %112 to <8 x i16>
  %142 = bitcast <2 x i64> %116 to <8 x i16>
  %143 = shufflevector <8 x i16> %141, <8 x i16> %142, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %144 = bitcast <2 x i64> %120 to <8 x i16>
  %145 = bitcast <2 x i64> %124 to <8 x i16>
  %146 = shufflevector <8 x i16> %144, <8 x i16> %145, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %147 = bitcast <2 x i64> %128 to <8 x i16>
  %148 = bitcast <2 x i64> %132 to <8 x i16>
  %149 = shufflevector <8 x i16> %147, <8 x i16> %148, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %150 = bitcast <2 x i64> %136 to <8 x i16>
  %151 = bitcast <2 x i64> %140 to <8 x i16>
  %152 = shufflevector <8 x i16> %150, <8 x i16> %151, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %153 = bitcast <8 x i16> %143 to <4 x i32>
  %154 = bitcast <8 x i16> %146 to <4 x i32>
  %155 = shufflevector <4 x i32> %153, <4 x i32> %154, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %156 = bitcast <4 x i32> %155 to <2 x i64>
  %157 = bitcast <8 x i16> %149 to <4 x i32>
  %158 = bitcast <8 x i16> %152 to <4 x i32>
  %159 = shufflevector <4 x i32> %157, <4 x i32> %158, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %160 = bitcast <4 x i32> %159 to <2 x i64>
  %161 = shufflevector <4 x i32> %153, <4 x i32> %154, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %162 = bitcast <4 x i32> %161 to <2 x i64>
  %163 = shufflevector <4 x i32> %157, <4 x i32> %158, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %164 = bitcast <4 x i32> %163 to <2 x i64>
  %165 = shufflevector <2 x i64> %156, <2 x i64> %160, <2 x i32> <i32 0, i32 2>
  %166 = shufflevector <2 x i64> %156, <2 x i64> %160, <2 x i32> <i32 1, i32 3>
  %167 = shufflevector <2 x i64> %162, <2 x i64> %164, <2 x i32> <i32 0, i32 2>
  %168 = shufflevector <2 x i64> %162, <2 x i64> %164, <2 x i32> <i32 1, i32 3>
  %169 = bitcast <2 x i64> %105 to <16 x i8>
  %170 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %169, <16 x i8> %18) #9
  %171 = bitcast <2 x i64> %104 to <16 x i8>
  %172 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %171, <16 x i8> %19) #9
  %173 = bitcast <2 x i64> %103 to <16 x i8>
  %174 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %173, <16 x i8> %20) #9
  %175 = bitcast <2 x i64> %165 to <16 x i8>
  %176 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %175, <16 x i8> %21) #9
  %177 = add <8 x i16> %176, %172
  %178 = add <8 x i16> %170, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %179 = add <8 x i16> %178, %174
  %180 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %179, <8 x i16> %177) #9
  %181 = ashr <8 x i16> %180, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %182 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %171, <16 x i8> %18) #9
  %183 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %173, <16 x i8> %19) #9
  %184 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %175, <16 x i8> %20) #9
  %185 = bitcast <2 x i64> %166 to <16 x i8>
  %186 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %185, <16 x i8> %21) #9
  %187 = add <8 x i16> %186, %183
  %188 = add <8 x i16> %182, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %189 = add <8 x i16> %188, %184
  %190 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %189, <8 x i16> %187) #9
  %191 = ashr <8 x i16> %190, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %192 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %173, <16 x i8> %18) #9
  %193 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %175, <16 x i8> %19) #9
  %194 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %185, <16 x i8> %20) #9
  %195 = bitcast <2 x i64> %167 to <16 x i8>
  %196 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %195, <16 x i8> %21) #9
  %197 = add <8 x i16> %196, %193
  %198 = add <8 x i16> %192, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %199 = add <8 x i16> %198, %194
  %200 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %199, <8 x i16> %197) #9
  %201 = ashr <8 x i16> %200, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %202 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %175, <16 x i8> %18) #9
  %203 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %185, <16 x i8> %19) #9
  %204 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %195, <16 x i8> %20) #9
  %205 = bitcast <2 x i64> %168 to <16 x i8>
  %206 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %205, <16 x i8> %21) #9
  %207 = add <8 x i16> %206, %203
  %208 = add <8 x i16> %202, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %209 = add <8 x i16> %208, %204
  %210 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %209, <8 x i16> %207) #9
  %211 = ashr <8 x i16> %210, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %212 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %181, <8 x i16> %201) #9
  %213 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %191, <8 x i16> %211) #9
  %214 = bitcast <16 x i8> %212 to <8 x i16>
  %215 = bitcast <16 x i8> %213 to <8 x i16>
  %216 = shufflevector <8 x i16> %214, <8 x i16> %215, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %217 = shufflevector <8 x i16> %214, <8 x i16> %215, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = bitcast <8 x i16> %217 to <4 x i32>
  %220 = shufflevector <4 x i32> %218, <4 x i32> %219, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %221 = bitcast <4 x i32> %220 to <2 x i64>
  %222 = shufflevector <4 x i32> %218, <4 x i32> %219, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %223 = bitcast <4 x i32> %222 to <2 x i64>
  %224 = extractelement <2 x i64> %221, i32 0
  %225 = bitcast i8* %108 to i64*
  store i64 %224, i64* %225, align 1
  %226 = getelementptr inbounds i8, i8* %108, i64 %34
  %227 = bitcast <4 x i32> %220 to <4 x float>
  %228 = shufflevector <4 x float> %227, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %229 = bitcast i8* %226 to <2 x float>*
  store <2 x float> %228, <2 x float>* %229, align 1
  %230 = getelementptr inbounds i8, i8* %108, i64 %35
  %231 = extractelement <2 x i64> %223, i32 0
  %232 = bitcast i8* %230 to i64*
  store i64 %231, i64* %232, align 1
  %233 = getelementptr inbounds i8, i8* %108, i64 %36
  %234 = bitcast <4 x i32> %222 to <4 x float>
  %235 = shufflevector <4 x float> %234, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %236 = bitcast i8* %233 to <2 x float>*
  store <2 x float> %235, <2 x float>* %236, align 1
  %237 = getelementptr inbounds i8, i8* %108, i64 8
  %238 = add nsw i32 %107, -4
  %239 = icmp eq i32 %238, 0
  br i1 %239, label %240, label %102

240:                                              ; preds = %102
  %241 = getelementptr inbounds i8, i8* %109, i64 %29
  %242 = getelementptr inbounds i8, i8* %237, i64 %38
  %243 = add nsw i32 %41, -8
  %244 = icmp eq i32 %243, 0
  br i1 %244, label %245, label %39

245:                                              ; preds = %240
  %246 = and i32 %11, -8
  %247 = and i32 %15, -4
  %248 = shl nsw i32 %15, 1
  %249 = or i32 %248, 6
  %250 = mul nsw i32 %249, %10
  %251 = sext i32 %250 to i64
  %252 = sub nsw i64 0, %251
  %253 = shl nsw i32 %10, 2
  %254 = sext i32 %253 to i64
  %255 = shl nsw i32 %10, 3
  %256 = sext i32 %255 to i64
  %257 = sext i32 %3 to i64
  %258 = shl nsw i64 %257, 1
  %259 = mul nsw i64 %257, 3
  %260 = shl nsw i32 %3, 2
  %261 = sext i32 %260 to i64
  %262 = mul nsw i32 %247, %3
  %263 = sext i32 %262 to i64
  %264 = sub nsw i64 0, %263
  br label %265

265:                                              ; preds = %245, %359
  %266 = phi i8* [ %363, %359 ], [ %2, %245 ]
  %267 = phi i32 [ %364, %359 ], [ %246, %245 ]
  %268 = phi i8* [ %361, %359 ], [ %7, %245 ]
  %269 = bitcast i8* %268 to <2 x i64>*
  %270 = load <2 x i64>, <2 x i64>* %269, align 1
  %271 = getelementptr inbounds i8, i8* %268, i64 %34
  %272 = bitcast i8* %271 to <2 x i64>*
  %273 = load <2 x i64>, <2 x i64>* %272, align 1
  %274 = getelementptr inbounds i8, i8* %268, i64 %254
  %275 = bitcast i8* %274 to <2 x i64>*
  %276 = load <2 x i64>, <2 x i64>* %275, align 1
  %277 = getelementptr inbounds i8, i8* %268, i64 %38
  br label %278

278:                                              ; preds = %278, %265
  %279 = phi <2 x i64> [ %276, %265 ], [ %295, %278 ]
  %280 = phi <2 x i64> [ %273, %265 ], [ %292, %278 ]
  %281 = phi <2 x i64> [ %270, %265 ], [ %289, %278 ]
  %282 = phi i8* [ %266, %265 ], [ %356, %278 ]
  %283 = phi i32 [ %247, %265 ], [ %357, %278 ]
  %284 = phi i8* [ %277, %265 ], [ %296, %278 ]
  %285 = bitcast i8* %284 to <16 x i8>*
  %286 = load <16 x i8>, <16 x i8>* %285, align 1
  %287 = getelementptr inbounds i8, i8* %284, i64 %34
  %288 = bitcast i8* %287 to <2 x i64>*
  %289 = load <2 x i64>, <2 x i64>* %288, align 1
  %290 = getelementptr inbounds i8, i8* %284, i64 %35
  %291 = bitcast i8* %290 to <2 x i64>*
  %292 = load <2 x i64>, <2 x i64>* %291, align 1
  %293 = getelementptr inbounds i8, i8* %284, i64 %36
  %294 = bitcast i8* %293 to <2 x i64>*
  %295 = load <2 x i64>, <2 x i64>* %294, align 1
  %296 = getelementptr inbounds i8, i8* %284, i64 %256
  %297 = bitcast <2 x i64> %281 to <16 x i8>
  %298 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %297, <16 x i8> %18) #9
  %299 = bitcast <2 x i64> %280 to <16 x i8>
  %300 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %299, <16 x i8> %19) #9
  %301 = bitcast <2 x i64> %279 to <16 x i8>
  %302 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %301, <16 x i8> %20) #9
  %303 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %286, <16 x i8> %21) #9
  %304 = add <8 x i16> %303, %300
  %305 = add <8 x i16> %298, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %306 = add <8 x i16> %305, %302
  %307 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %306, <8 x i16> %304) #9
  %308 = ashr <8 x i16> %307, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %309 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %299, <16 x i8> %18) #9
  %310 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %301, <16 x i8> %19) #9
  %311 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %286, <16 x i8> %20) #9
  %312 = bitcast <2 x i64> %289 to <16 x i8>
  %313 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %312, <16 x i8> %21) #9
  %314 = add <8 x i16> %313, %310
  %315 = add <8 x i16> %309, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %316 = add <8 x i16> %315, %311
  %317 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %316, <8 x i16> %314) #9
  %318 = ashr <8 x i16> %317, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %319 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %301, <16 x i8> %18) #9
  %320 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %286, <16 x i8> %19) #9
  %321 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %312, <16 x i8> %20) #9
  %322 = bitcast <2 x i64> %292 to <16 x i8>
  %323 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %322, <16 x i8> %21) #9
  %324 = add <8 x i16> %323, %320
  %325 = add <8 x i16> %319, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %326 = add <8 x i16> %325, %321
  %327 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %326, <8 x i16> %324) #9
  %328 = ashr <8 x i16> %327, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %329 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %286, <16 x i8> %18) #9
  %330 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %312, <16 x i8> %19) #9
  %331 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %322, <16 x i8> %20) #9
  %332 = bitcast <2 x i64> %295 to <16 x i8>
  %333 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %332, <16 x i8> %21) #9
  %334 = add <8 x i16> %333, %330
  %335 = add <8 x i16> %329, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %336 = add <8 x i16> %335, %331
  %337 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %336, <8 x i16> %334) #9
  %338 = ashr <8 x i16> %337, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %339 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %308, <8 x i16> %318) #9
  %340 = bitcast <16 x i8> %339 to <2 x i64>
  %341 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %328, <8 x i16> %338) #9
  %342 = bitcast <16 x i8> %341 to <2 x i64>
  %343 = extractelement <2 x i64> %340, i32 0
  %344 = bitcast i8* %282 to i64*
  store i64 %343, i64* %344, align 1
  %345 = getelementptr inbounds i8, i8* %282, i64 %257
  %346 = bitcast <16 x i8> %339 to <4 x float>
  %347 = shufflevector <4 x float> %346, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %348 = bitcast i8* %345 to <2 x float>*
  store <2 x float> %347, <2 x float>* %348, align 1
  %349 = getelementptr inbounds i8, i8* %282, i64 %258
  %350 = extractelement <2 x i64> %342, i32 0
  %351 = bitcast i8* %349 to i64*
  store i64 %350, i64* %351, align 1
  %352 = getelementptr inbounds i8, i8* %282, i64 %259
  %353 = bitcast <16 x i8> %341 to <4 x float>
  %354 = shufflevector <4 x float> %353, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %355 = bitcast i8* %352 to <2 x float>*
  store <2 x float> %354, <2 x float>* %355, align 1
  %356 = getelementptr inbounds i8, i8* %282, i64 %261
  %357 = add nsw i32 %283, -4
  %358 = icmp eq i32 %357, 0
  br i1 %358, label %359, label %278

359:                                              ; preds = %278
  %360 = getelementptr inbounds i8, i8* %296, i64 16
  %361 = getelementptr inbounds i8, i8* %360, i64 %252
  %362 = getelementptr inbounds i8, i8* %356, i64 8
  %363 = getelementptr inbounds i8, i8* %362, i64 %264
  %364 = add nsw i32 %267, -8
  %365 = icmp eq i32 %364, 0
  br i1 %365, label %366, label %265

366:                                              ; preds = %359
  ret void
}

; Function Attrs: nounwind
declare void @free(i8* nocapture) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @scale_plane_4_to_1_general(i8* nocapture readonly, i32, i8* nocapture, i32, i32, i32, i16* nocapture readonly, i8* nocapture) unnamed_addr #0 {
  %9 = add nsw i32 %4, 1
  %10 = and i32 %9, -2
  %11 = add nsw i32 %4, 7
  %12 = shl i32 %5, 2
  %13 = add nsw i32 %12, 13
  %14 = and i32 %13, -8
  %15 = add nsw i32 %5, 1
  %16 = bitcast i16* %6 to <16 x i8>*
  %17 = load <16 x i8>, <16 x i8>* %16, align 16
  %18 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2>
  %19 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6>
  %20 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10>
  %21 = shufflevector <16 x i8> %17, <16 x i8> undef, <16 x i32> <i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14>
  %22 = mul i32 %1, -3
  %23 = add i32 %22, -7
  %24 = sext i32 %23 to i64
  %25 = getelementptr inbounds i8, i8* %0, i64 %24
  %26 = shl nsw i32 %1, 3
  %27 = shl nsw i32 %10, 2
  %28 = sub nsw i32 %26, %27
  %29 = sext i32 %28 to i64
  %30 = sext i32 %1 to i64
  %31 = shl nsw i64 %30, 1
  %32 = mul nsw i64 %30, 3
  %33 = shl nsw i64 %30, 2
  %34 = shl nsw i32 %10, 1
  %35 = sext i32 %34 to i64
  %36 = shl nsw i64 %35, 1
  %37 = mul nsw i64 %35, 3
  %38 = mul nsw i32 %10, 6
  %39 = sext i32 %38 to i64
  br label %40

40:                                               ; preds = %215, %8
  %41 = phi i8* [ %25, %8 ], [ %216, %215 ]
  %42 = phi i32 [ %14, %8 ], [ %218, %215 ]
  %43 = phi i8* [ %7, %8 ], [ %217, %215 ]
  %44 = getelementptr inbounds i8, i8* %41, i64 4
  %45 = bitcast i8* %44 to i64*
  %46 = load i64, i64* %45, align 1
  %47 = insertelement <2 x i64> undef, i64 %46, i32 0
  %48 = getelementptr inbounds i8, i8* %44, i64 %30
  %49 = bitcast i8* %48 to i64*
  %50 = load i64, i64* %49, align 1
  %51 = insertelement <2 x i64> undef, i64 %50, i32 0
  %52 = getelementptr inbounds i8, i8* %44, i64 %31
  %53 = bitcast i8* %52 to i64*
  %54 = load i64, i64* %53, align 1
  %55 = insertelement <2 x i64> undef, i64 %54, i32 0
  %56 = getelementptr inbounds i8, i8* %44, i64 %32
  %57 = bitcast i8* %56 to i64*
  %58 = load i64, i64* %57, align 1
  %59 = insertelement <2 x i64> undef, i64 %58, i32 0
  %60 = getelementptr inbounds i8, i8* %44, i64 %33
  %61 = bitcast i8* %60 to i64*
  %62 = load i64, i64* %61, align 1
  %63 = insertelement <2 x i64> undef, i64 %62, i32 0
  %64 = getelementptr inbounds i8, i8* %60, i64 %30
  %65 = bitcast i8* %64 to i64*
  %66 = load i64, i64* %65, align 1
  %67 = insertelement <2 x i64> undef, i64 %66, i32 0
  %68 = getelementptr inbounds i8, i8* %60, i64 %31
  %69 = bitcast i8* %68 to i64*
  %70 = load i64, i64* %69, align 1
  %71 = insertelement <2 x i64> undef, i64 %70, i32 0
  %72 = getelementptr inbounds i8, i8* %60, i64 %32
  %73 = bitcast i8* %72 to i64*
  %74 = load i64, i64* %73, align 1
  %75 = insertelement <2 x i64> undef, i64 %74, i32 0
  %76 = bitcast <2 x i64> %47 to <8 x i16>
  %77 = bitcast <2 x i64> %51 to <8 x i16>
  %78 = shufflevector <8 x i16> %76, <8 x i16> %77, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 undef, i32 undef, i32 undef, i32 undef>
  %79 = bitcast <2 x i64> %55 to <8 x i16>
  %80 = bitcast <2 x i64> %59 to <8 x i16>
  %81 = shufflevector <8 x i16> %79, <8 x i16> %80, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 undef, i32 undef, i32 undef, i32 undef>
  %82 = bitcast <2 x i64> %63 to <8 x i16>
  %83 = bitcast <2 x i64> %67 to <8 x i16>
  %84 = shufflevector <8 x i16> %82, <8 x i16> %83, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 undef, i32 undef, i32 undef, i32 undef>
  %85 = bitcast <2 x i64> %71 to <8 x i16>
  %86 = bitcast <2 x i64> %75 to <8 x i16>
  %87 = shufflevector <8 x i16> %85, <8 x i16> %86, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 undef, i32 undef, i32 undef, i32 undef>
  %88 = bitcast <8 x i16> %78 to <4 x i32>
  %89 = bitcast <8 x i16> %81 to <4 x i32>
  %90 = shufflevector <4 x i32> %88, <4 x i32> %89, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %91 = bitcast <4 x i32> %90 to <2 x i64>
  %92 = bitcast <8 x i16> %84 to <4 x i32>
  %93 = bitcast <8 x i16> %87 to <4 x i32>
  %94 = shufflevector <4 x i32> %92, <4 x i32> %93, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %95 = bitcast <4 x i32> %94 to <2 x i64>
  %96 = shufflevector <2 x i64> %91, <2 x i64> %95, <2 x i32> <i32 0, i32 2>
  %97 = shufflevector <2 x i64> %91, <2 x i64> %95, <2 x i32> <i32 1, i32 3>
  br label %98

98:                                               ; preds = %98, %40
  %99 = phi <2 x i64> [ %97, %40 ], [ %163, %98 ]
  %100 = phi <2 x i64> [ %96, %40 ], [ %162, %98 ]
  %101 = phi i8* [ %41, %40 ], [ %104, %98 ]
  %102 = phi i32 [ %10, %40 ], [ %213, %98 ]
  %103 = phi i8* [ %43, %40 ], [ %212, %98 ]
  %104 = getelementptr inbounds i8, i8* %101, i64 8
  %105 = bitcast i8* %104 to i64*
  %106 = load i64, i64* %105, align 1
  %107 = insertelement <2 x i64> undef, i64 %106, i32 0
  %108 = getelementptr inbounds i8, i8* %104, i64 %30
  %109 = bitcast i8* %108 to i64*
  %110 = load i64, i64* %109, align 1
  %111 = insertelement <2 x i64> undef, i64 %110, i32 0
  %112 = getelementptr inbounds i8, i8* %104, i64 %31
  %113 = bitcast i8* %112 to i64*
  %114 = load i64, i64* %113, align 1
  %115 = insertelement <2 x i64> undef, i64 %114, i32 0
  %116 = getelementptr inbounds i8, i8* %104, i64 %32
  %117 = bitcast i8* %116 to i64*
  %118 = load i64, i64* %117, align 1
  %119 = insertelement <2 x i64> undef, i64 %118, i32 0
  %120 = getelementptr inbounds i8, i8* %104, i64 %33
  %121 = bitcast i8* %120 to i64*
  %122 = load i64, i64* %121, align 1
  %123 = insertelement <2 x i64> undef, i64 %122, i32 0
  %124 = getelementptr inbounds i8, i8* %120, i64 %30
  %125 = bitcast i8* %124 to i64*
  %126 = load i64, i64* %125, align 1
  %127 = insertelement <2 x i64> undef, i64 %126, i32 0
  %128 = getelementptr inbounds i8, i8* %120, i64 %31
  %129 = bitcast i8* %128 to i64*
  %130 = load i64, i64* %129, align 1
  %131 = insertelement <2 x i64> undef, i64 %130, i32 0
  %132 = getelementptr inbounds i8, i8* %120, i64 %32
  %133 = bitcast i8* %132 to i64*
  %134 = load i64, i64* %133, align 1
  %135 = insertelement <2 x i64> undef, i64 %134, i32 0
  %136 = bitcast <2 x i64> %107 to <8 x i16>
  %137 = bitcast <2 x i64> %111 to <8 x i16>
  %138 = shufflevector <8 x i16> %136, <8 x i16> %137, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %139 = bitcast <2 x i64> %115 to <8 x i16>
  %140 = bitcast <2 x i64> %119 to <8 x i16>
  %141 = shufflevector <8 x i16> %139, <8 x i16> %140, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %142 = bitcast <2 x i64> %123 to <8 x i16>
  %143 = bitcast <2 x i64> %127 to <8 x i16>
  %144 = shufflevector <8 x i16> %142, <8 x i16> %143, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %145 = bitcast <2 x i64> %131 to <8 x i16>
  %146 = bitcast <2 x i64> %135 to <8 x i16>
  %147 = shufflevector <8 x i16> %145, <8 x i16> %146, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %148 = bitcast <8 x i16> %138 to <4 x i32>
  %149 = bitcast <8 x i16> %141 to <4 x i32>
  %150 = shufflevector <4 x i32> %148, <4 x i32> %149, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %151 = bitcast <4 x i32> %150 to <2 x i64>
  %152 = bitcast <8 x i16> %144 to <4 x i32>
  %153 = bitcast <8 x i16> %147 to <4 x i32>
  %154 = shufflevector <4 x i32> %152, <4 x i32> %153, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %155 = bitcast <4 x i32> %154 to <2 x i64>
  %156 = shufflevector <4 x i32> %148, <4 x i32> %149, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %157 = bitcast <4 x i32> %156 to <2 x i64>
  %158 = shufflevector <4 x i32> %152, <4 x i32> %153, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %159 = bitcast <4 x i32> %158 to <2 x i64>
  %160 = shufflevector <2 x i64> %151, <2 x i64> %155, <2 x i32> <i32 0, i32 2>
  %161 = shufflevector <2 x i64> %151, <2 x i64> %155, <2 x i32> <i32 1, i32 3>
  %162 = shufflevector <2 x i64> %157, <2 x i64> %159, <2 x i32> <i32 0, i32 2>
  %163 = shufflevector <2 x i64> %157, <2 x i64> %159, <2 x i32> <i32 1, i32 3>
  %164 = bitcast <2 x i64> %100 to <16 x i8>
  %165 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %164, <16 x i8> %18) #9
  %166 = bitcast <2 x i64> %99 to <16 x i8>
  %167 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %166, <16 x i8> %19) #9
  %168 = bitcast <2 x i64> %160 to <16 x i8>
  %169 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %168, <16 x i8> %20) #9
  %170 = bitcast <2 x i64> %161 to <16 x i8>
  %171 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %170, <16 x i8> %21) #9
  %172 = add <8 x i16> %171, %167
  %173 = add <8 x i16> %165, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %174 = add <8 x i16> %173, %169
  %175 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %174, <8 x i16> %172) #9
  %176 = ashr <8 x i16> %175, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %177 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %168, <16 x i8> %18) #9
  %178 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %170, <16 x i8> %19) #9
  %179 = bitcast <2 x i64> %162 to <16 x i8>
  %180 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %179, <16 x i8> %20) #9
  %181 = bitcast <2 x i64> %163 to <16 x i8>
  %182 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %181, <16 x i8> %21) #9
  %183 = add <8 x i16> %182, %178
  %184 = add <8 x i16> %177, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %185 = add <8 x i16> %184, %180
  %186 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %185, <8 x i16> %183) #9
  %187 = ashr <8 x i16> %186, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %188 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %176, <8 x i16> undef) #9
  %189 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %187, <8 x i16> undef) #9
  %190 = bitcast <16 x i8> %188 to <8 x i16>
  %191 = bitcast <16 x i8> %189 to <8 x i16>
  %192 = shufflevector <8 x i16> %190, <8 x i16> %191, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %193 = bitcast <8 x i16> %192 to <16 x i8>
  %194 = shufflevector <16 x i8> %193, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %195 = bitcast <16 x i8> %194 to <4 x i32>
  %196 = shufflevector <16 x i8> %193, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %197 = bitcast <16 x i8> %196 to <4 x i32>
  %198 = shufflevector <16 x i8> %193, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %199 = bitcast <16 x i8> %198 to <4 x i32>
  %200 = bitcast <8 x i16> %192 to <4 x i32>
  %201 = extractelement <4 x i32> %200, i32 0
  %202 = bitcast i8* %103 to i32*
  store i32 %201, i32* %202, align 4
  %203 = extractelement <4 x i32> %195, i32 0
  %204 = getelementptr inbounds i8, i8* %103, i64 %35
  %205 = bitcast i8* %204 to i32*
  store i32 %203, i32* %205, align 4
  %206 = extractelement <4 x i32> %197, i32 0
  %207 = getelementptr inbounds i8, i8* %103, i64 %36
  %208 = bitcast i8* %207 to i32*
  store i32 %206, i32* %208, align 4
  %209 = extractelement <4 x i32> %199, i32 0
  %210 = getelementptr inbounds i8, i8* %103, i64 %37
  %211 = bitcast i8* %210 to i32*
  store i32 %209, i32* %211, align 4
  %212 = getelementptr inbounds i8, i8* %103, i64 4
  %213 = add nsw i32 %102, -2
  %214 = icmp eq i32 %213, 0
  br i1 %214, label %215, label %98

215:                                              ; preds = %98
  %216 = getelementptr inbounds i8, i8* %104, i64 %29
  %217 = getelementptr inbounds i8, i8* %212, i64 %39
  %218 = add nsw i32 %42, -8
  %219 = icmp eq i32 %218, 0
  br i1 %219, label %220, label %40

220:                                              ; preds = %215
  %221 = and i32 %11, -8
  %222 = and i32 %15, -2
  %223 = shl nsw i32 %15, 2
  %224 = or i32 %223, 4
  %225 = mul nsw i32 %224, %10
  %226 = sext i32 %225 to i64
  %227 = sub nsw i64 0, %226
  %228 = sext i32 %27 to i64
  %229 = shl nsw i32 %10, 3
  %230 = sext i32 %229 to i64
  %231 = sext i32 %3 to i64
  %232 = shl nsw i32 %3, 1
  %233 = sext i32 %232 to i64
  %234 = mul nsw i32 %222, %3
  %235 = sext i32 %234 to i64
  %236 = sub nsw i64 0, %235
  br label %237

237:                                              ; preds = %220, %298
  %238 = phi i8* [ %302, %298 ], [ %2, %220 ]
  %239 = phi i32 [ %303, %298 ], [ %221, %220 ]
  %240 = phi i8* [ %300, %298 ], [ %7, %220 ]
  %241 = bitcast i8* %240 to <2 x i64>*
  %242 = load <2 x i64>, <2 x i64>* %241, align 1
  %243 = getelementptr inbounds i8, i8* %240, i64 %35
  %244 = bitcast i8* %243 to <2 x i64>*
  %245 = load <2 x i64>, <2 x i64>* %244, align 1
  %246 = getelementptr inbounds i8, i8* %240, i64 %228
  br label %247

247:                                              ; preds = %247, %237
  %248 = phi <2 x i64> [ %245, %237 ], [ %263, %247 ]
  %249 = phi <2 x i64> [ %242, %237 ], [ %260, %247 ]
  %250 = phi i8* [ %238, %237 ], [ %295, %247 ]
  %251 = phi i32 [ %222, %237 ], [ %296, %247 ]
  %252 = phi i8* [ %246, %237 ], [ %264, %247 ]
  %253 = bitcast i8* %252 to <16 x i8>*
  %254 = load <16 x i8>, <16 x i8>* %253, align 1
  %255 = getelementptr inbounds i8, i8* %252, i64 %35
  %256 = bitcast i8* %255 to <16 x i8>*
  %257 = load <16 x i8>, <16 x i8>* %256, align 1
  %258 = getelementptr inbounds i8, i8* %252, i64 %36
  %259 = bitcast i8* %258 to <2 x i64>*
  %260 = load <2 x i64>, <2 x i64>* %259, align 1
  %261 = getelementptr inbounds i8, i8* %252, i64 %37
  %262 = bitcast i8* %261 to <2 x i64>*
  %263 = load <2 x i64>, <2 x i64>* %262, align 1
  %264 = getelementptr inbounds i8, i8* %252, i64 %230
  %265 = bitcast <2 x i64> %249 to <16 x i8>
  %266 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %265, <16 x i8> %18) #9
  %267 = bitcast <2 x i64> %248 to <16 x i8>
  %268 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %267, <16 x i8> %19) #9
  %269 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %254, <16 x i8> %20) #9
  %270 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %257, <16 x i8> %21) #9
  %271 = add <8 x i16> %270, %268
  %272 = add <8 x i16> %266, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %273 = add <8 x i16> %272, %269
  %274 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %273, <8 x i16> %271) #9
  %275 = ashr <8 x i16> %274, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %276 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %254, <16 x i8> %18) #9
  %277 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %257, <16 x i8> %19) #9
  %278 = bitcast <2 x i64> %260 to <16 x i8>
  %279 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %278, <16 x i8> %20) #9
  %280 = bitcast <2 x i64> %263 to <16 x i8>
  %281 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %280, <16 x i8> %21) #9
  %282 = add <8 x i16> %281, %277
  %283 = add <8 x i16> %276, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %284 = add <8 x i16> %283, %279
  %285 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %284, <8 x i16> %282) #9
  %286 = ashr <8 x i16> %285, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %287 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %275, <8 x i16> %286) #9
  %288 = bitcast <16 x i8> %287 to <2 x i64>
  %289 = extractelement <2 x i64> %288, i32 0
  %290 = bitcast i8* %250 to i64*
  store i64 %289, i64* %290, align 1
  %291 = getelementptr inbounds i8, i8* %250, i64 %231
  %292 = bitcast <16 x i8> %287 to <4 x float>
  %293 = shufflevector <4 x float> %292, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %294 = bitcast i8* %291 to <2 x float>*
  store <2 x float> %293, <2 x float>* %294, align 1
  %295 = getelementptr inbounds i8, i8* %250, i64 %233
  %296 = add nsw i32 %251, -2
  %297 = icmp eq i32 %296, 0
  br i1 %297, label %298, label %247

298:                                              ; preds = %247
  %299 = getelementptr inbounds i8, i8* %264, i64 16
  %300 = getelementptr inbounds i8, i8* %299, i64 %227
  %301 = getelementptr inbounds i8, i8* %295, i64 8
  %302 = getelementptr inbounds i8, i8* %301, i64 %236
  %303 = add nsw i32 %239, -8
  %304 = icmp eq i32 %303, 0
  br i1 %304, label %305, label %237

305:                                              ; preds = %298
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @scale_plane_4_to_3_general(i8* nocapture readonly, i32, i8* nocapture, i32, i32, i32, [8 x i16]*, i32, i8* nocapture) unnamed_addr #0 {
  %10 = alloca [12 x <2 x i64>], align 16
  %11 = alloca [5 x <2 x i64>], align 16
  %12 = alloca [5 x <2 x i64>], align 16
  %13 = add nsw i32 %4, 5
  %14 = srem i32 %13, 6
  %15 = sub nsw i32 %13, %14
  %16 = shl nsw i32 %15, 1
  %17 = add nsw i32 %16, 4
  %18 = add nsw i32 %4, 7
  %19 = shl nsw i32 %5, 2
  %20 = sdiv i32 %19, 3
  %21 = add nsw i32 %20, 14
  %22 = and i32 %21, -8
  %23 = add nsw i32 %5, 5
  %24 = srem i32 %23, 6
  %25 = bitcast [12 x <2 x i64>]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 192, i8* nonnull %25) #9
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %25, i8 -86, i64 192, i1 false)
  %26 = bitcast [5 x <2 x i64>]* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %26) #9
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %26, i8 -86, i64 80, i1 false)
  %27 = bitcast [5 x <2 x i64>]* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %27) #9
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %27, i8 -86, i64 80, i1 false)
  %28 = add nsw i32 %7, 21
  %29 = add nsw i32 %7, 42
  %30 = lshr i32 %28, 4
  %31 = and i32 %30, 1
  %32 = lshr i32 %29, 4
  %33 = and i32 %32, 1
  %34 = and i32 %7, 15
  %35 = zext i32 %34 to i64
  %36 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 %35, i64 0
  %37 = bitcast i16* %36 to <16 x i8>*
  %38 = load <16 x i8>, <16 x i8>* %37, align 16
  %39 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2>
  %40 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10>
  %41 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14>
  %42 = zext i32 %31 to i64
  %43 = getelementptr inbounds [2 x void (i16*, <2 x i64>*)*], [2 x void (i16*, <2 x i64>*)*]* @scale_plane_4_to_3_general.shuffle_filter_funcs, i64 0, i64 %42
  %44 = load void (i16*, <2 x i64>*)*, void (i16*, <2 x i64>*)** %43, align 8
  %45 = and i32 %28, 15
  %46 = zext i32 %45 to i64
  %47 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 %46, i64 0
  %48 = getelementptr inbounds [5 x <2 x i64>], [5 x <2 x i64>]* %11, i64 0, i64 0
  call void %44(i16* %47, <2 x i64>* nonnull %48) #9
  %49 = zext i32 %33 to i64
  %50 = getelementptr inbounds [2 x void (i16*, <2 x i64>*)*], [2 x void (i16*, <2 x i64>*)*]* @scale_plane_4_to_3_general.shuffle_filter_funcs, i64 0, i64 %49
  %51 = load void (i16*, <2 x i64>*)*, void (i16*, <2 x i64>*)** %50, align 8
  %52 = and i32 %29, 15
  %53 = zext i32 %52 to i64
  %54 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 %53, i64 0
  %55 = getelementptr inbounds [5 x <2 x i64>], [5 x <2 x i64>]* %12, i64 0, i64 0
  call void %51(i16* %54, <2 x i64>* nonnull %55) #9
  %56 = add <16 x i8> %38, <i8 undef, i8 undef, i8 undef, i8 undef, i8 -64, i8 undef, i8 -64, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %57 = shufflevector <16 x i8> %56, <16 x i8> undef, <16 x i32> <i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6>
  %58 = add nuw nsw i32 %31, 1
  %59 = zext i32 %58 to i64
  %60 = getelementptr inbounds [5 x <2 x i64>], [5 x <2 x i64>]* %11, i64 0, i64 %59
  %61 = bitcast <2 x i64>* %60 to <16 x i8>*
  %62 = load <16 x i8>, <16 x i8>* %61, align 16
  %63 = add <16 x i8> %62, <i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64>
  store <16 x i8> %63, <16 x i8>* %61, align 16
  %64 = add nuw nsw i32 %33, 1
  %65 = zext i32 %64 to i64
  %66 = getelementptr inbounds [5 x <2 x i64>], [5 x <2 x i64>]* %12, i64 0, i64 %65
  %67 = bitcast <2 x i64>* %66 to <16 x i8>*
  %68 = load <16 x i8>, <16 x i8>* %67, align 16
  %69 = add <16 x i8> %68, <i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64>
  store <16 x i8> %69, <16 x i8>* %67, align 16
  %70 = mul i32 %1, -3
  %71 = add i32 %70, -3
  %72 = sext i32 %71 to i64
  %73 = getelementptr inbounds i8, i8* %0, i64 %72
  %74 = shl nsw i32 %1, 3
  %75 = shl nsw i32 %15, 2
  %76 = sdiv i32 %75, 3
  %77 = sub nsw i32 %74, %76
  %78 = sext i32 %77 to i64
  %79 = sext i32 %1 to i64
  %80 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 0
  %81 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 1
  %82 = shl nsw i64 %79, 1
  %83 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 2
  %84 = mul nsw i64 %79, 3
  %85 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 3
  %86 = shl nsw i64 %79, 2
  %87 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 4
  %88 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 5
  %89 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 6
  %90 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 7
  %91 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 8
  %92 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 9
  %93 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 10
  %94 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 11
  %95 = bitcast <2 x i64>* %83 to <16 x i8>*
  %96 = bitcast <2 x i64>* %85 to <16 x i8>*
  %97 = getelementptr inbounds [2 x <2 x i64> (<2 x i64>*, <2 x i64>*)*], [2 x <2 x i64> (<2 x i64>*, <2 x i64>*)*]* @scale_plane_4_to_3_general.convolve8_funcs, i64 0, i64 %42
  %98 = load <2 x i64> (<2 x i64>*, <2 x i64>*)*, <2 x i64> (<2 x i64>*, <2 x i64>*)** %97, align 8
  %99 = ashr i32 %28, 5
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 %100
  %102 = getelementptr inbounds [2 x <2 x i64> (<2 x i64>*, <2 x i64>*)*], [2 x <2 x i64> (<2 x i64>*, <2 x i64>*)*]* @scale_plane_4_to_3_general.convolve8_funcs, i64 0, i64 %49
  %103 = ashr i32 %29, 5
  %104 = sext i32 %103 to i64
  %105 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 %104
  %106 = bitcast <2 x i64>* %87 to <16 x i8>*
  %107 = bitcast <2 x i64>* %88 to <16 x i8>*
  %108 = add nsw i32 %99, 2
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 %109
  %111 = add nsw i32 %103, 2
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %10, i64 0, i64 %112
  %114 = sext i32 %17 to i64
  %115 = shl nsw i64 %114, 1
  %116 = mul nsw i64 %114, 3
  %117 = mul nsw i32 %17, 3
  %118 = add nsw i32 %117, 4
  %119 = sext i32 %118 to i64
  br label %120

120:                                              ; preds = %330, %9
  %121 = phi i8* [ %73, %9 ], [ %331, %330 ]
  %122 = phi i32 [ %22, %9 ], [ %333, %330 ]
  %123 = phi i8* [ %8, %9 ], [ %332, %330 ]
  %124 = bitcast i8* %121 to i64*
  %125 = load i64, i64* %124, align 1
  %126 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %125, i32 0
  store <2 x i64> %126, <2 x i64>* %80, align 16
  %127 = getelementptr inbounds i8, i8* %121, i64 %79
  %128 = bitcast i8* %127 to i64*
  %129 = load i64, i64* %128, align 1
  %130 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %129, i32 0
  store <2 x i64> %130, <2 x i64>* %81, align 16
  %131 = getelementptr inbounds i8, i8* %121, i64 %82
  %132 = bitcast i8* %131 to i64*
  %133 = load i64, i64* %132, align 1
  %134 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %133, i32 0
  store <2 x i64> %134, <2 x i64>* %83, align 16
  %135 = getelementptr inbounds i8, i8* %121, i64 %84
  %136 = bitcast i8* %135 to i64*
  %137 = load i64, i64* %136, align 1
  %138 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %137, i32 0
  store <2 x i64> %138, <2 x i64>* %85, align 16
  %139 = getelementptr inbounds i8, i8* %121, i64 %86
  %140 = bitcast i8* %139 to i64*
  %141 = load i64, i64* %140, align 1
  %142 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %141, i32 0
  store <2 x i64> %142, <2 x i64>* %87, align 16
  %143 = getelementptr inbounds i8, i8* %139, i64 %79
  %144 = bitcast i8* %143 to i64*
  %145 = load i64, i64* %144, align 1
  %146 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %145, i32 0
  store <2 x i64> %146, <2 x i64>* %88, align 16
  %147 = getelementptr inbounds i8, i8* %139, i64 %82
  %148 = bitcast i8* %147 to i64*
  %149 = load i64, i64* %148, align 1
  %150 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %149, i32 0
  store <2 x i64> %150, <2 x i64>* %89, align 16
  %151 = getelementptr inbounds i8, i8* %139, i64 %84
  %152 = bitcast i8* %151 to i64*
  %153 = load i64, i64* %152, align 1
  %154 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %153, i32 0
  store <2 x i64> %154, <2 x i64>* %90, align 16
  %155 = bitcast <2 x i64> %126 to <8 x i16>
  %156 = bitcast <2 x i64> %130 to <8 x i16>
  %157 = shufflevector <8 x i16> %155, <8 x i16> %156, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %158 = bitcast <2 x i64> %134 to <8 x i16>
  %159 = bitcast <2 x i64> %138 to <8 x i16>
  %160 = shufflevector <8 x i16> %158, <8 x i16> %159, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %161 = bitcast <2 x i64> %142 to <8 x i16>
  %162 = bitcast <2 x i64> %146 to <8 x i16>
  %163 = shufflevector <8 x i16> %161, <8 x i16> %162, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %164 = bitcast <2 x i64> %150 to <8 x i16>
  %165 = bitcast <2 x i64> %154 to <8 x i16>
  %166 = shufflevector <8 x i16> %164, <8 x i16> %165, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %167 = bitcast <8 x i16> %157 to <4 x i32>
  %168 = bitcast <8 x i16> %160 to <4 x i32>
  %169 = shufflevector <4 x i32> %167, <4 x i32> %168, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %170 = bitcast <4 x i32> %169 to <2 x i64>
  %171 = bitcast <8 x i16> %163 to <4 x i32>
  %172 = bitcast <8 x i16> %166 to <4 x i32>
  %173 = shufflevector <4 x i32> %171, <4 x i32> %172, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %174 = bitcast <4 x i32> %173 to <2 x i64>
  %175 = shufflevector <4 x i32> %167, <4 x i32> %168, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %176 = bitcast <4 x i32> %175 to <2 x i64>
  %177 = shufflevector <4 x i32> %171, <4 x i32> %172, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %178 = bitcast <4 x i32> %177 to <2 x i64>
  %179 = shufflevector <2 x i64> %170, <2 x i64> %174, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %179, <2 x i64>* %80, align 16
  %180 = shufflevector <2 x i64> %170, <2 x i64> %174, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %180, <2 x i64>* %81, align 16
  %181 = shufflevector <2 x i64> %176, <2 x i64> %178, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %181, <2 x i64>* %83, align 16
  %182 = shufflevector <2 x i64> %176, <2 x i64> %178, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %182, <2 x i64>* %85, align 16
  br label %183

183:                                              ; preds = %183, %120
  %184 = phi <2 x i64> [ %182, %120 ], [ %326, %183 ]
  %185 = phi <2 x i64> [ %181, %120 ], [ %325, %183 ]
  %186 = phi <2 x i64> [ %180, %120 ], [ %324, %183 ]
  %187 = phi <2 x i64> [ %179, %120 ], [ %323, %183 ]
  %188 = phi i8* [ %121, %120 ], [ %195, %183 ]
  %189 = phi i32 [ %15, %120 ], [ %328, %183 ]
  %190 = phi i8* [ %123, %120 ], [ %327, %183 ]
  %191 = bitcast <2 x i64> %184 to <16 x i8>
  %192 = bitcast <2 x i64> %185 to <16 x i8>
  %193 = bitcast <2 x i64> %186 to <16 x i8>
  %194 = bitcast <2 x i64> %187 to <16 x i8>
  %195 = getelementptr inbounds i8, i8* %188, i64 8
  %196 = bitcast i8* %195 to i64*
  %197 = load i64, i64* %196, align 1
  %198 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %197, i32 0
  store <2 x i64> %198, <2 x i64>* %87, align 16
  %199 = getelementptr inbounds i8, i8* %195, i64 %79
  %200 = bitcast i8* %199 to i64*
  %201 = load i64, i64* %200, align 1
  %202 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %201, i32 0
  store <2 x i64> %202, <2 x i64>* %88, align 16
  %203 = getelementptr inbounds i8, i8* %195, i64 %82
  %204 = bitcast i8* %203 to i64*
  %205 = load i64, i64* %204, align 1
  %206 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %205, i32 0
  store <2 x i64> %206, <2 x i64>* %89, align 16
  %207 = getelementptr inbounds i8, i8* %195, i64 %84
  %208 = bitcast i8* %207 to i64*
  %209 = load i64, i64* %208, align 1
  %210 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %209, i32 0
  store <2 x i64> %210, <2 x i64>* %90, align 16
  %211 = getelementptr inbounds i8, i8* %195, i64 %86
  %212 = bitcast i8* %211 to i64*
  %213 = load i64, i64* %212, align 1
  %214 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %213, i32 0
  store <2 x i64> %214, <2 x i64>* %91, align 16
  %215 = getelementptr inbounds i8, i8* %211, i64 %79
  %216 = bitcast i8* %215 to i64*
  %217 = load i64, i64* %216, align 1
  %218 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %217, i32 0
  store <2 x i64> %218, <2 x i64>* %92, align 16
  %219 = getelementptr inbounds i8, i8* %211, i64 %82
  %220 = bitcast i8* %219 to i64*
  %221 = load i64, i64* %220, align 1
  %222 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %221, i32 0
  store <2 x i64> %222, <2 x i64>* %93, align 16
  %223 = getelementptr inbounds i8, i8* %211, i64 %84
  %224 = bitcast i8* %223 to i64*
  %225 = load i64, i64* %224, align 1
  %226 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %225, i32 0
  store <2 x i64> %226, <2 x i64>* %94, align 16
  %227 = bitcast <2 x i64> %198 to <8 x i16>
  %228 = bitcast <2 x i64> %202 to <8 x i16>
  %229 = shufflevector <8 x i16> %227, <8 x i16> %228, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %230 = bitcast <2 x i64> %206 to <8 x i16>
  %231 = bitcast <2 x i64> %210 to <8 x i16>
  %232 = shufflevector <8 x i16> %230, <8 x i16> %231, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %233 = bitcast <2 x i64> %214 to <8 x i16>
  %234 = bitcast <2 x i64> %218 to <8 x i16>
  %235 = shufflevector <8 x i16> %233, <8 x i16> %234, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %236 = bitcast <2 x i64> %222 to <8 x i16>
  %237 = bitcast <2 x i64> %226 to <8 x i16>
  %238 = shufflevector <8 x i16> %236, <8 x i16> %237, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %239 = bitcast <8 x i16> %229 to <4 x i32>
  %240 = bitcast <8 x i16> %232 to <4 x i32>
  %241 = shufflevector <4 x i32> %239, <4 x i32> %240, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %242 = bitcast <4 x i32> %241 to <2 x i64>
  %243 = bitcast <8 x i16> %235 to <4 x i32>
  %244 = bitcast <8 x i16> %238 to <4 x i32>
  %245 = shufflevector <4 x i32> %243, <4 x i32> %244, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %246 = bitcast <4 x i32> %245 to <2 x i64>
  %247 = shufflevector <4 x i32> %239, <4 x i32> %240, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %248 = bitcast <4 x i32> %247 to <2 x i64>
  %249 = shufflevector <4 x i32> %243, <4 x i32> %244, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %250 = bitcast <4 x i32> %249 to <2 x i64>
  %251 = shufflevector <2 x i64> %242, <2 x i64> %246, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %251, <2 x i64>* %87, align 16
  %252 = shufflevector <2 x i64> %242, <2 x i64> %246, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %252, <2 x i64>* %88, align 16
  %253 = shufflevector <2 x i64> %248, <2 x i64> %250, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %253, <2 x i64>* %89, align 16
  %254 = shufflevector <2 x i64> %248, <2 x i64> %250, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %254, <2 x i64>* %90, align 16
  %255 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %194, <16 x i8> %39) #9
  %256 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %193, <16 x i8> %57) #9
  %257 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %192, <16 x i8> %40) #9
  %258 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %191, <16 x i8> %41) #9
  %259 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %193, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>) #9
  %260 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %255, <8 x i16> %258) #9
  %261 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %260, <8 x i16> %256) #9
  %262 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %261, <8 x i16> %257) #9
  %263 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %262, <8 x i16> %259) #9
  %264 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %263, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %265 = ashr <8 x i16> %264, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %266 = call <2 x i64> %98(<2 x i64>* %101, <2 x i64>* nonnull %48) #9
  %267 = load <2 x i64> (<2 x i64>*, <2 x i64>*)*, <2 x i64> (<2 x i64>*, <2 x i64>*)** %102, align 8
  %268 = call <2 x i64> %267(<2 x i64>* %105, <2 x i64>* nonnull %55) #9
  %269 = load <16 x i8>, <16 x i8>* %95, align 16
  %270 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %269, <16 x i8> %39) #9
  %271 = load <16 x i8>, <16 x i8>* %96, align 16
  %272 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %271, <16 x i8> %57) #9
  %273 = load <16 x i8>, <16 x i8>* %106, align 16
  %274 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %273, <16 x i8> %40) #9
  %275 = load <16 x i8>, <16 x i8>* %107, align 16
  %276 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %275, <16 x i8> %41) #9
  %277 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %271, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>) #9
  %278 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %270, <8 x i16> %276) #9
  %279 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %278, <8 x i16> %272) #9
  %280 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %279, <8 x i16> %274) #9
  %281 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %280, <8 x i16> %277) #9
  %282 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %281, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %283 = ashr <8 x i16> %282, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %284 = call <2 x i64> %98(<2 x i64>* %110, <2 x i64>* nonnull %48) #9
  %285 = call <2 x i64> %267(<2 x i64>* %113, <2 x i64>* nonnull %55) #9
  %286 = bitcast <2 x i64> %268 to <8 x i16>
  %287 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %265, <8 x i16> %286) #9
  %288 = bitcast <2 x i64> %266 to <8 x i16>
  %289 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %288, <8 x i16> %283) #9
  %290 = bitcast <2 x i64> %284 to <8 x i16>
  %291 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %290, <8 x i16> undef) #9
  %292 = bitcast <2 x i64> %285 to <8 x i16>
  %293 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %292, <8 x i16> undef) #9
  %294 = bitcast <16 x i8> %287 to <8 x i16>
  %295 = bitcast <16 x i8> %289 to <8 x i16>
  %296 = shufflevector <8 x i16> %294, <8 x i16> %295, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %297 = shufflevector <8 x i16> %294, <8 x i16> %295, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %298 = bitcast <16 x i8> %291 to <8 x i16>
  %299 = bitcast <16 x i8> %293 to <8 x i16>
  %300 = shufflevector <8 x i16> %298, <8 x i16> %299, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %301 = bitcast <8 x i16> %296 to <4 x i32>
  %302 = bitcast <8 x i16> %297 to <4 x i32>
  %303 = shufflevector <4 x i32> %301, <4 x i32> %302, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %304 = bitcast <4 x i32> %303 to <2 x i64>
  %305 = shufflevector <4 x i32> %301, <4 x i32> %302, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %306 = bitcast <4 x i32> %305 to <2 x i64>
  %307 = bitcast <8 x i16> %300 to <4 x i32>
  %308 = shufflevector <4 x i32> %307, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %309 = bitcast <4 x i32> %308 to <2 x i64>
  %310 = shufflevector <4 x i32> %307, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %311 = bitcast <4 x i32> %310 to <2 x i64>
  %312 = shufflevector <2 x i64> %304, <2 x i64> %309, <2 x i32> <i32 0, i32 2>
  %313 = shufflevector <2 x i64> %304, <2 x i64> %309, <2 x i32> <i32 1, i32 3>
  %314 = shufflevector <2 x i64> %306, <2 x i64> %311, <2 x i32> <i32 0, i32 2>
  %315 = shufflevector <2 x i64> %306, <2 x i64> %311, <2 x i32> <i32 1, i32 3>
  %316 = bitcast i8* %190 to <2 x i64>*
  store <2 x i64> %312, <2 x i64>* %316, align 1
  %317 = getelementptr inbounds i8, i8* %190, i64 %114
  %318 = bitcast i8* %317 to <2 x i64>*
  store <2 x i64> %313, <2 x i64>* %318, align 1
  %319 = getelementptr inbounds i8, i8* %190, i64 %115
  %320 = bitcast i8* %319 to <2 x i64>*
  store <2 x i64> %314, <2 x i64>* %320, align 1
  %321 = getelementptr inbounds i8, i8* %190, i64 %116
  %322 = bitcast i8* %321 to <2 x i64>*
  store <2 x i64> %315, <2 x i64>* %322, align 1
  %323 = load <2 x i64>, <2 x i64>* %87, align 16
  store <2 x i64> %323, <2 x i64>* %80, align 16
  %324 = load <2 x i64>, <2 x i64>* %88, align 16
  store <2 x i64> %324, <2 x i64>* %81, align 16
  %325 = load <2 x i64>, <2 x i64>* %89, align 16
  store <2 x i64> %325, <2 x i64>* %83, align 16
  %326 = load <2 x i64>, <2 x i64>* %90, align 16
  store <2 x i64> %326, <2 x i64>* %85, align 16
  %327 = getelementptr inbounds i8, i8* %190, i64 12
  %328 = add nsw i32 %189, -6
  %329 = icmp eq i32 %328, 0
  br i1 %329, label %330, label %183

330:                                              ; preds = %183
  %331 = getelementptr inbounds i8, i8* %195, i64 %78
  %332 = getelementptr inbounds i8, i8* %327, i64 %119
  %333 = add nsw i32 %122, -8
  %334 = icmp eq i32 %333, 0
  br i1 %334, label %335, label %120

335:                                              ; preds = %330
  %336 = and i32 %18, -8
  %337 = sub nsw i32 %23, %24
  %338 = shl i32 %337, 1
  %339 = mul i32 %338, %17
  %340 = sdiv i32 %339, -3
  %341 = sext i32 %340 to i64
  %342 = shl nsw i32 %17, 2
  %343 = sext i32 %342 to i64
  %344 = sext i32 %3 to i64
  %345 = shl nsw i32 %3, 1
  %346 = sext i32 %345 to i64
  %347 = mul nsw i32 %3, 3
  %348 = sext i32 %347 to i64
  %349 = shl nsw i32 %3, 2
  %350 = sext i32 %349 to i64
  %351 = mul nsw i32 %3, 5
  %352 = sext i32 %351 to i64
  %353 = mul nsw i32 %3, 6
  %354 = sext i32 %353 to i64
  %355 = mul nsw i32 %337, %3
  %356 = sext i32 %355 to i64
  %357 = sub nsw i64 0, %356
  br label %358

358:                                              ; preds = %335, %464
  %359 = phi i8* [ %468, %464 ], [ %2, %335 ]
  %360 = phi i32 [ %469, %464 ], [ %336, %335 ]
  %361 = phi i8* [ %466, %464 ], [ %8, %335 ]
  %362 = bitcast i8* %361 to <2 x i64>*
  %363 = load <2 x i64>, <2 x i64>* %362, align 1
  store <2 x i64> %363, <2 x i64>* %80, align 16
  %364 = getelementptr inbounds i8, i8* %361, i64 %114
  %365 = bitcast i8* %364 to <2 x i64>*
  %366 = load <2 x i64>, <2 x i64>* %365, align 1
  store <2 x i64> %366, <2 x i64>* %81, align 16
  %367 = getelementptr inbounds i8, i8* %361, i64 %115
  %368 = bitcast i8* %367 to <2 x i64>*
  %369 = load <2 x i64>, <2 x i64>* %368, align 1
  store <2 x i64> %369, <2 x i64>* %83, align 16
  %370 = getelementptr inbounds i8, i8* %361, i64 %116
  %371 = bitcast i8* %370 to <2 x i64>*
  %372 = load <2 x i64>, <2 x i64>* %371, align 1
  store <2 x i64> %372, <2 x i64>* %85, align 16
  br label %373

373:                                              ; preds = %373, %358
  %374 = phi <2 x i64> [ %372, %358 ], [ %460, %373 ]
  %375 = phi <2 x i64> [ %369, %358 ], [ %459, %373 ]
  %376 = phi <2 x i64> [ %366, %358 ], [ %458, %373 ]
  %377 = phi <2 x i64> [ %363, %358 ], [ %457, %373 ]
  %378 = phi i8* [ %359, %358 ], [ %461, %373 ]
  %379 = phi i32 [ %337, %358 ], [ %462, %373 ]
  %380 = phi i8* [ %361, %358 ], [ %385, %373 ]
  %381 = bitcast <2 x i64> %374 to <16 x i8>
  %382 = bitcast <2 x i64> %375 to <16 x i8>
  %383 = bitcast <2 x i64> %376 to <16 x i8>
  %384 = bitcast <2 x i64> %377 to <16 x i8>
  %385 = getelementptr inbounds i8, i8* %380, i64 %343
  %386 = bitcast i8* %385 to <2 x i64>*
  %387 = load <2 x i64>, <2 x i64>* %386, align 1
  store <2 x i64> %387, <2 x i64>* %87, align 16
  %388 = getelementptr inbounds i8, i8* %385, i64 %114
  %389 = bitcast i8* %388 to <2 x i64>*
  %390 = load <2 x i64>, <2 x i64>* %389, align 1
  store <2 x i64> %390, <2 x i64>* %88, align 16
  %391 = getelementptr inbounds i8, i8* %385, i64 %115
  %392 = bitcast i8* %391 to <2 x i64>*
  %393 = load <2 x i64>, <2 x i64>* %392, align 1
  store <2 x i64> %393, <2 x i64>* %89, align 16
  %394 = getelementptr inbounds i8, i8* %385, i64 %116
  %395 = bitcast i8* %394 to <2 x i64>*
  %396 = load <2 x i64>, <2 x i64>* %395, align 1
  store <2 x i64> %396, <2 x i64>* %90, align 16
  %397 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %384, <16 x i8> %39) #9
  %398 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %383, <16 x i8> %57) #9
  %399 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %382, <16 x i8> %40) #9
  %400 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %381, <16 x i8> %41) #9
  %401 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %383, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>) #9
  %402 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %397, <8 x i16> %400) #9
  %403 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %402, <8 x i16> %398) #9
  %404 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %403, <8 x i16> %399) #9
  %405 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %404, <8 x i16> %401) #9
  %406 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %405, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %407 = ashr <8 x i16> %406, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %408 = call <2 x i64> %98(<2 x i64>* %101, <2 x i64>* nonnull %48) #9
  %409 = call <2 x i64> %267(<2 x i64>* %105, <2 x i64>* nonnull %55) #9
  %410 = load <16 x i8>, <16 x i8>* %95, align 16
  %411 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %410, <16 x i8> %39) #9
  %412 = load <16 x i8>, <16 x i8>* %96, align 16
  %413 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %412, <16 x i8> %57) #9
  %414 = load <16 x i8>, <16 x i8>* %106, align 16
  %415 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %414, <16 x i8> %40) #9
  %416 = load <16 x i8>, <16 x i8>* %107, align 16
  %417 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %416, <16 x i8> %41) #9
  %418 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %412, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>) #9
  %419 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %411, <8 x i16> %417) #9
  %420 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %419, <8 x i16> %413) #9
  %421 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %420, <8 x i16> %415) #9
  %422 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %421, <8 x i16> %418) #9
  %423 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %422, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %424 = ashr <8 x i16> %423, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %425 = call <2 x i64> %98(<2 x i64>* %110, <2 x i64>* nonnull %48) #9
  %426 = call <2 x i64> %267(<2 x i64>* %113, <2 x i64>* nonnull %55) #9
  %427 = bitcast <2 x i64> %408 to <8 x i16>
  %428 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %407, <8 x i16> %427) #9
  %429 = bitcast <16 x i8> %428 to <2 x i64>
  %430 = bitcast <2 x i64> %409 to <8 x i16>
  %431 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %430, <8 x i16> %424) #9
  %432 = bitcast <16 x i8> %431 to <2 x i64>
  %433 = bitcast <2 x i64> %425 to <8 x i16>
  %434 = bitcast <2 x i64> %426 to <8 x i16>
  %435 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %433, <8 x i16> %434) #9
  %436 = bitcast <16 x i8> %435 to <2 x i64>
  %437 = extractelement <2 x i64> %429, i32 0
  %438 = bitcast i8* %378 to i64*
  store i64 %437, i64* %438, align 1
  %439 = getelementptr inbounds i8, i8* %378, i64 %344
  %440 = bitcast <16 x i8> %428 to <4 x float>
  %441 = shufflevector <4 x float> %440, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %442 = bitcast i8* %439 to <2 x float>*
  store <2 x float> %441, <2 x float>* %442, align 1
  %443 = getelementptr inbounds i8, i8* %378, i64 %346
  %444 = extractelement <2 x i64> %432, i32 0
  %445 = bitcast i8* %443 to i64*
  store i64 %444, i64* %445, align 1
  %446 = getelementptr inbounds i8, i8* %378, i64 %348
  %447 = bitcast <16 x i8> %431 to <4 x float>
  %448 = shufflevector <4 x float> %447, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %449 = bitcast i8* %446 to <2 x float>*
  store <2 x float> %448, <2 x float>* %449, align 1
  %450 = getelementptr inbounds i8, i8* %378, i64 %350
  %451 = extractelement <2 x i64> %436, i32 0
  %452 = bitcast i8* %450 to i64*
  store i64 %451, i64* %452, align 1
  %453 = getelementptr inbounds i8, i8* %378, i64 %352
  %454 = bitcast <16 x i8> %435 to <4 x float>
  %455 = shufflevector <4 x float> %454, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %456 = bitcast i8* %453 to <2 x float>*
  store <2 x float> %455, <2 x float>* %456, align 1
  %457 = load <2 x i64>, <2 x i64>* %87, align 16
  store <2 x i64> %457, <2 x i64>* %80, align 16
  %458 = load <2 x i64>, <2 x i64>* %88, align 16
  store <2 x i64> %458, <2 x i64>* %81, align 16
  %459 = load <2 x i64>, <2 x i64>* %89, align 16
  store <2 x i64> %459, <2 x i64>* %83, align 16
  %460 = load <2 x i64>, <2 x i64>* %90, align 16
  store <2 x i64> %460, <2 x i64>* %85, align 16
  %461 = getelementptr inbounds i8, i8* %378, i64 %354
  %462 = add nsw i32 %379, -6
  %463 = icmp eq i32 %462, 0
  br i1 %463, label %464, label %373

464:                                              ; preds = %373
  %465 = getelementptr inbounds i8, i8* %385, i64 16
  %466 = getelementptr inbounds i8, i8* %465, i64 %341
  %467 = getelementptr inbounds i8, i8* %461, i64 8
  %468 = getelementptr inbounds i8, i8* %467, i64 %357
  %469 = add nsw i32 %360, -8
  %470 = icmp eq i32 %469, 0
  br i1 %470, label %471, label %358

471:                                              ; preds = %464
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %27) #9
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %26) #9
  call void @llvm.lifetime.end.p0i8(i64 192, i8* nonnull %25) #9
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @scale_plane_1_to_2_phase_0(i8* nocapture readonly, i64, i8* nocapture, i64, i32, i32, i16* nocapture readonly, i8* nocapture) unnamed_addr #0 {
  %9 = add nsw i32 %4, 7
  %10 = and i32 %9, -8
  %11 = sext i32 %10 to i64
  %12 = shl nsw i32 %10, 1
  %13 = sext i32 %12 to i64
  %14 = mul nsw i32 %10, 3
  %15 = sext i32 %14 to i64
  %16 = shl nsw i32 %10, 2
  %17 = sext i32 %16 to i64
  %18 = mul nsw i32 %10, 5
  %19 = sext i32 %18 to i64
  %20 = mul nsw i32 %10, 6
  %21 = sext i32 %20 to i64
  %22 = mul nsw i32 %10, 7
  %23 = sext i32 %22 to i64
  %24 = bitcast i16* %6 to <16 x i8>*
  %25 = load <16 x i8>, <16 x i8>* %24, align 16
  %26 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2>
  %27 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6>
  %28 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10>
  %29 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14>
  %30 = mul nsw i64 %1, 3
  %31 = sub i64 0, %30
  %32 = getelementptr inbounds i8, i8* %0, i64 %31
  %33 = getelementptr inbounds i8, i8* %32, i64 -3
  br label %34

34:                                               ; preds = %34, %8
  %35 = phi i8* [ %7, %8 ], [ %95, %34 ]
  %36 = phi i32 [ %10, %8 ], [ %96, %34 ]
  %37 = phi i8* [ %33, %8 ], [ %94, %34 ]
  %38 = bitcast i8* %37 to i64*
  %39 = load i64, i64* %38, align 1
  %40 = insertelement <2 x i64> undef, i64 %39, i32 0
  %41 = getelementptr inbounds i8, i8* %37, i64 1
  %42 = bitcast i8* %41 to i64*
  %43 = load i64, i64* %42, align 1
  %44 = insertelement <2 x i64> undef, i64 %43, i32 0
  %45 = getelementptr inbounds i8, i8* %37, i64 2
  %46 = bitcast i8* %45 to i64*
  %47 = load i64, i64* %46, align 1
  %48 = insertelement <2 x i64> undef, i64 %47, i32 0
  %49 = getelementptr inbounds i8, i8* %37, i64 3
  %50 = bitcast i8* %49 to i64*
  %51 = load i64, i64* %50, align 1
  %52 = insertelement <2 x i64> undef, i64 %51, i32 0
  %53 = getelementptr inbounds i8, i8* %37, i64 4
  %54 = bitcast i8* %53 to i64*
  %55 = load i64, i64* %54, align 1
  %56 = insertelement <2 x i64> undef, i64 %55, i32 0
  %57 = getelementptr inbounds i8, i8* %37, i64 5
  %58 = bitcast i8* %57 to i64*
  %59 = load i64, i64* %58, align 1
  %60 = insertelement <2 x i64> undef, i64 %59, i32 0
  %61 = getelementptr inbounds i8, i8* %37, i64 6
  %62 = bitcast i8* %61 to i64*
  %63 = load i64, i64* %62, align 1
  %64 = insertelement <2 x i64> undef, i64 %63, i32 0
  %65 = getelementptr inbounds i8, i8* %37, i64 7
  %66 = bitcast i8* %65 to i64*
  %67 = load i64, i64* %66, align 1
  %68 = insertelement <2 x i64> undef, i64 %67, i32 0
  %69 = bitcast <2 x i64> %40 to <16 x i8>
  %70 = bitcast <2 x i64> %44 to <16 x i8>
  %71 = shufflevector <16 x i8> %69, <16 x i8> %70, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %72 = bitcast <2 x i64> %48 to <16 x i8>
  %73 = bitcast <2 x i64> %52 to <16 x i8>
  %74 = shufflevector <16 x i8> %72, <16 x i8> %73, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %75 = bitcast <2 x i64> %56 to <16 x i8>
  %76 = bitcast <2 x i64> %60 to <16 x i8>
  %77 = shufflevector <16 x i8> %75, <16 x i8> %76, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %78 = bitcast <2 x i64> %64 to <16 x i8>
  %79 = bitcast <2 x i64> %68 to <16 x i8>
  %80 = shufflevector <16 x i8> %78, <16 x i8> %79, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %81 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %71, <16 x i8> %26) #9
  %82 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %74, <16 x i8> %27) #9
  %83 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %77, <16 x i8> %28) #9
  %84 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %80, <16 x i8> %29) #9
  %85 = add <8 x i16> %84, %82
  %86 = add <8 x i16> %81, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %87 = add <8 x i16> %86, %83
  %88 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %87, <8 x i16> %85) #9
  %89 = ashr <8 x i16> %88, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %90 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %89, <8 x i16> undef) #9
  %91 = bitcast <16 x i8> %90 to <2 x i64>
  %92 = extractelement <2 x i64> %91, i32 0
  %93 = bitcast i8* %35 to i64*
  store i64 %92, i64* %93, align 1
  %94 = getelementptr inbounds i8, i8* %37, i64 8
  %95 = getelementptr inbounds i8, i8* %35, i64 8
  %96 = add nsw i32 %36, -8
  %97 = icmp eq i32 %96, 0
  br i1 %97, label %98, label %34

98:                                               ; preds = %34
  %99 = getelementptr inbounds i8, i8* %7, i64 %11
  %100 = getelementptr inbounds i8, i8* %7, i64 %13
  %101 = getelementptr inbounds i8, i8* %7, i64 %15
  %102 = getelementptr inbounds i8, i8* %7, i64 %17
  %103 = getelementptr inbounds i8, i8* %7, i64 %19
  %104 = getelementptr inbounds i8, i8* %7, i64 %21
  %105 = getelementptr inbounds i8, i8* %7, i64 %23
  %106 = shl nsw i64 %1, 1
  %107 = sub i64 0, %106
  %108 = getelementptr inbounds i8, i8* %0, i64 %107
  %109 = getelementptr inbounds i8, i8* %108, i64 -3
  br label %110

110:                                              ; preds = %110, %98
  %111 = phi i8* [ %99, %98 ], [ %171, %110 ]
  %112 = phi i32 [ %10, %98 ], [ %172, %110 ]
  %113 = phi i8* [ %109, %98 ], [ %170, %110 ]
  %114 = bitcast i8* %113 to i64*
  %115 = load i64, i64* %114, align 1
  %116 = insertelement <2 x i64> undef, i64 %115, i32 0
  %117 = getelementptr inbounds i8, i8* %113, i64 1
  %118 = bitcast i8* %117 to i64*
  %119 = load i64, i64* %118, align 1
  %120 = insertelement <2 x i64> undef, i64 %119, i32 0
  %121 = getelementptr inbounds i8, i8* %113, i64 2
  %122 = bitcast i8* %121 to i64*
  %123 = load i64, i64* %122, align 1
  %124 = insertelement <2 x i64> undef, i64 %123, i32 0
  %125 = getelementptr inbounds i8, i8* %113, i64 3
  %126 = bitcast i8* %125 to i64*
  %127 = load i64, i64* %126, align 1
  %128 = insertelement <2 x i64> undef, i64 %127, i32 0
  %129 = getelementptr inbounds i8, i8* %113, i64 4
  %130 = bitcast i8* %129 to i64*
  %131 = load i64, i64* %130, align 1
  %132 = insertelement <2 x i64> undef, i64 %131, i32 0
  %133 = getelementptr inbounds i8, i8* %113, i64 5
  %134 = bitcast i8* %133 to i64*
  %135 = load i64, i64* %134, align 1
  %136 = insertelement <2 x i64> undef, i64 %135, i32 0
  %137 = getelementptr inbounds i8, i8* %113, i64 6
  %138 = bitcast i8* %137 to i64*
  %139 = load i64, i64* %138, align 1
  %140 = insertelement <2 x i64> undef, i64 %139, i32 0
  %141 = getelementptr inbounds i8, i8* %113, i64 7
  %142 = bitcast i8* %141 to i64*
  %143 = load i64, i64* %142, align 1
  %144 = insertelement <2 x i64> undef, i64 %143, i32 0
  %145 = bitcast <2 x i64> %116 to <16 x i8>
  %146 = bitcast <2 x i64> %120 to <16 x i8>
  %147 = shufflevector <16 x i8> %145, <16 x i8> %146, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %148 = bitcast <2 x i64> %124 to <16 x i8>
  %149 = bitcast <2 x i64> %128 to <16 x i8>
  %150 = shufflevector <16 x i8> %148, <16 x i8> %149, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %151 = bitcast <2 x i64> %132 to <16 x i8>
  %152 = bitcast <2 x i64> %136 to <16 x i8>
  %153 = shufflevector <16 x i8> %151, <16 x i8> %152, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %154 = bitcast <2 x i64> %140 to <16 x i8>
  %155 = bitcast <2 x i64> %144 to <16 x i8>
  %156 = shufflevector <16 x i8> %154, <16 x i8> %155, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %157 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %147, <16 x i8> %26) #9
  %158 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %150, <16 x i8> %27) #9
  %159 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %153, <16 x i8> %28) #9
  %160 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %156, <16 x i8> %29) #9
  %161 = add <8 x i16> %160, %158
  %162 = add <8 x i16> %157, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %163 = add <8 x i16> %162, %159
  %164 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %163, <8 x i16> %161) #9
  %165 = ashr <8 x i16> %164, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %166 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %165, <8 x i16> undef) #9
  %167 = bitcast <16 x i8> %166 to <2 x i64>
  %168 = extractelement <2 x i64> %167, i32 0
  %169 = bitcast i8* %111 to i64*
  store i64 %168, i64* %169, align 1
  %170 = getelementptr inbounds i8, i8* %113, i64 8
  %171 = getelementptr inbounds i8, i8* %111, i64 8
  %172 = add nsw i32 %112, -8
  %173 = icmp eq i32 %172, 0
  br i1 %173, label %174, label %110

174:                                              ; preds = %110
  %175 = sub i64 0, %1
  %176 = getelementptr inbounds i8, i8* %0, i64 %175
  %177 = getelementptr inbounds i8, i8* %176, i64 -3
  br label %178

178:                                              ; preds = %178, %174
  %179 = phi i8* [ %100, %174 ], [ %239, %178 ]
  %180 = phi i32 [ %10, %174 ], [ %240, %178 ]
  %181 = phi i8* [ %177, %174 ], [ %238, %178 ]
  %182 = bitcast i8* %181 to i64*
  %183 = load i64, i64* %182, align 1
  %184 = insertelement <2 x i64> undef, i64 %183, i32 0
  %185 = getelementptr inbounds i8, i8* %181, i64 1
  %186 = bitcast i8* %185 to i64*
  %187 = load i64, i64* %186, align 1
  %188 = insertelement <2 x i64> undef, i64 %187, i32 0
  %189 = getelementptr inbounds i8, i8* %181, i64 2
  %190 = bitcast i8* %189 to i64*
  %191 = load i64, i64* %190, align 1
  %192 = insertelement <2 x i64> undef, i64 %191, i32 0
  %193 = getelementptr inbounds i8, i8* %181, i64 3
  %194 = bitcast i8* %193 to i64*
  %195 = load i64, i64* %194, align 1
  %196 = insertelement <2 x i64> undef, i64 %195, i32 0
  %197 = getelementptr inbounds i8, i8* %181, i64 4
  %198 = bitcast i8* %197 to i64*
  %199 = load i64, i64* %198, align 1
  %200 = insertelement <2 x i64> undef, i64 %199, i32 0
  %201 = getelementptr inbounds i8, i8* %181, i64 5
  %202 = bitcast i8* %201 to i64*
  %203 = load i64, i64* %202, align 1
  %204 = insertelement <2 x i64> undef, i64 %203, i32 0
  %205 = getelementptr inbounds i8, i8* %181, i64 6
  %206 = bitcast i8* %205 to i64*
  %207 = load i64, i64* %206, align 1
  %208 = insertelement <2 x i64> undef, i64 %207, i32 0
  %209 = getelementptr inbounds i8, i8* %181, i64 7
  %210 = bitcast i8* %209 to i64*
  %211 = load i64, i64* %210, align 1
  %212 = insertelement <2 x i64> undef, i64 %211, i32 0
  %213 = bitcast <2 x i64> %184 to <16 x i8>
  %214 = bitcast <2 x i64> %188 to <16 x i8>
  %215 = shufflevector <16 x i8> %213, <16 x i8> %214, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %216 = bitcast <2 x i64> %192 to <16 x i8>
  %217 = bitcast <2 x i64> %196 to <16 x i8>
  %218 = shufflevector <16 x i8> %216, <16 x i8> %217, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %219 = bitcast <2 x i64> %200 to <16 x i8>
  %220 = bitcast <2 x i64> %204 to <16 x i8>
  %221 = shufflevector <16 x i8> %219, <16 x i8> %220, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %222 = bitcast <2 x i64> %208 to <16 x i8>
  %223 = bitcast <2 x i64> %212 to <16 x i8>
  %224 = shufflevector <16 x i8> %222, <16 x i8> %223, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %225 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %215, <16 x i8> %26) #9
  %226 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %218, <16 x i8> %27) #9
  %227 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %221, <16 x i8> %28) #9
  %228 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %224, <16 x i8> %29) #9
  %229 = add <8 x i16> %228, %226
  %230 = add <8 x i16> %225, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %231 = add <8 x i16> %230, %227
  %232 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %231, <8 x i16> %229) #9
  %233 = ashr <8 x i16> %232, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %234 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %233, <8 x i16> undef) #9
  %235 = bitcast <16 x i8> %234 to <2 x i64>
  %236 = extractelement <2 x i64> %235, i32 0
  %237 = bitcast i8* %179 to i64*
  store i64 %236, i64* %237, align 1
  %238 = getelementptr inbounds i8, i8* %181, i64 8
  %239 = getelementptr inbounds i8, i8* %179, i64 8
  %240 = add nsw i32 %180, -8
  %241 = icmp eq i32 %240, 0
  br i1 %241, label %242, label %178

242:                                              ; preds = %178
  %243 = getelementptr inbounds i8, i8* %0, i64 -3
  br label %244

244:                                              ; preds = %244, %242
  %245 = phi i8* [ %101, %242 ], [ %305, %244 ]
  %246 = phi i32 [ %10, %242 ], [ %306, %244 ]
  %247 = phi i8* [ %243, %242 ], [ %304, %244 ]
  %248 = bitcast i8* %247 to i64*
  %249 = load i64, i64* %248, align 1
  %250 = insertelement <2 x i64> undef, i64 %249, i32 0
  %251 = getelementptr inbounds i8, i8* %247, i64 1
  %252 = bitcast i8* %251 to i64*
  %253 = load i64, i64* %252, align 1
  %254 = insertelement <2 x i64> undef, i64 %253, i32 0
  %255 = getelementptr inbounds i8, i8* %247, i64 2
  %256 = bitcast i8* %255 to i64*
  %257 = load i64, i64* %256, align 1
  %258 = insertelement <2 x i64> undef, i64 %257, i32 0
  %259 = getelementptr inbounds i8, i8* %247, i64 3
  %260 = bitcast i8* %259 to i64*
  %261 = load i64, i64* %260, align 1
  %262 = insertelement <2 x i64> undef, i64 %261, i32 0
  %263 = getelementptr inbounds i8, i8* %247, i64 4
  %264 = bitcast i8* %263 to i64*
  %265 = load i64, i64* %264, align 1
  %266 = insertelement <2 x i64> undef, i64 %265, i32 0
  %267 = getelementptr inbounds i8, i8* %247, i64 5
  %268 = bitcast i8* %267 to i64*
  %269 = load i64, i64* %268, align 1
  %270 = insertelement <2 x i64> undef, i64 %269, i32 0
  %271 = getelementptr inbounds i8, i8* %247, i64 6
  %272 = bitcast i8* %271 to i64*
  %273 = load i64, i64* %272, align 1
  %274 = insertelement <2 x i64> undef, i64 %273, i32 0
  %275 = getelementptr inbounds i8, i8* %247, i64 7
  %276 = bitcast i8* %275 to i64*
  %277 = load i64, i64* %276, align 1
  %278 = insertelement <2 x i64> undef, i64 %277, i32 0
  %279 = bitcast <2 x i64> %250 to <16 x i8>
  %280 = bitcast <2 x i64> %254 to <16 x i8>
  %281 = shufflevector <16 x i8> %279, <16 x i8> %280, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %282 = bitcast <2 x i64> %258 to <16 x i8>
  %283 = bitcast <2 x i64> %262 to <16 x i8>
  %284 = shufflevector <16 x i8> %282, <16 x i8> %283, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %285 = bitcast <2 x i64> %266 to <16 x i8>
  %286 = bitcast <2 x i64> %270 to <16 x i8>
  %287 = shufflevector <16 x i8> %285, <16 x i8> %286, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %288 = bitcast <2 x i64> %274 to <16 x i8>
  %289 = bitcast <2 x i64> %278 to <16 x i8>
  %290 = shufflevector <16 x i8> %288, <16 x i8> %289, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %291 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %281, <16 x i8> %26) #9
  %292 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %284, <16 x i8> %27) #9
  %293 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %287, <16 x i8> %28) #9
  %294 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %290, <16 x i8> %29) #9
  %295 = add <8 x i16> %294, %292
  %296 = add <8 x i16> %291, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %297 = add <8 x i16> %296, %293
  %298 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %297, <8 x i16> %295) #9
  %299 = ashr <8 x i16> %298, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %300 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %299, <8 x i16> undef) #9
  %301 = bitcast <16 x i8> %300 to <2 x i64>
  %302 = extractelement <2 x i64> %301, i32 0
  %303 = bitcast i8* %245 to i64*
  store i64 %302, i64* %303, align 1
  %304 = getelementptr inbounds i8, i8* %247, i64 8
  %305 = getelementptr inbounds i8, i8* %245, i64 8
  %306 = add nsw i32 %246, -8
  %307 = icmp eq i32 %306, 0
  br i1 %307, label %308, label %244

308:                                              ; preds = %244
  %309 = getelementptr inbounds i8, i8* %0, i64 %1
  %310 = getelementptr inbounds i8, i8* %309, i64 -3
  br label %311

311:                                              ; preds = %311, %308
  %312 = phi i8* [ %102, %308 ], [ %372, %311 ]
  %313 = phi i32 [ %10, %308 ], [ %373, %311 ]
  %314 = phi i8* [ %310, %308 ], [ %371, %311 ]
  %315 = bitcast i8* %314 to i64*
  %316 = load i64, i64* %315, align 1
  %317 = insertelement <2 x i64> undef, i64 %316, i32 0
  %318 = getelementptr inbounds i8, i8* %314, i64 1
  %319 = bitcast i8* %318 to i64*
  %320 = load i64, i64* %319, align 1
  %321 = insertelement <2 x i64> undef, i64 %320, i32 0
  %322 = getelementptr inbounds i8, i8* %314, i64 2
  %323 = bitcast i8* %322 to i64*
  %324 = load i64, i64* %323, align 1
  %325 = insertelement <2 x i64> undef, i64 %324, i32 0
  %326 = getelementptr inbounds i8, i8* %314, i64 3
  %327 = bitcast i8* %326 to i64*
  %328 = load i64, i64* %327, align 1
  %329 = insertelement <2 x i64> undef, i64 %328, i32 0
  %330 = getelementptr inbounds i8, i8* %314, i64 4
  %331 = bitcast i8* %330 to i64*
  %332 = load i64, i64* %331, align 1
  %333 = insertelement <2 x i64> undef, i64 %332, i32 0
  %334 = getelementptr inbounds i8, i8* %314, i64 5
  %335 = bitcast i8* %334 to i64*
  %336 = load i64, i64* %335, align 1
  %337 = insertelement <2 x i64> undef, i64 %336, i32 0
  %338 = getelementptr inbounds i8, i8* %314, i64 6
  %339 = bitcast i8* %338 to i64*
  %340 = load i64, i64* %339, align 1
  %341 = insertelement <2 x i64> undef, i64 %340, i32 0
  %342 = getelementptr inbounds i8, i8* %314, i64 7
  %343 = bitcast i8* %342 to i64*
  %344 = load i64, i64* %343, align 1
  %345 = insertelement <2 x i64> undef, i64 %344, i32 0
  %346 = bitcast <2 x i64> %317 to <16 x i8>
  %347 = bitcast <2 x i64> %321 to <16 x i8>
  %348 = shufflevector <16 x i8> %346, <16 x i8> %347, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %349 = bitcast <2 x i64> %325 to <16 x i8>
  %350 = bitcast <2 x i64> %329 to <16 x i8>
  %351 = shufflevector <16 x i8> %349, <16 x i8> %350, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %352 = bitcast <2 x i64> %333 to <16 x i8>
  %353 = bitcast <2 x i64> %337 to <16 x i8>
  %354 = shufflevector <16 x i8> %352, <16 x i8> %353, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %355 = bitcast <2 x i64> %341 to <16 x i8>
  %356 = bitcast <2 x i64> %345 to <16 x i8>
  %357 = shufflevector <16 x i8> %355, <16 x i8> %356, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %358 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %348, <16 x i8> %26) #9
  %359 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %351, <16 x i8> %27) #9
  %360 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %354, <16 x i8> %28) #9
  %361 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %357, <16 x i8> %29) #9
  %362 = add <8 x i16> %361, %359
  %363 = add <8 x i16> %358, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %364 = add <8 x i16> %363, %360
  %365 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %364, <8 x i16> %362) #9
  %366 = ashr <8 x i16> %365, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %367 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %366, <8 x i16> undef) #9
  %368 = bitcast <16 x i8> %367 to <2 x i64>
  %369 = extractelement <2 x i64> %368, i32 0
  %370 = bitcast i8* %312 to i64*
  store i64 %369, i64* %370, align 1
  %371 = getelementptr inbounds i8, i8* %314, i64 8
  %372 = getelementptr inbounds i8, i8* %312, i64 8
  %373 = add nsw i32 %313, -8
  %374 = icmp eq i32 %373, 0
  br i1 %374, label %375, label %311

375:                                              ; preds = %311
  %376 = getelementptr inbounds i8, i8* %0, i64 %106
  %377 = getelementptr inbounds i8, i8* %376, i64 -3
  br label %378

378:                                              ; preds = %378, %375
  %379 = phi i8* [ %103, %375 ], [ %439, %378 ]
  %380 = phi i32 [ %10, %375 ], [ %440, %378 ]
  %381 = phi i8* [ %377, %375 ], [ %438, %378 ]
  %382 = bitcast i8* %381 to i64*
  %383 = load i64, i64* %382, align 1
  %384 = insertelement <2 x i64> undef, i64 %383, i32 0
  %385 = getelementptr inbounds i8, i8* %381, i64 1
  %386 = bitcast i8* %385 to i64*
  %387 = load i64, i64* %386, align 1
  %388 = insertelement <2 x i64> undef, i64 %387, i32 0
  %389 = getelementptr inbounds i8, i8* %381, i64 2
  %390 = bitcast i8* %389 to i64*
  %391 = load i64, i64* %390, align 1
  %392 = insertelement <2 x i64> undef, i64 %391, i32 0
  %393 = getelementptr inbounds i8, i8* %381, i64 3
  %394 = bitcast i8* %393 to i64*
  %395 = load i64, i64* %394, align 1
  %396 = insertelement <2 x i64> undef, i64 %395, i32 0
  %397 = getelementptr inbounds i8, i8* %381, i64 4
  %398 = bitcast i8* %397 to i64*
  %399 = load i64, i64* %398, align 1
  %400 = insertelement <2 x i64> undef, i64 %399, i32 0
  %401 = getelementptr inbounds i8, i8* %381, i64 5
  %402 = bitcast i8* %401 to i64*
  %403 = load i64, i64* %402, align 1
  %404 = insertelement <2 x i64> undef, i64 %403, i32 0
  %405 = getelementptr inbounds i8, i8* %381, i64 6
  %406 = bitcast i8* %405 to i64*
  %407 = load i64, i64* %406, align 1
  %408 = insertelement <2 x i64> undef, i64 %407, i32 0
  %409 = getelementptr inbounds i8, i8* %381, i64 7
  %410 = bitcast i8* %409 to i64*
  %411 = load i64, i64* %410, align 1
  %412 = insertelement <2 x i64> undef, i64 %411, i32 0
  %413 = bitcast <2 x i64> %384 to <16 x i8>
  %414 = bitcast <2 x i64> %388 to <16 x i8>
  %415 = shufflevector <16 x i8> %413, <16 x i8> %414, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %416 = bitcast <2 x i64> %392 to <16 x i8>
  %417 = bitcast <2 x i64> %396 to <16 x i8>
  %418 = shufflevector <16 x i8> %416, <16 x i8> %417, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %419 = bitcast <2 x i64> %400 to <16 x i8>
  %420 = bitcast <2 x i64> %404 to <16 x i8>
  %421 = shufflevector <16 x i8> %419, <16 x i8> %420, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %422 = bitcast <2 x i64> %408 to <16 x i8>
  %423 = bitcast <2 x i64> %412 to <16 x i8>
  %424 = shufflevector <16 x i8> %422, <16 x i8> %423, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %425 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %415, <16 x i8> %26) #9
  %426 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %418, <16 x i8> %27) #9
  %427 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %421, <16 x i8> %28) #9
  %428 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %424, <16 x i8> %29) #9
  %429 = add <8 x i16> %428, %426
  %430 = add <8 x i16> %425, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %431 = add <8 x i16> %430, %427
  %432 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %431, <8 x i16> %429) #9
  %433 = ashr <8 x i16> %432, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %434 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %433, <8 x i16> undef) #9
  %435 = bitcast <16 x i8> %434 to <2 x i64>
  %436 = extractelement <2 x i64> %435, i32 0
  %437 = bitcast i8* %379 to i64*
  store i64 %436, i64* %437, align 1
  %438 = getelementptr inbounds i8, i8* %381, i64 8
  %439 = getelementptr inbounds i8, i8* %379, i64 8
  %440 = add nsw i32 %380, -8
  %441 = icmp eq i32 %440, 0
  br i1 %441, label %442, label %378

442:                                              ; preds = %378
  %443 = getelementptr inbounds i8, i8* %0, i64 %30
  %444 = getelementptr inbounds i8, i8* %443, i64 -3
  br label %445

445:                                              ; preds = %445, %442
  %446 = phi i8* [ %104, %442 ], [ %506, %445 ]
  %447 = phi i32 [ %10, %442 ], [ %507, %445 ]
  %448 = phi i8* [ %444, %442 ], [ %505, %445 ]
  %449 = bitcast i8* %448 to i64*
  %450 = load i64, i64* %449, align 1
  %451 = insertelement <2 x i64> undef, i64 %450, i32 0
  %452 = getelementptr inbounds i8, i8* %448, i64 1
  %453 = bitcast i8* %452 to i64*
  %454 = load i64, i64* %453, align 1
  %455 = insertelement <2 x i64> undef, i64 %454, i32 0
  %456 = getelementptr inbounds i8, i8* %448, i64 2
  %457 = bitcast i8* %456 to i64*
  %458 = load i64, i64* %457, align 1
  %459 = insertelement <2 x i64> undef, i64 %458, i32 0
  %460 = getelementptr inbounds i8, i8* %448, i64 3
  %461 = bitcast i8* %460 to i64*
  %462 = load i64, i64* %461, align 1
  %463 = insertelement <2 x i64> undef, i64 %462, i32 0
  %464 = getelementptr inbounds i8, i8* %448, i64 4
  %465 = bitcast i8* %464 to i64*
  %466 = load i64, i64* %465, align 1
  %467 = insertelement <2 x i64> undef, i64 %466, i32 0
  %468 = getelementptr inbounds i8, i8* %448, i64 5
  %469 = bitcast i8* %468 to i64*
  %470 = load i64, i64* %469, align 1
  %471 = insertelement <2 x i64> undef, i64 %470, i32 0
  %472 = getelementptr inbounds i8, i8* %448, i64 6
  %473 = bitcast i8* %472 to i64*
  %474 = load i64, i64* %473, align 1
  %475 = insertelement <2 x i64> undef, i64 %474, i32 0
  %476 = getelementptr inbounds i8, i8* %448, i64 7
  %477 = bitcast i8* %476 to i64*
  %478 = load i64, i64* %477, align 1
  %479 = insertelement <2 x i64> undef, i64 %478, i32 0
  %480 = bitcast <2 x i64> %451 to <16 x i8>
  %481 = bitcast <2 x i64> %455 to <16 x i8>
  %482 = shufflevector <16 x i8> %480, <16 x i8> %481, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %483 = bitcast <2 x i64> %459 to <16 x i8>
  %484 = bitcast <2 x i64> %463 to <16 x i8>
  %485 = shufflevector <16 x i8> %483, <16 x i8> %484, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %486 = bitcast <2 x i64> %467 to <16 x i8>
  %487 = bitcast <2 x i64> %471 to <16 x i8>
  %488 = shufflevector <16 x i8> %486, <16 x i8> %487, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %489 = bitcast <2 x i64> %475 to <16 x i8>
  %490 = bitcast <2 x i64> %479 to <16 x i8>
  %491 = shufflevector <16 x i8> %489, <16 x i8> %490, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %492 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %482, <16 x i8> %26) #9
  %493 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %485, <16 x i8> %27) #9
  %494 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %488, <16 x i8> %28) #9
  %495 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %491, <16 x i8> %29) #9
  %496 = add <8 x i16> %495, %493
  %497 = add <8 x i16> %492, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %498 = add <8 x i16> %497, %494
  %499 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %498, <8 x i16> %496) #9
  %500 = ashr <8 x i16> %499, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %501 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %500, <8 x i16> undef) #9
  %502 = bitcast <16 x i8> %501 to <2 x i64>
  %503 = extractelement <2 x i64> %502, i32 0
  %504 = bitcast i8* %446 to i64*
  store i64 %503, i64* %504, align 1
  %505 = getelementptr inbounds i8, i8* %448, i64 8
  %506 = getelementptr inbounds i8, i8* %446, i64 8
  %507 = add nsw i32 %447, -8
  %508 = icmp eq i32 %507, 0
  br i1 %508, label %509, label %445

509:                                              ; preds = %445
  %510 = shl nsw i64 %1, 2
  %511 = icmp sgt i32 %10, 0
  %512 = shl nsw i64 %3, 1
  br label %513

513:                                              ; preds = %509, %721
  %514 = phi i8* [ %515, %721 ], [ %100, %509 ]
  %515 = phi i8* [ %516, %721 ], [ %101, %509 ]
  %516 = phi i8* [ %517, %721 ], [ %102, %509 ]
  %517 = phi i8* [ %518, %721 ], [ %103, %509 ]
  %518 = phi i8* [ %519, %721 ], [ %104, %509 ]
  %519 = phi i8* [ %521, %721 ], [ %105, %509 ]
  %520 = phi i8* [ %514, %721 ], [ %99, %509 ]
  %521 = phi i8* [ %520, %721 ], [ %7, %509 ]
  %522 = phi i32 [ %724, %721 ], [ %5, %509 ]
  %523 = phi i8* [ %723, %721 ], [ %2, %509 ]
  %524 = phi i8* [ %722, %721 ], [ %0, %509 ]
  %525 = getelementptr inbounds i8, i8* %524, i64 -3
  %526 = getelementptr inbounds i8, i8* %525, i64 %510
  br label %527

527:                                              ; preds = %527, %513
  %528 = phi i8* [ %519, %513 ], [ %588, %527 ]
  %529 = phi i32 [ %10, %513 ], [ %589, %527 ]
  %530 = phi i8* [ %526, %513 ], [ %587, %527 ]
  %531 = bitcast i8* %530 to i64*
  %532 = load i64, i64* %531, align 1
  %533 = insertelement <2 x i64> undef, i64 %532, i32 0
  %534 = getelementptr inbounds i8, i8* %530, i64 1
  %535 = bitcast i8* %534 to i64*
  %536 = load i64, i64* %535, align 1
  %537 = insertelement <2 x i64> undef, i64 %536, i32 0
  %538 = getelementptr inbounds i8, i8* %530, i64 2
  %539 = bitcast i8* %538 to i64*
  %540 = load i64, i64* %539, align 1
  %541 = insertelement <2 x i64> undef, i64 %540, i32 0
  %542 = getelementptr inbounds i8, i8* %530, i64 3
  %543 = bitcast i8* %542 to i64*
  %544 = load i64, i64* %543, align 1
  %545 = insertelement <2 x i64> undef, i64 %544, i32 0
  %546 = getelementptr inbounds i8, i8* %530, i64 4
  %547 = bitcast i8* %546 to i64*
  %548 = load i64, i64* %547, align 1
  %549 = insertelement <2 x i64> undef, i64 %548, i32 0
  %550 = getelementptr inbounds i8, i8* %530, i64 5
  %551 = bitcast i8* %550 to i64*
  %552 = load i64, i64* %551, align 1
  %553 = insertelement <2 x i64> undef, i64 %552, i32 0
  %554 = getelementptr inbounds i8, i8* %530, i64 6
  %555 = bitcast i8* %554 to i64*
  %556 = load i64, i64* %555, align 1
  %557 = insertelement <2 x i64> undef, i64 %556, i32 0
  %558 = getelementptr inbounds i8, i8* %530, i64 7
  %559 = bitcast i8* %558 to i64*
  %560 = load i64, i64* %559, align 1
  %561 = insertelement <2 x i64> undef, i64 %560, i32 0
  %562 = bitcast <2 x i64> %533 to <16 x i8>
  %563 = bitcast <2 x i64> %537 to <16 x i8>
  %564 = shufflevector <16 x i8> %562, <16 x i8> %563, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %565 = bitcast <2 x i64> %541 to <16 x i8>
  %566 = bitcast <2 x i64> %545 to <16 x i8>
  %567 = shufflevector <16 x i8> %565, <16 x i8> %566, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %568 = bitcast <2 x i64> %549 to <16 x i8>
  %569 = bitcast <2 x i64> %553 to <16 x i8>
  %570 = shufflevector <16 x i8> %568, <16 x i8> %569, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %571 = bitcast <2 x i64> %557 to <16 x i8>
  %572 = bitcast <2 x i64> %561 to <16 x i8>
  %573 = shufflevector <16 x i8> %571, <16 x i8> %572, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %574 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %564, <16 x i8> %26) #9
  %575 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %567, <16 x i8> %27) #9
  %576 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %570, <16 x i8> %28) #9
  %577 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %573, <16 x i8> %29) #9
  %578 = add <8 x i16> %577, %575
  %579 = add <8 x i16> %574, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %580 = add <8 x i16> %579, %576
  %581 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %580, <8 x i16> %578) #9
  %582 = ashr <8 x i16> %581, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %583 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %582, <8 x i16> undef) #9
  %584 = bitcast <16 x i8> %583 to <2 x i64>
  %585 = extractelement <2 x i64> %584, i32 0
  %586 = bitcast i8* %528 to i64*
  store i64 %585, i64* %586, align 1
  %587 = getelementptr inbounds i8, i8* %530, i64 8
  %588 = getelementptr inbounds i8, i8* %528, i64 8
  %589 = add nsw i32 %529, -8
  %590 = icmp eq i32 %589, 0
  br i1 %590, label %591, label %527

591:                                              ; preds = %527
  br i1 %511, label %592, label %721

592:                                              ; preds = %591
  %593 = getelementptr inbounds i8, i8* %523, i64 %3
  br label %594

594:                                              ; preds = %592, %594
  %595 = phi i64 [ 0, %592 ], [ %719, %594 ]
  %596 = getelementptr inbounds i8, i8* %524, i64 %595
  %597 = bitcast i8* %596 to i64*
  %598 = load i64, i64* %597, align 1
  %599 = insertelement <2 x i64> undef, i64 %598, i32 0
  %600 = getelementptr inbounds i8, i8* %515, i64 %595
  %601 = bitcast i8* %600 to i64*
  %602 = load i64, i64* %601, align 1
  %603 = insertelement <2 x i64> undef, i64 %602, i32 0
  %604 = bitcast <2 x i64> %599 to <16 x i8>
  %605 = bitcast <2 x i64> %603 to <16 x i8>
  %606 = shufflevector <16 x i8> %604, <16 x i8> %605, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %607 = shl nuw nsw i64 %595, 1
  %608 = getelementptr inbounds i8, i8* %523, i64 %607
  %609 = bitcast i8* %608 to <16 x i8>*
  store <16 x i8> %606, <16 x i8>* %609, align 1
  %610 = getelementptr inbounds i8, i8* %596, i64 %31
  %611 = bitcast i8* %610 to i64*
  %612 = load i64, i64* %611, align 1
  %613 = insertelement <2 x i64> undef, i64 %612, i32 0
  %614 = getelementptr inbounds i8, i8* %610, i64 %1
  %615 = bitcast i8* %614 to i64*
  %616 = load i64, i64* %615, align 1
  %617 = insertelement <2 x i64> undef, i64 %616, i32 0
  %618 = getelementptr inbounds i8, i8* %610, i64 %106
  %619 = bitcast i8* %618 to i64*
  %620 = load i64, i64* %619, align 1
  %621 = insertelement <2 x i64> undef, i64 %620, i32 0
  %622 = getelementptr inbounds i8, i8* %610, i64 %30
  %623 = bitcast i8* %622 to i64*
  %624 = load i64, i64* %623, align 1
  %625 = insertelement <2 x i64> undef, i64 %624, i32 0
  %626 = getelementptr inbounds i8, i8* %610, i64 %510
  %627 = bitcast i8* %626 to i64*
  %628 = load i64, i64* %627, align 1
  %629 = insertelement <2 x i64> undef, i64 %628, i32 0
  %630 = getelementptr inbounds i8, i8* %626, i64 %1
  %631 = bitcast i8* %630 to i64*
  %632 = load i64, i64* %631, align 1
  %633 = insertelement <2 x i64> undef, i64 %632, i32 0
  %634 = getelementptr inbounds i8, i8* %626, i64 %106
  %635 = bitcast i8* %634 to i64*
  %636 = load i64, i64* %635, align 1
  %637 = insertelement <2 x i64> undef, i64 %636, i32 0
  %638 = getelementptr inbounds i8, i8* %626, i64 %30
  %639 = bitcast i8* %638 to i64*
  %640 = load i64, i64* %639, align 1
  %641 = insertelement <2 x i64> undef, i64 %640, i32 0
  %642 = bitcast <2 x i64> %613 to <16 x i8>
  %643 = bitcast <2 x i64> %617 to <16 x i8>
  %644 = shufflevector <16 x i8> %642, <16 x i8> %643, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %645 = bitcast <2 x i64> %621 to <16 x i8>
  %646 = bitcast <2 x i64> %625 to <16 x i8>
  %647 = shufflevector <16 x i8> %645, <16 x i8> %646, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %648 = bitcast <2 x i64> %629 to <16 x i8>
  %649 = bitcast <2 x i64> %633 to <16 x i8>
  %650 = shufflevector <16 x i8> %648, <16 x i8> %649, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %651 = bitcast <2 x i64> %637 to <16 x i8>
  %652 = bitcast <2 x i64> %641 to <16 x i8>
  %653 = shufflevector <16 x i8> %651, <16 x i8> %652, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %654 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %644, <16 x i8> %26) #9
  %655 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %647, <16 x i8> %27) #9
  %656 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %650, <16 x i8> %28) #9
  %657 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %653, <16 x i8> %29) #9
  %658 = add <8 x i16> %657, %655
  %659 = add <8 x i16> %654, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %660 = add <8 x i16> %659, %656
  %661 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %660, <8 x i16> %658) #9
  %662 = ashr <8 x i16> %661, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %663 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %662, <8 x i16> undef) #9
  %664 = getelementptr inbounds i8, i8* %521, i64 %595
  %665 = bitcast i8* %664 to i64*
  %666 = load i64, i64* %665, align 1
  %667 = insertelement <2 x i64> undef, i64 %666, i32 0
  %668 = getelementptr inbounds i8, i8* %520, i64 %595
  %669 = bitcast i8* %668 to i64*
  %670 = load i64, i64* %669, align 1
  %671 = insertelement <2 x i64> undef, i64 %670, i32 0
  %672 = getelementptr inbounds i8, i8* %514, i64 %595
  %673 = bitcast i8* %672 to i64*
  %674 = load i64, i64* %673, align 1
  %675 = insertelement <2 x i64> undef, i64 %674, i32 0
  %676 = load i64, i64* %601, align 1
  %677 = insertelement <2 x i64> undef, i64 %676, i32 0
  %678 = getelementptr inbounds i8, i8* %516, i64 %595
  %679 = bitcast i8* %678 to i64*
  %680 = load i64, i64* %679, align 1
  %681 = insertelement <2 x i64> undef, i64 %680, i32 0
  %682 = getelementptr inbounds i8, i8* %517, i64 %595
  %683 = bitcast i8* %682 to i64*
  %684 = load i64, i64* %683, align 1
  %685 = insertelement <2 x i64> undef, i64 %684, i32 0
  %686 = getelementptr inbounds i8, i8* %518, i64 %595
  %687 = bitcast i8* %686 to i64*
  %688 = load i64, i64* %687, align 1
  %689 = insertelement <2 x i64> undef, i64 %688, i32 0
  %690 = getelementptr inbounds i8, i8* %519, i64 %595
  %691 = bitcast i8* %690 to i64*
  %692 = load i64, i64* %691, align 1
  %693 = insertelement <2 x i64> undef, i64 %692, i32 0
  %694 = bitcast <2 x i64> %667 to <16 x i8>
  %695 = bitcast <2 x i64> %671 to <16 x i8>
  %696 = shufflevector <16 x i8> %694, <16 x i8> %695, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %697 = bitcast <2 x i64> %675 to <16 x i8>
  %698 = bitcast <2 x i64> %677 to <16 x i8>
  %699 = shufflevector <16 x i8> %697, <16 x i8> %698, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %700 = bitcast <2 x i64> %681 to <16 x i8>
  %701 = bitcast <2 x i64> %685 to <16 x i8>
  %702 = shufflevector <16 x i8> %700, <16 x i8> %701, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %703 = bitcast <2 x i64> %689 to <16 x i8>
  %704 = bitcast <2 x i64> %693 to <16 x i8>
  %705 = shufflevector <16 x i8> %703, <16 x i8> %704, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %706 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %696, <16 x i8> %26) #9
  %707 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %699, <16 x i8> %27) #9
  %708 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %702, <16 x i8> %28) #9
  %709 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %705, <16 x i8> %29) #9
  %710 = add <8 x i16> %709, %707
  %711 = add <8 x i16> %706, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %712 = add <8 x i16> %711, %708
  %713 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %712, <8 x i16> %710) #9
  %714 = ashr <8 x i16> %713, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %715 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %714, <8 x i16> undef) #9
  %716 = shufflevector <16 x i8> %663, <16 x i8> %715, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %717 = getelementptr inbounds i8, i8* %593, i64 %607
  %718 = bitcast i8* %717 to <16 x i8>*
  store <16 x i8> %716, <16 x i8>* %718, align 1
  %719 = add nuw nsw i64 %595, 8
  %720 = icmp slt i64 %719, %11
  br i1 %720, label %594, label %721

721:                                              ; preds = %594, %591
  %722 = getelementptr inbounds i8, i8* %524, i64 %1
  %723 = getelementptr inbounds i8, i8* %523, i64 %512
  %724 = add nsw i32 %522, -1
  %725 = icmp eq i32 %724, 0
  br i1 %725, label %726, label %513

726:                                              ; preds = %721
  ret void
}

declare void @vpx_extend_frame_borders_c(%struct.yv12_buffer_config*) local_unnamed_addr #4

declare void @vp9_scale_and_extend_frame_c(%struct.yv12_buffer_config*, %struct.yv12_buffer_config*, i8 zeroext, i32) local_unnamed_addr #4

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #5

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8>, <16 x i8>) #5

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16>, <8 x i16>) #6

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: inlinehint nofree nounwind ssp uwtable
define internal void @shuffle_filter_ssse3(i16* nocapture readonly, <2 x i64>* nocapture) #7 {
  %3 = bitcast i16* %0 to <16 x i8>*
  %4 = load <16 x i8>, <16 x i8>* %3, align 16
  %5 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2>
  %6 = bitcast <2 x i64>* %1 to <16 x i8>*
  store <16 x i8> %5, <16 x i8>* %6, align 16
  %7 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6>
  %8 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %9 = bitcast <2 x i64>* %8 to <16 x i8>*
  store <16 x i8> %7, <16 x i8>* %9, align 16
  %10 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10>
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %12 = bitcast <2 x i64>* %11 to <16 x i8>*
  store <16 x i8> %10, <16 x i8>* %12, align 16
  %13 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14>
  %14 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %15 = bitcast <2 x i64>* %14 to <16 x i8>*
  store <16 x i8> %13, <16 x i8>* %15, align 16
  ret void
}

; Function Attrs: inlinehint nofree nounwind ssp uwtable
define internal void @shuffle_filter_odd_ssse3(i16* nocapture readonly, <2 x i64>* nocapture) #7 {
  %3 = bitcast i16* %0 to <16 x i8>*
  %4 = load <16 x i8>, <16 x i8>* %3, align 16
  %5 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 7, i32 0, i32 7, i32 0, i32 7, i32 0, i32 7, i32 0, i32 7, i32 0, i32 7, i32 0, i32 7, i32 0, i32 7, i32 0>
  %6 = bitcast <2 x i64>* %1 to <16 x i8>*
  store <16 x i8> %5, <16 x i8>* %6, align 16
  %7 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 2, i32 4, i32 2, i32 4, i32 2, i32 4, i32 2, i32 4, i32 2, i32 4, i32 2, i32 4, i32 2, i32 4, i32 2, i32 4>
  %8 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %9 = bitcast <2 x i64>* %8 to <16 x i8>*
  store <16 x i8> %7, <16 x i8>* %9, align 16
  %10 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 6, i32 8, i32 6, i32 8, i32 6, i32 8, i32 6, i32 8, i32 6, i32 8, i32 6, i32 8, i32 6, i32 8, i32 6, i32 8>
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %12 = bitcast <2 x i64>* %11 to <16 x i8>*
  store <16 x i8> %10, <16 x i8>* %12, align 16
  %13 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 10, i32 12, i32 10, i32 12, i32 10, i32 12, i32 10, i32 12, i32 10, i32 12, i32 10, i32 12, i32 10, i32 12, i32 10, i32 12>
  %14 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %15 = bitcast <2 x i64>* %14 to <16 x i8>*
  store <16 x i8> %13, <16 x i8>* %15, align 16
  %16 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 14, i32 7, i32 14, i32 7, i32 14, i32 7, i32 14, i32 7, i32 14, i32 7, i32 14, i32 7, i32 14, i32 7, i32 14, i32 7>
  %17 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %18 = bitcast <2 x i64>* %17 to <16 x i8>*
  store <16 x i8> %16, <16 x i8>* %18, align 16
  ret void
}

; Function Attrs: inlinehint nounwind readonly ssp uwtable
define internal <2 x i64> @convolve8_8_even_offset_ssse3(<2 x i64>* nocapture readonly, <2 x i64>* nocapture readonly) #8 {
  %3 = bitcast <2 x i64>* %0 to <16 x i8>*
  %4 = load <16 x i8>, <16 x i8>* %3, align 16
  %5 = bitcast <2 x i64>* %1 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 16
  %7 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4, <16 x i8> %6) #9
  %8 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %9 = bitcast <2 x i64>* %8 to <16 x i8>*
  %10 = load <16 x i8>, <16 x i8>* %9, align 16
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %12 = bitcast <2 x i64>* %11 to <16 x i8>*
  %13 = load <16 x i8>, <16 x i8>* %12, align 16
  %14 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10, <16 x i8> %13) #9
  %15 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %16 = bitcast <2 x i64>* %15 to <16 x i8>*
  %17 = load <16 x i8>, <16 x i8>* %16, align 16
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %19 = bitcast <2 x i64>* %18 to <16 x i8>*
  %20 = load <16 x i8>, <16 x i8>* %19, align 16
  %21 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %17, <16 x i8> %20) #9
  %22 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %23 = bitcast <2 x i64>* %22 to <16 x i8>*
  %24 = load <16 x i8>, <16 x i8>* %23, align 16
  %25 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %26 = bitcast <2 x i64>* %25 to <16 x i8>*
  %27 = load <16 x i8>, <16 x i8>* %26, align 16
  %28 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %24, <16 x i8> %27) #9
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>) #9
  %30 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %7, <8 x i16> %28) #9
  %31 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %30, <8 x i16> %14) #9
  %32 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %31, <8 x i16> %21) #9
  %33 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %32, <8 x i16> %29) #9
  %34 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %33, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %35 = ashr <8 x i16> %34, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %36 = bitcast <8 x i16> %35 to <2 x i64>
  ret <2 x i64> %36
}

; Function Attrs: inlinehint nounwind readonly ssp uwtable
define internal <2 x i64> @convolve8_8_odd_offset_ssse3(<2 x i64>* nocapture readonly, <2 x i64>* nocapture readonly) #8 {
  %3 = bitcast <2 x i64>* %0 to <16 x i8>*
  %4 = load <16 x i8>, <16 x i8>* %3, align 16
  %5 = bitcast <2 x i64>* %1 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 16
  %7 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4, <16 x i8> %6) #9
  %8 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %9 = bitcast <2 x i64>* %8 to <16 x i8>*
  %10 = load <16 x i8>, <16 x i8>* %9, align 16
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %12 = bitcast <2 x i64>* %11 to <16 x i8>*
  %13 = load <16 x i8>, <16 x i8>* %12, align 16
  %14 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10, <16 x i8> %13) #9
  %15 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %16 = bitcast <2 x i64>* %15 to <16 x i8>*
  %17 = load <16 x i8>, <16 x i8>* %16, align 16
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %19 = bitcast <2 x i64>* %18 to <16 x i8>*
  %20 = load <16 x i8>, <16 x i8>* %19, align 16
  %21 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %17, <16 x i8> %20) #9
  %22 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %23 = bitcast <2 x i64>* %22 to <16 x i8>*
  %24 = load <16 x i8>, <16 x i8>* %23, align 16
  %25 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %26 = bitcast <2 x i64>* %25 to <16 x i8>*
  %27 = load <16 x i8>, <16 x i8>* %26, align 16
  %28 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %24, <16 x i8> %27) #9
  %29 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %30 = bitcast <2 x i64>* %29 to <16 x i8>*
  %31 = load <16 x i8>, <16 x i8>* %30, align 16
  %32 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %33 = bitcast <2 x i64>* %32 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 16
  %35 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %31, <16 x i8> %34) #9
  %36 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %17, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>) #9
  %37 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %7, <8 x i16> %14) #9
  %38 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %37, <8 x i16> %21) #9
  %39 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %38, <8 x i16> %28) #9
  %40 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %39, <8 x i16> %35) #9
  %41 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %40, <8 x i16> %36) #9
  %42 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %41, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %43 = ashr <8 x i16> %42, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %44 = bitcast <8 x i16> %43 to <2 x i64>
  ret <2 x i64> %44
}

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nofree nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nounwind readnone }
attributes #6 = { nounwind readnone speculatable }
attributes #7 = { inlinehint nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { inlinehint nounwind readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
