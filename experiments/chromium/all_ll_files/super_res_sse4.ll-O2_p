; ModuleID = '../../third_party/libgav1/src/src/dsp/x86/super_res_sse4.cc'
source_filename = "../../third_party/libgav1/src/src/dsp/x86/super_res_sse4.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%"struct.libgav1::dsp::Dsp" = type { void (i8*, i8*, i32, i32, i8*, i64)*, void (i8*, i64, i8*, i32*)*, [2 x [3 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*]], [19 x void (i8*, i64, [32 x i16]*, i32)*], [19 x [3 x void ([32 x i16]*, i32, i32, i8*, i64)*]], [2 x [2 x [2 x [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i8*, i64)*]]]], [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i32, i32, i8*, i64)*], void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i64, i8*, i8*, i32, i32, i32, i32, i1, i1)*, void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i8*, i8, i8, i32, i32, i8*, i64)*, %"struct.libgav1::dsp::FilmGrainFuncs", void (i8*, i64, i8*, i8*, i8, i32, i32)*, [3 x void (i8*, i8*, i64, i8*, i64, i32, i32)*], void (i8*, i32, i32)*, void (i8*, i32)*, [19 x [10 x void (i8*, i64, i8*, i8*)*]], [4 x [5 x [2 x void (i8, i8, i32, i8*, i32, i32, i8*)*]]], [4 x [2 x void (i8*, i64, i32, i32, i32)*]], [2 x void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)*], [3 x [2 x void (i8*, i8*, i64, i8*, i64, i32, i32, i8*, i64)*]], void (%"struct.libgav1::ReferenceInfo"*, i32, i32, i32, i32, i32, i32, %"struct.libgav1::TemporalMotionField"*)*, [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32*, i32, %"union.libgav1::CompoundMotionVector"*)*], [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32, i32, %"struct.libgav1::MotionVector"*)*], [2 x void (i8*, i64, i32, i32, i8*, i64)*], void (i32, i32, i32, i8*)*, void (i8*, i8*, i64, i32, i32, i32, i32, i32, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, [6 x [6 x [2 x void (i8*, i8*, i8*, i64)*]]] }
%"struct.libgav1::dsp::FilmGrainFuncs" = type { [3 x void (%"struct.libgav1::FilmGrainParams"*, i8*)*], [2 x [4 x void (%"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i8*, i8*)*]], [2 x void (i8*, i32, i32, i32, i32, i32, i8*)*], void (i8*, i32, i32, i32, i32, i8*)*, void (i32, i8*, i8*, i8*)*, void (i8*, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64)*, [2 x void (i8, %"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64, i8*, i64)*] }
%"struct.libgav1::FilmGrainParams" = type { i8, i8, i8, i8, i8, i8, i8, i8, [14 x i8], [14 x i8], [10 x i8], [10 x i8], [10 x i8], [10 x i8], i8, i8, [24 x i8], [25 x i8], [25 x i8], i8, i16, i32, i32, i8, i8, i16, i8, i8, i16 }
%"struct.libgav1::RestorationUnitInfo" = type { i8, %"struct.libgav1::SgrProjInfo", [16 x i8], %"struct.libgav1::WienerInfo" }
%"struct.libgav1::SgrProjInfo" = type { i32, [2 x i32] }
%"struct.libgav1::WienerInfo" = type { [2 x i16], [28 x i8], [2 x [4 x i16]], [16 x i8] }
%"union.libgav1::RestorationBuffer" = type { %"struct.libgav1::SgrBuffer", [5024 x i8] }
%"struct.libgav1::SgrBuffer" = type { [1152 x i16], [1440 x i16], [1152 x i32], [1440 x i32], [1024 x i16], [768 x i16], [512 x i16], [1024 x i32], [768 x i32], [512 x i32], [288 x i8], [288 x i32] }
%"struct.libgav1::ReferenceInfo" = type { %"struct.std::__1::array", %"struct.std::__1::array.0", %"struct.std::__1::array.0", %"struct.std::__1::array.1", %"struct.std::__1::array.2", %"class.libgav1::Array2D", %"class.libgav1::Array2D.4" }
%"struct.std::__1::array" = type { [8 x i8] }
%"struct.std::__1::array.0" = type { [8 x i8] }
%"struct.std::__1::array.1" = type { [8 x i8] }
%"struct.std::__1::array.2" = type { [8 x i16] }
%"class.libgav1::Array2D" = type { %"class.std::__1::unique_ptr", i64, i64, %"class.libgav1::Array2DView" }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { i8* }
%"class.libgav1::Array2DView" = type { i32, i32, i8* }
%"class.libgav1::Array2D.4" = type { %"class.std::__1::unique_ptr.5", i64, i64, %"class.libgav1::Array2DView.11" }
%"class.std::__1::unique_ptr.5" = type { %"class.std::__1::__compressed_pair.6" }
%"class.std::__1::__compressed_pair.6" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::__compressed_pair_elem.7" = type { %"struct.libgav1::MotionVector"* }
%"struct.libgav1::MotionVector" = type { %union.anon }
%union.anon = type { i32 }
%"class.libgav1::Array2DView.11" = type { i32, i32, %"struct.libgav1::MotionVector"* }
%"struct.libgav1::TemporalMotionField" = type { %"class.libgav1::Array2D.4", %"class.libgav1::Array2D.12" }
%"class.libgav1::Array2D.12" = type { %"class.std::__1::unique_ptr.13", i64, i64, %"class.libgav1::Array2DView.19" }
%"class.std::__1::unique_ptr.13" = type { %"class.std::__1::__compressed_pair.14" }
%"class.std::__1::__compressed_pair.14" = type { %"struct.std::__1::__compressed_pair_elem.15" }
%"struct.std::__1::__compressed_pair_elem.15" = type { i8* }
%"class.libgav1::Array2DView.19" = type { i32, i32, i8* }
%"union.libgav1::CompoundMotionVector" = type { i64 }

@_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE = internal unnamed_addr constant [64 x [8 x i8]] [[8 x i8] c"\00\00\00\80\00\00\00\00", [8 x i8] c"\00\00\01\80\FE\01\00\00", [8 x i8] c"\00\FF\03\81\FC\02\FF\00", [8 x i8] c"\00\FF\04\81\FA\03\FF\00", [8 x i8] c"\00\FE\06\82\F8\03\FF\00", [8 x i8] c"\00\FE\07\83\F5\04\FF\00", [8 x i8] c"\01\FE\08\83\F3\05\FE\00", [8 x i8] c"\01\FD\09\84\F1\06\FE\00", [8 x i8] c"\01\FD\0A\85\EE\06\FE\01", [8 x i8] c"\01\FD\0B\86\EC\07\FD\01", [8 x i8] c"\01\FC\0C\87\EA\08\FD\01", [8 x i8] c"\01\FC\0D\88\E7\09\FD\01", [8 x i8] c"\01\FC\0E\8A\E4\09\FD\01", [8 x i8] c"\01\FC\0F\8B\E2\0A\FC\01", [8 x i8] c"\01\FB\10\8C\E0\0B\FC\01", [8 x i8] c"\01\FB\10\8E\DD\0C\FC\01", [8 x i8] c"\01\FB\11\90\DA\0C\FC\01", [8 x i8] c"\01\FB\12\91\D8\0D\FB\01", [8 x i8] c"\01\FB\12\93\D5\0E\FB\01", [8 x i8] c"\01\FA\13\95\D3\0E\FB\01", [8 x i8] c"\01\FA\13\97\D0\0F\FB\01", [8 x i8] c"\01\FA\13\99\CD\10\FB\01", [8 x i8] c"\01\FA\14\9B\CB\10\FA\01", [8 x i8] c"\01\FA\14\9D\C8\11\FA\01", [8 x i8] c"\01\FA\14\9F\C6\11\FA\01", [8 x i8] c"\01\FA\14\A1\C3\12\FA\01", [8 x i8] c"\02\F9\14\A3\C0\12\FA\02", [8 x i8] c"\02\F9\14\A5\BE\13\FA\01", [8 x i8] c"\02\F9\14\A8\BB\13\FA\01", [8 x i8] c"\02\F9\14\AA\B9\13\FA\01", [8 x i8] c"\02\F9\14\AC\B6\14\F9\02", [8 x i8] c"\02\F9\14\AF\B4\14\F9\01", [8 x i8] c"\02\F9\14\B1\B1\14\F9\02", [8 x i8] c"\01\F9\14\B4\AF\14\F9\02", [8 x i8] c"\02\F9\14\B6\AC\14\F9\02", [8 x i8] c"\01\FA\13\B9\AA\14\F9\02", [8 x i8] c"\01\FA\13\BB\A8\14\F9\02", [8 x i8] c"\01\FA\13\BE\A5\14\F9\02", [8 x i8] c"\02\FA\12\C0\A3\14\F9\02", [8 x i8] c"\01\FA\12\C3\A1\14\FA\01", [8 x i8] c"\01\FA\11\C6\9F\14\FA\01", [8 x i8] c"\01\FA\11\C8\9D\14\FA\01", [8 x i8] c"\01\FA\10\CB\9B\14\FA\01", [8 x i8] c"\01\FB\10\CD\99\13\FA\01", [8 x i8] c"\01\FB\0F\D0\97\13\FA\01", [8 x i8] c"\01\FB\0E\D3\95\13\FA\01", [8 x i8] c"\01\FB\0E\D5\93\12\FB\01", [8 x i8] c"\01\FB\0D\D8\91\12\FB\01", [8 x i8] c"\01\FC\0C\DA\90\11\FB\01", [8 x i8] c"\01\FC\0C\DD\8E\10\FB\01", [8 x i8] c"\01\FC\0B\E0\8C\10\FB\01", [8 x i8] c"\01\FC\0A\E2\8B\0F\FC\01", [8 x i8] c"\01\FD\09\E4\8A\0E\FC\01", [8 x i8] c"\01\FD\09\E7\88\0D\FC\01", [8 x i8] c"\01\FD\08\EA\87\0C\FC\01", [8 x i8] c"\01\FD\07\EC\86\0B\FD\01", [8 x i8] c"\01\FE\06\EE\85\0A\FD\01", [8 x i8] c"\00\FE\06\F1\84\09\FD\01", [8 x i8] c"\00\FE\05\F3\83\08\FE\01", [8 x i8] c"\00\FF\04\F5\83\07\FE\00", [8 x i8] c"\00\FF\03\F8\82\06\FE\00", [8 x i8] c"\00\FF\03\FA\81\04\FF\00", [8 x i8] c"\00\FF\02\FC\81\03\FF\00", [8 x i8] c"\00\00\01\FE\80\01\00\00"], align 16
@_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_114kUpscaleFilterE = internal unnamed_addr constant [64 x [8 x i16]] [[8 x i16] [i16 0, i16 0, i16 0, i16 128, i16 0, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 -1, i16 128, i16 2, i16 -1, i16 0, i16 0], [8 x i16] [i16 0, i16 1, i16 -3, i16 127, i16 4, i16 -2, i16 1, i16 0], [8 x i16] [i16 0, i16 1, i16 -4, i16 127, i16 6, i16 -3, i16 1, i16 0], [8 x i16] [i16 0, i16 2, i16 -6, i16 126, i16 8, i16 -3, i16 1, i16 0], [8 x i16] [i16 0, i16 2, i16 -7, i16 125, i16 11, i16 -4, i16 1, i16 0], [8 x i16] [i16 -1, i16 2, i16 -8, i16 125, i16 13, i16 -5, i16 2, i16 0], [8 x i16] [i16 -1, i16 3, i16 -9, i16 124, i16 15, i16 -6, i16 2, i16 0], [8 x i16] [i16 -1, i16 3, i16 -10, i16 123, i16 18, i16 -6, i16 2, i16 -1], [8 x i16] [i16 -1, i16 3, i16 -11, i16 122, i16 20, i16 -7, i16 3, i16 -1], [8 x i16] [i16 -1, i16 4, i16 -12, i16 121, i16 22, i16 -8, i16 3, i16 -1], [8 x i16] [i16 -1, i16 4, i16 -13, i16 120, i16 25, i16 -9, i16 3, i16 -1], [8 x i16] [i16 -1, i16 4, i16 -14, i16 118, i16 28, i16 -9, i16 3, i16 -1], [8 x i16] [i16 -1, i16 4, i16 -15, i16 117, i16 30, i16 -10, i16 4, i16 -1], [8 x i16] [i16 -1, i16 5, i16 -16, i16 116, i16 32, i16 -11, i16 4, i16 -1], [8 x i16] [i16 -1, i16 5, i16 -16, i16 114, i16 35, i16 -12, i16 4, i16 -1], [8 x i16] [i16 -1, i16 5, i16 -17, i16 112, i16 38, i16 -12, i16 4, i16 -1], [8 x i16] [i16 -1, i16 5, i16 -18, i16 111, i16 40, i16 -13, i16 5, i16 -1], [8 x i16] [i16 -1, i16 5, i16 -18, i16 109, i16 43, i16 -14, i16 5, i16 -1], [8 x i16] [i16 -1, i16 6, i16 -19, i16 107, i16 45, i16 -14, i16 5, i16 -1], [8 x i16] [i16 -1, i16 6, i16 -19, i16 105, i16 48, i16 -15, i16 5, i16 -1], [8 x i16] [i16 -1, i16 6, i16 -19, i16 103, i16 51, i16 -16, i16 5, i16 -1], [8 x i16] [i16 -1, i16 6, i16 -20, i16 101, i16 53, i16 -16, i16 6, i16 -1], [8 x i16] [i16 -1, i16 6, i16 -20, i16 99, i16 56, i16 -17, i16 6, i16 -1], [8 x i16] [i16 -1, i16 6, i16 -20, i16 97, i16 58, i16 -17, i16 6, i16 -1], [8 x i16] [i16 -1, i16 6, i16 -20, i16 95, i16 61, i16 -18, i16 6, i16 -1], [8 x i16] [i16 -2, i16 7, i16 -20, i16 93, i16 64, i16 -18, i16 6, i16 -2], [8 x i16] [i16 -2, i16 7, i16 -20, i16 91, i16 66, i16 -19, i16 6, i16 -1], [8 x i16] [i16 -2, i16 7, i16 -20, i16 88, i16 69, i16 -19, i16 6, i16 -1], [8 x i16] [i16 -2, i16 7, i16 -20, i16 86, i16 71, i16 -19, i16 6, i16 -1], [8 x i16] [i16 -2, i16 7, i16 -20, i16 84, i16 74, i16 -20, i16 7, i16 -2], [8 x i16] [i16 -2, i16 7, i16 -20, i16 81, i16 76, i16 -20, i16 7, i16 -1], [8 x i16] [i16 -2, i16 7, i16 -20, i16 79, i16 79, i16 -20, i16 7, i16 -2], [8 x i16] [i16 -1, i16 7, i16 -20, i16 76, i16 81, i16 -20, i16 7, i16 -2], [8 x i16] [i16 -2, i16 7, i16 -20, i16 74, i16 84, i16 -20, i16 7, i16 -2], [8 x i16] [i16 -1, i16 6, i16 -19, i16 71, i16 86, i16 -20, i16 7, i16 -2], [8 x i16] [i16 -1, i16 6, i16 -19, i16 69, i16 88, i16 -20, i16 7, i16 -2], [8 x i16] [i16 -1, i16 6, i16 -19, i16 66, i16 91, i16 -20, i16 7, i16 -2], [8 x i16] [i16 -2, i16 6, i16 -18, i16 64, i16 93, i16 -20, i16 7, i16 -2], [8 x i16] [i16 -1, i16 6, i16 -18, i16 61, i16 95, i16 -20, i16 6, i16 -1], [8 x i16] [i16 -1, i16 6, i16 -17, i16 58, i16 97, i16 -20, i16 6, i16 -1], [8 x i16] [i16 -1, i16 6, i16 -17, i16 56, i16 99, i16 -20, i16 6, i16 -1], [8 x i16] [i16 -1, i16 6, i16 -16, i16 53, i16 101, i16 -20, i16 6, i16 -1], [8 x i16] [i16 -1, i16 5, i16 -16, i16 51, i16 103, i16 -19, i16 6, i16 -1], [8 x i16] [i16 -1, i16 5, i16 -15, i16 48, i16 105, i16 -19, i16 6, i16 -1], [8 x i16] [i16 -1, i16 5, i16 -14, i16 45, i16 107, i16 -19, i16 6, i16 -1], [8 x i16] [i16 -1, i16 5, i16 -14, i16 43, i16 109, i16 -18, i16 5, i16 -1], [8 x i16] [i16 -1, i16 5, i16 -13, i16 40, i16 111, i16 -18, i16 5, i16 -1], [8 x i16] [i16 -1, i16 4, i16 -12, i16 38, i16 112, i16 -17, i16 5, i16 -1], [8 x i16] [i16 -1, i16 4, i16 -12, i16 35, i16 114, i16 -16, i16 5, i16 -1], [8 x i16] [i16 -1, i16 4, i16 -11, i16 32, i16 116, i16 -16, i16 5, i16 -1], [8 x i16] [i16 -1, i16 4, i16 -10, i16 30, i16 117, i16 -15, i16 4, i16 -1], [8 x i16] [i16 -1, i16 3, i16 -9, i16 28, i16 118, i16 -14, i16 4, i16 -1], [8 x i16] [i16 -1, i16 3, i16 -9, i16 25, i16 120, i16 -13, i16 4, i16 -1], [8 x i16] [i16 -1, i16 3, i16 -8, i16 22, i16 121, i16 -12, i16 4, i16 -1], [8 x i16] [i16 -1, i16 3, i16 -7, i16 20, i16 122, i16 -11, i16 3, i16 -1], [8 x i16] [i16 -1, i16 2, i16 -6, i16 18, i16 123, i16 -10, i16 3, i16 -1], [8 x i16] [i16 0, i16 2, i16 -6, i16 15, i16 124, i16 -9, i16 3, i16 -1], [8 x i16] [i16 0, i16 2, i16 -5, i16 13, i16 125, i16 -8, i16 2, i16 -1], [8 x i16] [i16 0, i16 1, i16 -4, i16 11, i16 125, i16 -7, i16 2, i16 0], [8 x i16] [i16 0, i16 1, i16 -3, i16 8, i16 126, i16 -6, i16 2, i16 0], [8 x i16] [i16 0, i16 1, i16 -3, i16 6, i16 127, i16 -4, i16 1, i16 0], [8 x i16] [i16 0, i16 1, i16 -2, i16 4, i16 127, i16 -3, i16 1, i16 0], [8 x i16] [i16 0, i16 0, i16 -1, i16 2, i16 128, i16 -1, i16 0, i16 0]], align 16

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN7libgav13dsp19SuperResInit_SSE4_1Ev() local_unnamed_addr #0 {
  %1 = tail call %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32 8) #7
  %2 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 25
  store void (i32, i32, i32, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SuperResCoefficients_SSE4_1EiiiPv, void (i32, i32, i32, i8*)** %2, align 8
  %3 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 26
  store void (i8*, i8*, i64, i32, i32, i32, i32, i32, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115SuperRes_SSE4_1EPKvPvliiiiiS5_l, void (i8*, i8*, i64, i32, i32, i32, i32, i32, i8*, i64)** %3, align 8
  %4 = tail call %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32 10) #7
  %5 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %4, i64 0, i32 25
  store void (i32, i32, i32, i8*)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_127SuperResCoefficients_SSE4_1EiiiPv, void (i32, i32, i32, i8*)** %5, align 8
  %6 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %4, i64 0, i32 26
  store void (i8*, i8*, i64, i32, i32, i32, i32, i32, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_115SuperRes_SSE4_1ILi10EEEvPKvPvliiiiiS6_l, void (i8*, i8*, i64, i32, i32, i32, i32, i32, i8*, i64)** %6, align 8
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

declare %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32) local_unnamed_addr #2

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127SuperResCoefficients_SSE4_1EiiiPv(i32, i32, i32, i8* nocapture) #3 {
  %5 = add i32 %0, 15
  %6 = ashr i32 %5, 4
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i32 [ %6, %4 ], [ %171, %7 ]
  %9 = phi i32 [ %1, %4 ], [ %168, %7 ]
  %10 = phi i8* [ %3, %4 ], [ %170, %7 ]
  %11 = lshr i32 %9, 8
  %12 = and i32 %11, 63
  %13 = zext i32 %12 to i64
  %14 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %13, i64 0
  %15 = bitcast i8* %14 to i64*
  %16 = load i64, i64* %15, align 8
  %17 = insertelement <2 x i64> undef, i64 %16, i32 0
  %18 = add nsw i32 %9, %2
  %19 = lshr i32 %18, 8
  %20 = and i32 %19, 63
  %21 = zext i32 %20 to i64
  %22 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %21, i64 0
  %23 = bitcast <2 x i64> %17 to <4 x float>
  %24 = bitcast i8* %22 to <2 x float>*
  %25 = load <2 x float>, <2 x float>* %24, align 8
  %26 = shufflevector <2 x float> %25, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %27 = shufflevector <4 x float> %23, <4 x float> %26, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %28 = add nsw i32 %18, %2
  %29 = bitcast i8* %10 to <4 x float>*
  store <4 x float> %27, <4 x float>* %29, align 16
  %30 = getelementptr inbounds i8, i8* %10, i64 16
  %31 = lshr i32 %28, 8
  %32 = and i32 %31, 63
  %33 = zext i32 %32 to i64
  %34 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %33, i64 0
  %35 = bitcast i8* %34 to i64*
  %36 = load i64, i64* %35, align 8
  %37 = insertelement <2 x i64> undef, i64 %36, i32 0
  %38 = add nsw i32 %28, %2
  %39 = lshr i32 %38, 8
  %40 = and i32 %39, 63
  %41 = zext i32 %40 to i64
  %42 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %41, i64 0
  %43 = bitcast <2 x i64> %37 to <4 x float>
  %44 = bitcast i8* %42 to <2 x float>*
  %45 = load <2 x float>, <2 x float>* %44, align 8
  %46 = shufflevector <2 x float> %45, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %47 = shufflevector <4 x float> %43, <4 x float> %46, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %48 = add nsw i32 %38, %2
  %49 = bitcast i8* %30 to <4 x float>*
  store <4 x float> %47, <4 x float>* %49, align 16
  %50 = getelementptr inbounds i8, i8* %10, i64 32
  %51 = lshr i32 %48, 8
  %52 = and i32 %51, 63
  %53 = zext i32 %52 to i64
  %54 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %53, i64 0
  %55 = bitcast i8* %54 to i64*
  %56 = load i64, i64* %55, align 8
  %57 = insertelement <2 x i64> undef, i64 %56, i32 0
  %58 = add nsw i32 %48, %2
  %59 = lshr i32 %58, 8
  %60 = and i32 %59, 63
  %61 = zext i32 %60 to i64
  %62 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %61, i64 0
  %63 = bitcast <2 x i64> %57 to <4 x float>
  %64 = bitcast i8* %62 to <2 x float>*
  %65 = load <2 x float>, <2 x float>* %64, align 8
  %66 = shufflevector <2 x float> %65, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %67 = shufflevector <4 x float> %63, <4 x float> %66, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %68 = add nsw i32 %58, %2
  %69 = bitcast i8* %50 to <4 x float>*
  store <4 x float> %67, <4 x float>* %69, align 16
  %70 = getelementptr inbounds i8, i8* %10, i64 48
  %71 = lshr i32 %68, 8
  %72 = and i32 %71, 63
  %73 = zext i32 %72 to i64
  %74 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %73, i64 0
  %75 = bitcast i8* %74 to i64*
  %76 = load i64, i64* %75, align 8
  %77 = insertelement <2 x i64> undef, i64 %76, i32 0
  %78 = add nsw i32 %68, %2
  %79 = lshr i32 %78, 8
  %80 = and i32 %79, 63
  %81 = zext i32 %80 to i64
  %82 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %81, i64 0
  %83 = bitcast <2 x i64> %77 to <4 x float>
  %84 = bitcast i8* %82 to <2 x float>*
  %85 = load <2 x float>, <2 x float>* %84, align 8
  %86 = shufflevector <2 x float> %85, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %87 = shufflevector <4 x float> %83, <4 x float> %86, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %88 = add nsw i32 %78, %2
  %89 = bitcast i8* %70 to <4 x float>*
  store <4 x float> %87, <4 x float>* %89, align 16
  %90 = getelementptr inbounds i8, i8* %10, i64 64
  %91 = lshr i32 %88, 8
  %92 = and i32 %91, 63
  %93 = zext i32 %92 to i64
  %94 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %93, i64 0
  %95 = bitcast i8* %94 to i64*
  %96 = load i64, i64* %95, align 8
  %97 = insertelement <2 x i64> undef, i64 %96, i32 0
  %98 = add nsw i32 %88, %2
  %99 = lshr i32 %98, 8
  %100 = and i32 %99, 63
  %101 = zext i32 %100 to i64
  %102 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %101, i64 0
  %103 = bitcast <2 x i64> %97 to <4 x float>
  %104 = bitcast i8* %102 to <2 x float>*
  %105 = load <2 x float>, <2 x float>* %104, align 8
  %106 = shufflevector <2 x float> %105, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %107 = shufflevector <4 x float> %103, <4 x float> %106, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %108 = add nsw i32 %98, %2
  %109 = bitcast i8* %90 to <4 x float>*
  store <4 x float> %107, <4 x float>* %109, align 16
  %110 = getelementptr inbounds i8, i8* %10, i64 80
  %111 = lshr i32 %108, 8
  %112 = and i32 %111, 63
  %113 = zext i32 %112 to i64
  %114 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %113, i64 0
  %115 = bitcast i8* %114 to i64*
  %116 = load i64, i64* %115, align 8
  %117 = insertelement <2 x i64> undef, i64 %116, i32 0
  %118 = add nsw i32 %108, %2
  %119 = lshr i32 %118, 8
  %120 = and i32 %119, 63
  %121 = zext i32 %120 to i64
  %122 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %121, i64 0
  %123 = bitcast <2 x i64> %117 to <4 x float>
  %124 = bitcast i8* %122 to <2 x float>*
  %125 = load <2 x float>, <2 x float>* %124, align 8
  %126 = shufflevector <2 x float> %125, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %127 = shufflevector <4 x float> %123, <4 x float> %126, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %128 = add nsw i32 %118, %2
  %129 = bitcast i8* %110 to <4 x float>*
  store <4 x float> %127, <4 x float>* %129, align 16
  %130 = getelementptr inbounds i8, i8* %10, i64 96
  %131 = lshr i32 %128, 8
  %132 = and i32 %131, 63
  %133 = zext i32 %132 to i64
  %134 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %133, i64 0
  %135 = bitcast i8* %134 to i64*
  %136 = load i64, i64* %135, align 8
  %137 = insertelement <2 x i64> undef, i64 %136, i32 0
  %138 = add nsw i32 %128, %2
  %139 = lshr i32 %138, 8
  %140 = and i32 %139, 63
  %141 = zext i32 %140 to i64
  %142 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %141, i64 0
  %143 = bitcast <2 x i64> %137 to <4 x float>
  %144 = bitcast i8* %142 to <2 x float>*
  %145 = load <2 x float>, <2 x float>* %144, align 8
  %146 = shufflevector <2 x float> %145, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %147 = shufflevector <4 x float> %143, <4 x float> %146, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %148 = add nsw i32 %138, %2
  %149 = bitcast i8* %130 to <4 x float>*
  store <4 x float> %147, <4 x float>* %149, align 16
  %150 = getelementptr inbounds i8, i8* %10, i64 112
  %151 = lshr i32 %148, 8
  %152 = and i32 %151, 63
  %153 = zext i32 %152 to i64
  %154 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %153, i64 0
  %155 = bitcast i8* %154 to i64*
  %156 = load i64, i64* %155, align 8
  %157 = insertelement <2 x i64> undef, i64 %156, i32 0
  %158 = add nsw i32 %148, %2
  %159 = lshr i32 %158, 8
  %160 = and i32 %159, 63
  %161 = zext i32 %160 to i64
  %162 = getelementptr inbounds [64 x [8 x i8]], [64 x [8 x i8]]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122kNegativeUpscaleFilterE, i64 0, i64 %161, i64 0
  %163 = bitcast <2 x i64> %157 to <4 x float>
  %164 = bitcast i8* %162 to <2 x float>*
  %165 = load <2 x float>, <2 x float>* %164, align 8
  %166 = shufflevector <2 x float> %165, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %167 = shufflevector <4 x float> %163, <4 x float> %166, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %168 = add nsw i32 %158, %2
  %169 = bitcast i8* %150 to <4 x float>*
  store <4 x float> %167, <4 x float>* %169, align 16
  %170 = getelementptr inbounds i8, i8* %10, i64 128
  %171 = add nsw i32 %8, -1
  %172 = icmp eq i32 %171, 0
  br i1 %172, label %173, label %7

173:                                              ; preds = %7
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115SuperRes_SSE4_1EPKvPvliiiiiS5_l(i8* nocapture readonly, i8* nocapture, i64, i32, i32, i32, i32, i32, i8* nocapture, i64) #4 {
  %11 = alloca [8 x <2 x i64>], align 16
  %12 = getelementptr inbounds i8, i8* %1, i64 -4
  %13 = sext i32 %4 to i64
  %14 = add nsw i32 %4, -1
  %15 = sext i32 %14 to i64
  %16 = add i32 %5, 15
  %17 = ashr i32 %16, 4
  %18 = bitcast [8 x <2 x i64>]* %11 to <8 x i16>*
  %19 = bitcast [8 x <2 x i64>]* %11 to i8*
  %20 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %11, i64 0, i64 1
  %21 = bitcast <2 x i64>* %20 to <8 x i16>*
  %22 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %11, i64 0, i64 2
  %23 = bitcast <2 x i64>* %22 to <8 x i16>*
  %24 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %11, i64 0, i64 3
  %25 = bitcast <2 x i64>* %24 to <8 x i16>*
  %26 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %11, i64 0, i64 4
  %27 = bitcast <2 x i64>* %26 to <8 x i16>*
  %28 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %11, i64 0, i64 5
  %29 = bitcast <2 x i64>* %28 to <8 x i16>*
  %30 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %11, i64 0, i64 6
  %31 = bitcast <2 x i64>* %30 to <8 x i16>*
  %32 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %11, i64 0, i64 7
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = bitcast [8 x <2 x i64>]* %11 to <8 x i16>*
  br label %35

35:                                               ; preds = %247, %10
  %36 = phi i32 [ %3, %10 ], [ %250, %247 ]
  %37 = phi i8* [ %8, %10 ], [ %249, %247 ]
  %38 = phi i8* [ %12, %10 ], [ %248, %247 ]
  %39 = getelementptr inbounds i8, i8* %38, i64 4
  %40 = load i8, i8* %39, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %38, i8 %40, i64 4, i1 false) #7
  %41 = getelementptr inbounds i8, i8* %39, i64 %13
  %42 = getelementptr inbounds i8, i8* %39, i64 %15
  %43 = load i8, i8* %42, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %41, i8 %43, i64 4, i1 false) #7
  br label %44

44:                                               ; preds = %44, %35
  %45 = phi i32 [ %6, %35 ], [ %211, %44 ]
  %46 = phi i32 [ %17, %35 ], [ %245, %44 ]
  %47 = phi i8* [ %37, %35 ], [ %244, %44 ]
  %48 = phi i8* [ %0, %35 ], [ %216, %44 ]
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %19) #7
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %19, i8 -86, i64 128, i1 false)
  %49 = ashr i32 %45, 14
  %50 = sext i32 %49 to i64
  %51 = getelementptr inbounds i8, i8* %38, i64 %50
  %52 = bitcast i8* %51 to i64*
  %53 = load i64, i64* %52, align 1
  %54 = insertelement <2 x i64> undef, i64 %53, i32 0
  %55 = add nsw i32 %45, %7
  %56 = ashr i32 %55, 14
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i8, i8* %38, i64 %57
  %59 = bitcast <2 x i64> %54 to <4 x float>
  %60 = bitcast i8* %58 to <2 x float>*
  %61 = load <2 x float>, <2 x float>* %60, align 1
  %62 = shufflevector <2 x float> %61, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %63 = shufflevector <4 x float> %59, <4 x float> %62, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %64 = add nsw i32 %55, %7
  %65 = bitcast i8* %48 to <16 x i8>*
  %66 = load <16 x i8>, <16 x i8>* %65, align 16
  %67 = bitcast <4 x float> %63 to <16 x i8>
  %68 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %67, <16 x i8> %66) #7
  store <8 x i16> %68, <8 x i16>* %34, align 16
  %69 = getelementptr inbounds i8, i8* %48, i64 16
  %70 = ashr i32 %64, 14
  %71 = sext i32 %70 to i64
  %72 = getelementptr inbounds i8, i8* %38, i64 %71
  %73 = bitcast i8* %72 to i64*
  %74 = load i64, i64* %73, align 1
  %75 = insertelement <2 x i64> undef, i64 %74, i32 0
  %76 = add nsw i32 %64, %7
  %77 = ashr i32 %76, 14
  %78 = sext i32 %77 to i64
  %79 = getelementptr inbounds i8, i8* %38, i64 %78
  %80 = bitcast <2 x i64> %75 to <4 x float>
  %81 = bitcast i8* %79 to <2 x float>*
  %82 = load <2 x float>, <2 x float>* %81, align 1
  %83 = shufflevector <2 x float> %82, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %84 = shufflevector <4 x float> %80, <4 x float> %83, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %85 = add nsw i32 %76, %7
  %86 = bitcast i8* %69 to <16 x i8>*
  %87 = load <16 x i8>, <16 x i8>* %86, align 16
  %88 = bitcast <4 x float> %84 to <16 x i8>
  %89 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %88, <16 x i8> %87) #7
  store <8 x i16> %89, <8 x i16>* %21, align 16
  %90 = getelementptr inbounds i8, i8* %48, i64 32
  %91 = ashr i32 %85, 14
  %92 = sext i32 %91 to i64
  %93 = getelementptr inbounds i8, i8* %38, i64 %92
  %94 = bitcast i8* %93 to i64*
  %95 = load i64, i64* %94, align 1
  %96 = insertelement <2 x i64> undef, i64 %95, i32 0
  %97 = add nsw i32 %85, %7
  %98 = ashr i32 %97, 14
  %99 = sext i32 %98 to i64
  %100 = getelementptr inbounds i8, i8* %38, i64 %99
  %101 = bitcast <2 x i64> %96 to <4 x float>
  %102 = bitcast i8* %100 to <2 x float>*
  %103 = load <2 x float>, <2 x float>* %102, align 1
  %104 = shufflevector <2 x float> %103, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %105 = shufflevector <4 x float> %101, <4 x float> %104, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %106 = add nsw i32 %97, %7
  %107 = bitcast i8* %90 to <16 x i8>*
  %108 = load <16 x i8>, <16 x i8>* %107, align 16
  %109 = bitcast <4 x float> %105 to <16 x i8>
  %110 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %109, <16 x i8> %108) #7
  store <8 x i16> %110, <8 x i16>* %23, align 16
  %111 = getelementptr inbounds i8, i8* %48, i64 48
  %112 = ashr i32 %106, 14
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds i8, i8* %38, i64 %113
  %115 = bitcast i8* %114 to i64*
  %116 = load i64, i64* %115, align 1
  %117 = insertelement <2 x i64> undef, i64 %116, i32 0
  %118 = add nsw i32 %106, %7
  %119 = ashr i32 %118, 14
  %120 = sext i32 %119 to i64
  %121 = getelementptr inbounds i8, i8* %38, i64 %120
  %122 = bitcast <2 x i64> %117 to <4 x float>
  %123 = bitcast i8* %121 to <2 x float>*
  %124 = load <2 x float>, <2 x float>* %123, align 1
  %125 = shufflevector <2 x float> %124, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %126 = shufflevector <4 x float> %122, <4 x float> %125, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %127 = add nsw i32 %118, %7
  %128 = bitcast i8* %111 to <16 x i8>*
  %129 = load <16 x i8>, <16 x i8>* %128, align 16
  %130 = bitcast <4 x float> %126 to <16 x i8>
  %131 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %130, <16 x i8> %129) #7
  store <8 x i16> %131, <8 x i16>* %25, align 16
  %132 = getelementptr inbounds i8, i8* %48, i64 64
  %133 = ashr i32 %127, 14
  %134 = sext i32 %133 to i64
  %135 = getelementptr inbounds i8, i8* %38, i64 %134
  %136 = bitcast i8* %135 to i64*
  %137 = load i64, i64* %136, align 1
  %138 = insertelement <2 x i64> undef, i64 %137, i32 0
  %139 = add nsw i32 %127, %7
  %140 = ashr i32 %139, 14
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds i8, i8* %38, i64 %141
  %143 = bitcast <2 x i64> %138 to <4 x float>
  %144 = bitcast i8* %142 to <2 x float>*
  %145 = load <2 x float>, <2 x float>* %144, align 1
  %146 = shufflevector <2 x float> %145, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %147 = shufflevector <4 x float> %143, <4 x float> %146, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %148 = add nsw i32 %139, %7
  %149 = bitcast i8* %132 to <16 x i8>*
  %150 = load <16 x i8>, <16 x i8>* %149, align 16
  %151 = bitcast <4 x float> %147 to <16 x i8>
  %152 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %151, <16 x i8> %150) #7
  store <8 x i16> %152, <8 x i16>* %27, align 16
  %153 = getelementptr inbounds i8, i8* %48, i64 80
  %154 = ashr i32 %148, 14
  %155 = sext i32 %154 to i64
  %156 = getelementptr inbounds i8, i8* %38, i64 %155
  %157 = bitcast i8* %156 to i64*
  %158 = load i64, i64* %157, align 1
  %159 = insertelement <2 x i64> undef, i64 %158, i32 0
  %160 = add nsw i32 %148, %7
  %161 = ashr i32 %160, 14
  %162 = sext i32 %161 to i64
  %163 = getelementptr inbounds i8, i8* %38, i64 %162
  %164 = bitcast <2 x i64> %159 to <4 x float>
  %165 = bitcast i8* %163 to <2 x float>*
  %166 = load <2 x float>, <2 x float>* %165, align 1
  %167 = shufflevector <2 x float> %166, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %168 = shufflevector <4 x float> %164, <4 x float> %167, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %169 = add nsw i32 %160, %7
  %170 = bitcast i8* %153 to <16 x i8>*
  %171 = load <16 x i8>, <16 x i8>* %170, align 16
  %172 = bitcast <4 x float> %168 to <16 x i8>
  %173 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %172, <16 x i8> %171) #7
  store <8 x i16> %173, <8 x i16>* %29, align 16
  %174 = getelementptr inbounds i8, i8* %48, i64 96
  %175 = ashr i32 %169, 14
  %176 = sext i32 %175 to i64
  %177 = getelementptr inbounds i8, i8* %38, i64 %176
  %178 = bitcast i8* %177 to i64*
  %179 = load i64, i64* %178, align 1
  %180 = insertelement <2 x i64> undef, i64 %179, i32 0
  %181 = add nsw i32 %169, %7
  %182 = ashr i32 %181, 14
  %183 = sext i32 %182 to i64
  %184 = getelementptr inbounds i8, i8* %38, i64 %183
  %185 = bitcast <2 x i64> %180 to <4 x float>
  %186 = bitcast i8* %184 to <2 x float>*
  %187 = load <2 x float>, <2 x float>* %186, align 1
  %188 = shufflevector <2 x float> %187, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %189 = shufflevector <4 x float> %185, <4 x float> %188, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %190 = add nsw i32 %181, %7
  %191 = bitcast i8* %174 to <16 x i8>*
  %192 = load <16 x i8>, <16 x i8>* %191, align 16
  %193 = bitcast <4 x float> %189 to <16 x i8>
  %194 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %193, <16 x i8> %192) #7
  store <8 x i16> %194, <8 x i16>* %31, align 16
  %195 = getelementptr inbounds i8, i8* %48, i64 112
  %196 = ashr i32 %190, 14
  %197 = sext i32 %196 to i64
  %198 = getelementptr inbounds i8, i8* %38, i64 %197
  %199 = bitcast i8* %198 to i64*
  %200 = load i64, i64* %199, align 1
  %201 = insertelement <2 x i64> undef, i64 %200, i32 0
  %202 = add nsw i32 %190, %7
  %203 = ashr i32 %202, 14
  %204 = sext i32 %203 to i64
  %205 = getelementptr inbounds i8, i8* %38, i64 %204
  %206 = bitcast <2 x i64> %201 to <4 x float>
  %207 = bitcast i8* %205 to <2 x float>*
  %208 = load <2 x float>, <2 x float>* %207, align 1
  %209 = shufflevector <2 x float> %208, <2 x float> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %210 = shufflevector <4 x float> %206, <4 x float> %209, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %211 = add nsw i32 %202, %7
  %212 = bitcast i8* %195 to <16 x i8>*
  %213 = load <16 x i8>, <16 x i8>* %212, align 16
  %214 = bitcast <4 x float> %210 to <16 x i8>
  %215 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %214, <16 x i8> %213) #7
  store <8 x i16> %215, <8 x i16>* %33, align 16
  %216 = getelementptr inbounds i8, i8* %48, i64 128
  %217 = load <8 x i16>, <8 x i16>* %18, align 16
  %218 = load <8 x i16>, <8 x i16>* %21, align 16
  %219 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %217, <8 x i16> %218) #7
  %220 = load <8 x i16>, <8 x i16>* %23, align 16
  %221 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %220, <8 x i16> %131) #7
  %222 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %152, <8 x i16> %173) #7
  %223 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %194, <8 x i16> %215) #7
  %224 = shufflevector <8 x i16> %219, <8 x i16> %221, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %225 = shufflevector <8 x i16> %219, <8 x i16> %221, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %226 = shufflevector <8 x i16> %222, <8 x i16> %223, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %227 = shufflevector <8 x i16> %222, <8 x i16> %223, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %228 = shufflevector <8 x i16> %224, <8 x i16> %225, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %229 = shufflevector <8 x i16> %224, <8 x i16> %225, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %230 = shufflevector <8 x i16> %226, <8 x i16> %227, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %231 = shufflevector <8 x i16> %226, <8 x i16> %227, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %232 = shufflevector <8 x i16> %228, <8 x i16> %229, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %233 = shufflevector <8 x i16> %228, <8 x i16> %229, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %234 = shufflevector <8 x i16> %230, <8 x i16> %231, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %235 = shufflevector <8 x i16> %230, <8 x i16> %231, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %236 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %232, <8 x i16> %233) #7
  %237 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %234, <8 x i16> %235) #7
  %238 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>, <8 x i16> %236) #7
  %239 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>, <8 x i16> %237) #7
  %240 = ashr <8 x i16> %238, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %241 = ashr <8 x i16> %239, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %242 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %240, <8 x i16> %241) #7
  %243 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %242, <16 x i8>* %243, align 16
  %244 = getelementptr inbounds i8, i8* %47, i64 16
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %19) #7
  %245 = add nsw i32 %46, -1
  %246 = icmp eq i32 %245, 0
  br i1 %246, label %247, label %44

247:                                              ; preds = %44
  %248 = getelementptr inbounds i8, i8* %38, i64 %2
  %249 = getelementptr inbounds i8, i8* %37, i64 %9
  %250 = add nsw i32 %36, -1
  %251 = icmp eq i32 %250, 0
  br i1 %251, label %252, label %35

252:                                              ; preds = %247
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8>, <16 x i8>) #5

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16>, <8 x i16>) #5

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16>, <8 x i16>) #6

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16>, <8 x i16>) #6

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #5

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_127SuperResCoefficients_SSE4_1EiiiPv(i32, i32, i32, i8* nocapture) #3 {
  %5 = bitcast i8* %3 to i16*
  %6 = add i32 %0, 7
  %7 = ashr i32 %6, 3
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i32 [ %7, %4 ], [ %84, %8 ]
  %10 = phi i32 [ %1, %4 ], [ %81, %8 ]
  %11 = phi i16* [ %5, %4 ], [ %83, %8 ]
  %12 = lshr i32 %10, 8
  %13 = and i32 %12, 63
  %14 = zext i32 %13 to i64
  %15 = getelementptr inbounds [64 x [8 x i16]], [64 x [8 x i16]]* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_114kUpscaleFilterE, i64 0, i64 %14, i64 0
  %16 = bitcast i16* %15 to <2 x i64>*
  %17 = load <2 x i64>, <2 x i64>* %16, align 16
  %18 = add nsw i32 %10, %2
  %19 = bitcast i16* %11 to <2 x i64>*
  store <2 x i64> %17, <2 x i64>* %19, align 16
  %20 = getelementptr inbounds i16, i16* %11, i64 8
  %21 = lshr i32 %18, 8
  %22 = and i32 %21, 63
  %23 = zext i32 %22 to i64
  %24 = getelementptr inbounds [64 x [8 x i16]], [64 x [8 x i16]]* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_114kUpscaleFilterE, i64 0, i64 %23, i64 0
  %25 = bitcast i16* %24 to <2 x i64>*
  %26 = load <2 x i64>, <2 x i64>* %25, align 16
  %27 = add nsw i32 %18, %2
  %28 = bitcast i16* %20 to <2 x i64>*
  store <2 x i64> %26, <2 x i64>* %28, align 16
  %29 = getelementptr inbounds i16, i16* %11, i64 16
  %30 = lshr i32 %27, 8
  %31 = and i32 %30, 63
  %32 = zext i32 %31 to i64
  %33 = getelementptr inbounds [64 x [8 x i16]], [64 x [8 x i16]]* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_114kUpscaleFilterE, i64 0, i64 %32, i64 0
  %34 = bitcast i16* %33 to <2 x i64>*
  %35 = load <2 x i64>, <2 x i64>* %34, align 16
  %36 = add nsw i32 %27, %2
  %37 = bitcast i16* %29 to <2 x i64>*
  store <2 x i64> %35, <2 x i64>* %37, align 16
  %38 = getelementptr inbounds i16, i16* %11, i64 24
  %39 = lshr i32 %36, 8
  %40 = and i32 %39, 63
  %41 = zext i32 %40 to i64
  %42 = getelementptr inbounds [64 x [8 x i16]], [64 x [8 x i16]]* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_114kUpscaleFilterE, i64 0, i64 %41, i64 0
  %43 = bitcast i16* %42 to <2 x i64>*
  %44 = load <2 x i64>, <2 x i64>* %43, align 16
  %45 = add nsw i32 %36, %2
  %46 = bitcast i16* %38 to <2 x i64>*
  store <2 x i64> %44, <2 x i64>* %46, align 16
  %47 = getelementptr inbounds i16, i16* %11, i64 32
  %48 = lshr i32 %45, 8
  %49 = and i32 %48, 63
  %50 = zext i32 %49 to i64
  %51 = getelementptr inbounds [64 x [8 x i16]], [64 x [8 x i16]]* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_114kUpscaleFilterE, i64 0, i64 %50, i64 0
  %52 = bitcast i16* %51 to <2 x i64>*
  %53 = load <2 x i64>, <2 x i64>* %52, align 16
  %54 = add nsw i32 %45, %2
  %55 = bitcast i16* %47 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %55, align 16
  %56 = getelementptr inbounds i16, i16* %11, i64 40
  %57 = lshr i32 %54, 8
  %58 = and i32 %57, 63
  %59 = zext i32 %58 to i64
  %60 = getelementptr inbounds [64 x [8 x i16]], [64 x [8 x i16]]* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_114kUpscaleFilterE, i64 0, i64 %59, i64 0
  %61 = bitcast i16* %60 to <2 x i64>*
  %62 = load <2 x i64>, <2 x i64>* %61, align 16
  %63 = add nsw i32 %54, %2
  %64 = bitcast i16* %56 to <2 x i64>*
  store <2 x i64> %62, <2 x i64>* %64, align 16
  %65 = getelementptr inbounds i16, i16* %11, i64 48
  %66 = lshr i32 %63, 8
  %67 = and i32 %66, 63
  %68 = zext i32 %67 to i64
  %69 = getelementptr inbounds [64 x [8 x i16]], [64 x [8 x i16]]* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_114kUpscaleFilterE, i64 0, i64 %68, i64 0
  %70 = bitcast i16* %69 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 16
  %72 = add nsw i32 %63, %2
  %73 = bitcast i16* %65 to <2 x i64>*
  store <2 x i64> %71, <2 x i64>* %73, align 16
  %74 = getelementptr inbounds i16, i16* %11, i64 56
  %75 = lshr i32 %72, 8
  %76 = and i32 %75, 63
  %77 = zext i32 %76 to i64
  %78 = getelementptr inbounds [64 x [8 x i16]], [64 x [8 x i16]]* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_114kUpscaleFilterE, i64 0, i64 %77, i64 0
  %79 = bitcast i16* %78 to <2 x i64>*
  %80 = load <2 x i64>, <2 x i64>* %79, align 16
  %81 = add nsw i32 %72, %2
  %82 = bitcast i16* %74 to <2 x i64>*
  store <2 x i64> %80, <2 x i64>* %82, align 16
  %83 = getelementptr inbounds i16, i16* %11, i64 64
  %84 = add nsw i32 %9, -1
  %85 = icmp eq i32 %84, 0
  br i1 %85, label %86, label %8

86:                                               ; preds = %8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_115SuperRes_SSE4_1ILi10EEEvPKvPvliiiiiS6_l(i8* nocapture readonly, i8* nocapture, i64, i32, i32, i32, i32, i32, i8* nocapture, i64) #4 {
  %11 = getelementptr inbounds i8, i8* %1, i64 -8
  %12 = bitcast i8* %11 to i16*
  %13 = bitcast i8* %8 to i16*
  %14 = bitcast i8* %0 to i16*
  %15 = sext i32 %4 to i64
  %16 = add nsw i32 %4, -1
  %17 = sext i32 %16 to i64
  %18 = add i32 %5, 7
  %19 = ashr i32 %18, 3
  br label %20

20:                                               ; preds = %145, %10
  %21 = phi i32 [ %3, %10 ], [ %148, %145 ]
  %22 = phi i16* [ %13, %10 ], [ %147, %145 ]
  %23 = phi i16* [ %12, %10 ], [ %146, %145 ]
  %24 = getelementptr inbounds i16, i16* %23, i64 4
  %25 = load i16, i16* %24, align 2
  store i16 %25, i16* %23, align 2
  %26 = getelementptr inbounds i16, i16* %23, i64 1
  store i16 %25, i16* %26, align 2
  %27 = getelementptr inbounds i16, i16* %23, i64 2
  store i16 %25, i16* %27, align 2
  %28 = getelementptr inbounds i16, i16* %23, i64 3
  store i16 %25, i16* %28, align 2
  %29 = getelementptr inbounds i16, i16* %24, i64 %15
  %30 = getelementptr inbounds i16, i16* %24, i64 %17
  %31 = load i16, i16* %30, align 2
  %32 = insertelement <8 x i16> undef, i16 %31, i32 0
  %33 = shufflevector <8 x i16> %32, <8 x i16> undef, <8 x i32> zeroinitializer
  %34 = bitcast i16* %29 to <8 x i16>*
  store <8 x i16> %33, <8 x i16>* %34, align 2
  %35 = getelementptr inbounds i16, i16* %29, i64 8
  store i16 %31, i16* %35, align 2
  %36 = getelementptr inbounds i16, i16* %29, i64 9
  store i16 %31, i16* %36, align 2
  %37 = getelementptr inbounds i16, i16* %29, i64 10
  store i16 %31, i16* %37, align 2
  %38 = getelementptr inbounds i16, i16* %29, i64 11
  store i16 %31, i16* %38, align 2
  %39 = getelementptr inbounds i16, i16* %29, i64 12
  store i16 %31, i16* %39, align 2
  %40 = getelementptr inbounds i16, i16* %29, i64 13
  store i16 %31, i16* %40, align 2
  %41 = getelementptr inbounds i16, i16* %29, i64 14
  store i16 %31, i16* %41, align 2
  %42 = getelementptr inbounds i16, i16* %29, i64 15
  store i16 %31, i16* %42, align 2
  br label %43

43:                                               ; preds = %20, %43
  %44 = phi i16* [ %127, %43 ], [ %14, %20 ]
  %45 = phi i16* [ %142, %43 ], [ %22, %20 ]
  %46 = phi i32 [ %123, %43 ], [ %6, %20 ]
  %47 = phi i32 [ %143, %43 ], [ %19, %20 ]
  %48 = ashr i32 %46, 14
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds i16, i16* %23, i64 %49
  %51 = bitcast i16* %50 to <8 x i16>*
  %52 = load <8 x i16>, <8 x i16>* %51, align 1
  %53 = add nsw i32 %46, %7
  %54 = bitcast i16* %44 to <8 x i16>*
  %55 = load <8 x i16>, <8 x i16>* %54, align 16
  %56 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %52, <8 x i16> %55) #7
  %57 = getelementptr inbounds i16, i16* %44, i64 8
  %58 = ashr i32 %53, 14
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds i16, i16* %23, i64 %59
  %61 = bitcast i16* %60 to <8 x i16>*
  %62 = load <8 x i16>, <8 x i16>* %61, align 1
  %63 = add nsw i32 %53, %7
  %64 = bitcast i16* %57 to <8 x i16>*
  %65 = load <8 x i16>, <8 x i16>* %64, align 16
  %66 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %62, <8 x i16> %65) #7
  %67 = getelementptr inbounds i16, i16* %44, i64 16
  %68 = ashr i32 %63, 14
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds i16, i16* %23, i64 %69
  %71 = bitcast i16* %70 to <8 x i16>*
  %72 = load <8 x i16>, <8 x i16>* %71, align 1
  %73 = add nsw i32 %63, %7
  %74 = bitcast i16* %67 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 16
  %76 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %72, <8 x i16> %75) #7
  %77 = getelementptr inbounds i16, i16* %44, i64 24
  %78 = ashr i32 %73, 14
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i16, i16* %23, i64 %79
  %81 = bitcast i16* %80 to <8 x i16>*
  %82 = load <8 x i16>, <8 x i16>* %81, align 1
  %83 = add nsw i32 %73, %7
  %84 = bitcast i16* %77 to <8 x i16>*
  %85 = load <8 x i16>, <8 x i16>* %84, align 16
  %86 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %82, <8 x i16> %85) #7
  %87 = getelementptr inbounds i16, i16* %44, i64 32
  %88 = ashr i32 %83, 14
  %89 = sext i32 %88 to i64
  %90 = getelementptr inbounds i16, i16* %23, i64 %89
  %91 = bitcast i16* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 1
  %93 = add nsw i32 %83, %7
  %94 = bitcast i16* %87 to <8 x i16>*
  %95 = load <8 x i16>, <8 x i16>* %94, align 16
  %96 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %92, <8 x i16> %95) #7
  %97 = getelementptr inbounds i16, i16* %44, i64 40
  %98 = ashr i32 %93, 14
  %99 = sext i32 %98 to i64
  %100 = getelementptr inbounds i16, i16* %23, i64 %99
  %101 = bitcast i16* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 1
  %103 = add nsw i32 %93, %7
  %104 = bitcast i16* %97 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %102, <8 x i16> %105) #7
  %107 = getelementptr inbounds i16, i16* %44, i64 48
  %108 = ashr i32 %103, 14
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds i16, i16* %23, i64 %109
  %111 = bitcast i16* %110 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 1
  %113 = add nsw i32 %103, %7
  %114 = bitcast i16* %107 to <8 x i16>*
  %115 = load <8 x i16>, <8 x i16>* %114, align 16
  %116 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %112, <8 x i16> %115) #7
  %117 = getelementptr inbounds i16, i16* %44, i64 56
  %118 = ashr i32 %113, 14
  %119 = sext i32 %118 to i64
  %120 = getelementptr inbounds i16, i16* %23, i64 %119
  %121 = bitcast i16* %120 to <8 x i16>*
  %122 = load <8 x i16>, <8 x i16>* %121, align 1
  %123 = add nsw i32 %113, %7
  %124 = bitcast i16* %117 to <8 x i16>*
  %125 = load <8 x i16>, <8 x i16>* %124, align 16
  %126 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %122, <8 x i16> %125) #7
  %127 = getelementptr inbounds i16, i16* %44, i64 64
  %128 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %56, <4 x i32> %66) #7
  %129 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %76, <4 x i32> %86) #7
  %130 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %96, <4 x i32> %106) #7
  %131 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %116, <4 x i32> %126) #7
  %132 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %128, <4 x i32> %129) #7
  %133 = tail call <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32> %130, <4 x i32> %131) #7
  %134 = add <4 x i32> %132, <i32 64, i32 64, i32 64, i32 64>
  %135 = ashr <4 x i32> %134, <i32 7, i32 7, i32 7, i32 7>
  %136 = add <4 x i32> %133, <i32 64, i32 64, i32 64, i32 64>
  %137 = ashr <4 x i32> %136, <i32 7, i32 7, i32 7, i32 7>
  %138 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %135, <4 x i32> %137) #7
  %139 = icmp slt <8 x i16> %138, <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %140 = select <8 x i1> %139, <8 x i16> %138, <8 x i16> <i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023, i16 1023>
  %141 = bitcast i16* %45 to <8 x i16>*
  store <8 x i16> %140, <8 x i16>* %141, align 16
  %142 = getelementptr inbounds i16, i16* %45, i64 8
  %143 = add nsw i32 %47, -1
  %144 = icmp eq i32 %143, 0
  br i1 %144, label %145, label %43

145:                                              ; preds = %43
  %146 = getelementptr inbounds i16, i16* %23, i64 %2
  %147 = getelementptr inbounds i16, i16* %22, i64 %9
  %148 = add nsw i32 %21, -1
  %149 = icmp eq i32 %148, 0
  br i1 %149, label %150, label %20

150:                                              ; preds = %145
  ret void
}

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16>, <8 x i16>) #5

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.ssse3.phadd.d.128(<4 x i32>, <4 x i32>) #5

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32>, <4 x i32>) #5

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nofree norecurse nounwind ssp uwtable writeonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nounwind readnone }
attributes #6 = { nounwind readnone speculatable }
attributes #7 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
