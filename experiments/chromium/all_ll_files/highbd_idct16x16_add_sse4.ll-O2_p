; ModuleID = '../../third_party/libvpx/source/libvpx/vpx_dsp/x86/highbd_idct16x16_add_sse4.c'
source_filename = "../../third_party/libvpx/source/libvpx/vpx_dsp/x86/highbd_idct16x16_add_sse4.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_highbd_idct16_4col_sse4_1(<2 x i64>*) local_unnamed_addr #0 {
  %2 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %3 = bitcast <2 x i64>* %2 to <4 x i32>*
  %4 = load <4 x i32>, <4 x i32>* %3, align 16
  %5 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %6 = bitcast <2 x i64>* %5 to <4 x i32>*
  %7 = load <4 x i32>, <4 x i32>* %6, align 16
  %8 = shufflevector <4 x i32> %4, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %9 = bitcast <4 x i32> %8 to <2 x i64>
  %10 = shufflevector <4 x i32> %4, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %11 = bitcast <4 x i32> %10 to <2 x i64>
  %12 = shufflevector <4 x i32> %7, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %13 = bitcast <4 x i32> %12 to <2 x i64>
  %14 = shufflevector <4 x i32> %7, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shl <2 x i64> %9, <i64 32, i64 32>
  %17 = ashr exact <2 x i64> %16, <i64 32, i64 32>
  %18 = mul nsw <2 x i64> %17, <i64 65220, i64 65220>
  %19 = shl <2 x i64> %11, <i64 32, i64 32>
  %20 = ashr exact <2 x i64> %19, <i64 32, i64 32>
  %21 = mul nsw <2 x i64> %20, <i64 65220, i64 65220>
  %22 = mul nsw <2 x i64> %17, <i64 6424, i64 6424>
  %23 = mul nsw <2 x i64> %20, <i64 6424, i64 6424>
  %24 = shl <2 x i64> %13, <i64 32, i64 32>
  %25 = ashr exact <2 x i64> %24, <i64 32, i64 32>
  %26 = mul nsw <2 x i64> %25, <i64 6424, i64 6424>
  %27 = shl <2 x i64> %15, <i64 32, i64 32>
  %28 = ashr exact <2 x i64> %27, <i64 32, i64 32>
  %29 = mul nsw <2 x i64> %28, <i64 6424, i64 6424>
  %30 = add nsw <2 x i64> %22, <i64 32768, i64 32768>
  %31 = mul nsw <2 x i64> %25, <i64 -65220, i64 -65220>
  %32 = add nsw <2 x i64> %30, %31
  %33 = bitcast <2 x i64> %32 to <16 x i8>
  %34 = shufflevector <16 x i8> %33, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %35 = add nsw <2 x i64> %23, <i64 32768, i64 32768>
  %36 = mul nsw <2 x i64> %28, <i64 -65220, i64 -65220>
  %37 = add nsw <2 x i64> %35, %36
  %38 = bitcast <2 x i64> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %40 = add nsw <2 x i64> %18, <i64 32768, i64 32768>
  %41 = add nsw <2 x i64> %40, %26
  %42 = bitcast <2 x i64> %41 to <16 x i8>
  %43 = shufflevector <16 x i8> %42, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %44 = add nsw <2 x i64> %21, <i64 32768, i64 32768>
  %45 = add nsw <2 x i64> %44, %29
  %46 = bitcast <2 x i64> %45 to <16 x i8>
  %47 = shufflevector <16 x i8> %46, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %48 = bitcast <16 x i8> %34 to <4 x i32>
  %49 = bitcast <16 x i8> %39 to <4 x i32>
  %50 = shufflevector <4 x i32> %48, <4 x i32> %49, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %51 = shufflevector <4 x i32> %48, <4 x i32> %49, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %52 = shufflevector <4 x i32> %50, <4 x i32> %51, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %53 = bitcast <16 x i8> %43 to <4 x i32>
  %54 = bitcast <16 x i8> %47 to <4 x i32>
  %55 = shufflevector <4 x i32> %53, <4 x i32> %54, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %56 = shufflevector <4 x i32> %53, <4 x i32> %54, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %57 = shufflevector <4 x i32> %55, <4 x i32> %56, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %58 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %59 = bitcast <2 x i64>* %58 to <4 x i32>*
  %60 = load <4 x i32>, <4 x i32>* %59, align 16
  %61 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %62 = bitcast <2 x i64>* %61 to <4 x i32>*
  %63 = load <4 x i32>, <4 x i32>* %62, align 16
  %64 = shufflevector <4 x i32> %60, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %65 = bitcast <4 x i32> %64 to <2 x i64>
  %66 = shufflevector <4 x i32> %60, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %67 = bitcast <4 x i32> %66 to <2 x i64>
  %68 = shufflevector <4 x i32> %63, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %69 = bitcast <4 x i32> %68 to <2 x i64>
  %70 = shufflevector <4 x i32> %63, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %71 = bitcast <4 x i32> %70 to <2 x i64>
  %72 = shl <2 x i64> %65, <i64 32, i64 32>
  %73 = ashr exact <2 x i64> %72, <i64 32, i64 32>
  %74 = mul nsw <2 x i64> %73, <i64 41576, i64 41576>
  %75 = shl <2 x i64> %67, <i64 32, i64 32>
  %76 = ashr exact <2 x i64> %75, <i64 32, i64 32>
  %77 = mul nsw <2 x i64> %76, <i64 41576, i64 41576>
  %78 = mul nsw <2 x i64> %73, <i64 50660, i64 50660>
  %79 = mul nsw <2 x i64> %76, <i64 50660, i64 50660>
  %80 = shl <2 x i64> %69, <i64 32, i64 32>
  %81 = ashr exact <2 x i64> %80, <i64 32, i64 32>
  %82 = mul nsw <2 x i64> %81, <i64 50660, i64 50660>
  %83 = shl <2 x i64> %71, <i64 32, i64 32>
  %84 = ashr exact <2 x i64> %83, <i64 32, i64 32>
  %85 = mul nsw <2 x i64> %84, <i64 50660, i64 50660>
  %86 = add nsw <2 x i64> %78, <i64 32768, i64 32768>
  %87 = mul nsw <2 x i64> %81, <i64 -41576, i64 -41576>
  %88 = add nsw <2 x i64> %86, %87
  %89 = bitcast <2 x i64> %88 to <16 x i8>
  %90 = shufflevector <16 x i8> %89, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %91 = add nsw <2 x i64> %79, <i64 32768, i64 32768>
  %92 = mul nsw <2 x i64> %84, <i64 -41576, i64 -41576>
  %93 = add nsw <2 x i64> %91, %92
  %94 = bitcast <2 x i64> %93 to <16 x i8>
  %95 = shufflevector <16 x i8> %94, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %96 = add nsw <2 x i64> %74, <i64 32768, i64 32768>
  %97 = add nsw <2 x i64> %96, %82
  %98 = bitcast <2 x i64> %97 to <16 x i8>
  %99 = shufflevector <16 x i8> %98, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %100 = add nsw <2 x i64> %77, <i64 32768, i64 32768>
  %101 = add nsw <2 x i64> %100, %85
  %102 = bitcast <2 x i64> %101 to <16 x i8>
  %103 = shufflevector <16 x i8> %102, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %104 = bitcast <16 x i8> %90 to <4 x i32>
  %105 = bitcast <16 x i8> %95 to <4 x i32>
  %106 = shufflevector <4 x i32> %104, <4 x i32> %105, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %107 = shufflevector <4 x i32> %104, <4 x i32> %105, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %108 = shufflevector <4 x i32> %106, <4 x i32> %107, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %109 = bitcast <16 x i8> %99 to <4 x i32>
  %110 = bitcast <16 x i8> %103 to <4 x i32>
  %111 = shufflevector <4 x i32> %109, <4 x i32> %110, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %112 = shufflevector <4 x i32> %109, <4 x i32> %110, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %113 = shufflevector <4 x i32> %111, <4 x i32> %112, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %114 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %115 = bitcast <2 x i64>* %114 to <4 x i32>*
  %116 = load <4 x i32>, <4 x i32>* %115, align 16
  %117 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %118 = bitcast <2 x i64>* %117 to <4 x i32>*
  %119 = load <4 x i32>, <4 x i32>* %118, align 16
  %120 = shufflevector <4 x i32> %116, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %121 = bitcast <4 x i32> %120 to <2 x i64>
  %122 = shufflevector <4 x i32> %116, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %123 = bitcast <4 x i32> %122 to <2 x i64>
  %124 = shufflevector <4 x i32> %119, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %125 = bitcast <4 x i32> %124 to <2 x i64>
  %126 = shufflevector <4 x i32> %119, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %127 = bitcast <4 x i32> %126 to <2 x i64>
  %128 = shl <2 x i64> %121, <i64 32, i64 32>
  %129 = ashr exact <2 x i64> %128, <i64 32, i64 32>
  %130 = mul nsw <2 x i64> %129, <i64 57796, i64 57796>
  %131 = shl <2 x i64> %123, <i64 32, i64 32>
  %132 = ashr exact <2 x i64> %131, <i64 32, i64 32>
  %133 = mul nsw <2 x i64> %132, <i64 57796, i64 57796>
  %134 = mul nsw <2 x i64> %129, <i64 30892, i64 30892>
  %135 = mul nsw <2 x i64> %132, <i64 30892, i64 30892>
  %136 = shl <2 x i64> %125, <i64 32, i64 32>
  %137 = ashr exact <2 x i64> %136, <i64 32, i64 32>
  %138 = mul nsw <2 x i64> %137, <i64 30892, i64 30892>
  %139 = shl <2 x i64> %127, <i64 32, i64 32>
  %140 = ashr exact <2 x i64> %139, <i64 32, i64 32>
  %141 = mul nsw <2 x i64> %140, <i64 30892, i64 30892>
  %142 = add nsw <2 x i64> %134, <i64 32768, i64 32768>
  %143 = mul nsw <2 x i64> %137, <i64 -57796, i64 -57796>
  %144 = add nsw <2 x i64> %142, %143
  %145 = bitcast <2 x i64> %144 to <16 x i8>
  %146 = shufflevector <16 x i8> %145, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %147 = add nsw <2 x i64> %135, <i64 32768, i64 32768>
  %148 = mul nsw <2 x i64> %140, <i64 -57796, i64 -57796>
  %149 = add nsw <2 x i64> %147, %148
  %150 = bitcast <2 x i64> %149 to <16 x i8>
  %151 = shufflevector <16 x i8> %150, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %152 = add nsw <2 x i64> %130, <i64 32768, i64 32768>
  %153 = add nsw <2 x i64> %152, %138
  %154 = bitcast <2 x i64> %153 to <16 x i8>
  %155 = shufflevector <16 x i8> %154, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %156 = add nsw <2 x i64> %133, <i64 32768, i64 32768>
  %157 = add nsw <2 x i64> %156, %141
  %158 = bitcast <2 x i64> %157 to <16 x i8>
  %159 = shufflevector <16 x i8> %158, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %160 = bitcast <16 x i8> %146 to <4 x i32>
  %161 = bitcast <16 x i8> %151 to <4 x i32>
  %162 = shufflevector <4 x i32> %160, <4 x i32> %161, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %163 = shufflevector <4 x i32> %160, <4 x i32> %161, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %164 = shufflevector <4 x i32> %162, <4 x i32> %163, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %165 = bitcast <16 x i8> %155 to <4 x i32>
  %166 = bitcast <16 x i8> %159 to <4 x i32>
  %167 = shufflevector <4 x i32> %165, <4 x i32> %166, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %168 = shufflevector <4 x i32> %165, <4 x i32> %166, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %169 = shufflevector <4 x i32> %167, <4 x i32> %168, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %170 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %171 = bitcast <2 x i64>* %170 to <4 x i32>*
  %172 = load <4 x i32>, <4 x i32>* %171, align 16
  %173 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %174 = bitcast <2 x i64>* %173 to <4 x i32>*
  %175 = load <4 x i32>, <4 x i32>* %174, align 16
  %176 = shufflevector <4 x i32> %172, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %177 = bitcast <4 x i32> %176 to <2 x i64>
  %178 = shufflevector <4 x i32> %172, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %179 = bitcast <4 x i32> %178 to <2 x i64>
  %180 = shufflevector <4 x i32> %175, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %181 = bitcast <4 x i32> %180 to <2 x i64>
  %182 = shufflevector <4 x i32> %175, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %183 = bitcast <4 x i32> %182 to <2 x i64>
  %184 = shl <2 x i64> %177, <i64 32, i64 32>
  %185 = ashr exact <2 x i64> %184, <i64 32, i64 32>
  %186 = mul nsw <2 x i64> %185, <i64 19024, i64 19024>
  %187 = shl <2 x i64> %179, <i64 32, i64 32>
  %188 = ashr exact <2 x i64> %187, <i64 32, i64 32>
  %189 = mul nsw <2 x i64> %188, <i64 19024, i64 19024>
  %190 = mul nsw <2 x i64> %185, <i64 62716, i64 62716>
  %191 = mul nsw <2 x i64> %188, <i64 62716, i64 62716>
  %192 = shl <2 x i64> %181, <i64 32, i64 32>
  %193 = ashr exact <2 x i64> %192, <i64 32, i64 32>
  %194 = mul nsw <2 x i64> %193, <i64 62716, i64 62716>
  %195 = shl <2 x i64> %183, <i64 32, i64 32>
  %196 = ashr exact <2 x i64> %195, <i64 32, i64 32>
  %197 = mul nsw <2 x i64> %196, <i64 62716, i64 62716>
  %198 = add nsw <2 x i64> %190, <i64 32768, i64 32768>
  %199 = mul nsw <2 x i64> %193, <i64 -19024, i64 -19024>
  %200 = add nsw <2 x i64> %198, %199
  %201 = bitcast <2 x i64> %200 to <16 x i8>
  %202 = shufflevector <16 x i8> %201, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %203 = add nsw <2 x i64> %191, <i64 32768, i64 32768>
  %204 = mul nsw <2 x i64> %196, <i64 -19024, i64 -19024>
  %205 = add nsw <2 x i64> %203, %204
  %206 = bitcast <2 x i64> %205 to <16 x i8>
  %207 = shufflevector <16 x i8> %206, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %208 = add nsw <2 x i64> %186, <i64 32768, i64 32768>
  %209 = add nsw <2 x i64> %208, %194
  %210 = bitcast <2 x i64> %209 to <16 x i8>
  %211 = shufflevector <16 x i8> %210, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %212 = add nsw <2 x i64> %189, <i64 32768, i64 32768>
  %213 = add nsw <2 x i64> %212, %197
  %214 = bitcast <2 x i64> %213 to <16 x i8>
  %215 = shufflevector <16 x i8> %214, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %216 = bitcast <16 x i8> %202 to <4 x i32>
  %217 = bitcast <16 x i8> %207 to <4 x i32>
  %218 = shufflevector <4 x i32> %216, <4 x i32> %217, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %219 = shufflevector <4 x i32> %216, <4 x i32> %217, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %220 = shufflevector <4 x i32> %218, <4 x i32> %219, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %221 = bitcast <16 x i8> %211 to <4 x i32>
  %222 = bitcast <16 x i8> %215 to <4 x i32>
  %223 = shufflevector <4 x i32> %221, <4 x i32> %222, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %224 = shufflevector <4 x i32> %221, <4 x i32> %222, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %225 = shufflevector <4 x i32> %223, <4 x i32> %224, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %226 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %227 = bitcast <2 x i64>* %226 to <4 x i32>*
  %228 = load <4 x i32>, <4 x i32>* %227, align 16
  %229 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %230 = bitcast <2 x i64>* %229 to <4 x i32>*
  %231 = load <4 x i32>, <4 x i32>* %230, align 16
  %232 = shufflevector <4 x i32> %228, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %233 = bitcast <4 x i32> %232 to <2 x i64>
  %234 = shufflevector <4 x i32> %228, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %235 = bitcast <4 x i32> %234 to <2 x i64>
  %236 = shufflevector <4 x i32> %231, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %237 = bitcast <4 x i32> %236 to <2 x i64>
  %238 = shufflevector <4 x i32> %231, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %239 = bitcast <4 x i32> %238 to <2 x i64>
  %240 = shl <2 x i64> %233, <i64 32, i64 32>
  %241 = ashr exact <2 x i64> %240, <i64 32, i64 32>
  %242 = mul nsw <2 x i64> %241, <i64 64276, i64 64276>
  %243 = shl <2 x i64> %235, <i64 32, i64 32>
  %244 = ashr exact <2 x i64> %243, <i64 32, i64 32>
  %245 = mul nsw <2 x i64> %244, <i64 64276, i64 64276>
  %246 = mul nsw <2 x i64> %241, <i64 12784, i64 12784>
  %247 = mul nsw <2 x i64> %244, <i64 12784, i64 12784>
  %248 = shl <2 x i64> %237, <i64 32, i64 32>
  %249 = ashr exact <2 x i64> %248, <i64 32, i64 32>
  %250 = mul nsw <2 x i64> %249, <i64 12784, i64 12784>
  %251 = shl <2 x i64> %239, <i64 32, i64 32>
  %252 = ashr exact <2 x i64> %251, <i64 32, i64 32>
  %253 = mul nsw <2 x i64> %252, <i64 12784, i64 12784>
  %254 = add nsw <2 x i64> %246, <i64 32768, i64 32768>
  %255 = mul nsw <2 x i64> %249, <i64 -64276, i64 -64276>
  %256 = add nsw <2 x i64> %254, %255
  %257 = bitcast <2 x i64> %256 to <16 x i8>
  %258 = shufflevector <16 x i8> %257, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %259 = add nsw <2 x i64> %247, <i64 32768, i64 32768>
  %260 = mul nsw <2 x i64> %252, <i64 -64276, i64 -64276>
  %261 = add nsw <2 x i64> %259, %260
  %262 = bitcast <2 x i64> %261 to <16 x i8>
  %263 = shufflevector <16 x i8> %262, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %264 = add nsw <2 x i64> %242, <i64 32768, i64 32768>
  %265 = add nsw <2 x i64> %264, %250
  %266 = bitcast <2 x i64> %265 to <16 x i8>
  %267 = shufflevector <16 x i8> %266, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %268 = add nsw <2 x i64> %245, <i64 32768, i64 32768>
  %269 = add nsw <2 x i64> %268, %253
  %270 = bitcast <2 x i64> %269 to <16 x i8>
  %271 = shufflevector <16 x i8> %270, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %272 = bitcast <16 x i8> %258 to <4 x i32>
  %273 = bitcast <16 x i8> %263 to <4 x i32>
  %274 = shufflevector <4 x i32> %272, <4 x i32> %273, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %275 = shufflevector <4 x i32> %272, <4 x i32> %273, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %276 = shufflevector <4 x i32> %274, <4 x i32> %275, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %277 = bitcast <16 x i8> %267 to <4 x i32>
  %278 = bitcast <16 x i8> %271 to <4 x i32>
  %279 = shufflevector <4 x i32> %277, <4 x i32> %278, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %280 = shufflevector <4 x i32> %277, <4 x i32> %278, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %281 = shufflevector <4 x i32> %279, <4 x i32> %280, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %282 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %283 = bitcast <2 x i64>* %282 to <4 x i32>*
  %284 = load <4 x i32>, <4 x i32>* %283, align 16
  %285 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %286 = bitcast <2 x i64>* %285 to <4 x i32>*
  %287 = load <4 x i32>, <4 x i32>* %286, align 16
  %288 = shufflevector <4 x i32> %284, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %289 = bitcast <4 x i32> %288 to <2 x i64>
  %290 = shufflevector <4 x i32> %284, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %291 = bitcast <4 x i32> %290 to <2 x i64>
  %292 = shufflevector <4 x i32> %287, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %293 = bitcast <4 x i32> %292 to <2 x i64>
  %294 = shufflevector <4 x i32> %287, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %295 = bitcast <4 x i32> %294 to <2 x i64>
  %296 = shl <2 x i64> %289, <i64 32, i64 32>
  %297 = ashr exact <2 x i64> %296, <i64 32, i64 32>
  %298 = mul nsw <2 x i64> %297, <i64 36408, i64 36408>
  %299 = shl <2 x i64> %291, <i64 32, i64 32>
  %300 = ashr exact <2 x i64> %299, <i64 32, i64 32>
  %301 = mul nsw <2 x i64> %300, <i64 36408, i64 36408>
  %302 = mul nsw <2 x i64> %297, <i64 54492, i64 54492>
  %303 = mul nsw <2 x i64> %300, <i64 54492, i64 54492>
  %304 = shl <2 x i64> %293, <i64 32, i64 32>
  %305 = ashr exact <2 x i64> %304, <i64 32, i64 32>
  %306 = mul nsw <2 x i64> %305, <i64 54492, i64 54492>
  %307 = shl <2 x i64> %295, <i64 32, i64 32>
  %308 = ashr exact <2 x i64> %307, <i64 32, i64 32>
  %309 = mul nsw <2 x i64> %308, <i64 54492, i64 54492>
  %310 = add nsw <2 x i64> %302, <i64 32768, i64 32768>
  %311 = mul nsw <2 x i64> %305, <i64 -36408, i64 -36408>
  %312 = add nsw <2 x i64> %310, %311
  %313 = bitcast <2 x i64> %312 to <16 x i8>
  %314 = shufflevector <16 x i8> %313, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %315 = add nsw <2 x i64> %303, <i64 32768, i64 32768>
  %316 = mul nsw <2 x i64> %308, <i64 -36408, i64 -36408>
  %317 = add nsw <2 x i64> %315, %316
  %318 = bitcast <2 x i64> %317 to <16 x i8>
  %319 = shufflevector <16 x i8> %318, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %320 = add nsw <2 x i64> %298, <i64 32768, i64 32768>
  %321 = add nsw <2 x i64> %320, %306
  %322 = bitcast <2 x i64> %321 to <16 x i8>
  %323 = shufflevector <16 x i8> %322, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %324 = add nsw <2 x i64> %301, <i64 32768, i64 32768>
  %325 = add nsw <2 x i64> %324, %309
  %326 = bitcast <2 x i64> %325 to <16 x i8>
  %327 = shufflevector <16 x i8> %326, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %328 = bitcast <16 x i8> %314 to <4 x i32>
  %329 = bitcast <16 x i8> %319 to <4 x i32>
  %330 = shufflevector <4 x i32> %328, <4 x i32> %329, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %331 = shufflevector <4 x i32> %328, <4 x i32> %329, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %332 = shufflevector <4 x i32> %330, <4 x i32> %331, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %333 = bitcast <16 x i8> %323 to <4 x i32>
  %334 = bitcast <16 x i8> %327 to <4 x i32>
  %335 = shufflevector <4 x i32> %333, <4 x i32> %334, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %336 = shufflevector <4 x i32> %333, <4 x i32> %334, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %337 = shufflevector <4 x i32> %335, <4 x i32> %336, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %338 = add <4 x i32> %108, %52
  %339 = sub <4 x i32> %52, %108
  %340 = sub <4 x i32> %220, %164
  %341 = add <4 x i32> %220, %164
  %342 = add <4 x i32> %225, %169
  %343 = sub <4 x i32> %225, %169
  %344 = sub <4 x i32> %57, %113
  %345 = add <4 x i32> %113, %57
  %346 = bitcast <2 x i64>* %0 to <4 x i32>*
  %347 = load <4 x i32>, <4 x i32>* %346, align 16
  %348 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %349 = bitcast <2 x i64>* %348 to <4 x i32>*
  %350 = load <4 x i32>, <4 x i32>* %349, align 16
  %351 = add <4 x i32> %350, %347
  %352 = shufflevector <4 x i32> %351, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %353 = bitcast <4 x i32> %352 to <2 x i64>
  %354 = shufflevector <4 x i32> %351, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %355 = bitcast <4 x i32> %354 to <2 x i64>
  %356 = shl <2 x i64> %353, <i64 32, i64 32>
  %357 = ashr exact <2 x i64> %356, <i64 32, i64 32>
  %358 = mul nsw <2 x i64> %357, <i64 46340, i64 46340>
  %359 = shl <2 x i64> %355, <i64 32, i64 32>
  %360 = ashr exact <2 x i64> %359, <i64 32, i64 32>
  %361 = mul nsw <2 x i64> %360, <i64 46340, i64 46340>
  %362 = add nsw <2 x i64> %358, <i64 32768, i64 32768>
  %363 = bitcast <2 x i64> %362 to <16 x i8>
  %364 = shufflevector <16 x i8> %363, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %365 = add nsw <2 x i64> %361, <i64 32768, i64 32768>
  %366 = bitcast <2 x i64> %365 to <16 x i8>
  %367 = shufflevector <16 x i8> %366, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %368 = bitcast <16 x i8> %364 to <4 x i32>
  %369 = bitcast <16 x i8> %367 to <4 x i32>
  %370 = shufflevector <4 x i32> %368, <4 x i32> %369, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %371 = shufflevector <4 x i32> %368, <4 x i32> %369, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %372 = shufflevector <4 x i32> %370, <4 x i32> %371, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %373 = sub <4 x i32> %347, %350
  %374 = shufflevector <4 x i32> %373, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %375 = bitcast <4 x i32> %374 to <2 x i64>
  %376 = shufflevector <4 x i32> %373, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %377 = bitcast <4 x i32> %376 to <2 x i64>
  %378 = shl <2 x i64> %375, <i64 32, i64 32>
  %379 = ashr exact <2 x i64> %378, <i64 32, i64 32>
  %380 = mul nsw <2 x i64> %379, <i64 46340, i64 46340>
  %381 = shl <2 x i64> %377, <i64 32, i64 32>
  %382 = ashr exact <2 x i64> %381, <i64 32, i64 32>
  %383 = mul nsw <2 x i64> %382, <i64 46340, i64 46340>
  %384 = add nsw <2 x i64> %380, <i64 32768, i64 32768>
  %385 = bitcast <2 x i64> %384 to <16 x i8>
  %386 = shufflevector <16 x i8> %385, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %387 = add nsw <2 x i64> %383, <i64 32768, i64 32768>
  %388 = bitcast <2 x i64> %387 to <16 x i8>
  %389 = shufflevector <16 x i8> %388, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %390 = bitcast <16 x i8> %386 to <4 x i32>
  %391 = bitcast <16 x i8> %389 to <4 x i32>
  %392 = shufflevector <4 x i32> %390, <4 x i32> %391, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %393 = shufflevector <4 x i32> %390, <4 x i32> %391, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %394 = shufflevector <4 x i32> %392, <4 x i32> %393, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %395 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %396 = bitcast <2 x i64>* %395 to <4 x i32>*
  %397 = load <4 x i32>, <4 x i32>* %396, align 16
  %398 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %399 = bitcast <2 x i64>* %398 to <4 x i32>*
  %400 = load <4 x i32>, <4 x i32>* %399, align 16
  %401 = shufflevector <4 x i32> %397, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %402 = bitcast <4 x i32> %401 to <2 x i64>
  %403 = shufflevector <4 x i32> %397, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %404 = bitcast <4 x i32> %403 to <2 x i64>
  %405 = shufflevector <4 x i32> %400, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %406 = bitcast <4 x i32> %405 to <2 x i64>
  %407 = shufflevector <4 x i32> %400, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %408 = bitcast <4 x i32> %407 to <2 x i64>
  %409 = shl <2 x i64> %402, <i64 32, i64 32>
  %410 = ashr exact <2 x i64> %409, <i64 32, i64 32>
  %411 = mul nsw <2 x i64> %410, <i64 60548, i64 60548>
  %412 = shl <2 x i64> %404, <i64 32, i64 32>
  %413 = ashr exact <2 x i64> %412, <i64 32, i64 32>
  %414 = mul nsw <2 x i64> %413, <i64 60548, i64 60548>
  %415 = mul nsw <2 x i64> %410, <i64 25080, i64 25080>
  %416 = mul nsw <2 x i64> %413, <i64 25080, i64 25080>
  %417 = shl <2 x i64> %406, <i64 32, i64 32>
  %418 = ashr exact <2 x i64> %417, <i64 32, i64 32>
  %419 = mul nsw <2 x i64> %418, <i64 25080, i64 25080>
  %420 = shl <2 x i64> %408, <i64 32, i64 32>
  %421 = ashr exact <2 x i64> %420, <i64 32, i64 32>
  %422 = mul nsw <2 x i64> %421, <i64 25080, i64 25080>
  %423 = add nsw <2 x i64> %415, <i64 32768, i64 32768>
  %424 = mul nsw <2 x i64> %418, <i64 -60548, i64 -60548>
  %425 = add nsw <2 x i64> %423, %424
  %426 = bitcast <2 x i64> %425 to <16 x i8>
  %427 = shufflevector <16 x i8> %426, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %428 = add nsw <2 x i64> %416, <i64 32768, i64 32768>
  %429 = mul nsw <2 x i64> %421, <i64 -60548, i64 -60548>
  %430 = add nsw <2 x i64> %428, %429
  %431 = bitcast <2 x i64> %430 to <16 x i8>
  %432 = shufflevector <16 x i8> %431, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %433 = add nsw <2 x i64> %411, <i64 32768, i64 32768>
  %434 = add nsw <2 x i64> %433, %419
  %435 = bitcast <2 x i64> %434 to <16 x i8>
  %436 = shufflevector <16 x i8> %435, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %437 = add nsw <2 x i64> %414, <i64 32768, i64 32768>
  %438 = add nsw <2 x i64> %437, %422
  %439 = bitcast <2 x i64> %438 to <16 x i8>
  %440 = shufflevector <16 x i8> %439, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %441 = bitcast <16 x i8> %427 to <4 x i32>
  %442 = bitcast <16 x i8> %432 to <4 x i32>
  %443 = shufflevector <4 x i32> %441, <4 x i32> %442, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %444 = shufflevector <4 x i32> %441, <4 x i32> %442, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %445 = shufflevector <4 x i32> %443, <4 x i32> %444, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %446 = bitcast <16 x i8> %436 to <4 x i32>
  %447 = bitcast <16 x i8> %440 to <4 x i32>
  %448 = shufflevector <4 x i32> %446, <4 x i32> %447, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %449 = shufflevector <4 x i32> %446, <4 x i32> %447, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %450 = shufflevector <4 x i32> %448, <4 x i32> %449, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %451 = shufflevector <4 x i32> %344, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %452 = bitcast <4 x i32> %451 to <2 x i64>
  %453 = shufflevector <4 x i32> %344, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %454 = bitcast <4 x i32> %453 to <2 x i64>
  %455 = shufflevector <4 x i32> %339, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %456 = bitcast <4 x i32> %455 to <2 x i64>
  %457 = shufflevector <4 x i32> %339, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %458 = bitcast <4 x i32> %457 to <2 x i64>
  %459 = shl <2 x i64> %452, <i64 32, i64 32>
  %460 = ashr exact <2 x i64> %459, <i64 32, i64 32>
  %461 = mul nsw <2 x i64> %460, <i64 60548, i64 60548>
  %462 = shl <2 x i64> %454, <i64 32, i64 32>
  %463 = ashr exact <2 x i64> %462, <i64 32, i64 32>
  %464 = mul nsw <2 x i64> %463, <i64 60548, i64 60548>
  %465 = mul nsw <2 x i64> %460, <i64 25080, i64 25080>
  %466 = mul nsw <2 x i64> %463, <i64 25080, i64 25080>
  %467 = shl <2 x i64> %456, <i64 32, i64 32>
  %468 = ashr exact <2 x i64> %467, <i64 32, i64 32>
  %469 = mul nsw <2 x i64> %468, <i64 25080, i64 25080>
  %470 = shl <2 x i64> %458, <i64 32, i64 32>
  %471 = ashr exact <2 x i64> %470, <i64 32, i64 32>
  %472 = mul nsw <2 x i64> %471, <i64 25080, i64 25080>
  %473 = mul nsw <2 x i64> %468, <i64 -60548, i64 -60548>
  %474 = add nsw <2 x i64> %473, <i64 32768, i64 32768>
  %475 = add nsw <2 x i64> %474, %465
  %476 = bitcast <2 x i64> %475 to <16 x i8>
  %477 = shufflevector <16 x i8> %476, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %478 = mul nsw <2 x i64> %471, <i64 -60548, i64 -60548>
  %479 = add nsw <2 x i64> %478, <i64 32768, i64 32768>
  %480 = add nsw <2 x i64> %479, %466
  %481 = bitcast <2 x i64> %480 to <16 x i8>
  %482 = shufflevector <16 x i8> %481, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %483 = add nsw <2 x i64> %469, <i64 32768, i64 32768>
  %484 = add nsw <2 x i64> %483, %461
  %485 = bitcast <2 x i64> %484 to <16 x i8>
  %486 = shufflevector <16 x i8> %485, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %487 = add nsw <2 x i64> %472, <i64 32768, i64 32768>
  %488 = add nsw <2 x i64> %487, %464
  %489 = bitcast <2 x i64> %488 to <16 x i8>
  %490 = shufflevector <16 x i8> %489, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %491 = bitcast <16 x i8> %477 to <4 x i32>
  %492 = bitcast <16 x i8> %482 to <4 x i32>
  %493 = shufflevector <4 x i32> %491, <4 x i32> %492, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %494 = shufflevector <4 x i32> %491, <4 x i32> %492, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %495 = shufflevector <4 x i32> %493, <4 x i32> %494, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %496 = bitcast <16 x i8> %486 to <4 x i32>
  %497 = bitcast <16 x i8> %490 to <4 x i32>
  %498 = shufflevector <4 x i32> %496, <4 x i32> %497, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %499 = shufflevector <4 x i32> %496, <4 x i32> %497, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %500 = shufflevector <4 x i32> %498, <4 x i32> %499, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %501 = shufflevector <4 x i32> %340, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %502 = bitcast <4 x i32> %501 to <2 x i64>
  %503 = shufflevector <4 x i32> %340, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %504 = bitcast <4 x i32> %503 to <2 x i64>
  %505 = shufflevector <4 x i32> %343, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %506 = bitcast <4 x i32> %505 to <2 x i64>
  %507 = shufflevector <4 x i32> %343, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %508 = bitcast <4 x i32> %507 to <2 x i64>
  %509 = shl <2 x i64> %502, <i64 32, i64 32>
  %510 = ashr exact <2 x i64> %509, <i64 32, i64 32>
  %511 = mul nsw <2 x i64> %510, <i64 -25080, i64 -25080>
  %512 = shl <2 x i64> %504, <i64 32, i64 32>
  %513 = ashr exact <2 x i64> %512, <i64 32, i64 32>
  %514 = mul nsw <2 x i64> %513, <i64 -25080, i64 -25080>
  %515 = mul nsw <2 x i64> %510, <i64 -60548, i64 -60548>
  %516 = mul nsw <2 x i64> %513, <i64 -60548, i64 -60548>
  %517 = shl <2 x i64> %506, <i64 32, i64 32>
  %518 = ashr exact <2 x i64> %517, <i64 32, i64 32>
  %519 = mul nsw <2 x i64> %518, <i64 -60548, i64 -60548>
  %520 = shl <2 x i64> %508, <i64 32, i64 32>
  %521 = ashr exact <2 x i64> %520, <i64 32, i64 32>
  %522 = mul nsw <2 x i64> %521, <i64 -60548, i64 -60548>
  %523 = add nsw <2 x i64> %515, <i64 32768, i64 32768>
  %524 = mul nsw <2 x i64> %518, <i64 25080, i64 25080>
  %525 = add nsw <2 x i64> %523, %524
  %526 = bitcast <2 x i64> %525 to <16 x i8>
  %527 = shufflevector <16 x i8> %526, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %528 = add nsw <2 x i64> %516, <i64 32768, i64 32768>
  %529 = mul nsw <2 x i64> %521, <i64 25080, i64 25080>
  %530 = add nsw <2 x i64> %528, %529
  %531 = bitcast <2 x i64> %530 to <16 x i8>
  %532 = shufflevector <16 x i8> %531, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %533 = add nsw <2 x i64> %511, <i64 32768, i64 32768>
  %534 = add nsw <2 x i64> %533, %519
  %535 = bitcast <2 x i64> %534 to <16 x i8>
  %536 = shufflevector <16 x i8> %535, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %537 = add nsw <2 x i64> %514, <i64 32768, i64 32768>
  %538 = add nsw <2 x i64> %537, %522
  %539 = bitcast <2 x i64> %538 to <16 x i8>
  %540 = shufflevector <16 x i8> %539, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %541 = bitcast <16 x i8> %527 to <4 x i32>
  %542 = bitcast <16 x i8> %532 to <4 x i32>
  %543 = shufflevector <4 x i32> %541, <4 x i32> %542, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %544 = shufflevector <4 x i32> %541, <4 x i32> %542, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %545 = shufflevector <4 x i32> %543, <4 x i32> %544, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %546 = bitcast <16 x i8> %536 to <4 x i32>
  %547 = bitcast <16 x i8> %540 to <4 x i32>
  %548 = shufflevector <4 x i32> %546, <4 x i32> %547, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %549 = shufflevector <4 x i32> %546, <4 x i32> %547, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %550 = shufflevector <4 x i32> %548, <4 x i32> %549, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %551 = sub <4 x i32> %276, %332
  %552 = add <4 x i32> %332, %276
  %553 = sub <4 x i32> %281, %337
  %554 = add <4 x i32> %337, %281
  %555 = add <4 x i32> %450, %372
  %556 = add <4 x i32> %445, %394
  %557 = sub <4 x i32> %394, %445
  %558 = sub <4 x i32> %372, %450
  %559 = add <4 x i32> %553, %551
  %560 = shufflevector <4 x i32> %559, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %561 = bitcast <4 x i32> %560 to <2 x i64>
  %562 = shufflevector <4 x i32> %559, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %563 = bitcast <4 x i32> %562 to <2 x i64>
  %564 = shl <2 x i64> %561, <i64 32, i64 32>
  %565 = ashr exact <2 x i64> %564, <i64 32, i64 32>
  %566 = mul nsw <2 x i64> %565, <i64 46340, i64 46340>
  %567 = shl <2 x i64> %563, <i64 32, i64 32>
  %568 = ashr exact <2 x i64> %567, <i64 32, i64 32>
  %569 = mul nsw <2 x i64> %568, <i64 46340, i64 46340>
  %570 = add nsw <2 x i64> %566, <i64 32768, i64 32768>
  %571 = bitcast <2 x i64> %570 to <16 x i8>
  %572 = shufflevector <16 x i8> %571, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %573 = add nsw <2 x i64> %569, <i64 32768, i64 32768>
  %574 = bitcast <2 x i64> %573 to <16 x i8>
  %575 = shufflevector <16 x i8> %574, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %576 = bitcast <16 x i8> %572 to <4 x i32>
  %577 = bitcast <16 x i8> %575 to <4 x i32>
  %578 = shufflevector <4 x i32> %576, <4 x i32> %577, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %579 = shufflevector <4 x i32> %576, <4 x i32> %577, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %580 = shufflevector <4 x i32> %578, <4 x i32> %579, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %581 = sub <4 x i32> %553, %551
  %582 = shufflevector <4 x i32> %581, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %583 = bitcast <4 x i32> %582 to <2 x i64>
  %584 = shufflevector <4 x i32> %581, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %585 = bitcast <4 x i32> %584 to <2 x i64>
  %586 = shl <2 x i64> %583, <i64 32, i64 32>
  %587 = ashr exact <2 x i64> %586, <i64 32, i64 32>
  %588 = mul nsw <2 x i64> %587, <i64 46340, i64 46340>
  %589 = shl <2 x i64> %585, <i64 32, i64 32>
  %590 = ashr exact <2 x i64> %589, <i64 32, i64 32>
  %591 = mul nsw <2 x i64> %590, <i64 46340, i64 46340>
  %592 = add nsw <2 x i64> %588, <i64 32768, i64 32768>
  %593 = bitcast <2 x i64> %592 to <16 x i8>
  %594 = shufflevector <16 x i8> %593, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %595 = add nsw <2 x i64> %591, <i64 32768, i64 32768>
  %596 = bitcast <2 x i64> %595 to <16 x i8>
  %597 = shufflevector <16 x i8> %596, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %598 = bitcast <16 x i8> %594 to <4 x i32>
  %599 = bitcast <16 x i8> %597 to <4 x i32>
  %600 = shufflevector <4 x i32> %598, <4 x i32> %599, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %601 = shufflevector <4 x i32> %598, <4 x i32> %599, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %602 = shufflevector <4 x i32> %600, <4 x i32> %601, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %603 = add <4 x i32> %341, %338
  %604 = add <4 x i32> %550, %495
  %605 = sub <4 x i32> %495, %550
  %606 = sub <4 x i32> %338, %341
  %607 = sub <4 x i32> %345, %342
  %608 = sub <4 x i32> %500, %545
  %609 = add <4 x i32> %545, %500
  %610 = add <4 x i32> %342, %345
  %611 = add <4 x i32> %555, %554
  %612 = add <4 x i32> %580, %556
  %613 = add <4 x i32> %602, %557
  %614 = add <4 x i32> %558, %552
  %615 = sub <4 x i32> %558, %552
  %616 = sub <4 x i32> %557, %602
  %617 = sub <4 x i32> %556, %580
  %618 = sub <4 x i32> %555, %554
  %619 = add <4 x i32> %605, %608
  %620 = shufflevector <4 x i32> %619, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %621 = bitcast <4 x i32> %620 to <2 x i64>
  %622 = shufflevector <4 x i32> %619, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %623 = bitcast <4 x i32> %622 to <2 x i64>
  %624 = shl <2 x i64> %621, <i64 32, i64 32>
  %625 = ashr exact <2 x i64> %624, <i64 32, i64 32>
  %626 = mul nsw <2 x i64> %625, <i64 46340, i64 46340>
  %627 = shl <2 x i64> %623, <i64 32, i64 32>
  %628 = ashr exact <2 x i64> %627, <i64 32, i64 32>
  %629 = mul nsw <2 x i64> %628, <i64 46340, i64 46340>
  %630 = add nsw <2 x i64> %626, <i64 32768, i64 32768>
  %631 = bitcast <2 x i64> %630 to <16 x i8>
  %632 = shufflevector <16 x i8> %631, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %633 = add nsw <2 x i64> %629, <i64 32768, i64 32768>
  %634 = bitcast <2 x i64> %633 to <16 x i8>
  %635 = shufflevector <16 x i8> %634, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %636 = bitcast <16 x i8> %632 to <4 x i32>
  %637 = bitcast <16 x i8> %635 to <4 x i32>
  %638 = shufflevector <4 x i32> %636, <4 x i32> %637, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %639 = shufflevector <4 x i32> %636, <4 x i32> %637, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %640 = shufflevector <4 x i32> %638, <4 x i32> %639, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %641 = sub <4 x i32> %608, %605
  %642 = shufflevector <4 x i32> %641, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %643 = bitcast <4 x i32> %642 to <2 x i64>
  %644 = shufflevector <4 x i32> %641, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %645 = bitcast <4 x i32> %644 to <2 x i64>
  %646 = shl <2 x i64> %643, <i64 32, i64 32>
  %647 = ashr exact <2 x i64> %646, <i64 32, i64 32>
  %648 = mul nsw <2 x i64> %647, <i64 46340, i64 46340>
  %649 = shl <2 x i64> %645, <i64 32, i64 32>
  %650 = ashr exact <2 x i64> %649, <i64 32, i64 32>
  %651 = mul nsw <2 x i64> %650, <i64 46340, i64 46340>
  %652 = add nsw <2 x i64> %648, <i64 32768, i64 32768>
  %653 = bitcast <2 x i64> %652 to <16 x i8>
  %654 = shufflevector <16 x i8> %653, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %655 = add nsw <2 x i64> %651, <i64 32768, i64 32768>
  %656 = bitcast <2 x i64> %655 to <16 x i8>
  %657 = shufflevector <16 x i8> %656, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %658 = bitcast <16 x i8> %654 to <4 x i32>
  %659 = bitcast <16 x i8> %657 to <4 x i32>
  %660 = shufflevector <4 x i32> %658, <4 x i32> %659, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %661 = shufflevector <4 x i32> %658, <4 x i32> %659, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %662 = shufflevector <4 x i32> %660, <4 x i32> %661, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %663 = add <4 x i32> %607, %606
  %664 = shufflevector <4 x i32> %663, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %665 = bitcast <4 x i32> %664 to <2 x i64>
  %666 = shufflevector <4 x i32> %663, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %667 = bitcast <4 x i32> %666 to <2 x i64>
  %668 = shl <2 x i64> %665, <i64 32, i64 32>
  %669 = ashr exact <2 x i64> %668, <i64 32, i64 32>
  %670 = mul nsw <2 x i64> %669, <i64 46340, i64 46340>
  %671 = shl <2 x i64> %667, <i64 32, i64 32>
  %672 = ashr exact <2 x i64> %671, <i64 32, i64 32>
  %673 = mul nsw <2 x i64> %672, <i64 46340, i64 46340>
  %674 = add nsw <2 x i64> %670, <i64 32768, i64 32768>
  %675 = bitcast <2 x i64> %674 to <16 x i8>
  %676 = shufflevector <16 x i8> %675, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %677 = add nsw <2 x i64> %673, <i64 32768, i64 32768>
  %678 = bitcast <2 x i64> %677 to <16 x i8>
  %679 = shufflevector <16 x i8> %678, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %680 = bitcast <16 x i8> %676 to <4 x i32>
  %681 = bitcast <16 x i8> %679 to <4 x i32>
  %682 = shufflevector <4 x i32> %680, <4 x i32> %681, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %683 = shufflevector <4 x i32> %680, <4 x i32> %681, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %684 = shufflevector <4 x i32> %682, <4 x i32> %683, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %685 = sub <4 x i32> %607, %606
  %686 = shufflevector <4 x i32> %685, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %687 = bitcast <4 x i32> %686 to <2 x i64>
  %688 = shufflevector <4 x i32> %685, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %689 = bitcast <4 x i32> %688 to <2 x i64>
  %690 = shl <2 x i64> %687, <i64 32, i64 32>
  %691 = ashr exact <2 x i64> %690, <i64 32, i64 32>
  %692 = mul nsw <2 x i64> %691, <i64 46340, i64 46340>
  %693 = shl <2 x i64> %689, <i64 32, i64 32>
  %694 = ashr exact <2 x i64> %693, <i64 32, i64 32>
  %695 = mul nsw <2 x i64> %694, <i64 46340, i64 46340>
  %696 = add nsw <2 x i64> %692, <i64 32768, i64 32768>
  %697 = bitcast <2 x i64> %696 to <16 x i8>
  %698 = shufflevector <16 x i8> %697, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %699 = add nsw <2 x i64> %695, <i64 32768, i64 32768>
  %700 = bitcast <2 x i64> %699 to <16 x i8>
  %701 = shufflevector <16 x i8> %700, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %702 = bitcast <16 x i8> %698 to <4 x i32>
  %703 = bitcast <16 x i8> %701 to <4 x i32>
  %704 = shufflevector <4 x i32> %702, <4 x i32> %703, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %705 = shufflevector <4 x i32> %702, <4 x i32> %703, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %706 = shufflevector <4 x i32> %704, <4 x i32> %705, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %707 = add <4 x i32> %611, %610
  store <4 x i32> %707, <4 x i32>* %346, align 16
  %708 = add <4 x i32> %612, %609
  store <4 x i32> %708, <4 x i32>* %3, align 16
  %709 = add <4 x i32> %640, %613
  store <4 x i32> %709, <4 x i32>* %227, align 16
  %710 = add <4 x i32> %684, %614
  store <4 x i32> %710, <4 x i32>* %174, align 16
  %711 = add <4 x i32> %706, %615
  store <4 x i32> %711, <4 x i32>* %396, align 16
  %712 = add <4 x i32> %662, %616
  store <4 x i32> %712, <4 x i32>* %115, align 16
  %713 = add <4 x i32> %617, %604
  store <4 x i32> %713, <4 x i32>* %286, align 16
  %714 = add <4 x i32> %618, %603
  store <4 x i32> %714, <4 x i32>* %62, align 16
  %715 = sub <4 x i32> %618, %603
  store <4 x i32> %715, <4 x i32>* %349, align 16
  %716 = sub <4 x i32> %617, %604
  store <4 x i32> %716, <4 x i32>* %59, align 16
  %717 = sub <4 x i32> %616, %662
  store <4 x i32> %717, <4 x i32>* %283, align 16
  %718 = sub <4 x i32> %615, %706
  store <4 x i32> %718, <4 x i32>* %118, align 16
  %719 = sub <4 x i32> %614, %684
  store <4 x i32> %719, <4 x i32>* %399, align 16
  %720 = sub <4 x i32> %613, %640
  store <4 x i32> %720, <4 x i32>* %171, align 16
  %721 = sub <4 x i32> %612, %609
  store <4 x i32> %721, <4 x i32>* %230, align 16
  %722 = sub <4 x i32> %611, %610
  store <4 x i32> %722, <4 x i32>* %6, align 16
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_highbd_idct16x16_256_add_sse4_1(i32* nocapture readonly, i16* nocapture, i32, i32) local_unnamed_addr #0 {
  %5 = alloca [16 x <2 x i64>], align 16
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = alloca [16 x <2 x i64>], align 16
  %8 = alloca [4 x [16 x <2 x i64>]], align 16
  %9 = bitcast [16 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %9) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 256, i1 false)
  %10 = icmp eq i32 %3, 8
  br i1 %10, label %11, label %430

11:                                               ; preds = %4
  %12 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %12) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %12, i8 -86, i64 256, i1 false)
  %13 = bitcast [16 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %13) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 256, i1 false)
  %14 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %15 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  br label %34

16:                                               ; preds = %34
  %17 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 0
  %18 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 1
  %19 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 2
  %20 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 3
  %21 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 4
  %22 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 5
  %23 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 6
  %24 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 7
  %25 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 8
  %26 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 9
  %27 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 10
  %28 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 11
  %29 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 12
  %30 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 13
  %31 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 14
  %32 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 15
  %33 = sext i32 %2 to i64
  br label %261

34:                                               ; preds = %34, %11
  %35 = phi <2 x i64>* [ %14, %11 ], [ %15, %34 ]
  %36 = phi i32 [ 0, %11 ], [ %259, %34 ]
  %37 = phi i32* [ %0, %11 ], [ %258, %34 ]
  %38 = bitcast i32* %37 to <4 x i32>*
  %39 = load <4 x i32>, <4 x i32>* %38, align 16
  %40 = getelementptr inbounds i32, i32* %37, i64 4
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 16
  %43 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %39, <4 x i32> %42) #5
  %44 = bitcast <2 x i64>* %35 to <8 x i16>*
  store <8 x i16> %43, <8 x i16>* %44, align 16
  %45 = getelementptr inbounds i32, i32* %37, i64 16
  %46 = bitcast i32* %45 to <4 x i32>*
  %47 = load <4 x i32>, <4 x i32>* %46, align 16
  %48 = getelementptr inbounds i32, i32* %37, i64 20
  %49 = bitcast i32* %48 to <4 x i32>*
  %50 = load <4 x i32>, <4 x i32>* %49, align 16
  %51 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %47, <4 x i32> %50) #5
  %52 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 1
  %53 = bitcast <2 x i64>* %52 to <8 x i16>*
  store <8 x i16> %51, <8 x i16>* %53, align 16
  %54 = getelementptr inbounds i32, i32* %37, i64 32
  %55 = bitcast i32* %54 to <4 x i32>*
  %56 = load <4 x i32>, <4 x i32>* %55, align 16
  %57 = getelementptr inbounds i32, i32* %37, i64 36
  %58 = bitcast i32* %57 to <4 x i32>*
  %59 = load <4 x i32>, <4 x i32>* %58, align 16
  %60 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %56, <4 x i32> %59) #5
  %61 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 2
  %62 = bitcast <2 x i64>* %61 to <8 x i16>*
  store <8 x i16> %60, <8 x i16>* %62, align 16
  %63 = getelementptr inbounds i32, i32* %37, i64 48
  %64 = bitcast i32* %63 to <4 x i32>*
  %65 = load <4 x i32>, <4 x i32>* %64, align 16
  %66 = getelementptr inbounds i32, i32* %37, i64 52
  %67 = bitcast i32* %66 to <4 x i32>*
  %68 = load <4 x i32>, <4 x i32>* %67, align 16
  %69 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %65, <4 x i32> %68) #5
  %70 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 3
  %71 = bitcast <2 x i64>* %70 to <8 x i16>*
  store <8 x i16> %69, <8 x i16>* %71, align 16
  %72 = getelementptr inbounds i32, i32* %37, i64 64
  %73 = bitcast i32* %72 to <4 x i32>*
  %74 = load <4 x i32>, <4 x i32>* %73, align 16
  %75 = getelementptr inbounds i32, i32* %37, i64 68
  %76 = bitcast i32* %75 to <4 x i32>*
  %77 = load <4 x i32>, <4 x i32>* %76, align 16
  %78 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %74, <4 x i32> %77) #5
  %79 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 4
  %80 = bitcast <2 x i64>* %79 to <8 x i16>*
  store <8 x i16> %78, <8 x i16>* %80, align 16
  %81 = getelementptr inbounds i32, i32* %37, i64 80
  %82 = bitcast i32* %81 to <4 x i32>*
  %83 = load <4 x i32>, <4 x i32>* %82, align 16
  %84 = getelementptr inbounds i32, i32* %37, i64 84
  %85 = bitcast i32* %84 to <4 x i32>*
  %86 = load <4 x i32>, <4 x i32>* %85, align 16
  %87 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %83, <4 x i32> %86) #5
  %88 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 5
  %89 = bitcast <2 x i64>* %88 to <8 x i16>*
  store <8 x i16> %87, <8 x i16>* %89, align 16
  %90 = getelementptr inbounds i32, i32* %37, i64 96
  %91 = bitcast i32* %90 to <4 x i32>*
  %92 = load <4 x i32>, <4 x i32>* %91, align 16
  %93 = getelementptr inbounds i32, i32* %37, i64 100
  %94 = bitcast i32* %93 to <4 x i32>*
  %95 = load <4 x i32>, <4 x i32>* %94, align 16
  %96 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %92, <4 x i32> %95) #5
  %97 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 6
  %98 = bitcast <2 x i64>* %97 to <8 x i16>*
  store <8 x i16> %96, <8 x i16>* %98, align 16
  %99 = getelementptr inbounds i32, i32* %37, i64 112
  %100 = bitcast i32* %99 to <4 x i32>*
  %101 = load <4 x i32>, <4 x i32>* %100, align 16
  %102 = getelementptr inbounds i32, i32* %37, i64 116
  %103 = bitcast i32* %102 to <4 x i32>*
  %104 = load <4 x i32>, <4 x i32>* %103, align 16
  %105 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %101, <4 x i32> %104) #5
  %106 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 7
  %107 = shufflevector <8 x i16> %43, <8 x i16> %51, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %108 = shufflevector <8 x i16> %60, <8 x i16> %69, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %109 = shufflevector <8 x i16> %78, <8 x i16> %87, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %110 = shufflevector <8 x i16> %96, <8 x i16> %105, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %111 = shufflevector <8 x i16> %43, <8 x i16> %51, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %112 = shufflevector <8 x i16> %60, <8 x i16> %69, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %113 = shufflevector <8 x i16> %78, <8 x i16> %87, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %114 = shufflevector <8 x i16> %96, <8 x i16> %105, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %115 = bitcast <8 x i16> %107 to <4 x i32>
  %116 = bitcast <8 x i16> %108 to <4 x i32>
  %117 = shufflevector <4 x i32> %115, <4 x i32> %116, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = bitcast <8 x i16> %109 to <4 x i32>
  %120 = bitcast <8 x i16> %110 to <4 x i32>
  %121 = shufflevector <4 x i32> %119, <4 x i32> %120, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %122 = bitcast <4 x i32> %121 to <2 x i64>
  %123 = bitcast <8 x i16> %111 to <4 x i32>
  %124 = bitcast <8 x i16> %112 to <4 x i32>
  %125 = shufflevector <4 x i32> %123, <4 x i32> %124, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %126 = bitcast <4 x i32> %125 to <2 x i64>
  %127 = bitcast <8 x i16> %113 to <4 x i32>
  %128 = bitcast <8 x i16> %114 to <4 x i32>
  %129 = shufflevector <4 x i32> %127, <4 x i32> %128, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %130 = bitcast <4 x i32> %129 to <2 x i64>
  %131 = shufflevector <4 x i32> %115, <4 x i32> %116, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %132 = bitcast <4 x i32> %131 to <2 x i64>
  %133 = shufflevector <4 x i32> %119, <4 x i32> %120, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %134 = bitcast <4 x i32> %133 to <2 x i64>
  %135 = shufflevector <4 x i32> %123, <4 x i32> %124, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %136 = bitcast <4 x i32> %135 to <2 x i64>
  %137 = shufflevector <4 x i32> %127, <4 x i32> %128, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %138 = bitcast <4 x i32> %137 to <2 x i64>
  %139 = shufflevector <2 x i64> %118, <2 x i64> %122, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %139, <2 x i64>* %35, align 16
  %140 = shufflevector <2 x i64> %118, <2 x i64> %122, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %140, <2 x i64>* %52, align 16
  %141 = shufflevector <2 x i64> %132, <2 x i64> %134, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %141, <2 x i64>* %61, align 16
  %142 = shufflevector <2 x i64> %132, <2 x i64> %134, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %142, <2 x i64>* %70, align 16
  %143 = shufflevector <2 x i64> %126, <2 x i64> %130, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %143, <2 x i64>* %79, align 16
  %144 = shufflevector <2 x i64> %126, <2 x i64> %130, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %144, <2 x i64>* %88, align 16
  %145 = shufflevector <2 x i64> %136, <2 x i64> %138, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %145, <2 x i64>* %97, align 16
  %146 = shufflevector <2 x i64> %136, <2 x i64> %138, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %146, <2 x i64>* %106, align 16
  %147 = getelementptr inbounds i32, i32* %37, i64 8
  %148 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 8
  %149 = bitcast i32* %147 to <4 x i32>*
  %150 = load <4 x i32>, <4 x i32>* %149, align 16
  %151 = getelementptr inbounds i32, i32* %37, i64 12
  %152 = bitcast i32* %151 to <4 x i32>*
  %153 = load <4 x i32>, <4 x i32>* %152, align 16
  %154 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %150, <4 x i32> %153) #5
  %155 = bitcast <2 x i64>* %148 to <8 x i16>*
  store <8 x i16> %154, <8 x i16>* %155, align 16
  %156 = getelementptr inbounds i32, i32* %37, i64 24
  %157 = bitcast i32* %156 to <4 x i32>*
  %158 = load <4 x i32>, <4 x i32>* %157, align 16
  %159 = getelementptr inbounds i32, i32* %37, i64 28
  %160 = bitcast i32* %159 to <4 x i32>*
  %161 = load <4 x i32>, <4 x i32>* %160, align 16
  %162 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %158, <4 x i32> %161) #5
  %163 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 9
  %164 = bitcast <2 x i64>* %163 to <8 x i16>*
  store <8 x i16> %162, <8 x i16>* %164, align 16
  %165 = getelementptr inbounds i32, i32* %37, i64 40
  %166 = bitcast i32* %165 to <4 x i32>*
  %167 = load <4 x i32>, <4 x i32>* %166, align 16
  %168 = getelementptr inbounds i32, i32* %37, i64 44
  %169 = bitcast i32* %168 to <4 x i32>*
  %170 = load <4 x i32>, <4 x i32>* %169, align 16
  %171 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %167, <4 x i32> %170) #5
  %172 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 10
  %173 = bitcast <2 x i64>* %172 to <8 x i16>*
  store <8 x i16> %171, <8 x i16>* %173, align 16
  %174 = getelementptr inbounds i32, i32* %37, i64 56
  %175 = bitcast i32* %174 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = getelementptr inbounds i32, i32* %37, i64 60
  %178 = bitcast i32* %177 to <4 x i32>*
  %179 = load <4 x i32>, <4 x i32>* %178, align 16
  %180 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %176, <4 x i32> %179) #5
  %181 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 11
  %182 = bitcast <2 x i64>* %181 to <8 x i16>*
  store <8 x i16> %180, <8 x i16>* %182, align 16
  %183 = getelementptr inbounds i32, i32* %37, i64 72
  %184 = bitcast i32* %183 to <4 x i32>*
  %185 = load <4 x i32>, <4 x i32>* %184, align 16
  %186 = getelementptr inbounds i32, i32* %37, i64 76
  %187 = bitcast i32* %186 to <4 x i32>*
  %188 = load <4 x i32>, <4 x i32>* %187, align 16
  %189 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %185, <4 x i32> %188) #5
  %190 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 12
  %191 = bitcast <2 x i64>* %190 to <8 x i16>*
  store <8 x i16> %189, <8 x i16>* %191, align 16
  %192 = getelementptr inbounds i32, i32* %37, i64 88
  %193 = bitcast i32* %192 to <4 x i32>*
  %194 = load <4 x i32>, <4 x i32>* %193, align 16
  %195 = getelementptr inbounds i32, i32* %37, i64 92
  %196 = bitcast i32* %195 to <4 x i32>*
  %197 = load <4 x i32>, <4 x i32>* %196, align 16
  %198 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %194, <4 x i32> %197) #5
  %199 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 13
  %200 = bitcast <2 x i64>* %199 to <8 x i16>*
  store <8 x i16> %198, <8 x i16>* %200, align 16
  %201 = getelementptr inbounds i32, i32* %37, i64 104
  %202 = bitcast i32* %201 to <4 x i32>*
  %203 = load <4 x i32>, <4 x i32>* %202, align 16
  %204 = getelementptr inbounds i32, i32* %37, i64 108
  %205 = bitcast i32* %204 to <4 x i32>*
  %206 = load <4 x i32>, <4 x i32>* %205, align 16
  %207 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %203, <4 x i32> %206) #5
  %208 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 14
  %209 = bitcast <2 x i64>* %208 to <8 x i16>*
  store <8 x i16> %207, <8 x i16>* %209, align 16
  %210 = getelementptr inbounds i32, i32* %37, i64 120
  %211 = bitcast i32* %210 to <4 x i32>*
  %212 = load <4 x i32>, <4 x i32>* %211, align 16
  %213 = getelementptr inbounds i32, i32* %37, i64 124
  %214 = bitcast i32* %213 to <4 x i32>*
  %215 = load <4 x i32>, <4 x i32>* %214, align 16
  %216 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %212, <4 x i32> %215) #5
  %217 = getelementptr inbounds <2 x i64>, <2 x i64>* %35, i64 15
  %218 = shufflevector <8 x i16> %154, <8 x i16> %162, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %219 = shufflevector <8 x i16> %171, <8 x i16> %180, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %220 = shufflevector <8 x i16> %189, <8 x i16> %198, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %221 = shufflevector <8 x i16> %207, <8 x i16> %216, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %222 = shufflevector <8 x i16> %154, <8 x i16> %162, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %223 = shufflevector <8 x i16> %171, <8 x i16> %180, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %224 = shufflevector <8 x i16> %189, <8 x i16> %198, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %225 = shufflevector <8 x i16> %207, <8 x i16> %216, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %226 = bitcast <8 x i16> %218 to <4 x i32>
  %227 = bitcast <8 x i16> %219 to <4 x i32>
  %228 = shufflevector <4 x i32> %226, <4 x i32> %227, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %229 = bitcast <4 x i32> %228 to <2 x i64>
  %230 = bitcast <8 x i16> %220 to <4 x i32>
  %231 = bitcast <8 x i16> %221 to <4 x i32>
  %232 = shufflevector <4 x i32> %230, <4 x i32> %231, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %233 = bitcast <4 x i32> %232 to <2 x i64>
  %234 = bitcast <8 x i16> %222 to <4 x i32>
  %235 = bitcast <8 x i16> %223 to <4 x i32>
  %236 = shufflevector <4 x i32> %234, <4 x i32> %235, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %237 = bitcast <4 x i32> %236 to <2 x i64>
  %238 = bitcast <8 x i16> %224 to <4 x i32>
  %239 = bitcast <8 x i16> %225 to <4 x i32>
  %240 = shufflevector <4 x i32> %238, <4 x i32> %239, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %241 = bitcast <4 x i32> %240 to <2 x i64>
  %242 = shufflevector <4 x i32> %226, <4 x i32> %227, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %243 = bitcast <4 x i32> %242 to <2 x i64>
  %244 = shufflevector <4 x i32> %230, <4 x i32> %231, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %245 = bitcast <4 x i32> %244 to <2 x i64>
  %246 = shufflevector <4 x i32> %234, <4 x i32> %235, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %247 = bitcast <4 x i32> %246 to <2 x i64>
  %248 = shufflevector <4 x i32> %238, <4 x i32> %239, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %249 = bitcast <4 x i32> %248 to <2 x i64>
  %250 = shufflevector <2 x i64> %229, <2 x i64> %233, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %250, <2 x i64>* %148, align 16
  %251 = shufflevector <2 x i64> %229, <2 x i64> %233, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %251, <2 x i64>* %163, align 16
  %252 = shufflevector <2 x i64> %243, <2 x i64> %245, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %252, <2 x i64>* %172, align 16
  %253 = shufflevector <2 x i64> %243, <2 x i64> %245, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %253, <2 x i64>* %181, align 16
  %254 = shufflevector <2 x i64> %237, <2 x i64> %241, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %254, <2 x i64>* %190, align 16
  %255 = shufflevector <2 x i64> %237, <2 x i64> %241, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %255, <2 x i64>* %199, align 16
  %256 = shufflevector <2 x i64> %247, <2 x i64> %249, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %256, <2 x i64>* %208, align 16
  %257 = shufflevector <2 x i64> %247, <2 x i64> %249, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %257, <2 x i64>* %217, align 16
  call fastcc void @idct16_8col(<2 x i64>* %35, <2 x i64>* %35)
  %258 = getelementptr inbounds i32, i32* %37, i64 128
  %259 = add nuw nsw i32 %36, 1
  %260 = icmp eq i32 %259, 2
  br i1 %260, label %16, label %34

261:                                              ; preds = %16, %425
  %262 = phi i64 [ 0, %16 ], [ %427, %425 ]
  %263 = phi i16* [ %1, %16 ], [ %426, %425 ]
  %264 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %262
  %265 = bitcast <2 x i64>* %264 to <8 x i16>*
  %266 = load <8 x i16>, <8 x i16>* %265, align 16
  %267 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 1
  %268 = bitcast <2 x i64>* %267 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = shufflevector <8 x i16> %266, <8 x i16> %269, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %271 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 2
  %272 = bitcast <2 x i64>* %271 to <8 x i16>*
  %273 = load <8 x i16>, <8 x i16>* %272, align 16
  %274 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 3
  %275 = bitcast <2 x i64>* %274 to <8 x i16>*
  %276 = load <8 x i16>, <8 x i16>* %275, align 16
  %277 = shufflevector <8 x i16> %273, <8 x i16> %276, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %278 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 4
  %279 = bitcast <2 x i64>* %278 to <8 x i16>*
  %280 = load <8 x i16>, <8 x i16>* %279, align 16
  %281 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 5
  %282 = bitcast <2 x i64>* %281 to <8 x i16>*
  %283 = load <8 x i16>, <8 x i16>* %282, align 16
  %284 = shufflevector <8 x i16> %280, <8 x i16> %283, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %285 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 6
  %286 = bitcast <2 x i64>* %285 to <8 x i16>*
  %287 = load <8 x i16>, <8 x i16>* %286, align 16
  %288 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 7
  %289 = bitcast <2 x i64>* %288 to <8 x i16>*
  %290 = load <8 x i16>, <8 x i16>* %289, align 16
  %291 = shufflevector <8 x i16> %287, <8 x i16> %290, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %292 = shufflevector <8 x i16> %266, <8 x i16> %269, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %293 = shufflevector <8 x i16> %273, <8 x i16> %276, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %294 = shufflevector <8 x i16> %280, <8 x i16> %283, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %295 = shufflevector <8 x i16> %287, <8 x i16> %290, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %296 = bitcast <8 x i16> %270 to <4 x i32>
  %297 = bitcast <8 x i16> %277 to <4 x i32>
  %298 = shufflevector <4 x i32> %296, <4 x i32> %297, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %299 = bitcast <4 x i32> %298 to <2 x i64>
  %300 = bitcast <8 x i16> %284 to <4 x i32>
  %301 = bitcast <8 x i16> %291 to <4 x i32>
  %302 = shufflevector <4 x i32> %300, <4 x i32> %301, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %303 = bitcast <4 x i32> %302 to <2 x i64>
  %304 = bitcast <8 x i16> %292 to <4 x i32>
  %305 = bitcast <8 x i16> %293 to <4 x i32>
  %306 = shufflevector <4 x i32> %304, <4 x i32> %305, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %307 = bitcast <4 x i32> %306 to <2 x i64>
  %308 = bitcast <8 x i16> %294 to <4 x i32>
  %309 = bitcast <8 x i16> %295 to <4 x i32>
  %310 = shufflevector <4 x i32> %308, <4 x i32> %309, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %311 = bitcast <4 x i32> %310 to <2 x i64>
  %312 = shufflevector <4 x i32> %296, <4 x i32> %297, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %313 = bitcast <4 x i32> %312 to <2 x i64>
  %314 = shufflevector <4 x i32> %300, <4 x i32> %301, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %315 = bitcast <4 x i32> %314 to <2 x i64>
  %316 = shufflevector <4 x i32> %304, <4 x i32> %305, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %317 = bitcast <4 x i32> %316 to <2 x i64>
  %318 = shufflevector <4 x i32> %308, <4 x i32> %309, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %319 = bitcast <4 x i32> %318 to <2 x i64>
  %320 = shufflevector <2 x i64> %299, <2 x i64> %303, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %320, <2 x i64>* %17, align 16
  %321 = shufflevector <2 x i64> %299, <2 x i64> %303, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %321, <2 x i64>* %18, align 16
  %322 = shufflevector <2 x i64> %313, <2 x i64> %315, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %322, <2 x i64>* %19, align 16
  %323 = shufflevector <2 x i64> %313, <2 x i64> %315, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %323, <2 x i64>* %20, align 16
  %324 = shufflevector <2 x i64> %307, <2 x i64> %311, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %324, <2 x i64>* %21, align 16
  %325 = shufflevector <2 x i64> %307, <2 x i64> %311, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %325, <2 x i64>* %22, align 16
  %326 = shufflevector <2 x i64> %317, <2 x i64> %319, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %326, <2 x i64>* %23, align 16
  %327 = shufflevector <2 x i64> %317, <2 x i64> %319, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %327, <2 x i64>* %24, align 16
  %328 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 %262
  %329 = bitcast <2 x i64>* %328 to <8 x i16>*
  %330 = load <8 x i16>, <8 x i16>* %329, align 16
  %331 = getelementptr inbounds <2 x i64>, <2 x i64>* %328, i64 1
  %332 = bitcast <2 x i64>* %331 to <8 x i16>*
  %333 = load <8 x i16>, <8 x i16>* %332, align 16
  %334 = shufflevector <8 x i16> %330, <8 x i16> %333, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %335 = getelementptr inbounds <2 x i64>, <2 x i64>* %328, i64 2
  %336 = bitcast <2 x i64>* %335 to <8 x i16>*
  %337 = load <8 x i16>, <8 x i16>* %336, align 16
  %338 = getelementptr inbounds <2 x i64>, <2 x i64>* %328, i64 3
  %339 = bitcast <2 x i64>* %338 to <8 x i16>*
  %340 = load <8 x i16>, <8 x i16>* %339, align 16
  %341 = shufflevector <8 x i16> %337, <8 x i16> %340, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %342 = getelementptr inbounds <2 x i64>, <2 x i64>* %328, i64 4
  %343 = bitcast <2 x i64>* %342 to <8 x i16>*
  %344 = load <8 x i16>, <8 x i16>* %343, align 16
  %345 = getelementptr inbounds <2 x i64>, <2 x i64>* %328, i64 5
  %346 = bitcast <2 x i64>* %345 to <8 x i16>*
  %347 = load <8 x i16>, <8 x i16>* %346, align 16
  %348 = shufflevector <8 x i16> %344, <8 x i16> %347, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %349 = getelementptr inbounds <2 x i64>, <2 x i64>* %328, i64 6
  %350 = bitcast <2 x i64>* %349 to <8 x i16>*
  %351 = load <8 x i16>, <8 x i16>* %350, align 16
  %352 = getelementptr inbounds <2 x i64>, <2 x i64>* %328, i64 7
  %353 = bitcast <2 x i64>* %352 to <8 x i16>*
  %354 = load <8 x i16>, <8 x i16>* %353, align 16
  %355 = shufflevector <8 x i16> %351, <8 x i16> %354, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %356 = shufflevector <8 x i16> %330, <8 x i16> %333, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %357 = shufflevector <8 x i16> %337, <8 x i16> %340, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %358 = shufflevector <8 x i16> %344, <8 x i16> %347, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %359 = shufflevector <8 x i16> %351, <8 x i16> %354, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %360 = bitcast <8 x i16> %334 to <4 x i32>
  %361 = bitcast <8 x i16> %341 to <4 x i32>
  %362 = shufflevector <4 x i32> %360, <4 x i32> %361, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %363 = bitcast <4 x i32> %362 to <2 x i64>
  %364 = bitcast <8 x i16> %348 to <4 x i32>
  %365 = bitcast <8 x i16> %355 to <4 x i32>
  %366 = shufflevector <4 x i32> %364, <4 x i32> %365, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %367 = bitcast <4 x i32> %366 to <2 x i64>
  %368 = bitcast <8 x i16> %356 to <4 x i32>
  %369 = bitcast <8 x i16> %357 to <4 x i32>
  %370 = shufflevector <4 x i32> %368, <4 x i32> %369, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %371 = bitcast <4 x i32> %370 to <2 x i64>
  %372 = bitcast <8 x i16> %358 to <4 x i32>
  %373 = bitcast <8 x i16> %359 to <4 x i32>
  %374 = shufflevector <4 x i32> %372, <4 x i32> %373, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %375 = bitcast <4 x i32> %374 to <2 x i64>
  %376 = shufflevector <4 x i32> %360, <4 x i32> %361, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %377 = bitcast <4 x i32> %376 to <2 x i64>
  %378 = shufflevector <4 x i32> %364, <4 x i32> %365, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %379 = bitcast <4 x i32> %378 to <2 x i64>
  %380 = shufflevector <4 x i32> %368, <4 x i32> %369, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %381 = bitcast <4 x i32> %380 to <2 x i64>
  %382 = shufflevector <4 x i32> %372, <4 x i32> %373, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %383 = bitcast <4 x i32> %382 to <2 x i64>
  %384 = shufflevector <2 x i64> %363, <2 x i64> %367, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %384, <2 x i64>* %25, align 16
  %385 = shufflevector <2 x i64> %363, <2 x i64> %367, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %385, <2 x i64>* %26, align 16
  %386 = shufflevector <2 x i64> %377, <2 x i64> %379, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %386, <2 x i64>* %27, align 16
  %387 = shufflevector <2 x i64> %377, <2 x i64> %379, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %387, <2 x i64>* %28, align 16
  %388 = shufflevector <2 x i64> %371, <2 x i64> %375, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %388, <2 x i64>* %29, align 16
  %389 = shufflevector <2 x i64> %371, <2 x i64> %375, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %389, <2 x i64>* %30, align 16
  %390 = shufflevector <2 x i64> %381, <2 x i64> %383, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %390, <2 x i64>* %31, align 16
  %391 = shufflevector <2 x i64> %381, <2 x i64> %383, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %391, <2 x i64>* %32, align 16
  call fastcc void @idct16_8col(<2 x i64>* nonnull %17, <2 x i64>* nonnull %17)
  br label %392

392:                                              ; preds = %392, %261
  %393 = phi i64 [ 0, %261 ], [ %423, %392 ]
  %394 = mul nsw i64 %393, %33
  %395 = getelementptr inbounds i16, i16* %263, i64 %394
  %396 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %393
  %397 = bitcast <2 x i64>* %396 to <8 x i16>*
  %398 = load <8 x i16>, <8 x i16>* %397, align 16
  %399 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %398, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %400 = ashr <8 x i16> %399, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %401 = bitcast i16* %395 to <8 x i16>*
  %402 = load <8 x i16>, <8 x i16>* %401, align 16
  %403 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %402, <8 x i16> %400) #5
  %404 = icmp sgt <8 x i16> %403, zeroinitializer
  %405 = select <8 x i1> %404, <8 x i16> %403, <8 x i16> zeroinitializer
  %406 = icmp slt <8 x i16> %405, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %407 = select <8 x i1> %406, <8 x i16> %405, <8 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  store <8 x i16> %407, <8 x i16>* %401, align 16
  %408 = or i64 %393, 1
  %409 = mul nsw i64 %408, %33
  %410 = getelementptr inbounds i16, i16* %263, i64 %409
  %411 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %408
  %412 = bitcast <2 x i64>* %411 to <8 x i16>*
  %413 = load <8 x i16>, <8 x i16>* %412, align 16
  %414 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %413, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %415 = ashr <8 x i16> %414, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %416 = bitcast i16* %410 to <8 x i16>*
  %417 = load <8 x i16>, <8 x i16>* %416, align 16
  %418 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %417, <8 x i16> %415) #5
  %419 = icmp sgt <8 x i16> %418, zeroinitializer
  %420 = select <8 x i1> %419, <8 x i16> %418, <8 x i16> zeroinitializer
  %421 = icmp slt <8 x i16> %420, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %422 = select <8 x i1> %421, <8 x i16> %420, <8 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  store <8 x i16> %422, <8 x i16>* %416, align 16
  %423 = add nuw nsw i64 %393, 2
  %424 = icmp eq i64 %423, 16
  br i1 %424, label %425, label %392

425:                                              ; preds = %392
  %426 = getelementptr inbounds i16, i16* %263, i64 8
  %427 = add nuw nsw i64 %262, 8
  %428 = icmp ult i64 %427, 16
  br i1 %428, label %261, label %429

429:                                              ; preds = %425
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %13) #5
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %12) #5
  br label %710

430:                                              ; preds = %4
  %431 = bitcast [4 x [16 x <2 x i64>]]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %431) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %431, i8 -86, i64 1024, i1 false)
  br label %450

432:                                              ; preds = %450
  %433 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 0
  %434 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 1
  %435 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 2
  %436 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 3
  %437 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 4
  %438 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 5
  %439 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 6
  %440 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 7
  %441 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 8
  %442 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 9
  %443 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 10
  %444 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 11
  %445 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 12
  %446 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 13
  %447 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 14
  %448 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 15
  %449 = sext i32 %2 to i64
  br label %581

450:                                              ; preds = %450, %430
  %451 = phi i64 [ 0, %430 ], [ %579, %450 ]
  %452 = phi i32* [ %0, %430 ], [ %578, %450 ]
  %453 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 0
  %454 = bitcast i32* %452 to <2 x i64>*
  %455 = load <2 x i64>, <2 x i64>* %454, align 16
  store <2 x i64> %455, <2 x i64>* %453, align 16
  %456 = getelementptr inbounds i32, i32* %452, i64 4
  %457 = bitcast i32* %456 to <2 x i64>*
  %458 = load <2 x i64>, <2 x i64>* %457, align 16
  %459 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 1
  store <2 x i64> %458, <2 x i64>* %459, align 16
  %460 = getelementptr inbounds i32, i32* %452, i64 16
  %461 = bitcast i32* %460 to <2 x i64>*
  %462 = load <2 x i64>, <2 x i64>* %461, align 16
  %463 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 2
  store <2 x i64> %462, <2 x i64>* %463, align 16
  %464 = getelementptr inbounds i32, i32* %452, i64 20
  %465 = bitcast i32* %464 to <2 x i64>*
  %466 = load <2 x i64>, <2 x i64>* %465, align 16
  %467 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 3
  store <2 x i64> %466, <2 x i64>* %467, align 16
  %468 = getelementptr inbounds i32, i32* %452, i64 32
  %469 = bitcast i32* %468 to <2 x i64>*
  %470 = load <2 x i64>, <2 x i64>* %469, align 16
  %471 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 4
  store <2 x i64> %470, <2 x i64>* %471, align 16
  %472 = getelementptr inbounds i32, i32* %452, i64 36
  %473 = bitcast i32* %472 to <2 x i64>*
  %474 = load <2 x i64>, <2 x i64>* %473, align 16
  %475 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 5
  store <2 x i64> %474, <2 x i64>* %475, align 16
  %476 = getelementptr inbounds i32, i32* %452, i64 48
  %477 = bitcast i32* %476 to <2 x i64>*
  %478 = load <2 x i64>, <2 x i64>* %477, align 16
  %479 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 6
  store <2 x i64> %478, <2 x i64>* %479, align 16
  %480 = getelementptr inbounds i32, i32* %452, i64 52
  %481 = bitcast i32* %480 to <4 x i32>*
  %482 = load <4 x i32>, <4 x i32>* %481, align 16
  %483 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 7
  %484 = bitcast <2 x i64> %455 to <4 x i32>
  %485 = bitcast <2 x i64> %462 to <4 x i32>
  %486 = shufflevector <4 x i32> %484, <4 x i32> %485, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %487 = bitcast <4 x i32> %486 to <2 x i64>
  %488 = bitcast <2 x i64> %470 to <4 x i32>
  %489 = bitcast <2 x i64> %478 to <4 x i32>
  %490 = shufflevector <4 x i32> %488, <4 x i32> %489, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %491 = bitcast <4 x i32> %490 to <2 x i64>
  %492 = shufflevector <4 x i32> %484, <4 x i32> %485, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %493 = bitcast <4 x i32> %492 to <2 x i64>
  %494 = shufflevector <4 x i32> %488, <4 x i32> %489, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %495 = bitcast <4 x i32> %494 to <2 x i64>
  %496 = bitcast <2 x i64> %458 to <4 x i32>
  %497 = bitcast <2 x i64> %466 to <4 x i32>
  %498 = shufflevector <4 x i32> %496, <4 x i32> %497, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %499 = bitcast <4 x i32> %498 to <2 x i64>
  %500 = bitcast <2 x i64> %474 to <4 x i32>
  %501 = shufflevector <4 x i32> %500, <4 x i32> %482, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %502 = bitcast <4 x i32> %501 to <2 x i64>
  %503 = shufflevector <4 x i32> %496, <4 x i32> %497, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %504 = bitcast <4 x i32> %503 to <2 x i64>
  %505 = shufflevector <4 x i32> %500, <4 x i32> %482, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %506 = bitcast <4 x i32> %505 to <2 x i64>
  %507 = shufflevector <2 x i64> %487, <2 x i64> %491, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %507, <2 x i64>* %453, align 16
  %508 = shufflevector <2 x i64> %487, <2 x i64> %491, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %508, <2 x i64>* %459, align 16
  %509 = shufflevector <2 x i64> %493, <2 x i64> %495, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %509, <2 x i64>* %463, align 16
  %510 = shufflevector <2 x i64> %493, <2 x i64> %495, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %510, <2 x i64>* %467, align 16
  %511 = shufflevector <2 x i64> %499, <2 x i64> %502, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %511, <2 x i64>* %471, align 16
  %512 = shufflevector <2 x i64> %499, <2 x i64> %502, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %512, <2 x i64>* %475, align 16
  %513 = shufflevector <2 x i64> %504, <2 x i64> %506, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %513, <2 x i64>* %479, align 16
  %514 = shufflevector <2 x i64> %504, <2 x i64> %506, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %514, <2 x i64>* %483, align 16
  %515 = getelementptr inbounds i32, i32* %452, i64 8
  %516 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 8
  %517 = bitcast i32* %515 to <2 x i64>*
  %518 = load <2 x i64>, <2 x i64>* %517, align 16
  store <2 x i64> %518, <2 x i64>* %516, align 16
  %519 = getelementptr inbounds i32, i32* %452, i64 12
  %520 = bitcast i32* %519 to <2 x i64>*
  %521 = load <2 x i64>, <2 x i64>* %520, align 16
  %522 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 9
  store <2 x i64> %521, <2 x i64>* %522, align 16
  %523 = getelementptr inbounds i32, i32* %452, i64 24
  %524 = bitcast i32* %523 to <2 x i64>*
  %525 = load <2 x i64>, <2 x i64>* %524, align 16
  %526 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 10
  store <2 x i64> %525, <2 x i64>* %526, align 16
  %527 = getelementptr inbounds i32, i32* %452, i64 28
  %528 = bitcast i32* %527 to <2 x i64>*
  %529 = load <2 x i64>, <2 x i64>* %528, align 16
  %530 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 11
  store <2 x i64> %529, <2 x i64>* %530, align 16
  %531 = getelementptr inbounds i32, i32* %452, i64 40
  %532 = bitcast i32* %531 to <2 x i64>*
  %533 = load <2 x i64>, <2 x i64>* %532, align 16
  %534 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 12
  store <2 x i64> %533, <2 x i64>* %534, align 16
  %535 = getelementptr inbounds i32, i32* %452, i64 44
  %536 = bitcast i32* %535 to <2 x i64>*
  %537 = load <2 x i64>, <2 x i64>* %536, align 16
  %538 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 13
  store <2 x i64> %537, <2 x i64>* %538, align 16
  %539 = getelementptr inbounds i32, i32* %452, i64 56
  %540 = bitcast i32* %539 to <2 x i64>*
  %541 = load <2 x i64>, <2 x i64>* %540, align 16
  %542 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 14
  store <2 x i64> %541, <2 x i64>* %542, align 16
  %543 = getelementptr inbounds i32, i32* %452, i64 60
  %544 = bitcast i32* %543 to <4 x i32>*
  %545 = load <4 x i32>, <4 x i32>* %544, align 16
  %546 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 %451, i64 15
  %547 = bitcast <2 x i64> %518 to <4 x i32>
  %548 = bitcast <2 x i64> %525 to <4 x i32>
  %549 = shufflevector <4 x i32> %547, <4 x i32> %548, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %550 = bitcast <4 x i32> %549 to <2 x i64>
  %551 = bitcast <2 x i64> %533 to <4 x i32>
  %552 = bitcast <2 x i64> %541 to <4 x i32>
  %553 = shufflevector <4 x i32> %551, <4 x i32> %552, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %554 = bitcast <4 x i32> %553 to <2 x i64>
  %555 = shufflevector <4 x i32> %547, <4 x i32> %548, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %556 = bitcast <4 x i32> %555 to <2 x i64>
  %557 = shufflevector <4 x i32> %551, <4 x i32> %552, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %558 = bitcast <4 x i32> %557 to <2 x i64>
  %559 = bitcast <2 x i64> %521 to <4 x i32>
  %560 = bitcast <2 x i64> %529 to <4 x i32>
  %561 = shufflevector <4 x i32> %559, <4 x i32> %560, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %562 = bitcast <4 x i32> %561 to <2 x i64>
  %563 = bitcast <2 x i64> %537 to <4 x i32>
  %564 = shufflevector <4 x i32> %563, <4 x i32> %545, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %565 = bitcast <4 x i32> %564 to <2 x i64>
  %566 = shufflevector <4 x i32> %559, <4 x i32> %560, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %567 = bitcast <4 x i32> %566 to <2 x i64>
  %568 = shufflevector <4 x i32> %563, <4 x i32> %545, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %569 = bitcast <4 x i32> %568 to <2 x i64>
  %570 = shufflevector <2 x i64> %550, <2 x i64> %554, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %570, <2 x i64>* %516, align 16
  %571 = shufflevector <2 x i64> %550, <2 x i64> %554, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %571, <2 x i64>* %522, align 16
  %572 = shufflevector <2 x i64> %556, <2 x i64> %558, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %572, <2 x i64>* %526, align 16
  %573 = shufflevector <2 x i64> %556, <2 x i64> %558, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %573, <2 x i64>* %530, align 16
  %574 = shufflevector <2 x i64> %562, <2 x i64> %565, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %574, <2 x i64>* %534, align 16
  %575 = shufflevector <2 x i64> %562, <2 x i64> %565, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %575, <2 x i64>* %538, align 16
  %576 = shufflevector <2 x i64> %567, <2 x i64> %569, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %576, <2 x i64>* %542, align 16
  %577 = shufflevector <2 x i64> %567, <2 x i64> %569, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %577, <2 x i64>* %546, align 16
  call void @vpx_highbd_idct16_4col_sse4_1(<2 x i64>* %453)
  %578 = getelementptr inbounds i32, i32* %452, i64 64
  %579 = add nuw nsw i64 %451, 1
  %580 = icmp eq i64 %579, 4
  br i1 %580, label %432, label %450

581:                                              ; preds = %432, %705
  %582 = phi i64 [ 0, %432 ], [ %707, %705 ]
  %583 = phi i16* [ %1, %432 ], [ %706, %705 ]
  %584 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 0, i64 %582
  %585 = bitcast <2 x i64>* %584 to <4 x i32>*
  %586 = load <4 x i32>, <4 x i32>* %585, align 16
  %587 = getelementptr inbounds <2 x i64>, <2 x i64>* %584, i64 1
  %588 = bitcast <2 x i64>* %587 to <4 x i32>*
  %589 = load <4 x i32>, <4 x i32>* %588, align 16
  %590 = shufflevector <4 x i32> %586, <4 x i32> %589, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %591 = bitcast <4 x i32> %590 to <2 x i64>
  %592 = getelementptr inbounds <2 x i64>, <2 x i64>* %584, i64 2
  %593 = bitcast <2 x i64>* %592 to <4 x i32>*
  %594 = load <4 x i32>, <4 x i32>* %593, align 16
  %595 = getelementptr inbounds <2 x i64>, <2 x i64>* %584, i64 3
  %596 = bitcast <2 x i64>* %595 to <4 x i32>*
  %597 = load <4 x i32>, <4 x i32>* %596, align 16
  %598 = shufflevector <4 x i32> %594, <4 x i32> %597, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %599 = bitcast <4 x i32> %598 to <2 x i64>
  %600 = shufflevector <4 x i32> %586, <4 x i32> %589, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %601 = bitcast <4 x i32> %600 to <2 x i64>
  %602 = shufflevector <4 x i32> %594, <4 x i32> %597, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %603 = bitcast <4 x i32> %602 to <2 x i64>
  %604 = shufflevector <2 x i64> %591, <2 x i64> %599, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %604, <2 x i64>* %433, align 16
  %605 = shufflevector <2 x i64> %591, <2 x i64> %599, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %605, <2 x i64>* %434, align 16
  %606 = shufflevector <2 x i64> %601, <2 x i64> %603, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %606, <2 x i64>* %435, align 16
  %607 = shufflevector <2 x i64> %601, <2 x i64> %603, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %607, <2 x i64>* %436, align 16
  %608 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 1, i64 %582
  %609 = bitcast <2 x i64>* %608 to <4 x i32>*
  %610 = load <4 x i32>, <4 x i32>* %609, align 16
  %611 = getelementptr inbounds <2 x i64>, <2 x i64>* %608, i64 1
  %612 = bitcast <2 x i64>* %611 to <4 x i32>*
  %613 = load <4 x i32>, <4 x i32>* %612, align 16
  %614 = shufflevector <4 x i32> %610, <4 x i32> %613, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %615 = bitcast <4 x i32> %614 to <2 x i64>
  %616 = getelementptr inbounds <2 x i64>, <2 x i64>* %608, i64 2
  %617 = bitcast <2 x i64>* %616 to <4 x i32>*
  %618 = load <4 x i32>, <4 x i32>* %617, align 16
  %619 = getelementptr inbounds <2 x i64>, <2 x i64>* %608, i64 3
  %620 = bitcast <2 x i64>* %619 to <4 x i32>*
  %621 = load <4 x i32>, <4 x i32>* %620, align 16
  %622 = shufflevector <4 x i32> %618, <4 x i32> %621, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %623 = bitcast <4 x i32> %622 to <2 x i64>
  %624 = shufflevector <4 x i32> %610, <4 x i32> %613, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %625 = bitcast <4 x i32> %624 to <2 x i64>
  %626 = shufflevector <4 x i32> %618, <4 x i32> %621, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %627 = bitcast <4 x i32> %626 to <2 x i64>
  %628 = shufflevector <2 x i64> %615, <2 x i64> %623, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %628, <2 x i64>* %437, align 16
  %629 = shufflevector <2 x i64> %615, <2 x i64> %623, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %629, <2 x i64>* %438, align 16
  %630 = shufflevector <2 x i64> %625, <2 x i64> %627, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %630, <2 x i64>* %439, align 16
  %631 = shufflevector <2 x i64> %625, <2 x i64> %627, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %631, <2 x i64>* %440, align 16
  %632 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 2, i64 %582
  %633 = bitcast <2 x i64>* %632 to <4 x i32>*
  %634 = load <4 x i32>, <4 x i32>* %633, align 16
  %635 = getelementptr inbounds <2 x i64>, <2 x i64>* %632, i64 1
  %636 = bitcast <2 x i64>* %635 to <4 x i32>*
  %637 = load <4 x i32>, <4 x i32>* %636, align 16
  %638 = shufflevector <4 x i32> %634, <4 x i32> %637, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %639 = bitcast <4 x i32> %638 to <2 x i64>
  %640 = getelementptr inbounds <2 x i64>, <2 x i64>* %632, i64 2
  %641 = bitcast <2 x i64>* %640 to <4 x i32>*
  %642 = load <4 x i32>, <4 x i32>* %641, align 16
  %643 = getelementptr inbounds <2 x i64>, <2 x i64>* %632, i64 3
  %644 = bitcast <2 x i64>* %643 to <4 x i32>*
  %645 = load <4 x i32>, <4 x i32>* %644, align 16
  %646 = shufflevector <4 x i32> %642, <4 x i32> %645, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %647 = bitcast <4 x i32> %646 to <2 x i64>
  %648 = shufflevector <4 x i32> %634, <4 x i32> %637, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %649 = bitcast <4 x i32> %648 to <2 x i64>
  %650 = shufflevector <4 x i32> %642, <4 x i32> %645, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %651 = bitcast <4 x i32> %650 to <2 x i64>
  %652 = shufflevector <2 x i64> %639, <2 x i64> %647, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %652, <2 x i64>* %441, align 16
  %653 = shufflevector <2 x i64> %639, <2 x i64> %647, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %653, <2 x i64>* %442, align 16
  %654 = shufflevector <2 x i64> %649, <2 x i64> %651, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %654, <2 x i64>* %443, align 16
  %655 = shufflevector <2 x i64> %649, <2 x i64> %651, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %655, <2 x i64>* %444, align 16
  %656 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %8, i64 0, i64 3, i64 %582
  %657 = bitcast <2 x i64>* %656 to <4 x i32>*
  %658 = load <4 x i32>, <4 x i32>* %657, align 16
  %659 = getelementptr inbounds <2 x i64>, <2 x i64>* %656, i64 1
  %660 = bitcast <2 x i64>* %659 to <4 x i32>*
  %661 = load <4 x i32>, <4 x i32>* %660, align 16
  %662 = shufflevector <4 x i32> %658, <4 x i32> %661, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %663 = bitcast <4 x i32> %662 to <2 x i64>
  %664 = getelementptr inbounds <2 x i64>, <2 x i64>* %656, i64 2
  %665 = bitcast <2 x i64>* %664 to <4 x i32>*
  %666 = load <4 x i32>, <4 x i32>* %665, align 16
  %667 = getelementptr inbounds <2 x i64>, <2 x i64>* %656, i64 3
  %668 = bitcast <2 x i64>* %667 to <4 x i32>*
  %669 = load <4 x i32>, <4 x i32>* %668, align 16
  %670 = shufflevector <4 x i32> %666, <4 x i32> %669, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %671 = bitcast <4 x i32> %670 to <2 x i64>
  %672 = shufflevector <4 x i32> %658, <4 x i32> %661, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %673 = bitcast <4 x i32> %672 to <2 x i64>
  %674 = shufflevector <4 x i32> %666, <4 x i32> %669, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %675 = bitcast <4 x i32> %674 to <2 x i64>
  %676 = shufflevector <2 x i64> %663, <2 x i64> %671, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %676, <2 x i64>* %445, align 16
  %677 = shufflevector <2 x i64> %663, <2 x i64> %671, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %677, <2 x i64>* %446, align 16
  %678 = shufflevector <2 x i64> %673, <2 x i64> %675, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %678, <2 x i64>* %447, align 16
  %679 = shufflevector <2 x i64> %673, <2 x i64> %675, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %679, <2 x i64>* %448, align 16
  call void @vpx_highbd_idct16_4col_sse4_1(<2 x i64>* nonnull %433)
  %680 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %3) #5
  %681 = add <8 x i16> %680, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  br label %682

682:                                              ; preds = %682, %581
  %683 = phi i64 [ 0, %581 ], [ %703, %682 ]
  %684 = mul nsw i64 %683, %449
  %685 = getelementptr inbounds i16, i16* %583, i64 %684
  %686 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %683
  %687 = bitcast <2 x i64>* %686 to <4 x i32>*
  %688 = load <4 x i32>, <4 x i32>* %687, align 16
  %689 = add <4 x i32> %688, <i32 32, i32 32, i32 32, i32 32>
  %690 = ashr <4 x i32> %689, <i32 6, i32 6, i32 6, i32 6>
  %691 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %690, <4 x i32> %690) #5
  %692 = bitcast i16* %685 to i64*
  %693 = load i64, i64* %692, align 1
  %694 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %693, i32 0
  %695 = bitcast <2 x i64> %694 to <8 x i16>
  %696 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %695, <8 x i16> %691) #5
  %697 = icmp sgt <8 x i16> %696, zeroinitializer
  %698 = select <8 x i1> %697, <8 x i16> %696, <8 x i16> zeroinitializer
  %699 = icmp slt <8 x i16> %698, %681
  %700 = select <8 x i1> %699, <8 x i16> %698, <8 x i16> %681
  %701 = bitcast <8 x i16> %700 to <2 x i64>
  %702 = extractelement <2 x i64> %701, i32 0
  store i64 %702, i64* %692, align 1
  %703 = add nuw nsw i64 %683, 1
  %704 = icmp eq i64 %703, 16
  br i1 %704, label %705, label %682

705:                                              ; preds = %682
  %706 = getelementptr inbounds i16, i16* %583, i64 4
  %707 = add nuw nsw i64 %582, 4
  %708 = icmp ult i64 %707, 16
  br i1 %708, label %581, label %709

709:                                              ; preds = %705
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %431) #5
  br label %710

710:                                              ; preds = %709, %429
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %9) #5
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define internal fastcc void @idct16_8col(<2 x i64>* nocapture readonly, <2 x i64>* nocapture) unnamed_addr #2 {
  %3 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %4 = bitcast <2 x i64>* %3 to <8 x i16>*
  %5 = load <8 x i16>, <8 x i16>* %4, align 16
  %6 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %7 = bitcast <2 x i64>* %6 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = shufflevector <8 x i16> %5, <8 x i16> %8, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10 = shufflevector <8 x i16> %5, <8 x i16> %8, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #5
  %12 = add <4 x i32> %11, <i32 8192, i32 8192, i32 8192, i32 8192>
  %13 = ashr <4 x i32> %12, <i32 14, i32 14, i32 14, i32 14>
  %14 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #5
  %15 = add <4 x i32> %14, <i32 8192, i32 8192, i32 8192, i32 8192>
  %16 = ashr <4 x i32> %15, <i32 14, i32 14, i32 14, i32 14>
  %17 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %13, <4 x i32> %16) #5
  %18 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #5
  %19 = add <4 x i32> %18, <i32 8192, i32 8192, i32 8192, i32 8192>
  %20 = ashr <4 x i32> %19, <i32 14, i32 14, i32 14, i32 14>
  %21 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #5
  %22 = add <4 x i32> %21, <i32 8192, i32 8192, i32 8192, i32 8192>
  %23 = ashr <4 x i32> %22, <i32 14, i32 14, i32 14, i32 14>
  %24 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %20, <4 x i32> %23) #5
  %25 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %26 = bitcast <2 x i64>* %25 to <8 x i16>*
  %27 = load <8 x i16>, <8 x i16>* %26, align 16
  %28 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %29 = bitcast <2 x i64>* %28 to <8 x i16>*
  %30 = load <8 x i16>, <8 x i16>* %29, align 16
  %31 = shufflevector <8 x i16> %27, <8 x i16> %30, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %32 = shufflevector <8 x i16> %27, <8 x i16> %30, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %33 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %31, <8 x i16> <i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394>) #5
  %34 = add <4 x i32> %33, <i32 8192, i32 8192, i32 8192, i32 8192>
  %35 = ashr <4 x i32> %34, <i32 14, i32 14, i32 14, i32 14>
  %36 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> <i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394>) #5
  %37 = add <4 x i32> %36, <i32 8192, i32 8192, i32 8192, i32 8192>
  %38 = ashr <4 x i32> %37, <i32 14, i32 14, i32 14, i32 14>
  %39 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %35, <4 x i32> %38) #5
  %40 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %31, <8 x i16> <i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665>) #5
  %41 = add <4 x i32> %40, <i32 8192, i32 8192, i32 8192, i32 8192>
  %42 = ashr <4 x i32> %41, <i32 14, i32 14, i32 14, i32 14>
  %43 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> <i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665>) #5
  %44 = add <4 x i32> %43, <i32 8192, i32 8192, i32 8192, i32 8192>
  %45 = ashr <4 x i32> %44, <i32 14, i32 14, i32 14, i32 14>
  %46 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %42, <4 x i32> %45) #5
  %47 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %48 = bitcast <2 x i64>* %47 to <8 x i16>*
  %49 = load <8 x i16>, <8 x i16>* %48, align 16
  %50 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %51 = bitcast <2 x i64>* %50 to <8 x i16>*
  %52 = load <8 x i16>, <8 x i16>* %51, align 16
  %53 = shufflevector <8 x i16> %49, <8 x i16> %52, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %54 = shufflevector <8 x i16> %49, <8 x i16> %52, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %53, <8 x i16> <i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449>) #5
  %56 = add <4 x i32> %55, <i32 8192, i32 8192, i32 8192, i32 8192>
  %57 = ashr <4 x i32> %56, <i32 14, i32 14, i32 14, i32 14>
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %54, <8 x i16> <i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449>) #5
  %59 = add <4 x i32> %58, <i32 8192, i32 8192, i32 8192, i32 8192>
  %60 = ashr <4 x i32> %59, <i32 14, i32 14, i32 14, i32 14>
  %61 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %57, <4 x i32> %60) #5
  %62 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %53, <8 x i16> <i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723>) #5
  %63 = add <4 x i32> %62, <i32 8192, i32 8192, i32 8192, i32 8192>
  %64 = ashr <4 x i32> %63, <i32 14, i32 14, i32 14, i32 14>
  %65 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %54, <8 x i16> <i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723>) #5
  %66 = add <4 x i32> %65, <i32 8192, i32 8192, i32 8192, i32 8192>
  %67 = ashr <4 x i32> %66, <i32 14, i32 14, i32 14, i32 14>
  %68 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %64, <4 x i32> %67) #5
  %69 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %70 = bitcast <2 x i64>* %69 to <8 x i16>*
  %71 = load <8 x i16>, <8 x i16>* %70, align 16
  %72 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %73 = bitcast <2 x i64>* %72 to <8 x i16>*
  %74 = load <8 x i16>, <8 x i16>* %73, align 16
  %75 = shufflevector <8 x i16> %71, <8 x i16> %74, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %76 = shufflevector <8 x i16> %71, <8 x i16> %74, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %77 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %75, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #5
  %78 = add <4 x i32> %77, <i32 8192, i32 8192, i32 8192, i32 8192>
  %79 = ashr <4 x i32> %78, <i32 14, i32 14, i32 14, i32 14>
  %80 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %76, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #5
  %81 = add <4 x i32> %80, <i32 8192, i32 8192, i32 8192, i32 8192>
  %82 = ashr <4 x i32> %81, <i32 14, i32 14, i32 14, i32 14>
  %83 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %79, <4 x i32> %82) #5
  %84 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %75, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #5
  %85 = add <4 x i32> %84, <i32 8192, i32 8192, i32 8192, i32 8192>
  %86 = ashr <4 x i32> %85, <i32 14, i32 14, i32 14, i32 14>
  %87 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %76, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #5
  %88 = add <4 x i32> %87, <i32 8192, i32 8192, i32 8192, i32 8192>
  %89 = ashr <4 x i32> %88, <i32 14, i32 14, i32 14, i32 14>
  %90 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %86, <4 x i32> %89) #5
  %91 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %92 = bitcast <2 x i64>* %91 to <8 x i16>*
  %93 = load <8 x i16>, <8 x i16>* %92, align 16
  %94 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %95 = bitcast <2 x i64>* %94 to <8 x i16>*
  %96 = load <8 x i16>, <8 x i16>* %95, align 16
  %97 = shufflevector <8 x i16> %93, <8 x i16> %96, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %98 = shufflevector <8 x i16> %93, <8 x i16> %96, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %99 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %97, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #5
  %100 = add <4 x i32> %99, <i32 8192, i32 8192, i32 8192, i32 8192>
  %101 = ashr <4 x i32> %100, <i32 14, i32 14, i32 14, i32 14>
  %102 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %98, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #5
  %103 = add <4 x i32> %102, <i32 8192, i32 8192, i32 8192, i32 8192>
  %104 = ashr <4 x i32> %103, <i32 14, i32 14, i32 14, i32 14>
  %105 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %101, <4 x i32> %104) #5
  %106 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %97, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #5
  %107 = add <4 x i32> %106, <i32 8192, i32 8192, i32 8192, i32 8192>
  %108 = ashr <4 x i32> %107, <i32 14, i32 14, i32 14, i32 14>
  %109 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %98, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #5
  %110 = add <4 x i32> %109, <i32 8192, i32 8192, i32 8192, i32 8192>
  %111 = ashr <4 x i32> %110, <i32 14, i32 14, i32 14, i32 14>
  %112 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %108, <4 x i32> %111) #5
  %113 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %114 = bitcast <2 x i64>* %113 to <8 x i16>*
  %115 = load <8 x i16>, <8 x i16>* %114, align 16
  %116 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %117 = bitcast <2 x i64>* %116 to <8 x i16>*
  %118 = load <8 x i16>, <8 x i16>* %117, align 16
  %119 = shufflevector <8 x i16> %115, <8 x i16> %118, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %120 = shufflevector <8 x i16> %115, <8 x i16> %118, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %121 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %119, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #5
  %122 = add <4 x i32> %121, <i32 8192, i32 8192, i32 8192, i32 8192>
  %123 = ashr <4 x i32> %122, <i32 14, i32 14, i32 14, i32 14>
  %124 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %120, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #5
  %125 = add <4 x i32> %124, <i32 8192, i32 8192, i32 8192, i32 8192>
  %126 = ashr <4 x i32> %125, <i32 14, i32 14, i32 14, i32 14>
  %127 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %123, <4 x i32> %126) #5
  %128 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %119, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #5
  %129 = add <4 x i32> %128, <i32 8192, i32 8192, i32 8192, i32 8192>
  %130 = ashr <4 x i32> %129, <i32 14, i32 14, i32 14, i32 14>
  %131 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %120, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #5
  %132 = add <4 x i32> %131, <i32 8192, i32 8192, i32 8192, i32 8192>
  %133 = ashr <4 x i32> %132, <i32 14, i32 14, i32 14, i32 14>
  %134 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %130, <4 x i32> %133) #5
  %135 = add <8 x i16> %39, %17
  %136 = sub <8 x i16> %17, %39
  %137 = sub <8 x i16> %83, %61
  %138 = add <8 x i16> %83, %61
  %139 = add <8 x i16> %90, %68
  %140 = sub <8 x i16> %90, %68
  %141 = sub <8 x i16> %24, %46
  %142 = add <8 x i16> %46, %24
  %143 = bitcast <2 x i64>* %0 to <8 x i16>*
  %144 = load <8 x i16>, <8 x i16>* %143, align 16
  %145 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %146 = bitcast <2 x i64>* %145 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = shufflevector <8 x i16> %144, <8 x i16> %147, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %149 = shufflevector <8 x i16> %144, <8 x i16> %147, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %150 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %148, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %151 = add <4 x i32> %150, <i32 8192, i32 8192, i32 8192, i32 8192>
  %152 = ashr <4 x i32> %151, <i32 14, i32 14, i32 14, i32 14>
  %153 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %149, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %154 = add <4 x i32> %153, <i32 8192, i32 8192, i32 8192, i32 8192>
  %155 = ashr <4 x i32> %154, <i32 14, i32 14, i32 14, i32 14>
  %156 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %152, <4 x i32> %155) #5
  %157 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %148, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %158 = add <4 x i32> %157, <i32 8192, i32 8192, i32 8192, i32 8192>
  %159 = ashr <4 x i32> %158, <i32 14, i32 14, i32 14, i32 14>
  %160 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %149, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %161 = add <4 x i32> %160, <i32 8192, i32 8192, i32 8192, i32 8192>
  %162 = ashr <4 x i32> %161, <i32 14, i32 14, i32 14, i32 14>
  %163 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %159, <4 x i32> %162) #5
  %164 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %165 = bitcast <2 x i64>* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %168 = bitcast <2 x i64>* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = shufflevector <8 x i16> %166, <8 x i16> %169, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %171 = shufflevector <8 x i16> %166, <8 x i16> %169, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %172 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %170, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #5
  %173 = add <4 x i32> %172, <i32 8192, i32 8192, i32 8192, i32 8192>
  %174 = ashr <4 x i32> %173, <i32 14, i32 14, i32 14, i32 14>
  %175 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %171, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #5
  %176 = add <4 x i32> %175, <i32 8192, i32 8192, i32 8192, i32 8192>
  %177 = ashr <4 x i32> %176, <i32 14, i32 14, i32 14, i32 14>
  %178 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %174, <4 x i32> %177) #5
  %179 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %170, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #5
  %180 = add <4 x i32> %179, <i32 8192, i32 8192, i32 8192, i32 8192>
  %181 = ashr <4 x i32> %180, <i32 14, i32 14, i32 14, i32 14>
  %182 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %171, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #5
  %183 = add <4 x i32> %182, <i32 8192, i32 8192, i32 8192, i32 8192>
  %184 = ashr <4 x i32> %183, <i32 14, i32 14, i32 14, i32 14>
  %185 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %181, <4 x i32> %184) #5
  %186 = shufflevector <8 x i16> %141, <8 x i16> %136, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %187 = shufflevector <8 x i16> %141, <8 x i16> %136, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %188 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %186, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #5
  %189 = add <4 x i32> %188, <i32 8192, i32 8192, i32 8192, i32 8192>
  %190 = ashr <4 x i32> %189, <i32 14, i32 14, i32 14, i32 14>
  %191 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %187, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #5
  %192 = add <4 x i32> %191, <i32 8192, i32 8192, i32 8192, i32 8192>
  %193 = ashr <4 x i32> %192, <i32 14, i32 14, i32 14, i32 14>
  %194 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %190, <4 x i32> %193) #5
  %195 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %186, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #5
  %196 = add <4 x i32> %195, <i32 8192, i32 8192, i32 8192, i32 8192>
  %197 = ashr <4 x i32> %196, <i32 14, i32 14, i32 14, i32 14>
  %198 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %187, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #5
  %199 = add <4 x i32> %198, <i32 8192, i32 8192, i32 8192, i32 8192>
  %200 = ashr <4 x i32> %199, <i32 14, i32 14, i32 14, i32 14>
  %201 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %197, <4 x i32> %200) #5
  %202 = shufflevector <8 x i16> %137, <8 x i16> %140, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %203 = shufflevector <8 x i16> %137, <8 x i16> %140, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %204 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %202, <8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>) #5
  %205 = add <4 x i32> %204, <i32 8192, i32 8192, i32 8192, i32 8192>
  %206 = ashr <4 x i32> %205, <i32 14, i32 14, i32 14, i32 14>
  %207 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %203, <8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>) #5
  %208 = add <4 x i32> %207, <i32 8192, i32 8192, i32 8192, i32 8192>
  %209 = ashr <4 x i32> %208, <i32 14, i32 14, i32 14, i32 14>
  %210 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %206, <4 x i32> %209) #5
  %211 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %202, <8 x i16> <i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137>) #5
  %212 = add <4 x i32> %211, <i32 8192, i32 8192, i32 8192, i32 8192>
  %213 = ashr <4 x i32> %212, <i32 14, i32 14, i32 14, i32 14>
  %214 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %203, <8 x i16> <i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137>) #5
  %215 = add <4 x i32> %214, <i32 8192, i32 8192, i32 8192, i32 8192>
  %216 = ashr <4 x i32> %215, <i32 14, i32 14, i32 14, i32 14>
  %217 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %213, <4 x i32> %216) #5
  %218 = sub <8 x i16> %105, %127
  %219 = add <8 x i16> %127, %105
  %220 = sub <8 x i16> %112, %134
  %221 = add <8 x i16> %134, %112
  %222 = add <8 x i16> %185, %163
  %223 = add <8 x i16> %178, %156
  %224 = sub <8 x i16> %156, %178
  %225 = sub <8 x i16> %163, %185
  %226 = shufflevector <8 x i16> %220, <8 x i16> %218, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %227 = shufflevector <8 x i16> %220, <8 x i16> %218, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %228 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %226, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %229 = add <4 x i32> %228, <i32 8192, i32 8192, i32 8192, i32 8192>
  %230 = ashr <4 x i32> %229, <i32 14, i32 14, i32 14, i32 14>
  %231 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %227, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %232 = add <4 x i32> %231, <i32 8192, i32 8192, i32 8192, i32 8192>
  %233 = ashr <4 x i32> %232, <i32 14, i32 14, i32 14, i32 14>
  %234 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %230, <4 x i32> %233) #5
  %235 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %226, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %236 = add <4 x i32> %235, <i32 8192, i32 8192, i32 8192, i32 8192>
  %237 = ashr <4 x i32> %236, <i32 14, i32 14, i32 14, i32 14>
  %238 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %227, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %239 = add <4 x i32> %238, <i32 8192, i32 8192, i32 8192, i32 8192>
  %240 = ashr <4 x i32> %239, <i32 14, i32 14, i32 14, i32 14>
  %241 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %237, <4 x i32> %240) #5
  %242 = add <8 x i16> %138, %135
  %243 = add <8 x i16> %217, %194
  %244 = sub <8 x i16> %194, %217
  %245 = sub <8 x i16> %135, %138
  %246 = sub <8 x i16> %142, %139
  %247 = sub <8 x i16> %201, %210
  %248 = add <8 x i16> %210, %201
  %249 = add <8 x i16> %139, %142
  %250 = add <8 x i16> %222, %221
  %251 = add <8 x i16> %241, %223
  %252 = add <8 x i16> %234, %224
  %253 = add <8 x i16> %225, %219
  %254 = sub <8 x i16> %225, %219
  %255 = sub <8 x i16> %224, %234
  %256 = sub <8 x i16> %223, %241
  %257 = sub <8 x i16> %222, %221
  %258 = shufflevector <8 x i16> %247, <8 x i16> %244, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %259 = shufflevector <8 x i16> %247, <8 x i16> %244, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %260 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %258, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %261 = add <4 x i32> %260, <i32 8192, i32 8192, i32 8192, i32 8192>
  %262 = ashr <4 x i32> %261, <i32 14, i32 14, i32 14, i32 14>
  %263 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %259, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %264 = add <4 x i32> %263, <i32 8192, i32 8192, i32 8192, i32 8192>
  %265 = ashr <4 x i32> %264, <i32 14, i32 14, i32 14, i32 14>
  %266 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %262, <4 x i32> %265) #5
  %267 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %258, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %268 = add <4 x i32> %267, <i32 8192, i32 8192, i32 8192, i32 8192>
  %269 = ashr <4 x i32> %268, <i32 14, i32 14, i32 14, i32 14>
  %270 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %259, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %271 = add <4 x i32> %270, <i32 8192, i32 8192, i32 8192, i32 8192>
  %272 = ashr <4 x i32> %271, <i32 14, i32 14, i32 14, i32 14>
  %273 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %269, <4 x i32> %272) #5
  %274 = shufflevector <8 x i16> %246, <8 x i16> %245, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %275 = shufflevector <8 x i16> %246, <8 x i16> %245, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %274, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %277 = add <4 x i32> %276, <i32 8192, i32 8192, i32 8192, i32 8192>
  %278 = ashr <4 x i32> %277, <i32 14, i32 14, i32 14, i32 14>
  %279 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %275, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %280 = add <4 x i32> %279, <i32 8192, i32 8192, i32 8192, i32 8192>
  %281 = ashr <4 x i32> %280, <i32 14, i32 14, i32 14, i32 14>
  %282 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %278, <4 x i32> %281) #5
  %283 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %274, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %284 = add <4 x i32> %283, <i32 8192, i32 8192, i32 8192, i32 8192>
  %285 = ashr <4 x i32> %284, <i32 14, i32 14, i32 14, i32 14>
  %286 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %275, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %287 = add <4 x i32> %286, <i32 8192, i32 8192, i32 8192, i32 8192>
  %288 = ashr <4 x i32> %287, <i32 14, i32 14, i32 14, i32 14>
  %289 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %285, <4 x i32> %288) #5
  %290 = add <8 x i16> %250, %249
  %291 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %290, <8 x i16>* %291, align 16
  %292 = add <8 x i16> %251, %248
  %293 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %294 = bitcast <2 x i64>* %293 to <8 x i16>*
  store <8 x i16> %292, <8 x i16>* %294, align 16
  %295 = add <8 x i16> %273, %252
  %296 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %297 = bitcast <2 x i64>* %296 to <8 x i16>*
  store <8 x i16> %295, <8 x i16>* %297, align 16
  %298 = add <8 x i16> %289, %253
  %299 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %300 = bitcast <2 x i64>* %299 to <8 x i16>*
  store <8 x i16> %298, <8 x i16>* %300, align 16
  %301 = add <8 x i16> %282, %254
  %302 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %303 = bitcast <2 x i64>* %302 to <8 x i16>*
  store <8 x i16> %301, <8 x i16>* %303, align 16
  %304 = add <8 x i16> %266, %255
  %305 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %306 = bitcast <2 x i64>* %305 to <8 x i16>*
  store <8 x i16> %304, <8 x i16>* %306, align 16
  %307 = add <8 x i16> %256, %243
  %308 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %309 = bitcast <2 x i64>* %308 to <8 x i16>*
  store <8 x i16> %307, <8 x i16>* %309, align 16
  %310 = add <8 x i16> %257, %242
  %311 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %312 = bitcast <2 x i64>* %311 to <8 x i16>*
  store <8 x i16> %310, <8 x i16>* %312, align 16
  %313 = sub <8 x i16> %257, %242
  %314 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %315 = bitcast <2 x i64>* %314 to <8 x i16>*
  store <8 x i16> %313, <8 x i16>* %315, align 16
  %316 = sub <8 x i16> %256, %243
  %317 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %318 = bitcast <2 x i64>* %317 to <8 x i16>*
  store <8 x i16> %316, <8 x i16>* %318, align 16
  %319 = sub <8 x i16> %255, %266
  %320 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %321 = bitcast <2 x i64>* %320 to <8 x i16>*
  store <8 x i16> %319, <8 x i16>* %321, align 16
  %322 = sub <8 x i16> %254, %282
  %323 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %324 = bitcast <2 x i64>* %323 to <8 x i16>*
  store <8 x i16> %322, <8 x i16>* %324, align 16
  %325 = sub <8 x i16> %253, %289
  %326 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %327 = bitcast <2 x i64>* %326 to <8 x i16>*
  store <8 x i16> %325, <8 x i16>* %327, align 16
  %328 = sub <8 x i16> %252, %273
  %329 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %330 = bitcast <2 x i64>* %329 to <8 x i16>*
  store <8 x i16> %328, <8 x i16>* %330, align 16
  %331 = sub <8 x i16> %251, %248
  %332 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %333 = bitcast <2 x i64>* %332 to <8 x i16>*
  store <8 x i16> %331, <8 x i16>* %333, align 16
  %334 = sub <8 x i16> %250, %249
  %335 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %336 = bitcast <2 x i64>* %335 to <8 x i16>*
  store <8 x i16> %334, <8 x i16>* %336, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_highbd_idct16x16_38_add_sse4_1(i32* nocapture readonly, i16* nocapture, i32, i32) local_unnamed_addr #0 {
  %5 = alloca [16 x <2 x i64>], align 16
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = alloca [16 x <2 x i64>], align 16
  %8 = alloca [2 x [16 x <2 x i64>]], align 16
  %9 = bitcast [16 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %9) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 256, i1 false)
  %10 = icmp eq i32 %3, 8
  br i1 %10, label %11, label %230

11:                                               ; preds = %4
  %12 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %12) #5
  %13 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %14 = bitcast <2 x i64>* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 144, i1 false)
  %15 = bitcast [16 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %15) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %15, i8 -86, i64 256, i1 false)
  %16 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %17 = bitcast i32* %0 to <4 x i32>*
  %18 = load <4 x i32>, <4 x i32>* %17, align 16
  %19 = getelementptr inbounds i32, i32* %0, i64 4
  %20 = bitcast i32* %19 to <4 x i32>*
  %21 = load <4 x i32>, <4 x i32>* %20, align 16
  %22 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %18, <4 x i32> %21) #5
  %23 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  store <8 x i16> %22, <8 x i16>* %23, align 16
  %24 = getelementptr inbounds i32, i32* %0, i64 16
  %25 = bitcast i32* %24 to <4 x i32>*
  %26 = load <4 x i32>, <4 x i32>* %25, align 16
  %27 = getelementptr inbounds i32, i32* %0, i64 20
  %28 = bitcast i32* %27 to <4 x i32>*
  %29 = load <4 x i32>, <4 x i32>* %28, align 16
  %30 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %26, <4 x i32> %29) #5
  %31 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %32 = getelementptr inbounds i32, i32* %0, i64 32
  %33 = bitcast i32* %32 to <4 x i32>*
  %34 = load <4 x i32>, <4 x i32>* %33, align 16
  %35 = getelementptr inbounds i32, i32* %0, i64 36
  %36 = bitcast i32* %35 to <4 x i32>*
  %37 = load <4 x i32>, <4 x i32>* %36, align 16
  %38 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %34, <4 x i32> %37) #5
  %39 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %40 = getelementptr inbounds i32, i32* %0, i64 48
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 16
  %43 = getelementptr inbounds i32, i32* %0, i64 52
  %44 = bitcast i32* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 16
  %46 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %42, <4 x i32> %45) #5
  %47 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %48 = getelementptr inbounds i32, i32* %0, i64 64
  %49 = bitcast i32* %48 to <4 x i32>*
  %50 = load <4 x i32>, <4 x i32>* %49, align 16
  %51 = getelementptr inbounds i32, i32* %0, i64 68
  %52 = bitcast i32* %51 to <4 x i32>*
  %53 = load <4 x i32>, <4 x i32>* %52, align 16
  %54 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %50, <4 x i32> %53) #5
  %55 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %56 = getelementptr inbounds i32, i32* %0, i64 80
  %57 = bitcast i32* %56 to <4 x i32>*
  %58 = load <4 x i32>, <4 x i32>* %57, align 16
  %59 = getelementptr inbounds i32, i32* %0, i64 84
  %60 = bitcast i32* %59 to <4 x i32>*
  %61 = load <4 x i32>, <4 x i32>* %60, align 16
  %62 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %58, <4 x i32> %61) #5
  %63 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %64 = getelementptr inbounds i32, i32* %0, i64 96
  %65 = bitcast i32* %64 to <4 x i32>*
  %66 = load <4 x i32>, <4 x i32>* %65, align 16
  %67 = getelementptr inbounds i32, i32* %0, i64 100
  %68 = bitcast i32* %67 to <4 x i32>*
  %69 = load <4 x i32>, <4 x i32>* %68, align 16
  %70 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %66, <4 x i32> %69) #5
  %71 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %72 = getelementptr inbounds i32, i32* %0, i64 112
  %73 = bitcast i32* %72 to <4 x i32>*
  %74 = load <4 x i32>, <4 x i32>* %73, align 16
  %75 = getelementptr inbounds i32, i32* %0, i64 116
  %76 = bitcast i32* %75 to <4 x i32>*
  %77 = load <4 x i32>, <4 x i32>* %76, align 16
  %78 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %74, <4 x i32> %77) #5
  %79 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %80 = shufflevector <8 x i16> %22, <8 x i16> %30, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %81 = shufflevector <8 x i16> %38, <8 x i16> %46, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %82 = shufflevector <8 x i16> %54, <8 x i16> %62, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %83 = shufflevector <8 x i16> %70, <8 x i16> %78, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %84 = shufflevector <8 x i16> %22, <8 x i16> %30, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %85 = shufflevector <8 x i16> %38, <8 x i16> %46, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %86 = shufflevector <8 x i16> %54, <8 x i16> %62, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %87 = shufflevector <8 x i16> %70, <8 x i16> %78, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %88 = bitcast <8 x i16> %80 to <4 x i32>
  %89 = bitcast <8 x i16> %81 to <4 x i32>
  %90 = shufflevector <4 x i32> %88, <4 x i32> %89, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %91 = bitcast <4 x i32> %90 to <2 x i64>
  %92 = bitcast <8 x i16> %82 to <4 x i32>
  %93 = bitcast <8 x i16> %83 to <4 x i32>
  %94 = shufflevector <4 x i32> %92, <4 x i32> %93, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %95 = bitcast <4 x i32> %94 to <2 x i64>
  %96 = bitcast <8 x i16> %84 to <4 x i32>
  %97 = bitcast <8 x i16> %85 to <4 x i32>
  %98 = shufflevector <4 x i32> %96, <4 x i32> %97, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %99 = bitcast <4 x i32> %98 to <2 x i64>
  %100 = bitcast <8 x i16> %86 to <4 x i32>
  %101 = bitcast <8 x i16> %87 to <4 x i32>
  %102 = shufflevector <4 x i32> %100, <4 x i32> %101, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %103 = bitcast <4 x i32> %102 to <2 x i64>
  %104 = shufflevector <4 x i32> %88, <4 x i32> %89, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %105 = bitcast <4 x i32> %104 to <2 x i64>
  %106 = shufflevector <4 x i32> %92, <4 x i32> %93, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %107 = bitcast <4 x i32> %106 to <2 x i64>
  %108 = shufflevector <4 x i32> %96, <4 x i32> %97, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %109 = bitcast <4 x i32> %108 to <2 x i64>
  %110 = shufflevector <4 x i32> %100, <4 x i32> %101, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %111 = bitcast <4 x i32> %110 to <2 x i64>
  %112 = shufflevector <2 x i64> %91, <2 x i64> %95, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %112, <2 x i64>* %16, align 16
  %113 = shufflevector <2 x i64> %91, <2 x i64> %95, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %113, <2 x i64>* %31, align 16
  %114 = shufflevector <2 x i64> %105, <2 x i64> %107, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %114, <2 x i64>* %39, align 16
  %115 = shufflevector <2 x i64> %105, <2 x i64> %107, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %115, <2 x i64>* %47, align 16
  %116 = shufflevector <2 x i64> %99, <2 x i64> %103, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %116, <2 x i64>* %55, align 16
  %117 = shufflevector <2 x i64> %99, <2 x i64> %103, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %117, <2 x i64>* %63, align 16
  %118 = shufflevector <2 x i64> %109, <2 x i64> %111, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %118, <2 x i64>* %71, align 16
  %119 = shufflevector <2 x i64> %109, <2 x i64> %111, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %119, <2 x i64>* %79, align 16
  %120 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %121 = bitcast <2 x i64>* %120 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %121, i8 0, i64 128, i1 false)
  %122 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  call fastcc void @idct16_8col(<2 x i64>* nonnull %16, <2 x i64>* nonnull %122)
  %123 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 0
  %124 = sext i32 %2 to i64
  br label %125

125:                                              ; preds = %11, %225
  %126 = phi i64 [ 0, %11 ], [ %227, %225 ]
  %127 = phi i16* [ %1, %11 ], [ %226, %225 ]
  %128 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 %126
  %129 = bitcast <2 x i64>* %128 to <8 x i16>*
  %130 = load <8 x i16>, <8 x i16>* %129, align 16
  %131 = getelementptr inbounds <2 x i64>, <2 x i64>* %128, i64 1
  %132 = bitcast <2 x i64>* %131 to <8 x i16>*
  %133 = load <8 x i16>, <8 x i16>* %132, align 16
  %134 = shufflevector <8 x i16> %130, <8 x i16> %133, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %135 = getelementptr inbounds <2 x i64>, <2 x i64>* %128, i64 2
  %136 = bitcast <2 x i64>* %135 to <8 x i16>*
  %137 = load <8 x i16>, <8 x i16>* %136, align 16
  %138 = getelementptr inbounds <2 x i64>, <2 x i64>* %128, i64 3
  %139 = bitcast <2 x i64>* %138 to <8 x i16>*
  %140 = load <8 x i16>, <8 x i16>* %139, align 16
  %141 = shufflevector <8 x i16> %137, <8 x i16> %140, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %142 = getelementptr inbounds <2 x i64>, <2 x i64>* %128, i64 4
  %143 = bitcast <2 x i64>* %142 to <8 x i16>*
  %144 = load <8 x i16>, <8 x i16>* %143, align 16
  %145 = getelementptr inbounds <2 x i64>, <2 x i64>* %128, i64 5
  %146 = bitcast <2 x i64>* %145 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = shufflevector <8 x i16> %144, <8 x i16> %147, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %149 = getelementptr inbounds <2 x i64>, <2 x i64>* %128, i64 6
  %150 = bitcast <2 x i64>* %149 to <8 x i16>*
  %151 = load <8 x i16>, <8 x i16>* %150, align 16
  %152 = getelementptr inbounds <2 x i64>, <2 x i64>* %128, i64 7
  %153 = bitcast <2 x i64>* %152 to <8 x i16>*
  %154 = load <8 x i16>, <8 x i16>* %153, align 16
  %155 = shufflevector <8 x i16> %151, <8 x i16> %154, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %156 = shufflevector <8 x i16> %130, <8 x i16> %133, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %157 = shufflevector <8 x i16> %137, <8 x i16> %140, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %158 = shufflevector <8 x i16> %144, <8 x i16> %147, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %159 = shufflevector <8 x i16> %151, <8 x i16> %154, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %160 = bitcast <8 x i16> %134 to <4 x i32>
  %161 = bitcast <8 x i16> %141 to <4 x i32>
  %162 = shufflevector <4 x i32> %160, <4 x i32> %161, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %163 = bitcast <4 x i32> %162 to <2 x i64>
  %164 = bitcast <8 x i16> %148 to <4 x i32>
  %165 = bitcast <8 x i16> %155 to <4 x i32>
  %166 = shufflevector <4 x i32> %164, <4 x i32> %165, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %167 = bitcast <4 x i32> %166 to <2 x i64>
  %168 = bitcast <8 x i16> %156 to <4 x i32>
  %169 = bitcast <8 x i16> %157 to <4 x i32>
  %170 = shufflevector <4 x i32> %168, <4 x i32> %169, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %171 = bitcast <4 x i32> %170 to <2 x i64>
  %172 = bitcast <8 x i16> %158 to <4 x i32>
  %173 = bitcast <8 x i16> %159 to <4 x i32>
  %174 = shufflevector <4 x i32> %172, <4 x i32> %173, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %175 = bitcast <4 x i32> %174 to <2 x i64>
  %176 = shufflevector <4 x i32> %160, <4 x i32> %161, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %177 = bitcast <4 x i32> %176 to <2 x i64>
  %178 = shufflevector <4 x i32> %164, <4 x i32> %165, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %179 = bitcast <4 x i32> %178 to <2 x i64>
  %180 = shufflevector <4 x i32> %168, <4 x i32> %169, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %181 = bitcast <4 x i32> %180 to <2 x i64>
  %182 = shufflevector <4 x i32> %172, <4 x i32> %173, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %183 = bitcast <4 x i32> %182 to <2 x i64>
  %184 = shufflevector <2 x i64> %163, <2 x i64> %167, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %184, <2 x i64>* %16, align 16
  %185 = shufflevector <2 x i64> %163, <2 x i64> %167, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %185, <2 x i64>* %31, align 16
  %186 = shufflevector <2 x i64> %177, <2 x i64> %179, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %186, <2 x i64>* %39, align 16
  %187 = shufflevector <2 x i64> %177, <2 x i64> %179, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %187, <2 x i64>* %47, align 16
  %188 = shufflevector <2 x i64> %171, <2 x i64> %175, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %188, <2 x i64>* %55, align 16
  %189 = shufflevector <2 x i64> %171, <2 x i64> %175, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %189, <2 x i64>* %63, align 16
  %190 = shufflevector <2 x i64> %181, <2 x i64> %183, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %190, <2 x i64>* %71, align 16
  %191 = shufflevector <2 x i64> %181, <2 x i64> %183, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %191, <2 x i64>* %79, align 16
  call fastcc void @idct16_8col(<2 x i64>* nonnull %16, <2 x i64>* nonnull %123)
  br label %192

192:                                              ; preds = %192, %125
  %193 = phi i64 [ 0, %125 ], [ %223, %192 ]
  %194 = mul nsw i64 %193, %124
  %195 = getelementptr inbounds i16, i16* %127, i64 %194
  %196 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %193
  %197 = bitcast <2 x i64>* %196 to <8 x i16>*
  %198 = load <8 x i16>, <8 x i16>* %197, align 16
  %199 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %198, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %200 = ashr <8 x i16> %199, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %201 = bitcast i16* %195 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %202, <8 x i16> %200) #5
  %204 = icmp sgt <8 x i16> %203, zeroinitializer
  %205 = select <8 x i1> %204, <8 x i16> %203, <8 x i16> zeroinitializer
  %206 = icmp slt <8 x i16> %205, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %207 = select <8 x i1> %206, <8 x i16> %205, <8 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  store <8 x i16> %207, <8 x i16>* %201, align 16
  %208 = or i64 %193, 1
  %209 = mul nsw i64 %208, %124
  %210 = getelementptr inbounds i16, i16* %127, i64 %209
  %211 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %208
  %212 = bitcast <2 x i64>* %211 to <8 x i16>*
  %213 = load <8 x i16>, <8 x i16>* %212, align 16
  %214 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %213, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %215 = ashr <8 x i16> %214, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %216 = bitcast i16* %210 to <8 x i16>*
  %217 = load <8 x i16>, <8 x i16>* %216, align 16
  %218 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %217, <8 x i16> %215) #5
  %219 = icmp sgt <8 x i16> %218, zeroinitializer
  %220 = select <8 x i1> %219, <8 x i16> %218, <8 x i16> zeroinitializer
  %221 = icmp slt <8 x i16> %220, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %222 = select <8 x i1> %221, <8 x i16> %220, <8 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  store <8 x i16> %222, <8 x i16>* %216, align 16
  %223 = add nuw nsw i64 %193, 2
  %224 = icmp eq i64 %223, 16
  br i1 %224, label %225, label %192

225:                                              ; preds = %192
  %226 = getelementptr inbounds i16, i16* %127, i64 8
  %227 = add nuw nsw i64 %126, 8
  %228 = icmp ult i64 %227, 16
  br i1 %228, label %125, label %229

229:                                              ; preds = %225
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %15) #5
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %12) #5
  br label %391

230:                                              ; preds = %4
  %231 = bitcast [2 x [16 x <2 x i64>]]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %231) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %231, i8 -86, i64 512, i1 false)
  br label %242

232:                                              ; preds = %242
  %233 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 0
  %234 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 1
  %235 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 2
  %236 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 3
  %237 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 4
  %238 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 5
  %239 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 6
  %240 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 7
  %241 = sext i32 %2 to i64
  br label %310

242:                                              ; preds = %242, %230
  %243 = phi i64 [ 0, %230 ], [ %308, %242 ]
  %244 = phi i32* [ %0, %230 ], [ %307, %242 ]
  %245 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 %243, i64 0
  %246 = bitcast i32* %244 to <2 x i64>*
  %247 = load <2 x i64>, <2 x i64>* %246, align 16
  store <2 x i64> %247, <2 x i64>* %245, align 16
  %248 = getelementptr inbounds i32, i32* %244, i64 4
  %249 = bitcast i32* %248 to <2 x i64>*
  %250 = load <2 x i64>, <2 x i64>* %249, align 16
  %251 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 %243, i64 1
  store <2 x i64> %250, <2 x i64>* %251, align 16
  %252 = getelementptr inbounds i32, i32* %244, i64 16
  %253 = bitcast i32* %252 to <2 x i64>*
  %254 = load <2 x i64>, <2 x i64>* %253, align 16
  %255 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 %243, i64 2
  store <2 x i64> %254, <2 x i64>* %255, align 16
  %256 = getelementptr inbounds i32, i32* %244, i64 20
  %257 = bitcast i32* %256 to <2 x i64>*
  %258 = load <2 x i64>, <2 x i64>* %257, align 16
  %259 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 %243, i64 3
  store <2 x i64> %258, <2 x i64>* %259, align 16
  %260 = getelementptr inbounds i32, i32* %244, i64 32
  %261 = bitcast i32* %260 to <2 x i64>*
  %262 = load <2 x i64>, <2 x i64>* %261, align 16
  %263 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 %243, i64 4
  store <2 x i64> %262, <2 x i64>* %263, align 16
  %264 = getelementptr inbounds i32, i32* %244, i64 36
  %265 = bitcast i32* %264 to <2 x i64>*
  %266 = load <2 x i64>, <2 x i64>* %265, align 16
  %267 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 %243, i64 5
  store <2 x i64> %266, <2 x i64>* %267, align 16
  %268 = getelementptr inbounds i32, i32* %244, i64 48
  %269 = bitcast i32* %268 to <2 x i64>*
  %270 = load <2 x i64>, <2 x i64>* %269, align 16
  %271 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 %243, i64 6
  store <2 x i64> %270, <2 x i64>* %271, align 16
  %272 = getelementptr inbounds i32, i32* %244, i64 52
  %273 = bitcast i32* %272 to <4 x i32>*
  %274 = load <4 x i32>, <4 x i32>* %273, align 16
  %275 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 %243, i64 7
  %276 = bitcast <2 x i64> %247 to <4 x i32>
  %277 = bitcast <2 x i64> %254 to <4 x i32>
  %278 = shufflevector <4 x i32> %276, <4 x i32> %277, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %279 = bitcast <4 x i32> %278 to <2 x i64>
  %280 = bitcast <2 x i64> %262 to <4 x i32>
  %281 = bitcast <2 x i64> %270 to <4 x i32>
  %282 = shufflevector <4 x i32> %280, <4 x i32> %281, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %283 = bitcast <4 x i32> %282 to <2 x i64>
  %284 = shufflevector <4 x i32> %276, <4 x i32> %277, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %285 = bitcast <4 x i32> %284 to <2 x i64>
  %286 = shufflevector <4 x i32> %280, <4 x i32> %281, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %287 = bitcast <4 x i32> %286 to <2 x i64>
  %288 = bitcast <2 x i64> %250 to <4 x i32>
  %289 = bitcast <2 x i64> %258 to <4 x i32>
  %290 = shufflevector <4 x i32> %288, <4 x i32> %289, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %291 = bitcast <4 x i32> %290 to <2 x i64>
  %292 = bitcast <2 x i64> %266 to <4 x i32>
  %293 = shufflevector <4 x i32> %292, <4 x i32> %274, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %294 = bitcast <4 x i32> %293 to <2 x i64>
  %295 = shufflevector <4 x i32> %288, <4 x i32> %289, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %296 = bitcast <4 x i32> %295 to <2 x i64>
  %297 = shufflevector <4 x i32> %292, <4 x i32> %274, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %298 = bitcast <4 x i32> %297 to <2 x i64>
  %299 = shufflevector <2 x i64> %279, <2 x i64> %283, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %299, <2 x i64>* %245, align 16
  %300 = shufflevector <2 x i64> %279, <2 x i64> %283, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %300, <2 x i64>* %251, align 16
  %301 = shufflevector <2 x i64> %285, <2 x i64> %287, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %301, <2 x i64>* %255, align 16
  %302 = shufflevector <2 x i64> %285, <2 x i64> %287, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %302, <2 x i64>* %259, align 16
  %303 = shufflevector <2 x i64> %291, <2 x i64> %294, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %303, <2 x i64>* %263, align 16
  %304 = shufflevector <2 x i64> %291, <2 x i64> %294, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %304, <2 x i64>* %267, align 16
  %305 = shufflevector <2 x i64> %296, <2 x i64> %298, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %305, <2 x i64>* %271, align 16
  %306 = shufflevector <2 x i64> %296, <2 x i64> %298, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %306, <2 x i64>* %275, align 16
  call fastcc void @highbd_idct16x16_38_4col(<2 x i64>* %245)
  %307 = getelementptr inbounds i32, i32* %244, i64 64
  %308 = add nuw nsw i64 %243, 1
  %309 = icmp eq i64 %308, 2
  br i1 %309, label %232, label %242

310:                                              ; preds = %232, %386
  %311 = phi i64 [ 0, %232 ], [ %388, %386 ]
  %312 = phi i16* [ %1, %232 ], [ %387, %386 ]
  %313 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 0, i64 %311
  %314 = bitcast <2 x i64>* %313 to <4 x i32>*
  %315 = load <4 x i32>, <4 x i32>* %314, align 16
  %316 = getelementptr inbounds <2 x i64>, <2 x i64>* %313, i64 1
  %317 = bitcast <2 x i64>* %316 to <4 x i32>*
  %318 = load <4 x i32>, <4 x i32>* %317, align 16
  %319 = shufflevector <4 x i32> %315, <4 x i32> %318, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %320 = bitcast <4 x i32> %319 to <2 x i64>
  %321 = getelementptr inbounds <2 x i64>, <2 x i64>* %313, i64 2
  %322 = bitcast <2 x i64>* %321 to <4 x i32>*
  %323 = load <4 x i32>, <4 x i32>* %322, align 16
  %324 = getelementptr inbounds <2 x i64>, <2 x i64>* %313, i64 3
  %325 = bitcast <2 x i64>* %324 to <4 x i32>*
  %326 = load <4 x i32>, <4 x i32>* %325, align 16
  %327 = shufflevector <4 x i32> %323, <4 x i32> %326, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %328 = bitcast <4 x i32> %327 to <2 x i64>
  %329 = shufflevector <4 x i32> %315, <4 x i32> %318, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %330 = bitcast <4 x i32> %329 to <2 x i64>
  %331 = shufflevector <4 x i32> %323, <4 x i32> %326, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %332 = bitcast <4 x i32> %331 to <2 x i64>
  %333 = shufflevector <2 x i64> %320, <2 x i64> %328, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %333, <2 x i64>* %233, align 16
  %334 = shufflevector <2 x i64> %320, <2 x i64> %328, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %334, <2 x i64>* %234, align 16
  %335 = shufflevector <2 x i64> %330, <2 x i64> %332, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %335, <2 x i64>* %235, align 16
  %336 = shufflevector <2 x i64> %330, <2 x i64> %332, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %336, <2 x i64>* %236, align 16
  %337 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 1, i64 %311
  %338 = bitcast <2 x i64>* %337 to <4 x i32>*
  %339 = load <4 x i32>, <4 x i32>* %338, align 16
  %340 = getelementptr inbounds <2 x i64>, <2 x i64>* %337, i64 1
  %341 = bitcast <2 x i64>* %340 to <4 x i32>*
  %342 = load <4 x i32>, <4 x i32>* %341, align 16
  %343 = shufflevector <4 x i32> %339, <4 x i32> %342, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %344 = bitcast <4 x i32> %343 to <2 x i64>
  %345 = getelementptr inbounds <2 x i64>, <2 x i64>* %337, i64 2
  %346 = bitcast <2 x i64>* %345 to <4 x i32>*
  %347 = load <4 x i32>, <4 x i32>* %346, align 16
  %348 = getelementptr inbounds <2 x i64>, <2 x i64>* %337, i64 3
  %349 = bitcast <2 x i64>* %348 to <4 x i32>*
  %350 = load <4 x i32>, <4 x i32>* %349, align 16
  %351 = shufflevector <4 x i32> %347, <4 x i32> %350, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %352 = bitcast <4 x i32> %351 to <2 x i64>
  %353 = shufflevector <4 x i32> %339, <4 x i32> %342, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %354 = bitcast <4 x i32> %353 to <2 x i64>
  %355 = shufflevector <4 x i32> %347, <4 x i32> %350, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %356 = bitcast <4 x i32> %355 to <2 x i64>
  %357 = shufflevector <2 x i64> %344, <2 x i64> %352, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %357, <2 x i64>* %237, align 16
  %358 = shufflevector <2 x i64> %344, <2 x i64> %352, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %358, <2 x i64>* %238, align 16
  %359 = shufflevector <2 x i64> %354, <2 x i64> %356, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %359, <2 x i64>* %239, align 16
  %360 = shufflevector <2 x i64> %354, <2 x i64> %356, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %360, <2 x i64>* %240, align 16
  call fastcc void @highbd_idct16x16_38_4col(<2 x i64>* nonnull %233)
  %361 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %3) #5
  %362 = add <8 x i16> %361, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  br label %363

363:                                              ; preds = %363, %310
  %364 = phi i64 [ 0, %310 ], [ %384, %363 ]
  %365 = mul nsw i64 %364, %241
  %366 = getelementptr inbounds i16, i16* %312, i64 %365
  %367 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %364
  %368 = bitcast <2 x i64>* %367 to <4 x i32>*
  %369 = load <4 x i32>, <4 x i32>* %368, align 16
  %370 = add <4 x i32> %369, <i32 32, i32 32, i32 32, i32 32>
  %371 = ashr <4 x i32> %370, <i32 6, i32 6, i32 6, i32 6>
  %372 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %371, <4 x i32> %371) #5
  %373 = bitcast i16* %366 to i64*
  %374 = load i64, i64* %373, align 1
  %375 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %374, i32 0
  %376 = bitcast <2 x i64> %375 to <8 x i16>
  %377 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %376, <8 x i16> %372) #5
  %378 = icmp sgt <8 x i16> %377, zeroinitializer
  %379 = select <8 x i1> %378, <8 x i16> %377, <8 x i16> zeroinitializer
  %380 = icmp slt <8 x i16> %379, %362
  %381 = select <8 x i1> %380, <8 x i16> %379, <8 x i16> %362
  %382 = bitcast <8 x i16> %381 to <2 x i64>
  %383 = extractelement <2 x i64> %382, i32 0
  store i64 %383, i64* %373, align 1
  %384 = add nuw nsw i64 %364, 1
  %385 = icmp eq i64 %384, 16
  br i1 %385, label %386, label %363

386:                                              ; preds = %363
  %387 = getelementptr inbounds i16, i16* %312, i64 4
  %388 = add nuw nsw i64 %311, 4
  %389 = icmp ult i64 %388, 16
  br i1 %389, label %310, label %390

390:                                              ; preds = %386
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %231) #5
  br label %391

391:                                              ; preds = %390, %229
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %9) #5
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define internal fastcc void @highbd_idct16x16_38_4col(<2 x i64>*) unnamed_addr #2 {
  %2 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %3 = bitcast <2 x i64>* %2 to <4 x i32>*
  %4 = load <4 x i32>, <4 x i32>* %3, align 16
  %5 = shufflevector <4 x i32> %4, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %6 = bitcast <4 x i32> %5 to <2 x i64>
  %7 = shufflevector <4 x i32> %4, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %8 = bitcast <4 x i32> %7 to <2 x i64>
  %9 = shl <2 x i64> %6, <i64 32, i64 32>
  %10 = ashr exact <2 x i64> %9, <i64 32, i64 32>
  %11 = mul nsw <2 x i64> %10, <i64 6424, i64 6424>
  %12 = shl <2 x i64> %8, <i64 32, i64 32>
  %13 = ashr exact <2 x i64> %12, <i64 32, i64 32>
  %14 = mul nsw <2 x i64> %13, <i64 6424, i64 6424>
  %15 = add nsw <2 x i64> %11, <i64 32768, i64 32768>
  %16 = bitcast <2 x i64> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %18 = add nsw <2 x i64> %14, <i64 32768, i64 32768>
  %19 = bitcast <2 x i64> %18 to <16 x i8>
  %20 = shufflevector <16 x i8> %19, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %21 = bitcast <16 x i8> %17 to <4 x i32>
  %22 = bitcast <16 x i8> %20 to <4 x i32>
  %23 = shufflevector <4 x i32> %21, <4 x i32> %22, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %24 = shufflevector <4 x i32> %21, <4 x i32> %22, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %25 = shufflevector <4 x i32> %23, <4 x i32> %24, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %26 = mul nsw <2 x i64> %10, <i64 65220, i64 65220>
  %27 = mul nsw <2 x i64> %13, <i64 65220, i64 65220>
  %28 = add nsw <2 x i64> %26, <i64 32768, i64 32768>
  %29 = bitcast <2 x i64> %28 to <16 x i8>
  %30 = shufflevector <16 x i8> %29, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %31 = add nsw <2 x i64> %27, <i64 32768, i64 32768>
  %32 = bitcast <2 x i64> %31 to <16 x i8>
  %33 = shufflevector <16 x i8> %32, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %34 = bitcast <16 x i8> %30 to <4 x i32>
  %35 = bitcast <16 x i8> %33 to <4 x i32>
  %36 = shufflevector <4 x i32> %34, <4 x i32> %35, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %37 = shufflevector <4 x i32> %34, <4 x i32> %35, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %38 = shufflevector <4 x i32> %36, <4 x i32> %37, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %39 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %40 = bitcast <2 x i64>* %39 to <4 x i32>*
  %41 = load <4 x i32>, <4 x i32>* %40, align 16
  %42 = shufflevector <4 x i32> %41, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %43 = bitcast <4 x i32> %42 to <2 x i64>
  %44 = shufflevector <4 x i32> %41, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %45 = bitcast <4 x i32> %44 to <2 x i64>
  %46 = shl <2 x i64> %43, <i64 32, i64 32>
  %47 = ashr exact <2 x i64> %46, <i64 32, i64 32>
  %48 = mul nsw <2 x i64> %47, <i64 -41576, i64 -41576>
  %49 = shl <2 x i64> %45, <i64 32, i64 32>
  %50 = ashr exact <2 x i64> %49, <i64 32, i64 32>
  %51 = mul nsw <2 x i64> %50, <i64 -41576, i64 -41576>
  %52 = add nsw <2 x i64> %48, <i64 32768, i64 32768>
  %53 = bitcast <2 x i64> %52 to <16 x i8>
  %54 = shufflevector <16 x i8> %53, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %55 = add nsw <2 x i64> %51, <i64 32768, i64 32768>
  %56 = bitcast <2 x i64> %55 to <16 x i8>
  %57 = shufflevector <16 x i8> %56, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %58 = bitcast <16 x i8> %54 to <4 x i32>
  %59 = bitcast <16 x i8> %57 to <4 x i32>
  %60 = shufflevector <4 x i32> %58, <4 x i32> %59, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %61 = shufflevector <4 x i32> %58, <4 x i32> %59, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %62 = shufflevector <4 x i32> %60, <4 x i32> %61, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %63 = mul nsw <2 x i64> %47, <i64 50660, i64 50660>
  %64 = mul nsw <2 x i64> %50, <i64 50660, i64 50660>
  %65 = add nsw <2 x i64> %63, <i64 32768, i64 32768>
  %66 = bitcast <2 x i64> %65 to <16 x i8>
  %67 = shufflevector <16 x i8> %66, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %68 = add nsw <2 x i64> %64, <i64 32768, i64 32768>
  %69 = bitcast <2 x i64> %68 to <16 x i8>
  %70 = shufflevector <16 x i8> %69, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %71 = bitcast <16 x i8> %67 to <4 x i32>
  %72 = bitcast <16 x i8> %70 to <4 x i32>
  %73 = shufflevector <4 x i32> %71, <4 x i32> %72, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %74 = shufflevector <4 x i32> %71, <4 x i32> %72, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %75 = shufflevector <4 x i32> %73, <4 x i32> %74, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %76 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %77 = bitcast <2 x i64>* %76 to <4 x i32>*
  %78 = load <4 x i32>, <4 x i32>* %77, align 16
  %79 = shufflevector <4 x i32> %78, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %80 = bitcast <4 x i32> %79 to <2 x i64>
  %81 = shufflevector <4 x i32> %78, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %82 = bitcast <4 x i32> %81 to <2 x i64>
  %83 = shl <2 x i64> %80, <i64 32, i64 32>
  %84 = ashr exact <2 x i64> %83, <i64 32, i64 32>
  %85 = mul nsw <2 x i64> %84, <i64 30892, i64 30892>
  %86 = shl <2 x i64> %82, <i64 32, i64 32>
  %87 = ashr exact <2 x i64> %86, <i64 32, i64 32>
  %88 = mul nsw <2 x i64> %87, <i64 30892, i64 30892>
  %89 = add nsw <2 x i64> %85, <i64 32768, i64 32768>
  %90 = bitcast <2 x i64> %89 to <16 x i8>
  %91 = shufflevector <16 x i8> %90, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %92 = add nsw <2 x i64> %88, <i64 32768, i64 32768>
  %93 = bitcast <2 x i64> %92 to <16 x i8>
  %94 = shufflevector <16 x i8> %93, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %95 = bitcast <16 x i8> %91 to <4 x i32>
  %96 = bitcast <16 x i8> %94 to <4 x i32>
  %97 = shufflevector <4 x i32> %95, <4 x i32> %96, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %98 = shufflevector <4 x i32> %95, <4 x i32> %96, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %99 = shufflevector <4 x i32> %97, <4 x i32> %98, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %100 = mul nsw <2 x i64> %84, <i64 57796, i64 57796>
  %101 = mul nsw <2 x i64> %87, <i64 57796, i64 57796>
  %102 = add nsw <2 x i64> %100, <i64 32768, i64 32768>
  %103 = bitcast <2 x i64> %102 to <16 x i8>
  %104 = shufflevector <16 x i8> %103, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %105 = add nsw <2 x i64> %101, <i64 32768, i64 32768>
  %106 = bitcast <2 x i64> %105 to <16 x i8>
  %107 = shufflevector <16 x i8> %106, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %108 = bitcast <16 x i8> %104 to <4 x i32>
  %109 = bitcast <16 x i8> %107 to <4 x i32>
  %110 = shufflevector <4 x i32> %108, <4 x i32> %109, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %111 = shufflevector <4 x i32> %108, <4 x i32> %109, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %112 = shufflevector <4 x i32> %110, <4 x i32> %111, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %113 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %114 = bitcast <2 x i64>* %113 to <4 x i32>*
  %115 = load <4 x i32>, <4 x i32>* %114, align 16
  %116 = shufflevector <4 x i32> %115, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %117 = bitcast <4 x i32> %116 to <2 x i64>
  %118 = shufflevector <4 x i32> %115, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %119 = bitcast <4 x i32> %118 to <2 x i64>
  %120 = shl <2 x i64> %117, <i64 32, i64 32>
  %121 = ashr exact <2 x i64> %120, <i64 32, i64 32>
  %122 = mul nsw <2 x i64> %121, <i64 -19024, i64 -19024>
  %123 = shl <2 x i64> %119, <i64 32, i64 32>
  %124 = ashr exact <2 x i64> %123, <i64 32, i64 32>
  %125 = mul nsw <2 x i64> %124, <i64 -19024, i64 -19024>
  %126 = add nsw <2 x i64> %122, <i64 32768, i64 32768>
  %127 = bitcast <2 x i64> %126 to <16 x i8>
  %128 = shufflevector <16 x i8> %127, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %129 = add nsw <2 x i64> %125, <i64 32768, i64 32768>
  %130 = bitcast <2 x i64> %129 to <16 x i8>
  %131 = shufflevector <16 x i8> %130, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %132 = bitcast <16 x i8> %128 to <4 x i32>
  %133 = bitcast <16 x i8> %131 to <4 x i32>
  %134 = shufflevector <4 x i32> %132, <4 x i32> %133, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %135 = shufflevector <4 x i32> %132, <4 x i32> %133, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %136 = shufflevector <4 x i32> %134, <4 x i32> %135, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %137 = mul nsw <2 x i64> %121, <i64 62716, i64 62716>
  %138 = mul nsw <2 x i64> %124, <i64 62716, i64 62716>
  %139 = add nsw <2 x i64> %137, <i64 32768, i64 32768>
  %140 = bitcast <2 x i64> %139 to <16 x i8>
  %141 = shufflevector <16 x i8> %140, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %142 = add nsw <2 x i64> %138, <i64 32768, i64 32768>
  %143 = bitcast <2 x i64> %142 to <16 x i8>
  %144 = shufflevector <16 x i8> %143, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %145 = bitcast <16 x i8> %141 to <4 x i32>
  %146 = bitcast <16 x i8> %144 to <4 x i32>
  %147 = shufflevector <4 x i32> %145, <4 x i32> %146, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %148 = shufflevector <4 x i32> %145, <4 x i32> %146, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %149 = shufflevector <4 x i32> %147, <4 x i32> %148, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %150 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %151 = bitcast <2 x i64>* %150 to <4 x i32>*
  %152 = load <4 x i32>, <4 x i32>* %151, align 16
  %153 = shufflevector <4 x i32> %152, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %154 = bitcast <4 x i32> %153 to <2 x i64>
  %155 = shufflevector <4 x i32> %152, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %156 = bitcast <4 x i32> %155 to <2 x i64>
  %157 = shl <2 x i64> %154, <i64 32, i64 32>
  %158 = ashr exact <2 x i64> %157, <i64 32, i64 32>
  %159 = mul nsw <2 x i64> %158, <i64 12784, i64 12784>
  %160 = shl <2 x i64> %156, <i64 32, i64 32>
  %161 = ashr exact <2 x i64> %160, <i64 32, i64 32>
  %162 = mul nsw <2 x i64> %161, <i64 12784, i64 12784>
  %163 = add nsw <2 x i64> %159, <i64 32768, i64 32768>
  %164 = bitcast <2 x i64> %163 to <16 x i8>
  %165 = shufflevector <16 x i8> %164, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %166 = add nsw <2 x i64> %162, <i64 32768, i64 32768>
  %167 = bitcast <2 x i64> %166 to <16 x i8>
  %168 = shufflevector <16 x i8> %167, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %169 = bitcast <16 x i8> %165 to <4 x i32>
  %170 = bitcast <16 x i8> %168 to <4 x i32>
  %171 = shufflevector <4 x i32> %169, <4 x i32> %170, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %172 = shufflevector <4 x i32> %169, <4 x i32> %170, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %173 = shufflevector <4 x i32> %171, <4 x i32> %172, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %174 = mul nsw <2 x i64> %158, <i64 64276, i64 64276>
  %175 = mul nsw <2 x i64> %161, <i64 64276, i64 64276>
  %176 = add nsw <2 x i64> %174, <i64 32768, i64 32768>
  %177 = bitcast <2 x i64> %176 to <16 x i8>
  %178 = shufflevector <16 x i8> %177, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %179 = add nsw <2 x i64> %175, <i64 32768, i64 32768>
  %180 = bitcast <2 x i64> %179 to <16 x i8>
  %181 = shufflevector <16 x i8> %180, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %182 = bitcast <16 x i8> %178 to <4 x i32>
  %183 = bitcast <16 x i8> %181 to <4 x i32>
  %184 = shufflevector <4 x i32> %182, <4 x i32> %183, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %185 = shufflevector <4 x i32> %182, <4 x i32> %183, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %186 = shufflevector <4 x i32> %184, <4 x i32> %185, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %187 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %188 = bitcast <2 x i64>* %187 to <4 x i32>*
  %189 = load <4 x i32>, <4 x i32>* %188, align 16
  %190 = shufflevector <4 x i32> %189, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %191 = bitcast <4 x i32> %190 to <2 x i64>
  %192 = shufflevector <4 x i32> %189, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %193 = bitcast <4 x i32> %192 to <2 x i64>
  %194 = shl <2 x i64> %191, <i64 32, i64 32>
  %195 = ashr exact <2 x i64> %194, <i64 32, i64 32>
  %196 = mul nsw <2 x i64> %195, <i64 -36408, i64 -36408>
  %197 = shl <2 x i64> %193, <i64 32, i64 32>
  %198 = ashr exact <2 x i64> %197, <i64 32, i64 32>
  %199 = mul nsw <2 x i64> %198, <i64 -36408, i64 -36408>
  %200 = add nsw <2 x i64> %196, <i64 32768, i64 32768>
  %201 = bitcast <2 x i64> %200 to <16 x i8>
  %202 = shufflevector <16 x i8> %201, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %203 = add nsw <2 x i64> %199, <i64 32768, i64 32768>
  %204 = bitcast <2 x i64> %203 to <16 x i8>
  %205 = shufflevector <16 x i8> %204, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %206 = bitcast <16 x i8> %202 to <4 x i32>
  %207 = bitcast <16 x i8> %205 to <4 x i32>
  %208 = shufflevector <4 x i32> %206, <4 x i32> %207, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %209 = shufflevector <4 x i32> %206, <4 x i32> %207, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %210 = shufflevector <4 x i32> %208, <4 x i32> %209, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %211 = mul nsw <2 x i64> %195, <i64 54492, i64 54492>
  %212 = mul nsw <2 x i64> %198, <i64 54492, i64 54492>
  %213 = add nsw <2 x i64> %211, <i64 32768, i64 32768>
  %214 = bitcast <2 x i64> %213 to <16 x i8>
  %215 = shufflevector <16 x i8> %214, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %216 = add nsw <2 x i64> %212, <i64 32768, i64 32768>
  %217 = bitcast <2 x i64> %216 to <16 x i8>
  %218 = shufflevector <16 x i8> %217, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %219 = bitcast <16 x i8> %215 to <4 x i32>
  %220 = bitcast <16 x i8> %218 to <4 x i32>
  %221 = shufflevector <4 x i32> %219, <4 x i32> %220, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %222 = shufflevector <4 x i32> %219, <4 x i32> %220, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %223 = shufflevector <4 x i32> %221, <4 x i32> %222, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %224 = add <4 x i32> %62, %25
  %225 = sub <4 x i32> %25, %62
  %226 = sub <4 x i32> %136, %99
  %227 = add <4 x i32> %136, %99
  %228 = add <4 x i32> %149, %112
  %229 = sub <4 x i32> %149, %112
  %230 = sub <4 x i32> %38, %75
  %231 = add <4 x i32> %75, %38
  %232 = bitcast <2 x i64>* %0 to <4 x i32>*
  %233 = load <4 x i32>, <4 x i32>* %232, align 16
  %234 = shufflevector <4 x i32> %233, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %235 = bitcast <4 x i32> %234 to <2 x i64>
  %236 = shufflevector <4 x i32> %233, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %237 = bitcast <4 x i32> %236 to <2 x i64>
  %238 = shl <2 x i64> %235, <i64 32, i64 32>
  %239 = ashr exact <2 x i64> %238, <i64 32, i64 32>
  %240 = mul nsw <2 x i64> %239, <i64 46340, i64 46340>
  %241 = shl <2 x i64> %237, <i64 32, i64 32>
  %242 = ashr exact <2 x i64> %241, <i64 32, i64 32>
  %243 = mul nsw <2 x i64> %242, <i64 46340, i64 46340>
  %244 = add nsw <2 x i64> %240, <i64 32768, i64 32768>
  %245 = bitcast <2 x i64> %244 to <16 x i8>
  %246 = shufflevector <16 x i8> %245, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %247 = add nsw <2 x i64> %243, <i64 32768, i64 32768>
  %248 = bitcast <2 x i64> %247 to <16 x i8>
  %249 = shufflevector <16 x i8> %248, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %250 = bitcast <16 x i8> %246 to <4 x i32>
  %251 = bitcast <16 x i8> %249 to <4 x i32>
  %252 = shufflevector <4 x i32> %250, <4 x i32> %251, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %253 = shufflevector <4 x i32> %250, <4 x i32> %251, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %254 = shufflevector <4 x i32> %252, <4 x i32> %253, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %255 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %256 = bitcast <2 x i64>* %255 to <4 x i32>*
  %257 = load <4 x i32>, <4 x i32>* %256, align 16
  %258 = shufflevector <4 x i32> %257, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %259 = bitcast <4 x i32> %258 to <2 x i64>
  %260 = shufflevector <4 x i32> %257, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %261 = bitcast <4 x i32> %260 to <2 x i64>
  %262 = shl <2 x i64> %259, <i64 32, i64 32>
  %263 = ashr exact <2 x i64> %262, <i64 32, i64 32>
  %264 = mul nsw <2 x i64> %263, <i64 25080, i64 25080>
  %265 = shl <2 x i64> %261, <i64 32, i64 32>
  %266 = ashr exact <2 x i64> %265, <i64 32, i64 32>
  %267 = mul nsw <2 x i64> %266, <i64 25080, i64 25080>
  %268 = add nsw <2 x i64> %264, <i64 32768, i64 32768>
  %269 = bitcast <2 x i64> %268 to <16 x i8>
  %270 = shufflevector <16 x i8> %269, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %271 = add nsw <2 x i64> %267, <i64 32768, i64 32768>
  %272 = bitcast <2 x i64> %271 to <16 x i8>
  %273 = shufflevector <16 x i8> %272, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %274 = bitcast <16 x i8> %270 to <4 x i32>
  %275 = bitcast <16 x i8> %273 to <4 x i32>
  %276 = shufflevector <4 x i32> %274, <4 x i32> %275, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %277 = shufflevector <4 x i32> %274, <4 x i32> %275, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %278 = shufflevector <4 x i32> %276, <4 x i32> %277, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %279 = mul nsw <2 x i64> %263, <i64 60548, i64 60548>
  %280 = mul nsw <2 x i64> %266, <i64 60548, i64 60548>
  %281 = add nsw <2 x i64> %279, <i64 32768, i64 32768>
  %282 = bitcast <2 x i64> %281 to <16 x i8>
  %283 = shufflevector <16 x i8> %282, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %284 = add nsw <2 x i64> %280, <i64 32768, i64 32768>
  %285 = bitcast <2 x i64> %284 to <16 x i8>
  %286 = shufflevector <16 x i8> %285, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %287 = bitcast <16 x i8> %283 to <4 x i32>
  %288 = bitcast <16 x i8> %286 to <4 x i32>
  %289 = shufflevector <4 x i32> %287, <4 x i32> %288, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %290 = shufflevector <4 x i32> %287, <4 x i32> %288, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %291 = shufflevector <4 x i32> %289, <4 x i32> %290, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %292 = shufflevector <4 x i32> %230, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %293 = bitcast <4 x i32> %292 to <2 x i64>
  %294 = shufflevector <4 x i32> %230, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %295 = bitcast <4 x i32> %294 to <2 x i64>
  %296 = shufflevector <4 x i32> %225, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %297 = bitcast <4 x i32> %296 to <2 x i64>
  %298 = shufflevector <4 x i32> %225, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %299 = bitcast <4 x i32> %298 to <2 x i64>
  %300 = shl <2 x i64> %293, <i64 32, i64 32>
  %301 = ashr exact <2 x i64> %300, <i64 32, i64 32>
  %302 = mul nsw <2 x i64> %301, <i64 60548, i64 60548>
  %303 = shl <2 x i64> %295, <i64 32, i64 32>
  %304 = ashr exact <2 x i64> %303, <i64 32, i64 32>
  %305 = mul nsw <2 x i64> %304, <i64 60548, i64 60548>
  %306 = mul nsw <2 x i64> %301, <i64 25080, i64 25080>
  %307 = mul nsw <2 x i64> %304, <i64 25080, i64 25080>
  %308 = shl <2 x i64> %297, <i64 32, i64 32>
  %309 = ashr exact <2 x i64> %308, <i64 32, i64 32>
  %310 = mul nsw <2 x i64> %309, <i64 25080, i64 25080>
  %311 = shl <2 x i64> %299, <i64 32, i64 32>
  %312 = ashr exact <2 x i64> %311, <i64 32, i64 32>
  %313 = mul nsw <2 x i64> %312, <i64 25080, i64 25080>
  %314 = add nsw <2 x i64> %306, <i64 32768, i64 32768>
  %315 = mul nsw <2 x i64> %309, <i64 -60548, i64 -60548>
  %316 = add nsw <2 x i64> %314, %315
  %317 = bitcast <2 x i64> %316 to <16 x i8>
  %318 = shufflevector <16 x i8> %317, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %319 = add nsw <2 x i64> %307, <i64 32768, i64 32768>
  %320 = mul nsw <2 x i64> %312, <i64 -60548, i64 -60548>
  %321 = add nsw <2 x i64> %319, %320
  %322 = bitcast <2 x i64> %321 to <16 x i8>
  %323 = shufflevector <16 x i8> %322, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %324 = add nsw <2 x i64> %310, <i64 32768, i64 32768>
  %325 = add nsw <2 x i64> %324, %302
  %326 = bitcast <2 x i64> %325 to <16 x i8>
  %327 = shufflevector <16 x i8> %326, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %328 = add nsw <2 x i64> %313, <i64 32768, i64 32768>
  %329 = add nsw <2 x i64> %328, %305
  %330 = bitcast <2 x i64> %329 to <16 x i8>
  %331 = shufflevector <16 x i8> %330, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %332 = bitcast <16 x i8> %318 to <4 x i32>
  %333 = bitcast <16 x i8> %323 to <4 x i32>
  %334 = shufflevector <4 x i32> %332, <4 x i32> %333, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %335 = shufflevector <4 x i32> %332, <4 x i32> %333, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %336 = shufflevector <4 x i32> %334, <4 x i32> %335, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %337 = bitcast <16 x i8> %327 to <4 x i32>
  %338 = bitcast <16 x i8> %331 to <4 x i32>
  %339 = shufflevector <4 x i32> %337, <4 x i32> %338, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %340 = shufflevector <4 x i32> %337, <4 x i32> %338, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %341 = shufflevector <4 x i32> %339, <4 x i32> %340, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %342 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %343 = bitcast <4 x i32> %342 to <2 x i64>
  %344 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %345 = bitcast <4 x i32> %344 to <2 x i64>
  %346 = shufflevector <4 x i32> %229, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %347 = bitcast <4 x i32> %346 to <2 x i64>
  %348 = shufflevector <4 x i32> %229, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %349 = bitcast <4 x i32> %348 to <2 x i64>
  %350 = shl <2 x i64> %343, <i64 32, i64 32>
  %351 = ashr exact <2 x i64> %350, <i64 32, i64 32>
  %352 = mul nsw <2 x i64> %351, <i64 -25080, i64 -25080>
  %353 = shl <2 x i64> %345, <i64 32, i64 32>
  %354 = ashr exact <2 x i64> %353, <i64 32, i64 32>
  %355 = mul nsw <2 x i64> %354, <i64 -25080, i64 -25080>
  %356 = mul nsw <2 x i64> %351, <i64 -60548, i64 -60548>
  %357 = mul nsw <2 x i64> %354, <i64 -60548, i64 -60548>
  %358 = shl <2 x i64> %347, <i64 32, i64 32>
  %359 = ashr exact <2 x i64> %358, <i64 32, i64 32>
  %360 = mul nsw <2 x i64> %359, <i64 -60548, i64 -60548>
  %361 = shl <2 x i64> %349, <i64 32, i64 32>
  %362 = ashr exact <2 x i64> %361, <i64 32, i64 32>
  %363 = mul nsw <2 x i64> %362, <i64 -60548, i64 -60548>
  %364 = add nsw <2 x i64> %356, <i64 32768, i64 32768>
  %365 = mul nsw <2 x i64> %359, <i64 25080, i64 25080>
  %366 = add nsw <2 x i64> %364, %365
  %367 = bitcast <2 x i64> %366 to <16 x i8>
  %368 = shufflevector <16 x i8> %367, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %369 = add nsw <2 x i64> %357, <i64 32768, i64 32768>
  %370 = mul nsw <2 x i64> %362, <i64 25080, i64 25080>
  %371 = add nsw <2 x i64> %369, %370
  %372 = bitcast <2 x i64> %371 to <16 x i8>
  %373 = shufflevector <16 x i8> %372, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %374 = add nsw <2 x i64> %360, <i64 32768, i64 32768>
  %375 = add nsw <2 x i64> %374, %352
  %376 = bitcast <2 x i64> %375 to <16 x i8>
  %377 = shufflevector <16 x i8> %376, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %378 = add nsw <2 x i64> %363, <i64 32768, i64 32768>
  %379 = add nsw <2 x i64> %378, %355
  %380 = bitcast <2 x i64> %379 to <16 x i8>
  %381 = shufflevector <16 x i8> %380, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %382 = bitcast <16 x i8> %368 to <4 x i32>
  %383 = bitcast <16 x i8> %373 to <4 x i32>
  %384 = shufflevector <4 x i32> %382, <4 x i32> %383, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %385 = shufflevector <4 x i32> %382, <4 x i32> %383, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %386 = shufflevector <4 x i32> %384, <4 x i32> %385, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %387 = bitcast <16 x i8> %377 to <4 x i32>
  %388 = bitcast <16 x i8> %381 to <4 x i32>
  %389 = shufflevector <4 x i32> %387, <4 x i32> %388, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %390 = shufflevector <4 x i32> %387, <4 x i32> %388, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %391 = shufflevector <4 x i32> %389, <4 x i32> %390, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %392 = sub <4 x i32> %173, %210
  %393 = add <4 x i32> %210, %173
  %394 = sub <4 x i32> %186, %223
  %395 = add <4 x i32> %223, %186
  %396 = add <4 x i32> %291, %254
  %397 = add <4 x i32> %278, %254
  %398 = sub <4 x i32> %254, %278
  %399 = sub <4 x i32> %254, %291
  %400 = add <4 x i32> %392, %394
  %401 = shufflevector <4 x i32> %400, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %402 = bitcast <4 x i32> %401 to <2 x i64>
  %403 = shufflevector <4 x i32> %400, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %404 = bitcast <4 x i32> %403 to <2 x i64>
  %405 = shl <2 x i64> %402, <i64 32, i64 32>
  %406 = ashr exact <2 x i64> %405, <i64 32, i64 32>
  %407 = mul nsw <2 x i64> %406, <i64 46340, i64 46340>
  %408 = shl <2 x i64> %404, <i64 32, i64 32>
  %409 = ashr exact <2 x i64> %408, <i64 32, i64 32>
  %410 = mul nsw <2 x i64> %409, <i64 46340, i64 46340>
  %411 = add nsw <2 x i64> %407, <i64 32768, i64 32768>
  %412 = bitcast <2 x i64> %411 to <16 x i8>
  %413 = shufflevector <16 x i8> %412, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %414 = add nsw <2 x i64> %410, <i64 32768, i64 32768>
  %415 = bitcast <2 x i64> %414 to <16 x i8>
  %416 = shufflevector <16 x i8> %415, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %417 = bitcast <16 x i8> %413 to <4 x i32>
  %418 = bitcast <16 x i8> %416 to <4 x i32>
  %419 = shufflevector <4 x i32> %417, <4 x i32> %418, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %420 = shufflevector <4 x i32> %417, <4 x i32> %418, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %421 = shufflevector <4 x i32> %419, <4 x i32> %420, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %422 = sub <4 x i32> %394, %392
  %423 = shufflevector <4 x i32> %422, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %424 = bitcast <4 x i32> %423 to <2 x i64>
  %425 = shufflevector <4 x i32> %422, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %426 = bitcast <4 x i32> %425 to <2 x i64>
  %427 = shl <2 x i64> %424, <i64 32, i64 32>
  %428 = ashr exact <2 x i64> %427, <i64 32, i64 32>
  %429 = mul nsw <2 x i64> %428, <i64 46340, i64 46340>
  %430 = shl <2 x i64> %426, <i64 32, i64 32>
  %431 = ashr exact <2 x i64> %430, <i64 32, i64 32>
  %432 = mul nsw <2 x i64> %431, <i64 46340, i64 46340>
  %433 = add nsw <2 x i64> %429, <i64 32768, i64 32768>
  %434 = bitcast <2 x i64> %433 to <16 x i8>
  %435 = shufflevector <16 x i8> %434, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %436 = add nsw <2 x i64> %432, <i64 32768, i64 32768>
  %437 = bitcast <2 x i64> %436 to <16 x i8>
  %438 = shufflevector <16 x i8> %437, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %439 = bitcast <16 x i8> %435 to <4 x i32>
  %440 = bitcast <16 x i8> %438 to <4 x i32>
  %441 = shufflevector <4 x i32> %439, <4 x i32> %440, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %442 = shufflevector <4 x i32> %439, <4 x i32> %440, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %443 = shufflevector <4 x i32> %441, <4 x i32> %442, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %444 = add <4 x i32> %227, %224
  %445 = add <4 x i32> %391, %336
  %446 = sub <4 x i32> %336, %391
  %447 = sub <4 x i32> %224, %227
  %448 = sub <4 x i32> %231, %228
  %449 = sub <4 x i32> %341, %386
  %450 = add <4 x i32> %386, %341
  %451 = add <4 x i32> %228, %231
  %452 = add <4 x i32> %396, %395
  %453 = add <4 x i32> %421, %397
  %454 = add <4 x i32> %443, %398
  %455 = add <4 x i32> %399, %393
  %456 = sub <4 x i32> %399, %393
  %457 = sub <4 x i32> %398, %443
  %458 = sub <4 x i32> %397, %421
  %459 = sub <4 x i32> %396, %395
  %460 = add <4 x i32> %446, %449
  %461 = shufflevector <4 x i32> %460, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %462 = bitcast <4 x i32> %461 to <2 x i64>
  %463 = shufflevector <4 x i32> %460, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %464 = bitcast <4 x i32> %463 to <2 x i64>
  %465 = shl <2 x i64> %462, <i64 32, i64 32>
  %466 = ashr exact <2 x i64> %465, <i64 32, i64 32>
  %467 = mul nsw <2 x i64> %466, <i64 46340, i64 46340>
  %468 = shl <2 x i64> %464, <i64 32, i64 32>
  %469 = ashr exact <2 x i64> %468, <i64 32, i64 32>
  %470 = mul nsw <2 x i64> %469, <i64 46340, i64 46340>
  %471 = add nsw <2 x i64> %467, <i64 32768, i64 32768>
  %472 = bitcast <2 x i64> %471 to <16 x i8>
  %473 = shufflevector <16 x i8> %472, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %474 = add nsw <2 x i64> %470, <i64 32768, i64 32768>
  %475 = bitcast <2 x i64> %474 to <16 x i8>
  %476 = shufflevector <16 x i8> %475, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %477 = bitcast <16 x i8> %473 to <4 x i32>
  %478 = bitcast <16 x i8> %476 to <4 x i32>
  %479 = shufflevector <4 x i32> %477, <4 x i32> %478, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %480 = shufflevector <4 x i32> %477, <4 x i32> %478, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %481 = shufflevector <4 x i32> %479, <4 x i32> %480, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %482 = sub <4 x i32> %449, %446
  %483 = shufflevector <4 x i32> %482, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %484 = bitcast <4 x i32> %483 to <2 x i64>
  %485 = shufflevector <4 x i32> %482, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %486 = bitcast <4 x i32> %485 to <2 x i64>
  %487 = shl <2 x i64> %484, <i64 32, i64 32>
  %488 = ashr exact <2 x i64> %487, <i64 32, i64 32>
  %489 = mul nsw <2 x i64> %488, <i64 46340, i64 46340>
  %490 = shl <2 x i64> %486, <i64 32, i64 32>
  %491 = ashr exact <2 x i64> %490, <i64 32, i64 32>
  %492 = mul nsw <2 x i64> %491, <i64 46340, i64 46340>
  %493 = add nsw <2 x i64> %489, <i64 32768, i64 32768>
  %494 = bitcast <2 x i64> %493 to <16 x i8>
  %495 = shufflevector <16 x i8> %494, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %496 = add nsw <2 x i64> %492, <i64 32768, i64 32768>
  %497 = bitcast <2 x i64> %496 to <16 x i8>
  %498 = shufflevector <16 x i8> %497, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %499 = bitcast <16 x i8> %495 to <4 x i32>
  %500 = bitcast <16 x i8> %498 to <4 x i32>
  %501 = shufflevector <4 x i32> %499, <4 x i32> %500, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %502 = shufflevector <4 x i32> %499, <4 x i32> %500, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %503 = shufflevector <4 x i32> %501, <4 x i32> %502, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %504 = add <4 x i32> %447, %448
  %505 = shufflevector <4 x i32> %504, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %506 = bitcast <4 x i32> %505 to <2 x i64>
  %507 = shufflevector <4 x i32> %504, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %508 = bitcast <4 x i32> %507 to <2 x i64>
  %509 = shl <2 x i64> %506, <i64 32, i64 32>
  %510 = ashr exact <2 x i64> %509, <i64 32, i64 32>
  %511 = mul nsw <2 x i64> %510, <i64 46340, i64 46340>
  %512 = shl <2 x i64> %508, <i64 32, i64 32>
  %513 = ashr exact <2 x i64> %512, <i64 32, i64 32>
  %514 = mul nsw <2 x i64> %513, <i64 46340, i64 46340>
  %515 = add nsw <2 x i64> %511, <i64 32768, i64 32768>
  %516 = bitcast <2 x i64> %515 to <16 x i8>
  %517 = shufflevector <16 x i8> %516, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %518 = add nsw <2 x i64> %514, <i64 32768, i64 32768>
  %519 = bitcast <2 x i64> %518 to <16 x i8>
  %520 = shufflevector <16 x i8> %519, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %521 = bitcast <16 x i8> %517 to <4 x i32>
  %522 = bitcast <16 x i8> %520 to <4 x i32>
  %523 = shufflevector <4 x i32> %521, <4 x i32> %522, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %524 = shufflevector <4 x i32> %521, <4 x i32> %522, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %525 = shufflevector <4 x i32> %523, <4 x i32> %524, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %526 = sub <4 x i32> %448, %447
  %527 = shufflevector <4 x i32> %526, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %528 = bitcast <4 x i32> %527 to <2 x i64>
  %529 = shufflevector <4 x i32> %526, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %530 = bitcast <4 x i32> %529 to <2 x i64>
  %531 = shl <2 x i64> %528, <i64 32, i64 32>
  %532 = ashr exact <2 x i64> %531, <i64 32, i64 32>
  %533 = mul nsw <2 x i64> %532, <i64 46340, i64 46340>
  %534 = shl <2 x i64> %530, <i64 32, i64 32>
  %535 = ashr exact <2 x i64> %534, <i64 32, i64 32>
  %536 = mul nsw <2 x i64> %535, <i64 46340, i64 46340>
  %537 = add nsw <2 x i64> %533, <i64 32768, i64 32768>
  %538 = bitcast <2 x i64> %537 to <16 x i8>
  %539 = shufflevector <16 x i8> %538, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %540 = add nsw <2 x i64> %536, <i64 32768, i64 32768>
  %541 = bitcast <2 x i64> %540 to <16 x i8>
  %542 = shufflevector <16 x i8> %541, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %543 = bitcast <16 x i8> %539 to <4 x i32>
  %544 = bitcast <16 x i8> %542 to <4 x i32>
  %545 = shufflevector <4 x i32> %543, <4 x i32> %544, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %546 = shufflevector <4 x i32> %543, <4 x i32> %544, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %547 = shufflevector <4 x i32> %545, <4 x i32> %546, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %548 = add <4 x i32> %452, %451
  store <4 x i32> %548, <4 x i32>* %232, align 16
  %549 = add <4 x i32> %453, %450
  store <4 x i32> %549, <4 x i32>* %3, align 16
  %550 = add <4 x i32> %481, %454
  store <4 x i32> %550, <4 x i32>* %151, align 16
  %551 = add <4 x i32> %525, %455
  store <4 x i32> %551, <4 x i32>* %114, align 16
  %552 = add <4 x i32> %547, %456
  store <4 x i32> %552, <4 x i32>* %256, align 16
  %553 = add <4 x i32> %503, %457
  store <4 x i32> %553, <4 x i32>* %77, align 16
  %554 = add <4 x i32> %458, %445
  store <4 x i32> %554, <4 x i32>* %188, align 16
  %555 = add <4 x i32> %459, %444
  store <4 x i32> %555, <4 x i32>* %40, align 16
  %556 = sub <4 x i32> %459, %444
  %557 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %558 = bitcast <2 x i64>* %557 to <4 x i32>*
  store <4 x i32> %556, <4 x i32>* %558, align 16
  %559 = sub <4 x i32> %458, %445
  %560 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %561 = bitcast <2 x i64>* %560 to <4 x i32>*
  store <4 x i32> %559, <4 x i32>* %561, align 16
  %562 = sub <4 x i32> %457, %503
  %563 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %564 = bitcast <2 x i64>* %563 to <4 x i32>*
  store <4 x i32> %562, <4 x i32>* %564, align 16
  %565 = sub <4 x i32> %456, %547
  %566 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %567 = bitcast <2 x i64>* %566 to <4 x i32>*
  store <4 x i32> %565, <4 x i32>* %567, align 16
  %568 = sub <4 x i32> %455, %525
  %569 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %570 = bitcast <2 x i64>* %569 to <4 x i32>*
  store <4 x i32> %568, <4 x i32>* %570, align 16
  %571 = sub <4 x i32> %454, %481
  %572 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %573 = bitcast <2 x i64>* %572 to <4 x i32>*
  store <4 x i32> %571, <4 x i32>* %573, align 16
  %574 = sub <4 x i32> %453, %450
  %575 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %576 = bitcast <2 x i64>* %575 to <4 x i32>*
  store <4 x i32> %574, <4 x i32>* %576, align 16
  %577 = sub <4 x i32> %452, %451
  %578 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %579 = bitcast <2 x i64>* %578 to <4 x i32>*
  store <4 x i32> %577, <4 x i32>* %579, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_highbd_idct16x16_10_add_sse4_1(i32* nocapture readonly, i16* nocapture, i32, i32) local_unnamed_addr #0 {
  %5 = alloca [16 x <2 x i64>], align 16
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = alloca [16 x <2 x i64>], align 16
  %8 = alloca [2 x [16 x <2 x i64>]], align 16
  %9 = bitcast [16 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %9) #5
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 256, i1 false)
  %10 = icmp eq i32 %3, 8
  br i1 %10, label %11, label %509

11:                                               ; preds = %4
  %12 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %12) #5
  %13 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %14 = bitcast <2 x i64>* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 192, i1 false)
  %15 = bitcast [16 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %15) #5
  %16 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  %17 = bitcast <2 x i64>* %16 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %17, i8 -86, i64 224, i1 false)
  %18 = bitcast i32* %0 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 16
  %20 = getelementptr inbounds i32, i32* %0, i64 4
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 16
  %23 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %19, <4 x i32> %22) #5
  %24 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %25 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  store <8 x i16> %23, <8 x i16>* %25, align 16
  %26 = getelementptr inbounds i32, i32* %0, i64 16
  %27 = bitcast i32* %26 to <4 x i32>*
  %28 = load <4 x i32>, <4 x i32>* %27, align 16
  %29 = getelementptr inbounds i32, i32* %0, i64 20
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 16
  %32 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %28, <4 x i32> %31) #5
  %33 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %34 = bitcast <2 x i64>* %33 to <8 x i16>*
  store <8 x i16> %32, <8 x i16>* %34, align 16
  %35 = getelementptr inbounds i32, i32* %0, i64 32
  %36 = bitcast i32* %35 to <4 x i32>*
  %37 = load <4 x i32>, <4 x i32>* %36, align 16
  %38 = getelementptr inbounds i32, i32* %0, i64 36
  %39 = bitcast i32* %38 to <4 x i32>*
  %40 = load <4 x i32>, <4 x i32>* %39, align 16
  %41 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %37, <4 x i32> %40) #5
  %42 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %43 = bitcast <2 x i64>* %42 to <8 x i16>*
  store <8 x i16> %41, <8 x i16>* %43, align 16
  %44 = getelementptr inbounds i32, i32* %0, i64 48
  %45 = bitcast i32* %44 to <4 x i32>*
  %46 = load <4 x i32>, <4 x i32>* %45, align 16
  %47 = getelementptr inbounds i32, i32* %0, i64 52
  %48 = bitcast i32* %47 to <4 x i32>*
  %49 = load <4 x i32>, <4 x i32>* %48, align 16
  %50 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %46, <4 x i32> %49) #5
  %51 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %52 = bitcast <2 x i64>* %51 to <8 x i16>*
  store <8 x i16> %50, <8 x i16>* %52, align 16
  %53 = shufflevector <8 x i16> %23, <8 x i16> %32, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %54 = shufflevector <8 x i16> %41, <8 x i16> %50, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %55 = bitcast <8 x i16> %53 to <4 x i32>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = shufflevector <4 x i32> %55, <4 x i32> %56, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %58 = bitcast [16 x <2 x i64>]* %7 to <4 x i32>*
  store <4 x i32> %57, <4 x i32>* %58, align 16
  %59 = shufflevector <4 x i32> %55, <4 x i32> %56, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %60 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  %61 = bitcast <2 x i64>* %60 to <4 x i32>*
  store <4 x i32> %59, <4 x i32>* %61, align 16
  %62 = bitcast <4 x i32> %57 to <8 x i16>
  %63 = shufflevector <8 x i16> %62, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %64 = bitcast <4 x i32> %59 to <8 x i16>
  %65 = shufflevector <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i16> %64, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %66 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>, <8 x i16> %63) #5
  %67 = add <4 x i32> %66, <i32 8192, i32 8192, i32 8192, i32 8192>
  %68 = ashr <4 x i32> %67, <i32 14, i32 14, i32 14, i32 14>
  %69 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>, <8 x i16> %63) #5
  %70 = add <4 x i32> %69, <i32 8192, i32 8192, i32 8192, i32 8192>
  %71 = ashr <4 x i32> %70, <i32 14, i32 14, i32 14, i32 14>
  %72 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %68, <4 x i32> %71) #5
  %73 = bitcast <8 x i16> %72 to <2 x i64>
  %74 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>, <8 x i16> %65) #5
  %75 = add <4 x i32> %74, <i32 8192, i32 8192, i32 8192, i32 8192>
  %76 = ashr <4 x i32> %75, <i32 14, i32 14, i32 14, i32 14>
  %77 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>, <8 x i16> %65) #5
  %78 = add <4 x i32> %77, <i32 8192, i32 8192, i32 8192, i32 8192>
  %79 = ashr <4 x i32> %78, <i32 14, i32 14, i32 14, i32 14>
  %80 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %76, <4 x i32> %79) #5
  %81 = bitcast <8 x i16> %80 to <2 x i64>
  %82 = shufflevector <8 x i16> %64, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %83 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>, <8 x i16> %82) #5
  %84 = add <4 x i32> %83, <i32 8192, i32 8192, i32 8192, i32 8192>
  %85 = ashr <4 x i32> %84, <i32 14, i32 14, i32 14, i32 14>
  %86 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>, <8 x i16> %82) #5
  %87 = add <4 x i32> %86, <i32 8192, i32 8192, i32 8192, i32 8192>
  %88 = ashr <4 x i32> %87, <i32 14, i32 14, i32 14, i32 14>
  %89 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %85, <4 x i32> %88) #5
  %90 = bitcast <8 x i16> %89 to <2 x i64>
  %91 = shufflevector <2 x i64> %81, <2 x i64> undef, <2 x i32> <i32 1, i32 undef>
  %92 = shufflevector <2 x i64> %73, <2 x i64> undef, <2 x i32> <i32 1, i32 undef>
  %93 = shufflevector <8 x i16> %62, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %94 = bitcast <2 x i64> %92 to <8 x i16>
  %95 = shufflevector <8 x i16> %72, <8 x i16> %94, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %96 = bitcast <2 x i64> %91 to <8 x i16>
  %97 = shufflevector <8 x i16> %80, <8 x i16> %96, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %98 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %93, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %99 = add <4 x i32> %98, <i32 8192, i32 8192, i32 8192, i32 8192>
  %100 = ashr <4 x i32> %99, <i32 14, i32 14, i32 14, i32 14>
  %101 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %100, <4 x i32> %100) #5
  %102 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>, <8 x i16> %95) #5
  %103 = add <4 x i32> %102, <i32 8192, i32 8192, i32 8192, i32 8192>
  %104 = ashr <4 x i32> %103, <i32 14, i32 14, i32 14, i32 14>
  %105 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137>, <8 x i16> %95) #5
  %106 = add <4 x i32> %105, <i32 8192, i32 8192, i32 8192, i32 8192>
  %107 = ashr <4 x i32> %106, <i32 14, i32 14, i32 14, i32 14>
  %108 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %104, <4 x i32> %107) #5
  %109 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137>, <8 x i16> %97) #5
  %110 = add <4 x i32> %109, <i32 8192, i32 8192, i32 8192, i32 8192>
  %111 = ashr <4 x i32> %110, <i32 14, i32 14, i32 14, i32 14>
  %112 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>, <8 x i16> %97) #5
  %113 = add <4 x i32> %112, <i32 8192, i32 8192, i32 8192, i32 8192>
  %114 = ashr <4 x i32> %113, <i32 14, i32 14, i32 14, i32 14>
  %115 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %111, <4 x i32> %114) #5
  %116 = shufflevector <2 x i64> %90, <2 x i64> undef, <2 x i32> <i32 1, i32 undef>
  %117 = bitcast <2 x i64> %116 to <8 x i16>
  %118 = shufflevector <8 x i16> %89, <8 x i16> %117, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %119 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>, <8 x i16> %118) #5
  %120 = add <4 x i32> %119, <i32 8192, i32 8192, i32 8192, i32 8192>
  %121 = ashr <4 x i32> %120, <i32 14, i32 14, i32 14, i32 14>
  %122 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585>, <8 x i16> %118) #5
  %123 = add <4 x i32> %122, <i32 8192, i32 8192, i32 8192, i32 8192>
  %124 = ashr <4 x i32> %123, <i32 14, i32 14, i32 14, i32 14>
  %125 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %121, <4 x i32> %124) #5
  %126 = add <8 x i16> %80, %72
  %127 = bitcast <8 x i16> %126 to <2 x i64>
  %128 = add <8 x i16> %115, %108
  %129 = bitcast <8 x i16> %128 to <2 x i64>
  %130 = sub <8 x i16> %108, %115
  %131 = bitcast <8 x i16> %130 to <2 x i64>
  %132 = sub <8 x i16> %72, %80
  %133 = bitcast <8 x i16> %132 to <2 x i64>
  %134 = shufflevector <2 x i64> %133, <2 x i64> undef, <2 x i32> <i32 1, i32 undef>
  %135 = shufflevector <2 x i64> %131, <2 x i64> undef, <2 x i32> <i32 1, i32 undef>
  %136 = shufflevector <2 x i64> %129, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %137 = shufflevector <2 x i64> %127, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %138 = bitcast <2 x i64> %135 to <8 x i16>
  %139 = shufflevector <8 x i16> %130, <8 x i16> %138, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %140 = bitcast <2 x i64> %134 to <8 x i16>
  %141 = shufflevector <8 x i16> %132, <8 x i16> %140, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %142 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585>, <8 x i16> %139) #5
  %143 = add <4 x i32> %142, <i32 8192, i32 8192, i32 8192, i32 8192>
  %144 = ashr <4 x i32> %143, <i32 14, i32 14, i32 14, i32 14>
  %145 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>, <8 x i16> %139) #5
  %146 = add <4 x i32> %145, <i32 8192, i32 8192, i32 8192, i32 8192>
  %147 = ashr <4 x i32> %146, <i32 14, i32 14, i32 14, i32 14>
  %148 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %144, <4 x i32> %147) #5
  %149 = bitcast <8 x i16> %148 to <2 x i64>
  %150 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585>, <8 x i16> %141) #5
  %151 = add <4 x i32> %150, <i32 8192, i32 8192, i32 8192, i32 8192>
  %152 = ashr <4 x i32> %151, <i32 14, i32 14, i32 14, i32 14>
  %153 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>, <8 x i16> %141) #5
  %154 = add <4 x i32> %153, <i32 8192, i32 8192, i32 8192, i32 8192>
  %155 = ashr <4 x i32> %154, <i32 14, i32 14, i32 14, i32 14>
  %156 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %152, <4 x i32> %155) #5
  %157 = bitcast <8 x i16> %156 to <2 x i64>
  %158 = shufflevector <2 x i64> %149, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %159 = shufflevector <2 x i64> %157, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %160 = add <8 x i16> %101, %89
  %161 = bitcast <8 x i16> %160 to <2 x i64>
  %162 = add <8 x i16> %125, %101
  %163 = bitcast <8 x i16> %162 to <2 x i64>
  %164 = sub <8 x i16> %101, %125
  %165 = bitcast <8 x i16> %164 to <2 x i64>
  %166 = sub <8 x i16> %101, %89
  %167 = bitcast <8 x i16> %166 to <2 x i64>
  %168 = shufflevector <2 x i64> %161, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %169 = shufflevector <2 x i64> %163, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %170 = shufflevector <2 x i64> %165, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %171 = shufflevector <2 x i64> %167, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %172 = bitcast <2 x i64> %168 to <8 x i16>
  %173 = bitcast <2 x i64> %137 to <8 x i16>
  %174 = add <8 x i16> %172, %173
  %175 = bitcast [16 x <2 x i64>]* %7 to <8 x i16>*
  store <8 x i16> %174, <8 x i16>* %175, align 16
  %176 = bitcast <2 x i64> %136 to <8 x i16>
  %177 = add <8 x i16> %162, %176
  %178 = bitcast <2 x i64>* %60 to <8 x i16>*
  store <8 x i16> %177, <8 x i16>* %178, align 16
  %179 = bitcast <2 x i64> %169 to <8 x i16>
  %180 = bitcast <2 x i64> %158 to <8 x i16>
  %181 = add <8 x i16> %180, %179
  %182 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  %183 = bitcast <2 x i64>* %182 to <8 x i16>*
  store <8 x i16> %181, <8 x i16>* %183, align 16
  %184 = bitcast <2 x i64> %159 to <8 x i16>
  %185 = add <8 x i16> %160, %184
  %186 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  %187 = bitcast <2 x i64>* %186 to <8 x i16>*
  store <8 x i16> %185, <8 x i16>* %187, align 16
  %188 = add <8 x i16> %156, %166
  %189 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 4
  %190 = bitcast <2 x i64>* %189 to <8 x i16>*
  store <8 x i16> %188, <8 x i16>* %190, align 16
  %191 = bitcast <2 x i64> %170 to <8 x i16>
  %192 = add <8 x i16> %148, %191
  %193 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 5
  %194 = bitcast <2 x i64>* %193 to <8 x i16>*
  store <8 x i16> %192, <8 x i16>* %194, align 16
  %195 = add <8 x i16> %164, %128
  %196 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 6
  %197 = bitcast <2 x i64>* %196 to <8 x i16>*
  store <8 x i16> %195, <8 x i16>* %197, align 16
  %198 = bitcast <2 x i64> %171 to <8 x i16>
  %199 = add <8 x i16> %126, %198
  %200 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 7
  %201 = bitcast <2 x i64>* %200 to <8 x i16>*
  store <8 x i16> %199, <8 x i16>* %201, align 16
  %202 = sub <8 x i16> %198, %126
  %203 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  %204 = bitcast <2 x i64>* %203 to <8 x i16>*
  store <8 x i16> %202, <8 x i16>* %204, align 16
  %205 = sub <8 x i16> %164, %128
  %206 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  %207 = bitcast <2 x i64>* %206 to <8 x i16>*
  store <8 x i16> %205, <8 x i16>* %207, align 16
  %208 = sub <8 x i16> %191, %148
  %209 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  %210 = bitcast <2 x i64>* %209 to <8 x i16>*
  store <8 x i16> %208, <8 x i16>* %210, align 16
  %211 = sub <8 x i16> %166, %156
  %212 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  %213 = bitcast <2 x i64>* %212 to <8 x i16>*
  store <8 x i16> %211, <8 x i16>* %213, align 16
  %214 = sub <8 x i16> %160, %184
  %215 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 12
  %216 = bitcast <2 x i64>* %215 to <8 x i16>*
  store <8 x i16> %214, <8 x i16>* %216, align 16
  %217 = sub <8 x i16> %179, %180
  %218 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 13
  %219 = bitcast <2 x i64>* %218 to <8 x i16>*
  store <8 x i16> %217, <8 x i16>* %219, align 16
  %220 = sub <8 x i16> %162, %176
  %221 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 14
  %222 = bitcast <2 x i64>* %221 to <8 x i16>*
  store <8 x i16> %220, <8 x i16>* %222, align 16
  %223 = sub <8 x i16> %172, %173
  %224 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 15
  %225 = bitcast <2 x i64>* %224 to <8 x i16>*
  store <8 x i16> %223, <8 x i16>* %225, align 16
  %226 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %227 = bitcast <2 x i64>* %226 to <8 x i16>*
  %228 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %229 = bitcast <2 x i64>* %228 to <8 x i16>*
  %230 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %231 = bitcast <2 x i64>* %230 to <8 x i16>*
  %232 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %233 = bitcast <2 x i64>* %232 to <8 x i16>*
  %234 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %235 = bitcast <2 x i64>* %234 to <8 x i16>*
  %236 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %237 = bitcast <2 x i64>* %236 to <8 x i16>*
  %238 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %239 = bitcast <2 x i64>* %238 to <8 x i16>*
  %240 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %241 = bitcast <2 x i64>* %240 to <8 x i16>*
  %242 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %243 = bitcast <2 x i64>* %242 to <8 x i16>*
  %244 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %245 = bitcast <2 x i64>* %244 to <8 x i16>*
  %246 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %247 = bitcast <2 x i64>* %246 to <8 x i16>*
  %248 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %249 = bitcast <2 x i64>* %248 to <8 x i16>*
  %250 = sext i32 %2 to i64
  br label %251

251:                                              ; preds = %11, %504
  %252 = phi i64 [ 0, %11 ], [ %506, %504 ]
  %253 = phi i16* [ %1, %11 ], [ %505, %504 ]
  %254 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 %252
  %255 = bitcast <2 x i64>* %254 to <8 x i16>*
  %256 = load <8 x i16>, <8 x i16>* %255, align 16
  %257 = getelementptr inbounds <2 x i64>, <2 x i64>* %254, i64 1
  %258 = bitcast <2 x i64>* %257 to <8 x i16>*
  %259 = load <8 x i16>, <8 x i16>* %258, align 16
  %260 = shufflevector <8 x i16> %256, <8 x i16> %259, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %261 = getelementptr inbounds <2 x i64>, <2 x i64>* %254, i64 2
  %262 = bitcast <2 x i64>* %261 to <8 x i16>*
  %263 = load <8 x i16>, <8 x i16>* %262, align 16
  %264 = getelementptr inbounds <2 x i64>, <2 x i64>* %254, i64 3
  %265 = bitcast <2 x i64>* %264 to <8 x i16>*
  %266 = load <8 x i16>, <8 x i16>* %265, align 16
  %267 = shufflevector <8 x i16> %263, <8 x i16> %266, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %268 = getelementptr inbounds <2 x i64>, <2 x i64>* %254, i64 4
  %269 = bitcast <2 x i64>* %268 to <8 x i16>*
  %270 = load <8 x i16>, <8 x i16>* %269, align 16
  %271 = getelementptr inbounds <2 x i64>, <2 x i64>* %254, i64 5
  %272 = bitcast <2 x i64>* %271 to <8 x i16>*
  %273 = load <8 x i16>, <8 x i16>* %272, align 16
  %274 = shufflevector <8 x i16> %270, <8 x i16> %273, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %275 = getelementptr inbounds <2 x i64>, <2 x i64>* %254, i64 6
  %276 = bitcast <2 x i64>* %275 to <8 x i16>*
  %277 = load <8 x i16>, <8 x i16>* %276, align 16
  %278 = getelementptr inbounds <2 x i64>, <2 x i64>* %254, i64 7
  %279 = bitcast <2 x i64>* %278 to <8 x i16>*
  %280 = load <8 x i16>, <8 x i16>* %279, align 16
  %281 = shufflevector <8 x i16> %277, <8 x i16> %280, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %282 = bitcast <8 x i16> %260 to <4 x i32>
  %283 = bitcast <8 x i16> %267 to <4 x i32>
  %284 = shufflevector <4 x i32> %282, <4 x i32> %283, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %285 = bitcast <4 x i32> %284 to <2 x i64>
  %286 = bitcast <8 x i16> %274 to <4 x i32>
  %287 = bitcast <8 x i16> %281 to <4 x i32>
  %288 = shufflevector <4 x i32> %286, <4 x i32> %287, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %289 = bitcast <4 x i32> %288 to <2 x i64>
  %290 = shufflevector <4 x i32> %282, <4 x i32> %283, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %291 = bitcast <4 x i32> %290 to <2 x i64>
  %292 = shufflevector <4 x i32> %286, <4 x i32> %287, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %293 = bitcast <4 x i32> %292 to <2 x i64>
  %294 = shufflevector <2 x i64> %285, <2 x i64> %289, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %294, <2 x i64>* %24, align 16
  %295 = shufflevector <2 x i64> %285, <2 x i64> %289, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %295, <2 x i64>* %33, align 16
  %296 = shufflevector <2 x i64> %291, <2 x i64> %293, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %296, <2 x i64>* %42, align 16
  %297 = shufflevector <2 x i64> %291, <2 x i64> %293, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %297, <2 x i64>* %51, align 16
  %298 = bitcast <2 x i64> %295 to <8 x i16>
  %299 = shufflevector <8 x i16> %298, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %300 = shufflevector <8 x i16> %298, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %301 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %299, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #5
  %302 = add <4 x i32> %301, <i32 8192, i32 8192, i32 8192, i32 8192>
  %303 = ashr <4 x i32> %302, <i32 14, i32 14, i32 14, i32 14>
  %304 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %300, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #5
  %305 = add <4 x i32> %304, <i32 8192, i32 8192, i32 8192, i32 8192>
  %306 = ashr <4 x i32> %305, <i32 14, i32 14, i32 14, i32 14>
  %307 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %303, <4 x i32> %306) #5
  %308 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %299, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #5
  %309 = add <4 x i32> %308, <i32 8192, i32 8192, i32 8192, i32 8192>
  %310 = ashr <4 x i32> %309, <i32 14, i32 14, i32 14, i32 14>
  %311 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %300, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #5
  %312 = add <4 x i32> %311, <i32 8192, i32 8192, i32 8192, i32 8192>
  %313 = ashr <4 x i32> %312, <i32 14, i32 14, i32 14, i32 14>
  %314 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %310, <4 x i32> %313) #5
  %315 = bitcast <2 x i64> %297 to <8 x i16>
  %316 = shufflevector <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i16> %315, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %317 = shufflevector <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i16> %315, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %318 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %316, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #5
  %319 = add <4 x i32> %318, <i32 8192, i32 8192, i32 8192, i32 8192>
  %320 = ashr <4 x i32> %319, <i32 14, i32 14, i32 14, i32 14>
  %321 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %317, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #5
  %322 = add <4 x i32> %321, <i32 8192, i32 8192, i32 8192, i32 8192>
  %323 = ashr <4 x i32> %322, <i32 14, i32 14, i32 14, i32 14>
  %324 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %320, <4 x i32> %323) #5
  %325 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %316, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #5
  %326 = add <4 x i32> %325, <i32 8192, i32 8192, i32 8192, i32 8192>
  %327 = ashr <4 x i32> %326, <i32 14, i32 14, i32 14, i32 14>
  %328 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %317, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #5
  %329 = add <4 x i32> %328, <i32 8192, i32 8192, i32 8192, i32 8192>
  %330 = ashr <4 x i32> %329, <i32 14, i32 14, i32 14, i32 14>
  %331 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %327, <4 x i32> %330) #5
  %332 = bitcast <2 x i64> %296 to <8 x i16>
  %333 = shufflevector <8 x i16> %332, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %334 = shufflevector <8 x i16> %332, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %335 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %333, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #5
  %336 = add <4 x i32> %335, <i32 8192, i32 8192, i32 8192, i32 8192>
  %337 = ashr <4 x i32> %336, <i32 14, i32 14, i32 14, i32 14>
  %338 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %334, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #5
  %339 = add <4 x i32> %338, <i32 8192, i32 8192, i32 8192, i32 8192>
  %340 = ashr <4 x i32> %339, <i32 14, i32 14, i32 14, i32 14>
  %341 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %337, <4 x i32> %340) #5
  %342 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %333, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #5
  %343 = add <4 x i32> %342, <i32 8192, i32 8192, i32 8192, i32 8192>
  %344 = ashr <4 x i32> %343, <i32 14, i32 14, i32 14, i32 14>
  %345 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %334, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #5
  %346 = add <4 x i32> %345, <i32 8192, i32 8192, i32 8192, i32 8192>
  %347 = ashr <4 x i32> %346, <i32 14, i32 14, i32 14, i32 14>
  %348 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %344, <4 x i32> %347) #5
  %349 = bitcast <2 x i64> %294 to <8 x i16>
  %350 = shufflevector <8 x i16> %349, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %351 = shufflevector <8 x i16> %349, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %352 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %350, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %353 = add <4 x i32> %352, <i32 8192, i32 8192, i32 8192, i32 8192>
  %354 = ashr <4 x i32> %353, <i32 14, i32 14, i32 14, i32 14>
  %355 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %351, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %356 = add <4 x i32> %355, <i32 8192, i32 8192, i32 8192, i32 8192>
  %357 = ashr <4 x i32> %356, <i32 14, i32 14, i32 14, i32 14>
  %358 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %354, <4 x i32> %357) #5
  %359 = shufflevector <8 x i16> %314, <8 x i16> %307, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %360 = shufflevector <8 x i16> %314, <8 x i16> %307, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %361 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %359, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #5
  %362 = add <4 x i32> %361, <i32 8192, i32 8192, i32 8192, i32 8192>
  %363 = ashr <4 x i32> %362, <i32 14, i32 14, i32 14, i32 14>
  %364 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %360, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #5
  %365 = add <4 x i32> %364, <i32 8192, i32 8192, i32 8192, i32 8192>
  %366 = ashr <4 x i32> %365, <i32 14, i32 14, i32 14, i32 14>
  %367 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %363, <4 x i32> %366) #5
  %368 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %359, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #5
  %369 = add <4 x i32> %368, <i32 8192, i32 8192, i32 8192, i32 8192>
  %370 = ashr <4 x i32> %369, <i32 14, i32 14, i32 14, i32 14>
  %371 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %360, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #5
  %372 = add <4 x i32> %371, <i32 8192, i32 8192, i32 8192, i32 8192>
  %373 = ashr <4 x i32> %372, <i32 14, i32 14, i32 14, i32 14>
  %374 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %370, <4 x i32> %373) #5
  %375 = shufflevector <8 x i16> %324, <8 x i16> %331, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %376 = shufflevector <8 x i16> %324, <8 x i16> %331, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %377 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %375, <8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>) #5
  %378 = add <4 x i32> %377, <i32 8192, i32 8192, i32 8192, i32 8192>
  %379 = ashr <4 x i32> %378, <i32 14, i32 14, i32 14, i32 14>
  %380 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %376, <8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>) #5
  %381 = add <4 x i32> %380, <i32 8192, i32 8192, i32 8192, i32 8192>
  %382 = ashr <4 x i32> %381, <i32 14, i32 14, i32 14, i32 14>
  %383 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %379, <4 x i32> %382) #5
  %384 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %375, <8 x i16> <i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137>) #5
  %385 = add <4 x i32> %384, <i32 8192, i32 8192, i32 8192, i32 8192>
  %386 = ashr <4 x i32> %385, <i32 14, i32 14, i32 14, i32 14>
  %387 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %376, <8 x i16> <i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137>) #5
  %388 = add <4 x i32> %387, <i32 8192, i32 8192, i32 8192, i32 8192>
  %389 = ashr <4 x i32> %388, <i32 14, i32 14, i32 14, i32 14>
  %390 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %386, <4 x i32> %389) #5
  %391 = shufflevector <8 x i16> %348, <8 x i16> %341, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %392 = shufflevector <8 x i16> %348, <8 x i16> %341, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %393 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %391, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %394 = add <4 x i32> %393, <i32 8192, i32 8192, i32 8192, i32 8192>
  %395 = ashr <4 x i32> %394, <i32 14, i32 14, i32 14, i32 14>
  %396 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %392, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %397 = add <4 x i32> %396, <i32 8192, i32 8192, i32 8192, i32 8192>
  %398 = ashr <4 x i32> %397, <i32 14, i32 14, i32 14, i32 14>
  %399 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %395, <4 x i32> %398) #5
  %400 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %391, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %401 = add <4 x i32> %400, <i32 8192, i32 8192, i32 8192, i32 8192>
  %402 = ashr <4 x i32> %401, <i32 14, i32 14, i32 14, i32 14>
  %403 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %392, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %404 = add <4 x i32> %403, <i32 8192, i32 8192, i32 8192, i32 8192>
  %405 = ashr <4 x i32> %404, <i32 14, i32 14, i32 14, i32 14>
  %406 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %402, <4 x i32> %405) #5
  %407 = add <8 x i16> %324, %307
  %408 = add <8 x i16> %390, %367
  %409 = sub <8 x i16> %367, %390
  %410 = sub <8 x i16> %307, %324
  %411 = sub <8 x i16> %314, %331
  %412 = sub <8 x i16> %374, %383
  %413 = add <8 x i16> %383, %374
  %414 = add <8 x i16> %331, %314
  %415 = add <8 x i16> %358, %348
  %416 = add <8 x i16> %406, %358
  %417 = add <8 x i16> %399, %358
  %418 = add <8 x i16> %358, %341
  %419 = sub <8 x i16> %358, %341
  %420 = sub <8 x i16> %358, %399
  %421 = sub <8 x i16> %358, %406
  %422 = sub <8 x i16> %358, %348
  %423 = shufflevector <8 x i16> %412, <8 x i16> %409, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %424 = shufflevector <8 x i16> %412, <8 x i16> %409, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %425 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %423, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %426 = add <4 x i32> %425, <i32 8192, i32 8192, i32 8192, i32 8192>
  %427 = ashr <4 x i32> %426, <i32 14, i32 14, i32 14, i32 14>
  %428 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %424, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %429 = add <4 x i32> %428, <i32 8192, i32 8192, i32 8192, i32 8192>
  %430 = ashr <4 x i32> %429, <i32 14, i32 14, i32 14, i32 14>
  %431 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %427, <4 x i32> %430) #5
  %432 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %423, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %433 = add <4 x i32> %432, <i32 8192, i32 8192, i32 8192, i32 8192>
  %434 = ashr <4 x i32> %433, <i32 14, i32 14, i32 14, i32 14>
  %435 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %424, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %436 = add <4 x i32> %435, <i32 8192, i32 8192, i32 8192, i32 8192>
  %437 = ashr <4 x i32> %436, <i32 14, i32 14, i32 14, i32 14>
  %438 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %434, <4 x i32> %437) #5
  %439 = shufflevector <8 x i16> %411, <8 x i16> %410, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %440 = shufflevector <8 x i16> %411, <8 x i16> %410, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %441 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %439, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %442 = add <4 x i32> %441, <i32 8192, i32 8192, i32 8192, i32 8192>
  %443 = ashr <4 x i32> %442, <i32 14, i32 14, i32 14, i32 14>
  %444 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %440, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #5
  %445 = add <4 x i32> %444, <i32 8192, i32 8192, i32 8192, i32 8192>
  %446 = ashr <4 x i32> %445, <i32 14, i32 14, i32 14, i32 14>
  %447 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %443, <4 x i32> %446) #5
  %448 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %439, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %449 = add <4 x i32> %448, <i32 8192, i32 8192, i32 8192, i32 8192>
  %450 = ashr <4 x i32> %449, <i32 14, i32 14, i32 14, i32 14>
  %451 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %440, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #5
  %452 = add <4 x i32> %451, <i32 8192, i32 8192, i32 8192, i32 8192>
  %453 = ashr <4 x i32> %452, <i32 14, i32 14, i32 14, i32 14>
  %454 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %450, <4 x i32> %453) #5
  %455 = add <8 x i16> %415, %414
  store <8 x i16> %455, <8 x i16>* %25, align 16
  %456 = add <8 x i16> %416, %413
  store <8 x i16> %456, <8 x i16>* %34, align 16
  %457 = add <8 x i16> %438, %417
  store <8 x i16> %457, <8 x i16>* %43, align 16
  %458 = add <8 x i16> %454, %418
  store <8 x i16> %458, <8 x i16>* %52, align 16
  %459 = add <8 x i16> %447, %419
  store <8 x i16> %459, <8 x i16>* %227, align 16
  %460 = add <8 x i16> %431, %420
  store <8 x i16> %460, <8 x i16>* %229, align 16
  %461 = add <8 x i16> %421, %408
  store <8 x i16> %461, <8 x i16>* %231, align 16
  %462 = add <8 x i16> %422, %407
  store <8 x i16> %462, <8 x i16>* %233, align 16
  %463 = sub <8 x i16> %422, %407
  store <8 x i16> %463, <8 x i16>* %235, align 16
  %464 = sub <8 x i16> %421, %408
  store <8 x i16> %464, <8 x i16>* %237, align 16
  %465 = sub <8 x i16> %420, %431
  store <8 x i16> %465, <8 x i16>* %239, align 16
  %466 = sub <8 x i16> %419, %447
  store <8 x i16> %466, <8 x i16>* %241, align 16
  %467 = sub <8 x i16> %418, %454
  store <8 x i16> %467, <8 x i16>* %243, align 16
  %468 = sub <8 x i16> %417, %438
  store <8 x i16> %468, <8 x i16>* %245, align 16
  %469 = sub <8 x i16> %416, %413
  store <8 x i16> %469, <8 x i16>* %247, align 16
  %470 = sub <8 x i16> %415, %414
  store <8 x i16> %470, <8 x i16>* %249, align 16
  br label %471

471:                                              ; preds = %471, %251
  %472 = phi i64 [ 0, %251 ], [ %502, %471 ]
  %473 = mul nsw i64 %472, %250
  %474 = getelementptr inbounds i16, i16* %253, i64 %473
  %475 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %472
  %476 = bitcast <2 x i64>* %475 to <8 x i16>*
  %477 = load <8 x i16>, <8 x i16>* %476, align 16
  %478 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %477, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %479 = ashr <8 x i16> %478, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %480 = bitcast i16* %474 to <8 x i16>*
  %481 = load <8 x i16>, <8 x i16>* %480, align 16
  %482 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %481, <8 x i16> %479) #5
  %483 = icmp sgt <8 x i16> %482, zeroinitializer
  %484 = select <8 x i1> %483, <8 x i16> %482, <8 x i16> zeroinitializer
  %485 = icmp slt <8 x i16> %484, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %486 = select <8 x i1> %485, <8 x i16> %484, <8 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  store <8 x i16> %486, <8 x i16>* %480, align 16
  %487 = or i64 %472, 1
  %488 = mul nsw i64 %487, %250
  %489 = getelementptr inbounds i16, i16* %253, i64 %488
  %490 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %487
  %491 = bitcast <2 x i64>* %490 to <8 x i16>*
  %492 = load <8 x i16>, <8 x i16>* %491, align 16
  %493 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %492, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #5
  %494 = ashr <8 x i16> %493, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %495 = bitcast i16* %489 to <8 x i16>*
  %496 = load <8 x i16>, <8 x i16>* %495, align 16
  %497 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %496, <8 x i16> %494) #5
  %498 = icmp sgt <8 x i16> %497, zeroinitializer
  %499 = select <8 x i1> %498, <8 x i16> %497, <8 x i16> zeroinitializer
  %500 = icmp slt <8 x i16> %499, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %501 = select <8 x i1> %500, <8 x i16> %499, <8 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  store <8 x i16> %501, <8 x i16>* %495, align 16
  %502 = add nuw nsw i64 %472, 2
  %503 = icmp eq i64 %502, 16
  br i1 %503, label %504, label %471

504:                                              ; preds = %471
  %505 = getelementptr inbounds i16, i16* %253, i64 8
  %506 = add nuw nsw i64 %252, 8
  %507 = icmp ult i64 %506, 16
  br i1 %507, label %251, label %508

508:                                              ; preds = %504
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %15) #5
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %12) #5
  br label %630

509:                                              ; preds = %4
  %510 = bitcast [2 x [16 x <2 x i64>]]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %510) #5
  %511 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 0, i64 4
  %512 = bitcast <2 x i64>* %511 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %512, i8 -86, i64 448, i1 false)
  %513 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 0, i64 0
  %514 = bitcast i32* %0 to <4 x i32>*
  %515 = load <4 x i32>, <4 x i32>* %514, align 16
  %516 = getelementptr inbounds i32, i32* %0, i64 16
  %517 = bitcast i32* %516 to <4 x i32>*
  %518 = load <4 x i32>, <4 x i32>* %517, align 16
  %519 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 0, i64 1
  %520 = getelementptr inbounds i32, i32* %0, i64 32
  %521 = bitcast i32* %520 to <4 x i32>*
  %522 = load <4 x i32>, <4 x i32>* %521, align 16
  %523 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 0, i64 2
  %524 = getelementptr inbounds i32, i32* %0, i64 48
  %525 = bitcast i32* %524 to <4 x i32>*
  %526 = load <4 x i32>, <4 x i32>* %525, align 16
  %527 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 0, i64 3
  %528 = shufflevector <4 x i32> %515, <4 x i32> %518, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %529 = bitcast <4 x i32> %528 to <2 x i64>
  %530 = shufflevector <4 x i32> %522, <4 x i32> %526, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %531 = bitcast <4 x i32> %530 to <2 x i64>
  %532 = shufflevector <4 x i32> %515, <4 x i32> %518, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %533 = bitcast <4 x i32> %532 to <2 x i64>
  %534 = shufflevector <4 x i32> %522, <4 x i32> %526, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %535 = bitcast <4 x i32> %534 to <2 x i64>
  %536 = shufflevector <2 x i64> %529, <2 x i64> %531, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %536, <2 x i64>* %513, align 16
  %537 = shufflevector <2 x i64> %529, <2 x i64> %531, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %537, <2 x i64>* %519, align 16
  %538 = shufflevector <2 x i64> %533, <2 x i64> %535, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %538, <2 x i64>* %523, align 16
  %539 = shufflevector <2 x i64> %533, <2 x i64> %535, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %539, <2 x i64>* %527, align 16
  call fastcc void @highbd_idct16x16_10_4col(<2 x i64>* nonnull %513)
  %540 = getelementptr inbounds i32, i32* %0, i64 64
  %541 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 1, i64 0
  %542 = bitcast i32* %540 to <4 x i32>*
  %543 = load <4 x i32>, <4 x i32>* %542, align 16
  %544 = getelementptr inbounds i32, i32* %0, i64 80
  %545 = bitcast i32* %544 to <4 x i32>*
  %546 = load <4 x i32>, <4 x i32>* %545, align 16
  %547 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 1, i64 1
  %548 = getelementptr inbounds i32, i32* %0, i64 96
  %549 = bitcast i32* %548 to <4 x i32>*
  %550 = load <4 x i32>, <4 x i32>* %549, align 16
  %551 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 1, i64 2
  %552 = getelementptr inbounds i32, i32* %0, i64 112
  %553 = bitcast i32* %552 to <4 x i32>*
  %554 = load <4 x i32>, <4 x i32>* %553, align 16
  %555 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 1, i64 3
  %556 = shufflevector <4 x i32> %543, <4 x i32> %546, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %557 = bitcast <4 x i32> %556 to <2 x i64>
  %558 = shufflevector <4 x i32> %550, <4 x i32> %554, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %559 = bitcast <4 x i32> %558 to <2 x i64>
  %560 = shufflevector <4 x i32> %543, <4 x i32> %546, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %561 = bitcast <4 x i32> %560 to <2 x i64>
  %562 = shufflevector <4 x i32> %550, <4 x i32> %554, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %563 = bitcast <4 x i32> %562 to <2 x i64>
  %564 = shufflevector <2 x i64> %557, <2 x i64> %559, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %564, <2 x i64>* %541, align 16
  %565 = shufflevector <2 x i64> %557, <2 x i64> %559, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %565, <2 x i64>* %547, align 16
  %566 = shufflevector <2 x i64> %561, <2 x i64> %563, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %566, <2 x i64>* %551, align 16
  %567 = shufflevector <2 x i64> %561, <2 x i64> %563, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %567, <2 x i64>* %555, align 16
  call fastcc void @highbd_idct16x16_10_4col(<2 x i64>* %541)
  %568 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 0
  %569 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 1
  %570 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 2
  %571 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 3
  %572 = sext i32 %2 to i64
  br label %573

573:                                              ; preds = %509, %625
  %574 = phi i64 [ 0, %509 ], [ %627, %625 ]
  %575 = phi i16* [ %1, %509 ], [ %626, %625 ]
  %576 = getelementptr inbounds [2 x [16 x <2 x i64>]], [2 x [16 x <2 x i64>]]* %8, i64 0, i64 0, i64 %574
  %577 = bitcast <2 x i64>* %576 to <4 x i32>*
  %578 = load <4 x i32>, <4 x i32>* %577, align 16
  %579 = getelementptr inbounds <2 x i64>, <2 x i64>* %576, i64 1
  %580 = bitcast <2 x i64>* %579 to <4 x i32>*
  %581 = load <4 x i32>, <4 x i32>* %580, align 16
  %582 = shufflevector <4 x i32> %578, <4 x i32> %581, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %583 = bitcast <4 x i32> %582 to <2 x i64>
  %584 = getelementptr inbounds <2 x i64>, <2 x i64>* %576, i64 2
  %585 = bitcast <2 x i64>* %584 to <4 x i32>*
  %586 = load <4 x i32>, <4 x i32>* %585, align 16
  %587 = getelementptr inbounds <2 x i64>, <2 x i64>* %576, i64 3
  %588 = bitcast <2 x i64>* %587 to <4 x i32>*
  %589 = load <4 x i32>, <4 x i32>* %588, align 16
  %590 = shufflevector <4 x i32> %586, <4 x i32> %589, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %591 = bitcast <4 x i32> %590 to <2 x i64>
  %592 = shufflevector <4 x i32> %578, <4 x i32> %581, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %593 = bitcast <4 x i32> %592 to <2 x i64>
  %594 = shufflevector <4 x i32> %586, <4 x i32> %589, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %595 = bitcast <4 x i32> %594 to <2 x i64>
  %596 = shufflevector <2 x i64> %583, <2 x i64> %591, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %596, <2 x i64>* %568, align 16
  %597 = shufflevector <2 x i64> %583, <2 x i64> %591, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %597, <2 x i64>* %569, align 16
  %598 = shufflevector <2 x i64> %593, <2 x i64> %595, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %598, <2 x i64>* %570, align 16
  %599 = shufflevector <2 x i64> %593, <2 x i64> %595, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %599, <2 x i64>* %571, align 16
  call fastcc void @highbd_idct16x16_10_4col(<2 x i64>* nonnull %568)
  %600 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %3) #5
  %601 = add <8 x i16> %600, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  br label %602

602:                                              ; preds = %602, %573
  %603 = phi i64 [ 0, %573 ], [ %623, %602 ]
  %604 = mul nsw i64 %603, %572
  %605 = getelementptr inbounds i16, i16* %575, i64 %604
  %606 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %603
  %607 = bitcast <2 x i64>* %606 to <4 x i32>*
  %608 = load <4 x i32>, <4 x i32>* %607, align 16
  %609 = add <4 x i32> %608, <i32 32, i32 32, i32 32, i32 32>
  %610 = ashr <4 x i32> %609, <i32 6, i32 6, i32 6, i32 6>
  %611 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %610, <4 x i32> %610) #5
  %612 = bitcast i16* %605 to i64*
  %613 = load i64, i64* %612, align 1
  %614 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %613, i32 0
  %615 = bitcast <2 x i64> %614 to <8 x i16>
  %616 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %615, <8 x i16> %611) #5
  %617 = icmp sgt <8 x i16> %616, zeroinitializer
  %618 = select <8 x i1> %617, <8 x i16> %616, <8 x i16> zeroinitializer
  %619 = icmp slt <8 x i16> %618, %601
  %620 = select <8 x i1> %619, <8 x i16> %618, <8 x i16> %601
  %621 = bitcast <8 x i16> %620 to <2 x i64>
  %622 = extractelement <2 x i64> %621, i32 0
  store i64 %622, i64* %612, align 1
  %623 = add nuw nsw i64 %603, 1
  %624 = icmp eq i64 %623, 16
  br i1 %624, label %625, label %602

625:                                              ; preds = %602
  %626 = getelementptr inbounds i16, i16* %575, i64 4
  %627 = add nuw nsw i64 %574, 4
  %628 = icmp ult i64 %627, 16
  br i1 %628, label %573, label %629

629:                                              ; preds = %625
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %510) #5
  br label %630

630:                                              ; preds = %629, %508
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %9) #5
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define internal fastcc void @highbd_idct16x16_10_4col(<2 x i64>* nocapture) unnamed_addr #2 {
  %2 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %3 = bitcast <2 x i64>* %2 to <4 x i32>*
  %4 = load <4 x i32>, <4 x i32>* %3, align 16
  %5 = shufflevector <4 x i32> %4, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %6 = bitcast <4 x i32> %5 to <2 x i64>
  %7 = shufflevector <4 x i32> %4, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %8 = bitcast <4 x i32> %7 to <2 x i64>
  %9 = shl <2 x i64> %6, <i64 32, i64 32>
  %10 = ashr exact <2 x i64> %9, <i64 32, i64 32>
  %11 = mul nsw <2 x i64> %10, <i64 6424, i64 6424>
  %12 = shl <2 x i64> %8, <i64 32, i64 32>
  %13 = ashr exact <2 x i64> %12, <i64 32, i64 32>
  %14 = mul nsw <2 x i64> %13, <i64 6424, i64 6424>
  %15 = add nsw <2 x i64> %11, <i64 32768, i64 32768>
  %16 = bitcast <2 x i64> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %18 = add nsw <2 x i64> %14, <i64 32768, i64 32768>
  %19 = bitcast <2 x i64> %18 to <16 x i8>
  %20 = shufflevector <16 x i8> %19, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %21 = bitcast <16 x i8> %17 to <4 x i32>
  %22 = bitcast <16 x i8> %20 to <4 x i32>
  %23 = shufflevector <4 x i32> %21, <4 x i32> %22, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %24 = shufflevector <4 x i32> %21, <4 x i32> %22, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %25 = shufflevector <4 x i32> %23, <4 x i32> %24, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %26 = mul nsw <2 x i64> %10, <i64 65220, i64 65220>
  %27 = mul nsw <2 x i64> %13, <i64 65220, i64 65220>
  %28 = add nsw <2 x i64> %26, <i64 32768, i64 32768>
  %29 = bitcast <2 x i64> %28 to <16 x i8>
  %30 = shufflevector <16 x i8> %29, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %31 = add nsw <2 x i64> %27, <i64 32768, i64 32768>
  %32 = bitcast <2 x i64> %31 to <16 x i8>
  %33 = shufflevector <16 x i8> %32, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %34 = bitcast <16 x i8> %30 to <4 x i32>
  %35 = bitcast <16 x i8> %33 to <4 x i32>
  %36 = shufflevector <4 x i32> %34, <4 x i32> %35, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %37 = shufflevector <4 x i32> %34, <4 x i32> %35, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %38 = shufflevector <4 x i32> %36, <4 x i32> %37, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %39 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %40 = bitcast <2 x i64>* %39 to <4 x i32>*
  %41 = load <4 x i32>, <4 x i32>* %40, align 16
  %42 = shufflevector <4 x i32> %41, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %43 = bitcast <4 x i32> %42 to <2 x i64>
  %44 = shufflevector <4 x i32> %41, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %45 = bitcast <4 x i32> %44 to <2 x i64>
  %46 = shl <2 x i64> %43, <i64 32, i64 32>
  %47 = ashr exact <2 x i64> %46, <i64 32, i64 32>
  %48 = mul nsw <2 x i64> %47, <i64 -19024, i64 -19024>
  %49 = shl <2 x i64> %45, <i64 32, i64 32>
  %50 = ashr exact <2 x i64> %49, <i64 32, i64 32>
  %51 = mul nsw <2 x i64> %50, <i64 -19024, i64 -19024>
  %52 = add nsw <2 x i64> %48, <i64 32768, i64 32768>
  %53 = bitcast <2 x i64> %52 to <16 x i8>
  %54 = shufflevector <16 x i8> %53, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %55 = add nsw <2 x i64> %51, <i64 32768, i64 32768>
  %56 = bitcast <2 x i64> %55 to <16 x i8>
  %57 = shufflevector <16 x i8> %56, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %58 = bitcast <16 x i8> %54 to <4 x i32>
  %59 = bitcast <16 x i8> %57 to <4 x i32>
  %60 = shufflevector <4 x i32> %58, <4 x i32> %59, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %61 = shufflevector <4 x i32> %58, <4 x i32> %59, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %62 = shufflevector <4 x i32> %60, <4 x i32> %61, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %63 = mul nsw <2 x i64> %47, <i64 62716, i64 62716>
  %64 = mul nsw <2 x i64> %50, <i64 62716, i64 62716>
  %65 = add nsw <2 x i64> %63, <i64 32768, i64 32768>
  %66 = bitcast <2 x i64> %65 to <16 x i8>
  %67 = shufflevector <16 x i8> %66, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %68 = add nsw <2 x i64> %64, <i64 32768, i64 32768>
  %69 = bitcast <2 x i64> %68 to <16 x i8>
  %70 = shufflevector <16 x i8> %69, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %71 = bitcast <16 x i8> %67 to <4 x i32>
  %72 = bitcast <16 x i8> %70 to <4 x i32>
  %73 = shufflevector <4 x i32> %71, <4 x i32> %72, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %74 = shufflevector <4 x i32> %71, <4 x i32> %72, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %75 = shufflevector <4 x i32> %73, <4 x i32> %74, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %76 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %77 = bitcast <2 x i64>* %76 to <4 x i32>*
  %78 = load <4 x i32>, <4 x i32>* %77, align 16
  %79 = shufflevector <4 x i32> %78, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %80 = bitcast <4 x i32> %79 to <2 x i64>
  %81 = shufflevector <4 x i32> %78, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %82 = bitcast <4 x i32> %81 to <2 x i64>
  %83 = shl <2 x i64> %80, <i64 32, i64 32>
  %84 = ashr exact <2 x i64> %83, <i64 32, i64 32>
  %85 = mul nsw <2 x i64> %84, <i64 12784, i64 12784>
  %86 = shl <2 x i64> %82, <i64 32, i64 32>
  %87 = ashr exact <2 x i64> %86, <i64 32, i64 32>
  %88 = mul nsw <2 x i64> %87, <i64 12784, i64 12784>
  %89 = add nsw <2 x i64> %85, <i64 32768, i64 32768>
  %90 = bitcast <2 x i64> %89 to <16 x i8>
  %91 = shufflevector <16 x i8> %90, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %92 = add nsw <2 x i64> %88, <i64 32768, i64 32768>
  %93 = bitcast <2 x i64> %92 to <16 x i8>
  %94 = shufflevector <16 x i8> %93, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %95 = bitcast <16 x i8> %91 to <4 x i32>
  %96 = bitcast <16 x i8> %94 to <4 x i32>
  %97 = shufflevector <4 x i32> %95, <4 x i32> %96, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %98 = shufflevector <4 x i32> %95, <4 x i32> %96, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %99 = shufflevector <4 x i32> %97, <4 x i32> %98, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %100 = mul nsw <2 x i64> %84, <i64 64276, i64 64276>
  %101 = mul nsw <2 x i64> %87, <i64 64276, i64 64276>
  %102 = add nsw <2 x i64> %100, <i64 32768, i64 32768>
  %103 = bitcast <2 x i64> %102 to <16 x i8>
  %104 = shufflevector <16 x i8> %103, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %105 = add nsw <2 x i64> %101, <i64 32768, i64 32768>
  %106 = bitcast <2 x i64> %105 to <16 x i8>
  %107 = shufflevector <16 x i8> %106, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %108 = bitcast <16 x i8> %104 to <4 x i32>
  %109 = bitcast <16 x i8> %107 to <4 x i32>
  %110 = shufflevector <4 x i32> %108, <4 x i32> %109, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %111 = shufflevector <4 x i32> %108, <4 x i32> %109, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %112 = shufflevector <4 x i32> %110, <4 x i32> %111, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %113 = bitcast <2 x i64>* %0 to <4 x i32>*
  %114 = load <4 x i32>, <4 x i32>* %113, align 16
  %115 = shufflevector <4 x i32> %114, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %116 = bitcast <4 x i32> %115 to <2 x i64>
  %117 = shufflevector <4 x i32> %114, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = shl <2 x i64> %116, <i64 32, i64 32>
  %120 = ashr exact <2 x i64> %119, <i64 32, i64 32>
  %121 = mul nsw <2 x i64> %120, <i64 46340, i64 46340>
  %122 = shl <2 x i64> %118, <i64 32, i64 32>
  %123 = ashr exact <2 x i64> %122, <i64 32, i64 32>
  %124 = mul nsw <2 x i64> %123, <i64 46340, i64 46340>
  %125 = add nsw <2 x i64> %121, <i64 32768, i64 32768>
  %126 = bitcast <2 x i64> %125 to <16 x i8>
  %127 = shufflevector <16 x i8> %126, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %128 = add nsw <2 x i64> %124, <i64 32768, i64 32768>
  %129 = bitcast <2 x i64> %128 to <16 x i8>
  %130 = shufflevector <16 x i8> %129, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %131 = bitcast <16 x i8> %127 to <4 x i32>
  %132 = bitcast <16 x i8> %130 to <4 x i32>
  %133 = shufflevector <4 x i32> %131, <4 x i32> %132, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %134 = shufflevector <4 x i32> %131, <4 x i32> %132, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %135 = shufflevector <4 x i32> %133, <4 x i32> %134, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %136 = shufflevector <4 x i32> %38, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %137 = bitcast <4 x i32> %136 to <2 x i64>
  %138 = shufflevector <4 x i32> %38, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %139 = bitcast <4 x i32> %138 to <2 x i64>
  %140 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %141 = bitcast <4 x i32> %140 to <2 x i64>
  %142 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %143 = bitcast <4 x i32> %142 to <2 x i64>
  %144 = shl <2 x i64> %137, <i64 32, i64 32>
  %145 = ashr exact <2 x i64> %144, <i64 32, i64 32>
  %146 = mul nsw <2 x i64> %145, <i64 60548, i64 60548>
  %147 = shl <2 x i64> %139, <i64 32, i64 32>
  %148 = ashr exact <2 x i64> %147, <i64 32, i64 32>
  %149 = mul nsw <2 x i64> %148, <i64 60548, i64 60548>
  %150 = mul nsw <2 x i64> %145, <i64 25080, i64 25080>
  %151 = mul nsw <2 x i64> %148, <i64 25080, i64 25080>
  %152 = shl <2 x i64> %141, <i64 32, i64 32>
  %153 = ashr exact <2 x i64> %152, <i64 32, i64 32>
  %154 = mul nsw <2 x i64> %153, <i64 25080, i64 25080>
  %155 = shl <2 x i64> %143, <i64 32, i64 32>
  %156 = ashr exact <2 x i64> %155, <i64 32, i64 32>
  %157 = mul nsw <2 x i64> %156, <i64 25080, i64 25080>
  %158 = add nsw <2 x i64> %150, <i64 32768, i64 32768>
  %159 = mul nsw <2 x i64> %153, <i64 -60548, i64 -60548>
  %160 = add nsw <2 x i64> %158, %159
  %161 = bitcast <2 x i64> %160 to <16 x i8>
  %162 = shufflevector <16 x i8> %161, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %163 = add nsw <2 x i64> %151, <i64 32768, i64 32768>
  %164 = mul nsw <2 x i64> %156, <i64 -60548, i64 -60548>
  %165 = add nsw <2 x i64> %163, %164
  %166 = bitcast <2 x i64> %165 to <16 x i8>
  %167 = shufflevector <16 x i8> %166, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %168 = add nsw <2 x i64> %154, <i64 32768, i64 32768>
  %169 = add nsw <2 x i64> %168, %146
  %170 = bitcast <2 x i64> %169 to <16 x i8>
  %171 = shufflevector <16 x i8> %170, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %172 = add nsw <2 x i64> %157, <i64 32768, i64 32768>
  %173 = add nsw <2 x i64> %172, %149
  %174 = bitcast <2 x i64> %173 to <16 x i8>
  %175 = shufflevector <16 x i8> %174, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %176 = bitcast <16 x i8> %162 to <4 x i32>
  %177 = bitcast <16 x i8> %167 to <4 x i32>
  %178 = shufflevector <4 x i32> %176, <4 x i32> %177, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %179 = shufflevector <4 x i32> %176, <4 x i32> %177, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %180 = shufflevector <4 x i32> %178, <4 x i32> %179, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %181 = bitcast <16 x i8> %171 to <4 x i32>
  %182 = bitcast <16 x i8> %175 to <4 x i32>
  %183 = shufflevector <4 x i32> %181, <4 x i32> %182, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %184 = shufflevector <4 x i32> %181, <4 x i32> %182, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %185 = shufflevector <4 x i32> %183, <4 x i32> %184, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %186 = shufflevector <4 x i32> %62, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %187 = bitcast <4 x i32> %186 to <2 x i64>
  %188 = shufflevector <4 x i32> %62, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %189 = bitcast <4 x i32> %188 to <2 x i64>
  %190 = shufflevector <4 x i32> %75, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %191 = bitcast <4 x i32> %190 to <2 x i64>
  %192 = shufflevector <4 x i32> %75, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %193 = bitcast <4 x i32> %192 to <2 x i64>
  %194 = shl <2 x i64> %187, <i64 32, i64 32>
  %195 = ashr exact <2 x i64> %194, <i64 32, i64 32>
  %196 = mul nsw <2 x i64> %195, <i64 -25080, i64 -25080>
  %197 = shl <2 x i64> %189, <i64 32, i64 32>
  %198 = ashr exact <2 x i64> %197, <i64 32, i64 32>
  %199 = mul nsw <2 x i64> %198, <i64 -25080, i64 -25080>
  %200 = mul nsw <2 x i64> %195, <i64 -60548, i64 -60548>
  %201 = mul nsw <2 x i64> %198, <i64 -60548, i64 -60548>
  %202 = shl <2 x i64> %191, <i64 32, i64 32>
  %203 = ashr exact <2 x i64> %202, <i64 32, i64 32>
  %204 = mul nsw <2 x i64> %203, <i64 -60548, i64 -60548>
  %205 = shl <2 x i64> %193, <i64 32, i64 32>
  %206 = ashr exact <2 x i64> %205, <i64 32, i64 32>
  %207 = mul nsw <2 x i64> %206, <i64 -60548, i64 -60548>
  %208 = add nsw <2 x i64> %200, <i64 32768, i64 32768>
  %209 = mul nsw <2 x i64> %203, <i64 25080, i64 25080>
  %210 = add nsw <2 x i64> %208, %209
  %211 = bitcast <2 x i64> %210 to <16 x i8>
  %212 = shufflevector <16 x i8> %211, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %213 = add nsw <2 x i64> %201, <i64 32768, i64 32768>
  %214 = mul nsw <2 x i64> %206, <i64 25080, i64 25080>
  %215 = add nsw <2 x i64> %213, %214
  %216 = bitcast <2 x i64> %215 to <16 x i8>
  %217 = shufflevector <16 x i8> %216, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %218 = add nsw <2 x i64> %204, <i64 32768, i64 32768>
  %219 = add nsw <2 x i64> %218, %196
  %220 = bitcast <2 x i64> %219 to <16 x i8>
  %221 = shufflevector <16 x i8> %220, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %222 = add nsw <2 x i64> %207, <i64 32768, i64 32768>
  %223 = add nsw <2 x i64> %222, %199
  %224 = bitcast <2 x i64> %223 to <16 x i8>
  %225 = shufflevector <16 x i8> %224, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %226 = bitcast <16 x i8> %212 to <4 x i32>
  %227 = bitcast <16 x i8> %217 to <4 x i32>
  %228 = shufflevector <4 x i32> %226, <4 x i32> %227, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %229 = shufflevector <4 x i32> %226, <4 x i32> %227, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %230 = shufflevector <4 x i32> %228, <4 x i32> %229, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %231 = bitcast <16 x i8> %221 to <4 x i32>
  %232 = bitcast <16 x i8> %225 to <4 x i32>
  %233 = shufflevector <4 x i32> %231, <4 x i32> %232, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %234 = shufflevector <4 x i32> %231, <4 x i32> %232, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %235 = shufflevector <4 x i32> %233, <4 x i32> %234, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %236 = add <4 x i32> %99, %112
  %237 = shufflevector <4 x i32> %236, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %238 = bitcast <4 x i32> %237 to <2 x i64>
  %239 = shufflevector <4 x i32> %236, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %240 = bitcast <4 x i32> %239 to <2 x i64>
  %241 = shl <2 x i64> %238, <i64 32, i64 32>
  %242 = ashr exact <2 x i64> %241, <i64 32, i64 32>
  %243 = mul nsw <2 x i64> %242, <i64 46340, i64 46340>
  %244 = shl <2 x i64> %240, <i64 32, i64 32>
  %245 = ashr exact <2 x i64> %244, <i64 32, i64 32>
  %246 = mul nsw <2 x i64> %245, <i64 46340, i64 46340>
  %247 = add nsw <2 x i64> %243, <i64 32768, i64 32768>
  %248 = bitcast <2 x i64> %247 to <16 x i8>
  %249 = shufflevector <16 x i8> %248, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %250 = add nsw <2 x i64> %246, <i64 32768, i64 32768>
  %251 = bitcast <2 x i64> %250 to <16 x i8>
  %252 = shufflevector <16 x i8> %251, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %253 = bitcast <16 x i8> %249 to <4 x i32>
  %254 = bitcast <16 x i8> %252 to <4 x i32>
  %255 = shufflevector <4 x i32> %253, <4 x i32> %254, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %256 = shufflevector <4 x i32> %253, <4 x i32> %254, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %257 = shufflevector <4 x i32> %255, <4 x i32> %256, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %258 = sub <4 x i32> %112, %99
  %259 = shufflevector <4 x i32> %258, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %260 = bitcast <4 x i32> %259 to <2 x i64>
  %261 = shufflevector <4 x i32> %258, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %262 = bitcast <4 x i32> %261 to <2 x i64>
  %263 = shl <2 x i64> %260, <i64 32, i64 32>
  %264 = ashr exact <2 x i64> %263, <i64 32, i64 32>
  %265 = mul nsw <2 x i64> %264, <i64 46340, i64 46340>
  %266 = shl <2 x i64> %262, <i64 32, i64 32>
  %267 = ashr exact <2 x i64> %266, <i64 32, i64 32>
  %268 = mul nsw <2 x i64> %267, <i64 46340, i64 46340>
  %269 = add nsw <2 x i64> %265, <i64 32768, i64 32768>
  %270 = bitcast <2 x i64> %269 to <16 x i8>
  %271 = shufflevector <16 x i8> %270, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %272 = add nsw <2 x i64> %268, <i64 32768, i64 32768>
  %273 = bitcast <2 x i64> %272 to <16 x i8>
  %274 = shufflevector <16 x i8> %273, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %275 = bitcast <16 x i8> %271 to <4 x i32>
  %276 = bitcast <16 x i8> %274 to <4 x i32>
  %277 = shufflevector <4 x i32> %275, <4 x i32> %276, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %278 = shufflevector <4 x i32> %275, <4 x i32> %276, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %279 = shufflevector <4 x i32> %277, <4 x i32> %278, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %280 = add <4 x i32> %62, %25
  %281 = add <4 x i32> %235, %180
  %282 = sub <4 x i32> %180, %235
  %283 = sub <4 x i32> %25, %62
  %284 = sub <4 x i32> %38, %75
  %285 = sub <4 x i32> %185, %230
  %286 = add <4 x i32> %230, %185
  %287 = add <4 x i32> %75, %38
  %288 = add <4 x i32> %135, %112
  %289 = add <4 x i32> %257, %135
  %290 = add <4 x i32> %279, %135
  %291 = add <4 x i32> %135, %99
  %292 = sub <4 x i32> %135, %99
  %293 = sub <4 x i32> %135, %279
  %294 = sub <4 x i32> %135, %257
  %295 = sub <4 x i32> %135, %112
  %296 = add <4 x i32> %282, %285
  %297 = shufflevector <4 x i32> %296, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %298 = bitcast <4 x i32> %297 to <2 x i64>
  %299 = shufflevector <4 x i32> %296, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %300 = bitcast <4 x i32> %299 to <2 x i64>
  %301 = shl <2 x i64> %298, <i64 32, i64 32>
  %302 = ashr exact <2 x i64> %301, <i64 32, i64 32>
  %303 = mul nsw <2 x i64> %302, <i64 46340, i64 46340>
  %304 = shl <2 x i64> %300, <i64 32, i64 32>
  %305 = ashr exact <2 x i64> %304, <i64 32, i64 32>
  %306 = mul nsw <2 x i64> %305, <i64 46340, i64 46340>
  %307 = add nsw <2 x i64> %303, <i64 32768, i64 32768>
  %308 = bitcast <2 x i64> %307 to <16 x i8>
  %309 = shufflevector <16 x i8> %308, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %310 = add nsw <2 x i64> %306, <i64 32768, i64 32768>
  %311 = bitcast <2 x i64> %310 to <16 x i8>
  %312 = shufflevector <16 x i8> %311, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %313 = bitcast <16 x i8> %309 to <4 x i32>
  %314 = bitcast <16 x i8> %312 to <4 x i32>
  %315 = shufflevector <4 x i32> %313, <4 x i32> %314, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %316 = shufflevector <4 x i32> %313, <4 x i32> %314, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %317 = shufflevector <4 x i32> %315, <4 x i32> %316, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %318 = sub <4 x i32> %285, %282
  %319 = shufflevector <4 x i32> %318, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %320 = bitcast <4 x i32> %319 to <2 x i64>
  %321 = shufflevector <4 x i32> %318, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %322 = bitcast <4 x i32> %321 to <2 x i64>
  %323 = shl <2 x i64> %320, <i64 32, i64 32>
  %324 = ashr exact <2 x i64> %323, <i64 32, i64 32>
  %325 = mul nsw <2 x i64> %324, <i64 46340, i64 46340>
  %326 = shl <2 x i64> %322, <i64 32, i64 32>
  %327 = ashr exact <2 x i64> %326, <i64 32, i64 32>
  %328 = mul nsw <2 x i64> %327, <i64 46340, i64 46340>
  %329 = add nsw <2 x i64> %325, <i64 32768, i64 32768>
  %330 = bitcast <2 x i64> %329 to <16 x i8>
  %331 = shufflevector <16 x i8> %330, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %332 = add nsw <2 x i64> %328, <i64 32768, i64 32768>
  %333 = bitcast <2 x i64> %332 to <16 x i8>
  %334 = shufflevector <16 x i8> %333, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %335 = bitcast <16 x i8> %331 to <4 x i32>
  %336 = bitcast <16 x i8> %334 to <4 x i32>
  %337 = shufflevector <4 x i32> %335, <4 x i32> %336, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %338 = shufflevector <4 x i32> %335, <4 x i32> %336, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %339 = shufflevector <4 x i32> %337, <4 x i32> %338, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %340 = add <4 x i32> %283, %284
  %341 = shufflevector <4 x i32> %340, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %342 = bitcast <4 x i32> %341 to <2 x i64>
  %343 = shufflevector <4 x i32> %340, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %344 = bitcast <4 x i32> %343 to <2 x i64>
  %345 = shl <2 x i64> %342, <i64 32, i64 32>
  %346 = ashr exact <2 x i64> %345, <i64 32, i64 32>
  %347 = mul nsw <2 x i64> %346, <i64 46340, i64 46340>
  %348 = shl <2 x i64> %344, <i64 32, i64 32>
  %349 = ashr exact <2 x i64> %348, <i64 32, i64 32>
  %350 = mul nsw <2 x i64> %349, <i64 46340, i64 46340>
  %351 = add nsw <2 x i64> %347, <i64 32768, i64 32768>
  %352 = bitcast <2 x i64> %351 to <16 x i8>
  %353 = shufflevector <16 x i8> %352, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %354 = add nsw <2 x i64> %350, <i64 32768, i64 32768>
  %355 = bitcast <2 x i64> %354 to <16 x i8>
  %356 = shufflevector <16 x i8> %355, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %357 = bitcast <16 x i8> %353 to <4 x i32>
  %358 = bitcast <16 x i8> %356 to <4 x i32>
  %359 = shufflevector <4 x i32> %357, <4 x i32> %358, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %360 = shufflevector <4 x i32> %357, <4 x i32> %358, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %361 = shufflevector <4 x i32> %359, <4 x i32> %360, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %362 = sub <4 x i32> %284, %283
  %363 = shufflevector <4 x i32> %362, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %364 = bitcast <4 x i32> %363 to <2 x i64>
  %365 = shufflevector <4 x i32> %362, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %366 = bitcast <4 x i32> %365 to <2 x i64>
  %367 = shl <2 x i64> %364, <i64 32, i64 32>
  %368 = ashr exact <2 x i64> %367, <i64 32, i64 32>
  %369 = mul nsw <2 x i64> %368, <i64 46340, i64 46340>
  %370 = shl <2 x i64> %366, <i64 32, i64 32>
  %371 = ashr exact <2 x i64> %370, <i64 32, i64 32>
  %372 = mul nsw <2 x i64> %371, <i64 46340, i64 46340>
  %373 = add nsw <2 x i64> %369, <i64 32768, i64 32768>
  %374 = bitcast <2 x i64> %373 to <16 x i8>
  %375 = shufflevector <16 x i8> %374, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %376 = add nsw <2 x i64> %372, <i64 32768, i64 32768>
  %377 = bitcast <2 x i64> %376 to <16 x i8>
  %378 = shufflevector <16 x i8> %377, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %379 = bitcast <16 x i8> %375 to <4 x i32>
  %380 = bitcast <16 x i8> %378 to <4 x i32>
  %381 = shufflevector <4 x i32> %379, <4 x i32> %380, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %382 = shufflevector <4 x i32> %379, <4 x i32> %380, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %383 = shufflevector <4 x i32> %381, <4 x i32> %382, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %384 = add <4 x i32> %288, %287
  store <4 x i32> %384, <4 x i32>* %113, align 16
  %385 = add <4 x i32> %289, %286
  store <4 x i32> %385, <4 x i32>* %3, align 16
  %386 = add <4 x i32> %317, %290
  store <4 x i32> %386, <4 x i32>* %77, align 16
  %387 = add <4 x i32> %361, %291
  store <4 x i32> %387, <4 x i32>* %40, align 16
  %388 = add <4 x i32> %383, %292
  %389 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %390 = bitcast <2 x i64>* %389 to <4 x i32>*
  store <4 x i32> %388, <4 x i32>* %390, align 16
  %391 = add <4 x i32> %339, %293
  %392 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %393 = bitcast <2 x i64>* %392 to <4 x i32>*
  store <4 x i32> %391, <4 x i32>* %393, align 16
  %394 = add <4 x i32> %294, %281
  %395 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %396 = bitcast <2 x i64>* %395 to <4 x i32>*
  store <4 x i32> %394, <4 x i32>* %396, align 16
  %397 = add <4 x i32> %295, %280
  %398 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %399 = bitcast <2 x i64>* %398 to <4 x i32>*
  store <4 x i32> %397, <4 x i32>* %399, align 16
  %400 = sub <4 x i32> %295, %280
  %401 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %402 = bitcast <2 x i64>* %401 to <4 x i32>*
  store <4 x i32> %400, <4 x i32>* %402, align 16
  %403 = sub <4 x i32> %294, %281
  %404 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %405 = bitcast <2 x i64>* %404 to <4 x i32>*
  store <4 x i32> %403, <4 x i32>* %405, align 16
  %406 = sub <4 x i32> %293, %339
  %407 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %408 = bitcast <2 x i64>* %407 to <4 x i32>*
  store <4 x i32> %406, <4 x i32>* %408, align 16
  %409 = sub <4 x i32> %292, %383
  %410 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %411 = bitcast <2 x i64>* %410 to <4 x i32>*
  store <4 x i32> %409, <4 x i32>* %411, align 16
  %412 = sub <4 x i32> %291, %361
  %413 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %414 = bitcast <2 x i64>* %413 to <4 x i32>*
  store <4 x i32> %412, <4 x i32>* %414, align 16
  %415 = sub <4 x i32> %290, %317
  %416 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %417 = bitcast <2 x i64>* %416 to <4 x i32>*
  store <4 x i32> %415, <4 x i32>* %417, align 16
  %418 = sub <4 x i32> %289, %286
  %419 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %420 = bitcast <2 x i64>* %419 to <4 x i32>*
  store <4 x i32> %418, <4 x i32>* %420, align 16
  %421 = sub <4 x i32> %288, %287
  %422 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %423 = bitcast <2 x i64>* %422 to <4 x i32>*
  store <4 x i32> %421, <4 x i32>* %423, align 16
  ret void
}

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16>, <8 x i16>) #3

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32>, <4 x i32>) #3

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16>, i32) #3

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind readnone }
attributes #4 = { nounwind readnone speculatable }
attributes #5 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
