; ModuleID = '../../third_party/libaom/source/libaom/av1/common/x86/resize_ssse3.c'
source_filename = "../../third_party/libaom/source/libaom/av1/common/x86/resize_ssse3.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%struct.InterpFilterParams = type { i16*, i16, i8 }
%struct.yv12_buffer_config = type { %union.anon, %union.anon.0, %union.anon.2, %union.anon.4, %union.anon.6, %union.anon.8, i32, [3 x i8*], i8*, i32, i8*, i64, i32, i64, i32, i32, i32, i32, i32, i32, i8, i32, i32, i32, i32, i32, i32, %struct.aom_metadata_array* }
%union.anon = type { %struct.anon }
%struct.anon = type { i32, i32 }
%union.anon.0 = type { %struct.anon.1 }
%struct.anon.1 = type { i32, i32 }
%union.anon.2 = type { %struct.anon.3 }
%struct.anon.3 = type { i32, i32 }
%union.anon.4 = type { %struct.anon.5 }
%struct.anon.5 = type { i32, i32 }
%union.anon.6 = type { %struct.anon.7 }
%struct.anon.7 = type { i32, i32 }
%union.anon.8 = type { %struct.anon.9 }
%struct.anon.9 = type { i8*, i8*, i8* }
%struct.aom_metadata_array = type { i64, %struct.aom_metadata** }
%struct.aom_metadata = type { i32, i8*, i64, i32 }

@av1_bilinear_filters = internal constant [16 x [8 x i16]] [[8 x i16] [i16 0, i16 0, i16 0, i16 128, i16 0, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 120, i16 8, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 112, i16 16, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 104, i16 24, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 96, i16 32, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 88, i16 40, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 80, i16 48, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 72, i16 56, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 64, i16 64, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 56, i16 72, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 48, i16 80, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 40, i16 88, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 32, i16 96, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 24, i16 104, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 16, i16 112, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 0, i16 8, i16 120, i16 0, i16 0, i16 0]], align 256
@av1_interp_filter_params_list = internal unnamed_addr constant [5 x %struct.InterpFilterParams] [%struct.InterpFilterParams { i16* getelementptr inbounds ([16 x [8 x i16]], [16 x [8 x i16]]* @av1_sub_pel_filters_8, i32 0, i32 0, i32 0), i16 8, i8 0 }, %struct.InterpFilterParams { i16* getelementptr inbounds ([16 x [8 x i16]], [16 x [8 x i16]]* @av1_sub_pel_filters_8smooth, i32 0, i32 0, i32 0), i16 8, i8 1 }, %struct.InterpFilterParams { i16* getelementptr inbounds ([16 x [8 x i16]], [16 x [8 x i16]]* @av1_sub_pel_filters_8sharp, i32 0, i32 0, i32 0), i16 8, i8 2 }, %struct.InterpFilterParams { i16* getelementptr inbounds ([16 x [8 x i16]], [16 x [8 x i16]]* @av1_bilinear_filters, i32 0, i32 0, i32 0), i16 8, i8 3 }, %struct.InterpFilterParams { i16* getelementptr inbounds ([16 x [12 x i16]], [16 x [12 x i16]]* @av1_sub_pel_filters_12sharp, i32 0, i32 0, i32 0), i16 12, i8 4 }], align 16
@av1_sub_pel_filters_8 = internal constant [16 x [8 x i16]] [[8 x i16] [i16 0, i16 0, i16 0, i16 128, i16 0, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 2, i16 -6, i16 126, i16 8, i16 -2, i16 0, i16 0], [8 x i16] [i16 0, i16 2, i16 -10, i16 122, i16 18, i16 -4, i16 0, i16 0], [8 x i16] [i16 0, i16 2, i16 -12, i16 116, i16 28, i16 -8, i16 2, i16 0], [8 x i16] [i16 0, i16 2, i16 -14, i16 110, i16 38, i16 -10, i16 2, i16 0], [8 x i16] [i16 0, i16 2, i16 -14, i16 102, i16 48, i16 -12, i16 2, i16 0], [8 x i16] [i16 0, i16 2, i16 -16, i16 94, i16 58, i16 -12, i16 2, i16 0], [8 x i16] [i16 0, i16 2, i16 -14, i16 84, i16 66, i16 -12, i16 2, i16 0], [8 x i16] [i16 0, i16 2, i16 -14, i16 76, i16 76, i16 -14, i16 2, i16 0], [8 x i16] [i16 0, i16 2, i16 -12, i16 66, i16 84, i16 -14, i16 2, i16 0], [8 x i16] [i16 0, i16 2, i16 -12, i16 58, i16 94, i16 -16, i16 2, i16 0], [8 x i16] [i16 0, i16 2, i16 -12, i16 48, i16 102, i16 -14, i16 2, i16 0], [8 x i16] [i16 0, i16 2, i16 -10, i16 38, i16 110, i16 -14, i16 2, i16 0], [8 x i16] [i16 0, i16 2, i16 -8, i16 28, i16 116, i16 -12, i16 2, i16 0], [8 x i16] [i16 0, i16 0, i16 -4, i16 18, i16 122, i16 -10, i16 2, i16 0], [8 x i16] [i16 0, i16 0, i16 -2, i16 8, i16 126, i16 -6, i16 2, i16 0]], align 256
@av1_sub_pel_filters_8smooth = internal constant [16 x [8 x i16]] [[8 x i16] [i16 0, i16 0, i16 0, i16 128, i16 0, i16 0, i16 0, i16 0], [8 x i16] [i16 0, i16 2, i16 28, i16 62, i16 34, i16 2, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 26, i16 62, i16 36, i16 4, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 22, i16 62, i16 40, i16 4, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 20, i16 60, i16 42, i16 6, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 18, i16 58, i16 44, i16 8, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 16, i16 56, i16 46, i16 10, i16 0, i16 0], [8 x i16] [i16 0, i16 -2, i16 16, i16 54, i16 48, i16 12, i16 0, i16 0], [8 x i16] [i16 0, i16 -2, i16 14, i16 52, i16 52, i16 14, i16 -2, i16 0], [8 x i16] [i16 0, i16 0, i16 12, i16 48, i16 54, i16 16, i16 -2, i16 0], [8 x i16] [i16 0, i16 0, i16 10, i16 46, i16 56, i16 16, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 8, i16 44, i16 58, i16 18, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 6, i16 42, i16 60, i16 20, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 4, i16 40, i16 62, i16 22, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 4, i16 36, i16 62, i16 26, i16 0, i16 0], [8 x i16] [i16 0, i16 0, i16 2, i16 34, i16 62, i16 28, i16 2, i16 0]], align 256
@av1_sub_pel_filters_8sharp = internal constant [16 x [8 x i16]] [[8 x i16] [i16 0, i16 0, i16 0, i16 128, i16 0, i16 0, i16 0, i16 0], [8 x i16] [i16 -2, i16 2, i16 -6, i16 126, i16 8, i16 -2, i16 2, i16 0], [8 x i16] [i16 -2, i16 6, i16 -12, i16 124, i16 16, i16 -6, i16 4, i16 -2], [8 x i16] [i16 -2, i16 8, i16 -18, i16 120, i16 26, i16 -10, i16 6, i16 -2], [8 x i16] [i16 -4, i16 10, i16 -22, i16 116, i16 38, i16 -14, i16 6, i16 -2], [8 x i16] [i16 -4, i16 10, i16 -22, i16 108, i16 48, i16 -18, i16 8, i16 -2], [8 x i16] [i16 -4, i16 10, i16 -24, i16 100, i16 60, i16 -20, i16 8, i16 -2], [8 x i16] [i16 -4, i16 10, i16 -24, i16 90, i16 70, i16 -22, i16 10, i16 -2], [8 x i16] [i16 -4, i16 12, i16 -24, i16 80, i16 80, i16 -24, i16 12, i16 -4], [8 x i16] [i16 -2, i16 10, i16 -22, i16 70, i16 90, i16 -24, i16 10, i16 -4], [8 x i16] [i16 -2, i16 8, i16 -20, i16 60, i16 100, i16 -24, i16 10, i16 -4], [8 x i16] [i16 -2, i16 8, i16 -18, i16 48, i16 108, i16 -22, i16 10, i16 -4], [8 x i16] [i16 -2, i16 6, i16 -14, i16 38, i16 116, i16 -22, i16 10, i16 -4], [8 x i16] [i16 -2, i16 6, i16 -10, i16 26, i16 120, i16 -18, i16 8, i16 -2], [8 x i16] [i16 -2, i16 4, i16 -6, i16 16, i16 124, i16 -12, i16 6, i16 -2], [8 x i16] [i16 0, i16 2, i16 -2, i16 8, i16 126, i16 -6, i16 2, i16 -2]], align 256
@av1_sub_pel_filters_12sharp = internal constant [16 x [12 x i16]] [[12 x i16] [i16 0, i16 0, i16 0, i16 0, i16 0, i16 128, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0], [12 x i16] [i16 0, i16 1, i16 -2, i16 3, i16 -7, i16 127, i16 8, i16 -4, i16 2, i16 -1, i16 1, i16 0], [12 x i16] [i16 -1, i16 2, i16 -3, i16 6, i16 -13, i16 124, i16 18, i16 -8, i16 4, i16 -2, i16 2, i16 -1], [12 x i16] [i16 -1, i16 3, i16 -4, i16 8, i16 -18, i16 120, i16 28, i16 -12, i16 7, i16 -4, i16 2, i16 -1], [12 x i16] [i16 -1, i16 3, i16 -6, i16 10, i16 -21, i16 115, i16 38, i16 -15, i16 8, i16 -5, i16 3, i16 -1], [12 x i16] [i16 -2, i16 4, i16 -6, i16 12, i16 -24, i16 108, i16 49, i16 -18, i16 10, i16 -6, i16 3, i16 -2], [12 x i16] [i16 -2, i16 4, i16 -7, i16 13, i16 -25, i16 100, i16 60, i16 -21, i16 11, i16 -7, i16 4, i16 -2], [12 x i16] [i16 -2, i16 4, i16 -7, i16 13, i16 -26, i16 91, i16 71, i16 -24, i16 13, i16 -7, i16 4, i16 -2], [12 x i16] [i16 -2, i16 4, i16 -7, i16 13, i16 -25, i16 81, i16 81, i16 -25, i16 13, i16 -7, i16 4, i16 -2], [12 x i16] [i16 -2, i16 4, i16 -7, i16 13, i16 -24, i16 71, i16 91, i16 -26, i16 13, i16 -7, i16 4, i16 -2], [12 x i16] [i16 -2, i16 4, i16 -7, i16 11, i16 -21, i16 60, i16 100, i16 -25, i16 13, i16 -7, i16 4, i16 -2], [12 x i16] [i16 -2, i16 3, i16 -6, i16 10, i16 -18, i16 49, i16 108, i16 -24, i16 12, i16 -6, i16 4, i16 -2], [12 x i16] [i16 -1, i16 3, i16 -5, i16 8, i16 -15, i16 38, i16 115, i16 -21, i16 10, i16 -6, i16 3, i16 -1], [12 x i16] [i16 -1, i16 2, i16 -4, i16 7, i16 -12, i16 28, i16 120, i16 -18, i16 8, i16 -4, i16 3, i16 -1], [12 x i16] [i16 -1, i16 2, i16 -2, i16 4, i16 -8, i16 18, i16 124, i16 -13, i16 6, i16 -3, i16 2, i16 -1], [12 x i16] [i16 0, i16 1, i16 -1, i16 2, i16 -4, i16 8, i16 127, i16 -7, i16 3, i16 -2, i16 1, i16 0]], align 256
@scale_plane_4_to_3_general.shuffle_filter_func_list = internal unnamed_addr constant [2 x void (i16*, <2 x i64>*)*] [void (i16*, <2 x i64>*)* @shuffle_filter_ssse3, void (i16*, <2 x i64>*)* @shuffle_filter_odd_ssse3], align 16
@scale_plane_4_to_3_general.convolve8_func_list = internal unnamed_addr constant [2 x <2 x i64> (<2 x i64>*, <2 x i64>*)*] [<2 x i64> (<2 x i64>*, <2 x i64>*)* @convolve8_8_even_offset_ssse3, <2 x i64> (<2 x i64>*, <2 x i64>*)* @convolve8_8_odd_offset_ssse3], align 16

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_resize_and_extend_frame_ssse3(%struct.yv12_buffer_config*, %struct.yv12_buffer_config*, i8 zeroext, i32, i32) local_unnamed_addr #0 {
  %6 = alloca [12 x <2 x i64>], align 16
  %7 = alloca [5 x <2 x i64>], align 16
  %8 = alloca [5 x <2 x i64>], align 16
  %9 = icmp sgt i32 %4, 0
  br i1 %9, label %10, label %2339

10:                                               ; preds = %5
  %11 = icmp slt i32 %4, 3
  %12 = select i1 %11, i32 %4, i32 3
  %13 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 2
  %14 = bitcast %union.anon.2* %13 to [2 x i32]*
  %15 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 3
  %16 = bitcast %union.anon.4* %15 to [2 x i32]*
  %17 = getelementptr inbounds %union.anon.2, %union.anon.2* %13, i64 0, i32 0, i32 0
  %18 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 2
  %19 = bitcast %union.anon.2* %18 to [2 x i32]*
  %20 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 3
  %21 = bitcast %union.anon.4* %20 to [2 x i32]*
  %22 = getelementptr inbounds %union.anon.2, %union.anon.2* %18, i64 0, i32 0, i32 0
  %23 = getelementptr inbounds %union.anon.4, %union.anon.4* %20, i64 0, i32 0, i32 0
  %24 = zext i8 %2 to i64
  %25 = getelementptr inbounds [5 x %struct.InterpFilterParams], [5 x %struct.InterpFilterParams]* @av1_interp_filter_params_list, i64 0, i64 %24, i32 0
  %26 = bitcast i16** %25 to [8 x i16]**
  %27 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 5
  %28 = bitcast %union.anon.8* %27 to [3 x i8*]*
  %29 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %0, i64 0, i32 4
  %30 = bitcast %union.anon.6* %29 to [2 x i32]*
  %31 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 5
  %32 = bitcast %union.anon.8* %31 to [3 x i8*]*
  %33 = getelementptr inbounds %struct.yv12_buffer_config, %struct.yv12_buffer_config* %1, i64 0, i32 4
  %34 = bitcast %union.anon.6* %33 to [2 x i32]*
  %35 = bitcast [12 x <2 x i64>]* %6 to i8*
  %36 = bitcast [5 x <2 x i64>]* %7 to i8*
  %37 = bitcast [5 x <2 x i64>]* %8 to i8*
  %38 = add nsw i32 %3, 21
  %39 = add nsw i32 %3, 42
  %40 = lshr i32 %38, 4
  %41 = and i32 %40, 1
  %42 = lshr i32 %39, 4
  %43 = and i32 %42, 1
  %44 = and i32 %3, 15
  %45 = zext i32 %44 to i64
  %46 = zext i32 %41 to i64
  %47 = getelementptr inbounds [2 x void (i16*, <2 x i64>*)*], [2 x void (i16*, <2 x i64>*)*]* @scale_plane_4_to_3_general.shuffle_filter_func_list, i64 0, i64 %46
  %48 = and i32 %38, 15
  %49 = zext i32 %48 to i64
  %50 = getelementptr inbounds [5 x <2 x i64>], [5 x <2 x i64>]* %7, i64 0, i64 0
  %51 = zext i32 %43 to i64
  %52 = getelementptr inbounds [2 x void (i16*, <2 x i64>*)*], [2 x void (i16*, <2 x i64>*)*]* @scale_plane_4_to_3_general.shuffle_filter_func_list, i64 0, i64 %51
  %53 = and i32 %39, 15
  %54 = zext i32 %53 to i64
  %55 = getelementptr inbounds [5 x <2 x i64>], [5 x <2 x i64>]* %8, i64 0, i64 0
  %56 = add nuw nsw i32 %41, 1
  %57 = zext i32 %56 to i64
  %58 = getelementptr inbounds [5 x <2 x i64>], [5 x <2 x i64>]* %7, i64 0, i64 %57
  %59 = bitcast <2 x i64>* %58 to <16 x i8>*
  %60 = add nuw nsw i32 %43, 1
  %61 = zext i32 %60 to i64
  %62 = getelementptr inbounds [5 x <2 x i64>], [5 x <2 x i64>]* %8, i64 0, i64 %61
  %63 = bitcast <2 x i64>* %62 to <16 x i8>*
  %64 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 0
  %65 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 1
  %66 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 2
  %67 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 3
  %68 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 4
  %69 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 5
  %70 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 6
  %71 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 7
  %72 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 8
  %73 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 9
  %74 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 10
  %75 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 11
  %76 = bitcast <2 x i64>* %66 to <16 x i8>*
  %77 = bitcast <2 x i64>* %67 to <16 x i8>*
  %78 = getelementptr inbounds [2 x <2 x i64> (<2 x i64>*, <2 x i64>*)*], [2 x <2 x i64> (<2 x i64>*, <2 x i64>*)*]* @scale_plane_4_to_3_general.convolve8_func_list, i64 0, i64 %46
  %79 = ashr i32 %38, 5
  %80 = sext i32 %79 to i64
  %81 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 %80
  %82 = getelementptr inbounds [2 x <2 x i64> (<2 x i64>*, <2 x i64>*)*], [2 x <2 x i64> (<2 x i64>*, <2 x i64>*)*]* @scale_plane_4_to_3_general.convolve8_func_list, i64 0, i64 %51
  %83 = ashr i32 %39, 5
  %84 = sext i32 %83 to i64
  %85 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 %84
  %86 = bitcast <2 x i64>* %68 to <16 x i8>*
  %87 = bitcast <2 x i64>* %69 to <16 x i8>*
  %88 = add nsw i32 %79, 2
  %89 = sext i32 %88 to i64
  %90 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 %89
  %91 = add nsw i32 %83, 2
  %92 = sext i32 %91 to i64
  %93 = getelementptr inbounds [12 x <2 x i64>], [12 x <2 x i64>]* %6, i64 0, i64 %92
  %94 = icmp eq i32 %3, 0
  %95 = icmp eq i8 %2, 3
  %96 = sext i32 %3 to i64
  %97 = getelementptr inbounds [16 x [8 x i16]], [16 x [8 x i16]]* @av1_bilinear_filters, i64 0, i64 %96, i64 3
  %98 = getelementptr inbounds [16 x [8 x i16]], [16 x [8 x i16]]* @av1_bilinear_filters, i64 0, i64 %96, i64 4
  %99 = sext i32 %12 to i64
  br label %102

100:                                              ; preds = %2335
  %101 = icmp eq i32 %2336, 0
  br i1 %101, label %2339, label %2340

102:                                              ; preds = %10, %2335
  %103 = phi i64 [ 0, %10 ], [ %2337, %2335 ]
  %104 = phi i32 [ 0, %10 ], [ %2336, %2335 ]
  %105 = icmp ne i64 %103, 0
  %106 = zext i1 %105 to i64
  %107 = getelementptr inbounds [2 x i32], [2 x i32]* %14, i64 0, i64 %106
  %108 = load i32, i32* %107, align 4
  %109 = getelementptr inbounds [2 x i32], [2 x i32]* %16, i64 0, i64 %106
  %110 = load i32, i32* %109, align 4
  %111 = load i32, i32* %17, align 8
  %112 = getelementptr inbounds [2 x i32], [2 x i32]* %19, i64 0, i64 %106
  %113 = load i32, i32* %112, align 4
  %114 = getelementptr inbounds [2 x i32], [2 x i32]* %21, i64 0, i64 %106
  %115 = load i32, i32* %114, align 4
  %116 = load i32, i32* %22, align 8
  %117 = add nsw i32 %116, 1
  %118 = and i32 %117, -2
  %119 = load i32, i32* %23, align 8
  %120 = add nsw i32 %119, 1
  %121 = and i32 %120, -2
  %122 = shl nsw i32 %113, 1
  %123 = icmp eq i32 %122, %108
  %124 = shl i32 %115, 1
  %125 = icmp eq i32 %124, %110
  %126 = and i1 %123, %125
  br i1 %126, label %127, label %662

127:                                              ; preds = %102
  br i1 %94, label %128, label %207

128:                                              ; preds = %127
  %129 = getelementptr inbounds [3 x i8*], [3 x i8*]* %28, i64 0, i64 %103
  %130 = load i8*, i8** %129, align 8
  %131 = getelementptr inbounds [2 x i32], [2 x i32]* %30, i64 0, i64 %106
  %132 = load i32, i32* %131, align 4
  %133 = sext i32 %132 to i64
  %134 = getelementptr inbounds [3 x i8*], [3 x i8*]* %32, i64 0, i64 %103
  %135 = load i8*, i8** %134, align 8
  %136 = getelementptr inbounds [2 x i32], [2 x i32]* %34, i64 0, i64 %106
  %137 = load i32, i32* %136, align 4
  %138 = sext i32 %137 to i64
  %139 = add nsw i32 %113, 15
  %140 = and i32 %139, -16
  %141 = sext i32 %140 to i64
  %142 = sub nsw i64 %133, %141
  %143 = shl nsw i64 %142, 1
  %144 = sub nsw i64 %138, %141
  %145 = add nsw i32 %140, -16
  %146 = and i32 %145, 16
  %147 = icmp eq i32 %146, 0
  %148 = add nsw i32 %140, -16
  %149 = icmp eq i32 %145, 0
  br label %150

150:                                              ; preds = %200, %128
  %151 = phi i8* [ %135, %128 ], [ %204, %200 ]
  %152 = phi i32 [ %115, %128 ], [ %205, %200 ]
  %153 = phi i8* [ %130, %128 ], [ %203, %200 ]
  br i1 %147, label %154, label %166

154:                                              ; preds = %150
  %155 = bitcast i8* %153 to <8 x i16>*
  %156 = load <8 x i16>, <8 x i16>* %155, align 1
  %157 = getelementptr inbounds i8, i8* %153, i64 16
  %158 = bitcast i8* %157 to <8 x i16>*
  %159 = load <8 x i16>, <8 x i16>* %158, align 1
  %160 = and <8 x i16> %156, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %161 = and <8 x i16> %159, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %162 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %160, <8 x i16> %161) #9
  %163 = bitcast i8* %151 to <16 x i8>*
  store <16 x i8> %162, <16 x i8>* %163, align 1
  %164 = getelementptr inbounds i8, i8* %153, i64 32
  %165 = getelementptr inbounds i8, i8* %151, i64 16
  br label %166

166:                                              ; preds = %154, %150
  %167 = phi i8* [ %164, %154 ], [ undef, %150 ]
  %168 = phi i8* [ %165, %154 ], [ undef, %150 ]
  %169 = phi i8* [ %165, %154 ], [ %151, %150 ]
  %170 = phi i32 [ %148, %154 ], [ %140, %150 ]
  %171 = phi i8* [ %164, %154 ], [ %153, %150 ]
  br i1 %149, label %200, label %172

172:                                              ; preds = %166, %172
  %173 = phi i8* [ %197, %172 ], [ %169, %166 ]
  %174 = phi i32 [ %198, %172 ], [ %170, %166 ]
  %175 = phi i8* [ %196, %172 ], [ %171, %166 ]
  %176 = bitcast i8* %175 to <8 x i16>*
  %177 = load <8 x i16>, <8 x i16>* %176, align 1
  %178 = getelementptr inbounds i8, i8* %175, i64 16
  %179 = bitcast i8* %178 to <8 x i16>*
  %180 = load <8 x i16>, <8 x i16>* %179, align 1
  %181 = and <8 x i16> %177, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %182 = and <8 x i16> %180, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %183 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %181, <8 x i16> %182) #9
  %184 = bitcast i8* %173 to <16 x i8>*
  store <16 x i8> %183, <16 x i8>* %184, align 1
  %185 = getelementptr inbounds i8, i8* %175, i64 32
  %186 = getelementptr inbounds i8, i8* %173, i64 16
  %187 = bitcast i8* %185 to <8 x i16>*
  %188 = load <8 x i16>, <8 x i16>* %187, align 1
  %189 = getelementptr inbounds i8, i8* %175, i64 48
  %190 = bitcast i8* %189 to <8 x i16>*
  %191 = load <8 x i16>, <8 x i16>* %190, align 1
  %192 = and <8 x i16> %188, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %193 = and <8 x i16> %191, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %194 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %192, <8 x i16> %193) #9
  %195 = bitcast i8* %186 to <16 x i8>*
  store <16 x i8> %194, <16 x i8>* %195, align 1
  %196 = getelementptr inbounds i8, i8* %175, i64 64
  %197 = getelementptr inbounds i8, i8* %173, i64 32
  %198 = add nsw i32 %174, -32
  %199 = icmp eq i32 %198, 0
  br i1 %199, label %200, label %172

200:                                              ; preds = %172, %166
  %201 = phi i8* [ %167, %166 ], [ %196, %172 ]
  %202 = phi i8* [ %168, %166 ], [ %197, %172 ]
  %203 = getelementptr inbounds i8, i8* %201, i64 %143
  %204 = getelementptr inbounds i8, i8* %202, i64 %144
  %205 = add nsw i32 %152, -1
  %206 = icmp eq i32 %205, 0
  br i1 %206, label %2335, label %150

207:                                              ; preds = %127
  br i1 %95, label %208, label %284

208:                                              ; preds = %207
  %209 = load i16, i16* %97, align 2
  %210 = load i16, i16* %98, align 8
  %211 = shl i16 %210, 8
  %212 = or i16 %211, %209
  %213 = insertelement <8 x i16> undef, i16 %212, i32 0
  %214 = shufflevector <8 x i16> %213, <8 x i16> undef, <8 x i32> zeroinitializer
  %215 = getelementptr inbounds [3 x i8*], [3 x i8*]* %28, i64 0, i64 %103
  %216 = load i8*, i8** %215, align 8
  %217 = getelementptr inbounds [2 x i32], [2 x i32]* %30, i64 0, i64 %106
  %218 = load i32, i32* %217, align 4
  %219 = sext i32 %218 to i64
  %220 = getelementptr inbounds [3 x i8*], [3 x i8*]* %32, i64 0, i64 %103
  %221 = load i8*, i8** %220, align 8
  %222 = getelementptr inbounds [2 x i32], [2 x i32]* %34, i64 0, i64 %106
  %223 = load i32, i32* %222, align 4
  %224 = sext i32 %223 to i64
  %225 = add nsw i32 %113, 15
  %226 = and i32 %225, -16
  %227 = sext i32 %226 to i64
  %228 = sub nsw i64 %219, %227
  %229 = shl nsw i64 %228, 1
  %230 = bitcast <8 x i16> %214 to <16 x i8>
  %231 = sub nsw i64 %224, %227
  br label %232

232:                                              ; preds = %279, %208
  %233 = phi i32 [ %115, %208 ], [ %282, %279 ]
  %234 = phi i8* [ %221, %208 ], [ %281, %279 ]
  %235 = phi i8* [ %216, %208 ], [ %280, %279 ]
  br label %236

236:                                              ; preds = %236, %232
  %237 = phi i32 [ %226, %232 ], [ %277, %236 ]
  %238 = phi i8* [ %234, %232 ], [ %276, %236 ]
  %239 = phi i8* [ %235, %232 ], [ %275, %236 ]
  %240 = bitcast i8* %239 to <16 x i8>*
  %241 = load <16 x i8>, <16 x i8>* %240, align 1
  %242 = getelementptr inbounds i8, i8* %239, i64 16
  %243 = bitcast i8* %242 to <16 x i8>*
  %244 = load <16 x i8>, <16 x i8>* %243, align 1
  %245 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %241, <16 x i8> %230) #9
  %246 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %244, <16 x i8> %230) #9
  %247 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %245, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %248 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %246, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %249 = ashr <8 x i16> %247, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %250 = ashr <8 x i16> %248, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %251 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %249, <8 x i16> %250) #9
  %252 = getelementptr inbounds i8, i8* %239, i64 %219
  %253 = bitcast i8* %252 to <16 x i8>*
  %254 = load <16 x i8>, <16 x i8>* %253, align 1
  %255 = getelementptr inbounds i8, i8* %252, i64 16
  %256 = bitcast i8* %255 to <16 x i8>*
  %257 = load <16 x i8>, <16 x i8>* %256, align 1
  %258 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %254, <16 x i8> %230) #9
  %259 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %257, <16 x i8> %230) #9
  %260 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %258, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %261 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %259, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %262 = ashr <8 x i16> %260, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %263 = ashr <8 x i16> %261, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %264 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %262, <8 x i16> %263) #9
  %265 = shufflevector <16 x i8> %251, <16 x i8> %264, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %266 = shufflevector <16 x i8> %251, <16 x i8> %264, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %267 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %265, <16 x i8> %230) #9
  %268 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %266, <16 x i8> %230) #9
  %269 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %267, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %270 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %268, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %271 = ashr <8 x i16> %269, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %272 = ashr <8 x i16> %270, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %273 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %271, <8 x i16> %272) #9
  %274 = bitcast i8* %238 to <16 x i8>*
  store <16 x i8> %273, <16 x i8>* %274, align 1
  %275 = getelementptr inbounds i8, i8* %239, i64 32
  %276 = getelementptr inbounds i8, i8* %238, i64 16
  %277 = add nsw i32 %237, -16
  %278 = icmp eq i32 %277, 0
  br i1 %278, label %279, label %236

279:                                              ; preds = %236
  %280 = getelementptr inbounds i8, i8* %275, i64 %229
  %281 = getelementptr inbounds i8, i8* %276, i64 %231
  %282 = add nsw i32 %233, -1
  %283 = icmp eq i32 %282, 0
  br i1 %283, label %2335, label %232

284:                                              ; preds = %207
  %285 = add nsw i32 %118, 3
  %286 = and i32 %285, -4
  %287 = shl i32 %121, 1
  %288 = add nsw i32 %287, 13
  %289 = and i32 %288, -8
  %290 = mul nsw i32 %289, %286
  %291 = sext i32 %290 to i64
  %292 = call noalias i8* @malloc(i64 %291) #9
  %293 = icmp eq i8* %292, null
  br i1 %293, label %2335, label %294

294:                                              ; preds = %284
  %295 = load [8 x i16]*, [8 x i16]** %26, align 16
  %296 = getelementptr inbounds [3 x i8*], [3 x i8*]* %28, i64 0, i64 %103
  %297 = load i8*, i8** %296, align 8
  %298 = getelementptr inbounds [2 x i32], [2 x i32]* %30, i64 0, i64 %106
  %299 = load i32, i32* %298, align 4
  %300 = getelementptr inbounds [3 x i8*], [3 x i8*]* %32, i64 0, i64 %103
  %301 = load i8*, i8** %300, align 8
  %302 = getelementptr inbounds [2 x i32], [2 x i32]* %34, i64 0, i64 %106
  %303 = load i32, i32* %302, align 4
  %304 = getelementptr inbounds [8 x i16], [8 x i16]* %295, i64 %96, i64 0
  %305 = add nsw i32 %113, 3
  %306 = and i32 %305, -4
  %307 = add nsw i32 %110, 13
  %308 = and i32 %307, -8
  %309 = bitcast i16* %304 to <16 x i8>*
  %310 = load <16 x i8>, <16 x i8>* %309, align 16
  %311 = shufflevector <16 x i8> %310, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2>
  %312 = shufflevector <16 x i8> %310, <16 x i8> undef, <16 x i32> <i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6>
  %313 = shufflevector <16 x i8> %310, <16 x i8> undef, <16 x i32> <i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10>
  %314 = shufflevector <16 x i8> %310, <16 x i8> undef, <16 x i32> <i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14>
  %315 = mul i32 %299, -3
  %316 = add i32 %315, -5
  %317 = sext i32 %316 to i64
  %318 = getelementptr inbounds i8, i8* %297, i64 %317
  %319 = shl nsw i32 %299, 3
  %320 = shl nsw i32 %306, 1
  %321 = sub nsw i32 %319, %320
  %322 = sext i32 %321 to i64
  %323 = sext i32 %299 to i64
  %324 = shl nsw i64 %323, 1
  %325 = mul nsw i64 %323, 3
  %326 = shl nsw i64 %323, 2
  %327 = sext i32 %320 to i64
  %328 = shl nsw i64 %327, 1
  %329 = mul nsw i64 %327, 3
  %330 = mul nsw i32 %306, 6
  %331 = sext i32 %330 to i64
  br label %332

332:                                              ; preds = %533, %294
  %333 = phi i8* [ %318, %294 ], [ %534, %533 ]
  %334 = phi i32 [ %308, %294 ], [ %536, %533 ]
  %335 = phi i8* [ %292, %294 ], [ %535, %533 ]
  %336 = getelementptr inbounds i8, i8* %333, i64 2
  %337 = bitcast i8* %336 to i64*
  %338 = load i64, i64* %337, align 1
  %339 = insertelement <2 x i64> undef, i64 %338, i32 0
  %340 = getelementptr inbounds i8, i8* %336, i64 %323
  %341 = bitcast i8* %340 to i64*
  %342 = load i64, i64* %341, align 1
  %343 = insertelement <2 x i64> undef, i64 %342, i32 0
  %344 = getelementptr inbounds i8, i8* %336, i64 %324
  %345 = bitcast i8* %344 to i64*
  %346 = load i64, i64* %345, align 1
  %347 = insertelement <2 x i64> undef, i64 %346, i32 0
  %348 = getelementptr inbounds i8, i8* %336, i64 %325
  %349 = bitcast i8* %348 to i64*
  %350 = load i64, i64* %349, align 1
  %351 = insertelement <2 x i64> undef, i64 %350, i32 0
  %352 = getelementptr inbounds i8, i8* %336, i64 %326
  %353 = bitcast i8* %352 to i64*
  %354 = load i64, i64* %353, align 1
  %355 = insertelement <2 x i64> undef, i64 %354, i32 0
  %356 = getelementptr inbounds i8, i8* %352, i64 %323
  %357 = bitcast i8* %356 to i64*
  %358 = load i64, i64* %357, align 1
  %359 = insertelement <2 x i64> undef, i64 %358, i32 0
  %360 = getelementptr inbounds i8, i8* %352, i64 %324
  %361 = bitcast i8* %360 to i64*
  %362 = load i64, i64* %361, align 1
  %363 = insertelement <2 x i64> undef, i64 %362, i32 0
  %364 = getelementptr inbounds i8, i8* %352, i64 %325
  %365 = bitcast i8* %364 to i64*
  %366 = load i64, i64* %365, align 1
  %367 = insertelement <2 x i64> undef, i64 %366, i32 0
  %368 = bitcast <2 x i64> %339 to <8 x i16>
  %369 = bitcast <2 x i64> %343 to <8 x i16>
  %370 = shufflevector <8 x i16> %368, <8 x i16> %369, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %371 = bitcast <2 x i64> %347 to <8 x i16>
  %372 = bitcast <2 x i64> %351 to <8 x i16>
  %373 = shufflevector <8 x i16> %371, <8 x i16> %372, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %374 = bitcast <2 x i64> %355 to <8 x i16>
  %375 = bitcast <2 x i64> %359 to <8 x i16>
  %376 = shufflevector <8 x i16> %374, <8 x i16> %375, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %377 = bitcast <2 x i64> %363 to <8 x i16>
  %378 = bitcast <2 x i64> %367 to <8 x i16>
  %379 = shufflevector <8 x i16> %377, <8 x i16> %378, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %380 = bitcast <8 x i16> %370 to <4 x i32>
  %381 = bitcast <8 x i16> %373 to <4 x i32>
  %382 = shufflevector <4 x i32> %380, <4 x i32> %381, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %383 = bitcast <4 x i32> %382 to <2 x i64>
  %384 = bitcast <8 x i16> %376 to <4 x i32>
  %385 = bitcast <8 x i16> %379 to <4 x i32>
  %386 = shufflevector <4 x i32> %384, <4 x i32> %385, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %387 = bitcast <4 x i32> %386 to <2 x i64>
  %388 = shufflevector <4 x i32> %380, <4 x i32> %381, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %389 = bitcast <4 x i32> %388 to <2 x i64>
  %390 = shufflevector <4 x i32> %384, <4 x i32> %385, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %391 = bitcast <4 x i32> %390 to <2 x i64>
  %392 = shufflevector <2 x i64> %383, <2 x i64> %387, <2 x i32> <i32 0, i32 2>
  %393 = shufflevector <2 x i64> %383, <2 x i64> %387, <2 x i32> <i32 1, i32 3>
  %394 = shufflevector <2 x i64> %389, <2 x i64> %391, <2 x i32> <i32 0, i32 2>
  br label %395

395:                                              ; preds = %395, %332
  %396 = phi <2 x i64> [ %394, %332 ], [ %461, %395 ]
  %397 = phi <2 x i64> [ %393, %332 ], [ %460, %395 ]
  %398 = phi <2 x i64> [ %392, %332 ], [ %459, %395 ]
  %399 = phi i8* [ %333, %332 ], [ %402, %395 ]
  %400 = phi i32 [ %306, %332 ], [ %531, %395 ]
  %401 = phi i8* [ %335, %332 ], [ %530, %395 ]
  %402 = getelementptr inbounds i8, i8* %399, i64 8
  %403 = bitcast i8* %402 to i64*
  %404 = load i64, i64* %403, align 1
  %405 = insertelement <2 x i64> undef, i64 %404, i32 0
  %406 = getelementptr inbounds i8, i8* %402, i64 %323
  %407 = bitcast i8* %406 to i64*
  %408 = load i64, i64* %407, align 1
  %409 = insertelement <2 x i64> undef, i64 %408, i32 0
  %410 = getelementptr inbounds i8, i8* %402, i64 %324
  %411 = bitcast i8* %410 to i64*
  %412 = load i64, i64* %411, align 1
  %413 = insertelement <2 x i64> undef, i64 %412, i32 0
  %414 = getelementptr inbounds i8, i8* %402, i64 %325
  %415 = bitcast i8* %414 to i64*
  %416 = load i64, i64* %415, align 1
  %417 = insertelement <2 x i64> undef, i64 %416, i32 0
  %418 = getelementptr inbounds i8, i8* %402, i64 %326
  %419 = bitcast i8* %418 to i64*
  %420 = load i64, i64* %419, align 1
  %421 = insertelement <2 x i64> undef, i64 %420, i32 0
  %422 = getelementptr inbounds i8, i8* %418, i64 %323
  %423 = bitcast i8* %422 to i64*
  %424 = load i64, i64* %423, align 1
  %425 = insertelement <2 x i64> undef, i64 %424, i32 0
  %426 = getelementptr inbounds i8, i8* %418, i64 %324
  %427 = bitcast i8* %426 to i64*
  %428 = load i64, i64* %427, align 1
  %429 = insertelement <2 x i64> undef, i64 %428, i32 0
  %430 = getelementptr inbounds i8, i8* %418, i64 %325
  %431 = bitcast i8* %430 to i64*
  %432 = load i64, i64* %431, align 1
  %433 = insertelement <2 x i64> undef, i64 %432, i32 0
  %434 = bitcast <2 x i64> %405 to <8 x i16>
  %435 = bitcast <2 x i64> %409 to <8 x i16>
  %436 = shufflevector <8 x i16> %434, <8 x i16> %435, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %437 = bitcast <2 x i64> %413 to <8 x i16>
  %438 = bitcast <2 x i64> %417 to <8 x i16>
  %439 = shufflevector <8 x i16> %437, <8 x i16> %438, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %440 = bitcast <2 x i64> %421 to <8 x i16>
  %441 = bitcast <2 x i64> %425 to <8 x i16>
  %442 = shufflevector <8 x i16> %440, <8 x i16> %441, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %443 = bitcast <2 x i64> %429 to <8 x i16>
  %444 = bitcast <2 x i64> %433 to <8 x i16>
  %445 = shufflevector <8 x i16> %443, <8 x i16> %444, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %446 = bitcast <8 x i16> %436 to <4 x i32>
  %447 = bitcast <8 x i16> %439 to <4 x i32>
  %448 = shufflevector <4 x i32> %446, <4 x i32> %447, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %449 = bitcast <4 x i32> %448 to <2 x i64>
  %450 = bitcast <8 x i16> %442 to <4 x i32>
  %451 = bitcast <8 x i16> %445 to <4 x i32>
  %452 = shufflevector <4 x i32> %450, <4 x i32> %451, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %453 = bitcast <4 x i32> %452 to <2 x i64>
  %454 = shufflevector <4 x i32> %446, <4 x i32> %447, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %455 = bitcast <4 x i32> %454 to <2 x i64>
  %456 = shufflevector <4 x i32> %450, <4 x i32> %451, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %457 = bitcast <4 x i32> %456 to <2 x i64>
  %458 = shufflevector <2 x i64> %449, <2 x i64> %453, <2 x i32> <i32 0, i32 2>
  %459 = shufflevector <2 x i64> %449, <2 x i64> %453, <2 x i32> <i32 1, i32 3>
  %460 = shufflevector <2 x i64> %455, <2 x i64> %457, <2 x i32> <i32 0, i32 2>
  %461 = shufflevector <2 x i64> %455, <2 x i64> %457, <2 x i32> <i32 1, i32 3>
  %462 = bitcast <2 x i64> %398 to <16 x i8>
  %463 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %462, <16 x i8> %311) #9
  %464 = bitcast <2 x i64> %397 to <16 x i8>
  %465 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %464, <16 x i8> %312) #9
  %466 = bitcast <2 x i64> %396 to <16 x i8>
  %467 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %466, <16 x i8> %313) #9
  %468 = bitcast <2 x i64> %458 to <16 x i8>
  %469 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %468, <16 x i8> %314) #9
  %470 = add <8 x i16> %469, %465
  %471 = add <8 x i16> %463, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %472 = add <8 x i16> %471, %467
  %473 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %472, <8 x i16> %470) #9
  %474 = ashr <8 x i16> %473, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %475 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %464, <16 x i8> %311) #9
  %476 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %466, <16 x i8> %312) #9
  %477 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %468, <16 x i8> %313) #9
  %478 = bitcast <2 x i64> %459 to <16 x i8>
  %479 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %478, <16 x i8> %314) #9
  %480 = add <8 x i16> %479, %476
  %481 = add <8 x i16> %475, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %482 = add <8 x i16> %481, %477
  %483 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %482, <8 x i16> %480) #9
  %484 = ashr <8 x i16> %483, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %485 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %466, <16 x i8> %311) #9
  %486 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %468, <16 x i8> %312) #9
  %487 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %478, <16 x i8> %313) #9
  %488 = bitcast <2 x i64> %460 to <16 x i8>
  %489 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %488, <16 x i8> %314) #9
  %490 = add <8 x i16> %489, %486
  %491 = add <8 x i16> %485, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %492 = add <8 x i16> %491, %487
  %493 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %492, <8 x i16> %490) #9
  %494 = ashr <8 x i16> %493, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %495 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %468, <16 x i8> %311) #9
  %496 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %478, <16 x i8> %312) #9
  %497 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %488, <16 x i8> %313) #9
  %498 = bitcast <2 x i64> %461 to <16 x i8>
  %499 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %498, <16 x i8> %314) #9
  %500 = add <8 x i16> %499, %496
  %501 = add <8 x i16> %495, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %502 = add <8 x i16> %501, %497
  %503 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %502, <8 x i16> %500) #9
  %504 = ashr <8 x i16> %503, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %505 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %474, <8 x i16> %494) #9
  %506 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %484, <8 x i16> %504) #9
  %507 = bitcast <16 x i8> %505 to <8 x i16>
  %508 = bitcast <16 x i8> %506 to <8 x i16>
  %509 = shufflevector <8 x i16> %507, <8 x i16> %508, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %510 = shufflevector <8 x i16> %507, <8 x i16> %508, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %511 = bitcast <8 x i16> %509 to <4 x i32>
  %512 = bitcast <8 x i16> %510 to <4 x i32>
  %513 = shufflevector <4 x i32> %511, <4 x i32> %512, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %514 = bitcast <4 x i32> %513 to <2 x i64>
  %515 = shufflevector <4 x i32> %511, <4 x i32> %512, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %516 = bitcast <4 x i32> %515 to <2 x i64>
  %517 = extractelement <2 x i64> %514, i32 0
  %518 = bitcast i8* %401 to i64*
  store i64 %517, i64* %518, align 1
  %519 = getelementptr inbounds i8, i8* %401, i64 %327
  %520 = bitcast <4 x i32> %513 to <4 x float>
  %521 = shufflevector <4 x float> %520, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %522 = bitcast i8* %519 to <2 x float>*
  store <2 x float> %521, <2 x float>* %522, align 1
  %523 = getelementptr inbounds i8, i8* %401, i64 %328
  %524 = extractelement <2 x i64> %516, i32 0
  %525 = bitcast i8* %523 to i64*
  store i64 %524, i64* %525, align 1
  %526 = getelementptr inbounds i8, i8* %401, i64 %329
  %527 = bitcast <4 x i32> %515 to <4 x float>
  %528 = shufflevector <4 x float> %527, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %529 = bitcast i8* %526 to <2 x float>*
  store <2 x float> %528, <2 x float>* %529, align 1
  %530 = getelementptr inbounds i8, i8* %401, i64 8
  %531 = add nsw i32 %400, -4
  %532 = icmp eq i32 %531, 0
  br i1 %532, label %533, label %395

533:                                              ; preds = %395
  %534 = getelementptr inbounds i8, i8* %402, i64 %322
  %535 = getelementptr inbounds i8, i8* %530, i64 %331
  %536 = add nsw i32 %334, -8
  %537 = icmp eq i32 %536, 0
  br i1 %537, label %538, label %332

538:                                              ; preds = %533
  %539 = add nsw i32 %113, 7
  %540 = add nsw i32 %115, 3
  %541 = and i32 %539, -8
  %542 = and i32 %540, -4
  %543 = shl nsw i32 %540, 1
  %544 = or i32 %543, 6
  %545 = mul nsw i32 %544, %306
  %546 = sext i32 %545 to i64
  %547 = sub nsw i64 0, %546
  %548 = shl nsw i32 %306, 2
  %549 = sext i32 %548 to i64
  %550 = shl nsw i32 %306, 3
  %551 = sext i32 %550 to i64
  %552 = sext i32 %303 to i64
  %553 = shl nsw i64 %552, 1
  %554 = mul nsw i64 %552, 3
  %555 = shl nsw i32 %303, 2
  %556 = sext i32 %555 to i64
  %557 = mul nsw i32 %303, %542
  %558 = sext i32 %557 to i64
  %559 = sub nsw i64 0, %558
  br label %560

560:                                              ; preds = %654, %538
  %561 = phi i8* [ %658, %654 ], [ %301, %538 ]
  %562 = phi i32 [ %659, %654 ], [ %541, %538 ]
  %563 = phi i8* [ %656, %654 ], [ %292, %538 ]
  %564 = bitcast i8* %563 to <2 x i64>*
  %565 = load <2 x i64>, <2 x i64>* %564, align 1
  %566 = getelementptr inbounds i8, i8* %563, i64 %327
  %567 = bitcast i8* %566 to <2 x i64>*
  %568 = load <2 x i64>, <2 x i64>* %567, align 1
  %569 = getelementptr inbounds i8, i8* %563, i64 %549
  %570 = bitcast i8* %569 to <2 x i64>*
  %571 = load <2 x i64>, <2 x i64>* %570, align 1
  %572 = getelementptr inbounds i8, i8* %563, i64 %331
  br label %573

573:                                              ; preds = %573, %560
  %574 = phi <2 x i64> [ %571, %560 ], [ %590, %573 ]
  %575 = phi <2 x i64> [ %568, %560 ], [ %587, %573 ]
  %576 = phi <2 x i64> [ %565, %560 ], [ %584, %573 ]
  %577 = phi i8* [ %561, %560 ], [ %651, %573 ]
  %578 = phi i32 [ %542, %560 ], [ %652, %573 ]
  %579 = phi i8* [ %572, %560 ], [ %591, %573 ]
  %580 = bitcast i8* %579 to <16 x i8>*
  %581 = load <16 x i8>, <16 x i8>* %580, align 1
  %582 = getelementptr inbounds i8, i8* %579, i64 %327
  %583 = bitcast i8* %582 to <2 x i64>*
  %584 = load <2 x i64>, <2 x i64>* %583, align 1
  %585 = getelementptr inbounds i8, i8* %579, i64 %328
  %586 = bitcast i8* %585 to <2 x i64>*
  %587 = load <2 x i64>, <2 x i64>* %586, align 1
  %588 = getelementptr inbounds i8, i8* %579, i64 %329
  %589 = bitcast i8* %588 to <2 x i64>*
  %590 = load <2 x i64>, <2 x i64>* %589, align 1
  %591 = getelementptr inbounds i8, i8* %579, i64 %551
  %592 = bitcast <2 x i64> %576 to <16 x i8>
  %593 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %592, <16 x i8> %311) #9
  %594 = bitcast <2 x i64> %575 to <16 x i8>
  %595 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %594, <16 x i8> %312) #9
  %596 = bitcast <2 x i64> %574 to <16 x i8>
  %597 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %596, <16 x i8> %313) #9
  %598 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %581, <16 x i8> %314) #9
  %599 = add <8 x i16> %598, %595
  %600 = add <8 x i16> %593, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %601 = add <8 x i16> %600, %597
  %602 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %601, <8 x i16> %599) #9
  %603 = ashr <8 x i16> %602, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %604 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %594, <16 x i8> %311) #9
  %605 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %596, <16 x i8> %312) #9
  %606 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %581, <16 x i8> %313) #9
  %607 = bitcast <2 x i64> %584 to <16 x i8>
  %608 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %607, <16 x i8> %314) #9
  %609 = add <8 x i16> %608, %605
  %610 = add <8 x i16> %604, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %611 = add <8 x i16> %610, %606
  %612 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %611, <8 x i16> %609) #9
  %613 = ashr <8 x i16> %612, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %614 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %596, <16 x i8> %311) #9
  %615 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %581, <16 x i8> %312) #9
  %616 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %607, <16 x i8> %313) #9
  %617 = bitcast <2 x i64> %587 to <16 x i8>
  %618 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %617, <16 x i8> %314) #9
  %619 = add <8 x i16> %618, %615
  %620 = add <8 x i16> %614, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %621 = add <8 x i16> %620, %616
  %622 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %621, <8 x i16> %619) #9
  %623 = ashr <8 x i16> %622, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %624 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %581, <16 x i8> %311) #9
  %625 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %607, <16 x i8> %312) #9
  %626 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %617, <16 x i8> %313) #9
  %627 = bitcast <2 x i64> %590 to <16 x i8>
  %628 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %627, <16 x i8> %314) #9
  %629 = add <8 x i16> %628, %625
  %630 = add <8 x i16> %624, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %631 = add <8 x i16> %630, %626
  %632 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %631, <8 x i16> %629) #9
  %633 = ashr <8 x i16> %632, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %634 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %603, <8 x i16> %613) #9
  %635 = bitcast <16 x i8> %634 to <2 x i64>
  %636 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %623, <8 x i16> %633) #9
  %637 = bitcast <16 x i8> %636 to <2 x i64>
  %638 = extractelement <2 x i64> %635, i32 0
  %639 = bitcast i8* %577 to i64*
  store i64 %638, i64* %639, align 1
  %640 = getelementptr inbounds i8, i8* %577, i64 %552
  %641 = bitcast <16 x i8> %634 to <4 x float>
  %642 = shufflevector <4 x float> %641, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %643 = bitcast i8* %640 to <2 x float>*
  store <2 x float> %642, <2 x float>* %643, align 1
  %644 = getelementptr inbounds i8, i8* %577, i64 %553
  %645 = extractelement <2 x i64> %637, i32 0
  %646 = bitcast i8* %644 to i64*
  store i64 %645, i64* %646, align 1
  %647 = getelementptr inbounds i8, i8* %577, i64 %554
  %648 = bitcast <16 x i8> %636 to <4 x float>
  %649 = shufflevector <4 x float> %648, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %650 = bitcast i8* %647 to <2 x float>*
  store <2 x float> %649, <2 x float>* %650, align 1
  %651 = getelementptr inbounds i8, i8* %577, i64 %556
  %652 = add nsw i32 %578, -4
  %653 = icmp eq i32 %652, 0
  br i1 %653, label %654, label %573

654:                                              ; preds = %573
  %655 = getelementptr inbounds i8, i8* %591, i64 16
  %656 = getelementptr inbounds i8, i8* %655, i64 %547
  %657 = getelementptr inbounds i8, i8* %651, i64 8
  %658 = getelementptr inbounds i8, i8* %657, i64 %559
  %659 = add nsw i32 %562, -8
  %660 = icmp eq i32 %659, 0
  br i1 %660, label %661, label %560

661:                                              ; preds = %654
  call void @free(i8* %292) #9
  br label %2335

662:                                              ; preds = %102
  %663 = shl nsw i32 %113, 2
  %664 = icmp eq i32 %663, %108
  %665 = shl i32 %115, 2
  %666 = icmp eq i32 %665, %110
  %667 = and i1 %664, %666
  br i1 %667, label %668, label %1160

668:                                              ; preds = %662
  br i1 %94, label %669, label %724

669:                                              ; preds = %668
  %670 = getelementptr inbounds [3 x i8*], [3 x i8*]* %28, i64 0, i64 %103
  %671 = load i8*, i8** %670, align 8
  %672 = getelementptr inbounds [2 x i32], [2 x i32]* %30, i64 0, i64 %106
  %673 = load i32, i32* %672, align 4
  %674 = sext i32 %673 to i64
  %675 = getelementptr inbounds [3 x i8*], [3 x i8*]* %32, i64 0, i64 %103
  %676 = load i8*, i8** %675, align 8
  %677 = getelementptr inbounds [2 x i32], [2 x i32]* %34, i64 0, i64 %106
  %678 = load i32, i32* %677, align 4
  %679 = sext i32 %678 to i64
  %680 = add nsw i32 %113, 15
  %681 = and i32 %680, -16
  %682 = sext i32 %681 to i64
  %683 = sub nsw i64 %674, %682
  %684 = shl nsw i64 %683, 2
  %685 = sub nsw i64 %679, %682
  br label %686

686:                                              ; preds = %719, %669
  %687 = phi i32 [ %115, %669 ], [ %722, %719 ]
  %688 = phi i8* [ %676, %669 ], [ %721, %719 ]
  %689 = phi i8* [ %671, %669 ], [ %720, %719 ]
  br label %690

690:                                              ; preds = %690, %686
  %691 = phi i32 [ %681, %686 ], [ %717, %690 ]
  %692 = phi i8* [ %688, %686 ], [ %716, %690 ]
  %693 = phi i8* [ %689, %686 ], [ %715, %690 ]
  %694 = bitcast i8* %693 to <8 x i16>*
  %695 = load <8 x i16>, <8 x i16>* %694, align 1
  %696 = getelementptr inbounds i8, i8* %693, i64 16
  %697 = bitcast i8* %696 to <8 x i16>*
  %698 = load <8 x i16>, <8 x i16>* %697, align 1
  %699 = and <8 x i16> %695, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %700 = and <8 x i16> %698, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %701 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %699, <8 x i16> %700) #9
  %702 = getelementptr inbounds i8, i8* %693, i64 32
  %703 = bitcast i8* %702 to <8 x i16>*
  %704 = load <8 x i16>, <8 x i16>* %703, align 1
  %705 = getelementptr inbounds i8, i8* %693, i64 48
  %706 = bitcast i8* %705 to <8 x i16>*
  %707 = load <8 x i16>, <8 x i16>* %706, align 1
  %708 = and <8 x i16> %704, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %709 = and <8 x i16> %707, <i16 255, i16 0, i16 255, i16 0, i16 255, i16 0, i16 255, i16 0>
  %710 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %708, <8 x i16> %709) #9
  %711 = bitcast <16 x i8> %701 to <8 x i16>
  %712 = bitcast <16 x i8> %710 to <8 x i16>
  %713 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %711, <8 x i16> %712) #9
  %714 = bitcast i8* %692 to <16 x i8>*
  store <16 x i8> %713, <16 x i8>* %714, align 1
  %715 = getelementptr inbounds i8, i8* %693, i64 64
  %716 = getelementptr inbounds i8, i8* %692, i64 16
  %717 = add nsw i32 %691, -16
  %718 = icmp eq i32 %717, 0
  br i1 %718, label %719, label %690

719:                                              ; preds = %690
  %720 = getelementptr inbounds i8, i8* %715, i64 %684
  %721 = getelementptr inbounds i8, i8* %716, i64 %685
  %722 = add nsw i32 %687, -1
  %723 = icmp eq i32 %722, 0
  br i1 %723, label %2335, label %686

724:                                              ; preds = %668
  br i1 %95, label %725, label %843

725:                                              ; preds = %724
  %726 = load i16, i16* %97, align 2
  %727 = load i16, i16* %98, align 8
  %728 = shl i16 %727, 8
  %729 = or i16 %728, %726
  %730 = insertelement <8 x i16> undef, i16 %729, i32 0
  %731 = shufflevector <8 x i16> %730, <8 x i16> undef, <8 x i32> zeroinitializer
  %732 = getelementptr inbounds [3 x i8*], [3 x i8*]* %28, i64 0, i64 %103
  %733 = load i8*, i8** %732, align 8
  %734 = getelementptr inbounds [2 x i32], [2 x i32]* %30, i64 0, i64 %106
  %735 = load i32, i32* %734, align 4
  %736 = sext i32 %735 to i64
  %737 = getelementptr inbounds [3 x i8*], [3 x i8*]* %32, i64 0, i64 %103
  %738 = load i8*, i8** %737, align 8
  %739 = getelementptr inbounds [2 x i32], [2 x i32]* %34, i64 0, i64 %106
  %740 = load i32, i32* %739, align 4
  %741 = sext i32 %740 to i64
  %742 = add nsw i32 %113, 15
  %743 = and i32 %742, -16
  %744 = sext i32 %743 to i64
  %745 = sub nsw i64 %736, %744
  %746 = shl nsw i64 %745, 2
  %747 = bitcast <8 x i16> %731 to <16 x i8>
  %748 = sub nsw i64 %741, %744
  br label %749

749:                                              ; preds = %838, %725
  %750 = phi i8* [ %738, %725 ], [ %840, %838 ]
  %751 = phi i8* [ %733, %725 ], [ %839, %838 ]
  %752 = phi i32 [ %115, %725 ], [ %841, %838 ]
  br label %753

753:                                              ; preds = %753, %749
  %754 = phi i8* [ %750, %749 ], [ %835, %753 ]
  %755 = phi i8* [ %751, %749 ], [ %834, %753 ]
  %756 = phi i32 [ %743, %749 ], [ %836, %753 ]
  %757 = bitcast i8* %755 to <8 x i16>*
  %758 = load <8 x i16>, <8 x i16>* %757, align 1
  %759 = getelementptr inbounds i8, i8* %755, i64 16
  %760 = bitcast i8* %759 to <8 x i16>*
  %761 = load <8 x i16>, <8 x i16>* %760, align 1
  %762 = getelementptr inbounds i8, i8* %755, i64 32
  %763 = bitcast i8* %762 to <8 x i16>*
  %764 = load <8 x i16>, <8 x i16>* %763, align 1
  %765 = getelementptr inbounds i8, i8* %755, i64 48
  %766 = bitcast i8* %765 to <8 x i16>*
  %767 = load <8 x i16>, <8 x i16>* %766, align 1
  %768 = getelementptr inbounds i8, i8* %755, i64 %736
  %769 = bitcast i8* %768 to <8 x i16>*
  %770 = load <8 x i16>, <8 x i16>* %769, align 1
  %771 = getelementptr inbounds i8, i8* %768, i64 16
  %772 = bitcast i8* %771 to <8 x i16>*
  %773 = load <8 x i16>, <8 x i16>* %772, align 1
  %774 = getelementptr inbounds i8, i8* %768, i64 32
  %775 = bitcast i8* %774 to <8 x i16>*
  %776 = load <8 x i16>, <8 x i16>* %775, align 1
  %777 = getelementptr inbounds i8, i8* %768, i64 48
  %778 = bitcast i8* %777 to <8 x i16>*
  %779 = load <8 x i16>, <8 x i16>* %778, align 1
  %780 = shufflevector <8 x i16> %758, <8 x i16> %770, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %781 = shufflevector <8 x i16> %758, <8 x i16> %770, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %782 = shufflevector <8 x i16> %761, <8 x i16> %773, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %783 = shufflevector <8 x i16> %761, <8 x i16> %773, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %784 = shufflevector <8 x i16> %764, <8 x i16> %776, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %785 = shufflevector <8 x i16> %764, <8 x i16> %776, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %786 = shufflevector <8 x i16> %767, <8 x i16> %779, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %787 = shufflevector <8 x i16> %767, <8 x i16> %779, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %788 = bitcast <8 x i16> %780 to <4 x i32>
  %789 = bitcast <8 x i16> %781 to <4 x i32>
  %790 = shufflevector <4 x i32> %788, <4 x i32> %789, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %791 = shufflevector <4 x i32> %788, <4 x i32> %789, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %792 = bitcast <8 x i16> %782 to <4 x i32>
  %793 = bitcast <8 x i16> %783 to <4 x i32>
  %794 = shufflevector <4 x i32> %792, <4 x i32> %793, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %795 = shufflevector <4 x i32> %792, <4 x i32> %793, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %796 = bitcast <8 x i16> %784 to <4 x i32>
  %797 = bitcast <8 x i16> %785 to <4 x i32>
  %798 = shufflevector <4 x i32> %796, <4 x i32> %797, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %799 = shufflevector <4 x i32> %796, <4 x i32> %797, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %800 = bitcast <8 x i16> %786 to <4 x i32>
  %801 = bitcast <8 x i16> %787 to <4 x i32>
  %802 = shufflevector <4 x i32> %800, <4 x i32> %801, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %803 = shufflevector <4 x i32> %800, <4 x i32> %801, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %804 = shufflevector <4 x i32> %790, <4 x i32> %791, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %805 = shufflevector <4 x i32> %794, <4 x i32> %795, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %806 = shufflevector <4 x i32> %798, <4 x i32> %799, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %807 = shufflevector <4 x i32> %802, <4 x i32> %803, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %808 = bitcast <4 x i32> %804 to <16 x i8>
  %809 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %808, <16 x i8> %747) #9
  %810 = bitcast <4 x i32> %805 to <16 x i8>
  %811 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %810, <16 x i8> %747) #9
  %812 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %809, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %813 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %811, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %814 = ashr <8 x i16> %812, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %815 = ashr <8 x i16> %813, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %816 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %814, <8 x i16> %815) #9
  %817 = bitcast <4 x i32> %806 to <16 x i8>
  %818 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %817, <16 x i8> %747) #9
  %819 = bitcast <4 x i32> %807 to <16 x i8>
  %820 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %819, <16 x i8> %747) #9
  %821 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %818, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %822 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %820, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %823 = ashr <8 x i16> %821, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %824 = ashr <8 x i16> %822, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %825 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %823, <8 x i16> %824) #9
  %826 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %816, <16 x i8> %747) #9
  %827 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %825, <16 x i8> %747) #9
  %828 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %826, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %829 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %827, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %830 = ashr <8 x i16> %828, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %831 = ashr <8 x i16> %829, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %832 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %830, <8 x i16> %831) #9
  %833 = bitcast i8* %754 to <16 x i8>*
  store <16 x i8> %832, <16 x i8>* %833, align 1
  %834 = getelementptr inbounds i8, i8* %755, i64 64
  %835 = getelementptr inbounds i8, i8* %754, i64 16
  %836 = add nsw i32 %756, -16
  %837 = icmp eq i32 %836, 0
  br i1 %837, label %838, label %753

838:                                              ; preds = %753
  %839 = getelementptr inbounds i8, i8* %834, i64 %746
  %840 = getelementptr inbounds i8, i8* %835, i64 %748
  %841 = add nsw i32 %752, -1
  %842 = icmp eq i32 %841, 0
  br i1 %842, label %2335, label %749

843:                                              ; preds = %724
  %844 = shl nsw i32 %120, 2
  %845 = or i32 %844, 6
  %846 = add nsw i32 %845, 7
  %847 = and i32 %846, -8
  %848 = mul nsw i32 %847, %118
  %849 = add nsw i32 %848, 16
  %850 = sext i32 %849 to i64
  %851 = call noalias i8* @malloc(i64 %850) #9
  %852 = icmp eq i8* %851, null
  br i1 %852, label %2335, label %853

853:                                              ; preds = %843
  %854 = load [8 x i16]*, [8 x i16]** %26, align 16
  %855 = getelementptr inbounds [3 x i8*], [3 x i8*]* %28, i64 0, i64 %103
  %856 = load i8*, i8** %855, align 8
  %857 = getelementptr inbounds [2 x i32], [2 x i32]* %30, i64 0, i64 %106
  %858 = load i32, i32* %857, align 4
  %859 = getelementptr inbounds [3 x i8*], [3 x i8*]* %32, i64 0, i64 %103
  %860 = load i8*, i8** %859, align 8
  %861 = getelementptr inbounds [2 x i32], [2 x i32]* %34, i64 0, i64 %106
  %862 = load i32, i32* %861, align 4
  %863 = getelementptr inbounds [8 x i16], [8 x i16]* %854, i64 %96, i64 0
  %864 = add nsw i32 %113, 1
  %865 = and i32 %864, -2
  %866 = add nsw i32 %110, 13
  %867 = and i32 %866, -8
  %868 = bitcast i16* %863 to <16 x i8>*
  %869 = load <16 x i8>, <16 x i8>* %868, align 16
  %870 = shufflevector <16 x i8> %869, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2>
  %871 = shufflevector <16 x i8> %869, <16 x i8> undef, <16 x i32> <i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6>
  %872 = shufflevector <16 x i8> %869, <16 x i8> undef, <16 x i32> <i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10>
  %873 = shufflevector <16 x i8> %869, <16 x i8> undef, <16 x i32> <i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14>
  %874 = mul i32 %858, -3
  %875 = add i32 %874, -7
  %876 = sext i32 %875 to i64
  %877 = getelementptr inbounds i8, i8* %856, i64 %876
  %878 = shl nsw i32 %858, 3
  %879 = shl nsw i32 %865, 2
  %880 = sub nsw i32 %878, %879
  %881 = sext i32 %880 to i64
  %882 = sext i32 %858 to i64
  %883 = shl nsw i64 %882, 1
  %884 = mul nsw i64 %882, 3
  %885 = shl nsw i64 %882, 2
  %886 = shl nsw i32 %865, 1
  %887 = sext i32 %886 to i64
  %888 = shl nsw i64 %887, 1
  %889 = mul nsw i64 %887, 3
  %890 = mul nsw i32 %865, 6
  %891 = sext i32 %890 to i64
  br label %892

892:                                              ; preds = %1067, %853
  %893 = phi i8* [ %877, %853 ], [ %1068, %1067 ]
  %894 = phi i32 [ %867, %853 ], [ %1070, %1067 ]
  %895 = phi i8* [ %851, %853 ], [ %1069, %1067 ]
  %896 = getelementptr inbounds i8, i8* %893, i64 4
  %897 = bitcast i8* %896 to i64*
  %898 = load i64, i64* %897, align 1
  %899 = insertelement <2 x i64> undef, i64 %898, i32 0
  %900 = getelementptr inbounds i8, i8* %896, i64 %882
  %901 = bitcast i8* %900 to i64*
  %902 = load i64, i64* %901, align 1
  %903 = insertelement <2 x i64> undef, i64 %902, i32 0
  %904 = getelementptr inbounds i8, i8* %896, i64 %883
  %905 = bitcast i8* %904 to i64*
  %906 = load i64, i64* %905, align 1
  %907 = insertelement <2 x i64> undef, i64 %906, i32 0
  %908 = getelementptr inbounds i8, i8* %896, i64 %884
  %909 = bitcast i8* %908 to i64*
  %910 = load i64, i64* %909, align 1
  %911 = insertelement <2 x i64> undef, i64 %910, i32 0
  %912 = getelementptr inbounds i8, i8* %896, i64 %885
  %913 = bitcast i8* %912 to i64*
  %914 = load i64, i64* %913, align 1
  %915 = insertelement <2 x i64> undef, i64 %914, i32 0
  %916 = getelementptr inbounds i8, i8* %912, i64 %882
  %917 = bitcast i8* %916 to i64*
  %918 = load i64, i64* %917, align 1
  %919 = insertelement <2 x i64> undef, i64 %918, i32 0
  %920 = getelementptr inbounds i8, i8* %912, i64 %883
  %921 = bitcast i8* %920 to i64*
  %922 = load i64, i64* %921, align 1
  %923 = insertelement <2 x i64> undef, i64 %922, i32 0
  %924 = getelementptr inbounds i8, i8* %912, i64 %884
  %925 = bitcast i8* %924 to i64*
  %926 = load i64, i64* %925, align 1
  %927 = insertelement <2 x i64> undef, i64 %926, i32 0
  %928 = bitcast <2 x i64> %899 to <8 x i16>
  %929 = bitcast <2 x i64> %903 to <8 x i16>
  %930 = shufflevector <8 x i16> %928, <8 x i16> %929, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 undef, i32 undef, i32 undef, i32 undef>
  %931 = bitcast <2 x i64> %907 to <8 x i16>
  %932 = bitcast <2 x i64> %911 to <8 x i16>
  %933 = shufflevector <8 x i16> %931, <8 x i16> %932, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 undef, i32 undef, i32 undef, i32 undef>
  %934 = bitcast <2 x i64> %915 to <8 x i16>
  %935 = bitcast <2 x i64> %919 to <8 x i16>
  %936 = shufflevector <8 x i16> %934, <8 x i16> %935, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 undef, i32 undef, i32 undef, i32 undef>
  %937 = bitcast <2 x i64> %923 to <8 x i16>
  %938 = bitcast <2 x i64> %927 to <8 x i16>
  %939 = shufflevector <8 x i16> %937, <8 x i16> %938, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 undef, i32 undef, i32 undef, i32 undef>
  %940 = bitcast <8 x i16> %930 to <4 x i32>
  %941 = bitcast <8 x i16> %933 to <4 x i32>
  %942 = shufflevector <4 x i32> %940, <4 x i32> %941, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %943 = bitcast <4 x i32> %942 to <2 x i64>
  %944 = bitcast <8 x i16> %936 to <4 x i32>
  %945 = bitcast <8 x i16> %939 to <4 x i32>
  %946 = shufflevector <4 x i32> %944, <4 x i32> %945, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %947 = bitcast <4 x i32> %946 to <2 x i64>
  %948 = shufflevector <2 x i64> %943, <2 x i64> %947, <2 x i32> <i32 0, i32 2>
  %949 = shufflevector <2 x i64> %943, <2 x i64> %947, <2 x i32> <i32 1, i32 3>
  br label %950

950:                                              ; preds = %950, %892
  %951 = phi <2 x i64> [ %949, %892 ], [ %1015, %950 ]
  %952 = phi <2 x i64> [ %948, %892 ], [ %1014, %950 ]
  %953 = phi i8* [ %893, %892 ], [ %956, %950 ]
  %954 = phi i32 [ %865, %892 ], [ %1065, %950 ]
  %955 = phi i8* [ %895, %892 ], [ %1064, %950 ]
  %956 = getelementptr inbounds i8, i8* %953, i64 8
  %957 = bitcast i8* %956 to i64*
  %958 = load i64, i64* %957, align 1
  %959 = insertelement <2 x i64> undef, i64 %958, i32 0
  %960 = getelementptr inbounds i8, i8* %956, i64 %882
  %961 = bitcast i8* %960 to i64*
  %962 = load i64, i64* %961, align 1
  %963 = insertelement <2 x i64> undef, i64 %962, i32 0
  %964 = getelementptr inbounds i8, i8* %956, i64 %883
  %965 = bitcast i8* %964 to i64*
  %966 = load i64, i64* %965, align 1
  %967 = insertelement <2 x i64> undef, i64 %966, i32 0
  %968 = getelementptr inbounds i8, i8* %956, i64 %884
  %969 = bitcast i8* %968 to i64*
  %970 = load i64, i64* %969, align 1
  %971 = insertelement <2 x i64> undef, i64 %970, i32 0
  %972 = getelementptr inbounds i8, i8* %956, i64 %885
  %973 = bitcast i8* %972 to i64*
  %974 = load i64, i64* %973, align 1
  %975 = insertelement <2 x i64> undef, i64 %974, i32 0
  %976 = getelementptr inbounds i8, i8* %972, i64 %882
  %977 = bitcast i8* %976 to i64*
  %978 = load i64, i64* %977, align 1
  %979 = insertelement <2 x i64> undef, i64 %978, i32 0
  %980 = getelementptr inbounds i8, i8* %972, i64 %883
  %981 = bitcast i8* %980 to i64*
  %982 = load i64, i64* %981, align 1
  %983 = insertelement <2 x i64> undef, i64 %982, i32 0
  %984 = getelementptr inbounds i8, i8* %972, i64 %884
  %985 = bitcast i8* %984 to i64*
  %986 = load i64, i64* %985, align 1
  %987 = insertelement <2 x i64> undef, i64 %986, i32 0
  %988 = bitcast <2 x i64> %959 to <8 x i16>
  %989 = bitcast <2 x i64> %963 to <8 x i16>
  %990 = shufflevector <8 x i16> %988, <8 x i16> %989, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %991 = bitcast <2 x i64> %967 to <8 x i16>
  %992 = bitcast <2 x i64> %971 to <8 x i16>
  %993 = shufflevector <8 x i16> %991, <8 x i16> %992, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %994 = bitcast <2 x i64> %975 to <8 x i16>
  %995 = bitcast <2 x i64> %979 to <8 x i16>
  %996 = shufflevector <8 x i16> %994, <8 x i16> %995, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %997 = bitcast <2 x i64> %983 to <8 x i16>
  %998 = bitcast <2 x i64> %987 to <8 x i16>
  %999 = shufflevector <8 x i16> %997, <8 x i16> %998, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1000 = bitcast <8 x i16> %990 to <4 x i32>
  %1001 = bitcast <8 x i16> %993 to <4 x i32>
  %1002 = shufflevector <4 x i32> %1000, <4 x i32> %1001, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1003 = bitcast <4 x i32> %1002 to <2 x i64>
  %1004 = bitcast <8 x i16> %996 to <4 x i32>
  %1005 = bitcast <8 x i16> %999 to <4 x i32>
  %1006 = shufflevector <4 x i32> %1004, <4 x i32> %1005, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1007 = bitcast <4 x i32> %1006 to <2 x i64>
  %1008 = shufflevector <4 x i32> %1000, <4 x i32> %1001, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1009 = bitcast <4 x i32> %1008 to <2 x i64>
  %1010 = shufflevector <4 x i32> %1004, <4 x i32> %1005, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1011 = bitcast <4 x i32> %1010 to <2 x i64>
  %1012 = shufflevector <2 x i64> %1003, <2 x i64> %1007, <2 x i32> <i32 0, i32 2>
  %1013 = shufflevector <2 x i64> %1003, <2 x i64> %1007, <2 x i32> <i32 1, i32 3>
  %1014 = shufflevector <2 x i64> %1009, <2 x i64> %1011, <2 x i32> <i32 0, i32 2>
  %1015 = shufflevector <2 x i64> %1009, <2 x i64> %1011, <2 x i32> <i32 1, i32 3>
  %1016 = bitcast <2 x i64> %952 to <16 x i8>
  %1017 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1016, <16 x i8> %870) #9
  %1018 = bitcast <2 x i64> %951 to <16 x i8>
  %1019 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1018, <16 x i8> %871) #9
  %1020 = bitcast <2 x i64> %1012 to <16 x i8>
  %1021 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1020, <16 x i8> %872) #9
  %1022 = bitcast <2 x i64> %1013 to <16 x i8>
  %1023 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1022, <16 x i8> %873) #9
  %1024 = add <8 x i16> %1023, %1019
  %1025 = add <8 x i16> %1017, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %1026 = add <8 x i16> %1025, %1021
  %1027 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1026, <8 x i16> %1024) #9
  %1028 = ashr <8 x i16> %1027, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1029 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1020, <16 x i8> %870) #9
  %1030 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1022, <16 x i8> %871) #9
  %1031 = bitcast <2 x i64> %1014 to <16 x i8>
  %1032 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1031, <16 x i8> %872) #9
  %1033 = bitcast <2 x i64> %1015 to <16 x i8>
  %1034 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1033, <16 x i8> %873) #9
  %1035 = add <8 x i16> %1034, %1030
  %1036 = add <8 x i16> %1029, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %1037 = add <8 x i16> %1036, %1032
  %1038 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1037, <8 x i16> %1035) #9
  %1039 = ashr <8 x i16> %1038, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1040 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1028, <8 x i16> undef) #9
  %1041 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1039, <8 x i16> undef) #9
  %1042 = bitcast <16 x i8> %1040 to <8 x i16>
  %1043 = bitcast <16 x i8> %1041 to <8 x i16>
  %1044 = shufflevector <8 x i16> %1042, <8 x i16> %1043, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1045 = bitcast <8 x i16> %1044 to <16 x i8>
  %1046 = shufflevector <16 x i8> %1045, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1047 = bitcast <16 x i8> %1046 to <4 x i32>
  %1048 = shufflevector <16 x i8> %1045, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1049 = bitcast <16 x i8> %1048 to <4 x i32>
  %1050 = shufflevector <16 x i8> %1045, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1051 = bitcast <16 x i8> %1050 to <4 x i32>
  %1052 = bitcast <8 x i16> %1044 to <4 x i32>
  %1053 = extractelement <4 x i32> %1052, i32 0
  %1054 = bitcast i8* %955 to i32*
  store i32 %1053, i32* %1054, align 4
  %1055 = extractelement <4 x i32> %1047, i32 0
  %1056 = getelementptr inbounds i8, i8* %955, i64 %887
  %1057 = bitcast i8* %1056 to i32*
  store i32 %1055, i32* %1057, align 4
  %1058 = extractelement <4 x i32> %1049, i32 0
  %1059 = getelementptr inbounds i8, i8* %955, i64 %888
  %1060 = bitcast i8* %1059 to i32*
  store i32 %1058, i32* %1060, align 4
  %1061 = extractelement <4 x i32> %1051, i32 0
  %1062 = getelementptr inbounds i8, i8* %955, i64 %889
  %1063 = bitcast i8* %1062 to i32*
  store i32 %1061, i32* %1063, align 4
  %1064 = getelementptr inbounds i8, i8* %955, i64 4
  %1065 = add nsw i32 %954, -2
  %1066 = icmp eq i32 %1065, 0
  br i1 %1066, label %1067, label %950

1067:                                             ; preds = %950
  %1068 = getelementptr inbounds i8, i8* %956, i64 %881
  %1069 = getelementptr inbounds i8, i8* %1064, i64 %891
  %1070 = add nsw i32 %894, -8
  %1071 = icmp eq i32 %1070, 0
  br i1 %1071, label %1072, label %892

1072:                                             ; preds = %1067
  %1073 = add nsw i32 %113, 7
  %1074 = add nsw i32 %115, 1
  %1075 = and i32 %1073, -8
  %1076 = and i32 %1074, -2
  %1077 = shl nsw i32 %1074, 2
  %1078 = or i32 %1077, 4
  %1079 = mul nsw i32 %1078, %865
  %1080 = sext i32 %1079 to i64
  %1081 = sub nsw i64 0, %1080
  %1082 = sext i32 %879 to i64
  %1083 = shl nsw i32 %865, 3
  %1084 = sext i32 %1083 to i64
  %1085 = sext i32 %862 to i64
  %1086 = shl nsw i32 %862, 1
  %1087 = sext i32 %1086 to i64
  %1088 = mul nsw i32 %862, %1076
  %1089 = sext i32 %1088 to i64
  %1090 = sub nsw i64 0, %1089
  br label %1091

1091:                                             ; preds = %1152, %1072
  %1092 = phi i8* [ %1156, %1152 ], [ %860, %1072 ]
  %1093 = phi i32 [ %1157, %1152 ], [ %1075, %1072 ]
  %1094 = phi i8* [ %1154, %1152 ], [ %851, %1072 ]
  %1095 = bitcast i8* %1094 to <2 x i64>*
  %1096 = load <2 x i64>, <2 x i64>* %1095, align 1
  %1097 = getelementptr inbounds i8, i8* %1094, i64 %887
  %1098 = bitcast i8* %1097 to <2 x i64>*
  %1099 = load <2 x i64>, <2 x i64>* %1098, align 1
  %1100 = getelementptr inbounds i8, i8* %1094, i64 %1082
  br label %1101

1101:                                             ; preds = %1101, %1091
  %1102 = phi <2 x i64> [ %1099, %1091 ], [ %1117, %1101 ]
  %1103 = phi <2 x i64> [ %1096, %1091 ], [ %1114, %1101 ]
  %1104 = phi i8* [ %1092, %1091 ], [ %1149, %1101 ]
  %1105 = phi i32 [ %1076, %1091 ], [ %1150, %1101 ]
  %1106 = phi i8* [ %1100, %1091 ], [ %1118, %1101 ]
  %1107 = bitcast i8* %1106 to <16 x i8>*
  %1108 = load <16 x i8>, <16 x i8>* %1107, align 1
  %1109 = getelementptr inbounds i8, i8* %1106, i64 %887
  %1110 = bitcast i8* %1109 to <16 x i8>*
  %1111 = load <16 x i8>, <16 x i8>* %1110, align 1
  %1112 = getelementptr inbounds i8, i8* %1106, i64 %888
  %1113 = bitcast i8* %1112 to <2 x i64>*
  %1114 = load <2 x i64>, <2 x i64>* %1113, align 1
  %1115 = getelementptr inbounds i8, i8* %1106, i64 %889
  %1116 = bitcast i8* %1115 to <2 x i64>*
  %1117 = load <2 x i64>, <2 x i64>* %1116, align 1
  %1118 = getelementptr inbounds i8, i8* %1106, i64 %1084
  %1119 = bitcast <2 x i64> %1103 to <16 x i8>
  %1120 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1119, <16 x i8> %870) #9
  %1121 = bitcast <2 x i64> %1102 to <16 x i8>
  %1122 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1121, <16 x i8> %871) #9
  %1123 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1108, <16 x i8> %872) #9
  %1124 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1111, <16 x i8> %873) #9
  %1125 = add <8 x i16> %1124, %1122
  %1126 = add <8 x i16> %1120, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %1127 = add <8 x i16> %1126, %1123
  %1128 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1127, <8 x i16> %1125) #9
  %1129 = ashr <8 x i16> %1128, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1130 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1108, <16 x i8> %870) #9
  %1131 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1111, <16 x i8> %871) #9
  %1132 = bitcast <2 x i64> %1114 to <16 x i8>
  %1133 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1132, <16 x i8> %872) #9
  %1134 = bitcast <2 x i64> %1117 to <16 x i8>
  %1135 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1134, <16 x i8> %873) #9
  %1136 = add <8 x i16> %1135, %1131
  %1137 = add <8 x i16> %1130, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %1138 = add <8 x i16> %1137, %1133
  %1139 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1138, <8 x i16> %1136) #9
  %1140 = ashr <8 x i16> %1139, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1141 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1129, <8 x i16> %1140) #9
  %1142 = bitcast <16 x i8> %1141 to <2 x i64>
  %1143 = extractelement <2 x i64> %1142, i32 0
  %1144 = bitcast i8* %1104 to i64*
  store i64 %1143, i64* %1144, align 1
  %1145 = getelementptr inbounds i8, i8* %1104, i64 %1085
  %1146 = bitcast <16 x i8> %1141 to <4 x float>
  %1147 = shufflevector <4 x float> %1146, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %1148 = bitcast i8* %1145 to <2 x float>*
  store <2 x float> %1147, <2 x float>* %1148, align 1
  %1149 = getelementptr inbounds i8, i8* %1104, i64 %1087
  %1150 = add nsw i32 %1105, -2
  %1151 = icmp eq i32 %1150, 0
  br i1 %1151, label %1152, label %1101

1152:                                             ; preds = %1101
  %1153 = getelementptr inbounds i8, i8* %1118, i64 16
  %1154 = getelementptr inbounds i8, i8* %1153, i64 %1081
  %1155 = getelementptr inbounds i8, i8* %1149, i64 8
  %1156 = getelementptr inbounds i8, i8* %1155, i64 %1090
  %1157 = add nsw i32 %1093, -8
  %1158 = icmp eq i32 %1157, 0
  br i1 %1158, label %1159, label %1091

1159:                                             ; preds = %1152
  call void @free(i8* %851) #9
  br label %2335

1160:                                             ; preds = %662
  %1161 = mul nsw i32 %108, 3
  %1162 = icmp eq i32 %663, %1161
  %1163 = mul nsw i32 %110, 3
  %1164 = icmp eq i32 %665, %1163
  %1165 = and i1 %1162, %1164
  br i1 %1165, label %1166, label %1595

1166:                                             ; preds = %1160
  %1167 = add nsw i32 %118, 5
  %1168 = srem i32 %1167, 6
  %1169 = sub nsw i32 %1167, %1168
  %1170 = add nsw i32 %1169, 2
  %1171 = add nsw i32 %118, 7
  %1172 = and i32 %1171, -8
  %1173 = shl nsw i32 %121, 2
  %1174 = sdiv i32 %1173, 3
  %1175 = add nsw i32 %1174, 14
  %1176 = and i32 %1175, -8
  %1177 = icmp sgt i32 %1172, %1170
  %1178 = sub nsw i32 %1172, %1170
  %1179 = shl nsw i32 %1178, 1
  %1180 = select i1 %1177, i32 %1179, i32 0
  %1181 = mul nsw i32 %1176, %1170
  %1182 = add nsw i32 %1180, %1181
  %1183 = sext i32 %1182 to i64
  %1184 = call noalias i8* @malloc(i64 %1183) #9
  %1185 = icmp eq i8* %1184, null
  br i1 %1185, label %2335, label %1186

1186:                                             ; preds = %1166
  %1187 = load [8 x i16]*, [8 x i16]** %26, align 16
  %1188 = getelementptr inbounds [3 x i8*], [3 x i8*]* %28, i64 0, i64 %103
  %1189 = load i8*, i8** %1188, align 8
  %1190 = getelementptr inbounds [2 x i32], [2 x i32]* %30, i64 0, i64 %106
  %1191 = load i32, i32* %1190, align 4
  %1192 = getelementptr inbounds [3 x i8*], [3 x i8*]* %32, i64 0, i64 %103
  %1193 = load i8*, i8** %1192, align 8
  %1194 = getelementptr inbounds [2 x i32], [2 x i32]* %34, i64 0, i64 %106
  %1195 = load i32, i32* %1194, align 4
  %1196 = add nsw i32 %113, 5
  %1197 = srem i32 %1196, 6
  %1198 = sub nsw i32 %1196, %1197
  %1199 = shl nsw i32 %1198, 1
  %1200 = add nsw i32 %1199, 4
  %1201 = sdiv i32 %665, 3
  %1202 = add nsw i32 %1201, 14
  %1203 = and i32 %1202, -8
  %1204 = add nsw i32 %115, 5
  call void @llvm.lifetime.start.p0i8(i64 192, i8* nonnull %35) #9
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %35, i8 -86, i64 192, i1 false) #9
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %36) #9
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %36, i8 -86, i64 80, i1 false) #9
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %37) #9
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %37, i8 -86, i64 80, i1 false) #9
  %1205 = getelementptr inbounds [8 x i16], [8 x i16]* %1187, i64 %45, i64 0
  %1206 = bitcast i16* %1205 to <16 x i8>*
  %1207 = load <16 x i8>, <16 x i8>* %1206, align 16
  %1208 = shufflevector <16 x i8> %1207, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2>
  %1209 = shufflevector <16 x i8> %1207, <16 x i8> undef, <16 x i32> <i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10>
  %1210 = shufflevector <16 x i8> %1207, <16 x i8> undef, <16 x i32> <i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14>
  %1211 = load void (i16*, <2 x i64>*)*, void (i16*, <2 x i64>*)** %47, align 8
  %1212 = getelementptr inbounds [8 x i16], [8 x i16]* %1187, i64 %49, i64 0
  call void %1211(i16* %1212, <2 x i64>* nonnull %50) #9
  %1213 = load void (i16*, <2 x i64>*)*, void (i16*, <2 x i64>*)** %52, align 8
  %1214 = getelementptr inbounds [8 x i16], [8 x i16]* %1187, i64 %54, i64 0
  call void %1213(i16* %1214, <2 x i64>* nonnull %55) #9
  %1215 = add <16 x i8> %1207, <i8 undef, i8 undef, i8 undef, i8 undef, i8 -64, i8 undef, i8 -64, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %1216 = shufflevector <16 x i8> %1215, <16 x i8> undef, <16 x i32> <i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6>
  %1217 = load <16 x i8>, <16 x i8>* %59, align 16
  %1218 = add <16 x i8> %1217, <i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64>
  store <16 x i8> %1218, <16 x i8>* %59, align 16
  %1219 = load <16 x i8>, <16 x i8>* %63, align 16
  %1220 = add <16 x i8> %1219, <i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64, i8 -64>
  store <16 x i8> %1220, <16 x i8>* %63, align 16
  %1221 = mul i32 %1191, -3
  %1222 = add i32 %1221, -3
  %1223 = sext i32 %1222 to i64
  %1224 = getelementptr inbounds i8, i8* %1189, i64 %1223
  %1225 = shl nsw i32 %1191, 3
  %1226 = shl nsw i32 %1198, 2
  %1227 = sdiv i32 %1226, 3
  %1228 = sub nsw i32 %1225, %1227
  %1229 = sext i32 %1228 to i64
  %1230 = sext i32 %1191 to i64
  %1231 = shl nsw i64 %1230, 1
  %1232 = mul nsw i64 %1230, 3
  %1233 = shl nsw i64 %1230, 2
  %1234 = load <2 x i64> (<2 x i64>*, <2 x i64>*)*, <2 x i64> (<2 x i64>*, <2 x i64>*)** %78, align 8
  %1235 = sext i32 %1200 to i64
  %1236 = shl nsw i64 %1235, 1
  %1237 = mul nsw i64 %1235, 3
  %1238 = mul nsw i32 %1200, 3
  %1239 = add nsw i32 %1238, 4
  %1240 = sext i32 %1239 to i64
  br label %1241

1241:                                             ; preds = %1451, %1186
  %1242 = phi i8* [ %1224, %1186 ], [ %1452, %1451 ]
  %1243 = phi i32 [ %1203, %1186 ], [ %1454, %1451 ]
  %1244 = phi i8* [ %1184, %1186 ], [ %1453, %1451 ]
  %1245 = bitcast i8* %1242 to i64*
  %1246 = load i64, i64* %1245, align 1
  %1247 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1246, i32 0
  store <2 x i64> %1247, <2 x i64>* %64, align 16
  %1248 = getelementptr inbounds i8, i8* %1242, i64 %1230
  %1249 = bitcast i8* %1248 to i64*
  %1250 = load i64, i64* %1249, align 1
  %1251 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1250, i32 0
  store <2 x i64> %1251, <2 x i64>* %65, align 16
  %1252 = getelementptr inbounds i8, i8* %1242, i64 %1231
  %1253 = bitcast i8* %1252 to i64*
  %1254 = load i64, i64* %1253, align 1
  %1255 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1254, i32 0
  store <2 x i64> %1255, <2 x i64>* %66, align 16
  %1256 = getelementptr inbounds i8, i8* %1242, i64 %1232
  %1257 = bitcast i8* %1256 to i64*
  %1258 = load i64, i64* %1257, align 1
  %1259 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1258, i32 0
  store <2 x i64> %1259, <2 x i64>* %67, align 16
  %1260 = getelementptr inbounds i8, i8* %1242, i64 %1233
  %1261 = bitcast i8* %1260 to i64*
  %1262 = load i64, i64* %1261, align 1
  %1263 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1262, i32 0
  store <2 x i64> %1263, <2 x i64>* %68, align 16
  %1264 = getelementptr inbounds i8, i8* %1260, i64 %1230
  %1265 = bitcast i8* %1264 to i64*
  %1266 = load i64, i64* %1265, align 1
  %1267 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1266, i32 0
  store <2 x i64> %1267, <2 x i64>* %69, align 16
  %1268 = getelementptr inbounds i8, i8* %1260, i64 %1231
  %1269 = bitcast i8* %1268 to i64*
  %1270 = load i64, i64* %1269, align 1
  %1271 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1270, i32 0
  store <2 x i64> %1271, <2 x i64>* %70, align 16
  %1272 = getelementptr inbounds i8, i8* %1260, i64 %1232
  %1273 = bitcast i8* %1272 to i64*
  %1274 = load i64, i64* %1273, align 1
  %1275 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1274, i32 0
  store <2 x i64> %1275, <2 x i64>* %71, align 16
  %1276 = bitcast <2 x i64> %1247 to <8 x i16>
  %1277 = bitcast <2 x i64> %1251 to <8 x i16>
  %1278 = shufflevector <8 x i16> %1276, <8 x i16> %1277, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1279 = bitcast <2 x i64> %1255 to <8 x i16>
  %1280 = bitcast <2 x i64> %1259 to <8 x i16>
  %1281 = shufflevector <8 x i16> %1279, <8 x i16> %1280, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1282 = bitcast <2 x i64> %1263 to <8 x i16>
  %1283 = bitcast <2 x i64> %1267 to <8 x i16>
  %1284 = shufflevector <8 x i16> %1282, <8 x i16> %1283, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1285 = bitcast <2 x i64> %1271 to <8 x i16>
  %1286 = bitcast <2 x i64> %1275 to <8 x i16>
  %1287 = shufflevector <8 x i16> %1285, <8 x i16> %1286, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1288 = bitcast <8 x i16> %1278 to <4 x i32>
  %1289 = bitcast <8 x i16> %1281 to <4 x i32>
  %1290 = shufflevector <4 x i32> %1288, <4 x i32> %1289, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1291 = bitcast <4 x i32> %1290 to <2 x i64>
  %1292 = bitcast <8 x i16> %1284 to <4 x i32>
  %1293 = bitcast <8 x i16> %1287 to <4 x i32>
  %1294 = shufflevector <4 x i32> %1292, <4 x i32> %1293, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1295 = bitcast <4 x i32> %1294 to <2 x i64>
  %1296 = shufflevector <4 x i32> %1288, <4 x i32> %1289, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1297 = bitcast <4 x i32> %1296 to <2 x i64>
  %1298 = shufflevector <4 x i32> %1292, <4 x i32> %1293, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1299 = bitcast <4 x i32> %1298 to <2 x i64>
  %1300 = shufflevector <2 x i64> %1291, <2 x i64> %1295, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1300, <2 x i64>* %64, align 16
  %1301 = shufflevector <2 x i64> %1291, <2 x i64> %1295, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1301, <2 x i64>* %65, align 16
  %1302 = shufflevector <2 x i64> %1297, <2 x i64> %1299, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1302, <2 x i64>* %66, align 16
  %1303 = shufflevector <2 x i64> %1297, <2 x i64> %1299, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1303, <2 x i64>* %67, align 16
  br label %1304

1304:                                             ; preds = %1304, %1241
  %1305 = phi <2 x i64> [ %1303, %1241 ], [ %1447, %1304 ]
  %1306 = phi <2 x i64> [ %1302, %1241 ], [ %1446, %1304 ]
  %1307 = phi <2 x i64> [ %1301, %1241 ], [ %1445, %1304 ]
  %1308 = phi <2 x i64> [ %1300, %1241 ], [ %1444, %1304 ]
  %1309 = phi i8* [ %1242, %1241 ], [ %1316, %1304 ]
  %1310 = phi i32 [ %1198, %1241 ], [ %1449, %1304 ]
  %1311 = phi i8* [ %1244, %1241 ], [ %1448, %1304 ]
  %1312 = bitcast <2 x i64> %1305 to <16 x i8>
  %1313 = bitcast <2 x i64> %1306 to <16 x i8>
  %1314 = bitcast <2 x i64> %1307 to <16 x i8>
  %1315 = bitcast <2 x i64> %1308 to <16 x i8>
  %1316 = getelementptr inbounds i8, i8* %1309, i64 8
  %1317 = bitcast i8* %1316 to i64*
  %1318 = load i64, i64* %1317, align 1
  %1319 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1318, i32 0
  store <2 x i64> %1319, <2 x i64>* %68, align 16
  %1320 = getelementptr inbounds i8, i8* %1316, i64 %1230
  %1321 = bitcast i8* %1320 to i64*
  %1322 = load i64, i64* %1321, align 1
  %1323 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1322, i32 0
  store <2 x i64> %1323, <2 x i64>* %69, align 16
  %1324 = getelementptr inbounds i8, i8* %1316, i64 %1231
  %1325 = bitcast i8* %1324 to i64*
  %1326 = load i64, i64* %1325, align 1
  %1327 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1326, i32 0
  store <2 x i64> %1327, <2 x i64>* %70, align 16
  %1328 = getelementptr inbounds i8, i8* %1316, i64 %1232
  %1329 = bitcast i8* %1328 to i64*
  %1330 = load i64, i64* %1329, align 1
  %1331 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1330, i32 0
  store <2 x i64> %1331, <2 x i64>* %71, align 16
  %1332 = getelementptr inbounds i8, i8* %1316, i64 %1233
  %1333 = bitcast i8* %1332 to i64*
  %1334 = load i64, i64* %1333, align 1
  %1335 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1334, i32 0
  store <2 x i64> %1335, <2 x i64>* %72, align 16
  %1336 = getelementptr inbounds i8, i8* %1332, i64 %1230
  %1337 = bitcast i8* %1336 to i64*
  %1338 = load i64, i64* %1337, align 1
  %1339 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1338, i32 0
  store <2 x i64> %1339, <2 x i64>* %73, align 16
  %1340 = getelementptr inbounds i8, i8* %1332, i64 %1231
  %1341 = bitcast i8* %1340 to i64*
  %1342 = load i64, i64* %1341, align 1
  %1343 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1342, i32 0
  store <2 x i64> %1343, <2 x i64>* %74, align 16
  %1344 = getelementptr inbounds i8, i8* %1332, i64 %1232
  %1345 = bitcast i8* %1344 to i64*
  %1346 = load i64, i64* %1345, align 1
  %1347 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %1346, i32 0
  store <2 x i64> %1347, <2 x i64>* %75, align 16
  %1348 = bitcast <2 x i64> %1319 to <8 x i16>
  %1349 = bitcast <2 x i64> %1323 to <8 x i16>
  %1350 = shufflevector <8 x i16> %1348, <8 x i16> %1349, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1351 = bitcast <2 x i64> %1327 to <8 x i16>
  %1352 = bitcast <2 x i64> %1331 to <8 x i16>
  %1353 = shufflevector <8 x i16> %1351, <8 x i16> %1352, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1354 = bitcast <2 x i64> %1335 to <8 x i16>
  %1355 = bitcast <2 x i64> %1339 to <8 x i16>
  %1356 = shufflevector <8 x i16> %1354, <8 x i16> %1355, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1357 = bitcast <2 x i64> %1343 to <8 x i16>
  %1358 = bitcast <2 x i64> %1347 to <8 x i16>
  %1359 = shufflevector <8 x i16> %1357, <8 x i16> %1358, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1360 = bitcast <8 x i16> %1350 to <4 x i32>
  %1361 = bitcast <8 x i16> %1353 to <4 x i32>
  %1362 = shufflevector <4 x i32> %1360, <4 x i32> %1361, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1363 = bitcast <4 x i32> %1362 to <2 x i64>
  %1364 = bitcast <8 x i16> %1356 to <4 x i32>
  %1365 = bitcast <8 x i16> %1359 to <4 x i32>
  %1366 = shufflevector <4 x i32> %1364, <4 x i32> %1365, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1367 = bitcast <4 x i32> %1366 to <2 x i64>
  %1368 = shufflevector <4 x i32> %1360, <4 x i32> %1361, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1369 = bitcast <4 x i32> %1368 to <2 x i64>
  %1370 = shufflevector <4 x i32> %1364, <4 x i32> %1365, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1371 = bitcast <4 x i32> %1370 to <2 x i64>
  %1372 = shufflevector <2 x i64> %1363, <2 x i64> %1367, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1372, <2 x i64>* %68, align 16
  %1373 = shufflevector <2 x i64> %1363, <2 x i64> %1367, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1373, <2 x i64>* %69, align 16
  %1374 = shufflevector <2 x i64> %1369, <2 x i64> %1371, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1374, <2 x i64>* %70, align 16
  %1375 = shufflevector <2 x i64> %1369, <2 x i64> %1371, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1375, <2 x i64>* %71, align 16
  %1376 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1315, <16 x i8> %1208) #9
  %1377 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1314, <16 x i8> %1216) #9
  %1378 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1313, <16 x i8> %1209) #9
  %1379 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1312, <16 x i8> %1210) #9
  %1380 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1314, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>) #9
  %1381 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1376, <8 x i16> %1379) #9
  %1382 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1381, <8 x i16> %1377) #9
  %1383 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1382, <8 x i16> %1378) #9
  %1384 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1383, <8 x i16> %1380) #9
  %1385 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1384, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %1386 = ashr <8 x i16> %1385, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1387 = call <2 x i64> %1234(<2 x i64>* %81, <2 x i64>* nonnull %50) #9
  %1388 = load <2 x i64> (<2 x i64>*, <2 x i64>*)*, <2 x i64> (<2 x i64>*, <2 x i64>*)** %82, align 8
  %1389 = call <2 x i64> %1388(<2 x i64>* %85, <2 x i64>* nonnull %55) #9
  %1390 = load <16 x i8>, <16 x i8>* %76, align 16
  %1391 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1390, <16 x i8> %1208) #9
  %1392 = load <16 x i8>, <16 x i8>* %77, align 16
  %1393 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1392, <16 x i8> %1216) #9
  %1394 = load <16 x i8>, <16 x i8>* %86, align 16
  %1395 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1394, <16 x i8> %1209) #9
  %1396 = load <16 x i8>, <16 x i8>* %87, align 16
  %1397 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1396, <16 x i8> %1210) #9
  %1398 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1392, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>) #9
  %1399 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1391, <8 x i16> %1397) #9
  %1400 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1399, <8 x i16> %1393) #9
  %1401 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1400, <8 x i16> %1395) #9
  %1402 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1401, <8 x i16> %1398) #9
  %1403 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1402, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %1404 = ashr <8 x i16> %1403, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1405 = call <2 x i64> %1234(<2 x i64>* %90, <2 x i64>* nonnull %50) #9
  %1406 = call <2 x i64> %1388(<2 x i64>* %93, <2 x i64>* nonnull %55) #9
  %1407 = bitcast <2 x i64> %1389 to <8 x i16>
  %1408 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1386, <8 x i16> %1407) #9
  %1409 = bitcast <2 x i64> %1387 to <8 x i16>
  %1410 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1409, <8 x i16> %1404) #9
  %1411 = bitcast <2 x i64> %1405 to <8 x i16>
  %1412 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1411, <8 x i16> undef) #9
  %1413 = bitcast <2 x i64> %1406 to <8 x i16>
  %1414 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1413, <8 x i16> undef) #9
  %1415 = bitcast <16 x i8> %1408 to <8 x i16>
  %1416 = bitcast <16 x i8> %1410 to <8 x i16>
  %1417 = shufflevector <8 x i16> %1415, <8 x i16> %1416, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1418 = shufflevector <8 x i16> %1415, <8 x i16> %1416, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1419 = bitcast <16 x i8> %1412 to <8 x i16>
  %1420 = bitcast <16 x i8> %1414 to <8 x i16>
  %1421 = shufflevector <8 x i16> %1419, <8 x i16> %1420, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1422 = bitcast <8 x i16> %1417 to <4 x i32>
  %1423 = bitcast <8 x i16> %1418 to <4 x i32>
  %1424 = shufflevector <4 x i32> %1422, <4 x i32> %1423, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1425 = bitcast <4 x i32> %1424 to <2 x i64>
  %1426 = shufflevector <4 x i32> %1422, <4 x i32> %1423, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1427 = bitcast <4 x i32> %1426 to <2 x i64>
  %1428 = bitcast <8 x i16> %1421 to <4 x i32>
  %1429 = shufflevector <4 x i32> %1428, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %1430 = bitcast <4 x i32> %1429 to <2 x i64>
  %1431 = shufflevector <4 x i32> %1428, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %1432 = bitcast <4 x i32> %1431 to <2 x i64>
  %1433 = shufflevector <2 x i64> %1425, <2 x i64> %1430, <2 x i32> <i32 0, i32 2>
  %1434 = shufflevector <2 x i64> %1425, <2 x i64> %1430, <2 x i32> <i32 1, i32 3>
  %1435 = shufflevector <2 x i64> %1427, <2 x i64> %1432, <2 x i32> <i32 0, i32 2>
  %1436 = shufflevector <2 x i64> %1427, <2 x i64> %1432, <2 x i32> <i32 1, i32 3>
  %1437 = bitcast i8* %1311 to <2 x i64>*
  store <2 x i64> %1433, <2 x i64>* %1437, align 1
  %1438 = getelementptr inbounds i8, i8* %1311, i64 %1235
  %1439 = bitcast i8* %1438 to <2 x i64>*
  store <2 x i64> %1434, <2 x i64>* %1439, align 1
  %1440 = getelementptr inbounds i8, i8* %1311, i64 %1236
  %1441 = bitcast i8* %1440 to <2 x i64>*
  store <2 x i64> %1435, <2 x i64>* %1441, align 1
  %1442 = getelementptr inbounds i8, i8* %1311, i64 %1237
  %1443 = bitcast i8* %1442 to <2 x i64>*
  store <2 x i64> %1436, <2 x i64>* %1443, align 1
  %1444 = load <2 x i64>, <2 x i64>* %68, align 16
  store <2 x i64> %1444, <2 x i64>* %64, align 16
  %1445 = load <2 x i64>, <2 x i64>* %69, align 16
  store <2 x i64> %1445, <2 x i64>* %65, align 16
  %1446 = load <2 x i64>, <2 x i64>* %70, align 16
  store <2 x i64> %1446, <2 x i64>* %66, align 16
  %1447 = load <2 x i64>, <2 x i64>* %71, align 16
  store <2 x i64> %1447, <2 x i64>* %67, align 16
  %1448 = getelementptr inbounds i8, i8* %1311, i64 12
  %1449 = add nsw i32 %1310, -6
  %1450 = icmp eq i32 %1449, 0
  br i1 %1450, label %1451, label %1304

1451:                                             ; preds = %1304
  %1452 = getelementptr inbounds i8, i8* %1316, i64 %1229
  %1453 = getelementptr inbounds i8, i8* %1448, i64 %1240
  %1454 = add nsw i32 %1243, -8
  %1455 = icmp eq i32 %1454, 0
  br i1 %1455, label %1456, label %1241

1456:                                             ; preds = %1451
  %1457 = add nsw i32 %113, 7
  %1458 = srem i32 %1204, 6
  %1459 = and i32 %1457, -8
  %1460 = sub nsw i32 %1204, %1458
  %1461 = shl i32 %1460, 1
  %1462 = mul i32 %1461, %1200
  %1463 = sdiv i32 %1462, -3
  %1464 = sext i32 %1463 to i64
  %1465 = shl nsw i32 %1200, 2
  %1466 = sext i32 %1465 to i64
  %1467 = sext i32 %1195 to i64
  %1468 = shl nsw i32 %1195, 1
  %1469 = sext i32 %1468 to i64
  %1470 = mul nsw i32 %1195, 3
  %1471 = sext i32 %1470 to i64
  %1472 = shl nsw i32 %1195, 2
  %1473 = sext i32 %1472 to i64
  %1474 = mul nsw i32 %1195, 5
  %1475 = sext i32 %1474 to i64
  %1476 = mul nsw i32 %1195, 6
  %1477 = sext i32 %1476 to i64
  %1478 = mul nsw i32 %1195, %1460
  %1479 = sext i32 %1478 to i64
  %1480 = sub nsw i64 0, %1479
  br label %1481

1481:                                             ; preds = %1587, %1456
  %1482 = phi i8* [ %1591, %1587 ], [ %1193, %1456 ]
  %1483 = phi i32 [ %1592, %1587 ], [ %1459, %1456 ]
  %1484 = phi i8* [ %1589, %1587 ], [ %1184, %1456 ]
  %1485 = bitcast i8* %1484 to <2 x i64>*
  %1486 = load <2 x i64>, <2 x i64>* %1485, align 1
  store <2 x i64> %1486, <2 x i64>* %64, align 16
  %1487 = getelementptr inbounds i8, i8* %1484, i64 %1235
  %1488 = bitcast i8* %1487 to <2 x i64>*
  %1489 = load <2 x i64>, <2 x i64>* %1488, align 1
  store <2 x i64> %1489, <2 x i64>* %65, align 16
  %1490 = getelementptr inbounds i8, i8* %1484, i64 %1236
  %1491 = bitcast i8* %1490 to <2 x i64>*
  %1492 = load <2 x i64>, <2 x i64>* %1491, align 1
  store <2 x i64> %1492, <2 x i64>* %66, align 16
  %1493 = getelementptr inbounds i8, i8* %1484, i64 %1237
  %1494 = bitcast i8* %1493 to <2 x i64>*
  %1495 = load <2 x i64>, <2 x i64>* %1494, align 1
  store <2 x i64> %1495, <2 x i64>* %67, align 16
  br label %1496

1496:                                             ; preds = %1496, %1481
  %1497 = phi <2 x i64> [ %1495, %1481 ], [ %1583, %1496 ]
  %1498 = phi <2 x i64> [ %1492, %1481 ], [ %1582, %1496 ]
  %1499 = phi <2 x i64> [ %1489, %1481 ], [ %1581, %1496 ]
  %1500 = phi <2 x i64> [ %1486, %1481 ], [ %1580, %1496 ]
  %1501 = phi i8* [ %1482, %1481 ], [ %1584, %1496 ]
  %1502 = phi i32 [ %1460, %1481 ], [ %1585, %1496 ]
  %1503 = phi i8* [ %1484, %1481 ], [ %1508, %1496 ]
  %1504 = bitcast <2 x i64> %1497 to <16 x i8>
  %1505 = bitcast <2 x i64> %1498 to <16 x i8>
  %1506 = bitcast <2 x i64> %1499 to <16 x i8>
  %1507 = bitcast <2 x i64> %1500 to <16 x i8>
  %1508 = getelementptr inbounds i8, i8* %1503, i64 %1466
  %1509 = bitcast i8* %1508 to <2 x i64>*
  %1510 = load <2 x i64>, <2 x i64>* %1509, align 1
  store <2 x i64> %1510, <2 x i64>* %68, align 16
  %1511 = getelementptr inbounds i8, i8* %1508, i64 %1235
  %1512 = bitcast i8* %1511 to <2 x i64>*
  %1513 = load <2 x i64>, <2 x i64>* %1512, align 1
  store <2 x i64> %1513, <2 x i64>* %69, align 16
  %1514 = getelementptr inbounds i8, i8* %1508, i64 %1236
  %1515 = bitcast i8* %1514 to <2 x i64>*
  %1516 = load <2 x i64>, <2 x i64>* %1515, align 1
  store <2 x i64> %1516, <2 x i64>* %70, align 16
  %1517 = getelementptr inbounds i8, i8* %1508, i64 %1237
  %1518 = bitcast i8* %1517 to <2 x i64>*
  %1519 = load <2 x i64>, <2 x i64>* %1518, align 1
  store <2 x i64> %1519, <2 x i64>* %71, align 16
  %1520 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1507, <16 x i8> %1208) #9
  %1521 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1506, <16 x i8> %1216) #9
  %1522 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1505, <16 x i8> %1209) #9
  %1523 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1504, <16 x i8> %1210) #9
  %1524 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1506, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>) #9
  %1525 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1520, <8 x i16> %1523) #9
  %1526 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1525, <8 x i16> %1521) #9
  %1527 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1526, <8 x i16> %1522) #9
  %1528 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1527, <8 x i16> %1524) #9
  %1529 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1528, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %1530 = ashr <8 x i16> %1529, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1531 = call <2 x i64> %1234(<2 x i64>* %81, <2 x i64>* nonnull %50) #9
  %1532 = call <2 x i64> %1388(<2 x i64>* %85, <2 x i64>* nonnull %55) #9
  %1533 = load <16 x i8>, <16 x i8>* %76, align 16
  %1534 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1533, <16 x i8> %1208) #9
  %1535 = load <16 x i8>, <16 x i8>* %77, align 16
  %1536 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1535, <16 x i8> %1216) #9
  %1537 = load <16 x i8>, <16 x i8>* %86, align 16
  %1538 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1537, <16 x i8> %1209) #9
  %1539 = load <16 x i8>, <16 x i8>* %87, align 16
  %1540 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1539, <16 x i8> %1210) #9
  %1541 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1535, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>) #9
  %1542 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1534, <8 x i16> %1540) #9
  %1543 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1542, <8 x i16> %1536) #9
  %1544 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1543, <8 x i16> %1538) #9
  %1545 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1544, <8 x i16> %1541) #9
  %1546 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1545, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %1547 = ashr <8 x i16> %1546, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1548 = call <2 x i64> %1234(<2 x i64>* %90, <2 x i64>* nonnull %50) #9
  %1549 = call <2 x i64> %1388(<2 x i64>* %93, <2 x i64>* nonnull %55) #9
  %1550 = bitcast <2 x i64> %1531 to <8 x i16>
  %1551 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1530, <8 x i16> %1550) #9
  %1552 = bitcast <16 x i8> %1551 to <2 x i64>
  %1553 = bitcast <2 x i64> %1532 to <8 x i16>
  %1554 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1553, <8 x i16> %1547) #9
  %1555 = bitcast <16 x i8> %1554 to <2 x i64>
  %1556 = bitcast <2 x i64> %1548 to <8 x i16>
  %1557 = bitcast <2 x i64> %1549 to <8 x i16>
  %1558 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1556, <8 x i16> %1557) #9
  %1559 = bitcast <16 x i8> %1558 to <2 x i64>
  %1560 = extractelement <2 x i64> %1552, i32 0
  %1561 = bitcast i8* %1501 to i64*
  store i64 %1560, i64* %1561, align 1
  %1562 = getelementptr inbounds i8, i8* %1501, i64 %1467
  %1563 = bitcast <16 x i8> %1551 to <4 x float>
  %1564 = shufflevector <4 x float> %1563, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %1565 = bitcast i8* %1562 to <2 x float>*
  store <2 x float> %1564, <2 x float>* %1565, align 1
  %1566 = getelementptr inbounds i8, i8* %1501, i64 %1469
  %1567 = extractelement <2 x i64> %1555, i32 0
  %1568 = bitcast i8* %1566 to i64*
  store i64 %1567, i64* %1568, align 1
  %1569 = getelementptr inbounds i8, i8* %1501, i64 %1471
  %1570 = bitcast <16 x i8> %1554 to <4 x float>
  %1571 = shufflevector <4 x float> %1570, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %1572 = bitcast i8* %1569 to <2 x float>*
  store <2 x float> %1571, <2 x float>* %1572, align 1
  %1573 = getelementptr inbounds i8, i8* %1501, i64 %1473
  %1574 = extractelement <2 x i64> %1559, i32 0
  %1575 = bitcast i8* %1573 to i64*
  store i64 %1574, i64* %1575, align 1
  %1576 = getelementptr inbounds i8, i8* %1501, i64 %1475
  %1577 = bitcast <16 x i8> %1558 to <4 x float>
  %1578 = shufflevector <4 x float> %1577, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %1579 = bitcast i8* %1576 to <2 x float>*
  store <2 x float> %1578, <2 x float>* %1579, align 1
  %1580 = load <2 x i64>, <2 x i64>* %68, align 16
  store <2 x i64> %1580, <2 x i64>* %64, align 16
  %1581 = load <2 x i64>, <2 x i64>* %69, align 16
  store <2 x i64> %1581, <2 x i64>* %65, align 16
  %1582 = load <2 x i64>, <2 x i64>* %70, align 16
  store <2 x i64> %1582, <2 x i64>* %66, align 16
  %1583 = load <2 x i64>, <2 x i64>* %71, align 16
  store <2 x i64> %1583, <2 x i64>* %67, align 16
  %1584 = getelementptr inbounds i8, i8* %1501, i64 %1477
  %1585 = add nsw i32 %1502, -6
  %1586 = icmp eq i32 %1585, 0
  br i1 %1586, label %1587, label %1496

1587:                                             ; preds = %1496
  %1588 = getelementptr inbounds i8, i8* %1508, i64 16
  %1589 = getelementptr inbounds i8, i8* %1588, i64 %1464
  %1590 = getelementptr inbounds i8, i8* %1584, i64 8
  %1591 = getelementptr inbounds i8, i8* %1590, i64 %1480
  %1592 = add nsw i32 %1483, -8
  %1593 = icmp eq i32 %1592, 0
  br i1 %1593, label %1594, label %1481

1594:                                             ; preds = %1587
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %37) #9
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %36) #9
  call void @llvm.lifetime.end.p0i8(i64 192, i8* nonnull %35) #9
  call void @free(i8* %1184) #9
  br label %2335

1595:                                             ; preds = %1160
  %1596 = shl nsw i32 %108, 1
  %1597 = icmp eq i32 %113, %1596
  %1598 = shl nsw i32 %110, 1
  %1599 = icmp eq i32 %115, %1598
  %1600 = and i1 %1597, %1599
  br i1 %1600, label %1601, label %2335

1601:                                             ; preds = %1595
  %1602 = shl i32 %111, 3
  %1603 = add i32 %1602, 8
  %1604 = and i32 %1603, -16
  %1605 = add i32 %1604, 56
  %1606 = and i32 %1605, -64
  %1607 = sext i32 %1606 to i64
  %1608 = call noalias i8* @malloc(i64 %1607) #9
  %1609 = icmp eq i8* %1608, null
  br i1 %1609, label %2335, label %1610

1610:                                             ; preds = %1601
  %1611 = load [8 x i16]*, [8 x i16]** %26, align 16
  %1612 = getelementptr inbounds [3 x i8*], [3 x i8*]* %28, i64 0, i64 %103
  %1613 = load i8*, i8** %1612, align 8
  %1614 = getelementptr inbounds [2 x i32], [2 x i32]* %30, i64 0, i64 %106
  %1615 = load i32, i32* %1614, align 4
  %1616 = sext i32 %1615 to i64
  %1617 = getelementptr inbounds [3 x i8*], [3 x i8*]* %32, i64 0, i64 %103
  %1618 = load i8*, i8** %1617, align 8
  %1619 = getelementptr inbounds [2 x i32], [2 x i32]* %34, i64 0, i64 %106
  %1620 = load i32, i32* %1619, align 4
  %1621 = getelementptr inbounds [8 x i16], [8 x i16]* %1611, i64 8, i64 0
  %1622 = add nsw i32 %108, 7
  %1623 = and i32 %1622, -8
  %1624 = shl nsw i32 %1623, 1
  %1625 = mul nsw i32 %1623, 3
  %1626 = shl nsw i32 %1623, 2
  %1627 = mul nsw i32 %1623, 5
  %1628 = mul nsw i32 %1623, 6
  %1629 = mul nsw i32 %1623, 7
  %1630 = bitcast i16* %1621 to <16 x i8>*
  %1631 = load <16 x i8>, <16 x i8>* %1630, align 16
  %1632 = shufflevector <16 x i8> %1631, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2>
  %1633 = shufflevector <16 x i8> %1631, <16 x i8> undef, <16 x i32> <i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6>
  %1634 = shufflevector <16 x i8> %1631, <16 x i8> undef, <16 x i32> <i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10>
  %1635 = shufflevector <16 x i8> %1631, <16 x i8> undef, <16 x i32> <i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14>
  %1636 = mul nsw i64 %1616, 3
  %1637 = sub nsw i64 0, %1636
  %1638 = getelementptr inbounds i8, i8* %1613, i64 -3
  %1639 = getelementptr inbounds i8, i8* %1638, i64 %1637
  br label %1640

1640:                                             ; preds = %1640, %1610
  %1641 = phi i8* [ %1608, %1610 ], [ %1701, %1640 ]
  %1642 = phi i32 [ %1623, %1610 ], [ %1702, %1640 ]
  %1643 = phi i8* [ %1639, %1610 ], [ %1700, %1640 ]
  %1644 = bitcast i8* %1643 to i64*
  %1645 = load i64, i64* %1644, align 1
  %1646 = insertelement <2 x i64> undef, i64 %1645, i32 0
  %1647 = getelementptr inbounds i8, i8* %1643, i64 1
  %1648 = bitcast i8* %1647 to i64*
  %1649 = load i64, i64* %1648, align 1
  %1650 = insertelement <2 x i64> undef, i64 %1649, i32 0
  %1651 = getelementptr inbounds i8, i8* %1643, i64 2
  %1652 = bitcast i8* %1651 to i64*
  %1653 = load i64, i64* %1652, align 1
  %1654 = insertelement <2 x i64> undef, i64 %1653, i32 0
  %1655 = getelementptr inbounds i8, i8* %1643, i64 3
  %1656 = bitcast i8* %1655 to i64*
  %1657 = load i64, i64* %1656, align 1
  %1658 = insertelement <2 x i64> undef, i64 %1657, i32 0
  %1659 = getelementptr inbounds i8, i8* %1643, i64 4
  %1660 = bitcast i8* %1659 to i64*
  %1661 = load i64, i64* %1660, align 1
  %1662 = insertelement <2 x i64> undef, i64 %1661, i32 0
  %1663 = getelementptr inbounds i8, i8* %1643, i64 5
  %1664 = bitcast i8* %1663 to i64*
  %1665 = load i64, i64* %1664, align 1
  %1666 = insertelement <2 x i64> undef, i64 %1665, i32 0
  %1667 = getelementptr inbounds i8, i8* %1643, i64 6
  %1668 = bitcast i8* %1667 to i64*
  %1669 = load i64, i64* %1668, align 1
  %1670 = insertelement <2 x i64> undef, i64 %1669, i32 0
  %1671 = getelementptr inbounds i8, i8* %1643, i64 7
  %1672 = bitcast i8* %1671 to i64*
  %1673 = load i64, i64* %1672, align 1
  %1674 = insertelement <2 x i64> undef, i64 %1673, i32 0
  %1675 = bitcast <2 x i64> %1646 to <16 x i8>
  %1676 = bitcast <2 x i64> %1650 to <16 x i8>
  %1677 = shufflevector <16 x i8> %1675, <16 x i8> %1676, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1678 = bitcast <2 x i64> %1654 to <16 x i8>
  %1679 = bitcast <2 x i64> %1658 to <16 x i8>
  %1680 = shufflevector <16 x i8> %1678, <16 x i8> %1679, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1681 = bitcast <2 x i64> %1662 to <16 x i8>
  %1682 = bitcast <2 x i64> %1666 to <16 x i8>
  %1683 = shufflevector <16 x i8> %1681, <16 x i8> %1682, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1684 = bitcast <2 x i64> %1670 to <16 x i8>
  %1685 = bitcast <2 x i64> %1674 to <16 x i8>
  %1686 = shufflevector <16 x i8> %1684, <16 x i8> %1685, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1687 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1677, <16 x i8> %1632) #9
  %1688 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1680, <16 x i8> %1633) #9
  %1689 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1683, <16 x i8> %1634) #9
  %1690 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1686, <16 x i8> %1635) #9
  %1691 = add <8 x i16> %1690, %1688
  %1692 = add <8 x i16> %1687, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %1693 = add <8 x i16> %1692, %1689
  %1694 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1693, <8 x i16> %1691) #9
  %1695 = ashr <8 x i16> %1694, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1696 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1695, <8 x i16> undef) #9
  %1697 = bitcast <16 x i8> %1696 to <2 x i64>
  %1698 = extractelement <2 x i64> %1697, i32 0
  %1699 = bitcast i8* %1641 to i64*
  store i64 %1698, i64* %1699, align 1
  %1700 = getelementptr inbounds i8, i8* %1643, i64 8
  %1701 = getelementptr inbounds i8, i8* %1641, i64 8
  %1702 = add nsw i32 %1642, -8
  %1703 = icmp eq i32 %1702, 0
  br i1 %1703, label %1704, label %1640

1704:                                             ; preds = %1640
  %1705 = sext i32 %1623 to i64
  %1706 = sext i32 %1624 to i64
  %1707 = sext i32 %1626 to i64
  %1708 = sext i32 %1628 to i64
  %1709 = getelementptr inbounds i8, i8* %1608, i64 %1705
  %1710 = getelementptr inbounds i8, i8* %1608, i64 %1706
  %1711 = getelementptr inbounds i8, i8* %1608, i64 %1707
  %1712 = getelementptr inbounds i8, i8* %1608, i64 %1708
  %1713 = shl nsw i64 %1616, 1
  %1714 = sub nsw i64 0, %1713
  %1715 = getelementptr inbounds i8, i8* %1638, i64 %1714
  br label %1716

1716:                                             ; preds = %1716, %1704
  %1717 = phi i8* [ %1709, %1704 ], [ %1777, %1716 ]
  %1718 = phi i32 [ %1623, %1704 ], [ %1778, %1716 ]
  %1719 = phi i8* [ %1715, %1704 ], [ %1776, %1716 ]
  %1720 = bitcast i8* %1719 to i64*
  %1721 = load i64, i64* %1720, align 1
  %1722 = insertelement <2 x i64> undef, i64 %1721, i32 0
  %1723 = getelementptr inbounds i8, i8* %1719, i64 1
  %1724 = bitcast i8* %1723 to i64*
  %1725 = load i64, i64* %1724, align 1
  %1726 = insertelement <2 x i64> undef, i64 %1725, i32 0
  %1727 = getelementptr inbounds i8, i8* %1719, i64 2
  %1728 = bitcast i8* %1727 to i64*
  %1729 = load i64, i64* %1728, align 1
  %1730 = insertelement <2 x i64> undef, i64 %1729, i32 0
  %1731 = getelementptr inbounds i8, i8* %1719, i64 3
  %1732 = bitcast i8* %1731 to i64*
  %1733 = load i64, i64* %1732, align 1
  %1734 = insertelement <2 x i64> undef, i64 %1733, i32 0
  %1735 = getelementptr inbounds i8, i8* %1719, i64 4
  %1736 = bitcast i8* %1735 to i64*
  %1737 = load i64, i64* %1736, align 1
  %1738 = insertelement <2 x i64> undef, i64 %1737, i32 0
  %1739 = getelementptr inbounds i8, i8* %1719, i64 5
  %1740 = bitcast i8* %1739 to i64*
  %1741 = load i64, i64* %1740, align 1
  %1742 = insertelement <2 x i64> undef, i64 %1741, i32 0
  %1743 = getelementptr inbounds i8, i8* %1719, i64 6
  %1744 = bitcast i8* %1743 to i64*
  %1745 = load i64, i64* %1744, align 1
  %1746 = insertelement <2 x i64> undef, i64 %1745, i32 0
  %1747 = getelementptr inbounds i8, i8* %1719, i64 7
  %1748 = bitcast i8* %1747 to i64*
  %1749 = load i64, i64* %1748, align 1
  %1750 = insertelement <2 x i64> undef, i64 %1749, i32 0
  %1751 = bitcast <2 x i64> %1722 to <16 x i8>
  %1752 = bitcast <2 x i64> %1726 to <16 x i8>
  %1753 = shufflevector <16 x i8> %1751, <16 x i8> %1752, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1754 = bitcast <2 x i64> %1730 to <16 x i8>
  %1755 = bitcast <2 x i64> %1734 to <16 x i8>
  %1756 = shufflevector <16 x i8> %1754, <16 x i8> %1755, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1757 = bitcast <2 x i64> %1738 to <16 x i8>
  %1758 = bitcast <2 x i64> %1742 to <16 x i8>
  %1759 = shufflevector <16 x i8> %1757, <16 x i8> %1758, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1760 = bitcast <2 x i64> %1746 to <16 x i8>
  %1761 = bitcast <2 x i64> %1750 to <16 x i8>
  %1762 = shufflevector <16 x i8> %1760, <16 x i8> %1761, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1763 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1753, <16 x i8> %1632) #9
  %1764 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1756, <16 x i8> %1633) #9
  %1765 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1759, <16 x i8> %1634) #9
  %1766 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1762, <16 x i8> %1635) #9
  %1767 = add <8 x i16> %1766, %1764
  %1768 = add <8 x i16> %1763, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %1769 = add <8 x i16> %1768, %1765
  %1770 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1769, <8 x i16> %1767) #9
  %1771 = ashr <8 x i16> %1770, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1772 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1771, <8 x i16> undef) #9
  %1773 = bitcast <16 x i8> %1772 to <2 x i64>
  %1774 = extractelement <2 x i64> %1773, i32 0
  %1775 = bitcast i8* %1717 to i64*
  store i64 %1774, i64* %1775, align 1
  %1776 = getelementptr inbounds i8, i8* %1719, i64 8
  %1777 = getelementptr inbounds i8, i8* %1717, i64 8
  %1778 = add nsw i32 %1718, -8
  %1779 = icmp eq i32 %1778, 0
  br i1 %1779, label %1780, label %1716

1780:                                             ; preds = %1716
  %1781 = sext i32 %1620 to i64
  %1782 = sext i32 %1627 to i64
  %1783 = sext i32 %1629 to i64
  %1784 = getelementptr inbounds i8, i8* %1608, i64 %1782
  %1785 = sub nsw i64 0, %1616
  %1786 = getelementptr inbounds i8, i8* %1638, i64 %1785
  br label %1787

1787:                                             ; preds = %1787, %1780
  %1788 = phi i8* [ %1710, %1780 ], [ %1848, %1787 ]
  %1789 = phi i32 [ %1623, %1780 ], [ %1849, %1787 ]
  %1790 = phi i8* [ %1786, %1780 ], [ %1847, %1787 ]
  %1791 = bitcast i8* %1790 to i64*
  %1792 = load i64, i64* %1791, align 1
  %1793 = insertelement <2 x i64> undef, i64 %1792, i32 0
  %1794 = getelementptr inbounds i8, i8* %1790, i64 1
  %1795 = bitcast i8* %1794 to i64*
  %1796 = load i64, i64* %1795, align 1
  %1797 = insertelement <2 x i64> undef, i64 %1796, i32 0
  %1798 = getelementptr inbounds i8, i8* %1790, i64 2
  %1799 = bitcast i8* %1798 to i64*
  %1800 = load i64, i64* %1799, align 1
  %1801 = insertelement <2 x i64> undef, i64 %1800, i32 0
  %1802 = getelementptr inbounds i8, i8* %1790, i64 3
  %1803 = bitcast i8* %1802 to i64*
  %1804 = load i64, i64* %1803, align 1
  %1805 = insertelement <2 x i64> undef, i64 %1804, i32 0
  %1806 = getelementptr inbounds i8, i8* %1790, i64 4
  %1807 = bitcast i8* %1806 to i64*
  %1808 = load i64, i64* %1807, align 1
  %1809 = insertelement <2 x i64> undef, i64 %1808, i32 0
  %1810 = getelementptr inbounds i8, i8* %1790, i64 5
  %1811 = bitcast i8* %1810 to i64*
  %1812 = load i64, i64* %1811, align 1
  %1813 = insertelement <2 x i64> undef, i64 %1812, i32 0
  %1814 = getelementptr inbounds i8, i8* %1790, i64 6
  %1815 = bitcast i8* %1814 to i64*
  %1816 = load i64, i64* %1815, align 1
  %1817 = insertelement <2 x i64> undef, i64 %1816, i32 0
  %1818 = getelementptr inbounds i8, i8* %1790, i64 7
  %1819 = bitcast i8* %1818 to i64*
  %1820 = load i64, i64* %1819, align 1
  %1821 = insertelement <2 x i64> undef, i64 %1820, i32 0
  %1822 = bitcast <2 x i64> %1793 to <16 x i8>
  %1823 = bitcast <2 x i64> %1797 to <16 x i8>
  %1824 = shufflevector <16 x i8> %1822, <16 x i8> %1823, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1825 = bitcast <2 x i64> %1801 to <16 x i8>
  %1826 = bitcast <2 x i64> %1805 to <16 x i8>
  %1827 = shufflevector <16 x i8> %1825, <16 x i8> %1826, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1828 = bitcast <2 x i64> %1809 to <16 x i8>
  %1829 = bitcast <2 x i64> %1813 to <16 x i8>
  %1830 = shufflevector <16 x i8> %1828, <16 x i8> %1829, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1831 = bitcast <2 x i64> %1817 to <16 x i8>
  %1832 = bitcast <2 x i64> %1821 to <16 x i8>
  %1833 = shufflevector <16 x i8> %1831, <16 x i8> %1832, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1834 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1824, <16 x i8> %1632) #9
  %1835 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1827, <16 x i8> %1633) #9
  %1836 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1830, <16 x i8> %1634) #9
  %1837 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1833, <16 x i8> %1635) #9
  %1838 = add <8 x i16> %1837, %1835
  %1839 = add <8 x i16> %1834, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %1840 = add <8 x i16> %1839, %1836
  %1841 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1840, <8 x i16> %1838) #9
  %1842 = ashr <8 x i16> %1841, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1843 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1842, <8 x i16> undef) #9
  %1844 = bitcast <16 x i8> %1843 to <2 x i64>
  %1845 = extractelement <2 x i64> %1844, i32 0
  %1846 = bitcast i8* %1788 to i64*
  store i64 %1845, i64* %1846, align 1
  %1847 = getelementptr inbounds i8, i8* %1790, i64 8
  %1848 = getelementptr inbounds i8, i8* %1788, i64 8
  %1849 = add nsw i32 %1789, -8
  %1850 = icmp eq i32 %1849, 0
  br i1 %1850, label %1851, label %1787

1851:                                             ; preds = %1787
  %1852 = sext i32 %1625 to i64
  %1853 = getelementptr inbounds i8, i8* %1608, i64 %1852
  br label %1854

1854:                                             ; preds = %1854, %1851
  %1855 = phi i8* [ %1853, %1851 ], [ %1915, %1854 ]
  %1856 = phi i32 [ %1623, %1851 ], [ %1916, %1854 ]
  %1857 = phi i8* [ %1638, %1851 ], [ %1914, %1854 ]
  %1858 = bitcast i8* %1857 to i64*
  %1859 = load i64, i64* %1858, align 1
  %1860 = insertelement <2 x i64> undef, i64 %1859, i32 0
  %1861 = getelementptr inbounds i8, i8* %1857, i64 1
  %1862 = bitcast i8* %1861 to i64*
  %1863 = load i64, i64* %1862, align 1
  %1864 = insertelement <2 x i64> undef, i64 %1863, i32 0
  %1865 = getelementptr inbounds i8, i8* %1857, i64 2
  %1866 = bitcast i8* %1865 to i64*
  %1867 = load i64, i64* %1866, align 1
  %1868 = insertelement <2 x i64> undef, i64 %1867, i32 0
  %1869 = getelementptr inbounds i8, i8* %1857, i64 3
  %1870 = bitcast i8* %1869 to i64*
  %1871 = load i64, i64* %1870, align 1
  %1872 = insertelement <2 x i64> undef, i64 %1871, i32 0
  %1873 = getelementptr inbounds i8, i8* %1857, i64 4
  %1874 = bitcast i8* %1873 to i64*
  %1875 = load i64, i64* %1874, align 1
  %1876 = insertelement <2 x i64> undef, i64 %1875, i32 0
  %1877 = getelementptr inbounds i8, i8* %1857, i64 5
  %1878 = bitcast i8* %1877 to i64*
  %1879 = load i64, i64* %1878, align 1
  %1880 = insertelement <2 x i64> undef, i64 %1879, i32 0
  %1881 = getelementptr inbounds i8, i8* %1857, i64 6
  %1882 = bitcast i8* %1881 to i64*
  %1883 = load i64, i64* %1882, align 1
  %1884 = insertelement <2 x i64> undef, i64 %1883, i32 0
  %1885 = getelementptr inbounds i8, i8* %1857, i64 7
  %1886 = bitcast i8* %1885 to i64*
  %1887 = load i64, i64* %1886, align 1
  %1888 = insertelement <2 x i64> undef, i64 %1887, i32 0
  %1889 = bitcast <2 x i64> %1860 to <16 x i8>
  %1890 = bitcast <2 x i64> %1864 to <16 x i8>
  %1891 = shufflevector <16 x i8> %1889, <16 x i8> %1890, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1892 = bitcast <2 x i64> %1868 to <16 x i8>
  %1893 = bitcast <2 x i64> %1872 to <16 x i8>
  %1894 = shufflevector <16 x i8> %1892, <16 x i8> %1893, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1895 = bitcast <2 x i64> %1876 to <16 x i8>
  %1896 = bitcast <2 x i64> %1880 to <16 x i8>
  %1897 = shufflevector <16 x i8> %1895, <16 x i8> %1896, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1898 = bitcast <2 x i64> %1884 to <16 x i8>
  %1899 = bitcast <2 x i64> %1888 to <16 x i8>
  %1900 = shufflevector <16 x i8> %1898, <16 x i8> %1899, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1901 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1891, <16 x i8> %1632) #9
  %1902 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1894, <16 x i8> %1633) #9
  %1903 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1897, <16 x i8> %1634) #9
  %1904 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1900, <16 x i8> %1635) #9
  %1905 = add <8 x i16> %1904, %1902
  %1906 = add <8 x i16> %1901, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %1907 = add <8 x i16> %1906, %1903
  %1908 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1907, <8 x i16> %1905) #9
  %1909 = ashr <8 x i16> %1908, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1910 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1909, <8 x i16> undef) #9
  %1911 = bitcast <16 x i8> %1910 to <2 x i64>
  %1912 = extractelement <2 x i64> %1911, i32 0
  %1913 = bitcast i8* %1855 to i64*
  store i64 %1912, i64* %1913, align 1
  %1914 = getelementptr inbounds i8, i8* %1857, i64 8
  %1915 = getelementptr inbounds i8, i8* %1855, i64 8
  %1916 = add nsw i32 %1856, -8
  %1917 = icmp eq i32 %1916, 0
  br i1 %1917, label %1918, label %1854

1918:                                             ; preds = %1854
  %1919 = getelementptr inbounds i8, i8* %1638, i64 %1616
  br label %1920

1920:                                             ; preds = %1920, %1918
  %1921 = phi i8* [ %1711, %1918 ], [ %1981, %1920 ]
  %1922 = phi i32 [ %1623, %1918 ], [ %1982, %1920 ]
  %1923 = phi i8* [ %1919, %1918 ], [ %1980, %1920 ]
  %1924 = bitcast i8* %1923 to i64*
  %1925 = load i64, i64* %1924, align 1
  %1926 = insertelement <2 x i64> undef, i64 %1925, i32 0
  %1927 = getelementptr inbounds i8, i8* %1923, i64 1
  %1928 = bitcast i8* %1927 to i64*
  %1929 = load i64, i64* %1928, align 1
  %1930 = insertelement <2 x i64> undef, i64 %1929, i32 0
  %1931 = getelementptr inbounds i8, i8* %1923, i64 2
  %1932 = bitcast i8* %1931 to i64*
  %1933 = load i64, i64* %1932, align 1
  %1934 = insertelement <2 x i64> undef, i64 %1933, i32 0
  %1935 = getelementptr inbounds i8, i8* %1923, i64 3
  %1936 = bitcast i8* %1935 to i64*
  %1937 = load i64, i64* %1936, align 1
  %1938 = insertelement <2 x i64> undef, i64 %1937, i32 0
  %1939 = getelementptr inbounds i8, i8* %1923, i64 4
  %1940 = bitcast i8* %1939 to i64*
  %1941 = load i64, i64* %1940, align 1
  %1942 = insertelement <2 x i64> undef, i64 %1941, i32 0
  %1943 = getelementptr inbounds i8, i8* %1923, i64 5
  %1944 = bitcast i8* %1943 to i64*
  %1945 = load i64, i64* %1944, align 1
  %1946 = insertelement <2 x i64> undef, i64 %1945, i32 0
  %1947 = getelementptr inbounds i8, i8* %1923, i64 6
  %1948 = bitcast i8* %1947 to i64*
  %1949 = load i64, i64* %1948, align 1
  %1950 = insertelement <2 x i64> undef, i64 %1949, i32 0
  %1951 = getelementptr inbounds i8, i8* %1923, i64 7
  %1952 = bitcast i8* %1951 to i64*
  %1953 = load i64, i64* %1952, align 1
  %1954 = insertelement <2 x i64> undef, i64 %1953, i32 0
  %1955 = bitcast <2 x i64> %1926 to <16 x i8>
  %1956 = bitcast <2 x i64> %1930 to <16 x i8>
  %1957 = shufflevector <16 x i8> %1955, <16 x i8> %1956, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1958 = bitcast <2 x i64> %1934 to <16 x i8>
  %1959 = bitcast <2 x i64> %1938 to <16 x i8>
  %1960 = shufflevector <16 x i8> %1958, <16 x i8> %1959, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1961 = bitcast <2 x i64> %1942 to <16 x i8>
  %1962 = bitcast <2 x i64> %1946 to <16 x i8>
  %1963 = shufflevector <16 x i8> %1961, <16 x i8> %1962, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1964 = bitcast <2 x i64> %1950 to <16 x i8>
  %1965 = bitcast <2 x i64> %1954 to <16 x i8>
  %1966 = shufflevector <16 x i8> %1964, <16 x i8> %1965, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1967 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1957, <16 x i8> %1632) #9
  %1968 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1960, <16 x i8> %1633) #9
  %1969 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1963, <16 x i8> %1634) #9
  %1970 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1966, <16 x i8> %1635) #9
  %1971 = add <8 x i16> %1970, %1968
  %1972 = add <8 x i16> %1967, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %1973 = add <8 x i16> %1972, %1969
  %1974 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1973, <8 x i16> %1971) #9
  %1975 = ashr <8 x i16> %1974, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %1976 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1975, <8 x i16> undef) #9
  %1977 = bitcast <16 x i8> %1976 to <2 x i64>
  %1978 = extractelement <2 x i64> %1977, i32 0
  %1979 = bitcast i8* %1921 to i64*
  store i64 %1978, i64* %1979, align 1
  %1980 = getelementptr inbounds i8, i8* %1923, i64 8
  %1981 = getelementptr inbounds i8, i8* %1921, i64 8
  %1982 = add nsw i32 %1922, -8
  %1983 = icmp eq i32 %1982, 0
  br i1 %1983, label %1984, label %1920

1984:                                             ; preds = %1920
  %1985 = getelementptr inbounds i8, i8* %1638, i64 %1713
  br label %1986

1986:                                             ; preds = %1986, %1984
  %1987 = phi i8* [ %1784, %1984 ], [ %2047, %1986 ]
  %1988 = phi i32 [ %1623, %1984 ], [ %2048, %1986 ]
  %1989 = phi i8* [ %1985, %1984 ], [ %2046, %1986 ]
  %1990 = bitcast i8* %1989 to i64*
  %1991 = load i64, i64* %1990, align 1
  %1992 = insertelement <2 x i64> undef, i64 %1991, i32 0
  %1993 = getelementptr inbounds i8, i8* %1989, i64 1
  %1994 = bitcast i8* %1993 to i64*
  %1995 = load i64, i64* %1994, align 1
  %1996 = insertelement <2 x i64> undef, i64 %1995, i32 0
  %1997 = getelementptr inbounds i8, i8* %1989, i64 2
  %1998 = bitcast i8* %1997 to i64*
  %1999 = load i64, i64* %1998, align 1
  %2000 = insertelement <2 x i64> undef, i64 %1999, i32 0
  %2001 = getelementptr inbounds i8, i8* %1989, i64 3
  %2002 = bitcast i8* %2001 to i64*
  %2003 = load i64, i64* %2002, align 1
  %2004 = insertelement <2 x i64> undef, i64 %2003, i32 0
  %2005 = getelementptr inbounds i8, i8* %1989, i64 4
  %2006 = bitcast i8* %2005 to i64*
  %2007 = load i64, i64* %2006, align 1
  %2008 = insertelement <2 x i64> undef, i64 %2007, i32 0
  %2009 = getelementptr inbounds i8, i8* %1989, i64 5
  %2010 = bitcast i8* %2009 to i64*
  %2011 = load i64, i64* %2010, align 1
  %2012 = insertelement <2 x i64> undef, i64 %2011, i32 0
  %2013 = getelementptr inbounds i8, i8* %1989, i64 6
  %2014 = bitcast i8* %2013 to i64*
  %2015 = load i64, i64* %2014, align 1
  %2016 = insertelement <2 x i64> undef, i64 %2015, i32 0
  %2017 = getelementptr inbounds i8, i8* %1989, i64 7
  %2018 = bitcast i8* %2017 to i64*
  %2019 = load i64, i64* %2018, align 1
  %2020 = insertelement <2 x i64> undef, i64 %2019, i32 0
  %2021 = bitcast <2 x i64> %1992 to <16 x i8>
  %2022 = bitcast <2 x i64> %1996 to <16 x i8>
  %2023 = shufflevector <16 x i8> %2021, <16 x i8> %2022, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2024 = bitcast <2 x i64> %2000 to <16 x i8>
  %2025 = bitcast <2 x i64> %2004 to <16 x i8>
  %2026 = shufflevector <16 x i8> %2024, <16 x i8> %2025, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2027 = bitcast <2 x i64> %2008 to <16 x i8>
  %2028 = bitcast <2 x i64> %2012 to <16 x i8>
  %2029 = shufflevector <16 x i8> %2027, <16 x i8> %2028, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2030 = bitcast <2 x i64> %2016 to <16 x i8>
  %2031 = bitcast <2 x i64> %2020 to <16 x i8>
  %2032 = shufflevector <16 x i8> %2030, <16 x i8> %2031, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2033 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2023, <16 x i8> %1632) #9
  %2034 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2026, <16 x i8> %1633) #9
  %2035 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2029, <16 x i8> %1634) #9
  %2036 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2032, <16 x i8> %1635) #9
  %2037 = add <8 x i16> %2036, %2034
  %2038 = add <8 x i16> %2033, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %2039 = add <8 x i16> %2038, %2035
  %2040 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %2039, <8 x i16> %2037) #9
  %2041 = ashr <8 x i16> %2040, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %2042 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2041, <8 x i16> undef) #9
  %2043 = bitcast <16 x i8> %2042 to <2 x i64>
  %2044 = extractelement <2 x i64> %2043, i32 0
  %2045 = bitcast i8* %1987 to i64*
  store i64 %2044, i64* %2045, align 1
  %2046 = getelementptr inbounds i8, i8* %1989, i64 8
  %2047 = getelementptr inbounds i8, i8* %1987, i64 8
  %2048 = add nsw i32 %1988, -8
  %2049 = icmp eq i32 %2048, 0
  br i1 %2049, label %2050, label %1986

2050:                                             ; preds = %1986
  %2051 = getelementptr inbounds i8, i8* %1638, i64 %1636
  br label %2052

2052:                                             ; preds = %2052, %2050
  %2053 = phi i8* [ %1712, %2050 ], [ %2113, %2052 ]
  %2054 = phi i32 [ %1623, %2050 ], [ %2114, %2052 ]
  %2055 = phi i8* [ %2051, %2050 ], [ %2112, %2052 ]
  %2056 = bitcast i8* %2055 to i64*
  %2057 = load i64, i64* %2056, align 1
  %2058 = insertelement <2 x i64> undef, i64 %2057, i32 0
  %2059 = getelementptr inbounds i8, i8* %2055, i64 1
  %2060 = bitcast i8* %2059 to i64*
  %2061 = load i64, i64* %2060, align 1
  %2062 = insertelement <2 x i64> undef, i64 %2061, i32 0
  %2063 = getelementptr inbounds i8, i8* %2055, i64 2
  %2064 = bitcast i8* %2063 to i64*
  %2065 = load i64, i64* %2064, align 1
  %2066 = insertelement <2 x i64> undef, i64 %2065, i32 0
  %2067 = getelementptr inbounds i8, i8* %2055, i64 3
  %2068 = bitcast i8* %2067 to i64*
  %2069 = load i64, i64* %2068, align 1
  %2070 = insertelement <2 x i64> undef, i64 %2069, i32 0
  %2071 = getelementptr inbounds i8, i8* %2055, i64 4
  %2072 = bitcast i8* %2071 to i64*
  %2073 = load i64, i64* %2072, align 1
  %2074 = insertelement <2 x i64> undef, i64 %2073, i32 0
  %2075 = getelementptr inbounds i8, i8* %2055, i64 5
  %2076 = bitcast i8* %2075 to i64*
  %2077 = load i64, i64* %2076, align 1
  %2078 = insertelement <2 x i64> undef, i64 %2077, i32 0
  %2079 = getelementptr inbounds i8, i8* %2055, i64 6
  %2080 = bitcast i8* %2079 to i64*
  %2081 = load i64, i64* %2080, align 1
  %2082 = insertelement <2 x i64> undef, i64 %2081, i32 0
  %2083 = getelementptr inbounds i8, i8* %2055, i64 7
  %2084 = bitcast i8* %2083 to i64*
  %2085 = load i64, i64* %2084, align 1
  %2086 = insertelement <2 x i64> undef, i64 %2085, i32 0
  %2087 = bitcast <2 x i64> %2058 to <16 x i8>
  %2088 = bitcast <2 x i64> %2062 to <16 x i8>
  %2089 = shufflevector <16 x i8> %2087, <16 x i8> %2088, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2090 = bitcast <2 x i64> %2066 to <16 x i8>
  %2091 = bitcast <2 x i64> %2070 to <16 x i8>
  %2092 = shufflevector <16 x i8> %2090, <16 x i8> %2091, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2093 = bitcast <2 x i64> %2074 to <16 x i8>
  %2094 = bitcast <2 x i64> %2078 to <16 x i8>
  %2095 = shufflevector <16 x i8> %2093, <16 x i8> %2094, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2096 = bitcast <2 x i64> %2082 to <16 x i8>
  %2097 = bitcast <2 x i64> %2086 to <16 x i8>
  %2098 = shufflevector <16 x i8> %2096, <16 x i8> %2097, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2099 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2089, <16 x i8> %1632) #9
  %2100 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2092, <16 x i8> %1633) #9
  %2101 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2095, <16 x i8> %1634) #9
  %2102 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2098, <16 x i8> %1635) #9
  %2103 = add <8 x i16> %2102, %2100
  %2104 = add <8 x i16> %2099, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %2105 = add <8 x i16> %2104, %2101
  %2106 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %2105, <8 x i16> %2103) #9
  %2107 = ashr <8 x i16> %2106, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %2108 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2107, <8 x i16> undef) #9
  %2109 = bitcast <16 x i8> %2108 to <2 x i64>
  %2110 = extractelement <2 x i64> %2109, i32 0
  %2111 = bitcast i8* %2053 to i64*
  store i64 %2110, i64* %2111, align 1
  %2112 = getelementptr inbounds i8, i8* %2055, i64 8
  %2113 = getelementptr inbounds i8, i8* %2053, i64 8
  %2114 = add nsw i32 %2054, -8
  %2115 = icmp eq i32 %2114, 0
  br i1 %2115, label %2116, label %2052

2116:                                             ; preds = %2052
  %2117 = getelementptr inbounds i8, i8* %1608, i64 %1783
  %2118 = shl nsw i64 %1616, 2
  %2119 = icmp sgt i32 %1623, 0
  %2120 = shl nsw i64 %1781, 1
  br label %2121

2121:                                             ; preds = %2329, %2116
  %2122 = phi i8* [ %2123, %2329 ], [ %1710, %2116 ]
  %2123 = phi i8* [ %2124, %2329 ], [ %1853, %2116 ]
  %2124 = phi i8* [ %2125, %2329 ], [ %1711, %2116 ]
  %2125 = phi i8* [ %2126, %2329 ], [ %1784, %2116 ]
  %2126 = phi i8* [ %2127, %2329 ], [ %1712, %2116 ]
  %2127 = phi i8* [ %2129, %2329 ], [ %2117, %2116 ]
  %2128 = phi i8* [ %2122, %2329 ], [ %1709, %2116 ]
  %2129 = phi i8* [ %2128, %2329 ], [ %1608, %2116 ]
  %2130 = phi i32 [ %2332, %2329 ], [ %110, %2116 ]
  %2131 = phi i8* [ %2331, %2329 ], [ %1618, %2116 ]
  %2132 = phi i8* [ %2330, %2329 ], [ %1613, %2116 ]
  %2133 = getelementptr inbounds i8, i8* %2132, i64 -3
  %2134 = getelementptr inbounds i8, i8* %2133, i64 %2118
  br label %2135

2135:                                             ; preds = %2135, %2121
  %2136 = phi i8* [ %2127, %2121 ], [ %2196, %2135 ]
  %2137 = phi i32 [ %1623, %2121 ], [ %2197, %2135 ]
  %2138 = phi i8* [ %2134, %2121 ], [ %2195, %2135 ]
  %2139 = bitcast i8* %2138 to i64*
  %2140 = load i64, i64* %2139, align 1
  %2141 = insertelement <2 x i64> undef, i64 %2140, i32 0
  %2142 = getelementptr inbounds i8, i8* %2138, i64 1
  %2143 = bitcast i8* %2142 to i64*
  %2144 = load i64, i64* %2143, align 1
  %2145 = insertelement <2 x i64> undef, i64 %2144, i32 0
  %2146 = getelementptr inbounds i8, i8* %2138, i64 2
  %2147 = bitcast i8* %2146 to i64*
  %2148 = load i64, i64* %2147, align 1
  %2149 = insertelement <2 x i64> undef, i64 %2148, i32 0
  %2150 = getelementptr inbounds i8, i8* %2138, i64 3
  %2151 = bitcast i8* %2150 to i64*
  %2152 = load i64, i64* %2151, align 1
  %2153 = insertelement <2 x i64> undef, i64 %2152, i32 0
  %2154 = getelementptr inbounds i8, i8* %2138, i64 4
  %2155 = bitcast i8* %2154 to i64*
  %2156 = load i64, i64* %2155, align 1
  %2157 = insertelement <2 x i64> undef, i64 %2156, i32 0
  %2158 = getelementptr inbounds i8, i8* %2138, i64 5
  %2159 = bitcast i8* %2158 to i64*
  %2160 = load i64, i64* %2159, align 1
  %2161 = insertelement <2 x i64> undef, i64 %2160, i32 0
  %2162 = getelementptr inbounds i8, i8* %2138, i64 6
  %2163 = bitcast i8* %2162 to i64*
  %2164 = load i64, i64* %2163, align 1
  %2165 = insertelement <2 x i64> undef, i64 %2164, i32 0
  %2166 = getelementptr inbounds i8, i8* %2138, i64 7
  %2167 = bitcast i8* %2166 to i64*
  %2168 = load i64, i64* %2167, align 1
  %2169 = insertelement <2 x i64> undef, i64 %2168, i32 0
  %2170 = bitcast <2 x i64> %2141 to <16 x i8>
  %2171 = bitcast <2 x i64> %2145 to <16 x i8>
  %2172 = shufflevector <16 x i8> %2170, <16 x i8> %2171, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2173 = bitcast <2 x i64> %2149 to <16 x i8>
  %2174 = bitcast <2 x i64> %2153 to <16 x i8>
  %2175 = shufflevector <16 x i8> %2173, <16 x i8> %2174, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2176 = bitcast <2 x i64> %2157 to <16 x i8>
  %2177 = bitcast <2 x i64> %2161 to <16 x i8>
  %2178 = shufflevector <16 x i8> %2176, <16 x i8> %2177, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2179 = bitcast <2 x i64> %2165 to <16 x i8>
  %2180 = bitcast <2 x i64> %2169 to <16 x i8>
  %2181 = shufflevector <16 x i8> %2179, <16 x i8> %2180, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2182 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2172, <16 x i8> %1632) #9
  %2183 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2175, <16 x i8> %1633) #9
  %2184 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2178, <16 x i8> %1634) #9
  %2185 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2181, <16 x i8> %1635) #9
  %2186 = add <8 x i16> %2185, %2183
  %2187 = add <8 x i16> %2182, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %2188 = add <8 x i16> %2187, %2184
  %2189 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %2188, <8 x i16> %2186) #9
  %2190 = ashr <8 x i16> %2189, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %2191 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2190, <8 x i16> undef) #9
  %2192 = bitcast <16 x i8> %2191 to <2 x i64>
  %2193 = extractelement <2 x i64> %2192, i32 0
  %2194 = bitcast i8* %2136 to i64*
  store i64 %2193, i64* %2194, align 1
  %2195 = getelementptr inbounds i8, i8* %2138, i64 8
  %2196 = getelementptr inbounds i8, i8* %2136, i64 8
  %2197 = add nsw i32 %2137, -8
  %2198 = icmp eq i32 %2197, 0
  br i1 %2198, label %2199, label %2135

2199:                                             ; preds = %2135
  br i1 %2119, label %2200, label %2329

2200:                                             ; preds = %2199
  %2201 = getelementptr inbounds i8, i8* %2131, i64 %1781
  br label %2202

2202:                                             ; preds = %2202, %2200
  %2203 = phi i64 [ 0, %2200 ], [ %2327, %2202 ]
  %2204 = getelementptr inbounds i8, i8* %2132, i64 %2203
  %2205 = bitcast i8* %2204 to i64*
  %2206 = load i64, i64* %2205, align 1
  %2207 = insertelement <2 x i64> undef, i64 %2206, i32 0
  %2208 = getelementptr inbounds i8, i8* %2123, i64 %2203
  %2209 = bitcast i8* %2208 to i64*
  %2210 = load i64, i64* %2209, align 1
  %2211 = insertelement <2 x i64> undef, i64 %2210, i32 0
  %2212 = bitcast <2 x i64> %2207 to <16 x i8>
  %2213 = bitcast <2 x i64> %2211 to <16 x i8>
  %2214 = shufflevector <16 x i8> %2212, <16 x i8> %2213, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2215 = shl nuw nsw i64 %2203, 1
  %2216 = getelementptr inbounds i8, i8* %2131, i64 %2215
  %2217 = bitcast i8* %2216 to <16 x i8>*
  store <16 x i8> %2214, <16 x i8>* %2217, align 1
  %2218 = getelementptr inbounds i8, i8* %2204, i64 %1637
  %2219 = bitcast i8* %2218 to i64*
  %2220 = load i64, i64* %2219, align 1
  %2221 = insertelement <2 x i64> undef, i64 %2220, i32 0
  %2222 = getelementptr inbounds i8, i8* %2218, i64 %1616
  %2223 = bitcast i8* %2222 to i64*
  %2224 = load i64, i64* %2223, align 1
  %2225 = insertelement <2 x i64> undef, i64 %2224, i32 0
  %2226 = getelementptr inbounds i8, i8* %2218, i64 %1713
  %2227 = bitcast i8* %2226 to i64*
  %2228 = load i64, i64* %2227, align 1
  %2229 = insertelement <2 x i64> undef, i64 %2228, i32 0
  %2230 = getelementptr inbounds i8, i8* %2218, i64 %1636
  %2231 = bitcast i8* %2230 to i64*
  %2232 = load i64, i64* %2231, align 1
  %2233 = insertelement <2 x i64> undef, i64 %2232, i32 0
  %2234 = getelementptr inbounds i8, i8* %2218, i64 %2118
  %2235 = bitcast i8* %2234 to i64*
  %2236 = load i64, i64* %2235, align 1
  %2237 = insertelement <2 x i64> undef, i64 %2236, i32 0
  %2238 = getelementptr inbounds i8, i8* %2234, i64 %1616
  %2239 = bitcast i8* %2238 to i64*
  %2240 = load i64, i64* %2239, align 1
  %2241 = insertelement <2 x i64> undef, i64 %2240, i32 0
  %2242 = getelementptr inbounds i8, i8* %2234, i64 %1713
  %2243 = bitcast i8* %2242 to i64*
  %2244 = load i64, i64* %2243, align 1
  %2245 = insertelement <2 x i64> undef, i64 %2244, i32 0
  %2246 = getelementptr inbounds i8, i8* %2234, i64 %1636
  %2247 = bitcast i8* %2246 to i64*
  %2248 = load i64, i64* %2247, align 1
  %2249 = insertelement <2 x i64> undef, i64 %2248, i32 0
  %2250 = bitcast <2 x i64> %2221 to <16 x i8>
  %2251 = bitcast <2 x i64> %2225 to <16 x i8>
  %2252 = shufflevector <16 x i8> %2250, <16 x i8> %2251, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2253 = bitcast <2 x i64> %2229 to <16 x i8>
  %2254 = bitcast <2 x i64> %2233 to <16 x i8>
  %2255 = shufflevector <16 x i8> %2253, <16 x i8> %2254, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2256 = bitcast <2 x i64> %2237 to <16 x i8>
  %2257 = bitcast <2 x i64> %2241 to <16 x i8>
  %2258 = shufflevector <16 x i8> %2256, <16 x i8> %2257, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2259 = bitcast <2 x i64> %2245 to <16 x i8>
  %2260 = bitcast <2 x i64> %2249 to <16 x i8>
  %2261 = shufflevector <16 x i8> %2259, <16 x i8> %2260, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2262 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2252, <16 x i8> %1632) #9
  %2263 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2255, <16 x i8> %1633) #9
  %2264 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2258, <16 x i8> %1634) #9
  %2265 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2261, <16 x i8> %1635) #9
  %2266 = add <8 x i16> %2265, %2263
  %2267 = add <8 x i16> %2262, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %2268 = add <8 x i16> %2267, %2264
  %2269 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %2268, <8 x i16> %2266) #9
  %2270 = ashr <8 x i16> %2269, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %2271 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2270, <8 x i16> undef) #9
  %2272 = getelementptr inbounds i8, i8* %2129, i64 %2203
  %2273 = bitcast i8* %2272 to i64*
  %2274 = load i64, i64* %2273, align 1
  %2275 = insertelement <2 x i64> undef, i64 %2274, i32 0
  %2276 = getelementptr inbounds i8, i8* %2128, i64 %2203
  %2277 = bitcast i8* %2276 to i64*
  %2278 = load i64, i64* %2277, align 1
  %2279 = insertelement <2 x i64> undef, i64 %2278, i32 0
  %2280 = getelementptr inbounds i8, i8* %2122, i64 %2203
  %2281 = bitcast i8* %2280 to i64*
  %2282 = load i64, i64* %2281, align 1
  %2283 = insertelement <2 x i64> undef, i64 %2282, i32 0
  %2284 = load i64, i64* %2209, align 1
  %2285 = insertelement <2 x i64> undef, i64 %2284, i32 0
  %2286 = getelementptr inbounds i8, i8* %2124, i64 %2203
  %2287 = bitcast i8* %2286 to i64*
  %2288 = load i64, i64* %2287, align 1
  %2289 = insertelement <2 x i64> undef, i64 %2288, i32 0
  %2290 = getelementptr inbounds i8, i8* %2125, i64 %2203
  %2291 = bitcast i8* %2290 to i64*
  %2292 = load i64, i64* %2291, align 1
  %2293 = insertelement <2 x i64> undef, i64 %2292, i32 0
  %2294 = getelementptr inbounds i8, i8* %2126, i64 %2203
  %2295 = bitcast i8* %2294 to i64*
  %2296 = load i64, i64* %2295, align 1
  %2297 = insertelement <2 x i64> undef, i64 %2296, i32 0
  %2298 = getelementptr inbounds i8, i8* %2127, i64 %2203
  %2299 = bitcast i8* %2298 to i64*
  %2300 = load i64, i64* %2299, align 1
  %2301 = insertelement <2 x i64> undef, i64 %2300, i32 0
  %2302 = bitcast <2 x i64> %2275 to <16 x i8>
  %2303 = bitcast <2 x i64> %2279 to <16 x i8>
  %2304 = shufflevector <16 x i8> %2302, <16 x i8> %2303, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2305 = bitcast <2 x i64> %2283 to <16 x i8>
  %2306 = bitcast <2 x i64> %2285 to <16 x i8>
  %2307 = shufflevector <16 x i8> %2305, <16 x i8> %2306, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2308 = bitcast <2 x i64> %2289 to <16 x i8>
  %2309 = bitcast <2 x i64> %2293 to <16 x i8>
  %2310 = shufflevector <16 x i8> %2308, <16 x i8> %2309, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2311 = bitcast <2 x i64> %2297 to <16 x i8>
  %2312 = bitcast <2 x i64> %2301 to <16 x i8>
  %2313 = shufflevector <16 x i8> %2311, <16 x i8> %2312, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2314 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2304, <16 x i8> %1632) #9
  %2315 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2307, <16 x i8> %1633) #9
  %2316 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2310, <16 x i8> %1634) #9
  %2317 = call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2313, <16 x i8> %1635) #9
  %2318 = add <8 x i16> %2317, %2315
  %2319 = add <8 x i16> %2314, <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>
  %2320 = add <8 x i16> %2319, %2316
  %2321 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %2320, <8 x i16> %2318) #9
  %2322 = ashr <8 x i16> %2321, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %2323 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2322, <8 x i16> undef) #9
  %2324 = shufflevector <16 x i8> %2271, <16 x i8> %2323, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2325 = getelementptr inbounds i8, i8* %2201, i64 %2215
  %2326 = bitcast i8* %2325 to <16 x i8>*
  store <16 x i8> %2324, <16 x i8>* %2326, align 1
  %2327 = add nuw nsw i64 %2203, 8
  %2328 = icmp slt i64 %2327, %1705
  br i1 %2328, label %2202, label %2329

2329:                                             ; preds = %2202, %2199
  %2330 = getelementptr inbounds i8, i8* %2132, i64 %1616
  %2331 = getelementptr inbounds i8, i8* %2131, i64 %2120
  %2332 = add nsw i32 %2130, -1
  %2333 = icmp eq i32 %2332, 0
  br i1 %2333, label %2334, label %2121

2334:                                             ; preds = %2329
  call void @free(i8* %1608) #9
  br label %2335

2335:                                             ; preds = %838, %719, %279, %200, %2334, %1601, %1594, %1166, %1159, %843, %661, %284, %1595
  %2336 = phi i32 [ %104, %1595 ], [ 1, %661 ], [ 0, %284 ], [ 1, %1159 ], [ 0, %843 ], [ 1, %1594 ], [ 0, %1166 ], [ 1, %2334 ], [ 0, %1601 ], [ 1, %200 ], [ 1, %279 ], [ 1, %719 ], [ 1, %838 ]
  %2337 = add nuw nsw i64 %103, 1
  %2338 = icmp slt i64 %2337, %99
  br i1 %2338, label %102, label %100

2339:                                             ; preds = %5, %100
  call void @av1_resize_and_extend_frame_c(%struct.yv12_buffer_config* %0, %struct.yv12_buffer_config* %1, i8 zeroext %2, i32 %3, i32 %4) #9
  br label %2341

2340:                                             ; preds = %100
  call void @aom_extend_frame_borders_c(%struct.yv12_buffer_config* %1, i32 %4) #9
  br label %2341

2341:                                             ; preds = %2340, %2339
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nofree nounwind
declare noalias i8* @malloc(i64) local_unnamed_addr #2

; Function Attrs: nounwind
declare void @free(i8* nocapture) local_unnamed_addr #3

declare void @av1_resize_and_extend_frame_c(%struct.yv12_buffer_config*, %struct.yv12_buffer_config*, i8 zeroext, i32, i32) local_unnamed_addr #4

declare void @aom_extend_frame_borders_c(%struct.yv12_buffer_config*, i32) local_unnamed_addr #4

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #5

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8>, <16 x i8>) #5

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16>, <8 x i16>) #6

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: inlinehint nofree nounwind ssp uwtable
define internal void @shuffle_filter_ssse3(i16* nocapture readonly, <2 x i64>* nocapture) #7 {
  %3 = bitcast i16* %0 to <16 x i8>*
  %4 = load <16 x i8>, <16 x i8>* %3, align 16
  %5 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2, i32 0, i32 2>
  %6 = bitcast <2 x i64>* %1 to <16 x i8>*
  store <16 x i8> %5, <16 x i8>* %6, align 16
  %7 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6, i32 4, i32 6>
  %8 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %9 = bitcast <2 x i64>* %8 to <16 x i8>*
  store <16 x i8> %7, <16 x i8>* %9, align 16
  %10 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10, i32 8, i32 10>
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %12 = bitcast <2 x i64>* %11 to <16 x i8>*
  store <16 x i8> %10, <16 x i8>* %12, align 16
  %13 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14, i32 12, i32 14>
  %14 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %15 = bitcast <2 x i64>* %14 to <16 x i8>*
  store <16 x i8> %13, <16 x i8>* %15, align 16
  ret void
}

; Function Attrs: inlinehint nofree nounwind ssp uwtable
define internal void @shuffle_filter_odd_ssse3(i16* nocapture readonly, <2 x i64>* nocapture) #7 {
  %3 = bitcast i16* %0 to <16 x i8>*
  %4 = load <16 x i8>, <16 x i8>* %3, align 16
  %5 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 7, i32 0, i32 7, i32 0, i32 7, i32 0, i32 7, i32 0, i32 7, i32 0, i32 7, i32 0, i32 7, i32 0, i32 7, i32 0>
  %6 = bitcast <2 x i64>* %1 to <16 x i8>*
  store <16 x i8> %5, <16 x i8>* %6, align 16
  %7 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 2, i32 4, i32 2, i32 4, i32 2, i32 4, i32 2, i32 4, i32 2, i32 4, i32 2, i32 4, i32 2, i32 4, i32 2, i32 4>
  %8 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %9 = bitcast <2 x i64>* %8 to <16 x i8>*
  store <16 x i8> %7, <16 x i8>* %9, align 16
  %10 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 6, i32 8, i32 6, i32 8, i32 6, i32 8, i32 6, i32 8, i32 6, i32 8, i32 6, i32 8, i32 6, i32 8, i32 6, i32 8>
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %12 = bitcast <2 x i64>* %11 to <16 x i8>*
  store <16 x i8> %10, <16 x i8>* %12, align 16
  %13 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 10, i32 12, i32 10, i32 12, i32 10, i32 12, i32 10, i32 12, i32 10, i32 12, i32 10, i32 12, i32 10, i32 12, i32 10, i32 12>
  %14 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %15 = bitcast <2 x i64>* %14 to <16 x i8>*
  store <16 x i8> %13, <16 x i8>* %15, align 16
  %16 = shufflevector <16 x i8> %4, <16 x i8> undef, <16 x i32> <i32 14, i32 7, i32 14, i32 7, i32 14, i32 7, i32 14, i32 7, i32 14, i32 7, i32 14, i32 7, i32 14, i32 7, i32 14, i32 7>
  %17 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %18 = bitcast <2 x i64>* %17 to <16 x i8>*
  store <16 x i8> %16, <16 x i8>* %18, align 16
  ret void
}

; Function Attrs: inlinehint nounwind readonly ssp uwtable
define internal <2 x i64> @convolve8_8_even_offset_ssse3(<2 x i64>* nocapture readonly, <2 x i64>* nocapture readonly) #8 {
  %3 = bitcast <2 x i64>* %0 to <16 x i8>*
  %4 = load <16 x i8>, <16 x i8>* %3, align 16
  %5 = bitcast <2 x i64>* %1 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 16
  %7 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4, <16 x i8> %6) #9
  %8 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %9 = bitcast <2 x i64>* %8 to <16 x i8>*
  %10 = load <16 x i8>, <16 x i8>* %9, align 16
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %12 = bitcast <2 x i64>* %11 to <16 x i8>*
  %13 = load <16 x i8>, <16 x i8>* %12, align 16
  %14 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10, <16 x i8> %13) #9
  %15 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %16 = bitcast <2 x i64>* %15 to <16 x i8>*
  %17 = load <16 x i8>, <16 x i8>* %16, align 16
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %19 = bitcast <2 x i64>* %18 to <16 x i8>*
  %20 = load <16 x i8>, <16 x i8>* %19, align 16
  %21 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %17, <16 x i8> %20) #9
  %22 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %23 = bitcast <2 x i64>* %22 to <16 x i8>*
  %24 = load <16 x i8>, <16 x i8>* %23, align 16
  %25 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %26 = bitcast <2 x i64>* %25 to <16 x i8>*
  %27 = load <16 x i8>, <16 x i8>* %26, align 16
  %28 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %24, <16 x i8> %27) #9
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>) #9
  %30 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %7, <8 x i16> %28) #9
  %31 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %30, <8 x i16> %14) #9
  %32 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %31, <8 x i16> %21) #9
  %33 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %32, <8 x i16> %29) #9
  %34 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %33, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %35 = ashr <8 x i16> %34, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %36 = bitcast <8 x i16> %35 to <2 x i64>
  ret <2 x i64> %36
}

; Function Attrs: inlinehint nounwind readonly ssp uwtable
define internal <2 x i64> @convolve8_8_odd_offset_ssse3(<2 x i64>* nocapture readonly, <2 x i64>* nocapture readonly) #8 {
  %3 = bitcast <2 x i64>* %0 to <16 x i8>*
  %4 = load <16 x i8>, <16 x i8>* %3, align 16
  %5 = bitcast <2 x i64>* %1 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 16
  %7 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4, <16 x i8> %6) #9
  %8 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %9 = bitcast <2 x i64>* %8 to <16 x i8>*
  %10 = load <16 x i8>, <16 x i8>* %9, align 16
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %12 = bitcast <2 x i64>* %11 to <16 x i8>*
  %13 = load <16 x i8>, <16 x i8>* %12, align 16
  %14 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10, <16 x i8> %13) #9
  %15 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %16 = bitcast <2 x i64>* %15 to <16 x i8>*
  %17 = load <16 x i8>, <16 x i8>* %16, align 16
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %19 = bitcast <2 x i64>* %18 to <16 x i8>*
  %20 = load <16 x i8>, <16 x i8>* %19, align 16
  %21 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %17, <16 x i8> %20) #9
  %22 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %23 = bitcast <2 x i64>* %22 to <16 x i8>*
  %24 = load <16 x i8>, <16 x i8>* %23, align 16
  %25 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %26 = bitcast <2 x i64>* %25 to <16 x i8>*
  %27 = load <16 x i8>, <16 x i8>* %26, align 16
  %28 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %24, <16 x i8> %27) #9
  %29 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %30 = bitcast <2 x i64>* %29 to <16 x i8>*
  %31 = load <16 x i8>, <16 x i8>* %30, align 16
  %32 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %33 = bitcast <2 x i64>* %32 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 16
  %35 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %31, <16 x i8> %34) #9
  %36 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %17, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>) #9
  %37 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %7, <8 x i16> %14) #9
  %38 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %37, <8 x i16> %21) #9
  %39 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %38, <8 x i16> %28) #9
  %40 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %39, <8 x i16> %35) #9
  %41 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %40, <8 x i16> %36) #9
  %42 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %41, <8 x i16> <i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64, i16 64>) #9
  %43 = ashr <8 x i16> %42, <i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7, i16 7>
  %44 = bitcast <8 x i16> %43 to <2 x i64>
  ret <2 x i64> %44
}

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nofree nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nounwind readnone }
attributes #6 = { nounwind readnone speculatable }
attributes #7 = { inlinehint nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { inlinehint nounwind readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
