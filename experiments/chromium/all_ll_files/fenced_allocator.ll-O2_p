; ModuleID = '../../gpu/command_buffer/client/fenced_allocator.cc'
source_filename = "../../gpu/command_buffer/client/fenced_allocator.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"class.gpu::FencedAllocator" = type <{ %"class.gpu::CommandBufferHelper"*, %"class.std::__1::vector", i32, [4 x i8] }>
%"class.std::__1::vector" = type { %"class.std::__1::__vector_base" }
%"class.std::__1::__vector_base" = type { %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"*, %"class.std::__1::__compressed_pair.2" }
%"struct.gpu::FencedAllocator::Block" = type { i32, i32, i32, i32 }
%"class.std::__1::__compressed_pair.2" = type { %"struct.std::__1::__compressed_pair_elem.3" }
%"struct.std::__1::__compressed_pair_elem.3" = type { %"struct.gpu::FencedAllocator::Block"* }
%"class.gpu::CommandBufferHelper" = type <{ i32 (...)**, %"class.gpu::CommandBuffer"*, i32, i32, %class.scoped_refptr, %"union.gpu::CommandBufferEntry"*, i32, i32, i32, i32, i32, i32, i32, i8, [3 x i8], i32, i8, i8, i8, i8, i32, i32, %"class.base::TimeTicks", i32, [4 x i8] }>
%"class.gpu::CommandBuffer" = type { i32 (...)** }
%class.scoped_refptr = type { %"class.gpu::Buffer"* }
%"class.gpu::Buffer" = type <{ %"class.base::RefCountedThreadSafe", [4 x i8], %"class.std::__1::unique_ptr", i8*, i32, [4 x i8] }>
%"class.base::RefCountedThreadSafe" = type { %"class.base::subtle::RefCountedThreadSafeBase" }
%"class.base::subtle::RefCountedThreadSafeBase" = type { %"class.base::AtomicRefCount" }
%"class.base::AtomicRefCount" = type { %"struct.std::__1::atomic" }
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__atomic_base.0" }
%"struct.std::__1::__atomic_base.0" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i32 }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { %"class.gpu::BufferBacking"* }
%"class.gpu::BufferBacking" = type { i32 (...)** }
%"union.gpu::CommandBufferEntry" = type { %"struct.gpu::CommandHeader" }
%"struct.gpu::CommandHeader" = type { i32 }
%"class.base::TimeTicks" = type { %"class.base::time_internal::TimeBase" }
%"class.base::time_internal::TimeBase" = type { i64 }
%"class.std::__1::__vector_base_common" = type { i8 }

$_ZNSt3__16vectorIN3gpu15FencedAllocator5BlockENS_9allocatorIS3_EEE6insertENS_11__wrap_iterIPKS3_EERS8_ = comdat any

@_ZN3gpu15FencedAllocatorC1EjPNS_19CommandBufferHelperE = hidden unnamed_addr alias void (%"class.gpu::FencedAllocator"*, i32, %"class.gpu::CommandBufferHelper"*), void (%"class.gpu::FencedAllocator"*, i32, %"class.gpu::CommandBufferHelper"*)* @_ZN3gpu15FencedAllocatorC2EjPNS_19CommandBufferHelperE
@_ZN3gpu15FencedAllocatorD1Ev = hidden unnamed_addr alias void (%"class.gpu::FencedAllocator"*), void (%"class.gpu::FencedAllocator"*)* @_ZN3gpu15FencedAllocatorD2Ev

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN3gpu15FencedAllocatorC2EjPNS_19CommandBufferHelperE(%"class.gpu::FencedAllocator"*, i32, %"class.gpu::CommandBufferHelper"*) unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 0
  store %"class.gpu::CommandBufferHelper"* %2, %"class.gpu::CommandBufferHelper"** %4, align 8
  %5 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1
  %6 = and i32 %1, -16
  %7 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 2, i32 0, i32 0
  %8 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %5, i64 1
  %9 = bitcast %"class.std::__1::vector"* %8 to i32*
  store i32 0, i32* %9, align 8
  %10 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %11 = bitcast %"struct.gpu::FencedAllocator::Block"** %10 to i64*
  %12 = bitcast %"class.std::__1::vector"* %5 to i64*
  %13 = bitcast %"struct.gpu::FencedAllocator::Block"** %7 to i64*
  %14 = tail call i8* @_Znwm(i64 16) #11
  %15 = getelementptr inbounds i8, i8* %14, i64 16
  %16 = ptrtoint i8* %15 to i64
  %17 = bitcast i8* %14 to i32*
  store i32 1, i32* %17, align 4
  %18 = getelementptr inbounds i8, i8* %14, i64 4
  %19 = bitcast i8* %18 to i32*
  store i32 0, i32* %19, align 4
  %20 = getelementptr inbounds i8, i8* %14, i64 8
  %21 = bitcast i8* %20 to i32*
  store i32 %6, i32* %21, align 4
  %22 = getelementptr inbounds i8, i8* %14, i64 12
  %23 = bitcast i8* %22 to i32*
  store i32 0, i32* %23, align 4
  %24 = ptrtoint i8* %14 to i64
  store i64 %24, i64* %12, align 8
  store i64 %16, i64* %11, align 8
  store i64 %16, i64* %13, align 8
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN3gpu15FencedAllocatorD2Ev(%"class.gpu::FencedAllocator"* nocapture) unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 0
  %3 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %2, align 8
  %4 = icmp eq %"struct.gpu::FencedAllocator::Block"* %3, null
  br i1 %4, label %10, label %5

5:                                                ; preds = %1
  %6 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %3 to i64
  %7 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %8 = bitcast %"struct.gpu::FencedAllocator::Block"** %7 to i64*
  store i64 %6, i64* %8, align 8
  %9 = bitcast %"struct.gpu::FencedAllocator::Block"* %3 to i8*
  tail call void @_ZdlPv(i8* %9) #11
  br label %10

10:                                               ; preds = %1, %5
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN3gpu15FencedAllocator5AllocEj(%"class.gpu::FencedAllocator"*, i32) local_unnamed_addr #0 align 2 {
  %3 = alloca %"struct.gpu::FencedAllocator::Block", align 4
  %4 = alloca %"struct.gpu::FencedAllocator::Block", align 4
  %5 = icmp eq i32 %1, 0
  br i1 %5, label %121, label %6

6:                                                ; preds = %2
  %7 = tail call { i32, i1 } @llvm.uadd.with.overflow.i32(i32 %1, i32 15) #12
  %8 = extractvalue { i32, i1 } %7, 1
  %9 = extractvalue { i32, i1 } %7, 0
  %10 = and i32 %9, -16
  %11 = select i1 %8, i32 0, i32 %10
  br i1 %8, label %121, label %12, !prof !2

12:                                               ; preds = %6
  %13 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1
  %14 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %15 = bitcast %"struct.gpu::FencedAllocator::Block"** %14 to i64*
  %16 = load i64, i64* %15, align 8
  %17 = bitcast %"class.std::__1::vector"* %13 to i64*
  %18 = load i64, i64* %17, align 8
  %19 = icmp eq i64 %16, %18
  %20 = inttoptr i64 %18 to %"struct.gpu::FencedAllocator::Block"*
  br i1 %19, label %121, label %21

21:                                               ; preds = %12
  %22 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %13, i64 0, i32 0, i32 0
  %23 = sub i64 %16, %18
  %24 = ashr exact i64 %23, 4
  br label %28

25:                                               ; preds = %61
  br i1 %19, label %121, label %26

26:                                               ; preds = %25
  %27 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %13, i64 0, i32 0, i32 0
  br label %65

28:                                               ; preds = %21, %61
  %29 = phi i64 [ 0, %21 ], [ %63, %61 ]
  %30 = phi i32 [ 0, %21 ], [ %62, %61 ]
  %31 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %20, i64 %29, i32 0
  %32 = load i32, i32* %31, align 4
  %33 = icmp eq i32 %32, 1
  br i1 %33, label %34, label %61

34:                                               ; preds = %28
  %35 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %20, i64 %29, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp ult i32 %36, %11
  br i1 %37, label %61, label %38

38:                                               ; preds = %34
  %39 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %20, i64 %29, i32 1
  %40 = load i32, i32* %39, align 4
  %41 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 2
  %42 = load i32, i32* %41, align 8
  %43 = add i32 %42, %11
  store i32 %43, i32* %41, align 8
  %44 = load i32, i32* %35, align 4
  %45 = icmp eq i32 %44, %11
  br i1 %45, label %46, label %47

46:                                               ; preds = %38
  store i32 0, i32* %31, align 4
  br label %121

47:                                               ; preds = %38
  %48 = bitcast %"struct.gpu::FencedAllocator::Block"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %48) #12
  %49 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %3, i64 0, i32 0
  %50 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %3, i64 0, i32 1
  %51 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %3, i64 0, i32 2
  %52 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %3, i64 0, i32 3
  %53 = bitcast i32* %51 to i64*
  store i64 -6148914691236517206, i64* %53, align 4
  store i32 1, i32* %49, align 4
  %54 = add i32 %40, %11
  store i32 %54, i32* %50, align 4
  %55 = load i32, i32* %35, align 4
  %56 = sub i32 %55, %11
  store i32 %56, i32* %51, align 4
  store i32 0, i32* %52, align 4
  store i32 0, i32* %31, align 4
  store i32 %11, i32* %35, align 4
  %57 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %22, align 8
  %58 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %57, i64 %29
  %59 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %58, i64 1
  %60 = call %"struct.gpu::FencedAllocator::Block"* @_ZNSt3__16vectorIN3gpu15FencedAllocator5BlockENS_9allocatorIS3_EEE6insertENS_11__wrap_iterIPKS3_EERS8_(%"class.std::__1::vector"* %13, %"struct.gpu::FencedAllocator::Block"* %59, %"struct.gpu::FencedAllocator::Block"* nonnull dereferenceable(16) %3) #12
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %48) #12
  br label %121

61:                                               ; preds = %34, %28
  %62 = add i32 %30, 1
  %63 = zext i32 %62 to i64
  %64 = icmp ugt i64 %24, %63
  br i1 %64, label %28, label %25

65:                                               ; preds = %26, %111
  %66 = phi i64 [ %18, %26 ], [ %112, %111 ]
  %67 = phi i64 [ %16, %26 ], [ %113, %111 ]
  %68 = phi %"struct.gpu::FencedAllocator::Block"* [ %20, %26 ], [ %120, %111 ]
  %69 = phi i64 [ 0, %26 ], [ %116, %111 ]
  %70 = phi i32 [ 0, %26 ], [ %115, %111 ]
  %71 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %68, i64 %69, i32 0
  %72 = load i32, i32* %71, align 4
  %73 = icmp eq i32 %72, 2
  br i1 %73, label %74, label %111

74:                                               ; preds = %65
  %75 = tail call i32 @_ZN3gpu15FencedAllocator24WaitForTokenAndFreeBlockEj(%"class.gpu::FencedAllocator"* %0, i32 %70)
  %76 = zext i32 %75 to i64
  %77 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %27, align 8
  %78 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %77, i64 %76, i32 2
  %79 = load i32, i32* %78, align 4
  %80 = icmp ult i32 %79, %11
  br i1 %80, label %81, label %84

81:                                               ; preds = %74
  %82 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %77 to i64
  %83 = load i64, i64* %15, align 8
  br label %111

84:                                               ; preds = %74
  %85 = zext i32 %75 to i64
  %86 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %77, i64 %85
  %87 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %77, i64 %85, i32 1
  %88 = load i32, i32* %87, align 4
  %89 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 2
  %90 = load i32, i32* %89, align 8
  %91 = add i32 %90, %11
  store i32 %91, i32* %89, align 8
  %92 = load i32, i32* %78, align 4
  %93 = icmp eq i32 %92, %11
  br i1 %93, label %94, label %96

94:                                               ; preds = %84
  %95 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %86, i64 0, i32 0
  store i32 0, i32* %95, align 4
  br label %121

96:                                               ; preds = %84
  %97 = bitcast %"struct.gpu::FencedAllocator::Block"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %97) #12
  %98 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %4, i64 0, i32 0
  %99 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %4, i64 0, i32 1
  %100 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %4, i64 0, i32 2
  %101 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %4, i64 0, i32 3
  %102 = bitcast i32* %100 to i64*
  store i64 -6148914691236517206, i64* %102, align 4
  store i32 1, i32* %98, align 4
  %103 = add i32 %88, %11
  store i32 %103, i32* %99, align 4
  %104 = load i32, i32* %78, align 4
  %105 = sub i32 %104, %11
  store i32 %105, i32* %100, align 4
  store i32 0, i32* %101, align 4
  %106 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %86, i64 0, i32 0
  store i32 0, i32* %106, align 4
  store i32 %11, i32* %78, align 4
  %107 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %27, align 8
  %108 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %107, i64 %85
  %109 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %108, i64 1
  %110 = call %"struct.gpu::FencedAllocator::Block"* @_ZNSt3__16vectorIN3gpu15FencedAllocator5BlockENS_9allocatorIS3_EEE6insertENS_11__wrap_iterIPKS3_EERS8_(%"class.std::__1::vector"* %13, %"struct.gpu::FencedAllocator::Block"* %109, %"struct.gpu::FencedAllocator::Block"* nonnull dereferenceable(16) %4) #12
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %97) #12
  br label %121

111:                                              ; preds = %81, %65
  %112 = phi i64 [ %66, %65 ], [ %82, %81 ]
  %113 = phi i64 [ %67, %65 ], [ %83, %81 ]
  %114 = phi i32 [ %70, %65 ], [ %75, %81 ]
  %115 = add i32 %114, 1
  %116 = zext i32 %115 to i64
  %117 = sub i64 %113, %112
  %118 = ashr exact i64 %117, 4
  %119 = icmp ugt i64 %118, %116
  %120 = inttoptr i64 %112 to %"struct.gpu::FencedAllocator::Block"*
  br i1 %119, label %65, label %121

121:                                              ; preds = %111, %12, %25, %96, %94, %47, %46, %6, %2
  %122 = phi i32 [ -1, %2 ], [ -1, %6 ], [ %40, %46 ], [ %40, %47 ], [ %88, %94 ], [ %88, %96 ], [ -1, %25 ], [ -1, %12 ], [ -1, %111 ]
  ret i32 %122
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN3gpu15FencedAllocator12AllocInBlockEjj(%"class.gpu::FencedAllocator"*, i32, i32) local_unnamed_addr #0 align 2 {
  %4 = alloca %"struct.gpu::FencedAllocator::Block", align 4
  %5 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1
  %6 = zext i32 %1 to i64
  %7 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %5, i64 0, i32 0, i32 0
  %8 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %7, align 8
  %9 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %8, i64 %6
  %10 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %8, i64 %6, i32 1
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 2
  %13 = load i32, i32* %12, align 8
  %14 = add i32 %13, %2
  store i32 %14, i32* %12, align 8
  %15 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %8, i64 %6, i32 2
  %16 = load i32, i32* %15, align 4
  %17 = icmp eq i32 %16, %2
  br i1 %17, label %18, label %20

18:                                               ; preds = %3
  %19 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %9, i64 0, i32 0
  store i32 0, i32* %19, align 4
  br label %36

20:                                               ; preds = %3
  %21 = bitcast %"struct.gpu::FencedAllocator::Block"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %21) #12
  %22 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %4, i64 0, i32 0
  %23 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %4, i64 0, i32 1
  %24 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %4, i64 0, i32 2
  %25 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %4, i64 0, i32 3
  %26 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %4, i64 0, i32 2
  %27 = bitcast i32* %26 to i64*
  store i64 -6148914691236517206, i64* %27, align 4
  store i32 1, i32* %22, align 4
  %28 = add i32 %11, %2
  store i32 %28, i32* %23, align 4
  %29 = load i32, i32* %15, align 4
  %30 = sub i32 %29, %2
  store i32 %30, i32* %24, align 4
  store i32 0, i32* %25, align 4
  %31 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %9, i64 0, i32 0
  store i32 0, i32* %31, align 4
  store i32 %2, i32* %15, align 4
  %32 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %7, align 8
  %33 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %32, i64 %6
  %34 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %33, i64 1
  %35 = call %"struct.gpu::FencedAllocator::Block"* @_ZNSt3__16vectorIN3gpu15FencedAllocator5BlockENS_9allocatorIS3_EEE6insertENS_11__wrap_iterIPKS3_EERS8_(%"class.std::__1::vector"* %5, %"struct.gpu::FencedAllocator::Block"* %34, %"struct.gpu::FencedAllocator::Block"* nonnull dereferenceable(16) %4)
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %21) #12
  br label %36

36:                                               ; preds = %20, %18
  ret i32 %11
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN3gpu15FencedAllocator24WaitForTokenAndFreeBlockEj(%"class.gpu::FencedAllocator"* nocapture, i32) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1
  %4 = zext i32 %1 to i64
  %5 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %3, i64 0, i32 0, i32 0
  %6 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %5, align 8
  %7 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 0
  %8 = load %"class.gpu::CommandBufferHelper"*, %"class.gpu::CommandBufferHelper"** %7, align 8
  %9 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %6, i64 %4, i32 3
  %10 = load i32, i32* %9, align 4
  tail call void @_ZN3gpu19CommandBufferHelper12WaitForTokenEi(%"class.gpu::CommandBufferHelper"* %8, i32 %10) #12
  %11 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %6, i64 %4, i32 0
  store i32 1, i32* %11, align 4
  %12 = add i32 %1, 1
  %13 = zext i32 %12 to i64
  %14 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %15 = bitcast %"struct.gpu::FencedAllocator::Block"** %14 to i64*
  %16 = load i64, i64* %15, align 8
  %17 = bitcast %"class.std::__1::vector"* %3 to i64*
  %18 = load i64, i64* %17, align 8
  %19 = sub i64 %16, %18
  %20 = ashr exact i64 %19, 4
  %21 = icmp ugt i64 %20, %13
  %22 = inttoptr i64 %18 to %"struct.gpu::FencedAllocator::Block"*
  br i1 %21, label %23, label %47

23:                                               ; preds = %2
  %24 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %22, i64 %13, i32 0
  %25 = load i32, i32* %24, align 4
  %26 = icmp eq i32 %25, 1
  br i1 %26, label %27, label %47

27:                                               ; preds = %23
  %28 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %22, i64 %13, i32 2
  %29 = load i32, i32* %28, align 4
  %30 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %22, i64 %4, i32 2
  %31 = load i32, i32* %30, align 4
  %32 = add i32 %31, %29
  store i32 %32, i32* %30, align 4
  %33 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %5, align 8
  %34 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %33, i64 %4
  %35 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %34, i64 1
  %36 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %35, i64 1
  %37 = load i64, i64* %15, align 8
  %38 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %36 to i64
  %39 = sub i64 %37, %38
  %40 = ashr exact i64 %39, 4
  %41 = icmp eq i64 %39, 0
  br i1 %41, label %45, label %42

42:                                               ; preds = %27
  %43 = bitcast %"struct.gpu::FencedAllocator::Block"* %35 to i8*
  %44 = bitcast %"struct.gpu::FencedAllocator::Block"* %36 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %43, i8* align 4 %44, i64 %39, i1 false) #12
  br label %45

45:                                               ; preds = %42, %27
  %46 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %35, i64 %40
  store %"struct.gpu::FencedAllocator::Block"* %46, %"struct.gpu::FencedAllocator::Block"** %14, align 8
  br label %47

47:                                               ; preds = %45, %23, %2
  %48 = icmp eq i32 %1, 0
  br i1 %48, label %75, label %49

49:                                               ; preds = %47
  %50 = add i32 %1, -1
  %51 = zext i32 %50 to i64
  %52 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %5, align 8
  %53 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %52, i64 %51, i32 0
  %54 = load i32, i32* %53, align 4
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %56, label %75

56:                                               ; preds = %49
  %57 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %52, i64 %4, i32 2
  %58 = load i32, i32* %57, align 4
  %59 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %52, i64 %51, i32 2
  %60 = load i32, i32* %59, align 4
  %61 = add i32 %60, %58
  store i32 %61, i32* %59, align 4
  %62 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %5, align 8
  %63 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %62, i64 %4
  %64 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %63, i64 1
  %65 = load i64, i64* %15, align 8
  %66 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %64 to i64
  %67 = sub i64 %65, %66
  %68 = ashr exact i64 %67, 4
  %69 = icmp eq i64 %67, 0
  br i1 %69, label %73, label %70

70:                                               ; preds = %56
  %71 = bitcast %"struct.gpu::FencedAllocator::Block"* %63 to i8*
  %72 = bitcast %"struct.gpu::FencedAllocator::Block"* %64 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %71, i8* align 4 %72, i64 %67, i1 false) #12
  br label %73

73:                                               ; preds = %70, %56
  %74 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %63, i64 %68
  store %"struct.gpu::FencedAllocator::Block"* %74, %"struct.gpu::FencedAllocator::Block"** %14, align 8
  br label %75

75:                                               ; preds = %47, %49, %73
  %76 = phi i32 [ 0, %47 ], [ %50, %73 ], [ %1, %49 ]
  ret i32 %76
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN3gpu15FencedAllocator4FreeEj(%"class.gpu::FencedAllocator"* nocapture, i32) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 0
  %4 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %3, align 8
  %5 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %6 = bitcast %"struct.gpu::FencedAllocator::Block"** %5 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %4 to i64
  %9 = sub i64 %7, %8
  %10 = icmp eq i64 %9, 0
  br i1 %10, label %29, label %11

11:                                               ; preds = %2
  %12 = ashr exact i64 %9, 4
  br label %13

13:                                               ; preds = %13, %11
  %14 = phi %"struct.gpu::FencedAllocator::Block"* [ %4, %11 ], [ %25, %13 ]
  %15 = phi i64 [ %12, %11 ], [ %24, %13 ]
  %16 = lshr i64 %15, 1
  %17 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %14, i64 1
  %18 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %14, i64 %16, i32 1
  %19 = load i32, i32* %18, align 4
  %20 = icmp ult i32 %19, %1
  %21 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %17, i64 %16
  %22 = xor i64 %16, -1
  %23 = add i64 %15, %22
  %24 = select i1 %20, i64 %23, i64 %16
  %25 = select i1 %20, %"struct.gpu::FencedAllocator::Block"* %21, %"struct.gpu::FencedAllocator::Block"* %14
  %26 = icmp eq i64 %24, 0
  br i1 %26, label %27, label %13

27:                                               ; preds = %13
  %28 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %25 to i64
  br label %29

29:                                               ; preds = %2, %27
  %30 = phi i64 [ %28, %27 ], [ %8, %2 ]
  %31 = sub i64 %30, %8
  %32 = lshr exact i64 %31, 4
  %33 = trunc i64 %32 to i32
  %34 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1
  %35 = and i64 %32, 4294967295
  %36 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %34, i64 0, i32 0, i32 0
  %37 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %4, i64 %35, i32 0
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 0
  br i1 %39, label %40, label %46

40:                                               ; preds = %29
  %41 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %4, i64 %35, i32 2
  %42 = load i32, i32* %41, align 4
  %43 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 2
  %44 = load i32, i32* %43, align 8
  %45 = sub i32 %44, %42
  store i32 %45, i32* %43, align 8
  br label %46

46:                                               ; preds = %40, %29
  store i32 1, i32* %37, align 4
  %47 = add nuw nsw i64 %32, 1
  %48 = and i64 %47, 4294967295
  %49 = load i64, i64* %6, align 8
  %50 = bitcast %"class.std::__1::vector"* %34 to i64*
  %51 = load i64, i64* %50, align 8
  %52 = sub i64 %49, %51
  %53 = ashr exact i64 %52, 4
  %54 = icmp ugt i64 %53, %48
  %55 = inttoptr i64 %51 to %"struct.gpu::FencedAllocator::Block"*
  br i1 %54, label %56, label %80

56:                                               ; preds = %46
  %57 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %55, i64 %48, i32 0
  %58 = load i32, i32* %57, align 4
  %59 = icmp eq i32 %58, 1
  br i1 %59, label %60, label %80

60:                                               ; preds = %56
  %61 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %55, i64 %48, i32 2
  %62 = load i32, i32* %61, align 4
  %63 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %55, i64 %35, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = add i32 %64, %62
  store i32 %65, i32* %63, align 4
  %66 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %36, align 8
  %67 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %66, i64 %35
  %68 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %67, i64 1
  %69 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %68, i64 1
  %70 = load i64, i64* %6, align 8
  %71 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %69 to i64
  %72 = sub i64 %70, %71
  %73 = ashr exact i64 %72, 4
  %74 = icmp eq i64 %72, 0
  br i1 %74, label %78, label %75

75:                                               ; preds = %60
  %76 = bitcast %"struct.gpu::FencedAllocator::Block"* %68 to i8*
  %77 = bitcast %"struct.gpu::FencedAllocator::Block"* %69 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %76, i8* align 4 %77, i64 %72, i1 false) #12
  br label %78

78:                                               ; preds = %75, %60
  %79 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %68, i64 %73
  store %"struct.gpu::FencedAllocator::Block"* %79, %"struct.gpu::FencedAllocator::Block"** %5, align 8
  br label %80

80:                                               ; preds = %78, %56, %46
  %81 = icmp eq i32 %33, 0
  br i1 %81, label %108, label %82

82:                                               ; preds = %80
  %83 = add nuw nsw i64 %32, 4294967295
  %84 = and i64 %83, 4294967295
  %85 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %36, align 8
  %86 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %85, i64 %84, i32 0
  %87 = load i32, i32* %86, align 4
  %88 = icmp eq i32 %87, 1
  br i1 %88, label %89, label %108

89:                                               ; preds = %82
  %90 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %85, i64 %35, i32 2
  %91 = load i32, i32* %90, align 4
  %92 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %85, i64 %84, i32 2
  %93 = load i32, i32* %92, align 4
  %94 = add i32 %93, %91
  store i32 %94, i32* %92, align 4
  %95 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %36, align 8
  %96 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %95, i64 %35
  %97 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %96, i64 1
  %98 = load i64, i64* %6, align 8
  %99 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %97 to i64
  %100 = sub i64 %98, %99
  %101 = ashr exact i64 %100, 4
  %102 = icmp eq i64 %100, 0
  br i1 %102, label %106, label %103

103:                                              ; preds = %89
  %104 = bitcast %"struct.gpu::FencedAllocator::Block"* %96 to i8*
  %105 = bitcast %"struct.gpu::FencedAllocator::Block"* %97 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %104, i8* align 4 %105, i64 %100, i1 false) #12
  br label %106

106:                                              ; preds = %103, %89
  %107 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %96, i64 %101
  store %"struct.gpu::FencedAllocator::Block"* %107, %"struct.gpu::FencedAllocator::Block"** %5, align 8
  br label %108

108:                                              ; preds = %80, %82, %106
  ret void
}

; Function Attrs: nounwind readonly ssp uwtable
define hidden i32 @_ZN3gpu15FencedAllocator16GetBlockByOffsetEj(%"class.gpu::FencedAllocator"* nocapture readonly, i32) local_unnamed_addr #2 align 2 {
  %3 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 0
  %4 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %3, align 8
  %5 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %6 = bitcast %"struct.gpu::FencedAllocator::Block"** %5 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %4 to i64
  %9 = sub i64 %7, %8
  %10 = icmp eq i64 %9, 0
  br i1 %10, label %29, label %11

11:                                               ; preds = %2
  %12 = ashr exact i64 %9, 4
  br label %13

13:                                               ; preds = %13, %11
  %14 = phi %"struct.gpu::FencedAllocator::Block"* [ %4, %11 ], [ %25, %13 ]
  %15 = phi i64 [ %12, %11 ], [ %24, %13 ]
  %16 = lshr i64 %15, 1
  %17 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %14, i64 1
  %18 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %14, i64 %16, i32 1
  %19 = load i32, i32* %18, align 4
  %20 = icmp ult i32 %19, %1
  %21 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %17, i64 %16
  %22 = xor i64 %16, -1
  %23 = add i64 %15, %22
  %24 = select i1 %20, i64 %23, i64 %16
  %25 = select i1 %20, %"struct.gpu::FencedAllocator::Block"* %21, %"struct.gpu::FencedAllocator::Block"* %14
  %26 = icmp eq i64 %24, 0
  br i1 %26, label %27, label %13

27:                                               ; preds = %13
  %28 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %25 to i64
  br label %29

29:                                               ; preds = %27, %2
  %30 = phi i64 [ %28, %27 ], [ %8, %2 ]
  %31 = sub i64 %30, %8
  %32 = lshr exact i64 %31, 4
  %33 = trunc i64 %32 to i32
  ret i32 %33
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN3gpu15FencedAllocator17CollapseFreeBlockEj(%"class.gpu::FencedAllocator"* nocapture, i32) local_unnamed_addr #0 align 2 {
  %3 = add i32 %1, 1
  %4 = zext i32 %3 to i64
  %5 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1
  %6 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %7 = bitcast %"struct.gpu::FencedAllocator::Block"** %6 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = bitcast %"class.std::__1::vector"* %5 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = sub i64 %8, %10
  %12 = ashr exact i64 %11, 4
  %13 = icmp ugt i64 %12, %4
  %14 = inttoptr i64 %10 to %"struct.gpu::FencedAllocator::Block"*
  br i1 %13, label %15, label %41

15:                                               ; preds = %2
  %16 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %14, i64 %4, i32 0
  %17 = load i32, i32* %16, align 4
  %18 = icmp eq i32 %17, 1
  br i1 %18, label %19, label %41

19:                                               ; preds = %15
  %20 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %5, i64 0, i32 0, i32 0
  %21 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %14, i64 %4, i32 2
  %22 = load i32, i32* %21, align 4
  %23 = zext i32 %1 to i64
  %24 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %14, i64 %23, i32 2
  %25 = load i32, i32* %24, align 4
  %26 = add i32 %25, %22
  store i32 %26, i32* %24, align 4
  %27 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %20, align 8
  %28 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %27, i64 %23
  %29 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %28, i64 1
  %30 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %29, i64 1
  %31 = load i64, i64* %7, align 8
  %32 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %30 to i64
  %33 = sub i64 %31, %32
  %34 = ashr exact i64 %33, 4
  %35 = icmp eq i64 %33, 0
  br i1 %35, label %39, label %36

36:                                               ; preds = %19
  %37 = bitcast %"struct.gpu::FencedAllocator::Block"* %29 to i8*
  %38 = bitcast %"struct.gpu::FencedAllocator::Block"* %30 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %37, i8* align 4 %38, i64 %33, i1 false) #12
  br label %39

39:                                               ; preds = %19, %36
  %40 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %29, i64 %34
  store %"struct.gpu::FencedAllocator::Block"* %40, %"struct.gpu::FencedAllocator::Block"** %6, align 8
  br label %41

41:                                               ; preds = %15, %39, %2
  %42 = icmp eq i32 %1, 0
  br i1 %42, label %71, label %43

43:                                               ; preds = %41
  %44 = add i32 %1, -1
  %45 = zext i32 %44 to i64
  %46 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %5, i64 0, i32 0, i32 0
  %47 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %46, align 8
  %48 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %47, i64 %45, i32 0
  %49 = load i32, i32* %48, align 4
  %50 = icmp eq i32 %49, 1
  br i1 %50, label %51, label %71

51:                                               ; preds = %43
  %52 = zext i32 %1 to i64
  %53 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %47, i64 %52, i32 2
  %54 = load i32, i32* %53, align 4
  %55 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %47, i64 %45, i32 2
  %56 = load i32, i32* %55, align 4
  %57 = add i32 %56, %54
  store i32 %57, i32* %55, align 4
  %58 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %46, align 8
  %59 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %58, i64 %52
  %60 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %59, i64 1
  %61 = load i64, i64* %7, align 8
  %62 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %60 to i64
  %63 = sub i64 %61, %62
  %64 = ashr exact i64 %63, 4
  %65 = icmp eq i64 %63, 0
  br i1 %65, label %69, label %66

66:                                               ; preds = %51
  %67 = bitcast %"struct.gpu::FencedAllocator::Block"* %59 to i8*
  %68 = bitcast %"struct.gpu::FencedAllocator::Block"* %60 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %67, i8* align 4 %68, i64 %63, i1 false) #12
  br label %69

69:                                               ; preds = %51, %66
  %70 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %59, i64 %64
  store %"struct.gpu::FencedAllocator::Block"* %70, %"struct.gpu::FencedAllocator::Block"** %6, align 8
  br label %71

71:                                               ; preds = %43, %69, %41
  %72 = phi i32 [ 0, %41 ], [ %44, %69 ], [ %1, %43 ]
  ret i32 %72
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @_ZN3gpu15FencedAllocator16FreePendingTokenEji(%"class.gpu::FencedAllocator"* nocapture, i32, i32) local_unnamed_addr #3 align 2 {
  %4 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 0
  %5 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %4, align 8
  %6 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %7 = bitcast %"struct.gpu::FencedAllocator::Block"** %6 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %5 to i64
  %10 = sub i64 %8, %9
  %11 = icmp eq i64 %10, 0
  br i1 %11, label %30, label %12

12:                                               ; preds = %3
  %13 = ashr exact i64 %10, 4
  br label %14

14:                                               ; preds = %14, %12
  %15 = phi %"struct.gpu::FencedAllocator::Block"* [ %5, %12 ], [ %26, %14 ]
  %16 = phi i64 [ %13, %12 ], [ %25, %14 ]
  %17 = lshr i64 %16, 1
  %18 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %15, i64 1
  %19 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %15, i64 %17, i32 1
  %20 = load i32, i32* %19, align 4
  %21 = icmp ult i32 %20, %1
  %22 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %18, i64 %17
  %23 = xor i64 %17, -1
  %24 = add i64 %16, %23
  %25 = select i1 %21, i64 %24, i64 %17
  %26 = select i1 %21, %"struct.gpu::FencedAllocator::Block"* %22, %"struct.gpu::FencedAllocator::Block"* %15
  %27 = icmp eq i64 %25, 0
  br i1 %27, label %28, label %14

28:                                               ; preds = %14
  %29 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %26 to i64
  br label %30

30:                                               ; preds = %3, %28
  %31 = phi i64 [ %29, %28 ], [ %9, %3 ]
  %32 = sub i64 %31, %9
  %33 = lshr exact i64 %32, 4
  %34 = and i64 %33, 4294967295
  %35 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %5, i64 %34, i32 0
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 0
  br i1 %37, label %38, label %44

38:                                               ; preds = %30
  %39 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %5, i64 %34, i32 2
  %40 = load i32, i32* %39, align 4
  %41 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 2
  %42 = load i32, i32* %41, align 8
  %43 = sub i32 %42, %40
  store i32 %43, i32* %41, align 8
  br label %44

44:                                               ; preds = %38, %30
  store i32 2, i32* %35, align 4
  %45 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %5, i64 %34, i32 3
  store i32 %2, i32* %45, align 4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN3gpu15FencedAllocator18GetLargestFreeSizeEv(%"class.gpu::FencedAllocator"* nocapture) local_unnamed_addr #0 align 2 {
  tail call void @_ZN3gpu15FencedAllocator10FreeUnusedEv(%"class.gpu::FencedAllocator"* %0)
  %2 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1
  %3 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %4 = bitcast %"struct.gpu::FencedAllocator::Block"** %3 to i64*
  %5 = load i64, i64* %4, align 8
  %6 = bitcast %"class.std::__1::vector"* %2 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = icmp eq i64 %5, %7
  %9 = inttoptr i64 %7 to %"struct.gpu::FencedAllocator::Block"*
  br i1 %8, label %13, label %10

10:                                               ; preds = %1
  %11 = sub i64 %5, %7
  %12 = ashr exact i64 %11, 4
  br label %15

13:                                               ; preds = %27, %1
  %14 = phi i32 [ 0, %1 ], [ %28, %27 ]
  ret i32 %14

15:                                               ; preds = %10, %27
  %16 = phi i64 [ 0, %10 ], [ %30, %27 ]
  %17 = phi i32 [ 0, %10 ], [ %29, %27 ]
  %18 = phi i32 [ 0, %10 ], [ %28, %27 ]
  %19 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %9, i64 %16, i32 0
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %20, 1
  br i1 %21, label %22, label %27

22:                                               ; preds = %15
  %23 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %9, i64 %16, i32 2
  %24 = load i32, i32* %23, align 4
  %25 = icmp ult i32 %18, %24
  %26 = select i1 %25, i32 %24, i32 %18
  br label %27

27:                                               ; preds = %22, %15
  %28 = phi i32 [ %26, %22 ], [ %18, %15 ]
  %29 = add i32 %17, 1
  %30 = zext i32 %29 to i64
  %31 = icmp ugt i64 %12, %30
  br i1 %31, label %15, label %13
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN3gpu15FencedAllocator10FreeUnusedEv(%"class.gpu::FencedAllocator"* nocapture) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 0
  %3 = load %"class.gpu::CommandBufferHelper"*, %"class.gpu::CommandBufferHelper"** %2, align 8
  tail call void @_ZN3gpu19CommandBufferHelper18RefreshCachedTokenEv(%"class.gpu::CommandBufferHelper"* %3) #12
  %4 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1
  %5 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %6 = bitcast %"struct.gpu::FencedAllocator::Block"** %5 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = bitcast %"class.std::__1::vector"* %4 to i64*
  %9 = load i64, i64* %8, align 8
  %10 = icmp eq i64 %7, %9
  br i1 %10, label %13, label %11

11:                                               ; preds = %1
  %12 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %4, i64 0, i32 0, i32 0
  br label %14

13:                                               ; preds = %97, %1
  ret void

14:                                               ; preds = %11, %97
  %15 = phi i64 [ %7, %11 ], [ %98, %97 ]
  %16 = phi i64 [ %9, %11 ], [ %101, %97 ]
  %17 = phi i64 [ 0, %11 ], [ %100, %97 ]
  %18 = phi i32 [ 0, %11 ], [ %99, %97 ]
  %19 = inttoptr i64 %16 to %"struct.gpu::FencedAllocator::Block"*
  %20 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %19, i64 %17, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = icmp eq i32 %21, 2
  br i1 %22, label %23, label %94

23:                                               ; preds = %14
  %24 = load %"class.gpu::CommandBufferHelper"*, %"class.gpu::CommandBufferHelper"** %2, align 8
  %25 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %19, i64 %17, i32 3
  %26 = load i32, i32* %25, align 4
  %27 = tail call zeroext i1 @_ZN3gpu19CommandBufferHelper20HasCachedTokenPassedEi(%"class.gpu::CommandBufferHelper"* %24, i32 %26) #12
  br i1 %27, label %30, label %28

28:                                               ; preds = %23
  %29 = load i64, i64* %6, align 8
  br label %94

30:                                               ; preds = %23
  store i32 1, i32* %20, align 4
  %31 = add i32 %18, 1
  %32 = zext i32 %31 to i64
  %33 = load i64, i64* %6, align 8
  %34 = load i64, i64* %8, align 8
  %35 = sub i64 %33, %34
  %36 = ashr exact i64 %35, 4
  %37 = icmp ugt i64 %36, %32
  %38 = inttoptr i64 %34 to %"struct.gpu::FencedAllocator::Block"*
  br i1 %37, label %39, label %64

39:                                               ; preds = %30
  %40 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %38, i64 %32, i32 0
  %41 = load i32, i32* %40, align 4
  %42 = icmp eq i32 %41, 1
  br i1 %42, label %43, label %64

43:                                               ; preds = %39
  %44 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %38, i64 %32, i32 2
  %45 = load i32, i32* %44, align 4
  %46 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %38, i64 %17, i32 2
  %47 = load i32, i32* %46, align 4
  %48 = add i32 %47, %45
  store i32 %48, i32* %46, align 4
  %49 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %12, align 8
  %50 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %49, i64 1
  %51 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %50, i64 %17
  %52 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %51, i64 1
  %53 = load i64, i64* %6, align 8
  %54 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %52 to i64
  %55 = sub i64 %53, %54
  %56 = ashr exact i64 %55, 4
  %57 = icmp eq i64 %55, 0
  br i1 %57, label %61, label %58

58:                                               ; preds = %43
  %59 = bitcast %"struct.gpu::FencedAllocator::Block"* %51 to i8*
  %60 = bitcast %"struct.gpu::FencedAllocator::Block"* %52 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %59, i8* align 4 %60, i64 %55, i1 false) #12
  br label %61

61:                                               ; preds = %58, %43
  %62 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %51, i64 %56
  store %"struct.gpu::FencedAllocator::Block"* %62, %"struct.gpu::FencedAllocator::Block"** %5, align 8
  %63 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %62 to i64
  br label %64

64:                                               ; preds = %61, %39, %30
  %65 = phi i64 [ %63, %61 ], [ %33, %39 ], [ %33, %30 ]
  %66 = icmp eq i32 %18, 0
  br i1 %66, label %97, label %67

67:                                               ; preds = %64
  %68 = add i32 %18, -1
  %69 = zext i32 %68 to i64
  %70 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %12, align 8
  %71 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %70, i64 %69, i32 0
  %72 = load i32, i32* %71, align 4
  %73 = icmp eq i32 %72, 1
  br i1 %73, label %74, label %97

74:                                               ; preds = %67
  %75 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %70, i64 %17, i32 2
  %76 = load i32, i32* %75, align 4
  %77 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %70, i64 %69, i32 2
  %78 = load i32, i32* %77, align 4
  %79 = add i32 %78, %76
  store i32 %79, i32* %77, align 4
  %80 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %12, align 8
  %81 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %80, i64 %17
  %82 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %81, i64 1
  %83 = load i64, i64* %6, align 8
  %84 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %82 to i64
  %85 = sub i64 %83, %84
  %86 = ashr exact i64 %85, 4
  %87 = icmp eq i64 %85, 0
  br i1 %87, label %91, label %88

88:                                               ; preds = %74
  %89 = bitcast %"struct.gpu::FencedAllocator::Block"* %81 to i8*
  %90 = bitcast %"struct.gpu::FencedAllocator::Block"* %82 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %89, i8* align 4 %90, i64 %85, i1 false) #12
  br label %91

91:                                               ; preds = %88, %74
  %92 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %81, i64 %86
  store %"struct.gpu::FencedAllocator::Block"* %92, %"struct.gpu::FencedAllocator::Block"** %5, align 8
  %93 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %92 to i64
  br label %97

94:                                               ; preds = %28, %14
  %95 = phi i64 [ %29, %28 ], [ %15, %14 ]
  %96 = add i32 %18, 1
  br label %97

97:                                               ; preds = %91, %67, %64, %94
  %98 = phi i64 [ %95, %94 ], [ %65, %64 ], [ %93, %91 ], [ %65, %67 ]
  %99 = phi i32 [ %96, %94 ], [ 0, %64 ], [ %68, %91 ], [ %18, %67 ]
  %100 = zext i32 %99 to i64
  %101 = load i64, i64* %8, align 8
  %102 = sub i64 %98, %101
  %103 = ashr exact i64 %102, 4
  %104 = icmp ugt i64 %103, %100
  br i1 %104, label %14, label %13
}

; Function Attrs: nounwind readonly ssp uwtable
define hidden i32 @_ZN3gpu15FencedAllocator27GetLargestFreeOrPendingSizeEv(%"class.gpu::FencedAllocator"* nocapture readonly) local_unnamed_addr #2 align 2 {
  %2 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1
  %3 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %4 = bitcast %"struct.gpu::FencedAllocator::Block"** %3 to i64*
  %5 = load i64, i64* %4, align 8
  %6 = bitcast %"class.std::__1::vector"* %2 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = icmp eq i64 %5, %7
  %9 = inttoptr i64 %7 to %"struct.gpu::FencedAllocator::Block"*
  br i1 %8, label %13, label %10

10:                                               ; preds = %1
  %11 = sub i64 %5, %7
  %12 = ashr exact i64 %11, 4
  br label %18

13:                                               ; preds = %33, %1
  %14 = phi i32 [ 0, %1 ], [ %34, %33 ]
  %15 = phi i32 [ 0, %1 ], [ %35, %33 ]
  %16 = icmp ult i32 %14, %15
  %17 = select i1 %16, i32 %15, i32 %14
  ret i32 %17

18:                                               ; preds = %10, %33
  %19 = phi i64 [ 0, %10 ], [ %37, %33 ]
  %20 = phi i32 [ 0, %10 ], [ %36, %33 ]
  %21 = phi i32 [ 0, %10 ], [ %35, %33 ]
  %22 = phi i32 [ 0, %10 ], [ %34, %33 ]
  %23 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %9, i64 %19, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = icmp eq i32 %24, 0
  br i1 %25, label %26, label %29

26:                                               ; preds = %18
  %27 = icmp ult i32 %22, %21
  %28 = select i1 %27, i32 %21, i32 %22
  br label %33

29:                                               ; preds = %18
  %30 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %9, i64 %19, i32 2
  %31 = load i32, i32* %30, align 4
  %32 = add i32 %31, %21
  br label %33

33:                                               ; preds = %29, %26
  %34 = phi i32 [ %28, %26 ], [ %22, %29 ]
  %35 = phi i32 [ 0, %26 ], [ %32, %29 ]
  %36 = add i32 %20, 1
  %37 = zext i32 %36 to i64
  %38 = icmp ugt i64 %12, %37
  br i1 %38, label %18, label %13
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN3gpu15FencedAllocator11GetFreeSizeEv(%"class.gpu::FencedAllocator"* nocapture) local_unnamed_addr #0 align 2 {
  tail call void @_ZN3gpu15FencedAllocator10FreeUnusedEv(%"class.gpu::FencedAllocator"* %0)
  %2 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1
  %3 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %4 = bitcast %"struct.gpu::FencedAllocator::Block"** %3 to i64*
  %5 = load i64, i64* %4, align 8
  %6 = bitcast %"class.std::__1::vector"* %2 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = icmp eq i64 %5, %7
  %9 = inttoptr i64 %7 to %"struct.gpu::FencedAllocator::Block"*
  br i1 %8, label %13, label %10

10:                                               ; preds = %1
  %11 = sub i64 %5, %7
  %12 = ashr exact i64 %11, 4
  br label %15

13:                                               ; preds = %15, %1
  %14 = phi i32 [ 0, %1 ], [ %25, %15 ]
  ret i32 %14

15:                                               ; preds = %10, %15
  %16 = phi i64 [ 0, %10 ], [ %27, %15 ]
  %17 = phi i32 [ 0, %10 ], [ %26, %15 ]
  %18 = phi i32 [ 0, %10 ], [ %25, %15 ]
  %19 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %9, i64 %16, i32 0
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %20, 1
  %22 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %9, i64 %16, i32 2
  %23 = load i32, i32* %22, align 4
  %24 = select i1 %21, i32 %23, i32 0
  %25 = add i32 %24, %18
  %26 = add i32 %17, 1
  %27 = zext i32 %26 to i64
  %28 = icmp ugt i64 %12, %27
  br i1 %28, label %15, label %13
}

; Function Attrs: norecurse nounwind readonly ssp uwtable
define hidden zeroext i1 @_ZN3gpu15FencedAllocator16CheckConsistencyEv(%"class.gpu::FencedAllocator"* nocapture readonly) local_unnamed_addr #4 align 2 {
  %2 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1
  %3 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %4 = bitcast %"struct.gpu::FencedAllocator::Block"** %3 to i64*
  %5 = load i64, i64* %4, align 8
  %6 = bitcast %"class.std::__1::vector"* %2 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = sub i64 %5, %7
  %9 = icmp eq i64 %8, 0
  %10 = inttoptr i64 %7 to %"struct.gpu::FencedAllocator::Block"*
  br i1 %9, label %42, label %11

11:                                               ; preds = %1
  %12 = ashr exact i64 %8, 4
  %13 = add nsw i64 %12, -1
  %14 = icmp eq i64 %13, 0
  br i1 %14, label %42, label %15

15:                                               ; preds = %11
  %16 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %10, i64 0, i32 1
  %17 = load i32, i32* %16, align 4
  br label %18

18:                                               ; preds = %15, %40
  %19 = phi i32 [ %17, %15 ], [ %25, %40 ]
  %20 = phi i64 [ 0, %15 ], [ %23, %40 ]
  %21 = phi i32 [ 0, %15 ], [ %22, %40 ]
  %22 = add i32 %21, 1
  %23 = zext i32 %22 to i64
  %24 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %10, i64 %23, i32 1
  %25 = load i32, i32* %24, align 4
  %26 = icmp ugt i32 %25, %19
  br i1 %26, label %27, label %42

27:                                               ; preds = %18
  %28 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %10, i64 %20, i32 2
  %29 = load i32, i32* %28, align 4
  %30 = add i32 %29, %19
  %31 = icmp eq i32 %25, %30
  br i1 %31, label %32, label %42

32:                                               ; preds = %27
  %33 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %10, i64 %20, i32 0
  %34 = load i32, i32* %33, align 4
  %35 = icmp eq i32 %34, 1
  br i1 %35, label %36, label %40

36:                                               ; preds = %32
  %37 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %10, i64 %23, i32 0
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 1
  br i1 %39, label %42, label %40

40:                                               ; preds = %32, %36
  %41 = icmp ugt i64 %13, %23
  br i1 %41, label %18, label %42

42:                                               ; preds = %18, %27, %36, %40, %11, %1
  %43 = phi i1 [ false, %1 ], [ true, %11 ], [ false, %18 ], [ false, %27 ], [ false, %36 ], [ true, %40 ]
  ret i1 %43
}

; Function Attrs: norecurse nounwind readonly ssp uwtable
define hidden zeroext i1 @_ZN3gpu15FencedAllocator18InUseOrFreePendingEv(%"class.gpu::FencedAllocator"* nocapture readonly) local_unnamed_addr #4 align 2 {
  %2 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1
  %3 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %4 = bitcast %"struct.gpu::FencedAllocator::Block"** %3 to i64*
  %5 = load i64, i64* %4, align 8
  %6 = bitcast %"class.std::__1::vector"* %2 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = sub i64 %5, %7
  %9 = icmp eq i64 %8, 16
  br i1 %9, label %10, label %15

10:                                               ; preds = %1
  %11 = inttoptr i64 %7 to %"struct.gpu::FencedAllocator::Block"*
  %12 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %11, i64 0, i32 0
  %13 = load i32, i32* %12, align 4
  %14 = icmp ne i32 %13, 1
  br label %15

15:                                               ; preds = %1, %10
  %16 = phi i1 [ true, %1 ], [ %14, %10 ]
  ret i1 %16
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden i32 @_ZN3gpu15FencedAllocator21GetBlockStatusForTestEjPi(%"class.gpu::FencedAllocator"* nocapture readonly, i32, i32*) local_unnamed_addr #3 align 2 {
  %4 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 0
  %5 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %4, align 8
  %6 = getelementptr inbounds %"class.gpu::FencedAllocator", %"class.gpu::FencedAllocator"* %0, i64 0, i32 1, i32 0, i32 1
  %7 = bitcast %"struct.gpu::FencedAllocator::Block"** %6 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %5 to i64
  %10 = sub i64 %8, %9
  %11 = icmp eq i64 %10, 0
  br i1 %11, label %30, label %12

12:                                               ; preds = %3
  %13 = ashr exact i64 %10, 4
  br label %14

14:                                               ; preds = %14, %12
  %15 = phi %"struct.gpu::FencedAllocator::Block"* [ %5, %12 ], [ %26, %14 ]
  %16 = phi i64 [ %13, %12 ], [ %25, %14 ]
  %17 = lshr i64 %16, 1
  %18 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %15, i64 1
  %19 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %15, i64 %17, i32 1
  %20 = load i32, i32* %19, align 4
  %21 = icmp ult i32 %20, %1
  %22 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %18, i64 %17
  %23 = xor i64 %17, -1
  %24 = add i64 %16, %23
  %25 = select i1 %21, i64 %24, i64 %17
  %26 = select i1 %21, %"struct.gpu::FencedAllocator::Block"* %22, %"struct.gpu::FencedAllocator::Block"* %15
  %27 = icmp eq i64 %25, 0
  br i1 %27, label %28, label %14

28:                                               ; preds = %14
  %29 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %26 to i64
  br label %30

30:                                               ; preds = %3, %28
  %31 = phi i64 [ %29, %28 ], [ %9, %3 ]
  %32 = sub i64 %31, %9
  %33 = lshr exact i64 %32, 4
  %34 = and i64 %33, 4294967295
  %35 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %5, i64 %34, i32 0
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, 2
  %38 = icmp ne i32* %2, null
  %39 = and i1 %38, %37
  br i1 %39, label %40, label %44

40:                                               ; preds = %30
  %41 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %5, i64 %34, i32 3
  %42 = load i32, i32* %41, align 4
  store i32 %42, i32* %2, align 4
  %43 = load i32, i32* %35, align 4
  br label %44

44:                                               ; preds = %40, %30
  %45 = phi i32 [ %43, %40 ], [ %36, %30 ]
  ret i32 %45
}

declare void @_ZN3gpu19CommandBufferHelper12WaitForTokenEi(%"class.gpu::CommandBufferHelper"*, i32) local_unnamed_addr #5

declare void @_ZN3gpu19CommandBufferHelper18RefreshCachedTokenEv(%"class.gpu::CommandBufferHelper"*) local_unnamed_addr #5

declare zeroext i1 @_ZN3gpu19CommandBufferHelper20HasCachedTokenPassedEi(%"class.gpu::CommandBufferHelper"*, i32) local_unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden %"struct.gpu::FencedAllocator::Block"* @_ZNSt3__16vectorIN3gpu15FencedAllocator5BlockENS_9allocatorIS3_EEE6insertENS_11__wrap_iterIPKS3_EERS8_(%"class.std::__1::vector"*, %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"* dereferenceable(16)) local_unnamed_addr #0 comdat align 2 {
  %4 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %1 to i64
  %5 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %0, i64 0, i32 0, i32 0
  %6 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %0, i64 0, i32 0, i32 1
  %7 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %6, align 8
  %8 = getelementptr inbounds %"class.std::__1::vector", %"class.std::__1::vector"* %0, i64 0, i32 0, i32 2, i32 0, i32 0
  %9 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %8, align 8
  %10 = icmp ult %"struct.gpu::FencedAllocator::Block"* %7, %9
  %11 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %7 to i64
  %12 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %9 to i64
  br i1 %10, label %13, label %97

13:                                               ; preds = %3
  %14 = icmp eq %"struct.gpu::FencedAllocator::Block"* %7, %1
  br i1 %14, label %15, label %21

15:                                               ; preds = %13
  %16 = bitcast %"struct.gpu::FencedAllocator::Block"* %1 to i8*
  %17 = bitcast %"struct.gpu::FencedAllocator::Block"* %2 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %16, i8* align 4 %17, i64 16, i1 false) #12
  %18 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %1, i64 1
  %19 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %18 to i64
  %20 = bitcast %"struct.gpu::FencedAllocator::Block"** %6 to i64*
  store i64 %19, i64* %20, align 8
  br label %235

21:                                               ; preds = %13
  %22 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %1, i64 1
  %23 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %22 to i64
  %24 = sub i64 %11, %23
  %25 = ashr exact i64 %24, 4
  %26 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %1, i64 %25
  %27 = bitcast %"struct.gpu::FencedAllocator::Block"** %6 to i64*
  %28 = icmp ult %"struct.gpu::FencedAllocator::Block"* %26, %7
  br i1 %28, label %29, label %58

29:                                               ; preds = %21
  %30 = sub nsw i64 0, %25
  %31 = getelementptr %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %7, i64 %30, i32 0
  %32 = bitcast i32* %31 to i8*
  %33 = xor i64 %4, -1
  %34 = getelementptr i8, i8* %32, i64 %33
  %35 = ptrtoint i8* %34 to i64
  %36 = lshr i64 %35, 4
  %37 = add nuw nsw i64 %36, 1
  %38 = and i64 %37, 3
  %39 = icmp eq i64 %38, 0
  br i1 %39, label %50, label %40

40:                                               ; preds = %29, %40
  %41 = phi %"struct.gpu::FencedAllocator::Block"* [ %47, %40 ], [ %7, %29 ]
  %42 = phi %"struct.gpu::FencedAllocator::Block"* [ %46, %40 ], [ %26, %29 ]
  %43 = phi i64 [ %48, %40 ], [ %38, %29 ]
  %44 = bitcast %"struct.gpu::FencedAllocator::Block"* %41 to i8*
  %45 = bitcast %"struct.gpu::FencedAllocator::Block"* %42 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %44, i8* align 4 %45, i64 16, i1 false) #12
  %46 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %42, i64 1
  %47 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %41, i64 1
  %48 = add i64 %43, -1
  %49 = icmp eq i64 %48, 0
  br i1 %49, label %50, label %40, !llvm.loop !3

50:                                               ; preds = %40, %29
  %51 = phi %"struct.gpu::FencedAllocator::Block"* [ %7, %29 ], [ %47, %40 ]
  %52 = phi %"struct.gpu::FencedAllocator::Block"* [ %26, %29 ], [ %46, %40 ]
  %53 = phi %"struct.gpu::FencedAllocator::Block"* [ undef, %29 ], [ %47, %40 ]
  %54 = icmp ult i8* %34, inttoptr (i64 48 to i8*)
  br i1 %54, label %55, label %66

55:                                               ; preds = %66, %50
  %56 = phi %"struct.gpu::FencedAllocator::Block"* [ %53, %50 ], [ %84, %66 ]
  %57 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %56 to i64
  br label %58

58:                                               ; preds = %55, %21
  %59 = phi i64 [ %57, %55 ], [ %11, %21 ]
  store i64 %59, i64* %27, align 8
  %60 = icmp eq i64 %24, 0
  br i1 %60, label %86, label %61

61:                                               ; preds = %58
  %62 = sub nsw i64 0, %25
  %63 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %7, i64 %62
  %64 = bitcast %"struct.gpu::FencedAllocator::Block"* %63 to i8*
  %65 = bitcast %"struct.gpu::FencedAllocator::Block"* %1 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %64, i8* align 4 %65, i64 %24, i1 false) #12
  br label %86

66:                                               ; preds = %50, %66
  %67 = phi %"struct.gpu::FencedAllocator::Block"* [ %84, %66 ], [ %51, %50 ]
  %68 = phi %"struct.gpu::FencedAllocator::Block"* [ %83, %66 ], [ %52, %50 ]
  %69 = bitcast %"struct.gpu::FencedAllocator::Block"* %67 to i8*
  %70 = bitcast %"struct.gpu::FencedAllocator::Block"* %68 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %69, i8* align 4 %70, i64 16, i1 false) #12
  %71 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %68, i64 1
  %72 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %67, i64 1
  %73 = bitcast %"struct.gpu::FencedAllocator::Block"* %72 to i8*
  %74 = bitcast %"struct.gpu::FencedAllocator::Block"* %71 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %73, i8* align 4 %74, i64 16, i1 false) #12
  %75 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %68, i64 2
  %76 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %67, i64 2
  %77 = bitcast %"struct.gpu::FencedAllocator::Block"* %76 to i8*
  %78 = bitcast %"struct.gpu::FencedAllocator::Block"* %75 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %77, i8* align 4 %78, i64 16, i1 false) #12
  %79 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %68, i64 3
  %80 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %67, i64 3
  %81 = bitcast %"struct.gpu::FencedAllocator::Block"* %80 to i8*
  %82 = bitcast %"struct.gpu::FencedAllocator::Block"* %79 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %81, i8* align 4 %82, i64 16, i1 false) #12
  %83 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %68, i64 4
  %84 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %67, i64 4
  %85 = icmp ult %"struct.gpu::FencedAllocator::Block"* %83, %7
  br i1 %85, label %66, label %55

86:                                               ; preds = %58, %61
  %87 = icmp ugt %"struct.gpu::FencedAllocator::Block"* %1, %2
  br i1 %87, label %93, label %88

88:                                               ; preds = %86
  %89 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %6, align 8
  %90 = icmp ugt %"struct.gpu::FencedAllocator::Block"* %89, %2
  %91 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %2, i64 1
  %92 = select i1 %90, %"struct.gpu::FencedAllocator::Block"* %91, %"struct.gpu::FencedAllocator::Block"* %2
  br label %93

93:                                               ; preds = %88, %86
  %94 = phi %"struct.gpu::FencedAllocator::Block"* [ %2, %86 ], [ %92, %88 ]
  %95 = bitcast %"struct.gpu::FencedAllocator::Block"* %1 to i8*
  %96 = bitcast %"struct.gpu::FencedAllocator::Block"* %94 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %95, i8* align 4 %96, i64 16, i1 false)
  br label %235

97:                                               ; preds = %3
  %98 = bitcast %"struct.gpu::FencedAllocator::Block"** %6 to i64*
  %99 = bitcast %"class.std::__1::vector"* %0 to i64*
  %100 = load i64, i64* %99, align 8
  %101 = sub i64 %11, %100
  %102 = ashr exact i64 %101, 4
  %103 = add nsw i64 %102, 1
  %104 = icmp ugt i64 %103, 1152921504606846975
  br i1 %104, label %105, label %107

105:                                              ; preds = %97
  %106 = bitcast %"class.std::__1::vector"* %0 to %"class.std::__1::__vector_base_common"*
  tail call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %106) #13
  unreachable

107:                                              ; preds = %97
  %108 = bitcast %"struct.gpu::FencedAllocator::Block"** %8 to i64*
  %109 = sub i64 %12, %100
  %110 = ashr exact i64 %109, 4
  %111 = icmp ult i64 %110, 576460752303423487
  br i1 %111, label %115, label %112

112:                                              ; preds = %107
  %113 = sub i64 %4, %100
  %114 = ashr exact i64 %113, 4
  br label %125

115:                                              ; preds = %107
  %116 = ashr exact i64 %109, 3
  %117 = icmp ult i64 %116, %103
  %118 = select i1 %117, i64 %103, i64 %116
  %119 = sub i64 %4, %100
  %120 = ashr exact i64 %119, 4
  %121 = icmp eq i64 %118, 0
  br i1 %121, label %131, label %122

122:                                              ; preds = %115
  %123 = icmp ugt i64 %118, 1152921504606846975
  br i1 %123, label %124, label %125

124:                                              ; preds = %122
  tail call void @abort() #13
  unreachable

125:                                              ; preds = %112, %122
  %126 = phi i64 [ 1152921504606846975, %112 ], [ %118, %122 ]
  %127 = phi i64 [ %114, %112 ], [ %120, %122 ]
  %128 = shl i64 %126, 4
  %129 = tail call i8* @_Znwm(i64 %128) #11
  %130 = bitcast i8* %129 to %"struct.gpu::FencedAllocator::Block"*
  br label %131

131:                                              ; preds = %115, %125
  %132 = phi i64 [ %127, %125 ], [ %120, %115 ]
  %133 = phi i64 [ %126, %125 ], [ 0, %115 ]
  %134 = phi i8* [ %129, %125 ], [ null, %115 ]
  %135 = phi %"struct.gpu::FencedAllocator::Block"* [ %130, %125 ], [ null, %115 ]
  %136 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %135, i64 %132
  %137 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %135, i64 %133
  %138 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %137 to i64
  %139 = icmp eq i64 %132, %133
  %140 = bitcast %"struct.gpu::FencedAllocator::Block"* %136 to i8*
  br i1 %139, label %141, label %165

141:                                              ; preds = %131
  %142 = icmp sgt i64 %132, 0
  br i1 %142, label %143, label %148

143:                                              ; preds = %141
  %144 = add nuw nsw i64 %132, 1
  %145 = sdiv i64 %144, -2
  %146 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %136, i64 %145
  %147 = bitcast %"struct.gpu::FencedAllocator::Block"* %146 to i8*
  br label %165

148:                                              ; preds = %141
  %149 = shl nsw i64 %132, 1
  %150 = icmp eq i64 %132, 0
  %151 = select i1 %150, i64 1, i64 %149
  %152 = icmp ugt i64 %151, 1152921504606846975
  br i1 %152, label %153, label %154

153:                                              ; preds = %148
  tail call void @abort() #13
  unreachable

154:                                              ; preds = %148
  %155 = lshr i64 %151, 2
  %156 = shl i64 %151, 4
  %157 = tail call i8* @_Znwm(i64 %156) #11
  %158 = bitcast i8* %157 to %"struct.gpu::FencedAllocator::Block"*
  %159 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %158, i64 %155
  %160 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %158, i64 %151
  %161 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %160 to i64
  %162 = icmp eq %"struct.gpu::FencedAllocator::Block"* %135, null
  %163 = bitcast %"struct.gpu::FencedAllocator::Block"* %159 to i8*
  br i1 %162, label %165, label %164

164:                                              ; preds = %154
  tail call void @_ZdlPv(i8* %134) #11
  br label %165

165:                                              ; preds = %131, %143, %154, %164
  %166 = phi %"struct.gpu::FencedAllocator::Block"* [ %146, %143 ], [ %159, %154 ], [ %159, %164 ], [ %136, %131 ]
  %167 = phi i64 [ %138, %143 ], [ %161, %154 ], [ %161, %164 ], [ %138, %131 ]
  %168 = phi i8* [ %147, %143 ], [ %163, %154 ], [ %163, %164 ], [ %140, %131 ]
  %169 = bitcast %"struct.gpu::FencedAllocator::Block"* %2 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %168, i8* align 4 %169, i64 16, i1 false) #12
  %170 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %166, i64 1
  %171 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %5, align 8
  %172 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %171 to i64
  %173 = sub i64 %4, %172
  %174 = ashr exact i64 %173, 4
  %175 = sub nsw i64 0, %174
  %176 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %166, i64 %175
  %177 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %176 to i64
  %178 = icmp sgt i64 %173, 0
  br i1 %178, label %179, label %182

179:                                              ; preds = %165
  %180 = bitcast %"struct.gpu::FencedAllocator::Block"* %176 to i8*
  %181 = bitcast %"struct.gpu::FencedAllocator::Block"* %171 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %180, i8* align 4 %181, i64 %173, i1 false) #12
  br label %182

182:                                              ; preds = %179, %165
  %183 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %6, align 8
  %184 = icmp eq %"struct.gpu::FencedAllocator::Block"* %183, %1
  br i1 %184, label %228, label %185

185:                                              ; preds = %182
  %186 = getelementptr %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %183, i64 -1, i32 0
  %187 = ptrtoint i32* %186 to i64
  %188 = sub i64 %187, %4
  %189 = lshr i64 %188, 4
  %190 = add nuw nsw i64 %189, 1
  %191 = and i64 %190, 3
  %192 = icmp eq i64 %191, 0
  br i1 %192, label %203, label %193

193:                                              ; preds = %185, %193
  %194 = phi %"struct.gpu::FencedAllocator::Block"* [ %200, %193 ], [ %170, %185 ]
  %195 = phi %"struct.gpu::FencedAllocator::Block"* [ %199, %193 ], [ %1, %185 ]
  %196 = phi i64 [ %201, %193 ], [ %191, %185 ]
  %197 = bitcast %"struct.gpu::FencedAllocator::Block"* %194 to i8*
  %198 = bitcast %"struct.gpu::FencedAllocator::Block"* %195 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %197, i8* align 4 %198, i64 16, i1 false) #12
  %199 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %195, i64 1
  %200 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %194, i64 1
  %201 = add i64 %196, -1
  %202 = icmp eq i64 %201, 0
  br i1 %202, label %203, label %193, !llvm.loop !5

203:                                              ; preds = %193, %185
  %204 = phi %"struct.gpu::FencedAllocator::Block"* [ undef, %185 ], [ %200, %193 ]
  %205 = phi %"struct.gpu::FencedAllocator::Block"* [ %170, %185 ], [ %200, %193 ]
  %206 = phi %"struct.gpu::FencedAllocator::Block"* [ %1, %185 ], [ %199, %193 ]
  %207 = icmp ult i64 %188, 48
  br i1 %207, label %228, label %208

208:                                              ; preds = %203, %208
  %209 = phi %"struct.gpu::FencedAllocator::Block"* [ %226, %208 ], [ %205, %203 ]
  %210 = phi %"struct.gpu::FencedAllocator::Block"* [ %225, %208 ], [ %206, %203 ]
  %211 = bitcast %"struct.gpu::FencedAllocator::Block"* %209 to i8*
  %212 = bitcast %"struct.gpu::FencedAllocator::Block"* %210 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %211, i8* align 4 %212, i64 16, i1 false) #12
  %213 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %210, i64 1
  %214 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %209, i64 1
  %215 = bitcast %"struct.gpu::FencedAllocator::Block"* %214 to i8*
  %216 = bitcast %"struct.gpu::FencedAllocator::Block"* %213 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %215, i8* align 4 %216, i64 16, i1 false) #12
  %217 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %210, i64 2
  %218 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %209, i64 2
  %219 = bitcast %"struct.gpu::FencedAllocator::Block"* %218 to i8*
  %220 = bitcast %"struct.gpu::FencedAllocator::Block"* %217 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %219, i8* align 4 %220, i64 16, i1 false) #12
  %221 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %210, i64 3
  %222 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %209, i64 3
  %223 = bitcast %"struct.gpu::FencedAllocator::Block"* %222 to i8*
  %224 = bitcast %"struct.gpu::FencedAllocator::Block"* %221 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %223, i8* align 4 %224, i64 16, i1 false) #12
  %225 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %210, i64 4
  %226 = getelementptr inbounds %"struct.gpu::FencedAllocator::Block", %"struct.gpu::FencedAllocator::Block"* %209, i64 4
  %227 = icmp eq %"struct.gpu::FencedAllocator::Block"* %225, %183
  br i1 %227, label %228, label %208

228:                                              ; preds = %203, %208, %182
  %229 = phi %"struct.gpu::FencedAllocator::Block"* [ %170, %182 ], [ %204, %203 ], [ %226, %208 ]
  %230 = ptrtoint %"struct.gpu::FencedAllocator::Block"* %229 to i64
  %231 = load %"struct.gpu::FencedAllocator::Block"*, %"struct.gpu::FencedAllocator::Block"** %5, align 8
  store i64 %177, i64* %99, align 8
  store i64 %230, i64* %98, align 8
  store i64 %167, i64* %108, align 8
  %232 = icmp eq %"struct.gpu::FencedAllocator::Block"* %231, null
  br i1 %232, label %235, label %233

233:                                              ; preds = %228
  %234 = bitcast %"struct.gpu::FencedAllocator::Block"* %231 to i8*
  tail call void @_ZdlPv(i8* %234) #11
  br label %235

235:                                              ; preds = %233, %228, %15, %93
  %236 = phi %"struct.gpu::FencedAllocator::Block"* [ %1, %15 ], [ %1, %93 ], [ %166, %228 ], [ %166, %233 ]
  ret %"struct.gpu::FencedAllocator::Block"* %236
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #1

; Function Attrs: nounwind readnone speculatable
declare { i32, i1 } @llvm.uadd.with.overflow.i32(i32, i32) #6

; Function Attrs: nobuiltin nounwind
declare void @_ZdlPv(i8*) local_unnamed_addr #7

; Function Attrs: noreturn
declare void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"*) local_unnamed_addr #8

; Function Attrs: noreturn nounwind
declare void @abort() local_unnamed_addr #9

; Function Attrs: nobuiltin nofree
declare noalias nonnull i8* @_Znwm(i64) local_unnamed_addr #10

; Function Attrs: argmemonly nounwind
declare void @llvm.memmove.p0i8.p0i8.i64(i8* nocapture, i8* nocapture readonly, i64, i1 immarg) #1

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nounwind readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { norecurse nounwind readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nounwind readnone speculatable }
attributes #7 = { nobuiltin nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { noreturn "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { noreturn nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { nobuiltin nofree "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #11 = { builtin nounwind }
attributes #12 = { nounwind }
attributes #13 = { noreturn nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{!"branch_weights", i32 1, i32 2000}
!3 = distinct !{!3, !4}
!4 = !{!"llvm.loop.unroll.disable"}
!5 = distinct !{!5, !4}
