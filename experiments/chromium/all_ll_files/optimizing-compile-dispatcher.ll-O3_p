; ModuleID = '../../v8/src/compiler-dispatcher/optimizing-compile-dispatcher.cc'
source_filename = "../../v8/src/compiler-dispatcher/optimizing-compile-dispatcher.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%struct._IO_FILE = type { i32, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, %struct._IO_marker*, %struct._IO_FILE*, i32, i32, i64, i16, i8, [1 x i8], i8*, i64, %struct._IO_codecvt*, %struct._IO_wide_data*, %struct._IO_FILE*, i8*, i64, i32, [20 x i8] }
%struct._IO_marker = type opaque
%struct._IO_codecvt = type opaque
%struct._IO_wide_data = type opaque
%"struct.std::__1::atomic.1218" = type { %"struct.std::__1::__atomic_base.1219" }
%"struct.std::__1::__atomic_base.1219" = type { %"struct.std::__1::__atomic_base.1220" }
%"struct.std::__1::__atomic_base.1220" = type { %"struct.std::__1::__cxx_atomic_impl.1221" }
%"struct.std::__1::__cxx_atomic_impl.1221" = type { %"struct.std::__1::__cxx_atomic_base_impl.1222" }
%"struct.std::__1::__cxx_atomic_base_impl.1222" = type { i32 }
%"class.v8::internal::OptimizingCompileDispatcher" = type <{ %"class.v8::internal::Isolate"*, %"class.v8::internal::OptimizedCompilationJob"**, i32, i32, i32, [4 x i8], %"class.v8::base::Mutex", %"class.std::__1::queue.1159", %"class.v8::base::Mutex", i32, i32, %"class.v8::base::Mutex", %"class.v8::base::ConditionVariable", i32, [4 x i8] }>
%"class.v8::internal::Isolate" = type { %"class.v8::internal::IsolateData", %"class.std::__1::unique_ptr", %"class.v8::internal::Heap", %"class.v8::internal::ReadOnlyHeap"*, %"class.std::__1::shared_ptr.645", %"class.std::__1::unique_ptr.666", i32, %"class.v8::internal::Isolate::EntryStackItem"*, i32, %"class.v8::internal::StringStream"*, [13 x i64], %"class.v8::internal::Bootstrapper"*, %"class.v8::internal::RuntimeProfiler"*, %"class.v8::internal::CompilationCache"*, %"class.std::__1::shared_ptr.676", %"class.v8::base::RecursiveMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::internal::Logger"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::Deoptimizer"*, i8, %"class.v8::internal::MaterializedObjectStore"*, i8, i32, i32, %"class.v8::internal::DescriptorLookupCache"*, %"struct.v8::internal::HandleScopeData", %"class.v8::internal::HandleScopeImplementer"*, %"class.v8::internal::UnicodeCache"*, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::InnerPointerToCodeCache"*, %"class.v8::internal::GlobalHandles"*, %"class.v8::internal::EternalHandles"*, %"class.v8::internal::ThreadManager"*, %"class.v8::bigint::Processor"*, %"class.v8::internal::RuntimeState", %"class.v8::internal::Builtins", %"class.v8::internal::SetupIsolateDelegate"*, %"class.v8::internal::RegExpStack"*, %"class.std::__1::vector.742", %"class.v8::internal::DateCache"*, %"class.v8::base::RandomNumberGenerator"*, %"class.v8::base::RandomNumberGenerator"*, %"struct.std::__1::atomic.870", {}*, i8*, void (i32, %"class.v8::Promise"*, %"class.v8::Value"*)*, {}*, {}*, %"struct.std::__1::atomic.880", {}*, %"class.v8::base::Mutex", double, %"class.std::__1::basic_string", %"class.std::__1::unordered_map.885", %"struct.std::__1::atomic.152", i8, i8, i8, i8, i8, i8, double, %"class.v8::internal::Debug"*, %"class.v8::internal::HeapProfiler"*, %"class.std::__1::unique_ptr.960", %"class.v8::internal::AstStringConstants"*, %"class.v8::internal::interpreter::Interpreter"*, %"class.v8::internal::compiler::PerIsolateCompilerCache"*, %"class.v8::internal::Zone"*, %"class.v8::internal::CompilerDispatcher"*, %"class.std::__1::queue", void (i8*, i8*)*, void (i8*, i1)*, void (i8*, i32)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*, i1)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::Context"*)*, void (%"class.v8::FunctionCallbackInfo"*)*, %"class.v8::String"* (%"class.v8::Isolate"*, i8*)*, i1 (%"class.v8::Context"*)*, i1 (%"class.v8::Context"*)*, %"class.v8::internal::Relocatable"*, %"class.std::__1::vector.1003"*, %"class.v8::internal::Object", i64*, %"class.v8::internal::AddressToIndexHashMap"*, %"class.v8::internal::HeapObjectToIndexHashMap"*, %"class.v8::internal::MicrotaskQueue"*, %"class.v8::internal::CompilationStatistics"*, %"class.v8::internal::CodeTracer"*, i32, void (%"class.v8::PromiseRejectMessage"*)*, %"class.v8::StartupData"*, i32, i32, i32, i64, i8, i8, i32, i8, i32, %"class.v8_inspector::V8Inspector"*, i8, i8, i8, i32, i32, %"class.v8::internal::compiler::NodeObserver"*, i8, [128 x i32], [256 x i32], [251 x i32], [251 x i32], %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.std::__1::unique_ptr.1012", i32, i8, i8, i32, i32, %"class.std::__1::vector.1018", %"class.std::__1::vector.1018", void (%"class.v8::Isolate"*, i32)*, %"class.std::__1::shared_ptr.1025", i64, %"class.std::__1::unordered_map.1026", i64, %"struct.v8::metrics::LongTaskStats", %"class.std::__1::vector.541", %"class.v8::internal::BuiltinsConstantsTableBuilder"*, i8*, i32, i8*, i32, %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::shared_ptr.160", %"class.v8::internal::FutexWaitListNode", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::debug::ConsoleDelegate"*, %"class.v8::debug::AsyncEventDelegate"*, i32, i32, %"class.std::__1::unique_ptr.1082", i1 (%"class.v8::Isolate"*)*, i8, %"class.v8::base::Mutex", %"struct.v8::internal::ManagedPtrDestructor"*, i64, i64, %"class.v8::internal::wasm::WasmEngine"*, %"class.std::__1::unique_ptr.1114", %"class.v8::internal::EmbeddedFileWriterInterface"*, %"class.v8::Context::BackupIncumbentScope"*, {}*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate::ThreadDataTable", i8, %"class.v8::internal::Isolate"*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"struct.std::__1::atomic.1148", %"class.std::__1::vector.1152", %"class.std::__1::vector.1152", void (i32, %"class.std::__1::basic_string"*)* }
%"class.v8::internal::IsolateData" = type { [4 x i8*], i64, i64, i64, i64, i64, %"class.v8::internal::StackGuard", %"class.v8::internal::RootsTable", %"class.v8::internal::ExternalReferenceTable", %"class.v8::internal::ThreadLocalTop", [1711 x i64], [1711 x i64], i8, [15 x i8] }
%"class.v8::internal::StackGuard" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::StackGuard::ThreadLocal" }
%"class.v8::internal::StackGuard::ThreadLocal" = type { i64, i64, i64, i64, %"class.v8::internal::InterruptsScope"*, i64 }
%"class.v8::internal::InterruptsScope" = type { i32 (...)**, %"class.v8::internal::StackGuard"*, i64, i64, i32, %"class.v8::internal::InterruptsScope"* }
%"class.v8::internal::RootsTable" = type { [669 x i64] }
%"class.v8::internal::ExternalReferenceTable" = type { [1042 x i64], i32, i32 }
%"class.v8::internal::ThreadLocalTop" = type { %"class.v8::TryCatch"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Context", %"struct.std::__1::atomic", %"class.v8::internal::Object", %"class.v8::internal::Context", i64, i64, i64, i64, i64, %"class.v8::internal::Object", i8, i8, %"class.v8::internal::Object", i64, i64, i64, %"class.v8::internal::PromiseOnStack"*, %"class.v8::internal::Simulator"*, i64, %"class.v8::internal::ExternalCallbackScope"*, i32, void (%"class.v8::Object"*, i32, %"class.v8::Value"*)*, i64 }
%"class.v8::TryCatch" = type <{ %"class.v8::internal::Isolate"*, %"class.v8::TryCatch"*, i8*, i8*, i8*, i8, [7 x i8] }>
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { %"class.v8::internal::ThreadId" }
%"class.v8::internal::ThreadId" = type { i32 }
%"class.v8::internal::Context" = type { %"class.v8::internal::TorqueGeneratedContext" }
%"class.v8::internal::TorqueGeneratedContext" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::HeapObject" = type { %"class.v8::internal::Object" }
%"class.v8::internal::PromiseOnStack" = type { %"class.v8::internal::Handle", %"class.v8::internal::PromiseOnStack"* }
%"class.v8::internal::Handle" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HandleBase" = type { i64* }
%"class.v8::internal::Simulator" = type opaque
%"class.v8::internal::ExternalCallbackScope" = type opaque
%"class.v8::Object" = type { i8 }
%"class.v8::Value" = type { i8 }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { %"class.v8::internal::IsolateAllocator"* }
%"class.v8::internal::IsolateAllocator" = type { i8*, %"class.v8::PageAllocator"* }
%"class.v8::PageAllocator" = type { i32 (...)** }
%"class.v8::internal::Heap" = type { %"class.std::__1::unordered_map", %"struct.std::__1::atomic.19", %"class.v8::internal::Heap::ExternalMemoryAccounting", %"class.v8::internal::Isolate"*, i64, i64, i64, i64, %"struct.std::__1::atomic.19", i64, i64, i64, i64, i64, i8, i64, i64, %"struct.std::__1::atomic.19", i64, i64, %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.29", %"class.std::__1::vector", i32, %"class.v8::internal::NewSpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::CodeSpace"*, %"class.v8::internal::MapSpace"*, %"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::NewLargeObjectSpace"*, %"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::MapSpace"*, %"class.std::__1::unique_ptr.146", %"class.std::__1::unique_ptr.146", [8 x %"class.v8::internal::Space"*], %"class.v8::internal::LocalHeap"*, %"class.v8::internal::ArrayBufferExtension"*, %"class.v8::internal::ArrayBufferExtension"*, i8, i64, %"struct.std::__1::atomic.161", i32, i32, i32, i32, %"class.v8::internal::AllocationObserver"*, %"class.v8::internal::StressScavengeObserver"*, double, i32, i32, i32, i64, i32, [128 x i64], %"struct.std::__1::atomic.19", i64, i8, %"struct.std::__1::atomic.19", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.std::__1::vector.165", %"class.std::__1::vector.165", i64 ()*, [113 x i32], i64, double, double, i64, i64, double, i32, i32, i32, i32, double, double, double, %"class.std::__1::unique_ptr.172", %"class.std::__1::unique_ptr.178", %"class.v8::internal::MinorMarkCompactCollector"*, %"class.std::__1::unique_ptr.308", %"class.std::__1::unique_ptr.314", %"class.std::__1::unique_ptr.320", %"class.std::__1::unique_ptr.359", %"class.std::__1::unique_ptr.398", %"class.std::__1::unique_ptr.428", %"class.std::__1::unique_ptr.434", %"class.std::__1::unique_ptr.444", %"class.std::__1::unique_ptr.450", %"class.std::__1::unique_ptr.450", %"class.std::__1::unique_ptr.456", %"class.std::__1::unique_ptr.462", %"class.std::__1::unique_ptr.462", %"class.std::__1::unique_ptr.468", %"class.std::__1::unique_ptr.474", %"class.std::__1::shared_ptr.480", %"class.v8::CppHeap"*, %"class.v8::EmbedderRootsHandler"*, %"class.v8::internal::StrongRootsEntry"*, %"class.v8::base::Mutex", i8, i64, i64, i64, i64, %"class.std::__1::unordered_map.503", %"class.std::__1::unique_ptr.529", [512 x i8], i8, i8, i64, i8, i32, i32, %"class.std::__1::unique_ptr.535", i8, %"class.v8::internal::Heap::ExternalStringTable", %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.548", i32, i8, i8, i8, i8, i8, %"class.v8::internal::HeapObject", %"class.v8::base::SharedMutex", %"class.v8::base::Mutex", %"class.std::__1::unordered_set.330", i8, [7 x i8], %"class.std::__1::unordered_map.554", %"class.std::__1::unordered_map.580", %"class.std::__1::unordered_map.554", %"class.std::__1::unordered_map.604", %"class.std::__1::vector.632", i8, %"class.std::__1::unique_ptr.639", i32, i32 }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr.2", %"class.std::__1::__compressed_pair.9", %"class.std::__1::__compressed_pair.14", %"class.std::__1::__compressed_pair.16", [4 x i8] }>
%"class.std::__1::unique_ptr.2" = type { %"class.std::__1::__compressed_pair.3" }
%"class.std::__1::__compressed_pair.3" = type { %"struct.std::__1::__compressed_pair_elem.4", %"struct.std::__1::__compressed_pair_elem.5" }
%"struct.std::__1::__compressed_pair_elem.4" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.5" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.6" }
%"class.std::__1::__compressed_pair.6" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::__compressed_pair_elem.7" = type { i64 }
%"class.std::__1::__compressed_pair.9" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"struct.std::__1::__compressed_pair_elem.10" = type { %"struct.std::__1::__hash_node_base" }
%"class.std::__1::__compressed_pair.14" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.16" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"struct.std::__1::__compressed_pair_elem.17" = type { float }
%"class.v8::internal::Heap::ExternalMemoryAccounting" = type { %"struct.std::__1::atomic.24", %"struct.std::__1::atomic.24", %"struct.std::__1::atomic.24" }
%"struct.std::__1::atomic.24" = type { %"struct.std::__1::__atomic_base.25" }
%"struct.std::__1::__atomic_base.25" = type { %"struct.std::__1::__atomic_base.26" }
%"struct.std::__1::__atomic_base.26" = type { %"struct.std::__1::__cxx_atomic_impl.27" }
%"struct.std::__1::__cxx_atomic_impl.27" = type { %"struct.std::__1::__cxx_atomic_base_impl.28" }
%"struct.std::__1::__cxx_atomic_base_impl.28" = type { i64 }
%"struct.std::__1::atomic.29" = type { %"struct.std::__1::__atomic_base.30" }
%"struct.std::__1::__atomic_base.30" = type { %"struct.std::__1::__cxx_atomic_impl.31" }
%"struct.std::__1::__cxx_atomic_impl.31" = type { %"struct.std::__1::__cxx_atomic_base_impl.32" }
%"struct.std::__1::__cxx_atomic_base_impl.32" = type { i32 }
%"class.std::__1::vector" = type { %"class.std::__1::__vector_base" }
%"class.std::__1::__vector_base" = type { %"struct.std::__1::pair"*, %"struct.std::__1::pair"*, %"class.std::__1::__compressed_pair.33" }
%"struct.std::__1::pair" = type opaque
%"class.std::__1::__compressed_pair.33" = type { %"struct.std::__1::__compressed_pair_elem.34" }
%"struct.std::__1::__compressed_pair_elem.34" = type { %"struct.std::__1::pair"* }
%"class.v8::internal::NewSpace" = type { %"class.v8::internal::SpaceWithLinearArea", %"class.v8::base::Mutex", %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace", %"class.v8::internal::VirtualMemory", %"class.std::__1::vector.103" }
%"class.v8::internal::SpaceWithLinearArea" = type { %"class.v8::internal::Space", %"class.v8::internal::LinearAllocationArea", [3 x i64] }
%"class.v8::internal::Space" = type { %"class.v8::internal::BaseSpace", %"class.v8::internal::AllocationCounter", %"class.v8::internal::heap::List", %"struct.std::__1::atomic.19"*, %"class.std::__1::unique_ptr.97" }
%"class.v8::internal::BaseSpace" = type { i32 (...)**, %"class.v8::internal::Heap"*, i32, %"struct.std::__1::atomic.19", i64 }
%"class.v8::internal::AllocationCounter" = type <{ %"class.std::__1::vector.38", %"class.std::__1::vector.38", %"class.std::__1::unordered_set", i8, [7 x i8], i64, i64, i8, [7 x i8] }>
%"class.std::__1::vector.38" = type { %"class.std::__1::__vector_base.39" }
%"class.std::__1::__vector_base.39" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"class.std::__1::__compressed_pair.40" }
%"struct.v8::internal::AllocationCounter::AllocationObserverCounter" = type { %"class.v8::internal::AllocationObserver"*, i64, i64 }
%"class.std::__1::__compressed_pair.40" = type { %"struct.std::__1::__compressed_pair_elem.41" }
%"struct.std::__1::__compressed_pair_elem.41" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* }
%"class.std::__1::unordered_set" = type { %"class.std::__1::__hash_table.45" }
%"class.std::__1::__hash_table.45" = type <{ %"class.std::__1::unique_ptr.46", %"class.std::__1::__compressed_pair.56", %"class.std::__1::__compressed_pair.61", %"class.std::__1::__compressed_pair.63", [4 x i8] }>
%"class.std::__1::unique_ptr.46" = type { %"class.std::__1::__compressed_pair.47" }
%"class.std::__1::__compressed_pair.47" = type { %"struct.std::__1::__compressed_pair_elem.48", %"struct.std::__1::__compressed_pair_elem.50" }
%"struct.std::__1::__compressed_pair_elem.48" = type { %"struct.std::__1::__hash_node_base.49"** }
%"struct.std::__1::__hash_node_base.49" = type { %"struct.std::__1::__hash_node_base.49"* }
%"struct.std::__1::__compressed_pair_elem.50" = type { %"class.std::__1::__bucket_list_deallocator.51" }
%"class.std::__1::__bucket_list_deallocator.51" = type { %"class.std::__1::__compressed_pair.52" }
%"class.std::__1::__compressed_pair.52" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.56" = type { %"struct.std::__1::__compressed_pair_elem.57" }
%"struct.std::__1::__compressed_pair_elem.57" = type { %"struct.std::__1::__hash_node_base.49" }
%"class.std::__1::__compressed_pair.61" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.63" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::internal::heap::List" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.v8::internal::MemoryChunk" = type { %"class.v8::internal::BasicMemoryChunk", [2 x %"class.v8::internal::SlotSet"*], %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.24", %"class.v8::internal::SlotSet"*, [2 x %"class.v8::internal::TypedSlotSet"*], [2 x %"class.std::__1::set"*], %"class.v8::base::Mutex"*, %"struct.std::__1::atomic.86", %"class.v8::base::Mutex"*, i64, [2 x %"struct.std::__1::atomic.19"], %"class.v8::internal::heap::ListNode", %"class.v8::internal::FreeListCategory"**, %"struct.std::__1::atomic.24", %"class.v8::internal::Bitmap"*, %"class.v8::internal::CodeObjectRegistry"*, %"class.v8::internal::PossiblyEmptyBuckets" }
%"class.v8::internal::BasicMemoryChunk" = type { i64, i64, %"class.v8::internal::Heap"*, i64, i64, i64, i64, %"struct.std::__1::atomic.24", %"struct.std::__1::atomic.68", %"class.v8::internal::VirtualMemory" }
%"struct.std::__1::atomic.68" = type { %"struct.std::__1::__atomic_base.69" }
%"struct.std::__1::__atomic_base.69" = type { %"struct.std::__1::__cxx_atomic_impl.70" }
%"struct.std::__1::__cxx_atomic_impl.70" = type { %"struct.std::__1::__cxx_atomic_base_impl.71" }
%"struct.std::__1::__cxx_atomic_base_impl.71" = type { %"class.v8::internal::BaseSpace"* }
%"class.v8::internal::SlotSet" = type { i8 }
%"class.v8::internal::TypedSlotSet" = type { %"class.v8::internal::TypedSlots", i64 }
%"class.v8::internal::TypedSlots" = type { i32 (...)**, %"struct.v8::internal::TypedSlots::Chunk"*, %"struct.v8::internal::TypedSlots::Chunk"* }
%"struct.v8::internal::TypedSlots::Chunk" = type { %"struct.v8::internal::TypedSlots::Chunk"*, %"class.std::__1::vector.72" }
%"class.std::__1::vector.72" = type { %"class.std::__1::__vector_base.73" }
%"class.std::__1::__vector_base.73" = type { %"struct.v8::internal::TypedSlots::TypedSlot"*, %"struct.v8::internal::TypedSlots::TypedSlot"*, %"class.std::__1::__compressed_pair.74" }
%"struct.v8::internal::TypedSlots::TypedSlot" = type { i32 }
%"class.std::__1::__compressed_pair.74" = type { %"struct.std::__1::__compressed_pair_elem.75" }
%"struct.std::__1::__compressed_pair_elem.75" = type { %"struct.v8::internal::TypedSlots::TypedSlot"* }
%"class.std::__1::set" = type { %"class.std::__1::__tree" }
%"class.std::__1::__tree" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.79", %"class.std::__1::__compressed_pair.84" }
%"class.std::__1::__tree_end_node" = type { %"class.std::__1::__tree_node_base"* }
%"class.std::__1::__tree_node_base" = type <{ %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_end_node"*, i8, [7 x i8] }>
%"class.std::__1::__compressed_pair.79" = type { %"struct.std::__1::__compressed_pair_elem.80" }
%"struct.std::__1::__compressed_pair_elem.80" = type { %"class.std::__1::__tree_end_node" }
%"class.std::__1::__compressed_pair.84" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::atomic.86" = type { %"struct.std::__1::__atomic_base.87" }
%"struct.std::__1::__atomic_base.87" = type { %"struct.std::__1::__cxx_atomic_impl.88" }
%"struct.std::__1::__cxx_atomic_impl.88" = type { %"struct.std::__1::__cxx_atomic_base_impl.89" }
%"struct.std::__1::__cxx_atomic_base_impl.89" = type { i64 }
%"class.v8::internal::heap::ListNode" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.v8::internal::FreeListCategory" = type { i32, i32, %"class.v8::internal::FreeSpace", %"class.v8::internal::FreeListCategory"*, %"class.v8::internal::FreeListCategory"* }
%"class.v8::internal::FreeSpace" = type { %"class.v8::internal::TorqueGeneratedFreeSpace" }
%"class.v8::internal::TorqueGeneratedFreeSpace" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Bitmap" = type { i8 }
%"class.v8::internal::CodeObjectRegistry" = type <{ %"class.std::__1::vector.90", i8, [7 x i8] }>
%"class.std::__1::vector.90" = type { %"class.std::__1::__vector_base.91" }
%"class.std::__1::__vector_base.91" = type { i64*, i64*, %"class.std::__1::__compressed_pair.92" }
%"class.std::__1::__compressed_pair.92" = type { %"struct.std::__1::__compressed_pair_elem.93" }
%"struct.std::__1::__compressed_pair_elem.93" = type { i64* }
%"class.v8::internal::PossiblyEmptyBuckets" = type { i64 }
%"class.std::__1::unique_ptr.97" = type { %"class.std::__1::__compressed_pair.98" }
%"class.std::__1::__compressed_pair.98" = type { %"struct.std::__1::__compressed_pair_elem.99" }
%"struct.std::__1::__compressed_pair_elem.99" = type { %"class.v8::internal::FreeList"* }
%"class.v8::internal::FreeList" = type { i32 (...)**, i32, i32, i64, %"struct.std::__1::atomic.19", %"class.v8::internal::FreeListCategory"**, i64 }
%"class.v8::internal::LinearAllocationArea" = type { i64, i64, i64 }
%"class.v8::internal::SemiSpace" = type { %"class.v8::internal::Space", i64, i64, i64, i64, i64, i32, %"class.v8::internal::Page"* }
%"class.v8::internal::Page" = type { %"class.v8::internal::MemoryChunk" }
%"class.v8::internal::VirtualMemory" = type { %"class.v8::PageAllocator"*, %"class.v8::base::AddressRegion" }
%"class.v8::base::AddressRegion" = type { i64, i64 }
%"class.std::__1::vector.103" = type { %"class.std::__1::__vector_base.104" }
%"class.std::__1::__vector_base.104" = type { %"struct.std::__1::pair.105"*, %"struct.std::__1::pair.105"*, %"class.std::__1::__compressed_pair.106" }
%"struct.std::__1::pair.105" = type { i32, i64 }
%"class.std::__1::__compressed_pair.106" = type { %"struct.std::__1::__compressed_pair_elem.107" }
%"struct.std::__1::__compressed_pair_elem.107" = type { %"struct.std::__1::pair.105"* }
%"class.v8::internal::CodeSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::PagedSpace" = type { %"class.v8::internal::SpaceWithLinearArea", i32, i32, i64, %"class.v8::internal::AllocationStats", %"class.v8::base::Mutex", i64, i64 }
%"class.v8::internal::AllocationStats" = type { %"struct.std::__1::atomic.19", i64, %"struct.std::__1::atomic.19" }
%"class.v8::internal::OldLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace" }
%"class.v8::internal::LargeObjectSpace" = type { %"class.v8::internal::Space", %"struct.std::__1::atomic.19", i32, %"struct.std::__1::atomic.19", %"class.v8::base::Mutex", %"struct.std::__1::atomic.19" }
%"class.v8::internal::CodeLargeObjectSpace" = type { %"class.v8::internal::OldLargeObjectSpace", %"class.std::__1::unordered_map.111" }
%"class.std::__1::unordered_map.111" = type { %"class.std::__1::__hash_table.112" }
%"class.std::__1::__hash_table.112" = type <{ %"class.std::__1::unique_ptr.113", %"class.std::__1::__compressed_pair.123", %"class.std::__1::__compressed_pair.128", %"class.std::__1::__compressed_pair.133", [4 x i8] }>
%"class.std::__1::unique_ptr.113" = type { %"class.std::__1::__compressed_pair.114" }
%"class.std::__1::__compressed_pair.114" = type { %"struct.std::__1::__compressed_pair_elem.115", %"struct.std::__1::__compressed_pair_elem.117" }
%"struct.std::__1::__compressed_pair_elem.115" = type { %"struct.std::__1::__hash_node_base.116"** }
%"struct.std::__1::__hash_node_base.116" = type { %"struct.std::__1::__hash_node_base.116"* }
%"struct.std::__1::__compressed_pair_elem.117" = type { %"class.std::__1::__bucket_list_deallocator.118" }
%"class.std::__1::__bucket_list_deallocator.118" = type { %"class.std::__1::__compressed_pair.119" }
%"class.std::__1::__compressed_pair.119" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.123" = type { %"struct.std::__1::__compressed_pair_elem.124" }
%"struct.std::__1::__compressed_pair_elem.124" = type { %"struct.std::__1::__hash_node_base.116" }
%"class.std::__1::__compressed_pair.128" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.133" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::internal::NewLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace", i64 }
%"class.v8::internal::ReadOnlySpace" = type { %"class.v8::internal::BaseSpace", i8, %"class.v8::internal::AllocationStats", %"class.std::__1::vector.139", i64, i64, i8, i64, i64 }
%"class.std::__1::vector.139" = type { %"class.std::__1::__vector_base.140" }
%"class.std::__1::__vector_base.140" = type { %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"**, %"class.std::__1::__compressed_pair.141" }
%"class.v8::internal::ReadOnlyPage" = type { %"class.v8::internal::BasicMemoryChunk" }
%"class.std::__1::__compressed_pair.141" = type { %"struct.std::__1::__compressed_pair_elem.142" }
%"struct.std::__1::__compressed_pair_elem.142" = type { %"class.v8::internal::ReadOnlyPage"** }
%"class.v8::internal::OldSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::MapSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.std::__1::unique_ptr.146" = type { %"class.std::__1::__compressed_pair.147" }
%"class.std::__1::__compressed_pair.147" = type { %"struct.std::__1::__compressed_pair_elem.148" }
%"struct.std::__1::__compressed_pair_elem.148" = type { %"class.v8::internal::ConcurrentAllocator"* }
%"class.v8::internal::ConcurrentAllocator" = type { %"class.v8::internal::LocalHeap"*, %"class.v8::internal::PagedSpace"*, %"class.v8::internal::LocalAllocationBuffer" }
%"class.v8::internal::LocalAllocationBuffer" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::LinearAllocationArea" }
%"class.v8::internal::LocalHeap" = type { %"class.v8::internal::Heap"*, i8, %"struct.std::__1::atomic.1087", i8, i8, %"class.v8::internal::LocalHeap"*, %"class.v8::internal::LocalHeap"*, %"class.std::__1::unique_ptr.1091", %"class.std::__1::unique_ptr.787", %"class.std::__1::unique_ptr.474", %"class.std::__1::vector.1097", %"class.v8::internal::ConcurrentAllocator" }
%"struct.std::__1::atomic.1087" = type { %"struct.std::__1::__atomic_base.1088" }
%"struct.std::__1::__atomic_base.1088" = type { %"struct.std::__1::__cxx_atomic_impl.1089" }
%"struct.std::__1::__cxx_atomic_impl.1089" = type { %"struct.std::__1::__cxx_atomic_base_impl.1090" }
%"struct.std::__1::__cxx_atomic_base_impl.1090" = type { i32 }
%"class.std::__1::unique_ptr.1091" = type { %"class.std::__1::__compressed_pair.1092" }
%"class.std::__1::__compressed_pair.1092" = type { %"struct.std::__1::__compressed_pair_elem.1093" }
%"struct.std::__1::__compressed_pair_elem.1093" = type { %"class.v8::internal::LocalHandles"* }
%"class.v8::internal::LocalHandles" = type { %"struct.v8::internal::HandleScopeData", %"class.std::__1::vector.790" }
%"class.std::__1::vector.790" = type { %"class.std::__1::__vector_base.791" }
%"class.std::__1::__vector_base.791" = type { i64**, i64**, %"class.std::__1::__compressed_pair.792" }
%"class.std::__1::__compressed_pair.792" = type { %"struct.std::__1::__compressed_pair_elem.793" }
%"struct.std::__1::__compressed_pair_elem.793" = type { i64** }
%"class.std::__1::unique_ptr.787" = type { %"class.std::__1::__compressed_pair.788" }
%"class.std::__1::__compressed_pair.788" = type { %"struct.std::__1::__compressed_pair_elem.789" }
%"struct.std::__1::__compressed_pair_elem.789" = type { %"class.v8::internal::PersistentHandles"* }
%"class.v8::internal::PersistentHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::vector.790", i64*, i64*, %"class.v8::internal::PersistentHandles"*, %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.1097" = type { %"class.std::__1::__vector_base.1098" }
%"class.std::__1::__vector_base.1098" = type { %"struct.std::__1::pair.1099"*, %"struct.std::__1::pair.1099"*, %"class.std::__1::__compressed_pair.1100" }
%"struct.std::__1::pair.1099" = type opaque
%"class.std::__1::__compressed_pair.1100" = type { %"struct.std::__1::__compressed_pair_elem.1101" }
%"struct.std::__1::__compressed_pair_elem.1101" = type { %"struct.std::__1::pair.1099"* }
%"class.v8::internal::ArrayBufferExtension" = type { %"struct.std::__1::atomic.152", %"struct.std::__1::atomic.156", %"class.std::__1::shared_ptr", %"class.v8::internal::ArrayBufferExtension"*, %"struct.std::__1::atomic.19" }
%"struct.std::__1::atomic.156" = type { %"struct.std::__1::__atomic_base.157" }
%"struct.std::__1::__atomic_base.157" = type { %"struct.std::__1::__cxx_atomic_impl.158" }
%"struct.std::__1::__cxx_atomic_impl.158" = type { %"struct.std::__1::__cxx_atomic_base_impl.159" }
%"struct.std::__1::__cxx_atomic_base_impl.159" = type { i8 }
%"class.std::__1::shared_ptr" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::BackingStore" = type <{ i8*, %"struct.std::__1::atomic.19", i64, %"union.v8::internal::BackingStore::TypeSpecificData", i16, [6 x i8] }>
%"union.v8::internal::BackingStore::TypeSpecificData" = type { %"class.std::__1::shared_ptr.160" }
%"class.std::__1::__shared_weak_count" = type { %"class.std::__1::__shared_count", i64 }
%"class.std::__1::__shared_count" = type { i32 (...)**, i64 }
%"struct.std::__1::atomic.161" = type { %"struct.std::__1::__atomic_base.162" }
%"struct.std::__1::__atomic_base.162" = type { %"struct.std::__1::__cxx_atomic_impl.163" }
%"struct.std::__1::__cxx_atomic_impl.163" = type { %"struct.std::__1::__cxx_atomic_base_impl.164" }
%"struct.std::__1::__cxx_atomic_base_impl.164" = type { i32 }
%"class.v8::internal::AllocationObserver" = type { i32 (...)**, i64 }
%"class.v8::internal::StressScavengeObserver" = type opaque
%"struct.std::__1::atomic.19" = type { %"struct.std::__1::__atomic_base.20" }
%"struct.std::__1::__atomic_base.20" = type { %"struct.std::__1::__atomic_base.21" }
%"struct.std::__1::__atomic_base.21" = type { %"struct.std::__1::__cxx_atomic_impl.22" }
%"struct.std::__1::__cxx_atomic_impl.22" = type { %"struct.std::__1::__cxx_atomic_base_impl.23" }
%"struct.std::__1::__cxx_atomic_base_impl.23" = type { i64 }
%"class.std::__1::vector.165" = type { %"class.std::__1::__vector_base.166" }
%"class.std::__1::__vector_base.166" = type { %"struct.v8::internal::Heap::GCCallbackTuple"*, %"struct.v8::internal::Heap::GCCallbackTuple"*, %"class.std::__1::__compressed_pair.167" }
%"struct.v8::internal::Heap::GCCallbackTuple" = type { void (%"class.v8::Isolate"*, i32, i32, i8*)*, i32, i8* }
%"class.v8::Isolate" = type { i8 }
%"class.std::__1::__compressed_pair.167" = type { %"struct.std::__1::__compressed_pair_elem.168" }
%"struct.std::__1::__compressed_pair_elem.168" = type { %"struct.v8::internal::Heap::GCCallbackTuple"* }
%"class.std::__1::unique_ptr.172" = type { %"class.std::__1::__compressed_pair.173" }
%"class.std::__1::__compressed_pair.173" = type { %"struct.std::__1::__compressed_pair_elem.174" }
%"struct.std::__1::__compressed_pair_elem.174" = type { %"class.v8::internal::GCTracer"* }
%"class.v8::internal::GCTracer" = type opaque
%"class.std::__1::unique_ptr.178" = type { %"class.std::__1::__compressed_pair.179" }
%"class.std::__1::__compressed_pair.179" = type { %"struct.std::__1::__compressed_pair_elem.180" }
%"struct.std::__1::__compressed_pair_elem.180" = type { %"class.v8::internal::MarkCompactCollector"* }
%"class.v8::internal::MarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::base::Mutex", %"class.v8::base::Semaphore", i8, i8, i8, i8, i8, i8, [2 x i8], %"class.v8::internal::MarkingWorklists", %"class.v8::internal::WeakObjects", %"struct.v8::internal::EphemeronMarking", %"class.std::__1::unique_ptr.220", %"class.std::__1::unique_ptr.226", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", %"class.std::__1::vector.280", %"class.std::__1::vector.280", %"class.std::__1::vector.280", %"class.std::__1::vector.287", %"class.v8::internal::Sweeper"*, %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", [2 x i8], i32, i32, [4 x i8] }>
%"class.v8::internal::MarkCompactCollectorBase" = type { i32 (...)**, %"class.v8::internal::Heap"* }
%"class.v8::base::Semaphore" = type { %union.sem_t }
%union.sem_t = type { i64, [24 x i8] }
%"class.v8::internal::MarkingWorklists" = type { %"class.heap::base::Worklist", %"class.heap::base::Worklist", %"class.heap::base::Worklist.181", %"class.std::__1::vector.182", %"class.std::__1::vector.189", %"class.heap::base::Worklist" }
%"class.heap::base::Worklist.181" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment" = type opaque
%"class.std::__1::vector.182" = type { %"class.std::__1::__vector_base.183" }
%"class.std::__1::__vector_base.183" = type { %"struct.v8::internal::ContextWorklistPair"*, %"struct.v8::internal::ContextWorklistPair"*, %"class.std::__1::__compressed_pair.184" }
%"struct.v8::internal::ContextWorklistPair" = type { i64, %"class.heap::base::Worklist"* }
%"class.std::__1::__compressed_pair.184" = type { %"struct.std::__1::__compressed_pair_elem.185" }
%"struct.std::__1::__compressed_pair_elem.185" = type { %"struct.v8::internal::ContextWorklistPair"* }
%"class.std::__1::vector.189" = type { %"class.std::__1::__vector_base.190" }
%"class.std::__1::__vector_base.190" = type { %"class.std::__1::unique_ptr.191"*, %"class.std::__1::unique_ptr.191"*, %"class.std::__1::__compressed_pair.192" }
%"class.std::__1::unique_ptr.191" = type opaque
%"class.std::__1::__compressed_pair.192" = type { %"struct.std::__1::__compressed_pair_elem.193" }
%"struct.std::__1::__compressed_pair_elem.193" = type { %"class.std::__1::unique_ptr.191"* }
%"class.heap::base::Worklist" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment" = type opaque
%"class.v8::internal::WeakObjects" = type { %"class.v8::internal::Worklist", %"class.v8::internal::Worklist.197", %"class.v8::internal::Worklist.199", %"class.v8::internal::Worklist.199", %"class.v8::internal::Worklist.199", %"class.v8::internal::Worklist.201", %"class.v8::internal::Worklist.203", %"class.v8::internal::Worklist.205", %"class.v8::internal::Worklist.207", %"class.v8::internal::Worklist.209", %"class.v8::internal::Worklist.211" }
%"class.v8::internal::Worklist" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.197" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.199" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.201" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.203" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.205" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.207" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.209" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.211" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"struct.v8::internal::EphemeronMarking" = type { %"class.std::__1::vector.213", i8, i64 }
%"class.std::__1::vector.213" = type { %"class.std::__1::__vector_base.214" }
%"class.std::__1::__vector_base.214" = type { %"class.v8::internal::HeapObject"*, %"class.v8::internal::HeapObject"*, %"class.std::__1::__compressed_pair.215" }
%"class.std::__1::__compressed_pair.215" = type { %"struct.std::__1::__compressed_pair_elem.216" }
%"struct.std::__1::__compressed_pair_elem.216" = type { %"class.v8::internal::HeapObject"* }
%"class.std::__1::unique_ptr.220" = type { %"class.std::__1::__compressed_pair.221" }
%"class.std::__1::__compressed_pair.221" = type { %"struct.std::__1::__compressed_pair_elem.222" }
%"struct.std::__1::__compressed_pair_elem.222" = type { %"class.v8::internal::MainMarkingVisitor"* }
%"class.v8::internal::MainMarkingVisitor" = type opaque
%"class.std::__1::unique_ptr.226" = type { %"class.std::__1::__compressed_pair.227" }
%"class.std::__1::__compressed_pair.227" = type { %"struct.std::__1::__compressed_pair_elem.228" }
%"struct.std::__1::__compressed_pair_elem.228" = type { %"class.v8::internal::MarkingWorklists::Local"* }
%"class.v8::internal::MarkingWorklists::Local" = type { %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", i64, %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local"*, i8, [7 x i8], %"class.std::__1::unordered_map.229" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local" = type { %"class.heap::base::Worklist.181"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.heap::base::internal::SegmentBase" = type { i16, i16 }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local" = type { %"class.heap::base::Worklist"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.std::__1::unordered_map.229" = type { %"class.std::__1::__hash_table.230" }
%"class.std::__1::__hash_table.230" = type <{ %"class.std::__1::unique_ptr.231", %"class.std::__1::__compressed_pair.241", %"class.std::__1::__compressed_pair.246", %"class.std::__1::__compressed_pair.249", [4 x i8] }>
%"class.std::__1::unique_ptr.231" = type { %"class.std::__1::__compressed_pair.232" }
%"class.std::__1::__compressed_pair.232" = type { %"struct.std::__1::__compressed_pair_elem.233", %"struct.std::__1::__compressed_pair_elem.235" }
%"struct.std::__1::__compressed_pair_elem.233" = type { %"struct.std::__1::__hash_node_base.234"** }
%"struct.std::__1::__hash_node_base.234" = type { %"struct.std::__1::__hash_node_base.234"* }
%"struct.std::__1::__compressed_pair_elem.235" = type { %"class.std::__1::__bucket_list_deallocator.236" }
%"class.std::__1::__bucket_list_deallocator.236" = type { %"class.std::__1::__compressed_pair.237" }
%"class.std::__1::__compressed_pair.237" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.241" = type { %"struct.std::__1::__compressed_pair_elem.242" }
%"struct.std::__1::__compressed_pair_elem.242" = type { %"struct.std::__1::__hash_node_base.234" }
%"class.std::__1::__compressed_pair.246" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.249" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::internal::NativeContextInferrer" = type { i8 }
%"class.v8::internal::NativeContextStats" = type { %"class.std::__1::unordered_map.256" }
%"class.std::__1::unordered_map.256" = type { %"class.std::__1::__hash_table.257" }
%"class.std::__1::__hash_table.257" = type <{ %"class.std::__1::unique_ptr.258", %"class.std::__1::__compressed_pair.268", %"class.std::__1::__compressed_pair.273", %"class.std::__1::__compressed_pair.276", [4 x i8] }>
%"class.std::__1::unique_ptr.258" = type { %"class.std::__1::__compressed_pair.259" }
%"class.std::__1::__compressed_pair.259" = type { %"struct.std::__1::__compressed_pair_elem.260", %"struct.std::__1::__compressed_pair_elem.262" }
%"struct.std::__1::__compressed_pair_elem.260" = type { %"struct.std::__1::__hash_node_base.261"** }
%"struct.std::__1::__hash_node_base.261" = type { %"struct.std::__1::__hash_node_base.261"* }
%"struct.std::__1::__compressed_pair_elem.262" = type { %"class.std::__1::__bucket_list_deallocator.263" }
%"class.std::__1::__bucket_list_deallocator.263" = type { %"class.std::__1::__compressed_pair.264" }
%"class.std::__1::__compressed_pair.264" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.268" = type { %"struct.std::__1::__compressed_pair_elem.269" }
%"struct.std::__1::__compressed_pair_elem.269" = type { %"struct.std::__1::__hash_node_base.261" }
%"class.std::__1::__compressed_pair.273" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.276" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::vector.280" = type { %"class.std::__1::__vector_base.281" }
%"class.std::__1::__vector_base.281" = type { %"class.v8::internal::Page"**, %"class.v8::internal::Page"**, %"class.std::__1::__compressed_pair.282" }
%"class.std::__1::__compressed_pair.282" = type { %"struct.std::__1::__compressed_pair_elem.283" }
%"struct.std::__1::__compressed_pair_elem.283" = type { %"class.v8::internal::Page"** }
%"class.std::__1::vector.287" = type { %"class.std::__1::__vector_base.288" }
%"class.std::__1::__vector_base.288" = type { %"struct.std::__1::pair.289"*, %"struct.std::__1::pair.289"*, %"class.std::__1::__compressed_pair.290" }
%"struct.std::__1::pair.289" = type opaque
%"class.std::__1::__compressed_pair.290" = type { %"struct.std::__1::__compressed_pair_elem.291" }
%"struct.std::__1::__compressed_pair_elem.291" = type { %"struct.std::__1::pair.289"* }
%"class.v8::internal::Sweeper" = type <{ %"class.v8::internal::Heap"*, %"class.v8::internal::MajorNonAtomicMarkingState"*, %"class.std::__1::unique_ptr.295", %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.280"], [3 x %"class.std::__1::vector.280"], i8, %"struct.std::__1::atomic.152", [6 x i8], %"class.std::__1::vector.280", i64, %"class.v8::base::Semaphore", i8, i8, i8, [5 x i8] }>
%"class.std::__1::unique_ptr.295" = type { %"class.std::__1::__compressed_pair.296" }
%"class.std::__1::__compressed_pair.296" = type { %"struct.std::__1::__compressed_pair_elem.297" }
%"struct.std::__1::__compressed_pair_elem.297" = type { %"class.v8::JobHandle"* }
%"class.v8::JobHandle" = type { i32 (...)** }
%"class.v8::internal::MajorMarkingState" = type { i8 }
%"class.v8::internal::MajorNonAtomicMarkingState" = type { i8 }
%"class.v8::internal::MinorMarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::internal::Worklist.305"*, %"class.v8::internal::YoungGenerationMarkingVisitor"*, %"class.v8::base::Semaphore", %"class.std::__1::vector.280", %"class.std::__1::vector.280", %"class.v8::internal::MinorMarkingState", %"class.v8::internal::MinorNonAtomicMarkingState", [6 x i8] }>
%"class.v8::internal::Worklist.305" = type opaque
%"class.v8::internal::YoungGenerationMarkingVisitor" = type opaque
%"class.v8::internal::MinorMarkingState" = type { i8 }
%"class.v8::internal::MinorNonAtomicMarkingState" = type { i8 }
%"class.std::__1::unique_ptr.308" = type { %"class.std::__1::__compressed_pair.309" }
%"class.std::__1::__compressed_pair.309" = type { %"struct.std::__1::__compressed_pair_elem.310" }
%"struct.std::__1::__compressed_pair_elem.310" = type { %"class.v8::internal::ScavengerCollector"* }
%"class.v8::internal::ScavengerCollector" = type opaque
%"class.std::__1::unique_ptr.314" = type { %"class.std::__1::__compressed_pair.315" }
%"class.std::__1::__compressed_pair.315" = type { %"struct.std::__1::__compressed_pair_elem.316" }
%"struct.std::__1::__compressed_pair_elem.316" = type { %"class.v8::internal::ArrayBufferSweeper"* }
%"class.v8::internal::ArrayBufferSweeper" = type opaque
%"class.std::__1::unique_ptr.320" = type { %"class.std::__1::__compressed_pair.321" }
%"class.std::__1::__compressed_pair.321" = type { %"struct.std::__1::__compressed_pair_elem.322" }
%"struct.std::__1::__compressed_pair_elem.322" = type { %"class.v8::internal::MemoryAllocator"* }
%"class.v8::internal::MemoryAllocator" = type { %"class.v8::internal::Isolate"*, %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"*, i64, %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"class.v8::internal::VirtualMemory", %"class.v8::internal::MemoryAllocator::Unmapper", %"class.std::__1::unordered_set.330", %"class.v8::base::Mutex" }
%"class.v8::internal::MemoryAllocator::Unmapper" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MemoryAllocator"*, %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.323"], %"class.std::__1::unique_ptr.295" }
%"class.std::__1::vector.323" = type { %"class.std::__1::__vector_base.324" }
%"class.std::__1::__vector_base.324" = type { %"class.v8::internal::MemoryChunk"**, %"class.v8::internal::MemoryChunk"**, %"class.std::__1::__compressed_pair.325" }
%"class.std::__1::__compressed_pair.325" = type { %"struct.std::__1::__compressed_pair_elem.326" }
%"struct.std::__1::__compressed_pair_elem.326" = type { %"class.v8::internal::MemoryChunk"** }
%"class.std::__1::unique_ptr.359" = type { %"class.std::__1::__compressed_pair.360" }
%"class.std::__1::__compressed_pair.360" = type { %"struct.std::__1::__compressed_pair_elem.361" }
%"struct.std::__1::__compressed_pair_elem.361" = type { %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::IncrementalMarking" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MarkCompactCollector"*, %"class.v8::internal::WeakObjects"*, double, double, i64, i64, i64, i64, double, i64, %"struct.std::__1::atomic.362", i8, i8, i8, i8, [3 x i8], %"class.v8::internal::IncrementalMarkingJob", %"struct.std::__1::atomic.366", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorAtomicMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", %"class.v8::base::Mutex", %"class.std::__1::unordered_map.371" }
%"struct.std::__1::atomic.362" = type { %"struct.std::__1::__atomic_base.363" }
%"struct.std::__1::__atomic_base.363" = type { %"struct.std::__1::__cxx_atomic_impl.364" }
%"struct.std::__1::__cxx_atomic_impl.364" = type { %"struct.std::__1::__cxx_atomic_base_impl.365" }
%"struct.std::__1::__cxx_atomic_base_impl.365" = type { i8 }
%"class.v8::internal::IncrementalMarkingJob" = type <{ %"class.v8::base::Mutex", double, i8, i8, [6 x i8] }>
%"struct.std::__1::atomic.366" = type { %"struct.std::__1::__atomic_base.367" }
%"struct.std::__1::__atomic_base.367" = type { %"struct.std::__1::__cxx_atomic_impl.368" }
%"struct.std::__1::__cxx_atomic_impl.368" = type { %"struct.std::__1::__cxx_atomic_base_impl.369" }
%"struct.std::__1::__cxx_atomic_base_impl.369" = type { i32 }
%"class.v8::internal::IncrementalMarking::Observer" = type { %"class.v8::internal::AllocationObserver", %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::MajorAtomicMarkingState" = type { i8 }
%"class.std::__1::unordered_map.371" = type { %"class.std::__1::__hash_table.372" }
%"class.std::__1::__hash_table.372" = type <{ %"class.std::__1::unique_ptr.373", %"class.std::__1::__compressed_pair.383", %"class.std::__1::__compressed_pair.388", %"class.std::__1::__compressed_pair.391", [4 x i8] }>
%"class.std::__1::unique_ptr.373" = type { %"class.std::__1::__compressed_pair.374" }
%"class.std::__1::__compressed_pair.374" = type { %"struct.std::__1::__compressed_pair_elem.375", %"struct.std::__1::__compressed_pair_elem.377" }
%"struct.std::__1::__compressed_pair_elem.375" = type { %"struct.std::__1::__hash_node_base.376"** }
%"struct.std::__1::__hash_node_base.376" = type { %"struct.std::__1::__hash_node_base.376"* }
%"struct.std::__1::__compressed_pair_elem.377" = type { %"class.std::__1::__bucket_list_deallocator.378" }
%"class.std::__1::__bucket_list_deallocator.378" = type { %"class.std::__1::__compressed_pair.379" }
%"class.std::__1::__compressed_pair.379" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.383" = type { %"struct.std::__1::__compressed_pair_elem.384" }
%"struct.std::__1::__compressed_pair_elem.384" = type { %"struct.std::__1::__hash_node_base.376" }
%"class.std::__1::__compressed_pair.388" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.391" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unique_ptr.398" = type { %"class.std::__1::__compressed_pair.399" }
%"class.std::__1::__compressed_pair.399" = type { %"struct.std::__1::__compressed_pair_elem.400" }
%"struct.std::__1::__compressed_pair_elem.400" = type { %"class.v8::internal::ConcurrentMarking"* }
%"class.v8::internal::ConcurrentMarking" = type <{ %"class.std::__1::unique_ptr.295", %"class.v8::internal::Heap"*, %"class.v8::internal::MarkingWorklists"*, %"class.v8::internal::WeakObjects"*, [8 x %"struct.v8::internal::ConcurrentMarking::TaskState"], %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.152", [7 x i8] }>
%"struct.v8::internal::ConcurrentMarking::TaskState" = type { i64, %"class.std::__1::unordered_map.401", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", [64 x i8] }
%"class.std::__1::unordered_map.401" = type { %"class.std::__1::__hash_table.402" }
%"class.std::__1::__hash_table.402" = type <{ %"class.std::__1::unique_ptr.403", %"class.std::__1::__compressed_pair.413", %"class.std::__1::__compressed_pair.418", %"class.std::__1::__compressed_pair.421", [4 x i8] }>
%"class.std::__1::unique_ptr.403" = type { %"class.std::__1::__compressed_pair.404" }
%"class.std::__1::__compressed_pair.404" = type { %"struct.std::__1::__compressed_pair_elem.405", %"struct.std::__1::__compressed_pair_elem.407" }
%"struct.std::__1::__compressed_pair_elem.405" = type { %"struct.std::__1::__hash_node_base.406"** }
%"struct.std::__1::__hash_node_base.406" = type { %"struct.std::__1::__hash_node_base.406"* }
%"struct.std::__1::__compressed_pair_elem.407" = type { %"class.std::__1::__bucket_list_deallocator.408" }
%"class.std::__1::__bucket_list_deallocator.408" = type { %"class.std::__1::__compressed_pair.409" }
%"class.std::__1::__compressed_pair.409" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.413" = type { %"struct.std::__1::__compressed_pair_elem.414" }
%"struct.std::__1::__compressed_pair_elem.414" = type { %"struct.std::__1::__hash_node_base.406" }
%"class.std::__1::__compressed_pair.418" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.421" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unique_ptr.428" = type { %"class.std::__1::__compressed_pair.429" }
%"class.std::__1::__compressed_pair.429" = type { %"struct.std::__1::__compressed_pair_elem.430" }
%"struct.std::__1::__compressed_pair_elem.430" = type { %"class.v8::internal::GCIdleTimeHandler"* }
%"class.v8::internal::GCIdleTimeHandler" = type opaque
%"class.std::__1::unique_ptr.434" = type { %"class.std::__1::__compressed_pair.435" }
%"class.std::__1::__compressed_pair.435" = type { %"struct.std::__1::__compressed_pair_elem.436" }
%"struct.std::__1::__compressed_pair_elem.436" = type { %"class.v8::internal::MemoryMeasurement"* }
%"class.v8::internal::MemoryMeasurement" = type { %"class.std::__1::list", %"class.std::__1::list", %"class.std::__1::list", %"class.v8::internal::Isolate"*, i8, i8, i8, %"class.v8::base::RandomNumberGenerator" }
%"class.std::__1::list" = type { %"class.std::__1::__list_imp" }
%"class.std::__1::__list_imp" = type { %"struct.std::__1::__list_node_base", %"class.std::__1::__compressed_pair.437" }
%"struct.std::__1::__list_node_base" = type { %"struct.std::__1::__list_node_base"*, %"struct.std::__1::__list_node_base"* }
%"class.std::__1::__compressed_pair.437" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.v8::base::RandomNumberGenerator" = type { i64, i64, i64 }
%"class.std::__1::unique_ptr.444" = type { %"class.std::__1::__compressed_pair.445" }
%"class.std::__1::__compressed_pair.445" = type { %"struct.std::__1::__compressed_pair_elem.446" }
%"struct.std::__1::__compressed_pair_elem.446" = type { %"class.v8::internal::MemoryReducer"* }
%"class.v8::internal::MemoryReducer" = type opaque
%"class.std::__1::unique_ptr.450" = type { %"class.std::__1::__compressed_pair.451" }
%"class.std::__1::__compressed_pair.451" = type { %"struct.std::__1::__compressed_pair_elem.452" }
%"struct.std::__1::__compressed_pair_elem.452" = type { %"class.v8::internal::ObjectStats"* }
%"class.v8::internal::ObjectStats" = type opaque
%"class.std::__1::unique_ptr.456" = type { %"class.std::__1::__compressed_pair.457" }
%"class.std::__1::__compressed_pair.457" = type { %"struct.std::__1::__compressed_pair_elem.458" }
%"struct.std::__1::__compressed_pair_elem.458" = type { %"class.v8::internal::ScavengeJob"* }
%"class.v8::internal::ScavengeJob" = type opaque
%"class.std::__1::unique_ptr.462" = type { %"class.std::__1::__compressed_pair.463" }
%"class.std::__1::__compressed_pair.463" = type { %"struct.std::__1::__compressed_pair_elem.464" }
%"struct.std::__1::__compressed_pair_elem.464" = type { %"class.v8::internal::AllocationObserver"* }
%"class.std::__1::unique_ptr.468" = type { %"class.std::__1::__compressed_pair.469" }
%"class.std::__1::__compressed_pair.469" = type { %"struct.std::__1::__compressed_pair_elem.470" }
%"struct.std::__1::__compressed_pair_elem.470" = type { %"class.v8::internal::LocalEmbedderHeapTracer"* }
%"class.v8::internal::LocalEmbedderHeapTracer" = type opaque
%"class.std::__1::unique_ptr.474" = type { %"class.std::__1::__compressed_pair.475" }
%"class.std::__1::__compressed_pair.475" = type { %"struct.std::__1::__compressed_pair_elem.476" }
%"struct.std::__1::__compressed_pair_elem.476" = type { %"class.v8::internal::MarkingBarrier"* }
%"class.v8::internal::MarkingBarrier" = type opaque
%"class.std::__1::shared_ptr.480" = type { %"class.v8::internal::CodeRange"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::CodeRange" = type { %"class.v8::internal::VirtualMemoryCage", %"struct.std::__1::atomic.499", %"class.v8::base::Mutex" }
%"class.v8::internal::VirtualMemoryCage" = type { i32 (...)**, i64, %"class.std::__1::unique_ptr.481", %"class.v8::internal::VirtualMemory" }
%"class.std::__1::unique_ptr.481" = type { %"class.std::__1::__compressed_pair.482" }
%"class.std::__1::__compressed_pair.482" = type { %"struct.std::__1::__compressed_pair_elem.483" }
%"struct.std::__1::__compressed_pair_elem.483" = type { %"class.v8::base::BoundedPageAllocator"* }
%"class.v8::base::BoundedPageAllocator" = type { %"class.v8::PageAllocator", %"class.v8::base::Mutex", i64, i64, %"class.v8::PageAllocator"*, %"class.v8::base::RegionAllocator" }
%"class.v8::base::RegionAllocator" = type { %"class.v8::base::RegionAllocator::Region", i64, i64, i64, i64, %"class.std::__1::set.484", %"class.std::__1::set.492" }
%"class.v8::base::RegionAllocator::Region" = type <{ %"class.v8::base::AddressRegion", i32, [4 x i8] }>
%"class.std::__1::set.484" = type { %"class.std::__1::__tree.485" }
%"class.std::__1::__tree.485" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.486", %"class.std::__1::__compressed_pair.490" }
%"class.std::__1::__compressed_pair.486" = type { %"struct.std::__1::__compressed_pair_elem.80" }
%"class.std::__1::__compressed_pair.490" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::set.492" = type { %"class.std::__1::__tree.493" }
%"class.std::__1::__tree.493" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.486", %"class.std::__1::__compressed_pair.494" }
%"class.std::__1::__compressed_pair.494" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::atomic.499" = type { %"struct.std::__1::__atomic_base.500" }
%"struct.std::__1::__atomic_base.500" = type { %"struct.std::__1::__cxx_atomic_impl.501" }
%"struct.std::__1::__cxx_atomic_impl.501" = type { %"struct.std::__1::__cxx_atomic_base_impl.502" }
%"struct.std::__1::__cxx_atomic_base_impl.502" = type { i8* }
%"class.v8::CppHeap" = type opaque
%"class.v8::EmbedderRootsHandler" = type { i32 (...)** }
%"class.v8::internal::StrongRootsEntry" = type { %"class.v8::internal::FullObjectSlot", %"class.v8::internal::FullObjectSlot", %"class.v8::internal::StrongRootsEntry"*, %"class.v8::internal::StrongRootsEntry"* }
%"class.v8::internal::FullObjectSlot" = type { %"class.v8::internal::SlotBase" }
%"class.v8::internal::SlotBase" = type { i64 }
%"class.std::__1::unordered_map.503" = type { %"class.std::__1::__hash_table.504" }
%"class.std::__1::__hash_table.504" = type <{ %"class.std::__1::unique_ptr.505", %"class.std::__1::__compressed_pair.515", %"class.std::__1::__compressed_pair.520", %"class.std::__1::__compressed_pair.523", [4 x i8] }>
%"class.std::__1::unique_ptr.505" = type { %"class.std::__1::__compressed_pair.506" }
%"class.std::__1::__compressed_pair.506" = type { %"struct.std::__1::__compressed_pair_elem.507", %"struct.std::__1::__compressed_pair_elem.509" }
%"struct.std::__1::__compressed_pair_elem.507" = type { %"struct.std::__1::__hash_node_base.508"** }
%"struct.std::__1::__hash_node_base.508" = type { %"struct.std::__1::__hash_node_base.508"* }
%"struct.std::__1::__compressed_pair_elem.509" = type { %"class.std::__1::__bucket_list_deallocator.510" }
%"class.std::__1::__bucket_list_deallocator.510" = type { %"class.std::__1::__compressed_pair.511" }
%"class.std::__1::__compressed_pair.511" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.515" = type { %"struct.std::__1::__compressed_pair_elem.516" }
%"struct.std::__1::__compressed_pair_elem.516" = type { %"struct.std::__1::__hash_node_base.508" }
%"class.std::__1::__compressed_pair.520" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.523" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unique_ptr.529" = type { %"class.std::__1::__compressed_pair.530" }
%"class.std::__1::__compressed_pair.530" = type { %"struct.std::__1::__compressed_pair_elem.531" }
%"struct.std::__1::__compressed_pair_elem.531" = type { %"class.v8::internal::GlobalHandleVector"* }
%"class.v8::internal::GlobalHandleVector" = type opaque
%"class.std::__1::unique_ptr.535" = type { %"class.std::__1::__compressed_pair.536" }
%"class.std::__1::__compressed_pair.536" = type { %"struct.std::__1::__compressed_pair_elem.537" }
%"struct.std::__1::__compressed_pair_elem.537" = type { %"class.v8::internal::GlobalSafepoint"* }
%"class.v8::internal::GlobalSafepoint" = type opaque
%"class.v8::internal::Heap::ExternalStringTable" = type { %"class.v8::internal::Heap"*, %"class.std::__1::vector.541", %"class.std::__1::vector.541" }
%"class.std::__1::unique_ptr.548" = type { %"class.std::__1::__compressed_pair.549" }
%"class.std::__1::__compressed_pair.549" = type { %"struct.std::__1::__compressed_pair_elem.550" }
%"struct.std::__1::__compressed_pair_elem.550" = type { %"class.v8::internal::CollectionBarrier"* }
%"class.v8::internal::CollectionBarrier" = type opaque
%"class.std::__1::unordered_set.330" = type { %"class.std::__1::__hash_table.331" }
%"class.std::__1::__hash_table.331" = type <{ %"class.std::__1::unique_ptr.332", %"class.std::__1::__compressed_pair.342", %"class.std::__1::__compressed_pair.347", %"class.std::__1::__compressed_pair.351", [4 x i8] }>
%"class.std::__1::unique_ptr.332" = type { %"class.std::__1::__compressed_pair.333" }
%"class.std::__1::__compressed_pair.333" = type { %"struct.std::__1::__compressed_pair_elem.334", %"struct.std::__1::__compressed_pair_elem.336" }
%"struct.std::__1::__compressed_pair_elem.334" = type { %"struct.std::__1::__hash_node_base.335"** }
%"struct.std::__1::__hash_node_base.335" = type { %"struct.std::__1::__hash_node_base.335"* }
%"struct.std::__1::__compressed_pair_elem.336" = type { %"class.std::__1::__bucket_list_deallocator.337" }
%"class.std::__1::__bucket_list_deallocator.337" = type { %"class.std::__1::__compressed_pair.338" }
%"class.std::__1::__compressed_pair.338" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.342" = type { %"struct.std::__1::__compressed_pair_elem.343" }
%"struct.std::__1::__compressed_pair_elem.343" = type { %"struct.std::__1::__hash_node_base.335" }
%"class.std::__1::__compressed_pair.347" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.351" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unordered_map.580" = type { %"class.std::__1::__hash_table.581" }
%"class.std::__1::__hash_table.581" = type <{ %"class.std::__1::unique_ptr.582", %"class.std::__1::__compressed_pair.592", %"class.std::__1::__compressed_pair.597", %"class.std::__1::__compressed_pair.600", [4 x i8] }>
%"class.std::__1::unique_ptr.582" = type { %"class.std::__1::__compressed_pair.583" }
%"class.std::__1::__compressed_pair.583" = type { %"struct.std::__1::__compressed_pair_elem.584", %"struct.std::__1::__compressed_pair_elem.586" }
%"struct.std::__1::__compressed_pair_elem.584" = type { %"struct.std::__1::__hash_node_base.585"** }
%"struct.std::__1::__hash_node_base.585" = type { %"struct.std::__1::__hash_node_base.585"* }
%"struct.std::__1::__compressed_pair_elem.586" = type { %"class.std::__1::__bucket_list_deallocator.587" }
%"class.std::__1::__bucket_list_deallocator.587" = type { %"class.std::__1::__compressed_pair.588" }
%"class.std::__1::__compressed_pair.588" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.592" = type { %"struct.std::__1::__compressed_pair_elem.593" }
%"struct.std::__1::__compressed_pair_elem.593" = type { %"struct.std::__1::__hash_node_base.585" }
%"class.std::__1::__compressed_pair.597" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.600" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unordered_map.554" = type { %"class.std::__1::__hash_table.555" }
%"class.std::__1::__hash_table.555" = type <{ %"class.std::__1::unique_ptr.556", %"class.std::__1::__compressed_pair.566", %"class.std::__1::__compressed_pair.571", %"class.std::__1::__compressed_pair.574", [4 x i8] }>
%"class.std::__1::unique_ptr.556" = type { %"class.std::__1::__compressed_pair.557" }
%"class.std::__1::__compressed_pair.557" = type { %"struct.std::__1::__compressed_pair_elem.558", %"struct.std::__1::__compressed_pair_elem.560" }
%"struct.std::__1::__compressed_pair_elem.558" = type { %"struct.std::__1::__hash_node_base.559"** }
%"struct.std::__1::__hash_node_base.559" = type { %"struct.std::__1::__hash_node_base.559"* }
%"struct.std::__1::__compressed_pair_elem.560" = type { %"class.std::__1::__bucket_list_deallocator.561" }
%"class.std::__1::__bucket_list_deallocator.561" = type { %"class.std::__1::__compressed_pair.562" }
%"class.std::__1::__compressed_pair.562" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.566" = type { %"struct.std::__1::__compressed_pair_elem.567" }
%"struct.std::__1::__compressed_pair_elem.567" = type { %"struct.std::__1::__hash_node_base.559" }
%"class.std::__1::__compressed_pair.571" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.574" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unordered_map.604" = type { %"class.std::__1::__hash_table.605" }
%"class.std::__1::__hash_table.605" = type <{ %"class.std::__1::unique_ptr.606", %"class.std::__1::__compressed_pair.616", %"class.std::__1::__compressed_pair.621", %"class.std::__1::__compressed_pair.626", [4 x i8] }>
%"class.std::__1::unique_ptr.606" = type { %"class.std::__1::__compressed_pair.607" }
%"class.std::__1::__compressed_pair.607" = type { %"struct.std::__1::__compressed_pair_elem.608", %"struct.std::__1::__compressed_pair_elem.610" }
%"struct.std::__1::__compressed_pair_elem.608" = type { %"struct.std::__1::__hash_node_base.609"** }
%"struct.std::__1::__hash_node_base.609" = type { %"struct.std::__1::__hash_node_base.609"* }
%"struct.std::__1::__compressed_pair_elem.610" = type { %"class.std::__1::__bucket_list_deallocator.611" }
%"class.std::__1::__bucket_list_deallocator.611" = type { %"class.std::__1::__compressed_pair.612" }
%"class.std::__1::__compressed_pair.612" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.616" = type { %"struct.std::__1::__compressed_pair_elem.617" }
%"struct.std::__1::__compressed_pair_elem.617" = type { %"struct.std::__1::__hash_node_base.609" }
%"class.std::__1::__compressed_pair.621" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.626" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::vector.632" = type { %"class.std::__1::__vector_base.633" }
%"class.std::__1::__vector_base.633" = type { %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.std::__1::__compressed_pair.634" }
%"class.v8::internal::HeapObjectAllocationTracker" = type { i32 (...)** }
%"class.std::__1::__compressed_pair.634" = type { %"struct.std::__1::__compressed_pair_elem.635" }
%"struct.std::__1::__compressed_pair_elem.635" = type { %"class.v8::internal::HeapObjectAllocationTracker"** }
%"class.std::__1::unique_ptr.639" = type { %"class.std::__1::__compressed_pair.640" }
%"class.std::__1::__compressed_pair.640" = type { %"struct.std::__1::__compressed_pair_elem.641" }
%"struct.std::__1::__compressed_pair_elem.641" = type { %"class.v8::internal::third_party_heap::Heap"* }
%"class.v8::internal::third_party_heap::Heap" = type { i8 }
%"class.v8::internal::ReadOnlyHeap" = type { i32 (...)**, i8, %"class.v8::internal::ReadOnlySpace"*, %"class.std::__1::vector.541" }
%"class.std::__1::shared_ptr.645" = type { %"class.v8::internal::ReadOnlyArtifacts"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::ReadOnlyArtifacts" = type { i32 (...)**, %"class.std::__1::vector.139", %"class.v8::internal::AllocationStats", %"class.std::__1::unique_ptr.646", %"class.std::__1::unique_ptr.660" }
%"class.std::__1::unique_ptr.646" = type { %"class.std::__1::__compressed_pair.647" }
%"class.std::__1::__compressed_pair.647" = type { %"struct.std::__1::__compressed_pair_elem.648" }
%"struct.std::__1::__compressed_pair_elem.648" = type { %"class.v8::internal::SharedReadOnlySpace"* }
%"class.v8::internal::SharedReadOnlySpace" = type { %"class.v8::internal::ReadOnlySpace", %"class.std::__1::vector.649" }
%"class.std::__1::vector.649" = type { %"class.std::__1::__vector_base.650" }
%"class.std::__1::__vector_base.650" = type { %"class.std::__1::unique_ptr.651"*, %"class.std::__1::unique_ptr.651"*, %"class.std::__1::__compressed_pair.652" }
%"class.std::__1::unique_ptr.651" = type { %"class.std::__1::__compressed_pair.1188" }
%"class.std::__1::__compressed_pair.1188" = type { %"struct.std::__1::__compressed_pair_elem.1189" }
%"struct.std::__1::__compressed_pair_elem.1189" = type { %"class.v8::PageAllocator::SharedMemoryMapping"* }
%"class.v8::PageAllocator::SharedMemoryMapping" = type { i32 (...)** }
%"class.std::__1::__compressed_pair.652" = type { %"struct.std::__1::__compressed_pair_elem.653" }
%"struct.std::__1::__compressed_pair_elem.653" = type { %"class.std::__1::unique_ptr.651"* }
%"class.std::__1::unique_ptr.660" = type { %"class.std::__1::__compressed_pair.661" }
%"class.std::__1::__compressed_pair.661" = type { %"struct.std::__1::__compressed_pair_elem.662" }
%"struct.std::__1::__compressed_pair_elem.662" = type { %"class.v8::internal::ReadOnlyHeap"* }
%"class.std::__1::unique_ptr.666" = type { %"class.std::__1::__compressed_pair.667" }
%"class.std::__1::__compressed_pair.667" = type { %"struct.std::__1::__compressed_pair_elem.668" }
%"struct.std::__1::__compressed_pair_elem.668" = type { %"class.v8::internal::StringTable"* }
%"class.v8::internal::StringTable" = type { %"struct.std::__1::atomic.669", %"class.v8::base::Mutex" }
%"struct.std::__1::atomic.669" = type { %"struct.std::__1::__atomic_base.670" }
%"struct.std::__1::__atomic_base.670" = type { %"struct.std::__1::__cxx_atomic_impl.671" }
%"struct.std::__1::__cxx_atomic_impl.671" = type { %"struct.std::__1::__cxx_atomic_base_impl.672" }
%"struct.std::__1::__cxx_atomic_base_impl.672" = type { %"class.v8::internal::StringTable::Data"* }
%"class.v8::internal::StringTable::Data" = type opaque
%"class.v8::internal::Isolate::EntryStackItem" = type { i32, %"class.v8::internal::Isolate::PerIsolateThreadData"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate::EntryStackItem"* }
%"class.v8::internal::Isolate::PerIsolateThreadData" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::ThreadId", i64, %"class.v8::internal::ThreadState"* }
%"class.v8::internal::ThreadState" = type opaque
%"class.v8::internal::StringStream" = type opaque
%"class.v8::internal::Bootstrapper" = type { %"class.v8::internal::Isolate"*, i32, %"class.v8::internal::SourceCodeCache" }
%"class.v8::internal::SourceCodeCache" = type { i32, %"class.v8::internal::FixedArray" }
%"class.v8::internal::FixedArray" = type { %"class.v8::internal::TorqueGeneratedFixedArray" }
%"class.v8::internal::TorqueGeneratedFixedArray" = type { %"class.v8::internal::FixedArrayBase" }
%"class.v8::internal::FixedArrayBase" = type { %"class.v8::internal::TorqueGeneratedFixedArrayBase" }
%"class.v8::internal::TorqueGeneratedFixedArrayBase" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::RuntimeProfiler" = type opaque
%"class.v8::internal::CompilationCache" = type opaque
%"class.std::__1::shared_ptr.676" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::Counters" = type { %"class.std::__1::enable_shared_from_this", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::AggregatableHistogramTimer", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::RuntimeCallStats", %"class.v8::internal::WorkerThreadRuntimeCallStats", %"class.v8::internal::Isolate"*, %"class.v8::internal::StatsTable" }
%"class.std::__1::enable_shared_from_this" = type { %"class.std::__1::weak_ptr" }
%"class.std::__1::weak_ptr" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::HistogramTimer" = type { %"class.v8::internal::TimedHistogram.base", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::TimedHistogram.base" = type <{ %"class.v8::internal::Histogram", i32 }>
%"class.v8::base::ElapsedTimer" = type { %"class.v8::base::TimeTicks" }
%"class.v8::base::TimeTicks" = type { %"class.v8::base::time_internal::TimeBase" }
%"class.v8::base::time_internal::TimeBase" = type { i64 }
%"class.v8::internal::TimedHistogram" = type <{ %"class.v8::internal::Histogram", i32, [4 x i8] }>
%"class.v8::internal::AggregatableHistogramTimer" = type { %"class.v8::internal::Histogram", %"class.v8::base::TimeDelta" }
%"class.v8::base::TimeDelta" = type { i64 }
%"class.v8::internal::Histogram" = type { i8*, i32, i32, i32, i8*, %"class.v8::internal::Counters"* }
%"class.v8::internal::StatsCounterThreadSafe" = type { %"class.v8::internal::StatsCounterBase", %"class.v8::base::Mutex" }
%"class.v8::internal::StatsCounterBase" = type { %"class.v8::internal::Counters"*, i8*, i32* }
%"class.v8::internal::StatsCounter" = type <{ %"class.v8::internal::StatsCounterBase", i8, [7 x i8] }>
%"class.v8::internal::RuntimeCallStats" = type { %"class.v8::base::AtomicValue", %"class.v8::base::AtomicValue.677", i8, i32, %"class.v8::internal::ThreadId", [1370 x %"class.v8::internal::RuntimeCallCounter"] }
%"class.v8::base::AtomicValue" = type { i64 }
%"class.v8::base::AtomicValue.677" = type { i64 }
%"class.v8::internal::RuntimeCallCounter" = type { i8*, i64, i64 }
%"class.v8::internal::WorkerThreadRuntimeCallStats" = type <{ %"class.v8::base::Mutex", %"class.std::__1::vector.678", %"class.v8::base::Optional", %"class.v8::internal::ThreadId", [4 x i8] }>
%"class.std::__1::vector.678" = type { %"class.std::__1::__vector_base.679" }
%"class.std::__1::__vector_base.679" = type { %"class.std::__1::unique_ptr.680"*, %"class.std::__1::unique_ptr.680"*, %"class.std::__1::__compressed_pair.681" }
%"class.std::__1::unique_ptr.680" = type opaque
%"class.std::__1::__compressed_pair.681" = type { %"struct.std::__1::__compressed_pair_elem.682" }
%"struct.std::__1::__compressed_pair_elem.682" = type { %"class.std::__1::unique_ptr.680"* }
%"class.v8::base::Optional" = type { %"class.v8::base::internal::OptionalBase" }
%"class.v8::base::internal::OptionalBase" = type { %"struct.v8::base::internal::OptionalStorage" }
%"struct.v8::base::internal::OptionalStorage" = type { %"struct.v8::base::internal::OptionalStorageBase" }
%"struct.v8::base::internal::OptionalStorageBase" = type { i8, %union.anon }
%union.anon = type { i32 }
%"class.v8::internal::StatsTable" = type { i32* (i8*)*, i8* (i8*, i32, i32, i64)*, void (i8*, i32)* }
%"class.v8::base::RecursiveMutex" = type { %union.pthread_mutex_t }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"class.v8::base::SharedMutex" = type { %union.pthread_rwlock_t }
%union.pthread_rwlock_t = type { %struct.__pthread_rwlock_arch_t }
%struct.__pthread_rwlock_arch_t = type { i32, i32, i32, i32, i32, i32, i32, i32, i8, [7 x i8], i64, i32 }
%"class.v8::internal::Logger" = type { %"class.v8::internal::CodeEventListener", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.686", %"class.std::__1::unique_ptr.692", %"struct.std::__1::atomic.152", %"class.std::__1::unique_ptr.698", %"class.std::__1::unique_ptr.704", %"class.std::__1::unique_ptr.710", %"class.std::__1::unique_ptr.716", %"class.std::__1::unique_ptr.722", %"class.std::__1::set.728", i32, i8, %"class.v8::internal::ExistingCodeLogger", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::CodeEventListener" = type { i32 (...)** }
%"class.std::__1::unique_ptr.686" = type { %"class.std::__1::__compressed_pair.687" }
%"class.std::__1::__compressed_pair.687" = type { %"struct.std::__1::__compressed_pair_elem.688" }
%"struct.std::__1::__compressed_pair_elem.688" = type { %"class.v8::internal::Ticker"* }
%"class.v8::internal::Ticker" = type opaque
%"class.std::__1::unique_ptr.692" = type { %"class.std::__1::__compressed_pair.693" }
%"class.std::__1::__compressed_pair.693" = type { %"struct.std::__1::__compressed_pair_elem.694" }
%"struct.std::__1::__compressed_pair_elem.694" = type { %"class.v8::internal::Profiler"* }
%"class.v8::internal::Profiler" = type opaque
%"class.std::__1::unique_ptr.698" = type { %"class.std::__1::__compressed_pair.699" }
%"class.std::__1::__compressed_pair.699" = type { %"struct.std::__1::__compressed_pair_elem.700" }
%"struct.std::__1::__compressed_pair_elem.700" = type { %"class.v8::internal::Log"* }
%"class.v8::internal::Log" = type opaque
%"class.std::__1::unique_ptr.704" = type { %"class.std::__1::__compressed_pair.705" }
%"class.std::__1::__compressed_pair.705" = type { %"struct.std::__1::__compressed_pair_elem.706" }
%"struct.std::__1::__compressed_pair_elem.706" = type { %"class.v8::internal::PerfBasicLogger"* }
%"class.v8::internal::PerfBasicLogger" = type opaque
%"class.std::__1::unique_ptr.710" = type { %"class.std::__1::__compressed_pair.711" }
%"class.std::__1::__compressed_pair.711" = type { %"struct.std::__1::__compressed_pair_elem.712" }
%"struct.std::__1::__compressed_pair_elem.712" = type { %"class.v8::internal::PerfJitLogger"* }
%"class.v8::internal::PerfJitLogger" = type opaque
%"class.std::__1::unique_ptr.716" = type { %"class.std::__1::__compressed_pair.717" }
%"class.std::__1::__compressed_pair.717" = type { %"struct.std::__1::__compressed_pair_elem.718" }
%"struct.std::__1::__compressed_pair_elem.718" = type { %"class.v8::internal::LowLevelLogger"* }
%"class.v8::internal::LowLevelLogger" = type opaque
%"class.std::__1::unique_ptr.722" = type { %"class.std::__1::__compressed_pair.723" }
%"class.std::__1::__compressed_pair.723" = type { %"struct.std::__1::__compressed_pair_elem.724" }
%"struct.std::__1::__compressed_pair_elem.724" = type { %"class.v8::internal::JitLogger"* }
%"class.v8::internal::JitLogger" = type opaque
%"class.std::__1::set.728" = type { %"class.std::__1::__tree.729" }
%"class.std::__1::__tree.729" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.730", %"class.std::__1::__compressed_pair.734" }
%"class.std::__1::__compressed_pair.730" = type { %"struct.std::__1::__compressed_pair_elem.80" }
%"class.std::__1::__compressed_pair.734" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.v8::internal::ExistingCodeLogger" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::CodeEventListener"* }
%"class.v8::internal::StubCache" = type { [2048 x %"struct.v8::internal::StubCache::Entry"], [512 x %"struct.v8::internal::StubCache::Entry"], %"class.v8::internal::Isolate"* }
%"struct.v8::internal::StubCache::Entry" = type { %"class.v8::internal::StrongTaggedValue", %"class.v8::internal::TaggedValue", %"class.v8::internal::StrongTaggedValue" }
%"class.v8::internal::TaggedValue" = type { %"class.v8::internal::TaggedImpl.737" }
%"class.v8::internal::TaggedImpl.737" = type { i32 }
%"class.v8::internal::StrongTaggedValue" = type { %"class.v8::internal::TaggedImpl.736" }
%"class.v8::internal::TaggedImpl.736" = type { i32 }
%"class.v8::internal::Deoptimizer" = type opaque
%"class.v8::internal::MaterializedObjectStore" = type opaque
%"class.v8::internal::DescriptorLookupCache" = type { [64 x %"struct.v8::internal::DescriptorLookupCache::Key"], [64 x i32] }
%"struct.v8::internal::DescriptorLookupCache::Key" = type { %"class.v8::internal::Map", %"class.v8::internal::Name" }
%"class.v8::internal::Map" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Name" = type { %"class.v8::internal::TorqueGeneratedName" }
%"class.v8::internal::TorqueGeneratedName" = type { %"class.v8::internal::PrimitiveHeapObject" }
%"class.v8::internal::PrimitiveHeapObject" = type { %"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" }
%"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" = type { %"class.v8::internal::HeapObject" }
%"struct.v8::internal::HandleScopeData" = type { i64*, i64*, i32, i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::CanonicalHandleScope" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::OptimizedCompilationInfo"*, %"class.v8::internal::Zone"*, %"class.v8::internal::RootIndexMap"*, %"class.std::__1::unique_ptr.800", i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::OptimizedCompilationInfo" = type { i32, i32, i32, i32, %"class.v8::internal::Handle.738", %"class.v8::internal::Handle.739", %"class.v8::internal::Handle.740", %"class.v8::internal::Handle.741", %"class.v8::internal::BasicBlockProfilerData"*, %"class.std::__1::unique_ptr.762", %"class.v8::internal::BytecodeOffset", %"class.v8::internal::JavaScriptFrame"*, %"class.v8::internal::Zone"*, %"class.v8::internal::compiler::NodeObserver"*, i8, %"class.std::__1::vector.774", i32, i32, %"class.v8::internal::Vector", %"class.std::__1::unique_ptr.781", %"class.v8::internal::TickCounter", %"class.std::__1::unique_ptr.787", %"class.std::__1::unique_ptr.800" }
%"class.v8::internal::Handle.738" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::Handle.739" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::Handle.740" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::Handle.741" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::BasicBlockProfilerData" = type <{ %"class.std::__1::vector.742", %"class.std::__1::vector.749", %"class.std::__1::basic_string", %"class.std::__1::basic_string", %"class.std::__1::basic_string", i32, [4 x i8] }>
%"class.std::__1::vector.749" = type { %"class.std::__1::__vector_base.750" }
%"class.std::__1::__vector_base.750" = type { i32*, i32*, %"class.std::__1::__compressed_pair.751" }
%"class.std::__1::__compressed_pair.751" = type { %"struct.std::__1::__compressed_pair_elem.752" }
%"struct.std::__1::__compressed_pair_elem.752" = type { i32* }
%"class.std::__1::unique_ptr.762" = type { %"class.std::__1::__compressed_pair.763" }
%"class.std::__1::__compressed_pair.763" = type { %"struct.std::__1::__compressed_pair_elem.764" }
%"struct.std::__1::__compressed_pair_elem.764" = type { %"struct.v8::internal::wasm::WasmCompilationResult"* }
%"struct.v8::internal::wasm::WasmCompilationResult" = type opaque
%"class.v8::internal::BytecodeOffset" = type { i32 }
%"class.v8::internal::JavaScriptFrame" = type { %"class.v8::internal::CommonFrameWithJSLinkage" }
%"class.v8::internal::CommonFrameWithJSLinkage" = type { %"class.v8::internal::CommonFrame" }
%"class.v8::internal::CommonFrame" = type { %"class.v8::internal::StackFrame" }
%"class.v8::internal::StackFrame" = type { i32 (...)**, %"class.v8::internal::StackFrameIteratorBase"*, %"class.v8::internal::Isolate"*, %"struct.v8::internal::StackFrame::State" }
%"class.v8::internal::StackFrameIteratorBase" = type <{ %"class.v8::internal::Isolate"*, %"class.v8::internal::EntryFrame", %"class.v8::internal::ConstructEntryFrame", %"class.v8::internal::ExitFrame", %"class.v8::internal::WasmFrame", %"class.v8::internal::WasmToJsFrame", %"class.v8::internal::JsToWasmFrame", %"class.v8::internal::WasmDebugBreakFrame", %"class.v8::internal::CWasmEntryFrame", %"class.v8::internal::WasmExitFrame", %"class.v8::internal::WasmCompileLazyFrame", %"class.v8::internal::InterpretedFrame", %"class.v8::internal::BaselineFrame", %"class.v8::internal::OptimizedFrame", %"class.v8::internal::StubFrame", %"class.v8::internal::BuiltinContinuationFrame", %"class.v8::internal::JavaScriptBuiltinContinuationFrame", %"class.v8::internal::JavaScriptBuiltinContinuationWithCatchFrame", %"class.v8::internal::InternalFrame", %"class.v8::internal::ConstructFrame", %"class.v8::internal::BuiltinFrame", %"class.v8::internal::BuiltinExitFrame", %"class.v8::internal::NativeFrame", %"class.v8::internal::StackFrame"*, %"class.v8::internal::StackHandler"*, i8, [7 x i8] }>
%"class.v8::internal::EntryFrame" = type { %"class.v8::internal::TypedFrame" }
%"class.v8::internal::TypedFrame" = type { %"class.v8::internal::CommonFrame" }
%"class.v8::internal::ConstructEntryFrame" = type { %"class.v8::internal::EntryFrame" }
%"class.v8::internal::ExitFrame" = type { %"class.v8::internal::TypedFrame" }
%"class.v8::internal::WasmFrame" = type { %"class.v8::internal::TypedFrame" }
%"class.v8::internal::WasmToJsFrame" = type { %"class.v8::internal::StubFrame" }
%"class.v8::internal::JsToWasmFrame" = type { %"class.v8::internal::StubFrame" }
%"class.v8::internal::WasmDebugBreakFrame" = type { %"class.v8::internal::TypedFrame" }
%"class.v8::internal::CWasmEntryFrame" = type { %"class.v8::internal::StubFrame" }
%"class.v8::internal::WasmExitFrame" = type { %"class.v8::internal::WasmFrame" }
%"class.v8::internal::WasmCompileLazyFrame" = type { %"class.v8::internal::TypedFrame" }
%"class.v8::internal::InterpretedFrame" = type { %"class.v8::internal::UnoptimizedFrame" }
%"class.v8::internal::UnoptimizedFrame" = type { %"class.v8::internal::JavaScriptFrame" }
%"class.v8::internal::BaselineFrame" = type { %"class.v8::internal::UnoptimizedFrame" }
%"class.v8::internal::OptimizedFrame" = type { %"class.v8::internal::JavaScriptFrame" }
%"class.v8::internal::StubFrame" = type { %"class.v8::internal::TypedFrame" }
%"class.v8::internal::BuiltinContinuationFrame" = type { %"class.v8::internal::InternalFrame" }
%"class.v8::internal::JavaScriptBuiltinContinuationFrame" = type { %"class.v8::internal::TypedFrameWithJSLinkage" }
%"class.v8::internal::TypedFrameWithJSLinkage" = type { %"class.v8::internal::CommonFrameWithJSLinkage" }
%"class.v8::internal::JavaScriptBuiltinContinuationWithCatchFrame" = type { %"class.v8::internal::JavaScriptBuiltinContinuationFrame" }
%"class.v8::internal::InternalFrame" = type { %"class.v8::internal::TypedFrame" }
%"class.v8::internal::ConstructFrame" = type { %"class.v8::internal::InternalFrame" }
%"class.v8::internal::BuiltinFrame" = type { %"class.v8::internal::TypedFrameWithJSLinkage" }
%"class.v8::internal::BuiltinExitFrame" = type { %"class.v8::internal::ExitFrame" }
%"class.v8::internal::NativeFrame" = type { %"class.v8::internal::TypedFrame" }
%"class.v8::internal::StackHandler" = type { i8 }
%"struct.v8::internal::StackFrame::State" = type { i64, i64, i64*, i64, i64*, i64* }
%"class.std::__1::vector.774" = type { %"class.std::__1::__vector_base.775" }
%"class.std::__1::__vector_base.775" = type { %"struct.v8::internal::OptimizedCompilationInfo::InlinedFunctionHolder"*, %"struct.v8::internal::OptimizedCompilationInfo::InlinedFunctionHolder"*, %"class.std::__1::__compressed_pair.776" }
%"struct.v8::internal::OptimizedCompilationInfo::InlinedFunctionHolder" = type { %"class.v8::internal::Handle.739", %"class.v8::internal::Handle.738", %"struct.v8::internal::InliningPosition" }
%"struct.v8::internal::InliningPosition" = type <{ %"class.v8::internal::SourcePosition", i32, [4 x i8] }>
%"class.v8::internal::SourcePosition" = type { i64 }
%"class.std::__1::__compressed_pair.776" = type { %"struct.std::__1::__compressed_pair_elem.777" }
%"struct.std::__1::__compressed_pair_elem.777" = type { %"struct.v8::internal::OptimizedCompilationInfo::InlinedFunctionHolder"* }
%"class.v8::internal::Vector" = type { i8*, i64 }
%"class.std::__1::unique_ptr.781" = type { %"class.std::__1::__compressed_pair.782" }
%"class.std::__1::__compressed_pair.782" = type { %"struct.std::__1::__compressed_pair_elem.783" }
%"struct.std::__1::__compressed_pair_elem.783" = type { i8* }
%"class.v8::internal::TickCounter" = type { i64, %"class.v8::internal::LocalHeap"* }
%"class.v8::internal::RootIndexMap" = type opaque
%"class.std::__1::unique_ptr.800" = type { %"class.std::__1::__compressed_pair.801" }
%"class.std::__1::__compressed_pair.801" = type { %"struct.std::__1::__compressed_pair_elem.802" }
%"struct.std::__1::__compressed_pair_elem.802" = type { %"class.v8::internal::IdentityMap"* }
%"class.v8::internal::IdentityMap" = type { %"class.v8::internal::IdentityMapBase.base", %"class.v8::internal::ZoneAllocationPolicy" }
%"class.v8::internal::IdentityMapBase.base" = type <{ i32 (...)**, %"struct.v8::base::hash", [7 x i8], %"class.v8::internal::Heap"*, i32, i32, i32, i32, i64*, %"class.v8::internal::StrongRootsEntry"*, i64*, i8 }>
%"struct.v8::base::hash" = type { i8 }
%"class.v8::internal::ZoneAllocationPolicy" = type { %"class.v8::internal::Zone"* }
%"class.v8::internal::HandleScopeImplementer" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::DetachableVector", %"class.v8::internal::DetachableVector.806", %"class.v8::internal::DetachableVector.807", %"class.v8::internal::DetachableVector.806", i64*, i64*, %"struct.v8::internal::HandleScopeData" }
%"class.v8::internal::DetachableVector" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVectorBase" = type { i8*, i64, i64 }
%"class.v8::internal::DetachableVector.807" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVector.806" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::UnicodeCache" = type opaque
%"class.v8::internal::AccountingAllocator" = type { i32 (...)**, %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"class.std::__1::unique_ptr.768", %"class.std::__1::unique_ptr.481" }
%"class.std::__1::unique_ptr.768" = type { %"class.std::__1::__compressed_pair.769" }
%"class.std::__1::__compressed_pair.769" = type { %"struct.std::__1::__compressed_pair_elem.770" }
%"struct.std::__1::__compressed_pair_elem.770" = type { %"class.v8::internal::VirtualMemory"* }
%"class.v8::internal::InnerPointerToCodeCache" = type opaque
%"class.v8::internal::GlobalHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.808", %"class.std::__1::vector.814", %"class.std::__1::unique_ptr.821", %"class.std::__1::vector.828", %"class.std::__1::unique_ptr.835", i64, %"class.std::__1::vector.841", %"class.std::__1::vector.849", %"class.std::__1::vector.857", i8, i8, i32 }
%"class.std::__1::unique_ptr.808" = type { %"class.std::__1::__compressed_pair.809" }
%"class.std::__1::__compressed_pair.809" = type { %"struct.std::__1::__compressed_pair_elem.810" }
%"struct.std::__1::__compressed_pair_elem.810" = type { %"class.v8::internal::GlobalHandles::NodeSpace"* }
%"class.v8::internal::GlobalHandles::NodeSpace" = type opaque
%"class.std::__1::vector.814" = type { %"class.std::__1::__vector_base.815" }
%"class.std::__1::__vector_base.815" = type { %"class.v8::internal::GlobalHandles::Node"**, %"class.v8::internal::GlobalHandles::Node"**, %"class.std::__1::__compressed_pair.816" }
%"class.v8::internal::GlobalHandles::Node" = type opaque
%"class.std::__1::__compressed_pair.816" = type { %"struct.std::__1::__compressed_pair_elem.817" }
%"struct.std::__1::__compressed_pair_elem.817" = type { %"class.v8::internal::GlobalHandles::Node"** }
%"class.std::__1::unique_ptr.821" = type { %"class.std::__1::__compressed_pair.822" }
%"class.std::__1::__compressed_pair.822" = type { %"struct.std::__1::__compressed_pair_elem.823" }
%"struct.std::__1::__compressed_pair_elem.823" = type { %"class.v8::internal::GlobalHandles::NodeSpace.824"* }
%"class.v8::internal::GlobalHandles::NodeSpace.824" = type opaque
%"class.std::__1::vector.828" = type { %"class.std::__1::__vector_base.829" }
%"class.std::__1::__vector_base.829" = type { %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.std::__1::__compressed_pair.830" }
%"class.v8::internal::GlobalHandles::TracedNode" = type opaque
%"class.std::__1::__compressed_pair.830" = type { %"struct.std::__1::__compressed_pair_elem.831" }
%"struct.std::__1::__compressed_pair_elem.831" = type { %"class.v8::internal::GlobalHandles::TracedNode"** }
%"class.std::__1::unique_ptr.835" = type { %"class.std::__1::__compressed_pair.836" }
%"class.std::__1::__compressed_pair.836" = type { %"struct.std::__1::__compressed_pair_elem.837" }
%"struct.std::__1::__compressed_pair_elem.837" = type { %"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace"* }
%"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace" = type opaque
%"class.std::__1::vector.841" = type { %"class.std::__1::__vector_base.842" }
%"class.std::__1::__vector_base.842" = type { %"struct.std::__1::pair.843"*, %"struct.std::__1::pair.843"*, %"class.std::__1::__compressed_pair.844" }
%"struct.std::__1::pair.843" = type opaque
%"class.std::__1::__compressed_pair.844" = type { %"struct.std::__1::__compressed_pair_elem.845" }
%"struct.std::__1::__compressed_pair_elem.845" = type { %"struct.std::__1::pair.843"* }
%"class.std::__1::vector.849" = type { %"class.std::__1::__vector_base.850" }
%"class.std::__1::__vector_base.850" = type { %"struct.std::__1::pair.851"*, %"struct.std::__1::pair.851"*, %"class.std::__1::__compressed_pair.852" }
%"struct.std::__1::pair.851" = type opaque
%"class.std::__1::__compressed_pair.852" = type { %"struct.std::__1::__compressed_pair_elem.853" }
%"struct.std::__1::__compressed_pair_elem.853" = type { %"struct.std::__1::pair.851"* }
%"class.std::__1::vector.857" = type { %"class.std::__1::__vector_base.858" }
%"class.std::__1::__vector_base.858" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.std::__1::__compressed_pair.859" }
%"class.v8::internal::GlobalHandles::PendingPhantomCallback" = type { void (%"class.v8::WeakCallbackInfo"*)*, i8*, [2 x i8*] }
%"class.v8::WeakCallbackInfo" = type { %"class.v8::Isolate"*, i8*, {}**, [2 x i8*] }
%"class.std::__1::__compressed_pair.859" = type { %"struct.std::__1::__compressed_pair_elem.860" }
%"struct.std::__1::__compressed_pair_elem.860" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"* }
%"class.v8::internal::EternalHandles" = type { i32, %"class.std::__1::vector.790", %"class.std::__1::vector.742" }
%"class.v8::internal::ThreadManager" = type opaque
%"class.v8::bigint::Processor" = type opaque
%"class.v8::internal::RuntimeState" = type { %"class.std::__1::unique_ptr.864" }
%"class.std::__1::unique_ptr.864" = type { %"class.std::__1::__compressed_pair.865" }
%"class.std::__1::__compressed_pair.865" = type { %"struct.std::__1::__compressed_pair_elem.866" }
%"struct.std::__1::__compressed_pair_elem.866" = type { %"struct.v8::internal::Runtime::Function"* }
%"struct.v8::internal::Runtime::Function" = type { i32, i32, i8*, i64, i8, i8 }
%"class.v8::internal::Builtins" = type { %"class.v8::internal::Isolate"*, i8, i32 }
%"class.v8::internal::SetupIsolateDelegate" = type opaque
%"class.v8::internal::RegExpStack" = type opaque
%"class.std::__1::vector.742" = type { %"class.std::__1::__vector_base.743" }
%"class.std::__1::__vector_base.743" = type { i32*, i32*, %"class.std::__1::__compressed_pair.744" }
%"class.std::__1::__compressed_pair.744" = type { %"struct.std::__1::__compressed_pair_elem.745" }
%"struct.std::__1::__compressed_pair_elem.745" = type { i32* }
%"class.v8::internal::DateCache" = type opaque
%"struct.std::__1::atomic.870" = type { %"struct.std::__1::__atomic_base.871" }
%"struct.std::__1::__atomic_base.871" = type { %"struct.std::__1::__cxx_atomic_impl.872" }
%"struct.std::__1::__cxx_atomic_impl.872" = type { %"struct.std::__1::__cxx_atomic_base_impl.873" }
%"struct.std::__1::__cxx_atomic_base_impl.873" = type { i32 }
%"class.v8::Promise" = type { i8 }
%"struct.std::__1::atomic.880" = type { %"struct.std::__1::__atomic_base.881" }
%"struct.std::__1::__atomic_base.881" = type { %"struct.std::__1::__cxx_atomic_impl.882" }
%"struct.std::__1::__cxx_atomic_impl.882" = type { %"struct.std::__1::__cxx_atomic_base_impl.883" }
%"struct.std::__1::__cxx_atomic_base_impl.883" = type { i32 }
%"class.std::__1::basic_string" = type { %"class.std::__1::__compressed_pair.756" }
%"class.std::__1::__compressed_pair.756" = type { %"struct.std::__1::__compressed_pair_elem.757" }
%"struct.std::__1::__compressed_pair_elem.757" = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" = type { %union.anon.758 }
%union.anon.758 = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" = type { i8*, i64, i64 }
%"class.std::__1::unordered_map.885" = type { %"class.std::__1::__hash_table.886" }
%"class.std::__1::__hash_table.886" = type <{ %"class.std::__1::unique_ptr.887", %"class.std::__1::__compressed_pair.897", %"class.std::__1::__compressed_pair.902", %"class.std::__1::__compressed_pair.905", [4 x i8] }>
%"class.std::__1::unique_ptr.887" = type { %"class.std::__1::__compressed_pair.888" }
%"class.std::__1::__compressed_pair.888" = type { %"struct.std::__1::__compressed_pair_elem.889", %"struct.std::__1::__compressed_pair_elem.891" }
%"struct.std::__1::__compressed_pair_elem.889" = type { %"struct.std::__1::__hash_node_base.890"** }
%"struct.std::__1::__hash_node_base.890" = type { %"struct.std::__1::__hash_node_base.890"* }
%"struct.std::__1::__compressed_pair_elem.891" = type { %"class.std::__1::__bucket_list_deallocator.892" }
%"class.std::__1::__bucket_list_deallocator.892" = type { %"class.std::__1::__compressed_pair.893" }
%"class.std::__1::__compressed_pair.893" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.897" = type { %"struct.std::__1::__compressed_pair_elem.898" }
%"struct.std::__1::__compressed_pair_elem.898" = type { %"struct.std::__1::__hash_node_base.890" }
%"class.std::__1::__compressed_pair.902" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.905" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"struct.std::__1::atomic.152" = type { %"struct.std::__1::__atomic_base.153" }
%"struct.std::__1::__atomic_base.153" = type { %"struct.std::__1::__cxx_atomic_impl.154" }
%"struct.std::__1::__cxx_atomic_impl.154" = type { %"struct.std::__1::__cxx_atomic_base_impl.155" }
%"struct.std::__1::__cxx_atomic_base_impl.155" = type { i8 }
%"class.v8::internal::Debug" = type { %"class.v8::debug::DebugDelegate"*, i8, i8, i8, i8, i8, i8, i8, i8, i8, %"class.v8::internal::DebugInfoListNode"*, %"class.std::__1::unique_ptr.911", %"class.v8::internal::Handle.917", %"class.v8::internal::DebugFeatureTracker", %"class.v8::internal::Debug::ThreadLocal", %"class.v8::internal::Handle.918", %"class.v8::internal::Isolate"* }
%"class.v8::debug::DebugDelegate" = type { i32 (...)** }
%"class.v8::internal::DebugInfoListNode" = type { i64*, %"class.v8::internal::DebugInfoListNode"* }
%"class.std::__1::unique_ptr.911" = type { %"class.std::__1::__compressed_pair.912" }
%"class.std::__1::__compressed_pair.912" = type { %"struct.std::__1::__compressed_pair_elem.913" }
%"struct.std::__1::__compressed_pair_elem.913" = type { %"class.v8::internal::Debug::TemporaryObjectsTracker"* }
%"class.v8::internal::Debug::TemporaryObjectsTracker" = type opaque
%"class.v8::internal::Handle.917" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::DebugFeatureTracker" = type <{ %"class.v8::internal::Isolate"*, i32, [4 x i8] }>
%"class.v8::internal::Debug::ThreadLocal" = type <{ i64, i32, i8, [3 x i8], %"class.v8::internal::Object", i8, [3 x i8], i32, i32, i32, %"class.v8::internal::Object", %"class.v8::internal::Object", i32, i8, [3 x i8] }>
%"class.v8::internal::Handle.918" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HeapProfiler" = type { %"class.v8::internal::HeapObjectAllocationTracker", %"class.std::__1::unique_ptr.919", %"class.std::__1::vector.925", %"class.std::__1::unique_ptr.933", %"class.std::__1::unique_ptr.939", i8, i8, %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.945", %"class.std::__1::vector.951", %"struct.std::__1::pair.959" }
%"class.std::__1::unique_ptr.919" = type { %"class.std::__1::__compressed_pair.920" }
%"class.std::__1::__compressed_pair.920" = type { %"struct.std::__1::__compressed_pair_elem.921" }
%"struct.std::__1::__compressed_pair_elem.921" = type { %"class.v8::internal::HeapObjectsMap"* }
%"class.v8::internal::HeapObjectsMap" = type opaque
%"class.std::__1::vector.925" = type { %"class.std::__1::__vector_base.926" }
%"class.std::__1::__vector_base.926" = type { %"class.std::__1::unique_ptr.927"*, %"class.std::__1::unique_ptr.927"*, %"class.std::__1::__compressed_pair.928" }
%"class.std::__1::unique_ptr.927" = type opaque
%"class.std::__1::__compressed_pair.928" = type { %"struct.std::__1::__compressed_pair_elem.929" }
%"struct.std::__1::__compressed_pair_elem.929" = type { %"class.std::__1::unique_ptr.927"* }
%"class.std::__1::unique_ptr.933" = type { %"class.std::__1::__compressed_pair.934" }
%"class.std::__1::__compressed_pair.934" = type { %"struct.std::__1::__compressed_pair_elem.935" }
%"struct.std::__1::__compressed_pair_elem.935" = type { %"class.v8::internal::StringsStorage"* }
%"class.v8::internal::StringsStorage" = type opaque
%"class.std::__1::unique_ptr.939" = type { %"class.std::__1::__compressed_pair.940" }
%"class.std::__1::__compressed_pair.940" = type { %"struct.std::__1::__compressed_pair_elem.941" }
%"struct.std::__1::__compressed_pair_elem.941" = type { %"class.v8::internal::AllocationTracker"* }
%"class.v8::internal::AllocationTracker" = type opaque
%"class.std::__1::unique_ptr.945" = type { %"class.std::__1::__compressed_pair.946" }
%"class.std::__1::__compressed_pair.946" = type { %"struct.std::__1::__compressed_pair_elem.947" }
%"struct.std::__1::__compressed_pair_elem.947" = type { %"class.v8::internal::SamplingHeapProfiler"* }
%"class.v8::internal::SamplingHeapProfiler" = type opaque
%"class.std::__1::vector.951" = type { %"class.std::__1::__vector_base.952" }
%"class.std::__1::__vector_base.952" = type { %"struct.std::__1::pair.953"*, %"struct.std::__1::pair.953"*, %"class.std::__1::__compressed_pair.954" }
%"struct.std::__1::pair.953" = type opaque
%"class.std::__1::__compressed_pair.954" = type { %"struct.std::__1::__compressed_pair_elem.955" }
%"struct.std::__1::__compressed_pair_elem.955" = type { %"struct.std::__1::pair.953"* }
%"struct.std::__1::pair.959" = type { i8 (%"class.v8::Isolate"*, %"class.v8::Local.0"*, i16, i8*)*, i8* }
%"class.v8::Local.0" = type { %"class.v8::Value"* }
%"class.std::__1::unique_ptr.960" = type { %"class.std::__1::__compressed_pair.961" }
%"class.std::__1::__compressed_pair.961" = type { %"struct.std::__1::__compressed_pair_elem.962" }
%"struct.std::__1::__compressed_pair_elem.962" = type { %"class.v8::internal::CodeEventDispatcher"* }
%"class.v8::internal::CodeEventDispatcher" = type { %"class.v8::internal::CodeEventListener", %"class.std::__1::unordered_set.963", %"class.v8::base::Mutex" }
%"class.std::__1::unordered_set.963" = type { %"class.std::__1::__hash_table.964" }
%"class.std::__1::__hash_table.964" = type <{ %"class.std::__1::unique_ptr.965", %"class.std::__1::__compressed_pair.975", %"class.std::__1::__compressed_pair.980", %"class.std::__1::__compressed_pair.984", [4 x i8] }>
%"class.std::__1::unique_ptr.965" = type { %"class.std::__1::__compressed_pair.966" }
%"class.std::__1::__compressed_pair.966" = type { %"struct.std::__1::__compressed_pair_elem.967", %"struct.std::__1::__compressed_pair_elem.969" }
%"struct.std::__1::__compressed_pair_elem.967" = type { %"struct.std::__1::__hash_node_base.968"** }
%"struct.std::__1::__hash_node_base.968" = type { %"struct.std::__1::__hash_node_base.968"* }
%"struct.std::__1::__compressed_pair_elem.969" = type { %"class.std::__1::__bucket_list_deallocator.970" }
%"class.std::__1::__bucket_list_deallocator.970" = type { %"class.std::__1::__compressed_pair.971" }
%"class.std::__1::__compressed_pair.971" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.975" = type { %"struct.std::__1::__compressed_pair_elem.976" }
%"struct.std::__1::__compressed_pair_elem.976" = type { %"struct.std::__1::__hash_node_base.968" }
%"class.std::__1::__compressed_pair.980" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.984" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::internal::AstStringConstants" = type opaque
%"class.v8::internal::interpreter::Interpreter" = type opaque
%"class.v8::internal::compiler::PerIsolateCompilerCache" = type opaque
%"class.v8::internal::Zone" = type <{ i64, i64, i64, i64, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::Segment"*, i8*, i8, i8, [6 x i8] }>
%"class.v8::internal::Segment" = type { %"class.v8::internal::Zone"*, %"class.v8::internal::Segment"*, i64 }
%"class.v8::internal::CompilerDispatcher" = type opaque
%"class.std::__1::queue" = type { %"class.std::__1::deque" }
%"class.std::__1::deque" = type { %"class.std::__1::__deque_base" }
%"class.std::__1::__deque_base" = type { %"struct.std::__1::__split_buffer", i64, %"class.std::__1::__compressed_pair.998" }
%"struct.std::__1::__split_buffer" = type { %"struct.std::__1::pair.992"**, %"struct.std::__1::pair.992"**, %"struct.std::__1::pair.992"**, %"class.std::__1::__compressed_pair.993" }
%"struct.std::__1::pair.992" = type opaque
%"class.std::__1::__compressed_pair.993" = type { %"struct.std::__1::__compressed_pair_elem.994" }
%"struct.std::__1::__compressed_pair_elem.994" = type { %"struct.std::__1::pair.992"** }
%"class.std::__1::__compressed_pair.998" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.v8::String" = type { i8 }
%"class.v8::Context" = type { i8 }
%"class.v8::FunctionCallbackInfo" = type <{ i64*, i64*, i32, [4 x i8] }>
%"class.v8::internal::Relocatable" = type { i32 (...)**, %"class.v8::internal::Isolate"*, %"class.v8::internal::Relocatable"* }
%"class.std::__1::vector.1003" = type { %"class.std::__1::__vector_base.1004" }
%"class.std::__1::__vector_base.1004" = type { %"class.v8::internal::Handle.1005"*, %"class.v8::internal::Handle.1005"*, %"class.std::__1::__compressed_pair.1006" }
%"class.v8::internal::Handle.1005" = type { %"class.v8::internal::HandleBase" }
%"class.std::__1::__compressed_pair.1006" = type { %"struct.std::__1::__compressed_pair_elem.1007" }
%"struct.std::__1::__compressed_pair_elem.1007" = type { %"class.v8::internal::Handle.1005"* }
%"class.v8::internal::Object" = type { %"class.v8::internal::TaggedImpl" }
%"class.v8::internal::TaggedImpl" = type { i64 }
%"class.v8::internal::AddressToIndexHashMap" = type opaque
%"class.v8::internal::HeapObjectToIndexHashMap" = type opaque
%"class.v8::internal::MicrotaskQueue" = type opaque
%"class.v8::internal::CompilationStatistics" = type opaque
%"class.v8::internal::CodeTracer" = type <{ %"class.v8::internal::EmbeddedVector", %struct._IO_FILE*, i32, [4 x i8] }>
%"class.v8::internal::EmbeddedVector" = type { %"class.v8::internal::Vector.1011", [128 x i8] }
%"class.v8::internal::Vector.1011" = type { i8*, i64 }
%"class.v8::PromiseRejectMessage" = type { %"class.v8::Local.875", i32, %"class.v8::Local.0" }
%"class.v8::Local.875" = type { %"class.v8::Promise"* }
%"class.v8::StartupData" = type { i8*, i32 }
%"class.v8_inspector::V8Inspector" = type opaque
%"class.v8::internal::compiler::NodeObserver" = type opaque
%"class.std::__1::unique_ptr.1012" = type { %"class.std::__1::__compressed_pair.1013" }
%"class.std::__1::__compressed_pair.1013" = type { %"struct.std::__1::__compressed_pair_elem.1014" }
%"struct.std::__1::__compressed_pair_elem.1014" = type { %"class.v8::internal::PersistentHandlesList"* }
%"class.v8::internal::PersistentHandlesList" = type { %"class.v8::base::Mutex", %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.1018" = type { %"class.std::__1::__vector_base.1019" }
%"class.std::__1::__vector_base.1019" = type { void (%"class.v8::Isolate"*)**, void (%"class.v8::Isolate"*)**, %"class.std::__1::__compressed_pair.1020" }
%"class.std::__1::__compressed_pair.1020" = type { %"struct.std::__1::__compressed_pair_elem.1021" }
%"struct.std::__1::__compressed_pair_elem.1021" = type { void (%"class.v8::Isolate"*)** }
%"class.std::__1::shared_ptr.1025" = type { %"class.v8::internal::metrics::Recorder"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::metrics::Recorder" = type opaque
%"class.std::__1::unordered_map.1026" = type { %"class.std::__1::__hash_table.1027" }
%"class.std::__1::__hash_table.1027" = type <{ %"class.std::__1::unique_ptr.1028", %"class.std::__1::__compressed_pair.1038", %"class.std::__1::__compressed_pair.1043", %"class.std::__1::__compressed_pair.1046", [4 x i8] }>
%"class.std::__1::unique_ptr.1028" = type { %"class.std::__1::__compressed_pair.1029" }
%"class.std::__1::__compressed_pair.1029" = type { %"struct.std::__1::__compressed_pair_elem.1030", %"struct.std::__1::__compressed_pair_elem.1032" }
%"struct.std::__1::__compressed_pair_elem.1030" = type { %"struct.std::__1::__hash_node_base.1031"** }
%"struct.std::__1::__hash_node_base.1031" = type { %"struct.std::__1::__hash_node_base.1031"* }
%"struct.std::__1::__compressed_pair_elem.1032" = type { %"class.std::__1::__bucket_list_deallocator.1033" }
%"class.std::__1::__bucket_list_deallocator.1033" = type { %"class.std::__1::__compressed_pair.1034" }
%"class.std::__1::__compressed_pair.1034" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1038" = type { %"struct.std::__1::__compressed_pair_elem.1039" }
%"struct.std::__1::__compressed_pair_elem.1039" = type { %"struct.std::__1::__hash_node_base.1031" }
%"class.std::__1::__compressed_pair.1043" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1046" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"struct.v8::metrics::LongTaskStats" = type { i64, i64, i64 }
%"class.std::__1::vector.541" = type { %"class.std::__1::__vector_base.542" }
%"class.std::__1::__vector_base.542" = type { %"class.v8::internal::Object"*, %"class.v8::internal::Object"*, %"class.std::__1::__compressed_pair.543" }
%"class.std::__1::__compressed_pair.543" = type { %"struct.std::__1::__compressed_pair_elem.544" }
%"struct.std::__1::__compressed_pair_elem.544" = type { %"class.v8::internal::Object"* }
%"class.v8::internal::BuiltinsConstantsTableBuilder" = type opaque
%"class.v8::ArrayBuffer::Allocator" = type { i32 (...)** }
%"class.std::__1::shared_ptr.160" = type { %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::FutexWaitListNode" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::shared_ptr.1050", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::base::ConditionVariable", %"class.v8::internal::FutexWaitListNode"*, %"class.v8::internal::FutexWaitListNode"*, %"class.std::__1::weak_ptr.1079", i64, i8*, i8, i8, %"class.v8::Global", %"class.v8::Global.1080", %"class.v8::base::TimeTicks", i64 }
%"class.std::__1::shared_ptr.1050" = type { %"class.v8::TaskRunner"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::TaskRunner" = type { i32 (...)** }
%"class.std::__1::weak_ptr.1079" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::Global" = type { %"class.v8::PersistentBase" }
%"class.v8::PersistentBase" = type { %"class.v8::Promise"* }
%"class.v8::Global.1080" = type { %"class.v8::PersistentBase.1081" }
%"class.v8::PersistentBase.1081" = type { %"class.v8::Context"* }
%"class.v8::internal::CancelableTaskManager" = type <{ i64, %"class.std::__1::unordered_map.1051", %"class.v8::base::ConditionVariable", %"class.v8::base::Mutex", i8, [7 x i8] }>
%"class.std::__1::unordered_map.1051" = type { %"class.std::__1::__hash_table.1052" }
%"class.std::__1::__hash_table.1052" = type <{ %"class.std::__1::unique_ptr.1053", %"class.std::__1::__compressed_pair.1063", %"class.std::__1::__compressed_pair.1068", %"class.std::__1::__compressed_pair.1071", [4 x i8] }>
%"class.std::__1::unique_ptr.1053" = type { %"class.std::__1::__compressed_pair.1054" }
%"class.std::__1::__compressed_pair.1054" = type { %"struct.std::__1::__compressed_pair_elem.1055", %"struct.std::__1::__compressed_pair_elem.1057" }
%"struct.std::__1::__compressed_pair_elem.1055" = type { %"struct.std::__1::__hash_node_base.1056"** }
%"struct.std::__1::__hash_node_base.1056" = type { %"struct.std::__1::__hash_node_base.1056"* }
%"struct.std::__1::__compressed_pair_elem.1057" = type { %"class.std::__1::__bucket_list_deallocator.1058" }
%"class.std::__1::__bucket_list_deallocator.1058" = type { %"class.std::__1::__compressed_pair.1059" }
%"class.std::__1::__compressed_pair.1059" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1063" = type { %"struct.std::__1::__compressed_pair_elem.1064" }
%"struct.std::__1::__compressed_pair_elem.1064" = type { %"struct.std::__1::__hash_node_base.1056" }
%"class.std::__1::__compressed_pair.1068" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1071" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::debug::ConsoleDelegate" = type { i32 (...)** }
%"class.v8::debug::AsyncEventDelegate" = type { i32 (...)** }
%"class.std::__1::unique_ptr.1082" = type { %"class.std::__1::__compressed_pair.1083" }
%"class.std::__1::__compressed_pair.1083" = type { %"struct.std::__1::__compressed_pair_elem.1084" }
%"struct.std::__1::__compressed_pair_elem.1084" = type { %"class.v8::internal::LocalIsolate"* }
%"class.v8::internal::LocalIsolate" = type { %"class.v8::internal::HiddenLocalFactory", %"class.v8::internal::LocalHeap", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.1105", %"class.v8::internal::ThreadId", i64, %"class.v8::internal::RuntimeCallStats"* }
%"class.v8::internal::HiddenLocalFactory" = type { %"class.v8::internal::LocalFactory" }
%"class.v8::internal::LocalFactory" = type { %"class.v8::internal::ReadOnlyRoots" }
%"class.v8::internal::ReadOnlyRoots" = type { i64* }
%"class.std::__1::unique_ptr.1105" = type { %"class.std::__1::__compressed_pair.1106" }
%"class.std::__1::__compressed_pair.1106" = type { %"struct.std::__1::__compressed_pair_elem.1107" }
%"struct.std::__1::__compressed_pair_elem.1107" = type { %"class.v8::internal::LocalLogger"* }
%"class.v8::internal::LocalLogger" = type opaque
%"struct.v8::internal::ManagedPtrDestructor" = type { i64, %"struct.v8::internal::ManagedPtrDestructor"*, %"struct.v8::internal::ManagedPtrDestructor"*, i8*, void (i8*)*, i64* }
%"class.v8::internal::wasm::WasmEngine" = type opaque
%"class.std::__1::unique_ptr.1114" = type { %"class.std::__1::__compressed_pair.1115" }
%"class.std::__1::__compressed_pair.1115" = type { %"struct.std::__1::__compressed_pair_elem.1116" }
%"struct.std::__1::__compressed_pair_elem.1116" = type { %"class.v8::internal::TracingCpuProfilerImpl"* }
%"class.v8::internal::TracingCpuProfilerImpl" = type opaque
%"class.v8::internal::EmbeddedFileWriterInterface" = type opaque
%"class.v8::Context::BackupIncumbentScope" = type { %"class.v8::Local.876", i64, %"class.v8::Context::BackupIncumbentScope"* }
%"class.v8::Local.876" = type { %"class.v8::Context"* }
%"class.v8::internal::Isolate::ThreadDataTable" = type { %"class.std::__1::unordered_map.1122" }
%"class.std::__1::unordered_map.1122" = type { %"class.std::__1::__hash_table.1123" }
%"class.std::__1::__hash_table.1123" = type <{ %"class.std::__1::unique_ptr.1124", %"class.std::__1::__compressed_pair.1134", %"class.std::__1::__compressed_pair.1139", %"class.std::__1::__compressed_pair.1142", [4 x i8] }>
%"class.std::__1::unique_ptr.1124" = type { %"class.std::__1::__compressed_pair.1125" }
%"class.std::__1::__compressed_pair.1125" = type { %"struct.std::__1::__compressed_pair_elem.1126", %"struct.std::__1::__compressed_pair_elem.1128" }
%"struct.std::__1::__compressed_pair_elem.1126" = type { %"struct.std::__1::__hash_node_base.1127"** }
%"struct.std::__1::__hash_node_base.1127" = type { %"struct.std::__1::__hash_node_base.1127"* }
%"struct.std::__1::__compressed_pair_elem.1128" = type { %"class.std::__1::__bucket_list_deallocator.1129" }
%"class.std::__1::__bucket_list_deallocator.1129" = type { %"class.std::__1::__compressed_pair.1130" }
%"class.std::__1::__compressed_pair.1130" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1134" = type { %"struct.std::__1::__compressed_pair_elem.1135" }
%"struct.std::__1::__compressed_pair_elem.1135" = type { %"struct.std::__1::__hash_node_base.1127" }
%"class.std::__1::__compressed_pair.1139" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1142" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"struct.std::__1::atomic.1148" = type { %"struct.std::__1::__atomic_base.1149" }
%"struct.std::__1::__atomic_base.1149" = type { %"struct.std::__1::__cxx_atomic_impl.1150" }
%"struct.std::__1::__cxx_atomic_impl.1150" = type { %"struct.std::__1::__cxx_atomic_base_impl.1151" }
%"struct.std::__1::__cxx_atomic_base_impl.1151" = type { %"class.std::__1::vector.1152"* }
%"class.std::__1::vector.1152" = type { %"class.std::__1::__vector_base.1153" }
%"class.std::__1::__vector_base.1153" = type { %"struct.v8::MemoryRange"*, %"struct.v8::MemoryRange"*, %"class.std::__1::__compressed_pair.1154" }
%"struct.v8::MemoryRange" = type { i8*, i64 }
%"class.std::__1::__compressed_pair.1154" = type { %"struct.std::__1::__compressed_pair_elem.1155" }
%"struct.std::__1::__compressed_pair_elem.1155" = type { %"struct.v8::MemoryRange"* }
%"class.v8::internal::OptimizedCompilationJob" = type { %"class.v8::internal::CompilationJob", %"class.v8::internal::OptimizedCompilationInfo"*, %"class.v8::base::TimeDelta", %"class.v8::base::TimeDelta", %"class.v8::base::TimeDelta", i8* }
%"class.v8::internal::CompilationJob" = type { i32 (...)**, i32, %"class.v8::base::ElapsedTimer" }
%"class.std::__1::queue.1159" = type { %"class.std::__1::deque.1160" }
%"class.std::__1::deque.1160" = type { %"class.std::__1::__deque_base.1161" }
%"class.std::__1::__deque_base.1161" = type { %"struct.std::__1::__split_buffer.1162", i64, %"class.std::__1::__compressed_pair.1168" }
%"struct.std::__1::__split_buffer.1162" = type { %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"***, %"class.std::__1::__compressed_pair.1163" }
%"class.std::__1::__compressed_pair.1163" = type { %"struct.std::__1::__compressed_pair_elem.1164" }
%"struct.std::__1::__compressed_pair_elem.1164" = type { %"class.v8::internal::OptimizedCompilationJob"*** }
%"class.std::__1::__compressed_pair.1168" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.v8::base::Mutex" = type { %union.pthread_mutex_t }
%"class.v8::base::ConditionVariable" = type { %union.pthread_cond_t }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon.1075, %union.anon.1077, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon.1075 = type { i64 }
%union.anon.1077 = type { i64 }
%"class.v8::internal::FeedbackVector" = type { %"class.v8::internal::TorqueGeneratedFeedbackVector" }
%"class.v8::internal::TorqueGeneratedFeedbackVector" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::SharedFunctionInfo" = type { %"class.v8::internal::TorqueGeneratedSharedFunctionInfo" }
%"class.v8::internal::TorqueGeneratedSharedFunctionInfo" = type { %"class.v8::internal::HeapObject" }
%"class.v8::Platform" = type { i32 (...)** }
%"class.v8::internal::CancelableTask" = type { %"class.v8::internal::Cancelable", %"class.v8::Task" }
%"class.v8::internal::Cancelable" = type { i32 (...)**, %"class.v8::internal::CancelableTaskManager"*, %"struct.std::__1::atomic.1181", i64 }
%"struct.std::__1::atomic.1181" = type { %"struct.std::__1::__atomic_base.1182" }
%"struct.std::__1::__atomic_base.1182" = type { %"struct.std::__1::__cxx_atomic_impl.1183" }
%"struct.std::__1::__cxx_atomic_impl.1183" = type { %"struct.std::__1::__cxx_atomic_base_impl.1184" }
%"struct.std::__1::__cxx_atomic_base_impl.1184" = type { i32 }
%"class.v8::Task" = type { i32 (...)** }
%"class.v8::internal::Handle<v8::internal::JSFunction>::ObjectRef" = type { %"class.v8::internal::JSFunction" }
%"class.v8::internal::JSFunction" = type { %"class.v8::internal::JSFunctionOrBoundFunction" }
%"class.v8::internal::JSFunctionOrBoundFunction" = type { %"class.v8::internal::TorqueGeneratedJSFunctionOrBoundFunction" }
%"class.v8::internal::TorqueGeneratedJSFunctionOrBoundFunction" = type { %"class.v8::internal::JSObject" }
%"class.v8::internal::JSObject" = type { %"class.v8::internal::TorqueGeneratedJSObject" }
%"class.v8::internal::TorqueGeneratedJSObject" = type { %"class.v8::internal::JSReceiver" }
%"class.v8::internal::JSReceiver" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::OptimizingCompileDispatcher::CompileTask" = type { %"class.v8::internal::CancelableTask", %"class.v8::internal::Isolate"*, %"class.v8::internal::WorkerThreadRuntimeCallStats"*, %"class.v8::internal::OptimizingCompileDispatcher"* }
%"class.std::__1::unique_ptr.1228" = type { %"class.std::__1::__compressed_pair.1229" }
%"class.std::__1::__compressed_pair.1229" = type { %"struct.std::__1::__compressed_pair_elem.1230" }
%"struct.std::__1::__compressed_pair_elem.1230" = type { %"class.v8::ConvertableToTraceFormat"* }
%"class.v8::ConvertableToTraceFormat" = type { i32 (...)** }
%"class.v8::internal::WorkerThreadRuntimeCallStatsScope" = type { %"class.v8::internal::RuntimeCallStats"* }
%"class.v8::internal::RuntimeCallTimerScope" = type { %"class.v8::internal::RuntimeCallStats"*, %"class.v8::internal::RuntimeCallTimer" }
%"class.v8::internal::RuntimeCallTimer" = type { %"class.v8::internal::RuntimeCallCounter"*, %"class.v8::base::AtomicValue", %"class.v8::base::TimeTicks", %"class.v8::base::TimeDelta" }
%"class.v8::internal::TimerEventScope" = type { %"class.v8::internal::Isolate"* }
%"class.v8::internal::tracing::ScopedTracer" = type { %"struct.v8::internal::tracing::ScopedTracer::Data"*, %"struct.v8::internal::tracing::ScopedTracer::Data" }
%"struct.v8::internal::tracing::ScopedTracer::Data" = type { i8*, i8*, i64 }
%"class.v8::TracingController" = type { i32 (...)** }

$_ZNSt3__15dequeIPN2v88internal23OptimizedCompilationJobENS_9allocatorIS4_EEE19__add_back_capacityEv = comdat any

$_ZNSt3__114__split_bufferIPPN2v88internal23OptimizedCompilationJobENS_9allocatorIS5_EEE9push_backEOS5_ = comdat any

$_ZNSt3__114__split_bufferIPPN2v88internal23OptimizedCompilationJobENS_9allocatorIS5_EEE10push_frontEOS5_ = comdat any

$_ZN2v88internal14CancelableTaskD2Ev = comdat any

$_ZN2v88internal27OptimizingCompileDispatcher11CompileTaskD0Ev = comdat any

$_ZN2v88internal14CancelableTask3RunEv = comdat any

$_ZN2v88internal27OptimizingCompileDispatcher11CompileTask11RunInternalEv = comdat any

$_ZThn32_N2v88internal27OptimizingCompileDispatcher11CompileTaskD1Ev = comdat any

$_ZThn32_N2v88internal27OptimizingCompileDispatcher11CompileTaskD0Ev = comdat any

$_ZThn32_N2v88internal14CancelableTask3RunEv = comdat any

$_ZTVN2v88internal27OptimizingCompileDispatcher11CompileTaskE = comdat any

$_ZZN2v88internal27OptimizingCompileDispatcher11CompileTask11RunInternalEvE27trace_event_unique_atomic77 = comdat any

@_ZN2v88internal35FLAG_block_concurrent_recompilationE = external local_unnamed_addr global i8, align 1
@_ZN2v88internal35FLAG_trace_concurrent_recompilationE = external local_unnamed_addr global i8, align 1
@.str = private unnamed_addr constant [58 x i8] c"  ** Flushed concurrent recompilation queues. (mode: %s)\0A\00", align 1
@.str.1 = private unnamed_addr constant [9 x i8] c"blocking\00", align 1
@.str.2 = private unnamed_addr constant [13 x i8] c"non blocking\00", align 1
@.str.3 = private unnamed_addr constant [31 x i8] c"  ** Aborting compilation for \00", align 1
@stdout = external local_unnamed_addr global %struct._IO_FILE*, align 8
@.str.4 = private unnamed_addr constant [36 x i8] c" as it has already been optimized.\0A\00", align 1
@_ZTVN2v88internal27OptimizingCompileDispatcher11CompileTaskE = linkonce_odr hidden unnamed_addr constant { [6 x i8*], [5 x i8*] } { [6 x i8*] [i8* null, i8* null, i8* bitcast (void (%"class.v8::internal::CancelableTask"*)* @_ZN2v88internal14CancelableTaskD2Ev to i8*), i8* bitcast (void (%"class.v8::internal::OptimizingCompileDispatcher::CompileTask"*)* @_ZN2v88internal27OptimizingCompileDispatcher11CompileTaskD0Ev to i8*), i8* bitcast (void (%"class.v8::internal::CancelableTask"*)* @_ZN2v88internal14CancelableTask3RunEv to i8*), i8* bitcast (void (%"class.v8::internal::OptimizingCompileDispatcher::CompileTask"*)* @_ZN2v88internal27OptimizingCompileDispatcher11CompileTask11RunInternalEv to i8*)], [5 x i8*] [i8* inttoptr (i64 -32 to i8*), i8* null, i8* bitcast (void (%"class.v8::internal::OptimizingCompileDispatcher::CompileTask"*)* @_ZThn32_N2v88internal27OptimizingCompileDispatcher11CompileTaskD1Ev to i8*), i8* bitcast (void (%"class.v8::internal::OptimizingCompileDispatcher::CompileTask"*)* @_ZThn32_N2v88internal27OptimizingCompileDispatcher11CompileTaskD0Ev to i8*), i8* bitcast (void (%"class.v8::internal::CancelableTask"*)* @_ZThn32_N2v88internal14CancelableTask3RunEv to i8*)] }, comdat, align 8
@_ZZN2v88internal27OptimizingCompileDispatcher11CompileTask11RunInternalEvE27trace_event_unique_atomic77 = linkonce_odr hidden global i64 0, comdat, align 8
@.str.6 = private unnamed_addr constant [31 x i8] c"disabled-by-default-v8.compile\00", align 1
@.str.7 = private unnamed_addr constant [22 x i8] c"V8.OptimizeBackground\00", align 1
@_ZN2v88internal12TracingFlags13runtime_statsE = external local_unnamed_addr global %"struct.std::__1::atomic.1218", align 4

@_ZN2v88internal27OptimizingCompileDispatcherD1Ev = hidden unnamed_addr alias void (%"class.v8::internal::OptimizingCompileDispatcher"*), void (%"class.v8::internal::OptimizingCompileDispatcher"*)* @_ZN2v88internal27OptimizingCompileDispatcherD2Ev

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27OptimizingCompileDispatcherD2Ev(%"class.v8::internal::OptimizingCompileDispatcher"*) unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 1
  %3 = load %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %2, align 8
  %4 = icmp eq %"class.v8::internal::OptimizedCompilationJob"** %3, null
  br i1 %4, label %7, label %5

5:                                                ; preds = %1
  %6 = bitcast %"class.v8::internal::OptimizedCompilationJob"** %3 to i8*
  tail call void @_ZdaPv(i8* %6) #8
  br label %7

7:                                                ; preds = %1, %5
  %8 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 12
  tail call void @_ZN2v84base17ConditionVariableD1Ev(%"class.v8::base::ConditionVariable"* %8) #9
  %9 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 11
  tail call void @_ZN2v84base5MutexD1Ev(%"class.v8::base::Mutex"* %9) #9
  %10 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 8
  tail call void @_ZN2v84base5MutexD1Ev(%"class.v8::base::Mutex"* %10) #9
  %11 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 0, i32 1
  %12 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %11, align 8
  %13 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 1
  %14 = load i64, i64* %13, align 8
  %15 = lshr i64 %14, 9
  %16 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %12, i64 %15
  %17 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 0, i32 2
  %18 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %17, align 8
  %19 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %18, %12
  %20 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %18 to i64
  %21 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %12 to i64
  br i1 %19, label %22, label %24

22:                                               ; preds = %7
  %23 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 2, i32 0, i32 0
  br label %37

24:                                               ; preds = %7
  %25 = load %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %16, align 8
  %26 = and i64 %14, 511
  %27 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %25, i64 %26
  %28 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 2, i32 0, i32 0
  %29 = load i64, i64* %28, align 8
  %30 = add i64 %29, %14
  %31 = lshr i64 %30, 9
  %32 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %12, i64 %31
  %33 = load %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %32, align 8
  %34 = and i64 %30, 511
  %35 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %33, i64 %34
  %36 = icmp eq %"class.v8::internal::OptimizedCompilationJob"** %35, %27
  br i1 %36, label %37, label %43

37:                                               ; preds = %56, %24, %22
  %38 = phi i64* [ %23, %22 ], [ %28, %24 ], [ %28, %56 ]
  store i64 0, i64* %38, align 8
  %39 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %17 to i64*
  %40 = sub i64 %20, %21
  %41 = ashr exact i64 %40, 3
  %42 = icmp ugt i64 %41, 2
  br i1 %42, label %61, label %74

43:                                               ; preds = %24, %56
  %44 = phi %"class.v8::internal::OptimizedCompilationJob"** [ %59, %56 ], [ %27, %24 ]
  %45 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %57, %56 ], [ %16, %24 ]
  %46 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %44, i64 1
  %47 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"** %46 to i64
  %48 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %45 to i64*
  %49 = load i64, i64* %48, align 8
  %50 = sub i64 %47, %49
  %51 = icmp eq i64 %50, 4096
  br i1 %51, label %52, label %56

52:                                               ; preds = %43
  %53 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %45, i64 1
  %54 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %53 to i64*
  %55 = load i64, i64* %54, align 8
  br label %56

56:                                               ; preds = %52, %43
  %57 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %53, %52 ], [ %45, %43 ]
  %58 = phi i64 [ %55, %52 ], [ %47, %43 ]
  %59 = inttoptr i64 %58 to %"class.v8::internal::OptimizedCompilationJob"**
  %60 = icmp eq %"class.v8::internal::OptimizedCompilationJob"** %35, %59
  br i1 %60, label %37, label %43

61:                                               ; preds = %37, %61
  %62 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %66, %61 ], [ %12, %37 ]
  %63 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %62 to i8**
  %64 = load i8*, i8** %63, align 8
  tail call void @_ZdlPv(i8* %64) #8
  %65 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %11, align 8
  %66 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %65, i64 1
  store %"class.v8::internal::OptimizedCompilationJob"*** %66, %"class.v8::internal::OptimizedCompilationJob"**** %11, align 8
  %67 = load i64, i64* %39, align 8
  %68 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %66 to i64
  %69 = sub i64 %67, %68
  %70 = ashr exact i64 %69, 3
  %71 = icmp ugt i64 %70, 2
  br i1 %71, label %61, label %72

72:                                               ; preds = %61
  %73 = inttoptr i64 %67 to %"class.v8::internal::OptimizedCompilationJob"***
  br label %74

74:                                               ; preds = %72, %37
  %75 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %18, %37 ], [ %73, %72 ]
  %76 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %12, %37 ], [ %66, %72 ]
  %77 = phi i64 [ %41, %37 ], [ %70, %72 ]
  switch i64 %77, label %81 [
    i64 1, label %79
    i64 2, label %78
  ]

78:                                               ; preds = %74
  br label %79

79:                                               ; preds = %74, %78
  %80 = phi i64 [ 512, %78 ], [ 256, %74 ]
  store i64 %80, i64* %13, align 8
  br label %81

81:                                               ; preds = %79, %74
  %82 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %76, %75
  br i1 %82, label %101, label %83

83:                                               ; preds = %81, %83
  %84 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %87, %83 ], [ %76, %81 ]
  %85 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %84 to i8**
  %86 = load i8*, i8** %85, align 8
  tail call void @_ZdlPv(i8* %86) #8
  %87 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %84, i64 1
  %88 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %87, %75
  br i1 %88, label %89, label %83

89:                                               ; preds = %83
  %90 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %11, align 8
  %91 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %17, align 8
  %92 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %91, %90
  br i1 %92, label %101, label %93

93:                                               ; preds = %89
  %94 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %90 to i64
  %95 = getelementptr %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %91, i64 -1
  %96 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %95 to i64
  %97 = sub i64 %96, %94
  %98 = lshr i64 %97, 3
  %99 = xor i64 %98, -1
  %100 = getelementptr %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %91, i64 %99
  store %"class.v8::internal::OptimizedCompilationJob"*** %100, %"class.v8::internal::OptimizedCompilationJob"**** %17, align 8
  br label %101

101:                                              ; preds = %93, %89, %81
  %102 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 0, i32 0
  %103 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %102, align 8
  %104 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %103, null
  br i1 %104, label %107, label %105

105:                                              ; preds = %101
  %106 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %103 to i8*
  tail call void @_ZdlPv(i8* %106) #8
  br label %107

107:                                              ; preds = %101, %105
  %108 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 6
  tail call void @_ZN2v84base5MutexD1Ev(%"class.v8::base::Mutex"* %108) #9
  ret void
}

; Function Attrs: nounwind
declare void @_ZN2v84base17ConditionVariableD1Ev(%"class.v8::base::ConditionVariable"*) unnamed_addr #1

; Function Attrs: nounwind
declare void @_ZN2v84base5MutexD1Ev(%"class.v8::base::Mutex"*) unnamed_addr #1

; Function Attrs: nounwind ssp uwtable
define hidden %"class.v8::internal::OptimizedCompilationJob"* @_ZN2v88internal27OptimizingCompileDispatcher9NextInputEPNS0_12LocalIsolateE(%"class.v8::internal::OptimizingCompileDispatcher"*, %"class.v8::internal::LocalIsolate"* nocapture readnone) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 6
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %3) #9
  %4 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 3
  %5 = load i32, i32* %4, align 4
  %6 = icmp eq i32 %5, 0
  br i1 %6, label %21, label %7

7:                                                ; preds = %2
  %8 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 1
  %9 = load %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %8, align 8
  %10 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 4
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 2
  %13 = load i32, i32* %12, align 8
  %14 = srem i32 %11, %13
  %15 = sext i32 %14 to i64
  %16 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %9, i64 %15
  %17 = load %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %16, align 8
  %18 = add nsw i32 %11, 1
  %19 = srem i32 %18, %13
  store i32 %19, i32* %10, align 8
  %20 = add nsw i32 %5, -1
  store i32 %20, i32* %4, align 4
  br label %21

21:                                               ; preds = %2, %7
  %22 = phi %"class.v8::internal::OptimizedCompilationJob"* [ %17, %7 ], [ null, %2 ]
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %3) #9
  ret %"class.v8::internal::OptimizedCompilationJob"* %22
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #2

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #2

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27OptimizingCompileDispatcher11CompileNextEPNS0_23OptimizedCompilationJobEPNS0_12LocalIsolateE(%"class.v8::internal::OptimizingCompileDispatcher"*, %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::LocalIsolate"*) local_unnamed_addr #0 align 2 {
  %4 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"* %1 to i64
  %5 = icmp eq %"class.v8::internal::OptimizedCompilationJob"* %1, null
  br i1 %5, label %56, label %6

6:                                                ; preds = %3
  %7 = getelementptr inbounds %"class.v8::internal::LocalIsolate", %"class.v8::internal::LocalIsolate"* %2, i64 0, i32 6
  %8 = load %"class.v8::internal::RuntimeCallStats"*, %"class.v8::internal::RuntimeCallStats"** %7, align 8
  %9 = tail call i32 @_ZN2v88internal23OptimizedCompilationJob10ExecuteJobEPNS0_16RuntimeCallStatsEPNS0_12LocalIsolateE(%"class.v8::internal::OptimizedCompilationJob"* nonnull %1, %"class.v8::internal::RuntimeCallStats"* %8, %"class.v8::internal::LocalIsolate"* %2) #9
  %10 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 8
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %10) #9
  %11 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 0, i32 2
  %12 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 0, i32 1
  %15 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %14 to i64*
  %16 = load i64, i64* %15, align 8
  %17 = sub i64 %13, %16
  %18 = icmp eq i64 %17, 0
  %19 = shl i64 %17, 6
  %20 = add i64 %19, -1
  %21 = select i1 %18, i64 0, i64 %20
  %22 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 1
  %23 = load i64, i64* %22, align 8
  %24 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 2, i32 0, i32 0
  %25 = load i64, i64* %24, align 8
  %26 = add i64 %25, %23
  %27 = icmp eq i64 %21, %26
  %28 = inttoptr i64 %16 to %"class.v8::internal::OptimizedCompilationJob"***
  %29 = inttoptr i64 %13 to %"class.v8::internal::OptimizedCompilationJob"***
  br i1 %27, label %30, label %37

30:                                               ; preds = %6
  %31 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0
  tail call void @_ZNSt3__15dequeIPN2v88internal23OptimizedCompilationJobENS_9allocatorIS4_EEE19__add_back_capacityEv(%"class.std::__1::deque.1160"* %31) #9
  %32 = load i64, i64* %24, align 8
  %33 = load i64, i64* %22, align 8
  %34 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %14, align 8
  %35 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %11, align 8
  %36 = add i64 %33, %32
  br label %37

37:                                               ; preds = %30, %6
  %38 = phi i64 [ %36, %30 ], [ %26, %6 ]
  %39 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %35, %30 ], [ %29, %6 ]
  %40 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %34, %30 ], [ %28, %6 ]
  %41 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %39, %40
  br i1 %41, label %49, label %42

42:                                               ; preds = %37
  %43 = lshr i64 %38, 9
  %44 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %40, i64 %43
  %45 = load %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %44, align 8
  %46 = and i64 %38, 511
  %47 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %45, i64 %46
  %48 = bitcast %"class.v8::internal::OptimizedCompilationJob"** %47 to i64*
  br label %49

49:                                               ; preds = %37, %42
  %50 = phi i64* [ %48, %42 ], [ null, %37 ]
  store i64 %4, i64* %50, align 8
  %51 = load i64, i64* %24, align 8
  %52 = add i64 %51, 1
  store i64 %52, i64* %24, align 8
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %10) #9
  %53 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 0
  %54 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %53, align 8
  %55 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %54, i64 0, i32 0, i32 6
  tail call void @_ZN2v88internal10StackGuard16RequestInterruptENS1_13InterruptFlagE(%"class.v8::internal::StackGuard"* %55, i32 4) #9
  br label %56

56:                                               ; preds = %3, %49
  ret void
}

declare i32 @_ZN2v88internal23OptimizedCompilationJob10ExecuteJobEPNS0_16RuntimeCallStatsEPNS0_12LocalIsolateE(%"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::RuntimeCallStats"*, %"class.v8::internal::LocalIsolate"*) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27OptimizingCompileDispatcher16FlushOutputQueueEb(%"class.v8::internal::OptimizingCompileDispatcher"*, i1 zeroext) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 8
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %3) #9
  %4 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 2, i32 0, i32 0
  %5 = load i64, i64* %4, align 8
  %6 = icmp eq i64 %5, 0
  br i1 %6, label %33, label %7

7:                                                ; preds = %2
  %8 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 0, i32 1
  %9 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 1
  br label %10

10:                                               ; preds = %7, %30
  %11 = phi i64 [ %5, %7 ], [ %31, %30 ]
  %12 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %8, align 8
  %13 = load i64, i64* %9, align 8
  %14 = lshr i64 %13, 9
  %15 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %12, i64 %14
  %16 = load %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %15, align 8
  %17 = and i64 %13, 511
  %18 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %16, i64 %17
  %19 = load %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %18, align 8
  %20 = add i64 %11, -1
  store i64 %20, i64* %4, align 8
  %21 = add i64 %13, 1
  store i64 %21, i64* %9, align 8
  %22 = icmp ult i64 %21, 1024
  br i1 %22, label %30, label %23

23:                                               ; preds = %10
  %24 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %12 to i8**
  %25 = load i8*, i8** %24, align 8
  tail call void @_ZdlPv(i8* %25) #8
  %26 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %8, align 8
  %27 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %26, i64 1
  store %"class.v8::internal::OptimizedCompilationJob"*** %27, %"class.v8::internal::OptimizedCompilationJob"**** %8, align 8
  %28 = load i64, i64* %9, align 8
  %29 = add i64 %28, -512
  store i64 %29, i64* %9, align 8
  br label %30

30:                                               ; preds = %23, %10
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %3) #9
  tail call fastcc void @_ZN2v88internal12_GLOBAL__N_121DisposeCompilationJobEPNS0_23OptimizedCompilationJobEb(%"class.v8::internal::OptimizedCompilationJob"* %19, i1 zeroext %1)
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %3) #9
  %31 = load i64, i64* %4, align 8
  %32 = icmp eq i64 %31, 0
  br i1 %32, label %33, label %10

33:                                               ; preds = %30, %2
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %3) #9
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @_ZN2v88internal12_GLOBAL__N_121DisposeCompilationJobEPNS0_23OptimizedCompilationJobEb(%"class.v8::internal::OptimizedCompilationJob"*, i1 zeroext) unnamed_addr #0 {
  %3 = alloca %"class.v8::internal::FeedbackVector", align 8
  %4 = alloca %"class.v8::internal::SharedFunctionInfo", align 8
  br i1 %1, label %5, label %120

5:                                                ; preds = %2
  %6 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob", %"class.v8::internal::OptimizedCompilationJob"* %0, i64 0, i32 1
  %7 = load %"class.v8::internal::OptimizedCompilationInfo"*, %"class.v8::internal::OptimizedCompilationInfo"** %6, align 8
  %8 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationInfo", %"class.v8::internal::OptimizedCompilationInfo"* %7, i64 0, i32 6, i32 0, i32 0
  %9 = load i64*, i64** %8, align 8
  %10 = load i64, i64* %9, align 8
  %11 = bitcast %"class.v8::internal::SharedFunctionInfo"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %11) #9
  %12 = add i64 %10, 11
  %13 = inttoptr i64 %12 to i32*
  %14 = load atomic i32, i32* %13 monotonic, align 4
  %15 = and i64 %10, -4294967296
  %16 = zext i32 %14 to i64
  %17 = or i64 %15, %16
  %18 = getelementptr inbounds %"class.v8::internal::SharedFunctionInfo", %"class.v8::internal::SharedFunctionInfo"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %17, i64* %18, align 8
  %19 = call i64 @_ZNK2v88internal18SharedFunctionInfo7GetCodeEv(%"class.v8::internal::SharedFunctionInfo"* nonnull %4) #9
  %20 = add i64 %10, 23
  %21 = inttoptr i64 %20 to i32*
  %22 = trunc i64 %19 to i32
  store atomic volatile i32 %22, i32* %21 release, align 4
  %23 = and i64 %19, 1
  %24 = icmp eq i64 %23, 0
  br i1 %24, label %36, label %25

25:                                               ; preds = %5
  %26 = and i64 %10, -262144
  %27 = or i64 %26, 8
  %28 = inttoptr i64 %27 to i64*
  %29 = load i64, i64* %28, align 8
  %30 = and i64 %29, 262144
  %31 = icmp eq i64 %30, 0
  br i1 %31, label %36, label %32

32:                                               ; preds = %25
  %33 = or i64 %26, 16
  %34 = inttoptr i64 %33 to %"class.v8::internal::Heap"**
  %35 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %34, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %35, i64 %10, i64 %20, i64 %19) #9
  br label %36

36:                                               ; preds = %32, %25, %5
  %37 = and i64 %19, -262144
  %38 = or i64 %37, 8
  %39 = inttoptr i64 %38 to i64*
  %40 = load i64, i64* %39, align 8
  %41 = and i64 %40, 24
  %42 = icmp eq i64 %41, 0
  br i1 %42, label %51, label %43

43:                                               ; preds = %36
  %44 = and i64 %10, -262144
  %45 = or i64 %44, 8
  %46 = inttoptr i64 %45 to i64*
  %47 = load i64, i64* %46, align 8
  %48 = and i64 %47, 24
  %49 = icmp eq i64 %48, 0
  br i1 %49, label %50, label %51

50:                                               ; preds = %43
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %10, i64 %20, i64 %19) #9
  br label %51

51:                                               ; preds = %36, %43, %50
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %11) #9
  %52 = load i64, i64* %9, align 8
  %53 = add i64 %52, 11
  %54 = inttoptr i64 %53 to i32*
  %55 = load atomic i32, i32* %54 monotonic, align 4
  %56 = and i64 %52, -4294967296
  %57 = zext i32 %55 to i64
  %58 = or i64 %56, %57
  %59 = add i64 %58, 3
  %60 = inttoptr i64 %59 to i32*
  %61 = load atomic i32, i32* %60 acquire, align 4
  %62 = zext i32 %61 to i64
  %63 = or i64 %56, %62
  %64 = icmp eq i32 %61, 170
  br i1 %64, label %120, label %65

65:                                               ; preds = %51
  %66 = and i64 %62, 1
  %67 = icmp eq i64 %66, 0
  br i1 %67, label %79, label %68

68:                                               ; preds = %65
  %69 = add i64 %63, -1
  %70 = inttoptr i64 %69 to i32*
  %71 = load atomic i32, i32* %70 monotonic, align 4
  %72 = zext i32 %71 to i64
  %73 = or i64 %56, %72
  %74 = add i64 %73, 7
  %75 = inttoptr i64 %74 to i16*
  %76 = load atomic i16, i16* %75 monotonic, align 2
  %77 = add i16 %76, -157
  %78 = icmp ugt i16 %77, 1
  br i1 %78, label %79, label %120

79:                                               ; preds = %68, %65
  %80 = add i64 %52, 19
  %81 = inttoptr i64 %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = zext i32 %82 to i64
  %84 = or i64 %56, %83
  %85 = add i64 %84, 3
  %86 = inttoptr i64 %85 to i32*
  %87 = load i32, i32* %86, align 4
  %88 = zext i32 %87 to i64
  %89 = or i64 %56, %88
  %90 = add i64 %89, -1
  %91 = inttoptr i64 %90 to i32*
  %92 = load atomic i32, i32* %91 monotonic, align 4
  %93 = zext i32 %92 to i64
  %94 = or i64 %56, %93
  %95 = add i64 %94, 7
  %96 = inttoptr i64 %95 to i16*
  %97 = load atomic i16, i16* %96 monotonic, align 2
  %98 = icmp eq i16 %97, 167
  br i1 %98, label %99, label %120

99:                                               ; preds = %79
  %100 = add i64 %89, 15
  %101 = inttoptr i64 %100 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = and i32 %102, 7
  %104 = icmp eq i32 %103, 1
  br i1 %104, label %105, label %120

105:                                              ; preds = %99
  %106 = load i64, i64* %9, align 8
  %107 = bitcast %"class.v8::internal::FeedbackVector"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %107) #9
  %108 = and i64 %106, -4294967296
  %109 = add i64 %106, 19
  %110 = inttoptr i64 %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = zext i32 %111 to i64
  %113 = or i64 %108, %112
  %114 = add i64 %113, 3
  %115 = inttoptr i64 %114 to i32*
  %116 = load i32, i32* %115, align 4
  %117 = zext i32 %116 to i64
  %118 = or i64 %108, %117
  %119 = getelementptr inbounds %"class.v8::internal::FeedbackVector", %"class.v8::internal::FeedbackVector"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %118, i64* %119, align 8
  call void @_ZN2v88internal14FeedbackVector23ClearOptimizationMarkerEv(%"class.v8::internal::FeedbackVector"* nonnull %3) #9
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %107) #9
  br label %120

120:                                              ; preds = %51, %68, %79, %99, %105, %2
  %121 = icmp eq %"class.v8::internal::OptimizedCompilationJob"* %0, null
  br i1 %121, label %127, label %122

122:                                              ; preds = %120
  %123 = bitcast %"class.v8::internal::OptimizedCompilationJob"* %0 to void (%"class.v8::internal::OptimizedCompilationJob"*)***
  %124 = load void (%"class.v8::internal::OptimizedCompilationJob"*)**, void (%"class.v8::internal::OptimizedCompilationJob"*)*** %123, align 8
  %125 = getelementptr inbounds void (%"class.v8::internal::OptimizedCompilationJob"*)*, void (%"class.v8::internal::OptimizedCompilationJob"*)** %124, i64 1
  %126 = load void (%"class.v8::internal::OptimizedCompilationJob"*)*, void (%"class.v8::internal::OptimizedCompilationJob"*)** %125, align 8
  call void %126(%"class.v8::internal::OptimizedCompilationJob"* nonnull %0) #9
  br label %127

127:                                              ; preds = %122, %120
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27OptimizingCompileDispatcher15FlushInputQueueEv(%"class.v8::internal::OptimizingCompileDispatcher"*) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 6
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %2) #9
  %3 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 3
  %4 = load i32, i32* %3, align 4
  %5 = icmp sgt i32 %4, 0
  br i1 %5, label %6, label %24

6:                                                ; preds = %1
  %7 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 1
  %8 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 4
  %9 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 2
  br label %10

10:                                               ; preds = %6, %10
  %11 = phi i32 [ %4, %6 ], [ %22, %10 ]
  %12 = load %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %7, align 8
  %13 = load i32, i32* %8, align 8
  %14 = load i32, i32* %9, align 8
  %15 = srem i32 %13, %14
  %16 = sext i32 %15 to i64
  %17 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %12, i64 %16
  %18 = load %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %17, align 8
  %19 = add nsw i32 %13, 1
  %20 = srem i32 %19, %14
  store i32 %20, i32* %8, align 8
  %21 = add nsw i32 %11, -1
  store i32 %21, i32* %3, align 4
  tail call fastcc void @_ZN2v88internal12_GLOBAL__N_121DisposeCompilationJobEPNS0_23OptimizedCompilationJobEb(%"class.v8::internal::OptimizedCompilationJob"* %18, i1 zeroext true)
  %22 = load i32, i32* %3, align 4
  %23 = icmp sgt i32 %22, 0
  br i1 %23, label %10, label %24

24:                                               ; preds = %10, %1
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %2) #9
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27OptimizingCompileDispatcher11FlushQueuesENS0_16BlockingBehaviorEb(%"class.v8::internal::OptimizingCompileDispatcher"*, i32, i1 zeroext) local_unnamed_addr #0 align 2 {
  %4 = load i8, i8* @_ZN2v88internal35FLAG_block_concurrent_recompilationE, align 1, !range !2
  %5 = icmp eq i8 %4, 0
  br i1 %5, label %7, label %6

6:                                                ; preds = %3
  tail call void @_ZN2v88internal27OptimizingCompileDispatcher7UnblockEv(%"class.v8::internal::OptimizingCompileDispatcher"* %0)
  br label %7

7:                                                ; preds = %3, %6
  %8 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 6
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %8) #9
  %9 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 3
  %10 = load i32, i32* %9, align 4
  %11 = icmp sgt i32 %10, 0
  br i1 %11, label %12, label %30

12:                                               ; preds = %7
  %13 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 1
  %14 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 4
  %15 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 2
  br label %16

16:                                               ; preds = %16, %12
  %17 = phi i32 [ %10, %12 ], [ %28, %16 ]
  %18 = load %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %13, align 8
  %19 = load i32, i32* %14, align 8
  %20 = load i32, i32* %15, align 8
  %21 = srem i32 %19, %20
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %18, i64 %22
  %24 = load %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %23, align 8
  %25 = add nsw i32 %19, 1
  %26 = srem i32 %25, %20
  store i32 %26, i32* %14, align 8
  %27 = add nsw i32 %17, -1
  store i32 %27, i32* %9, align 4
  tail call fastcc void @_ZN2v88internal12_GLOBAL__N_121DisposeCompilationJobEPNS0_23OptimizedCompilationJobEb(%"class.v8::internal::OptimizedCompilationJob"* %24, i1 zeroext true) #9
  %28 = load i32, i32* %9, align 4
  %29 = icmp sgt i32 %28, 0
  br i1 %29, label %16, label %30

30:                                               ; preds = %16, %7
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %8) #9
  %31 = icmp eq i32 %1, 0
  br i1 %31, label %32, label %43

32:                                               ; preds = %30
  %33 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 11
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %33) #9
  %34 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 10
  %35 = load i32, i32* %34, align 4
  %36 = icmp sgt i32 %35, 0
  br i1 %36, label %37, label %42

37:                                               ; preds = %32
  %38 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 12
  br label %39

39:                                               ; preds = %37, %39
  tail call void @_ZN2v84base17ConditionVariable4WaitEPNS0_5MutexE(%"class.v8::base::ConditionVariable"* %38, %"class.v8::base::Mutex"* %33) #9
  %40 = load i32, i32* %34, align 4
  %41 = icmp sgt i32 %40, 0
  br i1 %41, label %39, label %42

42:                                               ; preds = %39, %32
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %33) #9
  br label %43

43:                                               ; preds = %42, %30
  tail call void @_ZN2v88internal27OptimizingCompileDispatcher16FlushOutputQueueEb(%"class.v8::internal::OptimizingCompileDispatcher"* %0, i1 zeroext %2)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27OptimizingCompileDispatcher7UnblockEv(%"class.v8::internal::OptimizingCompileDispatcher"*) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 9
  %3 = load i32, i32* %2, align 8
  %4 = icmp sgt i32 %3, 0
  br i1 %4, label %5, label %37

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 0
  %7 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 11
  br label %8

8:                                                ; preds = %5, %8
  %9 = tail call %"class.v8::Platform"* @_ZN2v88internal2V818GetCurrentPlatformEv() #9
  %10 = tail call i8* @_Znwm(i64 64) #8
  %11 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %6, align 8
  %12 = bitcast i8* %10 to %"class.v8::internal::CancelableTask"*
  tail call void @_ZN2v88internal14CancelableTaskC2EPNS0_7IsolateE(%"class.v8::internal::CancelableTask"* nonnull %12, %"class.v8::internal::Isolate"* %11) #9
  %13 = bitcast i8* %10 to i32 (...)***
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*], [5 x i8*] }, { [6 x i8*], [5 x i8*] }* @_ZTVN2v88internal27OptimizingCompileDispatcher11CompileTaskE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %13, align 8
  %14 = getelementptr inbounds i8, i8* %10, i64 32
  %15 = bitcast i8* %14 to i32 (...)***
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*], [5 x i8*] }, { [6 x i8*], [5 x i8*] }* @_ZTVN2v88internal27OptimizingCompileDispatcher11CompileTaskE, i64 0, inrange i32 1, i64 2) to i32 (...)**), i32 (...)*** %15, align 8
  %16 = getelementptr inbounds i8, i8* %10, i64 40
  %17 = bitcast i8* %16 to %"class.v8::internal::Isolate"**
  store %"class.v8::internal::Isolate"* %11, %"class.v8::internal::Isolate"** %17, align 8
  %18 = getelementptr inbounds i8, i8* %10, i64 48
  %19 = bitcast i8* %18 to %"class.v8::internal::WorkerThreadRuntimeCallStats"**
  %20 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %11, i64 0, i32 14, i32 0
  %21 = load %"class.v8::internal::Counters"*, %"class.v8::internal::Counters"** %20, align 8
  %22 = getelementptr inbounds %"class.v8::internal::Counters", %"class.v8::internal::Counters"* %21, i64 0, i32 758
  store %"class.v8::internal::WorkerThreadRuntimeCallStats"* %22, %"class.v8::internal::WorkerThreadRuntimeCallStats"** %19, align 8
  %23 = getelementptr inbounds i8, i8* %10, i64 56
  %24 = bitcast i8* %23 to %"class.v8::internal::OptimizingCompileDispatcher"**
  store %"class.v8::internal::OptimizingCompileDispatcher"* %0, %"class.v8::internal::OptimizingCompileDispatcher"** %24, align 8
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %7) #9
  %25 = load %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.v8::internal::OptimizingCompileDispatcher"** %24, align 8
  %26 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %25, i64 0, i32 10
  %27 = load i32, i32* %26, align 4
  %28 = add nsw i32 %27, 1
  store i32 %28, i32* %26, align 4
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %7) #9
  %29 = bitcast i8* %14 to %"class.v8::Task"*
  %30 = bitcast %"class.v8::Platform"* %9 to void (%"class.v8::Platform"*, %"class.v8::Task"*)***
  %31 = load void (%"class.v8::Platform"*, %"class.v8::Task"*)**, void (%"class.v8::Platform"*, %"class.v8::Task"*)*** %30, align 8
  %32 = getelementptr inbounds void (%"class.v8::Platform"*, %"class.v8::Task"*)*, void (%"class.v8::Platform"*, %"class.v8::Task"*)** %31, i64 7
  %33 = load void (%"class.v8::Platform"*, %"class.v8::Task"*)*, void (%"class.v8::Platform"*, %"class.v8::Task"*)** %32, align 8
  tail call void %33(%"class.v8::Platform"* %9, %"class.v8::Task"* %29) #9
  %34 = load i32, i32* %2, align 8
  %35 = add nsw i32 %34, -1
  store i32 %35, i32* %2, align 8
  %36 = icmp sgt i32 %35, 0
  br i1 %36, label %8, label %37

37:                                               ; preds = %8, %1
  ret void
}

declare void @_ZN2v84base17ConditionVariable4WaitEPNS0_5MutexE(%"class.v8::base::ConditionVariable"*, %"class.v8::base::Mutex"*) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27OptimizingCompileDispatcher5FlushENS0_16BlockingBehaviorE(%"class.v8::internal::OptimizingCompileDispatcher"*, i32) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 0
  %4 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %3, align 8
  %5 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %4, i64 0, i32 31
  %6 = bitcast %"struct.v8::internal::HandleScopeData"* %5 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %4, i64 0, i32 31, i32 1
  %9 = load i64*, i64** %8, align 8
  %10 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %4, i64 0, i32 31, i32 2
  %11 = load i32, i32* %10, align 8
  %12 = add nsw i32 %11, 1
  store i32 %12, i32* %10, align 8
  tail call void @_ZN2v88internal27OptimizingCompileDispatcher11FlushQueuesENS0_16BlockingBehaviorEb(%"class.v8::internal::OptimizingCompileDispatcher"* %0, i32 %1, i1 zeroext true)
  %13 = load i8, i8* @_ZN2v88internal35FLAG_trace_concurrent_recompilationE, align 1, !range !2
  %14 = icmp eq i8 %13, 0
  br i1 %14, label %18, label %15

15:                                               ; preds = %2
  %16 = icmp eq i32 %1, 0
  %17 = select i1 %16, i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.1, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.2, i64 0, i64 0)
  tail call void (i8*, ...) @_ZN2v88internal6PrintFEPKcz(i8* getelementptr inbounds ([58 x i8], [58 x i8]* @.str, i64 0, i64 0), i8* %17) #9
  br label %18

18:                                               ; preds = %2, %15
  %19 = icmp eq %"class.v8::internal::Isolate"* %4, null
  br i1 %19, label %33, label %20

20:                                               ; preds = %18
  %21 = inttoptr i64 %7 to i64*
  %22 = getelementptr inbounds %"struct.v8::internal::HandleScopeData", %"struct.v8::internal::HandleScopeData"* %5, i64 0, i32 0
  %23 = load i64*, i64** %22, align 8
  store i64 %7, i64* %6, align 8
  %24 = load i32, i32* %10, align 8
  %25 = add nsw i32 %24, -1
  store i32 %25, i32* %10, align 8
  %26 = load i64*, i64** %8, align 8
  %27 = icmp eq i64* %26, %9
  br i1 %27, label %30, label %28

28:                                               ; preds = %20
  store i64* %9, i64** %8, align 8
  tail call void @_ZN2v88internal11HandleScope16DeleteExtensionsEPNS0_7IsolateE(%"class.v8::internal::Isolate"* nonnull %4) #9
  %29 = load i64*, i64** %22, align 8
  br label %30

30:                                               ; preds = %28, %20
  %31 = phi i64* [ %29, %28 ], [ %21, %20 ]
  %32 = phi i64* [ %9, %28 ], [ %23, %20 ]
  tail call void @_ZN2v88internal11HandleScope8ZapRangeEPmS2_(i64* %31, i64* %32) #9
  br label %33

33:                                               ; preds = %18, %30
  ret void
}

declare void @_ZN2v88internal6PrintFEPKcz(i8*, ...) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27OptimizingCompileDispatcher4StopEv(%"class.v8::internal::OptimizingCompileDispatcher"*) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 0
  %3 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %2, align 8
  %4 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %3, i64 0, i32 31
  %5 = bitcast %"struct.v8::internal::HandleScopeData"* %4 to i64*
  %6 = load i64, i64* %5, align 8
  %7 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %3, i64 0, i32 31, i32 1
  %8 = load i64*, i64** %7, align 8
  %9 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %3, i64 0, i32 31, i32 2
  %10 = load i32, i32* %9, align 8
  %11 = add nsw i32 %10, 1
  store i32 %11, i32* %9, align 8
  tail call void @_ZN2v88internal27OptimizingCompileDispatcher11FlushQueuesENS0_16BlockingBehaviorEb(%"class.v8::internal::OptimizingCompileDispatcher"* %0, i32 0, i1 zeroext false)
  %12 = icmp eq %"class.v8::internal::Isolate"* %3, null
  br i1 %12, label %26, label %13

13:                                               ; preds = %1
  %14 = inttoptr i64 %6 to i64*
  %15 = getelementptr inbounds %"struct.v8::internal::HandleScopeData", %"struct.v8::internal::HandleScopeData"* %4, i64 0, i32 0
  %16 = load i64*, i64** %15, align 8
  store i64 %6, i64* %5, align 8
  %17 = load i32, i32* %9, align 8
  %18 = add nsw i32 %17, -1
  store i32 %18, i32* %9, align 8
  %19 = load i64*, i64** %7, align 8
  %20 = icmp eq i64* %19, %8
  br i1 %20, label %23, label %21

21:                                               ; preds = %13
  store i64* %8, i64** %7, align 8
  tail call void @_ZN2v88internal11HandleScope16DeleteExtensionsEPNS0_7IsolateE(%"class.v8::internal::Isolate"* nonnull %3) #9
  %22 = load i64*, i64** %15, align 8
  br label %23

23:                                               ; preds = %21, %13
  %24 = phi i64* [ %22, %21 ], [ %14, %13 ]
  %25 = phi i64* [ %8, %21 ], [ %16, %13 ]
  tail call void @_ZN2v88internal11HandleScope8ZapRangeEPmS2_(i64* %24, i64* %25) #9
  br label %26

26:                                               ; preds = %1, %23
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27OptimizingCompileDispatcher25InstallOptimizedFunctionsEv(%"class.v8::internal::OptimizingCompileDispatcher"*) local_unnamed_addr #0 align 2 {
  %2 = alloca %"class.v8::internal::Handle<v8::internal::JSFunction>::ObjectRef", align 8
  %3 = alloca %"class.v8::internal::Handle<v8::internal::JSFunction>::ObjectRef", align 8
  %4 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 0
  %5 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %4, align 8
  %6 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %5, i64 0, i32 31
  %7 = bitcast %"struct.v8::internal::HandleScopeData"* %6 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %5, i64 0, i32 31, i32 1
  %10 = load i64*, i64** %9, align 8
  %11 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %5, i64 0, i32 31, i32 2
  %12 = load i32, i32* %11, align 8
  %13 = add nsw i32 %12, 1
  store i32 %13, i32* %11, align 8
  %14 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 8
  call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %14) #9
  %15 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 2, i32 0, i32 0
  %16 = load i64, i64* %15, align 8
  %17 = icmp eq i64 %16, 0
  br i1 %17, label %98, label %18

18:                                               ; preds = %1
  %19 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 0, i32 1
  %20 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 7, i32 0, i32 0, i32 1
  %21 = bitcast %"class.v8::internal::Handle<v8::internal::JSFunction>::ObjectRef"* %2 to i8*
  %22 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::JSFunction>::ObjectRef", %"class.v8::internal::Handle<v8::internal::JSFunction>::ObjectRef"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %23 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::JSFunction>::ObjectRef", %"class.v8::internal::Handle<v8::internal::JSFunction>::ObjectRef"* %2, i64 0, i32 0
  %24 = bitcast %"class.v8::internal::Handle<v8::internal::JSFunction>::ObjectRef"* %3 to i8*
  %25 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::JSFunction>::ObjectRef", %"class.v8::internal::Handle<v8::internal::JSFunction>::ObjectRef"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %26 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::JSFunction>::ObjectRef", %"class.v8::internal::Handle<v8::internal::JSFunction>::ObjectRef"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  br label %27

27:                                               ; preds = %18, %95
  %28 = phi i64 [ %16, %18 ], [ %96, %95 ]
  %29 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %19, align 8
  %30 = load i64, i64* %20, align 8
  %31 = lshr i64 %30, 9
  %32 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %29, i64 %31
  %33 = load %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %32, align 8
  %34 = and i64 %30, 511
  %35 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %33, i64 %34
  %36 = load %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %35, align 8
  %37 = add i64 %28, -1
  store i64 %37, i64* %15, align 8
  %38 = add i64 %30, 1
  store i64 %38, i64* %20, align 8
  %39 = icmp ult i64 %38, 1024
  br i1 %39, label %47, label %40

40:                                               ; preds = %27
  %41 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %29 to i8**
  %42 = load i8*, i8** %41, align 8
  call void @_ZdlPv(i8* %42) #8
  %43 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %19, align 8
  %44 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %43, i64 1
  store %"class.v8::internal::OptimizedCompilationJob"*** %44, %"class.v8::internal::OptimizedCompilationJob"**** %19, align 8
  %45 = load i64, i64* %20, align 8
  %46 = add i64 %45, -512
  store i64 %46, i64* %20, align 8
  br label %47

47:                                               ; preds = %27, %40
  call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %14) #9
  %48 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob", %"class.v8::internal::OptimizedCompilationJob"* %36, i64 0, i32 1
  %49 = load %"class.v8::internal::OptimizedCompilationInfo"*, %"class.v8::internal::OptimizedCompilationInfo"** %48, align 8
  %50 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationInfo", %"class.v8::internal::OptimizedCompilationInfo"* %49, i64 0, i32 6, i32 0, i32 0
  %51 = load i64*, i64** %50, align 8
  %52 = load i64, i64* %51, align 8
  %53 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %4, align 8
  %54 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %53, i64 0, i32 31, i32 4
  %55 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %54, align 8
  %56 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %55, null
  br i1 %56, label %60, label %57

57:                                               ; preds = %47
  %58 = call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %55, i64 %52) #9
  %59 = load i64, i64* %58, align 8
  br label %73

60:                                               ; preds = %47
  %61 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %53, i64 0, i32 31, i32 0
  %62 = load i64*, i64** %61, align 8
  %63 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %53, i64 0, i32 31, i32 1
  %64 = load i64*, i64** %63, align 8
  %65 = icmp eq i64* %62, %64
  br i1 %65, label %66, label %68

66:                                               ; preds = %60
  %67 = call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %53) #9
  br label %68

68:                                               ; preds = %66, %60
  %69 = phi i64* [ %67, %66 ], [ %62, %60 ]
  %70 = ptrtoint i64* %69 to i64
  %71 = add i64 %70, 8
  %72 = inttoptr i64 %71 to i64*
  store i64* %72, i64** %61, align 8
  store i64 %52, i64* %69, align 8
  br label %73

73:                                               ; preds = %57, %68
  %74 = phi i64 [ %59, %57 ], [ %52, %68 ]
  %75 = phi i64* [ %58, %57 ], [ %69, %68 ]
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %21) #9
  store i64 %74, i64* %22, align 8
  %76 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationInfo", %"class.v8::internal::OptimizedCompilationInfo"* %49, i64 0, i32 2
  %77 = load i32, i32* %76, align 8
  %78 = call zeroext i1 @_ZNK2v88internal10JSFunction20HasAvailableCodeKindENS0_8CodeKindE(%"class.v8::internal::JSFunction"* nonnull %23, i32 %77) #9
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %21) #9
  br i1 %78, label %79, label %92

79:                                               ; preds = %73
  %80 = load i8, i8* @_ZN2v88internal35FLAG_trace_concurrent_recompilationE, align 1, !range !2
  %81 = icmp eq i8 %80, 0
  br i1 %81, label %85, label %82

82:                                               ; preds = %79
  call void (i8*, ...) @_ZN2v88internal6PrintFEPKcz(i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.3, i64 0, i64 0)) #9
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %24) #9
  %83 = load i64, i64* %75, align 8
  store i64 %83, i64* %25, align 8
  %84 = load %struct._IO_FILE*, %struct._IO_FILE** @stdout, align 8
  call void @_ZNK2v88internal6Object10ShortPrintEP8_IO_FILE(%"class.v8::internal::Object"* nonnull %26, %struct._IO_FILE* %84) #9
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %24) #9
  call void (i8*, ...) @_ZN2v88internal6PrintFEPKcz(i8* getelementptr inbounds ([36 x i8], [36 x i8]* @.str.4, i64 0, i64 0)) #9
  br label %85

85:                                               ; preds = %79, %82
  %86 = icmp eq %"class.v8::internal::OptimizedCompilationJob"* %36, null
  br i1 %86, label %95, label %87

87:                                               ; preds = %85
  %88 = bitcast %"class.v8::internal::OptimizedCompilationJob"* %36 to void (%"class.v8::internal::OptimizedCompilationJob"*)***
  %89 = load void (%"class.v8::internal::OptimizedCompilationJob"*)**, void (%"class.v8::internal::OptimizedCompilationJob"*)*** %88, align 8
  %90 = getelementptr inbounds void (%"class.v8::internal::OptimizedCompilationJob"*)*, void (%"class.v8::internal::OptimizedCompilationJob"*)** %89, i64 1
  %91 = load void (%"class.v8::internal::OptimizedCompilationJob"*)*, void (%"class.v8::internal::OptimizedCompilationJob"*)** %90, align 8
  call void %91(%"class.v8::internal::OptimizedCompilationJob"* nonnull %36) #9
  br label %95

92:                                               ; preds = %73
  %93 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %4, align 8
  %94 = call zeroext i1 @_ZN2v88internal8Compiler31FinalizeOptimizedCompilationJobEPNS0_23OptimizedCompilationJobEPNS0_7IsolateE(%"class.v8::internal::OptimizedCompilationJob"* %36, %"class.v8::internal::Isolate"* %93) #9
  br label %95

95:                                               ; preds = %92, %85, %87
  call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %14) #9
  %96 = load i64, i64* %15, align 8
  %97 = icmp eq i64 %96, 0
  br i1 %97, label %98, label %27

98:                                               ; preds = %95, %1
  call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %14) #9
  %99 = icmp eq %"class.v8::internal::Isolate"* %5, null
  br i1 %99, label %113, label %100

100:                                              ; preds = %98
  %101 = inttoptr i64 %8 to i64*
  %102 = getelementptr inbounds %"struct.v8::internal::HandleScopeData", %"struct.v8::internal::HandleScopeData"* %6, i64 0, i32 0
  %103 = load i64*, i64** %102, align 8
  store i64 %8, i64* %7, align 8
  %104 = load i32, i32* %11, align 8
  %105 = add nsw i32 %104, -1
  store i32 %105, i32* %11, align 8
  %106 = load i64*, i64** %9, align 8
  %107 = icmp eq i64* %106, %10
  br i1 %107, label %110, label %108

108:                                              ; preds = %100
  store i64* %10, i64** %9, align 8
  call void @_ZN2v88internal11HandleScope16DeleteExtensionsEPNS0_7IsolateE(%"class.v8::internal::Isolate"* nonnull %5) #9
  %109 = load i64*, i64** %102, align 8
  br label %110

110:                                              ; preds = %108, %100
  %111 = phi i64* [ %109, %108 ], [ %101, %100 ]
  %112 = phi i64* [ %10, %108 ], [ %103, %100 ]
  call void @_ZN2v88internal11HandleScope8ZapRangeEPmS2_(i64* %111, i64* %112) #9
  br label %113

113:                                              ; preds = %98, %110
  ret void
}

declare zeroext i1 @_ZNK2v88internal10JSFunction20HasAvailableCodeKindENS0_8CodeKindE(%"class.v8::internal::JSFunction"*, i32) local_unnamed_addr #3

declare void @_ZNK2v88internal6Object10ShortPrintEP8_IO_FILE(%"class.v8::internal::Object"*, %struct._IO_FILE*) local_unnamed_addr #3

declare zeroext i1 @_ZN2v88internal8Compiler31FinalizeOptimizedCompilationJobEPNS0_23OptimizedCompilationJobEPNS0_7IsolateE(%"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::Isolate"*) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal27OptimizingCompileDispatcher20QueueForOptimizationEPNS0_23OptimizedCompilationJobE(%"class.v8::internal::OptimizingCompileDispatcher"*, %"class.v8::internal::OptimizedCompilationJob"*) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 6
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %3) #9
  %4 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 1
  %5 = load %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %4, align 8
  %6 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 3
  %7 = load i32, i32* %6, align 4
  %8 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 4
  %9 = load i32, i32* %8, align 8
  %10 = add nsw i32 %9, %7
  %11 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 2
  %12 = load i32, i32* %11, align 8
  %13 = srem i32 %10, %12
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %5, i64 %14
  store %"class.v8::internal::OptimizedCompilationJob"* %1, %"class.v8::internal::OptimizedCompilationJob"** %15, align 8
  %16 = load i32, i32* %6, align 4
  %17 = add nsw i32 %16, 1
  store i32 %17, i32* %6, align 4
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %3) #9
  %18 = load i8, i8* @_ZN2v88internal35FLAG_block_concurrent_recompilationE, align 1, !range !2
  %19 = icmp eq i8 %18, 0
  br i1 %19, label %24, label %20

20:                                               ; preds = %2
  %21 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 9
  %22 = load i32, i32* %21, align 8
  %23 = add nsw i32 %22, 1
  store i32 %23, i32* %21, align 8
  br label %52

24:                                               ; preds = %2
  %25 = tail call %"class.v8::Platform"* @_ZN2v88internal2V818GetCurrentPlatformEv() #9
  %26 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 0
  %27 = tail call i8* @_Znwm(i64 64) #8
  %28 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %26, align 8
  %29 = bitcast i8* %27 to %"class.v8::internal::CancelableTask"*
  tail call void @_ZN2v88internal14CancelableTaskC2EPNS0_7IsolateE(%"class.v8::internal::CancelableTask"* nonnull %29, %"class.v8::internal::Isolate"* %28) #9
  %30 = bitcast i8* %27 to i32 (...)***
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*], [5 x i8*] }, { [6 x i8*], [5 x i8*] }* @_ZTVN2v88internal27OptimizingCompileDispatcher11CompileTaskE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %30, align 8
  %31 = getelementptr inbounds i8, i8* %27, i64 32
  %32 = bitcast i8* %31 to i32 (...)***
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*], [5 x i8*] }, { [6 x i8*], [5 x i8*] }* @_ZTVN2v88internal27OptimizingCompileDispatcher11CompileTaskE, i64 0, inrange i32 1, i64 2) to i32 (...)**), i32 (...)*** %32, align 8
  %33 = getelementptr inbounds i8, i8* %27, i64 40
  %34 = bitcast i8* %33 to %"class.v8::internal::Isolate"**
  store %"class.v8::internal::Isolate"* %28, %"class.v8::internal::Isolate"** %34, align 8
  %35 = getelementptr inbounds i8, i8* %27, i64 48
  %36 = bitcast i8* %35 to %"class.v8::internal::WorkerThreadRuntimeCallStats"**
  %37 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %28, i64 0, i32 14, i32 0
  %38 = load %"class.v8::internal::Counters"*, %"class.v8::internal::Counters"** %37, align 8
  %39 = getelementptr inbounds %"class.v8::internal::Counters", %"class.v8::internal::Counters"* %38, i64 0, i32 758
  store %"class.v8::internal::WorkerThreadRuntimeCallStats"* %39, %"class.v8::internal::WorkerThreadRuntimeCallStats"** %36, align 8
  %40 = getelementptr inbounds i8, i8* %27, i64 56
  %41 = bitcast i8* %40 to %"class.v8::internal::OptimizingCompileDispatcher"**
  store %"class.v8::internal::OptimizingCompileDispatcher"* %0, %"class.v8::internal::OptimizingCompileDispatcher"** %41, align 8
  %42 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %0, i64 0, i32 11
  tail call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %42) #9
  %43 = load %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.v8::internal::OptimizingCompileDispatcher"** %41, align 8
  %44 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %43, i64 0, i32 10
  %45 = load i32, i32* %44, align 4
  %46 = add nsw i32 %45, 1
  store i32 %46, i32* %44, align 4
  tail call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %42) #9
  %47 = bitcast i8* %31 to %"class.v8::Task"*
  %48 = bitcast %"class.v8::Platform"* %25 to void (%"class.v8::Platform"*, %"class.v8::Task"*)***
  %49 = load void (%"class.v8::Platform"*, %"class.v8::Task"*)**, void (%"class.v8::Platform"*, %"class.v8::Task"*)*** %48, align 8
  %50 = getelementptr inbounds void (%"class.v8::Platform"*, %"class.v8::Task"*)*, void (%"class.v8::Platform"*, %"class.v8::Task"*)** %49, i64 7
  %51 = load void (%"class.v8::Platform"*, %"class.v8::Task"*)*, void (%"class.v8::Platform"*, %"class.v8::Task"*)** %50, align 8
  tail call void %51(%"class.v8::Platform"* %25, %"class.v8::Task"* %47) #9
  br label %52

52:                                               ; preds = %24, %20
  ret void
}

declare %"class.v8::Platform"* @_ZN2v88internal2V818GetCurrentPlatformEv() local_unnamed_addr #3

; Function Attrs: nobuiltin nounwind
declare void @_ZdlPv(i8*) local_unnamed_addr #4

declare void @_ZN2v88internal10StackGuard16RequestInterruptENS1_13InterruptFlagE(%"class.v8::internal::StackGuard"*, i32) local_unnamed_addr #3

declare i64 @_ZNK2v88internal18SharedFunctionInfo7GetCodeEv(%"class.v8::internal::SharedFunctionInfo"*) local_unnamed_addr #3

declare void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"*, i64, i64, i64) local_unnamed_addr #3

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #2

declare void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64, i64, i64) local_unnamed_addr #3

declare void @_ZN2v88internal14FeedbackVector23ClearOptimizationMarkerEv(%"class.v8::internal::FeedbackVector"*) local_unnamed_addr #3

declare void @_ZN2v88internal11HandleScope16DeleteExtensionsEPNS0_7IsolateE(%"class.v8::internal::Isolate"*) local_unnamed_addr #3

declare void @_ZN2v88internal11HandleScope8ZapRangeEPmS2_(i64*, i64*) local_unnamed_addr #3

declare void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"*) local_unnamed_addr #3

declare void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"*) local_unnamed_addr #3

declare i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"*, i64) local_unnamed_addr #3

declare i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"*) local_unnamed_addr #3

; Function Attrs: nobuiltin nounwind
declare void @_ZdaPv(i8*) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNSt3__15dequeIPN2v88internal23OptimizedCompilationJobENS_9allocatorIS4_EEE19__add_back_capacityEv(%"class.std::__1::deque.1160"*) local_unnamed_addr #0 comdat align 2 {
  %2 = alloca %"class.v8::internal::OptimizedCompilationJob"**, align 8
  %3 = alloca %"class.v8::internal::OptimizedCompilationJob"**, align 8
  %4 = getelementptr inbounds %"class.std::__1::deque.1160", %"class.std::__1::deque.1160"* %0, i64 0, i32 0, i32 1
  %5 = load i64, i64* %4, align 8
  %6 = icmp ugt i64 %5, 511
  br i1 %6, label %7, label %161

7:                                                ; preds = %1
  %8 = add i64 %5, -512
  store i64 %8, i64* %4, align 8
  %9 = getelementptr inbounds %"class.std::__1::deque.1160", %"class.std::__1::deque.1160"* %0, i64 0, i32 0, i32 0, i32 1
  %10 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %9, align 8
  %11 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %10 to i64*
  %12 = load i64, i64* %11, align 8
  %13 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %10, i64 1
  store %"class.v8::internal::OptimizedCompilationJob"*** %13, %"class.v8::internal::OptimizedCompilationJob"**** %9, align 8
  %14 = getelementptr inbounds %"class.std::__1::deque.1160", %"class.std::__1::deque.1160"* %0, i64 0, i32 0, i32 0, i32 2
  %15 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %14, align 8
  %16 = getelementptr inbounds %"class.std::__1::deque.1160", %"class.std::__1::deque.1160"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0
  %17 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %16, align 8
  %18 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %15, %17
  %19 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %17 to i64
  %20 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %15 to i64*
  br i1 %18, label %21, label %157

21:                                               ; preds = %7
  %22 = getelementptr inbounds %"class.std::__1::deque.1160", %"class.std::__1::deque.1160"* %0, i64 0, i32 0, i32 0, i32 0
  %23 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %22, align 8
  %24 = icmp ugt %"class.v8::internal::OptimizedCompilationJob"*** %13, %23
  %25 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %23 to i64
  br i1 %24, label %26, label %46

26:                                               ; preds = %21
  %27 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %13 to i64
  %28 = sub i64 %27, %25
  %29 = ashr exact i64 %28, 3
  %30 = add nsw i64 %29, 1
  %31 = sdiv i64 %30, -2
  %32 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %13, i64 %31
  %33 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %15 to i64
  %34 = sub i64 %33, %27
  %35 = ashr exact i64 %34, 3
  %36 = icmp eq i64 %34, 0
  br i1 %36, label %41, label %37

37:                                               ; preds = %26
  %38 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %32 to i8*
  %39 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %13 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 8 %38, i8* align 8 %39, i64 %34, i1 false) #9
  %40 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %9, align 8
  br label %41

41:                                               ; preds = %37, %26
  %42 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %13, %26 ], [ %40, %37 ]
  %43 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %32, i64 %35
  store %"class.v8::internal::OptimizedCompilationJob"*** %43, %"class.v8::internal::OptimizedCompilationJob"**** %14, align 8
  %44 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %42, i64 %31
  store %"class.v8::internal::OptimizedCompilationJob"*** %44, %"class.v8::internal::OptimizedCompilationJob"**** %9, align 8
  %45 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %43 to i64*
  br label %157

46:                                               ; preds = %21
  %47 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %16 to i64*
  %48 = bitcast %"class.std::__1::deque.1160"* %0 to i64*
  %49 = sub i64 %19, %25
  %50 = ashr exact i64 %49, 2
  %51 = icmp eq i64 %49, 0
  %52 = select i1 %51, i64 1, i64 %50
  %53 = icmp ugt i64 %52, 2305843009213693951
  br i1 %53, label %54, label %55

54:                                               ; preds = %46
  tail call void @abort() #10
  unreachable

55:                                               ; preds = %46
  %56 = lshr i64 %52, 2
  %57 = shl i64 %52, 3
  %58 = tail call i8* @_Znwm(i64 %57) #8
  %59 = bitcast i8* %58 to %"class.v8::internal::OptimizedCompilationJob"***
  %60 = ptrtoint i8* %58 to i64
  %61 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %59, i64 %56
  %62 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %61 to i64
  %63 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %59, i64 %52
  %64 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %63 to i64
  %65 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %13 to i64
  %66 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %15 to i64
  %67 = sub i64 %66, %65
  %68 = ashr exact i64 %67, 3
  %69 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %61, i64 %68
  %70 = icmp eq i64 %67, 0
  br i1 %70, label %146, label %71

71:                                               ; preds = %55
  %72 = add i64 %67, -8
  %73 = lshr i64 %72, 3
  %74 = add nuw nsw i64 %73, 1
  %75 = and i64 %74, 7
  %76 = icmp eq i64 %75, 0
  br i1 %76, label %92, label %77

77:                                               ; preds = %71, %77
  %78 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %85, %77 ], [ %61, %71 ]
  %79 = phi i64 [ %86, %77 ], [ %62, %71 ]
  %80 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %87, %77 ], [ %13, %71 ]
  %81 = phi i64 [ %88, %77 ], [ %75, %71 ]
  %82 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %80 to i64*
  %83 = load i64, i64* %82, align 8
  %84 = inttoptr i64 %79 to i64*
  store i64 %83, i64* %84, align 8
  %85 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %78, i64 1
  %86 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %85 to i64
  %87 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %80, i64 1
  %88 = add i64 %81, -1
  %89 = icmp eq i64 %88, 0
  br i1 %89, label %90, label %77, !llvm.loop !3

90:                                               ; preds = %77
  %91 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %85 to i64
  br label %92

92:                                               ; preds = %71, %90
  %93 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %61, %71 ], [ %85, %90 ]
  %94 = phi i64 [ %62, %71 ], [ %91, %90 ]
  %95 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %13, %71 ], [ %87, %90 ]
  %96 = icmp ult i64 %72, 56
  br i1 %96, label %143, label %97

97:                                               ; preds = %92, %97
  %98 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %139, %97 ], [ %93, %92 ]
  %99 = phi i64 [ %140, %97 ], [ %94, %92 ]
  %100 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %141, %97 ], [ %95, %92 ]
  %101 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %100 to i64*
  %102 = load i64, i64* %101, align 8
  %103 = inttoptr i64 %99 to i64*
  store i64 %102, i64* %103, align 8
  %104 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %98, i64 1
  %105 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %100, i64 1
  %106 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %105 to i64*
  %107 = load i64, i64* %106, align 8
  %108 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %104 to i64*
  store i64 %107, i64* %108, align 8
  %109 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %98, i64 2
  %110 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %100, i64 2
  %111 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %110 to i64*
  %112 = load i64, i64* %111, align 8
  %113 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %109 to i64*
  store i64 %112, i64* %113, align 8
  %114 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %98, i64 3
  %115 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %100, i64 3
  %116 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %115 to i64*
  %117 = load i64, i64* %116, align 8
  %118 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %114 to i64*
  store i64 %117, i64* %118, align 8
  %119 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %98, i64 4
  %120 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %100, i64 4
  %121 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %120 to i64*
  %122 = load i64, i64* %121, align 8
  %123 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %119 to i64*
  store i64 %122, i64* %123, align 8
  %124 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %98, i64 5
  %125 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %100, i64 5
  %126 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %125 to i64*
  %127 = load i64, i64* %126, align 8
  %128 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %124 to i64*
  store i64 %127, i64* %128, align 8
  %129 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %98, i64 6
  %130 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %100, i64 6
  %131 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %130 to i64*
  %132 = load i64, i64* %131, align 8
  %133 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %129 to i64*
  store i64 %132, i64* %133, align 8
  %134 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %98, i64 7
  %135 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %100, i64 7
  %136 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %135 to i64*
  %137 = load i64, i64* %136, align 8
  %138 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %134 to i64*
  store i64 %137, i64* %138, align 8
  %139 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %98, i64 8
  %140 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %139 to i64
  %141 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %100, i64 8
  %142 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %69, %139
  br i1 %142, label %143, label %97

143:                                              ; preds = %97, %92
  %144 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %69 to i64
  %145 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %22, align 8
  br label %146

146:                                              ; preds = %143, %55
  %147 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %145, %143 ], [ %23, %55 ]
  %148 = phi i64 [ %144, %143 ], [ %62, %55 ]
  store i64 %60, i64* %48, align 8
  %149 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %9 to i64*
  store i64 %62, i64* %149, align 8
  %150 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %14 to i64*
  store i64 %148, i64* %150, align 8
  store i64 %64, i64* %47, align 8
  %151 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %147, null
  %152 = inttoptr i64 %148 to i64*
  br i1 %151, label %157, label %153

153:                                              ; preds = %146
  %154 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %147 to i8*
  tail call void @_ZdlPv(i8* %154) #8
  %155 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %14 to i64**
  %156 = load i64*, i64** %155, align 8
  br label %157

157:                                              ; preds = %7, %41, %146, %153
  %158 = phi i64* [ %156, %153 ], [ %152, %146 ], [ %45, %41 ], [ %20, %7 ]
  store i64 %12, i64* %158, align 8
  %159 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %14, align 8
  %160 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %159, i64 1
  store %"class.v8::internal::OptimizedCompilationJob"*** %160, %"class.v8::internal::OptimizedCompilationJob"**** %14, align 8
  br label %549

161:                                              ; preds = %1
  %162 = getelementptr inbounds %"class.std::__1::deque.1160", %"class.std::__1::deque.1160"* %0, i64 0, i32 0, i32 0
  %163 = getelementptr inbounds %"class.std::__1::deque.1160", %"class.std::__1::deque.1160"* %0, i64 0, i32 0, i32 0, i32 2
  %164 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %163 to i64*
  %165 = load i64, i64* %164, align 8
  %166 = getelementptr inbounds %"class.std::__1::deque.1160", %"class.std::__1::deque.1160"* %0, i64 0, i32 0, i32 0, i32 1
  %167 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %166 to i64*
  %168 = load i64, i64* %167, align 8
  %169 = sub i64 %165, %168
  %170 = ashr exact i64 %169, 3
  %171 = getelementptr inbounds %"class.std::__1::deque.1160", %"class.std::__1::deque.1160"* %0, i64 0, i32 0, i32 0, i32 3, i32 0, i32 0
  %172 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %171 to i64*
  %173 = load i64, i64* %172, align 8
  %174 = bitcast %"class.std::__1::deque.1160"* %0 to i64*
  %175 = load i64, i64* %174, align 8
  %176 = sub i64 %173, %175
  %177 = ashr exact i64 %176, 3
  %178 = icmp ult i64 %170, %177
  %179 = inttoptr i64 %165 to %"class.v8::internal::OptimizedCompilationJob"***
  %180 = inttoptr i64 %168 to %"class.v8::internal::OptimizedCompilationJob"***
  br i1 %178, label %181, label %336

181:                                              ; preds = %161
  %182 = icmp eq i64 %173, %165
  br i1 %182, label %187, label %183

183:                                              ; preds = %181
  %184 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %184) #9
  %185 = tail call i8* @_Znwm(i64 4096) #8
  %186 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %2 to i8**
  store i8* %185, i8** %186, align 8
  call void @_ZNSt3__114__split_bufferIPPN2v88internal23OptimizedCompilationJobENS_9allocatorIS5_EEE9push_backEOS5_(%"struct.std::__1::__split_buffer.1162"* %162, %"class.v8::internal::OptimizedCompilationJob"*** nonnull dereferenceable(8) %2)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %184) #9
  br label %549

187:                                              ; preds = %181
  %188 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %188) #9
  %189 = tail call i8* @_Znwm(i64 4096) #8
  %190 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %3 to i8**
  store i8* %189, i8** %190, align 8
  call void @_ZNSt3__114__split_bufferIPPN2v88internal23OptimizedCompilationJobENS_9allocatorIS5_EEE10push_frontEOS5_(%"struct.std::__1::__split_buffer.1162"* %162, %"class.v8::internal::OptimizedCompilationJob"*** nonnull dereferenceable(8) %3)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %188) #9
  %191 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %166, align 8
  %192 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %191 to i64*
  %193 = load i64, i64* %192, align 8
  %194 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %191, i64 1
  store %"class.v8::internal::OptimizedCompilationJob"*** %194, %"class.v8::internal::OptimizedCompilationJob"**** %166, align 8
  %195 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %163, align 8
  %196 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %171, align 8
  %197 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %195, %196
  %198 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %196 to i64
  %199 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %195 to i64*
  br i1 %197, label %200, label %332

200:                                              ; preds = %187
  %201 = getelementptr inbounds %"class.std::__1::deque.1160", %"class.std::__1::deque.1160"* %0, i64 0, i32 0, i32 0, i32 0
  %202 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %201, align 8
  %203 = icmp ugt %"class.v8::internal::OptimizedCompilationJob"*** %194, %202
  %204 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %202 to i64
  br i1 %203, label %205, label %225

205:                                              ; preds = %200
  %206 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %194 to i64
  %207 = sub i64 %206, %204
  %208 = ashr exact i64 %207, 3
  %209 = add nsw i64 %208, 1
  %210 = sdiv i64 %209, -2
  %211 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %194, i64 %210
  %212 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %195 to i64
  %213 = sub i64 %212, %206
  %214 = ashr exact i64 %213, 3
  %215 = icmp eq i64 %213, 0
  br i1 %215, label %220, label %216

216:                                              ; preds = %205
  %217 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %211 to i8*
  %218 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %194 to i8*
  call void @llvm.memmove.p0i8.p0i8.i64(i8* align 8 %217, i8* align 8 %218, i64 %213, i1 false) #9
  %219 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %166, align 8
  br label %220

220:                                              ; preds = %216, %205
  %221 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %194, %205 ], [ %219, %216 ]
  %222 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %211, i64 %214
  store %"class.v8::internal::OptimizedCompilationJob"*** %222, %"class.v8::internal::OptimizedCompilationJob"**** %163, align 8
  %223 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %221, i64 %210
  store %"class.v8::internal::OptimizedCompilationJob"*** %223, %"class.v8::internal::OptimizedCompilationJob"**** %166, align 8
  %224 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %222 to i64*
  br label %332

225:                                              ; preds = %200
  %226 = sub i64 %198, %204
  %227 = ashr exact i64 %226, 2
  %228 = icmp eq i64 %226, 0
  %229 = select i1 %228, i64 1, i64 %227
  %230 = icmp ugt i64 %229, 2305843009213693951
  br i1 %230, label %231, label %232

231:                                              ; preds = %225
  call void @abort() #10
  unreachable

232:                                              ; preds = %225
  %233 = lshr i64 %229, 2
  %234 = shl i64 %229, 3
  %235 = call i8* @_Znwm(i64 %234) #8
  %236 = bitcast i8* %235 to %"class.v8::internal::OptimizedCompilationJob"***
  %237 = ptrtoint i8* %235 to i64
  %238 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %236, i64 %233
  %239 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %238 to i64
  %240 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %236, i64 %229
  %241 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %240 to i64
  %242 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %194 to i64
  %243 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %195 to i64
  %244 = sub i64 %243, %242
  %245 = ashr exact i64 %244, 3
  %246 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %238, i64 %245
  %247 = icmp eq i64 %244, 0
  br i1 %247, label %323, label %248

248:                                              ; preds = %232
  %249 = add i64 %244, -8
  %250 = lshr i64 %249, 3
  %251 = add nuw nsw i64 %250, 1
  %252 = and i64 %251, 7
  %253 = icmp eq i64 %252, 0
  br i1 %253, label %269, label %254

254:                                              ; preds = %248, %254
  %255 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %262, %254 ], [ %238, %248 ]
  %256 = phi i64 [ %263, %254 ], [ %239, %248 ]
  %257 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %264, %254 ], [ %194, %248 ]
  %258 = phi i64 [ %265, %254 ], [ %252, %248 ]
  %259 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %257 to i64*
  %260 = load i64, i64* %259, align 8
  %261 = inttoptr i64 %256 to i64*
  store i64 %260, i64* %261, align 8
  %262 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %255, i64 1
  %263 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %262 to i64
  %264 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %257, i64 1
  %265 = add i64 %258, -1
  %266 = icmp eq i64 %265, 0
  br i1 %266, label %267, label %254, !llvm.loop !5

267:                                              ; preds = %254
  %268 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %262 to i64
  br label %269

269:                                              ; preds = %248, %267
  %270 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %238, %248 ], [ %262, %267 ]
  %271 = phi i64 [ %239, %248 ], [ %268, %267 ]
  %272 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %194, %248 ], [ %264, %267 ]
  %273 = icmp ult i64 %249, 56
  br i1 %273, label %320, label %274

274:                                              ; preds = %269, %274
  %275 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %316, %274 ], [ %270, %269 ]
  %276 = phi i64 [ %317, %274 ], [ %271, %269 ]
  %277 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %318, %274 ], [ %272, %269 ]
  %278 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %277 to i64*
  %279 = load i64, i64* %278, align 8
  %280 = inttoptr i64 %276 to i64*
  store i64 %279, i64* %280, align 8
  %281 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %275, i64 1
  %282 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %277, i64 1
  %283 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %282 to i64*
  %284 = load i64, i64* %283, align 8
  %285 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %281 to i64*
  store i64 %284, i64* %285, align 8
  %286 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %275, i64 2
  %287 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %277, i64 2
  %288 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %287 to i64*
  %289 = load i64, i64* %288, align 8
  %290 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %286 to i64*
  store i64 %289, i64* %290, align 8
  %291 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %275, i64 3
  %292 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %277, i64 3
  %293 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %292 to i64*
  %294 = load i64, i64* %293, align 8
  %295 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %291 to i64*
  store i64 %294, i64* %295, align 8
  %296 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %275, i64 4
  %297 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %277, i64 4
  %298 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %297 to i64*
  %299 = load i64, i64* %298, align 8
  %300 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %296 to i64*
  store i64 %299, i64* %300, align 8
  %301 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %275, i64 5
  %302 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %277, i64 5
  %303 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %302 to i64*
  %304 = load i64, i64* %303, align 8
  %305 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %301 to i64*
  store i64 %304, i64* %305, align 8
  %306 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %275, i64 6
  %307 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %277, i64 6
  %308 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %307 to i64*
  %309 = load i64, i64* %308, align 8
  %310 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %306 to i64*
  store i64 %309, i64* %310, align 8
  %311 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %275, i64 7
  %312 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %277, i64 7
  %313 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %312 to i64*
  %314 = load i64, i64* %313, align 8
  %315 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %311 to i64*
  store i64 %314, i64* %315, align 8
  %316 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %275, i64 8
  %317 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %316 to i64
  %318 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %277, i64 8
  %319 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %246, %316
  br i1 %319, label %320, label %274

320:                                              ; preds = %274, %269
  %321 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %246 to i64
  %322 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %201, align 8
  br label %323

323:                                              ; preds = %320, %232
  %324 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %322, %320 ], [ %202, %232 ]
  %325 = phi i64 [ %321, %320 ], [ %239, %232 ]
  store i64 %237, i64* %174, align 8
  store i64 %239, i64* %167, align 8
  store i64 %325, i64* %164, align 8
  store i64 %241, i64* %172, align 8
  %326 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %324, null
  %327 = inttoptr i64 %325 to i64*
  br i1 %326, label %332, label %328

328:                                              ; preds = %323
  %329 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %324 to i8*
  call void @_ZdlPv(i8* %329) #8
  %330 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %163 to i64**
  %331 = load i64*, i64** %330, align 8
  br label %332

332:                                              ; preds = %187, %220, %323, %328
  %333 = phi i64* [ %331, %328 ], [ %327, %323 ], [ %224, %220 ], [ %199, %187 ]
  store i64 %193, i64* %333, align 8
  %334 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %163, align 8
  %335 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %334, i64 1
  store %"class.v8::internal::OptimizedCompilationJob"*** %335, %"class.v8::internal::OptimizedCompilationJob"**** %163, align 8
  br label %549

336:                                              ; preds = %161
  %337 = ashr exact i64 %176, 2
  %338 = icmp eq i64 %176, 0
  %339 = select i1 %338, i64 1, i64 %337
  %340 = icmp ugt i64 %339, 2305843009213693951
  br i1 %340, label %341, label %342

341:                                              ; preds = %336
  tail call void @abort() #10
  unreachable

342:                                              ; preds = %336
  %343 = shl i64 %339, 3
  %344 = tail call i8* @_Znwm(i64 %343) #8
  %345 = bitcast i8* %344 to %"class.v8::internal::OptimizedCompilationJob"***
  %346 = ptrtoint i8* %344 to i64
  %347 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %345, i64 %170
  %348 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %347 to i64
  %349 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %345, i64 %339
  %350 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %349 to i64
  %351 = tail call i8* @_Znwm(i64 4096) #8
  %352 = ptrtoint i8* %351 to i64
  %353 = icmp eq i64 %170, %339
  br i1 %353, label %354, label %382

354:                                              ; preds = %342
  %355 = icmp ugt %"class.v8::internal::OptimizedCompilationJob"*** %347, %345
  br i1 %355, label %356, label %363

356:                                              ; preds = %354
  %357 = sub i64 %348, %346
  %358 = ashr exact i64 %357, 3
  %359 = add nsw i64 %358, 1
  %360 = sdiv i64 %359, -2
  %361 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %347, i64 %360
  %362 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %361 to i64
  br label %382

363:                                              ; preds = %354
  %364 = sub i64 %350, %346
  %365 = ashr exact i64 %364, 2
  %366 = icmp eq i64 %364, 0
  %367 = select i1 %366, i64 1, i64 %365
  %368 = icmp ugt i64 %367, 2305843009213693951
  br i1 %368, label %369, label %370

369:                                              ; preds = %363
  tail call void @abort() #10
  unreachable

370:                                              ; preds = %363
  %371 = lshr i64 %367, 2
  %372 = shl i64 %367, 3
  %373 = tail call i8* @_Znwm(i64 %372) #8
  %374 = bitcast i8* %373 to %"class.v8::internal::OptimizedCompilationJob"***
  %375 = ptrtoint i8* %373 to i64
  %376 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %374, i64 %371
  %377 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %376 to i64
  %378 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %374, i64 %367
  %379 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %378 to i64
  tail call void @_ZdlPv(i8* nonnull %344) #8
  %380 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %163, align 8
  %381 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %166, align 8
  br label %382

382:                                              ; preds = %342, %356, %370
  %383 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %180, %356 ], [ %381, %370 ], [ %180, %342 ]
  %384 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %179, %356 ], [ %380, %370 ], [ %179, %342 ]
  %385 = phi i64 [ %346, %356 ], [ %375, %370 ], [ %346, %342 ]
  %386 = phi i64 [ %362, %356 ], [ %377, %370 ], [ %348, %342 ]
  %387 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %361, %356 ], [ %376, %370 ], [ %347, %342 ]
  %388 = phi i64 [ %350, %356 ], [ %379, %370 ], [ %350, %342 ]
  %389 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %387 to i64*
  store i64 %352, i64* %389, align 8
  %390 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %387, i64 1
  %391 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %390 to i64
  %392 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %384, %383
  br i1 %392, label %395, label %405

393:                                              ; preds = %537
  %394 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %542 to i64
  br label %395

395:                                              ; preds = %393, %382
  %396 = phi i64 [ %385, %382 ], [ %538, %393 ]
  %397 = phi i64 [ %386, %382 ], [ %394, %393 ]
  %398 = phi i64 [ %391, %382 ], [ %539, %393 ]
  %399 = phi i64 [ %388, %382 ], [ %540, %393 ]
  %400 = getelementptr inbounds %"class.std::__1::deque.1160", %"class.std::__1::deque.1160"* %0, i64 0, i32 0, i32 0, i32 0
  %401 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %400, align 8
  store i64 %396, i64* %174, align 8
  store i64 %397, i64* %167, align 8
  store i64 %398, i64* %164, align 8
  store i64 %399, i64* %172, align 8
  %402 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %401, null
  br i1 %402, label %549, label %403

403:                                              ; preds = %395
  %404 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %401 to i8*
  tail call void @_ZdlPv(i8* %404) #8
  br label %549

405:                                              ; preds = %382, %537
  %406 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %411, %537 ], [ %384, %382 ]
  %407 = phi i64 [ %540, %537 ], [ %388, %382 ]
  %408 = phi i64 [ %539, %537 ], [ %391, %382 ]
  %409 = phi i64 [ %546, %537 ], [ %386, %382 ]
  %410 = phi i64 [ %538, %537 ], [ %385, %382 ]
  %411 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %406, i64 -1
  %412 = inttoptr i64 %409 to %"class.v8::internal::OptimizedCompilationJob"***
  %413 = inttoptr i64 %410 to %"class.v8::internal::OptimizedCompilationJob"***
  %414 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %412, %413
  br i1 %414, label %415, label %537

415:                                              ; preds = %405
  %416 = inttoptr i64 %408 to %"class.v8::internal::OptimizedCompilationJob"***
  %417 = inttoptr i64 %407 to %"class.v8::internal::OptimizedCompilationJob"***
  %418 = icmp ult %"class.v8::internal::OptimizedCompilationJob"*** %416, %417
  br i1 %418, label %419, label %436

419:                                              ; preds = %415
  %420 = sub i64 %407, %408
  %421 = ashr exact i64 %420, 3
  %422 = add nsw i64 %421, 1
  %423 = sdiv i64 %422, 2
  %424 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %416, i64 %423
  %425 = sub i64 %408, %409
  %426 = icmp eq i64 %425, 0
  br i1 %426, label %433, label %427

427:                                              ; preds = %419
  %428 = ashr exact i64 %425, 3
  %429 = sub nsw i64 0, %428
  %430 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %424, i64 %429
  %431 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %430 to i8*
  %432 = inttoptr i64 %409 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 8 %431, i8* align 8 %432, i64 %425, i1 false) #9
  br label %433

433:                                              ; preds = %427, %419
  %434 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %430, %427 ], [ %424, %419 ]
  %435 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %424 to i64
  br label %537

436:                                              ; preds = %415
  %437 = sub i64 %407, %410
  %438 = ashr exact i64 %437, 2
  %439 = icmp eq i64 %437, 0
  %440 = select i1 %439, i64 1, i64 %438
  %441 = icmp ugt i64 %440, 2305843009213693951
  br i1 %441, label %442, label %443

442:                                              ; preds = %436
  tail call void @abort() #10
  unreachable

443:                                              ; preds = %436
  %444 = add nuw nsw i64 %440, 3
  %445 = lshr i64 %444, 2
  %446 = shl i64 %440, 3
  %447 = tail call i8* @_Znwm(i64 %446) #8
  %448 = bitcast i8* %447 to %"class.v8::internal::OptimizedCompilationJob"***
  %449 = ptrtoint i8* %447 to i64
  %450 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %448, i64 %445
  %451 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %450 to i64
  %452 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %448, i64 %440
  %453 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %452 to i64
  %454 = sub i64 %408, %409
  %455 = ashr exact i64 %454, 3
  %456 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %450, i64 %455
  %457 = icmp eq i64 %454, 0
  br i1 %457, label %532, label %458

458:                                              ; preds = %443
  %459 = add i64 %454, -8
  %460 = lshr i64 %459, 3
  %461 = add nuw nsw i64 %460, 1
  %462 = and i64 %461, 7
  %463 = icmp eq i64 %462, 0
  br i1 %463, label %479, label %464

464:                                              ; preds = %458, %464
  %465 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %472, %464 ], [ %450, %458 ]
  %466 = phi i64 [ %473, %464 ], [ %451, %458 ]
  %467 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %474, %464 ], [ %412, %458 ]
  %468 = phi i64 [ %475, %464 ], [ %462, %458 ]
  %469 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %467 to i64*
  %470 = load i64, i64* %469, align 8
  %471 = inttoptr i64 %466 to i64*
  store i64 %470, i64* %471, align 8
  %472 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %465, i64 1
  %473 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %472 to i64
  %474 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %467, i64 1
  %475 = add i64 %468, -1
  %476 = icmp eq i64 %475, 0
  br i1 %476, label %477, label %464, !llvm.loop !6

477:                                              ; preds = %464
  %478 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %472 to i64
  br label %479

479:                                              ; preds = %458, %477
  %480 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %450, %458 ], [ %472, %477 ]
  %481 = phi i64 [ %451, %458 ], [ %478, %477 ]
  %482 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %412, %458 ], [ %474, %477 ]
  %483 = icmp ult i64 %459, 56
  br i1 %483, label %530, label %484

484:                                              ; preds = %479, %484
  %485 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %526, %484 ], [ %480, %479 ]
  %486 = phi i64 [ %527, %484 ], [ %481, %479 ]
  %487 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %528, %484 ], [ %482, %479 ]
  %488 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %487 to i64*
  %489 = load i64, i64* %488, align 8
  %490 = inttoptr i64 %486 to i64*
  store i64 %489, i64* %490, align 8
  %491 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %485, i64 1
  %492 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %487, i64 1
  %493 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %492 to i64*
  %494 = load i64, i64* %493, align 8
  %495 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %491 to i64*
  store i64 %494, i64* %495, align 8
  %496 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %485, i64 2
  %497 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %487, i64 2
  %498 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %497 to i64*
  %499 = load i64, i64* %498, align 8
  %500 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %496 to i64*
  store i64 %499, i64* %500, align 8
  %501 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %485, i64 3
  %502 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %487, i64 3
  %503 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %502 to i64*
  %504 = load i64, i64* %503, align 8
  %505 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %501 to i64*
  store i64 %504, i64* %505, align 8
  %506 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %485, i64 4
  %507 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %487, i64 4
  %508 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %507 to i64*
  %509 = load i64, i64* %508, align 8
  %510 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %506 to i64*
  store i64 %509, i64* %510, align 8
  %511 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %485, i64 5
  %512 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %487, i64 5
  %513 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %512 to i64*
  %514 = load i64, i64* %513, align 8
  %515 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %511 to i64*
  store i64 %514, i64* %515, align 8
  %516 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %485, i64 6
  %517 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %487, i64 6
  %518 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %517 to i64*
  %519 = load i64, i64* %518, align 8
  %520 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %516 to i64*
  store i64 %519, i64* %520, align 8
  %521 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %485, i64 7
  %522 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %487, i64 7
  %523 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %522 to i64*
  %524 = load i64, i64* %523, align 8
  %525 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %521 to i64*
  store i64 %524, i64* %525, align 8
  %526 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %485, i64 8
  %527 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %526 to i64
  %528 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %487, i64 8
  %529 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %456, %526
  br i1 %529, label %530, label %484

530:                                              ; preds = %484, %479
  %531 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %456 to i64
  br label %532

532:                                              ; preds = %530, %443
  %533 = phi i64 [ %531, %530 ], [ %451, %443 ]
  %534 = icmp eq i64 %409, 0
  br i1 %534, label %537, label %535

535:                                              ; preds = %532
  %536 = inttoptr i64 %409 to i8*
  tail call void @_ZdlPv(i8* %536) #8
  br label %537

537:                                              ; preds = %405, %433, %532, %535
  %538 = phi i64 [ %410, %433 ], [ %449, %532 ], [ %449, %535 ], [ %410, %405 ]
  %539 = phi i64 [ %435, %433 ], [ %533, %532 ], [ %533, %535 ], [ %408, %405 ]
  %540 = phi i64 [ %407, %433 ], [ %453, %532 ], [ %453, %535 ], [ %407, %405 ]
  %541 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %434, %433 ], [ %450, %532 ], [ %450, %535 ], [ %412, %405 ]
  %542 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %541, i64 -1
  %543 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %411 to i64*
  %544 = load i64, i64* %543, align 8
  %545 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %542 to i64*
  store i64 %544, i64* %545, align 8
  %546 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %542 to i64
  %547 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %166, align 8
  %548 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %411, %547
  br i1 %548, label %393, label %405

549:                                              ; preds = %403, %395, %332, %183, %157
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNSt3__114__split_bufferIPPN2v88internal23OptimizedCompilationJobENS_9allocatorIS5_EEE9push_backEOS5_(%"struct.std::__1::__split_buffer.1162"*, %"class.v8::internal::OptimizedCompilationJob"*** dereferenceable(8)) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %"struct.std::__1::__split_buffer.1162", %"struct.std::__1::__split_buffer.1162"* %0, i64 0, i32 2
  %4 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %3, align 8
  %5 = getelementptr inbounds %"struct.std::__1::__split_buffer.1162", %"struct.std::__1::__split_buffer.1162"* %0, i64 0, i32 3, i32 0, i32 0
  %6 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %5, align 8
  %7 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %4, %6
  %8 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %6 to i64
  %9 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %4 to i64*
  br i1 %7, label %10, label %148

10:                                               ; preds = %2
  %11 = getelementptr inbounds %"struct.std::__1::__split_buffer.1162", %"struct.std::__1::__split_buffer.1162"* %0, i64 0, i32 1
  %12 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %11, align 8
  %13 = getelementptr inbounds %"struct.std::__1::__split_buffer.1162", %"struct.std::__1::__split_buffer.1162"* %0, i64 0, i32 0
  %14 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %13, align 8
  %15 = icmp ugt %"class.v8::internal::OptimizedCompilationJob"*** %12, %14
  %16 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %14 to i64
  br i1 %15, label %17, label %37

17:                                               ; preds = %10
  %18 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %12 to i64
  %19 = sub i64 %18, %16
  %20 = ashr exact i64 %19, 3
  %21 = add nsw i64 %20, 1
  %22 = sdiv i64 %21, -2
  %23 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %12, i64 %22
  %24 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %4 to i64
  %25 = sub i64 %24, %18
  %26 = ashr exact i64 %25, 3
  %27 = icmp eq i64 %25, 0
  br i1 %27, label %32, label %28

28:                                               ; preds = %17
  %29 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %23 to i8*
  %30 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %12 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 8 %29, i8* align 8 %30, i64 %25, i1 false) #9
  %31 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %11, align 8
  br label %32

32:                                               ; preds = %17, %28
  %33 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %12, %17 ], [ %31, %28 ]
  %34 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %23, i64 %26
  store %"class.v8::internal::OptimizedCompilationJob"*** %34, %"class.v8::internal::OptimizedCompilationJob"**** %3, align 8
  %35 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %33, i64 %22
  store %"class.v8::internal::OptimizedCompilationJob"*** %35, %"class.v8::internal::OptimizedCompilationJob"**** %11, align 8
  %36 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %34 to i64*
  br label %148

37:                                               ; preds = %10
  %38 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %5 to i64*
  %39 = bitcast %"struct.std::__1::__split_buffer.1162"* %0 to i64*
  %40 = sub i64 %8, %16
  %41 = ashr exact i64 %40, 2
  %42 = icmp eq i64 %40, 0
  %43 = select i1 %42, i64 1, i64 %41
  %44 = icmp ugt i64 %43, 2305843009213693951
  br i1 %44, label %45, label %46

45:                                               ; preds = %37
  tail call void @abort() #10
  unreachable

46:                                               ; preds = %37
  %47 = lshr i64 %43, 2
  %48 = shl i64 %43, 3
  %49 = tail call i8* @_Znwm(i64 %48) #8
  %50 = bitcast i8* %49 to %"class.v8::internal::OptimizedCompilationJob"***
  %51 = ptrtoint i8* %49 to i64
  %52 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %50, i64 %47
  %53 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %52 to i64
  %54 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %50, i64 %43
  %55 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %54 to i64
  %56 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %12 to i64
  %57 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %4 to i64
  %58 = sub i64 %57, %56
  %59 = ashr exact i64 %58, 3
  %60 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %52, i64 %59
  %61 = icmp eq i64 %58, 0
  br i1 %61, label %137, label %62

62:                                               ; preds = %46
  %63 = add i64 %58, -8
  %64 = lshr i64 %63, 3
  %65 = add nuw nsw i64 %64, 1
  %66 = and i64 %65, 7
  %67 = icmp eq i64 %66, 0
  br i1 %67, label %83, label %68

68:                                               ; preds = %62, %68
  %69 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %76, %68 ], [ %52, %62 ]
  %70 = phi i64 [ %77, %68 ], [ %53, %62 ]
  %71 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %78, %68 ], [ %12, %62 ]
  %72 = phi i64 [ %79, %68 ], [ %66, %62 ]
  %73 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %71 to i64*
  %74 = load i64, i64* %73, align 8
  %75 = inttoptr i64 %70 to i64*
  store i64 %74, i64* %75, align 8
  %76 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %69, i64 1
  %77 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %76 to i64
  %78 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %71, i64 1
  %79 = add i64 %72, -1
  %80 = icmp eq i64 %79, 0
  br i1 %80, label %81, label %68, !llvm.loop !7

81:                                               ; preds = %68
  %82 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %76 to i64
  br label %83

83:                                               ; preds = %62, %81
  %84 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %52, %62 ], [ %76, %81 ]
  %85 = phi i64 [ %53, %62 ], [ %82, %81 ]
  %86 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %12, %62 ], [ %78, %81 ]
  %87 = icmp ult i64 %63, 56
  br i1 %87, label %134, label %88

88:                                               ; preds = %83, %88
  %89 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %130, %88 ], [ %84, %83 ]
  %90 = phi i64 [ %131, %88 ], [ %85, %83 ]
  %91 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %132, %88 ], [ %86, %83 ]
  %92 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %91 to i64*
  %93 = load i64, i64* %92, align 8
  %94 = inttoptr i64 %90 to i64*
  store i64 %93, i64* %94, align 8
  %95 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %89, i64 1
  %96 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %91, i64 1
  %97 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %96 to i64*
  %98 = load i64, i64* %97, align 8
  %99 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %95 to i64*
  store i64 %98, i64* %99, align 8
  %100 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %89, i64 2
  %101 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %91, i64 2
  %102 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %101 to i64*
  %103 = load i64, i64* %102, align 8
  %104 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %100 to i64*
  store i64 %103, i64* %104, align 8
  %105 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %89, i64 3
  %106 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %91, i64 3
  %107 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %106 to i64*
  %108 = load i64, i64* %107, align 8
  %109 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %105 to i64*
  store i64 %108, i64* %109, align 8
  %110 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %89, i64 4
  %111 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %91, i64 4
  %112 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %111 to i64*
  %113 = load i64, i64* %112, align 8
  %114 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %110 to i64*
  store i64 %113, i64* %114, align 8
  %115 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %89, i64 5
  %116 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %91, i64 5
  %117 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %116 to i64*
  %118 = load i64, i64* %117, align 8
  %119 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %115 to i64*
  store i64 %118, i64* %119, align 8
  %120 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %89, i64 6
  %121 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %91, i64 6
  %122 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %121 to i64*
  %123 = load i64, i64* %122, align 8
  %124 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %120 to i64*
  store i64 %123, i64* %124, align 8
  %125 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %89, i64 7
  %126 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %91, i64 7
  %127 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %126 to i64*
  %128 = load i64, i64* %127, align 8
  %129 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %125 to i64*
  store i64 %128, i64* %129, align 8
  %130 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %89, i64 8
  %131 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %130 to i64
  %132 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %91, i64 8
  %133 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %60, %130
  br i1 %133, label %134, label %88

134:                                              ; preds = %88, %83
  %135 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %60 to i64
  %136 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %13, align 8
  br label %137

137:                                              ; preds = %46, %134
  %138 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %136, %134 ], [ %14, %46 ]
  %139 = phi i64 [ %135, %134 ], [ %53, %46 ]
  store i64 %51, i64* %39, align 8
  %140 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %11 to i64*
  store i64 %53, i64* %140, align 8
  %141 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %3 to i64*
  store i64 %139, i64* %141, align 8
  store i64 %55, i64* %38, align 8
  %142 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %138, null
  %143 = inttoptr i64 %139 to i64*
  br i1 %142, label %148, label %144

144:                                              ; preds = %137
  %145 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %138 to i8*
  tail call void @_ZdlPv(i8* %145) #8
  %146 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %3 to i64**
  %147 = load i64*, i64** %146, align 8
  br label %148

148:                                              ; preds = %144, %137, %32, %2
  %149 = phi i64* [ %147, %144 ], [ %143, %137 ], [ %36, %32 ], [ %9, %2 ]
  %150 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %1 to i64*
  %151 = load i64, i64* %150, align 8
  store i64 %151, i64* %149, align 8
  %152 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %3, align 8
  %153 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %152, i64 1
  store %"class.v8::internal::OptimizedCompilationJob"*** %153, %"class.v8::internal::OptimizedCompilationJob"**** %3, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNSt3__114__split_bufferIPPN2v88internal23OptimizedCompilationJobENS_9allocatorIS5_EEE10push_frontEOS5_(%"struct.std::__1::__split_buffer.1162"*, %"class.v8::internal::OptimizedCompilationJob"*** dereferenceable(8)) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %"struct.std::__1::__split_buffer.1162", %"struct.std::__1::__split_buffer.1162"* %0, i64 0, i32 1
  %4 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %3, align 8
  %5 = getelementptr inbounds %"struct.std::__1::__split_buffer.1162", %"struct.std::__1::__split_buffer.1162"* %0, i64 0, i32 0
  %6 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %5, align 8
  %7 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %4, %6
  %8 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %6 to i64
  br i1 %7, label %9, label %147

9:                                                ; preds = %2
  %10 = getelementptr inbounds %"struct.std::__1::__split_buffer.1162", %"struct.std::__1::__split_buffer.1162"* %0, i64 0, i32 2
  %11 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %10, align 8
  %12 = getelementptr inbounds %"struct.std::__1::__split_buffer.1162", %"struct.std::__1::__split_buffer.1162"* %0, i64 0, i32 3, i32 0, i32 0
  %13 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %12, align 8
  %14 = icmp ult %"class.v8::internal::OptimizedCompilationJob"*** %11, %13
  %15 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %12 to i64*
  %16 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %13 to i64
  br i1 %14, label %17, label %38

17:                                               ; preds = %9
  %18 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %11 to i64
  %19 = sub i64 %16, %18
  %20 = ashr exact i64 %19, 3
  %21 = add nsw i64 %20, 1
  %22 = sdiv i64 %21, 2
  %23 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %11, i64 %22
  %24 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %4 to i64
  %25 = sub i64 %18, %24
  %26 = icmp eq i64 %25, 0
  br i1 %26, label %34, label %27

27:                                               ; preds = %17
  %28 = ashr exact i64 %25, 3
  %29 = sub nsw i64 0, %28
  %30 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %23, i64 %29
  %31 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %30 to i8*
  %32 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %4 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 8 %31, i8* align 8 %32, i64 %25, i1 false) #9
  %33 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %10, align 8
  br label %34

34:                                               ; preds = %17, %27
  %35 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %33, %27 ], [ %11, %17 ]
  %36 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %30, %27 ], [ %23, %17 ]
  store %"class.v8::internal::OptimizedCompilationJob"*** %36, %"class.v8::internal::OptimizedCompilationJob"**** %3, align 8
  %37 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %35, i64 %22
  store %"class.v8::internal::OptimizedCompilationJob"*** %37, %"class.v8::internal::OptimizedCompilationJob"**** %10, align 8
  br label %147

38:                                               ; preds = %9
  %39 = bitcast %"struct.std::__1::__split_buffer.1162"* %0 to i64*
  %40 = sub i64 %16, %8
  %41 = ashr exact i64 %40, 2
  %42 = icmp eq i64 %40, 0
  %43 = select i1 %42, i64 1, i64 %41
  %44 = icmp ugt i64 %43, 2305843009213693951
  br i1 %44, label %45, label %46

45:                                               ; preds = %38
  tail call void @abort() #10
  unreachable

46:                                               ; preds = %38
  %47 = add nuw nsw i64 %43, 3
  %48 = lshr i64 %47, 2
  %49 = shl i64 %43, 3
  %50 = tail call i8* @_Znwm(i64 %49) #8
  %51 = bitcast i8* %50 to %"class.v8::internal::OptimizedCompilationJob"***
  %52 = ptrtoint i8* %50 to i64
  %53 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %51, i64 %48
  %54 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %53 to i64
  %55 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %51, i64 %43
  %56 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %55 to i64
  %57 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %4 to i64
  %58 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %11 to i64
  %59 = sub i64 %58, %57
  %60 = ashr exact i64 %59, 3
  %61 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %53, i64 %60
  %62 = icmp eq i64 %59, 0
  br i1 %62, label %138, label %63

63:                                               ; preds = %46
  %64 = add i64 %59, -8
  %65 = lshr i64 %64, 3
  %66 = add nuw nsw i64 %65, 1
  %67 = and i64 %66, 7
  %68 = icmp eq i64 %67, 0
  br i1 %68, label %84, label %69

69:                                               ; preds = %63, %69
  %70 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %77, %69 ], [ %53, %63 ]
  %71 = phi i64 [ %78, %69 ], [ %54, %63 ]
  %72 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %79, %69 ], [ %4, %63 ]
  %73 = phi i64 [ %80, %69 ], [ %67, %63 ]
  %74 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %72 to i64*
  %75 = load i64, i64* %74, align 8
  %76 = inttoptr i64 %71 to i64*
  store i64 %75, i64* %76, align 8
  %77 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %70, i64 1
  %78 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %77 to i64
  %79 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %72, i64 1
  %80 = add i64 %73, -1
  %81 = icmp eq i64 %80, 0
  br i1 %81, label %82, label %69, !llvm.loop !8

82:                                               ; preds = %69
  %83 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %77 to i64
  br label %84

84:                                               ; preds = %63, %82
  %85 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %53, %63 ], [ %77, %82 ]
  %86 = phi i64 [ %54, %63 ], [ %83, %82 ]
  %87 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %4, %63 ], [ %79, %82 ]
  %88 = icmp ult i64 %64, 56
  br i1 %88, label %135, label %89

89:                                               ; preds = %84, %89
  %90 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %131, %89 ], [ %85, %84 ]
  %91 = phi i64 [ %132, %89 ], [ %86, %84 ]
  %92 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %133, %89 ], [ %87, %84 ]
  %93 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %92 to i64*
  %94 = load i64, i64* %93, align 8
  %95 = inttoptr i64 %91 to i64*
  store i64 %94, i64* %95, align 8
  %96 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %90, i64 1
  %97 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %92, i64 1
  %98 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %97 to i64*
  %99 = load i64, i64* %98, align 8
  %100 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %96 to i64*
  store i64 %99, i64* %100, align 8
  %101 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %90, i64 2
  %102 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %92, i64 2
  %103 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %102 to i64*
  %104 = load i64, i64* %103, align 8
  %105 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %101 to i64*
  store i64 %104, i64* %105, align 8
  %106 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %90, i64 3
  %107 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %92, i64 3
  %108 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %107 to i64*
  %109 = load i64, i64* %108, align 8
  %110 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %106 to i64*
  store i64 %109, i64* %110, align 8
  %111 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %90, i64 4
  %112 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %92, i64 4
  %113 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %112 to i64*
  %114 = load i64, i64* %113, align 8
  %115 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %111 to i64*
  store i64 %114, i64* %115, align 8
  %116 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %90, i64 5
  %117 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %92, i64 5
  %118 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %117 to i64*
  %119 = load i64, i64* %118, align 8
  %120 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %116 to i64*
  store i64 %119, i64* %120, align 8
  %121 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %90, i64 6
  %122 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %92, i64 6
  %123 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %122 to i64*
  %124 = load i64, i64* %123, align 8
  %125 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %121 to i64*
  store i64 %124, i64* %125, align 8
  %126 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %90, i64 7
  %127 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %92, i64 7
  %128 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %127 to i64*
  %129 = load i64, i64* %128, align 8
  %130 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %126 to i64*
  store i64 %129, i64* %130, align 8
  %131 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %90, i64 8
  %132 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %131 to i64
  %133 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %92, i64 8
  %134 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %61, %131
  br i1 %134, label %135, label %89

135:                                              ; preds = %89, %84
  %136 = ptrtoint %"class.v8::internal::OptimizedCompilationJob"*** %61 to i64
  %137 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %5, align 8
  br label %138

138:                                              ; preds = %46, %135
  %139 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %137, %135 ], [ %4, %46 ]
  %140 = phi i64 [ %136, %135 ], [ %54, %46 ]
  store i64 %52, i64* %39, align 8
  %141 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %3 to i64*
  store i64 %54, i64* %141, align 8
  %142 = bitcast %"class.v8::internal::OptimizedCompilationJob"**** %10 to i64*
  store i64 %140, i64* %142, align 8
  store i64 %56, i64* %15, align 8
  %143 = icmp eq %"class.v8::internal::OptimizedCompilationJob"*** %139, null
  br i1 %143, label %147, label %144

144:                                              ; preds = %138
  %145 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %139 to i8*
  tail call void @_ZdlPv(i8* %145) #8
  %146 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %3, align 8
  br label %147

147:                                              ; preds = %144, %138, %34, %2
  %148 = phi %"class.v8::internal::OptimizedCompilationJob"*** [ %146, %144 ], [ %53, %138 ], [ %36, %34 ], [ %4, %2 ]
  %149 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %148, i64 -1
  %150 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %1 to i64*
  %151 = load i64, i64* %150, align 8
  %152 = bitcast %"class.v8::internal::OptimizedCompilationJob"*** %149 to i64*
  store i64 %151, i64* %152, align 8
  %153 = load %"class.v8::internal::OptimizedCompilationJob"***, %"class.v8::internal::OptimizedCompilationJob"**** %3, align 8
  %154 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %153, i64 -1
  store %"class.v8::internal::OptimizedCompilationJob"*** %154, %"class.v8::internal::OptimizedCompilationJob"**** %3, align 8
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memmove.p0i8.p0i8.i64(i8* nocapture, i8* nocapture readonly, i64, i1 immarg) #2

; Function Attrs: noreturn nounwind
declare void @abort() local_unnamed_addr #5

; Function Attrs: nobuiltin nofree
declare noalias nonnull i8* @_Znwm(i64) local_unnamed_addr #6

declare void @_ZN2v88internal14CancelableTaskC2EPNS0_7IsolateE(%"class.v8::internal::CancelableTask"*, %"class.v8::internal::Isolate"*) unnamed_addr #3

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal14CancelableTaskD2Ev(%"class.v8::internal::CancelableTask"*) unnamed_addr #7 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::CancelableTask", %"class.v8::internal::CancelableTask"* %0, i64 0, i32 0
  tail call void @_ZN2v88internal10CancelableD2Ev(%"class.v8::internal::Cancelable"* %2) #9
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal27OptimizingCompileDispatcher11CompileTaskD0Ev(%"class.v8::internal::OptimizingCompileDispatcher::CompileTask"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher::CompileTask", %"class.v8::internal::OptimizingCompileDispatcher::CompileTask"* %0, i64 0, i32 0, i32 0
  tail call void @_ZN2v88internal10CancelableD2Ev(%"class.v8::internal::Cancelable"* %2) #9
  %3 = bitcast %"class.v8::internal::OptimizingCompileDispatcher::CompileTask"* %0 to i8*
  tail call void @_ZdlPv(i8* %3) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal14CancelableTask3RunEv(%"class.v8::internal::CancelableTask"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::CancelableTask", %"class.v8::internal::CancelableTask"* %0, i64 0, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %3 = cmpxchg i32* %2, i32 0, i32 2 acq_rel acquire
  %4 = extractvalue { i32, i1 } %3, 1
  br i1 %4, label %5, label %10

5:                                                ; preds = %1
  %6 = bitcast %"class.v8::internal::CancelableTask"* %0 to void (%"class.v8::internal::CancelableTask"*)***
  %7 = load void (%"class.v8::internal::CancelableTask"*)**, void (%"class.v8::internal::CancelableTask"*)*** %6, align 8
  %8 = getelementptr inbounds void (%"class.v8::internal::CancelableTask"*)*, void (%"class.v8::internal::CancelableTask"*)** %7, i64 3
  %9 = load void (%"class.v8::internal::CancelableTask"*)*, void (%"class.v8::internal::CancelableTask"*)** %8, align 8
  tail call void %9(%"class.v8::internal::CancelableTask"* %0) #9
  br label %10

10:                                               ; preds = %5, %1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal27OptimizingCompileDispatcher11CompileTask11RunInternalEv(%"class.v8::internal::OptimizingCompileDispatcher::CompileTask"*) unnamed_addr #0 comdat align 2 {
  %2 = alloca [2 x %"class.std::__1::unique_ptr.1228"], align 16
  %3 = alloca %"class.v8::internal::WorkerThreadRuntimeCallStatsScope", align 8
  %4 = alloca %"class.v8::internal::LocalIsolate", align 8
  %5 = alloca %"class.v8::internal::RuntimeCallTimerScope", align 8
  %6 = alloca %"class.v8::internal::TimerEventScope", align 8
  %7 = alloca %"class.v8::internal::tracing::ScopedTracer", align 8
  %8 = bitcast %"class.v8::internal::WorkerThreadRuntimeCallStatsScope"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %8) #9
  %9 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher::CompileTask", %"class.v8::internal::OptimizingCompileDispatcher::CompileTask"* %0, i64 0, i32 2
  %10 = load %"class.v8::internal::WorkerThreadRuntimeCallStats"*, %"class.v8::internal::WorkerThreadRuntimeCallStats"** %9, align 8
  call void @_ZN2v88internal33WorkerThreadRuntimeCallStatsScopeC1EPNS0_28WorkerThreadRuntimeCallStatsE(%"class.v8::internal::WorkerThreadRuntimeCallStatsScope"* nonnull %3, %"class.v8::internal::WorkerThreadRuntimeCallStats"* %10) #9
  %11 = bitcast %"class.v8::internal::LocalIsolate"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 184, i8* nonnull %11) #9
  %12 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher::CompileTask", %"class.v8::internal::OptimizingCompileDispatcher::CompileTask"* %0, i64 0, i32 1
  %13 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %12, align 8
  %14 = getelementptr inbounds %"class.v8::internal::WorkerThreadRuntimeCallStatsScope", %"class.v8::internal::WorkerThreadRuntimeCallStatsScope"* %3, i64 0, i32 0
  %15 = load %"class.v8::internal::RuntimeCallStats"*, %"class.v8::internal::RuntimeCallStats"** %14, align 8
  call void @_ZN2v88internal12LocalIsolateC1EPNS0_7IsolateENS0_10ThreadKindEPNS0_16RuntimeCallStatsE(%"class.v8::internal::LocalIsolate"* nonnull %4, %"class.v8::internal::Isolate"* %13, i32 1, %"class.v8::internal::RuntimeCallStats"* %15) #9
  %16 = bitcast %"class.v8::internal::RuntimeCallTimerScope"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %16) #9
  %17 = load %"class.v8::internal::RuntimeCallStats"*, %"class.v8::internal::RuntimeCallStats"** %14, align 8
  %18 = getelementptr inbounds %"class.v8::internal::RuntimeCallTimerScope", %"class.v8::internal::RuntimeCallTimerScope"* %5, i64 0, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 0, i64 40, i1 false) #9
  %19 = load atomic i32, i32* getelementptr inbounds (%"struct.std::__1::atomic.1218", %"struct.std::__1::atomic.1218"* @_ZN2v88internal12TracingFlags13runtime_statsE, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0) monotonic, align 4
  %20 = icmp eq i32 %19, 0
  %21 = icmp eq %"class.v8::internal::RuntimeCallStats"* %17, null
  %22 = or i1 %21, %20
  br i1 %22, label %25, label %23, !prof !9

23:                                               ; preds = %1
  %24 = getelementptr inbounds %"class.v8::internal::RuntimeCallTimerScope", %"class.v8::internal::RuntimeCallTimerScope"* %5, i64 0, i32 0
  store %"class.v8::internal::RuntimeCallStats"* %17, %"class.v8::internal::RuntimeCallStats"** %24, align 8
  call void @_ZN2v88internal16RuntimeCallStats5EnterEPNS0_16RuntimeCallTimerENS0_20RuntimeCallCounterIdE(%"class.v8::internal::RuntimeCallStats"* nonnull %17, %"class.v8::internal::RuntimeCallTimer"* %18, i32 191) #9
  br label %25

25:                                               ; preds = %1, %23
  %26 = bitcast %"class.v8::internal::TimerEventScope"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %26) #9
  %27 = bitcast %"class.v8::internal::Isolate"** %12 to i64*
  %28 = load i64, i64* %27, align 8
  %29 = bitcast %"class.v8::internal::TimerEventScope"* %6 to i64*
  store i64 %28, i64* %29, align 8
  call void @_ZN2v88internal15TimerEventScopeINS0_29TimerEventRecompileConcurrentEE13LogTimerEventENS0_6Logger8StartEndE(%"class.v8::internal::TimerEventScope"* nonnull %6, i32 0) #9
  %30 = load atomic i64, i64* @_ZZN2v88internal27OptimizingCompileDispatcher11CompileTask11RunInternalEvE27trace_event_unique_atomic77 monotonic, align 8
  %31 = inttoptr i64 %30 to i8*
  %32 = icmp eq i64 %30, 0
  br i1 %32, label %33, label %41

33:                                               ; preds = %25
  %34 = call %"class.v8::TracingController"* @_ZN2v88internal7tracing16TraceEventHelper20GetTracingControllerEv() #9
  %35 = bitcast %"class.v8::TracingController"* %34 to i8* (%"class.v8::TracingController"*, i8*)***
  %36 = load i8* (%"class.v8::TracingController"*, i8*)**, i8* (%"class.v8::TracingController"*, i8*)*** %35, align 8
  %37 = getelementptr inbounds i8* (%"class.v8::TracingController"*, i8*)*, i8* (%"class.v8::TracingController"*, i8*)** %36, i64 2
  %38 = load i8* (%"class.v8::TracingController"*, i8*)*, i8* (%"class.v8::TracingController"*, i8*)** %37, align 8
  %39 = call i8* %38(%"class.v8::TracingController"* %34, i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.6, i64 0, i64 0)) #9
  %40 = ptrtoint i8* %39 to i64
  store atomic volatile i64 %40, i64* @_ZZN2v88internal27OptimizingCompileDispatcher11CompileTask11RunInternalEvE27trace_event_unique_atomic77 monotonic, align 8
  br label %41

41:                                               ; preds = %25, %33
  %42 = phi i8* [ %31, %25 ], [ %39, %33 ]
  %43 = bitcast %"class.v8::internal::tracing::ScopedTracer"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %43) #9
  %44 = getelementptr inbounds %"class.v8::internal::tracing::ScopedTracer", %"class.v8::internal::tracing::ScopedTracer"* %7, i64 0, i32 0
  store %"struct.v8::internal::tracing::ScopedTracer::Data"* null, %"struct.v8::internal::tracing::ScopedTracer::Data"** %44, align 8
  %45 = load atomic i8, i8* %42 monotonic, align 1
  %46 = and i8 %45, 5
  %47 = icmp eq i8 %46, 0
  br i1 %47, label %79, label %48

48:                                               ; preds = %41
  %49 = bitcast [2 x %"class.std::__1::unique_ptr.1228"]* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %49) #9
  %50 = getelementptr inbounds [2 x %"class.std::__1::unique_ptr.1228"], [2 x %"class.std::__1::unique_ptr.1228"]* %2, i64 0, i64 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %49, i8 0, i64 16, i1 false) #9
  %51 = call %"class.v8::TracingController"* @_ZN2v88internal7tracing16TraceEventHelper20GetTracingControllerEv() #9
  %52 = bitcast %"class.v8::TracingController"* %51 to i64 (%"class.v8::TracingController"*, i8, i8*, i8*, i8*, i64, i64, i32, i8**, i8*, i64*, %"class.std::__1::unique_ptr.1228"*, i32)***
  %53 = load i64 (%"class.v8::TracingController"*, i8, i8*, i8*, i8*, i64, i64, i32, i8**, i8*, i64*, %"class.std::__1::unique_ptr.1228"*, i32)**, i64 (%"class.v8::TracingController"*, i8, i8*, i8*, i8*, i64, i64, i32, i8**, i8*, i64*, %"class.std::__1::unique_ptr.1228"*, i32)*** %52, align 8
  %54 = getelementptr inbounds i64 (%"class.v8::TracingController"*, i8, i8*, i8*, i8*, i64, i64, i32, i8**, i8*, i64*, %"class.std::__1::unique_ptr.1228"*, i32)*, i64 (%"class.v8::TracingController"*, i8, i8*, i8*, i8*, i64, i64, i32, i8**, i8*, i64*, %"class.std::__1::unique_ptr.1228"*, i32)** %53, i64 3
  %55 = load i64 (%"class.v8::TracingController"*, i8, i8*, i8*, i8*, i64, i64, i32, i8**, i8*, i64*, %"class.std::__1::unique_ptr.1228"*, i32)*, i64 (%"class.v8::TracingController"*, i8, i8*, i8*, i8*, i64, i64, i32, i8**, i8*, i64*, %"class.std::__1::unique_ptr.1228"*, i32)** %54, align 8
  %56 = call i64 %55(%"class.v8::TracingController"* %51, i8 signext 88, i8* %42, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.7, i64 0, i64 0), i8* null, i64 0, i64 0, i32 0, i8** null, i8* null, i64* null, %"class.std::__1::unique_ptr.1228"* nonnull %50, i32 0) #9
  %57 = getelementptr inbounds [2 x %"class.std::__1::unique_ptr.1228"], [2 x %"class.std::__1::unique_ptr.1228"]* %2, i64 0, i64 1, i32 0, i32 0, i32 0
  %58 = load %"class.v8::ConvertableToTraceFormat"*, %"class.v8::ConvertableToTraceFormat"** %57, align 8
  store %"class.v8::ConvertableToTraceFormat"* null, %"class.v8::ConvertableToTraceFormat"** %57, align 8
  %59 = icmp eq %"class.v8::ConvertableToTraceFormat"* %58, null
  br i1 %59, label %65, label %60

60:                                               ; preds = %48
  %61 = bitcast %"class.v8::ConvertableToTraceFormat"* %58 to void (%"class.v8::ConvertableToTraceFormat"*)***
  %62 = load void (%"class.v8::ConvertableToTraceFormat"*)**, void (%"class.v8::ConvertableToTraceFormat"*)*** %61, align 8
  %63 = getelementptr inbounds void (%"class.v8::ConvertableToTraceFormat"*)*, void (%"class.v8::ConvertableToTraceFormat"*)** %62, i64 1
  %64 = load void (%"class.v8::ConvertableToTraceFormat"*)*, void (%"class.v8::ConvertableToTraceFormat"*)** %63, align 8
  call void %64(%"class.v8::ConvertableToTraceFormat"* nonnull %58) #9
  br label %65

65:                                               ; preds = %60, %48
  %66 = getelementptr inbounds [2 x %"class.std::__1::unique_ptr.1228"], [2 x %"class.std::__1::unique_ptr.1228"]* %2, i64 0, i64 0, i32 0, i32 0, i32 0
  %67 = load %"class.v8::ConvertableToTraceFormat"*, %"class.v8::ConvertableToTraceFormat"** %66, align 16
  store %"class.v8::ConvertableToTraceFormat"* null, %"class.v8::ConvertableToTraceFormat"** %66, align 16
  %68 = icmp eq %"class.v8::ConvertableToTraceFormat"* %67, null
  br i1 %68, label %74, label %69

69:                                               ; preds = %65
  %70 = bitcast %"class.v8::ConvertableToTraceFormat"* %67 to void (%"class.v8::ConvertableToTraceFormat"*)***
  %71 = load void (%"class.v8::ConvertableToTraceFormat"*)**, void (%"class.v8::ConvertableToTraceFormat"*)*** %70, align 8
  %72 = getelementptr inbounds void (%"class.v8::ConvertableToTraceFormat"*)*, void (%"class.v8::ConvertableToTraceFormat"*)** %71, i64 1
  %73 = load void (%"class.v8::ConvertableToTraceFormat"*)*, void (%"class.v8::ConvertableToTraceFormat"*)** %72, align 8
  call void %73(%"class.v8::ConvertableToTraceFormat"* nonnull %67) #9
  br label %74

74:                                               ; preds = %65, %69
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %49) #9
  %75 = getelementptr inbounds %"class.v8::internal::tracing::ScopedTracer", %"class.v8::internal::tracing::ScopedTracer"* %7, i64 0, i32 1
  %76 = getelementptr inbounds %"struct.v8::internal::tracing::ScopedTracer::Data", %"struct.v8::internal::tracing::ScopedTracer::Data"* %75, i64 0, i32 0
  store i8* %42, i8** %76, align 8
  %77 = getelementptr inbounds %"class.v8::internal::tracing::ScopedTracer", %"class.v8::internal::tracing::ScopedTracer"* %7, i64 0, i32 1, i32 1
  store i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.7, i64 0, i64 0), i8** %77, align 8
  %78 = getelementptr inbounds %"class.v8::internal::tracing::ScopedTracer", %"class.v8::internal::tracing::ScopedTracer"* %7, i64 0, i32 1, i32 2
  store i64 %56, i64* %78, align 8
  store %"struct.v8::internal::tracing::ScopedTracer::Data"* %75, %"struct.v8::internal::tracing::ScopedTracer::Data"** %44, align 8
  br label %79

79:                                               ; preds = %41, %74
  %80 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher::CompileTask", %"class.v8::internal::OptimizingCompileDispatcher::CompileTask"* %0, i64 0, i32 3
  %81 = load %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.v8::internal::OptimizingCompileDispatcher"** %80, align 8
  %82 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %81, i64 0, i32 13
  %83 = load i32, i32* %82, align 8
  %84 = icmp eq i32 %83, 0
  br i1 %84, label %89, label %85

85:                                               ; preds = %79
  %86 = sext i32 %83 to i64
  %87 = mul nsw i64 %86, 1000
  call void @_ZN2v84base2OS5SleepENS0_9TimeDeltaE(i64 %87) #9
  %88 = load %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.v8::internal::OptimizingCompileDispatcher"** %80, align 8
  br label %89

89:                                               ; preds = %79, %85
  %90 = phi %"class.v8::internal::OptimizingCompileDispatcher"* [ %81, %79 ], [ %88, %85 ]
  %91 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %90, i64 0, i32 6
  call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %91) #9
  %92 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %90, i64 0, i32 3
  %93 = load i32, i32* %92, align 4
  %94 = icmp eq i32 %93, 0
  br i1 %94, label %109, label %95

95:                                               ; preds = %89
  %96 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %90, i64 0, i32 1
  %97 = load %"class.v8::internal::OptimizedCompilationJob"**, %"class.v8::internal::OptimizedCompilationJob"*** %96, align 8
  %98 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %90, i64 0, i32 4
  %99 = load i32, i32* %98, align 8
  %100 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %90, i64 0, i32 2
  %101 = load i32, i32* %100, align 8
  %102 = srem i32 %99, %101
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %97, i64 %103
  %105 = load %"class.v8::internal::OptimizedCompilationJob"*, %"class.v8::internal::OptimizedCompilationJob"** %104, align 8
  %106 = add nsw i32 %99, 1
  %107 = srem i32 %106, %101
  store i32 %107, i32* %98, align 8
  %108 = add nsw i32 %93, -1
  store i32 %108, i32* %92, align 4
  br label %109

109:                                              ; preds = %89, %95
  %110 = phi %"class.v8::internal::OptimizedCompilationJob"* [ %105, %95 ], [ null, %89 ]
  call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %91) #9
  call void @_ZN2v88internal27OptimizingCompileDispatcher11CompileNextEPNS0_23OptimizedCompilationJobEPNS0_12LocalIsolateE(%"class.v8::internal::OptimizingCompileDispatcher"* %90, %"class.v8::internal::OptimizedCompilationJob"* %110, %"class.v8::internal::LocalIsolate"* nonnull %4)
  %111 = load %"struct.v8::internal::tracing::ScopedTracer::Data"*, %"struct.v8::internal::tracing::ScopedTracer::Data"** %44, align 8
  %112 = icmp eq %"struct.v8::internal::tracing::ScopedTracer::Data"* %111, null
  br i1 %112, label %129, label %113

113:                                              ; preds = %109
  %114 = getelementptr inbounds %"class.v8::internal::tracing::ScopedTracer", %"class.v8::internal::tracing::ScopedTracer"* %7, i64 0, i32 1, i32 0
  %115 = load i8*, i8** %114, align 8
  %116 = load atomic i8, i8* %115 monotonic, align 1
  %117 = icmp eq i8 %116, 0
  br i1 %117, label %129, label %118

118:                                              ; preds = %113
  %119 = call %"class.v8::TracingController"* @_ZN2v88internal7tracing16TraceEventHelper20GetTracingControllerEv() #9
  %120 = load i8*, i8** %114, align 8
  %121 = getelementptr inbounds %"class.v8::internal::tracing::ScopedTracer", %"class.v8::internal::tracing::ScopedTracer"* %7, i64 0, i32 1, i32 1
  %122 = load i8*, i8** %121, align 8
  %123 = getelementptr inbounds %"class.v8::internal::tracing::ScopedTracer", %"class.v8::internal::tracing::ScopedTracer"* %7, i64 0, i32 1, i32 2
  %124 = load i64, i64* %123, align 8
  %125 = bitcast %"class.v8::TracingController"* %119 to void (%"class.v8::TracingController"*, i8*, i8*, i64)***
  %126 = load void (%"class.v8::TracingController"*, i8*, i8*, i64)**, void (%"class.v8::TracingController"*, i8*, i8*, i64)*** %125, align 8
  %127 = getelementptr inbounds void (%"class.v8::TracingController"*, i8*, i8*, i64)*, void (%"class.v8::TracingController"*, i8*, i8*, i64)** %126, i64 5
  %128 = load void (%"class.v8::TracingController"*, i8*, i8*, i64)*, void (%"class.v8::TracingController"*, i8*, i8*, i64)** %127, align 8
  call void %128(%"class.v8::TracingController"* %119, i8* %120, i8* %122, i64 %124) #9
  br label %129

129:                                              ; preds = %109, %113, %118
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %43) #9
  call void @_ZN2v88internal15TimerEventScopeINS0_29TimerEventRecompileConcurrentEE13LogTimerEventENS0_6Logger8StartEndE(%"class.v8::internal::TimerEventScope"* nonnull %6, i32 1) #9
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %26) #9
  %130 = getelementptr inbounds %"class.v8::internal::RuntimeCallTimerScope", %"class.v8::internal::RuntimeCallTimerScope"* %5, i64 0, i32 0
  %131 = load %"class.v8::internal::RuntimeCallStats"*, %"class.v8::internal::RuntimeCallStats"** %130, align 8
  %132 = icmp eq %"class.v8::internal::RuntimeCallStats"* %131, null
  br i1 %132, label %134, label %133, !prof !9

133:                                              ; preds = %129
  call void @_ZN2v88internal16RuntimeCallStats5LeaveEPNS0_16RuntimeCallTimerE(%"class.v8::internal::RuntimeCallStats"* nonnull %131, %"class.v8::internal::RuntimeCallTimer"* %18) #9
  br label %134

134:                                              ; preds = %129, %133
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %16) #9
  %135 = load %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.v8::internal::OptimizingCompileDispatcher"** %80, align 8
  %136 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %135, i64 0, i32 11
  call void @_ZN2v84base5Mutex4LockEv(%"class.v8::base::Mutex"* %136) #9
  %137 = load %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.v8::internal::OptimizingCompileDispatcher"** %80, align 8
  %138 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %137, i64 0, i32 10
  %139 = load i32, i32* %138, align 4
  %140 = add nsw i32 %139, -1
  store i32 %140, i32* %138, align 4
  %141 = icmp eq i32 %140, 0
  br i1 %141, label %142, label %145

142:                                              ; preds = %134
  %143 = load %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.v8::internal::OptimizingCompileDispatcher"** %80, align 8
  %144 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher", %"class.v8::internal::OptimizingCompileDispatcher"* %143, i64 0, i32 12
  call void @_ZN2v84base17ConditionVariable9NotifyOneEv(%"class.v8::base::ConditionVariable"* %144) #9
  br label %145

145:                                              ; preds = %142, %134
  call void @_ZN2v84base5Mutex6UnlockEv(%"class.v8::base::Mutex"* %136) #9
  call void @_ZN2v88internal12LocalIsolateD1Ev(%"class.v8::internal::LocalIsolate"* nonnull %4) #9
  call void @llvm.lifetime.end.p0i8(i64 184, i8* nonnull %11) #9
  call void @_ZN2v88internal33WorkerThreadRuntimeCallStatsScopeD1Ev(%"class.v8::internal::WorkerThreadRuntimeCallStatsScope"* nonnull %3) #9
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %8) #9
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZThn32_N2v88internal27OptimizingCompileDispatcher11CompileTaskD1Ev(%"class.v8::internal::OptimizingCompileDispatcher::CompileTask"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher::CompileTask", %"class.v8::internal::OptimizingCompileDispatcher::CompileTask"* %0, i64 -1, i32 0, i32 1
  %3 = bitcast %"class.v8::Task"* %2 to %"class.v8::internal::Cancelable"*
  tail call void @_ZN2v88internal10CancelableD2Ev(%"class.v8::internal::Cancelable"* %3) #9
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZThn32_N2v88internal27OptimizingCompileDispatcher11CompileTaskD0Ev(%"class.v8::internal::OptimizingCompileDispatcher::CompileTask"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OptimizingCompileDispatcher::CompileTask", %"class.v8::internal::OptimizingCompileDispatcher::CompileTask"* %0, i64 -1, i32 0, i32 1
  %3 = bitcast %"class.v8::Task"* %2 to %"class.v8::internal::Cancelable"*
  tail call void @_ZN2v88internal10CancelableD2Ev(%"class.v8::internal::Cancelable"* %3) #9
  %4 = bitcast %"class.v8::Task"* %2 to i8*
  tail call void @_ZdlPv(i8* %4) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZThn32_N2v88internal14CancelableTask3RunEv(%"class.v8::internal::CancelableTask"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::CancelableTask", %"class.v8::internal::CancelableTask"* %0, i64 -1, i32 0, i32 1
  %3 = getelementptr inbounds %"class.v8::internal::CancelableTaskManager"*, %"class.v8::internal::CancelableTaskManager"** %2, i64 2
  %4 = bitcast %"class.v8::internal::CancelableTaskManager"** %3 to i32*
  %5 = cmpxchg i32* %4, i32 0, i32 2 acq_rel acquire
  %6 = extractvalue { i32, i1 } %5, 1
  br i1 %6, label %7, label %13

7:                                                ; preds = %1
  %8 = bitcast %"class.v8::internal::CancelableTaskManager"** %2 to %"class.v8::internal::CancelableTask"*
  %9 = bitcast %"class.v8::internal::CancelableTaskManager"** %2 to void (%"class.v8::internal::CancelableTask"*)***
  %10 = load void (%"class.v8::internal::CancelableTask"*)**, void (%"class.v8::internal::CancelableTask"*)*** %9, align 8
  %11 = getelementptr inbounds void (%"class.v8::internal::CancelableTask"*)*, void (%"class.v8::internal::CancelableTask"*)** %10, i64 3
  %12 = load void (%"class.v8::internal::CancelableTask"*)*, void (%"class.v8::internal::CancelableTask"*)** %11, align 8
  tail call void %12(%"class.v8::internal::CancelableTask"* %8) #9
  br label %13

13:                                               ; preds = %1, %7
  ret void
}

; Function Attrs: nounwind
declare void @_ZN2v88internal10CancelableD2Ev(%"class.v8::internal::Cancelable"*) unnamed_addr #1

declare void @_ZN2v88internal33WorkerThreadRuntimeCallStatsScopeC1EPNS0_28WorkerThreadRuntimeCallStatsE(%"class.v8::internal::WorkerThreadRuntimeCallStatsScope"*, %"class.v8::internal::WorkerThreadRuntimeCallStats"*) unnamed_addr #3

declare void @_ZN2v88internal12LocalIsolateC1EPNS0_7IsolateENS0_10ThreadKindEPNS0_16RuntimeCallStatsE(%"class.v8::internal::LocalIsolate"*, %"class.v8::internal::Isolate"*, i32, %"class.v8::internal::RuntimeCallStats"*) unnamed_addr #3

declare %"class.v8::TracingController"* @_ZN2v88internal7tracing16TraceEventHelper20GetTracingControllerEv() local_unnamed_addr #3

declare void @_ZN2v84base2OS5SleepENS0_9TimeDeltaE(i64) local_unnamed_addr #3

declare void @_ZN2v84base17ConditionVariable9NotifyOneEv(%"class.v8::base::ConditionVariable"*) local_unnamed_addr #3

; Function Attrs: nounwind
declare void @_ZN2v88internal12LocalIsolateD1Ev(%"class.v8::internal::LocalIsolate"*) unnamed_addr #1

; Function Attrs: nounwind
declare void @_ZN2v88internal33WorkerThreadRuntimeCallStatsScopeD1Ev(%"class.v8::internal::WorkerThreadRuntimeCallStatsScope"*) unnamed_addr #1

declare void @_ZN2v88internal16RuntimeCallStats5EnterEPNS0_16RuntimeCallTimerENS0_20RuntimeCallCounterIdE(%"class.v8::internal::RuntimeCallStats"*, %"class.v8::internal::RuntimeCallTimer"*, i32) local_unnamed_addr #3

declare void @_ZN2v88internal15TimerEventScopeINS0_29TimerEventRecompileConcurrentEE13LogTimerEventENS0_6Logger8StartEndE(%"class.v8::internal::TimerEventScope"*, i32) local_unnamed_addr #3

declare void @_ZN2v88internal16RuntimeCallStats5LeaveEPNS0_16RuntimeCallTimerE(%"class.v8::internal::RuntimeCallStats"*, %"class.v8::internal::RuntimeCallTimer"*) local_unnamed_addr #3

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { argmemonly nounwind }
attributes #3 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nobuiltin nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { noreturn nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nobuiltin nofree "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { builtin nounwind }
attributes #9 = { nounwind }
attributes #10 = { noreturn nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i8 0, i8 2}
!3 = distinct !{!3, !4}
!4 = !{!"llvm.loop.unroll.disable"}
!5 = distinct !{!5, !4}
!6 = distinct !{!6, !4}
!7 = distinct !{!7, !4}
!8 = distinct !{!8, !4}
!9 = !{!"branch_weights", i32 2000, i32 1}
