; ModuleID = '../../third_party/libaom/source/libaom/aom_dsp/x86/masked_sad4d_ssse3.c'
source_filename = "../../third_party/libaom/source/libaom/aom_dsp/x86/masked_sad4d_ssse3.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad8xhx4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %12 = icmp sgt i32 %8, 0
  br i1 %12, label %13, label %34

13:                                               ; preds = %11
  %14 = getelementptr inbounds i8*, i8** %2, i64 3
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds i8*, i8** %2, i64 2
  %17 = load i8*, i8** %16, align 8
  %18 = getelementptr inbounds i8*, i8** %2, i64 1
  %19 = load i8*, i8** %18, align 8
  %20 = load i8*, i8** %2, align 8
  %21 = sext i32 %1 to i64
  %22 = sext i32 %5 to i64
  %23 = sext i32 %7 to i64
  %24 = icmp ne i32 %9, 0
  %25 = sext i32 %3 to i64
  %26 = shl nsw i32 %3, 1
  %27 = sext i32 %26 to i64
  %28 = shl nsw i32 %1, 1
  %29 = sext i32 %28 to i64
  %30 = shl nsw i32 %5, 1
  %31 = sext i32 %30 to i64
  %32 = shl nsw i32 %7, 1
  %33 = sext i32 %32 to i64
  br label %49

34:                                               ; preds = %49, %11
  %35 = phi <4 x i32> [ zeroinitializer, %11 ], [ %157, %49 ]
  %36 = phi <4 x i32> [ zeroinitializer, %11 ], [ %178, %49 ]
  %37 = phi <4 x i32> [ zeroinitializer, %11 ], [ %136, %49 ]
  %38 = phi <4 x i32> [ zeroinitializer, %11 ], [ %115, %49 ]
  %39 = shufflevector <4 x i32> %38, <4 x i32> %37, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %40 = shufflevector <4 x i32> %38, <4 x i32> %37, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %41 = add <4 x i32> %40, %39
  %42 = bitcast <4 x i32> %41 to <2 x i64>
  %43 = shufflevector <4 x i32> %35, <4 x i32> %36, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %44 = shufflevector <4 x i32> %35, <4 x i32> %36, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %45 = add <4 x i32> %44, %43
  %46 = bitcast <4 x i32> %45 to <2 x i64>
  %47 = shufflevector <2 x i64> %42, <2 x i64> %46, <2 x i32> <i32 0, i32 2>
  %48 = bitcast i32* %10 to <2 x i64>*
  store <2 x i64> %47, <2 x i64>* %48, align 1
  ret void

49:                                               ; preds = %13, %49
  %50 = phi i8* [ %0, %13 ], [ %183, %49 ]
  %51 = phi i8* [ %4, %13 ], [ %184, %49 ]
  %52 = phi i8* [ %6, %13 ], [ %185, %49 ]
  %53 = phi i8* [ %20, %13 ], [ %179, %49 ]
  %54 = phi i8* [ %19, %13 ], [ %180, %49 ]
  %55 = phi i8* [ %17, %13 ], [ %181, %49 ]
  %56 = phi i8* [ %15, %13 ], [ %182, %49 ]
  %57 = phi <4 x i32> [ zeroinitializer, %13 ], [ %115, %49 ]
  %58 = phi <4 x i32> [ zeroinitializer, %13 ], [ %136, %49 ]
  %59 = phi i32 [ 0, %13 ], [ %186, %49 ]
  %60 = phi <4 x i32> [ zeroinitializer, %13 ], [ %178, %49 ]
  %61 = phi <4 x i32> [ zeroinitializer, %13 ], [ %157, %49 ]
  %62 = bitcast i8* %50 to i64*
  %63 = load i64, i64* %62, align 1
  %64 = insertelement <2 x i64> undef, i64 %63, i32 0
  %65 = getelementptr inbounds i8, i8* %50, i64 %21
  %66 = bitcast i8* %65 to i64*
  %67 = load i64, i64* %66, align 1
  %68 = insertelement <2 x i64> %64, i64 %67, i32 1
  %69 = bitcast i8* %51 to i64*
  %70 = load i64, i64* %69, align 1
  %71 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %70, i32 0
  %72 = getelementptr inbounds i8, i8* %51, i64 %22
  %73 = bitcast i8* %72 to i64*
  %74 = load i64, i64* %73, align 1
  %75 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %74, i32 0
  %76 = bitcast i8* %52 to i64*
  %77 = load i64, i64* %76, align 1
  %78 = insertelement <2 x i64> undef, i64 %77, i32 0
  %79 = getelementptr inbounds i8, i8* %52, i64 %23
  %80 = bitcast i8* %79 to i64*
  %81 = load i64, i64* %80, align 1
  %82 = insertelement <2 x i64> %78, i64 %81, i32 1
  %83 = bitcast <2 x i64> %82 to <16 x i8>
  %84 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %83
  %85 = bitcast <16 x i8> %84 to <2 x i64>
  %86 = select i1 %24, <2 x i64> %85, <2 x i64> %82
  %87 = select i1 %24, <2 x i64> %82, <2 x i64> %85
  %88 = bitcast i8* %53 to i64*
  %89 = load i64, i64* %88, align 1
  %90 = insertelement <2 x i64> undef, i64 %89, i32 0
  %91 = getelementptr inbounds i8, i8* %53, i64 %25
  %92 = bitcast i8* %91 to i64*
  %93 = load i64, i64* %92, align 1
  %94 = insertelement <2 x i64> undef, i64 %93, i32 0
  %95 = bitcast <2 x i64> %90 to <16 x i8>
  %96 = bitcast <2 x i64> %71 to <16 x i8>
  %97 = shufflevector <16 x i8> %95, <16 x i8> %96, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %98 = bitcast <2 x i64> %86 to <16 x i8>
  %99 = bitcast <2 x i64> %87 to <16 x i8>
  %100 = shufflevector <16 x i8> %98, <16 x i8> %99, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %101 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %97, <16 x i8> %100) #2
  %102 = lshr <8 x i16> %101, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %103 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %102, <8 x i16> zeroinitializer) #2
  %104 = bitcast <2 x i64> %94 to <16 x i8>
  %105 = bitcast <2 x i64> %75 to <16 x i8>
  %106 = shufflevector <16 x i8> %104, <16 x i8> %105, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %107 = shufflevector <16 x i8> %98, <16 x i8> %99, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %108 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %106, <16 x i8> %107) #2
  %109 = lshr <8 x i16> %108, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %110 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %109, <8 x i16> zeroinitializer) #2
  %111 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %103, <8 x i16> %110) #2
  %112 = bitcast <2 x i64> %68 to <16 x i8>
  %113 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %111, <16 x i8> %112) #2
  %114 = bitcast <2 x i64> %113 to <4 x i32>
  %115 = add <4 x i32> %57, %114
  %116 = bitcast i8* %54 to i64*
  %117 = load i64, i64* %116, align 1
  %118 = insertelement <2 x i64> undef, i64 %117, i32 0
  %119 = getelementptr inbounds i8, i8* %54, i64 %25
  %120 = bitcast i8* %119 to i64*
  %121 = load i64, i64* %120, align 1
  %122 = insertelement <2 x i64> undef, i64 %121, i32 0
  %123 = bitcast <2 x i64> %118 to <16 x i8>
  %124 = shufflevector <16 x i8> %123, <16 x i8> %96, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %125 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %124, <16 x i8> %100) #2
  %126 = lshr <8 x i16> %125, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %127 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %126, <8 x i16> zeroinitializer) #2
  %128 = bitcast <2 x i64> %122 to <16 x i8>
  %129 = shufflevector <16 x i8> %128, <16 x i8> %105, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %130 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %129, <16 x i8> %107) #2
  %131 = lshr <8 x i16> %130, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %132 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %131, <8 x i16> zeroinitializer) #2
  %133 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %127, <8 x i16> %132) #2
  %134 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %133, <16 x i8> %112) #2
  %135 = bitcast <2 x i64> %134 to <4 x i32>
  %136 = add <4 x i32> %58, %135
  %137 = bitcast i8* %55 to i64*
  %138 = load i64, i64* %137, align 1
  %139 = insertelement <2 x i64> undef, i64 %138, i32 0
  %140 = getelementptr inbounds i8, i8* %55, i64 %25
  %141 = bitcast i8* %140 to i64*
  %142 = load i64, i64* %141, align 1
  %143 = insertelement <2 x i64> undef, i64 %142, i32 0
  %144 = bitcast <2 x i64> %139 to <16 x i8>
  %145 = shufflevector <16 x i8> %144, <16 x i8> %96, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %146 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %145, <16 x i8> %100) #2
  %147 = lshr <8 x i16> %146, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %148 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %147, <8 x i16> zeroinitializer) #2
  %149 = bitcast <2 x i64> %143 to <16 x i8>
  %150 = shufflevector <16 x i8> %149, <16 x i8> %105, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %151 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %150, <16 x i8> %107) #2
  %152 = lshr <8 x i16> %151, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %153 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %152, <8 x i16> zeroinitializer) #2
  %154 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %148, <8 x i16> %153) #2
  %155 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %154, <16 x i8> %112) #2
  %156 = bitcast <2 x i64> %155 to <4 x i32>
  %157 = add <4 x i32> %61, %156
  %158 = bitcast i8* %56 to i64*
  %159 = load i64, i64* %158, align 1
  %160 = insertelement <2 x i64> undef, i64 %159, i32 0
  %161 = getelementptr inbounds i8, i8* %56, i64 %25
  %162 = bitcast i8* %161 to i64*
  %163 = load i64, i64* %162, align 1
  %164 = insertelement <2 x i64> undef, i64 %163, i32 0
  %165 = bitcast <2 x i64> %160 to <16 x i8>
  %166 = shufflevector <16 x i8> %165, <16 x i8> %96, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %167 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %166, <16 x i8> %100) #2
  %168 = lshr <8 x i16> %167, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %169 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %168, <8 x i16> zeroinitializer) #2
  %170 = bitcast <2 x i64> %164 to <16 x i8>
  %171 = shufflevector <16 x i8> %170, <16 x i8> %105, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %172 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %171, <16 x i8> %107) #2
  %173 = lshr <8 x i16> %172, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %174 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %173, <8 x i16> zeroinitializer) #2
  %175 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %169, <8 x i16> %174) #2
  %176 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %175, <16 x i8> %112) #2
  %177 = bitcast <2 x i64> %176 to <4 x i32>
  %178 = add <4 x i32> %60, %177
  %179 = getelementptr inbounds i8, i8* %53, i64 %27
  %180 = getelementptr inbounds i8, i8* %54, i64 %27
  %181 = getelementptr inbounds i8, i8* %55, i64 %27
  %182 = getelementptr inbounds i8, i8* %56, i64 %27
  %183 = getelementptr inbounds i8, i8* %50, i64 %29
  %184 = getelementptr inbounds i8, i8* %51, i64 %31
  %185 = getelementptr inbounds i8, i8* %52, i64 %33
  %186 = add nuw nsw i32 %59, 2
  %187 = icmp slt i32 %186, %8
  br i1 %187, label %49, label %34
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad4xhx4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %12 = icmp sgt i32 %8, 0
  br i1 %12, label %13, label %34

13:                                               ; preds = %11
  %14 = getelementptr inbounds i8*, i8** %2, i64 3
  %15 = load i8*, i8** %14, align 8
  %16 = getelementptr inbounds i8*, i8** %2, i64 2
  %17 = load i8*, i8** %16, align 8
  %18 = getelementptr inbounds i8*, i8** %2, i64 1
  %19 = load i8*, i8** %18, align 8
  %20 = load i8*, i8** %2, align 8
  %21 = sext i32 %1 to i64
  %22 = sext i32 %5 to i64
  %23 = sext i32 %7 to i64
  %24 = icmp ne i32 %9, 0
  %25 = sext i32 %3 to i64
  %26 = shl nsw i32 %3, 1
  %27 = sext i32 %26 to i64
  %28 = shl nsw i32 %1, 1
  %29 = sext i32 %28 to i64
  %30 = shl nsw i32 %5, 1
  %31 = sext i32 %30 to i64
  %32 = shl nsw i32 %7, 1
  %33 = sext i32 %32 to i64
  br label %45

34:                                               ; preds = %45, %11
  %35 = phi <4 x i32> [ zeroinitializer, %11 ], [ %108, %45 ]
  %36 = phi <4 x i32> [ zeroinitializer, %11 ], [ %124, %45 ]
  %37 = phi <4 x i32> [ zeroinitializer, %11 ], [ %140, %45 ]
  %38 = phi <4 x i32> [ zeroinitializer, %11 ], [ %156, %45 ]
  %39 = shufflevector <4 x i32> %35, <4 x i32> %36, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %40 = bitcast <4 x i32> %39 to <2 x i64>
  %41 = shufflevector <4 x i32> %37, <4 x i32> %38, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %42 = bitcast <4 x i32> %41 to <2 x i64>
  %43 = shufflevector <2 x i64> %40, <2 x i64> %42, <2 x i32> <i32 0, i32 2>
  %44 = bitcast i32* %10 to <2 x i64>*
  store <2 x i64> %43, <2 x i64>* %44, align 1
  ret void

45:                                               ; preds = %13, %45
  %46 = phi i8* [ %0, %13 ], [ %161, %45 ]
  %47 = phi i8* [ %4, %13 ], [ %162, %45 ]
  %48 = phi i8* [ %6, %13 ], [ %163, %45 ]
  %49 = phi i8* [ %20, %13 ], [ %157, %45 ]
  %50 = phi i8* [ %19, %13 ], [ %158, %45 ]
  %51 = phi i32 [ 0, %13 ], [ %164, %45 ]
  %52 = phi <4 x i32> [ zeroinitializer, %13 ], [ %156, %45 ]
  %53 = phi <4 x i32> [ zeroinitializer, %13 ], [ %140, %45 ]
  %54 = phi <4 x i32> [ zeroinitializer, %13 ], [ %124, %45 ]
  %55 = phi <4 x i32> [ zeroinitializer, %13 ], [ %108, %45 ]
  %56 = phi i8* [ %15, %13 ], [ %160, %45 ]
  %57 = phi i8* [ %17, %13 ], [ %159, %45 ]
  %58 = bitcast i8* %46 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %59, i32 0
  %61 = getelementptr inbounds i8, i8* %46, i64 %21
  %62 = bitcast i8* %61 to i32*
  %63 = load i32, i32* %62, align 4
  %64 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %63, i32 0
  %65 = shufflevector <4 x i32> %60, <4 x i32> %64, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %66 = bitcast i8* %47 to i32*
  %67 = load i32, i32* %66, align 4
  %68 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %67, i32 0
  %69 = getelementptr inbounds i8, i8* %47, i64 %22
  %70 = bitcast i8* %69 to i32*
  %71 = load i32, i32* %70, align 4
  %72 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %71, i32 0
  %73 = shufflevector <4 x i32> %68, <4 x i32> %72, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %74 = bitcast i8* %48 to i32*
  %75 = load i32, i32* %74, align 4
  %76 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %75, i32 0
  %77 = getelementptr inbounds i8, i8* %48, i64 %23
  %78 = bitcast i8* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %79, i32 0
  %81 = shufflevector <4 x i32> %76, <4 x i32> %80, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %82 = bitcast <4 x i32> %81 to <2 x i64>
  %83 = bitcast <4 x i32> %81 to <16 x i8>
  %84 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %83
  %85 = bitcast <16 x i8> %84 to <2 x i64>
  %86 = select i1 %24, <2 x i64> %85, <2 x i64> %82
  %87 = select i1 %24, <2 x i64> %82, <2 x i64> %85
  %88 = bitcast i8* %49 to i32*
  %89 = load i32, i32* %88, align 4
  %90 = insertelement <4 x i32> undef, i32 %89, i32 0
  %91 = getelementptr inbounds i8, i8* %49, i64 %25
  %92 = bitcast i8* %91 to i32*
  %93 = load i32, i32* %92, align 4
  %94 = insertelement <4 x i32> %90, i32 %93, i32 1
  %95 = bitcast <4 x i32> %94 to <16 x i8>
  %96 = bitcast <4 x i32> %73 to <16 x i8>
  %97 = shufflevector <16 x i8> %95, <16 x i8> %96, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %98 = bitcast <2 x i64> %86 to <16 x i8>
  %99 = bitcast <2 x i64> %87 to <16 x i8>
  %100 = shufflevector <16 x i8> %98, <16 x i8> %99, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %101 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %97, <16 x i8> %100) #2
  %102 = lshr <8 x i16> %101, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %103 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %102, <8 x i16> zeroinitializer) #2
  %104 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %103, <8 x i16> zeroinitializer) #2
  %105 = bitcast <4 x i32> %65 to <16 x i8>
  %106 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %104, <16 x i8> %105) #2
  %107 = bitcast <2 x i64> %106 to <4 x i32>
  %108 = add <4 x i32> %55, %107
  %109 = bitcast i8* %50 to i32*
  %110 = load i32, i32* %109, align 4
  %111 = insertelement <4 x i32> undef, i32 %110, i32 0
  %112 = getelementptr inbounds i8, i8* %50, i64 %25
  %113 = bitcast i8* %112 to i32*
  %114 = load i32, i32* %113, align 4
  %115 = insertelement <4 x i32> %111, i32 %114, i32 1
  %116 = bitcast <4 x i32> %115 to <16 x i8>
  %117 = shufflevector <16 x i8> %116, <16 x i8> %96, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %118 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %117, <16 x i8> %100) #2
  %119 = lshr <8 x i16> %118, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %120 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %119, <8 x i16> zeroinitializer) #2
  %121 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %120, <8 x i16> zeroinitializer) #2
  %122 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %121, <16 x i8> %105) #2
  %123 = bitcast <2 x i64> %122 to <4 x i32>
  %124 = add <4 x i32> %54, %123
  %125 = bitcast i8* %57 to i32*
  %126 = load i32, i32* %125, align 4
  %127 = insertelement <4 x i32> undef, i32 %126, i32 0
  %128 = getelementptr inbounds i8, i8* %57, i64 %25
  %129 = bitcast i8* %128 to i32*
  %130 = load i32, i32* %129, align 4
  %131 = insertelement <4 x i32> %127, i32 %130, i32 1
  %132 = bitcast <4 x i32> %131 to <16 x i8>
  %133 = shufflevector <16 x i8> %132, <16 x i8> %96, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %134 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %133, <16 x i8> %100) #2
  %135 = lshr <8 x i16> %134, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %136 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %135, <8 x i16> zeroinitializer) #2
  %137 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %136, <8 x i16> zeroinitializer) #2
  %138 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %137, <16 x i8> %105) #2
  %139 = bitcast <2 x i64> %138 to <4 x i32>
  %140 = add <4 x i32> %53, %139
  %141 = bitcast i8* %56 to i32*
  %142 = load i32, i32* %141, align 4
  %143 = insertelement <4 x i32> undef, i32 %142, i32 0
  %144 = getelementptr inbounds i8, i8* %56, i64 %25
  %145 = bitcast i8* %144 to i32*
  %146 = load i32, i32* %145, align 4
  %147 = insertelement <4 x i32> %143, i32 %146, i32 1
  %148 = bitcast <4 x i32> %147 to <16 x i8>
  %149 = shufflevector <16 x i8> %148, <16 x i8> %96, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %150 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %149, <16 x i8> %100) #2
  %151 = lshr <8 x i16> %150, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %152 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %151, <8 x i16> zeroinitializer) #2
  %153 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %152, <8 x i16> zeroinitializer) #2
  %154 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %153, <16 x i8> %105) #2
  %155 = bitcast <2 x i64> %154 to <4 x i32>
  %156 = add <4 x i32> %52, %155
  %157 = getelementptr inbounds i8, i8* %49, i64 %27
  %158 = getelementptr inbounds i8, i8* %50, i64 %27
  %159 = getelementptr inbounds i8, i8* %57, i64 %27
  %160 = getelementptr inbounds i8, i8* %56, i64 %27
  %161 = getelementptr inbounds i8, i8* %46, i64 %29
  %162 = getelementptr inbounds i8, i8* %47, i64 %31
  %163 = getelementptr inbounds i8, i8* %48, i64 %33
  %164 = add nuw nsw i32 %51, 2
  %165 = icmp slt i32 %164, %8
  br i1 %165, label %45, label %34
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad128x128x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %120, %9
  %22 = phi i8* [ %0, %9 ], [ %121, %120 ]
  %23 = phi i8* [ %4, %9 ], [ %126, %120 ]
  %24 = phi i8* [ %5, %9 ], [ %127, %120 ]
  %25 = phi i32 [ 0, %9 ], [ %128, %120 ]
  %26 = phi i8* [ %11, %9 ], [ %125, %120 ]
  %27 = phi i8* [ %13, %9 ], [ %124, %120 ]
  %28 = phi i8* [ %15, %9 ], [ %123, %120 ]
  %29 = phi i8* [ %16, %9 ], [ %122, %120 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %117, %120 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %102, %120 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %87, %120 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %72, %120 ]
  br label %34

34:                                               ; preds = %34, %21
  %35 = phi i64 [ %118, %34 ], [ 0, %21 ]
  %36 = phi <4 x i32> [ %117, %34 ], [ %30, %21 ]
  %37 = phi <4 x i32> [ %102, %34 ], [ %31, %21 ]
  %38 = phi <4 x i32> [ %87, %34 ], [ %32, %21 ]
  %39 = phi <4 x i32> [ %72, %34 ], [ %33, %21 ]
  %40 = getelementptr inbounds i8, i8* %22, i64 %35
  %41 = bitcast i8* %40 to <16 x i8>*
  %42 = load <16 x i8>, <16 x i8>* %41, align 1
  %43 = getelementptr inbounds i8, i8* %23, i64 %35
  %44 = bitcast i8* %43 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 1
  %46 = getelementptr inbounds i8, i8* %24, i64 %35
  %47 = bitcast i8* %46 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 1
  %49 = bitcast <2 x i64> %48 to <16 x i8>
  %50 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %49
  %51 = bitcast <16 x i8> %50 to <2 x i64>
  %52 = select i1 %17, <2 x i64> %51, <2 x i64> %48
  %53 = select i1 %17, <2 x i64> %48, <2 x i64> %51
  %54 = getelementptr inbounds i8, i8* %29, i64 %35
  %55 = bitcast i8* %54 to <16 x i8>*
  %56 = load <16 x i8>, <16 x i8>* %55, align 1
  %57 = shufflevector <16 x i8> %56, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %58 = bitcast <2 x i64> %52 to <16 x i8>
  %59 = bitcast <2 x i64> %53 to <16 x i8>
  %60 = shufflevector <16 x i8> %58, <16 x i8> %59, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %61 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %57, <16 x i8> %60) #2
  %62 = lshr <8 x i16> %61, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %63 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %62, <8 x i16> zeroinitializer) #2
  %64 = shufflevector <16 x i8> %56, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %65 = shufflevector <16 x i8> %58, <16 x i8> %59, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %64, <16 x i8> %65) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %63, <8 x i16> %68) #2
  %70 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %69, <16 x i8> %42) #2
  %71 = bitcast <2 x i64> %70 to <4 x i32>
  %72 = add <4 x i32> %39, %71
  %73 = getelementptr inbounds i8, i8* %28, i64 %35
  %74 = bitcast i8* %73 to <16 x i8>*
  %75 = load <16 x i8>, <16 x i8>* %74, align 1
  %76 = shufflevector <16 x i8> %75, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %77 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %76, <16 x i8> %60) #2
  %78 = lshr <8 x i16> %77, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %79 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %78, <8 x i16> zeroinitializer) #2
  %80 = shufflevector <16 x i8> %75, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %81 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %80, <16 x i8> %65) #2
  %82 = lshr <8 x i16> %81, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %83 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %82, <8 x i16> zeroinitializer) #2
  %84 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> %83) #2
  %85 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %84, <16 x i8> %42) #2
  %86 = bitcast <2 x i64> %85 to <4 x i32>
  %87 = add <4 x i32> %38, %86
  %88 = getelementptr inbounds i8, i8* %27, i64 %35
  %89 = bitcast i8* %88 to <16 x i8>*
  %90 = load <16 x i8>, <16 x i8>* %89, align 1
  %91 = shufflevector <16 x i8> %90, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %92 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %91, <16 x i8> %60) #2
  %93 = lshr <8 x i16> %92, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %94 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %93, <8 x i16> zeroinitializer) #2
  %95 = shufflevector <16 x i8> %90, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %96 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %95, <16 x i8> %65) #2
  %97 = lshr <8 x i16> %96, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #2
  %99 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %94, <8 x i16> %98) #2
  %100 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %99, <16 x i8> %42) #2
  %101 = bitcast <2 x i64> %100 to <4 x i32>
  %102 = add <4 x i32> %37, %101
  %103 = getelementptr inbounds i8, i8* %26, i64 %35
  %104 = bitcast i8* %103 to <16 x i8>*
  %105 = load <16 x i8>, <16 x i8>* %104, align 1
  %106 = shufflevector <16 x i8> %105, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %107 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %106, <16 x i8> %60) #2
  %108 = lshr <8 x i16> %107, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %109 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %108, <8 x i16> zeroinitializer) #2
  %110 = shufflevector <16 x i8> %105, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %111 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %110, <16 x i8> %65) #2
  %112 = lshr <8 x i16> %111, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %113 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %112, <8 x i16> zeroinitializer) #2
  %114 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> %113) #2
  %115 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %114, <16 x i8> %42) #2
  %116 = bitcast <2 x i64> %115 to <4 x i32>
  %117 = add <4 x i32> %36, %116
  %118 = add nuw nsw i64 %35, 16
  %119 = icmp ult i64 %118, 128
  br i1 %119, label %34, label %120

120:                                              ; preds = %34
  %121 = getelementptr inbounds i8, i8* %22, i64 %18
  %122 = getelementptr inbounds i8, i8* %29, i64 %19
  %123 = getelementptr inbounds i8, i8* %28, i64 %19
  %124 = getelementptr inbounds i8, i8* %27, i64 %19
  %125 = getelementptr inbounds i8, i8* %26, i64 %19
  %126 = getelementptr inbounds i8, i8* %23, i64 128
  %127 = getelementptr inbounds i8, i8* %24, i64 %20
  %128 = add nuw nsw i32 %25, 1
  %129 = icmp eq i32 %128, 128
  br i1 %129, label %130, label %21

130:                                              ; preds = %120
  %131 = shufflevector <4 x i32> %72, <4 x i32> %87, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %132 = shufflevector <4 x i32> %72, <4 x i32> %87, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %133 = add <4 x i32> %132, %131
  %134 = bitcast <4 x i32> %133 to <2 x i64>
  %135 = shufflevector <4 x i32> %102, <4 x i32> %117, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %136 = shufflevector <4 x i32> %102, <4 x i32> %117, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %137 = add <4 x i32> %136, %135
  %138 = bitcast <4 x i32> %137 to <2 x i64>
  %139 = shufflevector <2 x i64> %134, <2 x i64> %138, <2 x i32> <i32 0, i32 2>
  %140 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %139, <2 x i64>* %140, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad128x64x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %120, %9
  %22 = phi i8* [ %0, %9 ], [ %121, %120 ]
  %23 = phi i8* [ %4, %9 ], [ %126, %120 ]
  %24 = phi i8* [ %5, %9 ], [ %127, %120 ]
  %25 = phi i32 [ 0, %9 ], [ %128, %120 ]
  %26 = phi i8* [ %11, %9 ], [ %125, %120 ]
  %27 = phi i8* [ %13, %9 ], [ %124, %120 ]
  %28 = phi i8* [ %15, %9 ], [ %123, %120 ]
  %29 = phi i8* [ %16, %9 ], [ %122, %120 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %117, %120 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %102, %120 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %87, %120 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %72, %120 ]
  br label %34

34:                                               ; preds = %34, %21
  %35 = phi i64 [ %118, %34 ], [ 0, %21 ]
  %36 = phi <4 x i32> [ %117, %34 ], [ %30, %21 ]
  %37 = phi <4 x i32> [ %102, %34 ], [ %31, %21 ]
  %38 = phi <4 x i32> [ %87, %34 ], [ %32, %21 ]
  %39 = phi <4 x i32> [ %72, %34 ], [ %33, %21 ]
  %40 = getelementptr inbounds i8, i8* %22, i64 %35
  %41 = bitcast i8* %40 to <16 x i8>*
  %42 = load <16 x i8>, <16 x i8>* %41, align 1
  %43 = getelementptr inbounds i8, i8* %23, i64 %35
  %44 = bitcast i8* %43 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 1
  %46 = getelementptr inbounds i8, i8* %24, i64 %35
  %47 = bitcast i8* %46 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 1
  %49 = bitcast <2 x i64> %48 to <16 x i8>
  %50 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %49
  %51 = bitcast <16 x i8> %50 to <2 x i64>
  %52 = select i1 %17, <2 x i64> %51, <2 x i64> %48
  %53 = select i1 %17, <2 x i64> %48, <2 x i64> %51
  %54 = getelementptr inbounds i8, i8* %29, i64 %35
  %55 = bitcast i8* %54 to <16 x i8>*
  %56 = load <16 x i8>, <16 x i8>* %55, align 1
  %57 = shufflevector <16 x i8> %56, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %58 = bitcast <2 x i64> %52 to <16 x i8>
  %59 = bitcast <2 x i64> %53 to <16 x i8>
  %60 = shufflevector <16 x i8> %58, <16 x i8> %59, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %61 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %57, <16 x i8> %60) #2
  %62 = lshr <8 x i16> %61, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %63 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %62, <8 x i16> zeroinitializer) #2
  %64 = shufflevector <16 x i8> %56, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %65 = shufflevector <16 x i8> %58, <16 x i8> %59, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %64, <16 x i8> %65) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %63, <8 x i16> %68) #2
  %70 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %69, <16 x i8> %42) #2
  %71 = bitcast <2 x i64> %70 to <4 x i32>
  %72 = add <4 x i32> %39, %71
  %73 = getelementptr inbounds i8, i8* %28, i64 %35
  %74 = bitcast i8* %73 to <16 x i8>*
  %75 = load <16 x i8>, <16 x i8>* %74, align 1
  %76 = shufflevector <16 x i8> %75, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %77 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %76, <16 x i8> %60) #2
  %78 = lshr <8 x i16> %77, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %79 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %78, <8 x i16> zeroinitializer) #2
  %80 = shufflevector <16 x i8> %75, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %81 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %80, <16 x i8> %65) #2
  %82 = lshr <8 x i16> %81, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %83 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %82, <8 x i16> zeroinitializer) #2
  %84 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> %83) #2
  %85 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %84, <16 x i8> %42) #2
  %86 = bitcast <2 x i64> %85 to <4 x i32>
  %87 = add <4 x i32> %38, %86
  %88 = getelementptr inbounds i8, i8* %27, i64 %35
  %89 = bitcast i8* %88 to <16 x i8>*
  %90 = load <16 x i8>, <16 x i8>* %89, align 1
  %91 = shufflevector <16 x i8> %90, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %92 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %91, <16 x i8> %60) #2
  %93 = lshr <8 x i16> %92, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %94 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %93, <8 x i16> zeroinitializer) #2
  %95 = shufflevector <16 x i8> %90, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %96 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %95, <16 x i8> %65) #2
  %97 = lshr <8 x i16> %96, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #2
  %99 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %94, <8 x i16> %98) #2
  %100 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %99, <16 x i8> %42) #2
  %101 = bitcast <2 x i64> %100 to <4 x i32>
  %102 = add <4 x i32> %37, %101
  %103 = getelementptr inbounds i8, i8* %26, i64 %35
  %104 = bitcast i8* %103 to <16 x i8>*
  %105 = load <16 x i8>, <16 x i8>* %104, align 1
  %106 = shufflevector <16 x i8> %105, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %107 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %106, <16 x i8> %60) #2
  %108 = lshr <8 x i16> %107, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %109 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %108, <8 x i16> zeroinitializer) #2
  %110 = shufflevector <16 x i8> %105, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %111 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %110, <16 x i8> %65) #2
  %112 = lshr <8 x i16> %111, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %113 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %112, <8 x i16> zeroinitializer) #2
  %114 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> %113) #2
  %115 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %114, <16 x i8> %42) #2
  %116 = bitcast <2 x i64> %115 to <4 x i32>
  %117 = add <4 x i32> %36, %116
  %118 = add nuw nsw i64 %35, 16
  %119 = icmp ult i64 %118, 128
  br i1 %119, label %34, label %120

120:                                              ; preds = %34
  %121 = getelementptr inbounds i8, i8* %22, i64 %18
  %122 = getelementptr inbounds i8, i8* %29, i64 %19
  %123 = getelementptr inbounds i8, i8* %28, i64 %19
  %124 = getelementptr inbounds i8, i8* %27, i64 %19
  %125 = getelementptr inbounds i8, i8* %26, i64 %19
  %126 = getelementptr inbounds i8, i8* %23, i64 128
  %127 = getelementptr inbounds i8, i8* %24, i64 %20
  %128 = add nuw nsw i32 %25, 1
  %129 = icmp eq i32 %128, 64
  br i1 %129, label %130, label %21

130:                                              ; preds = %120
  %131 = shufflevector <4 x i32> %72, <4 x i32> %87, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %132 = shufflevector <4 x i32> %72, <4 x i32> %87, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %133 = add <4 x i32> %132, %131
  %134 = bitcast <4 x i32> %133 to <2 x i64>
  %135 = shufflevector <4 x i32> %102, <4 x i32> %117, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %136 = shufflevector <4 x i32> %102, <4 x i32> %117, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %137 = add <4 x i32> %136, %135
  %138 = bitcast <4 x i32> %137 to <2 x i64>
  %139 = shufflevector <2 x i64> %134, <2 x i64> %138, <2 x i32> <i32 0, i32 2>
  %140 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %139, <2 x i64>* %140, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad64x128x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %120, %9
  %22 = phi i8* [ %0, %9 ], [ %121, %120 ]
  %23 = phi i8* [ %4, %9 ], [ %126, %120 ]
  %24 = phi i8* [ %5, %9 ], [ %127, %120 ]
  %25 = phi i32 [ 0, %9 ], [ %128, %120 ]
  %26 = phi i8* [ %11, %9 ], [ %125, %120 ]
  %27 = phi i8* [ %13, %9 ], [ %124, %120 ]
  %28 = phi i8* [ %15, %9 ], [ %123, %120 ]
  %29 = phi i8* [ %16, %9 ], [ %122, %120 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %117, %120 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %102, %120 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %87, %120 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %72, %120 ]
  br label %34

34:                                               ; preds = %34, %21
  %35 = phi i64 [ %118, %34 ], [ 0, %21 ]
  %36 = phi <4 x i32> [ %117, %34 ], [ %30, %21 ]
  %37 = phi <4 x i32> [ %102, %34 ], [ %31, %21 ]
  %38 = phi <4 x i32> [ %87, %34 ], [ %32, %21 ]
  %39 = phi <4 x i32> [ %72, %34 ], [ %33, %21 ]
  %40 = getelementptr inbounds i8, i8* %22, i64 %35
  %41 = bitcast i8* %40 to <16 x i8>*
  %42 = load <16 x i8>, <16 x i8>* %41, align 1
  %43 = getelementptr inbounds i8, i8* %23, i64 %35
  %44 = bitcast i8* %43 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 1
  %46 = getelementptr inbounds i8, i8* %24, i64 %35
  %47 = bitcast i8* %46 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 1
  %49 = bitcast <2 x i64> %48 to <16 x i8>
  %50 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %49
  %51 = bitcast <16 x i8> %50 to <2 x i64>
  %52 = select i1 %17, <2 x i64> %51, <2 x i64> %48
  %53 = select i1 %17, <2 x i64> %48, <2 x i64> %51
  %54 = getelementptr inbounds i8, i8* %29, i64 %35
  %55 = bitcast i8* %54 to <16 x i8>*
  %56 = load <16 x i8>, <16 x i8>* %55, align 1
  %57 = shufflevector <16 x i8> %56, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %58 = bitcast <2 x i64> %52 to <16 x i8>
  %59 = bitcast <2 x i64> %53 to <16 x i8>
  %60 = shufflevector <16 x i8> %58, <16 x i8> %59, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %61 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %57, <16 x i8> %60) #2
  %62 = lshr <8 x i16> %61, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %63 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %62, <8 x i16> zeroinitializer) #2
  %64 = shufflevector <16 x i8> %56, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %65 = shufflevector <16 x i8> %58, <16 x i8> %59, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %64, <16 x i8> %65) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %63, <8 x i16> %68) #2
  %70 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %69, <16 x i8> %42) #2
  %71 = bitcast <2 x i64> %70 to <4 x i32>
  %72 = add <4 x i32> %39, %71
  %73 = getelementptr inbounds i8, i8* %28, i64 %35
  %74 = bitcast i8* %73 to <16 x i8>*
  %75 = load <16 x i8>, <16 x i8>* %74, align 1
  %76 = shufflevector <16 x i8> %75, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %77 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %76, <16 x i8> %60) #2
  %78 = lshr <8 x i16> %77, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %79 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %78, <8 x i16> zeroinitializer) #2
  %80 = shufflevector <16 x i8> %75, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %81 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %80, <16 x i8> %65) #2
  %82 = lshr <8 x i16> %81, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %83 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %82, <8 x i16> zeroinitializer) #2
  %84 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> %83) #2
  %85 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %84, <16 x i8> %42) #2
  %86 = bitcast <2 x i64> %85 to <4 x i32>
  %87 = add <4 x i32> %38, %86
  %88 = getelementptr inbounds i8, i8* %27, i64 %35
  %89 = bitcast i8* %88 to <16 x i8>*
  %90 = load <16 x i8>, <16 x i8>* %89, align 1
  %91 = shufflevector <16 x i8> %90, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %92 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %91, <16 x i8> %60) #2
  %93 = lshr <8 x i16> %92, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %94 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %93, <8 x i16> zeroinitializer) #2
  %95 = shufflevector <16 x i8> %90, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %96 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %95, <16 x i8> %65) #2
  %97 = lshr <8 x i16> %96, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #2
  %99 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %94, <8 x i16> %98) #2
  %100 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %99, <16 x i8> %42) #2
  %101 = bitcast <2 x i64> %100 to <4 x i32>
  %102 = add <4 x i32> %37, %101
  %103 = getelementptr inbounds i8, i8* %26, i64 %35
  %104 = bitcast i8* %103 to <16 x i8>*
  %105 = load <16 x i8>, <16 x i8>* %104, align 1
  %106 = shufflevector <16 x i8> %105, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %107 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %106, <16 x i8> %60) #2
  %108 = lshr <8 x i16> %107, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %109 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %108, <8 x i16> zeroinitializer) #2
  %110 = shufflevector <16 x i8> %105, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %111 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %110, <16 x i8> %65) #2
  %112 = lshr <8 x i16> %111, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %113 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %112, <8 x i16> zeroinitializer) #2
  %114 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> %113) #2
  %115 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %114, <16 x i8> %42) #2
  %116 = bitcast <2 x i64> %115 to <4 x i32>
  %117 = add <4 x i32> %36, %116
  %118 = add nuw nsw i64 %35, 16
  %119 = icmp ult i64 %118, 64
  br i1 %119, label %34, label %120

120:                                              ; preds = %34
  %121 = getelementptr inbounds i8, i8* %22, i64 %18
  %122 = getelementptr inbounds i8, i8* %29, i64 %19
  %123 = getelementptr inbounds i8, i8* %28, i64 %19
  %124 = getelementptr inbounds i8, i8* %27, i64 %19
  %125 = getelementptr inbounds i8, i8* %26, i64 %19
  %126 = getelementptr inbounds i8, i8* %23, i64 64
  %127 = getelementptr inbounds i8, i8* %24, i64 %20
  %128 = add nuw nsw i32 %25, 1
  %129 = icmp eq i32 %128, 128
  br i1 %129, label %130, label %21

130:                                              ; preds = %120
  %131 = shufflevector <4 x i32> %72, <4 x i32> %87, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %132 = shufflevector <4 x i32> %72, <4 x i32> %87, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %133 = add <4 x i32> %132, %131
  %134 = bitcast <4 x i32> %133 to <2 x i64>
  %135 = shufflevector <4 x i32> %102, <4 x i32> %117, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %136 = shufflevector <4 x i32> %102, <4 x i32> %117, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %137 = add <4 x i32> %136, %135
  %138 = bitcast <4 x i32> %137 to <2 x i64>
  %139 = shufflevector <2 x i64> %134, <2 x i64> %138, <2 x i32> <i32 0, i32 2>
  %140 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %139, <2 x i64>* %140, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad64x64x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %120, %9
  %22 = phi i8* [ %0, %9 ], [ %121, %120 ]
  %23 = phi i8* [ %4, %9 ], [ %126, %120 ]
  %24 = phi i8* [ %5, %9 ], [ %127, %120 ]
  %25 = phi i32 [ 0, %9 ], [ %128, %120 ]
  %26 = phi i8* [ %11, %9 ], [ %125, %120 ]
  %27 = phi i8* [ %13, %9 ], [ %124, %120 ]
  %28 = phi i8* [ %15, %9 ], [ %123, %120 ]
  %29 = phi i8* [ %16, %9 ], [ %122, %120 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %117, %120 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %102, %120 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %87, %120 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %72, %120 ]
  br label %34

34:                                               ; preds = %34, %21
  %35 = phi i64 [ %118, %34 ], [ 0, %21 ]
  %36 = phi <4 x i32> [ %117, %34 ], [ %30, %21 ]
  %37 = phi <4 x i32> [ %102, %34 ], [ %31, %21 ]
  %38 = phi <4 x i32> [ %87, %34 ], [ %32, %21 ]
  %39 = phi <4 x i32> [ %72, %34 ], [ %33, %21 ]
  %40 = getelementptr inbounds i8, i8* %22, i64 %35
  %41 = bitcast i8* %40 to <16 x i8>*
  %42 = load <16 x i8>, <16 x i8>* %41, align 1
  %43 = getelementptr inbounds i8, i8* %23, i64 %35
  %44 = bitcast i8* %43 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 1
  %46 = getelementptr inbounds i8, i8* %24, i64 %35
  %47 = bitcast i8* %46 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 1
  %49 = bitcast <2 x i64> %48 to <16 x i8>
  %50 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %49
  %51 = bitcast <16 x i8> %50 to <2 x i64>
  %52 = select i1 %17, <2 x i64> %51, <2 x i64> %48
  %53 = select i1 %17, <2 x i64> %48, <2 x i64> %51
  %54 = getelementptr inbounds i8, i8* %29, i64 %35
  %55 = bitcast i8* %54 to <16 x i8>*
  %56 = load <16 x i8>, <16 x i8>* %55, align 1
  %57 = shufflevector <16 x i8> %56, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %58 = bitcast <2 x i64> %52 to <16 x i8>
  %59 = bitcast <2 x i64> %53 to <16 x i8>
  %60 = shufflevector <16 x i8> %58, <16 x i8> %59, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %61 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %57, <16 x i8> %60) #2
  %62 = lshr <8 x i16> %61, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %63 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %62, <8 x i16> zeroinitializer) #2
  %64 = shufflevector <16 x i8> %56, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %65 = shufflevector <16 x i8> %58, <16 x i8> %59, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %64, <16 x i8> %65) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %63, <8 x i16> %68) #2
  %70 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %69, <16 x i8> %42) #2
  %71 = bitcast <2 x i64> %70 to <4 x i32>
  %72 = add <4 x i32> %39, %71
  %73 = getelementptr inbounds i8, i8* %28, i64 %35
  %74 = bitcast i8* %73 to <16 x i8>*
  %75 = load <16 x i8>, <16 x i8>* %74, align 1
  %76 = shufflevector <16 x i8> %75, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %77 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %76, <16 x i8> %60) #2
  %78 = lshr <8 x i16> %77, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %79 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %78, <8 x i16> zeroinitializer) #2
  %80 = shufflevector <16 x i8> %75, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %81 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %80, <16 x i8> %65) #2
  %82 = lshr <8 x i16> %81, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %83 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %82, <8 x i16> zeroinitializer) #2
  %84 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> %83) #2
  %85 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %84, <16 x i8> %42) #2
  %86 = bitcast <2 x i64> %85 to <4 x i32>
  %87 = add <4 x i32> %38, %86
  %88 = getelementptr inbounds i8, i8* %27, i64 %35
  %89 = bitcast i8* %88 to <16 x i8>*
  %90 = load <16 x i8>, <16 x i8>* %89, align 1
  %91 = shufflevector <16 x i8> %90, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %92 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %91, <16 x i8> %60) #2
  %93 = lshr <8 x i16> %92, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %94 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %93, <8 x i16> zeroinitializer) #2
  %95 = shufflevector <16 x i8> %90, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %96 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %95, <16 x i8> %65) #2
  %97 = lshr <8 x i16> %96, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #2
  %99 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %94, <8 x i16> %98) #2
  %100 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %99, <16 x i8> %42) #2
  %101 = bitcast <2 x i64> %100 to <4 x i32>
  %102 = add <4 x i32> %37, %101
  %103 = getelementptr inbounds i8, i8* %26, i64 %35
  %104 = bitcast i8* %103 to <16 x i8>*
  %105 = load <16 x i8>, <16 x i8>* %104, align 1
  %106 = shufflevector <16 x i8> %105, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %107 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %106, <16 x i8> %60) #2
  %108 = lshr <8 x i16> %107, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %109 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %108, <8 x i16> zeroinitializer) #2
  %110 = shufflevector <16 x i8> %105, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %111 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %110, <16 x i8> %65) #2
  %112 = lshr <8 x i16> %111, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %113 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %112, <8 x i16> zeroinitializer) #2
  %114 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> %113) #2
  %115 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %114, <16 x i8> %42) #2
  %116 = bitcast <2 x i64> %115 to <4 x i32>
  %117 = add <4 x i32> %36, %116
  %118 = add nuw nsw i64 %35, 16
  %119 = icmp ult i64 %118, 64
  br i1 %119, label %34, label %120

120:                                              ; preds = %34
  %121 = getelementptr inbounds i8, i8* %22, i64 %18
  %122 = getelementptr inbounds i8, i8* %29, i64 %19
  %123 = getelementptr inbounds i8, i8* %28, i64 %19
  %124 = getelementptr inbounds i8, i8* %27, i64 %19
  %125 = getelementptr inbounds i8, i8* %26, i64 %19
  %126 = getelementptr inbounds i8, i8* %23, i64 64
  %127 = getelementptr inbounds i8, i8* %24, i64 %20
  %128 = add nuw nsw i32 %25, 1
  %129 = icmp eq i32 %128, 64
  br i1 %129, label %130, label %21

130:                                              ; preds = %120
  %131 = shufflevector <4 x i32> %72, <4 x i32> %87, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %132 = shufflevector <4 x i32> %72, <4 x i32> %87, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %133 = add <4 x i32> %132, %131
  %134 = bitcast <4 x i32> %133 to <2 x i64>
  %135 = shufflevector <4 x i32> %102, <4 x i32> %117, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %136 = shufflevector <4 x i32> %102, <4 x i32> %117, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %137 = add <4 x i32> %136, %135
  %138 = bitcast <4 x i32> %137 to <2 x i64>
  %139 = shufflevector <2 x i64> %134, <2 x i64> %138, <2 x i32> <i32 0, i32 2>
  %140 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %139, <2 x i64>* %140, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad64x32x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %120, %9
  %22 = phi i8* [ %0, %9 ], [ %121, %120 ]
  %23 = phi i8* [ %4, %9 ], [ %126, %120 ]
  %24 = phi i8* [ %5, %9 ], [ %127, %120 ]
  %25 = phi i32 [ 0, %9 ], [ %128, %120 ]
  %26 = phi i8* [ %11, %9 ], [ %125, %120 ]
  %27 = phi i8* [ %13, %9 ], [ %124, %120 ]
  %28 = phi i8* [ %15, %9 ], [ %123, %120 ]
  %29 = phi i8* [ %16, %9 ], [ %122, %120 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %117, %120 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %102, %120 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %87, %120 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %72, %120 ]
  br label %34

34:                                               ; preds = %34, %21
  %35 = phi i64 [ %118, %34 ], [ 0, %21 ]
  %36 = phi <4 x i32> [ %117, %34 ], [ %30, %21 ]
  %37 = phi <4 x i32> [ %102, %34 ], [ %31, %21 ]
  %38 = phi <4 x i32> [ %87, %34 ], [ %32, %21 ]
  %39 = phi <4 x i32> [ %72, %34 ], [ %33, %21 ]
  %40 = getelementptr inbounds i8, i8* %22, i64 %35
  %41 = bitcast i8* %40 to <16 x i8>*
  %42 = load <16 x i8>, <16 x i8>* %41, align 1
  %43 = getelementptr inbounds i8, i8* %23, i64 %35
  %44 = bitcast i8* %43 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 1
  %46 = getelementptr inbounds i8, i8* %24, i64 %35
  %47 = bitcast i8* %46 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 1
  %49 = bitcast <2 x i64> %48 to <16 x i8>
  %50 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %49
  %51 = bitcast <16 x i8> %50 to <2 x i64>
  %52 = select i1 %17, <2 x i64> %51, <2 x i64> %48
  %53 = select i1 %17, <2 x i64> %48, <2 x i64> %51
  %54 = getelementptr inbounds i8, i8* %29, i64 %35
  %55 = bitcast i8* %54 to <16 x i8>*
  %56 = load <16 x i8>, <16 x i8>* %55, align 1
  %57 = shufflevector <16 x i8> %56, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %58 = bitcast <2 x i64> %52 to <16 x i8>
  %59 = bitcast <2 x i64> %53 to <16 x i8>
  %60 = shufflevector <16 x i8> %58, <16 x i8> %59, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %61 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %57, <16 x i8> %60) #2
  %62 = lshr <8 x i16> %61, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %63 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %62, <8 x i16> zeroinitializer) #2
  %64 = shufflevector <16 x i8> %56, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %65 = shufflevector <16 x i8> %58, <16 x i8> %59, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %64, <16 x i8> %65) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %63, <8 x i16> %68) #2
  %70 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %69, <16 x i8> %42) #2
  %71 = bitcast <2 x i64> %70 to <4 x i32>
  %72 = add <4 x i32> %39, %71
  %73 = getelementptr inbounds i8, i8* %28, i64 %35
  %74 = bitcast i8* %73 to <16 x i8>*
  %75 = load <16 x i8>, <16 x i8>* %74, align 1
  %76 = shufflevector <16 x i8> %75, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %77 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %76, <16 x i8> %60) #2
  %78 = lshr <8 x i16> %77, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %79 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %78, <8 x i16> zeroinitializer) #2
  %80 = shufflevector <16 x i8> %75, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %81 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %80, <16 x i8> %65) #2
  %82 = lshr <8 x i16> %81, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %83 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %82, <8 x i16> zeroinitializer) #2
  %84 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> %83) #2
  %85 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %84, <16 x i8> %42) #2
  %86 = bitcast <2 x i64> %85 to <4 x i32>
  %87 = add <4 x i32> %38, %86
  %88 = getelementptr inbounds i8, i8* %27, i64 %35
  %89 = bitcast i8* %88 to <16 x i8>*
  %90 = load <16 x i8>, <16 x i8>* %89, align 1
  %91 = shufflevector <16 x i8> %90, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %92 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %91, <16 x i8> %60) #2
  %93 = lshr <8 x i16> %92, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %94 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %93, <8 x i16> zeroinitializer) #2
  %95 = shufflevector <16 x i8> %90, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %96 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %95, <16 x i8> %65) #2
  %97 = lshr <8 x i16> %96, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #2
  %99 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %94, <8 x i16> %98) #2
  %100 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %99, <16 x i8> %42) #2
  %101 = bitcast <2 x i64> %100 to <4 x i32>
  %102 = add <4 x i32> %37, %101
  %103 = getelementptr inbounds i8, i8* %26, i64 %35
  %104 = bitcast i8* %103 to <16 x i8>*
  %105 = load <16 x i8>, <16 x i8>* %104, align 1
  %106 = shufflevector <16 x i8> %105, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %107 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %106, <16 x i8> %60) #2
  %108 = lshr <8 x i16> %107, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %109 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %108, <8 x i16> zeroinitializer) #2
  %110 = shufflevector <16 x i8> %105, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %111 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %110, <16 x i8> %65) #2
  %112 = lshr <8 x i16> %111, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %113 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %112, <8 x i16> zeroinitializer) #2
  %114 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> %113) #2
  %115 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %114, <16 x i8> %42) #2
  %116 = bitcast <2 x i64> %115 to <4 x i32>
  %117 = add <4 x i32> %36, %116
  %118 = add nuw nsw i64 %35, 16
  %119 = icmp ult i64 %118, 64
  br i1 %119, label %34, label %120

120:                                              ; preds = %34
  %121 = getelementptr inbounds i8, i8* %22, i64 %18
  %122 = getelementptr inbounds i8, i8* %29, i64 %19
  %123 = getelementptr inbounds i8, i8* %28, i64 %19
  %124 = getelementptr inbounds i8, i8* %27, i64 %19
  %125 = getelementptr inbounds i8, i8* %26, i64 %19
  %126 = getelementptr inbounds i8, i8* %23, i64 64
  %127 = getelementptr inbounds i8, i8* %24, i64 %20
  %128 = add nuw nsw i32 %25, 1
  %129 = icmp eq i32 %128, 32
  br i1 %129, label %130, label %21

130:                                              ; preds = %120
  %131 = shufflevector <4 x i32> %72, <4 x i32> %87, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %132 = shufflevector <4 x i32> %72, <4 x i32> %87, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %133 = add <4 x i32> %132, %131
  %134 = bitcast <4 x i32> %133 to <2 x i64>
  %135 = shufflevector <4 x i32> %102, <4 x i32> %117, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %136 = shufflevector <4 x i32> %102, <4 x i32> %117, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %137 = add <4 x i32> %136, %135
  %138 = bitcast <4 x i32> %137 to <2 x i64>
  %139 = shufflevector <2 x i64> %134, <2 x i64> %138, <2 x i32> <i32 0, i32 2>
  %140 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %139, <2 x i64>* %140, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad32x64x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %21, %9
  %22 = phi i8* [ %0, %9 ], [ %183, %21 ]
  %23 = phi i8* [ %4, %9 ], [ %188, %21 ]
  %24 = phi i8* [ %5, %9 ], [ %189, %21 ]
  %25 = phi i32 [ 0, %9 ], [ %190, %21 ]
  %26 = phi i8* [ %11, %9 ], [ %187, %21 ]
  %27 = phi i8* [ %13, %9 ], [ %186, %21 ]
  %28 = phi i8* [ %15, %9 ], [ %185, %21 ]
  %29 = phi i8* [ %16, %9 ], [ %184, %21 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %182, %21 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %167, %21 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %152, %21 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %137, %21 ]
  %34 = bitcast i8* %22 to <16 x i8>*
  %35 = load <16 x i8>, <16 x i8>* %34, align 1
  %36 = bitcast i8* %23 to <16 x i8>*
  %37 = load <16 x i8>, <16 x i8>* %36, align 1
  %38 = bitcast i8* %24 to <2 x i64>*
  %39 = load <2 x i64>, <2 x i64>* %38, align 1
  %40 = bitcast <2 x i64> %39 to <16 x i8>
  %41 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %40
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = select i1 %17, <2 x i64> %42, <2 x i64> %39
  %44 = select i1 %17, <2 x i64> %39, <2 x i64> %42
  %45 = bitcast i8* %29 to <16 x i8>*
  %46 = load <16 x i8>, <16 x i8>* %45, align 1
  %47 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %48 = bitcast <2 x i64> %43 to <16 x i8>
  %49 = bitcast <2 x i64> %44 to <16 x i8>
  %50 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %47, <16 x i8> %50) #2
  %52 = lshr <8 x i16> %51, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #2
  %54 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %55 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %56 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %54, <16 x i8> %55) #2
  %57 = lshr <8 x i16> %56, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %58 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %57, <8 x i16> zeroinitializer) #2
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %58) #2
  %60 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %59, <16 x i8> %35) #2
  %61 = bitcast <2 x i64> %60 to <4 x i32>
  %62 = add <4 x i32> %33, %61
  %63 = bitcast i8* %28 to <16 x i8>*
  %64 = load <16 x i8>, <16 x i8>* %63, align 1
  %65 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> %50) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %70 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %55) #2
  %71 = lshr <8 x i16> %70, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %72 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %71, <8 x i16> zeroinitializer) #2
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %68, <8 x i16> %72) #2
  %74 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %73, <16 x i8> %35) #2
  %75 = bitcast <2 x i64> %74 to <4 x i32>
  %76 = add <4 x i32> %32, %75
  %77 = bitcast i8* %27 to <16 x i8>*
  %78 = load <16 x i8>, <16 x i8>* %77, align 1
  %79 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %80 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %79, <16 x i8> %50) #2
  %81 = lshr <8 x i16> %80, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %82 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %81, <8 x i16> zeroinitializer) #2
  %83 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %84 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %83, <16 x i8> %55) #2
  %85 = lshr <8 x i16> %84, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %86 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %85, <8 x i16> zeroinitializer) #2
  %87 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %82, <8 x i16> %86) #2
  %88 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %87, <16 x i8> %35) #2
  %89 = bitcast <2 x i64> %88 to <4 x i32>
  %90 = add <4 x i32> %31, %89
  %91 = bitcast i8* %26 to <16 x i8>*
  %92 = load <16 x i8>, <16 x i8>* %91, align 1
  %93 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %94 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %93, <16 x i8> %50) #2
  %95 = lshr <8 x i16> %94, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %96 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %95, <8 x i16> zeroinitializer) #2
  %97 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %98 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %97, <16 x i8> %55) #2
  %99 = lshr <8 x i16> %98, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #2
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %96, <8 x i16> %100) #2
  %102 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %101, <16 x i8> %35) #2
  %103 = bitcast <2 x i64> %102 to <4 x i32>
  %104 = add <4 x i32> %30, %103
  %105 = getelementptr inbounds i8, i8* %22, i64 16
  %106 = bitcast i8* %105 to <16 x i8>*
  %107 = load <16 x i8>, <16 x i8>* %106, align 1
  %108 = getelementptr inbounds i8, i8* %23, i64 16
  %109 = bitcast i8* %108 to <16 x i8>*
  %110 = load <16 x i8>, <16 x i8>* %109, align 1
  %111 = getelementptr inbounds i8, i8* %24, i64 16
  %112 = bitcast i8* %111 to <2 x i64>*
  %113 = load <2 x i64>, <2 x i64>* %112, align 1
  %114 = bitcast <2 x i64> %113 to <16 x i8>
  %115 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %114
  %116 = bitcast <16 x i8> %115 to <2 x i64>
  %117 = select i1 %17, <2 x i64> %116, <2 x i64> %113
  %118 = select i1 %17, <2 x i64> %113, <2 x i64> %116
  %119 = getelementptr inbounds i8, i8* %29, i64 16
  %120 = bitcast i8* %119 to <16 x i8>*
  %121 = load <16 x i8>, <16 x i8>* %120, align 1
  %122 = shufflevector <16 x i8> %121, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %123 = bitcast <2 x i64> %117 to <16 x i8>
  %124 = bitcast <2 x i64> %118 to <16 x i8>
  %125 = shufflevector <16 x i8> %123, <16 x i8> %124, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %126 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %122, <16 x i8> %125) #2
  %127 = lshr <8 x i16> %126, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %128 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %127, <8 x i16> zeroinitializer) #2
  %129 = shufflevector <16 x i8> %121, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %130 = shufflevector <16 x i8> %123, <16 x i8> %124, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %131 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %129, <16 x i8> %130) #2
  %132 = lshr <8 x i16> %131, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #2
  %134 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %128, <8 x i16> %133) #2
  %135 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %134, <16 x i8> %107) #2
  %136 = bitcast <2 x i64> %135 to <4 x i32>
  %137 = add <4 x i32> %62, %136
  %138 = getelementptr inbounds i8, i8* %28, i64 16
  %139 = bitcast i8* %138 to <16 x i8>*
  %140 = load <16 x i8>, <16 x i8>* %139, align 1
  %141 = shufflevector <16 x i8> %140, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %142 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %141, <16 x i8> %125) #2
  %143 = lshr <8 x i16> %142, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %144 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %143, <8 x i16> zeroinitializer) #2
  %145 = shufflevector <16 x i8> %140, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %146 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %145, <16 x i8> %130) #2
  %147 = lshr <8 x i16> %146, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %148 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %147, <8 x i16> zeroinitializer) #2
  %149 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %144, <8 x i16> %148) #2
  %150 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %149, <16 x i8> %107) #2
  %151 = bitcast <2 x i64> %150 to <4 x i32>
  %152 = add <4 x i32> %76, %151
  %153 = getelementptr inbounds i8, i8* %27, i64 16
  %154 = bitcast i8* %153 to <16 x i8>*
  %155 = load <16 x i8>, <16 x i8>* %154, align 1
  %156 = shufflevector <16 x i8> %155, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %157 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %156, <16 x i8> %125) #2
  %158 = lshr <8 x i16> %157, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %159 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %158, <8 x i16> zeroinitializer) #2
  %160 = shufflevector <16 x i8> %155, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %161 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %160, <16 x i8> %130) #2
  %162 = lshr <8 x i16> %161, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %163 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %162, <8 x i16> zeroinitializer) #2
  %164 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %159, <8 x i16> %163) #2
  %165 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %164, <16 x i8> %107) #2
  %166 = bitcast <2 x i64> %165 to <4 x i32>
  %167 = add <4 x i32> %90, %166
  %168 = getelementptr inbounds i8, i8* %26, i64 16
  %169 = bitcast i8* %168 to <16 x i8>*
  %170 = load <16 x i8>, <16 x i8>* %169, align 1
  %171 = shufflevector <16 x i8> %170, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %172 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %171, <16 x i8> %125) #2
  %173 = lshr <8 x i16> %172, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %174 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %173, <8 x i16> zeroinitializer) #2
  %175 = shufflevector <16 x i8> %170, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %176 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %175, <16 x i8> %130) #2
  %177 = lshr <8 x i16> %176, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %178 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %177, <8 x i16> zeroinitializer) #2
  %179 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %174, <8 x i16> %178) #2
  %180 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %179, <16 x i8> %107) #2
  %181 = bitcast <2 x i64> %180 to <4 x i32>
  %182 = add <4 x i32> %104, %181
  %183 = getelementptr inbounds i8, i8* %22, i64 %18
  %184 = getelementptr inbounds i8, i8* %29, i64 %19
  %185 = getelementptr inbounds i8, i8* %28, i64 %19
  %186 = getelementptr inbounds i8, i8* %27, i64 %19
  %187 = getelementptr inbounds i8, i8* %26, i64 %19
  %188 = getelementptr inbounds i8, i8* %23, i64 32
  %189 = getelementptr inbounds i8, i8* %24, i64 %20
  %190 = add nuw nsw i32 %25, 1
  %191 = icmp eq i32 %190, 64
  br i1 %191, label %192, label %21

192:                                              ; preds = %21
  %193 = shufflevector <4 x i32> %137, <4 x i32> %152, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %194 = shufflevector <4 x i32> %137, <4 x i32> %152, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %195 = add <4 x i32> %194, %193
  %196 = bitcast <4 x i32> %195 to <2 x i64>
  %197 = shufflevector <4 x i32> %167, <4 x i32> %182, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %198 = shufflevector <4 x i32> %167, <4 x i32> %182, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %199 = add <4 x i32> %198, %197
  %200 = bitcast <4 x i32> %199 to <2 x i64>
  %201 = shufflevector <2 x i64> %196, <2 x i64> %200, <2 x i32> <i32 0, i32 2>
  %202 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %201, <2 x i64>* %202, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad32x32x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %21, %9
  %22 = phi i8* [ %0, %9 ], [ %183, %21 ]
  %23 = phi i8* [ %4, %9 ], [ %188, %21 ]
  %24 = phi i8* [ %5, %9 ], [ %189, %21 ]
  %25 = phi i32 [ 0, %9 ], [ %190, %21 ]
  %26 = phi i8* [ %11, %9 ], [ %187, %21 ]
  %27 = phi i8* [ %13, %9 ], [ %186, %21 ]
  %28 = phi i8* [ %15, %9 ], [ %185, %21 ]
  %29 = phi i8* [ %16, %9 ], [ %184, %21 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %182, %21 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %167, %21 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %152, %21 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %137, %21 ]
  %34 = bitcast i8* %22 to <16 x i8>*
  %35 = load <16 x i8>, <16 x i8>* %34, align 1
  %36 = bitcast i8* %23 to <16 x i8>*
  %37 = load <16 x i8>, <16 x i8>* %36, align 1
  %38 = bitcast i8* %24 to <2 x i64>*
  %39 = load <2 x i64>, <2 x i64>* %38, align 1
  %40 = bitcast <2 x i64> %39 to <16 x i8>
  %41 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %40
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = select i1 %17, <2 x i64> %42, <2 x i64> %39
  %44 = select i1 %17, <2 x i64> %39, <2 x i64> %42
  %45 = bitcast i8* %29 to <16 x i8>*
  %46 = load <16 x i8>, <16 x i8>* %45, align 1
  %47 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %48 = bitcast <2 x i64> %43 to <16 x i8>
  %49 = bitcast <2 x i64> %44 to <16 x i8>
  %50 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %47, <16 x i8> %50) #2
  %52 = lshr <8 x i16> %51, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #2
  %54 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %55 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %56 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %54, <16 x i8> %55) #2
  %57 = lshr <8 x i16> %56, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %58 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %57, <8 x i16> zeroinitializer) #2
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %58) #2
  %60 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %59, <16 x i8> %35) #2
  %61 = bitcast <2 x i64> %60 to <4 x i32>
  %62 = add <4 x i32> %33, %61
  %63 = bitcast i8* %28 to <16 x i8>*
  %64 = load <16 x i8>, <16 x i8>* %63, align 1
  %65 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> %50) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %70 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %55) #2
  %71 = lshr <8 x i16> %70, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %72 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %71, <8 x i16> zeroinitializer) #2
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %68, <8 x i16> %72) #2
  %74 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %73, <16 x i8> %35) #2
  %75 = bitcast <2 x i64> %74 to <4 x i32>
  %76 = add <4 x i32> %32, %75
  %77 = bitcast i8* %27 to <16 x i8>*
  %78 = load <16 x i8>, <16 x i8>* %77, align 1
  %79 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %80 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %79, <16 x i8> %50) #2
  %81 = lshr <8 x i16> %80, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %82 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %81, <8 x i16> zeroinitializer) #2
  %83 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %84 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %83, <16 x i8> %55) #2
  %85 = lshr <8 x i16> %84, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %86 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %85, <8 x i16> zeroinitializer) #2
  %87 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %82, <8 x i16> %86) #2
  %88 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %87, <16 x i8> %35) #2
  %89 = bitcast <2 x i64> %88 to <4 x i32>
  %90 = add <4 x i32> %31, %89
  %91 = bitcast i8* %26 to <16 x i8>*
  %92 = load <16 x i8>, <16 x i8>* %91, align 1
  %93 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %94 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %93, <16 x i8> %50) #2
  %95 = lshr <8 x i16> %94, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %96 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %95, <8 x i16> zeroinitializer) #2
  %97 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %98 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %97, <16 x i8> %55) #2
  %99 = lshr <8 x i16> %98, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #2
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %96, <8 x i16> %100) #2
  %102 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %101, <16 x i8> %35) #2
  %103 = bitcast <2 x i64> %102 to <4 x i32>
  %104 = add <4 x i32> %30, %103
  %105 = getelementptr inbounds i8, i8* %22, i64 16
  %106 = bitcast i8* %105 to <16 x i8>*
  %107 = load <16 x i8>, <16 x i8>* %106, align 1
  %108 = getelementptr inbounds i8, i8* %23, i64 16
  %109 = bitcast i8* %108 to <16 x i8>*
  %110 = load <16 x i8>, <16 x i8>* %109, align 1
  %111 = getelementptr inbounds i8, i8* %24, i64 16
  %112 = bitcast i8* %111 to <2 x i64>*
  %113 = load <2 x i64>, <2 x i64>* %112, align 1
  %114 = bitcast <2 x i64> %113 to <16 x i8>
  %115 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %114
  %116 = bitcast <16 x i8> %115 to <2 x i64>
  %117 = select i1 %17, <2 x i64> %116, <2 x i64> %113
  %118 = select i1 %17, <2 x i64> %113, <2 x i64> %116
  %119 = getelementptr inbounds i8, i8* %29, i64 16
  %120 = bitcast i8* %119 to <16 x i8>*
  %121 = load <16 x i8>, <16 x i8>* %120, align 1
  %122 = shufflevector <16 x i8> %121, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %123 = bitcast <2 x i64> %117 to <16 x i8>
  %124 = bitcast <2 x i64> %118 to <16 x i8>
  %125 = shufflevector <16 x i8> %123, <16 x i8> %124, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %126 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %122, <16 x i8> %125) #2
  %127 = lshr <8 x i16> %126, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %128 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %127, <8 x i16> zeroinitializer) #2
  %129 = shufflevector <16 x i8> %121, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %130 = shufflevector <16 x i8> %123, <16 x i8> %124, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %131 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %129, <16 x i8> %130) #2
  %132 = lshr <8 x i16> %131, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #2
  %134 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %128, <8 x i16> %133) #2
  %135 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %134, <16 x i8> %107) #2
  %136 = bitcast <2 x i64> %135 to <4 x i32>
  %137 = add <4 x i32> %62, %136
  %138 = getelementptr inbounds i8, i8* %28, i64 16
  %139 = bitcast i8* %138 to <16 x i8>*
  %140 = load <16 x i8>, <16 x i8>* %139, align 1
  %141 = shufflevector <16 x i8> %140, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %142 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %141, <16 x i8> %125) #2
  %143 = lshr <8 x i16> %142, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %144 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %143, <8 x i16> zeroinitializer) #2
  %145 = shufflevector <16 x i8> %140, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %146 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %145, <16 x i8> %130) #2
  %147 = lshr <8 x i16> %146, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %148 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %147, <8 x i16> zeroinitializer) #2
  %149 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %144, <8 x i16> %148) #2
  %150 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %149, <16 x i8> %107) #2
  %151 = bitcast <2 x i64> %150 to <4 x i32>
  %152 = add <4 x i32> %76, %151
  %153 = getelementptr inbounds i8, i8* %27, i64 16
  %154 = bitcast i8* %153 to <16 x i8>*
  %155 = load <16 x i8>, <16 x i8>* %154, align 1
  %156 = shufflevector <16 x i8> %155, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %157 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %156, <16 x i8> %125) #2
  %158 = lshr <8 x i16> %157, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %159 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %158, <8 x i16> zeroinitializer) #2
  %160 = shufflevector <16 x i8> %155, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %161 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %160, <16 x i8> %130) #2
  %162 = lshr <8 x i16> %161, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %163 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %162, <8 x i16> zeroinitializer) #2
  %164 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %159, <8 x i16> %163) #2
  %165 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %164, <16 x i8> %107) #2
  %166 = bitcast <2 x i64> %165 to <4 x i32>
  %167 = add <4 x i32> %90, %166
  %168 = getelementptr inbounds i8, i8* %26, i64 16
  %169 = bitcast i8* %168 to <16 x i8>*
  %170 = load <16 x i8>, <16 x i8>* %169, align 1
  %171 = shufflevector <16 x i8> %170, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %172 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %171, <16 x i8> %125) #2
  %173 = lshr <8 x i16> %172, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %174 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %173, <8 x i16> zeroinitializer) #2
  %175 = shufflevector <16 x i8> %170, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %176 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %175, <16 x i8> %130) #2
  %177 = lshr <8 x i16> %176, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %178 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %177, <8 x i16> zeroinitializer) #2
  %179 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %174, <8 x i16> %178) #2
  %180 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %179, <16 x i8> %107) #2
  %181 = bitcast <2 x i64> %180 to <4 x i32>
  %182 = add <4 x i32> %104, %181
  %183 = getelementptr inbounds i8, i8* %22, i64 %18
  %184 = getelementptr inbounds i8, i8* %29, i64 %19
  %185 = getelementptr inbounds i8, i8* %28, i64 %19
  %186 = getelementptr inbounds i8, i8* %27, i64 %19
  %187 = getelementptr inbounds i8, i8* %26, i64 %19
  %188 = getelementptr inbounds i8, i8* %23, i64 32
  %189 = getelementptr inbounds i8, i8* %24, i64 %20
  %190 = add nuw nsw i32 %25, 1
  %191 = icmp eq i32 %190, 32
  br i1 %191, label %192, label %21

192:                                              ; preds = %21
  %193 = shufflevector <4 x i32> %137, <4 x i32> %152, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %194 = shufflevector <4 x i32> %137, <4 x i32> %152, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %195 = add <4 x i32> %194, %193
  %196 = bitcast <4 x i32> %195 to <2 x i64>
  %197 = shufflevector <4 x i32> %167, <4 x i32> %182, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %198 = shufflevector <4 x i32> %167, <4 x i32> %182, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %199 = add <4 x i32> %198, %197
  %200 = bitcast <4 x i32> %199 to <2 x i64>
  %201 = shufflevector <2 x i64> %196, <2 x i64> %200, <2 x i32> <i32 0, i32 2>
  %202 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %201, <2 x i64>* %202, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad32x16x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %21, %9
  %22 = phi i8* [ %0, %9 ], [ %183, %21 ]
  %23 = phi i8* [ %4, %9 ], [ %188, %21 ]
  %24 = phi i8* [ %5, %9 ], [ %189, %21 ]
  %25 = phi i32 [ 0, %9 ], [ %190, %21 ]
  %26 = phi i8* [ %11, %9 ], [ %187, %21 ]
  %27 = phi i8* [ %13, %9 ], [ %186, %21 ]
  %28 = phi i8* [ %15, %9 ], [ %185, %21 ]
  %29 = phi i8* [ %16, %9 ], [ %184, %21 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %182, %21 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %167, %21 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %152, %21 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %137, %21 ]
  %34 = bitcast i8* %22 to <16 x i8>*
  %35 = load <16 x i8>, <16 x i8>* %34, align 1
  %36 = bitcast i8* %23 to <16 x i8>*
  %37 = load <16 x i8>, <16 x i8>* %36, align 1
  %38 = bitcast i8* %24 to <2 x i64>*
  %39 = load <2 x i64>, <2 x i64>* %38, align 1
  %40 = bitcast <2 x i64> %39 to <16 x i8>
  %41 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %40
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = select i1 %17, <2 x i64> %42, <2 x i64> %39
  %44 = select i1 %17, <2 x i64> %39, <2 x i64> %42
  %45 = bitcast i8* %29 to <16 x i8>*
  %46 = load <16 x i8>, <16 x i8>* %45, align 1
  %47 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %48 = bitcast <2 x i64> %43 to <16 x i8>
  %49 = bitcast <2 x i64> %44 to <16 x i8>
  %50 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %47, <16 x i8> %50) #2
  %52 = lshr <8 x i16> %51, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #2
  %54 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %55 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %56 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %54, <16 x i8> %55) #2
  %57 = lshr <8 x i16> %56, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %58 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %57, <8 x i16> zeroinitializer) #2
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %58) #2
  %60 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %59, <16 x i8> %35) #2
  %61 = bitcast <2 x i64> %60 to <4 x i32>
  %62 = add <4 x i32> %33, %61
  %63 = bitcast i8* %28 to <16 x i8>*
  %64 = load <16 x i8>, <16 x i8>* %63, align 1
  %65 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> %50) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %70 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %55) #2
  %71 = lshr <8 x i16> %70, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %72 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %71, <8 x i16> zeroinitializer) #2
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %68, <8 x i16> %72) #2
  %74 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %73, <16 x i8> %35) #2
  %75 = bitcast <2 x i64> %74 to <4 x i32>
  %76 = add <4 x i32> %32, %75
  %77 = bitcast i8* %27 to <16 x i8>*
  %78 = load <16 x i8>, <16 x i8>* %77, align 1
  %79 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %80 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %79, <16 x i8> %50) #2
  %81 = lshr <8 x i16> %80, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %82 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %81, <8 x i16> zeroinitializer) #2
  %83 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %84 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %83, <16 x i8> %55) #2
  %85 = lshr <8 x i16> %84, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %86 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %85, <8 x i16> zeroinitializer) #2
  %87 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %82, <8 x i16> %86) #2
  %88 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %87, <16 x i8> %35) #2
  %89 = bitcast <2 x i64> %88 to <4 x i32>
  %90 = add <4 x i32> %31, %89
  %91 = bitcast i8* %26 to <16 x i8>*
  %92 = load <16 x i8>, <16 x i8>* %91, align 1
  %93 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %94 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %93, <16 x i8> %50) #2
  %95 = lshr <8 x i16> %94, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %96 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %95, <8 x i16> zeroinitializer) #2
  %97 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %98 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %97, <16 x i8> %55) #2
  %99 = lshr <8 x i16> %98, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #2
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %96, <8 x i16> %100) #2
  %102 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %101, <16 x i8> %35) #2
  %103 = bitcast <2 x i64> %102 to <4 x i32>
  %104 = add <4 x i32> %30, %103
  %105 = getelementptr inbounds i8, i8* %22, i64 16
  %106 = bitcast i8* %105 to <16 x i8>*
  %107 = load <16 x i8>, <16 x i8>* %106, align 1
  %108 = getelementptr inbounds i8, i8* %23, i64 16
  %109 = bitcast i8* %108 to <16 x i8>*
  %110 = load <16 x i8>, <16 x i8>* %109, align 1
  %111 = getelementptr inbounds i8, i8* %24, i64 16
  %112 = bitcast i8* %111 to <2 x i64>*
  %113 = load <2 x i64>, <2 x i64>* %112, align 1
  %114 = bitcast <2 x i64> %113 to <16 x i8>
  %115 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %114
  %116 = bitcast <16 x i8> %115 to <2 x i64>
  %117 = select i1 %17, <2 x i64> %116, <2 x i64> %113
  %118 = select i1 %17, <2 x i64> %113, <2 x i64> %116
  %119 = getelementptr inbounds i8, i8* %29, i64 16
  %120 = bitcast i8* %119 to <16 x i8>*
  %121 = load <16 x i8>, <16 x i8>* %120, align 1
  %122 = shufflevector <16 x i8> %121, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %123 = bitcast <2 x i64> %117 to <16 x i8>
  %124 = bitcast <2 x i64> %118 to <16 x i8>
  %125 = shufflevector <16 x i8> %123, <16 x i8> %124, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %126 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %122, <16 x i8> %125) #2
  %127 = lshr <8 x i16> %126, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %128 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %127, <8 x i16> zeroinitializer) #2
  %129 = shufflevector <16 x i8> %121, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %130 = shufflevector <16 x i8> %123, <16 x i8> %124, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %131 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %129, <16 x i8> %130) #2
  %132 = lshr <8 x i16> %131, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #2
  %134 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %128, <8 x i16> %133) #2
  %135 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %134, <16 x i8> %107) #2
  %136 = bitcast <2 x i64> %135 to <4 x i32>
  %137 = add <4 x i32> %62, %136
  %138 = getelementptr inbounds i8, i8* %28, i64 16
  %139 = bitcast i8* %138 to <16 x i8>*
  %140 = load <16 x i8>, <16 x i8>* %139, align 1
  %141 = shufflevector <16 x i8> %140, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %142 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %141, <16 x i8> %125) #2
  %143 = lshr <8 x i16> %142, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %144 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %143, <8 x i16> zeroinitializer) #2
  %145 = shufflevector <16 x i8> %140, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %146 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %145, <16 x i8> %130) #2
  %147 = lshr <8 x i16> %146, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %148 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %147, <8 x i16> zeroinitializer) #2
  %149 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %144, <8 x i16> %148) #2
  %150 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %149, <16 x i8> %107) #2
  %151 = bitcast <2 x i64> %150 to <4 x i32>
  %152 = add <4 x i32> %76, %151
  %153 = getelementptr inbounds i8, i8* %27, i64 16
  %154 = bitcast i8* %153 to <16 x i8>*
  %155 = load <16 x i8>, <16 x i8>* %154, align 1
  %156 = shufflevector <16 x i8> %155, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %157 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %156, <16 x i8> %125) #2
  %158 = lshr <8 x i16> %157, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %159 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %158, <8 x i16> zeroinitializer) #2
  %160 = shufflevector <16 x i8> %155, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %161 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %160, <16 x i8> %130) #2
  %162 = lshr <8 x i16> %161, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %163 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %162, <8 x i16> zeroinitializer) #2
  %164 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %159, <8 x i16> %163) #2
  %165 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %164, <16 x i8> %107) #2
  %166 = bitcast <2 x i64> %165 to <4 x i32>
  %167 = add <4 x i32> %90, %166
  %168 = getelementptr inbounds i8, i8* %26, i64 16
  %169 = bitcast i8* %168 to <16 x i8>*
  %170 = load <16 x i8>, <16 x i8>* %169, align 1
  %171 = shufflevector <16 x i8> %170, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %172 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %171, <16 x i8> %125) #2
  %173 = lshr <8 x i16> %172, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %174 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %173, <8 x i16> zeroinitializer) #2
  %175 = shufflevector <16 x i8> %170, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %176 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %175, <16 x i8> %130) #2
  %177 = lshr <8 x i16> %176, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %178 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %177, <8 x i16> zeroinitializer) #2
  %179 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %174, <8 x i16> %178) #2
  %180 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %179, <16 x i8> %107) #2
  %181 = bitcast <2 x i64> %180 to <4 x i32>
  %182 = add <4 x i32> %104, %181
  %183 = getelementptr inbounds i8, i8* %22, i64 %18
  %184 = getelementptr inbounds i8, i8* %29, i64 %19
  %185 = getelementptr inbounds i8, i8* %28, i64 %19
  %186 = getelementptr inbounds i8, i8* %27, i64 %19
  %187 = getelementptr inbounds i8, i8* %26, i64 %19
  %188 = getelementptr inbounds i8, i8* %23, i64 32
  %189 = getelementptr inbounds i8, i8* %24, i64 %20
  %190 = add nuw nsw i32 %25, 1
  %191 = icmp eq i32 %190, 16
  br i1 %191, label %192, label %21

192:                                              ; preds = %21
  %193 = shufflevector <4 x i32> %137, <4 x i32> %152, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %194 = shufflevector <4 x i32> %137, <4 x i32> %152, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %195 = add <4 x i32> %194, %193
  %196 = bitcast <4 x i32> %195 to <2 x i64>
  %197 = shufflevector <4 x i32> %167, <4 x i32> %182, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %198 = shufflevector <4 x i32> %167, <4 x i32> %182, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %199 = add <4 x i32> %198, %197
  %200 = bitcast <4 x i32> %199 to <2 x i64>
  %201 = shufflevector <2 x i64> %196, <2 x i64> %200, <2 x i32> <i32 0, i32 2>
  %202 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %201, <2 x i64>* %202, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad16x32x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %21, %9
  %22 = phi i8* [ %0, %9 ], [ %105, %21 ]
  %23 = phi i8* [ %4, %9 ], [ %110, %21 ]
  %24 = phi i8* [ %5, %9 ], [ %111, %21 ]
  %25 = phi i32 [ 0, %9 ], [ %112, %21 ]
  %26 = phi i8* [ %11, %9 ], [ %109, %21 ]
  %27 = phi i8* [ %13, %9 ], [ %108, %21 ]
  %28 = phi i8* [ %15, %9 ], [ %107, %21 ]
  %29 = phi i8* [ %16, %9 ], [ %106, %21 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %104, %21 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %90, %21 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %76, %21 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %62, %21 ]
  %34 = bitcast i8* %22 to <16 x i8>*
  %35 = load <16 x i8>, <16 x i8>* %34, align 1
  %36 = bitcast i8* %23 to <16 x i8>*
  %37 = load <16 x i8>, <16 x i8>* %36, align 1
  %38 = bitcast i8* %24 to <2 x i64>*
  %39 = load <2 x i64>, <2 x i64>* %38, align 1
  %40 = bitcast <2 x i64> %39 to <16 x i8>
  %41 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %40
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = select i1 %17, <2 x i64> %42, <2 x i64> %39
  %44 = select i1 %17, <2 x i64> %39, <2 x i64> %42
  %45 = bitcast i8* %29 to <16 x i8>*
  %46 = load <16 x i8>, <16 x i8>* %45, align 1
  %47 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %48 = bitcast <2 x i64> %43 to <16 x i8>
  %49 = bitcast <2 x i64> %44 to <16 x i8>
  %50 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %47, <16 x i8> %50) #2
  %52 = lshr <8 x i16> %51, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #2
  %54 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %55 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %56 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %54, <16 x i8> %55) #2
  %57 = lshr <8 x i16> %56, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %58 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %57, <8 x i16> zeroinitializer) #2
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %58) #2
  %60 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %59, <16 x i8> %35) #2
  %61 = bitcast <2 x i64> %60 to <4 x i32>
  %62 = add <4 x i32> %33, %61
  %63 = bitcast i8* %28 to <16 x i8>*
  %64 = load <16 x i8>, <16 x i8>* %63, align 1
  %65 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> %50) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %70 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %55) #2
  %71 = lshr <8 x i16> %70, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %72 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %71, <8 x i16> zeroinitializer) #2
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %68, <8 x i16> %72) #2
  %74 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %73, <16 x i8> %35) #2
  %75 = bitcast <2 x i64> %74 to <4 x i32>
  %76 = add <4 x i32> %32, %75
  %77 = bitcast i8* %27 to <16 x i8>*
  %78 = load <16 x i8>, <16 x i8>* %77, align 1
  %79 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %80 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %79, <16 x i8> %50) #2
  %81 = lshr <8 x i16> %80, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %82 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %81, <8 x i16> zeroinitializer) #2
  %83 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %84 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %83, <16 x i8> %55) #2
  %85 = lshr <8 x i16> %84, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %86 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %85, <8 x i16> zeroinitializer) #2
  %87 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %82, <8 x i16> %86) #2
  %88 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %87, <16 x i8> %35) #2
  %89 = bitcast <2 x i64> %88 to <4 x i32>
  %90 = add <4 x i32> %31, %89
  %91 = bitcast i8* %26 to <16 x i8>*
  %92 = load <16 x i8>, <16 x i8>* %91, align 1
  %93 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %94 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %93, <16 x i8> %50) #2
  %95 = lshr <8 x i16> %94, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %96 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %95, <8 x i16> zeroinitializer) #2
  %97 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %98 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %97, <16 x i8> %55) #2
  %99 = lshr <8 x i16> %98, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #2
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %96, <8 x i16> %100) #2
  %102 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %101, <16 x i8> %35) #2
  %103 = bitcast <2 x i64> %102 to <4 x i32>
  %104 = add <4 x i32> %30, %103
  %105 = getelementptr inbounds i8, i8* %22, i64 %18
  %106 = getelementptr inbounds i8, i8* %29, i64 %19
  %107 = getelementptr inbounds i8, i8* %28, i64 %19
  %108 = getelementptr inbounds i8, i8* %27, i64 %19
  %109 = getelementptr inbounds i8, i8* %26, i64 %19
  %110 = getelementptr inbounds i8, i8* %23, i64 16
  %111 = getelementptr inbounds i8, i8* %24, i64 %20
  %112 = add nuw nsw i32 %25, 1
  %113 = icmp eq i32 %112, 32
  br i1 %113, label %114, label %21

114:                                              ; preds = %21
  %115 = shufflevector <4 x i32> %62, <4 x i32> %76, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %116 = shufflevector <4 x i32> %62, <4 x i32> %76, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %117 = add <4 x i32> %116, %115
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = shufflevector <4 x i32> %90, <4 x i32> %104, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %120 = shufflevector <4 x i32> %90, <4 x i32> %104, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %121 = add <4 x i32> %120, %119
  %122 = bitcast <4 x i32> %121 to <2 x i64>
  %123 = shufflevector <2 x i64> %118, <2 x i64> %122, <2 x i32> <i32 0, i32 2>
  %124 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %123, <2 x i64>* %124, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad16x16x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %21, %9
  %22 = phi i8* [ %0, %9 ], [ %105, %21 ]
  %23 = phi i8* [ %4, %9 ], [ %110, %21 ]
  %24 = phi i8* [ %5, %9 ], [ %111, %21 ]
  %25 = phi i32 [ 0, %9 ], [ %112, %21 ]
  %26 = phi i8* [ %11, %9 ], [ %109, %21 ]
  %27 = phi i8* [ %13, %9 ], [ %108, %21 ]
  %28 = phi i8* [ %15, %9 ], [ %107, %21 ]
  %29 = phi i8* [ %16, %9 ], [ %106, %21 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %104, %21 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %90, %21 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %76, %21 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %62, %21 ]
  %34 = bitcast i8* %22 to <16 x i8>*
  %35 = load <16 x i8>, <16 x i8>* %34, align 1
  %36 = bitcast i8* %23 to <16 x i8>*
  %37 = load <16 x i8>, <16 x i8>* %36, align 1
  %38 = bitcast i8* %24 to <2 x i64>*
  %39 = load <2 x i64>, <2 x i64>* %38, align 1
  %40 = bitcast <2 x i64> %39 to <16 x i8>
  %41 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %40
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = select i1 %17, <2 x i64> %42, <2 x i64> %39
  %44 = select i1 %17, <2 x i64> %39, <2 x i64> %42
  %45 = bitcast i8* %29 to <16 x i8>*
  %46 = load <16 x i8>, <16 x i8>* %45, align 1
  %47 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %48 = bitcast <2 x i64> %43 to <16 x i8>
  %49 = bitcast <2 x i64> %44 to <16 x i8>
  %50 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %47, <16 x i8> %50) #2
  %52 = lshr <8 x i16> %51, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #2
  %54 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %55 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %56 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %54, <16 x i8> %55) #2
  %57 = lshr <8 x i16> %56, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %58 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %57, <8 x i16> zeroinitializer) #2
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %58) #2
  %60 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %59, <16 x i8> %35) #2
  %61 = bitcast <2 x i64> %60 to <4 x i32>
  %62 = add <4 x i32> %33, %61
  %63 = bitcast i8* %28 to <16 x i8>*
  %64 = load <16 x i8>, <16 x i8>* %63, align 1
  %65 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> %50) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %70 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %55) #2
  %71 = lshr <8 x i16> %70, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %72 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %71, <8 x i16> zeroinitializer) #2
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %68, <8 x i16> %72) #2
  %74 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %73, <16 x i8> %35) #2
  %75 = bitcast <2 x i64> %74 to <4 x i32>
  %76 = add <4 x i32> %32, %75
  %77 = bitcast i8* %27 to <16 x i8>*
  %78 = load <16 x i8>, <16 x i8>* %77, align 1
  %79 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %80 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %79, <16 x i8> %50) #2
  %81 = lshr <8 x i16> %80, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %82 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %81, <8 x i16> zeroinitializer) #2
  %83 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %84 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %83, <16 x i8> %55) #2
  %85 = lshr <8 x i16> %84, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %86 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %85, <8 x i16> zeroinitializer) #2
  %87 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %82, <8 x i16> %86) #2
  %88 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %87, <16 x i8> %35) #2
  %89 = bitcast <2 x i64> %88 to <4 x i32>
  %90 = add <4 x i32> %31, %89
  %91 = bitcast i8* %26 to <16 x i8>*
  %92 = load <16 x i8>, <16 x i8>* %91, align 1
  %93 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %94 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %93, <16 x i8> %50) #2
  %95 = lshr <8 x i16> %94, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %96 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %95, <8 x i16> zeroinitializer) #2
  %97 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %98 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %97, <16 x i8> %55) #2
  %99 = lshr <8 x i16> %98, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #2
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %96, <8 x i16> %100) #2
  %102 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %101, <16 x i8> %35) #2
  %103 = bitcast <2 x i64> %102 to <4 x i32>
  %104 = add <4 x i32> %30, %103
  %105 = getelementptr inbounds i8, i8* %22, i64 %18
  %106 = getelementptr inbounds i8, i8* %29, i64 %19
  %107 = getelementptr inbounds i8, i8* %28, i64 %19
  %108 = getelementptr inbounds i8, i8* %27, i64 %19
  %109 = getelementptr inbounds i8, i8* %26, i64 %19
  %110 = getelementptr inbounds i8, i8* %23, i64 16
  %111 = getelementptr inbounds i8, i8* %24, i64 %20
  %112 = add nuw nsw i32 %25, 1
  %113 = icmp eq i32 %112, 16
  br i1 %113, label %114, label %21

114:                                              ; preds = %21
  %115 = shufflevector <4 x i32> %62, <4 x i32> %76, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %116 = shufflevector <4 x i32> %62, <4 x i32> %76, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %117 = add <4 x i32> %116, %115
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = shufflevector <4 x i32> %90, <4 x i32> %104, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %120 = shufflevector <4 x i32> %90, <4 x i32> %104, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %121 = add <4 x i32> %120, %119
  %122 = bitcast <4 x i32> %121 to <2 x i64>
  %123 = shufflevector <2 x i64> %118, <2 x i64> %122, <2 x i32> <i32 0, i32 2>
  %124 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %123, <2 x i64>* %124, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad16x8x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %21, %9
  %22 = phi i8* [ %0, %9 ], [ %105, %21 ]
  %23 = phi i8* [ %4, %9 ], [ %110, %21 ]
  %24 = phi i8* [ %5, %9 ], [ %111, %21 ]
  %25 = phi i32 [ 0, %9 ], [ %112, %21 ]
  %26 = phi i8* [ %11, %9 ], [ %109, %21 ]
  %27 = phi i8* [ %13, %9 ], [ %108, %21 ]
  %28 = phi i8* [ %15, %9 ], [ %107, %21 ]
  %29 = phi i8* [ %16, %9 ], [ %106, %21 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %104, %21 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %90, %21 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %76, %21 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %62, %21 ]
  %34 = bitcast i8* %22 to <16 x i8>*
  %35 = load <16 x i8>, <16 x i8>* %34, align 1
  %36 = bitcast i8* %23 to <16 x i8>*
  %37 = load <16 x i8>, <16 x i8>* %36, align 1
  %38 = bitcast i8* %24 to <2 x i64>*
  %39 = load <2 x i64>, <2 x i64>* %38, align 1
  %40 = bitcast <2 x i64> %39 to <16 x i8>
  %41 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %40
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = select i1 %17, <2 x i64> %42, <2 x i64> %39
  %44 = select i1 %17, <2 x i64> %39, <2 x i64> %42
  %45 = bitcast i8* %29 to <16 x i8>*
  %46 = load <16 x i8>, <16 x i8>* %45, align 1
  %47 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %48 = bitcast <2 x i64> %43 to <16 x i8>
  %49 = bitcast <2 x i64> %44 to <16 x i8>
  %50 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %47, <16 x i8> %50) #2
  %52 = lshr <8 x i16> %51, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #2
  %54 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %55 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %56 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %54, <16 x i8> %55) #2
  %57 = lshr <8 x i16> %56, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %58 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %57, <8 x i16> zeroinitializer) #2
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %58) #2
  %60 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %59, <16 x i8> %35) #2
  %61 = bitcast <2 x i64> %60 to <4 x i32>
  %62 = add <4 x i32> %33, %61
  %63 = bitcast i8* %28 to <16 x i8>*
  %64 = load <16 x i8>, <16 x i8>* %63, align 1
  %65 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> %50) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %70 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %55) #2
  %71 = lshr <8 x i16> %70, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %72 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %71, <8 x i16> zeroinitializer) #2
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %68, <8 x i16> %72) #2
  %74 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %73, <16 x i8> %35) #2
  %75 = bitcast <2 x i64> %74 to <4 x i32>
  %76 = add <4 x i32> %32, %75
  %77 = bitcast i8* %27 to <16 x i8>*
  %78 = load <16 x i8>, <16 x i8>* %77, align 1
  %79 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %80 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %79, <16 x i8> %50) #2
  %81 = lshr <8 x i16> %80, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %82 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %81, <8 x i16> zeroinitializer) #2
  %83 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %84 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %83, <16 x i8> %55) #2
  %85 = lshr <8 x i16> %84, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %86 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %85, <8 x i16> zeroinitializer) #2
  %87 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %82, <8 x i16> %86) #2
  %88 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %87, <16 x i8> %35) #2
  %89 = bitcast <2 x i64> %88 to <4 x i32>
  %90 = add <4 x i32> %31, %89
  %91 = bitcast i8* %26 to <16 x i8>*
  %92 = load <16 x i8>, <16 x i8>* %91, align 1
  %93 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %94 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %93, <16 x i8> %50) #2
  %95 = lshr <8 x i16> %94, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %96 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %95, <8 x i16> zeroinitializer) #2
  %97 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %98 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %97, <16 x i8> %55) #2
  %99 = lshr <8 x i16> %98, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #2
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %96, <8 x i16> %100) #2
  %102 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %101, <16 x i8> %35) #2
  %103 = bitcast <2 x i64> %102 to <4 x i32>
  %104 = add <4 x i32> %30, %103
  %105 = getelementptr inbounds i8, i8* %22, i64 %18
  %106 = getelementptr inbounds i8, i8* %29, i64 %19
  %107 = getelementptr inbounds i8, i8* %28, i64 %19
  %108 = getelementptr inbounds i8, i8* %27, i64 %19
  %109 = getelementptr inbounds i8, i8* %26, i64 %19
  %110 = getelementptr inbounds i8, i8* %23, i64 16
  %111 = getelementptr inbounds i8, i8* %24, i64 %20
  %112 = add nuw nsw i32 %25, 1
  %113 = icmp eq i32 %112, 8
  br i1 %113, label %114, label %21

114:                                              ; preds = %21
  %115 = shufflevector <4 x i32> %62, <4 x i32> %76, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %116 = shufflevector <4 x i32> %62, <4 x i32> %76, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %117 = add <4 x i32> %116, %115
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = shufflevector <4 x i32> %90, <4 x i32> %104, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %120 = shufflevector <4 x i32> %90, <4 x i32> %104, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %121 = add <4 x i32> %120, %119
  %122 = bitcast <4 x i32> %121 to <2 x i64>
  %123 = shufflevector <2 x i64> %118, <2 x i64> %122, <2 x i32> <i32 0, i32 2>
  %124 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %123, <2 x i64>* %124, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad8x16x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = sext i32 %1 to i64
  %18 = sext i32 %6 to i64
  %19 = icmp ne i32 %7, 0
  %20 = sext i32 %3 to i64
  %21 = shl nsw i32 %3, 1
  %22 = sext i32 %21 to i64
  %23 = shl nsw i32 %1, 1
  %24 = sext i32 %23 to i64
  %25 = shl nsw i32 %6, 1
  %26 = sext i32 %25 to i64
  br label %27

27:                                               ; preds = %27, %9
  %28 = phi i8* [ %0, %9 ], [ %161, %27 ]
  %29 = phi i8* [ %4, %9 ], [ %162, %27 ]
  %30 = phi i8* [ %5, %9 ], [ %163, %27 ]
  %31 = phi i8* [ %16, %9 ], [ %157, %27 ]
  %32 = phi i8* [ %15, %9 ], [ %158, %27 ]
  %33 = phi i8* [ %13, %9 ], [ %159, %27 ]
  %34 = phi i8* [ %11, %9 ], [ %160, %27 ]
  %35 = phi <4 x i32> [ zeroinitializer, %9 ], [ %93, %27 ]
  %36 = phi <4 x i32> [ zeroinitializer, %9 ], [ %114, %27 ]
  %37 = phi i32 [ 0, %9 ], [ %164, %27 ]
  %38 = phi <4 x i32> [ zeroinitializer, %9 ], [ %156, %27 ]
  %39 = phi <4 x i32> [ zeroinitializer, %9 ], [ %135, %27 ]
  %40 = bitcast i8* %28 to i64*
  %41 = load i64, i64* %40, align 1
  %42 = insertelement <2 x i64> undef, i64 %41, i32 0
  %43 = getelementptr inbounds i8, i8* %28, i64 %17
  %44 = bitcast i8* %43 to i64*
  %45 = load i64, i64* %44, align 1
  %46 = insertelement <2 x i64> %42, i64 %45, i32 1
  %47 = bitcast i8* %29 to i64*
  %48 = load i64, i64* %47, align 1
  %49 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %48, i32 0
  %50 = getelementptr inbounds i8, i8* %29, i64 8
  %51 = bitcast i8* %50 to i64*
  %52 = load i64, i64* %51, align 1
  %53 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %52, i32 0
  %54 = bitcast i8* %30 to i64*
  %55 = load i64, i64* %54, align 1
  %56 = insertelement <2 x i64> undef, i64 %55, i32 0
  %57 = getelementptr inbounds i8, i8* %30, i64 %18
  %58 = bitcast i8* %57 to i64*
  %59 = load i64, i64* %58, align 1
  %60 = insertelement <2 x i64> %56, i64 %59, i32 1
  %61 = bitcast <2 x i64> %60 to <16 x i8>
  %62 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %61
  %63 = bitcast <16 x i8> %62 to <2 x i64>
  %64 = select i1 %19, <2 x i64> %63, <2 x i64> %60
  %65 = select i1 %19, <2 x i64> %60, <2 x i64> %63
  %66 = bitcast i8* %31 to i64*
  %67 = load i64, i64* %66, align 1
  %68 = insertelement <2 x i64> undef, i64 %67, i32 0
  %69 = getelementptr inbounds i8, i8* %31, i64 %20
  %70 = bitcast i8* %69 to i64*
  %71 = load i64, i64* %70, align 1
  %72 = insertelement <2 x i64> undef, i64 %71, i32 0
  %73 = bitcast <2 x i64> %68 to <16 x i8>
  %74 = bitcast <2 x i64> %49 to <16 x i8>
  %75 = shufflevector <16 x i8> %73, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %76 = bitcast <2 x i64> %64 to <16 x i8>
  %77 = bitcast <2 x i64> %65 to <16 x i8>
  %78 = shufflevector <16 x i8> %76, <16 x i8> %77, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %75, <16 x i8> %78) #2
  %80 = lshr <8 x i16> %79, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %81 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %80, <8 x i16> zeroinitializer) #2
  %82 = bitcast <2 x i64> %72 to <16 x i8>
  %83 = bitcast <2 x i64> %53 to <16 x i8>
  %84 = shufflevector <16 x i8> %82, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %85 = shufflevector <16 x i8> %76, <16 x i8> %77, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %86 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %84, <16 x i8> %85) #2
  %87 = lshr <8 x i16> %86, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %88 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %87, <8 x i16> zeroinitializer) #2
  %89 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> %88) #2
  %90 = bitcast <2 x i64> %46 to <16 x i8>
  %91 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %89, <16 x i8> %90) #2
  %92 = bitcast <2 x i64> %91 to <4 x i32>
  %93 = add <4 x i32> %35, %92
  %94 = bitcast i8* %32 to i64*
  %95 = load i64, i64* %94, align 1
  %96 = insertelement <2 x i64> undef, i64 %95, i32 0
  %97 = getelementptr inbounds i8, i8* %32, i64 %20
  %98 = bitcast i8* %97 to i64*
  %99 = load i64, i64* %98, align 1
  %100 = insertelement <2 x i64> undef, i64 %99, i32 0
  %101 = bitcast <2 x i64> %96 to <16 x i8>
  %102 = shufflevector <16 x i8> %101, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %103 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %102, <16 x i8> %78) #2
  %104 = lshr <8 x i16> %103, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %105 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %104, <8 x i16> zeroinitializer) #2
  %106 = bitcast <2 x i64> %100 to <16 x i8>
  %107 = shufflevector <16 x i8> %106, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %108 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %107, <16 x i8> %85) #2
  %109 = lshr <8 x i16> %108, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %110 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %109, <8 x i16> zeroinitializer) #2
  %111 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %105, <8 x i16> %110) #2
  %112 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %111, <16 x i8> %90) #2
  %113 = bitcast <2 x i64> %112 to <4 x i32>
  %114 = add <4 x i32> %36, %113
  %115 = bitcast i8* %33 to i64*
  %116 = load i64, i64* %115, align 1
  %117 = insertelement <2 x i64> undef, i64 %116, i32 0
  %118 = getelementptr inbounds i8, i8* %33, i64 %20
  %119 = bitcast i8* %118 to i64*
  %120 = load i64, i64* %119, align 1
  %121 = insertelement <2 x i64> undef, i64 %120, i32 0
  %122 = bitcast <2 x i64> %117 to <16 x i8>
  %123 = shufflevector <16 x i8> %122, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %124 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %123, <16 x i8> %78) #2
  %125 = lshr <8 x i16> %124, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %126 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %125, <8 x i16> zeroinitializer) #2
  %127 = bitcast <2 x i64> %121 to <16 x i8>
  %128 = shufflevector <16 x i8> %127, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %129 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %128, <16 x i8> %85) #2
  %130 = lshr <8 x i16> %129, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %131 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %130, <8 x i16> zeroinitializer) #2
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %126, <8 x i16> %131) #2
  %133 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %132, <16 x i8> %90) #2
  %134 = bitcast <2 x i64> %133 to <4 x i32>
  %135 = add <4 x i32> %39, %134
  %136 = bitcast i8* %34 to i64*
  %137 = load i64, i64* %136, align 1
  %138 = insertelement <2 x i64> undef, i64 %137, i32 0
  %139 = getelementptr inbounds i8, i8* %34, i64 %20
  %140 = bitcast i8* %139 to i64*
  %141 = load i64, i64* %140, align 1
  %142 = insertelement <2 x i64> undef, i64 %141, i32 0
  %143 = bitcast <2 x i64> %138 to <16 x i8>
  %144 = shufflevector <16 x i8> %143, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %145 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %144, <16 x i8> %78) #2
  %146 = lshr <8 x i16> %145, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %147 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %146, <8 x i16> zeroinitializer) #2
  %148 = bitcast <2 x i64> %142 to <16 x i8>
  %149 = shufflevector <16 x i8> %148, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %150 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %149, <16 x i8> %85) #2
  %151 = lshr <8 x i16> %150, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %152 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %151, <8 x i16> zeroinitializer) #2
  %153 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %147, <8 x i16> %152) #2
  %154 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %153, <16 x i8> %90) #2
  %155 = bitcast <2 x i64> %154 to <4 x i32>
  %156 = add <4 x i32> %38, %155
  %157 = getelementptr inbounds i8, i8* %31, i64 %22
  %158 = getelementptr inbounds i8, i8* %32, i64 %22
  %159 = getelementptr inbounds i8, i8* %33, i64 %22
  %160 = getelementptr inbounds i8, i8* %34, i64 %22
  %161 = getelementptr inbounds i8, i8* %28, i64 %24
  %162 = getelementptr inbounds i8, i8* %29, i64 16
  %163 = getelementptr inbounds i8, i8* %30, i64 %26
  %164 = add nuw nsw i32 %37, 2
  %165 = icmp ult i32 %164, 16
  br i1 %165, label %27, label %166

166:                                              ; preds = %27
  %167 = shufflevector <4 x i32> %93, <4 x i32> %114, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %168 = shufflevector <4 x i32> %93, <4 x i32> %114, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %169 = add <4 x i32> %168, %167
  %170 = bitcast <4 x i32> %169 to <2 x i64>
  %171 = shufflevector <4 x i32> %135, <4 x i32> %156, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %172 = shufflevector <4 x i32> %135, <4 x i32> %156, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %173 = add <4 x i32> %172, %171
  %174 = bitcast <4 x i32> %173 to <2 x i64>
  %175 = shufflevector <2 x i64> %170, <2 x i64> %174, <2 x i32> <i32 0, i32 2>
  %176 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %175, <2 x i64>* %176, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad8x8x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = sext i32 %1 to i64
  %18 = sext i32 %6 to i64
  %19 = icmp ne i32 %7, 0
  %20 = sext i32 %3 to i64
  %21 = shl nsw i32 %3, 1
  %22 = sext i32 %21 to i64
  %23 = shl nsw i32 %1, 1
  %24 = sext i32 %23 to i64
  %25 = shl nsw i32 %6, 1
  %26 = sext i32 %25 to i64
  br label %27

27:                                               ; preds = %27, %9
  %28 = phi i8* [ %0, %9 ], [ %161, %27 ]
  %29 = phi i8* [ %4, %9 ], [ %162, %27 ]
  %30 = phi i8* [ %5, %9 ], [ %163, %27 ]
  %31 = phi i8* [ %16, %9 ], [ %157, %27 ]
  %32 = phi i8* [ %15, %9 ], [ %158, %27 ]
  %33 = phi i8* [ %13, %9 ], [ %159, %27 ]
  %34 = phi i8* [ %11, %9 ], [ %160, %27 ]
  %35 = phi <4 x i32> [ zeroinitializer, %9 ], [ %93, %27 ]
  %36 = phi <4 x i32> [ zeroinitializer, %9 ], [ %114, %27 ]
  %37 = phi i32 [ 0, %9 ], [ %164, %27 ]
  %38 = phi <4 x i32> [ zeroinitializer, %9 ], [ %156, %27 ]
  %39 = phi <4 x i32> [ zeroinitializer, %9 ], [ %135, %27 ]
  %40 = bitcast i8* %28 to i64*
  %41 = load i64, i64* %40, align 1
  %42 = insertelement <2 x i64> undef, i64 %41, i32 0
  %43 = getelementptr inbounds i8, i8* %28, i64 %17
  %44 = bitcast i8* %43 to i64*
  %45 = load i64, i64* %44, align 1
  %46 = insertelement <2 x i64> %42, i64 %45, i32 1
  %47 = bitcast i8* %29 to i64*
  %48 = load i64, i64* %47, align 1
  %49 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %48, i32 0
  %50 = getelementptr inbounds i8, i8* %29, i64 8
  %51 = bitcast i8* %50 to i64*
  %52 = load i64, i64* %51, align 1
  %53 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %52, i32 0
  %54 = bitcast i8* %30 to i64*
  %55 = load i64, i64* %54, align 1
  %56 = insertelement <2 x i64> undef, i64 %55, i32 0
  %57 = getelementptr inbounds i8, i8* %30, i64 %18
  %58 = bitcast i8* %57 to i64*
  %59 = load i64, i64* %58, align 1
  %60 = insertelement <2 x i64> %56, i64 %59, i32 1
  %61 = bitcast <2 x i64> %60 to <16 x i8>
  %62 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %61
  %63 = bitcast <16 x i8> %62 to <2 x i64>
  %64 = select i1 %19, <2 x i64> %63, <2 x i64> %60
  %65 = select i1 %19, <2 x i64> %60, <2 x i64> %63
  %66 = bitcast i8* %31 to i64*
  %67 = load i64, i64* %66, align 1
  %68 = insertelement <2 x i64> undef, i64 %67, i32 0
  %69 = getelementptr inbounds i8, i8* %31, i64 %20
  %70 = bitcast i8* %69 to i64*
  %71 = load i64, i64* %70, align 1
  %72 = insertelement <2 x i64> undef, i64 %71, i32 0
  %73 = bitcast <2 x i64> %68 to <16 x i8>
  %74 = bitcast <2 x i64> %49 to <16 x i8>
  %75 = shufflevector <16 x i8> %73, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %76 = bitcast <2 x i64> %64 to <16 x i8>
  %77 = bitcast <2 x i64> %65 to <16 x i8>
  %78 = shufflevector <16 x i8> %76, <16 x i8> %77, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %75, <16 x i8> %78) #2
  %80 = lshr <8 x i16> %79, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %81 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %80, <8 x i16> zeroinitializer) #2
  %82 = bitcast <2 x i64> %72 to <16 x i8>
  %83 = bitcast <2 x i64> %53 to <16 x i8>
  %84 = shufflevector <16 x i8> %82, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %85 = shufflevector <16 x i8> %76, <16 x i8> %77, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %86 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %84, <16 x i8> %85) #2
  %87 = lshr <8 x i16> %86, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %88 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %87, <8 x i16> zeroinitializer) #2
  %89 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> %88) #2
  %90 = bitcast <2 x i64> %46 to <16 x i8>
  %91 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %89, <16 x i8> %90) #2
  %92 = bitcast <2 x i64> %91 to <4 x i32>
  %93 = add <4 x i32> %35, %92
  %94 = bitcast i8* %32 to i64*
  %95 = load i64, i64* %94, align 1
  %96 = insertelement <2 x i64> undef, i64 %95, i32 0
  %97 = getelementptr inbounds i8, i8* %32, i64 %20
  %98 = bitcast i8* %97 to i64*
  %99 = load i64, i64* %98, align 1
  %100 = insertelement <2 x i64> undef, i64 %99, i32 0
  %101 = bitcast <2 x i64> %96 to <16 x i8>
  %102 = shufflevector <16 x i8> %101, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %103 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %102, <16 x i8> %78) #2
  %104 = lshr <8 x i16> %103, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %105 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %104, <8 x i16> zeroinitializer) #2
  %106 = bitcast <2 x i64> %100 to <16 x i8>
  %107 = shufflevector <16 x i8> %106, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %108 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %107, <16 x i8> %85) #2
  %109 = lshr <8 x i16> %108, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %110 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %109, <8 x i16> zeroinitializer) #2
  %111 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %105, <8 x i16> %110) #2
  %112 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %111, <16 x i8> %90) #2
  %113 = bitcast <2 x i64> %112 to <4 x i32>
  %114 = add <4 x i32> %36, %113
  %115 = bitcast i8* %33 to i64*
  %116 = load i64, i64* %115, align 1
  %117 = insertelement <2 x i64> undef, i64 %116, i32 0
  %118 = getelementptr inbounds i8, i8* %33, i64 %20
  %119 = bitcast i8* %118 to i64*
  %120 = load i64, i64* %119, align 1
  %121 = insertelement <2 x i64> undef, i64 %120, i32 0
  %122 = bitcast <2 x i64> %117 to <16 x i8>
  %123 = shufflevector <16 x i8> %122, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %124 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %123, <16 x i8> %78) #2
  %125 = lshr <8 x i16> %124, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %126 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %125, <8 x i16> zeroinitializer) #2
  %127 = bitcast <2 x i64> %121 to <16 x i8>
  %128 = shufflevector <16 x i8> %127, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %129 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %128, <16 x i8> %85) #2
  %130 = lshr <8 x i16> %129, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %131 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %130, <8 x i16> zeroinitializer) #2
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %126, <8 x i16> %131) #2
  %133 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %132, <16 x i8> %90) #2
  %134 = bitcast <2 x i64> %133 to <4 x i32>
  %135 = add <4 x i32> %39, %134
  %136 = bitcast i8* %34 to i64*
  %137 = load i64, i64* %136, align 1
  %138 = insertelement <2 x i64> undef, i64 %137, i32 0
  %139 = getelementptr inbounds i8, i8* %34, i64 %20
  %140 = bitcast i8* %139 to i64*
  %141 = load i64, i64* %140, align 1
  %142 = insertelement <2 x i64> undef, i64 %141, i32 0
  %143 = bitcast <2 x i64> %138 to <16 x i8>
  %144 = shufflevector <16 x i8> %143, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %145 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %144, <16 x i8> %78) #2
  %146 = lshr <8 x i16> %145, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %147 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %146, <8 x i16> zeroinitializer) #2
  %148 = bitcast <2 x i64> %142 to <16 x i8>
  %149 = shufflevector <16 x i8> %148, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %150 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %149, <16 x i8> %85) #2
  %151 = lshr <8 x i16> %150, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %152 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %151, <8 x i16> zeroinitializer) #2
  %153 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %147, <8 x i16> %152) #2
  %154 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %153, <16 x i8> %90) #2
  %155 = bitcast <2 x i64> %154 to <4 x i32>
  %156 = add <4 x i32> %38, %155
  %157 = getelementptr inbounds i8, i8* %31, i64 %22
  %158 = getelementptr inbounds i8, i8* %32, i64 %22
  %159 = getelementptr inbounds i8, i8* %33, i64 %22
  %160 = getelementptr inbounds i8, i8* %34, i64 %22
  %161 = getelementptr inbounds i8, i8* %28, i64 %24
  %162 = getelementptr inbounds i8, i8* %29, i64 16
  %163 = getelementptr inbounds i8, i8* %30, i64 %26
  %164 = add nuw nsw i32 %37, 2
  %165 = icmp ult i32 %164, 8
  br i1 %165, label %27, label %166

166:                                              ; preds = %27
  %167 = shufflevector <4 x i32> %93, <4 x i32> %114, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %168 = shufflevector <4 x i32> %93, <4 x i32> %114, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %169 = add <4 x i32> %168, %167
  %170 = bitcast <4 x i32> %169 to <2 x i64>
  %171 = shufflevector <4 x i32> %135, <4 x i32> %156, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %172 = shufflevector <4 x i32> %135, <4 x i32> %156, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %173 = add <4 x i32> %172, %171
  %174 = bitcast <4 x i32> %173 to <2 x i64>
  %175 = shufflevector <2 x i64> %170, <2 x i64> %174, <2 x i32> <i32 0, i32 2>
  %176 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %175, <2 x i64>* %176, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad8x4x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = sext i32 %1 to i64
  %18 = sext i32 %6 to i64
  %19 = icmp ne i32 %7, 0
  %20 = sext i32 %3 to i64
  %21 = shl nsw i32 %3, 1
  %22 = sext i32 %21 to i64
  %23 = shl nsw i32 %1, 1
  %24 = sext i32 %23 to i64
  %25 = shl nsw i32 %6, 1
  %26 = sext i32 %25 to i64
  br label %27

27:                                               ; preds = %27, %9
  %28 = phi i8* [ %0, %9 ], [ %161, %27 ]
  %29 = phi i8* [ %4, %9 ], [ %162, %27 ]
  %30 = phi i8* [ %5, %9 ], [ %163, %27 ]
  %31 = phi i8* [ %16, %9 ], [ %157, %27 ]
  %32 = phi i8* [ %15, %9 ], [ %158, %27 ]
  %33 = phi i8* [ %13, %9 ], [ %159, %27 ]
  %34 = phi i8* [ %11, %9 ], [ %160, %27 ]
  %35 = phi <4 x i32> [ zeroinitializer, %9 ], [ %93, %27 ]
  %36 = phi <4 x i32> [ zeroinitializer, %9 ], [ %114, %27 ]
  %37 = phi i32 [ 0, %9 ], [ %164, %27 ]
  %38 = phi <4 x i32> [ zeroinitializer, %9 ], [ %156, %27 ]
  %39 = phi <4 x i32> [ zeroinitializer, %9 ], [ %135, %27 ]
  %40 = bitcast i8* %28 to i64*
  %41 = load i64, i64* %40, align 1
  %42 = insertelement <2 x i64> undef, i64 %41, i32 0
  %43 = getelementptr inbounds i8, i8* %28, i64 %17
  %44 = bitcast i8* %43 to i64*
  %45 = load i64, i64* %44, align 1
  %46 = insertelement <2 x i64> %42, i64 %45, i32 1
  %47 = bitcast i8* %29 to i64*
  %48 = load i64, i64* %47, align 1
  %49 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %48, i32 0
  %50 = getelementptr inbounds i8, i8* %29, i64 8
  %51 = bitcast i8* %50 to i64*
  %52 = load i64, i64* %51, align 1
  %53 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %52, i32 0
  %54 = bitcast i8* %30 to i64*
  %55 = load i64, i64* %54, align 1
  %56 = insertelement <2 x i64> undef, i64 %55, i32 0
  %57 = getelementptr inbounds i8, i8* %30, i64 %18
  %58 = bitcast i8* %57 to i64*
  %59 = load i64, i64* %58, align 1
  %60 = insertelement <2 x i64> %56, i64 %59, i32 1
  %61 = bitcast <2 x i64> %60 to <16 x i8>
  %62 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %61
  %63 = bitcast <16 x i8> %62 to <2 x i64>
  %64 = select i1 %19, <2 x i64> %63, <2 x i64> %60
  %65 = select i1 %19, <2 x i64> %60, <2 x i64> %63
  %66 = bitcast i8* %31 to i64*
  %67 = load i64, i64* %66, align 1
  %68 = insertelement <2 x i64> undef, i64 %67, i32 0
  %69 = getelementptr inbounds i8, i8* %31, i64 %20
  %70 = bitcast i8* %69 to i64*
  %71 = load i64, i64* %70, align 1
  %72 = insertelement <2 x i64> undef, i64 %71, i32 0
  %73 = bitcast <2 x i64> %68 to <16 x i8>
  %74 = bitcast <2 x i64> %49 to <16 x i8>
  %75 = shufflevector <16 x i8> %73, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %76 = bitcast <2 x i64> %64 to <16 x i8>
  %77 = bitcast <2 x i64> %65 to <16 x i8>
  %78 = shufflevector <16 x i8> %76, <16 x i8> %77, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %75, <16 x i8> %78) #2
  %80 = lshr <8 x i16> %79, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %81 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %80, <8 x i16> zeroinitializer) #2
  %82 = bitcast <2 x i64> %72 to <16 x i8>
  %83 = bitcast <2 x i64> %53 to <16 x i8>
  %84 = shufflevector <16 x i8> %82, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %85 = shufflevector <16 x i8> %76, <16 x i8> %77, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %86 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %84, <16 x i8> %85) #2
  %87 = lshr <8 x i16> %86, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %88 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %87, <8 x i16> zeroinitializer) #2
  %89 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> %88) #2
  %90 = bitcast <2 x i64> %46 to <16 x i8>
  %91 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %89, <16 x i8> %90) #2
  %92 = bitcast <2 x i64> %91 to <4 x i32>
  %93 = add <4 x i32> %35, %92
  %94 = bitcast i8* %32 to i64*
  %95 = load i64, i64* %94, align 1
  %96 = insertelement <2 x i64> undef, i64 %95, i32 0
  %97 = getelementptr inbounds i8, i8* %32, i64 %20
  %98 = bitcast i8* %97 to i64*
  %99 = load i64, i64* %98, align 1
  %100 = insertelement <2 x i64> undef, i64 %99, i32 0
  %101 = bitcast <2 x i64> %96 to <16 x i8>
  %102 = shufflevector <16 x i8> %101, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %103 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %102, <16 x i8> %78) #2
  %104 = lshr <8 x i16> %103, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %105 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %104, <8 x i16> zeroinitializer) #2
  %106 = bitcast <2 x i64> %100 to <16 x i8>
  %107 = shufflevector <16 x i8> %106, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %108 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %107, <16 x i8> %85) #2
  %109 = lshr <8 x i16> %108, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %110 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %109, <8 x i16> zeroinitializer) #2
  %111 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %105, <8 x i16> %110) #2
  %112 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %111, <16 x i8> %90) #2
  %113 = bitcast <2 x i64> %112 to <4 x i32>
  %114 = add <4 x i32> %36, %113
  %115 = bitcast i8* %33 to i64*
  %116 = load i64, i64* %115, align 1
  %117 = insertelement <2 x i64> undef, i64 %116, i32 0
  %118 = getelementptr inbounds i8, i8* %33, i64 %20
  %119 = bitcast i8* %118 to i64*
  %120 = load i64, i64* %119, align 1
  %121 = insertelement <2 x i64> undef, i64 %120, i32 0
  %122 = bitcast <2 x i64> %117 to <16 x i8>
  %123 = shufflevector <16 x i8> %122, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %124 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %123, <16 x i8> %78) #2
  %125 = lshr <8 x i16> %124, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %126 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %125, <8 x i16> zeroinitializer) #2
  %127 = bitcast <2 x i64> %121 to <16 x i8>
  %128 = shufflevector <16 x i8> %127, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %129 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %128, <16 x i8> %85) #2
  %130 = lshr <8 x i16> %129, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %131 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %130, <8 x i16> zeroinitializer) #2
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %126, <8 x i16> %131) #2
  %133 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %132, <16 x i8> %90) #2
  %134 = bitcast <2 x i64> %133 to <4 x i32>
  %135 = add <4 x i32> %39, %134
  %136 = bitcast i8* %34 to i64*
  %137 = load i64, i64* %136, align 1
  %138 = insertelement <2 x i64> undef, i64 %137, i32 0
  %139 = getelementptr inbounds i8, i8* %34, i64 %20
  %140 = bitcast i8* %139 to i64*
  %141 = load i64, i64* %140, align 1
  %142 = insertelement <2 x i64> undef, i64 %141, i32 0
  %143 = bitcast <2 x i64> %138 to <16 x i8>
  %144 = shufflevector <16 x i8> %143, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %145 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %144, <16 x i8> %78) #2
  %146 = lshr <8 x i16> %145, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %147 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %146, <8 x i16> zeroinitializer) #2
  %148 = bitcast <2 x i64> %142 to <16 x i8>
  %149 = shufflevector <16 x i8> %148, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %150 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %149, <16 x i8> %85) #2
  %151 = lshr <8 x i16> %150, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %152 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %151, <8 x i16> zeroinitializer) #2
  %153 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %147, <8 x i16> %152) #2
  %154 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %153, <16 x i8> %90) #2
  %155 = bitcast <2 x i64> %154 to <4 x i32>
  %156 = add <4 x i32> %38, %155
  %157 = getelementptr inbounds i8, i8* %31, i64 %22
  %158 = getelementptr inbounds i8, i8* %32, i64 %22
  %159 = getelementptr inbounds i8, i8* %33, i64 %22
  %160 = getelementptr inbounds i8, i8* %34, i64 %22
  %161 = getelementptr inbounds i8, i8* %28, i64 %24
  %162 = getelementptr inbounds i8, i8* %29, i64 16
  %163 = getelementptr inbounds i8, i8* %30, i64 %26
  %164 = add nuw nsw i32 %37, 2
  %165 = icmp ult i32 %164, 4
  br i1 %165, label %27, label %166

166:                                              ; preds = %27
  %167 = shufflevector <4 x i32> %93, <4 x i32> %114, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %168 = shufflevector <4 x i32> %93, <4 x i32> %114, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %169 = add <4 x i32> %168, %167
  %170 = bitcast <4 x i32> %169 to <2 x i64>
  %171 = shufflevector <4 x i32> %135, <4 x i32> %156, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %172 = shufflevector <4 x i32> %135, <4 x i32> %156, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %173 = add <4 x i32> %172, %171
  %174 = bitcast <4 x i32> %173 to <2 x i64>
  %175 = shufflevector <2 x i64> %170, <2 x i64> %174, <2 x i32> <i32 0, i32 2>
  %176 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %175, <2 x i64>* %176, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad4x8x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = sext i32 %1 to i64
  %18 = sext i32 %6 to i64
  %19 = icmp ne i32 %7, 0
  %20 = sext i32 %3 to i64
  %21 = shl nsw i32 %3, 1
  %22 = sext i32 %21 to i64
  %23 = shl nsw i32 %1, 1
  %24 = sext i32 %23 to i64
  %25 = shl nsw i32 %6, 1
  %26 = sext i32 %25 to i64
  br label %27

27:                                               ; preds = %27, %9
  %28 = phi i8* [ %0, %9 ], [ %143, %27 ]
  %29 = phi i8* [ %4, %9 ], [ %144, %27 ]
  %30 = phi i8* [ %5, %9 ], [ %145, %27 ]
  %31 = phi i8* [ %16, %9 ], [ %139, %27 ]
  %32 = phi i8* [ %15, %9 ], [ %140, %27 ]
  %33 = phi i32 [ 0, %9 ], [ %146, %27 ]
  %34 = phi <4 x i32> [ zeroinitializer, %9 ], [ %138, %27 ]
  %35 = phi <4 x i32> [ zeroinitializer, %9 ], [ %122, %27 ]
  %36 = phi <4 x i32> [ zeroinitializer, %9 ], [ %106, %27 ]
  %37 = phi <4 x i32> [ zeroinitializer, %9 ], [ %90, %27 ]
  %38 = phi i8* [ %11, %9 ], [ %142, %27 ]
  %39 = phi i8* [ %13, %9 ], [ %141, %27 ]
  %40 = bitcast i8* %28 to i32*
  %41 = load i32, i32* %40, align 4
  %42 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %41, i32 0
  %43 = getelementptr inbounds i8, i8* %28, i64 %17
  %44 = bitcast i8* %43 to i32*
  %45 = load i32, i32* %44, align 4
  %46 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %45, i32 0
  %47 = shufflevector <4 x i32> %42, <4 x i32> %46, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %48 = bitcast i8* %29 to i32*
  %49 = load i32, i32* %48, align 4
  %50 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %49, i32 0
  %51 = getelementptr inbounds i8, i8* %29, i64 4
  %52 = bitcast i8* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %53, i32 0
  %55 = shufflevector <4 x i32> %50, <4 x i32> %54, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %56 = bitcast i8* %30 to i32*
  %57 = load i32, i32* %56, align 4
  %58 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %57, i32 0
  %59 = getelementptr inbounds i8, i8* %30, i64 %18
  %60 = bitcast i8* %59 to i32*
  %61 = load i32, i32* %60, align 4
  %62 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %61, i32 0
  %63 = shufflevector <4 x i32> %58, <4 x i32> %62, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %64 = bitcast <4 x i32> %63 to <2 x i64>
  %65 = bitcast <4 x i32> %63 to <16 x i8>
  %66 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %65
  %67 = bitcast <16 x i8> %66 to <2 x i64>
  %68 = select i1 %19, <2 x i64> %67, <2 x i64> %64
  %69 = select i1 %19, <2 x i64> %64, <2 x i64> %67
  %70 = bitcast i8* %31 to i32*
  %71 = load i32, i32* %70, align 4
  %72 = insertelement <4 x i32> undef, i32 %71, i32 0
  %73 = getelementptr inbounds i8, i8* %31, i64 %20
  %74 = bitcast i8* %73 to i32*
  %75 = load i32, i32* %74, align 4
  %76 = insertelement <4 x i32> %72, i32 %75, i32 1
  %77 = bitcast <4 x i32> %76 to <16 x i8>
  %78 = bitcast <4 x i32> %55 to <16 x i8>
  %79 = shufflevector <16 x i8> %77, <16 x i8> %78, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %80 = bitcast <2 x i64> %68 to <16 x i8>
  %81 = bitcast <2 x i64> %69 to <16 x i8>
  %82 = shufflevector <16 x i8> %80, <16 x i8> %81, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %83 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %79, <16 x i8> %82) #2
  %84 = lshr <8 x i16> %83, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %85 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %84, <8 x i16> zeroinitializer) #2
  %86 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %85, <8 x i16> zeroinitializer) #2
  %87 = bitcast <4 x i32> %47 to <16 x i8>
  %88 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %86, <16 x i8> %87) #2
  %89 = bitcast <2 x i64> %88 to <4 x i32>
  %90 = add <4 x i32> %37, %89
  %91 = bitcast i8* %32 to i32*
  %92 = load i32, i32* %91, align 4
  %93 = insertelement <4 x i32> undef, i32 %92, i32 0
  %94 = getelementptr inbounds i8, i8* %32, i64 %20
  %95 = bitcast i8* %94 to i32*
  %96 = load i32, i32* %95, align 4
  %97 = insertelement <4 x i32> %93, i32 %96, i32 1
  %98 = bitcast <4 x i32> %97 to <16 x i8>
  %99 = shufflevector <16 x i8> %98, <16 x i8> %78, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %100 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %99, <16 x i8> %82) #2
  %101 = lshr <8 x i16> %100, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %102 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %101, <8 x i16> zeroinitializer) #2
  %103 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %102, <8 x i16> zeroinitializer) #2
  %104 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %103, <16 x i8> %87) #2
  %105 = bitcast <2 x i64> %104 to <4 x i32>
  %106 = add <4 x i32> %36, %105
  %107 = bitcast i8* %39 to i32*
  %108 = load i32, i32* %107, align 4
  %109 = insertelement <4 x i32> undef, i32 %108, i32 0
  %110 = getelementptr inbounds i8, i8* %39, i64 %20
  %111 = bitcast i8* %110 to i32*
  %112 = load i32, i32* %111, align 4
  %113 = insertelement <4 x i32> %109, i32 %112, i32 1
  %114 = bitcast <4 x i32> %113 to <16 x i8>
  %115 = shufflevector <16 x i8> %114, <16 x i8> %78, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %116 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %115, <16 x i8> %82) #2
  %117 = lshr <8 x i16> %116, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %118 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %117, <8 x i16> zeroinitializer) #2
  %119 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> zeroinitializer) #2
  %120 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %119, <16 x i8> %87) #2
  %121 = bitcast <2 x i64> %120 to <4 x i32>
  %122 = add <4 x i32> %35, %121
  %123 = bitcast i8* %38 to i32*
  %124 = load i32, i32* %123, align 4
  %125 = insertelement <4 x i32> undef, i32 %124, i32 0
  %126 = getelementptr inbounds i8, i8* %38, i64 %20
  %127 = bitcast i8* %126 to i32*
  %128 = load i32, i32* %127, align 4
  %129 = insertelement <4 x i32> %125, i32 %128, i32 1
  %130 = bitcast <4 x i32> %129 to <16 x i8>
  %131 = shufflevector <16 x i8> %130, <16 x i8> %78, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %132 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %131, <16 x i8> %82) #2
  %133 = lshr <8 x i16> %132, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %134 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %133, <8 x i16> zeroinitializer) #2
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %134, <8 x i16> zeroinitializer) #2
  %136 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %135, <16 x i8> %87) #2
  %137 = bitcast <2 x i64> %136 to <4 x i32>
  %138 = add <4 x i32> %34, %137
  %139 = getelementptr inbounds i8, i8* %31, i64 %22
  %140 = getelementptr inbounds i8, i8* %32, i64 %22
  %141 = getelementptr inbounds i8, i8* %39, i64 %22
  %142 = getelementptr inbounds i8, i8* %38, i64 %22
  %143 = getelementptr inbounds i8, i8* %28, i64 %24
  %144 = getelementptr inbounds i8, i8* %29, i64 8
  %145 = getelementptr inbounds i8, i8* %30, i64 %26
  %146 = add nuw nsw i32 %33, 2
  %147 = icmp ult i32 %146, 8
  br i1 %147, label %27, label %148

148:                                              ; preds = %27
  %149 = shufflevector <4 x i32> %90, <4 x i32> %106, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %150 = bitcast <4 x i32> %149 to <2 x i64>
  %151 = shufflevector <4 x i32> %122, <4 x i32> %138, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %152 = bitcast <4 x i32> %151 to <2 x i64>
  %153 = shufflevector <2 x i64> %150, <2 x i64> %152, <2 x i32> <i32 0, i32 2>
  %154 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %153, <2 x i64>* %154, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad4x4x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = sext i32 %1 to i64
  %18 = sext i32 %6 to i64
  %19 = icmp ne i32 %7, 0
  %20 = sext i32 %3 to i64
  %21 = shl nsw i32 %3, 1
  %22 = sext i32 %21 to i64
  %23 = shl nsw i32 %1, 1
  %24 = sext i32 %23 to i64
  %25 = shl nsw i32 %6, 1
  %26 = sext i32 %25 to i64
  %27 = bitcast i8* %0 to i32*
  %28 = load i32, i32* %27, align 4
  %29 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %28, i32 0
  %30 = getelementptr inbounds i8, i8* %0, i64 %17
  %31 = bitcast i8* %30 to i32*
  %32 = load i32, i32* %31, align 4
  %33 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %32, i32 0
  %34 = shufflevector <4 x i32> %29, <4 x i32> %33, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %35 = bitcast i8* %4 to i32*
  %36 = load i32, i32* %35, align 4
  %37 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %36, i32 0
  %38 = getelementptr inbounds i8, i8* %4, i64 4
  %39 = bitcast i8* %38 to i32*
  %40 = load i32, i32* %39, align 4
  %41 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %40, i32 0
  %42 = shufflevector <4 x i32> %37, <4 x i32> %41, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %43 = bitcast i8* %5 to i32*
  %44 = load i32, i32* %43, align 4
  %45 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %44, i32 0
  %46 = getelementptr inbounds i8, i8* %5, i64 %18
  %47 = bitcast i8* %46 to i32*
  %48 = load i32, i32* %47, align 4
  %49 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %48, i32 0
  %50 = shufflevector <4 x i32> %45, <4 x i32> %49, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %51 = bitcast <4 x i32> %50 to <2 x i64>
  %52 = bitcast <4 x i32> %50 to <16 x i8>
  %53 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %52
  %54 = bitcast <16 x i8> %53 to <2 x i64>
  %55 = select i1 %19, <2 x i64> %54, <2 x i64> %51
  %56 = select i1 %19, <2 x i64> %51, <2 x i64> %54
  %57 = bitcast i8* %16 to i32*
  %58 = load i32, i32* %57, align 4
  %59 = insertelement <4 x i32> undef, i32 %58, i32 0
  %60 = getelementptr inbounds i8, i8* %16, i64 %20
  %61 = bitcast i8* %60 to i32*
  %62 = load i32, i32* %61, align 4
  %63 = insertelement <4 x i32> %59, i32 %62, i32 1
  %64 = bitcast <4 x i32> %63 to <16 x i8>
  %65 = bitcast <4 x i32> %42 to <16 x i8>
  %66 = shufflevector <16 x i8> %64, <16 x i8> %65, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %67 = bitcast <2 x i64> %55 to <16 x i8>
  %68 = bitcast <2 x i64> %56 to <16 x i8>
  %69 = shufflevector <16 x i8> %67, <16 x i8> %68, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %70 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %66, <16 x i8> %69) #2
  %71 = lshr <8 x i16> %70, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %72 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %71, <8 x i16> zeroinitializer) #2
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %72, <8 x i16> zeroinitializer) #2
  %74 = bitcast <4 x i32> %34 to <16 x i8>
  %75 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %73, <16 x i8> %74) #2
  %76 = bitcast <2 x i64> %75 to <4 x i32>
  %77 = bitcast i8* %15 to i32*
  %78 = load i32, i32* %77, align 4
  %79 = insertelement <4 x i32> undef, i32 %78, i32 0
  %80 = getelementptr inbounds i8, i8* %15, i64 %20
  %81 = bitcast i8* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = insertelement <4 x i32> %79, i32 %82, i32 1
  %84 = bitcast <4 x i32> %83 to <16 x i8>
  %85 = shufflevector <16 x i8> %84, <16 x i8> %65, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %86 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %85, <16 x i8> %69) #2
  %87 = lshr <8 x i16> %86, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %88 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %87, <8 x i16> zeroinitializer) #2
  %89 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %88, <8 x i16> zeroinitializer) #2
  %90 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %89, <16 x i8> %74) #2
  %91 = bitcast <2 x i64> %90 to <4 x i32>
  %92 = bitcast i8* %13 to i32*
  %93 = load i32, i32* %92, align 4
  %94 = insertelement <4 x i32> undef, i32 %93, i32 0
  %95 = getelementptr inbounds i8, i8* %13, i64 %20
  %96 = bitcast i8* %95 to i32*
  %97 = load i32, i32* %96, align 4
  %98 = insertelement <4 x i32> %94, i32 %97, i32 1
  %99 = bitcast <4 x i32> %98 to <16 x i8>
  %100 = shufflevector <16 x i8> %99, <16 x i8> %65, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %101 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %100, <16 x i8> %69) #2
  %102 = lshr <8 x i16> %101, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %103 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %102, <8 x i16> zeroinitializer) #2
  %104 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %103, <8 x i16> zeroinitializer) #2
  %105 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %104, <16 x i8> %74) #2
  %106 = bitcast <2 x i64> %105 to <4 x i32>
  %107 = bitcast i8* %11 to i32*
  %108 = load i32, i32* %107, align 4
  %109 = insertelement <4 x i32> undef, i32 %108, i32 0
  %110 = getelementptr inbounds i8, i8* %11, i64 %20
  %111 = bitcast i8* %110 to i32*
  %112 = load i32, i32* %111, align 4
  %113 = insertelement <4 x i32> %109, i32 %112, i32 1
  %114 = bitcast <4 x i32> %113 to <16 x i8>
  %115 = shufflevector <16 x i8> %114, <16 x i8> %65, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %116 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %115, <16 x i8> %69) #2
  %117 = lshr <8 x i16> %116, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %118 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %117, <8 x i16> zeroinitializer) #2
  %119 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> zeroinitializer) #2
  %120 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %119, <16 x i8> %74) #2
  %121 = bitcast <2 x i64> %120 to <4 x i32>
  %122 = getelementptr inbounds i8, i8* %16, i64 %22
  %123 = getelementptr inbounds i8, i8* %15, i64 %22
  %124 = getelementptr inbounds i8, i8* %13, i64 %22
  %125 = getelementptr inbounds i8, i8* %11, i64 %22
  %126 = getelementptr inbounds i8, i8* %0, i64 %24
  %127 = getelementptr inbounds i8, i8* %4, i64 8
  %128 = getelementptr inbounds i8, i8* %5, i64 %26
  %129 = bitcast i8* %126 to i32*
  %130 = load i32, i32* %129, align 4
  %131 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %130, i32 0
  %132 = getelementptr inbounds i8, i8* %126, i64 %17
  %133 = bitcast i8* %132 to i32*
  %134 = load i32, i32* %133, align 4
  %135 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %134, i32 0
  %136 = shufflevector <4 x i32> %131, <4 x i32> %135, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %137 = bitcast i8* %127 to i32*
  %138 = load i32, i32* %137, align 4
  %139 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %138, i32 0
  %140 = getelementptr inbounds i8, i8* %4, i64 12
  %141 = bitcast i8* %140 to i32*
  %142 = load i32, i32* %141, align 4
  %143 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %142, i32 0
  %144 = shufflevector <4 x i32> %139, <4 x i32> %143, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %145 = bitcast i8* %128 to i32*
  %146 = load i32, i32* %145, align 4
  %147 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %146, i32 0
  %148 = getelementptr inbounds i8, i8* %128, i64 %18
  %149 = bitcast i8* %148 to i32*
  %150 = load i32, i32* %149, align 4
  %151 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %150, i32 0
  %152 = shufflevector <4 x i32> %147, <4 x i32> %151, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %153 = bitcast <4 x i32> %152 to <2 x i64>
  %154 = bitcast <4 x i32> %152 to <16 x i8>
  %155 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %154
  %156 = bitcast <16 x i8> %155 to <2 x i64>
  %157 = select i1 %19, <2 x i64> %156, <2 x i64> %153
  %158 = select i1 %19, <2 x i64> %153, <2 x i64> %156
  %159 = bitcast i8* %122 to i32*
  %160 = load i32, i32* %159, align 4
  %161 = insertelement <4 x i32> undef, i32 %160, i32 0
  %162 = getelementptr inbounds i8, i8* %122, i64 %20
  %163 = bitcast i8* %162 to i32*
  %164 = load i32, i32* %163, align 4
  %165 = insertelement <4 x i32> %161, i32 %164, i32 1
  %166 = bitcast <4 x i32> %165 to <16 x i8>
  %167 = bitcast <4 x i32> %144 to <16 x i8>
  %168 = shufflevector <16 x i8> %166, <16 x i8> %167, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %169 = bitcast <2 x i64> %157 to <16 x i8>
  %170 = bitcast <2 x i64> %158 to <16 x i8>
  %171 = shufflevector <16 x i8> %169, <16 x i8> %170, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %172 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %168, <16 x i8> %171) #2
  %173 = lshr <8 x i16> %172, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %174 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %173, <8 x i16> zeroinitializer) #2
  %175 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %174, <8 x i16> zeroinitializer) #2
  %176 = bitcast <4 x i32> %136 to <16 x i8>
  %177 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %175, <16 x i8> %176) #2
  %178 = bitcast <2 x i64> %177 to <4 x i32>
  %179 = add <4 x i32> %76, %178
  %180 = bitcast i8* %123 to i32*
  %181 = load i32, i32* %180, align 4
  %182 = insertelement <4 x i32> undef, i32 %181, i32 0
  %183 = getelementptr inbounds i8, i8* %123, i64 %20
  %184 = bitcast i8* %183 to i32*
  %185 = load i32, i32* %184, align 4
  %186 = insertelement <4 x i32> %182, i32 %185, i32 1
  %187 = bitcast <4 x i32> %186 to <16 x i8>
  %188 = shufflevector <16 x i8> %187, <16 x i8> %167, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %189 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %188, <16 x i8> %171) #2
  %190 = lshr <8 x i16> %189, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %191 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %190, <8 x i16> zeroinitializer) #2
  %192 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %191, <8 x i16> zeroinitializer) #2
  %193 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %192, <16 x i8> %176) #2
  %194 = bitcast <2 x i64> %193 to <4 x i32>
  %195 = add <4 x i32> %91, %194
  %196 = bitcast i8* %124 to i32*
  %197 = load i32, i32* %196, align 4
  %198 = insertelement <4 x i32> undef, i32 %197, i32 0
  %199 = getelementptr inbounds i8, i8* %124, i64 %20
  %200 = bitcast i8* %199 to i32*
  %201 = load i32, i32* %200, align 4
  %202 = insertelement <4 x i32> %198, i32 %201, i32 1
  %203 = bitcast <4 x i32> %202 to <16 x i8>
  %204 = shufflevector <16 x i8> %203, <16 x i8> %167, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %205 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %204, <16 x i8> %171) #2
  %206 = lshr <8 x i16> %205, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %207 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %206, <8 x i16> zeroinitializer) #2
  %208 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %207, <8 x i16> zeroinitializer) #2
  %209 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %208, <16 x i8> %176) #2
  %210 = bitcast <2 x i64> %209 to <4 x i32>
  %211 = add <4 x i32> %106, %210
  %212 = bitcast i8* %125 to i32*
  %213 = load i32, i32* %212, align 4
  %214 = insertelement <4 x i32> undef, i32 %213, i32 0
  %215 = getelementptr inbounds i8, i8* %125, i64 %20
  %216 = bitcast i8* %215 to i32*
  %217 = load i32, i32* %216, align 4
  %218 = insertelement <4 x i32> %214, i32 %217, i32 1
  %219 = bitcast <4 x i32> %218 to <16 x i8>
  %220 = shufflevector <16 x i8> %219, <16 x i8> %167, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %221 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %220, <16 x i8> %171) #2
  %222 = lshr <8 x i16> %221, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %223 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %222, <8 x i16> zeroinitializer) #2
  %224 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %223, <8 x i16> zeroinitializer) #2
  %225 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %224, <16 x i8> %176) #2
  %226 = bitcast <2 x i64> %225 to <4 x i32>
  %227 = add <4 x i32> %121, %226
  %228 = shufflevector <4 x i32> %179, <4 x i32> %195, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %229 = bitcast <4 x i32> %228 to <2 x i64>
  %230 = shufflevector <4 x i32> %211, <4 x i32> %227, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %231 = bitcast <4 x i32> %230 to <2 x i64>
  %232 = shufflevector <2 x i64> %229, <2 x i64> %231, <2 x i32> <i32 0, i32 2>
  %233 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %232, <2 x i64>* %233, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad4x16x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = sext i32 %1 to i64
  %18 = sext i32 %6 to i64
  %19 = icmp ne i32 %7, 0
  %20 = sext i32 %3 to i64
  %21 = shl nsw i32 %3, 1
  %22 = sext i32 %21 to i64
  %23 = shl nsw i32 %1, 1
  %24 = sext i32 %23 to i64
  %25 = shl nsw i32 %6, 1
  %26 = sext i32 %25 to i64
  br label %27

27:                                               ; preds = %27, %9
  %28 = phi i8* [ %0, %9 ], [ %143, %27 ]
  %29 = phi i8* [ %4, %9 ], [ %144, %27 ]
  %30 = phi i8* [ %5, %9 ], [ %145, %27 ]
  %31 = phi i8* [ %16, %9 ], [ %139, %27 ]
  %32 = phi i8* [ %15, %9 ], [ %140, %27 ]
  %33 = phi i32 [ 0, %9 ], [ %146, %27 ]
  %34 = phi <4 x i32> [ zeroinitializer, %9 ], [ %138, %27 ]
  %35 = phi <4 x i32> [ zeroinitializer, %9 ], [ %122, %27 ]
  %36 = phi <4 x i32> [ zeroinitializer, %9 ], [ %106, %27 ]
  %37 = phi <4 x i32> [ zeroinitializer, %9 ], [ %90, %27 ]
  %38 = phi i8* [ %11, %9 ], [ %142, %27 ]
  %39 = phi i8* [ %13, %9 ], [ %141, %27 ]
  %40 = bitcast i8* %28 to i32*
  %41 = load i32, i32* %40, align 4
  %42 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %41, i32 0
  %43 = getelementptr inbounds i8, i8* %28, i64 %17
  %44 = bitcast i8* %43 to i32*
  %45 = load i32, i32* %44, align 4
  %46 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %45, i32 0
  %47 = shufflevector <4 x i32> %42, <4 x i32> %46, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %48 = bitcast i8* %29 to i32*
  %49 = load i32, i32* %48, align 4
  %50 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %49, i32 0
  %51 = getelementptr inbounds i8, i8* %29, i64 4
  %52 = bitcast i8* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %53, i32 0
  %55 = shufflevector <4 x i32> %50, <4 x i32> %54, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %56 = bitcast i8* %30 to i32*
  %57 = load i32, i32* %56, align 4
  %58 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %57, i32 0
  %59 = getelementptr inbounds i8, i8* %30, i64 %18
  %60 = bitcast i8* %59 to i32*
  %61 = load i32, i32* %60, align 4
  %62 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %61, i32 0
  %63 = shufflevector <4 x i32> %58, <4 x i32> %62, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %64 = bitcast <4 x i32> %63 to <2 x i64>
  %65 = bitcast <4 x i32> %63 to <16 x i8>
  %66 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %65
  %67 = bitcast <16 x i8> %66 to <2 x i64>
  %68 = select i1 %19, <2 x i64> %67, <2 x i64> %64
  %69 = select i1 %19, <2 x i64> %64, <2 x i64> %67
  %70 = bitcast i8* %31 to i32*
  %71 = load i32, i32* %70, align 4
  %72 = insertelement <4 x i32> undef, i32 %71, i32 0
  %73 = getelementptr inbounds i8, i8* %31, i64 %20
  %74 = bitcast i8* %73 to i32*
  %75 = load i32, i32* %74, align 4
  %76 = insertelement <4 x i32> %72, i32 %75, i32 1
  %77 = bitcast <4 x i32> %76 to <16 x i8>
  %78 = bitcast <4 x i32> %55 to <16 x i8>
  %79 = shufflevector <16 x i8> %77, <16 x i8> %78, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %80 = bitcast <2 x i64> %68 to <16 x i8>
  %81 = bitcast <2 x i64> %69 to <16 x i8>
  %82 = shufflevector <16 x i8> %80, <16 x i8> %81, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %83 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %79, <16 x i8> %82) #2
  %84 = lshr <8 x i16> %83, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %85 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %84, <8 x i16> zeroinitializer) #2
  %86 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %85, <8 x i16> zeroinitializer) #2
  %87 = bitcast <4 x i32> %47 to <16 x i8>
  %88 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %86, <16 x i8> %87) #2
  %89 = bitcast <2 x i64> %88 to <4 x i32>
  %90 = add <4 x i32> %37, %89
  %91 = bitcast i8* %32 to i32*
  %92 = load i32, i32* %91, align 4
  %93 = insertelement <4 x i32> undef, i32 %92, i32 0
  %94 = getelementptr inbounds i8, i8* %32, i64 %20
  %95 = bitcast i8* %94 to i32*
  %96 = load i32, i32* %95, align 4
  %97 = insertelement <4 x i32> %93, i32 %96, i32 1
  %98 = bitcast <4 x i32> %97 to <16 x i8>
  %99 = shufflevector <16 x i8> %98, <16 x i8> %78, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %100 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %99, <16 x i8> %82) #2
  %101 = lshr <8 x i16> %100, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %102 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %101, <8 x i16> zeroinitializer) #2
  %103 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %102, <8 x i16> zeroinitializer) #2
  %104 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %103, <16 x i8> %87) #2
  %105 = bitcast <2 x i64> %104 to <4 x i32>
  %106 = add <4 x i32> %36, %105
  %107 = bitcast i8* %39 to i32*
  %108 = load i32, i32* %107, align 4
  %109 = insertelement <4 x i32> undef, i32 %108, i32 0
  %110 = getelementptr inbounds i8, i8* %39, i64 %20
  %111 = bitcast i8* %110 to i32*
  %112 = load i32, i32* %111, align 4
  %113 = insertelement <4 x i32> %109, i32 %112, i32 1
  %114 = bitcast <4 x i32> %113 to <16 x i8>
  %115 = shufflevector <16 x i8> %114, <16 x i8> %78, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %116 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %115, <16 x i8> %82) #2
  %117 = lshr <8 x i16> %116, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %118 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %117, <8 x i16> zeroinitializer) #2
  %119 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> zeroinitializer) #2
  %120 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %119, <16 x i8> %87) #2
  %121 = bitcast <2 x i64> %120 to <4 x i32>
  %122 = add <4 x i32> %35, %121
  %123 = bitcast i8* %38 to i32*
  %124 = load i32, i32* %123, align 4
  %125 = insertelement <4 x i32> undef, i32 %124, i32 0
  %126 = getelementptr inbounds i8, i8* %38, i64 %20
  %127 = bitcast i8* %126 to i32*
  %128 = load i32, i32* %127, align 4
  %129 = insertelement <4 x i32> %125, i32 %128, i32 1
  %130 = bitcast <4 x i32> %129 to <16 x i8>
  %131 = shufflevector <16 x i8> %130, <16 x i8> %78, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %132 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %131, <16 x i8> %82) #2
  %133 = lshr <8 x i16> %132, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %134 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %133, <8 x i16> zeroinitializer) #2
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %134, <8 x i16> zeroinitializer) #2
  %136 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %135, <16 x i8> %87) #2
  %137 = bitcast <2 x i64> %136 to <4 x i32>
  %138 = add <4 x i32> %34, %137
  %139 = getelementptr inbounds i8, i8* %31, i64 %22
  %140 = getelementptr inbounds i8, i8* %32, i64 %22
  %141 = getelementptr inbounds i8, i8* %39, i64 %22
  %142 = getelementptr inbounds i8, i8* %38, i64 %22
  %143 = getelementptr inbounds i8, i8* %28, i64 %24
  %144 = getelementptr inbounds i8, i8* %29, i64 8
  %145 = getelementptr inbounds i8, i8* %30, i64 %26
  %146 = add nuw nsw i32 %33, 2
  %147 = icmp ult i32 %146, 16
  br i1 %147, label %27, label %148

148:                                              ; preds = %27
  %149 = shufflevector <4 x i32> %90, <4 x i32> %106, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %150 = bitcast <4 x i32> %149 to <2 x i64>
  %151 = shufflevector <4 x i32> %122, <4 x i32> %138, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %152 = bitcast <4 x i32> %151 to <2 x i64>
  %153 = shufflevector <2 x i64> %150, <2 x i64> %152, <2 x i32> <i32 0, i32 2>
  %154 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %153, <2 x i64>* %154, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad16x4x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %21, %9
  %22 = phi i8* [ %0, %9 ], [ %105, %21 ]
  %23 = phi i8* [ %4, %9 ], [ %110, %21 ]
  %24 = phi i8* [ %5, %9 ], [ %111, %21 ]
  %25 = phi i32 [ 0, %9 ], [ %112, %21 ]
  %26 = phi i8* [ %11, %9 ], [ %109, %21 ]
  %27 = phi i8* [ %13, %9 ], [ %108, %21 ]
  %28 = phi i8* [ %15, %9 ], [ %107, %21 ]
  %29 = phi i8* [ %16, %9 ], [ %106, %21 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %104, %21 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %90, %21 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %76, %21 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %62, %21 ]
  %34 = bitcast i8* %22 to <16 x i8>*
  %35 = load <16 x i8>, <16 x i8>* %34, align 1
  %36 = bitcast i8* %23 to <16 x i8>*
  %37 = load <16 x i8>, <16 x i8>* %36, align 1
  %38 = bitcast i8* %24 to <2 x i64>*
  %39 = load <2 x i64>, <2 x i64>* %38, align 1
  %40 = bitcast <2 x i64> %39 to <16 x i8>
  %41 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %40
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = select i1 %17, <2 x i64> %42, <2 x i64> %39
  %44 = select i1 %17, <2 x i64> %39, <2 x i64> %42
  %45 = bitcast i8* %29 to <16 x i8>*
  %46 = load <16 x i8>, <16 x i8>* %45, align 1
  %47 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %48 = bitcast <2 x i64> %43 to <16 x i8>
  %49 = bitcast <2 x i64> %44 to <16 x i8>
  %50 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %47, <16 x i8> %50) #2
  %52 = lshr <8 x i16> %51, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #2
  %54 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %55 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %56 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %54, <16 x i8> %55) #2
  %57 = lshr <8 x i16> %56, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %58 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %57, <8 x i16> zeroinitializer) #2
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %58) #2
  %60 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %59, <16 x i8> %35) #2
  %61 = bitcast <2 x i64> %60 to <4 x i32>
  %62 = add <4 x i32> %33, %61
  %63 = bitcast i8* %28 to <16 x i8>*
  %64 = load <16 x i8>, <16 x i8>* %63, align 1
  %65 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> %50) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %70 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %55) #2
  %71 = lshr <8 x i16> %70, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %72 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %71, <8 x i16> zeroinitializer) #2
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %68, <8 x i16> %72) #2
  %74 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %73, <16 x i8> %35) #2
  %75 = bitcast <2 x i64> %74 to <4 x i32>
  %76 = add <4 x i32> %32, %75
  %77 = bitcast i8* %27 to <16 x i8>*
  %78 = load <16 x i8>, <16 x i8>* %77, align 1
  %79 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %80 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %79, <16 x i8> %50) #2
  %81 = lshr <8 x i16> %80, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %82 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %81, <8 x i16> zeroinitializer) #2
  %83 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %84 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %83, <16 x i8> %55) #2
  %85 = lshr <8 x i16> %84, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %86 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %85, <8 x i16> zeroinitializer) #2
  %87 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %82, <8 x i16> %86) #2
  %88 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %87, <16 x i8> %35) #2
  %89 = bitcast <2 x i64> %88 to <4 x i32>
  %90 = add <4 x i32> %31, %89
  %91 = bitcast i8* %26 to <16 x i8>*
  %92 = load <16 x i8>, <16 x i8>* %91, align 1
  %93 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %94 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %93, <16 x i8> %50) #2
  %95 = lshr <8 x i16> %94, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %96 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %95, <8 x i16> zeroinitializer) #2
  %97 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %98 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %97, <16 x i8> %55) #2
  %99 = lshr <8 x i16> %98, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #2
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %96, <8 x i16> %100) #2
  %102 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %101, <16 x i8> %35) #2
  %103 = bitcast <2 x i64> %102 to <4 x i32>
  %104 = add <4 x i32> %30, %103
  %105 = getelementptr inbounds i8, i8* %22, i64 %18
  %106 = getelementptr inbounds i8, i8* %29, i64 %19
  %107 = getelementptr inbounds i8, i8* %28, i64 %19
  %108 = getelementptr inbounds i8, i8* %27, i64 %19
  %109 = getelementptr inbounds i8, i8* %26, i64 %19
  %110 = getelementptr inbounds i8, i8* %23, i64 16
  %111 = getelementptr inbounds i8, i8* %24, i64 %20
  %112 = add nuw nsw i32 %25, 1
  %113 = icmp eq i32 %112, 4
  br i1 %113, label %114, label %21

114:                                              ; preds = %21
  %115 = shufflevector <4 x i32> %62, <4 x i32> %76, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %116 = shufflevector <4 x i32> %62, <4 x i32> %76, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %117 = add <4 x i32> %116, %115
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = shufflevector <4 x i32> %90, <4 x i32> %104, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %120 = shufflevector <4 x i32> %90, <4 x i32> %104, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %121 = add <4 x i32> %120, %119
  %122 = bitcast <4 x i32> %121 to <2 x i64>
  %123 = shufflevector <2 x i64> %118, <2 x i64> %122, <2 x i32> <i32 0, i32 2>
  %124 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %123, <2 x i64>* %124, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad8x32x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = sext i32 %1 to i64
  %18 = sext i32 %6 to i64
  %19 = icmp ne i32 %7, 0
  %20 = sext i32 %3 to i64
  %21 = shl nsw i32 %3, 1
  %22 = sext i32 %21 to i64
  %23 = shl nsw i32 %1, 1
  %24 = sext i32 %23 to i64
  %25 = shl nsw i32 %6, 1
  %26 = sext i32 %25 to i64
  br label %27

27:                                               ; preds = %27, %9
  %28 = phi i8* [ %0, %9 ], [ %161, %27 ]
  %29 = phi i8* [ %4, %9 ], [ %162, %27 ]
  %30 = phi i8* [ %5, %9 ], [ %163, %27 ]
  %31 = phi i8* [ %16, %9 ], [ %157, %27 ]
  %32 = phi i8* [ %15, %9 ], [ %158, %27 ]
  %33 = phi i8* [ %13, %9 ], [ %159, %27 ]
  %34 = phi i8* [ %11, %9 ], [ %160, %27 ]
  %35 = phi <4 x i32> [ zeroinitializer, %9 ], [ %93, %27 ]
  %36 = phi <4 x i32> [ zeroinitializer, %9 ], [ %114, %27 ]
  %37 = phi i32 [ 0, %9 ], [ %164, %27 ]
  %38 = phi <4 x i32> [ zeroinitializer, %9 ], [ %156, %27 ]
  %39 = phi <4 x i32> [ zeroinitializer, %9 ], [ %135, %27 ]
  %40 = bitcast i8* %28 to i64*
  %41 = load i64, i64* %40, align 1
  %42 = insertelement <2 x i64> undef, i64 %41, i32 0
  %43 = getelementptr inbounds i8, i8* %28, i64 %17
  %44 = bitcast i8* %43 to i64*
  %45 = load i64, i64* %44, align 1
  %46 = insertelement <2 x i64> %42, i64 %45, i32 1
  %47 = bitcast i8* %29 to i64*
  %48 = load i64, i64* %47, align 1
  %49 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %48, i32 0
  %50 = getelementptr inbounds i8, i8* %29, i64 8
  %51 = bitcast i8* %50 to i64*
  %52 = load i64, i64* %51, align 1
  %53 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %52, i32 0
  %54 = bitcast i8* %30 to i64*
  %55 = load i64, i64* %54, align 1
  %56 = insertelement <2 x i64> undef, i64 %55, i32 0
  %57 = getelementptr inbounds i8, i8* %30, i64 %18
  %58 = bitcast i8* %57 to i64*
  %59 = load i64, i64* %58, align 1
  %60 = insertelement <2 x i64> %56, i64 %59, i32 1
  %61 = bitcast <2 x i64> %60 to <16 x i8>
  %62 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %61
  %63 = bitcast <16 x i8> %62 to <2 x i64>
  %64 = select i1 %19, <2 x i64> %63, <2 x i64> %60
  %65 = select i1 %19, <2 x i64> %60, <2 x i64> %63
  %66 = bitcast i8* %31 to i64*
  %67 = load i64, i64* %66, align 1
  %68 = insertelement <2 x i64> undef, i64 %67, i32 0
  %69 = getelementptr inbounds i8, i8* %31, i64 %20
  %70 = bitcast i8* %69 to i64*
  %71 = load i64, i64* %70, align 1
  %72 = insertelement <2 x i64> undef, i64 %71, i32 0
  %73 = bitcast <2 x i64> %68 to <16 x i8>
  %74 = bitcast <2 x i64> %49 to <16 x i8>
  %75 = shufflevector <16 x i8> %73, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %76 = bitcast <2 x i64> %64 to <16 x i8>
  %77 = bitcast <2 x i64> %65 to <16 x i8>
  %78 = shufflevector <16 x i8> %76, <16 x i8> %77, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %75, <16 x i8> %78) #2
  %80 = lshr <8 x i16> %79, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %81 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %80, <8 x i16> zeroinitializer) #2
  %82 = bitcast <2 x i64> %72 to <16 x i8>
  %83 = bitcast <2 x i64> %53 to <16 x i8>
  %84 = shufflevector <16 x i8> %82, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %85 = shufflevector <16 x i8> %76, <16 x i8> %77, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %86 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %84, <16 x i8> %85) #2
  %87 = lshr <8 x i16> %86, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %88 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %87, <8 x i16> zeroinitializer) #2
  %89 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> %88) #2
  %90 = bitcast <2 x i64> %46 to <16 x i8>
  %91 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %89, <16 x i8> %90) #2
  %92 = bitcast <2 x i64> %91 to <4 x i32>
  %93 = add <4 x i32> %35, %92
  %94 = bitcast i8* %32 to i64*
  %95 = load i64, i64* %94, align 1
  %96 = insertelement <2 x i64> undef, i64 %95, i32 0
  %97 = getelementptr inbounds i8, i8* %32, i64 %20
  %98 = bitcast i8* %97 to i64*
  %99 = load i64, i64* %98, align 1
  %100 = insertelement <2 x i64> undef, i64 %99, i32 0
  %101 = bitcast <2 x i64> %96 to <16 x i8>
  %102 = shufflevector <16 x i8> %101, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %103 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %102, <16 x i8> %78) #2
  %104 = lshr <8 x i16> %103, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %105 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %104, <8 x i16> zeroinitializer) #2
  %106 = bitcast <2 x i64> %100 to <16 x i8>
  %107 = shufflevector <16 x i8> %106, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %108 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %107, <16 x i8> %85) #2
  %109 = lshr <8 x i16> %108, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %110 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %109, <8 x i16> zeroinitializer) #2
  %111 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %105, <8 x i16> %110) #2
  %112 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %111, <16 x i8> %90) #2
  %113 = bitcast <2 x i64> %112 to <4 x i32>
  %114 = add <4 x i32> %36, %113
  %115 = bitcast i8* %33 to i64*
  %116 = load i64, i64* %115, align 1
  %117 = insertelement <2 x i64> undef, i64 %116, i32 0
  %118 = getelementptr inbounds i8, i8* %33, i64 %20
  %119 = bitcast i8* %118 to i64*
  %120 = load i64, i64* %119, align 1
  %121 = insertelement <2 x i64> undef, i64 %120, i32 0
  %122 = bitcast <2 x i64> %117 to <16 x i8>
  %123 = shufflevector <16 x i8> %122, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %124 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %123, <16 x i8> %78) #2
  %125 = lshr <8 x i16> %124, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %126 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %125, <8 x i16> zeroinitializer) #2
  %127 = bitcast <2 x i64> %121 to <16 x i8>
  %128 = shufflevector <16 x i8> %127, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %129 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %128, <16 x i8> %85) #2
  %130 = lshr <8 x i16> %129, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %131 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %130, <8 x i16> zeroinitializer) #2
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %126, <8 x i16> %131) #2
  %133 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %132, <16 x i8> %90) #2
  %134 = bitcast <2 x i64> %133 to <4 x i32>
  %135 = add <4 x i32> %39, %134
  %136 = bitcast i8* %34 to i64*
  %137 = load i64, i64* %136, align 1
  %138 = insertelement <2 x i64> undef, i64 %137, i32 0
  %139 = getelementptr inbounds i8, i8* %34, i64 %20
  %140 = bitcast i8* %139 to i64*
  %141 = load i64, i64* %140, align 1
  %142 = insertelement <2 x i64> undef, i64 %141, i32 0
  %143 = bitcast <2 x i64> %138 to <16 x i8>
  %144 = shufflevector <16 x i8> %143, <16 x i8> %74, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %145 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %144, <16 x i8> %78) #2
  %146 = lshr <8 x i16> %145, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %147 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %146, <8 x i16> zeroinitializer) #2
  %148 = bitcast <2 x i64> %142 to <16 x i8>
  %149 = shufflevector <16 x i8> %148, <16 x i8> %83, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %150 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %149, <16 x i8> %85) #2
  %151 = lshr <8 x i16> %150, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %152 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %151, <8 x i16> zeroinitializer) #2
  %153 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %147, <8 x i16> %152) #2
  %154 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %153, <16 x i8> %90) #2
  %155 = bitcast <2 x i64> %154 to <4 x i32>
  %156 = add <4 x i32> %38, %155
  %157 = getelementptr inbounds i8, i8* %31, i64 %22
  %158 = getelementptr inbounds i8, i8* %32, i64 %22
  %159 = getelementptr inbounds i8, i8* %33, i64 %22
  %160 = getelementptr inbounds i8, i8* %34, i64 %22
  %161 = getelementptr inbounds i8, i8* %28, i64 %24
  %162 = getelementptr inbounds i8, i8* %29, i64 16
  %163 = getelementptr inbounds i8, i8* %30, i64 %26
  %164 = add nuw nsw i32 %37, 2
  %165 = icmp ult i32 %164, 32
  br i1 %165, label %27, label %166

166:                                              ; preds = %27
  %167 = shufflevector <4 x i32> %93, <4 x i32> %114, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %168 = shufflevector <4 x i32> %93, <4 x i32> %114, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %169 = add <4 x i32> %168, %167
  %170 = bitcast <4 x i32> %169 to <2 x i64>
  %171 = shufflevector <4 x i32> %135, <4 x i32> %156, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %172 = shufflevector <4 x i32> %135, <4 x i32> %156, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %173 = add <4 x i32> %172, %171
  %174 = bitcast <4 x i32> %173 to <2 x i64>
  %175 = shufflevector <2 x i64> %170, <2 x i64> %174, <2 x i32> <i32 0, i32 2>
  %176 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %175, <2 x i64>* %176, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad32x8x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %21, %9
  %22 = phi i8* [ %0, %9 ], [ %183, %21 ]
  %23 = phi i8* [ %4, %9 ], [ %188, %21 ]
  %24 = phi i8* [ %5, %9 ], [ %189, %21 ]
  %25 = phi i32 [ 0, %9 ], [ %190, %21 ]
  %26 = phi i8* [ %11, %9 ], [ %187, %21 ]
  %27 = phi i8* [ %13, %9 ], [ %186, %21 ]
  %28 = phi i8* [ %15, %9 ], [ %185, %21 ]
  %29 = phi i8* [ %16, %9 ], [ %184, %21 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %182, %21 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %167, %21 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %152, %21 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %137, %21 ]
  %34 = bitcast i8* %22 to <16 x i8>*
  %35 = load <16 x i8>, <16 x i8>* %34, align 1
  %36 = bitcast i8* %23 to <16 x i8>*
  %37 = load <16 x i8>, <16 x i8>* %36, align 1
  %38 = bitcast i8* %24 to <2 x i64>*
  %39 = load <2 x i64>, <2 x i64>* %38, align 1
  %40 = bitcast <2 x i64> %39 to <16 x i8>
  %41 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %40
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = select i1 %17, <2 x i64> %42, <2 x i64> %39
  %44 = select i1 %17, <2 x i64> %39, <2 x i64> %42
  %45 = bitcast i8* %29 to <16 x i8>*
  %46 = load <16 x i8>, <16 x i8>* %45, align 1
  %47 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %48 = bitcast <2 x i64> %43 to <16 x i8>
  %49 = bitcast <2 x i64> %44 to <16 x i8>
  %50 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %47, <16 x i8> %50) #2
  %52 = lshr <8 x i16> %51, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #2
  %54 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %55 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %56 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %54, <16 x i8> %55) #2
  %57 = lshr <8 x i16> %56, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %58 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %57, <8 x i16> zeroinitializer) #2
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %58) #2
  %60 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %59, <16 x i8> %35) #2
  %61 = bitcast <2 x i64> %60 to <4 x i32>
  %62 = add <4 x i32> %33, %61
  %63 = bitcast i8* %28 to <16 x i8>*
  %64 = load <16 x i8>, <16 x i8>* %63, align 1
  %65 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> %50) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %70 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %55) #2
  %71 = lshr <8 x i16> %70, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %72 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %71, <8 x i16> zeroinitializer) #2
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %68, <8 x i16> %72) #2
  %74 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %73, <16 x i8> %35) #2
  %75 = bitcast <2 x i64> %74 to <4 x i32>
  %76 = add <4 x i32> %32, %75
  %77 = bitcast i8* %27 to <16 x i8>*
  %78 = load <16 x i8>, <16 x i8>* %77, align 1
  %79 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %80 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %79, <16 x i8> %50) #2
  %81 = lshr <8 x i16> %80, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %82 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %81, <8 x i16> zeroinitializer) #2
  %83 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %84 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %83, <16 x i8> %55) #2
  %85 = lshr <8 x i16> %84, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %86 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %85, <8 x i16> zeroinitializer) #2
  %87 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %82, <8 x i16> %86) #2
  %88 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %87, <16 x i8> %35) #2
  %89 = bitcast <2 x i64> %88 to <4 x i32>
  %90 = add <4 x i32> %31, %89
  %91 = bitcast i8* %26 to <16 x i8>*
  %92 = load <16 x i8>, <16 x i8>* %91, align 1
  %93 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %94 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %93, <16 x i8> %50) #2
  %95 = lshr <8 x i16> %94, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %96 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %95, <8 x i16> zeroinitializer) #2
  %97 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %98 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %97, <16 x i8> %55) #2
  %99 = lshr <8 x i16> %98, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #2
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %96, <8 x i16> %100) #2
  %102 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %101, <16 x i8> %35) #2
  %103 = bitcast <2 x i64> %102 to <4 x i32>
  %104 = add <4 x i32> %30, %103
  %105 = getelementptr inbounds i8, i8* %22, i64 16
  %106 = bitcast i8* %105 to <16 x i8>*
  %107 = load <16 x i8>, <16 x i8>* %106, align 1
  %108 = getelementptr inbounds i8, i8* %23, i64 16
  %109 = bitcast i8* %108 to <16 x i8>*
  %110 = load <16 x i8>, <16 x i8>* %109, align 1
  %111 = getelementptr inbounds i8, i8* %24, i64 16
  %112 = bitcast i8* %111 to <2 x i64>*
  %113 = load <2 x i64>, <2 x i64>* %112, align 1
  %114 = bitcast <2 x i64> %113 to <16 x i8>
  %115 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %114
  %116 = bitcast <16 x i8> %115 to <2 x i64>
  %117 = select i1 %17, <2 x i64> %116, <2 x i64> %113
  %118 = select i1 %17, <2 x i64> %113, <2 x i64> %116
  %119 = getelementptr inbounds i8, i8* %29, i64 16
  %120 = bitcast i8* %119 to <16 x i8>*
  %121 = load <16 x i8>, <16 x i8>* %120, align 1
  %122 = shufflevector <16 x i8> %121, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %123 = bitcast <2 x i64> %117 to <16 x i8>
  %124 = bitcast <2 x i64> %118 to <16 x i8>
  %125 = shufflevector <16 x i8> %123, <16 x i8> %124, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %126 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %122, <16 x i8> %125) #2
  %127 = lshr <8 x i16> %126, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %128 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %127, <8 x i16> zeroinitializer) #2
  %129 = shufflevector <16 x i8> %121, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %130 = shufflevector <16 x i8> %123, <16 x i8> %124, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %131 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %129, <16 x i8> %130) #2
  %132 = lshr <8 x i16> %131, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #2
  %134 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %128, <8 x i16> %133) #2
  %135 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %134, <16 x i8> %107) #2
  %136 = bitcast <2 x i64> %135 to <4 x i32>
  %137 = add <4 x i32> %62, %136
  %138 = getelementptr inbounds i8, i8* %28, i64 16
  %139 = bitcast i8* %138 to <16 x i8>*
  %140 = load <16 x i8>, <16 x i8>* %139, align 1
  %141 = shufflevector <16 x i8> %140, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %142 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %141, <16 x i8> %125) #2
  %143 = lshr <8 x i16> %142, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %144 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %143, <8 x i16> zeroinitializer) #2
  %145 = shufflevector <16 x i8> %140, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %146 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %145, <16 x i8> %130) #2
  %147 = lshr <8 x i16> %146, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %148 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %147, <8 x i16> zeroinitializer) #2
  %149 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %144, <8 x i16> %148) #2
  %150 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %149, <16 x i8> %107) #2
  %151 = bitcast <2 x i64> %150 to <4 x i32>
  %152 = add <4 x i32> %76, %151
  %153 = getelementptr inbounds i8, i8* %27, i64 16
  %154 = bitcast i8* %153 to <16 x i8>*
  %155 = load <16 x i8>, <16 x i8>* %154, align 1
  %156 = shufflevector <16 x i8> %155, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %157 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %156, <16 x i8> %125) #2
  %158 = lshr <8 x i16> %157, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %159 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %158, <8 x i16> zeroinitializer) #2
  %160 = shufflevector <16 x i8> %155, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %161 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %160, <16 x i8> %130) #2
  %162 = lshr <8 x i16> %161, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %163 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %162, <8 x i16> zeroinitializer) #2
  %164 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %159, <8 x i16> %163) #2
  %165 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %164, <16 x i8> %107) #2
  %166 = bitcast <2 x i64> %165 to <4 x i32>
  %167 = add <4 x i32> %90, %166
  %168 = getelementptr inbounds i8, i8* %26, i64 16
  %169 = bitcast i8* %168 to <16 x i8>*
  %170 = load <16 x i8>, <16 x i8>* %169, align 1
  %171 = shufflevector <16 x i8> %170, <16 x i8> %110, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %172 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %171, <16 x i8> %125) #2
  %173 = lshr <8 x i16> %172, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %174 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %173, <8 x i16> zeroinitializer) #2
  %175 = shufflevector <16 x i8> %170, <16 x i8> %110, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %176 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %175, <16 x i8> %130) #2
  %177 = lshr <8 x i16> %176, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %178 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %177, <8 x i16> zeroinitializer) #2
  %179 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %174, <8 x i16> %178) #2
  %180 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %179, <16 x i8> %107) #2
  %181 = bitcast <2 x i64> %180 to <4 x i32>
  %182 = add <4 x i32> %104, %181
  %183 = getelementptr inbounds i8, i8* %22, i64 %18
  %184 = getelementptr inbounds i8, i8* %29, i64 %19
  %185 = getelementptr inbounds i8, i8* %28, i64 %19
  %186 = getelementptr inbounds i8, i8* %27, i64 %19
  %187 = getelementptr inbounds i8, i8* %26, i64 %19
  %188 = getelementptr inbounds i8, i8* %23, i64 32
  %189 = getelementptr inbounds i8, i8* %24, i64 %20
  %190 = add nuw nsw i32 %25, 1
  %191 = icmp eq i32 %190, 8
  br i1 %191, label %192, label %21

192:                                              ; preds = %21
  %193 = shufflevector <4 x i32> %137, <4 x i32> %152, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %194 = shufflevector <4 x i32> %137, <4 x i32> %152, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %195 = add <4 x i32> %194, %193
  %196 = bitcast <4 x i32> %195 to <2 x i64>
  %197 = shufflevector <4 x i32> %167, <4 x i32> %182, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %198 = shufflevector <4 x i32> %167, <4 x i32> %182, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %199 = add <4 x i32> %198, %197
  %200 = bitcast <4 x i32> %199 to <2 x i64>
  %201 = shufflevector <2 x i64> %196, <2 x i64> %200, <2 x i32> <i32 0, i32 2>
  %202 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %201, <2 x i64>* %202, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad16x64x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %21, %9
  %22 = phi i8* [ %0, %9 ], [ %105, %21 ]
  %23 = phi i8* [ %4, %9 ], [ %110, %21 ]
  %24 = phi i8* [ %5, %9 ], [ %111, %21 ]
  %25 = phi i32 [ 0, %9 ], [ %112, %21 ]
  %26 = phi i8* [ %11, %9 ], [ %109, %21 ]
  %27 = phi i8* [ %13, %9 ], [ %108, %21 ]
  %28 = phi i8* [ %15, %9 ], [ %107, %21 ]
  %29 = phi i8* [ %16, %9 ], [ %106, %21 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %104, %21 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %90, %21 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %76, %21 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %62, %21 ]
  %34 = bitcast i8* %22 to <16 x i8>*
  %35 = load <16 x i8>, <16 x i8>* %34, align 1
  %36 = bitcast i8* %23 to <16 x i8>*
  %37 = load <16 x i8>, <16 x i8>* %36, align 1
  %38 = bitcast i8* %24 to <2 x i64>*
  %39 = load <2 x i64>, <2 x i64>* %38, align 1
  %40 = bitcast <2 x i64> %39 to <16 x i8>
  %41 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %40
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = select i1 %17, <2 x i64> %42, <2 x i64> %39
  %44 = select i1 %17, <2 x i64> %39, <2 x i64> %42
  %45 = bitcast i8* %29 to <16 x i8>*
  %46 = load <16 x i8>, <16 x i8>* %45, align 1
  %47 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %48 = bitcast <2 x i64> %43 to <16 x i8>
  %49 = bitcast <2 x i64> %44 to <16 x i8>
  %50 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %47, <16 x i8> %50) #2
  %52 = lshr <8 x i16> %51, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #2
  %54 = shufflevector <16 x i8> %46, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %55 = shufflevector <16 x i8> %48, <16 x i8> %49, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %56 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %54, <16 x i8> %55) #2
  %57 = lshr <8 x i16> %56, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %58 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %57, <8 x i16> zeroinitializer) #2
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %58) #2
  %60 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %59, <16 x i8> %35) #2
  %61 = bitcast <2 x i64> %60 to <4 x i32>
  %62 = add <4 x i32> %33, %61
  %63 = bitcast i8* %28 to <16 x i8>*
  %64 = load <16 x i8>, <16 x i8>* %63, align 1
  %65 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> %50) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = shufflevector <16 x i8> %64, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %70 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %55) #2
  %71 = lshr <8 x i16> %70, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %72 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %71, <8 x i16> zeroinitializer) #2
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %68, <8 x i16> %72) #2
  %74 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %73, <16 x i8> %35) #2
  %75 = bitcast <2 x i64> %74 to <4 x i32>
  %76 = add <4 x i32> %32, %75
  %77 = bitcast i8* %27 to <16 x i8>*
  %78 = load <16 x i8>, <16 x i8>* %77, align 1
  %79 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %80 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %79, <16 x i8> %50) #2
  %81 = lshr <8 x i16> %80, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %82 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %81, <8 x i16> zeroinitializer) #2
  %83 = shufflevector <16 x i8> %78, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %84 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %83, <16 x i8> %55) #2
  %85 = lshr <8 x i16> %84, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %86 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %85, <8 x i16> zeroinitializer) #2
  %87 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %82, <8 x i16> %86) #2
  %88 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %87, <16 x i8> %35) #2
  %89 = bitcast <2 x i64> %88 to <4 x i32>
  %90 = add <4 x i32> %31, %89
  %91 = bitcast i8* %26 to <16 x i8>*
  %92 = load <16 x i8>, <16 x i8>* %91, align 1
  %93 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %94 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %93, <16 x i8> %50) #2
  %95 = lshr <8 x i16> %94, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %96 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %95, <8 x i16> zeroinitializer) #2
  %97 = shufflevector <16 x i8> %92, <16 x i8> %37, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %98 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %97, <16 x i8> %55) #2
  %99 = lshr <8 x i16> %98, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #2
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %96, <8 x i16> %100) #2
  %102 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %101, <16 x i8> %35) #2
  %103 = bitcast <2 x i64> %102 to <4 x i32>
  %104 = add <4 x i32> %30, %103
  %105 = getelementptr inbounds i8, i8* %22, i64 %18
  %106 = getelementptr inbounds i8, i8* %29, i64 %19
  %107 = getelementptr inbounds i8, i8* %28, i64 %19
  %108 = getelementptr inbounds i8, i8* %27, i64 %19
  %109 = getelementptr inbounds i8, i8* %26, i64 %19
  %110 = getelementptr inbounds i8, i8* %23, i64 16
  %111 = getelementptr inbounds i8, i8* %24, i64 %20
  %112 = add nuw nsw i32 %25, 1
  %113 = icmp eq i32 %112, 64
  br i1 %113, label %114, label %21

114:                                              ; preds = %21
  %115 = shufflevector <4 x i32> %62, <4 x i32> %76, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %116 = shufflevector <4 x i32> %62, <4 x i32> %76, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %117 = add <4 x i32> %116, %115
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = shufflevector <4 x i32> %90, <4 x i32> %104, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %120 = shufflevector <4 x i32> %90, <4 x i32> %104, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %121 = add <4 x i32> %120, %119
  %122 = bitcast <4 x i32> %121 to <2 x i64>
  %123 = shufflevector <2 x i64> %118, <2 x i64> %122, <2 x i32> <i32 0, i32 2>
  %124 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %123, <2 x i64>* %124, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @aom_masked_sad64x16x4d_ssse3(i8* nocapture readonly, i32, i8** nocapture readonly, i32, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32* nocapture) local_unnamed_addr #0 {
  %10 = getelementptr inbounds i8*, i8** %2, i64 3
  %11 = load i8*, i8** %10, align 8
  %12 = getelementptr inbounds i8*, i8** %2, i64 2
  %13 = load i8*, i8** %12, align 8
  %14 = getelementptr inbounds i8*, i8** %2, i64 1
  %15 = load i8*, i8** %14, align 8
  %16 = load i8*, i8** %2, align 8
  %17 = icmp ne i32 %7, 0
  %18 = sext i32 %1 to i64
  %19 = sext i32 %3 to i64
  %20 = sext i32 %6 to i64
  br label %21

21:                                               ; preds = %120, %9
  %22 = phi i8* [ %0, %9 ], [ %121, %120 ]
  %23 = phi i8* [ %4, %9 ], [ %126, %120 ]
  %24 = phi i8* [ %5, %9 ], [ %127, %120 ]
  %25 = phi i32 [ 0, %9 ], [ %128, %120 ]
  %26 = phi i8* [ %11, %9 ], [ %125, %120 ]
  %27 = phi i8* [ %13, %9 ], [ %124, %120 ]
  %28 = phi i8* [ %15, %9 ], [ %123, %120 ]
  %29 = phi i8* [ %16, %9 ], [ %122, %120 ]
  %30 = phi <4 x i32> [ zeroinitializer, %9 ], [ %117, %120 ]
  %31 = phi <4 x i32> [ zeroinitializer, %9 ], [ %102, %120 ]
  %32 = phi <4 x i32> [ zeroinitializer, %9 ], [ %87, %120 ]
  %33 = phi <4 x i32> [ zeroinitializer, %9 ], [ %72, %120 ]
  br label %34

34:                                               ; preds = %34, %21
  %35 = phi i64 [ %118, %34 ], [ 0, %21 ]
  %36 = phi <4 x i32> [ %117, %34 ], [ %30, %21 ]
  %37 = phi <4 x i32> [ %102, %34 ], [ %31, %21 ]
  %38 = phi <4 x i32> [ %87, %34 ], [ %32, %21 ]
  %39 = phi <4 x i32> [ %72, %34 ], [ %33, %21 ]
  %40 = getelementptr inbounds i8, i8* %22, i64 %35
  %41 = bitcast i8* %40 to <16 x i8>*
  %42 = load <16 x i8>, <16 x i8>* %41, align 1
  %43 = getelementptr inbounds i8, i8* %23, i64 %35
  %44 = bitcast i8* %43 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 1
  %46 = getelementptr inbounds i8, i8* %24, i64 %35
  %47 = bitcast i8* %46 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 1
  %49 = bitcast <2 x i64> %48 to <16 x i8>
  %50 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %49
  %51 = bitcast <16 x i8> %50 to <2 x i64>
  %52 = select i1 %17, <2 x i64> %51, <2 x i64> %48
  %53 = select i1 %17, <2 x i64> %48, <2 x i64> %51
  %54 = getelementptr inbounds i8, i8* %29, i64 %35
  %55 = bitcast i8* %54 to <16 x i8>*
  %56 = load <16 x i8>, <16 x i8>* %55, align 1
  %57 = shufflevector <16 x i8> %56, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %58 = bitcast <2 x i64> %52 to <16 x i8>
  %59 = bitcast <2 x i64> %53 to <16 x i8>
  %60 = shufflevector <16 x i8> %58, <16 x i8> %59, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %61 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %57, <16 x i8> %60) #2
  %62 = lshr <8 x i16> %61, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %63 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %62, <8 x i16> zeroinitializer) #2
  %64 = shufflevector <16 x i8> %56, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %65 = shufflevector <16 x i8> %58, <16 x i8> %59, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %64, <16 x i8> %65) #2
  %67 = lshr <8 x i16> %66, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #2
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %63, <8 x i16> %68) #2
  %70 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %69, <16 x i8> %42) #2
  %71 = bitcast <2 x i64> %70 to <4 x i32>
  %72 = add <4 x i32> %39, %71
  %73 = getelementptr inbounds i8, i8* %28, i64 %35
  %74 = bitcast i8* %73 to <16 x i8>*
  %75 = load <16 x i8>, <16 x i8>* %74, align 1
  %76 = shufflevector <16 x i8> %75, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %77 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %76, <16 x i8> %60) #2
  %78 = lshr <8 x i16> %77, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %79 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %78, <8 x i16> zeroinitializer) #2
  %80 = shufflevector <16 x i8> %75, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %81 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %80, <16 x i8> %65) #2
  %82 = lshr <8 x i16> %81, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %83 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %82, <8 x i16> zeroinitializer) #2
  %84 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> %83) #2
  %85 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %84, <16 x i8> %42) #2
  %86 = bitcast <2 x i64> %85 to <4 x i32>
  %87 = add <4 x i32> %38, %86
  %88 = getelementptr inbounds i8, i8* %27, i64 %35
  %89 = bitcast i8* %88 to <16 x i8>*
  %90 = load <16 x i8>, <16 x i8>* %89, align 1
  %91 = shufflevector <16 x i8> %90, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %92 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %91, <16 x i8> %60) #2
  %93 = lshr <8 x i16> %92, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %94 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %93, <8 x i16> zeroinitializer) #2
  %95 = shufflevector <16 x i8> %90, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %96 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %95, <16 x i8> %65) #2
  %97 = lshr <8 x i16> %96, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #2
  %99 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %94, <8 x i16> %98) #2
  %100 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %99, <16 x i8> %42) #2
  %101 = bitcast <2 x i64> %100 to <4 x i32>
  %102 = add <4 x i32> %37, %101
  %103 = getelementptr inbounds i8, i8* %26, i64 %35
  %104 = bitcast i8* %103 to <16 x i8>*
  %105 = load <16 x i8>, <16 x i8>* %104, align 1
  %106 = shufflevector <16 x i8> %105, <16 x i8> %45, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %107 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %106, <16 x i8> %60) #2
  %108 = lshr <8 x i16> %107, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %109 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %108, <8 x i16> zeroinitializer) #2
  %110 = shufflevector <16 x i8> %105, <16 x i8> %45, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %111 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %110, <16 x i8> %65) #2
  %112 = lshr <8 x i16> %111, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %113 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %112, <8 x i16> zeroinitializer) #2
  %114 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> %113) #2
  %115 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %114, <16 x i8> %42) #2
  %116 = bitcast <2 x i64> %115 to <4 x i32>
  %117 = add <4 x i32> %36, %116
  %118 = add nuw nsw i64 %35, 16
  %119 = icmp ult i64 %118, 64
  br i1 %119, label %34, label %120

120:                                              ; preds = %34
  %121 = getelementptr inbounds i8, i8* %22, i64 %18
  %122 = getelementptr inbounds i8, i8* %29, i64 %19
  %123 = getelementptr inbounds i8, i8* %28, i64 %19
  %124 = getelementptr inbounds i8, i8* %27, i64 %19
  %125 = getelementptr inbounds i8, i8* %26, i64 %19
  %126 = getelementptr inbounds i8, i8* %23, i64 64
  %127 = getelementptr inbounds i8, i8* %24, i64 %20
  %128 = add nuw nsw i32 %25, 1
  %129 = icmp eq i32 %128, 16
  br i1 %129, label %130, label %21

130:                                              ; preds = %120
  %131 = shufflevector <4 x i32> %72, <4 x i32> %87, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %132 = shufflevector <4 x i32> %72, <4 x i32> %87, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %133 = add <4 x i32> %132, %131
  %134 = bitcast <4 x i32> %133 to <2 x i64>
  %135 = shufflevector <4 x i32> %102, <4 x i32> %117, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %136 = shufflevector <4 x i32> %102, <4 x i32> %117, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %137 = add <4 x i32> %136, %135
  %138 = bitcast <4 x i32> %137 to <2 x i64>
  %139 = shufflevector <2 x i64> %134, <2 x i64> %138, <2 x i32> <i32 0, i32 2>
  %140 = bitcast i32* %8 to <2 x i64>*
  store <2 x i64> %139, <2 x i64>* %140, align 1
  ret void
}

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8>, <16 x i8>) #1

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16>, <8 x i16>) #1

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #1

; Function Attrs: nounwind readnone
declare <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8>, <16 x i8>) #1

attributes #0 = { nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind readnone }
attributes #2 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
