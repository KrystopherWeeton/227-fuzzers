; ModuleID = '../../third_party/libaom/source/libaom/av1/common/x86/highbd_inv_txfm_sse4.c'
source_filename = "../../third_party/libaom/source/libaom/av1/common/x86/highbd_inv_txfm_sse4.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%struct.txfm_param = type { i8, i8, i32, i32, i32, i8, i32 }

@av1_inv_txfm_shift_ls = external local_unnamed_addr global [19 x i8*], align 16
@av1_inv_cos_bit_row = external local_unnamed_addr constant [5 x [5 x i8]], align 16
@av1_inv_cos_bit_col = external local_unnamed_addr constant [5 x [5 x i8]], align 16
@tx_size_wide_log2 = internal unnamed_addr constant [19 x i32] [i32 2, i32 3, i32 4, i32 5, i32 6, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 2, i32 4, i32 3, i32 5, i32 4, i32 6], align 16
@tx_size_high_log2 = internal unnamed_addr constant [19 x i32] [i32 2, i32 3, i32 4, i32 5, i32 6, i32 3, i32 2, i32 4, i32 3, i32 5, i32 4, i32 6, i32 5, i32 4, i32 2, i32 5, i32 3, i32 6, i32 4], align 16
@av1_cospi_arr_data = external local_unnamed_addr constant [7 x [64 x i32]], align 16
@av1_sinpi_arr_data = external local_unnamed_addr constant [7 x [5 x i32]], align 16
@tx_size_wide = internal unnamed_addr constant [19 x i32] [i32 4, i32 8, i32 16, i32 32, i32 64, i32 4, i32 8, i32 8, i32 16, i32 16, i32 32, i32 32, i32 64, i32 4, i32 16, i32 8, i32 32, i32 16, i32 64], align 16
@tx_size_high = internal unnamed_addr constant [19 x i32] [i32 4, i32 8, i32 16, i32 32, i32 64, i32 8, i32 4, i32 16, i32 8, i32 32, i32 16, i32 64, i32 32, i32 16, i32 4, i32 32, i32 8, i32 64, i32 16], align 16
@lowbd_txfm_all_1d_zeros_idx = internal unnamed_addr constant [32 x i32] [i32 0, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3], align 16
@highbd_txfm_all_1d_zeros_w8_arr = internal unnamed_addr constant [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]] [[3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]] [[4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] [void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct4x4_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null], [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] [void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iadst4x4_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null], [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] [void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iidentity4_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iidentity4_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iidentity4_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null]], [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]] [[4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] [void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct8x8_low1_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct8x8_new_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null], [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] [void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iadst8x8_low1_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iadst8x8_new_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null], [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] [void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iidentity8_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iidentity8_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null]], [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]] [[4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] [void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct16x16_low1_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct16x16_low8_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct16x16_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null], [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] [void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iadst16x16_low1_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iadst16x16_low8_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iadst16x16_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null], [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] [void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iidentity16_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iidentity16_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null]], [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]] [[4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] [void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct32x32_low1_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct32x32_low8_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct32x32_low16_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct32x32_sse4_1], [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] zeroinitializer, [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] [void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @iidentity32_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* null]], [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]] [[4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] [void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct64x64_low1_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct64x64_low8_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct64x64_low16_sse4_1, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)* @idct64x64_sse4_1], [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] zeroinitializer, [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*] zeroinitializer]], align 16
@hitx_1d_tab = internal unnamed_addr constant [16 x i8] c"\00\00\01\01\00\01\01\01\01\02\02\00\02\01\02\01", align 16
@vitx_1d_tab = internal unnamed_addr constant [16 x i8] c"\00\01\00\01\01\00\01\01\01\02\00\02\01\02\01\02", align 16
@tx_size_wide_log2_eob = internal unnamed_addr constant [19 x i32] [i32 2, i32 3, i32 4, i32 5, i32 5, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 5, i32 2, i32 4, i32 3, i32 5, i32 4, i32 5], align 16
@av1_eob_to_eobxy_default = internal unnamed_addr constant [19 x i16*] [i16* null, i16* getelementptr inbounds ([8 x i16], [8 x i16]* @av1_eob_to_eobxy_8x8_default, i32 0, i32 0), i16* getelementptr inbounds ([16 x i16], [16 x i16]* @av1_eob_to_eobxy_16x16_default, i32 0, i32 0), i16* getelementptr inbounds ([32 x i16], [32 x i16]* @av1_eob_to_eobxy_32x32_default, i32 0, i32 0), i16* getelementptr inbounds ([32 x i16], [32 x i16]* @av1_eob_to_eobxy_32x32_default, i32 0, i32 0), i16* null, i16* null, i16* getelementptr inbounds ([16 x i16], [16 x i16]* @av1_eob_to_eobxy_8x16_default, i32 0, i32 0), i16* getelementptr inbounds ([8 x i16], [8 x i16]* @av1_eob_to_eobxy_16x8_default, i32 0, i32 0), i16* getelementptr inbounds ([32 x i16], [32 x i16]* @av1_eob_to_eobxy_16x32_default, i32 0, i32 0), i16* getelementptr inbounds ([16 x i16], [16 x i16]* @av1_eob_to_eobxy_32x16_default, i32 0, i32 0), i16* getelementptr inbounds ([32 x i16], [32 x i16]* @av1_eob_to_eobxy_32x32_default, i32 0, i32 0), i16* getelementptr inbounds ([32 x i16], [32 x i16]* @av1_eob_to_eobxy_32x32_default, i32 0, i32 0), i16* null, i16* null, i16* getelementptr inbounds ([32 x i16], [32 x i16]* @av1_eob_to_eobxy_8x32_default, i32 0, i32 0), i16* getelementptr inbounds ([8 x i16], [8 x i16]* @av1_eob_to_eobxy_32x8_default, i32 0, i32 0), i16* getelementptr inbounds ([32 x i16], [32 x i16]* @av1_eob_to_eobxy_16x32_default, i32 0, i32 0), i16* getelementptr inbounds ([16 x i16], [16 x i16]* @av1_eob_to_eobxy_32x16_default, i32 0, i32 0)], align 16
@av1_eob_to_eobxy_8x8_default = internal constant [8 x i16] [i16 1799, i16 1799, i16 1799, i16 1799, i16 1799, i16 1799, i16 1799, i16 1799], align 16
@av1_eob_to_eobxy_16x16_default = internal constant [16 x i16] [i16 1799, i16 1799, i16 3855, i16 3855, i16 3855, i16 3855, i16 3855, i16 3855, i16 3855, i16 3855, i16 3855, i16 3855, i16 3855, i16 3855, i16 3855, i16 3855], align 16
@av1_eob_to_eobxy_32x32_default = internal constant [32 x i16] [i16 1799, i16 3855, i16 3855, i16 3855, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967, i16 7967], align 16
@av1_eob_to_eobxy_8x16_default = internal constant [16 x i16] [i16 1799, i16 1799, i16 1799, i16 1799, i16 1799, i16 3847, i16 3847, i16 3847, i16 3847, i16 3847, i16 3847, i16 3847, i16 3847, i16 3847, i16 3847, i16 3847], align 16
@av1_eob_to_eobxy_16x8_default = internal constant [8 x i16] [i16 1799, i16 1799, i16 1807, i16 1807, i16 1807, i16 1807, i16 1807, i16 1807], align 16
@av1_eob_to_eobxy_16x32_default = internal constant [32 x i16] [i16 1799, i16 1799, i16 3855, i16 3855, i16 3855, i16 3855, i16 3855, i16 3855, i16 3855, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951, i16 7951], align 16
@av1_eob_to_eobxy_32x16_default = internal constant [16 x i16] [i16 1799, i16 3855, i16 3855, i16 3855, i16 3871, i16 3871, i16 3871, i16 3871, i16 3871, i16 3871, i16 3871, i16 3871, i16 3871, i16 3871, i16 3871, i16 3871], align 16
@av1_eob_to_eobxy_8x32_default = internal constant [32 x i16] [i16 1799, i16 1799, i16 1799, i16 1799, i16 1799, i16 3847, i16 3847, i16 3847, i16 3847, i16 3847, i16 3847, i16 3847, i16 3847, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943, i16 7943], align 16
@av1_eob_to_eobxy_32x8_default = internal constant [8 x i16] [i16 1799, i16 1807, i16 1807, i16 1823, i16 1823, i16 1823, i16 1823, i16 1823], align 16
@eob_fill = internal unnamed_addr constant [32 x i32] [i32 0, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31], align 16
@switch.table.av1_highbd_inv_txfm2d_add_universe_sse4_1 = private unnamed_addr constant [5 x i32] [i32 1, i32 0, i32 1, i32 0, i32 1], align 4
@switch.table.av1_highbd_inv_txfm2d_add_universe_sse4_1.1 = private unnamed_addr constant [5 x i32] [i32 0, i32 1, i32 1, i32 1, i32 0], align 4
@switch.table.av1_highbd_inv_txfm2d_add_universe_sse4_1.2 = private unnamed_addr constant [6 x i32] [i32 1, i32 1, i32 1, i32 0, i32 0, i32 1], align 4
@switch.table.av1_highbd_inv_txfm_add_16x4_sse4_1 = private unnamed_addr constant [12 x i32] [i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1, i32 0], align 4
@switch.table.av1_highbd_inv_txfm_add_16x4_sse4_1.6 = private unnamed_addr constant [12 x i32] [i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1], align 4

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_inv_txfm2d_add_4x4_sse4_1(i32* readonly, i16*, i32, i8 zeroext, i32) local_unnamed_addr #0 {
  %6 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_inv_txfm_shift_ls, i64 0, i64 0), align 16
  switch i8 %3, label %6074 [
    i8 0, label %7
    i8 1, label %302
    i8 2, label %666
    i8 3, label %1022
    i8 4, label %1447
    i8 5, label %1811
    i8 6, label %2171
    i8 7, label %2600
    i8 8, label %3029
    i8 9, label %3454
    i8 10, label %3811
    i8 11, label %4135
    i8 12, label %4471
    i8 13, label %4864
    i8 14, label %5261
    i8 15, label %5654
  ]

7:                                                ; preds = %5
  %8 = bitcast i32* %0 to <4 x i32>*
  %9 = load <4 x i32>, <4 x i32>* %8, align 16
  %10 = getelementptr inbounds i32, i32* %0, i64 4
  %11 = bitcast i32* %10 to <4 x i32>*
  %12 = load <4 x i32>, <4 x i32>* %11, align 16
  %13 = getelementptr inbounds i32, i32* %0, i64 8
  %14 = bitcast i32* %13 to <4 x i32>*
  %15 = load <4 x i32>, <4 x i32>* %14, align 16
  %16 = getelementptr inbounds i32, i32* %0, i64 12
  %17 = bitcast i32* %16 to <4 x i32>*
  %18 = load <4 x i32>, <4 x i32>* %17, align 16
  %19 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 0, i64 0), align 16
  %20 = sext i8 %19 to i32
  %21 = add nsw i32 %20, -10
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %22, i64 32
  %24 = load i32, i32* %23, align 16
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> zeroinitializer
  %27 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %22, i64 48
  %28 = load i32, i32* %27, align 16
  %29 = insertelement <4 x i32> undef, i32 %28, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %22, i64 16
  %32 = load i32, i32* %31, align 16
  %33 = insertelement <4 x i32> undef, i32 %32, i32 0
  %34 = shufflevector <4 x i32> %33, <4 x i32> undef, <4 x i32> zeroinitializer
  %35 = sub nsw i32 0, %32
  %36 = insertelement <4 x i32> undef, i32 %35, i32 0
  %37 = shufflevector <4 x i32> %36, <4 x i32> undef, <4 x i32> zeroinitializer
  %38 = add nsw i32 %20, -1
  %39 = shl i32 1, %38
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = icmp slt i32 %4, 8
  %43 = add i32 %4, 7
  %44 = shl i32 1, %43
  %45 = select i1 %42, i32 32768, i32 %44
  %46 = sub nsw i32 0, %45
  %47 = insertelement <4 x i32> undef, i32 %46, i32 0
  %48 = shufflevector <4 x i32> %47, <4 x i32> undef, <4 x i32> zeroinitializer
  %49 = add nsw i32 %45, -1
  %50 = insertelement <4 x i32> undef, i32 %49, i32 0
  %51 = shufflevector <4 x i32> %50, <4 x i32> undef, <4 x i32> zeroinitializer
  %52 = shufflevector <4 x i32> %9, <4 x i32> %12, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %53 = bitcast <4 x i32> %52 to <2 x i64>
  %54 = shufflevector <4 x i32> %9, <4 x i32> %12, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %55 = bitcast <4 x i32> %54 to <2 x i64>
  %56 = shufflevector <4 x i32> %15, <4 x i32> %18, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %57 = bitcast <4 x i32> %56 to <2 x i64>
  %58 = shufflevector <4 x i32> %15, <4 x i32> %18, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %59 = bitcast <4 x i32> %58 to <2 x i64>
  %60 = shufflevector <2 x i64> %53, <2 x i64> %57, <2 x i32> <i32 0, i32 2>
  %61 = shufflevector <2 x i64> %53, <2 x i64> %57, <2 x i32> <i32 1, i32 3>
  %62 = shufflevector <2 x i64> %55, <2 x i64> %59, <2 x i32> <i32 0, i32 2>
  %63 = shufflevector <2 x i64> %55, <2 x i64> %59, <2 x i32> <i32 1, i32 3>
  %64 = bitcast <2 x i64> %60 to <4 x i32>
  %65 = mul <4 x i32> %26, %64
  %66 = bitcast <2 x i64> %62 to <4 x i32>
  %67 = mul <4 x i32> %26, %66
  %68 = add <4 x i32> %67, %65
  %69 = add <4 x i32> %68, %41
  %70 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %69, i32 %20) #8
  %71 = sub <4 x i32> %65, %67
  %72 = add <4 x i32> %71, %41
  %73 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %72, i32 %20) #8
  %74 = bitcast <2 x i64> %61 to <4 x i32>
  %75 = mul <4 x i32> %30, %74
  %76 = bitcast <2 x i64> %63 to <4 x i32>
  %77 = mul <4 x i32> %37, %76
  %78 = add <4 x i32> %75, %41
  %79 = add <4 x i32> %78, %77
  %80 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %79, i32 %20) #8
  %81 = mul <4 x i32> %34, %74
  %82 = mul <4 x i32> %30, %76
  %83 = add <4 x i32> %82, %41
  %84 = add <4 x i32> %83, %81
  %85 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %84, i32 %20) #8
  %86 = add <4 x i32> %85, %70
  %87 = sub <4 x i32> %70, %85
  %88 = icmp sgt <4 x i32> %86, %48
  %89 = select <4 x i1> %88, <4 x i32> %86, <4 x i32> %48
  %90 = icmp slt <4 x i32> %89, %51
  %91 = select <4 x i1> %90, <4 x i32> %89, <4 x i32> %51
  %92 = icmp sgt <4 x i32> %87, %48
  %93 = select <4 x i1> %92, <4 x i32> %87, <4 x i32> %48
  %94 = icmp slt <4 x i32> %93, %51
  %95 = select <4 x i1> %94, <4 x i32> %93, <4 x i32> %51
  %96 = add <4 x i32> %80, %73
  %97 = sub <4 x i32> %73, %80
  %98 = icmp sgt <4 x i32> %96, %48
  %99 = select <4 x i1> %98, <4 x i32> %96, <4 x i32> %48
  %100 = icmp slt <4 x i32> %99, %51
  %101 = select <4 x i1> %100, <4 x i32> %99, <4 x i32> %51
  %102 = icmp sgt <4 x i32> %97, %48
  %103 = select <4 x i1> %102, <4 x i32> %97, <4 x i32> %48
  %104 = icmp slt <4 x i32> %103, %51
  %105 = select <4 x i1> %104, <4 x i32> %103, <4 x i32> %51
  %106 = icmp sgt i32 %4, 10
  %107 = select i1 %106, i32 %4, i32 10
  %108 = shl i32 32, %107
  %109 = sub nsw i32 0, %108
  %110 = insertelement <4 x i32> undef, i32 %109, i32 0
  %111 = shufflevector <4 x i32> %110, <4 x i32> undef, <4 x i32> zeroinitializer
  %112 = add nsw i32 %108, -1
  %113 = insertelement <4 x i32> undef, i32 %112, i32 0
  %114 = shufflevector <4 x i32> %113, <4 x i32> undef, <4 x i32> zeroinitializer
  %115 = icmp sgt <4 x i32> %91, %111
  %116 = select <4 x i1> %115, <4 x i32> %91, <4 x i32> %111
  %117 = icmp slt <4 x i32> %116, %114
  %118 = select <4 x i1> %117, <4 x i32> %116, <4 x i32> %114
  %119 = icmp sgt <4 x i32> %95, %111
  %120 = select <4 x i1> %119, <4 x i32> %95, <4 x i32> %111
  %121 = icmp slt <4 x i32> %120, %114
  %122 = select <4 x i1> %121, <4 x i32> %120, <4 x i32> %114
  %123 = icmp sgt <4 x i32> %101, %111
  %124 = select <4 x i1> %123, <4 x i32> %101, <4 x i32> %111
  %125 = icmp slt <4 x i32> %124, %114
  %126 = select <4 x i1> %125, <4 x i32> %124, <4 x i32> %114
  %127 = icmp sgt <4 x i32> %105, %111
  %128 = select <4 x i1> %127, <4 x i32> %105, <4 x i32> %111
  %129 = icmp slt <4 x i32> %128, %114
  %130 = select <4 x i1> %129, <4 x i32> %128, <4 x i32> %114
  %131 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 0, i64 0), align 16
  %132 = sext i8 %131 to i32
  %133 = add nsw i32 %132, -10
  %134 = sext i32 %133 to i64
  %135 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %134, i64 32
  %136 = load i32, i32* %135, align 16
  %137 = insertelement <4 x i32> undef, i32 %136, i32 0
  %138 = shufflevector <4 x i32> %137, <4 x i32> undef, <4 x i32> zeroinitializer
  %139 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %134, i64 48
  %140 = load i32, i32* %139, align 16
  %141 = insertelement <4 x i32> undef, i32 %140, i32 0
  %142 = shufflevector <4 x i32> %141, <4 x i32> undef, <4 x i32> zeroinitializer
  %143 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %134, i64 16
  %144 = load i32, i32* %143, align 16
  %145 = insertelement <4 x i32> undef, i32 %144, i32 0
  %146 = shufflevector <4 x i32> %145, <4 x i32> undef, <4 x i32> zeroinitializer
  %147 = sub nsw i32 0, %144
  %148 = insertelement <4 x i32> undef, i32 %147, i32 0
  %149 = shufflevector <4 x i32> %148, <4 x i32> undef, <4 x i32> zeroinitializer
  %150 = add nsw i32 %132, -1
  %151 = shl i32 1, %150
  %152 = insertelement <4 x i32> undef, i32 %151, i32 0
  %153 = shufflevector <4 x i32> %152, <4 x i32> undef, <4 x i32> zeroinitializer
  %154 = icmp slt i32 %4, 10
  %155 = add i32 %4, 5
  %156 = shl i32 1, %155
  %157 = select i1 %154, i32 32768, i32 %156
  %158 = sub nsw i32 0, %157
  %159 = insertelement <4 x i32> undef, i32 %158, i32 0
  %160 = shufflevector <4 x i32> %159, <4 x i32> undef, <4 x i32> zeroinitializer
  %161 = add nsw i32 %157, -1
  %162 = insertelement <4 x i32> undef, i32 %161, i32 0
  %163 = shufflevector <4 x i32> %162, <4 x i32> undef, <4 x i32> zeroinitializer
  %164 = shufflevector <4 x i32> %118, <4 x i32> %126, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %165 = bitcast <4 x i32> %164 to <2 x i64>
  %166 = shufflevector <4 x i32> %118, <4 x i32> %126, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %167 = bitcast <4 x i32> %166 to <2 x i64>
  %168 = shufflevector <4 x i32> %130, <4 x i32> %122, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %169 = bitcast <4 x i32> %168 to <2 x i64>
  %170 = shufflevector <4 x i32> %130, <4 x i32> %122, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %171 = bitcast <4 x i32> %170 to <2 x i64>
  %172 = shufflevector <2 x i64> %165, <2 x i64> %169, <2 x i32> <i32 0, i32 2>
  %173 = shufflevector <2 x i64> %165, <2 x i64> %169, <2 x i32> <i32 1, i32 3>
  %174 = shufflevector <2 x i64> %167, <2 x i64> %171, <2 x i32> <i32 0, i32 2>
  %175 = shufflevector <2 x i64> %167, <2 x i64> %171, <2 x i32> <i32 1, i32 3>
  %176 = bitcast <2 x i64> %172 to <4 x i32>
  %177 = mul <4 x i32> %138, %176
  %178 = bitcast <2 x i64> %174 to <4 x i32>
  %179 = mul <4 x i32> %138, %178
  %180 = add <4 x i32> %177, %153
  %181 = add <4 x i32> %180, %179
  %182 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %181, i32 %132) #8
  %183 = sub <4 x i32> %153, %179
  %184 = add <4 x i32> %183, %177
  %185 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %184, i32 %132) #8
  %186 = bitcast <2 x i64> %173 to <4 x i32>
  %187 = mul <4 x i32> %142, %186
  %188 = bitcast <2 x i64> %175 to <4 x i32>
  %189 = mul <4 x i32> %149, %188
  %190 = add <4 x i32> %187, %153
  %191 = add <4 x i32> %190, %189
  %192 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %191, i32 %132) #8
  %193 = mul <4 x i32> %146, %186
  %194 = mul <4 x i32> %142, %188
  %195 = add <4 x i32> %193, %153
  %196 = add <4 x i32> %195, %194
  %197 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %196, i32 %132) #8
  %198 = add <4 x i32> %197, %182
  %199 = sub <4 x i32> %182, %197
  %200 = icmp sgt <4 x i32> %198, %160
  %201 = select <4 x i1> %200, <4 x i32> %198, <4 x i32> %160
  %202 = icmp slt <4 x i32> %201, %163
  %203 = select <4 x i1> %202, <4 x i32> %201, <4 x i32> %163
  %204 = icmp sgt <4 x i32> %199, %160
  %205 = select <4 x i1> %204, <4 x i32> %199, <4 x i32> %160
  %206 = icmp slt <4 x i32> %205, %163
  %207 = select <4 x i1> %206, <4 x i32> %205, <4 x i32> %163
  %208 = add <4 x i32> %192, %185
  %209 = sub <4 x i32> %185, %192
  %210 = icmp sgt <4 x i32> %208, %160
  %211 = select <4 x i1> %210, <4 x i32> %208, <4 x i32> %160
  %212 = icmp slt <4 x i32> %211, %163
  %213 = select <4 x i1> %212, <4 x i32> %211, <4 x i32> %163
  %214 = icmp sgt <4 x i32> %209, %160
  %215 = select <4 x i1> %214, <4 x i32> %209, <4 x i32> %160
  %216 = icmp slt <4 x i32> %215, %163
  %217 = select <4 x i1> %216, <4 x i32> %215, <4 x i32> %163
  %218 = getelementptr inbounds i8, i8* %6, i64 1
  %219 = load i8, i8* %218, align 1
  %220 = sext i8 %219 to i32
  %221 = sub nsw i32 0, %220
  %222 = icmp eq i8 %219, 0
  br i1 %222, label %236, label %223

223:                                              ; preds = %7
  %224 = xor i32 %220, -1
  %225 = shl i32 1, %224
  %226 = insertelement <4 x i32> undef, i32 %225, i32 0
  %227 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> zeroinitializer
  %228 = add <4 x i32> %203, %227
  %229 = add <4 x i32> %227, %213
  %230 = add <4 x i32> %227, %217
  %231 = add <4 x i32> %207, %227
  %232 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %228, i32 %221) #8
  %233 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %229, i32 %221) #8
  %234 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %230, i32 %221) #8
  %235 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %231, i32 %221) #8
  br label %236

236:                                              ; preds = %7, %223
  %237 = phi <4 x i32> [ %207, %7 ], [ %235, %223 ]
  %238 = phi <4 x i32> [ %217, %7 ], [ %234, %223 ]
  %239 = phi <4 x i32> [ %213, %7 ], [ %233, %223 ]
  %240 = phi <4 x i32> [ %203, %7 ], [ %232, %223 ]
  %241 = bitcast i16* %1 to i64*
  %242 = load i64, i64* %241, align 1
  %243 = insertelement <2 x i64> undef, i64 %242, i32 0
  %244 = sext i32 %2 to i64
  %245 = getelementptr inbounds i16, i16* %1, i64 %244
  %246 = bitcast i16* %245 to i64*
  %247 = load i64, i64* %246, align 1
  %248 = insertelement <2 x i64> undef, i64 %247, i32 0
  %249 = shl nsw i32 %2, 1
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds i16, i16* %1, i64 %250
  %252 = bitcast i16* %251 to i64*
  %253 = load i64, i64* %252, align 1
  %254 = insertelement <2 x i64> undef, i64 %253, i32 0
  %255 = mul nsw i32 %2, 3
  %256 = sext i32 %255 to i64
  %257 = getelementptr inbounds i16, i16* %1, i64 %256
  %258 = bitcast i16* %257 to i64*
  %259 = load i64, i64* %258, align 1
  %260 = insertelement <2 x i64> undef, i64 %259, i32 0
  %261 = bitcast <2 x i64> %243 to <8 x i16>
  %262 = shufflevector <8 x i16> %261, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %263 = bitcast <2 x i64> %248 to <8 x i16>
  %264 = shufflevector <8 x i16> %263, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %265 = bitcast <2 x i64> %254 to <8 x i16>
  %266 = shufflevector <8 x i16> %265, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %267 = bitcast <2 x i64> %260 to <8 x i16>
  %268 = shufflevector <8 x i16> %267, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %269 = bitcast <8 x i16> %262 to <4 x i32>
  %270 = add <4 x i32> %240, %269
  %271 = bitcast <8 x i16> %264 to <4 x i32>
  %272 = add <4 x i32> %239, %271
  %273 = bitcast <8 x i16> %266 to <4 x i32>
  %274 = add <4 x i32> %238, %273
  %275 = bitcast <8 x i16> %268 to <4 x i32>
  %276 = add <4 x i32> %237, %275
  %277 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %270, <4 x i32> %272) #8
  %278 = bitcast <8 x i16> %277 to <2 x i64>
  %279 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %274, <4 x i32> %276) #8
  %280 = bitcast <8 x i16> %279 to <2 x i64>
  %281 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %282 = add <8 x i16> %281, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %283 = icmp slt <8 x i16> %282, %277
  %284 = sext <8 x i1> %283 to <8 x i16>
  %285 = bitcast <8 x i16> %284 to <2 x i64>
  %286 = xor <2 x i64> %285, <i64 -1, i64 -1>
  %287 = and <2 x i64> %286, %278
  %288 = and <8 x i16> %282, %284
  %289 = bitcast <8 x i16> %288 to <2 x i64>
  %290 = or <2 x i64> %287, %289
  %291 = bitcast <2 x i64> %290 to <8 x i16>
  %292 = icmp sgt <8 x i16> %291, zeroinitializer
  %293 = sext <8 x i1> %292 to <8 x i16>
  %294 = bitcast <8 x i16> %293 to <2 x i64>
  %295 = and <2 x i64> %290, %294
  %296 = icmp slt <8 x i16> %282, %279
  %297 = sext <8 x i1> %296 to <8 x i16>
  %298 = bitcast <8 x i16> %297 to <2 x i64>
  %299 = xor <2 x i64> %298, <i64 -1, i64 -1>
  %300 = and <2 x i64> %299, %280
  %301 = and <8 x i16> %282, %297
  br label %6055

302:                                              ; preds = %5
  %303 = bitcast i32* %0 to <4 x i32>*
  %304 = load <4 x i32>, <4 x i32>* %303, align 16
  %305 = getelementptr inbounds i32, i32* %0, i64 4
  %306 = bitcast i32* %305 to <4 x i32>*
  %307 = load <4 x i32>, <4 x i32>* %306, align 16
  %308 = getelementptr inbounds i32, i32* %0, i64 8
  %309 = bitcast i32* %308 to <4 x i32>*
  %310 = load <4 x i32>, <4 x i32>* %309, align 16
  %311 = getelementptr inbounds i32, i32* %0, i64 12
  %312 = bitcast i32* %311 to <4 x i32>*
  %313 = load <4 x i32>, <4 x i32>* %312, align 16
  %314 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 0, i64 0), align 16
  %315 = sext i8 %314 to i32
  %316 = add nsw i32 %315, -10
  %317 = sext i32 %316 to i64
  %318 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %317, i64 32
  %319 = load i32, i32* %318, align 16
  %320 = insertelement <4 x i32> undef, i32 %319, i32 0
  %321 = shufflevector <4 x i32> %320, <4 x i32> undef, <4 x i32> zeroinitializer
  %322 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %317, i64 48
  %323 = load i32, i32* %322, align 16
  %324 = insertelement <4 x i32> undef, i32 %323, i32 0
  %325 = shufflevector <4 x i32> %324, <4 x i32> undef, <4 x i32> zeroinitializer
  %326 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %317, i64 16
  %327 = load i32, i32* %326, align 16
  %328 = insertelement <4 x i32> undef, i32 %327, i32 0
  %329 = shufflevector <4 x i32> %328, <4 x i32> undef, <4 x i32> zeroinitializer
  %330 = sub nsw i32 0, %327
  %331 = insertelement <4 x i32> undef, i32 %330, i32 0
  %332 = shufflevector <4 x i32> %331, <4 x i32> undef, <4 x i32> zeroinitializer
  %333 = add nsw i32 %315, -1
  %334 = shl i32 1, %333
  %335 = insertelement <4 x i32> undef, i32 %334, i32 0
  %336 = shufflevector <4 x i32> %335, <4 x i32> undef, <4 x i32> zeroinitializer
  %337 = icmp slt i32 %4, 8
  %338 = add i32 %4, 7
  %339 = shl i32 1, %338
  %340 = select i1 %337, i32 32768, i32 %339
  %341 = sub nsw i32 0, %340
  %342 = insertelement <4 x i32> undef, i32 %341, i32 0
  %343 = shufflevector <4 x i32> %342, <4 x i32> undef, <4 x i32> zeroinitializer
  %344 = add nsw i32 %340, -1
  %345 = insertelement <4 x i32> undef, i32 %344, i32 0
  %346 = shufflevector <4 x i32> %345, <4 x i32> undef, <4 x i32> zeroinitializer
  %347 = shufflevector <4 x i32> %304, <4 x i32> %307, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %348 = bitcast <4 x i32> %347 to <2 x i64>
  %349 = shufflevector <4 x i32> %304, <4 x i32> %307, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %350 = bitcast <4 x i32> %349 to <2 x i64>
  %351 = shufflevector <4 x i32> %310, <4 x i32> %313, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %352 = bitcast <4 x i32> %351 to <2 x i64>
  %353 = shufflevector <4 x i32> %310, <4 x i32> %313, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %354 = bitcast <4 x i32> %353 to <2 x i64>
  %355 = shufflevector <2 x i64> %348, <2 x i64> %352, <2 x i32> <i32 0, i32 2>
  %356 = shufflevector <2 x i64> %348, <2 x i64> %352, <2 x i32> <i32 1, i32 3>
  %357 = shufflevector <2 x i64> %350, <2 x i64> %354, <2 x i32> <i32 0, i32 2>
  %358 = shufflevector <2 x i64> %350, <2 x i64> %354, <2 x i32> <i32 1, i32 3>
  %359 = bitcast <2 x i64> %355 to <4 x i32>
  %360 = mul <4 x i32> %321, %359
  %361 = bitcast <2 x i64> %357 to <4 x i32>
  %362 = mul <4 x i32> %321, %361
  %363 = add <4 x i32> %362, %360
  %364 = add <4 x i32> %363, %336
  %365 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %364, i32 %315) #8
  %366 = sub <4 x i32> %360, %362
  %367 = add <4 x i32> %366, %336
  %368 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %367, i32 %315) #8
  %369 = bitcast <2 x i64> %356 to <4 x i32>
  %370 = mul <4 x i32> %325, %369
  %371 = bitcast <2 x i64> %358 to <4 x i32>
  %372 = mul <4 x i32> %332, %371
  %373 = add <4 x i32> %370, %336
  %374 = add <4 x i32> %373, %372
  %375 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %374, i32 %315) #8
  %376 = mul <4 x i32> %329, %369
  %377 = mul <4 x i32> %325, %371
  %378 = add <4 x i32> %377, %336
  %379 = add <4 x i32> %378, %376
  %380 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %379, i32 %315) #8
  %381 = add <4 x i32> %380, %365
  %382 = sub <4 x i32> %365, %380
  %383 = icmp sgt <4 x i32> %381, %343
  %384 = select <4 x i1> %383, <4 x i32> %381, <4 x i32> %343
  %385 = icmp slt <4 x i32> %384, %346
  %386 = select <4 x i1> %385, <4 x i32> %384, <4 x i32> %346
  %387 = icmp sgt <4 x i32> %382, %343
  %388 = select <4 x i1> %387, <4 x i32> %382, <4 x i32> %343
  %389 = icmp slt <4 x i32> %388, %346
  %390 = select <4 x i1> %389, <4 x i32> %388, <4 x i32> %346
  %391 = add <4 x i32> %375, %368
  %392 = sub <4 x i32> %368, %375
  %393 = icmp sgt <4 x i32> %391, %343
  %394 = select <4 x i1> %393, <4 x i32> %391, <4 x i32> %343
  %395 = icmp slt <4 x i32> %394, %346
  %396 = select <4 x i1> %395, <4 x i32> %394, <4 x i32> %346
  %397 = icmp sgt <4 x i32> %392, %343
  %398 = select <4 x i1> %397, <4 x i32> %392, <4 x i32> %343
  %399 = icmp slt <4 x i32> %398, %346
  %400 = select <4 x i1> %399, <4 x i32> %398, <4 x i32> %346
  %401 = icmp sgt i32 %4, 10
  %402 = select i1 %401, i32 %4, i32 10
  %403 = shl i32 32, %402
  %404 = sub nsw i32 0, %403
  %405 = insertelement <4 x i32> undef, i32 %404, i32 0
  %406 = shufflevector <4 x i32> %405, <4 x i32> undef, <4 x i32> zeroinitializer
  %407 = add nsw i32 %403, -1
  %408 = insertelement <4 x i32> undef, i32 %407, i32 0
  %409 = shufflevector <4 x i32> %408, <4 x i32> undef, <4 x i32> zeroinitializer
  %410 = icmp sgt <4 x i32> %386, %406
  %411 = select <4 x i1> %410, <4 x i32> %386, <4 x i32> %406
  %412 = icmp slt <4 x i32> %411, %409
  %413 = select <4 x i1> %412, <4 x i32> %411, <4 x i32> %409
  %414 = icmp sgt <4 x i32> %390, %406
  %415 = select <4 x i1> %414, <4 x i32> %390, <4 x i32> %406
  %416 = icmp slt <4 x i32> %415, %409
  %417 = select <4 x i1> %416, <4 x i32> %415, <4 x i32> %409
  %418 = icmp sgt <4 x i32> %396, %406
  %419 = select <4 x i1> %418, <4 x i32> %396, <4 x i32> %406
  %420 = icmp slt <4 x i32> %419, %409
  %421 = select <4 x i1> %420, <4 x i32> %419, <4 x i32> %409
  %422 = icmp sgt <4 x i32> %400, %406
  %423 = select <4 x i1> %422, <4 x i32> %400, <4 x i32> %406
  %424 = icmp slt <4 x i32> %423, %409
  %425 = select <4 x i1> %424, <4 x i32> %423, <4 x i32> %409
  %426 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 0, i64 0), align 16
  %427 = sext i8 %426 to i32
  %428 = add nsw i32 %427, -10
  %429 = sext i32 %428 to i64
  %430 = add nsw i32 %427, 3
  %431 = shl i32 1, %430
  %432 = insertelement <4 x i32> undef, i32 %431, i32 0
  %433 = shufflevector <4 x i32> %432, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %434 = shufflevector <4 x i32> %433, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %435 = bitcast <4 x i32> %434 to <2 x i64>
  %436 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %429, i64 1
  %437 = load i32, i32* %436, align 4
  %438 = insertelement <4 x i32> undef, i32 %437, i32 0
  %439 = shufflevector <4 x i32> %438, <4 x i32> undef, <4 x i32> zeroinitializer
  %440 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %429, i64 2
  %441 = load i32, i32* %440, align 4
  %442 = insertelement <4 x i32> undef, i32 %441, i32 0
  %443 = shufflevector <4 x i32> %442, <4 x i32> undef, <4 x i32> zeroinitializer
  %444 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %429, i64 3
  %445 = load i32, i32* %444, align 4
  %446 = insertelement <4 x i32> undef, i32 %445, i32 0
  %447 = shufflevector <4 x i32> %446, <4 x i32> undef, <4 x i32> zeroinitializer
  %448 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %429, i64 4
  %449 = load i32, i32* %448, align 4
  %450 = insertelement <4 x i32> undef, i32 %449, i32 0
  %451 = shufflevector <4 x i32> %450, <4 x i32> undef, <4 x i32> zeroinitializer
  %452 = shufflevector <4 x i32> %413, <4 x i32> %421, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %453 = bitcast <4 x i32> %452 to <2 x i64>
  %454 = shufflevector <4 x i32> %413, <4 x i32> %421, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %455 = bitcast <4 x i32> %454 to <2 x i64>
  %456 = shufflevector <4 x i32> %425, <4 x i32> %417, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %457 = bitcast <4 x i32> %456 to <2 x i64>
  %458 = shufflevector <4 x i32> %425, <4 x i32> %417, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %459 = bitcast <4 x i32> %458 to <2 x i64>
  %460 = shufflevector <2 x i64> %453, <2 x i64> %457, <2 x i32> <i32 0, i32 2>
  %461 = shufflevector <2 x i64> %453, <2 x i64> %457, <2 x i32> <i32 1, i32 3>
  %462 = shufflevector <2 x i64> %455, <2 x i64> %459, <2 x i32> <i32 0, i32 2>
  %463 = shufflevector <2 x i64> %455, <2 x i64> %459, <2 x i32> <i32 1, i32 3>
  %464 = bitcast <2 x i64> %460 to <4 x i32>
  %465 = mul <4 x i32> %439, %464
  %466 = mul <4 x i32> %443, %464
  %467 = bitcast <2 x i64> %461 to <4 x i32>
  %468 = mul <4 x i32> %447, %467
  %469 = bitcast <2 x i64> %462 to <4 x i32>
  %470 = mul <4 x i32> %451, %469
  %471 = mul <4 x i32> %439, %469
  %472 = bitcast <2 x i64> %463 to <4 x i32>
  %473 = mul <4 x i32> %443, %472
  %474 = sub <4 x i32> %464, %469
  %475 = add <4 x i32> %474, %472
  %476 = add <4 x i32> %470, %465
  %477 = add <4 x i32> %476, %473
  %478 = sub <4 x i32> %466, %471
  %479 = mul <4 x i32> %451, %472
  %480 = sub <4 x i32> %478, %479
  %481 = mul <4 x i32> %475, %447
  %482 = bitcast <4 x i32> %481 to <2 x i64>
  %483 = add <4 x i32> %477, %468
  %484 = bitcast <4 x i32> %483 to <2 x i64>
  %485 = add <4 x i32> %480, %468
  %486 = bitcast <4 x i32> %485 to <2 x i64>
  %487 = sub <4 x i32> %477, %468
  %488 = add <4 x i32> %487, %480
  %489 = bitcast <4 x i32> %488 to <2 x i64>
  %490 = shl <2 x i64> %484, <i64 32, i64 32>
  %491 = ashr exact <2 x i64> %490, <i64 28, i64 28>
  %492 = add <2 x i64> %491, %435
  %493 = bitcast <4 x i32> %483 to <16 x i8>
  %494 = shufflevector <16 x i8> %493, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %495 = bitcast <16 x i8> %494 to <2 x i64>
  %496 = shl <2 x i64> %495, <i64 32, i64 32>
  %497 = ashr exact <2 x i64> %496, <i64 28, i64 28>
  %498 = add <2 x i64> %497, %435
  %499 = bitcast <2 x i64> %492 to <16 x i8>
  %500 = shufflevector <16 x i8> %499, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %501 = bitcast <2 x i64> %498 to <16 x i8>
  %502 = shufflevector <16 x i8> %501, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %503 = bitcast <16 x i8> %500 to <4 x i32>
  %504 = bitcast <16 x i8> %502 to <4 x i32>
  %505 = shufflevector <4 x i32> %503, <4 x i32> %504, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %506 = bitcast <4 x i32> %505 to <2 x i64>
  %507 = shufflevector <4 x i32> %503, <4 x i32> %504, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %508 = bitcast <4 x i32> %507 to <2 x i64>
  %509 = shufflevector <2 x i64> %506, <2 x i64> %508, <2 x i32> <i32 0, i32 2>
  %510 = shl <2 x i64> %486, <i64 32, i64 32>
  %511 = ashr exact <2 x i64> %510, <i64 28, i64 28>
  %512 = add <2 x i64> %511, %435
  %513 = bitcast <4 x i32> %485 to <16 x i8>
  %514 = shufflevector <16 x i8> %513, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %515 = bitcast <16 x i8> %514 to <2 x i64>
  %516 = shl <2 x i64> %515, <i64 32, i64 32>
  %517 = ashr exact <2 x i64> %516, <i64 28, i64 28>
  %518 = add <2 x i64> %517, %435
  %519 = bitcast <2 x i64> %512 to <16 x i8>
  %520 = shufflevector <16 x i8> %519, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %521 = bitcast <2 x i64> %518 to <16 x i8>
  %522 = shufflevector <16 x i8> %521, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %523 = bitcast <16 x i8> %520 to <4 x i32>
  %524 = bitcast <16 x i8> %522 to <4 x i32>
  %525 = shufflevector <4 x i32> %523, <4 x i32> %524, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %526 = bitcast <4 x i32> %525 to <2 x i64>
  %527 = shufflevector <4 x i32> %523, <4 x i32> %524, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %528 = bitcast <4 x i32> %527 to <2 x i64>
  %529 = shufflevector <2 x i64> %526, <2 x i64> %528, <2 x i32> <i32 0, i32 2>
  %530 = shl <2 x i64> %482, <i64 32, i64 32>
  %531 = ashr exact <2 x i64> %530, <i64 28, i64 28>
  %532 = add <2 x i64> %531, %435
  %533 = bitcast <4 x i32> %481 to <16 x i8>
  %534 = shufflevector <16 x i8> %533, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %535 = bitcast <16 x i8> %534 to <2 x i64>
  %536 = shl <2 x i64> %535, <i64 32, i64 32>
  %537 = ashr exact <2 x i64> %536, <i64 28, i64 28>
  %538 = add <2 x i64> %537, %435
  %539 = bitcast <2 x i64> %532 to <16 x i8>
  %540 = shufflevector <16 x i8> %539, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %541 = bitcast <2 x i64> %538 to <16 x i8>
  %542 = shufflevector <16 x i8> %541, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %543 = bitcast <16 x i8> %540 to <4 x i32>
  %544 = bitcast <16 x i8> %542 to <4 x i32>
  %545 = shufflevector <4 x i32> %543, <4 x i32> %544, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %546 = bitcast <4 x i32> %545 to <2 x i64>
  %547 = shufflevector <4 x i32> %543, <4 x i32> %544, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %548 = bitcast <4 x i32> %547 to <2 x i64>
  %549 = shufflevector <2 x i64> %546, <2 x i64> %548, <2 x i32> <i32 0, i32 2>
  %550 = shl <2 x i64> %489, <i64 32, i64 32>
  %551 = ashr exact <2 x i64> %550, <i64 28, i64 28>
  %552 = add <2 x i64> %551, %435
  %553 = bitcast <4 x i32> %488 to <16 x i8>
  %554 = shufflevector <16 x i8> %553, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %555 = bitcast <16 x i8> %554 to <2 x i64>
  %556 = shl <2 x i64> %555, <i64 32, i64 32>
  %557 = ashr exact <2 x i64> %556, <i64 28, i64 28>
  %558 = add <2 x i64> %557, %435
  %559 = bitcast <2 x i64> %552 to <16 x i8>
  %560 = shufflevector <16 x i8> %559, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %561 = bitcast <2 x i64> %558 to <16 x i8>
  %562 = shufflevector <16 x i8> %561, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %563 = bitcast <16 x i8> %560 to <4 x i32>
  %564 = bitcast <16 x i8> %562 to <4 x i32>
  %565 = shufflevector <4 x i32> %563, <4 x i32> %564, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %566 = bitcast <4 x i32> %565 to <2 x i64>
  %567 = shufflevector <4 x i32> %563, <4 x i32> %564, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %568 = bitcast <4 x i32> %567 to <2 x i64>
  %569 = shufflevector <2 x i64> %566, <2 x i64> %568, <2 x i32> <i32 0, i32 2>
  %570 = getelementptr inbounds i8, i8* %6, i64 1
  %571 = load i8, i8* %570, align 1
  %572 = sext i8 %571 to i32
  %573 = sub nsw i32 0, %572
  %574 = icmp eq i8 %571, 0
  br i1 %574, label %596, label %575

575:                                              ; preds = %302
  %576 = xor i32 %572, -1
  %577 = shl i32 1, %576
  %578 = insertelement <4 x i32> undef, i32 %577, i32 0
  %579 = shufflevector <4 x i32> %578, <4 x i32> undef, <4 x i32> zeroinitializer
  %580 = bitcast <2 x i64> %509 to <4 x i32>
  %581 = add <4 x i32> %579, %580
  %582 = bitcast <2 x i64> %529 to <4 x i32>
  %583 = add <4 x i32> %579, %582
  %584 = bitcast <2 x i64> %549 to <4 x i32>
  %585 = add <4 x i32> %579, %584
  %586 = bitcast <2 x i64> %569 to <4 x i32>
  %587 = add <4 x i32> %579, %586
  %588 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %581, i32 %573) #8
  %589 = bitcast <4 x i32> %588 to <2 x i64>
  %590 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %583, i32 %573) #8
  %591 = bitcast <4 x i32> %590 to <2 x i64>
  %592 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %585, i32 %573) #8
  %593 = bitcast <4 x i32> %592 to <2 x i64>
  %594 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %587, i32 %573) #8
  %595 = bitcast <4 x i32> %594 to <2 x i64>
  br label %596

596:                                              ; preds = %302, %575
  %597 = phi <2 x i64> [ %569, %302 ], [ %595, %575 ]
  %598 = phi <2 x i64> [ %549, %302 ], [ %593, %575 ]
  %599 = phi <2 x i64> [ %529, %302 ], [ %591, %575 ]
  %600 = phi <2 x i64> [ %509, %302 ], [ %589, %575 ]
  %601 = bitcast i16* %1 to i64*
  %602 = load i64, i64* %601, align 1
  %603 = insertelement <2 x i64> undef, i64 %602, i32 0
  %604 = sext i32 %2 to i64
  %605 = getelementptr inbounds i16, i16* %1, i64 %604
  %606 = bitcast i16* %605 to i64*
  %607 = load i64, i64* %606, align 1
  %608 = insertelement <2 x i64> undef, i64 %607, i32 0
  %609 = shl nsw i32 %2, 1
  %610 = sext i32 %609 to i64
  %611 = getelementptr inbounds i16, i16* %1, i64 %610
  %612 = bitcast i16* %611 to i64*
  %613 = load i64, i64* %612, align 1
  %614 = insertelement <2 x i64> undef, i64 %613, i32 0
  %615 = mul nsw i32 %2, 3
  %616 = sext i32 %615 to i64
  %617 = getelementptr inbounds i16, i16* %1, i64 %616
  %618 = bitcast i16* %617 to i64*
  %619 = load i64, i64* %618, align 1
  %620 = insertelement <2 x i64> undef, i64 %619, i32 0
  %621 = bitcast <2 x i64> %603 to <8 x i16>
  %622 = shufflevector <8 x i16> %621, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %623 = bitcast <2 x i64> %608 to <8 x i16>
  %624 = shufflevector <8 x i16> %623, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %625 = bitcast <2 x i64> %614 to <8 x i16>
  %626 = shufflevector <8 x i16> %625, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %627 = bitcast <2 x i64> %620 to <8 x i16>
  %628 = shufflevector <8 x i16> %627, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %629 = bitcast <2 x i64> %600 to <4 x i32>
  %630 = bitcast <8 x i16> %622 to <4 x i32>
  %631 = add <4 x i32> %630, %629
  %632 = bitcast <2 x i64> %599 to <4 x i32>
  %633 = bitcast <8 x i16> %624 to <4 x i32>
  %634 = add <4 x i32> %633, %632
  %635 = bitcast <2 x i64> %598 to <4 x i32>
  %636 = bitcast <8 x i16> %626 to <4 x i32>
  %637 = add <4 x i32> %636, %635
  %638 = bitcast <2 x i64> %597 to <4 x i32>
  %639 = bitcast <8 x i16> %628 to <4 x i32>
  %640 = add <4 x i32> %639, %638
  %641 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %631, <4 x i32> %634) #8
  %642 = bitcast <8 x i16> %641 to <2 x i64>
  %643 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %637, <4 x i32> %640) #8
  %644 = bitcast <8 x i16> %643 to <2 x i64>
  %645 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %646 = add <8 x i16> %645, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %647 = icmp slt <8 x i16> %646, %641
  %648 = sext <8 x i1> %647 to <8 x i16>
  %649 = bitcast <8 x i16> %648 to <2 x i64>
  %650 = xor <2 x i64> %649, <i64 -1, i64 -1>
  %651 = and <2 x i64> %650, %642
  %652 = and <8 x i16> %646, %648
  %653 = bitcast <8 x i16> %652 to <2 x i64>
  %654 = or <2 x i64> %651, %653
  %655 = bitcast <2 x i64> %654 to <8 x i16>
  %656 = icmp sgt <8 x i16> %655, zeroinitializer
  %657 = sext <8 x i1> %656 to <8 x i16>
  %658 = bitcast <8 x i16> %657 to <2 x i64>
  %659 = and <2 x i64> %654, %658
  %660 = icmp slt <8 x i16> %646, %643
  %661 = sext <8 x i1> %660 to <8 x i16>
  %662 = bitcast <8 x i16> %661 to <2 x i64>
  %663 = xor <2 x i64> %662, <i64 -1, i64 -1>
  %664 = and <2 x i64> %663, %644
  %665 = and <8 x i16> %646, %661
  br label %6055

666:                                              ; preds = %5
  %667 = bitcast i32* %0 to <4 x i32>*
  %668 = load <4 x i32>, <4 x i32>* %667, align 16
  %669 = getelementptr inbounds i32, i32* %0, i64 4
  %670 = bitcast i32* %669 to <4 x i32>*
  %671 = load <4 x i32>, <4 x i32>* %670, align 16
  %672 = getelementptr inbounds i32, i32* %0, i64 8
  %673 = bitcast i32* %672 to <4 x i32>*
  %674 = load <4 x i32>, <4 x i32>* %673, align 16
  %675 = getelementptr inbounds i32, i32* %0, i64 12
  %676 = bitcast i32* %675 to <4 x i32>*
  %677 = load <4 x i32>, <4 x i32>* %676, align 16
  %678 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 0, i64 0), align 16
  %679 = sext i8 %678 to i32
  %680 = add nsw i32 %679, -10
  %681 = sext i32 %680 to i64
  %682 = add nsw i32 %679, 3
  %683 = shl i32 1, %682
  %684 = insertelement <4 x i32> undef, i32 %683, i32 0
  %685 = shufflevector <4 x i32> %684, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %686 = shufflevector <4 x i32> %685, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %687 = bitcast <4 x i32> %686 to <2 x i64>
  %688 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %681, i64 1
  %689 = load i32, i32* %688, align 4
  %690 = insertelement <4 x i32> undef, i32 %689, i32 0
  %691 = shufflevector <4 x i32> %690, <4 x i32> undef, <4 x i32> zeroinitializer
  %692 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %681, i64 2
  %693 = load i32, i32* %692, align 4
  %694 = insertelement <4 x i32> undef, i32 %693, i32 0
  %695 = shufflevector <4 x i32> %694, <4 x i32> undef, <4 x i32> zeroinitializer
  %696 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %681, i64 3
  %697 = load i32, i32* %696, align 4
  %698 = insertelement <4 x i32> undef, i32 %697, i32 0
  %699 = shufflevector <4 x i32> %698, <4 x i32> undef, <4 x i32> zeroinitializer
  %700 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %681, i64 4
  %701 = load i32, i32* %700, align 4
  %702 = insertelement <4 x i32> undef, i32 %701, i32 0
  %703 = shufflevector <4 x i32> %702, <4 x i32> undef, <4 x i32> zeroinitializer
  %704 = shufflevector <4 x i32> %668, <4 x i32> %671, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %705 = bitcast <4 x i32> %704 to <2 x i64>
  %706 = shufflevector <4 x i32> %668, <4 x i32> %671, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %707 = bitcast <4 x i32> %706 to <2 x i64>
  %708 = shufflevector <4 x i32> %674, <4 x i32> %677, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %709 = bitcast <4 x i32> %708 to <2 x i64>
  %710 = shufflevector <4 x i32> %674, <4 x i32> %677, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %711 = bitcast <4 x i32> %710 to <2 x i64>
  %712 = shufflevector <2 x i64> %705, <2 x i64> %709, <2 x i32> <i32 0, i32 2>
  %713 = shufflevector <2 x i64> %705, <2 x i64> %709, <2 x i32> <i32 1, i32 3>
  %714 = shufflevector <2 x i64> %707, <2 x i64> %711, <2 x i32> <i32 0, i32 2>
  %715 = shufflevector <2 x i64> %707, <2 x i64> %711, <2 x i32> <i32 1, i32 3>
  %716 = bitcast <2 x i64> %712 to <4 x i32>
  %717 = mul <4 x i32> %691, %716
  %718 = mul <4 x i32> %695, %716
  %719 = bitcast <2 x i64> %713 to <4 x i32>
  %720 = mul <4 x i32> %699, %719
  %721 = bitcast <2 x i64> %714 to <4 x i32>
  %722 = mul <4 x i32> %703, %721
  %723 = mul <4 x i32> %691, %721
  %724 = bitcast <2 x i64> %715 to <4 x i32>
  %725 = mul <4 x i32> %695, %724
  %726 = sub <4 x i32> %716, %721
  %727 = add <4 x i32> %726, %724
  %728 = add <4 x i32> %725, %717
  %729 = add <4 x i32> %728, %722
  %730 = sub <4 x i32> %718, %723
  %731 = mul <4 x i32> %703, %724
  %732 = sub <4 x i32> %730, %731
  %733 = mul <4 x i32> %727, %699
  %734 = bitcast <4 x i32> %733 to <2 x i64>
  %735 = add <4 x i32> %729, %720
  %736 = bitcast <4 x i32> %735 to <2 x i64>
  %737 = add <4 x i32> %732, %720
  %738 = bitcast <4 x i32> %737 to <2 x i64>
  %739 = sub <4 x i32> %729, %720
  %740 = add <4 x i32> %739, %732
  %741 = bitcast <4 x i32> %740 to <2 x i64>
  %742 = shl <2 x i64> %736, <i64 32, i64 32>
  %743 = ashr exact <2 x i64> %742, <i64 28, i64 28>
  %744 = add <2 x i64> %743, %687
  %745 = bitcast <4 x i32> %735 to <16 x i8>
  %746 = shufflevector <16 x i8> %745, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %747 = bitcast <16 x i8> %746 to <2 x i64>
  %748 = shl <2 x i64> %747, <i64 32, i64 32>
  %749 = ashr exact <2 x i64> %748, <i64 28, i64 28>
  %750 = add <2 x i64> %749, %687
  %751 = bitcast <2 x i64> %744 to <16 x i8>
  %752 = shufflevector <16 x i8> %751, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %753 = bitcast <2 x i64> %750 to <16 x i8>
  %754 = shufflevector <16 x i8> %753, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %755 = bitcast <16 x i8> %752 to <4 x i32>
  %756 = bitcast <16 x i8> %754 to <4 x i32>
  %757 = shufflevector <4 x i32> %755, <4 x i32> %756, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %758 = bitcast <4 x i32> %757 to <2 x i64>
  %759 = shufflevector <4 x i32> %755, <4 x i32> %756, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %760 = bitcast <4 x i32> %759 to <2 x i64>
  %761 = shufflevector <2 x i64> %758, <2 x i64> %760, <2 x i32> <i32 0, i32 2>
  %762 = shl <2 x i64> %738, <i64 32, i64 32>
  %763 = ashr exact <2 x i64> %762, <i64 28, i64 28>
  %764 = add <2 x i64> %763, %687
  %765 = bitcast <4 x i32> %737 to <16 x i8>
  %766 = shufflevector <16 x i8> %765, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %767 = bitcast <16 x i8> %766 to <2 x i64>
  %768 = shl <2 x i64> %767, <i64 32, i64 32>
  %769 = ashr exact <2 x i64> %768, <i64 28, i64 28>
  %770 = add <2 x i64> %769, %687
  %771 = bitcast <2 x i64> %764 to <16 x i8>
  %772 = shufflevector <16 x i8> %771, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %773 = bitcast <2 x i64> %770 to <16 x i8>
  %774 = shufflevector <16 x i8> %773, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %775 = bitcast <16 x i8> %772 to <4 x i32>
  %776 = bitcast <16 x i8> %774 to <4 x i32>
  %777 = shufflevector <4 x i32> %775, <4 x i32> %776, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %778 = bitcast <4 x i32> %777 to <2 x i64>
  %779 = shufflevector <4 x i32> %775, <4 x i32> %776, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %780 = bitcast <4 x i32> %779 to <2 x i64>
  %781 = shufflevector <2 x i64> %778, <2 x i64> %780, <2 x i32> <i32 0, i32 2>
  %782 = shl <2 x i64> %734, <i64 32, i64 32>
  %783 = ashr exact <2 x i64> %782, <i64 28, i64 28>
  %784 = add <2 x i64> %783, %687
  %785 = bitcast <4 x i32> %733 to <16 x i8>
  %786 = shufflevector <16 x i8> %785, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %787 = bitcast <16 x i8> %786 to <2 x i64>
  %788 = shl <2 x i64> %787, <i64 32, i64 32>
  %789 = ashr exact <2 x i64> %788, <i64 28, i64 28>
  %790 = add <2 x i64> %789, %687
  %791 = bitcast <2 x i64> %784 to <16 x i8>
  %792 = shufflevector <16 x i8> %791, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %793 = bitcast <2 x i64> %790 to <16 x i8>
  %794 = shufflevector <16 x i8> %793, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %795 = bitcast <16 x i8> %792 to <4 x i32>
  %796 = bitcast <16 x i8> %794 to <4 x i32>
  %797 = shufflevector <4 x i32> %795, <4 x i32> %796, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %798 = bitcast <4 x i32> %797 to <2 x i64>
  %799 = shufflevector <4 x i32> %795, <4 x i32> %796, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %800 = bitcast <4 x i32> %799 to <2 x i64>
  %801 = shufflevector <2 x i64> %798, <2 x i64> %800, <2 x i32> <i32 0, i32 2>
  %802 = shl <2 x i64> %741, <i64 32, i64 32>
  %803 = ashr exact <2 x i64> %802, <i64 28, i64 28>
  %804 = add <2 x i64> %803, %687
  %805 = bitcast <4 x i32> %740 to <16 x i8>
  %806 = shufflevector <16 x i8> %805, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %807 = bitcast <16 x i8> %806 to <2 x i64>
  %808 = shl <2 x i64> %807, <i64 32, i64 32>
  %809 = ashr exact <2 x i64> %808, <i64 28, i64 28>
  %810 = add <2 x i64> %809, %687
  %811 = bitcast <2 x i64> %804 to <16 x i8>
  %812 = shufflevector <16 x i8> %811, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %813 = bitcast <2 x i64> %810 to <16 x i8>
  %814 = shufflevector <16 x i8> %813, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %815 = bitcast <16 x i8> %812 to <4 x i32>
  %816 = bitcast <16 x i8> %814 to <4 x i32>
  %817 = shufflevector <4 x i32> %815, <4 x i32> %816, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %818 = bitcast <4 x i32> %817 to <2 x i64>
  %819 = shufflevector <4 x i32> %815, <4 x i32> %816, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %820 = bitcast <4 x i32> %819 to <2 x i64>
  %821 = shufflevector <2 x i64> %818, <2 x i64> %820, <2 x i32> <i32 0, i32 2>
  %822 = bitcast <2 x i64> %761 to <4 x i32>
  %823 = bitcast <2 x i64> %781 to <4 x i32>
  %824 = bitcast <2 x i64> %801 to <4 x i32>
  %825 = bitcast <2 x i64> %821 to <4 x i32>
  %826 = icmp sgt i32 %4, 10
  %827 = select i1 %826, i32 %4, i32 10
  %828 = shl i32 32, %827
  %829 = sub nsw i32 0, %828
  %830 = insertelement <4 x i32> undef, i32 %829, i32 0
  %831 = shufflevector <4 x i32> %830, <4 x i32> undef, <4 x i32> zeroinitializer
  %832 = add nsw i32 %828, -1
  %833 = insertelement <4 x i32> undef, i32 %832, i32 0
  %834 = shufflevector <4 x i32> %833, <4 x i32> undef, <4 x i32> zeroinitializer
  %835 = icmp slt <4 x i32> %831, %822
  %836 = select <4 x i1> %835, <4 x i32> %822, <4 x i32> %831
  %837 = icmp slt <4 x i32> %836, %834
  %838 = select <4 x i1> %837, <4 x i32> %836, <4 x i32> %834
  %839 = icmp slt <4 x i32> %831, %823
  %840 = select <4 x i1> %839, <4 x i32> %823, <4 x i32> %831
  %841 = icmp slt <4 x i32> %840, %834
  %842 = select <4 x i1> %841, <4 x i32> %840, <4 x i32> %834
  %843 = icmp slt <4 x i32> %831, %824
  %844 = select <4 x i1> %843, <4 x i32> %824, <4 x i32> %831
  %845 = icmp slt <4 x i32> %844, %834
  %846 = select <4 x i1> %845, <4 x i32> %844, <4 x i32> %834
  %847 = icmp slt <4 x i32> %831, %825
  %848 = select <4 x i1> %847, <4 x i32> %825, <4 x i32> %831
  %849 = icmp slt <4 x i32> %848, %834
  %850 = select <4 x i1> %849, <4 x i32> %848, <4 x i32> %834
  %851 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 0, i64 0), align 16
  %852 = sext i8 %851 to i32
  %853 = add nsw i32 %852, -10
  %854 = sext i32 %853 to i64
  %855 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %854, i64 32
  %856 = load i32, i32* %855, align 16
  %857 = insertelement <4 x i32> undef, i32 %856, i32 0
  %858 = shufflevector <4 x i32> %857, <4 x i32> undef, <4 x i32> zeroinitializer
  %859 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %854, i64 48
  %860 = load i32, i32* %859, align 16
  %861 = insertelement <4 x i32> undef, i32 %860, i32 0
  %862 = shufflevector <4 x i32> %861, <4 x i32> undef, <4 x i32> zeroinitializer
  %863 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %854, i64 16
  %864 = load i32, i32* %863, align 16
  %865 = insertelement <4 x i32> undef, i32 %864, i32 0
  %866 = shufflevector <4 x i32> %865, <4 x i32> undef, <4 x i32> zeroinitializer
  %867 = sub nsw i32 0, %864
  %868 = insertelement <4 x i32> undef, i32 %867, i32 0
  %869 = shufflevector <4 x i32> %868, <4 x i32> undef, <4 x i32> zeroinitializer
  %870 = add nsw i32 %852, -1
  %871 = shl i32 1, %870
  %872 = insertelement <4 x i32> undef, i32 %871, i32 0
  %873 = shufflevector <4 x i32> %872, <4 x i32> undef, <4 x i32> zeroinitializer
  %874 = icmp slt i32 %4, 10
  %875 = add i32 %4, 5
  %876 = shl i32 1, %875
  %877 = select i1 %874, i32 32768, i32 %876
  %878 = sub nsw i32 0, %877
  %879 = insertelement <4 x i32> undef, i32 %878, i32 0
  %880 = shufflevector <4 x i32> %879, <4 x i32> undef, <4 x i32> zeroinitializer
  %881 = add nsw i32 %877, -1
  %882 = insertelement <4 x i32> undef, i32 %881, i32 0
  %883 = shufflevector <4 x i32> %882, <4 x i32> undef, <4 x i32> zeroinitializer
  %884 = shufflevector <4 x i32> %838, <4 x i32> %842, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %885 = bitcast <4 x i32> %884 to <2 x i64>
  %886 = shufflevector <4 x i32> %838, <4 x i32> %842, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %887 = bitcast <4 x i32> %886 to <2 x i64>
  %888 = shufflevector <4 x i32> %846, <4 x i32> %850, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %889 = bitcast <4 x i32> %888 to <2 x i64>
  %890 = shufflevector <4 x i32> %846, <4 x i32> %850, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %891 = bitcast <4 x i32> %890 to <2 x i64>
  %892 = shufflevector <2 x i64> %885, <2 x i64> %889, <2 x i32> <i32 0, i32 2>
  %893 = shufflevector <2 x i64> %885, <2 x i64> %889, <2 x i32> <i32 1, i32 3>
  %894 = shufflevector <2 x i64> %887, <2 x i64> %891, <2 x i32> <i32 0, i32 2>
  %895 = shufflevector <2 x i64> %887, <2 x i64> %891, <2 x i32> <i32 1, i32 3>
  %896 = bitcast <2 x i64> %892 to <4 x i32>
  %897 = mul <4 x i32> %858, %896
  %898 = bitcast <2 x i64> %894 to <4 x i32>
  %899 = mul <4 x i32> %858, %898
  %900 = add <4 x i32> %897, %873
  %901 = add <4 x i32> %900, %899
  %902 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %901, i32 %852) #8
  %903 = sub <4 x i32> %873, %899
  %904 = add <4 x i32> %903, %897
  %905 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %904, i32 %852) #8
  %906 = bitcast <2 x i64> %893 to <4 x i32>
  %907 = mul <4 x i32> %862, %906
  %908 = bitcast <2 x i64> %895 to <4 x i32>
  %909 = mul <4 x i32> %869, %908
  %910 = add <4 x i32> %907, %873
  %911 = add <4 x i32> %910, %909
  %912 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %911, i32 %852) #8
  %913 = mul <4 x i32> %866, %906
  %914 = mul <4 x i32> %862, %908
  %915 = add <4 x i32> %913, %873
  %916 = add <4 x i32> %915, %914
  %917 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %916, i32 %852) #8
  %918 = add <4 x i32> %917, %902
  %919 = sub <4 x i32> %902, %917
  %920 = icmp sgt <4 x i32> %918, %880
  %921 = select <4 x i1> %920, <4 x i32> %918, <4 x i32> %880
  %922 = icmp slt <4 x i32> %921, %883
  %923 = select <4 x i1> %922, <4 x i32> %921, <4 x i32> %883
  %924 = icmp sgt <4 x i32> %919, %880
  %925 = select <4 x i1> %924, <4 x i32> %919, <4 x i32> %880
  %926 = icmp slt <4 x i32> %925, %883
  %927 = select <4 x i1> %926, <4 x i32> %925, <4 x i32> %883
  %928 = add <4 x i32> %912, %905
  %929 = sub <4 x i32> %905, %912
  %930 = icmp sgt <4 x i32> %928, %880
  %931 = select <4 x i1> %930, <4 x i32> %928, <4 x i32> %880
  %932 = icmp slt <4 x i32> %931, %883
  %933 = select <4 x i1> %932, <4 x i32> %931, <4 x i32> %883
  %934 = icmp sgt <4 x i32> %929, %880
  %935 = select <4 x i1> %934, <4 x i32> %929, <4 x i32> %880
  %936 = icmp slt <4 x i32> %935, %883
  %937 = select <4 x i1> %936, <4 x i32> %935, <4 x i32> %883
  %938 = getelementptr inbounds i8, i8* %6, i64 1
  %939 = load i8, i8* %938, align 1
  %940 = sext i8 %939 to i32
  %941 = sub nsw i32 0, %940
  %942 = icmp eq i8 %939, 0
  br i1 %942, label %956, label %943

943:                                              ; preds = %666
  %944 = xor i32 %940, -1
  %945 = shl i32 1, %944
  %946 = insertelement <4 x i32> undef, i32 %945, i32 0
  %947 = shufflevector <4 x i32> %946, <4 x i32> undef, <4 x i32> zeroinitializer
  %948 = add <4 x i32> %923, %947
  %949 = add <4 x i32> %947, %933
  %950 = add <4 x i32> %947, %937
  %951 = add <4 x i32> %927, %947
  %952 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %948, i32 %941) #8
  %953 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %949, i32 %941) #8
  %954 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %950, i32 %941) #8
  %955 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %951, i32 %941) #8
  br label %956

956:                                              ; preds = %666, %943
  %957 = phi <4 x i32> [ %927, %666 ], [ %955, %943 ]
  %958 = phi <4 x i32> [ %937, %666 ], [ %954, %943 ]
  %959 = phi <4 x i32> [ %933, %666 ], [ %953, %943 ]
  %960 = phi <4 x i32> [ %923, %666 ], [ %952, %943 ]
  %961 = bitcast i16* %1 to i64*
  %962 = load i64, i64* %961, align 1
  %963 = insertelement <2 x i64> undef, i64 %962, i32 0
  %964 = sext i32 %2 to i64
  %965 = getelementptr inbounds i16, i16* %1, i64 %964
  %966 = bitcast i16* %965 to i64*
  %967 = load i64, i64* %966, align 1
  %968 = insertelement <2 x i64> undef, i64 %967, i32 0
  %969 = shl nsw i32 %2, 1
  %970 = sext i32 %969 to i64
  %971 = getelementptr inbounds i16, i16* %1, i64 %970
  %972 = bitcast i16* %971 to i64*
  %973 = load i64, i64* %972, align 1
  %974 = insertelement <2 x i64> undef, i64 %973, i32 0
  %975 = mul nsw i32 %2, 3
  %976 = sext i32 %975 to i64
  %977 = getelementptr inbounds i16, i16* %1, i64 %976
  %978 = bitcast i16* %977 to i64*
  %979 = load i64, i64* %978, align 1
  %980 = insertelement <2 x i64> undef, i64 %979, i32 0
  %981 = bitcast <2 x i64> %963 to <8 x i16>
  %982 = shufflevector <8 x i16> %981, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %983 = bitcast <2 x i64> %968 to <8 x i16>
  %984 = shufflevector <8 x i16> %983, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %985 = bitcast <2 x i64> %974 to <8 x i16>
  %986 = shufflevector <8 x i16> %985, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %987 = bitcast <2 x i64> %980 to <8 x i16>
  %988 = shufflevector <8 x i16> %987, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %989 = bitcast <8 x i16> %982 to <4 x i32>
  %990 = add <4 x i32> %960, %989
  %991 = bitcast <8 x i16> %984 to <4 x i32>
  %992 = add <4 x i32> %959, %991
  %993 = bitcast <8 x i16> %986 to <4 x i32>
  %994 = add <4 x i32> %958, %993
  %995 = bitcast <8 x i16> %988 to <4 x i32>
  %996 = add <4 x i32> %957, %995
  %997 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %990, <4 x i32> %992) #8
  %998 = bitcast <8 x i16> %997 to <2 x i64>
  %999 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %994, <4 x i32> %996) #8
  %1000 = bitcast <8 x i16> %999 to <2 x i64>
  %1001 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %1002 = add <8 x i16> %1001, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %1003 = icmp slt <8 x i16> %1002, %997
  %1004 = sext <8 x i1> %1003 to <8 x i16>
  %1005 = bitcast <8 x i16> %1004 to <2 x i64>
  %1006 = xor <2 x i64> %1005, <i64 -1, i64 -1>
  %1007 = and <2 x i64> %1006, %998
  %1008 = and <8 x i16> %1002, %1004
  %1009 = bitcast <8 x i16> %1008 to <2 x i64>
  %1010 = or <2 x i64> %1007, %1009
  %1011 = bitcast <2 x i64> %1010 to <8 x i16>
  %1012 = icmp sgt <8 x i16> %1011, zeroinitializer
  %1013 = sext <8 x i1> %1012 to <8 x i16>
  %1014 = bitcast <8 x i16> %1013 to <2 x i64>
  %1015 = and <2 x i64> %1010, %1014
  %1016 = icmp slt <8 x i16> %1002, %999
  %1017 = sext <8 x i1> %1016 to <8 x i16>
  %1018 = bitcast <8 x i16> %1017 to <2 x i64>
  %1019 = xor <2 x i64> %1018, <i64 -1, i64 -1>
  %1020 = and <2 x i64> %1019, %1000
  %1021 = and <8 x i16> %1002, %1017
  br label %6055

1022:                                             ; preds = %5
  %1023 = bitcast i32* %0 to <4 x i32>*
  %1024 = load <4 x i32>, <4 x i32>* %1023, align 16
  %1025 = getelementptr inbounds i32, i32* %0, i64 4
  %1026 = bitcast i32* %1025 to <4 x i32>*
  %1027 = load <4 x i32>, <4 x i32>* %1026, align 16
  %1028 = getelementptr inbounds i32, i32* %0, i64 8
  %1029 = bitcast i32* %1028 to <4 x i32>*
  %1030 = load <4 x i32>, <4 x i32>* %1029, align 16
  %1031 = getelementptr inbounds i32, i32* %0, i64 12
  %1032 = bitcast i32* %1031 to <4 x i32>*
  %1033 = load <4 x i32>, <4 x i32>* %1032, align 16
  %1034 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 0, i64 0), align 16
  %1035 = sext i8 %1034 to i32
  %1036 = add nsw i32 %1035, -10
  %1037 = sext i32 %1036 to i64
  %1038 = add nsw i32 %1035, 3
  %1039 = shl i32 1, %1038
  %1040 = insertelement <4 x i32> undef, i32 %1039, i32 0
  %1041 = shufflevector <4 x i32> %1040, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %1042 = shufflevector <4 x i32> %1041, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1043 = bitcast <4 x i32> %1042 to <2 x i64>
  %1044 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1037, i64 1
  %1045 = load i32, i32* %1044, align 4
  %1046 = insertelement <4 x i32> undef, i32 %1045, i32 0
  %1047 = shufflevector <4 x i32> %1046, <4 x i32> undef, <4 x i32> zeroinitializer
  %1048 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1037, i64 2
  %1049 = load i32, i32* %1048, align 4
  %1050 = insertelement <4 x i32> undef, i32 %1049, i32 0
  %1051 = shufflevector <4 x i32> %1050, <4 x i32> undef, <4 x i32> zeroinitializer
  %1052 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1037, i64 3
  %1053 = load i32, i32* %1052, align 4
  %1054 = insertelement <4 x i32> undef, i32 %1053, i32 0
  %1055 = shufflevector <4 x i32> %1054, <4 x i32> undef, <4 x i32> zeroinitializer
  %1056 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1037, i64 4
  %1057 = load i32, i32* %1056, align 4
  %1058 = insertelement <4 x i32> undef, i32 %1057, i32 0
  %1059 = shufflevector <4 x i32> %1058, <4 x i32> undef, <4 x i32> zeroinitializer
  %1060 = shufflevector <4 x i32> %1024, <4 x i32> %1027, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1061 = bitcast <4 x i32> %1060 to <2 x i64>
  %1062 = shufflevector <4 x i32> %1024, <4 x i32> %1027, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1063 = bitcast <4 x i32> %1062 to <2 x i64>
  %1064 = shufflevector <4 x i32> %1030, <4 x i32> %1033, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1065 = bitcast <4 x i32> %1064 to <2 x i64>
  %1066 = shufflevector <4 x i32> %1030, <4 x i32> %1033, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1067 = bitcast <4 x i32> %1066 to <2 x i64>
  %1068 = shufflevector <2 x i64> %1061, <2 x i64> %1065, <2 x i32> <i32 0, i32 2>
  %1069 = shufflevector <2 x i64> %1061, <2 x i64> %1065, <2 x i32> <i32 1, i32 3>
  %1070 = shufflevector <2 x i64> %1063, <2 x i64> %1067, <2 x i32> <i32 0, i32 2>
  %1071 = shufflevector <2 x i64> %1063, <2 x i64> %1067, <2 x i32> <i32 1, i32 3>
  %1072 = bitcast <2 x i64> %1068 to <4 x i32>
  %1073 = mul <4 x i32> %1047, %1072
  %1074 = mul <4 x i32> %1051, %1072
  %1075 = bitcast <2 x i64> %1069 to <4 x i32>
  %1076 = mul <4 x i32> %1055, %1075
  %1077 = bitcast <2 x i64> %1070 to <4 x i32>
  %1078 = mul <4 x i32> %1059, %1077
  %1079 = mul <4 x i32> %1047, %1077
  %1080 = bitcast <2 x i64> %1071 to <4 x i32>
  %1081 = mul <4 x i32> %1051, %1080
  %1082 = sub <4 x i32> %1072, %1077
  %1083 = add <4 x i32> %1082, %1080
  %1084 = add <4 x i32> %1081, %1073
  %1085 = add <4 x i32> %1084, %1078
  %1086 = sub <4 x i32> %1074, %1079
  %1087 = mul <4 x i32> %1059, %1080
  %1088 = sub <4 x i32> %1086, %1087
  %1089 = mul <4 x i32> %1083, %1055
  %1090 = bitcast <4 x i32> %1089 to <2 x i64>
  %1091 = add <4 x i32> %1085, %1076
  %1092 = bitcast <4 x i32> %1091 to <2 x i64>
  %1093 = add <4 x i32> %1088, %1076
  %1094 = bitcast <4 x i32> %1093 to <2 x i64>
  %1095 = sub <4 x i32> %1085, %1076
  %1096 = add <4 x i32> %1095, %1088
  %1097 = bitcast <4 x i32> %1096 to <2 x i64>
  %1098 = shl <2 x i64> %1092, <i64 32, i64 32>
  %1099 = ashr exact <2 x i64> %1098, <i64 28, i64 28>
  %1100 = add <2 x i64> %1099, %1043
  %1101 = bitcast <4 x i32> %1091 to <16 x i8>
  %1102 = shufflevector <16 x i8> %1101, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1103 = bitcast <16 x i8> %1102 to <2 x i64>
  %1104 = shl <2 x i64> %1103, <i64 32, i64 32>
  %1105 = ashr exact <2 x i64> %1104, <i64 28, i64 28>
  %1106 = add <2 x i64> %1105, %1043
  %1107 = bitcast <2 x i64> %1100 to <16 x i8>
  %1108 = shufflevector <16 x i8> %1107, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1109 = bitcast <2 x i64> %1106 to <16 x i8>
  %1110 = shufflevector <16 x i8> %1109, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1111 = bitcast <16 x i8> %1108 to <4 x i32>
  %1112 = bitcast <16 x i8> %1110 to <4 x i32>
  %1113 = shufflevector <4 x i32> %1111, <4 x i32> %1112, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1114 = bitcast <4 x i32> %1113 to <2 x i64>
  %1115 = shufflevector <4 x i32> %1111, <4 x i32> %1112, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1116 = bitcast <4 x i32> %1115 to <2 x i64>
  %1117 = shufflevector <2 x i64> %1114, <2 x i64> %1116, <2 x i32> <i32 0, i32 2>
  %1118 = shl <2 x i64> %1094, <i64 32, i64 32>
  %1119 = ashr exact <2 x i64> %1118, <i64 28, i64 28>
  %1120 = add <2 x i64> %1119, %1043
  %1121 = bitcast <4 x i32> %1093 to <16 x i8>
  %1122 = shufflevector <16 x i8> %1121, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1123 = bitcast <16 x i8> %1122 to <2 x i64>
  %1124 = shl <2 x i64> %1123, <i64 32, i64 32>
  %1125 = ashr exact <2 x i64> %1124, <i64 28, i64 28>
  %1126 = add <2 x i64> %1125, %1043
  %1127 = bitcast <2 x i64> %1120 to <16 x i8>
  %1128 = shufflevector <16 x i8> %1127, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1129 = bitcast <2 x i64> %1126 to <16 x i8>
  %1130 = shufflevector <16 x i8> %1129, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1131 = bitcast <16 x i8> %1128 to <4 x i32>
  %1132 = bitcast <16 x i8> %1130 to <4 x i32>
  %1133 = shufflevector <4 x i32> %1131, <4 x i32> %1132, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1134 = bitcast <4 x i32> %1133 to <2 x i64>
  %1135 = shufflevector <4 x i32> %1131, <4 x i32> %1132, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1136 = bitcast <4 x i32> %1135 to <2 x i64>
  %1137 = shufflevector <2 x i64> %1134, <2 x i64> %1136, <2 x i32> <i32 0, i32 2>
  %1138 = shl <2 x i64> %1090, <i64 32, i64 32>
  %1139 = ashr exact <2 x i64> %1138, <i64 28, i64 28>
  %1140 = add <2 x i64> %1139, %1043
  %1141 = bitcast <4 x i32> %1089 to <16 x i8>
  %1142 = shufflevector <16 x i8> %1141, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1143 = bitcast <16 x i8> %1142 to <2 x i64>
  %1144 = shl <2 x i64> %1143, <i64 32, i64 32>
  %1145 = ashr exact <2 x i64> %1144, <i64 28, i64 28>
  %1146 = add <2 x i64> %1145, %1043
  %1147 = bitcast <2 x i64> %1140 to <16 x i8>
  %1148 = shufflevector <16 x i8> %1147, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1149 = bitcast <2 x i64> %1146 to <16 x i8>
  %1150 = shufflevector <16 x i8> %1149, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1151 = bitcast <16 x i8> %1148 to <4 x i32>
  %1152 = bitcast <16 x i8> %1150 to <4 x i32>
  %1153 = shufflevector <4 x i32> %1151, <4 x i32> %1152, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1154 = bitcast <4 x i32> %1153 to <2 x i64>
  %1155 = shufflevector <4 x i32> %1151, <4 x i32> %1152, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1156 = bitcast <4 x i32> %1155 to <2 x i64>
  %1157 = shufflevector <2 x i64> %1154, <2 x i64> %1156, <2 x i32> <i32 0, i32 2>
  %1158 = shl <2 x i64> %1097, <i64 32, i64 32>
  %1159 = ashr exact <2 x i64> %1158, <i64 28, i64 28>
  %1160 = add <2 x i64> %1159, %1043
  %1161 = bitcast <4 x i32> %1096 to <16 x i8>
  %1162 = shufflevector <16 x i8> %1161, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1163 = bitcast <16 x i8> %1162 to <2 x i64>
  %1164 = shl <2 x i64> %1163, <i64 32, i64 32>
  %1165 = ashr exact <2 x i64> %1164, <i64 28, i64 28>
  %1166 = add <2 x i64> %1165, %1043
  %1167 = bitcast <2 x i64> %1160 to <16 x i8>
  %1168 = shufflevector <16 x i8> %1167, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1169 = bitcast <2 x i64> %1166 to <16 x i8>
  %1170 = shufflevector <16 x i8> %1169, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1171 = bitcast <16 x i8> %1168 to <4 x i32>
  %1172 = bitcast <16 x i8> %1170 to <4 x i32>
  %1173 = shufflevector <4 x i32> %1171, <4 x i32> %1172, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1174 = bitcast <4 x i32> %1173 to <2 x i64>
  %1175 = shufflevector <4 x i32> %1171, <4 x i32> %1172, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1176 = bitcast <4 x i32> %1175 to <2 x i64>
  %1177 = shufflevector <2 x i64> %1174, <2 x i64> %1176, <2 x i32> <i32 0, i32 2>
  %1178 = bitcast <2 x i64> %1117 to <4 x i32>
  %1179 = bitcast <2 x i64> %1137 to <4 x i32>
  %1180 = bitcast <2 x i64> %1157 to <4 x i32>
  %1181 = bitcast <2 x i64> %1177 to <4 x i32>
  %1182 = icmp sgt i32 %4, 10
  %1183 = select i1 %1182, i32 %4, i32 10
  %1184 = shl i32 32, %1183
  %1185 = sub nsw i32 0, %1184
  %1186 = insertelement <4 x i32> undef, i32 %1185, i32 0
  %1187 = shufflevector <4 x i32> %1186, <4 x i32> undef, <4 x i32> zeroinitializer
  %1188 = add nsw i32 %1184, -1
  %1189 = insertelement <4 x i32> undef, i32 %1188, i32 0
  %1190 = shufflevector <4 x i32> %1189, <4 x i32> undef, <4 x i32> zeroinitializer
  %1191 = icmp slt <4 x i32> %1187, %1178
  %1192 = select <4 x i1> %1191, <4 x i32> %1178, <4 x i32> %1187
  %1193 = icmp slt <4 x i32> %1192, %1190
  %1194 = select <4 x i1> %1193, <4 x i32> %1192, <4 x i32> %1190
  %1195 = icmp slt <4 x i32> %1187, %1179
  %1196 = select <4 x i1> %1195, <4 x i32> %1179, <4 x i32> %1187
  %1197 = icmp slt <4 x i32> %1196, %1190
  %1198 = select <4 x i1> %1197, <4 x i32> %1196, <4 x i32> %1190
  %1199 = icmp slt <4 x i32> %1187, %1180
  %1200 = select <4 x i1> %1199, <4 x i32> %1180, <4 x i32> %1187
  %1201 = icmp slt <4 x i32> %1200, %1190
  %1202 = select <4 x i1> %1201, <4 x i32> %1200, <4 x i32> %1190
  %1203 = icmp slt <4 x i32> %1187, %1181
  %1204 = select <4 x i1> %1203, <4 x i32> %1181, <4 x i32> %1187
  %1205 = icmp slt <4 x i32> %1204, %1190
  %1206 = select <4 x i1> %1205, <4 x i32> %1204, <4 x i32> %1190
  %1207 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 0, i64 0), align 16
  %1208 = sext i8 %1207 to i32
  %1209 = add nsw i32 %1208, -10
  %1210 = sext i32 %1209 to i64
  %1211 = add nsw i32 %1208, 3
  %1212 = shl i32 1, %1211
  %1213 = insertelement <4 x i32> undef, i32 %1212, i32 0
  %1214 = shufflevector <4 x i32> %1213, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %1215 = shufflevector <4 x i32> %1214, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1216 = bitcast <4 x i32> %1215 to <2 x i64>
  %1217 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1210, i64 1
  %1218 = load i32, i32* %1217, align 4
  %1219 = insertelement <4 x i32> undef, i32 %1218, i32 0
  %1220 = shufflevector <4 x i32> %1219, <4 x i32> undef, <4 x i32> zeroinitializer
  %1221 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1210, i64 2
  %1222 = load i32, i32* %1221, align 4
  %1223 = insertelement <4 x i32> undef, i32 %1222, i32 0
  %1224 = shufflevector <4 x i32> %1223, <4 x i32> undef, <4 x i32> zeroinitializer
  %1225 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1210, i64 3
  %1226 = load i32, i32* %1225, align 4
  %1227 = insertelement <4 x i32> undef, i32 %1226, i32 0
  %1228 = shufflevector <4 x i32> %1227, <4 x i32> undef, <4 x i32> zeroinitializer
  %1229 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1210, i64 4
  %1230 = load i32, i32* %1229, align 4
  %1231 = insertelement <4 x i32> undef, i32 %1230, i32 0
  %1232 = shufflevector <4 x i32> %1231, <4 x i32> undef, <4 x i32> zeroinitializer
  %1233 = shufflevector <4 x i32> %1194, <4 x i32> %1198, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1234 = bitcast <4 x i32> %1233 to <2 x i64>
  %1235 = shufflevector <4 x i32> %1194, <4 x i32> %1198, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1236 = bitcast <4 x i32> %1235 to <2 x i64>
  %1237 = shufflevector <4 x i32> %1202, <4 x i32> %1206, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1238 = bitcast <4 x i32> %1237 to <2 x i64>
  %1239 = shufflevector <4 x i32> %1202, <4 x i32> %1206, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1240 = bitcast <4 x i32> %1239 to <2 x i64>
  %1241 = shufflevector <2 x i64> %1234, <2 x i64> %1238, <2 x i32> <i32 0, i32 2>
  %1242 = shufflevector <2 x i64> %1234, <2 x i64> %1238, <2 x i32> <i32 1, i32 3>
  %1243 = shufflevector <2 x i64> %1236, <2 x i64> %1240, <2 x i32> <i32 0, i32 2>
  %1244 = shufflevector <2 x i64> %1236, <2 x i64> %1240, <2 x i32> <i32 1, i32 3>
  %1245 = bitcast <2 x i64> %1241 to <4 x i32>
  %1246 = mul <4 x i32> %1220, %1245
  %1247 = mul <4 x i32> %1224, %1245
  %1248 = bitcast <2 x i64> %1242 to <4 x i32>
  %1249 = mul <4 x i32> %1228, %1248
  %1250 = bitcast <2 x i64> %1243 to <4 x i32>
  %1251 = mul <4 x i32> %1232, %1250
  %1252 = mul <4 x i32> %1220, %1250
  %1253 = bitcast <2 x i64> %1244 to <4 x i32>
  %1254 = mul <4 x i32> %1224, %1253
  %1255 = sub <4 x i32> %1245, %1250
  %1256 = add <4 x i32> %1255, %1253
  %1257 = add <4 x i32> %1251, %1246
  %1258 = add <4 x i32> %1257, %1254
  %1259 = sub <4 x i32> %1247, %1252
  %1260 = mul <4 x i32> %1232, %1253
  %1261 = sub <4 x i32> %1259, %1260
  %1262 = mul <4 x i32> %1256, %1228
  %1263 = bitcast <4 x i32> %1262 to <2 x i64>
  %1264 = add <4 x i32> %1258, %1249
  %1265 = bitcast <4 x i32> %1264 to <2 x i64>
  %1266 = add <4 x i32> %1261, %1249
  %1267 = bitcast <4 x i32> %1266 to <2 x i64>
  %1268 = sub <4 x i32> %1258, %1249
  %1269 = add <4 x i32> %1268, %1261
  %1270 = bitcast <4 x i32> %1269 to <2 x i64>
  %1271 = shl <2 x i64> %1265, <i64 32, i64 32>
  %1272 = ashr exact <2 x i64> %1271, <i64 28, i64 28>
  %1273 = add <2 x i64> %1272, %1216
  %1274 = bitcast <4 x i32> %1264 to <16 x i8>
  %1275 = shufflevector <16 x i8> %1274, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1276 = bitcast <16 x i8> %1275 to <2 x i64>
  %1277 = shl <2 x i64> %1276, <i64 32, i64 32>
  %1278 = ashr exact <2 x i64> %1277, <i64 28, i64 28>
  %1279 = add <2 x i64> %1278, %1216
  %1280 = bitcast <2 x i64> %1273 to <16 x i8>
  %1281 = shufflevector <16 x i8> %1280, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1282 = bitcast <2 x i64> %1279 to <16 x i8>
  %1283 = shufflevector <16 x i8> %1282, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1284 = bitcast <16 x i8> %1281 to <4 x i32>
  %1285 = bitcast <16 x i8> %1283 to <4 x i32>
  %1286 = shufflevector <4 x i32> %1284, <4 x i32> %1285, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1287 = bitcast <4 x i32> %1286 to <2 x i64>
  %1288 = shufflevector <4 x i32> %1284, <4 x i32> %1285, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1289 = bitcast <4 x i32> %1288 to <2 x i64>
  %1290 = shufflevector <2 x i64> %1287, <2 x i64> %1289, <2 x i32> <i32 0, i32 2>
  %1291 = shl <2 x i64> %1267, <i64 32, i64 32>
  %1292 = ashr exact <2 x i64> %1291, <i64 28, i64 28>
  %1293 = add <2 x i64> %1292, %1216
  %1294 = bitcast <4 x i32> %1266 to <16 x i8>
  %1295 = shufflevector <16 x i8> %1294, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1296 = bitcast <16 x i8> %1295 to <2 x i64>
  %1297 = shl <2 x i64> %1296, <i64 32, i64 32>
  %1298 = ashr exact <2 x i64> %1297, <i64 28, i64 28>
  %1299 = add <2 x i64> %1298, %1216
  %1300 = bitcast <2 x i64> %1293 to <16 x i8>
  %1301 = shufflevector <16 x i8> %1300, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1302 = bitcast <2 x i64> %1299 to <16 x i8>
  %1303 = shufflevector <16 x i8> %1302, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1304 = bitcast <16 x i8> %1301 to <4 x i32>
  %1305 = bitcast <16 x i8> %1303 to <4 x i32>
  %1306 = shufflevector <4 x i32> %1304, <4 x i32> %1305, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1307 = bitcast <4 x i32> %1306 to <2 x i64>
  %1308 = shufflevector <4 x i32> %1304, <4 x i32> %1305, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1309 = bitcast <4 x i32> %1308 to <2 x i64>
  %1310 = shufflevector <2 x i64> %1307, <2 x i64> %1309, <2 x i32> <i32 0, i32 2>
  %1311 = shl <2 x i64> %1263, <i64 32, i64 32>
  %1312 = ashr exact <2 x i64> %1311, <i64 28, i64 28>
  %1313 = add <2 x i64> %1312, %1216
  %1314 = bitcast <4 x i32> %1262 to <16 x i8>
  %1315 = shufflevector <16 x i8> %1314, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1316 = bitcast <16 x i8> %1315 to <2 x i64>
  %1317 = shl <2 x i64> %1316, <i64 32, i64 32>
  %1318 = ashr exact <2 x i64> %1317, <i64 28, i64 28>
  %1319 = add <2 x i64> %1318, %1216
  %1320 = bitcast <2 x i64> %1313 to <16 x i8>
  %1321 = shufflevector <16 x i8> %1320, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1322 = bitcast <2 x i64> %1319 to <16 x i8>
  %1323 = shufflevector <16 x i8> %1322, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1324 = bitcast <16 x i8> %1321 to <4 x i32>
  %1325 = bitcast <16 x i8> %1323 to <4 x i32>
  %1326 = shufflevector <4 x i32> %1324, <4 x i32> %1325, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1327 = bitcast <4 x i32> %1326 to <2 x i64>
  %1328 = shufflevector <4 x i32> %1324, <4 x i32> %1325, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1329 = bitcast <4 x i32> %1328 to <2 x i64>
  %1330 = shufflevector <2 x i64> %1327, <2 x i64> %1329, <2 x i32> <i32 0, i32 2>
  %1331 = shl <2 x i64> %1270, <i64 32, i64 32>
  %1332 = ashr exact <2 x i64> %1331, <i64 28, i64 28>
  %1333 = add <2 x i64> %1332, %1216
  %1334 = bitcast <4 x i32> %1269 to <16 x i8>
  %1335 = shufflevector <16 x i8> %1334, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1336 = bitcast <16 x i8> %1335 to <2 x i64>
  %1337 = shl <2 x i64> %1336, <i64 32, i64 32>
  %1338 = ashr exact <2 x i64> %1337, <i64 28, i64 28>
  %1339 = add <2 x i64> %1338, %1216
  %1340 = bitcast <2 x i64> %1333 to <16 x i8>
  %1341 = shufflevector <16 x i8> %1340, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1342 = bitcast <2 x i64> %1339 to <16 x i8>
  %1343 = shufflevector <16 x i8> %1342, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1344 = bitcast <16 x i8> %1341 to <4 x i32>
  %1345 = bitcast <16 x i8> %1343 to <4 x i32>
  %1346 = shufflevector <4 x i32> %1344, <4 x i32> %1345, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1347 = bitcast <4 x i32> %1346 to <2 x i64>
  %1348 = shufflevector <4 x i32> %1344, <4 x i32> %1345, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1349 = bitcast <4 x i32> %1348 to <2 x i64>
  %1350 = shufflevector <2 x i64> %1347, <2 x i64> %1349, <2 x i32> <i32 0, i32 2>
  %1351 = getelementptr inbounds i8, i8* %6, i64 1
  %1352 = load i8, i8* %1351, align 1
  %1353 = sext i8 %1352 to i32
  %1354 = sub nsw i32 0, %1353
  %1355 = icmp eq i8 %1352, 0
  br i1 %1355, label %1377, label %1356

1356:                                             ; preds = %1022
  %1357 = xor i32 %1353, -1
  %1358 = shl i32 1, %1357
  %1359 = insertelement <4 x i32> undef, i32 %1358, i32 0
  %1360 = shufflevector <4 x i32> %1359, <4 x i32> undef, <4 x i32> zeroinitializer
  %1361 = bitcast <2 x i64> %1290 to <4 x i32>
  %1362 = add <4 x i32> %1360, %1361
  %1363 = bitcast <2 x i64> %1310 to <4 x i32>
  %1364 = add <4 x i32> %1360, %1363
  %1365 = bitcast <2 x i64> %1330 to <4 x i32>
  %1366 = add <4 x i32> %1360, %1365
  %1367 = bitcast <2 x i64> %1350 to <4 x i32>
  %1368 = add <4 x i32> %1360, %1367
  %1369 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1362, i32 %1354) #8
  %1370 = bitcast <4 x i32> %1369 to <2 x i64>
  %1371 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1364, i32 %1354) #8
  %1372 = bitcast <4 x i32> %1371 to <2 x i64>
  %1373 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1366, i32 %1354) #8
  %1374 = bitcast <4 x i32> %1373 to <2 x i64>
  %1375 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1368, i32 %1354) #8
  %1376 = bitcast <4 x i32> %1375 to <2 x i64>
  br label %1377

1377:                                             ; preds = %1022, %1356
  %1378 = phi <2 x i64> [ %1350, %1022 ], [ %1376, %1356 ]
  %1379 = phi <2 x i64> [ %1330, %1022 ], [ %1374, %1356 ]
  %1380 = phi <2 x i64> [ %1310, %1022 ], [ %1372, %1356 ]
  %1381 = phi <2 x i64> [ %1290, %1022 ], [ %1370, %1356 ]
  %1382 = bitcast i16* %1 to i64*
  %1383 = load i64, i64* %1382, align 1
  %1384 = insertelement <2 x i64> undef, i64 %1383, i32 0
  %1385 = sext i32 %2 to i64
  %1386 = getelementptr inbounds i16, i16* %1, i64 %1385
  %1387 = bitcast i16* %1386 to i64*
  %1388 = load i64, i64* %1387, align 1
  %1389 = insertelement <2 x i64> undef, i64 %1388, i32 0
  %1390 = shl nsw i32 %2, 1
  %1391 = sext i32 %1390 to i64
  %1392 = getelementptr inbounds i16, i16* %1, i64 %1391
  %1393 = bitcast i16* %1392 to i64*
  %1394 = load i64, i64* %1393, align 1
  %1395 = insertelement <2 x i64> undef, i64 %1394, i32 0
  %1396 = mul nsw i32 %2, 3
  %1397 = sext i32 %1396 to i64
  %1398 = getelementptr inbounds i16, i16* %1, i64 %1397
  %1399 = bitcast i16* %1398 to i64*
  %1400 = load i64, i64* %1399, align 1
  %1401 = insertelement <2 x i64> undef, i64 %1400, i32 0
  %1402 = bitcast <2 x i64> %1384 to <8 x i16>
  %1403 = shufflevector <8 x i16> %1402, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1404 = bitcast <2 x i64> %1389 to <8 x i16>
  %1405 = shufflevector <8 x i16> %1404, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1406 = bitcast <2 x i64> %1395 to <8 x i16>
  %1407 = shufflevector <8 x i16> %1406, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1408 = bitcast <2 x i64> %1401 to <8 x i16>
  %1409 = shufflevector <8 x i16> %1408, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1410 = bitcast <2 x i64> %1381 to <4 x i32>
  %1411 = bitcast <8 x i16> %1403 to <4 x i32>
  %1412 = add <4 x i32> %1411, %1410
  %1413 = bitcast <2 x i64> %1380 to <4 x i32>
  %1414 = bitcast <8 x i16> %1405 to <4 x i32>
  %1415 = add <4 x i32> %1414, %1413
  %1416 = bitcast <2 x i64> %1379 to <4 x i32>
  %1417 = bitcast <8 x i16> %1407 to <4 x i32>
  %1418 = add <4 x i32> %1417, %1416
  %1419 = bitcast <2 x i64> %1378 to <4 x i32>
  %1420 = bitcast <8 x i16> %1409 to <4 x i32>
  %1421 = add <4 x i32> %1420, %1419
  %1422 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1412, <4 x i32> %1415) #8
  %1423 = bitcast <8 x i16> %1422 to <2 x i64>
  %1424 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1418, <4 x i32> %1421) #8
  %1425 = bitcast <8 x i16> %1424 to <2 x i64>
  %1426 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %1427 = add <8 x i16> %1426, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %1428 = icmp slt <8 x i16> %1427, %1422
  %1429 = sext <8 x i1> %1428 to <8 x i16>
  %1430 = bitcast <8 x i16> %1429 to <2 x i64>
  %1431 = xor <2 x i64> %1430, <i64 -1, i64 -1>
  %1432 = and <2 x i64> %1431, %1423
  %1433 = and <8 x i16> %1427, %1429
  %1434 = bitcast <8 x i16> %1433 to <2 x i64>
  %1435 = or <2 x i64> %1432, %1434
  %1436 = bitcast <2 x i64> %1435 to <8 x i16>
  %1437 = icmp sgt <8 x i16> %1436, zeroinitializer
  %1438 = sext <8 x i1> %1437 to <8 x i16>
  %1439 = bitcast <8 x i16> %1438 to <2 x i64>
  %1440 = and <2 x i64> %1435, %1439
  %1441 = icmp slt <8 x i16> %1427, %1424
  %1442 = sext <8 x i1> %1441 to <8 x i16>
  %1443 = bitcast <8 x i16> %1442 to <2 x i64>
  %1444 = xor <2 x i64> %1443, <i64 -1, i64 -1>
  %1445 = and <2 x i64> %1444, %1425
  %1446 = and <8 x i16> %1427, %1442
  br label %6055

1447:                                             ; preds = %5
  %1448 = bitcast i32* %0 to <4 x i32>*
  %1449 = load <4 x i32>, <4 x i32>* %1448, align 16
  %1450 = getelementptr inbounds i32, i32* %0, i64 4
  %1451 = bitcast i32* %1450 to <4 x i32>*
  %1452 = load <4 x i32>, <4 x i32>* %1451, align 16
  %1453 = getelementptr inbounds i32, i32* %0, i64 8
  %1454 = bitcast i32* %1453 to <4 x i32>*
  %1455 = load <4 x i32>, <4 x i32>* %1454, align 16
  %1456 = getelementptr inbounds i32, i32* %0, i64 12
  %1457 = bitcast i32* %1456 to <4 x i32>*
  %1458 = load <4 x i32>, <4 x i32>* %1457, align 16
  %1459 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 0, i64 0), align 16
  %1460 = sext i8 %1459 to i32
  %1461 = add nsw i32 %1460, -10
  %1462 = sext i32 %1461 to i64
  %1463 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %1462, i64 32
  %1464 = load i32, i32* %1463, align 16
  %1465 = insertelement <4 x i32> undef, i32 %1464, i32 0
  %1466 = shufflevector <4 x i32> %1465, <4 x i32> undef, <4 x i32> zeroinitializer
  %1467 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %1462, i64 48
  %1468 = load i32, i32* %1467, align 16
  %1469 = insertelement <4 x i32> undef, i32 %1468, i32 0
  %1470 = shufflevector <4 x i32> %1469, <4 x i32> undef, <4 x i32> zeroinitializer
  %1471 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %1462, i64 16
  %1472 = load i32, i32* %1471, align 16
  %1473 = insertelement <4 x i32> undef, i32 %1472, i32 0
  %1474 = shufflevector <4 x i32> %1473, <4 x i32> undef, <4 x i32> zeroinitializer
  %1475 = sub nsw i32 0, %1472
  %1476 = insertelement <4 x i32> undef, i32 %1475, i32 0
  %1477 = shufflevector <4 x i32> %1476, <4 x i32> undef, <4 x i32> zeroinitializer
  %1478 = add nsw i32 %1460, -1
  %1479 = shl i32 1, %1478
  %1480 = insertelement <4 x i32> undef, i32 %1479, i32 0
  %1481 = shufflevector <4 x i32> %1480, <4 x i32> undef, <4 x i32> zeroinitializer
  %1482 = icmp slt i32 %4, 8
  %1483 = add i32 %4, 7
  %1484 = shl i32 1, %1483
  %1485 = select i1 %1482, i32 32768, i32 %1484
  %1486 = sub nsw i32 0, %1485
  %1487 = insertelement <4 x i32> undef, i32 %1486, i32 0
  %1488 = shufflevector <4 x i32> %1487, <4 x i32> undef, <4 x i32> zeroinitializer
  %1489 = add nsw i32 %1485, -1
  %1490 = insertelement <4 x i32> undef, i32 %1489, i32 0
  %1491 = shufflevector <4 x i32> %1490, <4 x i32> undef, <4 x i32> zeroinitializer
  %1492 = shufflevector <4 x i32> %1449, <4 x i32> %1452, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1493 = bitcast <4 x i32> %1492 to <2 x i64>
  %1494 = shufflevector <4 x i32> %1449, <4 x i32> %1452, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1495 = bitcast <4 x i32> %1494 to <2 x i64>
  %1496 = shufflevector <4 x i32> %1455, <4 x i32> %1458, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1497 = bitcast <4 x i32> %1496 to <2 x i64>
  %1498 = shufflevector <4 x i32> %1455, <4 x i32> %1458, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1499 = bitcast <4 x i32> %1498 to <2 x i64>
  %1500 = shufflevector <2 x i64> %1493, <2 x i64> %1497, <2 x i32> <i32 0, i32 2>
  %1501 = shufflevector <2 x i64> %1493, <2 x i64> %1497, <2 x i32> <i32 1, i32 3>
  %1502 = shufflevector <2 x i64> %1495, <2 x i64> %1499, <2 x i32> <i32 0, i32 2>
  %1503 = shufflevector <2 x i64> %1495, <2 x i64> %1499, <2 x i32> <i32 1, i32 3>
  %1504 = bitcast <2 x i64> %1500 to <4 x i32>
  %1505 = mul <4 x i32> %1466, %1504
  %1506 = bitcast <2 x i64> %1502 to <4 x i32>
  %1507 = mul <4 x i32> %1466, %1506
  %1508 = add <4 x i32> %1507, %1505
  %1509 = add <4 x i32> %1508, %1481
  %1510 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1509, i32 %1460) #8
  %1511 = sub <4 x i32> %1505, %1507
  %1512 = add <4 x i32> %1511, %1481
  %1513 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1512, i32 %1460) #8
  %1514 = bitcast <2 x i64> %1501 to <4 x i32>
  %1515 = mul <4 x i32> %1470, %1514
  %1516 = bitcast <2 x i64> %1503 to <4 x i32>
  %1517 = mul <4 x i32> %1477, %1516
  %1518 = add <4 x i32> %1515, %1481
  %1519 = add <4 x i32> %1518, %1517
  %1520 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1519, i32 %1460) #8
  %1521 = mul <4 x i32> %1474, %1514
  %1522 = mul <4 x i32> %1470, %1516
  %1523 = add <4 x i32> %1522, %1481
  %1524 = add <4 x i32> %1523, %1521
  %1525 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1524, i32 %1460) #8
  %1526 = add <4 x i32> %1525, %1510
  %1527 = sub <4 x i32> %1510, %1525
  %1528 = icmp sgt <4 x i32> %1526, %1488
  %1529 = select <4 x i1> %1528, <4 x i32> %1526, <4 x i32> %1488
  %1530 = icmp slt <4 x i32> %1529, %1491
  %1531 = select <4 x i1> %1530, <4 x i32> %1529, <4 x i32> %1491
  %1532 = icmp sgt <4 x i32> %1527, %1488
  %1533 = select <4 x i1> %1532, <4 x i32> %1527, <4 x i32> %1488
  %1534 = icmp slt <4 x i32> %1533, %1491
  %1535 = select <4 x i1> %1534, <4 x i32> %1533, <4 x i32> %1491
  %1536 = add <4 x i32> %1520, %1513
  %1537 = sub <4 x i32> %1513, %1520
  %1538 = icmp sgt <4 x i32> %1536, %1488
  %1539 = select <4 x i1> %1538, <4 x i32> %1536, <4 x i32> %1488
  %1540 = icmp slt <4 x i32> %1539, %1491
  %1541 = select <4 x i1> %1540, <4 x i32> %1539, <4 x i32> %1491
  %1542 = icmp sgt <4 x i32> %1537, %1488
  %1543 = select <4 x i1> %1542, <4 x i32> %1537, <4 x i32> %1488
  %1544 = icmp slt <4 x i32> %1543, %1491
  %1545 = select <4 x i1> %1544, <4 x i32> %1543, <4 x i32> %1491
  %1546 = icmp sgt i32 %4, 10
  %1547 = select i1 %1546, i32 %4, i32 10
  %1548 = shl i32 32, %1547
  %1549 = sub nsw i32 0, %1548
  %1550 = insertelement <4 x i32> undef, i32 %1549, i32 0
  %1551 = shufflevector <4 x i32> %1550, <4 x i32> undef, <4 x i32> zeroinitializer
  %1552 = add nsw i32 %1548, -1
  %1553 = insertelement <4 x i32> undef, i32 %1552, i32 0
  %1554 = shufflevector <4 x i32> %1553, <4 x i32> undef, <4 x i32> zeroinitializer
  %1555 = icmp sgt <4 x i32> %1531, %1551
  %1556 = select <4 x i1> %1555, <4 x i32> %1531, <4 x i32> %1551
  %1557 = icmp slt <4 x i32> %1556, %1554
  %1558 = select <4 x i1> %1557, <4 x i32> %1556, <4 x i32> %1554
  %1559 = icmp sgt <4 x i32> %1535, %1551
  %1560 = select <4 x i1> %1559, <4 x i32> %1535, <4 x i32> %1551
  %1561 = icmp slt <4 x i32> %1560, %1554
  %1562 = select <4 x i1> %1561, <4 x i32> %1560, <4 x i32> %1554
  %1563 = icmp sgt <4 x i32> %1541, %1551
  %1564 = select <4 x i1> %1563, <4 x i32> %1541, <4 x i32> %1551
  %1565 = icmp slt <4 x i32> %1564, %1554
  %1566 = select <4 x i1> %1565, <4 x i32> %1564, <4 x i32> %1554
  %1567 = icmp sgt <4 x i32> %1545, %1551
  %1568 = select <4 x i1> %1567, <4 x i32> %1545, <4 x i32> %1551
  %1569 = icmp slt <4 x i32> %1568, %1554
  %1570 = select <4 x i1> %1569, <4 x i32> %1568, <4 x i32> %1554
  %1571 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 0, i64 0), align 16
  %1572 = sext i8 %1571 to i32
  %1573 = add nsw i32 %1572, -10
  %1574 = sext i32 %1573 to i64
  %1575 = add nsw i32 %1572, 3
  %1576 = shl i32 1, %1575
  %1577 = insertelement <4 x i32> undef, i32 %1576, i32 0
  %1578 = shufflevector <4 x i32> %1577, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %1579 = shufflevector <4 x i32> %1578, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1580 = bitcast <4 x i32> %1579 to <2 x i64>
  %1581 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1574, i64 1
  %1582 = load i32, i32* %1581, align 4
  %1583 = insertelement <4 x i32> undef, i32 %1582, i32 0
  %1584 = shufflevector <4 x i32> %1583, <4 x i32> undef, <4 x i32> zeroinitializer
  %1585 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1574, i64 2
  %1586 = load i32, i32* %1585, align 4
  %1587 = insertelement <4 x i32> undef, i32 %1586, i32 0
  %1588 = shufflevector <4 x i32> %1587, <4 x i32> undef, <4 x i32> zeroinitializer
  %1589 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1574, i64 3
  %1590 = load i32, i32* %1589, align 4
  %1591 = insertelement <4 x i32> undef, i32 %1590, i32 0
  %1592 = shufflevector <4 x i32> %1591, <4 x i32> undef, <4 x i32> zeroinitializer
  %1593 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1574, i64 4
  %1594 = load i32, i32* %1593, align 4
  %1595 = insertelement <4 x i32> undef, i32 %1594, i32 0
  %1596 = shufflevector <4 x i32> %1595, <4 x i32> undef, <4 x i32> zeroinitializer
  %1597 = shufflevector <4 x i32> %1558, <4 x i32> %1566, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1598 = bitcast <4 x i32> %1597 to <2 x i64>
  %1599 = shufflevector <4 x i32> %1558, <4 x i32> %1566, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1600 = bitcast <4 x i32> %1599 to <2 x i64>
  %1601 = shufflevector <4 x i32> %1570, <4 x i32> %1562, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1602 = bitcast <4 x i32> %1601 to <2 x i64>
  %1603 = shufflevector <4 x i32> %1570, <4 x i32> %1562, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1604 = bitcast <4 x i32> %1603 to <2 x i64>
  %1605 = shufflevector <2 x i64> %1598, <2 x i64> %1602, <2 x i32> <i32 0, i32 2>
  %1606 = shufflevector <2 x i64> %1598, <2 x i64> %1602, <2 x i32> <i32 1, i32 3>
  %1607 = shufflevector <2 x i64> %1600, <2 x i64> %1604, <2 x i32> <i32 0, i32 2>
  %1608 = shufflevector <2 x i64> %1600, <2 x i64> %1604, <2 x i32> <i32 1, i32 3>
  %1609 = bitcast <2 x i64> %1605 to <4 x i32>
  %1610 = mul <4 x i32> %1584, %1609
  %1611 = mul <4 x i32> %1588, %1609
  %1612 = bitcast <2 x i64> %1606 to <4 x i32>
  %1613 = mul <4 x i32> %1592, %1612
  %1614 = bitcast <2 x i64> %1607 to <4 x i32>
  %1615 = mul <4 x i32> %1596, %1614
  %1616 = mul <4 x i32> %1584, %1614
  %1617 = bitcast <2 x i64> %1608 to <4 x i32>
  %1618 = mul <4 x i32> %1588, %1617
  %1619 = sub <4 x i32> %1609, %1614
  %1620 = add <4 x i32> %1619, %1617
  %1621 = add <4 x i32> %1615, %1610
  %1622 = add <4 x i32> %1621, %1618
  %1623 = sub <4 x i32> %1611, %1616
  %1624 = mul <4 x i32> %1596, %1617
  %1625 = sub <4 x i32> %1623, %1624
  %1626 = mul <4 x i32> %1620, %1592
  %1627 = bitcast <4 x i32> %1626 to <2 x i64>
  %1628 = add <4 x i32> %1622, %1613
  %1629 = bitcast <4 x i32> %1628 to <2 x i64>
  %1630 = add <4 x i32> %1625, %1613
  %1631 = bitcast <4 x i32> %1630 to <2 x i64>
  %1632 = sub <4 x i32> %1622, %1613
  %1633 = add <4 x i32> %1632, %1625
  %1634 = bitcast <4 x i32> %1633 to <2 x i64>
  %1635 = shl <2 x i64> %1629, <i64 32, i64 32>
  %1636 = ashr exact <2 x i64> %1635, <i64 28, i64 28>
  %1637 = add <2 x i64> %1636, %1580
  %1638 = bitcast <4 x i32> %1628 to <16 x i8>
  %1639 = shufflevector <16 x i8> %1638, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1640 = bitcast <16 x i8> %1639 to <2 x i64>
  %1641 = shl <2 x i64> %1640, <i64 32, i64 32>
  %1642 = ashr exact <2 x i64> %1641, <i64 28, i64 28>
  %1643 = add <2 x i64> %1642, %1580
  %1644 = bitcast <2 x i64> %1637 to <16 x i8>
  %1645 = shufflevector <16 x i8> %1644, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1646 = bitcast <2 x i64> %1643 to <16 x i8>
  %1647 = shufflevector <16 x i8> %1646, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1648 = bitcast <16 x i8> %1645 to <4 x i32>
  %1649 = bitcast <16 x i8> %1647 to <4 x i32>
  %1650 = shufflevector <4 x i32> %1648, <4 x i32> %1649, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1651 = bitcast <4 x i32> %1650 to <2 x i64>
  %1652 = shufflevector <4 x i32> %1648, <4 x i32> %1649, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1653 = bitcast <4 x i32> %1652 to <2 x i64>
  %1654 = shufflevector <2 x i64> %1651, <2 x i64> %1653, <2 x i32> <i32 0, i32 2>
  %1655 = shl <2 x i64> %1631, <i64 32, i64 32>
  %1656 = ashr exact <2 x i64> %1655, <i64 28, i64 28>
  %1657 = add <2 x i64> %1656, %1580
  %1658 = bitcast <4 x i32> %1630 to <16 x i8>
  %1659 = shufflevector <16 x i8> %1658, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1660 = bitcast <16 x i8> %1659 to <2 x i64>
  %1661 = shl <2 x i64> %1660, <i64 32, i64 32>
  %1662 = ashr exact <2 x i64> %1661, <i64 28, i64 28>
  %1663 = add <2 x i64> %1662, %1580
  %1664 = bitcast <2 x i64> %1657 to <16 x i8>
  %1665 = shufflevector <16 x i8> %1664, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1666 = bitcast <2 x i64> %1663 to <16 x i8>
  %1667 = shufflevector <16 x i8> %1666, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1668 = bitcast <16 x i8> %1665 to <4 x i32>
  %1669 = bitcast <16 x i8> %1667 to <4 x i32>
  %1670 = shufflevector <4 x i32> %1668, <4 x i32> %1669, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1671 = bitcast <4 x i32> %1670 to <2 x i64>
  %1672 = shufflevector <4 x i32> %1668, <4 x i32> %1669, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1673 = bitcast <4 x i32> %1672 to <2 x i64>
  %1674 = shufflevector <2 x i64> %1671, <2 x i64> %1673, <2 x i32> <i32 0, i32 2>
  %1675 = shl <2 x i64> %1627, <i64 32, i64 32>
  %1676 = ashr exact <2 x i64> %1675, <i64 28, i64 28>
  %1677 = add <2 x i64> %1676, %1580
  %1678 = bitcast <4 x i32> %1626 to <16 x i8>
  %1679 = shufflevector <16 x i8> %1678, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1680 = bitcast <16 x i8> %1679 to <2 x i64>
  %1681 = shl <2 x i64> %1680, <i64 32, i64 32>
  %1682 = ashr exact <2 x i64> %1681, <i64 28, i64 28>
  %1683 = add <2 x i64> %1682, %1580
  %1684 = bitcast <2 x i64> %1677 to <16 x i8>
  %1685 = shufflevector <16 x i8> %1684, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1686 = bitcast <2 x i64> %1683 to <16 x i8>
  %1687 = shufflevector <16 x i8> %1686, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1688 = bitcast <16 x i8> %1685 to <4 x i32>
  %1689 = bitcast <16 x i8> %1687 to <4 x i32>
  %1690 = shufflevector <4 x i32> %1688, <4 x i32> %1689, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1691 = bitcast <4 x i32> %1690 to <2 x i64>
  %1692 = shufflevector <4 x i32> %1688, <4 x i32> %1689, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1693 = bitcast <4 x i32> %1692 to <2 x i64>
  %1694 = shufflevector <2 x i64> %1691, <2 x i64> %1693, <2 x i32> <i32 0, i32 2>
  %1695 = shl <2 x i64> %1634, <i64 32, i64 32>
  %1696 = ashr exact <2 x i64> %1695, <i64 28, i64 28>
  %1697 = add <2 x i64> %1696, %1580
  %1698 = bitcast <4 x i32> %1633 to <16 x i8>
  %1699 = shufflevector <16 x i8> %1698, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1700 = bitcast <16 x i8> %1699 to <2 x i64>
  %1701 = shl <2 x i64> %1700, <i64 32, i64 32>
  %1702 = ashr exact <2 x i64> %1701, <i64 28, i64 28>
  %1703 = add <2 x i64> %1702, %1580
  %1704 = bitcast <2 x i64> %1697 to <16 x i8>
  %1705 = shufflevector <16 x i8> %1704, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1706 = bitcast <2 x i64> %1703 to <16 x i8>
  %1707 = shufflevector <16 x i8> %1706, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1708 = bitcast <16 x i8> %1705 to <4 x i32>
  %1709 = bitcast <16 x i8> %1707 to <4 x i32>
  %1710 = shufflevector <4 x i32> %1708, <4 x i32> %1709, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1711 = bitcast <4 x i32> %1710 to <2 x i64>
  %1712 = shufflevector <4 x i32> %1708, <4 x i32> %1709, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1713 = bitcast <4 x i32> %1712 to <2 x i64>
  %1714 = shufflevector <2 x i64> %1711, <2 x i64> %1713, <2 x i32> <i32 0, i32 2>
  %1715 = getelementptr inbounds i8, i8* %6, i64 1
  %1716 = load i8, i8* %1715, align 1
  %1717 = sext i8 %1716 to i32
  %1718 = sub nsw i32 0, %1717
  %1719 = icmp eq i8 %1716, 0
  br i1 %1719, label %1741, label %1720

1720:                                             ; preds = %1447
  %1721 = xor i32 %1717, -1
  %1722 = shl i32 1, %1721
  %1723 = insertelement <4 x i32> undef, i32 %1722, i32 0
  %1724 = shufflevector <4 x i32> %1723, <4 x i32> undef, <4 x i32> zeroinitializer
  %1725 = bitcast <2 x i64> %1654 to <4 x i32>
  %1726 = add <4 x i32> %1724, %1725
  %1727 = bitcast <2 x i64> %1674 to <4 x i32>
  %1728 = add <4 x i32> %1724, %1727
  %1729 = bitcast <2 x i64> %1694 to <4 x i32>
  %1730 = add <4 x i32> %1724, %1729
  %1731 = bitcast <2 x i64> %1714 to <4 x i32>
  %1732 = add <4 x i32> %1724, %1731
  %1733 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1726, i32 %1718) #8
  %1734 = bitcast <4 x i32> %1733 to <2 x i64>
  %1735 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1728, i32 %1718) #8
  %1736 = bitcast <4 x i32> %1735 to <2 x i64>
  %1737 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1730, i32 %1718) #8
  %1738 = bitcast <4 x i32> %1737 to <2 x i64>
  %1739 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1732, i32 %1718) #8
  %1740 = bitcast <4 x i32> %1739 to <2 x i64>
  br label %1741

1741:                                             ; preds = %1447, %1720
  %1742 = phi <2 x i64> [ %1714, %1447 ], [ %1740, %1720 ]
  %1743 = phi <2 x i64> [ %1694, %1447 ], [ %1738, %1720 ]
  %1744 = phi <2 x i64> [ %1674, %1447 ], [ %1736, %1720 ]
  %1745 = phi <2 x i64> [ %1654, %1447 ], [ %1734, %1720 ]
  %1746 = bitcast i16* %1 to i64*
  %1747 = load i64, i64* %1746, align 1
  %1748 = insertelement <2 x i64> undef, i64 %1747, i32 0
  %1749 = sext i32 %2 to i64
  %1750 = getelementptr inbounds i16, i16* %1, i64 %1749
  %1751 = bitcast i16* %1750 to i64*
  %1752 = load i64, i64* %1751, align 1
  %1753 = insertelement <2 x i64> undef, i64 %1752, i32 0
  %1754 = shl nsw i32 %2, 1
  %1755 = sext i32 %1754 to i64
  %1756 = getelementptr inbounds i16, i16* %1, i64 %1755
  %1757 = bitcast i16* %1756 to i64*
  %1758 = load i64, i64* %1757, align 1
  %1759 = insertelement <2 x i64> undef, i64 %1758, i32 0
  %1760 = mul nsw i32 %2, 3
  %1761 = sext i32 %1760 to i64
  %1762 = getelementptr inbounds i16, i16* %1, i64 %1761
  %1763 = bitcast i16* %1762 to i64*
  %1764 = load i64, i64* %1763, align 1
  %1765 = insertelement <2 x i64> undef, i64 %1764, i32 0
  %1766 = bitcast <2 x i64> %1748 to <8 x i16>
  %1767 = shufflevector <8 x i16> %1766, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1768 = bitcast <2 x i64> %1753 to <8 x i16>
  %1769 = shufflevector <8 x i16> %1768, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1770 = bitcast <2 x i64> %1759 to <8 x i16>
  %1771 = shufflevector <8 x i16> %1770, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1772 = bitcast <2 x i64> %1765 to <8 x i16>
  %1773 = shufflevector <8 x i16> %1772, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1774 = bitcast <2 x i64> %1742 to <4 x i32>
  %1775 = bitcast <8 x i16> %1767 to <4 x i32>
  %1776 = add <4 x i32> %1775, %1774
  %1777 = bitcast <2 x i64> %1743 to <4 x i32>
  %1778 = bitcast <8 x i16> %1769 to <4 x i32>
  %1779 = add <4 x i32> %1778, %1777
  %1780 = bitcast <2 x i64> %1744 to <4 x i32>
  %1781 = bitcast <8 x i16> %1771 to <4 x i32>
  %1782 = add <4 x i32> %1781, %1780
  %1783 = bitcast <2 x i64> %1745 to <4 x i32>
  %1784 = bitcast <8 x i16> %1773 to <4 x i32>
  %1785 = add <4 x i32> %1784, %1783
  %1786 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1776, <4 x i32> %1779) #8
  %1787 = bitcast <8 x i16> %1786 to <2 x i64>
  %1788 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1782, <4 x i32> %1785) #8
  %1789 = bitcast <8 x i16> %1788 to <2 x i64>
  %1790 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %1791 = add <8 x i16> %1790, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %1792 = icmp slt <8 x i16> %1791, %1786
  %1793 = sext <8 x i1> %1792 to <8 x i16>
  %1794 = bitcast <8 x i16> %1793 to <2 x i64>
  %1795 = xor <2 x i64> %1794, <i64 -1, i64 -1>
  %1796 = and <2 x i64> %1795, %1787
  %1797 = and <8 x i16> %1791, %1793
  %1798 = bitcast <8 x i16> %1797 to <2 x i64>
  %1799 = or <2 x i64> %1796, %1798
  %1800 = bitcast <2 x i64> %1799 to <8 x i16>
  %1801 = icmp sgt <8 x i16> %1800, zeroinitializer
  %1802 = sext <8 x i1> %1801 to <8 x i16>
  %1803 = bitcast <8 x i16> %1802 to <2 x i64>
  %1804 = and <2 x i64> %1799, %1803
  %1805 = icmp slt <8 x i16> %1791, %1788
  %1806 = sext <8 x i1> %1805 to <8 x i16>
  %1807 = bitcast <8 x i16> %1806 to <2 x i64>
  %1808 = xor <2 x i64> %1807, <i64 -1, i64 -1>
  %1809 = and <2 x i64> %1808, %1789
  %1810 = and <8 x i16> %1791, %1806
  br label %6055

1811:                                             ; preds = %5
  %1812 = bitcast i32* %0 to <4 x i32>*
  %1813 = load <4 x i32>, <4 x i32>* %1812, align 16
  %1814 = getelementptr inbounds i32, i32* %0, i64 4
  %1815 = bitcast i32* %1814 to <4 x i32>*
  %1816 = load <4 x i32>, <4 x i32>* %1815, align 16
  %1817 = getelementptr inbounds i32, i32* %0, i64 8
  %1818 = bitcast i32* %1817 to <4 x i32>*
  %1819 = load <4 x i32>, <4 x i32>* %1818, align 16
  %1820 = getelementptr inbounds i32, i32* %0, i64 12
  %1821 = bitcast i32* %1820 to <4 x i32>*
  %1822 = load <4 x i32>, <4 x i32>* %1821, align 16
  %1823 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 0, i64 0), align 16
  %1824 = sext i8 %1823 to i32
  %1825 = add nsw i32 %1824, -10
  %1826 = sext i32 %1825 to i64
  %1827 = add nsw i32 %1824, 3
  %1828 = shl i32 1, %1827
  %1829 = insertelement <4 x i32> undef, i32 %1828, i32 0
  %1830 = shufflevector <4 x i32> %1829, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %1831 = shufflevector <4 x i32> %1830, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1832 = bitcast <4 x i32> %1831 to <2 x i64>
  %1833 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1826, i64 1
  %1834 = load i32, i32* %1833, align 4
  %1835 = insertelement <4 x i32> undef, i32 %1834, i32 0
  %1836 = shufflevector <4 x i32> %1835, <4 x i32> undef, <4 x i32> zeroinitializer
  %1837 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1826, i64 2
  %1838 = load i32, i32* %1837, align 4
  %1839 = insertelement <4 x i32> undef, i32 %1838, i32 0
  %1840 = shufflevector <4 x i32> %1839, <4 x i32> undef, <4 x i32> zeroinitializer
  %1841 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1826, i64 3
  %1842 = load i32, i32* %1841, align 4
  %1843 = insertelement <4 x i32> undef, i32 %1842, i32 0
  %1844 = shufflevector <4 x i32> %1843, <4 x i32> undef, <4 x i32> zeroinitializer
  %1845 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %1826, i64 4
  %1846 = load i32, i32* %1845, align 4
  %1847 = insertelement <4 x i32> undef, i32 %1846, i32 0
  %1848 = shufflevector <4 x i32> %1847, <4 x i32> undef, <4 x i32> zeroinitializer
  %1849 = shufflevector <4 x i32> %1813, <4 x i32> %1816, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1850 = bitcast <4 x i32> %1849 to <2 x i64>
  %1851 = shufflevector <4 x i32> %1813, <4 x i32> %1816, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1852 = bitcast <4 x i32> %1851 to <2 x i64>
  %1853 = shufflevector <4 x i32> %1819, <4 x i32> %1822, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1854 = bitcast <4 x i32> %1853 to <2 x i64>
  %1855 = shufflevector <4 x i32> %1819, <4 x i32> %1822, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1856 = bitcast <4 x i32> %1855 to <2 x i64>
  %1857 = shufflevector <2 x i64> %1850, <2 x i64> %1854, <2 x i32> <i32 0, i32 2>
  %1858 = shufflevector <2 x i64> %1850, <2 x i64> %1854, <2 x i32> <i32 1, i32 3>
  %1859 = shufflevector <2 x i64> %1852, <2 x i64> %1856, <2 x i32> <i32 0, i32 2>
  %1860 = shufflevector <2 x i64> %1852, <2 x i64> %1856, <2 x i32> <i32 1, i32 3>
  %1861 = bitcast <2 x i64> %1857 to <4 x i32>
  %1862 = mul <4 x i32> %1836, %1861
  %1863 = mul <4 x i32> %1840, %1861
  %1864 = bitcast <2 x i64> %1858 to <4 x i32>
  %1865 = mul <4 x i32> %1844, %1864
  %1866 = bitcast <2 x i64> %1859 to <4 x i32>
  %1867 = mul <4 x i32> %1848, %1866
  %1868 = mul <4 x i32> %1836, %1866
  %1869 = bitcast <2 x i64> %1860 to <4 x i32>
  %1870 = mul <4 x i32> %1840, %1869
  %1871 = sub <4 x i32> %1861, %1866
  %1872 = add <4 x i32> %1871, %1869
  %1873 = add <4 x i32> %1870, %1862
  %1874 = add <4 x i32> %1873, %1867
  %1875 = sub <4 x i32> %1863, %1868
  %1876 = mul <4 x i32> %1848, %1869
  %1877 = sub <4 x i32> %1875, %1876
  %1878 = mul <4 x i32> %1872, %1844
  %1879 = bitcast <4 x i32> %1878 to <2 x i64>
  %1880 = add <4 x i32> %1874, %1865
  %1881 = bitcast <4 x i32> %1880 to <2 x i64>
  %1882 = add <4 x i32> %1877, %1865
  %1883 = bitcast <4 x i32> %1882 to <2 x i64>
  %1884 = sub <4 x i32> %1874, %1865
  %1885 = add <4 x i32> %1884, %1877
  %1886 = bitcast <4 x i32> %1885 to <2 x i64>
  %1887 = shl <2 x i64> %1881, <i64 32, i64 32>
  %1888 = ashr exact <2 x i64> %1887, <i64 28, i64 28>
  %1889 = add <2 x i64> %1888, %1832
  %1890 = bitcast <4 x i32> %1880 to <16 x i8>
  %1891 = shufflevector <16 x i8> %1890, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1892 = bitcast <16 x i8> %1891 to <2 x i64>
  %1893 = shl <2 x i64> %1892, <i64 32, i64 32>
  %1894 = ashr exact <2 x i64> %1893, <i64 28, i64 28>
  %1895 = add <2 x i64> %1894, %1832
  %1896 = bitcast <2 x i64> %1889 to <16 x i8>
  %1897 = shufflevector <16 x i8> %1896, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1898 = bitcast <2 x i64> %1895 to <16 x i8>
  %1899 = shufflevector <16 x i8> %1898, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1900 = bitcast <16 x i8> %1897 to <4 x i32>
  %1901 = bitcast <16 x i8> %1899 to <4 x i32>
  %1902 = shufflevector <4 x i32> %1900, <4 x i32> %1901, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1903 = bitcast <4 x i32> %1902 to <2 x i64>
  %1904 = shufflevector <4 x i32> %1900, <4 x i32> %1901, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1905 = bitcast <4 x i32> %1904 to <2 x i64>
  %1906 = shufflevector <2 x i64> %1903, <2 x i64> %1905, <2 x i32> <i32 0, i32 2>
  %1907 = shl <2 x i64> %1883, <i64 32, i64 32>
  %1908 = ashr exact <2 x i64> %1907, <i64 28, i64 28>
  %1909 = add <2 x i64> %1908, %1832
  %1910 = bitcast <4 x i32> %1882 to <16 x i8>
  %1911 = shufflevector <16 x i8> %1910, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1912 = bitcast <16 x i8> %1911 to <2 x i64>
  %1913 = shl <2 x i64> %1912, <i64 32, i64 32>
  %1914 = ashr exact <2 x i64> %1913, <i64 28, i64 28>
  %1915 = add <2 x i64> %1914, %1832
  %1916 = bitcast <2 x i64> %1909 to <16 x i8>
  %1917 = shufflevector <16 x i8> %1916, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1918 = bitcast <2 x i64> %1915 to <16 x i8>
  %1919 = shufflevector <16 x i8> %1918, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1920 = bitcast <16 x i8> %1917 to <4 x i32>
  %1921 = bitcast <16 x i8> %1919 to <4 x i32>
  %1922 = shufflevector <4 x i32> %1920, <4 x i32> %1921, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1923 = bitcast <4 x i32> %1922 to <2 x i64>
  %1924 = shufflevector <4 x i32> %1920, <4 x i32> %1921, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1925 = bitcast <4 x i32> %1924 to <2 x i64>
  %1926 = shufflevector <2 x i64> %1923, <2 x i64> %1925, <2 x i32> <i32 0, i32 2>
  %1927 = shl <2 x i64> %1879, <i64 32, i64 32>
  %1928 = ashr exact <2 x i64> %1927, <i64 28, i64 28>
  %1929 = add <2 x i64> %1928, %1832
  %1930 = bitcast <4 x i32> %1878 to <16 x i8>
  %1931 = shufflevector <16 x i8> %1930, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1932 = bitcast <16 x i8> %1931 to <2 x i64>
  %1933 = shl <2 x i64> %1932, <i64 32, i64 32>
  %1934 = ashr exact <2 x i64> %1933, <i64 28, i64 28>
  %1935 = add <2 x i64> %1934, %1832
  %1936 = bitcast <2 x i64> %1929 to <16 x i8>
  %1937 = shufflevector <16 x i8> %1936, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1938 = bitcast <2 x i64> %1935 to <16 x i8>
  %1939 = shufflevector <16 x i8> %1938, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1940 = bitcast <16 x i8> %1937 to <4 x i32>
  %1941 = bitcast <16 x i8> %1939 to <4 x i32>
  %1942 = shufflevector <4 x i32> %1940, <4 x i32> %1941, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1943 = bitcast <4 x i32> %1942 to <2 x i64>
  %1944 = shufflevector <4 x i32> %1940, <4 x i32> %1941, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1945 = bitcast <4 x i32> %1944 to <2 x i64>
  %1946 = shufflevector <2 x i64> %1943, <2 x i64> %1945, <2 x i32> <i32 0, i32 2>
  %1947 = shl <2 x i64> %1886, <i64 32, i64 32>
  %1948 = ashr exact <2 x i64> %1947, <i64 28, i64 28>
  %1949 = add <2 x i64> %1948, %1832
  %1950 = bitcast <4 x i32> %1885 to <16 x i8>
  %1951 = shufflevector <16 x i8> %1950, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %1952 = bitcast <16 x i8> %1951 to <2 x i64>
  %1953 = shl <2 x i64> %1952, <i64 32, i64 32>
  %1954 = ashr exact <2 x i64> %1953, <i64 28, i64 28>
  %1955 = add <2 x i64> %1954, %1832
  %1956 = bitcast <2 x i64> %1949 to <16 x i8>
  %1957 = shufflevector <16 x i8> %1956, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1958 = bitcast <2 x i64> %1955 to <16 x i8>
  %1959 = shufflevector <16 x i8> %1958, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1960 = bitcast <16 x i8> %1957 to <4 x i32>
  %1961 = bitcast <16 x i8> %1959 to <4 x i32>
  %1962 = shufflevector <4 x i32> %1960, <4 x i32> %1961, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1963 = bitcast <4 x i32> %1962 to <2 x i64>
  %1964 = shufflevector <4 x i32> %1960, <4 x i32> %1961, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1965 = bitcast <4 x i32> %1964 to <2 x i64>
  %1966 = shufflevector <2 x i64> %1963, <2 x i64> %1965, <2 x i32> <i32 0, i32 2>
  %1967 = bitcast <2 x i64> %1906 to <4 x i32>
  %1968 = bitcast <2 x i64> %1926 to <4 x i32>
  %1969 = bitcast <2 x i64> %1946 to <4 x i32>
  %1970 = bitcast <2 x i64> %1966 to <4 x i32>
  %1971 = icmp sgt i32 %4, 10
  %1972 = select i1 %1971, i32 %4, i32 10
  %1973 = shl i32 32, %1972
  %1974 = sub nsw i32 0, %1973
  %1975 = insertelement <4 x i32> undef, i32 %1974, i32 0
  %1976 = shufflevector <4 x i32> %1975, <4 x i32> undef, <4 x i32> zeroinitializer
  %1977 = add nsw i32 %1973, -1
  %1978 = insertelement <4 x i32> undef, i32 %1977, i32 0
  %1979 = shufflevector <4 x i32> %1978, <4 x i32> undef, <4 x i32> zeroinitializer
  %1980 = icmp slt <4 x i32> %1976, %1967
  %1981 = select <4 x i1> %1980, <4 x i32> %1967, <4 x i32> %1976
  %1982 = icmp slt <4 x i32> %1981, %1979
  %1983 = select <4 x i1> %1982, <4 x i32> %1981, <4 x i32> %1979
  %1984 = icmp slt <4 x i32> %1976, %1968
  %1985 = select <4 x i1> %1984, <4 x i32> %1968, <4 x i32> %1976
  %1986 = icmp slt <4 x i32> %1985, %1979
  %1987 = select <4 x i1> %1986, <4 x i32> %1985, <4 x i32> %1979
  %1988 = icmp slt <4 x i32> %1976, %1969
  %1989 = select <4 x i1> %1988, <4 x i32> %1969, <4 x i32> %1976
  %1990 = icmp slt <4 x i32> %1989, %1979
  %1991 = select <4 x i1> %1990, <4 x i32> %1989, <4 x i32> %1979
  %1992 = icmp slt <4 x i32> %1976, %1970
  %1993 = select <4 x i1> %1992, <4 x i32> %1970, <4 x i32> %1976
  %1994 = icmp slt <4 x i32> %1993, %1979
  %1995 = select <4 x i1> %1994, <4 x i32> %1993, <4 x i32> %1979
  %1996 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 0, i64 0), align 16
  %1997 = sext i8 %1996 to i32
  %1998 = add nsw i32 %1997, -10
  %1999 = sext i32 %1998 to i64
  %2000 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %1999, i64 32
  %2001 = load i32, i32* %2000, align 16
  %2002 = insertelement <4 x i32> undef, i32 %2001, i32 0
  %2003 = shufflevector <4 x i32> %2002, <4 x i32> undef, <4 x i32> zeroinitializer
  %2004 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %1999, i64 48
  %2005 = load i32, i32* %2004, align 16
  %2006 = insertelement <4 x i32> undef, i32 %2005, i32 0
  %2007 = shufflevector <4 x i32> %2006, <4 x i32> undef, <4 x i32> zeroinitializer
  %2008 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %1999, i64 16
  %2009 = load i32, i32* %2008, align 16
  %2010 = insertelement <4 x i32> undef, i32 %2009, i32 0
  %2011 = shufflevector <4 x i32> %2010, <4 x i32> undef, <4 x i32> zeroinitializer
  %2012 = sub nsw i32 0, %2009
  %2013 = insertelement <4 x i32> undef, i32 %2012, i32 0
  %2014 = shufflevector <4 x i32> %2013, <4 x i32> undef, <4 x i32> zeroinitializer
  %2015 = add nsw i32 %1997, -1
  %2016 = shl i32 1, %2015
  %2017 = insertelement <4 x i32> undef, i32 %2016, i32 0
  %2018 = shufflevector <4 x i32> %2017, <4 x i32> undef, <4 x i32> zeroinitializer
  %2019 = icmp slt i32 %4, 10
  %2020 = add i32 %4, 5
  %2021 = shl i32 1, %2020
  %2022 = select i1 %2019, i32 32768, i32 %2021
  %2023 = sub nsw i32 0, %2022
  %2024 = insertelement <4 x i32> undef, i32 %2023, i32 0
  %2025 = shufflevector <4 x i32> %2024, <4 x i32> undef, <4 x i32> zeroinitializer
  %2026 = add nsw i32 %2022, -1
  %2027 = insertelement <4 x i32> undef, i32 %2026, i32 0
  %2028 = shufflevector <4 x i32> %2027, <4 x i32> undef, <4 x i32> zeroinitializer
  %2029 = shufflevector <4 x i32> %1983, <4 x i32> %1987, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2030 = bitcast <4 x i32> %2029 to <2 x i64>
  %2031 = shufflevector <4 x i32> %1983, <4 x i32> %1987, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2032 = bitcast <4 x i32> %2031 to <2 x i64>
  %2033 = shufflevector <4 x i32> %1991, <4 x i32> %1995, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2034 = bitcast <4 x i32> %2033 to <2 x i64>
  %2035 = shufflevector <4 x i32> %1991, <4 x i32> %1995, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2036 = bitcast <4 x i32> %2035 to <2 x i64>
  %2037 = shufflevector <2 x i64> %2030, <2 x i64> %2034, <2 x i32> <i32 0, i32 2>
  %2038 = shufflevector <2 x i64> %2030, <2 x i64> %2034, <2 x i32> <i32 1, i32 3>
  %2039 = shufflevector <2 x i64> %2032, <2 x i64> %2036, <2 x i32> <i32 0, i32 2>
  %2040 = shufflevector <2 x i64> %2032, <2 x i64> %2036, <2 x i32> <i32 1, i32 3>
  %2041 = bitcast <2 x i64> %2037 to <4 x i32>
  %2042 = mul <4 x i32> %2003, %2041
  %2043 = bitcast <2 x i64> %2039 to <4 x i32>
  %2044 = mul <4 x i32> %2003, %2043
  %2045 = add <4 x i32> %2042, %2018
  %2046 = add <4 x i32> %2045, %2044
  %2047 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2046, i32 %1997) #8
  %2048 = sub <4 x i32> %2018, %2044
  %2049 = add <4 x i32> %2048, %2042
  %2050 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2049, i32 %1997) #8
  %2051 = bitcast <2 x i64> %2038 to <4 x i32>
  %2052 = mul <4 x i32> %2007, %2051
  %2053 = bitcast <2 x i64> %2040 to <4 x i32>
  %2054 = mul <4 x i32> %2014, %2053
  %2055 = add <4 x i32> %2052, %2018
  %2056 = add <4 x i32> %2055, %2054
  %2057 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2056, i32 %1997) #8
  %2058 = mul <4 x i32> %2011, %2051
  %2059 = mul <4 x i32> %2007, %2053
  %2060 = add <4 x i32> %2058, %2018
  %2061 = add <4 x i32> %2060, %2059
  %2062 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2061, i32 %1997) #8
  %2063 = add <4 x i32> %2062, %2047
  %2064 = sub <4 x i32> %2047, %2062
  %2065 = icmp sgt <4 x i32> %2063, %2025
  %2066 = select <4 x i1> %2065, <4 x i32> %2063, <4 x i32> %2025
  %2067 = icmp slt <4 x i32> %2066, %2028
  %2068 = select <4 x i1> %2067, <4 x i32> %2066, <4 x i32> %2028
  %2069 = icmp sgt <4 x i32> %2064, %2025
  %2070 = select <4 x i1> %2069, <4 x i32> %2064, <4 x i32> %2025
  %2071 = icmp slt <4 x i32> %2070, %2028
  %2072 = select <4 x i1> %2071, <4 x i32> %2070, <4 x i32> %2028
  %2073 = add <4 x i32> %2057, %2050
  %2074 = sub <4 x i32> %2050, %2057
  %2075 = icmp sgt <4 x i32> %2073, %2025
  %2076 = select <4 x i1> %2075, <4 x i32> %2073, <4 x i32> %2025
  %2077 = icmp slt <4 x i32> %2076, %2028
  %2078 = select <4 x i1> %2077, <4 x i32> %2076, <4 x i32> %2028
  %2079 = icmp sgt <4 x i32> %2074, %2025
  %2080 = select <4 x i1> %2079, <4 x i32> %2074, <4 x i32> %2025
  %2081 = icmp slt <4 x i32> %2080, %2028
  %2082 = select <4 x i1> %2081, <4 x i32> %2080, <4 x i32> %2028
  %2083 = getelementptr inbounds i8, i8* %6, i64 1
  %2084 = load i8, i8* %2083, align 1
  %2085 = sext i8 %2084 to i32
  %2086 = sub nsw i32 0, %2085
  %2087 = icmp eq i8 %2084, 0
  br i1 %2087, label %2101, label %2088

2088:                                             ; preds = %1811
  %2089 = xor i32 %2085, -1
  %2090 = shl i32 1, %2089
  %2091 = insertelement <4 x i32> undef, i32 %2090, i32 0
  %2092 = shufflevector <4 x i32> %2091, <4 x i32> undef, <4 x i32> zeroinitializer
  %2093 = add <4 x i32> %2068, %2092
  %2094 = add <4 x i32> %2092, %2078
  %2095 = add <4 x i32> %2092, %2082
  %2096 = add <4 x i32> %2072, %2092
  %2097 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2093, i32 %2086) #8
  %2098 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2094, i32 %2086) #8
  %2099 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2095, i32 %2086) #8
  %2100 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2096, i32 %2086) #8
  br label %2101

2101:                                             ; preds = %1811, %2088
  %2102 = phi <4 x i32> [ %2072, %1811 ], [ %2100, %2088 ]
  %2103 = phi <4 x i32> [ %2082, %1811 ], [ %2099, %2088 ]
  %2104 = phi <4 x i32> [ %2078, %1811 ], [ %2098, %2088 ]
  %2105 = phi <4 x i32> [ %2068, %1811 ], [ %2097, %2088 ]
  %2106 = bitcast i16* %1 to i64*
  %2107 = load i64, i64* %2106, align 1
  %2108 = insertelement <2 x i64> undef, i64 %2107, i32 0
  %2109 = sext i32 %2 to i64
  %2110 = getelementptr inbounds i16, i16* %1, i64 %2109
  %2111 = bitcast i16* %2110 to i64*
  %2112 = load i64, i64* %2111, align 1
  %2113 = insertelement <2 x i64> undef, i64 %2112, i32 0
  %2114 = shl nsw i32 %2, 1
  %2115 = sext i32 %2114 to i64
  %2116 = getelementptr inbounds i16, i16* %1, i64 %2115
  %2117 = bitcast i16* %2116 to i64*
  %2118 = load i64, i64* %2117, align 1
  %2119 = insertelement <2 x i64> undef, i64 %2118, i32 0
  %2120 = mul nsw i32 %2, 3
  %2121 = sext i32 %2120 to i64
  %2122 = getelementptr inbounds i16, i16* %1, i64 %2121
  %2123 = bitcast i16* %2122 to i64*
  %2124 = load i64, i64* %2123, align 1
  %2125 = insertelement <2 x i64> undef, i64 %2124, i32 0
  %2126 = bitcast <2 x i64> %2108 to <8 x i16>
  %2127 = shufflevector <8 x i16> %2126, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2128 = bitcast <2 x i64> %2113 to <8 x i16>
  %2129 = shufflevector <8 x i16> %2128, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2130 = bitcast <2 x i64> %2119 to <8 x i16>
  %2131 = shufflevector <8 x i16> %2130, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2132 = bitcast <2 x i64> %2125 to <8 x i16>
  %2133 = shufflevector <8 x i16> %2132, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2134 = shufflevector <4 x i32> %2105, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %2135 = shufflevector <4 x i32> %2104, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %2136 = shufflevector <4 x i32> %2103, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %2137 = shufflevector <4 x i32> %2102, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %2138 = bitcast <8 x i16> %2127 to <4 x i32>
  %2139 = add <4 x i32> %2134, %2138
  %2140 = bitcast <8 x i16> %2129 to <4 x i32>
  %2141 = add <4 x i32> %2135, %2140
  %2142 = bitcast <8 x i16> %2131 to <4 x i32>
  %2143 = add <4 x i32> %2136, %2142
  %2144 = bitcast <8 x i16> %2133 to <4 x i32>
  %2145 = add <4 x i32> %2137, %2144
  %2146 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2139, <4 x i32> %2141) #8
  %2147 = bitcast <8 x i16> %2146 to <2 x i64>
  %2148 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2143, <4 x i32> %2145) #8
  %2149 = bitcast <8 x i16> %2148 to <2 x i64>
  %2150 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %2151 = add <8 x i16> %2150, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %2152 = icmp slt <8 x i16> %2151, %2146
  %2153 = sext <8 x i1> %2152 to <8 x i16>
  %2154 = bitcast <8 x i16> %2153 to <2 x i64>
  %2155 = xor <2 x i64> %2154, <i64 -1, i64 -1>
  %2156 = and <2 x i64> %2155, %2147
  %2157 = and <8 x i16> %2151, %2153
  %2158 = bitcast <8 x i16> %2157 to <2 x i64>
  %2159 = or <2 x i64> %2156, %2158
  %2160 = bitcast <2 x i64> %2159 to <8 x i16>
  %2161 = icmp sgt <8 x i16> %2160, zeroinitializer
  %2162 = sext <8 x i1> %2161 to <8 x i16>
  %2163 = bitcast <8 x i16> %2162 to <2 x i64>
  %2164 = and <2 x i64> %2159, %2163
  %2165 = icmp slt <8 x i16> %2151, %2148
  %2166 = sext <8 x i1> %2165 to <8 x i16>
  %2167 = bitcast <8 x i16> %2166 to <2 x i64>
  %2168 = xor <2 x i64> %2167, <i64 -1, i64 -1>
  %2169 = and <2 x i64> %2168, %2149
  %2170 = and <8 x i16> %2151, %2166
  br label %6055

2171:                                             ; preds = %5
  %2172 = bitcast i32* %0 to <4 x i32>*
  %2173 = load <4 x i32>, <4 x i32>* %2172, align 16
  %2174 = getelementptr inbounds i32, i32* %0, i64 4
  %2175 = bitcast i32* %2174 to <4 x i32>*
  %2176 = load <4 x i32>, <4 x i32>* %2175, align 16
  %2177 = getelementptr inbounds i32, i32* %0, i64 8
  %2178 = bitcast i32* %2177 to <4 x i32>*
  %2179 = load <4 x i32>, <4 x i32>* %2178, align 16
  %2180 = getelementptr inbounds i32, i32* %0, i64 12
  %2181 = bitcast i32* %2180 to <4 x i32>*
  %2182 = load <4 x i32>, <4 x i32>* %2181, align 16
  %2183 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 0, i64 0), align 16
  %2184 = sext i8 %2183 to i32
  %2185 = add nsw i32 %2184, -10
  %2186 = sext i32 %2185 to i64
  %2187 = add nsw i32 %2184, 3
  %2188 = shl i32 1, %2187
  %2189 = insertelement <4 x i32> undef, i32 %2188, i32 0
  %2190 = shufflevector <4 x i32> %2189, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %2191 = shufflevector <4 x i32> %2190, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2192 = bitcast <4 x i32> %2191 to <2 x i64>
  %2193 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2186, i64 1
  %2194 = load i32, i32* %2193, align 4
  %2195 = insertelement <4 x i32> undef, i32 %2194, i32 0
  %2196 = shufflevector <4 x i32> %2195, <4 x i32> undef, <4 x i32> zeroinitializer
  %2197 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2186, i64 2
  %2198 = load i32, i32* %2197, align 4
  %2199 = insertelement <4 x i32> undef, i32 %2198, i32 0
  %2200 = shufflevector <4 x i32> %2199, <4 x i32> undef, <4 x i32> zeroinitializer
  %2201 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2186, i64 3
  %2202 = load i32, i32* %2201, align 4
  %2203 = insertelement <4 x i32> undef, i32 %2202, i32 0
  %2204 = shufflevector <4 x i32> %2203, <4 x i32> undef, <4 x i32> zeroinitializer
  %2205 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2186, i64 4
  %2206 = load i32, i32* %2205, align 4
  %2207 = insertelement <4 x i32> undef, i32 %2206, i32 0
  %2208 = shufflevector <4 x i32> %2207, <4 x i32> undef, <4 x i32> zeroinitializer
  %2209 = shufflevector <4 x i32> %2173, <4 x i32> %2176, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2210 = bitcast <4 x i32> %2209 to <2 x i64>
  %2211 = shufflevector <4 x i32> %2173, <4 x i32> %2176, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2212 = bitcast <4 x i32> %2211 to <2 x i64>
  %2213 = shufflevector <4 x i32> %2179, <4 x i32> %2182, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2214 = bitcast <4 x i32> %2213 to <2 x i64>
  %2215 = shufflevector <4 x i32> %2179, <4 x i32> %2182, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2216 = bitcast <4 x i32> %2215 to <2 x i64>
  %2217 = shufflevector <2 x i64> %2210, <2 x i64> %2214, <2 x i32> <i32 0, i32 2>
  %2218 = shufflevector <2 x i64> %2210, <2 x i64> %2214, <2 x i32> <i32 1, i32 3>
  %2219 = shufflevector <2 x i64> %2212, <2 x i64> %2216, <2 x i32> <i32 0, i32 2>
  %2220 = shufflevector <2 x i64> %2212, <2 x i64> %2216, <2 x i32> <i32 1, i32 3>
  %2221 = bitcast <2 x i64> %2217 to <4 x i32>
  %2222 = mul <4 x i32> %2196, %2221
  %2223 = mul <4 x i32> %2200, %2221
  %2224 = bitcast <2 x i64> %2218 to <4 x i32>
  %2225 = mul <4 x i32> %2204, %2224
  %2226 = bitcast <2 x i64> %2219 to <4 x i32>
  %2227 = mul <4 x i32> %2208, %2226
  %2228 = mul <4 x i32> %2196, %2226
  %2229 = bitcast <2 x i64> %2220 to <4 x i32>
  %2230 = mul <4 x i32> %2200, %2229
  %2231 = sub <4 x i32> %2221, %2226
  %2232 = add <4 x i32> %2231, %2229
  %2233 = add <4 x i32> %2230, %2222
  %2234 = add <4 x i32> %2233, %2227
  %2235 = sub <4 x i32> %2223, %2228
  %2236 = mul <4 x i32> %2208, %2229
  %2237 = sub <4 x i32> %2235, %2236
  %2238 = mul <4 x i32> %2232, %2204
  %2239 = bitcast <4 x i32> %2238 to <2 x i64>
  %2240 = add <4 x i32> %2234, %2225
  %2241 = bitcast <4 x i32> %2240 to <2 x i64>
  %2242 = add <4 x i32> %2237, %2225
  %2243 = bitcast <4 x i32> %2242 to <2 x i64>
  %2244 = sub <4 x i32> %2234, %2225
  %2245 = add <4 x i32> %2244, %2237
  %2246 = bitcast <4 x i32> %2245 to <2 x i64>
  %2247 = shl <2 x i64> %2241, <i64 32, i64 32>
  %2248 = ashr exact <2 x i64> %2247, <i64 28, i64 28>
  %2249 = add <2 x i64> %2248, %2192
  %2250 = bitcast <4 x i32> %2240 to <16 x i8>
  %2251 = shufflevector <16 x i8> %2250, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2252 = bitcast <16 x i8> %2251 to <2 x i64>
  %2253 = shl <2 x i64> %2252, <i64 32, i64 32>
  %2254 = ashr exact <2 x i64> %2253, <i64 28, i64 28>
  %2255 = add <2 x i64> %2254, %2192
  %2256 = bitcast <2 x i64> %2249 to <16 x i8>
  %2257 = shufflevector <16 x i8> %2256, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2258 = bitcast <2 x i64> %2255 to <16 x i8>
  %2259 = shufflevector <16 x i8> %2258, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2260 = bitcast <16 x i8> %2257 to <4 x i32>
  %2261 = bitcast <16 x i8> %2259 to <4 x i32>
  %2262 = shufflevector <4 x i32> %2260, <4 x i32> %2261, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2263 = bitcast <4 x i32> %2262 to <2 x i64>
  %2264 = shufflevector <4 x i32> %2260, <4 x i32> %2261, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2265 = bitcast <4 x i32> %2264 to <2 x i64>
  %2266 = shufflevector <2 x i64> %2263, <2 x i64> %2265, <2 x i32> <i32 0, i32 2>
  %2267 = shl <2 x i64> %2243, <i64 32, i64 32>
  %2268 = ashr exact <2 x i64> %2267, <i64 28, i64 28>
  %2269 = add <2 x i64> %2268, %2192
  %2270 = bitcast <4 x i32> %2242 to <16 x i8>
  %2271 = shufflevector <16 x i8> %2270, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2272 = bitcast <16 x i8> %2271 to <2 x i64>
  %2273 = shl <2 x i64> %2272, <i64 32, i64 32>
  %2274 = ashr exact <2 x i64> %2273, <i64 28, i64 28>
  %2275 = add <2 x i64> %2274, %2192
  %2276 = bitcast <2 x i64> %2269 to <16 x i8>
  %2277 = shufflevector <16 x i8> %2276, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2278 = bitcast <2 x i64> %2275 to <16 x i8>
  %2279 = shufflevector <16 x i8> %2278, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2280 = bitcast <16 x i8> %2277 to <4 x i32>
  %2281 = bitcast <16 x i8> %2279 to <4 x i32>
  %2282 = shufflevector <4 x i32> %2280, <4 x i32> %2281, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2283 = bitcast <4 x i32> %2282 to <2 x i64>
  %2284 = shufflevector <4 x i32> %2280, <4 x i32> %2281, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2285 = bitcast <4 x i32> %2284 to <2 x i64>
  %2286 = shufflevector <2 x i64> %2283, <2 x i64> %2285, <2 x i32> <i32 0, i32 2>
  %2287 = shl <2 x i64> %2239, <i64 32, i64 32>
  %2288 = ashr exact <2 x i64> %2287, <i64 28, i64 28>
  %2289 = add <2 x i64> %2288, %2192
  %2290 = bitcast <4 x i32> %2238 to <16 x i8>
  %2291 = shufflevector <16 x i8> %2290, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2292 = bitcast <16 x i8> %2291 to <2 x i64>
  %2293 = shl <2 x i64> %2292, <i64 32, i64 32>
  %2294 = ashr exact <2 x i64> %2293, <i64 28, i64 28>
  %2295 = add <2 x i64> %2294, %2192
  %2296 = bitcast <2 x i64> %2289 to <16 x i8>
  %2297 = shufflevector <16 x i8> %2296, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2298 = bitcast <2 x i64> %2295 to <16 x i8>
  %2299 = shufflevector <16 x i8> %2298, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2300 = bitcast <16 x i8> %2297 to <4 x i32>
  %2301 = bitcast <16 x i8> %2299 to <4 x i32>
  %2302 = shufflevector <4 x i32> %2300, <4 x i32> %2301, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2303 = bitcast <4 x i32> %2302 to <2 x i64>
  %2304 = shufflevector <4 x i32> %2300, <4 x i32> %2301, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2305 = bitcast <4 x i32> %2304 to <2 x i64>
  %2306 = shufflevector <2 x i64> %2303, <2 x i64> %2305, <2 x i32> <i32 0, i32 2>
  %2307 = shl <2 x i64> %2246, <i64 32, i64 32>
  %2308 = ashr exact <2 x i64> %2307, <i64 28, i64 28>
  %2309 = add <2 x i64> %2308, %2192
  %2310 = bitcast <4 x i32> %2245 to <16 x i8>
  %2311 = shufflevector <16 x i8> %2310, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2312 = bitcast <16 x i8> %2311 to <2 x i64>
  %2313 = shl <2 x i64> %2312, <i64 32, i64 32>
  %2314 = ashr exact <2 x i64> %2313, <i64 28, i64 28>
  %2315 = add <2 x i64> %2314, %2192
  %2316 = bitcast <2 x i64> %2309 to <16 x i8>
  %2317 = shufflevector <16 x i8> %2316, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2318 = bitcast <2 x i64> %2315 to <16 x i8>
  %2319 = shufflevector <16 x i8> %2318, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2320 = bitcast <16 x i8> %2317 to <4 x i32>
  %2321 = bitcast <16 x i8> %2319 to <4 x i32>
  %2322 = shufflevector <4 x i32> %2320, <4 x i32> %2321, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2323 = bitcast <4 x i32> %2322 to <2 x i64>
  %2324 = shufflevector <4 x i32> %2320, <4 x i32> %2321, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2325 = bitcast <4 x i32> %2324 to <2 x i64>
  %2326 = shufflevector <2 x i64> %2323, <2 x i64> %2325, <2 x i32> <i32 0, i32 2>
  %2327 = bitcast <2 x i64> %2266 to <4 x i32>
  %2328 = bitcast <2 x i64> %2286 to <4 x i32>
  %2329 = bitcast <2 x i64> %2306 to <4 x i32>
  %2330 = bitcast <2 x i64> %2326 to <4 x i32>
  %2331 = icmp sgt i32 %4, 10
  %2332 = select i1 %2331, i32 %4, i32 10
  %2333 = shl i32 32, %2332
  %2334 = sub nsw i32 0, %2333
  %2335 = insertelement <4 x i32> undef, i32 %2334, i32 0
  %2336 = shufflevector <4 x i32> %2335, <4 x i32> undef, <4 x i32> zeroinitializer
  %2337 = add nsw i32 %2333, -1
  %2338 = insertelement <4 x i32> undef, i32 %2337, i32 0
  %2339 = shufflevector <4 x i32> %2338, <4 x i32> undef, <4 x i32> zeroinitializer
  %2340 = icmp slt <4 x i32> %2336, %2327
  %2341 = select <4 x i1> %2340, <4 x i32> %2327, <4 x i32> %2336
  %2342 = icmp slt <4 x i32> %2341, %2339
  %2343 = select <4 x i1> %2342, <4 x i32> %2341, <4 x i32> %2339
  %2344 = icmp slt <4 x i32> %2336, %2328
  %2345 = select <4 x i1> %2344, <4 x i32> %2328, <4 x i32> %2336
  %2346 = icmp slt <4 x i32> %2345, %2339
  %2347 = select <4 x i1> %2346, <4 x i32> %2345, <4 x i32> %2339
  %2348 = icmp slt <4 x i32> %2336, %2329
  %2349 = select <4 x i1> %2348, <4 x i32> %2329, <4 x i32> %2336
  %2350 = icmp slt <4 x i32> %2349, %2339
  %2351 = select <4 x i1> %2350, <4 x i32> %2349, <4 x i32> %2339
  %2352 = icmp slt <4 x i32> %2336, %2330
  %2353 = select <4 x i1> %2352, <4 x i32> %2330, <4 x i32> %2336
  %2354 = icmp slt <4 x i32> %2353, %2339
  %2355 = select <4 x i1> %2354, <4 x i32> %2353, <4 x i32> %2339
  %2356 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 0, i64 0), align 16
  %2357 = sext i8 %2356 to i32
  %2358 = add nsw i32 %2357, -10
  %2359 = sext i32 %2358 to i64
  %2360 = add nsw i32 %2357, 3
  %2361 = shl i32 1, %2360
  %2362 = insertelement <4 x i32> undef, i32 %2361, i32 0
  %2363 = shufflevector <4 x i32> %2362, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %2364 = shufflevector <4 x i32> %2363, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2365 = bitcast <4 x i32> %2364 to <2 x i64>
  %2366 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2359, i64 1
  %2367 = load i32, i32* %2366, align 4
  %2368 = insertelement <4 x i32> undef, i32 %2367, i32 0
  %2369 = shufflevector <4 x i32> %2368, <4 x i32> undef, <4 x i32> zeroinitializer
  %2370 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2359, i64 2
  %2371 = load i32, i32* %2370, align 4
  %2372 = insertelement <4 x i32> undef, i32 %2371, i32 0
  %2373 = shufflevector <4 x i32> %2372, <4 x i32> undef, <4 x i32> zeroinitializer
  %2374 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2359, i64 3
  %2375 = load i32, i32* %2374, align 4
  %2376 = insertelement <4 x i32> undef, i32 %2375, i32 0
  %2377 = shufflevector <4 x i32> %2376, <4 x i32> undef, <4 x i32> zeroinitializer
  %2378 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2359, i64 4
  %2379 = load i32, i32* %2378, align 4
  %2380 = insertelement <4 x i32> undef, i32 %2379, i32 0
  %2381 = shufflevector <4 x i32> %2380, <4 x i32> undef, <4 x i32> zeroinitializer
  %2382 = shufflevector <4 x i32> %2343, <4 x i32> %2347, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2383 = bitcast <4 x i32> %2382 to <2 x i64>
  %2384 = shufflevector <4 x i32> %2343, <4 x i32> %2347, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2385 = bitcast <4 x i32> %2384 to <2 x i64>
  %2386 = shufflevector <4 x i32> %2351, <4 x i32> %2355, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2387 = bitcast <4 x i32> %2386 to <2 x i64>
  %2388 = shufflevector <4 x i32> %2351, <4 x i32> %2355, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2389 = bitcast <4 x i32> %2388 to <2 x i64>
  %2390 = shufflevector <2 x i64> %2383, <2 x i64> %2387, <2 x i32> <i32 0, i32 2>
  %2391 = shufflevector <2 x i64> %2383, <2 x i64> %2387, <2 x i32> <i32 1, i32 3>
  %2392 = shufflevector <2 x i64> %2385, <2 x i64> %2389, <2 x i32> <i32 0, i32 2>
  %2393 = shufflevector <2 x i64> %2385, <2 x i64> %2389, <2 x i32> <i32 1, i32 3>
  %2394 = bitcast <2 x i64> %2390 to <4 x i32>
  %2395 = mul <4 x i32> %2369, %2394
  %2396 = mul <4 x i32> %2373, %2394
  %2397 = bitcast <2 x i64> %2391 to <4 x i32>
  %2398 = mul <4 x i32> %2377, %2397
  %2399 = bitcast <2 x i64> %2392 to <4 x i32>
  %2400 = mul <4 x i32> %2381, %2399
  %2401 = mul <4 x i32> %2369, %2399
  %2402 = bitcast <2 x i64> %2393 to <4 x i32>
  %2403 = mul <4 x i32> %2373, %2402
  %2404 = sub <4 x i32> %2394, %2399
  %2405 = add <4 x i32> %2404, %2402
  %2406 = add <4 x i32> %2400, %2395
  %2407 = add <4 x i32> %2406, %2403
  %2408 = sub <4 x i32> %2396, %2401
  %2409 = mul <4 x i32> %2381, %2402
  %2410 = sub <4 x i32> %2408, %2409
  %2411 = mul <4 x i32> %2405, %2377
  %2412 = bitcast <4 x i32> %2411 to <2 x i64>
  %2413 = add <4 x i32> %2407, %2398
  %2414 = bitcast <4 x i32> %2413 to <2 x i64>
  %2415 = add <4 x i32> %2410, %2398
  %2416 = bitcast <4 x i32> %2415 to <2 x i64>
  %2417 = sub <4 x i32> %2407, %2398
  %2418 = add <4 x i32> %2417, %2410
  %2419 = bitcast <4 x i32> %2418 to <2 x i64>
  %2420 = shl <2 x i64> %2414, <i64 32, i64 32>
  %2421 = ashr exact <2 x i64> %2420, <i64 28, i64 28>
  %2422 = add <2 x i64> %2421, %2365
  %2423 = bitcast <4 x i32> %2413 to <16 x i8>
  %2424 = shufflevector <16 x i8> %2423, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2425 = bitcast <16 x i8> %2424 to <2 x i64>
  %2426 = shl <2 x i64> %2425, <i64 32, i64 32>
  %2427 = ashr exact <2 x i64> %2426, <i64 28, i64 28>
  %2428 = add <2 x i64> %2427, %2365
  %2429 = bitcast <2 x i64> %2422 to <16 x i8>
  %2430 = shufflevector <16 x i8> %2429, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2431 = bitcast <2 x i64> %2428 to <16 x i8>
  %2432 = shufflevector <16 x i8> %2431, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2433 = bitcast <16 x i8> %2430 to <4 x i32>
  %2434 = bitcast <16 x i8> %2432 to <4 x i32>
  %2435 = shufflevector <4 x i32> %2433, <4 x i32> %2434, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2436 = bitcast <4 x i32> %2435 to <2 x i64>
  %2437 = shufflevector <4 x i32> %2433, <4 x i32> %2434, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2438 = bitcast <4 x i32> %2437 to <2 x i64>
  %2439 = shufflevector <2 x i64> %2436, <2 x i64> %2438, <2 x i32> <i32 0, i32 2>
  %2440 = shl <2 x i64> %2416, <i64 32, i64 32>
  %2441 = ashr exact <2 x i64> %2440, <i64 28, i64 28>
  %2442 = add <2 x i64> %2441, %2365
  %2443 = bitcast <4 x i32> %2415 to <16 x i8>
  %2444 = shufflevector <16 x i8> %2443, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2445 = bitcast <16 x i8> %2444 to <2 x i64>
  %2446 = shl <2 x i64> %2445, <i64 32, i64 32>
  %2447 = ashr exact <2 x i64> %2446, <i64 28, i64 28>
  %2448 = add <2 x i64> %2447, %2365
  %2449 = bitcast <2 x i64> %2442 to <16 x i8>
  %2450 = shufflevector <16 x i8> %2449, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2451 = bitcast <2 x i64> %2448 to <16 x i8>
  %2452 = shufflevector <16 x i8> %2451, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2453 = bitcast <16 x i8> %2450 to <4 x i32>
  %2454 = bitcast <16 x i8> %2452 to <4 x i32>
  %2455 = shufflevector <4 x i32> %2453, <4 x i32> %2454, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2456 = bitcast <4 x i32> %2455 to <2 x i64>
  %2457 = shufflevector <4 x i32> %2453, <4 x i32> %2454, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2458 = bitcast <4 x i32> %2457 to <2 x i64>
  %2459 = shufflevector <2 x i64> %2456, <2 x i64> %2458, <2 x i32> <i32 0, i32 2>
  %2460 = shl <2 x i64> %2412, <i64 32, i64 32>
  %2461 = ashr exact <2 x i64> %2460, <i64 28, i64 28>
  %2462 = add <2 x i64> %2461, %2365
  %2463 = bitcast <4 x i32> %2411 to <16 x i8>
  %2464 = shufflevector <16 x i8> %2463, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2465 = bitcast <16 x i8> %2464 to <2 x i64>
  %2466 = shl <2 x i64> %2465, <i64 32, i64 32>
  %2467 = ashr exact <2 x i64> %2466, <i64 28, i64 28>
  %2468 = add <2 x i64> %2467, %2365
  %2469 = bitcast <2 x i64> %2462 to <16 x i8>
  %2470 = shufflevector <16 x i8> %2469, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2471 = bitcast <2 x i64> %2468 to <16 x i8>
  %2472 = shufflevector <16 x i8> %2471, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2473 = bitcast <16 x i8> %2470 to <4 x i32>
  %2474 = bitcast <16 x i8> %2472 to <4 x i32>
  %2475 = shufflevector <4 x i32> %2473, <4 x i32> %2474, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2476 = bitcast <4 x i32> %2475 to <2 x i64>
  %2477 = shufflevector <4 x i32> %2473, <4 x i32> %2474, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2478 = bitcast <4 x i32> %2477 to <2 x i64>
  %2479 = shufflevector <2 x i64> %2476, <2 x i64> %2478, <2 x i32> <i32 0, i32 2>
  %2480 = shl <2 x i64> %2419, <i64 32, i64 32>
  %2481 = ashr exact <2 x i64> %2480, <i64 28, i64 28>
  %2482 = add <2 x i64> %2481, %2365
  %2483 = bitcast <4 x i32> %2418 to <16 x i8>
  %2484 = shufflevector <16 x i8> %2483, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2485 = bitcast <16 x i8> %2484 to <2 x i64>
  %2486 = shl <2 x i64> %2485, <i64 32, i64 32>
  %2487 = ashr exact <2 x i64> %2486, <i64 28, i64 28>
  %2488 = add <2 x i64> %2487, %2365
  %2489 = bitcast <2 x i64> %2482 to <16 x i8>
  %2490 = shufflevector <16 x i8> %2489, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2491 = bitcast <2 x i64> %2488 to <16 x i8>
  %2492 = shufflevector <16 x i8> %2491, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2493 = bitcast <16 x i8> %2490 to <4 x i32>
  %2494 = bitcast <16 x i8> %2492 to <4 x i32>
  %2495 = shufflevector <4 x i32> %2493, <4 x i32> %2494, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2496 = bitcast <4 x i32> %2495 to <2 x i64>
  %2497 = shufflevector <4 x i32> %2493, <4 x i32> %2494, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2498 = bitcast <4 x i32> %2497 to <2 x i64>
  %2499 = shufflevector <2 x i64> %2496, <2 x i64> %2498, <2 x i32> <i32 0, i32 2>
  %2500 = getelementptr inbounds i8, i8* %6, i64 1
  %2501 = load i8, i8* %2500, align 1
  %2502 = sext i8 %2501 to i32
  %2503 = sub nsw i32 0, %2502
  %2504 = icmp eq i8 %2501, 0
  br i1 %2504, label %2526, label %2505

2505:                                             ; preds = %2171
  %2506 = xor i32 %2502, -1
  %2507 = shl i32 1, %2506
  %2508 = insertelement <4 x i32> undef, i32 %2507, i32 0
  %2509 = shufflevector <4 x i32> %2508, <4 x i32> undef, <4 x i32> zeroinitializer
  %2510 = bitcast <2 x i64> %2439 to <4 x i32>
  %2511 = add <4 x i32> %2509, %2510
  %2512 = bitcast <2 x i64> %2459 to <4 x i32>
  %2513 = add <4 x i32> %2509, %2512
  %2514 = bitcast <2 x i64> %2479 to <4 x i32>
  %2515 = add <4 x i32> %2509, %2514
  %2516 = bitcast <2 x i64> %2499 to <4 x i32>
  %2517 = add <4 x i32> %2509, %2516
  %2518 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2511, i32 %2503) #8
  %2519 = bitcast <4 x i32> %2518 to <2 x i64>
  %2520 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2513, i32 %2503) #8
  %2521 = bitcast <4 x i32> %2520 to <2 x i64>
  %2522 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2515, i32 %2503) #8
  %2523 = bitcast <4 x i32> %2522 to <2 x i64>
  %2524 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2517, i32 %2503) #8
  %2525 = bitcast <4 x i32> %2524 to <2 x i64>
  br label %2526

2526:                                             ; preds = %2171, %2505
  %2527 = phi <2 x i64> [ %2499, %2171 ], [ %2525, %2505 ]
  %2528 = phi <2 x i64> [ %2479, %2171 ], [ %2523, %2505 ]
  %2529 = phi <2 x i64> [ %2459, %2171 ], [ %2521, %2505 ]
  %2530 = phi <2 x i64> [ %2439, %2171 ], [ %2519, %2505 ]
  %2531 = bitcast i16* %1 to i64*
  %2532 = load i64, i64* %2531, align 1
  %2533 = insertelement <2 x i64> undef, i64 %2532, i32 0
  %2534 = sext i32 %2 to i64
  %2535 = getelementptr inbounds i16, i16* %1, i64 %2534
  %2536 = bitcast i16* %2535 to i64*
  %2537 = load i64, i64* %2536, align 1
  %2538 = insertelement <2 x i64> undef, i64 %2537, i32 0
  %2539 = shl nsw i32 %2, 1
  %2540 = sext i32 %2539 to i64
  %2541 = getelementptr inbounds i16, i16* %1, i64 %2540
  %2542 = bitcast i16* %2541 to i64*
  %2543 = load i64, i64* %2542, align 1
  %2544 = insertelement <2 x i64> undef, i64 %2543, i32 0
  %2545 = mul nsw i32 %2, 3
  %2546 = sext i32 %2545 to i64
  %2547 = getelementptr inbounds i16, i16* %1, i64 %2546
  %2548 = bitcast i16* %2547 to i64*
  %2549 = load i64, i64* %2548, align 1
  %2550 = insertelement <2 x i64> undef, i64 %2549, i32 0
  %2551 = bitcast <2 x i64> %2533 to <8 x i16>
  %2552 = shufflevector <8 x i16> %2551, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2553 = bitcast <2 x i64> %2538 to <8 x i16>
  %2554 = shufflevector <8 x i16> %2553, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2555 = bitcast <2 x i64> %2544 to <8 x i16>
  %2556 = shufflevector <8 x i16> %2555, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2557 = bitcast <2 x i64> %2550 to <8 x i16>
  %2558 = shufflevector <8 x i16> %2557, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2559 = bitcast <2 x i64> %2530 to <4 x i32>
  %2560 = shufflevector <4 x i32> %2559, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %2561 = bitcast <2 x i64> %2529 to <4 x i32>
  %2562 = shufflevector <4 x i32> %2561, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %2563 = bitcast <2 x i64> %2528 to <4 x i32>
  %2564 = shufflevector <4 x i32> %2563, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %2565 = bitcast <2 x i64> %2527 to <4 x i32>
  %2566 = shufflevector <4 x i32> %2565, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %2567 = bitcast <8 x i16> %2552 to <4 x i32>
  %2568 = add <4 x i32> %2566, %2567
  %2569 = bitcast <8 x i16> %2554 to <4 x i32>
  %2570 = add <4 x i32> %2564, %2569
  %2571 = bitcast <8 x i16> %2556 to <4 x i32>
  %2572 = add <4 x i32> %2562, %2571
  %2573 = bitcast <8 x i16> %2558 to <4 x i32>
  %2574 = add <4 x i32> %2560, %2573
  %2575 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2568, <4 x i32> %2570) #8
  %2576 = bitcast <8 x i16> %2575 to <2 x i64>
  %2577 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2572, <4 x i32> %2574) #8
  %2578 = bitcast <8 x i16> %2577 to <2 x i64>
  %2579 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %2580 = add <8 x i16> %2579, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %2581 = icmp slt <8 x i16> %2580, %2575
  %2582 = sext <8 x i1> %2581 to <8 x i16>
  %2583 = bitcast <8 x i16> %2582 to <2 x i64>
  %2584 = xor <2 x i64> %2583, <i64 -1, i64 -1>
  %2585 = and <2 x i64> %2584, %2576
  %2586 = and <8 x i16> %2580, %2582
  %2587 = bitcast <8 x i16> %2586 to <2 x i64>
  %2588 = or <2 x i64> %2585, %2587
  %2589 = bitcast <2 x i64> %2588 to <8 x i16>
  %2590 = icmp sgt <8 x i16> %2589, zeroinitializer
  %2591 = sext <8 x i1> %2590 to <8 x i16>
  %2592 = bitcast <8 x i16> %2591 to <2 x i64>
  %2593 = and <2 x i64> %2588, %2592
  %2594 = icmp slt <8 x i16> %2580, %2577
  %2595 = sext <8 x i1> %2594 to <8 x i16>
  %2596 = bitcast <8 x i16> %2595 to <2 x i64>
  %2597 = xor <2 x i64> %2596, <i64 -1, i64 -1>
  %2598 = and <2 x i64> %2597, %2578
  %2599 = and <8 x i16> %2580, %2595
  br label %6055

2600:                                             ; preds = %5
  %2601 = bitcast i32* %0 to <4 x i32>*
  %2602 = load <4 x i32>, <4 x i32>* %2601, align 16
  %2603 = getelementptr inbounds i32, i32* %0, i64 4
  %2604 = bitcast i32* %2603 to <4 x i32>*
  %2605 = load <4 x i32>, <4 x i32>* %2604, align 16
  %2606 = getelementptr inbounds i32, i32* %0, i64 8
  %2607 = bitcast i32* %2606 to <4 x i32>*
  %2608 = load <4 x i32>, <4 x i32>* %2607, align 16
  %2609 = getelementptr inbounds i32, i32* %0, i64 12
  %2610 = bitcast i32* %2609 to <4 x i32>*
  %2611 = load <4 x i32>, <4 x i32>* %2610, align 16
  %2612 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 0, i64 0), align 16
  %2613 = sext i8 %2612 to i32
  %2614 = add nsw i32 %2613, -10
  %2615 = sext i32 %2614 to i64
  %2616 = add nsw i32 %2613, 3
  %2617 = shl i32 1, %2616
  %2618 = insertelement <4 x i32> undef, i32 %2617, i32 0
  %2619 = shufflevector <4 x i32> %2618, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %2620 = shufflevector <4 x i32> %2619, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2621 = bitcast <4 x i32> %2620 to <2 x i64>
  %2622 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2615, i64 1
  %2623 = load i32, i32* %2622, align 4
  %2624 = insertelement <4 x i32> undef, i32 %2623, i32 0
  %2625 = shufflevector <4 x i32> %2624, <4 x i32> undef, <4 x i32> zeroinitializer
  %2626 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2615, i64 2
  %2627 = load i32, i32* %2626, align 4
  %2628 = insertelement <4 x i32> undef, i32 %2627, i32 0
  %2629 = shufflevector <4 x i32> %2628, <4 x i32> undef, <4 x i32> zeroinitializer
  %2630 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2615, i64 3
  %2631 = load i32, i32* %2630, align 4
  %2632 = insertelement <4 x i32> undef, i32 %2631, i32 0
  %2633 = shufflevector <4 x i32> %2632, <4 x i32> undef, <4 x i32> zeroinitializer
  %2634 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2615, i64 4
  %2635 = load i32, i32* %2634, align 4
  %2636 = insertelement <4 x i32> undef, i32 %2635, i32 0
  %2637 = shufflevector <4 x i32> %2636, <4 x i32> undef, <4 x i32> zeroinitializer
  %2638 = shufflevector <4 x i32> %2602, <4 x i32> %2605, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2639 = bitcast <4 x i32> %2638 to <2 x i64>
  %2640 = shufflevector <4 x i32> %2602, <4 x i32> %2605, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2641 = bitcast <4 x i32> %2640 to <2 x i64>
  %2642 = shufflevector <4 x i32> %2608, <4 x i32> %2611, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2643 = bitcast <4 x i32> %2642 to <2 x i64>
  %2644 = shufflevector <4 x i32> %2608, <4 x i32> %2611, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2645 = bitcast <4 x i32> %2644 to <2 x i64>
  %2646 = shufflevector <2 x i64> %2639, <2 x i64> %2643, <2 x i32> <i32 0, i32 2>
  %2647 = shufflevector <2 x i64> %2639, <2 x i64> %2643, <2 x i32> <i32 1, i32 3>
  %2648 = shufflevector <2 x i64> %2641, <2 x i64> %2645, <2 x i32> <i32 0, i32 2>
  %2649 = shufflevector <2 x i64> %2641, <2 x i64> %2645, <2 x i32> <i32 1, i32 3>
  %2650 = bitcast <2 x i64> %2646 to <4 x i32>
  %2651 = mul <4 x i32> %2625, %2650
  %2652 = mul <4 x i32> %2629, %2650
  %2653 = bitcast <2 x i64> %2647 to <4 x i32>
  %2654 = mul <4 x i32> %2633, %2653
  %2655 = bitcast <2 x i64> %2648 to <4 x i32>
  %2656 = mul <4 x i32> %2637, %2655
  %2657 = mul <4 x i32> %2625, %2655
  %2658 = bitcast <2 x i64> %2649 to <4 x i32>
  %2659 = mul <4 x i32> %2629, %2658
  %2660 = sub <4 x i32> %2650, %2655
  %2661 = add <4 x i32> %2660, %2658
  %2662 = add <4 x i32> %2659, %2651
  %2663 = add <4 x i32> %2662, %2656
  %2664 = sub <4 x i32> %2652, %2657
  %2665 = mul <4 x i32> %2637, %2658
  %2666 = sub <4 x i32> %2664, %2665
  %2667 = mul <4 x i32> %2661, %2633
  %2668 = bitcast <4 x i32> %2667 to <2 x i64>
  %2669 = add <4 x i32> %2663, %2654
  %2670 = bitcast <4 x i32> %2669 to <2 x i64>
  %2671 = add <4 x i32> %2666, %2654
  %2672 = bitcast <4 x i32> %2671 to <2 x i64>
  %2673 = sub <4 x i32> %2663, %2654
  %2674 = add <4 x i32> %2673, %2666
  %2675 = bitcast <4 x i32> %2674 to <2 x i64>
  %2676 = shl <2 x i64> %2670, <i64 32, i64 32>
  %2677 = ashr exact <2 x i64> %2676, <i64 28, i64 28>
  %2678 = add <2 x i64> %2677, %2621
  %2679 = bitcast <4 x i32> %2669 to <16 x i8>
  %2680 = shufflevector <16 x i8> %2679, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2681 = bitcast <16 x i8> %2680 to <2 x i64>
  %2682 = shl <2 x i64> %2681, <i64 32, i64 32>
  %2683 = ashr exact <2 x i64> %2682, <i64 28, i64 28>
  %2684 = add <2 x i64> %2683, %2621
  %2685 = bitcast <2 x i64> %2678 to <16 x i8>
  %2686 = shufflevector <16 x i8> %2685, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2687 = bitcast <2 x i64> %2684 to <16 x i8>
  %2688 = shufflevector <16 x i8> %2687, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2689 = bitcast <16 x i8> %2686 to <4 x i32>
  %2690 = bitcast <16 x i8> %2688 to <4 x i32>
  %2691 = shufflevector <4 x i32> %2689, <4 x i32> %2690, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2692 = bitcast <4 x i32> %2691 to <2 x i64>
  %2693 = shufflevector <4 x i32> %2689, <4 x i32> %2690, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2694 = bitcast <4 x i32> %2693 to <2 x i64>
  %2695 = shufflevector <2 x i64> %2692, <2 x i64> %2694, <2 x i32> <i32 0, i32 2>
  %2696 = shl <2 x i64> %2672, <i64 32, i64 32>
  %2697 = ashr exact <2 x i64> %2696, <i64 28, i64 28>
  %2698 = add <2 x i64> %2697, %2621
  %2699 = bitcast <4 x i32> %2671 to <16 x i8>
  %2700 = shufflevector <16 x i8> %2699, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2701 = bitcast <16 x i8> %2700 to <2 x i64>
  %2702 = shl <2 x i64> %2701, <i64 32, i64 32>
  %2703 = ashr exact <2 x i64> %2702, <i64 28, i64 28>
  %2704 = add <2 x i64> %2703, %2621
  %2705 = bitcast <2 x i64> %2698 to <16 x i8>
  %2706 = shufflevector <16 x i8> %2705, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2707 = bitcast <2 x i64> %2704 to <16 x i8>
  %2708 = shufflevector <16 x i8> %2707, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2709 = bitcast <16 x i8> %2706 to <4 x i32>
  %2710 = bitcast <16 x i8> %2708 to <4 x i32>
  %2711 = shufflevector <4 x i32> %2709, <4 x i32> %2710, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2712 = bitcast <4 x i32> %2711 to <2 x i64>
  %2713 = shufflevector <4 x i32> %2709, <4 x i32> %2710, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2714 = bitcast <4 x i32> %2713 to <2 x i64>
  %2715 = shufflevector <2 x i64> %2712, <2 x i64> %2714, <2 x i32> <i32 0, i32 2>
  %2716 = shl <2 x i64> %2668, <i64 32, i64 32>
  %2717 = ashr exact <2 x i64> %2716, <i64 28, i64 28>
  %2718 = add <2 x i64> %2717, %2621
  %2719 = bitcast <4 x i32> %2667 to <16 x i8>
  %2720 = shufflevector <16 x i8> %2719, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2721 = bitcast <16 x i8> %2720 to <2 x i64>
  %2722 = shl <2 x i64> %2721, <i64 32, i64 32>
  %2723 = ashr exact <2 x i64> %2722, <i64 28, i64 28>
  %2724 = add <2 x i64> %2723, %2621
  %2725 = bitcast <2 x i64> %2718 to <16 x i8>
  %2726 = shufflevector <16 x i8> %2725, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2727 = bitcast <2 x i64> %2724 to <16 x i8>
  %2728 = shufflevector <16 x i8> %2727, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2729 = bitcast <16 x i8> %2726 to <4 x i32>
  %2730 = bitcast <16 x i8> %2728 to <4 x i32>
  %2731 = shufflevector <4 x i32> %2729, <4 x i32> %2730, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2732 = bitcast <4 x i32> %2731 to <2 x i64>
  %2733 = shufflevector <4 x i32> %2729, <4 x i32> %2730, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2734 = bitcast <4 x i32> %2733 to <2 x i64>
  %2735 = shufflevector <2 x i64> %2732, <2 x i64> %2734, <2 x i32> <i32 0, i32 2>
  %2736 = shl <2 x i64> %2675, <i64 32, i64 32>
  %2737 = ashr exact <2 x i64> %2736, <i64 28, i64 28>
  %2738 = add <2 x i64> %2737, %2621
  %2739 = bitcast <4 x i32> %2674 to <16 x i8>
  %2740 = shufflevector <16 x i8> %2739, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2741 = bitcast <16 x i8> %2740 to <2 x i64>
  %2742 = shl <2 x i64> %2741, <i64 32, i64 32>
  %2743 = ashr exact <2 x i64> %2742, <i64 28, i64 28>
  %2744 = add <2 x i64> %2743, %2621
  %2745 = bitcast <2 x i64> %2738 to <16 x i8>
  %2746 = shufflevector <16 x i8> %2745, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2747 = bitcast <2 x i64> %2744 to <16 x i8>
  %2748 = shufflevector <16 x i8> %2747, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2749 = bitcast <16 x i8> %2746 to <4 x i32>
  %2750 = bitcast <16 x i8> %2748 to <4 x i32>
  %2751 = shufflevector <4 x i32> %2749, <4 x i32> %2750, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2752 = bitcast <4 x i32> %2751 to <2 x i64>
  %2753 = shufflevector <4 x i32> %2749, <4 x i32> %2750, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2754 = bitcast <4 x i32> %2753 to <2 x i64>
  %2755 = shufflevector <2 x i64> %2752, <2 x i64> %2754, <2 x i32> <i32 0, i32 2>
  %2756 = bitcast <2 x i64> %2695 to <4 x i32>
  %2757 = bitcast <2 x i64> %2715 to <4 x i32>
  %2758 = bitcast <2 x i64> %2735 to <4 x i32>
  %2759 = bitcast <2 x i64> %2755 to <4 x i32>
  %2760 = icmp sgt i32 %4, 10
  %2761 = select i1 %2760, i32 %4, i32 10
  %2762 = shl i32 32, %2761
  %2763 = sub nsw i32 0, %2762
  %2764 = insertelement <4 x i32> undef, i32 %2763, i32 0
  %2765 = shufflevector <4 x i32> %2764, <4 x i32> undef, <4 x i32> zeroinitializer
  %2766 = add nsw i32 %2762, -1
  %2767 = insertelement <4 x i32> undef, i32 %2766, i32 0
  %2768 = shufflevector <4 x i32> %2767, <4 x i32> undef, <4 x i32> zeroinitializer
  %2769 = icmp slt <4 x i32> %2765, %2756
  %2770 = select <4 x i1> %2769, <4 x i32> %2756, <4 x i32> %2765
  %2771 = icmp slt <4 x i32> %2770, %2768
  %2772 = select <4 x i1> %2771, <4 x i32> %2770, <4 x i32> %2768
  %2773 = icmp slt <4 x i32> %2765, %2757
  %2774 = select <4 x i1> %2773, <4 x i32> %2757, <4 x i32> %2765
  %2775 = icmp slt <4 x i32> %2774, %2768
  %2776 = select <4 x i1> %2775, <4 x i32> %2774, <4 x i32> %2768
  %2777 = icmp slt <4 x i32> %2765, %2758
  %2778 = select <4 x i1> %2777, <4 x i32> %2758, <4 x i32> %2765
  %2779 = icmp slt <4 x i32> %2778, %2768
  %2780 = select <4 x i1> %2779, <4 x i32> %2778, <4 x i32> %2768
  %2781 = icmp slt <4 x i32> %2765, %2759
  %2782 = select <4 x i1> %2781, <4 x i32> %2759, <4 x i32> %2765
  %2783 = icmp slt <4 x i32> %2782, %2768
  %2784 = select <4 x i1> %2783, <4 x i32> %2782, <4 x i32> %2768
  %2785 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 0, i64 0), align 16
  %2786 = sext i8 %2785 to i32
  %2787 = add nsw i32 %2786, -10
  %2788 = sext i32 %2787 to i64
  %2789 = add nsw i32 %2786, 3
  %2790 = shl i32 1, %2789
  %2791 = insertelement <4 x i32> undef, i32 %2790, i32 0
  %2792 = shufflevector <4 x i32> %2791, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %2793 = shufflevector <4 x i32> %2792, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2794 = bitcast <4 x i32> %2793 to <2 x i64>
  %2795 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2788, i64 1
  %2796 = load i32, i32* %2795, align 4
  %2797 = insertelement <4 x i32> undef, i32 %2796, i32 0
  %2798 = shufflevector <4 x i32> %2797, <4 x i32> undef, <4 x i32> zeroinitializer
  %2799 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2788, i64 2
  %2800 = load i32, i32* %2799, align 4
  %2801 = insertelement <4 x i32> undef, i32 %2800, i32 0
  %2802 = shufflevector <4 x i32> %2801, <4 x i32> undef, <4 x i32> zeroinitializer
  %2803 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2788, i64 3
  %2804 = load i32, i32* %2803, align 4
  %2805 = insertelement <4 x i32> undef, i32 %2804, i32 0
  %2806 = shufflevector <4 x i32> %2805, <4 x i32> undef, <4 x i32> zeroinitializer
  %2807 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %2788, i64 4
  %2808 = load i32, i32* %2807, align 4
  %2809 = insertelement <4 x i32> undef, i32 %2808, i32 0
  %2810 = shufflevector <4 x i32> %2809, <4 x i32> undef, <4 x i32> zeroinitializer
  %2811 = shufflevector <4 x i32> %2772, <4 x i32> %2776, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2812 = bitcast <4 x i32> %2811 to <2 x i64>
  %2813 = shufflevector <4 x i32> %2772, <4 x i32> %2776, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2814 = bitcast <4 x i32> %2813 to <2 x i64>
  %2815 = shufflevector <4 x i32> %2780, <4 x i32> %2784, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2816 = bitcast <4 x i32> %2815 to <2 x i64>
  %2817 = shufflevector <4 x i32> %2780, <4 x i32> %2784, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2818 = bitcast <4 x i32> %2817 to <2 x i64>
  %2819 = shufflevector <2 x i64> %2812, <2 x i64> %2816, <2 x i32> <i32 0, i32 2>
  %2820 = shufflevector <2 x i64> %2812, <2 x i64> %2816, <2 x i32> <i32 1, i32 3>
  %2821 = shufflevector <2 x i64> %2814, <2 x i64> %2818, <2 x i32> <i32 0, i32 2>
  %2822 = shufflevector <2 x i64> %2814, <2 x i64> %2818, <2 x i32> <i32 1, i32 3>
  %2823 = bitcast <2 x i64> %2819 to <4 x i32>
  %2824 = mul <4 x i32> %2798, %2823
  %2825 = mul <4 x i32> %2802, %2823
  %2826 = bitcast <2 x i64> %2820 to <4 x i32>
  %2827 = mul <4 x i32> %2806, %2826
  %2828 = bitcast <2 x i64> %2821 to <4 x i32>
  %2829 = mul <4 x i32> %2810, %2828
  %2830 = mul <4 x i32> %2798, %2828
  %2831 = bitcast <2 x i64> %2822 to <4 x i32>
  %2832 = mul <4 x i32> %2802, %2831
  %2833 = sub <4 x i32> %2823, %2828
  %2834 = add <4 x i32> %2833, %2831
  %2835 = add <4 x i32> %2829, %2824
  %2836 = add <4 x i32> %2835, %2832
  %2837 = sub <4 x i32> %2825, %2830
  %2838 = mul <4 x i32> %2810, %2831
  %2839 = sub <4 x i32> %2837, %2838
  %2840 = mul <4 x i32> %2834, %2806
  %2841 = bitcast <4 x i32> %2840 to <2 x i64>
  %2842 = add <4 x i32> %2836, %2827
  %2843 = bitcast <4 x i32> %2842 to <2 x i64>
  %2844 = add <4 x i32> %2839, %2827
  %2845 = bitcast <4 x i32> %2844 to <2 x i64>
  %2846 = sub <4 x i32> %2836, %2827
  %2847 = add <4 x i32> %2846, %2839
  %2848 = bitcast <4 x i32> %2847 to <2 x i64>
  %2849 = shl <2 x i64> %2843, <i64 32, i64 32>
  %2850 = ashr exact <2 x i64> %2849, <i64 28, i64 28>
  %2851 = add <2 x i64> %2850, %2794
  %2852 = bitcast <4 x i32> %2842 to <16 x i8>
  %2853 = shufflevector <16 x i8> %2852, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2854 = bitcast <16 x i8> %2853 to <2 x i64>
  %2855 = shl <2 x i64> %2854, <i64 32, i64 32>
  %2856 = ashr exact <2 x i64> %2855, <i64 28, i64 28>
  %2857 = add <2 x i64> %2856, %2794
  %2858 = bitcast <2 x i64> %2851 to <16 x i8>
  %2859 = shufflevector <16 x i8> %2858, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2860 = bitcast <2 x i64> %2857 to <16 x i8>
  %2861 = shufflevector <16 x i8> %2860, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2862 = bitcast <16 x i8> %2859 to <4 x i32>
  %2863 = bitcast <16 x i8> %2861 to <4 x i32>
  %2864 = shufflevector <4 x i32> %2862, <4 x i32> %2863, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2865 = bitcast <4 x i32> %2864 to <2 x i64>
  %2866 = shufflevector <4 x i32> %2862, <4 x i32> %2863, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2867 = bitcast <4 x i32> %2866 to <2 x i64>
  %2868 = shufflevector <2 x i64> %2865, <2 x i64> %2867, <2 x i32> <i32 0, i32 2>
  %2869 = shl <2 x i64> %2845, <i64 32, i64 32>
  %2870 = ashr exact <2 x i64> %2869, <i64 28, i64 28>
  %2871 = add <2 x i64> %2870, %2794
  %2872 = bitcast <4 x i32> %2844 to <16 x i8>
  %2873 = shufflevector <16 x i8> %2872, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2874 = bitcast <16 x i8> %2873 to <2 x i64>
  %2875 = shl <2 x i64> %2874, <i64 32, i64 32>
  %2876 = ashr exact <2 x i64> %2875, <i64 28, i64 28>
  %2877 = add <2 x i64> %2876, %2794
  %2878 = bitcast <2 x i64> %2871 to <16 x i8>
  %2879 = shufflevector <16 x i8> %2878, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2880 = bitcast <2 x i64> %2877 to <16 x i8>
  %2881 = shufflevector <16 x i8> %2880, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2882 = bitcast <16 x i8> %2879 to <4 x i32>
  %2883 = bitcast <16 x i8> %2881 to <4 x i32>
  %2884 = shufflevector <4 x i32> %2882, <4 x i32> %2883, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2885 = bitcast <4 x i32> %2884 to <2 x i64>
  %2886 = shufflevector <4 x i32> %2882, <4 x i32> %2883, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2887 = bitcast <4 x i32> %2886 to <2 x i64>
  %2888 = shufflevector <2 x i64> %2885, <2 x i64> %2887, <2 x i32> <i32 0, i32 2>
  %2889 = shl <2 x i64> %2841, <i64 32, i64 32>
  %2890 = ashr exact <2 x i64> %2889, <i64 28, i64 28>
  %2891 = add <2 x i64> %2890, %2794
  %2892 = bitcast <4 x i32> %2840 to <16 x i8>
  %2893 = shufflevector <16 x i8> %2892, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2894 = bitcast <16 x i8> %2893 to <2 x i64>
  %2895 = shl <2 x i64> %2894, <i64 32, i64 32>
  %2896 = ashr exact <2 x i64> %2895, <i64 28, i64 28>
  %2897 = add <2 x i64> %2896, %2794
  %2898 = bitcast <2 x i64> %2891 to <16 x i8>
  %2899 = shufflevector <16 x i8> %2898, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2900 = bitcast <2 x i64> %2897 to <16 x i8>
  %2901 = shufflevector <16 x i8> %2900, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2902 = bitcast <16 x i8> %2899 to <4 x i32>
  %2903 = bitcast <16 x i8> %2901 to <4 x i32>
  %2904 = shufflevector <4 x i32> %2902, <4 x i32> %2903, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2905 = bitcast <4 x i32> %2904 to <2 x i64>
  %2906 = shufflevector <4 x i32> %2902, <4 x i32> %2903, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2907 = bitcast <4 x i32> %2906 to <2 x i64>
  %2908 = shufflevector <2 x i64> %2905, <2 x i64> %2907, <2 x i32> <i32 0, i32 2>
  %2909 = shl <2 x i64> %2848, <i64 32, i64 32>
  %2910 = ashr exact <2 x i64> %2909, <i64 28, i64 28>
  %2911 = add <2 x i64> %2910, %2794
  %2912 = bitcast <4 x i32> %2847 to <16 x i8>
  %2913 = shufflevector <16 x i8> %2912, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %2914 = bitcast <16 x i8> %2913 to <2 x i64>
  %2915 = shl <2 x i64> %2914, <i64 32, i64 32>
  %2916 = ashr exact <2 x i64> %2915, <i64 28, i64 28>
  %2917 = add <2 x i64> %2916, %2794
  %2918 = bitcast <2 x i64> %2911 to <16 x i8>
  %2919 = shufflevector <16 x i8> %2918, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2920 = bitcast <2 x i64> %2917 to <16 x i8>
  %2921 = shufflevector <16 x i8> %2920, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %2922 = bitcast <16 x i8> %2919 to <4 x i32>
  %2923 = bitcast <16 x i8> %2921 to <4 x i32>
  %2924 = shufflevector <4 x i32> %2922, <4 x i32> %2923, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %2925 = bitcast <4 x i32> %2924 to <2 x i64>
  %2926 = shufflevector <4 x i32> %2922, <4 x i32> %2923, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %2927 = bitcast <4 x i32> %2926 to <2 x i64>
  %2928 = shufflevector <2 x i64> %2925, <2 x i64> %2927, <2 x i32> <i32 0, i32 2>
  %2929 = getelementptr inbounds i8, i8* %6, i64 1
  %2930 = load i8, i8* %2929, align 1
  %2931 = sext i8 %2930 to i32
  %2932 = sub nsw i32 0, %2931
  %2933 = icmp eq i8 %2930, 0
  br i1 %2933, label %2955, label %2934

2934:                                             ; preds = %2600
  %2935 = xor i32 %2931, -1
  %2936 = shl i32 1, %2935
  %2937 = insertelement <4 x i32> undef, i32 %2936, i32 0
  %2938 = shufflevector <4 x i32> %2937, <4 x i32> undef, <4 x i32> zeroinitializer
  %2939 = bitcast <2 x i64> %2868 to <4 x i32>
  %2940 = add <4 x i32> %2938, %2939
  %2941 = bitcast <2 x i64> %2888 to <4 x i32>
  %2942 = add <4 x i32> %2938, %2941
  %2943 = bitcast <2 x i64> %2908 to <4 x i32>
  %2944 = add <4 x i32> %2938, %2943
  %2945 = bitcast <2 x i64> %2928 to <4 x i32>
  %2946 = add <4 x i32> %2938, %2945
  %2947 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2940, i32 %2932) #8
  %2948 = bitcast <4 x i32> %2947 to <2 x i64>
  %2949 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2942, i32 %2932) #8
  %2950 = bitcast <4 x i32> %2949 to <2 x i64>
  %2951 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2944, i32 %2932) #8
  %2952 = bitcast <4 x i32> %2951 to <2 x i64>
  %2953 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2946, i32 %2932) #8
  %2954 = bitcast <4 x i32> %2953 to <2 x i64>
  br label %2955

2955:                                             ; preds = %2600, %2934
  %2956 = phi <2 x i64> [ %2928, %2600 ], [ %2954, %2934 ]
  %2957 = phi <2 x i64> [ %2908, %2600 ], [ %2952, %2934 ]
  %2958 = phi <2 x i64> [ %2888, %2600 ], [ %2950, %2934 ]
  %2959 = phi <2 x i64> [ %2868, %2600 ], [ %2948, %2934 ]
  %2960 = bitcast i16* %1 to i64*
  %2961 = load i64, i64* %2960, align 1
  %2962 = insertelement <2 x i64> undef, i64 %2961, i32 0
  %2963 = sext i32 %2 to i64
  %2964 = getelementptr inbounds i16, i16* %1, i64 %2963
  %2965 = bitcast i16* %2964 to i64*
  %2966 = load i64, i64* %2965, align 1
  %2967 = insertelement <2 x i64> undef, i64 %2966, i32 0
  %2968 = shl nsw i32 %2, 1
  %2969 = sext i32 %2968 to i64
  %2970 = getelementptr inbounds i16, i16* %1, i64 %2969
  %2971 = bitcast i16* %2970 to i64*
  %2972 = load i64, i64* %2971, align 1
  %2973 = insertelement <2 x i64> undef, i64 %2972, i32 0
  %2974 = mul nsw i32 %2, 3
  %2975 = sext i32 %2974 to i64
  %2976 = getelementptr inbounds i16, i16* %1, i64 %2975
  %2977 = bitcast i16* %2976 to i64*
  %2978 = load i64, i64* %2977, align 1
  %2979 = insertelement <2 x i64> undef, i64 %2978, i32 0
  %2980 = bitcast <2 x i64> %2962 to <8 x i16>
  %2981 = shufflevector <8 x i16> %2980, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2982 = bitcast <2 x i64> %2967 to <8 x i16>
  %2983 = shufflevector <8 x i16> %2982, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2984 = bitcast <2 x i64> %2973 to <8 x i16>
  %2985 = shufflevector <8 x i16> %2984, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2986 = bitcast <2 x i64> %2979 to <8 x i16>
  %2987 = shufflevector <8 x i16> %2986, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2988 = bitcast <2 x i64> %2959 to <4 x i32>
  %2989 = shufflevector <4 x i32> %2988, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %2990 = bitcast <2 x i64> %2958 to <4 x i32>
  %2991 = shufflevector <4 x i32> %2990, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %2992 = bitcast <2 x i64> %2957 to <4 x i32>
  %2993 = shufflevector <4 x i32> %2992, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %2994 = bitcast <2 x i64> %2956 to <4 x i32>
  %2995 = shufflevector <4 x i32> %2994, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %2996 = bitcast <8 x i16> %2981 to <4 x i32>
  %2997 = add <4 x i32> %2989, %2996
  %2998 = bitcast <8 x i16> %2983 to <4 x i32>
  %2999 = add <4 x i32> %2991, %2998
  %3000 = bitcast <8 x i16> %2985 to <4 x i32>
  %3001 = add <4 x i32> %2993, %3000
  %3002 = bitcast <8 x i16> %2987 to <4 x i32>
  %3003 = add <4 x i32> %2995, %3002
  %3004 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2997, <4 x i32> %2999) #8
  %3005 = bitcast <8 x i16> %3004 to <2 x i64>
  %3006 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %3001, <4 x i32> %3003) #8
  %3007 = bitcast <8 x i16> %3006 to <2 x i64>
  %3008 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %3009 = add <8 x i16> %3008, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %3010 = icmp slt <8 x i16> %3009, %3004
  %3011 = sext <8 x i1> %3010 to <8 x i16>
  %3012 = bitcast <8 x i16> %3011 to <2 x i64>
  %3013 = xor <2 x i64> %3012, <i64 -1, i64 -1>
  %3014 = and <2 x i64> %3013, %3005
  %3015 = and <8 x i16> %3009, %3011
  %3016 = bitcast <8 x i16> %3015 to <2 x i64>
  %3017 = or <2 x i64> %3014, %3016
  %3018 = bitcast <2 x i64> %3017 to <8 x i16>
  %3019 = icmp sgt <8 x i16> %3018, zeroinitializer
  %3020 = sext <8 x i1> %3019 to <8 x i16>
  %3021 = bitcast <8 x i16> %3020 to <2 x i64>
  %3022 = and <2 x i64> %3017, %3021
  %3023 = icmp slt <8 x i16> %3009, %3006
  %3024 = sext <8 x i1> %3023 to <8 x i16>
  %3025 = bitcast <8 x i16> %3024 to <2 x i64>
  %3026 = xor <2 x i64> %3025, <i64 -1, i64 -1>
  %3027 = and <2 x i64> %3026, %3007
  %3028 = and <8 x i16> %3009, %3024
  br label %6055

3029:                                             ; preds = %5
  %3030 = bitcast i32* %0 to <4 x i32>*
  %3031 = load <4 x i32>, <4 x i32>* %3030, align 16
  %3032 = getelementptr inbounds i32, i32* %0, i64 4
  %3033 = bitcast i32* %3032 to <4 x i32>*
  %3034 = load <4 x i32>, <4 x i32>* %3033, align 16
  %3035 = getelementptr inbounds i32, i32* %0, i64 8
  %3036 = bitcast i32* %3035 to <4 x i32>*
  %3037 = load <4 x i32>, <4 x i32>* %3036, align 16
  %3038 = getelementptr inbounds i32, i32* %0, i64 12
  %3039 = bitcast i32* %3038 to <4 x i32>*
  %3040 = load <4 x i32>, <4 x i32>* %3039, align 16
  %3041 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 0, i64 0), align 16
  %3042 = sext i8 %3041 to i32
  %3043 = add nsw i32 %3042, -10
  %3044 = sext i32 %3043 to i64
  %3045 = add nsw i32 %3042, 3
  %3046 = shl i32 1, %3045
  %3047 = insertelement <4 x i32> undef, i32 %3046, i32 0
  %3048 = shufflevector <4 x i32> %3047, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %3049 = shufflevector <4 x i32> %3048, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3050 = bitcast <4 x i32> %3049 to <2 x i64>
  %3051 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %3044, i64 1
  %3052 = load i32, i32* %3051, align 4
  %3053 = insertelement <4 x i32> undef, i32 %3052, i32 0
  %3054 = shufflevector <4 x i32> %3053, <4 x i32> undef, <4 x i32> zeroinitializer
  %3055 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %3044, i64 2
  %3056 = load i32, i32* %3055, align 4
  %3057 = insertelement <4 x i32> undef, i32 %3056, i32 0
  %3058 = shufflevector <4 x i32> %3057, <4 x i32> undef, <4 x i32> zeroinitializer
  %3059 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %3044, i64 3
  %3060 = load i32, i32* %3059, align 4
  %3061 = insertelement <4 x i32> undef, i32 %3060, i32 0
  %3062 = shufflevector <4 x i32> %3061, <4 x i32> undef, <4 x i32> zeroinitializer
  %3063 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %3044, i64 4
  %3064 = load i32, i32* %3063, align 4
  %3065 = insertelement <4 x i32> undef, i32 %3064, i32 0
  %3066 = shufflevector <4 x i32> %3065, <4 x i32> undef, <4 x i32> zeroinitializer
  %3067 = shufflevector <4 x i32> %3031, <4 x i32> %3034, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3068 = bitcast <4 x i32> %3067 to <2 x i64>
  %3069 = shufflevector <4 x i32> %3031, <4 x i32> %3034, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3070 = bitcast <4 x i32> %3069 to <2 x i64>
  %3071 = shufflevector <4 x i32> %3037, <4 x i32> %3040, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3072 = bitcast <4 x i32> %3071 to <2 x i64>
  %3073 = shufflevector <4 x i32> %3037, <4 x i32> %3040, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3074 = bitcast <4 x i32> %3073 to <2 x i64>
  %3075 = shufflevector <2 x i64> %3068, <2 x i64> %3072, <2 x i32> <i32 0, i32 2>
  %3076 = shufflevector <2 x i64> %3068, <2 x i64> %3072, <2 x i32> <i32 1, i32 3>
  %3077 = shufflevector <2 x i64> %3070, <2 x i64> %3074, <2 x i32> <i32 0, i32 2>
  %3078 = shufflevector <2 x i64> %3070, <2 x i64> %3074, <2 x i32> <i32 1, i32 3>
  %3079 = bitcast <2 x i64> %3075 to <4 x i32>
  %3080 = mul <4 x i32> %3054, %3079
  %3081 = mul <4 x i32> %3058, %3079
  %3082 = bitcast <2 x i64> %3076 to <4 x i32>
  %3083 = mul <4 x i32> %3062, %3082
  %3084 = bitcast <2 x i64> %3077 to <4 x i32>
  %3085 = mul <4 x i32> %3066, %3084
  %3086 = mul <4 x i32> %3054, %3084
  %3087 = bitcast <2 x i64> %3078 to <4 x i32>
  %3088 = mul <4 x i32> %3058, %3087
  %3089 = sub <4 x i32> %3079, %3084
  %3090 = add <4 x i32> %3089, %3087
  %3091 = add <4 x i32> %3088, %3080
  %3092 = add <4 x i32> %3091, %3085
  %3093 = sub <4 x i32> %3081, %3086
  %3094 = mul <4 x i32> %3066, %3087
  %3095 = sub <4 x i32> %3093, %3094
  %3096 = mul <4 x i32> %3090, %3062
  %3097 = bitcast <4 x i32> %3096 to <2 x i64>
  %3098 = add <4 x i32> %3092, %3083
  %3099 = bitcast <4 x i32> %3098 to <2 x i64>
  %3100 = add <4 x i32> %3095, %3083
  %3101 = bitcast <4 x i32> %3100 to <2 x i64>
  %3102 = sub <4 x i32> %3092, %3083
  %3103 = add <4 x i32> %3102, %3095
  %3104 = bitcast <4 x i32> %3103 to <2 x i64>
  %3105 = shl <2 x i64> %3099, <i64 32, i64 32>
  %3106 = ashr exact <2 x i64> %3105, <i64 28, i64 28>
  %3107 = add <2 x i64> %3106, %3050
  %3108 = bitcast <4 x i32> %3098 to <16 x i8>
  %3109 = shufflevector <16 x i8> %3108, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3110 = bitcast <16 x i8> %3109 to <2 x i64>
  %3111 = shl <2 x i64> %3110, <i64 32, i64 32>
  %3112 = ashr exact <2 x i64> %3111, <i64 28, i64 28>
  %3113 = add <2 x i64> %3112, %3050
  %3114 = bitcast <2 x i64> %3107 to <16 x i8>
  %3115 = shufflevector <16 x i8> %3114, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3116 = bitcast <2 x i64> %3113 to <16 x i8>
  %3117 = shufflevector <16 x i8> %3116, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3118 = bitcast <16 x i8> %3115 to <4 x i32>
  %3119 = bitcast <16 x i8> %3117 to <4 x i32>
  %3120 = shufflevector <4 x i32> %3118, <4 x i32> %3119, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3121 = bitcast <4 x i32> %3120 to <2 x i64>
  %3122 = shufflevector <4 x i32> %3118, <4 x i32> %3119, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3123 = bitcast <4 x i32> %3122 to <2 x i64>
  %3124 = shufflevector <2 x i64> %3121, <2 x i64> %3123, <2 x i32> <i32 0, i32 2>
  %3125 = shl <2 x i64> %3101, <i64 32, i64 32>
  %3126 = ashr exact <2 x i64> %3125, <i64 28, i64 28>
  %3127 = add <2 x i64> %3126, %3050
  %3128 = bitcast <4 x i32> %3100 to <16 x i8>
  %3129 = shufflevector <16 x i8> %3128, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3130 = bitcast <16 x i8> %3129 to <2 x i64>
  %3131 = shl <2 x i64> %3130, <i64 32, i64 32>
  %3132 = ashr exact <2 x i64> %3131, <i64 28, i64 28>
  %3133 = add <2 x i64> %3132, %3050
  %3134 = bitcast <2 x i64> %3127 to <16 x i8>
  %3135 = shufflevector <16 x i8> %3134, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3136 = bitcast <2 x i64> %3133 to <16 x i8>
  %3137 = shufflevector <16 x i8> %3136, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3138 = bitcast <16 x i8> %3135 to <4 x i32>
  %3139 = bitcast <16 x i8> %3137 to <4 x i32>
  %3140 = shufflevector <4 x i32> %3138, <4 x i32> %3139, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3141 = bitcast <4 x i32> %3140 to <2 x i64>
  %3142 = shufflevector <4 x i32> %3138, <4 x i32> %3139, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3143 = bitcast <4 x i32> %3142 to <2 x i64>
  %3144 = shufflevector <2 x i64> %3141, <2 x i64> %3143, <2 x i32> <i32 0, i32 2>
  %3145 = shl <2 x i64> %3097, <i64 32, i64 32>
  %3146 = ashr exact <2 x i64> %3145, <i64 28, i64 28>
  %3147 = add <2 x i64> %3146, %3050
  %3148 = bitcast <4 x i32> %3096 to <16 x i8>
  %3149 = shufflevector <16 x i8> %3148, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3150 = bitcast <16 x i8> %3149 to <2 x i64>
  %3151 = shl <2 x i64> %3150, <i64 32, i64 32>
  %3152 = ashr exact <2 x i64> %3151, <i64 28, i64 28>
  %3153 = add <2 x i64> %3152, %3050
  %3154 = bitcast <2 x i64> %3147 to <16 x i8>
  %3155 = shufflevector <16 x i8> %3154, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3156 = bitcast <2 x i64> %3153 to <16 x i8>
  %3157 = shufflevector <16 x i8> %3156, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3158 = bitcast <16 x i8> %3155 to <4 x i32>
  %3159 = bitcast <16 x i8> %3157 to <4 x i32>
  %3160 = shufflevector <4 x i32> %3158, <4 x i32> %3159, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3161 = bitcast <4 x i32> %3160 to <2 x i64>
  %3162 = shufflevector <4 x i32> %3158, <4 x i32> %3159, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3163 = bitcast <4 x i32> %3162 to <2 x i64>
  %3164 = shufflevector <2 x i64> %3161, <2 x i64> %3163, <2 x i32> <i32 0, i32 2>
  %3165 = shl <2 x i64> %3104, <i64 32, i64 32>
  %3166 = ashr exact <2 x i64> %3165, <i64 28, i64 28>
  %3167 = add <2 x i64> %3166, %3050
  %3168 = bitcast <4 x i32> %3103 to <16 x i8>
  %3169 = shufflevector <16 x i8> %3168, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3170 = bitcast <16 x i8> %3169 to <2 x i64>
  %3171 = shl <2 x i64> %3170, <i64 32, i64 32>
  %3172 = ashr exact <2 x i64> %3171, <i64 28, i64 28>
  %3173 = add <2 x i64> %3172, %3050
  %3174 = bitcast <2 x i64> %3167 to <16 x i8>
  %3175 = shufflevector <16 x i8> %3174, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3176 = bitcast <2 x i64> %3173 to <16 x i8>
  %3177 = shufflevector <16 x i8> %3176, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3178 = bitcast <16 x i8> %3175 to <4 x i32>
  %3179 = bitcast <16 x i8> %3177 to <4 x i32>
  %3180 = shufflevector <4 x i32> %3178, <4 x i32> %3179, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3181 = bitcast <4 x i32> %3180 to <2 x i64>
  %3182 = shufflevector <4 x i32> %3178, <4 x i32> %3179, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3183 = bitcast <4 x i32> %3182 to <2 x i64>
  %3184 = shufflevector <2 x i64> %3181, <2 x i64> %3183, <2 x i32> <i32 0, i32 2>
  %3185 = bitcast <2 x i64> %3124 to <4 x i32>
  %3186 = bitcast <2 x i64> %3144 to <4 x i32>
  %3187 = bitcast <2 x i64> %3164 to <4 x i32>
  %3188 = bitcast <2 x i64> %3184 to <4 x i32>
  %3189 = icmp sgt i32 %4, 10
  %3190 = select i1 %3189, i32 %4, i32 10
  %3191 = shl i32 32, %3190
  %3192 = sub nsw i32 0, %3191
  %3193 = insertelement <4 x i32> undef, i32 %3192, i32 0
  %3194 = shufflevector <4 x i32> %3193, <4 x i32> undef, <4 x i32> zeroinitializer
  %3195 = add nsw i32 %3191, -1
  %3196 = insertelement <4 x i32> undef, i32 %3195, i32 0
  %3197 = shufflevector <4 x i32> %3196, <4 x i32> undef, <4 x i32> zeroinitializer
  %3198 = icmp slt <4 x i32> %3194, %3185
  %3199 = select <4 x i1> %3198, <4 x i32> %3185, <4 x i32> %3194
  %3200 = icmp slt <4 x i32> %3199, %3197
  %3201 = select <4 x i1> %3200, <4 x i32> %3199, <4 x i32> %3197
  %3202 = icmp slt <4 x i32> %3194, %3186
  %3203 = select <4 x i1> %3202, <4 x i32> %3186, <4 x i32> %3194
  %3204 = icmp slt <4 x i32> %3203, %3197
  %3205 = select <4 x i1> %3204, <4 x i32> %3203, <4 x i32> %3197
  %3206 = icmp slt <4 x i32> %3194, %3187
  %3207 = select <4 x i1> %3206, <4 x i32> %3187, <4 x i32> %3194
  %3208 = icmp slt <4 x i32> %3207, %3197
  %3209 = select <4 x i1> %3208, <4 x i32> %3207, <4 x i32> %3197
  %3210 = icmp slt <4 x i32> %3194, %3188
  %3211 = select <4 x i1> %3210, <4 x i32> %3188, <4 x i32> %3194
  %3212 = icmp slt <4 x i32> %3211, %3197
  %3213 = select <4 x i1> %3212, <4 x i32> %3211, <4 x i32> %3197
  %3214 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 0, i64 0), align 16
  %3215 = sext i8 %3214 to i32
  %3216 = add nsw i32 %3215, -10
  %3217 = sext i32 %3216 to i64
  %3218 = add nsw i32 %3215, 3
  %3219 = shl i32 1, %3218
  %3220 = insertelement <4 x i32> undef, i32 %3219, i32 0
  %3221 = shufflevector <4 x i32> %3220, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %3222 = shufflevector <4 x i32> %3221, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3223 = bitcast <4 x i32> %3222 to <2 x i64>
  %3224 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %3217, i64 1
  %3225 = load i32, i32* %3224, align 4
  %3226 = insertelement <4 x i32> undef, i32 %3225, i32 0
  %3227 = shufflevector <4 x i32> %3226, <4 x i32> undef, <4 x i32> zeroinitializer
  %3228 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %3217, i64 2
  %3229 = load i32, i32* %3228, align 4
  %3230 = insertelement <4 x i32> undef, i32 %3229, i32 0
  %3231 = shufflevector <4 x i32> %3230, <4 x i32> undef, <4 x i32> zeroinitializer
  %3232 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %3217, i64 3
  %3233 = load i32, i32* %3232, align 4
  %3234 = insertelement <4 x i32> undef, i32 %3233, i32 0
  %3235 = shufflevector <4 x i32> %3234, <4 x i32> undef, <4 x i32> zeroinitializer
  %3236 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %3217, i64 4
  %3237 = load i32, i32* %3236, align 4
  %3238 = insertelement <4 x i32> undef, i32 %3237, i32 0
  %3239 = shufflevector <4 x i32> %3238, <4 x i32> undef, <4 x i32> zeroinitializer
  %3240 = shufflevector <4 x i32> %3201, <4 x i32> %3205, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3241 = bitcast <4 x i32> %3240 to <2 x i64>
  %3242 = shufflevector <4 x i32> %3201, <4 x i32> %3205, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3243 = bitcast <4 x i32> %3242 to <2 x i64>
  %3244 = shufflevector <4 x i32> %3209, <4 x i32> %3213, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3245 = bitcast <4 x i32> %3244 to <2 x i64>
  %3246 = shufflevector <4 x i32> %3209, <4 x i32> %3213, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3247 = bitcast <4 x i32> %3246 to <2 x i64>
  %3248 = shufflevector <2 x i64> %3241, <2 x i64> %3245, <2 x i32> <i32 0, i32 2>
  %3249 = shufflevector <2 x i64> %3241, <2 x i64> %3245, <2 x i32> <i32 1, i32 3>
  %3250 = shufflevector <2 x i64> %3243, <2 x i64> %3247, <2 x i32> <i32 0, i32 2>
  %3251 = shufflevector <2 x i64> %3243, <2 x i64> %3247, <2 x i32> <i32 1, i32 3>
  %3252 = bitcast <2 x i64> %3248 to <4 x i32>
  %3253 = mul <4 x i32> %3227, %3252
  %3254 = mul <4 x i32> %3231, %3252
  %3255 = bitcast <2 x i64> %3249 to <4 x i32>
  %3256 = mul <4 x i32> %3235, %3255
  %3257 = bitcast <2 x i64> %3250 to <4 x i32>
  %3258 = mul <4 x i32> %3239, %3257
  %3259 = mul <4 x i32> %3227, %3257
  %3260 = bitcast <2 x i64> %3251 to <4 x i32>
  %3261 = mul <4 x i32> %3231, %3260
  %3262 = sub <4 x i32> %3252, %3257
  %3263 = add <4 x i32> %3262, %3260
  %3264 = add <4 x i32> %3258, %3253
  %3265 = add <4 x i32> %3264, %3261
  %3266 = sub <4 x i32> %3254, %3259
  %3267 = mul <4 x i32> %3239, %3260
  %3268 = sub <4 x i32> %3266, %3267
  %3269 = mul <4 x i32> %3263, %3235
  %3270 = bitcast <4 x i32> %3269 to <2 x i64>
  %3271 = add <4 x i32> %3265, %3256
  %3272 = bitcast <4 x i32> %3271 to <2 x i64>
  %3273 = add <4 x i32> %3268, %3256
  %3274 = bitcast <4 x i32> %3273 to <2 x i64>
  %3275 = sub <4 x i32> %3265, %3256
  %3276 = add <4 x i32> %3275, %3268
  %3277 = bitcast <4 x i32> %3276 to <2 x i64>
  %3278 = shl <2 x i64> %3272, <i64 32, i64 32>
  %3279 = ashr exact <2 x i64> %3278, <i64 28, i64 28>
  %3280 = add <2 x i64> %3279, %3223
  %3281 = bitcast <4 x i32> %3271 to <16 x i8>
  %3282 = shufflevector <16 x i8> %3281, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3283 = bitcast <16 x i8> %3282 to <2 x i64>
  %3284 = shl <2 x i64> %3283, <i64 32, i64 32>
  %3285 = ashr exact <2 x i64> %3284, <i64 28, i64 28>
  %3286 = add <2 x i64> %3285, %3223
  %3287 = bitcast <2 x i64> %3280 to <16 x i8>
  %3288 = shufflevector <16 x i8> %3287, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3289 = bitcast <2 x i64> %3286 to <16 x i8>
  %3290 = shufflevector <16 x i8> %3289, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3291 = bitcast <16 x i8> %3288 to <4 x i32>
  %3292 = bitcast <16 x i8> %3290 to <4 x i32>
  %3293 = shufflevector <4 x i32> %3291, <4 x i32> %3292, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3294 = bitcast <4 x i32> %3293 to <2 x i64>
  %3295 = shufflevector <4 x i32> %3291, <4 x i32> %3292, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3296 = bitcast <4 x i32> %3295 to <2 x i64>
  %3297 = shufflevector <2 x i64> %3294, <2 x i64> %3296, <2 x i32> <i32 0, i32 2>
  %3298 = shl <2 x i64> %3274, <i64 32, i64 32>
  %3299 = ashr exact <2 x i64> %3298, <i64 28, i64 28>
  %3300 = add <2 x i64> %3299, %3223
  %3301 = bitcast <4 x i32> %3273 to <16 x i8>
  %3302 = shufflevector <16 x i8> %3301, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3303 = bitcast <16 x i8> %3302 to <2 x i64>
  %3304 = shl <2 x i64> %3303, <i64 32, i64 32>
  %3305 = ashr exact <2 x i64> %3304, <i64 28, i64 28>
  %3306 = add <2 x i64> %3305, %3223
  %3307 = bitcast <2 x i64> %3300 to <16 x i8>
  %3308 = shufflevector <16 x i8> %3307, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3309 = bitcast <2 x i64> %3306 to <16 x i8>
  %3310 = shufflevector <16 x i8> %3309, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3311 = bitcast <16 x i8> %3308 to <4 x i32>
  %3312 = bitcast <16 x i8> %3310 to <4 x i32>
  %3313 = shufflevector <4 x i32> %3311, <4 x i32> %3312, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3314 = bitcast <4 x i32> %3313 to <2 x i64>
  %3315 = shufflevector <4 x i32> %3311, <4 x i32> %3312, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3316 = bitcast <4 x i32> %3315 to <2 x i64>
  %3317 = shufflevector <2 x i64> %3314, <2 x i64> %3316, <2 x i32> <i32 0, i32 2>
  %3318 = shl <2 x i64> %3270, <i64 32, i64 32>
  %3319 = ashr exact <2 x i64> %3318, <i64 28, i64 28>
  %3320 = add <2 x i64> %3319, %3223
  %3321 = bitcast <4 x i32> %3269 to <16 x i8>
  %3322 = shufflevector <16 x i8> %3321, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3323 = bitcast <16 x i8> %3322 to <2 x i64>
  %3324 = shl <2 x i64> %3323, <i64 32, i64 32>
  %3325 = ashr exact <2 x i64> %3324, <i64 28, i64 28>
  %3326 = add <2 x i64> %3325, %3223
  %3327 = bitcast <2 x i64> %3320 to <16 x i8>
  %3328 = shufflevector <16 x i8> %3327, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3329 = bitcast <2 x i64> %3326 to <16 x i8>
  %3330 = shufflevector <16 x i8> %3329, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3331 = bitcast <16 x i8> %3328 to <4 x i32>
  %3332 = bitcast <16 x i8> %3330 to <4 x i32>
  %3333 = shufflevector <4 x i32> %3331, <4 x i32> %3332, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3334 = bitcast <4 x i32> %3333 to <2 x i64>
  %3335 = shufflevector <4 x i32> %3331, <4 x i32> %3332, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3336 = bitcast <4 x i32> %3335 to <2 x i64>
  %3337 = shufflevector <2 x i64> %3334, <2 x i64> %3336, <2 x i32> <i32 0, i32 2>
  %3338 = shl <2 x i64> %3277, <i64 32, i64 32>
  %3339 = ashr exact <2 x i64> %3338, <i64 28, i64 28>
  %3340 = add <2 x i64> %3339, %3223
  %3341 = bitcast <4 x i32> %3276 to <16 x i8>
  %3342 = shufflevector <16 x i8> %3341, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3343 = bitcast <16 x i8> %3342 to <2 x i64>
  %3344 = shl <2 x i64> %3343, <i64 32, i64 32>
  %3345 = ashr exact <2 x i64> %3344, <i64 28, i64 28>
  %3346 = add <2 x i64> %3345, %3223
  %3347 = bitcast <2 x i64> %3340 to <16 x i8>
  %3348 = shufflevector <16 x i8> %3347, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3349 = bitcast <2 x i64> %3346 to <16 x i8>
  %3350 = shufflevector <16 x i8> %3349, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %3351 = bitcast <16 x i8> %3348 to <4 x i32>
  %3352 = bitcast <16 x i8> %3350 to <4 x i32>
  %3353 = shufflevector <4 x i32> %3351, <4 x i32> %3352, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3354 = bitcast <4 x i32> %3353 to <2 x i64>
  %3355 = shufflevector <4 x i32> %3351, <4 x i32> %3352, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3356 = bitcast <4 x i32> %3355 to <2 x i64>
  %3357 = shufflevector <2 x i64> %3354, <2 x i64> %3356, <2 x i32> <i32 0, i32 2>
  %3358 = getelementptr inbounds i8, i8* %6, i64 1
  %3359 = load i8, i8* %3358, align 1
  %3360 = sext i8 %3359 to i32
  %3361 = sub nsw i32 0, %3360
  %3362 = icmp eq i8 %3359, 0
  br i1 %3362, label %3384, label %3363

3363:                                             ; preds = %3029
  %3364 = xor i32 %3360, -1
  %3365 = shl i32 1, %3364
  %3366 = insertelement <4 x i32> undef, i32 %3365, i32 0
  %3367 = shufflevector <4 x i32> %3366, <4 x i32> undef, <4 x i32> zeroinitializer
  %3368 = bitcast <2 x i64> %3297 to <4 x i32>
  %3369 = add <4 x i32> %3367, %3368
  %3370 = bitcast <2 x i64> %3317 to <4 x i32>
  %3371 = add <4 x i32> %3367, %3370
  %3372 = bitcast <2 x i64> %3337 to <4 x i32>
  %3373 = add <4 x i32> %3367, %3372
  %3374 = bitcast <2 x i64> %3357 to <4 x i32>
  %3375 = add <4 x i32> %3367, %3374
  %3376 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %3369, i32 %3361) #8
  %3377 = bitcast <4 x i32> %3376 to <2 x i64>
  %3378 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %3371, i32 %3361) #8
  %3379 = bitcast <4 x i32> %3378 to <2 x i64>
  %3380 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %3373, i32 %3361) #8
  %3381 = bitcast <4 x i32> %3380 to <2 x i64>
  %3382 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %3375, i32 %3361) #8
  %3383 = bitcast <4 x i32> %3382 to <2 x i64>
  br label %3384

3384:                                             ; preds = %3029, %3363
  %3385 = phi <2 x i64> [ %3357, %3029 ], [ %3383, %3363 ]
  %3386 = phi <2 x i64> [ %3337, %3029 ], [ %3381, %3363 ]
  %3387 = phi <2 x i64> [ %3317, %3029 ], [ %3379, %3363 ]
  %3388 = phi <2 x i64> [ %3297, %3029 ], [ %3377, %3363 ]
  %3389 = bitcast i16* %1 to i64*
  %3390 = load i64, i64* %3389, align 1
  %3391 = insertelement <2 x i64> undef, i64 %3390, i32 0
  %3392 = sext i32 %2 to i64
  %3393 = getelementptr inbounds i16, i16* %1, i64 %3392
  %3394 = bitcast i16* %3393 to i64*
  %3395 = load i64, i64* %3394, align 1
  %3396 = insertelement <2 x i64> undef, i64 %3395, i32 0
  %3397 = shl nsw i32 %2, 1
  %3398 = sext i32 %3397 to i64
  %3399 = getelementptr inbounds i16, i16* %1, i64 %3398
  %3400 = bitcast i16* %3399 to i64*
  %3401 = load i64, i64* %3400, align 1
  %3402 = insertelement <2 x i64> undef, i64 %3401, i32 0
  %3403 = mul nsw i32 %2, 3
  %3404 = sext i32 %3403 to i64
  %3405 = getelementptr inbounds i16, i16* %1, i64 %3404
  %3406 = bitcast i16* %3405 to i64*
  %3407 = load i64, i64* %3406, align 1
  %3408 = insertelement <2 x i64> undef, i64 %3407, i32 0
  %3409 = bitcast <2 x i64> %3391 to <8 x i16>
  %3410 = shufflevector <8 x i16> %3409, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3411 = bitcast <2 x i64> %3396 to <8 x i16>
  %3412 = shufflevector <8 x i16> %3411, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3413 = bitcast <2 x i64> %3402 to <8 x i16>
  %3414 = shufflevector <8 x i16> %3413, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3415 = bitcast <2 x i64> %3408 to <8 x i16>
  %3416 = shufflevector <8 x i16> %3415, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3417 = bitcast <2 x i64> %3385 to <4 x i32>
  %3418 = bitcast <8 x i16> %3410 to <4 x i32>
  %3419 = add <4 x i32> %3418, %3417
  %3420 = bitcast <2 x i64> %3386 to <4 x i32>
  %3421 = bitcast <8 x i16> %3412 to <4 x i32>
  %3422 = add <4 x i32> %3421, %3420
  %3423 = bitcast <2 x i64> %3387 to <4 x i32>
  %3424 = bitcast <8 x i16> %3414 to <4 x i32>
  %3425 = add <4 x i32> %3424, %3423
  %3426 = bitcast <2 x i64> %3388 to <4 x i32>
  %3427 = bitcast <8 x i16> %3416 to <4 x i32>
  %3428 = add <4 x i32> %3427, %3426
  %3429 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %3419, <4 x i32> %3422) #8
  %3430 = bitcast <8 x i16> %3429 to <2 x i64>
  %3431 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %3425, <4 x i32> %3428) #8
  %3432 = bitcast <8 x i16> %3431 to <2 x i64>
  %3433 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %3434 = add <8 x i16> %3433, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %3435 = icmp slt <8 x i16> %3434, %3429
  %3436 = sext <8 x i1> %3435 to <8 x i16>
  %3437 = bitcast <8 x i16> %3436 to <2 x i64>
  %3438 = xor <2 x i64> %3437, <i64 -1, i64 -1>
  %3439 = and <2 x i64> %3438, %3430
  %3440 = and <8 x i16> %3434, %3436
  %3441 = bitcast <8 x i16> %3440 to <2 x i64>
  %3442 = or <2 x i64> %3439, %3441
  %3443 = bitcast <2 x i64> %3442 to <8 x i16>
  %3444 = icmp sgt <8 x i16> %3443, zeroinitializer
  %3445 = sext <8 x i1> %3444 to <8 x i16>
  %3446 = bitcast <8 x i16> %3445 to <2 x i64>
  %3447 = and <2 x i64> %3442, %3446
  %3448 = icmp slt <8 x i16> %3434, %3431
  %3449 = sext <8 x i1> %3448 to <8 x i16>
  %3450 = bitcast <8 x i16> %3449 to <2 x i64>
  %3451 = xor <2 x i64> %3450, <i64 -1, i64 -1>
  %3452 = and <2 x i64> %3451, %3432
  %3453 = and <8 x i16> %3434, %3449
  br label %6055

3454:                                             ; preds = %5
  %3455 = bitcast i32* %0 to <2 x i64>*
  %3456 = load <2 x i64>, <2 x i64>* %3455, align 16
  %3457 = getelementptr inbounds i32, i32* %0, i64 4
  %3458 = bitcast i32* %3457 to <2 x i64>*
  %3459 = load <2 x i64>, <2 x i64>* %3458, align 16
  %3460 = getelementptr inbounds i32, i32* %0, i64 8
  %3461 = bitcast i32* %3460 to <2 x i64>*
  %3462 = load <2 x i64>, <2 x i64>* %3461, align 16
  %3463 = getelementptr inbounds i32, i32* %0, i64 12
  %3464 = bitcast i32* %3463 to <2 x i64>*
  %3465 = load <2 x i64>, <2 x i64>* %3464, align 16
  %3466 = shl <2 x i64> %3456, <i64 32, i64 32>
  %3467 = ashr exact <2 x i64> %3466, <i64 32, i64 32>
  %3468 = mul nsw <2 x i64> %3467, <i64 5793, i64 5793>
  %3469 = bitcast <2 x i64> %3468 to <4 x i32>
  %3470 = add <4 x i32> %3469, <i32 2048, i32 0, i32 2048, i32 0>
  %3471 = bitcast <4 x i32> %3470 to <2 x i64>
  %3472 = lshr <2 x i64> %3471, <i64 12, i64 12>
  %3473 = bitcast <2 x i64> %3456 to <16 x i8>
  %3474 = shufflevector <16 x i8> %3473, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3475 = bitcast <16 x i8> %3474 to <2 x i64>
  %3476 = shl <2 x i64> %3475, <i64 32, i64 32>
  %3477 = ashr exact <2 x i64> %3476, <i64 32, i64 32>
  %3478 = mul nsw <2 x i64> %3477, <i64 5793, i64 5793>
  %3479 = bitcast <2 x i64> %3478 to <4 x i32>
  %3480 = add <4 x i32> %3479, <i32 2048, i32 0, i32 2048, i32 0>
  %3481 = bitcast <4 x i32> %3480 to <2 x i64>
  %3482 = lshr <2 x i64> %3481, <i64 12, i64 12>
  %3483 = bitcast <2 x i64> %3472 to <4 x i32>
  %3484 = bitcast <2 x i64> %3482 to <4 x i32>
  %3485 = shufflevector <4 x i32> %3483, <4 x i32> %3484, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3486 = bitcast <4 x i32> %3485 to <2 x i64>
  %3487 = shufflevector <4 x i32> %3483, <4 x i32> %3484, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3488 = bitcast <4 x i32> %3487 to <2 x i64>
  %3489 = shufflevector <2 x i64> %3486, <2 x i64> %3488, <2 x i32> <i32 0, i32 2>
  %3490 = shl <2 x i64> %3459, <i64 32, i64 32>
  %3491 = ashr exact <2 x i64> %3490, <i64 32, i64 32>
  %3492 = mul nsw <2 x i64> %3491, <i64 5793, i64 5793>
  %3493 = bitcast <2 x i64> %3492 to <4 x i32>
  %3494 = add <4 x i32> %3493, <i32 2048, i32 0, i32 2048, i32 0>
  %3495 = bitcast <4 x i32> %3494 to <2 x i64>
  %3496 = lshr <2 x i64> %3495, <i64 12, i64 12>
  %3497 = bitcast <2 x i64> %3459 to <16 x i8>
  %3498 = shufflevector <16 x i8> %3497, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3499 = bitcast <16 x i8> %3498 to <2 x i64>
  %3500 = shl <2 x i64> %3499, <i64 32, i64 32>
  %3501 = ashr exact <2 x i64> %3500, <i64 32, i64 32>
  %3502 = mul nsw <2 x i64> %3501, <i64 5793, i64 5793>
  %3503 = bitcast <2 x i64> %3502 to <4 x i32>
  %3504 = add <4 x i32> %3503, <i32 2048, i32 0, i32 2048, i32 0>
  %3505 = bitcast <4 x i32> %3504 to <2 x i64>
  %3506 = lshr <2 x i64> %3505, <i64 12, i64 12>
  %3507 = bitcast <2 x i64> %3496 to <4 x i32>
  %3508 = bitcast <2 x i64> %3506 to <4 x i32>
  %3509 = shufflevector <4 x i32> %3507, <4 x i32> %3508, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3510 = bitcast <4 x i32> %3509 to <2 x i64>
  %3511 = shufflevector <4 x i32> %3507, <4 x i32> %3508, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3512 = bitcast <4 x i32> %3511 to <2 x i64>
  %3513 = shufflevector <2 x i64> %3510, <2 x i64> %3512, <2 x i32> <i32 0, i32 2>
  %3514 = shl <2 x i64> %3462, <i64 32, i64 32>
  %3515 = ashr exact <2 x i64> %3514, <i64 32, i64 32>
  %3516 = mul nsw <2 x i64> %3515, <i64 5793, i64 5793>
  %3517 = bitcast <2 x i64> %3516 to <4 x i32>
  %3518 = add <4 x i32> %3517, <i32 2048, i32 0, i32 2048, i32 0>
  %3519 = bitcast <4 x i32> %3518 to <2 x i64>
  %3520 = lshr <2 x i64> %3519, <i64 12, i64 12>
  %3521 = bitcast <2 x i64> %3462 to <16 x i8>
  %3522 = shufflevector <16 x i8> %3521, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3523 = bitcast <16 x i8> %3522 to <2 x i64>
  %3524 = shl <2 x i64> %3523, <i64 32, i64 32>
  %3525 = ashr exact <2 x i64> %3524, <i64 32, i64 32>
  %3526 = mul nsw <2 x i64> %3525, <i64 5793, i64 5793>
  %3527 = bitcast <2 x i64> %3526 to <4 x i32>
  %3528 = add <4 x i32> %3527, <i32 2048, i32 0, i32 2048, i32 0>
  %3529 = bitcast <4 x i32> %3528 to <2 x i64>
  %3530 = lshr <2 x i64> %3529, <i64 12, i64 12>
  %3531 = bitcast <2 x i64> %3520 to <4 x i32>
  %3532 = bitcast <2 x i64> %3530 to <4 x i32>
  %3533 = shufflevector <4 x i32> %3531, <4 x i32> %3532, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3534 = bitcast <4 x i32> %3533 to <2 x i64>
  %3535 = shufflevector <4 x i32> %3531, <4 x i32> %3532, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3536 = bitcast <4 x i32> %3535 to <2 x i64>
  %3537 = shufflevector <2 x i64> %3534, <2 x i64> %3536, <2 x i32> <i32 0, i32 2>
  %3538 = shl <2 x i64> %3465, <i64 32, i64 32>
  %3539 = ashr exact <2 x i64> %3538, <i64 32, i64 32>
  %3540 = mul nsw <2 x i64> %3539, <i64 5793, i64 5793>
  %3541 = bitcast <2 x i64> %3540 to <4 x i32>
  %3542 = add <4 x i32> %3541, <i32 2048, i32 0, i32 2048, i32 0>
  %3543 = bitcast <4 x i32> %3542 to <2 x i64>
  %3544 = lshr <2 x i64> %3543, <i64 12, i64 12>
  %3545 = bitcast <2 x i64> %3465 to <16 x i8>
  %3546 = shufflevector <16 x i8> %3545, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3547 = bitcast <16 x i8> %3546 to <2 x i64>
  %3548 = shl <2 x i64> %3547, <i64 32, i64 32>
  %3549 = ashr exact <2 x i64> %3548, <i64 32, i64 32>
  %3550 = mul nsw <2 x i64> %3549, <i64 5793, i64 5793>
  %3551 = bitcast <2 x i64> %3550 to <4 x i32>
  %3552 = add <4 x i32> %3551, <i32 2048, i32 0, i32 2048, i32 0>
  %3553 = bitcast <4 x i32> %3552 to <2 x i64>
  %3554 = lshr <2 x i64> %3553, <i64 12, i64 12>
  %3555 = bitcast <2 x i64> %3544 to <4 x i32>
  %3556 = bitcast <2 x i64> %3554 to <4 x i32>
  %3557 = shufflevector <4 x i32> %3555, <4 x i32> %3556, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3558 = bitcast <4 x i32> %3557 to <2 x i64>
  %3559 = shufflevector <4 x i32> %3555, <4 x i32> %3556, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3560 = bitcast <4 x i32> %3559 to <2 x i64>
  %3561 = shufflevector <2 x i64> %3558, <2 x i64> %3560, <2 x i32> <i32 0, i32 2>
  %3562 = bitcast <2 x i64> %3513 to <4 x i32>
  %3563 = bitcast <2 x i64> %3537 to <4 x i32>
  %3564 = bitcast <2 x i64> %3561 to <4 x i32>
  %3565 = icmp sgt i32 %4, 10
  %3566 = select i1 %3565, i32 %4, i32 10
  %3567 = shl i32 32, %3566
  %3568 = sub nsw i32 0, %3567
  %3569 = insertelement <4 x i32> undef, i32 %3568, i32 0
  %3570 = shufflevector <4 x i32> %3569, <4 x i32> undef, <4 x i32> zeroinitializer
  %3571 = add nsw i32 %3567, -1
  %3572 = insertelement <4 x i32> undef, i32 %3571, i32 0
  %3573 = shufflevector <4 x i32> %3572, <4 x i32> undef, <4 x i32> zeroinitializer
  %3574 = bitcast <2 x i64> %3489 to <4 x i32>
  %3575 = icmp slt <4 x i32> %3570, %3574
  %3576 = select <4 x i1> %3575, <4 x i32> %3574, <4 x i32> %3570
  %3577 = icmp slt <4 x i32> %3576, %3573
  %3578 = select <4 x i1> %3577, <4 x i32> %3576, <4 x i32> %3573
  %3579 = icmp slt <4 x i32> %3570, %3562
  %3580 = select <4 x i1> %3579, <4 x i32> %3562, <4 x i32> %3570
  %3581 = icmp slt <4 x i32> %3580, %3573
  %3582 = select <4 x i1> %3581, <4 x i32> %3580, <4 x i32> %3573
  %3583 = icmp slt <4 x i32> %3570, %3563
  %3584 = select <4 x i1> %3583, <4 x i32> %3563, <4 x i32> %3570
  %3585 = icmp slt <4 x i32> %3584, %3573
  %3586 = select <4 x i1> %3585, <4 x i32> %3584, <4 x i32> %3573
  %3587 = icmp slt <4 x i32> %3570, %3564
  %3588 = select <4 x i1> %3587, <4 x i32> %3564, <4 x i32> %3570
  %3589 = icmp slt <4 x i32> %3588, %3573
  %3590 = select <4 x i1> %3589, <4 x i32> %3588, <4 x i32> %3573
  %3591 = shufflevector <4 x i32> %3578, <4 x i32> %3582, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3592 = bitcast <4 x i32> %3591 to <2 x i64>
  %3593 = shufflevector <4 x i32> %3578, <4 x i32> %3582, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3594 = bitcast <4 x i32> %3593 to <2 x i64>
  %3595 = shufflevector <4 x i32> %3586, <4 x i32> %3590, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3596 = bitcast <4 x i32> %3595 to <2 x i64>
  %3597 = shufflevector <4 x i32> %3586, <4 x i32> %3590, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3598 = bitcast <4 x i32> %3597 to <2 x i64>
  %3599 = shufflevector <2 x i64> %3592, <2 x i64> %3596, <2 x i32> <i32 0, i32 2>
  %3600 = shufflevector <2 x i64> %3592, <2 x i64> %3596, <2 x i32> <i32 1, i32 3>
  %3601 = shufflevector <2 x i64> %3594, <2 x i64> %3598, <2 x i32> <i32 0, i32 2>
  %3602 = shufflevector <2 x i64> %3594, <2 x i64> %3598, <2 x i32> <i32 1, i32 3>
  %3603 = shl <2 x i64> %3599, <i64 32, i64 32>
  %3604 = ashr exact <2 x i64> %3603, <i64 32, i64 32>
  %3605 = mul nsw <2 x i64> %3604, <i64 5793, i64 5793>
  %3606 = bitcast <2 x i64> %3605 to <4 x i32>
  %3607 = add <4 x i32> %3606, <i32 2048, i32 0, i32 2048, i32 0>
  %3608 = bitcast <4 x i32> %3607 to <2 x i64>
  %3609 = lshr <2 x i64> %3608, <i64 12, i64 12>
  %3610 = bitcast <2 x i64> %3599 to <16 x i8>
  %3611 = shufflevector <16 x i8> %3610, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3612 = bitcast <16 x i8> %3611 to <2 x i64>
  %3613 = shl <2 x i64> %3612, <i64 32, i64 32>
  %3614 = ashr exact <2 x i64> %3613, <i64 32, i64 32>
  %3615 = mul nsw <2 x i64> %3614, <i64 5793, i64 5793>
  %3616 = bitcast <2 x i64> %3615 to <4 x i32>
  %3617 = add <4 x i32> %3616, <i32 2048, i32 0, i32 2048, i32 0>
  %3618 = bitcast <4 x i32> %3617 to <2 x i64>
  %3619 = lshr <2 x i64> %3618, <i64 12, i64 12>
  %3620 = bitcast <2 x i64> %3609 to <4 x i32>
  %3621 = bitcast <2 x i64> %3619 to <4 x i32>
  %3622 = shufflevector <4 x i32> %3620, <4 x i32> %3621, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3623 = bitcast <4 x i32> %3622 to <2 x i64>
  %3624 = shufflevector <4 x i32> %3620, <4 x i32> %3621, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3625 = bitcast <4 x i32> %3624 to <2 x i64>
  %3626 = shufflevector <2 x i64> %3623, <2 x i64> %3625, <2 x i32> <i32 0, i32 2>
  %3627 = shl <2 x i64> %3600, <i64 32, i64 32>
  %3628 = ashr exact <2 x i64> %3627, <i64 32, i64 32>
  %3629 = mul nsw <2 x i64> %3628, <i64 5793, i64 5793>
  %3630 = bitcast <2 x i64> %3629 to <4 x i32>
  %3631 = add <4 x i32> %3630, <i32 2048, i32 0, i32 2048, i32 0>
  %3632 = bitcast <4 x i32> %3631 to <2 x i64>
  %3633 = lshr <2 x i64> %3632, <i64 12, i64 12>
  %3634 = bitcast <2 x i64> %3600 to <16 x i8>
  %3635 = shufflevector <16 x i8> %3634, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3636 = bitcast <16 x i8> %3635 to <2 x i64>
  %3637 = shl <2 x i64> %3636, <i64 32, i64 32>
  %3638 = ashr exact <2 x i64> %3637, <i64 32, i64 32>
  %3639 = mul nsw <2 x i64> %3638, <i64 5793, i64 5793>
  %3640 = bitcast <2 x i64> %3639 to <4 x i32>
  %3641 = add <4 x i32> %3640, <i32 2048, i32 0, i32 2048, i32 0>
  %3642 = bitcast <4 x i32> %3641 to <2 x i64>
  %3643 = lshr <2 x i64> %3642, <i64 12, i64 12>
  %3644 = bitcast <2 x i64> %3633 to <4 x i32>
  %3645 = bitcast <2 x i64> %3643 to <4 x i32>
  %3646 = shufflevector <4 x i32> %3644, <4 x i32> %3645, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3647 = bitcast <4 x i32> %3646 to <2 x i64>
  %3648 = shufflevector <4 x i32> %3644, <4 x i32> %3645, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3649 = bitcast <4 x i32> %3648 to <2 x i64>
  %3650 = shufflevector <2 x i64> %3647, <2 x i64> %3649, <2 x i32> <i32 0, i32 2>
  %3651 = shl <2 x i64> %3601, <i64 32, i64 32>
  %3652 = ashr exact <2 x i64> %3651, <i64 32, i64 32>
  %3653 = mul nsw <2 x i64> %3652, <i64 5793, i64 5793>
  %3654 = bitcast <2 x i64> %3653 to <4 x i32>
  %3655 = add <4 x i32> %3654, <i32 2048, i32 0, i32 2048, i32 0>
  %3656 = bitcast <4 x i32> %3655 to <2 x i64>
  %3657 = lshr <2 x i64> %3656, <i64 12, i64 12>
  %3658 = bitcast <2 x i64> %3601 to <16 x i8>
  %3659 = shufflevector <16 x i8> %3658, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3660 = bitcast <16 x i8> %3659 to <2 x i64>
  %3661 = shl <2 x i64> %3660, <i64 32, i64 32>
  %3662 = ashr exact <2 x i64> %3661, <i64 32, i64 32>
  %3663 = mul nsw <2 x i64> %3662, <i64 5793, i64 5793>
  %3664 = bitcast <2 x i64> %3663 to <4 x i32>
  %3665 = add <4 x i32> %3664, <i32 2048, i32 0, i32 2048, i32 0>
  %3666 = bitcast <4 x i32> %3665 to <2 x i64>
  %3667 = lshr <2 x i64> %3666, <i64 12, i64 12>
  %3668 = bitcast <2 x i64> %3657 to <4 x i32>
  %3669 = bitcast <2 x i64> %3667 to <4 x i32>
  %3670 = shufflevector <4 x i32> %3668, <4 x i32> %3669, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3671 = bitcast <4 x i32> %3670 to <2 x i64>
  %3672 = shufflevector <4 x i32> %3668, <4 x i32> %3669, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3673 = bitcast <4 x i32> %3672 to <2 x i64>
  %3674 = shufflevector <2 x i64> %3671, <2 x i64> %3673, <2 x i32> <i32 0, i32 2>
  %3675 = shl <2 x i64> %3602, <i64 32, i64 32>
  %3676 = ashr exact <2 x i64> %3675, <i64 32, i64 32>
  %3677 = mul nsw <2 x i64> %3676, <i64 5793, i64 5793>
  %3678 = bitcast <2 x i64> %3677 to <4 x i32>
  %3679 = add <4 x i32> %3678, <i32 2048, i32 0, i32 2048, i32 0>
  %3680 = bitcast <4 x i32> %3679 to <2 x i64>
  %3681 = lshr <2 x i64> %3680, <i64 12, i64 12>
  %3682 = bitcast <2 x i64> %3602 to <16 x i8>
  %3683 = shufflevector <16 x i8> %3682, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3684 = bitcast <16 x i8> %3683 to <2 x i64>
  %3685 = shl <2 x i64> %3684, <i64 32, i64 32>
  %3686 = ashr exact <2 x i64> %3685, <i64 32, i64 32>
  %3687 = mul nsw <2 x i64> %3686, <i64 5793, i64 5793>
  %3688 = bitcast <2 x i64> %3687 to <4 x i32>
  %3689 = add <4 x i32> %3688, <i32 2048, i32 0, i32 2048, i32 0>
  %3690 = bitcast <4 x i32> %3689 to <2 x i64>
  %3691 = lshr <2 x i64> %3690, <i64 12, i64 12>
  %3692 = bitcast <2 x i64> %3681 to <4 x i32>
  %3693 = bitcast <2 x i64> %3691 to <4 x i32>
  %3694 = shufflevector <4 x i32> %3692, <4 x i32> %3693, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3695 = bitcast <4 x i32> %3694 to <2 x i64>
  %3696 = shufflevector <4 x i32> %3692, <4 x i32> %3693, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3697 = bitcast <4 x i32> %3696 to <2 x i64>
  %3698 = shufflevector <2 x i64> %3695, <2 x i64> %3697, <2 x i32> <i32 0, i32 2>
  %3699 = bitcast <2 x i64> %3650 to <4 x i32>
  %3700 = bitcast <2 x i64> %3674 to <4 x i32>
  %3701 = bitcast <2 x i64> %3698 to <4 x i32>
  %3702 = bitcast <2 x i64> %3626 to <4 x i32>
  %3703 = shufflevector <4 x i32> %3702, <4 x i32> %3699, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3704 = bitcast <4 x i32> %3703 to <2 x i64>
  %3705 = shufflevector <4 x i32> %3702, <4 x i32> %3699, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3706 = bitcast <4 x i32> %3705 to <2 x i64>
  %3707 = shufflevector <4 x i32> %3700, <4 x i32> %3701, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3708 = bitcast <4 x i32> %3707 to <2 x i64>
  %3709 = shufflevector <4 x i32> %3700, <4 x i32> %3701, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3710 = bitcast <4 x i32> %3709 to <2 x i64>
  %3711 = shufflevector <2 x i64> %3704, <2 x i64> %3708, <2 x i32> <i32 0, i32 2>
  %3712 = shufflevector <2 x i64> %3704, <2 x i64> %3708, <2 x i32> <i32 1, i32 3>
  %3713 = shufflevector <2 x i64> %3706, <2 x i64> %3710, <2 x i32> <i32 0, i32 2>
  %3714 = shufflevector <2 x i64> %3706, <2 x i64> %3710, <2 x i32> <i32 1, i32 3>
  %3715 = getelementptr inbounds i8, i8* %6, i64 1
  %3716 = load i8, i8* %3715, align 1
  %3717 = sext i8 %3716 to i32
  %3718 = sub nsw i32 0, %3717
  %3719 = icmp eq i8 %3716, 0
  br i1 %3719, label %3741, label %3720

3720:                                             ; preds = %3454
  %3721 = xor i32 %3717, -1
  %3722 = shl i32 1, %3721
  %3723 = insertelement <4 x i32> undef, i32 %3722, i32 0
  %3724 = shufflevector <4 x i32> %3723, <4 x i32> undef, <4 x i32> zeroinitializer
  %3725 = bitcast <2 x i64> %3711 to <4 x i32>
  %3726 = add <4 x i32> %3724, %3725
  %3727 = bitcast <2 x i64> %3712 to <4 x i32>
  %3728 = add <4 x i32> %3724, %3727
  %3729 = bitcast <2 x i64> %3713 to <4 x i32>
  %3730 = add <4 x i32> %3724, %3729
  %3731 = bitcast <2 x i64> %3714 to <4 x i32>
  %3732 = add <4 x i32> %3724, %3731
  %3733 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %3726, i32 %3718) #8
  %3734 = bitcast <4 x i32> %3733 to <2 x i64>
  %3735 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %3728, i32 %3718) #8
  %3736 = bitcast <4 x i32> %3735 to <2 x i64>
  %3737 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %3730, i32 %3718) #8
  %3738 = bitcast <4 x i32> %3737 to <2 x i64>
  %3739 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %3732, i32 %3718) #8
  %3740 = bitcast <4 x i32> %3739 to <2 x i64>
  br label %3741

3741:                                             ; preds = %3454, %3720
  %3742 = phi <2 x i64> [ %3714, %3454 ], [ %3740, %3720 ]
  %3743 = phi <2 x i64> [ %3713, %3454 ], [ %3738, %3720 ]
  %3744 = phi <2 x i64> [ %3712, %3454 ], [ %3736, %3720 ]
  %3745 = phi <2 x i64> [ %3711, %3454 ], [ %3734, %3720 ]
  %3746 = bitcast i16* %1 to i64*
  %3747 = load i64, i64* %3746, align 1
  %3748 = insertelement <2 x i64> undef, i64 %3747, i32 0
  %3749 = sext i32 %2 to i64
  %3750 = getelementptr inbounds i16, i16* %1, i64 %3749
  %3751 = bitcast i16* %3750 to i64*
  %3752 = load i64, i64* %3751, align 1
  %3753 = insertelement <2 x i64> undef, i64 %3752, i32 0
  %3754 = shl nsw i32 %2, 1
  %3755 = sext i32 %3754 to i64
  %3756 = getelementptr inbounds i16, i16* %1, i64 %3755
  %3757 = bitcast i16* %3756 to i64*
  %3758 = load i64, i64* %3757, align 1
  %3759 = insertelement <2 x i64> undef, i64 %3758, i32 0
  %3760 = mul nsw i32 %2, 3
  %3761 = sext i32 %3760 to i64
  %3762 = getelementptr inbounds i16, i16* %1, i64 %3761
  %3763 = bitcast i16* %3762 to i64*
  %3764 = load i64, i64* %3763, align 1
  %3765 = insertelement <2 x i64> undef, i64 %3764, i32 0
  %3766 = bitcast <2 x i64> %3748 to <8 x i16>
  %3767 = shufflevector <8 x i16> %3766, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3768 = bitcast <2 x i64> %3753 to <8 x i16>
  %3769 = shufflevector <8 x i16> %3768, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3770 = bitcast <2 x i64> %3759 to <8 x i16>
  %3771 = shufflevector <8 x i16> %3770, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3772 = bitcast <2 x i64> %3765 to <8 x i16>
  %3773 = shufflevector <8 x i16> %3772, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3774 = bitcast <2 x i64> %3745 to <4 x i32>
  %3775 = bitcast <8 x i16> %3767 to <4 x i32>
  %3776 = add <4 x i32> %3775, %3774
  %3777 = bitcast <2 x i64> %3744 to <4 x i32>
  %3778 = bitcast <8 x i16> %3769 to <4 x i32>
  %3779 = add <4 x i32> %3778, %3777
  %3780 = bitcast <2 x i64> %3743 to <4 x i32>
  %3781 = bitcast <8 x i16> %3771 to <4 x i32>
  %3782 = add <4 x i32> %3781, %3780
  %3783 = bitcast <2 x i64> %3742 to <4 x i32>
  %3784 = bitcast <8 x i16> %3773 to <4 x i32>
  %3785 = add <4 x i32> %3784, %3783
  %3786 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %3776, <4 x i32> %3779) #8
  %3787 = bitcast <8 x i16> %3786 to <2 x i64>
  %3788 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %3782, <4 x i32> %3785) #8
  %3789 = bitcast <8 x i16> %3788 to <2 x i64>
  %3790 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %3791 = add <8 x i16> %3790, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %3792 = icmp slt <8 x i16> %3791, %3786
  %3793 = sext <8 x i1> %3792 to <8 x i16>
  %3794 = bitcast <8 x i16> %3793 to <2 x i64>
  %3795 = xor <2 x i64> %3794, <i64 -1, i64 -1>
  %3796 = and <2 x i64> %3795, %3787
  %3797 = and <8 x i16> %3791, %3793
  %3798 = bitcast <8 x i16> %3797 to <2 x i64>
  %3799 = or <2 x i64> %3796, %3798
  %3800 = bitcast <2 x i64> %3799 to <8 x i16>
  %3801 = icmp sgt <8 x i16> %3800, zeroinitializer
  %3802 = sext <8 x i1> %3801 to <8 x i16>
  %3803 = bitcast <8 x i16> %3802 to <2 x i64>
  %3804 = and <2 x i64> %3799, %3803
  %3805 = icmp slt <8 x i16> %3791, %3788
  %3806 = sext <8 x i1> %3805 to <8 x i16>
  %3807 = bitcast <8 x i16> %3806 to <2 x i64>
  %3808 = xor <2 x i64> %3807, <i64 -1, i64 -1>
  %3809 = and <2 x i64> %3808, %3789
  %3810 = and <8 x i16> %3791, %3806
  br label %6055

3811:                                             ; preds = %5
  %3812 = bitcast i32* %0 to <2 x i64>*
  %3813 = load <2 x i64>, <2 x i64>* %3812, align 16
  %3814 = getelementptr inbounds i32, i32* %0, i64 4
  %3815 = bitcast i32* %3814 to <2 x i64>*
  %3816 = load <2 x i64>, <2 x i64>* %3815, align 16
  %3817 = getelementptr inbounds i32, i32* %0, i64 8
  %3818 = bitcast i32* %3817 to <2 x i64>*
  %3819 = load <2 x i64>, <2 x i64>* %3818, align 16
  %3820 = getelementptr inbounds i32, i32* %0, i64 12
  %3821 = bitcast i32* %3820 to <2 x i64>*
  %3822 = load <2 x i64>, <2 x i64>* %3821, align 16
  %3823 = shl <2 x i64> %3813, <i64 32, i64 32>
  %3824 = ashr exact <2 x i64> %3823, <i64 32, i64 32>
  %3825 = mul nsw <2 x i64> %3824, <i64 5793, i64 5793>
  %3826 = bitcast <2 x i64> %3825 to <4 x i32>
  %3827 = add <4 x i32> %3826, <i32 2048, i32 0, i32 2048, i32 0>
  %3828 = bitcast <4 x i32> %3827 to <2 x i64>
  %3829 = lshr <2 x i64> %3828, <i64 12, i64 12>
  %3830 = bitcast <2 x i64> %3813 to <16 x i8>
  %3831 = shufflevector <16 x i8> %3830, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3832 = bitcast <16 x i8> %3831 to <2 x i64>
  %3833 = shl <2 x i64> %3832, <i64 32, i64 32>
  %3834 = ashr exact <2 x i64> %3833, <i64 32, i64 32>
  %3835 = mul nsw <2 x i64> %3834, <i64 5793, i64 5793>
  %3836 = bitcast <2 x i64> %3835 to <4 x i32>
  %3837 = add <4 x i32> %3836, <i32 2048, i32 0, i32 2048, i32 0>
  %3838 = bitcast <4 x i32> %3837 to <2 x i64>
  %3839 = lshr <2 x i64> %3838, <i64 12, i64 12>
  %3840 = bitcast <2 x i64> %3829 to <4 x i32>
  %3841 = bitcast <2 x i64> %3839 to <4 x i32>
  %3842 = shufflevector <4 x i32> %3840, <4 x i32> %3841, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3843 = bitcast <4 x i32> %3842 to <2 x i64>
  %3844 = shufflevector <4 x i32> %3840, <4 x i32> %3841, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3845 = bitcast <4 x i32> %3844 to <2 x i64>
  %3846 = shufflevector <2 x i64> %3843, <2 x i64> %3845, <2 x i32> <i32 0, i32 2>
  %3847 = shl <2 x i64> %3816, <i64 32, i64 32>
  %3848 = ashr exact <2 x i64> %3847, <i64 32, i64 32>
  %3849 = mul nsw <2 x i64> %3848, <i64 5793, i64 5793>
  %3850 = bitcast <2 x i64> %3849 to <4 x i32>
  %3851 = add <4 x i32> %3850, <i32 2048, i32 0, i32 2048, i32 0>
  %3852 = bitcast <4 x i32> %3851 to <2 x i64>
  %3853 = lshr <2 x i64> %3852, <i64 12, i64 12>
  %3854 = bitcast <2 x i64> %3816 to <16 x i8>
  %3855 = shufflevector <16 x i8> %3854, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3856 = bitcast <16 x i8> %3855 to <2 x i64>
  %3857 = shl <2 x i64> %3856, <i64 32, i64 32>
  %3858 = ashr exact <2 x i64> %3857, <i64 32, i64 32>
  %3859 = mul nsw <2 x i64> %3858, <i64 5793, i64 5793>
  %3860 = bitcast <2 x i64> %3859 to <4 x i32>
  %3861 = add <4 x i32> %3860, <i32 2048, i32 0, i32 2048, i32 0>
  %3862 = bitcast <4 x i32> %3861 to <2 x i64>
  %3863 = lshr <2 x i64> %3862, <i64 12, i64 12>
  %3864 = bitcast <2 x i64> %3853 to <4 x i32>
  %3865 = bitcast <2 x i64> %3863 to <4 x i32>
  %3866 = shufflevector <4 x i32> %3864, <4 x i32> %3865, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3867 = bitcast <4 x i32> %3866 to <2 x i64>
  %3868 = shufflevector <4 x i32> %3864, <4 x i32> %3865, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3869 = bitcast <4 x i32> %3868 to <2 x i64>
  %3870 = shufflevector <2 x i64> %3867, <2 x i64> %3869, <2 x i32> <i32 0, i32 2>
  %3871 = shl <2 x i64> %3819, <i64 32, i64 32>
  %3872 = ashr exact <2 x i64> %3871, <i64 32, i64 32>
  %3873 = mul nsw <2 x i64> %3872, <i64 5793, i64 5793>
  %3874 = bitcast <2 x i64> %3873 to <4 x i32>
  %3875 = add <4 x i32> %3874, <i32 2048, i32 0, i32 2048, i32 0>
  %3876 = bitcast <4 x i32> %3875 to <2 x i64>
  %3877 = lshr <2 x i64> %3876, <i64 12, i64 12>
  %3878 = bitcast <2 x i64> %3819 to <16 x i8>
  %3879 = shufflevector <16 x i8> %3878, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3880 = bitcast <16 x i8> %3879 to <2 x i64>
  %3881 = shl <2 x i64> %3880, <i64 32, i64 32>
  %3882 = ashr exact <2 x i64> %3881, <i64 32, i64 32>
  %3883 = mul nsw <2 x i64> %3882, <i64 5793, i64 5793>
  %3884 = bitcast <2 x i64> %3883 to <4 x i32>
  %3885 = add <4 x i32> %3884, <i32 2048, i32 0, i32 2048, i32 0>
  %3886 = bitcast <4 x i32> %3885 to <2 x i64>
  %3887 = lshr <2 x i64> %3886, <i64 12, i64 12>
  %3888 = bitcast <2 x i64> %3877 to <4 x i32>
  %3889 = bitcast <2 x i64> %3887 to <4 x i32>
  %3890 = shufflevector <4 x i32> %3888, <4 x i32> %3889, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3891 = bitcast <4 x i32> %3890 to <2 x i64>
  %3892 = shufflevector <4 x i32> %3888, <4 x i32> %3889, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3893 = bitcast <4 x i32> %3892 to <2 x i64>
  %3894 = shufflevector <2 x i64> %3891, <2 x i64> %3893, <2 x i32> <i32 0, i32 2>
  %3895 = shl <2 x i64> %3822, <i64 32, i64 32>
  %3896 = ashr exact <2 x i64> %3895, <i64 32, i64 32>
  %3897 = mul nsw <2 x i64> %3896, <i64 5793, i64 5793>
  %3898 = bitcast <2 x i64> %3897 to <4 x i32>
  %3899 = add <4 x i32> %3898, <i32 2048, i32 0, i32 2048, i32 0>
  %3900 = bitcast <4 x i32> %3899 to <2 x i64>
  %3901 = lshr <2 x i64> %3900, <i64 12, i64 12>
  %3902 = bitcast <2 x i64> %3822 to <16 x i8>
  %3903 = shufflevector <16 x i8> %3902, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %3904 = bitcast <16 x i8> %3903 to <2 x i64>
  %3905 = shl <2 x i64> %3904, <i64 32, i64 32>
  %3906 = ashr exact <2 x i64> %3905, <i64 32, i64 32>
  %3907 = mul nsw <2 x i64> %3906, <i64 5793, i64 5793>
  %3908 = bitcast <2 x i64> %3907 to <4 x i32>
  %3909 = add <4 x i32> %3908, <i32 2048, i32 0, i32 2048, i32 0>
  %3910 = bitcast <4 x i32> %3909 to <2 x i64>
  %3911 = lshr <2 x i64> %3910, <i64 12, i64 12>
  %3912 = bitcast <2 x i64> %3901 to <4 x i32>
  %3913 = bitcast <2 x i64> %3911 to <4 x i32>
  %3914 = shufflevector <4 x i32> %3912, <4 x i32> %3913, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %3915 = bitcast <4 x i32> %3914 to <2 x i64>
  %3916 = shufflevector <4 x i32> %3912, <4 x i32> %3913, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %3917 = bitcast <4 x i32> %3916 to <2 x i64>
  %3918 = shufflevector <2 x i64> %3915, <2 x i64> %3917, <2 x i32> <i32 0, i32 2>
  %3919 = bitcast <2 x i64> %3870 to <4 x i32>
  %3920 = bitcast <2 x i64> %3894 to <4 x i32>
  %3921 = bitcast <2 x i64> %3918 to <4 x i32>
  %3922 = icmp sgt i32 %4, 10
  %3923 = select i1 %3922, i32 %4, i32 10
  %3924 = shl i32 32, %3923
  %3925 = sub nsw i32 0, %3924
  %3926 = insertelement <4 x i32> undef, i32 %3925, i32 0
  %3927 = shufflevector <4 x i32> %3926, <4 x i32> undef, <4 x i32> zeroinitializer
  %3928 = add nsw i32 %3924, -1
  %3929 = insertelement <4 x i32> undef, i32 %3928, i32 0
  %3930 = shufflevector <4 x i32> %3929, <4 x i32> undef, <4 x i32> zeroinitializer
  %3931 = bitcast <2 x i64> %3846 to <4 x i32>
  %3932 = icmp slt <4 x i32> %3927, %3931
  %3933 = select <4 x i1> %3932, <4 x i32> %3931, <4 x i32> %3927
  %3934 = icmp slt <4 x i32> %3933, %3930
  %3935 = select <4 x i1> %3934, <4 x i32> %3933, <4 x i32> %3930
  %3936 = icmp slt <4 x i32> %3927, %3919
  %3937 = select <4 x i1> %3936, <4 x i32> %3919, <4 x i32> %3927
  %3938 = icmp slt <4 x i32> %3937, %3930
  %3939 = select <4 x i1> %3938, <4 x i32> %3937, <4 x i32> %3930
  %3940 = icmp slt <4 x i32> %3927, %3920
  %3941 = select <4 x i1> %3940, <4 x i32> %3920, <4 x i32> %3927
  %3942 = icmp slt <4 x i32> %3941, %3930
  %3943 = select <4 x i1> %3942, <4 x i32> %3941, <4 x i32> %3930
  %3944 = icmp slt <4 x i32> %3927, %3921
  %3945 = select <4 x i1> %3944, <4 x i32> %3921, <4 x i32> %3927
  %3946 = icmp slt <4 x i32> %3945, %3930
  %3947 = select <4 x i1> %3946, <4 x i32> %3945, <4 x i32> %3930
  %3948 = shufflevector <4 x i32> %3935, <4 x i32> %3939, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3949 = bitcast <4 x i32> %3948 to <2 x i64>
  %3950 = shufflevector <4 x i32> %3935, <4 x i32> %3939, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3951 = bitcast <4 x i32> %3950 to <2 x i64>
  %3952 = shufflevector <4 x i32> %3943, <4 x i32> %3947, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3953 = bitcast <4 x i32> %3952 to <2 x i64>
  %3954 = shufflevector <4 x i32> %3943, <4 x i32> %3947, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3955 = bitcast <4 x i32> %3954 to <2 x i64>
  %3956 = shufflevector <2 x i64> %3949, <2 x i64> %3953, <2 x i32> <i32 0, i32 2>
  %3957 = shufflevector <2 x i64> %3949, <2 x i64> %3953, <2 x i32> <i32 1, i32 3>
  %3958 = shufflevector <2 x i64> %3951, <2 x i64> %3955, <2 x i32> <i32 0, i32 2>
  %3959 = shufflevector <2 x i64> %3951, <2 x i64> %3955, <2 x i32> <i32 1, i32 3>
  %3960 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 0, i64 0), align 16
  %3961 = sext i8 %3960 to i32
  %3962 = add nsw i32 %3961, -10
  %3963 = sext i32 %3962 to i64
  %3964 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %3963, i64 32
  %3965 = load i32, i32* %3964, align 16
  %3966 = insertelement <4 x i32> undef, i32 %3965, i32 0
  %3967 = shufflevector <4 x i32> %3966, <4 x i32> undef, <4 x i32> zeroinitializer
  %3968 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %3963, i64 48
  %3969 = load i32, i32* %3968, align 16
  %3970 = insertelement <4 x i32> undef, i32 %3969, i32 0
  %3971 = shufflevector <4 x i32> %3970, <4 x i32> undef, <4 x i32> zeroinitializer
  %3972 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %3963, i64 16
  %3973 = load i32, i32* %3972, align 16
  %3974 = insertelement <4 x i32> undef, i32 %3973, i32 0
  %3975 = shufflevector <4 x i32> %3974, <4 x i32> undef, <4 x i32> zeroinitializer
  %3976 = sub nsw i32 0, %3973
  %3977 = insertelement <4 x i32> undef, i32 %3976, i32 0
  %3978 = shufflevector <4 x i32> %3977, <4 x i32> undef, <4 x i32> zeroinitializer
  %3979 = add nsw i32 %3961, -1
  %3980 = shl i32 1, %3979
  %3981 = insertelement <4 x i32> undef, i32 %3980, i32 0
  %3982 = shufflevector <4 x i32> %3981, <4 x i32> undef, <4 x i32> zeroinitializer
  %3983 = icmp slt i32 %4, 10
  %3984 = add i32 %4, 5
  %3985 = shl i32 1, %3984
  %3986 = select i1 %3983, i32 32768, i32 %3985
  %3987 = sub nsw i32 0, %3986
  %3988 = insertelement <4 x i32> undef, i32 %3987, i32 0
  %3989 = shufflevector <4 x i32> %3988, <4 x i32> undef, <4 x i32> zeroinitializer
  %3990 = add nsw i32 %3986, -1
  %3991 = insertelement <4 x i32> undef, i32 %3990, i32 0
  %3992 = shufflevector <4 x i32> %3991, <4 x i32> undef, <4 x i32> zeroinitializer
  %3993 = bitcast <2 x i64> %3956 to <4 x i32>
  %3994 = bitcast <2 x i64> %3957 to <4 x i32>
  %3995 = shufflevector <4 x i32> %3993, <4 x i32> %3994, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3996 = bitcast <4 x i32> %3995 to <2 x i64>
  %3997 = shufflevector <4 x i32> %3993, <4 x i32> %3994, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3998 = bitcast <4 x i32> %3997 to <2 x i64>
  %3999 = bitcast <2 x i64> %3958 to <4 x i32>
  %4000 = bitcast <2 x i64> %3959 to <4 x i32>
  %4001 = shufflevector <4 x i32> %3999, <4 x i32> %4000, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4002 = bitcast <4 x i32> %4001 to <2 x i64>
  %4003 = shufflevector <4 x i32> %3999, <4 x i32> %4000, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4004 = bitcast <4 x i32> %4003 to <2 x i64>
  %4005 = shufflevector <2 x i64> %3996, <2 x i64> %4002, <2 x i32> <i32 0, i32 2>
  %4006 = shufflevector <2 x i64> %3996, <2 x i64> %4002, <2 x i32> <i32 1, i32 3>
  %4007 = shufflevector <2 x i64> %3998, <2 x i64> %4004, <2 x i32> <i32 0, i32 2>
  %4008 = shufflevector <2 x i64> %3998, <2 x i64> %4004, <2 x i32> <i32 1, i32 3>
  %4009 = bitcast <2 x i64> %4005 to <4 x i32>
  %4010 = mul <4 x i32> %3967, %4009
  %4011 = bitcast <2 x i64> %4007 to <4 x i32>
  %4012 = mul <4 x i32> %3967, %4011
  %4013 = add <4 x i32> %4010, %3982
  %4014 = add <4 x i32> %4013, %4012
  %4015 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4014, i32 %3961) #8
  %4016 = sub <4 x i32> %3982, %4012
  %4017 = add <4 x i32> %4016, %4010
  %4018 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4017, i32 %3961) #8
  %4019 = bitcast <2 x i64> %4006 to <4 x i32>
  %4020 = mul <4 x i32> %3971, %4019
  %4021 = bitcast <2 x i64> %4008 to <4 x i32>
  %4022 = mul <4 x i32> %3978, %4021
  %4023 = add <4 x i32> %4020, %3982
  %4024 = add <4 x i32> %4023, %4022
  %4025 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4024, i32 %3961) #8
  %4026 = mul <4 x i32> %3975, %4019
  %4027 = mul <4 x i32> %3971, %4021
  %4028 = add <4 x i32> %4026, %3982
  %4029 = add <4 x i32> %4028, %4027
  %4030 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4029, i32 %3961) #8
  %4031 = add <4 x i32> %4030, %4015
  %4032 = sub <4 x i32> %4015, %4030
  %4033 = icmp sgt <4 x i32> %4031, %3989
  %4034 = select <4 x i1> %4033, <4 x i32> %4031, <4 x i32> %3989
  %4035 = icmp slt <4 x i32> %4034, %3992
  %4036 = select <4 x i1> %4035, <4 x i32> %4034, <4 x i32> %3992
  %4037 = icmp sgt <4 x i32> %4032, %3989
  %4038 = select <4 x i1> %4037, <4 x i32> %4032, <4 x i32> %3989
  %4039 = icmp slt <4 x i32> %4038, %3992
  %4040 = select <4 x i1> %4039, <4 x i32> %4038, <4 x i32> %3992
  %4041 = add <4 x i32> %4025, %4018
  %4042 = sub <4 x i32> %4018, %4025
  %4043 = icmp sgt <4 x i32> %4041, %3989
  %4044 = select <4 x i1> %4043, <4 x i32> %4041, <4 x i32> %3989
  %4045 = icmp slt <4 x i32> %4044, %3992
  %4046 = select <4 x i1> %4045, <4 x i32> %4044, <4 x i32> %3992
  %4047 = icmp sgt <4 x i32> %4042, %3989
  %4048 = select <4 x i1> %4047, <4 x i32> %4042, <4 x i32> %3989
  %4049 = icmp slt <4 x i32> %4048, %3992
  %4050 = select <4 x i1> %4049, <4 x i32> %4048, <4 x i32> %3992
  %4051 = getelementptr inbounds i8, i8* %6, i64 1
  %4052 = load i8, i8* %4051, align 1
  %4053 = sext i8 %4052 to i32
  %4054 = sub nsw i32 0, %4053
  %4055 = icmp eq i8 %4052, 0
  br i1 %4055, label %4069, label %4056

4056:                                             ; preds = %3811
  %4057 = xor i32 %4053, -1
  %4058 = shl i32 1, %4057
  %4059 = insertelement <4 x i32> undef, i32 %4058, i32 0
  %4060 = shufflevector <4 x i32> %4059, <4 x i32> undef, <4 x i32> zeroinitializer
  %4061 = add <4 x i32> %4036, %4060
  %4062 = add <4 x i32> %4060, %4046
  %4063 = add <4 x i32> %4060, %4050
  %4064 = add <4 x i32> %4040, %4060
  %4065 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4061, i32 %4054) #8
  %4066 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4062, i32 %4054) #8
  %4067 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4063, i32 %4054) #8
  %4068 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4064, i32 %4054) #8
  br label %4069

4069:                                             ; preds = %3811, %4056
  %4070 = phi <4 x i32> [ %4040, %3811 ], [ %4068, %4056 ]
  %4071 = phi <4 x i32> [ %4050, %3811 ], [ %4067, %4056 ]
  %4072 = phi <4 x i32> [ %4046, %3811 ], [ %4066, %4056 ]
  %4073 = phi <4 x i32> [ %4036, %3811 ], [ %4065, %4056 ]
  %4074 = bitcast i16* %1 to i64*
  %4075 = load i64, i64* %4074, align 1
  %4076 = insertelement <2 x i64> undef, i64 %4075, i32 0
  %4077 = sext i32 %2 to i64
  %4078 = getelementptr inbounds i16, i16* %1, i64 %4077
  %4079 = bitcast i16* %4078 to i64*
  %4080 = load i64, i64* %4079, align 1
  %4081 = insertelement <2 x i64> undef, i64 %4080, i32 0
  %4082 = shl nsw i32 %2, 1
  %4083 = sext i32 %4082 to i64
  %4084 = getelementptr inbounds i16, i16* %1, i64 %4083
  %4085 = bitcast i16* %4084 to i64*
  %4086 = load i64, i64* %4085, align 1
  %4087 = insertelement <2 x i64> undef, i64 %4086, i32 0
  %4088 = mul nsw i32 %2, 3
  %4089 = sext i32 %4088 to i64
  %4090 = getelementptr inbounds i16, i16* %1, i64 %4089
  %4091 = bitcast i16* %4090 to i64*
  %4092 = load i64, i64* %4091, align 1
  %4093 = insertelement <2 x i64> undef, i64 %4092, i32 0
  %4094 = bitcast <2 x i64> %4076 to <8 x i16>
  %4095 = shufflevector <8 x i16> %4094, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4096 = bitcast <2 x i64> %4081 to <8 x i16>
  %4097 = shufflevector <8 x i16> %4096, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4098 = bitcast <2 x i64> %4087 to <8 x i16>
  %4099 = shufflevector <8 x i16> %4098, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4100 = bitcast <2 x i64> %4093 to <8 x i16>
  %4101 = shufflevector <8 x i16> %4100, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4102 = bitcast <8 x i16> %4095 to <4 x i32>
  %4103 = add <4 x i32> %4073, %4102
  %4104 = bitcast <8 x i16> %4097 to <4 x i32>
  %4105 = add <4 x i32> %4072, %4104
  %4106 = bitcast <8 x i16> %4099 to <4 x i32>
  %4107 = add <4 x i32> %4071, %4106
  %4108 = bitcast <8 x i16> %4101 to <4 x i32>
  %4109 = add <4 x i32> %4070, %4108
  %4110 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %4103, <4 x i32> %4105) #8
  %4111 = bitcast <8 x i16> %4110 to <2 x i64>
  %4112 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %4107, <4 x i32> %4109) #8
  %4113 = bitcast <8 x i16> %4112 to <2 x i64>
  %4114 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %4115 = add <8 x i16> %4114, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %4116 = icmp slt <8 x i16> %4115, %4110
  %4117 = sext <8 x i1> %4116 to <8 x i16>
  %4118 = bitcast <8 x i16> %4117 to <2 x i64>
  %4119 = xor <2 x i64> %4118, <i64 -1, i64 -1>
  %4120 = and <2 x i64> %4119, %4111
  %4121 = and <8 x i16> %4115, %4117
  %4122 = bitcast <8 x i16> %4121 to <2 x i64>
  %4123 = or <2 x i64> %4120, %4122
  %4124 = bitcast <2 x i64> %4123 to <8 x i16>
  %4125 = icmp sgt <8 x i16> %4124, zeroinitializer
  %4126 = sext <8 x i1> %4125 to <8 x i16>
  %4127 = bitcast <8 x i16> %4126 to <2 x i64>
  %4128 = and <2 x i64> %4123, %4127
  %4129 = icmp slt <8 x i16> %4115, %4112
  %4130 = sext <8 x i1> %4129 to <8 x i16>
  %4131 = bitcast <8 x i16> %4130 to <2 x i64>
  %4132 = xor <2 x i64> %4131, <i64 -1, i64 -1>
  %4133 = and <2 x i64> %4132, %4113
  %4134 = and <8 x i16> %4115, %4130
  br label %6055

4135:                                             ; preds = %5
  %4136 = bitcast i32* %0 to <4 x i32>*
  %4137 = load <4 x i32>, <4 x i32>* %4136, align 16
  %4138 = getelementptr inbounds i32, i32* %0, i64 4
  %4139 = bitcast i32* %4138 to <4 x i32>*
  %4140 = load <4 x i32>, <4 x i32>* %4139, align 16
  %4141 = getelementptr inbounds i32, i32* %0, i64 8
  %4142 = bitcast i32* %4141 to <4 x i32>*
  %4143 = load <4 x i32>, <4 x i32>* %4142, align 16
  %4144 = getelementptr inbounds i32, i32* %0, i64 12
  %4145 = bitcast i32* %4144 to <4 x i32>*
  %4146 = load <4 x i32>, <4 x i32>* %4145, align 16
  %4147 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 0, i64 0), align 16
  %4148 = sext i8 %4147 to i32
  %4149 = add nsw i32 %4148, -10
  %4150 = sext i32 %4149 to i64
  %4151 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %4150, i64 32
  %4152 = load i32, i32* %4151, align 16
  %4153 = insertelement <4 x i32> undef, i32 %4152, i32 0
  %4154 = shufflevector <4 x i32> %4153, <4 x i32> undef, <4 x i32> zeroinitializer
  %4155 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %4150, i64 48
  %4156 = load i32, i32* %4155, align 16
  %4157 = insertelement <4 x i32> undef, i32 %4156, i32 0
  %4158 = shufflevector <4 x i32> %4157, <4 x i32> undef, <4 x i32> zeroinitializer
  %4159 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %4150, i64 16
  %4160 = load i32, i32* %4159, align 16
  %4161 = insertelement <4 x i32> undef, i32 %4160, i32 0
  %4162 = shufflevector <4 x i32> %4161, <4 x i32> undef, <4 x i32> zeroinitializer
  %4163 = sub nsw i32 0, %4160
  %4164 = insertelement <4 x i32> undef, i32 %4163, i32 0
  %4165 = shufflevector <4 x i32> %4164, <4 x i32> undef, <4 x i32> zeroinitializer
  %4166 = add nsw i32 %4148, -1
  %4167 = shl i32 1, %4166
  %4168 = insertelement <4 x i32> undef, i32 %4167, i32 0
  %4169 = shufflevector <4 x i32> %4168, <4 x i32> undef, <4 x i32> zeroinitializer
  %4170 = icmp slt i32 %4, 8
  %4171 = add i32 %4, 7
  %4172 = shl i32 1, %4171
  %4173 = select i1 %4170, i32 32768, i32 %4172
  %4174 = sub nsw i32 0, %4173
  %4175 = insertelement <4 x i32> undef, i32 %4174, i32 0
  %4176 = shufflevector <4 x i32> %4175, <4 x i32> undef, <4 x i32> zeroinitializer
  %4177 = add nsw i32 %4173, -1
  %4178 = insertelement <4 x i32> undef, i32 %4177, i32 0
  %4179 = shufflevector <4 x i32> %4178, <4 x i32> undef, <4 x i32> zeroinitializer
  %4180 = shufflevector <4 x i32> %4137, <4 x i32> %4140, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4181 = bitcast <4 x i32> %4180 to <2 x i64>
  %4182 = shufflevector <4 x i32> %4137, <4 x i32> %4140, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4183 = bitcast <4 x i32> %4182 to <2 x i64>
  %4184 = shufflevector <4 x i32> %4143, <4 x i32> %4146, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4185 = bitcast <4 x i32> %4184 to <2 x i64>
  %4186 = shufflevector <4 x i32> %4143, <4 x i32> %4146, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4187 = bitcast <4 x i32> %4186 to <2 x i64>
  %4188 = shufflevector <2 x i64> %4181, <2 x i64> %4185, <2 x i32> <i32 0, i32 2>
  %4189 = shufflevector <2 x i64> %4181, <2 x i64> %4185, <2 x i32> <i32 1, i32 3>
  %4190 = shufflevector <2 x i64> %4183, <2 x i64> %4187, <2 x i32> <i32 0, i32 2>
  %4191 = shufflevector <2 x i64> %4183, <2 x i64> %4187, <2 x i32> <i32 1, i32 3>
  %4192 = bitcast <2 x i64> %4188 to <4 x i32>
  %4193 = mul <4 x i32> %4154, %4192
  %4194 = bitcast <2 x i64> %4190 to <4 x i32>
  %4195 = mul <4 x i32> %4154, %4194
  %4196 = add <4 x i32> %4195, %4193
  %4197 = add <4 x i32> %4196, %4169
  %4198 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4197, i32 %4148) #8
  %4199 = sub <4 x i32> %4193, %4195
  %4200 = add <4 x i32> %4199, %4169
  %4201 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4200, i32 %4148) #8
  %4202 = bitcast <2 x i64> %4189 to <4 x i32>
  %4203 = mul <4 x i32> %4158, %4202
  %4204 = bitcast <2 x i64> %4191 to <4 x i32>
  %4205 = mul <4 x i32> %4165, %4204
  %4206 = add <4 x i32> %4203, %4169
  %4207 = add <4 x i32> %4206, %4205
  %4208 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4207, i32 %4148) #8
  %4209 = mul <4 x i32> %4162, %4202
  %4210 = mul <4 x i32> %4158, %4204
  %4211 = add <4 x i32> %4210, %4169
  %4212 = add <4 x i32> %4211, %4209
  %4213 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4212, i32 %4148) #8
  %4214 = add <4 x i32> %4213, %4198
  %4215 = sub <4 x i32> %4198, %4213
  %4216 = icmp sgt <4 x i32> %4214, %4176
  %4217 = select <4 x i1> %4216, <4 x i32> %4214, <4 x i32> %4176
  %4218 = icmp slt <4 x i32> %4217, %4179
  %4219 = select <4 x i1> %4218, <4 x i32> %4217, <4 x i32> %4179
  %4220 = icmp sgt <4 x i32> %4215, %4176
  %4221 = select <4 x i1> %4220, <4 x i32> %4215, <4 x i32> %4176
  %4222 = icmp slt <4 x i32> %4221, %4179
  %4223 = select <4 x i1> %4222, <4 x i32> %4221, <4 x i32> %4179
  %4224 = add <4 x i32> %4208, %4201
  %4225 = sub <4 x i32> %4201, %4208
  %4226 = icmp sgt <4 x i32> %4224, %4176
  %4227 = select <4 x i1> %4226, <4 x i32> %4224, <4 x i32> %4176
  %4228 = icmp slt <4 x i32> %4227, %4179
  %4229 = select <4 x i1> %4228, <4 x i32> %4227, <4 x i32> %4179
  %4230 = icmp sgt <4 x i32> %4225, %4176
  %4231 = select <4 x i1> %4230, <4 x i32> %4225, <4 x i32> %4176
  %4232 = icmp slt <4 x i32> %4231, %4179
  %4233 = select <4 x i1> %4232, <4 x i32> %4231, <4 x i32> %4179
  %4234 = icmp sgt i32 %4, 10
  %4235 = select i1 %4234, i32 %4, i32 10
  %4236 = shl i32 32, %4235
  %4237 = sub nsw i32 0, %4236
  %4238 = insertelement <4 x i32> undef, i32 %4237, i32 0
  %4239 = shufflevector <4 x i32> %4238, <4 x i32> undef, <4 x i32> zeroinitializer
  %4240 = add nsw i32 %4236, -1
  %4241 = insertelement <4 x i32> undef, i32 %4240, i32 0
  %4242 = shufflevector <4 x i32> %4241, <4 x i32> undef, <4 x i32> zeroinitializer
  %4243 = icmp sgt <4 x i32> %4219, %4239
  %4244 = select <4 x i1> %4243, <4 x i32> %4219, <4 x i32> %4239
  %4245 = icmp slt <4 x i32> %4244, %4242
  %4246 = select <4 x i1> %4245, <4 x i32> %4244, <4 x i32> %4242
  %4247 = icmp sgt <4 x i32> %4223, %4239
  %4248 = select <4 x i1> %4247, <4 x i32> %4223, <4 x i32> %4239
  %4249 = icmp slt <4 x i32> %4248, %4242
  %4250 = select <4 x i1> %4249, <4 x i32> %4248, <4 x i32> %4242
  %4251 = bitcast <4 x i32> %4246 to <2 x i64>
  %4252 = bitcast <4 x i32> %4250 to <2 x i64>
  %4253 = icmp sgt <4 x i32> %4229, %4239
  %4254 = select <4 x i1> %4253, <4 x i32> %4229, <4 x i32> %4239
  %4255 = icmp slt <4 x i32> %4254, %4242
  %4256 = select <4 x i1> %4255, <4 x i32> %4254, <4 x i32> %4242
  %4257 = icmp sgt <4 x i32> %4233, %4239
  %4258 = select <4 x i1> %4257, <4 x i32> %4233, <4 x i32> %4239
  %4259 = icmp slt <4 x i32> %4258, %4242
  %4260 = select <4 x i1> %4259, <4 x i32> %4258, <4 x i32> %4242
  %4261 = bitcast <4 x i32> %4256 to <2 x i64>
  %4262 = bitcast <4 x i32> %4260 to <2 x i64>
  %4263 = shl <2 x i64> %4251, <i64 32, i64 32>
  %4264 = ashr exact <2 x i64> %4263, <i64 32, i64 32>
  %4265 = mul nsw <2 x i64> %4264, <i64 5793, i64 5793>
  %4266 = bitcast <2 x i64> %4265 to <4 x i32>
  %4267 = add <4 x i32> %4266, <i32 2048, i32 0, i32 2048, i32 0>
  %4268 = bitcast <4 x i32> %4267 to <2 x i64>
  %4269 = lshr <2 x i64> %4268, <i64 12, i64 12>
  %4270 = bitcast <4 x i32> %4246 to <16 x i8>
  %4271 = shufflevector <16 x i8> %4270, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4272 = bitcast <16 x i8> %4271 to <2 x i64>
  %4273 = shl <2 x i64> %4272, <i64 32, i64 32>
  %4274 = ashr exact <2 x i64> %4273, <i64 32, i64 32>
  %4275 = mul nsw <2 x i64> %4274, <i64 5793, i64 5793>
  %4276 = bitcast <2 x i64> %4275 to <4 x i32>
  %4277 = add <4 x i32> %4276, <i32 2048, i32 0, i32 2048, i32 0>
  %4278 = bitcast <4 x i32> %4277 to <2 x i64>
  %4279 = lshr <2 x i64> %4278, <i64 12, i64 12>
  %4280 = bitcast <2 x i64> %4269 to <4 x i32>
  %4281 = bitcast <2 x i64> %4279 to <4 x i32>
  %4282 = shufflevector <4 x i32> %4280, <4 x i32> %4281, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4283 = bitcast <4 x i32> %4282 to <2 x i64>
  %4284 = shufflevector <4 x i32> %4280, <4 x i32> %4281, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4285 = bitcast <4 x i32> %4284 to <2 x i64>
  %4286 = shufflevector <2 x i64> %4283, <2 x i64> %4285, <2 x i32> <i32 0, i32 2>
  %4287 = shl <2 x i64> %4261, <i64 32, i64 32>
  %4288 = ashr exact <2 x i64> %4287, <i64 32, i64 32>
  %4289 = mul nsw <2 x i64> %4288, <i64 5793, i64 5793>
  %4290 = bitcast <2 x i64> %4289 to <4 x i32>
  %4291 = add <4 x i32> %4290, <i32 2048, i32 0, i32 2048, i32 0>
  %4292 = bitcast <4 x i32> %4291 to <2 x i64>
  %4293 = lshr <2 x i64> %4292, <i64 12, i64 12>
  %4294 = bitcast <4 x i32> %4256 to <16 x i8>
  %4295 = shufflevector <16 x i8> %4294, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4296 = bitcast <16 x i8> %4295 to <2 x i64>
  %4297 = shl <2 x i64> %4296, <i64 32, i64 32>
  %4298 = ashr exact <2 x i64> %4297, <i64 32, i64 32>
  %4299 = mul nsw <2 x i64> %4298, <i64 5793, i64 5793>
  %4300 = bitcast <2 x i64> %4299 to <4 x i32>
  %4301 = add <4 x i32> %4300, <i32 2048, i32 0, i32 2048, i32 0>
  %4302 = bitcast <4 x i32> %4301 to <2 x i64>
  %4303 = lshr <2 x i64> %4302, <i64 12, i64 12>
  %4304 = bitcast <2 x i64> %4293 to <4 x i32>
  %4305 = bitcast <2 x i64> %4303 to <4 x i32>
  %4306 = shufflevector <4 x i32> %4304, <4 x i32> %4305, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4307 = bitcast <4 x i32> %4306 to <2 x i64>
  %4308 = shufflevector <4 x i32> %4304, <4 x i32> %4305, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4309 = bitcast <4 x i32> %4308 to <2 x i64>
  %4310 = shufflevector <2 x i64> %4307, <2 x i64> %4309, <2 x i32> <i32 0, i32 2>
  %4311 = shl <2 x i64> %4262, <i64 32, i64 32>
  %4312 = ashr exact <2 x i64> %4311, <i64 32, i64 32>
  %4313 = mul nsw <2 x i64> %4312, <i64 5793, i64 5793>
  %4314 = bitcast <2 x i64> %4313 to <4 x i32>
  %4315 = add <4 x i32> %4314, <i32 2048, i32 0, i32 2048, i32 0>
  %4316 = bitcast <4 x i32> %4315 to <2 x i64>
  %4317 = lshr <2 x i64> %4316, <i64 12, i64 12>
  %4318 = bitcast <4 x i32> %4260 to <16 x i8>
  %4319 = shufflevector <16 x i8> %4318, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4320 = bitcast <16 x i8> %4319 to <2 x i64>
  %4321 = shl <2 x i64> %4320, <i64 32, i64 32>
  %4322 = ashr exact <2 x i64> %4321, <i64 32, i64 32>
  %4323 = mul nsw <2 x i64> %4322, <i64 5793, i64 5793>
  %4324 = bitcast <2 x i64> %4323 to <4 x i32>
  %4325 = add <4 x i32> %4324, <i32 2048, i32 0, i32 2048, i32 0>
  %4326 = bitcast <4 x i32> %4325 to <2 x i64>
  %4327 = lshr <2 x i64> %4326, <i64 12, i64 12>
  %4328 = bitcast <2 x i64> %4317 to <4 x i32>
  %4329 = bitcast <2 x i64> %4327 to <4 x i32>
  %4330 = shufflevector <4 x i32> %4328, <4 x i32> %4329, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4331 = bitcast <4 x i32> %4330 to <2 x i64>
  %4332 = shufflevector <4 x i32> %4328, <4 x i32> %4329, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4333 = bitcast <4 x i32> %4332 to <2 x i64>
  %4334 = shufflevector <2 x i64> %4331, <2 x i64> %4333, <2 x i32> <i32 0, i32 2>
  %4335 = shl <2 x i64> %4252, <i64 32, i64 32>
  %4336 = ashr exact <2 x i64> %4335, <i64 32, i64 32>
  %4337 = mul nsw <2 x i64> %4336, <i64 5793, i64 5793>
  %4338 = bitcast <2 x i64> %4337 to <4 x i32>
  %4339 = add <4 x i32> %4338, <i32 2048, i32 0, i32 2048, i32 0>
  %4340 = bitcast <4 x i32> %4339 to <2 x i64>
  %4341 = lshr <2 x i64> %4340, <i64 12, i64 12>
  %4342 = bitcast <4 x i32> %4250 to <16 x i8>
  %4343 = shufflevector <16 x i8> %4342, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4344 = bitcast <16 x i8> %4343 to <2 x i64>
  %4345 = shl <2 x i64> %4344, <i64 32, i64 32>
  %4346 = ashr exact <2 x i64> %4345, <i64 32, i64 32>
  %4347 = mul nsw <2 x i64> %4346, <i64 5793, i64 5793>
  %4348 = bitcast <2 x i64> %4347 to <4 x i32>
  %4349 = add <4 x i32> %4348, <i32 2048, i32 0, i32 2048, i32 0>
  %4350 = bitcast <4 x i32> %4349 to <2 x i64>
  %4351 = lshr <2 x i64> %4350, <i64 12, i64 12>
  %4352 = bitcast <2 x i64> %4341 to <4 x i32>
  %4353 = bitcast <2 x i64> %4351 to <4 x i32>
  %4354 = shufflevector <4 x i32> %4352, <4 x i32> %4353, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4355 = bitcast <4 x i32> %4354 to <2 x i64>
  %4356 = shufflevector <4 x i32> %4352, <4 x i32> %4353, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4357 = bitcast <4 x i32> %4356 to <2 x i64>
  %4358 = shufflevector <2 x i64> %4355, <2 x i64> %4357, <2 x i32> <i32 0, i32 2>
  %4359 = bitcast <2 x i64> %4310 to <4 x i32>
  %4360 = bitcast <2 x i64> %4334 to <4 x i32>
  %4361 = bitcast <2 x i64> %4358 to <4 x i32>
  %4362 = bitcast <2 x i64> %4286 to <4 x i32>
  %4363 = shufflevector <4 x i32> %4362, <4 x i32> %4359, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4364 = bitcast <4 x i32> %4363 to <2 x i64>
  %4365 = shufflevector <4 x i32> %4362, <4 x i32> %4359, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4366 = bitcast <4 x i32> %4365 to <2 x i64>
  %4367 = shufflevector <4 x i32> %4360, <4 x i32> %4361, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4368 = bitcast <4 x i32> %4367 to <2 x i64>
  %4369 = shufflevector <4 x i32> %4360, <4 x i32> %4361, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4370 = bitcast <4 x i32> %4369 to <2 x i64>
  %4371 = shufflevector <2 x i64> %4364, <2 x i64> %4368, <2 x i32> <i32 0, i32 2>
  %4372 = shufflevector <2 x i64> %4364, <2 x i64> %4368, <2 x i32> <i32 1, i32 3>
  %4373 = shufflevector <2 x i64> %4366, <2 x i64> %4370, <2 x i32> <i32 0, i32 2>
  %4374 = shufflevector <2 x i64> %4366, <2 x i64> %4370, <2 x i32> <i32 1, i32 3>
  %4375 = getelementptr inbounds i8, i8* %6, i64 1
  %4376 = load i8, i8* %4375, align 1
  %4377 = sext i8 %4376 to i32
  %4378 = sub nsw i32 0, %4377
  %4379 = icmp eq i8 %4376, 0
  br i1 %4379, label %4401, label %4380

4380:                                             ; preds = %4135
  %4381 = xor i32 %4377, -1
  %4382 = shl i32 1, %4381
  %4383 = insertelement <4 x i32> undef, i32 %4382, i32 0
  %4384 = shufflevector <4 x i32> %4383, <4 x i32> undef, <4 x i32> zeroinitializer
  %4385 = bitcast <2 x i64> %4371 to <4 x i32>
  %4386 = add <4 x i32> %4384, %4385
  %4387 = bitcast <2 x i64> %4372 to <4 x i32>
  %4388 = add <4 x i32> %4384, %4387
  %4389 = bitcast <2 x i64> %4373 to <4 x i32>
  %4390 = add <4 x i32> %4384, %4389
  %4391 = bitcast <2 x i64> %4374 to <4 x i32>
  %4392 = add <4 x i32> %4384, %4391
  %4393 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4386, i32 %4378) #8
  %4394 = bitcast <4 x i32> %4393 to <2 x i64>
  %4395 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4388, i32 %4378) #8
  %4396 = bitcast <4 x i32> %4395 to <2 x i64>
  %4397 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4390, i32 %4378) #8
  %4398 = bitcast <4 x i32> %4397 to <2 x i64>
  %4399 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4392, i32 %4378) #8
  %4400 = bitcast <4 x i32> %4399 to <2 x i64>
  br label %4401

4401:                                             ; preds = %4135, %4380
  %4402 = phi <2 x i64> [ %4374, %4135 ], [ %4400, %4380 ]
  %4403 = phi <2 x i64> [ %4373, %4135 ], [ %4398, %4380 ]
  %4404 = phi <2 x i64> [ %4372, %4135 ], [ %4396, %4380 ]
  %4405 = phi <2 x i64> [ %4371, %4135 ], [ %4394, %4380 ]
  %4406 = bitcast i16* %1 to i64*
  %4407 = load i64, i64* %4406, align 1
  %4408 = insertelement <2 x i64> undef, i64 %4407, i32 0
  %4409 = sext i32 %2 to i64
  %4410 = getelementptr inbounds i16, i16* %1, i64 %4409
  %4411 = bitcast i16* %4410 to i64*
  %4412 = load i64, i64* %4411, align 1
  %4413 = insertelement <2 x i64> undef, i64 %4412, i32 0
  %4414 = shl nsw i32 %2, 1
  %4415 = sext i32 %4414 to i64
  %4416 = getelementptr inbounds i16, i16* %1, i64 %4415
  %4417 = bitcast i16* %4416 to i64*
  %4418 = load i64, i64* %4417, align 1
  %4419 = insertelement <2 x i64> undef, i64 %4418, i32 0
  %4420 = mul nsw i32 %2, 3
  %4421 = sext i32 %4420 to i64
  %4422 = getelementptr inbounds i16, i16* %1, i64 %4421
  %4423 = bitcast i16* %4422 to i64*
  %4424 = load i64, i64* %4423, align 1
  %4425 = insertelement <2 x i64> undef, i64 %4424, i32 0
  %4426 = bitcast <2 x i64> %4408 to <8 x i16>
  %4427 = shufflevector <8 x i16> %4426, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4428 = bitcast <2 x i64> %4413 to <8 x i16>
  %4429 = shufflevector <8 x i16> %4428, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4430 = bitcast <2 x i64> %4419 to <8 x i16>
  %4431 = shufflevector <8 x i16> %4430, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4432 = bitcast <2 x i64> %4425 to <8 x i16>
  %4433 = shufflevector <8 x i16> %4432, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4434 = bitcast <2 x i64> %4405 to <4 x i32>
  %4435 = bitcast <8 x i16> %4427 to <4 x i32>
  %4436 = add <4 x i32> %4435, %4434
  %4437 = bitcast <2 x i64> %4404 to <4 x i32>
  %4438 = bitcast <8 x i16> %4429 to <4 x i32>
  %4439 = add <4 x i32> %4438, %4437
  %4440 = bitcast <2 x i64> %4403 to <4 x i32>
  %4441 = bitcast <8 x i16> %4431 to <4 x i32>
  %4442 = add <4 x i32> %4441, %4440
  %4443 = bitcast <2 x i64> %4402 to <4 x i32>
  %4444 = bitcast <8 x i16> %4433 to <4 x i32>
  %4445 = add <4 x i32> %4444, %4443
  %4446 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %4436, <4 x i32> %4439) #8
  %4447 = bitcast <8 x i16> %4446 to <2 x i64>
  %4448 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %4442, <4 x i32> %4445) #8
  %4449 = bitcast <8 x i16> %4448 to <2 x i64>
  %4450 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %4451 = add <8 x i16> %4450, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %4452 = icmp slt <8 x i16> %4451, %4446
  %4453 = sext <8 x i1> %4452 to <8 x i16>
  %4454 = bitcast <8 x i16> %4453 to <2 x i64>
  %4455 = xor <2 x i64> %4454, <i64 -1, i64 -1>
  %4456 = and <2 x i64> %4455, %4447
  %4457 = and <8 x i16> %4451, %4453
  %4458 = bitcast <8 x i16> %4457 to <2 x i64>
  %4459 = or <2 x i64> %4456, %4458
  %4460 = bitcast <2 x i64> %4459 to <8 x i16>
  %4461 = icmp sgt <8 x i16> %4460, zeroinitializer
  %4462 = sext <8 x i1> %4461 to <8 x i16>
  %4463 = bitcast <8 x i16> %4462 to <2 x i64>
  %4464 = and <2 x i64> %4459, %4463
  %4465 = icmp slt <8 x i16> %4451, %4448
  %4466 = sext <8 x i1> %4465 to <8 x i16>
  %4467 = bitcast <8 x i16> %4466 to <2 x i64>
  %4468 = xor <2 x i64> %4467, <i64 -1, i64 -1>
  %4469 = and <2 x i64> %4468, %4449
  %4470 = and <8 x i16> %4451, %4466
  br label %6055

4471:                                             ; preds = %5
  %4472 = bitcast i32* %0 to <2 x i64>*
  %4473 = load <2 x i64>, <2 x i64>* %4472, align 16
  %4474 = getelementptr inbounds i32, i32* %0, i64 4
  %4475 = bitcast i32* %4474 to <2 x i64>*
  %4476 = load <2 x i64>, <2 x i64>* %4475, align 16
  %4477 = getelementptr inbounds i32, i32* %0, i64 8
  %4478 = bitcast i32* %4477 to <2 x i64>*
  %4479 = load <2 x i64>, <2 x i64>* %4478, align 16
  %4480 = getelementptr inbounds i32, i32* %0, i64 12
  %4481 = bitcast i32* %4480 to <2 x i64>*
  %4482 = load <2 x i64>, <2 x i64>* %4481, align 16
  %4483 = shl <2 x i64> %4473, <i64 32, i64 32>
  %4484 = ashr exact <2 x i64> %4483, <i64 32, i64 32>
  %4485 = mul nsw <2 x i64> %4484, <i64 5793, i64 5793>
  %4486 = bitcast <2 x i64> %4485 to <4 x i32>
  %4487 = add <4 x i32> %4486, <i32 2048, i32 0, i32 2048, i32 0>
  %4488 = bitcast <4 x i32> %4487 to <2 x i64>
  %4489 = lshr <2 x i64> %4488, <i64 12, i64 12>
  %4490 = bitcast <2 x i64> %4473 to <16 x i8>
  %4491 = shufflevector <16 x i8> %4490, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4492 = bitcast <16 x i8> %4491 to <2 x i64>
  %4493 = shl <2 x i64> %4492, <i64 32, i64 32>
  %4494 = ashr exact <2 x i64> %4493, <i64 32, i64 32>
  %4495 = mul nsw <2 x i64> %4494, <i64 5793, i64 5793>
  %4496 = bitcast <2 x i64> %4495 to <4 x i32>
  %4497 = add <4 x i32> %4496, <i32 2048, i32 0, i32 2048, i32 0>
  %4498 = bitcast <4 x i32> %4497 to <2 x i64>
  %4499 = lshr <2 x i64> %4498, <i64 12, i64 12>
  %4500 = bitcast <2 x i64> %4489 to <4 x i32>
  %4501 = bitcast <2 x i64> %4499 to <4 x i32>
  %4502 = shufflevector <4 x i32> %4500, <4 x i32> %4501, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4503 = bitcast <4 x i32> %4502 to <2 x i64>
  %4504 = shufflevector <4 x i32> %4500, <4 x i32> %4501, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4505 = bitcast <4 x i32> %4504 to <2 x i64>
  %4506 = shufflevector <2 x i64> %4503, <2 x i64> %4505, <2 x i32> <i32 0, i32 2>
  %4507 = shl <2 x i64> %4476, <i64 32, i64 32>
  %4508 = ashr exact <2 x i64> %4507, <i64 32, i64 32>
  %4509 = mul nsw <2 x i64> %4508, <i64 5793, i64 5793>
  %4510 = bitcast <2 x i64> %4509 to <4 x i32>
  %4511 = add <4 x i32> %4510, <i32 2048, i32 0, i32 2048, i32 0>
  %4512 = bitcast <4 x i32> %4511 to <2 x i64>
  %4513 = lshr <2 x i64> %4512, <i64 12, i64 12>
  %4514 = bitcast <2 x i64> %4476 to <16 x i8>
  %4515 = shufflevector <16 x i8> %4514, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4516 = bitcast <16 x i8> %4515 to <2 x i64>
  %4517 = shl <2 x i64> %4516, <i64 32, i64 32>
  %4518 = ashr exact <2 x i64> %4517, <i64 32, i64 32>
  %4519 = mul nsw <2 x i64> %4518, <i64 5793, i64 5793>
  %4520 = bitcast <2 x i64> %4519 to <4 x i32>
  %4521 = add <4 x i32> %4520, <i32 2048, i32 0, i32 2048, i32 0>
  %4522 = bitcast <4 x i32> %4521 to <2 x i64>
  %4523 = lshr <2 x i64> %4522, <i64 12, i64 12>
  %4524 = bitcast <2 x i64> %4513 to <4 x i32>
  %4525 = bitcast <2 x i64> %4523 to <4 x i32>
  %4526 = shufflevector <4 x i32> %4524, <4 x i32> %4525, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4527 = bitcast <4 x i32> %4526 to <2 x i64>
  %4528 = shufflevector <4 x i32> %4524, <4 x i32> %4525, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4529 = bitcast <4 x i32> %4528 to <2 x i64>
  %4530 = shufflevector <2 x i64> %4527, <2 x i64> %4529, <2 x i32> <i32 0, i32 2>
  %4531 = shl <2 x i64> %4479, <i64 32, i64 32>
  %4532 = ashr exact <2 x i64> %4531, <i64 32, i64 32>
  %4533 = mul nsw <2 x i64> %4532, <i64 5793, i64 5793>
  %4534 = bitcast <2 x i64> %4533 to <4 x i32>
  %4535 = add <4 x i32> %4534, <i32 2048, i32 0, i32 2048, i32 0>
  %4536 = bitcast <4 x i32> %4535 to <2 x i64>
  %4537 = lshr <2 x i64> %4536, <i64 12, i64 12>
  %4538 = bitcast <2 x i64> %4479 to <16 x i8>
  %4539 = shufflevector <16 x i8> %4538, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4540 = bitcast <16 x i8> %4539 to <2 x i64>
  %4541 = shl <2 x i64> %4540, <i64 32, i64 32>
  %4542 = ashr exact <2 x i64> %4541, <i64 32, i64 32>
  %4543 = mul nsw <2 x i64> %4542, <i64 5793, i64 5793>
  %4544 = bitcast <2 x i64> %4543 to <4 x i32>
  %4545 = add <4 x i32> %4544, <i32 2048, i32 0, i32 2048, i32 0>
  %4546 = bitcast <4 x i32> %4545 to <2 x i64>
  %4547 = lshr <2 x i64> %4546, <i64 12, i64 12>
  %4548 = bitcast <2 x i64> %4537 to <4 x i32>
  %4549 = bitcast <2 x i64> %4547 to <4 x i32>
  %4550 = shufflevector <4 x i32> %4548, <4 x i32> %4549, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4551 = bitcast <4 x i32> %4550 to <2 x i64>
  %4552 = shufflevector <4 x i32> %4548, <4 x i32> %4549, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4553 = bitcast <4 x i32> %4552 to <2 x i64>
  %4554 = shufflevector <2 x i64> %4551, <2 x i64> %4553, <2 x i32> <i32 0, i32 2>
  %4555 = shl <2 x i64> %4482, <i64 32, i64 32>
  %4556 = ashr exact <2 x i64> %4555, <i64 32, i64 32>
  %4557 = mul nsw <2 x i64> %4556, <i64 5793, i64 5793>
  %4558 = bitcast <2 x i64> %4557 to <4 x i32>
  %4559 = add <4 x i32> %4558, <i32 2048, i32 0, i32 2048, i32 0>
  %4560 = bitcast <4 x i32> %4559 to <2 x i64>
  %4561 = lshr <2 x i64> %4560, <i64 12, i64 12>
  %4562 = bitcast <2 x i64> %4482 to <16 x i8>
  %4563 = shufflevector <16 x i8> %4562, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4564 = bitcast <16 x i8> %4563 to <2 x i64>
  %4565 = shl <2 x i64> %4564, <i64 32, i64 32>
  %4566 = ashr exact <2 x i64> %4565, <i64 32, i64 32>
  %4567 = mul nsw <2 x i64> %4566, <i64 5793, i64 5793>
  %4568 = bitcast <2 x i64> %4567 to <4 x i32>
  %4569 = add <4 x i32> %4568, <i32 2048, i32 0, i32 2048, i32 0>
  %4570 = bitcast <4 x i32> %4569 to <2 x i64>
  %4571 = lshr <2 x i64> %4570, <i64 12, i64 12>
  %4572 = bitcast <2 x i64> %4561 to <4 x i32>
  %4573 = bitcast <2 x i64> %4571 to <4 x i32>
  %4574 = shufflevector <4 x i32> %4572, <4 x i32> %4573, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4575 = bitcast <4 x i32> %4574 to <2 x i64>
  %4576 = shufflevector <4 x i32> %4572, <4 x i32> %4573, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4577 = bitcast <4 x i32> %4576 to <2 x i64>
  %4578 = shufflevector <2 x i64> %4575, <2 x i64> %4577, <2 x i32> <i32 0, i32 2>
  %4579 = bitcast <2 x i64> %4530 to <4 x i32>
  %4580 = bitcast <2 x i64> %4554 to <4 x i32>
  %4581 = bitcast <2 x i64> %4578 to <4 x i32>
  %4582 = icmp sgt i32 %4, 10
  %4583 = select i1 %4582, i32 %4, i32 10
  %4584 = shl i32 32, %4583
  %4585 = sub nsw i32 0, %4584
  %4586 = insertelement <4 x i32> undef, i32 %4585, i32 0
  %4587 = shufflevector <4 x i32> %4586, <4 x i32> undef, <4 x i32> zeroinitializer
  %4588 = add nsw i32 %4584, -1
  %4589 = insertelement <4 x i32> undef, i32 %4588, i32 0
  %4590 = shufflevector <4 x i32> %4589, <4 x i32> undef, <4 x i32> zeroinitializer
  %4591 = bitcast <2 x i64> %4506 to <4 x i32>
  %4592 = icmp slt <4 x i32> %4587, %4591
  %4593 = select <4 x i1> %4592, <4 x i32> %4591, <4 x i32> %4587
  %4594 = icmp slt <4 x i32> %4593, %4590
  %4595 = select <4 x i1> %4594, <4 x i32> %4593, <4 x i32> %4590
  %4596 = icmp slt <4 x i32> %4587, %4579
  %4597 = select <4 x i1> %4596, <4 x i32> %4579, <4 x i32> %4587
  %4598 = icmp slt <4 x i32> %4597, %4590
  %4599 = select <4 x i1> %4598, <4 x i32> %4597, <4 x i32> %4590
  %4600 = icmp slt <4 x i32> %4587, %4580
  %4601 = select <4 x i1> %4600, <4 x i32> %4580, <4 x i32> %4587
  %4602 = icmp slt <4 x i32> %4601, %4590
  %4603 = select <4 x i1> %4602, <4 x i32> %4601, <4 x i32> %4590
  %4604 = icmp slt <4 x i32> %4587, %4581
  %4605 = select <4 x i1> %4604, <4 x i32> %4581, <4 x i32> %4587
  %4606 = icmp slt <4 x i32> %4605, %4590
  %4607 = select <4 x i1> %4606, <4 x i32> %4605, <4 x i32> %4590
  %4608 = shufflevector <4 x i32> %4595, <4 x i32> %4599, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4609 = bitcast <4 x i32> %4608 to <2 x i64>
  %4610 = shufflevector <4 x i32> %4595, <4 x i32> %4599, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4611 = bitcast <4 x i32> %4610 to <2 x i64>
  %4612 = shufflevector <4 x i32> %4603, <4 x i32> %4607, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4613 = bitcast <4 x i32> %4612 to <2 x i64>
  %4614 = shufflevector <4 x i32> %4603, <4 x i32> %4607, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4615 = bitcast <4 x i32> %4614 to <2 x i64>
  %4616 = shufflevector <2 x i64> %4609, <2 x i64> %4613, <2 x i32> <i32 0, i32 2>
  %4617 = shufflevector <2 x i64> %4609, <2 x i64> %4613, <2 x i32> <i32 1, i32 3>
  %4618 = shufflevector <2 x i64> %4611, <2 x i64> %4615, <2 x i32> <i32 0, i32 2>
  %4619 = shufflevector <2 x i64> %4611, <2 x i64> %4615, <2 x i32> <i32 1, i32 3>
  %4620 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 0, i64 0), align 16
  %4621 = sext i8 %4620 to i32
  %4622 = add nsw i32 %4621, -10
  %4623 = sext i32 %4622 to i64
  %4624 = add nsw i32 %4621, 3
  %4625 = shl i32 1, %4624
  %4626 = insertelement <4 x i32> undef, i32 %4625, i32 0
  %4627 = shufflevector <4 x i32> %4626, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %4628 = shufflevector <4 x i32> %4627, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4629 = bitcast <4 x i32> %4628 to <2 x i64>
  %4630 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %4623, i64 1
  %4631 = load i32, i32* %4630, align 4
  %4632 = insertelement <4 x i32> undef, i32 %4631, i32 0
  %4633 = shufflevector <4 x i32> %4632, <4 x i32> undef, <4 x i32> zeroinitializer
  %4634 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %4623, i64 2
  %4635 = load i32, i32* %4634, align 4
  %4636 = insertelement <4 x i32> undef, i32 %4635, i32 0
  %4637 = shufflevector <4 x i32> %4636, <4 x i32> undef, <4 x i32> zeroinitializer
  %4638 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %4623, i64 3
  %4639 = load i32, i32* %4638, align 4
  %4640 = insertelement <4 x i32> undef, i32 %4639, i32 0
  %4641 = shufflevector <4 x i32> %4640, <4 x i32> undef, <4 x i32> zeroinitializer
  %4642 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %4623, i64 4
  %4643 = load i32, i32* %4642, align 4
  %4644 = insertelement <4 x i32> undef, i32 %4643, i32 0
  %4645 = shufflevector <4 x i32> %4644, <4 x i32> undef, <4 x i32> zeroinitializer
  %4646 = bitcast <2 x i64> %4616 to <4 x i32>
  %4647 = bitcast <2 x i64> %4617 to <4 x i32>
  %4648 = shufflevector <4 x i32> %4646, <4 x i32> %4647, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4649 = bitcast <4 x i32> %4648 to <2 x i64>
  %4650 = shufflevector <4 x i32> %4646, <4 x i32> %4647, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4651 = bitcast <4 x i32> %4650 to <2 x i64>
  %4652 = bitcast <2 x i64> %4618 to <4 x i32>
  %4653 = bitcast <2 x i64> %4619 to <4 x i32>
  %4654 = shufflevector <4 x i32> %4652, <4 x i32> %4653, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4655 = bitcast <4 x i32> %4654 to <2 x i64>
  %4656 = shufflevector <4 x i32> %4652, <4 x i32> %4653, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4657 = bitcast <4 x i32> %4656 to <2 x i64>
  %4658 = shufflevector <2 x i64> %4649, <2 x i64> %4655, <2 x i32> <i32 0, i32 2>
  %4659 = shufflevector <2 x i64> %4649, <2 x i64> %4655, <2 x i32> <i32 1, i32 3>
  %4660 = shufflevector <2 x i64> %4651, <2 x i64> %4657, <2 x i32> <i32 0, i32 2>
  %4661 = shufflevector <2 x i64> %4651, <2 x i64> %4657, <2 x i32> <i32 1, i32 3>
  %4662 = bitcast <2 x i64> %4658 to <4 x i32>
  %4663 = mul <4 x i32> %4633, %4662
  %4664 = mul <4 x i32> %4637, %4662
  %4665 = bitcast <2 x i64> %4659 to <4 x i32>
  %4666 = mul <4 x i32> %4641, %4665
  %4667 = bitcast <2 x i64> %4660 to <4 x i32>
  %4668 = mul <4 x i32> %4645, %4667
  %4669 = mul <4 x i32> %4633, %4667
  %4670 = bitcast <2 x i64> %4661 to <4 x i32>
  %4671 = mul <4 x i32> %4637, %4670
  %4672 = sub <4 x i32> %4662, %4667
  %4673 = add <4 x i32> %4672, %4670
  %4674 = add <4 x i32> %4668, %4663
  %4675 = add <4 x i32> %4674, %4671
  %4676 = sub <4 x i32> %4664, %4669
  %4677 = mul <4 x i32> %4645, %4670
  %4678 = sub <4 x i32> %4676, %4677
  %4679 = mul <4 x i32> %4673, %4641
  %4680 = bitcast <4 x i32> %4679 to <2 x i64>
  %4681 = add <4 x i32> %4675, %4666
  %4682 = bitcast <4 x i32> %4681 to <2 x i64>
  %4683 = add <4 x i32> %4678, %4666
  %4684 = bitcast <4 x i32> %4683 to <2 x i64>
  %4685 = sub <4 x i32> %4675, %4666
  %4686 = add <4 x i32> %4685, %4678
  %4687 = bitcast <4 x i32> %4686 to <2 x i64>
  %4688 = shl <2 x i64> %4682, <i64 32, i64 32>
  %4689 = ashr exact <2 x i64> %4688, <i64 28, i64 28>
  %4690 = add <2 x i64> %4689, %4629
  %4691 = bitcast <4 x i32> %4681 to <16 x i8>
  %4692 = shufflevector <16 x i8> %4691, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4693 = bitcast <16 x i8> %4692 to <2 x i64>
  %4694 = shl <2 x i64> %4693, <i64 32, i64 32>
  %4695 = ashr exact <2 x i64> %4694, <i64 28, i64 28>
  %4696 = add <2 x i64> %4695, %4629
  %4697 = bitcast <2 x i64> %4690 to <16 x i8>
  %4698 = shufflevector <16 x i8> %4697, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4699 = bitcast <2 x i64> %4696 to <16 x i8>
  %4700 = shufflevector <16 x i8> %4699, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4701 = bitcast <16 x i8> %4698 to <4 x i32>
  %4702 = bitcast <16 x i8> %4700 to <4 x i32>
  %4703 = shufflevector <4 x i32> %4701, <4 x i32> %4702, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4704 = bitcast <4 x i32> %4703 to <2 x i64>
  %4705 = shufflevector <4 x i32> %4701, <4 x i32> %4702, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4706 = bitcast <4 x i32> %4705 to <2 x i64>
  %4707 = shufflevector <2 x i64> %4704, <2 x i64> %4706, <2 x i32> <i32 0, i32 2>
  %4708 = shl <2 x i64> %4684, <i64 32, i64 32>
  %4709 = ashr exact <2 x i64> %4708, <i64 28, i64 28>
  %4710 = add <2 x i64> %4709, %4629
  %4711 = bitcast <4 x i32> %4683 to <16 x i8>
  %4712 = shufflevector <16 x i8> %4711, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4713 = bitcast <16 x i8> %4712 to <2 x i64>
  %4714 = shl <2 x i64> %4713, <i64 32, i64 32>
  %4715 = ashr exact <2 x i64> %4714, <i64 28, i64 28>
  %4716 = add <2 x i64> %4715, %4629
  %4717 = bitcast <2 x i64> %4710 to <16 x i8>
  %4718 = shufflevector <16 x i8> %4717, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4719 = bitcast <2 x i64> %4716 to <16 x i8>
  %4720 = shufflevector <16 x i8> %4719, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4721 = bitcast <16 x i8> %4718 to <4 x i32>
  %4722 = bitcast <16 x i8> %4720 to <4 x i32>
  %4723 = shufflevector <4 x i32> %4721, <4 x i32> %4722, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4724 = bitcast <4 x i32> %4723 to <2 x i64>
  %4725 = shufflevector <4 x i32> %4721, <4 x i32> %4722, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4726 = bitcast <4 x i32> %4725 to <2 x i64>
  %4727 = shufflevector <2 x i64> %4724, <2 x i64> %4726, <2 x i32> <i32 0, i32 2>
  %4728 = shl <2 x i64> %4680, <i64 32, i64 32>
  %4729 = ashr exact <2 x i64> %4728, <i64 28, i64 28>
  %4730 = add <2 x i64> %4729, %4629
  %4731 = bitcast <4 x i32> %4679 to <16 x i8>
  %4732 = shufflevector <16 x i8> %4731, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4733 = bitcast <16 x i8> %4732 to <2 x i64>
  %4734 = shl <2 x i64> %4733, <i64 32, i64 32>
  %4735 = ashr exact <2 x i64> %4734, <i64 28, i64 28>
  %4736 = add <2 x i64> %4735, %4629
  %4737 = bitcast <2 x i64> %4730 to <16 x i8>
  %4738 = shufflevector <16 x i8> %4737, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4739 = bitcast <2 x i64> %4736 to <16 x i8>
  %4740 = shufflevector <16 x i8> %4739, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4741 = bitcast <16 x i8> %4738 to <4 x i32>
  %4742 = bitcast <16 x i8> %4740 to <4 x i32>
  %4743 = shufflevector <4 x i32> %4741, <4 x i32> %4742, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4744 = bitcast <4 x i32> %4743 to <2 x i64>
  %4745 = shufflevector <4 x i32> %4741, <4 x i32> %4742, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4746 = bitcast <4 x i32> %4745 to <2 x i64>
  %4747 = shufflevector <2 x i64> %4744, <2 x i64> %4746, <2 x i32> <i32 0, i32 2>
  %4748 = shl <2 x i64> %4687, <i64 32, i64 32>
  %4749 = ashr exact <2 x i64> %4748, <i64 28, i64 28>
  %4750 = add <2 x i64> %4749, %4629
  %4751 = bitcast <4 x i32> %4686 to <16 x i8>
  %4752 = shufflevector <16 x i8> %4751, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4753 = bitcast <16 x i8> %4752 to <2 x i64>
  %4754 = shl <2 x i64> %4753, <i64 32, i64 32>
  %4755 = ashr exact <2 x i64> %4754, <i64 28, i64 28>
  %4756 = add <2 x i64> %4755, %4629
  %4757 = bitcast <2 x i64> %4750 to <16 x i8>
  %4758 = shufflevector <16 x i8> %4757, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4759 = bitcast <2 x i64> %4756 to <16 x i8>
  %4760 = shufflevector <16 x i8> %4759, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4761 = bitcast <16 x i8> %4758 to <4 x i32>
  %4762 = bitcast <16 x i8> %4760 to <4 x i32>
  %4763 = shufflevector <4 x i32> %4761, <4 x i32> %4762, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4764 = bitcast <4 x i32> %4763 to <2 x i64>
  %4765 = shufflevector <4 x i32> %4761, <4 x i32> %4762, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4766 = bitcast <4 x i32> %4765 to <2 x i64>
  %4767 = shufflevector <2 x i64> %4764, <2 x i64> %4766, <2 x i32> <i32 0, i32 2>
  %4768 = getelementptr inbounds i8, i8* %6, i64 1
  %4769 = load i8, i8* %4768, align 1
  %4770 = sext i8 %4769 to i32
  %4771 = sub nsw i32 0, %4770
  %4772 = icmp eq i8 %4769, 0
  br i1 %4772, label %4794, label %4773

4773:                                             ; preds = %4471
  %4774 = xor i32 %4770, -1
  %4775 = shl i32 1, %4774
  %4776 = insertelement <4 x i32> undef, i32 %4775, i32 0
  %4777 = shufflevector <4 x i32> %4776, <4 x i32> undef, <4 x i32> zeroinitializer
  %4778 = bitcast <2 x i64> %4707 to <4 x i32>
  %4779 = add <4 x i32> %4777, %4778
  %4780 = bitcast <2 x i64> %4727 to <4 x i32>
  %4781 = add <4 x i32> %4777, %4780
  %4782 = bitcast <2 x i64> %4747 to <4 x i32>
  %4783 = add <4 x i32> %4777, %4782
  %4784 = bitcast <2 x i64> %4767 to <4 x i32>
  %4785 = add <4 x i32> %4777, %4784
  %4786 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4779, i32 %4771) #8
  %4787 = bitcast <4 x i32> %4786 to <2 x i64>
  %4788 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4781, i32 %4771) #8
  %4789 = bitcast <4 x i32> %4788 to <2 x i64>
  %4790 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4783, i32 %4771) #8
  %4791 = bitcast <4 x i32> %4790 to <2 x i64>
  %4792 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %4785, i32 %4771) #8
  %4793 = bitcast <4 x i32> %4792 to <2 x i64>
  br label %4794

4794:                                             ; preds = %4471, %4773
  %4795 = phi <2 x i64> [ %4767, %4471 ], [ %4793, %4773 ]
  %4796 = phi <2 x i64> [ %4747, %4471 ], [ %4791, %4773 ]
  %4797 = phi <2 x i64> [ %4727, %4471 ], [ %4789, %4773 ]
  %4798 = phi <2 x i64> [ %4707, %4471 ], [ %4787, %4773 ]
  %4799 = bitcast i16* %1 to i64*
  %4800 = load i64, i64* %4799, align 1
  %4801 = insertelement <2 x i64> undef, i64 %4800, i32 0
  %4802 = sext i32 %2 to i64
  %4803 = getelementptr inbounds i16, i16* %1, i64 %4802
  %4804 = bitcast i16* %4803 to i64*
  %4805 = load i64, i64* %4804, align 1
  %4806 = insertelement <2 x i64> undef, i64 %4805, i32 0
  %4807 = shl nsw i32 %2, 1
  %4808 = sext i32 %4807 to i64
  %4809 = getelementptr inbounds i16, i16* %1, i64 %4808
  %4810 = bitcast i16* %4809 to i64*
  %4811 = load i64, i64* %4810, align 1
  %4812 = insertelement <2 x i64> undef, i64 %4811, i32 0
  %4813 = mul nsw i32 %2, 3
  %4814 = sext i32 %4813 to i64
  %4815 = getelementptr inbounds i16, i16* %1, i64 %4814
  %4816 = bitcast i16* %4815 to i64*
  %4817 = load i64, i64* %4816, align 1
  %4818 = insertelement <2 x i64> undef, i64 %4817, i32 0
  %4819 = bitcast <2 x i64> %4801 to <8 x i16>
  %4820 = shufflevector <8 x i16> %4819, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4821 = bitcast <2 x i64> %4806 to <8 x i16>
  %4822 = shufflevector <8 x i16> %4821, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4823 = bitcast <2 x i64> %4812 to <8 x i16>
  %4824 = shufflevector <8 x i16> %4823, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4825 = bitcast <2 x i64> %4818 to <8 x i16>
  %4826 = shufflevector <8 x i16> %4825, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4827 = bitcast <2 x i64> %4798 to <4 x i32>
  %4828 = bitcast <8 x i16> %4820 to <4 x i32>
  %4829 = add <4 x i32> %4828, %4827
  %4830 = bitcast <2 x i64> %4797 to <4 x i32>
  %4831 = bitcast <8 x i16> %4822 to <4 x i32>
  %4832 = add <4 x i32> %4831, %4830
  %4833 = bitcast <2 x i64> %4796 to <4 x i32>
  %4834 = bitcast <8 x i16> %4824 to <4 x i32>
  %4835 = add <4 x i32> %4834, %4833
  %4836 = bitcast <2 x i64> %4795 to <4 x i32>
  %4837 = bitcast <8 x i16> %4826 to <4 x i32>
  %4838 = add <4 x i32> %4837, %4836
  %4839 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %4829, <4 x i32> %4832) #8
  %4840 = bitcast <8 x i16> %4839 to <2 x i64>
  %4841 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %4835, <4 x i32> %4838) #8
  %4842 = bitcast <8 x i16> %4841 to <2 x i64>
  %4843 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %4844 = add <8 x i16> %4843, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %4845 = icmp slt <8 x i16> %4844, %4839
  %4846 = sext <8 x i1> %4845 to <8 x i16>
  %4847 = bitcast <8 x i16> %4846 to <2 x i64>
  %4848 = xor <2 x i64> %4847, <i64 -1, i64 -1>
  %4849 = and <2 x i64> %4848, %4840
  %4850 = and <8 x i16> %4844, %4846
  %4851 = bitcast <8 x i16> %4850 to <2 x i64>
  %4852 = or <2 x i64> %4849, %4851
  %4853 = bitcast <2 x i64> %4852 to <8 x i16>
  %4854 = icmp sgt <8 x i16> %4853, zeroinitializer
  %4855 = sext <8 x i1> %4854 to <8 x i16>
  %4856 = bitcast <8 x i16> %4855 to <2 x i64>
  %4857 = and <2 x i64> %4852, %4856
  %4858 = icmp slt <8 x i16> %4844, %4841
  %4859 = sext <8 x i1> %4858 to <8 x i16>
  %4860 = bitcast <8 x i16> %4859 to <2 x i64>
  %4861 = xor <2 x i64> %4860, <i64 -1, i64 -1>
  %4862 = and <2 x i64> %4861, %4842
  %4863 = and <8 x i16> %4844, %4859
  br label %6055

4864:                                             ; preds = %5
  %4865 = bitcast i32* %0 to <4 x i32>*
  %4866 = load <4 x i32>, <4 x i32>* %4865, align 16
  %4867 = getelementptr inbounds i32, i32* %0, i64 4
  %4868 = bitcast i32* %4867 to <4 x i32>*
  %4869 = load <4 x i32>, <4 x i32>* %4868, align 16
  %4870 = getelementptr inbounds i32, i32* %0, i64 8
  %4871 = bitcast i32* %4870 to <4 x i32>*
  %4872 = load <4 x i32>, <4 x i32>* %4871, align 16
  %4873 = getelementptr inbounds i32, i32* %0, i64 12
  %4874 = bitcast i32* %4873 to <4 x i32>*
  %4875 = load <4 x i32>, <4 x i32>* %4874, align 16
  %4876 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 0, i64 0), align 16
  %4877 = sext i8 %4876 to i32
  %4878 = add nsw i32 %4877, -10
  %4879 = sext i32 %4878 to i64
  %4880 = add nsw i32 %4877, 3
  %4881 = shl i32 1, %4880
  %4882 = insertelement <4 x i32> undef, i32 %4881, i32 0
  %4883 = shufflevector <4 x i32> %4882, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %4884 = shufflevector <4 x i32> %4883, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4885 = bitcast <4 x i32> %4884 to <2 x i64>
  %4886 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %4879, i64 1
  %4887 = load i32, i32* %4886, align 4
  %4888 = insertelement <4 x i32> undef, i32 %4887, i32 0
  %4889 = shufflevector <4 x i32> %4888, <4 x i32> undef, <4 x i32> zeroinitializer
  %4890 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %4879, i64 2
  %4891 = load i32, i32* %4890, align 4
  %4892 = insertelement <4 x i32> undef, i32 %4891, i32 0
  %4893 = shufflevector <4 x i32> %4892, <4 x i32> undef, <4 x i32> zeroinitializer
  %4894 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %4879, i64 3
  %4895 = load i32, i32* %4894, align 4
  %4896 = insertelement <4 x i32> undef, i32 %4895, i32 0
  %4897 = shufflevector <4 x i32> %4896, <4 x i32> undef, <4 x i32> zeroinitializer
  %4898 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %4879, i64 4
  %4899 = load i32, i32* %4898, align 4
  %4900 = insertelement <4 x i32> undef, i32 %4899, i32 0
  %4901 = shufflevector <4 x i32> %4900, <4 x i32> undef, <4 x i32> zeroinitializer
  %4902 = shufflevector <4 x i32> %4866, <4 x i32> %4869, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4903 = bitcast <4 x i32> %4902 to <2 x i64>
  %4904 = shufflevector <4 x i32> %4866, <4 x i32> %4869, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4905 = bitcast <4 x i32> %4904 to <2 x i64>
  %4906 = shufflevector <4 x i32> %4872, <4 x i32> %4875, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4907 = bitcast <4 x i32> %4906 to <2 x i64>
  %4908 = shufflevector <4 x i32> %4872, <4 x i32> %4875, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4909 = bitcast <4 x i32> %4908 to <2 x i64>
  %4910 = shufflevector <2 x i64> %4903, <2 x i64> %4907, <2 x i32> <i32 0, i32 2>
  %4911 = shufflevector <2 x i64> %4903, <2 x i64> %4907, <2 x i32> <i32 1, i32 3>
  %4912 = shufflevector <2 x i64> %4905, <2 x i64> %4909, <2 x i32> <i32 0, i32 2>
  %4913 = shufflevector <2 x i64> %4905, <2 x i64> %4909, <2 x i32> <i32 1, i32 3>
  %4914 = bitcast <2 x i64> %4910 to <4 x i32>
  %4915 = mul <4 x i32> %4889, %4914
  %4916 = mul <4 x i32> %4893, %4914
  %4917 = bitcast <2 x i64> %4911 to <4 x i32>
  %4918 = mul <4 x i32> %4897, %4917
  %4919 = bitcast <2 x i64> %4912 to <4 x i32>
  %4920 = mul <4 x i32> %4901, %4919
  %4921 = mul <4 x i32> %4889, %4919
  %4922 = bitcast <2 x i64> %4913 to <4 x i32>
  %4923 = mul <4 x i32> %4893, %4922
  %4924 = sub <4 x i32> %4914, %4919
  %4925 = add <4 x i32> %4924, %4922
  %4926 = add <4 x i32> %4923, %4915
  %4927 = add <4 x i32> %4926, %4920
  %4928 = sub <4 x i32> %4916, %4921
  %4929 = mul <4 x i32> %4901, %4922
  %4930 = sub <4 x i32> %4928, %4929
  %4931 = mul <4 x i32> %4925, %4897
  %4932 = bitcast <4 x i32> %4931 to <2 x i64>
  %4933 = add <4 x i32> %4927, %4918
  %4934 = bitcast <4 x i32> %4933 to <2 x i64>
  %4935 = add <4 x i32> %4930, %4918
  %4936 = bitcast <4 x i32> %4935 to <2 x i64>
  %4937 = sub <4 x i32> %4927, %4918
  %4938 = add <4 x i32> %4937, %4930
  %4939 = bitcast <4 x i32> %4938 to <2 x i64>
  %4940 = shl <2 x i64> %4934, <i64 32, i64 32>
  %4941 = ashr exact <2 x i64> %4940, <i64 28, i64 28>
  %4942 = add <2 x i64> %4941, %4885
  %4943 = bitcast <4 x i32> %4933 to <16 x i8>
  %4944 = shufflevector <16 x i8> %4943, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4945 = bitcast <16 x i8> %4944 to <2 x i64>
  %4946 = shl <2 x i64> %4945, <i64 32, i64 32>
  %4947 = ashr exact <2 x i64> %4946, <i64 28, i64 28>
  %4948 = add <2 x i64> %4947, %4885
  %4949 = bitcast <2 x i64> %4942 to <16 x i8>
  %4950 = shufflevector <16 x i8> %4949, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4951 = bitcast <2 x i64> %4948 to <16 x i8>
  %4952 = shufflevector <16 x i8> %4951, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4953 = bitcast <16 x i8> %4950 to <4 x i32>
  %4954 = bitcast <16 x i8> %4952 to <4 x i32>
  %4955 = shufflevector <4 x i32> %4953, <4 x i32> %4954, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4956 = bitcast <4 x i32> %4955 to <2 x i64>
  %4957 = shufflevector <4 x i32> %4953, <4 x i32> %4954, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4958 = bitcast <4 x i32> %4957 to <2 x i64>
  %4959 = shufflevector <2 x i64> %4956, <2 x i64> %4958, <2 x i32> <i32 0, i32 2>
  %4960 = shl <2 x i64> %4936, <i64 32, i64 32>
  %4961 = ashr exact <2 x i64> %4960, <i64 28, i64 28>
  %4962 = add <2 x i64> %4961, %4885
  %4963 = bitcast <4 x i32> %4935 to <16 x i8>
  %4964 = shufflevector <16 x i8> %4963, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4965 = bitcast <16 x i8> %4964 to <2 x i64>
  %4966 = shl <2 x i64> %4965, <i64 32, i64 32>
  %4967 = ashr exact <2 x i64> %4966, <i64 28, i64 28>
  %4968 = add <2 x i64> %4967, %4885
  %4969 = bitcast <2 x i64> %4962 to <16 x i8>
  %4970 = shufflevector <16 x i8> %4969, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4971 = bitcast <2 x i64> %4968 to <16 x i8>
  %4972 = shufflevector <16 x i8> %4971, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4973 = bitcast <16 x i8> %4970 to <4 x i32>
  %4974 = bitcast <16 x i8> %4972 to <4 x i32>
  %4975 = shufflevector <4 x i32> %4973, <4 x i32> %4974, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4976 = bitcast <4 x i32> %4975 to <2 x i64>
  %4977 = shufflevector <4 x i32> %4973, <4 x i32> %4974, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4978 = bitcast <4 x i32> %4977 to <2 x i64>
  %4979 = shufflevector <2 x i64> %4976, <2 x i64> %4978, <2 x i32> <i32 0, i32 2>
  %4980 = shl <2 x i64> %4932, <i64 32, i64 32>
  %4981 = ashr exact <2 x i64> %4980, <i64 28, i64 28>
  %4982 = add <2 x i64> %4981, %4885
  %4983 = bitcast <4 x i32> %4931 to <16 x i8>
  %4984 = shufflevector <16 x i8> %4983, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %4985 = bitcast <16 x i8> %4984 to <2 x i64>
  %4986 = shl <2 x i64> %4985, <i64 32, i64 32>
  %4987 = ashr exact <2 x i64> %4986, <i64 28, i64 28>
  %4988 = add <2 x i64> %4987, %4885
  %4989 = bitcast <2 x i64> %4982 to <16 x i8>
  %4990 = shufflevector <16 x i8> %4989, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4991 = bitcast <2 x i64> %4988 to <16 x i8>
  %4992 = shufflevector <16 x i8> %4991, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %4993 = bitcast <16 x i8> %4990 to <4 x i32>
  %4994 = bitcast <16 x i8> %4992 to <4 x i32>
  %4995 = shufflevector <4 x i32> %4993, <4 x i32> %4994, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %4996 = bitcast <4 x i32> %4995 to <2 x i64>
  %4997 = shufflevector <4 x i32> %4993, <4 x i32> %4994, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %4998 = bitcast <4 x i32> %4997 to <2 x i64>
  %4999 = shufflevector <2 x i64> %4996, <2 x i64> %4998, <2 x i32> <i32 0, i32 2>
  %5000 = shl <2 x i64> %4939, <i64 32, i64 32>
  %5001 = ashr exact <2 x i64> %5000, <i64 28, i64 28>
  %5002 = add <2 x i64> %5001, %4885
  %5003 = bitcast <4 x i32> %4938 to <16 x i8>
  %5004 = shufflevector <16 x i8> %5003, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5005 = bitcast <16 x i8> %5004 to <2 x i64>
  %5006 = shl <2 x i64> %5005, <i64 32, i64 32>
  %5007 = ashr exact <2 x i64> %5006, <i64 28, i64 28>
  %5008 = add <2 x i64> %5007, %4885
  %5009 = bitcast <2 x i64> %5002 to <16 x i8>
  %5010 = shufflevector <16 x i8> %5009, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5011 = bitcast <2 x i64> %5008 to <16 x i8>
  %5012 = shufflevector <16 x i8> %5011, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5013 = bitcast <16 x i8> %5010 to <4 x i32>
  %5014 = bitcast <16 x i8> %5012 to <4 x i32>
  %5015 = shufflevector <4 x i32> %5013, <4 x i32> %5014, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5016 = bitcast <4 x i32> %5015 to <2 x i64>
  %5017 = shufflevector <4 x i32> %5013, <4 x i32> %5014, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5018 = bitcast <4 x i32> %5017 to <2 x i64>
  %5019 = shufflevector <2 x i64> %5016, <2 x i64> %5018, <2 x i32> <i32 0, i32 2>
  %5020 = bitcast <2 x i64> %4959 to <4 x i32>
  %5021 = bitcast <2 x i64> %4979 to <4 x i32>
  %5022 = bitcast <2 x i64> %4999 to <4 x i32>
  %5023 = bitcast <2 x i64> %5019 to <4 x i32>
  %5024 = icmp sgt i32 %4, 10
  %5025 = select i1 %5024, i32 %4, i32 10
  %5026 = shl i32 32, %5025
  %5027 = sub nsw i32 0, %5026
  %5028 = insertelement <4 x i32> undef, i32 %5027, i32 0
  %5029 = shufflevector <4 x i32> %5028, <4 x i32> undef, <4 x i32> zeroinitializer
  %5030 = add nsw i32 %5026, -1
  %5031 = insertelement <4 x i32> undef, i32 %5030, i32 0
  %5032 = shufflevector <4 x i32> %5031, <4 x i32> undef, <4 x i32> zeroinitializer
  %5033 = icmp slt <4 x i32> %5029, %5020
  %5034 = select <4 x i1> %5033, <4 x i32> %5020, <4 x i32> %5029
  %5035 = icmp slt <4 x i32> %5034, %5032
  %5036 = select <4 x i1> %5035, <4 x i32> %5034, <4 x i32> %5032
  %5037 = bitcast <4 x i32> %5036 to <2 x i64>
  %5038 = icmp slt <4 x i32> %5029, %5021
  %5039 = select <4 x i1> %5038, <4 x i32> %5021, <4 x i32> %5029
  %5040 = icmp slt <4 x i32> %5039, %5032
  %5041 = select <4 x i1> %5040, <4 x i32> %5039, <4 x i32> %5032
  %5042 = bitcast <4 x i32> %5041 to <2 x i64>
  %5043 = icmp slt <4 x i32> %5029, %5022
  %5044 = select <4 x i1> %5043, <4 x i32> %5022, <4 x i32> %5029
  %5045 = icmp slt <4 x i32> %5044, %5032
  %5046 = select <4 x i1> %5045, <4 x i32> %5044, <4 x i32> %5032
  %5047 = bitcast <4 x i32> %5046 to <2 x i64>
  %5048 = icmp slt <4 x i32> %5029, %5023
  %5049 = select <4 x i1> %5048, <4 x i32> %5023, <4 x i32> %5029
  %5050 = icmp slt <4 x i32> %5049, %5032
  %5051 = select <4 x i1> %5050, <4 x i32> %5049, <4 x i32> %5032
  %5052 = bitcast <4 x i32> %5051 to <2 x i64>
  %5053 = shl <2 x i64> %5037, <i64 32, i64 32>
  %5054 = ashr exact <2 x i64> %5053, <i64 32, i64 32>
  %5055 = mul nsw <2 x i64> %5054, <i64 5793, i64 5793>
  %5056 = bitcast <2 x i64> %5055 to <4 x i32>
  %5057 = add <4 x i32> %5056, <i32 2048, i32 0, i32 2048, i32 0>
  %5058 = bitcast <4 x i32> %5057 to <2 x i64>
  %5059 = lshr <2 x i64> %5058, <i64 12, i64 12>
  %5060 = bitcast <4 x i32> %5036 to <16 x i8>
  %5061 = shufflevector <16 x i8> %5060, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5062 = bitcast <16 x i8> %5061 to <2 x i64>
  %5063 = shl <2 x i64> %5062, <i64 32, i64 32>
  %5064 = ashr exact <2 x i64> %5063, <i64 32, i64 32>
  %5065 = mul nsw <2 x i64> %5064, <i64 5793, i64 5793>
  %5066 = bitcast <2 x i64> %5065 to <4 x i32>
  %5067 = add <4 x i32> %5066, <i32 2048, i32 0, i32 2048, i32 0>
  %5068 = bitcast <4 x i32> %5067 to <2 x i64>
  %5069 = lshr <2 x i64> %5068, <i64 12, i64 12>
  %5070 = bitcast <2 x i64> %5059 to <4 x i32>
  %5071 = bitcast <2 x i64> %5069 to <4 x i32>
  %5072 = shufflevector <4 x i32> %5070, <4 x i32> %5071, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5073 = bitcast <4 x i32> %5072 to <2 x i64>
  %5074 = shufflevector <4 x i32> %5070, <4 x i32> %5071, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5075 = bitcast <4 x i32> %5074 to <2 x i64>
  %5076 = shufflevector <2 x i64> %5073, <2 x i64> %5075, <2 x i32> <i32 0, i32 2>
  %5077 = shl <2 x i64> %5042, <i64 32, i64 32>
  %5078 = ashr exact <2 x i64> %5077, <i64 32, i64 32>
  %5079 = mul nsw <2 x i64> %5078, <i64 5793, i64 5793>
  %5080 = bitcast <2 x i64> %5079 to <4 x i32>
  %5081 = add <4 x i32> %5080, <i32 2048, i32 0, i32 2048, i32 0>
  %5082 = bitcast <4 x i32> %5081 to <2 x i64>
  %5083 = lshr <2 x i64> %5082, <i64 12, i64 12>
  %5084 = bitcast <4 x i32> %5041 to <16 x i8>
  %5085 = shufflevector <16 x i8> %5084, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5086 = bitcast <16 x i8> %5085 to <2 x i64>
  %5087 = shl <2 x i64> %5086, <i64 32, i64 32>
  %5088 = ashr exact <2 x i64> %5087, <i64 32, i64 32>
  %5089 = mul nsw <2 x i64> %5088, <i64 5793, i64 5793>
  %5090 = bitcast <2 x i64> %5089 to <4 x i32>
  %5091 = add <4 x i32> %5090, <i32 2048, i32 0, i32 2048, i32 0>
  %5092 = bitcast <4 x i32> %5091 to <2 x i64>
  %5093 = lshr <2 x i64> %5092, <i64 12, i64 12>
  %5094 = bitcast <2 x i64> %5083 to <4 x i32>
  %5095 = bitcast <2 x i64> %5093 to <4 x i32>
  %5096 = shufflevector <4 x i32> %5094, <4 x i32> %5095, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5097 = bitcast <4 x i32> %5096 to <2 x i64>
  %5098 = shufflevector <4 x i32> %5094, <4 x i32> %5095, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5099 = bitcast <4 x i32> %5098 to <2 x i64>
  %5100 = shufflevector <2 x i64> %5097, <2 x i64> %5099, <2 x i32> <i32 0, i32 2>
  %5101 = shl <2 x i64> %5047, <i64 32, i64 32>
  %5102 = ashr exact <2 x i64> %5101, <i64 32, i64 32>
  %5103 = mul nsw <2 x i64> %5102, <i64 5793, i64 5793>
  %5104 = bitcast <2 x i64> %5103 to <4 x i32>
  %5105 = add <4 x i32> %5104, <i32 2048, i32 0, i32 2048, i32 0>
  %5106 = bitcast <4 x i32> %5105 to <2 x i64>
  %5107 = lshr <2 x i64> %5106, <i64 12, i64 12>
  %5108 = bitcast <4 x i32> %5046 to <16 x i8>
  %5109 = shufflevector <16 x i8> %5108, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5110 = bitcast <16 x i8> %5109 to <2 x i64>
  %5111 = shl <2 x i64> %5110, <i64 32, i64 32>
  %5112 = ashr exact <2 x i64> %5111, <i64 32, i64 32>
  %5113 = mul nsw <2 x i64> %5112, <i64 5793, i64 5793>
  %5114 = bitcast <2 x i64> %5113 to <4 x i32>
  %5115 = add <4 x i32> %5114, <i32 2048, i32 0, i32 2048, i32 0>
  %5116 = bitcast <4 x i32> %5115 to <2 x i64>
  %5117 = lshr <2 x i64> %5116, <i64 12, i64 12>
  %5118 = bitcast <2 x i64> %5107 to <4 x i32>
  %5119 = bitcast <2 x i64> %5117 to <4 x i32>
  %5120 = shufflevector <4 x i32> %5118, <4 x i32> %5119, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5121 = bitcast <4 x i32> %5120 to <2 x i64>
  %5122 = shufflevector <4 x i32> %5118, <4 x i32> %5119, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5123 = bitcast <4 x i32> %5122 to <2 x i64>
  %5124 = shufflevector <2 x i64> %5121, <2 x i64> %5123, <2 x i32> <i32 0, i32 2>
  %5125 = shl <2 x i64> %5052, <i64 32, i64 32>
  %5126 = ashr exact <2 x i64> %5125, <i64 32, i64 32>
  %5127 = mul nsw <2 x i64> %5126, <i64 5793, i64 5793>
  %5128 = bitcast <2 x i64> %5127 to <4 x i32>
  %5129 = add <4 x i32> %5128, <i32 2048, i32 0, i32 2048, i32 0>
  %5130 = bitcast <4 x i32> %5129 to <2 x i64>
  %5131 = lshr <2 x i64> %5130, <i64 12, i64 12>
  %5132 = bitcast <4 x i32> %5051 to <16 x i8>
  %5133 = shufflevector <16 x i8> %5132, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5134 = bitcast <16 x i8> %5133 to <2 x i64>
  %5135 = shl <2 x i64> %5134, <i64 32, i64 32>
  %5136 = ashr exact <2 x i64> %5135, <i64 32, i64 32>
  %5137 = mul nsw <2 x i64> %5136, <i64 5793, i64 5793>
  %5138 = bitcast <2 x i64> %5137 to <4 x i32>
  %5139 = add <4 x i32> %5138, <i32 2048, i32 0, i32 2048, i32 0>
  %5140 = bitcast <4 x i32> %5139 to <2 x i64>
  %5141 = lshr <2 x i64> %5140, <i64 12, i64 12>
  %5142 = bitcast <2 x i64> %5131 to <4 x i32>
  %5143 = bitcast <2 x i64> %5141 to <4 x i32>
  %5144 = shufflevector <4 x i32> %5142, <4 x i32> %5143, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5145 = bitcast <4 x i32> %5144 to <2 x i64>
  %5146 = shufflevector <4 x i32> %5142, <4 x i32> %5143, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5147 = bitcast <4 x i32> %5146 to <2 x i64>
  %5148 = shufflevector <2 x i64> %5145, <2 x i64> %5147, <2 x i32> <i32 0, i32 2>
  %5149 = bitcast <2 x i64> %5100 to <4 x i32>
  %5150 = bitcast <2 x i64> %5124 to <4 x i32>
  %5151 = bitcast <2 x i64> %5148 to <4 x i32>
  %5152 = bitcast <2 x i64> %5076 to <4 x i32>
  %5153 = shufflevector <4 x i32> %5152, <4 x i32> %5149, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5154 = bitcast <4 x i32> %5153 to <2 x i64>
  %5155 = shufflevector <4 x i32> %5152, <4 x i32> %5149, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5156 = bitcast <4 x i32> %5155 to <2 x i64>
  %5157 = shufflevector <4 x i32> %5150, <4 x i32> %5151, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5158 = bitcast <4 x i32> %5157 to <2 x i64>
  %5159 = shufflevector <4 x i32> %5150, <4 x i32> %5151, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5160 = bitcast <4 x i32> %5159 to <2 x i64>
  %5161 = shufflevector <2 x i64> %5154, <2 x i64> %5158, <2 x i32> <i32 0, i32 2>
  %5162 = shufflevector <2 x i64> %5154, <2 x i64> %5158, <2 x i32> <i32 1, i32 3>
  %5163 = shufflevector <2 x i64> %5156, <2 x i64> %5160, <2 x i32> <i32 0, i32 2>
  %5164 = shufflevector <2 x i64> %5156, <2 x i64> %5160, <2 x i32> <i32 1, i32 3>
  %5165 = getelementptr inbounds i8, i8* %6, i64 1
  %5166 = load i8, i8* %5165, align 1
  %5167 = sext i8 %5166 to i32
  %5168 = sub nsw i32 0, %5167
  %5169 = icmp eq i8 %5166, 0
  br i1 %5169, label %5191, label %5170

5170:                                             ; preds = %4864
  %5171 = xor i32 %5167, -1
  %5172 = shl i32 1, %5171
  %5173 = insertelement <4 x i32> undef, i32 %5172, i32 0
  %5174 = shufflevector <4 x i32> %5173, <4 x i32> undef, <4 x i32> zeroinitializer
  %5175 = bitcast <2 x i64> %5161 to <4 x i32>
  %5176 = add <4 x i32> %5174, %5175
  %5177 = bitcast <2 x i64> %5162 to <4 x i32>
  %5178 = add <4 x i32> %5174, %5177
  %5179 = bitcast <2 x i64> %5163 to <4 x i32>
  %5180 = add <4 x i32> %5174, %5179
  %5181 = bitcast <2 x i64> %5164 to <4 x i32>
  %5182 = add <4 x i32> %5174, %5181
  %5183 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %5176, i32 %5168) #8
  %5184 = bitcast <4 x i32> %5183 to <2 x i64>
  %5185 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %5178, i32 %5168) #8
  %5186 = bitcast <4 x i32> %5185 to <2 x i64>
  %5187 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %5180, i32 %5168) #8
  %5188 = bitcast <4 x i32> %5187 to <2 x i64>
  %5189 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %5182, i32 %5168) #8
  %5190 = bitcast <4 x i32> %5189 to <2 x i64>
  br label %5191

5191:                                             ; preds = %4864, %5170
  %5192 = phi <2 x i64> [ %5164, %4864 ], [ %5190, %5170 ]
  %5193 = phi <2 x i64> [ %5163, %4864 ], [ %5188, %5170 ]
  %5194 = phi <2 x i64> [ %5162, %4864 ], [ %5186, %5170 ]
  %5195 = phi <2 x i64> [ %5161, %4864 ], [ %5184, %5170 ]
  %5196 = bitcast i16* %1 to i64*
  %5197 = load i64, i64* %5196, align 1
  %5198 = insertelement <2 x i64> undef, i64 %5197, i32 0
  %5199 = sext i32 %2 to i64
  %5200 = getelementptr inbounds i16, i16* %1, i64 %5199
  %5201 = bitcast i16* %5200 to i64*
  %5202 = load i64, i64* %5201, align 1
  %5203 = insertelement <2 x i64> undef, i64 %5202, i32 0
  %5204 = shl nsw i32 %2, 1
  %5205 = sext i32 %5204 to i64
  %5206 = getelementptr inbounds i16, i16* %1, i64 %5205
  %5207 = bitcast i16* %5206 to i64*
  %5208 = load i64, i64* %5207, align 1
  %5209 = insertelement <2 x i64> undef, i64 %5208, i32 0
  %5210 = mul nsw i32 %2, 3
  %5211 = sext i32 %5210 to i64
  %5212 = getelementptr inbounds i16, i16* %1, i64 %5211
  %5213 = bitcast i16* %5212 to i64*
  %5214 = load i64, i64* %5213, align 1
  %5215 = insertelement <2 x i64> undef, i64 %5214, i32 0
  %5216 = bitcast <2 x i64> %5198 to <8 x i16>
  %5217 = shufflevector <8 x i16> %5216, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5218 = bitcast <2 x i64> %5203 to <8 x i16>
  %5219 = shufflevector <8 x i16> %5218, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5220 = bitcast <2 x i64> %5209 to <8 x i16>
  %5221 = shufflevector <8 x i16> %5220, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5222 = bitcast <2 x i64> %5215 to <8 x i16>
  %5223 = shufflevector <8 x i16> %5222, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5224 = bitcast <2 x i64> %5195 to <4 x i32>
  %5225 = bitcast <8 x i16> %5217 to <4 x i32>
  %5226 = add <4 x i32> %5225, %5224
  %5227 = bitcast <2 x i64> %5194 to <4 x i32>
  %5228 = bitcast <8 x i16> %5219 to <4 x i32>
  %5229 = add <4 x i32> %5228, %5227
  %5230 = bitcast <2 x i64> %5193 to <4 x i32>
  %5231 = bitcast <8 x i16> %5221 to <4 x i32>
  %5232 = add <4 x i32> %5231, %5230
  %5233 = bitcast <2 x i64> %5192 to <4 x i32>
  %5234 = bitcast <8 x i16> %5223 to <4 x i32>
  %5235 = add <4 x i32> %5234, %5233
  %5236 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %5226, <4 x i32> %5229) #8
  %5237 = bitcast <8 x i16> %5236 to <2 x i64>
  %5238 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %5232, <4 x i32> %5235) #8
  %5239 = bitcast <8 x i16> %5238 to <2 x i64>
  %5240 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %5241 = add <8 x i16> %5240, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %5242 = icmp slt <8 x i16> %5241, %5236
  %5243 = sext <8 x i1> %5242 to <8 x i16>
  %5244 = bitcast <8 x i16> %5243 to <2 x i64>
  %5245 = xor <2 x i64> %5244, <i64 -1, i64 -1>
  %5246 = and <2 x i64> %5245, %5237
  %5247 = and <8 x i16> %5241, %5243
  %5248 = bitcast <8 x i16> %5247 to <2 x i64>
  %5249 = or <2 x i64> %5246, %5248
  %5250 = bitcast <2 x i64> %5249 to <8 x i16>
  %5251 = icmp sgt <8 x i16> %5250, zeroinitializer
  %5252 = sext <8 x i1> %5251 to <8 x i16>
  %5253 = bitcast <8 x i16> %5252 to <2 x i64>
  %5254 = and <2 x i64> %5249, %5253
  %5255 = icmp slt <8 x i16> %5241, %5238
  %5256 = sext <8 x i1> %5255 to <8 x i16>
  %5257 = bitcast <8 x i16> %5256 to <2 x i64>
  %5258 = xor <2 x i64> %5257, <i64 -1, i64 -1>
  %5259 = and <2 x i64> %5258, %5239
  %5260 = and <8 x i16> %5241, %5256
  br label %6055

5261:                                             ; preds = %5
  %5262 = bitcast i32* %0 to <2 x i64>*
  %5263 = load <2 x i64>, <2 x i64>* %5262, align 16
  %5264 = getelementptr inbounds i32, i32* %0, i64 4
  %5265 = bitcast i32* %5264 to <2 x i64>*
  %5266 = load <2 x i64>, <2 x i64>* %5265, align 16
  %5267 = getelementptr inbounds i32, i32* %0, i64 8
  %5268 = bitcast i32* %5267 to <2 x i64>*
  %5269 = load <2 x i64>, <2 x i64>* %5268, align 16
  %5270 = getelementptr inbounds i32, i32* %0, i64 12
  %5271 = bitcast i32* %5270 to <2 x i64>*
  %5272 = load <2 x i64>, <2 x i64>* %5271, align 16
  %5273 = shl <2 x i64> %5263, <i64 32, i64 32>
  %5274 = ashr exact <2 x i64> %5273, <i64 32, i64 32>
  %5275 = mul nsw <2 x i64> %5274, <i64 5793, i64 5793>
  %5276 = bitcast <2 x i64> %5275 to <4 x i32>
  %5277 = add <4 x i32> %5276, <i32 2048, i32 0, i32 2048, i32 0>
  %5278 = bitcast <4 x i32> %5277 to <2 x i64>
  %5279 = lshr <2 x i64> %5278, <i64 12, i64 12>
  %5280 = bitcast <2 x i64> %5263 to <16 x i8>
  %5281 = shufflevector <16 x i8> %5280, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5282 = bitcast <16 x i8> %5281 to <2 x i64>
  %5283 = shl <2 x i64> %5282, <i64 32, i64 32>
  %5284 = ashr exact <2 x i64> %5283, <i64 32, i64 32>
  %5285 = mul nsw <2 x i64> %5284, <i64 5793, i64 5793>
  %5286 = bitcast <2 x i64> %5285 to <4 x i32>
  %5287 = add <4 x i32> %5286, <i32 2048, i32 0, i32 2048, i32 0>
  %5288 = bitcast <4 x i32> %5287 to <2 x i64>
  %5289 = lshr <2 x i64> %5288, <i64 12, i64 12>
  %5290 = bitcast <2 x i64> %5279 to <4 x i32>
  %5291 = bitcast <2 x i64> %5289 to <4 x i32>
  %5292 = shufflevector <4 x i32> %5290, <4 x i32> %5291, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5293 = bitcast <4 x i32> %5292 to <2 x i64>
  %5294 = shufflevector <4 x i32> %5290, <4 x i32> %5291, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5295 = bitcast <4 x i32> %5294 to <2 x i64>
  %5296 = shufflevector <2 x i64> %5293, <2 x i64> %5295, <2 x i32> <i32 0, i32 2>
  %5297 = shl <2 x i64> %5266, <i64 32, i64 32>
  %5298 = ashr exact <2 x i64> %5297, <i64 32, i64 32>
  %5299 = mul nsw <2 x i64> %5298, <i64 5793, i64 5793>
  %5300 = bitcast <2 x i64> %5299 to <4 x i32>
  %5301 = add <4 x i32> %5300, <i32 2048, i32 0, i32 2048, i32 0>
  %5302 = bitcast <4 x i32> %5301 to <2 x i64>
  %5303 = lshr <2 x i64> %5302, <i64 12, i64 12>
  %5304 = bitcast <2 x i64> %5266 to <16 x i8>
  %5305 = shufflevector <16 x i8> %5304, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5306 = bitcast <16 x i8> %5305 to <2 x i64>
  %5307 = shl <2 x i64> %5306, <i64 32, i64 32>
  %5308 = ashr exact <2 x i64> %5307, <i64 32, i64 32>
  %5309 = mul nsw <2 x i64> %5308, <i64 5793, i64 5793>
  %5310 = bitcast <2 x i64> %5309 to <4 x i32>
  %5311 = add <4 x i32> %5310, <i32 2048, i32 0, i32 2048, i32 0>
  %5312 = bitcast <4 x i32> %5311 to <2 x i64>
  %5313 = lshr <2 x i64> %5312, <i64 12, i64 12>
  %5314 = bitcast <2 x i64> %5303 to <4 x i32>
  %5315 = bitcast <2 x i64> %5313 to <4 x i32>
  %5316 = shufflevector <4 x i32> %5314, <4 x i32> %5315, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5317 = bitcast <4 x i32> %5316 to <2 x i64>
  %5318 = shufflevector <4 x i32> %5314, <4 x i32> %5315, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5319 = bitcast <4 x i32> %5318 to <2 x i64>
  %5320 = shufflevector <2 x i64> %5317, <2 x i64> %5319, <2 x i32> <i32 0, i32 2>
  %5321 = shl <2 x i64> %5269, <i64 32, i64 32>
  %5322 = ashr exact <2 x i64> %5321, <i64 32, i64 32>
  %5323 = mul nsw <2 x i64> %5322, <i64 5793, i64 5793>
  %5324 = bitcast <2 x i64> %5323 to <4 x i32>
  %5325 = add <4 x i32> %5324, <i32 2048, i32 0, i32 2048, i32 0>
  %5326 = bitcast <4 x i32> %5325 to <2 x i64>
  %5327 = lshr <2 x i64> %5326, <i64 12, i64 12>
  %5328 = bitcast <2 x i64> %5269 to <16 x i8>
  %5329 = shufflevector <16 x i8> %5328, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5330 = bitcast <16 x i8> %5329 to <2 x i64>
  %5331 = shl <2 x i64> %5330, <i64 32, i64 32>
  %5332 = ashr exact <2 x i64> %5331, <i64 32, i64 32>
  %5333 = mul nsw <2 x i64> %5332, <i64 5793, i64 5793>
  %5334 = bitcast <2 x i64> %5333 to <4 x i32>
  %5335 = add <4 x i32> %5334, <i32 2048, i32 0, i32 2048, i32 0>
  %5336 = bitcast <4 x i32> %5335 to <2 x i64>
  %5337 = lshr <2 x i64> %5336, <i64 12, i64 12>
  %5338 = bitcast <2 x i64> %5327 to <4 x i32>
  %5339 = bitcast <2 x i64> %5337 to <4 x i32>
  %5340 = shufflevector <4 x i32> %5338, <4 x i32> %5339, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5341 = bitcast <4 x i32> %5340 to <2 x i64>
  %5342 = shufflevector <4 x i32> %5338, <4 x i32> %5339, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5343 = bitcast <4 x i32> %5342 to <2 x i64>
  %5344 = shufflevector <2 x i64> %5341, <2 x i64> %5343, <2 x i32> <i32 0, i32 2>
  %5345 = shl <2 x i64> %5272, <i64 32, i64 32>
  %5346 = ashr exact <2 x i64> %5345, <i64 32, i64 32>
  %5347 = mul nsw <2 x i64> %5346, <i64 5793, i64 5793>
  %5348 = bitcast <2 x i64> %5347 to <4 x i32>
  %5349 = add <4 x i32> %5348, <i32 2048, i32 0, i32 2048, i32 0>
  %5350 = bitcast <4 x i32> %5349 to <2 x i64>
  %5351 = lshr <2 x i64> %5350, <i64 12, i64 12>
  %5352 = bitcast <2 x i64> %5272 to <16 x i8>
  %5353 = shufflevector <16 x i8> %5352, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5354 = bitcast <16 x i8> %5353 to <2 x i64>
  %5355 = shl <2 x i64> %5354, <i64 32, i64 32>
  %5356 = ashr exact <2 x i64> %5355, <i64 32, i64 32>
  %5357 = mul nsw <2 x i64> %5356, <i64 5793, i64 5793>
  %5358 = bitcast <2 x i64> %5357 to <4 x i32>
  %5359 = add <4 x i32> %5358, <i32 2048, i32 0, i32 2048, i32 0>
  %5360 = bitcast <4 x i32> %5359 to <2 x i64>
  %5361 = lshr <2 x i64> %5360, <i64 12, i64 12>
  %5362 = bitcast <2 x i64> %5351 to <4 x i32>
  %5363 = bitcast <2 x i64> %5361 to <4 x i32>
  %5364 = shufflevector <4 x i32> %5362, <4 x i32> %5363, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5365 = bitcast <4 x i32> %5364 to <2 x i64>
  %5366 = shufflevector <4 x i32> %5362, <4 x i32> %5363, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5367 = bitcast <4 x i32> %5366 to <2 x i64>
  %5368 = shufflevector <2 x i64> %5365, <2 x i64> %5367, <2 x i32> <i32 0, i32 2>
  %5369 = bitcast <2 x i64> %5320 to <4 x i32>
  %5370 = bitcast <2 x i64> %5344 to <4 x i32>
  %5371 = bitcast <2 x i64> %5368 to <4 x i32>
  %5372 = icmp sgt i32 %4, 10
  %5373 = select i1 %5372, i32 %4, i32 10
  %5374 = shl i32 32, %5373
  %5375 = sub nsw i32 0, %5374
  %5376 = insertelement <4 x i32> undef, i32 %5375, i32 0
  %5377 = shufflevector <4 x i32> %5376, <4 x i32> undef, <4 x i32> zeroinitializer
  %5378 = add nsw i32 %5374, -1
  %5379 = insertelement <4 x i32> undef, i32 %5378, i32 0
  %5380 = shufflevector <4 x i32> %5379, <4 x i32> undef, <4 x i32> zeroinitializer
  %5381 = bitcast <2 x i64> %5296 to <4 x i32>
  %5382 = icmp slt <4 x i32> %5377, %5381
  %5383 = select <4 x i1> %5382, <4 x i32> %5381, <4 x i32> %5377
  %5384 = icmp slt <4 x i32> %5383, %5380
  %5385 = select <4 x i1> %5384, <4 x i32> %5383, <4 x i32> %5380
  %5386 = icmp slt <4 x i32> %5377, %5369
  %5387 = select <4 x i1> %5386, <4 x i32> %5369, <4 x i32> %5377
  %5388 = icmp slt <4 x i32> %5387, %5380
  %5389 = select <4 x i1> %5388, <4 x i32> %5387, <4 x i32> %5380
  %5390 = icmp slt <4 x i32> %5377, %5370
  %5391 = select <4 x i1> %5390, <4 x i32> %5370, <4 x i32> %5377
  %5392 = icmp slt <4 x i32> %5391, %5380
  %5393 = select <4 x i1> %5392, <4 x i32> %5391, <4 x i32> %5380
  %5394 = icmp slt <4 x i32> %5377, %5371
  %5395 = select <4 x i1> %5394, <4 x i32> %5371, <4 x i32> %5377
  %5396 = icmp slt <4 x i32> %5395, %5380
  %5397 = select <4 x i1> %5396, <4 x i32> %5395, <4 x i32> %5380
  %5398 = shufflevector <4 x i32> %5385, <4 x i32> %5389, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5399 = bitcast <4 x i32> %5398 to <2 x i64>
  %5400 = shufflevector <4 x i32> %5385, <4 x i32> %5389, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5401 = bitcast <4 x i32> %5400 to <2 x i64>
  %5402 = shufflevector <4 x i32> %5393, <4 x i32> %5397, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5403 = bitcast <4 x i32> %5402 to <2 x i64>
  %5404 = shufflevector <4 x i32> %5393, <4 x i32> %5397, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5405 = bitcast <4 x i32> %5404 to <2 x i64>
  %5406 = shufflevector <2 x i64> %5399, <2 x i64> %5403, <2 x i32> <i32 0, i32 2>
  %5407 = shufflevector <2 x i64> %5399, <2 x i64> %5403, <2 x i32> <i32 1, i32 3>
  %5408 = shufflevector <2 x i64> %5401, <2 x i64> %5405, <2 x i32> <i32 0, i32 2>
  %5409 = shufflevector <2 x i64> %5401, <2 x i64> %5405, <2 x i32> <i32 1, i32 3>
  %5410 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 0, i64 0), align 16
  %5411 = sext i8 %5410 to i32
  %5412 = add nsw i32 %5411, -10
  %5413 = sext i32 %5412 to i64
  %5414 = add nsw i32 %5411, 3
  %5415 = shl i32 1, %5414
  %5416 = insertelement <4 x i32> undef, i32 %5415, i32 0
  %5417 = shufflevector <4 x i32> %5416, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %5418 = shufflevector <4 x i32> %5417, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5419 = bitcast <4 x i32> %5418 to <2 x i64>
  %5420 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %5413, i64 1
  %5421 = load i32, i32* %5420, align 4
  %5422 = insertelement <4 x i32> undef, i32 %5421, i32 0
  %5423 = shufflevector <4 x i32> %5422, <4 x i32> undef, <4 x i32> zeroinitializer
  %5424 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %5413, i64 2
  %5425 = load i32, i32* %5424, align 4
  %5426 = insertelement <4 x i32> undef, i32 %5425, i32 0
  %5427 = shufflevector <4 x i32> %5426, <4 x i32> undef, <4 x i32> zeroinitializer
  %5428 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %5413, i64 3
  %5429 = load i32, i32* %5428, align 4
  %5430 = insertelement <4 x i32> undef, i32 %5429, i32 0
  %5431 = shufflevector <4 x i32> %5430, <4 x i32> undef, <4 x i32> zeroinitializer
  %5432 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %5413, i64 4
  %5433 = load i32, i32* %5432, align 4
  %5434 = insertelement <4 x i32> undef, i32 %5433, i32 0
  %5435 = shufflevector <4 x i32> %5434, <4 x i32> undef, <4 x i32> zeroinitializer
  %5436 = bitcast <2 x i64> %5406 to <4 x i32>
  %5437 = bitcast <2 x i64> %5407 to <4 x i32>
  %5438 = shufflevector <4 x i32> %5436, <4 x i32> %5437, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5439 = bitcast <4 x i32> %5438 to <2 x i64>
  %5440 = shufflevector <4 x i32> %5436, <4 x i32> %5437, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5441 = bitcast <4 x i32> %5440 to <2 x i64>
  %5442 = bitcast <2 x i64> %5408 to <4 x i32>
  %5443 = bitcast <2 x i64> %5409 to <4 x i32>
  %5444 = shufflevector <4 x i32> %5442, <4 x i32> %5443, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5445 = bitcast <4 x i32> %5444 to <2 x i64>
  %5446 = shufflevector <4 x i32> %5442, <4 x i32> %5443, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5447 = bitcast <4 x i32> %5446 to <2 x i64>
  %5448 = shufflevector <2 x i64> %5439, <2 x i64> %5445, <2 x i32> <i32 0, i32 2>
  %5449 = shufflevector <2 x i64> %5439, <2 x i64> %5445, <2 x i32> <i32 1, i32 3>
  %5450 = shufflevector <2 x i64> %5441, <2 x i64> %5447, <2 x i32> <i32 0, i32 2>
  %5451 = shufflevector <2 x i64> %5441, <2 x i64> %5447, <2 x i32> <i32 1, i32 3>
  %5452 = bitcast <2 x i64> %5448 to <4 x i32>
  %5453 = mul <4 x i32> %5423, %5452
  %5454 = mul <4 x i32> %5427, %5452
  %5455 = bitcast <2 x i64> %5449 to <4 x i32>
  %5456 = mul <4 x i32> %5431, %5455
  %5457 = bitcast <2 x i64> %5450 to <4 x i32>
  %5458 = mul <4 x i32> %5435, %5457
  %5459 = mul <4 x i32> %5423, %5457
  %5460 = bitcast <2 x i64> %5451 to <4 x i32>
  %5461 = mul <4 x i32> %5427, %5460
  %5462 = sub <4 x i32> %5452, %5457
  %5463 = add <4 x i32> %5462, %5460
  %5464 = add <4 x i32> %5458, %5453
  %5465 = add <4 x i32> %5464, %5461
  %5466 = sub <4 x i32> %5454, %5459
  %5467 = mul <4 x i32> %5435, %5460
  %5468 = sub <4 x i32> %5466, %5467
  %5469 = mul <4 x i32> %5463, %5431
  %5470 = bitcast <4 x i32> %5469 to <2 x i64>
  %5471 = add <4 x i32> %5465, %5456
  %5472 = bitcast <4 x i32> %5471 to <2 x i64>
  %5473 = add <4 x i32> %5468, %5456
  %5474 = bitcast <4 x i32> %5473 to <2 x i64>
  %5475 = sub <4 x i32> %5465, %5456
  %5476 = add <4 x i32> %5475, %5468
  %5477 = bitcast <4 x i32> %5476 to <2 x i64>
  %5478 = shl <2 x i64> %5472, <i64 32, i64 32>
  %5479 = ashr exact <2 x i64> %5478, <i64 28, i64 28>
  %5480 = add <2 x i64> %5479, %5419
  %5481 = bitcast <4 x i32> %5471 to <16 x i8>
  %5482 = shufflevector <16 x i8> %5481, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5483 = bitcast <16 x i8> %5482 to <2 x i64>
  %5484 = shl <2 x i64> %5483, <i64 32, i64 32>
  %5485 = ashr exact <2 x i64> %5484, <i64 28, i64 28>
  %5486 = add <2 x i64> %5485, %5419
  %5487 = bitcast <2 x i64> %5480 to <16 x i8>
  %5488 = shufflevector <16 x i8> %5487, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5489 = bitcast <2 x i64> %5486 to <16 x i8>
  %5490 = shufflevector <16 x i8> %5489, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5491 = bitcast <16 x i8> %5488 to <4 x i32>
  %5492 = bitcast <16 x i8> %5490 to <4 x i32>
  %5493 = shufflevector <4 x i32> %5491, <4 x i32> %5492, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5494 = bitcast <4 x i32> %5493 to <2 x i64>
  %5495 = shufflevector <4 x i32> %5491, <4 x i32> %5492, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5496 = bitcast <4 x i32> %5495 to <2 x i64>
  %5497 = shufflevector <2 x i64> %5494, <2 x i64> %5496, <2 x i32> <i32 0, i32 2>
  %5498 = shl <2 x i64> %5474, <i64 32, i64 32>
  %5499 = ashr exact <2 x i64> %5498, <i64 28, i64 28>
  %5500 = add <2 x i64> %5499, %5419
  %5501 = bitcast <4 x i32> %5473 to <16 x i8>
  %5502 = shufflevector <16 x i8> %5501, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5503 = bitcast <16 x i8> %5502 to <2 x i64>
  %5504 = shl <2 x i64> %5503, <i64 32, i64 32>
  %5505 = ashr exact <2 x i64> %5504, <i64 28, i64 28>
  %5506 = add <2 x i64> %5505, %5419
  %5507 = bitcast <2 x i64> %5500 to <16 x i8>
  %5508 = shufflevector <16 x i8> %5507, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5509 = bitcast <2 x i64> %5506 to <16 x i8>
  %5510 = shufflevector <16 x i8> %5509, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5511 = bitcast <16 x i8> %5508 to <4 x i32>
  %5512 = bitcast <16 x i8> %5510 to <4 x i32>
  %5513 = shufflevector <4 x i32> %5511, <4 x i32> %5512, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5514 = bitcast <4 x i32> %5513 to <2 x i64>
  %5515 = shufflevector <4 x i32> %5511, <4 x i32> %5512, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5516 = bitcast <4 x i32> %5515 to <2 x i64>
  %5517 = shufflevector <2 x i64> %5514, <2 x i64> %5516, <2 x i32> <i32 0, i32 2>
  %5518 = shl <2 x i64> %5470, <i64 32, i64 32>
  %5519 = ashr exact <2 x i64> %5518, <i64 28, i64 28>
  %5520 = add <2 x i64> %5519, %5419
  %5521 = bitcast <4 x i32> %5469 to <16 x i8>
  %5522 = shufflevector <16 x i8> %5521, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5523 = bitcast <16 x i8> %5522 to <2 x i64>
  %5524 = shl <2 x i64> %5523, <i64 32, i64 32>
  %5525 = ashr exact <2 x i64> %5524, <i64 28, i64 28>
  %5526 = add <2 x i64> %5525, %5419
  %5527 = bitcast <2 x i64> %5520 to <16 x i8>
  %5528 = shufflevector <16 x i8> %5527, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5529 = bitcast <2 x i64> %5526 to <16 x i8>
  %5530 = shufflevector <16 x i8> %5529, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5531 = bitcast <16 x i8> %5528 to <4 x i32>
  %5532 = bitcast <16 x i8> %5530 to <4 x i32>
  %5533 = shufflevector <4 x i32> %5531, <4 x i32> %5532, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5534 = bitcast <4 x i32> %5533 to <2 x i64>
  %5535 = shufflevector <4 x i32> %5531, <4 x i32> %5532, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5536 = bitcast <4 x i32> %5535 to <2 x i64>
  %5537 = shufflevector <2 x i64> %5534, <2 x i64> %5536, <2 x i32> <i32 0, i32 2>
  %5538 = shl <2 x i64> %5477, <i64 32, i64 32>
  %5539 = ashr exact <2 x i64> %5538, <i64 28, i64 28>
  %5540 = add <2 x i64> %5539, %5419
  %5541 = bitcast <4 x i32> %5476 to <16 x i8>
  %5542 = shufflevector <16 x i8> %5541, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5543 = bitcast <16 x i8> %5542 to <2 x i64>
  %5544 = shl <2 x i64> %5543, <i64 32, i64 32>
  %5545 = ashr exact <2 x i64> %5544, <i64 28, i64 28>
  %5546 = add <2 x i64> %5545, %5419
  %5547 = bitcast <2 x i64> %5540 to <16 x i8>
  %5548 = shufflevector <16 x i8> %5547, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5549 = bitcast <2 x i64> %5546 to <16 x i8>
  %5550 = shufflevector <16 x i8> %5549, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5551 = bitcast <16 x i8> %5548 to <4 x i32>
  %5552 = bitcast <16 x i8> %5550 to <4 x i32>
  %5553 = shufflevector <4 x i32> %5551, <4 x i32> %5552, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5554 = bitcast <4 x i32> %5553 to <2 x i64>
  %5555 = shufflevector <4 x i32> %5551, <4 x i32> %5552, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5556 = bitcast <4 x i32> %5555 to <2 x i64>
  %5557 = shufflevector <2 x i64> %5554, <2 x i64> %5556, <2 x i32> <i32 0, i32 2>
  %5558 = getelementptr inbounds i8, i8* %6, i64 1
  %5559 = load i8, i8* %5558, align 1
  %5560 = sext i8 %5559 to i32
  %5561 = sub nsw i32 0, %5560
  %5562 = icmp eq i8 %5559, 0
  br i1 %5562, label %5584, label %5563

5563:                                             ; preds = %5261
  %5564 = xor i32 %5560, -1
  %5565 = shl i32 1, %5564
  %5566 = insertelement <4 x i32> undef, i32 %5565, i32 0
  %5567 = shufflevector <4 x i32> %5566, <4 x i32> undef, <4 x i32> zeroinitializer
  %5568 = bitcast <2 x i64> %5497 to <4 x i32>
  %5569 = add <4 x i32> %5567, %5568
  %5570 = bitcast <2 x i64> %5517 to <4 x i32>
  %5571 = add <4 x i32> %5567, %5570
  %5572 = bitcast <2 x i64> %5537 to <4 x i32>
  %5573 = add <4 x i32> %5567, %5572
  %5574 = bitcast <2 x i64> %5557 to <4 x i32>
  %5575 = add <4 x i32> %5567, %5574
  %5576 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %5569, i32 %5561) #8
  %5577 = bitcast <4 x i32> %5576 to <2 x i64>
  %5578 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %5571, i32 %5561) #8
  %5579 = bitcast <4 x i32> %5578 to <2 x i64>
  %5580 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %5573, i32 %5561) #8
  %5581 = bitcast <4 x i32> %5580 to <2 x i64>
  %5582 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %5575, i32 %5561) #8
  %5583 = bitcast <4 x i32> %5582 to <2 x i64>
  br label %5584

5584:                                             ; preds = %5261, %5563
  %5585 = phi <2 x i64> [ %5557, %5261 ], [ %5583, %5563 ]
  %5586 = phi <2 x i64> [ %5537, %5261 ], [ %5581, %5563 ]
  %5587 = phi <2 x i64> [ %5517, %5261 ], [ %5579, %5563 ]
  %5588 = phi <2 x i64> [ %5497, %5261 ], [ %5577, %5563 ]
  %5589 = bitcast i16* %1 to i64*
  %5590 = load i64, i64* %5589, align 1
  %5591 = insertelement <2 x i64> undef, i64 %5590, i32 0
  %5592 = sext i32 %2 to i64
  %5593 = getelementptr inbounds i16, i16* %1, i64 %5592
  %5594 = bitcast i16* %5593 to i64*
  %5595 = load i64, i64* %5594, align 1
  %5596 = insertelement <2 x i64> undef, i64 %5595, i32 0
  %5597 = shl nsw i32 %2, 1
  %5598 = sext i32 %5597 to i64
  %5599 = getelementptr inbounds i16, i16* %1, i64 %5598
  %5600 = bitcast i16* %5599 to i64*
  %5601 = load i64, i64* %5600, align 1
  %5602 = insertelement <2 x i64> undef, i64 %5601, i32 0
  %5603 = mul nsw i32 %2, 3
  %5604 = sext i32 %5603 to i64
  %5605 = getelementptr inbounds i16, i16* %1, i64 %5604
  %5606 = bitcast i16* %5605 to i64*
  %5607 = load i64, i64* %5606, align 1
  %5608 = insertelement <2 x i64> undef, i64 %5607, i32 0
  %5609 = bitcast <2 x i64> %5591 to <8 x i16>
  %5610 = shufflevector <8 x i16> %5609, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5611 = bitcast <2 x i64> %5596 to <8 x i16>
  %5612 = shufflevector <8 x i16> %5611, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5613 = bitcast <2 x i64> %5602 to <8 x i16>
  %5614 = shufflevector <8 x i16> %5613, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5615 = bitcast <2 x i64> %5608 to <8 x i16>
  %5616 = shufflevector <8 x i16> %5615, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5617 = bitcast <2 x i64> %5585 to <4 x i32>
  %5618 = bitcast <8 x i16> %5610 to <4 x i32>
  %5619 = add <4 x i32> %5618, %5617
  %5620 = bitcast <2 x i64> %5586 to <4 x i32>
  %5621 = bitcast <8 x i16> %5612 to <4 x i32>
  %5622 = add <4 x i32> %5621, %5620
  %5623 = bitcast <2 x i64> %5587 to <4 x i32>
  %5624 = bitcast <8 x i16> %5614 to <4 x i32>
  %5625 = add <4 x i32> %5624, %5623
  %5626 = bitcast <2 x i64> %5588 to <4 x i32>
  %5627 = bitcast <8 x i16> %5616 to <4 x i32>
  %5628 = add <4 x i32> %5627, %5626
  %5629 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %5619, <4 x i32> %5622) #8
  %5630 = bitcast <8 x i16> %5629 to <2 x i64>
  %5631 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %5625, <4 x i32> %5628) #8
  %5632 = bitcast <8 x i16> %5631 to <2 x i64>
  %5633 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %5634 = add <8 x i16> %5633, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %5635 = icmp slt <8 x i16> %5634, %5629
  %5636 = sext <8 x i1> %5635 to <8 x i16>
  %5637 = bitcast <8 x i16> %5636 to <2 x i64>
  %5638 = xor <2 x i64> %5637, <i64 -1, i64 -1>
  %5639 = and <2 x i64> %5638, %5630
  %5640 = and <8 x i16> %5634, %5636
  %5641 = bitcast <8 x i16> %5640 to <2 x i64>
  %5642 = or <2 x i64> %5639, %5641
  %5643 = bitcast <2 x i64> %5642 to <8 x i16>
  %5644 = icmp sgt <8 x i16> %5643, zeroinitializer
  %5645 = sext <8 x i1> %5644 to <8 x i16>
  %5646 = bitcast <8 x i16> %5645 to <2 x i64>
  %5647 = and <2 x i64> %5642, %5646
  %5648 = icmp slt <8 x i16> %5634, %5631
  %5649 = sext <8 x i1> %5648 to <8 x i16>
  %5650 = bitcast <8 x i16> %5649 to <2 x i64>
  %5651 = xor <2 x i64> %5650, <i64 -1, i64 -1>
  %5652 = and <2 x i64> %5651, %5632
  %5653 = and <8 x i16> %5634, %5649
  br label %6055

5654:                                             ; preds = %5
  %5655 = bitcast i32* %0 to <4 x i32>*
  %5656 = load <4 x i32>, <4 x i32>* %5655, align 16
  %5657 = getelementptr inbounds i32, i32* %0, i64 4
  %5658 = bitcast i32* %5657 to <4 x i32>*
  %5659 = load <4 x i32>, <4 x i32>* %5658, align 16
  %5660 = getelementptr inbounds i32, i32* %0, i64 8
  %5661 = bitcast i32* %5660 to <4 x i32>*
  %5662 = load <4 x i32>, <4 x i32>* %5661, align 16
  %5663 = getelementptr inbounds i32, i32* %0, i64 12
  %5664 = bitcast i32* %5663 to <4 x i32>*
  %5665 = load <4 x i32>, <4 x i32>* %5664, align 16
  %5666 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 0, i64 0), align 16
  %5667 = sext i8 %5666 to i32
  %5668 = add nsw i32 %5667, -10
  %5669 = sext i32 %5668 to i64
  %5670 = add nsw i32 %5667, 3
  %5671 = shl i32 1, %5670
  %5672 = insertelement <4 x i32> undef, i32 %5671, i32 0
  %5673 = shufflevector <4 x i32> %5672, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %5674 = shufflevector <4 x i32> %5673, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5675 = bitcast <4 x i32> %5674 to <2 x i64>
  %5676 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %5669, i64 1
  %5677 = load i32, i32* %5676, align 4
  %5678 = insertelement <4 x i32> undef, i32 %5677, i32 0
  %5679 = shufflevector <4 x i32> %5678, <4 x i32> undef, <4 x i32> zeroinitializer
  %5680 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %5669, i64 2
  %5681 = load i32, i32* %5680, align 4
  %5682 = insertelement <4 x i32> undef, i32 %5681, i32 0
  %5683 = shufflevector <4 x i32> %5682, <4 x i32> undef, <4 x i32> zeroinitializer
  %5684 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %5669, i64 3
  %5685 = load i32, i32* %5684, align 4
  %5686 = insertelement <4 x i32> undef, i32 %5685, i32 0
  %5687 = shufflevector <4 x i32> %5686, <4 x i32> undef, <4 x i32> zeroinitializer
  %5688 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %5669, i64 4
  %5689 = load i32, i32* %5688, align 4
  %5690 = insertelement <4 x i32> undef, i32 %5689, i32 0
  %5691 = shufflevector <4 x i32> %5690, <4 x i32> undef, <4 x i32> zeroinitializer
  %5692 = shufflevector <4 x i32> %5656, <4 x i32> %5659, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5693 = bitcast <4 x i32> %5692 to <2 x i64>
  %5694 = shufflevector <4 x i32> %5656, <4 x i32> %5659, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5695 = bitcast <4 x i32> %5694 to <2 x i64>
  %5696 = shufflevector <4 x i32> %5662, <4 x i32> %5665, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5697 = bitcast <4 x i32> %5696 to <2 x i64>
  %5698 = shufflevector <4 x i32> %5662, <4 x i32> %5665, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5699 = bitcast <4 x i32> %5698 to <2 x i64>
  %5700 = shufflevector <2 x i64> %5693, <2 x i64> %5697, <2 x i32> <i32 0, i32 2>
  %5701 = shufflevector <2 x i64> %5693, <2 x i64> %5697, <2 x i32> <i32 1, i32 3>
  %5702 = shufflevector <2 x i64> %5695, <2 x i64> %5699, <2 x i32> <i32 0, i32 2>
  %5703 = shufflevector <2 x i64> %5695, <2 x i64> %5699, <2 x i32> <i32 1, i32 3>
  %5704 = bitcast <2 x i64> %5700 to <4 x i32>
  %5705 = mul <4 x i32> %5679, %5704
  %5706 = mul <4 x i32> %5683, %5704
  %5707 = bitcast <2 x i64> %5701 to <4 x i32>
  %5708 = mul <4 x i32> %5687, %5707
  %5709 = bitcast <2 x i64> %5702 to <4 x i32>
  %5710 = mul <4 x i32> %5691, %5709
  %5711 = mul <4 x i32> %5679, %5709
  %5712 = bitcast <2 x i64> %5703 to <4 x i32>
  %5713 = mul <4 x i32> %5683, %5712
  %5714 = sub <4 x i32> %5704, %5709
  %5715 = add <4 x i32> %5714, %5712
  %5716 = add <4 x i32> %5713, %5705
  %5717 = add <4 x i32> %5716, %5710
  %5718 = sub <4 x i32> %5706, %5711
  %5719 = mul <4 x i32> %5691, %5712
  %5720 = sub <4 x i32> %5718, %5719
  %5721 = mul <4 x i32> %5715, %5687
  %5722 = bitcast <4 x i32> %5721 to <2 x i64>
  %5723 = add <4 x i32> %5717, %5708
  %5724 = bitcast <4 x i32> %5723 to <2 x i64>
  %5725 = add <4 x i32> %5720, %5708
  %5726 = bitcast <4 x i32> %5725 to <2 x i64>
  %5727 = sub <4 x i32> %5717, %5708
  %5728 = add <4 x i32> %5727, %5720
  %5729 = bitcast <4 x i32> %5728 to <2 x i64>
  %5730 = shl <2 x i64> %5724, <i64 32, i64 32>
  %5731 = ashr exact <2 x i64> %5730, <i64 28, i64 28>
  %5732 = add <2 x i64> %5731, %5675
  %5733 = bitcast <4 x i32> %5723 to <16 x i8>
  %5734 = shufflevector <16 x i8> %5733, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5735 = bitcast <16 x i8> %5734 to <2 x i64>
  %5736 = shl <2 x i64> %5735, <i64 32, i64 32>
  %5737 = ashr exact <2 x i64> %5736, <i64 28, i64 28>
  %5738 = add <2 x i64> %5737, %5675
  %5739 = bitcast <2 x i64> %5732 to <16 x i8>
  %5740 = shufflevector <16 x i8> %5739, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5741 = bitcast <2 x i64> %5738 to <16 x i8>
  %5742 = shufflevector <16 x i8> %5741, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5743 = bitcast <16 x i8> %5740 to <4 x i32>
  %5744 = bitcast <16 x i8> %5742 to <4 x i32>
  %5745 = shufflevector <4 x i32> %5743, <4 x i32> %5744, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5746 = bitcast <4 x i32> %5745 to <2 x i64>
  %5747 = shufflevector <4 x i32> %5743, <4 x i32> %5744, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5748 = bitcast <4 x i32> %5747 to <2 x i64>
  %5749 = shufflevector <2 x i64> %5746, <2 x i64> %5748, <2 x i32> <i32 0, i32 2>
  %5750 = shl <2 x i64> %5726, <i64 32, i64 32>
  %5751 = ashr exact <2 x i64> %5750, <i64 28, i64 28>
  %5752 = add <2 x i64> %5751, %5675
  %5753 = bitcast <4 x i32> %5725 to <16 x i8>
  %5754 = shufflevector <16 x i8> %5753, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5755 = bitcast <16 x i8> %5754 to <2 x i64>
  %5756 = shl <2 x i64> %5755, <i64 32, i64 32>
  %5757 = ashr exact <2 x i64> %5756, <i64 28, i64 28>
  %5758 = add <2 x i64> %5757, %5675
  %5759 = bitcast <2 x i64> %5752 to <16 x i8>
  %5760 = shufflevector <16 x i8> %5759, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5761 = bitcast <2 x i64> %5758 to <16 x i8>
  %5762 = shufflevector <16 x i8> %5761, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5763 = bitcast <16 x i8> %5760 to <4 x i32>
  %5764 = bitcast <16 x i8> %5762 to <4 x i32>
  %5765 = shufflevector <4 x i32> %5763, <4 x i32> %5764, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5766 = bitcast <4 x i32> %5765 to <2 x i64>
  %5767 = shufflevector <4 x i32> %5763, <4 x i32> %5764, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5768 = bitcast <4 x i32> %5767 to <2 x i64>
  %5769 = shufflevector <2 x i64> %5766, <2 x i64> %5768, <2 x i32> <i32 0, i32 2>
  %5770 = shl <2 x i64> %5722, <i64 32, i64 32>
  %5771 = ashr exact <2 x i64> %5770, <i64 28, i64 28>
  %5772 = add <2 x i64> %5771, %5675
  %5773 = bitcast <4 x i32> %5721 to <16 x i8>
  %5774 = shufflevector <16 x i8> %5773, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5775 = bitcast <16 x i8> %5774 to <2 x i64>
  %5776 = shl <2 x i64> %5775, <i64 32, i64 32>
  %5777 = ashr exact <2 x i64> %5776, <i64 28, i64 28>
  %5778 = add <2 x i64> %5777, %5675
  %5779 = bitcast <2 x i64> %5772 to <16 x i8>
  %5780 = shufflevector <16 x i8> %5779, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5781 = bitcast <2 x i64> %5778 to <16 x i8>
  %5782 = shufflevector <16 x i8> %5781, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5783 = bitcast <16 x i8> %5780 to <4 x i32>
  %5784 = bitcast <16 x i8> %5782 to <4 x i32>
  %5785 = shufflevector <4 x i32> %5783, <4 x i32> %5784, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5786 = bitcast <4 x i32> %5785 to <2 x i64>
  %5787 = shufflevector <4 x i32> %5783, <4 x i32> %5784, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5788 = bitcast <4 x i32> %5787 to <2 x i64>
  %5789 = shufflevector <2 x i64> %5786, <2 x i64> %5788, <2 x i32> <i32 0, i32 2>
  %5790 = shl <2 x i64> %5729, <i64 32, i64 32>
  %5791 = ashr exact <2 x i64> %5790, <i64 28, i64 28>
  %5792 = add <2 x i64> %5791, %5675
  %5793 = bitcast <4 x i32> %5728 to <16 x i8>
  %5794 = shufflevector <16 x i8> %5793, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5795 = bitcast <16 x i8> %5794 to <2 x i64>
  %5796 = shl <2 x i64> %5795, <i64 32, i64 32>
  %5797 = ashr exact <2 x i64> %5796, <i64 28, i64 28>
  %5798 = add <2 x i64> %5797, %5675
  %5799 = bitcast <2 x i64> %5792 to <16 x i8>
  %5800 = shufflevector <16 x i8> %5799, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5801 = bitcast <2 x i64> %5798 to <16 x i8>
  %5802 = shufflevector <16 x i8> %5801, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %5803 = bitcast <16 x i8> %5800 to <4 x i32>
  %5804 = bitcast <16 x i8> %5802 to <4 x i32>
  %5805 = shufflevector <4 x i32> %5803, <4 x i32> %5804, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5806 = bitcast <4 x i32> %5805 to <2 x i64>
  %5807 = shufflevector <4 x i32> %5803, <4 x i32> %5804, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5808 = bitcast <4 x i32> %5807 to <2 x i64>
  %5809 = shufflevector <2 x i64> %5806, <2 x i64> %5808, <2 x i32> <i32 0, i32 2>
  %5810 = bitcast <2 x i64> %5749 to <4 x i32>
  %5811 = bitcast <2 x i64> %5769 to <4 x i32>
  %5812 = bitcast <2 x i64> %5789 to <4 x i32>
  %5813 = bitcast <2 x i64> %5809 to <4 x i32>
  %5814 = icmp sgt i32 %4, 10
  %5815 = select i1 %5814, i32 %4, i32 10
  %5816 = shl i32 32, %5815
  %5817 = sub nsw i32 0, %5816
  %5818 = insertelement <4 x i32> undef, i32 %5817, i32 0
  %5819 = shufflevector <4 x i32> %5818, <4 x i32> undef, <4 x i32> zeroinitializer
  %5820 = add nsw i32 %5816, -1
  %5821 = insertelement <4 x i32> undef, i32 %5820, i32 0
  %5822 = shufflevector <4 x i32> %5821, <4 x i32> undef, <4 x i32> zeroinitializer
  %5823 = icmp slt <4 x i32> %5819, %5810
  %5824 = select <4 x i1> %5823, <4 x i32> %5810, <4 x i32> %5819
  %5825 = icmp slt <4 x i32> %5824, %5822
  %5826 = select <4 x i1> %5825, <4 x i32> %5824, <4 x i32> %5822
  %5827 = bitcast <4 x i32> %5826 to <2 x i64>
  %5828 = icmp slt <4 x i32> %5819, %5811
  %5829 = select <4 x i1> %5828, <4 x i32> %5811, <4 x i32> %5819
  %5830 = icmp slt <4 x i32> %5829, %5822
  %5831 = select <4 x i1> %5830, <4 x i32> %5829, <4 x i32> %5822
  %5832 = bitcast <4 x i32> %5831 to <2 x i64>
  %5833 = icmp slt <4 x i32> %5819, %5812
  %5834 = select <4 x i1> %5833, <4 x i32> %5812, <4 x i32> %5819
  %5835 = icmp slt <4 x i32> %5834, %5822
  %5836 = select <4 x i1> %5835, <4 x i32> %5834, <4 x i32> %5822
  %5837 = bitcast <4 x i32> %5836 to <2 x i64>
  %5838 = icmp slt <4 x i32> %5819, %5813
  %5839 = select <4 x i1> %5838, <4 x i32> %5813, <4 x i32> %5819
  %5840 = icmp slt <4 x i32> %5839, %5822
  %5841 = select <4 x i1> %5840, <4 x i32> %5839, <4 x i32> %5822
  %5842 = bitcast <4 x i32> %5841 to <2 x i64>
  %5843 = shl <2 x i64> %5827, <i64 32, i64 32>
  %5844 = ashr exact <2 x i64> %5843, <i64 32, i64 32>
  %5845 = mul nsw <2 x i64> %5844, <i64 5793, i64 5793>
  %5846 = bitcast <2 x i64> %5845 to <4 x i32>
  %5847 = add <4 x i32> %5846, <i32 2048, i32 0, i32 2048, i32 0>
  %5848 = bitcast <4 x i32> %5847 to <2 x i64>
  %5849 = lshr <2 x i64> %5848, <i64 12, i64 12>
  %5850 = bitcast <4 x i32> %5826 to <16 x i8>
  %5851 = shufflevector <16 x i8> %5850, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5852 = bitcast <16 x i8> %5851 to <2 x i64>
  %5853 = shl <2 x i64> %5852, <i64 32, i64 32>
  %5854 = ashr exact <2 x i64> %5853, <i64 32, i64 32>
  %5855 = mul nsw <2 x i64> %5854, <i64 5793, i64 5793>
  %5856 = bitcast <2 x i64> %5855 to <4 x i32>
  %5857 = add <4 x i32> %5856, <i32 2048, i32 0, i32 2048, i32 0>
  %5858 = bitcast <4 x i32> %5857 to <2 x i64>
  %5859 = lshr <2 x i64> %5858, <i64 12, i64 12>
  %5860 = bitcast <2 x i64> %5849 to <4 x i32>
  %5861 = bitcast <2 x i64> %5859 to <4 x i32>
  %5862 = shufflevector <4 x i32> %5860, <4 x i32> %5861, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5863 = bitcast <4 x i32> %5862 to <2 x i64>
  %5864 = shufflevector <4 x i32> %5860, <4 x i32> %5861, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5865 = bitcast <4 x i32> %5864 to <2 x i64>
  %5866 = shufflevector <2 x i64> %5863, <2 x i64> %5865, <2 x i32> <i32 0, i32 2>
  %5867 = shl <2 x i64> %5832, <i64 32, i64 32>
  %5868 = ashr exact <2 x i64> %5867, <i64 32, i64 32>
  %5869 = mul nsw <2 x i64> %5868, <i64 5793, i64 5793>
  %5870 = bitcast <2 x i64> %5869 to <4 x i32>
  %5871 = add <4 x i32> %5870, <i32 2048, i32 0, i32 2048, i32 0>
  %5872 = bitcast <4 x i32> %5871 to <2 x i64>
  %5873 = lshr <2 x i64> %5872, <i64 12, i64 12>
  %5874 = bitcast <4 x i32> %5831 to <16 x i8>
  %5875 = shufflevector <16 x i8> %5874, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5876 = bitcast <16 x i8> %5875 to <2 x i64>
  %5877 = shl <2 x i64> %5876, <i64 32, i64 32>
  %5878 = ashr exact <2 x i64> %5877, <i64 32, i64 32>
  %5879 = mul nsw <2 x i64> %5878, <i64 5793, i64 5793>
  %5880 = bitcast <2 x i64> %5879 to <4 x i32>
  %5881 = add <4 x i32> %5880, <i32 2048, i32 0, i32 2048, i32 0>
  %5882 = bitcast <4 x i32> %5881 to <2 x i64>
  %5883 = lshr <2 x i64> %5882, <i64 12, i64 12>
  %5884 = bitcast <2 x i64> %5873 to <4 x i32>
  %5885 = bitcast <2 x i64> %5883 to <4 x i32>
  %5886 = shufflevector <4 x i32> %5884, <4 x i32> %5885, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5887 = bitcast <4 x i32> %5886 to <2 x i64>
  %5888 = shufflevector <4 x i32> %5884, <4 x i32> %5885, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5889 = bitcast <4 x i32> %5888 to <2 x i64>
  %5890 = shufflevector <2 x i64> %5887, <2 x i64> %5889, <2 x i32> <i32 0, i32 2>
  %5891 = shl <2 x i64> %5837, <i64 32, i64 32>
  %5892 = ashr exact <2 x i64> %5891, <i64 32, i64 32>
  %5893 = mul nsw <2 x i64> %5892, <i64 5793, i64 5793>
  %5894 = bitcast <2 x i64> %5893 to <4 x i32>
  %5895 = add <4 x i32> %5894, <i32 2048, i32 0, i32 2048, i32 0>
  %5896 = bitcast <4 x i32> %5895 to <2 x i64>
  %5897 = lshr <2 x i64> %5896, <i64 12, i64 12>
  %5898 = bitcast <4 x i32> %5836 to <16 x i8>
  %5899 = shufflevector <16 x i8> %5898, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5900 = bitcast <16 x i8> %5899 to <2 x i64>
  %5901 = shl <2 x i64> %5900, <i64 32, i64 32>
  %5902 = ashr exact <2 x i64> %5901, <i64 32, i64 32>
  %5903 = mul nsw <2 x i64> %5902, <i64 5793, i64 5793>
  %5904 = bitcast <2 x i64> %5903 to <4 x i32>
  %5905 = add <4 x i32> %5904, <i32 2048, i32 0, i32 2048, i32 0>
  %5906 = bitcast <4 x i32> %5905 to <2 x i64>
  %5907 = lshr <2 x i64> %5906, <i64 12, i64 12>
  %5908 = bitcast <2 x i64> %5897 to <4 x i32>
  %5909 = bitcast <2 x i64> %5907 to <4 x i32>
  %5910 = shufflevector <4 x i32> %5908, <4 x i32> %5909, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5911 = bitcast <4 x i32> %5910 to <2 x i64>
  %5912 = shufflevector <4 x i32> %5908, <4 x i32> %5909, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5913 = bitcast <4 x i32> %5912 to <2 x i64>
  %5914 = shufflevector <2 x i64> %5911, <2 x i64> %5913, <2 x i32> <i32 0, i32 2>
  %5915 = shl <2 x i64> %5842, <i64 32, i64 32>
  %5916 = ashr exact <2 x i64> %5915, <i64 32, i64 32>
  %5917 = mul nsw <2 x i64> %5916, <i64 5793, i64 5793>
  %5918 = bitcast <2 x i64> %5917 to <4 x i32>
  %5919 = add <4 x i32> %5918, <i32 2048, i32 0, i32 2048, i32 0>
  %5920 = bitcast <4 x i32> %5919 to <2 x i64>
  %5921 = lshr <2 x i64> %5920, <i64 12, i64 12>
  %5922 = bitcast <4 x i32> %5841 to <16 x i8>
  %5923 = shufflevector <16 x i8> %5922, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %5924 = bitcast <16 x i8> %5923 to <2 x i64>
  %5925 = shl <2 x i64> %5924, <i64 32, i64 32>
  %5926 = ashr exact <2 x i64> %5925, <i64 32, i64 32>
  %5927 = mul nsw <2 x i64> %5926, <i64 5793, i64 5793>
  %5928 = bitcast <2 x i64> %5927 to <4 x i32>
  %5929 = add <4 x i32> %5928, <i32 2048, i32 0, i32 2048, i32 0>
  %5930 = bitcast <4 x i32> %5929 to <2 x i64>
  %5931 = lshr <2 x i64> %5930, <i64 12, i64 12>
  %5932 = bitcast <2 x i64> %5921 to <4 x i32>
  %5933 = bitcast <2 x i64> %5931 to <4 x i32>
  %5934 = shufflevector <4 x i32> %5932, <4 x i32> %5933, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %5935 = bitcast <4 x i32> %5934 to <2 x i64>
  %5936 = shufflevector <4 x i32> %5932, <4 x i32> %5933, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %5937 = bitcast <4 x i32> %5936 to <2 x i64>
  %5938 = shufflevector <2 x i64> %5935, <2 x i64> %5937, <2 x i32> <i32 0, i32 2>
  %5939 = bitcast <2 x i64> %5890 to <4 x i32>
  %5940 = bitcast <2 x i64> %5914 to <4 x i32>
  %5941 = bitcast <2 x i64> %5938 to <4 x i32>
  %5942 = bitcast <2 x i64> %5866 to <4 x i32>
  %5943 = shufflevector <4 x i32> %5942, <4 x i32> %5939, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5944 = bitcast <4 x i32> %5943 to <2 x i64>
  %5945 = shufflevector <4 x i32> %5942, <4 x i32> %5939, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5946 = bitcast <4 x i32> %5945 to <2 x i64>
  %5947 = shufflevector <4 x i32> %5940, <4 x i32> %5941, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5948 = bitcast <4 x i32> %5947 to <2 x i64>
  %5949 = shufflevector <4 x i32> %5940, <4 x i32> %5941, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5950 = bitcast <4 x i32> %5949 to <2 x i64>
  %5951 = shufflevector <2 x i64> %5944, <2 x i64> %5948, <2 x i32> <i32 0, i32 2>
  %5952 = shufflevector <2 x i64> %5944, <2 x i64> %5948, <2 x i32> <i32 1, i32 3>
  %5953 = shufflevector <2 x i64> %5946, <2 x i64> %5950, <2 x i32> <i32 0, i32 2>
  %5954 = shufflevector <2 x i64> %5946, <2 x i64> %5950, <2 x i32> <i32 1, i32 3>
  %5955 = getelementptr inbounds i8, i8* %6, i64 1
  %5956 = load i8, i8* %5955, align 1
  %5957 = sext i8 %5956 to i32
  %5958 = sub nsw i32 0, %5957
  %5959 = icmp eq i8 %5956, 0
  br i1 %5959, label %5981, label %5960

5960:                                             ; preds = %5654
  %5961 = xor i32 %5957, -1
  %5962 = shl i32 1, %5961
  %5963 = insertelement <4 x i32> undef, i32 %5962, i32 0
  %5964 = shufflevector <4 x i32> %5963, <4 x i32> undef, <4 x i32> zeroinitializer
  %5965 = bitcast <2 x i64> %5951 to <4 x i32>
  %5966 = add <4 x i32> %5964, %5965
  %5967 = bitcast <2 x i64> %5952 to <4 x i32>
  %5968 = add <4 x i32> %5964, %5967
  %5969 = bitcast <2 x i64> %5953 to <4 x i32>
  %5970 = add <4 x i32> %5964, %5969
  %5971 = bitcast <2 x i64> %5954 to <4 x i32>
  %5972 = add <4 x i32> %5964, %5971
  %5973 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %5966, i32 %5958) #8
  %5974 = bitcast <4 x i32> %5973 to <2 x i64>
  %5975 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %5968, i32 %5958) #8
  %5976 = bitcast <4 x i32> %5975 to <2 x i64>
  %5977 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %5970, i32 %5958) #8
  %5978 = bitcast <4 x i32> %5977 to <2 x i64>
  %5979 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %5972, i32 %5958) #8
  %5980 = bitcast <4 x i32> %5979 to <2 x i64>
  br label %5981

5981:                                             ; preds = %5654, %5960
  %5982 = phi <2 x i64> [ %5954, %5654 ], [ %5980, %5960 ]
  %5983 = phi <2 x i64> [ %5953, %5654 ], [ %5978, %5960 ]
  %5984 = phi <2 x i64> [ %5952, %5654 ], [ %5976, %5960 ]
  %5985 = phi <2 x i64> [ %5951, %5654 ], [ %5974, %5960 ]
  %5986 = bitcast i16* %1 to i64*
  %5987 = load i64, i64* %5986, align 1
  %5988 = insertelement <2 x i64> undef, i64 %5987, i32 0
  %5989 = sext i32 %2 to i64
  %5990 = getelementptr inbounds i16, i16* %1, i64 %5989
  %5991 = bitcast i16* %5990 to i64*
  %5992 = load i64, i64* %5991, align 1
  %5993 = insertelement <2 x i64> undef, i64 %5992, i32 0
  %5994 = shl nsw i32 %2, 1
  %5995 = sext i32 %5994 to i64
  %5996 = getelementptr inbounds i16, i16* %1, i64 %5995
  %5997 = bitcast i16* %5996 to i64*
  %5998 = load i64, i64* %5997, align 1
  %5999 = insertelement <2 x i64> undef, i64 %5998, i32 0
  %6000 = mul nsw i32 %2, 3
  %6001 = sext i32 %6000 to i64
  %6002 = getelementptr inbounds i16, i16* %1, i64 %6001
  %6003 = bitcast i16* %6002 to i64*
  %6004 = load i64, i64* %6003, align 1
  %6005 = insertelement <2 x i64> undef, i64 %6004, i32 0
  %6006 = bitcast <2 x i64> %5988 to <8 x i16>
  %6007 = shufflevector <8 x i16> %6006, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6008 = bitcast <2 x i64> %5993 to <8 x i16>
  %6009 = shufflevector <8 x i16> %6008, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6010 = bitcast <2 x i64> %5999 to <8 x i16>
  %6011 = shufflevector <8 x i16> %6010, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6012 = bitcast <2 x i64> %6005 to <8 x i16>
  %6013 = shufflevector <8 x i16> %6012, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6014 = bitcast <2 x i64> %5985 to <4 x i32>
  %6015 = shufflevector <4 x i32> %6014, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %6016 = bitcast <2 x i64> %5984 to <4 x i32>
  %6017 = shufflevector <4 x i32> %6016, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %6018 = bitcast <2 x i64> %5983 to <4 x i32>
  %6019 = shufflevector <4 x i32> %6018, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %6020 = bitcast <2 x i64> %5982 to <4 x i32>
  %6021 = shufflevector <4 x i32> %6020, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %6022 = bitcast <8 x i16> %6007 to <4 x i32>
  %6023 = add <4 x i32> %6015, %6022
  %6024 = bitcast <8 x i16> %6009 to <4 x i32>
  %6025 = add <4 x i32> %6017, %6024
  %6026 = bitcast <8 x i16> %6011 to <4 x i32>
  %6027 = add <4 x i32> %6019, %6026
  %6028 = bitcast <8 x i16> %6013 to <4 x i32>
  %6029 = add <4 x i32> %6021, %6028
  %6030 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %6023, <4 x i32> %6025) #8
  %6031 = bitcast <8 x i16> %6030 to <2 x i64>
  %6032 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %6027, <4 x i32> %6029) #8
  %6033 = bitcast <8 x i16> %6032 to <2 x i64>
  %6034 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #8
  %6035 = add <8 x i16> %6034, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %6036 = icmp slt <8 x i16> %6035, %6030
  %6037 = sext <8 x i1> %6036 to <8 x i16>
  %6038 = bitcast <8 x i16> %6037 to <2 x i64>
  %6039 = xor <2 x i64> %6038, <i64 -1, i64 -1>
  %6040 = and <2 x i64> %6039, %6031
  %6041 = and <8 x i16> %6035, %6037
  %6042 = bitcast <8 x i16> %6041 to <2 x i64>
  %6043 = or <2 x i64> %6040, %6042
  %6044 = bitcast <2 x i64> %6043 to <8 x i16>
  %6045 = icmp sgt <8 x i16> %6044, zeroinitializer
  %6046 = sext <8 x i1> %6045 to <8 x i16>
  %6047 = bitcast <8 x i16> %6046 to <2 x i64>
  %6048 = and <2 x i64> %6043, %6047
  %6049 = icmp slt <8 x i16> %6035, %6032
  %6050 = sext <8 x i1> %6049 to <8 x i16>
  %6051 = bitcast <8 x i16> %6050 to <2 x i64>
  %6052 = xor <2 x i64> %6051, <i64 -1, i64 -1>
  %6053 = and <2 x i64> %6052, %6033
  %6054 = and <8 x i16> %6035, %6050
  br label %6055

6055:                                             ; preds = %236, %596, %956, %1377, %1741, %2101, %2526, %2955, %3384, %3741, %4069, %4401, %4794, %5191, %5584, %5981
  %6056 = phi <8 x i16> [ %301, %236 ], [ %665, %596 ], [ %1021, %956 ], [ %1446, %1377 ], [ %1810, %1741 ], [ %2170, %2101 ], [ %2599, %2526 ], [ %3028, %2955 ], [ %3453, %3384 ], [ %3810, %3741 ], [ %4134, %4069 ], [ %4470, %4401 ], [ %4863, %4794 ], [ %5260, %5191 ], [ %5653, %5584 ], [ %6054, %5981 ]
  %6057 = phi <2 x i64> [ %300, %236 ], [ %664, %596 ], [ %1020, %956 ], [ %1445, %1377 ], [ %1809, %1741 ], [ %2169, %2101 ], [ %2598, %2526 ], [ %3027, %2955 ], [ %3452, %3384 ], [ %3809, %3741 ], [ %4133, %4069 ], [ %4469, %4401 ], [ %4862, %4794 ], [ %5259, %5191 ], [ %5652, %5584 ], [ %6053, %5981 ]
  %6058 = phi <2 x i64> [ %295, %236 ], [ %659, %596 ], [ %1015, %956 ], [ %1440, %1377 ], [ %1804, %1741 ], [ %2164, %2101 ], [ %2593, %2526 ], [ %3022, %2955 ], [ %3447, %3384 ], [ %3804, %3741 ], [ %4128, %4069 ], [ %4464, %4401 ], [ %4857, %4794 ], [ %5254, %5191 ], [ %5647, %5584 ], [ %6048, %5981 ]
  %6059 = phi i64* [ %241, %236 ], [ %601, %596 ], [ %961, %956 ], [ %1382, %1377 ], [ %1746, %1741 ], [ %2106, %2101 ], [ %2531, %2526 ], [ %2960, %2955 ], [ %3389, %3384 ], [ %3746, %3741 ], [ %4074, %4069 ], [ %4406, %4401 ], [ %4799, %4794 ], [ %5196, %5191 ], [ %5589, %5584 ], [ %5986, %5981 ]
  %6060 = phi i64* [ %246, %236 ], [ %606, %596 ], [ %966, %956 ], [ %1387, %1377 ], [ %1751, %1741 ], [ %2111, %2101 ], [ %2536, %2526 ], [ %2965, %2955 ], [ %3394, %3384 ], [ %3751, %3741 ], [ %4079, %4069 ], [ %4411, %4401 ], [ %4804, %4794 ], [ %5201, %5191 ], [ %5594, %5584 ], [ %5991, %5981 ]
  %6061 = phi i64* [ %252, %236 ], [ %612, %596 ], [ %972, %956 ], [ %1393, %1377 ], [ %1757, %1741 ], [ %2117, %2101 ], [ %2542, %2526 ], [ %2971, %2955 ], [ %3400, %3384 ], [ %3757, %3741 ], [ %4085, %4069 ], [ %4417, %4401 ], [ %4810, %4794 ], [ %5207, %5191 ], [ %5600, %5584 ], [ %5997, %5981 ]
  %6062 = phi i64* [ %258, %236 ], [ %618, %596 ], [ %978, %956 ], [ %1399, %1377 ], [ %1763, %1741 ], [ %2123, %2101 ], [ %2548, %2526 ], [ %2977, %2955 ], [ %3406, %3384 ], [ %3763, %3741 ], [ %4091, %4069 ], [ %4423, %4401 ], [ %4816, %4794 ], [ %5213, %5191 ], [ %5606, %5584 ], [ %6003, %5981 ]
  %6063 = bitcast <8 x i16> %6056 to <2 x i64>
  %6064 = or <2 x i64> %6057, %6063
  %6065 = bitcast <2 x i64> %6064 to <8 x i16>
  %6066 = icmp sgt <8 x i16> %6065, zeroinitializer
  %6067 = sext <8 x i1> %6066 to <8 x i16>
  %6068 = bitcast <8 x i16> %6067 to <2 x i64>
  %6069 = and <2 x i64> %6064, %6068
  %6070 = extractelement <2 x i64> %6058, i32 0
  store i64 %6070, i64* %6059, align 1
  %6071 = extractelement <2 x i64> %6058, i32 1
  store i64 %6071, i64* %6060, align 1
  %6072 = extractelement <2 x i64> %6069, i32 0
  store i64 %6072, i64* %6061, align 1
  %6073 = extractelement <2 x i64> %6069, i32 1
  store i64 %6073, i64* %6062, align 1
  br label %6074

6074:                                             ; preds = %6055, %5
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: nounwind ssp uwtable
define internal void @idct4x4_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i32, i32, i32, i32) #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %10 = load i32, i32* %9, align 16
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 48
  %14 = load i32, i32* %13, align 16
  %15 = insertelement <4 x i32> undef, i32 %14, i32 0
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> zeroinitializer
  %17 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 16
  %18 = load i32, i32* %17, align 16
  %19 = insertelement <4 x i32> undef, i32 %18, i32 0
  %20 = shufflevector <4 x i32> %19, <4 x i32> undef, <4 x i32> zeroinitializer
  %21 = sub nsw i32 0, %18
  %22 = insertelement <4 x i32> undef, i32 %21, i32 0
  %23 = shufflevector <4 x i32> %22, <4 x i32> undef, <4 x i32> zeroinitializer
  %24 = add nsw i32 %2, -1
  %25 = shl i32 1, %24
  %26 = insertelement <4 x i32> undef, i32 %25, i32 0
  %27 = shufflevector <4 x i32> %26, <4 x i32> undef, <4 x i32> zeroinitializer
  %28 = icmp ne i32 %3, 0
  %29 = select i1 %28, i32 6, i32 8
  %30 = add nsw i32 %29, %4
  %31 = icmp slt i32 %30, 16
  %32 = add i32 %30, -1
  %33 = shl i32 1, %32
  %34 = select i1 %31, i32 32768, i32 %33
  %35 = sub nsw i32 0, %34
  %36 = insertelement <4 x i32> undef, i32 %35, i32 0
  %37 = shufflevector <4 x i32> %36, <4 x i32> undef, <4 x i32> zeroinitializer
  %38 = add nsw i32 %34, -1
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> zeroinitializer
  %41 = bitcast <2 x i64>* %0 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 16
  %43 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %44 = bitcast <2 x i64>* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 16
  %46 = shufflevector <4 x i32> %42, <4 x i32> %45, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %47 = bitcast <4 x i32> %46 to <2 x i64>
  %48 = shufflevector <4 x i32> %42, <4 x i32> %45, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %49 = bitcast <4 x i32> %48 to <2 x i64>
  %50 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %51 = bitcast <2 x i64>* %50 to <4 x i32>*
  %52 = load <4 x i32>, <4 x i32>* %51, align 16
  %53 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %54 = bitcast <2 x i64>* %53 to <4 x i32>*
  %55 = load <4 x i32>, <4 x i32>* %54, align 16
  %56 = shufflevector <4 x i32> %52, <4 x i32> %55, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %57 = bitcast <4 x i32> %56 to <2 x i64>
  %58 = shufflevector <4 x i32> %52, <4 x i32> %55, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %59 = bitcast <4 x i32> %58 to <2 x i64>
  %60 = shufflevector <2 x i64> %47, <2 x i64> %57, <2 x i32> <i32 0, i32 2>
  %61 = shufflevector <2 x i64> %47, <2 x i64> %57, <2 x i32> <i32 1, i32 3>
  %62 = shufflevector <2 x i64> %49, <2 x i64> %59, <2 x i32> <i32 0, i32 2>
  %63 = shufflevector <2 x i64> %49, <2 x i64> %59, <2 x i32> <i32 1, i32 3>
  %64 = bitcast <2 x i64> %60 to <4 x i32>
  %65 = mul <4 x i32> %12, %64
  %66 = bitcast <2 x i64> %62 to <4 x i32>
  %67 = mul <4 x i32> %12, %66
  %68 = add <4 x i32> %65, %27
  %69 = add <4 x i32> %68, %67
  %70 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %69, i32 %2) #8
  %71 = sub <4 x i32> %27, %67
  %72 = add <4 x i32> %71, %65
  %73 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %72, i32 %2) #8
  %74 = bitcast <2 x i64> %61 to <4 x i32>
  %75 = mul <4 x i32> %16, %74
  %76 = bitcast <2 x i64> %63 to <4 x i32>
  %77 = mul <4 x i32> %23, %76
  %78 = add <4 x i32> %75, %27
  %79 = add <4 x i32> %78, %77
  %80 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %79, i32 %2) #8
  %81 = mul <4 x i32> %20, %74
  %82 = mul <4 x i32> %16, %76
  %83 = add <4 x i32> %81, %27
  %84 = add <4 x i32> %83, %82
  %85 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %84, i32 %2) #8
  %86 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %87 = add <4 x i32> %85, %70
  %88 = sub <4 x i32> %70, %85
  %89 = icmp sgt <4 x i32> %87, %37
  %90 = select <4 x i1> %89, <4 x i32> %87, <4 x i32> %37
  %91 = icmp slt <4 x i32> %90, %40
  %92 = select <4 x i1> %91, <4 x i32> %90, <4 x i32> %40
  %93 = icmp sgt <4 x i32> %88, %37
  %94 = select <4 x i1> %93, <4 x i32> %88, <4 x i32> %37
  %95 = icmp slt <4 x i32> %94, %40
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %40
  %97 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %92, <4 x i32>* %97, align 16
  %98 = bitcast <2 x i64>* %86 to <4 x i32>*
  store <4 x i32> %96, <4 x i32>* %98, align 16
  %99 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %100 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %101 = add <4 x i32> %80, %73
  %102 = sub <4 x i32> %73, %80
  %103 = icmp sgt <4 x i32> %101, %37
  %104 = select <4 x i1> %103, <4 x i32> %101, <4 x i32> %37
  %105 = icmp slt <4 x i32> %104, %40
  %106 = select <4 x i1> %105, <4 x i32> %104, <4 x i32> %40
  %107 = icmp sgt <4 x i32> %102, %37
  %108 = select <4 x i1> %107, <4 x i32> %102, <4 x i32> %37
  %109 = icmp slt <4 x i32> %108, %40
  %110 = select <4 x i1> %109, <4 x i32> %108, <4 x i32> %40
  %111 = bitcast <2 x i64>* %99 to <4 x i32>*
  store <4 x i32> %106, <4 x i32>* %111, align 16
  %112 = bitcast <2 x i64>* %100 to <4 x i32>*
  store <4 x i32> %110, <4 x i32>* %112, align 16
  br i1 %28, label %152, label %113

113:                                              ; preds = %6
  %114 = icmp sgt i32 %4, 10
  %115 = select i1 %114, i32 %4, i32 10
  %116 = shl i32 32, %115
  %117 = sub nsw i32 0, %116
  %118 = insertelement <4 x i32> undef, i32 %117, i32 0
  %119 = shufflevector <4 x i32> %118, <4 x i32> undef, <4 x i32> zeroinitializer
  %120 = add nsw i32 %116, -1
  %121 = insertelement <4 x i32> undef, i32 %120, i32 0
  %122 = shufflevector <4 x i32> %121, <4 x i32> undef, <4 x i32> zeroinitializer
  %123 = shl i32 1, %5
  %124 = ashr i32 %123, 1
  %125 = insertelement <4 x i32> undef, i32 %124, i32 0
  %126 = shufflevector <4 x i32> %125, <4 x i32> undef, <4 x i32> zeroinitializer
  %127 = add <4 x i32> %92, %126
  %128 = add <4 x i32> %96, %126
  %129 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %5, i32 0
  %130 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %127, <4 x i32> %129) #8
  %131 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %128, <4 x i32> %129) #8
  %132 = icmp sgt <4 x i32> %130, %119
  %133 = select <4 x i1> %132, <4 x i32> %130, <4 x i32> %119
  %134 = icmp slt <4 x i32> %133, %122
  %135 = select <4 x i1> %134, <4 x i32> %133, <4 x i32> %122
  %136 = icmp sgt <4 x i32> %131, %119
  %137 = select <4 x i1> %136, <4 x i32> %131, <4 x i32> %119
  %138 = icmp slt <4 x i32> %137, %122
  %139 = select <4 x i1> %138, <4 x i32> %137, <4 x i32> %122
  store <4 x i32> %135, <4 x i32>* %97, align 16
  store <4 x i32> %139, <4 x i32>* %98, align 16
  %140 = add <4 x i32> %106, %126
  %141 = add <4 x i32> %110, %126
  %142 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %140, <4 x i32> %129) #8
  %143 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %141, <4 x i32> %129) #8
  %144 = icmp sgt <4 x i32> %142, %119
  %145 = select <4 x i1> %144, <4 x i32> %142, <4 x i32> %119
  %146 = icmp slt <4 x i32> %145, %122
  %147 = select <4 x i1> %146, <4 x i32> %145, <4 x i32> %122
  %148 = icmp sgt <4 x i32> %143, %119
  %149 = select <4 x i1> %148, <4 x i32> %143, <4 x i32> %119
  %150 = icmp slt <4 x i32> %149, %122
  %151 = select <4 x i1> %150, <4 x i32> %149, <4 x i32> %122
  store <4 x i32> %147, <4 x i32>* %111, align 16
  store <4 x i32> %151, <4 x i32>* %112, align 16
  br label %152

152:                                              ; preds = %113, %6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @iadst4x4_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i32, i32, i32, i32) #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = add nsw i32 %2, 3
  %10 = shl i32 1, %9
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>
  %13 = shufflevector <4 x i32> %12, <4 x i32> <i32 0, i32 0, i32 undef, i32 undef>, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %8, i64 1
  %16 = load i32, i32* %15, align 4
  %17 = insertelement <4 x i32> undef, i32 %16, i32 0
  %18 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> zeroinitializer
  %19 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %8, i64 2
  %20 = load i32, i32* %19, align 4
  %21 = insertelement <4 x i32> undef, i32 %20, i32 0
  %22 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> zeroinitializer
  %23 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %8, i64 3
  %24 = load i32, i32* %23, align 4
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> zeroinitializer
  %27 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %8, i64 4
  %28 = load i32, i32* %27, align 4
  %29 = insertelement <4 x i32> undef, i32 %28, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = bitcast <2 x i64>* %0 to <4 x i32>*
  %32 = load <4 x i32>, <4 x i32>* %31, align 16
  %33 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %34 = bitcast <2 x i64>* %33 to <4 x i32>*
  %35 = load <4 x i32>, <4 x i32>* %34, align 16
  %36 = shufflevector <4 x i32> %32, <4 x i32> %35, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %37 = bitcast <4 x i32> %36 to <2 x i64>
  %38 = shufflevector <4 x i32> %32, <4 x i32> %35, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %39 = bitcast <4 x i32> %38 to <2 x i64>
  %40 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %41 = bitcast <2 x i64>* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 16
  %43 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %44 = bitcast <2 x i64>* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 16
  %46 = shufflevector <4 x i32> %42, <4 x i32> %45, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %47 = bitcast <4 x i32> %46 to <2 x i64>
  %48 = shufflevector <4 x i32> %42, <4 x i32> %45, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %49 = bitcast <4 x i32> %48 to <2 x i64>
  %50 = shufflevector <2 x i64> %37, <2 x i64> %47, <2 x i32> <i32 0, i32 2>
  %51 = shufflevector <2 x i64> %37, <2 x i64> %47, <2 x i32> <i32 1, i32 3>
  %52 = shufflevector <2 x i64> %39, <2 x i64> %49, <2 x i32> <i32 0, i32 2>
  %53 = shufflevector <2 x i64> %39, <2 x i64> %49, <2 x i32> <i32 1, i32 3>
  %54 = bitcast <2 x i64> %50 to <4 x i32>
  %55 = mul <4 x i32> %18, %54
  %56 = mul <4 x i32> %22, %54
  %57 = bitcast <2 x i64> %51 to <4 x i32>
  %58 = mul <4 x i32> %26, %57
  %59 = bitcast <2 x i64> %52 to <4 x i32>
  %60 = mul <4 x i32> %30, %59
  %61 = mul <4 x i32> %18, %59
  %62 = bitcast <2 x i64> %53 to <4 x i32>
  %63 = mul <4 x i32> %22, %62
  %64 = sub <4 x i32> %54, %59
  %65 = add <4 x i32> %64, %62
  %66 = add <4 x i32> %60, %55
  %67 = add <4 x i32> %66, %63
  %68 = sub <4 x i32> %56, %61
  %69 = mul <4 x i32> %30, %62
  %70 = sub <4 x i32> %68, %69
  %71 = mul <4 x i32> %65, %26
  %72 = bitcast <4 x i32> %71 to <2 x i64>
  %73 = add <4 x i32> %67, %58
  %74 = bitcast <4 x i32> %73 to <2 x i64>
  %75 = add <4 x i32> %70, %58
  %76 = bitcast <4 x i32> %75 to <2 x i64>
  %77 = sub <4 x i32> %67, %58
  %78 = add <4 x i32> %77, %70
  %79 = bitcast <4 x i32> %78 to <2 x i64>
  %80 = shl <2 x i64> %74, <i64 32, i64 32>
  %81 = ashr exact <2 x i64> %80, <i64 28, i64 28>
  %82 = add <2 x i64> %81, %14
  %83 = bitcast <4 x i32> %73 to <16 x i8>
  %84 = shufflevector <16 x i8> %83, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %85 = bitcast <16 x i8> %84 to <2 x i64>
  %86 = shl <2 x i64> %85, <i64 32, i64 32>
  %87 = ashr exact <2 x i64> %86, <i64 28, i64 28>
  %88 = add <2 x i64> %87, %14
  %89 = bitcast <2 x i64> %82 to <16 x i8>
  %90 = shufflevector <16 x i8> %89, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %91 = bitcast <2 x i64> %88 to <16 x i8>
  %92 = shufflevector <16 x i8> %91, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %93 = bitcast <16 x i8> %90 to <4 x i32>
  %94 = bitcast <16 x i8> %92 to <4 x i32>
  %95 = shufflevector <4 x i32> %93, <4 x i32> %94, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %96 = bitcast <4 x i32> %95 to <2 x i64>
  %97 = shufflevector <4 x i32> %93, <4 x i32> %94, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %98 = bitcast <4 x i32> %97 to <2 x i64>
  %99 = shufflevector <2 x i64> %96, <2 x i64> %98, <2 x i32> <i32 0, i32 2>
  %100 = shl <2 x i64> %76, <i64 32, i64 32>
  %101 = ashr exact <2 x i64> %100, <i64 28, i64 28>
  %102 = add <2 x i64> %101, %14
  %103 = bitcast <4 x i32> %75 to <16 x i8>
  %104 = shufflevector <16 x i8> %103, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %105 = bitcast <16 x i8> %104 to <2 x i64>
  %106 = shl <2 x i64> %105, <i64 32, i64 32>
  %107 = ashr exact <2 x i64> %106, <i64 28, i64 28>
  %108 = add <2 x i64> %107, %14
  %109 = bitcast <2 x i64> %102 to <16 x i8>
  %110 = shufflevector <16 x i8> %109, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %111 = bitcast <2 x i64> %108 to <16 x i8>
  %112 = shufflevector <16 x i8> %111, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %113 = bitcast <16 x i8> %110 to <4 x i32>
  %114 = bitcast <16 x i8> %112 to <4 x i32>
  %115 = shufflevector <4 x i32> %113, <4 x i32> %114, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %116 = bitcast <4 x i32> %115 to <2 x i64>
  %117 = shufflevector <4 x i32> %113, <4 x i32> %114, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = shufflevector <2 x i64> %116, <2 x i64> %118, <2 x i32> <i32 0, i32 2>
  %120 = shl <2 x i64> %72, <i64 32, i64 32>
  %121 = ashr exact <2 x i64> %120, <i64 28, i64 28>
  %122 = add <2 x i64> %121, %14
  %123 = bitcast <4 x i32> %71 to <16 x i8>
  %124 = shufflevector <16 x i8> %123, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %125 = bitcast <16 x i8> %124 to <2 x i64>
  %126 = shl <2 x i64> %125, <i64 32, i64 32>
  %127 = ashr exact <2 x i64> %126, <i64 28, i64 28>
  %128 = add <2 x i64> %127, %14
  %129 = bitcast <2 x i64> %122 to <16 x i8>
  %130 = shufflevector <16 x i8> %129, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %131 = bitcast <2 x i64> %128 to <16 x i8>
  %132 = shufflevector <16 x i8> %131, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %133 = bitcast <16 x i8> %130 to <4 x i32>
  %134 = bitcast <16 x i8> %132 to <4 x i32>
  %135 = shufflevector <4 x i32> %133, <4 x i32> %134, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %136 = bitcast <4 x i32> %135 to <2 x i64>
  %137 = shufflevector <4 x i32> %133, <4 x i32> %134, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %138 = bitcast <4 x i32> %137 to <2 x i64>
  %139 = shufflevector <2 x i64> %136, <2 x i64> %138, <2 x i32> <i32 0, i32 2>
  %140 = shl <2 x i64> %79, <i64 32, i64 32>
  %141 = ashr exact <2 x i64> %140, <i64 28, i64 28>
  %142 = add <2 x i64> %141, %14
  %143 = bitcast <4 x i32> %78 to <16 x i8>
  %144 = shufflevector <16 x i8> %143, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %145 = bitcast <16 x i8> %144 to <2 x i64>
  %146 = shl <2 x i64> %145, <i64 32, i64 32>
  %147 = ashr exact <2 x i64> %146, <i64 28, i64 28>
  %148 = add <2 x i64> %147, %14
  %149 = bitcast <2 x i64> %142 to <16 x i8>
  %150 = shufflevector <16 x i8> %149, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %151 = bitcast <2 x i64> %148 to <16 x i8>
  %152 = shufflevector <16 x i8> %151, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %153 = bitcast <16 x i8> %150 to <4 x i32>
  %154 = bitcast <16 x i8> %152 to <4 x i32>
  %155 = shufflevector <4 x i32> %153, <4 x i32> %154, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %156 = bitcast <4 x i32> %155 to <2 x i64>
  %157 = shufflevector <4 x i32> %153, <4 x i32> %154, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %158 = bitcast <4 x i32> %157 to <2 x i64>
  %159 = shufflevector <2 x i64> %156, <2 x i64> %158, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %99, <2 x i64>* %1, align 16
  %160 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  store <2 x i64> %119, <2 x i64>* %160, align 16
  %161 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  store <2 x i64> %139, <2 x i64>* %161, align 16
  %162 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  store <2 x i64> %159, <2 x i64>* %162, align 16
  %163 = icmp eq i32 %3, 0
  %164 = bitcast <2 x i64> %99 to <4 x i32>
  %165 = bitcast <2 x i64> %119 to <4 x i32>
  %166 = bitcast <2 x i64> %139 to <4 x i32>
  %167 = bitcast <2 x i64> %159 to <4 x i32>
  br i1 %163, label %168, label %226

168:                                              ; preds = %6
  %169 = icmp sgt i32 %4, 10
  %170 = select i1 %169, i32 %4, i32 10
  %171 = shl i32 32, %170
  %172 = sub nsw i32 0, %171
  %173 = insertelement <4 x i32> undef, i32 %172, i32 0
  %174 = shufflevector <4 x i32> %173, <4 x i32> undef, <4 x i32> zeroinitializer
  %175 = add nsw i32 %171, -1
  %176 = insertelement <4 x i32> undef, i32 %175, i32 0
  %177 = shufflevector <4 x i32> %176, <4 x i32> undef, <4 x i32> zeroinitializer
  %178 = icmp eq i32 %5, 0
  br i1 %178, label %179, label %184

179:                                              ; preds = %168
  %180 = bitcast <2 x i64>* %1 to <4 x i32>*
  %181 = bitcast <2 x i64>* %160 to <4 x i32>*
  %182 = bitcast <2 x i64>* %161 to <4 x i32>*
  %183 = bitcast <2 x i64>* %162 to <4 x i32>*
  br label %201

184:                                              ; preds = %168
  %185 = add nsw i32 %5, -1
  %186 = shl i32 1, %185
  %187 = insertelement <4 x i32> undef, i32 %186, i32 0
  %188 = shufflevector <4 x i32> %187, <4 x i32> undef, <4 x i32> zeroinitializer
  %189 = bitcast <2 x i64>* %1 to <4 x i32>*
  %190 = add <4 x i32> %188, %164
  %191 = bitcast <2 x i64>* %160 to <4 x i32>*
  %192 = add <4 x i32> %188, %165
  %193 = bitcast <2 x i64>* %161 to <4 x i32>*
  %194 = add <4 x i32> %188, %166
  %195 = bitcast <2 x i64>* %162 to <4 x i32>*
  %196 = add <4 x i32> %188, %167
  %197 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %190, i32 %5) #8
  store <4 x i32> %197, <4 x i32>* %189, align 16
  %198 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %192, i32 %5) #8
  store <4 x i32> %198, <4 x i32>* %191, align 16
  %199 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %194, i32 %5) #8
  store <4 x i32> %199, <4 x i32>* %193, align 16
  %200 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %196, i32 %5) #8
  store <4 x i32> %200, <4 x i32>* %195, align 16
  br label %201

201:                                              ; preds = %179, %184
  %202 = phi <4 x i32>* [ %183, %179 ], [ %195, %184 ]
  %203 = phi <4 x i32>* [ %182, %179 ], [ %193, %184 ]
  %204 = phi <4 x i32>* [ %181, %179 ], [ %191, %184 ]
  %205 = phi <4 x i32>* [ %180, %179 ], [ %189, %184 ]
  %206 = phi <4 x i32> [ %167, %179 ], [ %200, %184 ]
  %207 = phi <4 x i32> [ %166, %179 ], [ %199, %184 ]
  %208 = phi <4 x i32> [ %165, %179 ], [ %198, %184 ]
  %209 = phi <4 x i32> [ %164, %179 ], [ %197, %184 ]
  %210 = icmp sgt <4 x i32> %209, %174
  %211 = select <4 x i1> %210, <4 x i32> %209, <4 x i32> %174
  %212 = icmp slt <4 x i32> %211, %177
  %213 = select <4 x i1> %212, <4 x i32> %211, <4 x i32> %177
  store <4 x i32> %213, <4 x i32>* %205, align 16
  %214 = icmp sgt <4 x i32> %208, %174
  %215 = select <4 x i1> %214, <4 x i32> %208, <4 x i32> %174
  %216 = icmp slt <4 x i32> %215, %177
  %217 = select <4 x i1> %216, <4 x i32> %215, <4 x i32> %177
  store <4 x i32> %217, <4 x i32>* %204, align 16
  %218 = icmp sgt <4 x i32> %207, %174
  %219 = select <4 x i1> %218, <4 x i32> %207, <4 x i32> %174
  %220 = icmp slt <4 x i32> %219, %177
  %221 = select <4 x i1> %220, <4 x i32> %219, <4 x i32> %177
  store <4 x i32> %221, <4 x i32>* %203, align 16
  %222 = icmp sgt <4 x i32> %206, %174
  %223 = select <4 x i1> %222, <4 x i32> %206, <4 x i32> %174
  %224 = icmp slt <4 x i32> %223, %177
  %225 = select <4 x i1> %224, <4 x i32> %223, <4 x i32> %177
  store <4 x i32> %225, <4 x i32>* %202, align 16
  br label %226

226:                                              ; preds = %6, %201
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @iidentity4_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i32, i32, i32, i32) #0 {
  %7 = load <2 x i64>, <2 x i64>* %0, align 16
  %8 = shl <2 x i64> %7, <i64 32, i64 32>
  %9 = ashr exact <2 x i64> %8, <i64 32, i64 32>
  %10 = mul nsw <2 x i64> %9, <i64 5793, i64 5793>
  %11 = bitcast <2 x i64> %10 to <4 x i32>
  %12 = add <4 x i32> %11, <i32 2048, i32 0, i32 2048, i32 0>
  %13 = bitcast <4 x i32> %12 to <2 x i64>
  %14 = lshr <2 x i64> %13, <i64 12, i64 12>
  %15 = bitcast <2 x i64> %7 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %17 = bitcast <16 x i8> %16 to <2 x i64>
  %18 = shl <2 x i64> %17, <i64 32, i64 32>
  %19 = ashr exact <2 x i64> %18, <i64 32, i64 32>
  %20 = mul nsw <2 x i64> %19, <i64 5793, i64 5793>
  %21 = bitcast <2 x i64> %20 to <4 x i32>
  %22 = add <4 x i32> %21, <i32 2048, i32 0, i32 2048, i32 0>
  %23 = bitcast <4 x i32> %22 to <2 x i64>
  %24 = lshr <2 x i64> %23, <i64 12, i64 12>
  %25 = bitcast <2 x i64> %14 to <4 x i32>
  %26 = bitcast <2 x i64> %24 to <4 x i32>
  %27 = shufflevector <4 x i32> %25, <4 x i32> %26, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %28 = bitcast <4 x i32> %27 to <2 x i64>
  %29 = shufflevector <4 x i32> %25, <4 x i32> %26, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %30 = bitcast <4 x i32> %29 to <2 x i64>
  %31 = shufflevector <2 x i64> %28, <2 x i64> %30, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %31, <2 x i64>* %1, align 16
  %32 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %33 = load <2 x i64>, <2 x i64>* %32, align 16
  %34 = shl <2 x i64> %33, <i64 32, i64 32>
  %35 = ashr exact <2 x i64> %34, <i64 32, i64 32>
  %36 = mul nsw <2 x i64> %35, <i64 5793, i64 5793>
  %37 = bitcast <2 x i64> %36 to <4 x i32>
  %38 = add <4 x i32> %37, <i32 2048, i32 0, i32 2048, i32 0>
  %39 = bitcast <4 x i32> %38 to <2 x i64>
  %40 = lshr <2 x i64> %39, <i64 12, i64 12>
  %41 = bitcast <2 x i64> %33 to <16 x i8>
  %42 = shufflevector <16 x i8> %41, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %43 = bitcast <16 x i8> %42 to <2 x i64>
  %44 = shl <2 x i64> %43, <i64 32, i64 32>
  %45 = ashr exact <2 x i64> %44, <i64 32, i64 32>
  %46 = mul nsw <2 x i64> %45, <i64 5793, i64 5793>
  %47 = bitcast <2 x i64> %46 to <4 x i32>
  %48 = add <4 x i32> %47, <i32 2048, i32 0, i32 2048, i32 0>
  %49 = bitcast <4 x i32> %48 to <2 x i64>
  %50 = lshr <2 x i64> %49, <i64 12, i64 12>
  %51 = bitcast <2 x i64> %40 to <4 x i32>
  %52 = bitcast <2 x i64> %50 to <4 x i32>
  %53 = shufflevector <4 x i32> %51, <4 x i32> %52, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %54 = bitcast <4 x i32> %53 to <2 x i64>
  %55 = shufflevector <4 x i32> %51, <4 x i32> %52, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %56 = bitcast <4 x i32> %55 to <2 x i64>
  %57 = shufflevector <2 x i64> %54, <2 x i64> %56, <2 x i32> <i32 0, i32 2>
  %58 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  store <2 x i64> %57, <2 x i64>* %58, align 16
  %59 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %60 = load <2 x i64>, <2 x i64>* %59, align 16
  %61 = shl <2 x i64> %60, <i64 32, i64 32>
  %62 = ashr exact <2 x i64> %61, <i64 32, i64 32>
  %63 = mul nsw <2 x i64> %62, <i64 5793, i64 5793>
  %64 = bitcast <2 x i64> %63 to <4 x i32>
  %65 = add <4 x i32> %64, <i32 2048, i32 0, i32 2048, i32 0>
  %66 = bitcast <4 x i32> %65 to <2 x i64>
  %67 = lshr <2 x i64> %66, <i64 12, i64 12>
  %68 = bitcast <2 x i64> %60 to <16 x i8>
  %69 = shufflevector <16 x i8> %68, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %70 = bitcast <16 x i8> %69 to <2 x i64>
  %71 = shl <2 x i64> %70, <i64 32, i64 32>
  %72 = ashr exact <2 x i64> %71, <i64 32, i64 32>
  %73 = mul nsw <2 x i64> %72, <i64 5793, i64 5793>
  %74 = bitcast <2 x i64> %73 to <4 x i32>
  %75 = add <4 x i32> %74, <i32 2048, i32 0, i32 2048, i32 0>
  %76 = bitcast <4 x i32> %75 to <2 x i64>
  %77 = lshr <2 x i64> %76, <i64 12, i64 12>
  %78 = bitcast <2 x i64> %67 to <4 x i32>
  %79 = bitcast <2 x i64> %77 to <4 x i32>
  %80 = shufflevector <4 x i32> %78, <4 x i32> %79, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %81 = bitcast <4 x i32> %80 to <2 x i64>
  %82 = shufflevector <4 x i32> %78, <4 x i32> %79, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %83 = bitcast <4 x i32> %82 to <2 x i64>
  %84 = shufflevector <2 x i64> %81, <2 x i64> %83, <2 x i32> <i32 0, i32 2>
  %85 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  store <2 x i64> %84, <2 x i64>* %85, align 16
  %86 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %87 = load <2 x i64>, <2 x i64>* %86, align 16
  %88 = shl <2 x i64> %87, <i64 32, i64 32>
  %89 = ashr exact <2 x i64> %88, <i64 32, i64 32>
  %90 = mul nsw <2 x i64> %89, <i64 5793, i64 5793>
  %91 = bitcast <2 x i64> %90 to <4 x i32>
  %92 = add <4 x i32> %91, <i32 2048, i32 0, i32 2048, i32 0>
  %93 = bitcast <4 x i32> %92 to <2 x i64>
  %94 = lshr <2 x i64> %93, <i64 12, i64 12>
  %95 = bitcast <2 x i64> %87 to <16 x i8>
  %96 = shufflevector <16 x i8> %95, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %97 = bitcast <16 x i8> %96 to <2 x i64>
  %98 = shl <2 x i64> %97, <i64 32, i64 32>
  %99 = ashr exact <2 x i64> %98, <i64 32, i64 32>
  %100 = mul nsw <2 x i64> %99, <i64 5793, i64 5793>
  %101 = bitcast <2 x i64> %100 to <4 x i32>
  %102 = add <4 x i32> %101, <i32 2048, i32 0, i32 2048, i32 0>
  %103 = bitcast <4 x i32> %102 to <2 x i64>
  %104 = lshr <2 x i64> %103, <i64 12, i64 12>
  %105 = bitcast <2 x i64> %94 to <4 x i32>
  %106 = bitcast <2 x i64> %104 to <4 x i32>
  %107 = shufflevector <4 x i32> %105, <4 x i32> %106, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %108 = bitcast <4 x i32> %107 to <2 x i64>
  %109 = shufflevector <4 x i32> %105, <4 x i32> %106, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %110 = bitcast <4 x i32> %109 to <2 x i64>
  %111 = shufflevector <2 x i64> %108, <2 x i64> %110, <2 x i32> <i32 0, i32 2>
  %112 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  store <2 x i64> %111, <2 x i64>* %112, align 16
  %113 = icmp eq i32 %3, 0
  %114 = bitcast <2 x i64> %31 to <4 x i32>
  %115 = bitcast <2 x i64> %57 to <4 x i32>
  %116 = bitcast <2 x i64> %84 to <4 x i32>
  %117 = bitcast <2 x i64> %111 to <4 x i32>
  br i1 %113, label %121, label %118

118:                                              ; preds = %6
  %119 = bitcast <2 x i64>* %1 to <4 x i32>*
  %120 = load <4 x i32>, <4 x i32>* %119, align 16
  br label %180

121:                                              ; preds = %6
  %122 = icmp sgt i32 %4, 10
  %123 = select i1 %122, i32 %4, i32 10
  %124 = shl i32 32, %123
  %125 = sub nsw i32 0, %124
  %126 = insertelement <4 x i32> undef, i32 %125, i32 0
  %127 = shufflevector <4 x i32> %126, <4 x i32> undef, <4 x i32> zeroinitializer
  %128 = add nsw i32 %124, -1
  %129 = insertelement <4 x i32> undef, i32 %128, i32 0
  %130 = shufflevector <4 x i32> %129, <4 x i32> undef, <4 x i32> zeroinitializer
  %131 = icmp eq i32 %5, 0
  br i1 %131, label %132, label %138

132:                                              ; preds = %121
  %133 = bitcast <2 x i64>* %1 to <4 x i32>*
  %134 = load <4 x i32>, <4 x i32>* %133, align 16
  %135 = bitcast <2 x i64>* %58 to <4 x i32>*
  %136 = bitcast <2 x i64>* %85 to <4 x i32>*
  %137 = bitcast <2 x i64>* %112 to <4 x i32>*
  br label %155

138:                                              ; preds = %121
  %139 = add nsw i32 %5, -1
  %140 = shl i32 1, %139
  %141 = insertelement <4 x i32> undef, i32 %140, i32 0
  %142 = shufflevector <4 x i32> %141, <4 x i32> undef, <4 x i32> zeroinitializer
  %143 = bitcast <2 x i64>* %1 to <4 x i32>*
  %144 = add <4 x i32> %142, %114
  %145 = bitcast <2 x i64>* %58 to <4 x i32>*
  %146 = add <4 x i32> %142, %115
  %147 = bitcast <2 x i64>* %85 to <4 x i32>*
  %148 = add <4 x i32> %142, %116
  %149 = bitcast <2 x i64>* %112 to <4 x i32>*
  %150 = add <4 x i32> %142, %117
  %151 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %144, i32 %5) #8
  store <4 x i32> %151, <4 x i32>* %143, align 16
  %152 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %146, i32 %5) #8
  store <4 x i32> %152, <4 x i32>* %145, align 16
  %153 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %148, i32 %5) #8
  store <4 x i32> %153, <4 x i32>* %147, align 16
  %154 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %150, i32 %5) #8
  store <4 x i32> %154, <4 x i32>* %149, align 16
  br label %155

155:                                              ; preds = %132, %138
  %156 = phi <4 x i32>* [ %137, %132 ], [ %149, %138 ]
  %157 = phi <4 x i32>* [ %136, %132 ], [ %147, %138 ]
  %158 = phi <4 x i32>* [ %135, %132 ], [ %145, %138 ]
  %159 = phi <4 x i32>* [ %133, %132 ], [ %143, %138 ]
  %160 = phi <4 x i32> [ %117, %132 ], [ %154, %138 ]
  %161 = phi <4 x i32> [ %116, %132 ], [ %153, %138 ]
  %162 = phi <4 x i32> [ %115, %132 ], [ %152, %138 ]
  %163 = phi <4 x i32> [ %134, %132 ], [ %151, %138 ]
  %164 = icmp sgt <4 x i32> %163, %127
  %165 = select <4 x i1> %164, <4 x i32> %163, <4 x i32> %127
  %166 = icmp slt <4 x i32> %165, %130
  %167 = select <4 x i1> %166, <4 x i32> %165, <4 x i32> %130
  store <4 x i32> %167, <4 x i32>* %159, align 16
  %168 = icmp sgt <4 x i32> %162, %127
  %169 = select <4 x i1> %168, <4 x i32> %162, <4 x i32> %127
  %170 = icmp slt <4 x i32> %169, %130
  %171 = select <4 x i1> %170, <4 x i32> %169, <4 x i32> %130
  store <4 x i32> %171, <4 x i32>* %158, align 16
  %172 = icmp sgt <4 x i32> %161, %127
  %173 = select <4 x i1> %172, <4 x i32> %161, <4 x i32> %127
  %174 = icmp slt <4 x i32> %173, %130
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %130
  store <4 x i32> %175, <4 x i32>* %157, align 16
  %176 = icmp sgt <4 x i32> %160, %127
  %177 = select <4 x i1> %176, <4 x i32> %160, <4 x i32> %127
  %178 = icmp slt <4 x i32> %177, %130
  %179 = select <4 x i1> %178, <4 x i32> %177, <4 x i32> %130
  store <4 x i32> %179, <4 x i32>* %156, align 16
  br label %180

180:                                              ; preds = %118, %155
  %181 = phi <4 x i32> [ %117, %118 ], [ %179, %155 ]
  %182 = phi <4 x i32> [ %116, %118 ], [ %175, %155 ]
  %183 = phi <4 x i32> [ %115, %118 ], [ %171, %155 ]
  %184 = phi <4 x i32> [ %120, %118 ], [ %167, %155 ]
  %185 = shufflevector <4 x i32> %184, <4 x i32> %183, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %186 = bitcast <4 x i32> %185 to <2 x i64>
  %187 = shufflevector <4 x i32> %184, <4 x i32> %183, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %188 = bitcast <4 x i32> %187 to <2 x i64>
  %189 = shufflevector <4 x i32> %182, <4 x i32> %181, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %190 = bitcast <4 x i32> %189 to <2 x i64>
  %191 = shufflevector <4 x i32> %182, <4 x i32> %181, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %192 = bitcast <4 x i32> %191 to <2 x i64>
  %193 = shufflevector <2 x i64> %186, <2 x i64> %190, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %193, <2 x i64>* %1, align 16
  %194 = shufflevector <2 x i64> %186, <2 x i64> %190, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %194, <2 x i64>* %58, align 16
  %195 = shufflevector <2 x i64> %188, <2 x i64> %192, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %195, <2 x i64>* %85, align 16
  %196 = shufflevector <2 x i64> %188, <2 x i64> %192, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %196, <2 x i64>* %112, align 16
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_inv_txfm2d_add_8x8_sse4_1(i32* readonly, i16* nocapture, i32, i8 zeroext, i32) local_unnamed_addr #0 {
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = alloca [16 x <2 x i64>], align 16
  %8 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 256, i1 false)
  %9 = bitcast [16 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 256, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_inv_txfm_shift_ls, i64 0, i64 1), align 8
  switch i8 %3, label %2126 [
    i8 0, label %11
    i8 2, label %246
    i8 1, label %481
    i8 3, label %716
    i8 4, label %951
    i8 5, label %1186
    i8 7, label %1421
    i8 6, label %1656
    i8 8, label %1891
  ]

11:                                               ; preds = %5
  %12 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %13 = bitcast i32* %0 to <2 x i64>*
  %14 = load <2 x i64>, <2 x i64>* %13, align 16
  store <2 x i64> %14, <2 x i64>* %12, align 16
  %15 = getelementptr inbounds i32, i32* %0, i64 4
  %16 = bitcast i32* %15 to <2 x i64>*
  %17 = load <2 x i64>, <2 x i64>* %16, align 16
  %18 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %17, <2 x i64>* %18, align 16
  %19 = getelementptr inbounds i32, i32* %0, i64 8
  %20 = bitcast i32* %19 to <2 x i64>*
  %21 = load <2 x i64>, <2 x i64>* %20, align 16
  %22 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %21, <2 x i64>* %22, align 16
  %23 = getelementptr inbounds i32, i32* %0, i64 12
  %24 = bitcast i32* %23 to <2 x i64>*
  %25 = load <2 x i64>, <2 x i64>* %24, align 16
  %26 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %25, <2 x i64>* %26, align 16
  %27 = getelementptr inbounds i32, i32* %0, i64 16
  %28 = bitcast i32* %27 to <2 x i64>*
  %29 = load <2 x i64>, <2 x i64>* %28, align 16
  %30 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %29, <2 x i64>* %30, align 16
  %31 = getelementptr inbounds i32, i32* %0, i64 20
  %32 = bitcast i32* %31 to <2 x i64>*
  %33 = load <2 x i64>, <2 x i64>* %32, align 16
  %34 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %33, <2 x i64>* %34, align 16
  %35 = getelementptr inbounds i32, i32* %0, i64 24
  %36 = bitcast i32* %35 to <2 x i64>*
  %37 = load <2 x i64>, <2 x i64>* %36, align 16
  %38 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %37, <2 x i64>* %38, align 16
  %39 = getelementptr inbounds i32, i32* %0, i64 28
  %40 = bitcast i32* %39 to <2 x i64>*
  %41 = load <2 x i64>, <2 x i64>* %40, align 16
  %42 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %41, <2 x i64>* %42, align 16
  %43 = getelementptr inbounds i32, i32* %0, i64 32
  %44 = bitcast i32* %43 to <2 x i64>*
  %45 = load <2 x i64>, <2 x i64>* %44, align 16
  %46 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %45, <2 x i64>* %46, align 16
  %47 = getelementptr inbounds i32, i32* %0, i64 36
  %48 = bitcast i32* %47 to <2 x i64>*
  %49 = load <2 x i64>, <2 x i64>* %48, align 16
  %50 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %49, <2 x i64>* %50, align 16
  %51 = getelementptr inbounds i32, i32* %0, i64 40
  %52 = bitcast i32* %51 to <2 x i64>*
  %53 = load <2 x i64>, <2 x i64>* %52, align 16
  %54 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %53, <2 x i64>* %54, align 16
  %55 = getelementptr inbounds i32, i32* %0, i64 44
  %56 = bitcast i32* %55 to <2 x i64>*
  %57 = load <2 x i64>, <2 x i64>* %56, align 16
  %58 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %57, <2 x i64>* %58, align 16
  %59 = getelementptr inbounds i32, i32* %0, i64 48
  %60 = bitcast i32* %59 to <2 x i64>*
  %61 = load <2 x i64>, <2 x i64>* %60, align 16
  %62 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %61, <2 x i64>* %62, align 16
  %63 = getelementptr inbounds i32, i32* %0, i64 52
  %64 = bitcast i32* %63 to <2 x i64>*
  %65 = load <2 x i64>, <2 x i64>* %64, align 16
  %66 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %65, <2 x i64>* %66, align 16
  %67 = getelementptr inbounds i32, i32* %0, i64 56
  %68 = bitcast i32* %67 to <2 x i64>*
  %69 = load <2 x i64>, <2 x i64>* %68, align 16
  %70 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %69, <2 x i64>* %70, align 16
  %71 = getelementptr inbounds i32, i32* %0, i64 60
  %72 = bitcast i32* %71 to <2 x i64>*
  %73 = load <2 x i64>, <2 x i64>* %72, align 16
  %74 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %73, <2 x i64>* %74, align 16
  %75 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  %76 = bitcast [16 x <2 x i64>]* %6 to <4 x i32>*
  %77 = bitcast <2 x i64> %14 to <4 x i32>
  %78 = bitcast <2 x i64>* %22 to <4 x i32>*
  %79 = bitcast <2 x i64> %21 to <4 x i32>
  %80 = shufflevector <4 x i32> %77, <4 x i32> %79, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %81 = bitcast <4 x i32> %80 to <2 x i64>
  %82 = shufflevector <4 x i32> %77, <4 x i32> %79, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %83 = bitcast <4 x i32> %82 to <2 x i64>
  %84 = bitcast <2 x i64>* %30 to <4 x i32>*
  %85 = bitcast <2 x i64> %29 to <4 x i32>
  %86 = bitcast <2 x i64>* %38 to <4 x i32>*
  %87 = bitcast <2 x i64> %37 to <4 x i32>
  %88 = shufflevector <4 x i32> %85, <4 x i32> %87, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %89 = bitcast <4 x i32> %88 to <2 x i64>
  %90 = shufflevector <4 x i32> %85, <4 x i32> %87, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %91 = bitcast <4 x i32> %90 to <2 x i64>
  %92 = shufflevector <2 x i64> %81, <2 x i64> %89, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %92, <2 x i64>* %75, align 16
  %93 = shufflevector <2 x i64> %81, <2 x i64> %89, <2 x i32> <i32 1, i32 3>
  %94 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %93, <2 x i64>* %94, align 16
  %95 = shufflevector <2 x i64> %83, <2 x i64> %91, <2 x i32> <i32 0, i32 2>
  %96 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 4
  store <2 x i64> %95, <2 x i64>* %96, align 16
  %97 = shufflevector <2 x i64> %83, <2 x i64> %91, <2 x i32> <i32 1, i32 3>
  %98 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 6
  store <2 x i64> %97, <2 x i64>* %98, align 16
  %99 = bitcast <2 x i64>* %18 to <4 x i32>*
  %100 = load <4 x i32>, <4 x i32>* %99, align 16
  %101 = bitcast <2 x i64>* %26 to <4 x i32>*
  %102 = bitcast <2 x i64> %25 to <4 x i32>
  %103 = shufflevector <4 x i32> %100, <4 x i32> %102, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %104 = bitcast <4 x i32> %103 to <2 x i64>
  %105 = shufflevector <4 x i32> %100, <4 x i32> %102, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %106 = bitcast <4 x i32> %105 to <2 x i64>
  %107 = bitcast <2 x i64>* %34 to <4 x i32>*
  %108 = bitcast <2 x i64> %33 to <4 x i32>
  %109 = bitcast <2 x i64>* %42 to <4 x i32>*
  %110 = bitcast <2 x i64> %41 to <4 x i32>
  %111 = shufflevector <4 x i32> %108, <4 x i32> %110, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %112 = bitcast <4 x i32> %111 to <2 x i64>
  %113 = shufflevector <4 x i32> %108, <4 x i32> %110, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %114 = bitcast <4 x i32> %113 to <2 x i64>
  %115 = shufflevector <2 x i64> %104, <2 x i64> %112, <2 x i32> <i32 0, i32 2>
  %116 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  store <2 x i64> %115, <2 x i64>* %116, align 16
  %117 = shufflevector <2 x i64> %104, <2 x i64> %112, <2 x i32> <i32 1, i32 3>
  %118 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  store <2 x i64> %117, <2 x i64>* %118, align 16
  %119 = shufflevector <2 x i64> %106, <2 x i64> %114, <2 x i32> <i32 0, i32 2>
  %120 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 12
  store <2 x i64> %119, <2 x i64>* %120, align 16
  %121 = shufflevector <2 x i64> %106, <2 x i64> %114, <2 x i32> <i32 1, i32 3>
  %122 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 14
  store <2 x i64> %121, <2 x i64>* %122, align 16
  %123 = bitcast <2 x i64>* %46 to <4 x i32>*
  %124 = load <4 x i32>, <4 x i32>* %123, align 16
  %125 = bitcast <2 x i64>* %54 to <4 x i32>*
  %126 = bitcast <2 x i64> %53 to <4 x i32>
  %127 = shufflevector <4 x i32> %124, <4 x i32> %126, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %128 = bitcast <4 x i32> %127 to <2 x i64>
  %129 = shufflevector <4 x i32> %124, <4 x i32> %126, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %130 = bitcast <4 x i32> %129 to <2 x i64>
  %131 = bitcast <2 x i64>* %62 to <4 x i32>*
  %132 = bitcast <2 x i64> %61 to <4 x i32>
  %133 = bitcast <2 x i64>* %70 to <4 x i32>*
  %134 = bitcast <2 x i64> %69 to <4 x i32>
  %135 = shufflevector <4 x i32> %132, <4 x i32> %134, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %136 = bitcast <4 x i32> %135 to <2 x i64>
  %137 = shufflevector <4 x i32> %132, <4 x i32> %134, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %138 = bitcast <4 x i32> %137 to <2 x i64>
  %139 = shufflevector <2 x i64> %128, <2 x i64> %136, <2 x i32> <i32 0, i32 2>
  %140 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %139, <2 x i64>* %140, align 16
  %141 = shufflevector <2 x i64> %128, <2 x i64> %136, <2 x i32> <i32 1, i32 3>
  %142 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %141, <2 x i64>* %142, align 16
  %143 = shufflevector <2 x i64> %130, <2 x i64> %138, <2 x i32> <i32 0, i32 2>
  %144 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 5
  store <2 x i64> %143, <2 x i64>* %144, align 16
  %145 = shufflevector <2 x i64> %130, <2 x i64> %138, <2 x i32> <i32 1, i32 3>
  %146 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 7
  store <2 x i64> %145, <2 x i64>* %146, align 16
  %147 = bitcast <2 x i64>* %50 to <4 x i32>*
  %148 = load <4 x i32>, <4 x i32>* %147, align 16
  %149 = bitcast <2 x i64>* %58 to <4 x i32>*
  %150 = load <4 x i32>, <4 x i32>* %149, align 16
  %151 = shufflevector <4 x i32> %148, <4 x i32> %150, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %152 = bitcast <4 x i32> %151 to <2 x i64>
  %153 = shufflevector <4 x i32> %148, <4 x i32> %150, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %154 = bitcast <4 x i32> %153 to <2 x i64>
  %155 = bitcast <2 x i64>* %66 to <4 x i32>*
  %156 = load <4 x i32>, <4 x i32>* %155, align 16
  %157 = bitcast <2 x i64>* %74 to <4 x i32>*
  %158 = load <4 x i32>, <4 x i32>* %157, align 16
  %159 = shufflevector <4 x i32> %156, <4 x i32> %158, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %160 = bitcast <4 x i32> %159 to <2 x i64>
  %161 = shufflevector <4 x i32> %156, <4 x i32> %158, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %162 = bitcast <4 x i32> %161 to <2 x i64>
  %163 = shufflevector <2 x i64> %152, <2 x i64> %160, <2 x i32> <i32 0, i32 2>
  %164 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  store <2 x i64> %163, <2 x i64>* %164, align 16
  %165 = shufflevector <2 x i64> %152, <2 x i64> %160, <2 x i32> <i32 1, i32 3>
  %166 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  store <2 x i64> %165, <2 x i64>* %166, align 16
  %167 = shufflevector <2 x i64> %154, <2 x i64> %162, <2 x i32> <i32 0, i32 2>
  %168 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 13
  store <2 x i64> %167, <2 x i64>* %168, align 16
  %169 = shufflevector <2 x i64> %154, <2 x i64> %162, <2 x i32> <i32 1, i32 3>
  %170 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 15
  store <2 x i64> %169, <2 x i64>* %170, align 16
  %171 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 1, i64 1), align 1
  %172 = sext i8 %171 to i32
  %173 = load i8, i8* %10, align 1
  %174 = sext i8 %173 to i32
  %175 = sub nsw i32 0, %174
  call fastcc void @idct8x8_sse4_1(<2 x i64>* nonnull %75, <2 x i64>* nonnull %12, i32 %172, i32 0, i32 %4, i32 %175)
  %176 = load <4 x i32>, <4 x i32>* %76, align 16
  %177 = load <4 x i32>, <4 x i32>* %78, align 16
  %178 = shufflevector <4 x i32> %176, <4 x i32> %177, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %179 = bitcast <4 x i32> %178 to <2 x i64>
  %180 = shufflevector <4 x i32> %176, <4 x i32> %177, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %181 = bitcast <4 x i32> %180 to <2 x i64>
  %182 = load <4 x i32>, <4 x i32>* %84, align 16
  %183 = load <4 x i32>, <4 x i32>* %86, align 16
  %184 = shufflevector <4 x i32> %182, <4 x i32> %183, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %185 = bitcast <4 x i32> %184 to <2 x i64>
  %186 = shufflevector <4 x i32> %182, <4 x i32> %183, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %187 = bitcast <4 x i32> %186 to <2 x i64>
  %188 = shufflevector <2 x i64> %179, <2 x i64> %185, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %188, <2 x i64>* %75, align 16
  %189 = shufflevector <2 x i64> %179, <2 x i64> %185, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %189, <2 x i64>* %94, align 16
  %190 = shufflevector <2 x i64> %181, <2 x i64> %187, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %190, <2 x i64>* %96, align 16
  %191 = shufflevector <2 x i64> %181, <2 x i64> %187, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %191, <2 x i64>* %98, align 16
  %192 = load <4 x i32>, <4 x i32>* %99, align 16
  %193 = load <4 x i32>, <4 x i32>* %101, align 16
  %194 = shufflevector <4 x i32> %192, <4 x i32> %193, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %195 = bitcast <4 x i32> %194 to <2 x i64>
  %196 = shufflevector <4 x i32> %192, <4 x i32> %193, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %197 = bitcast <4 x i32> %196 to <2 x i64>
  %198 = load <4 x i32>, <4 x i32>* %107, align 16
  %199 = load <4 x i32>, <4 x i32>* %109, align 16
  %200 = shufflevector <4 x i32> %198, <4 x i32> %199, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %201 = bitcast <4 x i32> %200 to <2 x i64>
  %202 = shufflevector <4 x i32> %198, <4 x i32> %199, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %203 = bitcast <4 x i32> %202 to <2 x i64>
  %204 = shufflevector <2 x i64> %195, <2 x i64> %201, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %204, <2 x i64>* %116, align 16
  %205 = shufflevector <2 x i64> %195, <2 x i64> %201, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %205, <2 x i64>* %118, align 16
  %206 = shufflevector <2 x i64> %197, <2 x i64> %203, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %206, <2 x i64>* %120, align 16
  %207 = shufflevector <2 x i64> %197, <2 x i64> %203, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %207, <2 x i64>* %122, align 16
  %208 = load <4 x i32>, <4 x i32>* %123, align 16
  %209 = load <4 x i32>, <4 x i32>* %125, align 16
  %210 = shufflevector <4 x i32> %208, <4 x i32> %209, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %211 = bitcast <4 x i32> %210 to <2 x i64>
  %212 = shufflevector <4 x i32> %208, <4 x i32> %209, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %213 = bitcast <4 x i32> %212 to <2 x i64>
  %214 = load <4 x i32>, <4 x i32>* %131, align 16
  %215 = load <4 x i32>, <4 x i32>* %133, align 16
  %216 = shufflevector <4 x i32> %214, <4 x i32> %215, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %217 = bitcast <4 x i32> %216 to <2 x i64>
  %218 = shufflevector <4 x i32> %214, <4 x i32> %215, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %219 = bitcast <4 x i32> %218 to <2 x i64>
  %220 = shufflevector <2 x i64> %211, <2 x i64> %217, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %220, <2 x i64>* %140, align 16
  %221 = shufflevector <2 x i64> %211, <2 x i64> %217, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %221, <2 x i64>* %142, align 16
  %222 = shufflevector <2 x i64> %213, <2 x i64> %219, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %222, <2 x i64>* %144, align 16
  %223 = shufflevector <2 x i64> %213, <2 x i64> %219, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %223, <2 x i64>* %146, align 16
  %224 = load <4 x i32>, <4 x i32>* %147, align 16
  %225 = load <4 x i32>, <4 x i32>* %149, align 16
  %226 = shufflevector <4 x i32> %224, <4 x i32> %225, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %227 = bitcast <4 x i32> %226 to <2 x i64>
  %228 = shufflevector <4 x i32> %224, <4 x i32> %225, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %229 = bitcast <4 x i32> %228 to <2 x i64>
  %230 = load <4 x i32>, <4 x i32>* %155, align 16
  %231 = load <4 x i32>, <4 x i32>* %157, align 16
  %232 = shufflevector <4 x i32> %230, <4 x i32> %231, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %233 = bitcast <4 x i32> %232 to <2 x i64>
  %234 = shufflevector <4 x i32> %230, <4 x i32> %231, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %235 = bitcast <4 x i32> %234 to <2 x i64>
  %236 = shufflevector <2 x i64> %227, <2 x i64> %233, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %236, <2 x i64>* %164, align 16
  %237 = shufflevector <2 x i64> %227, <2 x i64> %233, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %237, <2 x i64>* %166, align 16
  %238 = shufflevector <2 x i64> %229, <2 x i64> %235, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %238, <2 x i64>* %168, align 16
  %239 = shufflevector <2 x i64> %229, <2 x i64> %235, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %239, <2 x i64>* %170, align 16
  %240 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 1, i64 1), align 1
  %241 = sext i8 %240 to i32
  call fastcc void @idct8x8_sse4_1(<2 x i64>* nonnull %75, <2 x i64>* nonnull %12, i32 %241, i32 1, i32 %4, i32 0)
  %242 = getelementptr inbounds i8, i8* %10, i64 1
  %243 = load i8, i8* %242, align 1
  %244 = sext i8 %243 to i32
  %245 = sub nsw i32 0, %244
  call fastcc void @write_buffer_8x8(<2 x i64>* nonnull %12, i16* %1, i32 %2, i32 0, i32 0, i32 %245, i32 %4)
  br label %2126

246:                                              ; preds = %5
  %247 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %248 = bitcast i32* %0 to <2 x i64>*
  %249 = load <2 x i64>, <2 x i64>* %248, align 16
  store <2 x i64> %249, <2 x i64>* %247, align 16
  %250 = getelementptr inbounds i32, i32* %0, i64 4
  %251 = bitcast i32* %250 to <2 x i64>*
  %252 = load <2 x i64>, <2 x i64>* %251, align 16
  %253 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %252, <2 x i64>* %253, align 16
  %254 = getelementptr inbounds i32, i32* %0, i64 8
  %255 = bitcast i32* %254 to <2 x i64>*
  %256 = load <2 x i64>, <2 x i64>* %255, align 16
  %257 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %256, <2 x i64>* %257, align 16
  %258 = getelementptr inbounds i32, i32* %0, i64 12
  %259 = bitcast i32* %258 to <2 x i64>*
  %260 = load <2 x i64>, <2 x i64>* %259, align 16
  %261 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %260, <2 x i64>* %261, align 16
  %262 = getelementptr inbounds i32, i32* %0, i64 16
  %263 = bitcast i32* %262 to <2 x i64>*
  %264 = load <2 x i64>, <2 x i64>* %263, align 16
  %265 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %264, <2 x i64>* %265, align 16
  %266 = getelementptr inbounds i32, i32* %0, i64 20
  %267 = bitcast i32* %266 to <2 x i64>*
  %268 = load <2 x i64>, <2 x i64>* %267, align 16
  %269 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %268, <2 x i64>* %269, align 16
  %270 = getelementptr inbounds i32, i32* %0, i64 24
  %271 = bitcast i32* %270 to <2 x i64>*
  %272 = load <2 x i64>, <2 x i64>* %271, align 16
  %273 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %272, <2 x i64>* %273, align 16
  %274 = getelementptr inbounds i32, i32* %0, i64 28
  %275 = bitcast i32* %274 to <2 x i64>*
  %276 = load <2 x i64>, <2 x i64>* %275, align 16
  %277 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %276, <2 x i64>* %277, align 16
  %278 = getelementptr inbounds i32, i32* %0, i64 32
  %279 = bitcast i32* %278 to <2 x i64>*
  %280 = load <2 x i64>, <2 x i64>* %279, align 16
  %281 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %280, <2 x i64>* %281, align 16
  %282 = getelementptr inbounds i32, i32* %0, i64 36
  %283 = bitcast i32* %282 to <2 x i64>*
  %284 = load <2 x i64>, <2 x i64>* %283, align 16
  %285 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %284, <2 x i64>* %285, align 16
  %286 = getelementptr inbounds i32, i32* %0, i64 40
  %287 = bitcast i32* %286 to <2 x i64>*
  %288 = load <2 x i64>, <2 x i64>* %287, align 16
  %289 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %288, <2 x i64>* %289, align 16
  %290 = getelementptr inbounds i32, i32* %0, i64 44
  %291 = bitcast i32* %290 to <2 x i64>*
  %292 = load <2 x i64>, <2 x i64>* %291, align 16
  %293 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %292, <2 x i64>* %293, align 16
  %294 = getelementptr inbounds i32, i32* %0, i64 48
  %295 = bitcast i32* %294 to <2 x i64>*
  %296 = load <2 x i64>, <2 x i64>* %295, align 16
  %297 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %296, <2 x i64>* %297, align 16
  %298 = getelementptr inbounds i32, i32* %0, i64 52
  %299 = bitcast i32* %298 to <2 x i64>*
  %300 = load <2 x i64>, <2 x i64>* %299, align 16
  %301 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %300, <2 x i64>* %301, align 16
  %302 = getelementptr inbounds i32, i32* %0, i64 56
  %303 = bitcast i32* %302 to <2 x i64>*
  %304 = load <2 x i64>, <2 x i64>* %303, align 16
  %305 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %304, <2 x i64>* %305, align 16
  %306 = getelementptr inbounds i32, i32* %0, i64 60
  %307 = bitcast i32* %306 to <2 x i64>*
  %308 = load <2 x i64>, <2 x i64>* %307, align 16
  %309 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %308, <2 x i64>* %309, align 16
  %310 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  %311 = bitcast [16 x <2 x i64>]* %6 to <4 x i32>*
  %312 = bitcast <2 x i64> %249 to <4 x i32>
  %313 = bitcast <2 x i64>* %257 to <4 x i32>*
  %314 = bitcast <2 x i64> %256 to <4 x i32>
  %315 = shufflevector <4 x i32> %312, <4 x i32> %314, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %316 = bitcast <4 x i32> %315 to <2 x i64>
  %317 = shufflevector <4 x i32> %312, <4 x i32> %314, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %318 = bitcast <4 x i32> %317 to <2 x i64>
  %319 = bitcast <2 x i64>* %265 to <4 x i32>*
  %320 = bitcast <2 x i64> %264 to <4 x i32>
  %321 = bitcast <2 x i64>* %273 to <4 x i32>*
  %322 = bitcast <2 x i64> %272 to <4 x i32>
  %323 = shufflevector <4 x i32> %320, <4 x i32> %322, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %324 = bitcast <4 x i32> %323 to <2 x i64>
  %325 = shufflevector <4 x i32> %320, <4 x i32> %322, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %326 = bitcast <4 x i32> %325 to <2 x i64>
  %327 = shufflevector <2 x i64> %316, <2 x i64> %324, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %327, <2 x i64>* %310, align 16
  %328 = shufflevector <2 x i64> %316, <2 x i64> %324, <2 x i32> <i32 1, i32 3>
  %329 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %328, <2 x i64>* %329, align 16
  %330 = shufflevector <2 x i64> %318, <2 x i64> %326, <2 x i32> <i32 0, i32 2>
  %331 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 4
  store <2 x i64> %330, <2 x i64>* %331, align 16
  %332 = shufflevector <2 x i64> %318, <2 x i64> %326, <2 x i32> <i32 1, i32 3>
  %333 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 6
  store <2 x i64> %332, <2 x i64>* %333, align 16
  %334 = bitcast <2 x i64>* %253 to <4 x i32>*
  %335 = load <4 x i32>, <4 x i32>* %334, align 16
  %336 = bitcast <2 x i64>* %261 to <4 x i32>*
  %337 = bitcast <2 x i64> %260 to <4 x i32>
  %338 = shufflevector <4 x i32> %335, <4 x i32> %337, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %339 = bitcast <4 x i32> %338 to <2 x i64>
  %340 = shufflevector <4 x i32> %335, <4 x i32> %337, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %341 = bitcast <4 x i32> %340 to <2 x i64>
  %342 = bitcast <2 x i64>* %269 to <4 x i32>*
  %343 = bitcast <2 x i64> %268 to <4 x i32>
  %344 = bitcast <2 x i64>* %277 to <4 x i32>*
  %345 = bitcast <2 x i64> %276 to <4 x i32>
  %346 = shufflevector <4 x i32> %343, <4 x i32> %345, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %347 = bitcast <4 x i32> %346 to <2 x i64>
  %348 = shufflevector <4 x i32> %343, <4 x i32> %345, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %349 = bitcast <4 x i32> %348 to <2 x i64>
  %350 = shufflevector <2 x i64> %339, <2 x i64> %347, <2 x i32> <i32 0, i32 2>
  %351 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  store <2 x i64> %350, <2 x i64>* %351, align 16
  %352 = shufflevector <2 x i64> %339, <2 x i64> %347, <2 x i32> <i32 1, i32 3>
  %353 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  store <2 x i64> %352, <2 x i64>* %353, align 16
  %354 = shufflevector <2 x i64> %341, <2 x i64> %349, <2 x i32> <i32 0, i32 2>
  %355 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 12
  store <2 x i64> %354, <2 x i64>* %355, align 16
  %356 = shufflevector <2 x i64> %341, <2 x i64> %349, <2 x i32> <i32 1, i32 3>
  %357 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 14
  store <2 x i64> %356, <2 x i64>* %357, align 16
  %358 = bitcast <2 x i64>* %281 to <4 x i32>*
  %359 = load <4 x i32>, <4 x i32>* %358, align 16
  %360 = bitcast <2 x i64>* %289 to <4 x i32>*
  %361 = bitcast <2 x i64> %288 to <4 x i32>
  %362 = shufflevector <4 x i32> %359, <4 x i32> %361, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %363 = bitcast <4 x i32> %362 to <2 x i64>
  %364 = shufflevector <4 x i32> %359, <4 x i32> %361, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %365 = bitcast <4 x i32> %364 to <2 x i64>
  %366 = bitcast <2 x i64>* %297 to <4 x i32>*
  %367 = bitcast <2 x i64> %296 to <4 x i32>
  %368 = bitcast <2 x i64>* %305 to <4 x i32>*
  %369 = bitcast <2 x i64> %304 to <4 x i32>
  %370 = shufflevector <4 x i32> %367, <4 x i32> %369, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %371 = bitcast <4 x i32> %370 to <2 x i64>
  %372 = shufflevector <4 x i32> %367, <4 x i32> %369, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %373 = bitcast <4 x i32> %372 to <2 x i64>
  %374 = shufflevector <2 x i64> %363, <2 x i64> %371, <2 x i32> <i32 0, i32 2>
  %375 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %374, <2 x i64>* %375, align 16
  %376 = shufflevector <2 x i64> %363, <2 x i64> %371, <2 x i32> <i32 1, i32 3>
  %377 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %376, <2 x i64>* %377, align 16
  %378 = shufflevector <2 x i64> %365, <2 x i64> %373, <2 x i32> <i32 0, i32 2>
  %379 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 5
  store <2 x i64> %378, <2 x i64>* %379, align 16
  %380 = shufflevector <2 x i64> %365, <2 x i64> %373, <2 x i32> <i32 1, i32 3>
  %381 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 7
  store <2 x i64> %380, <2 x i64>* %381, align 16
  %382 = bitcast <2 x i64>* %285 to <4 x i32>*
  %383 = load <4 x i32>, <4 x i32>* %382, align 16
  %384 = bitcast <2 x i64>* %293 to <4 x i32>*
  %385 = load <4 x i32>, <4 x i32>* %384, align 16
  %386 = shufflevector <4 x i32> %383, <4 x i32> %385, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %387 = bitcast <4 x i32> %386 to <2 x i64>
  %388 = shufflevector <4 x i32> %383, <4 x i32> %385, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %389 = bitcast <4 x i32> %388 to <2 x i64>
  %390 = bitcast <2 x i64>* %301 to <4 x i32>*
  %391 = load <4 x i32>, <4 x i32>* %390, align 16
  %392 = bitcast <2 x i64>* %309 to <4 x i32>*
  %393 = load <4 x i32>, <4 x i32>* %392, align 16
  %394 = shufflevector <4 x i32> %391, <4 x i32> %393, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %395 = bitcast <4 x i32> %394 to <2 x i64>
  %396 = shufflevector <4 x i32> %391, <4 x i32> %393, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %397 = bitcast <4 x i32> %396 to <2 x i64>
  %398 = shufflevector <2 x i64> %387, <2 x i64> %395, <2 x i32> <i32 0, i32 2>
  %399 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  store <2 x i64> %398, <2 x i64>* %399, align 16
  %400 = shufflevector <2 x i64> %387, <2 x i64> %395, <2 x i32> <i32 1, i32 3>
  %401 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  store <2 x i64> %400, <2 x i64>* %401, align 16
  %402 = shufflevector <2 x i64> %389, <2 x i64> %397, <2 x i32> <i32 0, i32 2>
  %403 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 13
  store <2 x i64> %402, <2 x i64>* %403, align 16
  %404 = shufflevector <2 x i64> %389, <2 x i64> %397, <2 x i32> <i32 1, i32 3>
  %405 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 15
  store <2 x i64> %404, <2 x i64>* %405, align 16
  %406 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 1, i64 1), align 1
  %407 = sext i8 %406 to i32
  %408 = load i8, i8* %10, align 1
  %409 = sext i8 %408 to i32
  %410 = sub nsw i32 0, %409
  call fastcc void @iadst8x8_sse4_1(<2 x i64>* nonnull %310, <2 x i64>* nonnull %247, i32 %407, i32 0, i32 %4, i32 %410)
  %411 = load <4 x i32>, <4 x i32>* %311, align 16
  %412 = load <4 x i32>, <4 x i32>* %313, align 16
  %413 = shufflevector <4 x i32> %411, <4 x i32> %412, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %414 = bitcast <4 x i32> %413 to <2 x i64>
  %415 = shufflevector <4 x i32> %411, <4 x i32> %412, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %416 = bitcast <4 x i32> %415 to <2 x i64>
  %417 = load <4 x i32>, <4 x i32>* %319, align 16
  %418 = load <4 x i32>, <4 x i32>* %321, align 16
  %419 = shufflevector <4 x i32> %417, <4 x i32> %418, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %420 = bitcast <4 x i32> %419 to <2 x i64>
  %421 = shufflevector <4 x i32> %417, <4 x i32> %418, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %422 = bitcast <4 x i32> %421 to <2 x i64>
  %423 = shufflevector <2 x i64> %414, <2 x i64> %420, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %423, <2 x i64>* %310, align 16
  %424 = shufflevector <2 x i64> %414, <2 x i64> %420, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %424, <2 x i64>* %329, align 16
  %425 = shufflevector <2 x i64> %416, <2 x i64> %422, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %425, <2 x i64>* %331, align 16
  %426 = shufflevector <2 x i64> %416, <2 x i64> %422, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %426, <2 x i64>* %333, align 16
  %427 = load <4 x i32>, <4 x i32>* %334, align 16
  %428 = load <4 x i32>, <4 x i32>* %336, align 16
  %429 = shufflevector <4 x i32> %427, <4 x i32> %428, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %430 = bitcast <4 x i32> %429 to <2 x i64>
  %431 = shufflevector <4 x i32> %427, <4 x i32> %428, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %432 = bitcast <4 x i32> %431 to <2 x i64>
  %433 = load <4 x i32>, <4 x i32>* %342, align 16
  %434 = load <4 x i32>, <4 x i32>* %344, align 16
  %435 = shufflevector <4 x i32> %433, <4 x i32> %434, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %436 = bitcast <4 x i32> %435 to <2 x i64>
  %437 = shufflevector <4 x i32> %433, <4 x i32> %434, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %438 = bitcast <4 x i32> %437 to <2 x i64>
  %439 = shufflevector <2 x i64> %430, <2 x i64> %436, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %439, <2 x i64>* %351, align 16
  %440 = shufflevector <2 x i64> %430, <2 x i64> %436, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %440, <2 x i64>* %353, align 16
  %441 = shufflevector <2 x i64> %432, <2 x i64> %438, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %441, <2 x i64>* %355, align 16
  %442 = shufflevector <2 x i64> %432, <2 x i64> %438, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %442, <2 x i64>* %357, align 16
  %443 = load <4 x i32>, <4 x i32>* %358, align 16
  %444 = load <4 x i32>, <4 x i32>* %360, align 16
  %445 = shufflevector <4 x i32> %443, <4 x i32> %444, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %446 = bitcast <4 x i32> %445 to <2 x i64>
  %447 = shufflevector <4 x i32> %443, <4 x i32> %444, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %448 = bitcast <4 x i32> %447 to <2 x i64>
  %449 = load <4 x i32>, <4 x i32>* %366, align 16
  %450 = load <4 x i32>, <4 x i32>* %368, align 16
  %451 = shufflevector <4 x i32> %449, <4 x i32> %450, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %452 = bitcast <4 x i32> %451 to <2 x i64>
  %453 = shufflevector <4 x i32> %449, <4 x i32> %450, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %454 = bitcast <4 x i32> %453 to <2 x i64>
  %455 = shufflevector <2 x i64> %446, <2 x i64> %452, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %455, <2 x i64>* %375, align 16
  %456 = shufflevector <2 x i64> %446, <2 x i64> %452, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %456, <2 x i64>* %377, align 16
  %457 = shufflevector <2 x i64> %448, <2 x i64> %454, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %457, <2 x i64>* %379, align 16
  %458 = shufflevector <2 x i64> %448, <2 x i64> %454, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %458, <2 x i64>* %381, align 16
  %459 = load <4 x i32>, <4 x i32>* %382, align 16
  %460 = load <4 x i32>, <4 x i32>* %384, align 16
  %461 = shufflevector <4 x i32> %459, <4 x i32> %460, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %462 = bitcast <4 x i32> %461 to <2 x i64>
  %463 = shufflevector <4 x i32> %459, <4 x i32> %460, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %464 = bitcast <4 x i32> %463 to <2 x i64>
  %465 = load <4 x i32>, <4 x i32>* %390, align 16
  %466 = load <4 x i32>, <4 x i32>* %392, align 16
  %467 = shufflevector <4 x i32> %465, <4 x i32> %466, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %468 = bitcast <4 x i32> %467 to <2 x i64>
  %469 = shufflevector <4 x i32> %465, <4 x i32> %466, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %470 = bitcast <4 x i32> %469 to <2 x i64>
  %471 = shufflevector <2 x i64> %462, <2 x i64> %468, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %471, <2 x i64>* %399, align 16
  %472 = shufflevector <2 x i64> %462, <2 x i64> %468, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %472, <2 x i64>* %401, align 16
  %473 = shufflevector <2 x i64> %464, <2 x i64> %470, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %473, <2 x i64>* %403, align 16
  %474 = shufflevector <2 x i64> %464, <2 x i64> %470, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %474, <2 x i64>* %405, align 16
  %475 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 1, i64 1), align 1
  %476 = sext i8 %475 to i32
  call fastcc void @idct8x8_sse4_1(<2 x i64>* nonnull %310, <2 x i64>* nonnull %247, i32 %476, i32 1, i32 %4, i32 0)
  %477 = getelementptr inbounds i8, i8* %10, i64 1
  %478 = load i8, i8* %477, align 1
  %479 = sext i8 %478 to i32
  %480 = sub nsw i32 0, %479
  call fastcc void @write_buffer_8x8(<2 x i64>* nonnull %247, i16* %1, i32 %2, i32 0, i32 0, i32 %480, i32 %4)
  br label %2126

481:                                              ; preds = %5
  %482 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %483 = bitcast i32* %0 to <2 x i64>*
  %484 = load <2 x i64>, <2 x i64>* %483, align 16
  store <2 x i64> %484, <2 x i64>* %482, align 16
  %485 = getelementptr inbounds i32, i32* %0, i64 4
  %486 = bitcast i32* %485 to <2 x i64>*
  %487 = load <2 x i64>, <2 x i64>* %486, align 16
  %488 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %487, <2 x i64>* %488, align 16
  %489 = getelementptr inbounds i32, i32* %0, i64 8
  %490 = bitcast i32* %489 to <2 x i64>*
  %491 = load <2 x i64>, <2 x i64>* %490, align 16
  %492 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %491, <2 x i64>* %492, align 16
  %493 = getelementptr inbounds i32, i32* %0, i64 12
  %494 = bitcast i32* %493 to <2 x i64>*
  %495 = load <2 x i64>, <2 x i64>* %494, align 16
  %496 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %495, <2 x i64>* %496, align 16
  %497 = getelementptr inbounds i32, i32* %0, i64 16
  %498 = bitcast i32* %497 to <2 x i64>*
  %499 = load <2 x i64>, <2 x i64>* %498, align 16
  %500 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %499, <2 x i64>* %500, align 16
  %501 = getelementptr inbounds i32, i32* %0, i64 20
  %502 = bitcast i32* %501 to <2 x i64>*
  %503 = load <2 x i64>, <2 x i64>* %502, align 16
  %504 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %503, <2 x i64>* %504, align 16
  %505 = getelementptr inbounds i32, i32* %0, i64 24
  %506 = bitcast i32* %505 to <2 x i64>*
  %507 = load <2 x i64>, <2 x i64>* %506, align 16
  %508 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %507, <2 x i64>* %508, align 16
  %509 = getelementptr inbounds i32, i32* %0, i64 28
  %510 = bitcast i32* %509 to <2 x i64>*
  %511 = load <2 x i64>, <2 x i64>* %510, align 16
  %512 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %511, <2 x i64>* %512, align 16
  %513 = getelementptr inbounds i32, i32* %0, i64 32
  %514 = bitcast i32* %513 to <2 x i64>*
  %515 = load <2 x i64>, <2 x i64>* %514, align 16
  %516 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %515, <2 x i64>* %516, align 16
  %517 = getelementptr inbounds i32, i32* %0, i64 36
  %518 = bitcast i32* %517 to <2 x i64>*
  %519 = load <2 x i64>, <2 x i64>* %518, align 16
  %520 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %519, <2 x i64>* %520, align 16
  %521 = getelementptr inbounds i32, i32* %0, i64 40
  %522 = bitcast i32* %521 to <2 x i64>*
  %523 = load <2 x i64>, <2 x i64>* %522, align 16
  %524 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %523, <2 x i64>* %524, align 16
  %525 = getelementptr inbounds i32, i32* %0, i64 44
  %526 = bitcast i32* %525 to <2 x i64>*
  %527 = load <2 x i64>, <2 x i64>* %526, align 16
  %528 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %527, <2 x i64>* %528, align 16
  %529 = getelementptr inbounds i32, i32* %0, i64 48
  %530 = bitcast i32* %529 to <2 x i64>*
  %531 = load <2 x i64>, <2 x i64>* %530, align 16
  %532 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %531, <2 x i64>* %532, align 16
  %533 = getelementptr inbounds i32, i32* %0, i64 52
  %534 = bitcast i32* %533 to <2 x i64>*
  %535 = load <2 x i64>, <2 x i64>* %534, align 16
  %536 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %535, <2 x i64>* %536, align 16
  %537 = getelementptr inbounds i32, i32* %0, i64 56
  %538 = bitcast i32* %537 to <2 x i64>*
  %539 = load <2 x i64>, <2 x i64>* %538, align 16
  %540 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %539, <2 x i64>* %540, align 16
  %541 = getelementptr inbounds i32, i32* %0, i64 60
  %542 = bitcast i32* %541 to <2 x i64>*
  %543 = load <2 x i64>, <2 x i64>* %542, align 16
  %544 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %543, <2 x i64>* %544, align 16
  %545 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  %546 = bitcast [16 x <2 x i64>]* %6 to <4 x i32>*
  %547 = bitcast <2 x i64> %484 to <4 x i32>
  %548 = bitcast <2 x i64>* %492 to <4 x i32>*
  %549 = bitcast <2 x i64> %491 to <4 x i32>
  %550 = shufflevector <4 x i32> %547, <4 x i32> %549, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %551 = bitcast <4 x i32> %550 to <2 x i64>
  %552 = shufflevector <4 x i32> %547, <4 x i32> %549, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %553 = bitcast <4 x i32> %552 to <2 x i64>
  %554 = bitcast <2 x i64>* %500 to <4 x i32>*
  %555 = bitcast <2 x i64> %499 to <4 x i32>
  %556 = bitcast <2 x i64>* %508 to <4 x i32>*
  %557 = bitcast <2 x i64> %507 to <4 x i32>
  %558 = shufflevector <4 x i32> %555, <4 x i32> %557, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %559 = bitcast <4 x i32> %558 to <2 x i64>
  %560 = shufflevector <4 x i32> %555, <4 x i32> %557, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %561 = bitcast <4 x i32> %560 to <2 x i64>
  %562 = shufflevector <2 x i64> %551, <2 x i64> %559, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %562, <2 x i64>* %545, align 16
  %563 = shufflevector <2 x i64> %551, <2 x i64> %559, <2 x i32> <i32 1, i32 3>
  %564 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %563, <2 x i64>* %564, align 16
  %565 = shufflevector <2 x i64> %553, <2 x i64> %561, <2 x i32> <i32 0, i32 2>
  %566 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 4
  store <2 x i64> %565, <2 x i64>* %566, align 16
  %567 = shufflevector <2 x i64> %553, <2 x i64> %561, <2 x i32> <i32 1, i32 3>
  %568 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 6
  store <2 x i64> %567, <2 x i64>* %568, align 16
  %569 = bitcast <2 x i64>* %488 to <4 x i32>*
  %570 = load <4 x i32>, <4 x i32>* %569, align 16
  %571 = bitcast <2 x i64>* %496 to <4 x i32>*
  %572 = bitcast <2 x i64> %495 to <4 x i32>
  %573 = shufflevector <4 x i32> %570, <4 x i32> %572, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %574 = bitcast <4 x i32> %573 to <2 x i64>
  %575 = shufflevector <4 x i32> %570, <4 x i32> %572, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %576 = bitcast <4 x i32> %575 to <2 x i64>
  %577 = bitcast <2 x i64>* %504 to <4 x i32>*
  %578 = bitcast <2 x i64> %503 to <4 x i32>
  %579 = bitcast <2 x i64>* %512 to <4 x i32>*
  %580 = bitcast <2 x i64> %511 to <4 x i32>
  %581 = shufflevector <4 x i32> %578, <4 x i32> %580, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %582 = bitcast <4 x i32> %581 to <2 x i64>
  %583 = shufflevector <4 x i32> %578, <4 x i32> %580, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %584 = bitcast <4 x i32> %583 to <2 x i64>
  %585 = shufflevector <2 x i64> %574, <2 x i64> %582, <2 x i32> <i32 0, i32 2>
  %586 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  store <2 x i64> %585, <2 x i64>* %586, align 16
  %587 = shufflevector <2 x i64> %574, <2 x i64> %582, <2 x i32> <i32 1, i32 3>
  %588 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  store <2 x i64> %587, <2 x i64>* %588, align 16
  %589 = shufflevector <2 x i64> %576, <2 x i64> %584, <2 x i32> <i32 0, i32 2>
  %590 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 12
  store <2 x i64> %589, <2 x i64>* %590, align 16
  %591 = shufflevector <2 x i64> %576, <2 x i64> %584, <2 x i32> <i32 1, i32 3>
  %592 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 14
  store <2 x i64> %591, <2 x i64>* %592, align 16
  %593 = bitcast <2 x i64>* %516 to <4 x i32>*
  %594 = load <4 x i32>, <4 x i32>* %593, align 16
  %595 = bitcast <2 x i64>* %524 to <4 x i32>*
  %596 = bitcast <2 x i64> %523 to <4 x i32>
  %597 = shufflevector <4 x i32> %594, <4 x i32> %596, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %598 = bitcast <4 x i32> %597 to <2 x i64>
  %599 = shufflevector <4 x i32> %594, <4 x i32> %596, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %600 = bitcast <4 x i32> %599 to <2 x i64>
  %601 = bitcast <2 x i64>* %532 to <4 x i32>*
  %602 = bitcast <2 x i64> %531 to <4 x i32>
  %603 = bitcast <2 x i64>* %540 to <4 x i32>*
  %604 = bitcast <2 x i64> %539 to <4 x i32>
  %605 = shufflevector <4 x i32> %602, <4 x i32> %604, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %606 = bitcast <4 x i32> %605 to <2 x i64>
  %607 = shufflevector <4 x i32> %602, <4 x i32> %604, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %608 = bitcast <4 x i32> %607 to <2 x i64>
  %609 = shufflevector <2 x i64> %598, <2 x i64> %606, <2 x i32> <i32 0, i32 2>
  %610 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %609, <2 x i64>* %610, align 16
  %611 = shufflevector <2 x i64> %598, <2 x i64> %606, <2 x i32> <i32 1, i32 3>
  %612 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %611, <2 x i64>* %612, align 16
  %613 = shufflevector <2 x i64> %600, <2 x i64> %608, <2 x i32> <i32 0, i32 2>
  %614 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 5
  store <2 x i64> %613, <2 x i64>* %614, align 16
  %615 = shufflevector <2 x i64> %600, <2 x i64> %608, <2 x i32> <i32 1, i32 3>
  %616 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 7
  store <2 x i64> %615, <2 x i64>* %616, align 16
  %617 = bitcast <2 x i64>* %520 to <4 x i32>*
  %618 = load <4 x i32>, <4 x i32>* %617, align 16
  %619 = bitcast <2 x i64>* %528 to <4 x i32>*
  %620 = load <4 x i32>, <4 x i32>* %619, align 16
  %621 = shufflevector <4 x i32> %618, <4 x i32> %620, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %622 = bitcast <4 x i32> %621 to <2 x i64>
  %623 = shufflevector <4 x i32> %618, <4 x i32> %620, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %624 = bitcast <4 x i32> %623 to <2 x i64>
  %625 = bitcast <2 x i64>* %536 to <4 x i32>*
  %626 = load <4 x i32>, <4 x i32>* %625, align 16
  %627 = bitcast <2 x i64>* %544 to <4 x i32>*
  %628 = load <4 x i32>, <4 x i32>* %627, align 16
  %629 = shufflevector <4 x i32> %626, <4 x i32> %628, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %630 = bitcast <4 x i32> %629 to <2 x i64>
  %631 = shufflevector <4 x i32> %626, <4 x i32> %628, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %632 = bitcast <4 x i32> %631 to <2 x i64>
  %633 = shufflevector <2 x i64> %622, <2 x i64> %630, <2 x i32> <i32 0, i32 2>
  %634 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  store <2 x i64> %633, <2 x i64>* %634, align 16
  %635 = shufflevector <2 x i64> %622, <2 x i64> %630, <2 x i32> <i32 1, i32 3>
  %636 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  store <2 x i64> %635, <2 x i64>* %636, align 16
  %637 = shufflevector <2 x i64> %624, <2 x i64> %632, <2 x i32> <i32 0, i32 2>
  %638 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 13
  store <2 x i64> %637, <2 x i64>* %638, align 16
  %639 = shufflevector <2 x i64> %624, <2 x i64> %632, <2 x i32> <i32 1, i32 3>
  %640 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 15
  store <2 x i64> %639, <2 x i64>* %640, align 16
  %641 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 1, i64 1), align 1
  %642 = sext i8 %641 to i32
  %643 = load i8, i8* %10, align 1
  %644 = sext i8 %643 to i32
  %645 = sub nsw i32 0, %644
  call fastcc void @idct8x8_sse4_1(<2 x i64>* nonnull %545, <2 x i64>* nonnull %482, i32 %642, i32 0, i32 %4, i32 %645)
  %646 = load <4 x i32>, <4 x i32>* %546, align 16
  %647 = load <4 x i32>, <4 x i32>* %548, align 16
  %648 = shufflevector <4 x i32> %646, <4 x i32> %647, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %649 = bitcast <4 x i32> %648 to <2 x i64>
  %650 = shufflevector <4 x i32> %646, <4 x i32> %647, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %651 = bitcast <4 x i32> %650 to <2 x i64>
  %652 = load <4 x i32>, <4 x i32>* %554, align 16
  %653 = load <4 x i32>, <4 x i32>* %556, align 16
  %654 = shufflevector <4 x i32> %652, <4 x i32> %653, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %655 = bitcast <4 x i32> %654 to <2 x i64>
  %656 = shufflevector <4 x i32> %652, <4 x i32> %653, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %657 = bitcast <4 x i32> %656 to <2 x i64>
  %658 = shufflevector <2 x i64> %649, <2 x i64> %655, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %658, <2 x i64>* %545, align 16
  %659 = shufflevector <2 x i64> %649, <2 x i64> %655, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %659, <2 x i64>* %564, align 16
  %660 = shufflevector <2 x i64> %651, <2 x i64> %657, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %660, <2 x i64>* %566, align 16
  %661 = shufflevector <2 x i64> %651, <2 x i64> %657, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %661, <2 x i64>* %568, align 16
  %662 = load <4 x i32>, <4 x i32>* %569, align 16
  %663 = load <4 x i32>, <4 x i32>* %571, align 16
  %664 = shufflevector <4 x i32> %662, <4 x i32> %663, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %665 = bitcast <4 x i32> %664 to <2 x i64>
  %666 = shufflevector <4 x i32> %662, <4 x i32> %663, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %667 = bitcast <4 x i32> %666 to <2 x i64>
  %668 = load <4 x i32>, <4 x i32>* %577, align 16
  %669 = load <4 x i32>, <4 x i32>* %579, align 16
  %670 = shufflevector <4 x i32> %668, <4 x i32> %669, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %671 = bitcast <4 x i32> %670 to <2 x i64>
  %672 = shufflevector <4 x i32> %668, <4 x i32> %669, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %673 = bitcast <4 x i32> %672 to <2 x i64>
  %674 = shufflevector <2 x i64> %665, <2 x i64> %671, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %674, <2 x i64>* %586, align 16
  %675 = shufflevector <2 x i64> %665, <2 x i64> %671, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %675, <2 x i64>* %588, align 16
  %676 = shufflevector <2 x i64> %667, <2 x i64> %673, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %676, <2 x i64>* %590, align 16
  %677 = shufflevector <2 x i64> %667, <2 x i64> %673, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %677, <2 x i64>* %592, align 16
  %678 = load <4 x i32>, <4 x i32>* %593, align 16
  %679 = load <4 x i32>, <4 x i32>* %595, align 16
  %680 = shufflevector <4 x i32> %678, <4 x i32> %679, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %681 = bitcast <4 x i32> %680 to <2 x i64>
  %682 = shufflevector <4 x i32> %678, <4 x i32> %679, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %683 = bitcast <4 x i32> %682 to <2 x i64>
  %684 = load <4 x i32>, <4 x i32>* %601, align 16
  %685 = load <4 x i32>, <4 x i32>* %603, align 16
  %686 = shufflevector <4 x i32> %684, <4 x i32> %685, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %687 = bitcast <4 x i32> %686 to <2 x i64>
  %688 = shufflevector <4 x i32> %684, <4 x i32> %685, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %689 = bitcast <4 x i32> %688 to <2 x i64>
  %690 = shufflevector <2 x i64> %681, <2 x i64> %687, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %690, <2 x i64>* %610, align 16
  %691 = shufflevector <2 x i64> %681, <2 x i64> %687, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %691, <2 x i64>* %612, align 16
  %692 = shufflevector <2 x i64> %683, <2 x i64> %689, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %692, <2 x i64>* %614, align 16
  %693 = shufflevector <2 x i64> %683, <2 x i64> %689, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %693, <2 x i64>* %616, align 16
  %694 = load <4 x i32>, <4 x i32>* %617, align 16
  %695 = load <4 x i32>, <4 x i32>* %619, align 16
  %696 = shufflevector <4 x i32> %694, <4 x i32> %695, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %697 = bitcast <4 x i32> %696 to <2 x i64>
  %698 = shufflevector <4 x i32> %694, <4 x i32> %695, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %699 = bitcast <4 x i32> %698 to <2 x i64>
  %700 = load <4 x i32>, <4 x i32>* %625, align 16
  %701 = load <4 x i32>, <4 x i32>* %627, align 16
  %702 = shufflevector <4 x i32> %700, <4 x i32> %701, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %703 = bitcast <4 x i32> %702 to <2 x i64>
  %704 = shufflevector <4 x i32> %700, <4 x i32> %701, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %705 = bitcast <4 x i32> %704 to <2 x i64>
  %706 = shufflevector <2 x i64> %697, <2 x i64> %703, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %706, <2 x i64>* %634, align 16
  %707 = shufflevector <2 x i64> %697, <2 x i64> %703, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %707, <2 x i64>* %636, align 16
  %708 = shufflevector <2 x i64> %699, <2 x i64> %705, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %708, <2 x i64>* %638, align 16
  %709 = shufflevector <2 x i64> %699, <2 x i64> %705, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %709, <2 x i64>* %640, align 16
  %710 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 1, i64 1), align 1
  %711 = sext i8 %710 to i32
  call fastcc void @iadst8x8_sse4_1(<2 x i64>* nonnull %545, <2 x i64>* nonnull %482, i32 %711, i32 1, i32 %4, i32 0)
  %712 = getelementptr inbounds i8, i8* %10, i64 1
  %713 = load i8, i8* %712, align 1
  %714 = sext i8 %713 to i32
  %715 = sub nsw i32 0, %714
  call fastcc void @write_buffer_8x8(<2 x i64>* nonnull %482, i16* %1, i32 %2, i32 0, i32 0, i32 %715, i32 %4)
  br label %2126

716:                                              ; preds = %5
  %717 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %718 = bitcast i32* %0 to <2 x i64>*
  %719 = load <2 x i64>, <2 x i64>* %718, align 16
  store <2 x i64> %719, <2 x i64>* %717, align 16
  %720 = getelementptr inbounds i32, i32* %0, i64 4
  %721 = bitcast i32* %720 to <2 x i64>*
  %722 = load <2 x i64>, <2 x i64>* %721, align 16
  %723 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %722, <2 x i64>* %723, align 16
  %724 = getelementptr inbounds i32, i32* %0, i64 8
  %725 = bitcast i32* %724 to <2 x i64>*
  %726 = load <2 x i64>, <2 x i64>* %725, align 16
  %727 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %726, <2 x i64>* %727, align 16
  %728 = getelementptr inbounds i32, i32* %0, i64 12
  %729 = bitcast i32* %728 to <2 x i64>*
  %730 = load <2 x i64>, <2 x i64>* %729, align 16
  %731 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %730, <2 x i64>* %731, align 16
  %732 = getelementptr inbounds i32, i32* %0, i64 16
  %733 = bitcast i32* %732 to <2 x i64>*
  %734 = load <2 x i64>, <2 x i64>* %733, align 16
  %735 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %734, <2 x i64>* %735, align 16
  %736 = getelementptr inbounds i32, i32* %0, i64 20
  %737 = bitcast i32* %736 to <2 x i64>*
  %738 = load <2 x i64>, <2 x i64>* %737, align 16
  %739 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %738, <2 x i64>* %739, align 16
  %740 = getelementptr inbounds i32, i32* %0, i64 24
  %741 = bitcast i32* %740 to <2 x i64>*
  %742 = load <2 x i64>, <2 x i64>* %741, align 16
  %743 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %742, <2 x i64>* %743, align 16
  %744 = getelementptr inbounds i32, i32* %0, i64 28
  %745 = bitcast i32* %744 to <2 x i64>*
  %746 = load <2 x i64>, <2 x i64>* %745, align 16
  %747 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %746, <2 x i64>* %747, align 16
  %748 = getelementptr inbounds i32, i32* %0, i64 32
  %749 = bitcast i32* %748 to <2 x i64>*
  %750 = load <2 x i64>, <2 x i64>* %749, align 16
  %751 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %750, <2 x i64>* %751, align 16
  %752 = getelementptr inbounds i32, i32* %0, i64 36
  %753 = bitcast i32* %752 to <2 x i64>*
  %754 = load <2 x i64>, <2 x i64>* %753, align 16
  %755 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %754, <2 x i64>* %755, align 16
  %756 = getelementptr inbounds i32, i32* %0, i64 40
  %757 = bitcast i32* %756 to <2 x i64>*
  %758 = load <2 x i64>, <2 x i64>* %757, align 16
  %759 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %758, <2 x i64>* %759, align 16
  %760 = getelementptr inbounds i32, i32* %0, i64 44
  %761 = bitcast i32* %760 to <2 x i64>*
  %762 = load <2 x i64>, <2 x i64>* %761, align 16
  %763 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %762, <2 x i64>* %763, align 16
  %764 = getelementptr inbounds i32, i32* %0, i64 48
  %765 = bitcast i32* %764 to <2 x i64>*
  %766 = load <2 x i64>, <2 x i64>* %765, align 16
  %767 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %766, <2 x i64>* %767, align 16
  %768 = getelementptr inbounds i32, i32* %0, i64 52
  %769 = bitcast i32* %768 to <2 x i64>*
  %770 = load <2 x i64>, <2 x i64>* %769, align 16
  %771 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %770, <2 x i64>* %771, align 16
  %772 = getelementptr inbounds i32, i32* %0, i64 56
  %773 = bitcast i32* %772 to <2 x i64>*
  %774 = load <2 x i64>, <2 x i64>* %773, align 16
  %775 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %774, <2 x i64>* %775, align 16
  %776 = getelementptr inbounds i32, i32* %0, i64 60
  %777 = bitcast i32* %776 to <2 x i64>*
  %778 = load <2 x i64>, <2 x i64>* %777, align 16
  %779 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %778, <2 x i64>* %779, align 16
  %780 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  %781 = bitcast [16 x <2 x i64>]* %6 to <4 x i32>*
  %782 = bitcast <2 x i64> %719 to <4 x i32>
  %783 = bitcast <2 x i64>* %727 to <4 x i32>*
  %784 = bitcast <2 x i64> %726 to <4 x i32>
  %785 = shufflevector <4 x i32> %782, <4 x i32> %784, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %786 = bitcast <4 x i32> %785 to <2 x i64>
  %787 = shufflevector <4 x i32> %782, <4 x i32> %784, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %788 = bitcast <4 x i32> %787 to <2 x i64>
  %789 = bitcast <2 x i64>* %735 to <4 x i32>*
  %790 = bitcast <2 x i64> %734 to <4 x i32>
  %791 = bitcast <2 x i64>* %743 to <4 x i32>*
  %792 = bitcast <2 x i64> %742 to <4 x i32>
  %793 = shufflevector <4 x i32> %790, <4 x i32> %792, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %794 = bitcast <4 x i32> %793 to <2 x i64>
  %795 = shufflevector <4 x i32> %790, <4 x i32> %792, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %796 = bitcast <4 x i32> %795 to <2 x i64>
  %797 = shufflevector <2 x i64> %786, <2 x i64> %794, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %797, <2 x i64>* %780, align 16
  %798 = shufflevector <2 x i64> %786, <2 x i64> %794, <2 x i32> <i32 1, i32 3>
  %799 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %798, <2 x i64>* %799, align 16
  %800 = shufflevector <2 x i64> %788, <2 x i64> %796, <2 x i32> <i32 0, i32 2>
  %801 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 4
  store <2 x i64> %800, <2 x i64>* %801, align 16
  %802 = shufflevector <2 x i64> %788, <2 x i64> %796, <2 x i32> <i32 1, i32 3>
  %803 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 6
  store <2 x i64> %802, <2 x i64>* %803, align 16
  %804 = bitcast <2 x i64>* %723 to <4 x i32>*
  %805 = load <4 x i32>, <4 x i32>* %804, align 16
  %806 = bitcast <2 x i64>* %731 to <4 x i32>*
  %807 = bitcast <2 x i64> %730 to <4 x i32>
  %808 = shufflevector <4 x i32> %805, <4 x i32> %807, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %809 = bitcast <4 x i32> %808 to <2 x i64>
  %810 = shufflevector <4 x i32> %805, <4 x i32> %807, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %811 = bitcast <4 x i32> %810 to <2 x i64>
  %812 = bitcast <2 x i64>* %739 to <4 x i32>*
  %813 = bitcast <2 x i64> %738 to <4 x i32>
  %814 = bitcast <2 x i64>* %747 to <4 x i32>*
  %815 = bitcast <2 x i64> %746 to <4 x i32>
  %816 = shufflevector <4 x i32> %813, <4 x i32> %815, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %817 = bitcast <4 x i32> %816 to <2 x i64>
  %818 = shufflevector <4 x i32> %813, <4 x i32> %815, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %819 = bitcast <4 x i32> %818 to <2 x i64>
  %820 = shufflevector <2 x i64> %809, <2 x i64> %817, <2 x i32> <i32 0, i32 2>
  %821 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  store <2 x i64> %820, <2 x i64>* %821, align 16
  %822 = shufflevector <2 x i64> %809, <2 x i64> %817, <2 x i32> <i32 1, i32 3>
  %823 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  store <2 x i64> %822, <2 x i64>* %823, align 16
  %824 = shufflevector <2 x i64> %811, <2 x i64> %819, <2 x i32> <i32 0, i32 2>
  %825 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 12
  store <2 x i64> %824, <2 x i64>* %825, align 16
  %826 = shufflevector <2 x i64> %811, <2 x i64> %819, <2 x i32> <i32 1, i32 3>
  %827 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 14
  store <2 x i64> %826, <2 x i64>* %827, align 16
  %828 = bitcast <2 x i64>* %751 to <4 x i32>*
  %829 = load <4 x i32>, <4 x i32>* %828, align 16
  %830 = bitcast <2 x i64>* %759 to <4 x i32>*
  %831 = bitcast <2 x i64> %758 to <4 x i32>
  %832 = shufflevector <4 x i32> %829, <4 x i32> %831, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %833 = bitcast <4 x i32> %832 to <2 x i64>
  %834 = shufflevector <4 x i32> %829, <4 x i32> %831, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %835 = bitcast <4 x i32> %834 to <2 x i64>
  %836 = bitcast <2 x i64>* %767 to <4 x i32>*
  %837 = bitcast <2 x i64> %766 to <4 x i32>
  %838 = bitcast <2 x i64>* %775 to <4 x i32>*
  %839 = bitcast <2 x i64> %774 to <4 x i32>
  %840 = shufflevector <4 x i32> %837, <4 x i32> %839, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %841 = bitcast <4 x i32> %840 to <2 x i64>
  %842 = shufflevector <4 x i32> %837, <4 x i32> %839, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %843 = bitcast <4 x i32> %842 to <2 x i64>
  %844 = shufflevector <2 x i64> %833, <2 x i64> %841, <2 x i32> <i32 0, i32 2>
  %845 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %844, <2 x i64>* %845, align 16
  %846 = shufflevector <2 x i64> %833, <2 x i64> %841, <2 x i32> <i32 1, i32 3>
  %847 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %846, <2 x i64>* %847, align 16
  %848 = shufflevector <2 x i64> %835, <2 x i64> %843, <2 x i32> <i32 0, i32 2>
  %849 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 5
  store <2 x i64> %848, <2 x i64>* %849, align 16
  %850 = shufflevector <2 x i64> %835, <2 x i64> %843, <2 x i32> <i32 1, i32 3>
  %851 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 7
  store <2 x i64> %850, <2 x i64>* %851, align 16
  %852 = bitcast <2 x i64>* %755 to <4 x i32>*
  %853 = load <4 x i32>, <4 x i32>* %852, align 16
  %854 = bitcast <2 x i64>* %763 to <4 x i32>*
  %855 = load <4 x i32>, <4 x i32>* %854, align 16
  %856 = shufflevector <4 x i32> %853, <4 x i32> %855, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %857 = bitcast <4 x i32> %856 to <2 x i64>
  %858 = shufflevector <4 x i32> %853, <4 x i32> %855, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %859 = bitcast <4 x i32> %858 to <2 x i64>
  %860 = bitcast <2 x i64>* %771 to <4 x i32>*
  %861 = load <4 x i32>, <4 x i32>* %860, align 16
  %862 = bitcast <2 x i64>* %779 to <4 x i32>*
  %863 = load <4 x i32>, <4 x i32>* %862, align 16
  %864 = shufflevector <4 x i32> %861, <4 x i32> %863, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %865 = bitcast <4 x i32> %864 to <2 x i64>
  %866 = shufflevector <4 x i32> %861, <4 x i32> %863, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %867 = bitcast <4 x i32> %866 to <2 x i64>
  %868 = shufflevector <2 x i64> %857, <2 x i64> %865, <2 x i32> <i32 0, i32 2>
  %869 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  store <2 x i64> %868, <2 x i64>* %869, align 16
  %870 = shufflevector <2 x i64> %857, <2 x i64> %865, <2 x i32> <i32 1, i32 3>
  %871 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  store <2 x i64> %870, <2 x i64>* %871, align 16
  %872 = shufflevector <2 x i64> %859, <2 x i64> %867, <2 x i32> <i32 0, i32 2>
  %873 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 13
  store <2 x i64> %872, <2 x i64>* %873, align 16
  %874 = shufflevector <2 x i64> %859, <2 x i64> %867, <2 x i32> <i32 1, i32 3>
  %875 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 15
  store <2 x i64> %874, <2 x i64>* %875, align 16
  %876 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 1, i64 1), align 1
  %877 = sext i8 %876 to i32
  %878 = load i8, i8* %10, align 1
  %879 = sext i8 %878 to i32
  %880 = sub nsw i32 0, %879
  call fastcc void @iadst8x8_sse4_1(<2 x i64>* nonnull %780, <2 x i64>* nonnull %717, i32 %877, i32 0, i32 %4, i32 %880)
  %881 = load <4 x i32>, <4 x i32>* %781, align 16
  %882 = load <4 x i32>, <4 x i32>* %783, align 16
  %883 = shufflevector <4 x i32> %881, <4 x i32> %882, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %884 = bitcast <4 x i32> %883 to <2 x i64>
  %885 = shufflevector <4 x i32> %881, <4 x i32> %882, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %886 = bitcast <4 x i32> %885 to <2 x i64>
  %887 = load <4 x i32>, <4 x i32>* %789, align 16
  %888 = load <4 x i32>, <4 x i32>* %791, align 16
  %889 = shufflevector <4 x i32> %887, <4 x i32> %888, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %890 = bitcast <4 x i32> %889 to <2 x i64>
  %891 = shufflevector <4 x i32> %887, <4 x i32> %888, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %892 = bitcast <4 x i32> %891 to <2 x i64>
  %893 = shufflevector <2 x i64> %884, <2 x i64> %890, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %893, <2 x i64>* %780, align 16
  %894 = shufflevector <2 x i64> %884, <2 x i64> %890, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %894, <2 x i64>* %799, align 16
  %895 = shufflevector <2 x i64> %886, <2 x i64> %892, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %895, <2 x i64>* %801, align 16
  %896 = shufflevector <2 x i64> %886, <2 x i64> %892, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %896, <2 x i64>* %803, align 16
  %897 = load <4 x i32>, <4 x i32>* %804, align 16
  %898 = load <4 x i32>, <4 x i32>* %806, align 16
  %899 = shufflevector <4 x i32> %897, <4 x i32> %898, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %900 = bitcast <4 x i32> %899 to <2 x i64>
  %901 = shufflevector <4 x i32> %897, <4 x i32> %898, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %902 = bitcast <4 x i32> %901 to <2 x i64>
  %903 = load <4 x i32>, <4 x i32>* %812, align 16
  %904 = load <4 x i32>, <4 x i32>* %814, align 16
  %905 = shufflevector <4 x i32> %903, <4 x i32> %904, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %906 = bitcast <4 x i32> %905 to <2 x i64>
  %907 = shufflevector <4 x i32> %903, <4 x i32> %904, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %908 = bitcast <4 x i32> %907 to <2 x i64>
  %909 = shufflevector <2 x i64> %900, <2 x i64> %906, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %909, <2 x i64>* %821, align 16
  %910 = shufflevector <2 x i64> %900, <2 x i64> %906, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %910, <2 x i64>* %823, align 16
  %911 = shufflevector <2 x i64> %902, <2 x i64> %908, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %911, <2 x i64>* %825, align 16
  %912 = shufflevector <2 x i64> %902, <2 x i64> %908, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %912, <2 x i64>* %827, align 16
  %913 = load <4 x i32>, <4 x i32>* %828, align 16
  %914 = load <4 x i32>, <4 x i32>* %830, align 16
  %915 = shufflevector <4 x i32> %913, <4 x i32> %914, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %916 = bitcast <4 x i32> %915 to <2 x i64>
  %917 = shufflevector <4 x i32> %913, <4 x i32> %914, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %918 = bitcast <4 x i32> %917 to <2 x i64>
  %919 = load <4 x i32>, <4 x i32>* %836, align 16
  %920 = load <4 x i32>, <4 x i32>* %838, align 16
  %921 = shufflevector <4 x i32> %919, <4 x i32> %920, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %922 = bitcast <4 x i32> %921 to <2 x i64>
  %923 = shufflevector <4 x i32> %919, <4 x i32> %920, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %924 = bitcast <4 x i32> %923 to <2 x i64>
  %925 = shufflevector <2 x i64> %916, <2 x i64> %922, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %925, <2 x i64>* %845, align 16
  %926 = shufflevector <2 x i64> %916, <2 x i64> %922, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %926, <2 x i64>* %847, align 16
  %927 = shufflevector <2 x i64> %918, <2 x i64> %924, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %927, <2 x i64>* %849, align 16
  %928 = shufflevector <2 x i64> %918, <2 x i64> %924, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %928, <2 x i64>* %851, align 16
  %929 = load <4 x i32>, <4 x i32>* %852, align 16
  %930 = load <4 x i32>, <4 x i32>* %854, align 16
  %931 = shufflevector <4 x i32> %929, <4 x i32> %930, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %932 = bitcast <4 x i32> %931 to <2 x i64>
  %933 = shufflevector <4 x i32> %929, <4 x i32> %930, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %934 = bitcast <4 x i32> %933 to <2 x i64>
  %935 = load <4 x i32>, <4 x i32>* %860, align 16
  %936 = load <4 x i32>, <4 x i32>* %862, align 16
  %937 = shufflevector <4 x i32> %935, <4 x i32> %936, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %938 = bitcast <4 x i32> %937 to <2 x i64>
  %939 = shufflevector <4 x i32> %935, <4 x i32> %936, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %940 = bitcast <4 x i32> %939 to <2 x i64>
  %941 = shufflevector <2 x i64> %932, <2 x i64> %938, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %941, <2 x i64>* %869, align 16
  %942 = shufflevector <2 x i64> %932, <2 x i64> %938, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %942, <2 x i64>* %871, align 16
  %943 = shufflevector <2 x i64> %934, <2 x i64> %940, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %943, <2 x i64>* %873, align 16
  %944 = shufflevector <2 x i64> %934, <2 x i64> %940, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %944, <2 x i64>* %875, align 16
  %945 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 1, i64 1), align 1
  %946 = sext i8 %945 to i32
  call fastcc void @iadst8x8_sse4_1(<2 x i64>* nonnull %780, <2 x i64>* nonnull %717, i32 %946, i32 1, i32 %4, i32 0)
  %947 = getelementptr inbounds i8, i8* %10, i64 1
  %948 = load i8, i8* %947, align 1
  %949 = sext i8 %948 to i32
  %950 = sub nsw i32 0, %949
  call fastcc void @write_buffer_8x8(<2 x i64>* nonnull %717, i16* %1, i32 %2, i32 0, i32 0, i32 %950, i32 %4)
  br label %2126

951:                                              ; preds = %5
  %952 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %953 = bitcast i32* %0 to <2 x i64>*
  %954 = load <2 x i64>, <2 x i64>* %953, align 16
  store <2 x i64> %954, <2 x i64>* %952, align 16
  %955 = getelementptr inbounds i32, i32* %0, i64 4
  %956 = bitcast i32* %955 to <2 x i64>*
  %957 = load <2 x i64>, <2 x i64>* %956, align 16
  %958 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %957, <2 x i64>* %958, align 16
  %959 = getelementptr inbounds i32, i32* %0, i64 8
  %960 = bitcast i32* %959 to <2 x i64>*
  %961 = load <2 x i64>, <2 x i64>* %960, align 16
  %962 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %961, <2 x i64>* %962, align 16
  %963 = getelementptr inbounds i32, i32* %0, i64 12
  %964 = bitcast i32* %963 to <2 x i64>*
  %965 = load <2 x i64>, <2 x i64>* %964, align 16
  %966 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %965, <2 x i64>* %966, align 16
  %967 = getelementptr inbounds i32, i32* %0, i64 16
  %968 = bitcast i32* %967 to <2 x i64>*
  %969 = load <2 x i64>, <2 x i64>* %968, align 16
  %970 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %969, <2 x i64>* %970, align 16
  %971 = getelementptr inbounds i32, i32* %0, i64 20
  %972 = bitcast i32* %971 to <2 x i64>*
  %973 = load <2 x i64>, <2 x i64>* %972, align 16
  %974 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %973, <2 x i64>* %974, align 16
  %975 = getelementptr inbounds i32, i32* %0, i64 24
  %976 = bitcast i32* %975 to <2 x i64>*
  %977 = load <2 x i64>, <2 x i64>* %976, align 16
  %978 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %977, <2 x i64>* %978, align 16
  %979 = getelementptr inbounds i32, i32* %0, i64 28
  %980 = bitcast i32* %979 to <2 x i64>*
  %981 = load <2 x i64>, <2 x i64>* %980, align 16
  %982 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %981, <2 x i64>* %982, align 16
  %983 = getelementptr inbounds i32, i32* %0, i64 32
  %984 = bitcast i32* %983 to <2 x i64>*
  %985 = load <2 x i64>, <2 x i64>* %984, align 16
  %986 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %985, <2 x i64>* %986, align 16
  %987 = getelementptr inbounds i32, i32* %0, i64 36
  %988 = bitcast i32* %987 to <2 x i64>*
  %989 = load <2 x i64>, <2 x i64>* %988, align 16
  %990 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %989, <2 x i64>* %990, align 16
  %991 = getelementptr inbounds i32, i32* %0, i64 40
  %992 = bitcast i32* %991 to <2 x i64>*
  %993 = load <2 x i64>, <2 x i64>* %992, align 16
  %994 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %993, <2 x i64>* %994, align 16
  %995 = getelementptr inbounds i32, i32* %0, i64 44
  %996 = bitcast i32* %995 to <2 x i64>*
  %997 = load <2 x i64>, <2 x i64>* %996, align 16
  %998 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %997, <2 x i64>* %998, align 16
  %999 = getelementptr inbounds i32, i32* %0, i64 48
  %1000 = bitcast i32* %999 to <2 x i64>*
  %1001 = load <2 x i64>, <2 x i64>* %1000, align 16
  %1002 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %1001, <2 x i64>* %1002, align 16
  %1003 = getelementptr inbounds i32, i32* %0, i64 52
  %1004 = bitcast i32* %1003 to <2 x i64>*
  %1005 = load <2 x i64>, <2 x i64>* %1004, align 16
  %1006 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %1005, <2 x i64>* %1006, align 16
  %1007 = getelementptr inbounds i32, i32* %0, i64 56
  %1008 = bitcast i32* %1007 to <2 x i64>*
  %1009 = load <2 x i64>, <2 x i64>* %1008, align 16
  %1010 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %1009, <2 x i64>* %1010, align 16
  %1011 = getelementptr inbounds i32, i32* %0, i64 60
  %1012 = bitcast i32* %1011 to <2 x i64>*
  %1013 = load <2 x i64>, <2 x i64>* %1012, align 16
  %1014 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %1013, <2 x i64>* %1014, align 16
  %1015 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  %1016 = bitcast [16 x <2 x i64>]* %6 to <4 x i32>*
  %1017 = bitcast <2 x i64> %954 to <4 x i32>
  %1018 = bitcast <2 x i64>* %962 to <4 x i32>*
  %1019 = bitcast <2 x i64> %961 to <4 x i32>
  %1020 = shufflevector <4 x i32> %1017, <4 x i32> %1019, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1021 = bitcast <4 x i32> %1020 to <2 x i64>
  %1022 = shufflevector <4 x i32> %1017, <4 x i32> %1019, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1023 = bitcast <4 x i32> %1022 to <2 x i64>
  %1024 = bitcast <2 x i64>* %970 to <4 x i32>*
  %1025 = bitcast <2 x i64> %969 to <4 x i32>
  %1026 = bitcast <2 x i64>* %978 to <4 x i32>*
  %1027 = bitcast <2 x i64> %977 to <4 x i32>
  %1028 = shufflevector <4 x i32> %1025, <4 x i32> %1027, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1029 = bitcast <4 x i32> %1028 to <2 x i64>
  %1030 = shufflevector <4 x i32> %1025, <4 x i32> %1027, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1031 = bitcast <4 x i32> %1030 to <2 x i64>
  %1032 = shufflevector <2 x i64> %1021, <2 x i64> %1029, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1032, <2 x i64>* %1015, align 16
  %1033 = shufflevector <2 x i64> %1021, <2 x i64> %1029, <2 x i32> <i32 1, i32 3>
  %1034 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %1033, <2 x i64>* %1034, align 16
  %1035 = shufflevector <2 x i64> %1023, <2 x i64> %1031, <2 x i32> <i32 0, i32 2>
  %1036 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 4
  store <2 x i64> %1035, <2 x i64>* %1036, align 16
  %1037 = shufflevector <2 x i64> %1023, <2 x i64> %1031, <2 x i32> <i32 1, i32 3>
  %1038 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 6
  store <2 x i64> %1037, <2 x i64>* %1038, align 16
  %1039 = bitcast <2 x i64>* %958 to <4 x i32>*
  %1040 = load <4 x i32>, <4 x i32>* %1039, align 16
  %1041 = bitcast <2 x i64>* %966 to <4 x i32>*
  %1042 = bitcast <2 x i64> %965 to <4 x i32>
  %1043 = shufflevector <4 x i32> %1040, <4 x i32> %1042, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1044 = bitcast <4 x i32> %1043 to <2 x i64>
  %1045 = shufflevector <4 x i32> %1040, <4 x i32> %1042, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1046 = bitcast <4 x i32> %1045 to <2 x i64>
  %1047 = bitcast <2 x i64>* %974 to <4 x i32>*
  %1048 = bitcast <2 x i64> %973 to <4 x i32>
  %1049 = bitcast <2 x i64>* %982 to <4 x i32>*
  %1050 = bitcast <2 x i64> %981 to <4 x i32>
  %1051 = shufflevector <4 x i32> %1048, <4 x i32> %1050, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1052 = bitcast <4 x i32> %1051 to <2 x i64>
  %1053 = shufflevector <4 x i32> %1048, <4 x i32> %1050, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1054 = bitcast <4 x i32> %1053 to <2 x i64>
  %1055 = shufflevector <2 x i64> %1044, <2 x i64> %1052, <2 x i32> <i32 0, i32 2>
  %1056 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  store <2 x i64> %1055, <2 x i64>* %1056, align 16
  %1057 = shufflevector <2 x i64> %1044, <2 x i64> %1052, <2 x i32> <i32 1, i32 3>
  %1058 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  store <2 x i64> %1057, <2 x i64>* %1058, align 16
  %1059 = shufflevector <2 x i64> %1046, <2 x i64> %1054, <2 x i32> <i32 0, i32 2>
  %1060 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 12
  store <2 x i64> %1059, <2 x i64>* %1060, align 16
  %1061 = shufflevector <2 x i64> %1046, <2 x i64> %1054, <2 x i32> <i32 1, i32 3>
  %1062 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 14
  store <2 x i64> %1061, <2 x i64>* %1062, align 16
  %1063 = bitcast <2 x i64>* %986 to <4 x i32>*
  %1064 = load <4 x i32>, <4 x i32>* %1063, align 16
  %1065 = bitcast <2 x i64>* %994 to <4 x i32>*
  %1066 = bitcast <2 x i64> %993 to <4 x i32>
  %1067 = shufflevector <4 x i32> %1064, <4 x i32> %1066, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1068 = bitcast <4 x i32> %1067 to <2 x i64>
  %1069 = shufflevector <4 x i32> %1064, <4 x i32> %1066, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1070 = bitcast <4 x i32> %1069 to <2 x i64>
  %1071 = bitcast <2 x i64>* %1002 to <4 x i32>*
  %1072 = bitcast <2 x i64> %1001 to <4 x i32>
  %1073 = bitcast <2 x i64>* %1010 to <4 x i32>*
  %1074 = bitcast <2 x i64> %1009 to <4 x i32>
  %1075 = shufflevector <4 x i32> %1072, <4 x i32> %1074, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1076 = bitcast <4 x i32> %1075 to <2 x i64>
  %1077 = shufflevector <4 x i32> %1072, <4 x i32> %1074, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1078 = bitcast <4 x i32> %1077 to <2 x i64>
  %1079 = shufflevector <2 x i64> %1068, <2 x i64> %1076, <2 x i32> <i32 0, i32 2>
  %1080 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %1079, <2 x i64>* %1080, align 16
  %1081 = shufflevector <2 x i64> %1068, <2 x i64> %1076, <2 x i32> <i32 1, i32 3>
  %1082 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %1081, <2 x i64>* %1082, align 16
  %1083 = shufflevector <2 x i64> %1070, <2 x i64> %1078, <2 x i32> <i32 0, i32 2>
  %1084 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 5
  store <2 x i64> %1083, <2 x i64>* %1084, align 16
  %1085 = shufflevector <2 x i64> %1070, <2 x i64> %1078, <2 x i32> <i32 1, i32 3>
  %1086 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 7
  store <2 x i64> %1085, <2 x i64>* %1086, align 16
  %1087 = bitcast <2 x i64>* %990 to <4 x i32>*
  %1088 = load <4 x i32>, <4 x i32>* %1087, align 16
  %1089 = bitcast <2 x i64>* %998 to <4 x i32>*
  %1090 = load <4 x i32>, <4 x i32>* %1089, align 16
  %1091 = shufflevector <4 x i32> %1088, <4 x i32> %1090, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1092 = bitcast <4 x i32> %1091 to <2 x i64>
  %1093 = shufflevector <4 x i32> %1088, <4 x i32> %1090, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1094 = bitcast <4 x i32> %1093 to <2 x i64>
  %1095 = bitcast <2 x i64>* %1006 to <4 x i32>*
  %1096 = load <4 x i32>, <4 x i32>* %1095, align 16
  %1097 = bitcast <2 x i64>* %1014 to <4 x i32>*
  %1098 = load <4 x i32>, <4 x i32>* %1097, align 16
  %1099 = shufflevector <4 x i32> %1096, <4 x i32> %1098, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1100 = bitcast <4 x i32> %1099 to <2 x i64>
  %1101 = shufflevector <4 x i32> %1096, <4 x i32> %1098, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1102 = bitcast <4 x i32> %1101 to <2 x i64>
  %1103 = shufflevector <2 x i64> %1092, <2 x i64> %1100, <2 x i32> <i32 0, i32 2>
  %1104 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  store <2 x i64> %1103, <2 x i64>* %1104, align 16
  %1105 = shufflevector <2 x i64> %1092, <2 x i64> %1100, <2 x i32> <i32 1, i32 3>
  %1106 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  store <2 x i64> %1105, <2 x i64>* %1106, align 16
  %1107 = shufflevector <2 x i64> %1094, <2 x i64> %1102, <2 x i32> <i32 0, i32 2>
  %1108 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 13
  store <2 x i64> %1107, <2 x i64>* %1108, align 16
  %1109 = shufflevector <2 x i64> %1094, <2 x i64> %1102, <2 x i32> <i32 1, i32 3>
  %1110 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 15
  store <2 x i64> %1109, <2 x i64>* %1110, align 16
  %1111 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 1, i64 1), align 1
  %1112 = sext i8 %1111 to i32
  %1113 = load i8, i8* %10, align 1
  %1114 = sext i8 %1113 to i32
  %1115 = sub nsw i32 0, %1114
  call fastcc void @idct8x8_sse4_1(<2 x i64>* nonnull %1015, <2 x i64>* nonnull %952, i32 %1112, i32 0, i32 %4, i32 %1115)
  %1116 = load <4 x i32>, <4 x i32>* %1016, align 16
  %1117 = load <4 x i32>, <4 x i32>* %1018, align 16
  %1118 = shufflevector <4 x i32> %1116, <4 x i32> %1117, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1119 = bitcast <4 x i32> %1118 to <2 x i64>
  %1120 = shufflevector <4 x i32> %1116, <4 x i32> %1117, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1121 = bitcast <4 x i32> %1120 to <2 x i64>
  %1122 = load <4 x i32>, <4 x i32>* %1024, align 16
  %1123 = load <4 x i32>, <4 x i32>* %1026, align 16
  %1124 = shufflevector <4 x i32> %1122, <4 x i32> %1123, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1125 = bitcast <4 x i32> %1124 to <2 x i64>
  %1126 = shufflevector <4 x i32> %1122, <4 x i32> %1123, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1127 = bitcast <4 x i32> %1126 to <2 x i64>
  %1128 = shufflevector <2 x i64> %1119, <2 x i64> %1125, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1128, <2 x i64>* %1015, align 16
  %1129 = shufflevector <2 x i64> %1119, <2 x i64> %1125, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1129, <2 x i64>* %1034, align 16
  %1130 = shufflevector <2 x i64> %1121, <2 x i64> %1127, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1130, <2 x i64>* %1036, align 16
  %1131 = shufflevector <2 x i64> %1121, <2 x i64> %1127, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1131, <2 x i64>* %1038, align 16
  %1132 = load <4 x i32>, <4 x i32>* %1039, align 16
  %1133 = load <4 x i32>, <4 x i32>* %1041, align 16
  %1134 = shufflevector <4 x i32> %1132, <4 x i32> %1133, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1135 = bitcast <4 x i32> %1134 to <2 x i64>
  %1136 = shufflevector <4 x i32> %1132, <4 x i32> %1133, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1137 = bitcast <4 x i32> %1136 to <2 x i64>
  %1138 = load <4 x i32>, <4 x i32>* %1047, align 16
  %1139 = load <4 x i32>, <4 x i32>* %1049, align 16
  %1140 = shufflevector <4 x i32> %1138, <4 x i32> %1139, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1141 = bitcast <4 x i32> %1140 to <2 x i64>
  %1142 = shufflevector <4 x i32> %1138, <4 x i32> %1139, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1143 = bitcast <4 x i32> %1142 to <2 x i64>
  %1144 = shufflevector <2 x i64> %1135, <2 x i64> %1141, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1144, <2 x i64>* %1056, align 16
  %1145 = shufflevector <2 x i64> %1135, <2 x i64> %1141, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1145, <2 x i64>* %1058, align 16
  %1146 = shufflevector <2 x i64> %1137, <2 x i64> %1143, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1146, <2 x i64>* %1060, align 16
  %1147 = shufflevector <2 x i64> %1137, <2 x i64> %1143, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1147, <2 x i64>* %1062, align 16
  %1148 = load <4 x i32>, <4 x i32>* %1063, align 16
  %1149 = load <4 x i32>, <4 x i32>* %1065, align 16
  %1150 = shufflevector <4 x i32> %1148, <4 x i32> %1149, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1151 = bitcast <4 x i32> %1150 to <2 x i64>
  %1152 = shufflevector <4 x i32> %1148, <4 x i32> %1149, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1153 = bitcast <4 x i32> %1152 to <2 x i64>
  %1154 = load <4 x i32>, <4 x i32>* %1071, align 16
  %1155 = load <4 x i32>, <4 x i32>* %1073, align 16
  %1156 = shufflevector <4 x i32> %1154, <4 x i32> %1155, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1157 = bitcast <4 x i32> %1156 to <2 x i64>
  %1158 = shufflevector <4 x i32> %1154, <4 x i32> %1155, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1159 = bitcast <4 x i32> %1158 to <2 x i64>
  %1160 = shufflevector <2 x i64> %1151, <2 x i64> %1157, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1160, <2 x i64>* %1080, align 16
  %1161 = shufflevector <2 x i64> %1151, <2 x i64> %1157, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1161, <2 x i64>* %1082, align 16
  %1162 = shufflevector <2 x i64> %1153, <2 x i64> %1159, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1162, <2 x i64>* %1084, align 16
  %1163 = shufflevector <2 x i64> %1153, <2 x i64> %1159, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1163, <2 x i64>* %1086, align 16
  %1164 = load <4 x i32>, <4 x i32>* %1087, align 16
  %1165 = load <4 x i32>, <4 x i32>* %1089, align 16
  %1166 = shufflevector <4 x i32> %1164, <4 x i32> %1165, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1167 = bitcast <4 x i32> %1166 to <2 x i64>
  %1168 = shufflevector <4 x i32> %1164, <4 x i32> %1165, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1169 = bitcast <4 x i32> %1168 to <2 x i64>
  %1170 = load <4 x i32>, <4 x i32>* %1095, align 16
  %1171 = load <4 x i32>, <4 x i32>* %1097, align 16
  %1172 = shufflevector <4 x i32> %1170, <4 x i32> %1171, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1173 = bitcast <4 x i32> %1172 to <2 x i64>
  %1174 = shufflevector <4 x i32> %1170, <4 x i32> %1171, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1175 = bitcast <4 x i32> %1174 to <2 x i64>
  %1176 = shufflevector <2 x i64> %1167, <2 x i64> %1173, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1176, <2 x i64>* %1104, align 16
  %1177 = shufflevector <2 x i64> %1167, <2 x i64> %1173, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1177, <2 x i64>* %1106, align 16
  %1178 = shufflevector <2 x i64> %1169, <2 x i64> %1175, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1178, <2 x i64>* %1108, align 16
  %1179 = shufflevector <2 x i64> %1169, <2 x i64> %1175, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1179, <2 x i64>* %1110, align 16
  %1180 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 1, i64 1), align 1
  %1181 = sext i8 %1180 to i32
  call fastcc void @iadst8x8_sse4_1(<2 x i64>* nonnull %1015, <2 x i64>* nonnull %952, i32 %1181, i32 1, i32 %4, i32 0)
  %1182 = getelementptr inbounds i8, i8* %10, i64 1
  %1183 = load i8, i8* %1182, align 1
  %1184 = sext i8 %1183 to i32
  %1185 = sub nsw i32 0, %1184
  call fastcc void @write_buffer_8x8(<2 x i64>* nonnull %952, i16* %1, i32 %2, i32 0, i32 1, i32 %1185, i32 %4)
  br label %2126

1186:                                             ; preds = %5
  %1187 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %1188 = bitcast i32* %0 to <2 x i64>*
  %1189 = load <2 x i64>, <2 x i64>* %1188, align 16
  store <2 x i64> %1189, <2 x i64>* %1187, align 16
  %1190 = getelementptr inbounds i32, i32* %0, i64 4
  %1191 = bitcast i32* %1190 to <2 x i64>*
  %1192 = load <2 x i64>, <2 x i64>* %1191, align 16
  %1193 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %1192, <2 x i64>* %1193, align 16
  %1194 = getelementptr inbounds i32, i32* %0, i64 8
  %1195 = bitcast i32* %1194 to <2 x i64>*
  %1196 = load <2 x i64>, <2 x i64>* %1195, align 16
  %1197 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %1196, <2 x i64>* %1197, align 16
  %1198 = getelementptr inbounds i32, i32* %0, i64 12
  %1199 = bitcast i32* %1198 to <2 x i64>*
  %1200 = load <2 x i64>, <2 x i64>* %1199, align 16
  %1201 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %1200, <2 x i64>* %1201, align 16
  %1202 = getelementptr inbounds i32, i32* %0, i64 16
  %1203 = bitcast i32* %1202 to <2 x i64>*
  %1204 = load <2 x i64>, <2 x i64>* %1203, align 16
  %1205 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %1204, <2 x i64>* %1205, align 16
  %1206 = getelementptr inbounds i32, i32* %0, i64 20
  %1207 = bitcast i32* %1206 to <2 x i64>*
  %1208 = load <2 x i64>, <2 x i64>* %1207, align 16
  %1209 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %1208, <2 x i64>* %1209, align 16
  %1210 = getelementptr inbounds i32, i32* %0, i64 24
  %1211 = bitcast i32* %1210 to <2 x i64>*
  %1212 = load <2 x i64>, <2 x i64>* %1211, align 16
  %1213 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %1212, <2 x i64>* %1213, align 16
  %1214 = getelementptr inbounds i32, i32* %0, i64 28
  %1215 = bitcast i32* %1214 to <2 x i64>*
  %1216 = load <2 x i64>, <2 x i64>* %1215, align 16
  %1217 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %1216, <2 x i64>* %1217, align 16
  %1218 = getelementptr inbounds i32, i32* %0, i64 32
  %1219 = bitcast i32* %1218 to <2 x i64>*
  %1220 = load <2 x i64>, <2 x i64>* %1219, align 16
  %1221 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %1220, <2 x i64>* %1221, align 16
  %1222 = getelementptr inbounds i32, i32* %0, i64 36
  %1223 = bitcast i32* %1222 to <2 x i64>*
  %1224 = load <2 x i64>, <2 x i64>* %1223, align 16
  %1225 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %1224, <2 x i64>* %1225, align 16
  %1226 = getelementptr inbounds i32, i32* %0, i64 40
  %1227 = bitcast i32* %1226 to <2 x i64>*
  %1228 = load <2 x i64>, <2 x i64>* %1227, align 16
  %1229 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %1228, <2 x i64>* %1229, align 16
  %1230 = getelementptr inbounds i32, i32* %0, i64 44
  %1231 = bitcast i32* %1230 to <2 x i64>*
  %1232 = load <2 x i64>, <2 x i64>* %1231, align 16
  %1233 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %1232, <2 x i64>* %1233, align 16
  %1234 = getelementptr inbounds i32, i32* %0, i64 48
  %1235 = bitcast i32* %1234 to <2 x i64>*
  %1236 = load <2 x i64>, <2 x i64>* %1235, align 16
  %1237 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %1236, <2 x i64>* %1237, align 16
  %1238 = getelementptr inbounds i32, i32* %0, i64 52
  %1239 = bitcast i32* %1238 to <2 x i64>*
  %1240 = load <2 x i64>, <2 x i64>* %1239, align 16
  %1241 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %1240, <2 x i64>* %1241, align 16
  %1242 = getelementptr inbounds i32, i32* %0, i64 56
  %1243 = bitcast i32* %1242 to <2 x i64>*
  %1244 = load <2 x i64>, <2 x i64>* %1243, align 16
  %1245 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %1244, <2 x i64>* %1245, align 16
  %1246 = getelementptr inbounds i32, i32* %0, i64 60
  %1247 = bitcast i32* %1246 to <2 x i64>*
  %1248 = load <2 x i64>, <2 x i64>* %1247, align 16
  %1249 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %1248, <2 x i64>* %1249, align 16
  %1250 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  %1251 = bitcast [16 x <2 x i64>]* %6 to <4 x i32>*
  %1252 = bitcast <2 x i64> %1189 to <4 x i32>
  %1253 = bitcast <2 x i64>* %1197 to <4 x i32>*
  %1254 = bitcast <2 x i64> %1196 to <4 x i32>
  %1255 = shufflevector <4 x i32> %1252, <4 x i32> %1254, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1256 = bitcast <4 x i32> %1255 to <2 x i64>
  %1257 = shufflevector <4 x i32> %1252, <4 x i32> %1254, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1258 = bitcast <4 x i32> %1257 to <2 x i64>
  %1259 = bitcast <2 x i64>* %1205 to <4 x i32>*
  %1260 = bitcast <2 x i64> %1204 to <4 x i32>
  %1261 = bitcast <2 x i64>* %1213 to <4 x i32>*
  %1262 = bitcast <2 x i64> %1212 to <4 x i32>
  %1263 = shufflevector <4 x i32> %1260, <4 x i32> %1262, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1264 = bitcast <4 x i32> %1263 to <2 x i64>
  %1265 = shufflevector <4 x i32> %1260, <4 x i32> %1262, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1266 = bitcast <4 x i32> %1265 to <2 x i64>
  %1267 = shufflevector <2 x i64> %1256, <2 x i64> %1264, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1267, <2 x i64>* %1250, align 16
  %1268 = shufflevector <2 x i64> %1256, <2 x i64> %1264, <2 x i32> <i32 1, i32 3>
  %1269 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %1268, <2 x i64>* %1269, align 16
  %1270 = shufflevector <2 x i64> %1258, <2 x i64> %1266, <2 x i32> <i32 0, i32 2>
  %1271 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 4
  store <2 x i64> %1270, <2 x i64>* %1271, align 16
  %1272 = shufflevector <2 x i64> %1258, <2 x i64> %1266, <2 x i32> <i32 1, i32 3>
  %1273 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 6
  store <2 x i64> %1272, <2 x i64>* %1273, align 16
  %1274 = bitcast <2 x i64>* %1193 to <4 x i32>*
  %1275 = load <4 x i32>, <4 x i32>* %1274, align 16
  %1276 = bitcast <2 x i64>* %1201 to <4 x i32>*
  %1277 = bitcast <2 x i64> %1200 to <4 x i32>
  %1278 = shufflevector <4 x i32> %1275, <4 x i32> %1277, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1279 = bitcast <4 x i32> %1278 to <2 x i64>
  %1280 = shufflevector <4 x i32> %1275, <4 x i32> %1277, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1281 = bitcast <4 x i32> %1280 to <2 x i64>
  %1282 = bitcast <2 x i64>* %1209 to <4 x i32>*
  %1283 = bitcast <2 x i64> %1208 to <4 x i32>
  %1284 = bitcast <2 x i64>* %1217 to <4 x i32>*
  %1285 = bitcast <2 x i64> %1216 to <4 x i32>
  %1286 = shufflevector <4 x i32> %1283, <4 x i32> %1285, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1287 = bitcast <4 x i32> %1286 to <2 x i64>
  %1288 = shufflevector <4 x i32> %1283, <4 x i32> %1285, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1289 = bitcast <4 x i32> %1288 to <2 x i64>
  %1290 = shufflevector <2 x i64> %1279, <2 x i64> %1287, <2 x i32> <i32 0, i32 2>
  %1291 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  store <2 x i64> %1290, <2 x i64>* %1291, align 16
  %1292 = shufflevector <2 x i64> %1279, <2 x i64> %1287, <2 x i32> <i32 1, i32 3>
  %1293 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  store <2 x i64> %1292, <2 x i64>* %1293, align 16
  %1294 = shufflevector <2 x i64> %1281, <2 x i64> %1289, <2 x i32> <i32 0, i32 2>
  %1295 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 12
  store <2 x i64> %1294, <2 x i64>* %1295, align 16
  %1296 = shufflevector <2 x i64> %1281, <2 x i64> %1289, <2 x i32> <i32 1, i32 3>
  %1297 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 14
  store <2 x i64> %1296, <2 x i64>* %1297, align 16
  %1298 = bitcast <2 x i64>* %1221 to <4 x i32>*
  %1299 = load <4 x i32>, <4 x i32>* %1298, align 16
  %1300 = bitcast <2 x i64>* %1229 to <4 x i32>*
  %1301 = bitcast <2 x i64> %1228 to <4 x i32>
  %1302 = shufflevector <4 x i32> %1299, <4 x i32> %1301, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1303 = bitcast <4 x i32> %1302 to <2 x i64>
  %1304 = shufflevector <4 x i32> %1299, <4 x i32> %1301, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1305 = bitcast <4 x i32> %1304 to <2 x i64>
  %1306 = bitcast <2 x i64>* %1237 to <4 x i32>*
  %1307 = bitcast <2 x i64> %1236 to <4 x i32>
  %1308 = bitcast <2 x i64>* %1245 to <4 x i32>*
  %1309 = bitcast <2 x i64> %1244 to <4 x i32>
  %1310 = shufflevector <4 x i32> %1307, <4 x i32> %1309, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1311 = bitcast <4 x i32> %1310 to <2 x i64>
  %1312 = shufflevector <4 x i32> %1307, <4 x i32> %1309, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1313 = bitcast <4 x i32> %1312 to <2 x i64>
  %1314 = shufflevector <2 x i64> %1303, <2 x i64> %1311, <2 x i32> <i32 0, i32 2>
  %1315 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %1314, <2 x i64>* %1315, align 16
  %1316 = shufflevector <2 x i64> %1303, <2 x i64> %1311, <2 x i32> <i32 1, i32 3>
  %1317 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %1316, <2 x i64>* %1317, align 16
  %1318 = shufflevector <2 x i64> %1305, <2 x i64> %1313, <2 x i32> <i32 0, i32 2>
  %1319 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 5
  store <2 x i64> %1318, <2 x i64>* %1319, align 16
  %1320 = shufflevector <2 x i64> %1305, <2 x i64> %1313, <2 x i32> <i32 1, i32 3>
  %1321 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 7
  store <2 x i64> %1320, <2 x i64>* %1321, align 16
  %1322 = bitcast <2 x i64>* %1225 to <4 x i32>*
  %1323 = load <4 x i32>, <4 x i32>* %1322, align 16
  %1324 = bitcast <2 x i64>* %1233 to <4 x i32>*
  %1325 = load <4 x i32>, <4 x i32>* %1324, align 16
  %1326 = shufflevector <4 x i32> %1323, <4 x i32> %1325, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1327 = bitcast <4 x i32> %1326 to <2 x i64>
  %1328 = shufflevector <4 x i32> %1323, <4 x i32> %1325, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1329 = bitcast <4 x i32> %1328 to <2 x i64>
  %1330 = bitcast <2 x i64>* %1241 to <4 x i32>*
  %1331 = load <4 x i32>, <4 x i32>* %1330, align 16
  %1332 = bitcast <2 x i64>* %1249 to <4 x i32>*
  %1333 = load <4 x i32>, <4 x i32>* %1332, align 16
  %1334 = shufflevector <4 x i32> %1331, <4 x i32> %1333, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1335 = bitcast <4 x i32> %1334 to <2 x i64>
  %1336 = shufflevector <4 x i32> %1331, <4 x i32> %1333, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1337 = bitcast <4 x i32> %1336 to <2 x i64>
  %1338 = shufflevector <2 x i64> %1327, <2 x i64> %1335, <2 x i32> <i32 0, i32 2>
  %1339 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  store <2 x i64> %1338, <2 x i64>* %1339, align 16
  %1340 = shufflevector <2 x i64> %1327, <2 x i64> %1335, <2 x i32> <i32 1, i32 3>
  %1341 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  store <2 x i64> %1340, <2 x i64>* %1341, align 16
  %1342 = shufflevector <2 x i64> %1329, <2 x i64> %1337, <2 x i32> <i32 0, i32 2>
  %1343 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 13
  store <2 x i64> %1342, <2 x i64>* %1343, align 16
  %1344 = shufflevector <2 x i64> %1329, <2 x i64> %1337, <2 x i32> <i32 1, i32 3>
  %1345 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 15
  store <2 x i64> %1344, <2 x i64>* %1345, align 16
  %1346 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 1, i64 1), align 1
  %1347 = sext i8 %1346 to i32
  %1348 = load i8, i8* %10, align 1
  %1349 = sext i8 %1348 to i32
  %1350 = sub nsw i32 0, %1349
  call fastcc void @iadst8x8_sse4_1(<2 x i64>* nonnull %1250, <2 x i64>* nonnull %1187, i32 %1347, i32 0, i32 %4, i32 %1350)
  %1351 = load <4 x i32>, <4 x i32>* %1251, align 16
  %1352 = load <4 x i32>, <4 x i32>* %1253, align 16
  %1353 = shufflevector <4 x i32> %1351, <4 x i32> %1352, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1354 = bitcast <4 x i32> %1353 to <2 x i64>
  %1355 = shufflevector <4 x i32> %1351, <4 x i32> %1352, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1356 = bitcast <4 x i32> %1355 to <2 x i64>
  %1357 = load <4 x i32>, <4 x i32>* %1259, align 16
  %1358 = load <4 x i32>, <4 x i32>* %1261, align 16
  %1359 = shufflevector <4 x i32> %1357, <4 x i32> %1358, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1360 = bitcast <4 x i32> %1359 to <2 x i64>
  %1361 = shufflevector <4 x i32> %1357, <4 x i32> %1358, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1362 = bitcast <4 x i32> %1361 to <2 x i64>
  %1363 = shufflevector <2 x i64> %1354, <2 x i64> %1360, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1363, <2 x i64>* %1250, align 16
  %1364 = shufflevector <2 x i64> %1354, <2 x i64> %1360, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1364, <2 x i64>* %1269, align 16
  %1365 = shufflevector <2 x i64> %1356, <2 x i64> %1362, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1365, <2 x i64>* %1271, align 16
  %1366 = shufflevector <2 x i64> %1356, <2 x i64> %1362, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1366, <2 x i64>* %1273, align 16
  %1367 = load <4 x i32>, <4 x i32>* %1274, align 16
  %1368 = load <4 x i32>, <4 x i32>* %1276, align 16
  %1369 = shufflevector <4 x i32> %1367, <4 x i32> %1368, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1370 = bitcast <4 x i32> %1369 to <2 x i64>
  %1371 = shufflevector <4 x i32> %1367, <4 x i32> %1368, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1372 = bitcast <4 x i32> %1371 to <2 x i64>
  %1373 = load <4 x i32>, <4 x i32>* %1282, align 16
  %1374 = load <4 x i32>, <4 x i32>* %1284, align 16
  %1375 = shufflevector <4 x i32> %1373, <4 x i32> %1374, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1376 = bitcast <4 x i32> %1375 to <2 x i64>
  %1377 = shufflevector <4 x i32> %1373, <4 x i32> %1374, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1378 = bitcast <4 x i32> %1377 to <2 x i64>
  %1379 = shufflevector <2 x i64> %1370, <2 x i64> %1376, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1379, <2 x i64>* %1291, align 16
  %1380 = shufflevector <2 x i64> %1370, <2 x i64> %1376, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1380, <2 x i64>* %1293, align 16
  %1381 = shufflevector <2 x i64> %1372, <2 x i64> %1378, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1381, <2 x i64>* %1295, align 16
  %1382 = shufflevector <2 x i64> %1372, <2 x i64> %1378, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1382, <2 x i64>* %1297, align 16
  %1383 = load <4 x i32>, <4 x i32>* %1298, align 16
  %1384 = load <4 x i32>, <4 x i32>* %1300, align 16
  %1385 = shufflevector <4 x i32> %1383, <4 x i32> %1384, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1386 = bitcast <4 x i32> %1385 to <2 x i64>
  %1387 = shufflevector <4 x i32> %1383, <4 x i32> %1384, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1388 = bitcast <4 x i32> %1387 to <2 x i64>
  %1389 = load <4 x i32>, <4 x i32>* %1306, align 16
  %1390 = load <4 x i32>, <4 x i32>* %1308, align 16
  %1391 = shufflevector <4 x i32> %1389, <4 x i32> %1390, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1392 = bitcast <4 x i32> %1391 to <2 x i64>
  %1393 = shufflevector <4 x i32> %1389, <4 x i32> %1390, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1394 = bitcast <4 x i32> %1393 to <2 x i64>
  %1395 = shufflevector <2 x i64> %1386, <2 x i64> %1392, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1395, <2 x i64>* %1315, align 16
  %1396 = shufflevector <2 x i64> %1386, <2 x i64> %1392, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1396, <2 x i64>* %1317, align 16
  %1397 = shufflevector <2 x i64> %1388, <2 x i64> %1394, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1397, <2 x i64>* %1319, align 16
  %1398 = shufflevector <2 x i64> %1388, <2 x i64> %1394, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1398, <2 x i64>* %1321, align 16
  %1399 = load <4 x i32>, <4 x i32>* %1322, align 16
  %1400 = load <4 x i32>, <4 x i32>* %1324, align 16
  %1401 = shufflevector <4 x i32> %1399, <4 x i32> %1400, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1402 = bitcast <4 x i32> %1401 to <2 x i64>
  %1403 = shufflevector <4 x i32> %1399, <4 x i32> %1400, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1404 = bitcast <4 x i32> %1403 to <2 x i64>
  %1405 = load <4 x i32>, <4 x i32>* %1330, align 16
  %1406 = load <4 x i32>, <4 x i32>* %1332, align 16
  %1407 = shufflevector <4 x i32> %1405, <4 x i32> %1406, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1408 = bitcast <4 x i32> %1407 to <2 x i64>
  %1409 = shufflevector <4 x i32> %1405, <4 x i32> %1406, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1410 = bitcast <4 x i32> %1409 to <2 x i64>
  %1411 = shufflevector <2 x i64> %1402, <2 x i64> %1408, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1411, <2 x i64>* %1339, align 16
  %1412 = shufflevector <2 x i64> %1402, <2 x i64> %1408, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1412, <2 x i64>* %1341, align 16
  %1413 = shufflevector <2 x i64> %1404, <2 x i64> %1410, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1413, <2 x i64>* %1343, align 16
  %1414 = shufflevector <2 x i64> %1404, <2 x i64> %1410, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1414, <2 x i64>* %1345, align 16
  %1415 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 1, i64 1), align 1
  %1416 = sext i8 %1415 to i32
  call fastcc void @idct8x8_sse4_1(<2 x i64>* nonnull %1250, <2 x i64>* nonnull %1187, i32 %1416, i32 1, i32 %4, i32 0)
  %1417 = getelementptr inbounds i8, i8* %10, i64 1
  %1418 = load i8, i8* %1417, align 1
  %1419 = sext i8 %1418 to i32
  %1420 = sub nsw i32 0, %1419
  call fastcc void @write_buffer_8x8(<2 x i64>* nonnull %1187, i16* %1, i32 %2, i32 1, i32 0, i32 %1420, i32 %4)
  br label %2126

1421:                                             ; preds = %5
  %1422 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %1423 = bitcast i32* %0 to <2 x i64>*
  %1424 = load <2 x i64>, <2 x i64>* %1423, align 16
  store <2 x i64> %1424, <2 x i64>* %1422, align 16
  %1425 = getelementptr inbounds i32, i32* %0, i64 4
  %1426 = bitcast i32* %1425 to <2 x i64>*
  %1427 = load <2 x i64>, <2 x i64>* %1426, align 16
  %1428 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %1427, <2 x i64>* %1428, align 16
  %1429 = getelementptr inbounds i32, i32* %0, i64 8
  %1430 = bitcast i32* %1429 to <2 x i64>*
  %1431 = load <2 x i64>, <2 x i64>* %1430, align 16
  %1432 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %1431, <2 x i64>* %1432, align 16
  %1433 = getelementptr inbounds i32, i32* %0, i64 12
  %1434 = bitcast i32* %1433 to <2 x i64>*
  %1435 = load <2 x i64>, <2 x i64>* %1434, align 16
  %1436 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %1435, <2 x i64>* %1436, align 16
  %1437 = getelementptr inbounds i32, i32* %0, i64 16
  %1438 = bitcast i32* %1437 to <2 x i64>*
  %1439 = load <2 x i64>, <2 x i64>* %1438, align 16
  %1440 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %1439, <2 x i64>* %1440, align 16
  %1441 = getelementptr inbounds i32, i32* %0, i64 20
  %1442 = bitcast i32* %1441 to <2 x i64>*
  %1443 = load <2 x i64>, <2 x i64>* %1442, align 16
  %1444 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %1443, <2 x i64>* %1444, align 16
  %1445 = getelementptr inbounds i32, i32* %0, i64 24
  %1446 = bitcast i32* %1445 to <2 x i64>*
  %1447 = load <2 x i64>, <2 x i64>* %1446, align 16
  %1448 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %1447, <2 x i64>* %1448, align 16
  %1449 = getelementptr inbounds i32, i32* %0, i64 28
  %1450 = bitcast i32* %1449 to <2 x i64>*
  %1451 = load <2 x i64>, <2 x i64>* %1450, align 16
  %1452 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %1451, <2 x i64>* %1452, align 16
  %1453 = getelementptr inbounds i32, i32* %0, i64 32
  %1454 = bitcast i32* %1453 to <2 x i64>*
  %1455 = load <2 x i64>, <2 x i64>* %1454, align 16
  %1456 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %1455, <2 x i64>* %1456, align 16
  %1457 = getelementptr inbounds i32, i32* %0, i64 36
  %1458 = bitcast i32* %1457 to <2 x i64>*
  %1459 = load <2 x i64>, <2 x i64>* %1458, align 16
  %1460 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %1459, <2 x i64>* %1460, align 16
  %1461 = getelementptr inbounds i32, i32* %0, i64 40
  %1462 = bitcast i32* %1461 to <2 x i64>*
  %1463 = load <2 x i64>, <2 x i64>* %1462, align 16
  %1464 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %1463, <2 x i64>* %1464, align 16
  %1465 = getelementptr inbounds i32, i32* %0, i64 44
  %1466 = bitcast i32* %1465 to <2 x i64>*
  %1467 = load <2 x i64>, <2 x i64>* %1466, align 16
  %1468 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %1467, <2 x i64>* %1468, align 16
  %1469 = getelementptr inbounds i32, i32* %0, i64 48
  %1470 = bitcast i32* %1469 to <2 x i64>*
  %1471 = load <2 x i64>, <2 x i64>* %1470, align 16
  %1472 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %1471, <2 x i64>* %1472, align 16
  %1473 = getelementptr inbounds i32, i32* %0, i64 52
  %1474 = bitcast i32* %1473 to <2 x i64>*
  %1475 = load <2 x i64>, <2 x i64>* %1474, align 16
  %1476 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %1475, <2 x i64>* %1476, align 16
  %1477 = getelementptr inbounds i32, i32* %0, i64 56
  %1478 = bitcast i32* %1477 to <2 x i64>*
  %1479 = load <2 x i64>, <2 x i64>* %1478, align 16
  %1480 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %1479, <2 x i64>* %1480, align 16
  %1481 = getelementptr inbounds i32, i32* %0, i64 60
  %1482 = bitcast i32* %1481 to <2 x i64>*
  %1483 = load <2 x i64>, <2 x i64>* %1482, align 16
  %1484 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %1483, <2 x i64>* %1484, align 16
  %1485 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  %1486 = bitcast [16 x <2 x i64>]* %6 to <4 x i32>*
  %1487 = bitcast <2 x i64> %1424 to <4 x i32>
  %1488 = bitcast <2 x i64>* %1432 to <4 x i32>*
  %1489 = bitcast <2 x i64> %1431 to <4 x i32>
  %1490 = shufflevector <4 x i32> %1487, <4 x i32> %1489, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1491 = bitcast <4 x i32> %1490 to <2 x i64>
  %1492 = shufflevector <4 x i32> %1487, <4 x i32> %1489, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1493 = bitcast <4 x i32> %1492 to <2 x i64>
  %1494 = bitcast <2 x i64>* %1440 to <4 x i32>*
  %1495 = bitcast <2 x i64> %1439 to <4 x i32>
  %1496 = bitcast <2 x i64>* %1448 to <4 x i32>*
  %1497 = bitcast <2 x i64> %1447 to <4 x i32>
  %1498 = shufflevector <4 x i32> %1495, <4 x i32> %1497, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1499 = bitcast <4 x i32> %1498 to <2 x i64>
  %1500 = shufflevector <4 x i32> %1495, <4 x i32> %1497, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1501 = bitcast <4 x i32> %1500 to <2 x i64>
  %1502 = shufflevector <2 x i64> %1491, <2 x i64> %1499, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1502, <2 x i64>* %1485, align 16
  %1503 = shufflevector <2 x i64> %1491, <2 x i64> %1499, <2 x i32> <i32 1, i32 3>
  %1504 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %1503, <2 x i64>* %1504, align 16
  %1505 = shufflevector <2 x i64> %1493, <2 x i64> %1501, <2 x i32> <i32 0, i32 2>
  %1506 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 4
  store <2 x i64> %1505, <2 x i64>* %1506, align 16
  %1507 = shufflevector <2 x i64> %1493, <2 x i64> %1501, <2 x i32> <i32 1, i32 3>
  %1508 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 6
  store <2 x i64> %1507, <2 x i64>* %1508, align 16
  %1509 = bitcast <2 x i64>* %1428 to <4 x i32>*
  %1510 = load <4 x i32>, <4 x i32>* %1509, align 16
  %1511 = bitcast <2 x i64>* %1436 to <4 x i32>*
  %1512 = bitcast <2 x i64> %1435 to <4 x i32>
  %1513 = shufflevector <4 x i32> %1510, <4 x i32> %1512, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1514 = bitcast <4 x i32> %1513 to <2 x i64>
  %1515 = shufflevector <4 x i32> %1510, <4 x i32> %1512, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1516 = bitcast <4 x i32> %1515 to <2 x i64>
  %1517 = bitcast <2 x i64>* %1444 to <4 x i32>*
  %1518 = bitcast <2 x i64> %1443 to <4 x i32>
  %1519 = bitcast <2 x i64>* %1452 to <4 x i32>*
  %1520 = bitcast <2 x i64> %1451 to <4 x i32>
  %1521 = shufflevector <4 x i32> %1518, <4 x i32> %1520, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1522 = bitcast <4 x i32> %1521 to <2 x i64>
  %1523 = shufflevector <4 x i32> %1518, <4 x i32> %1520, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1524 = bitcast <4 x i32> %1523 to <2 x i64>
  %1525 = shufflevector <2 x i64> %1514, <2 x i64> %1522, <2 x i32> <i32 0, i32 2>
  %1526 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  store <2 x i64> %1525, <2 x i64>* %1526, align 16
  %1527 = shufflevector <2 x i64> %1514, <2 x i64> %1522, <2 x i32> <i32 1, i32 3>
  %1528 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  store <2 x i64> %1527, <2 x i64>* %1528, align 16
  %1529 = shufflevector <2 x i64> %1516, <2 x i64> %1524, <2 x i32> <i32 0, i32 2>
  %1530 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 12
  store <2 x i64> %1529, <2 x i64>* %1530, align 16
  %1531 = shufflevector <2 x i64> %1516, <2 x i64> %1524, <2 x i32> <i32 1, i32 3>
  %1532 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 14
  store <2 x i64> %1531, <2 x i64>* %1532, align 16
  %1533 = bitcast <2 x i64>* %1456 to <4 x i32>*
  %1534 = load <4 x i32>, <4 x i32>* %1533, align 16
  %1535 = bitcast <2 x i64>* %1464 to <4 x i32>*
  %1536 = bitcast <2 x i64> %1463 to <4 x i32>
  %1537 = shufflevector <4 x i32> %1534, <4 x i32> %1536, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1538 = bitcast <4 x i32> %1537 to <2 x i64>
  %1539 = shufflevector <4 x i32> %1534, <4 x i32> %1536, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1540 = bitcast <4 x i32> %1539 to <2 x i64>
  %1541 = bitcast <2 x i64>* %1472 to <4 x i32>*
  %1542 = bitcast <2 x i64> %1471 to <4 x i32>
  %1543 = bitcast <2 x i64>* %1480 to <4 x i32>*
  %1544 = bitcast <2 x i64> %1479 to <4 x i32>
  %1545 = shufflevector <4 x i32> %1542, <4 x i32> %1544, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1546 = bitcast <4 x i32> %1545 to <2 x i64>
  %1547 = shufflevector <4 x i32> %1542, <4 x i32> %1544, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1548 = bitcast <4 x i32> %1547 to <2 x i64>
  %1549 = shufflevector <2 x i64> %1538, <2 x i64> %1546, <2 x i32> <i32 0, i32 2>
  %1550 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %1549, <2 x i64>* %1550, align 16
  %1551 = shufflevector <2 x i64> %1538, <2 x i64> %1546, <2 x i32> <i32 1, i32 3>
  %1552 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %1551, <2 x i64>* %1552, align 16
  %1553 = shufflevector <2 x i64> %1540, <2 x i64> %1548, <2 x i32> <i32 0, i32 2>
  %1554 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 5
  store <2 x i64> %1553, <2 x i64>* %1554, align 16
  %1555 = shufflevector <2 x i64> %1540, <2 x i64> %1548, <2 x i32> <i32 1, i32 3>
  %1556 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 7
  store <2 x i64> %1555, <2 x i64>* %1556, align 16
  %1557 = bitcast <2 x i64>* %1460 to <4 x i32>*
  %1558 = load <4 x i32>, <4 x i32>* %1557, align 16
  %1559 = bitcast <2 x i64>* %1468 to <4 x i32>*
  %1560 = load <4 x i32>, <4 x i32>* %1559, align 16
  %1561 = shufflevector <4 x i32> %1558, <4 x i32> %1560, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1562 = bitcast <4 x i32> %1561 to <2 x i64>
  %1563 = shufflevector <4 x i32> %1558, <4 x i32> %1560, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1564 = bitcast <4 x i32> %1563 to <2 x i64>
  %1565 = bitcast <2 x i64>* %1476 to <4 x i32>*
  %1566 = load <4 x i32>, <4 x i32>* %1565, align 16
  %1567 = bitcast <2 x i64>* %1484 to <4 x i32>*
  %1568 = load <4 x i32>, <4 x i32>* %1567, align 16
  %1569 = shufflevector <4 x i32> %1566, <4 x i32> %1568, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1570 = bitcast <4 x i32> %1569 to <2 x i64>
  %1571 = shufflevector <4 x i32> %1566, <4 x i32> %1568, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1572 = bitcast <4 x i32> %1571 to <2 x i64>
  %1573 = shufflevector <2 x i64> %1562, <2 x i64> %1570, <2 x i32> <i32 0, i32 2>
  %1574 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  store <2 x i64> %1573, <2 x i64>* %1574, align 16
  %1575 = shufflevector <2 x i64> %1562, <2 x i64> %1570, <2 x i32> <i32 1, i32 3>
  %1576 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  store <2 x i64> %1575, <2 x i64>* %1576, align 16
  %1577 = shufflevector <2 x i64> %1564, <2 x i64> %1572, <2 x i32> <i32 0, i32 2>
  %1578 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 13
  store <2 x i64> %1577, <2 x i64>* %1578, align 16
  %1579 = shufflevector <2 x i64> %1564, <2 x i64> %1572, <2 x i32> <i32 1, i32 3>
  %1580 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 15
  store <2 x i64> %1579, <2 x i64>* %1580, align 16
  %1581 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 1, i64 1), align 1
  %1582 = sext i8 %1581 to i32
  %1583 = load i8, i8* %10, align 1
  %1584 = sext i8 %1583 to i32
  %1585 = sub nsw i32 0, %1584
  call fastcc void @iadst8x8_sse4_1(<2 x i64>* nonnull %1485, <2 x i64>* nonnull %1422, i32 %1582, i32 0, i32 %4, i32 %1585)
  %1586 = load <4 x i32>, <4 x i32>* %1486, align 16
  %1587 = load <4 x i32>, <4 x i32>* %1488, align 16
  %1588 = shufflevector <4 x i32> %1586, <4 x i32> %1587, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1589 = bitcast <4 x i32> %1588 to <2 x i64>
  %1590 = shufflevector <4 x i32> %1586, <4 x i32> %1587, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1591 = bitcast <4 x i32> %1590 to <2 x i64>
  %1592 = load <4 x i32>, <4 x i32>* %1494, align 16
  %1593 = load <4 x i32>, <4 x i32>* %1496, align 16
  %1594 = shufflevector <4 x i32> %1592, <4 x i32> %1593, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1595 = bitcast <4 x i32> %1594 to <2 x i64>
  %1596 = shufflevector <4 x i32> %1592, <4 x i32> %1593, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1597 = bitcast <4 x i32> %1596 to <2 x i64>
  %1598 = shufflevector <2 x i64> %1589, <2 x i64> %1595, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1598, <2 x i64>* %1485, align 16
  %1599 = shufflevector <2 x i64> %1589, <2 x i64> %1595, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1599, <2 x i64>* %1504, align 16
  %1600 = shufflevector <2 x i64> %1591, <2 x i64> %1597, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1600, <2 x i64>* %1506, align 16
  %1601 = shufflevector <2 x i64> %1591, <2 x i64> %1597, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1601, <2 x i64>* %1508, align 16
  %1602 = load <4 x i32>, <4 x i32>* %1509, align 16
  %1603 = load <4 x i32>, <4 x i32>* %1511, align 16
  %1604 = shufflevector <4 x i32> %1602, <4 x i32> %1603, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1605 = bitcast <4 x i32> %1604 to <2 x i64>
  %1606 = shufflevector <4 x i32> %1602, <4 x i32> %1603, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1607 = bitcast <4 x i32> %1606 to <2 x i64>
  %1608 = load <4 x i32>, <4 x i32>* %1517, align 16
  %1609 = load <4 x i32>, <4 x i32>* %1519, align 16
  %1610 = shufflevector <4 x i32> %1608, <4 x i32> %1609, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1611 = bitcast <4 x i32> %1610 to <2 x i64>
  %1612 = shufflevector <4 x i32> %1608, <4 x i32> %1609, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1613 = bitcast <4 x i32> %1612 to <2 x i64>
  %1614 = shufflevector <2 x i64> %1605, <2 x i64> %1611, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1614, <2 x i64>* %1526, align 16
  %1615 = shufflevector <2 x i64> %1605, <2 x i64> %1611, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1615, <2 x i64>* %1528, align 16
  %1616 = shufflevector <2 x i64> %1607, <2 x i64> %1613, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1616, <2 x i64>* %1530, align 16
  %1617 = shufflevector <2 x i64> %1607, <2 x i64> %1613, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1617, <2 x i64>* %1532, align 16
  %1618 = load <4 x i32>, <4 x i32>* %1533, align 16
  %1619 = load <4 x i32>, <4 x i32>* %1535, align 16
  %1620 = shufflevector <4 x i32> %1618, <4 x i32> %1619, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1621 = bitcast <4 x i32> %1620 to <2 x i64>
  %1622 = shufflevector <4 x i32> %1618, <4 x i32> %1619, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1623 = bitcast <4 x i32> %1622 to <2 x i64>
  %1624 = load <4 x i32>, <4 x i32>* %1541, align 16
  %1625 = load <4 x i32>, <4 x i32>* %1543, align 16
  %1626 = shufflevector <4 x i32> %1624, <4 x i32> %1625, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1627 = bitcast <4 x i32> %1626 to <2 x i64>
  %1628 = shufflevector <4 x i32> %1624, <4 x i32> %1625, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1629 = bitcast <4 x i32> %1628 to <2 x i64>
  %1630 = shufflevector <2 x i64> %1621, <2 x i64> %1627, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1630, <2 x i64>* %1550, align 16
  %1631 = shufflevector <2 x i64> %1621, <2 x i64> %1627, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1631, <2 x i64>* %1552, align 16
  %1632 = shufflevector <2 x i64> %1623, <2 x i64> %1629, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1632, <2 x i64>* %1554, align 16
  %1633 = shufflevector <2 x i64> %1623, <2 x i64> %1629, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1633, <2 x i64>* %1556, align 16
  %1634 = load <4 x i32>, <4 x i32>* %1557, align 16
  %1635 = load <4 x i32>, <4 x i32>* %1559, align 16
  %1636 = shufflevector <4 x i32> %1634, <4 x i32> %1635, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1637 = bitcast <4 x i32> %1636 to <2 x i64>
  %1638 = shufflevector <4 x i32> %1634, <4 x i32> %1635, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1639 = bitcast <4 x i32> %1638 to <2 x i64>
  %1640 = load <4 x i32>, <4 x i32>* %1565, align 16
  %1641 = load <4 x i32>, <4 x i32>* %1567, align 16
  %1642 = shufflevector <4 x i32> %1640, <4 x i32> %1641, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1643 = bitcast <4 x i32> %1642 to <2 x i64>
  %1644 = shufflevector <4 x i32> %1640, <4 x i32> %1641, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1645 = bitcast <4 x i32> %1644 to <2 x i64>
  %1646 = shufflevector <2 x i64> %1637, <2 x i64> %1643, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1646, <2 x i64>* %1574, align 16
  %1647 = shufflevector <2 x i64> %1637, <2 x i64> %1643, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1647, <2 x i64>* %1576, align 16
  %1648 = shufflevector <2 x i64> %1639, <2 x i64> %1645, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1648, <2 x i64>* %1578, align 16
  %1649 = shufflevector <2 x i64> %1639, <2 x i64> %1645, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1649, <2 x i64>* %1580, align 16
  %1650 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 1, i64 1), align 1
  %1651 = sext i8 %1650 to i32
  call fastcc void @iadst8x8_sse4_1(<2 x i64>* nonnull %1485, <2 x i64>* nonnull %1422, i32 %1651, i32 1, i32 %4, i32 0)
  %1652 = getelementptr inbounds i8, i8* %10, i64 1
  %1653 = load i8, i8* %1652, align 1
  %1654 = sext i8 %1653 to i32
  %1655 = sub nsw i32 0, %1654
  call fastcc void @write_buffer_8x8(<2 x i64>* nonnull %1422, i16* %1, i32 %2, i32 1, i32 0, i32 %1655, i32 %4)
  br label %2126

1656:                                             ; preds = %5
  %1657 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %1658 = bitcast i32* %0 to <2 x i64>*
  %1659 = load <2 x i64>, <2 x i64>* %1658, align 16
  store <2 x i64> %1659, <2 x i64>* %1657, align 16
  %1660 = getelementptr inbounds i32, i32* %0, i64 4
  %1661 = bitcast i32* %1660 to <2 x i64>*
  %1662 = load <2 x i64>, <2 x i64>* %1661, align 16
  %1663 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %1662, <2 x i64>* %1663, align 16
  %1664 = getelementptr inbounds i32, i32* %0, i64 8
  %1665 = bitcast i32* %1664 to <2 x i64>*
  %1666 = load <2 x i64>, <2 x i64>* %1665, align 16
  %1667 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %1666, <2 x i64>* %1667, align 16
  %1668 = getelementptr inbounds i32, i32* %0, i64 12
  %1669 = bitcast i32* %1668 to <2 x i64>*
  %1670 = load <2 x i64>, <2 x i64>* %1669, align 16
  %1671 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %1670, <2 x i64>* %1671, align 16
  %1672 = getelementptr inbounds i32, i32* %0, i64 16
  %1673 = bitcast i32* %1672 to <2 x i64>*
  %1674 = load <2 x i64>, <2 x i64>* %1673, align 16
  %1675 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %1674, <2 x i64>* %1675, align 16
  %1676 = getelementptr inbounds i32, i32* %0, i64 20
  %1677 = bitcast i32* %1676 to <2 x i64>*
  %1678 = load <2 x i64>, <2 x i64>* %1677, align 16
  %1679 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %1678, <2 x i64>* %1679, align 16
  %1680 = getelementptr inbounds i32, i32* %0, i64 24
  %1681 = bitcast i32* %1680 to <2 x i64>*
  %1682 = load <2 x i64>, <2 x i64>* %1681, align 16
  %1683 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %1682, <2 x i64>* %1683, align 16
  %1684 = getelementptr inbounds i32, i32* %0, i64 28
  %1685 = bitcast i32* %1684 to <2 x i64>*
  %1686 = load <2 x i64>, <2 x i64>* %1685, align 16
  %1687 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %1686, <2 x i64>* %1687, align 16
  %1688 = getelementptr inbounds i32, i32* %0, i64 32
  %1689 = bitcast i32* %1688 to <2 x i64>*
  %1690 = load <2 x i64>, <2 x i64>* %1689, align 16
  %1691 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %1690, <2 x i64>* %1691, align 16
  %1692 = getelementptr inbounds i32, i32* %0, i64 36
  %1693 = bitcast i32* %1692 to <2 x i64>*
  %1694 = load <2 x i64>, <2 x i64>* %1693, align 16
  %1695 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %1694, <2 x i64>* %1695, align 16
  %1696 = getelementptr inbounds i32, i32* %0, i64 40
  %1697 = bitcast i32* %1696 to <2 x i64>*
  %1698 = load <2 x i64>, <2 x i64>* %1697, align 16
  %1699 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %1698, <2 x i64>* %1699, align 16
  %1700 = getelementptr inbounds i32, i32* %0, i64 44
  %1701 = bitcast i32* %1700 to <2 x i64>*
  %1702 = load <2 x i64>, <2 x i64>* %1701, align 16
  %1703 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %1702, <2 x i64>* %1703, align 16
  %1704 = getelementptr inbounds i32, i32* %0, i64 48
  %1705 = bitcast i32* %1704 to <2 x i64>*
  %1706 = load <2 x i64>, <2 x i64>* %1705, align 16
  %1707 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %1706, <2 x i64>* %1707, align 16
  %1708 = getelementptr inbounds i32, i32* %0, i64 52
  %1709 = bitcast i32* %1708 to <2 x i64>*
  %1710 = load <2 x i64>, <2 x i64>* %1709, align 16
  %1711 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %1710, <2 x i64>* %1711, align 16
  %1712 = getelementptr inbounds i32, i32* %0, i64 56
  %1713 = bitcast i32* %1712 to <2 x i64>*
  %1714 = load <2 x i64>, <2 x i64>* %1713, align 16
  %1715 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %1714, <2 x i64>* %1715, align 16
  %1716 = getelementptr inbounds i32, i32* %0, i64 60
  %1717 = bitcast i32* %1716 to <2 x i64>*
  %1718 = load <2 x i64>, <2 x i64>* %1717, align 16
  %1719 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %1718, <2 x i64>* %1719, align 16
  %1720 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  %1721 = bitcast [16 x <2 x i64>]* %6 to <4 x i32>*
  %1722 = bitcast <2 x i64> %1659 to <4 x i32>
  %1723 = bitcast <2 x i64>* %1667 to <4 x i32>*
  %1724 = bitcast <2 x i64> %1666 to <4 x i32>
  %1725 = shufflevector <4 x i32> %1722, <4 x i32> %1724, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1726 = bitcast <4 x i32> %1725 to <2 x i64>
  %1727 = shufflevector <4 x i32> %1722, <4 x i32> %1724, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1728 = bitcast <4 x i32> %1727 to <2 x i64>
  %1729 = bitcast <2 x i64>* %1675 to <4 x i32>*
  %1730 = bitcast <2 x i64> %1674 to <4 x i32>
  %1731 = bitcast <2 x i64>* %1683 to <4 x i32>*
  %1732 = bitcast <2 x i64> %1682 to <4 x i32>
  %1733 = shufflevector <4 x i32> %1730, <4 x i32> %1732, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1734 = bitcast <4 x i32> %1733 to <2 x i64>
  %1735 = shufflevector <4 x i32> %1730, <4 x i32> %1732, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1736 = bitcast <4 x i32> %1735 to <2 x i64>
  %1737 = shufflevector <2 x i64> %1726, <2 x i64> %1734, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1737, <2 x i64>* %1720, align 16
  %1738 = shufflevector <2 x i64> %1726, <2 x i64> %1734, <2 x i32> <i32 1, i32 3>
  %1739 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %1738, <2 x i64>* %1739, align 16
  %1740 = shufflevector <2 x i64> %1728, <2 x i64> %1736, <2 x i32> <i32 0, i32 2>
  %1741 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 4
  store <2 x i64> %1740, <2 x i64>* %1741, align 16
  %1742 = shufflevector <2 x i64> %1728, <2 x i64> %1736, <2 x i32> <i32 1, i32 3>
  %1743 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 6
  store <2 x i64> %1742, <2 x i64>* %1743, align 16
  %1744 = bitcast <2 x i64>* %1663 to <4 x i32>*
  %1745 = load <4 x i32>, <4 x i32>* %1744, align 16
  %1746 = bitcast <2 x i64>* %1671 to <4 x i32>*
  %1747 = bitcast <2 x i64> %1670 to <4 x i32>
  %1748 = shufflevector <4 x i32> %1745, <4 x i32> %1747, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1749 = bitcast <4 x i32> %1748 to <2 x i64>
  %1750 = shufflevector <4 x i32> %1745, <4 x i32> %1747, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1751 = bitcast <4 x i32> %1750 to <2 x i64>
  %1752 = bitcast <2 x i64>* %1679 to <4 x i32>*
  %1753 = bitcast <2 x i64> %1678 to <4 x i32>
  %1754 = bitcast <2 x i64>* %1687 to <4 x i32>*
  %1755 = bitcast <2 x i64> %1686 to <4 x i32>
  %1756 = shufflevector <4 x i32> %1753, <4 x i32> %1755, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1757 = bitcast <4 x i32> %1756 to <2 x i64>
  %1758 = shufflevector <4 x i32> %1753, <4 x i32> %1755, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1759 = bitcast <4 x i32> %1758 to <2 x i64>
  %1760 = shufflevector <2 x i64> %1749, <2 x i64> %1757, <2 x i32> <i32 0, i32 2>
  %1761 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  store <2 x i64> %1760, <2 x i64>* %1761, align 16
  %1762 = shufflevector <2 x i64> %1749, <2 x i64> %1757, <2 x i32> <i32 1, i32 3>
  %1763 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  store <2 x i64> %1762, <2 x i64>* %1763, align 16
  %1764 = shufflevector <2 x i64> %1751, <2 x i64> %1759, <2 x i32> <i32 0, i32 2>
  %1765 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 12
  store <2 x i64> %1764, <2 x i64>* %1765, align 16
  %1766 = shufflevector <2 x i64> %1751, <2 x i64> %1759, <2 x i32> <i32 1, i32 3>
  %1767 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 14
  store <2 x i64> %1766, <2 x i64>* %1767, align 16
  %1768 = bitcast <2 x i64>* %1691 to <4 x i32>*
  %1769 = load <4 x i32>, <4 x i32>* %1768, align 16
  %1770 = bitcast <2 x i64>* %1699 to <4 x i32>*
  %1771 = bitcast <2 x i64> %1698 to <4 x i32>
  %1772 = shufflevector <4 x i32> %1769, <4 x i32> %1771, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1773 = bitcast <4 x i32> %1772 to <2 x i64>
  %1774 = shufflevector <4 x i32> %1769, <4 x i32> %1771, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1775 = bitcast <4 x i32> %1774 to <2 x i64>
  %1776 = bitcast <2 x i64>* %1707 to <4 x i32>*
  %1777 = bitcast <2 x i64> %1706 to <4 x i32>
  %1778 = bitcast <2 x i64>* %1715 to <4 x i32>*
  %1779 = bitcast <2 x i64> %1714 to <4 x i32>
  %1780 = shufflevector <4 x i32> %1777, <4 x i32> %1779, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1781 = bitcast <4 x i32> %1780 to <2 x i64>
  %1782 = shufflevector <4 x i32> %1777, <4 x i32> %1779, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1783 = bitcast <4 x i32> %1782 to <2 x i64>
  %1784 = shufflevector <2 x i64> %1773, <2 x i64> %1781, <2 x i32> <i32 0, i32 2>
  %1785 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %1784, <2 x i64>* %1785, align 16
  %1786 = shufflevector <2 x i64> %1773, <2 x i64> %1781, <2 x i32> <i32 1, i32 3>
  %1787 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %1786, <2 x i64>* %1787, align 16
  %1788 = shufflevector <2 x i64> %1775, <2 x i64> %1783, <2 x i32> <i32 0, i32 2>
  %1789 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 5
  store <2 x i64> %1788, <2 x i64>* %1789, align 16
  %1790 = shufflevector <2 x i64> %1775, <2 x i64> %1783, <2 x i32> <i32 1, i32 3>
  %1791 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 7
  store <2 x i64> %1790, <2 x i64>* %1791, align 16
  %1792 = bitcast <2 x i64>* %1695 to <4 x i32>*
  %1793 = load <4 x i32>, <4 x i32>* %1792, align 16
  %1794 = bitcast <2 x i64>* %1703 to <4 x i32>*
  %1795 = load <4 x i32>, <4 x i32>* %1794, align 16
  %1796 = shufflevector <4 x i32> %1793, <4 x i32> %1795, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1797 = bitcast <4 x i32> %1796 to <2 x i64>
  %1798 = shufflevector <4 x i32> %1793, <4 x i32> %1795, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1799 = bitcast <4 x i32> %1798 to <2 x i64>
  %1800 = bitcast <2 x i64>* %1711 to <4 x i32>*
  %1801 = load <4 x i32>, <4 x i32>* %1800, align 16
  %1802 = bitcast <2 x i64>* %1719 to <4 x i32>*
  %1803 = load <4 x i32>, <4 x i32>* %1802, align 16
  %1804 = shufflevector <4 x i32> %1801, <4 x i32> %1803, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1805 = bitcast <4 x i32> %1804 to <2 x i64>
  %1806 = shufflevector <4 x i32> %1801, <4 x i32> %1803, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1807 = bitcast <4 x i32> %1806 to <2 x i64>
  %1808 = shufflevector <2 x i64> %1797, <2 x i64> %1805, <2 x i32> <i32 0, i32 2>
  %1809 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  store <2 x i64> %1808, <2 x i64>* %1809, align 16
  %1810 = shufflevector <2 x i64> %1797, <2 x i64> %1805, <2 x i32> <i32 1, i32 3>
  %1811 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  store <2 x i64> %1810, <2 x i64>* %1811, align 16
  %1812 = shufflevector <2 x i64> %1799, <2 x i64> %1807, <2 x i32> <i32 0, i32 2>
  %1813 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 13
  store <2 x i64> %1812, <2 x i64>* %1813, align 16
  %1814 = shufflevector <2 x i64> %1799, <2 x i64> %1807, <2 x i32> <i32 1, i32 3>
  %1815 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 15
  store <2 x i64> %1814, <2 x i64>* %1815, align 16
  %1816 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 1, i64 1), align 1
  %1817 = sext i8 %1816 to i32
  %1818 = load i8, i8* %10, align 1
  %1819 = sext i8 %1818 to i32
  %1820 = sub nsw i32 0, %1819
  call fastcc void @iadst8x8_sse4_1(<2 x i64>* nonnull %1720, <2 x i64>* nonnull %1657, i32 %1817, i32 0, i32 %4, i32 %1820)
  %1821 = load <4 x i32>, <4 x i32>* %1721, align 16
  %1822 = load <4 x i32>, <4 x i32>* %1723, align 16
  %1823 = shufflevector <4 x i32> %1821, <4 x i32> %1822, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1824 = bitcast <4 x i32> %1823 to <2 x i64>
  %1825 = shufflevector <4 x i32> %1821, <4 x i32> %1822, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1826 = bitcast <4 x i32> %1825 to <2 x i64>
  %1827 = load <4 x i32>, <4 x i32>* %1729, align 16
  %1828 = load <4 x i32>, <4 x i32>* %1731, align 16
  %1829 = shufflevector <4 x i32> %1827, <4 x i32> %1828, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1830 = bitcast <4 x i32> %1829 to <2 x i64>
  %1831 = shufflevector <4 x i32> %1827, <4 x i32> %1828, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1832 = bitcast <4 x i32> %1831 to <2 x i64>
  %1833 = shufflevector <2 x i64> %1824, <2 x i64> %1830, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1833, <2 x i64>* %1720, align 16
  %1834 = shufflevector <2 x i64> %1824, <2 x i64> %1830, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1834, <2 x i64>* %1739, align 16
  %1835 = shufflevector <2 x i64> %1826, <2 x i64> %1832, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1835, <2 x i64>* %1741, align 16
  %1836 = shufflevector <2 x i64> %1826, <2 x i64> %1832, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1836, <2 x i64>* %1743, align 16
  %1837 = load <4 x i32>, <4 x i32>* %1744, align 16
  %1838 = load <4 x i32>, <4 x i32>* %1746, align 16
  %1839 = shufflevector <4 x i32> %1837, <4 x i32> %1838, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1840 = bitcast <4 x i32> %1839 to <2 x i64>
  %1841 = shufflevector <4 x i32> %1837, <4 x i32> %1838, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1842 = bitcast <4 x i32> %1841 to <2 x i64>
  %1843 = load <4 x i32>, <4 x i32>* %1752, align 16
  %1844 = load <4 x i32>, <4 x i32>* %1754, align 16
  %1845 = shufflevector <4 x i32> %1843, <4 x i32> %1844, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1846 = bitcast <4 x i32> %1845 to <2 x i64>
  %1847 = shufflevector <4 x i32> %1843, <4 x i32> %1844, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1848 = bitcast <4 x i32> %1847 to <2 x i64>
  %1849 = shufflevector <2 x i64> %1840, <2 x i64> %1846, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1849, <2 x i64>* %1761, align 16
  %1850 = shufflevector <2 x i64> %1840, <2 x i64> %1846, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1850, <2 x i64>* %1763, align 16
  %1851 = shufflevector <2 x i64> %1842, <2 x i64> %1848, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1851, <2 x i64>* %1765, align 16
  %1852 = shufflevector <2 x i64> %1842, <2 x i64> %1848, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1852, <2 x i64>* %1767, align 16
  %1853 = load <4 x i32>, <4 x i32>* %1768, align 16
  %1854 = load <4 x i32>, <4 x i32>* %1770, align 16
  %1855 = shufflevector <4 x i32> %1853, <4 x i32> %1854, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1856 = bitcast <4 x i32> %1855 to <2 x i64>
  %1857 = shufflevector <4 x i32> %1853, <4 x i32> %1854, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1858 = bitcast <4 x i32> %1857 to <2 x i64>
  %1859 = load <4 x i32>, <4 x i32>* %1776, align 16
  %1860 = load <4 x i32>, <4 x i32>* %1778, align 16
  %1861 = shufflevector <4 x i32> %1859, <4 x i32> %1860, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1862 = bitcast <4 x i32> %1861 to <2 x i64>
  %1863 = shufflevector <4 x i32> %1859, <4 x i32> %1860, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1864 = bitcast <4 x i32> %1863 to <2 x i64>
  %1865 = shufflevector <2 x i64> %1856, <2 x i64> %1862, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1865, <2 x i64>* %1785, align 16
  %1866 = shufflevector <2 x i64> %1856, <2 x i64> %1862, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1866, <2 x i64>* %1787, align 16
  %1867 = shufflevector <2 x i64> %1858, <2 x i64> %1864, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1867, <2 x i64>* %1789, align 16
  %1868 = shufflevector <2 x i64> %1858, <2 x i64> %1864, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1868, <2 x i64>* %1791, align 16
  %1869 = load <4 x i32>, <4 x i32>* %1792, align 16
  %1870 = load <4 x i32>, <4 x i32>* %1794, align 16
  %1871 = shufflevector <4 x i32> %1869, <4 x i32> %1870, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1872 = bitcast <4 x i32> %1871 to <2 x i64>
  %1873 = shufflevector <4 x i32> %1869, <4 x i32> %1870, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1874 = bitcast <4 x i32> %1873 to <2 x i64>
  %1875 = load <4 x i32>, <4 x i32>* %1800, align 16
  %1876 = load <4 x i32>, <4 x i32>* %1802, align 16
  %1877 = shufflevector <4 x i32> %1875, <4 x i32> %1876, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1878 = bitcast <4 x i32> %1877 to <2 x i64>
  %1879 = shufflevector <4 x i32> %1875, <4 x i32> %1876, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1880 = bitcast <4 x i32> %1879 to <2 x i64>
  %1881 = shufflevector <2 x i64> %1872, <2 x i64> %1878, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1881, <2 x i64>* %1809, align 16
  %1882 = shufflevector <2 x i64> %1872, <2 x i64> %1878, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1882, <2 x i64>* %1811, align 16
  %1883 = shufflevector <2 x i64> %1874, <2 x i64> %1880, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1883, <2 x i64>* %1813, align 16
  %1884 = shufflevector <2 x i64> %1874, <2 x i64> %1880, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1884, <2 x i64>* %1815, align 16
  %1885 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 1, i64 1), align 1
  %1886 = sext i8 %1885 to i32
  call fastcc void @iadst8x8_sse4_1(<2 x i64>* nonnull %1720, <2 x i64>* nonnull %1657, i32 %1886, i32 1, i32 %4, i32 0)
  %1887 = getelementptr inbounds i8, i8* %10, i64 1
  %1888 = load i8, i8* %1887, align 1
  %1889 = sext i8 %1888 to i32
  %1890 = sub nsw i32 0, %1889
  call fastcc void @write_buffer_8x8(<2 x i64>* nonnull %1657, i16* %1, i32 %2, i32 1, i32 1, i32 %1890, i32 %4)
  br label %2126

1891:                                             ; preds = %5
  %1892 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %1893 = bitcast i32* %0 to <2 x i64>*
  %1894 = load <2 x i64>, <2 x i64>* %1893, align 16
  store <2 x i64> %1894, <2 x i64>* %1892, align 16
  %1895 = getelementptr inbounds i32, i32* %0, i64 4
  %1896 = bitcast i32* %1895 to <2 x i64>*
  %1897 = load <2 x i64>, <2 x i64>* %1896, align 16
  %1898 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %1897, <2 x i64>* %1898, align 16
  %1899 = getelementptr inbounds i32, i32* %0, i64 8
  %1900 = bitcast i32* %1899 to <2 x i64>*
  %1901 = load <2 x i64>, <2 x i64>* %1900, align 16
  %1902 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %1901, <2 x i64>* %1902, align 16
  %1903 = getelementptr inbounds i32, i32* %0, i64 12
  %1904 = bitcast i32* %1903 to <2 x i64>*
  %1905 = load <2 x i64>, <2 x i64>* %1904, align 16
  %1906 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %1905, <2 x i64>* %1906, align 16
  %1907 = getelementptr inbounds i32, i32* %0, i64 16
  %1908 = bitcast i32* %1907 to <2 x i64>*
  %1909 = load <2 x i64>, <2 x i64>* %1908, align 16
  %1910 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %1909, <2 x i64>* %1910, align 16
  %1911 = getelementptr inbounds i32, i32* %0, i64 20
  %1912 = bitcast i32* %1911 to <2 x i64>*
  %1913 = load <2 x i64>, <2 x i64>* %1912, align 16
  %1914 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %1913, <2 x i64>* %1914, align 16
  %1915 = getelementptr inbounds i32, i32* %0, i64 24
  %1916 = bitcast i32* %1915 to <2 x i64>*
  %1917 = load <2 x i64>, <2 x i64>* %1916, align 16
  %1918 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %1917, <2 x i64>* %1918, align 16
  %1919 = getelementptr inbounds i32, i32* %0, i64 28
  %1920 = bitcast i32* %1919 to <2 x i64>*
  %1921 = load <2 x i64>, <2 x i64>* %1920, align 16
  %1922 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %1921, <2 x i64>* %1922, align 16
  %1923 = getelementptr inbounds i32, i32* %0, i64 32
  %1924 = bitcast i32* %1923 to <2 x i64>*
  %1925 = load <2 x i64>, <2 x i64>* %1924, align 16
  %1926 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %1925, <2 x i64>* %1926, align 16
  %1927 = getelementptr inbounds i32, i32* %0, i64 36
  %1928 = bitcast i32* %1927 to <2 x i64>*
  %1929 = load <2 x i64>, <2 x i64>* %1928, align 16
  %1930 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %1929, <2 x i64>* %1930, align 16
  %1931 = getelementptr inbounds i32, i32* %0, i64 40
  %1932 = bitcast i32* %1931 to <2 x i64>*
  %1933 = load <2 x i64>, <2 x i64>* %1932, align 16
  %1934 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %1933, <2 x i64>* %1934, align 16
  %1935 = getelementptr inbounds i32, i32* %0, i64 44
  %1936 = bitcast i32* %1935 to <2 x i64>*
  %1937 = load <2 x i64>, <2 x i64>* %1936, align 16
  %1938 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %1937, <2 x i64>* %1938, align 16
  %1939 = getelementptr inbounds i32, i32* %0, i64 48
  %1940 = bitcast i32* %1939 to <2 x i64>*
  %1941 = load <2 x i64>, <2 x i64>* %1940, align 16
  %1942 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %1941, <2 x i64>* %1942, align 16
  %1943 = getelementptr inbounds i32, i32* %0, i64 52
  %1944 = bitcast i32* %1943 to <2 x i64>*
  %1945 = load <2 x i64>, <2 x i64>* %1944, align 16
  %1946 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %1945, <2 x i64>* %1946, align 16
  %1947 = getelementptr inbounds i32, i32* %0, i64 56
  %1948 = bitcast i32* %1947 to <2 x i64>*
  %1949 = load <2 x i64>, <2 x i64>* %1948, align 16
  %1950 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %1949, <2 x i64>* %1950, align 16
  %1951 = getelementptr inbounds i32, i32* %0, i64 60
  %1952 = bitcast i32* %1951 to <2 x i64>*
  %1953 = load <2 x i64>, <2 x i64>* %1952, align 16
  %1954 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %1953, <2 x i64>* %1954, align 16
  %1955 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  %1956 = bitcast [16 x <2 x i64>]* %6 to <4 x i32>*
  %1957 = bitcast <2 x i64> %1894 to <4 x i32>
  %1958 = bitcast <2 x i64>* %1902 to <4 x i32>*
  %1959 = bitcast <2 x i64> %1901 to <4 x i32>
  %1960 = shufflevector <4 x i32> %1957, <4 x i32> %1959, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1961 = bitcast <4 x i32> %1960 to <2 x i64>
  %1962 = shufflevector <4 x i32> %1957, <4 x i32> %1959, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1963 = bitcast <4 x i32> %1962 to <2 x i64>
  %1964 = bitcast <2 x i64>* %1910 to <4 x i32>*
  %1965 = bitcast <2 x i64> %1909 to <4 x i32>
  %1966 = bitcast <2 x i64>* %1918 to <4 x i32>*
  %1967 = bitcast <2 x i64> %1917 to <4 x i32>
  %1968 = shufflevector <4 x i32> %1965, <4 x i32> %1967, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1969 = bitcast <4 x i32> %1968 to <2 x i64>
  %1970 = shufflevector <4 x i32> %1965, <4 x i32> %1967, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1971 = bitcast <4 x i32> %1970 to <2 x i64>
  %1972 = shufflevector <2 x i64> %1961, <2 x i64> %1969, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1972, <2 x i64>* %1955, align 16
  %1973 = shufflevector <2 x i64> %1961, <2 x i64> %1969, <2 x i32> <i32 1, i32 3>
  %1974 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %1973, <2 x i64>* %1974, align 16
  %1975 = shufflevector <2 x i64> %1963, <2 x i64> %1971, <2 x i32> <i32 0, i32 2>
  %1976 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 4
  store <2 x i64> %1975, <2 x i64>* %1976, align 16
  %1977 = shufflevector <2 x i64> %1963, <2 x i64> %1971, <2 x i32> <i32 1, i32 3>
  %1978 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 6
  store <2 x i64> %1977, <2 x i64>* %1978, align 16
  %1979 = bitcast <2 x i64>* %1898 to <4 x i32>*
  %1980 = load <4 x i32>, <4 x i32>* %1979, align 16
  %1981 = bitcast <2 x i64>* %1906 to <4 x i32>*
  %1982 = bitcast <2 x i64> %1905 to <4 x i32>
  %1983 = shufflevector <4 x i32> %1980, <4 x i32> %1982, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1984 = bitcast <4 x i32> %1983 to <2 x i64>
  %1985 = shufflevector <4 x i32> %1980, <4 x i32> %1982, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1986 = bitcast <4 x i32> %1985 to <2 x i64>
  %1987 = bitcast <2 x i64>* %1914 to <4 x i32>*
  %1988 = bitcast <2 x i64> %1913 to <4 x i32>
  %1989 = bitcast <2 x i64>* %1922 to <4 x i32>*
  %1990 = bitcast <2 x i64> %1921 to <4 x i32>
  %1991 = shufflevector <4 x i32> %1988, <4 x i32> %1990, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1992 = bitcast <4 x i32> %1991 to <2 x i64>
  %1993 = shufflevector <4 x i32> %1988, <4 x i32> %1990, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1994 = bitcast <4 x i32> %1993 to <2 x i64>
  %1995 = shufflevector <2 x i64> %1984, <2 x i64> %1992, <2 x i32> <i32 0, i32 2>
  %1996 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  store <2 x i64> %1995, <2 x i64>* %1996, align 16
  %1997 = shufflevector <2 x i64> %1984, <2 x i64> %1992, <2 x i32> <i32 1, i32 3>
  %1998 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  store <2 x i64> %1997, <2 x i64>* %1998, align 16
  %1999 = shufflevector <2 x i64> %1986, <2 x i64> %1994, <2 x i32> <i32 0, i32 2>
  %2000 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 12
  store <2 x i64> %1999, <2 x i64>* %2000, align 16
  %2001 = shufflevector <2 x i64> %1986, <2 x i64> %1994, <2 x i32> <i32 1, i32 3>
  %2002 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 14
  store <2 x i64> %2001, <2 x i64>* %2002, align 16
  %2003 = bitcast <2 x i64>* %1926 to <4 x i32>*
  %2004 = load <4 x i32>, <4 x i32>* %2003, align 16
  %2005 = bitcast <2 x i64>* %1934 to <4 x i32>*
  %2006 = bitcast <2 x i64> %1933 to <4 x i32>
  %2007 = shufflevector <4 x i32> %2004, <4 x i32> %2006, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2008 = bitcast <4 x i32> %2007 to <2 x i64>
  %2009 = shufflevector <4 x i32> %2004, <4 x i32> %2006, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2010 = bitcast <4 x i32> %2009 to <2 x i64>
  %2011 = bitcast <2 x i64>* %1942 to <4 x i32>*
  %2012 = bitcast <2 x i64> %1941 to <4 x i32>
  %2013 = bitcast <2 x i64>* %1950 to <4 x i32>*
  %2014 = bitcast <2 x i64> %1949 to <4 x i32>
  %2015 = shufflevector <4 x i32> %2012, <4 x i32> %2014, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2016 = bitcast <4 x i32> %2015 to <2 x i64>
  %2017 = shufflevector <4 x i32> %2012, <4 x i32> %2014, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2018 = bitcast <4 x i32> %2017 to <2 x i64>
  %2019 = shufflevector <2 x i64> %2008, <2 x i64> %2016, <2 x i32> <i32 0, i32 2>
  %2020 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %2019, <2 x i64>* %2020, align 16
  %2021 = shufflevector <2 x i64> %2008, <2 x i64> %2016, <2 x i32> <i32 1, i32 3>
  %2022 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %2021, <2 x i64>* %2022, align 16
  %2023 = shufflevector <2 x i64> %2010, <2 x i64> %2018, <2 x i32> <i32 0, i32 2>
  %2024 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 5
  store <2 x i64> %2023, <2 x i64>* %2024, align 16
  %2025 = shufflevector <2 x i64> %2010, <2 x i64> %2018, <2 x i32> <i32 1, i32 3>
  %2026 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 7
  store <2 x i64> %2025, <2 x i64>* %2026, align 16
  %2027 = bitcast <2 x i64>* %1930 to <4 x i32>*
  %2028 = load <4 x i32>, <4 x i32>* %2027, align 16
  %2029 = bitcast <2 x i64>* %1938 to <4 x i32>*
  %2030 = load <4 x i32>, <4 x i32>* %2029, align 16
  %2031 = shufflevector <4 x i32> %2028, <4 x i32> %2030, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2032 = bitcast <4 x i32> %2031 to <2 x i64>
  %2033 = shufflevector <4 x i32> %2028, <4 x i32> %2030, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2034 = bitcast <4 x i32> %2033 to <2 x i64>
  %2035 = bitcast <2 x i64>* %1946 to <4 x i32>*
  %2036 = load <4 x i32>, <4 x i32>* %2035, align 16
  %2037 = bitcast <2 x i64>* %1954 to <4 x i32>*
  %2038 = load <4 x i32>, <4 x i32>* %2037, align 16
  %2039 = shufflevector <4 x i32> %2036, <4 x i32> %2038, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2040 = bitcast <4 x i32> %2039 to <2 x i64>
  %2041 = shufflevector <4 x i32> %2036, <4 x i32> %2038, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2042 = bitcast <4 x i32> %2041 to <2 x i64>
  %2043 = shufflevector <2 x i64> %2032, <2 x i64> %2040, <2 x i32> <i32 0, i32 2>
  %2044 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  store <2 x i64> %2043, <2 x i64>* %2044, align 16
  %2045 = shufflevector <2 x i64> %2032, <2 x i64> %2040, <2 x i32> <i32 1, i32 3>
  %2046 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  store <2 x i64> %2045, <2 x i64>* %2046, align 16
  %2047 = shufflevector <2 x i64> %2034, <2 x i64> %2042, <2 x i32> <i32 0, i32 2>
  %2048 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 13
  store <2 x i64> %2047, <2 x i64>* %2048, align 16
  %2049 = shufflevector <2 x i64> %2034, <2 x i64> %2042, <2 x i32> <i32 1, i32 3>
  %2050 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 15
  store <2 x i64> %2049, <2 x i64>* %2050, align 16
  %2051 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 1, i64 1), align 1
  %2052 = sext i8 %2051 to i32
  %2053 = load i8, i8* %10, align 1
  %2054 = sext i8 %2053 to i32
  %2055 = sub nsw i32 0, %2054
  call fastcc void @iadst8x8_sse4_1(<2 x i64>* nonnull %1955, <2 x i64>* nonnull %1892, i32 %2052, i32 0, i32 %4, i32 %2055)
  %2056 = load <4 x i32>, <4 x i32>* %1956, align 16
  %2057 = load <4 x i32>, <4 x i32>* %1958, align 16
  %2058 = shufflevector <4 x i32> %2056, <4 x i32> %2057, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2059 = bitcast <4 x i32> %2058 to <2 x i64>
  %2060 = shufflevector <4 x i32> %2056, <4 x i32> %2057, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2061 = bitcast <4 x i32> %2060 to <2 x i64>
  %2062 = load <4 x i32>, <4 x i32>* %1964, align 16
  %2063 = load <4 x i32>, <4 x i32>* %1966, align 16
  %2064 = shufflevector <4 x i32> %2062, <4 x i32> %2063, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2065 = bitcast <4 x i32> %2064 to <2 x i64>
  %2066 = shufflevector <4 x i32> %2062, <4 x i32> %2063, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2067 = bitcast <4 x i32> %2066 to <2 x i64>
  %2068 = shufflevector <2 x i64> %2059, <2 x i64> %2065, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %2068, <2 x i64>* %1955, align 16
  %2069 = shufflevector <2 x i64> %2059, <2 x i64> %2065, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %2069, <2 x i64>* %1974, align 16
  %2070 = shufflevector <2 x i64> %2061, <2 x i64> %2067, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %2070, <2 x i64>* %1976, align 16
  %2071 = shufflevector <2 x i64> %2061, <2 x i64> %2067, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %2071, <2 x i64>* %1978, align 16
  %2072 = load <4 x i32>, <4 x i32>* %1979, align 16
  %2073 = load <4 x i32>, <4 x i32>* %1981, align 16
  %2074 = shufflevector <4 x i32> %2072, <4 x i32> %2073, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2075 = bitcast <4 x i32> %2074 to <2 x i64>
  %2076 = shufflevector <4 x i32> %2072, <4 x i32> %2073, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2077 = bitcast <4 x i32> %2076 to <2 x i64>
  %2078 = load <4 x i32>, <4 x i32>* %1987, align 16
  %2079 = load <4 x i32>, <4 x i32>* %1989, align 16
  %2080 = shufflevector <4 x i32> %2078, <4 x i32> %2079, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2081 = bitcast <4 x i32> %2080 to <2 x i64>
  %2082 = shufflevector <4 x i32> %2078, <4 x i32> %2079, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2083 = bitcast <4 x i32> %2082 to <2 x i64>
  %2084 = shufflevector <2 x i64> %2075, <2 x i64> %2081, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %2084, <2 x i64>* %1996, align 16
  %2085 = shufflevector <2 x i64> %2075, <2 x i64> %2081, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %2085, <2 x i64>* %1998, align 16
  %2086 = shufflevector <2 x i64> %2077, <2 x i64> %2083, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %2086, <2 x i64>* %2000, align 16
  %2087 = shufflevector <2 x i64> %2077, <2 x i64> %2083, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %2087, <2 x i64>* %2002, align 16
  %2088 = load <4 x i32>, <4 x i32>* %2003, align 16
  %2089 = load <4 x i32>, <4 x i32>* %2005, align 16
  %2090 = shufflevector <4 x i32> %2088, <4 x i32> %2089, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2091 = bitcast <4 x i32> %2090 to <2 x i64>
  %2092 = shufflevector <4 x i32> %2088, <4 x i32> %2089, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2093 = bitcast <4 x i32> %2092 to <2 x i64>
  %2094 = load <4 x i32>, <4 x i32>* %2011, align 16
  %2095 = load <4 x i32>, <4 x i32>* %2013, align 16
  %2096 = shufflevector <4 x i32> %2094, <4 x i32> %2095, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2097 = bitcast <4 x i32> %2096 to <2 x i64>
  %2098 = shufflevector <4 x i32> %2094, <4 x i32> %2095, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2099 = bitcast <4 x i32> %2098 to <2 x i64>
  %2100 = shufflevector <2 x i64> %2091, <2 x i64> %2097, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %2100, <2 x i64>* %2020, align 16
  %2101 = shufflevector <2 x i64> %2091, <2 x i64> %2097, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %2101, <2 x i64>* %2022, align 16
  %2102 = shufflevector <2 x i64> %2093, <2 x i64> %2099, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %2102, <2 x i64>* %2024, align 16
  %2103 = shufflevector <2 x i64> %2093, <2 x i64> %2099, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %2103, <2 x i64>* %2026, align 16
  %2104 = load <4 x i32>, <4 x i32>* %2027, align 16
  %2105 = load <4 x i32>, <4 x i32>* %2029, align 16
  %2106 = shufflevector <4 x i32> %2104, <4 x i32> %2105, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2107 = bitcast <4 x i32> %2106 to <2 x i64>
  %2108 = shufflevector <4 x i32> %2104, <4 x i32> %2105, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2109 = bitcast <4 x i32> %2108 to <2 x i64>
  %2110 = load <4 x i32>, <4 x i32>* %2035, align 16
  %2111 = load <4 x i32>, <4 x i32>* %2037, align 16
  %2112 = shufflevector <4 x i32> %2110, <4 x i32> %2111, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2113 = bitcast <4 x i32> %2112 to <2 x i64>
  %2114 = shufflevector <4 x i32> %2110, <4 x i32> %2111, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2115 = bitcast <4 x i32> %2114 to <2 x i64>
  %2116 = shufflevector <2 x i64> %2107, <2 x i64> %2113, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %2116, <2 x i64>* %2044, align 16
  %2117 = shufflevector <2 x i64> %2107, <2 x i64> %2113, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %2117, <2 x i64>* %2046, align 16
  %2118 = shufflevector <2 x i64> %2109, <2 x i64> %2115, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %2118, <2 x i64>* %2048, align 16
  %2119 = shufflevector <2 x i64> %2109, <2 x i64> %2115, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %2119, <2 x i64>* %2050, align 16
  %2120 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 1, i64 1), align 1
  %2121 = sext i8 %2120 to i32
  call fastcc void @iadst8x8_sse4_1(<2 x i64>* nonnull %1955, <2 x i64>* nonnull %1892, i32 %2121, i32 1, i32 %4, i32 0)
  %2122 = getelementptr inbounds i8, i8* %10, i64 1
  %2123 = load i8, i8* %2122, align 1
  %2124 = sext i8 %2123 to i32
  %2125 = sub nsw i32 0, %2124
  call fastcc void @write_buffer_8x8(<2 x i64>* nonnull %1892, i16* %1, i32 %2, i32 0, i32 1, i32 %2125, i32 %4)
  br label %2126

2126:                                             ; preds = %5, %1891, %1656, %1421, %1186, %951, %716, %481, %246, %11
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %8) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @idct8x8_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>*, i32, i32, i32, i32) unnamed_addr #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 56
  %10 = load i32, i32* %9, align 16
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 8
  %14 = load i32, i32* %13, align 16
  %15 = sub nsw i32 0, %14
  %16 = insertelement <4 x i32> undef, i32 %15, i32 0
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> zeroinitializer
  %18 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 24
  %19 = load i32, i32* %18, align 16
  %20 = insertelement <4 x i32> undef, i32 %19, i32 0
  %21 = shufflevector <4 x i32> %20, <4 x i32> undef, <4 x i32> zeroinitializer
  %22 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 40
  %23 = load i32, i32* %22, align 16
  %24 = sub nsw i32 0, %23
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> zeroinitializer
  %27 = insertelement <4 x i32> undef, i32 %23, i32 0
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> zeroinitializer
  %29 = insertelement <4 x i32> undef, i32 %14, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %32 = load i32, i32* %31, align 16
  %33 = insertelement <4 x i32> undef, i32 %32, i32 0
  %34 = shufflevector <4 x i32> %33, <4 x i32> undef, <4 x i32> zeroinitializer
  %35 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 48
  %36 = load i32, i32* %35, align 16
  %37 = insertelement <4 x i32> undef, i32 %36, i32 0
  %38 = shufflevector <4 x i32> %37, <4 x i32> undef, <4 x i32> zeroinitializer
  %39 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 16
  %40 = load i32, i32* %39, align 16
  %41 = sub nsw i32 0, %40
  %42 = insertelement <4 x i32> undef, i32 %41, i32 0
  %43 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> zeroinitializer
  %44 = insertelement <4 x i32> undef, i32 %40, i32 0
  %45 = shufflevector <4 x i32> %44, <4 x i32> undef, <4 x i32> zeroinitializer
  %46 = add nsw i32 %2, -1
  %47 = shl i32 1, %46
  %48 = insertelement <4 x i32> undef, i32 %47, i32 0
  %49 = shufflevector <4 x i32> %48, <4 x i32> undef, <4 x i32> zeroinitializer
  %50 = icmp ne i32 %3, 0
  %51 = select i1 %50, i32 6, i32 8
  %52 = add nsw i32 %51, %4
  %53 = icmp slt i32 %52, 16
  %54 = add i32 %52, -1
  %55 = shl i32 1, %54
  %56 = select i1 %53, i32 32768, i32 %55
  %57 = sub nsw i32 0, %56
  %58 = insertelement <4 x i32> undef, i32 %57, i32 0
  %59 = shufflevector <4 x i32> %58, <4 x i32> undef, <4 x i32> zeroinitializer
  %60 = add nsw i32 %56, -1
  %61 = insertelement <4 x i32> undef, i32 %60, i32 0
  %62 = shufflevector <4 x i32> %61, <4 x i32> undef, <4 x i32> zeroinitializer
  %63 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %64 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %65 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %66 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %67 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %68 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %69 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  br label %70

70:                                               ; preds = %70, %6
  %71 = phi i64 [ 0, %6 ], [ %244, %70 ]
  %72 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %71
  %73 = bitcast <2 x i64>* %72 to <4 x i32>*
  %74 = load <4 x i32>, <4 x i32>* %73, align 16
  %75 = add nuw nsw i64 %71, 8
  %76 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %75
  %77 = bitcast <2 x i64>* %76 to <4 x i32>*
  %78 = load <4 x i32>, <4 x i32>* %77, align 16
  %79 = add nuw nsw i64 %71, 4
  %80 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %79
  %81 = bitcast <2 x i64>* %80 to <4 x i32>*
  %82 = load <4 x i32>, <4 x i32>* %81, align 16
  %83 = add nuw nsw i64 %71, 12
  %84 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %83
  %85 = bitcast <2 x i64>* %84 to <4 x i32>*
  %86 = load <4 x i32>, <4 x i32>* %85, align 16
  %87 = add nuw nsw i64 %71, 2
  %88 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %87
  %89 = bitcast <2 x i64>* %88 to <4 x i32>*
  %90 = load <4 x i32>, <4 x i32>* %89, align 16
  %91 = mul <4 x i32> %90, %12
  %92 = add nuw nsw i64 %71, 14
  %93 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %92
  %94 = bitcast <2 x i64>* %93 to <4 x i32>*
  %95 = load <4 x i32>, <4 x i32>* %94, align 16
  %96 = mul <4 x i32> %95, %17
  %97 = add <4 x i32> %91, %49
  %98 = add <4 x i32> %97, %96
  %99 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %98, i32 %2) #8
  %100 = mul <4 x i32> %90, %30
  %101 = mul <4 x i32> %95, %12
  %102 = add <4 x i32> %100, %49
  %103 = add <4 x i32> %102, %101
  %104 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %103, i32 %2) #8
  %105 = add nuw nsw i64 %71, 10
  %106 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %105
  %107 = bitcast <2 x i64>* %106 to <4 x i32>*
  %108 = load <4 x i32>, <4 x i32>* %107, align 16
  %109 = mul <4 x i32> %108, %21
  %110 = add nuw nsw i64 %71, 6
  %111 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %110
  %112 = bitcast <2 x i64>* %111 to <4 x i32>*
  %113 = load <4 x i32>, <4 x i32>* %112, align 16
  %114 = mul <4 x i32> %113, %26
  %115 = add <4 x i32> %109, %49
  %116 = add <4 x i32> %115, %114
  %117 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %116, i32 %2) #8
  %118 = mul <4 x i32> %108, %28
  %119 = mul <4 x i32> %113, %21
  %120 = add <4 x i32> %118, %49
  %121 = add <4 x i32> %120, %119
  %122 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %121, i32 %2) #8
  %123 = mul <4 x i32> %74, %34
  %124 = mul <4 x i32> %78, %34
  %125 = add <4 x i32> %123, %49
  %126 = add <4 x i32> %125, %124
  %127 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %126, i32 %2) #8
  %128 = sub <4 x i32> %125, %124
  %129 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %128, i32 %2) #8
  %130 = mul <4 x i32> %82, %38
  %131 = mul <4 x i32> %86, %43
  %132 = add <4 x i32> %130, %49
  %133 = add <4 x i32> %132, %131
  %134 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %133, i32 %2) #8
  %135 = mul <4 x i32> %82, %45
  %136 = mul <4 x i32> %86, %38
  %137 = add <4 x i32> %135, %49
  %138 = add <4 x i32> %137, %136
  %139 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %138, i32 %2) #8
  %140 = add <4 x i32> %117, %99
  %141 = sub <4 x i32> %99, %117
  %142 = icmp sgt <4 x i32> %140, %59
  %143 = select <4 x i1> %142, <4 x i32> %140, <4 x i32> %59
  %144 = icmp slt <4 x i32> %143, %62
  %145 = select <4 x i1> %144, <4 x i32> %143, <4 x i32> %62
  %146 = icmp sgt <4 x i32> %141, %59
  %147 = select <4 x i1> %146, <4 x i32> %141, <4 x i32> %59
  %148 = icmp slt <4 x i32> %147, %62
  %149 = select <4 x i1> %148, <4 x i32> %147, <4 x i32> %62
  %150 = add <4 x i32> %122, %104
  %151 = sub <4 x i32> %104, %122
  %152 = icmp sgt <4 x i32> %150, %59
  %153 = select <4 x i1> %152, <4 x i32> %150, <4 x i32> %59
  %154 = icmp slt <4 x i32> %153, %62
  %155 = select <4 x i1> %154, <4 x i32> %153, <4 x i32> %62
  %156 = icmp sgt <4 x i32> %151, %59
  %157 = select <4 x i1> %156, <4 x i32> %151, <4 x i32> %59
  %158 = icmp slt <4 x i32> %157, %62
  %159 = select <4 x i1> %158, <4 x i32> %157, <4 x i32> %62
  %160 = add <4 x i32> %139, %127
  %161 = sub <4 x i32> %127, %139
  %162 = icmp sgt <4 x i32> %160, %59
  %163 = select <4 x i1> %162, <4 x i32> %160, <4 x i32> %59
  %164 = icmp slt <4 x i32> %163, %62
  %165 = select <4 x i1> %164, <4 x i32> %163, <4 x i32> %62
  %166 = icmp sgt <4 x i32> %161, %59
  %167 = select <4 x i1> %166, <4 x i32> %161, <4 x i32> %59
  %168 = icmp slt <4 x i32> %167, %62
  %169 = select <4 x i1> %168, <4 x i32> %167, <4 x i32> %62
  %170 = add <4 x i32> %134, %129
  %171 = sub <4 x i32> %129, %134
  %172 = icmp sgt <4 x i32> %170, %59
  %173 = select <4 x i1> %172, <4 x i32> %170, <4 x i32> %59
  %174 = icmp slt <4 x i32> %173, %62
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %62
  %176 = icmp sgt <4 x i32> %171, %59
  %177 = select <4 x i1> %176, <4 x i32> %171, <4 x i32> %59
  %178 = icmp slt <4 x i32> %177, %62
  %179 = select <4 x i1> %178, <4 x i32> %177, <4 x i32> %62
  %180 = mul <4 x i32> %149, %34
  %181 = mul <4 x i32> %159, %34
  %182 = add <4 x i32> %180, %49
  %183 = add <4 x i32> %182, %181
  %184 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %183, i32 %2) #8
  %185 = sub <4 x i32> %49, %180
  %186 = add <4 x i32> %185, %181
  %187 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %186, i32 %2) #8
  %188 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %71
  %189 = getelementptr inbounds <2 x i64>, <2 x i64>* %63, i64 %71
  %190 = add <4 x i32> %165, %155
  %191 = sub <4 x i32> %165, %155
  %192 = icmp sgt <4 x i32> %190, %59
  %193 = select <4 x i1> %192, <4 x i32> %190, <4 x i32> %59
  %194 = icmp slt <4 x i32> %193, %62
  %195 = select <4 x i1> %194, <4 x i32> %193, <4 x i32> %62
  %196 = icmp sgt <4 x i32> %191, %59
  %197 = select <4 x i1> %196, <4 x i32> %191, <4 x i32> %59
  %198 = icmp slt <4 x i32> %197, %62
  %199 = select <4 x i1> %198, <4 x i32> %197, <4 x i32> %62
  %200 = bitcast <2 x i64>* %188 to <4 x i32>*
  store <4 x i32> %195, <4 x i32>* %200, align 16
  %201 = bitcast <2 x i64>* %189 to <4 x i32>*
  store <4 x i32> %199, <4 x i32>* %201, align 16
  %202 = getelementptr inbounds <2 x i64>, <2 x i64>* %64, i64 %71
  %203 = getelementptr inbounds <2 x i64>, <2 x i64>* %65, i64 %71
  %204 = add <4 x i32> %175, %184
  %205 = sub <4 x i32> %175, %184
  %206 = icmp sgt <4 x i32> %204, %59
  %207 = select <4 x i1> %206, <4 x i32> %204, <4 x i32> %59
  %208 = icmp slt <4 x i32> %207, %62
  %209 = select <4 x i1> %208, <4 x i32> %207, <4 x i32> %62
  %210 = icmp sgt <4 x i32> %205, %59
  %211 = select <4 x i1> %210, <4 x i32> %205, <4 x i32> %59
  %212 = icmp slt <4 x i32> %211, %62
  %213 = select <4 x i1> %212, <4 x i32> %211, <4 x i32> %62
  %214 = bitcast <2 x i64>* %202 to <4 x i32>*
  store <4 x i32> %209, <4 x i32>* %214, align 16
  %215 = bitcast <2 x i64>* %203 to <4 x i32>*
  store <4 x i32> %213, <4 x i32>* %215, align 16
  %216 = getelementptr inbounds <2 x i64>, <2 x i64>* %66, i64 %71
  %217 = getelementptr inbounds <2 x i64>, <2 x i64>* %67, i64 %71
  %218 = add <4 x i32> %179, %187
  %219 = sub <4 x i32> %179, %187
  %220 = icmp sgt <4 x i32> %218, %59
  %221 = select <4 x i1> %220, <4 x i32> %218, <4 x i32> %59
  %222 = icmp slt <4 x i32> %221, %62
  %223 = select <4 x i1> %222, <4 x i32> %221, <4 x i32> %62
  %224 = icmp sgt <4 x i32> %219, %59
  %225 = select <4 x i1> %224, <4 x i32> %219, <4 x i32> %59
  %226 = icmp slt <4 x i32> %225, %62
  %227 = select <4 x i1> %226, <4 x i32> %225, <4 x i32> %62
  %228 = bitcast <2 x i64>* %216 to <4 x i32>*
  store <4 x i32> %223, <4 x i32>* %228, align 16
  %229 = bitcast <2 x i64>* %217 to <4 x i32>*
  store <4 x i32> %227, <4 x i32>* %229, align 16
  %230 = getelementptr inbounds <2 x i64>, <2 x i64>* %68, i64 %71
  %231 = getelementptr inbounds <2 x i64>, <2 x i64>* %69, i64 %71
  %232 = add <4 x i32> %169, %145
  %233 = sub <4 x i32> %169, %145
  %234 = icmp sgt <4 x i32> %232, %59
  %235 = select <4 x i1> %234, <4 x i32> %232, <4 x i32> %59
  %236 = icmp slt <4 x i32> %235, %62
  %237 = select <4 x i1> %236, <4 x i32> %235, <4 x i32> %62
  %238 = icmp sgt <4 x i32> %233, %59
  %239 = select <4 x i1> %238, <4 x i32> %233, <4 x i32> %59
  %240 = icmp slt <4 x i32> %239, %62
  %241 = select <4 x i1> %240, <4 x i32> %239, <4 x i32> %62
  %242 = bitcast <2 x i64>* %230 to <4 x i32>*
  store <4 x i32> %237, <4 x i32>* %242, align 16
  %243 = bitcast <2 x i64>* %231 to <4 x i32>*
  store <4 x i32> %241, <4 x i32>* %243, align 16
  %244 = add nuw nsw i64 %71, 1
  %245 = icmp eq i64 %244, 2
  br i1 %245, label %246, label %70

246:                                              ; preds = %70
  br i1 %50, label %470, label %247

247:                                              ; preds = %246
  %248 = icmp sgt i32 %4, 10
  %249 = select i1 %248, i32 %4, i32 10
  %250 = shl i32 32, %249
  %251 = sub nsw i32 0, %250
  %252 = insertelement <4 x i32> undef, i32 %251, i32 0
  %253 = shufflevector <4 x i32> %252, <4 x i32> undef, <4 x i32> zeroinitializer
  %254 = add nsw i32 %250, -1
  %255 = insertelement <4 x i32> undef, i32 %254, i32 0
  %256 = shufflevector <4 x i32> %255, <4 x i32> undef, <4 x i32> zeroinitializer
  %257 = icmp eq i32 %5, 0
  br i1 %257, label %258, label %295

258:                                              ; preds = %247
  %259 = bitcast <2 x i64>* %1 to <4 x i32>*
  %260 = load <4 x i32>, <4 x i32>* %259, align 16
  %261 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %262 = bitcast <2 x i64>* %261 to <4 x i32>*
  %263 = load <4 x i32>, <4 x i32>* %262, align 16
  %264 = bitcast <2 x i64>* %64 to <4 x i32>*
  %265 = load <4 x i32>, <4 x i32>* %264, align 16
  %266 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %267 = bitcast <2 x i64>* %266 to <4 x i32>*
  %268 = load <4 x i32>, <4 x i32>* %267, align 16
  %269 = bitcast <2 x i64>* %66 to <4 x i32>*
  %270 = load <4 x i32>, <4 x i32>* %269, align 16
  %271 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %272 = bitcast <2 x i64>* %271 to <4 x i32>*
  %273 = load <4 x i32>, <4 x i32>* %272, align 16
  %274 = bitcast <2 x i64>* %68 to <4 x i32>*
  %275 = load <4 x i32>, <4 x i32>* %274, align 16
  %276 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %277 = bitcast <2 x i64>* %276 to <4 x i32>*
  %278 = load <4 x i32>, <4 x i32>* %277, align 16
  %279 = bitcast <2 x i64>* %69 to <4 x i32>*
  %280 = load <4 x i32>, <4 x i32>* %279, align 16
  %281 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %282 = bitcast <2 x i64>* %281 to <4 x i32>*
  %283 = load <4 x i32>, <4 x i32>* %282, align 16
  %284 = bitcast <2 x i64>* %67 to <4 x i32>*
  %285 = load <4 x i32>, <4 x i32>* %284, align 16
  %286 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %287 = bitcast <2 x i64>* %286 to <4 x i32>*
  %288 = load <4 x i32>, <4 x i32>* %287, align 16
  %289 = bitcast <2 x i64>* %65 to <4 x i32>*
  %290 = load <4 x i32>, <4 x i32>* %289, align 16
  %291 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %292 = bitcast <2 x i64>* %291 to <4 x i32>*
  %293 = load <4 x i32>, <4 x i32>* %292, align 16
  %294 = bitcast <2 x i64>* %63 to <4 x i32>*
  br label %372

295:                                              ; preds = %247
  %296 = add nsw i32 %5, -1
  %297 = shl i32 1, %296
  %298 = insertelement <4 x i32> undef, i32 %297, i32 0
  %299 = shufflevector <4 x i32> %298, <4 x i32> undef, <4 x i32> zeroinitializer
  %300 = bitcast <2 x i64>* %1 to <4 x i32>*
  %301 = load <4 x i32>, <4 x i32>* %300, align 16
  %302 = add <4 x i32> %301, %299
  %303 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %304 = bitcast <2 x i64>* %303 to <4 x i32>*
  %305 = load <4 x i32>, <4 x i32>* %304, align 16
  %306 = add <4 x i32> %305, %299
  %307 = bitcast <2 x i64>* %64 to <4 x i32>*
  %308 = load <4 x i32>, <4 x i32>* %307, align 16
  %309 = add <4 x i32> %308, %299
  %310 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %311 = bitcast <2 x i64>* %310 to <4 x i32>*
  %312 = load <4 x i32>, <4 x i32>* %311, align 16
  %313 = add <4 x i32> %312, %299
  %314 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %302, i32 %5) #8
  store <4 x i32> %314, <4 x i32>* %300, align 16
  %315 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %306, i32 %5) #8
  store <4 x i32> %315, <4 x i32>* %304, align 16
  %316 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %309, i32 %5) #8
  store <4 x i32> %316, <4 x i32>* %307, align 16
  %317 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %313, i32 %5) #8
  store <4 x i32> %317, <4 x i32>* %311, align 16
  %318 = bitcast <2 x i64>* %66 to <4 x i32>*
  %319 = load <4 x i32>, <4 x i32>* %318, align 16
  %320 = add <4 x i32> %319, %299
  %321 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %322 = bitcast <2 x i64>* %321 to <4 x i32>*
  %323 = load <4 x i32>, <4 x i32>* %322, align 16
  %324 = add <4 x i32> %323, %299
  %325 = bitcast <2 x i64>* %68 to <4 x i32>*
  %326 = load <4 x i32>, <4 x i32>* %325, align 16
  %327 = add <4 x i32> %326, %299
  %328 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %329 = bitcast <2 x i64>* %328 to <4 x i32>*
  %330 = load <4 x i32>, <4 x i32>* %329, align 16
  %331 = add <4 x i32> %330, %299
  %332 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %320, i32 %5) #8
  store <4 x i32> %332, <4 x i32>* %318, align 16
  %333 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %324, i32 %5) #8
  store <4 x i32> %333, <4 x i32>* %322, align 16
  %334 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %327, i32 %5) #8
  store <4 x i32> %334, <4 x i32>* %325, align 16
  %335 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %331, i32 %5) #8
  store <4 x i32> %335, <4 x i32>* %329, align 16
  %336 = bitcast <2 x i64>* %69 to <4 x i32>*
  %337 = load <4 x i32>, <4 x i32>* %336, align 16
  %338 = add <4 x i32> %337, %299
  %339 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %340 = bitcast <2 x i64>* %339 to <4 x i32>*
  %341 = load <4 x i32>, <4 x i32>* %340, align 16
  %342 = add <4 x i32> %341, %299
  %343 = bitcast <2 x i64>* %67 to <4 x i32>*
  %344 = load <4 x i32>, <4 x i32>* %343, align 16
  %345 = add <4 x i32> %344, %299
  %346 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %347 = bitcast <2 x i64>* %346 to <4 x i32>*
  %348 = load <4 x i32>, <4 x i32>* %347, align 16
  %349 = add <4 x i32> %348, %299
  %350 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %338, i32 %5) #8
  store <4 x i32> %350, <4 x i32>* %336, align 16
  %351 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %342, i32 %5) #8
  store <4 x i32> %351, <4 x i32>* %340, align 16
  %352 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %345, i32 %5) #8
  store <4 x i32> %352, <4 x i32>* %343, align 16
  %353 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %349, i32 %5) #8
  store <4 x i32> %353, <4 x i32>* %347, align 16
  %354 = bitcast <2 x i64>* %65 to <4 x i32>*
  %355 = load <4 x i32>, <4 x i32>* %354, align 16
  %356 = add <4 x i32> %355, %299
  %357 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %358 = bitcast <2 x i64>* %357 to <4 x i32>*
  %359 = load <4 x i32>, <4 x i32>* %358, align 16
  %360 = add <4 x i32> %359, %299
  %361 = bitcast <2 x i64>* %63 to <4 x i32>*
  %362 = load <4 x i32>, <4 x i32>* %361, align 16
  %363 = add <4 x i32> %362, %299
  %364 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %365 = bitcast <2 x i64>* %364 to <4 x i32>*
  %366 = load <4 x i32>, <4 x i32>* %365, align 16
  %367 = add <4 x i32> %366, %299
  %368 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %356, i32 %5) #8
  store <4 x i32> %368, <4 x i32>* %354, align 16
  %369 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %360, i32 %5) #8
  store <4 x i32> %369, <4 x i32>* %358, align 16
  %370 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %363, i32 %5) #8
  store <4 x i32> %370, <4 x i32>* %361, align 16
  %371 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %367, i32 %5) #8
  store <4 x i32> %371, <4 x i32>* %365, align 16
  br label %372

372:                                              ; preds = %258, %295
  %373 = phi <4 x i32>* [ %294, %258 ], [ %361, %295 ]
  %374 = phi <4 x i32>* [ %292, %258 ], [ %358, %295 ]
  %375 = phi <4 x i32>* [ %289, %258 ], [ %354, %295 ]
  %376 = phi <4 x i32>* [ %287, %258 ], [ %347, %295 ]
  %377 = phi <4 x i32>* [ %284, %258 ], [ %343, %295 ]
  %378 = phi <4 x i32>* [ %282, %258 ], [ %340, %295 ]
  %379 = phi <4 x i32>* [ %279, %258 ], [ %336, %295 ]
  %380 = phi <4 x i32>* [ %277, %258 ], [ %329, %295 ]
  %381 = phi <4 x i32>* [ %274, %258 ], [ %325, %295 ]
  %382 = phi <4 x i32>* [ %272, %258 ], [ %322, %295 ]
  %383 = phi <4 x i32>* [ %269, %258 ], [ %318, %295 ]
  %384 = phi <4 x i32>* [ %267, %258 ], [ %311, %295 ]
  %385 = phi <4 x i32>* [ %264, %258 ], [ %307, %295 ]
  %386 = phi <4 x i32>* [ %262, %258 ], [ %304, %295 ]
  %387 = phi <4 x i32>* [ %259, %258 ], [ %300, %295 ]
  %388 = phi <4 x i32> [ %293, %258 ], [ %369, %295 ]
  %389 = phi <4 x i32> [ %290, %258 ], [ %368, %295 ]
  %390 = phi <4 x i32> [ %288, %258 ], [ %353, %295 ]
  %391 = phi <4 x i32> [ %285, %258 ], [ %352, %295 ]
  %392 = phi <4 x i32> [ %283, %258 ], [ %351, %295 ]
  %393 = phi <4 x i32> [ %280, %258 ], [ %350, %295 ]
  %394 = phi <4 x i32> [ %278, %258 ], [ %335, %295 ]
  %395 = phi <4 x i32> [ %275, %258 ], [ %334, %295 ]
  %396 = phi <4 x i32> [ %273, %258 ], [ %333, %295 ]
  %397 = phi <4 x i32> [ %270, %258 ], [ %332, %295 ]
  %398 = phi <4 x i32> [ %268, %258 ], [ %317, %295 ]
  %399 = phi <4 x i32> [ %265, %258 ], [ %316, %295 ]
  %400 = phi <4 x i32> [ %263, %258 ], [ %315, %295 ]
  %401 = phi <4 x i32> [ %260, %258 ], [ %314, %295 ]
  %402 = icmp sgt <4 x i32> %401, %253
  %403 = select <4 x i1> %402, <4 x i32> %401, <4 x i32> %253
  %404 = icmp slt <4 x i32> %403, %256
  %405 = select <4 x i1> %404, <4 x i32> %403, <4 x i32> %256
  store <4 x i32> %405, <4 x i32>* %387, align 16
  %406 = icmp sgt <4 x i32> %400, %253
  %407 = select <4 x i1> %406, <4 x i32> %400, <4 x i32> %253
  %408 = icmp slt <4 x i32> %407, %256
  %409 = select <4 x i1> %408, <4 x i32> %407, <4 x i32> %256
  store <4 x i32> %409, <4 x i32>* %386, align 16
  %410 = icmp sgt <4 x i32> %399, %253
  %411 = select <4 x i1> %410, <4 x i32> %399, <4 x i32> %253
  %412 = icmp slt <4 x i32> %411, %256
  %413 = select <4 x i1> %412, <4 x i32> %411, <4 x i32> %256
  store <4 x i32> %413, <4 x i32>* %385, align 16
  %414 = icmp sgt <4 x i32> %398, %253
  %415 = select <4 x i1> %414, <4 x i32> %398, <4 x i32> %253
  %416 = icmp slt <4 x i32> %415, %256
  %417 = select <4 x i1> %416, <4 x i32> %415, <4 x i32> %256
  store <4 x i32> %417, <4 x i32>* %384, align 16
  %418 = icmp sgt <4 x i32> %397, %253
  %419 = select <4 x i1> %418, <4 x i32> %397, <4 x i32> %253
  %420 = icmp slt <4 x i32> %419, %256
  %421 = select <4 x i1> %420, <4 x i32> %419, <4 x i32> %256
  store <4 x i32> %421, <4 x i32>* %383, align 16
  %422 = icmp sgt <4 x i32> %396, %253
  %423 = select <4 x i1> %422, <4 x i32> %396, <4 x i32> %253
  %424 = icmp slt <4 x i32> %423, %256
  %425 = select <4 x i1> %424, <4 x i32> %423, <4 x i32> %256
  store <4 x i32> %425, <4 x i32>* %382, align 16
  %426 = icmp sgt <4 x i32> %395, %253
  %427 = select <4 x i1> %426, <4 x i32> %395, <4 x i32> %253
  %428 = icmp slt <4 x i32> %427, %256
  %429 = select <4 x i1> %428, <4 x i32> %427, <4 x i32> %256
  store <4 x i32> %429, <4 x i32>* %381, align 16
  %430 = icmp sgt <4 x i32> %394, %253
  %431 = select <4 x i1> %430, <4 x i32> %394, <4 x i32> %253
  %432 = icmp slt <4 x i32> %431, %256
  %433 = select <4 x i1> %432, <4 x i32> %431, <4 x i32> %256
  store <4 x i32> %433, <4 x i32>* %380, align 16
  %434 = icmp sgt <4 x i32> %393, %253
  %435 = select <4 x i1> %434, <4 x i32> %393, <4 x i32> %253
  %436 = icmp slt <4 x i32> %435, %256
  %437 = select <4 x i1> %436, <4 x i32> %435, <4 x i32> %256
  store <4 x i32> %437, <4 x i32>* %379, align 16
  %438 = icmp sgt <4 x i32> %392, %253
  %439 = select <4 x i1> %438, <4 x i32> %392, <4 x i32> %253
  %440 = icmp slt <4 x i32> %439, %256
  %441 = select <4 x i1> %440, <4 x i32> %439, <4 x i32> %256
  store <4 x i32> %441, <4 x i32>* %378, align 16
  %442 = icmp sgt <4 x i32> %391, %253
  %443 = select <4 x i1> %442, <4 x i32> %391, <4 x i32> %253
  %444 = icmp slt <4 x i32> %443, %256
  %445 = select <4 x i1> %444, <4 x i32> %443, <4 x i32> %256
  store <4 x i32> %445, <4 x i32>* %377, align 16
  %446 = icmp sgt <4 x i32> %390, %253
  %447 = select <4 x i1> %446, <4 x i32> %390, <4 x i32> %253
  %448 = icmp slt <4 x i32> %447, %256
  %449 = select <4 x i1> %448, <4 x i32> %447, <4 x i32> %256
  store <4 x i32> %449, <4 x i32>* %376, align 16
  %450 = icmp sgt <4 x i32> %389, %253
  %451 = select <4 x i1> %450, <4 x i32> %389, <4 x i32> %253
  %452 = icmp slt <4 x i32> %451, %256
  %453 = select <4 x i1> %452, <4 x i32> %451, <4 x i32> %256
  store <4 x i32> %453, <4 x i32>* %375, align 16
  %454 = icmp sgt <4 x i32> %388, %253
  %455 = select <4 x i1> %454, <4 x i32> %388, <4 x i32> %253
  %456 = icmp slt <4 x i32> %455, %256
  %457 = select <4 x i1> %456, <4 x i32> %455, <4 x i32> %256
  store <4 x i32> %457, <4 x i32>* %374, align 16
  %458 = load <4 x i32>, <4 x i32>* %373, align 16
  %459 = icmp sgt <4 x i32> %458, %253
  %460 = select <4 x i1> %459, <4 x i32> %458, <4 x i32> %253
  %461 = icmp slt <4 x i32> %460, %256
  %462 = select <4 x i1> %461, <4 x i32> %460, <4 x i32> %256
  store <4 x i32> %462, <4 x i32>* %373, align 16
  %463 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %464 = bitcast <2 x i64>* %463 to <4 x i32>*
  %465 = load <4 x i32>, <4 x i32>* %464, align 16
  %466 = icmp sgt <4 x i32> %465, %253
  %467 = select <4 x i1> %466, <4 x i32> %465, <4 x i32> %253
  %468 = icmp slt <4 x i32> %467, %256
  %469 = select <4 x i1> %468, <4 x i32> %467, <4 x i32> %256
  store <4 x i32> %469, <4 x i32>* %464, align 16
  br label %470

470:                                              ; preds = %372, %246
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal fastcc void @write_buffer_8x8(<2 x i64>*, i16* nocapture, i32, i32, i32, i32, i32) unnamed_addr #2 {
  %8 = icmp eq i32 %5, 0
  br i1 %8, label %93, label %9

9:                                                ; preds = %7
  %10 = add nsw i32 %5, -1
  %11 = shl i32 1, %10
  %12 = insertelement <4 x i32> undef, i32 %11, i32 0
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> zeroinitializer
  %14 = bitcast <2 x i64>* %0 to <4 x i32>*
  %15 = load <4 x i32>, <4 x i32>* %14, align 16
  %16 = add <4 x i32> %15, %13
  %17 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %18 = bitcast <2 x i64>* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 16
  %20 = add <4 x i32> %19, %13
  %21 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %22 = bitcast <2 x i64>* %21 to <4 x i32>*
  %23 = load <4 x i32>, <4 x i32>* %22, align 16
  %24 = add <4 x i32> %23, %13
  %25 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %26 = bitcast <2 x i64>* %25 to <4 x i32>*
  %27 = load <4 x i32>, <4 x i32>* %26, align 16
  %28 = add <4 x i32> %27, %13
  %29 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %16, i32 %5) #8
  store <4 x i32> %29, <4 x i32>* %14, align 16
  %30 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %20, i32 %5) #8
  store <4 x i32> %30, <4 x i32>* %18, align 16
  %31 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %24, i32 %5) #8
  store <4 x i32> %31, <4 x i32>* %22, align 16
  %32 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %28, i32 %5) #8
  store <4 x i32> %32, <4 x i32>* %26, align 16
  %33 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %34 = bitcast <2 x i64>* %33 to <4 x i32>*
  %35 = load <4 x i32>, <4 x i32>* %34, align 16
  %36 = add <4 x i32> %35, %13
  %37 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %38 = bitcast <2 x i64>* %37 to <4 x i32>*
  %39 = load <4 x i32>, <4 x i32>* %38, align 16
  %40 = add <4 x i32> %39, %13
  %41 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %42 = bitcast <2 x i64>* %41 to <4 x i32>*
  %43 = load <4 x i32>, <4 x i32>* %42, align 16
  %44 = add <4 x i32> %43, %13
  %45 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %46 = bitcast <2 x i64>* %45 to <4 x i32>*
  %47 = load <4 x i32>, <4 x i32>* %46, align 16
  %48 = add <4 x i32> %47, %13
  %49 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %36, i32 %5) #8
  store <4 x i32> %49, <4 x i32>* %34, align 16
  %50 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %40, i32 %5) #8
  store <4 x i32> %50, <4 x i32>* %38, align 16
  %51 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %44, i32 %5) #8
  store <4 x i32> %51, <4 x i32>* %42, align 16
  %52 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %48, i32 %5) #8
  store <4 x i32> %52, <4 x i32>* %46, align 16
  %53 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %54 = bitcast <2 x i64>* %53 to <4 x i32>*
  %55 = load <4 x i32>, <4 x i32>* %54, align 16
  %56 = add <4 x i32> %55, %13
  %57 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %58 = bitcast <2 x i64>* %57 to <4 x i32>*
  %59 = load <4 x i32>, <4 x i32>* %58, align 16
  %60 = add <4 x i32> %59, %13
  %61 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %62 = bitcast <2 x i64>* %61 to <4 x i32>*
  %63 = load <4 x i32>, <4 x i32>* %62, align 16
  %64 = add <4 x i32> %63, %13
  %65 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %66 = bitcast <2 x i64>* %65 to <4 x i32>*
  %67 = load <4 x i32>, <4 x i32>* %66, align 16
  %68 = add <4 x i32> %67, %13
  %69 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %56, i32 %5) #8
  store <4 x i32> %69, <4 x i32>* %54, align 16
  %70 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %60, i32 %5) #8
  store <4 x i32> %70, <4 x i32>* %58, align 16
  %71 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %64, i32 %5) #8
  store <4 x i32> %71, <4 x i32>* %62, align 16
  %72 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %68, i32 %5) #8
  store <4 x i32> %72, <4 x i32>* %66, align 16
  %73 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %74 = bitcast <2 x i64>* %73 to <4 x i32>*
  %75 = load <4 x i32>, <4 x i32>* %74, align 16
  %76 = add <4 x i32> %75, %13
  %77 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %78 = bitcast <2 x i64>* %77 to <4 x i32>*
  %79 = load <4 x i32>, <4 x i32>* %78, align 16
  %80 = add <4 x i32> %79, %13
  %81 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %82 = bitcast <2 x i64>* %81 to <4 x i32>*
  %83 = load <4 x i32>, <4 x i32>* %82, align 16
  %84 = add <4 x i32> %83, %13
  %85 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %86 = bitcast <2 x i64>* %85 to <4 x i32>*
  %87 = load <4 x i32>, <4 x i32>* %86, align 16
  %88 = add <4 x i32> %87, %13
  %89 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %76, i32 %5) #8
  store <4 x i32> %89, <4 x i32>* %74, align 16
  %90 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %80, i32 %5) #8
  store <4 x i32> %90, <4 x i32>* %78, align 16
  %91 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %84, i32 %5) #8
  store <4 x i32> %91, <4 x i32>* %82, align 16
  %92 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %88, i32 %5) #8
  store <4 x i32> %92, <4 x i32>* %86, align 16
  br label %93

93:                                               ; preds = %7, %9
  %94 = bitcast i16* %1 to <2 x i64>*
  %95 = load <2 x i64>, <2 x i64>* %94, align 16
  %96 = sext i32 %2 to i64
  %97 = getelementptr inbounds i16, i16* %1, i64 %96
  %98 = bitcast i16* %97 to <2 x i64>*
  %99 = load <2 x i64>, <2 x i64>* %98, align 16
  %100 = shl nsw i32 %2, 1
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds i16, i16* %1, i64 %101
  %103 = bitcast i16* %102 to <2 x i64>*
  %104 = load <2 x i64>, <2 x i64>* %103, align 16
  %105 = mul nsw i32 %2, 3
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i16, i16* %1, i64 %106
  %108 = bitcast i16* %107 to <2 x i64>*
  %109 = load <2 x i64>, <2 x i64>* %108, align 16
  %110 = shl nsw i32 %2, 2
  %111 = sext i32 %110 to i64
  %112 = getelementptr inbounds i16, i16* %1, i64 %111
  %113 = bitcast i16* %112 to <2 x i64>*
  %114 = load <2 x i64>, <2 x i64>* %113, align 16
  %115 = mul nsw i32 %2, 5
  %116 = sext i32 %115 to i64
  %117 = getelementptr inbounds i16, i16* %1, i64 %116
  %118 = bitcast i16* %117 to <2 x i64>*
  %119 = load <2 x i64>, <2 x i64>* %118, align 16
  %120 = mul nsw i32 %2, 6
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds i16, i16* %1, i64 %121
  %123 = bitcast i16* %122 to <2 x i64>*
  %124 = load <2 x i64>, <2 x i64>* %123, align 16
  %125 = mul nsw i32 %2, 7
  %126 = sext i32 %125 to i64
  %127 = getelementptr inbounds i16, i16* %1, i64 %126
  %128 = bitcast i16* %127 to <2 x i64>*
  %129 = load <2 x i64>, <2 x i64>* %128, align 16
  %130 = icmp eq i32 %4, 0
  br i1 %130, label %431, label %131

131:                                              ; preds = %93
  %132 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %133 = bitcast <2 x i64>* %132 to <4 x i32>*
  %134 = load <4 x i32>, <4 x i32>* %133, align 16
  %135 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %136 = load <2 x i64>, <2 x i64>* %135, align 16
  %137 = bitcast <2 x i64> %95 to <8 x i16>
  %138 = shufflevector <8 x i16> %137, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %139 = shufflevector <8 x i16> %137, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %140 = icmp eq i32 %3, 0
  br i1 %140, label %147, label %141

141:                                              ; preds = %131
  %142 = shufflevector <4 x i32> %134, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %143 = bitcast <2 x i64> %136 to <4 x i32>
  %144 = shufflevector <4 x i32> %143, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %145 = bitcast <8 x i16> %138 to <4 x i32>
  %146 = add <4 x i32> %144, %145
  br label %151

147:                                              ; preds = %131
  %148 = bitcast <8 x i16> %138 to <4 x i32>
  %149 = add <4 x i32> %134, %148
  %150 = bitcast <2 x i64> %136 to <4 x i32>
  br label %151

151:                                              ; preds = %141, %147
  %152 = phi <4 x i32> [ %142, %141 ], [ %150, %147 ]
  %153 = phi <4 x i32> [ %146, %141 ], [ %149, %147 ]
  %154 = bitcast <8 x i16> %139 to <4 x i32>
  %155 = add <4 x i32> %152, %154
  %156 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %153, <4 x i32> %155) #8
  %157 = bitcast <8 x i16> %156 to <2 x i64>
  %158 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %6) #8
  %159 = add <8 x i16> %158, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %160 = icmp slt <8 x i16> %159, %156
  %161 = sext <8 x i1> %160 to <8 x i16>
  %162 = bitcast <8 x i16> %161 to <2 x i64>
  %163 = xor <2 x i64> %162, <i64 -1, i64 -1>
  %164 = and <2 x i64> %163, %157
  %165 = and <8 x i16> %159, %161
  %166 = bitcast <8 x i16> %165 to <2 x i64>
  %167 = or <2 x i64> %164, %166
  %168 = bitcast <2 x i64> %167 to <8 x i16>
  %169 = icmp sgt <8 x i16> %168, zeroinitializer
  %170 = sext <8 x i1> %169 to <8 x i16>
  %171 = bitcast <8 x i16> %170 to <2 x i64>
  %172 = and <2 x i64> %167, %171
  %173 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %174 = bitcast <2 x i64>* %173 to <4 x i32>*
  %175 = load <4 x i32>, <4 x i32>* %174, align 16
  %176 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %177 = load <2 x i64>, <2 x i64>* %176, align 16
  %178 = bitcast <2 x i64> %99 to <8 x i16>
  %179 = shufflevector <8 x i16> %178, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %180 = shufflevector <8 x i16> %178, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %140, label %187, label %181

181:                                              ; preds = %151
  %182 = shufflevector <4 x i32> %175, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %183 = bitcast <2 x i64> %177 to <4 x i32>
  %184 = shufflevector <4 x i32> %183, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %185 = bitcast <8 x i16> %179 to <4 x i32>
  %186 = add <4 x i32> %184, %185
  br label %191

187:                                              ; preds = %151
  %188 = bitcast <8 x i16> %179 to <4 x i32>
  %189 = add <4 x i32> %175, %188
  %190 = bitcast <2 x i64> %177 to <4 x i32>
  br label %191

191:                                              ; preds = %181, %187
  %192 = phi <4 x i32> [ %182, %181 ], [ %190, %187 ]
  %193 = phi <4 x i32> [ %186, %181 ], [ %189, %187 ]
  %194 = bitcast <8 x i16> %180 to <4 x i32>
  %195 = add <4 x i32> %192, %194
  %196 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %193, <4 x i32> %195) #8
  %197 = bitcast <8 x i16> %196 to <2 x i64>
  %198 = icmp slt <8 x i16> %159, %196
  %199 = sext <8 x i1> %198 to <8 x i16>
  %200 = bitcast <8 x i16> %199 to <2 x i64>
  %201 = xor <2 x i64> %200, <i64 -1, i64 -1>
  %202 = and <2 x i64> %201, %197
  %203 = and <8 x i16> %159, %199
  %204 = bitcast <8 x i16> %203 to <2 x i64>
  %205 = or <2 x i64> %202, %204
  %206 = bitcast <2 x i64> %205 to <8 x i16>
  %207 = icmp sgt <8 x i16> %206, zeroinitializer
  %208 = sext <8 x i1> %207 to <8 x i16>
  %209 = bitcast <8 x i16> %208 to <2 x i64>
  %210 = and <2 x i64> %205, %209
  %211 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %212 = bitcast <2 x i64>* %211 to <4 x i32>*
  %213 = load <4 x i32>, <4 x i32>* %212, align 16
  %214 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %215 = load <2 x i64>, <2 x i64>* %214, align 16
  %216 = bitcast <2 x i64> %104 to <8 x i16>
  %217 = shufflevector <8 x i16> %216, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %218 = shufflevector <8 x i16> %216, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %140, label %225, label %219

219:                                              ; preds = %191
  %220 = shufflevector <4 x i32> %213, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %221 = bitcast <2 x i64> %215 to <4 x i32>
  %222 = shufflevector <4 x i32> %221, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %223 = bitcast <8 x i16> %217 to <4 x i32>
  %224 = add <4 x i32> %222, %223
  br label %229

225:                                              ; preds = %191
  %226 = bitcast <8 x i16> %217 to <4 x i32>
  %227 = add <4 x i32> %213, %226
  %228 = bitcast <2 x i64> %215 to <4 x i32>
  br label %229

229:                                              ; preds = %219, %225
  %230 = phi <4 x i32> [ %220, %219 ], [ %228, %225 ]
  %231 = phi <4 x i32> [ %224, %219 ], [ %227, %225 ]
  %232 = bitcast <8 x i16> %218 to <4 x i32>
  %233 = add <4 x i32> %230, %232
  %234 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %231, <4 x i32> %233) #8
  %235 = bitcast <8 x i16> %234 to <2 x i64>
  %236 = icmp slt <8 x i16> %159, %234
  %237 = sext <8 x i1> %236 to <8 x i16>
  %238 = bitcast <8 x i16> %237 to <2 x i64>
  %239 = xor <2 x i64> %238, <i64 -1, i64 -1>
  %240 = and <2 x i64> %239, %235
  %241 = and <8 x i16> %159, %237
  %242 = bitcast <8 x i16> %241 to <2 x i64>
  %243 = or <2 x i64> %240, %242
  %244 = bitcast <2 x i64> %243 to <8 x i16>
  %245 = icmp sgt <8 x i16> %244, zeroinitializer
  %246 = sext <8 x i1> %245 to <8 x i16>
  %247 = bitcast <8 x i16> %246 to <2 x i64>
  %248 = and <2 x i64> %243, %247
  %249 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %250 = bitcast <2 x i64>* %249 to <4 x i32>*
  %251 = load <4 x i32>, <4 x i32>* %250, align 16
  %252 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %253 = load <2 x i64>, <2 x i64>* %252, align 16
  %254 = bitcast <2 x i64> %109 to <8 x i16>
  %255 = shufflevector <8 x i16> %254, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %256 = shufflevector <8 x i16> %254, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %140, label %263, label %257

257:                                              ; preds = %229
  %258 = shufflevector <4 x i32> %251, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %259 = bitcast <2 x i64> %253 to <4 x i32>
  %260 = shufflevector <4 x i32> %259, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %261 = bitcast <8 x i16> %255 to <4 x i32>
  %262 = add <4 x i32> %260, %261
  br label %267

263:                                              ; preds = %229
  %264 = bitcast <8 x i16> %255 to <4 x i32>
  %265 = add <4 x i32> %251, %264
  %266 = bitcast <2 x i64> %253 to <4 x i32>
  br label %267

267:                                              ; preds = %257, %263
  %268 = phi <4 x i32> [ %258, %257 ], [ %266, %263 ]
  %269 = phi <4 x i32> [ %262, %257 ], [ %265, %263 ]
  %270 = bitcast <8 x i16> %256 to <4 x i32>
  %271 = add <4 x i32> %268, %270
  %272 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %269, <4 x i32> %271) #8
  %273 = bitcast <8 x i16> %272 to <2 x i64>
  %274 = icmp slt <8 x i16> %159, %272
  %275 = sext <8 x i1> %274 to <8 x i16>
  %276 = bitcast <8 x i16> %275 to <2 x i64>
  %277 = xor <2 x i64> %276, <i64 -1, i64 -1>
  %278 = and <2 x i64> %277, %273
  %279 = and <8 x i16> %159, %275
  %280 = bitcast <8 x i16> %279 to <2 x i64>
  %281 = or <2 x i64> %278, %280
  %282 = bitcast <2 x i64> %281 to <8 x i16>
  %283 = icmp sgt <8 x i16> %282, zeroinitializer
  %284 = sext <8 x i1> %283 to <8 x i16>
  %285 = bitcast <8 x i16> %284 to <2 x i64>
  %286 = and <2 x i64> %281, %285
  %287 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %288 = bitcast <2 x i64>* %287 to <4 x i32>*
  %289 = load <4 x i32>, <4 x i32>* %288, align 16
  %290 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %291 = load <2 x i64>, <2 x i64>* %290, align 16
  %292 = bitcast <2 x i64> %114 to <8 x i16>
  %293 = shufflevector <8 x i16> %292, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %294 = shufflevector <8 x i16> %292, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %140, label %301, label %295

295:                                              ; preds = %267
  %296 = shufflevector <4 x i32> %289, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %297 = bitcast <2 x i64> %291 to <4 x i32>
  %298 = shufflevector <4 x i32> %297, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %299 = bitcast <8 x i16> %293 to <4 x i32>
  %300 = add <4 x i32> %298, %299
  br label %305

301:                                              ; preds = %267
  %302 = bitcast <8 x i16> %293 to <4 x i32>
  %303 = add <4 x i32> %289, %302
  %304 = bitcast <2 x i64> %291 to <4 x i32>
  br label %305

305:                                              ; preds = %295, %301
  %306 = phi <4 x i32> [ %296, %295 ], [ %304, %301 ]
  %307 = phi <4 x i32> [ %300, %295 ], [ %303, %301 ]
  %308 = bitcast <8 x i16> %294 to <4 x i32>
  %309 = add <4 x i32> %306, %308
  %310 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %307, <4 x i32> %309) #8
  %311 = bitcast <8 x i16> %310 to <2 x i64>
  %312 = icmp slt <8 x i16> %159, %310
  %313 = sext <8 x i1> %312 to <8 x i16>
  %314 = bitcast <8 x i16> %313 to <2 x i64>
  %315 = xor <2 x i64> %314, <i64 -1, i64 -1>
  %316 = and <2 x i64> %315, %311
  %317 = and <8 x i16> %159, %313
  %318 = bitcast <8 x i16> %317 to <2 x i64>
  %319 = or <2 x i64> %316, %318
  %320 = bitcast <2 x i64> %319 to <8 x i16>
  %321 = icmp sgt <8 x i16> %320, zeroinitializer
  %322 = sext <8 x i1> %321 to <8 x i16>
  %323 = bitcast <8 x i16> %322 to <2 x i64>
  %324 = and <2 x i64> %319, %323
  %325 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %326 = bitcast <2 x i64>* %325 to <4 x i32>*
  %327 = load <4 x i32>, <4 x i32>* %326, align 16
  %328 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %329 = load <2 x i64>, <2 x i64>* %328, align 16
  %330 = bitcast <2 x i64> %119 to <8 x i16>
  %331 = shufflevector <8 x i16> %330, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %332 = shufflevector <8 x i16> %330, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %140, label %339, label %333

333:                                              ; preds = %305
  %334 = shufflevector <4 x i32> %327, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %335 = bitcast <2 x i64> %329 to <4 x i32>
  %336 = shufflevector <4 x i32> %335, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %337 = bitcast <8 x i16> %331 to <4 x i32>
  %338 = add <4 x i32> %336, %337
  br label %343

339:                                              ; preds = %305
  %340 = bitcast <8 x i16> %331 to <4 x i32>
  %341 = add <4 x i32> %327, %340
  %342 = bitcast <2 x i64> %329 to <4 x i32>
  br label %343

343:                                              ; preds = %333, %339
  %344 = phi <4 x i32> [ %334, %333 ], [ %342, %339 ]
  %345 = phi <4 x i32> [ %338, %333 ], [ %341, %339 ]
  %346 = bitcast <8 x i16> %332 to <4 x i32>
  %347 = add <4 x i32> %344, %346
  %348 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %345, <4 x i32> %347) #8
  %349 = bitcast <8 x i16> %348 to <2 x i64>
  %350 = icmp slt <8 x i16> %159, %348
  %351 = sext <8 x i1> %350 to <8 x i16>
  %352 = bitcast <8 x i16> %351 to <2 x i64>
  %353 = xor <2 x i64> %352, <i64 -1, i64 -1>
  %354 = and <2 x i64> %353, %349
  %355 = and <8 x i16> %159, %351
  %356 = bitcast <8 x i16> %355 to <2 x i64>
  %357 = or <2 x i64> %354, %356
  %358 = bitcast <2 x i64> %357 to <8 x i16>
  %359 = icmp sgt <8 x i16> %358, zeroinitializer
  %360 = sext <8 x i1> %359 to <8 x i16>
  %361 = bitcast <8 x i16> %360 to <2 x i64>
  %362 = and <2 x i64> %357, %361
  %363 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %364 = bitcast <2 x i64>* %363 to <4 x i32>*
  %365 = load <4 x i32>, <4 x i32>* %364, align 16
  %366 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %367 = load <2 x i64>, <2 x i64>* %366, align 16
  %368 = bitcast <2 x i64> %124 to <8 x i16>
  %369 = shufflevector <8 x i16> %368, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %370 = shufflevector <8 x i16> %368, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %140, label %377, label %371

371:                                              ; preds = %343
  %372 = shufflevector <4 x i32> %365, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %373 = bitcast <2 x i64> %367 to <4 x i32>
  %374 = shufflevector <4 x i32> %373, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %375 = bitcast <8 x i16> %369 to <4 x i32>
  %376 = add <4 x i32> %374, %375
  br label %381

377:                                              ; preds = %343
  %378 = bitcast <8 x i16> %369 to <4 x i32>
  %379 = add <4 x i32> %365, %378
  %380 = bitcast <2 x i64> %367 to <4 x i32>
  br label %381

381:                                              ; preds = %371, %377
  %382 = phi <4 x i32> [ %372, %371 ], [ %380, %377 ]
  %383 = phi <4 x i32> [ %376, %371 ], [ %379, %377 ]
  %384 = bitcast <8 x i16> %370 to <4 x i32>
  %385 = add <4 x i32> %382, %384
  %386 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %383, <4 x i32> %385) #8
  %387 = bitcast <8 x i16> %386 to <2 x i64>
  %388 = icmp slt <8 x i16> %159, %386
  %389 = sext <8 x i1> %388 to <8 x i16>
  %390 = bitcast <8 x i16> %389 to <2 x i64>
  %391 = xor <2 x i64> %390, <i64 -1, i64 -1>
  %392 = and <2 x i64> %391, %387
  %393 = and <8 x i16> %159, %389
  %394 = bitcast <8 x i16> %393 to <2 x i64>
  %395 = or <2 x i64> %392, %394
  %396 = bitcast <2 x i64> %395 to <8 x i16>
  %397 = icmp sgt <8 x i16> %396, zeroinitializer
  %398 = sext <8 x i1> %397 to <8 x i16>
  %399 = bitcast <8 x i16> %398 to <2 x i64>
  %400 = and <2 x i64> %395, %399
  %401 = bitcast <2 x i64>* %0 to <4 x i32>*
  %402 = load <4 x i32>, <4 x i32>* %401, align 16
  %403 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %404 = load <2 x i64>, <2 x i64>* %403, align 16
  %405 = bitcast <2 x i64> %129 to <8 x i16>
  %406 = shufflevector <8 x i16> %405, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %407 = shufflevector <8 x i16> %405, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %140, label %414, label %408

408:                                              ; preds = %381
  %409 = shufflevector <4 x i32> %402, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %410 = bitcast <2 x i64> %404 to <4 x i32>
  %411 = shufflevector <4 x i32> %410, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %412 = bitcast <8 x i16> %406 to <4 x i32>
  %413 = add <4 x i32> %411, %412
  br label %418

414:                                              ; preds = %381
  %415 = bitcast <8 x i16> %406 to <4 x i32>
  %416 = add <4 x i32> %402, %415
  %417 = bitcast <2 x i64> %404 to <4 x i32>
  br label %418

418:                                              ; preds = %408, %414
  %419 = phi <4 x i32> [ %409, %408 ], [ %417, %414 ]
  %420 = phi <4 x i32> [ %413, %408 ], [ %416, %414 ]
  %421 = bitcast <8 x i16> %407 to <4 x i32>
  %422 = add <4 x i32> %419, %421
  %423 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %420, <4 x i32> %422) #8
  %424 = bitcast <8 x i16> %423 to <2 x i64>
  %425 = icmp slt <8 x i16> %159, %423
  %426 = sext <8 x i1> %425 to <8 x i16>
  %427 = bitcast <8 x i16> %426 to <2 x i64>
  %428 = xor <2 x i64> %427, <i64 -1, i64 -1>
  %429 = and <2 x i64> %428, %424
  %430 = and <8 x i16> %159, %426
  br label %731

431:                                              ; preds = %93
  %432 = bitcast <2 x i64>* %0 to <4 x i32>*
  %433 = load <4 x i32>, <4 x i32>* %432, align 16
  %434 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %435 = load <2 x i64>, <2 x i64>* %434, align 16
  %436 = bitcast <2 x i64> %95 to <8 x i16>
  %437 = shufflevector <8 x i16> %436, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %438 = shufflevector <8 x i16> %436, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %439 = icmp eq i32 %3, 0
  br i1 %439, label %446, label %440

440:                                              ; preds = %431
  %441 = shufflevector <4 x i32> %433, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %442 = bitcast <2 x i64> %435 to <4 x i32>
  %443 = shufflevector <4 x i32> %442, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %444 = bitcast <8 x i16> %437 to <4 x i32>
  %445 = add <4 x i32> %443, %444
  br label %450

446:                                              ; preds = %431
  %447 = bitcast <8 x i16> %437 to <4 x i32>
  %448 = add <4 x i32> %433, %447
  %449 = bitcast <2 x i64> %435 to <4 x i32>
  br label %450

450:                                              ; preds = %440, %446
  %451 = phi <4 x i32> [ %441, %440 ], [ %449, %446 ]
  %452 = phi <4 x i32> [ %445, %440 ], [ %448, %446 ]
  %453 = bitcast <8 x i16> %438 to <4 x i32>
  %454 = add <4 x i32> %451, %453
  %455 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %452, <4 x i32> %454) #8
  %456 = bitcast <8 x i16> %455 to <2 x i64>
  %457 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %6) #8
  %458 = add <8 x i16> %457, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %459 = icmp slt <8 x i16> %458, %455
  %460 = sext <8 x i1> %459 to <8 x i16>
  %461 = bitcast <8 x i16> %460 to <2 x i64>
  %462 = xor <2 x i64> %461, <i64 -1, i64 -1>
  %463 = and <2 x i64> %462, %456
  %464 = and <8 x i16> %458, %460
  %465 = bitcast <8 x i16> %464 to <2 x i64>
  %466 = or <2 x i64> %463, %465
  %467 = bitcast <2 x i64> %466 to <8 x i16>
  %468 = icmp sgt <8 x i16> %467, zeroinitializer
  %469 = sext <8 x i1> %468 to <8 x i16>
  %470 = bitcast <8 x i16> %469 to <2 x i64>
  %471 = and <2 x i64> %466, %470
  %472 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %473 = bitcast <2 x i64>* %472 to <4 x i32>*
  %474 = load <4 x i32>, <4 x i32>* %473, align 16
  %475 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %476 = load <2 x i64>, <2 x i64>* %475, align 16
  %477 = bitcast <2 x i64> %99 to <8 x i16>
  %478 = shufflevector <8 x i16> %477, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %479 = shufflevector <8 x i16> %477, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %439, label %486, label %480

480:                                              ; preds = %450
  %481 = shufflevector <4 x i32> %474, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %482 = bitcast <2 x i64> %476 to <4 x i32>
  %483 = shufflevector <4 x i32> %482, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %484 = bitcast <8 x i16> %478 to <4 x i32>
  %485 = add <4 x i32> %483, %484
  br label %490

486:                                              ; preds = %450
  %487 = bitcast <8 x i16> %478 to <4 x i32>
  %488 = add <4 x i32> %474, %487
  %489 = bitcast <2 x i64> %476 to <4 x i32>
  br label %490

490:                                              ; preds = %480, %486
  %491 = phi <4 x i32> [ %481, %480 ], [ %489, %486 ]
  %492 = phi <4 x i32> [ %485, %480 ], [ %488, %486 ]
  %493 = bitcast <8 x i16> %479 to <4 x i32>
  %494 = add <4 x i32> %491, %493
  %495 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %492, <4 x i32> %494) #8
  %496 = bitcast <8 x i16> %495 to <2 x i64>
  %497 = icmp slt <8 x i16> %458, %495
  %498 = sext <8 x i1> %497 to <8 x i16>
  %499 = bitcast <8 x i16> %498 to <2 x i64>
  %500 = xor <2 x i64> %499, <i64 -1, i64 -1>
  %501 = and <2 x i64> %500, %496
  %502 = and <8 x i16> %458, %498
  %503 = bitcast <8 x i16> %502 to <2 x i64>
  %504 = or <2 x i64> %501, %503
  %505 = bitcast <2 x i64> %504 to <8 x i16>
  %506 = icmp sgt <8 x i16> %505, zeroinitializer
  %507 = sext <8 x i1> %506 to <8 x i16>
  %508 = bitcast <8 x i16> %507 to <2 x i64>
  %509 = and <2 x i64> %504, %508
  %510 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %511 = bitcast <2 x i64>* %510 to <4 x i32>*
  %512 = load <4 x i32>, <4 x i32>* %511, align 16
  %513 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %514 = load <2 x i64>, <2 x i64>* %513, align 16
  %515 = bitcast <2 x i64> %104 to <8 x i16>
  %516 = shufflevector <8 x i16> %515, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %517 = shufflevector <8 x i16> %515, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %439, label %524, label %518

518:                                              ; preds = %490
  %519 = shufflevector <4 x i32> %512, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %520 = bitcast <2 x i64> %514 to <4 x i32>
  %521 = shufflevector <4 x i32> %520, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %522 = bitcast <8 x i16> %516 to <4 x i32>
  %523 = add <4 x i32> %521, %522
  br label %528

524:                                              ; preds = %490
  %525 = bitcast <8 x i16> %516 to <4 x i32>
  %526 = add <4 x i32> %512, %525
  %527 = bitcast <2 x i64> %514 to <4 x i32>
  br label %528

528:                                              ; preds = %518, %524
  %529 = phi <4 x i32> [ %519, %518 ], [ %527, %524 ]
  %530 = phi <4 x i32> [ %523, %518 ], [ %526, %524 ]
  %531 = bitcast <8 x i16> %517 to <4 x i32>
  %532 = add <4 x i32> %529, %531
  %533 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %530, <4 x i32> %532) #8
  %534 = bitcast <8 x i16> %533 to <2 x i64>
  %535 = icmp slt <8 x i16> %458, %533
  %536 = sext <8 x i1> %535 to <8 x i16>
  %537 = bitcast <8 x i16> %536 to <2 x i64>
  %538 = xor <2 x i64> %537, <i64 -1, i64 -1>
  %539 = and <2 x i64> %538, %534
  %540 = and <8 x i16> %458, %536
  %541 = bitcast <8 x i16> %540 to <2 x i64>
  %542 = or <2 x i64> %539, %541
  %543 = bitcast <2 x i64> %542 to <8 x i16>
  %544 = icmp sgt <8 x i16> %543, zeroinitializer
  %545 = sext <8 x i1> %544 to <8 x i16>
  %546 = bitcast <8 x i16> %545 to <2 x i64>
  %547 = and <2 x i64> %542, %546
  %548 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %549 = bitcast <2 x i64>* %548 to <4 x i32>*
  %550 = load <4 x i32>, <4 x i32>* %549, align 16
  %551 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %552 = load <2 x i64>, <2 x i64>* %551, align 16
  %553 = bitcast <2 x i64> %109 to <8 x i16>
  %554 = shufflevector <8 x i16> %553, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %555 = shufflevector <8 x i16> %553, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %439, label %562, label %556

556:                                              ; preds = %528
  %557 = shufflevector <4 x i32> %550, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %558 = bitcast <2 x i64> %552 to <4 x i32>
  %559 = shufflevector <4 x i32> %558, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %560 = bitcast <8 x i16> %554 to <4 x i32>
  %561 = add <4 x i32> %559, %560
  br label %566

562:                                              ; preds = %528
  %563 = bitcast <8 x i16> %554 to <4 x i32>
  %564 = add <4 x i32> %550, %563
  %565 = bitcast <2 x i64> %552 to <4 x i32>
  br label %566

566:                                              ; preds = %556, %562
  %567 = phi <4 x i32> [ %557, %556 ], [ %565, %562 ]
  %568 = phi <4 x i32> [ %561, %556 ], [ %564, %562 ]
  %569 = bitcast <8 x i16> %555 to <4 x i32>
  %570 = add <4 x i32> %567, %569
  %571 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %568, <4 x i32> %570) #8
  %572 = bitcast <8 x i16> %571 to <2 x i64>
  %573 = icmp slt <8 x i16> %458, %571
  %574 = sext <8 x i1> %573 to <8 x i16>
  %575 = bitcast <8 x i16> %574 to <2 x i64>
  %576 = xor <2 x i64> %575, <i64 -1, i64 -1>
  %577 = and <2 x i64> %576, %572
  %578 = and <8 x i16> %458, %574
  %579 = bitcast <8 x i16> %578 to <2 x i64>
  %580 = or <2 x i64> %577, %579
  %581 = bitcast <2 x i64> %580 to <8 x i16>
  %582 = icmp sgt <8 x i16> %581, zeroinitializer
  %583 = sext <8 x i1> %582 to <8 x i16>
  %584 = bitcast <8 x i16> %583 to <2 x i64>
  %585 = and <2 x i64> %580, %584
  %586 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %587 = bitcast <2 x i64>* %586 to <4 x i32>*
  %588 = load <4 x i32>, <4 x i32>* %587, align 16
  %589 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %590 = load <2 x i64>, <2 x i64>* %589, align 16
  %591 = bitcast <2 x i64> %114 to <8 x i16>
  %592 = shufflevector <8 x i16> %591, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %593 = shufflevector <8 x i16> %591, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %439, label %600, label %594

594:                                              ; preds = %566
  %595 = shufflevector <4 x i32> %588, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %596 = bitcast <2 x i64> %590 to <4 x i32>
  %597 = shufflevector <4 x i32> %596, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %598 = bitcast <8 x i16> %592 to <4 x i32>
  %599 = add <4 x i32> %597, %598
  br label %604

600:                                              ; preds = %566
  %601 = bitcast <8 x i16> %592 to <4 x i32>
  %602 = add <4 x i32> %588, %601
  %603 = bitcast <2 x i64> %590 to <4 x i32>
  br label %604

604:                                              ; preds = %594, %600
  %605 = phi <4 x i32> [ %595, %594 ], [ %603, %600 ]
  %606 = phi <4 x i32> [ %599, %594 ], [ %602, %600 ]
  %607 = bitcast <8 x i16> %593 to <4 x i32>
  %608 = add <4 x i32> %605, %607
  %609 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %606, <4 x i32> %608) #8
  %610 = bitcast <8 x i16> %609 to <2 x i64>
  %611 = icmp slt <8 x i16> %458, %609
  %612 = sext <8 x i1> %611 to <8 x i16>
  %613 = bitcast <8 x i16> %612 to <2 x i64>
  %614 = xor <2 x i64> %613, <i64 -1, i64 -1>
  %615 = and <2 x i64> %614, %610
  %616 = and <8 x i16> %458, %612
  %617 = bitcast <8 x i16> %616 to <2 x i64>
  %618 = or <2 x i64> %615, %617
  %619 = bitcast <2 x i64> %618 to <8 x i16>
  %620 = icmp sgt <8 x i16> %619, zeroinitializer
  %621 = sext <8 x i1> %620 to <8 x i16>
  %622 = bitcast <8 x i16> %621 to <2 x i64>
  %623 = and <2 x i64> %618, %622
  %624 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %625 = bitcast <2 x i64>* %624 to <4 x i32>*
  %626 = load <4 x i32>, <4 x i32>* %625, align 16
  %627 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %628 = load <2 x i64>, <2 x i64>* %627, align 16
  %629 = bitcast <2 x i64> %119 to <8 x i16>
  %630 = shufflevector <8 x i16> %629, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %631 = shufflevector <8 x i16> %629, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %439, label %638, label %632

632:                                              ; preds = %604
  %633 = shufflevector <4 x i32> %626, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %634 = bitcast <2 x i64> %628 to <4 x i32>
  %635 = shufflevector <4 x i32> %634, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %636 = bitcast <8 x i16> %630 to <4 x i32>
  %637 = add <4 x i32> %635, %636
  br label %642

638:                                              ; preds = %604
  %639 = bitcast <8 x i16> %630 to <4 x i32>
  %640 = add <4 x i32> %626, %639
  %641 = bitcast <2 x i64> %628 to <4 x i32>
  br label %642

642:                                              ; preds = %632, %638
  %643 = phi <4 x i32> [ %633, %632 ], [ %641, %638 ]
  %644 = phi <4 x i32> [ %637, %632 ], [ %640, %638 ]
  %645 = bitcast <8 x i16> %631 to <4 x i32>
  %646 = add <4 x i32> %643, %645
  %647 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %644, <4 x i32> %646) #8
  %648 = bitcast <8 x i16> %647 to <2 x i64>
  %649 = icmp slt <8 x i16> %458, %647
  %650 = sext <8 x i1> %649 to <8 x i16>
  %651 = bitcast <8 x i16> %650 to <2 x i64>
  %652 = xor <2 x i64> %651, <i64 -1, i64 -1>
  %653 = and <2 x i64> %652, %648
  %654 = and <8 x i16> %458, %650
  %655 = bitcast <8 x i16> %654 to <2 x i64>
  %656 = or <2 x i64> %653, %655
  %657 = bitcast <2 x i64> %656 to <8 x i16>
  %658 = icmp sgt <8 x i16> %657, zeroinitializer
  %659 = sext <8 x i1> %658 to <8 x i16>
  %660 = bitcast <8 x i16> %659 to <2 x i64>
  %661 = and <2 x i64> %656, %660
  %662 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %663 = bitcast <2 x i64>* %662 to <4 x i32>*
  %664 = load <4 x i32>, <4 x i32>* %663, align 16
  %665 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %666 = load <2 x i64>, <2 x i64>* %665, align 16
  %667 = bitcast <2 x i64> %124 to <8 x i16>
  %668 = shufflevector <8 x i16> %667, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %669 = shufflevector <8 x i16> %667, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %439, label %676, label %670

670:                                              ; preds = %642
  %671 = shufflevector <4 x i32> %664, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %672 = bitcast <2 x i64> %666 to <4 x i32>
  %673 = shufflevector <4 x i32> %672, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %674 = bitcast <8 x i16> %668 to <4 x i32>
  %675 = add <4 x i32> %673, %674
  br label %680

676:                                              ; preds = %642
  %677 = bitcast <8 x i16> %668 to <4 x i32>
  %678 = add <4 x i32> %664, %677
  %679 = bitcast <2 x i64> %666 to <4 x i32>
  br label %680

680:                                              ; preds = %670, %676
  %681 = phi <4 x i32> [ %671, %670 ], [ %679, %676 ]
  %682 = phi <4 x i32> [ %675, %670 ], [ %678, %676 ]
  %683 = bitcast <8 x i16> %669 to <4 x i32>
  %684 = add <4 x i32> %681, %683
  %685 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %682, <4 x i32> %684) #8
  %686 = bitcast <8 x i16> %685 to <2 x i64>
  %687 = icmp slt <8 x i16> %458, %685
  %688 = sext <8 x i1> %687 to <8 x i16>
  %689 = bitcast <8 x i16> %688 to <2 x i64>
  %690 = xor <2 x i64> %689, <i64 -1, i64 -1>
  %691 = and <2 x i64> %690, %686
  %692 = and <8 x i16> %458, %688
  %693 = bitcast <8 x i16> %692 to <2 x i64>
  %694 = or <2 x i64> %691, %693
  %695 = bitcast <2 x i64> %694 to <8 x i16>
  %696 = icmp sgt <8 x i16> %695, zeroinitializer
  %697 = sext <8 x i1> %696 to <8 x i16>
  %698 = bitcast <8 x i16> %697 to <2 x i64>
  %699 = and <2 x i64> %694, %698
  %700 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %701 = bitcast <2 x i64>* %700 to <4 x i32>*
  %702 = load <4 x i32>, <4 x i32>* %701, align 16
  %703 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %704 = load <2 x i64>, <2 x i64>* %703, align 16
  %705 = bitcast <2 x i64> %129 to <8 x i16>
  %706 = shufflevector <8 x i16> %705, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %707 = shufflevector <8 x i16> %705, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  br i1 %439, label %714, label %708

708:                                              ; preds = %680
  %709 = shufflevector <4 x i32> %702, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %710 = bitcast <2 x i64> %704 to <4 x i32>
  %711 = shufflevector <4 x i32> %710, <4 x i32> undef, <4 x i32> <i32 3, i32 2, i32 1, i32 0>
  %712 = bitcast <8 x i16> %706 to <4 x i32>
  %713 = add <4 x i32> %711, %712
  br label %718

714:                                              ; preds = %680
  %715 = bitcast <8 x i16> %706 to <4 x i32>
  %716 = add <4 x i32> %702, %715
  %717 = bitcast <2 x i64> %704 to <4 x i32>
  br label %718

718:                                              ; preds = %708, %714
  %719 = phi <4 x i32> [ %709, %708 ], [ %717, %714 ]
  %720 = phi <4 x i32> [ %713, %708 ], [ %716, %714 ]
  %721 = bitcast <8 x i16> %707 to <4 x i32>
  %722 = add <4 x i32> %719, %721
  %723 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %720, <4 x i32> %722) #8
  %724 = bitcast <8 x i16> %723 to <2 x i64>
  %725 = icmp slt <8 x i16> %458, %723
  %726 = sext <8 x i1> %725 to <8 x i16>
  %727 = bitcast <8 x i16> %726 to <2 x i64>
  %728 = xor <2 x i64> %727, <i64 -1, i64 -1>
  %729 = and <2 x i64> %728, %724
  %730 = and <8 x i16> %458, %726
  br label %731

731:                                              ; preds = %718, %418
  %732 = phi <8 x i16> [ %730, %718 ], [ %430, %418 ]
  %733 = phi <2 x i64> [ %729, %718 ], [ %429, %418 ]
  %734 = phi <2 x i64> [ %509, %718 ], [ %210, %418 ]
  %735 = phi <2 x i64> [ %547, %718 ], [ %248, %418 ]
  %736 = phi <2 x i64> [ %585, %718 ], [ %286, %418 ]
  %737 = phi <2 x i64> [ %623, %718 ], [ %324, %418 ]
  %738 = phi <2 x i64> [ %661, %718 ], [ %362, %418 ]
  %739 = phi <2 x i64> [ %699, %718 ], [ %400, %418 ]
  %740 = phi <2 x i64> [ %471, %718 ], [ %172, %418 ]
  %741 = bitcast <8 x i16> %732 to <2 x i64>
  %742 = or <2 x i64> %733, %741
  %743 = bitcast <2 x i64> %742 to <8 x i16>
  %744 = icmp sgt <8 x i16> %743, zeroinitializer
  %745 = sext <8 x i1> %744 to <8 x i16>
  %746 = bitcast <8 x i16> %745 to <2 x i64>
  %747 = and <2 x i64> %742, %746
  store <2 x i64> %740, <2 x i64>* %94, align 16
  store <2 x i64> %734, <2 x i64>* %98, align 16
  store <2 x i64> %735, <2 x i64>* %103, align 16
  store <2 x i64> %736, <2 x i64>* %108, align 16
  store <2 x i64> %737, <2 x i64>* %113, align 16
  store <2 x i64> %738, <2 x i64>* %118, align 16
  store <2 x i64> %739, <2 x i64>* %123, align 16
  store <2 x i64> %747, <2 x i64>* %128, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @iadst8x8_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>*, i32, i32, i32, i32) unnamed_addr #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 4
  %10 = load i32, i32* %9, align 16
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 60
  %14 = load i32, i32* %13, align 16
  %15 = insertelement <4 x i32> undef, i32 %14, i32 0
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> zeroinitializer
  %17 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 20
  %18 = load i32, i32* %17, align 16
  %19 = insertelement <4 x i32> undef, i32 %18, i32 0
  %20 = shufflevector <4 x i32> %19, <4 x i32> undef, <4 x i32> zeroinitializer
  %21 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 44
  %22 = load i32, i32* %21, align 16
  %23 = insertelement <4 x i32> undef, i32 %22, i32 0
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> zeroinitializer
  %25 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 36
  %26 = load i32, i32* %25, align 16
  %27 = insertelement <4 x i32> undef, i32 %26, i32 0
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> zeroinitializer
  %29 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 28
  %30 = load i32, i32* %29, align 16
  %31 = insertelement <4 x i32> undef, i32 %30, i32 0
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> zeroinitializer
  %33 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 52
  %34 = load i32, i32* %33, align 16
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 12
  %38 = load i32, i32* %37, align 16
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> zeroinitializer
  %41 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 16
  %42 = load i32, i32* %41, align 16
  %43 = insertelement <4 x i32> undef, i32 %42, i32 0
  %44 = shufflevector <4 x i32> %43, <4 x i32> undef, <4 x i32> zeroinitializer
  %45 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 48
  %46 = load i32, i32* %45, align 16
  %47 = insertelement <4 x i32> undef, i32 %46, i32 0
  %48 = shufflevector <4 x i32> %47, <4 x i32> undef, <4 x i32> zeroinitializer
  %49 = sub nsw i32 0, %46
  %50 = insertelement <4 x i32> undef, i32 %49, i32 0
  %51 = shufflevector <4 x i32> %50, <4 x i32> undef, <4 x i32> zeroinitializer
  %52 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %53 = load i32, i32* %52, align 16
  %54 = insertelement <4 x i32> undef, i32 %53, i32 0
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> zeroinitializer
  %56 = add nsw i32 %2, -1
  %57 = shl i32 1, %56
  %58 = insertelement <4 x i32> undef, i32 %57, i32 0
  %59 = shufflevector <4 x i32> %58, <4 x i32> undef, <4 x i32> zeroinitializer
  %60 = icmp ne i32 %3, 0
  %61 = select i1 %60, i32 6, i32 8
  %62 = add nsw i32 %61, %4
  %63 = icmp slt i32 %62, 16
  %64 = add i32 %62, -1
  %65 = shl i32 1, %64
  %66 = select i1 %63, i32 32768, i32 %65
  %67 = sub nsw i32 0, %66
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = add nsw i32 %66, -1
  %71 = insertelement <4 x i32> undef, i32 %70, i32 0
  %72 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> zeroinitializer
  %73 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %74 = bitcast <2 x i64>* %73 to <4 x i32>*
  %75 = load <4 x i32>, <4 x i32>* %74, align 16
  %76 = mul <4 x i32> %75, %12
  %77 = bitcast <2 x i64>* %0 to <4 x i32>*
  %78 = load <4 x i32>, <4 x i32>* %77, align 16
  %79 = mul <4 x i32> %78, %16
  %80 = add <4 x i32> %76, %59
  %81 = add <4 x i32> %80, %79
  %82 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %81, i32 %2) #8
  %83 = mul <4 x i32> %75, %16
  %84 = mul <4 x i32> %12, %78
  %85 = add <4 x i32> %83, %59
  %86 = sub <4 x i32> %85, %84
  %87 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %86, i32 %2) #8
  %88 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %89 = bitcast <2 x i64>* %88 to <4 x i32>*
  %90 = load <4 x i32>, <4 x i32>* %89, align 16
  %91 = mul <4 x i32> %90, %20
  %92 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %93 = bitcast <2 x i64>* %92 to <4 x i32>*
  %94 = load <4 x i32>, <4 x i32>* %93, align 16
  %95 = mul <4 x i32> %94, %24
  %96 = add <4 x i32> %91, %59
  %97 = add <4 x i32> %96, %95
  %98 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %97, i32 %2) #8
  %99 = mul <4 x i32> %90, %24
  %100 = mul <4 x i32> %20, %94
  %101 = add <4 x i32> %99, %59
  %102 = sub <4 x i32> %101, %100
  %103 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %102, i32 %2) #8
  %104 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %105 = bitcast <2 x i64>* %104 to <4 x i32>*
  %106 = load <4 x i32>, <4 x i32>* %105, align 16
  %107 = mul <4 x i32> %106, %28
  %108 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %109 = bitcast <2 x i64>* %108 to <4 x i32>*
  %110 = load <4 x i32>, <4 x i32>* %109, align 16
  %111 = mul <4 x i32> %110, %32
  %112 = add <4 x i32> %107, %59
  %113 = add <4 x i32> %112, %111
  %114 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %113, i32 %2) #8
  %115 = mul <4 x i32> %106, %32
  %116 = mul <4 x i32> %28, %110
  %117 = add <4 x i32> %115, %59
  %118 = sub <4 x i32> %117, %116
  %119 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %118, i32 %2) #8
  %120 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %121 = bitcast <2 x i64>* %120 to <4 x i32>*
  %122 = load <4 x i32>, <4 x i32>* %121, align 16
  %123 = mul <4 x i32> %122, %36
  %124 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %125 = bitcast <2 x i64>* %124 to <4 x i32>*
  %126 = load <4 x i32>, <4 x i32>* %125, align 16
  %127 = mul <4 x i32> %126, %40
  %128 = add <4 x i32> %123, %59
  %129 = add <4 x i32> %128, %127
  %130 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %129, i32 %2) #8
  %131 = mul <4 x i32> %122, %40
  %132 = mul <4 x i32> %36, %126
  %133 = add <4 x i32> %131, %59
  %134 = sub <4 x i32> %133, %132
  %135 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %134, i32 %2) #8
  %136 = add <4 x i32> %114, %82
  %137 = sub <4 x i32> %82, %114
  %138 = icmp sgt <4 x i32> %136, %69
  %139 = select <4 x i1> %138, <4 x i32> %136, <4 x i32> %69
  %140 = icmp slt <4 x i32> %139, %72
  %141 = select <4 x i1> %140, <4 x i32> %139, <4 x i32> %72
  %142 = icmp sgt <4 x i32> %137, %69
  %143 = select <4 x i1> %142, <4 x i32> %137, <4 x i32> %69
  %144 = icmp slt <4 x i32> %143, %72
  %145 = select <4 x i1> %144, <4 x i32> %143, <4 x i32> %72
  %146 = add <4 x i32> %119, %87
  %147 = sub <4 x i32> %87, %119
  %148 = icmp sgt <4 x i32> %146, %69
  %149 = select <4 x i1> %148, <4 x i32> %146, <4 x i32> %69
  %150 = icmp slt <4 x i32> %149, %72
  %151 = select <4 x i1> %150, <4 x i32> %149, <4 x i32> %72
  %152 = icmp sgt <4 x i32> %147, %69
  %153 = select <4 x i1> %152, <4 x i32> %147, <4 x i32> %69
  %154 = icmp slt <4 x i32> %153, %72
  %155 = select <4 x i1> %154, <4 x i32> %153, <4 x i32> %72
  %156 = add <4 x i32> %130, %98
  %157 = sub <4 x i32> %98, %130
  %158 = icmp sgt <4 x i32> %156, %69
  %159 = select <4 x i1> %158, <4 x i32> %156, <4 x i32> %69
  %160 = icmp slt <4 x i32> %159, %72
  %161 = select <4 x i1> %160, <4 x i32> %159, <4 x i32> %72
  %162 = icmp sgt <4 x i32> %157, %69
  %163 = select <4 x i1> %162, <4 x i32> %157, <4 x i32> %69
  %164 = icmp slt <4 x i32> %163, %72
  %165 = select <4 x i1> %164, <4 x i32> %163, <4 x i32> %72
  %166 = add <4 x i32> %135, %103
  %167 = sub <4 x i32> %103, %135
  %168 = icmp sgt <4 x i32> %166, %69
  %169 = select <4 x i1> %168, <4 x i32> %166, <4 x i32> %69
  %170 = icmp slt <4 x i32> %169, %72
  %171 = select <4 x i1> %170, <4 x i32> %169, <4 x i32> %72
  %172 = icmp sgt <4 x i32> %167, %69
  %173 = select <4 x i1> %172, <4 x i32> %167, <4 x i32> %69
  %174 = icmp slt <4 x i32> %173, %72
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %72
  %176 = mul <4 x i32> %145, %44
  %177 = mul <4 x i32> %155, %48
  %178 = add <4 x i32> %176, %59
  %179 = add <4 x i32> %178, %177
  %180 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %179, i32 %2) #8
  %181 = mul <4 x i32> %145, %48
  %182 = mul <4 x i32> %44, %155
  %183 = add <4 x i32> %181, %59
  %184 = sub <4 x i32> %183, %182
  %185 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %184, i32 %2) #8
  %186 = mul <4 x i32> %165, %51
  %187 = mul <4 x i32> %175, %44
  %188 = add <4 x i32> %186, %59
  %189 = add <4 x i32> %188, %187
  %190 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %189, i32 %2) #8
  %191 = mul <4 x i32> %165, %44
  %192 = mul <4 x i32> %51, %175
  %193 = add <4 x i32> %191, %59
  %194 = sub <4 x i32> %193, %192
  %195 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %194, i32 %2) #8
  %196 = add <4 x i32> %161, %141
  %197 = sub <4 x i32> %141, %161
  %198 = icmp sgt <4 x i32> %196, %69
  %199 = select <4 x i1> %198, <4 x i32> %196, <4 x i32> %69
  %200 = icmp slt <4 x i32> %199, %72
  %201 = select <4 x i1> %200, <4 x i32> %199, <4 x i32> %72
  %202 = icmp sgt <4 x i32> %197, %69
  %203 = select <4 x i1> %202, <4 x i32> %197, <4 x i32> %69
  %204 = icmp slt <4 x i32> %203, %72
  %205 = select <4 x i1> %204, <4 x i32> %203, <4 x i32> %72
  %206 = add <4 x i32> %171, %151
  %207 = sub <4 x i32> %151, %171
  %208 = icmp sgt <4 x i32> %206, %69
  %209 = select <4 x i1> %208, <4 x i32> %206, <4 x i32> %69
  %210 = icmp slt <4 x i32> %209, %72
  %211 = select <4 x i1> %210, <4 x i32> %209, <4 x i32> %72
  %212 = icmp sgt <4 x i32> %207, %69
  %213 = select <4 x i1> %212, <4 x i32> %207, <4 x i32> %69
  %214 = icmp slt <4 x i32> %213, %72
  %215 = select <4 x i1> %214, <4 x i32> %213, <4 x i32> %72
  %216 = add <4 x i32> %190, %180
  %217 = sub <4 x i32> %180, %190
  %218 = icmp sgt <4 x i32> %216, %69
  %219 = select <4 x i1> %218, <4 x i32> %216, <4 x i32> %69
  %220 = icmp slt <4 x i32> %219, %72
  %221 = select <4 x i1> %220, <4 x i32> %219, <4 x i32> %72
  %222 = icmp sgt <4 x i32> %217, %69
  %223 = select <4 x i1> %222, <4 x i32> %217, <4 x i32> %69
  %224 = icmp slt <4 x i32> %223, %72
  %225 = select <4 x i1> %224, <4 x i32> %223, <4 x i32> %72
  %226 = add <4 x i32> %195, %185
  %227 = sub <4 x i32> %185, %195
  %228 = icmp sgt <4 x i32> %226, %69
  %229 = select <4 x i1> %228, <4 x i32> %226, <4 x i32> %69
  %230 = icmp slt <4 x i32> %229, %72
  %231 = select <4 x i1> %230, <4 x i32> %229, <4 x i32> %72
  %232 = icmp sgt <4 x i32> %227, %69
  %233 = select <4 x i1> %232, <4 x i32> %227, <4 x i32> %69
  %234 = icmp slt <4 x i32> %233, %72
  %235 = select <4 x i1> %234, <4 x i32> %233, <4 x i32> %72
  %236 = mul <4 x i32> %205, %55
  %237 = mul <4 x i32> %215, %55
  %238 = add <4 x i32> %236, %59
  %239 = add <4 x i32> %238, %237
  %240 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %239, i32 %2) #8
  %241 = sub <4 x i32> %238, %237
  %242 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %241, i32 %2) #8
  %243 = mul <4 x i32> %225, %55
  %244 = mul <4 x i32> %235, %55
  %245 = add <4 x i32> %243, %59
  %246 = add <4 x i32> %245, %244
  %247 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %246, i32 %2) #8
  %248 = sub <4 x i32> %245, %244
  %249 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %248, i32 %2) #8
  br i1 %60, label %250, label %268

250:                                              ; preds = %6
  %251 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %201, <4 x i32>* %251, align 16
  %252 = sub <4 x i32> zeroinitializer, %221
  %253 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %254 = bitcast <2 x i64>* %253 to <4 x i32>*
  store <4 x i32> %252, <4 x i32>* %254, align 16
  %255 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %256 = bitcast <2 x i64>* %255 to <4 x i32>*
  store <4 x i32> %247, <4 x i32>* %256, align 16
  %257 = sub <4 x i32> zeroinitializer, %240
  %258 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %259 = bitcast <2 x i64>* %258 to <4 x i32>*
  store <4 x i32> %257, <4 x i32>* %259, align 16
  %260 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %261 = bitcast <2 x i64>* %260 to <4 x i32>*
  store <4 x i32> %242, <4 x i32>* %261, align 16
  %262 = sub <4 x i32> zeroinitializer, %249
  %263 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %264 = bitcast <2 x i64>* %263 to <4 x i32>*
  store <4 x i32> %262, <4 x i32>* %264, align 16
  %265 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %266 = bitcast <2 x i64>* %265 to <4 x i32>*
  store <4 x i32> %231, <4 x i32>* %266, align 16
  %267 = sub <4 x i32> zeroinitializer, %211
  br label %344

268:                                              ; preds = %6
  %269 = icmp sgt i32 %4, 10
  %270 = select i1 %269, i32 %4, i32 10
  %271 = shl i32 32, %270
  %272 = sub nsw i32 0, %271
  %273 = insertelement <4 x i32> undef, i32 %272, i32 0
  %274 = shufflevector <4 x i32> %273, <4 x i32> undef, <4 x i32> zeroinitializer
  %275 = add nsw i32 %271, -1
  %276 = insertelement <4 x i32> undef, i32 %275, i32 0
  %277 = shufflevector <4 x i32> %276, <4 x i32> undef, <4 x i32> zeroinitializer
  %278 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %279 = shl i32 1, %5
  %280 = ashr i32 %279, 1
  %281 = insertelement <4 x i32> undef, i32 %280, i32 0
  %282 = shufflevector <4 x i32> %281, <4 x i32> undef, <4 x i32> zeroinitializer
  %283 = add <4 x i32> %201, %282
  %284 = sub <4 x i32> %282, %221
  %285 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %5, i32 0
  %286 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %283, <4 x i32> %285) #8
  %287 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %284, <4 x i32> %285) #8
  %288 = icmp sgt <4 x i32> %286, %274
  %289 = select <4 x i1> %288, <4 x i32> %286, <4 x i32> %274
  %290 = icmp slt <4 x i32> %289, %277
  %291 = select <4 x i1> %290, <4 x i32> %289, <4 x i32> %277
  %292 = icmp sgt <4 x i32> %287, %274
  %293 = select <4 x i1> %292, <4 x i32> %287, <4 x i32> %274
  %294 = icmp slt <4 x i32> %293, %277
  %295 = select <4 x i1> %294, <4 x i32> %293, <4 x i32> %277
  %296 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %291, <4 x i32>* %296, align 16
  %297 = bitcast <2 x i64>* %278 to <4 x i32>*
  store <4 x i32> %295, <4 x i32>* %297, align 16
  %298 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %299 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %300 = add <4 x i32> %247, %282
  %301 = sub <4 x i32> %282, %240
  %302 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %300, <4 x i32> %285) #8
  %303 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %301, <4 x i32> %285) #8
  %304 = icmp sgt <4 x i32> %302, %274
  %305 = select <4 x i1> %304, <4 x i32> %302, <4 x i32> %274
  %306 = icmp slt <4 x i32> %305, %277
  %307 = select <4 x i1> %306, <4 x i32> %305, <4 x i32> %277
  %308 = icmp sgt <4 x i32> %303, %274
  %309 = select <4 x i1> %308, <4 x i32> %303, <4 x i32> %274
  %310 = icmp slt <4 x i32> %309, %277
  %311 = select <4 x i1> %310, <4 x i32> %309, <4 x i32> %277
  %312 = bitcast <2 x i64>* %298 to <4 x i32>*
  store <4 x i32> %307, <4 x i32>* %312, align 16
  %313 = bitcast <2 x i64>* %299 to <4 x i32>*
  store <4 x i32> %311, <4 x i32>* %313, align 16
  %314 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %315 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %316 = add <4 x i32> %242, %282
  %317 = sub <4 x i32> %282, %249
  %318 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %316, <4 x i32> %285) #8
  %319 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %317, <4 x i32> %285) #8
  %320 = icmp sgt <4 x i32> %318, %274
  %321 = select <4 x i1> %320, <4 x i32> %318, <4 x i32> %274
  %322 = icmp slt <4 x i32> %321, %277
  %323 = select <4 x i1> %322, <4 x i32> %321, <4 x i32> %277
  %324 = icmp sgt <4 x i32> %319, %274
  %325 = select <4 x i1> %324, <4 x i32> %319, <4 x i32> %274
  %326 = icmp slt <4 x i32> %325, %277
  %327 = select <4 x i1> %326, <4 x i32> %325, <4 x i32> %277
  %328 = bitcast <2 x i64>* %314 to <4 x i32>*
  store <4 x i32> %323, <4 x i32>* %328, align 16
  %329 = bitcast <2 x i64>* %315 to <4 x i32>*
  store <4 x i32> %327, <4 x i32>* %329, align 16
  %330 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %331 = add <4 x i32> %231, %282
  %332 = sub <4 x i32> %282, %211
  %333 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %331, <4 x i32> %285) #8
  %334 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %332, <4 x i32> %285) #8
  %335 = icmp sgt <4 x i32> %333, %274
  %336 = select <4 x i1> %335, <4 x i32> %333, <4 x i32> %274
  %337 = icmp slt <4 x i32> %336, %277
  %338 = select <4 x i1> %337, <4 x i32> %336, <4 x i32> %277
  %339 = icmp sgt <4 x i32> %334, %274
  %340 = select <4 x i1> %339, <4 x i32> %334, <4 x i32> %274
  %341 = icmp slt <4 x i32> %340, %277
  %342 = select <4 x i1> %341, <4 x i32> %340, <4 x i32> %277
  %343 = bitcast <2 x i64>* %330 to <4 x i32>*
  store <4 x i32> %338, <4 x i32>* %343, align 16
  br label %344

344:                                              ; preds = %268, %250
  %345 = phi <4 x i32> [ %342, %268 ], [ %267, %250 ]
  %346 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %347 = bitcast <2 x i64>* %346 to <4 x i32>*
  store <4 x i32> %345, <4 x i32>* %347, align 16
  %348 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %349 = bitcast <2 x i64>* %348 to <4 x i32>*
  %350 = load <4 x i32>, <4 x i32>* %349, align 16
  %351 = mul <4 x i32> %350, %12
  %352 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %353 = bitcast <2 x i64>* %352 to <4 x i32>*
  %354 = load <4 x i32>, <4 x i32>* %353, align 16
  %355 = mul <4 x i32> %354, %16
  %356 = add <4 x i32> %351, %59
  %357 = add <4 x i32> %356, %355
  %358 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %357, i32 %2) #8
  %359 = mul <4 x i32> %350, %16
  %360 = mul <4 x i32> %12, %354
  %361 = add <4 x i32> %359, %59
  %362 = sub <4 x i32> %361, %360
  %363 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %362, i32 %2) #8
  %364 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %365 = bitcast <2 x i64>* %364 to <4 x i32>*
  %366 = load <4 x i32>, <4 x i32>* %365, align 16
  %367 = mul <4 x i32> %366, %20
  %368 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %369 = bitcast <2 x i64>* %368 to <4 x i32>*
  %370 = load <4 x i32>, <4 x i32>* %369, align 16
  %371 = mul <4 x i32> %370, %24
  %372 = add <4 x i32> %367, %59
  %373 = add <4 x i32> %372, %371
  %374 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %373, i32 %2) #8
  %375 = mul <4 x i32> %366, %24
  %376 = mul <4 x i32> %20, %370
  %377 = add <4 x i32> %375, %59
  %378 = sub <4 x i32> %377, %376
  %379 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %378, i32 %2) #8
  %380 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %381 = bitcast <2 x i64>* %380 to <4 x i32>*
  %382 = load <4 x i32>, <4 x i32>* %381, align 16
  %383 = mul <4 x i32> %382, %28
  %384 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %385 = bitcast <2 x i64>* %384 to <4 x i32>*
  %386 = load <4 x i32>, <4 x i32>* %385, align 16
  %387 = mul <4 x i32> %386, %32
  %388 = add <4 x i32> %383, %59
  %389 = add <4 x i32> %388, %387
  %390 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %389, i32 %2) #8
  %391 = mul <4 x i32> %382, %32
  %392 = mul <4 x i32> %28, %386
  %393 = add <4 x i32> %391, %59
  %394 = sub <4 x i32> %393, %392
  %395 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %394, i32 %2) #8
  %396 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %397 = bitcast <2 x i64>* %396 to <4 x i32>*
  %398 = load <4 x i32>, <4 x i32>* %397, align 16
  %399 = mul <4 x i32> %398, %36
  %400 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %401 = bitcast <2 x i64>* %400 to <4 x i32>*
  %402 = load <4 x i32>, <4 x i32>* %401, align 16
  %403 = mul <4 x i32> %402, %40
  %404 = add <4 x i32> %399, %59
  %405 = add <4 x i32> %404, %403
  %406 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %405, i32 %2) #8
  %407 = mul <4 x i32> %398, %40
  %408 = mul <4 x i32> %36, %402
  %409 = add <4 x i32> %407, %59
  %410 = sub <4 x i32> %409, %408
  %411 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %410, i32 %2) #8
  %412 = add <4 x i32> %390, %358
  %413 = sub <4 x i32> %358, %390
  %414 = icmp sgt <4 x i32> %412, %69
  %415 = select <4 x i1> %414, <4 x i32> %412, <4 x i32> %69
  %416 = icmp slt <4 x i32> %415, %72
  %417 = select <4 x i1> %416, <4 x i32> %415, <4 x i32> %72
  %418 = icmp sgt <4 x i32> %413, %69
  %419 = select <4 x i1> %418, <4 x i32> %413, <4 x i32> %69
  %420 = icmp slt <4 x i32> %419, %72
  %421 = select <4 x i1> %420, <4 x i32> %419, <4 x i32> %72
  %422 = add <4 x i32> %395, %363
  %423 = sub <4 x i32> %363, %395
  %424 = icmp sgt <4 x i32> %422, %69
  %425 = select <4 x i1> %424, <4 x i32> %422, <4 x i32> %69
  %426 = icmp slt <4 x i32> %425, %72
  %427 = select <4 x i1> %426, <4 x i32> %425, <4 x i32> %72
  %428 = icmp sgt <4 x i32> %423, %69
  %429 = select <4 x i1> %428, <4 x i32> %423, <4 x i32> %69
  %430 = icmp slt <4 x i32> %429, %72
  %431 = select <4 x i1> %430, <4 x i32> %429, <4 x i32> %72
  %432 = add <4 x i32> %406, %374
  %433 = sub <4 x i32> %374, %406
  %434 = icmp sgt <4 x i32> %432, %69
  %435 = select <4 x i1> %434, <4 x i32> %432, <4 x i32> %69
  %436 = icmp slt <4 x i32> %435, %72
  %437 = select <4 x i1> %436, <4 x i32> %435, <4 x i32> %72
  %438 = icmp sgt <4 x i32> %433, %69
  %439 = select <4 x i1> %438, <4 x i32> %433, <4 x i32> %69
  %440 = icmp slt <4 x i32> %439, %72
  %441 = select <4 x i1> %440, <4 x i32> %439, <4 x i32> %72
  %442 = add <4 x i32> %411, %379
  %443 = sub <4 x i32> %379, %411
  %444 = icmp sgt <4 x i32> %442, %69
  %445 = select <4 x i1> %444, <4 x i32> %442, <4 x i32> %69
  %446 = icmp slt <4 x i32> %445, %72
  %447 = select <4 x i1> %446, <4 x i32> %445, <4 x i32> %72
  %448 = icmp sgt <4 x i32> %443, %69
  %449 = select <4 x i1> %448, <4 x i32> %443, <4 x i32> %69
  %450 = icmp slt <4 x i32> %449, %72
  %451 = select <4 x i1> %450, <4 x i32> %449, <4 x i32> %72
  %452 = mul <4 x i32> %421, %44
  %453 = mul <4 x i32> %431, %48
  %454 = add <4 x i32> %452, %59
  %455 = add <4 x i32> %454, %453
  %456 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %455, i32 %2) #8
  %457 = mul <4 x i32> %421, %48
  %458 = mul <4 x i32> %44, %431
  %459 = add <4 x i32> %457, %59
  %460 = sub <4 x i32> %459, %458
  %461 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %460, i32 %2) #8
  %462 = mul <4 x i32> %441, %51
  %463 = mul <4 x i32> %451, %44
  %464 = add <4 x i32> %462, %59
  %465 = add <4 x i32> %464, %463
  %466 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %465, i32 %2) #8
  %467 = mul <4 x i32> %441, %44
  %468 = mul <4 x i32> %51, %451
  %469 = add <4 x i32> %467, %59
  %470 = sub <4 x i32> %469, %468
  %471 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %470, i32 %2) #8
  %472 = add <4 x i32> %437, %417
  %473 = sub <4 x i32> %417, %437
  %474 = icmp sgt <4 x i32> %472, %69
  %475 = select <4 x i1> %474, <4 x i32> %472, <4 x i32> %69
  %476 = icmp slt <4 x i32> %475, %72
  %477 = select <4 x i1> %476, <4 x i32> %475, <4 x i32> %72
  %478 = icmp sgt <4 x i32> %473, %69
  %479 = select <4 x i1> %478, <4 x i32> %473, <4 x i32> %69
  %480 = icmp slt <4 x i32> %479, %72
  %481 = select <4 x i1> %480, <4 x i32> %479, <4 x i32> %72
  %482 = add <4 x i32> %447, %427
  %483 = sub <4 x i32> %427, %447
  %484 = icmp sgt <4 x i32> %482, %69
  %485 = select <4 x i1> %484, <4 x i32> %482, <4 x i32> %69
  %486 = icmp slt <4 x i32> %485, %72
  %487 = select <4 x i1> %486, <4 x i32> %485, <4 x i32> %72
  %488 = icmp sgt <4 x i32> %483, %69
  %489 = select <4 x i1> %488, <4 x i32> %483, <4 x i32> %69
  %490 = icmp slt <4 x i32> %489, %72
  %491 = select <4 x i1> %490, <4 x i32> %489, <4 x i32> %72
  %492 = add <4 x i32> %466, %456
  %493 = sub <4 x i32> %456, %466
  %494 = icmp sgt <4 x i32> %492, %69
  %495 = select <4 x i1> %494, <4 x i32> %492, <4 x i32> %69
  %496 = icmp slt <4 x i32> %495, %72
  %497 = select <4 x i1> %496, <4 x i32> %495, <4 x i32> %72
  %498 = icmp sgt <4 x i32> %493, %69
  %499 = select <4 x i1> %498, <4 x i32> %493, <4 x i32> %69
  %500 = icmp slt <4 x i32> %499, %72
  %501 = select <4 x i1> %500, <4 x i32> %499, <4 x i32> %72
  %502 = add <4 x i32> %471, %461
  %503 = sub <4 x i32> %461, %471
  %504 = icmp sgt <4 x i32> %502, %69
  %505 = select <4 x i1> %504, <4 x i32> %502, <4 x i32> %69
  %506 = icmp slt <4 x i32> %505, %72
  %507 = select <4 x i1> %506, <4 x i32> %505, <4 x i32> %72
  %508 = icmp sgt <4 x i32> %503, %69
  %509 = select <4 x i1> %508, <4 x i32> %503, <4 x i32> %69
  %510 = icmp slt <4 x i32> %509, %72
  %511 = select <4 x i1> %510, <4 x i32> %509, <4 x i32> %72
  %512 = mul <4 x i32> %481, %55
  %513 = mul <4 x i32> %491, %55
  %514 = add <4 x i32> %512, %59
  %515 = add <4 x i32> %514, %513
  %516 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %515, i32 %2) #8
  %517 = sub <4 x i32> %514, %513
  %518 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %517, i32 %2) #8
  %519 = mul <4 x i32> %501, %55
  %520 = mul <4 x i32> %511, %55
  %521 = add <4 x i32> %519, %59
  %522 = add <4 x i32> %521, %520
  %523 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %522, i32 %2) #8
  %524 = sub <4 x i32> %521, %520
  %525 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %524, i32 %2) #8
  br i1 %60, label %526, label %545

526:                                              ; preds = %344
  %527 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %528 = bitcast <2 x i64>* %527 to <4 x i32>*
  store <4 x i32> %477, <4 x i32>* %528, align 16
  %529 = sub <4 x i32> zeroinitializer, %497
  %530 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %531 = bitcast <2 x i64>* %530 to <4 x i32>*
  store <4 x i32> %529, <4 x i32>* %531, align 16
  %532 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %533 = bitcast <2 x i64>* %532 to <4 x i32>*
  store <4 x i32> %523, <4 x i32>* %533, align 16
  %534 = sub <4 x i32> zeroinitializer, %516
  %535 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %536 = bitcast <2 x i64>* %535 to <4 x i32>*
  store <4 x i32> %534, <4 x i32>* %536, align 16
  %537 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %538 = bitcast <2 x i64>* %537 to <4 x i32>*
  store <4 x i32> %518, <4 x i32>* %538, align 16
  %539 = sub <4 x i32> zeroinitializer, %525
  %540 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %541 = bitcast <2 x i64>* %540 to <4 x i32>*
  store <4 x i32> %539, <4 x i32>* %541, align 16
  %542 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %543 = bitcast <2 x i64>* %542 to <4 x i32>*
  store <4 x i32> %507, <4 x i32>* %543, align 16
  %544 = sub <4 x i32> zeroinitializer, %487
  br label %622

545:                                              ; preds = %344
  %546 = icmp sgt i32 %4, 10
  %547 = select i1 %546, i32 %4, i32 10
  %548 = shl i32 32, %547
  %549 = sub nsw i32 0, %548
  %550 = insertelement <4 x i32> undef, i32 %549, i32 0
  %551 = shufflevector <4 x i32> %550, <4 x i32> undef, <4 x i32> zeroinitializer
  %552 = add nsw i32 %548, -1
  %553 = insertelement <4 x i32> undef, i32 %552, i32 0
  %554 = shufflevector <4 x i32> %553, <4 x i32> undef, <4 x i32> zeroinitializer
  %555 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %556 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %557 = shl i32 1, %5
  %558 = ashr i32 %557, 1
  %559 = insertelement <4 x i32> undef, i32 %558, i32 0
  %560 = shufflevector <4 x i32> %559, <4 x i32> undef, <4 x i32> zeroinitializer
  %561 = add <4 x i32> %477, %560
  %562 = sub <4 x i32> %560, %497
  %563 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %5, i32 0
  %564 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %561, <4 x i32> %563) #8
  %565 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %562, <4 x i32> %563) #8
  %566 = icmp sgt <4 x i32> %564, %551
  %567 = select <4 x i1> %566, <4 x i32> %564, <4 x i32> %551
  %568 = icmp slt <4 x i32> %567, %554
  %569 = select <4 x i1> %568, <4 x i32> %567, <4 x i32> %554
  %570 = icmp sgt <4 x i32> %565, %551
  %571 = select <4 x i1> %570, <4 x i32> %565, <4 x i32> %551
  %572 = icmp slt <4 x i32> %571, %554
  %573 = select <4 x i1> %572, <4 x i32> %571, <4 x i32> %554
  %574 = bitcast <2 x i64>* %555 to <4 x i32>*
  store <4 x i32> %569, <4 x i32>* %574, align 16
  %575 = bitcast <2 x i64>* %556 to <4 x i32>*
  store <4 x i32> %573, <4 x i32>* %575, align 16
  %576 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %577 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %578 = add <4 x i32> %523, %560
  %579 = sub <4 x i32> %560, %516
  %580 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %578, <4 x i32> %563) #8
  %581 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %579, <4 x i32> %563) #8
  %582 = icmp sgt <4 x i32> %580, %551
  %583 = select <4 x i1> %582, <4 x i32> %580, <4 x i32> %551
  %584 = icmp slt <4 x i32> %583, %554
  %585 = select <4 x i1> %584, <4 x i32> %583, <4 x i32> %554
  %586 = icmp sgt <4 x i32> %581, %551
  %587 = select <4 x i1> %586, <4 x i32> %581, <4 x i32> %551
  %588 = icmp slt <4 x i32> %587, %554
  %589 = select <4 x i1> %588, <4 x i32> %587, <4 x i32> %554
  %590 = bitcast <2 x i64>* %576 to <4 x i32>*
  store <4 x i32> %585, <4 x i32>* %590, align 16
  %591 = bitcast <2 x i64>* %577 to <4 x i32>*
  store <4 x i32> %589, <4 x i32>* %591, align 16
  %592 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %593 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %594 = add <4 x i32> %518, %560
  %595 = sub <4 x i32> %560, %525
  %596 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %594, <4 x i32> %563) #8
  %597 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %595, <4 x i32> %563) #8
  %598 = icmp sgt <4 x i32> %596, %551
  %599 = select <4 x i1> %598, <4 x i32> %596, <4 x i32> %551
  %600 = icmp slt <4 x i32> %599, %554
  %601 = select <4 x i1> %600, <4 x i32> %599, <4 x i32> %554
  %602 = icmp sgt <4 x i32> %597, %551
  %603 = select <4 x i1> %602, <4 x i32> %597, <4 x i32> %551
  %604 = icmp slt <4 x i32> %603, %554
  %605 = select <4 x i1> %604, <4 x i32> %603, <4 x i32> %554
  %606 = bitcast <2 x i64>* %592 to <4 x i32>*
  store <4 x i32> %601, <4 x i32>* %606, align 16
  %607 = bitcast <2 x i64>* %593 to <4 x i32>*
  store <4 x i32> %605, <4 x i32>* %607, align 16
  %608 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %609 = add <4 x i32> %507, %560
  %610 = sub <4 x i32> %560, %487
  %611 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %609, <4 x i32> %563) #8
  %612 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %610, <4 x i32> %563) #8
  %613 = icmp sgt <4 x i32> %611, %551
  %614 = select <4 x i1> %613, <4 x i32> %611, <4 x i32> %551
  %615 = icmp slt <4 x i32> %614, %554
  %616 = select <4 x i1> %615, <4 x i32> %614, <4 x i32> %554
  %617 = icmp sgt <4 x i32> %612, %551
  %618 = select <4 x i1> %617, <4 x i32> %612, <4 x i32> %551
  %619 = icmp slt <4 x i32> %618, %554
  %620 = select <4 x i1> %619, <4 x i32> %618, <4 x i32> %554
  %621 = bitcast <2 x i64>* %608 to <4 x i32>*
  store <4 x i32> %616, <4 x i32>* %621, align 16
  br label %622

622:                                              ; preds = %545, %526
  %623 = phi <4 x i32> [ %620, %545 ], [ %544, %526 ]
  %624 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %625 = bitcast <2 x i64>* %624 to <4 x i32>*
  store <4 x i32> %623, <4 x i32>* %625, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_highbd_inv_txfm_add_8x8_sse4_1(i32* readonly, i8*, i32, %struct.txfm_param* nocapture readonly) local_unnamed_addr #3 {
  %5 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 3
  %6 = load i32, i32* %5, align 4
  %7 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 0
  %8 = load i8, i8* %7, align 4
  %9 = zext i8 %8 to i32
  %10 = add nsw i32 %9, -9
  %11 = icmp ult i32 %10, 7
  br i1 %11, label %12, label %17

12:                                               ; preds = %4
  %13 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 1
  %14 = load i8, i8* %13, align 1
  %15 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 6
  %16 = load i32, i32* %15, align 4
  tail call void @av1_highbd_inv_txfm2d_add_universe_sse4_1(i32* %0, i8* %1, i32 %2, i8 zeroext %8, i8 zeroext %14, i32 %16, i32 %6)
  br label %21

17:                                               ; preds = %4
  %18 = ptrtoint i8* %1 to i64
  %19 = shl i64 %18, 1
  %20 = inttoptr i64 %19 to i16*
  tail call void @av1_inv_txfm2d_add_8x8_sse4_1(i32* %0, i16* %20, i32 %2, i8 zeroext %8, i32 %6)
  br label %21

21:                                               ; preds = %17, %12
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_highbd_inv_txfm2d_add_universe_sse4_1(i32* nocapture readonly, i8*, i32, i8 zeroext, i8 zeroext, i32, i32) local_unnamed_addr #0 {
  %8 = alloca [256 x <2 x i64>], align 16
  %9 = alloca [32 x <2 x i64>], align 16
  %10 = alloca [16 x <2 x i64>], align 16
  %11 = alloca [1024 x <2 x i64>], align 16
  %12 = alloca [64 x <2 x i64>], align 16
  switch i8 %3, label %1606 [
    i8 0, label %13
    i8 1, label %13
    i8 2, label %13
    i8 3, label %13
    i8 4, label %13
    i8 5, label %13
    i8 6, label %13
    i8 7, label %13
    i8 8, label %13
    i8 10, label %459
    i8 12, label %459
    i8 14, label %459
    i8 11, label %835
    i8 13, label %835
    i8 15, label %835
    i8 9, label %1268
  ]

13:                                               ; preds = %7, %7, %7, %7, %7, %7, %7, %7, %7
  %14 = ptrtoint i8* %1 to i64
  %15 = shl i64 %14, 1
  %16 = inttoptr i64 %15 to i16*
  %17 = bitcast [1024 x <2 x i64>]* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16384, i8* nonnull %17) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %17, i8 -86, i64 16384, i1 false) #8
  %18 = icmp eq i32 %5, 1
  %19 = zext i8 %4 to i64
  br i1 %18, label %33, label %20

20:                                               ; preds = %13
  %21 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide_log2_eob, i64 0, i64 %19
  %22 = load i32, i32* %21, align 4
  %23 = add nsw i32 %5, -1
  %24 = ashr i32 %23, %22
  %25 = getelementptr inbounds [19 x i16*], [19 x i16*]* @av1_eob_to_eobxy_default, i64 0, i64 %19
  %26 = load i16*, i16** %25, align 8
  %27 = sext i32 %24 to i64
  %28 = getelementptr inbounds i16, i16* %26, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = sext i16 %29 to i32
  %31 = and i32 %30, 255
  %32 = ashr i32 %30, 8
  br label %33

33:                                               ; preds = %20, %13
  %34 = phi i32 [ %31, %20 ], [ 0, %13 ]
  %35 = phi i32 [ %32, %20 ], [ 0, %13 ]
  %36 = getelementptr inbounds [19 x i8*], [19 x i8*]* @av1_inv_txfm_shift_ls, i64 0, i64 %19
  %37 = load i8*, i8** %36, align 8
  %38 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide_log2, i64 0, i64 %19
  %39 = load i32, i32* %38, align 4
  %40 = add nsw i32 %39, -2
  %41 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high_log2, i64 0, i64 %19
  %42 = load i32, i32* %41, align 4
  %43 = add nsw i32 %42, -2
  %44 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide, i64 0, i64 %19
  %45 = load i32, i32* %44, align 4
  %46 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high, i64 0, i64 %19
  %47 = load i32, i32* %46, align 4
  %48 = ashr i32 %45, 2
  %49 = add nuw nsw i32 %34, 8
  %50 = lshr i32 %49, 3
  %51 = add nsw i32 %35, 8
  %52 = ashr i32 %51, 3
  %53 = icmp slt i32 %45, 32
  %54 = select i1 %53, i32 %45, i32 32
  %55 = icmp eq i32 %45, %47
  br i1 %55, label %71, label %56

56:                                               ; preds = %33
  %57 = icmp sgt i32 %45, %47
  br i1 %57, label %58, label %64

58:                                               ; preds = %56
  %59 = shl nsw i32 %47, 1
  %60 = icmp eq i32 %59, %45
  br i1 %60, label %71, label %61

61:                                               ; preds = %58
  %62 = shl nsw i32 %47, 2
  %63 = icmp eq i32 %62, %45
  br i1 %63, label %71, label %70

64:                                               ; preds = %56
  %65 = shl nsw i32 %45, 1
  %66 = icmp eq i32 %65, %47
  br i1 %66, label %71, label %67

67:                                               ; preds = %64
  %68 = shl nsw i32 %45, 2
  %69 = icmp eq i32 %68, %47
  br i1 %69, label %71, label %70

70:                                               ; preds = %67, %61
  br label %71

71:                                               ; preds = %70, %67, %64, %61, %58, %33
  %72 = phi i32 [ 0, %70 ], [ 0, %33 ], [ 1, %58 ], [ 2, %61 ], [ -1, %64 ], [ -2, %67 ]
  %73 = zext i32 %34 to i64
  %74 = getelementptr inbounds [32 x i32], [32 x i32]* @lowbd_txfm_all_1d_zeros_idx, i64 0, i64 %73
  %75 = load i32, i32* %74, align 4
  %76 = sext i32 %35 to i64
  %77 = getelementptr inbounds [32 x i32], [32 x i32]* @lowbd_txfm_all_1d_zeros_idx, i64 0, i64 %76
  %78 = load i32, i32* %77, align 4
  %79 = sext i32 %40 to i64
  %80 = zext i8 %3 to i64
  %81 = getelementptr inbounds [16 x i8], [16 x i8]* @hitx_1d_tab, i64 0, i64 %80
  %82 = load i8, i8* %81, align 1
  %83 = zext i8 %82 to i64
  %84 = sext i32 %75 to i64
  %85 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %79, i64 %83, i64 %84
  %86 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %85, align 8
  %87 = sext i32 %43 to i64
  %88 = getelementptr inbounds [16 x i8], [16 x i8]* @vitx_1d_tab, i64 0, i64 %80
  %89 = load i8, i8* %88, align 1
  %90 = zext i8 %89 to i64
  %91 = sext i32 %78 to i64
  %92 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %87, i64 %90, i64 %91
  %93 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %92, align 8
  %94 = add i8 %3, -4
  %95 = icmp ult i8 %94, 5
  br i1 %95, label %96, label %103

96:                                               ; preds = %71
  %97 = sext i8 %94 to i64
  %98 = getelementptr inbounds [5 x i32], [5 x i32]* @switch.table.av1_highbd_inv_txfm2d_add_universe_sse4_1, i64 0, i64 %97
  %99 = load i32, i32* %98, align 4
  %100 = sext i8 %94 to i64
  %101 = getelementptr inbounds [5 x i32], [5 x i32]* @switch.table.av1_highbd_inv_txfm2d_add_universe_sse4_1.1, i64 0, i64 %100
  %102 = load i32, i32* %101, align 4
  br label %103

103:                                              ; preds = %96, %71
  %104 = phi i32 [ 0, %71 ], [ %99, %96 ]
  %105 = phi i32 [ 0, %71 ], [ %102, %96 ]
  %106 = icmp sgt i32 %51, 7
  br i1 %106, label %110, label %107

107:                                              ; preds = %103
  %108 = sext i32 %47 to i64
  %109 = sext i32 %48 to i64
  br label %130

110:                                              ; preds = %103
  %111 = shl nsw i32 %52, 1
  %112 = bitcast [64 x <2 x i64>]* %12 to i8*
  %113 = shl i32 %54, 2
  %114 = shl nuw nsw i32 %50, 1
  %115 = sext i32 %54 to i64
  %116 = and i32 %49, 504
  %117 = icmp eq i32 %116, 0
  %118 = zext i32 %116 to i64
  %119 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 0
  %120 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 %79, i64 %87
  %121 = load i8, i8* %120, align 1
  %122 = sext i8 %121 to i32
  %123 = icmp eq i32 %105, 0
  %124 = sext i32 %48 to i64
  %125 = sext i32 %47 to i64
  %126 = sext i32 %111 to i64
  %127 = zext i32 %114 to i64
  %128 = shl nsw i64 %115, 1
  %129 = mul nsw i64 %115, 3
  br label %147

130:                                              ; preds = %293, %107
  %131 = phi i64 [ %109, %107 ], [ %124, %293 ]
  %132 = phi i64 [ %108, %107 ], [ %125, %293 ]
  %133 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 %79, i64 %87
  %134 = load i8, i8* %133, align 1
  %135 = sext i8 %134 to i32
  %136 = getelementptr inbounds i8, i8* %37, i64 1
  %137 = zext i32 %47 to i64
  %138 = add nsw i64 %137, -1
  %139 = and i64 %137, 3
  %140 = icmp ult i64 %138, 3
  %141 = sub nsw i64 %137, %139
  %142 = icmp eq i64 %139, 0
  %143 = and i64 %137, 3
  %144 = icmp ult i64 %138, 3
  %145 = sub nsw i64 %137, %143
  %146 = icmp eq i64 %143, 0
  br label %314

147:                                              ; preds = %293, %110
  %148 = phi i64 [ 0, %110 ], [ %294, %293 ]
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %112) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %112, i8 -86, i64 1024, i1 false) #8
  %149 = trunc i64 %148 to i32
  %150 = mul i32 %113, %149
  %151 = sext i32 %150 to i64
  %152 = getelementptr inbounds i32, i32* %0, i64 %151
  br label %154

153:                                              ; preds = %154
  switch i32 %72, label %205 [
    i32 -1, label %187
    i32 1, label %187
  ]

154:                                              ; preds = %154, %147
  %155 = phi i64 [ 0, %147 ], [ %185, %154 ]
  %156 = shl nsw i64 %155, 2
  %157 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %156
  %158 = getelementptr inbounds i32, i32* %152, i64 %156
  %159 = bitcast i32* %158 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 1
  %161 = getelementptr inbounds i32, i32* %158, i64 %115
  %162 = bitcast i32* %161 to <4 x i32>*
  %163 = load <4 x i32>, <4 x i32>* %162, align 1
  %164 = getelementptr inbounds <2 x i64>, <2 x i64>* %157, i64 1
  %165 = getelementptr inbounds i32, i32* %158, i64 %128
  %166 = bitcast i32* %165 to <4 x i32>*
  %167 = load <4 x i32>, <4 x i32>* %166, align 1
  %168 = getelementptr inbounds <2 x i64>, <2 x i64>* %157, i64 2
  %169 = getelementptr inbounds i32, i32* %158, i64 %129
  %170 = bitcast i32* %169 to <4 x i32>*
  %171 = load <4 x i32>, <4 x i32>* %170, align 1
  %172 = getelementptr inbounds <2 x i64>, <2 x i64>* %157, i64 3
  %173 = shufflevector <4 x i32> %160, <4 x i32> %163, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %174 = bitcast <4 x i32> %173 to <2 x i64>
  %175 = shufflevector <4 x i32> %160, <4 x i32> %163, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %176 = bitcast <4 x i32> %175 to <2 x i64>
  %177 = shufflevector <4 x i32> %167, <4 x i32> %171, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %178 = bitcast <4 x i32> %177 to <2 x i64>
  %179 = shufflevector <4 x i32> %167, <4 x i32> %171, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %180 = bitcast <4 x i32> %179 to <2 x i64>
  %181 = shufflevector <2 x i64> %174, <2 x i64> %178, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %181, <2 x i64>* %157, align 16
  %182 = shufflevector <2 x i64> %174, <2 x i64> %178, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %182, <2 x i64>* %164, align 16
  %183 = shufflevector <2 x i64> %176, <2 x i64> %180, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %183, <2 x i64>* %168, align 16
  %184 = shufflevector <2 x i64> %176, <2 x i64> %180, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %184, <2 x i64>* %172, align 16
  %185 = add nuw nsw i64 %155, 1
  %186 = icmp eq i64 %185, %127
  br i1 %186, label %153, label %154

187:                                              ; preds = %153, %153
  br i1 %117, label %205, label %188

188:                                              ; preds = %187, %188
  %189 = phi i64 [ %203, %188 ], [ 0, %187 ]
  %190 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %189
  %191 = bitcast <2 x i64>* %190 to <4 x i32>*
  %192 = load <4 x i32>, <4 x i32>* %191, align 16
  %193 = mul <4 x i32> %192, <i32 2896, i32 2896, i32 2896, i32 2896>
  %194 = add <4 x i32> %193, <i32 2048, i32 2048, i32 2048, i32 2048>
  %195 = ashr <4 x i32> %194, <i32 12, i32 12, i32 12, i32 12>
  store <4 x i32> %195, <4 x i32>* %191, align 16
  %196 = or i64 %189, 1
  %197 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %196
  %198 = bitcast <2 x i64>* %197 to <4 x i32>*
  %199 = load <4 x i32>, <4 x i32>* %198, align 16
  %200 = mul <4 x i32> %199, <i32 2896, i32 2896, i32 2896, i32 2896>
  %201 = add <4 x i32> %200, <i32 2048, i32 2048, i32 2048, i32 2048>
  %202 = ashr <4 x i32> %201, <i32 12, i32 12, i32 12, i32 12>
  store <4 x i32> %202, <4 x i32>* %198, align 16
  %203 = add nuw nsw i64 %189, 2
  %204 = icmp eq i64 %203, %118
  br i1 %204, label %205, label %188

205:                                              ; preds = %188, %187, %153
  %206 = load i8, i8* %37, align 1
  %207 = sext i8 %206 to i32
  %208 = sub nsw i32 0, %207
  call void %86(<2 x i64>* nonnull %119, <2 x i64>* nonnull %119, i32 %122, i32 0, i32 %6, i32 %208) #8
  %209 = shl nsw i64 %148, 2
  %210 = getelementptr inbounds [1024 x <2 x i64>], [1024 x <2 x i64>]* %11, i64 0, i64 %209
  br i1 %123, label %253, label %211

211:                                              ; preds = %205, %211
  %212 = phi i64 [ %251, %211 ], [ 0, %205 ]
  %213 = shl nsw i64 %212, 2
  %214 = or i64 %213, 3
  %215 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %214
  %216 = bitcast <2 x i64>* %215 to <4 x i32>*
  %217 = load <4 x i32>, <4 x i32>* %216, align 16
  %218 = or i64 %213, 2
  %219 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %218
  %220 = bitcast <2 x i64>* %219 to <4 x i32>*
  %221 = load <4 x i32>, <4 x i32>* %220, align 16
  %222 = shufflevector <4 x i32> %217, <4 x i32> %221, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %223 = bitcast <4 x i32> %222 to <2 x i64>
  %224 = shufflevector <4 x i32> %217, <4 x i32> %221, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %225 = bitcast <4 x i32> %224 to <2 x i64>
  %226 = or i64 %213, 1
  %227 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %226
  %228 = bitcast <2 x i64>* %227 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16
  %230 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %213
  %231 = bitcast <2 x i64>* %230 to <4 x i32>*
  %232 = load <4 x i32>, <4 x i32>* %231, align 16
  %233 = shufflevector <4 x i32> %229, <4 x i32> %232, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %234 = bitcast <4 x i32> %233 to <2 x i64>
  %235 = shufflevector <4 x i32> %229, <4 x i32> %232, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %236 = bitcast <4 x i32> %235 to <2 x i64>
  %237 = shufflevector <2 x i64> %223, <2 x i64> %234, <2 x i32> <i32 0, i32 2>
  %238 = xor i64 %212, -1
  %239 = add nsw i64 %238, %124
  %240 = mul nsw i64 %239, %125
  %241 = getelementptr inbounds <2 x i64>, <2 x i64>* %210, i64 %240
  store <2 x i64> %237, <2 x i64>* %241, align 16
  %242 = shufflevector <2 x i64> %223, <2 x i64> %234, <2 x i32> <i32 1, i32 3>
  %243 = add nsw i64 %240, 1
  %244 = getelementptr inbounds <2 x i64>, <2 x i64>* %210, i64 %243
  store <2 x i64> %242, <2 x i64>* %244, align 16
  %245 = shufflevector <2 x i64> %225, <2 x i64> %236, <2 x i32> <i32 0, i32 2>
  %246 = add nsw i64 %240, 2
  %247 = getelementptr inbounds <2 x i64>, <2 x i64>* %210, i64 %246
  store <2 x i64> %245, <2 x i64>* %247, align 16
  %248 = shufflevector <2 x i64> %225, <2 x i64> %236, <2 x i32> <i32 1, i32 3>
  %249 = add nsw i64 %240, 3
  %250 = getelementptr inbounds <2 x i64>, <2 x i64>* %210, i64 %249
  store <2 x i64> %248, <2 x i64>* %250, align 16
  %251 = add nuw nsw i64 %212, 1
  %252 = icmp slt i64 %251, %124
  br i1 %252, label %211, label %293

253:                                              ; preds = %205, %253
  %254 = phi i64 [ %291, %253 ], [ 0, %205 ]
  %255 = shl nsw i64 %254, 2
  %256 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %255
  %257 = bitcast <2 x i64>* %256 to <4 x i32>*
  %258 = load <4 x i32>, <4 x i32>* %257, align 16
  %259 = or i64 %255, 1
  %260 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %259
  %261 = bitcast <2 x i64>* %260 to <4 x i32>*
  %262 = load <4 x i32>, <4 x i32>* %261, align 16
  %263 = shufflevector <4 x i32> %258, <4 x i32> %262, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %264 = bitcast <4 x i32> %263 to <2 x i64>
  %265 = shufflevector <4 x i32> %258, <4 x i32> %262, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %266 = bitcast <4 x i32> %265 to <2 x i64>
  %267 = or i64 %255, 2
  %268 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %267
  %269 = bitcast <2 x i64>* %268 to <4 x i32>*
  %270 = load <4 x i32>, <4 x i32>* %269, align 16
  %271 = or i64 %255, 3
  %272 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %271
  %273 = bitcast <2 x i64>* %272 to <4 x i32>*
  %274 = load <4 x i32>, <4 x i32>* %273, align 16
  %275 = shufflevector <4 x i32> %270, <4 x i32> %274, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %276 = bitcast <4 x i32> %275 to <2 x i64>
  %277 = shufflevector <4 x i32> %270, <4 x i32> %274, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %278 = bitcast <4 x i32> %277 to <2 x i64>
  %279 = shufflevector <2 x i64> %264, <2 x i64> %276, <2 x i32> <i32 0, i32 2>
  %280 = mul nsw i64 %254, %125
  %281 = getelementptr inbounds <2 x i64>, <2 x i64>* %210, i64 %280
  store <2 x i64> %279, <2 x i64>* %281, align 16
  %282 = shufflevector <2 x i64> %264, <2 x i64> %276, <2 x i32> <i32 1, i32 3>
  %283 = add nsw i64 %280, 1
  %284 = getelementptr inbounds <2 x i64>, <2 x i64>* %210, i64 %283
  store <2 x i64> %282, <2 x i64>* %284, align 16
  %285 = shufflevector <2 x i64> %266, <2 x i64> %278, <2 x i32> <i32 0, i32 2>
  %286 = add nsw i64 %280, 2
  %287 = getelementptr inbounds <2 x i64>, <2 x i64>* %210, i64 %286
  store <2 x i64> %285, <2 x i64>* %287, align 16
  %288 = shufflevector <2 x i64> %266, <2 x i64> %278, <2 x i32> <i32 1, i32 3>
  %289 = add nsw i64 %280, 3
  %290 = getelementptr inbounds <2 x i64>, <2 x i64>* %210, i64 %289
  store <2 x i64> %288, <2 x i64>* %290, align 16
  %291 = add nuw nsw i64 %254, 1
  %292 = icmp slt i64 %291, %124
  br i1 %292, label %253, label %293

293:                                              ; preds = %211, %253
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %112) #8
  %294 = add nuw nsw i64 %148, 1
  %295 = icmp slt i64 %294, %126
  br i1 %295, label %147, label %130

296:                                              ; preds = %407
  %297 = lshr i64 516062, %19
  %298 = and i64 %297, 1
  %299 = icmp eq i64 %298, 0
  br i1 %299, label %458, label %300

300:                                              ; preds = %296
  %301 = ashr i32 %45, 3
  %302 = shl i32 %47, 1
  %303 = icmp ne i32 %104, 0
  %304 = select i1 %303, i64 -1, i64 1
  %305 = add nsw i32 %47, -1
  %306 = select i1 %303, i32 %305, i32 0
  %307 = shl nsw i32 -1, %6
  %308 = xor i32 %307, -1
  %309 = insertelement <4 x i32> undef, i32 %308, i32 0
  %310 = shufflevector <4 x i32> %309, <4 x i32> undef, <4 x i32> zeroinitializer
  %311 = sext i32 %306 to i64
  %312 = sext i32 %2 to i64
  %313 = sext i32 %301 to i64
  br label %410

314:                                              ; preds = %407, %130
  %315 = phi i64 [ 0, %130 ], [ %408, %407 ]
  %316 = mul nsw i64 %315, %132
  %317 = getelementptr inbounds [1024 x <2 x i64>], [1024 x <2 x i64>]* %11, i64 0, i64 %316
  call void %93(<2 x i64>* %317, <2 x i64>* %317, i32 %135, i32 1, i32 %6, i32 0) #8
  %318 = load i8, i8* %136, align 1
  %319 = sext i8 %318 to i32
  %320 = sub nsw i32 0, %319
  %321 = icmp slt i8 %318, 0
  br i1 %321, label %323, label %322

322:                                              ; preds = %314
  br i1 %140, label %395, label %357

323:                                              ; preds = %314
  %324 = xor i32 %319, -1
  %325 = shl i32 1, %324
  %326 = insertelement <4 x i32> undef, i32 %325, i32 0
  %327 = shufflevector <4 x i32> %326, <4 x i32> undef, <4 x i32> zeroinitializer
  br i1 %144, label %382, label %328

328:                                              ; preds = %323, %328
  %329 = phi i64 [ %354, %328 ], [ 0, %323 ]
  %330 = phi i64 [ %355, %328 ], [ %145, %323 ]
  %331 = getelementptr inbounds <2 x i64>, <2 x i64>* %317, i64 %329
  %332 = bitcast <2 x i64>* %331 to <4 x i32>*
  %333 = load <4 x i32>, <4 x i32>* %332, align 16
  %334 = add <4 x i32> %333, %327
  %335 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %334, i32 %320) #8
  store <4 x i32> %335, <4 x i32>* %332, align 16
  %336 = or i64 %329, 1
  %337 = getelementptr inbounds <2 x i64>, <2 x i64>* %317, i64 %336
  %338 = bitcast <2 x i64>* %337 to <4 x i32>*
  %339 = load <4 x i32>, <4 x i32>* %338, align 16
  %340 = add <4 x i32> %339, %327
  %341 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %340, i32 %320) #8
  store <4 x i32> %341, <4 x i32>* %338, align 16
  %342 = or i64 %329, 2
  %343 = getelementptr inbounds <2 x i64>, <2 x i64>* %317, i64 %342
  %344 = bitcast <2 x i64>* %343 to <4 x i32>*
  %345 = load <4 x i32>, <4 x i32>* %344, align 16
  %346 = add <4 x i32> %345, %327
  %347 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %346, i32 %320) #8
  store <4 x i32> %347, <4 x i32>* %344, align 16
  %348 = or i64 %329, 3
  %349 = getelementptr inbounds <2 x i64>, <2 x i64>* %317, i64 %348
  %350 = bitcast <2 x i64>* %349 to <4 x i32>*
  %351 = load <4 x i32>, <4 x i32>* %350, align 16
  %352 = add <4 x i32> %351, %327
  %353 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %352, i32 %320) #8
  store <4 x i32> %353, <4 x i32>* %350, align 16
  %354 = add nuw nsw i64 %329, 4
  %355 = add i64 %330, -4
  %356 = icmp eq i64 %355, 0
  br i1 %356, label %382, label %328

357:                                              ; preds = %322, %357
  %358 = phi i64 [ %379, %357 ], [ 0, %322 ]
  %359 = phi i64 [ %380, %357 ], [ %141, %322 ]
  %360 = getelementptr inbounds <2 x i64>, <2 x i64>* %317, i64 %358
  %361 = bitcast <2 x i64>* %360 to <4 x i32>*
  %362 = load <4 x i32>, <4 x i32>* %361, align 16
  %363 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %362, i32 %319) #8
  store <4 x i32> %363, <4 x i32>* %361, align 16
  %364 = or i64 %358, 1
  %365 = getelementptr inbounds <2 x i64>, <2 x i64>* %317, i64 %364
  %366 = bitcast <2 x i64>* %365 to <4 x i32>*
  %367 = load <4 x i32>, <4 x i32>* %366, align 16
  %368 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %367, i32 %319) #8
  store <4 x i32> %368, <4 x i32>* %366, align 16
  %369 = or i64 %358, 2
  %370 = getelementptr inbounds <2 x i64>, <2 x i64>* %317, i64 %369
  %371 = bitcast <2 x i64>* %370 to <4 x i32>*
  %372 = load <4 x i32>, <4 x i32>* %371, align 16
  %373 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %372, i32 %319) #8
  store <4 x i32> %373, <4 x i32>* %371, align 16
  %374 = or i64 %358, 3
  %375 = getelementptr inbounds <2 x i64>, <2 x i64>* %317, i64 %374
  %376 = bitcast <2 x i64>* %375 to <4 x i32>*
  %377 = load <4 x i32>, <4 x i32>* %376, align 16
  %378 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %377, i32 %319) #8
  store <4 x i32> %378, <4 x i32>* %376, align 16
  %379 = add nuw nsw i64 %358, 4
  %380 = add i64 %359, -4
  %381 = icmp eq i64 %380, 0
  br i1 %381, label %395, label %357

382:                                              ; preds = %328, %323
  %383 = phi i64 [ 0, %323 ], [ %354, %328 ]
  br i1 %146, label %407, label %384

384:                                              ; preds = %382, %384
  %385 = phi i64 [ %392, %384 ], [ %383, %382 ]
  %386 = phi i64 [ %393, %384 ], [ %143, %382 ]
  %387 = getelementptr inbounds <2 x i64>, <2 x i64>* %317, i64 %385
  %388 = bitcast <2 x i64>* %387 to <4 x i32>*
  %389 = load <4 x i32>, <4 x i32>* %388, align 16
  %390 = add <4 x i32> %389, %327
  %391 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %390, i32 %320) #8
  store <4 x i32> %391, <4 x i32>* %388, align 16
  %392 = add nuw nsw i64 %385, 1
  %393 = add i64 %386, -1
  %394 = icmp eq i64 %393, 0
  br i1 %394, label %407, label %384, !llvm.loop !2

395:                                              ; preds = %357, %322
  %396 = phi i64 [ 0, %322 ], [ %379, %357 ]
  br i1 %142, label %407, label %397

397:                                              ; preds = %395, %397
  %398 = phi i64 [ %404, %397 ], [ %396, %395 ]
  %399 = phi i64 [ %405, %397 ], [ %139, %395 ]
  %400 = getelementptr inbounds <2 x i64>, <2 x i64>* %317, i64 %398
  %401 = bitcast <2 x i64>* %400 to <4 x i32>*
  %402 = load <4 x i32>, <4 x i32>* %401, align 16
  %403 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %402, i32 %319) #8
  store <4 x i32> %403, <4 x i32>* %401, align 16
  %404 = add nuw nsw i64 %398, 1
  %405 = add i64 %399, -1
  %406 = icmp eq i64 %405, 0
  br i1 %406, label %407, label %397, !llvm.loop !4

407:                                              ; preds = %395, %397, %382, %384
  %408 = add nuw nsw i64 %315, 1
  %409 = icmp slt i64 %408, %131
  br i1 %409, label %314, label %296

410:                                              ; preds = %455, %300
  %411 = phi i64 [ 0, %300 ], [ %456, %455 ]
  %412 = trunc i64 %411 to i32
  %413 = mul i32 %302, %412
  %414 = sext i32 %413 to i64
  %415 = getelementptr inbounds [1024 x <2 x i64>], [1024 x <2 x i64>]* %11, i64 0, i64 %414
  %416 = shl nsw i64 %411, 3
  %417 = getelementptr inbounds i16, i16* %16, i64 %416
  br label %418

418:                                              ; preds = %418, %410
  %419 = phi i64 [ 0, %410 ], [ %452, %418 ]
  %420 = phi i64 [ %311, %410 ], [ %453, %418 ]
  %421 = mul nsw i64 %419, %312
  %422 = getelementptr inbounds i16, i16* %417, i64 %421
  %423 = bitcast i16* %422 to <2 x i64>*
  %424 = load <2 x i64>, <2 x i64>* %423, align 2
  %425 = getelementptr inbounds <2 x i64>, <2 x i64>* %415, i64 %420
  %426 = bitcast <2 x i64>* %425 to <4 x i32>*
  %427 = load <4 x i32>, <4 x i32>* %426, align 16
  %428 = add nsw i64 %420, %132
  %429 = getelementptr inbounds <2 x i64>, <2 x i64>* %415, i64 %428
  %430 = bitcast <2 x i64>* %429 to <4 x i32>*
  %431 = load <4 x i32>, <4 x i32>* %430, align 16
  %432 = bitcast <2 x i64> %424 to <8 x i16>
  %433 = shufflevector <8 x i16> %432, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %434 = sext <4 x i16> %433 to <4 x i32>
  %435 = bitcast <2 x i64> %424 to <16 x i8>
  %436 = shufflevector <16 x i8> %435, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %437 = bitcast <16 x i8> %436 to <8 x i16>
  %438 = shufflevector <8 x i16> %437, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %439 = sext <4 x i16> %438 to <4 x i32>
  %440 = add <4 x i32> %427, %434
  %441 = add <4 x i32> %431, %439
  %442 = icmp sgt <4 x i32> %440, zeroinitializer
  %443 = select <4 x i1> %442, <4 x i32> %440, <4 x i32> zeroinitializer
  %444 = icmp slt <4 x i32> %443, %310
  %445 = select <4 x i1> %444, <4 x i32> %443, <4 x i32> %310
  %446 = icmp sgt <4 x i32> %441, zeroinitializer
  %447 = select <4 x i1> %446, <4 x i32> %441, <4 x i32> zeroinitializer
  %448 = icmp slt <4 x i32> %447, %310
  %449 = select <4 x i1> %448, <4 x i32> %447, <4 x i32> %310
  %450 = call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %445, <4 x i32> %449) #8
  %451 = bitcast i16* %422 to <8 x i16>*
  store <8 x i16> %450, <8 x i16>* %451, align 2
  %452 = add nuw nsw i64 %419, 1
  %453 = add i64 %420, %304
  %454 = icmp eq i64 %452, %137
  br i1 %454, label %455, label %418

455:                                              ; preds = %418
  %456 = add nuw nsw i64 %411, 1
  %457 = icmp slt i64 %456, %313
  br i1 %457, label %410, label %458

458:                                              ; preds = %455, %296
  call void @llvm.lifetime.end.p0i8(i64 16384, i8* nonnull %17) #8
  br label %1606

459:                                              ; preds = %7, %7, %7
  %460 = ptrtoint i8* %1 to i64
  %461 = shl i64 %460, 1
  %462 = inttoptr i64 %461 to i16*
  %463 = bitcast [64 x <2 x i64>]* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %463) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %463, i8 -86, i64 1024, i1 false) #8
  %464 = zext i8 %4 to i64
  %465 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high, i64 0, i64 %464
  %466 = load i32, i32* %465, align 4
  %467 = icmp slt i32 %466, 32
  %468 = select i1 %467, i32 %466, i32 32
  %469 = icmp sgt i32 %468, %5
  br i1 %469, label %472, label %470

470:                                              ; preds = %459
  %471 = add nsw i32 %468, -1
  br label %477

472:                                              ; preds = %459
  %473 = add nsw i32 %5, -1
  %474 = sext i32 %473 to i64
  %475 = getelementptr inbounds [32 x i32], [32 x i32]* @eob_fill, i64 0, i64 %474
  %476 = load i32, i32* %475, align 4
  br label %477

477:                                              ; preds = %472, %470
  %478 = phi i32 [ %471, %470 ], [ %476, %472 ]
  %479 = getelementptr inbounds [19 x i8*], [19 x i8*]* @av1_inv_txfm_shift_ls, i64 0, i64 %464
  %480 = load i8*, i8** %479, align 8
  %481 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide_log2, i64 0, i64 %464
  %482 = load i32, i32* %481, align 4
  %483 = add nsw i32 %482, -2
  %484 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high_log2, i64 0, i64 %464
  %485 = load i32, i32* %484, align 4
  %486 = add nsw i32 %485, -2
  %487 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide, i64 0, i64 %464
  %488 = load i32, i32* %487, align 4
  %489 = icmp slt i32 %488, 32
  %490 = select i1 %489, i32 %488, i32 32
  %491 = ashr i32 %490, 2
  %492 = add nsw i32 %478, 8
  %493 = ashr i32 %492, 3
  %494 = icmp eq i32 %488, %466
  br i1 %494, label %510, label %495

495:                                              ; preds = %477
  %496 = icmp sgt i32 %488, %466
  br i1 %496, label %497, label %503

497:                                              ; preds = %495
  %498 = shl nsw i32 %466, 1
  %499 = icmp eq i32 %498, %488
  br i1 %499, label %510, label %500

500:                                              ; preds = %497
  %501 = shl nsw i32 %466, 2
  %502 = icmp eq i32 %501, %488
  br i1 %502, label %510, label %509

503:                                              ; preds = %495
  %504 = shl nsw i32 %488, 1
  %505 = icmp eq i32 %504, %466
  br i1 %505, label %510, label %506

506:                                              ; preds = %503
  %507 = shl nsw i32 %488, 2
  %508 = icmp eq i32 %507, %466
  br i1 %508, label %510, label %509

509:                                              ; preds = %506, %500
  br label %510

510:                                              ; preds = %509, %506, %503, %500, %497, %477
  %511 = phi i32 [ 0, %509 ], [ 0, %477 ], [ 1, %497 ], [ 2, %500 ], [ -1, %503 ], [ -2, %506 ]
  %512 = sext i32 %478 to i64
  %513 = getelementptr inbounds [32 x i32], [32 x i32]* @lowbd_txfm_all_1d_zeros_idx, i64 0, i64 %512
  %514 = load i32, i32* %513, align 4
  %515 = sext i32 %483 to i64
  %516 = zext i8 %3 to i64
  %517 = getelementptr inbounds [16 x i8], [16 x i8]* @hitx_1d_tab, i64 0, i64 %516
  %518 = load i8, i8* %517, align 1
  %519 = zext i8 %518 to i64
  %520 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %515, i64 %519, i64 0
  %521 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %520, align 16
  %522 = sext i32 %486 to i64
  %523 = getelementptr inbounds [16 x i8], [16 x i8]* @vitx_1d_tab, i64 0, i64 %516
  %524 = load i8, i8* %523, align 1
  %525 = zext i8 %524 to i64
  %526 = sext i32 %514 to i64
  %527 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %522, i64 %525, i64 %526
  %528 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %527, align 8
  %529 = add nsw i8 %3, -4
  %530 = lshr i8 %529, 1
  %531 = shl i8 %529, 7
  %532 = or i8 %530, %531
  %533 = icmp ult i8 %532, 6
  br i1 %533, label %534, label %538

534:                                              ; preds = %510
  %535 = sext i8 %532 to i64
  %536 = getelementptr inbounds [6 x i32], [6 x i32]* @switch.table.av1_highbd_inv_txfm2d_add_universe_sse4_1.2, i64 0, i64 %535
  %537 = load i32, i32* %536, align 4
  br label %538

538:                                              ; preds = %534, %510
  %539 = phi i32 [ 0, %510 ], [ %537, %534 ]
  %540 = icmp sgt i32 %492, 7
  br i1 %540, label %541, label %561

541:                                              ; preds = %538
  %542 = shl nsw i32 %493, 1
  %543 = bitcast [16 x <2 x i64>]* %10 to i8*
  %544 = shl i32 %490, 2
  %545 = icmp sgt i32 %490, 3
  %546 = sext i32 %490 to i64
  %547 = zext i32 %490 to i64
  %548 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 0
  %549 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 %515, i64 %522
  %550 = load i8, i8* %549, align 1
  %551 = sext i8 %550 to i32
  %552 = sext i32 %491 to i64
  %553 = sext i32 %466 to i64
  %554 = sext i32 %542 to i64
  %555 = shl nsw i64 %546, 1
  %556 = mul nsw i64 %546, 3
  %557 = and i64 %547, 1
  %558 = icmp eq i32 %490, 1
  %559 = sub nsw i64 %547, %557
  %560 = icmp eq i64 %557, 0
  br label %580

561:                                              ; preds = %643, %538
  %562 = icmp sgt i32 %490, 3
  br i1 %562, label %563, label %670

563:                                              ; preds = %561
  %564 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 %515, i64 %522
  %565 = load i8, i8* %564, align 1
  %566 = sext i8 %565 to i32
  %567 = getelementptr inbounds i8, i8* %480, i64 1
  %568 = zext i32 %466 to i64
  %569 = sext i32 %466 to i64
  %570 = sext i32 %491 to i64
  %571 = add nsw i64 %568, -1
  %572 = and i64 %568, 3
  %573 = icmp ult i64 %571, 3
  %574 = sub nsw i64 %568, %572
  %575 = icmp eq i64 %572, 0
  %576 = and i64 %568, 3
  %577 = icmp ult i64 %571, 3
  %578 = sub nsw i64 %568, %576
  %579 = icmp eq i64 %576, 0
  br label %690

580:                                              ; preds = %643, %541
  %581 = phi i64 [ 0, %541 ], [ %644, %643 ]
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %543) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %543, i8 -86, i64 256, i1 false) #8
  %582 = trunc i64 %581 to i32
  %583 = mul i32 %544, %582
  %584 = sext i32 %583 to i64
  %585 = getelementptr inbounds i32, i32* %0, i64 %584
  br i1 %545, label %588, label %586

586:                                              ; preds = %588, %580
  switch i32 %511, label %637 [
    i32 -1, label %587
    i32 1, label %587
  ]

587:                                              ; preds = %586, %586
  br i1 %558, label %628, label %609

588:                                              ; preds = %580, %588
  %589 = phi i64 [ %607, %588 ], [ 0, %580 ]
  %590 = shl nsw i64 %589, 2
  %591 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %590
  %592 = getelementptr inbounds i32, i32* %585, i64 %590
  %593 = bitcast i32* %592 to <2 x i64>*
  %594 = load <2 x i64>, <2 x i64>* %593, align 1
  store <2 x i64> %594, <2 x i64>* %591, align 16
  %595 = getelementptr inbounds i32, i32* %592, i64 %546
  %596 = bitcast i32* %595 to <2 x i64>*
  %597 = load <2 x i64>, <2 x i64>* %596, align 1
  %598 = getelementptr inbounds <2 x i64>, <2 x i64>* %591, i64 1
  store <2 x i64> %597, <2 x i64>* %598, align 16
  %599 = getelementptr inbounds i32, i32* %592, i64 %555
  %600 = bitcast i32* %599 to <2 x i64>*
  %601 = load <2 x i64>, <2 x i64>* %600, align 1
  %602 = getelementptr inbounds <2 x i64>, <2 x i64>* %591, i64 2
  store <2 x i64> %601, <2 x i64>* %602, align 16
  %603 = getelementptr inbounds i32, i32* %592, i64 %556
  %604 = bitcast i32* %603 to <2 x i64>*
  %605 = load <2 x i64>, <2 x i64>* %604, align 1
  %606 = getelementptr inbounds <2 x i64>, <2 x i64>* %591, i64 3
  store <2 x i64> %605, <2 x i64>* %606, align 16
  %607 = add nuw nsw i64 %589, 1
  %608 = icmp slt i64 %607, %552
  br i1 %608, label %588, label %586

609:                                              ; preds = %587, %609
  %610 = phi i64 [ %625, %609 ], [ 0, %587 ]
  %611 = phi i64 [ %626, %609 ], [ %559, %587 ]
  %612 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %610
  %613 = bitcast <2 x i64>* %612 to <4 x i32>*
  %614 = load <4 x i32>, <4 x i32>* %613, align 16
  %615 = mul <4 x i32> %614, <i32 2896, i32 2896, i32 2896, i32 2896>
  %616 = add <4 x i32> %615, <i32 2048, i32 2048, i32 2048, i32 2048>
  %617 = ashr <4 x i32> %616, <i32 12, i32 12, i32 12, i32 12>
  store <4 x i32> %617, <4 x i32>* %613, align 16
  %618 = or i64 %610, 1
  %619 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %618
  %620 = bitcast <2 x i64>* %619 to <4 x i32>*
  %621 = load <4 x i32>, <4 x i32>* %620, align 16
  %622 = mul <4 x i32> %621, <i32 2896, i32 2896, i32 2896, i32 2896>
  %623 = add <4 x i32> %622, <i32 2048, i32 2048, i32 2048, i32 2048>
  %624 = ashr <4 x i32> %623, <i32 12, i32 12, i32 12, i32 12>
  store <4 x i32> %624, <4 x i32>* %620, align 16
  %625 = add nuw nsw i64 %610, 2
  %626 = add i64 %611, -2
  %627 = icmp eq i64 %626, 0
  br i1 %627, label %628, label %609

628:                                              ; preds = %609, %587
  %629 = phi i64 [ 0, %587 ], [ %625, %609 ]
  br i1 %560, label %637, label %630

630:                                              ; preds = %628
  %631 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %629
  %632 = bitcast <2 x i64>* %631 to <4 x i32>*
  %633 = load <4 x i32>, <4 x i32>* %632, align 16
  %634 = mul <4 x i32> %633, <i32 2896, i32 2896, i32 2896, i32 2896>
  %635 = add <4 x i32> %634, <i32 2048, i32 2048, i32 2048, i32 2048>
  %636 = ashr <4 x i32> %635, <i32 12, i32 12, i32 12, i32 12>
  store <4 x i32> %636, <4 x i32>* %632, align 16
  br label %637

637:                                              ; preds = %630, %628, %586
  %638 = load i8, i8* %480, align 1
  %639 = sext i8 %638 to i32
  %640 = sub nsw i32 0, %639
  call void %521(<2 x i64>* nonnull %548, <2 x i64>* nonnull %548, i32 %551, i32 0, i32 %6, i32 %640) #8
  %641 = shl nsw i64 %581, 2
  %642 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %641
  br i1 %545, label %646, label %643

643:                                              ; preds = %646, %637
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %543) #8
  %644 = add nuw nsw i64 %581, 1
  %645 = icmp slt i64 %644, %554
  br i1 %645, label %580, label %561

646:                                              ; preds = %637, %646
  %647 = phi i64 [ %668, %646 ], [ 0, %637 ]
  %648 = shl nsw i64 %647, 2
  %649 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %648
  %650 = load <2 x i64>, <2 x i64>* %649, align 16
  %651 = mul nsw i64 %647, %553
  %652 = getelementptr inbounds <2 x i64>, <2 x i64>* %642, i64 %651
  store <2 x i64> %650, <2 x i64>* %652, align 16
  %653 = or i64 %648, 1
  %654 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %653
  %655 = load <2 x i64>, <2 x i64>* %654, align 16
  %656 = add nsw i64 %651, 1
  %657 = getelementptr inbounds <2 x i64>, <2 x i64>* %642, i64 %656
  store <2 x i64> %655, <2 x i64>* %657, align 16
  %658 = or i64 %648, 2
  %659 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %658
  %660 = load <2 x i64>, <2 x i64>* %659, align 16
  %661 = add nsw i64 %651, 2
  %662 = getelementptr inbounds <2 x i64>, <2 x i64>* %642, i64 %661
  store <2 x i64> %660, <2 x i64>* %662, align 16
  %663 = or i64 %648, 3
  %664 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %663
  %665 = load <2 x i64>, <2 x i64>* %664, align 16
  %666 = add nsw i64 %651, 3
  %667 = getelementptr inbounds <2 x i64>, <2 x i64>* %642, i64 %666
  store <2 x i64> %665, <2 x i64>* %667, align 16
  %668 = add nuw nsw i64 %647, 1
  %669 = icmp slt i64 %668, %552
  br i1 %669, label %646, label %643

670:                                              ; preds = %783, %561
  %671 = lshr i64 516062, %464
  %672 = and i64 %671, 1
  %673 = icmp eq i64 %672, 0
  br i1 %673, label %834, label %674

674:                                              ; preds = %670
  %675 = ashr i32 %488, 3
  %676 = shl i32 %466, 1
  %677 = icmp ne i32 %539, 0
  %678 = select i1 %677, i64 -1, i64 1
  %679 = add nsw i32 %466, -1
  %680 = select i1 %677, i32 %679, i32 0
  %681 = shl nsw i32 -1, %6
  %682 = xor i32 %681, -1
  %683 = insertelement <4 x i32> undef, i32 %682, i32 0
  %684 = shufflevector <4 x i32> %683, <4 x i32> undef, <4 x i32> zeroinitializer
  %685 = sext i32 %680 to i64
  %686 = sext i32 %466 to i64
  %687 = sext i32 %2 to i64
  %688 = zext i32 %466 to i64
  %689 = sext i32 %675 to i64
  br label %786

690:                                              ; preds = %783, %563
  %691 = phi i64 [ 0, %563 ], [ %784, %783 ]
  %692 = mul nsw i64 %691, %569
  %693 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %692
  call void %528(<2 x i64>* %693, <2 x i64>* %693, i32 %566, i32 1, i32 %6, i32 0) #8
  %694 = load i8, i8* %567, align 1
  %695 = sext i8 %694 to i32
  %696 = sub nsw i32 0, %695
  %697 = icmp slt i8 %694, 0
  br i1 %697, label %699, label %698

698:                                              ; preds = %690
  br i1 %573, label %771, label %733

699:                                              ; preds = %690
  %700 = xor i32 %695, -1
  %701 = shl i32 1, %700
  %702 = insertelement <4 x i32> undef, i32 %701, i32 0
  %703 = shufflevector <4 x i32> %702, <4 x i32> undef, <4 x i32> zeroinitializer
  br i1 %577, label %758, label %704

704:                                              ; preds = %699, %704
  %705 = phi i64 [ %730, %704 ], [ 0, %699 ]
  %706 = phi i64 [ %731, %704 ], [ %578, %699 ]
  %707 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 %705
  %708 = bitcast <2 x i64>* %707 to <4 x i32>*
  %709 = load <4 x i32>, <4 x i32>* %708, align 16
  %710 = add <4 x i32> %709, %703
  %711 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %710, i32 %696) #8
  store <4 x i32> %711, <4 x i32>* %708, align 16
  %712 = or i64 %705, 1
  %713 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 %712
  %714 = bitcast <2 x i64>* %713 to <4 x i32>*
  %715 = load <4 x i32>, <4 x i32>* %714, align 16
  %716 = add <4 x i32> %715, %703
  %717 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %716, i32 %696) #8
  store <4 x i32> %717, <4 x i32>* %714, align 16
  %718 = or i64 %705, 2
  %719 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 %718
  %720 = bitcast <2 x i64>* %719 to <4 x i32>*
  %721 = load <4 x i32>, <4 x i32>* %720, align 16
  %722 = add <4 x i32> %721, %703
  %723 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %722, i32 %696) #8
  store <4 x i32> %723, <4 x i32>* %720, align 16
  %724 = or i64 %705, 3
  %725 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 %724
  %726 = bitcast <2 x i64>* %725 to <4 x i32>*
  %727 = load <4 x i32>, <4 x i32>* %726, align 16
  %728 = add <4 x i32> %727, %703
  %729 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %728, i32 %696) #8
  store <4 x i32> %729, <4 x i32>* %726, align 16
  %730 = add nuw nsw i64 %705, 4
  %731 = add i64 %706, -4
  %732 = icmp eq i64 %731, 0
  br i1 %732, label %758, label %704

733:                                              ; preds = %698, %733
  %734 = phi i64 [ %755, %733 ], [ 0, %698 ]
  %735 = phi i64 [ %756, %733 ], [ %574, %698 ]
  %736 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 %734
  %737 = bitcast <2 x i64>* %736 to <4 x i32>*
  %738 = load <4 x i32>, <4 x i32>* %737, align 16
  %739 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %738, i32 %695) #8
  store <4 x i32> %739, <4 x i32>* %737, align 16
  %740 = or i64 %734, 1
  %741 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 %740
  %742 = bitcast <2 x i64>* %741 to <4 x i32>*
  %743 = load <4 x i32>, <4 x i32>* %742, align 16
  %744 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %743, i32 %695) #8
  store <4 x i32> %744, <4 x i32>* %742, align 16
  %745 = or i64 %734, 2
  %746 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 %745
  %747 = bitcast <2 x i64>* %746 to <4 x i32>*
  %748 = load <4 x i32>, <4 x i32>* %747, align 16
  %749 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %748, i32 %695) #8
  store <4 x i32> %749, <4 x i32>* %747, align 16
  %750 = or i64 %734, 3
  %751 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 %750
  %752 = bitcast <2 x i64>* %751 to <4 x i32>*
  %753 = load <4 x i32>, <4 x i32>* %752, align 16
  %754 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %753, i32 %695) #8
  store <4 x i32> %754, <4 x i32>* %752, align 16
  %755 = add nuw nsw i64 %734, 4
  %756 = add i64 %735, -4
  %757 = icmp eq i64 %756, 0
  br i1 %757, label %771, label %733

758:                                              ; preds = %704, %699
  %759 = phi i64 [ 0, %699 ], [ %730, %704 ]
  br i1 %579, label %783, label %760

760:                                              ; preds = %758, %760
  %761 = phi i64 [ %768, %760 ], [ %759, %758 ]
  %762 = phi i64 [ %769, %760 ], [ %576, %758 ]
  %763 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 %761
  %764 = bitcast <2 x i64>* %763 to <4 x i32>*
  %765 = load <4 x i32>, <4 x i32>* %764, align 16
  %766 = add <4 x i32> %765, %703
  %767 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %766, i32 %696) #8
  store <4 x i32> %767, <4 x i32>* %764, align 16
  %768 = add nuw nsw i64 %761, 1
  %769 = add i64 %762, -1
  %770 = icmp eq i64 %769, 0
  br i1 %770, label %783, label %760, !llvm.loop !5

771:                                              ; preds = %733, %698
  %772 = phi i64 [ 0, %698 ], [ %755, %733 ]
  br i1 %575, label %783, label %773

773:                                              ; preds = %771, %773
  %774 = phi i64 [ %780, %773 ], [ %772, %771 ]
  %775 = phi i64 [ %781, %773 ], [ %572, %771 ]
  %776 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 %774
  %777 = bitcast <2 x i64>* %776 to <4 x i32>*
  %778 = load <4 x i32>, <4 x i32>* %777, align 16
  %779 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %778, i32 %695) #8
  store <4 x i32> %779, <4 x i32>* %777, align 16
  %780 = add nuw nsw i64 %774, 1
  %781 = add i64 %775, -1
  %782 = icmp eq i64 %781, 0
  br i1 %782, label %783, label %773, !llvm.loop !6

783:                                              ; preds = %771, %773, %758, %760
  %784 = add nuw nsw i64 %691, 1
  %785 = icmp slt i64 %784, %570
  br i1 %785, label %690, label %670

786:                                              ; preds = %831, %674
  %787 = phi i64 [ 0, %674 ], [ %832, %831 ]
  %788 = trunc i64 %787 to i32
  %789 = mul i32 %676, %788
  %790 = sext i32 %789 to i64
  %791 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %790
  %792 = shl nsw i64 %787, 3
  %793 = getelementptr inbounds i16, i16* %462, i64 %792
  br label %794

794:                                              ; preds = %794, %786
  %795 = phi i64 [ 0, %786 ], [ %828, %794 ]
  %796 = phi i64 [ %685, %786 ], [ %829, %794 ]
  %797 = mul nsw i64 %795, %687
  %798 = getelementptr inbounds i16, i16* %793, i64 %797
  %799 = bitcast i16* %798 to <2 x i64>*
  %800 = load <2 x i64>, <2 x i64>* %799, align 2
  %801 = getelementptr inbounds <2 x i64>, <2 x i64>* %791, i64 %796
  %802 = bitcast <2 x i64>* %801 to <4 x i32>*
  %803 = load <4 x i32>, <4 x i32>* %802, align 16
  %804 = add nsw i64 %796, %686
  %805 = getelementptr inbounds <2 x i64>, <2 x i64>* %791, i64 %804
  %806 = bitcast <2 x i64>* %805 to <4 x i32>*
  %807 = load <4 x i32>, <4 x i32>* %806, align 16
  %808 = bitcast <2 x i64> %800 to <8 x i16>
  %809 = shufflevector <8 x i16> %808, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %810 = sext <4 x i16> %809 to <4 x i32>
  %811 = bitcast <2 x i64> %800 to <16 x i8>
  %812 = shufflevector <16 x i8> %811, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %813 = bitcast <16 x i8> %812 to <8 x i16>
  %814 = shufflevector <8 x i16> %813, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %815 = sext <4 x i16> %814 to <4 x i32>
  %816 = add <4 x i32> %803, %810
  %817 = add <4 x i32> %807, %815
  %818 = icmp sgt <4 x i32> %816, zeroinitializer
  %819 = select <4 x i1> %818, <4 x i32> %816, <4 x i32> zeroinitializer
  %820 = icmp slt <4 x i32> %819, %684
  %821 = select <4 x i1> %820, <4 x i32> %819, <4 x i32> %684
  %822 = icmp sgt <4 x i32> %817, zeroinitializer
  %823 = select <4 x i1> %822, <4 x i32> %817, <4 x i32> zeroinitializer
  %824 = icmp slt <4 x i32> %823, %684
  %825 = select <4 x i1> %824, <4 x i32> %823, <4 x i32> %684
  %826 = call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %821, <4 x i32> %825) #8
  %827 = bitcast i16* %798 to <8 x i16>*
  store <8 x i16> %826, <8 x i16>* %827, align 2
  %828 = add nuw nsw i64 %795, 1
  %829 = add i64 %796, %678
  %830 = icmp eq i64 %828, %688
  br i1 %830, label %831, label %794

831:                                              ; preds = %794
  %832 = add nuw nsw i64 %787, 1
  %833 = icmp slt i64 %832, %689
  br i1 %833, label %786, label %834

834:                                              ; preds = %831, %670
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %463) #8
  br label %1606

835:                                              ; preds = %7, %7, %7
  %836 = ptrtoint i8* %1 to i64
  %837 = shl i64 %836, 1
  %838 = inttoptr i64 %837 to i16*
  %839 = bitcast [64 x <2 x i64>]* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %839) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %839, i8 -86, i64 1024, i1 false) #8
  %840 = zext i8 %4 to i64
  %841 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide, i64 0, i64 %840
  %842 = load i32, i32* %841, align 4
  %843 = icmp slt i32 %842, 32
  %844 = select i1 %843, i32 %842, i32 32
  %845 = icmp sgt i32 %844, %5
  br i1 %845, label %848, label %846

846:                                              ; preds = %835
  %847 = add nsw i32 %844, -1
  br label %853

848:                                              ; preds = %835
  %849 = add nsw i32 %5, -1
  %850 = sext i32 %849 to i64
  %851 = getelementptr inbounds [32 x i32], [32 x i32]* @eob_fill, i64 0, i64 %850
  %852 = load i32, i32* %851, align 4
  br label %853

853:                                              ; preds = %848, %846
  %854 = phi i32 [ %847, %846 ], [ %852, %848 ]
  %855 = getelementptr inbounds [19 x i8*], [19 x i8*]* @av1_inv_txfm_shift_ls, i64 0, i64 %840
  %856 = load i8*, i8** %855, align 8
  %857 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide_log2, i64 0, i64 %840
  %858 = load i32, i32* %857, align 4
  %859 = add nsw i32 %858, -2
  %860 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high_log2, i64 0, i64 %840
  %861 = load i32, i32* %860, align 4
  %862 = add nsw i32 %861, -2
  %863 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high, i64 0, i64 %840
  %864 = load i32, i32* %863, align 4
  %865 = ashr i32 %844, 2
  %866 = icmp slt i32 %864, 32
  %867 = select i1 %866, i32 %864, i32 32
  %868 = add nsw i32 %854, 8
  %869 = ashr i32 %868, 3
  %870 = icmp eq i32 %842, %864
  br i1 %870, label %886, label %871

871:                                              ; preds = %853
  %872 = icmp sgt i32 %842, %864
  br i1 %872, label %873, label %879

873:                                              ; preds = %871
  %874 = shl nsw i32 %864, 1
  %875 = icmp eq i32 %874, %842
  br i1 %875, label %886, label %876

876:                                              ; preds = %873
  %877 = shl nsw i32 %864, 2
  %878 = icmp eq i32 %877, %842
  br i1 %878, label %886, label %885

879:                                              ; preds = %871
  %880 = shl nsw i32 %842, 1
  %881 = icmp eq i32 %880, %864
  br i1 %881, label %886, label %882

882:                                              ; preds = %879
  %883 = shl nsw i32 %842, 2
  %884 = icmp eq i32 %883, %864
  br i1 %884, label %886, label %885

885:                                              ; preds = %882, %876
  br label %886

886:                                              ; preds = %885, %882, %879, %876, %873, %853
  %887 = phi i32 [ 0, %885 ], [ 0, %853 ], [ 1, %873 ], [ 2, %876 ], [ -1, %879 ], [ -2, %882 ]
  %888 = sext i32 %854 to i64
  %889 = getelementptr inbounds [32 x i32], [32 x i32]* @lowbd_txfm_all_1d_zeros_idx, i64 0, i64 %888
  %890 = load i32, i32* %889, align 4
  %891 = sext i32 %859 to i64
  %892 = zext i8 %3 to i64
  %893 = getelementptr inbounds [16 x i8], [16 x i8]* @hitx_1d_tab, i64 0, i64 %892
  %894 = load i8, i8* %893, align 1
  %895 = zext i8 %894 to i64
  %896 = sext i32 %890 to i64
  %897 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %891, i64 %895, i64 %896
  %898 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %897, align 8
  %899 = sext i32 %862 to i64
  %900 = getelementptr inbounds [16 x i8], [16 x i8]* @vitx_1d_tab, i64 0, i64 %892
  %901 = load i8, i8* %900, align 1
  %902 = zext i8 %901 to i64
  %903 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %899, i64 %902, i64 0
  %904 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %903, align 16
  switch i8 %3, label %907 [
    i8 14, label %905
    i8 15, label %906
  ]

905:                                              ; preds = %886
  br label %907

906:                                              ; preds = %886
  br label %907

907:                                              ; preds = %906, %905, %886
  %908 = phi i32 [ 0, %906 ], [ 1, %905 ], [ 0, %886 ]
  %909 = phi i32 [ 1, %906 ], [ 0, %905 ], [ 0, %886 ]
  %910 = icmp sgt i32 %867, 3
  br i1 %910, label %911, label %933

911:                                              ; preds = %907
  %912 = lshr i32 %867, 2
  %913 = bitcast [16 x <2 x i64>]* %10 to i8*
  %914 = shl i32 %844, 2
  %915 = shl nsw i32 %869, 1
  %916 = icmp sgt i32 %868, 7
  %917 = sext i32 %844 to i64
  %918 = and i32 %868, -8
  %919 = icmp sgt i32 %918, 0
  %920 = zext i32 %918 to i64
  %921 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 0
  %922 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 %891, i64 %899
  %923 = load i8, i8* %922, align 1
  %924 = sext i8 %923 to i32
  %925 = icmp eq i32 %909, 0
  %926 = icmp sgt i32 %844, 3
  %927 = sext i32 %915 to i64
  %928 = sext i32 %865 to i64
  %929 = sext i32 %864 to i64
  %930 = zext i32 %912 to i64
  %931 = shl nsw i64 %917, 1
  %932 = mul nsw i64 %917, 3
  br label %952

933:                                              ; preds = %1100, %907
  %934 = icmp sgt i32 %844, 3
  br i1 %934, label %935, label %1103

935:                                              ; preds = %933
  %936 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 %891, i64 %899
  %937 = load i8, i8* %936, align 1
  %938 = sext i8 %937 to i32
  %939 = getelementptr inbounds i8, i8* %856, i64 1
  %940 = zext i32 %864 to i64
  %941 = sext i32 %864 to i64
  %942 = sext i32 %865 to i64
  %943 = add nsw i64 %940, -1
  %944 = and i64 %940, 3
  %945 = icmp ult i64 %943, 3
  %946 = sub nsw i64 %940, %944
  %947 = icmp eq i64 %944, 0
  %948 = and i64 %940, 3
  %949 = icmp ult i64 %943, 3
  %950 = sub nsw i64 %940, %948
  %951 = icmp eq i64 %948, 0
  br label %1123

952:                                              ; preds = %1100, %911
  %953 = phi i64 [ 0, %911 ], [ %1101, %1100 ]
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %913) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %913, i8 -86, i64 256, i1 false) #8
  %954 = trunc i64 %953 to i32
  %955 = mul i32 %914, %954
  %956 = sext i32 %955 to i64
  %957 = getelementptr inbounds i32, i32* %0, i64 %956
  br i1 %916, label %959, label %958

958:                                              ; preds = %959, %952
  switch i32 %887, label %1010 [
    i32 -1, label %992
    i32 1, label %992
  ]

959:                                              ; preds = %952, %959
  %960 = phi i64 [ %990, %959 ], [ 0, %952 ]
  %961 = shl nsw i64 %960, 2
  %962 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %961
  %963 = getelementptr inbounds i32, i32* %957, i64 %961
  %964 = bitcast i32* %963 to <4 x i32>*
  %965 = load <4 x i32>, <4 x i32>* %964, align 1
  %966 = getelementptr inbounds i32, i32* %963, i64 %917
  %967 = bitcast i32* %966 to <4 x i32>*
  %968 = load <4 x i32>, <4 x i32>* %967, align 1
  %969 = getelementptr inbounds <2 x i64>, <2 x i64>* %962, i64 1
  %970 = getelementptr inbounds i32, i32* %963, i64 %931
  %971 = bitcast i32* %970 to <4 x i32>*
  %972 = load <4 x i32>, <4 x i32>* %971, align 1
  %973 = getelementptr inbounds <2 x i64>, <2 x i64>* %962, i64 2
  %974 = getelementptr inbounds i32, i32* %963, i64 %932
  %975 = bitcast i32* %974 to <4 x i32>*
  %976 = load <4 x i32>, <4 x i32>* %975, align 1
  %977 = getelementptr inbounds <2 x i64>, <2 x i64>* %962, i64 3
  %978 = shufflevector <4 x i32> %965, <4 x i32> %968, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %979 = bitcast <4 x i32> %978 to <2 x i64>
  %980 = shufflevector <4 x i32> %965, <4 x i32> %968, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %981 = bitcast <4 x i32> %980 to <2 x i64>
  %982 = shufflevector <4 x i32> %972, <4 x i32> %976, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %983 = bitcast <4 x i32> %982 to <2 x i64>
  %984 = shufflevector <4 x i32> %972, <4 x i32> %976, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %985 = bitcast <4 x i32> %984 to <2 x i64>
  %986 = shufflevector <2 x i64> %979, <2 x i64> %983, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %986, <2 x i64>* %962, align 16
  %987 = shufflevector <2 x i64> %979, <2 x i64> %983, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %987, <2 x i64>* %969, align 16
  %988 = shufflevector <2 x i64> %981, <2 x i64> %985, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %988, <2 x i64>* %973, align 16
  %989 = shufflevector <2 x i64> %981, <2 x i64> %985, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %989, <2 x i64>* %977, align 16
  %990 = add nuw nsw i64 %960, 1
  %991 = icmp slt i64 %990, %927
  br i1 %991, label %959, label %958

992:                                              ; preds = %958, %958
  br i1 %919, label %993, label %1010

993:                                              ; preds = %992, %993
  %994 = phi i64 [ %1008, %993 ], [ 0, %992 ]
  %995 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %994
  %996 = bitcast <2 x i64>* %995 to <4 x i32>*
  %997 = load <4 x i32>, <4 x i32>* %996, align 16
  %998 = mul <4 x i32> %997, <i32 2896, i32 2896, i32 2896, i32 2896>
  %999 = add <4 x i32> %998, <i32 2048, i32 2048, i32 2048, i32 2048>
  %1000 = ashr <4 x i32> %999, <i32 12, i32 12, i32 12, i32 12>
  store <4 x i32> %1000, <4 x i32>* %996, align 16
  %1001 = or i64 %994, 1
  %1002 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %1001
  %1003 = bitcast <2 x i64>* %1002 to <4 x i32>*
  %1004 = load <4 x i32>, <4 x i32>* %1003, align 16
  %1005 = mul <4 x i32> %1004, <i32 2896, i32 2896, i32 2896, i32 2896>
  %1006 = add <4 x i32> %1005, <i32 2048, i32 2048, i32 2048, i32 2048>
  %1007 = ashr <4 x i32> %1006, <i32 12, i32 12, i32 12, i32 12>
  store <4 x i32> %1007, <4 x i32>* %1003, align 16
  %1008 = add nuw nsw i64 %994, 2
  %1009 = icmp eq i64 %1008, %920
  br i1 %1009, label %1010, label %993

1010:                                             ; preds = %993, %992, %958
  %1011 = load i8, i8* %856, align 1
  %1012 = sext i8 %1011 to i32
  %1013 = sub nsw i32 0, %1012
  call void %898(<2 x i64>* nonnull %921, <2 x i64>* nonnull %921, i32 %924, i32 0, i32 %6, i32 %1013) #8
  %1014 = shl nsw i64 %953, 2
  %1015 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1014
  br i1 %925, label %1017, label %1016

1016:                                             ; preds = %1010
  br i1 %926, label %1018, label %1100

1017:                                             ; preds = %1010
  br i1 %926, label %1060, label %1100

1018:                                             ; preds = %1016, %1018
  %1019 = phi i64 [ %1058, %1018 ], [ 0, %1016 ]
  %1020 = shl nsw i64 %1019, 2
  %1021 = or i64 %1020, 3
  %1022 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %1021
  %1023 = bitcast <2 x i64>* %1022 to <4 x i32>*
  %1024 = load <4 x i32>, <4 x i32>* %1023, align 16
  %1025 = or i64 %1020, 2
  %1026 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %1025
  %1027 = bitcast <2 x i64>* %1026 to <4 x i32>*
  %1028 = load <4 x i32>, <4 x i32>* %1027, align 16
  %1029 = shufflevector <4 x i32> %1024, <4 x i32> %1028, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1030 = bitcast <4 x i32> %1029 to <2 x i64>
  %1031 = shufflevector <4 x i32> %1024, <4 x i32> %1028, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1032 = bitcast <4 x i32> %1031 to <2 x i64>
  %1033 = or i64 %1020, 1
  %1034 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %1033
  %1035 = bitcast <2 x i64>* %1034 to <4 x i32>*
  %1036 = load <4 x i32>, <4 x i32>* %1035, align 16
  %1037 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %1020
  %1038 = bitcast <2 x i64>* %1037 to <4 x i32>*
  %1039 = load <4 x i32>, <4 x i32>* %1038, align 16
  %1040 = shufflevector <4 x i32> %1036, <4 x i32> %1039, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1041 = bitcast <4 x i32> %1040 to <2 x i64>
  %1042 = shufflevector <4 x i32> %1036, <4 x i32> %1039, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1043 = bitcast <4 x i32> %1042 to <2 x i64>
  %1044 = shufflevector <2 x i64> %1030, <2 x i64> %1041, <2 x i32> <i32 0, i32 2>
  %1045 = xor i64 %1019, -1
  %1046 = add nsw i64 %1045, %928
  %1047 = mul nsw i64 %1046, %929
  %1048 = getelementptr inbounds <2 x i64>, <2 x i64>* %1015, i64 %1047
  store <2 x i64> %1044, <2 x i64>* %1048, align 16
  %1049 = shufflevector <2 x i64> %1030, <2 x i64> %1041, <2 x i32> <i32 1, i32 3>
  %1050 = add nsw i64 %1047, 1
  %1051 = getelementptr inbounds <2 x i64>, <2 x i64>* %1015, i64 %1050
  store <2 x i64> %1049, <2 x i64>* %1051, align 16
  %1052 = shufflevector <2 x i64> %1032, <2 x i64> %1043, <2 x i32> <i32 0, i32 2>
  %1053 = add nsw i64 %1047, 2
  %1054 = getelementptr inbounds <2 x i64>, <2 x i64>* %1015, i64 %1053
  store <2 x i64> %1052, <2 x i64>* %1054, align 16
  %1055 = shufflevector <2 x i64> %1032, <2 x i64> %1043, <2 x i32> <i32 1, i32 3>
  %1056 = add nsw i64 %1047, 3
  %1057 = getelementptr inbounds <2 x i64>, <2 x i64>* %1015, i64 %1056
  store <2 x i64> %1055, <2 x i64>* %1057, align 16
  %1058 = add nuw nsw i64 %1019, 1
  %1059 = icmp slt i64 %1058, %928
  br i1 %1059, label %1018, label %1100

1060:                                             ; preds = %1017, %1060
  %1061 = phi i64 [ %1098, %1060 ], [ 0, %1017 ]
  %1062 = shl nsw i64 %1061, 2
  %1063 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %1062
  %1064 = bitcast <2 x i64>* %1063 to <4 x i32>*
  %1065 = load <4 x i32>, <4 x i32>* %1064, align 16
  %1066 = or i64 %1062, 1
  %1067 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %1066
  %1068 = bitcast <2 x i64>* %1067 to <4 x i32>*
  %1069 = load <4 x i32>, <4 x i32>* %1068, align 16
  %1070 = shufflevector <4 x i32> %1065, <4 x i32> %1069, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1071 = bitcast <4 x i32> %1070 to <2 x i64>
  %1072 = shufflevector <4 x i32> %1065, <4 x i32> %1069, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1073 = bitcast <4 x i32> %1072 to <2 x i64>
  %1074 = or i64 %1062, 2
  %1075 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %1074
  %1076 = bitcast <2 x i64>* %1075 to <4 x i32>*
  %1077 = load <4 x i32>, <4 x i32>* %1076, align 16
  %1078 = or i64 %1062, 3
  %1079 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %10, i64 0, i64 %1078
  %1080 = bitcast <2 x i64>* %1079 to <4 x i32>*
  %1081 = load <4 x i32>, <4 x i32>* %1080, align 16
  %1082 = shufflevector <4 x i32> %1077, <4 x i32> %1081, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1083 = bitcast <4 x i32> %1082 to <2 x i64>
  %1084 = shufflevector <4 x i32> %1077, <4 x i32> %1081, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1085 = bitcast <4 x i32> %1084 to <2 x i64>
  %1086 = shufflevector <2 x i64> %1071, <2 x i64> %1083, <2 x i32> <i32 0, i32 2>
  %1087 = mul nsw i64 %1061, %929
  %1088 = getelementptr inbounds <2 x i64>, <2 x i64>* %1015, i64 %1087
  store <2 x i64> %1086, <2 x i64>* %1088, align 16
  %1089 = shufflevector <2 x i64> %1071, <2 x i64> %1083, <2 x i32> <i32 1, i32 3>
  %1090 = add nsw i64 %1087, 1
  %1091 = getelementptr inbounds <2 x i64>, <2 x i64>* %1015, i64 %1090
  store <2 x i64> %1089, <2 x i64>* %1091, align 16
  %1092 = shufflevector <2 x i64> %1073, <2 x i64> %1085, <2 x i32> <i32 0, i32 2>
  %1093 = add nsw i64 %1087, 2
  %1094 = getelementptr inbounds <2 x i64>, <2 x i64>* %1015, i64 %1093
  store <2 x i64> %1092, <2 x i64>* %1094, align 16
  %1095 = shufflevector <2 x i64> %1073, <2 x i64> %1085, <2 x i32> <i32 1, i32 3>
  %1096 = add nsw i64 %1087, 3
  %1097 = getelementptr inbounds <2 x i64>, <2 x i64>* %1015, i64 %1096
  store <2 x i64> %1095, <2 x i64>* %1097, align 16
  %1098 = add nuw nsw i64 %1061, 1
  %1099 = icmp slt i64 %1098, %928
  br i1 %1099, label %1060, label %1100

1100:                                             ; preds = %1018, %1060, %1017, %1016
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %913) #8
  %1101 = add nuw nsw i64 %953, 1
  %1102 = icmp ult i64 %1101, %930
  br i1 %1102, label %952, label %933

1103:                                             ; preds = %1216, %933
  %1104 = lshr i64 516062, %840
  %1105 = and i64 %1104, 1
  %1106 = icmp eq i64 %1105, 0
  br i1 %1106, label %1267, label %1107

1107:                                             ; preds = %1103
  %1108 = ashr i32 %842, 3
  %1109 = shl i32 %864, 1
  %1110 = icmp ne i32 %908, 0
  %1111 = select i1 %1110, i64 -1, i64 1
  %1112 = add nsw i32 %864, -1
  %1113 = select i1 %1110, i32 %1112, i32 0
  %1114 = shl nsw i32 -1, %6
  %1115 = xor i32 %1114, -1
  %1116 = insertelement <4 x i32> undef, i32 %1115, i32 0
  %1117 = shufflevector <4 x i32> %1116, <4 x i32> undef, <4 x i32> zeroinitializer
  %1118 = sext i32 %1113 to i64
  %1119 = sext i32 %864 to i64
  %1120 = sext i32 %2 to i64
  %1121 = zext i32 %864 to i64
  %1122 = sext i32 %1108 to i64
  br label %1219

1123:                                             ; preds = %1216, %935
  %1124 = phi i64 [ 0, %935 ], [ %1217, %1216 ]
  %1125 = mul nsw i64 %1124, %941
  %1126 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1125
  call void %904(<2 x i64>* %1126, <2 x i64>* %1126, i32 %938, i32 1, i32 %6, i32 0) #8
  %1127 = load i8, i8* %939, align 1
  %1128 = sext i8 %1127 to i32
  %1129 = sub nsw i32 0, %1128
  %1130 = icmp slt i8 %1127, 0
  br i1 %1130, label %1132, label %1131

1131:                                             ; preds = %1123
  br i1 %945, label %1204, label %1166

1132:                                             ; preds = %1123
  %1133 = xor i32 %1128, -1
  %1134 = shl i32 1, %1133
  %1135 = insertelement <4 x i32> undef, i32 %1134, i32 0
  %1136 = shufflevector <4 x i32> %1135, <4 x i32> undef, <4 x i32> zeroinitializer
  br i1 %949, label %1191, label %1137

1137:                                             ; preds = %1132, %1137
  %1138 = phi i64 [ %1163, %1137 ], [ 0, %1132 ]
  %1139 = phi i64 [ %1164, %1137 ], [ %950, %1132 ]
  %1140 = getelementptr inbounds <2 x i64>, <2 x i64>* %1126, i64 %1138
  %1141 = bitcast <2 x i64>* %1140 to <4 x i32>*
  %1142 = load <4 x i32>, <4 x i32>* %1141, align 16
  %1143 = add <4 x i32> %1142, %1136
  %1144 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1143, i32 %1129) #8
  store <4 x i32> %1144, <4 x i32>* %1141, align 16
  %1145 = or i64 %1138, 1
  %1146 = getelementptr inbounds <2 x i64>, <2 x i64>* %1126, i64 %1145
  %1147 = bitcast <2 x i64>* %1146 to <4 x i32>*
  %1148 = load <4 x i32>, <4 x i32>* %1147, align 16
  %1149 = add <4 x i32> %1148, %1136
  %1150 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1149, i32 %1129) #8
  store <4 x i32> %1150, <4 x i32>* %1147, align 16
  %1151 = or i64 %1138, 2
  %1152 = getelementptr inbounds <2 x i64>, <2 x i64>* %1126, i64 %1151
  %1153 = bitcast <2 x i64>* %1152 to <4 x i32>*
  %1154 = load <4 x i32>, <4 x i32>* %1153, align 16
  %1155 = add <4 x i32> %1154, %1136
  %1156 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1155, i32 %1129) #8
  store <4 x i32> %1156, <4 x i32>* %1153, align 16
  %1157 = or i64 %1138, 3
  %1158 = getelementptr inbounds <2 x i64>, <2 x i64>* %1126, i64 %1157
  %1159 = bitcast <2 x i64>* %1158 to <4 x i32>*
  %1160 = load <4 x i32>, <4 x i32>* %1159, align 16
  %1161 = add <4 x i32> %1160, %1136
  %1162 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1161, i32 %1129) #8
  store <4 x i32> %1162, <4 x i32>* %1159, align 16
  %1163 = add nuw nsw i64 %1138, 4
  %1164 = add i64 %1139, -4
  %1165 = icmp eq i64 %1164, 0
  br i1 %1165, label %1191, label %1137

1166:                                             ; preds = %1131, %1166
  %1167 = phi i64 [ %1188, %1166 ], [ 0, %1131 ]
  %1168 = phi i64 [ %1189, %1166 ], [ %946, %1131 ]
  %1169 = getelementptr inbounds <2 x i64>, <2 x i64>* %1126, i64 %1167
  %1170 = bitcast <2 x i64>* %1169 to <4 x i32>*
  %1171 = load <4 x i32>, <4 x i32>* %1170, align 16
  %1172 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %1171, i32 %1128) #8
  store <4 x i32> %1172, <4 x i32>* %1170, align 16
  %1173 = or i64 %1167, 1
  %1174 = getelementptr inbounds <2 x i64>, <2 x i64>* %1126, i64 %1173
  %1175 = bitcast <2 x i64>* %1174 to <4 x i32>*
  %1176 = load <4 x i32>, <4 x i32>* %1175, align 16
  %1177 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %1176, i32 %1128) #8
  store <4 x i32> %1177, <4 x i32>* %1175, align 16
  %1178 = or i64 %1167, 2
  %1179 = getelementptr inbounds <2 x i64>, <2 x i64>* %1126, i64 %1178
  %1180 = bitcast <2 x i64>* %1179 to <4 x i32>*
  %1181 = load <4 x i32>, <4 x i32>* %1180, align 16
  %1182 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %1181, i32 %1128) #8
  store <4 x i32> %1182, <4 x i32>* %1180, align 16
  %1183 = or i64 %1167, 3
  %1184 = getelementptr inbounds <2 x i64>, <2 x i64>* %1126, i64 %1183
  %1185 = bitcast <2 x i64>* %1184 to <4 x i32>*
  %1186 = load <4 x i32>, <4 x i32>* %1185, align 16
  %1187 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %1186, i32 %1128) #8
  store <4 x i32> %1187, <4 x i32>* %1185, align 16
  %1188 = add nuw nsw i64 %1167, 4
  %1189 = add i64 %1168, -4
  %1190 = icmp eq i64 %1189, 0
  br i1 %1190, label %1204, label %1166

1191:                                             ; preds = %1137, %1132
  %1192 = phi i64 [ 0, %1132 ], [ %1163, %1137 ]
  br i1 %951, label %1216, label %1193

1193:                                             ; preds = %1191, %1193
  %1194 = phi i64 [ %1201, %1193 ], [ %1192, %1191 ]
  %1195 = phi i64 [ %1202, %1193 ], [ %948, %1191 ]
  %1196 = getelementptr inbounds <2 x i64>, <2 x i64>* %1126, i64 %1194
  %1197 = bitcast <2 x i64>* %1196 to <4 x i32>*
  %1198 = load <4 x i32>, <4 x i32>* %1197, align 16
  %1199 = add <4 x i32> %1198, %1136
  %1200 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1199, i32 %1129) #8
  store <4 x i32> %1200, <4 x i32>* %1197, align 16
  %1201 = add nuw nsw i64 %1194, 1
  %1202 = add i64 %1195, -1
  %1203 = icmp eq i64 %1202, 0
  br i1 %1203, label %1216, label %1193, !llvm.loop !7

1204:                                             ; preds = %1166, %1131
  %1205 = phi i64 [ 0, %1131 ], [ %1188, %1166 ]
  br i1 %947, label %1216, label %1206

1206:                                             ; preds = %1204, %1206
  %1207 = phi i64 [ %1213, %1206 ], [ %1205, %1204 ]
  %1208 = phi i64 [ %1214, %1206 ], [ %944, %1204 ]
  %1209 = getelementptr inbounds <2 x i64>, <2 x i64>* %1126, i64 %1207
  %1210 = bitcast <2 x i64>* %1209 to <4 x i32>*
  %1211 = load <4 x i32>, <4 x i32>* %1210, align 16
  %1212 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %1211, i32 %1128) #8
  store <4 x i32> %1212, <4 x i32>* %1210, align 16
  %1213 = add nuw nsw i64 %1207, 1
  %1214 = add i64 %1208, -1
  %1215 = icmp eq i64 %1214, 0
  br i1 %1215, label %1216, label %1206, !llvm.loop !8

1216:                                             ; preds = %1204, %1206, %1191, %1193
  %1217 = add nuw nsw i64 %1124, 1
  %1218 = icmp slt i64 %1217, %942
  br i1 %1218, label %1123, label %1103

1219:                                             ; preds = %1264, %1107
  %1220 = phi i64 [ 0, %1107 ], [ %1265, %1264 ]
  %1221 = trunc i64 %1220 to i32
  %1222 = mul i32 %1109, %1221
  %1223 = sext i32 %1222 to i64
  %1224 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1223
  %1225 = shl nsw i64 %1220, 3
  %1226 = getelementptr inbounds i16, i16* %838, i64 %1225
  br label %1227

1227:                                             ; preds = %1227, %1219
  %1228 = phi i64 [ 0, %1219 ], [ %1261, %1227 ]
  %1229 = phi i64 [ %1118, %1219 ], [ %1262, %1227 ]
  %1230 = mul nsw i64 %1228, %1120
  %1231 = getelementptr inbounds i16, i16* %1226, i64 %1230
  %1232 = bitcast i16* %1231 to <2 x i64>*
  %1233 = load <2 x i64>, <2 x i64>* %1232, align 2
  %1234 = getelementptr inbounds <2 x i64>, <2 x i64>* %1224, i64 %1229
  %1235 = bitcast <2 x i64>* %1234 to <4 x i32>*
  %1236 = load <4 x i32>, <4 x i32>* %1235, align 16
  %1237 = add nsw i64 %1229, %1119
  %1238 = getelementptr inbounds <2 x i64>, <2 x i64>* %1224, i64 %1237
  %1239 = bitcast <2 x i64>* %1238 to <4 x i32>*
  %1240 = load <4 x i32>, <4 x i32>* %1239, align 16
  %1241 = bitcast <2 x i64> %1233 to <8 x i16>
  %1242 = shufflevector <8 x i16> %1241, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1243 = sext <4 x i16> %1242 to <4 x i32>
  %1244 = bitcast <2 x i64> %1233 to <16 x i8>
  %1245 = shufflevector <16 x i8> %1244, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1246 = bitcast <16 x i8> %1245 to <8 x i16>
  %1247 = shufflevector <8 x i16> %1246, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1248 = sext <4 x i16> %1247 to <4 x i32>
  %1249 = add <4 x i32> %1236, %1243
  %1250 = add <4 x i32> %1240, %1248
  %1251 = icmp sgt <4 x i32> %1249, zeroinitializer
  %1252 = select <4 x i1> %1251, <4 x i32> %1249, <4 x i32> zeroinitializer
  %1253 = icmp slt <4 x i32> %1252, %1117
  %1254 = select <4 x i1> %1253, <4 x i32> %1252, <4 x i32> %1117
  %1255 = icmp sgt <4 x i32> %1250, zeroinitializer
  %1256 = select <4 x i1> %1255, <4 x i32> %1250, <4 x i32> zeroinitializer
  %1257 = icmp slt <4 x i32> %1256, %1117
  %1258 = select <4 x i1> %1257, <4 x i32> %1256, <4 x i32> %1117
  %1259 = call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1254, <4 x i32> %1258) #8
  %1260 = bitcast i16* %1231 to <8 x i16>*
  store <8 x i16> %1259, <8 x i16>* %1260, align 2
  %1261 = add nuw nsw i64 %1228, 1
  %1262 = add i64 %1229, %1111
  %1263 = icmp eq i64 %1261, %1121
  br i1 %1263, label %1264, label %1227

1264:                                             ; preds = %1227
  %1265 = add nuw nsw i64 %1220, 1
  %1266 = icmp slt i64 %1265, %1122
  br i1 %1266, label %1219, label %1267

1267:                                             ; preds = %1264, %1103
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %839) #8
  br label %1606

1268:                                             ; preds = %7
  %1269 = ptrtoint i8* %1 to i64
  %1270 = shl i64 %1269, 1
  %1271 = inttoptr i64 %1270 to i16*
  %1272 = bitcast [256 x <2 x i64>]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4096, i8* nonnull %1272) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %1272, i8 -86, i64 4096, i1 false) #8
  %1273 = zext i8 %4 to i64
  %1274 = getelementptr inbounds [19 x i8*], [19 x i8*]* @av1_inv_txfm_shift_ls, i64 0, i64 %1273
  %1275 = load i8*, i8** %1274, align 8
  %1276 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide_log2, i64 0, i64 %1273
  %1277 = load i32, i32* %1276, align 4
  %1278 = add nsw i32 %1277, -2
  %1279 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high_log2, i64 0, i64 %1273
  %1280 = load i32, i32* %1279, align 4
  %1281 = add nsw i32 %1280, -2
  %1282 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide, i64 0, i64 %1273
  %1283 = load i32, i32* %1282, align 4
  %1284 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high, i64 0, i64 %1273
  %1285 = load i32, i32* %1284, align 4
  %1286 = icmp slt i32 %1283, 32
  %1287 = select i1 %1286, i32 %1283, i32 32
  %1288 = icmp slt i32 %1285, 32
  %1289 = select i1 %1288, i32 %1285, i32 32
  %1290 = icmp eq i32 %1283, %1285
  br i1 %1290, label %1306, label %1291

1291:                                             ; preds = %1268
  %1292 = icmp sgt i32 %1283, %1285
  br i1 %1292, label %1293, label %1299

1293:                                             ; preds = %1291
  %1294 = shl nsw i32 %1285, 1
  %1295 = icmp eq i32 %1294, %1283
  br i1 %1295, label %1306, label %1296

1296:                                             ; preds = %1293
  %1297 = shl nsw i32 %1285, 2
  %1298 = icmp eq i32 %1297, %1283
  br i1 %1298, label %1306, label %1305

1299:                                             ; preds = %1291
  %1300 = shl nsw i32 %1283, 1
  %1301 = icmp eq i32 %1300, %1285
  br i1 %1301, label %1306, label %1302

1302:                                             ; preds = %1299
  %1303 = shl nsw i32 %1283, 2
  %1304 = icmp eq i32 %1303, %1285
  br i1 %1304, label %1306, label %1305

1305:                                             ; preds = %1302, %1296
  br label %1306

1306:                                             ; preds = %1305, %1302, %1299, %1296, %1293, %1268
  %1307 = phi i32 [ 0, %1305 ], [ 0, %1268 ], [ 1, %1293 ], [ 2, %1296 ], [ -1, %1299 ], [ -2, %1302 ]
  %1308 = sext i32 %1278 to i64
  %1309 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %1308, i64 2, i64 0
  %1310 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %1309, align 16
  %1311 = sext i32 %1281 to i64
  %1312 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %1311, i64 2, i64 0
  %1313 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %1312, align 16
  %1314 = icmp sgt i32 %1289, 3
  br i1 %1314, label %1317, label %1315

1315:                                             ; preds = %1306
  %1316 = ashr i32 %1287, 2
  br label %1338

1317:                                             ; preds = %1306
  %1318 = lshr i32 %1289, 2
  %1319 = bitcast [32 x <2 x i64>]* %9 to i8*
  %1320 = shl i32 %1287, 2
  %1321 = ashr i32 %1287, 2
  %1322 = icmp sgt i32 %1287, 3
  %1323 = sext i32 %1287 to i64
  %1324 = zext i32 %1287 to i64
  %1325 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 0
  %1326 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 %1308, i64 %1311
  %1327 = load i8, i8* %1326, align 1
  %1328 = sext i8 %1327 to i32
  %1329 = sext i32 %1321 to i64
  %1330 = sext i32 %1285 to i64
  %1331 = zext i32 %1318 to i64
  %1332 = shl nsw i64 %1323, 1
  %1333 = mul nsw i64 %1323, 3
  %1334 = and i64 %1324, 1
  %1335 = icmp eq i32 %1287, 1
  %1336 = sub nsw i64 %1324, %1334
  %1337 = icmp eq i64 %1334, 0
  br label %1358

1338:                                             ; preds = %1421, %1315
  %1339 = phi i32 [ %1316, %1315 ], [ %1321, %1421 ]
  %1340 = icmp sgt i32 %1287, 3
  br i1 %1340, label %1341, label %1448

1341:                                             ; preds = %1338
  %1342 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 %1308, i64 %1311
  %1343 = load i8, i8* %1342, align 1
  %1344 = sext i8 %1343 to i32
  %1345 = getelementptr inbounds i8, i8* %1275, i64 1
  %1346 = zext i32 %1285 to i64
  %1347 = sext i32 %1285 to i64
  %1348 = sext i32 %1339 to i64
  %1349 = add nsw i64 %1346, -1
  %1350 = and i64 %1346, 3
  %1351 = icmp ult i64 %1349, 3
  %1352 = sub nsw i64 %1346, %1350
  %1353 = icmp eq i64 %1350, 0
  %1354 = and i64 %1346, 3
  %1355 = icmp ult i64 %1349, 3
  %1356 = sub nsw i64 %1346, %1354
  %1357 = icmp eq i64 %1354, 0
  br label %1463

1358:                                             ; preds = %1421, %1317
  %1359 = phi i64 [ 0, %1317 ], [ %1422, %1421 ]
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %1319) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %1319, i8 -86, i64 512, i1 false) #8
  %1360 = trunc i64 %1359 to i32
  %1361 = mul i32 %1320, %1360
  %1362 = sext i32 %1361 to i64
  %1363 = getelementptr inbounds i32, i32* %0, i64 %1362
  br i1 %1322, label %1366, label %1364

1364:                                             ; preds = %1366, %1358
  switch i32 %1307, label %1415 [
    i32 -1, label %1365
    i32 1, label %1365
  ]

1365:                                             ; preds = %1364, %1364
  br i1 %1335, label %1406, label %1387

1366:                                             ; preds = %1358, %1366
  %1367 = phi i64 [ %1385, %1366 ], [ 0, %1358 ]
  %1368 = shl nsw i64 %1367, 2
  %1369 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 %1368
  %1370 = getelementptr inbounds i32, i32* %1363, i64 %1368
  %1371 = bitcast i32* %1370 to <2 x i64>*
  %1372 = load <2 x i64>, <2 x i64>* %1371, align 1
  store <2 x i64> %1372, <2 x i64>* %1369, align 16
  %1373 = getelementptr inbounds i32, i32* %1370, i64 %1323
  %1374 = bitcast i32* %1373 to <2 x i64>*
  %1375 = load <2 x i64>, <2 x i64>* %1374, align 1
  %1376 = getelementptr inbounds <2 x i64>, <2 x i64>* %1369, i64 1
  store <2 x i64> %1375, <2 x i64>* %1376, align 16
  %1377 = getelementptr inbounds i32, i32* %1370, i64 %1332
  %1378 = bitcast i32* %1377 to <2 x i64>*
  %1379 = load <2 x i64>, <2 x i64>* %1378, align 1
  %1380 = getelementptr inbounds <2 x i64>, <2 x i64>* %1369, i64 2
  store <2 x i64> %1379, <2 x i64>* %1380, align 16
  %1381 = getelementptr inbounds i32, i32* %1370, i64 %1333
  %1382 = bitcast i32* %1381 to <2 x i64>*
  %1383 = load <2 x i64>, <2 x i64>* %1382, align 1
  %1384 = getelementptr inbounds <2 x i64>, <2 x i64>* %1369, i64 3
  store <2 x i64> %1383, <2 x i64>* %1384, align 16
  %1385 = add nuw nsw i64 %1367, 1
  %1386 = icmp slt i64 %1385, %1329
  br i1 %1386, label %1366, label %1364

1387:                                             ; preds = %1365, %1387
  %1388 = phi i64 [ %1403, %1387 ], [ 0, %1365 ]
  %1389 = phi i64 [ %1404, %1387 ], [ %1336, %1365 ]
  %1390 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 %1388
  %1391 = bitcast <2 x i64>* %1390 to <4 x i32>*
  %1392 = load <4 x i32>, <4 x i32>* %1391, align 16
  %1393 = mul <4 x i32> %1392, <i32 2896, i32 2896, i32 2896, i32 2896>
  %1394 = add <4 x i32> %1393, <i32 2048, i32 2048, i32 2048, i32 2048>
  %1395 = ashr <4 x i32> %1394, <i32 12, i32 12, i32 12, i32 12>
  store <4 x i32> %1395, <4 x i32>* %1391, align 16
  %1396 = or i64 %1388, 1
  %1397 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 %1396
  %1398 = bitcast <2 x i64>* %1397 to <4 x i32>*
  %1399 = load <4 x i32>, <4 x i32>* %1398, align 16
  %1400 = mul <4 x i32> %1399, <i32 2896, i32 2896, i32 2896, i32 2896>
  %1401 = add <4 x i32> %1400, <i32 2048, i32 2048, i32 2048, i32 2048>
  %1402 = ashr <4 x i32> %1401, <i32 12, i32 12, i32 12, i32 12>
  store <4 x i32> %1402, <4 x i32>* %1398, align 16
  %1403 = add nuw nsw i64 %1388, 2
  %1404 = add i64 %1389, -2
  %1405 = icmp eq i64 %1404, 0
  br i1 %1405, label %1406, label %1387

1406:                                             ; preds = %1387, %1365
  %1407 = phi i64 [ 0, %1365 ], [ %1403, %1387 ]
  br i1 %1337, label %1415, label %1408

1408:                                             ; preds = %1406
  %1409 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 %1407
  %1410 = bitcast <2 x i64>* %1409 to <4 x i32>*
  %1411 = load <4 x i32>, <4 x i32>* %1410, align 16
  %1412 = mul <4 x i32> %1411, <i32 2896, i32 2896, i32 2896, i32 2896>
  %1413 = add <4 x i32> %1412, <i32 2048, i32 2048, i32 2048, i32 2048>
  %1414 = ashr <4 x i32> %1413, <i32 12, i32 12, i32 12, i32 12>
  store <4 x i32> %1414, <4 x i32>* %1410, align 16
  br label %1415

1415:                                             ; preds = %1408, %1406, %1364
  %1416 = load i8, i8* %1275, align 1
  %1417 = sext i8 %1416 to i32
  %1418 = sub nsw i32 0, %1417
  call void %1310(<2 x i64>* nonnull %1325, <2 x i64>* nonnull %1325, i32 %1328, i32 0, i32 %6, i32 %1418) #8
  %1419 = shl nsw i64 %1359, 2
  %1420 = getelementptr inbounds [256 x <2 x i64>], [256 x <2 x i64>]* %8, i64 0, i64 %1419
  br i1 %1322, label %1424, label %1421

1421:                                             ; preds = %1424, %1415
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %1319) #8
  %1422 = add nuw nsw i64 %1359, 1
  %1423 = icmp ult i64 %1422, %1331
  br i1 %1423, label %1358, label %1338

1424:                                             ; preds = %1415, %1424
  %1425 = phi i64 [ %1446, %1424 ], [ 0, %1415 ]
  %1426 = shl nsw i64 %1425, 2
  %1427 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 %1426
  %1428 = load <2 x i64>, <2 x i64>* %1427, align 16
  %1429 = mul nsw i64 %1425, %1330
  %1430 = getelementptr inbounds <2 x i64>, <2 x i64>* %1420, i64 %1429
  store <2 x i64> %1428, <2 x i64>* %1430, align 16
  %1431 = or i64 %1426, 1
  %1432 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 %1431
  %1433 = load <2 x i64>, <2 x i64>* %1432, align 16
  %1434 = add nsw i64 %1429, 1
  %1435 = getelementptr inbounds <2 x i64>, <2 x i64>* %1420, i64 %1434
  store <2 x i64> %1433, <2 x i64>* %1435, align 16
  %1436 = or i64 %1426, 2
  %1437 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 %1436
  %1438 = load <2 x i64>, <2 x i64>* %1437, align 16
  %1439 = add nsw i64 %1429, 2
  %1440 = getelementptr inbounds <2 x i64>, <2 x i64>* %1420, i64 %1439
  store <2 x i64> %1438, <2 x i64>* %1440, align 16
  %1441 = or i64 %1426, 3
  %1442 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 %1441
  %1443 = load <2 x i64>, <2 x i64>* %1442, align 16
  %1444 = add nsw i64 %1429, 3
  %1445 = getelementptr inbounds <2 x i64>, <2 x i64>* %1420, i64 %1444
  store <2 x i64> %1443, <2 x i64>* %1445, align 16
  %1446 = add nuw nsw i64 %1425, 1
  %1447 = icmp slt i64 %1446, %1329
  br i1 %1447, label %1424, label %1421

1448:                                             ; preds = %1556, %1338
  %1449 = lshr i64 516062, %1273
  %1450 = and i64 %1449, 1
  %1451 = icmp eq i64 %1450, 0
  br i1 %1451, label %1605, label %1452

1452:                                             ; preds = %1448
  %1453 = ashr i32 %1283, 3
  %1454 = shl i32 %1285, 1
  %1455 = shl nsw i32 -1, %6
  %1456 = xor i32 %1455, -1
  %1457 = insertelement <4 x i32> undef, i32 %1456, i32 0
  %1458 = shufflevector <4 x i32> %1457, <4 x i32> undef, <4 x i32> zeroinitializer
  %1459 = sext i32 %1285 to i64
  %1460 = sext i32 %2 to i64
  %1461 = zext i32 %1285 to i64
  %1462 = sext i32 %1453 to i64
  br label %1559

1463:                                             ; preds = %1556, %1341
  %1464 = phi i64 [ 0, %1341 ], [ %1557, %1556 ]
  %1465 = mul nsw i64 %1464, %1347
  %1466 = getelementptr inbounds [256 x <2 x i64>], [256 x <2 x i64>]* %8, i64 0, i64 %1465
  call void %1313(<2 x i64>* %1466, <2 x i64>* %1466, i32 %1344, i32 1, i32 %6, i32 0) #8
  %1467 = load i8, i8* %1345, align 1
  %1468 = sext i8 %1467 to i32
  %1469 = sub nsw i32 0, %1468
  %1470 = icmp slt i8 %1467, 0
  br i1 %1470, label %1472, label %1471

1471:                                             ; preds = %1463
  br i1 %1351, label %1544, label %1506

1472:                                             ; preds = %1463
  %1473 = xor i32 %1468, -1
  %1474 = shl i32 1, %1473
  %1475 = insertelement <4 x i32> undef, i32 %1474, i32 0
  %1476 = shufflevector <4 x i32> %1475, <4 x i32> undef, <4 x i32> zeroinitializer
  br i1 %1355, label %1531, label %1477

1477:                                             ; preds = %1472, %1477
  %1478 = phi i64 [ %1503, %1477 ], [ 0, %1472 ]
  %1479 = phi i64 [ %1504, %1477 ], [ %1356, %1472 ]
  %1480 = getelementptr inbounds <2 x i64>, <2 x i64>* %1466, i64 %1478
  %1481 = bitcast <2 x i64>* %1480 to <4 x i32>*
  %1482 = load <4 x i32>, <4 x i32>* %1481, align 16
  %1483 = add <4 x i32> %1482, %1476
  %1484 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1483, i32 %1469) #8
  store <4 x i32> %1484, <4 x i32>* %1481, align 16
  %1485 = or i64 %1478, 1
  %1486 = getelementptr inbounds <2 x i64>, <2 x i64>* %1466, i64 %1485
  %1487 = bitcast <2 x i64>* %1486 to <4 x i32>*
  %1488 = load <4 x i32>, <4 x i32>* %1487, align 16
  %1489 = add <4 x i32> %1488, %1476
  %1490 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1489, i32 %1469) #8
  store <4 x i32> %1490, <4 x i32>* %1487, align 16
  %1491 = or i64 %1478, 2
  %1492 = getelementptr inbounds <2 x i64>, <2 x i64>* %1466, i64 %1491
  %1493 = bitcast <2 x i64>* %1492 to <4 x i32>*
  %1494 = load <4 x i32>, <4 x i32>* %1493, align 16
  %1495 = add <4 x i32> %1494, %1476
  %1496 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1495, i32 %1469) #8
  store <4 x i32> %1496, <4 x i32>* %1493, align 16
  %1497 = or i64 %1478, 3
  %1498 = getelementptr inbounds <2 x i64>, <2 x i64>* %1466, i64 %1497
  %1499 = bitcast <2 x i64>* %1498 to <4 x i32>*
  %1500 = load <4 x i32>, <4 x i32>* %1499, align 16
  %1501 = add <4 x i32> %1500, %1476
  %1502 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1501, i32 %1469) #8
  store <4 x i32> %1502, <4 x i32>* %1499, align 16
  %1503 = add nuw nsw i64 %1478, 4
  %1504 = add i64 %1479, -4
  %1505 = icmp eq i64 %1504, 0
  br i1 %1505, label %1531, label %1477

1506:                                             ; preds = %1471, %1506
  %1507 = phi i64 [ %1528, %1506 ], [ 0, %1471 ]
  %1508 = phi i64 [ %1529, %1506 ], [ %1352, %1471 ]
  %1509 = getelementptr inbounds <2 x i64>, <2 x i64>* %1466, i64 %1507
  %1510 = bitcast <2 x i64>* %1509 to <4 x i32>*
  %1511 = load <4 x i32>, <4 x i32>* %1510, align 16
  %1512 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %1511, i32 %1468) #8
  store <4 x i32> %1512, <4 x i32>* %1510, align 16
  %1513 = or i64 %1507, 1
  %1514 = getelementptr inbounds <2 x i64>, <2 x i64>* %1466, i64 %1513
  %1515 = bitcast <2 x i64>* %1514 to <4 x i32>*
  %1516 = load <4 x i32>, <4 x i32>* %1515, align 16
  %1517 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %1516, i32 %1468) #8
  store <4 x i32> %1517, <4 x i32>* %1515, align 16
  %1518 = or i64 %1507, 2
  %1519 = getelementptr inbounds <2 x i64>, <2 x i64>* %1466, i64 %1518
  %1520 = bitcast <2 x i64>* %1519 to <4 x i32>*
  %1521 = load <4 x i32>, <4 x i32>* %1520, align 16
  %1522 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %1521, i32 %1468) #8
  store <4 x i32> %1522, <4 x i32>* %1520, align 16
  %1523 = or i64 %1507, 3
  %1524 = getelementptr inbounds <2 x i64>, <2 x i64>* %1466, i64 %1523
  %1525 = bitcast <2 x i64>* %1524 to <4 x i32>*
  %1526 = load <4 x i32>, <4 x i32>* %1525, align 16
  %1527 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %1526, i32 %1468) #8
  store <4 x i32> %1527, <4 x i32>* %1525, align 16
  %1528 = add nuw nsw i64 %1507, 4
  %1529 = add i64 %1508, -4
  %1530 = icmp eq i64 %1529, 0
  br i1 %1530, label %1544, label %1506

1531:                                             ; preds = %1477, %1472
  %1532 = phi i64 [ 0, %1472 ], [ %1503, %1477 ]
  br i1 %1357, label %1556, label %1533

1533:                                             ; preds = %1531, %1533
  %1534 = phi i64 [ %1541, %1533 ], [ %1532, %1531 ]
  %1535 = phi i64 [ %1542, %1533 ], [ %1354, %1531 ]
  %1536 = getelementptr inbounds <2 x i64>, <2 x i64>* %1466, i64 %1534
  %1537 = bitcast <2 x i64>* %1536 to <4 x i32>*
  %1538 = load <4 x i32>, <4 x i32>* %1537, align 16
  %1539 = add <4 x i32> %1538, %1476
  %1540 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1539, i32 %1469) #8
  store <4 x i32> %1540, <4 x i32>* %1537, align 16
  %1541 = add nuw nsw i64 %1534, 1
  %1542 = add i64 %1535, -1
  %1543 = icmp eq i64 %1542, 0
  br i1 %1543, label %1556, label %1533, !llvm.loop !9

1544:                                             ; preds = %1506, %1471
  %1545 = phi i64 [ 0, %1471 ], [ %1528, %1506 ]
  br i1 %1353, label %1556, label %1546

1546:                                             ; preds = %1544, %1546
  %1547 = phi i64 [ %1553, %1546 ], [ %1545, %1544 ]
  %1548 = phi i64 [ %1554, %1546 ], [ %1350, %1544 ]
  %1549 = getelementptr inbounds <2 x i64>, <2 x i64>* %1466, i64 %1547
  %1550 = bitcast <2 x i64>* %1549 to <4 x i32>*
  %1551 = load <4 x i32>, <4 x i32>* %1550, align 16
  %1552 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %1551, i32 %1468) #8
  store <4 x i32> %1552, <4 x i32>* %1550, align 16
  %1553 = add nuw nsw i64 %1547, 1
  %1554 = add i64 %1548, -1
  %1555 = icmp eq i64 %1554, 0
  br i1 %1555, label %1556, label %1546, !llvm.loop !10

1556:                                             ; preds = %1544, %1546, %1531, %1533
  %1557 = add nuw nsw i64 %1464, 1
  %1558 = icmp slt i64 %1557, %1348
  br i1 %1558, label %1463, label %1448

1559:                                             ; preds = %1602, %1452
  %1560 = phi i64 [ 0, %1452 ], [ %1603, %1602 ]
  %1561 = trunc i64 %1560 to i32
  %1562 = mul i32 %1454, %1561
  %1563 = sext i32 %1562 to i64
  %1564 = getelementptr inbounds [256 x <2 x i64>], [256 x <2 x i64>]* %8, i64 0, i64 %1563
  %1565 = shl nsw i64 %1560, 3
  %1566 = getelementptr inbounds i16, i16* %1271, i64 %1565
  br label %1567

1567:                                             ; preds = %1567, %1559
  %1568 = phi i64 [ 0, %1559 ], [ %1600, %1567 ]
  %1569 = mul nsw i64 %1568, %1460
  %1570 = getelementptr inbounds i16, i16* %1566, i64 %1569
  %1571 = bitcast i16* %1570 to <2 x i64>*
  %1572 = load <2 x i64>, <2 x i64>* %1571, align 2
  %1573 = getelementptr inbounds <2 x i64>, <2 x i64>* %1564, i64 %1568
  %1574 = bitcast <2 x i64>* %1573 to <4 x i32>*
  %1575 = load <4 x i32>, <4 x i32>* %1574, align 16
  %1576 = add nsw i64 %1568, %1459
  %1577 = getelementptr inbounds <2 x i64>, <2 x i64>* %1564, i64 %1576
  %1578 = bitcast <2 x i64>* %1577 to <4 x i32>*
  %1579 = load <4 x i32>, <4 x i32>* %1578, align 16
  %1580 = bitcast <2 x i64> %1572 to <8 x i16>
  %1581 = shufflevector <8 x i16> %1580, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1582 = sext <4 x i16> %1581 to <4 x i32>
  %1583 = bitcast <2 x i64> %1572 to <16 x i8>
  %1584 = shufflevector <16 x i8> %1583, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %1585 = bitcast <16 x i8> %1584 to <8 x i16>
  %1586 = shufflevector <8 x i16> %1585, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1587 = sext <4 x i16> %1586 to <4 x i32>
  %1588 = add <4 x i32> %1575, %1582
  %1589 = add <4 x i32> %1579, %1587
  %1590 = icmp sgt <4 x i32> %1588, zeroinitializer
  %1591 = select <4 x i1> %1590, <4 x i32> %1588, <4 x i32> zeroinitializer
  %1592 = icmp slt <4 x i32> %1591, %1458
  %1593 = select <4 x i1> %1592, <4 x i32> %1591, <4 x i32> %1458
  %1594 = icmp sgt <4 x i32> %1589, zeroinitializer
  %1595 = select <4 x i1> %1594, <4 x i32> %1589, <4 x i32> zeroinitializer
  %1596 = icmp slt <4 x i32> %1595, %1458
  %1597 = select <4 x i1> %1596, <4 x i32> %1595, <4 x i32> %1458
  %1598 = call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1593, <4 x i32> %1597) #8
  %1599 = bitcast i16* %1570 to <8 x i16>*
  store <8 x i16> %1598, <8 x i16>* %1599, align 2
  %1600 = add nuw nsw i64 %1568, 1
  %1601 = icmp eq i64 %1600, %1461
  br i1 %1601, label %1602, label %1567

1602:                                             ; preds = %1567
  %1603 = add nuw nsw i64 %1560, 1
  %1604 = icmp slt i64 %1603, %1462
  br i1 %1604, label %1559, label %1605

1605:                                             ; preds = %1602, %1448
  call void @llvm.lifetime.end.p0i8(i64 4096, i8* nonnull %1272) #8
  br label %1606

1606:                                             ; preds = %7, %1605, %1267, %834, %458
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_highbd_inv_txfm_add_4x4_sse4_1(i32*, i8*, i32, %struct.txfm_param* nocapture readonly) local_unnamed_addr #3 {
  %5 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 3
  %6 = load i32, i32* %5, align 4
  %7 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 2
  %8 = load i32, i32* %7, align 4
  %9 = icmp eq i32 %8, 0
  br i1 %9, label %13, label %10

10:                                               ; preds = %4
  %11 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 6
  %12 = load i32, i32* %11, align 4
  tail call void @av1_highbd_iwht4x4_add(i32* %0, i8* %1, i32 %2, i32 %12, i32 %6) #8
  br label %19

13:                                               ; preds = %4
  %14 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 0
  %15 = load i8, i8* %14, align 4
  %16 = ptrtoint i8* %1 to i64
  %17 = shl i64 %16, 1
  %18 = inttoptr i64 %17 to i16*
  tail call void @av1_inv_txfm2d_add_4x4_sse4_1(i32* %0, i16* %18, i32 %2, i8 zeroext %15, i32 %6)
  br label %19

19:                                               ; preds = %13, %10
  ret void
}

declare void @av1_highbd_iwht4x4_add(i32*, i8*, i32, i32, i32) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_highbd_inv_txfm_add_4x8_sse4_1(i32* nocapture readonly, i8*, i32, %struct.txfm_param* nocapture readonly) local_unnamed_addr #0 {
  %5 = alloca [8 x <2 x i64>], align 16
  %6 = alloca [8 x <2 x i64>], align 16
  %7 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 3
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 0
  %10 = load i8, i8* %9, align 4
  %11 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 1
  %12 = load i8, i8* %11, align 1
  %13 = ptrtoint i8* %1 to i64
  %14 = shl i64 %13, 1
  %15 = inttoptr i64 %14 to i16*
  %16 = bitcast [8 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %16) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %16, i8 -86, i64 128, i1 false) #8
  %17 = zext i8 %12 to i64
  %18 = getelementptr inbounds [19 x i8*], [19 x i8*]* @av1_inv_txfm_shift_ls, i64 0, i64 %17
  %19 = load i8*, i8** %18, align 8
  %20 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide_log2, i64 0, i64 %17
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, -2
  %23 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high_log2, i64 0, i64 %17
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %24, -2
  %26 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide, i64 0, i64 %17
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high, i64 0, i64 %17
  %29 = load i32, i32* %28, align 4
  %30 = sext i32 %22 to i64
  %31 = zext i8 %10 to i64
  %32 = getelementptr inbounds [16 x i8], [16 x i8]* @hitx_1d_tab, i64 0, i64 %31
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i64
  %35 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %30, i64 %34, i64 0
  %36 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %35, align 16
  %37 = sext i32 %25 to i64
  %38 = getelementptr inbounds [16 x i8], [16 x i8]* @vitx_1d_tab, i64 0, i64 %31
  %39 = load i8, i8* %38, align 1
  %40 = zext i8 %39 to i64
  %41 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %37, i64 %40, i64 1
  %42 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %41, align 8
  %43 = icmp slt i32 %27, 32
  %44 = select i1 %43, i32 %27, i32 32
  %45 = add i8 %10, -4
  %46 = icmp ult i8 %45, 12
  br i1 %46, label %47, label %54

47:                                               ; preds = %4
  %48 = sext i8 %45 to i64
  %49 = getelementptr inbounds [12 x i32], [12 x i32]* @switch.table.av1_highbd_inv_txfm_add_16x4_sse4_1, i64 0, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = sext i8 %45 to i64
  %52 = getelementptr inbounds [12 x i32], [12 x i32]* @switch.table.av1_highbd_inv_txfm_add_16x4_sse4_1.6, i64 0, i64 %51
  %53 = load i32, i32* %52, align 4
  br label %54

54:                                               ; preds = %47, %4
  %55 = phi i32 [ 0, %4 ], [ %50, %47 ]
  %56 = phi i32 [ 0, %4 ], [ %53, %47 ]
  %57 = bitcast [8 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %57) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %57, i8 -86, i64 128, i1 false) #8
  %58 = sext i32 %44 to i64
  %59 = zext i32 %29 to i64
  %60 = add nsw i64 %59, -1
  %61 = and i64 %59, 3
  %62 = icmp ult i64 %60, 3
  br i1 %62, label %94, label %63

63:                                               ; preds = %54
  %64 = sub nsw i64 %59, %61
  br label %65

65:                                               ; preds = %65, %63
  %66 = phi i64 [ 0, %63 ], [ %91, %65 ]
  %67 = phi i64 [ %64, %63 ], [ %92, %65 ]
  %68 = mul nsw i64 %66, %58
  %69 = getelementptr inbounds i32, i32* %0, i64 %68
  %70 = bitcast i32* %69 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 1
  %72 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %66
  store <2 x i64> %71, <2 x i64>* %72, align 16
  %73 = or i64 %66, 1
  %74 = mul nsw i64 %73, %58
  %75 = getelementptr inbounds i32, i32* %0, i64 %74
  %76 = bitcast i32* %75 to <2 x i64>*
  %77 = load <2 x i64>, <2 x i64>* %76, align 1
  %78 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %73
  store <2 x i64> %77, <2 x i64>* %78, align 16
  %79 = or i64 %66, 2
  %80 = mul nsw i64 %79, %58
  %81 = getelementptr inbounds i32, i32* %0, i64 %80
  %82 = bitcast i32* %81 to <2 x i64>*
  %83 = load <2 x i64>, <2 x i64>* %82, align 1
  %84 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %79
  store <2 x i64> %83, <2 x i64>* %84, align 16
  %85 = or i64 %66, 3
  %86 = mul nsw i64 %85, %58
  %87 = getelementptr inbounds i32, i32* %0, i64 %86
  %88 = bitcast i32* %87 to <2 x i64>*
  %89 = load <2 x i64>, <2 x i64>* %88, align 1
  %90 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %85
  store <2 x i64> %89, <2 x i64>* %90, align 16
  %91 = add nuw nsw i64 %66, 4
  %92 = add i64 %67, -4
  %93 = icmp eq i64 %92, 0
  br i1 %93, label %94, label %65

94:                                               ; preds = %65, %54
  %95 = phi i64 [ 0, %54 ], [ %91, %65 ]
  %96 = icmp eq i64 %61, 0
  br i1 %96, label %108, label %97

97:                                               ; preds = %94, %97
  %98 = phi i64 [ %105, %97 ], [ %95, %94 ]
  %99 = phi i64 [ %106, %97 ], [ %61, %94 ]
  %100 = mul nsw i64 %98, %58
  %101 = getelementptr inbounds i32, i32* %0, i64 %100
  %102 = bitcast i32* %101 to <2 x i64>*
  %103 = load <2 x i64>, <2 x i64>* %102, align 1
  %104 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %98
  store <2 x i64> %103, <2 x i64>* %104, align 16
  %105 = add nuw nsw i64 %98, 1
  %106 = add i64 %99, -1
  %107 = icmp eq i64 %106, 0
  br i1 %107, label %108, label %97, !llvm.loop !11

108:                                              ; preds = %97, %94
  %109 = and i64 %59, 1
  %110 = sub nsw i64 %59, %109
  br label %111

111:                                              ; preds = %111, %108
  %112 = phi i64 [ 0, %108 ], [ %127, %111 ]
  %113 = phi i64 [ %110, %108 ], [ %128, %111 ]
  %114 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %112
  %115 = bitcast <2 x i64>* %114 to <4 x i32>*
  %116 = load <4 x i32>, <4 x i32>* %115, align 16
  %117 = mul <4 x i32> %116, <i32 2896, i32 2896, i32 2896, i32 2896>
  %118 = add <4 x i32> %117, <i32 2048, i32 2048, i32 2048, i32 2048>
  %119 = ashr <4 x i32> %118, <i32 12, i32 12, i32 12, i32 12>
  store <4 x i32> %119, <4 x i32>* %115, align 16
  %120 = or i64 %112, 1
  %121 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %120
  %122 = bitcast <2 x i64>* %121 to <4 x i32>*
  %123 = load <4 x i32>, <4 x i32>* %122, align 16
  %124 = mul <4 x i32> %123, <i32 2896, i32 2896, i32 2896, i32 2896>
  %125 = add <4 x i32> %124, <i32 2048, i32 2048, i32 2048, i32 2048>
  %126 = ashr <4 x i32> %125, <i32 12, i32 12, i32 12, i32 12>
  store <4 x i32> %126, <4 x i32>* %122, align 16
  %127 = add nuw nsw i64 %112, 2
  %128 = add i64 %113, -2
  %129 = icmp eq i64 %128, 0
  br i1 %129, label %130, label %111

130:                                              ; preds = %111
  %131 = icmp eq i64 %109, 0
  br i1 %131, label %139, label %132

132:                                              ; preds = %130
  %133 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %127
  %134 = bitcast <2 x i64>* %133 to <4 x i32>*
  %135 = load <4 x i32>, <4 x i32>* %134, align 16
  %136 = mul <4 x i32> %135, <i32 2896, i32 2896, i32 2896, i32 2896>
  %137 = add <4 x i32> %136, <i32 2048, i32 2048, i32 2048, i32 2048>
  %138 = ashr <4 x i32> %137, <i32 12, i32 12, i32 12, i32 12>
  store <4 x i32> %138, <4 x i32>* %134, align 16
  br label %139

139:                                              ; preds = %130, %132
  %140 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 0
  %141 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 %30, i64 %37
  %142 = load i8, i8* %141, align 1
  %143 = sext i8 %142 to i32
  %144 = load i8, i8* %19, align 1
  %145 = sext i8 %144 to i32
  %146 = sub nsw i32 0, %145
  call void %36(<2 x i64>* nonnull %140, <2 x i64>* nonnull %140, i32 %143, i32 0, i32 %8, i32 %146) #8
  %147 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %148 = load i8, i8* %19, align 1
  %149 = sext i8 %148 to i32
  %150 = sub nsw i32 0, %149
  call void %36(<2 x i64>* %147, <2 x i64>* %147, i32 %143, i32 0, i32 %8, i32 %150) #8
  %151 = icmp eq i32 %56, 0
  br i1 %151, label %200, label %152

152:                                              ; preds = %139
  %153 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %154 = bitcast <2 x i64>* %153 to <4 x i32>*
  %155 = load <4 x i32>, <4 x i32>* %154, align 16
  %156 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %157 = bitcast <2 x i64>* %156 to <4 x i32>*
  %158 = load <4 x i32>, <4 x i32>* %157, align 16
  %159 = shufflevector <4 x i32> %155, <4 x i32> %158, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %160 = bitcast <4 x i32> %159 to <2 x i64>
  %161 = shufflevector <4 x i32> %155, <4 x i32> %158, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %162 = bitcast <4 x i32> %161 to <2 x i64>
  %163 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %164 = bitcast <2 x i64>* %163 to <4 x i32>*
  %165 = load <4 x i32>, <4 x i32>* %164, align 16
  %166 = bitcast [8 x <2 x i64>]* %6 to <4 x i32>*
  %167 = load <4 x i32>, <4 x i32>* %166, align 16
  %168 = shufflevector <4 x i32> %165, <4 x i32> %167, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %169 = bitcast <4 x i32> %168 to <2 x i64>
  %170 = shufflevector <4 x i32> %165, <4 x i32> %167, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %171 = bitcast <4 x i32> %170 to <2 x i64>
  %172 = shufflevector <2 x i64> %160, <2 x i64> %169, <2 x i32> <i32 0, i32 2>
  %173 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 0
  store <2 x i64> %172, <2 x i64>* %173, align 16
  %174 = shufflevector <2 x i64> %160, <2 x i64> %169, <2 x i32> <i32 1, i32 3>
  %175 = shufflevector <2 x i64> %162, <2 x i64> %171, <2 x i32> <i32 0, i32 2>
  %176 = shufflevector <2 x i64> %162, <2 x i64> %171, <2 x i32> <i32 1, i32 3>
  %177 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %178 = bitcast <2 x i64>* %177 to <4 x i32>*
  %179 = load <4 x i32>, <4 x i32>* %178, align 16
  %180 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %181 = bitcast <2 x i64>* %180 to <4 x i32>*
  %182 = load <4 x i32>, <4 x i32>* %181, align 16
  %183 = shufflevector <4 x i32> %179, <4 x i32> %182, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %184 = bitcast <4 x i32> %183 to <2 x i64>
  %185 = shufflevector <4 x i32> %179, <4 x i32> %182, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %186 = bitcast <4 x i32> %185 to <2 x i64>
  %187 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %188 = bitcast <2 x i64>* %187 to <4 x i32>*
  %189 = load <4 x i32>, <4 x i32>* %188, align 16
  %190 = bitcast <2 x i64>* %147 to <4 x i32>*
  %191 = load <4 x i32>, <4 x i32>* %190, align 16
  %192 = shufflevector <4 x i32> %189, <4 x i32> %191, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %193 = bitcast <4 x i32> %192 to <2 x i64>
  %194 = shufflevector <4 x i32> %189, <4 x i32> %191, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %195 = bitcast <4 x i32> %194 to <2 x i64>
  %196 = shufflevector <2 x i64> %184, <2 x i64> %193, <2 x i32> <i32 0, i32 2>
  %197 = shufflevector <2 x i64> %184, <2 x i64> %193, <2 x i32> <i32 1, i32 3>
  %198 = shufflevector <2 x i64> %186, <2 x i64> %195, <2 x i32> <i32 0, i32 2>
  %199 = shufflevector <2 x i64> %186, <2 x i64> %195, <2 x i32> <i32 1, i32 3>
  br label %248

200:                                              ; preds = %139
  %201 = bitcast [8 x <2 x i64>]* %6 to <4 x i32>*
  %202 = load <4 x i32>, <4 x i32>* %201, align 16
  %203 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %204 = bitcast <2 x i64>* %203 to <4 x i32>*
  %205 = load <4 x i32>, <4 x i32>* %204, align 16
  %206 = shufflevector <4 x i32> %202, <4 x i32> %205, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %207 = bitcast <4 x i32> %206 to <2 x i64>
  %208 = shufflevector <4 x i32> %202, <4 x i32> %205, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %209 = bitcast <4 x i32> %208 to <2 x i64>
  %210 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %211 = bitcast <2 x i64>* %210 to <4 x i32>*
  %212 = load <4 x i32>, <4 x i32>* %211, align 16
  %213 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %214 = bitcast <2 x i64>* %213 to <4 x i32>*
  %215 = load <4 x i32>, <4 x i32>* %214, align 16
  %216 = shufflevector <4 x i32> %212, <4 x i32> %215, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %217 = bitcast <4 x i32> %216 to <2 x i64>
  %218 = shufflevector <4 x i32> %212, <4 x i32> %215, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %219 = bitcast <4 x i32> %218 to <2 x i64>
  %220 = shufflevector <2 x i64> %207, <2 x i64> %217, <2 x i32> <i32 0, i32 2>
  %221 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 0
  store <2 x i64> %220, <2 x i64>* %221, align 16
  %222 = shufflevector <2 x i64> %207, <2 x i64> %217, <2 x i32> <i32 1, i32 3>
  %223 = shufflevector <2 x i64> %209, <2 x i64> %219, <2 x i32> <i32 0, i32 2>
  %224 = shufflevector <2 x i64> %209, <2 x i64> %219, <2 x i32> <i32 1, i32 3>
  %225 = bitcast <2 x i64>* %147 to <4 x i32>*
  %226 = load <4 x i32>, <4 x i32>* %225, align 16
  %227 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %228 = bitcast <2 x i64>* %227 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16
  %230 = shufflevector <4 x i32> %226, <4 x i32> %229, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %231 = bitcast <4 x i32> %230 to <2 x i64>
  %232 = shufflevector <4 x i32> %226, <4 x i32> %229, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %233 = bitcast <4 x i32> %232 to <2 x i64>
  %234 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %235 = bitcast <2 x i64>* %234 to <4 x i32>*
  %236 = load <4 x i32>, <4 x i32>* %235, align 16
  %237 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %238 = bitcast <2 x i64>* %237 to <4 x i32>*
  %239 = load <4 x i32>, <4 x i32>* %238, align 16
  %240 = shufflevector <4 x i32> %236, <4 x i32> %239, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %241 = bitcast <4 x i32> %240 to <2 x i64>
  %242 = shufflevector <4 x i32> %236, <4 x i32> %239, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %243 = bitcast <4 x i32> %242 to <2 x i64>
  %244 = shufflevector <2 x i64> %231, <2 x i64> %241, <2 x i32> <i32 0, i32 2>
  %245 = shufflevector <2 x i64> %231, <2 x i64> %241, <2 x i32> <i32 1, i32 3>
  %246 = shufflevector <2 x i64> %233, <2 x i64> %243, <2 x i32> <i32 0, i32 2>
  %247 = shufflevector <2 x i64> %233, <2 x i64> %243, <2 x i32> <i32 1, i32 3>
  br label %248

248:                                              ; preds = %200, %152
  %249 = phi <2 x i64> [ %222, %200 ], [ %174, %152 ]
  %250 = phi <2 x i64> [ %223, %200 ], [ %175, %152 ]
  %251 = phi <2 x i64> [ %224, %200 ], [ %176, %152 ]
  %252 = phi <2 x i64> [ %244, %200 ], [ %196, %152 ]
  %253 = phi <2 x i64> [ %245, %200 ], [ %197, %152 ]
  %254 = phi <2 x i64> [ %246, %200 ], [ %198, %152 ]
  %255 = phi <2 x i64> [ %247, %200 ], [ %199, %152 ]
  %256 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 1
  store <2 x i64> %249, <2 x i64>* %256, align 16
  %257 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 2
  store <2 x i64> %250, <2 x i64>* %257, align 16
  %258 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 3
  store <2 x i64> %251, <2 x i64>* %258, align 16
  %259 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 4
  store <2 x i64> %252, <2 x i64>* %259, align 16
  %260 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 5
  store <2 x i64> %253, <2 x i64>* %260, align 16
  %261 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 6
  store <2 x i64> %254, <2 x i64>* %261, align 16
  %262 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 7
  store <2 x i64> %255, <2 x i64>* %262, align 16
  %263 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 0
  %264 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 %30, i64 %37
  %265 = load i8, i8* %264, align 1
  %266 = sext i8 %265 to i32
  call void %42(<2 x i64>* nonnull %263, <2 x i64>* nonnull %263, i32 %266, i32 1, i32 %8, i32 0) #8
  %267 = getelementptr inbounds i8, i8* %19, i64 1
  %268 = load i8, i8* %267, align 1
  %269 = sext i8 %268 to i32
  %270 = sub nsw i32 0, %269
  %271 = icmp slt i8 %268, 0
  br i1 %271, label %278, label %272

272:                                              ; preds = %248
  %273 = add nsw i64 %59, -1
  %274 = and i64 %59, 3
  %275 = icmp ult i64 %273, 3
  br i1 %275, label %356, label %276

276:                                              ; preds = %272
  %277 = sub nsw i64 %59, %274
  br label %317

278:                                              ; preds = %248
  %279 = xor i32 %269, -1
  %280 = shl i32 1, %279
  %281 = insertelement <4 x i32> undef, i32 %280, i32 0
  %282 = shufflevector <4 x i32> %281, <4 x i32> undef, <4 x i32> zeroinitializer
  %283 = add nsw i64 %59, -1
  %284 = and i64 %59, 3
  %285 = icmp ult i64 %283, 3
  br i1 %285, label %342, label %286

286:                                              ; preds = %278
  %287 = sub nsw i64 %59, %284
  br label %288

288:                                              ; preds = %288, %286
  %289 = phi i64 [ 0, %286 ], [ %314, %288 ]
  %290 = phi i64 [ %287, %286 ], [ %315, %288 ]
  %291 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %289
  %292 = bitcast <2 x i64>* %291 to <4 x i32>*
  %293 = load <4 x i32>, <4 x i32>* %292, align 16
  %294 = add <4 x i32> %293, %282
  %295 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %294, i32 %270) #8
  store <4 x i32> %295, <4 x i32>* %292, align 16
  %296 = or i64 %289, 1
  %297 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %296
  %298 = bitcast <2 x i64>* %297 to <4 x i32>*
  %299 = load <4 x i32>, <4 x i32>* %298, align 16
  %300 = add <4 x i32> %299, %282
  %301 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %300, i32 %270) #8
  store <4 x i32> %301, <4 x i32>* %298, align 16
  %302 = or i64 %289, 2
  %303 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %302
  %304 = bitcast <2 x i64>* %303 to <4 x i32>*
  %305 = load <4 x i32>, <4 x i32>* %304, align 16
  %306 = add <4 x i32> %305, %282
  %307 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %306, i32 %270) #8
  store <4 x i32> %307, <4 x i32>* %304, align 16
  %308 = or i64 %289, 3
  %309 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %308
  %310 = bitcast <2 x i64>* %309 to <4 x i32>*
  %311 = load <4 x i32>, <4 x i32>* %310, align 16
  %312 = add <4 x i32> %311, %282
  %313 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %312, i32 %270) #8
  store <4 x i32> %313, <4 x i32>* %310, align 16
  %314 = add nuw nsw i64 %289, 4
  %315 = add i64 %290, -4
  %316 = icmp eq i64 %315, 0
  br i1 %316, label %342, label %288

317:                                              ; preds = %317, %276
  %318 = phi i64 [ 0, %276 ], [ %339, %317 ]
  %319 = phi i64 [ %277, %276 ], [ %340, %317 ]
  %320 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %318
  %321 = bitcast <2 x i64>* %320 to <4 x i32>*
  %322 = load <4 x i32>, <4 x i32>* %321, align 16
  %323 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %322, i32 %269) #8
  store <4 x i32> %323, <4 x i32>* %321, align 16
  %324 = or i64 %318, 1
  %325 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %324
  %326 = bitcast <2 x i64>* %325 to <4 x i32>*
  %327 = load <4 x i32>, <4 x i32>* %326, align 16
  %328 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %327, i32 %269) #8
  store <4 x i32> %328, <4 x i32>* %326, align 16
  %329 = or i64 %318, 2
  %330 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %329
  %331 = bitcast <2 x i64>* %330 to <4 x i32>*
  %332 = load <4 x i32>, <4 x i32>* %331, align 16
  %333 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %332, i32 %269) #8
  store <4 x i32> %333, <4 x i32>* %331, align 16
  %334 = or i64 %318, 3
  %335 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %334
  %336 = bitcast <2 x i64>* %335 to <4 x i32>*
  %337 = load <4 x i32>, <4 x i32>* %336, align 16
  %338 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %337, i32 %269) #8
  store <4 x i32> %338, <4 x i32>* %336, align 16
  %339 = add nuw nsw i64 %318, 4
  %340 = add i64 %319, -4
  %341 = icmp eq i64 %340, 0
  br i1 %341, label %356, label %317

342:                                              ; preds = %288, %278
  %343 = phi i64 [ 0, %278 ], [ %314, %288 ]
  %344 = icmp eq i64 %284, 0
  br i1 %344, label %369, label %345

345:                                              ; preds = %342, %345
  %346 = phi i64 [ %353, %345 ], [ %343, %342 ]
  %347 = phi i64 [ %354, %345 ], [ %284, %342 ]
  %348 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %346
  %349 = bitcast <2 x i64>* %348 to <4 x i32>*
  %350 = load <4 x i32>, <4 x i32>* %349, align 16
  %351 = add <4 x i32> %350, %282
  %352 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %351, i32 %270) #8
  store <4 x i32> %352, <4 x i32>* %349, align 16
  %353 = add nuw nsw i64 %346, 1
  %354 = add i64 %347, -1
  %355 = icmp eq i64 %354, 0
  br i1 %355, label %369, label %345, !llvm.loop !12

356:                                              ; preds = %317, %272
  %357 = phi i64 [ 0, %272 ], [ %339, %317 ]
  %358 = icmp eq i64 %274, 0
  br i1 %358, label %369, label %359

359:                                              ; preds = %356, %359
  %360 = phi i64 [ %366, %359 ], [ %357, %356 ]
  %361 = phi i64 [ %367, %359 ], [ %274, %356 ]
  %362 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %360
  %363 = bitcast <2 x i64>* %362 to <4 x i32>*
  %364 = load <4 x i32>, <4 x i32>* %363, align 16
  %365 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %364, i32 %269) #8
  store <4 x i32> %365, <4 x i32>* %363, align 16
  %366 = add nuw nsw i64 %360, 1
  %367 = add i64 %361, -1
  %368 = icmp eq i64 %367, 0
  br i1 %368, label %369, label %359, !llvm.loop !13

369:                                              ; preds = %356, %359, %342, %345
  %370 = icmp ne i32 %55, 0
  %371 = select i1 %370, i64 -1, i64 1
  %372 = add nsw i32 %29, -1
  %373 = select i1 %370, i32 %372, i32 0
  %374 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %8) #8
  %375 = add <8 x i16> %374, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %376 = sext i32 %373 to i64
  %377 = sext i32 %2 to i64
  br label %378

378:                                              ; preds = %378, %369
  %379 = phi i64 [ 0, %369 ], [ %409, %378 ]
  %380 = phi i64 [ %376, %369 ], [ %410, %378 ]
  %381 = mul nsw i64 %379, %377
  %382 = getelementptr inbounds i16, i16* %15, i64 %381
  %383 = bitcast i16* %382 to i64*
  %384 = load i64, i64* %383, align 2
  %385 = insertelement <2 x i64> undef, i64 %384, i32 0
  %386 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %380
  %387 = bitcast <2 x i64>* %386 to <4 x i32>*
  %388 = load <4 x i32>, <4 x i32>* %387, align 16
  %389 = bitcast <2 x i64> %385 to <8 x i16>
  %390 = shufflevector <8 x i16> %389, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %391 = sext <4 x i16> %390 to <4 x i32>
  %392 = add <4 x i32> %388, %391
  %393 = call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %392, <4 x i32> %392) #8
  %394 = bitcast <8 x i16> %393 to <2 x i64>
  %395 = icmp slt <8 x i16> %375, %393
  %396 = sext <8 x i1> %395 to <8 x i16>
  %397 = bitcast <8 x i16> %396 to <2 x i64>
  %398 = xor <2 x i64> %397, <i64 -1, i64 -1>
  %399 = and <2 x i64> %398, %394
  %400 = and <8 x i16> %375, %396
  %401 = bitcast <8 x i16> %400 to <2 x i64>
  %402 = or <2 x i64> %399, %401
  %403 = bitcast <2 x i64> %402 to <8 x i16>
  %404 = icmp sgt <8 x i16> %403, zeroinitializer
  %405 = sext <8 x i1> %404 to <8 x i16>
  %406 = bitcast <8 x i16> %405 to <2 x i64>
  %407 = and <2 x i64> %402, %406
  %408 = extractelement <2 x i64> %407, i32 0
  store i64 %408, i64* %383, align 2
  %409 = add nuw nsw i64 %379, 1
  %410 = add i64 %380, %371
  %411 = icmp eq i64 %409, %59
  br i1 %411, label %412, label %378

412:                                              ; preds = %378
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %57) #8
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %16) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_highbd_inv_txfm_add_8x4_sse4_1(i32* nocapture readonly, i8*, i32, %struct.txfm_param* nocapture readonly) local_unnamed_addr #0 {
  %5 = alloca [8 x <2 x i64>], align 16
  %6 = alloca [8 x <2 x i64>], align 16
  %7 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 3
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 0
  %10 = load i8, i8* %9, align 4
  %11 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 1
  %12 = load i8, i8* %11, align 1
  %13 = ptrtoint i8* %1 to i64
  %14 = shl i64 %13, 1
  %15 = inttoptr i64 %14 to i16*
  %16 = bitcast i32* %0 to i8*
  %17 = bitcast [8 x <2 x i64>]* %6 to i8*
  %18 = bitcast [8 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %18, i8 -86, i64 128, i1 false) #8
  %19 = zext i8 %12 to i64
  %20 = getelementptr inbounds [19 x i8*], [19 x i8*]* @av1_inv_txfm_shift_ls, i64 0, i64 %19
  %21 = load i8*, i8** %20, align 8
  %22 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide_log2, i64 0, i64 %19
  %23 = load i32, i32* %22, align 4
  %24 = add nsw i32 %23, -2
  %25 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high_log2, i64 0, i64 %19
  %26 = load i32, i32* %25, align 4
  %27 = add nsw i32 %26, -2
  %28 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide, i64 0, i64 %19
  %29 = load i32, i32* %28, align 4
  %30 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high, i64 0, i64 %19
  %31 = load i32, i32* %30, align 4
  %32 = sext i32 %24 to i64
  %33 = zext i8 %10 to i64
  %34 = getelementptr inbounds [16 x i8], [16 x i8]* @hitx_1d_tab, i64 0, i64 %33
  %35 = load i8, i8* %34, align 1
  %36 = zext i8 %35 to i64
  %37 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %32, i64 %36, i64 1
  %38 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %37, align 8
  %39 = sext i32 %27 to i64
  %40 = getelementptr inbounds [16 x i8], [16 x i8]* @vitx_1d_tab, i64 0, i64 %33
  %41 = load i8, i8* %40, align 1
  %42 = zext i8 %41 to i64
  %43 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %39, i64 %42, i64 0
  %44 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %43, align 16
  %45 = add i8 %10, -4
  %46 = icmp ult i8 %45, 12
  br i1 %46, label %47, label %54

47:                                               ; preds = %4
  %48 = sext i8 %45 to i64
  %49 = getelementptr inbounds [12 x i32], [12 x i32]* @switch.table.av1_highbd_inv_txfm_add_16x4_sse4_1, i64 0, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = sext i8 %45 to i64
  %52 = getelementptr inbounds [12 x i32], [12 x i32]* @switch.table.av1_highbd_inv_txfm_add_16x4_sse4_1.6, i64 0, i64 %51
  %53 = load i32, i32* %52, align 4
  br label %54

54:                                               ; preds = %47, %4
  %55 = phi i32 [ 0, %4 ], [ %50, %47 ]
  %56 = phi i32 [ 0, %4 ], [ %53, %47 ]
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %17) #8
  %57 = zext i32 %29 to i64
  %58 = shl nuw nsw i64 %57, 4
  %59 = lshr i64 516062, %19
  %60 = and i64 %59, 1
  %61 = icmp eq i64 %60, 0
  %62 = sub nsw i64 128, %58
  %63 = select i1 %61, i64 %62, i64 0
  %64 = getelementptr [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %57
  %65 = bitcast <2 x i64>* %64 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %65, i8 -86, i64 %63, i1 false) #8
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %17, i8* align 1 %16, i64 %58, i1 false) #8
  %66 = bitcast [8 x <2 x i64>]* %6 to <4 x i32>*
  %67 = load <4 x i32>, <4 x i32>* %66, align 16
  %68 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %69 = bitcast <2 x i64>* %68 to <4 x i32>*
  %70 = load <4 x i32>, <4 x i32>* %69, align 16
  %71 = shufflevector <4 x i32> %67, <4 x i32> %70, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %72 = bitcast <4 x i32> %71 to <2 x i64>
  %73 = shufflevector <4 x i32> %67, <4 x i32> %70, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %74 = bitcast <4 x i32> %73 to <2 x i64>
  %75 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %76 = bitcast <2 x i64>* %75 to <4 x i32>*
  %77 = load <4 x i32>, <4 x i32>* %76, align 16
  %78 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %79 = bitcast <2 x i64>* %78 to <4 x i32>*
  %80 = load <4 x i32>, <4 x i32>* %79, align 16
  %81 = shufflevector <4 x i32> %77, <4 x i32> %80, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %82 = bitcast <4 x i32> %81 to <2 x i64>
  %83 = shufflevector <4 x i32> %77, <4 x i32> %80, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %84 = bitcast <4 x i32> %83 to <2 x i64>
  %85 = shufflevector <2 x i64> %72, <2 x i64> %82, <2 x i32> <i32 0, i32 2>
  %86 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 0
  store <2 x i64> %85, <2 x i64>* %86, align 16
  %87 = shufflevector <2 x i64> %72, <2 x i64> %82, <2 x i32> <i32 1, i32 3>
  %88 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 1
  store <2 x i64> %87, <2 x i64>* %88, align 16
  %89 = shufflevector <2 x i64> %74, <2 x i64> %84, <2 x i32> <i32 0, i32 2>
  %90 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 2
  store <2 x i64> %89, <2 x i64>* %90, align 16
  %91 = shufflevector <2 x i64> %74, <2 x i64> %84, <2 x i32> <i32 1, i32 3>
  %92 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 3
  store <2 x i64> %91, <2 x i64>* %92, align 16
  %93 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %94 = bitcast <2 x i64>* %93 to <4 x i32>*
  %95 = load <4 x i32>, <4 x i32>* %94, align 16
  %96 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %97 = bitcast <2 x i64>* %96 to <4 x i32>*
  %98 = load <4 x i32>, <4 x i32>* %97, align 16
  %99 = shufflevector <4 x i32> %95, <4 x i32> %98, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %100 = bitcast <4 x i32> %99 to <2 x i64>
  %101 = shufflevector <4 x i32> %95, <4 x i32> %98, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %102 = bitcast <4 x i32> %101 to <2 x i64>
  %103 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %104 = bitcast <2 x i64>* %103 to <4 x i32>*
  %105 = load <4 x i32>, <4 x i32>* %104, align 16
  %106 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %107 = bitcast <2 x i64>* %106 to <4 x i32>*
  %108 = load <4 x i32>, <4 x i32>* %107, align 16
  %109 = shufflevector <4 x i32> %105, <4 x i32> %108, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %110 = bitcast <4 x i32> %109 to <2 x i64>
  %111 = shufflevector <4 x i32> %105, <4 x i32> %108, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %112 = bitcast <4 x i32> %111 to <2 x i64>
  %113 = shufflevector <2 x i64> %100, <2 x i64> %110, <2 x i32> <i32 0, i32 2>
  %114 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 4
  store <2 x i64> %113, <2 x i64>* %114, align 16
  %115 = shufflevector <2 x i64> %100, <2 x i64> %110, <2 x i32> <i32 1, i32 3>
  %116 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 5
  store <2 x i64> %115, <2 x i64>* %116, align 16
  %117 = shufflevector <2 x i64> %102, <2 x i64> %112, <2 x i32> <i32 0, i32 2>
  %118 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 6
  store <2 x i64> %117, <2 x i64>* %118, align 16
  %119 = shufflevector <2 x i64> %102, <2 x i64> %112, <2 x i32> <i32 1, i32 3>
  %120 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 7
  store <2 x i64> %119, <2 x i64>* %120, align 16
  %121 = and i64 %57, 1
  %122 = sub nsw i64 %57, %121
  br label %123

123:                                              ; preds = %123, %54
  %124 = phi i64 [ 0, %54 ], [ %143, %123 ]
  %125 = phi i64 [ %122, %54 ], [ %144, %123 ]
  %126 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %124
  %127 = bitcast <2 x i64>* %126 to <4 x i32>*
  %128 = load <4 x i32>, <4 x i32>* %127, align 16
  %129 = mul <4 x i32> %128, <i32 2896, i32 2896, i32 2896, i32 2896>
  %130 = add <4 x i32> %129, <i32 2048, i32 2048, i32 2048, i32 2048>
  %131 = ashr <4 x i32> %130, <i32 12, i32 12, i32 12, i32 12>
  %132 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %124
  %133 = bitcast <2 x i64>* %132 to <4 x i32>*
  store <4 x i32> %131, <4 x i32>* %133, align 16
  %134 = or i64 %124, 1
  %135 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %134
  %136 = bitcast <2 x i64>* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 16
  %138 = mul <4 x i32> %137, <i32 2896, i32 2896, i32 2896, i32 2896>
  %139 = add <4 x i32> %138, <i32 2048, i32 2048, i32 2048, i32 2048>
  %140 = ashr <4 x i32> %139, <i32 12, i32 12, i32 12, i32 12>
  %141 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %134
  %142 = bitcast <2 x i64>* %141 to <4 x i32>*
  store <4 x i32> %140, <4 x i32>* %142, align 16
  %143 = add nuw nsw i64 %124, 2
  %144 = add i64 %125, -2
  %145 = icmp eq i64 %144, 0
  br i1 %145, label %146, label %123

146:                                              ; preds = %123
  %147 = icmp eq i64 %121, 0
  br i1 %147, label %157, label %148

148:                                              ; preds = %146
  %149 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %143
  %150 = bitcast <2 x i64>* %149 to <4 x i32>*
  %151 = load <4 x i32>, <4 x i32>* %150, align 16
  %152 = mul <4 x i32> %151, <i32 2896, i32 2896, i32 2896, i32 2896>
  %153 = add <4 x i32> %152, <i32 2048, i32 2048, i32 2048, i32 2048>
  %154 = ashr <4 x i32> %153, <i32 12, i32 12, i32 12, i32 12>
  %155 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %143
  %156 = bitcast <2 x i64>* %155 to <4 x i32>*
  store <4 x i32> %154, <4 x i32>* %156, align 16
  br label %157

157:                                              ; preds = %146, %148
  %158 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 0
  %159 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 %32, i64 %39
  %160 = load i8, i8* %159, align 1
  %161 = sext i8 %160 to i32
  %162 = load i8, i8* %21, align 1
  %163 = sext i8 %162 to i32
  %164 = sub nsw i32 0, %163
  call void %38(<2 x i64>* nonnull %158, <2 x i64>* nonnull %158, i32 %161, i32 0, i32 %8, i32 %164) #8
  %165 = icmp eq i32 %56, 0
  br i1 %165, label %200, label %166

166:                                              ; preds = %157
  %167 = and i64 %57, 1
  %168 = sub nsw i64 %57, %167
  br label %169

169:                                              ; preds = %169, %166
  %170 = phi i64 [ 0, %166 ], [ %187, %169 ]
  %171 = phi i64 [ %168, %166 ], [ %188, %169 ]
  %172 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %170
  %173 = load <2 x i64>, <2 x i64>* %172, align 16
  %174 = trunc i64 %170 to i32
  %175 = xor i32 %174, -1
  %176 = add i32 %29, %175
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %177
  store <2 x i64> %173, <2 x i64>* %178, align 16
  %179 = or i64 %170, 1
  %180 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %179
  %181 = load <2 x i64>, <2 x i64>* %180, align 16
  %182 = trunc i64 %179 to i32
  %183 = xor i32 %182, -1
  %184 = add i32 %29, %183
  %185 = sext i32 %184 to i64
  %186 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %185
  store <2 x i64> %181, <2 x i64>* %186, align 16
  %187 = add nuw nsw i64 %170, 2
  %188 = add i64 %171, -2
  %189 = icmp eq i64 %188, 0
  br i1 %189, label %190, label %169

190:                                              ; preds = %169
  %191 = icmp eq i64 %167, 0
  br i1 %191, label %200, label %192

192:                                              ; preds = %190
  %193 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 %187
  %194 = load <2 x i64>, <2 x i64>* %193, align 16
  %195 = trunc i64 %187 to i32
  %196 = xor i32 %195, -1
  %197 = add i32 %29, %196
  %198 = sext i32 %197 to i64
  %199 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %5, i64 0, i64 %198
  store <2 x i64> %194, <2 x i64>* %199, align 16
  br label %200

200:                                              ; preds = %192, %190, %157
  %201 = phi <2 x i64>* [ %158, %157 ], [ %86, %190 ], [ %86, %192 ]
  %202 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 %32, i64 %39
  %203 = load i8, i8* %202, align 1
  %204 = sext i8 %203 to i32
  %205 = sext i32 %31 to i64
  call void %44(<2 x i64>* %201, <2 x i64>* %201, i32 %204, i32 1, i32 %8, i32 0) #8
  %206 = getelementptr inbounds <2 x i64>, <2 x i64>* %201, i64 %205
  call void %44(<2 x i64>* %206, <2 x i64>* %206, i32 %204, i32 1, i32 %8, i32 0) #8
  %207 = getelementptr inbounds i8, i8* %21, i64 1
  %208 = load i8, i8* %207, align 1
  %209 = sext i8 %208 to i32
  %210 = sub nsw i32 0, %209
  %211 = icmp slt i8 %208, 0
  br i1 %211, label %218, label %212

212:                                              ; preds = %200
  %213 = add nsw i64 %57, -1
  %214 = and i64 %57, 3
  %215 = icmp ult i64 %213, 3
  br i1 %215, label %296, label %216

216:                                              ; preds = %212
  %217 = sub nsw i64 %57, %214
  br label %257

218:                                              ; preds = %200
  %219 = xor i32 %209, -1
  %220 = shl i32 1, %219
  %221 = insertelement <4 x i32> undef, i32 %220, i32 0
  %222 = shufflevector <4 x i32> %221, <4 x i32> undef, <4 x i32> zeroinitializer
  %223 = add nsw i64 %57, -1
  %224 = and i64 %57, 3
  %225 = icmp ult i64 %223, 3
  br i1 %225, label %282, label %226

226:                                              ; preds = %218
  %227 = sub nsw i64 %57, %224
  br label %228

228:                                              ; preds = %228, %226
  %229 = phi i64 [ 0, %226 ], [ %254, %228 ]
  %230 = phi i64 [ %227, %226 ], [ %255, %228 ]
  %231 = getelementptr inbounds <2 x i64>, <2 x i64>* %201, i64 %229
  %232 = bitcast <2 x i64>* %231 to <4 x i32>*
  %233 = load <4 x i32>, <4 x i32>* %232, align 16
  %234 = add <4 x i32> %233, %222
  %235 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %234, i32 %210) #8
  store <4 x i32> %235, <4 x i32>* %232, align 16
  %236 = or i64 %229, 1
  %237 = getelementptr inbounds <2 x i64>, <2 x i64>* %201, i64 %236
  %238 = bitcast <2 x i64>* %237 to <4 x i32>*
  %239 = load <4 x i32>, <4 x i32>* %238, align 16
  %240 = add <4 x i32> %239, %222
  %241 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %240, i32 %210) #8
  store <4 x i32> %241, <4 x i32>* %238, align 16
  %242 = or i64 %229, 2
  %243 = getelementptr inbounds <2 x i64>, <2 x i64>* %201, i64 %242
  %244 = bitcast <2 x i64>* %243 to <4 x i32>*
  %245 = load <4 x i32>, <4 x i32>* %244, align 16
  %246 = add <4 x i32> %245, %222
  %247 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %246, i32 %210) #8
  store <4 x i32> %247, <4 x i32>* %244, align 16
  %248 = or i64 %229, 3
  %249 = getelementptr inbounds <2 x i64>, <2 x i64>* %201, i64 %248
  %250 = bitcast <2 x i64>* %249 to <4 x i32>*
  %251 = load <4 x i32>, <4 x i32>* %250, align 16
  %252 = add <4 x i32> %251, %222
  %253 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %252, i32 %210) #8
  store <4 x i32> %253, <4 x i32>* %250, align 16
  %254 = add nuw nsw i64 %229, 4
  %255 = add i64 %230, -4
  %256 = icmp eq i64 %255, 0
  br i1 %256, label %282, label %228

257:                                              ; preds = %257, %216
  %258 = phi i64 [ 0, %216 ], [ %279, %257 ]
  %259 = phi i64 [ %217, %216 ], [ %280, %257 ]
  %260 = getelementptr inbounds <2 x i64>, <2 x i64>* %201, i64 %258
  %261 = bitcast <2 x i64>* %260 to <4 x i32>*
  %262 = load <4 x i32>, <4 x i32>* %261, align 16
  %263 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %262, i32 %209) #8
  store <4 x i32> %263, <4 x i32>* %261, align 16
  %264 = or i64 %258, 1
  %265 = getelementptr inbounds <2 x i64>, <2 x i64>* %201, i64 %264
  %266 = bitcast <2 x i64>* %265 to <4 x i32>*
  %267 = load <4 x i32>, <4 x i32>* %266, align 16
  %268 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %267, i32 %209) #8
  store <4 x i32> %268, <4 x i32>* %266, align 16
  %269 = or i64 %258, 2
  %270 = getelementptr inbounds <2 x i64>, <2 x i64>* %201, i64 %269
  %271 = bitcast <2 x i64>* %270 to <4 x i32>*
  %272 = load <4 x i32>, <4 x i32>* %271, align 16
  %273 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %272, i32 %209) #8
  store <4 x i32> %273, <4 x i32>* %271, align 16
  %274 = or i64 %258, 3
  %275 = getelementptr inbounds <2 x i64>, <2 x i64>* %201, i64 %274
  %276 = bitcast <2 x i64>* %275 to <4 x i32>*
  %277 = load <4 x i32>, <4 x i32>* %276, align 16
  %278 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %277, i32 %209) #8
  store <4 x i32> %278, <4 x i32>* %276, align 16
  %279 = add nuw nsw i64 %258, 4
  %280 = add i64 %259, -4
  %281 = icmp eq i64 %280, 0
  br i1 %281, label %296, label %257

282:                                              ; preds = %228, %218
  %283 = phi i64 [ 0, %218 ], [ %254, %228 ]
  %284 = icmp eq i64 %224, 0
  br i1 %284, label %309, label %285

285:                                              ; preds = %282, %285
  %286 = phi i64 [ %293, %285 ], [ %283, %282 ]
  %287 = phi i64 [ %294, %285 ], [ %224, %282 ]
  %288 = getelementptr inbounds <2 x i64>, <2 x i64>* %201, i64 %286
  %289 = bitcast <2 x i64>* %288 to <4 x i32>*
  %290 = load <4 x i32>, <4 x i32>* %289, align 16
  %291 = add <4 x i32> %290, %222
  %292 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %291, i32 %210) #8
  store <4 x i32> %292, <4 x i32>* %289, align 16
  %293 = add nuw nsw i64 %286, 1
  %294 = add i64 %287, -1
  %295 = icmp eq i64 %294, 0
  br i1 %295, label %309, label %285, !llvm.loop !14

296:                                              ; preds = %257, %212
  %297 = phi i64 [ 0, %212 ], [ %279, %257 ]
  %298 = icmp eq i64 %214, 0
  br i1 %298, label %309, label %299

299:                                              ; preds = %296, %299
  %300 = phi i64 [ %306, %299 ], [ %297, %296 ]
  %301 = phi i64 [ %307, %299 ], [ %214, %296 ]
  %302 = getelementptr inbounds <2 x i64>, <2 x i64>* %201, i64 %300
  %303 = bitcast <2 x i64>* %302 to <4 x i32>*
  %304 = load <4 x i32>, <4 x i32>* %303, align 16
  %305 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %304, i32 %209) #8
  store <4 x i32> %305, <4 x i32>* %303, align 16
  %306 = add nuw nsw i64 %300, 1
  %307 = add i64 %301, -1
  %308 = icmp eq i64 %307, 0
  br i1 %308, label %309, label %299, !llvm.loop !15

309:                                              ; preds = %296, %299, %282, %285
  %310 = icmp ne i32 %55, 0
  %311 = select i1 %310, i64 -1, i64 1
  %312 = add nsw i32 %31, -1
  %313 = select i1 %310, i32 %312, i32 0
  %314 = shl nsw i32 -1, %8
  %315 = xor i32 %314, -1
  %316 = insertelement <4 x i32> undef, i32 %315, i32 0
  %317 = shufflevector <4 x i32> %316, <4 x i32> undef, <4 x i32> zeroinitializer
  %318 = sext i32 %313 to i64
  %319 = sext i32 %2 to i64
  %320 = zext i32 %31 to i64
  br label %321

321:                                              ; preds = %321, %309
  %322 = phi i64 [ 0, %309 ], [ %355, %321 ]
  %323 = phi i64 [ %318, %309 ], [ %356, %321 ]
  %324 = mul nsw i64 %322, %319
  %325 = getelementptr inbounds i16, i16* %15, i64 %324
  %326 = bitcast i16* %325 to <2 x i64>*
  %327 = load <2 x i64>, <2 x i64>* %326, align 2
  %328 = getelementptr inbounds <2 x i64>, <2 x i64>* %201, i64 %323
  %329 = bitcast <2 x i64>* %328 to <4 x i32>*
  %330 = load <4 x i32>, <4 x i32>* %329, align 16
  %331 = add nsw i64 %323, %205
  %332 = getelementptr inbounds <2 x i64>, <2 x i64>* %201, i64 %331
  %333 = bitcast <2 x i64>* %332 to <4 x i32>*
  %334 = load <4 x i32>, <4 x i32>* %333, align 16
  %335 = bitcast <2 x i64> %327 to <8 x i16>
  %336 = shufflevector <8 x i16> %335, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %337 = sext <4 x i16> %336 to <4 x i32>
  %338 = bitcast <2 x i64> %327 to <16 x i8>
  %339 = shufflevector <16 x i8> %338, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %340 = bitcast <16 x i8> %339 to <8 x i16>
  %341 = shufflevector <8 x i16> %340, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %342 = sext <4 x i16> %341 to <4 x i32>
  %343 = add <4 x i32> %330, %337
  %344 = add <4 x i32> %334, %342
  %345 = icmp sgt <4 x i32> %343, zeroinitializer
  %346 = select <4 x i1> %345, <4 x i32> %343, <4 x i32> zeroinitializer
  %347 = icmp slt <4 x i32> %346, %317
  %348 = select <4 x i1> %347, <4 x i32> %346, <4 x i32> %317
  %349 = icmp sgt <4 x i32> %344, zeroinitializer
  %350 = select <4 x i1> %349, <4 x i32> %344, <4 x i32> zeroinitializer
  %351 = icmp slt <4 x i32> %350, %317
  %352 = select <4 x i1> %351, <4 x i32> %350, <4 x i32> %317
  %353 = call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %348, <4 x i32> %352) #8
  %354 = bitcast i16* %325 to <8 x i16>*
  store <8 x i16> %353, <8 x i16>* %354, align 2
  %355 = add nuw nsw i64 %322, 1
  %356 = add i64 %323, %311
  %357 = icmp eq i64 %355, %320
  br i1 %357, label %358, label %321

358:                                              ; preds = %321
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %17) #8
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_highbd_inv_txfm_add_4x16_sse4_1(i32* nocapture readonly, i8*, i32, %struct.txfm_param* nocapture readonly) local_unnamed_addr #0 {
  %5 = alloca [16 x <2 x i64>], align 16
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 3
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 0
  %10 = load i8, i8* %9, align 4
  %11 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 1
  %12 = load i8, i8* %11, align 1
  %13 = ptrtoint i8* %1 to i64
  %14 = shl i64 %13, 1
  %15 = inttoptr i64 %14 to i16*
  %16 = bitcast [16 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %16) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %16, i8 -86, i64 256, i1 false) #8
  %17 = zext i8 %12 to i64
  %18 = getelementptr inbounds [19 x i8*], [19 x i8*]* @av1_inv_txfm_shift_ls, i64 0, i64 %17
  %19 = load i8*, i8** %18, align 8
  %20 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide_log2, i64 0, i64 %17
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, -2
  %23 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high_log2, i64 0, i64 %17
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %24, -2
  %26 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide, i64 0, i64 %17
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high, i64 0, i64 %17
  %29 = load i32, i32* %28, align 4
  %30 = ashr i32 %29, 2
  %31 = sext i32 %22 to i64
  %32 = zext i8 %10 to i64
  %33 = getelementptr inbounds [16 x i8], [16 x i8]* @hitx_1d_tab, i64 0, i64 %32
  %34 = load i8, i8* %33, align 1
  %35 = zext i8 %34 to i64
  %36 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %31, i64 %35, i64 0
  %37 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %36, align 16
  %38 = sext i32 %25 to i64
  %39 = getelementptr inbounds [16 x i8], [16 x i8]* @vitx_1d_tab, i64 0, i64 %32
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i64
  %42 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %38, i64 %41, i64 2
  %43 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %42, align 16
  %44 = icmp slt i32 %27, 32
  %45 = select i1 %44, i32 %27, i32 32
  %46 = add i8 %10, -4
  %47 = icmp ult i8 %46, 12
  br i1 %47, label %48, label %55

48:                                               ; preds = %4
  %49 = sext i8 %46 to i64
  %50 = getelementptr inbounds [12 x i32], [12 x i32]* @switch.table.av1_highbd_inv_txfm_add_16x4_sse4_1, i64 0, i64 %49
  %51 = load i32, i32* %50, align 4
  %52 = sext i8 %46 to i64
  %53 = getelementptr inbounds [12 x i32], [12 x i32]* @switch.table.av1_highbd_inv_txfm_add_16x4_sse4_1.6, i64 0, i64 %52
  %54 = load i32, i32* %53, align 4
  br label %55

55:                                               ; preds = %48, %4
  %56 = phi i32 [ 0, %4 ], [ %51, %48 ]
  %57 = phi i32 [ 0, %4 ], [ %54, %48 ]
  %58 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %58) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %58, i8 -86, i64 256, i1 false) #8
  %59 = sext i32 %45 to i64
  %60 = zext i32 %29 to i64
  %61 = add nsw i64 %60, -1
  %62 = and i64 %60, 3
  %63 = icmp ult i64 %61, 3
  br i1 %63, label %95, label %64

64:                                               ; preds = %55
  %65 = sub nsw i64 %60, %62
  br label %66

66:                                               ; preds = %66, %64
  %67 = phi i64 [ 0, %64 ], [ %92, %66 ]
  %68 = phi i64 [ %65, %64 ], [ %93, %66 ]
  %69 = mul nsw i64 %67, %59
  %70 = getelementptr inbounds i32, i32* %0, i64 %69
  %71 = bitcast i32* %70 to <2 x i64>*
  %72 = load <2 x i64>, <2 x i64>* %71, align 1
  %73 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %67
  store <2 x i64> %72, <2 x i64>* %73, align 16
  %74 = or i64 %67, 1
  %75 = mul nsw i64 %74, %59
  %76 = getelementptr inbounds i32, i32* %0, i64 %75
  %77 = bitcast i32* %76 to <2 x i64>*
  %78 = load <2 x i64>, <2 x i64>* %77, align 1
  %79 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %74
  store <2 x i64> %78, <2 x i64>* %79, align 16
  %80 = or i64 %67, 2
  %81 = mul nsw i64 %80, %59
  %82 = getelementptr inbounds i32, i32* %0, i64 %81
  %83 = bitcast i32* %82 to <2 x i64>*
  %84 = load <2 x i64>, <2 x i64>* %83, align 1
  %85 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %80
  store <2 x i64> %84, <2 x i64>* %85, align 16
  %86 = or i64 %67, 3
  %87 = mul nsw i64 %86, %59
  %88 = getelementptr inbounds i32, i32* %0, i64 %87
  %89 = bitcast i32* %88 to <2 x i64>*
  %90 = load <2 x i64>, <2 x i64>* %89, align 1
  %91 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %86
  store <2 x i64> %90, <2 x i64>* %91, align 16
  %92 = add nuw nsw i64 %67, 4
  %93 = add i64 %68, -4
  %94 = icmp eq i64 %93, 0
  br i1 %94, label %95, label %66

95:                                               ; preds = %66, %55
  %96 = phi i64 [ 0, %55 ], [ %92, %66 ]
  %97 = icmp eq i64 %62, 0
  br i1 %97, label %109, label %98

98:                                               ; preds = %95, %98
  %99 = phi i64 [ %106, %98 ], [ %96, %95 ]
  %100 = phi i64 [ %107, %98 ], [ %62, %95 ]
  %101 = mul nsw i64 %99, %59
  %102 = getelementptr inbounds i32, i32* %0, i64 %101
  %103 = bitcast i32* %102 to <2 x i64>*
  %104 = load <2 x i64>, <2 x i64>* %103, align 1
  %105 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %99
  store <2 x i64> %104, <2 x i64>* %105, align 16
  %106 = add nuw nsw i64 %99, 1
  %107 = add i64 %100, -1
  %108 = icmp eq i64 %107, 0
  br i1 %108, label %109, label %98, !llvm.loop !16

109:                                              ; preds = %98, %95
  %110 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 %31, i64 %38
  %111 = load i8, i8* %110, align 1
  %112 = sext i8 %111 to i32
  %113 = sext i32 %30 to i64
  br label %116

114:                                              ; preds = %116
  %115 = icmp eq i32 %57, 0
  br i1 %115, label %161, label %125

116:                                              ; preds = %116, %109
  %117 = phi i64 [ 0, %109 ], [ %123, %116 ]
  %118 = shl i64 %117, 2
  %119 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %118
  %120 = load i8, i8* %19, align 1
  %121 = sext i8 %120 to i32
  %122 = sub nsw i32 0, %121
  call void %37(<2 x i64>* %119, <2 x i64>* %119, i32 %112, i32 0, i32 %8, i32 %122) #8
  %123 = add nuw nsw i64 %117, 1
  %124 = icmp slt i64 %123, %113
  br i1 %124, label %116, label %114

125:                                              ; preds = %114, %125
  %126 = phi i64 [ %159, %125 ], [ 0, %114 ]
  %127 = shl nsw i64 %126, 2
  %128 = or i64 %127, 3
  %129 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %128
  %130 = bitcast <2 x i64>* %129 to <4 x i32>*
  %131 = load <4 x i32>, <4 x i32>* %130, align 16
  %132 = or i64 %127, 2
  %133 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %132
  %134 = bitcast <2 x i64>* %133 to <4 x i32>*
  %135 = load <4 x i32>, <4 x i32>* %134, align 16
  %136 = shufflevector <4 x i32> %131, <4 x i32> %135, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %137 = bitcast <4 x i32> %136 to <2 x i64>
  %138 = shufflevector <4 x i32> %131, <4 x i32> %135, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %139 = bitcast <4 x i32> %138 to <2 x i64>
  %140 = or i64 %127, 1
  %141 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %140
  %142 = bitcast <2 x i64>* %141 to <4 x i32>*
  %143 = load <4 x i32>, <4 x i32>* %142, align 16
  %144 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %127
  %145 = bitcast <2 x i64>* %144 to <4 x i32>*
  %146 = load <4 x i32>, <4 x i32>* %145, align 16
  %147 = shufflevector <4 x i32> %143, <4 x i32> %146, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %148 = bitcast <4 x i32> %147 to <2 x i64>
  %149 = shufflevector <4 x i32> %143, <4 x i32> %146, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %150 = bitcast <4 x i32> %149 to <2 x i64>
  %151 = shufflevector <2 x i64> %137, <2 x i64> %148, <2 x i32> <i32 0, i32 2>
  %152 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %127
  store <2 x i64> %151, <2 x i64>* %152, align 16
  %153 = shufflevector <2 x i64> %137, <2 x i64> %148, <2 x i32> <i32 1, i32 3>
  %154 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %140
  store <2 x i64> %153, <2 x i64>* %154, align 16
  %155 = shufflevector <2 x i64> %139, <2 x i64> %150, <2 x i32> <i32 0, i32 2>
  %156 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %132
  store <2 x i64> %155, <2 x i64>* %156, align 16
  %157 = shufflevector <2 x i64> %139, <2 x i64> %150, <2 x i32> <i32 1, i32 3>
  %158 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %128
  store <2 x i64> %157, <2 x i64>* %158, align 16
  %159 = add nuw nsw i64 %126, 1
  %160 = icmp slt i64 %159, %113
  br i1 %160, label %125, label %197

161:                                              ; preds = %114, %161
  %162 = phi i64 [ %195, %161 ], [ 0, %114 ]
  %163 = shl nsw i64 %162, 2
  %164 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %163
  %165 = bitcast <2 x i64>* %164 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = or i64 %163, 1
  %168 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %167
  %169 = bitcast <2 x i64>* %168 to <4 x i32>*
  %170 = load <4 x i32>, <4 x i32>* %169, align 16
  %171 = shufflevector <4 x i32> %166, <4 x i32> %170, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %172 = bitcast <4 x i32> %171 to <2 x i64>
  %173 = shufflevector <4 x i32> %166, <4 x i32> %170, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %174 = bitcast <4 x i32> %173 to <2 x i64>
  %175 = or i64 %163, 2
  %176 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %175
  %177 = bitcast <2 x i64>* %176 to <4 x i32>*
  %178 = load <4 x i32>, <4 x i32>* %177, align 16
  %179 = or i64 %163, 3
  %180 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %179
  %181 = bitcast <2 x i64>* %180 to <4 x i32>*
  %182 = load <4 x i32>, <4 x i32>* %181, align 16
  %183 = shufflevector <4 x i32> %178, <4 x i32> %182, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %184 = bitcast <4 x i32> %183 to <2 x i64>
  %185 = shufflevector <4 x i32> %178, <4 x i32> %182, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %186 = bitcast <4 x i32> %185 to <2 x i64>
  %187 = shufflevector <2 x i64> %172, <2 x i64> %184, <2 x i32> <i32 0, i32 2>
  %188 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %163
  store <2 x i64> %187, <2 x i64>* %188, align 16
  %189 = shufflevector <2 x i64> %172, <2 x i64> %184, <2 x i32> <i32 1, i32 3>
  %190 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %167
  store <2 x i64> %189, <2 x i64>* %190, align 16
  %191 = shufflevector <2 x i64> %174, <2 x i64> %186, <2 x i32> <i32 0, i32 2>
  %192 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %175
  store <2 x i64> %191, <2 x i64>* %192, align 16
  %193 = shufflevector <2 x i64> %174, <2 x i64> %186, <2 x i32> <i32 1, i32 3>
  %194 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %179
  store <2 x i64> %193, <2 x i64>* %194, align 16
  %195 = add nuw nsw i64 %162, 1
  %196 = icmp slt i64 %195, %113
  br i1 %196, label %161, label %197

197:                                              ; preds = %125, %161
  %198 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 0
  %199 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 %31, i64 %38
  %200 = load i8, i8* %199, align 1
  %201 = sext i8 %200 to i32
  call void %43(<2 x i64>* nonnull %198, <2 x i64>* nonnull %198, i32 %201, i32 1, i32 %8, i32 0) #8
  %202 = getelementptr inbounds i8, i8* %19, i64 1
  %203 = load i8, i8* %202, align 1
  %204 = sext i8 %203 to i32
  %205 = sub nsw i32 0, %204
  %206 = icmp slt i8 %203, 0
  br i1 %206, label %213, label %207

207:                                              ; preds = %197
  %208 = add nsw i64 %60, -1
  %209 = and i64 %60, 3
  %210 = icmp ult i64 %208, 3
  br i1 %210, label %291, label %211

211:                                              ; preds = %207
  %212 = sub nsw i64 %60, %209
  br label %252

213:                                              ; preds = %197
  %214 = xor i32 %204, -1
  %215 = shl i32 1, %214
  %216 = insertelement <4 x i32> undef, i32 %215, i32 0
  %217 = shufflevector <4 x i32> %216, <4 x i32> undef, <4 x i32> zeroinitializer
  %218 = add nsw i64 %60, -1
  %219 = and i64 %60, 3
  %220 = icmp ult i64 %218, 3
  br i1 %220, label %277, label %221

221:                                              ; preds = %213
  %222 = sub nsw i64 %60, %219
  br label %223

223:                                              ; preds = %223, %221
  %224 = phi i64 [ 0, %221 ], [ %249, %223 ]
  %225 = phi i64 [ %222, %221 ], [ %250, %223 ]
  %226 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %224
  %227 = bitcast <2 x i64>* %226 to <4 x i32>*
  %228 = load <4 x i32>, <4 x i32>* %227, align 16
  %229 = add <4 x i32> %228, %217
  %230 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %229, i32 %205) #8
  store <4 x i32> %230, <4 x i32>* %227, align 16
  %231 = or i64 %224, 1
  %232 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %231
  %233 = bitcast <2 x i64>* %232 to <4 x i32>*
  %234 = load <4 x i32>, <4 x i32>* %233, align 16
  %235 = add <4 x i32> %234, %217
  %236 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %235, i32 %205) #8
  store <4 x i32> %236, <4 x i32>* %233, align 16
  %237 = or i64 %224, 2
  %238 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %237
  %239 = bitcast <2 x i64>* %238 to <4 x i32>*
  %240 = load <4 x i32>, <4 x i32>* %239, align 16
  %241 = add <4 x i32> %240, %217
  %242 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %241, i32 %205) #8
  store <4 x i32> %242, <4 x i32>* %239, align 16
  %243 = or i64 %224, 3
  %244 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %243
  %245 = bitcast <2 x i64>* %244 to <4 x i32>*
  %246 = load <4 x i32>, <4 x i32>* %245, align 16
  %247 = add <4 x i32> %246, %217
  %248 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %247, i32 %205) #8
  store <4 x i32> %248, <4 x i32>* %245, align 16
  %249 = add nuw nsw i64 %224, 4
  %250 = add i64 %225, -4
  %251 = icmp eq i64 %250, 0
  br i1 %251, label %277, label %223

252:                                              ; preds = %252, %211
  %253 = phi i64 [ 0, %211 ], [ %274, %252 ]
  %254 = phi i64 [ %212, %211 ], [ %275, %252 ]
  %255 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %253
  %256 = bitcast <2 x i64>* %255 to <4 x i32>*
  %257 = load <4 x i32>, <4 x i32>* %256, align 16
  %258 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %257, i32 %204) #8
  store <4 x i32> %258, <4 x i32>* %256, align 16
  %259 = or i64 %253, 1
  %260 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %259
  %261 = bitcast <2 x i64>* %260 to <4 x i32>*
  %262 = load <4 x i32>, <4 x i32>* %261, align 16
  %263 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %262, i32 %204) #8
  store <4 x i32> %263, <4 x i32>* %261, align 16
  %264 = or i64 %253, 2
  %265 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %264
  %266 = bitcast <2 x i64>* %265 to <4 x i32>*
  %267 = load <4 x i32>, <4 x i32>* %266, align 16
  %268 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %267, i32 %204) #8
  store <4 x i32> %268, <4 x i32>* %266, align 16
  %269 = or i64 %253, 3
  %270 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %269
  %271 = bitcast <2 x i64>* %270 to <4 x i32>*
  %272 = load <4 x i32>, <4 x i32>* %271, align 16
  %273 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %272, i32 %204) #8
  store <4 x i32> %273, <4 x i32>* %271, align 16
  %274 = add nuw nsw i64 %253, 4
  %275 = add i64 %254, -4
  %276 = icmp eq i64 %275, 0
  br i1 %276, label %291, label %252

277:                                              ; preds = %223, %213
  %278 = phi i64 [ 0, %213 ], [ %249, %223 ]
  %279 = icmp eq i64 %219, 0
  br i1 %279, label %304, label %280

280:                                              ; preds = %277, %280
  %281 = phi i64 [ %288, %280 ], [ %278, %277 ]
  %282 = phi i64 [ %289, %280 ], [ %219, %277 ]
  %283 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %281
  %284 = bitcast <2 x i64>* %283 to <4 x i32>*
  %285 = load <4 x i32>, <4 x i32>* %284, align 16
  %286 = add <4 x i32> %285, %217
  %287 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %286, i32 %205) #8
  store <4 x i32> %287, <4 x i32>* %284, align 16
  %288 = add nuw nsw i64 %281, 1
  %289 = add i64 %282, -1
  %290 = icmp eq i64 %289, 0
  br i1 %290, label %304, label %280, !llvm.loop !17

291:                                              ; preds = %252, %207
  %292 = phi i64 [ 0, %207 ], [ %274, %252 ]
  %293 = icmp eq i64 %209, 0
  br i1 %293, label %304, label %294

294:                                              ; preds = %291, %294
  %295 = phi i64 [ %301, %294 ], [ %292, %291 ]
  %296 = phi i64 [ %302, %294 ], [ %209, %291 ]
  %297 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %295
  %298 = bitcast <2 x i64>* %297 to <4 x i32>*
  %299 = load <4 x i32>, <4 x i32>* %298, align 16
  %300 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %299, i32 %204) #8
  store <4 x i32> %300, <4 x i32>* %298, align 16
  %301 = add nuw nsw i64 %295, 1
  %302 = add i64 %296, -1
  %303 = icmp eq i64 %302, 0
  br i1 %303, label %304, label %294, !llvm.loop !18

304:                                              ; preds = %291, %294, %277, %280
  %305 = icmp ne i32 %56, 0
  %306 = select i1 %305, i64 -1, i64 1
  %307 = add nsw i32 %29, -1
  %308 = select i1 %305, i32 %307, i32 0
  %309 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %8) #8
  %310 = add <8 x i16> %309, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  %311 = sext i32 %308 to i64
  %312 = sext i32 %2 to i64
  br label %313

313:                                              ; preds = %313, %304
  %314 = phi i64 [ 0, %304 ], [ %344, %313 ]
  %315 = phi i64 [ %311, %304 ], [ %345, %313 ]
  %316 = mul nsw i64 %314, %312
  %317 = getelementptr inbounds i16, i16* %15, i64 %316
  %318 = bitcast i16* %317 to i64*
  %319 = load i64, i64* %318, align 2
  %320 = insertelement <2 x i64> undef, i64 %319, i32 0
  %321 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %315
  %322 = bitcast <2 x i64>* %321 to <4 x i32>*
  %323 = load <4 x i32>, <4 x i32>* %322, align 16
  %324 = bitcast <2 x i64> %320 to <8 x i16>
  %325 = shufflevector <8 x i16> %324, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %326 = sext <4 x i16> %325 to <4 x i32>
  %327 = add <4 x i32> %323, %326
  %328 = call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %327, <4 x i32> %327) #8
  %329 = bitcast <8 x i16> %328 to <2 x i64>
  %330 = icmp slt <8 x i16> %310, %328
  %331 = sext <8 x i1> %330 to <8 x i16>
  %332 = bitcast <8 x i16> %331 to <2 x i64>
  %333 = xor <2 x i64> %332, <i64 -1, i64 -1>
  %334 = and <2 x i64> %333, %329
  %335 = and <8 x i16> %310, %331
  %336 = bitcast <8 x i16> %335 to <2 x i64>
  %337 = or <2 x i64> %334, %336
  %338 = bitcast <2 x i64> %337 to <8 x i16>
  %339 = icmp sgt <8 x i16> %338, zeroinitializer
  %340 = sext <8 x i1> %339 to <8 x i16>
  %341 = bitcast <8 x i16> %340 to <2 x i64>
  %342 = and <2 x i64> %337, %341
  %343 = extractelement <2 x i64> %342, i32 0
  store i64 %343, i64* %318, align 2
  %344 = add nuw nsw i64 %314, 1
  %345 = add i64 %315, %306
  %346 = icmp eq i64 %344, %60
  br i1 %346, label %347, label %313

347:                                              ; preds = %313
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %58) #8
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %16) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_highbd_inv_txfm_add_16x4_sse4_1(i32* nocapture readonly, i8*, i32, %struct.txfm_param* nocapture readonly) local_unnamed_addr #0 {
  %5 = alloca [16 x <2 x i64>], align 16
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 3
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 0
  %10 = load i8, i8* %9, align 4
  %11 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 1
  %12 = load i8, i8* %11, align 1
  %13 = ptrtoint i8* %1 to i64
  %14 = shl i64 %13, 1
  %15 = inttoptr i64 %14 to i16*
  %16 = bitcast i32* %0 to i8*
  %17 = bitcast [16 x <2 x i64>]* %6 to i8*
  %18 = bitcast [16 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %18) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %18, i8 -86, i64 256, i1 false) #8
  %19 = zext i8 %12 to i64
  %20 = getelementptr inbounds [19 x i8*], [19 x i8*]* @av1_inv_txfm_shift_ls, i64 0, i64 %19
  %21 = load i8*, i8** %20, align 8
  %22 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide_log2, i64 0, i64 %19
  %23 = load i32, i32* %22, align 4
  %24 = add nsw i32 %23, -2
  %25 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high_log2, i64 0, i64 %19
  %26 = load i32, i32* %25, align 4
  %27 = add nsw i32 %26, -2
  %28 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_wide, i64 0, i64 %19
  %29 = load i32, i32* %28, align 4
  %30 = getelementptr inbounds [19 x i32], [19 x i32]* @tx_size_high, i64 0, i64 %19
  %31 = load i32, i32* %30, align 4
  %32 = ashr i32 %29, 2
  %33 = sext i32 %24 to i64
  %34 = zext i8 %10 to i64
  %35 = getelementptr inbounds [16 x i8], [16 x i8]* @hitx_1d_tab, i64 0, i64 %34
  %36 = load i8, i8* %35, align 1
  %37 = zext i8 %36 to i64
  %38 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %33, i64 %37, i64 2
  %39 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %38, align 16
  %40 = sext i32 %27 to i64
  %41 = getelementptr inbounds [16 x i8], [16 x i8]* @vitx_1d_tab, i64 0, i64 %34
  %42 = load i8, i8* %41, align 1
  %43 = zext i8 %42 to i64
  %44 = getelementptr inbounds [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]], [5 x [3 x [4 x void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*]]]* @highbd_txfm_all_1d_zeros_w8_arr, i64 0, i64 %40, i64 %43, i64 0
  %45 = load void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)*, void (<2 x i64>*, <2 x i64>*, i32, i32, i32, i32)** %44, align 16
  %46 = add i8 %10, -4
  %47 = icmp ult i8 %46, 12
  br i1 %47, label %48, label %55

48:                                               ; preds = %4
  %49 = sext i8 %46 to i64
  %50 = getelementptr inbounds [12 x i32], [12 x i32]* @switch.table.av1_highbd_inv_txfm_add_16x4_sse4_1, i64 0, i64 %49
  %51 = load i32, i32* %50, align 4
  %52 = sext i8 %46 to i64
  %53 = getelementptr inbounds [12 x i32], [12 x i32]* @switch.table.av1_highbd_inv_txfm_add_16x4_sse4_1.6, i64 0, i64 %52
  %54 = load i32, i32* %53, align 4
  br label %55

55:                                               ; preds = %48, %4
  %56 = phi i32 [ 0, %4 ], [ %51, %48 ]
  %57 = phi i32 [ 0, %4 ], [ %54, %48 ]
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %17) #8
  %58 = zext i32 %29 to i64
  %59 = shl nuw nsw i64 %58, 4
  %60 = lshr i64 483100, %19
  %61 = and i64 %60, 1
  %62 = icmp eq i64 %61, 0
  %63 = sub nsw i64 256, %59
  %64 = select i1 %62, i64 %63, i64 0
  %65 = getelementptr [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %58
  %66 = bitcast <2 x i64>* %65 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %66, i8 -86, i64 %64, i1 false) #8
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %17, i8* align 1 %16, i64 %59, i1 false) #8
  %67 = sext i32 %32 to i64
  br label %81

68:                                               ; preds = %81
  %69 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %70 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 0
  %71 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_row, i64 0, i64 %33, i64 %40
  %72 = load i8, i8* %71, align 1
  %73 = sext i8 %72 to i32
  %74 = load i8, i8* %21, align 1
  %75 = sext i8 %74 to i32
  %76 = sub nsw i32 0, %75
  call void %39(<2 x i64>* nonnull %70, <2 x i64>* nonnull %69, i32 %73, i32 0, i32 %8, i32 %76) #8
  %77 = icmp eq i32 %57, 0
  br i1 %77, label %151, label %78

78:                                               ; preds = %68
  %79 = and i64 %58, 1
  %80 = sub nsw i64 %58, %79
  br label %120

81:                                               ; preds = %81, %55
  %82 = phi i64 [ 0, %55 ], [ %118, %81 ]
  %83 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %82
  %84 = bitcast <2 x i64>* %83 to <4 x i32>*
  %85 = load <4 x i32>, <4 x i32>* %84, align 16
  %86 = add nuw nsw i64 %82, 4
  %87 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %86
  %88 = bitcast <2 x i64>* %87 to <4 x i32>*
  %89 = load <4 x i32>, <4 x i32>* %88, align 16
  %90 = shufflevector <4 x i32> %85, <4 x i32> %89, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %91 = bitcast <4 x i32> %90 to <2 x i64>
  %92 = shufflevector <4 x i32> %85, <4 x i32> %89, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %93 = bitcast <4 x i32> %92 to <2 x i64>
  %94 = add nuw nsw i64 %82, 8
  %95 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %94
  %96 = bitcast <2 x i64>* %95 to <4 x i32>*
  %97 = load <4 x i32>, <4 x i32>* %96, align 16
  %98 = add nuw nsw i64 %82, 12
  %99 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %98
  %100 = bitcast <2 x i64>* %99 to <4 x i32>*
  %101 = load <4 x i32>, <4 x i32>* %100, align 16
  %102 = shufflevector <4 x i32> %97, <4 x i32> %101, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %103 = bitcast <4 x i32> %102 to <2 x i64>
  %104 = shufflevector <4 x i32> %97, <4 x i32> %101, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %105 = bitcast <4 x i32> %104 to <2 x i64>
  %106 = shufflevector <2 x i64> %91, <2 x i64> %103, <2 x i32> <i32 0, i32 2>
  %107 = shl nsw i64 %82, 2
  %108 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %107
  store <2 x i64> %106, <2 x i64>* %108, align 16
  %109 = shufflevector <2 x i64> %91, <2 x i64> %103, <2 x i32> <i32 1, i32 3>
  %110 = or i64 %107, 1
  %111 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %110
  store <2 x i64> %109, <2 x i64>* %111, align 16
  %112 = shufflevector <2 x i64> %93, <2 x i64> %105, <2 x i32> <i32 0, i32 2>
  %113 = or i64 %107, 2
  %114 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %113
  store <2 x i64> %112, <2 x i64>* %114, align 16
  %115 = shufflevector <2 x i64> %93, <2 x i64> %105, <2 x i32> <i32 1, i32 3>
  %116 = or i64 %107, 3
  %117 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %116
  store <2 x i64> %115, <2 x i64>* %117, align 16
  %118 = add nuw nsw i64 %82, 1
  %119 = icmp slt i64 %118, %67
  br i1 %119, label %81, label %68

120:                                              ; preds = %120, %78
  %121 = phi i64 [ 0, %78 ], [ %138, %120 ]
  %122 = phi i64 [ %80, %78 ], [ %139, %120 ]
  %123 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %121
  %124 = load <2 x i64>, <2 x i64>* %123, align 16
  %125 = trunc i64 %121 to i32
  %126 = xor i32 %125, -1
  %127 = add i32 %29, %126
  %128 = sext i32 %127 to i64
  %129 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %128
  store <2 x i64> %124, <2 x i64>* %129, align 16
  %130 = or i64 %121, 1
  %131 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %130
  %132 = load <2 x i64>, <2 x i64>* %131, align 16
  %133 = trunc i64 %130 to i32
  %134 = xor i32 %133, -1
  %135 = add i32 %29, %134
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %136
  store <2 x i64> %132, <2 x i64>* %137, align 16
  %138 = add nuw nsw i64 %121, 2
  %139 = add i64 %122, -2
  %140 = icmp eq i64 %139, 0
  br i1 %140, label %141, label %120

141:                                              ; preds = %120
  %142 = icmp eq i64 %79, 0
  br i1 %142, label %151, label %143

143:                                              ; preds = %141
  %144 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %138
  %145 = load <2 x i64>, <2 x i64>* %144, align 16
  %146 = trunc i64 %138 to i32
  %147 = xor i32 %146, -1
  %148 = add i32 %29, %147
  %149 = sext i32 %148 to i64
  %150 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %149
  store <2 x i64> %145, <2 x i64>* %150, align 16
  br label %151

151:                                              ; preds = %143, %141, %68
  %152 = phi <2 x i64>* [ %69, %68 ], [ %70, %141 ], [ %70, %143 ]
  %153 = getelementptr inbounds [5 x [5 x i8]], [5 x [5 x i8]]* @av1_inv_cos_bit_col, i64 0, i64 %33, i64 %40
  %154 = load i8, i8* %153, align 1
  %155 = sext i8 %154 to i32
  %156 = sext i32 %31 to i64
  br label %279

157:                                              ; preds = %279
  %158 = getelementptr inbounds i8, i8* %21, i64 1
  %159 = load i8, i8* %158, align 1
  %160 = sext i8 %159 to i32
  %161 = sub nsw i32 0, %160
  %162 = icmp slt i8 %159, 0
  br i1 %162, label %169, label %163

163:                                              ; preds = %157
  %164 = add nsw i64 %58, -1
  %165 = and i64 %58, 3
  %166 = icmp ult i64 %164, 3
  br i1 %166, label %247, label %167

167:                                              ; preds = %163
  %168 = sub nsw i64 %58, %165
  br label %208

169:                                              ; preds = %157
  %170 = xor i32 %160, -1
  %171 = shl i32 1, %170
  %172 = insertelement <4 x i32> undef, i32 %171, i32 0
  %173 = shufflevector <4 x i32> %172, <4 x i32> undef, <4 x i32> zeroinitializer
  %174 = add nsw i64 %58, -1
  %175 = and i64 %58, 3
  %176 = icmp ult i64 %174, 3
  br i1 %176, label %233, label %177

177:                                              ; preds = %169
  %178 = sub nsw i64 %58, %175
  br label %179

179:                                              ; preds = %179, %177
  %180 = phi i64 [ 0, %177 ], [ %205, %179 ]
  %181 = phi i64 [ %178, %177 ], [ %206, %179 ]
  %182 = getelementptr inbounds <2 x i64>, <2 x i64>* %152, i64 %180
  %183 = bitcast <2 x i64>* %182 to <4 x i32>*
  %184 = load <4 x i32>, <4 x i32>* %183, align 16
  %185 = add <4 x i32> %184, %173
  %186 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %185, i32 %161) #8
  store <4 x i32> %186, <4 x i32>* %183, align 16
  %187 = or i64 %180, 1
  %188 = getelementptr inbounds <2 x i64>, <2 x i64>* %152, i64 %187
  %189 = bitcast <2 x i64>* %188 to <4 x i32>*
  %190 = load <4 x i32>, <4 x i32>* %189, align 16
  %191 = add <4 x i32> %190, %173
  %192 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %191, i32 %161) #8
  store <4 x i32> %192, <4 x i32>* %189, align 16
  %193 = or i64 %180, 2
  %194 = getelementptr inbounds <2 x i64>, <2 x i64>* %152, i64 %193
  %195 = bitcast <2 x i64>* %194 to <4 x i32>*
  %196 = load <4 x i32>, <4 x i32>* %195, align 16
  %197 = add <4 x i32> %196, %173
  %198 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %197, i32 %161) #8
  store <4 x i32> %198, <4 x i32>* %195, align 16
  %199 = or i64 %180, 3
  %200 = getelementptr inbounds <2 x i64>, <2 x i64>* %152, i64 %199
  %201 = bitcast <2 x i64>* %200 to <4 x i32>*
  %202 = load <4 x i32>, <4 x i32>* %201, align 16
  %203 = add <4 x i32> %202, %173
  %204 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %203, i32 %161) #8
  store <4 x i32> %204, <4 x i32>* %201, align 16
  %205 = add nuw nsw i64 %180, 4
  %206 = add i64 %181, -4
  %207 = icmp eq i64 %206, 0
  br i1 %207, label %233, label %179

208:                                              ; preds = %208, %167
  %209 = phi i64 [ 0, %167 ], [ %230, %208 ]
  %210 = phi i64 [ %168, %167 ], [ %231, %208 ]
  %211 = getelementptr inbounds <2 x i64>, <2 x i64>* %152, i64 %209
  %212 = bitcast <2 x i64>* %211 to <4 x i32>*
  %213 = load <4 x i32>, <4 x i32>* %212, align 16
  %214 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %213, i32 %160) #8
  store <4 x i32> %214, <4 x i32>* %212, align 16
  %215 = or i64 %209, 1
  %216 = getelementptr inbounds <2 x i64>, <2 x i64>* %152, i64 %215
  %217 = bitcast <2 x i64>* %216 to <4 x i32>*
  %218 = load <4 x i32>, <4 x i32>* %217, align 16
  %219 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %218, i32 %160) #8
  store <4 x i32> %219, <4 x i32>* %217, align 16
  %220 = or i64 %209, 2
  %221 = getelementptr inbounds <2 x i64>, <2 x i64>* %152, i64 %220
  %222 = bitcast <2 x i64>* %221 to <4 x i32>*
  %223 = load <4 x i32>, <4 x i32>* %222, align 16
  %224 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %223, i32 %160) #8
  store <4 x i32> %224, <4 x i32>* %222, align 16
  %225 = or i64 %209, 3
  %226 = getelementptr inbounds <2 x i64>, <2 x i64>* %152, i64 %225
  %227 = bitcast <2 x i64>* %226 to <4 x i32>*
  %228 = load <4 x i32>, <4 x i32>* %227, align 16
  %229 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %228, i32 %160) #8
  store <4 x i32> %229, <4 x i32>* %227, align 16
  %230 = add nuw nsw i64 %209, 4
  %231 = add i64 %210, -4
  %232 = icmp eq i64 %231, 0
  br i1 %232, label %247, label %208

233:                                              ; preds = %179, %169
  %234 = phi i64 [ 0, %169 ], [ %205, %179 ]
  %235 = icmp eq i64 %175, 0
  br i1 %235, label %260, label %236

236:                                              ; preds = %233, %236
  %237 = phi i64 [ %244, %236 ], [ %234, %233 ]
  %238 = phi i64 [ %245, %236 ], [ %175, %233 ]
  %239 = getelementptr inbounds <2 x i64>, <2 x i64>* %152, i64 %237
  %240 = bitcast <2 x i64>* %239 to <4 x i32>*
  %241 = load <4 x i32>, <4 x i32>* %240, align 16
  %242 = add <4 x i32> %241, %173
  %243 = call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %242, i32 %161) #8
  store <4 x i32> %243, <4 x i32>* %240, align 16
  %244 = add nuw nsw i64 %237, 1
  %245 = add i64 %238, -1
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %260, label %236, !llvm.loop !19

247:                                              ; preds = %208, %163
  %248 = phi i64 [ 0, %163 ], [ %230, %208 ]
  %249 = icmp eq i64 %165, 0
  br i1 %249, label %260, label %250

250:                                              ; preds = %247, %250
  %251 = phi i64 [ %257, %250 ], [ %248, %247 ]
  %252 = phi i64 [ %258, %250 ], [ %165, %247 ]
  %253 = getelementptr inbounds <2 x i64>, <2 x i64>* %152, i64 %251
  %254 = bitcast <2 x i64>* %253 to <4 x i32>*
  %255 = load <4 x i32>, <4 x i32>* %254, align 16
  %256 = call <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32> %255, i32 %160) #8
  store <4 x i32> %256, <4 x i32>* %254, align 16
  %257 = add nuw nsw i64 %251, 1
  %258 = add i64 %252, -1
  %259 = icmp eq i64 %258, 0
  br i1 %259, label %260, label %250, !llvm.loop !20

260:                                              ; preds = %247, %250, %233, %236
  %261 = lshr i64 516062, %19
  %262 = and i64 %261, 1
  %263 = icmp eq i64 %262, 0
  br i1 %263, label %333, label %264

264:                                              ; preds = %260
  %265 = ashr i32 %29, 3
  %266 = shl i32 %31, 1
  %267 = icmp ne i32 %56, 0
  %268 = select i1 %267, i64 -1, i64 1
  %269 = add nsw i32 %31, -1
  %270 = select i1 %267, i32 %269, i32 0
  %271 = shl nsw i32 -1, %8
  %272 = xor i32 %271, -1
  %273 = insertelement <4 x i32> undef, i32 %272, i32 0
  %274 = shufflevector <4 x i32> %273, <4 x i32> undef, <4 x i32> zeroinitializer
  %275 = sext i32 %270 to i64
  %276 = sext i32 %2 to i64
  %277 = zext i32 %31 to i64
  %278 = sext i32 %265 to i64
  br label %285

279:                                              ; preds = %279, %151
  %280 = phi i64 [ 0, %151 ], [ %283, %279 ]
  %281 = mul nsw i64 %280, %156
  %282 = getelementptr inbounds <2 x i64>, <2 x i64>* %152, i64 %281
  call void %45(<2 x i64>* %282, <2 x i64>* %282, i32 %155, i32 1, i32 %8, i32 0) #8
  %283 = add nuw nsw i64 %280, 1
  %284 = icmp slt i64 %283, %67
  br i1 %284, label %279, label %157

285:                                              ; preds = %330, %264
  %286 = phi i64 [ 0, %264 ], [ %331, %330 ]
  %287 = trunc i64 %286 to i32
  %288 = mul i32 %266, %287
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds <2 x i64>, <2 x i64>* %152, i64 %289
  %291 = shl nsw i64 %286, 3
  %292 = getelementptr inbounds i16, i16* %15, i64 %291
  br label %293

293:                                              ; preds = %293, %285
  %294 = phi i64 [ 0, %285 ], [ %327, %293 ]
  %295 = phi i64 [ %275, %285 ], [ %328, %293 ]
  %296 = mul nsw i64 %294, %276
  %297 = getelementptr inbounds i16, i16* %292, i64 %296
  %298 = bitcast i16* %297 to <2 x i64>*
  %299 = load <2 x i64>, <2 x i64>* %298, align 2
  %300 = getelementptr inbounds <2 x i64>, <2 x i64>* %290, i64 %295
  %301 = bitcast <2 x i64>* %300 to <4 x i32>*
  %302 = load <4 x i32>, <4 x i32>* %301, align 16
  %303 = add nsw i64 %295, %156
  %304 = getelementptr inbounds <2 x i64>, <2 x i64>* %290, i64 %303
  %305 = bitcast <2 x i64>* %304 to <4 x i32>*
  %306 = load <4 x i32>, <4 x i32>* %305, align 16
  %307 = bitcast <2 x i64> %299 to <8 x i16>
  %308 = shufflevector <8 x i16> %307, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %309 = sext <4 x i16> %308 to <4 x i32>
  %310 = bitcast <2 x i64> %299 to <16 x i8>
  %311 = shufflevector <16 x i8> %310, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %312 = bitcast <16 x i8> %311 to <8 x i16>
  %313 = shufflevector <8 x i16> %312, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %314 = sext <4 x i16> %313 to <4 x i32>
  %315 = add <4 x i32> %302, %309
  %316 = add <4 x i32> %306, %314
  %317 = icmp sgt <4 x i32> %315, zeroinitializer
  %318 = select <4 x i1> %317, <4 x i32> %315, <4 x i32> zeroinitializer
  %319 = icmp slt <4 x i32> %318, %274
  %320 = select <4 x i1> %319, <4 x i32> %318, <4 x i32> %274
  %321 = icmp sgt <4 x i32> %316, zeroinitializer
  %322 = select <4 x i1> %321, <4 x i32> %316, <4 x i32> zeroinitializer
  %323 = icmp slt <4 x i32> %322, %274
  %324 = select <4 x i1> %323, <4 x i32> %322, <4 x i32> %274
  %325 = call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %320, <4 x i32> %324) #8
  %326 = bitcast i16* %297 to <8 x i16>*
  store <8 x i16> %325, <8 x i16>* %326, align 2
  %327 = add nuw nsw i64 %294, 1
  %328 = add i64 %295, %268
  %329 = icmp eq i64 %327, %277
  br i1 %329, label %330, label %293

330:                                              ; preds = %293
  %331 = add nuw nsw i64 %286, 1
  %332 = icmp slt i64 %331, %278
  br i1 %332, label %285, label %333

333:                                              ; preds = %330, %260
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %17) #8
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %18) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_highbd_inv_txfm_add_sse4_1(i32*, i8*, i32, %struct.txfm_param* nocapture readonly) local_unnamed_addr #3 {
  %5 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 1
  %6 = load i8, i8* %5, align 1
  switch i8 %6, label %41 [
    i8 1, label %7
    i8 5, label %22
    i8 6, label %23
    i8 0, label %24
    i8 14, label %39
    i8 13, label %40
  ]

7:                                                ; preds = %4
  %8 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 3
  %9 = load i32, i32* %8, align 4
  %10 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 0
  %11 = load i8, i8* %10, align 4
  %12 = zext i8 %11 to i32
  %13 = add nsw i32 %12, -9
  %14 = icmp ult i32 %13, 7
  br i1 %14, label %15, label %18

15:                                               ; preds = %7
  %16 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 6
  %17 = load i32, i32* %16, align 4
  tail call void @av1_highbd_inv_txfm2d_add_universe_sse4_1(i32* %0, i8* %1, i32 %2, i8 zeroext %11, i8 zeroext 1, i32 %17, i32 %9) #8
  br label %48

18:                                               ; preds = %7
  %19 = ptrtoint i8* %1 to i64
  %20 = shl i64 %19, 1
  %21 = inttoptr i64 %20 to i16*
  tail call void @av1_inv_txfm2d_add_8x8_sse4_1(i32* %0, i16* %21, i32 %2, i8 zeroext %11, i32 %9) #8
  br label %48

22:                                               ; preds = %4
  tail call void @av1_highbd_inv_txfm_add_4x8_sse4_1(i32* %0, i8* %1, i32 %2, %struct.txfm_param* %3)
  br label %48

23:                                               ; preds = %4
  tail call void @av1_highbd_inv_txfm_add_8x4_sse4_1(i32* %0, i8* %1, i32 %2, %struct.txfm_param* %3)
  br label %48

24:                                               ; preds = %4
  %25 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 3
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = icmp eq i32 %28, 0
  br i1 %29, label %33, label %30

30:                                               ; preds = %24
  %31 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 6
  %32 = load i32, i32* %31, align 4
  tail call void @av1_highbd_iwht4x4_add(i32* %0, i8* %1, i32 %2, i32 %32, i32 %26) #8
  br label %48

33:                                               ; preds = %24
  %34 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 0
  %35 = load i8, i8* %34, align 4
  %36 = ptrtoint i8* %1 to i64
  %37 = shl i64 %36, 1
  %38 = inttoptr i64 %37 to i16*
  tail call void @av1_inv_txfm2d_add_4x4_sse4_1(i32* %0, i16* %38, i32 %2, i8 zeroext %35, i32 %26) #8
  br label %48

39:                                               ; preds = %4
  tail call void @av1_highbd_inv_txfm_add_16x4_sse4_1(i32* %0, i8* %1, i32 %2, %struct.txfm_param* %3)
  br label %48

40:                                               ; preds = %4
  tail call void @av1_highbd_inv_txfm_add_4x16_sse4_1(i32* %0, i8* %1, i32 %2, %struct.txfm_param* %3)
  br label %48

41:                                               ; preds = %4
  %42 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 0
  %43 = load i8, i8* %42, align 4
  %44 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 6
  %45 = load i32, i32* %44, align 4
  %46 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 3
  %47 = load i32, i32* %46, align 4
  tail call void @av1_highbd_inv_txfm2d_add_universe_sse4_1(i32* %0, i8* %1, i32 %2, i8 zeroext %43, i8 zeroext %6, i32 %45, i32 %47)
  br label %48

48:                                               ; preds = %33, %30, %18, %15, %41, %40, %39, %23, %22
  ret void
}

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32>, i32) #5

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32>, <4 x i32>) #5

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32>, <4 x i32>) #5

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16>, i32) #5

; Function Attrs: nofree nounwind ssp uwtable
define internal void @idct8x8_low1_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i32, i32, i32, i32) #2 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %10 = load i32, i32* %9, align 16
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = add nsw i32 %2, -1
  %14 = shl i32 1, %13
  %15 = insertelement <4 x i32> undef, i32 %14, i32 0
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> zeroinitializer
  %17 = icmp ne i32 %3, 0
  %18 = select i1 %17, i32 6, i32 8
  %19 = add nsw i32 %18, %4
  %20 = icmp slt i32 %19, 16
  %21 = add i32 %19, -1
  %22 = shl i32 1, %21
  %23 = select i1 %20, i32 32768, i32 %22
  %24 = sub nsw i32 0, %23
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> zeroinitializer
  %27 = add nsw i32 %23, -1
  %28 = insertelement <4 x i32> undef, i32 %27, i32 0
  %29 = shufflevector <4 x i32> %28, <4 x i32> undef, <4 x i32> zeroinitializer
  %30 = bitcast <2 x i64>* %0 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 16
  %32 = mul <4 x i32> %12, %31
  %33 = add <4 x i32> %32, %16
  %34 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %33, i32 %2) #8
  br i1 %17, label %52, label %35

35:                                               ; preds = %6
  %36 = icmp sgt i32 %4, 10
  %37 = select i1 %36, i32 %4, i32 10
  %38 = shl i32 32, %37
  %39 = sub nsw i32 0, %38
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = add nsw i32 %38, -1
  %43 = insertelement <4 x i32> undef, i32 %42, i32 0
  %44 = shufflevector <4 x i32> %43, <4 x i32> undef, <4 x i32> zeroinitializer
  %45 = shl i32 1, %5
  %46 = ashr i32 %45, 1
  %47 = insertelement <4 x i32> undef, i32 %46, i32 0
  %48 = shufflevector <4 x i32> %47, <4 x i32> undef, <4 x i32> zeroinitializer
  %49 = add <4 x i32> %34, %48
  %50 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %5, i32 0
  %51 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %49, <4 x i32> %50) #8
  br label %52

52:                                               ; preds = %35, %6
  %53 = phi <4 x i32> [ %26, %6 ], [ %41, %35 ]
  %54 = phi <4 x i32> [ %29, %6 ], [ %44, %35 ]
  %55 = phi <4 x i32> [ %34, %6 ], [ %51, %35 ]
  %56 = icmp sgt <4 x i32> %55, %53
  %57 = select <4 x i1> %56, <4 x i32> %55, <4 x i32> %53
  %58 = icmp slt <4 x i32> %57, %54
  %59 = select <4 x i1> %58, <4 x i32> %57, <4 x i32> %54
  %60 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %59, <4 x i32>* %60, align 16
  %61 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %62 = bitcast <2 x i64>* %61 to <4 x i32>*
  store <4 x i32> %59, <4 x i32>* %62, align 16
  %63 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %64 = bitcast <2 x i64>* %63 to <4 x i32>*
  store <4 x i32> %59, <4 x i32>* %64, align 16
  %65 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %66 = bitcast <2 x i64>* %65 to <4 x i32>*
  store <4 x i32> %59, <4 x i32>* %66, align 16
  %67 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %68 = bitcast <2 x i64>* %67 to <4 x i32>*
  store <4 x i32> %59, <4 x i32>* %68, align 16
  %69 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %70 = bitcast <2 x i64>* %69 to <4 x i32>*
  store <4 x i32> %59, <4 x i32>* %70, align 16
  %71 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %72 = bitcast <2 x i64>* %71 to <4 x i32>*
  store <4 x i32> %59, <4 x i32>* %72, align 16
  %73 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %74 = bitcast <2 x i64>* %73 to <4 x i32>*
  store <4 x i32> %59, <4 x i32>* %74, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @idct8x8_new_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i32, i32, i32, i32) #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 56
  %10 = load i32, i32* %9, align 16
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 8
  %14 = load i32, i32* %13, align 16
  %15 = sub nsw i32 0, %14
  %16 = insertelement <4 x i32> undef, i32 %15, i32 0
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> zeroinitializer
  %18 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 24
  %19 = load i32, i32* %18, align 16
  %20 = insertelement <4 x i32> undef, i32 %19, i32 0
  %21 = shufflevector <4 x i32> %20, <4 x i32> undef, <4 x i32> zeroinitializer
  %22 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 40
  %23 = load i32, i32* %22, align 16
  %24 = sub nsw i32 0, %23
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> zeroinitializer
  %27 = insertelement <4 x i32> undef, i32 %23, i32 0
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> zeroinitializer
  %29 = insertelement <4 x i32> undef, i32 %14, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %32 = load i32, i32* %31, align 16
  %33 = insertelement <4 x i32> undef, i32 %32, i32 0
  %34 = shufflevector <4 x i32> %33, <4 x i32> undef, <4 x i32> zeroinitializer
  %35 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 48
  %36 = load i32, i32* %35, align 16
  %37 = insertelement <4 x i32> undef, i32 %36, i32 0
  %38 = shufflevector <4 x i32> %37, <4 x i32> undef, <4 x i32> zeroinitializer
  %39 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 16
  %40 = load i32, i32* %39, align 16
  %41 = sub nsw i32 0, %40
  %42 = insertelement <4 x i32> undef, i32 %41, i32 0
  %43 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> zeroinitializer
  %44 = insertelement <4 x i32> undef, i32 %40, i32 0
  %45 = shufflevector <4 x i32> %44, <4 x i32> undef, <4 x i32> zeroinitializer
  %46 = add nsw i32 %2, -1
  %47 = shl i32 1, %46
  %48 = insertelement <4 x i32> undef, i32 %47, i32 0
  %49 = shufflevector <4 x i32> %48, <4 x i32> undef, <4 x i32> zeroinitializer
  %50 = icmp ne i32 %3, 0
  %51 = select i1 %50, i32 6, i32 8
  %52 = add nsw i32 %51, %4
  %53 = icmp slt i32 %52, 16
  %54 = add i32 %52, -1
  %55 = shl i32 1, %54
  %56 = select i1 %53, i32 32768, i32 %55
  %57 = sub nsw i32 0, %56
  %58 = insertelement <4 x i32> undef, i32 %57, i32 0
  %59 = shufflevector <4 x i32> %58, <4 x i32> undef, <4 x i32> zeroinitializer
  %60 = add nsw i32 %56, -1
  %61 = insertelement <4 x i32> undef, i32 %60, i32 0
  %62 = shufflevector <4 x i32> %61, <4 x i32> undef, <4 x i32> zeroinitializer
  %63 = bitcast <2 x i64>* %0 to <4 x i32>*
  %64 = load <4 x i32>, <4 x i32>* %63, align 16
  %65 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %66 = bitcast <2 x i64>* %65 to <4 x i32>*
  %67 = load <4 x i32>, <4 x i32>* %66, align 16
  %68 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %69 = bitcast <2 x i64>* %68 to <4 x i32>*
  %70 = load <4 x i32>, <4 x i32>* %69, align 16
  %71 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %72 = bitcast <2 x i64>* %71 to <4 x i32>*
  %73 = load <4 x i32>, <4 x i32>* %72, align 16
  %74 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %75 = bitcast <2 x i64>* %74 to <4 x i32>*
  %76 = load <4 x i32>, <4 x i32>* %75, align 16
  %77 = mul <4 x i32> %76, %12
  %78 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %79 = bitcast <2 x i64>* %78 to <4 x i32>*
  %80 = load <4 x i32>, <4 x i32>* %79, align 16
  %81 = mul <4 x i32> %80, %17
  %82 = add <4 x i32> %77, %49
  %83 = add <4 x i32> %82, %81
  %84 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %83, i32 %2) #8
  %85 = mul <4 x i32> %76, %30
  %86 = mul <4 x i32> %80, %12
  %87 = add <4 x i32> %85, %49
  %88 = add <4 x i32> %87, %86
  %89 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %88, i32 %2) #8
  %90 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %91 = bitcast <2 x i64>* %90 to <4 x i32>*
  %92 = load <4 x i32>, <4 x i32>* %91, align 16
  %93 = mul <4 x i32> %92, %21
  %94 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %95 = bitcast <2 x i64>* %94 to <4 x i32>*
  %96 = load <4 x i32>, <4 x i32>* %95, align 16
  %97 = mul <4 x i32> %96, %26
  %98 = add <4 x i32> %93, %49
  %99 = add <4 x i32> %98, %97
  %100 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %99, i32 %2) #8
  %101 = mul <4 x i32> %92, %28
  %102 = mul <4 x i32> %96, %21
  %103 = add <4 x i32> %101, %49
  %104 = add <4 x i32> %103, %102
  %105 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %104, i32 %2) #8
  %106 = mul <4 x i32> %64, %34
  %107 = mul <4 x i32> %67, %34
  %108 = add <4 x i32> %106, %49
  %109 = add <4 x i32> %108, %107
  %110 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %109, i32 %2) #8
  %111 = sub <4 x i32> %108, %107
  %112 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %111, i32 %2) #8
  %113 = mul <4 x i32> %70, %38
  %114 = mul <4 x i32> %73, %43
  %115 = add <4 x i32> %113, %49
  %116 = add <4 x i32> %115, %114
  %117 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %116, i32 %2) #8
  %118 = mul <4 x i32> %70, %45
  %119 = mul <4 x i32> %73, %38
  %120 = add <4 x i32> %118, %49
  %121 = add <4 x i32> %120, %119
  %122 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %121, i32 %2) #8
  %123 = add <4 x i32> %100, %84
  %124 = sub <4 x i32> %84, %100
  %125 = icmp sgt <4 x i32> %123, %59
  %126 = select <4 x i1> %125, <4 x i32> %123, <4 x i32> %59
  %127 = icmp slt <4 x i32> %126, %62
  %128 = select <4 x i1> %127, <4 x i32> %126, <4 x i32> %62
  %129 = icmp sgt <4 x i32> %124, %59
  %130 = select <4 x i1> %129, <4 x i32> %124, <4 x i32> %59
  %131 = icmp slt <4 x i32> %130, %62
  %132 = select <4 x i1> %131, <4 x i32> %130, <4 x i32> %62
  %133 = add <4 x i32> %105, %89
  %134 = sub <4 x i32> %89, %105
  %135 = icmp sgt <4 x i32> %133, %59
  %136 = select <4 x i1> %135, <4 x i32> %133, <4 x i32> %59
  %137 = icmp slt <4 x i32> %136, %62
  %138 = select <4 x i1> %137, <4 x i32> %136, <4 x i32> %62
  %139 = icmp sgt <4 x i32> %134, %59
  %140 = select <4 x i1> %139, <4 x i32> %134, <4 x i32> %59
  %141 = icmp slt <4 x i32> %140, %62
  %142 = select <4 x i1> %141, <4 x i32> %140, <4 x i32> %62
  %143 = add <4 x i32> %122, %110
  %144 = sub <4 x i32> %110, %122
  %145 = icmp sgt <4 x i32> %143, %59
  %146 = select <4 x i1> %145, <4 x i32> %143, <4 x i32> %59
  %147 = icmp slt <4 x i32> %146, %62
  %148 = select <4 x i1> %147, <4 x i32> %146, <4 x i32> %62
  %149 = icmp sgt <4 x i32> %144, %59
  %150 = select <4 x i1> %149, <4 x i32> %144, <4 x i32> %59
  %151 = icmp slt <4 x i32> %150, %62
  %152 = select <4 x i1> %151, <4 x i32> %150, <4 x i32> %62
  %153 = add <4 x i32> %117, %112
  %154 = sub <4 x i32> %112, %117
  %155 = icmp sgt <4 x i32> %153, %59
  %156 = select <4 x i1> %155, <4 x i32> %153, <4 x i32> %59
  %157 = icmp slt <4 x i32> %156, %62
  %158 = select <4 x i1> %157, <4 x i32> %156, <4 x i32> %62
  %159 = icmp sgt <4 x i32> %154, %59
  %160 = select <4 x i1> %159, <4 x i32> %154, <4 x i32> %59
  %161 = icmp slt <4 x i32> %160, %62
  %162 = select <4 x i1> %161, <4 x i32> %160, <4 x i32> %62
  %163 = mul <4 x i32> %132, %34
  %164 = mul <4 x i32> %142, %34
  %165 = add <4 x i32> %163, %49
  %166 = add <4 x i32> %165, %164
  %167 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %166, i32 %2) #8
  %168 = sub <4 x i32> %49, %163
  %169 = add <4 x i32> %168, %164
  %170 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %169, i32 %2) #8
  %171 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %172 = add <4 x i32> %148, %138
  %173 = sub <4 x i32> %148, %138
  %174 = icmp sgt <4 x i32> %172, %59
  %175 = select <4 x i1> %174, <4 x i32> %172, <4 x i32> %59
  %176 = icmp slt <4 x i32> %175, %62
  %177 = select <4 x i1> %176, <4 x i32> %175, <4 x i32> %62
  %178 = icmp sgt <4 x i32> %173, %59
  %179 = select <4 x i1> %178, <4 x i32> %173, <4 x i32> %59
  %180 = icmp slt <4 x i32> %179, %62
  %181 = select <4 x i1> %180, <4 x i32> %179, <4 x i32> %62
  %182 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %177, <4 x i32>* %182, align 16
  %183 = bitcast <2 x i64>* %171 to <4 x i32>*
  store <4 x i32> %181, <4 x i32>* %183, align 16
  %184 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %185 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %186 = add <4 x i32> %158, %167
  %187 = sub <4 x i32> %158, %167
  %188 = icmp sgt <4 x i32> %186, %59
  %189 = select <4 x i1> %188, <4 x i32> %186, <4 x i32> %59
  %190 = icmp slt <4 x i32> %189, %62
  %191 = select <4 x i1> %190, <4 x i32> %189, <4 x i32> %62
  %192 = icmp sgt <4 x i32> %187, %59
  %193 = select <4 x i1> %192, <4 x i32> %187, <4 x i32> %59
  %194 = icmp slt <4 x i32> %193, %62
  %195 = select <4 x i1> %194, <4 x i32> %193, <4 x i32> %62
  %196 = bitcast <2 x i64>* %184 to <4 x i32>*
  store <4 x i32> %191, <4 x i32>* %196, align 16
  %197 = bitcast <2 x i64>* %185 to <4 x i32>*
  store <4 x i32> %195, <4 x i32>* %197, align 16
  %198 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %199 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %200 = add <4 x i32> %162, %170
  %201 = sub <4 x i32> %162, %170
  %202 = icmp sgt <4 x i32> %200, %59
  %203 = select <4 x i1> %202, <4 x i32> %200, <4 x i32> %59
  %204 = icmp slt <4 x i32> %203, %62
  %205 = select <4 x i1> %204, <4 x i32> %203, <4 x i32> %62
  %206 = icmp sgt <4 x i32> %201, %59
  %207 = select <4 x i1> %206, <4 x i32> %201, <4 x i32> %59
  %208 = icmp slt <4 x i32> %207, %62
  %209 = select <4 x i1> %208, <4 x i32> %207, <4 x i32> %62
  %210 = bitcast <2 x i64>* %198 to <4 x i32>*
  store <4 x i32> %205, <4 x i32>* %210, align 16
  %211 = bitcast <2 x i64>* %199 to <4 x i32>*
  store <4 x i32> %209, <4 x i32>* %211, align 16
  %212 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %213 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %214 = add <4 x i32> %152, %128
  %215 = sub <4 x i32> %152, %128
  %216 = icmp sgt <4 x i32> %214, %59
  %217 = select <4 x i1> %216, <4 x i32> %214, <4 x i32> %59
  %218 = icmp slt <4 x i32> %217, %62
  %219 = select <4 x i1> %218, <4 x i32> %217, <4 x i32> %62
  %220 = icmp sgt <4 x i32> %215, %59
  %221 = select <4 x i1> %220, <4 x i32> %215, <4 x i32> %59
  %222 = icmp slt <4 x i32> %221, %62
  %223 = select <4 x i1> %222, <4 x i32> %221, <4 x i32> %62
  %224 = bitcast <2 x i64>* %212 to <4 x i32>*
  store <4 x i32> %219, <4 x i32>* %224, align 16
  %225 = bitcast <2 x i64>* %213 to <4 x i32>*
  store <4 x i32> %223, <4 x i32>* %225, align 16
  br i1 %50, label %299, label %226

226:                                              ; preds = %6
  %227 = icmp sgt i32 %4, 10
  %228 = select i1 %227, i32 %4, i32 10
  %229 = shl i32 32, %228
  %230 = sub nsw i32 0, %229
  %231 = insertelement <4 x i32> undef, i32 %230, i32 0
  %232 = shufflevector <4 x i32> %231, <4 x i32> undef, <4 x i32> zeroinitializer
  %233 = add nsw i32 %229, -1
  %234 = insertelement <4 x i32> undef, i32 %233, i32 0
  %235 = shufflevector <4 x i32> %234, <4 x i32> undef, <4 x i32> zeroinitializer
  %236 = icmp eq i32 %5, 0
  br i1 %236, label %258, label %237

237:                                              ; preds = %226
  %238 = add nsw i32 %5, -1
  %239 = shl i32 1, %238
  %240 = insertelement <4 x i32> undef, i32 %239, i32 0
  %241 = shufflevector <4 x i32> %240, <4 x i32> undef, <4 x i32> zeroinitializer
  %242 = add <4 x i32> %177, %241
  %243 = add <4 x i32> %191, %241
  %244 = add <4 x i32> %205, %241
  %245 = add <4 x i32> %219, %241
  %246 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %242, i32 %5) #8
  store <4 x i32> %246, <4 x i32>* %182, align 16
  %247 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %243, i32 %5) #8
  store <4 x i32> %247, <4 x i32>* %196, align 16
  %248 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %244, i32 %5) #8
  store <4 x i32> %248, <4 x i32>* %210, align 16
  %249 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %245, i32 %5) #8
  store <4 x i32> %249, <4 x i32>* %224, align 16
  %250 = add <4 x i32> %223, %241
  %251 = add <4 x i32> %209, %241
  %252 = add <4 x i32> %195, %241
  %253 = add <4 x i32> %181, %241
  %254 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %250, i32 %5) #8
  store <4 x i32> %254, <4 x i32>* %225, align 16
  %255 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %251, i32 %5) #8
  store <4 x i32> %255, <4 x i32>* %211, align 16
  %256 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %252, i32 %5) #8
  store <4 x i32> %256, <4 x i32>* %197, align 16
  %257 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %253, i32 %5) #8
  store <4 x i32> %257, <4 x i32>* %183, align 16
  br label %258

258:                                              ; preds = %226, %237
  %259 = phi <4 x i32> [ %181, %226 ], [ %257, %237 ]
  %260 = phi <4 x i32> [ %195, %226 ], [ %256, %237 ]
  %261 = phi <4 x i32> [ %209, %226 ], [ %255, %237 ]
  %262 = phi <4 x i32> [ %223, %226 ], [ %254, %237 ]
  %263 = phi <4 x i32> [ %219, %226 ], [ %249, %237 ]
  %264 = phi <4 x i32> [ %205, %226 ], [ %248, %237 ]
  %265 = phi <4 x i32> [ %191, %226 ], [ %247, %237 ]
  %266 = phi <4 x i32> [ %177, %226 ], [ %246, %237 ]
  %267 = icmp sgt <4 x i32> %266, %232
  %268 = select <4 x i1> %267, <4 x i32> %266, <4 x i32> %232
  %269 = icmp slt <4 x i32> %268, %235
  %270 = select <4 x i1> %269, <4 x i32> %268, <4 x i32> %235
  store <4 x i32> %270, <4 x i32>* %182, align 16
  %271 = icmp sgt <4 x i32> %265, %232
  %272 = select <4 x i1> %271, <4 x i32> %265, <4 x i32> %232
  %273 = icmp slt <4 x i32> %272, %235
  %274 = select <4 x i1> %273, <4 x i32> %272, <4 x i32> %235
  store <4 x i32> %274, <4 x i32>* %196, align 16
  %275 = icmp sgt <4 x i32> %264, %232
  %276 = select <4 x i1> %275, <4 x i32> %264, <4 x i32> %232
  %277 = icmp slt <4 x i32> %276, %235
  %278 = select <4 x i1> %277, <4 x i32> %276, <4 x i32> %235
  store <4 x i32> %278, <4 x i32>* %210, align 16
  %279 = icmp sgt <4 x i32> %263, %232
  %280 = select <4 x i1> %279, <4 x i32> %263, <4 x i32> %232
  %281 = icmp slt <4 x i32> %280, %235
  %282 = select <4 x i1> %281, <4 x i32> %280, <4 x i32> %235
  store <4 x i32> %282, <4 x i32>* %224, align 16
  %283 = icmp sgt <4 x i32> %262, %232
  %284 = select <4 x i1> %283, <4 x i32> %262, <4 x i32> %232
  %285 = icmp slt <4 x i32> %284, %235
  %286 = select <4 x i1> %285, <4 x i32> %284, <4 x i32> %235
  store <4 x i32> %286, <4 x i32>* %225, align 16
  %287 = icmp sgt <4 x i32> %261, %232
  %288 = select <4 x i1> %287, <4 x i32> %261, <4 x i32> %232
  %289 = icmp slt <4 x i32> %288, %235
  %290 = select <4 x i1> %289, <4 x i32> %288, <4 x i32> %235
  store <4 x i32> %290, <4 x i32>* %211, align 16
  %291 = icmp sgt <4 x i32> %260, %232
  %292 = select <4 x i1> %291, <4 x i32> %260, <4 x i32> %232
  %293 = icmp slt <4 x i32> %292, %235
  %294 = select <4 x i1> %293, <4 x i32> %292, <4 x i32> %235
  store <4 x i32> %294, <4 x i32>* %197, align 16
  %295 = icmp sgt <4 x i32> %259, %232
  %296 = select <4 x i1> %295, <4 x i32> %259, <4 x i32> %232
  %297 = icmp slt <4 x i32> %296, %235
  %298 = select <4 x i1> %297, <4 x i32> %296, <4 x i32> %235
  store <4 x i32> %298, <4 x i32>* %183, align 16
  br label %299

299:                                              ; preds = %258, %6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @iadst8x8_low1_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i32, i32, i32, i32) #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 4
  %10 = load i32, i32* %9, align 16
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 60
  %14 = load i32, i32* %13, align 16
  %15 = insertelement <4 x i32> undef, i32 %14, i32 0
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> zeroinitializer
  %17 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 16
  %18 = load i32, i32* %17, align 16
  %19 = insertelement <4 x i32> undef, i32 %18, i32 0
  %20 = shufflevector <4 x i32> %19, <4 x i32> undef, <4 x i32> zeroinitializer
  %21 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 48
  %22 = load i32, i32* %21, align 16
  %23 = insertelement <4 x i32> undef, i32 %22, i32 0
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> zeroinitializer
  %25 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %26 = load i32, i32* %25, align 16
  %27 = insertelement <4 x i32> undef, i32 %26, i32 0
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> zeroinitializer
  %29 = add nsw i32 %2, -1
  %30 = shl i32 1, %29
  %31 = insertelement <4 x i32> undef, i32 %30, i32 0
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> zeroinitializer
  %33 = bitcast <2 x i64>* %0 to <4 x i32>*
  %34 = load <4 x i32>, <4 x i32>* %33, align 16
  %35 = mul <4 x i32> %34, %16
  %36 = add <4 x i32> %35, %32
  %37 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %36, i32 %2) #8
  %38 = mul <4 x i32> %34, %12
  %39 = sub <4 x i32> %32, %38
  %40 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %39, i32 %2) #8
  %41 = mul <4 x i32> %37, %20
  %42 = mul <4 x i32> %40, %24
  %43 = add <4 x i32> %41, %32
  %44 = add <4 x i32> %43, %42
  %45 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %44, i32 %2) #8
  %46 = mul <4 x i32> %37, %24
  %47 = mul <4 x i32> %20, %40
  %48 = add <4 x i32> %46, %32
  %49 = sub <4 x i32> %48, %47
  %50 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %49, i32 %2) #8
  %51 = mul <4 x i32> %28, %37
  %52 = mul <4 x i32> %40, %28
  %53 = add <4 x i32> %51, %32
  %54 = add <4 x i32> %53, %52
  %55 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %54, i32 %2) #8
  %56 = sub <4 x i32> %53, %52
  %57 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %56, i32 %2) #8
  %58 = mul <4 x i32> %45, %28
  %59 = mul <4 x i32> %50, %28
  %60 = add <4 x i32> %58, %32
  %61 = add <4 x i32> %60, %59
  %62 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %61, i32 %2) #8
  %63 = sub <4 x i32> %60, %59
  %64 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %63, i32 %2) #8
  %65 = icmp eq i32 %3, 0
  br i1 %65, label %84, label %66

66:                                               ; preds = %6
  %67 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %37, <4 x i32>* %67, align 16
  %68 = sub <4 x i32> zeroinitializer, %45
  %69 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %70 = bitcast <2 x i64>* %69 to <4 x i32>*
  store <4 x i32> %68, <4 x i32>* %70, align 16
  %71 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %72 = bitcast <2 x i64>* %71 to <4 x i32>*
  store <4 x i32> %62, <4 x i32>* %72, align 16
  %73 = sub <4 x i32> zeroinitializer, %55
  %74 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %75 = bitcast <2 x i64>* %74 to <4 x i32>*
  store <4 x i32> %73, <4 x i32>* %75, align 16
  %76 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %77 = bitcast <2 x i64>* %76 to <4 x i32>*
  store <4 x i32> %57, <4 x i32>* %77, align 16
  %78 = sub <4 x i32> zeroinitializer, %64
  %79 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %80 = bitcast <2 x i64>* %79 to <4 x i32>*
  store <4 x i32> %78, <4 x i32>* %80, align 16
  %81 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %82 = bitcast <2 x i64>* %81 to <4 x i32>*
  store <4 x i32> %50, <4 x i32>* %82, align 16
  %83 = sub <4 x i32> zeroinitializer, %40
  br label %160

84:                                               ; preds = %6
  %85 = icmp sgt i32 %4, 10
  %86 = select i1 %85, i32 %4, i32 10
  %87 = shl i32 32, %86
  %88 = sub nsw i32 0, %87
  %89 = insertelement <4 x i32> undef, i32 %88, i32 0
  %90 = shufflevector <4 x i32> %89, <4 x i32> undef, <4 x i32> zeroinitializer
  %91 = add nsw i32 %87, -1
  %92 = insertelement <4 x i32> undef, i32 %91, i32 0
  %93 = shufflevector <4 x i32> %92, <4 x i32> undef, <4 x i32> zeroinitializer
  %94 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %95 = shl i32 1, %5
  %96 = ashr i32 %95, 1
  %97 = insertelement <4 x i32> undef, i32 %96, i32 0
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> zeroinitializer
  %99 = add <4 x i32> %37, %98
  %100 = sub <4 x i32> %98, %45
  %101 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %5, i32 0
  %102 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %99, <4 x i32> %101) #8
  %103 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %100, <4 x i32> %101) #8
  %104 = icmp sgt <4 x i32> %102, %90
  %105 = select <4 x i1> %104, <4 x i32> %102, <4 x i32> %90
  %106 = icmp slt <4 x i32> %105, %93
  %107 = select <4 x i1> %106, <4 x i32> %105, <4 x i32> %93
  %108 = icmp sgt <4 x i32> %103, %90
  %109 = select <4 x i1> %108, <4 x i32> %103, <4 x i32> %90
  %110 = icmp slt <4 x i32> %109, %93
  %111 = select <4 x i1> %110, <4 x i32> %109, <4 x i32> %93
  %112 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %107, <4 x i32>* %112, align 16
  %113 = bitcast <2 x i64>* %94 to <4 x i32>*
  store <4 x i32> %111, <4 x i32>* %113, align 16
  %114 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %115 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %116 = add <4 x i32> %62, %98
  %117 = sub <4 x i32> %98, %55
  %118 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %116, <4 x i32> %101) #8
  %119 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %117, <4 x i32> %101) #8
  %120 = icmp sgt <4 x i32> %118, %90
  %121 = select <4 x i1> %120, <4 x i32> %118, <4 x i32> %90
  %122 = icmp slt <4 x i32> %121, %93
  %123 = select <4 x i1> %122, <4 x i32> %121, <4 x i32> %93
  %124 = icmp sgt <4 x i32> %119, %90
  %125 = select <4 x i1> %124, <4 x i32> %119, <4 x i32> %90
  %126 = icmp slt <4 x i32> %125, %93
  %127 = select <4 x i1> %126, <4 x i32> %125, <4 x i32> %93
  %128 = bitcast <2 x i64>* %114 to <4 x i32>*
  store <4 x i32> %123, <4 x i32>* %128, align 16
  %129 = bitcast <2 x i64>* %115 to <4 x i32>*
  store <4 x i32> %127, <4 x i32>* %129, align 16
  %130 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %131 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %132 = add <4 x i32> %57, %98
  %133 = sub <4 x i32> %98, %64
  %134 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %132, <4 x i32> %101) #8
  %135 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %133, <4 x i32> %101) #8
  %136 = icmp sgt <4 x i32> %134, %90
  %137 = select <4 x i1> %136, <4 x i32> %134, <4 x i32> %90
  %138 = icmp slt <4 x i32> %137, %93
  %139 = select <4 x i1> %138, <4 x i32> %137, <4 x i32> %93
  %140 = icmp sgt <4 x i32> %135, %90
  %141 = select <4 x i1> %140, <4 x i32> %135, <4 x i32> %90
  %142 = icmp slt <4 x i32> %141, %93
  %143 = select <4 x i1> %142, <4 x i32> %141, <4 x i32> %93
  %144 = bitcast <2 x i64>* %130 to <4 x i32>*
  store <4 x i32> %139, <4 x i32>* %144, align 16
  %145 = bitcast <2 x i64>* %131 to <4 x i32>*
  store <4 x i32> %143, <4 x i32>* %145, align 16
  %146 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %147 = add <4 x i32> %50, %98
  %148 = sub <4 x i32> %98, %40
  %149 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %147, <4 x i32> %101) #8
  %150 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %148, <4 x i32> %101) #8
  %151 = icmp sgt <4 x i32> %149, %90
  %152 = select <4 x i1> %151, <4 x i32> %149, <4 x i32> %90
  %153 = icmp slt <4 x i32> %152, %93
  %154 = select <4 x i1> %153, <4 x i32> %152, <4 x i32> %93
  %155 = icmp sgt <4 x i32> %150, %90
  %156 = select <4 x i1> %155, <4 x i32> %150, <4 x i32> %90
  %157 = icmp slt <4 x i32> %156, %93
  %158 = select <4 x i1> %157, <4 x i32> %156, <4 x i32> %93
  %159 = bitcast <2 x i64>* %146 to <4 x i32>*
  store <4 x i32> %154, <4 x i32>* %159, align 16
  br label %160

160:                                              ; preds = %84, %66
  %161 = phi <4 x i32> [ %158, %84 ], [ %83, %66 ]
  %162 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %163 = bitcast <2 x i64>* %162 to <4 x i32>*
  store <4 x i32> %161, <4 x i32>* %163, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @iadst8x8_new_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i32, i32, i32, i32) #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 4
  %10 = load i32, i32* %9, align 16
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 60
  %14 = load i32, i32* %13, align 16
  %15 = insertelement <4 x i32> undef, i32 %14, i32 0
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> zeroinitializer
  %17 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 20
  %18 = load i32, i32* %17, align 16
  %19 = insertelement <4 x i32> undef, i32 %18, i32 0
  %20 = shufflevector <4 x i32> %19, <4 x i32> undef, <4 x i32> zeroinitializer
  %21 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 44
  %22 = load i32, i32* %21, align 16
  %23 = insertelement <4 x i32> undef, i32 %22, i32 0
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> zeroinitializer
  %25 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 36
  %26 = load i32, i32* %25, align 16
  %27 = insertelement <4 x i32> undef, i32 %26, i32 0
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> zeroinitializer
  %29 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 28
  %30 = load i32, i32* %29, align 16
  %31 = insertelement <4 x i32> undef, i32 %30, i32 0
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> zeroinitializer
  %33 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 52
  %34 = load i32, i32* %33, align 16
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 12
  %38 = load i32, i32* %37, align 16
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> zeroinitializer
  %41 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 16
  %42 = load i32, i32* %41, align 16
  %43 = insertelement <4 x i32> undef, i32 %42, i32 0
  %44 = shufflevector <4 x i32> %43, <4 x i32> undef, <4 x i32> zeroinitializer
  %45 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 48
  %46 = load i32, i32* %45, align 16
  %47 = insertelement <4 x i32> undef, i32 %46, i32 0
  %48 = shufflevector <4 x i32> %47, <4 x i32> undef, <4 x i32> zeroinitializer
  %49 = sub nsw i32 0, %46
  %50 = insertelement <4 x i32> undef, i32 %49, i32 0
  %51 = shufflevector <4 x i32> %50, <4 x i32> undef, <4 x i32> zeroinitializer
  %52 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %53 = load i32, i32* %52, align 16
  %54 = insertelement <4 x i32> undef, i32 %53, i32 0
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> zeroinitializer
  %56 = add nsw i32 %2, -1
  %57 = shl i32 1, %56
  %58 = insertelement <4 x i32> undef, i32 %57, i32 0
  %59 = shufflevector <4 x i32> %58, <4 x i32> undef, <4 x i32> zeroinitializer
  %60 = icmp ne i32 %3, 0
  %61 = select i1 %60, i32 6, i32 8
  %62 = add nsw i32 %61, %4
  %63 = icmp slt i32 %62, 16
  %64 = add i32 %62, -1
  %65 = shl i32 1, %64
  %66 = select i1 %63, i32 32768, i32 %65
  %67 = sub nsw i32 0, %66
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = add nsw i32 %66, -1
  %71 = insertelement <4 x i32> undef, i32 %70, i32 0
  %72 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> zeroinitializer
  %73 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %74 = bitcast <2 x i64>* %73 to <4 x i32>*
  %75 = load <4 x i32>, <4 x i32>* %74, align 16
  %76 = mul <4 x i32> %75, %12
  %77 = bitcast <2 x i64>* %0 to <4 x i32>*
  %78 = load <4 x i32>, <4 x i32>* %77, align 16
  %79 = mul <4 x i32> %78, %16
  %80 = add <4 x i32> %76, %59
  %81 = add <4 x i32> %80, %79
  %82 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %81, i32 %2) #8
  %83 = mul <4 x i32> %75, %16
  %84 = mul <4 x i32> %12, %78
  %85 = add <4 x i32> %83, %59
  %86 = sub <4 x i32> %85, %84
  %87 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %86, i32 %2) #8
  %88 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %89 = bitcast <2 x i64>* %88 to <4 x i32>*
  %90 = load <4 x i32>, <4 x i32>* %89, align 16
  %91 = mul <4 x i32> %90, %20
  %92 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %93 = bitcast <2 x i64>* %92 to <4 x i32>*
  %94 = load <4 x i32>, <4 x i32>* %93, align 16
  %95 = mul <4 x i32> %94, %24
  %96 = add <4 x i32> %91, %59
  %97 = add <4 x i32> %96, %95
  %98 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %97, i32 %2) #8
  %99 = mul <4 x i32> %90, %24
  %100 = mul <4 x i32> %20, %94
  %101 = add <4 x i32> %99, %59
  %102 = sub <4 x i32> %101, %100
  %103 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %102, i32 %2) #8
  %104 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %105 = bitcast <2 x i64>* %104 to <4 x i32>*
  %106 = load <4 x i32>, <4 x i32>* %105, align 16
  %107 = mul <4 x i32> %106, %28
  %108 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %109 = bitcast <2 x i64>* %108 to <4 x i32>*
  %110 = load <4 x i32>, <4 x i32>* %109, align 16
  %111 = mul <4 x i32> %110, %32
  %112 = add <4 x i32> %107, %59
  %113 = add <4 x i32> %112, %111
  %114 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %113, i32 %2) #8
  %115 = mul <4 x i32> %106, %32
  %116 = mul <4 x i32> %28, %110
  %117 = add <4 x i32> %115, %59
  %118 = sub <4 x i32> %117, %116
  %119 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %118, i32 %2) #8
  %120 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %121 = bitcast <2 x i64>* %120 to <4 x i32>*
  %122 = load <4 x i32>, <4 x i32>* %121, align 16
  %123 = mul <4 x i32> %122, %36
  %124 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %125 = bitcast <2 x i64>* %124 to <4 x i32>*
  %126 = load <4 x i32>, <4 x i32>* %125, align 16
  %127 = mul <4 x i32> %126, %40
  %128 = add <4 x i32> %123, %59
  %129 = add <4 x i32> %128, %127
  %130 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %129, i32 %2) #8
  %131 = mul <4 x i32> %122, %40
  %132 = mul <4 x i32> %36, %126
  %133 = add <4 x i32> %131, %59
  %134 = sub <4 x i32> %133, %132
  %135 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %134, i32 %2) #8
  %136 = add <4 x i32> %114, %82
  %137 = sub <4 x i32> %82, %114
  %138 = icmp sgt <4 x i32> %136, %69
  %139 = select <4 x i1> %138, <4 x i32> %136, <4 x i32> %69
  %140 = icmp slt <4 x i32> %139, %72
  %141 = select <4 x i1> %140, <4 x i32> %139, <4 x i32> %72
  %142 = icmp sgt <4 x i32> %137, %69
  %143 = select <4 x i1> %142, <4 x i32> %137, <4 x i32> %69
  %144 = icmp slt <4 x i32> %143, %72
  %145 = select <4 x i1> %144, <4 x i32> %143, <4 x i32> %72
  %146 = add <4 x i32> %119, %87
  %147 = sub <4 x i32> %87, %119
  %148 = icmp sgt <4 x i32> %146, %69
  %149 = select <4 x i1> %148, <4 x i32> %146, <4 x i32> %69
  %150 = icmp slt <4 x i32> %149, %72
  %151 = select <4 x i1> %150, <4 x i32> %149, <4 x i32> %72
  %152 = icmp sgt <4 x i32> %147, %69
  %153 = select <4 x i1> %152, <4 x i32> %147, <4 x i32> %69
  %154 = icmp slt <4 x i32> %153, %72
  %155 = select <4 x i1> %154, <4 x i32> %153, <4 x i32> %72
  %156 = add <4 x i32> %130, %98
  %157 = sub <4 x i32> %98, %130
  %158 = icmp sgt <4 x i32> %156, %69
  %159 = select <4 x i1> %158, <4 x i32> %156, <4 x i32> %69
  %160 = icmp slt <4 x i32> %159, %72
  %161 = select <4 x i1> %160, <4 x i32> %159, <4 x i32> %72
  %162 = icmp sgt <4 x i32> %157, %69
  %163 = select <4 x i1> %162, <4 x i32> %157, <4 x i32> %69
  %164 = icmp slt <4 x i32> %163, %72
  %165 = select <4 x i1> %164, <4 x i32> %163, <4 x i32> %72
  %166 = add <4 x i32> %135, %103
  %167 = sub <4 x i32> %103, %135
  %168 = icmp sgt <4 x i32> %166, %69
  %169 = select <4 x i1> %168, <4 x i32> %166, <4 x i32> %69
  %170 = icmp slt <4 x i32> %169, %72
  %171 = select <4 x i1> %170, <4 x i32> %169, <4 x i32> %72
  %172 = icmp sgt <4 x i32> %167, %69
  %173 = select <4 x i1> %172, <4 x i32> %167, <4 x i32> %69
  %174 = icmp slt <4 x i32> %173, %72
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %72
  %176 = mul <4 x i32> %145, %44
  %177 = mul <4 x i32> %155, %48
  %178 = add <4 x i32> %176, %59
  %179 = add <4 x i32> %178, %177
  %180 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %179, i32 %2) #8
  %181 = mul <4 x i32> %145, %48
  %182 = mul <4 x i32> %44, %155
  %183 = add <4 x i32> %181, %59
  %184 = sub <4 x i32> %183, %182
  %185 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %184, i32 %2) #8
  %186 = mul <4 x i32> %165, %51
  %187 = mul <4 x i32> %175, %44
  %188 = add <4 x i32> %186, %59
  %189 = add <4 x i32> %188, %187
  %190 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %189, i32 %2) #8
  %191 = mul <4 x i32> %165, %44
  %192 = mul <4 x i32> %51, %175
  %193 = add <4 x i32> %191, %59
  %194 = sub <4 x i32> %193, %192
  %195 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %194, i32 %2) #8
  %196 = add <4 x i32> %161, %141
  %197 = sub <4 x i32> %141, %161
  %198 = icmp sgt <4 x i32> %196, %69
  %199 = select <4 x i1> %198, <4 x i32> %196, <4 x i32> %69
  %200 = icmp slt <4 x i32> %199, %72
  %201 = select <4 x i1> %200, <4 x i32> %199, <4 x i32> %72
  %202 = icmp sgt <4 x i32> %197, %69
  %203 = select <4 x i1> %202, <4 x i32> %197, <4 x i32> %69
  %204 = icmp slt <4 x i32> %203, %72
  %205 = select <4 x i1> %204, <4 x i32> %203, <4 x i32> %72
  %206 = add <4 x i32> %171, %151
  %207 = sub <4 x i32> %151, %171
  %208 = icmp sgt <4 x i32> %206, %69
  %209 = select <4 x i1> %208, <4 x i32> %206, <4 x i32> %69
  %210 = icmp slt <4 x i32> %209, %72
  %211 = select <4 x i1> %210, <4 x i32> %209, <4 x i32> %72
  %212 = icmp sgt <4 x i32> %207, %69
  %213 = select <4 x i1> %212, <4 x i32> %207, <4 x i32> %69
  %214 = icmp slt <4 x i32> %213, %72
  %215 = select <4 x i1> %214, <4 x i32> %213, <4 x i32> %72
  %216 = add <4 x i32> %190, %180
  %217 = sub <4 x i32> %180, %190
  %218 = icmp sgt <4 x i32> %216, %69
  %219 = select <4 x i1> %218, <4 x i32> %216, <4 x i32> %69
  %220 = icmp slt <4 x i32> %219, %72
  %221 = select <4 x i1> %220, <4 x i32> %219, <4 x i32> %72
  %222 = icmp sgt <4 x i32> %217, %69
  %223 = select <4 x i1> %222, <4 x i32> %217, <4 x i32> %69
  %224 = icmp slt <4 x i32> %223, %72
  %225 = select <4 x i1> %224, <4 x i32> %223, <4 x i32> %72
  %226 = add <4 x i32> %195, %185
  %227 = sub <4 x i32> %185, %195
  %228 = icmp sgt <4 x i32> %226, %69
  %229 = select <4 x i1> %228, <4 x i32> %226, <4 x i32> %69
  %230 = icmp slt <4 x i32> %229, %72
  %231 = select <4 x i1> %230, <4 x i32> %229, <4 x i32> %72
  %232 = icmp sgt <4 x i32> %227, %69
  %233 = select <4 x i1> %232, <4 x i32> %227, <4 x i32> %69
  %234 = icmp slt <4 x i32> %233, %72
  %235 = select <4 x i1> %234, <4 x i32> %233, <4 x i32> %72
  %236 = mul <4 x i32> %205, %55
  %237 = mul <4 x i32> %215, %55
  %238 = add <4 x i32> %236, %59
  %239 = add <4 x i32> %238, %237
  %240 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %239, i32 %2) #8
  %241 = sub <4 x i32> %238, %237
  %242 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %241, i32 %2) #8
  %243 = mul <4 x i32> %225, %55
  %244 = mul <4 x i32> %235, %55
  %245 = add <4 x i32> %243, %59
  %246 = add <4 x i32> %245, %244
  %247 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %246, i32 %2) #8
  %248 = sub <4 x i32> %245, %244
  %249 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %248, i32 %2) #8
  br i1 %60, label %250, label %268

250:                                              ; preds = %6
  %251 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %201, <4 x i32>* %251, align 16
  %252 = sub <4 x i32> zeroinitializer, %221
  %253 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %254 = bitcast <2 x i64>* %253 to <4 x i32>*
  store <4 x i32> %252, <4 x i32>* %254, align 16
  %255 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %256 = bitcast <2 x i64>* %255 to <4 x i32>*
  store <4 x i32> %247, <4 x i32>* %256, align 16
  %257 = sub <4 x i32> zeroinitializer, %240
  %258 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %259 = bitcast <2 x i64>* %258 to <4 x i32>*
  store <4 x i32> %257, <4 x i32>* %259, align 16
  %260 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %261 = bitcast <2 x i64>* %260 to <4 x i32>*
  store <4 x i32> %242, <4 x i32>* %261, align 16
  %262 = sub <4 x i32> zeroinitializer, %249
  %263 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %264 = bitcast <2 x i64>* %263 to <4 x i32>*
  store <4 x i32> %262, <4 x i32>* %264, align 16
  %265 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %266 = bitcast <2 x i64>* %265 to <4 x i32>*
  store <4 x i32> %231, <4 x i32>* %266, align 16
  %267 = sub <4 x i32> zeroinitializer, %211
  br label %344

268:                                              ; preds = %6
  %269 = icmp sgt i32 %4, 10
  %270 = select i1 %269, i32 %4, i32 10
  %271 = shl i32 32, %270
  %272 = sub nsw i32 0, %271
  %273 = insertelement <4 x i32> undef, i32 %272, i32 0
  %274 = shufflevector <4 x i32> %273, <4 x i32> undef, <4 x i32> zeroinitializer
  %275 = add nsw i32 %271, -1
  %276 = insertelement <4 x i32> undef, i32 %275, i32 0
  %277 = shufflevector <4 x i32> %276, <4 x i32> undef, <4 x i32> zeroinitializer
  %278 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %279 = shl i32 1, %5
  %280 = ashr i32 %279, 1
  %281 = insertelement <4 x i32> undef, i32 %280, i32 0
  %282 = shufflevector <4 x i32> %281, <4 x i32> undef, <4 x i32> zeroinitializer
  %283 = add <4 x i32> %201, %282
  %284 = sub <4 x i32> %282, %221
  %285 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %5, i32 0
  %286 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %283, <4 x i32> %285) #8
  %287 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %284, <4 x i32> %285) #8
  %288 = icmp sgt <4 x i32> %286, %274
  %289 = select <4 x i1> %288, <4 x i32> %286, <4 x i32> %274
  %290 = icmp slt <4 x i32> %289, %277
  %291 = select <4 x i1> %290, <4 x i32> %289, <4 x i32> %277
  %292 = icmp sgt <4 x i32> %287, %274
  %293 = select <4 x i1> %292, <4 x i32> %287, <4 x i32> %274
  %294 = icmp slt <4 x i32> %293, %277
  %295 = select <4 x i1> %294, <4 x i32> %293, <4 x i32> %277
  %296 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %291, <4 x i32>* %296, align 16
  %297 = bitcast <2 x i64>* %278 to <4 x i32>*
  store <4 x i32> %295, <4 x i32>* %297, align 16
  %298 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %299 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %300 = add <4 x i32> %247, %282
  %301 = sub <4 x i32> %282, %240
  %302 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %300, <4 x i32> %285) #8
  %303 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %301, <4 x i32> %285) #8
  %304 = icmp sgt <4 x i32> %302, %274
  %305 = select <4 x i1> %304, <4 x i32> %302, <4 x i32> %274
  %306 = icmp slt <4 x i32> %305, %277
  %307 = select <4 x i1> %306, <4 x i32> %305, <4 x i32> %277
  %308 = icmp sgt <4 x i32> %303, %274
  %309 = select <4 x i1> %308, <4 x i32> %303, <4 x i32> %274
  %310 = icmp slt <4 x i32> %309, %277
  %311 = select <4 x i1> %310, <4 x i32> %309, <4 x i32> %277
  %312 = bitcast <2 x i64>* %298 to <4 x i32>*
  store <4 x i32> %307, <4 x i32>* %312, align 16
  %313 = bitcast <2 x i64>* %299 to <4 x i32>*
  store <4 x i32> %311, <4 x i32>* %313, align 16
  %314 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %315 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %316 = add <4 x i32> %242, %282
  %317 = sub <4 x i32> %282, %249
  %318 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %316, <4 x i32> %285) #8
  %319 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %317, <4 x i32> %285) #8
  %320 = icmp sgt <4 x i32> %318, %274
  %321 = select <4 x i1> %320, <4 x i32> %318, <4 x i32> %274
  %322 = icmp slt <4 x i32> %321, %277
  %323 = select <4 x i1> %322, <4 x i32> %321, <4 x i32> %277
  %324 = icmp sgt <4 x i32> %319, %274
  %325 = select <4 x i1> %324, <4 x i32> %319, <4 x i32> %274
  %326 = icmp slt <4 x i32> %325, %277
  %327 = select <4 x i1> %326, <4 x i32> %325, <4 x i32> %277
  %328 = bitcast <2 x i64>* %314 to <4 x i32>*
  store <4 x i32> %323, <4 x i32>* %328, align 16
  %329 = bitcast <2 x i64>* %315 to <4 x i32>*
  store <4 x i32> %327, <4 x i32>* %329, align 16
  %330 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %331 = add <4 x i32> %231, %282
  %332 = sub <4 x i32> %282, %211
  %333 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %331, <4 x i32> %285) #8
  %334 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %332, <4 x i32> %285) #8
  %335 = icmp sgt <4 x i32> %333, %274
  %336 = select <4 x i1> %335, <4 x i32> %333, <4 x i32> %274
  %337 = icmp slt <4 x i32> %336, %277
  %338 = select <4 x i1> %337, <4 x i32> %336, <4 x i32> %277
  %339 = icmp sgt <4 x i32> %334, %274
  %340 = select <4 x i1> %339, <4 x i32> %334, <4 x i32> %274
  %341 = icmp slt <4 x i32> %340, %277
  %342 = select <4 x i1> %341, <4 x i32> %340, <4 x i32> %277
  %343 = bitcast <2 x i64>* %330 to <4 x i32>*
  store <4 x i32> %338, <4 x i32>* %343, align 16
  br label %344

344:                                              ; preds = %268, %250
  %345 = phi <4 x i32> [ %342, %268 ], [ %267, %250 ]
  %346 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %347 = bitcast <2 x i64>* %346 to <4 x i32>*
  store <4 x i32> %345, <4 x i32>* %347, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @iidentity8_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i32, i32, i32, i32) #0 {
  %7 = bitcast <2 x i64>* %0 to <4 x i32>*
  %8 = load <4 x i32>, <4 x i32>* %7, align 16
  %9 = shl <4 x i32> %8, <i32 1, i32 1, i32 1, i32 1>
  %10 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %9, <4 x i32>* %10, align 16
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %12 = bitcast <2 x i64>* %11 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 16
  %14 = shl <4 x i32> %13, <i32 1, i32 1, i32 1, i32 1>
  %15 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %16 = bitcast <2 x i64>* %15 to <4 x i32>*
  store <4 x i32> %14, <4 x i32>* %16, align 16
  %17 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %18 = bitcast <2 x i64>* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 16
  %20 = shl <4 x i32> %19, <i32 1, i32 1, i32 1, i32 1>
  %21 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %22 = bitcast <2 x i64>* %21 to <4 x i32>*
  store <4 x i32> %20, <4 x i32>* %22, align 16
  %23 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %24 = bitcast <2 x i64>* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 16
  %26 = shl <4 x i32> %25, <i32 1, i32 1, i32 1, i32 1>
  %27 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %28 = bitcast <2 x i64>* %27 to <4 x i32>*
  store <4 x i32> %26, <4 x i32>* %28, align 16
  %29 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %30 = bitcast <2 x i64>* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 16
  %32 = shl <4 x i32> %31, <i32 1, i32 1, i32 1, i32 1>
  %33 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %34 = bitcast <2 x i64>* %33 to <4 x i32>*
  store <4 x i32> %32, <4 x i32>* %34, align 16
  %35 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %36 = bitcast <2 x i64>* %35 to <4 x i32>*
  %37 = load <4 x i32>, <4 x i32>* %36, align 16
  %38 = shl <4 x i32> %37, <i32 1, i32 1, i32 1, i32 1>
  %39 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %40 = bitcast <2 x i64>* %39 to <4 x i32>*
  store <4 x i32> %38, <4 x i32>* %40, align 16
  %41 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %42 = bitcast <2 x i64>* %41 to <4 x i32>*
  %43 = load <4 x i32>, <4 x i32>* %42, align 16
  %44 = shl <4 x i32> %43, <i32 1, i32 1, i32 1, i32 1>
  %45 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %46 = bitcast <2 x i64>* %45 to <4 x i32>*
  store <4 x i32> %44, <4 x i32>* %46, align 16
  %47 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %48 = bitcast <2 x i64>* %47 to <4 x i32>*
  %49 = load <4 x i32>, <4 x i32>* %48, align 16
  %50 = shl <4 x i32> %49, <i32 1, i32 1, i32 1, i32 1>
  %51 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %52 = bitcast <2 x i64>* %51 to <4 x i32>*
  store <4 x i32> %50, <4 x i32>* %52, align 16
  %53 = icmp eq i32 %3, 0
  br i1 %53, label %54, label %127

54:                                               ; preds = %6
  %55 = icmp sgt i32 %4, 10
  %56 = select i1 %55, i32 %4, i32 10
  %57 = shl i32 32, %56
  %58 = sub nsw i32 0, %57
  %59 = insertelement <4 x i32> undef, i32 %58, i32 0
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = add nsw i32 %57, -1
  %62 = insertelement <4 x i32> undef, i32 %61, i32 0
  %63 = shufflevector <4 x i32> %62, <4 x i32> undef, <4 x i32> zeroinitializer
  %64 = icmp eq i32 %5, 0
  br i1 %64, label %86, label %65

65:                                               ; preds = %54
  %66 = add nsw i32 %5, -1
  %67 = shl i32 1, %66
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = add <4 x i32> %9, %69
  %71 = add <4 x i32> %14, %69
  %72 = add <4 x i32> %20, %69
  %73 = add <4 x i32> %26, %69
  %74 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %70, i32 %5) #8
  store <4 x i32> %74, <4 x i32>* %10, align 16
  %75 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %71, i32 %5) #8
  store <4 x i32> %75, <4 x i32>* %16, align 16
  %76 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %72, i32 %5) #8
  store <4 x i32> %76, <4 x i32>* %22, align 16
  %77 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %73, i32 %5) #8
  store <4 x i32> %77, <4 x i32>* %28, align 16
  %78 = add <4 x i32> %32, %69
  %79 = add <4 x i32> %38, %69
  %80 = add <4 x i32> %44, %69
  %81 = add <4 x i32> %50, %69
  %82 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %78, i32 %5) #8
  store <4 x i32> %82, <4 x i32>* %34, align 16
  %83 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %79, i32 %5) #8
  store <4 x i32> %83, <4 x i32>* %40, align 16
  %84 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %80, i32 %5) #8
  store <4 x i32> %84, <4 x i32>* %46, align 16
  %85 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %81, i32 %5) #8
  store <4 x i32> %85, <4 x i32>* %52, align 16
  br label %86

86:                                               ; preds = %54, %65
  %87 = phi <4 x i32> [ %50, %54 ], [ %85, %65 ]
  %88 = phi <4 x i32> [ %44, %54 ], [ %84, %65 ]
  %89 = phi <4 x i32> [ %38, %54 ], [ %83, %65 ]
  %90 = phi <4 x i32> [ %32, %54 ], [ %82, %65 ]
  %91 = phi <4 x i32> [ %26, %54 ], [ %77, %65 ]
  %92 = phi <4 x i32> [ %20, %54 ], [ %76, %65 ]
  %93 = phi <4 x i32> [ %14, %54 ], [ %75, %65 ]
  %94 = phi <4 x i32> [ %9, %54 ], [ %74, %65 ]
  %95 = icmp sgt <4 x i32> %94, %60
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %60
  %97 = icmp slt <4 x i32> %96, %63
  %98 = select <4 x i1> %97, <4 x i32> %96, <4 x i32> %63
  store <4 x i32> %98, <4 x i32>* %10, align 16
  %99 = icmp sgt <4 x i32> %93, %60
  %100 = select <4 x i1> %99, <4 x i32> %93, <4 x i32> %60
  %101 = icmp slt <4 x i32> %100, %63
  %102 = select <4 x i1> %101, <4 x i32> %100, <4 x i32> %63
  store <4 x i32> %102, <4 x i32>* %16, align 16
  %103 = icmp sgt <4 x i32> %92, %60
  %104 = select <4 x i1> %103, <4 x i32> %92, <4 x i32> %60
  %105 = icmp slt <4 x i32> %104, %63
  %106 = select <4 x i1> %105, <4 x i32> %104, <4 x i32> %63
  store <4 x i32> %106, <4 x i32>* %22, align 16
  %107 = icmp sgt <4 x i32> %91, %60
  %108 = select <4 x i1> %107, <4 x i32> %91, <4 x i32> %60
  %109 = icmp slt <4 x i32> %108, %63
  %110 = select <4 x i1> %109, <4 x i32> %108, <4 x i32> %63
  store <4 x i32> %110, <4 x i32>* %28, align 16
  %111 = icmp sgt <4 x i32> %90, %60
  %112 = select <4 x i1> %111, <4 x i32> %90, <4 x i32> %60
  %113 = icmp slt <4 x i32> %112, %63
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %63
  store <4 x i32> %114, <4 x i32>* %34, align 16
  %115 = icmp sgt <4 x i32> %89, %60
  %116 = select <4 x i1> %115, <4 x i32> %89, <4 x i32> %60
  %117 = icmp slt <4 x i32> %116, %63
  %118 = select <4 x i1> %117, <4 x i32> %116, <4 x i32> %63
  store <4 x i32> %118, <4 x i32>* %40, align 16
  %119 = icmp sgt <4 x i32> %88, %60
  %120 = select <4 x i1> %119, <4 x i32> %88, <4 x i32> %60
  %121 = icmp slt <4 x i32> %120, %63
  %122 = select <4 x i1> %121, <4 x i32> %120, <4 x i32> %63
  store <4 x i32> %122, <4 x i32>* %46, align 16
  %123 = icmp sgt <4 x i32> %87, %60
  %124 = select <4 x i1> %123, <4 x i32> %87, <4 x i32> %60
  %125 = icmp slt <4 x i32> %124, %63
  %126 = select <4 x i1> %125, <4 x i32> %124, <4 x i32> %63
  store <4 x i32> %126, <4 x i32>* %52, align 16
  br label %127

127:                                              ; preds = %86, %6
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @idct16x16_low1_sse4_1(<2 x i64>*, <2 x i64>* nocapture, i32, i32, i32, i32) #2 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %10 = load i32, i32* %9, align 16
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = add nsw i32 %2, -1
  %14 = shl i32 1, %13
  %15 = insertelement <4 x i32> undef, i32 %14, i32 0
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> zeroinitializer
  %17 = icmp ne i32 %3, 0
  %18 = select i1 %17, i32 6, i32 8
  %19 = add nsw i32 %18, %4
  %20 = icmp slt i32 %19, 16
  %21 = add i32 %19, -1
  %22 = shl i32 1, %21
  %23 = select i1 %20, i32 32768, i32 %22
  %24 = sub nsw i32 0, %23
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> zeroinitializer
  %27 = add nsw i32 %23, -1
  %28 = insertelement <4 x i32> undef, i32 %27, i32 0
  %29 = shufflevector <4 x i32> %28, <4 x i32> undef, <4 x i32> zeroinitializer
  %30 = bitcast <2 x i64>* %0 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 16
  %32 = mul <4 x i32> %12, %31
  %33 = add <4 x i32> %32, %16
  %34 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %33, i32 %2) #8
  store <4 x i32> %34, <4 x i32>* %30, align 16
  br i1 %17, label %54, label %35

35:                                               ; preds = %6
  %36 = icmp sgt i32 %4, 10
  %37 = select i1 %36, i32 %4, i32 10
  %38 = shl i32 32, %37
  %39 = sub nsw i32 0, %38
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = add nsw i32 %38, -1
  %43 = insertelement <4 x i32> undef, i32 %42, i32 0
  %44 = shufflevector <4 x i32> %43, <4 x i32> undef, <4 x i32> zeroinitializer
  %45 = icmp eq i32 %5, 0
  br i1 %45, label %54, label %46

46:                                               ; preds = %35
  %47 = shl i32 1, %5
  %48 = ashr i32 %47, 1
  %49 = insertelement <4 x i32> undef, i32 %48, i32 0
  %50 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> zeroinitializer
  %51 = add <4 x i32> %34, %50
  %52 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %5, i32 0
  %53 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %51, <4 x i32> %52) #8
  store <4 x i32> %53, <4 x i32>* %30, align 16
  br label %54

54:                                               ; preds = %35, %46, %6
  %55 = phi <4 x i32> [ %34, %6 ], [ %53, %46 ], [ %34, %35 ]
  %56 = phi <4 x i32> [ %26, %6 ], [ %41, %46 ], [ %41, %35 ]
  %57 = phi <4 x i32> [ %29, %6 ], [ %44, %46 ], [ %44, %35 ]
  %58 = icmp sgt <4 x i32> %55, %56
  %59 = select <4 x i1> %58, <4 x i32> %55, <4 x i32> %56
  %60 = icmp slt <4 x i32> %59, %57
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %57
  store <4 x i32> %61, <4 x i32>* %30, align 16
  %62 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %62, align 16
  %63 = load <2 x i64>, <2 x i64>* %0, align 16
  %64 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  store <2 x i64> %63, <2 x i64>* %64, align 16
  %65 = load <2 x i64>, <2 x i64>* %0, align 16
  %66 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  store <2 x i64> %65, <2 x i64>* %66, align 16
  %67 = load <2 x i64>, <2 x i64>* %0, align 16
  %68 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  store <2 x i64> %67, <2 x i64>* %68, align 16
  %69 = load <2 x i64>, <2 x i64>* %0, align 16
  %70 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  store <2 x i64> %69, <2 x i64>* %70, align 16
  %71 = load <2 x i64>, <2 x i64>* %0, align 16
  %72 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  store <2 x i64> %71, <2 x i64>* %72, align 16
  %73 = load <2 x i64>, <2 x i64>* %0, align 16
  %74 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  store <2 x i64> %73, <2 x i64>* %74, align 16
  %75 = load <2 x i64>, <2 x i64>* %0, align 16
  %76 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  store <2 x i64> %75, <2 x i64>* %76, align 16
  %77 = load <2 x i64>, <2 x i64>* %0, align 16
  %78 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  store <2 x i64> %77, <2 x i64>* %78, align 16
  %79 = load <2 x i64>, <2 x i64>* %0, align 16
  %80 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  store <2 x i64> %79, <2 x i64>* %80, align 16
  %81 = load <2 x i64>, <2 x i64>* %0, align 16
  %82 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  store <2 x i64> %81, <2 x i64>* %82, align 16
  %83 = load <2 x i64>, <2 x i64>* %0, align 16
  %84 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  store <2 x i64> %83, <2 x i64>* %84, align 16
  %85 = load <2 x i64>, <2 x i64>* %0, align 16
  %86 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  store <2 x i64> %85, <2 x i64>* %86, align 16
  %87 = load <2 x i64>, <2 x i64>* %0, align 16
  %88 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  store <2 x i64> %87, <2 x i64>* %88, align 16
  %89 = load <2 x i64>, <2 x i64>* %0, align 16
  %90 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  store <2 x i64> %89, <2 x i64>* %90, align 16
  %91 = load <2 x i64>, <2 x i64>* %0, align 16
  %92 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  store <2 x i64> %91, <2 x i64>* %92, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @idct16x16_low8_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>*, i32, i32, i32, i32) #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 60
  %10 = load i32, i32* %9, align 16
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 28
  %14 = load i32, i32* %13, align 16
  %15 = insertelement <4 x i32> undef, i32 %14, i32 0
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> zeroinitializer
  %17 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 44
  %18 = load i32, i32* %17, align 16
  %19 = insertelement <4 x i32> undef, i32 %18, i32 0
  %20 = shufflevector <4 x i32> %19, <4 x i32> undef, <4 x i32> zeroinitializer
  %21 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 20
  %22 = load i32, i32* %21, align 16
  %23 = insertelement <4 x i32> undef, i32 %22, i32 0
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> zeroinitializer
  %25 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 12
  %26 = load i32, i32* %25, align 16
  %27 = insertelement <4 x i32> undef, i32 %26, i32 0
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> zeroinitializer
  %29 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 4
  %30 = load i32, i32* %29, align 16
  %31 = insertelement <4 x i32> undef, i32 %30, i32 0
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> zeroinitializer
  %33 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 56
  %34 = load i32, i32* %33, align 16
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 24
  %38 = load i32, i32* %37, align 16
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> zeroinitializer
  %41 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 40
  %42 = load i32, i32* %41, align 16
  %43 = sub nsw i32 0, %42
  %44 = insertelement <4 x i32> undef, i32 %43, i32 0
  %45 = shufflevector <4 x i32> %44, <4 x i32> undef, <4 x i32> zeroinitializer
  %46 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 8
  %47 = load i32, i32* %46, align 16
  %48 = insertelement <4 x i32> undef, i32 %47, i32 0
  %49 = shufflevector <4 x i32> %48, <4 x i32> undef, <4 x i32> zeroinitializer
  %50 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %51 = load i32, i32* %50, align 16
  %52 = insertelement <4 x i32> undef, i32 %51, i32 0
  %53 = shufflevector <4 x i32> %52, <4 x i32> undef, <4 x i32> zeroinitializer
  %54 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 48
  %55 = load i32, i32* %54, align 16
  %56 = insertelement <4 x i32> undef, i32 %55, i32 0
  %57 = shufflevector <4 x i32> %56, <4 x i32> undef, <4 x i32> zeroinitializer
  %58 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 16
  %59 = load i32, i32* %58, align 16
  %60 = insertelement <4 x i32> undef, i32 %59, i32 0
  %61 = shufflevector <4 x i32> %60, <4 x i32> undef, <4 x i32> zeroinitializer
  %62 = sub nsw i32 0, %59
  %63 = insertelement <4 x i32> undef, i32 %62, i32 0
  %64 = shufflevector <4 x i32> %63, <4 x i32> undef, <4 x i32> zeroinitializer
  %65 = sub nsw i32 0, %55
  %66 = insertelement <4 x i32> undef, i32 %65, i32 0
  %67 = shufflevector <4 x i32> %66, <4 x i32> undef, <4 x i32> zeroinitializer
  %68 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 36
  %69 = load i32, i32* %68, align 16
  %70 = sub nsw i32 0, %69
  %71 = insertelement <4 x i32> undef, i32 %70, i32 0
  %72 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> zeroinitializer
  %73 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 52
  %74 = load i32, i32* %73, align 16
  %75 = sub nsw i32 0, %74
  %76 = insertelement <4 x i32> undef, i32 %75, i32 0
  %77 = shufflevector <4 x i32> %76, <4 x i32> undef, <4 x i32> zeroinitializer
  %78 = add nsw i32 %2, -1
  %79 = shl i32 1, %78
  %80 = insertelement <4 x i32> undef, i32 %79, i32 0
  %81 = shufflevector <4 x i32> %80, <4 x i32> undef, <4 x i32> zeroinitializer
  %82 = icmp ne i32 %3, 0
  %83 = select i1 %82, i32 6, i32 8
  %84 = add nsw i32 %83, %4
  %85 = icmp slt i32 %84, 16
  %86 = add i32 %84, -1
  %87 = shl i32 1, %86
  %88 = select i1 %85, i32 32768, i32 %87
  %89 = sub nsw i32 0, %88
  %90 = insertelement <4 x i32> undef, i32 %89, i32 0
  %91 = shufflevector <4 x i32> %90, <4 x i32> undef, <4 x i32> zeroinitializer
  %92 = add nsw i32 %88, -1
  %93 = insertelement <4 x i32> undef, i32 %92, i32 0
  %94 = shufflevector <4 x i32> %93, <4 x i32> undef, <4 x i32> zeroinitializer
  %95 = bitcast <2 x i64>* %0 to <4 x i32>*
  %96 = load <4 x i32>, <4 x i32>* %95, align 16
  %97 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %98 = bitcast <2 x i64>* %97 to <4 x i32>*
  %99 = load <4 x i32>, <4 x i32>* %98, align 16
  %100 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %101 = bitcast <2 x i64>* %100 to <4 x i32>*
  %102 = load <4 x i32>, <4 x i32>* %101, align 16
  %103 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %104 = bitcast <2 x i64>* %103 to <4 x i32>*
  %105 = load <4 x i32>, <4 x i32>* %104, align 16
  %106 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %107 = bitcast <2 x i64>* %106 to <4 x i32>*
  %108 = load <4 x i32>, <4 x i32>* %107, align 16
  %109 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %110 = bitcast <2 x i64>* %109 to <4 x i32>*
  %111 = load <4 x i32>, <4 x i32>* %110, align 16
  %112 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %113 = bitcast <2 x i64>* %112 to <4 x i32>*
  %114 = load <4 x i32>, <4 x i32>* %113, align 16
  %115 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %116 = bitcast <2 x i64>* %115 to <4 x i32>*
  %117 = load <4 x i32>, <4 x i32>* %116, align 16
  %118 = mul <4 x i32> %108, %32
  %119 = add <4 x i32> %118, %81
  %120 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %119, i32 %2) #8
  %121 = mul <4 x i32> %108, %12
  %122 = add <4 x i32> %121, %81
  %123 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %122, i32 %2) #8
  %124 = mul <4 x i32> %117, %72
  %125 = add <4 x i32> %124, %81
  %126 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %125, i32 %2) #8
  %127 = mul <4 x i32> %117, %16
  %128 = add <4 x i32> %127, %81
  %129 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %128, i32 %2) #8
  %130 = mul <4 x i32> %111, %24
  %131 = add <4 x i32> %130, %81
  %132 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %131, i32 %2) #8
  %133 = mul <4 x i32> %111, %20
  %134 = add <4 x i32> %133, %81
  %135 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %134, i32 %2) #8
  %136 = mul <4 x i32> %114, %77
  %137 = add <4 x i32> %136, %81
  %138 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %137, i32 %2) #8
  %139 = mul <4 x i32> %114, %28
  %140 = add <4 x i32> %139, %81
  %141 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %140, i32 %2) #8
  %142 = mul <4 x i32> %102, %49
  %143 = add <4 x i32> %142, %81
  %144 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %143, i32 %2) #8
  %145 = mul <4 x i32> %102, %36
  %146 = add <4 x i32> %145, %81
  %147 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %146, i32 %2) #8
  %148 = mul <4 x i32> %105, %45
  %149 = add <4 x i32> %148, %81
  %150 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %149, i32 %2) #8
  %151 = mul <4 x i32> %105, %40
  %152 = add <4 x i32> %151, %81
  %153 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %152, i32 %2) #8
  %154 = add <4 x i32> %126, %123
  %155 = sub <4 x i32> %123, %126
  %156 = icmp sgt <4 x i32> %154, %91
  %157 = select <4 x i1> %156, <4 x i32> %154, <4 x i32> %91
  %158 = icmp slt <4 x i32> %157, %94
  %159 = select <4 x i1> %158, <4 x i32> %157, <4 x i32> %94
  %160 = icmp sgt <4 x i32> %155, %91
  %161 = select <4 x i1> %160, <4 x i32> %155, <4 x i32> %91
  %162 = icmp slt <4 x i32> %161, %94
  %163 = select <4 x i1> %162, <4 x i32> %161, <4 x i32> %94
  %164 = add <4 x i32> %138, %135
  %165 = sub <4 x i32> %138, %135
  %166 = icmp sgt <4 x i32> %164, %91
  %167 = select <4 x i1> %166, <4 x i32> %164, <4 x i32> %91
  %168 = icmp slt <4 x i32> %167, %94
  %169 = select <4 x i1> %168, <4 x i32> %167, <4 x i32> %94
  %170 = icmp sgt <4 x i32> %165, %91
  %171 = select <4 x i1> %170, <4 x i32> %165, <4 x i32> %91
  %172 = icmp slt <4 x i32> %171, %94
  %173 = select <4 x i1> %172, <4 x i32> %171, <4 x i32> %94
  %174 = add <4 x i32> %141, %132
  %175 = sub <4 x i32> %141, %132
  %176 = icmp sgt <4 x i32> %174, %91
  %177 = select <4 x i1> %176, <4 x i32> %174, <4 x i32> %91
  %178 = icmp slt <4 x i32> %177, %94
  %179 = select <4 x i1> %178, <4 x i32> %177, <4 x i32> %94
  %180 = icmp sgt <4 x i32> %175, %91
  %181 = select <4 x i1> %180, <4 x i32> %175, <4 x i32> %91
  %182 = icmp slt <4 x i32> %181, %94
  %183 = select <4 x i1> %182, <4 x i32> %181, <4 x i32> %94
  %184 = add <4 x i32> %129, %120
  %185 = sub <4 x i32> %120, %129
  %186 = icmp sgt <4 x i32> %184, %91
  %187 = select <4 x i1> %186, <4 x i32> %184, <4 x i32> %91
  %188 = icmp slt <4 x i32> %187, %94
  %189 = select <4 x i1> %188, <4 x i32> %187, <4 x i32> %94
  %190 = icmp sgt <4 x i32> %185, %91
  %191 = select <4 x i1> %190, <4 x i32> %185, <4 x i32> %91
  %192 = icmp slt <4 x i32> %191, %94
  %193 = select <4 x i1> %192, <4 x i32> %191, <4 x i32> %94
  %194 = mul <4 x i32> %96, %53
  %195 = add <4 x i32> %194, %81
  %196 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %195, i32 %2) #8
  %197 = mul <4 x i32> %99, %61
  %198 = add <4 x i32> %197, %81
  %199 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %198, i32 %2) #8
  %200 = mul <4 x i32> %99, %57
  %201 = add <4 x i32> %200, %81
  %202 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %201, i32 %2) #8
  %203 = add <4 x i32> %150, %147
  %204 = sub <4 x i32> %147, %150
  %205 = icmp sgt <4 x i32> %203, %91
  %206 = select <4 x i1> %205, <4 x i32> %203, <4 x i32> %91
  %207 = icmp slt <4 x i32> %206, %94
  %208 = select <4 x i1> %207, <4 x i32> %206, <4 x i32> %94
  %209 = icmp sgt <4 x i32> %204, %91
  %210 = select <4 x i1> %209, <4 x i32> %204, <4 x i32> %91
  %211 = icmp slt <4 x i32> %210, %94
  %212 = select <4 x i1> %211, <4 x i32> %210, <4 x i32> %94
  %213 = add <4 x i32> %153, %144
  %214 = sub <4 x i32> %144, %153
  %215 = icmp sgt <4 x i32> %213, %91
  %216 = select <4 x i1> %215, <4 x i32> %213, <4 x i32> %91
  %217 = icmp slt <4 x i32> %216, %94
  %218 = select <4 x i1> %217, <4 x i32> %216, <4 x i32> %94
  %219 = icmp sgt <4 x i32> %214, %91
  %220 = select <4 x i1> %219, <4 x i32> %214, <4 x i32> %91
  %221 = icmp slt <4 x i32> %220, %94
  %222 = select <4 x i1> %221, <4 x i32> %220, <4 x i32> %94
  %223 = mul <4 x i32> %163, %64
  %224 = mul <4 x i32> %193, %57
  %225 = add <4 x i32> %223, %81
  %226 = add <4 x i32> %225, %224
  %227 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %226, i32 %2) #8
  %228 = mul <4 x i32> %163, %57
  %229 = mul <4 x i32> %193, %61
  %230 = add <4 x i32> %228, %81
  %231 = add <4 x i32> %230, %229
  %232 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %231, i32 %2) #8
  %233 = mul <4 x i32> %173, %67
  %234 = mul <4 x i32> %183, %64
  %235 = add <4 x i32> %233, %81
  %236 = add <4 x i32> %235, %234
  %237 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %236, i32 %2) #8
  %238 = mul <4 x i32> %173, %64
  %239 = mul <4 x i32> %183, %57
  %240 = add <4 x i32> %238, %81
  %241 = add <4 x i32> %240, %239
  %242 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %241, i32 %2) #8
  %243 = add <4 x i32> %199, %196
  %244 = sub <4 x i32> %196, %199
  %245 = icmp sgt <4 x i32> %243, %91
  %246 = select <4 x i1> %245, <4 x i32> %243, <4 x i32> %91
  %247 = icmp slt <4 x i32> %246, %94
  %248 = select <4 x i1> %247, <4 x i32> %246, <4 x i32> %94
  %249 = icmp sgt <4 x i32> %244, %91
  %250 = select <4 x i1> %249, <4 x i32> %244, <4 x i32> %91
  %251 = icmp slt <4 x i32> %250, %94
  %252 = select <4 x i1> %251, <4 x i32> %250, <4 x i32> %94
  %253 = add <4 x i32> %202, %196
  %254 = sub <4 x i32> %196, %202
  %255 = icmp sgt <4 x i32> %253, %91
  %256 = select <4 x i1> %255, <4 x i32> %253, <4 x i32> %91
  %257 = icmp slt <4 x i32> %256, %94
  %258 = select <4 x i1> %257, <4 x i32> %256, <4 x i32> %94
  %259 = icmp sgt <4 x i32> %254, %91
  %260 = select <4 x i1> %259, <4 x i32> %254, <4 x i32> %91
  %261 = icmp slt <4 x i32> %260, %94
  %262 = select <4 x i1> %261, <4 x i32> %260, <4 x i32> %94
  %263 = mul <4 x i32> %212, %53
  %264 = mul <4 x i32> %222, %53
  %265 = sub <4 x i32> %81, %263
  %266 = add <4 x i32> %265, %264
  %267 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %266, i32 %2) #8
  %268 = add <4 x i32> %263, %81
  %269 = add <4 x i32> %268, %264
  %270 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %269, i32 %2) #8
  %271 = add <4 x i32> %169, %159
  %272 = sub <4 x i32> %159, %169
  %273 = icmp sgt <4 x i32> %271, %91
  %274 = select <4 x i1> %273, <4 x i32> %271, <4 x i32> %91
  %275 = icmp slt <4 x i32> %274, %94
  %276 = select <4 x i1> %275, <4 x i32> %274, <4 x i32> %94
  %277 = icmp sgt <4 x i32> %272, %91
  %278 = select <4 x i1> %277, <4 x i32> %272, <4 x i32> %91
  %279 = icmp slt <4 x i32> %278, %94
  %280 = select <4 x i1> %279, <4 x i32> %278, <4 x i32> %94
  %281 = add <4 x i32> %237, %227
  %282 = sub <4 x i32> %227, %237
  %283 = icmp sgt <4 x i32> %281, %91
  %284 = select <4 x i1> %283, <4 x i32> %281, <4 x i32> %91
  %285 = icmp slt <4 x i32> %284, %94
  %286 = select <4 x i1> %285, <4 x i32> %284, <4 x i32> %94
  %287 = icmp sgt <4 x i32> %282, %91
  %288 = select <4 x i1> %287, <4 x i32> %282, <4 x i32> %91
  %289 = icmp slt <4 x i32> %288, %94
  %290 = select <4 x i1> %289, <4 x i32> %288, <4 x i32> %94
  %291 = add <4 x i32> %179, %189
  %292 = sub <4 x i32> %189, %179
  %293 = icmp sgt <4 x i32> %291, %91
  %294 = select <4 x i1> %293, <4 x i32> %291, <4 x i32> %91
  %295 = icmp slt <4 x i32> %294, %94
  %296 = select <4 x i1> %295, <4 x i32> %294, <4 x i32> %94
  %297 = icmp sgt <4 x i32> %292, %91
  %298 = select <4 x i1> %297, <4 x i32> %292, <4 x i32> %91
  %299 = icmp slt <4 x i32> %298, %94
  %300 = select <4 x i1> %299, <4 x i32> %298, <4 x i32> %94
  %301 = add <4 x i32> %242, %232
  %302 = sub <4 x i32> %232, %242
  %303 = icmp sgt <4 x i32> %301, %91
  %304 = select <4 x i1> %303, <4 x i32> %301, <4 x i32> %91
  %305 = icmp slt <4 x i32> %304, %94
  %306 = select <4 x i1> %305, <4 x i32> %304, <4 x i32> %94
  %307 = icmp sgt <4 x i32> %302, %91
  %308 = select <4 x i1> %307, <4 x i32> %302, <4 x i32> %91
  %309 = icmp slt <4 x i32> %308, %94
  %310 = select <4 x i1> %309, <4 x i32> %308, <4 x i32> %94
  %311 = add <4 x i32> %248, %218
  %312 = sub <4 x i32> %248, %218
  %313 = icmp sgt <4 x i32> %311, %91
  %314 = select <4 x i1> %313, <4 x i32> %311, <4 x i32> %91
  %315 = icmp slt <4 x i32> %314, %94
  %316 = select <4 x i1> %315, <4 x i32> %314, <4 x i32> %94
  %317 = icmp sgt <4 x i32> %312, %91
  %318 = select <4 x i1> %317, <4 x i32> %312, <4 x i32> %91
  %319 = icmp slt <4 x i32> %318, %94
  %320 = select <4 x i1> %319, <4 x i32> %318, <4 x i32> %94
  %321 = add <4 x i32> %270, %258
  %322 = sub <4 x i32> %258, %270
  %323 = icmp sgt <4 x i32> %321, %91
  %324 = select <4 x i1> %323, <4 x i32> %321, <4 x i32> %91
  %325 = icmp slt <4 x i32> %324, %94
  %326 = select <4 x i1> %325, <4 x i32> %324, <4 x i32> %94
  %327 = icmp sgt <4 x i32> %322, %91
  %328 = select <4 x i1> %327, <4 x i32> %322, <4 x i32> %91
  %329 = icmp slt <4 x i32> %328, %94
  %330 = select <4 x i1> %329, <4 x i32> %328, <4 x i32> %94
  %331 = add <4 x i32> %267, %262
  %332 = sub <4 x i32> %262, %267
  %333 = icmp sgt <4 x i32> %331, %91
  %334 = select <4 x i1> %333, <4 x i32> %331, <4 x i32> %91
  %335 = icmp slt <4 x i32> %334, %94
  %336 = select <4 x i1> %335, <4 x i32> %334, <4 x i32> %94
  %337 = icmp sgt <4 x i32> %332, %91
  %338 = select <4 x i1> %337, <4 x i32> %332, <4 x i32> %91
  %339 = icmp slt <4 x i32> %338, %94
  %340 = select <4 x i1> %339, <4 x i32> %338, <4 x i32> %94
  %341 = add <4 x i32> %252, %208
  %342 = sub <4 x i32> %252, %208
  %343 = icmp sgt <4 x i32> %341, %91
  %344 = select <4 x i1> %343, <4 x i32> %341, <4 x i32> %91
  %345 = icmp slt <4 x i32> %344, %94
  %346 = select <4 x i1> %345, <4 x i32> %344, <4 x i32> %94
  %347 = icmp sgt <4 x i32> %342, %91
  %348 = select <4 x i1> %347, <4 x i32> %342, <4 x i32> %91
  %349 = icmp slt <4 x i32> %348, %94
  %350 = select <4 x i1> %349, <4 x i32> %348, <4 x i32> %94
  %351 = mul <4 x i32> %290, %53
  %352 = mul <4 x i32> %310, %53
  %353 = sub <4 x i32> %81, %351
  %354 = add <4 x i32> %353, %352
  %355 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %354, i32 %2) #8
  %356 = add <4 x i32> %351, %81
  %357 = add <4 x i32> %356, %352
  %358 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %357, i32 %2) #8
  %359 = mul <4 x i32> %280, %53
  %360 = mul <4 x i32> %300, %53
  %361 = sub <4 x i32> %81, %359
  %362 = add <4 x i32> %361, %360
  %363 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %362, i32 %2) #8
  %364 = add <4 x i32> %359, %81
  %365 = add <4 x i32> %364, %360
  %366 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %365, i32 %2) #8
  %367 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %368 = add <4 x i32> %316, %296
  %369 = sub <4 x i32> %316, %296
  %370 = icmp sgt <4 x i32> %368, %91
  %371 = select <4 x i1> %370, <4 x i32> %368, <4 x i32> %91
  %372 = icmp slt <4 x i32> %371, %94
  %373 = select <4 x i1> %372, <4 x i32> %371, <4 x i32> %94
  %374 = icmp sgt <4 x i32> %369, %91
  %375 = select <4 x i1> %374, <4 x i32> %369, <4 x i32> %91
  %376 = icmp slt <4 x i32> %375, %94
  %377 = select <4 x i1> %376, <4 x i32> %375, <4 x i32> %94
  %378 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %373, <4 x i32>* %378, align 16
  %379 = bitcast <2 x i64>* %367 to <4 x i32>*
  store <4 x i32> %377, <4 x i32>* %379, align 16
  %380 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %381 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %382 = add <4 x i32> %326, %306
  %383 = sub <4 x i32> %326, %306
  %384 = icmp sgt <4 x i32> %382, %91
  %385 = select <4 x i1> %384, <4 x i32> %382, <4 x i32> %91
  %386 = icmp slt <4 x i32> %385, %94
  %387 = select <4 x i1> %386, <4 x i32> %385, <4 x i32> %94
  %388 = icmp sgt <4 x i32> %383, %91
  %389 = select <4 x i1> %388, <4 x i32> %383, <4 x i32> %91
  %390 = icmp slt <4 x i32> %389, %94
  %391 = select <4 x i1> %390, <4 x i32> %389, <4 x i32> %94
  %392 = bitcast <2 x i64>* %380 to <4 x i32>*
  store <4 x i32> %387, <4 x i32>* %392, align 16
  %393 = bitcast <2 x i64>* %381 to <4 x i32>*
  store <4 x i32> %391, <4 x i32>* %393, align 16
  %394 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %395 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %396 = add <4 x i32> %336, %358
  %397 = sub <4 x i32> %336, %358
  %398 = icmp sgt <4 x i32> %396, %91
  %399 = select <4 x i1> %398, <4 x i32> %396, <4 x i32> %91
  %400 = icmp slt <4 x i32> %399, %94
  %401 = select <4 x i1> %400, <4 x i32> %399, <4 x i32> %94
  %402 = icmp sgt <4 x i32> %397, %91
  %403 = select <4 x i1> %402, <4 x i32> %397, <4 x i32> %91
  %404 = icmp slt <4 x i32> %403, %94
  %405 = select <4 x i1> %404, <4 x i32> %403, <4 x i32> %94
  %406 = bitcast <2 x i64>* %394 to <4 x i32>*
  store <4 x i32> %401, <4 x i32>* %406, align 16
  %407 = bitcast <2 x i64>* %395 to <4 x i32>*
  store <4 x i32> %405, <4 x i32>* %407, align 16
  %408 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %409 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %410 = add <4 x i32> %366, %346
  %411 = sub <4 x i32> %346, %366
  %412 = icmp sgt <4 x i32> %410, %91
  %413 = select <4 x i1> %412, <4 x i32> %410, <4 x i32> %91
  %414 = icmp slt <4 x i32> %413, %94
  %415 = select <4 x i1> %414, <4 x i32> %413, <4 x i32> %94
  %416 = icmp sgt <4 x i32> %411, %91
  %417 = select <4 x i1> %416, <4 x i32> %411, <4 x i32> %91
  %418 = icmp slt <4 x i32> %417, %94
  %419 = select <4 x i1> %418, <4 x i32> %417, <4 x i32> %94
  %420 = bitcast <2 x i64>* %408 to <4 x i32>*
  store <4 x i32> %415, <4 x i32>* %420, align 16
  %421 = bitcast <2 x i64>* %409 to <4 x i32>*
  store <4 x i32> %419, <4 x i32>* %421, align 16
  %422 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %423 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %424 = add <4 x i32> %363, %350
  %425 = sub <4 x i32> %350, %363
  %426 = icmp sgt <4 x i32> %424, %91
  %427 = select <4 x i1> %426, <4 x i32> %424, <4 x i32> %91
  %428 = icmp slt <4 x i32> %427, %94
  %429 = select <4 x i1> %428, <4 x i32> %427, <4 x i32> %94
  %430 = icmp sgt <4 x i32> %425, %91
  %431 = select <4 x i1> %430, <4 x i32> %425, <4 x i32> %91
  %432 = icmp slt <4 x i32> %431, %94
  %433 = select <4 x i1> %432, <4 x i32> %431, <4 x i32> %94
  %434 = bitcast <2 x i64>* %422 to <4 x i32>*
  store <4 x i32> %429, <4 x i32>* %434, align 16
  %435 = bitcast <2 x i64>* %423 to <4 x i32>*
  store <4 x i32> %433, <4 x i32>* %435, align 16
  %436 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %437 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %438 = add <4 x i32> %340, %355
  %439 = sub <4 x i32> %340, %355
  %440 = icmp sgt <4 x i32> %438, %91
  %441 = select <4 x i1> %440, <4 x i32> %438, <4 x i32> %91
  %442 = icmp slt <4 x i32> %441, %94
  %443 = select <4 x i1> %442, <4 x i32> %441, <4 x i32> %94
  %444 = icmp sgt <4 x i32> %439, %91
  %445 = select <4 x i1> %444, <4 x i32> %439, <4 x i32> %91
  %446 = icmp slt <4 x i32> %445, %94
  %447 = select <4 x i1> %446, <4 x i32> %445, <4 x i32> %94
  %448 = bitcast <2 x i64>* %436 to <4 x i32>*
  store <4 x i32> %443, <4 x i32>* %448, align 16
  %449 = bitcast <2 x i64>* %437 to <4 x i32>*
  store <4 x i32> %447, <4 x i32>* %449, align 16
  %450 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %451 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %452 = add <4 x i32> %330, %286
  %453 = sub <4 x i32> %330, %286
  %454 = icmp sgt <4 x i32> %452, %91
  %455 = select <4 x i1> %454, <4 x i32> %452, <4 x i32> %91
  %456 = icmp slt <4 x i32> %455, %94
  %457 = select <4 x i1> %456, <4 x i32> %455, <4 x i32> %94
  %458 = icmp sgt <4 x i32> %453, %91
  %459 = select <4 x i1> %458, <4 x i32> %453, <4 x i32> %91
  %460 = icmp slt <4 x i32> %459, %94
  %461 = select <4 x i1> %460, <4 x i32> %459, <4 x i32> %94
  %462 = bitcast <2 x i64>* %450 to <4 x i32>*
  store <4 x i32> %457, <4 x i32>* %462, align 16
  %463 = bitcast <2 x i64>* %451 to <4 x i32>*
  store <4 x i32> %461, <4 x i32>* %463, align 16
  %464 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %465 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %466 = add <4 x i32> %320, %276
  %467 = sub <4 x i32> %320, %276
  %468 = icmp sgt <4 x i32> %466, %91
  %469 = select <4 x i1> %468, <4 x i32> %466, <4 x i32> %91
  %470 = icmp slt <4 x i32> %469, %94
  %471 = select <4 x i1> %470, <4 x i32> %469, <4 x i32> %94
  %472 = icmp sgt <4 x i32> %467, %91
  %473 = select <4 x i1> %472, <4 x i32> %467, <4 x i32> %91
  %474 = icmp slt <4 x i32> %473, %94
  %475 = select <4 x i1> %474, <4 x i32> %473, <4 x i32> %94
  %476 = bitcast <2 x i64>* %464 to <4 x i32>*
  store <4 x i32> %471, <4 x i32>* %476, align 16
  %477 = bitcast <2 x i64>* %465 to <4 x i32>*
  store <4 x i32> %475, <4 x i32>* %477, align 16
  br i1 %82, label %611, label %478

478:                                              ; preds = %6
  %479 = icmp sgt i32 %4, 10
  %480 = select i1 %479, i32 %4, i32 10
  %481 = shl i32 32, %480
  %482 = sub nsw i32 0, %481
  %483 = insertelement <4 x i32> undef, i32 %482, i32 0
  %484 = shufflevector <4 x i32> %483, <4 x i32> undef, <4 x i32> zeroinitializer
  %485 = add nsw i32 %481, -1
  %486 = insertelement <4 x i32> undef, i32 %485, i32 0
  %487 = shufflevector <4 x i32> %486, <4 x i32> undef, <4 x i32> zeroinitializer
  %488 = icmp eq i32 %5, 0
  br i1 %488, label %489, label %493

489:                                              ; preds = %478
  %490 = load <4 x i32>, <4 x i32>* %378, align 16
  %491 = load <4 x i32>, <4 x i32>* %392, align 16
  %492 = load <4 x i32>, <4 x i32>* %379, align 16
  br label %530

493:                                              ; preds = %478
  %494 = add nsw i32 %5, -1
  %495 = shl i32 1, %494
  %496 = insertelement <4 x i32> undef, i32 %495, i32 0
  %497 = shufflevector <4 x i32> %496, <4 x i32> undef, <4 x i32> zeroinitializer
  %498 = add <4 x i32> %373, %497
  %499 = add <4 x i32> %387, %497
  %500 = add <4 x i32> %401, %497
  %501 = add <4 x i32> %415, %497
  %502 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %498, i32 %5) #8
  store <4 x i32> %502, <4 x i32>* %378, align 16
  %503 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %499, i32 %5) #8
  store <4 x i32> %503, <4 x i32>* %392, align 16
  %504 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %500, i32 %5) #8
  store <4 x i32> %504, <4 x i32>* %406, align 16
  %505 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %501, i32 %5) #8
  store <4 x i32> %505, <4 x i32>* %420, align 16
  %506 = add <4 x i32> %429, %497
  %507 = add <4 x i32> %443, %497
  %508 = add <4 x i32> %457, %497
  %509 = add <4 x i32> %471, %497
  %510 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %506, i32 %5) #8
  store <4 x i32> %510, <4 x i32>* %434, align 16
  %511 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %507, i32 %5) #8
  store <4 x i32> %511, <4 x i32>* %448, align 16
  %512 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %508, i32 %5) #8
  store <4 x i32> %512, <4 x i32>* %462, align 16
  %513 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %509, i32 %5) #8
  store <4 x i32> %513, <4 x i32>* %476, align 16
  %514 = add <4 x i32> %475, %497
  %515 = add <4 x i32> %461, %497
  %516 = add <4 x i32> %447, %497
  %517 = add <4 x i32> %433, %497
  %518 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %514, i32 %5) #8
  store <4 x i32> %518, <4 x i32>* %477, align 16
  %519 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %515, i32 %5) #8
  store <4 x i32> %519, <4 x i32>* %463, align 16
  %520 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %516, i32 %5) #8
  store <4 x i32> %520, <4 x i32>* %449, align 16
  %521 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %517, i32 %5) #8
  store <4 x i32> %521, <4 x i32>* %435, align 16
  %522 = add <4 x i32> %419, %497
  %523 = add <4 x i32> %405, %497
  %524 = add <4 x i32> %391, %497
  %525 = add <4 x i32> %377, %497
  %526 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %522, i32 %5) #8
  store <4 x i32> %526, <4 x i32>* %421, align 16
  %527 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %523, i32 %5) #8
  store <4 x i32> %527, <4 x i32>* %407, align 16
  %528 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %524, i32 %5) #8
  store <4 x i32> %528, <4 x i32>* %393, align 16
  %529 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %525, i32 %5) #8
  store <4 x i32> %529, <4 x i32>* %379, align 16
  br label %530

530:                                              ; preds = %489, %493
  %531 = phi <4 x i32> [ %492, %489 ], [ %529, %493 ]
  %532 = phi <4 x i32> [ %391, %489 ], [ %528, %493 ]
  %533 = phi <4 x i32> [ %405, %489 ], [ %527, %493 ]
  %534 = phi <4 x i32> [ %419, %489 ], [ %526, %493 ]
  %535 = phi <4 x i32> [ %433, %489 ], [ %521, %493 ]
  %536 = phi <4 x i32> [ %447, %489 ], [ %520, %493 ]
  %537 = phi <4 x i32> [ %461, %489 ], [ %519, %493 ]
  %538 = phi <4 x i32> [ %475, %489 ], [ %518, %493 ]
  %539 = phi <4 x i32> [ %471, %489 ], [ %513, %493 ]
  %540 = phi <4 x i32> [ %457, %489 ], [ %512, %493 ]
  %541 = phi <4 x i32> [ %443, %489 ], [ %511, %493 ]
  %542 = phi <4 x i32> [ %429, %489 ], [ %510, %493 ]
  %543 = phi <4 x i32> [ %415, %489 ], [ %505, %493 ]
  %544 = phi <4 x i32> [ %401, %489 ], [ %504, %493 ]
  %545 = phi <4 x i32> [ %491, %489 ], [ %503, %493 ]
  %546 = phi <4 x i32> [ %490, %489 ], [ %502, %493 ]
  %547 = icmp sgt <4 x i32> %546, %484
  %548 = select <4 x i1> %547, <4 x i32> %546, <4 x i32> %484
  %549 = icmp slt <4 x i32> %548, %487
  %550 = select <4 x i1> %549, <4 x i32> %548, <4 x i32> %487
  store <4 x i32> %550, <4 x i32>* %378, align 16
  %551 = icmp sgt <4 x i32> %545, %484
  %552 = select <4 x i1> %551, <4 x i32> %545, <4 x i32> %484
  %553 = icmp slt <4 x i32> %552, %487
  %554 = select <4 x i1> %553, <4 x i32> %552, <4 x i32> %487
  store <4 x i32> %554, <4 x i32>* %392, align 16
  %555 = icmp sgt <4 x i32> %544, %484
  %556 = select <4 x i1> %555, <4 x i32> %544, <4 x i32> %484
  %557 = icmp slt <4 x i32> %556, %487
  %558 = select <4 x i1> %557, <4 x i32> %556, <4 x i32> %487
  store <4 x i32> %558, <4 x i32>* %406, align 16
  %559 = icmp sgt <4 x i32> %543, %484
  %560 = select <4 x i1> %559, <4 x i32> %543, <4 x i32> %484
  %561 = icmp slt <4 x i32> %560, %487
  %562 = select <4 x i1> %561, <4 x i32> %560, <4 x i32> %487
  store <4 x i32> %562, <4 x i32>* %420, align 16
  %563 = icmp sgt <4 x i32> %542, %484
  %564 = select <4 x i1> %563, <4 x i32> %542, <4 x i32> %484
  %565 = icmp slt <4 x i32> %564, %487
  %566 = select <4 x i1> %565, <4 x i32> %564, <4 x i32> %487
  store <4 x i32> %566, <4 x i32>* %434, align 16
  %567 = icmp sgt <4 x i32> %541, %484
  %568 = select <4 x i1> %567, <4 x i32> %541, <4 x i32> %484
  %569 = icmp slt <4 x i32> %568, %487
  %570 = select <4 x i1> %569, <4 x i32> %568, <4 x i32> %487
  store <4 x i32> %570, <4 x i32>* %448, align 16
  %571 = icmp sgt <4 x i32> %540, %484
  %572 = select <4 x i1> %571, <4 x i32> %540, <4 x i32> %484
  %573 = icmp slt <4 x i32> %572, %487
  %574 = select <4 x i1> %573, <4 x i32> %572, <4 x i32> %487
  store <4 x i32> %574, <4 x i32>* %462, align 16
  %575 = icmp sgt <4 x i32> %539, %484
  %576 = select <4 x i1> %575, <4 x i32> %539, <4 x i32> %484
  %577 = icmp slt <4 x i32> %576, %487
  %578 = select <4 x i1> %577, <4 x i32> %576, <4 x i32> %487
  store <4 x i32> %578, <4 x i32>* %476, align 16
  %579 = icmp sgt <4 x i32> %538, %484
  %580 = select <4 x i1> %579, <4 x i32> %538, <4 x i32> %484
  %581 = icmp slt <4 x i32> %580, %487
  %582 = select <4 x i1> %581, <4 x i32> %580, <4 x i32> %487
  store <4 x i32> %582, <4 x i32>* %477, align 16
  %583 = icmp sgt <4 x i32> %537, %484
  %584 = select <4 x i1> %583, <4 x i32> %537, <4 x i32> %484
  %585 = icmp slt <4 x i32> %584, %487
  %586 = select <4 x i1> %585, <4 x i32> %584, <4 x i32> %487
  store <4 x i32> %586, <4 x i32>* %463, align 16
  %587 = icmp sgt <4 x i32> %536, %484
  %588 = select <4 x i1> %587, <4 x i32> %536, <4 x i32> %484
  %589 = icmp slt <4 x i32> %588, %487
  %590 = select <4 x i1> %589, <4 x i32> %588, <4 x i32> %487
  store <4 x i32> %590, <4 x i32>* %449, align 16
  %591 = icmp sgt <4 x i32> %535, %484
  %592 = select <4 x i1> %591, <4 x i32> %535, <4 x i32> %484
  %593 = icmp slt <4 x i32> %592, %487
  %594 = select <4 x i1> %593, <4 x i32> %592, <4 x i32> %487
  store <4 x i32> %594, <4 x i32>* %435, align 16
  %595 = icmp sgt <4 x i32> %534, %484
  %596 = select <4 x i1> %595, <4 x i32> %534, <4 x i32> %484
  %597 = icmp slt <4 x i32> %596, %487
  %598 = select <4 x i1> %597, <4 x i32> %596, <4 x i32> %487
  store <4 x i32> %598, <4 x i32>* %421, align 16
  %599 = icmp sgt <4 x i32> %533, %484
  %600 = select <4 x i1> %599, <4 x i32> %533, <4 x i32> %484
  %601 = icmp slt <4 x i32> %600, %487
  %602 = select <4 x i1> %601, <4 x i32> %600, <4 x i32> %487
  store <4 x i32> %602, <4 x i32>* %407, align 16
  %603 = icmp sgt <4 x i32> %532, %484
  %604 = select <4 x i1> %603, <4 x i32> %532, <4 x i32> %484
  %605 = icmp slt <4 x i32> %604, %487
  %606 = select <4 x i1> %605, <4 x i32> %604, <4 x i32> %487
  store <4 x i32> %606, <4 x i32>* %393, align 16
  %607 = icmp sgt <4 x i32> %531, %484
  %608 = select <4 x i1> %607, <4 x i32> %531, <4 x i32> %484
  %609 = icmp slt <4 x i32> %608, %487
  %610 = select <4 x i1> %609, <4 x i32> %608, <4 x i32> %487
  store <4 x i32> %610, <4 x i32>* %379, align 16
  br label %611

611:                                              ; preds = %530, %6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @idct16x16_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>*, i32, i32, i32, i32) #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 60
  %10 = load i32, i32* %9, align 16
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 4
  %14 = load i32, i32* %13, align 16
  %15 = sub nsw i32 0, %14
  %16 = insertelement <4 x i32> undef, i32 %15, i32 0
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> zeroinitializer
  %18 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 28
  %19 = load i32, i32* %18, align 16
  %20 = insertelement <4 x i32> undef, i32 %19, i32 0
  %21 = shufflevector <4 x i32> %20, <4 x i32> undef, <4 x i32> zeroinitializer
  %22 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 36
  %23 = load i32, i32* %22, align 16
  %24 = sub nsw i32 0, %23
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> zeroinitializer
  %27 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 44
  %28 = load i32, i32* %27, align 16
  %29 = insertelement <4 x i32> undef, i32 %28, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 20
  %32 = load i32, i32* %31, align 16
  %33 = insertelement <4 x i32> undef, i32 %32, i32 0
  %34 = shufflevector <4 x i32> %33, <4 x i32> undef, <4 x i32> zeroinitializer
  %35 = sub nsw i32 0, %32
  %36 = insertelement <4 x i32> undef, i32 %35, i32 0
  %37 = shufflevector <4 x i32> %36, <4 x i32> undef, <4 x i32> zeroinitializer
  %38 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 12
  %39 = load i32, i32* %38, align 16
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 52
  %43 = load i32, i32* %42, align 16
  %44 = sub nsw i32 0, %43
  %45 = insertelement <4 x i32> undef, i32 %44, i32 0
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = insertelement <4 x i32> undef, i32 %43, i32 0
  %48 = shufflevector <4 x i32> %47, <4 x i32> undef, <4 x i32> zeroinitializer
  %49 = insertelement <4 x i32> undef, i32 %23, i32 0
  %50 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> zeroinitializer
  %51 = insertelement <4 x i32> undef, i32 %14, i32 0
  %52 = shufflevector <4 x i32> %51, <4 x i32> undef, <4 x i32> zeroinitializer
  %53 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 56
  %54 = load i32, i32* %53, align 16
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 8
  %58 = load i32, i32* %57, align 16
  %59 = sub nsw i32 0, %58
  %60 = insertelement <4 x i32> undef, i32 %59, i32 0
  %61 = shufflevector <4 x i32> %60, <4 x i32> undef, <4 x i32> zeroinitializer
  %62 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 24
  %63 = load i32, i32* %62, align 16
  %64 = insertelement <4 x i32> undef, i32 %63, i32 0
  %65 = shufflevector <4 x i32> %64, <4 x i32> undef, <4 x i32> zeroinitializer
  %66 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 40
  %67 = load i32, i32* %66, align 16
  %68 = sub nsw i32 0, %67
  %69 = insertelement <4 x i32> undef, i32 %68, i32 0
  %70 = shufflevector <4 x i32> %69, <4 x i32> undef, <4 x i32> zeroinitializer
  %71 = insertelement <4 x i32> undef, i32 %67, i32 0
  %72 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> zeroinitializer
  %73 = insertelement <4 x i32> undef, i32 %58, i32 0
  %74 = shufflevector <4 x i32> %73, <4 x i32> undef, <4 x i32> zeroinitializer
  %75 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %76 = load i32, i32* %75, align 16
  %77 = insertelement <4 x i32> undef, i32 %76, i32 0
  %78 = shufflevector <4 x i32> %77, <4 x i32> undef, <4 x i32> zeroinitializer
  %79 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 48
  %80 = load i32, i32* %79, align 16
  %81 = insertelement <4 x i32> undef, i32 %80, i32 0
  %82 = shufflevector <4 x i32> %81, <4 x i32> undef, <4 x i32> zeroinitializer
  %83 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 16
  %84 = load i32, i32* %83, align 16
  %85 = insertelement <4 x i32> undef, i32 %84, i32 0
  %86 = shufflevector <4 x i32> %85, <4 x i32> undef, <4 x i32> zeroinitializer
  %87 = sub nsw i32 0, %84
  %88 = insertelement <4 x i32> undef, i32 %87, i32 0
  %89 = shufflevector <4 x i32> %88, <4 x i32> undef, <4 x i32> zeroinitializer
  %90 = sub nsw i32 0, %80
  %91 = insertelement <4 x i32> undef, i32 %90, i32 0
  %92 = shufflevector <4 x i32> %91, <4 x i32> undef, <4 x i32> zeroinitializer
  %93 = add nsw i32 %2, -1
  %94 = shl i32 1, %93
  %95 = insertelement <4 x i32> undef, i32 %94, i32 0
  %96 = shufflevector <4 x i32> %95, <4 x i32> undef, <4 x i32> zeroinitializer
  %97 = icmp ne i32 %3, 0
  %98 = select i1 %97, i32 6, i32 8
  %99 = add nsw i32 %98, %4
  %100 = icmp slt i32 %99, 16
  %101 = add i32 %99, -1
  %102 = shl i32 1, %101
  %103 = select i1 %100, i32 32768, i32 %102
  %104 = sub nsw i32 0, %103
  %105 = insertelement <4 x i32> undef, i32 %104, i32 0
  %106 = shufflevector <4 x i32> %105, <4 x i32> undef, <4 x i32> zeroinitializer
  %107 = add nsw i32 %103, -1
  %108 = insertelement <4 x i32> undef, i32 %107, i32 0
  %109 = shufflevector <4 x i32> %108, <4 x i32> undef, <4 x i32> zeroinitializer
  %110 = bitcast <2 x i64>* %0 to <4 x i32>*
  %111 = load <4 x i32>, <4 x i32>* %110, align 16
  %112 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %113 = bitcast <2 x i64>* %112 to <4 x i32>*
  %114 = load <4 x i32>, <4 x i32>* %113, align 16
  %115 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %116 = bitcast <2 x i64>* %115 to <4 x i32>*
  %117 = load <4 x i32>, <4 x i32>* %116, align 16
  %118 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %119 = bitcast <2 x i64>* %118 to <4 x i32>*
  %120 = load <4 x i32>, <4 x i32>* %119, align 16
  %121 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %122 = bitcast <2 x i64>* %121 to <4 x i32>*
  %123 = load <4 x i32>, <4 x i32>* %122, align 16
  %124 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %125 = bitcast <2 x i64>* %124 to <4 x i32>*
  %126 = load <4 x i32>, <4 x i32>* %125, align 16
  %127 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %128 = bitcast <2 x i64>* %127 to <4 x i32>*
  %129 = load <4 x i32>, <4 x i32>* %128, align 16
  %130 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %131 = bitcast <2 x i64>* %130 to <4 x i32>*
  %132 = load <4 x i32>, <4 x i32>* %131, align 16
  %133 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %134 = bitcast <2 x i64>* %133 to <4 x i32>*
  %135 = load <4 x i32>, <4 x i32>* %134, align 16
  %136 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %137 = bitcast <2 x i64>* %136 to <4 x i32>*
  %138 = load <4 x i32>, <4 x i32>* %137, align 16
  %139 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %140 = bitcast <2 x i64>* %139 to <4 x i32>*
  %141 = load <4 x i32>, <4 x i32>* %140, align 16
  %142 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %143 = bitcast <2 x i64>* %142 to <4 x i32>*
  %144 = load <4 x i32>, <4 x i32>* %143, align 16
  %145 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %146 = bitcast <2 x i64>* %145 to <4 x i32>*
  %147 = load <4 x i32>, <4 x i32>* %146, align 16
  %148 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %149 = bitcast <2 x i64>* %148 to <4 x i32>*
  %150 = load <4 x i32>, <4 x i32>* %149, align 16
  %151 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %152 = bitcast <2 x i64>* %151 to <4 x i32>*
  %153 = load <4 x i32>, <4 x i32>* %152, align 16
  %154 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %155 = bitcast <2 x i64>* %154 to <4 x i32>*
  %156 = load <4 x i32>, <4 x i32>* %155, align 16
  %157 = mul <4 x i32> %135, %12
  %158 = mul <4 x i32> %156, %17
  %159 = add <4 x i32> %157, %96
  %160 = add <4 x i32> %159, %158
  %161 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %160, i32 %2) #8
  %162 = mul <4 x i32> %138, %21
  %163 = mul <4 x i32> %153, %26
  %164 = add <4 x i32> %162, %96
  %165 = add <4 x i32> %164, %163
  %166 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %165, i32 %2) #8
  %167 = mul <4 x i32> %141, %30
  %168 = mul <4 x i32> %150, %37
  %169 = add <4 x i32> %167, %96
  %170 = add <4 x i32> %169, %168
  %171 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %170, i32 %2) #8
  %172 = mul <4 x i32> %144, %41
  %173 = mul <4 x i32> %147, %46
  %174 = add <4 x i32> %172, %96
  %175 = add <4 x i32> %174, %173
  %176 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %175, i32 %2) #8
  %177 = mul <4 x i32> %144, %48
  %178 = mul <4 x i32> %147, %41
  %179 = add <4 x i32> %177, %96
  %180 = add <4 x i32> %179, %178
  %181 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %180, i32 %2) #8
  %182 = mul <4 x i32> %141, %34
  %183 = mul <4 x i32> %150, %30
  %184 = add <4 x i32> %182, %96
  %185 = add <4 x i32> %184, %183
  %186 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %185, i32 %2) #8
  %187 = mul <4 x i32> %138, %50
  %188 = mul <4 x i32> %153, %21
  %189 = add <4 x i32> %187, %96
  %190 = add <4 x i32> %189, %188
  %191 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %190, i32 %2) #8
  %192 = mul <4 x i32> %135, %52
  %193 = mul <4 x i32> %156, %12
  %194 = add <4 x i32> %192, %96
  %195 = add <4 x i32> %194, %193
  %196 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %195, i32 %2) #8
  %197 = mul <4 x i32> %123, %56
  %198 = mul <4 x i32> %132, %61
  %199 = add <4 x i32> %197, %96
  %200 = add <4 x i32> %199, %198
  %201 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %200, i32 %2) #8
  %202 = mul <4 x i32> %126, %65
  %203 = mul <4 x i32> %129, %70
  %204 = add <4 x i32> %202, %96
  %205 = add <4 x i32> %204, %203
  %206 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %205, i32 %2) #8
  %207 = mul <4 x i32> %126, %72
  %208 = mul <4 x i32> %129, %65
  %209 = add <4 x i32> %207, %96
  %210 = add <4 x i32> %209, %208
  %211 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %210, i32 %2) #8
  %212 = mul <4 x i32> %123, %74
  %213 = mul <4 x i32> %132, %56
  %214 = add <4 x i32> %212, %96
  %215 = add <4 x i32> %214, %213
  %216 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %215, i32 %2) #8
  %217 = add <4 x i32> %166, %161
  %218 = sub <4 x i32> %161, %166
  %219 = icmp sgt <4 x i32> %217, %106
  %220 = select <4 x i1> %219, <4 x i32> %217, <4 x i32> %106
  %221 = icmp slt <4 x i32> %220, %109
  %222 = select <4 x i1> %221, <4 x i32> %220, <4 x i32> %109
  %223 = icmp sgt <4 x i32> %218, %106
  %224 = select <4 x i1> %223, <4 x i32> %218, <4 x i32> %106
  %225 = icmp slt <4 x i32> %224, %109
  %226 = select <4 x i1> %225, <4 x i32> %224, <4 x i32> %109
  %227 = add <4 x i32> %176, %171
  %228 = sub <4 x i32> %176, %171
  %229 = icmp sgt <4 x i32> %227, %106
  %230 = select <4 x i1> %229, <4 x i32> %227, <4 x i32> %106
  %231 = icmp slt <4 x i32> %230, %109
  %232 = select <4 x i1> %231, <4 x i32> %230, <4 x i32> %109
  %233 = icmp sgt <4 x i32> %228, %106
  %234 = select <4 x i1> %233, <4 x i32> %228, <4 x i32> %106
  %235 = icmp slt <4 x i32> %234, %109
  %236 = select <4 x i1> %235, <4 x i32> %234, <4 x i32> %109
  %237 = add <4 x i32> %186, %181
  %238 = sub <4 x i32> %181, %186
  %239 = icmp sgt <4 x i32> %237, %106
  %240 = select <4 x i1> %239, <4 x i32> %237, <4 x i32> %106
  %241 = icmp slt <4 x i32> %240, %109
  %242 = select <4 x i1> %241, <4 x i32> %240, <4 x i32> %109
  %243 = icmp sgt <4 x i32> %238, %106
  %244 = select <4 x i1> %243, <4 x i32> %238, <4 x i32> %106
  %245 = icmp slt <4 x i32> %244, %109
  %246 = select <4 x i1> %245, <4 x i32> %244, <4 x i32> %109
  %247 = add <4 x i32> %196, %191
  %248 = sub <4 x i32> %196, %191
  %249 = icmp sgt <4 x i32> %247, %106
  %250 = select <4 x i1> %249, <4 x i32> %247, <4 x i32> %106
  %251 = icmp slt <4 x i32> %250, %109
  %252 = select <4 x i1> %251, <4 x i32> %250, <4 x i32> %109
  %253 = icmp sgt <4 x i32> %248, %106
  %254 = select <4 x i1> %253, <4 x i32> %248, <4 x i32> %106
  %255 = icmp slt <4 x i32> %254, %109
  %256 = select <4 x i1> %255, <4 x i32> %254, <4 x i32> %109
  %257 = mul <4 x i32> %111, %78
  %258 = mul <4 x i32> %114, %78
  %259 = add <4 x i32> %257, %96
  %260 = add <4 x i32> %259, %258
  %261 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %260, i32 %2) #8
  %262 = sub <4 x i32> %259, %258
  %263 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %262, i32 %2) #8
  %264 = mul <4 x i32> %117, %82
  %265 = mul <4 x i32> %120, %89
  %266 = add <4 x i32> %264, %96
  %267 = add <4 x i32> %266, %265
  %268 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %267, i32 %2) #8
  %269 = mul <4 x i32> %117, %86
  %270 = mul <4 x i32> %120, %82
  %271 = add <4 x i32> %269, %96
  %272 = add <4 x i32> %271, %270
  %273 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %272, i32 %2) #8
  %274 = add <4 x i32> %206, %201
  %275 = sub <4 x i32> %201, %206
  %276 = icmp sgt <4 x i32> %274, %106
  %277 = select <4 x i1> %276, <4 x i32> %274, <4 x i32> %106
  %278 = icmp slt <4 x i32> %277, %109
  %279 = select <4 x i1> %278, <4 x i32> %277, <4 x i32> %109
  %280 = icmp sgt <4 x i32> %275, %106
  %281 = select <4 x i1> %280, <4 x i32> %275, <4 x i32> %106
  %282 = icmp slt <4 x i32> %281, %109
  %283 = select <4 x i1> %282, <4 x i32> %281, <4 x i32> %109
  %284 = add <4 x i32> %216, %211
  %285 = sub <4 x i32> %216, %211
  %286 = icmp sgt <4 x i32> %284, %106
  %287 = select <4 x i1> %286, <4 x i32> %284, <4 x i32> %106
  %288 = icmp slt <4 x i32> %287, %109
  %289 = select <4 x i1> %288, <4 x i32> %287, <4 x i32> %109
  %290 = icmp sgt <4 x i32> %285, %106
  %291 = select <4 x i1> %290, <4 x i32> %285, <4 x i32> %106
  %292 = icmp slt <4 x i32> %291, %109
  %293 = select <4 x i1> %292, <4 x i32> %291, <4 x i32> %109
  %294 = mul <4 x i32> %226, %89
  %295 = mul <4 x i32> %256, %82
  %296 = add <4 x i32> %294, %96
  %297 = add <4 x i32> %296, %295
  %298 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %297, i32 %2) #8
  %299 = mul <4 x i32> %236, %92
  %300 = mul <4 x i32> %246, %89
  %301 = add <4 x i32> %299, %96
  %302 = add <4 x i32> %301, %300
  %303 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %302, i32 %2) #8
  %304 = mul <4 x i32> %236, %89
  %305 = mul <4 x i32> %246, %82
  %306 = add <4 x i32> %304, %96
  %307 = add <4 x i32> %306, %305
  %308 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %307, i32 %2) #8
  %309 = mul <4 x i32> %226, %82
  %310 = mul <4 x i32> %256, %86
  %311 = add <4 x i32> %309, %96
  %312 = add <4 x i32> %311, %310
  %313 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %312, i32 %2) #8
  %314 = add <4 x i32> %273, %261
  %315 = sub <4 x i32> %261, %273
  %316 = icmp sgt <4 x i32> %314, %106
  %317 = select <4 x i1> %316, <4 x i32> %314, <4 x i32> %106
  %318 = icmp slt <4 x i32> %317, %109
  %319 = select <4 x i1> %318, <4 x i32> %317, <4 x i32> %109
  %320 = icmp sgt <4 x i32> %315, %106
  %321 = select <4 x i1> %320, <4 x i32> %315, <4 x i32> %106
  %322 = icmp slt <4 x i32> %321, %109
  %323 = select <4 x i1> %322, <4 x i32> %321, <4 x i32> %109
  %324 = add <4 x i32> %268, %263
  %325 = sub <4 x i32> %263, %268
  %326 = icmp sgt <4 x i32> %324, %106
  %327 = select <4 x i1> %326, <4 x i32> %324, <4 x i32> %106
  %328 = icmp slt <4 x i32> %327, %109
  %329 = select <4 x i1> %328, <4 x i32> %327, <4 x i32> %109
  %330 = icmp sgt <4 x i32> %325, %106
  %331 = select <4 x i1> %330, <4 x i32> %325, <4 x i32> %106
  %332 = icmp slt <4 x i32> %331, %109
  %333 = select <4 x i1> %332, <4 x i32> %331, <4 x i32> %109
  %334 = mul <4 x i32> %283, %78
  %335 = mul <4 x i32> %293, %78
  %336 = sub <4 x i32> %96, %334
  %337 = add <4 x i32> %336, %335
  %338 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %337, i32 %2) #8
  %339 = add <4 x i32> %334, %96
  %340 = add <4 x i32> %339, %335
  %341 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %340, i32 %2) #8
  %342 = add <4 x i32> %232, %222
  %343 = sub <4 x i32> %222, %232
  %344 = icmp sgt <4 x i32> %342, %106
  %345 = select <4 x i1> %344, <4 x i32> %342, <4 x i32> %106
  %346 = icmp slt <4 x i32> %345, %109
  %347 = select <4 x i1> %346, <4 x i32> %345, <4 x i32> %109
  %348 = icmp sgt <4 x i32> %343, %106
  %349 = select <4 x i1> %348, <4 x i32> %343, <4 x i32> %106
  %350 = icmp slt <4 x i32> %349, %109
  %351 = select <4 x i1> %350, <4 x i32> %349, <4 x i32> %109
  %352 = add <4 x i32> %303, %298
  %353 = sub <4 x i32> %298, %303
  %354 = icmp sgt <4 x i32> %352, %106
  %355 = select <4 x i1> %354, <4 x i32> %352, <4 x i32> %106
  %356 = icmp slt <4 x i32> %355, %109
  %357 = select <4 x i1> %356, <4 x i32> %355, <4 x i32> %109
  %358 = icmp sgt <4 x i32> %353, %106
  %359 = select <4 x i1> %358, <4 x i32> %353, <4 x i32> %106
  %360 = icmp slt <4 x i32> %359, %109
  %361 = select <4 x i1> %360, <4 x i32> %359, <4 x i32> %109
  %362 = add <4 x i32> %252, %242
  %363 = sub <4 x i32> %252, %242
  %364 = icmp sgt <4 x i32> %362, %106
  %365 = select <4 x i1> %364, <4 x i32> %362, <4 x i32> %106
  %366 = icmp slt <4 x i32> %365, %109
  %367 = select <4 x i1> %366, <4 x i32> %365, <4 x i32> %109
  %368 = icmp sgt <4 x i32> %363, %106
  %369 = select <4 x i1> %368, <4 x i32> %363, <4 x i32> %106
  %370 = icmp slt <4 x i32> %369, %109
  %371 = select <4 x i1> %370, <4 x i32> %369, <4 x i32> %109
  %372 = add <4 x i32> %313, %308
  %373 = sub <4 x i32> %313, %308
  %374 = icmp sgt <4 x i32> %372, %106
  %375 = select <4 x i1> %374, <4 x i32> %372, <4 x i32> %106
  %376 = icmp slt <4 x i32> %375, %109
  %377 = select <4 x i1> %376, <4 x i32> %375, <4 x i32> %109
  %378 = icmp sgt <4 x i32> %373, %106
  %379 = select <4 x i1> %378, <4 x i32> %373, <4 x i32> %106
  %380 = icmp slt <4 x i32> %379, %109
  %381 = select <4 x i1> %380, <4 x i32> %379, <4 x i32> %109
  %382 = add <4 x i32> %319, %289
  %383 = sub <4 x i32> %319, %289
  %384 = icmp sgt <4 x i32> %382, %106
  %385 = select <4 x i1> %384, <4 x i32> %382, <4 x i32> %106
  %386 = icmp slt <4 x i32> %385, %109
  %387 = select <4 x i1> %386, <4 x i32> %385, <4 x i32> %109
  %388 = icmp sgt <4 x i32> %383, %106
  %389 = select <4 x i1> %388, <4 x i32> %383, <4 x i32> %106
  %390 = icmp slt <4 x i32> %389, %109
  %391 = select <4 x i1> %390, <4 x i32> %389, <4 x i32> %109
  %392 = add <4 x i32> %341, %329
  %393 = sub <4 x i32> %329, %341
  %394 = icmp sgt <4 x i32> %392, %106
  %395 = select <4 x i1> %394, <4 x i32> %392, <4 x i32> %106
  %396 = icmp slt <4 x i32> %395, %109
  %397 = select <4 x i1> %396, <4 x i32> %395, <4 x i32> %109
  %398 = icmp sgt <4 x i32> %393, %106
  %399 = select <4 x i1> %398, <4 x i32> %393, <4 x i32> %106
  %400 = icmp slt <4 x i32> %399, %109
  %401 = select <4 x i1> %400, <4 x i32> %399, <4 x i32> %109
  %402 = add <4 x i32> %338, %333
  %403 = sub <4 x i32> %333, %338
  %404 = icmp sgt <4 x i32> %402, %106
  %405 = select <4 x i1> %404, <4 x i32> %402, <4 x i32> %106
  %406 = icmp slt <4 x i32> %405, %109
  %407 = select <4 x i1> %406, <4 x i32> %405, <4 x i32> %109
  %408 = icmp sgt <4 x i32> %403, %106
  %409 = select <4 x i1> %408, <4 x i32> %403, <4 x i32> %106
  %410 = icmp slt <4 x i32> %409, %109
  %411 = select <4 x i1> %410, <4 x i32> %409, <4 x i32> %109
  %412 = add <4 x i32> %323, %279
  %413 = sub <4 x i32> %323, %279
  %414 = icmp sgt <4 x i32> %412, %106
  %415 = select <4 x i1> %414, <4 x i32> %412, <4 x i32> %106
  %416 = icmp slt <4 x i32> %415, %109
  %417 = select <4 x i1> %416, <4 x i32> %415, <4 x i32> %109
  %418 = icmp sgt <4 x i32> %413, %106
  %419 = select <4 x i1> %418, <4 x i32> %413, <4 x i32> %106
  %420 = icmp slt <4 x i32> %419, %109
  %421 = select <4 x i1> %420, <4 x i32> %419, <4 x i32> %109
  %422 = mul <4 x i32> %361, %78
  %423 = mul <4 x i32> %381, %78
  %424 = sub <4 x i32> %96, %422
  %425 = add <4 x i32> %424, %423
  %426 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %425, i32 %2) #8
  %427 = add <4 x i32> %422, %96
  %428 = add <4 x i32> %427, %423
  %429 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %428, i32 %2) #8
  %430 = mul <4 x i32> %351, %78
  %431 = mul <4 x i32> %371, %78
  %432 = sub <4 x i32> %96, %430
  %433 = add <4 x i32> %432, %431
  %434 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %433, i32 %2) #8
  %435 = add <4 x i32> %430, %96
  %436 = add <4 x i32> %435, %431
  %437 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %436, i32 %2) #8
  %438 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %439 = add <4 x i32> %387, %367
  %440 = sub <4 x i32> %387, %367
  %441 = icmp sgt <4 x i32> %439, %106
  %442 = select <4 x i1> %441, <4 x i32> %439, <4 x i32> %106
  %443 = icmp slt <4 x i32> %442, %109
  %444 = select <4 x i1> %443, <4 x i32> %442, <4 x i32> %109
  %445 = icmp sgt <4 x i32> %440, %106
  %446 = select <4 x i1> %445, <4 x i32> %440, <4 x i32> %106
  %447 = icmp slt <4 x i32> %446, %109
  %448 = select <4 x i1> %447, <4 x i32> %446, <4 x i32> %109
  %449 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %444, <4 x i32>* %449, align 16
  %450 = bitcast <2 x i64>* %438 to <4 x i32>*
  store <4 x i32> %448, <4 x i32>* %450, align 16
  %451 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %452 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %453 = add <4 x i32> %397, %377
  %454 = sub <4 x i32> %397, %377
  %455 = icmp sgt <4 x i32> %453, %106
  %456 = select <4 x i1> %455, <4 x i32> %453, <4 x i32> %106
  %457 = icmp slt <4 x i32> %456, %109
  %458 = select <4 x i1> %457, <4 x i32> %456, <4 x i32> %109
  %459 = icmp sgt <4 x i32> %454, %106
  %460 = select <4 x i1> %459, <4 x i32> %454, <4 x i32> %106
  %461 = icmp slt <4 x i32> %460, %109
  %462 = select <4 x i1> %461, <4 x i32> %460, <4 x i32> %109
  %463 = bitcast <2 x i64>* %451 to <4 x i32>*
  store <4 x i32> %458, <4 x i32>* %463, align 16
  %464 = bitcast <2 x i64>* %452 to <4 x i32>*
  store <4 x i32> %462, <4 x i32>* %464, align 16
  %465 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %466 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %467 = add <4 x i32> %407, %429
  %468 = sub <4 x i32> %407, %429
  %469 = icmp sgt <4 x i32> %467, %106
  %470 = select <4 x i1> %469, <4 x i32> %467, <4 x i32> %106
  %471 = icmp slt <4 x i32> %470, %109
  %472 = select <4 x i1> %471, <4 x i32> %470, <4 x i32> %109
  %473 = icmp sgt <4 x i32> %468, %106
  %474 = select <4 x i1> %473, <4 x i32> %468, <4 x i32> %106
  %475 = icmp slt <4 x i32> %474, %109
  %476 = select <4 x i1> %475, <4 x i32> %474, <4 x i32> %109
  %477 = bitcast <2 x i64>* %465 to <4 x i32>*
  store <4 x i32> %472, <4 x i32>* %477, align 16
  %478 = bitcast <2 x i64>* %466 to <4 x i32>*
  store <4 x i32> %476, <4 x i32>* %478, align 16
  %479 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %480 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %481 = add <4 x i32> %437, %417
  %482 = sub <4 x i32> %417, %437
  %483 = icmp sgt <4 x i32> %481, %106
  %484 = select <4 x i1> %483, <4 x i32> %481, <4 x i32> %106
  %485 = icmp slt <4 x i32> %484, %109
  %486 = select <4 x i1> %485, <4 x i32> %484, <4 x i32> %109
  %487 = icmp sgt <4 x i32> %482, %106
  %488 = select <4 x i1> %487, <4 x i32> %482, <4 x i32> %106
  %489 = icmp slt <4 x i32> %488, %109
  %490 = select <4 x i1> %489, <4 x i32> %488, <4 x i32> %109
  %491 = bitcast <2 x i64>* %479 to <4 x i32>*
  store <4 x i32> %486, <4 x i32>* %491, align 16
  %492 = bitcast <2 x i64>* %480 to <4 x i32>*
  store <4 x i32> %490, <4 x i32>* %492, align 16
  %493 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %494 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %495 = add <4 x i32> %421, %434
  %496 = sub <4 x i32> %421, %434
  %497 = icmp sgt <4 x i32> %495, %106
  %498 = select <4 x i1> %497, <4 x i32> %495, <4 x i32> %106
  %499 = icmp slt <4 x i32> %498, %109
  %500 = select <4 x i1> %499, <4 x i32> %498, <4 x i32> %109
  %501 = icmp sgt <4 x i32> %496, %106
  %502 = select <4 x i1> %501, <4 x i32> %496, <4 x i32> %106
  %503 = icmp slt <4 x i32> %502, %109
  %504 = select <4 x i1> %503, <4 x i32> %502, <4 x i32> %109
  %505 = bitcast <2 x i64>* %493 to <4 x i32>*
  store <4 x i32> %500, <4 x i32>* %505, align 16
  %506 = bitcast <2 x i64>* %494 to <4 x i32>*
  store <4 x i32> %504, <4 x i32>* %506, align 16
  %507 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %508 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %509 = add <4 x i32> %411, %426
  %510 = sub <4 x i32> %411, %426
  %511 = icmp sgt <4 x i32> %509, %106
  %512 = select <4 x i1> %511, <4 x i32> %509, <4 x i32> %106
  %513 = icmp slt <4 x i32> %512, %109
  %514 = select <4 x i1> %513, <4 x i32> %512, <4 x i32> %109
  %515 = icmp sgt <4 x i32> %510, %106
  %516 = select <4 x i1> %515, <4 x i32> %510, <4 x i32> %106
  %517 = icmp slt <4 x i32> %516, %109
  %518 = select <4 x i1> %517, <4 x i32> %516, <4 x i32> %109
  %519 = bitcast <2 x i64>* %507 to <4 x i32>*
  store <4 x i32> %514, <4 x i32>* %519, align 16
  %520 = bitcast <2 x i64>* %508 to <4 x i32>*
  store <4 x i32> %518, <4 x i32>* %520, align 16
  %521 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %522 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %523 = add <4 x i32> %401, %357
  %524 = sub <4 x i32> %401, %357
  %525 = icmp sgt <4 x i32> %523, %106
  %526 = select <4 x i1> %525, <4 x i32> %523, <4 x i32> %106
  %527 = icmp slt <4 x i32> %526, %109
  %528 = select <4 x i1> %527, <4 x i32> %526, <4 x i32> %109
  %529 = icmp sgt <4 x i32> %524, %106
  %530 = select <4 x i1> %529, <4 x i32> %524, <4 x i32> %106
  %531 = icmp slt <4 x i32> %530, %109
  %532 = select <4 x i1> %531, <4 x i32> %530, <4 x i32> %109
  %533 = bitcast <2 x i64>* %521 to <4 x i32>*
  store <4 x i32> %528, <4 x i32>* %533, align 16
  %534 = bitcast <2 x i64>* %522 to <4 x i32>*
  store <4 x i32> %532, <4 x i32>* %534, align 16
  %535 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %536 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %537 = add <4 x i32> %391, %347
  %538 = sub <4 x i32> %391, %347
  %539 = icmp sgt <4 x i32> %537, %106
  %540 = select <4 x i1> %539, <4 x i32> %537, <4 x i32> %106
  %541 = icmp slt <4 x i32> %540, %109
  %542 = select <4 x i1> %541, <4 x i32> %540, <4 x i32> %109
  %543 = icmp sgt <4 x i32> %538, %106
  %544 = select <4 x i1> %543, <4 x i32> %538, <4 x i32> %106
  %545 = icmp slt <4 x i32> %544, %109
  %546 = select <4 x i1> %545, <4 x i32> %544, <4 x i32> %109
  %547 = bitcast <2 x i64>* %535 to <4 x i32>*
  store <4 x i32> %542, <4 x i32>* %547, align 16
  %548 = bitcast <2 x i64>* %536 to <4 x i32>*
  store <4 x i32> %546, <4 x i32>* %548, align 16
  br i1 %97, label %682, label %549

549:                                              ; preds = %6
  %550 = icmp sgt i32 %4, 10
  %551 = select i1 %550, i32 %4, i32 10
  %552 = shl i32 32, %551
  %553 = sub nsw i32 0, %552
  %554 = insertelement <4 x i32> undef, i32 %553, i32 0
  %555 = shufflevector <4 x i32> %554, <4 x i32> undef, <4 x i32> zeroinitializer
  %556 = add nsw i32 %552, -1
  %557 = insertelement <4 x i32> undef, i32 %556, i32 0
  %558 = shufflevector <4 x i32> %557, <4 x i32> undef, <4 x i32> zeroinitializer
  %559 = icmp eq i32 %5, 0
  br i1 %559, label %560, label %564

560:                                              ; preds = %549
  %561 = load <4 x i32>, <4 x i32>* %449, align 16
  %562 = load <4 x i32>, <4 x i32>* %463, align 16
  %563 = load <4 x i32>, <4 x i32>* %450, align 16
  br label %601

564:                                              ; preds = %549
  %565 = add nsw i32 %5, -1
  %566 = shl i32 1, %565
  %567 = insertelement <4 x i32> undef, i32 %566, i32 0
  %568 = shufflevector <4 x i32> %567, <4 x i32> undef, <4 x i32> zeroinitializer
  %569 = add <4 x i32> %444, %568
  %570 = add <4 x i32> %458, %568
  %571 = add <4 x i32> %472, %568
  %572 = add <4 x i32> %486, %568
  %573 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %569, i32 %5) #8
  store <4 x i32> %573, <4 x i32>* %449, align 16
  %574 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %570, i32 %5) #8
  store <4 x i32> %574, <4 x i32>* %463, align 16
  %575 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %571, i32 %5) #8
  store <4 x i32> %575, <4 x i32>* %477, align 16
  %576 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %572, i32 %5) #8
  store <4 x i32> %576, <4 x i32>* %491, align 16
  %577 = add <4 x i32> %500, %568
  %578 = add <4 x i32> %514, %568
  %579 = add <4 x i32> %528, %568
  %580 = add <4 x i32> %542, %568
  %581 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %577, i32 %5) #8
  store <4 x i32> %581, <4 x i32>* %505, align 16
  %582 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %578, i32 %5) #8
  store <4 x i32> %582, <4 x i32>* %519, align 16
  %583 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %579, i32 %5) #8
  store <4 x i32> %583, <4 x i32>* %533, align 16
  %584 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %580, i32 %5) #8
  store <4 x i32> %584, <4 x i32>* %547, align 16
  %585 = add <4 x i32> %546, %568
  %586 = add <4 x i32> %532, %568
  %587 = add <4 x i32> %518, %568
  %588 = add <4 x i32> %504, %568
  %589 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %585, i32 %5) #8
  store <4 x i32> %589, <4 x i32>* %548, align 16
  %590 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %586, i32 %5) #8
  store <4 x i32> %590, <4 x i32>* %534, align 16
  %591 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %587, i32 %5) #8
  store <4 x i32> %591, <4 x i32>* %520, align 16
  %592 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %588, i32 %5) #8
  store <4 x i32> %592, <4 x i32>* %506, align 16
  %593 = add <4 x i32> %490, %568
  %594 = add <4 x i32> %476, %568
  %595 = add <4 x i32> %462, %568
  %596 = add <4 x i32> %448, %568
  %597 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %593, i32 %5) #8
  store <4 x i32> %597, <4 x i32>* %492, align 16
  %598 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %594, i32 %5) #8
  store <4 x i32> %598, <4 x i32>* %478, align 16
  %599 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %595, i32 %5) #8
  store <4 x i32> %599, <4 x i32>* %464, align 16
  %600 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %596, i32 %5) #8
  store <4 x i32> %600, <4 x i32>* %450, align 16
  br label %601

601:                                              ; preds = %560, %564
  %602 = phi <4 x i32> [ %563, %560 ], [ %600, %564 ]
  %603 = phi <4 x i32> [ %462, %560 ], [ %599, %564 ]
  %604 = phi <4 x i32> [ %476, %560 ], [ %598, %564 ]
  %605 = phi <4 x i32> [ %490, %560 ], [ %597, %564 ]
  %606 = phi <4 x i32> [ %504, %560 ], [ %592, %564 ]
  %607 = phi <4 x i32> [ %518, %560 ], [ %591, %564 ]
  %608 = phi <4 x i32> [ %532, %560 ], [ %590, %564 ]
  %609 = phi <4 x i32> [ %546, %560 ], [ %589, %564 ]
  %610 = phi <4 x i32> [ %542, %560 ], [ %584, %564 ]
  %611 = phi <4 x i32> [ %528, %560 ], [ %583, %564 ]
  %612 = phi <4 x i32> [ %514, %560 ], [ %582, %564 ]
  %613 = phi <4 x i32> [ %500, %560 ], [ %581, %564 ]
  %614 = phi <4 x i32> [ %486, %560 ], [ %576, %564 ]
  %615 = phi <4 x i32> [ %472, %560 ], [ %575, %564 ]
  %616 = phi <4 x i32> [ %562, %560 ], [ %574, %564 ]
  %617 = phi <4 x i32> [ %561, %560 ], [ %573, %564 ]
  %618 = icmp sgt <4 x i32> %617, %555
  %619 = select <4 x i1> %618, <4 x i32> %617, <4 x i32> %555
  %620 = icmp slt <4 x i32> %619, %558
  %621 = select <4 x i1> %620, <4 x i32> %619, <4 x i32> %558
  store <4 x i32> %621, <4 x i32>* %449, align 16
  %622 = icmp sgt <4 x i32> %616, %555
  %623 = select <4 x i1> %622, <4 x i32> %616, <4 x i32> %555
  %624 = icmp slt <4 x i32> %623, %558
  %625 = select <4 x i1> %624, <4 x i32> %623, <4 x i32> %558
  store <4 x i32> %625, <4 x i32>* %463, align 16
  %626 = icmp sgt <4 x i32> %615, %555
  %627 = select <4 x i1> %626, <4 x i32> %615, <4 x i32> %555
  %628 = icmp slt <4 x i32> %627, %558
  %629 = select <4 x i1> %628, <4 x i32> %627, <4 x i32> %558
  store <4 x i32> %629, <4 x i32>* %477, align 16
  %630 = icmp sgt <4 x i32> %614, %555
  %631 = select <4 x i1> %630, <4 x i32> %614, <4 x i32> %555
  %632 = icmp slt <4 x i32> %631, %558
  %633 = select <4 x i1> %632, <4 x i32> %631, <4 x i32> %558
  store <4 x i32> %633, <4 x i32>* %491, align 16
  %634 = icmp sgt <4 x i32> %613, %555
  %635 = select <4 x i1> %634, <4 x i32> %613, <4 x i32> %555
  %636 = icmp slt <4 x i32> %635, %558
  %637 = select <4 x i1> %636, <4 x i32> %635, <4 x i32> %558
  store <4 x i32> %637, <4 x i32>* %505, align 16
  %638 = icmp sgt <4 x i32> %612, %555
  %639 = select <4 x i1> %638, <4 x i32> %612, <4 x i32> %555
  %640 = icmp slt <4 x i32> %639, %558
  %641 = select <4 x i1> %640, <4 x i32> %639, <4 x i32> %558
  store <4 x i32> %641, <4 x i32>* %519, align 16
  %642 = icmp sgt <4 x i32> %611, %555
  %643 = select <4 x i1> %642, <4 x i32> %611, <4 x i32> %555
  %644 = icmp slt <4 x i32> %643, %558
  %645 = select <4 x i1> %644, <4 x i32> %643, <4 x i32> %558
  store <4 x i32> %645, <4 x i32>* %533, align 16
  %646 = icmp sgt <4 x i32> %610, %555
  %647 = select <4 x i1> %646, <4 x i32> %610, <4 x i32> %555
  %648 = icmp slt <4 x i32> %647, %558
  %649 = select <4 x i1> %648, <4 x i32> %647, <4 x i32> %558
  store <4 x i32> %649, <4 x i32>* %547, align 16
  %650 = icmp sgt <4 x i32> %609, %555
  %651 = select <4 x i1> %650, <4 x i32> %609, <4 x i32> %555
  %652 = icmp slt <4 x i32> %651, %558
  %653 = select <4 x i1> %652, <4 x i32> %651, <4 x i32> %558
  store <4 x i32> %653, <4 x i32>* %548, align 16
  %654 = icmp sgt <4 x i32> %608, %555
  %655 = select <4 x i1> %654, <4 x i32> %608, <4 x i32> %555
  %656 = icmp slt <4 x i32> %655, %558
  %657 = select <4 x i1> %656, <4 x i32> %655, <4 x i32> %558
  store <4 x i32> %657, <4 x i32>* %534, align 16
  %658 = icmp sgt <4 x i32> %607, %555
  %659 = select <4 x i1> %658, <4 x i32> %607, <4 x i32> %555
  %660 = icmp slt <4 x i32> %659, %558
  %661 = select <4 x i1> %660, <4 x i32> %659, <4 x i32> %558
  store <4 x i32> %661, <4 x i32>* %520, align 16
  %662 = icmp sgt <4 x i32> %606, %555
  %663 = select <4 x i1> %662, <4 x i32> %606, <4 x i32> %555
  %664 = icmp slt <4 x i32> %663, %558
  %665 = select <4 x i1> %664, <4 x i32> %663, <4 x i32> %558
  store <4 x i32> %665, <4 x i32>* %506, align 16
  %666 = icmp sgt <4 x i32> %605, %555
  %667 = select <4 x i1> %666, <4 x i32> %605, <4 x i32> %555
  %668 = icmp slt <4 x i32> %667, %558
  %669 = select <4 x i1> %668, <4 x i32> %667, <4 x i32> %558
  store <4 x i32> %669, <4 x i32>* %492, align 16
  %670 = icmp sgt <4 x i32> %604, %555
  %671 = select <4 x i1> %670, <4 x i32> %604, <4 x i32> %555
  %672 = icmp slt <4 x i32> %671, %558
  %673 = select <4 x i1> %672, <4 x i32> %671, <4 x i32> %558
  store <4 x i32> %673, <4 x i32>* %478, align 16
  %674 = icmp sgt <4 x i32> %603, %555
  %675 = select <4 x i1> %674, <4 x i32> %603, <4 x i32> %555
  %676 = icmp slt <4 x i32> %675, %558
  %677 = select <4 x i1> %676, <4 x i32> %675, <4 x i32> %558
  store <4 x i32> %677, <4 x i32>* %464, align 16
  %678 = icmp sgt <4 x i32> %602, %555
  %679 = select <4 x i1> %678, <4 x i32> %602, <4 x i32> %555
  %680 = icmp slt <4 x i32> %679, %558
  %681 = select <4 x i1> %680, <4 x i32> %679, <4 x i32> %558
  store <4 x i32> %681, <4 x i32>* %450, align 16
  br label %682

682:                                              ; preds = %601, %6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @iadst16x16_low1_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>*, i32, i32, i32, i32) #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 2
  %10 = load i32, i32* %9, align 8
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 62
  %14 = load i32, i32* %13, align 8
  %15 = insertelement <4 x i32> undef, i32 %14, i32 0
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> zeroinitializer
  %17 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 8
  %18 = load i32, i32* %17, align 16
  %19 = insertelement <4 x i32> undef, i32 %18, i32 0
  %20 = shufflevector <4 x i32> %19, <4 x i32> undef, <4 x i32> zeroinitializer
  %21 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 56
  %22 = load i32, i32* %21, align 16
  %23 = insertelement <4 x i32> undef, i32 %22, i32 0
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> zeroinitializer
  %25 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 48
  %26 = load i32, i32* %25, align 16
  %27 = insertelement <4 x i32> undef, i32 %26, i32 0
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> zeroinitializer
  %29 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 16
  %30 = load i32, i32* %29, align 16
  %31 = insertelement <4 x i32> undef, i32 %30, i32 0
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> zeroinitializer
  %33 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %34 = load i32, i32* %33, align 16
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = add nsw i32 %2, -1
  %38 = shl i32 1, %37
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> zeroinitializer
  %41 = bitcast <2 x i64>* %0 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 16
  %43 = mul <4 x i32> %42, %16
  %44 = add <4 x i32> %43, %40
  %45 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %44, i32 %2) #8
  %46 = mul <4 x i32> %42, %12
  %47 = sub <4 x i32> %40, %46
  %48 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %47, i32 %2) #8
  %49 = mul <4 x i32> %45, %20
  %50 = mul <4 x i32> %48, %24
  %51 = add <4 x i32> %49, %40
  %52 = add <4 x i32> %51, %50
  %53 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %52, i32 %2) #8
  %54 = mul <4 x i32> %45, %24
  %55 = mul <4 x i32> %20, %48
  %56 = add <4 x i32> %54, %40
  %57 = sub <4 x i32> %56, %55
  %58 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %57, i32 %2) #8
  %59 = mul <4 x i32> %45, %32
  %60 = mul <4 x i32> %48, %28
  %61 = add <4 x i32> %59, %40
  %62 = add <4 x i32> %61, %60
  %63 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %62, i32 %2) #8
  %64 = mul <4 x i32> %45, %28
  %65 = mul <4 x i32> %32, %48
  %66 = add <4 x i32> %64, %40
  %67 = sub <4 x i32> %66, %65
  %68 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %67, i32 %2) #8
  %69 = mul <4 x i32> %53, %32
  %70 = mul <4 x i32> %58, %28
  %71 = add <4 x i32> %69, %40
  %72 = add <4 x i32> %71, %70
  %73 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %72, i32 %2) #8
  %74 = mul <4 x i32> %53, %28
  %75 = mul <4 x i32> %32, %58
  %76 = add <4 x i32> %74, %40
  %77 = sub <4 x i32> %76, %75
  %78 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %77, i32 %2) #8
  %79 = mul <4 x i32> %36, %45
  %80 = mul <4 x i32> %48, %36
  %81 = add <4 x i32> %79, %40
  %82 = add <4 x i32> %81, %80
  %83 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %82, i32 %2) #8
  %84 = sub <4 x i32> %81, %80
  %85 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %84, i32 %2) #8
  %86 = mul <4 x i32> %63, %36
  %87 = mul <4 x i32> %68, %36
  %88 = add <4 x i32> %86, %40
  %89 = add <4 x i32> %88, %87
  %90 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %89, i32 %2) #8
  %91 = sub <4 x i32> %88, %87
  %92 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %91, i32 %2) #8
  %93 = mul <4 x i32> %53, %36
  %94 = mul <4 x i32> %58, %36
  %95 = add <4 x i32> %93, %40
  %96 = add <4 x i32> %95, %94
  %97 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %96, i32 %2) #8
  %98 = sub <4 x i32> %95, %94
  %99 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %98, i32 %2) #8
  %100 = mul <4 x i32> %73, %36
  %101 = mul <4 x i32> %78, %36
  %102 = add <4 x i32> %100, %40
  %103 = add <4 x i32> %102, %101
  %104 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %103, i32 %2) #8
  %105 = sub <4 x i32> %102, %101
  %106 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %105, i32 %2) #8
  %107 = icmp eq i32 %3, 0
  br i1 %107, label %146, label %108

108:                                              ; preds = %6
  %109 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %45, <4 x i32>* %109, align 16
  %110 = sub <4 x i32> zeroinitializer, %53
  %111 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %112 = bitcast <2 x i64>* %111 to <4 x i32>*
  store <4 x i32> %110, <4 x i32>* %112, align 16
  %113 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %114 = bitcast <2 x i64>* %113 to <4 x i32>*
  store <4 x i32> %73, <4 x i32>* %114, align 16
  %115 = sub <4 x i32> zeroinitializer, %63
  %116 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %117 = bitcast <2 x i64>* %116 to <4 x i32>*
  store <4 x i32> %115, <4 x i32>* %117, align 16
  %118 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %119 = bitcast <2 x i64>* %118 to <4 x i32>*
  store <4 x i32> %90, <4 x i32>* %119, align 16
  %120 = sub <4 x i32> zeroinitializer, %104
  %121 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %122 = bitcast <2 x i64>* %121 to <4 x i32>*
  store <4 x i32> %120, <4 x i32>* %122, align 16
  %123 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %124 = bitcast <2 x i64>* %123 to <4 x i32>*
  store <4 x i32> %97, <4 x i32>* %124, align 16
  %125 = sub <4 x i32> zeroinitializer, %83
  %126 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %127 = bitcast <2 x i64>* %126 to <4 x i32>*
  store <4 x i32> %125, <4 x i32>* %127, align 16
  %128 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %129 = bitcast <2 x i64>* %128 to <4 x i32>*
  store <4 x i32> %85, <4 x i32>* %129, align 16
  %130 = sub <4 x i32> zeroinitializer, %99
  %131 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %132 = bitcast <2 x i64>* %131 to <4 x i32>*
  store <4 x i32> %130, <4 x i32>* %132, align 16
  %133 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %134 = bitcast <2 x i64>* %133 to <4 x i32>*
  store <4 x i32> %106, <4 x i32>* %134, align 16
  %135 = sub <4 x i32> zeroinitializer, %92
  %136 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %137 = bitcast <2 x i64>* %136 to <4 x i32>*
  store <4 x i32> %135, <4 x i32>* %137, align 16
  %138 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %139 = bitcast <2 x i64>* %138 to <4 x i32>*
  store <4 x i32> %68, <4 x i32>* %139, align 16
  %140 = sub <4 x i32> zeroinitializer, %78
  %141 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %142 = bitcast <2 x i64>* %141 to <4 x i32>*
  store <4 x i32> %140, <4 x i32>* %142, align 16
  %143 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %144 = bitcast <2 x i64>* %143 to <4 x i32>*
  store <4 x i32> %58, <4 x i32>* %144, align 16
  %145 = sub <4 x i32> zeroinitializer, %48
  br label %286

146:                                              ; preds = %6
  %147 = icmp sgt i32 %4, 10
  %148 = select i1 %147, i32 %4, i32 10
  %149 = shl i32 32, %148
  %150 = sub nsw i32 0, %149
  %151 = insertelement <4 x i32> undef, i32 %150, i32 0
  %152 = shufflevector <4 x i32> %151, <4 x i32> undef, <4 x i32> zeroinitializer
  %153 = add nsw i32 %149, -1
  %154 = insertelement <4 x i32> undef, i32 %153, i32 0
  %155 = shufflevector <4 x i32> %154, <4 x i32> undef, <4 x i32> zeroinitializer
  %156 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %157 = shl i32 1, %5
  %158 = ashr i32 %157, 1
  %159 = insertelement <4 x i32> undef, i32 %158, i32 0
  %160 = shufflevector <4 x i32> %159, <4 x i32> undef, <4 x i32> zeroinitializer
  %161 = add <4 x i32> %45, %160
  %162 = sub <4 x i32> %160, %53
  %163 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %5, i32 0
  %164 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %161, <4 x i32> %163) #8
  %165 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %162, <4 x i32> %163) #8
  %166 = icmp sgt <4 x i32> %164, %152
  %167 = select <4 x i1> %166, <4 x i32> %164, <4 x i32> %152
  %168 = icmp slt <4 x i32> %167, %155
  %169 = select <4 x i1> %168, <4 x i32> %167, <4 x i32> %155
  %170 = icmp sgt <4 x i32> %165, %152
  %171 = select <4 x i1> %170, <4 x i32> %165, <4 x i32> %152
  %172 = icmp slt <4 x i32> %171, %155
  %173 = select <4 x i1> %172, <4 x i32> %171, <4 x i32> %155
  %174 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %169, <4 x i32>* %174, align 16
  %175 = bitcast <2 x i64>* %156 to <4 x i32>*
  store <4 x i32> %173, <4 x i32>* %175, align 16
  %176 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %177 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %178 = add <4 x i32> %73, %160
  %179 = sub <4 x i32> %160, %63
  %180 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %178, <4 x i32> %163) #8
  %181 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %179, <4 x i32> %163) #8
  %182 = icmp sgt <4 x i32> %180, %152
  %183 = select <4 x i1> %182, <4 x i32> %180, <4 x i32> %152
  %184 = icmp slt <4 x i32> %183, %155
  %185 = select <4 x i1> %184, <4 x i32> %183, <4 x i32> %155
  %186 = icmp sgt <4 x i32> %181, %152
  %187 = select <4 x i1> %186, <4 x i32> %181, <4 x i32> %152
  %188 = icmp slt <4 x i32> %187, %155
  %189 = select <4 x i1> %188, <4 x i32> %187, <4 x i32> %155
  %190 = bitcast <2 x i64>* %176 to <4 x i32>*
  store <4 x i32> %185, <4 x i32>* %190, align 16
  %191 = bitcast <2 x i64>* %177 to <4 x i32>*
  store <4 x i32> %189, <4 x i32>* %191, align 16
  %192 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %193 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %194 = add <4 x i32> %90, %160
  %195 = sub <4 x i32> %160, %104
  %196 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %194, <4 x i32> %163) #8
  %197 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %195, <4 x i32> %163) #8
  %198 = icmp sgt <4 x i32> %196, %152
  %199 = select <4 x i1> %198, <4 x i32> %196, <4 x i32> %152
  %200 = icmp slt <4 x i32> %199, %155
  %201 = select <4 x i1> %200, <4 x i32> %199, <4 x i32> %155
  %202 = icmp sgt <4 x i32> %197, %152
  %203 = select <4 x i1> %202, <4 x i32> %197, <4 x i32> %152
  %204 = icmp slt <4 x i32> %203, %155
  %205 = select <4 x i1> %204, <4 x i32> %203, <4 x i32> %155
  %206 = bitcast <2 x i64>* %192 to <4 x i32>*
  store <4 x i32> %201, <4 x i32>* %206, align 16
  %207 = bitcast <2 x i64>* %193 to <4 x i32>*
  store <4 x i32> %205, <4 x i32>* %207, align 16
  %208 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %209 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %210 = add <4 x i32> %97, %160
  %211 = sub <4 x i32> %160, %83
  %212 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %210, <4 x i32> %163) #8
  %213 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %211, <4 x i32> %163) #8
  %214 = icmp sgt <4 x i32> %212, %152
  %215 = select <4 x i1> %214, <4 x i32> %212, <4 x i32> %152
  %216 = icmp slt <4 x i32> %215, %155
  %217 = select <4 x i1> %216, <4 x i32> %215, <4 x i32> %155
  %218 = icmp sgt <4 x i32> %213, %152
  %219 = select <4 x i1> %218, <4 x i32> %213, <4 x i32> %152
  %220 = icmp slt <4 x i32> %219, %155
  %221 = select <4 x i1> %220, <4 x i32> %219, <4 x i32> %155
  %222 = bitcast <2 x i64>* %208 to <4 x i32>*
  store <4 x i32> %217, <4 x i32>* %222, align 16
  %223 = bitcast <2 x i64>* %209 to <4 x i32>*
  store <4 x i32> %221, <4 x i32>* %223, align 16
  %224 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %225 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %226 = add <4 x i32> %85, %160
  %227 = sub <4 x i32> %160, %99
  %228 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %226, <4 x i32> %163) #8
  %229 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %227, <4 x i32> %163) #8
  %230 = icmp sgt <4 x i32> %228, %152
  %231 = select <4 x i1> %230, <4 x i32> %228, <4 x i32> %152
  %232 = icmp slt <4 x i32> %231, %155
  %233 = select <4 x i1> %232, <4 x i32> %231, <4 x i32> %155
  %234 = icmp sgt <4 x i32> %229, %152
  %235 = select <4 x i1> %234, <4 x i32> %229, <4 x i32> %152
  %236 = icmp slt <4 x i32> %235, %155
  %237 = select <4 x i1> %236, <4 x i32> %235, <4 x i32> %155
  %238 = bitcast <2 x i64>* %224 to <4 x i32>*
  store <4 x i32> %233, <4 x i32>* %238, align 16
  %239 = bitcast <2 x i64>* %225 to <4 x i32>*
  store <4 x i32> %237, <4 x i32>* %239, align 16
  %240 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %241 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %242 = add <4 x i32> %106, %160
  %243 = sub <4 x i32> %160, %92
  %244 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %242, <4 x i32> %163) #8
  %245 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %243, <4 x i32> %163) #8
  %246 = icmp sgt <4 x i32> %244, %152
  %247 = select <4 x i1> %246, <4 x i32> %244, <4 x i32> %152
  %248 = icmp slt <4 x i32> %247, %155
  %249 = select <4 x i1> %248, <4 x i32> %247, <4 x i32> %155
  %250 = icmp sgt <4 x i32> %245, %152
  %251 = select <4 x i1> %250, <4 x i32> %245, <4 x i32> %152
  %252 = icmp slt <4 x i32> %251, %155
  %253 = select <4 x i1> %252, <4 x i32> %251, <4 x i32> %155
  %254 = bitcast <2 x i64>* %240 to <4 x i32>*
  store <4 x i32> %249, <4 x i32>* %254, align 16
  %255 = bitcast <2 x i64>* %241 to <4 x i32>*
  store <4 x i32> %253, <4 x i32>* %255, align 16
  %256 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %257 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %258 = add <4 x i32> %68, %160
  %259 = sub <4 x i32> %160, %78
  %260 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %258, <4 x i32> %163) #8
  %261 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %259, <4 x i32> %163) #8
  %262 = icmp sgt <4 x i32> %260, %152
  %263 = select <4 x i1> %262, <4 x i32> %260, <4 x i32> %152
  %264 = icmp slt <4 x i32> %263, %155
  %265 = select <4 x i1> %264, <4 x i32> %263, <4 x i32> %155
  %266 = icmp sgt <4 x i32> %261, %152
  %267 = select <4 x i1> %266, <4 x i32> %261, <4 x i32> %152
  %268 = icmp slt <4 x i32> %267, %155
  %269 = select <4 x i1> %268, <4 x i32> %267, <4 x i32> %155
  %270 = bitcast <2 x i64>* %256 to <4 x i32>*
  store <4 x i32> %265, <4 x i32>* %270, align 16
  %271 = bitcast <2 x i64>* %257 to <4 x i32>*
  store <4 x i32> %269, <4 x i32>* %271, align 16
  %272 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %273 = add <4 x i32> %58, %160
  %274 = sub <4 x i32> %160, %48
  %275 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %273, <4 x i32> %163) #8
  %276 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %274, <4 x i32> %163) #8
  %277 = icmp sgt <4 x i32> %275, %152
  %278 = select <4 x i1> %277, <4 x i32> %275, <4 x i32> %152
  %279 = icmp slt <4 x i32> %278, %155
  %280 = select <4 x i1> %279, <4 x i32> %278, <4 x i32> %155
  %281 = icmp sgt <4 x i32> %276, %152
  %282 = select <4 x i1> %281, <4 x i32> %276, <4 x i32> %152
  %283 = icmp slt <4 x i32> %282, %155
  %284 = select <4 x i1> %283, <4 x i32> %282, <4 x i32> %155
  %285 = bitcast <2 x i64>* %272 to <4 x i32>*
  store <4 x i32> %280, <4 x i32>* %285, align 16
  br label %286

286:                                              ; preds = %146, %108
  %287 = phi <4 x i32> [ %284, %146 ], [ %145, %108 ]
  %288 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %289 = bitcast <2 x i64>* %288 to <4 x i32>*
  store <4 x i32> %287, <4 x i32>* %289, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @iadst16x16_low8_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>*, i32, i32, i32, i32) #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 2
  %10 = load i32, i32* %9, align 8
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 62
  %14 = load i32, i32* %13, align 8
  %15 = insertelement <4 x i32> undef, i32 %14, i32 0
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> zeroinitializer
  %17 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 10
  %18 = load i32, i32* %17, align 8
  %19 = insertelement <4 x i32> undef, i32 %18, i32 0
  %20 = shufflevector <4 x i32> %19, <4 x i32> undef, <4 x i32> zeroinitializer
  %21 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 54
  %22 = load i32, i32* %21, align 8
  %23 = insertelement <4 x i32> undef, i32 %22, i32 0
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> zeroinitializer
  %25 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 18
  %26 = load i32, i32* %25, align 8
  %27 = insertelement <4 x i32> undef, i32 %26, i32 0
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> zeroinitializer
  %29 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 46
  %30 = load i32, i32* %29, align 8
  %31 = insertelement <4 x i32> undef, i32 %30, i32 0
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> zeroinitializer
  %33 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 26
  %34 = load i32, i32* %33, align 8
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 38
  %38 = load i32, i32* %37, align 8
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> zeroinitializer
  %41 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 34
  %42 = load i32, i32* %41, align 8
  %43 = insertelement <4 x i32> undef, i32 %42, i32 0
  %44 = shufflevector <4 x i32> %43, <4 x i32> undef, <4 x i32> zeroinitializer
  %45 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 30
  %46 = load i32, i32* %45, align 8
  %47 = insertelement <4 x i32> undef, i32 %46, i32 0
  %48 = shufflevector <4 x i32> %47, <4 x i32> undef, <4 x i32> zeroinitializer
  %49 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 42
  %50 = load i32, i32* %49, align 8
  %51 = insertelement <4 x i32> undef, i32 %50, i32 0
  %52 = shufflevector <4 x i32> %51, <4 x i32> undef, <4 x i32> zeroinitializer
  %53 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 22
  %54 = load i32, i32* %53, align 8
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 50
  %58 = load i32, i32* %57, align 8
  %59 = insertelement <4 x i32> undef, i32 %58, i32 0
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 14
  %62 = load i32, i32* %61, align 8
  %63 = insertelement <4 x i32> undef, i32 %62, i32 0
  %64 = shufflevector <4 x i32> %63, <4 x i32> undef, <4 x i32> zeroinitializer
  %65 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 58
  %66 = load i32, i32* %65, align 8
  %67 = insertelement <4 x i32> undef, i32 %66, i32 0
  %68 = shufflevector <4 x i32> %67, <4 x i32> undef, <4 x i32> zeroinitializer
  %69 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 6
  %70 = load i32, i32* %69, align 8
  %71 = insertelement <4 x i32> undef, i32 %70, i32 0
  %72 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> zeroinitializer
  %73 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 8
  %74 = load i32, i32* %73, align 16
  %75 = insertelement <4 x i32> undef, i32 %74, i32 0
  %76 = shufflevector <4 x i32> %75, <4 x i32> undef, <4 x i32> zeroinitializer
  %77 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 56
  %78 = load i32, i32* %77, align 16
  %79 = insertelement <4 x i32> undef, i32 %78, i32 0
  %80 = shufflevector <4 x i32> %79, <4 x i32> undef, <4 x i32> zeroinitializer
  %81 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 40
  %82 = load i32, i32* %81, align 16
  %83 = insertelement <4 x i32> undef, i32 %82, i32 0
  %84 = shufflevector <4 x i32> %83, <4 x i32> undef, <4 x i32> zeroinitializer
  %85 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 24
  %86 = load i32, i32* %85, align 16
  %87 = insertelement <4 x i32> undef, i32 %86, i32 0
  %88 = shufflevector <4 x i32> %87, <4 x i32> undef, <4 x i32> zeroinitializer
  %89 = sub nsw i32 0, %78
  %90 = insertelement <4 x i32> undef, i32 %89, i32 0
  %91 = shufflevector <4 x i32> %90, <4 x i32> undef, <4 x i32> zeroinitializer
  %92 = sub nsw i32 0, %86
  %93 = insertelement <4 x i32> undef, i32 %92, i32 0
  %94 = shufflevector <4 x i32> %93, <4 x i32> undef, <4 x i32> zeroinitializer
  %95 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 48
  %96 = load i32, i32* %95, align 16
  %97 = insertelement <4 x i32> undef, i32 %96, i32 0
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> zeroinitializer
  %99 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 16
  %100 = load i32, i32* %99, align 16
  %101 = insertelement <4 x i32> undef, i32 %100, i32 0
  %102 = shufflevector <4 x i32> %101, <4 x i32> undef, <4 x i32> zeroinitializer
  %103 = sub nsw i32 0, %96
  %104 = insertelement <4 x i32> undef, i32 %103, i32 0
  %105 = shufflevector <4 x i32> %104, <4 x i32> undef, <4 x i32> zeroinitializer
  %106 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %107 = load i32, i32* %106, align 16
  %108 = insertelement <4 x i32> undef, i32 %107, i32 0
  %109 = shufflevector <4 x i32> %108, <4 x i32> undef, <4 x i32> zeroinitializer
  %110 = add nsw i32 %2, -1
  %111 = shl i32 1, %110
  %112 = insertelement <4 x i32> undef, i32 %111, i32 0
  %113 = shufflevector <4 x i32> %112, <4 x i32> undef, <4 x i32> zeroinitializer
  %114 = icmp ne i32 %3, 0
  %115 = select i1 %114, i32 6, i32 8
  %116 = add nsw i32 %115, %4
  %117 = icmp slt i32 %116, 16
  %118 = add i32 %116, -1
  %119 = shl i32 1, %118
  %120 = select i1 %117, i32 32768, i32 %119
  %121 = sub nsw i32 0, %120
  %122 = insertelement <4 x i32> undef, i32 %121, i32 0
  %123 = shufflevector <4 x i32> %122, <4 x i32> undef, <4 x i32> zeroinitializer
  %124 = add nsw i32 %120, -1
  %125 = insertelement <4 x i32> undef, i32 %124, i32 0
  %126 = shufflevector <4 x i32> %125, <4 x i32> undef, <4 x i32> zeroinitializer
  %127 = bitcast <2 x i64>* %0 to <4 x i32>*
  %128 = load <4 x i32>, <4 x i32>* %127, align 16
  %129 = mul <4 x i32> %128, %16
  %130 = add <4 x i32> %129, %113
  %131 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %130, i32 %2) #8
  %132 = mul <4 x i32> %128, %12
  %133 = sub <4 x i32> %113, %132
  %134 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %133, i32 %2) #8
  %135 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %136 = bitcast <2 x i64>* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 16
  %138 = mul <4 x i32> %137, %24
  %139 = add <4 x i32> %138, %113
  %140 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %139, i32 %2) #8
  %141 = mul <4 x i32> %137, %20
  %142 = sub <4 x i32> %113, %141
  %143 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %142, i32 %2) #8
  %144 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %145 = bitcast <2 x i64>* %144 to <4 x i32>*
  %146 = load <4 x i32>, <4 x i32>* %145, align 16
  %147 = mul <4 x i32> %146, %32
  %148 = add <4 x i32> %147, %113
  %149 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %148, i32 %2) #8
  %150 = mul <4 x i32> %146, %28
  %151 = sub <4 x i32> %113, %150
  %152 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %151, i32 %2) #8
  %153 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %154 = bitcast <2 x i64>* %153 to <4 x i32>*
  %155 = load <4 x i32>, <4 x i32>* %154, align 16
  %156 = mul <4 x i32> %155, %40
  %157 = add <4 x i32> %156, %113
  %158 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %157, i32 %2) #8
  %159 = mul <4 x i32> %155, %36
  %160 = sub <4 x i32> %113, %159
  %161 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %160, i32 %2) #8
  %162 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %163 = bitcast <2 x i64>* %162 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = mul <4 x i32> %164, %44
  %166 = add <4 x i32> %165, %113
  %167 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %166, i32 %2) #8
  %168 = mul <4 x i32> %164, %48
  %169 = add <4 x i32> %168, %113
  %170 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %169, i32 %2) #8
  %171 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %172 = bitcast <2 x i64>* %171 to <4 x i32>*
  %173 = load <4 x i32>, <4 x i32>* %172, align 16
  %174 = mul <4 x i32> %173, %52
  %175 = add <4 x i32> %174, %113
  %176 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %175, i32 %2) #8
  %177 = mul <4 x i32> %173, %56
  %178 = add <4 x i32> %177, %113
  %179 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %178, i32 %2) #8
  %180 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %181 = bitcast <2 x i64>* %180 to <4 x i32>*
  %182 = load <4 x i32>, <4 x i32>* %181, align 16
  %183 = mul <4 x i32> %182, %60
  %184 = add <4 x i32> %183, %113
  %185 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %184, i32 %2) #8
  %186 = mul <4 x i32> %182, %64
  %187 = add <4 x i32> %186, %113
  %188 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %187, i32 %2) #8
  %189 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %190 = bitcast <2 x i64>* %189 to <4 x i32>*
  %191 = load <4 x i32>, <4 x i32>* %190, align 16
  %192 = mul <4 x i32> %191, %68
  %193 = add <4 x i32> %192, %113
  %194 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %193, i32 %2) #8
  %195 = mul <4 x i32> %191, %72
  %196 = add <4 x i32> %195, %113
  %197 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %196, i32 %2) #8
  %198 = add <4 x i32> %167, %131
  %199 = sub <4 x i32> %131, %167
  %200 = icmp sgt <4 x i32> %198, %123
  %201 = select <4 x i1> %200, <4 x i32> %198, <4 x i32> %123
  %202 = icmp slt <4 x i32> %201, %126
  %203 = select <4 x i1> %202, <4 x i32> %201, <4 x i32> %126
  %204 = icmp sgt <4 x i32> %199, %123
  %205 = select <4 x i1> %204, <4 x i32> %199, <4 x i32> %123
  %206 = icmp slt <4 x i32> %205, %126
  %207 = select <4 x i1> %206, <4 x i32> %205, <4 x i32> %126
  %208 = add <4 x i32> %170, %134
  %209 = sub <4 x i32> %134, %170
  %210 = icmp sgt <4 x i32> %208, %123
  %211 = select <4 x i1> %210, <4 x i32> %208, <4 x i32> %123
  %212 = icmp slt <4 x i32> %211, %126
  %213 = select <4 x i1> %212, <4 x i32> %211, <4 x i32> %126
  %214 = icmp sgt <4 x i32> %209, %123
  %215 = select <4 x i1> %214, <4 x i32> %209, <4 x i32> %123
  %216 = icmp slt <4 x i32> %215, %126
  %217 = select <4 x i1> %216, <4 x i32> %215, <4 x i32> %126
  %218 = add <4 x i32> %176, %140
  %219 = sub <4 x i32> %140, %176
  %220 = icmp sgt <4 x i32> %218, %123
  %221 = select <4 x i1> %220, <4 x i32> %218, <4 x i32> %123
  %222 = icmp slt <4 x i32> %221, %126
  %223 = select <4 x i1> %222, <4 x i32> %221, <4 x i32> %126
  %224 = icmp sgt <4 x i32> %219, %123
  %225 = select <4 x i1> %224, <4 x i32> %219, <4 x i32> %123
  %226 = icmp slt <4 x i32> %225, %126
  %227 = select <4 x i1> %226, <4 x i32> %225, <4 x i32> %126
  %228 = add <4 x i32> %179, %143
  %229 = sub <4 x i32> %143, %179
  %230 = icmp sgt <4 x i32> %228, %123
  %231 = select <4 x i1> %230, <4 x i32> %228, <4 x i32> %123
  %232 = icmp slt <4 x i32> %231, %126
  %233 = select <4 x i1> %232, <4 x i32> %231, <4 x i32> %126
  %234 = icmp sgt <4 x i32> %229, %123
  %235 = select <4 x i1> %234, <4 x i32> %229, <4 x i32> %123
  %236 = icmp slt <4 x i32> %235, %126
  %237 = select <4 x i1> %236, <4 x i32> %235, <4 x i32> %126
  %238 = add <4 x i32> %185, %149
  %239 = sub <4 x i32> %149, %185
  %240 = icmp sgt <4 x i32> %238, %123
  %241 = select <4 x i1> %240, <4 x i32> %238, <4 x i32> %123
  %242 = icmp slt <4 x i32> %241, %126
  %243 = select <4 x i1> %242, <4 x i32> %241, <4 x i32> %126
  %244 = icmp sgt <4 x i32> %239, %123
  %245 = select <4 x i1> %244, <4 x i32> %239, <4 x i32> %123
  %246 = icmp slt <4 x i32> %245, %126
  %247 = select <4 x i1> %246, <4 x i32> %245, <4 x i32> %126
  %248 = add <4 x i32> %188, %152
  %249 = sub <4 x i32> %152, %188
  %250 = icmp sgt <4 x i32> %248, %123
  %251 = select <4 x i1> %250, <4 x i32> %248, <4 x i32> %123
  %252 = icmp slt <4 x i32> %251, %126
  %253 = select <4 x i1> %252, <4 x i32> %251, <4 x i32> %126
  %254 = icmp sgt <4 x i32> %249, %123
  %255 = select <4 x i1> %254, <4 x i32> %249, <4 x i32> %123
  %256 = icmp slt <4 x i32> %255, %126
  %257 = select <4 x i1> %256, <4 x i32> %255, <4 x i32> %126
  %258 = add <4 x i32> %194, %158
  %259 = sub <4 x i32> %158, %194
  %260 = icmp sgt <4 x i32> %258, %123
  %261 = select <4 x i1> %260, <4 x i32> %258, <4 x i32> %123
  %262 = icmp slt <4 x i32> %261, %126
  %263 = select <4 x i1> %262, <4 x i32> %261, <4 x i32> %126
  %264 = icmp sgt <4 x i32> %259, %123
  %265 = select <4 x i1> %264, <4 x i32> %259, <4 x i32> %123
  %266 = icmp slt <4 x i32> %265, %126
  %267 = select <4 x i1> %266, <4 x i32> %265, <4 x i32> %126
  %268 = add <4 x i32> %197, %161
  %269 = sub <4 x i32> %161, %197
  %270 = icmp sgt <4 x i32> %268, %123
  %271 = select <4 x i1> %270, <4 x i32> %268, <4 x i32> %123
  %272 = icmp slt <4 x i32> %271, %126
  %273 = select <4 x i1> %272, <4 x i32> %271, <4 x i32> %126
  %274 = icmp sgt <4 x i32> %269, %123
  %275 = select <4 x i1> %274, <4 x i32> %269, <4 x i32> %123
  %276 = icmp slt <4 x i32> %275, %126
  %277 = select <4 x i1> %276, <4 x i32> %275, <4 x i32> %126
  %278 = mul <4 x i32> %207, %80
  %279 = mul <4 x i32> %217, %80
  %280 = mul <4 x i32> %207, %76
  %281 = add <4 x i32> %280, %113
  %282 = add <4 x i32> %281, %279
  %283 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %282, i32 %2) #8
  %284 = mul <4 x i32> %76, %217
  %285 = add <4 x i32> %278, %113
  %286 = sub <4 x i32> %285, %284
  %287 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %286, i32 %2) #8
  %288 = mul <4 x i32> %237, %88
  %289 = mul <4 x i32> %227, %88
  %290 = mul <4 x i32> %227, %84
  %291 = add <4 x i32> %290, %113
  %292 = add <4 x i32> %291, %288
  %293 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %292, i32 %2) #8
  %294 = mul <4 x i32> %84, %237
  %295 = add <4 x i32> %289, %113
  %296 = sub <4 x i32> %295, %294
  %297 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %296, i32 %2) #8
  %298 = mul <4 x i32> %257, %76
  %299 = mul <4 x i32> %247, %76
  %300 = mul <4 x i32> %247, %91
  %301 = add <4 x i32> %300, %113
  %302 = add <4 x i32> %301, %298
  %303 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %302, i32 %2) #8
  %304 = mul <4 x i32> %91, %257
  %305 = add <4 x i32> %299, %113
  %306 = sub <4 x i32> %305, %304
  %307 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %306, i32 %2) #8
  %308 = mul <4 x i32> %277, %84
  %309 = mul <4 x i32> %267, %84
  %310 = mul <4 x i32> %267, %94
  %311 = add <4 x i32> %310, %113
  %312 = add <4 x i32> %311, %308
  %313 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %312, i32 %2) #8
  %314 = mul <4 x i32> %94, %277
  %315 = add <4 x i32> %309, %113
  %316 = sub <4 x i32> %315, %314
  %317 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %316, i32 %2) #8
  %318 = add <4 x i32> %243, %203
  %319 = sub <4 x i32> %203, %243
  %320 = icmp sgt <4 x i32> %318, %123
  %321 = select <4 x i1> %320, <4 x i32> %318, <4 x i32> %123
  %322 = icmp slt <4 x i32> %321, %126
  %323 = select <4 x i1> %322, <4 x i32> %321, <4 x i32> %126
  %324 = icmp sgt <4 x i32> %319, %123
  %325 = select <4 x i1> %324, <4 x i32> %319, <4 x i32> %123
  %326 = icmp slt <4 x i32> %325, %126
  %327 = select <4 x i1> %326, <4 x i32> %325, <4 x i32> %126
  %328 = add <4 x i32> %253, %213
  %329 = sub <4 x i32> %213, %253
  %330 = icmp sgt <4 x i32> %328, %123
  %331 = select <4 x i1> %330, <4 x i32> %328, <4 x i32> %123
  %332 = icmp slt <4 x i32> %331, %126
  %333 = select <4 x i1> %332, <4 x i32> %331, <4 x i32> %126
  %334 = icmp sgt <4 x i32> %329, %123
  %335 = select <4 x i1> %334, <4 x i32> %329, <4 x i32> %123
  %336 = icmp slt <4 x i32> %335, %126
  %337 = select <4 x i1> %336, <4 x i32> %335, <4 x i32> %126
  %338 = add <4 x i32> %263, %223
  %339 = sub <4 x i32> %223, %263
  %340 = icmp sgt <4 x i32> %338, %123
  %341 = select <4 x i1> %340, <4 x i32> %338, <4 x i32> %123
  %342 = icmp slt <4 x i32> %341, %126
  %343 = select <4 x i1> %342, <4 x i32> %341, <4 x i32> %126
  %344 = icmp sgt <4 x i32> %339, %123
  %345 = select <4 x i1> %344, <4 x i32> %339, <4 x i32> %123
  %346 = icmp slt <4 x i32> %345, %126
  %347 = select <4 x i1> %346, <4 x i32> %345, <4 x i32> %126
  %348 = add <4 x i32> %273, %233
  %349 = sub <4 x i32> %233, %273
  %350 = icmp sgt <4 x i32> %348, %123
  %351 = select <4 x i1> %350, <4 x i32> %348, <4 x i32> %123
  %352 = icmp slt <4 x i32> %351, %126
  %353 = select <4 x i1> %352, <4 x i32> %351, <4 x i32> %126
  %354 = icmp sgt <4 x i32> %349, %123
  %355 = select <4 x i1> %354, <4 x i32> %349, <4 x i32> %123
  %356 = icmp slt <4 x i32> %355, %126
  %357 = select <4 x i1> %356, <4 x i32> %355, <4 x i32> %126
  %358 = add <4 x i32> %303, %283
  %359 = sub <4 x i32> %283, %303
  %360 = icmp sgt <4 x i32> %358, %123
  %361 = select <4 x i1> %360, <4 x i32> %358, <4 x i32> %123
  %362 = icmp slt <4 x i32> %361, %126
  %363 = select <4 x i1> %362, <4 x i32> %361, <4 x i32> %126
  %364 = icmp sgt <4 x i32> %359, %123
  %365 = select <4 x i1> %364, <4 x i32> %359, <4 x i32> %123
  %366 = icmp slt <4 x i32> %365, %126
  %367 = select <4 x i1> %366, <4 x i32> %365, <4 x i32> %126
  %368 = add <4 x i32> %307, %287
  %369 = sub <4 x i32> %287, %307
  %370 = icmp sgt <4 x i32> %368, %123
  %371 = select <4 x i1> %370, <4 x i32> %368, <4 x i32> %123
  %372 = icmp slt <4 x i32> %371, %126
  %373 = select <4 x i1> %372, <4 x i32> %371, <4 x i32> %126
  %374 = icmp sgt <4 x i32> %369, %123
  %375 = select <4 x i1> %374, <4 x i32> %369, <4 x i32> %123
  %376 = icmp slt <4 x i32> %375, %126
  %377 = select <4 x i1> %376, <4 x i32> %375, <4 x i32> %126
  %378 = add <4 x i32> %313, %293
  %379 = sub <4 x i32> %293, %313
  %380 = icmp sgt <4 x i32> %378, %123
  %381 = select <4 x i1> %380, <4 x i32> %378, <4 x i32> %123
  %382 = icmp slt <4 x i32> %381, %126
  %383 = select <4 x i1> %382, <4 x i32> %381, <4 x i32> %126
  %384 = icmp sgt <4 x i32> %379, %123
  %385 = select <4 x i1> %384, <4 x i32> %379, <4 x i32> %123
  %386 = icmp slt <4 x i32> %385, %126
  %387 = select <4 x i1> %386, <4 x i32> %385, <4 x i32> %126
  %388 = add <4 x i32> %317, %297
  %389 = sub <4 x i32> %297, %317
  %390 = icmp sgt <4 x i32> %388, %123
  %391 = select <4 x i1> %390, <4 x i32> %388, <4 x i32> %123
  %392 = icmp slt <4 x i32> %391, %126
  %393 = select <4 x i1> %392, <4 x i32> %391, <4 x i32> %126
  %394 = icmp sgt <4 x i32> %389, %123
  %395 = select <4 x i1> %394, <4 x i32> %389, <4 x i32> %123
  %396 = icmp slt <4 x i32> %395, %126
  %397 = select <4 x i1> %396, <4 x i32> %395, <4 x i32> %126
  %398 = mul <4 x i32> %337, %98
  %399 = mul <4 x i32> %327, %98
  %400 = mul <4 x i32> %327, %102
  %401 = add <4 x i32> %400, %113
  %402 = add <4 x i32> %401, %398
  %403 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %402, i32 %2) #8
  %404 = mul <4 x i32> %102, %337
  %405 = add <4 x i32> %399, %113
  %406 = sub <4 x i32> %405, %404
  %407 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %406, i32 %2) #8
  %408 = mul <4 x i32> %357, %102
  %409 = mul <4 x i32> %347, %102
  %410 = mul <4 x i32> %347, %105
  %411 = add <4 x i32> %410, %113
  %412 = add <4 x i32> %411, %408
  %413 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %412, i32 %2) #8
  %414 = mul <4 x i32> %105, %357
  %415 = add <4 x i32> %409, %113
  %416 = sub <4 x i32> %415, %414
  %417 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %416, i32 %2) #8
  %418 = mul <4 x i32> %377, %98
  %419 = mul <4 x i32> %367, %98
  %420 = mul <4 x i32> %367, %102
  %421 = add <4 x i32> %420, %113
  %422 = add <4 x i32> %421, %418
  %423 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %422, i32 %2) #8
  %424 = mul <4 x i32> %102, %377
  %425 = add <4 x i32> %419, %113
  %426 = sub <4 x i32> %425, %424
  %427 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %426, i32 %2) #8
  %428 = mul <4 x i32> %397, %102
  %429 = mul <4 x i32> %387, %102
  %430 = mul <4 x i32> %387, %105
  %431 = add <4 x i32> %430, %113
  %432 = add <4 x i32> %431, %428
  %433 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %432, i32 %2) #8
  %434 = mul <4 x i32> %105, %397
  %435 = add <4 x i32> %429, %113
  %436 = sub <4 x i32> %435, %434
  %437 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %436, i32 %2) #8
  %438 = add <4 x i32> %343, %323
  %439 = sub <4 x i32> %323, %343
  %440 = icmp sgt <4 x i32> %438, %123
  %441 = select <4 x i1> %440, <4 x i32> %438, <4 x i32> %123
  %442 = icmp slt <4 x i32> %441, %126
  %443 = select <4 x i1> %442, <4 x i32> %441, <4 x i32> %126
  %444 = icmp sgt <4 x i32> %439, %123
  %445 = select <4 x i1> %444, <4 x i32> %439, <4 x i32> %123
  %446 = icmp slt <4 x i32> %445, %126
  %447 = select <4 x i1> %446, <4 x i32> %445, <4 x i32> %126
  %448 = add <4 x i32> %353, %333
  %449 = sub <4 x i32> %333, %353
  %450 = icmp sgt <4 x i32> %448, %123
  %451 = select <4 x i1> %450, <4 x i32> %448, <4 x i32> %123
  %452 = icmp slt <4 x i32> %451, %126
  %453 = select <4 x i1> %452, <4 x i32> %451, <4 x i32> %126
  %454 = icmp sgt <4 x i32> %449, %123
  %455 = select <4 x i1> %454, <4 x i32> %449, <4 x i32> %123
  %456 = icmp slt <4 x i32> %455, %126
  %457 = select <4 x i1> %456, <4 x i32> %455, <4 x i32> %126
  %458 = add <4 x i32> %413, %403
  %459 = sub <4 x i32> %403, %413
  %460 = icmp sgt <4 x i32> %458, %123
  %461 = select <4 x i1> %460, <4 x i32> %458, <4 x i32> %123
  %462 = icmp slt <4 x i32> %461, %126
  %463 = select <4 x i1> %462, <4 x i32> %461, <4 x i32> %126
  %464 = icmp sgt <4 x i32> %459, %123
  %465 = select <4 x i1> %464, <4 x i32> %459, <4 x i32> %123
  %466 = icmp slt <4 x i32> %465, %126
  %467 = select <4 x i1> %466, <4 x i32> %465, <4 x i32> %126
  %468 = add <4 x i32> %417, %407
  %469 = sub <4 x i32> %407, %417
  %470 = icmp sgt <4 x i32> %468, %123
  %471 = select <4 x i1> %470, <4 x i32> %468, <4 x i32> %123
  %472 = icmp slt <4 x i32> %471, %126
  %473 = select <4 x i1> %472, <4 x i32> %471, <4 x i32> %126
  %474 = icmp sgt <4 x i32> %469, %123
  %475 = select <4 x i1> %474, <4 x i32> %469, <4 x i32> %123
  %476 = icmp slt <4 x i32> %475, %126
  %477 = select <4 x i1> %476, <4 x i32> %475, <4 x i32> %126
  %478 = add <4 x i32> %383, %363
  %479 = sub <4 x i32> %363, %383
  %480 = icmp sgt <4 x i32> %478, %123
  %481 = select <4 x i1> %480, <4 x i32> %478, <4 x i32> %123
  %482 = icmp slt <4 x i32> %481, %126
  %483 = select <4 x i1> %482, <4 x i32> %481, <4 x i32> %126
  %484 = icmp sgt <4 x i32> %479, %123
  %485 = select <4 x i1> %484, <4 x i32> %479, <4 x i32> %123
  %486 = icmp slt <4 x i32> %485, %126
  %487 = select <4 x i1> %486, <4 x i32> %485, <4 x i32> %126
  %488 = add <4 x i32> %393, %373
  %489 = sub <4 x i32> %373, %393
  %490 = icmp sgt <4 x i32> %488, %123
  %491 = select <4 x i1> %490, <4 x i32> %488, <4 x i32> %123
  %492 = icmp slt <4 x i32> %491, %126
  %493 = select <4 x i1> %492, <4 x i32> %491, <4 x i32> %126
  %494 = icmp sgt <4 x i32> %489, %123
  %495 = select <4 x i1> %494, <4 x i32> %489, <4 x i32> %123
  %496 = icmp slt <4 x i32> %495, %126
  %497 = select <4 x i1> %496, <4 x i32> %495, <4 x i32> %126
  %498 = add <4 x i32> %433, %423
  %499 = sub <4 x i32> %423, %433
  %500 = icmp sgt <4 x i32> %498, %123
  %501 = select <4 x i1> %500, <4 x i32> %498, <4 x i32> %123
  %502 = icmp slt <4 x i32> %501, %126
  %503 = select <4 x i1> %502, <4 x i32> %501, <4 x i32> %126
  %504 = icmp sgt <4 x i32> %499, %123
  %505 = select <4 x i1> %504, <4 x i32> %499, <4 x i32> %123
  %506 = icmp slt <4 x i32> %505, %126
  %507 = select <4 x i1> %506, <4 x i32> %505, <4 x i32> %126
  %508 = add <4 x i32> %437, %427
  %509 = sub <4 x i32> %427, %437
  %510 = icmp sgt <4 x i32> %508, %123
  %511 = select <4 x i1> %510, <4 x i32> %508, <4 x i32> %123
  %512 = icmp slt <4 x i32> %511, %126
  %513 = select <4 x i1> %512, <4 x i32> %511, <4 x i32> %126
  %514 = icmp sgt <4 x i32> %509, %123
  %515 = select <4 x i1> %514, <4 x i32> %509, <4 x i32> %123
  %516 = icmp slt <4 x i32> %515, %126
  %517 = select <4 x i1> %516, <4 x i32> %515, <4 x i32> %126
  %518 = mul <4 x i32> %447, %109
  %519 = mul <4 x i32> %457, %109
  %520 = add <4 x i32> %518, %113
  %521 = add <4 x i32> %520, %519
  %522 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %521, i32 %2) #8
  %523 = sub <4 x i32> %520, %519
  %524 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %523, i32 %2) #8
  %525 = mul <4 x i32> %467, %109
  %526 = mul <4 x i32> %477, %109
  %527 = add <4 x i32> %525, %113
  %528 = add <4 x i32> %527, %526
  %529 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %528, i32 %2) #8
  %530 = sub <4 x i32> %527, %526
  %531 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %530, i32 %2) #8
  %532 = mul <4 x i32> %487, %109
  %533 = mul <4 x i32> %497, %109
  %534 = add <4 x i32> %532, %113
  %535 = add <4 x i32> %534, %533
  %536 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %535, i32 %2) #8
  %537 = sub <4 x i32> %534, %533
  %538 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %537, i32 %2) #8
  %539 = mul <4 x i32> %507, %109
  %540 = mul <4 x i32> %517, %109
  %541 = add <4 x i32> %539, %113
  %542 = add <4 x i32> %541, %540
  %543 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %542, i32 %2) #8
  %544 = sub <4 x i32> %541, %540
  %545 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %544, i32 %2) #8
  br i1 %114, label %546, label %584

546:                                              ; preds = %6
  %547 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %443, <4 x i32>* %547, align 16
  %548 = sub <4 x i32> zeroinitializer, %483
  %549 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %550 = bitcast <2 x i64>* %549 to <4 x i32>*
  store <4 x i32> %548, <4 x i32>* %550, align 16
  %551 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %552 = bitcast <2 x i64>* %551 to <4 x i32>*
  store <4 x i32> %503, <4 x i32>* %552, align 16
  %553 = sub <4 x i32> zeroinitializer, %463
  %554 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %555 = bitcast <2 x i64>* %554 to <4 x i32>*
  store <4 x i32> %553, <4 x i32>* %555, align 16
  %556 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %557 = bitcast <2 x i64>* %556 to <4 x i32>*
  store <4 x i32> %529, <4 x i32>* %557, align 16
  %558 = sub <4 x i32> zeroinitializer, %543
  %559 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %560 = bitcast <2 x i64>* %559 to <4 x i32>*
  store <4 x i32> %558, <4 x i32>* %560, align 16
  %561 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %562 = bitcast <2 x i64>* %561 to <4 x i32>*
  store <4 x i32> %536, <4 x i32>* %562, align 16
  %563 = sub <4 x i32> zeroinitializer, %522
  %564 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %565 = bitcast <2 x i64>* %564 to <4 x i32>*
  store <4 x i32> %563, <4 x i32>* %565, align 16
  %566 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %567 = bitcast <2 x i64>* %566 to <4 x i32>*
  store <4 x i32> %524, <4 x i32>* %567, align 16
  %568 = sub <4 x i32> zeroinitializer, %538
  %569 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %570 = bitcast <2 x i64>* %569 to <4 x i32>*
  store <4 x i32> %568, <4 x i32>* %570, align 16
  %571 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %572 = bitcast <2 x i64>* %571 to <4 x i32>*
  store <4 x i32> %545, <4 x i32>* %572, align 16
  %573 = sub <4 x i32> zeroinitializer, %531
  %574 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %575 = bitcast <2 x i64>* %574 to <4 x i32>*
  store <4 x i32> %573, <4 x i32>* %575, align 16
  %576 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %577 = bitcast <2 x i64>* %576 to <4 x i32>*
  store <4 x i32> %473, <4 x i32>* %577, align 16
  %578 = sub <4 x i32> zeroinitializer, %513
  %579 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %580 = bitcast <2 x i64>* %579 to <4 x i32>*
  store <4 x i32> %578, <4 x i32>* %580, align 16
  %581 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %582 = bitcast <2 x i64>* %581 to <4 x i32>*
  store <4 x i32> %493, <4 x i32>* %582, align 16
  %583 = sub <4 x i32> zeroinitializer, %453
  br label %724

584:                                              ; preds = %6
  %585 = icmp sgt i32 %4, 10
  %586 = select i1 %585, i32 %4, i32 10
  %587 = shl i32 32, %586
  %588 = sub nsw i32 0, %587
  %589 = insertelement <4 x i32> undef, i32 %588, i32 0
  %590 = shufflevector <4 x i32> %589, <4 x i32> undef, <4 x i32> zeroinitializer
  %591 = add nsw i32 %587, -1
  %592 = insertelement <4 x i32> undef, i32 %591, i32 0
  %593 = shufflevector <4 x i32> %592, <4 x i32> undef, <4 x i32> zeroinitializer
  %594 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %595 = shl i32 1, %5
  %596 = ashr i32 %595, 1
  %597 = insertelement <4 x i32> undef, i32 %596, i32 0
  %598 = shufflevector <4 x i32> %597, <4 x i32> undef, <4 x i32> zeroinitializer
  %599 = add <4 x i32> %443, %598
  %600 = sub <4 x i32> %598, %483
  %601 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %5, i32 0
  %602 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %599, <4 x i32> %601) #8
  %603 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %600, <4 x i32> %601) #8
  %604 = icmp sgt <4 x i32> %602, %590
  %605 = select <4 x i1> %604, <4 x i32> %602, <4 x i32> %590
  %606 = icmp slt <4 x i32> %605, %593
  %607 = select <4 x i1> %606, <4 x i32> %605, <4 x i32> %593
  %608 = icmp sgt <4 x i32> %603, %590
  %609 = select <4 x i1> %608, <4 x i32> %603, <4 x i32> %590
  %610 = icmp slt <4 x i32> %609, %593
  %611 = select <4 x i1> %610, <4 x i32> %609, <4 x i32> %593
  %612 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %607, <4 x i32>* %612, align 16
  %613 = bitcast <2 x i64>* %594 to <4 x i32>*
  store <4 x i32> %611, <4 x i32>* %613, align 16
  %614 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %615 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %616 = add <4 x i32> %503, %598
  %617 = sub <4 x i32> %598, %463
  %618 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %616, <4 x i32> %601) #8
  %619 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %617, <4 x i32> %601) #8
  %620 = icmp sgt <4 x i32> %618, %590
  %621 = select <4 x i1> %620, <4 x i32> %618, <4 x i32> %590
  %622 = icmp slt <4 x i32> %621, %593
  %623 = select <4 x i1> %622, <4 x i32> %621, <4 x i32> %593
  %624 = icmp sgt <4 x i32> %619, %590
  %625 = select <4 x i1> %624, <4 x i32> %619, <4 x i32> %590
  %626 = icmp slt <4 x i32> %625, %593
  %627 = select <4 x i1> %626, <4 x i32> %625, <4 x i32> %593
  %628 = bitcast <2 x i64>* %614 to <4 x i32>*
  store <4 x i32> %623, <4 x i32>* %628, align 16
  %629 = bitcast <2 x i64>* %615 to <4 x i32>*
  store <4 x i32> %627, <4 x i32>* %629, align 16
  %630 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %631 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %632 = add <4 x i32> %529, %598
  %633 = sub <4 x i32> %598, %543
  %634 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %632, <4 x i32> %601) #8
  %635 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %633, <4 x i32> %601) #8
  %636 = icmp sgt <4 x i32> %634, %590
  %637 = select <4 x i1> %636, <4 x i32> %634, <4 x i32> %590
  %638 = icmp slt <4 x i32> %637, %593
  %639 = select <4 x i1> %638, <4 x i32> %637, <4 x i32> %593
  %640 = icmp sgt <4 x i32> %635, %590
  %641 = select <4 x i1> %640, <4 x i32> %635, <4 x i32> %590
  %642 = icmp slt <4 x i32> %641, %593
  %643 = select <4 x i1> %642, <4 x i32> %641, <4 x i32> %593
  %644 = bitcast <2 x i64>* %630 to <4 x i32>*
  store <4 x i32> %639, <4 x i32>* %644, align 16
  %645 = bitcast <2 x i64>* %631 to <4 x i32>*
  store <4 x i32> %643, <4 x i32>* %645, align 16
  %646 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %647 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %648 = add <4 x i32> %536, %598
  %649 = sub <4 x i32> %598, %522
  %650 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %648, <4 x i32> %601) #8
  %651 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %649, <4 x i32> %601) #8
  %652 = icmp sgt <4 x i32> %650, %590
  %653 = select <4 x i1> %652, <4 x i32> %650, <4 x i32> %590
  %654 = icmp slt <4 x i32> %653, %593
  %655 = select <4 x i1> %654, <4 x i32> %653, <4 x i32> %593
  %656 = icmp sgt <4 x i32> %651, %590
  %657 = select <4 x i1> %656, <4 x i32> %651, <4 x i32> %590
  %658 = icmp slt <4 x i32> %657, %593
  %659 = select <4 x i1> %658, <4 x i32> %657, <4 x i32> %593
  %660 = bitcast <2 x i64>* %646 to <4 x i32>*
  store <4 x i32> %655, <4 x i32>* %660, align 16
  %661 = bitcast <2 x i64>* %647 to <4 x i32>*
  store <4 x i32> %659, <4 x i32>* %661, align 16
  %662 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %663 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %664 = add <4 x i32> %524, %598
  %665 = sub <4 x i32> %598, %538
  %666 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %664, <4 x i32> %601) #8
  %667 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %665, <4 x i32> %601) #8
  %668 = icmp sgt <4 x i32> %666, %590
  %669 = select <4 x i1> %668, <4 x i32> %666, <4 x i32> %590
  %670 = icmp slt <4 x i32> %669, %593
  %671 = select <4 x i1> %670, <4 x i32> %669, <4 x i32> %593
  %672 = icmp sgt <4 x i32> %667, %590
  %673 = select <4 x i1> %672, <4 x i32> %667, <4 x i32> %590
  %674 = icmp slt <4 x i32> %673, %593
  %675 = select <4 x i1> %674, <4 x i32> %673, <4 x i32> %593
  %676 = bitcast <2 x i64>* %662 to <4 x i32>*
  store <4 x i32> %671, <4 x i32>* %676, align 16
  %677 = bitcast <2 x i64>* %663 to <4 x i32>*
  store <4 x i32> %675, <4 x i32>* %677, align 16
  %678 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %679 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %680 = add <4 x i32> %545, %598
  %681 = sub <4 x i32> %598, %531
  %682 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %680, <4 x i32> %601) #8
  %683 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %681, <4 x i32> %601) #8
  %684 = icmp sgt <4 x i32> %682, %590
  %685 = select <4 x i1> %684, <4 x i32> %682, <4 x i32> %590
  %686 = icmp slt <4 x i32> %685, %593
  %687 = select <4 x i1> %686, <4 x i32> %685, <4 x i32> %593
  %688 = icmp sgt <4 x i32> %683, %590
  %689 = select <4 x i1> %688, <4 x i32> %683, <4 x i32> %590
  %690 = icmp slt <4 x i32> %689, %593
  %691 = select <4 x i1> %690, <4 x i32> %689, <4 x i32> %593
  %692 = bitcast <2 x i64>* %678 to <4 x i32>*
  store <4 x i32> %687, <4 x i32>* %692, align 16
  %693 = bitcast <2 x i64>* %679 to <4 x i32>*
  store <4 x i32> %691, <4 x i32>* %693, align 16
  %694 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %695 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %696 = add <4 x i32> %473, %598
  %697 = sub <4 x i32> %598, %513
  %698 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %696, <4 x i32> %601) #8
  %699 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %697, <4 x i32> %601) #8
  %700 = icmp sgt <4 x i32> %698, %590
  %701 = select <4 x i1> %700, <4 x i32> %698, <4 x i32> %590
  %702 = icmp slt <4 x i32> %701, %593
  %703 = select <4 x i1> %702, <4 x i32> %701, <4 x i32> %593
  %704 = icmp sgt <4 x i32> %699, %590
  %705 = select <4 x i1> %704, <4 x i32> %699, <4 x i32> %590
  %706 = icmp slt <4 x i32> %705, %593
  %707 = select <4 x i1> %706, <4 x i32> %705, <4 x i32> %593
  %708 = bitcast <2 x i64>* %694 to <4 x i32>*
  store <4 x i32> %703, <4 x i32>* %708, align 16
  %709 = bitcast <2 x i64>* %695 to <4 x i32>*
  store <4 x i32> %707, <4 x i32>* %709, align 16
  %710 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %711 = add <4 x i32> %493, %598
  %712 = sub <4 x i32> %598, %453
  %713 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %711, <4 x i32> %601) #8
  %714 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %712, <4 x i32> %601) #8
  %715 = icmp sgt <4 x i32> %713, %590
  %716 = select <4 x i1> %715, <4 x i32> %713, <4 x i32> %590
  %717 = icmp slt <4 x i32> %716, %593
  %718 = select <4 x i1> %717, <4 x i32> %716, <4 x i32> %593
  %719 = icmp sgt <4 x i32> %714, %590
  %720 = select <4 x i1> %719, <4 x i32> %714, <4 x i32> %590
  %721 = icmp slt <4 x i32> %720, %593
  %722 = select <4 x i1> %721, <4 x i32> %720, <4 x i32> %593
  %723 = bitcast <2 x i64>* %710 to <4 x i32>*
  store <4 x i32> %718, <4 x i32>* %723, align 16
  br label %724

724:                                              ; preds = %584, %546
  %725 = phi <4 x i32> [ %722, %584 ], [ %583, %546 ]
  %726 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %727 = bitcast <2 x i64>* %726 to <4 x i32>*
  store <4 x i32> %725, <4 x i32>* %727, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @iadst16x16_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>*, i32, i32, i32, i32) #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 2
  %10 = load i32, i32* %9, align 8
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 62
  %14 = load i32, i32* %13, align 8
  %15 = insertelement <4 x i32> undef, i32 %14, i32 0
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> zeroinitializer
  %17 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 10
  %18 = load i32, i32* %17, align 8
  %19 = insertelement <4 x i32> undef, i32 %18, i32 0
  %20 = shufflevector <4 x i32> %19, <4 x i32> undef, <4 x i32> zeroinitializer
  %21 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 54
  %22 = load i32, i32* %21, align 8
  %23 = insertelement <4 x i32> undef, i32 %22, i32 0
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> zeroinitializer
  %25 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 18
  %26 = load i32, i32* %25, align 8
  %27 = insertelement <4 x i32> undef, i32 %26, i32 0
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> zeroinitializer
  %29 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 46
  %30 = load i32, i32* %29, align 8
  %31 = insertelement <4 x i32> undef, i32 %30, i32 0
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> zeroinitializer
  %33 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 26
  %34 = load i32, i32* %33, align 8
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 38
  %38 = load i32, i32* %37, align 8
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> zeroinitializer
  %41 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 34
  %42 = load i32, i32* %41, align 8
  %43 = insertelement <4 x i32> undef, i32 %42, i32 0
  %44 = shufflevector <4 x i32> %43, <4 x i32> undef, <4 x i32> zeroinitializer
  %45 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 30
  %46 = load i32, i32* %45, align 8
  %47 = insertelement <4 x i32> undef, i32 %46, i32 0
  %48 = shufflevector <4 x i32> %47, <4 x i32> undef, <4 x i32> zeroinitializer
  %49 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 42
  %50 = load i32, i32* %49, align 8
  %51 = insertelement <4 x i32> undef, i32 %50, i32 0
  %52 = shufflevector <4 x i32> %51, <4 x i32> undef, <4 x i32> zeroinitializer
  %53 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 22
  %54 = load i32, i32* %53, align 8
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 50
  %58 = load i32, i32* %57, align 8
  %59 = insertelement <4 x i32> undef, i32 %58, i32 0
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 14
  %62 = load i32, i32* %61, align 8
  %63 = insertelement <4 x i32> undef, i32 %62, i32 0
  %64 = shufflevector <4 x i32> %63, <4 x i32> undef, <4 x i32> zeroinitializer
  %65 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 58
  %66 = load i32, i32* %65, align 8
  %67 = insertelement <4 x i32> undef, i32 %66, i32 0
  %68 = shufflevector <4 x i32> %67, <4 x i32> undef, <4 x i32> zeroinitializer
  %69 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 6
  %70 = load i32, i32* %69, align 8
  %71 = insertelement <4 x i32> undef, i32 %70, i32 0
  %72 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> zeroinitializer
  %73 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 8
  %74 = load i32, i32* %73, align 16
  %75 = insertelement <4 x i32> undef, i32 %74, i32 0
  %76 = shufflevector <4 x i32> %75, <4 x i32> undef, <4 x i32> zeroinitializer
  %77 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 56
  %78 = load i32, i32* %77, align 16
  %79 = insertelement <4 x i32> undef, i32 %78, i32 0
  %80 = shufflevector <4 x i32> %79, <4 x i32> undef, <4 x i32> zeroinitializer
  %81 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 40
  %82 = load i32, i32* %81, align 16
  %83 = insertelement <4 x i32> undef, i32 %82, i32 0
  %84 = shufflevector <4 x i32> %83, <4 x i32> undef, <4 x i32> zeroinitializer
  %85 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 24
  %86 = load i32, i32* %85, align 16
  %87 = insertelement <4 x i32> undef, i32 %86, i32 0
  %88 = shufflevector <4 x i32> %87, <4 x i32> undef, <4 x i32> zeroinitializer
  %89 = sub nsw i32 0, %78
  %90 = insertelement <4 x i32> undef, i32 %89, i32 0
  %91 = shufflevector <4 x i32> %90, <4 x i32> undef, <4 x i32> zeroinitializer
  %92 = sub nsw i32 0, %86
  %93 = insertelement <4 x i32> undef, i32 %92, i32 0
  %94 = shufflevector <4 x i32> %93, <4 x i32> undef, <4 x i32> zeroinitializer
  %95 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 48
  %96 = load i32, i32* %95, align 16
  %97 = insertelement <4 x i32> undef, i32 %96, i32 0
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> zeroinitializer
  %99 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 16
  %100 = load i32, i32* %99, align 16
  %101 = insertelement <4 x i32> undef, i32 %100, i32 0
  %102 = shufflevector <4 x i32> %101, <4 x i32> undef, <4 x i32> zeroinitializer
  %103 = sub nsw i32 0, %96
  %104 = insertelement <4 x i32> undef, i32 %103, i32 0
  %105 = shufflevector <4 x i32> %104, <4 x i32> undef, <4 x i32> zeroinitializer
  %106 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %107 = load i32, i32* %106, align 16
  %108 = insertelement <4 x i32> undef, i32 %107, i32 0
  %109 = shufflevector <4 x i32> %108, <4 x i32> undef, <4 x i32> zeroinitializer
  %110 = add nsw i32 %2, -1
  %111 = shl i32 1, %110
  %112 = insertelement <4 x i32> undef, i32 %111, i32 0
  %113 = shufflevector <4 x i32> %112, <4 x i32> undef, <4 x i32> zeroinitializer
  %114 = icmp ne i32 %3, 0
  %115 = select i1 %114, i32 6, i32 8
  %116 = add nsw i32 %115, %4
  %117 = icmp slt i32 %116, 16
  %118 = add i32 %116, -1
  %119 = shl i32 1, %118
  %120 = select i1 %117, i32 32768, i32 %119
  %121 = sub nsw i32 0, %120
  %122 = insertelement <4 x i32> undef, i32 %121, i32 0
  %123 = shufflevector <4 x i32> %122, <4 x i32> undef, <4 x i32> zeroinitializer
  %124 = add nsw i32 %120, -1
  %125 = insertelement <4 x i32> undef, i32 %124, i32 0
  %126 = shufflevector <4 x i32> %125, <4 x i32> undef, <4 x i32> zeroinitializer
  %127 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %128 = bitcast <2 x i64>* %127 to <4 x i32>*
  %129 = load <4 x i32>, <4 x i32>* %128, align 16
  %130 = mul <4 x i32> %129, %12
  %131 = bitcast <2 x i64>* %0 to <4 x i32>*
  %132 = load <4 x i32>, <4 x i32>* %131, align 16
  %133 = mul <4 x i32> %132, %16
  %134 = add <4 x i32> %130, %113
  %135 = add <4 x i32> %134, %133
  %136 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %135, i32 %2) #8
  %137 = mul <4 x i32> %129, %16
  %138 = mul <4 x i32> %12, %132
  %139 = add <4 x i32> %137, %113
  %140 = sub <4 x i32> %139, %138
  %141 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %140, i32 %2) #8
  %142 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %143 = bitcast <2 x i64>* %142 to <4 x i32>*
  %144 = load <4 x i32>, <4 x i32>* %143, align 16
  %145 = mul <4 x i32> %144, %20
  %146 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %147 = bitcast <2 x i64>* %146 to <4 x i32>*
  %148 = load <4 x i32>, <4 x i32>* %147, align 16
  %149 = mul <4 x i32> %148, %24
  %150 = add <4 x i32> %145, %113
  %151 = add <4 x i32> %150, %149
  %152 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %151, i32 %2) #8
  %153 = mul <4 x i32> %144, %24
  %154 = mul <4 x i32> %20, %148
  %155 = add <4 x i32> %153, %113
  %156 = sub <4 x i32> %155, %154
  %157 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %156, i32 %2) #8
  %158 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %159 = bitcast <2 x i64>* %158 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16
  %161 = mul <4 x i32> %160, %28
  %162 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %163 = bitcast <2 x i64>* %162 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = mul <4 x i32> %164, %32
  %166 = add <4 x i32> %161, %113
  %167 = add <4 x i32> %166, %165
  %168 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %167, i32 %2) #8
  %169 = mul <4 x i32> %160, %32
  %170 = mul <4 x i32> %28, %164
  %171 = add <4 x i32> %169, %113
  %172 = sub <4 x i32> %171, %170
  %173 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %172, i32 %2) #8
  %174 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %175 = bitcast <2 x i64>* %174 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = mul <4 x i32> %176, %36
  %178 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %179 = bitcast <2 x i64>* %178 to <4 x i32>*
  %180 = load <4 x i32>, <4 x i32>* %179, align 16
  %181 = mul <4 x i32> %180, %40
  %182 = add <4 x i32> %177, %113
  %183 = add <4 x i32> %182, %181
  %184 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %183, i32 %2) #8
  %185 = mul <4 x i32> %176, %40
  %186 = mul <4 x i32> %36, %180
  %187 = add <4 x i32> %185, %113
  %188 = sub <4 x i32> %187, %186
  %189 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %188, i32 %2) #8
  %190 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %191 = bitcast <2 x i64>* %190 to <4 x i32>*
  %192 = load <4 x i32>, <4 x i32>* %191, align 16
  %193 = mul <4 x i32> %192, %44
  %194 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %195 = bitcast <2 x i64>* %194 to <4 x i32>*
  %196 = load <4 x i32>, <4 x i32>* %195, align 16
  %197 = mul <4 x i32> %196, %48
  %198 = add <4 x i32> %193, %113
  %199 = add <4 x i32> %198, %197
  %200 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %199, i32 %2) #8
  %201 = mul <4 x i32> %192, %48
  %202 = mul <4 x i32> %44, %196
  %203 = add <4 x i32> %201, %113
  %204 = sub <4 x i32> %203, %202
  %205 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %204, i32 %2) #8
  %206 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %207 = bitcast <2 x i64>* %206 to <4 x i32>*
  %208 = load <4 x i32>, <4 x i32>* %207, align 16
  %209 = mul <4 x i32> %208, %52
  %210 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %211 = bitcast <2 x i64>* %210 to <4 x i32>*
  %212 = load <4 x i32>, <4 x i32>* %211, align 16
  %213 = mul <4 x i32> %212, %56
  %214 = add <4 x i32> %209, %113
  %215 = add <4 x i32> %214, %213
  %216 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %215, i32 %2) #8
  %217 = mul <4 x i32> %208, %56
  %218 = mul <4 x i32> %52, %212
  %219 = add <4 x i32> %217, %113
  %220 = sub <4 x i32> %219, %218
  %221 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %220, i32 %2) #8
  %222 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %223 = bitcast <2 x i64>* %222 to <4 x i32>*
  %224 = load <4 x i32>, <4 x i32>* %223, align 16
  %225 = mul <4 x i32> %224, %60
  %226 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %227 = bitcast <2 x i64>* %226 to <4 x i32>*
  %228 = load <4 x i32>, <4 x i32>* %227, align 16
  %229 = mul <4 x i32> %228, %64
  %230 = add <4 x i32> %225, %113
  %231 = add <4 x i32> %230, %229
  %232 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %231, i32 %2) #8
  %233 = mul <4 x i32> %224, %64
  %234 = mul <4 x i32> %60, %228
  %235 = add <4 x i32> %233, %113
  %236 = sub <4 x i32> %235, %234
  %237 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %236, i32 %2) #8
  %238 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %239 = bitcast <2 x i64>* %238 to <4 x i32>*
  %240 = load <4 x i32>, <4 x i32>* %239, align 16
  %241 = mul <4 x i32> %240, %68
  %242 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %243 = bitcast <2 x i64>* %242 to <4 x i32>*
  %244 = load <4 x i32>, <4 x i32>* %243, align 16
  %245 = mul <4 x i32> %244, %72
  %246 = add <4 x i32> %241, %113
  %247 = add <4 x i32> %246, %245
  %248 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %247, i32 %2) #8
  %249 = mul <4 x i32> %240, %72
  %250 = mul <4 x i32> %68, %244
  %251 = add <4 x i32> %249, %113
  %252 = sub <4 x i32> %251, %250
  %253 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %252, i32 %2) #8
  %254 = add <4 x i32> %200, %136
  %255 = sub <4 x i32> %136, %200
  %256 = icmp sgt <4 x i32> %254, %123
  %257 = select <4 x i1> %256, <4 x i32> %254, <4 x i32> %123
  %258 = icmp slt <4 x i32> %257, %126
  %259 = select <4 x i1> %258, <4 x i32> %257, <4 x i32> %126
  %260 = icmp sgt <4 x i32> %255, %123
  %261 = select <4 x i1> %260, <4 x i32> %255, <4 x i32> %123
  %262 = icmp slt <4 x i32> %261, %126
  %263 = select <4 x i1> %262, <4 x i32> %261, <4 x i32> %126
  %264 = add <4 x i32> %205, %141
  %265 = sub <4 x i32> %141, %205
  %266 = icmp sgt <4 x i32> %264, %123
  %267 = select <4 x i1> %266, <4 x i32> %264, <4 x i32> %123
  %268 = icmp slt <4 x i32> %267, %126
  %269 = select <4 x i1> %268, <4 x i32> %267, <4 x i32> %126
  %270 = icmp sgt <4 x i32> %265, %123
  %271 = select <4 x i1> %270, <4 x i32> %265, <4 x i32> %123
  %272 = icmp slt <4 x i32> %271, %126
  %273 = select <4 x i1> %272, <4 x i32> %271, <4 x i32> %126
  %274 = add <4 x i32> %216, %152
  %275 = sub <4 x i32> %152, %216
  %276 = icmp sgt <4 x i32> %274, %123
  %277 = select <4 x i1> %276, <4 x i32> %274, <4 x i32> %123
  %278 = icmp slt <4 x i32> %277, %126
  %279 = select <4 x i1> %278, <4 x i32> %277, <4 x i32> %126
  %280 = icmp sgt <4 x i32> %275, %123
  %281 = select <4 x i1> %280, <4 x i32> %275, <4 x i32> %123
  %282 = icmp slt <4 x i32> %281, %126
  %283 = select <4 x i1> %282, <4 x i32> %281, <4 x i32> %126
  %284 = add <4 x i32> %221, %157
  %285 = sub <4 x i32> %157, %221
  %286 = icmp sgt <4 x i32> %284, %123
  %287 = select <4 x i1> %286, <4 x i32> %284, <4 x i32> %123
  %288 = icmp slt <4 x i32> %287, %126
  %289 = select <4 x i1> %288, <4 x i32> %287, <4 x i32> %126
  %290 = icmp sgt <4 x i32> %285, %123
  %291 = select <4 x i1> %290, <4 x i32> %285, <4 x i32> %123
  %292 = icmp slt <4 x i32> %291, %126
  %293 = select <4 x i1> %292, <4 x i32> %291, <4 x i32> %126
  %294 = add <4 x i32> %232, %168
  %295 = sub <4 x i32> %168, %232
  %296 = icmp sgt <4 x i32> %294, %123
  %297 = select <4 x i1> %296, <4 x i32> %294, <4 x i32> %123
  %298 = icmp slt <4 x i32> %297, %126
  %299 = select <4 x i1> %298, <4 x i32> %297, <4 x i32> %126
  %300 = icmp sgt <4 x i32> %295, %123
  %301 = select <4 x i1> %300, <4 x i32> %295, <4 x i32> %123
  %302 = icmp slt <4 x i32> %301, %126
  %303 = select <4 x i1> %302, <4 x i32> %301, <4 x i32> %126
  %304 = add <4 x i32> %237, %173
  %305 = sub <4 x i32> %173, %237
  %306 = icmp sgt <4 x i32> %304, %123
  %307 = select <4 x i1> %306, <4 x i32> %304, <4 x i32> %123
  %308 = icmp slt <4 x i32> %307, %126
  %309 = select <4 x i1> %308, <4 x i32> %307, <4 x i32> %126
  %310 = icmp sgt <4 x i32> %305, %123
  %311 = select <4 x i1> %310, <4 x i32> %305, <4 x i32> %123
  %312 = icmp slt <4 x i32> %311, %126
  %313 = select <4 x i1> %312, <4 x i32> %311, <4 x i32> %126
  %314 = add <4 x i32> %248, %184
  %315 = sub <4 x i32> %184, %248
  %316 = icmp sgt <4 x i32> %314, %123
  %317 = select <4 x i1> %316, <4 x i32> %314, <4 x i32> %123
  %318 = icmp slt <4 x i32> %317, %126
  %319 = select <4 x i1> %318, <4 x i32> %317, <4 x i32> %126
  %320 = icmp sgt <4 x i32> %315, %123
  %321 = select <4 x i1> %320, <4 x i32> %315, <4 x i32> %123
  %322 = icmp slt <4 x i32> %321, %126
  %323 = select <4 x i1> %322, <4 x i32> %321, <4 x i32> %126
  %324 = add <4 x i32> %253, %189
  %325 = sub <4 x i32> %189, %253
  %326 = icmp sgt <4 x i32> %324, %123
  %327 = select <4 x i1> %326, <4 x i32> %324, <4 x i32> %123
  %328 = icmp slt <4 x i32> %327, %126
  %329 = select <4 x i1> %328, <4 x i32> %327, <4 x i32> %126
  %330 = icmp sgt <4 x i32> %325, %123
  %331 = select <4 x i1> %330, <4 x i32> %325, <4 x i32> %123
  %332 = icmp slt <4 x i32> %331, %126
  %333 = select <4 x i1> %332, <4 x i32> %331, <4 x i32> %126
  %334 = mul <4 x i32> %263, %76
  %335 = mul <4 x i32> %273, %80
  %336 = add <4 x i32> %334, %113
  %337 = add <4 x i32> %336, %335
  %338 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %337, i32 %2) #8
  %339 = mul <4 x i32> %263, %80
  %340 = mul <4 x i32> %76, %273
  %341 = add <4 x i32> %339, %113
  %342 = sub <4 x i32> %341, %340
  %343 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %342, i32 %2) #8
  %344 = mul <4 x i32> %283, %84
  %345 = mul <4 x i32> %293, %88
  %346 = add <4 x i32> %344, %113
  %347 = add <4 x i32> %346, %345
  %348 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %347, i32 %2) #8
  %349 = mul <4 x i32> %283, %88
  %350 = mul <4 x i32> %84, %293
  %351 = add <4 x i32> %349, %113
  %352 = sub <4 x i32> %351, %350
  %353 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %352, i32 %2) #8
  %354 = mul <4 x i32> %303, %91
  %355 = mul <4 x i32> %313, %76
  %356 = add <4 x i32> %354, %113
  %357 = add <4 x i32> %356, %355
  %358 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %357, i32 %2) #8
  %359 = mul <4 x i32> %303, %76
  %360 = mul <4 x i32> %91, %313
  %361 = add <4 x i32> %359, %113
  %362 = sub <4 x i32> %361, %360
  %363 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %362, i32 %2) #8
  %364 = mul <4 x i32> %323, %94
  %365 = mul <4 x i32> %333, %84
  %366 = add <4 x i32> %364, %113
  %367 = add <4 x i32> %366, %365
  %368 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %367, i32 %2) #8
  %369 = mul <4 x i32> %323, %84
  %370 = mul <4 x i32> %94, %333
  %371 = add <4 x i32> %369, %113
  %372 = sub <4 x i32> %371, %370
  %373 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %372, i32 %2) #8
  %374 = add <4 x i32> %299, %259
  %375 = sub <4 x i32> %259, %299
  %376 = icmp sgt <4 x i32> %374, %123
  %377 = select <4 x i1> %376, <4 x i32> %374, <4 x i32> %123
  %378 = icmp slt <4 x i32> %377, %126
  %379 = select <4 x i1> %378, <4 x i32> %377, <4 x i32> %126
  %380 = icmp sgt <4 x i32> %375, %123
  %381 = select <4 x i1> %380, <4 x i32> %375, <4 x i32> %123
  %382 = icmp slt <4 x i32> %381, %126
  %383 = select <4 x i1> %382, <4 x i32> %381, <4 x i32> %126
  %384 = add <4 x i32> %309, %269
  %385 = sub <4 x i32> %269, %309
  %386 = icmp sgt <4 x i32> %384, %123
  %387 = select <4 x i1> %386, <4 x i32> %384, <4 x i32> %123
  %388 = icmp slt <4 x i32> %387, %126
  %389 = select <4 x i1> %388, <4 x i32> %387, <4 x i32> %126
  %390 = icmp sgt <4 x i32> %385, %123
  %391 = select <4 x i1> %390, <4 x i32> %385, <4 x i32> %123
  %392 = icmp slt <4 x i32> %391, %126
  %393 = select <4 x i1> %392, <4 x i32> %391, <4 x i32> %126
  %394 = add <4 x i32> %319, %279
  %395 = sub <4 x i32> %279, %319
  %396 = icmp sgt <4 x i32> %394, %123
  %397 = select <4 x i1> %396, <4 x i32> %394, <4 x i32> %123
  %398 = icmp slt <4 x i32> %397, %126
  %399 = select <4 x i1> %398, <4 x i32> %397, <4 x i32> %126
  %400 = icmp sgt <4 x i32> %395, %123
  %401 = select <4 x i1> %400, <4 x i32> %395, <4 x i32> %123
  %402 = icmp slt <4 x i32> %401, %126
  %403 = select <4 x i1> %402, <4 x i32> %401, <4 x i32> %126
  %404 = add <4 x i32> %329, %289
  %405 = sub <4 x i32> %289, %329
  %406 = icmp sgt <4 x i32> %404, %123
  %407 = select <4 x i1> %406, <4 x i32> %404, <4 x i32> %123
  %408 = icmp slt <4 x i32> %407, %126
  %409 = select <4 x i1> %408, <4 x i32> %407, <4 x i32> %126
  %410 = icmp sgt <4 x i32> %405, %123
  %411 = select <4 x i1> %410, <4 x i32> %405, <4 x i32> %123
  %412 = icmp slt <4 x i32> %411, %126
  %413 = select <4 x i1> %412, <4 x i32> %411, <4 x i32> %126
  %414 = add <4 x i32> %358, %338
  %415 = sub <4 x i32> %338, %358
  %416 = icmp sgt <4 x i32> %414, %123
  %417 = select <4 x i1> %416, <4 x i32> %414, <4 x i32> %123
  %418 = icmp slt <4 x i32> %417, %126
  %419 = select <4 x i1> %418, <4 x i32> %417, <4 x i32> %126
  %420 = icmp sgt <4 x i32> %415, %123
  %421 = select <4 x i1> %420, <4 x i32> %415, <4 x i32> %123
  %422 = icmp slt <4 x i32> %421, %126
  %423 = select <4 x i1> %422, <4 x i32> %421, <4 x i32> %126
  %424 = add <4 x i32> %363, %343
  %425 = sub <4 x i32> %343, %363
  %426 = icmp sgt <4 x i32> %424, %123
  %427 = select <4 x i1> %426, <4 x i32> %424, <4 x i32> %123
  %428 = icmp slt <4 x i32> %427, %126
  %429 = select <4 x i1> %428, <4 x i32> %427, <4 x i32> %126
  %430 = icmp sgt <4 x i32> %425, %123
  %431 = select <4 x i1> %430, <4 x i32> %425, <4 x i32> %123
  %432 = icmp slt <4 x i32> %431, %126
  %433 = select <4 x i1> %432, <4 x i32> %431, <4 x i32> %126
  %434 = add <4 x i32> %368, %348
  %435 = sub <4 x i32> %348, %368
  %436 = icmp sgt <4 x i32> %434, %123
  %437 = select <4 x i1> %436, <4 x i32> %434, <4 x i32> %123
  %438 = icmp slt <4 x i32> %437, %126
  %439 = select <4 x i1> %438, <4 x i32> %437, <4 x i32> %126
  %440 = icmp sgt <4 x i32> %435, %123
  %441 = select <4 x i1> %440, <4 x i32> %435, <4 x i32> %123
  %442 = icmp slt <4 x i32> %441, %126
  %443 = select <4 x i1> %442, <4 x i32> %441, <4 x i32> %126
  %444 = add <4 x i32> %373, %353
  %445 = sub <4 x i32> %353, %373
  %446 = icmp sgt <4 x i32> %444, %123
  %447 = select <4 x i1> %446, <4 x i32> %444, <4 x i32> %123
  %448 = icmp slt <4 x i32> %447, %126
  %449 = select <4 x i1> %448, <4 x i32> %447, <4 x i32> %126
  %450 = icmp sgt <4 x i32> %445, %123
  %451 = select <4 x i1> %450, <4 x i32> %445, <4 x i32> %123
  %452 = icmp slt <4 x i32> %451, %126
  %453 = select <4 x i1> %452, <4 x i32> %451, <4 x i32> %126
  %454 = mul <4 x i32> %383, %102
  %455 = mul <4 x i32> %393, %98
  %456 = add <4 x i32> %454, %113
  %457 = add <4 x i32> %456, %455
  %458 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %457, i32 %2) #8
  %459 = mul <4 x i32> %383, %98
  %460 = mul <4 x i32> %102, %393
  %461 = add <4 x i32> %459, %113
  %462 = sub <4 x i32> %461, %460
  %463 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %462, i32 %2) #8
  %464 = mul <4 x i32> %403, %105
  %465 = mul <4 x i32> %413, %102
  %466 = add <4 x i32> %464, %113
  %467 = add <4 x i32> %466, %465
  %468 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %467, i32 %2) #8
  %469 = mul <4 x i32> %403, %102
  %470 = mul <4 x i32> %105, %413
  %471 = add <4 x i32> %469, %113
  %472 = sub <4 x i32> %471, %470
  %473 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %472, i32 %2) #8
  %474 = mul <4 x i32> %423, %102
  %475 = mul <4 x i32> %433, %98
  %476 = add <4 x i32> %474, %113
  %477 = add <4 x i32> %476, %475
  %478 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %477, i32 %2) #8
  %479 = mul <4 x i32> %423, %98
  %480 = mul <4 x i32> %102, %433
  %481 = add <4 x i32> %479, %113
  %482 = sub <4 x i32> %481, %480
  %483 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %482, i32 %2) #8
  %484 = mul <4 x i32> %443, %105
  %485 = mul <4 x i32> %453, %102
  %486 = add <4 x i32> %484, %113
  %487 = add <4 x i32> %486, %485
  %488 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %487, i32 %2) #8
  %489 = mul <4 x i32> %443, %102
  %490 = mul <4 x i32> %105, %453
  %491 = add <4 x i32> %489, %113
  %492 = sub <4 x i32> %491, %490
  %493 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %492, i32 %2) #8
  %494 = add <4 x i32> %399, %379
  %495 = sub <4 x i32> %379, %399
  %496 = icmp sgt <4 x i32> %494, %123
  %497 = select <4 x i1> %496, <4 x i32> %494, <4 x i32> %123
  %498 = icmp slt <4 x i32> %497, %126
  %499 = select <4 x i1> %498, <4 x i32> %497, <4 x i32> %126
  %500 = icmp sgt <4 x i32> %495, %123
  %501 = select <4 x i1> %500, <4 x i32> %495, <4 x i32> %123
  %502 = icmp slt <4 x i32> %501, %126
  %503 = select <4 x i1> %502, <4 x i32> %501, <4 x i32> %126
  %504 = add <4 x i32> %409, %389
  %505 = sub <4 x i32> %389, %409
  %506 = icmp sgt <4 x i32> %504, %123
  %507 = select <4 x i1> %506, <4 x i32> %504, <4 x i32> %123
  %508 = icmp slt <4 x i32> %507, %126
  %509 = select <4 x i1> %508, <4 x i32> %507, <4 x i32> %126
  %510 = icmp sgt <4 x i32> %505, %123
  %511 = select <4 x i1> %510, <4 x i32> %505, <4 x i32> %123
  %512 = icmp slt <4 x i32> %511, %126
  %513 = select <4 x i1> %512, <4 x i32> %511, <4 x i32> %126
  %514 = add <4 x i32> %468, %458
  %515 = sub <4 x i32> %458, %468
  %516 = icmp sgt <4 x i32> %514, %123
  %517 = select <4 x i1> %516, <4 x i32> %514, <4 x i32> %123
  %518 = icmp slt <4 x i32> %517, %126
  %519 = select <4 x i1> %518, <4 x i32> %517, <4 x i32> %126
  %520 = icmp sgt <4 x i32> %515, %123
  %521 = select <4 x i1> %520, <4 x i32> %515, <4 x i32> %123
  %522 = icmp slt <4 x i32> %521, %126
  %523 = select <4 x i1> %522, <4 x i32> %521, <4 x i32> %126
  %524 = add <4 x i32> %473, %463
  %525 = sub <4 x i32> %463, %473
  %526 = icmp sgt <4 x i32> %524, %123
  %527 = select <4 x i1> %526, <4 x i32> %524, <4 x i32> %123
  %528 = icmp slt <4 x i32> %527, %126
  %529 = select <4 x i1> %528, <4 x i32> %527, <4 x i32> %126
  %530 = icmp sgt <4 x i32> %525, %123
  %531 = select <4 x i1> %530, <4 x i32> %525, <4 x i32> %123
  %532 = icmp slt <4 x i32> %531, %126
  %533 = select <4 x i1> %532, <4 x i32> %531, <4 x i32> %126
  %534 = add <4 x i32> %439, %419
  %535 = sub <4 x i32> %419, %439
  %536 = icmp sgt <4 x i32> %534, %123
  %537 = select <4 x i1> %536, <4 x i32> %534, <4 x i32> %123
  %538 = icmp slt <4 x i32> %537, %126
  %539 = select <4 x i1> %538, <4 x i32> %537, <4 x i32> %126
  %540 = icmp sgt <4 x i32> %535, %123
  %541 = select <4 x i1> %540, <4 x i32> %535, <4 x i32> %123
  %542 = icmp slt <4 x i32> %541, %126
  %543 = select <4 x i1> %542, <4 x i32> %541, <4 x i32> %126
  %544 = add <4 x i32> %449, %429
  %545 = sub <4 x i32> %429, %449
  %546 = icmp sgt <4 x i32> %544, %123
  %547 = select <4 x i1> %546, <4 x i32> %544, <4 x i32> %123
  %548 = icmp slt <4 x i32> %547, %126
  %549 = select <4 x i1> %548, <4 x i32> %547, <4 x i32> %126
  %550 = icmp sgt <4 x i32> %545, %123
  %551 = select <4 x i1> %550, <4 x i32> %545, <4 x i32> %123
  %552 = icmp slt <4 x i32> %551, %126
  %553 = select <4 x i1> %552, <4 x i32> %551, <4 x i32> %126
  %554 = add <4 x i32> %488, %478
  %555 = sub <4 x i32> %478, %488
  %556 = icmp sgt <4 x i32> %554, %123
  %557 = select <4 x i1> %556, <4 x i32> %554, <4 x i32> %123
  %558 = icmp slt <4 x i32> %557, %126
  %559 = select <4 x i1> %558, <4 x i32> %557, <4 x i32> %126
  %560 = icmp sgt <4 x i32> %555, %123
  %561 = select <4 x i1> %560, <4 x i32> %555, <4 x i32> %123
  %562 = icmp slt <4 x i32> %561, %126
  %563 = select <4 x i1> %562, <4 x i32> %561, <4 x i32> %126
  %564 = add <4 x i32> %493, %483
  %565 = sub <4 x i32> %483, %493
  %566 = icmp sgt <4 x i32> %564, %123
  %567 = select <4 x i1> %566, <4 x i32> %564, <4 x i32> %123
  %568 = icmp slt <4 x i32> %567, %126
  %569 = select <4 x i1> %568, <4 x i32> %567, <4 x i32> %126
  %570 = icmp sgt <4 x i32> %565, %123
  %571 = select <4 x i1> %570, <4 x i32> %565, <4 x i32> %123
  %572 = icmp slt <4 x i32> %571, %126
  %573 = select <4 x i1> %572, <4 x i32> %571, <4 x i32> %126
  %574 = mul <4 x i32> %503, %109
  %575 = mul <4 x i32> %513, %109
  %576 = add <4 x i32> %574, %113
  %577 = add <4 x i32> %576, %575
  %578 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %577, i32 %2) #8
  %579 = sub <4 x i32> %576, %575
  %580 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %579, i32 %2) #8
  %581 = mul <4 x i32> %523, %109
  %582 = mul <4 x i32> %533, %109
  %583 = add <4 x i32> %581, %113
  %584 = add <4 x i32> %583, %582
  %585 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %584, i32 %2) #8
  %586 = sub <4 x i32> %583, %582
  %587 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %586, i32 %2) #8
  %588 = mul <4 x i32> %543, %109
  %589 = mul <4 x i32> %553, %109
  %590 = add <4 x i32> %588, %113
  %591 = add <4 x i32> %590, %589
  %592 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %591, i32 %2) #8
  %593 = sub <4 x i32> %590, %589
  %594 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %593, i32 %2) #8
  %595 = mul <4 x i32> %563, %109
  %596 = mul <4 x i32> %573, %109
  %597 = add <4 x i32> %595, %113
  %598 = add <4 x i32> %597, %596
  %599 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %598, i32 %2) #8
  %600 = sub <4 x i32> %597, %596
  %601 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %600, i32 %2) #8
  br i1 %114, label %602, label %640

602:                                              ; preds = %6
  %603 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %499, <4 x i32>* %603, align 16
  %604 = sub <4 x i32> zeroinitializer, %539
  %605 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %606 = bitcast <2 x i64>* %605 to <4 x i32>*
  store <4 x i32> %604, <4 x i32>* %606, align 16
  %607 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %608 = bitcast <2 x i64>* %607 to <4 x i32>*
  store <4 x i32> %559, <4 x i32>* %608, align 16
  %609 = sub <4 x i32> zeroinitializer, %519
  %610 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %611 = bitcast <2 x i64>* %610 to <4 x i32>*
  store <4 x i32> %609, <4 x i32>* %611, align 16
  %612 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %613 = bitcast <2 x i64>* %612 to <4 x i32>*
  store <4 x i32> %585, <4 x i32>* %613, align 16
  %614 = sub <4 x i32> zeroinitializer, %599
  %615 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %616 = bitcast <2 x i64>* %615 to <4 x i32>*
  store <4 x i32> %614, <4 x i32>* %616, align 16
  %617 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %618 = bitcast <2 x i64>* %617 to <4 x i32>*
  store <4 x i32> %592, <4 x i32>* %618, align 16
  %619 = sub <4 x i32> zeroinitializer, %578
  %620 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %621 = bitcast <2 x i64>* %620 to <4 x i32>*
  store <4 x i32> %619, <4 x i32>* %621, align 16
  %622 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %623 = bitcast <2 x i64>* %622 to <4 x i32>*
  store <4 x i32> %580, <4 x i32>* %623, align 16
  %624 = sub <4 x i32> zeroinitializer, %594
  %625 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %626 = bitcast <2 x i64>* %625 to <4 x i32>*
  store <4 x i32> %624, <4 x i32>* %626, align 16
  %627 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %628 = bitcast <2 x i64>* %627 to <4 x i32>*
  store <4 x i32> %601, <4 x i32>* %628, align 16
  %629 = sub <4 x i32> zeroinitializer, %587
  %630 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %631 = bitcast <2 x i64>* %630 to <4 x i32>*
  store <4 x i32> %629, <4 x i32>* %631, align 16
  %632 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %633 = bitcast <2 x i64>* %632 to <4 x i32>*
  store <4 x i32> %529, <4 x i32>* %633, align 16
  %634 = sub <4 x i32> zeroinitializer, %569
  %635 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %636 = bitcast <2 x i64>* %635 to <4 x i32>*
  store <4 x i32> %634, <4 x i32>* %636, align 16
  %637 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %638 = bitcast <2 x i64>* %637 to <4 x i32>*
  store <4 x i32> %549, <4 x i32>* %638, align 16
  %639 = sub <4 x i32> zeroinitializer, %509
  br label %780

640:                                              ; preds = %6
  %641 = icmp sgt i32 %4, 10
  %642 = select i1 %641, i32 %4, i32 10
  %643 = shl i32 32, %642
  %644 = sub nsw i32 0, %643
  %645 = insertelement <4 x i32> undef, i32 %644, i32 0
  %646 = shufflevector <4 x i32> %645, <4 x i32> undef, <4 x i32> zeroinitializer
  %647 = add nsw i32 %643, -1
  %648 = insertelement <4 x i32> undef, i32 %647, i32 0
  %649 = shufflevector <4 x i32> %648, <4 x i32> undef, <4 x i32> zeroinitializer
  %650 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %651 = shl i32 1, %5
  %652 = ashr i32 %651, 1
  %653 = insertelement <4 x i32> undef, i32 %652, i32 0
  %654 = shufflevector <4 x i32> %653, <4 x i32> undef, <4 x i32> zeroinitializer
  %655 = add <4 x i32> %499, %654
  %656 = sub <4 x i32> %654, %539
  %657 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %5, i32 0
  %658 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %655, <4 x i32> %657) #8
  %659 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %656, <4 x i32> %657) #8
  %660 = icmp sgt <4 x i32> %658, %646
  %661 = select <4 x i1> %660, <4 x i32> %658, <4 x i32> %646
  %662 = icmp slt <4 x i32> %661, %649
  %663 = select <4 x i1> %662, <4 x i32> %661, <4 x i32> %649
  %664 = icmp sgt <4 x i32> %659, %646
  %665 = select <4 x i1> %664, <4 x i32> %659, <4 x i32> %646
  %666 = icmp slt <4 x i32> %665, %649
  %667 = select <4 x i1> %666, <4 x i32> %665, <4 x i32> %649
  %668 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %663, <4 x i32>* %668, align 16
  %669 = bitcast <2 x i64>* %650 to <4 x i32>*
  store <4 x i32> %667, <4 x i32>* %669, align 16
  %670 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %671 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %672 = add <4 x i32> %559, %654
  %673 = sub <4 x i32> %654, %519
  %674 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %672, <4 x i32> %657) #8
  %675 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %673, <4 x i32> %657) #8
  %676 = icmp sgt <4 x i32> %674, %646
  %677 = select <4 x i1> %676, <4 x i32> %674, <4 x i32> %646
  %678 = icmp slt <4 x i32> %677, %649
  %679 = select <4 x i1> %678, <4 x i32> %677, <4 x i32> %649
  %680 = icmp sgt <4 x i32> %675, %646
  %681 = select <4 x i1> %680, <4 x i32> %675, <4 x i32> %646
  %682 = icmp slt <4 x i32> %681, %649
  %683 = select <4 x i1> %682, <4 x i32> %681, <4 x i32> %649
  %684 = bitcast <2 x i64>* %670 to <4 x i32>*
  store <4 x i32> %679, <4 x i32>* %684, align 16
  %685 = bitcast <2 x i64>* %671 to <4 x i32>*
  store <4 x i32> %683, <4 x i32>* %685, align 16
  %686 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %687 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %688 = add <4 x i32> %585, %654
  %689 = sub <4 x i32> %654, %599
  %690 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %688, <4 x i32> %657) #8
  %691 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %689, <4 x i32> %657) #8
  %692 = icmp sgt <4 x i32> %690, %646
  %693 = select <4 x i1> %692, <4 x i32> %690, <4 x i32> %646
  %694 = icmp slt <4 x i32> %693, %649
  %695 = select <4 x i1> %694, <4 x i32> %693, <4 x i32> %649
  %696 = icmp sgt <4 x i32> %691, %646
  %697 = select <4 x i1> %696, <4 x i32> %691, <4 x i32> %646
  %698 = icmp slt <4 x i32> %697, %649
  %699 = select <4 x i1> %698, <4 x i32> %697, <4 x i32> %649
  %700 = bitcast <2 x i64>* %686 to <4 x i32>*
  store <4 x i32> %695, <4 x i32>* %700, align 16
  %701 = bitcast <2 x i64>* %687 to <4 x i32>*
  store <4 x i32> %699, <4 x i32>* %701, align 16
  %702 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %703 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %704 = add <4 x i32> %592, %654
  %705 = sub <4 x i32> %654, %578
  %706 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %704, <4 x i32> %657) #8
  %707 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %705, <4 x i32> %657) #8
  %708 = icmp sgt <4 x i32> %706, %646
  %709 = select <4 x i1> %708, <4 x i32> %706, <4 x i32> %646
  %710 = icmp slt <4 x i32> %709, %649
  %711 = select <4 x i1> %710, <4 x i32> %709, <4 x i32> %649
  %712 = icmp sgt <4 x i32> %707, %646
  %713 = select <4 x i1> %712, <4 x i32> %707, <4 x i32> %646
  %714 = icmp slt <4 x i32> %713, %649
  %715 = select <4 x i1> %714, <4 x i32> %713, <4 x i32> %649
  %716 = bitcast <2 x i64>* %702 to <4 x i32>*
  store <4 x i32> %711, <4 x i32>* %716, align 16
  %717 = bitcast <2 x i64>* %703 to <4 x i32>*
  store <4 x i32> %715, <4 x i32>* %717, align 16
  %718 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %719 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %720 = add <4 x i32> %580, %654
  %721 = sub <4 x i32> %654, %594
  %722 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %720, <4 x i32> %657) #8
  %723 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %721, <4 x i32> %657) #8
  %724 = icmp sgt <4 x i32> %722, %646
  %725 = select <4 x i1> %724, <4 x i32> %722, <4 x i32> %646
  %726 = icmp slt <4 x i32> %725, %649
  %727 = select <4 x i1> %726, <4 x i32> %725, <4 x i32> %649
  %728 = icmp sgt <4 x i32> %723, %646
  %729 = select <4 x i1> %728, <4 x i32> %723, <4 x i32> %646
  %730 = icmp slt <4 x i32> %729, %649
  %731 = select <4 x i1> %730, <4 x i32> %729, <4 x i32> %649
  %732 = bitcast <2 x i64>* %718 to <4 x i32>*
  store <4 x i32> %727, <4 x i32>* %732, align 16
  %733 = bitcast <2 x i64>* %719 to <4 x i32>*
  store <4 x i32> %731, <4 x i32>* %733, align 16
  %734 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %735 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %736 = add <4 x i32> %601, %654
  %737 = sub <4 x i32> %654, %587
  %738 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %736, <4 x i32> %657) #8
  %739 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %737, <4 x i32> %657) #8
  %740 = icmp sgt <4 x i32> %738, %646
  %741 = select <4 x i1> %740, <4 x i32> %738, <4 x i32> %646
  %742 = icmp slt <4 x i32> %741, %649
  %743 = select <4 x i1> %742, <4 x i32> %741, <4 x i32> %649
  %744 = icmp sgt <4 x i32> %739, %646
  %745 = select <4 x i1> %744, <4 x i32> %739, <4 x i32> %646
  %746 = icmp slt <4 x i32> %745, %649
  %747 = select <4 x i1> %746, <4 x i32> %745, <4 x i32> %649
  %748 = bitcast <2 x i64>* %734 to <4 x i32>*
  store <4 x i32> %743, <4 x i32>* %748, align 16
  %749 = bitcast <2 x i64>* %735 to <4 x i32>*
  store <4 x i32> %747, <4 x i32>* %749, align 16
  %750 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %751 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %752 = add <4 x i32> %529, %654
  %753 = sub <4 x i32> %654, %569
  %754 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %752, <4 x i32> %657) #8
  %755 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %753, <4 x i32> %657) #8
  %756 = icmp sgt <4 x i32> %754, %646
  %757 = select <4 x i1> %756, <4 x i32> %754, <4 x i32> %646
  %758 = icmp slt <4 x i32> %757, %649
  %759 = select <4 x i1> %758, <4 x i32> %757, <4 x i32> %649
  %760 = icmp sgt <4 x i32> %755, %646
  %761 = select <4 x i1> %760, <4 x i32> %755, <4 x i32> %646
  %762 = icmp slt <4 x i32> %761, %649
  %763 = select <4 x i1> %762, <4 x i32> %761, <4 x i32> %649
  %764 = bitcast <2 x i64>* %750 to <4 x i32>*
  store <4 x i32> %759, <4 x i32>* %764, align 16
  %765 = bitcast <2 x i64>* %751 to <4 x i32>*
  store <4 x i32> %763, <4 x i32>* %765, align 16
  %766 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %767 = add <4 x i32> %549, %654
  %768 = sub <4 x i32> %654, %509
  %769 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %767, <4 x i32> %657) #8
  %770 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %768, <4 x i32> %657) #8
  %771 = icmp sgt <4 x i32> %769, %646
  %772 = select <4 x i1> %771, <4 x i32> %769, <4 x i32> %646
  %773 = icmp slt <4 x i32> %772, %649
  %774 = select <4 x i1> %773, <4 x i32> %772, <4 x i32> %649
  %775 = icmp sgt <4 x i32> %770, %646
  %776 = select <4 x i1> %775, <4 x i32> %770, <4 x i32> %646
  %777 = icmp slt <4 x i32> %776, %649
  %778 = select <4 x i1> %777, <4 x i32> %776, <4 x i32> %649
  %779 = bitcast <2 x i64>* %766 to <4 x i32>*
  store <4 x i32> %774, <4 x i32>* %779, align 16
  br label %780

780:                                              ; preds = %640, %602
  %781 = phi <4 x i32> [ %778, %640 ], [ %639, %602 ]
  %782 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %783 = bitcast <2 x i64>* %782 to <4 x i32>*
  store <4 x i32> %781, <4 x i32>* %783, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @iidentity16_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>*, i32, i32, i32, i32) #0 {
  br label %9

7:                                                ; preds = %9
  %8 = icmp eq i32 %3, 0
  br i1 %8, label %40, label %274

9:                                                ; preds = %9, %6
  %10 = phi i64 [ 0, %6 ], [ %38, %9 ]
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %10
  %12 = load <2 x i64>, <2 x i64>* %11, align 16
  %13 = shl <2 x i64> %12, <i64 32, i64 32>
  %14 = ashr exact <2 x i64> %13, <i64 32, i64 32>
  %15 = mul nsw <2 x i64> %14, <i64 11586, i64 11586>
  %16 = bitcast <2 x i64> %15 to <4 x i32>
  %17 = add <4 x i32> %16, <i32 2048, i32 0, i32 2048, i32 0>
  %18 = bitcast <4 x i32> %17 to <2 x i64>
  %19 = lshr <2 x i64> %18, <i64 12, i64 12>
  %20 = bitcast <2 x i64> %12 to <16 x i8>
  %21 = shufflevector <16 x i8> %20, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %22 = bitcast <16 x i8> %21 to <2 x i64>
  %23 = shl <2 x i64> %22, <i64 32, i64 32>
  %24 = ashr exact <2 x i64> %23, <i64 32, i64 32>
  %25 = mul nsw <2 x i64> %24, <i64 11586, i64 11586>
  %26 = bitcast <2 x i64> %25 to <4 x i32>
  %27 = add <4 x i32> %26, <i32 2048, i32 0, i32 2048, i32 0>
  %28 = bitcast <4 x i32> %27 to <2 x i64>
  %29 = lshr <2 x i64> %28, <i64 12, i64 12>
  %30 = bitcast <2 x i64> %19 to <4 x i32>
  %31 = bitcast <2 x i64> %29 to <4 x i32>
  %32 = shufflevector <4 x i32> %30, <4 x i32> %31, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %33 = bitcast <4 x i32> %32 to <2 x i64>
  %34 = shufflevector <4 x i32> %30, <4 x i32> %31, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %35 = bitcast <4 x i32> %34 to <2 x i64>
  %36 = shufflevector <2 x i64> %33, <2 x i64> %35, <2 x i32> <i32 0, i32 2>
  %37 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %10
  store <2 x i64> %36, <2 x i64>* %37, align 16
  %38 = add nuw nsw i64 %10, 1
  %39 = icmp eq i64 %38, 16
  br i1 %39, label %7, label %9

40:                                               ; preds = %7
  %41 = icmp sgt i32 %4, 10
  %42 = select i1 %41, i32 %4, i32 10
  %43 = shl i32 32, %42
  %44 = sub nsw i32 0, %43
  %45 = insertelement <4 x i32> undef, i32 %44, i32 0
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = add nsw i32 %43, -1
  %48 = insertelement <4 x i32> undef, i32 %47, i32 0
  %49 = shufflevector <4 x i32> %48, <4 x i32> undef, <4 x i32> zeroinitializer
  %50 = icmp eq i32 %5, 0
  br i1 %50, label %51, label %90

51:                                               ; preds = %40
  %52 = bitcast <2 x i64>* %1 to <4 x i32>*
  %53 = load <4 x i32>, <4 x i32>* %52, align 16
  %54 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %55 = bitcast <2 x i64>* %54 to <4 x i32>*
  %56 = load <4 x i32>, <4 x i32>* %55, align 16
  %57 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %58 = bitcast <2 x i64>* %57 to <4 x i32>*
  %59 = load <4 x i32>, <4 x i32>* %58, align 16
  %60 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %61 = bitcast <2 x i64>* %60 to <4 x i32>*
  %62 = load <4 x i32>, <4 x i32>* %61, align 16
  %63 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %64 = bitcast <2 x i64>* %63 to <4 x i32>*
  %65 = load <4 x i32>, <4 x i32>* %64, align 16
  %66 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %67 = bitcast <2 x i64>* %66 to <4 x i32>*
  %68 = load <4 x i32>, <4 x i32>* %67, align 16
  %69 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %70 = bitcast <2 x i64>* %69 to <4 x i32>*
  %71 = load <4 x i32>, <4 x i32>* %70, align 16
  %72 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %73 = bitcast <2 x i64>* %72 to <4 x i32>*
  %74 = load <4 x i32>, <4 x i32>* %73, align 16
  %75 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %76 = bitcast <2 x i64>* %75 to <4 x i32>*
  %77 = load <4 x i32>, <4 x i32>* %76, align 16
  %78 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %79 = bitcast <2 x i64>* %78 to <4 x i32>*
  %80 = load <4 x i32>, <4 x i32>* %79, align 16
  %81 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %82 = bitcast <2 x i64>* %81 to <4 x i32>*
  %83 = load <4 x i32>, <4 x i32>* %82, align 16
  %84 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %85 = bitcast <2 x i64>* %84 to <4 x i32>*
  %86 = load <4 x i32>, <4 x i32>* %85, align 16
  %87 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %88 = bitcast <2 x i64>* %87 to <4 x i32>*
  %89 = load <4 x i32>, <4 x i32>* %88, align 16
  br label %174

90:                                               ; preds = %40
  %91 = add nsw i32 %5, -1
  %92 = shl i32 1, %91
  %93 = insertelement <4 x i32> undef, i32 %92, i32 0
  %94 = shufflevector <4 x i32> %93, <4 x i32> undef, <4 x i32> zeroinitializer
  %95 = bitcast <2 x i64>* %1 to <4 x i32>*
  %96 = load <4 x i32>, <4 x i32>* %95, align 16
  %97 = add <4 x i32> %96, %94
  %98 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %99 = bitcast <2 x i64>* %98 to <4 x i32>*
  %100 = load <4 x i32>, <4 x i32>* %99, align 16
  %101 = add <4 x i32> %100, %94
  %102 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %103 = bitcast <2 x i64>* %102 to <4 x i32>*
  %104 = load <4 x i32>, <4 x i32>* %103, align 16
  %105 = add <4 x i32> %104, %94
  %106 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %107 = bitcast <2 x i64>* %106 to <4 x i32>*
  %108 = load <4 x i32>, <4 x i32>* %107, align 16
  %109 = add <4 x i32> %108, %94
  %110 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %97, i32 %5) #8
  store <4 x i32> %110, <4 x i32>* %95, align 16
  %111 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %101, i32 %5) #8
  store <4 x i32> %111, <4 x i32>* %99, align 16
  %112 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %105, i32 %5) #8
  store <4 x i32> %112, <4 x i32>* %103, align 16
  %113 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %109, i32 %5) #8
  store <4 x i32> %113, <4 x i32>* %107, align 16
  %114 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %115 = bitcast <2 x i64>* %114 to <4 x i32>*
  %116 = load <4 x i32>, <4 x i32>* %115, align 16
  %117 = add <4 x i32> %116, %94
  %118 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %119 = bitcast <2 x i64>* %118 to <4 x i32>*
  %120 = load <4 x i32>, <4 x i32>* %119, align 16
  %121 = add <4 x i32> %120, %94
  %122 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %123 = bitcast <2 x i64>* %122 to <4 x i32>*
  %124 = load <4 x i32>, <4 x i32>* %123, align 16
  %125 = add <4 x i32> %124, %94
  %126 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %127 = bitcast <2 x i64>* %126 to <4 x i32>*
  %128 = load <4 x i32>, <4 x i32>* %127, align 16
  %129 = add <4 x i32> %128, %94
  %130 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %117, i32 %5) #8
  store <4 x i32> %130, <4 x i32>* %115, align 16
  %131 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %121, i32 %5) #8
  store <4 x i32> %131, <4 x i32>* %119, align 16
  %132 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %125, i32 %5) #8
  store <4 x i32> %132, <4 x i32>* %123, align 16
  %133 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %129, i32 %5) #8
  store <4 x i32> %133, <4 x i32>* %127, align 16
  %134 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %135 = bitcast <2 x i64>* %134 to <4 x i32>*
  %136 = load <4 x i32>, <4 x i32>* %135, align 16
  %137 = add <4 x i32> %136, %94
  %138 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %139 = bitcast <2 x i64>* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 16
  %141 = add <4 x i32> %140, %94
  %142 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %143 = bitcast <2 x i64>* %142 to <4 x i32>*
  %144 = load <4 x i32>, <4 x i32>* %143, align 16
  %145 = add <4 x i32> %144, %94
  %146 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %147 = bitcast <2 x i64>* %146 to <4 x i32>*
  %148 = load <4 x i32>, <4 x i32>* %147, align 16
  %149 = add <4 x i32> %148, %94
  %150 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %137, i32 %5) #8
  store <4 x i32> %150, <4 x i32>* %135, align 16
  %151 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %141, i32 %5) #8
  store <4 x i32> %151, <4 x i32>* %139, align 16
  %152 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %145, i32 %5) #8
  store <4 x i32> %152, <4 x i32>* %143, align 16
  %153 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %149, i32 %5) #8
  store <4 x i32> %153, <4 x i32>* %147, align 16
  %154 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %155 = bitcast <2 x i64>* %154 to <4 x i32>*
  %156 = load <4 x i32>, <4 x i32>* %155, align 16
  %157 = add <4 x i32> %156, %94
  %158 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %159 = bitcast <2 x i64>* %158 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16
  %161 = add <4 x i32> %160, %94
  %162 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %163 = bitcast <2 x i64>* %162 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = add <4 x i32> %164, %94
  %166 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %167 = bitcast <2 x i64>* %166 to <4 x i32>*
  %168 = load <4 x i32>, <4 x i32>* %167, align 16
  %169 = add <4 x i32> %168, %94
  %170 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %157, i32 %5) #8
  store <4 x i32> %170, <4 x i32>* %155, align 16
  %171 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %161, i32 %5) #8
  store <4 x i32> %171, <4 x i32>* %159, align 16
  %172 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %165, i32 %5) #8
  store <4 x i32> %172, <4 x i32>* %163, align 16
  %173 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %169, i32 %5) #8
  store <4 x i32> %173, <4 x i32>* %167, align 16
  br label %174

174:                                              ; preds = %51, %90
  %175 = phi <4 x i32>* [ %88, %51 ], [ %155, %90 ]
  %176 = phi <4 x i32>* [ %85, %51 ], [ %147, %90 ]
  %177 = phi <4 x i32>* [ %82, %51 ], [ %143, %90 ]
  %178 = phi <4 x i32>* [ %79, %51 ], [ %139, %90 ]
  %179 = phi <4 x i32>* [ %76, %51 ], [ %135, %90 ]
  %180 = phi <4 x i32>* [ %73, %51 ], [ %127, %90 ]
  %181 = phi <4 x i32>* [ %70, %51 ], [ %123, %90 ]
  %182 = phi <4 x i32>* [ %67, %51 ], [ %119, %90 ]
  %183 = phi <4 x i32>* [ %64, %51 ], [ %115, %90 ]
  %184 = phi <4 x i32>* [ %61, %51 ], [ %107, %90 ]
  %185 = phi <4 x i32>* [ %58, %51 ], [ %103, %90 ]
  %186 = phi <4 x i32>* [ %55, %51 ], [ %99, %90 ]
  %187 = phi <4 x i32>* [ %52, %51 ], [ %95, %90 ]
  %188 = phi <4 x i32> [ %89, %51 ], [ %170, %90 ]
  %189 = phi <4 x i32> [ %86, %51 ], [ %153, %90 ]
  %190 = phi <4 x i32> [ %83, %51 ], [ %152, %90 ]
  %191 = phi <4 x i32> [ %80, %51 ], [ %151, %90 ]
  %192 = phi <4 x i32> [ %77, %51 ], [ %150, %90 ]
  %193 = phi <4 x i32> [ %74, %51 ], [ %133, %90 ]
  %194 = phi <4 x i32> [ %71, %51 ], [ %132, %90 ]
  %195 = phi <4 x i32> [ %68, %51 ], [ %131, %90 ]
  %196 = phi <4 x i32> [ %65, %51 ], [ %130, %90 ]
  %197 = phi <4 x i32> [ %62, %51 ], [ %113, %90 ]
  %198 = phi <4 x i32> [ %59, %51 ], [ %112, %90 ]
  %199 = phi <4 x i32> [ %56, %51 ], [ %111, %90 ]
  %200 = phi <4 x i32> [ %53, %51 ], [ %110, %90 ]
  %201 = icmp sgt <4 x i32> %200, %46
  %202 = select <4 x i1> %201, <4 x i32> %200, <4 x i32> %46
  %203 = icmp slt <4 x i32> %202, %49
  %204 = select <4 x i1> %203, <4 x i32> %202, <4 x i32> %49
  store <4 x i32> %204, <4 x i32>* %187, align 16
  %205 = icmp sgt <4 x i32> %199, %46
  %206 = select <4 x i1> %205, <4 x i32> %199, <4 x i32> %46
  %207 = icmp slt <4 x i32> %206, %49
  %208 = select <4 x i1> %207, <4 x i32> %206, <4 x i32> %49
  store <4 x i32> %208, <4 x i32>* %186, align 16
  %209 = icmp sgt <4 x i32> %198, %46
  %210 = select <4 x i1> %209, <4 x i32> %198, <4 x i32> %46
  %211 = icmp slt <4 x i32> %210, %49
  %212 = select <4 x i1> %211, <4 x i32> %210, <4 x i32> %49
  store <4 x i32> %212, <4 x i32>* %185, align 16
  %213 = icmp sgt <4 x i32> %197, %46
  %214 = select <4 x i1> %213, <4 x i32> %197, <4 x i32> %46
  %215 = icmp slt <4 x i32> %214, %49
  %216 = select <4 x i1> %215, <4 x i32> %214, <4 x i32> %49
  store <4 x i32> %216, <4 x i32>* %184, align 16
  %217 = icmp sgt <4 x i32> %196, %46
  %218 = select <4 x i1> %217, <4 x i32> %196, <4 x i32> %46
  %219 = icmp slt <4 x i32> %218, %49
  %220 = select <4 x i1> %219, <4 x i32> %218, <4 x i32> %49
  store <4 x i32> %220, <4 x i32>* %183, align 16
  %221 = icmp sgt <4 x i32> %195, %46
  %222 = select <4 x i1> %221, <4 x i32> %195, <4 x i32> %46
  %223 = icmp slt <4 x i32> %222, %49
  %224 = select <4 x i1> %223, <4 x i32> %222, <4 x i32> %49
  store <4 x i32> %224, <4 x i32>* %182, align 16
  %225 = icmp sgt <4 x i32> %194, %46
  %226 = select <4 x i1> %225, <4 x i32> %194, <4 x i32> %46
  %227 = icmp slt <4 x i32> %226, %49
  %228 = select <4 x i1> %227, <4 x i32> %226, <4 x i32> %49
  store <4 x i32> %228, <4 x i32>* %181, align 16
  %229 = icmp sgt <4 x i32> %193, %46
  %230 = select <4 x i1> %229, <4 x i32> %193, <4 x i32> %46
  %231 = icmp slt <4 x i32> %230, %49
  %232 = select <4 x i1> %231, <4 x i32> %230, <4 x i32> %49
  store <4 x i32> %232, <4 x i32>* %180, align 16
  %233 = icmp sgt <4 x i32> %192, %46
  %234 = select <4 x i1> %233, <4 x i32> %192, <4 x i32> %46
  %235 = icmp slt <4 x i32> %234, %49
  %236 = select <4 x i1> %235, <4 x i32> %234, <4 x i32> %49
  store <4 x i32> %236, <4 x i32>* %179, align 16
  %237 = icmp sgt <4 x i32> %191, %46
  %238 = select <4 x i1> %237, <4 x i32> %191, <4 x i32> %46
  %239 = icmp slt <4 x i32> %238, %49
  %240 = select <4 x i1> %239, <4 x i32> %238, <4 x i32> %49
  store <4 x i32> %240, <4 x i32>* %178, align 16
  %241 = icmp sgt <4 x i32> %190, %46
  %242 = select <4 x i1> %241, <4 x i32> %190, <4 x i32> %46
  %243 = icmp slt <4 x i32> %242, %49
  %244 = select <4 x i1> %243, <4 x i32> %242, <4 x i32> %49
  store <4 x i32> %244, <4 x i32>* %177, align 16
  %245 = icmp sgt <4 x i32> %189, %46
  %246 = select <4 x i1> %245, <4 x i32> %189, <4 x i32> %46
  %247 = icmp slt <4 x i32> %246, %49
  %248 = select <4 x i1> %247, <4 x i32> %246, <4 x i32> %49
  store <4 x i32> %248, <4 x i32>* %176, align 16
  %249 = icmp sgt <4 x i32> %188, %46
  %250 = select <4 x i1> %249, <4 x i32> %188, <4 x i32> %46
  %251 = icmp slt <4 x i32> %250, %49
  %252 = select <4 x i1> %251, <4 x i32> %250, <4 x i32> %49
  store <4 x i32> %252, <4 x i32>* %175, align 16
  %253 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %254 = bitcast <2 x i64>* %253 to <4 x i32>*
  %255 = load <4 x i32>, <4 x i32>* %254, align 16
  %256 = icmp sgt <4 x i32> %255, %46
  %257 = select <4 x i1> %256, <4 x i32> %255, <4 x i32> %46
  %258 = icmp slt <4 x i32> %257, %49
  %259 = select <4 x i1> %258, <4 x i32> %257, <4 x i32> %49
  store <4 x i32> %259, <4 x i32>* %254, align 16
  %260 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %261 = bitcast <2 x i64>* %260 to <4 x i32>*
  %262 = load <4 x i32>, <4 x i32>* %261, align 16
  %263 = icmp sgt <4 x i32> %262, %46
  %264 = select <4 x i1> %263, <4 x i32> %262, <4 x i32> %46
  %265 = icmp slt <4 x i32> %264, %49
  %266 = select <4 x i1> %265, <4 x i32> %264, <4 x i32> %49
  store <4 x i32> %266, <4 x i32>* %261, align 16
  %267 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %268 = bitcast <2 x i64>* %267 to <4 x i32>*
  %269 = load <4 x i32>, <4 x i32>* %268, align 16
  %270 = icmp sgt <4 x i32> %269, %46
  %271 = select <4 x i1> %270, <4 x i32> %269, <4 x i32> %46
  %272 = icmp slt <4 x i32> %271, %49
  %273 = select <4 x i1> %272, <4 x i32> %271, <4 x i32> %49
  store <4 x i32> %273, <4 x i32>* %268, align 16
  br label %274

274:                                              ; preds = %174, %7
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @idct32x32_low1_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>*, i32, i32, i32, i32) #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %10 = load i32, i32* %9, align 16
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = add nsw i32 %2, -1
  %14 = shl i32 1, %13
  %15 = insertelement <4 x i32> undef, i32 %14, i32 0
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> zeroinitializer
  %17 = icmp ne i32 %3, 0
  %18 = select i1 %17, i32 6, i32 8
  %19 = add nsw i32 %18, %4
  %20 = icmp slt i32 %19, 16
  %21 = add i32 %19, -1
  %22 = shl i32 1, %21
  %23 = select i1 %20, i32 32768, i32 %22
  %24 = sub nsw i32 0, %23
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> zeroinitializer
  %27 = add nsw i32 %23, -1
  %28 = insertelement <4 x i32> undef, i32 %27, i32 0
  %29 = shufflevector <4 x i32> %28, <4 x i32> undef, <4 x i32> zeroinitializer
  %30 = bitcast <2 x i64>* %0 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 16
  %32 = mul <4 x i32> %12, %31
  %33 = add <4 x i32> %32, %16
  %34 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %33, i32 %2) #8
  br i1 %17, label %35, label %40

35:                                               ; preds = %6
  %36 = icmp sgt <4 x i32> %34, %26
  %37 = select <4 x i1> %36, <4 x i32> %34, <4 x i32> %26
  %38 = icmp slt <4 x i32> %37, %29
  %39 = select <4 x i1> %38, <4 x i32> %37, <4 x i32> %29
  br label %59

40:                                               ; preds = %6
  %41 = icmp sgt i32 %4, 10
  %42 = select i1 %41, i32 %4, i32 10
  %43 = shl i32 32, %42
  %44 = sub nsw i32 0, %43
  %45 = insertelement <4 x i32> undef, i32 %44, i32 0
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = add nsw i32 %43, -1
  %48 = insertelement <4 x i32> undef, i32 %47, i32 0
  %49 = shufflevector <4 x i32> %48, <4 x i32> undef, <4 x i32> zeroinitializer
  %50 = icmp eq i32 %5, 0
  br i1 %50, label %59, label %51

51:                                               ; preds = %40
  %52 = shl i32 1, %5
  %53 = ashr i32 %52, 1
  %54 = insertelement <4 x i32> undef, i32 %53, i32 0
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> zeroinitializer
  %56 = add <4 x i32> %34, %55
  %57 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %5, i32 0
  %58 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %56, <4 x i32> %57) #8
  br label %59

59:                                               ; preds = %51, %40, %35
  %60 = phi <4 x i32> [ %39, %35 ], [ %34, %40 ], [ %58, %51 ]
  %61 = phi <4 x i32> [ %29, %35 ], [ %49, %40 ], [ %49, %51 ]
  %62 = phi <4 x i32> [ %26, %35 ], [ %46, %40 ], [ %46, %51 ]
  %63 = icmp sgt <4 x i32> %60, %62
  %64 = select <4 x i1> %63, <4 x i32> %60, <4 x i32> %62
  %65 = icmp slt <4 x i32> %64, %61
  %66 = select <4 x i1> %65, <4 x i32> %64, <4 x i32> %61
  %67 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %67, align 16
  %68 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %69 = bitcast <2 x i64>* %68 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %69, align 16
  %70 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %71 = bitcast <2 x i64>* %70 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %71, align 16
  %72 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %73 = bitcast <2 x i64>* %72 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %73, align 16
  %74 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %75 = bitcast <2 x i64>* %74 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %75, align 16
  %76 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %77 = bitcast <2 x i64>* %76 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %77, align 16
  %78 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %79 = bitcast <2 x i64>* %78 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %79, align 16
  %80 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %81 = bitcast <2 x i64>* %80 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %81, align 16
  %82 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %83 = bitcast <2 x i64>* %82 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %83, align 16
  %84 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %85 = bitcast <2 x i64>* %84 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %85, align 16
  %86 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %87 = bitcast <2 x i64>* %86 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %87, align 16
  %88 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %89 = bitcast <2 x i64>* %88 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %89, align 16
  %90 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %91 = bitcast <2 x i64>* %90 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %91, align 16
  %92 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %93 = bitcast <2 x i64>* %92 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %93, align 16
  %94 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %95 = bitcast <2 x i64>* %94 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %95, align 16
  %96 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %97 = bitcast <2 x i64>* %96 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %97, align 16
  %98 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 16
  %99 = bitcast <2 x i64>* %98 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %99, align 16
  %100 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 17
  %101 = bitcast <2 x i64>* %100 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %101, align 16
  %102 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 18
  %103 = bitcast <2 x i64>* %102 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %103, align 16
  %104 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 19
  %105 = bitcast <2 x i64>* %104 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %105, align 16
  %106 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 20
  %107 = bitcast <2 x i64>* %106 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %107, align 16
  %108 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 21
  %109 = bitcast <2 x i64>* %108 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %109, align 16
  %110 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 22
  %111 = bitcast <2 x i64>* %110 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %111, align 16
  %112 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 23
  %113 = bitcast <2 x i64>* %112 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %113, align 16
  %114 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 24
  %115 = bitcast <2 x i64>* %114 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %115, align 16
  %116 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 25
  %117 = bitcast <2 x i64>* %116 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %117, align 16
  %118 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 26
  %119 = bitcast <2 x i64>* %118 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %119, align 16
  %120 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 27
  %121 = bitcast <2 x i64>* %120 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %121, align 16
  %122 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 28
  %123 = bitcast <2 x i64>* %122 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %123, align 16
  %124 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 29
  %125 = bitcast <2 x i64>* %124 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %125, align 16
  %126 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 30
  %127 = bitcast <2 x i64>* %126 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %127, align 16
  %128 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 31
  %129 = bitcast <2 x i64>* %128 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %129, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @idct32x32_low8_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>*, i32, i32, i32, i32) #0 {
  %7 = alloca <2 x i64>, align 16
  %8 = alloca <2 x i64>, align 16
  %9 = alloca [32 x <2 x i64>], align 16
  %10 = add nsw i32 %2, -10
  %11 = sext i32 %10 to i64
  %12 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 62
  %13 = load i32, i32* %12, align 8
  %14 = insertelement <4 x i32> undef, i32 %13, i32 0
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> zeroinitializer
  %16 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 14
  %17 = load i32, i32* %16, align 8
  %18 = insertelement <4 x i32> undef, i32 %17, i32 0
  %19 = shufflevector <4 x i32> %18, <4 x i32> undef, <4 x i32> zeroinitializer
  %20 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 54
  %21 = load i32, i32* %20, align 8
  %22 = insertelement <4 x i32> undef, i32 %21, i32 0
  %23 = shufflevector <4 x i32> %22, <4 x i32> undef, <4 x i32> zeroinitializer
  %24 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 6
  %25 = load i32, i32* %24, align 8
  %26 = insertelement <4 x i32> undef, i32 %25, i32 0
  %27 = shufflevector <4 x i32> %26, <4 x i32> undef, <4 x i32> zeroinitializer
  %28 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 10
  %29 = load i32, i32* %28, align 8
  %30 = insertelement <4 x i32> undef, i32 %29, i32 0
  %31 = shufflevector <4 x i32> %30, <4 x i32> undef, <4 x i32> zeroinitializer
  %32 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 2
  %33 = load i32, i32* %32, align 8
  %34 = insertelement <4 x i32> undef, i32 %33, i32 0
  %35 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> zeroinitializer
  %36 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 58
  %37 = load i32, i32* %36, align 8
  %38 = sub nsw i32 0, %37
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> zeroinitializer
  %41 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 50
  %42 = load i32, i32* %41, align 8
  %43 = sub nsw i32 0, %42
  %44 = insertelement <4 x i32> undef, i32 %43, i32 0
  %45 = shufflevector <4 x i32> %44, <4 x i32> undef, <4 x i32> zeroinitializer
  %46 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 60
  %47 = load i32, i32* %46, align 16
  %48 = insertelement <4 x i32> undef, i32 %47, i32 0
  %49 = shufflevector <4 x i32> %48, <4 x i32> undef, <4 x i32> zeroinitializer
  %50 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 12
  %51 = load i32, i32* %50, align 16
  %52 = insertelement <4 x i32> undef, i32 %51, i32 0
  %53 = shufflevector <4 x i32> %52, <4 x i32> undef, <4 x i32> zeroinitializer
  %54 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 4
  %55 = load i32, i32* %54, align 16
  %56 = insertelement <4 x i32> undef, i32 %55, i32 0
  %57 = shufflevector <4 x i32> %56, <4 x i32> undef, <4 x i32> zeroinitializer
  %58 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 52
  %59 = load i32, i32* %58, align 16
  %60 = sub nsw i32 0, %59
  %61 = insertelement <4 x i32> undef, i32 %60, i32 0
  %62 = shufflevector <4 x i32> %61, <4 x i32> undef, <4 x i32> zeroinitializer
  %63 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 56
  %64 = load i32, i32* %63, align 16
  %65 = insertelement <4 x i32> undef, i32 %64, i32 0
  %66 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> zeroinitializer
  %67 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 24
  %68 = load i32, i32* %67, align 16
  %69 = insertelement <4 x i32> undef, i32 %68, i32 0
  %70 = shufflevector <4 x i32> %69, <4 x i32> undef, <4 x i32> zeroinitializer
  %71 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 40
  %72 = load i32, i32* %71, align 16
  %73 = insertelement <4 x i32> undef, i32 %72, i32 0
  %74 = shufflevector <4 x i32> %73, <4 x i32> undef, <4 x i32> zeroinitializer
  %75 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 8
  %76 = load i32, i32* %75, align 16
  %77 = insertelement <4 x i32> undef, i32 %76, i32 0
  %78 = shufflevector <4 x i32> %77, <4 x i32> undef, <4 x i32> zeroinitializer
  %79 = sub nsw i32 0, %72
  %80 = insertelement <4 x i32> undef, i32 %79, i32 0
  %81 = shufflevector <4 x i32> %80, <4 x i32> undef, <4 x i32> zeroinitializer
  %82 = sub nsw i32 0, %76
  %83 = insertelement <4 x i32> undef, i32 %82, i32 0
  %84 = shufflevector <4 x i32> %83, <4 x i32> undef, <4 x i32> zeroinitializer
  %85 = sub nsw i32 0, %64
  %86 = insertelement <4 x i32> undef, i32 %85, i32 0
  %87 = shufflevector <4 x i32> %86, <4 x i32> undef, <4 x i32> zeroinitializer
  %88 = sub nsw i32 0, %68
  %89 = insertelement <4 x i32> undef, i32 %88, i32 0
  %90 = shufflevector <4 x i32> %89, <4 x i32> undef, <4 x i32> zeroinitializer
  %91 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 32
  %92 = load i32, i32* %91, align 16
  %93 = insertelement <4 x i32> undef, i32 %92, i32 0
  %94 = shufflevector <4 x i32> %93, <4 x i32> undef, <4 x i32> zeroinitializer
  %95 = sub nsw i32 0, %92
  %96 = insertelement <4 x i32> undef, i32 %95, i32 0
  %97 = shufflevector <4 x i32> %96, <4 x i32> undef, <4 x i32> zeroinitializer
  %98 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 48
  %99 = load i32, i32* %98, align 16
  %100 = insertelement <4 x i32> undef, i32 %99, i32 0
  %101 = shufflevector <4 x i32> %100, <4 x i32> undef, <4 x i32> zeroinitializer
  %102 = sub nsw i32 0, %99
  %103 = insertelement <4 x i32> undef, i32 %102, i32 0
  %104 = shufflevector <4 x i32> %103, <4 x i32> undef, <4 x i32> zeroinitializer
  %105 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 16
  %106 = load i32, i32* %105, align 16
  %107 = insertelement <4 x i32> undef, i32 %106, i32 0
  %108 = shufflevector <4 x i32> %107, <4 x i32> undef, <4 x i32> zeroinitializer
  %109 = sub nsw i32 0, %106
  %110 = insertelement <4 x i32> undef, i32 %109, i32 0
  %111 = shufflevector <4 x i32> %110, <4 x i32> undef, <4 x i32> zeroinitializer
  %112 = add nsw i32 %2, -1
  %113 = shl i32 1, %112
  %114 = insertelement <4 x i32> undef, i32 %113, i32 0
  %115 = shufflevector <4 x i32> %114, <4 x i32> undef, <4 x i32> zeroinitializer
  %116 = icmp eq i32 %3, 0
  %117 = select i1 %116, i32 8, i32 6
  %118 = add nsw i32 %117, %4
  %119 = icmp slt i32 %118, 16
  %120 = add i32 %118, -1
  %121 = bitcast <2 x i64>* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #8
  %122 = shl i32 1, %120
  %123 = select i1 %119, i32 32768, i32 %122
  %124 = sub nsw i32 0, %123
  %125 = insertelement <4 x i32> undef, i32 %124, i32 0
  %126 = shufflevector <4 x i32> %125, <4 x i32> undef, <4 x i32> zeroinitializer
  %127 = bitcast <2 x i64>* %7 to <4 x i32>*
  store <4 x i32> %126, <4 x i32>* %127, align 16
  %128 = bitcast <2 x i64>* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %128) #8
  %129 = add nsw i32 %123, -1
  %130 = insertelement <4 x i32> undef, i32 %129, i32 0
  %131 = shufflevector <4 x i32> %130, <4 x i32> undef, <4 x i32> zeroinitializer
  %132 = bitcast <2 x i64>* %8 to <4 x i32>*
  store <4 x i32> %131, <4 x i32>* %132, align 16
  %133 = bitcast [32 x <2 x i64>]* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %133) #8
  %134 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 1
  %135 = bitcast <2 x i64>* %134 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %135, i8 -86, i64 480, i1 false)
  %136 = load <2 x i64>, <2 x i64>* %0, align 16
  %137 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 0
  store <2 x i64> %136, <2 x i64>* %137, align 16
  %138 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %139 = load <2 x i64>, <2 x i64>* %138, align 16
  %140 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 4
  store <2 x i64> %139, <2 x i64>* %140, align 16
  %141 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %142 = bitcast <2 x i64>* %141 to <4 x i32>*
  %143 = load <4 x i32>, <4 x i32>* %142, align 16
  %144 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 8
  %145 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %146 = bitcast <2 x i64>* %145 to <4 x i32>*
  %147 = load <4 x i32>, <4 x i32>* %146, align 16
  %148 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 12
  %149 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %150 = bitcast <2 x i64>* %149 to <4 x i32>*
  %151 = load <4 x i32>, <4 x i32>* %150, align 16
  %152 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 16
  %153 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %154 = bitcast <2 x i64>* %153 to <4 x i32>*
  %155 = load <4 x i32>, <4 x i32>* %154, align 16
  %156 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 20
  %157 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %158 = bitcast <2 x i64>* %157 to <4 x i32>*
  %159 = load <4 x i32>, <4 x i32>* %158, align 16
  %160 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 24
  %161 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %162 = bitcast <2 x i64>* %161 to <4 x i32>*
  %163 = load <4 x i32>, <4 x i32>* %162, align 16
  %164 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 28
  %165 = bitcast <2 x i64>* %152 to <4 x i32>*
  %166 = mul <4 x i32> %35, %151
  %167 = add <4 x i32> %166, %115
  %168 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %167, i32 %2) #8
  %169 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 31
  %170 = bitcast <2 x i64>* %169 to <4 x i32>*
  store <4 x i32> %168, <4 x i32>* %170, align 16
  %171 = mul <4 x i32> %15, %151
  %172 = add <4 x i32> %171, %115
  %173 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %172, i32 %2) #8
  store <4 x i32> %173, <4 x i32>* %165, align 16
  %174 = bitcast <2 x i64>* %164 to <4 x i32>*
  %175 = mul <4 x i32> %45, %163
  %176 = add <4 x i32> %175, %115
  %177 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %176, i32 %2) #8
  %178 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 19
  %179 = bitcast <2 x i64>* %178 to <4 x i32>*
  store <4 x i32> %177, <4 x i32>* %179, align 16
  %180 = mul <4 x i32> %19, %163
  %181 = add <4 x i32> %180, %115
  %182 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %181, i32 %2) #8
  store <4 x i32> %182, <4 x i32>* %174, align 16
  %183 = bitcast <2 x i64>* %156 to <4 x i32>*
  %184 = mul <4 x i32> %31, %155
  %185 = add <4 x i32> %184, %115
  %186 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %185, i32 %2) #8
  %187 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 27
  %188 = bitcast <2 x i64>* %187 to <4 x i32>*
  store <4 x i32> %186, <4 x i32>* %188, align 16
  %189 = mul <4 x i32> %23, %155
  %190 = add <4 x i32> %189, %115
  %191 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %190, i32 %2) #8
  store <4 x i32> %191, <4 x i32>* %183, align 16
  %192 = bitcast <2 x i64>* %160 to <4 x i32>*
  %193 = mul <4 x i32> %40, %159
  %194 = add <4 x i32> %193, %115
  %195 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %194, i32 %2) #8
  %196 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 23
  %197 = bitcast <2 x i64>* %196 to <4 x i32>*
  store <4 x i32> %195, <4 x i32>* %197, align 16
  %198 = mul <4 x i32> %27, %159
  %199 = add <4 x i32> %198, %115
  %200 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %199, i32 %2) #8
  store <4 x i32> %200, <4 x i32>* %192, align 16
  %201 = bitcast <2 x i64>* %144 to <4 x i32>*
  %202 = mul <4 x i32> %57, %143
  %203 = add <4 x i32> %202, %115
  %204 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %203, i32 %2) #8
  %205 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 15
  %206 = bitcast <2 x i64>* %205 to <4 x i32>*
  store <4 x i32> %204, <4 x i32>* %206, align 16
  %207 = mul <4 x i32> %49, %143
  %208 = add <4 x i32> %207, %115
  %209 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %208, i32 %2) #8
  store <4 x i32> %209, <4 x i32>* %201, align 16
  %210 = bitcast <2 x i64>* %148 to <4 x i32>*
  %211 = mul <4 x i32> %62, %147
  %212 = add <4 x i32> %211, %115
  %213 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %212, i32 %2) #8
  %214 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 11
  %215 = bitcast <2 x i64>* %214 to <4 x i32>*
  store <4 x i32> %213, <4 x i32>* %215, align 16
  %216 = mul <4 x i32> %53, %147
  %217 = add <4 x i32> %216, %115
  %218 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %217, i32 %2) #8
  store <4 x i32> %218, <4 x i32>* %210, align 16
  %219 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 17
  %220 = bitcast <2 x i64>* %219 to <4 x i32>*
  %221 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 18
  %222 = bitcast <2 x i64>* %221 to <4 x i32>*
  %223 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 21
  %224 = bitcast <2 x i64>* %223 to <4 x i32>*
  %225 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 22
  %226 = bitcast <2 x i64>* %225 to <4 x i32>*
  %227 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 25
  %228 = bitcast <2 x i64>* %227 to <4 x i32>*
  %229 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 26
  %230 = bitcast <2 x i64>* %229 to <4 x i32>*
  %231 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 29
  %232 = bitcast <2 x i64>* %231 to <4 x i32>*
  %233 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 30
  %234 = bitcast <2 x i64>* %233 to <4 x i32>*
  %235 = bitcast <2 x i64>* %140 to <4 x i32>*
  %236 = load <4 x i32>, <4 x i32>* %235, align 16
  %237 = mul <4 x i32> %236, %78
  %238 = add <4 x i32> %237, %115
  %239 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %238, i32 %2) #8
  %240 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 7
  %241 = bitcast <2 x i64>* %240 to <4 x i32>*
  store <4 x i32> %239, <4 x i32>* %241, align 16
  %242 = mul <4 x i32> %236, %66
  %243 = add <4 x i32> %242, %115
  %244 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %243, i32 %2) #8
  store <4 x i32> %244, <4 x i32>* %235, align 16
  %245 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 9
  %246 = bitcast <2 x i64>* %245 to <4 x i32>*
  %247 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 10
  %248 = bitcast <2 x i64>* %247 to <4 x i32>*
  %249 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 13
  %250 = bitcast <2 x i64>* %249 to <4 x i32>*
  %251 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 14
  %252 = bitcast <2 x i64>* %251 to <4 x i32>*
  %253 = mul <4 x i32> %173, %84
  %254 = mul <4 x i32> %168, %66
  %255 = add <4 x i32> %253, %115
  %256 = add <4 x i32> %255, %254
  %257 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %256, i32 %2) #8
  %258 = mul <4 x i32> %173, %66
  %259 = mul <4 x i32> %168, %78
  %260 = add <4 x i32> %258, %115
  %261 = add <4 x i32> %260, %259
  %262 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %261, i32 %2) #8
  store <4 x i32> %262, <4 x i32>* %234, align 16
  store <4 x i32> %257, <4 x i32>* %220, align 16
  %263 = mul <4 x i32> %177, %87
  %264 = mul <4 x i32> %182, %84
  %265 = add <4 x i32> %263, %115
  %266 = add <4 x i32> %265, %264
  %267 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %266, i32 %2) #8
  %268 = mul <4 x i32> %177, %84
  %269 = mul <4 x i32> %182, %66
  %270 = add <4 x i32> %268, %115
  %271 = add <4 x i32> %270, %269
  %272 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %271, i32 %2) #8
  store <4 x i32> %272, <4 x i32>* %232, align 16
  %273 = mul <4 x i32> %191, %81
  %274 = mul <4 x i32> %186, %70
  %275 = add <4 x i32> %273, %115
  %276 = add <4 x i32> %275, %274
  %277 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %276, i32 %2) #8
  %278 = mul <4 x i32> %191, %70
  %279 = mul <4 x i32> %186, %74
  %280 = add <4 x i32> %278, %115
  %281 = add <4 x i32> %280, %279
  %282 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %281, i32 %2) #8
  store <4 x i32> %282, <4 x i32>* %230, align 16
  store <4 x i32> %277, <4 x i32>* %224, align 16
  %283 = mul <4 x i32> %195, %90
  %284 = mul <4 x i32> %200, %81
  %285 = add <4 x i32> %283, %115
  %286 = add <4 x i32> %285, %284
  %287 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %286, i32 %2) #8
  %288 = mul <4 x i32> %195, %81
  %289 = mul <4 x i32> %200, %70
  %290 = add <4 x i32> %288, %115
  %291 = add <4 x i32> %290, %289
  %292 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %291, i32 %2) #8
  store <4 x i32> %292, <4 x i32>* %228, align 16
  %293 = bitcast [32 x <2 x i64>]* %9 to <4 x i32>*
  %294 = load <4 x i32>, <4 x i32>* %293, align 16
  %295 = mul <4 x i32> %294, %94
  %296 = add <4 x i32> %295, %115
  %297 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %296, i32 %2) #8
  store <4 x i32> %297, <4 x i32>* %293, align 16
  %298 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 1
  %299 = bitcast <2 x i64>* %298 to <4 x i32>*
  store <4 x i32> %297, <4 x i32>* %299, align 16
  %300 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 5
  %301 = bitcast <2 x i64>* %300 to <4 x i32>*
  store <4 x i32> %244, <4 x i32>* %301, align 16
  %302 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 6
  %303 = bitcast <2 x i64>* %302 to <4 x i32>*
  store <4 x i32> %239, <4 x i32>* %303, align 16
  %304 = mul <4 x i32> %209, %111
  %305 = mul <4 x i32> %204, %101
  %306 = add <4 x i32> %304, %115
  %307 = add <4 x i32> %306, %305
  %308 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %307, i32 %2) #8
  %309 = mul <4 x i32> %209, %101
  %310 = mul <4 x i32> %204, %108
  %311 = add <4 x i32> %309, %115
  %312 = add <4 x i32> %311, %310
  %313 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %312, i32 %2) #8
  store <4 x i32> %313, <4 x i32>* %252, align 16
  store <4 x i32> %308, <4 x i32>* %246, align 16
  %314 = mul <4 x i32> %213, %104
  %315 = mul <4 x i32> %218, %111
  %316 = add <4 x i32> %314, %115
  %317 = add <4 x i32> %316, %315
  %318 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %317, i32 %2) #8
  %319 = mul <4 x i32> %213, %111
  %320 = mul <4 x i32> %218, %101
  %321 = add <4 x i32> %319, %115
  %322 = add <4 x i32> %321, %320
  %323 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %322, i32 %2) #8
  store <4 x i32> %323, <4 x i32>* %250, align 16
  store <4 x i32> %318, <4 x i32>* %248, align 16
  %324 = load <4 x i32>, <4 x i32>* %165, align 16
  %325 = load <4 x i32>, <4 x i32>* %179, align 16
  %326 = add <4 x i32> %325, %324
  %327 = sub <4 x i32> %324, %325
  %328 = load <4 x i32>, <4 x i32>* %127, align 16
  %329 = icmp sgt <4 x i32> %326, %328
  %330 = select <4 x i1> %329, <4 x i32> %326, <4 x i32> %328
  %331 = load <4 x i32>, <4 x i32>* %132, align 16
  %332 = icmp slt <4 x i32> %330, %331
  %333 = select <4 x i1> %332, <4 x i32> %330, <4 x i32> %331
  %334 = icmp sgt <4 x i32> %327, %328
  %335 = select <4 x i1> %334, <4 x i32> %327, <4 x i32> %328
  %336 = icmp slt <4 x i32> %335, %331
  %337 = select <4 x i1> %336, <4 x i32> %335, <4 x i32> %331
  store <4 x i32> %333, <4 x i32>* %165, align 16
  store <4 x i32> %337, <4 x i32>* %179, align 16
  %338 = add <4 x i32> %267, %257
  %339 = sub <4 x i32> %257, %267
  %340 = icmp sgt <4 x i32> %338, %328
  %341 = select <4 x i1> %340, <4 x i32> %338, <4 x i32> %328
  %342 = icmp slt <4 x i32> %341, %331
  %343 = select <4 x i1> %342, <4 x i32> %341, <4 x i32> %331
  %344 = icmp sgt <4 x i32> %339, %328
  %345 = select <4 x i1> %344, <4 x i32> %339, <4 x i32> %328
  %346 = icmp slt <4 x i32> %345, %331
  %347 = select <4 x i1> %346, <4 x i32> %345, <4 x i32> %331
  store <4 x i32> %343, <4 x i32>* %220, align 16
  store <4 x i32> %347, <4 x i32>* %222, align 16
  %348 = load <4 x i32>, <4 x i32>* %197, align 16
  %349 = load <4 x i32>, <4 x i32>* %183, align 16
  %350 = add <4 x i32> %349, %348
  %351 = sub <4 x i32> %348, %349
  %352 = icmp sgt <4 x i32> %350, %328
  %353 = select <4 x i1> %352, <4 x i32> %350, <4 x i32> %328
  %354 = icmp slt <4 x i32> %353, %331
  %355 = select <4 x i1> %354, <4 x i32> %353, <4 x i32> %331
  %356 = icmp sgt <4 x i32> %351, %328
  %357 = select <4 x i1> %356, <4 x i32> %351, <4 x i32> %328
  %358 = icmp slt <4 x i32> %357, %331
  %359 = select <4 x i1> %358, <4 x i32> %357, <4 x i32> %331
  store <4 x i32> %355, <4 x i32>* %197, align 16
  store <4 x i32> %359, <4 x i32>* %183, align 16
  %360 = add <4 x i32> %287, %277
  %361 = sub <4 x i32> %287, %277
  %362 = icmp sgt <4 x i32> %360, %328
  %363 = select <4 x i1> %362, <4 x i32> %360, <4 x i32> %328
  %364 = icmp slt <4 x i32> %363, %331
  %365 = select <4 x i1> %364, <4 x i32> %363, <4 x i32> %331
  %366 = icmp sgt <4 x i32> %361, %328
  %367 = select <4 x i1> %366, <4 x i32> %361, <4 x i32> %328
  %368 = icmp slt <4 x i32> %367, %331
  %369 = select <4 x i1> %368, <4 x i32> %367, <4 x i32> %331
  store <4 x i32> %365, <4 x i32>* %226, align 16
  store <4 x i32> %369, <4 x i32>* %224, align 16
  %370 = load <4 x i32>, <4 x i32>* %192, align 16
  %371 = load <4 x i32>, <4 x i32>* %188, align 16
  %372 = add <4 x i32> %371, %370
  %373 = sub <4 x i32> %370, %371
  %374 = icmp sgt <4 x i32> %372, %328
  %375 = select <4 x i1> %374, <4 x i32> %372, <4 x i32> %328
  %376 = icmp slt <4 x i32> %375, %331
  %377 = select <4 x i1> %376, <4 x i32> %375, <4 x i32> %331
  %378 = icmp sgt <4 x i32> %373, %328
  %379 = select <4 x i1> %378, <4 x i32> %373, <4 x i32> %328
  %380 = icmp slt <4 x i32> %379, %331
  %381 = select <4 x i1> %380, <4 x i32> %379, <4 x i32> %331
  store <4 x i32> %377, <4 x i32>* %192, align 16
  store <4 x i32> %381, <4 x i32>* %188, align 16
  %382 = add <4 x i32> %292, %282
  %383 = sub <4 x i32> %292, %282
  %384 = icmp sgt <4 x i32> %382, %328
  %385 = select <4 x i1> %384, <4 x i32> %382, <4 x i32> %328
  %386 = icmp slt <4 x i32> %385, %331
  %387 = select <4 x i1> %386, <4 x i32> %385, <4 x i32> %331
  %388 = icmp sgt <4 x i32> %383, %328
  %389 = select <4 x i1> %388, <4 x i32> %383, <4 x i32> %328
  %390 = icmp slt <4 x i32> %389, %331
  %391 = select <4 x i1> %390, <4 x i32> %389, <4 x i32> %331
  store <4 x i32> %387, <4 x i32>* %228, align 16
  store <4 x i32> %391, <4 x i32>* %230, align 16
  %392 = load <4 x i32>, <4 x i32>* %170, align 16
  %393 = load <4 x i32>, <4 x i32>* %174, align 16
  %394 = add <4 x i32> %393, %392
  %395 = sub <4 x i32> %392, %393
  %396 = icmp sgt <4 x i32> %394, %328
  %397 = select <4 x i1> %396, <4 x i32> %394, <4 x i32> %328
  %398 = icmp slt <4 x i32> %397, %331
  %399 = select <4 x i1> %398, <4 x i32> %397, <4 x i32> %331
  %400 = icmp sgt <4 x i32> %395, %328
  %401 = select <4 x i1> %400, <4 x i32> %395, <4 x i32> %328
  %402 = icmp slt <4 x i32> %401, %331
  %403 = select <4 x i1> %402, <4 x i32> %401, <4 x i32> %331
  store <4 x i32> %399, <4 x i32>* %170, align 16
  store <4 x i32> %403, <4 x i32>* %174, align 16
  %404 = add <4 x i32> %272, %262
  %405 = sub <4 x i32> %262, %272
  %406 = icmp sgt <4 x i32> %404, %328
  %407 = select <4 x i1> %406, <4 x i32> %404, <4 x i32> %328
  %408 = icmp slt <4 x i32> %407, %331
  %409 = select <4 x i1> %408, <4 x i32> %407, <4 x i32> %331
  %410 = icmp sgt <4 x i32> %405, %328
  %411 = select <4 x i1> %410, <4 x i32> %405, <4 x i32> %328
  %412 = icmp slt <4 x i32> %411, %331
  %413 = select <4 x i1> %412, <4 x i32> %411, <4 x i32> %331
  store <4 x i32> %409, <4 x i32>* %234, align 16
  %414 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 3
  %415 = bitcast <2 x i64>* %414 to <4 x i32>*
  store <4 x i32> %297, <4 x i32>* %415, align 16
  %416 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 2
  %417 = bitcast <2 x i64>* %416 to <4 x i32>*
  store <4 x i32> %297, <4 x i32>* %417, align 16
  %418 = load <4 x i32>, <4 x i32>* %301, align 16
  %419 = mul <4 x i32> %418, %97
  %420 = load <4 x i32>, <4 x i32>* %303, align 16
  %421 = mul <4 x i32> %420, %94
  %422 = add <4 x i32> %421, %115
  %423 = add <4 x i32> %422, %419
  %424 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %423, i32 %2) #8
  %425 = mul <4 x i32> %418, %94
  %426 = add <4 x i32> %422, %425
  %427 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %426, i32 %2) #8
  store <4 x i32> %427, <4 x i32>* %303, align 16
  store <4 x i32> %424, <4 x i32>* %301, align 16
  %428 = load <4 x i32>, <4 x i32>* %201, align 16
  %429 = load <4 x i32>, <4 x i32>* %215, align 16
  %430 = add <4 x i32> %429, %428
  %431 = sub <4 x i32> %428, %429
  %432 = icmp sgt <4 x i32> %430, %328
  %433 = select <4 x i1> %432, <4 x i32> %430, <4 x i32> %328
  %434 = icmp slt <4 x i32> %433, %331
  %435 = select <4 x i1> %434, <4 x i32> %433, <4 x i32> %331
  %436 = icmp sgt <4 x i32> %431, %328
  %437 = select <4 x i1> %436, <4 x i32> %431, <4 x i32> %328
  %438 = icmp slt <4 x i32> %437, %331
  %439 = select <4 x i1> %438, <4 x i32> %437, <4 x i32> %331
  store <4 x i32> %435, <4 x i32>* %201, align 16
  store <4 x i32> %439, <4 x i32>* %215, align 16
  %440 = add <4 x i32> %318, %308
  %441 = sub <4 x i32> %308, %318
  %442 = icmp sgt <4 x i32> %440, %328
  %443 = select <4 x i1> %442, <4 x i32> %440, <4 x i32> %328
  %444 = icmp slt <4 x i32> %443, %331
  %445 = select <4 x i1> %444, <4 x i32> %443, <4 x i32> %331
  %446 = icmp sgt <4 x i32> %441, %328
  %447 = select <4 x i1> %446, <4 x i32> %441, <4 x i32> %328
  %448 = icmp slt <4 x i32> %447, %331
  %449 = select <4 x i1> %448, <4 x i32> %447, <4 x i32> %331
  store <4 x i32> %445, <4 x i32>* %246, align 16
  store <4 x i32> %449, <4 x i32>* %248, align 16
  %450 = load <4 x i32>, <4 x i32>* %206, align 16
  %451 = load <4 x i32>, <4 x i32>* %210, align 16
  %452 = add <4 x i32> %451, %450
  %453 = sub <4 x i32> %450, %451
  %454 = icmp sgt <4 x i32> %452, %328
  %455 = select <4 x i1> %454, <4 x i32> %452, <4 x i32> %328
  %456 = icmp slt <4 x i32> %455, %331
  %457 = select <4 x i1> %456, <4 x i32> %455, <4 x i32> %331
  %458 = icmp sgt <4 x i32> %453, %328
  %459 = select <4 x i1> %458, <4 x i32> %453, <4 x i32> %328
  %460 = icmp slt <4 x i32> %459, %331
  %461 = select <4 x i1> %460, <4 x i32> %459, <4 x i32> %331
  store <4 x i32> %457, <4 x i32>* %206, align 16
  store <4 x i32> %461, <4 x i32>* %210, align 16
  %462 = add <4 x i32> %323, %313
  %463 = sub <4 x i32> %313, %323
  %464 = icmp sgt <4 x i32> %462, %328
  %465 = select <4 x i1> %464, <4 x i32> %462, <4 x i32> %328
  %466 = icmp slt <4 x i32> %465, %331
  %467 = select <4 x i1> %466, <4 x i32> %465, <4 x i32> %331
  %468 = icmp sgt <4 x i32> %463, %328
  %469 = select <4 x i1> %468, <4 x i32> %463, <4 x i32> %328
  %470 = icmp slt <4 x i32> %469, %331
  %471 = select <4 x i1> %470, <4 x i32> %469, <4 x i32> %331
  store <4 x i32> %467, <4 x i32>* %252, align 16
  store <4 x i32> %471, <4 x i32>* %250, align 16
  %472 = mul <4 x i32> %347, %111
  %473 = mul <4 x i32> %413, %101
  %474 = add <4 x i32> %472, %115
  %475 = add <4 x i32> %474, %473
  %476 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %475, i32 %2) #8
  %477 = mul <4 x i32> %347, %101
  %478 = mul <4 x i32> %413, %108
  %479 = add <4 x i32> %477, %115
  %480 = add <4 x i32> %479, %478
  %481 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %480, i32 %2) #8
  store <4 x i32> %481, <4 x i32>* %232, align 16
  store <4 x i32> %476, <4 x i32>* %222, align 16
  %482 = mul <4 x i32> %337, %111
  %483 = mul <4 x i32> %403, %101
  %484 = add <4 x i32> %482, %115
  %485 = add <4 x i32> %484, %483
  %486 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %485, i32 %2) #8
  %487 = mul <4 x i32> %337, %101
  %488 = mul <4 x i32> %403, %108
  %489 = add <4 x i32> %487, %115
  %490 = add <4 x i32> %489, %488
  %491 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %490, i32 %2) #8
  store <4 x i32> %491, <4 x i32>* %174, align 16
  store <4 x i32> %486, <4 x i32>* %179, align 16
  %492 = mul <4 x i32> %359, %104
  %493 = mul <4 x i32> %381, %111
  %494 = add <4 x i32> %492, %115
  %495 = add <4 x i32> %494, %493
  %496 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %495, i32 %2) #8
  %497 = mul <4 x i32> %359, %111
  %498 = mul <4 x i32> %381, %101
  %499 = add <4 x i32> %497, %115
  %500 = add <4 x i32> %499, %498
  %501 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %500, i32 %2) #8
  store <4 x i32> %501, <4 x i32>* %188, align 16
  store <4 x i32> %496, <4 x i32>* %183, align 16
  %502 = mul <4 x i32> %369, %104
  %503 = mul <4 x i32> %391, %111
  %504 = add <4 x i32> %502, %115
  %505 = add <4 x i32> %504, %503
  %506 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %505, i32 %2) #8
  %507 = mul <4 x i32> %369, %111
  %508 = mul <4 x i32> %391, %101
  %509 = add <4 x i32> %507, %115
  %510 = add <4 x i32> %509, %508
  %511 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %510, i32 %2) #8
  store <4 x i32> %511, <4 x i32>* %230, align 16
  store <4 x i32> %506, <4 x i32>* %224, align 16
  %512 = load <4 x i32>, <4 x i32>* %293, align 16
  %513 = load <4 x i32>, <4 x i32>* %241, align 16
  %514 = add <4 x i32> %513, %512
  %515 = sub <4 x i32> %512, %513
  %516 = icmp sgt <4 x i32> %514, %328
  %517 = select <4 x i1> %516, <4 x i32> %514, <4 x i32> %328
  %518 = icmp slt <4 x i32> %517, %331
  %519 = select <4 x i1> %518, <4 x i32> %517, <4 x i32> %331
  %520 = icmp sgt <4 x i32> %515, %328
  %521 = select <4 x i1> %520, <4 x i32> %515, <4 x i32> %328
  %522 = icmp slt <4 x i32> %521, %331
  %523 = select <4 x i1> %522, <4 x i32> %521, <4 x i32> %331
  store <4 x i32> %519, <4 x i32>* %293, align 16
  store <4 x i32> %523, <4 x i32>* %241, align 16
  %524 = load <4 x i32>, <4 x i32>* %299, align 16
  %525 = add <4 x i32> %524, %427
  %526 = sub <4 x i32> %524, %427
  %527 = icmp sgt <4 x i32> %525, %328
  %528 = select <4 x i1> %527, <4 x i32> %525, <4 x i32> %328
  %529 = icmp slt <4 x i32> %528, %331
  %530 = select <4 x i1> %529, <4 x i32> %528, <4 x i32> %331
  %531 = icmp sgt <4 x i32> %526, %328
  %532 = select <4 x i1> %531, <4 x i32> %526, <4 x i32> %328
  %533 = icmp slt <4 x i32> %532, %331
  %534 = select <4 x i1> %533, <4 x i32> %532, <4 x i32> %331
  store <4 x i32> %530, <4 x i32>* %299, align 16
  store <4 x i32> %534, <4 x i32>* %303, align 16
  %535 = load <4 x i32>, <4 x i32>* %417, align 16
  %536 = add <4 x i32> %535, %424
  %537 = sub <4 x i32> %535, %424
  %538 = icmp sgt <4 x i32> %536, %328
  %539 = select <4 x i1> %538, <4 x i32> %536, <4 x i32> %328
  %540 = icmp slt <4 x i32> %539, %331
  %541 = select <4 x i1> %540, <4 x i32> %539, <4 x i32> %331
  %542 = icmp sgt <4 x i32> %537, %328
  %543 = select <4 x i1> %542, <4 x i32> %537, <4 x i32> %328
  %544 = icmp slt <4 x i32> %543, %331
  %545 = select <4 x i1> %544, <4 x i32> %543, <4 x i32> %331
  store <4 x i32> %541, <4 x i32>* %417, align 16
  store <4 x i32> %545, <4 x i32>* %301, align 16
  %546 = load <4 x i32>, <4 x i32>* %415, align 16
  %547 = load <4 x i32>, <4 x i32>* %235, align 16
  %548 = add <4 x i32> %547, %546
  %549 = sub <4 x i32> %546, %547
  %550 = icmp sgt <4 x i32> %548, %328
  %551 = select <4 x i1> %550, <4 x i32> %548, <4 x i32> %328
  %552 = icmp slt <4 x i32> %551, %331
  %553 = select <4 x i1> %552, <4 x i32> %551, <4 x i32> %331
  %554 = icmp sgt <4 x i32> %549, %328
  %555 = select <4 x i1> %554, <4 x i32> %549, <4 x i32> %328
  %556 = icmp slt <4 x i32> %555, %331
  %557 = select <4 x i1> %556, <4 x i32> %555, <4 x i32> %331
  store <4 x i32> %553, <4 x i32>* %415, align 16
  store <4 x i32> %557, <4 x i32>* %235, align 16
  %558 = mul <4 x i32> %449, %97
  %559 = mul <4 x i32> %471, %94
  %560 = add <4 x i32> %559, %115
  %561 = add <4 x i32> %560, %558
  %562 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %561, i32 %2) #8
  %563 = mul <4 x i32> %449, %94
  %564 = add <4 x i32> %560, %563
  %565 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %564, i32 %2) #8
  store <4 x i32> %565, <4 x i32>* %250, align 16
  store <4 x i32> %562, <4 x i32>* %248, align 16
  %566 = mul <4 x i32> %439, %97
  %567 = mul <4 x i32> %461, %94
  %568 = add <4 x i32> %567, %115
  %569 = add <4 x i32> %568, %566
  %570 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %569, i32 %2) #8
  %571 = mul <4 x i32> %439, %94
  %572 = add <4 x i32> %568, %571
  %573 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %572, i32 %2) #8
  store <4 x i32> %573, <4 x i32>* %210, align 16
  store <4 x i32> %570, <4 x i32>* %215, align 16
  %574 = add <4 x i32> %355, %333
  %575 = sub <4 x i32> %333, %355
  %576 = icmp sgt <4 x i32> %574, %328
  %577 = select <4 x i1> %576, <4 x i32> %574, <4 x i32> %328
  %578 = icmp slt <4 x i32> %577, %331
  %579 = select <4 x i1> %578, <4 x i32> %577, <4 x i32> %331
  %580 = icmp sgt <4 x i32> %575, %328
  %581 = select <4 x i1> %580, <4 x i32> %575, <4 x i32> %328
  %582 = icmp slt <4 x i32> %581, %331
  %583 = select <4 x i1> %582, <4 x i32> %581, <4 x i32> %331
  store <4 x i32> %579, <4 x i32>* %165, align 16
  store <4 x i32> %583, <4 x i32>* %197, align 16
  %584 = add <4 x i32> %365, %343
  %585 = sub <4 x i32> %343, %365
  %586 = icmp sgt <4 x i32> %584, %328
  %587 = select <4 x i1> %586, <4 x i32> %584, <4 x i32> %328
  %588 = icmp slt <4 x i32> %587, %331
  %589 = select <4 x i1> %588, <4 x i32> %587, <4 x i32> %331
  %590 = icmp sgt <4 x i32> %585, %328
  %591 = select <4 x i1> %590, <4 x i32> %585, <4 x i32> %328
  %592 = icmp slt <4 x i32> %591, %331
  %593 = select <4 x i1> %592, <4 x i32> %591, <4 x i32> %331
  store <4 x i32> %589, <4 x i32>* %220, align 16
  store <4 x i32> %593, <4 x i32>* %226, align 16
  %594 = add <4 x i32> %506, %476
  %595 = sub <4 x i32> %476, %506
  %596 = icmp sgt <4 x i32> %594, %328
  %597 = select <4 x i1> %596, <4 x i32> %594, <4 x i32> %328
  %598 = icmp slt <4 x i32> %597, %331
  %599 = select <4 x i1> %598, <4 x i32> %597, <4 x i32> %331
  %600 = icmp sgt <4 x i32> %595, %328
  %601 = select <4 x i1> %600, <4 x i32> %595, <4 x i32> %328
  %602 = icmp slt <4 x i32> %601, %331
  %603 = select <4 x i1> %602, <4 x i32> %601, <4 x i32> %331
  store <4 x i32> %599, <4 x i32>* %222, align 16
  store <4 x i32> %603, <4 x i32>* %224, align 16
  %604 = add <4 x i32> %496, %486
  %605 = sub <4 x i32> %486, %496
  %606 = icmp sgt <4 x i32> %604, %328
  %607 = select <4 x i1> %606, <4 x i32> %604, <4 x i32> %328
  %608 = icmp slt <4 x i32> %607, %331
  %609 = select <4 x i1> %608, <4 x i32> %607, <4 x i32> %331
  %610 = icmp sgt <4 x i32> %605, %328
  %611 = select <4 x i1> %610, <4 x i32> %605, <4 x i32> %328
  %612 = icmp slt <4 x i32> %611, %331
  %613 = select <4 x i1> %612, <4 x i32> %611, <4 x i32> %331
  store <4 x i32> %609, <4 x i32>* %179, align 16
  store <4 x i32> %613, <4 x i32>* %183, align 16
  %614 = add <4 x i32> %399, %377
  %615 = sub <4 x i32> %399, %377
  %616 = icmp sgt <4 x i32> %614, %328
  %617 = select <4 x i1> %616, <4 x i32> %614, <4 x i32> %328
  %618 = icmp slt <4 x i32> %617, %331
  %619 = select <4 x i1> %618, <4 x i32> %617, <4 x i32> %331
  %620 = icmp sgt <4 x i32> %615, %328
  %621 = select <4 x i1> %620, <4 x i32> %615, <4 x i32> %328
  %622 = icmp slt <4 x i32> %621, %331
  %623 = select <4 x i1> %622, <4 x i32> %621, <4 x i32> %331
  store <4 x i32> %619, <4 x i32>* %170, align 16
  store <4 x i32> %623, <4 x i32>* %192, align 16
  %624 = add <4 x i32> %387, %409
  %625 = sub <4 x i32> %409, %387
  %626 = icmp sgt <4 x i32> %624, %328
  %627 = select <4 x i1> %626, <4 x i32> %624, <4 x i32> %328
  %628 = icmp slt <4 x i32> %627, %331
  %629 = select <4 x i1> %628, <4 x i32> %627, <4 x i32> %331
  %630 = icmp sgt <4 x i32> %625, %328
  %631 = select <4 x i1> %630, <4 x i32> %625, <4 x i32> %328
  %632 = icmp slt <4 x i32> %631, %331
  %633 = select <4 x i1> %632, <4 x i32> %631, <4 x i32> %331
  store <4 x i32> %629, <4 x i32>* %234, align 16
  store <4 x i32> %633, <4 x i32>* %228, align 16
  %634 = add <4 x i32> %511, %481
  %635 = sub <4 x i32> %481, %511
  %636 = icmp sgt <4 x i32> %634, %328
  %637 = select <4 x i1> %636, <4 x i32> %634, <4 x i32> %328
  %638 = icmp slt <4 x i32> %637, %331
  %639 = select <4 x i1> %638, <4 x i32> %637, <4 x i32> %331
  %640 = icmp sgt <4 x i32> %635, %328
  %641 = select <4 x i1> %640, <4 x i32> %635, <4 x i32> %328
  %642 = icmp slt <4 x i32> %641, %331
  %643 = select <4 x i1> %642, <4 x i32> %641, <4 x i32> %331
  store <4 x i32> %639, <4 x i32>* %232, align 16
  store <4 x i32> %643, <4 x i32>* %230, align 16
  %644 = add <4 x i32> %501, %491
  %645 = sub <4 x i32> %491, %501
  %646 = icmp sgt <4 x i32> %644, %328
  %647 = select <4 x i1> %646, <4 x i32> %644, <4 x i32> %328
  %648 = icmp slt <4 x i32> %647, %331
  %649 = select <4 x i1> %648, <4 x i32> %647, <4 x i32> %331
  %650 = icmp sgt <4 x i32> %645, %328
  %651 = select <4 x i1> %650, <4 x i32> %645, <4 x i32> %328
  %652 = icmp slt <4 x i32> %651, %331
  %653 = select <4 x i1> %652, <4 x i32> %651, <4 x i32> %331
  store <4 x i32> %649, <4 x i32>* %174, align 16
  store <4 x i32> %653, <4 x i32>* %188, align 16
  %654 = add <4 x i32> %519, %457
  %655 = sub <4 x i32> %519, %457
  %656 = icmp sgt <4 x i32> %654, %328
  %657 = select <4 x i1> %656, <4 x i32> %654, <4 x i32> %328
  %658 = icmp slt <4 x i32> %657, %331
  %659 = select <4 x i1> %658, <4 x i32> %657, <4 x i32> %331
  %660 = icmp sgt <4 x i32> %655, %328
  %661 = select <4 x i1> %660, <4 x i32> %655, <4 x i32> %328
  %662 = icmp slt <4 x i32> %661, %331
  %663 = select <4 x i1> %662, <4 x i32> %661, <4 x i32> %331
  store <4 x i32> %659, <4 x i32>* %293, align 16
  store <4 x i32> %663, <4 x i32>* %206, align 16
  %664 = add <4 x i32> %530, %467
  %665 = sub <4 x i32> %530, %467
  %666 = icmp sgt <4 x i32> %664, %328
  %667 = select <4 x i1> %666, <4 x i32> %664, <4 x i32> %328
  %668 = icmp slt <4 x i32> %667, %331
  %669 = select <4 x i1> %668, <4 x i32> %667, <4 x i32> %331
  %670 = icmp sgt <4 x i32> %665, %328
  %671 = select <4 x i1> %670, <4 x i32> %665, <4 x i32> %328
  %672 = icmp slt <4 x i32> %671, %331
  %673 = select <4 x i1> %672, <4 x i32> %671, <4 x i32> %331
  store <4 x i32> %669, <4 x i32>* %299, align 16
  store <4 x i32> %673, <4 x i32>* %252, align 16
  %674 = add <4 x i32> %565, %541
  %675 = sub <4 x i32> %541, %565
  %676 = icmp sgt <4 x i32> %674, %328
  %677 = select <4 x i1> %676, <4 x i32> %674, <4 x i32> %328
  %678 = icmp slt <4 x i32> %677, %331
  %679 = select <4 x i1> %678, <4 x i32> %677, <4 x i32> %331
  %680 = icmp sgt <4 x i32> %675, %328
  %681 = select <4 x i1> %680, <4 x i32> %675, <4 x i32> %328
  %682 = icmp slt <4 x i32> %681, %331
  %683 = select <4 x i1> %682, <4 x i32> %681, <4 x i32> %331
  store <4 x i32> %679, <4 x i32>* %417, align 16
  store <4 x i32> %683, <4 x i32>* %250, align 16
  %684 = add <4 x i32> %573, %553
  %685 = sub <4 x i32> %553, %573
  %686 = icmp sgt <4 x i32> %684, %328
  %687 = select <4 x i1> %686, <4 x i32> %684, <4 x i32> %328
  %688 = icmp slt <4 x i32> %687, %331
  %689 = select <4 x i1> %688, <4 x i32> %687, <4 x i32> %331
  %690 = icmp sgt <4 x i32> %685, %328
  %691 = select <4 x i1> %690, <4 x i32> %685, <4 x i32> %328
  %692 = icmp slt <4 x i32> %691, %331
  %693 = select <4 x i1> %692, <4 x i32> %691, <4 x i32> %331
  store <4 x i32> %689, <4 x i32>* %415, align 16
  store <4 x i32> %693, <4 x i32>* %210, align 16
  %694 = add <4 x i32> %570, %557
  %695 = sub <4 x i32> %557, %570
  %696 = icmp sgt <4 x i32> %694, %328
  %697 = select <4 x i1> %696, <4 x i32> %694, <4 x i32> %328
  %698 = icmp slt <4 x i32> %697, %331
  %699 = select <4 x i1> %698, <4 x i32> %697, <4 x i32> %331
  %700 = icmp sgt <4 x i32> %695, %328
  %701 = select <4 x i1> %700, <4 x i32> %695, <4 x i32> %328
  %702 = icmp slt <4 x i32> %701, %331
  %703 = select <4 x i1> %702, <4 x i32> %701, <4 x i32> %331
  store <4 x i32> %699, <4 x i32>* %235, align 16
  store <4 x i32> %703, <4 x i32>* %215, align 16
  %704 = add <4 x i32> %562, %545
  %705 = sub <4 x i32> %545, %562
  %706 = icmp sgt <4 x i32> %704, %328
  %707 = select <4 x i1> %706, <4 x i32> %704, <4 x i32> %328
  %708 = icmp slt <4 x i32> %707, %331
  %709 = select <4 x i1> %708, <4 x i32> %707, <4 x i32> %331
  %710 = icmp sgt <4 x i32> %705, %328
  %711 = select <4 x i1> %710, <4 x i32> %705, <4 x i32> %328
  %712 = icmp slt <4 x i32> %711, %331
  %713 = select <4 x i1> %712, <4 x i32> %711, <4 x i32> %331
  store <4 x i32> %709, <4 x i32>* %301, align 16
  store <4 x i32> %713, <4 x i32>* %248, align 16
  %714 = add <4 x i32> %534, %445
  %715 = sub <4 x i32> %534, %445
  %716 = icmp sgt <4 x i32> %714, %328
  %717 = select <4 x i1> %716, <4 x i32> %714, <4 x i32> %328
  %718 = icmp slt <4 x i32> %717, %331
  %719 = select <4 x i1> %718, <4 x i32> %717, <4 x i32> %331
  %720 = icmp sgt <4 x i32> %715, %328
  %721 = select <4 x i1> %720, <4 x i32> %715, <4 x i32> %328
  %722 = icmp slt <4 x i32> %721, %331
  %723 = select <4 x i1> %722, <4 x i32> %721, <4 x i32> %331
  store <4 x i32> %719, <4 x i32>* %303, align 16
  store <4 x i32> %723, <4 x i32>* %246, align 16
  %724 = add <4 x i32> %523, %435
  %725 = sub <4 x i32> %523, %435
  %726 = icmp sgt <4 x i32> %724, %328
  %727 = select <4 x i1> %726, <4 x i32> %724, <4 x i32> %328
  %728 = icmp slt <4 x i32> %727, %331
  %729 = select <4 x i1> %728, <4 x i32> %727, <4 x i32> %331
  %730 = icmp sgt <4 x i32> %725, %328
  %731 = select <4 x i1> %730, <4 x i32> %725, <4 x i32> %328
  %732 = icmp slt <4 x i32> %731, %331
  %733 = select <4 x i1> %732, <4 x i32> %731, <4 x i32> %331
  store <4 x i32> %729, <4 x i32>* %241, align 16
  store <4 x i32> %733, <4 x i32>* %201, align 16
  %734 = mul <4 x i32> %613, %97
  %735 = mul <4 x i32> %653, %94
  %736 = add <4 x i32> %735, %115
  %737 = add <4 x i32> %736, %734
  %738 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %737, i32 %2) #8
  %739 = mul <4 x i32> %613, %94
  %740 = add <4 x i32> %736, %739
  %741 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %740, i32 %2) #8
  store <4 x i32> %741, <4 x i32>* %188, align 16
  store <4 x i32> %738, <4 x i32>* %183, align 16
  %742 = mul <4 x i32> %603, %97
  %743 = mul <4 x i32> %643, %94
  %744 = add <4 x i32> %743, %115
  %745 = add <4 x i32> %744, %742
  %746 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %745, i32 %2) #8
  %747 = mul <4 x i32> %603, %94
  %748 = add <4 x i32> %744, %747
  %749 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %748, i32 %2) #8
  store <4 x i32> %749, <4 x i32>* %230, align 16
  store <4 x i32> %746, <4 x i32>* %224, align 16
  %750 = mul <4 x i32> %593, %97
  %751 = mul <4 x i32> %633, %94
  %752 = add <4 x i32> %751, %115
  %753 = add <4 x i32> %752, %750
  %754 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %753, i32 %2) #8
  %755 = mul <4 x i32> %593, %94
  %756 = add <4 x i32> %752, %755
  %757 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %756, i32 %2) #8
  store <4 x i32> %757, <4 x i32>* %228, align 16
  store <4 x i32> %754, <4 x i32>* %226, align 16
  %758 = mul <4 x i32> %583, %97
  %759 = mul <4 x i32> %623, %94
  %760 = add <4 x i32> %759, %115
  %761 = add <4 x i32> %760, %758
  %762 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %761, i32 %2) #8
  %763 = mul <4 x i32> %583, %94
  %764 = add <4 x i32> %760, %763
  %765 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %764, i32 %2) #8
  store <4 x i32> %765, <4 x i32>* %192, align 16
  store <4 x i32> %762, <4 x i32>* %197, align 16
  call fastcc void @idct32_stage9_sse4_1(<2 x i64>* nonnull %137, <2 x i64>* %1, i32 %3, i32 %4, i32 %5, <2 x i64>* nonnull %7, <2 x i64>* nonnull %8)
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %133) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %128) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @idct32x32_low16_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>*, i32, i32, i32, i32) #0 {
  %7 = alloca <2 x i64>, align 16
  %8 = alloca <2 x i64>, align 16
  %9 = alloca [32 x <2 x i64>], align 16
  %10 = add nsw i32 %2, -10
  %11 = sext i32 %10 to i64
  %12 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 62
  %13 = load i32, i32* %12, align 8
  %14 = insertelement <4 x i32> undef, i32 %13, i32 0
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> zeroinitializer
  %16 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 30
  %17 = load i32, i32* %16, align 8
  %18 = insertelement <4 x i32> undef, i32 %17, i32 0
  %19 = shufflevector <4 x i32> %18, <4 x i32> undef, <4 x i32> zeroinitializer
  %20 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 46
  %21 = load i32, i32* %20, align 8
  %22 = insertelement <4 x i32> undef, i32 %21, i32 0
  %23 = shufflevector <4 x i32> %22, <4 x i32> undef, <4 x i32> zeroinitializer
  %24 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 14
  %25 = load i32, i32* %24, align 8
  %26 = insertelement <4 x i32> undef, i32 %25, i32 0
  %27 = shufflevector <4 x i32> %26, <4 x i32> undef, <4 x i32> zeroinitializer
  %28 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 54
  %29 = load i32, i32* %28, align 8
  %30 = insertelement <4 x i32> undef, i32 %29, i32 0
  %31 = shufflevector <4 x i32> %30, <4 x i32> undef, <4 x i32> zeroinitializer
  %32 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 22
  %33 = load i32, i32* %32, align 8
  %34 = insertelement <4 x i32> undef, i32 %33, i32 0
  %35 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> zeroinitializer
  %36 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 38
  %37 = load i32, i32* %36, align 8
  %38 = insertelement <4 x i32> undef, i32 %37, i32 0
  %39 = shufflevector <4 x i32> %38, <4 x i32> undef, <4 x i32> zeroinitializer
  %40 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 6
  %41 = load i32, i32* %40, align 8
  %42 = insertelement <4 x i32> undef, i32 %41, i32 0
  %43 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> zeroinitializer
  %44 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 26
  %45 = load i32, i32* %44, align 8
  %46 = insertelement <4 x i32> undef, i32 %45, i32 0
  %47 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> zeroinitializer
  %48 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 10
  %49 = load i32, i32* %48, align 8
  %50 = insertelement <4 x i32> undef, i32 %49, i32 0
  %51 = shufflevector <4 x i32> %50, <4 x i32> undef, <4 x i32> zeroinitializer
  %52 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 18
  %53 = load i32, i32* %52, align 8
  %54 = insertelement <4 x i32> undef, i32 %53, i32 0
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> zeroinitializer
  %56 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 2
  %57 = load i32, i32* %56, align 8
  %58 = insertelement <4 x i32> undef, i32 %57, i32 0
  %59 = shufflevector <4 x i32> %58, <4 x i32> undef, <4 x i32> zeroinitializer
  %60 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 58
  %61 = load i32, i32* %60, align 8
  %62 = sub nsw i32 0, %61
  %63 = insertelement <4 x i32> undef, i32 %62, i32 0
  %64 = shufflevector <4 x i32> %63, <4 x i32> undef, <4 x i32> zeroinitializer
  %65 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 42
  %66 = load i32, i32* %65, align 8
  %67 = sub nsw i32 0, %66
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 50
  %71 = load i32, i32* %70, align 8
  %72 = sub nsw i32 0, %71
  %73 = insertelement <4 x i32> undef, i32 %72, i32 0
  %74 = shufflevector <4 x i32> %73, <4 x i32> undef, <4 x i32> zeroinitializer
  %75 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 34
  %76 = load i32, i32* %75, align 8
  %77 = sub nsw i32 0, %76
  %78 = insertelement <4 x i32> undef, i32 %77, i32 0
  %79 = shufflevector <4 x i32> %78, <4 x i32> undef, <4 x i32> zeroinitializer
  %80 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 60
  %81 = load i32, i32* %80, align 16
  %82 = insertelement <4 x i32> undef, i32 %81, i32 0
  %83 = shufflevector <4 x i32> %82, <4 x i32> undef, <4 x i32> zeroinitializer
  %84 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 28
  %85 = load i32, i32* %84, align 16
  %86 = insertelement <4 x i32> undef, i32 %85, i32 0
  %87 = shufflevector <4 x i32> %86, <4 x i32> undef, <4 x i32> zeroinitializer
  %88 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 44
  %89 = load i32, i32* %88, align 16
  %90 = insertelement <4 x i32> undef, i32 %89, i32 0
  %91 = shufflevector <4 x i32> %90, <4 x i32> undef, <4 x i32> zeroinitializer
  %92 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 12
  %93 = load i32, i32* %92, align 16
  %94 = insertelement <4 x i32> undef, i32 %93, i32 0
  %95 = shufflevector <4 x i32> %94, <4 x i32> undef, <4 x i32> zeroinitializer
  %96 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 20
  %97 = load i32, i32* %96, align 16
  %98 = insertelement <4 x i32> undef, i32 %97, i32 0
  %99 = shufflevector <4 x i32> %98, <4 x i32> undef, <4 x i32> zeroinitializer
  %100 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 4
  %101 = load i32, i32* %100, align 16
  %102 = insertelement <4 x i32> undef, i32 %101, i32 0
  %103 = shufflevector <4 x i32> %102, <4 x i32> undef, <4 x i32> zeroinitializer
  %104 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 52
  %105 = load i32, i32* %104, align 16
  %106 = sub nsw i32 0, %105
  %107 = insertelement <4 x i32> undef, i32 %106, i32 0
  %108 = shufflevector <4 x i32> %107, <4 x i32> undef, <4 x i32> zeroinitializer
  %109 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 36
  %110 = load i32, i32* %109, align 16
  %111 = sub nsw i32 0, %110
  %112 = insertelement <4 x i32> undef, i32 %111, i32 0
  %113 = shufflevector <4 x i32> %112, <4 x i32> undef, <4 x i32> zeroinitializer
  %114 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 56
  %115 = load i32, i32* %114, align 16
  %116 = insertelement <4 x i32> undef, i32 %115, i32 0
  %117 = shufflevector <4 x i32> %116, <4 x i32> undef, <4 x i32> zeroinitializer
  %118 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 24
  %119 = load i32, i32* %118, align 16
  %120 = insertelement <4 x i32> undef, i32 %119, i32 0
  %121 = shufflevector <4 x i32> %120, <4 x i32> undef, <4 x i32> zeroinitializer
  %122 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 40
  %123 = load i32, i32* %122, align 16
  %124 = insertelement <4 x i32> undef, i32 %123, i32 0
  %125 = shufflevector <4 x i32> %124, <4 x i32> undef, <4 x i32> zeroinitializer
  %126 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 8
  %127 = load i32, i32* %126, align 16
  %128 = insertelement <4 x i32> undef, i32 %127, i32 0
  %129 = shufflevector <4 x i32> %128, <4 x i32> undef, <4 x i32> zeroinitializer
  %130 = sub nsw i32 0, %123
  %131 = insertelement <4 x i32> undef, i32 %130, i32 0
  %132 = shufflevector <4 x i32> %131, <4 x i32> undef, <4 x i32> zeroinitializer
  %133 = sub nsw i32 0, %127
  %134 = insertelement <4 x i32> undef, i32 %133, i32 0
  %135 = shufflevector <4 x i32> %134, <4 x i32> undef, <4 x i32> zeroinitializer
  %136 = sub nsw i32 0, %115
  %137 = insertelement <4 x i32> undef, i32 %136, i32 0
  %138 = shufflevector <4 x i32> %137, <4 x i32> undef, <4 x i32> zeroinitializer
  %139 = sub nsw i32 0, %119
  %140 = insertelement <4 x i32> undef, i32 %139, i32 0
  %141 = shufflevector <4 x i32> %140, <4 x i32> undef, <4 x i32> zeroinitializer
  %142 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 32
  %143 = load i32, i32* %142, align 16
  %144 = insertelement <4 x i32> undef, i32 %143, i32 0
  %145 = shufflevector <4 x i32> %144, <4 x i32> undef, <4 x i32> zeroinitializer
  %146 = sub nsw i32 0, %143
  %147 = insertelement <4 x i32> undef, i32 %146, i32 0
  %148 = shufflevector <4 x i32> %147, <4 x i32> undef, <4 x i32> zeroinitializer
  %149 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 48
  %150 = load i32, i32* %149, align 16
  %151 = insertelement <4 x i32> undef, i32 %150, i32 0
  %152 = shufflevector <4 x i32> %151, <4 x i32> undef, <4 x i32> zeroinitializer
  %153 = sub nsw i32 0, %150
  %154 = insertelement <4 x i32> undef, i32 %153, i32 0
  %155 = shufflevector <4 x i32> %154, <4 x i32> undef, <4 x i32> zeroinitializer
  %156 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %11, i64 16
  %157 = load i32, i32* %156, align 16
  %158 = insertelement <4 x i32> undef, i32 %157, i32 0
  %159 = shufflevector <4 x i32> %158, <4 x i32> undef, <4 x i32> zeroinitializer
  %160 = sub nsw i32 0, %157
  %161 = insertelement <4 x i32> undef, i32 %160, i32 0
  %162 = shufflevector <4 x i32> %161, <4 x i32> undef, <4 x i32> zeroinitializer
  %163 = add nsw i32 %2, -1
  %164 = shl i32 1, %163
  %165 = insertelement <4 x i32> undef, i32 %164, i32 0
  %166 = shufflevector <4 x i32> %165, <4 x i32> undef, <4 x i32> zeroinitializer
  %167 = icmp eq i32 %3, 0
  %168 = select i1 %167, i32 8, i32 6
  %169 = add nsw i32 %168, %4
  %170 = icmp slt i32 %169, 16
  %171 = add i32 %169, -1
  %172 = bitcast <2 x i64>* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %172) #8
  %173 = shl i32 1, %171
  %174 = select i1 %170, i32 32768, i32 %173
  %175 = sub nsw i32 0, %174
  %176 = insertelement <4 x i32> undef, i32 %175, i32 0
  %177 = shufflevector <4 x i32> %176, <4 x i32> undef, <4 x i32> zeroinitializer
  %178 = bitcast <2 x i64>* %7 to <4 x i32>*
  store <4 x i32> %177, <4 x i32>* %178, align 16
  %179 = bitcast <2 x i64>* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %179) #8
  %180 = add nsw i32 %174, -1
  %181 = insertelement <4 x i32> undef, i32 %180, i32 0
  %182 = shufflevector <4 x i32> %181, <4 x i32> undef, <4 x i32> zeroinitializer
  %183 = bitcast <2 x i64>* %8 to <4 x i32>*
  store <4 x i32> %182, <4 x i32>* %183, align 16
  %184 = bitcast [32 x <2 x i64>]* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %184) #8
  %185 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 1
  %186 = bitcast <2 x i64>* %185 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %186, i8 -86, i64 432, i1 false)
  %187 = load <2 x i64>, <2 x i64>* %0, align 16
  %188 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 0
  store <2 x i64> %187, <2 x i64>* %188, align 16
  %189 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %190 = load <2 x i64>, <2 x i64>* %189, align 16
  %191 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 2
  store <2 x i64> %190, <2 x i64>* %191, align 16
  %192 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %193 = load <2 x i64>, <2 x i64>* %192, align 16
  %194 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 4
  store <2 x i64> %193, <2 x i64>* %194, align 16
  %195 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %196 = load <2 x i64>, <2 x i64>* %195, align 16
  %197 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 6
  store <2 x i64> %196, <2 x i64>* %197, align 16
  %198 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %199 = load <2 x i64>, <2 x i64>* %198, align 16
  %200 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 8
  store <2 x i64> %199, <2 x i64>* %200, align 16
  %201 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %202 = load <2 x i64>, <2 x i64>* %201, align 16
  %203 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 10
  store <2 x i64> %202, <2 x i64>* %203, align 16
  %204 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %205 = load <2 x i64>, <2 x i64>* %204, align 16
  %206 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 12
  store <2 x i64> %205, <2 x i64>* %206, align 16
  %207 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %208 = load <2 x i64>, <2 x i64>* %207, align 16
  %209 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 14
  store <2 x i64> %208, <2 x i64>* %209, align 16
  %210 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %211 = bitcast <2 x i64>* %210 to <4 x i32>*
  %212 = load <4 x i32>, <4 x i32>* %211, align 16
  %213 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 16
  %214 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %215 = bitcast <2 x i64>* %214 to <4 x i32>*
  %216 = load <4 x i32>, <4 x i32>* %215, align 16
  %217 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 18
  %218 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %219 = bitcast <2 x i64>* %218 to <4 x i32>*
  %220 = load <4 x i32>, <4 x i32>* %219, align 16
  %221 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 20
  %222 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %223 = bitcast <2 x i64>* %222 to <4 x i32>*
  %224 = load <4 x i32>, <4 x i32>* %223, align 16
  %225 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 22
  %226 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %227 = load <2 x i64>, <2 x i64>* %226, align 16
  %228 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 24
  store <2 x i64> %227, <2 x i64>* %228, align 16
  %229 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %230 = bitcast <2 x i64>* %229 to <4 x i32>*
  %231 = load <4 x i32>, <4 x i32>* %230, align 16
  %232 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 26
  %233 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %234 = bitcast <2 x i64>* %233 to <4 x i32>*
  %235 = load <4 x i32>, <4 x i32>* %234, align 16
  %236 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 28
  %237 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %238 = bitcast <2 x i64>* %237 to <4 x i32>*
  %239 = load <4 x i32>, <4 x i32>* %238, align 16
  %240 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 30
  %241 = bitcast <2 x i64>* %213 to <4 x i32>*
  %242 = mul <4 x i32> %59, %212
  %243 = add <4 x i32> %242, %166
  %244 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %243, i32 %2) #8
  %245 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 31
  %246 = bitcast <2 x i64>* %245 to <4 x i32>*
  store <4 x i32> %244, <4 x i32>* %246, align 16
  %247 = mul <4 x i32> %15, %212
  %248 = add <4 x i32> %247, %166
  %249 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %248, i32 %2) #8
  store <4 x i32> %249, <4 x i32>* %241, align 16
  %250 = bitcast <2 x i64>* %240 to <4 x i32>*
  %251 = mul <4 x i32> %79, %239
  %252 = add <4 x i32> %251, %166
  %253 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %252, i32 %2) #8
  %254 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 17
  %255 = bitcast <2 x i64>* %254 to <4 x i32>*
  store <4 x i32> %253, <4 x i32>* %255, align 16
  %256 = mul <4 x i32> %19, %239
  %257 = add <4 x i32> %256, %166
  %258 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %257, i32 %2) #8
  store <4 x i32> %258, <4 x i32>* %250, align 16
  %259 = bitcast <2 x i64>* %217 to <4 x i32>*
  %260 = mul <4 x i32> %55, %216
  %261 = add <4 x i32> %260, %166
  %262 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %261, i32 %2) #8
  %263 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 29
  %264 = bitcast <2 x i64>* %263 to <4 x i32>*
  store <4 x i32> %262, <4 x i32>* %264, align 16
  %265 = mul <4 x i32> %23, %216
  %266 = add <4 x i32> %265, %166
  %267 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %266, i32 %2) #8
  store <4 x i32> %267, <4 x i32>* %259, align 16
  %268 = bitcast <2 x i64>* %236 to <4 x i32>*
  %269 = mul <4 x i32> %74, %235
  %270 = add <4 x i32> %269, %166
  %271 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %270, i32 %2) #8
  %272 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 19
  %273 = bitcast <2 x i64>* %272 to <4 x i32>*
  store <4 x i32> %271, <4 x i32>* %273, align 16
  %274 = mul <4 x i32> %27, %235
  %275 = add <4 x i32> %274, %166
  %276 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %275, i32 %2) #8
  store <4 x i32> %276, <4 x i32>* %268, align 16
  %277 = bitcast <2 x i64>* %221 to <4 x i32>*
  %278 = mul <4 x i32> %51, %220
  %279 = add <4 x i32> %278, %166
  %280 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %279, i32 %2) #8
  %281 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 27
  %282 = bitcast <2 x i64>* %281 to <4 x i32>*
  store <4 x i32> %280, <4 x i32>* %282, align 16
  %283 = mul <4 x i32> %31, %220
  %284 = add <4 x i32> %283, %166
  %285 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %284, i32 %2) #8
  store <4 x i32> %285, <4 x i32>* %277, align 16
  %286 = bitcast <2 x i64>* %232 to <4 x i32>*
  %287 = mul <4 x i32> %69, %231
  %288 = add <4 x i32> %287, %166
  %289 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %288, i32 %2) #8
  %290 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 21
  %291 = bitcast <2 x i64>* %290 to <4 x i32>*
  store <4 x i32> %289, <4 x i32>* %291, align 16
  %292 = mul <4 x i32> %35, %231
  %293 = add <4 x i32> %292, %166
  %294 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %293, i32 %2) #8
  store <4 x i32> %294, <4 x i32>* %286, align 16
  %295 = bitcast <2 x i64>* %225 to <4 x i32>*
  %296 = mul <4 x i32> %47, %224
  %297 = add <4 x i32> %296, %166
  %298 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %297, i32 %2) #8
  %299 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 25
  %300 = bitcast <2 x i64>* %299 to <4 x i32>*
  store <4 x i32> %298, <4 x i32>* %300, align 16
  %301 = mul <4 x i32> %39, %224
  %302 = add <4 x i32> %301, %166
  %303 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %302, i32 %2) #8
  store <4 x i32> %303, <4 x i32>* %295, align 16
  %304 = bitcast <2 x i64>* %228 to <4 x i32>*
  %305 = load <4 x i32>, <4 x i32>* %304, align 16
  %306 = mul <4 x i32> %305, %64
  %307 = add <4 x i32> %306, %166
  %308 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %307, i32 %2) #8
  %309 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 23
  %310 = bitcast <2 x i64>* %309 to <4 x i32>*
  store <4 x i32> %308, <4 x i32>* %310, align 16
  %311 = mul <4 x i32> %305, %43
  %312 = add <4 x i32> %311, %166
  %313 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %312, i32 %2) #8
  store <4 x i32> %313, <4 x i32>* %304, align 16
  %314 = bitcast <2 x i64>* %200 to <4 x i32>*
  %315 = load <4 x i32>, <4 x i32>* %314, align 16
  %316 = mul <4 x i32> %315, %103
  %317 = add <4 x i32> %316, %166
  %318 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %317, i32 %2) #8
  %319 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 15
  %320 = bitcast <2 x i64>* %319 to <4 x i32>*
  store <4 x i32> %318, <4 x i32>* %320, align 16
  %321 = mul <4 x i32> %315, %83
  %322 = add <4 x i32> %321, %166
  %323 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %322, i32 %2) #8
  store <4 x i32> %323, <4 x i32>* %314, align 16
  %324 = bitcast <2 x i64>* %209 to <4 x i32>*
  %325 = load <4 x i32>, <4 x i32>* %324, align 16
  %326 = mul <4 x i32> %325, %113
  %327 = add <4 x i32> %326, %166
  %328 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %327, i32 %2) #8
  %329 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 9
  %330 = bitcast <2 x i64>* %329 to <4 x i32>*
  store <4 x i32> %328, <4 x i32>* %330, align 16
  %331 = mul <4 x i32> %325, %87
  %332 = add <4 x i32> %331, %166
  %333 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %332, i32 %2) #8
  store <4 x i32> %333, <4 x i32>* %324, align 16
  %334 = bitcast <2 x i64>* %203 to <4 x i32>*
  %335 = load <4 x i32>, <4 x i32>* %334, align 16
  %336 = mul <4 x i32> %335, %99
  %337 = add <4 x i32> %336, %166
  %338 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %337, i32 %2) #8
  %339 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 13
  %340 = bitcast <2 x i64>* %339 to <4 x i32>*
  store <4 x i32> %338, <4 x i32>* %340, align 16
  %341 = mul <4 x i32> %335, %91
  %342 = add <4 x i32> %341, %166
  %343 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %342, i32 %2) #8
  store <4 x i32> %343, <4 x i32>* %334, align 16
  %344 = bitcast <2 x i64>* %206 to <4 x i32>*
  %345 = load <4 x i32>, <4 x i32>* %344, align 16
  %346 = mul <4 x i32> %345, %108
  %347 = add <4 x i32> %346, %166
  %348 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %347, i32 %2) #8
  %349 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 11
  %350 = bitcast <2 x i64>* %349 to <4 x i32>*
  store <4 x i32> %348, <4 x i32>* %350, align 16
  %351 = mul <4 x i32> %345, %95
  %352 = add <4 x i32> %351, %166
  %353 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %352, i32 %2) #8
  store <4 x i32> %353, <4 x i32>* %344, align 16
  %354 = add <4 x i32> %253, %249
  %355 = sub <4 x i32> %249, %253
  %356 = load <4 x i32>, <4 x i32>* %178, align 16
  %357 = icmp sgt <4 x i32> %354, %356
  %358 = select <4 x i1> %357, <4 x i32> %354, <4 x i32> %356
  %359 = load <4 x i32>, <4 x i32>* %183, align 16
  %360 = icmp slt <4 x i32> %358, %359
  %361 = select <4 x i1> %360, <4 x i32> %358, <4 x i32> %359
  %362 = icmp sgt <4 x i32> %355, %356
  %363 = select <4 x i1> %362, <4 x i32> %355, <4 x i32> %356
  %364 = icmp slt <4 x i32> %363, %359
  %365 = select <4 x i1> %364, <4 x i32> %363, <4 x i32> %359
  store <4 x i32> %361, <4 x i32>* %241, align 16
  store <4 x i32> %365, <4 x i32>* %255, align 16
  %366 = add <4 x i32> %271, %267
  %367 = sub <4 x i32> %271, %267
  %368 = icmp sgt <4 x i32> %366, %356
  %369 = select <4 x i1> %368, <4 x i32> %366, <4 x i32> %356
  %370 = icmp slt <4 x i32> %369, %359
  %371 = select <4 x i1> %370, <4 x i32> %369, <4 x i32> %359
  %372 = icmp sgt <4 x i32> %367, %356
  %373 = select <4 x i1> %372, <4 x i32> %367, <4 x i32> %356
  %374 = icmp slt <4 x i32> %373, %359
  %375 = select <4 x i1> %374, <4 x i32> %373, <4 x i32> %359
  store <4 x i32> %371, <4 x i32>* %273, align 16
  store <4 x i32> %375, <4 x i32>* %259, align 16
  %376 = add <4 x i32> %289, %285
  %377 = sub <4 x i32> %285, %289
  %378 = icmp sgt <4 x i32> %376, %356
  %379 = select <4 x i1> %378, <4 x i32> %376, <4 x i32> %356
  %380 = icmp slt <4 x i32> %379, %359
  %381 = select <4 x i1> %380, <4 x i32> %379, <4 x i32> %359
  %382 = icmp sgt <4 x i32> %377, %356
  %383 = select <4 x i1> %382, <4 x i32> %377, <4 x i32> %356
  %384 = icmp slt <4 x i32> %383, %359
  %385 = select <4 x i1> %384, <4 x i32> %383, <4 x i32> %359
  store <4 x i32> %381, <4 x i32>* %277, align 16
  store <4 x i32> %385, <4 x i32>* %291, align 16
  %386 = add <4 x i32> %308, %303
  %387 = sub <4 x i32> %308, %303
  %388 = icmp sgt <4 x i32> %386, %356
  %389 = select <4 x i1> %388, <4 x i32> %386, <4 x i32> %356
  %390 = icmp slt <4 x i32> %389, %359
  %391 = select <4 x i1> %390, <4 x i32> %389, <4 x i32> %359
  %392 = icmp sgt <4 x i32> %387, %356
  %393 = select <4 x i1> %392, <4 x i32> %387, <4 x i32> %356
  %394 = icmp slt <4 x i32> %393, %359
  %395 = select <4 x i1> %394, <4 x i32> %393, <4 x i32> %359
  store <4 x i32> %391, <4 x i32>* %310, align 16
  store <4 x i32> %395, <4 x i32>* %295, align 16
  %396 = add <4 x i32> %313, %298
  %397 = sub <4 x i32> %313, %298
  %398 = icmp sgt <4 x i32> %396, %356
  %399 = select <4 x i1> %398, <4 x i32> %396, <4 x i32> %356
  %400 = icmp slt <4 x i32> %399, %359
  %401 = select <4 x i1> %400, <4 x i32> %399, <4 x i32> %359
  %402 = icmp sgt <4 x i32> %397, %356
  %403 = select <4 x i1> %402, <4 x i32> %397, <4 x i32> %356
  %404 = icmp slt <4 x i32> %403, %359
  %405 = select <4 x i1> %404, <4 x i32> %403, <4 x i32> %359
  store <4 x i32> %401, <4 x i32>* %304, align 16
  store <4 x i32> %405, <4 x i32>* %300, align 16
  %406 = add <4 x i32> %294, %280
  %407 = sub <4 x i32> %280, %294
  %408 = icmp sgt <4 x i32> %406, %356
  %409 = select <4 x i1> %408, <4 x i32> %406, <4 x i32> %356
  %410 = icmp slt <4 x i32> %409, %359
  %411 = select <4 x i1> %410, <4 x i32> %409, <4 x i32> %359
  %412 = icmp sgt <4 x i32> %407, %356
  %413 = select <4 x i1> %412, <4 x i32> %407, <4 x i32> %356
  %414 = icmp slt <4 x i32> %413, %359
  %415 = select <4 x i1> %414, <4 x i32> %413, <4 x i32> %359
  store <4 x i32> %411, <4 x i32>* %282, align 16
  store <4 x i32> %415, <4 x i32>* %286, align 16
  %416 = add <4 x i32> %276, %262
  %417 = sub <4 x i32> %276, %262
  %418 = icmp sgt <4 x i32> %416, %356
  %419 = select <4 x i1> %418, <4 x i32> %416, <4 x i32> %356
  %420 = icmp slt <4 x i32> %419, %359
  %421 = select <4 x i1> %420, <4 x i32> %419, <4 x i32> %359
  %422 = icmp sgt <4 x i32> %417, %356
  %423 = select <4 x i1> %422, <4 x i32> %417, <4 x i32> %356
  %424 = icmp slt <4 x i32> %423, %359
  %425 = select <4 x i1> %424, <4 x i32> %423, <4 x i32> %359
  store <4 x i32> %421, <4 x i32>* %268, align 16
  store <4 x i32> %425, <4 x i32>* %264, align 16
  %426 = add <4 x i32> %258, %244
  %427 = sub <4 x i32> %244, %258
  %428 = icmp sgt <4 x i32> %426, %356
  %429 = select <4 x i1> %428, <4 x i32> %426, <4 x i32> %356
  %430 = icmp slt <4 x i32> %429, %359
  %431 = select <4 x i1> %430, <4 x i32> %429, <4 x i32> %359
  %432 = icmp sgt <4 x i32> %427, %356
  %433 = select <4 x i1> %432, <4 x i32> %427, <4 x i32> %356
  %434 = icmp slt <4 x i32> %433, %359
  %435 = select <4 x i1> %434, <4 x i32> %433, <4 x i32> %359
  store <4 x i32> %431, <4 x i32>* %246, align 16
  %436 = bitcast <2 x i64>* %194 to <4 x i32>*
  %437 = load <4 x i32>, <4 x i32>* %436, align 16
  %438 = mul <4 x i32> %437, %129
  %439 = add <4 x i32> %438, %166
  %440 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %439, i32 %2) #8
  %441 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 7
  %442 = bitcast <2 x i64>* %441 to <4 x i32>*
  store <4 x i32> %440, <4 x i32>* %442, align 16
  %443 = mul <4 x i32> %437, %117
  %444 = add <4 x i32> %443, %166
  %445 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %444, i32 %2) #8
  store <4 x i32> %445, <4 x i32>* %436, align 16
  %446 = bitcast <2 x i64>* %197 to <4 x i32>*
  %447 = load <4 x i32>, <4 x i32>* %446, align 16
  %448 = mul <4 x i32> %447, %132
  %449 = add <4 x i32> %448, %166
  %450 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %449, i32 %2) #8
  %451 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 5
  %452 = bitcast <2 x i64>* %451 to <4 x i32>*
  store <4 x i32> %450, <4 x i32>* %452, align 16
  %453 = mul <4 x i32> %447, %121
  %454 = add <4 x i32> %453, %166
  %455 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %454, i32 %2) #8
  store <4 x i32> %455, <4 x i32>* %446, align 16
  %456 = add <4 x i32> %328, %323
  %457 = sub <4 x i32> %323, %328
  %458 = icmp sgt <4 x i32> %456, %356
  %459 = select <4 x i1> %458, <4 x i32> %456, <4 x i32> %356
  %460 = icmp slt <4 x i32> %459, %359
  %461 = select <4 x i1> %460, <4 x i32> %459, <4 x i32> %359
  %462 = icmp sgt <4 x i32> %457, %356
  %463 = select <4 x i1> %462, <4 x i32> %457, <4 x i32> %356
  %464 = icmp slt <4 x i32> %463, %359
  %465 = select <4 x i1> %464, <4 x i32> %463, <4 x i32> %359
  store <4 x i32> %461, <4 x i32>* %314, align 16
  store <4 x i32> %465, <4 x i32>* %330, align 16
  %466 = add <4 x i32> %348, %343
  %467 = sub <4 x i32> %348, %343
  %468 = icmp sgt <4 x i32> %466, %356
  %469 = select <4 x i1> %468, <4 x i32> %466, <4 x i32> %356
  %470 = icmp slt <4 x i32> %469, %359
  %471 = select <4 x i1> %470, <4 x i32> %469, <4 x i32> %359
  %472 = icmp sgt <4 x i32> %467, %356
  %473 = select <4 x i1> %472, <4 x i32> %467, <4 x i32> %356
  %474 = icmp slt <4 x i32> %473, %359
  %475 = select <4 x i1> %474, <4 x i32> %473, <4 x i32> %359
  store <4 x i32> %471, <4 x i32>* %350, align 16
  store <4 x i32> %475, <4 x i32>* %334, align 16
  %476 = add <4 x i32> %353, %338
  %477 = sub <4 x i32> %353, %338
  %478 = icmp sgt <4 x i32> %476, %356
  %479 = select <4 x i1> %478, <4 x i32> %476, <4 x i32> %356
  %480 = icmp slt <4 x i32> %479, %359
  %481 = select <4 x i1> %480, <4 x i32> %479, <4 x i32> %359
  %482 = icmp sgt <4 x i32> %477, %356
  %483 = select <4 x i1> %482, <4 x i32> %477, <4 x i32> %356
  %484 = icmp slt <4 x i32> %483, %359
  %485 = select <4 x i1> %484, <4 x i32> %483, <4 x i32> %359
  store <4 x i32> %481, <4 x i32>* %344, align 16
  store <4 x i32> %485, <4 x i32>* %340, align 16
  %486 = add <4 x i32> %333, %318
  %487 = sub <4 x i32> %318, %333
  %488 = icmp sgt <4 x i32> %486, %356
  %489 = select <4 x i1> %488, <4 x i32> %486, <4 x i32> %356
  %490 = icmp slt <4 x i32> %489, %359
  %491 = select <4 x i1> %490, <4 x i32> %489, <4 x i32> %359
  %492 = icmp sgt <4 x i32> %487, %356
  %493 = select <4 x i1> %492, <4 x i32> %487, <4 x i32> %356
  %494 = icmp slt <4 x i32> %493, %359
  %495 = select <4 x i1> %494, <4 x i32> %493, <4 x i32> %359
  store <4 x i32> %491, <4 x i32>* %320, align 16
  store <4 x i32> %495, <4 x i32>* %324, align 16
  %496 = load <4 x i32>, <4 x i32>* %255, align 16
  %497 = mul <4 x i32> %496, %135
  %498 = mul <4 x i32> %435, %117
  %499 = add <4 x i32> %497, %166
  %500 = add <4 x i32> %499, %498
  %501 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %500, i32 %2) #8
  %502 = mul <4 x i32> %496, %117
  %503 = mul <4 x i32> %435, %129
  %504 = add <4 x i32> %502, %166
  %505 = add <4 x i32> %504, %503
  %506 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %505, i32 %2) #8
  store <4 x i32> %506, <4 x i32>* %250, align 16
  store <4 x i32> %501, <4 x i32>* %255, align 16
  %507 = load <4 x i32>, <4 x i32>* %259, align 16
  %508 = mul <4 x i32> %507, %138
  %509 = load <4 x i32>, <4 x i32>* %264, align 16
  %510 = mul <4 x i32> %509, %135
  %511 = add <4 x i32> %508, %166
  %512 = add <4 x i32> %511, %510
  %513 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %512, i32 %2) #8
  %514 = mul <4 x i32> %507, %135
  %515 = mul <4 x i32> %509, %117
  %516 = add <4 x i32> %514, %166
  %517 = add <4 x i32> %516, %515
  %518 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %517, i32 %2) #8
  store <4 x i32> %518, <4 x i32>* %264, align 16
  store <4 x i32> %513, <4 x i32>* %259, align 16
  %519 = load <4 x i32>, <4 x i32>* %291, align 16
  %520 = mul <4 x i32> %519, %132
  %521 = load <4 x i32>, <4 x i32>* %286, align 16
  %522 = mul <4 x i32> %521, %121
  %523 = add <4 x i32> %520, %166
  %524 = add <4 x i32> %523, %522
  %525 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %524, i32 %2) #8
  %526 = mul <4 x i32> %519, %121
  %527 = mul <4 x i32> %521, %125
  %528 = add <4 x i32> %526, %166
  %529 = add <4 x i32> %528, %527
  %530 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %529, i32 %2) #8
  store <4 x i32> %530, <4 x i32>* %286, align 16
  store <4 x i32> %525, <4 x i32>* %291, align 16
  %531 = load <4 x i32>, <4 x i32>* %295, align 16
  %532 = mul <4 x i32> %531, %141
  %533 = load <4 x i32>, <4 x i32>* %300, align 16
  %534 = mul <4 x i32> %533, %132
  %535 = add <4 x i32> %532, %166
  %536 = add <4 x i32> %535, %534
  %537 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %536, i32 %2) #8
  %538 = mul <4 x i32> %531, %132
  %539 = mul <4 x i32> %533, %121
  %540 = add <4 x i32> %538, %166
  %541 = add <4 x i32> %540, %539
  %542 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %541, i32 %2) #8
  store <4 x i32> %542, <4 x i32>* %300, align 16
  store <4 x i32> %537, <4 x i32>* %295, align 16
  %543 = bitcast [32 x <2 x i64>]* %9 to <4 x i32>*
  %544 = load <4 x i32>, <4 x i32>* %543, align 16
  %545 = mul <4 x i32> %544, %145
  %546 = add <4 x i32> %545, %166
  %547 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %546, i32 %2) #8
  store <4 x i32> %547, <4 x i32>* %543, align 16
  %548 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 1
  %549 = bitcast <2 x i64>* %548 to <4 x i32>*
  store <4 x i32> %547, <4 x i32>* %549, align 16
  %550 = bitcast <2 x i64>* %191 to <4 x i32>*
  %551 = load <4 x i32>, <4 x i32>* %550, align 16
  %552 = mul <4 x i32> %551, %159
  %553 = add <4 x i32> %552, %166
  %554 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %553, i32 %2) #8
  %555 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %9, i64 0, i64 3
  %556 = bitcast <2 x i64>* %555 to <4 x i32>*
  store <4 x i32> %554, <4 x i32>* %556, align 16
  %557 = mul <4 x i32> %551, %152
  %558 = add <4 x i32> %557, %166
  %559 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %558, i32 %2) #8
  store <4 x i32> %559, <4 x i32>* %550, align 16
  %560 = add <4 x i32> %450, %445
  %561 = sub <4 x i32> %445, %450
  %562 = icmp sgt <4 x i32> %560, %356
  %563 = select <4 x i1> %562, <4 x i32> %560, <4 x i32> %356
  %564 = icmp slt <4 x i32> %563, %359
  %565 = select <4 x i1> %564, <4 x i32> %563, <4 x i32> %359
  %566 = icmp sgt <4 x i32> %561, %356
  %567 = select <4 x i1> %566, <4 x i32> %561, <4 x i32> %356
  %568 = icmp slt <4 x i32> %567, %359
  %569 = select <4 x i1> %568, <4 x i32> %567, <4 x i32> %359
  store <4 x i32> %565, <4 x i32>* %436, align 16
  store <4 x i32> %569, <4 x i32>* %452, align 16
  %570 = add <4 x i32> %455, %440
  %571 = sub <4 x i32> %440, %455
  %572 = icmp sgt <4 x i32> %570, %356
  %573 = select <4 x i1> %572, <4 x i32> %570, <4 x i32> %356
  %574 = icmp slt <4 x i32> %573, %359
  %575 = select <4 x i1> %574, <4 x i32> %573, <4 x i32> %359
  %576 = icmp sgt <4 x i32> %571, %356
  %577 = select <4 x i1> %576, <4 x i32> %571, <4 x i32> %356
  %578 = icmp slt <4 x i32> %577, %359
  %579 = select <4 x i1> %578, <4 x i32> %577, <4 x i32> %359
  store <4 x i32> %575, <4 x i32>* %442, align 16
  store <4 x i32> %579, <4 x i32>* %446, align 16
  %580 = load <4 x i32>, <4 x i32>* %330, align 16
  %581 = mul <4 x i32> %580, %162
  %582 = load <4 x i32>, <4 x i32>* %324, align 16
  %583 = mul <4 x i32> %582, %152
  %584 = add <4 x i32> %581, %166
  %585 = add <4 x i32> %584, %583
  %586 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %585, i32 %2) #8
  %587 = mul <4 x i32> %580, %152
  %588 = mul <4 x i32> %582, %159
  %589 = add <4 x i32> %587, %166
  %590 = add <4 x i32> %589, %588
  %591 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %590, i32 %2) #8
  store <4 x i32> %591, <4 x i32>* %324, align 16
  store <4 x i32> %586, <4 x i32>* %330, align 16
  %592 = load <4 x i32>, <4 x i32>* %334, align 16
  %593 = mul <4 x i32> %592, %155
  %594 = load <4 x i32>, <4 x i32>* %340, align 16
  %595 = mul <4 x i32> %594, %162
  %596 = add <4 x i32> %593, %166
  %597 = add <4 x i32> %596, %595
  %598 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %597, i32 %2) #8
  %599 = mul <4 x i32> %592, %162
  %600 = mul <4 x i32> %594, %152
  %601 = add <4 x i32> %599, %166
  %602 = add <4 x i32> %601, %600
  %603 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %602, i32 %2) #8
  store <4 x i32> %603, <4 x i32>* %340, align 16
  store <4 x i32> %598, <4 x i32>* %334, align 16
  %604 = load <4 x i32>, <4 x i32>* %241, align 16
  %605 = load <4 x i32>, <4 x i32>* %273, align 16
  %606 = add <4 x i32> %605, %604
  %607 = sub <4 x i32> %604, %605
  %608 = icmp sgt <4 x i32> %606, %356
  %609 = select <4 x i1> %608, <4 x i32> %606, <4 x i32> %356
  %610 = icmp slt <4 x i32> %609, %359
  %611 = select <4 x i1> %610, <4 x i32> %609, <4 x i32> %359
  %612 = icmp sgt <4 x i32> %607, %356
  %613 = select <4 x i1> %612, <4 x i32> %607, <4 x i32> %356
  %614 = icmp slt <4 x i32> %613, %359
  %615 = select <4 x i1> %614, <4 x i32> %613, <4 x i32> %359
  store <4 x i32> %611, <4 x i32>* %241, align 16
  store <4 x i32> %615, <4 x i32>* %273, align 16
  %616 = add <4 x i32> %513, %501
  %617 = sub <4 x i32> %501, %513
  %618 = icmp sgt <4 x i32> %616, %356
  %619 = select <4 x i1> %618, <4 x i32> %616, <4 x i32> %356
  %620 = icmp slt <4 x i32> %619, %359
  %621 = select <4 x i1> %620, <4 x i32> %619, <4 x i32> %359
  %622 = icmp sgt <4 x i32> %617, %356
  %623 = select <4 x i1> %622, <4 x i32> %617, <4 x i32> %356
  %624 = icmp slt <4 x i32> %623, %359
  %625 = select <4 x i1> %624, <4 x i32> %623, <4 x i32> %359
  store <4 x i32> %621, <4 x i32>* %255, align 16
  store <4 x i32> %625, <4 x i32>* %259, align 16
  %626 = load <4 x i32>, <4 x i32>* %310, align 16
  %627 = load <4 x i32>, <4 x i32>* %277, align 16
  %628 = add <4 x i32> %627, %626
  %629 = sub <4 x i32> %626, %627
  %630 = icmp sgt <4 x i32> %628, %356
  %631 = select <4 x i1> %630, <4 x i32> %628, <4 x i32> %356
  %632 = icmp slt <4 x i32> %631, %359
  %633 = select <4 x i1> %632, <4 x i32> %631, <4 x i32> %359
  %634 = icmp sgt <4 x i32> %629, %356
  %635 = select <4 x i1> %634, <4 x i32> %629, <4 x i32> %356
  %636 = icmp slt <4 x i32> %635, %359
  %637 = select <4 x i1> %636, <4 x i32> %635, <4 x i32> %359
  store <4 x i32> %633, <4 x i32>* %310, align 16
  store <4 x i32> %637, <4 x i32>* %277, align 16
  %638 = add <4 x i32> %537, %525
  %639 = sub <4 x i32> %537, %525
  %640 = icmp sgt <4 x i32> %638, %356
  %641 = select <4 x i1> %640, <4 x i32> %638, <4 x i32> %356
  %642 = icmp slt <4 x i32> %641, %359
  %643 = select <4 x i1> %642, <4 x i32> %641, <4 x i32> %359
  %644 = icmp sgt <4 x i32> %639, %356
  %645 = select <4 x i1> %644, <4 x i32> %639, <4 x i32> %356
  %646 = icmp slt <4 x i32> %645, %359
  %647 = select <4 x i1> %646, <4 x i32> %645, <4 x i32> %359
  store <4 x i32> %643, <4 x i32>* %295, align 16
  store <4 x i32> %647, <4 x i32>* %291, align 16
  %648 = load <4 x i32>, <4 x i32>* %304, align 16
  %649 = load <4 x i32>, <4 x i32>* %282, align 16
  %650 = add <4 x i32> %649, %648
  %651 = sub <4 x i32> %648, %649
  %652 = icmp sgt <4 x i32> %650, %356
  %653 = select <4 x i1> %652, <4 x i32> %650, <4 x i32> %356
  %654 = icmp slt <4 x i32> %653, %359
  %655 = select <4 x i1> %654, <4 x i32> %653, <4 x i32> %359
  %656 = icmp sgt <4 x i32> %651, %356
  %657 = select <4 x i1> %656, <4 x i32> %651, <4 x i32> %356
  %658 = icmp slt <4 x i32> %657, %359
  %659 = select <4 x i1> %658, <4 x i32> %657, <4 x i32> %359
  store <4 x i32> %655, <4 x i32>* %304, align 16
  store <4 x i32> %659, <4 x i32>* %282, align 16
  %660 = add <4 x i32> %542, %530
  %661 = sub <4 x i32> %542, %530
  %662 = icmp sgt <4 x i32> %660, %356
  %663 = select <4 x i1> %662, <4 x i32> %660, <4 x i32> %356
  %664 = icmp slt <4 x i32> %663, %359
  %665 = select <4 x i1> %664, <4 x i32> %663, <4 x i32> %359
  %666 = icmp sgt <4 x i32> %661, %356
  %667 = select <4 x i1> %666, <4 x i32> %661, <4 x i32> %356
  %668 = icmp slt <4 x i32> %667, %359
  %669 = select <4 x i1> %668, <4 x i32> %667, <4 x i32> %359
  store <4 x i32> %665, <4 x i32>* %300, align 16
  store <4 x i32> %669, <4 x i32>* %286, align 16
  %670 = load <4 x i32>, <4 x i32>* %246, align 16
  %671 = load <4 x i32>, <4 x i32>* %268, align 16
  %672 = add <4 x i32> %671, %670
  %673 = sub <4 x i32> %670, %671
  %674 = icmp sgt <4 x i32> %672, %356
  %675 = select <4 x i1> %674, <4 x i32> %672, <4 x i32> %356
  %676 = icmp slt <4 x i32> %675, %359
  %677 = select <4 x i1> %676, <4 x i32> %675, <4 x i32> %359
  %678 = icmp sgt <4 x i32> %673, %356
  %679 = select <4 x i1> %678, <4 x i32> %673, <4 x i32> %356
  %680 = icmp slt <4 x i32> %679, %359
  %681 = select <4 x i1> %680, <4 x i32> %679, <4 x i32> %359
  store <4 x i32> %677, <4 x i32>* %246, align 16
  store <4 x i32> %681, <4 x i32>* %268, align 16
  %682 = add <4 x i32> %518, %506
  %683 = sub <4 x i32> %506, %518
  %684 = icmp sgt <4 x i32> %682, %356
  %685 = select <4 x i1> %684, <4 x i32> %682, <4 x i32> %356
  %686 = icmp slt <4 x i32> %685, %359
  %687 = select <4 x i1> %686, <4 x i32> %685, <4 x i32> %359
  %688 = icmp sgt <4 x i32> %683, %356
  %689 = select <4 x i1> %688, <4 x i32> %683, <4 x i32> %356
  %690 = icmp slt <4 x i32> %689, %359
  %691 = select <4 x i1> %690, <4 x i32> %689, <4 x i32> %359
  store <4 x i32> %687, <4 x i32>* %250, align 16
  %692 = add <4 x i32> %554, %547
  %693 = sub <4 x i32> %547, %554
  %694 = icmp sgt <4 x i32> %692, %356
  %695 = select <4 x i1> %694, <4 x i32> %692, <4 x i32> %356
  %696 = icmp slt <4 x i32> %695, %359
  %697 = select <4 x i1> %696, <4 x i32> %695, <4 x i32> %359
  %698 = icmp sgt <4 x i32> %693, %356
  %699 = select <4 x i1> %698, <4 x i32> %693, <4 x i32> %356
  %700 = icmp slt <4 x i32> %699, %359
  %701 = select <4 x i1> %700, <4 x i32> %699, <4 x i32> %359
  store <4 x i32> %697, <4 x i32>* %543, align 16
  store <4 x i32> %701, <4 x i32>* %556, align 16
  %702 = add <4 x i32> %559, %547
  %703 = sub <4 x i32> %547, %559
  %704 = icmp sgt <4 x i32> %702, %356
  %705 = select <4 x i1> %704, <4 x i32> %702, <4 x i32> %356
  %706 = icmp slt <4 x i32> %705, %359
  %707 = select <4 x i1> %706, <4 x i32> %705, <4 x i32> %359
  %708 = icmp sgt <4 x i32> %703, %356
  %709 = select <4 x i1> %708, <4 x i32> %703, <4 x i32> %356
  %710 = icmp slt <4 x i32> %709, %359
  %711 = select <4 x i1> %710, <4 x i32> %709, <4 x i32> %359
  store <4 x i32> %707, <4 x i32>* %549, align 16
  store <4 x i32> %711, <4 x i32>* %550, align 16
  %712 = load <4 x i32>, <4 x i32>* %452, align 16
  %713 = mul <4 x i32> %712, %148
  %714 = load <4 x i32>, <4 x i32>* %446, align 16
  %715 = mul <4 x i32> %714, %145
  %716 = add <4 x i32> %715, %166
  %717 = add <4 x i32> %716, %713
  %718 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %717, i32 %2) #8
  %719 = mul <4 x i32> %712, %145
  %720 = add <4 x i32> %716, %719
  %721 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %720, i32 %2) #8
  store <4 x i32> %721, <4 x i32>* %446, align 16
  store <4 x i32> %718, <4 x i32>* %452, align 16
  %722 = load <4 x i32>, <4 x i32>* %314, align 16
  %723 = load <4 x i32>, <4 x i32>* %350, align 16
  %724 = add <4 x i32> %723, %722
  %725 = sub <4 x i32> %722, %723
  %726 = icmp sgt <4 x i32> %724, %356
  %727 = select <4 x i1> %726, <4 x i32> %724, <4 x i32> %356
  %728 = icmp slt <4 x i32> %727, %359
  %729 = select <4 x i1> %728, <4 x i32> %727, <4 x i32> %359
  %730 = icmp sgt <4 x i32> %725, %356
  %731 = select <4 x i1> %730, <4 x i32> %725, <4 x i32> %356
  %732 = icmp slt <4 x i32> %731, %359
  %733 = select <4 x i1> %732, <4 x i32> %731, <4 x i32> %359
  store <4 x i32> %729, <4 x i32>* %314, align 16
  store <4 x i32> %733, <4 x i32>* %350, align 16
  %734 = add <4 x i32> %598, %586
  %735 = sub <4 x i32> %586, %598
  %736 = icmp sgt <4 x i32> %734, %356
  %737 = select <4 x i1> %736, <4 x i32> %734, <4 x i32> %356
  %738 = icmp slt <4 x i32> %737, %359
  %739 = select <4 x i1> %738, <4 x i32> %737, <4 x i32> %359
  %740 = icmp sgt <4 x i32> %735, %356
  %741 = select <4 x i1> %740, <4 x i32> %735, <4 x i32> %356
  %742 = icmp slt <4 x i32> %741, %359
  %743 = select <4 x i1> %742, <4 x i32> %741, <4 x i32> %359
  store <4 x i32> %739, <4 x i32>* %330, align 16
  store <4 x i32> %743, <4 x i32>* %334, align 16
  %744 = load <4 x i32>, <4 x i32>* %320, align 16
  %745 = load <4 x i32>, <4 x i32>* %344, align 16
  %746 = add <4 x i32> %745, %744
  %747 = sub <4 x i32> %744, %745
  %748 = icmp sgt <4 x i32> %746, %356
  %749 = select <4 x i1> %748, <4 x i32> %746, <4 x i32> %356
  %750 = icmp slt <4 x i32> %749, %359
  %751 = select <4 x i1> %750, <4 x i32> %749, <4 x i32> %359
  %752 = icmp sgt <4 x i32> %747, %356
  %753 = select <4 x i1> %752, <4 x i32> %747, <4 x i32> %356
  %754 = icmp slt <4 x i32> %753, %359
  %755 = select <4 x i1> %754, <4 x i32> %753, <4 x i32> %359
  store <4 x i32> %751, <4 x i32>* %320, align 16
  store <4 x i32> %755, <4 x i32>* %344, align 16
  %756 = add <4 x i32> %603, %591
  %757 = sub <4 x i32> %591, %603
  %758 = icmp sgt <4 x i32> %756, %356
  %759 = select <4 x i1> %758, <4 x i32> %756, <4 x i32> %356
  %760 = icmp slt <4 x i32> %759, %359
  %761 = select <4 x i1> %760, <4 x i32> %759, <4 x i32> %359
  %762 = icmp sgt <4 x i32> %757, %356
  %763 = select <4 x i1> %762, <4 x i32> %757, <4 x i32> %356
  %764 = icmp slt <4 x i32> %763, %359
  %765 = select <4 x i1> %764, <4 x i32> %763, <4 x i32> %359
  store <4 x i32> %761, <4 x i32>* %324, align 16
  store <4 x i32> %765, <4 x i32>* %340, align 16
  %766 = mul <4 x i32> %625, %162
  %767 = mul <4 x i32> %691, %152
  %768 = add <4 x i32> %766, %166
  %769 = add <4 x i32> %768, %767
  %770 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %769, i32 %2) #8
  %771 = mul <4 x i32> %625, %152
  %772 = mul <4 x i32> %691, %159
  %773 = add <4 x i32> %771, %166
  %774 = add <4 x i32> %773, %772
  %775 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %774, i32 %2) #8
  store <4 x i32> %775, <4 x i32>* %264, align 16
  store <4 x i32> %770, <4 x i32>* %259, align 16
  %776 = mul <4 x i32> %615, %162
  %777 = mul <4 x i32> %681, %152
  %778 = add <4 x i32> %776, %166
  %779 = add <4 x i32> %778, %777
  %780 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %779, i32 %2) #8
  %781 = mul <4 x i32> %615, %152
  %782 = mul <4 x i32> %681, %159
  %783 = add <4 x i32> %781, %166
  %784 = add <4 x i32> %783, %782
  %785 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %784, i32 %2) #8
  store <4 x i32> %785, <4 x i32>* %268, align 16
  store <4 x i32> %780, <4 x i32>* %273, align 16
  %786 = mul <4 x i32> %637, %155
  %787 = mul <4 x i32> %659, %162
  %788 = add <4 x i32> %786, %166
  %789 = add <4 x i32> %788, %787
  %790 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %789, i32 %2) #8
  %791 = mul <4 x i32> %637, %162
  %792 = mul <4 x i32> %659, %152
  %793 = add <4 x i32> %791, %166
  %794 = add <4 x i32> %793, %792
  %795 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %794, i32 %2) #8
  store <4 x i32> %795, <4 x i32>* %282, align 16
  store <4 x i32> %790, <4 x i32>* %277, align 16
  %796 = mul <4 x i32> %647, %155
  %797 = mul <4 x i32> %669, %162
  %798 = add <4 x i32> %796, %166
  %799 = add <4 x i32> %798, %797
  %800 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %799, i32 %2) #8
  %801 = mul <4 x i32> %647, %162
  %802 = mul <4 x i32> %669, %152
  %803 = add <4 x i32> %801, %166
  %804 = add <4 x i32> %803, %802
  %805 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %804, i32 %2) #8
  store <4 x i32> %805, <4 x i32>* %286, align 16
  store <4 x i32> %800, <4 x i32>* %291, align 16
  %806 = load <4 x i32>, <4 x i32>* %442, align 16
  %807 = add <4 x i32> %806, %697
  %808 = sub <4 x i32> %697, %806
  %809 = icmp sgt <4 x i32> %807, %356
  %810 = select <4 x i1> %809, <4 x i32> %807, <4 x i32> %356
  %811 = icmp slt <4 x i32> %810, %359
  %812 = select <4 x i1> %811, <4 x i32> %810, <4 x i32> %359
  %813 = icmp sgt <4 x i32> %808, %356
  %814 = select <4 x i1> %813, <4 x i32> %808, <4 x i32> %356
  %815 = icmp slt <4 x i32> %814, %359
  %816 = select <4 x i1> %815, <4 x i32> %814, <4 x i32> %359
  store <4 x i32> %812, <4 x i32>* %543, align 16
  store <4 x i32> %816, <4 x i32>* %442, align 16
  %817 = load <4 x i32>, <4 x i32>* %549, align 16
  %818 = add <4 x i32> %817, %721
  %819 = sub <4 x i32> %817, %721
  %820 = icmp sgt <4 x i32> %818, %356
  %821 = select <4 x i1> %820, <4 x i32> %818, <4 x i32> %356
  %822 = icmp slt <4 x i32> %821, %359
  %823 = select <4 x i1> %822, <4 x i32> %821, <4 x i32> %359
  %824 = icmp sgt <4 x i32> %819, %356
  %825 = select <4 x i1> %824, <4 x i32> %819, <4 x i32> %356
  %826 = icmp slt <4 x i32> %825, %359
  %827 = select <4 x i1> %826, <4 x i32> %825, <4 x i32> %359
  store <4 x i32> %823, <4 x i32>* %549, align 16
  store <4 x i32> %827, <4 x i32>* %446, align 16
  %828 = load <4 x i32>, <4 x i32>* %550, align 16
  %829 = add <4 x i32> %828, %718
  %830 = sub <4 x i32> %828, %718
  %831 = icmp sgt <4 x i32> %829, %356
  %832 = select <4 x i1> %831, <4 x i32> %829, <4 x i32> %356
  %833 = icmp slt <4 x i32> %832, %359
  %834 = select <4 x i1> %833, <4 x i32> %832, <4 x i32> %359
  %835 = icmp sgt <4 x i32> %830, %356
  %836 = select <4 x i1> %835, <4 x i32> %830, <4 x i32> %356
  %837 = icmp slt <4 x i32> %836, %359
  %838 = select <4 x i1> %837, <4 x i32> %836, <4 x i32> %359
  store <4 x i32> %834, <4 x i32>* %550, align 16
  store <4 x i32> %838, <4 x i32>* %452, align 16
  %839 = load <4 x i32>, <4 x i32>* %556, align 16
  %840 = load <4 x i32>, <4 x i32>* %436, align 16
  %841 = add <4 x i32> %840, %839
  %842 = sub <4 x i32> %839, %840
  %843 = icmp sgt <4 x i32> %841, %356
  %844 = select <4 x i1> %843, <4 x i32> %841, <4 x i32> %356
  %845 = icmp slt <4 x i32> %844, %359
  %846 = select <4 x i1> %845, <4 x i32> %844, <4 x i32> %359
  %847 = icmp sgt <4 x i32> %842, %356
  %848 = select <4 x i1> %847, <4 x i32> %842, <4 x i32> %356
  %849 = icmp slt <4 x i32> %848, %359
  %850 = select <4 x i1> %849, <4 x i32> %848, <4 x i32> %359
  store <4 x i32> %846, <4 x i32>* %556, align 16
  store <4 x i32> %850, <4 x i32>* %436, align 16
  %851 = mul <4 x i32> %743, %148
  %852 = mul <4 x i32> %765, %145
  %853 = add <4 x i32> %852, %166
  %854 = add <4 x i32> %853, %851
  %855 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %854, i32 %2) #8
  %856 = mul <4 x i32> %743, %145
  %857 = add <4 x i32> %853, %856
  %858 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %857, i32 %2) #8
  store <4 x i32> %858, <4 x i32>* %340, align 16
  store <4 x i32> %855, <4 x i32>* %334, align 16
  %859 = mul <4 x i32> %733, %148
  %860 = mul <4 x i32> %755, %145
  %861 = add <4 x i32> %860, %166
  %862 = add <4 x i32> %861, %859
  %863 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %862, i32 %2) #8
  %864 = mul <4 x i32> %733, %145
  %865 = add <4 x i32> %861, %864
  %866 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %865, i32 %2) #8
  store <4 x i32> %866, <4 x i32>* %344, align 16
  store <4 x i32> %863, <4 x i32>* %350, align 16
  %867 = add <4 x i32> %633, %611
  %868 = sub <4 x i32> %611, %633
  %869 = icmp sgt <4 x i32> %867, %356
  %870 = select <4 x i1> %869, <4 x i32> %867, <4 x i32> %356
  %871 = icmp slt <4 x i32> %870, %359
  %872 = select <4 x i1> %871, <4 x i32> %870, <4 x i32> %359
  %873 = icmp sgt <4 x i32> %868, %356
  %874 = select <4 x i1> %873, <4 x i32> %868, <4 x i32> %356
  %875 = icmp slt <4 x i32> %874, %359
  %876 = select <4 x i1> %875, <4 x i32> %874, <4 x i32> %359
  store <4 x i32> %872, <4 x i32>* %241, align 16
  store <4 x i32> %876, <4 x i32>* %310, align 16
  %877 = add <4 x i32> %643, %621
  %878 = sub <4 x i32> %621, %643
  %879 = load <4 x i32>, <4 x i32>* %178, align 16
  %880 = icmp sgt <4 x i32> %877, %879
  %881 = select <4 x i1> %880, <4 x i32> %877, <4 x i32> %879
  %882 = load <4 x i32>, <4 x i32>* %183, align 16
  %883 = icmp slt <4 x i32> %881, %882
  %884 = select <4 x i1> %883, <4 x i32> %881, <4 x i32> %882
  %885 = icmp sgt <4 x i32> %878, %879
  %886 = select <4 x i1> %885, <4 x i32> %878, <4 x i32> %879
  %887 = icmp slt <4 x i32> %886, %882
  %888 = select <4 x i1> %887, <4 x i32> %886, <4 x i32> %882
  store <4 x i32> %884, <4 x i32>* %255, align 16
  store <4 x i32> %888, <4 x i32>* %295, align 16
  %889 = add <4 x i32> %800, %770
  %890 = sub <4 x i32> %770, %800
  %891 = icmp sgt <4 x i32> %889, %879
  %892 = select <4 x i1> %891, <4 x i32> %889, <4 x i32> %879
  %893 = icmp slt <4 x i32> %892, %882
  %894 = select <4 x i1> %893, <4 x i32> %892, <4 x i32> %882
  %895 = icmp sgt <4 x i32> %890, %879
  %896 = select <4 x i1> %895, <4 x i32> %890, <4 x i32> %879
  %897 = icmp slt <4 x i32> %896, %882
  %898 = select <4 x i1> %897, <4 x i32> %896, <4 x i32> %882
  store <4 x i32> %894, <4 x i32>* %259, align 16
  store <4 x i32> %898, <4 x i32>* %291, align 16
  %899 = add <4 x i32> %790, %780
  %900 = sub <4 x i32> %780, %790
  %901 = icmp sgt <4 x i32> %899, %879
  %902 = select <4 x i1> %901, <4 x i32> %899, <4 x i32> %879
  %903 = icmp slt <4 x i32> %902, %882
  %904 = select <4 x i1> %903, <4 x i32> %902, <4 x i32> %882
  %905 = icmp sgt <4 x i32> %900, %879
  %906 = select <4 x i1> %905, <4 x i32> %900, <4 x i32> %879
  %907 = icmp slt <4 x i32> %906, %882
  %908 = select <4 x i1> %907, <4 x i32> %906, <4 x i32> %882
  store <4 x i32> %904, <4 x i32>* %273, align 16
  store <4 x i32> %908, <4 x i32>* %277, align 16
  %909 = add <4 x i32> %677, %655
  %910 = sub <4 x i32> %677, %655
  %911 = icmp sgt <4 x i32> %909, %879
  %912 = select <4 x i1> %911, <4 x i32> %909, <4 x i32> %879
  %913 = icmp slt <4 x i32> %912, %882
  %914 = select <4 x i1> %913, <4 x i32> %912, <4 x i32> %882
  %915 = icmp sgt <4 x i32> %910, %879
  %916 = select <4 x i1> %915, <4 x i32> %910, <4 x i32> %879
  %917 = icmp slt <4 x i32> %916, %882
  %918 = select <4 x i1> %917, <4 x i32> %916, <4 x i32> %882
  store <4 x i32> %914, <4 x i32>* %246, align 16
  store <4 x i32> %918, <4 x i32>* %304, align 16
  %919 = add <4 x i32> %665, %687
  %920 = sub <4 x i32> %687, %665
  %921 = icmp sgt <4 x i32> %919, %879
  %922 = select <4 x i1> %921, <4 x i32> %919, <4 x i32> %879
  %923 = icmp slt <4 x i32> %922, %882
  %924 = select <4 x i1> %923, <4 x i32> %922, <4 x i32> %882
  %925 = icmp sgt <4 x i32> %920, %879
  %926 = select <4 x i1> %925, <4 x i32> %920, <4 x i32> %879
  %927 = icmp slt <4 x i32> %926, %882
  %928 = select <4 x i1> %927, <4 x i32> %926, <4 x i32> %882
  store <4 x i32> %924, <4 x i32>* %250, align 16
  store <4 x i32> %928, <4 x i32>* %300, align 16
  %929 = add <4 x i32> %805, %775
  %930 = sub <4 x i32> %775, %805
  %931 = icmp sgt <4 x i32> %929, %879
  %932 = select <4 x i1> %931, <4 x i32> %929, <4 x i32> %879
  %933 = icmp slt <4 x i32> %932, %882
  %934 = select <4 x i1> %933, <4 x i32> %932, <4 x i32> %882
  %935 = icmp sgt <4 x i32> %930, %879
  %936 = select <4 x i1> %935, <4 x i32> %930, <4 x i32> %879
  %937 = icmp slt <4 x i32> %936, %882
  %938 = select <4 x i1> %937, <4 x i32> %936, <4 x i32> %882
  store <4 x i32> %934, <4 x i32>* %264, align 16
  store <4 x i32> %938, <4 x i32>* %286, align 16
  %939 = add <4 x i32> %795, %785
  %940 = sub <4 x i32> %785, %795
  %941 = icmp sgt <4 x i32> %939, %879
  %942 = select <4 x i1> %941, <4 x i32> %939, <4 x i32> %879
  %943 = icmp slt <4 x i32> %942, %882
  %944 = select <4 x i1> %943, <4 x i32> %942, <4 x i32> %882
  %945 = icmp sgt <4 x i32> %940, %879
  %946 = select <4 x i1> %945, <4 x i32> %940, <4 x i32> %879
  %947 = icmp slt <4 x i32> %946, %882
  %948 = select <4 x i1> %947, <4 x i32> %946, <4 x i32> %882
  store <4 x i32> %944, <4 x i32>* %268, align 16
  store <4 x i32> %948, <4 x i32>* %282, align 16
  %949 = add <4 x i32> %812, %751
  %950 = sub <4 x i32> %812, %751
  %951 = icmp sgt <4 x i32> %949, %879
  %952 = select <4 x i1> %951, <4 x i32> %949, <4 x i32> %879
  %953 = icmp slt <4 x i32> %952, %882
  %954 = select <4 x i1> %953, <4 x i32> %952, <4 x i32> %882
  %955 = icmp sgt <4 x i32> %950, %879
  %956 = select <4 x i1> %955, <4 x i32> %950, <4 x i32> %879
  %957 = icmp slt <4 x i32> %956, %882
  %958 = select <4 x i1> %957, <4 x i32> %956, <4 x i32> %882
  store <4 x i32> %954, <4 x i32>* %543, align 16
  store <4 x i32> %958, <4 x i32>* %320, align 16
  %959 = add <4 x i32> %823, %761
  %960 = sub <4 x i32> %823, %761
  %961 = icmp sgt <4 x i32> %959, %879
  %962 = select <4 x i1> %961, <4 x i32> %959, <4 x i32> %879
  %963 = icmp slt <4 x i32> %962, %882
  %964 = select <4 x i1> %963, <4 x i32> %962, <4 x i32> %882
  %965 = icmp sgt <4 x i32> %960, %879
  %966 = select <4 x i1> %965, <4 x i32> %960, <4 x i32> %879
  %967 = icmp slt <4 x i32> %966, %882
  %968 = select <4 x i1> %967, <4 x i32> %966, <4 x i32> %882
  store <4 x i32> %964, <4 x i32>* %549, align 16
  store <4 x i32> %968, <4 x i32>* %324, align 16
  %969 = add <4 x i32> %858, %834
  %970 = sub <4 x i32> %834, %858
  %971 = icmp sgt <4 x i32> %969, %879
  %972 = select <4 x i1> %971, <4 x i32> %969, <4 x i32> %879
  %973 = icmp slt <4 x i32> %972, %882
  %974 = select <4 x i1> %973, <4 x i32> %972, <4 x i32> %882
  %975 = icmp sgt <4 x i32> %970, %879
  %976 = select <4 x i1> %975, <4 x i32> %970, <4 x i32> %879
  %977 = icmp slt <4 x i32> %976, %882
  %978 = select <4 x i1> %977, <4 x i32> %976, <4 x i32> %882
  store <4 x i32> %974, <4 x i32>* %550, align 16
  store <4 x i32> %978, <4 x i32>* %340, align 16
  %979 = add <4 x i32> %866, %846
  %980 = sub <4 x i32> %846, %866
  %981 = icmp sgt <4 x i32> %979, %879
  %982 = select <4 x i1> %981, <4 x i32> %979, <4 x i32> %879
  %983 = icmp slt <4 x i32> %982, %882
  %984 = select <4 x i1> %983, <4 x i32> %982, <4 x i32> %882
  %985 = icmp sgt <4 x i32> %980, %879
  %986 = select <4 x i1> %985, <4 x i32> %980, <4 x i32> %879
  %987 = icmp slt <4 x i32> %986, %882
  %988 = select <4 x i1> %987, <4 x i32> %986, <4 x i32> %882
  store <4 x i32> %984, <4 x i32>* %556, align 16
  store <4 x i32> %988, <4 x i32>* %344, align 16
  %989 = add <4 x i32> %863, %850
  %990 = sub <4 x i32> %850, %863
  %991 = icmp sgt <4 x i32> %989, %879
  %992 = select <4 x i1> %991, <4 x i32> %989, <4 x i32> %879
  %993 = icmp slt <4 x i32> %992, %882
  %994 = select <4 x i1> %993, <4 x i32> %992, <4 x i32> %882
  %995 = icmp sgt <4 x i32> %990, %879
  %996 = select <4 x i1> %995, <4 x i32> %990, <4 x i32> %879
  %997 = icmp slt <4 x i32> %996, %882
  %998 = select <4 x i1> %997, <4 x i32> %996, <4 x i32> %882
  store <4 x i32> %994, <4 x i32>* %436, align 16
  store <4 x i32> %998, <4 x i32>* %350, align 16
  %999 = add <4 x i32> %855, %838
  %1000 = sub <4 x i32> %838, %855
  %1001 = icmp sgt <4 x i32> %999, %879
  %1002 = select <4 x i1> %1001, <4 x i32> %999, <4 x i32> %879
  %1003 = icmp slt <4 x i32> %1002, %882
  %1004 = select <4 x i1> %1003, <4 x i32> %1002, <4 x i32> %882
  %1005 = icmp sgt <4 x i32> %1000, %879
  %1006 = select <4 x i1> %1005, <4 x i32> %1000, <4 x i32> %879
  %1007 = icmp slt <4 x i32> %1006, %882
  %1008 = select <4 x i1> %1007, <4 x i32> %1006, <4 x i32> %882
  store <4 x i32> %1004, <4 x i32>* %452, align 16
  store <4 x i32> %1008, <4 x i32>* %334, align 16
  %1009 = add <4 x i32> %827, %739
  %1010 = sub <4 x i32> %827, %739
  %1011 = icmp sgt <4 x i32> %1009, %879
  %1012 = select <4 x i1> %1011, <4 x i32> %1009, <4 x i32> %879
  %1013 = icmp slt <4 x i32> %1012, %882
  %1014 = select <4 x i1> %1013, <4 x i32> %1012, <4 x i32> %882
  %1015 = icmp sgt <4 x i32> %1010, %879
  %1016 = select <4 x i1> %1015, <4 x i32> %1010, <4 x i32> %879
  %1017 = icmp slt <4 x i32> %1016, %882
  %1018 = select <4 x i1> %1017, <4 x i32> %1016, <4 x i32> %882
  store <4 x i32> %1014, <4 x i32>* %446, align 16
  store <4 x i32> %1018, <4 x i32>* %330, align 16
  %1019 = add <4 x i32> %816, %729
  %1020 = sub <4 x i32> %816, %729
  %1021 = icmp sgt <4 x i32> %1019, %879
  %1022 = select <4 x i1> %1021, <4 x i32> %1019, <4 x i32> %879
  %1023 = icmp slt <4 x i32> %1022, %882
  %1024 = select <4 x i1> %1023, <4 x i32> %1022, <4 x i32> %882
  %1025 = icmp sgt <4 x i32> %1020, %879
  %1026 = select <4 x i1> %1025, <4 x i32> %1020, <4 x i32> %879
  %1027 = icmp slt <4 x i32> %1026, %882
  %1028 = select <4 x i1> %1027, <4 x i32> %1026, <4 x i32> %882
  store <4 x i32> %1024, <4 x i32>* %442, align 16
  store <4 x i32> %1028, <4 x i32>* %314, align 16
  %1029 = mul <4 x i32> %908, %148
  %1030 = mul <4 x i32> %948, %145
  %1031 = add <4 x i32> %1030, %166
  %1032 = add <4 x i32> %1031, %1029
  %1033 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1032, i32 %2) #8
  %1034 = mul <4 x i32> %908, %145
  %1035 = add <4 x i32> %1031, %1034
  %1036 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1035, i32 %2) #8
  store <4 x i32> %1036, <4 x i32>* %282, align 16
  store <4 x i32> %1033, <4 x i32>* %277, align 16
  %1037 = mul <4 x i32> %898, %148
  %1038 = mul <4 x i32> %938, %145
  %1039 = add <4 x i32> %1038, %166
  %1040 = add <4 x i32> %1039, %1037
  %1041 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1040, i32 %2) #8
  %1042 = mul <4 x i32> %898, %145
  %1043 = add <4 x i32> %1039, %1042
  %1044 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1043, i32 %2) #8
  store <4 x i32> %1044, <4 x i32>* %286, align 16
  store <4 x i32> %1041, <4 x i32>* %291, align 16
  %1045 = mul <4 x i32> %888, %148
  %1046 = mul <4 x i32> %928, %145
  %1047 = add <4 x i32> %1046, %166
  %1048 = add <4 x i32> %1047, %1045
  %1049 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1048, i32 %2) #8
  %1050 = mul <4 x i32> %888, %145
  %1051 = add <4 x i32> %1047, %1050
  %1052 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1051, i32 %2) #8
  store <4 x i32> %1052, <4 x i32>* %300, align 16
  store <4 x i32> %1049, <4 x i32>* %295, align 16
  %1053 = mul <4 x i32> %876, %148
  %1054 = mul <4 x i32> %918, %145
  %1055 = add <4 x i32> %1054, %166
  %1056 = add <4 x i32> %1055, %1053
  %1057 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1056, i32 %2) #8
  %1058 = mul <4 x i32> %876, %145
  %1059 = add <4 x i32> %1055, %1058
  %1060 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1059, i32 %2) #8
  store <4 x i32> %1060, <4 x i32>* %304, align 16
  store <4 x i32> %1057, <4 x i32>* %310, align 16
  call fastcc void @idct32_stage9_sse4_1(<2 x i64>* nonnull %188, <2 x i64>* %1, i32 %3, i32 %4, i32 %5, <2 x i64>* nonnull %7, <2 x i64>* nonnull %8)
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %184) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %179) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %172) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @idct32x32_sse4_1(<2 x i64>* readonly, <2 x i64>*, i32, i32, i32, i32) #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 62
  %10 = load i32, i32* %9, align 8
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 30
  %14 = load i32, i32* %13, align 8
  %15 = insertelement <4 x i32> undef, i32 %14, i32 0
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> zeroinitializer
  %17 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 46
  %18 = load i32, i32* %17, align 8
  %19 = insertelement <4 x i32> undef, i32 %18, i32 0
  %20 = shufflevector <4 x i32> %19, <4 x i32> undef, <4 x i32> zeroinitializer
  %21 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 14
  %22 = load i32, i32* %21, align 8
  %23 = insertelement <4 x i32> undef, i32 %22, i32 0
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> zeroinitializer
  %25 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 54
  %26 = load i32, i32* %25, align 8
  %27 = insertelement <4 x i32> undef, i32 %26, i32 0
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> zeroinitializer
  %29 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 22
  %30 = load i32, i32* %29, align 8
  %31 = insertelement <4 x i32> undef, i32 %30, i32 0
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> zeroinitializer
  %33 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 38
  %34 = load i32, i32* %33, align 8
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 6
  %38 = load i32, i32* %37, align 8
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> zeroinitializer
  %41 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 58
  %42 = load i32, i32* %41, align 8
  %43 = insertelement <4 x i32> undef, i32 %42, i32 0
  %44 = shufflevector <4 x i32> %43, <4 x i32> undef, <4 x i32> zeroinitializer
  %45 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 26
  %46 = load i32, i32* %45, align 8
  %47 = insertelement <4 x i32> undef, i32 %46, i32 0
  %48 = shufflevector <4 x i32> %47, <4 x i32> undef, <4 x i32> zeroinitializer
  %49 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 42
  %50 = load i32, i32* %49, align 8
  %51 = insertelement <4 x i32> undef, i32 %50, i32 0
  %52 = shufflevector <4 x i32> %51, <4 x i32> undef, <4 x i32> zeroinitializer
  %53 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 10
  %54 = load i32, i32* %53, align 8
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 50
  %58 = load i32, i32* %57, align 8
  %59 = insertelement <4 x i32> undef, i32 %58, i32 0
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 18
  %62 = load i32, i32* %61, align 8
  %63 = insertelement <4 x i32> undef, i32 %62, i32 0
  %64 = shufflevector <4 x i32> %63, <4 x i32> undef, <4 x i32> zeroinitializer
  %65 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 34
  %66 = load i32, i32* %65, align 8
  %67 = insertelement <4 x i32> undef, i32 %66, i32 0
  %68 = shufflevector <4 x i32> %67, <4 x i32> undef, <4 x i32> zeroinitializer
  %69 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 2
  %70 = load i32, i32* %69, align 8
  %71 = insertelement <4 x i32> undef, i32 %70, i32 0
  %72 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> zeroinitializer
  %73 = sub nsw i32 0, %42
  %74 = insertelement <4 x i32> undef, i32 %73, i32 0
  %75 = shufflevector <4 x i32> %74, <4 x i32> undef, <4 x i32> zeroinitializer
  %76 = sub nsw i32 0, %46
  %77 = insertelement <4 x i32> undef, i32 %76, i32 0
  %78 = shufflevector <4 x i32> %77, <4 x i32> undef, <4 x i32> zeroinitializer
  %79 = sub nsw i32 0, %50
  %80 = insertelement <4 x i32> undef, i32 %79, i32 0
  %81 = shufflevector <4 x i32> %80, <4 x i32> undef, <4 x i32> zeroinitializer
  %82 = sub nsw i32 0, %54
  %83 = insertelement <4 x i32> undef, i32 %82, i32 0
  %84 = shufflevector <4 x i32> %83, <4 x i32> undef, <4 x i32> zeroinitializer
  %85 = sub nsw i32 0, %58
  %86 = insertelement <4 x i32> undef, i32 %85, i32 0
  %87 = shufflevector <4 x i32> %86, <4 x i32> undef, <4 x i32> zeroinitializer
  %88 = sub nsw i32 0, %62
  %89 = insertelement <4 x i32> undef, i32 %88, i32 0
  %90 = shufflevector <4 x i32> %89, <4 x i32> undef, <4 x i32> zeroinitializer
  %91 = sub nsw i32 0, %66
  %92 = insertelement <4 x i32> undef, i32 %91, i32 0
  %93 = shufflevector <4 x i32> %92, <4 x i32> undef, <4 x i32> zeroinitializer
  %94 = sub nsw i32 0, %70
  %95 = insertelement <4 x i32> undef, i32 %94, i32 0
  %96 = shufflevector <4 x i32> %95, <4 x i32> undef, <4 x i32> zeroinitializer
  %97 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 60
  %98 = load i32, i32* %97, align 16
  %99 = insertelement <4 x i32> undef, i32 %98, i32 0
  %100 = shufflevector <4 x i32> %99, <4 x i32> undef, <4 x i32> zeroinitializer
  %101 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 28
  %102 = load i32, i32* %101, align 16
  %103 = insertelement <4 x i32> undef, i32 %102, i32 0
  %104 = shufflevector <4 x i32> %103, <4 x i32> undef, <4 x i32> zeroinitializer
  %105 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 44
  %106 = load i32, i32* %105, align 16
  %107 = insertelement <4 x i32> undef, i32 %106, i32 0
  %108 = shufflevector <4 x i32> %107, <4 x i32> undef, <4 x i32> zeroinitializer
  %109 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 12
  %110 = load i32, i32* %109, align 16
  %111 = insertelement <4 x i32> undef, i32 %110, i32 0
  %112 = shufflevector <4 x i32> %111, <4 x i32> undef, <4 x i32> zeroinitializer
  %113 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 52
  %114 = load i32, i32* %113, align 16
  %115 = insertelement <4 x i32> undef, i32 %114, i32 0
  %116 = shufflevector <4 x i32> %115, <4 x i32> undef, <4 x i32> zeroinitializer
  %117 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 20
  %118 = load i32, i32* %117, align 16
  %119 = insertelement <4 x i32> undef, i32 %118, i32 0
  %120 = shufflevector <4 x i32> %119, <4 x i32> undef, <4 x i32> zeroinitializer
  %121 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 36
  %122 = load i32, i32* %121, align 16
  %123 = insertelement <4 x i32> undef, i32 %122, i32 0
  %124 = shufflevector <4 x i32> %123, <4 x i32> undef, <4 x i32> zeroinitializer
  %125 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 4
  %126 = load i32, i32* %125, align 16
  %127 = insertelement <4 x i32> undef, i32 %126, i32 0
  %128 = shufflevector <4 x i32> %127, <4 x i32> undef, <4 x i32> zeroinitializer
  %129 = sub nsw i32 0, %114
  %130 = insertelement <4 x i32> undef, i32 %129, i32 0
  %131 = shufflevector <4 x i32> %130, <4 x i32> undef, <4 x i32> zeroinitializer
  %132 = sub nsw i32 0, %118
  %133 = insertelement <4 x i32> undef, i32 %132, i32 0
  %134 = shufflevector <4 x i32> %133, <4 x i32> undef, <4 x i32> zeroinitializer
  %135 = sub nsw i32 0, %122
  %136 = insertelement <4 x i32> undef, i32 %135, i32 0
  %137 = shufflevector <4 x i32> %136, <4 x i32> undef, <4 x i32> zeroinitializer
  %138 = sub nsw i32 0, %126
  %139 = insertelement <4 x i32> undef, i32 %138, i32 0
  %140 = shufflevector <4 x i32> %139, <4 x i32> undef, <4 x i32> zeroinitializer
  %141 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 56
  %142 = load i32, i32* %141, align 16
  %143 = insertelement <4 x i32> undef, i32 %142, i32 0
  %144 = shufflevector <4 x i32> %143, <4 x i32> undef, <4 x i32> zeroinitializer
  %145 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 24
  %146 = load i32, i32* %145, align 16
  %147 = insertelement <4 x i32> undef, i32 %146, i32 0
  %148 = shufflevector <4 x i32> %147, <4 x i32> undef, <4 x i32> zeroinitializer
  %149 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 40
  %150 = load i32, i32* %149, align 16
  %151 = insertelement <4 x i32> undef, i32 %150, i32 0
  %152 = shufflevector <4 x i32> %151, <4 x i32> undef, <4 x i32> zeroinitializer
  %153 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 8
  %154 = load i32, i32* %153, align 16
  %155 = insertelement <4 x i32> undef, i32 %154, i32 0
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> zeroinitializer
  %157 = sub nsw i32 0, %150
  %158 = insertelement <4 x i32> undef, i32 %157, i32 0
  %159 = shufflevector <4 x i32> %158, <4 x i32> undef, <4 x i32> zeroinitializer
  %160 = sub nsw i32 0, %154
  %161 = insertelement <4 x i32> undef, i32 %160, i32 0
  %162 = shufflevector <4 x i32> %161, <4 x i32> undef, <4 x i32> zeroinitializer
  %163 = sub nsw i32 0, %142
  %164 = insertelement <4 x i32> undef, i32 %163, i32 0
  %165 = shufflevector <4 x i32> %164, <4 x i32> undef, <4 x i32> zeroinitializer
  %166 = sub nsw i32 0, %146
  %167 = insertelement <4 x i32> undef, i32 %166, i32 0
  %168 = shufflevector <4 x i32> %167, <4 x i32> undef, <4 x i32> zeroinitializer
  %169 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %170 = load i32, i32* %169, align 16
  %171 = insertelement <4 x i32> undef, i32 %170, i32 0
  %172 = shufflevector <4 x i32> %171, <4 x i32> undef, <4 x i32> zeroinitializer
  %173 = sub nsw i32 0, %170
  %174 = insertelement <4 x i32> undef, i32 %173, i32 0
  %175 = shufflevector <4 x i32> %174, <4 x i32> undef, <4 x i32> zeroinitializer
  %176 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 48
  %177 = load i32, i32* %176, align 16
  %178 = insertelement <4 x i32> undef, i32 %177, i32 0
  %179 = shufflevector <4 x i32> %178, <4 x i32> undef, <4 x i32> zeroinitializer
  %180 = sub nsw i32 0, %177
  %181 = insertelement <4 x i32> undef, i32 %180, i32 0
  %182 = shufflevector <4 x i32> %181, <4 x i32> undef, <4 x i32> zeroinitializer
  %183 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 16
  %184 = load i32, i32* %183, align 16
  %185 = insertelement <4 x i32> undef, i32 %184, i32 0
  %186 = shufflevector <4 x i32> %185, <4 x i32> undef, <4 x i32> zeroinitializer
  %187 = sub nsw i32 0, %184
  %188 = insertelement <4 x i32> undef, i32 %187, i32 0
  %189 = shufflevector <4 x i32> %188, <4 x i32> undef, <4 x i32> zeroinitializer
  %190 = add nsw i32 %2, -1
  %191 = shl i32 1, %190
  %192 = insertelement <4 x i32> undef, i32 %191, i32 0
  %193 = shufflevector <4 x i32> %192, <4 x i32> undef, <4 x i32> zeroinitializer
  %194 = icmp ne i32 %3, 0
  %195 = select i1 %194, i32 6, i32 8
  %196 = add nsw i32 %195, %4
  %197 = icmp slt i32 %196, 16
  %198 = add i32 %196, -1
  %199 = shl i32 1, %198
  %200 = select i1 %197, i32 32768, i32 %199
  %201 = sub nsw i32 0, %200
  %202 = insertelement <4 x i32> undef, i32 %201, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = add nsw i32 %200, -1
  %205 = insertelement <4 x i32> undef, i32 %204, i32 0
  %206 = shufflevector <4 x i32> %205, <4 x i32> undef, <4 x i32> zeroinitializer
  %207 = bitcast <2 x i64>* %0 to <4 x i32>*
  %208 = load <4 x i32>, <4 x i32>* %207, align 16
  %209 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 16
  %210 = bitcast <2 x i64>* %209 to <4 x i32>*
  %211 = load <4 x i32>, <4 x i32>* %210, align 16
  %212 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %213 = bitcast <2 x i64>* %212 to <4 x i32>*
  %214 = load <4 x i32>, <4 x i32>* %213, align 16
  %215 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 24
  %216 = bitcast <2 x i64>* %215 to <4 x i32>*
  %217 = load <4 x i32>, <4 x i32>* %216, align 16
  %218 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %219 = bitcast <2 x i64>* %218 to <4 x i32>*
  %220 = load <4 x i32>, <4 x i32>* %219, align 16
  %221 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 20
  %222 = bitcast <2 x i64>* %221 to <4 x i32>*
  %223 = load <4 x i32>, <4 x i32>* %222, align 16
  %224 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %225 = bitcast <2 x i64>* %224 to <4 x i32>*
  %226 = load <4 x i32>, <4 x i32>* %225, align 16
  %227 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 28
  %228 = bitcast <2 x i64>* %227 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16
  %230 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %231 = bitcast <2 x i64>* %230 to <4 x i32>*
  %232 = load <4 x i32>, <4 x i32>* %231, align 16
  %233 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 18
  %234 = bitcast <2 x i64>* %233 to <4 x i32>*
  %235 = load <4 x i32>, <4 x i32>* %234, align 16
  %236 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %237 = bitcast <2 x i64>* %236 to <4 x i32>*
  %238 = load <4 x i32>, <4 x i32>* %237, align 16
  %239 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 26
  %240 = bitcast <2 x i64>* %239 to <4 x i32>*
  %241 = load <4 x i32>, <4 x i32>* %240, align 16
  %242 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %243 = bitcast <2 x i64>* %242 to <4 x i32>*
  %244 = load <4 x i32>, <4 x i32>* %243, align 16
  %245 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 22
  %246 = bitcast <2 x i64>* %245 to <4 x i32>*
  %247 = load <4 x i32>, <4 x i32>* %246, align 16
  %248 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %249 = bitcast <2 x i64>* %248 to <4 x i32>*
  %250 = load <4 x i32>, <4 x i32>* %249, align 16
  %251 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 30
  %252 = bitcast <2 x i64>* %251 to <4 x i32>*
  %253 = load <4 x i32>, <4 x i32>* %252, align 16
  %254 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %255 = bitcast <2 x i64>* %254 to <4 x i32>*
  %256 = load <4 x i32>, <4 x i32>* %255, align 16
  %257 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 17
  %258 = bitcast <2 x i64>* %257 to <4 x i32>*
  %259 = load <4 x i32>, <4 x i32>* %258, align 16
  %260 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %261 = bitcast <2 x i64>* %260 to <4 x i32>*
  %262 = load <4 x i32>, <4 x i32>* %261, align 16
  %263 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 25
  %264 = bitcast <2 x i64>* %263 to <4 x i32>*
  %265 = load <4 x i32>, <4 x i32>* %264, align 16
  %266 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %267 = bitcast <2 x i64>* %266 to <4 x i32>*
  %268 = load <4 x i32>, <4 x i32>* %267, align 16
  %269 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 21
  %270 = bitcast <2 x i64>* %269 to <4 x i32>*
  %271 = load <4 x i32>, <4 x i32>* %270, align 16
  %272 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %273 = bitcast <2 x i64>* %272 to <4 x i32>*
  %274 = load <4 x i32>, <4 x i32>* %273, align 16
  %275 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 29
  %276 = bitcast <2 x i64>* %275 to <4 x i32>*
  %277 = load <4 x i32>, <4 x i32>* %276, align 16
  %278 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %279 = bitcast <2 x i64>* %278 to <4 x i32>*
  %280 = load <4 x i32>, <4 x i32>* %279, align 16
  %281 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 19
  %282 = bitcast <2 x i64>* %281 to <4 x i32>*
  %283 = load <4 x i32>, <4 x i32>* %282, align 16
  %284 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %285 = bitcast <2 x i64>* %284 to <4 x i32>*
  %286 = load <4 x i32>, <4 x i32>* %285, align 16
  %287 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 27
  %288 = bitcast <2 x i64>* %287 to <4 x i32>*
  %289 = load <4 x i32>, <4 x i32>* %288, align 16
  %290 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %291 = bitcast <2 x i64>* %290 to <4 x i32>*
  %292 = load <4 x i32>, <4 x i32>* %291, align 16
  %293 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 23
  %294 = bitcast <2 x i64>* %293 to <4 x i32>*
  %295 = load <4 x i32>, <4 x i32>* %294, align 16
  %296 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %297 = bitcast <2 x i64>* %296 to <4 x i32>*
  %298 = load <4 x i32>, <4 x i32>* %297, align 16
  %299 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 31
  %300 = bitcast <2 x i64>* %299 to <4 x i32>*
  %301 = load <4 x i32>, <4 x i32>* %300, align 16
  %302 = mul <4 x i32> %256, %12
  %303 = mul <4 x i32> %301, %96
  %304 = add <4 x i32> %302, %193
  %305 = add <4 x i32> %304, %303
  %306 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %305, i32 %2) #8
  %307 = mul <4 x i32> %259, %16
  %308 = mul <4 x i32> %298, %93
  %309 = add <4 x i32> %307, %193
  %310 = add <4 x i32> %309, %308
  %311 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %310, i32 %2) #8
  %312 = mul <4 x i32> %262, %20
  %313 = mul <4 x i32> %295, %90
  %314 = add <4 x i32> %312, %193
  %315 = add <4 x i32> %314, %313
  %316 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %315, i32 %2) #8
  %317 = mul <4 x i32> %265, %24
  %318 = mul <4 x i32> %292, %87
  %319 = add <4 x i32> %317, %193
  %320 = add <4 x i32> %319, %318
  %321 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %320, i32 %2) #8
  %322 = mul <4 x i32> %268, %28
  %323 = mul <4 x i32> %289, %84
  %324 = add <4 x i32> %322, %193
  %325 = add <4 x i32> %324, %323
  %326 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %325, i32 %2) #8
  %327 = mul <4 x i32> %271, %32
  %328 = mul <4 x i32> %286, %81
  %329 = add <4 x i32> %327, %193
  %330 = add <4 x i32> %329, %328
  %331 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %330, i32 %2) #8
  %332 = mul <4 x i32> %274, %36
  %333 = mul <4 x i32> %283, %78
  %334 = add <4 x i32> %332, %193
  %335 = add <4 x i32> %334, %333
  %336 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %335, i32 %2) #8
  %337 = mul <4 x i32> %277, %40
  %338 = mul <4 x i32> %280, %75
  %339 = add <4 x i32> %337, %193
  %340 = add <4 x i32> %339, %338
  %341 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %340, i32 %2) #8
  %342 = mul <4 x i32> %277, %44
  %343 = mul <4 x i32> %280, %40
  %344 = add <4 x i32> %342, %193
  %345 = add <4 x i32> %344, %343
  %346 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %345, i32 %2) #8
  %347 = mul <4 x i32> %274, %48
  %348 = mul <4 x i32> %283, %36
  %349 = add <4 x i32> %347, %193
  %350 = add <4 x i32> %349, %348
  %351 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %350, i32 %2) #8
  %352 = mul <4 x i32> %271, %52
  %353 = mul <4 x i32> %286, %32
  %354 = add <4 x i32> %352, %193
  %355 = add <4 x i32> %354, %353
  %356 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %355, i32 %2) #8
  %357 = mul <4 x i32> %268, %56
  %358 = mul <4 x i32> %289, %28
  %359 = add <4 x i32> %357, %193
  %360 = add <4 x i32> %359, %358
  %361 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %360, i32 %2) #8
  %362 = mul <4 x i32> %265, %60
  %363 = mul <4 x i32> %292, %24
  %364 = add <4 x i32> %362, %193
  %365 = add <4 x i32> %364, %363
  %366 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %365, i32 %2) #8
  %367 = mul <4 x i32> %262, %64
  %368 = mul <4 x i32> %295, %20
  %369 = add <4 x i32> %367, %193
  %370 = add <4 x i32> %369, %368
  %371 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %370, i32 %2) #8
  %372 = mul <4 x i32> %259, %68
  %373 = mul <4 x i32> %298, %16
  %374 = add <4 x i32> %372, %193
  %375 = add <4 x i32> %374, %373
  %376 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %375, i32 %2) #8
  %377 = mul <4 x i32> %256, %72
  %378 = mul <4 x i32> %301, %12
  %379 = add <4 x i32> %377, %193
  %380 = add <4 x i32> %379, %378
  %381 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %380, i32 %2) #8
  %382 = mul <4 x i32> %232, %100
  %383 = mul <4 x i32> %253, %140
  %384 = add <4 x i32> %382, %193
  %385 = add <4 x i32> %384, %383
  %386 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %385, i32 %2) #8
  %387 = mul <4 x i32> %235, %104
  %388 = mul <4 x i32> %250, %137
  %389 = add <4 x i32> %387, %193
  %390 = add <4 x i32> %389, %388
  %391 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %390, i32 %2) #8
  %392 = mul <4 x i32> %238, %108
  %393 = mul <4 x i32> %247, %134
  %394 = add <4 x i32> %392, %193
  %395 = add <4 x i32> %394, %393
  %396 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %395, i32 %2) #8
  %397 = mul <4 x i32> %241, %112
  %398 = mul <4 x i32> %244, %131
  %399 = add <4 x i32> %397, %193
  %400 = add <4 x i32> %399, %398
  %401 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %400, i32 %2) #8
  %402 = mul <4 x i32> %241, %116
  %403 = mul <4 x i32> %244, %112
  %404 = add <4 x i32> %402, %193
  %405 = add <4 x i32> %404, %403
  %406 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %405, i32 %2) #8
  %407 = mul <4 x i32> %238, %120
  %408 = mul <4 x i32> %247, %108
  %409 = add <4 x i32> %407, %193
  %410 = add <4 x i32> %409, %408
  %411 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %410, i32 %2) #8
  %412 = mul <4 x i32> %235, %124
  %413 = mul <4 x i32> %250, %104
  %414 = add <4 x i32> %412, %193
  %415 = add <4 x i32> %414, %413
  %416 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %415, i32 %2) #8
  %417 = mul <4 x i32> %232, %128
  %418 = mul <4 x i32> %253, %100
  %419 = add <4 x i32> %417, %193
  %420 = add <4 x i32> %419, %418
  %421 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %420, i32 %2) #8
  %422 = add <4 x i32> %311, %306
  %423 = sub <4 x i32> %306, %311
  %424 = icmp sgt <4 x i32> %422, %203
  %425 = select <4 x i1> %424, <4 x i32> %422, <4 x i32> %203
  %426 = icmp slt <4 x i32> %425, %206
  %427 = select <4 x i1> %426, <4 x i32> %425, <4 x i32> %206
  %428 = icmp sgt <4 x i32> %423, %203
  %429 = select <4 x i1> %428, <4 x i32> %423, <4 x i32> %203
  %430 = icmp slt <4 x i32> %429, %206
  %431 = select <4 x i1> %430, <4 x i32> %429, <4 x i32> %206
  %432 = add <4 x i32> %321, %316
  %433 = sub <4 x i32> %321, %316
  %434 = icmp sgt <4 x i32> %432, %203
  %435 = select <4 x i1> %434, <4 x i32> %432, <4 x i32> %203
  %436 = icmp slt <4 x i32> %435, %206
  %437 = select <4 x i1> %436, <4 x i32> %435, <4 x i32> %206
  %438 = icmp sgt <4 x i32> %433, %203
  %439 = select <4 x i1> %438, <4 x i32> %433, <4 x i32> %203
  %440 = icmp slt <4 x i32> %439, %206
  %441 = select <4 x i1> %440, <4 x i32> %439, <4 x i32> %206
  %442 = add <4 x i32> %331, %326
  %443 = sub <4 x i32> %326, %331
  %444 = icmp sgt <4 x i32> %442, %203
  %445 = select <4 x i1> %444, <4 x i32> %442, <4 x i32> %203
  %446 = icmp slt <4 x i32> %445, %206
  %447 = select <4 x i1> %446, <4 x i32> %445, <4 x i32> %206
  %448 = icmp sgt <4 x i32> %443, %203
  %449 = select <4 x i1> %448, <4 x i32> %443, <4 x i32> %203
  %450 = icmp slt <4 x i32> %449, %206
  %451 = select <4 x i1> %450, <4 x i32> %449, <4 x i32> %206
  %452 = add <4 x i32> %341, %336
  %453 = sub <4 x i32> %341, %336
  %454 = icmp sgt <4 x i32> %452, %203
  %455 = select <4 x i1> %454, <4 x i32> %452, <4 x i32> %203
  %456 = icmp slt <4 x i32> %455, %206
  %457 = select <4 x i1> %456, <4 x i32> %455, <4 x i32> %206
  %458 = icmp sgt <4 x i32> %453, %203
  %459 = select <4 x i1> %458, <4 x i32> %453, <4 x i32> %203
  %460 = icmp slt <4 x i32> %459, %206
  %461 = select <4 x i1> %460, <4 x i32> %459, <4 x i32> %206
  %462 = add <4 x i32> %351, %346
  %463 = sub <4 x i32> %346, %351
  %464 = icmp sgt <4 x i32> %462, %203
  %465 = select <4 x i1> %464, <4 x i32> %462, <4 x i32> %203
  %466 = icmp slt <4 x i32> %465, %206
  %467 = select <4 x i1> %466, <4 x i32> %465, <4 x i32> %206
  %468 = icmp sgt <4 x i32> %463, %203
  %469 = select <4 x i1> %468, <4 x i32> %463, <4 x i32> %203
  %470 = icmp slt <4 x i32> %469, %206
  %471 = select <4 x i1> %470, <4 x i32> %469, <4 x i32> %206
  %472 = add <4 x i32> %361, %356
  %473 = sub <4 x i32> %361, %356
  %474 = icmp sgt <4 x i32> %472, %203
  %475 = select <4 x i1> %474, <4 x i32> %472, <4 x i32> %203
  %476 = icmp slt <4 x i32> %475, %206
  %477 = select <4 x i1> %476, <4 x i32> %475, <4 x i32> %206
  %478 = icmp sgt <4 x i32> %473, %203
  %479 = select <4 x i1> %478, <4 x i32> %473, <4 x i32> %203
  %480 = icmp slt <4 x i32> %479, %206
  %481 = select <4 x i1> %480, <4 x i32> %479, <4 x i32> %206
  %482 = add <4 x i32> %371, %366
  %483 = sub <4 x i32> %366, %371
  %484 = icmp sgt <4 x i32> %482, %203
  %485 = select <4 x i1> %484, <4 x i32> %482, <4 x i32> %203
  %486 = icmp slt <4 x i32> %485, %206
  %487 = select <4 x i1> %486, <4 x i32> %485, <4 x i32> %206
  %488 = icmp sgt <4 x i32> %483, %203
  %489 = select <4 x i1> %488, <4 x i32> %483, <4 x i32> %203
  %490 = icmp slt <4 x i32> %489, %206
  %491 = select <4 x i1> %490, <4 x i32> %489, <4 x i32> %206
  %492 = add <4 x i32> %381, %376
  %493 = sub <4 x i32> %381, %376
  %494 = icmp sgt <4 x i32> %492, %203
  %495 = select <4 x i1> %494, <4 x i32> %492, <4 x i32> %203
  %496 = icmp slt <4 x i32> %495, %206
  %497 = select <4 x i1> %496, <4 x i32> %495, <4 x i32> %206
  %498 = icmp sgt <4 x i32> %493, %203
  %499 = select <4 x i1> %498, <4 x i32> %493, <4 x i32> %203
  %500 = icmp slt <4 x i32> %499, %206
  %501 = select <4 x i1> %500, <4 x i32> %499, <4 x i32> %206
  %502 = mul <4 x i32> %220, %144
  %503 = mul <4 x i32> %229, %162
  %504 = add <4 x i32> %502, %193
  %505 = add <4 x i32> %504, %503
  %506 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %505, i32 %2) #8
  %507 = mul <4 x i32> %223, %148
  %508 = mul <4 x i32> %226, %159
  %509 = add <4 x i32> %507, %193
  %510 = add <4 x i32> %509, %508
  %511 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %510, i32 %2) #8
  %512 = mul <4 x i32> %223, %152
  %513 = mul <4 x i32> %226, %148
  %514 = add <4 x i32> %512, %193
  %515 = add <4 x i32> %514, %513
  %516 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %515, i32 %2) #8
  %517 = mul <4 x i32> %220, %156
  %518 = mul <4 x i32> %229, %144
  %519 = add <4 x i32> %517, %193
  %520 = add <4 x i32> %519, %518
  %521 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %520, i32 %2) #8
  %522 = add <4 x i32> %391, %386
  %523 = sub <4 x i32> %386, %391
  %524 = icmp sgt <4 x i32> %522, %203
  %525 = select <4 x i1> %524, <4 x i32> %522, <4 x i32> %203
  %526 = icmp slt <4 x i32> %525, %206
  %527 = select <4 x i1> %526, <4 x i32> %525, <4 x i32> %206
  %528 = icmp sgt <4 x i32> %523, %203
  %529 = select <4 x i1> %528, <4 x i32> %523, <4 x i32> %203
  %530 = icmp slt <4 x i32> %529, %206
  %531 = select <4 x i1> %530, <4 x i32> %529, <4 x i32> %206
  %532 = add <4 x i32> %401, %396
  %533 = sub <4 x i32> %401, %396
  %534 = icmp sgt <4 x i32> %532, %203
  %535 = select <4 x i1> %534, <4 x i32> %532, <4 x i32> %203
  %536 = icmp slt <4 x i32> %535, %206
  %537 = select <4 x i1> %536, <4 x i32> %535, <4 x i32> %206
  %538 = icmp sgt <4 x i32> %533, %203
  %539 = select <4 x i1> %538, <4 x i32> %533, <4 x i32> %203
  %540 = icmp slt <4 x i32> %539, %206
  %541 = select <4 x i1> %540, <4 x i32> %539, <4 x i32> %206
  %542 = add <4 x i32> %411, %406
  %543 = sub <4 x i32> %406, %411
  %544 = icmp sgt <4 x i32> %542, %203
  %545 = select <4 x i1> %544, <4 x i32> %542, <4 x i32> %203
  %546 = icmp slt <4 x i32> %545, %206
  %547 = select <4 x i1> %546, <4 x i32> %545, <4 x i32> %206
  %548 = icmp sgt <4 x i32> %543, %203
  %549 = select <4 x i1> %548, <4 x i32> %543, <4 x i32> %203
  %550 = icmp slt <4 x i32> %549, %206
  %551 = select <4 x i1> %550, <4 x i32> %549, <4 x i32> %206
  %552 = add <4 x i32> %421, %416
  %553 = sub <4 x i32> %421, %416
  %554 = icmp sgt <4 x i32> %552, %203
  %555 = select <4 x i1> %554, <4 x i32> %552, <4 x i32> %203
  %556 = icmp slt <4 x i32> %555, %206
  %557 = select <4 x i1> %556, <4 x i32> %555, <4 x i32> %206
  %558 = icmp sgt <4 x i32> %553, %203
  %559 = select <4 x i1> %558, <4 x i32> %553, <4 x i32> %203
  %560 = icmp slt <4 x i32> %559, %206
  %561 = select <4 x i1> %560, <4 x i32> %559, <4 x i32> %206
  %562 = mul <4 x i32> %431, %162
  %563 = mul <4 x i32> %501, %144
  %564 = add <4 x i32> %562, %193
  %565 = add <4 x i32> %564, %563
  %566 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %565, i32 %2) #8
  %567 = mul <4 x i32> %441, %165
  %568 = mul <4 x i32> %491, %162
  %569 = add <4 x i32> %567, %193
  %570 = add <4 x i32> %569, %568
  %571 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %570, i32 %2) #8
  %572 = mul <4 x i32> %451, %159
  %573 = mul <4 x i32> %481, %148
  %574 = add <4 x i32> %572, %193
  %575 = add <4 x i32> %574, %573
  %576 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %575, i32 %2) #8
  %577 = mul <4 x i32> %461, %168
  %578 = mul <4 x i32> %471, %159
  %579 = add <4 x i32> %577, %193
  %580 = add <4 x i32> %579, %578
  %581 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %580, i32 %2) #8
  %582 = mul <4 x i32> %461, %159
  %583 = mul <4 x i32> %471, %148
  %584 = add <4 x i32> %582, %193
  %585 = add <4 x i32> %584, %583
  %586 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %585, i32 %2) #8
  %587 = mul <4 x i32> %451, %148
  %588 = mul <4 x i32> %481, %152
  %589 = add <4 x i32> %587, %193
  %590 = add <4 x i32> %589, %588
  %591 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %590, i32 %2) #8
  %592 = mul <4 x i32> %441, %162
  %593 = mul <4 x i32> %491, %144
  %594 = add <4 x i32> %592, %193
  %595 = add <4 x i32> %594, %593
  %596 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %595, i32 %2) #8
  %597 = mul <4 x i32> %431, %144
  %598 = mul <4 x i32> %501, %156
  %599 = add <4 x i32> %597, %193
  %600 = add <4 x i32> %599, %598
  %601 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %600, i32 %2) #8
  %602 = mul <4 x i32> %208, %172
  %603 = mul <4 x i32> %211, %172
  %604 = add <4 x i32> %602, %193
  %605 = add <4 x i32> %604, %603
  %606 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %605, i32 %2) #8
  %607 = mul <4 x i32> %211, %175
  %608 = add <4 x i32> %604, %607
  %609 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %608, i32 %2) #8
  %610 = mul <4 x i32> %214, %179
  %611 = mul <4 x i32> %217, %189
  %612 = add <4 x i32> %610, %193
  %613 = add <4 x i32> %612, %611
  %614 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %613, i32 %2) #8
  %615 = mul <4 x i32> %214, %186
  %616 = mul <4 x i32> %217, %179
  %617 = add <4 x i32> %615, %193
  %618 = add <4 x i32> %617, %616
  %619 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %618, i32 %2) #8
  %620 = add <4 x i32> %511, %506
  %621 = sub <4 x i32> %506, %511
  %622 = icmp sgt <4 x i32> %620, %203
  %623 = select <4 x i1> %622, <4 x i32> %620, <4 x i32> %203
  %624 = icmp slt <4 x i32> %623, %206
  %625 = select <4 x i1> %624, <4 x i32> %623, <4 x i32> %206
  %626 = icmp sgt <4 x i32> %621, %203
  %627 = select <4 x i1> %626, <4 x i32> %621, <4 x i32> %203
  %628 = icmp slt <4 x i32> %627, %206
  %629 = select <4 x i1> %628, <4 x i32> %627, <4 x i32> %206
  %630 = add <4 x i32> %521, %516
  %631 = sub <4 x i32> %521, %516
  %632 = icmp sgt <4 x i32> %630, %203
  %633 = select <4 x i1> %632, <4 x i32> %630, <4 x i32> %203
  %634 = icmp slt <4 x i32> %633, %206
  %635 = select <4 x i1> %634, <4 x i32> %633, <4 x i32> %206
  %636 = icmp sgt <4 x i32> %631, %203
  %637 = select <4 x i1> %636, <4 x i32> %631, <4 x i32> %203
  %638 = icmp slt <4 x i32> %637, %206
  %639 = select <4 x i1> %638, <4 x i32> %637, <4 x i32> %206
  %640 = mul <4 x i32> %531, %189
  %641 = mul <4 x i32> %561, %179
  %642 = add <4 x i32> %640, %193
  %643 = add <4 x i32> %642, %641
  %644 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %643, i32 %2) #8
  %645 = mul <4 x i32> %541, %182
  %646 = mul <4 x i32> %551, %189
  %647 = add <4 x i32> %645, %193
  %648 = add <4 x i32> %647, %646
  %649 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %648, i32 %2) #8
  %650 = mul <4 x i32> %541, %189
  %651 = mul <4 x i32> %551, %179
  %652 = add <4 x i32> %650, %193
  %653 = add <4 x i32> %652, %651
  %654 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %653, i32 %2) #8
  %655 = mul <4 x i32> %531, %179
  %656 = mul <4 x i32> %561, %186
  %657 = add <4 x i32> %655, %193
  %658 = add <4 x i32> %657, %656
  %659 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %658, i32 %2) #8
  %660 = add <4 x i32> %437, %427
  %661 = sub <4 x i32> %427, %437
  %662 = icmp sgt <4 x i32> %660, %203
  %663 = select <4 x i1> %662, <4 x i32> %660, <4 x i32> %203
  %664 = icmp slt <4 x i32> %663, %206
  %665 = select <4 x i1> %664, <4 x i32> %663, <4 x i32> %206
  %666 = icmp sgt <4 x i32> %661, %203
  %667 = select <4 x i1> %666, <4 x i32> %661, <4 x i32> %203
  %668 = icmp slt <4 x i32> %667, %206
  %669 = select <4 x i1> %668, <4 x i32> %667, <4 x i32> %206
  %670 = add <4 x i32> %571, %566
  %671 = sub <4 x i32> %566, %571
  %672 = icmp sgt <4 x i32> %670, %203
  %673 = select <4 x i1> %672, <4 x i32> %670, <4 x i32> %203
  %674 = icmp slt <4 x i32> %673, %206
  %675 = select <4 x i1> %674, <4 x i32> %673, <4 x i32> %206
  %676 = icmp sgt <4 x i32> %671, %203
  %677 = select <4 x i1> %676, <4 x i32> %671, <4 x i32> %203
  %678 = icmp slt <4 x i32> %677, %206
  %679 = select <4 x i1> %678, <4 x i32> %677, <4 x i32> %206
  %680 = add <4 x i32> %457, %447
  %681 = sub <4 x i32> %457, %447
  %682 = icmp sgt <4 x i32> %680, %203
  %683 = select <4 x i1> %682, <4 x i32> %680, <4 x i32> %203
  %684 = icmp slt <4 x i32> %683, %206
  %685 = select <4 x i1> %684, <4 x i32> %683, <4 x i32> %206
  %686 = icmp sgt <4 x i32> %681, %203
  %687 = select <4 x i1> %686, <4 x i32> %681, <4 x i32> %203
  %688 = icmp slt <4 x i32> %687, %206
  %689 = select <4 x i1> %688, <4 x i32> %687, <4 x i32> %206
  %690 = add <4 x i32> %581, %576
  %691 = sub <4 x i32> %581, %576
  %692 = icmp sgt <4 x i32> %690, %203
  %693 = select <4 x i1> %692, <4 x i32> %690, <4 x i32> %203
  %694 = icmp slt <4 x i32> %693, %206
  %695 = select <4 x i1> %694, <4 x i32> %693, <4 x i32> %206
  %696 = icmp sgt <4 x i32> %691, %203
  %697 = select <4 x i1> %696, <4 x i32> %691, <4 x i32> %203
  %698 = icmp slt <4 x i32> %697, %206
  %699 = select <4 x i1> %698, <4 x i32> %697, <4 x i32> %206
  %700 = add <4 x i32> %477, %467
  %701 = sub <4 x i32> %467, %477
  %702 = icmp sgt <4 x i32> %700, %203
  %703 = select <4 x i1> %702, <4 x i32> %700, <4 x i32> %203
  %704 = icmp slt <4 x i32> %703, %206
  %705 = select <4 x i1> %704, <4 x i32> %703, <4 x i32> %206
  %706 = icmp sgt <4 x i32> %701, %203
  %707 = select <4 x i1> %706, <4 x i32> %701, <4 x i32> %203
  %708 = icmp slt <4 x i32> %707, %206
  %709 = select <4 x i1> %708, <4 x i32> %707, <4 x i32> %206
  %710 = add <4 x i32> %591, %586
  %711 = sub <4 x i32> %586, %591
  %712 = icmp sgt <4 x i32> %710, %203
  %713 = select <4 x i1> %712, <4 x i32> %710, <4 x i32> %203
  %714 = icmp slt <4 x i32> %713, %206
  %715 = select <4 x i1> %714, <4 x i32> %713, <4 x i32> %206
  %716 = icmp sgt <4 x i32> %711, %203
  %717 = select <4 x i1> %716, <4 x i32> %711, <4 x i32> %203
  %718 = icmp slt <4 x i32> %717, %206
  %719 = select <4 x i1> %718, <4 x i32> %717, <4 x i32> %206
  %720 = add <4 x i32> %497, %487
  %721 = sub <4 x i32> %497, %487
  %722 = icmp sgt <4 x i32> %720, %203
  %723 = select <4 x i1> %722, <4 x i32> %720, <4 x i32> %203
  %724 = icmp slt <4 x i32> %723, %206
  %725 = select <4 x i1> %724, <4 x i32> %723, <4 x i32> %206
  %726 = icmp sgt <4 x i32> %721, %203
  %727 = select <4 x i1> %726, <4 x i32> %721, <4 x i32> %203
  %728 = icmp slt <4 x i32> %727, %206
  %729 = select <4 x i1> %728, <4 x i32> %727, <4 x i32> %206
  %730 = add <4 x i32> %601, %596
  %731 = sub <4 x i32> %601, %596
  %732 = icmp sgt <4 x i32> %730, %203
  %733 = select <4 x i1> %732, <4 x i32> %730, <4 x i32> %203
  %734 = icmp slt <4 x i32> %733, %206
  %735 = select <4 x i1> %734, <4 x i32> %733, <4 x i32> %206
  %736 = icmp sgt <4 x i32> %731, %203
  %737 = select <4 x i1> %736, <4 x i32> %731, <4 x i32> %203
  %738 = icmp slt <4 x i32> %737, %206
  %739 = select <4 x i1> %738, <4 x i32> %737, <4 x i32> %206
  %740 = add <4 x i32> %619, %606
  %741 = sub <4 x i32> %606, %619
  %742 = icmp sgt <4 x i32> %740, %203
  %743 = select <4 x i1> %742, <4 x i32> %740, <4 x i32> %203
  %744 = icmp slt <4 x i32> %743, %206
  %745 = select <4 x i1> %744, <4 x i32> %743, <4 x i32> %206
  %746 = icmp sgt <4 x i32> %741, %203
  %747 = select <4 x i1> %746, <4 x i32> %741, <4 x i32> %203
  %748 = icmp slt <4 x i32> %747, %206
  %749 = select <4 x i1> %748, <4 x i32> %747, <4 x i32> %206
  %750 = add <4 x i32> %614, %609
  %751 = sub <4 x i32> %609, %614
  %752 = icmp sgt <4 x i32> %750, %203
  %753 = select <4 x i1> %752, <4 x i32> %750, <4 x i32> %203
  %754 = icmp slt <4 x i32> %753, %206
  %755 = select <4 x i1> %754, <4 x i32> %753, <4 x i32> %206
  %756 = icmp sgt <4 x i32> %751, %203
  %757 = select <4 x i1> %756, <4 x i32> %751, <4 x i32> %203
  %758 = icmp slt <4 x i32> %757, %206
  %759 = select <4 x i1> %758, <4 x i32> %757, <4 x i32> %206
  %760 = mul <4 x i32> %629, %175
  %761 = mul <4 x i32> %639, %172
  %762 = add <4 x i32> %761, %193
  %763 = add <4 x i32> %762, %760
  %764 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %763, i32 %2) #8
  %765 = mul <4 x i32> %629, %172
  %766 = add <4 x i32> %762, %765
  %767 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %766, i32 %2) #8
  %768 = add <4 x i32> %537, %527
  %769 = sub <4 x i32> %527, %537
  %770 = icmp sgt <4 x i32> %768, %203
  %771 = select <4 x i1> %770, <4 x i32> %768, <4 x i32> %203
  %772 = icmp slt <4 x i32> %771, %206
  %773 = select <4 x i1> %772, <4 x i32> %771, <4 x i32> %206
  %774 = icmp sgt <4 x i32> %769, %203
  %775 = select <4 x i1> %774, <4 x i32> %769, <4 x i32> %203
  %776 = icmp slt <4 x i32> %775, %206
  %777 = select <4 x i1> %776, <4 x i32> %775, <4 x i32> %206
  %778 = add <4 x i32> %649, %644
  %779 = sub <4 x i32> %644, %649
  %780 = icmp sgt <4 x i32> %778, %203
  %781 = select <4 x i1> %780, <4 x i32> %778, <4 x i32> %203
  %782 = icmp slt <4 x i32> %781, %206
  %783 = select <4 x i1> %782, <4 x i32> %781, <4 x i32> %206
  %784 = icmp sgt <4 x i32> %779, %203
  %785 = select <4 x i1> %784, <4 x i32> %779, <4 x i32> %203
  %786 = icmp slt <4 x i32> %785, %206
  %787 = select <4 x i1> %786, <4 x i32> %785, <4 x i32> %206
  %788 = add <4 x i32> %557, %547
  %789 = sub <4 x i32> %557, %547
  %790 = icmp sgt <4 x i32> %788, %203
  %791 = select <4 x i1> %790, <4 x i32> %788, <4 x i32> %203
  %792 = icmp slt <4 x i32> %791, %206
  %793 = select <4 x i1> %792, <4 x i32> %791, <4 x i32> %206
  %794 = icmp sgt <4 x i32> %789, %203
  %795 = select <4 x i1> %794, <4 x i32> %789, <4 x i32> %203
  %796 = icmp slt <4 x i32> %795, %206
  %797 = select <4 x i1> %796, <4 x i32> %795, <4 x i32> %206
  %798 = add <4 x i32> %659, %654
  %799 = sub <4 x i32> %659, %654
  %800 = icmp sgt <4 x i32> %798, %203
  %801 = select <4 x i1> %800, <4 x i32> %798, <4 x i32> %203
  %802 = icmp slt <4 x i32> %801, %206
  %803 = select <4 x i1> %802, <4 x i32> %801, <4 x i32> %206
  %804 = icmp sgt <4 x i32> %799, %203
  %805 = select <4 x i1> %804, <4 x i32> %799, <4 x i32> %203
  %806 = icmp slt <4 x i32> %805, %206
  %807 = select <4 x i1> %806, <4 x i32> %805, <4 x i32> %206
  %808 = mul <4 x i32> %679, %189
  %809 = mul <4 x i32> %739, %179
  %810 = add <4 x i32> %808, %193
  %811 = add <4 x i32> %810, %809
  %812 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %811, i32 %2) #8
  %813 = mul <4 x i32> %669, %189
  %814 = mul <4 x i32> %729, %179
  %815 = add <4 x i32> %813, %193
  %816 = add <4 x i32> %815, %814
  %817 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %816, i32 %2) #8
  %818 = mul <4 x i32> %689, %182
  %819 = mul <4 x i32> %709, %189
  %820 = add <4 x i32> %818, %193
  %821 = add <4 x i32> %820, %819
  %822 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %821, i32 %2) #8
  %823 = mul <4 x i32> %699, %182
  %824 = mul <4 x i32> %719, %189
  %825 = add <4 x i32> %823, %193
  %826 = add <4 x i32> %825, %824
  %827 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %826, i32 %2) #8
  %828 = mul <4 x i32> %699, %189
  %829 = mul <4 x i32> %719, %179
  %830 = add <4 x i32> %828, %193
  %831 = add <4 x i32> %830, %829
  %832 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %831, i32 %2) #8
  %833 = mul <4 x i32> %689, %189
  %834 = mul <4 x i32> %709, %179
  %835 = add <4 x i32> %833, %193
  %836 = add <4 x i32> %835, %834
  %837 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %836, i32 %2) #8
  %838 = mul <4 x i32> %669, %179
  %839 = mul <4 x i32> %729, %186
  %840 = add <4 x i32> %838, %193
  %841 = add <4 x i32> %840, %839
  %842 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %841, i32 %2) #8
  %843 = mul <4 x i32> %679, %179
  %844 = mul <4 x i32> %739, %186
  %845 = add <4 x i32> %843, %193
  %846 = add <4 x i32> %845, %844
  %847 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %846, i32 %2) #8
  %848 = add <4 x i32> %745, %635
  %849 = sub <4 x i32> %745, %635
  %850 = icmp sgt <4 x i32> %848, %203
  %851 = select <4 x i1> %850, <4 x i32> %848, <4 x i32> %203
  %852 = icmp slt <4 x i32> %851, %206
  %853 = select <4 x i1> %852, <4 x i32> %851, <4 x i32> %206
  %854 = icmp sgt <4 x i32> %849, %203
  %855 = select <4 x i1> %854, <4 x i32> %849, <4 x i32> %203
  %856 = icmp slt <4 x i32> %855, %206
  %857 = select <4 x i1> %856, <4 x i32> %855, <4 x i32> %206
  %858 = add <4 x i32> %767, %755
  %859 = sub <4 x i32> %755, %767
  %860 = icmp sgt <4 x i32> %858, %203
  %861 = select <4 x i1> %860, <4 x i32> %858, <4 x i32> %203
  %862 = icmp slt <4 x i32> %861, %206
  %863 = select <4 x i1> %862, <4 x i32> %861, <4 x i32> %206
  %864 = icmp sgt <4 x i32> %859, %203
  %865 = select <4 x i1> %864, <4 x i32> %859, <4 x i32> %203
  %866 = icmp slt <4 x i32> %865, %206
  %867 = select <4 x i1> %866, <4 x i32> %865, <4 x i32> %206
  %868 = add <4 x i32> %764, %759
  %869 = sub <4 x i32> %759, %764
  %870 = icmp sgt <4 x i32> %868, %203
  %871 = select <4 x i1> %870, <4 x i32> %868, <4 x i32> %203
  %872 = icmp slt <4 x i32> %871, %206
  %873 = select <4 x i1> %872, <4 x i32> %871, <4 x i32> %206
  %874 = icmp sgt <4 x i32> %869, %203
  %875 = select <4 x i1> %874, <4 x i32> %869, <4 x i32> %203
  %876 = icmp slt <4 x i32> %875, %206
  %877 = select <4 x i1> %876, <4 x i32> %875, <4 x i32> %206
  %878 = add <4 x i32> %749, %625
  %879 = sub <4 x i32> %749, %625
  %880 = icmp sgt <4 x i32> %878, %203
  %881 = select <4 x i1> %880, <4 x i32> %878, <4 x i32> %203
  %882 = icmp slt <4 x i32> %881, %206
  %883 = select <4 x i1> %882, <4 x i32> %881, <4 x i32> %206
  %884 = icmp sgt <4 x i32> %879, %203
  %885 = select <4 x i1> %884, <4 x i32> %879, <4 x i32> %203
  %886 = icmp slt <4 x i32> %885, %206
  %887 = select <4 x i1> %886, <4 x i32> %885, <4 x i32> %206
  %888 = mul <4 x i32> %787, %175
  %889 = mul <4 x i32> %807, %172
  %890 = add <4 x i32> %889, %193
  %891 = add <4 x i32> %890, %888
  %892 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %891, i32 %2) #8
  %893 = mul <4 x i32> %777, %175
  %894 = mul <4 x i32> %797, %172
  %895 = add <4 x i32> %894, %193
  %896 = add <4 x i32> %895, %893
  %897 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %896, i32 %2) #8
  %898 = mul <4 x i32> %777, %172
  %899 = add <4 x i32> %895, %898
  %900 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %899, i32 %2) #8
  %901 = mul <4 x i32> %787, %172
  %902 = add <4 x i32> %890, %901
  %903 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %902, i32 %2) #8
  %904 = add <4 x i32> %685, %665
  %905 = sub <4 x i32> %665, %685
  %906 = icmp sgt <4 x i32> %904, %203
  %907 = select <4 x i1> %906, <4 x i32> %904, <4 x i32> %203
  %908 = icmp slt <4 x i32> %907, %206
  %909 = select <4 x i1> %908, <4 x i32> %907, <4 x i32> %206
  %910 = icmp sgt <4 x i32> %905, %203
  %911 = select <4 x i1> %910, <4 x i32> %905, <4 x i32> %203
  %912 = icmp slt <4 x i32> %911, %206
  %913 = select <4 x i1> %912, <4 x i32> %911, <4 x i32> %206
  %914 = add <4 x i32> %695, %675
  %915 = sub <4 x i32> %675, %695
  %916 = icmp sgt <4 x i32> %914, %203
  %917 = select <4 x i1> %916, <4 x i32> %914, <4 x i32> %203
  %918 = icmp slt <4 x i32> %917, %206
  %919 = select <4 x i1> %918, <4 x i32> %917, <4 x i32> %206
  %920 = icmp sgt <4 x i32> %915, %203
  %921 = select <4 x i1> %920, <4 x i32> %915, <4 x i32> %203
  %922 = icmp slt <4 x i32> %921, %206
  %923 = select <4 x i1> %922, <4 x i32> %921, <4 x i32> %206
  %924 = add <4 x i32> %827, %812
  %925 = sub <4 x i32> %812, %827
  %926 = icmp sgt <4 x i32> %924, %203
  %927 = select <4 x i1> %926, <4 x i32> %924, <4 x i32> %203
  %928 = icmp slt <4 x i32> %927, %206
  %929 = select <4 x i1> %928, <4 x i32> %927, <4 x i32> %206
  %930 = icmp sgt <4 x i32> %925, %203
  %931 = select <4 x i1> %930, <4 x i32> %925, <4 x i32> %203
  %932 = icmp slt <4 x i32> %931, %206
  %933 = select <4 x i1> %932, <4 x i32> %931, <4 x i32> %206
  %934 = add <4 x i32> %822, %817
  %935 = sub <4 x i32> %817, %822
  %936 = icmp sgt <4 x i32> %934, %203
  %937 = select <4 x i1> %936, <4 x i32> %934, <4 x i32> %203
  %938 = icmp slt <4 x i32> %937, %206
  %939 = select <4 x i1> %938, <4 x i32> %937, <4 x i32> %206
  %940 = icmp sgt <4 x i32> %935, %203
  %941 = select <4 x i1> %940, <4 x i32> %935, <4 x i32> %203
  %942 = icmp slt <4 x i32> %941, %206
  %943 = select <4 x i1> %942, <4 x i32> %941, <4 x i32> %206
  %944 = add <4 x i32> %725, %705
  %945 = sub <4 x i32> %725, %705
  %946 = icmp sgt <4 x i32> %944, %203
  %947 = select <4 x i1> %946, <4 x i32> %944, <4 x i32> %203
  %948 = icmp slt <4 x i32> %947, %206
  %949 = select <4 x i1> %948, <4 x i32> %947, <4 x i32> %206
  %950 = icmp sgt <4 x i32> %945, %203
  %951 = select <4 x i1> %950, <4 x i32> %945, <4 x i32> %203
  %952 = icmp slt <4 x i32> %951, %206
  %953 = select <4 x i1> %952, <4 x i32> %951, <4 x i32> %206
  %954 = add <4 x i32> %735, %715
  %955 = sub <4 x i32> %735, %715
  %956 = icmp sgt <4 x i32> %954, %203
  %957 = select <4 x i1> %956, <4 x i32> %954, <4 x i32> %203
  %958 = icmp slt <4 x i32> %957, %206
  %959 = select <4 x i1> %958, <4 x i32> %957, <4 x i32> %206
  %960 = icmp sgt <4 x i32> %955, %203
  %961 = select <4 x i1> %960, <4 x i32> %955, <4 x i32> %203
  %962 = icmp slt <4 x i32> %961, %206
  %963 = select <4 x i1> %962, <4 x i32> %961, <4 x i32> %206
  %964 = add <4 x i32> %847, %832
  %965 = sub <4 x i32> %847, %832
  %966 = icmp sgt <4 x i32> %964, %203
  %967 = select <4 x i1> %966, <4 x i32> %964, <4 x i32> %203
  %968 = icmp slt <4 x i32> %967, %206
  %969 = select <4 x i1> %968, <4 x i32> %967, <4 x i32> %206
  %970 = icmp sgt <4 x i32> %965, %203
  %971 = select <4 x i1> %970, <4 x i32> %965, <4 x i32> %203
  %972 = icmp slt <4 x i32> %971, %206
  %973 = select <4 x i1> %972, <4 x i32> %971, <4 x i32> %206
  %974 = add <4 x i32> %842, %837
  %975 = sub <4 x i32> %842, %837
  %976 = icmp sgt <4 x i32> %974, %203
  %977 = select <4 x i1> %976, <4 x i32> %974, <4 x i32> %203
  %978 = icmp slt <4 x i32> %977, %206
  %979 = select <4 x i1> %978, <4 x i32> %977, <4 x i32> %206
  %980 = icmp sgt <4 x i32> %975, %203
  %981 = select <4 x i1> %980, <4 x i32> %975, <4 x i32> %203
  %982 = icmp slt <4 x i32> %981, %206
  %983 = select <4 x i1> %982, <4 x i32> %981, <4 x i32> %206
  %984 = add <4 x i32> %853, %793
  %985 = sub <4 x i32> %853, %793
  %986 = icmp sgt <4 x i32> %984, %203
  %987 = select <4 x i1> %986, <4 x i32> %984, <4 x i32> %203
  %988 = icmp slt <4 x i32> %987, %206
  %989 = select <4 x i1> %988, <4 x i32> %987, <4 x i32> %206
  %990 = icmp sgt <4 x i32> %985, %203
  %991 = select <4 x i1> %990, <4 x i32> %985, <4 x i32> %203
  %992 = icmp slt <4 x i32> %991, %206
  %993 = select <4 x i1> %992, <4 x i32> %991, <4 x i32> %206
  %994 = add <4 x i32> %863, %803
  %995 = sub <4 x i32> %863, %803
  %996 = icmp sgt <4 x i32> %994, %203
  %997 = select <4 x i1> %996, <4 x i32> %994, <4 x i32> %203
  %998 = icmp slt <4 x i32> %997, %206
  %999 = select <4 x i1> %998, <4 x i32> %997, <4 x i32> %206
  %1000 = icmp sgt <4 x i32> %995, %203
  %1001 = select <4 x i1> %1000, <4 x i32> %995, <4 x i32> %203
  %1002 = icmp slt <4 x i32> %1001, %206
  %1003 = select <4 x i1> %1002, <4 x i32> %1001, <4 x i32> %206
  %1004 = add <4 x i32> %903, %873
  %1005 = sub <4 x i32> %873, %903
  %1006 = icmp sgt <4 x i32> %1004, %203
  %1007 = select <4 x i1> %1006, <4 x i32> %1004, <4 x i32> %203
  %1008 = icmp slt <4 x i32> %1007, %206
  %1009 = select <4 x i1> %1008, <4 x i32> %1007, <4 x i32> %206
  %1010 = icmp sgt <4 x i32> %1005, %203
  %1011 = select <4 x i1> %1010, <4 x i32> %1005, <4 x i32> %203
  %1012 = icmp slt <4 x i32> %1011, %206
  %1013 = select <4 x i1> %1012, <4 x i32> %1011, <4 x i32> %206
  %1014 = add <4 x i32> %900, %883
  %1015 = sub <4 x i32> %883, %900
  %1016 = icmp sgt <4 x i32> %1014, %203
  %1017 = select <4 x i1> %1016, <4 x i32> %1014, <4 x i32> %203
  %1018 = icmp slt <4 x i32> %1017, %206
  %1019 = select <4 x i1> %1018, <4 x i32> %1017, <4 x i32> %206
  %1020 = icmp sgt <4 x i32> %1015, %203
  %1021 = select <4 x i1> %1020, <4 x i32> %1015, <4 x i32> %203
  %1022 = icmp slt <4 x i32> %1021, %206
  %1023 = select <4 x i1> %1022, <4 x i32> %1021, <4 x i32> %206
  %1024 = add <4 x i32> %897, %887
  %1025 = sub <4 x i32> %887, %897
  %1026 = icmp sgt <4 x i32> %1024, %203
  %1027 = select <4 x i1> %1026, <4 x i32> %1024, <4 x i32> %203
  %1028 = icmp slt <4 x i32> %1027, %206
  %1029 = select <4 x i1> %1028, <4 x i32> %1027, <4 x i32> %206
  %1030 = icmp sgt <4 x i32> %1025, %203
  %1031 = select <4 x i1> %1030, <4 x i32> %1025, <4 x i32> %203
  %1032 = icmp slt <4 x i32> %1031, %206
  %1033 = select <4 x i1> %1032, <4 x i32> %1031, <4 x i32> %206
  %1034 = add <4 x i32> %892, %877
  %1035 = sub <4 x i32> %877, %892
  %1036 = icmp sgt <4 x i32> %1034, %203
  %1037 = select <4 x i1> %1036, <4 x i32> %1034, <4 x i32> %203
  %1038 = icmp slt <4 x i32> %1037, %206
  %1039 = select <4 x i1> %1038, <4 x i32> %1037, <4 x i32> %206
  %1040 = icmp sgt <4 x i32> %1035, %203
  %1041 = select <4 x i1> %1040, <4 x i32> %1035, <4 x i32> %203
  %1042 = icmp slt <4 x i32> %1041, %206
  %1043 = select <4 x i1> %1042, <4 x i32> %1041, <4 x i32> %206
  %1044 = add <4 x i32> %867, %783
  %1045 = sub <4 x i32> %867, %783
  %1046 = icmp sgt <4 x i32> %1044, %203
  %1047 = select <4 x i1> %1046, <4 x i32> %1044, <4 x i32> %203
  %1048 = icmp slt <4 x i32> %1047, %206
  %1049 = select <4 x i1> %1048, <4 x i32> %1047, <4 x i32> %206
  %1050 = icmp sgt <4 x i32> %1045, %203
  %1051 = select <4 x i1> %1050, <4 x i32> %1045, <4 x i32> %203
  %1052 = icmp slt <4 x i32> %1051, %206
  %1053 = select <4 x i1> %1052, <4 x i32> %1051, <4 x i32> %206
  %1054 = add <4 x i32> %857, %773
  %1055 = sub <4 x i32> %857, %773
  %1056 = icmp sgt <4 x i32> %1054, %203
  %1057 = select <4 x i1> %1056, <4 x i32> %1054, <4 x i32> %203
  %1058 = icmp slt <4 x i32> %1057, %206
  %1059 = select <4 x i1> %1058, <4 x i32> %1057, <4 x i32> %206
  %1060 = icmp sgt <4 x i32> %1055, %203
  %1061 = select <4 x i1> %1060, <4 x i32> %1055, <4 x i32> %203
  %1062 = icmp slt <4 x i32> %1061, %206
  %1063 = select <4 x i1> %1062, <4 x i32> %1061, <4 x i32> %206
  %1064 = mul <4 x i32> %943, %175
  %1065 = mul <4 x i32> %983, %172
  %1066 = add <4 x i32> %1065, %193
  %1067 = add <4 x i32> %1066, %1064
  %1068 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1067, i32 %2) #8
  %1069 = mul <4 x i32> %933, %175
  %1070 = mul <4 x i32> %973, %172
  %1071 = add <4 x i32> %1070, %193
  %1072 = add <4 x i32> %1071, %1069
  %1073 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1072, i32 %2) #8
  %1074 = mul <4 x i32> %923, %175
  %1075 = mul <4 x i32> %963, %172
  %1076 = add <4 x i32> %1075, %193
  %1077 = add <4 x i32> %1076, %1074
  %1078 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1077, i32 %2) #8
  %1079 = mul <4 x i32> %913, %175
  %1080 = mul <4 x i32> %953, %172
  %1081 = add <4 x i32> %1080, %193
  %1082 = add <4 x i32> %1081, %1079
  %1083 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1082, i32 %2) #8
  %1084 = mul <4 x i32> %913, %172
  %1085 = add <4 x i32> %1081, %1084
  %1086 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1085, i32 %2) #8
  %1087 = mul <4 x i32> %923, %172
  %1088 = add <4 x i32> %1076, %1087
  %1089 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1088, i32 %2) #8
  %1090 = mul <4 x i32> %933, %172
  %1091 = add <4 x i32> %1071, %1090
  %1092 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1091, i32 %2) #8
  %1093 = mul <4 x i32> %943, %172
  %1094 = add <4 x i32> %1066, %1093
  %1095 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1094, i32 %2) #8
  %1096 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 31
  %1097 = add <4 x i32> %989, %949
  %1098 = sub <4 x i32> %989, %949
  %1099 = icmp sgt <4 x i32> %1097, %203
  %1100 = select <4 x i1> %1099, <4 x i32> %1097, <4 x i32> %203
  %1101 = icmp slt <4 x i32> %1100, %206
  %1102 = select <4 x i1> %1101, <4 x i32> %1100, <4 x i32> %206
  %1103 = icmp sgt <4 x i32> %1098, %203
  %1104 = select <4 x i1> %1103, <4 x i32> %1098, <4 x i32> %203
  %1105 = icmp slt <4 x i32> %1104, %206
  %1106 = select <4 x i1> %1105, <4 x i32> %1104, <4 x i32> %206
  %1107 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %1102, <4 x i32>* %1107, align 16
  %1108 = bitcast <2 x i64>* %1096 to <4 x i32>*
  store <4 x i32> %1106, <4 x i32>* %1108, align 16
  %1109 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %1110 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 30
  %1111 = add <4 x i32> %999, %959
  %1112 = sub <4 x i32> %999, %959
  %1113 = icmp sgt <4 x i32> %1111, %203
  %1114 = select <4 x i1> %1113, <4 x i32> %1111, <4 x i32> %203
  %1115 = icmp slt <4 x i32> %1114, %206
  %1116 = select <4 x i1> %1115, <4 x i32> %1114, <4 x i32> %206
  %1117 = icmp sgt <4 x i32> %1112, %203
  %1118 = select <4 x i1> %1117, <4 x i32> %1112, <4 x i32> %203
  %1119 = icmp slt <4 x i32> %1118, %206
  %1120 = select <4 x i1> %1119, <4 x i32> %1118, <4 x i32> %206
  %1121 = bitcast <2 x i64>* %1109 to <4 x i32>*
  store <4 x i32> %1116, <4 x i32>* %1121, align 16
  %1122 = bitcast <2 x i64>* %1110 to <4 x i32>*
  store <4 x i32> %1120, <4 x i32>* %1122, align 16
  %1123 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %1124 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 29
  %1125 = add <4 x i32> %1009, %969
  %1126 = sub <4 x i32> %1009, %969
  %1127 = icmp sgt <4 x i32> %1125, %203
  %1128 = select <4 x i1> %1127, <4 x i32> %1125, <4 x i32> %203
  %1129 = icmp slt <4 x i32> %1128, %206
  %1130 = select <4 x i1> %1129, <4 x i32> %1128, <4 x i32> %206
  %1131 = icmp sgt <4 x i32> %1126, %203
  %1132 = select <4 x i1> %1131, <4 x i32> %1126, <4 x i32> %203
  %1133 = icmp slt <4 x i32> %1132, %206
  %1134 = select <4 x i1> %1133, <4 x i32> %1132, <4 x i32> %206
  %1135 = bitcast <2 x i64>* %1123 to <4 x i32>*
  store <4 x i32> %1130, <4 x i32>* %1135, align 16
  %1136 = bitcast <2 x i64>* %1124 to <4 x i32>*
  store <4 x i32> %1134, <4 x i32>* %1136, align 16
  %1137 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %1138 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 28
  %1139 = add <4 x i32> %1019, %979
  %1140 = sub <4 x i32> %1019, %979
  %1141 = icmp sgt <4 x i32> %1139, %203
  %1142 = select <4 x i1> %1141, <4 x i32> %1139, <4 x i32> %203
  %1143 = icmp slt <4 x i32> %1142, %206
  %1144 = select <4 x i1> %1143, <4 x i32> %1142, <4 x i32> %206
  %1145 = icmp sgt <4 x i32> %1140, %203
  %1146 = select <4 x i1> %1145, <4 x i32> %1140, <4 x i32> %203
  %1147 = icmp slt <4 x i32> %1146, %206
  %1148 = select <4 x i1> %1147, <4 x i32> %1146, <4 x i32> %206
  %1149 = bitcast <2 x i64>* %1137 to <4 x i32>*
  store <4 x i32> %1144, <4 x i32>* %1149, align 16
  %1150 = bitcast <2 x i64>* %1138 to <4 x i32>*
  store <4 x i32> %1148, <4 x i32>* %1150, align 16
  %1151 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %1152 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 27
  %1153 = add <4 x i32> %1095, %1029
  %1154 = sub <4 x i32> %1029, %1095
  %1155 = icmp sgt <4 x i32> %1153, %203
  %1156 = select <4 x i1> %1155, <4 x i32> %1153, <4 x i32> %203
  %1157 = icmp slt <4 x i32> %1156, %206
  %1158 = select <4 x i1> %1157, <4 x i32> %1156, <4 x i32> %206
  %1159 = icmp sgt <4 x i32> %1154, %203
  %1160 = select <4 x i1> %1159, <4 x i32> %1154, <4 x i32> %203
  %1161 = icmp slt <4 x i32> %1160, %206
  %1162 = select <4 x i1> %1161, <4 x i32> %1160, <4 x i32> %206
  %1163 = bitcast <2 x i64>* %1151 to <4 x i32>*
  store <4 x i32> %1158, <4 x i32>* %1163, align 16
  %1164 = bitcast <2 x i64>* %1152 to <4 x i32>*
  store <4 x i32> %1162, <4 x i32>* %1164, align 16
  %1165 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %1166 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 26
  %1167 = add <4 x i32> %1092, %1039
  %1168 = sub <4 x i32> %1039, %1092
  %1169 = icmp sgt <4 x i32> %1167, %203
  %1170 = select <4 x i1> %1169, <4 x i32> %1167, <4 x i32> %203
  %1171 = icmp slt <4 x i32> %1170, %206
  %1172 = select <4 x i1> %1171, <4 x i32> %1170, <4 x i32> %206
  %1173 = icmp sgt <4 x i32> %1168, %203
  %1174 = select <4 x i1> %1173, <4 x i32> %1168, <4 x i32> %203
  %1175 = icmp slt <4 x i32> %1174, %206
  %1176 = select <4 x i1> %1175, <4 x i32> %1174, <4 x i32> %206
  %1177 = bitcast <2 x i64>* %1165 to <4 x i32>*
  store <4 x i32> %1172, <4 x i32>* %1177, align 16
  %1178 = bitcast <2 x i64>* %1166 to <4 x i32>*
  store <4 x i32> %1176, <4 x i32>* %1178, align 16
  %1179 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %1180 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 25
  %1181 = add <4 x i32> %1089, %1049
  %1182 = sub <4 x i32> %1049, %1089
  %1183 = icmp sgt <4 x i32> %1181, %203
  %1184 = select <4 x i1> %1183, <4 x i32> %1181, <4 x i32> %203
  %1185 = icmp slt <4 x i32> %1184, %206
  %1186 = select <4 x i1> %1185, <4 x i32> %1184, <4 x i32> %206
  %1187 = icmp sgt <4 x i32> %1182, %203
  %1188 = select <4 x i1> %1187, <4 x i32> %1182, <4 x i32> %203
  %1189 = icmp slt <4 x i32> %1188, %206
  %1190 = select <4 x i1> %1189, <4 x i32> %1188, <4 x i32> %206
  %1191 = bitcast <2 x i64>* %1179 to <4 x i32>*
  store <4 x i32> %1186, <4 x i32>* %1191, align 16
  %1192 = bitcast <2 x i64>* %1180 to <4 x i32>*
  store <4 x i32> %1190, <4 x i32>* %1192, align 16
  %1193 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %1194 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 24
  %1195 = add <4 x i32> %1086, %1059
  %1196 = sub <4 x i32> %1059, %1086
  %1197 = icmp sgt <4 x i32> %1195, %203
  %1198 = select <4 x i1> %1197, <4 x i32> %1195, <4 x i32> %203
  %1199 = icmp slt <4 x i32> %1198, %206
  %1200 = select <4 x i1> %1199, <4 x i32> %1198, <4 x i32> %206
  %1201 = icmp sgt <4 x i32> %1196, %203
  %1202 = select <4 x i1> %1201, <4 x i32> %1196, <4 x i32> %203
  %1203 = icmp slt <4 x i32> %1202, %206
  %1204 = select <4 x i1> %1203, <4 x i32> %1202, <4 x i32> %206
  %1205 = bitcast <2 x i64>* %1193 to <4 x i32>*
  store <4 x i32> %1200, <4 x i32>* %1205, align 16
  %1206 = bitcast <2 x i64>* %1194 to <4 x i32>*
  store <4 x i32> %1204, <4 x i32>* %1206, align 16
  %1207 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %1208 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 23
  %1209 = add <4 x i32> %1083, %1063
  %1210 = sub <4 x i32> %1063, %1083
  %1211 = icmp sgt <4 x i32> %1209, %203
  %1212 = select <4 x i1> %1211, <4 x i32> %1209, <4 x i32> %203
  %1213 = icmp slt <4 x i32> %1212, %206
  %1214 = select <4 x i1> %1213, <4 x i32> %1212, <4 x i32> %206
  %1215 = icmp sgt <4 x i32> %1210, %203
  %1216 = select <4 x i1> %1215, <4 x i32> %1210, <4 x i32> %203
  %1217 = icmp slt <4 x i32> %1216, %206
  %1218 = select <4 x i1> %1217, <4 x i32> %1216, <4 x i32> %206
  %1219 = bitcast <2 x i64>* %1207 to <4 x i32>*
  store <4 x i32> %1214, <4 x i32>* %1219, align 16
  %1220 = bitcast <2 x i64>* %1208 to <4 x i32>*
  store <4 x i32> %1218, <4 x i32>* %1220, align 16
  %1221 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %1222 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 22
  %1223 = add <4 x i32> %1078, %1053
  %1224 = sub <4 x i32> %1053, %1078
  %1225 = icmp sgt <4 x i32> %1223, %203
  %1226 = select <4 x i1> %1225, <4 x i32> %1223, <4 x i32> %203
  %1227 = icmp slt <4 x i32> %1226, %206
  %1228 = select <4 x i1> %1227, <4 x i32> %1226, <4 x i32> %206
  %1229 = icmp sgt <4 x i32> %1224, %203
  %1230 = select <4 x i1> %1229, <4 x i32> %1224, <4 x i32> %203
  %1231 = icmp slt <4 x i32> %1230, %206
  %1232 = select <4 x i1> %1231, <4 x i32> %1230, <4 x i32> %206
  %1233 = bitcast <2 x i64>* %1221 to <4 x i32>*
  store <4 x i32> %1228, <4 x i32>* %1233, align 16
  %1234 = bitcast <2 x i64>* %1222 to <4 x i32>*
  store <4 x i32> %1232, <4 x i32>* %1234, align 16
  %1235 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %1236 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 21
  %1237 = add <4 x i32> %1073, %1043
  %1238 = sub <4 x i32> %1043, %1073
  %1239 = icmp sgt <4 x i32> %1237, %203
  %1240 = select <4 x i1> %1239, <4 x i32> %1237, <4 x i32> %203
  %1241 = icmp slt <4 x i32> %1240, %206
  %1242 = select <4 x i1> %1241, <4 x i32> %1240, <4 x i32> %206
  %1243 = icmp sgt <4 x i32> %1238, %203
  %1244 = select <4 x i1> %1243, <4 x i32> %1238, <4 x i32> %203
  %1245 = icmp slt <4 x i32> %1244, %206
  %1246 = select <4 x i1> %1245, <4 x i32> %1244, <4 x i32> %206
  %1247 = bitcast <2 x i64>* %1235 to <4 x i32>*
  store <4 x i32> %1242, <4 x i32>* %1247, align 16
  %1248 = bitcast <2 x i64>* %1236 to <4 x i32>*
  store <4 x i32> %1246, <4 x i32>* %1248, align 16
  %1249 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %1250 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 20
  %1251 = add <4 x i32> %1033, %1068
  %1252 = sub <4 x i32> %1033, %1068
  %1253 = icmp sgt <4 x i32> %1251, %203
  %1254 = select <4 x i1> %1253, <4 x i32> %1251, <4 x i32> %203
  %1255 = icmp slt <4 x i32> %1254, %206
  %1256 = select <4 x i1> %1255, <4 x i32> %1254, <4 x i32> %206
  %1257 = icmp sgt <4 x i32> %1252, %203
  %1258 = select <4 x i1> %1257, <4 x i32> %1252, <4 x i32> %203
  %1259 = icmp slt <4 x i32> %1258, %206
  %1260 = select <4 x i1> %1259, <4 x i32> %1258, <4 x i32> %206
  %1261 = bitcast <2 x i64>* %1249 to <4 x i32>*
  store <4 x i32> %1256, <4 x i32>* %1261, align 16
  %1262 = bitcast <2 x i64>* %1250 to <4 x i32>*
  store <4 x i32> %1260, <4 x i32>* %1262, align 16
  %1263 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %1264 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 19
  %1265 = add <4 x i32> %1023, %939
  %1266 = sub <4 x i32> %1023, %939
  %1267 = icmp sgt <4 x i32> %1265, %203
  %1268 = select <4 x i1> %1267, <4 x i32> %1265, <4 x i32> %203
  %1269 = icmp slt <4 x i32> %1268, %206
  %1270 = select <4 x i1> %1269, <4 x i32> %1268, <4 x i32> %206
  %1271 = icmp sgt <4 x i32> %1266, %203
  %1272 = select <4 x i1> %1271, <4 x i32> %1266, <4 x i32> %203
  %1273 = icmp slt <4 x i32> %1272, %206
  %1274 = select <4 x i1> %1273, <4 x i32> %1272, <4 x i32> %206
  %1275 = bitcast <2 x i64>* %1263 to <4 x i32>*
  store <4 x i32> %1270, <4 x i32>* %1275, align 16
  %1276 = bitcast <2 x i64>* %1264 to <4 x i32>*
  store <4 x i32> %1274, <4 x i32>* %1276, align 16
  %1277 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %1278 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 18
  %1279 = add <4 x i32> %1013, %929
  %1280 = sub <4 x i32> %1013, %929
  %1281 = icmp sgt <4 x i32> %1279, %203
  %1282 = select <4 x i1> %1281, <4 x i32> %1279, <4 x i32> %203
  %1283 = icmp slt <4 x i32> %1282, %206
  %1284 = select <4 x i1> %1283, <4 x i32> %1282, <4 x i32> %206
  %1285 = icmp sgt <4 x i32> %1280, %203
  %1286 = select <4 x i1> %1285, <4 x i32> %1280, <4 x i32> %203
  %1287 = icmp slt <4 x i32> %1286, %206
  %1288 = select <4 x i1> %1287, <4 x i32> %1286, <4 x i32> %206
  %1289 = bitcast <2 x i64>* %1277 to <4 x i32>*
  store <4 x i32> %1284, <4 x i32>* %1289, align 16
  %1290 = bitcast <2 x i64>* %1278 to <4 x i32>*
  store <4 x i32> %1288, <4 x i32>* %1290, align 16
  %1291 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %1292 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 17
  %1293 = add <4 x i32> %1003, %919
  %1294 = sub <4 x i32> %1003, %919
  %1295 = icmp sgt <4 x i32> %1293, %203
  %1296 = select <4 x i1> %1295, <4 x i32> %1293, <4 x i32> %203
  %1297 = icmp slt <4 x i32> %1296, %206
  %1298 = select <4 x i1> %1297, <4 x i32> %1296, <4 x i32> %206
  %1299 = icmp sgt <4 x i32> %1294, %203
  %1300 = select <4 x i1> %1299, <4 x i32> %1294, <4 x i32> %203
  %1301 = icmp slt <4 x i32> %1300, %206
  %1302 = select <4 x i1> %1301, <4 x i32> %1300, <4 x i32> %206
  %1303 = bitcast <2 x i64>* %1291 to <4 x i32>*
  store <4 x i32> %1298, <4 x i32>* %1303, align 16
  %1304 = bitcast <2 x i64>* %1292 to <4 x i32>*
  store <4 x i32> %1302, <4 x i32>* %1304, align 16
  %1305 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %1306 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 16
  %1307 = add <4 x i32> %993, %909
  %1308 = sub <4 x i32> %993, %909
  %1309 = icmp sgt <4 x i32> %1307, %203
  %1310 = select <4 x i1> %1309, <4 x i32> %1307, <4 x i32> %203
  %1311 = icmp slt <4 x i32> %1310, %206
  %1312 = select <4 x i1> %1311, <4 x i32> %1310, <4 x i32> %206
  %1313 = icmp sgt <4 x i32> %1308, %203
  %1314 = select <4 x i1> %1313, <4 x i32> %1308, <4 x i32> %203
  %1315 = icmp slt <4 x i32> %1314, %206
  %1316 = select <4 x i1> %1315, <4 x i32> %1314, <4 x i32> %206
  %1317 = bitcast <2 x i64>* %1305 to <4 x i32>*
  store <4 x i32> %1312, <4 x i32>* %1317, align 16
  %1318 = bitcast <2 x i64>* %1306 to <4 x i32>*
  store <4 x i32> %1316, <4 x i32>* %1318, align 16
  br i1 %194, label %1447, label %1319

1319:                                             ; preds = %6
  %1320 = icmp sgt i32 %4, 10
  %1321 = select i1 %1320, i32 %4, i32 10
  %1322 = shl i32 32, %1321
  %1323 = sub nsw i32 0, %1322
  %1324 = insertelement <4 x i32> undef, i32 %1323, i32 0
  %1325 = shufflevector <4 x i32> %1324, <4 x i32> undef, <4 x i32> zeroinitializer
  %1326 = add nsw i32 %1322, -1
  %1327 = insertelement <4 x i32> undef, i32 %1326, i32 0
  %1328 = shufflevector <4 x i32> %1327, <4 x i32> undef, <4 x i32> zeroinitializer
  %1329 = icmp eq i32 %5, 0
  br i1 %1329, label %1411, label %1330

1330:                                             ; preds = %1319
  %1331 = add nsw i32 %5, -1
  %1332 = shl i32 1, %1331
  %1333 = insertelement <4 x i32> undef, i32 %1332, i32 0
  %1334 = shufflevector <4 x i32> %1333, <4 x i32> undef, <4 x i32> zeroinitializer
  %1335 = add <4 x i32> %1102, %1334
  %1336 = add <4 x i32> %1116, %1334
  %1337 = add <4 x i32> %1130, %1334
  %1338 = add <4 x i32> %1144, %1334
  %1339 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1335, i32 %5) #8
  store <4 x i32> %1339, <4 x i32>* %1107, align 16
  %1340 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1336, i32 %5) #8
  store <4 x i32> %1340, <4 x i32>* %1121, align 16
  %1341 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1337, i32 %5) #8
  store <4 x i32> %1341, <4 x i32>* %1135, align 16
  %1342 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1338, i32 %5) #8
  store <4 x i32> %1342, <4 x i32>* %1149, align 16
  %1343 = add <4 x i32> %1158, %1334
  %1344 = load <4 x i32>, <4 x i32>* %1177, align 16
  %1345 = add <4 x i32> %1344, %1334
  %1346 = load <4 x i32>, <4 x i32>* %1191, align 16
  %1347 = add <4 x i32> %1346, %1334
  %1348 = load <4 x i32>, <4 x i32>* %1205, align 16
  %1349 = add <4 x i32> %1348, %1334
  %1350 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1343, i32 %5) #8
  store <4 x i32> %1350, <4 x i32>* %1163, align 16
  %1351 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1345, i32 %5) #8
  store <4 x i32> %1351, <4 x i32>* %1177, align 16
  %1352 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1347, i32 %5) #8
  store <4 x i32> %1352, <4 x i32>* %1191, align 16
  %1353 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1349, i32 %5) #8
  store <4 x i32> %1353, <4 x i32>* %1205, align 16
  %1354 = add <4 x i32> %1214, %1334
  %1355 = add <4 x i32> %1228, %1334
  %1356 = add <4 x i32> %1242, %1334
  %1357 = add <4 x i32> %1256, %1334
  %1358 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1354, i32 %5) #8
  store <4 x i32> %1358, <4 x i32>* %1219, align 16
  %1359 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1355, i32 %5) #8
  store <4 x i32> %1359, <4 x i32>* %1233, align 16
  %1360 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1356, i32 %5) #8
  store <4 x i32> %1360, <4 x i32>* %1247, align 16
  %1361 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1357, i32 %5) #8
  store <4 x i32> %1361, <4 x i32>* %1261, align 16
  %1362 = add <4 x i32> %1270, %1334
  %1363 = add <4 x i32> %1284, %1334
  %1364 = add <4 x i32> %1298, %1334
  %1365 = add <4 x i32> %1312, %1334
  %1366 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1362, i32 %5) #8
  store <4 x i32> %1366, <4 x i32>* %1275, align 16
  %1367 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1363, i32 %5) #8
  store <4 x i32> %1367, <4 x i32>* %1289, align 16
  %1368 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1364, i32 %5) #8
  store <4 x i32> %1368, <4 x i32>* %1303, align 16
  %1369 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1365, i32 %5) #8
  store <4 x i32> %1369, <4 x i32>* %1317, align 16
  %1370 = add <4 x i32> %1316, %1334
  %1371 = add <4 x i32> %1302, %1334
  %1372 = add <4 x i32> %1288, %1334
  %1373 = add <4 x i32> %1274, %1334
  %1374 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1370, i32 %5) #8
  store <4 x i32> %1374, <4 x i32>* %1318, align 16
  %1375 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1371, i32 %5) #8
  store <4 x i32> %1375, <4 x i32>* %1304, align 16
  %1376 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1372, i32 %5) #8
  store <4 x i32> %1376, <4 x i32>* %1290, align 16
  %1377 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1373, i32 %5) #8
  store <4 x i32> %1377, <4 x i32>* %1276, align 16
  %1378 = add <4 x i32> %1260, %1334
  %1379 = add <4 x i32> %1246, %1334
  %1380 = add <4 x i32> %1232, %1334
  %1381 = load <4 x i32>, <4 x i32>* %1220, align 16
  %1382 = add <4 x i32> %1381, %1334
  %1383 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1378, i32 %5) #8
  store <4 x i32> %1383, <4 x i32>* %1262, align 16
  %1384 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1379, i32 %5) #8
  store <4 x i32> %1384, <4 x i32>* %1248, align 16
  %1385 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1380, i32 %5) #8
  store <4 x i32> %1385, <4 x i32>* %1234, align 16
  %1386 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1382, i32 %5) #8
  store <4 x i32> %1386, <4 x i32>* %1220, align 16
  %1387 = load <4 x i32>, <4 x i32>* %1206, align 16
  %1388 = add <4 x i32> %1387, %1334
  %1389 = load <4 x i32>, <4 x i32>* %1192, align 16
  %1390 = add <4 x i32> %1389, %1334
  %1391 = load <4 x i32>, <4 x i32>* %1178, align 16
  %1392 = add <4 x i32> %1391, %1334
  %1393 = load <4 x i32>, <4 x i32>* %1164, align 16
  %1394 = add <4 x i32> %1393, %1334
  %1395 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1388, i32 %5) #8
  store <4 x i32> %1395, <4 x i32>* %1206, align 16
  %1396 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1390, i32 %5) #8
  store <4 x i32> %1396, <4 x i32>* %1192, align 16
  %1397 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1392, i32 %5) #8
  store <4 x i32> %1397, <4 x i32>* %1178, align 16
  %1398 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1394, i32 %5) #8
  store <4 x i32> %1398, <4 x i32>* %1164, align 16
  %1399 = load <4 x i32>, <4 x i32>* %1150, align 16
  %1400 = add <4 x i32> %1399, %1334
  %1401 = load <4 x i32>, <4 x i32>* %1136, align 16
  %1402 = add <4 x i32> %1401, %1334
  %1403 = load <4 x i32>, <4 x i32>* %1122, align 16
  %1404 = add <4 x i32> %1403, %1334
  %1405 = load <4 x i32>, <4 x i32>* %1108, align 16
  %1406 = add <4 x i32> %1405, %1334
  %1407 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1400, i32 %5) #8
  store <4 x i32> %1407, <4 x i32>* %1150, align 16
  %1408 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1402, i32 %5) #8
  store <4 x i32> %1408, <4 x i32>* %1136, align 16
  %1409 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1404, i32 %5) #8
  store <4 x i32> %1409, <4 x i32>* %1122, align 16
  %1410 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1406, i32 %5) #8
  store <4 x i32> %1410, <4 x i32>* %1108, align 16
  br label %1411

1411:                                             ; preds = %1319, %1330
  br label %1412

1412:                                             ; preds = %1411, %1412
  %1413 = phi i64 [ %1445, %1412 ], [ 0, %1411 ]
  %1414 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %1413
  %1415 = bitcast <2 x i64>* %1414 to <4 x i32>*
  %1416 = load <4 x i32>, <4 x i32>* %1415, align 16
  %1417 = icmp sgt <4 x i32> %1416, %1325
  %1418 = select <4 x i1> %1417, <4 x i32> %1416, <4 x i32> %1325
  %1419 = icmp slt <4 x i32> %1418, %1328
  %1420 = select <4 x i1> %1419, <4 x i32> %1418, <4 x i32> %1328
  store <4 x i32> %1420, <4 x i32>* %1415, align 16
  %1421 = or i64 %1413, 1
  %1422 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %1421
  %1423 = bitcast <2 x i64>* %1422 to <4 x i32>*
  %1424 = load <4 x i32>, <4 x i32>* %1423, align 16
  %1425 = icmp sgt <4 x i32> %1424, %1325
  %1426 = select <4 x i1> %1425, <4 x i32> %1424, <4 x i32> %1325
  %1427 = icmp slt <4 x i32> %1426, %1328
  %1428 = select <4 x i1> %1427, <4 x i32> %1426, <4 x i32> %1328
  store <4 x i32> %1428, <4 x i32>* %1423, align 16
  %1429 = or i64 %1413, 2
  %1430 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %1429
  %1431 = bitcast <2 x i64>* %1430 to <4 x i32>*
  %1432 = load <4 x i32>, <4 x i32>* %1431, align 16
  %1433 = icmp sgt <4 x i32> %1432, %1325
  %1434 = select <4 x i1> %1433, <4 x i32> %1432, <4 x i32> %1325
  %1435 = icmp slt <4 x i32> %1434, %1328
  %1436 = select <4 x i1> %1435, <4 x i32> %1434, <4 x i32> %1328
  store <4 x i32> %1436, <4 x i32>* %1431, align 16
  %1437 = or i64 %1413, 3
  %1438 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %1437
  %1439 = bitcast <2 x i64>* %1438 to <4 x i32>*
  %1440 = load <4 x i32>, <4 x i32>* %1439, align 16
  %1441 = icmp sgt <4 x i32> %1440, %1325
  %1442 = select <4 x i1> %1441, <4 x i32> %1440, <4 x i32> %1325
  %1443 = icmp slt <4 x i32> %1442, %1328
  %1444 = select <4 x i1> %1443, <4 x i32> %1442, <4 x i32> %1328
  store <4 x i32> %1444, <4 x i32>* %1439, align 16
  %1445 = add nuw nsw i64 %1413, 4
  %1446 = icmp ult i64 %1445, 32
  br i1 %1446, label %1412, label %1447

1447:                                             ; preds = %1412, %6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @iidentity32_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>*, i32, i32, i32, i32) #0 {
  %7 = bitcast <2 x i64>* %0 to <4 x i32>*
  %8 = load <4 x i32>, <4 x i32>* %7, align 16
  %9 = shl <4 x i32> %8, <i32 2, i32 2, i32 2, i32 2>
  %10 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %9, <4 x i32>* %10, align 16
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %12 = bitcast <2 x i64>* %11 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 16
  %14 = shl <4 x i32> %13, <i32 2, i32 2, i32 2, i32 2>
  %15 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %16 = bitcast <2 x i64>* %15 to <4 x i32>*
  store <4 x i32> %14, <4 x i32>* %16, align 16
  %17 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %18 = bitcast <2 x i64>* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 16
  %20 = shl <4 x i32> %19, <i32 2, i32 2, i32 2, i32 2>
  %21 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %22 = bitcast <2 x i64>* %21 to <4 x i32>*
  store <4 x i32> %20, <4 x i32>* %22, align 16
  %23 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %24 = bitcast <2 x i64>* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 16
  %26 = shl <4 x i32> %25, <i32 2, i32 2, i32 2, i32 2>
  %27 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %28 = bitcast <2 x i64>* %27 to <4 x i32>*
  store <4 x i32> %26, <4 x i32>* %28, align 16
  %29 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %30 = bitcast <2 x i64>* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 16
  %32 = shl <4 x i32> %31, <i32 2, i32 2, i32 2, i32 2>
  %33 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %34 = bitcast <2 x i64>* %33 to <4 x i32>*
  store <4 x i32> %32, <4 x i32>* %34, align 16
  %35 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %36 = bitcast <2 x i64>* %35 to <4 x i32>*
  %37 = load <4 x i32>, <4 x i32>* %36, align 16
  %38 = shl <4 x i32> %37, <i32 2, i32 2, i32 2, i32 2>
  %39 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %40 = bitcast <2 x i64>* %39 to <4 x i32>*
  store <4 x i32> %38, <4 x i32>* %40, align 16
  %41 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %42 = bitcast <2 x i64>* %41 to <4 x i32>*
  %43 = load <4 x i32>, <4 x i32>* %42, align 16
  %44 = shl <4 x i32> %43, <i32 2, i32 2, i32 2, i32 2>
  %45 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %46 = bitcast <2 x i64>* %45 to <4 x i32>*
  store <4 x i32> %44, <4 x i32>* %46, align 16
  %47 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %48 = bitcast <2 x i64>* %47 to <4 x i32>*
  %49 = load <4 x i32>, <4 x i32>* %48, align 16
  %50 = shl <4 x i32> %49, <i32 2, i32 2, i32 2, i32 2>
  %51 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %52 = bitcast <2 x i64>* %51 to <4 x i32>*
  store <4 x i32> %50, <4 x i32>* %52, align 16
  %53 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %54 = bitcast <2 x i64>* %53 to <4 x i32>*
  %55 = load <4 x i32>, <4 x i32>* %54, align 16
  %56 = shl <4 x i32> %55, <i32 2, i32 2, i32 2, i32 2>
  %57 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %58 = bitcast <2 x i64>* %57 to <4 x i32>*
  store <4 x i32> %56, <4 x i32>* %58, align 16
  %59 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %60 = bitcast <2 x i64>* %59 to <4 x i32>*
  %61 = load <4 x i32>, <4 x i32>* %60, align 16
  %62 = shl <4 x i32> %61, <i32 2, i32 2, i32 2, i32 2>
  %63 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %64 = bitcast <2 x i64>* %63 to <4 x i32>*
  store <4 x i32> %62, <4 x i32>* %64, align 16
  %65 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %66 = bitcast <2 x i64>* %65 to <4 x i32>*
  %67 = load <4 x i32>, <4 x i32>* %66, align 16
  %68 = shl <4 x i32> %67, <i32 2, i32 2, i32 2, i32 2>
  %69 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %70 = bitcast <2 x i64>* %69 to <4 x i32>*
  store <4 x i32> %68, <4 x i32>* %70, align 16
  %71 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %72 = bitcast <2 x i64>* %71 to <4 x i32>*
  %73 = load <4 x i32>, <4 x i32>* %72, align 16
  %74 = shl <4 x i32> %73, <i32 2, i32 2, i32 2, i32 2>
  %75 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %76 = bitcast <2 x i64>* %75 to <4 x i32>*
  store <4 x i32> %74, <4 x i32>* %76, align 16
  %77 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %78 = bitcast <2 x i64>* %77 to <4 x i32>*
  %79 = load <4 x i32>, <4 x i32>* %78, align 16
  %80 = shl <4 x i32> %79, <i32 2, i32 2, i32 2, i32 2>
  %81 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %82 = bitcast <2 x i64>* %81 to <4 x i32>*
  store <4 x i32> %80, <4 x i32>* %82, align 16
  %83 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %84 = bitcast <2 x i64>* %83 to <4 x i32>*
  %85 = load <4 x i32>, <4 x i32>* %84, align 16
  %86 = shl <4 x i32> %85, <i32 2, i32 2, i32 2, i32 2>
  %87 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %88 = bitcast <2 x i64>* %87 to <4 x i32>*
  store <4 x i32> %86, <4 x i32>* %88, align 16
  %89 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %90 = bitcast <2 x i64>* %89 to <4 x i32>*
  %91 = load <4 x i32>, <4 x i32>* %90, align 16
  %92 = shl <4 x i32> %91, <i32 2, i32 2, i32 2, i32 2>
  %93 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %94 = bitcast <2 x i64>* %93 to <4 x i32>*
  store <4 x i32> %92, <4 x i32>* %94, align 16
  %95 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %96 = bitcast <2 x i64>* %95 to <4 x i32>*
  %97 = load <4 x i32>, <4 x i32>* %96, align 16
  %98 = shl <4 x i32> %97, <i32 2, i32 2, i32 2, i32 2>
  %99 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %100 = bitcast <2 x i64>* %99 to <4 x i32>*
  store <4 x i32> %98, <4 x i32>* %100, align 16
  %101 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 16
  %102 = bitcast <2 x i64>* %101 to <4 x i32>*
  %103 = load <4 x i32>, <4 x i32>* %102, align 16
  %104 = shl <4 x i32> %103, <i32 2, i32 2, i32 2, i32 2>
  %105 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 16
  %106 = bitcast <2 x i64>* %105 to <4 x i32>*
  store <4 x i32> %104, <4 x i32>* %106, align 16
  %107 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 17
  %108 = bitcast <2 x i64>* %107 to <4 x i32>*
  %109 = load <4 x i32>, <4 x i32>* %108, align 16
  %110 = shl <4 x i32> %109, <i32 2, i32 2, i32 2, i32 2>
  %111 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 17
  %112 = bitcast <2 x i64>* %111 to <4 x i32>*
  store <4 x i32> %110, <4 x i32>* %112, align 16
  %113 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 18
  %114 = bitcast <2 x i64>* %113 to <4 x i32>*
  %115 = load <4 x i32>, <4 x i32>* %114, align 16
  %116 = shl <4 x i32> %115, <i32 2, i32 2, i32 2, i32 2>
  %117 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 18
  %118 = bitcast <2 x i64>* %117 to <4 x i32>*
  store <4 x i32> %116, <4 x i32>* %118, align 16
  %119 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 19
  %120 = bitcast <2 x i64>* %119 to <4 x i32>*
  %121 = load <4 x i32>, <4 x i32>* %120, align 16
  %122 = shl <4 x i32> %121, <i32 2, i32 2, i32 2, i32 2>
  %123 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 19
  %124 = bitcast <2 x i64>* %123 to <4 x i32>*
  store <4 x i32> %122, <4 x i32>* %124, align 16
  %125 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 20
  %126 = bitcast <2 x i64>* %125 to <4 x i32>*
  %127 = load <4 x i32>, <4 x i32>* %126, align 16
  %128 = shl <4 x i32> %127, <i32 2, i32 2, i32 2, i32 2>
  %129 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 20
  %130 = bitcast <2 x i64>* %129 to <4 x i32>*
  store <4 x i32> %128, <4 x i32>* %130, align 16
  %131 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 21
  %132 = bitcast <2 x i64>* %131 to <4 x i32>*
  %133 = load <4 x i32>, <4 x i32>* %132, align 16
  %134 = shl <4 x i32> %133, <i32 2, i32 2, i32 2, i32 2>
  %135 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 21
  %136 = bitcast <2 x i64>* %135 to <4 x i32>*
  store <4 x i32> %134, <4 x i32>* %136, align 16
  %137 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 22
  %138 = bitcast <2 x i64>* %137 to <4 x i32>*
  %139 = load <4 x i32>, <4 x i32>* %138, align 16
  %140 = shl <4 x i32> %139, <i32 2, i32 2, i32 2, i32 2>
  %141 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 22
  %142 = bitcast <2 x i64>* %141 to <4 x i32>*
  store <4 x i32> %140, <4 x i32>* %142, align 16
  %143 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 23
  %144 = bitcast <2 x i64>* %143 to <4 x i32>*
  %145 = load <4 x i32>, <4 x i32>* %144, align 16
  %146 = shl <4 x i32> %145, <i32 2, i32 2, i32 2, i32 2>
  %147 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 23
  %148 = bitcast <2 x i64>* %147 to <4 x i32>*
  store <4 x i32> %146, <4 x i32>* %148, align 16
  %149 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 24
  %150 = bitcast <2 x i64>* %149 to <4 x i32>*
  %151 = load <4 x i32>, <4 x i32>* %150, align 16
  %152 = shl <4 x i32> %151, <i32 2, i32 2, i32 2, i32 2>
  %153 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 24
  %154 = bitcast <2 x i64>* %153 to <4 x i32>*
  store <4 x i32> %152, <4 x i32>* %154, align 16
  %155 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 25
  %156 = bitcast <2 x i64>* %155 to <4 x i32>*
  %157 = load <4 x i32>, <4 x i32>* %156, align 16
  %158 = shl <4 x i32> %157, <i32 2, i32 2, i32 2, i32 2>
  %159 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 25
  %160 = bitcast <2 x i64>* %159 to <4 x i32>*
  store <4 x i32> %158, <4 x i32>* %160, align 16
  %161 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 26
  %162 = bitcast <2 x i64>* %161 to <4 x i32>*
  %163 = load <4 x i32>, <4 x i32>* %162, align 16
  %164 = shl <4 x i32> %163, <i32 2, i32 2, i32 2, i32 2>
  %165 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 26
  %166 = bitcast <2 x i64>* %165 to <4 x i32>*
  store <4 x i32> %164, <4 x i32>* %166, align 16
  %167 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 27
  %168 = bitcast <2 x i64>* %167 to <4 x i32>*
  %169 = load <4 x i32>, <4 x i32>* %168, align 16
  %170 = shl <4 x i32> %169, <i32 2, i32 2, i32 2, i32 2>
  %171 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 27
  %172 = bitcast <2 x i64>* %171 to <4 x i32>*
  store <4 x i32> %170, <4 x i32>* %172, align 16
  %173 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 28
  %174 = bitcast <2 x i64>* %173 to <4 x i32>*
  %175 = load <4 x i32>, <4 x i32>* %174, align 16
  %176 = shl <4 x i32> %175, <i32 2, i32 2, i32 2, i32 2>
  %177 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 28
  %178 = bitcast <2 x i64>* %177 to <4 x i32>*
  store <4 x i32> %176, <4 x i32>* %178, align 16
  %179 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 29
  %180 = bitcast <2 x i64>* %179 to <4 x i32>*
  %181 = load <4 x i32>, <4 x i32>* %180, align 16
  %182 = shl <4 x i32> %181, <i32 2, i32 2, i32 2, i32 2>
  %183 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 29
  %184 = bitcast <2 x i64>* %183 to <4 x i32>*
  store <4 x i32> %182, <4 x i32>* %184, align 16
  %185 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 30
  %186 = bitcast <2 x i64>* %185 to <4 x i32>*
  %187 = load <4 x i32>, <4 x i32>* %186, align 16
  %188 = shl <4 x i32> %187, <i32 2, i32 2, i32 2, i32 2>
  %189 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 30
  %190 = bitcast <2 x i64>* %189 to <4 x i32>*
  store <4 x i32> %188, <4 x i32>* %190, align 16
  %191 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 31
  %192 = bitcast <2 x i64>* %191 to <4 x i32>*
  %193 = load <4 x i32>, <4 x i32>* %192, align 16
  %194 = shl <4 x i32> %193, <i32 2, i32 2, i32 2, i32 2>
  %195 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 31
  %196 = bitcast <2 x i64>* %195 to <4 x i32>*
  store <4 x i32> %194, <4 x i32>* %196, align 16
  %197 = icmp eq i32 %3, 0
  br i1 %197, label %198, label %336

198:                                              ; preds = %6
  %199 = icmp sgt i32 %4, 10
  %200 = select i1 %199, i32 %4, i32 10
  %201 = shl i32 32, %200
  %202 = sub nsw i32 0, %201
  %203 = insertelement <4 x i32> undef, i32 %202, i32 0
  %204 = shufflevector <4 x i32> %203, <4 x i32> undef, <4 x i32> zeroinitializer
  %205 = add nsw i32 %201, -1
  %206 = insertelement <4 x i32> undef, i32 %205, i32 0
  %207 = shufflevector <4 x i32> %206, <4 x i32> undef, <4 x i32> zeroinitializer
  %208 = icmp eq i32 %5, 0
  br i1 %208, label %300, label %209

209:                                              ; preds = %198
  %210 = add nsw i32 %5, -1
  %211 = shl i32 1, %210
  %212 = insertelement <4 x i32> undef, i32 %211, i32 0
  %213 = shufflevector <4 x i32> %212, <4 x i32> undef, <4 x i32> zeroinitializer
  %214 = load <4 x i32>, <4 x i32>* %10, align 16
  %215 = add <4 x i32> %214, %213
  %216 = load <4 x i32>, <4 x i32>* %16, align 16
  %217 = add <4 x i32> %216, %213
  %218 = load <4 x i32>, <4 x i32>* %22, align 16
  %219 = add <4 x i32> %218, %213
  %220 = load <4 x i32>, <4 x i32>* %28, align 16
  %221 = add <4 x i32> %220, %213
  %222 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %215, i32 %5) #8
  store <4 x i32> %222, <4 x i32>* %10, align 16
  %223 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %217, i32 %5) #8
  store <4 x i32> %223, <4 x i32>* %16, align 16
  %224 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %219, i32 %5) #8
  store <4 x i32> %224, <4 x i32>* %22, align 16
  %225 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %221, i32 %5) #8
  store <4 x i32> %225, <4 x i32>* %28, align 16
  %226 = load <4 x i32>, <4 x i32>* %34, align 16
  %227 = add <4 x i32> %226, %213
  %228 = load <4 x i32>, <4 x i32>* %40, align 16
  %229 = add <4 x i32> %228, %213
  %230 = load <4 x i32>, <4 x i32>* %46, align 16
  %231 = add <4 x i32> %230, %213
  %232 = load <4 x i32>, <4 x i32>* %52, align 16
  %233 = add <4 x i32> %232, %213
  %234 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %227, i32 %5) #8
  store <4 x i32> %234, <4 x i32>* %34, align 16
  %235 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %229, i32 %5) #8
  store <4 x i32> %235, <4 x i32>* %40, align 16
  %236 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %231, i32 %5) #8
  store <4 x i32> %236, <4 x i32>* %46, align 16
  %237 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %233, i32 %5) #8
  store <4 x i32> %237, <4 x i32>* %52, align 16
  %238 = load <4 x i32>, <4 x i32>* %58, align 16
  %239 = add <4 x i32> %238, %213
  %240 = load <4 x i32>, <4 x i32>* %64, align 16
  %241 = add <4 x i32> %240, %213
  %242 = load <4 x i32>, <4 x i32>* %70, align 16
  %243 = add <4 x i32> %242, %213
  %244 = load <4 x i32>, <4 x i32>* %76, align 16
  %245 = add <4 x i32> %244, %213
  %246 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %239, i32 %5) #8
  store <4 x i32> %246, <4 x i32>* %58, align 16
  %247 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %241, i32 %5) #8
  store <4 x i32> %247, <4 x i32>* %64, align 16
  %248 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %243, i32 %5) #8
  store <4 x i32> %248, <4 x i32>* %70, align 16
  %249 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %245, i32 %5) #8
  store <4 x i32> %249, <4 x i32>* %76, align 16
  %250 = load <4 x i32>, <4 x i32>* %82, align 16
  %251 = add <4 x i32> %250, %213
  %252 = load <4 x i32>, <4 x i32>* %88, align 16
  %253 = add <4 x i32> %252, %213
  %254 = load <4 x i32>, <4 x i32>* %94, align 16
  %255 = add <4 x i32> %254, %213
  %256 = load <4 x i32>, <4 x i32>* %100, align 16
  %257 = add <4 x i32> %256, %213
  %258 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %251, i32 %5) #8
  store <4 x i32> %258, <4 x i32>* %82, align 16
  %259 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %253, i32 %5) #8
  store <4 x i32> %259, <4 x i32>* %88, align 16
  %260 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %255, i32 %5) #8
  store <4 x i32> %260, <4 x i32>* %94, align 16
  %261 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %257, i32 %5) #8
  store <4 x i32> %261, <4 x i32>* %100, align 16
  %262 = load <4 x i32>, <4 x i32>* %106, align 16
  %263 = add <4 x i32> %262, %213
  %264 = load <4 x i32>, <4 x i32>* %112, align 16
  %265 = add <4 x i32> %264, %213
  %266 = add <4 x i32> %116, %213
  %267 = add <4 x i32> %122, %213
  %268 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %263, i32 %5) #8
  store <4 x i32> %268, <4 x i32>* %106, align 16
  %269 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %265, i32 %5) #8
  store <4 x i32> %269, <4 x i32>* %112, align 16
  %270 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %266, i32 %5) #8
  store <4 x i32> %270, <4 x i32>* %118, align 16
  %271 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %267, i32 %5) #8
  store <4 x i32> %271, <4 x i32>* %124, align 16
  %272 = add <4 x i32> %128, %213
  %273 = add <4 x i32> %134, %213
  %274 = add <4 x i32> %140, %213
  %275 = add <4 x i32> %146, %213
  %276 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %272, i32 %5) #8
  store <4 x i32> %276, <4 x i32>* %130, align 16
  %277 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %273, i32 %5) #8
  store <4 x i32> %277, <4 x i32>* %136, align 16
  %278 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %274, i32 %5) #8
  store <4 x i32> %278, <4 x i32>* %142, align 16
  %279 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %275, i32 %5) #8
  store <4 x i32> %279, <4 x i32>* %148, align 16
  %280 = add <4 x i32> %152, %213
  %281 = add <4 x i32> %158, %213
  %282 = add <4 x i32> %164, %213
  %283 = add <4 x i32> %170, %213
  %284 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %280, i32 %5) #8
  store <4 x i32> %284, <4 x i32>* %154, align 16
  %285 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %281, i32 %5) #8
  store <4 x i32> %285, <4 x i32>* %160, align 16
  %286 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %282, i32 %5) #8
  store <4 x i32> %286, <4 x i32>* %166, align 16
  %287 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %283, i32 %5) #8
  store <4 x i32> %287, <4 x i32>* %172, align 16
  %288 = load <4 x i32>, <4 x i32>* %178, align 16
  %289 = add <4 x i32> %288, %213
  %290 = load <4 x i32>, <4 x i32>* %184, align 16
  %291 = add <4 x i32> %290, %213
  %292 = load <4 x i32>, <4 x i32>* %190, align 16
  %293 = add <4 x i32> %292, %213
  %294 = load <4 x i32>, <4 x i32>* %196, align 16
  %295 = add <4 x i32> %294, %213
  %296 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %289, i32 %5) #8
  store <4 x i32> %296, <4 x i32>* %178, align 16
  %297 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %291, i32 %5) #8
  store <4 x i32> %297, <4 x i32>* %184, align 16
  %298 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %293, i32 %5) #8
  store <4 x i32> %298, <4 x i32>* %190, align 16
  %299 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %295, i32 %5) #8
  store <4 x i32> %299, <4 x i32>* %196, align 16
  br label %300

300:                                              ; preds = %198, %209
  br label %301

301:                                              ; preds = %300, %301
  %302 = phi i64 [ %334, %301 ], [ 0, %300 ]
  %303 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %302
  %304 = bitcast <2 x i64>* %303 to <4 x i32>*
  %305 = load <4 x i32>, <4 x i32>* %304, align 16
  %306 = icmp sgt <4 x i32> %305, %204
  %307 = select <4 x i1> %306, <4 x i32> %305, <4 x i32> %204
  %308 = icmp slt <4 x i32> %307, %207
  %309 = select <4 x i1> %308, <4 x i32> %307, <4 x i32> %207
  store <4 x i32> %309, <4 x i32>* %304, align 16
  %310 = or i64 %302, 1
  %311 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %310
  %312 = bitcast <2 x i64>* %311 to <4 x i32>*
  %313 = load <4 x i32>, <4 x i32>* %312, align 16
  %314 = icmp sgt <4 x i32> %313, %204
  %315 = select <4 x i1> %314, <4 x i32> %313, <4 x i32> %204
  %316 = icmp slt <4 x i32> %315, %207
  %317 = select <4 x i1> %316, <4 x i32> %315, <4 x i32> %207
  store <4 x i32> %317, <4 x i32>* %312, align 16
  %318 = or i64 %302, 2
  %319 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %318
  %320 = bitcast <2 x i64>* %319 to <4 x i32>*
  %321 = load <4 x i32>, <4 x i32>* %320, align 16
  %322 = icmp sgt <4 x i32> %321, %204
  %323 = select <4 x i1> %322, <4 x i32> %321, <4 x i32> %204
  %324 = icmp slt <4 x i32> %323, %207
  %325 = select <4 x i1> %324, <4 x i32> %323, <4 x i32> %207
  store <4 x i32> %325, <4 x i32>* %320, align 16
  %326 = or i64 %302, 3
  %327 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %326
  %328 = bitcast <2 x i64>* %327 to <4 x i32>*
  %329 = load <4 x i32>, <4 x i32>* %328, align 16
  %330 = icmp sgt <4 x i32> %329, %204
  %331 = select <4 x i1> %330, <4 x i32> %329, <4 x i32> %204
  %332 = icmp slt <4 x i32> %331, %207
  %333 = select <4 x i1> %332, <4 x i32> %331, <4 x i32> %207
  store <4 x i32> %333, <4 x i32>* %328, align 16
  %334 = add nuw nsw i64 %302, 4
  %335 = icmp ult i64 %334, 32
  br i1 %335, label %301, label %336

336:                                              ; preds = %301, %6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @idct64x64_low1_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>*, i32, i32, i32, i32) #0 {
  %7 = add nsw i32 %2, -10
  %8 = sext i32 %7 to i64
  %9 = add nsw i32 %2, -1
  %10 = shl i32 1, %9
  %11 = insertelement <4 x i32> undef, i32 %10, i32 0
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> zeroinitializer
  %13 = icmp ne i32 %3, 0
  %14 = select i1 %13, i32 6, i32 8
  %15 = add nsw i32 %14, %4
  %16 = icmp slt i32 %15, 16
  %17 = add i32 %15, -1
  %18 = shl i32 1, %17
  %19 = select i1 %16, i32 32768, i32 %18
  %20 = sub nsw i32 0, %19
  %21 = insertelement <4 x i32> undef, i32 %20, i32 0
  %22 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> zeroinitializer
  %23 = add nsw i32 %19, -1
  %24 = insertelement <4 x i32> undef, i32 %23, i32 0
  %25 = shufflevector <4 x i32> %24, <4 x i32> undef, <4 x i32> zeroinitializer
  %26 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %8, i64 32
  %27 = load i32, i32* %26, align 16
  %28 = insertelement <4 x i32> undef, i32 %27, i32 0
  %29 = shufflevector <4 x i32> %28, <4 x i32> undef, <4 x i32> zeroinitializer
  %30 = bitcast <2 x i64>* %0 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 16
  %32 = mul <4 x i32> %29, %31
  %33 = add <4 x i32> %32, %12
  %34 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %33, i32 %2) #8
  br i1 %13, label %54, label %35

35:                                               ; preds = %6
  %36 = icmp sgt i32 %4, 10
  %37 = select i1 %36, i32 %4, i32 10
  %38 = shl i32 32, %37
  %39 = sub nsw i32 0, %38
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = add nsw i32 %38, -1
  %43 = insertelement <4 x i32> undef, i32 %42, i32 0
  %44 = shufflevector <4 x i32> %43, <4 x i32> undef, <4 x i32> zeroinitializer
  %45 = icmp eq i32 %5, 0
  br i1 %45, label %54, label %46

46:                                               ; preds = %35
  %47 = shl i32 1, %5
  %48 = ashr i32 %47, 1
  %49 = insertelement <4 x i32> undef, i32 %48, i32 0
  %50 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> zeroinitializer
  %51 = add <4 x i32> %34, %50
  %52 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %5, i32 0
  %53 = tail call <4 x i32> @llvm.x86.sse2.psra.d(<4 x i32> %51, <4 x i32> %52) #8
  br label %54

54:                                               ; preds = %46, %35, %6
  %55 = phi <4 x i32> [ %22, %6 ], [ %41, %35 ], [ %41, %46 ]
  %56 = phi <4 x i32> [ %25, %6 ], [ %44, %35 ], [ %44, %46 ]
  %57 = phi <4 x i32> [ %34, %6 ], [ %34, %35 ], [ %53, %46 ]
  %58 = icmp sgt <4 x i32> %57, %55
  %59 = select <4 x i1> %58, <4 x i32> %57, <4 x i32> %55
  %60 = icmp slt <4 x i32> %59, %56
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %56
  %62 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %62, align 16
  %63 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %64 = bitcast <2 x i64>* %63 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %64, align 16
  %65 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %66 = bitcast <2 x i64>* %65 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %66, align 16
  %67 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %68 = bitcast <2 x i64>* %67 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %68, align 16
  %69 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %70 = bitcast <2 x i64>* %69 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %70, align 16
  %71 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %72 = bitcast <2 x i64>* %71 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %72, align 16
  %73 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %74 = bitcast <2 x i64>* %73 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %74, align 16
  %75 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %76 = bitcast <2 x i64>* %75 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %76, align 16
  %77 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %78 = bitcast <2 x i64>* %77 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %78, align 16
  %79 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %80 = bitcast <2 x i64>* %79 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %80, align 16
  %81 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %82 = bitcast <2 x i64>* %81 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %82, align 16
  %83 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %84 = bitcast <2 x i64>* %83 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %84, align 16
  %85 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %86 = bitcast <2 x i64>* %85 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %86, align 16
  %87 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %88 = bitcast <2 x i64>* %87 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %88, align 16
  %89 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %90 = bitcast <2 x i64>* %89 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %90, align 16
  %91 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %92 = bitcast <2 x i64>* %91 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %92, align 16
  %93 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 16
  %94 = bitcast <2 x i64>* %93 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %94, align 16
  %95 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 17
  %96 = bitcast <2 x i64>* %95 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %96, align 16
  %97 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 18
  %98 = bitcast <2 x i64>* %97 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %98, align 16
  %99 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 19
  %100 = bitcast <2 x i64>* %99 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %100, align 16
  %101 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 20
  %102 = bitcast <2 x i64>* %101 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %102, align 16
  %103 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 21
  %104 = bitcast <2 x i64>* %103 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %104, align 16
  %105 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 22
  %106 = bitcast <2 x i64>* %105 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %106, align 16
  %107 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 23
  %108 = bitcast <2 x i64>* %107 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %108, align 16
  %109 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 24
  %110 = bitcast <2 x i64>* %109 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %110, align 16
  %111 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 25
  %112 = bitcast <2 x i64>* %111 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %112, align 16
  %113 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 26
  %114 = bitcast <2 x i64>* %113 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %114, align 16
  %115 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 27
  %116 = bitcast <2 x i64>* %115 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %116, align 16
  %117 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 28
  %118 = bitcast <2 x i64>* %117 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %118, align 16
  %119 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 29
  %120 = bitcast <2 x i64>* %119 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %120, align 16
  %121 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 30
  %122 = bitcast <2 x i64>* %121 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %122, align 16
  %123 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 31
  %124 = bitcast <2 x i64>* %123 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %124, align 16
  %125 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 32
  %126 = bitcast <2 x i64>* %125 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %126, align 16
  %127 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 33
  %128 = bitcast <2 x i64>* %127 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %128, align 16
  %129 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 34
  %130 = bitcast <2 x i64>* %129 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %130, align 16
  %131 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 35
  %132 = bitcast <2 x i64>* %131 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %132, align 16
  %133 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 36
  %134 = bitcast <2 x i64>* %133 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %134, align 16
  %135 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 37
  %136 = bitcast <2 x i64>* %135 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %136, align 16
  %137 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 38
  %138 = bitcast <2 x i64>* %137 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %138, align 16
  %139 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 39
  %140 = bitcast <2 x i64>* %139 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %140, align 16
  %141 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 40
  %142 = bitcast <2 x i64>* %141 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %142, align 16
  %143 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 41
  %144 = bitcast <2 x i64>* %143 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %144, align 16
  %145 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 42
  %146 = bitcast <2 x i64>* %145 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %146, align 16
  %147 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 43
  %148 = bitcast <2 x i64>* %147 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %148, align 16
  %149 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 44
  %150 = bitcast <2 x i64>* %149 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %150, align 16
  %151 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 45
  %152 = bitcast <2 x i64>* %151 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %152, align 16
  %153 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 46
  %154 = bitcast <2 x i64>* %153 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %154, align 16
  %155 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 47
  %156 = bitcast <2 x i64>* %155 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %156, align 16
  %157 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 48
  %158 = bitcast <2 x i64>* %157 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %158, align 16
  %159 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 49
  %160 = bitcast <2 x i64>* %159 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %160, align 16
  %161 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 50
  %162 = bitcast <2 x i64>* %161 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %162, align 16
  %163 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 51
  %164 = bitcast <2 x i64>* %163 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %164, align 16
  %165 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 52
  %166 = bitcast <2 x i64>* %165 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %166, align 16
  %167 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 53
  %168 = bitcast <2 x i64>* %167 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %168, align 16
  %169 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 54
  %170 = bitcast <2 x i64>* %169 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %170, align 16
  %171 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 55
  %172 = bitcast <2 x i64>* %171 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %172, align 16
  %173 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 56
  %174 = bitcast <2 x i64>* %173 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %174, align 16
  %175 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 57
  %176 = bitcast <2 x i64>* %175 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %176, align 16
  %177 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 58
  %178 = bitcast <2 x i64>* %177 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %178, align 16
  %179 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 59
  %180 = bitcast <2 x i64>* %179 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %180, align 16
  %181 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 60
  %182 = bitcast <2 x i64>* %181 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %182, align 16
  %183 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 61
  %184 = bitcast <2 x i64>* %183 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %184, align 16
  %185 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 62
  %186 = bitcast <2 x i64>* %185 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %186, align 16
  %187 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 63
  %188 = bitcast <2 x i64>* %187 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %188, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @idct64x64_low8_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i32, i32, i32, i32) #0 {
  %7 = alloca <2 x i64>, align 16
  %8 = alloca <2 x i64>, align 16
  %9 = alloca <2 x i64>, align 16
  %10 = alloca <2 x i64>, align 16
  %11 = alloca <2 x i64>, align 16
  %12 = alloca [64 x <2 x i64>], align 16
  %13 = add nsw i32 %2, -10
  %14 = sext i32 %13 to i64
  %15 = bitcast <2 x i64>* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %15) #8
  %16 = add nsw i32 %2, -1
  %17 = shl i32 1, %16
  %18 = insertelement <4 x i32> undef, i32 %17, i32 0
  %19 = shufflevector <4 x i32> %18, <4 x i32> undef, <4 x i32> zeroinitializer
  %20 = bitcast <2 x i64>* %7 to <4 x i32>*
  store <4 x i32> %19, <4 x i32>* %20, align 16
  %21 = icmp eq i32 %3, 0
  %22 = select i1 %21, i32 8, i32 6
  %23 = add nsw i32 %22, %4
  %24 = icmp slt i32 %23, 16
  %25 = add i32 %23, -1
  %26 = bitcast <2 x i64>* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %26) #8
  %27 = shl i32 1, %25
  %28 = select i1 %24, i32 32768, i32 %27
  %29 = sub nsw i32 0, %28
  %30 = insertelement <4 x i32> undef, i32 %29, i32 0
  %31 = shufflevector <4 x i32> %30, <4 x i32> undef, <4 x i32> zeroinitializer
  %32 = bitcast <2 x i64>* %8 to <4 x i32>*
  store <4 x i32> %31, <4 x i32>* %32, align 16
  %33 = bitcast <2 x i64>* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %33) #8
  %34 = add nsw i32 %28, -1
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = bitcast <2 x i64>* %9 to <4 x i32>*
  store <4 x i32> %36, <4 x i32>* %37, align 16
  %38 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 1
  %39 = load i32, i32* %38, align 4
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 2
  %43 = load i32, i32* %42, align 8
  %44 = insertelement <4 x i32> undef, i32 %43, i32 0
  %45 = shufflevector <4 x i32> %44, <4 x i32> undef, <4 x i32> zeroinitializer
  %46 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 3
  %47 = load i32, i32* %46, align 4
  %48 = insertelement <4 x i32> undef, i32 %47, i32 0
  %49 = shufflevector <4 x i32> %48, <4 x i32> undef, <4 x i32> zeroinitializer
  %50 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 4
  %51 = load i32, i32* %50, align 16
  %52 = insertelement <4 x i32> undef, i32 %51, i32 0
  %53 = shufflevector <4 x i32> %52, <4 x i32> undef, <4 x i32> zeroinitializer
  %54 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 6
  %55 = load i32, i32* %54, align 8
  %56 = insertelement <4 x i32> undef, i32 %55, i32 0
  %57 = shufflevector <4 x i32> %56, <4 x i32> undef, <4 x i32> zeroinitializer
  %58 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 8
  %59 = load i32, i32* %58, align 16
  %60 = insertelement <4 x i32> undef, i32 %59, i32 0
  %61 = shufflevector <4 x i32> %60, <4 x i32> undef, <4 x i32> zeroinitializer
  %62 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 12
  %63 = load i32, i32* %62, align 16
  %64 = insertelement <4 x i32> undef, i32 %63, i32 0
  %65 = shufflevector <4 x i32> %64, <4 x i32> undef, <4 x i32> zeroinitializer
  %66 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 16
  %67 = load i32, i32* %66, align 16
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 20
  %71 = load i32, i32* %70, align 16
  %72 = insertelement <4 x i32> undef, i32 %71, i32 0
  %73 = shufflevector <4 x i32> %72, <4 x i32> undef, <4 x i32> zeroinitializer
  %74 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 24
  %75 = load i32, i32* %74, align 16
  %76 = insertelement <4 x i32> undef, i32 %75, i32 0
  %77 = shufflevector <4 x i32> %76, <4 x i32> undef, <4 x i32> zeroinitializer
  %78 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 28
  %79 = load i32, i32* %78, align 16
  %80 = insertelement <4 x i32> undef, i32 %79, i32 0
  %81 = shufflevector <4 x i32> %80, <4 x i32> undef, <4 x i32> zeroinitializer
  %82 = bitcast <2 x i64>* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %82) #8
  %83 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 32
  %84 = load i32, i32* %83, align 16
  %85 = insertelement <4 x i32> undef, i32 %84, i32 0
  %86 = shufflevector <4 x i32> %85, <4 x i32> undef, <4 x i32> zeroinitializer
  %87 = bitcast <2 x i64>* %10 to <4 x i32>*
  store <4 x i32> %86, <4 x i32>* %87, align 16
  %88 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 40
  %89 = load i32, i32* %88, align 16
  %90 = insertelement <4 x i32> undef, i32 %89, i32 0
  %91 = shufflevector <4 x i32> %90, <4 x i32> undef, <4 x i32> zeroinitializer
  %92 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 44
  %93 = load i32, i32* %92, align 16
  %94 = insertelement <4 x i32> undef, i32 %93, i32 0
  %95 = shufflevector <4 x i32> %94, <4 x i32> undef, <4 x i32> zeroinitializer
  %96 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 48
  %97 = load i32, i32* %96, align 16
  %98 = insertelement <4 x i32> undef, i32 %97, i32 0
  %99 = shufflevector <4 x i32> %98, <4 x i32> undef, <4 x i32> zeroinitializer
  %100 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 56
  %101 = load i32, i32* %100, align 16
  %102 = insertelement <4 x i32> undef, i32 %101, i32 0
  %103 = shufflevector <4 x i32> %102, <4 x i32> undef, <4 x i32> zeroinitializer
  %104 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 60
  %105 = load i32, i32* %104, align 16
  %106 = insertelement <4 x i32> undef, i32 %105, i32 0
  %107 = shufflevector <4 x i32> %106, <4 x i32> undef, <4 x i32> zeroinitializer
  %108 = sub nsw i32 0, %51
  %109 = insertelement <4 x i32> undef, i32 %108, i32 0
  %110 = shufflevector <4 x i32> %109, <4 x i32> undef, <4 x i32> zeroinitializer
  %111 = sub nsw i32 0, %59
  %112 = insertelement <4 x i32> undef, i32 %111, i32 0
  %113 = shufflevector <4 x i32> %112, <4 x i32> undef, <4 x i32> zeroinitializer
  %114 = sub nsw i32 0, %63
  %115 = insertelement <4 x i32> undef, i32 %114, i32 0
  %116 = shufflevector <4 x i32> %115, <4 x i32> undef, <4 x i32> zeroinitializer
  %117 = sub nsw i32 0, %67
  %118 = insertelement <4 x i32> undef, i32 %117, i32 0
  %119 = shufflevector <4 x i32> %118, <4 x i32> undef, <4 x i32> zeroinitializer
  %120 = sub nsw i32 0, %71
  %121 = insertelement <4 x i32> undef, i32 %120, i32 0
  %122 = shufflevector <4 x i32> %121, <4 x i32> undef, <4 x i32> zeroinitializer
  %123 = sub nsw i32 0, %75
  %124 = insertelement <4 x i32> undef, i32 %123, i32 0
  %125 = shufflevector <4 x i32> %124, <4 x i32> undef, <4 x i32> zeroinitializer
  %126 = sub nsw i32 0, %79
  %127 = insertelement <4 x i32> undef, i32 %126, i32 0
  %128 = shufflevector <4 x i32> %127, <4 x i32> undef, <4 x i32> zeroinitializer
  %129 = bitcast <2 x i64>* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %129) #8
  %130 = sub nsw i32 0, %84
  %131 = insertelement <4 x i32> undef, i32 %130, i32 0
  %132 = shufflevector <4 x i32> %131, <4 x i32> undef, <4 x i32> zeroinitializer
  %133 = bitcast <2 x i64>* %11 to <4 x i32>*
  store <4 x i32> %132, <4 x i32>* %133, align 16
  %134 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 36
  %135 = load i32, i32* %134, align 16
  %136 = sub nsw i32 0, %135
  %137 = insertelement <4 x i32> undef, i32 %136, i32 0
  %138 = shufflevector <4 x i32> %137, <4 x i32> undef, <4 x i32> zeroinitializer
  %139 = sub nsw i32 0, %89
  %140 = insertelement <4 x i32> undef, i32 %139, i32 0
  %141 = shufflevector <4 x i32> %140, <4 x i32> undef, <4 x i32> zeroinitializer
  %142 = sub nsw i32 0, %97
  %143 = insertelement <4 x i32> undef, i32 %142, i32 0
  %144 = shufflevector <4 x i32> %143, <4 x i32> undef, <4 x i32> zeroinitializer
  %145 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 52
  %146 = load i32, i32* %145, align 16
  %147 = sub nsw i32 0, %146
  %148 = insertelement <4 x i32> undef, i32 %147, i32 0
  %149 = shufflevector <4 x i32> %148, <4 x i32> undef, <4 x i32> zeroinitializer
  %150 = sub nsw i32 0, %101
  %151 = insertelement <4 x i32> undef, i32 %150, i32 0
  %152 = shufflevector <4 x i32> %151, <4 x i32> undef, <4 x i32> zeroinitializer
  %153 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 63
  %154 = load i32, i32* %153, align 4
  %155 = insertelement <4 x i32> undef, i32 %154, i32 0
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> zeroinitializer
  %157 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 57
  %158 = load i32, i32* %157, align 4
  %159 = sub nsw i32 0, %158
  %160 = insertelement <4 x i32> undef, i32 %159, i32 0
  %161 = shufflevector <4 x i32> %160, <4 x i32> undef, <4 x i32> zeroinitializer
  %162 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 7
  %163 = load i32, i32* %162, align 4
  %164 = insertelement <4 x i32> undef, i32 %163, i32 0
  %165 = shufflevector <4 x i32> %164, <4 x i32> undef, <4 x i32> zeroinitializer
  %166 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 5
  %167 = load i32, i32* %166, align 4
  %168 = insertelement <4 x i32> undef, i32 %167, i32 0
  %169 = shufflevector <4 x i32> %168, <4 x i32> undef, <4 x i32> zeroinitializer
  %170 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 59
  %171 = load i32, i32* %170, align 4
  %172 = insertelement <4 x i32> undef, i32 %171, i32 0
  %173 = shufflevector <4 x i32> %172, <4 x i32> undef, <4 x i32> zeroinitializer
  %174 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 61
  %175 = load i32, i32* %174, align 4
  %176 = sub nsw i32 0, %175
  %177 = insertelement <4 x i32> undef, i32 %176, i32 0
  %178 = shufflevector <4 x i32> %177, <4 x i32> undef, <4 x i32> zeroinitializer
  %179 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 58
  %180 = load i32, i32* %179, align 8
  %181 = sub nsw i32 0, %180
  %182 = insertelement <4 x i32> undef, i32 %181, i32 0
  %183 = shufflevector <4 x i32> %182, <4 x i32> undef, <4 x i32> zeroinitializer
  %184 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 62
  %185 = load i32, i32* %184, align 8
  %186 = insertelement <4 x i32> undef, i32 %185, i32 0
  %187 = shufflevector <4 x i32> %186, <4 x i32> undef, <4 x i32> zeroinitializer
  %188 = bitcast [64 x <2 x i64>]* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %188) #8
  %189 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 1
  %190 = bitcast <2 x i64>* %189 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %190, i8 -86, i64 992, i1 false)
  %191 = load <2 x i64>, <2 x i64>* %0, align 16
  %192 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 0
  store <2 x i64> %191, <2 x i64>* %192, align 16
  %193 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %194 = load <2 x i64>, <2 x i64>* %193, align 16
  %195 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 8
  store <2 x i64> %194, <2 x i64>* %195, align 16
  %196 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %197 = bitcast <2 x i64>* %196 to <4 x i32>*
  %198 = load <4 x i32>, <4 x i32>* %197, align 16
  %199 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 16
  %200 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %201 = bitcast <2 x i64>* %200 to <4 x i32>*
  %202 = load <4 x i32>, <4 x i32>* %201, align 16
  %203 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 24
  %204 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %205 = bitcast <2 x i64>* %204 to <4 x i32>*
  %206 = load <4 x i32>, <4 x i32>* %205, align 16
  %207 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 32
  %208 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %209 = bitcast <2 x i64>* %208 to <4 x i32>*
  %210 = load <4 x i32>, <4 x i32>* %209, align 16
  %211 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 40
  %212 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %213 = bitcast <2 x i64>* %212 to <4 x i32>*
  %214 = load <4 x i32>, <4 x i32>* %213, align 16
  %215 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 48
  %216 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %217 = bitcast <2 x i64>* %216 to <4 x i32>*
  %218 = load <4 x i32>, <4 x i32>* %217, align 16
  %219 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 56
  %220 = bitcast <2 x i64>* %207 to <4 x i32>*
  %221 = mul <4 x i32> %41, %206
  %222 = load <4 x i32>, <4 x i32>* %20, align 16
  %223 = add <4 x i32> %222, %221
  %224 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %223, i32 %2) #8
  %225 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 63
  %226 = bitcast <2 x i64>* %225 to <4 x i32>*
  store <4 x i32> %224, <4 x i32>* %226, align 16
  %227 = mul <4 x i32> %156, %206
  %228 = add <4 x i32> %222, %227
  %229 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %228, i32 %2) #8
  store <4 x i32> %229, <4 x i32>* %220, align 16
  %230 = bitcast <2 x i64>* %219 to <4 x i32>*
  %231 = mul <4 x i32> %161, %218
  %232 = add <4 x i32> %231, %222
  %233 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %232, i32 %2) #8
  %234 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 39
  %235 = bitcast <2 x i64>* %234 to <4 x i32>*
  store <4 x i32> %233, <4 x i32>* %235, align 16
  %236 = mul <4 x i32> %165, %218
  %237 = add <4 x i32> %236, %222
  %238 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %237, i32 %2) #8
  store <4 x i32> %238, <4 x i32>* %230, align 16
  %239 = bitcast <2 x i64>* %211 to <4 x i32>*
  %240 = mul <4 x i32> %169, %210
  %241 = add <4 x i32> %240, %222
  %242 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %241, i32 %2) #8
  %243 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 55
  %244 = bitcast <2 x i64>* %243 to <4 x i32>*
  store <4 x i32> %242, <4 x i32>* %244, align 16
  %245 = mul <4 x i32> %173, %210
  %246 = add <4 x i32> %245, %222
  %247 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %246, i32 %2) #8
  store <4 x i32> %247, <4 x i32>* %239, align 16
  %248 = bitcast <2 x i64>* %215 to <4 x i32>*
  %249 = mul <4 x i32> %178, %214
  %250 = add <4 x i32> %249, %222
  %251 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %250, i32 %2) #8
  %252 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 47
  %253 = bitcast <2 x i64>* %252 to <4 x i32>*
  store <4 x i32> %251, <4 x i32>* %253, align 16
  %254 = mul <4 x i32> %49, %214
  %255 = add <4 x i32> %254, %222
  %256 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %255, i32 %2) #8
  store <4 x i32> %256, <4 x i32>* %248, align 16
  %257 = bitcast <2 x i64>* %199 to <4 x i32>*
  %258 = mul <4 x i32> %45, %198
  %259 = add <4 x i32> %258, %222
  %260 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %259, i32 %2) #8
  %261 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 31
  %262 = bitcast <2 x i64>* %261 to <4 x i32>*
  store <4 x i32> %260, <4 x i32>* %262, align 16
  %263 = mul <4 x i32> %187, %198
  %264 = add <4 x i32> %263, %222
  %265 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %264, i32 %2) #8
  store <4 x i32> %265, <4 x i32>* %257, align 16
  %266 = bitcast <2 x i64>* %203 to <4 x i32>*
  %267 = mul <4 x i32> %183, %202
  %268 = add <4 x i32> %267, %222
  %269 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %268, i32 %2) #8
  %270 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 23
  %271 = bitcast <2 x i64>* %270 to <4 x i32>*
  store <4 x i32> %269, <4 x i32>* %271, align 16
  %272 = mul <4 x i32> %57, %202
  %273 = add <4 x i32> %272, %222
  %274 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %273, i32 %2) #8
  store <4 x i32> %274, <4 x i32>* %266, align 16
  %275 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 33
  %276 = bitcast <2 x i64>* %275 to <4 x i32>*
  %277 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 38
  %278 = bitcast <2 x i64>* %277 to <4 x i32>*
  %279 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 41
  %280 = bitcast <2 x i64>* %279 to <4 x i32>*
  %281 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 46
  %282 = bitcast <2 x i64>* %281 to <4 x i32>*
  %283 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 49
  %284 = bitcast <2 x i64>* %283 to <4 x i32>*
  %285 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 54
  %286 = bitcast <2 x i64>* %285 to <4 x i32>*
  %287 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 57
  %288 = bitcast <2 x i64>* %287 to <4 x i32>*
  %289 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 62
  %290 = bitcast <2 x i64>* %289 to <4 x i32>*
  %291 = bitcast <2 x i64>* %195 to <4 x i32>*
  %292 = load <4 x i32>, <4 x i32>* %291, align 16
  %293 = mul <4 x i32> %292, %53
  %294 = add <4 x i32> %293, %222
  %295 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %294, i32 %2) #8
  %296 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 15
  %297 = bitcast <2 x i64>* %296 to <4 x i32>*
  store <4 x i32> %295, <4 x i32>* %297, align 16
  %298 = mul <4 x i32> %292, %107
  %299 = add <4 x i32> %298, %222
  %300 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %299, i32 %2) #8
  store <4 x i32> %300, <4 x i32>* %291, align 16
  %301 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 17
  %302 = bitcast <2 x i64>* %301 to <4 x i32>*
  %303 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 22
  %304 = bitcast <2 x i64>* %303 to <4 x i32>*
  %305 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 25
  %306 = bitcast <2 x i64>* %305 to <4 x i32>*
  %307 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 30
  %308 = bitcast <2 x i64>* %307 to <4 x i32>*
  %309 = mul <4 x i32> %229, %110
  %310 = mul <4 x i32> %224, %107
  %311 = add <4 x i32> %309, %222
  %312 = add <4 x i32> %311, %310
  %313 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %312, i32 %2) #8
  %314 = mul <4 x i32> %229, %107
  %315 = mul <4 x i32> %224, %53
  %316 = add <4 x i32> %314, %222
  %317 = add <4 x i32> %316, %315
  %318 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %317, i32 %2) #8
  store <4 x i32> %318, <4 x i32>* %290, align 16
  store <4 x i32> %313, <4 x i32>* %276, align 16
  %319 = mul <4 x i32> %233, %138
  %320 = mul <4 x i32> %238, %81
  %321 = add <4 x i32> %319, %222
  %322 = add <4 x i32> %321, %320
  %323 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %322, i32 %2) #8
  %324 = mul <4 x i32> %233, %128
  %325 = mul <4 x i32> %238, %138
  %326 = add <4 x i32> %324, %222
  %327 = add <4 x i32> %326, %325
  %328 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %327, i32 %2) #8
  store <4 x i32> %328, <4 x i32>* %278, align 16
  store <4 x i32> %323, <4 x i32>* %288, align 16
  %329 = mul <4 x i32> %247, %122
  %330 = mul <4 x i32> %242, %95
  %331 = add <4 x i32> %329, %222
  %332 = add <4 x i32> %331, %330
  %333 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %332, i32 %2) #8
  %334 = mul <4 x i32> %247, %95
  %335 = mul <4 x i32> %242, %73
  %336 = add <4 x i32> %334, %222
  %337 = add <4 x i32> %336, %335
  %338 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %337, i32 %2) #8
  store <4 x i32> %338, <4 x i32>* %286, align 16
  store <4 x i32> %333, <4 x i32>* %280, align 16
  %339 = mul <4 x i32> %251, %116
  %340 = mul <4 x i32> %256, %149
  %341 = add <4 x i32> %339, %222
  %342 = add <4 x i32> %341, %340
  %343 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %342, i32 %2) #8
  %344 = mul <4 x i32> %251, %149
  %345 = mul <4 x i32> %256, %65
  %346 = add <4 x i32> %344, %222
  %347 = add <4 x i32> %346, %345
  %348 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %347, i32 %2) #8
  store <4 x i32> %348, <4 x i32>* %284, align 16
  store <4 x i32> %343, <4 x i32>* %282, align 16
  %349 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 9
  %350 = bitcast <2 x i64>* %349 to <4 x i32>*
  %351 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 14
  %352 = bitcast <2 x i64>* %351 to <4 x i32>*
  %353 = mul <4 x i32> %265, %113
  %354 = mul <4 x i32> %260, %103
  %355 = add <4 x i32> %353, %222
  %356 = add <4 x i32> %355, %354
  %357 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %356, i32 %2) #8
  %358 = mul <4 x i32> %265, %103
  %359 = mul <4 x i32> %260, %61
  %360 = add <4 x i32> %358, %222
  %361 = add <4 x i32> %360, %359
  %362 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %361, i32 %2) #8
  store <4 x i32> %362, <4 x i32>* %308, align 16
  store <4 x i32> %357, <4 x i32>* %302, align 16
  %363 = mul <4 x i32> %269, %125
  %364 = mul <4 x i32> %274, %141
  %365 = add <4 x i32> %363, %222
  %366 = add <4 x i32> %365, %364
  %367 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %366, i32 %2) #8
  %368 = mul <4 x i32> %269, %141
  %369 = mul <4 x i32> %274, %77
  %370 = add <4 x i32> %368, %222
  %371 = add <4 x i32> %370, %369
  %372 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %371, i32 %2) #8
  store <4 x i32> %372, <4 x i32>* %306, align 16
  store <4 x i32> %367, <4 x i32>* %304, align 16
  %373 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 35
  %374 = bitcast <2 x i64>* %373 to <4 x i32>*
  store <4 x i32> %229, <4 x i32>* %374, align 16
  %375 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 34
  %376 = bitcast <2 x i64>* %375 to <4 x i32>*
  %377 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 36
  %378 = bitcast <2 x i64>* %377 to <4 x i32>*
  store <4 x i32> %233, <4 x i32>* %378, align 16
  %379 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 37
  %380 = bitcast <2 x i64>* %379 to <4 x i32>*
  store <4 x i32> %328, <4 x i32>* %380, align 16
  %381 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 43
  %382 = bitcast <2 x i64>* %381 to <4 x i32>*
  store <4 x i32> %247, <4 x i32>* %382, align 16
  %383 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 42
  %384 = bitcast <2 x i64>* %383 to <4 x i32>*
  store <4 x i32> %333, <4 x i32>* %384, align 16
  %385 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 44
  %386 = bitcast <2 x i64>* %385 to <4 x i32>*
  store <4 x i32> %251, <4 x i32>* %386, align 16
  %387 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 45
  %388 = bitcast <2 x i64>* %387 to <4 x i32>*
  store <4 x i32> %343, <4 x i32>* %388, align 16
  %389 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 51
  %390 = bitcast <2 x i64>* %389 to <4 x i32>*
  store <4 x i32> %256, <4 x i32>* %390, align 16
  %391 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 50
  %392 = bitcast <2 x i64>* %391 to <4 x i32>*
  store <4 x i32> %348, <4 x i32>* %392, align 16
  %393 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 52
  %394 = bitcast <2 x i64>* %393 to <4 x i32>*
  store <4 x i32> %242, <4 x i32>* %394, align 16
  %395 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 53
  %396 = bitcast <2 x i64>* %395 to <4 x i32>*
  store <4 x i32> %338, <4 x i32>* %396, align 16
  %397 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 59
  %398 = bitcast <2 x i64>* %397 to <4 x i32>*
  %399 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 58
  %400 = bitcast <2 x i64>* %399 to <4 x i32>*
  store <4 x i32> %323, <4 x i32>* %400, align 16
  %401 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 60
  %402 = bitcast <2 x i64>* %401 to <4 x i32>*
  %403 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 61
  %404 = bitcast <2 x i64>* %403 to <4 x i32>*
  %405 = load <4 x i32>, <4 x i32>* %87, align 16
  %406 = bitcast [64 x <2 x i64>]* %12 to <4 x i32>*
  %407 = load <4 x i32>, <4 x i32>* %406, align 16
  %408 = mul <4 x i32> %407, %405
  %409 = add <4 x i32> %408, %222
  %410 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %409, i32 %2) #8
  %411 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 1
  %412 = bitcast <2 x i64>* %411 to <4 x i32>*
  store <4 x i32> %410, <4 x i32>* %412, align 16
  store <4 x i32> %410, <4 x i32>* %406, align 16
  %413 = mul <4 x i32> %300, %119
  %414 = mul <4 x i32> %295, %99
  %415 = add <4 x i32> %413, %222
  %416 = add <4 x i32> %415, %414
  %417 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %416, i32 %2) #8
  %418 = mul <4 x i32> %300, %99
  %419 = mul <4 x i32> %295, %69
  %420 = add <4 x i32> %418, %222
  %421 = add <4 x i32> %420, %419
  %422 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %421, i32 %2) #8
  store <4 x i32> %422, <4 x i32>* %352, align 16
  store <4 x i32> %417, <4 x i32>* %350, align 16
  %423 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 19
  %424 = bitcast <2 x i64>* %423 to <4 x i32>*
  store <4 x i32> %265, <4 x i32>* %424, align 16
  %425 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 18
  %426 = bitcast <2 x i64>* %425 to <4 x i32>*
  store <4 x i32> %357, <4 x i32>* %426, align 16
  %427 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 20
  %428 = bitcast <2 x i64>* %427 to <4 x i32>*
  store <4 x i32> %269, <4 x i32>* %428, align 16
  %429 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 21
  %430 = bitcast <2 x i64>* %429 to <4 x i32>*
  store <4 x i32> %367, <4 x i32>* %430, align 16
  %431 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 27
  %432 = bitcast <2 x i64>* %431 to <4 x i32>*
  store <4 x i32> %274, <4 x i32>* %432, align 16
  %433 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 26
  %434 = bitcast <2 x i64>* %433 to <4 x i32>*
  store <4 x i32> %372, <4 x i32>* %434, align 16
  %435 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 28
  %436 = bitcast <2 x i64>* %435 to <4 x i32>*
  store <4 x i32> %260, <4 x i32>* %436, align 16
  %437 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 29
  %438 = bitcast <2 x i64>* %437 to <4 x i32>*
  store <4 x i32> %362, <4 x i32>* %438, align 16
  %439 = mul <4 x i32> %313, %113
  %440 = mul <4 x i32> %318, %103
  %441 = add <4 x i32> %439, %222
  %442 = add <4 x i32> %441, %440
  %443 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %442, i32 %2) #8
  %444 = mul <4 x i32> %313, %103
  %445 = mul <4 x i32> %318, %61
  %446 = add <4 x i32> %444, %222
  %447 = add <4 x i32> %446, %445
  %448 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %447, i32 %2) #8
  store <4 x i32> %448, <4 x i32>* %404, align 16
  store <4 x i32> %443, <4 x i32>* %376, align 16
  %449 = load <4 x i32>, <4 x i32>* %374, align 16
  %450 = mul <4 x i32> %449, %113
  %451 = mul <4 x i32> %224, %103
  %452 = add <4 x i32> %450, %222
  %453 = add <4 x i32> %452, %451
  %454 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %453, i32 %2) #8
  %455 = mul <4 x i32> %449, %103
  %456 = mul <4 x i32> %224, %61
  %457 = add <4 x i32> %455, %222
  %458 = add <4 x i32> %457, %456
  %459 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %458, i32 %2) #8
  store <4 x i32> %459, <4 x i32>* %402, align 16
  store <4 x i32> %454, <4 x i32>* %374, align 16
  %460 = load <4 x i32>, <4 x i32>* %378, align 16
  %461 = mul <4 x i32> %460, %152
  %462 = mul <4 x i32> %238, %113
  %463 = add <4 x i32> %461, %222
  %464 = add <4 x i32> %463, %462
  %465 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %464, i32 %2) #8
  %466 = mul <4 x i32> %460, %113
  %467 = mul <4 x i32> %238, %103
  %468 = add <4 x i32> %466, %222
  %469 = add <4 x i32> %468, %467
  %470 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %469, i32 %2) #8
  store <4 x i32> %470, <4 x i32>* %398, align 16
  store <4 x i32> %465, <4 x i32>* %378, align 16
  %471 = load <4 x i32>, <4 x i32>* %380, align 16
  %472 = mul <4 x i32> %471, %152
  %473 = mul <4 x i32> %323, %113
  %474 = add <4 x i32> %472, %222
  %475 = add <4 x i32> %474, %473
  %476 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %475, i32 %2) #8
  %477 = mul <4 x i32> %471, %113
  %478 = mul <4 x i32> %323, %103
  %479 = add <4 x i32> %477, %222
  %480 = add <4 x i32> %479, %478
  %481 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %480, i32 %2) #8
  store <4 x i32> %481, <4 x i32>* %400, align 16
  store <4 x i32> %476, <4 x i32>* %380, align 16
  %482 = load <4 x i32>, <4 x i32>* %384, align 16
  %483 = mul <4 x i32> %482, %141
  %484 = load <4 x i32>, <4 x i32>* %396, align 16
  %485 = mul <4 x i32> %484, %77
  %486 = add <4 x i32> %483, %222
  %487 = add <4 x i32> %486, %485
  %488 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %487, i32 %2) #8
  %489 = mul <4 x i32> %482, %77
  %490 = mul <4 x i32> %484, %91
  %491 = add <4 x i32> %489, %222
  %492 = add <4 x i32> %491, %490
  %493 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %492, i32 %2) #8
  store <4 x i32> %493, <4 x i32>* %396, align 16
  store <4 x i32> %488, <4 x i32>* %384, align 16
  %494 = load <4 x i32>, <4 x i32>* %382, align 16
  %495 = mul <4 x i32> %494, %141
  %496 = load <4 x i32>, <4 x i32>* %394, align 16
  %497 = mul <4 x i32> %496, %77
  %498 = add <4 x i32> %495, %222
  %499 = add <4 x i32> %498, %497
  %500 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %499, i32 %2) #8
  %501 = mul <4 x i32> %494, %77
  %502 = mul <4 x i32> %496, %91
  %503 = add <4 x i32> %501, %222
  %504 = add <4 x i32> %503, %502
  %505 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %504, i32 %2) #8
  store <4 x i32> %505, <4 x i32>* %394, align 16
  store <4 x i32> %500, <4 x i32>* %382, align 16
  %506 = load <4 x i32>, <4 x i32>* %386, align 16
  %507 = mul <4 x i32> %506, %125
  %508 = load <4 x i32>, <4 x i32>* %390, align 16
  %509 = mul <4 x i32> %508, %141
  %510 = add <4 x i32> %507, %222
  %511 = add <4 x i32> %510, %509
  %512 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %511, i32 %2) #8
  %513 = mul <4 x i32> %506, %141
  %514 = mul <4 x i32> %508, %77
  %515 = add <4 x i32> %513, %222
  %516 = add <4 x i32> %515, %514
  %517 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %516, i32 %2) #8
  store <4 x i32> %517, <4 x i32>* %390, align 16
  store <4 x i32> %512, <4 x i32>* %386, align 16
  %518 = load <4 x i32>, <4 x i32>* %388, align 16
  %519 = mul <4 x i32> %518, %125
  %520 = load <4 x i32>, <4 x i32>* %392, align 16
  %521 = mul <4 x i32> %520, %141
  %522 = add <4 x i32> %519, %222
  %523 = add <4 x i32> %522, %521
  %524 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %523, i32 %2) #8
  %525 = mul <4 x i32> %518, %141
  %526 = mul <4 x i32> %520, %77
  %527 = add <4 x i32> %525, %222
  %528 = add <4 x i32> %527, %526
  %529 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %528, i32 %2) #8
  store <4 x i32> %529, <4 x i32>* %392, align 16
  store <4 x i32> %524, <4 x i32>* %388, align 16
  %530 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 3
  %531 = bitcast <2 x i64>* %530 to <4 x i32>*
  store <4 x i32> %410, <4 x i32>* %531, align 16
  %532 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 2
  %533 = bitcast <2 x i64>* %532 to <4 x i32>*
  store <4 x i32> %410, <4 x i32>* %533, align 16
  %534 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 11
  %535 = bitcast <2 x i64>* %534 to <4 x i32>*
  store <4 x i32> %300, <4 x i32>* %535, align 16
  %536 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 10
  %537 = bitcast <2 x i64>* %536 to <4 x i32>*
  store <4 x i32> %417, <4 x i32>* %537, align 16
  %538 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 12
  %539 = bitcast <2 x i64>* %538 to <4 x i32>*
  store <4 x i32> %295, <4 x i32>* %539, align 16
  %540 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 13
  %541 = bitcast <2 x i64>* %540 to <4 x i32>*
  store <4 x i32> %422, <4 x i32>* %541, align 16
  %542 = load <4 x i32>, <4 x i32>* %426, align 16
  %543 = mul <4 x i32> %542, %119
  %544 = load <4 x i32>, <4 x i32>* %438, align 16
  %545 = mul <4 x i32> %544, %99
  %546 = add <4 x i32> %543, %222
  %547 = add <4 x i32> %546, %545
  %548 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %547, i32 %2) #8
  %549 = mul <4 x i32> %542, %99
  %550 = mul <4 x i32> %544, %69
  %551 = add <4 x i32> %549, %222
  %552 = add <4 x i32> %551, %550
  %553 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %552, i32 %2) #8
  store <4 x i32> %553, <4 x i32>* %438, align 16
  store <4 x i32> %548, <4 x i32>* %426, align 16
  %554 = load <4 x i32>, <4 x i32>* %424, align 16
  %555 = mul <4 x i32> %554, %119
  %556 = load <4 x i32>, <4 x i32>* %436, align 16
  %557 = mul <4 x i32> %556, %99
  %558 = add <4 x i32> %555, %222
  %559 = add <4 x i32> %558, %557
  %560 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %559, i32 %2) #8
  %561 = mul <4 x i32> %554, %99
  %562 = mul <4 x i32> %556, %69
  %563 = add <4 x i32> %561, %222
  %564 = add <4 x i32> %563, %562
  %565 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %564, i32 %2) #8
  store <4 x i32> %565, <4 x i32>* %436, align 16
  store <4 x i32> %560, <4 x i32>* %424, align 16
  %566 = load <4 x i32>, <4 x i32>* %428, align 16
  %567 = mul <4 x i32> %566, %144
  %568 = load <4 x i32>, <4 x i32>* %432, align 16
  %569 = mul <4 x i32> %568, %119
  %570 = add <4 x i32> %567, %222
  %571 = add <4 x i32> %570, %569
  %572 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %571, i32 %2) #8
  %573 = mul <4 x i32> %566, %119
  %574 = mul <4 x i32> %568, %99
  %575 = add <4 x i32> %573, %222
  %576 = add <4 x i32> %575, %574
  %577 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %576, i32 %2) #8
  store <4 x i32> %577, <4 x i32>* %432, align 16
  store <4 x i32> %572, <4 x i32>* %428, align 16
  %578 = load <4 x i32>, <4 x i32>* %430, align 16
  %579 = mul <4 x i32> %578, %144
  %580 = load <4 x i32>, <4 x i32>* %434, align 16
  %581 = mul <4 x i32> %580, %119
  %582 = add <4 x i32> %579, %222
  %583 = add <4 x i32> %582, %581
  %584 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %583, i32 %2) #8
  %585 = mul <4 x i32> %578, %119
  %586 = mul <4 x i32> %580, %99
  %587 = add <4 x i32> %585, %222
  %588 = add <4 x i32> %587, %586
  %589 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %588, i32 %2) #8
  store <4 x i32> %589, <4 x i32>* %434, align 16
  store <4 x i32> %584, <4 x i32>* %430, align 16
  %590 = load <4 x i32>, <4 x i32>* %32, align 16
  %591 = load <4 x i32>, <4 x i32>* %37, align 16
  br label %592

592:                                              ; preds = %6, %592
  %593 = phi i64 [ 32, %6 ], [ %752, %592 ]
  %594 = phi i32 [ 32, %6 ], [ %750, %592 ]
  %595 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %593
  %596 = bitcast <2 x i64>* %595 to <4 x i32>*
  %597 = load <4 x i32>, <4 x i32>* %596, align 16
  %598 = and i64 %593, 4294967280
  %599 = or i64 %598, 7
  %600 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %599
  %601 = bitcast <2 x i64>* %600 to <4 x i32>*
  %602 = load <4 x i32>, <4 x i32>* %601, align 16
  %603 = add <4 x i32> %602, %597
  %604 = sub <4 x i32> %597, %602
  %605 = icmp sgt <4 x i32> %603, %590
  %606 = select <4 x i1> %605, <4 x i32> %603, <4 x i32> %590
  %607 = icmp slt <4 x i32> %606, %591
  %608 = select <4 x i1> %607, <4 x i32> %606, <4 x i32> %591
  %609 = icmp sgt <4 x i32> %604, %590
  %610 = select <4 x i1> %609, <4 x i32> %604, <4 x i32> %590
  %611 = icmp slt <4 x i32> %610, %591
  %612 = select <4 x i1> %611, <4 x i32> %610, <4 x i32> %591
  store <4 x i32> %608, <4 x i32>* %596, align 16
  store <4 x i32> %612, <4 x i32>* %601, align 16
  %613 = and i64 %593, 4294967280
  %614 = or i64 %613, 15
  %615 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %614
  %616 = bitcast <2 x i64>* %615 to <4 x i32>*
  %617 = load <4 x i32>, <4 x i32>* %616, align 16
  %618 = and i64 %593, 4294967280
  %619 = or i64 %618, 8
  %620 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %619
  %621 = bitcast <2 x i64>* %620 to <4 x i32>*
  %622 = load <4 x i32>, <4 x i32>* %621, align 16
  %623 = add <4 x i32> %622, %617
  %624 = sub <4 x i32> %617, %622
  %625 = icmp sgt <4 x i32> %623, %590
  %626 = select <4 x i1> %625, <4 x i32> %623, <4 x i32> %590
  %627 = icmp slt <4 x i32> %626, %591
  %628 = select <4 x i1> %627, <4 x i32> %626, <4 x i32> %591
  %629 = icmp sgt <4 x i32> %624, %590
  %630 = select <4 x i1> %629, <4 x i32> %624, <4 x i32> %590
  %631 = icmp slt <4 x i32> %630, %591
  %632 = select <4 x i1> %631, <4 x i32> %630, <4 x i32> %591
  store <4 x i32> %628, <4 x i32>* %616, align 16
  store <4 x i32> %632, <4 x i32>* %621, align 16
  %633 = or i64 %593, 1
  %634 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %633
  %635 = bitcast <2 x i64>* %634 to <4 x i32>*
  %636 = load <4 x i32>, <4 x i32>* %635, align 16
  %637 = and i64 %593, 4294967280
  %638 = or i64 %637, 6
  %639 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %638
  %640 = bitcast <2 x i64>* %639 to <4 x i32>*
  %641 = load <4 x i32>, <4 x i32>* %640, align 16
  %642 = add <4 x i32> %641, %636
  %643 = sub <4 x i32> %636, %641
  %644 = icmp sgt <4 x i32> %642, %590
  %645 = select <4 x i1> %644, <4 x i32> %642, <4 x i32> %590
  %646 = icmp slt <4 x i32> %645, %591
  %647 = select <4 x i1> %646, <4 x i32> %645, <4 x i32> %591
  %648 = icmp sgt <4 x i32> %643, %590
  %649 = select <4 x i1> %648, <4 x i32> %643, <4 x i32> %590
  %650 = icmp slt <4 x i32> %649, %591
  %651 = select <4 x i1> %650, <4 x i32> %649, <4 x i32> %591
  store <4 x i32> %647, <4 x i32>* %635, align 16
  store <4 x i32> %651, <4 x i32>* %640, align 16
  %652 = and i64 %593, 4294967280
  %653 = or i64 %652, 14
  %654 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %653
  %655 = bitcast <2 x i64>* %654 to <4 x i32>*
  %656 = load <4 x i32>, <4 x i32>* %655, align 16
  %657 = and i64 %633, 4294967281
  %658 = or i64 %657, 8
  %659 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %658
  %660 = bitcast <2 x i64>* %659 to <4 x i32>*
  %661 = load <4 x i32>, <4 x i32>* %660, align 16
  %662 = add <4 x i32> %661, %656
  %663 = sub <4 x i32> %656, %661
  %664 = icmp sgt <4 x i32> %662, %590
  %665 = select <4 x i1> %664, <4 x i32> %662, <4 x i32> %590
  %666 = icmp slt <4 x i32> %665, %591
  %667 = select <4 x i1> %666, <4 x i32> %665, <4 x i32> %591
  %668 = icmp sgt <4 x i32> %663, %590
  %669 = select <4 x i1> %668, <4 x i32> %663, <4 x i32> %590
  %670 = icmp slt <4 x i32> %669, %591
  %671 = select <4 x i1> %670, <4 x i32> %669, <4 x i32> %591
  store <4 x i32> %667, <4 x i32>* %655, align 16
  store <4 x i32> %671, <4 x i32>* %660, align 16
  %672 = add nuw nsw i64 %633, 1
  %673 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %672
  %674 = bitcast <2 x i64>* %673 to <4 x i32>*
  %675 = load <4 x i32>, <4 x i32>* %674, align 16
  %676 = and i64 %672, 4294967280
  %677 = or i64 %676, 5
  %678 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %677
  %679 = bitcast <2 x i64>* %678 to <4 x i32>*
  %680 = load <4 x i32>, <4 x i32>* %679, align 16
  %681 = add <4 x i32> %680, %675
  %682 = sub <4 x i32> %675, %680
  %683 = icmp sgt <4 x i32> %681, %590
  %684 = select <4 x i1> %683, <4 x i32> %681, <4 x i32> %590
  %685 = icmp slt <4 x i32> %684, %591
  %686 = select <4 x i1> %685, <4 x i32> %684, <4 x i32> %591
  %687 = icmp sgt <4 x i32> %682, %590
  %688 = select <4 x i1> %687, <4 x i32> %682, <4 x i32> %590
  %689 = icmp slt <4 x i32> %688, %591
  %690 = select <4 x i1> %689, <4 x i32> %688, <4 x i32> %591
  store <4 x i32> %686, <4 x i32>* %674, align 16
  store <4 x i32> %690, <4 x i32>* %679, align 16
  %691 = and i64 %672, 4294967280
  %692 = or i64 %691, 13
  %693 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %692
  %694 = bitcast <2 x i64>* %693 to <4 x i32>*
  %695 = load <4 x i32>, <4 x i32>* %694, align 16
  %696 = and i64 %672, 4294967282
  %697 = or i64 %696, 8
  %698 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %697
  %699 = bitcast <2 x i64>* %698 to <4 x i32>*
  %700 = load <4 x i32>, <4 x i32>* %699, align 16
  %701 = add <4 x i32> %700, %695
  %702 = sub <4 x i32> %695, %700
  %703 = icmp sgt <4 x i32> %701, %590
  %704 = select <4 x i1> %703, <4 x i32> %701, <4 x i32> %590
  %705 = icmp slt <4 x i32> %704, %591
  %706 = select <4 x i1> %705, <4 x i32> %704, <4 x i32> %591
  %707 = icmp sgt <4 x i32> %702, %590
  %708 = select <4 x i1> %707, <4 x i32> %702, <4 x i32> %590
  %709 = icmp slt <4 x i32> %708, %591
  %710 = select <4 x i1> %709, <4 x i32> %708, <4 x i32> %591
  store <4 x i32> %706, <4 x i32>* %694, align 16
  store <4 x i32> %710, <4 x i32>* %699, align 16
  %711 = or i64 %593, 3
  %712 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %711
  %713 = bitcast <2 x i64>* %712 to <4 x i32>*
  %714 = load <4 x i32>, <4 x i32>* %713, align 16
  %715 = and i64 %593, 4294967280
  %716 = or i64 %715, 4
  %717 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %716
  %718 = bitcast <2 x i64>* %717 to <4 x i32>*
  %719 = load <4 x i32>, <4 x i32>* %718, align 16
  %720 = add <4 x i32> %719, %714
  %721 = sub <4 x i32> %714, %719
  %722 = icmp sgt <4 x i32> %720, %590
  %723 = select <4 x i1> %722, <4 x i32> %720, <4 x i32> %590
  %724 = icmp slt <4 x i32> %723, %591
  %725 = select <4 x i1> %724, <4 x i32> %723, <4 x i32> %591
  %726 = icmp sgt <4 x i32> %721, %590
  %727 = select <4 x i1> %726, <4 x i32> %721, <4 x i32> %590
  %728 = icmp slt <4 x i32> %727, %591
  %729 = select <4 x i1> %728, <4 x i32> %727, <4 x i32> %591
  store <4 x i32> %725, <4 x i32>* %713, align 16
  store <4 x i32> %729, <4 x i32>* %718, align 16
  %730 = and i64 %593, 4294967280
  %731 = or i64 %730, 12
  %732 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %731
  %733 = bitcast <2 x i64>* %732 to <4 x i32>*
  %734 = load <4 x i32>, <4 x i32>* %733, align 16
  %735 = and i64 %711, 4294967283
  %736 = or i64 %735, 8
  %737 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %736
  %738 = bitcast <2 x i64>* %737 to <4 x i32>*
  %739 = load <4 x i32>, <4 x i32>* %738, align 16
  %740 = add <4 x i32> %739, %734
  %741 = sub <4 x i32> %734, %739
  %742 = icmp sgt <4 x i32> %740, %590
  %743 = select <4 x i1> %742, <4 x i32> %740, <4 x i32> %590
  %744 = icmp slt <4 x i32> %743, %591
  %745 = select <4 x i1> %744, <4 x i32> %743, <4 x i32> %591
  %746 = icmp sgt <4 x i32> %741, %590
  %747 = select <4 x i1> %746, <4 x i32> %741, <4 x i32> %590
  %748 = icmp slt <4 x i32> %747, %591
  %749 = select <4 x i1> %748, <4 x i32> %747, <4 x i32> %591
  store <4 x i32> %745, <4 x i32>* %733, align 16
  store <4 x i32> %749, <4 x i32>* %738, align 16
  %750 = add nuw nsw i32 %594, 16
  %751 = icmp ult i32 %750, 64
  %752 = add nuw nsw i64 %593, 16
  br i1 %751, label %592, label %753

753:                                              ; preds = %592
  %754 = load <2 x i64>, <2 x i64>* %192, align 16
  %755 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 7
  store <2 x i64> %754, <2 x i64>* %755, align 16
  %756 = load <2 x i64>, <2 x i64>* %411, align 16
  %757 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 6
  store <2 x i64> %756, <2 x i64>* %757, align 16
  %758 = load <2 x i64>, <2 x i64>* %532, align 16
  %759 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 5
  store <2 x i64> %758, <2 x i64>* %759, align 16
  %760 = load <2 x i64>, <2 x i64>* %530, align 16
  %761 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 4
  store <2 x i64> %760, <2 x i64>* %761, align 16
  %762 = load <4 x i32>, <4 x i32>* %133, align 16
  %763 = load <4 x i32>, <4 x i32>* %537, align 16
  %764 = mul <4 x i32> %763, %762
  %765 = load <4 x i32>, <4 x i32>* %541, align 16
  %766 = mul <4 x i32> %765, %405
  %767 = load <4 x i32>, <4 x i32>* %20, align 16
  %768 = add <4 x i32> %767, %766
  %769 = add <4 x i32> %768, %764
  %770 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %769, i32 %2) #8
  %771 = mul <4 x i32> %763, %405
  %772 = add <4 x i32> %768, %771
  %773 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %772, i32 %2) #8
  store <4 x i32> %773, <4 x i32>* %541, align 16
  store <4 x i32> %770, <4 x i32>* %537, align 16
  %774 = load <4 x i32>, <4 x i32>* %535, align 16
  %775 = mul <4 x i32> %774, %762
  %776 = load <4 x i32>, <4 x i32>* %539, align 16
  %777 = mul <4 x i32> %776, %405
  %778 = add <4 x i32> %777, %767
  %779 = add <4 x i32> %778, %775
  %780 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %779, i32 %2) #8
  %781 = mul <4 x i32> %774, %405
  %782 = add <4 x i32> %778, %781
  %783 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %782, i32 %2) #8
  store <4 x i32> %783, <4 x i32>* %539, align 16
  store <4 x i32> %780, <4 x i32>* %535, align 16
  %784 = load <4 x i32>, <4 x i32>* %257, align 16
  %785 = load <4 x i32>, <4 x i32>* %271, align 16
  %786 = add <4 x i32> %785, %784
  %787 = sub <4 x i32> %784, %785
  %788 = load <4 x i32>, <4 x i32>* %32, align 16
  %789 = icmp sgt <4 x i32> %786, %788
  %790 = select <4 x i1> %789, <4 x i32> %786, <4 x i32> %788
  %791 = load <4 x i32>, <4 x i32>* %37, align 16
  %792 = icmp slt <4 x i32> %790, %791
  %793 = select <4 x i1> %792, <4 x i32> %790, <4 x i32> %791
  %794 = icmp sgt <4 x i32> %787, %788
  %795 = select <4 x i1> %794, <4 x i32> %787, <4 x i32> %788
  %796 = icmp slt <4 x i32> %795, %791
  %797 = select <4 x i1> %796, <4 x i32> %795, <4 x i32> %791
  store <4 x i32> %793, <4 x i32>* %257, align 16
  store <4 x i32> %797, <4 x i32>* %271, align 16
  %798 = load <4 x i32>, <4 x i32>* %262, align 16
  %799 = load <4 x i32>, <4 x i32>* %266, align 16
  %800 = add <4 x i32> %799, %798
  %801 = sub <4 x i32> %798, %799
  %802 = icmp sgt <4 x i32> %800, %788
  %803 = select <4 x i1> %802, <4 x i32> %800, <4 x i32> %788
  %804 = icmp slt <4 x i32> %803, %791
  %805 = select <4 x i1> %804, <4 x i32> %803, <4 x i32> %791
  %806 = icmp sgt <4 x i32> %801, %788
  %807 = select <4 x i1> %806, <4 x i32> %801, <4 x i32> %788
  %808 = icmp slt <4 x i32> %807, %791
  %809 = select <4 x i1> %808, <4 x i32> %807, <4 x i32> %791
  store <4 x i32> %805, <4 x i32>* %262, align 16
  store <4 x i32> %809, <4 x i32>* %266, align 16
  %810 = load <4 x i32>, <4 x i32>* %302, align 16
  %811 = load <4 x i32>, <4 x i32>* %304, align 16
  %812 = add <4 x i32> %811, %810
  %813 = sub <4 x i32> %810, %811
  %814 = icmp sgt <4 x i32> %812, %788
  %815 = select <4 x i1> %814, <4 x i32> %812, <4 x i32> %788
  %816 = icmp slt <4 x i32> %815, %791
  %817 = select <4 x i1> %816, <4 x i32> %815, <4 x i32> %791
  %818 = icmp sgt <4 x i32> %813, %788
  %819 = select <4 x i1> %818, <4 x i32> %813, <4 x i32> %788
  %820 = icmp slt <4 x i32> %819, %791
  %821 = select <4 x i1> %820, <4 x i32> %819, <4 x i32> %791
  store <4 x i32> %817, <4 x i32>* %302, align 16
  store <4 x i32> %821, <4 x i32>* %304, align 16
  %822 = load <4 x i32>, <4 x i32>* %308, align 16
  %823 = load <4 x i32>, <4 x i32>* %306, align 16
  %824 = add <4 x i32> %823, %822
  %825 = sub <4 x i32> %822, %823
  %826 = icmp sgt <4 x i32> %824, %788
  %827 = select <4 x i1> %826, <4 x i32> %824, <4 x i32> %788
  %828 = icmp slt <4 x i32> %827, %791
  %829 = select <4 x i1> %828, <4 x i32> %827, <4 x i32> %791
  %830 = icmp sgt <4 x i32> %825, %788
  %831 = select <4 x i1> %830, <4 x i32> %825, <4 x i32> %788
  %832 = icmp slt <4 x i32> %831, %791
  %833 = select <4 x i1> %832, <4 x i32> %831, <4 x i32> %791
  store <4 x i32> %829, <4 x i32>* %308, align 16
  store <4 x i32> %833, <4 x i32>* %306, align 16
  %834 = load <4 x i32>, <4 x i32>* %426, align 16
  %835 = load <4 x i32>, <4 x i32>* %430, align 16
  %836 = add <4 x i32> %835, %834
  %837 = sub <4 x i32> %834, %835
  %838 = icmp sgt <4 x i32> %836, %788
  %839 = select <4 x i1> %838, <4 x i32> %836, <4 x i32> %788
  %840 = icmp slt <4 x i32> %839, %791
  %841 = select <4 x i1> %840, <4 x i32> %839, <4 x i32> %791
  %842 = icmp sgt <4 x i32> %837, %788
  %843 = select <4 x i1> %842, <4 x i32> %837, <4 x i32> %788
  %844 = icmp slt <4 x i32> %843, %791
  %845 = select <4 x i1> %844, <4 x i32> %843, <4 x i32> %791
  store <4 x i32> %841, <4 x i32>* %426, align 16
  store <4 x i32> %845, <4 x i32>* %430, align 16
  %846 = load <4 x i32>, <4 x i32>* %438, align 16
  %847 = load <4 x i32>, <4 x i32>* %434, align 16
  %848 = add <4 x i32> %847, %846
  %849 = sub <4 x i32> %846, %847
  %850 = icmp sgt <4 x i32> %848, %788
  %851 = select <4 x i1> %850, <4 x i32> %848, <4 x i32> %788
  %852 = icmp slt <4 x i32> %851, %791
  %853 = select <4 x i1> %852, <4 x i32> %851, <4 x i32> %791
  %854 = icmp sgt <4 x i32> %849, %788
  %855 = select <4 x i1> %854, <4 x i32> %849, <4 x i32> %788
  %856 = icmp slt <4 x i32> %855, %791
  %857 = select <4 x i1> %856, <4 x i32> %855, <4 x i32> %791
  store <4 x i32> %853, <4 x i32>* %438, align 16
  store <4 x i32> %857, <4 x i32>* %434, align 16
  %858 = load <4 x i32>, <4 x i32>* %424, align 16
  %859 = load <4 x i32>, <4 x i32>* %428, align 16
  %860 = add <4 x i32> %859, %858
  %861 = sub <4 x i32> %858, %859
  %862 = icmp sgt <4 x i32> %860, %788
  %863 = select <4 x i1> %862, <4 x i32> %860, <4 x i32> %788
  %864 = icmp slt <4 x i32> %863, %791
  %865 = select <4 x i1> %864, <4 x i32> %863, <4 x i32> %791
  %866 = icmp sgt <4 x i32> %861, %788
  %867 = select <4 x i1> %866, <4 x i32> %861, <4 x i32> %788
  %868 = icmp slt <4 x i32> %867, %791
  %869 = select <4 x i1> %868, <4 x i32> %867, <4 x i32> %791
  store <4 x i32> %865, <4 x i32>* %424, align 16
  store <4 x i32> %869, <4 x i32>* %428, align 16
  %870 = load <4 x i32>, <4 x i32>* %436, align 16
  %871 = load <4 x i32>, <4 x i32>* %432, align 16
  %872 = add <4 x i32> %871, %870
  %873 = sub <4 x i32> %870, %871
  %874 = icmp sgt <4 x i32> %872, %788
  %875 = select <4 x i1> %874, <4 x i32> %872, <4 x i32> %788
  %876 = icmp slt <4 x i32> %875, %791
  %877 = select <4 x i1> %876, <4 x i32> %875, <4 x i32> %791
  %878 = icmp sgt <4 x i32> %873, %788
  %879 = select <4 x i1> %878, <4 x i32> %873, <4 x i32> %788
  %880 = icmp slt <4 x i32> %879, %791
  %881 = select <4 x i1> %880, <4 x i32> %879, <4 x i32> %791
  store <4 x i32> %877, <4 x i32>* %436, align 16
  store <4 x i32> %881, <4 x i32>* %432, align 16
  %882 = load <4 x i32>, <4 x i32>* %378, align 16
  %883 = mul <4 x i32> %882, %119
  %884 = load <4 x i32>, <4 x i32>* %398, align 16
  %885 = mul <4 x i32> %884, %99
  %886 = add <4 x i32> %883, %767
  %887 = add <4 x i32> %886, %885
  %888 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %887, i32 %2) #8
  %889 = load <4 x i32>, <4 x i32>* %380, align 16
  %890 = mul <4 x i32> %889, %119
  %891 = load <4 x i32>, <4 x i32>* %400, align 16
  %892 = mul <4 x i32> %891, %99
  %893 = add <4 x i32> %890, %767
  %894 = add <4 x i32> %893, %892
  %895 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %894, i32 %2) #8
  %896 = load <4 x i32>, <4 x i32>* %278, align 16
  %897 = mul <4 x i32> %896, %119
  %898 = load <4 x i32>, <4 x i32>* %288, align 16
  %899 = mul <4 x i32> %898, %99
  %900 = add <4 x i32> %897, %767
  %901 = add <4 x i32> %900, %899
  %902 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %901, i32 %2) #8
  %903 = load <4 x i32>, <4 x i32>* %235, align 16
  %904 = mul <4 x i32> %903, %119
  %905 = load <4 x i32>, <4 x i32>* %230, align 16
  %906 = mul <4 x i32> %905, %99
  %907 = add <4 x i32> %904, %767
  %908 = add <4 x i32> %907, %906
  %909 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %908, i32 %2) #8
  %910 = mul <4 x i32> %903, %99
  %911 = mul <4 x i32> %905, %69
  %912 = add <4 x i32> %910, %767
  %913 = add <4 x i32> %912, %911
  %914 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %913, i32 %2) #8
  store <4 x i32> %914, <4 x i32>* %230, align 16
  %915 = mul <4 x i32> %896, %99
  %916 = mul <4 x i32> %898, %69
  %917 = add <4 x i32> %915, %767
  %918 = add <4 x i32> %917, %916
  %919 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %918, i32 %2) #8
  store <4 x i32> %919, <4 x i32>* %288, align 16
  %920 = mul <4 x i32> %889, %99
  %921 = mul <4 x i32> %891, %69
  %922 = add <4 x i32> %920, %767
  %923 = add <4 x i32> %922, %921
  %924 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %923, i32 %2) #8
  store <4 x i32> %924, <4 x i32>* %400, align 16
  %925 = mul <4 x i32> %882, %99
  %926 = mul <4 x i32> %884, %69
  %927 = add <4 x i32> %925, %767
  %928 = add <4 x i32> %927, %926
  %929 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %928, i32 %2) #8
  store <4 x i32> %929, <4 x i32>* %398, align 16
  store <4 x i32> %888, <4 x i32>* %378, align 16
  store <4 x i32> %895, <4 x i32>* %380, align 16
  store <4 x i32> %902, <4 x i32>* %278, align 16
  store <4 x i32> %909, <4 x i32>* %235, align 16
  %930 = load <4 x i32>, <4 x i32>* %239, align 16
  %931 = mul <4 x i32> %930, %144
  %932 = load <4 x i32>, <4 x i32>* %244, align 16
  %933 = mul <4 x i32> %932, %119
  %934 = add <4 x i32> %931, %767
  %935 = add <4 x i32> %934, %933
  %936 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %935, i32 %2) #8
  %937 = load <4 x i32>, <4 x i32>* %280, align 16
  %938 = mul <4 x i32> %937, %144
  %939 = load <4 x i32>, <4 x i32>* %286, align 16
  %940 = mul <4 x i32> %939, %119
  %941 = add <4 x i32> %938, %767
  %942 = add <4 x i32> %941, %940
  %943 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %942, i32 %2) #8
  %944 = load <4 x i32>, <4 x i32>* %384, align 16
  %945 = mul <4 x i32> %944, %144
  %946 = load <4 x i32>, <4 x i32>* %396, align 16
  %947 = mul <4 x i32> %946, %119
  %948 = add <4 x i32> %945, %767
  %949 = add <4 x i32> %948, %947
  %950 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %949, i32 %2) #8
  %951 = load <4 x i32>, <4 x i32>* %382, align 16
  %952 = mul <4 x i32> %951, %144
  %953 = load <4 x i32>, <4 x i32>* %394, align 16
  %954 = mul <4 x i32> %953, %119
  %955 = add <4 x i32> %952, %767
  %956 = add <4 x i32> %955, %954
  %957 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %956, i32 %2) #8
  %958 = mul <4 x i32> %951, %119
  %959 = mul <4 x i32> %953, %99
  %960 = add <4 x i32> %958, %767
  %961 = add <4 x i32> %960, %959
  %962 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %961, i32 %2) #8
  store <4 x i32> %962, <4 x i32>* %394, align 16
  %963 = mul <4 x i32> %944, %119
  %964 = mul <4 x i32> %946, %99
  %965 = add <4 x i32> %963, %767
  %966 = add <4 x i32> %965, %964
  %967 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %966, i32 %2) #8
  store <4 x i32> %967, <4 x i32>* %396, align 16
  %968 = mul <4 x i32> %937, %119
  %969 = mul <4 x i32> %939, %99
  %970 = add <4 x i32> %968, %767
  %971 = add <4 x i32> %970, %969
  %972 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %971, i32 %2) #8
  store <4 x i32> %972, <4 x i32>* %286, align 16
  %973 = mul <4 x i32> %930, %119
  %974 = mul <4 x i32> %932, %99
  %975 = add <4 x i32> %973, %767
  %976 = add <4 x i32> %975, %974
  %977 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %976, i32 %2) #8
  store <4 x i32> %977, <4 x i32>* %244, align 16
  store <4 x i32> %936, <4 x i32>* %239, align 16
  store <4 x i32> %943, <4 x i32>* %280, align 16
  store <4 x i32> %950, <4 x i32>* %384, align 16
  store <4 x i32> %957, <4 x i32>* %382, align 16
  call fastcc void @idct64_stage9_sse4_1(<2 x i64>* nonnull %192, <2 x i64>* nonnull %11, <2 x i64>* nonnull %10, <2 x i64>* nonnull %8, <2 x i64>* nonnull %9, <2 x i64>* nonnull %7, i32 %2)
  br label %978

978:                                              ; preds = %978, %753
  %979 = phi i64 [ 0, %753 ], [ %997, %978 ]
  %980 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %979
  %981 = bitcast <2 x i64>* %980 to <4 x i32>*
  %982 = load <4 x i32>, <4 x i32>* %981, align 16
  %983 = sub nuw nsw i64 31, %979
  %984 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %983
  %985 = bitcast <2 x i64>* %984 to <4 x i32>*
  %986 = load <4 x i32>, <4 x i32>* %985, align 16
  %987 = add <4 x i32> %986, %982
  %988 = sub <4 x i32> %982, %986
  %989 = icmp sgt <4 x i32> %987, %788
  %990 = select <4 x i1> %989, <4 x i32> %987, <4 x i32> %788
  %991 = icmp slt <4 x i32> %990, %791
  %992 = select <4 x i1> %991, <4 x i32> %990, <4 x i32> %791
  %993 = icmp sgt <4 x i32> %988, %788
  %994 = select <4 x i1> %993, <4 x i32> %988, <4 x i32> %788
  %995 = icmp slt <4 x i32> %994, %791
  %996 = select <4 x i1> %995, <4 x i32> %994, <4 x i32> %791
  store <4 x i32> %992, <4 x i32>* %981, align 16
  store <4 x i32> %996, <4 x i32>* %985, align 16
  %997 = add nuw nsw i64 %979, 1
  %998 = icmp eq i64 %997, 16
  br i1 %998, label %999, label %978

999:                                              ; preds = %978
  %1000 = load <4 x i32>, <4 x i32>* %239, align 16
  %1001 = mul <4 x i32> %1000, %762
  %1002 = load <4 x i32>, <4 x i32>* %244, align 16
  %1003 = mul <4 x i32> %1002, %405
  %1004 = add <4 x i32> %1001, %767
  %1005 = add <4 x i32> %1004, %1003
  %1006 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1005, i32 %2) #8
  %1007 = load <4 x i32>, <4 x i32>* %280, align 16
  %1008 = mul <4 x i32> %1007, %762
  %1009 = load <4 x i32>, <4 x i32>* %286, align 16
  %1010 = mul <4 x i32> %1009, %405
  %1011 = add <4 x i32> %1008, %767
  %1012 = add <4 x i32> %1011, %1010
  %1013 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1012, i32 %2) #8
  %1014 = load <4 x i32>, <4 x i32>* %384, align 16
  %1015 = mul <4 x i32> %1014, %762
  %1016 = load <4 x i32>, <4 x i32>* %396, align 16
  %1017 = mul <4 x i32> %1016, %405
  %1018 = add <4 x i32> %1015, %767
  %1019 = add <4 x i32> %1018, %1017
  %1020 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1019, i32 %2) #8
  %1021 = load <4 x i32>, <4 x i32>* %382, align 16
  %1022 = mul <4 x i32> %1021, %762
  %1023 = load <4 x i32>, <4 x i32>* %394, align 16
  %1024 = mul <4 x i32> %1023, %405
  %1025 = add <4 x i32> %1024, %767
  %1026 = add <4 x i32> %1025, %1022
  %1027 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1026, i32 %2) #8
  %1028 = mul <4 x i32> %1021, %405
  %1029 = add <4 x i32> %1025, %1028
  %1030 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1029, i32 %2) #8
  store <4 x i32> %1030, <4 x i32>* %394, align 16
  %1031 = add <4 x i32> %1016, %1014
  %1032 = mul <4 x i32> %1031, %405
  %1033 = add <4 x i32> %1032, %767
  %1034 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1033, i32 %2) #8
  store <4 x i32> %1034, <4 x i32>* %396, align 16
  %1035 = add <4 x i32> %1009, %1007
  %1036 = mul <4 x i32> %1035, %405
  %1037 = add <4 x i32> %1036, %767
  %1038 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1037, i32 %2) #8
  store <4 x i32> %1038, <4 x i32>* %286, align 16
  %1039 = add <4 x i32> %1002, %1000
  %1040 = mul <4 x i32> %1039, %405
  %1041 = add <4 x i32> %1040, %767
  %1042 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1041, i32 %2) #8
  store <4 x i32> %1042, <4 x i32>* %244, align 16
  store <4 x i32> %1006, <4 x i32>* %239, align 16
  store <4 x i32> %1013, <4 x i32>* %280, align 16
  store <4 x i32> %1020, <4 x i32>* %384, align 16
  store <4 x i32> %1027, <4 x i32>* %382, align 16
  %1043 = load <4 x i32>, <4 x i32>* %386, align 16
  %1044 = mul <4 x i32> %1043, %762
  %1045 = load <4 x i32>, <4 x i32>* %390, align 16
  %1046 = mul <4 x i32> %1045, %405
  %1047 = add <4 x i32> %1044, %767
  %1048 = add <4 x i32> %1047, %1046
  %1049 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1048, i32 %2) #8
  %1050 = load <4 x i32>, <4 x i32>* %388, align 16
  %1051 = mul <4 x i32> %1050, %762
  %1052 = load <4 x i32>, <4 x i32>* %392, align 16
  %1053 = mul <4 x i32> %1052, %405
  %1054 = add <4 x i32> %1051, %767
  %1055 = add <4 x i32> %1054, %1053
  %1056 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1055, i32 %2) #8
  %1057 = load <4 x i32>, <4 x i32>* %282, align 16
  %1058 = mul <4 x i32> %1057, %762
  %1059 = load <4 x i32>, <4 x i32>* %284, align 16
  %1060 = mul <4 x i32> %1059, %405
  %1061 = add <4 x i32> %1058, %767
  %1062 = add <4 x i32> %1061, %1060
  %1063 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1062, i32 %2) #8
  %1064 = load <4 x i32>, <4 x i32>* %253, align 16
  %1065 = mul <4 x i32> %1064, %762
  %1066 = load <4 x i32>, <4 x i32>* %248, align 16
  %1067 = mul <4 x i32> %1066, %405
  %1068 = add <4 x i32> %1067, %767
  %1069 = add <4 x i32> %1068, %1065
  %1070 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1069, i32 %2) #8
  %1071 = mul <4 x i32> %1064, %405
  %1072 = add <4 x i32> %1068, %1071
  %1073 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1072, i32 %2) #8
  store <4 x i32> %1073, <4 x i32>* %248, align 16
  %1074 = load <4 x i32>, <4 x i32>* %87, align 16
  %1075 = add <4 x i32> %1059, %1057
  %1076 = mul <4 x i32> %1074, %1075
  %1077 = add <4 x i32> %1076, %767
  %1078 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1077, i32 %2) #8
  store <4 x i32> %1078, <4 x i32>* %284, align 16
  %1079 = add <4 x i32> %1052, %1050
  %1080 = mul <4 x i32> %1074, %1079
  %1081 = add <4 x i32> %1080, %767
  %1082 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1081, i32 %2) #8
  store <4 x i32> %1082, <4 x i32>* %392, align 16
  %1083 = add <4 x i32> %1045, %1043
  %1084 = mul <4 x i32> %1074, %1083
  %1085 = add <4 x i32> %1084, %767
  %1086 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1085, i32 %2) #8
  store <4 x i32> %1086, <4 x i32>* %390, align 16
  store <4 x i32> %1049, <4 x i32>* %386, align 16
  store <4 x i32> %1056, <4 x i32>* %388, align 16
  store <4 x i32> %1063, <4 x i32>* %282, align 16
  store <4 x i32> %1070, <4 x i32>* %253, align 16
  %1087 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 63
  br label %1089

1088:                                             ; preds = %1089
  br i1 %21, label %1115, label %1189

1089:                                             ; preds = %1089, %999
  %1090 = phi i64 [ 0, %999 ], [ %1113, %1089 ]
  %1091 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1090
  %1092 = bitcast <2 x i64>* %1091 to <4 x i32>*
  %1093 = load <4 x i32>, <4 x i32>* %1092, align 16
  %1094 = sub nuw nsw i64 63, %1090
  %1095 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1094
  %1096 = bitcast <2 x i64>* %1095 to <4 x i32>*
  %1097 = load <4 x i32>, <4 x i32>* %1096, align 16
  %1098 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %1090
  %1099 = sub nsw i64 0, %1090
  %1100 = getelementptr inbounds <2 x i64>, <2 x i64>* %1087, i64 %1099
  %1101 = add <4 x i32> %1097, %1093
  %1102 = sub <4 x i32> %1093, %1097
  %1103 = icmp sgt <4 x i32> %1101, %788
  %1104 = select <4 x i1> %1103, <4 x i32> %1101, <4 x i32> %788
  %1105 = icmp slt <4 x i32> %1104, %791
  %1106 = select <4 x i1> %1105, <4 x i32> %1104, <4 x i32> %791
  %1107 = icmp sgt <4 x i32> %1102, %788
  %1108 = select <4 x i1> %1107, <4 x i32> %1102, <4 x i32> %788
  %1109 = icmp slt <4 x i32> %1108, %791
  %1110 = select <4 x i1> %1109, <4 x i32> %1108, <4 x i32> %791
  %1111 = bitcast <2 x i64>* %1098 to <4 x i32>*
  store <4 x i32> %1106, <4 x i32>* %1111, align 16
  %1112 = bitcast <2 x i64>* %1100 to <4 x i32>*
  store <4 x i32> %1110, <4 x i32>* %1112, align 16
  %1113 = add nuw nsw i64 %1090, 1
  %1114 = icmp eq i64 %1113, 32
  br i1 %1114, label %1088, label %1089

1115:                                             ; preds = %1088
  %1116 = icmp sgt i32 %4, 10
  %1117 = select i1 %1116, i32 %4, i32 10
  %1118 = shl i32 32, %1117
  %1119 = sub nsw i32 0, %1118
  %1120 = insertelement <4 x i32> undef, i32 %1119, i32 0
  %1121 = shufflevector <4 x i32> %1120, <4 x i32> undef, <4 x i32> zeroinitializer
  %1122 = add nsw i32 %1118, -1
  %1123 = insertelement <4 x i32> undef, i32 %1122, i32 0
  %1124 = shufflevector <4 x i32> %1123, <4 x i32> undef, <4 x i32> zeroinitializer
  %1125 = icmp eq i32 %5, 0
  %1126 = add nsw i32 %5, -1
  %1127 = shl i32 1, %1126
  %1128 = insertelement <4 x i32> undef, i32 %1127, i32 0
  %1129 = shufflevector <4 x i32> %1128, <4 x i32> undef, <4 x i32> zeroinitializer
  br label %1130

1130:                                             ; preds = %1163, %1115
  %1131 = phi i64 [ 0, %1115 ], [ %1187, %1163 ]
  %1132 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %1131
  %1133 = bitcast <2 x i64>* %1132 to <4 x i32>*
  %1134 = load <4 x i32>, <4 x i32>* %1133, align 16
  br i1 %1125, label %1135, label %1145

1135:                                             ; preds = %1130
  %1136 = getelementptr inbounds <2 x i64>, <2 x i64>* %1132, i64 1
  %1137 = bitcast <2 x i64>* %1136 to <4 x i32>*
  %1138 = load <4 x i32>, <4 x i32>* %1137, align 16
  %1139 = getelementptr inbounds <2 x i64>, <2 x i64>* %1132, i64 2
  %1140 = bitcast <2 x i64>* %1139 to <4 x i32>*
  %1141 = load <4 x i32>, <4 x i32>* %1140, align 16
  %1142 = getelementptr inbounds <2 x i64>, <2 x i64>* %1132, i64 3
  %1143 = bitcast <2 x i64>* %1142 to <4 x i32>*
  %1144 = load <4 x i32>, <4 x i32>* %1143, align 16
  br label %1163

1145:                                             ; preds = %1130
  %1146 = add <4 x i32> %1134, %1129
  %1147 = getelementptr inbounds <2 x i64>, <2 x i64>* %1132, i64 1
  %1148 = bitcast <2 x i64>* %1147 to <4 x i32>*
  %1149 = load <4 x i32>, <4 x i32>* %1148, align 16
  %1150 = add <4 x i32> %1149, %1129
  %1151 = getelementptr inbounds <2 x i64>, <2 x i64>* %1132, i64 2
  %1152 = bitcast <2 x i64>* %1151 to <4 x i32>*
  %1153 = load <4 x i32>, <4 x i32>* %1152, align 16
  %1154 = add <4 x i32> %1153, %1129
  %1155 = getelementptr inbounds <2 x i64>, <2 x i64>* %1132, i64 3
  %1156 = bitcast <2 x i64>* %1155 to <4 x i32>*
  %1157 = load <4 x i32>, <4 x i32>* %1156, align 16
  %1158 = add <4 x i32> %1157, %1129
  %1159 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1146, i32 %5) #8
  store <4 x i32> %1159, <4 x i32>* %1133, align 16
  %1160 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1150, i32 %5) #8
  store <4 x i32> %1160, <4 x i32>* %1148, align 16
  %1161 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1154, i32 %5) #8
  store <4 x i32> %1161, <4 x i32>* %1152, align 16
  %1162 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1158, i32 %5) #8
  store <4 x i32> %1162, <4 x i32>* %1156, align 16
  br label %1163

1163:                                             ; preds = %1145, %1135
  %1164 = phi <4 x i32>* [ %1143, %1135 ], [ %1156, %1145 ]
  %1165 = phi <4 x i32>* [ %1140, %1135 ], [ %1152, %1145 ]
  %1166 = phi <4 x i32>* [ %1137, %1135 ], [ %1148, %1145 ]
  %1167 = phi <4 x i32> [ %1144, %1135 ], [ %1162, %1145 ]
  %1168 = phi <4 x i32> [ %1141, %1135 ], [ %1161, %1145 ]
  %1169 = phi <4 x i32> [ %1138, %1135 ], [ %1160, %1145 ]
  %1170 = phi <4 x i32> [ %1134, %1135 ], [ %1159, %1145 ]
  %1171 = icmp sgt <4 x i32> %1170, %1121
  %1172 = select <4 x i1> %1171, <4 x i32> %1170, <4 x i32> %1121
  %1173 = icmp slt <4 x i32> %1172, %1124
  %1174 = select <4 x i1> %1173, <4 x i32> %1172, <4 x i32> %1124
  store <4 x i32> %1174, <4 x i32>* %1133, align 16
  %1175 = icmp sgt <4 x i32> %1169, %1121
  %1176 = select <4 x i1> %1175, <4 x i32> %1169, <4 x i32> %1121
  %1177 = icmp slt <4 x i32> %1176, %1124
  %1178 = select <4 x i1> %1177, <4 x i32> %1176, <4 x i32> %1124
  store <4 x i32> %1178, <4 x i32>* %1166, align 16
  %1179 = icmp sgt <4 x i32> %1168, %1121
  %1180 = select <4 x i1> %1179, <4 x i32> %1168, <4 x i32> %1121
  %1181 = icmp slt <4 x i32> %1180, %1124
  %1182 = select <4 x i1> %1181, <4 x i32> %1180, <4 x i32> %1124
  store <4 x i32> %1182, <4 x i32>* %1165, align 16
  %1183 = icmp sgt <4 x i32> %1167, %1121
  %1184 = select <4 x i1> %1183, <4 x i32> %1167, <4 x i32> %1121
  %1185 = icmp slt <4 x i32> %1184, %1124
  %1186 = select <4 x i1> %1185, <4 x i32> %1184, <4 x i32> %1124
  store <4 x i32> %1186, <4 x i32>* %1164, align 16
  %1187 = add nuw nsw i64 %1131, 4
  %1188 = icmp ult i64 %1187, 64
  br i1 %1188, label %1130, label %1189

1189:                                             ; preds = %1163, %1088
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %188) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %129) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %82) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %33) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %26) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %15) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @idct64x64_low16_sse4_1(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i32, i32, i32, i32) #0 {
  %7 = alloca <2 x i64>, align 16
  %8 = alloca <2 x i64>, align 16
  %9 = alloca <2 x i64>, align 16
  %10 = alloca <2 x i64>, align 16
  %11 = alloca <2 x i64>, align 16
  %12 = alloca [64 x <2 x i64>], align 16
  %13 = add nsw i32 %2, -10
  %14 = sext i32 %13 to i64
  %15 = bitcast <2 x i64>* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %15) #8
  %16 = add nsw i32 %2, -1
  %17 = shl i32 1, %16
  %18 = insertelement <4 x i32> undef, i32 %17, i32 0
  %19 = shufflevector <4 x i32> %18, <4 x i32> undef, <4 x i32> zeroinitializer
  %20 = bitcast <2 x i64>* %7 to <4 x i32>*
  store <4 x i32> %19, <4 x i32>* %20, align 16
  %21 = icmp eq i32 %3, 0
  %22 = select i1 %21, i32 8, i32 6
  %23 = add nsw i32 %22, %4
  %24 = icmp slt i32 %23, 16
  %25 = add i32 %23, -1
  %26 = bitcast <2 x i64>* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %26) #8
  %27 = shl i32 1, %25
  %28 = select i1 %24, i32 32768, i32 %27
  %29 = sub nsw i32 0, %28
  %30 = insertelement <4 x i32> undef, i32 %29, i32 0
  %31 = shufflevector <4 x i32> %30, <4 x i32> undef, <4 x i32> zeroinitializer
  %32 = bitcast <2 x i64>* %8 to <4 x i32>*
  store <4 x i32> %31, <4 x i32>* %32, align 16
  %33 = bitcast <2 x i64>* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %33) #8
  %34 = add nsw i32 %28, -1
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = bitcast <2 x i64>* %9 to <4 x i32>*
  store <4 x i32> %36, <4 x i32>* %37, align 16
  %38 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 1
  %39 = load i32, i32* %38, align 4
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 2
  %43 = load i32, i32* %42, align 8
  %44 = insertelement <4 x i32> undef, i32 %43, i32 0
  %45 = shufflevector <4 x i32> %44, <4 x i32> undef, <4 x i32> zeroinitializer
  %46 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 3
  %47 = load i32, i32* %46, align 4
  %48 = insertelement <4 x i32> undef, i32 %47, i32 0
  %49 = shufflevector <4 x i32> %48, <4 x i32> undef, <4 x i32> zeroinitializer
  %50 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 4
  %51 = load i32, i32* %50, align 16
  %52 = insertelement <4 x i32> undef, i32 %51, i32 0
  %53 = shufflevector <4 x i32> %52, <4 x i32> undef, <4 x i32> zeroinitializer
  %54 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 5
  %55 = load i32, i32* %54, align 4
  %56 = insertelement <4 x i32> undef, i32 %55, i32 0
  %57 = shufflevector <4 x i32> %56, <4 x i32> undef, <4 x i32> zeroinitializer
  %58 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 6
  %59 = load i32, i32* %58, align 8
  %60 = insertelement <4 x i32> undef, i32 %59, i32 0
  %61 = shufflevector <4 x i32> %60, <4 x i32> undef, <4 x i32> zeroinitializer
  %62 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 7
  %63 = load i32, i32* %62, align 4
  %64 = insertelement <4 x i32> undef, i32 %63, i32 0
  %65 = shufflevector <4 x i32> %64, <4 x i32> undef, <4 x i32> zeroinitializer
  %66 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 8
  %67 = load i32, i32* %66, align 16
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 9
  %71 = load i32, i32* %70, align 4
  %72 = insertelement <4 x i32> undef, i32 %71, i32 0
  %73 = shufflevector <4 x i32> %72, <4 x i32> undef, <4 x i32> zeroinitializer
  %74 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 10
  %75 = load i32, i32* %74, align 8
  %76 = insertelement <4 x i32> undef, i32 %75, i32 0
  %77 = shufflevector <4 x i32> %76, <4 x i32> undef, <4 x i32> zeroinitializer
  %78 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 11
  %79 = load i32, i32* %78, align 4
  %80 = insertelement <4 x i32> undef, i32 %79, i32 0
  %81 = shufflevector <4 x i32> %80, <4 x i32> undef, <4 x i32> zeroinitializer
  %82 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 12
  %83 = load i32, i32* %82, align 16
  %84 = insertelement <4 x i32> undef, i32 %83, i32 0
  %85 = shufflevector <4 x i32> %84, <4 x i32> undef, <4 x i32> zeroinitializer
  %86 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 13
  %87 = load i32, i32* %86, align 4
  %88 = insertelement <4 x i32> undef, i32 %87, i32 0
  %89 = shufflevector <4 x i32> %88, <4 x i32> undef, <4 x i32> zeroinitializer
  %90 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 14
  %91 = load i32, i32* %90, align 8
  %92 = insertelement <4 x i32> undef, i32 %91, i32 0
  %93 = shufflevector <4 x i32> %92, <4 x i32> undef, <4 x i32> zeroinitializer
  %94 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 15
  %95 = load i32, i32* %94, align 4
  %96 = insertelement <4 x i32> undef, i32 %95, i32 0
  %97 = shufflevector <4 x i32> %96, <4 x i32> undef, <4 x i32> zeroinitializer
  %98 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 16
  %99 = load i32, i32* %98, align 16
  %100 = insertelement <4 x i32> undef, i32 %99, i32 0
  %101 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 20
  %102 = load i32, i32* %101, align 16
  %103 = insertelement <4 x i32> undef, i32 %102, i32 0
  %104 = shufflevector <4 x i32> %103, <4 x i32> undef, <4 x i32> zeroinitializer
  %105 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 24
  %106 = load i32, i32* %105, align 16
  %107 = insertelement <4 x i32> undef, i32 %106, i32 0
  %108 = shufflevector <4 x i32> %107, <4 x i32> undef, <4 x i32> zeroinitializer
  %109 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 28
  %110 = load i32, i32* %109, align 16
  %111 = insertelement <4 x i32> undef, i32 %110, i32 0
  %112 = shufflevector <4 x i32> %111, <4 x i32> undef, <4 x i32> zeroinitializer
  %113 = bitcast <2 x i64>* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %113) #8
  %114 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 32
  %115 = load i32, i32* %114, align 16
  %116 = insertelement <4 x i32> undef, i32 %115, i32 0
  %117 = shufflevector <4 x i32> %116, <4 x i32> undef, <4 x i32> zeroinitializer
  %118 = bitcast <2 x i64>* %10 to <4 x i32>*
  store <4 x i32> %117, <4 x i32>* %118, align 16
  %119 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 36
  %120 = load i32, i32* %119, align 16
  %121 = insertelement <4 x i32> undef, i32 %120, i32 0
  %122 = shufflevector <4 x i32> %121, <4 x i32> undef, <4 x i32> zeroinitializer
  %123 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 40
  %124 = load i32, i32* %123, align 16
  %125 = insertelement <4 x i32> undef, i32 %124, i32 0
  %126 = shufflevector <4 x i32> %125, <4 x i32> undef, <4 x i32> zeroinitializer
  %127 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 44
  %128 = load i32, i32* %127, align 16
  %129 = insertelement <4 x i32> undef, i32 %128, i32 0
  %130 = shufflevector <4 x i32> %129, <4 x i32> undef, <4 x i32> zeroinitializer
  %131 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 48
  %132 = load i32, i32* %131, align 16
  %133 = insertelement <4 x i32> undef, i32 %132, i32 0
  %134 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 51
  %135 = load i32, i32* %134, align 4
  %136 = insertelement <4 x i32> undef, i32 %135, i32 0
  %137 = shufflevector <4 x i32> %136, <4 x i32> undef, <4 x i32> zeroinitializer
  %138 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 52
  %139 = load i32, i32* %138, align 16
  %140 = insertelement <4 x i32> undef, i32 %139, i32 0
  %141 = shufflevector <4 x i32> %140, <4 x i32> undef, <4 x i32> zeroinitializer
  %142 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 54
  %143 = load i32, i32* %142, align 8
  %144 = insertelement <4 x i32> undef, i32 %143, i32 0
  %145 = shufflevector <4 x i32> %144, <4 x i32> undef, <4 x i32> zeroinitializer
  %146 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 55
  %147 = load i32, i32* %146, align 4
  %148 = insertelement <4 x i32> undef, i32 %147, i32 0
  %149 = shufflevector <4 x i32> %148, <4 x i32> undef, <4 x i32> zeroinitializer
  %150 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 56
  %151 = load i32, i32* %150, align 16
  %152 = insertelement <4 x i32> undef, i32 %151, i32 0
  %153 = shufflevector <4 x i32> %152, <4 x i32> undef, <4 x i32> zeroinitializer
  %154 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 59
  %155 = load i32, i32* %154, align 4
  %156 = insertelement <4 x i32> undef, i32 %155, i32 0
  %157 = shufflevector <4 x i32> %156, <4 x i32> undef, <4 x i32> zeroinitializer
  %158 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 60
  %159 = load i32, i32* %158, align 16
  %160 = insertelement <4 x i32> undef, i32 %159, i32 0
  %161 = shufflevector <4 x i32> %160, <4 x i32> undef, <4 x i32> zeroinitializer
  %162 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 62
  %163 = load i32, i32* %162, align 8
  %164 = insertelement <4 x i32> undef, i32 %163, i32 0
  %165 = shufflevector <4 x i32> %164, <4 x i32> undef, <4 x i32> zeroinitializer
  %166 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 63
  %167 = load i32, i32* %166, align 4
  %168 = insertelement <4 x i32> undef, i32 %167, i32 0
  %169 = shufflevector <4 x i32> %168, <4 x i32> undef, <4 x i32> zeroinitializer
  %170 = sub nsw i32 0, %51
  %171 = insertelement <4 x i32> undef, i32 %170, i32 0
  %172 = shufflevector <4 x i32> %171, <4 x i32> undef, <4 x i32> zeroinitializer
  %173 = sub nsw i32 0, %67
  %174 = insertelement <4 x i32> undef, i32 %173, i32 0
  %175 = shufflevector <4 x i32> %174, <4 x i32> undef, <4 x i32> zeroinitializer
  %176 = sub nsw i32 0, %83
  %177 = insertelement <4 x i32> undef, i32 %176, i32 0
  %178 = shufflevector <4 x i32> %177, <4 x i32> undef, <4 x i32> zeroinitializer
  %179 = sub nsw i32 0, %99
  %180 = insertelement <4 x i32> undef, i32 %179, i32 0
  %181 = sub nsw i32 0, %102
  %182 = insertelement <4 x i32> undef, i32 %181, i32 0
  %183 = shufflevector <4 x i32> %182, <4 x i32> undef, <4 x i32> zeroinitializer
  %184 = sub nsw i32 0, %106
  %185 = insertelement <4 x i32> undef, i32 %184, i32 0
  %186 = shufflevector <4 x i32> %185, <4 x i32> undef, <4 x i32> zeroinitializer
  %187 = sub nsw i32 0, %110
  %188 = insertelement <4 x i32> undef, i32 %187, i32 0
  %189 = shufflevector <4 x i32> %188, <4 x i32> undef, <4 x i32> zeroinitializer
  %190 = bitcast <2 x i64>* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %190) #8
  %191 = sub nsw i32 0, %115
  %192 = insertelement <4 x i32> undef, i32 %191, i32 0
  %193 = shufflevector <4 x i32> %192, <4 x i32> undef, <4 x i32> zeroinitializer
  %194 = bitcast <2 x i64>* %11 to <4 x i32>*
  store <4 x i32> %193, <4 x i32>* %194, align 16
  %195 = sub nsw i32 0, %120
  %196 = insertelement <4 x i32> undef, i32 %195, i32 0
  %197 = shufflevector <4 x i32> %196, <4 x i32> undef, <4 x i32> zeroinitializer
  %198 = sub nsw i32 0, %124
  %199 = insertelement <4 x i32> undef, i32 %198, i32 0
  %200 = shufflevector <4 x i32> %199, <4 x i32> undef, <4 x i32> zeroinitializer
  %201 = sub nsw i32 0, %128
  %202 = insertelement <4 x i32> undef, i32 %201, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = sub nsw i32 0, %132
  %205 = insertelement <4 x i32> undef, i32 %204, i32 0
  %206 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 49
  %207 = load i32, i32* %206, align 4
  %208 = sub nsw i32 0, %207
  %209 = insertelement <4 x i32> undef, i32 %208, i32 0
  %210 = shufflevector <4 x i32> %209, <4 x i32> undef, <4 x i32> zeroinitializer
  %211 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 50
  %212 = load i32, i32* %211, align 8
  %213 = sub nsw i32 0, %212
  %214 = insertelement <4 x i32> undef, i32 %213, i32 0
  %215 = shufflevector <4 x i32> %214, <4 x i32> undef, <4 x i32> zeroinitializer
  %216 = sub nsw i32 0, %139
  %217 = insertelement <4 x i32> undef, i32 %216, i32 0
  %218 = shufflevector <4 x i32> %217, <4 x i32> undef, <4 x i32> zeroinitializer
  %219 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 53
  %220 = load i32, i32* %219, align 4
  %221 = sub nsw i32 0, %220
  %222 = insertelement <4 x i32> undef, i32 %221, i32 0
  %223 = shufflevector <4 x i32> %222, <4 x i32> undef, <4 x i32> zeroinitializer
  %224 = sub nsw i32 0, %151
  %225 = insertelement <4 x i32> undef, i32 %224, i32 0
  %226 = shufflevector <4 x i32> %225, <4 x i32> undef, <4 x i32> zeroinitializer
  %227 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 57
  %228 = load i32, i32* %227, align 4
  %229 = sub nsw i32 0, %228
  %230 = insertelement <4 x i32> undef, i32 %229, i32 0
  %231 = shufflevector <4 x i32> %230, <4 x i32> undef, <4 x i32> zeroinitializer
  %232 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 58
  %233 = load i32, i32* %232, align 8
  %234 = sub nsw i32 0, %233
  %235 = insertelement <4 x i32> undef, i32 %234, i32 0
  %236 = shufflevector <4 x i32> %235, <4 x i32> undef, <4 x i32> zeroinitializer
  %237 = sub nsw i32 0, %159
  %238 = insertelement <4 x i32> undef, i32 %237, i32 0
  %239 = shufflevector <4 x i32> %238, <4 x i32> undef, <4 x i32> zeroinitializer
  %240 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %14, i64 61
  %241 = load i32, i32* %240, align 4
  %242 = sub nsw i32 0, %241
  %243 = insertelement <4 x i32> undef, i32 %242, i32 0
  %244 = shufflevector <4 x i32> %243, <4 x i32> undef, <4 x i32> zeroinitializer
  %245 = bitcast [64 x <2 x i64>]* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %245) #8
  %246 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 1
  %247 = bitcast <2 x i64>* %246 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %247, i8 -86, i64 992, i1 false)
  %248 = load <2 x i64>, <2 x i64>* %0, align 16
  %249 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 0
  store <2 x i64> %248, <2 x i64>* %249, align 16
  %250 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %251 = bitcast <2 x i64>* %250 to <4 x i32>*
  %252 = load <4 x i32>, <4 x i32>* %251, align 16
  %253 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 32
  %254 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %255 = bitcast <2 x i64>* %254 to <4 x i32>*
  %256 = load <4 x i32>, <4 x i32>* %255, align 16
  %257 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 36
  %258 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %259 = load <2 x i64>, <2 x i64>* %258, align 16
  %260 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 40
  store <2 x i64> %259, <2 x i64>* %260, align 16
  %261 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %262 = load <2 x i64>, <2 x i64>* %261, align 16
  %263 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 44
  store <2 x i64> %262, <2 x i64>* %263, align 16
  %264 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %265 = load <2 x i64>, <2 x i64>* %264, align 16
  %266 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 48
  store <2 x i64> %265, <2 x i64>* %266, align 16
  %267 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %268 = load <2 x i64>, <2 x i64>* %267, align 16
  %269 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 52
  store <2 x i64> %268, <2 x i64>* %269, align 16
  %270 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %271 = bitcast <2 x i64>* %270 to <4 x i32>*
  %272 = load <4 x i32>, <4 x i32>* %271, align 16
  %273 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 56
  %274 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %275 = bitcast <2 x i64>* %274 to <4 x i32>*
  %276 = load <4 x i32>, <4 x i32>* %275, align 16
  %277 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 60
  %278 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %279 = load <2 x i64>, <2 x i64>* %278, align 16
  %280 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 16
  store <2 x i64> %279, <2 x i64>* %280, align 16
  %281 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %282 = load <2 x i64>, <2 x i64>* %281, align 16
  %283 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 20
  store <2 x i64> %282, <2 x i64>* %283, align 16
  %284 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %285 = load <2 x i64>, <2 x i64>* %284, align 16
  %286 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 24
  store <2 x i64> %285, <2 x i64>* %286, align 16
  %287 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %288 = load <2 x i64>, <2 x i64>* %287, align 16
  %289 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 28
  store <2 x i64> %288, <2 x i64>* %289, align 16
  %290 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %291 = load <2 x i64>, <2 x i64>* %290, align 16
  %292 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 4
  store <2 x i64> %291, <2 x i64>* %292, align 16
  %293 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %294 = load <2 x i64>, <2 x i64>* %293, align 16
  %295 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 8
  store <2 x i64> %294, <2 x i64>* %295, align 16
  %296 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %297 = load <2 x i64>, <2 x i64>* %296, align 16
  %298 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 12
  store <2 x i64> %297, <2 x i64>* %298, align 16
  %299 = bitcast <2 x i64>* %253 to <4 x i32>*
  %300 = mul <4 x i32> %41, %252
  %301 = load <4 x i32>, <4 x i32>* %20, align 16
  %302 = add <4 x i32> %301, %300
  %303 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %302, i32 %2) #8
  %304 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 63
  %305 = bitcast <2 x i64>* %304 to <4 x i32>*
  store <4 x i32> %303, <4 x i32>* %305, align 16
  %306 = mul <4 x i32> %169, %252
  %307 = add <4 x i32> %301, %306
  %308 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %307, i32 %2) #8
  store <4 x i32> %308, <4 x i32>* %299, align 16
  %309 = bitcast <2 x i64>* %277 to <4 x i32>*
  %310 = mul <4 x i32> %210, %276
  %311 = add <4 x i32> %310, %301
  %312 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %311, i32 %2) #8
  %313 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 35
  %314 = bitcast <2 x i64>* %313 to <4 x i32>*
  store <4 x i32> %312, <4 x i32>* %314, align 16
  %315 = mul <4 x i32> %97, %276
  %316 = add <4 x i32> %315, %301
  %317 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %316, i32 %2) #8
  store <4 x i32> %317, <4 x i32>* %309, align 16
  %318 = bitcast <2 x i64>* %257 to <4 x i32>*
  %319 = mul <4 x i32> %73, %256
  %320 = add <4 x i32> %319, %301
  %321 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %320, i32 %2) #8
  %322 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 59
  %323 = bitcast <2 x i64>* %322 to <4 x i32>*
  store <4 x i32> %321, <4 x i32>* %323, align 16
  %324 = mul <4 x i32> %149, %256
  %325 = add <4 x i32> %324, %301
  %326 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %325, i32 %2) #8
  store <4 x i32> %326, <4 x i32>* %318, align 16
  %327 = bitcast <2 x i64>* %273 to <4 x i32>*
  %328 = mul <4 x i32> %231, %272
  %329 = add <4 x i32> %328, %301
  %330 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %329, i32 %2) #8
  %331 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 39
  %332 = bitcast <2 x i64>* %331 to <4 x i32>*
  store <4 x i32> %330, <4 x i32>* %332, align 16
  %333 = mul <4 x i32> %65, %272
  %334 = add <4 x i32> %333, %301
  %335 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %334, i32 %2) #8
  store <4 x i32> %335, <4 x i32>* %327, align 16
  %336 = bitcast <2 x i64>* %260 to <4 x i32>*
  %337 = load <4 x i32>, <4 x i32>* %336, align 16
  %338 = mul <4 x i32> %337, %57
  %339 = add <4 x i32> %338, %301
  %340 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %339, i32 %2) #8
  %341 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 55
  %342 = bitcast <2 x i64>* %341 to <4 x i32>*
  store <4 x i32> %340, <4 x i32>* %342, align 16
  %343 = mul <4 x i32> %337, %157
  %344 = add <4 x i32> %343, %301
  %345 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %344, i32 %2) #8
  store <4 x i32> %345, <4 x i32>* %336, align 16
  %346 = bitcast <2 x i64>* %269 to <4 x i32>*
  %347 = load <4 x i32>, <4 x i32>* %346, align 16
  %348 = mul <4 x i32> %347, %223
  %349 = add <4 x i32> %348, %301
  %350 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %349, i32 %2) #8
  %351 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 43
  %352 = bitcast <2 x i64>* %351 to <4 x i32>*
  store <4 x i32> %350, <4 x i32>* %352, align 16
  %353 = mul <4 x i32> %347, %81
  %354 = add <4 x i32> %353, %301
  %355 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %354, i32 %2) #8
  store <4 x i32> %355, <4 x i32>* %346, align 16
  %356 = bitcast <2 x i64>* %266 to <4 x i32>*
  %357 = load <4 x i32>, <4 x i32>* %356, align 16
  %358 = mul <4 x i32> %357, %244
  %359 = add <4 x i32> %358, %301
  %360 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %359, i32 %2) #8
  %361 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 47
  %362 = bitcast <2 x i64>* %361 to <4 x i32>*
  store <4 x i32> %360, <4 x i32>* %362, align 16
  %363 = mul <4 x i32> %357, %49
  %364 = add <4 x i32> %363, %301
  %365 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %364, i32 %2) #8
  store <4 x i32> %365, <4 x i32>* %356, align 16
  %366 = bitcast <2 x i64>* %263 to <4 x i32>*
  %367 = load <4 x i32>, <4 x i32>* %366, align 16
  %368 = mul <4 x i32> %367, %89
  %369 = add <4 x i32> %368, %301
  %370 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %369, i32 %2) #8
  %371 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 51
  %372 = bitcast <2 x i64>* %371 to <4 x i32>*
  store <4 x i32> %370, <4 x i32>* %372, align 16
  %373 = mul <4 x i32> %367, %137
  %374 = add <4 x i32> %373, %301
  %375 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %374, i32 %2) #8
  store <4 x i32> %375, <4 x i32>* %366, align 16
  %376 = bitcast <2 x i64>* %280 to <4 x i32>*
  %377 = load <4 x i32>, <4 x i32>* %376, align 16
  %378 = mul <4 x i32> %377, %45
  %379 = add <4 x i32> %378, %301
  %380 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %379, i32 %2) #8
  %381 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 31
  %382 = bitcast <2 x i64>* %381 to <4 x i32>*
  store <4 x i32> %380, <4 x i32>* %382, align 16
  %383 = mul <4 x i32> %377, %165
  %384 = add <4 x i32> %383, %301
  %385 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %384, i32 %2) #8
  store <4 x i32> %385, <4 x i32>* %376, align 16
  %386 = bitcast <2 x i64>* %289 to <4 x i32>*
  %387 = load <4 x i32>, <4 x i32>* %386, align 16
  %388 = mul <4 x i32> %387, %215
  %389 = add <4 x i32> %388, %301
  %390 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %389, i32 %2) #8
  %391 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 19
  %392 = bitcast <2 x i64>* %391 to <4 x i32>*
  store <4 x i32> %390, <4 x i32>* %392, align 16
  %393 = mul <4 x i32> %387, %93
  %394 = add <4 x i32> %393, %301
  %395 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %394, i32 %2) #8
  store <4 x i32> %395, <4 x i32>* %386, align 16
  %396 = bitcast <2 x i64>* %283 to <4 x i32>*
  %397 = load <4 x i32>, <4 x i32>* %396, align 16
  %398 = mul <4 x i32> %397, %77
  %399 = add <4 x i32> %398, %301
  %400 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %399, i32 %2) #8
  %401 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 27
  %402 = bitcast <2 x i64>* %401 to <4 x i32>*
  store <4 x i32> %400, <4 x i32>* %402, align 16
  %403 = mul <4 x i32> %397, %145
  %404 = add <4 x i32> %403, %301
  %405 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %404, i32 %2) #8
  store <4 x i32> %405, <4 x i32>* %396, align 16
  %406 = bitcast <2 x i64>* %286 to <4 x i32>*
  %407 = load <4 x i32>, <4 x i32>* %406, align 16
  %408 = mul <4 x i32> %407, %236
  %409 = add <4 x i32> %408, %301
  %410 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %409, i32 %2) #8
  %411 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 23
  %412 = bitcast <2 x i64>* %411 to <4 x i32>*
  store <4 x i32> %410, <4 x i32>* %412, align 16
  %413 = mul <4 x i32> %407, %61
  %414 = add <4 x i32> %413, %301
  %415 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %414, i32 %2) #8
  store <4 x i32> %415, <4 x i32>* %406, align 16
  %416 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 33
  %417 = bitcast <2 x i64>* %416 to <4 x i32>*
  store <4 x i32> %308, <4 x i32>* %417, align 16
  %418 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 34
  %419 = bitcast <2 x i64>* %418 to <4 x i32>*
  store <4 x i32> %312, <4 x i32>* %419, align 16
  %420 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 37
  %421 = bitcast <2 x i64>* %420 to <4 x i32>*
  store <4 x i32> %326, <4 x i32>* %421, align 16
  %422 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 38
  %423 = bitcast <2 x i64>* %422 to <4 x i32>*
  store <4 x i32> %330, <4 x i32>* %423, align 16
  %424 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 41
  %425 = bitcast <2 x i64>* %424 to <4 x i32>*
  store <4 x i32> %345, <4 x i32>* %425, align 16
  %426 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 42
  %427 = bitcast <2 x i64>* %426 to <4 x i32>*
  store <4 x i32> %350, <4 x i32>* %427, align 16
  %428 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 45
  %429 = bitcast <2 x i64>* %428 to <4 x i32>*
  store <4 x i32> %375, <4 x i32>* %429, align 16
  %430 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 46
  %431 = bitcast <2 x i64>* %430 to <4 x i32>*
  store <4 x i32> %360, <4 x i32>* %431, align 16
  %432 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 49
  %433 = bitcast <2 x i64>* %432 to <4 x i32>*
  store <4 x i32> %365, <4 x i32>* %433, align 16
  %434 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 50
  %435 = bitcast <2 x i64>* %434 to <4 x i32>*
  store <4 x i32> %370, <4 x i32>* %435, align 16
  %436 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 53
  %437 = bitcast <2 x i64>* %436 to <4 x i32>*
  store <4 x i32> %355, <4 x i32>* %437, align 16
  %438 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 54
  %439 = bitcast <2 x i64>* %438 to <4 x i32>*
  store <4 x i32> %340, <4 x i32>* %439, align 16
  %440 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 57
  %441 = bitcast <2 x i64>* %440 to <4 x i32>*
  %442 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 58
  %443 = bitcast <2 x i64>* %442 to <4 x i32>*
  %444 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 61
  %445 = bitcast <2 x i64>* %444 to <4 x i32>*
  %446 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 62
  %447 = bitcast <2 x i64>* %446 to <4 x i32>*
  %448 = bitcast <2 x i64>* %295 to <4 x i32>*
  %449 = load <4 x i32>, <4 x i32>* %448, align 16
  %450 = mul <4 x i32> %449, %53
  %451 = add <4 x i32> %450, %301
  %452 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %451, i32 %2) #8
  %453 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 15
  %454 = bitcast <2 x i64>* %453 to <4 x i32>*
  store <4 x i32> %452, <4 x i32>* %454, align 16
  %455 = mul <4 x i32> %449, %161
  %456 = add <4 x i32> %455, %301
  %457 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %456, i32 %2) #8
  store <4 x i32> %457, <4 x i32>* %448, align 16
  %458 = bitcast <2 x i64>* %298 to <4 x i32>*
  %459 = load <4 x i32>, <4 x i32>* %458, align 16
  %460 = mul <4 x i32> %459, %218
  %461 = add <4 x i32> %460, %301
  %462 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %461, i32 %2) #8
  %463 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 11
  %464 = bitcast <2 x i64>* %463 to <4 x i32>*
  store <4 x i32> %462, <4 x i32>* %464, align 16
  %465 = mul <4 x i32> %459, %85
  %466 = add <4 x i32> %465, %301
  %467 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %466, i32 %2) #8
  store <4 x i32> %467, <4 x i32>* %458, align 16
  %468 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 17
  %469 = bitcast <2 x i64>* %468 to <4 x i32>*
  store <4 x i32> %385, <4 x i32>* %469, align 16
  %470 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 18
  %471 = bitcast <2 x i64>* %470 to <4 x i32>*
  store <4 x i32> %390, <4 x i32>* %471, align 16
  %472 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 21
  %473 = bitcast <2 x i64>* %472 to <4 x i32>*
  store <4 x i32> %405, <4 x i32>* %473, align 16
  %474 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 22
  %475 = bitcast <2 x i64>* %474 to <4 x i32>*
  store <4 x i32> %410, <4 x i32>* %475, align 16
  %476 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 25
  %477 = bitcast <2 x i64>* %476 to <4 x i32>*
  store <4 x i32> %415, <4 x i32>* %477, align 16
  %478 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 26
  %479 = bitcast <2 x i64>* %478 to <4 x i32>*
  store <4 x i32> %400, <4 x i32>* %479, align 16
  %480 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 29
  %481 = bitcast <2 x i64>* %480 to <4 x i32>*
  store <4 x i32> %395, <4 x i32>* %481, align 16
  %482 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 30
  %483 = bitcast <2 x i64>* %482 to <4 x i32>*
  store <4 x i32> %380, <4 x i32>* %483, align 16
  %484 = mul <4 x i32> %308, %172
  %485 = mul <4 x i32> %303, %161
  %486 = add <4 x i32> %484, %301
  %487 = add <4 x i32> %486, %485
  %488 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %487, i32 %2) #8
  %489 = mul <4 x i32> %312, %239
  %490 = mul <4 x i32> %317, %172
  %491 = add <4 x i32> %489, %301
  %492 = add <4 x i32> %491, %490
  %493 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %492, i32 %2) #8
  %494 = mul <4 x i32> %326, %197
  %495 = mul <4 x i32> %321, %112
  %496 = add <4 x i32> %494, %301
  %497 = add <4 x i32> %496, %495
  %498 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %497, i32 %2) #8
  %499 = load <4 x i32>, <4 x i32>* %423, align 16
  %500 = mul <4 x i32> %499, %189
  %501 = mul <4 x i32> %335, %197
  %502 = add <4 x i32> %500, %301
  %503 = add <4 x i32> %502, %501
  %504 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %503, i32 %2) #8
  %505 = mul <4 x i32> %499, %197
  %506 = mul <4 x i32> %335, %112
  %507 = add <4 x i32> %505, %301
  %508 = add <4 x i32> %507, %506
  %509 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %508, i32 %2) #8
  store <4 x i32> %509, <4 x i32>* %441, align 16
  %510 = mul <4 x i32> %326, %112
  %511 = mul <4 x i32> %321, %122
  %512 = add <4 x i32> %510, %301
  %513 = add <4 x i32> %512, %511
  %514 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %513, i32 %2) #8
  store <4 x i32> %514, <4 x i32>* %443, align 16
  %515 = mul <4 x i32> %312, %172
  %516 = mul <4 x i32> %317, %161
  %517 = add <4 x i32> %515, %301
  %518 = add <4 x i32> %517, %516
  %519 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %518, i32 %2) #8
  store <4 x i32> %519, <4 x i32>* %445, align 16
  %520 = mul <4 x i32> %308, %161
  %521 = mul <4 x i32> %303, %53
  %522 = add <4 x i32> %520, %301
  %523 = add <4 x i32> %522, %521
  %524 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %523, i32 %2) #8
  store <4 x i32> %524, <4 x i32>* %447, align 16
  store <4 x i32> %488, <4 x i32>* %417, align 16
  store <4 x i32> %493, <4 x i32>* %419, align 16
  store <4 x i32> %498, <4 x i32>* %421, align 16
  store <4 x i32> %504, <4 x i32>* %423, align 16
  %525 = load <4 x i32>, <4 x i32>* %425, align 16
  %526 = mul <4 x i32> %525, %183
  %527 = load <4 x i32>, <4 x i32>* %439, align 16
  %528 = mul <4 x i32> %527, %130
  %529 = add <4 x i32> %526, %301
  %530 = add <4 x i32> %529, %528
  %531 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %530, i32 %2) #8
  %532 = load <4 x i32>, <4 x i32>* %427, align 16
  %533 = mul <4 x i32> %532, %203
  %534 = load <4 x i32>, <4 x i32>* %437, align 16
  %535 = mul <4 x i32> %534, %183
  %536 = add <4 x i32> %533, %301
  %537 = add <4 x i32> %536, %535
  %538 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %537, i32 %2) #8
  %539 = load <4 x i32>, <4 x i32>* %429, align 16
  %540 = mul <4 x i32> %539, %218
  %541 = load <4 x i32>, <4 x i32>* %435, align 16
  %542 = mul <4 x i32> %541, %85
  %543 = add <4 x i32> %540, %301
  %544 = add <4 x i32> %543, %542
  %545 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %544, i32 %2) #8
  %546 = load <4 x i32>, <4 x i32>* %431, align 16
  %547 = mul <4 x i32> %546, %178
  %548 = load <4 x i32>, <4 x i32>* %433, align 16
  %549 = mul <4 x i32> %548, %218
  %550 = add <4 x i32> %547, %301
  %551 = add <4 x i32> %550, %549
  %552 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %551, i32 %2) #8
  %553 = mul <4 x i32> %546, %218
  %554 = mul <4 x i32> %548, %85
  %555 = add <4 x i32> %553, %301
  %556 = add <4 x i32> %555, %554
  %557 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %556, i32 %2) #8
  store <4 x i32> %557, <4 x i32>* %433, align 16
  %558 = mul <4 x i32> %539, %85
  %559 = mul <4 x i32> %541, %141
  %560 = add <4 x i32> %558, %301
  %561 = add <4 x i32> %560, %559
  %562 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %561, i32 %2) #8
  store <4 x i32> %562, <4 x i32>* %435, align 16
  %563 = mul <4 x i32> %532, %183
  %564 = mul <4 x i32> %534, %130
  %565 = add <4 x i32> %563, %301
  %566 = add <4 x i32> %565, %564
  %567 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %566, i32 %2) #8
  store <4 x i32> %567, <4 x i32>* %437, align 16
  %568 = mul <4 x i32> %525, %130
  %569 = mul <4 x i32> %527, %104
  %570 = add <4 x i32> %568, %301
  %571 = add <4 x i32> %570, %569
  %572 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %571, i32 %2) #8
  store <4 x i32> %572, <4 x i32>* %439, align 16
  store <4 x i32> %531, <4 x i32>* %425, align 16
  store <4 x i32> %538, <4 x i32>* %427, align 16
  store <4 x i32> %545, <4 x i32>* %429, align 16
  store <4 x i32> %552, <4 x i32>* %431, align 16
  %573 = bitcast <2 x i64>* %292 to <4 x i32>*
  %574 = load <4 x i32>, <4 x i32>* %573, align 16
  %575 = mul <4 x i32> %574, %69
  %576 = add <4 x i32> %575, %301
  %577 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %576, i32 %2) #8
  %578 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 7
  %579 = bitcast <2 x i64>* %578 to <4 x i32>*
  store <4 x i32> %577, <4 x i32>* %579, align 16
  %580 = mul <4 x i32> %574, %153
  %581 = add <4 x i32> %580, %301
  %582 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %581, i32 %2) #8
  store <4 x i32> %582, <4 x i32>* %573, align 16
  %583 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 9
  %584 = bitcast <2 x i64>* %583 to <4 x i32>*
  store <4 x i32> %457, <4 x i32>* %584, align 16
  %585 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 10
  %586 = bitcast <2 x i64>* %585 to <4 x i32>*
  store <4 x i32> %462, <4 x i32>* %586, align 16
  %587 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 13
  %588 = bitcast <2 x i64>* %587 to <4 x i32>*
  store <4 x i32> %467, <4 x i32>* %588, align 16
  %589 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 14
  %590 = bitcast <2 x i64>* %589 to <4 x i32>*
  store <4 x i32> %452, <4 x i32>* %590, align 16
  %591 = load <4 x i32>, <4 x i32>* %469, align 16
  %592 = mul <4 x i32> %591, %175
  %593 = load <4 x i32>, <4 x i32>* %483, align 16
  %594 = mul <4 x i32> %593, %153
  %595 = add <4 x i32> %592, %301
  %596 = add <4 x i32> %595, %594
  %597 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %596, i32 %2) #8
  %598 = load <4 x i32>, <4 x i32>* %471, align 16
  %599 = mul <4 x i32> %598, %226
  %600 = load <4 x i32>, <4 x i32>* %481, align 16
  %601 = mul <4 x i32> %600, %175
  %602 = add <4 x i32> %599, %301
  %603 = add <4 x i32> %602, %601
  %604 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %603, i32 %2) #8
  %605 = load <4 x i32>, <4 x i32>* %473, align 16
  %606 = mul <4 x i32> %605, %200
  %607 = load <4 x i32>, <4 x i32>* %479, align 16
  %608 = mul <4 x i32> %607, %108
  %609 = add <4 x i32> %606, %301
  %610 = add <4 x i32> %609, %608
  %611 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %610, i32 %2) #8
  %612 = load <4 x i32>, <4 x i32>* %475, align 16
  %613 = mul <4 x i32> %612, %186
  %614 = load <4 x i32>, <4 x i32>* %477, align 16
  %615 = mul <4 x i32> %614, %200
  %616 = add <4 x i32> %613, %301
  %617 = add <4 x i32> %616, %615
  %618 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %617, i32 %2) #8
  %619 = mul <4 x i32> %612, %200
  %620 = mul <4 x i32> %614, %108
  %621 = add <4 x i32> %619, %301
  %622 = add <4 x i32> %621, %620
  %623 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %622, i32 %2) #8
  store <4 x i32> %623, <4 x i32>* %477, align 16
  %624 = mul <4 x i32> %605, %108
  %625 = mul <4 x i32> %607, %126
  %626 = add <4 x i32> %624, %301
  %627 = add <4 x i32> %626, %625
  %628 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %627, i32 %2) #8
  store <4 x i32> %628, <4 x i32>* %479, align 16
  %629 = mul <4 x i32> %598, %175
  %630 = mul <4 x i32> %600, %153
  %631 = add <4 x i32> %629, %301
  %632 = add <4 x i32> %631, %630
  %633 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %632, i32 %2) #8
  store <4 x i32> %633, <4 x i32>* %481, align 16
  %634 = mul <4 x i32> %591, %153
  %635 = mul <4 x i32> %593, %69
  %636 = add <4 x i32> %634, %301
  %637 = add <4 x i32> %636, %635
  %638 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %637, i32 %2) #8
  store <4 x i32> %638, <4 x i32>* %483, align 16
  store <4 x i32> %597, <4 x i32>* %469, align 16
  store <4 x i32> %604, <4 x i32>* %471, align 16
  store <4 x i32> %611, <4 x i32>* %473, align 16
  store <4 x i32> %618, <4 x i32>* %475, align 16
  %639 = load <4 x i32>, <4 x i32>* %32, align 16
  %640 = load <4 x i32>, <4 x i32>* %37, align 16
  br label %641

641:                                              ; preds = %6, %641
  %642 = phi i64 [ 32, %6 ], [ %714, %641 ]
  %643 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %642
  %644 = bitcast <2 x i64>* %643 to <4 x i32>*
  %645 = load <4 x i32>, <4 x i32>* %644, align 16
  %646 = or i64 %642, 3
  %647 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %646
  %648 = bitcast <2 x i64>* %647 to <4 x i32>*
  %649 = load <4 x i32>, <4 x i32>* %648, align 16
  %650 = add <4 x i32> %649, %645
  %651 = sub <4 x i32> %645, %649
  %652 = icmp sgt <4 x i32> %650, %639
  %653 = select <4 x i1> %652, <4 x i32> %650, <4 x i32> %639
  %654 = icmp slt <4 x i32> %653, %640
  %655 = select <4 x i1> %654, <4 x i32> %653, <4 x i32> %640
  %656 = icmp sgt <4 x i32> %651, %639
  %657 = select <4 x i1> %656, <4 x i32> %651, <4 x i32> %639
  %658 = icmp slt <4 x i32> %657, %640
  %659 = select <4 x i1> %658, <4 x i32> %657, <4 x i32> %640
  store <4 x i32> %655, <4 x i32>* %644, align 16
  store <4 x i32> %659, <4 x i32>* %648, align 16
  %660 = or i64 %642, 1
  %661 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %660
  %662 = bitcast <2 x i64>* %661 to <4 x i32>*
  %663 = load <4 x i32>, <4 x i32>* %662, align 16
  %664 = or i64 %642, 2
  %665 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %664
  %666 = bitcast <2 x i64>* %665 to <4 x i32>*
  %667 = load <4 x i32>, <4 x i32>* %666, align 16
  %668 = add <4 x i32> %667, %663
  %669 = sub <4 x i32> %663, %667
  %670 = icmp sgt <4 x i32> %668, %639
  %671 = select <4 x i1> %670, <4 x i32> %668, <4 x i32> %639
  %672 = icmp slt <4 x i32> %671, %640
  %673 = select <4 x i1> %672, <4 x i32> %671, <4 x i32> %640
  %674 = icmp sgt <4 x i32> %669, %639
  %675 = select <4 x i1> %674, <4 x i32> %669, <4 x i32> %639
  %676 = icmp slt <4 x i32> %675, %640
  %677 = select <4 x i1> %676, <4 x i32> %675, <4 x i32> %640
  store <4 x i32> %673, <4 x i32>* %662, align 16
  store <4 x i32> %677, <4 x i32>* %666, align 16
  %678 = or i64 %642, 7
  %679 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %678
  %680 = bitcast <2 x i64>* %679 to <4 x i32>*
  %681 = load <4 x i32>, <4 x i32>* %680, align 16
  %682 = or i64 %642, 4
  %683 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %682
  %684 = bitcast <2 x i64>* %683 to <4 x i32>*
  %685 = load <4 x i32>, <4 x i32>* %684, align 16
  %686 = add <4 x i32> %685, %681
  %687 = sub <4 x i32> %681, %685
  %688 = icmp sgt <4 x i32> %686, %639
  %689 = select <4 x i1> %688, <4 x i32> %686, <4 x i32> %639
  %690 = icmp slt <4 x i32> %689, %640
  %691 = select <4 x i1> %690, <4 x i32> %689, <4 x i32> %640
  %692 = icmp sgt <4 x i32> %687, %639
  %693 = select <4 x i1> %692, <4 x i32> %687, <4 x i32> %639
  %694 = icmp slt <4 x i32> %693, %640
  %695 = select <4 x i1> %694, <4 x i32> %693, <4 x i32> %640
  store <4 x i32> %691, <4 x i32>* %680, align 16
  store <4 x i32> %695, <4 x i32>* %684, align 16
  %696 = or i64 %642, 6
  %697 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %696
  %698 = bitcast <2 x i64>* %697 to <4 x i32>*
  %699 = load <4 x i32>, <4 x i32>* %698, align 16
  %700 = or i64 %642, 5
  %701 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %700
  %702 = bitcast <2 x i64>* %701 to <4 x i32>*
  %703 = load <4 x i32>, <4 x i32>* %702, align 16
  %704 = add <4 x i32> %703, %699
  %705 = sub <4 x i32> %699, %703
  %706 = icmp sgt <4 x i32> %704, %639
  %707 = select <4 x i1> %706, <4 x i32> %704, <4 x i32> %639
  %708 = icmp slt <4 x i32> %707, %640
  %709 = select <4 x i1> %708, <4 x i32> %707, <4 x i32> %640
  %710 = icmp sgt <4 x i32> %705, %639
  %711 = select <4 x i1> %710, <4 x i32> %705, <4 x i32> %639
  %712 = icmp slt <4 x i32> %711, %640
  %713 = select <4 x i1> %712, <4 x i32> %711, <4 x i32> %640
  store <4 x i32> %709, <4 x i32>* %698, align 16
  store <4 x i32> %713, <4 x i32>* %702, align 16
  %714 = add nuw nsw i64 %642, 8
  %715 = icmp ult i64 %714, 64
  br i1 %715, label %641, label %716

716:                                              ; preds = %641
  %717 = shufflevector <4 x i32> %100, <4 x i32> undef, <4 x i32> zeroinitializer
  %718 = shufflevector <4 x i32> %133, <4 x i32> undef, <4 x i32> zeroinitializer
  %719 = shufflevector <4 x i32> %180, <4 x i32> undef, <4 x i32> zeroinitializer
  %720 = shufflevector <4 x i32> %205, <4 x i32> undef, <4 x i32> zeroinitializer
  %721 = load <4 x i32>, <4 x i32>* %118, align 16
  %722 = bitcast [64 x <2 x i64>]* %12 to <4 x i32>*
  %723 = load <4 x i32>, <4 x i32>* %722, align 16
  %724 = mul <4 x i32> %723, %721
  %725 = add <4 x i32> %724, %301
  %726 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %725, i32 %2) #8
  %727 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 1
  %728 = bitcast <2 x i64>* %727 to <4 x i32>*
  store <4 x i32> %726, <4 x i32>* %728, align 16
  store <4 x i32> %726, <4 x i32>* %722, align 16
  %729 = load <2 x i64>, <2 x i64>* %292, align 16
  %730 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 5
  store <2 x i64> %729, <2 x i64>* %730, align 16
  %731 = load <2 x i64>, <2 x i64>* %578, align 16
  %732 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 6
  store <2 x i64> %731, <2 x i64>* %732, align 16
  %733 = load <4 x i32>, <4 x i32>* %584, align 16
  %734 = mul <4 x i32> %733, %719
  %735 = load <4 x i32>, <4 x i32>* %590, align 16
  %736 = mul <4 x i32> %735, %718
  %737 = add <4 x i32> %734, %301
  %738 = add <4 x i32> %737, %736
  %739 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %738, i32 %2) #8
  %740 = mul <4 x i32> %733, %718
  %741 = mul <4 x i32> %735, %717
  %742 = add <4 x i32> %740, %301
  %743 = add <4 x i32> %742, %741
  %744 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %743, i32 %2) #8
  store <4 x i32> %744, <4 x i32>* %590, align 16
  store <4 x i32> %739, <4 x i32>* %584, align 16
  %745 = load <4 x i32>, <4 x i32>* %586, align 16
  %746 = mul <4 x i32> %745, %720
  %747 = load <4 x i32>, <4 x i32>* %588, align 16
  %748 = mul <4 x i32> %747, %719
  %749 = add <4 x i32> %746, %301
  %750 = add <4 x i32> %749, %748
  %751 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %750, i32 %2) #8
  %752 = mul <4 x i32> %745, %719
  %753 = mul <4 x i32> %747, %718
  %754 = add <4 x i32> %752, %301
  %755 = add <4 x i32> %754, %753
  %756 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %755, i32 %2) #8
  store <4 x i32> %756, <4 x i32>* %588, align 16
  store <4 x i32> %751, <4 x i32>* %586, align 16
  %757 = load <4 x i32>, <4 x i32>* %376, align 16
  %758 = load <4 x i32>, <4 x i32>* %392, align 16
  %759 = add <4 x i32> %758, %757
  %760 = sub <4 x i32> %757, %758
  %761 = icmp sgt <4 x i32> %759, %639
  %762 = select <4 x i1> %761, <4 x i32> %759, <4 x i32> %639
  %763 = icmp slt <4 x i32> %762, %640
  %764 = select <4 x i1> %763, <4 x i32> %762, <4 x i32> %640
  %765 = icmp sgt <4 x i32> %760, %639
  %766 = select <4 x i1> %765, <4 x i32> %760, <4 x i32> %639
  %767 = icmp slt <4 x i32> %766, %640
  %768 = select <4 x i1> %767, <4 x i32> %766, <4 x i32> %640
  store <4 x i32> %764, <4 x i32>* %376, align 16
  store <4 x i32> %768, <4 x i32>* %392, align 16
  %769 = load <4 x i32>, <4 x i32>* %469, align 16
  %770 = load <4 x i32>, <4 x i32>* %471, align 16
  %771 = add <4 x i32> %770, %769
  %772 = sub <4 x i32> %769, %770
  %773 = icmp sgt <4 x i32> %771, %639
  %774 = select <4 x i1> %773, <4 x i32> %771, <4 x i32> %639
  %775 = icmp slt <4 x i32> %774, %640
  %776 = select <4 x i1> %775, <4 x i32> %774, <4 x i32> %640
  %777 = icmp sgt <4 x i32> %772, %639
  %778 = select <4 x i1> %777, <4 x i32> %772, <4 x i32> %639
  %779 = icmp slt <4 x i32> %778, %640
  %780 = select <4 x i1> %779, <4 x i32> %778, <4 x i32> %640
  store <4 x i32> %776, <4 x i32>* %469, align 16
  store <4 x i32> %780, <4 x i32>* %471, align 16
  %781 = load <4 x i32>, <4 x i32>* %412, align 16
  %782 = load <4 x i32>, <4 x i32>* %396, align 16
  %783 = add <4 x i32> %782, %781
  %784 = sub <4 x i32> %781, %782
  %785 = icmp sgt <4 x i32> %783, %639
  %786 = select <4 x i1> %785, <4 x i32> %783, <4 x i32> %639
  %787 = icmp slt <4 x i32> %786, %640
  %788 = select <4 x i1> %787, <4 x i32> %786, <4 x i32> %640
  %789 = icmp sgt <4 x i32> %784, %639
  %790 = select <4 x i1> %789, <4 x i32> %784, <4 x i32> %639
  %791 = icmp slt <4 x i32> %790, %640
  %792 = select <4 x i1> %791, <4 x i32> %790, <4 x i32> %640
  store <4 x i32> %788, <4 x i32>* %412, align 16
  store <4 x i32> %792, <4 x i32>* %396, align 16
  %793 = load <4 x i32>, <4 x i32>* %475, align 16
  %794 = load <4 x i32>, <4 x i32>* %473, align 16
  %795 = add <4 x i32> %794, %793
  %796 = sub <4 x i32> %793, %794
  %797 = icmp sgt <4 x i32> %795, %639
  %798 = select <4 x i1> %797, <4 x i32> %795, <4 x i32> %639
  %799 = icmp slt <4 x i32> %798, %640
  %800 = select <4 x i1> %799, <4 x i32> %798, <4 x i32> %640
  %801 = icmp sgt <4 x i32> %796, %639
  %802 = select <4 x i1> %801, <4 x i32> %796, <4 x i32> %639
  %803 = icmp slt <4 x i32> %802, %640
  %804 = select <4 x i1> %803, <4 x i32> %802, <4 x i32> %640
  store <4 x i32> %800, <4 x i32>* %475, align 16
  store <4 x i32> %804, <4 x i32>* %473, align 16
  %805 = load <4 x i32>, <4 x i32>* %406, align 16
  %806 = load <4 x i32>, <4 x i32>* %402, align 16
  %807 = add <4 x i32> %806, %805
  %808 = sub <4 x i32> %805, %806
  %809 = icmp sgt <4 x i32> %807, %639
  %810 = select <4 x i1> %809, <4 x i32> %807, <4 x i32> %639
  %811 = icmp slt <4 x i32> %810, %640
  %812 = select <4 x i1> %811, <4 x i32> %810, <4 x i32> %640
  %813 = icmp sgt <4 x i32> %808, %639
  %814 = select <4 x i1> %813, <4 x i32> %808, <4 x i32> %639
  %815 = icmp slt <4 x i32> %814, %640
  %816 = select <4 x i1> %815, <4 x i32> %814, <4 x i32> %640
  store <4 x i32> %812, <4 x i32>* %406, align 16
  store <4 x i32> %816, <4 x i32>* %402, align 16
  %817 = load <4 x i32>, <4 x i32>* %477, align 16
  %818 = load <4 x i32>, <4 x i32>* %479, align 16
  %819 = add <4 x i32> %818, %817
  %820 = sub <4 x i32> %817, %818
  %821 = icmp sgt <4 x i32> %819, %639
  %822 = select <4 x i1> %821, <4 x i32> %819, <4 x i32> %639
  %823 = icmp slt <4 x i32> %822, %640
  %824 = select <4 x i1> %823, <4 x i32> %822, <4 x i32> %640
  %825 = icmp sgt <4 x i32> %820, %639
  %826 = select <4 x i1> %825, <4 x i32> %820, <4 x i32> %639
  %827 = icmp slt <4 x i32> %826, %640
  %828 = select <4 x i1> %827, <4 x i32> %826, <4 x i32> %640
  store <4 x i32> %824, <4 x i32>* %477, align 16
  store <4 x i32> %828, <4 x i32>* %479, align 16
  %829 = load <4 x i32>, <4 x i32>* %382, align 16
  %830 = load <4 x i32>, <4 x i32>* %386, align 16
  %831 = add <4 x i32> %830, %829
  %832 = sub <4 x i32> %829, %830
  %833 = icmp sgt <4 x i32> %831, %639
  %834 = select <4 x i1> %833, <4 x i32> %831, <4 x i32> %639
  %835 = icmp slt <4 x i32> %834, %640
  %836 = select <4 x i1> %835, <4 x i32> %834, <4 x i32> %640
  %837 = icmp sgt <4 x i32> %832, %639
  %838 = select <4 x i1> %837, <4 x i32> %832, <4 x i32> %639
  %839 = icmp slt <4 x i32> %838, %640
  %840 = select <4 x i1> %839, <4 x i32> %838, <4 x i32> %640
  store <4 x i32> %836, <4 x i32>* %382, align 16
  store <4 x i32> %840, <4 x i32>* %386, align 16
  %841 = load <4 x i32>, <4 x i32>* %483, align 16
  %842 = load <4 x i32>, <4 x i32>* %481, align 16
  %843 = add <4 x i32> %842, %841
  %844 = sub <4 x i32> %841, %842
  %845 = icmp sgt <4 x i32> %843, %639
  %846 = select <4 x i1> %845, <4 x i32> %843, <4 x i32> %639
  %847 = icmp slt <4 x i32> %846, %640
  %848 = select <4 x i1> %847, <4 x i32> %846, <4 x i32> %640
  %849 = icmp sgt <4 x i32> %844, %639
  %850 = select <4 x i1> %849, <4 x i32> %844, <4 x i32> %639
  %851 = icmp slt <4 x i32> %850, %640
  %852 = select <4 x i1> %851, <4 x i32> %850, <4 x i32> %640
  store <4 x i32> %848, <4 x i32>* %483, align 16
  store <4 x i32> %852, <4 x i32>* %481, align 16
  %853 = load <4 x i32>, <4 x i32>* %419, align 16
  %854 = mul <4 x i32> %853, %175
  %855 = load <4 x i32>, <4 x i32>* %445, align 16
  %856 = mul <4 x i32> %855, %153
  %857 = add <4 x i32> %856, %854
  %858 = load <4 x i32>, <4 x i32>* %20, align 16
  %859 = add <4 x i32> %857, %858
  %860 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %859, i32 %2) #8
  %861 = load <4 x i32>, <4 x i32>* %314, align 16
  %862 = mul <4 x i32> %861, %175
  %863 = load <4 x i32>, <4 x i32>* %309, align 16
  %864 = mul <4 x i32> %863, %153
  %865 = add <4 x i32> %862, %858
  %866 = add <4 x i32> %865, %864
  %867 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %866, i32 %2) #8
  %868 = load <4 x i32>, <4 x i32>* %318, align 16
  %869 = mul <4 x i32> %868, %226
  %870 = load <4 x i32>, <4 x i32>* %323, align 16
  %871 = mul <4 x i32> %870, %175
  %872 = add <4 x i32> %869, %858
  %873 = add <4 x i32> %872, %871
  %874 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %873, i32 %2) #8
  %875 = load <4 x i32>, <4 x i32>* %421, align 16
  %876 = mul <4 x i32> %875, %226
  %877 = load <4 x i32>, <4 x i32>* %443, align 16
  %878 = mul <4 x i32> %877, %175
  %879 = add <4 x i32> %876, %858
  %880 = add <4 x i32> %879, %878
  %881 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %880, i32 %2) #8
  %882 = mul <4 x i32> %875, %175
  %883 = mul <4 x i32> %877, %153
  %884 = add <4 x i32> %882, %858
  %885 = add <4 x i32> %884, %883
  %886 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %885, i32 %2) #8
  store <4 x i32> %886, <4 x i32>* %443, align 16
  %887 = mul <4 x i32> %868, %175
  %888 = mul <4 x i32> %870, %153
  %889 = add <4 x i32> %887, %858
  %890 = add <4 x i32> %889, %888
  %891 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %890, i32 %2) #8
  store <4 x i32> %891, <4 x i32>* %323, align 16
  %892 = mul <4 x i32> %861, %153
  %893 = mul <4 x i32> %863, %69
  %894 = add <4 x i32> %892, %858
  %895 = add <4 x i32> %894, %893
  %896 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %895, i32 %2) #8
  store <4 x i32> %896, <4 x i32>* %309, align 16
  %897 = mul <4 x i32> %853, %153
  %898 = mul <4 x i32> %855, %69
  %899 = add <4 x i32> %898, %897
  %900 = add <4 x i32> %899, %858
  %901 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %900, i32 %2) #8
  store <4 x i32> %901, <4 x i32>* %445, align 16
  store <4 x i32> %860, <4 x i32>* %419, align 16
  store <4 x i32> %867, <4 x i32>* %314, align 16
  store <4 x i32> %874, <4 x i32>* %318, align 16
  store <4 x i32> %881, <4 x i32>* %421, align 16
  %902 = load <4 x i32>, <4 x i32>* %427, align 16
  %903 = mul <4 x i32> %902, %200
  %904 = load <4 x i32>, <4 x i32>* %437, align 16
  %905 = mul <4 x i32> %904, %108
  %906 = add <4 x i32> %903, %858
  %907 = add <4 x i32> %906, %905
  %908 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %907, i32 %2) #8
  %909 = load <4 x i32>, <4 x i32>* %352, align 16
  %910 = mul <4 x i32> %909, %200
  %911 = load <4 x i32>, <4 x i32>* %346, align 16
  %912 = mul <4 x i32> %911, %108
  %913 = add <4 x i32> %910, %858
  %914 = add <4 x i32> %913, %912
  %915 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %914, i32 %2) #8
  %916 = load <4 x i32>, <4 x i32>* %366, align 16
  %917 = mul <4 x i32> %916, %186
  %918 = load <4 x i32>, <4 x i32>* %372, align 16
  %919 = mul <4 x i32> %918, %200
  %920 = add <4 x i32> %917, %858
  %921 = add <4 x i32> %920, %919
  %922 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %921, i32 %2) #8
  %923 = load <4 x i32>, <4 x i32>* %429, align 16
  %924 = mul <4 x i32> %923, %186
  %925 = load <4 x i32>, <4 x i32>* %435, align 16
  %926 = mul <4 x i32> %925, %200
  %927 = add <4 x i32> %924, %858
  %928 = add <4 x i32> %927, %926
  %929 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %928, i32 %2) #8
  %930 = mul <4 x i32> %923, %200
  %931 = mul <4 x i32> %925, %108
  %932 = add <4 x i32> %930, %858
  %933 = add <4 x i32> %932, %931
  %934 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %933, i32 %2) #8
  store <4 x i32> %934, <4 x i32>* %435, align 16
  %935 = mul <4 x i32> %916, %200
  %936 = mul <4 x i32> %918, %108
  %937 = add <4 x i32> %935, %858
  %938 = add <4 x i32> %937, %936
  %939 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %938, i32 %2) #8
  store <4 x i32> %939, <4 x i32>* %372, align 16
  %940 = mul <4 x i32> %909, %108
  %941 = mul <4 x i32> %911, %126
  %942 = add <4 x i32> %940, %858
  %943 = add <4 x i32> %942, %941
  %944 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %943, i32 %2) #8
  store <4 x i32> %944, <4 x i32>* %346, align 16
  %945 = mul <4 x i32> %902, %108
  %946 = mul <4 x i32> %904, %126
  %947 = add <4 x i32> %945, %858
  %948 = add <4 x i32> %947, %946
  %949 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %948, i32 %2) #8
  store <4 x i32> %949, <4 x i32>* %437, align 16
  store <4 x i32> %908, <4 x i32>* %427, align 16
  store <4 x i32> %915, <4 x i32>* %352, align 16
  store <4 x i32> %922, <4 x i32>* %366, align 16
  store <4 x i32> %929, <4 x i32>* %429, align 16
  %950 = load <2 x i64>, <2 x i64>* %249, align 16
  %951 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 3
  store <2 x i64> %950, <2 x i64>* %951, align 16
  %952 = load <2 x i64>, <2 x i64>* %727, align 16
  %953 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 2
  store <2 x i64> %952, <2 x i64>* %953, align 16
  %954 = load <4 x i32>, <4 x i32>* %194, align 16
  %955 = bitcast <2 x i64>* %730 to <4 x i32>*
  %956 = load <4 x i32>, <4 x i32>* %955, align 16
  %957 = mul <4 x i32> %956, %954
  %958 = bitcast <2 x i64>* %732 to <4 x i32>*
  %959 = load <4 x i32>, <4 x i32>* %958, align 16
  %960 = mul <4 x i32> %959, %721
  %961 = add <4 x i32> %960, %858
  %962 = add <4 x i32> %961, %957
  %963 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %962, i32 %2) #8
  %964 = mul <4 x i32> %956, %721
  %965 = add <4 x i32> %961, %964
  %966 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %965, i32 %2) #8
  store <4 x i32> %966, <4 x i32>* %958, align 16
  store <4 x i32> %963, <4 x i32>* %955, align 16
  %967 = load <4 x i32>, <4 x i32>* %448, align 16
  %968 = load <4 x i32>, <4 x i32>* %464, align 16
  %969 = add <4 x i32> %968, %967
  %970 = sub <4 x i32> %967, %968
  %971 = load <4 x i32>, <4 x i32>* %32, align 16
  %972 = icmp sgt <4 x i32> %969, %971
  %973 = select <4 x i1> %972, <4 x i32> %969, <4 x i32> %971
  %974 = load <4 x i32>, <4 x i32>* %37, align 16
  %975 = icmp slt <4 x i32> %973, %974
  %976 = select <4 x i1> %975, <4 x i32> %973, <4 x i32> %974
  %977 = icmp sgt <4 x i32> %970, %971
  %978 = select <4 x i1> %977, <4 x i32> %970, <4 x i32> %971
  %979 = icmp slt <4 x i32> %978, %974
  %980 = select <4 x i1> %979, <4 x i32> %978, <4 x i32> %974
  store <4 x i32> %976, <4 x i32>* %448, align 16
  store <4 x i32> %980, <4 x i32>* %464, align 16
  %981 = load <4 x i32>, <4 x i32>* %584, align 16
  %982 = load <4 x i32>, <4 x i32>* %586, align 16
  %983 = add <4 x i32> %982, %981
  %984 = sub <4 x i32> %981, %982
  %985 = icmp sgt <4 x i32> %983, %971
  %986 = select <4 x i1> %985, <4 x i32> %983, <4 x i32> %971
  %987 = icmp slt <4 x i32> %986, %974
  %988 = select <4 x i1> %987, <4 x i32> %986, <4 x i32> %974
  %989 = icmp sgt <4 x i32> %984, %971
  %990 = select <4 x i1> %989, <4 x i32> %984, <4 x i32> %971
  %991 = icmp slt <4 x i32> %990, %974
  %992 = select <4 x i1> %991, <4 x i32> %990, <4 x i32> %974
  store <4 x i32> %988, <4 x i32>* %584, align 16
  store <4 x i32> %992, <4 x i32>* %586, align 16
  %993 = load <4 x i32>, <4 x i32>* %454, align 16
  %994 = load <4 x i32>, <4 x i32>* %458, align 16
  %995 = add <4 x i32> %994, %993
  %996 = sub <4 x i32> %993, %994
  %997 = icmp sgt <4 x i32> %995, %971
  %998 = select <4 x i1> %997, <4 x i32> %995, <4 x i32> %971
  %999 = icmp slt <4 x i32> %998, %974
  %1000 = select <4 x i1> %999, <4 x i32> %998, <4 x i32> %974
  %1001 = icmp sgt <4 x i32> %996, %971
  %1002 = select <4 x i1> %1001, <4 x i32> %996, <4 x i32> %971
  %1003 = icmp slt <4 x i32> %1002, %974
  %1004 = select <4 x i1> %1003, <4 x i32> %1002, <4 x i32> %974
  store <4 x i32> %1000, <4 x i32>* %454, align 16
  store <4 x i32> %1004, <4 x i32>* %458, align 16
  %1005 = load <4 x i32>, <4 x i32>* %590, align 16
  %1006 = load <4 x i32>, <4 x i32>* %588, align 16
  %1007 = add <4 x i32> %1006, %1005
  %1008 = sub <4 x i32> %1005, %1006
  %1009 = icmp sgt <4 x i32> %1007, %971
  %1010 = select <4 x i1> %1009, <4 x i32> %1007, <4 x i32> %971
  %1011 = icmp slt <4 x i32> %1010, %974
  %1012 = select <4 x i1> %1011, <4 x i32> %1010, <4 x i32> %974
  %1013 = icmp sgt <4 x i32> %1008, %971
  %1014 = select <4 x i1> %1013, <4 x i32> %1008, <4 x i32> %971
  %1015 = icmp slt <4 x i32> %1014, %974
  %1016 = select <4 x i1> %1015, <4 x i32> %1014, <4 x i32> %974
  store <4 x i32> %1012, <4 x i32>* %590, align 16
  store <4 x i32> %1016, <4 x i32>* %588, align 16
  %1017 = load <4 x i32>, <4 x i32>* %471, align 16
  %1018 = mul <4 x i32> %1017, %719
  %1019 = load <4 x i32>, <4 x i32>* %481, align 16
  %1020 = mul <4 x i32> %1019, %718
  %1021 = add <4 x i32> %1018, %858
  %1022 = add <4 x i32> %1021, %1020
  %1023 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1022, i32 %2) #8
  %1024 = load <4 x i32>, <4 x i32>* %392, align 16
  %1025 = mul <4 x i32> %1024, %719
  %1026 = load <4 x i32>, <4 x i32>* %386, align 16
  %1027 = mul <4 x i32> %1026, %718
  %1028 = add <4 x i32> %1025, %858
  %1029 = add <4 x i32> %1028, %1027
  %1030 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1029, i32 %2) #8
  %1031 = load <4 x i32>, <4 x i32>* %396, align 16
  %1032 = mul <4 x i32> %1031, %720
  %1033 = load <4 x i32>, <4 x i32>* %402, align 16
  %1034 = mul <4 x i32> %1033, %719
  %1035 = add <4 x i32> %1032, %858
  %1036 = add <4 x i32> %1035, %1034
  %1037 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1036, i32 %2) #8
  %1038 = load <4 x i32>, <4 x i32>* %473, align 16
  %1039 = mul <4 x i32> %1038, %720
  %1040 = load <4 x i32>, <4 x i32>* %479, align 16
  %1041 = mul <4 x i32> %1040, %719
  %1042 = add <4 x i32> %1039, %858
  %1043 = add <4 x i32> %1042, %1041
  %1044 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1043, i32 %2) #8
  %1045 = mul <4 x i32> %1038, %719
  %1046 = mul <4 x i32> %1040, %718
  %1047 = add <4 x i32> %1045, %858
  %1048 = add <4 x i32> %1047, %1046
  %1049 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1048, i32 %2) #8
  store <4 x i32> %1049, <4 x i32>* %479, align 16
  %1050 = mul <4 x i32> %1031, %719
  %1051 = mul <4 x i32> %1033, %718
  %1052 = add <4 x i32> %1050, %858
  %1053 = add <4 x i32> %1052, %1051
  %1054 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1053, i32 %2) #8
  store <4 x i32> %1054, <4 x i32>* %402, align 16
  %1055 = mul <4 x i32> %1024, %718
  %1056 = mul <4 x i32> %1026, %717
  %1057 = add <4 x i32> %1055, %858
  %1058 = add <4 x i32> %1057, %1056
  %1059 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1058, i32 %2) #8
  store <4 x i32> %1059, <4 x i32>* %386, align 16
  %1060 = mul <4 x i32> %1017, %718
  %1061 = mul <4 x i32> %1019, %717
  %1062 = add <4 x i32> %1060, %858
  %1063 = add <4 x i32> %1062, %1061
  %1064 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1063, i32 %2) #8
  store <4 x i32> %1064, <4 x i32>* %481, align 16
  store <4 x i32> %1023, <4 x i32>* %471, align 16
  store <4 x i32> %1030, <4 x i32>* %392, align 16
  store <4 x i32> %1037, <4 x i32>* %396, align 16
  store <4 x i32> %1044, <4 x i32>* %473, align 16
  br label %1065

1065:                                             ; preds = %716, %1065
  %1066 = phi i64 [ 32, %716 ], [ %1225, %1065 ]
  %1067 = phi i32 [ 32, %716 ], [ %1223, %1065 ]
  %1068 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1066
  %1069 = bitcast <2 x i64>* %1068 to <4 x i32>*
  %1070 = load <4 x i32>, <4 x i32>* %1069, align 16
  %1071 = and i64 %1066, 4294967280
  %1072 = or i64 %1071, 7
  %1073 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1072
  %1074 = bitcast <2 x i64>* %1073 to <4 x i32>*
  %1075 = load <4 x i32>, <4 x i32>* %1074, align 16
  %1076 = add <4 x i32> %1075, %1070
  %1077 = sub <4 x i32> %1070, %1075
  %1078 = icmp sgt <4 x i32> %1076, %971
  %1079 = select <4 x i1> %1078, <4 x i32> %1076, <4 x i32> %971
  %1080 = icmp slt <4 x i32> %1079, %974
  %1081 = select <4 x i1> %1080, <4 x i32> %1079, <4 x i32> %974
  %1082 = icmp sgt <4 x i32> %1077, %971
  %1083 = select <4 x i1> %1082, <4 x i32> %1077, <4 x i32> %971
  %1084 = icmp slt <4 x i32> %1083, %974
  %1085 = select <4 x i1> %1084, <4 x i32> %1083, <4 x i32> %974
  store <4 x i32> %1081, <4 x i32>* %1069, align 16
  store <4 x i32> %1085, <4 x i32>* %1074, align 16
  %1086 = and i64 %1066, 4294967280
  %1087 = or i64 %1086, 15
  %1088 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1087
  %1089 = bitcast <2 x i64>* %1088 to <4 x i32>*
  %1090 = load <4 x i32>, <4 x i32>* %1089, align 16
  %1091 = and i64 %1066, 4294967280
  %1092 = or i64 %1091, 8
  %1093 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1092
  %1094 = bitcast <2 x i64>* %1093 to <4 x i32>*
  %1095 = load <4 x i32>, <4 x i32>* %1094, align 16
  %1096 = add <4 x i32> %1095, %1090
  %1097 = sub <4 x i32> %1090, %1095
  %1098 = icmp sgt <4 x i32> %1096, %971
  %1099 = select <4 x i1> %1098, <4 x i32> %1096, <4 x i32> %971
  %1100 = icmp slt <4 x i32> %1099, %974
  %1101 = select <4 x i1> %1100, <4 x i32> %1099, <4 x i32> %974
  %1102 = icmp sgt <4 x i32> %1097, %971
  %1103 = select <4 x i1> %1102, <4 x i32> %1097, <4 x i32> %971
  %1104 = icmp slt <4 x i32> %1103, %974
  %1105 = select <4 x i1> %1104, <4 x i32> %1103, <4 x i32> %974
  store <4 x i32> %1101, <4 x i32>* %1089, align 16
  store <4 x i32> %1105, <4 x i32>* %1094, align 16
  %1106 = or i64 %1066, 1
  %1107 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1106
  %1108 = bitcast <2 x i64>* %1107 to <4 x i32>*
  %1109 = load <4 x i32>, <4 x i32>* %1108, align 16
  %1110 = and i64 %1066, 4294967280
  %1111 = or i64 %1110, 6
  %1112 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1111
  %1113 = bitcast <2 x i64>* %1112 to <4 x i32>*
  %1114 = load <4 x i32>, <4 x i32>* %1113, align 16
  %1115 = add <4 x i32> %1114, %1109
  %1116 = sub <4 x i32> %1109, %1114
  %1117 = icmp sgt <4 x i32> %1115, %971
  %1118 = select <4 x i1> %1117, <4 x i32> %1115, <4 x i32> %971
  %1119 = icmp slt <4 x i32> %1118, %974
  %1120 = select <4 x i1> %1119, <4 x i32> %1118, <4 x i32> %974
  %1121 = icmp sgt <4 x i32> %1116, %971
  %1122 = select <4 x i1> %1121, <4 x i32> %1116, <4 x i32> %971
  %1123 = icmp slt <4 x i32> %1122, %974
  %1124 = select <4 x i1> %1123, <4 x i32> %1122, <4 x i32> %974
  store <4 x i32> %1120, <4 x i32>* %1108, align 16
  store <4 x i32> %1124, <4 x i32>* %1113, align 16
  %1125 = and i64 %1066, 4294967280
  %1126 = or i64 %1125, 14
  %1127 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1126
  %1128 = bitcast <2 x i64>* %1127 to <4 x i32>*
  %1129 = load <4 x i32>, <4 x i32>* %1128, align 16
  %1130 = and i64 %1106, 4294967281
  %1131 = or i64 %1130, 8
  %1132 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1131
  %1133 = bitcast <2 x i64>* %1132 to <4 x i32>*
  %1134 = load <4 x i32>, <4 x i32>* %1133, align 16
  %1135 = add <4 x i32> %1134, %1129
  %1136 = sub <4 x i32> %1129, %1134
  %1137 = icmp sgt <4 x i32> %1135, %971
  %1138 = select <4 x i1> %1137, <4 x i32> %1135, <4 x i32> %971
  %1139 = icmp slt <4 x i32> %1138, %974
  %1140 = select <4 x i1> %1139, <4 x i32> %1138, <4 x i32> %974
  %1141 = icmp sgt <4 x i32> %1136, %971
  %1142 = select <4 x i1> %1141, <4 x i32> %1136, <4 x i32> %971
  %1143 = icmp slt <4 x i32> %1142, %974
  %1144 = select <4 x i1> %1143, <4 x i32> %1142, <4 x i32> %974
  store <4 x i32> %1140, <4 x i32>* %1128, align 16
  store <4 x i32> %1144, <4 x i32>* %1133, align 16
  %1145 = add nuw nsw i64 %1106, 1
  %1146 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1145
  %1147 = bitcast <2 x i64>* %1146 to <4 x i32>*
  %1148 = load <4 x i32>, <4 x i32>* %1147, align 16
  %1149 = and i64 %1145, 4294967280
  %1150 = or i64 %1149, 5
  %1151 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1150
  %1152 = bitcast <2 x i64>* %1151 to <4 x i32>*
  %1153 = load <4 x i32>, <4 x i32>* %1152, align 16
  %1154 = add <4 x i32> %1153, %1148
  %1155 = sub <4 x i32> %1148, %1153
  %1156 = icmp sgt <4 x i32> %1154, %971
  %1157 = select <4 x i1> %1156, <4 x i32> %1154, <4 x i32> %971
  %1158 = icmp slt <4 x i32> %1157, %974
  %1159 = select <4 x i1> %1158, <4 x i32> %1157, <4 x i32> %974
  %1160 = icmp sgt <4 x i32> %1155, %971
  %1161 = select <4 x i1> %1160, <4 x i32> %1155, <4 x i32> %971
  %1162 = icmp slt <4 x i32> %1161, %974
  %1163 = select <4 x i1> %1162, <4 x i32> %1161, <4 x i32> %974
  store <4 x i32> %1159, <4 x i32>* %1147, align 16
  store <4 x i32> %1163, <4 x i32>* %1152, align 16
  %1164 = and i64 %1145, 4294967280
  %1165 = or i64 %1164, 13
  %1166 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1165
  %1167 = bitcast <2 x i64>* %1166 to <4 x i32>*
  %1168 = load <4 x i32>, <4 x i32>* %1167, align 16
  %1169 = and i64 %1145, 4294967282
  %1170 = or i64 %1169, 8
  %1171 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1170
  %1172 = bitcast <2 x i64>* %1171 to <4 x i32>*
  %1173 = load <4 x i32>, <4 x i32>* %1172, align 16
  %1174 = add <4 x i32> %1173, %1168
  %1175 = sub <4 x i32> %1168, %1173
  %1176 = icmp sgt <4 x i32> %1174, %971
  %1177 = select <4 x i1> %1176, <4 x i32> %1174, <4 x i32> %971
  %1178 = icmp slt <4 x i32> %1177, %974
  %1179 = select <4 x i1> %1178, <4 x i32> %1177, <4 x i32> %974
  %1180 = icmp sgt <4 x i32> %1175, %971
  %1181 = select <4 x i1> %1180, <4 x i32> %1175, <4 x i32> %971
  %1182 = icmp slt <4 x i32> %1181, %974
  %1183 = select <4 x i1> %1182, <4 x i32> %1181, <4 x i32> %974
  store <4 x i32> %1179, <4 x i32>* %1167, align 16
  store <4 x i32> %1183, <4 x i32>* %1172, align 16
  %1184 = or i64 %1066, 3
  %1185 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1184
  %1186 = bitcast <2 x i64>* %1185 to <4 x i32>*
  %1187 = load <4 x i32>, <4 x i32>* %1186, align 16
  %1188 = and i64 %1066, 4294967280
  %1189 = or i64 %1188, 4
  %1190 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1189
  %1191 = bitcast <2 x i64>* %1190 to <4 x i32>*
  %1192 = load <4 x i32>, <4 x i32>* %1191, align 16
  %1193 = add <4 x i32> %1192, %1187
  %1194 = sub <4 x i32> %1187, %1192
  %1195 = icmp sgt <4 x i32> %1193, %971
  %1196 = select <4 x i1> %1195, <4 x i32> %1193, <4 x i32> %971
  %1197 = icmp slt <4 x i32> %1196, %974
  %1198 = select <4 x i1> %1197, <4 x i32> %1196, <4 x i32> %974
  %1199 = icmp sgt <4 x i32> %1194, %971
  %1200 = select <4 x i1> %1199, <4 x i32> %1194, <4 x i32> %971
  %1201 = icmp slt <4 x i32> %1200, %974
  %1202 = select <4 x i1> %1201, <4 x i32> %1200, <4 x i32> %974
  store <4 x i32> %1198, <4 x i32>* %1186, align 16
  store <4 x i32> %1202, <4 x i32>* %1191, align 16
  %1203 = and i64 %1066, 4294967280
  %1204 = or i64 %1203, 12
  %1205 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1204
  %1206 = bitcast <2 x i64>* %1205 to <4 x i32>*
  %1207 = load <4 x i32>, <4 x i32>* %1206, align 16
  %1208 = and i64 %1184, 4294967283
  %1209 = or i64 %1208, 8
  %1210 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1209
  %1211 = bitcast <2 x i64>* %1210 to <4 x i32>*
  %1212 = load <4 x i32>, <4 x i32>* %1211, align 16
  %1213 = add <4 x i32> %1212, %1207
  %1214 = sub <4 x i32> %1207, %1212
  %1215 = icmp sgt <4 x i32> %1213, %971
  %1216 = select <4 x i1> %1215, <4 x i32> %1213, <4 x i32> %971
  %1217 = icmp slt <4 x i32> %1216, %974
  %1218 = select <4 x i1> %1217, <4 x i32> %1216, <4 x i32> %974
  %1219 = icmp sgt <4 x i32> %1214, %971
  %1220 = select <4 x i1> %1219, <4 x i32> %1214, <4 x i32> %971
  %1221 = icmp slt <4 x i32> %1220, %974
  %1222 = select <4 x i1> %1221, <4 x i32> %1220, <4 x i32> %974
  store <4 x i32> %1218, <4 x i32>* %1206, align 16
  store <4 x i32> %1222, <4 x i32>* %1211, align 16
  %1223 = add nuw nsw i32 %1067, 16
  %1224 = icmp ult i32 %1223, 64
  %1225 = add nuw nsw i64 %1066, 16
  br i1 %1224, label %1065, label %1226

1226:                                             ; preds = %1065
  %1227 = bitcast [64 x <2 x i64>]* %12 to <4 x i32>*
  %1228 = load <4 x i32>, <4 x i32>* %1227, align 16
  %1229 = load <4 x i32>, <4 x i32>* %579, align 16
  %1230 = add <4 x i32> %1229, %1228
  %1231 = sub <4 x i32> %1228, %1229
  %1232 = icmp sgt <4 x i32> %1230, %971
  %1233 = select <4 x i1> %1232, <4 x i32> %1230, <4 x i32> %971
  %1234 = icmp slt <4 x i32> %1233, %974
  %1235 = select <4 x i1> %1234, <4 x i32> %1233, <4 x i32> %974
  %1236 = icmp sgt <4 x i32> %1231, %971
  %1237 = select <4 x i1> %1236, <4 x i32> %1231, <4 x i32> %971
  %1238 = icmp slt <4 x i32> %1237, %974
  %1239 = select <4 x i1> %1238, <4 x i32> %1237, <4 x i32> %974
  store <4 x i32> %1235, <4 x i32>* %1227, align 16
  store <4 x i32> %1239, <4 x i32>* %579, align 16
  %1240 = load <4 x i32>, <4 x i32>* %728, align 16
  %1241 = load <4 x i32>, <4 x i32>* %958, align 16
  %1242 = add <4 x i32> %1241, %1240
  %1243 = sub <4 x i32> %1240, %1241
  %1244 = icmp sgt <4 x i32> %1242, %971
  %1245 = select <4 x i1> %1244, <4 x i32> %1242, <4 x i32> %971
  %1246 = icmp slt <4 x i32> %1245, %974
  %1247 = select <4 x i1> %1246, <4 x i32> %1245, <4 x i32> %974
  %1248 = icmp sgt <4 x i32> %1243, %971
  %1249 = select <4 x i1> %1248, <4 x i32> %1243, <4 x i32> %971
  %1250 = icmp slt <4 x i32> %1249, %974
  %1251 = select <4 x i1> %1250, <4 x i32> %1249, <4 x i32> %974
  store <4 x i32> %1247, <4 x i32>* %728, align 16
  store <4 x i32> %1251, <4 x i32>* %958, align 16
  %1252 = bitcast <2 x i64>* %953 to <4 x i32>*
  %1253 = load <4 x i32>, <4 x i32>* %1252, align 16
  %1254 = load <4 x i32>, <4 x i32>* %955, align 16
  %1255 = add <4 x i32> %1254, %1253
  %1256 = sub <4 x i32> %1253, %1254
  %1257 = icmp sgt <4 x i32> %1255, %971
  %1258 = select <4 x i1> %1257, <4 x i32> %1255, <4 x i32> %971
  %1259 = icmp slt <4 x i32> %1258, %974
  %1260 = select <4 x i1> %1259, <4 x i32> %1258, <4 x i32> %974
  %1261 = icmp sgt <4 x i32> %1256, %971
  %1262 = select <4 x i1> %1261, <4 x i32> %1256, <4 x i32> %971
  %1263 = icmp slt <4 x i32> %1262, %974
  %1264 = select <4 x i1> %1263, <4 x i32> %1262, <4 x i32> %974
  store <4 x i32> %1260, <4 x i32>* %1252, align 16
  store <4 x i32> %1264, <4 x i32>* %955, align 16
  %1265 = bitcast <2 x i64>* %951 to <4 x i32>*
  %1266 = load <4 x i32>, <4 x i32>* %1265, align 16
  %1267 = load <4 x i32>, <4 x i32>* %573, align 16
  %1268 = add <4 x i32> %1267, %1266
  %1269 = sub <4 x i32> %1266, %1267
  %1270 = icmp sgt <4 x i32> %1268, %971
  %1271 = select <4 x i1> %1270, <4 x i32> %1268, <4 x i32> %971
  %1272 = icmp slt <4 x i32> %1271, %974
  %1273 = select <4 x i1> %1272, <4 x i32> %1271, <4 x i32> %974
  %1274 = icmp sgt <4 x i32> %1269, %971
  %1275 = select <4 x i1> %1274, <4 x i32> %1269, <4 x i32> %971
  %1276 = icmp slt <4 x i32> %1275, %974
  %1277 = select <4 x i1> %1276, <4 x i32> %1275, <4 x i32> %974
  store <4 x i32> %1273, <4 x i32>* %1265, align 16
  store <4 x i32> %1277, <4 x i32>* %573, align 16
  %1278 = load <4 x i32>, <4 x i32>* %586, align 16
  %1279 = mul <4 x i32> %1278, %954
  %1280 = load <4 x i32>, <4 x i32>* %588, align 16
  %1281 = mul <4 x i32> %1280, %721
  %1282 = add <4 x i32> %1281, %858
  %1283 = add <4 x i32> %1282, %1279
  %1284 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1283, i32 %2) #8
  %1285 = mul <4 x i32> %1278, %721
  %1286 = add <4 x i32> %1282, %1285
  %1287 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1286, i32 %2) #8
  store <4 x i32> %1287, <4 x i32>* %588, align 16
  store <4 x i32> %1284, <4 x i32>* %586, align 16
  %1288 = load <4 x i32>, <4 x i32>* %464, align 16
  %1289 = mul <4 x i32> %1288, %954
  %1290 = load <4 x i32>, <4 x i32>* %458, align 16
  %1291 = mul <4 x i32> %1290, %721
  %1292 = add <4 x i32> %1291, %858
  %1293 = add <4 x i32> %1292, %1289
  %1294 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1293, i32 %2) #8
  %1295 = mul <4 x i32> %1288, %721
  %1296 = add <4 x i32> %1292, %1295
  %1297 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1296, i32 %2) #8
  store <4 x i32> %1297, <4 x i32>* %458, align 16
  store <4 x i32> %1294, <4 x i32>* %464, align 16
  %1298 = load <4 x i32>, <4 x i32>* %376, align 16
  %1299 = load <4 x i32>, <4 x i32>* %412, align 16
  %1300 = add <4 x i32> %1299, %1298
  %1301 = sub <4 x i32> %1298, %1299
  %1302 = icmp sgt <4 x i32> %1300, %971
  %1303 = select <4 x i1> %1302, <4 x i32> %1300, <4 x i32> %971
  %1304 = icmp slt <4 x i32> %1303, %974
  %1305 = select <4 x i1> %1304, <4 x i32> %1303, <4 x i32> %974
  %1306 = icmp sgt <4 x i32> %1301, %971
  %1307 = select <4 x i1> %1306, <4 x i32> %1301, <4 x i32> %971
  %1308 = icmp slt <4 x i32> %1307, %974
  %1309 = select <4 x i1> %1308, <4 x i32> %1307, <4 x i32> %974
  store <4 x i32> %1305, <4 x i32>* %376, align 16
  store <4 x i32> %1309, <4 x i32>* %412, align 16
  %1310 = load <4 x i32>, <4 x i32>* %382, align 16
  %1311 = load <4 x i32>, <4 x i32>* %406, align 16
  %1312 = add <4 x i32> %1311, %1310
  %1313 = sub <4 x i32> %1310, %1311
  %1314 = icmp sgt <4 x i32> %1312, %971
  %1315 = select <4 x i1> %1314, <4 x i32> %1312, <4 x i32> %971
  %1316 = icmp slt <4 x i32> %1315, %974
  %1317 = select <4 x i1> %1316, <4 x i32> %1315, <4 x i32> %974
  %1318 = icmp sgt <4 x i32> %1313, %971
  %1319 = select <4 x i1> %1318, <4 x i32> %1313, <4 x i32> %971
  %1320 = icmp slt <4 x i32> %1319, %974
  %1321 = select <4 x i1> %1320, <4 x i32> %1319, <4 x i32> %974
  store <4 x i32> %1317, <4 x i32>* %382, align 16
  store <4 x i32> %1321, <4 x i32>* %406, align 16
  %1322 = load <4 x i32>, <4 x i32>* %469, align 16
  %1323 = load <4 x i32>, <4 x i32>* %475, align 16
  %1324 = add <4 x i32> %1323, %1322
  %1325 = sub <4 x i32> %1322, %1323
  %1326 = icmp sgt <4 x i32> %1324, %971
  %1327 = select <4 x i1> %1326, <4 x i32> %1324, <4 x i32> %971
  %1328 = icmp slt <4 x i32> %1327, %974
  %1329 = select <4 x i1> %1328, <4 x i32> %1327, <4 x i32> %974
  %1330 = icmp sgt <4 x i32> %1325, %971
  %1331 = select <4 x i1> %1330, <4 x i32> %1325, <4 x i32> %971
  %1332 = icmp slt <4 x i32> %1331, %974
  %1333 = select <4 x i1> %1332, <4 x i32> %1331, <4 x i32> %974
  store <4 x i32> %1329, <4 x i32>* %469, align 16
  store <4 x i32> %1333, <4 x i32>* %475, align 16
  %1334 = load <4 x i32>, <4 x i32>* %483, align 16
  %1335 = load <4 x i32>, <4 x i32>* %477, align 16
  %1336 = add <4 x i32> %1335, %1334
  %1337 = sub <4 x i32> %1334, %1335
  %1338 = icmp sgt <4 x i32> %1336, %971
  %1339 = select <4 x i1> %1338, <4 x i32> %1336, <4 x i32> %971
  %1340 = icmp slt <4 x i32> %1339, %974
  %1341 = select <4 x i1> %1340, <4 x i32> %1339, <4 x i32> %974
  %1342 = icmp sgt <4 x i32> %1337, %971
  %1343 = select <4 x i1> %1342, <4 x i32> %1337, <4 x i32> %971
  %1344 = icmp slt <4 x i32> %1343, %974
  %1345 = select <4 x i1> %1344, <4 x i32> %1343, <4 x i32> %974
  store <4 x i32> %1341, <4 x i32>* %483, align 16
  store <4 x i32> %1345, <4 x i32>* %477, align 16
  %1346 = load <4 x i32>, <4 x i32>* %471, align 16
  %1347 = load <4 x i32>, <4 x i32>* %473, align 16
  %1348 = add <4 x i32> %1347, %1346
  %1349 = sub <4 x i32> %1346, %1347
  %1350 = icmp sgt <4 x i32> %1348, %971
  %1351 = select <4 x i1> %1350, <4 x i32> %1348, <4 x i32> %971
  %1352 = icmp slt <4 x i32> %1351, %974
  %1353 = select <4 x i1> %1352, <4 x i32> %1351, <4 x i32> %974
  %1354 = icmp sgt <4 x i32> %1349, %971
  %1355 = select <4 x i1> %1354, <4 x i32> %1349, <4 x i32> %971
  %1356 = icmp slt <4 x i32> %1355, %974
  %1357 = select <4 x i1> %1356, <4 x i32> %1355, <4 x i32> %974
  store <4 x i32> %1353, <4 x i32>* %471, align 16
  store <4 x i32> %1357, <4 x i32>* %473, align 16
  %1358 = load <4 x i32>, <4 x i32>* %481, align 16
  %1359 = load <4 x i32>, <4 x i32>* %479, align 16
  %1360 = add <4 x i32> %1359, %1358
  %1361 = sub <4 x i32> %1358, %1359
  %1362 = icmp sgt <4 x i32> %1360, %971
  %1363 = select <4 x i1> %1362, <4 x i32> %1360, <4 x i32> %971
  %1364 = icmp slt <4 x i32> %1363, %974
  %1365 = select <4 x i1> %1364, <4 x i32> %1363, <4 x i32> %974
  %1366 = icmp sgt <4 x i32> %1361, %971
  %1367 = select <4 x i1> %1366, <4 x i32> %1361, <4 x i32> %971
  %1368 = icmp slt <4 x i32> %1367, %974
  %1369 = select <4 x i1> %1368, <4 x i32> %1367, <4 x i32> %974
  store <4 x i32> %1365, <4 x i32>* %481, align 16
  store <4 x i32> %1369, <4 x i32>* %479, align 16
  %1370 = load <4 x i32>, <4 x i32>* %392, align 16
  %1371 = load <4 x i32>, <4 x i32>* %396, align 16
  %1372 = add <4 x i32> %1371, %1370
  %1373 = sub <4 x i32> %1370, %1371
  %1374 = icmp sgt <4 x i32> %1372, %971
  %1375 = select <4 x i1> %1374, <4 x i32> %1372, <4 x i32> %971
  %1376 = icmp slt <4 x i32> %1375, %974
  %1377 = select <4 x i1> %1376, <4 x i32> %1375, <4 x i32> %974
  %1378 = icmp sgt <4 x i32> %1373, %971
  %1379 = select <4 x i1> %1378, <4 x i32> %1373, <4 x i32> %971
  %1380 = icmp slt <4 x i32> %1379, %974
  %1381 = select <4 x i1> %1380, <4 x i32> %1379, <4 x i32> %974
  store <4 x i32> %1377, <4 x i32>* %392, align 16
  store <4 x i32> %1381, <4 x i32>* %396, align 16
  %1382 = load <4 x i32>, <4 x i32>* %386, align 16
  %1383 = load <4 x i32>, <4 x i32>* %402, align 16
  %1384 = add <4 x i32> %1383, %1382
  %1385 = sub <4 x i32> %1382, %1383
  %1386 = icmp sgt <4 x i32> %1384, %971
  %1387 = select <4 x i1> %1386, <4 x i32> %1384, <4 x i32> %971
  %1388 = icmp slt <4 x i32> %1387, %974
  %1389 = select <4 x i1> %1388, <4 x i32> %1387, <4 x i32> %974
  %1390 = icmp sgt <4 x i32> %1385, %971
  %1391 = select <4 x i1> %1390, <4 x i32> %1385, <4 x i32> %971
  %1392 = icmp slt <4 x i32> %1391, %974
  %1393 = select <4 x i1> %1392, <4 x i32> %1391, <4 x i32> %974
  store <4 x i32> %1389, <4 x i32>* %386, align 16
  store <4 x i32> %1393, <4 x i32>* %402, align 16
  %1394 = load <4 x i32>, <4 x i32>* %318, align 16
  %1395 = mul <4 x i32> %1394, %719
  %1396 = load <4 x i32>, <4 x i32>* %323, align 16
  %1397 = mul <4 x i32> %1396, %718
  %1398 = add <4 x i32> %1395, %858
  %1399 = add <4 x i32> %1398, %1397
  %1400 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1399, i32 %2) #8
  %1401 = load <4 x i32>, <4 x i32>* %421, align 16
  %1402 = mul <4 x i32> %1401, %719
  %1403 = load <4 x i32>, <4 x i32>* %443, align 16
  %1404 = mul <4 x i32> %1403, %718
  %1405 = add <4 x i32> %1402, %858
  %1406 = add <4 x i32> %1405, %1404
  %1407 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1406, i32 %2) #8
  %1408 = load <4 x i32>, <4 x i32>* %423, align 16
  %1409 = mul <4 x i32> %1408, %719
  %1410 = load <4 x i32>, <4 x i32>* %441, align 16
  %1411 = mul <4 x i32> %1410, %718
  %1412 = add <4 x i32> %1409, %858
  %1413 = add <4 x i32> %1412, %1411
  %1414 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1413, i32 %2) #8
  %1415 = load <4 x i32>, <4 x i32>* %332, align 16
  %1416 = mul <4 x i32> %1415, %719
  %1417 = load <4 x i32>, <4 x i32>* %327, align 16
  %1418 = mul <4 x i32> %1417, %718
  %1419 = add <4 x i32> %1416, %858
  %1420 = add <4 x i32> %1419, %1418
  %1421 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1420, i32 %2) #8
  %1422 = mul <4 x i32> %1415, %718
  %1423 = mul <4 x i32> %1417, %717
  %1424 = add <4 x i32> %1422, %858
  %1425 = add <4 x i32> %1424, %1423
  %1426 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1425, i32 %2) #8
  store <4 x i32> %1426, <4 x i32>* %327, align 16
  %1427 = mul <4 x i32> %1408, %718
  %1428 = mul <4 x i32> %1410, %717
  %1429 = add <4 x i32> %1427, %858
  %1430 = add <4 x i32> %1429, %1428
  %1431 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1430, i32 %2) #8
  store <4 x i32> %1431, <4 x i32>* %441, align 16
  %1432 = mul <4 x i32> %1401, %718
  %1433 = mul <4 x i32> %1403, %717
  %1434 = add <4 x i32> %1432, %858
  %1435 = add <4 x i32> %1434, %1433
  %1436 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1435, i32 %2) #8
  store <4 x i32> %1436, <4 x i32>* %443, align 16
  %1437 = mul <4 x i32> %1394, %718
  %1438 = mul <4 x i32> %1396, %717
  %1439 = add <4 x i32> %1437, %858
  %1440 = add <4 x i32> %1439, %1438
  %1441 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1440, i32 %2) #8
  store <4 x i32> %1441, <4 x i32>* %323, align 16
  store <4 x i32> %1400, <4 x i32>* %318, align 16
  store <4 x i32> %1407, <4 x i32>* %421, align 16
  store <4 x i32> %1414, <4 x i32>* %423, align 16
  store <4 x i32> %1421, <4 x i32>* %332, align 16
  %1442 = load <4 x i32>, <4 x i32>* %336, align 16
  %1443 = mul <4 x i32> %1442, %720
  %1444 = load <4 x i32>, <4 x i32>* %342, align 16
  %1445 = mul <4 x i32> %1444, %719
  %1446 = add <4 x i32> %1443, %858
  %1447 = add <4 x i32> %1446, %1445
  %1448 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1447, i32 %2) #8
  %1449 = load <4 x i32>, <4 x i32>* %425, align 16
  %1450 = mul <4 x i32> %1449, %720
  %1451 = load <4 x i32>, <4 x i32>* %439, align 16
  %1452 = mul <4 x i32> %1451, %719
  %1453 = add <4 x i32> %1450, %858
  %1454 = add <4 x i32> %1453, %1452
  %1455 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1454, i32 %2) #8
  %1456 = load <4 x i32>, <4 x i32>* %427, align 16
  %1457 = mul <4 x i32> %1456, %720
  %1458 = load <4 x i32>, <4 x i32>* %437, align 16
  %1459 = mul <4 x i32> %1458, %719
  %1460 = add <4 x i32> %1457, %858
  %1461 = add <4 x i32> %1460, %1459
  %1462 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1461, i32 %2) #8
  %1463 = load <4 x i32>, <4 x i32>* %352, align 16
  %1464 = mul <4 x i32> %1463, %720
  %1465 = load <4 x i32>, <4 x i32>* %346, align 16
  %1466 = mul <4 x i32> %1465, %719
  %1467 = add <4 x i32> %1464, %858
  %1468 = add <4 x i32> %1467, %1466
  %1469 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1468, i32 %2) #8
  %1470 = mul <4 x i32> %1463, %719
  %1471 = mul <4 x i32> %1465, %718
  %1472 = add <4 x i32> %1470, %858
  %1473 = add <4 x i32> %1472, %1471
  %1474 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1473, i32 %2) #8
  store <4 x i32> %1474, <4 x i32>* %346, align 16
  %1475 = mul <4 x i32> %1456, %719
  %1476 = mul <4 x i32> %1458, %718
  %1477 = add <4 x i32> %1475, %858
  %1478 = add <4 x i32> %1477, %1476
  %1479 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1478, i32 %2) #8
  store <4 x i32> %1479, <4 x i32>* %437, align 16
  %1480 = mul <4 x i32> %1449, %719
  %1481 = mul <4 x i32> %1451, %718
  %1482 = add <4 x i32> %1480, %858
  %1483 = add <4 x i32> %1482, %1481
  %1484 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1483, i32 %2) #8
  store <4 x i32> %1484, <4 x i32>* %439, align 16
  %1485 = mul <4 x i32> %1442, %719
  %1486 = mul <4 x i32> %1444, %718
  %1487 = add <4 x i32> %1485, %858
  %1488 = add <4 x i32> %1487, %1486
  %1489 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1488, i32 %2) #8
  store <4 x i32> %1489, <4 x i32>* %342, align 16
  store <4 x i32> %1448, <4 x i32>* %336, align 16
  store <4 x i32> %1455, <4 x i32>* %425, align 16
  store <4 x i32> %1462, <4 x i32>* %427, align 16
  store <4 x i32> %1469, <4 x i32>* %352, align 16
  call fastcc void @idct64_stage9_sse4_1(<2 x i64>* nonnull %249, <2 x i64>* nonnull %11, <2 x i64>* nonnull %10, <2 x i64>* nonnull %8, <2 x i64>* nonnull %9, <2 x i64>* nonnull %7, i32 %2)
  br label %1490

1490:                                             ; preds = %1490, %1226
  %1491 = phi i64 [ 0, %1226 ], [ %1509, %1490 ]
  %1492 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1491
  %1493 = bitcast <2 x i64>* %1492 to <4 x i32>*
  %1494 = load <4 x i32>, <4 x i32>* %1493, align 16
  %1495 = sub nuw nsw i64 31, %1491
  %1496 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1495
  %1497 = bitcast <2 x i64>* %1496 to <4 x i32>*
  %1498 = load <4 x i32>, <4 x i32>* %1497, align 16
  %1499 = add <4 x i32> %1498, %1494
  %1500 = sub <4 x i32> %1494, %1498
  %1501 = icmp sgt <4 x i32> %1499, %971
  %1502 = select <4 x i1> %1501, <4 x i32> %1499, <4 x i32> %971
  %1503 = icmp slt <4 x i32> %1502, %974
  %1504 = select <4 x i1> %1503, <4 x i32> %1502, <4 x i32> %974
  %1505 = icmp sgt <4 x i32> %1500, %971
  %1506 = select <4 x i1> %1505, <4 x i32> %1500, <4 x i32> %971
  %1507 = icmp slt <4 x i32> %1506, %974
  %1508 = select <4 x i1> %1507, <4 x i32> %1506, <4 x i32> %974
  store <4 x i32> %1504, <4 x i32>* %1493, align 16
  store <4 x i32> %1508, <4 x i32>* %1497, align 16
  %1509 = add nuw nsw i64 %1491, 1
  %1510 = icmp eq i64 %1509, 16
  br i1 %1510, label %1511, label %1490

1511:                                             ; preds = %1490
  %1512 = load <4 x i32>, <4 x i32>* %336, align 16
  %1513 = mul <4 x i32> %1512, %954
  %1514 = load <4 x i32>, <4 x i32>* %342, align 16
  %1515 = mul <4 x i32> %1514, %721
  %1516 = add <4 x i32> %1513, %858
  %1517 = add <4 x i32> %1516, %1515
  %1518 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1517, i32 %2) #8
  %1519 = load <4 x i32>, <4 x i32>* %425, align 16
  %1520 = mul <4 x i32> %1519, %954
  %1521 = load <4 x i32>, <4 x i32>* %439, align 16
  %1522 = mul <4 x i32> %1521, %721
  %1523 = add <4 x i32> %1520, %858
  %1524 = add <4 x i32> %1523, %1522
  %1525 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1524, i32 %2) #8
  %1526 = load <4 x i32>, <4 x i32>* %427, align 16
  %1527 = mul <4 x i32> %1526, %954
  %1528 = load <4 x i32>, <4 x i32>* %437, align 16
  %1529 = mul <4 x i32> %1528, %721
  %1530 = add <4 x i32> %1527, %858
  %1531 = add <4 x i32> %1530, %1529
  %1532 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1531, i32 %2) #8
  %1533 = load <4 x i32>, <4 x i32>* %352, align 16
  %1534 = mul <4 x i32> %1533, %954
  %1535 = load <4 x i32>, <4 x i32>* %346, align 16
  %1536 = mul <4 x i32> %1535, %721
  %1537 = add <4 x i32> %1536, %858
  %1538 = add <4 x i32> %1537, %1534
  %1539 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1538, i32 %2) #8
  %1540 = mul <4 x i32> %1533, %721
  %1541 = add <4 x i32> %1537, %1540
  %1542 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1541, i32 %2) #8
  store <4 x i32> %1542, <4 x i32>* %346, align 16
  %1543 = load <4 x i32>, <4 x i32>* %118, align 16
  %1544 = add <4 x i32> %1528, %1526
  %1545 = mul <4 x i32> %1543, %1544
  %1546 = add <4 x i32> %1545, %858
  %1547 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1546, i32 %2) #8
  store <4 x i32> %1547, <4 x i32>* %437, align 16
  %1548 = add <4 x i32> %1521, %1519
  %1549 = mul <4 x i32> %1543, %1548
  %1550 = add <4 x i32> %1549, %858
  %1551 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1550, i32 %2) #8
  store <4 x i32> %1551, <4 x i32>* %439, align 16
  %1552 = add <4 x i32> %1514, %1512
  %1553 = mul <4 x i32> %1543, %1552
  %1554 = add <4 x i32> %1553, %858
  %1555 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1554, i32 %2) #8
  store <4 x i32> %1555, <4 x i32>* %342, align 16
  store <4 x i32> %1518, <4 x i32>* %336, align 16
  store <4 x i32> %1525, <4 x i32>* %425, align 16
  store <4 x i32> %1532, <4 x i32>* %427, align 16
  store <4 x i32> %1539, <4 x i32>* %352, align 16
  %1556 = load <4 x i32>, <4 x i32>* %366, align 16
  %1557 = mul <4 x i32> %1556, %954
  %1558 = load <4 x i32>, <4 x i32>* %372, align 16
  %1559 = mul <4 x i32> %1558, %1543
  %1560 = add <4 x i32> %1557, %858
  %1561 = add <4 x i32> %1560, %1559
  %1562 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1561, i32 %2) #8
  %1563 = load <4 x i32>, <4 x i32>* %429, align 16
  %1564 = mul <4 x i32> %1563, %954
  %1565 = load <4 x i32>, <4 x i32>* %435, align 16
  %1566 = mul <4 x i32> %1565, %1543
  %1567 = add <4 x i32> %1564, %858
  %1568 = add <4 x i32> %1567, %1566
  %1569 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1568, i32 %2) #8
  %1570 = load <4 x i32>, <4 x i32>* %431, align 16
  %1571 = mul <4 x i32> %1570, %954
  %1572 = load <4 x i32>, <4 x i32>* %433, align 16
  %1573 = mul <4 x i32> %1572, %1543
  %1574 = add <4 x i32> %1571, %858
  %1575 = add <4 x i32> %1574, %1573
  %1576 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1575, i32 %2) #8
  %1577 = load <4 x i32>, <4 x i32>* %362, align 16
  %1578 = mul <4 x i32> %1577, %954
  %1579 = load <4 x i32>, <4 x i32>* %356, align 16
  %1580 = mul <4 x i32> %1579, %1543
  %1581 = add <4 x i32> %1580, %858
  %1582 = add <4 x i32> %1581, %1578
  %1583 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1582, i32 %2) #8
  %1584 = mul <4 x i32> %1577, %1543
  %1585 = add <4 x i32> %1581, %1584
  %1586 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1585, i32 %2) #8
  store <4 x i32> %1586, <4 x i32>* %356, align 16
  %1587 = add <4 x i32> %1572, %1570
  %1588 = mul <4 x i32> %1587, %1543
  %1589 = add <4 x i32> %1588, %858
  %1590 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1589, i32 %2) #8
  store <4 x i32> %1590, <4 x i32>* %433, align 16
  %1591 = add <4 x i32> %1565, %1563
  %1592 = mul <4 x i32> %1591, %1543
  %1593 = add <4 x i32> %1592, %858
  %1594 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1593, i32 %2) #8
  store <4 x i32> %1594, <4 x i32>* %435, align 16
  %1595 = add <4 x i32> %1558, %1556
  %1596 = mul <4 x i32> %1595, %1543
  %1597 = add <4 x i32> %1596, %858
  %1598 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1597, i32 %2) #8
  store <4 x i32> %1598, <4 x i32>* %372, align 16
  store <4 x i32> %1562, <4 x i32>* %366, align 16
  store <4 x i32> %1569, <4 x i32>* %429, align 16
  store <4 x i32> %1576, <4 x i32>* %431, align 16
  store <4 x i32> %1583, <4 x i32>* %362, align 16
  %1599 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 63
  br label %1601

1600:                                             ; preds = %1601
  br i1 %21, label %1627, label %1701

1601:                                             ; preds = %1601, %1511
  %1602 = phi i64 [ 0, %1511 ], [ %1625, %1601 ]
  %1603 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1602
  %1604 = bitcast <2 x i64>* %1603 to <4 x i32>*
  %1605 = load <4 x i32>, <4 x i32>* %1604, align 16
  %1606 = sub nuw nsw i64 63, %1602
  %1607 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %12, i64 0, i64 %1606
  %1608 = bitcast <2 x i64>* %1607 to <4 x i32>*
  %1609 = load <4 x i32>, <4 x i32>* %1608, align 16
  %1610 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %1602
  %1611 = sub nsw i64 0, %1602
  %1612 = getelementptr inbounds <2 x i64>, <2 x i64>* %1599, i64 %1611
  %1613 = add <4 x i32> %1609, %1605
  %1614 = sub <4 x i32> %1605, %1609
  %1615 = icmp sgt <4 x i32> %1613, %971
  %1616 = select <4 x i1> %1615, <4 x i32> %1613, <4 x i32> %971
  %1617 = icmp slt <4 x i32> %1616, %974
  %1618 = select <4 x i1> %1617, <4 x i32> %1616, <4 x i32> %974
  %1619 = icmp sgt <4 x i32> %1614, %971
  %1620 = select <4 x i1> %1619, <4 x i32> %1614, <4 x i32> %971
  %1621 = icmp slt <4 x i32> %1620, %974
  %1622 = select <4 x i1> %1621, <4 x i32> %1620, <4 x i32> %974
  %1623 = bitcast <2 x i64>* %1610 to <4 x i32>*
  store <4 x i32> %1618, <4 x i32>* %1623, align 16
  %1624 = bitcast <2 x i64>* %1612 to <4 x i32>*
  store <4 x i32> %1622, <4 x i32>* %1624, align 16
  %1625 = add nuw nsw i64 %1602, 1
  %1626 = icmp eq i64 %1625, 32
  br i1 %1626, label %1600, label %1601

1627:                                             ; preds = %1600
  %1628 = icmp sgt i32 %4, 10
  %1629 = select i1 %1628, i32 %4, i32 10
  %1630 = shl i32 32, %1629
  %1631 = sub nsw i32 0, %1630
  %1632 = insertelement <4 x i32> undef, i32 %1631, i32 0
  %1633 = shufflevector <4 x i32> %1632, <4 x i32> undef, <4 x i32> zeroinitializer
  %1634 = add nsw i32 %1630, -1
  %1635 = insertelement <4 x i32> undef, i32 %1634, i32 0
  %1636 = shufflevector <4 x i32> %1635, <4 x i32> undef, <4 x i32> zeroinitializer
  %1637 = icmp eq i32 %5, 0
  %1638 = add nsw i32 %5, -1
  %1639 = shl i32 1, %1638
  %1640 = insertelement <4 x i32> undef, i32 %1639, i32 0
  %1641 = shufflevector <4 x i32> %1640, <4 x i32> undef, <4 x i32> zeroinitializer
  br label %1642

1642:                                             ; preds = %1675, %1627
  %1643 = phi i64 [ 0, %1627 ], [ %1699, %1675 ]
  %1644 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %1643
  %1645 = bitcast <2 x i64>* %1644 to <4 x i32>*
  %1646 = load <4 x i32>, <4 x i32>* %1645, align 16
  br i1 %1637, label %1647, label %1657

1647:                                             ; preds = %1642
  %1648 = getelementptr inbounds <2 x i64>, <2 x i64>* %1644, i64 1
  %1649 = bitcast <2 x i64>* %1648 to <4 x i32>*
  %1650 = load <4 x i32>, <4 x i32>* %1649, align 16
  %1651 = getelementptr inbounds <2 x i64>, <2 x i64>* %1644, i64 2
  %1652 = bitcast <2 x i64>* %1651 to <4 x i32>*
  %1653 = load <4 x i32>, <4 x i32>* %1652, align 16
  %1654 = getelementptr inbounds <2 x i64>, <2 x i64>* %1644, i64 3
  %1655 = bitcast <2 x i64>* %1654 to <4 x i32>*
  %1656 = load <4 x i32>, <4 x i32>* %1655, align 16
  br label %1675

1657:                                             ; preds = %1642
  %1658 = add <4 x i32> %1646, %1641
  %1659 = getelementptr inbounds <2 x i64>, <2 x i64>* %1644, i64 1
  %1660 = bitcast <2 x i64>* %1659 to <4 x i32>*
  %1661 = load <4 x i32>, <4 x i32>* %1660, align 16
  %1662 = add <4 x i32> %1661, %1641
  %1663 = getelementptr inbounds <2 x i64>, <2 x i64>* %1644, i64 2
  %1664 = bitcast <2 x i64>* %1663 to <4 x i32>*
  %1665 = load <4 x i32>, <4 x i32>* %1664, align 16
  %1666 = add <4 x i32> %1665, %1641
  %1667 = getelementptr inbounds <2 x i64>, <2 x i64>* %1644, i64 3
  %1668 = bitcast <2 x i64>* %1667 to <4 x i32>*
  %1669 = load <4 x i32>, <4 x i32>* %1668, align 16
  %1670 = add <4 x i32> %1669, %1641
  %1671 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1658, i32 %5) #8
  store <4 x i32> %1671, <4 x i32>* %1645, align 16
  %1672 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1662, i32 %5) #8
  store <4 x i32> %1672, <4 x i32>* %1660, align 16
  %1673 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1666, i32 %5) #8
  store <4 x i32> %1673, <4 x i32>* %1664, align 16
  %1674 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1670, i32 %5) #8
  store <4 x i32> %1674, <4 x i32>* %1668, align 16
  br label %1675

1675:                                             ; preds = %1657, %1647
  %1676 = phi <4 x i32>* [ %1655, %1647 ], [ %1668, %1657 ]
  %1677 = phi <4 x i32>* [ %1652, %1647 ], [ %1664, %1657 ]
  %1678 = phi <4 x i32>* [ %1649, %1647 ], [ %1660, %1657 ]
  %1679 = phi <4 x i32> [ %1656, %1647 ], [ %1674, %1657 ]
  %1680 = phi <4 x i32> [ %1653, %1647 ], [ %1673, %1657 ]
  %1681 = phi <4 x i32> [ %1650, %1647 ], [ %1672, %1657 ]
  %1682 = phi <4 x i32> [ %1646, %1647 ], [ %1671, %1657 ]
  %1683 = icmp sgt <4 x i32> %1682, %1633
  %1684 = select <4 x i1> %1683, <4 x i32> %1682, <4 x i32> %1633
  %1685 = icmp slt <4 x i32> %1684, %1636
  %1686 = select <4 x i1> %1685, <4 x i32> %1684, <4 x i32> %1636
  store <4 x i32> %1686, <4 x i32>* %1645, align 16
  %1687 = icmp sgt <4 x i32> %1681, %1633
  %1688 = select <4 x i1> %1687, <4 x i32> %1681, <4 x i32> %1633
  %1689 = icmp slt <4 x i32> %1688, %1636
  %1690 = select <4 x i1> %1689, <4 x i32> %1688, <4 x i32> %1636
  store <4 x i32> %1690, <4 x i32>* %1678, align 16
  %1691 = icmp sgt <4 x i32> %1680, %1633
  %1692 = select <4 x i1> %1691, <4 x i32> %1680, <4 x i32> %1633
  %1693 = icmp slt <4 x i32> %1692, %1636
  %1694 = select <4 x i1> %1693, <4 x i32> %1692, <4 x i32> %1636
  store <4 x i32> %1694, <4 x i32>* %1677, align 16
  %1695 = icmp sgt <4 x i32> %1679, %1633
  %1696 = select <4 x i1> %1695, <4 x i32> %1679, <4 x i32> %1633
  %1697 = icmp slt <4 x i32> %1696, %1636
  %1698 = select <4 x i1> %1697, <4 x i32> %1696, <4 x i32> %1636
  store <4 x i32> %1698, <4 x i32>* %1676, align 16
  %1699 = add nuw nsw i64 %1643, 4
  %1700 = icmp ult i64 %1699, 64
  br i1 %1700, label %1642, label %1701

1701:                                             ; preds = %1675, %1600
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %245) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %190) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %113) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %33) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %26) #8
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %15) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @idct64x64_sse4_1(<2 x i64>* readonly, <2 x i64>* nocapture, i32, i32, i32, i32) #0 {
  %7 = alloca [64 x <2 x i64>], align 16
  %8 = alloca [64 x <2 x i64>], align 16
  %9 = add nsw i32 %2, -10
  %10 = sext i32 %9 to i64
  %11 = add nsw i32 %2, -1
  %12 = shl i32 1, %11
  %13 = insertelement <4 x i32> undef, i32 %12, i32 0
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> zeroinitializer
  %15 = icmp ne i32 %3, 0
  %16 = select i1 %15, i32 6, i32 8
  %17 = add nsw i32 %16, %4
  %18 = icmp sgt i32 %17, 16
  %19 = select i1 %18, i32 %17, i32 16
  %20 = add nsw i32 %19, -1
  %21 = shl i32 1, %20
  %22 = sub nsw i32 0, %21
  %23 = insertelement <4 x i32> undef, i32 %22, i32 0
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> zeroinitializer
  %25 = add nsw i32 %21, -1
  %26 = insertelement <4 x i32> undef, i32 %25, i32 0
  %27 = shufflevector <4 x i32> %26, <4 x i32> undef, <4 x i32> zeroinitializer
  %28 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 1
  %29 = load i32, i32* %28, align 4
  %30 = insertelement <4 x i32> undef, i32 %29, i32 0
  %31 = shufflevector <4 x i32> %30, <4 x i32> undef, <4 x i32> zeroinitializer
  %32 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 2
  %33 = load i32, i32* %32, align 8
  %34 = insertelement <4 x i32> undef, i32 %33, i32 0
  %35 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> zeroinitializer
  %36 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 3
  %37 = load i32, i32* %36, align 4
  %38 = insertelement <4 x i32> undef, i32 %37, i32 0
  %39 = shufflevector <4 x i32> %38, <4 x i32> undef, <4 x i32> zeroinitializer
  %40 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 4
  %41 = load i32, i32* %40, align 16
  %42 = insertelement <4 x i32> undef, i32 %41, i32 0
  %43 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 5
  %44 = load i32, i32* %43, align 4
  %45 = insertelement <4 x i32> undef, i32 %44, i32 0
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 6
  %48 = load i32, i32* %47, align 8
  %49 = insertelement <4 x i32> undef, i32 %48, i32 0
  %50 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> zeroinitializer
  %51 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 7
  %52 = load i32, i32* %51, align 4
  %53 = insertelement <4 x i32> undef, i32 %52, i32 0
  %54 = shufflevector <4 x i32> %53, <4 x i32> undef, <4 x i32> zeroinitializer
  %55 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 8
  %56 = load i32, i32* %55, align 16
  %57 = insertelement <4 x i32> undef, i32 %56, i32 0
  %58 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 9
  %59 = load i32, i32* %58, align 4
  %60 = insertelement <4 x i32> undef, i32 %59, i32 0
  %61 = shufflevector <4 x i32> %60, <4 x i32> undef, <4 x i32> zeroinitializer
  %62 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 10
  %63 = load i32, i32* %62, align 8
  %64 = insertelement <4 x i32> undef, i32 %63, i32 0
  %65 = shufflevector <4 x i32> %64, <4 x i32> undef, <4 x i32> zeroinitializer
  %66 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 11
  %67 = load i32, i32* %66, align 4
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 12
  %71 = load i32, i32* %70, align 16
  %72 = insertelement <4 x i32> undef, i32 %71, i32 0
  %73 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 13
  %74 = load i32, i32* %73, align 4
  %75 = insertelement <4 x i32> undef, i32 %74, i32 0
  %76 = shufflevector <4 x i32> %75, <4 x i32> undef, <4 x i32> zeroinitializer
  %77 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 14
  %78 = load i32, i32* %77, align 8
  %79 = insertelement <4 x i32> undef, i32 %78, i32 0
  %80 = shufflevector <4 x i32> %79, <4 x i32> undef, <4 x i32> zeroinitializer
  %81 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 15
  %82 = load i32, i32* %81, align 4
  %83 = insertelement <4 x i32> undef, i32 %82, i32 0
  %84 = shufflevector <4 x i32> %83, <4 x i32> undef, <4 x i32> zeroinitializer
  %85 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 16
  %86 = load i32, i32* %85, align 16
  %87 = insertelement <4 x i32> undef, i32 %86, i32 0
  %88 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 17
  %89 = load i32, i32* %88, align 4
  %90 = insertelement <4 x i32> undef, i32 %89, i32 0
  %91 = shufflevector <4 x i32> %90, <4 x i32> undef, <4 x i32> zeroinitializer
  %92 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 18
  %93 = load i32, i32* %92, align 8
  %94 = insertelement <4 x i32> undef, i32 %93, i32 0
  %95 = shufflevector <4 x i32> %94, <4 x i32> undef, <4 x i32> zeroinitializer
  %96 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 19
  %97 = load i32, i32* %96, align 4
  %98 = insertelement <4 x i32> undef, i32 %97, i32 0
  %99 = shufflevector <4 x i32> %98, <4 x i32> undef, <4 x i32> zeroinitializer
  %100 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 20
  %101 = load i32, i32* %100, align 16
  %102 = insertelement <4 x i32> undef, i32 %101, i32 0
  %103 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 21
  %104 = load i32, i32* %103, align 4
  %105 = insertelement <4 x i32> undef, i32 %104, i32 0
  %106 = shufflevector <4 x i32> %105, <4 x i32> undef, <4 x i32> zeroinitializer
  %107 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 22
  %108 = load i32, i32* %107, align 8
  %109 = insertelement <4 x i32> undef, i32 %108, i32 0
  %110 = shufflevector <4 x i32> %109, <4 x i32> undef, <4 x i32> zeroinitializer
  %111 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 23
  %112 = load i32, i32* %111, align 4
  %113 = insertelement <4 x i32> undef, i32 %112, i32 0
  %114 = shufflevector <4 x i32> %113, <4 x i32> undef, <4 x i32> zeroinitializer
  %115 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 24
  %116 = load i32, i32* %115, align 16
  %117 = insertelement <4 x i32> undef, i32 %116, i32 0
  %118 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 25
  %119 = load i32, i32* %118, align 4
  %120 = insertelement <4 x i32> undef, i32 %119, i32 0
  %121 = shufflevector <4 x i32> %120, <4 x i32> undef, <4 x i32> zeroinitializer
  %122 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 26
  %123 = load i32, i32* %122, align 8
  %124 = insertelement <4 x i32> undef, i32 %123, i32 0
  %125 = shufflevector <4 x i32> %124, <4 x i32> undef, <4 x i32> zeroinitializer
  %126 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 27
  %127 = load i32, i32* %126, align 4
  %128 = insertelement <4 x i32> undef, i32 %127, i32 0
  %129 = shufflevector <4 x i32> %128, <4 x i32> undef, <4 x i32> zeroinitializer
  %130 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 28
  %131 = load i32, i32* %130, align 16
  %132 = insertelement <4 x i32> undef, i32 %131, i32 0
  %133 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 29
  %134 = load i32, i32* %133, align 4
  %135 = insertelement <4 x i32> undef, i32 %134, i32 0
  %136 = shufflevector <4 x i32> %135, <4 x i32> undef, <4 x i32> zeroinitializer
  %137 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 30
  %138 = load i32, i32* %137, align 8
  %139 = insertelement <4 x i32> undef, i32 %138, i32 0
  %140 = shufflevector <4 x i32> %139, <4 x i32> undef, <4 x i32> zeroinitializer
  %141 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 31
  %142 = load i32, i32* %141, align 4
  %143 = insertelement <4 x i32> undef, i32 %142, i32 0
  %144 = shufflevector <4 x i32> %143, <4 x i32> undef, <4 x i32> zeroinitializer
  %145 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 32
  %146 = load i32, i32* %145, align 16
  %147 = insertelement <4 x i32> undef, i32 %146, i32 0
  %148 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 35
  %149 = load i32, i32* %148, align 4
  %150 = insertelement <4 x i32> undef, i32 %149, i32 0
  %151 = shufflevector <4 x i32> %150, <4 x i32> undef, <4 x i32> zeroinitializer
  %152 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 36
  %153 = load i32, i32* %152, align 16
  %154 = insertelement <4 x i32> undef, i32 %153, i32 0
  %155 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 38
  %156 = load i32, i32* %155, align 8
  %157 = insertelement <4 x i32> undef, i32 %156, i32 0
  %158 = shufflevector <4 x i32> %157, <4 x i32> undef, <4 x i32> zeroinitializer
  %159 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 39
  %160 = load i32, i32* %159, align 4
  %161 = insertelement <4 x i32> undef, i32 %160, i32 0
  %162 = shufflevector <4 x i32> %161, <4 x i32> undef, <4 x i32> zeroinitializer
  %163 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 40
  %164 = load i32, i32* %163, align 16
  %165 = insertelement <4 x i32> undef, i32 %164, i32 0
  %166 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 43
  %167 = load i32, i32* %166, align 4
  %168 = insertelement <4 x i32> undef, i32 %167, i32 0
  %169 = shufflevector <4 x i32> %168, <4 x i32> undef, <4 x i32> zeroinitializer
  %170 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 44
  %171 = load i32, i32* %170, align 16
  %172 = insertelement <4 x i32> undef, i32 %171, i32 0
  %173 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 46
  %174 = load i32, i32* %173, align 8
  %175 = insertelement <4 x i32> undef, i32 %174, i32 0
  %176 = shufflevector <4 x i32> %175, <4 x i32> undef, <4 x i32> zeroinitializer
  %177 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 47
  %178 = load i32, i32* %177, align 4
  %179 = insertelement <4 x i32> undef, i32 %178, i32 0
  %180 = shufflevector <4 x i32> %179, <4 x i32> undef, <4 x i32> zeroinitializer
  %181 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 48
  %182 = load i32, i32* %181, align 16
  %183 = insertelement <4 x i32> undef, i32 %182, i32 0
  %184 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 51
  %185 = load i32, i32* %184, align 4
  %186 = insertelement <4 x i32> undef, i32 %185, i32 0
  %187 = shufflevector <4 x i32> %186, <4 x i32> undef, <4 x i32> zeroinitializer
  %188 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 52
  %189 = load i32, i32* %188, align 16
  %190 = insertelement <4 x i32> undef, i32 %189, i32 0
  %191 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 54
  %192 = load i32, i32* %191, align 8
  %193 = insertelement <4 x i32> undef, i32 %192, i32 0
  %194 = shufflevector <4 x i32> %193, <4 x i32> undef, <4 x i32> zeroinitializer
  %195 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 55
  %196 = load i32, i32* %195, align 4
  %197 = insertelement <4 x i32> undef, i32 %196, i32 0
  %198 = shufflevector <4 x i32> %197, <4 x i32> undef, <4 x i32> zeroinitializer
  %199 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 56
  %200 = load i32, i32* %199, align 16
  %201 = insertelement <4 x i32> undef, i32 %200, i32 0
  %202 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 59
  %203 = load i32, i32* %202, align 4
  %204 = insertelement <4 x i32> undef, i32 %203, i32 0
  %205 = shufflevector <4 x i32> %204, <4 x i32> undef, <4 x i32> zeroinitializer
  %206 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 60
  %207 = load i32, i32* %206, align 16
  %208 = insertelement <4 x i32> undef, i32 %207, i32 0
  %209 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 62
  %210 = load i32, i32* %209, align 8
  %211 = insertelement <4 x i32> undef, i32 %210, i32 0
  %212 = shufflevector <4 x i32> %211, <4 x i32> undef, <4 x i32> zeroinitializer
  %213 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 63
  %214 = load i32, i32* %213, align 4
  %215 = insertelement <4 x i32> undef, i32 %214, i32 0
  %216 = shufflevector <4 x i32> %215, <4 x i32> undef, <4 x i32> zeroinitializer
  %217 = sub nsw i32 0, %41
  %218 = insertelement <4 x i32> undef, i32 %217, i32 0
  %219 = sub nsw i32 0, %56
  %220 = insertelement <4 x i32> undef, i32 %219, i32 0
  %221 = sub nsw i32 0, %71
  %222 = insertelement <4 x i32> undef, i32 %221, i32 0
  %223 = sub nsw i32 0, %86
  %224 = insertelement <4 x i32> undef, i32 %223, i32 0
  %225 = sub nsw i32 0, %101
  %226 = insertelement <4 x i32> undef, i32 %225, i32 0
  %227 = sub nsw i32 0, %116
  %228 = insertelement <4 x i32> undef, i32 %227, i32 0
  %229 = sub nsw i32 0, %131
  %230 = insertelement <4 x i32> undef, i32 %229, i32 0
  %231 = sub nsw i32 0, %146
  %232 = insertelement <4 x i32> undef, i32 %231, i32 0
  %233 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 33
  %234 = load i32, i32* %233, align 4
  %235 = sub nsw i32 0, %234
  %236 = insertelement <4 x i32> undef, i32 %235, i32 0
  %237 = shufflevector <4 x i32> %236, <4 x i32> undef, <4 x i32> zeroinitializer
  %238 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 34
  %239 = load i32, i32* %238, align 8
  %240 = sub nsw i32 0, %239
  %241 = insertelement <4 x i32> undef, i32 %240, i32 0
  %242 = shufflevector <4 x i32> %241, <4 x i32> undef, <4 x i32> zeroinitializer
  %243 = sub nsw i32 0, %153
  %244 = insertelement <4 x i32> undef, i32 %243, i32 0
  %245 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 37
  %246 = load i32, i32* %245, align 4
  %247 = sub nsw i32 0, %246
  %248 = insertelement <4 x i32> undef, i32 %247, i32 0
  %249 = shufflevector <4 x i32> %248, <4 x i32> undef, <4 x i32> zeroinitializer
  %250 = sub nsw i32 0, %164
  %251 = insertelement <4 x i32> undef, i32 %250, i32 0
  %252 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 41
  %253 = load i32, i32* %252, align 4
  %254 = sub nsw i32 0, %253
  %255 = insertelement <4 x i32> undef, i32 %254, i32 0
  %256 = shufflevector <4 x i32> %255, <4 x i32> undef, <4 x i32> zeroinitializer
  %257 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 42
  %258 = load i32, i32* %257, align 8
  %259 = sub nsw i32 0, %258
  %260 = insertelement <4 x i32> undef, i32 %259, i32 0
  %261 = shufflevector <4 x i32> %260, <4 x i32> undef, <4 x i32> zeroinitializer
  %262 = sub nsw i32 0, %171
  %263 = insertelement <4 x i32> undef, i32 %262, i32 0
  %264 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 45
  %265 = load i32, i32* %264, align 4
  %266 = sub nsw i32 0, %265
  %267 = insertelement <4 x i32> undef, i32 %266, i32 0
  %268 = shufflevector <4 x i32> %267, <4 x i32> undef, <4 x i32> zeroinitializer
  %269 = sub nsw i32 0, %182
  %270 = insertelement <4 x i32> undef, i32 %269, i32 0
  %271 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 49
  %272 = load i32, i32* %271, align 4
  %273 = sub nsw i32 0, %272
  %274 = insertelement <4 x i32> undef, i32 %273, i32 0
  %275 = shufflevector <4 x i32> %274, <4 x i32> undef, <4 x i32> zeroinitializer
  %276 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 50
  %277 = load i32, i32* %276, align 8
  %278 = sub nsw i32 0, %277
  %279 = insertelement <4 x i32> undef, i32 %278, i32 0
  %280 = shufflevector <4 x i32> %279, <4 x i32> undef, <4 x i32> zeroinitializer
  %281 = sub nsw i32 0, %189
  %282 = insertelement <4 x i32> undef, i32 %281, i32 0
  %283 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 53
  %284 = load i32, i32* %283, align 4
  %285 = sub nsw i32 0, %284
  %286 = insertelement <4 x i32> undef, i32 %285, i32 0
  %287 = shufflevector <4 x i32> %286, <4 x i32> undef, <4 x i32> zeroinitializer
  %288 = sub nsw i32 0, %200
  %289 = insertelement <4 x i32> undef, i32 %288, i32 0
  %290 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 57
  %291 = load i32, i32* %290, align 4
  %292 = sub nsw i32 0, %291
  %293 = insertelement <4 x i32> undef, i32 %292, i32 0
  %294 = shufflevector <4 x i32> %293, <4 x i32> undef, <4 x i32> zeroinitializer
  %295 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 58
  %296 = load i32, i32* %295, align 8
  %297 = sub nsw i32 0, %296
  %298 = insertelement <4 x i32> undef, i32 %297, i32 0
  %299 = shufflevector <4 x i32> %298, <4 x i32> undef, <4 x i32> zeroinitializer
  %300 = sub nsw i32 0, %207
  %301 = insertelement <4 x i32> undef, i32 %300, i32 0
  %302 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %10, i64 61
  %303 = load i32, i32* %302, align 4
  %304 = sub nsw i32 0, %303
  %305 = insertelement <4 x i32> undef, i32 %304, i32 0
  %306 = shufflevector <4 x i32> %305, <4 x i32> undef, <4 x i32> zeroinitializer
  %307 = bitcast [64 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %307) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %307, i8 -86, i64 1024, i1 false)
  %308 = bitcast [64 x <2 x i64>]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %308) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %308, i8 -86, i64 1024, i1 false)
  %309 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %310 = load <2 x i64>, <2 x i64>* %309, align 16
  %311 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 32
  store <2 x i64> %310, <2 x i64>* %311, align 16
  %312 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 17
  %313 = load <2 x i64>, <2 x i64>* %312, align 16
  %314 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 34
  store <2 x i64> %313, <2 x i64>* %314, align 16
  %315 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %316 = load <2 x i64>, <2 x i64>* %315, align 16
  %317 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 36
  store <2 x i64> %316, <2 x i64>* %317, align 16
  %318 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 25
  %319 = load <2 x i64>, <2 x i64>* %318, align 16
  %320 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 38
  store <2 x i64> %319, <2 x i64>* %320, align 16
  %321 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %322 = load <2 x i64>, <2 x i64>* %321, align 16
  %323 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 40
  store <2 x i64> %322, <2 x i64>* %323, align 16
  %324 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 21
  %325 = load <2 x i64>, <2 x i64>* %324, align 16
  %326 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 42
  store <2 x i64> %325, <2 x i64>* %326, align 16
  %327 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %328 = load <2 x i64>, <2 x i64>* %327, align 16
  %329 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 44
  store <2 x i64> %328, <2 x i64>* %329, align 16
  %330 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 29
  %331 = load <2 x i64>, <2 x i64>* %330, align 16
  %332 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 46
  store <2 x i64> %331, <2 x i64>* %332, align 16
  %333 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %334 = load <2 x i64>, <2 x i64>* %333, align 16
  %335 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 48
  store <2 x i64> %334, <2 x i64>* %335, align 16
  %336 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 19
  %337 = load <2 x i64>, <2 x i64>* %336, align 16
  %338 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 50
  store <2 x i64> %337, <2 x i64>* %338, align 16
  %339 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %340 = load <2 x i64>, <2 x i64>* %339, align 16
  %341 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 52
  store <2 x i64> %340, <2 x i64>* %341, align 16
  %342 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 27
  %343 = load <2 x i64>, <2 x i64>* %342, align 16
  %344 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 54
  store <2 x i64> %343, <2 x i64>* %344, align 16
  %345 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %346 = load <2 x i64>, <2 x i64>* %345, align 16
  %347 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 56
  store <2 x i64> %346, <2 x i64>* %347, align 16
  %348 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 23
  %349 = load <2 x i64>, <2 x i64>* %348, align 16
  %350 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 58
  store <2 x i64> %349, <2 x i64>* %350, align 16
  %351 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %352 = load <2 x i64>, <2 x i64>* %351, align 16
  %353 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 60
  store <2 x i64> %352, <2 x i64>* %353, align 16
  %354 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 31
  %355 = load <2 x i64>, <2 x i64>* %354, align 16
  %356 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 62
  store <2 x i64> %355, <2 x i64>* %356, align 16
  %357 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %358 = load <2 x i64>, <2 x i64>* %357, align 16
  %359 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 16
  store <2 x i64> %358, <2 x i64>* %359, align 16
  %360 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 18
  %361 = load <2 x i64>, <2 x i64>* %360, align 16
  %362 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 18
  store <2 x i64> %361, <2 x i64>* %362, align 16
  %363 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %364 = load <2 x i64>, <2 x i64>* %363, align 16
  %365 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 20
  store <2 x i64> %364, <2 x i64>* %365, align 16
  %366 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 26
  %367 = load <2 x i64>, <2 x i64>* %366, align 16
  %368 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 22
  store <2 x i64> %367, <2 x i64>* %368, align 16
  %369 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %370 = load <2 x i64>, <2 x i64>* %369, align 16
  %371 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 24
  store <2 x i64> %370, <2 x i64>* %371, align 16
  %372 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 22
  %373 = load <2 x i64>, <2 x i64>* %372, align 16
  %374 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 26
  store <2 x i64> %373, <2 x i64>* %374, align 16
  %375 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %376 = load <2 x i64>, <2 x i64>* %375, align 16
  %377 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 28
  store <2 x i64> %376, <2 x i64>* %377, align 16
  %378 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 30
  %379 = load <2 x i64>, <2 x i64>* %378, align 16
  %380 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 30
  store <2 x i64> %379, <2 x i64>* %380, align 16
  %381 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %382 = load <2 x i64>, <2 x i64>* %381, align 16
  %383 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 8
  store <2 x i64> %382, <2 x i64>* %383, align 16
  %384 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 20
  %385 = load <2 x i64>, <2 x i64>* %384, align 16
  %386 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 10
  store <2 x i64> %385, <2 x i64>* %386, align 16
  %387 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %388 = load <2 x i64>, <2 x i64>* %387, align 16
  %389 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 12
  store <2 x i64> %388, <2 x i64>* %389, align 16
  %390 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 28
  %391 = load <2 x i64>, <2 x i64>* %390, align 16
  %392 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 14
  store <2 x i64> %391, <2 x i64>* %392, align 16
  %393 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %394 = load <2 x i64>, <2 x i64>* %393, align 16
  %395 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 4
  store <2 x i64> %394, <2 x i64>* %395, align 16
  %396 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 24
  %397 = load <2 x i64>, <2 x i64>* %396, align 16
  %398 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 6
  store <2 x i64> %397, <2 x i64>* %398, align 16
  %399 = load <2 x i64>, <2 x i64>* %0, align 16
  %400 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 0
  store <2 x i64> %399, <2 x i64>* %400, align 16
  %401 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 16
  %402 = load <2 x i64>, <2 x i64>* %401, align 16
  %403 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %402, <2 x i64>* %403, align 16
  %404 = bitcast <2 x i64>* %311 to <4 x i32>*
  %405 = load <4 x i32>, <4 x i32>* %404, align 16
  %406 = mul <4 x i32> %405, %216
  %407 = add <4 x i32> %406, %14
  %408 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %407, i32 %2) #8
  %409 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 32
  %410 = bitcast <2 x i64>* %409 to <4 x i32>*
  store <4 x i32> %408, <4 x i32>* %410, align 16
  %411 = bitcast <2 x i64>* %356 to <4 x i32>*
  %412 = bitcast <2 x i64> %355 to <4 x i32>
  %413 = mul <4 x i32> %237, %412
  %414 = add <4 x i32> %413, %14
  %415 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %414, i32 %2) #8
  %416 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 33
  %417 = bitcast <2 x i64>* %416 to <4 x i32>*
  store <4 x i32> %415, <4 x i32>* %417, align 16
  %418 = bitcast <2 x i64>* %314 to <4 x i32>*
  %419 = load <4 x i32>, <4 x i32>* %418, align 16
  %420 = mul <4 x i32> %419, %180
  %421 = add <4 x i32> %420, %14
  %422 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %421, i32 %2) #8
  %423 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 34
  %424 = bitcast <2 x i64>* %423 to <4 x i32>*
  store <4 x i32> %422, <4 x i32>* %424, align 16
  %425 = bitcast <2 x i64>* %353 to <4 x i32>*
  %426 = bitcast <2 x i64> %352 to <4 x i32>
  %427 = mul <4 x i32> %275, %426
  %428 = add <4 x i32> %427, %14
  %429 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %428, i32 %2) #8
  %430 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 35
  %431 = bitcast <2 x i64>* %430 to <4 x i32>*
  store <4 x i32> %429, <4 x i32>* %431, align 16
  %432 = bitcast <2 x i64>* %317 to <4 x i32>*
  %433 = load <4 x i32>, <4 x i32>* %432, align 16
  %434 = mul <4 x i32> %433, %198
  %435 = add <4 x i32> %434, %14
  %436 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %435, i32 %2) #8
  %437 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 36
  %438 = bitcast <2 x i64>* %437 to <4 x i32>*
  store <4 x i32> %436, <4 x i32>* %438, align 16
  %439 = bitcast <2 x i64>* %350 to <4 x i32>*
  %440 = load <4 x i32>, <4 x i32>* %439, align 16
  %441 = mul <4 x i32> %440, %256
  %442 = add <4 x i32> %441, %14
  %443 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %442, i32 %2) #8
  %444 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 37
  %445 = bitcast <2 x i64>* %444 to <4 x i32>*
  store <4 x i32> %443, <4 x i32>* %445, align 16
  %446 = bitcast <2 x i64>* %320 to <4 x i32>*
  %447 = load <4 x i32>, <4 x i32>* %446, align 16
  %448 = mul <4 x i32> %447, %162
  %449 = add <4 x i32> %448, %14
  %450 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %449, i32 %2) #8
  %451 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 38
  %452 = bitcast <2 x i64>* %451 to <4 x i32>*
  store <4 x i32> %450, <4 x i32>* %452, align 16
  %453 = bitcast <2 x i64>* %347 to <4 x i32>*
  %454 = load <4 x i32>, <4 x i32>* %453, align 16
  %455 = mul <4 x i32> %454, %294
  %456 = add <4 x i32> %455, %14
  %457 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %456, i32 %2) #8
  %458 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 39
  %459 = bitcast <2 x i64>* %458 to <4 x i32>*
  store <4 x i32> %457, <4 x i32>* %459, align 16
  %460 = bitcast <2 x i64>* %323 to <4 x i32>*
  %461 = load <4 x i32>, <4 x i32>* %460, align 16
  %462 = mul <4 x i32> %461, %205
  %463 = add <4 x i32> %462, %14
  %464 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %463, i32 %2) #8
  %465 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 40
  %466 = bitcast <2 x i64>* %465 to <4 x i32>*
  store <4 x i32> %464, <4 x i32>* %466, align 16
  %467 = bitcast <2 x i64>* %344 to <4 x i32>*
  %468 = load <4 x i32>, <4 x i32>* %467, align 16
  %469 = mul <4 x i32> %468, %249
  %470 = add <4 x i32> %469, %14
  %471 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %470, i32 %2) #8
  %472 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 41
  %473 = bitcast <2 x i64>* %472 to <4 x i32>*
  store <4 x i32> %471, <4 x i32>* %473, align 16
  %474 = bitcast <2 x i64>* %326 to <4 x i32>*
  %475 = load <4 x i32>, <4 x i32>* %474, align 16
  %476 = mul <4 x i32> %475, %169
  %477 = add <4 x i32> %476, %14
  %478 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %477, i32 %2) #8
  %479 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 42
  %480 = bitcast <2 x i64>* %479 to <4 x i32>*
  store <4 x i32> %478, <4 x i32>* %480, align 16
  %481 = bitcast <2 x i64>* %341 to <4 x i32>*
  %482 = load <4 x i32>, <4 x i32>* %481, align 16
  %483 = mul <4 x i32> %482, %287
  %484 = add <4 x i32> %483, %14
  %485 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %484, i32 %2) #8
  %486 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 43
  %487 = bitcast <2 x i64>* %486 to <4 x i32>*
  store <4 x i32> %485, <4 x i32>* %487, align 16
  %488 = bitcast <2 x i64>* %329 to <4 x i32>*
  %489 = load <4 x i32>, <4 x i32>* %488, align 16
  %490 = mul <4 x i32> %489, %187
  %491 = add <4 x i32> %490, %14
  %492 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %491, i32 %2) #8
  %493 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 44
  %494 = bitcast <2 x i64>* %493 to <4 x i32>*
  store <4 x i32> %492, <4 x i32>* %494, align 16
  %495 = bitcast <2 x i64>* %338 to <4 x i32>*
  %496 = load <4 x i32>, <4 x i32>* %495, align 16
  %497 = mul <4 x i32> %496, %268
  %498 = add <4 x i32> %497, %14
  %499 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %498, i32 %2) #8
  %500 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 45
  %501 = bitcast <2 x i64>* %500 to <4 x i32>*
  store <4 x i32> %499, <4 x i32>* %501, align 16
  %502 = bitcast <2 x i64>* %332 to <4 x i32>*
  %503 = load <4 x i32>, <4 x i32>* %502, align 16
  %504 = mul <4 x i32> %503, %151
  %505 = add <4 x i32> %504, %14
  %506 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %505, i32 %2) #8
  %507 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 46
  %508 = bitcast <2 x i64>* %507 to <4 x i32>*
  store <4 x i32> %506, <4 x i32>* %508, align 16
  %509 = bitcast <2 x i64>* %335 to <4 x i32>*
  %510 = load <4 x i32>, <4 x i32>* %509, align 16
  %511 = mul <4 x i32> %510, %306
  %512 = add <4 x i32> %511, %14
  %513 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %512, i32 %2) #8
  %514 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 47
  %515 = bitcast <2 x i64>* %514 to <4 x i32>*
  store <4 x i32> %513, <4 x i32>* %515, align 16
  %516 = mul <4 x i32> %510, %39
  %517 = add <4 x i32> %516, %14
  %518 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %517, i32 %2) #8
  %519 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 48
  %520 = bitcast <2 x i64>* %519 to <4 x i32>*
  store <4 x i32> %518, <4 x i32>* %520, align 16
  %521 = mul <4 x i32> %503, %136
  %522 = add <4 x i32> %521, %14
  %523 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %522, i32 %2) #8
  %524 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 49
  %525 = bitcast <2 x i64>* %524 to <4 x i32>*
  store <4 x i32> %523, <4 x i32>* %525, align 16
  %526 = mul <4 x i32> %496, %99
  %527 = add <4 x i32> %526, %14
  %528 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %527, i32 %2) #8
  %529 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 50
  %530 = bitcast <2 x i64>* %529 to <4 x i32>*
  store <4 x i32> %528, <4 x i32>* %530, align 16
  %531 = mul <4 x i32> %489, %76
  %532 = add <4 x i32> %531, %14
  %533 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %532, i32 %2) #8
  %534 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 51
  %535 = bitcast <2 x i64>* %534 to <4 x i32>*
  store <4 x i32> %533, <4 x i32>* %535, align 16
  %536 = mul <4 x i32> %482, %69
  %537 = add <4 x i32> %536, %14
  %538 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %537, i32 %2) #8
  %539 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 52
  %540 = bitcast <2 x i64>* %539 to <4 x i32>*
  store <4 x i32> %538, <4 x i32>* %540, align 16
  %541 = mul <4 x i32> %475, %106
  %542 = add <4 x i32> %541, %14
  %543 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %542, i32 %2) #8
  %544 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 53
  %545 = bitcast <2 x i64>* %544 to <4 x i32>*
  store <4 x i32> %543, <4 x i32>* %545, align 16
  %546 = mul <4 x i32> %468, %129
  %547 = add <4 x i32> %546, %14
  %548 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %547, i32 %2) #8
  %549 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 54
  %550 = bitcast <2 x i64>* %549 to <4 x i32>*
  store <4 x i32> %548, <4 x i32>* %550, align 16
  %551 = mul <4 x i32> %461, %46
  %552 = add <4 x i32> %551, %14
  %553 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %552, i32 %2) #8
  %554 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 55
  %555 = bitcast <2 x i64>* %554 to <4 x i32>*
  store <4 x i32> %553, <4 x i32>* %555, align 16
  %556 = mul <4 x i32> %454, %54
  %557 = add <4 x i32> %556, %14
  %558 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %557, i32 %2) #8
  %559 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 56
  %560 = bitcast <2 x i64>* %559 to <4 x i32>*
  store <4 x i32> %558, <4 x i32>* %560, align 16
  %561 = mul <4 x i32> %447, %121
  %562 = add <4 x i32> %561, %14
  %563 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %562, i32 %2) #8
  %564 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 57
  %565 = bitcast <2 x i64>* %564 to <4 x i32>*
  store <4 x i32> %563, <4 x i32>* %565, align 16
  %566 = mul <4 x i32> %440, %114
  %567 = add <4 x i32> %566, %14
  %568 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %567, i32 %2) #8
  %569 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 58
  %570 = bitcast <2 x i64>* %569 to <4 x i32>*
  store <4 x i32> %568, <4 x i32>* %570, align 16
  %571 = mul <4 x i32> %433, %61
  %572 = add <4 x i32> %571, %14
  %573 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %572, i32 %2) #8
  %574 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 59
  %575 = bitcast <2 x i64>* %574 to <4 x i32>*
  store <4 x i32> %573, <4 x i32>* %575, align 16
  %576 = mul <4 x i32> %84, %426
  %577 = add <4 x i32> %576, %14
  %578 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %577, i32 %2) #8
  %579 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 60
  %580 = bitcast <2 x i64>* %579 to <4 x i32>*
  store <4 x i32> %578, <4 x i32>* %580, align 16
  %581 = mul <4 x i32> %419, %91
  %582 = add <4 x i32> %581, %14
  %583 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %582, i32 %2) #8
  %584 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 61
  %585 = bitcast <2 x i64>* %584 to <4 x i32>*
  store <4 x i32> %583, <4 x i32>* %585, align 16
  %586 = mul <4 x i32> %144, %412
  %587 = add <4 x i32> %586, %14
  %588 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %587, i32 %2) #8
  %589 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 62
  %590 = bitcast <2 x i64>* %589 to <4 x i32>*
  store <4 x i32> %588, <4 x i32>* %590, align 16
  %591 = mul <4 x i32> %405, %31
  %592 = add <4 x i32> %591, %14
  %593 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %592, i32 %2) #8
  %594 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 63
  %595 = bitcast <2 x i64>* %594 to <4 x i32>*
  store <4 x i32> %593, <4 x i32>* %595, align 16
  %596 = bitcast <2 x i64>* %359 to <4 x i32>*
  %597 = load <4 x i32>, <4 x i32>* %596, align 16
  %598 = mul <4 x i32> %597, %212
  %599 = add <4 x i32> %598, %14
  %600 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %599, i32 %2) #8
  %601 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 16
  %602 = bitcast <2 x i64>* %601 to <4 x i32>*
  store <4 x i32> %600, <4 x i32>* %602, align 16
  %603 = bitcast <2 x i64>* %380 to <4 x i32>*
  %604 = load <4 x i32>, <4 x i32>* %603, align 16
  %605 = mul <4 x i32> %604, %242
  %606 = add <4 x i32> %605, %14
  %607 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %606, i32 %2) #8
  %608 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 17
  %609 = bitcast <2 x i64>* %608 to <4 x i32>*
  store <4 x i32> %607, <4 x i32>* %609, align 16
  %610 = bitcast <2 x i64>* %362 to <4 x i32>*
  %611 = load <4 x i32>, <4 x i32>* %610, align 16
  %612 = mul <4 x i32> %611, %176
  %613 = add <4 x i32> %612, %14
  %614 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %613, i32 %2) #8
  %615 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 18
  %616 = bitcast <2 x i64>* %615 to <4 x i32>*
  store <4 x i32> %614, <4 x i32>* %616, align 16
  %617 = bitcast <2 x i64>* %377 to <4 x i32>*
  %618 = load <4 x i32>, <4 x i32>* %617, align 16
  %619 = mul <4 x i32> %618, %280
  %620 = add <4 x i32> %619, %14
  %621 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %620, i32 %2) #8
  %622 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 19
  %623 = bitcast <2 x i64>* %622 to <4 x i32>*
  store <4 x i32> %621, <4 x i32>* %623, align 16
  %624 = bitcast <2 x i64>* %365 to <4 x i32>*
  %625 = load <4 x i32>, <4 x i32>* %624, align 16
  %626 = mul <4 x i32> %625, %194
  %627 = add <4 x i32> %626, %14
  %628 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %627, i32 %2) #8
  %629 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 20
  %630 = bitcast <2 x i64>* %629 to <4 x i32>*
  store <4 x i32> %628, <4 x i32>* %630, align 16
  %631 = bitcast <2 x i64>* %374 to <4 x i32>*
  %632 = load <4 x i32>, <4 x i32>* %631, align 16
  %633 = mul <4 x i32> %632, %261
  %634 = add <4 x i32> %633, %14
  %635 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %634, i32 %2) #8
  %636 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 21
  %637 = bitcast <2 x i64>* %636 to <4 x i32>*
  store <4 x i32> %635, <4 x i32>* %637, align 16
  %638 = bitcast <2 x i64>* %368 to <4 x i32>*
  %639 = load <4 x i32>, <4 x i32>* %638, align 16
  %640 = mul <4 x i32> %639, %158
  %641 = add <4 x i32> %640, %14
  %642 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %641, i32 %2) #8
  %643 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 22
  %644 = bitcast <2 x i64>* %643 to <4 x i32>*
  store <4 x i32> %642, <4 x i32>* %644, align 16
  %645 = bitcast <2 x i64>* %371 to <4 x i32>*
  %646 = load <4 x i32>, <4 x i32>* %645, align 16
  %647 = mul <4 x i32> %646, %299
  %648 = add <4 x i32> %647, %14
  %649 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %648, i32 %2) #8
  %650 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 23
  %651 = bitcast <2 x i64>* %650 to <4 x i32>*
  store <4 x i32> %649, <4 x i32>* %651, align 16
  %652 = mul <4 x i32> %646, %50
  %653 = add <4 x i32> %652, %14
  %654 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %653, i32 %2) #8
  %655 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 24
  %656 = bitcast <2 x i64>* %655 to <4 x i32>*
  store <4 x i32> %654, <4 x i32>* %656, align 16
  %657 = mul <4 x i32> %639, %125
  %658 = add <4 x i32> %657, %14
  %659 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %658, i32 %2) #8
  %660 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 25
  %661 = bitcast <2 x i64>* %660 to <4 x i32>*
  store <4 x i32> %659, <4 x i32>* %661, align 16
  %662 = mul <4 x i32> %632, %110
  %663 = add <4 x i32> %662, %14
  %664 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %663, i32 %2) #8
  %665 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 26
  %666 = bitcast <2 x i64>* %665 to <4 x i32>*
  store <4 x i32> %664, <4 x i32>* %666, align 16
  %667 = mul <4 x i32> %625, %65
  %668 = add <4 x i32> %667, %14
  %669 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %668, i32 %2) #8
  %670 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 27
  %671 = bitcast <2 x i64>* %670 to <4 x i32>*
  store <4 x i32> %669, <4 x i32>* %671, align 16
  %672 = mul <4 x i32> %618, %80
  %673 = add <4 x i32> %672, %14
  %674 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %673, i32 %2) #8
  %675 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 28
  %676 = bitcast <2 x i64>* %675 to <4 x i32>*
  store <4 x i32> %674, <4 x i32>* %676, align 16
  %677 = mul <4 x i32> %611, %95
  %678 = add <4 x i32> %677, %14
  %679 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %678, i32 %2) #8
  %680 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 29
  %681 = bitcast <2 x i64>* %680 to <4 x i32>*
  store <4 x i32> %679, <4 x i32>* %681, align 16
  %682 = mul <4 x i32> %604, %140
  %683 = add <4 x i32> %682, %14
  %684 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %683, i32 %2) #8
  %685 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 30
  %686 = bitcast <2 x i64>* %685 to <4 x i32>*
  store <4 x i32> %684, <4 x i32>* %686, align 16
  %687 = mul <4 x i32> %597, %35
  %688 = add <4 x i32> %687, %14
  %689 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %688, i32 %2) #8
  %690 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 31
  %691 = bitcast <2 x i64>* %690 to <4 x i32>*
  store <4 x i32> %689, <4 x i32>* %691, align 16
  br label %692

692:                                              ; preds = %6, %692
  %693 = phi i64 [ 32, %6 ], [ %737, %692 ]
  %694 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %693
  %695 = bitcast <2 x i64>* %694 to <4 x i32>*
  %696 = load <4 x i32>, <4 x i32>* %695, align 16
  %697 = or i64 %693, 1
  %698 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %697
  %699 = bitcast <2 x i64>* %698 to <4 x i32>*
  %700 = load <4 x i32>, <4 x i32>* %699, align 16
  %701 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %693
  %702 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %697
  %703 = add <4 x i32> %700, %696
  %704 = sub <4 x i32> %696, %700
  %705 = icmp sgt <4 x i32> %703, %24
  %706 = select <4 x i1> %705, <4 x i32> %703, <4 x i32> %24
  %707 = icmp slt <4 x i32> %706, %27
  %708 = select <4 x i1> %707, <4 x i32> %706, <4 x i32> %27
  %709 = icmp sgt <4 x i32> %704, %24
  %710 = select <4 x i1> %709, <4 x i32> %704, <4 x i32> %24
  %711 = icmp slt <4 x i32> %710, %27
  %712 = select <4 x i1> %711, <4 x i32> %710, <4 x i32> %27
  %713 = bitcast <2 x i64>* %701 to <4 x i32>*
  store <4 x i32> %708, <4 x i32>* %713, align 16
  %714 = bitcast <2 x i64>* %702 to <4 x i32>*
  store <4 x i32> %712, <4 x i32>* %714, align 16
  %715 = or i64 %693, 3
  %716 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %715
  %717 = bitcast <2 x i64>* %716 to <4 x i32>*
  %718 = load <4 x i32>, <4 x i32>* %717, align 16
  %719 = or i64 %693, 2
  %720 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %719
  %721 = bitcast <2 x i64>* %720 to <4 x i32>*
  %722 = load <4 x i32>, <4 x i32>* %721, align 16
  %723 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %715
  %724 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %719
  %725 = add <4 x i32> %722, %718
  %726 = sub <4 x i32> %718, %722
  %727 = icmp sgt <4 x i32> %725, %24
  %728 = select <4 x i1> %727, <4 x i32> %725, <4 x i32> %24
  %729 = icmp slt <4 x i32> %728, %27
  %730 = select <4 x i1> %729, <4 x i32> %728, <4 x i32> %27
  %731 = icmp sgt <4 x i32> %726, %24
  %732 = select <4 x i1> %731, <4 x i32> %726, <4 x i32> %24
  %733 = icmp slt <4 x i32> %732, %27
  %734 = select <4 x i1> %733, <4 x i32> %732, <4 x i32> %27
  %735 = bitcast <2 x i64>* %723 to <4 x i32>*
  store <4 x i32> %730, <4 x i32>* %735, align 16
  %736 = bitcast <2 x i64>* %724 to <4 x i32>*
  store <4 x i32> %734, <4 x i32>* %736, align 16
  %737 = add nuw nsw i64 %693, 4
  %738 = icmp ult i64 %737, 64
  br i1 %738, label %692, label %739

739:                                              ; preds = %692
  %740 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> zeroinitializer
  %741 = shufflevector <4 x i32> %57, <4 x i32> undef, <4 x i32> zeroinitializer
  %742 = shufflevector <4 x i32> %72, <4 x i32> undef, <4 x i32> zeroinitializer
  %743 = shufflevector <4 x i32> %87, <4 x i32> undef, <4 x i32> zeroinitializer
  %744 = shufflevector <4 x i32> %102, <4 x i32> undef, <4 x i32> zeroinitializer
  %745 = shufflevector <4 x i32> %117, <4 x i32> undef, <4 x i32> zeroinitializer
  %746 = shufflevector <4 x i32> %132, <4 x i32> undef, <4 x i32> zeroinitializer
  %747 = shufflevector <4 x i32> %147, <4 x i32> undef, <4 x i32> zeroinitializer
  %748 = shufflevector <4 x i32> %154, <4 x i32> undef, <4 x i32> zeroinitializer
  %749 = shufflevector <4 x i32> %165, <4 x i32> undef, <4 x i32> zeroinitializer
  %750 = shufflevector <4 x i32> %172, <4 x i32> undef, <4 x i32> zeroinitializer
  %751 = shufflevector <4 x i32> %183, <4 x i32> undef, <4 x i32> zeroinitializer
  %752 = shufflevector <4 x i32> %190, <4 x i32> undef, <4 x i32> zeroinitializer
  %753 = shufflevector <4 x i32> %201, <4 x i32> undef, <4 x i32> zeroinitializer
  %754 = shufflevector <4 x i32> %208, <4 x i32> undef, <4 x i32> zeroinitializer
  %755 = shufflevector <4 x i32> %218, <4 x i32> undef, <4 x i32> zeroinitializer
  %756 = shufflevector <4 x i32> %220, <4 x i32> undef, <4 x i32> zeroinitializer
  %757 = shufflevector <4 x i32> %222, <4 x i32> undef, <4 x i32> zeroinitializer
  %758 = shufflevector <4 x i32> %224, <4 x i32> undef, <4 x i32> zeroinitializer
  %759 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> zeroinitializer
  %760 = shufflevector <4 x i32> %228, <4 x i32> undef, <4 x i32> zeroinitializer
  %761 = shufflevector <4 x i32> %230, <4 x i32> undef, <4 x i32> zeroinitializer
  %762 = shufflevector <4 x i32> %232, <4 x i32> undef, <4 x i32> zeroinitializer
  %763 = shufflevector <4 x i32> %244, <4 x i32> undef, <4 x i32> zeroinitializer
  %764 = shufflevector <4 x i32> %251, <4 x i32> undef, <4 x i32> zeroinitializer
  %765 = shufflevector <4 x i32> %263, <4 x i32> undef, <4 x i32> zeroinitializer
  %766 = shufflevector <4 x i32> %270, <4 x i32> undef, <4 x i32> zeroinitializer
  %767 = shufflevector <4 x i32> %282, <4 x i32> undef, <4 x i32> zeroinitializer
  %768 = shufflevector <4 x i32> %289, <4 x i32> undef, <4 x i32> zeroinitializer
  %769 = shufflevector <4 x i32> %301, <4 x i32> undef, <4 x i32> zeroinitializer
  %770 = bitcast <2 x i64>* %383 to <4 x i32>*
  %771 = load <4 x i32>, <4 x i32>* %770, align 16
  %772 = mul <4 x i32> %771, %754
  %773 = add <4 x i32> %772, %14
  %774 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %773, i32 %2) #8
  %775 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 8
  %776 = bitcast <2 x i64>* %775 to <4 x i32>*
  store <4 x i32> %774, <4 x i32>* %776, align 16
  %777 = bitcast <2 x i64>* %392 to <4 x i32>*
  %778 = load <4 x i32>, <4 x i32>* %777, align 16
  %779 = mul <4 x i32> %778, %763
  %780 = add <4 x i32> %779, %14
  %781 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %780, i32 %2) #8
  %782 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 9
  %783 = bitcast <2 x i64>* %782 to <4 x i32>*
  store <4 x i32> %781, <4 x i32>* %783, align 16
  %784 = bitcast <2 x i64>* %386 to <4 x i32>*
  %785 = load <4 x i32>, <4 x i32>* %784, align 16
  %786 = mul <4 x i32> %785, %750
  %787 = add <4 x i32> %786, %14
  %788 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %787, i32 %2) #8
  %789 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 10
  %790 = bitcast <2 x i64>* %789 to <4 x i32>*
  store <4 x i32> %788, <4 x i32>* %790, align 16
  %791 = bitcast <2 x i64>* %389 to <4 x i32>*
  %792 = load <4 x i32>, <4 x i32>* %791, align 16
  %793 = mul <4 x i32> %792, %767
  %794 = add <4 x i32> %793, %14
  %795 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %794, i32 %2) #8
  %796 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 11
  %797 = bitcast <2 x i64>* %796 to <4 x i32>*
  store <4 x i32> %795, <4 x i32>* %797, align 16
  %798 = mul <4 x i32> %792, %742
  %799 = add <4 x i32> %798, %14
  %800 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %799, i32 %2) #8
  %801 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 12
  %802 = bitcast <2 x i64>* %801 to <4 x i32>*
  store <4 x i32> %800, <4 x i32>* %802, align 16
  %803 = mul <4 x i32> %785, %744
  %804 = add <4 x i32> %803, %14
  %805 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %804, i32 %2) #8
  %806 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 13
  %807 = bitcast <2 x i64>* %806 to <4 x i32>*
  store <4 x i32> %805, <4 x i32>* %807, align 16
  %808 = mul <4 x i32> %778, %746
  %809 = add <4 x i32> %808, %14
  %810 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %809, i32 %2) #8
  %811 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 14
  %812 = bitcast <2 x i64>* %811 to <4 x i32>*
  store <4 x i32> %810, <4 x i32>* %812, align 16
  %813 = mul <4 x i32> %771, %740
  %814 = add <4 x i32> %813, %14
  %815 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %814, i32 %2) #8
  %816 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 15
  %817 = bitcast <2 x i64>* %816 to <4 x i32>*
  store <4 x i32> %815, <4 x i32>* %817, align 16
  %818 = load <4 x i32>, <4 x i32>* %602, align 16
  %819 = load <4 x i32>, <4 x i32>* %609, align 16
  %820 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 17
  %821 = add <4 x i32> %819, %818
  %822 = sub <4 x i32> %818, %819
  %823 = icmp sgt <4 x i32> %821, %24
  %824 = select <4 x i1> %823, <4 x i32> %821, <4 x i32> %24
  %825 = icmp slt <4 x i32> %824, %27
  %826 = select <4 x i1> %825, <4 x i32> %824, <4 x i32> %27
  %827 = icmp sgt <4 x i32> %822, %24
  %828 = select <4 x i1> %827, <4 x i32> %822, <4 x i32> %24
  %829 = icmp slt <4 x i32> %828, %27
  %830 = select <4 x i1> %829, <4 x i32> %828, <4 x i32> %27
  store <4 x i32> %826, <4 x i32>* %596, align 16
  %831 = bitcast <2 x i64>* %820 to <4 x i32>*
  store <4 x i32> %830, <4 x i32>* %831, align 16
  %832 = load <4 x i32>, <4 x i32>* %623, align 16
  %833 = load <4 x i32>, <4 x i32>* %616, align 16
  %834 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 19
  %835 = add <4 x i32> %833, %832
  %836 = sub <4 x i32> %832, %833
  %837 = icmp sgt <4 x i32> %835, %24
  %838 = select <4 x i1> %837, <4 x i32> %835, <4 x i32> %24
  %839 = icmp slt <4 x i32> %838, %27
  %840 = select <4 x i1> %839, <4 x i32> %838, <4 x i32> %27
  %841 = icmp sgt <4 x i32> %836, %24
  %842 = select <4 x i1> %841, <4 x i32> %836, <4 x i32> %24
  %843 = icmp slt <4 x i32> %842, %27
  %844 = select <4 x i1> %843, <4 x i32> %842, <4 x i32> %27
  %845 = bitcast <2 x i64>* %834 to <4 x i32>*
  store <4 x i32> %840, <4 x i32>* %845, align 16
  store <4 x i32> %844, <4 x i32>* %610, align 16
  %846 = load <4 x i32>, <4 x i32>* %630, align 16
  %847 = load <4 x i32>, <4 x i32>* %637, align 16
  %848 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 21
  %849 = add <4 x i32> %847, %846
  %850 = sub <4 x i32> %846, %847
  %851 = icmp sgt <4 x i32> %849, %24
  %852 = select <4 x i1> %851, <4 x i32> %849, <4 x i32> %24
  %853 = icmp slt <4 x i32> %852, %27
  %854 = select <4 x i1> %853, <4 x i32> %852, <4 x i32> %27
  %855 = icmp sgt <4 x i32> %850, %24
  %856 = select <4 x i1> %855, <4 x i32> %850, <4 x i32> %24
  %857 = icmp slt <4 x i32> %856, %27
  %858 = select <4 x i1> %857, <4 x i32> %856, <4 x i32> %27
  store <4 x i32> %854, <4 x i32>* %624, align 16
  %859 = bitcast <2 x i64>* %848 to <4 x i32>*
  store <4 x i32> %858, <4 x i32>* %859, align 16
  %860 = load <4 x i32>, <4 x i32>* %651, align 16
  %861 = load <4 x i32>, <4 x i32>* %644, align 16
  %862 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 23
  %863 = add <4 x i32> %861, %860
  %864 = sub <4 x i32> %860, %861
  %865 = icmp sgt <4 x i32> %863, %24
  %866 = select <4 x i1> %865, <4 x i32> %863, <4 x i32> %24
  %867 = icmp slt <4 x i32> %866, %27
  %868 = select <4 x i1> %867, <4 x i32> %866, <4 x i32> %27
  %869 = icmp sgt <4 x i32> %864, %24
  %870 = select <4 x i1> %869, <4 x i32> %864, <4 x i32> %24
  %871 = icmp slt <4 x i32> %870, %27
  %872 = select <4 x i1> %871, <4 x i32> %870, <4 x i32> %27
  %873 = bitcast <2 x i64>* %862 to <4 x i32>*
  store <4 x i32> %868, <4 x i32>* %873, align 16
  store <4 x i32> %872, <4 x i32>* %638, align 16
  %874 = load <4 x i32>, <4 x i32>* %656, align 16
  %875 = load <4 x i32>, <4 x i32>* %661, align 16
  %876 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 25
  %877 = add <4 x i32> %875, %874
  %878 = sub <4 x i32> %874, %875
  %879 = icmp sgt <4 x i32> %877, %24
  %880 = select <4 x i1> %879, <4 x i32> %877, <4 x i32> %24
  %881 = icmp slt <4 x i32> %880, %27
  %882 = select <4 x i1> %881, <4 x i32> %880, <4 x i32> %27
  %883 = icmp sgt <4 x i32> %878, %24
  %884 = select <4 x i1> %883, <4 x i32> %878, <4 x i32> %24
  %885 = icmp slt <4 x i32> %884, %27
  %886 = select <4 x i1> %885, <4 x i32> %884, <4 x i32> %27
  store <4 x i32> %882, <4 x i32>* %645, align 16
  %887 = bitcast <2 x i64>* %876 to <4 x i32>*
  store <4 x i32> %886, <4 x i32>* %887, align 16
  %888 = load <4 x i32>, <4 x i32>* %671, align 16
  %889 = load <4 x i32>, <4 x i32>* %666, align 16
  %890 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 27
  %891 = add <4 x i32> %889, %888
  %892 = sub <4 x i32> %888, %889
  %893 = icmp sgt <4 x i32> %891, %24
  %894 = select <4 x i1> %893, <4 x i32> %891, <4 x i32> %24
  %895 = icmp slt <4 x i32> %894, %27
  %896 = select <4 x i1> %895, <4 x i32> %894, <4 x i32> %27
  %897 = icmp sgt <4 x i32> %892, %24
  %898 = select <4 x i1> %897, <4 x i32> %892, <4 x i32> %24
  %899 = icmp slt <4 x i32> %898, %27
  %900 = select <4 x i1> %899, <4 x i32> %898, <4 x i32> %27
  %901 = bitcast <2 x i64>* %890 to <4 x i32>*
  store <4 x i32> %896, <4 x i32>* %901, align 16
  store <4 x i32> %900, <4 x i32>* %631, align 16
  %902 = load <4 x i32>, <4 x i32>* %676, align 16
  %903 = load <4 x i32>, <4 x i32>* %681, align 16
  %904 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 29
  %905 = add <4 x i32> %903, %902
  %906 = sub <4 x i32> %902, %903
  %907 = icmp sgt <4 x i32> %905, %24
  %908 = select <4 x i1> %907, <4 x i32> %905, <4 x i32> %24
  %909 = icmp slt <4 x i32> %908, %27
  %910 = select <4 x i1> %909, <4 x i32> %908, <4 x i32> %27
  %911 = icmp sgt <4 x i32> %906, %24
  %912 = select <4 x i1> %911, <4 x i32> %906, <4 x i32> %24
  %913 = icmp slt <4 x i32> %912, %27
  %914 = select <4 x i1> %913, <4 x i32> %912, <4 x i32> %27
  store <4 x i32> %910, <4 x i32>* %617, align 16
  %915 = bitcast <2 x i64>* %904 to <4 x i32>*
  store <4 x i32> %914, <4 x i32>* %915, align 16
  %916 = load <4 x i32>, <4 x i32>* %691, align 16
  %917 = load <4 x i32>, <4 x i32>* %686, align 16
  %918 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 31
  %919 = add <4 x i32> %917, %916
  %920 = sub <4 x i32> %916, %917
  %921 = icmp sgt <4 x i32> %919, %24
  %922 = select <4 x i1> %921, <4 x i32> %919, <4 x i32> %24
  %923 = icmp slt <4 x i32> %922, %27
  %924 = select <4 x i1> %923, <4 x i32> %922, <4 x i32> %27
  %925 = icmp sgt <4 x i32> %920, %24
  %926 = select <4 x i1> %925, <4 x i32> %920, <4 x i32> %24
  %927 = icmp slt <4 x i32> %926, %27
  %928 = select <4 x i1> %927, <4 x i32> %926, <4 x i32> %27
  %929 = bitcast <2 x i64>* %918 to <4 x i32>*
  store <4 x i32> %924, <4 x i32>* %929, align 16
  store <4 x i32> %928, <4 x i32>* %603, align 16
  %930 = load <2 x i64>, <2 x i64>* %311, align 16
  store <2 x i64> %930, <2 x i64>* %409, align 16
  %931 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 35
  %932 = load <2 x i64>, <2 x i64>* %931, align 16
  store <2 x i64> %932, <2 x i64>* %430, align 16
  %933 = load <2 x i64>, <2 x i64>* %317, align 16
  store <2 x i64> %933, <2 x i64>* %437, align 16
  %934 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 39
  %935 = load <2 x i64>, <2 x i64>* %934, align 16
  store <2 x i64> %935, <2 x i64>* %458, align 16
  %936 = load <2 x i64>, <2 x i64>* %323, align 16
  store <2 x i64> %936, <2 x i64>* %465, align 16
  %937 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 43
  %938 = load <2 x i64>, <2 x i64>* %937, align 16
  store <2 x i64> %938, <2 x i64>* %486, align 16
  %939 = load <2 x i64>, <2 x i64>* %329, align 16
  store <2 x i64> %939, <2 x i64>* %493, align 16
  %940 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 47
  %941 = load <2 x i64>, <2 x i64>* %940, align 16
  store <2 x i64> %941, <2 x i64>* %514, align 16
  %942 = load <2 x i64>, <2 x i64>* %335, align 16
  store <2 x i64> %942, <2 x i64>* %519, align 16
  %943 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 51
  %944 = load <2 x i64>, <2 x i64>* %943, align 16
  store <2 x i64> %944, <2 x i64>* %534, align 16
  %945 = load <2 x i64>, <2 x i64>* %341, align 16
  store <2 x i64> %945, <2 x i64>* %539, align 16
  %946 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 55
  %947 = load <2 x i64>, <2 x i64>* %946, align 16
  store <2 x i64> %947, <2 x i64>* %554, align 16
  %948 = load <2 x i64>, <2 x i64>* %347, align 16
  store <2 x i64> %948, <2 x i64>* %559, align 16
  %949 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 59
  %950 = load <2 x i64>, <2 x i64>* %949, align 16
  store <2 x i64> %950, <2 x i64>* %574, align 16
  %951 = load <2 x i64>, <2 x i64>* %353, align 16
  store <2 x i64> %951, <2 x i64>* %579, align 16
  %952 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 63
  %953 = load <2 x i64>, <2 x i64>* %952, align 16
  store <2 x i64> %953, <2 x i64>* %594, align 16
  %954 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 33
  %955 = bitcast <2 x i64>* %954 to <4 x i32>*
  %956 = load <4 x i32>, <4 x i32>* %955, align 16
  %957 = mul <4 x i32> %956, %755
  %958 = load <4 x i32>, <4 x i32>* %411, align 16
  %959 = mul <4 x i32> %958, %754
  %960 = add <4 x i32> %957, %14
  %961 = add <4 x i32> %960, %959
  %962 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %961, i32 %2) #8
  store <4 x i32> %962, <4 x i32>* %417, align 16
  %963 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 61
  %964 = load <4 x i32>, <4 x i32>* %418, align 16
  %965 = mul <4 x i32> %964, %769
  %966 = bitcast <2 x i64>* %963 to <4 x i32>*
  %967 = load <4 x i32>, <4 x i32>* %966, align 16
  %968 = mul <4 x i32> %967, %755
  %969 = add <4 x i32> %965, %14
  %970 = add <4 x i32> %969, %968
  %971 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %970, i32 %2) #8
  store <4 x i32> %971, <4 x i32>* %424, align 16
  %972 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 37
  %973 = bitcast <2 x i64>* %972 to <4 x i32>*
  %974 = load <4 x i32>, <4 x i32>* %973, align 16
  %975 = mul <4 x i32> %974, %763
  %976 = load <4 x i32>, <4 x i32>* %439, align 16
  %977 = mul <4 x i32> %976, %746
  %978 = add <4 x i32> %975, %14
  %979 = add <4 x i32> %978, %977
  %980 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %979, i32 %2) #8
  store <4 x i32> %980, <4 x i32>* %445, align 16
  %981 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 57
  %982 = load <4 x i32>, <4 x i32>* %446, align 16
  %983 = mul <4 x i32> %982, %761
  %984 = bitcast <2 x i64>* %981 to <4 x i32>*
  %985 = load <4 x i32>, <4 x i32>* %984, align 16
  %986 = mul <4 x i32> %985, %763
  %987 = add <4 x i32> %983, %14
  %988 = add <4 x i32> %987, %986
  %989 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %988, i32 %2) #8
  store <4 x i32> %989, <4 x i32>* %452, align 16
  %990 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 41
  %991 = bitcast <2 x i64>* %990 to <4 x i32>*
  %992 = load <4 x i32>, <4 x i32>* %991, align 16
  %993 = mul <4 x i32> %992, %759
  %994 = load <4 x i32>, <4 x i32>* %467, align 16
  %995 = mul <4 x i32> %994, %750
  %996 = add <4 x i32> %993, %14
  %997 = add <4 x i32> %996, %995
  %998 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %997, i32 %2) #8
  store <4 x i32> %998, <4 x i32>* %473, align 16
  %999 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 53
  %1000 = load <4 x i32>, <4 x i32>* %474, align 16
  %1001 = mul <4 x i32> %1000, %765
  %1002 = bitcast <2 x i64>* %999 to <4 x i32>*
  %1003 = load <4 x i32>, <4 x i32>* %1002, align 16
  %1004 = mul <4 x i32> %1003, %759
  %1005 = add <4 x i32> %1001, %14
  %1006 = add <4 x i32> %1005, %1004
  %1007 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1006, i32 %2) #8
  store <4 x i32> %1007, <4 x i32>* %480, align 16
  %1008 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 45
  %1009 = bitcast <2 x i64>* %1008 to <4 x i32>*
  %1010 = load <4 x i32>, <4 x i32>* %1009, align 16
  %1011 = mul <4 x i32> %1010, %767
  %1012 = load <4 x i32>, <4 x i32>* %495, align 16
  %1013 = mul <4 x i32> %1012, %742
  %1014 = add <4 x i32> %1011, %14
  %1015 = add <4 x i32> %1014, %1013
  %1016 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1015, i32 %2) #8
  store <4 x i32> %1016, <4 x i32>* %501, align 16
  %1017 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 49
  %1018 = load <4 x i32>, <4 x i32>* %502, align 16
  %1019 = mul <4 x i32> %1018, %757
  %1020 = bitcast <2 x i64>* %1017 to <4 x i32>*
  %1021 = load <4 x i32>, <4 x i32>* %1020, align 16
  %1022 = mul <4 x i32> %1021, %767
  %1023 = add <4 x i32> %1019, %14
  %1024 = add <4 x i32> %1023, %1022
  %1025 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1024, i32 %2) #8
  store <4 x i32> %1025, <4 x i32>* %508, align 16
  %1026 = mul <4 x i32> %1018, %767
  %1027 = mul <4 x i32> %1021, %742
  %1028 = add <4 x i32> %1026, %14
  %1029 = add <4 x i32> %1028, %1027
  %1030 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1029, i32 %2) #8
  store <4 x i32> %1030, <4 x i32>* %525, align 16
  %1031 = mul <4 x i32> %1010, %742
  %1032 = mul <4 x i32> %1012, %752
  %1033 = add <4 x i32> %1031, %14
  %1034 = add <4 x i32> %1033, %1032
  %1035 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1034, i32 %2) #8
  store <4 x i32> %1035, <4 x i32>* %530, align 16
  %1036 = mul <4 x i32> %1000, %759
  %1037 = mul <4 x i32> %1003, %750
  %1038 = add <4 x i32> %1036, %14
  %1039 = add <4 x i32> %1038, %1037
  %1040 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1039, i32 %2) #8
  store <4 x i32> %1040, <4 x i32>* %545, align 16
  %1041 = mul <4 x i32> %992, %750
  %1042 = mul <4 x i32> %994, %744
  %1043 = add <4 x i32> %1041, %14
  %1044 = add <4 x i32> %1043, %1042
  %1045 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1044, i32 %2) #8
  store <4 x i32> %1045, <4 x i32>* %550, align 16
  %1046 = mul <4 x i32> %982, %763
  %1047 = mul <4 x i32> %985, %746
  %1048 = add <4 x i32> %1046, %14
  %1049 = add <4 x i32> %1048, %1047
  %1050 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1049, i32 %2) #8
  store <4 x i32> %1050, <4 x i32>* %565, align 16
  %1051 = mul <4 x i32> %974, %746
  %1052 = mul <4 x i32> %976, %748
  %1053 = add <4 x i32> %1051, %14
  %1054 = add <4 x i32> %1053, %1052
  %1055 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1054, i32 %2) #8
  store <4 x i32> %1055, <4 x i32>* %570, align 16
  %1056 = mul <4 x i32> %964, %755
  %1057 = mul <4 x i32> %967, %754
  %1058 = add <4 x i32> %1056, %14
  %1059 = add <4 x i32> %1058, %1057
  %1060 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1059, i32 %2) #8
  store <4 x i32> %1060, <4 x i32>* %585, align 16
  %1061 = mul <4 x i32> %956, %754
  %1062 = mul <4 x i32> %958, %740
  %1063 = add <4 x i32> %1061, %14
  %1064 = add <4 x i32> %1063, %1062
  %1065 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1064, i32 %2) #8
  store <4 x i32> %1065, <4 x i32>* %590, align 16
  %1066 = bitcast <2 x i64>* %395 to <4 x i32>*
  %1067 = load <4 x i32>, <4 x i32>* %1066, align 16
  %1068 = mul <4 x i32> %1067, %753
  %1069 = add <4 x i32> %1068, %14
  %1070 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1069, i32 %2) #8
  %1071 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 4
  %1072 = bitcast <2 x i64>* %1071 to <4 x i32>*
  store <4 x i32> %1070, <4 x i32>* %1072, align 16
  %1073 = bitcast <2 x i64>* %398 to <4 x i32>*
  %1074 = load <4 x i32>, <4 x i32>* %1073, align 16
  %1075 = mul <4 x i32> %1074, %764
  %1076 = add <4 x i32> %1075, %14
  %1077 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1076, i32 %2) #8
  %1078 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 5
  %1079 = bitcast <2 x i64>* %1078 to <4 x i32>*
  store <4 x i32> %1077, <4 x i32>* %1079, align 16
  %1080 = mul <4 x i32> %1074, %745
  %1081 = add <4 x i32> %1080, %14
  %1082 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1081, i32 %2) #8
  %1083 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 6
  %1084 = bitcast <2 x i64>* %1083 to <4 x i32>*
  store <4 x i32> %1082, <4 x i32>* %1084, align 16
  %1085 = mul <4 x i32> %1067, %741
  %1086 = add <4 x i32> %1085, %14
  %1087 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1086, i32 %2) #8
  %1088 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 7
  %1089 = bitcast <2 x i64>* %1088 to <4 x i32>*
  store <4 x i32> %1087, <4 x i32>* %1089, align 16
  %1090 = load <4 x i32>, <4 x i32>* %776, align 16
  %1091 = load <4 x i32>, <4 x i32>* %783, align 16
  %1092 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 9
  %1093 = add <4 x i32> %1091, %1090
  %1094 = sub <4 x i32> %1090, %1091
  %1095 = icmp sgt <4 x i32> %1093, %24
  %1096 = select <4 x i1> %1095, <4 x i32> %1093, <4 x i32> %24
  %1097 = icmp slt <4 x i32> %1096, %27
  %1098 = select <4 x i1> %1097, <4 x i32> %1096, <4 x i32> %27
  %1099 = icmp sgt <4 x i32> %1094, %24
  %1100 = select <4 x i1> %1099, <4 x i32> %1094, <4 x i32> %24
  %1101 = icmp slt <4 x i32> %1100, %27
  %1102 = select <4 x i1> %1101, <4 x i32> %1100, <4 x i32> %27
  store <4 x i32> %1098, <4 x i32>* %770, align 16
  %1103 = bitcast <2 x i64>* %1092 to <4 x i32>*
  store <4 x i32> %1102, <4 x i32>* %1103, align 16
  %1104 = load <4 x i32>, <4 x i32>* %797, align 16
  %1105 = load <4 x i32>, <4 x i32>* %790, align 16
  %1106 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 11
  %1107 = add <4 x i32> %1105, %1104
  %1108 = sub <4 x i32> %1104, %1105
  %1109 = icmp sgt <4 x i32> %1107, %24
  %1110 = select <4 x i1> %1109, <4 x i32> %1107, <4 x i32> %24
  %1111 = icmp slt <4 x i32> %1110, %27
  %1112 = select <4 x i1> %1111, <4 x i32> %1110, <4 x i32> %27
  %1113 = icmp sgt <4 x i32> %1108, %24
  %1114 = select <4 x i1> %1113, <4 x i32> %1108, <4 x i32> %24
  %1115 = icmp slt <4 x i32> %1114, %27
  %1116 = select <4 x i1> %1115, <4 x i32> %1114, <4 x i32> %27
  %1117 = bitcast <2 x i64>* %1106 to <4 x i32>*
  store <4 x i32> %1112, <4 x i32>* %1117, align 16
  store <4 x i32> %1116, <4 x i32>* %784, align 16
  %1118 = load <4 x i32>, <4 x i32>* %802, align 16
  %1119 = load <4 x i32>, <4 x i32>* %807, align 16
  %1120 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 13
  %1121 = add <4 x i32> %1119, %1118
  %1122 = sub <4 x i32> %1118, %1119
  %1123 = icmp sgt <4 x i32> %1121, %24
  %1124 = select <4 x i1> %1123, <4 x i32> %1121, <4 x i32> %24
  %1125 = icmp slt <4 x i32> %1124, %27
  %1126 = select <4 x i1> %1125, <4 x i32> %1124, <4 x i32> %27
  %1127 = icmp sgt <4 x i32> %1122, %24
  %1128 = select <4 x i1> %1127, <4 x i32> %1122, <4 x i32> %24
  %1129 = icmp slt <4 x i32> %1128, %27
  %1130 = select <4 x i1> %1129, <4 x i32> %1128, <4 x i32> %27
  store <4 x i32> %1126, <4 x i32>* %791, align 16
  %1131 = bitcast <2 x i64>* %1120 to <4 x i32>*
  store <4 x i32> %1130, <4 x i32>* %1131, align 16
  %1132 = load <4 x i32>, <4 x i32>* %817, align 16
  %1133 = load <4 x i32>, <4 x i32>* %812, align 16
  %1134 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 15
  %1135 = add <4 x i32> %1133, %1132
  %1136 = sub <4 x i32> %1132, %1133
  %1137 = icmp sgt <4 x i32> %1135, %24
  %1138 = select <4 x i1> %1137, <4 x i32> %1135, <4 x i32> %24
  %1139 = icmp slt <4 x i32> %1138, %27
  %1140 = select <4 x i1> %1139, <4 x i32> %1138, <4 x i32> %27
  %1141 = icmp sgt <4 x i32> %1136, %24
  %1142 = select <4 x i1> %1141, <4 x i32> %1136, <4 x i32> %24
  %1143 = icmp slt <4 x i32> %1142, %27
  %1144 = select <4 x i1> %1143, <4 x i32> %1142, <4 x i32> %27
  %1145 = bitcast <2 x i64>* %1134 to <4 x i32>*
  store <4 x i32> %1140, <4 x i32>* %1145, align 16
  store <4 x i32> %1144, <4 x i32>* %777, align 16
  %1146 = load <2 x i64>, <2 x i64>* %359, align 16
  store <2 x i64> %1146, <2 x i64>* %601, align 16
  %1147 = load <2 x i64>, <2 x i64>* %834, align 16
  store <2 x i64> %1147, <2 x i64>* %622, align 16
  %1148 = load <2 x i64>, <2 x i64>* %365, align 16
  store <2 x i64> %1148, <2 x i64>* %629, align 16
  %1149 = load <2 x i64>, <2 x i64>* %862, align 16
  store <2 x i64> %1149, <2 x i64>* %650, align 16
  %1150 = load <2 x i64>, <2 x i64>* %371, align 16
  store <2 x i64> %1150, <2 x i64>* %655, align 16
  %1151 = load <2 x i64>, <2 x i64>* %890, align 16
  store <2 x i64> %1151, <2 x i64>* %670, align 16
  %1152 = load <2 x i64>, <2 x i64>* %377, align 16
  store <2 x i64> %1152, <2 x i64>* %675, align 16
  %1153 = load <2 x i64>, <2 x i64>* %918, align 16
  store <2 x i64> %1153, <2 x i64>* %690, align 16
  %1154 = load <4 x i32>, <4 x i32>* %831, align 16
  %1155 = mul <4 x i32> %1154, %756
  %1156 = load <4 x i32>, <4 x i32>* %603, align 16
  %1157 = mul <4 x i32> %1156, %753
  %1158 = add <4 x i32> %1155, %14
  %1159 = add <4 x i32> %1158, %1157
  %1160 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1159, i32 %2) #8
  store <4 x i32> %1160, <4 x i32>* %609, align 16
  %1161 = load <4 x i32>, <4 x i32>* %610, align 16
  %1162 = mul <4 x i32> %1161, %768
  %1163 = load <4 x i32>, <4 x i32>* %915, align 16
  %1164 = mul <4 x i32> %1163, %756
  %1165 = add <4 x i32> %1162, %14
  %1166 = add <4 x i32> %1165, %1164
  %1167 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1166, i32 %2) #8
  store <4 x i32> %1167, <4 x i32>* %616, align 16
  %1168 = load <4 x i32>, <4 x i32>* %859, align 16
  %1169 = mul <4 x i32> %1168, %764
  %1170 = load <4 x i32>, <4 x i32>* %631, align 16
  %1171 = mul <4 x i32> %1170, %745
  %1172 = add <4 x i32> %1169, %14
  %1173 = add <4 x i32> %1172, %1171
  %1174 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1173, i32 %2) #8
  store <4 x i32> %1174, <4 x i32>* %637, align 16
  %1175 = load <4 x i32>, <4 x i32>* %638, align 16
  %1176 = mul <4 x i32> %1175, %760
  %1177 = load <4 x i32>, <4 x i32>* %887, align 16
  %1178 = mul <4 x i32> %1177, %764
  %1179 = add <4 x i32> %1176, %14
  %1180 = add <4 x i32> %1179, %1178
  %1181 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1180, i32 %2) #8
  store <4 x i32> %1181, <4 x i32>* %644, align 16
  %1182 = mul <4 x i32> %1175, %764
  %1183 = mul <4 x i32> %1177, %745
  %1184 = add <4 x i32> %1182, %14
  %1185 = add <4 x i32> %1184, %1183
  %1186 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1185, i32 %2) #8
  store <4 x i32> %1186, <4 x i32>* %661, align 16
  %1187 = mul <4 x i32> %1168, %745
  %1188 = mul <4 x i32> %1170, %749
  %1189 = add <4 x i32> %1187, %14
  %1190 = add <4 x i32> %1189, %1188
  %1191 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1190, i32 %2) #8
  store <4 x i32> %1191, <4 x i32>* %666, align 16
  %1192 = mul <4 x i32> %1161, %756
  %1193 = mul <4 x i32> %1163, %753
  %1194 = add <4 x i32> %1192, %14
  %1195 = add <4 x i32> %1194, %1193
  %1196 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1195, i32 %2) #8
  store <4 x i32> %1196, <4 x i32>* %681, align 16
  %1197 = mul <4 x i32> %1154, %753
  %1198 = mul <4 x i32> %1156, %741
  %1199 = add <4 x i32> %1197, %14
  %1200 = add <4 x i32> %1199, %1198
  %1201 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1200, i32 %2) #8
  store <4 x i32> %1201, <4 x i32>* %686, align 16
  br label %1202

1202:                                             ; preds = %739, %1202
  %1203 = phi i64 [ 32, %739 ], [ %1291, %1202 ]
  %1204 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %1203
  %1205 = bitcast <2 x i64>* %1204 to <4 x i32>*
  %1206 = load <4 x i32>, <4 x i32>* %1205, align 16
  %1207 = or i64 %1203, 3
  %1208 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %1207
  %1209 = bitcast <2 x i64>* %1208 to <4 x i32>*
  %1210 = load <4 x i32>, <4 x i32>* %1209, align 16
  %1211 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %1203
  %1212 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %1207
  %1213 = add <4 x i32> %1210, %1206
  %1214 = sub <4 x i32> %1206, %1210
  %1215 = icmp sgt <4 x i32> %1213, %24
  %1216 = select <4 x i1> %1215, <4 x i32> %1213, <4 x i32> %24
  %1217 = icmp slt <4 x i32> %1216, %27
  %1218 = select <4 x i1> %1217, <4 x i32> %1216, <4 x i32> %27
  %1219 = icmp sgt <4 x i32> %1214, %24
  %1220 = select <4 x i1> %1219, <4 x i32> %1214, <4 x i32> %24
  %1221 = icmp slt <4 x i32> %1220, %27
  %1222 = select <4 x i1> %1221, <4 x i32> %1220, <4 x i32> %27
  %1223 = bitcast <2 x i64>* %1211 to <4 x i32>*
  store <4 x i32> %1218, <4 x i32>* %1223, align 16
  %1224 = bitcast <2 x i64>* %1212 to <4 x i32>*
  store <4 x i32> %1222, <4 x i32>* %1224, align 16
  %1225 = or i64 %1203, 1
  %1226 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %1225
  %1227 = bitcast <2 x i64>* %1226 to <4 x i32>*
  %1228 = load <4 x i32>, <4 x i32>* %1227, align 16
  %1229 = or i64 %1203, 2
  %1230 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %1229
  %1231 = bitcast <2 x i64>* %1230 to <4 x i32>*
  %1232 = load <4 x i32>, <4 x i32>* %1231, align 16
  %1233 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %1225
  %1234 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %1229
  %1235 = add <4 x i32> %1232, %1228
  %1236 = sub <4 x i32> %1228, %1232
  %1237 = icmp sgt <4 x i32> %1235, %24
  %1238 = select <4 x i1> %1237, <4 x i32> %1235, <4 x i32> %24
  %1239 = icmp slt <4 x i32> %1238, %27
  %1240 = select <4 x i1> %1239, <4 x i32> %1238, <4 x i32> %27
  %1241 = icmp sgt <4 x i32> %1236, %24
  %1242 = select <4 x i1> %1241, <4 x i32> %1236, <4 x i32> %24
  %1243 = icmp slt <4 x i32> %1242, %27
  %1244 = select <4 x i1> %1243, <4 x i32> %1242, <4 x i32> %27
  %1245 = bitcast <2 x i64>* %1233 to <4 x i32>*
  store <4 x i32> %1240, <4 x i32>* %1245, align 16
  %1246 = bitcast <2 x i64>* %1234 to <4 x i32>*
  store <4 x i32> %1244, <4 x i32>* %1246, align 16
  %1247 = or i64 %1203, 7
  %1248 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %1247
  %1249 = bitcast <2 x i64>* %1248 to <4 x i32>*
  %1250 = load <4 x i32>, <4 x i32>* %1249, align 16
  %1251 = or i64 %1203, 4
  %1252 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %1251
  %1253 = bitcast <2 x i64>* %1252 to <4 x i32>*
  %1254 = load <4 x i32>, <4 x i32>* %1253, align 16
  %1255 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %1247
  %1256 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %1251
  %1257 = add <4 x i32> %1254, %1250
  %1258 = sub <4 x i32> %1250, %1254
  %1259 = icmp sgt <4 x i32> %1257, %24
  %1260 = select <4 x i1> %1259, <4 x i32> %1257, <4 x i32> %24
  %1261 = icmp slt <4 x i32> %1260, %27
  %1262 = select <4 x i1> %1261, <4 x i32> %1260, <4 x i32> %27
  %1263 = icmp sgt <4 x i32> %1258, %24
  %1264 = select <4 x i1> %1263, <4 x i32> %1258, <4 x i32> %24
  %1265 = icmp slt <4 x i32> %1264, %27
  %1266 = select <4 x i1> %1265, <4 x i32> %1264, <4 x i32> %27
  %1267 = bitcast <2 x i64>* %1255 to <4 x i32>*
  store <4 x i32> %1262, <4 x i32>* %1267, align 16
  %1268 = bitcast <2 x i64>* %1256 to <4 x i32>*
  store <4 x i32> %1266, <4 x i32>* %1268, align 16
  %1269 = or i64 %1203, 6
  %1270 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %1269
  %1271 = bitcast <2 x i64>* %1270 to <4 x i32>*
  %1272 = load <4 x i32>, <4 x i32>* %1271, align 16
  %1273 = or i64 %1203, 5
  %1274 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %1273
  %1275 = bitcast <2 x i64>* %1274 to <4 x i32>*
  %1276 = load <4 x i32>, <4 x i32>* %1275, align 16
  %1277 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %1269
  %1278 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %1273
  %1279 = add <4 x i32> %1276, %1272
  %1280 = sub <4 x i32> %1272, %1276
  %1281 = icmp sgt <4 x i32> %1279, %24
  %1282 = select <4 x i1> %1281, <4 x i32> %1279, <4 x i32> %24
  %1283 = icmp slt <4 x i32> %1282, %27
  %1284 = select <4 x i1> %1283, <4 x i32> %1282, <4 x i32> %27
  %1285 = icmp sgt <4 x i32> %1280, %24
  %1286 = select <4 x i1> %1285, <4 x i32> %1280, <4 x i32> %24
  %1287 = icmp slt <4 x i32> %1286, %27
  %1288 = select <4 x i1> %1287, <4 x i32> %1286, <4 x i32> %27
  %1289 = bitcast <2 x i64>* %1277 to <4 x i32>*
  store <4 x i32> %1284, <4 x i32>* %1289, align 16
  %1290 = bitcast <2 x i64>* %1278 to <4 x i32>*
  store <4 x i32> %1288, <4 x i32>* %1290, align 16
  %1291 = add nuw nsw i64 %1203, 8
  %1292 = icmp ult i64 %1291, 64
  br i1 %1292, label %1202, label %1293

1293:                                             ; preds = %1202
  %1294 = bitcast [64 x <2 x i64>]* %7 to <4 x i32>*
  %1295 = load <4 x i32>, <4 x i32>* %1294, align 16
  %1296 = mul <4 x i32> %1295, %747
  %1297 = add <4 x i32> %1296, %14
  %1298 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1297, i32 %2) #8
  %1299 = bitcast [64 x <2 x i64>]* %8 to <4 x i32>*
  store <4 x i32> %1298, <4 x i32>* %1299, align 16
  %1300 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 1
  %1301 = bitcast <2 x i64>* %1300 to <4 x i32>*
  store <4 x i32> %1298, <4 x i32>* %1301, align 16
  %1302 = bitcast <2 x i64>* %403 to <4 x i32>*
  %1303 = load <4 x i32>, <4 x i32>* %1302, align 16
  %1304 = mul <4 x i32> %1303, %751
  %1305 = add <4 x i32> %1304, %14
  %1306 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1305, i32 %2) #8
  %1307 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 2
  %1308 = bitcast <2 x i64>* %1307 to <4 x i32>*
  store <4 x i32> %1306, <4 x i32>* %1308, align 16
  %1309 = mul <4 x i32> %1303, %743
  %1310 = add <4 x i32> %1309, %14
  %1311 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1310, i32 %2) #8
  %1312 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 3
  %1313 = bitcast <2 x i64>* %1312 to <4 x i32>*
  store <4 x i32> %1311, <4 x i32>* %1313, align 16
  %1314 = load <4 x i32>, <4 x i32>* %1072, align 16
  %1315 = load <4 x i32>, <4 x i32>* %1079, align 16
  %1316 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 5
  %1317 = add <4 x i32> %1315, %1314
  %1318 = sub <4 x i32> %1314, %1315
  %1319 = icmp sgt <4 x i32> %1317, %24
  %1320 = select <4 x i1> %1319, <4 x i32> %1317, <4 x i32> %24
  %1321 = icmp slt <4 x i32> %1320, %27
  %1322 = select <4 x i1> %1321, <4 x i32> %1320, <4 x i32> %27
  %1323 = icmp sgt <4 x i32> %1318, %24
  %1324 = select <4 x i1> %1323, <4 x i32> %1318, <4 x i32> %24
  %1325 = icmp slt <4 x i32> %1324, %27
  %1326 = select <4 x i1> %1325, <4 x i32> %1324, <4 x i32> %27
  store <4 x i32> %1322, <4 x i32>* %1066, align 16
  %1327 = bitcast <2 x i64>* %1316 to <4 x i32>*
  store <4 x i32> %1326, <4 x i32>* %1327, align 16
  %1328 = load <4 x i32>, <4 x i32>* %1089, align 16
  %1329 = load <4 x i32>, <4 x i32>* %1084, align 16
  %1330 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 7
  %1331 = add <4 x i32> %1329, %1328
  %1332 = sub <4 x i32> %1328, %1329
  %1333 = icmp sgt <4 x i32> %1331, %24
  %1334 = select <4 x i1> %1333, <4 x i32> %1331, <4 x i32> %24
  %1335 = icmp slt <4 x i32> %1334, %27
  %1336 = select <4 x i1> %1335, <4 x i32> %1334, <4 x i32> %27
  %1337 = icmp sgt <4 x i32> %1332, %24
  %1338 = select <4 x i1> %1337, <4 x i32> %1332, <4 x i32> %24
  %1339 = icmp slt <4 x i32> %1338, %27
  %1340 = select <4 x i1> %1339, <4 x i32> %1338, <4 x i32> %27
  %1341 = bitcast <2 x i64>* %1330 to <4 x i32>*
  store <4 x i32> %1336, <4 x i32>* %1341, align 16
  store <4 x i32> %1340, <4 x i32>* %1073, align 16
  %1342 = load <2 x i64>, <2 x i64>* %383, align 16
  store <2 x i64> %1342, <2 x i64>* %775, align 16
  %1343 = load <2 x i64>, <2 x i64>* %1106, align 16
  store <2 x i64> %1343, <2 x i64>* %796, align 16
  %1344 = load <2 x i64>, <2 x i64>* %389, align 16
  store <2 x i64> %1344, <2 x i64>* %801, align 16
  %1345 = load <2 x i64>, <2 x i64>* %1134, align 16
  store <2 x i64> %1345, <2 x i64>* %816, align 16
  %1346 = load <4 x i32>, <4 x i32>* %1103, align 16
  %1347 = mul <4 x i32> %1346, %758
  %1348 = load <4 x i32>, <4 x i32>* %777, align 16
  %1349 = mul <4 x i32> %1348, %751
  %1350 = add <4 x i32> %1347, %14
  %1351 = add <4 x i32> %1350, %1349
  %1352 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1351, i32 %2) #8
  store <4 x i32> %1352, <4 x i32>* %783, align 16
  %1353 = load <4 x i32>, <4 x i32>* %784, align 16
  %1354 = mul <4 x i32> %1353, %766
  %1355 = load <4 x i32>, <4 x i32>* %1131, align 16
  %1356 = mul <4 x i32> %1355, %758
  %1357 = add <4 x i32> %1354, %14
  %1358 = add <4 x i32> %1357, %1356
  %1359 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1358, i32 %2) #8
  store <4 x i32> %1359, <4 x i32>* %790, align 16
  %1360 = mul <4 x i32> %1353, %758
  %1361 = mul <4 x i32> %1355, %751
  %1362 = add <4 x i32> %1360, %14
  %1363 = add <4 x i32> %1362, %1361
  %1364 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1363, i32 %2) #8
  store <4 x i32> %1364, <4 x i32>* %807, align 16
  %1365 = mul <4 x i32> %1346, %751
  %1366 = mul <4 x i32> %1348, %743
  %1367 = add <4 x i32> %1365, %14
  %1368 = add <4 x i32> %1367, %1366
  %1369 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1368, i32 %2) #8
  store <4 x i32> %1369, <4 x i32>* %812, align 16
  %1370 = load <4 x i32>, <4 x i32>* %602, align 16
  %1371 = load <4 x i32>, <4 x i32>* %623, align 16
  %1372 = add <4 x i32> %1371, %1370
  %1373 = sub <4 x i32> %1370, %1371
  %1374 = icmp sgt <4 x i32> %1372, %24
  %1375 = select <4 x i1> %1374, <4 x i32> %1372, <4 x i32> %24
  %1376 = icmp slt <4 x i32> %1375, %27
  %1377 = select <4 x i1> %1376, <4 x i32> %1375, <4 x i32> %27
  %1378 = icmp sgt <4 x i32> %1373, %24
  %1379 = select <4 x i1> %1378, <4 x i32> %1373, <4 x i32> %24
  %1380 = icmp slt <4 x i32> %1379, %27
  %1381 = select <4 x i1> %1380, <4 x i32> %1379, <4 x i32> %27
  store <4 x i32> %1377, <4 x i32>* %596, align 16
  store <4 x i32> %1381, <4 x i32>* %845, align 16
  %1382 = load <4 x i32>, <4 x i32>* %609, align 16
  %1383 = load <4 x i32>, <4 x i32>* %616, align 16
  %1384 = add <4 x i32> %1383, %1382
  %1385 = sub <4 x i32> %1382, %1383
  %1386 = icmp sgt <4 x i32> %1384, %24
  %1387 = select <4 x i1> %1386, <4 x i32> %1384, <4 x i32> %24
  %1388 = icmp slt <4 x i32> %1387, %27
  %1389 = select <4 x i1> %1388, <4 x i32> %1387, <4 x i32> %27
  %1390 = icmp sgt <4 x i32> %1385, %24
  %1391 = select <4 x i1> %1390, <4 x i32> %1385, <4 x i32> %24
  %1392 = icmp slt <4 x i32> %1391, %27
  %1393 = select <4 x i1> %1392, <4 x i32> %1391, <4 x i32> %27
  store <4 x i32> %1389, <4 x i32>* %831, align 16
  store <4 x i32> %1393, <4 x i32>* %610, align 16
  %1394 = load <4 x i32>, <4 x i32>* %651, align 16
  %1395 = load <4 x i32>, <4 x i32>* %630, align 16
  %1396 = add <4 x i32> %1395, %1394
  %1397 = sub <4 x i32> %1394, %1395
  %1398 = icmp sgt <4 x i32> %1396, %24
  %1399 = select <4 x i1> %1398, <4 x i32> %1396, <4 x i32> %24
  %1400 = icmp slt <4 x i32> %1399, %27
  %1401 = select <4 x i1> %1400, <4 x i32> %1399, <4 x i32> %27
  %1402 = icmp sgt <4 x i32> %1397, %24
  %1403 = select <4 x i1> %1402, <4 x i32> %1397, <4 x i32> %24
  %1404 = icmp slt <4 x i32> %1403, %27
  %1405 = select <4 x i1> %1404, <4 x i32> %1403, <4 x i32> %27
  store <4 x i32> %1401, <4 x i32>* %873, align 16
  store <4 x i32> %1405, <4 x i32>* %624, align 16
  %1406 = load <4 x i32>, <4 x i32>* %644, align 16
  %1407 = load <4 x i32>, <4 x i32>* %637, align 16
  %1408 = add <4 x i32> %1407, %1406
  %1409 = sub <4 x i32> %1406, %1407
  %1410 = icmp sgt <4 x i32> %1408, %24
  %1411 = select <4 x i1> %1410, <4 x i32> %1408, <4 x i32> %24
  %1412 = icmp slt <4 x i32> %1411, %27
  %1413 = select <4 x i1> %1412, <4 x i32> %1411, <4 x i32> %27
  %1414 = icmp sgt <4 x i32> %1409, %24
  %1415 = select <4 x i1> %1414, <4 x i32> %1409, <4 x i32> %24
  %1416 = icmp slt <4 x i32> %1415, %27
  %1417 = select <4 x i1> %1416, <4 x i32> %1415, <4 x i32> %27
  store <4 x i32> %1413, <4 x i32>* %638, align 16
  store <4 x i32> %1417, <4 x i32>* %859, align 16
  %1418 = load <4 x i32>, <4 x i32>* %656, align 16
  %1419 = load <4 x i32>, <4 x i32>* %671, align 16
  %1420 = add <4 x i32> %1419, %1418
  %1421 = sub <4 x i32> %1418, %1419
  %1422 = icmp sgt <4 x i32> %1420, %24
  %1423 = select <4 x i1> %1422, <4 x i32> %1420, <4 x i32> %24
  %1424 = icmp slt <4 x i32> %1423, %27
  %1425 = select <4 x i1> %1424, <4 x i32> %1423, <4 x i32> %27
  %1426 = icmp sgt <4 x i32> %1421, %24
  %1427 = select <4 x i1> %1426, <4 x i32> %1421, <4 x i32> %24
  %1428 = icmp slt <4 x i32> %1427, %27
  %1429 = select <4 x i1> %1428, <4 x i32> %1427, <4 x i32> %27
  store <4 x i32> %1425, <4 x i32>* %645, align 16
  store <4 x i32> %1429, <4 x i32>* %901, align 16
  %1430 = load <4 x i32>, <4 x i32>* %661, align 16
  %1431 = load <4 x i32>, <4 x i32>* %666, align 16
  %1432 = add <4 x i32> %1431, %1430
  %1433 = sub <4 x i32> %1430, %1431
  %1434 = icmp sgt <4 x i32> %1432, %24
  %1435 = select <4 x i1> %1434, <4 x i32> %1432, <4 x i32> %24
  %1436 = icmp slt <4 x i32> %1435, %27
  %1437 = select <4 x i1> %1436, <4 x i32> %1435, <4 x i32> %27
  %1438 = icmp sgt <4 x i32> %1433, %24
  %1439 = select <4 x i1> %1438, <4 x i32> %1433, <4 x i32> %24
  %1440 = icmp slt <4 x i32> %1439, %27
  %1441 = select <4 x i1> %1440, <4 x i32> %1439, <4 x i32> %27
  store <4 x i32> %1437, <4 x i32>* %887, align 16
  store <4 x i32> %1441, <4 x i32>* %631, align 16
  %1442 = load <4 x i32>, <4 x i32>* %691, align 16
  %1443 = load <4 x i32>, <4 x i32>* %676, align 16
  %1444 = add <4 x i32> %1443, %1442
  %1445 = sub <4 x i32> %1442, %1443
  %1446 = icmp sgt <4 x i32> %1444, %24
  %1447 = select <4 x i1> %1446, <4 x i32> %1444, <4 x i32> %24
  %1448 = icmp slt <4 x i32> %1447, %27
  %1449 = select <4 x i1> %1448, <4 x i32> %1447, <4 x i32> %27
  %1450 = icmp sgt <4 x i32> %1445, %24
  %1451 = select <4 x i1> %1450, <4 x i32> %1445, <4 x i32> %24
  %1452 = icmp slt <4 x i32> %1451, %27
  %1453 = select <4 x i1> %1452, <4 x i32> %1451, <4 x i32> %27
  store <4 x i32> %1449, <4 x i32>* %929, align 16
  store <4 x i32> %1453, <4 x i32>* %617, align 16
  %1454 = load <4 x i32>, <4 x i32>* %686, align 16
  %1455 = load <4 x i32>, <4 x i32>* %681, align 16
  %1456 = add <4 x i32> %1455, %1454
  %1457 = sub <4 x i32> %1454, %1455
  %1458 = icmp sgt <4 x i32> %1456, %24
  %1459 = select <4 x i1> %1458, <4 x i32> %1456, <4 x i32> %24
  %1460 = icmp slt <4 x i32> %1459, %27
  %1461 = select <4 x i1> %1460, <4 x i32> %1459, <4 x i32> %27
  %1462 = icmp sgt <4 x i32> %1457, %24
  %1463 = select <4 x i1> %1462, <4 x i32> %1457, <4 x i32> %24
  %1464 = icmp slt <4 x i32> %1463, %27
  %1465 = select <4 x i1> %1464, <4 x i32> %1463, <4 x i32> %27
  store <4 x i32> %1461, <4 x i32>* %603, align 16
  store <4 x i32> %1465, <4 x i32>* %915, align 16
  %1466 = load <2 x i64>, <2 x i64>* %311, align 16
  store <2 x i64> %1466, <2 x i64>* %409, align 16
  %1467 = load <2 x i64>, <2 x i64>* %954, align 16
  store <2 x i64> %1467, <2 x i64>* %416, align 16
  %1468 = load <2 x i64>, <2 x i64>* %320, align 16
  store <2 x i64> %1468, <2 x i64>* %451, align 16
  %1469 = load <2 x i64>, <2 x i64>* %934, align 16
  store <2 x i64> %1469, <2 x i64>* %458, align 16
  %1470 = load <2 x i64>, <2 x i64>* %323, align 16
  store <2 x i64> %1470, <2 x i64>* %465, align 16
  %1471 = load <2 x i64>, <2 x i64>* %990, align 16
  store <2 x i64> %1471, <2 x i64>* %472, align 16
  %1472 = load <2 x i64>, <2 x i64>* %332, align 16
  store <2 x i64> %1472, <2 x i64>* %507, align 16
  %1473 = load <2 x i64>, <2 x i64>* %940, align 16
  store <2 x i64> %1473, <2 x i64>* %514, align 16
  %1474 = load <2 x i64>, <2 x i64>* %335, align 16
  store <2 x i64> %1474, <2 x i64>* %519, align 16
  %1475 = load <2 x i64>, <2 x i64>* %1017, align 16
  store <2 x i64> %1475, <2 x i64>* %524, align 16
  %1476 = load <2 x i64>, <2 x i64>* %344, align 16
  store <2 x i64> %1476, <2 x i64>* %549, align 16
  %1477 = load <2 x i64>, <2 x i64>* %946, align 16
  store <2 x i64> %1477, <2 x i64>* %554, align 16
  %1478 = load <2 x i64>, <2 x i64>* %347, align 16
  store <2 x i64> %1478, <2 x i64>* %559, align 16
  %1479 = load <2 x i64>, <2 x i64>* %981, align 16
  store <2 x i64> %1479, <2 x i64>* %564, align 16
  %1480 = load <2 x i64>, <2 x i64>* %356, align 16
  store <2 x i64> %1480, <2 x i64>* %589, align 16
  %1481 = load <2 x i64>, <2 x i64>* %952, align 16
  store <2 x i64> %1481, <2 x i64>* %594, align 16
  %1482 = load <4 x i32>, <4 x i32>* %418, align 16
  %1483 = mul <4 x i32> %1482, %756
  %1484 = load <4 x i32>, <4 x i32>* %966, align 16
  %1485 = mul <4 x i32> %1484, %753
  %1486 = add <4 x i32> %1483, %14
  %1487 = add <4 x i32> %1486, %1485
  %1488 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1487, i32 %2) #8
  store <4 x i32> %1488, <4 x i32>* %424, align 16
  %1489 = bitcast <2 x i64>* %931 to <4 x i32>*
  %1490 = load <4 x i32>, <4 x i32>* %1489, align 16
  %1491 = mul <4 x i32> %1490, %756
  %1492 = load <4 x i32>, <4 x i32>* %425, align 16
  %1493 = mul <4 x i32> %1492, %753
  %1494 = add <4 x i32> %1491, %14
  %1495 = add <4 x i32> %1494, %1493
  %1496 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1495, i32 %2) #8
  store <4 x i32> %1496, <4 x i32>* %431, align 16
  %1497 = load <4 x i32>, <4 x i32>* %432, align 16
  %1498 = mul <4 x i32> %1497, %768
  %1499 = bitcast <2 x i64>* %949 to <4 x i32>*
  %1500 = load <4 x i32>, <4 x i32>* %1499, align 16
  %1501 = mul <4 x i32> %1500, %756
  %1502 = add <4 x i32> %1498, %14
  %1503 = add <4 x i32> %1502, %1501
  %1504 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1503, i32 %2) #8
  store <4 x i32> %1504, <4 x i32>* %438, align 16
  %1505 = load <4 x i32>, <4 x i32>* %973, align 16
  %1506 = mul <4 x i32> %1505, %768
  %1507 = load <4 x i32>, <4 x i32>* %439, align 16
  %1508 = mul <4 x i32> %1507, %756
  %1509 = add <4 x i32> %1506, %14
  %1510 = add <4 x i32> %1509, %1508
  %1511 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1510, i32 %2) #8
  store <4 x i32> %1511, <4 x i32>* %445, align 16
  %1512 = load <4 x i32>, <4 x i32>* %474, align 16
  %1513 = mul <4 x i32> %1512, %764
  %1514 = load <4 x i32>, <4 x i32>* %1002, align 16
  %1515 = mul <4 x i32> %1514, %745
  %1516 = add <4 x i32> %1513, %14
  %1517 = add <4 x i32> %1516, %1515
  %1518 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1517, i32 %2) #8
  store <4 x i32> %1518, <4 x i32>* %480, align 16
  %1519 = bitcast <2 x i64>* %937 to <4 x i32>*
  %1520 = load <4 x i32>, <4 x i32>* %1519, align 16
  %1521 = mul <4 x i32> %1520, %764
  %1522 = load <4 x i32>, <4 x i32>* %481, align 16
  %1523 = mul <4 x i32> %1522, %745
  %1524 = add <4 x i32> %1521, %14
  %1525 = add <4 x i32> %1524, %1523
  %1526 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1525, i32 %2) #8
  store <4 x i32> %1526, <4 x i32>* %487, align 16
  %1527 = load <4 x i32>, <4 x i32>* %488, align 16
  %1528 = mul <4 x i32> %1527, %760
  %1529 = bitcast <2 x i64>* %943 to <4 x i32>*
  %1530 = load <4 x i32>, <4 x i32>* %1529, align 16
  %1531 = mul <4 x i32> %1530, %764
  %1532 = add <4 x i32> %1528, %14
  %1533 = add <4 x i32> %1532, %1531
  %1534 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1533, i32 %2) #8
  store <4 x i32> %1534, <4 x i32>* %494, align 16
  %1535 = load <4 x i32>, <4 x i32>* %1009, align 16
  %1536 = mul <4 x i32> %1535, %760
  %1537 = load <4 x i32>, <4 x i32>* %495, align 16
  %1538 = mul <4 x i32> %1537, %764
  %1539 = add <4 x i32> %1536, %14
  %1540 = add <4 x i32> %1539, %1538
  %1541 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1540, i32 %2) #8
  store <4 x i32> %1541, <4 x i32>* %501, align 16
  %1542 = mul <4 x i32> %1535, %764
  %1543 = mul <4 x i32> %1537, %745
  %1544 = add <4 x i32> %1542, %14
  %1545 = add <4 x i32> %1544, %1543
  %1546 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1545, i32 %2) #8
  store <4 x i32> %1546, <4 x i32>* %530, align 16
  %1547 = mul <4 x i32> %1527, %764
  %1548 = mul <4 x i32> %1530, %745
  %1549 = add <4 x i32> %1547, %14
  %1550 = add <4 x i32> %1549, %1548
  %1551 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1550, i32 %2) #8
  store <4 x i32> %1551, <4 x i32>* %535, align 16
  %1552 = mul <4 x i32> %1520, %745
  %1553 = mul <4 x i32> %1522, %749
  %1554 = add <4 x i32> %1552, %14
  %1555 = add <4 x i32> %1554, %1553
  %1556 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1555, i32 %2) #8
  store <4 x i32> %1556, <4 x i32>* %540, align 16
  %1557 = mul <4 x i32> %1512, %745
  %1558 = mul <4 x i32> %1514, %749
  %1559 = add <4 x i32> %1557, %14
  %1560 = add <4 x i32> %1559, %1558
  %1561 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1560, i32 %2) #8
  store <4 x i32> %1561, <4 x i32>* %545, align 16
  %1562 = mul <4 x i32> %1505, %756
  %1563 = mul <4 x i32> %1507, %753
  %1564 = add <4 x i32> %1562, %14
  %1565 = add <4 x i32> %1564, %1563
  %1566 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1565, i32 %2) #8
  store <4 x i32> %1566, <4 x i32>* %570, align 16
  %1567 = mul <4 x i32> %1497, %756
  %1568 = mul <4 x i32> %1500, %753
  %1569 = add <4 x i32> %1567, %14
  %1570 = add <4 x i32> %1569, %1568
  %1571 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1570, i32 %2) #8
  store <4 x i32> %1571, <4 x i32>* %575, align 16
  %1572 = mul <4 x i32> %1490, %753
  %1573 = mul <4 x i32> %1492, %741
  %1574 = add <4 x i32> %1572, %14
  %1575 = add <4 x i32> %1574, %1573
  %1576 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1575, i32 %2) #8
  store <4 x i32> %1576, <4 x i32>* %580, align 16
  %1577 = mul <4 x i32> %1482, %753
  %1578 = mul <4 x i32> %1484, %741
  %1579 = add <4 x i32> %1577, %14
  %1580 = add <4 x i32> %1579, %1578
  %1581 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1580, i32 %2) #8
  store <4 x i32> %1581, <4 x i32>* %585, align 16
  %1582 = load <4 x i32>, <4 x i32>* %1299, align 16
  %1583 = load <4 x i32>, <4 x i32>* %1313, align 16
  %1584 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 3
  %1585 = add <4 x i32> %1583, %1582
  %1586 = sub <4 x i32> %1582, %1583
  %1587 = icmp sgt <4 x i32> %1585, %24
  %1588 = select <4 x i1> %1587, <4 x i32> %1585, <4 x i32> %24
  %1589 = icmp slt <4 x i32> %1588, %27
  %1590 = select <4 x i1> %1589, <4 x i32> %1588, <4 x i32> %27
  %1591 = icmp sgt <4 x i32> %1586, %24
  %1592 = select <4 x i1> %1591, <4 x i32> %1586, <4 x i32> %24
  %1593 = icmp slt <4 x i32> %1592, %27
  %1594 = select <4 x i1> %1593, <4 x i32> %1592, <4 x i32> %27
  store <4 x i32> %1590, <4 x i32>* %1294, align 16
  %1595 = bitcast <2 x i64>* %1584 to <4 x i32>*
  store <4 x i32> %1594, <4 x i32>* %1595, align 16
  %1596 = load <4 x i32>, <4 x i32>* %1301, align 16
  %1597 = load <4 x i32>, <4 x i32>* %1308, align 16
  %1598 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 1
  %1599 = add <4 x i32> %1597, %1596
  %1600 = sub <4 x i32> %1596, %1597
  %1601 = icmp sgt <4 x i32> %1599, %24
  %1602 = select <4 x i1> %1601, <4 x i32> %1599, <4 x i32> %24
  %1603 = icmp slt <4 x i32> %1602, %27
  %1604 = select <4 x i1> %1603, <4 x i32> %1602, <4 x i32> %27
  %1605 = icmp sgt <4 x i32> %1600, %24
  %1606 = select <4 x i1> %1605, <4 x i32> %1600, <4 x i32> %24
  %1607 = icmp slt <4 x i32> %1606, %27
  %1608 = select <4 x i1> %1607, <4 x i32> %1606, <4 x i32> %27
  %1609 = bitcast <2 x i64>* %1598 to <4 x i32>*
  store <4 x i32> %1604, <4 x i32>* %1609, align 16
  store <4 x i32> %1608, <4 x i32>* %1302, align 16
  %1610 = load <2 x i64>, <2 x i64>* %395, align 16
  store <2 x i64> %1610, <2 x i64>* %1071, align 16
  %1611 = load <2 x i64>, <2 x i64>* %1330, align 16
  store <2 x i64> %1611, <2 x i64>* %1088, align 16
  %1612 = load <4 x i32>, <4 x i32>* %1327, align 16
  %1613 = mul <4 x i32> %1612, %762
  %1614 = load <4 x i32>, <4 x i32>* %1073, align 16
  %1615 = mul <4 x i32> %1614, %747
  %1616 = add <4 x i32> %1615, %14
  %1617 = add <4 x i32> %1616, %1613
  %1618 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1617, i32 %2) #8
  store <4 x i32> %1618, <4 x i32>* %1079, align 16
  %1619 = mul <4 x i32> %1612, %747
  %1620 = add <4 x i32> %1616, %1619
  %1621 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1620, i32 %2) #8
  store <4 x i32> %1621, <4 x i32>* %1084, align 16
  %1622 = load <4 x i32>, <4 x i32>* %776, align 16
  %1623 = load <4 x i32>, <4 x i32>* %797, align 16
  %1624 = add <4 x i32> %1623, %1622
  %1625 = sub <4 x i32> %1622, %1623
  %1626 = icmp sgt <4 x i32> %1624, %24
  %1627 = select <4 x i1> %1626, <4 x i32> %1624, <4 x i32> %24
  %1628 = icmp slt <4 x i32> %1627, %27
  %1629 = select <4 x i1> %1628, <4 x i32> %1627, <4 x i32> %27
  %1630 = icmp sgt <4 x i32> %1625, %24
  %1631 = select <4 x i1> %1630, <4 x i32> %1625, <4 x i32> %24
  %1632 = icmp slt <4 x i32> %1631, %27
  %1633 = select <4 x i1> %1632, <4 x i32> %1631, <4 x i32> %27
  store <4 x i32> %1629, <4 x i32>* %770, align 16
  store <4 x i32> %1633, <4 x i32>* %1117, align 16
  %1634 = load <4 x i32>, <4 x i32>* %783, align 16
  %1635 = load <4 x i32>, <4 x i32>* %790, align 16
  %1636 = add <4 x i32> %1635, %1634
  %1637 = sub <4 x i32> %1634, %1635
  %1638 = icmp sgt <4 x i32> %1636, %24
  %1639 = select <4 x i1> %1638, <4 x i32> %1636, <4 x i32> %24
  %1640 = icmp slt <4 x i32> %1639, %27
  %1641 = select <4 x i1> %1640, <4 x i32> %1639, <4 x i32> %27
  %1642 = icmp sgt <4 x i32> %1637, %24
  %1643 = select <4 x i1> %1642, <4 x i32> %1637, <4 x i32> %24
  %1644 = icmp slt <4 x i32> %1643, %27
  %1645 = select <4 x i1> %1644, <4 x i32> %1643, <4 x i32> %27
  store <4 x i32> %1641, <4 x i32>* %1103, align 16
  store <4 x i32> %1645, <4 x i32>* %784, align 16
  %1646 = load <4 x i32>, <4 x i32>* %817, align 16
  %1647 = load <4 x i32>, <4 x i32>* %802, align 16
  %1648 = add <4 x i32> %1647, %1646
  %1649 = sub <4 x i32> %1646, %1647
  %1650 = icmp sgt <4 x i32> %1648, %24
  %1651 = select <4 x i1> %1650, <4 x i32> %1648, <4 x i32> %24
  %1652 = icmp slt <4 x i32> %1651, %27
  %1653 = select <4 x i1> %1652, <4 x i32> %1651, <4 x i32> %27
  %1654 = icmp sgt <4 x i32> %1649, %24
  %1655 = select <4 x i1> %1654, <4 x i32> %1649, <4 x i32> %24
  %1656 = icmp slt <4 x i32> %1655, %27
  %1657 = select <4 x i1> %1656, <4 x i32> %1655, <4 x i32> %27
  store <4 x i32> %1653, <4 x i32>* %1145, align 16
  store <4 x i32> %1657, <4 x i32>* %791, align 16
  %1658 = load <4 x i32>, <4 x i32>* %812, align 16
  %1659 = load <4 x i32>, <4 x i32>* %807, align 16
  %1660 = add <4 x i32> %1659, %1658
  %1661 = sub <4 x i32> %1658, %1659
  %1662 = icmp sgt <4 x i32> %1660, %24
  %1663 = select <4 x i1> %1662, <4 x i32> %1660, <4 x i32> %24
  %1664 = icmp slt <4 x i32> %1663, %27
  %1665 = select <4 x i1> %1664, <4 x i32> %1663, <4 x i32> %27
  %1666 = icmp sgt <4 x i32> %1661, %24
  %1667 = select <4 x i1> %1666, <4 x i32> %1661, <4 x i32> %24
  %1668 = icmp slt <4 x i32> %1667, %27
  %1669 = select <4 x i1> %1668, <4 x i32> %1667, <4 x i32> %27
  store <4 x i32> %1665, <4 x i32>* %777, align 16
  store <4 x i32> %1669, <4 x i32>* %1131, align 16
  %1670 = load <2 x i64>, <2 x i64>* %359, align 16
  store <2 x i64> %1670, <2 x i64>* %601, align 16
  %1671 = load <2 x i64>, <2 x i64>* %820, align 16
  store <2 x i64> %1671, <2 x i64>* %608, align 16
  %1672 = load <2 x i64>, <2 x i64>* %368, align 16
  store <2 x i64> %1672, <2 x i64>* %643, align 16
  %1673 = load <2 x i64>, <2 x i64>* %862, align 16
  store <2 x i64> %1673, <2 x i64>* %650, align 16
  %1674 = load <2 x i64>, <2 x i64>* %371, align 16
  store <2 x i64> %1674, <2 x i64>* %655, align 16
  %1675 = load <2 x i64>, <2 x i64>* %876, align 16
  store <2 x i64> %1675, <2 x i64>* %660, align 16
  %1676 = load <2 x i64>, <2 x i64>* %380, align 16
  store <2 x i64> %1676, <2 x i64>* %685, align 16
  %1677 = load <2 x i64>, <2 x i64>* %918, align 16
  store <2 x i64> %1677, <2 x i64>* %690, align 16
  %1678 = load <4 x i32>, <4 x i32>* %610, align 16
  %1679 = mul <4 x i32> %1678, %758
  %1680 = load <4 x i32>, <4 x i32>* %915, align 16
  %1681 = mul <4 x i32> %1680, %751
  %1682 = add <4 x i32> %1679, %14
  %1683 = add <4 x i32> %1682, %1681
  %1684 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1683, i32 %2) #8
  store <4 x i32> %1684, <4 x i32>* %616, align 16
  %1685 = load <4 x i32>, <4 x i32>* %845, align 16
  %1686 = mul <4 x i32> %1685, %758
  %1687 = load <4 x i32>, <4 x i32>* %617, align 16
  %1688 = mul <4 x i32> %1687, %751
  %1689 = add <4 x i32> %1686, %14
  %1690 = add <4 x i32> %1689, %1688
  %1691 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1690, i32 %2) #8
  store <4 x i32> %1691, <4 x i32>* %623, align 16
  %1692 = load <4 x i32>, <4 x i32>* %624, align 16
  %1693 = mul <4 x i32> %1692, %766
  %1694 = load <4 x i32>, <4 x i32>* %901, align 16
  %1695 = mul <4 x i32> %1694, %758
  %1696 = add <4 x i32> %1693, %14
  %1697 = add <4 x i32> %1696, %1695
  %1698 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1697, i32 %2) #8
  store <4 x i32> %1698, <4 x i32>* %630, align 16
  %1699 = load <4 x i32>, <4 x i32>* %859, align 16
  %1700 = mul <4 x i32> %1699, %766
  %1701 = load <4 x i32>, <4 x i32>* %631, align 16
  %1702 = mul <4 x i32> %1701, %758
  %1703 = add <4 x i32> %1700, %14
  %1704 = add <4 x i32> %1703, %1702
  %1705 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1704, i32 %2) #8
  store <4 x i32> %1705, <4 x i32>* %637, align 16
  %1706 = mul <4 x i32> %1699, %758
  %1707 = mul <4 x i32> %1701, %751
  %1708 = add <4 x i32> %1706, %14
  %1709 = add <4 x i32> %1708, %1707
  %1710 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1709, i32 %2) #8
  store <4 x i32> %1710, <4 x i32>* %666, align 16
  %1711 = mul <4 x i32> %1692, %758
  %1712 = mul <4 x i32> %1694, %751
  %1713 = add <4 x i32> %1711, %14
  %1714 = add <4 x i32> %1713, %1712
  %1715 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1714, i32 %2) #8
  store <4 x i32> %1715, <4 x i32>* %671, align 16
  %1716 = mul <4 x i32> %1685, %751
  %1717 = mul <4 x i32> %1687, %743
  %1718 = add <4 x i32> %1716, %14
  %1719 = add <4 x i32> %1718, %1717
  %1720 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1719, i32 %2) #8
  store <4 x i32> %1720, <4 x i32>* %676, align 16
  %1721 = mul <4 x i32> %1678, %751
  %1722 = mul <4 x i32> %1680, %743
  %1723 = add <4 x i32> %1721, %14
  %1724 = add <4 x i32> %1723, %1722
  %1725 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1724, i32 %2) #8
  store <4 x i32> %1725, <4 x i32>* %681, align 16
  %1726 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 32
  %1727 = bitcast <2 x i64>* %1726 to <4 x i32>*
  %1728 = load <4 x i32>, <4 x i32>* %1727, align 16
  %1729 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 39
  %1730 = bitcast <2 x i64>* %1729 to <4 x i32>*
  %1731 = load <4 x i32>, <4 x i32>* %1730, align 16
  %1732 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 32
  %1733 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 39
  %1734 = add <4 x i32> %1731, %1728
  %1735 = sub <4 x i32> %1728, %1731
  %1736 = icmp sgt <4 x i32> %1734, %24
  %1737 = select <4 x i1> %1736, <4 x i32> %1734, <4 x i32> %24
  %1738 = icmp slt <4 x i32> %1737, %27
  %1739 = select <4 x i1> %1738, <4 x i32> %1737, <4 x i32> %27
  %1740 = icmp sgt <4 x i32> %1735, %24
  %1741 = select <4 x i1> %1740, <4 x i32> %1735, <4 x i32> %24
  %1742 = icmp slt <4 x i32> %1741, %27
  %1743 = select <4 x i1> %1742, <4 x i32> %1741, <4 x i32> %27
  %1744 = bitcast <2 x i64>* %1732 to <4 x i32>*
  store <4 x i32> %1739, <4 x i32>* %1744, align 16
  %1745 = bitcast <2 x i64>* %1733 to <4 x i32>*
  store <4 x i32> %1743, <4 x i32>* %1745, align 16
  %1746 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 47
  %1747 = bitcast <2 x i64>* %1746 to <4 x i32>*
  %1748 = load <4 x i32>, <4 x i32>* %1747, align 16
  %1749 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 40
  %1750 = bitcast <2 x i64>* %1749 to <4 x i32>*
  %1751 = load <4 x i32>, <4 x i32>* %1750, align 16
  %1752 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 47
  %1753 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 40
  %1754 = add <4 x i32> %1751, %1748
  %1755 = sub <4 x i32> %1748, %1751
  %1756 = icmp sgt <4 x i32> %1754, %24
  %1757 = select <4 x i1> %1756, <4 x i32> %1754, <4 x i32> %24
  %1758 = icmp slt <4 x i32> %1757, %27
  %1759 = select <4 x i1> %1758, <4 x i32> %1757, <4 x i32> %27
  %1760 = icmp sgt <4 x i32> %1755, %24
  %1761 = select <4 x i1> %1760, <4 x i32> %1755, <4 x i32> %24
  %1762 = icmp slt <4 x i32> %1761, %27
  %1763 = select <4 x i1> %1762, <4 x i32> %1761, <4 x i32> %27
  %1764 = bitcast <2 x i64>* %1752 to <4 x i32>*
  store <4 x i32> %1759, <4 x i32>* %1764, align 16
  %1765 = bitcast <2 x i64>* %1753 to <4 x i32>*
  store <4 x i32> %1763, <4 x i32>* %1765, align 16
  %1766 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 33
  %1767 = bitcast <2 x i64>* %1766 to <4 x i32>*
  %1768 = load <4 x i32>, <4 x i32>* %1767, align 16
  %1769 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 38
  %1770 = bitcast <2 x i64>* %1769 to <4 x i32>*
  %1771 = load <4 x i32>, <4 x i32>* %1770, align 16
  %1772 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 33
  %1773 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 38
  %1774 = add <4 x i32> %1771, %1768
  %1775 = sub <4 x i32> %1768, %1771
  %1776 = icmp sgt <4 x i32> %1774, %24
  %1777 = select <4 x i1> %1776, <4 x i32> %1774, <4 x i32> %24
  %1778 = icmp slt <4 x i32> %1777, %27
  %1779 = select <4 x i1> %1778, <4 x i32> %1777, <4 x i32> %27
  %1780 = icmp sgt <4 x i32> %1775, %24
  %1781 = select <4 x i1> %1780, <4 x i32> %1775, <4 x i32> %24
  %1782 = icmp slt <4 x i32> %1781, %27
  %1783 = select <4 x i1> %1782, <4 x i32> %1781, <4 x i32> %27
  %1784 = bitcast <2 x i64>* %1772 to <4 x i32>*
  store <4 x i32> %1779, <4 x i32>* %1784, align 16
  %1785 = bitcast <2 x i64>* %1773 to <4 x i32>*
  store <4 x i32> %1783, <4 x i32>* %1785, align 16
  %1786 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 46
  %1787 = bitcast <2 x i64>* %1786 to <4 x i32>*
  %1788 = load <4 x i32>, <4 x i32>* %1787, align 16
  %1789 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 41
  %1790 = bitcast <2 x i64>* %1789 to <4 x i32>*
  %1791 = load <4 x i32>, <4 x i32>* %1790, align 16
  %1792 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 46
  %1793 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 41
  %1794 = add <4 x i32> %1791, %1788
  %1795 = sub <4 x i32> %1788, %1791
  %1796 = icmp sgt <4 x i32> %1794, %24
  %1797 = select <4 x i1> %1796, <4 x i32> %1794, <4 x i32> %24
  %1798 = icmp slt <4 x i32> %1797, %27
  %1799 = select <4 x i1> %1798, <4 x i32> %1797, <4 x i32> %27
  %1800 = icmp sgt <4 x i32> %1795, %24
  %1801 = select <4 x i1> %1800, <4 x i32> %1795, <4 x i32> %24
  %1802 = icmp slt <4 x i32> %1801, %27
  %1803 = select <4 x i1> %1802, <4 x i32> %1801, <4 x i32> %27
  %1804 = bitcast <2 x i64>* %1792 to <4 x i32>*
  store <4 x i32> %1799, <4 x i32>* %1804, align 16
  %1805 = bitcast <2 x i64>* %1793 to <4 x i32>*
  store <4 x i32> %1803, <4 x i32>* %1805, align 16
  %1806 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 34
  %1807 = bitcast <2 x i64>* %1806 to <4 x i32>*
  %1808 = load <4 x i32>, <4 x i32>* %1807, align 16
  %1809 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 37
  %1810 = bitcast <2 x i64>* %1809 to <4 x i32>*
  %1811 = load <4 x i32>, <4 x i32>* %1810, align 16
  %1812 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 34
  %1813 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 37
  %1814 = add <4 x i32> %1811, %1808
  %1815 = sub <4 x i32> %1808, %1811
  %1816 = icmp sgt <4 x i32> %1814, %24
  %1817 = select <4 x i1> %1816, <4 x i32> %1814, <4 x i32> %24
  %1818 = icmp slt <4 x i32> %1817, %27
  %1819 = select <4 x i1> %1818, <4 x i32> %1817, <4 x i32> %27
  %1820 = icmp sgt <4 x i32> %1815, %24
  %1821 = select <4 x i1> %1820, <4 x i32> %1815, <4 x i32> %24
  %1822 = icmp slt <4 x i32> %1821, %27
  %1823 = select <4 x i1> %1822, <4 x i32> %1821, <4 x i32> %27
  %1824 = bitcast <2 x i64>* %1812 to <4 x i32>*
  store <4 x i32> %1819, <4 x i32>* %1824, align 16
  %1825 = bitcast <2 x i64>* %1813 to <4 x i32>*
  store <4 x i32> %1823, <4 x i32>* %1825, align 16
  %1826 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 45
  %1827 = bitcast <2 x i64>* %1826 to <4 x i32>*
  %1828 = load <4 x i32>, <4 x i32>* %1827, align 16
  %1829 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 42
  %1830 = bitcast <2 x i64>* %1829 to <4 x i32>*
  %1831 = load <4 x i32>, <4 x i32>* %1830, align 16
  %1832 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 45
  %1833 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 42
  %1834 = add <4 x i32> %1831, %1828
  %1835 = sub <4 x i32> %1828, %1831
  %1836 = icmp sgt <4 x i32> %1834, %24
  %1837 = select <4 x i1> %1836, <4 x i32> %1834, <4 x i32> %24
  %1838 = icmp slt <4 x i32> %1837, %27
  %1839 = select <4 x i1> %1838, <4 x i32> %1837, <4 x i32> %27
  %1840 = icmp sgt <4 x i32> %1835, %24
  %1841 = select <4 x i1> %1840, <4 x i32> %1835, <4 x i32> %24
  %1842 = icmp slt <4 x i32> %1841, %27
  %1843 = select <4 x i1> %1842, <4 x i32> %1841, <4 x i32> %27
  %1844 = bitcast <2 x i64>* %1832 to <4 x i32>*
  store <4 x i32> %1839, <4 x i32>* %1844, align 16
  %1845 = bitcast <2 x i64>* %1833 to <4 x i32>*
  store <4 x i32> %1843, <4 x i32>* %1845, align 16
  %1846 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 35
  %1847 = bitcast <2 x i64>* %1846 to <4 x i32>*
  %1848 = load <4 x i32>, <4 x i32>* %1847, align 16
  %1849 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 36
  %1850 = bitcast <2 x i64>* %1849 to <4 x i32>*
  %1851 = load <4 x i32>, <4 x i32>* %1850, align 16
  %1852 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 35
  %1853 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 36
  %1854 = add <4 x i32> %1851, %1848
  %1855 = sub <4 x i32> %1848, %1851
  %1856 = icmp sgt <4 x i32> %1854, %24
  %1857 = select <4 x i1> %1856, <4 x i32> %1854, <4 x i32> %24
  %1858 = icmp slt <4 x i32> %1857, %27
  %1859 = select <4 x i1> %1858, <4 x i32> %1857, <4 x i32> %27
  %1860 = icmp sgt <4 x i32> %1855, %24
  %1861 = select <4 x i1> %1860, <4 x i32> %1855, <4 x i32> %24
  %1862 = icmp slt <4 x i32> %1861, %27
  %1863 = select <4 x i1> %1862, <4 x i32> %1861, <4 x i32> %27
  %1864 = bitcast <2 x i64>* %1852 to <4 x i32>*
  store <4 x i32> %1859, <4 x i32>* %1864, align 16
  %1865 = bitcast <2 x i64>* %1853 to <4 x i32>*
  store <4 x i32> %1863, <4 x i32>* %1865, align 16
  %1866 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 44
  %1867 = bitcast <2 x i64>* %1866 to <4 x i32>*
  %1868 = load <4 x i32>, <4 x i32>* %1867, align 16
  %1869 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 43
  %1870 = bitcast <2 x i64>* %1869 to <4 x i32>*
  %1871 = load <4 x i32>, <4 x i32>* %1870, align 16
  %1872 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 44
  %1873 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 43
  %1874 = add <4 x i32> %1871, %1868
  %1875 = sub <4 x i32> %1868, %1871
  %1876 = icmp sgt <4 x i32> %1874, %24
  %1877 = select <4 x i1> %1876, <4 x i32> %1874, <4 x i32> %24
  %1878 = icmp slt <4 x i32> %1877, %27
  %1879 = select <4 x i1> %1878, <4 x i32> %1877, <4 x i32> %27
  %1880 = icmp sgt <4 x i32> %1875, %24
  %1881 = select <4 x i1> %1880, <4 x i32> %1875, <4 x i32> %24
  %1882 = icmp slt <4 x i32> %1881, %27
  %1883 = select <4 x i1> %1882, <4 x i32> %1881, <4 x i32> %27
  %1884 = bitcast <2 x i64>* %1872 to <4 x i32>*
  store <4 x i32> %1879, <4 x i32>* %1884, align 16
  %1885 = bitcast <2 x i64>* %1873 to <4 x i32>*
  store <4 x i32> %1883, <4 x i32>* %1885, align 16
  %1886 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 48
  %1887 = bitcast <2 x i64>* %1886 to <4 x i32>*
  %1888 = load <4 x i32>, <4 x i32>* %1887, align 16
  %1889 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 55
  %1890 = bitcast <2 x i64>* %1889 to <4 x i32>*
  %1891 = load <4 x i32>, <4 x i32>* %1890, align 16
  %1892 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 48
  %1893 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 55
  %1894 = add <4 x i32> %1891, %1888
  %1895 = sub <4 x i32> %1888, %1891
  %1896 = icmp sgt <4 x i32> %1894, %24
  %1897 = select <4 x i1> %1896, <4 x i32> %1894, <4 x i32> %24
  %1898 = icmp slt <4 x i32> %1897, %27
  %1899 = select <4 x i1> %1898, <4 x i32> %1897, <4 x i32> %27
  %1900 = icmp sgt <4 x i32> %1895, %24
  %1901 = select <4 x i1> %1900, <4 x i32> %1895, <4 x i32> %24
  %1902 = icmp slt <4 x i32> %1901, %27
  %1903 = select <4 x i1> %1902, <4 x i32> %1901, <4 x i32> %27
  %1904 = bitcast <2 x i64>* %1892 to <4 x i32>*
  store <4 x i32> %1899, <4 x i32>* %1904, align 16
  %1905 = bitcast <2 x i64>* %1893 to <4 x i32>*
  store <4 x i32> %1903, <4 x i32>* %1905, align 16
  %1906 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 63
  %1907 = bitcast <2 x i64>* %1906 to <4 x i32>*
  %1908 = load <4 x i32>, <4 x i32>* %1907, align 16
  %1909 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 56
  %1910 = bitcast <2 x i64>* %1909 to <4 x i32>*
  %1911 = load <4 x i32>, <4 x i32>* %1910, align 16
  %1912 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 63
  %1913 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 56
  %1914 = add <4 x i32> %1911, %1908
  %1915 = sub <4 x i32> %1908, %1911
  %1916 = icmp sgt <4 x i32> %1914, %24
  %1917 = select <4 x i1> %1916, <4 x i32> %1914, <4 x i32> %24
  %1918 = icmp slt <4 x i32> %1917, %27
  %1919 = select <4 x i1> %1918, <4 x i32> %1917, <4 x i32> %27
  %1920 = icmp sgt <4 x i32> %1915, %24
  %1921 = select <4 x i1> %1920, <4 x i32> %1915, <4 x i32> %24
  %1922 = icmp slt <4 x i32> %1921, %27
  %1923 = select <4 x i1> %1922, <4 x i32> %1921, <4 x i32> %27
  %1924 = bitcast <2 x i64>* %1912 to <4 x i32>*
  store <4 x i32> %1919, <4 x i32>* %1924, align 16
  %1925 = bitcast <2 x i64>* %1913 to <4 x i32>*
  store <4 x i32> %1923, <4 x i32>* %1925, align 16
  %1926 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 49
  %1927 = bitcast <2 x i64>* %1926 to <4 x i32>*
  %1928 = load <4 x i32>, <4 x i32>* %1927, align 16
  %1929 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 54
  %1930 = bitcast <2 x i64>* %1929 to <4 x i32>*
  %1931 = load <4 x i32>, <4 x i32>* %1930, align 16
  %1932 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 49
  %1933 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 54
  %1934 = add <4 x i32> %1931, %1928
  %1935 = sub <4 x i32> %1928, %1931
  %1936 = icmp sgt <4 x i32> %1934, %24
  %1937 = select <4 x i1> %1936, <4 x i32> %1934, <4 x i32> %24
  %1938 = icmp slt <4 x i32> %1937, %27
  %1939 = select <4 x i1> %1938, <4 x i32> %1937, <4 x i32> %27
  %1940 = icmp sgt <4 x i32> %1935, %24
  %1941 = select <4 x i1> %1940, <4 x i32> %1935, <4 x i32> %24
  %1942 = icmp slt <4 x i32> %1941, %27
  %1943 = select <4 x i1> %1942, <4 x i32> %1941, <4 x i32> %27
  %1944 = bitcast <2 x i64>* %1932 to <4 x i32>*
  store <4 x i32> %1939, <4 x i32>* %1944, align 16
  %1945 = bitcast <2 x i64>* %1933 to <4 x i32>*
  store <4 x i32> %1943, <4 x i32>* %1945, align 16
  %1946 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 62
  %1947 = bitcast <2 x i64>* %1946 to <4 x i32>*
  %1948 = load <4 x i32>, <4 x i32>* %1947, align 16
  %1949 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 57
  %1950 = bitcast <2 x i64>* %1949 to <4 x i32>*
  %1951 = load <4 x i32>, <4 x i32>* %1950, align 16
  %1952 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 62
  %1953 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 57
  %1954 = add <4 x i32> %1951, %1948
  %1955 = sub <4 x i32> %1948, %1951
  %1956 = icmp sgt <4 x i32> %1954, %24
  %1957 = select <4 x i1> %1956, <4 x i32> %1954, <4 x i32> %24
  %1958 = icmp slt <4 x i32> %1957, %27
  %1959 = select <4 x i1> %1958, <4 x i32> %1957, <4 x i32> %27
  %1960 = icmp sgt <4 x i32> %1955, %24
  %1961 = select <4 x i1> %1960, <4 x i32> %1955, <4 x i32> %24
  %1962 = icmp slt <4 x i32> %1961, %27
  %1963 = select <4 x i1> %1962, <4 x i32> %1961, <4 x i32> %27
  %1964 = bitcast <2 x i64>* %1952 to <4 x i32>*
  store <4 x i32> %1959, <4 x i32>* %1964, align 16
  %1965 = bitcast <2 x i64>* %1953 to <4 x i32>*
  store <4 x i32> %1963, <4 x i32>* %1965, align 16
  %1966 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 50
  %1967 = bitcast <2 x i64>* %1966 to <4 x i32>*
  %1968 = load <4 x i32>, <4 x i32>* %1967, align 16
  %1969 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 53
  %1970 = bitcast <2 x i64>* %1969 to <4 x i32>*
  %1971 = load <4 x i32>, <4 x i32>* %1970, align 16
  %1972 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 50
  %1973 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 53
  %1974 = add <4 x i32> %1971, %1968
  %1975 = sub <4 x i32> %1968, %1971
  %1976 = icmp sgt <4 x i32> %1974, %24
  %1977 = select <4 x i1> %1976, <4 x i32> %1974, <4 x i32> %24
  %1978 = icmp slt <4 x i32> %1977, %27
  %1979 = select <4 x i1> %1978, <4 x i32> %1977, <4 x i32> %27
  %1980 = icmp sgt <4 x i32> %1975, %24
  %1981 = select <4 x i1> %1980, <4 x i32> %1975, <4 x i32> %24
  %1982 = icmp slt <4 x i32> %1981, %27
  %1983 = select <4 x i1> %1982, <4 x i32> %1981, <4 x i32> %27
  %1984 = bitcast <2 x i64>* %1972 to <4 x i32>*
  store <4 x i32> %1979, <4 x i32>* %1984, align 16
  %1985 = bitcast <2 x i64>* %1973 to <4 x i32>*
  store <4 x i32> %1983, <4 x i32>* %1985, align 16
  %1986 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 61
  %1987 = bitcast <2 x i64>* %1986 to <4 x i32>*
  %1988 = load <4 x i32>, <4 x i32>* %1987, align 16
  %1989 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 58
  %1990 = bitcast <2 x i64>* %1989 to <4 x i32>*
  %1991 = load <4 x i32>, <4 x i32>* %1990, align 16
  %1992 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 61
  %1993 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 58
  %1994 = add <4 x i32> %1991, %1988
  %1995 = sub <4 x i32> %1988, %1991
  %1996 = icmp sgt <4 x i32> %1994, %24
  %1997 = select <4 x i1> %1996, <4 x i32> %1994, <4 x i32> %24
  %1998 = icmp slt <4 x i32> %1997, %27
  %1999 = select <4 x i1> %1998, <4 x i32> %1997, <4 x i32> %27
  %2000 = icmp sgt <4 x i32> %1995, %24
  %2001 = select <4 x i1> %2000, <4 x i32> %1995, <4 x i32> %24
  %2002 = icmp slt <4 x i32> %2001, %27
  %2003 = select <4 x i1> %2002, <4 x i32> %2001, <4 x i32> %27
  %2004 = bitcast <2 x i64>* %1992 to <4 x i32>*
  store <4 x i32> %1999, <4 x i32>* %2004, align 16
  %2005 = bitcast <2 x i64>* %1993 to <4 x i32>*
  store <4 x i32> %2003, <4 x i32>* %2005, align 16
  %2006 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 51
  %2007 = bitcast <2 x i64>* %2006 to <4 x i32>*
  %2008 = load <4 x i32>, <4 x i32>* %2007, align 16
  %2009 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 52
  %2010 = bitcast <2 x i64>* %2009 to <4 x i32>*
  %2011 = load <4 x i32>, <4 x i32>* %2010, align 16
  %2012 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 51
  %2013 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 52
  %2014 = add <4 x i32> %2011, %2008
  %2015 = sub <4 x i32> %2008, %2011
  %2016 = icmp sgt <4 x i32> %2014, %24
  %2017 = select <4 x i1> %2016, <4 x i32> %2014, <4 x i32> %24
  %2018 = icmp slt <4 x i32> %2017, %27
  %2019 = select <4 x i1> %2018, <4 x i32> %2017, <4 x i32> %27
  %2020 = icmp sgt <4 x i32> %2015, %24
  %2021 = select <4 x i1> %2020, <4 x i32> %2015, <4 x i32> %24
  %2022 = icmp slt <4 x i32> %2021, %27
  %2023 = select <4 x i1> %2022, <4 x i32> %2021, <4 x i32> %27
  %2024 = bitcast <2 x i64>* %2012 to <4 x i32>*
  store <4 x i32> %2019, <4 x i32>* %2024, align 16
  %2025 = bitcast <2 x i64>* %2013 to <4 x i32>*
  store <4 x i32> %2023, <4 x i32>* %2025, align 16
  %2026 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 60
  %2027 = bitcast <2 x i64>* %2026 to <4 x i32>*
  %2028 = load <4 x i32>, <4 x i32>* %2027, align 16
  %2029 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 59
  %2030 = bitcast <2 x i64>* %2029 to <4 x i32>*
  %2031 = load <4 x i32>, <4 x i32>* %2030, align 16
  %2032 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 60
  %2033 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 59
  %2034 = add <4 x i32> %2031, %2028
  %2035 = sub <4 x i32> %2028, %2031
  %2036 = icmp sgt <4 x i32> %2034, %24
  %2037 = select <4 x i1> %2036, <4 x i32> %2034, <4 x i32> %24
  %2038 = icmp slt <4 x i32> %2037, %27
  %2039 = select <4 x i1> %2038, <4 x i32> %2037, <4 x i32> %27
  %2040 = icmp sgt <4 x i32> %2035, %24
  %2041 = select <4 x i1> %2040, <4 x i32> %2035, <4 x i32> %24
  %2042 = icmp slt <4 x i32> %2041, %27
  %2043 = select <4 x i1> %2042, <4 x i32> %2041, <4 x i32> %27
  %2044 = bitcast <2 x i64>* %2032 to <4 x i32>*
  store <4 x i32> %2039, <4 x i32>* %2044, align 16
  %2045 = bitcast <2 x i64>* %2033 to <4 x i32>*
  store <4 x i32> %2043, <4 x i32>* %2045, align 16
  %2046 = bitcast [64 x <2 x i64>]* %7 to <4 x i32>*
  %2047 = load <4 x i32>, <4 x i32>* %2046, align 16
  %2048 = load <4 x i32>, <4 x i32>* %1089, align 16
  %2049 = add <4 x i32> %2048, %2047
  %2050 = sub <4 x i32> %2047, %2048
  %2051 = icmp sgt <4 x i32> %2049, %24
  %2052 = select <4 x i1> %2051, <4 x i32> %2049, <4 x i32> %24
  %2053 = icmp slt <4 x i32> %2052, %27
  %2054 = select <4 x i1> %2053, <4 x i32> %2052, <4 x i32> %27
  %2055 = icmp sgt <4 x i32> %2050, %24
  %2056 = select <4 x i1> %2055, <4 x i32> %2050, <4 x i32> %24
  %2057 = icmp slt <4 x i32> %2056, %27
  %2058 = select <4 x i1> %2057, <4 x i32> %2056, <4 x i32> %27
  %2059 = bitcast [64 x <2 x i64>]* %8 to <4 x i32>*
  store <4 x i32> %2054, <4 x i32>* %2059, align 16
  store <4 x i32> %2058, <4 x i32>* %1341, align 16
  %2060 = load <4 x i32>, <4 x i32>* %1609, align 16
  %2061 = load <4 x i32>, <4 x i32>* %1084, align 16
  %2062 = add <4 x i32> %2061, %2060
  %2063 = sub <4 x i32> %2060, %2061
  %2064 = icmp sgt <4 x i32> %2062, %24
  %2065 = select <4 x i1> %2064, <4 x i32> %2062, <4 x i32> %24
  %2066 = icmp slt <4 x i32> %2065, %27
  %2067 = select <4 x i1> %2066, <4 x i32> %2065, <4 x i32> %27
  %2068 = icmp sgt <4 x i32> %2063, %24
  %2069 = select <4 x i1> %2068, <4 x i32> %2063, <4 x i32> %24
  %2070 = icmp slt <4 x i32> %2069, %27
  %2071 = select <4 x i1> %2070, <4 x i32> %2069, <4 x i32> %27
  store <4 x i32> %2067, <4 x i32>* %1301, align 16
  store <4 x i32> %2071, <4 x i32>* %1073, align 16
  %2072 = load <4 x i32>, <4 x i32>* %1302, align 16
  %2073 = load <4 x i32>, <4 x i32>* %1079, align 16
  %2074 = add <4 x i32> %2073, %2072
  %2075 = sub <4 x i32> %2072, %2073
  %2076 = icmp sgt <4 x i32> %2074, %24
  %2077 = select <4 x i1> %2076, <4 x i32> %2074, <4 x i32> %24
  %2078 = icmp slt <4 x i32> %2077, %27
  %2079 = select <4 x i1> %2078, <4 x i32> %2077, <4 x i32> %27
  %2080 = icmp sgt <4 x i32> %2075, %24
  %2081 = select <4 x i1> %2080, <4 x i32> %2075, <4 x i32> %24
  %2082 = icmp slt <4 x i32> %2081, %27
  %2083 = select <4 x i1> %2082, <4 x i32> %2081, <4 x i32> %27
  store <4 x i32> %2079, <4 x i32>* %1308, align 16
  store <4 x i32> %2083, <4 x i32>* %1327, align 16
  %2084 = load <4 x i32>, <4 x i32>* %1595, align 16
  %2085 = load <4 x i32>, <4 x i32>* %1072, align 16
  %2086 = add <4 x i32> %2085, %2084
  %2087 = sub <4 x i32> %2084, %2085
  %2088 = icmp sgt <4 x i32> %2086, %24
  %2089 = select <4 x i1> %2088, <4 x i32> %2086, <4 x i32> %24
  %2090 = icmp slt <4 x i32> %2089, %27
  %2091 = select <4 x i1> %2090, <4 x i32> %2089, <4 x i32> %27
  %2092 = icmp sgt <4 x i32> %2087, %24
  %2093 = select <4 x i1> %2092, <4 x i32> %2087, <4 x i32> %24
  %2094 = icmp slt <4 x i32> %2093, %27
  %2095 = select <4 x i1> %2094, <4 x i32> %2093, <4 x i32> %27
  store <4 x i32> %2091, <4 x i32>* %1313, align 16
  store <4 x i32> %2095, <4 x i32>* %1066, align 16
  %2096 = load <2 x i64>, <2 x i64>* %383, align 16
  store <2 x i64> %2096, <2 x i64>* %775, align 16
  %2097 = load <2 x i64>, <2 x i64>* %1092, align 16
  store <2 x i64> %2097, <2 x i64>* %782, align 16
  %2098 = load <2 x i64>, <2 x i64>* %392, align 16
  store <2 x i64> %2098, <2 x i64>* %811, align 16
  %2099 = load <2 x i64>, <2 x i64>* %1134, align 16
  store <2 x i64> %2099, <2 x i64>* %816, align 16
  %2100 = load <4 x i32>, <4 x i32>* %784, align 16
  %2101 = mul <4 x i32> %2100, %762
  %2102 = load <4 x i32>, <4 x i32>* %1131, align 16
  %2103 = mul <4 x i32> %2102, %747
  %2104 = add <4 x i32> %2103, %14
  %2105 = add <4 x i32> %2104, %2101
  %2106 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2105, i32 %2) #8
  store <4 x i32> %2106, <4 x i32>* %790, align 16
  %2107 = load <4 x i32>, <4 x i32>* %1117, align 16
  %2108 = mul <4 x i32> %2107, %762
  %2109 = load <4 x i32>, <4 x i32>* %791, align 16
  %2110 = mul <4 x i32> %2109, %747
  %2111 = add <4 x i32> %2110, %14
  %2112 = add <4 x i32> %2111, %2108
  %2113 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2112, i32 %2) #8
  store <4 x i32> %2113, <4 x i32>* %797, align 16
  %2114 = mul <4 x i32> %2107, %747
  %2115 = add <4 x i32> %2111, %2114
  %2116 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2115, i32 %2) #8
  store <4 x i32> %2116, <4 x i32>* %802, align 16
  %2117 = mul <4 x i32> %2100, %747
  %2118 = add <4 x i32> %2104, %2117
  %2119 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2118, i32 %2) #8
  store <4 x i32> %2119, <4 x i32>* %807, align 16
  %2120 = load <4 x i32>, <4 x i32>* %602, align 16
  %2121 = load <4 x i32>, <4 x i32>* %651, align 16
  %2122 = add <4 x i32> %2121, %2120
  %2123 = sub <4 x i32> %2120, %2121
  %2124 = icmp sgt <4 x i32> %2122, %24
  %2125 = select <4 x i1> %2124, <4 x i32> %2122, <4 x i32> %24
  %2126 = icmp slt <4 x i32> %2125, %27
  %2127 = select <4 x i1> %2126, <4 x i32> %2125, <4 x i32> %27
  %2128 = icmp sgt <4 x i32> %2123, %24
  %2129 = select <4 x i1> %2128, <4 x i32> %2123, <4 x i32> %24
  %2130 = icmp slt <4 x i32> %2129, %27
  %2131 = select <4 x i1> %2130, <4 x i32> %2129, <4 x i32> %27
  store <4 x i32> %2127, <4 x i32>* %596, align 16
  store <4 x i32> %2131, <4 x i32>* %873, align 16
  %2132 = load <4 x i32>, <4 x i32>* %691, align 16
  %2133 = load <4 x i32>, <4 x i32>* %656, align 16
  %2134 = add <4 x i32> %2133, %2132
  %2135 = sub <4 x i32> %2132, %2133
  %2136 = icmp sgt <4 x i32> %2134, %24
  %2137 = select <4 x i1> %2136, <4 x i32> %2134, <4 x i32> %24
  %2138 = icmp slt <4 x i32> %2137, %27
  %2139 = select <4 x i1> %2138, <4 x i32> %2137, <4 x i32> %27
  %2140 = icmp sgt <4 x i32> %2135, %24
  %2141 = select <4 x i1> %2140, <4 x i32> %2135, <4 x i32> %24
  %2142 = icmp slt <4 x i32> %2141, %27
  %2143 = select <4 x i1> %2142, <4 x i32> %2141, <4 x i32> %27
  store <4 x i32> %2139, <4 x i32>* %929, align 16
  store <4 x i32> %2143, <4 x i32>* %645, align 16
  %2144 = load <4 x i32>, <4 x i32>* %609, align 16
  %2145 = load <4 x i32>, <4 x i32>* %644, align 16
  %2146 = add <4 x i32> %2145, %2144
  %2147 = sub <4 x i32> %2144, %2145
  %2148 = icmp sgt <4 x i32> %2146, %24
  %2149 = select <4 x i1> %2148, <4 x i32> %2146, <4 x i32> %24
  %2150 = icmp slt <4 x i32> %2149, %27
  %2151 = select <4 x i1> %2150, <4 x i32> %2149, <4 x i32> %27
  %2152 = icmp sgt <4 x i32> %2147, %24
  %2153 = select <4 x i1> %2152, <4 x i32> %2147, <4 x i32> %24
  %2154 = icmp slt <4 x i32> %2153, %27
  %2155 = select <4 x i1> %2154, <4 x i32> %2153, <4 x i32> %27
  store <4 x i32> %2151, <4 x i32>* %831, align 16
  store <4 x i32> %2155, <4 x i32>* %638, align 16
  %2156 = load <4 x i32>, <4 x i32>* %686, align 16
  %2157 = load <4 x i32>, <4 x i32>* %661, align 16
  %2158 = add <4 x i32> %2157, %2156
  %2159 = sub <4 x i32> %2156, %2157
  %2160 = icmp sgt <4 x i32> %2158, %24
  %2161 = select <4 x i1> %2160, <4 x i32> %2158, <4 x i32> %24
  %2162 = icmp slt <4 x i32> %2161, %27
  %2163 = select <4 x i1> %2162, <4 x i32> %2161, <4 x i32> %27
  %2164 = icmp sgt <4 x i32> %2159, %24
  %2165 = select <4 x i1> %2164, <4 x i32> %2159, <4 x i32> %24
  %2166 = icmp slt <4 x i32> %2165, %27
  %2167 = select <4 x i1> %2166, <4 x i32> %2165, <4 x i32> %27
  store <4 x i32> %2163, <4 x i32>* %603, align 16
  store <4 x i32> %2167, <4 x i32>* %887, align 16
  %2168 = load <4 x i32>, <4 x i32>* %616, align 16
  %2169 = load <4 x i32>, <4 x i32>* %637, align 16
  %2170 = add <4 x i32> %2169, %2168
  %2171 = sub <4 x i32> %2168, %2169
  %2172 = icmp sgt <4 x i32> %2170, %24
  %2173 = select <4 x i1> %2172, <4 x i32> %2170, <4 x i32> %24
  %2174 = icmp slt <4 x i32> %2173, %27
  %2175 = select <4 x i1> %2174, <4 x i32> %2173, <4 x i32> %27
  %2176 = icmp sgt <4 x i32> %2171, %24
  %2177 = select <4 x i1> %2176, <4 x i32> %2171, <4 x i32> %24
  %2178 = icmp slt <4 x i32> %2177, %27
  %2179 = select <4 x i1> %2178, <4 x i32> %2177, <4 x i32> %27
  store <4 x i32> %2175, <4 x i32>* %610, align 16
  store <4 x i32> %2179, <4 x i32>* %859, align 16
  %2180 = load <4 x i32>, <4 x i32>* %681, align 16
  %2181 = load <4 x i32>, <4 x i32>* %666, align 16
  %2182 = add <4 x i32> %2181, %2180
  %2183 = sub <4 x i32> %2180, %2181
  %2184 = icmp sgt <4 x i32> %2182, %24
  %2185 = select <4 x i1> %2184, <4 x i32> %2182, <4 x i32> %24
  %2186 = icmp slt <4 x i32> %2185, %27
  %2187 = select <4 x i1> %2186, <4 x i32> %2185, <4 x i32> %27
  %2188 = icmp sgt <4 x i32> %2183, %24
  %2189 = select <4 x i1> %2188, <4 x i32> %2183, <4 x i32> %24
  %2190 = icmp slt <4 x i32> %2189, %27
  %2191 = select <4 x i1> %2190, <4 x i32> %2189, <4 x i32> %27
  store <4 x i32> %2187, <4 x i32>* %915, align 16
  store <4 x i32> %2191, <4 x i32>* %631, align 16
  %2192 = load <4 x i32>, <4 x i32>* %623, align 16
  %2193 = load <4 x i32>, <4 x i32>* %630, align 16
  %2194 = add <4 x i32> %2193, %2192
  %2195 = sub <4 x i32> %2192, %2193
  %2196 = icmp sgt <4 x i32> %2194, %24
  %2197 = select <4 x i1> %2196, <4 x i32> %2194, <4 x i32> %24
  %2198 = icmp slt <4 x i32> %2197, %27
  %2199 = select <4 x i1> %2198, <4 x i32> %2197, <4 x i32> %27
  %2200 = icmp sgt <4 x i32> %2195, %24
  %2201 = select <4 x i1> %2200, <4 x i32> %2195, <4 x i32> %24
  %2202 = icmp slt <4 x i32> %2201, %27
  %2203 = select <4 x i1> %2202, <4 x i32> %2201, <4 x i32> %27
  store <4 x i32> %2199, <4 x i32>* %845, align 16
  store <4 x i32> %2203, <4 x i32>* %624, align 16
  %2204 = load <4 x i32>, <4 x i32>* %676, align 16
  %2205 = load <4 x i32>, <4 x i32>* %671, align 16
  %2206 = add <4 x i32> %2205, %2204
  %2207 = sub <4 x i32> %2204, %2205
  %2208 = icmp sgt <4 x i32> %2206, %24
  %2209 = select <4 x i1> %2208, <4 x i32> %2206, <4 x i32> %24
  %2210 = icmp slt <4 x i32> %2209, %27
  %2211 = select <4 x i1> %2210, <4 x i32> %2209, <4 x i32> %27
  %2212 = icmp sgt <4 x i32> %2207, %24
  %2213 = select <4 x i1> %2212, <4 x i32> %2207, <4 x i32> %24
  %2214 = icmp slt <4 x i32> %2213, %27
  %2215 = select <4 x i1> %2214, <4 x i32> %2213, <4 x i32> %27
  store <4 x i32> %2211, <4 x i32>* %617, align 16
  store <4 x i32> %2215, <4 x i32>* %901, align 16
  %2216 = load <2 x i64>, <2 x i64>* %311, align 16
  store <2 x i64> %2216, <2 x i64>* %409, align 16
  %2217 = load <2 x i64>, <2 x i64>* %329, align 16
  store <2 x i64> %2217, <2 x i64>* %493, align 16
  %2218 = load <2 x i64>, <2 x i64>* %335, align 16
  store <2 x i64> %2218, <2 x i64>* %519, align 16
  %2219 = load <2 x i64>, <2 x i64>* %353, align 16
  store <2 x i64> %2219, <2 x i64>* %579, align 16
  %2220 = load <2 x i64>, <2 x i64>* %954, align 16
  store <2 x i64> %2220, <2 x i64>* %416, align 16
  %2221 = load <2 x i64>, <2 x i64>* %1008, align 16
  store <2 x i64> %2221, <2 x i64>* %500, align 16
  %2222 = load <2 x i64>, <2 x i64>* %1017, align 16
  store <2 x i64> %2222, <2 x i64>* %524, align 16
  %2223 = load <2 x i64>, <2 x i64>* %963, align 16
  store <2 x i64> %2223, <2 x i64>* %584, align 16
  %2224 = load <2 x i64>, <2 x i64>* %314, align 16
  store <2 x i64> %2224, <2 x i64>* %423, align 16
  %2225 = load <2 x i64>, <2 x i64>* %332, align 16
  store <2 x i64> %2225, <2 x i64>* %507, align 16
  %2226 = load <2 x i64>, <2 x i64>* %338, align 16
  store <2 x i64> %2226, <2 x i64>* %529, align 16
  %2227 = load <2 x i64>, <2 x i64>* %356, align 16
  store <2 x i64> %2227, <2 x i64>* %589, align 16
  %2228 = load <2 x i64>, <2 x i64>* %931, align 16
  store <2 x i64> %2228, <2 x i64>* %430, align 16
  %2229 = load <2 x i64>, <2 x i64>* %940, align 16
  store <2 x i64> %2229, <2 x i64>* %514, align 16
  %2230 = load <2 x i64>, <2 x i64>* %943, align 16
  store <2 x i64> %2230, <2 x i64>* %534, align 16
  %2231 = load <2 x i64>, <2 x i64>* %952, align 16
  store <2 x i64> %2231, <2 x i64>* %594, align 16
  %2232 = load <4 x i32>, <4 x i32>* %432, align 16
  %2233 = mul <4 x i32> %2232, %758
  %2234 = load <4 x i32>, <4 x i32>* %1499, align 16
  %2235 = mul <4 x i32> %2234, %751
  %2236 = add <4 x i32> %2233, %14
  %2237 = add <4 x i32> %2236, %2235
  %2238 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2237, i32 %2) #8
  store <4 x i32> %2238, <4 x i32>* %438, align 16
  %2239 = load <4 x i32>, <4 x i32>* %973, align 16
  %2240 = mul <4 x i32> %2239, %758
  %2241 = load <4 x i32>, <4 x i32>* %439, align 16
  %2242 = mul <4 x i32> %2241, %751
  %2243 = add <4 x i32> %2240, %14
  %2244 = add <4 x i32> %2243, %2242
  %2245 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2244, i32 %2) #8
  store <4 x i32> %2245, <4 x i32>* %445, align 16
  %2246 = load <4 x i32>, <4 x i32>* %446, align 16
  %2247 = mul <4 x i32> %2246, %758
  %2248 = load <4 x i32>, <4 x i32>* %984, align 16
  %2249 = mul <4 x i32> %2248, %751
  %2250 = add <4 x i32> %2247, %14
  %2251 = add <4 x i32> %2250, %2249
  %2252 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2251, i32 %2) #8
  store <4 x i32> %2252, <4 x i32>* %452, align 16
  %2253 = bitcast <2 x i64>* %934 to <4 x i32>*
  %2254 = load <4 x i32>, <4 x i32>* %2253, align 16
  %2255 = mul <4 x i32> %2254, %758
  %2256 = load <4 x i32>, <4 x i32>* %453, align 16
  %2257 = mul <4 x i32> %2256, %751
  %2258 = add <4 x i32> %2255, %14
  %2259 = add <4 x i32> %2258, %2257
  %2260 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2259, i32 %2) #8
  store <4 x i32> %2260, <4 x i32>* %459, align 16
  %2261 = load <4 x i32>, <4 x i32>* %460, align 16
  %2262 = mul <4 x i32> %2261, %766
  %2263 = bitcast <2 x i64>* %946 to <4 x i32>*
  %2264 = load <4 x i32>, <4 x i32>* %2263, align 16
  %2265 = mul <4 x i32> %2264, %758
  %2266 = add <4 x i32> %2262, %14
  %2267 = add <4 x i32> %2266, %2265
  %2268 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2267, i32 %2) #8
  store <4 x i32> %2268, <4 x i32>* %466, align 16
  %2269 = load <4 x i32>, <4 x i32>* %991, align 16
  %2270 = mul <4 x i32> %2269, %766
  %2271 = load <4 x i32>, <4 x i32>* %467, align 16
  %2272 = mul <4 x i32> %2271, %758
  %2273 = add <4 x i32> %2270, %14
  %2274 = add <4 x i32> %2273, %2272
  %2275 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2274, i32 %2) #8
  store <4 x i32> %2275, <4 x i32>* %473, align 16
  %2276 = load <4 x i32>, <4 x i32>* %474, align 16
  %2277 = mul <4 x i32> %2276, %766
  %2278 = load <4 x i32>, <4 x i32>* %1002, align 16
  %2279 = mul <4 x i32> %2278, %758
  %2280 = add <4 x i32> %2277, %14
  %2281 = add <4 x i32> %2280, %2279
  %2282 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2281, i32 %2) #8
  store <4 x i32> %2282, <4 x i32>* %480, align 16
  %2283 = load <4 x i32>, <4 x i32>* %1519, align 16
  %2284 = mul <4 x i32> %2283, %766
  %2285 = load <4 x i32>, <4 x i32>* %481, align 16
  %2286 = mul <4 x i32> %2285, %758
  %2287 = add <4 x i32> %2284, %14
  %2288 = add <4 x i32> %2287, %2286
  %2289 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2288, i32 %2) #8
  store <4 x i32> %2289, <4 x i32>* %487, align 16
  %2290 = mul <4 x i32> %2283, %758
  %2291 = mul <4 x i32> %2285, %751
  %2292 = add <4 x i32> %2290, %14
  %2293 = add <4 x i32> %2292, %2291
  %2294 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2293, i32 %2) #8
  store <4 x i32> %2294, <4 x i32>* %540, align 16
  %2295 = mul <4 x i32> %2276, %758
  %2296 = mul <4 x i32> %2278, %751
  %2297 = add <4 x i32> %2295, %14
  %2298 = add <4 x i32> %2297, %2296
  %2299 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2298, i32 %2) #8
  store <4 x i32> %2299, <4 x i32>* %545, align 16
  %2300 = mul <4 x i32> %2269, %758
  %2301 = mul <4 x i32> %2271, %751
  %2302 = add <4 x i32> %2300, %14
  %2303 = add <4 x i32> %2302, %2301
  %2304 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2303, i32 %2) #8
  store <4 x i32> %2304, <4 x i32>* %550, align 16
  %2305 = mul <4 x i32> %2261, %758
  %2306 = mul <4 x i32> %2264, %751
  %2307 = add <4 x i32> %2305, %14
  %2308 = add <4 x i32> %2307, %2306
  %2309 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2308, i32 %2) #8
  store <4 x i32> %2309, <4 x i32>* %555, align 16
  %2310 = mul <4 x i32> %2254, %751
  %2311 = mul <4 x i32> %2256, %743
  %2312 = add <4 x i32> %2310, %14
  %2313 = add <4 x i32> %2312, %2311
  %2314 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2313, i32 %2) #8
  store <4 x i32> %2314, <4 x i32>* %560, align 16
  %2315 = mul <4 x i32> %2246, %751
  %2316 = mul <4 x i32> %2248, %743
  %2317 = add <4 x i32> %2315, %14
  %2318 = add <4 x i32> %2317, %2316
  %2319 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2318, i32 %2) #8
  store <4 x i32> %2319, <4 x i32>* %565, align 16
  %2320 = mul <4 x i32> %2239, %751
  %2321 = mul <4 x i32> %2241, %743
  %2322 = add <4 x i32> %2320, %14
  %2323 = add <4 x i32> %2322, %2321
  %2324 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2323, i32 %2) #8
  store <4 x i32> %2324, <4 x i32>* %570, align 16
  %2325 = mul <4 x i32> %2232, %751
  %2326 = mul <4 x i32> %2234, %743
  %2327 = add <4 x i32> %2325, %14
  %2328 = add <4 x i32> %2327, %2326
  %2329 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2328, i32 %2) #8
  store <4 x i32> %2329, <4 x i32>* %575, align 16
  %2330 = load <4 x i32>, <4 x i32>* %2059, align 16
  %2331 = load <4 x i32>, <4 x i32>* %817, align 16
  %2332 = add <4 x i32> %2331, %2330
  %2333 = sub <4 x i32> %2330, %2331
  %2334 = icmp sgt <4 x i32> %2332, %24
  %2335 = select <4 x i1> %2334, <4 x i32> %2332, <4 x i32> %24
  %2336 = icmp slt <4 x i32> %2335, %27
  %2337 = select <4 x i1> %2336, <4 x i32> %2335, <4 x i32> %27
  %2338 = icmp sgt <4 x i32> %2333, %24
  %2339 = select <4 x i1> %2338, <4 x i32> %2333, <4 x i32> %24
  %2340 = icmp slt <4 x i32> %2339, %27
  %2341 = select <4 x i1> %2340, <4 x i32> %2339, <4 x i32> %27
  store <4 x i32> %2337, <4 x i32>* %2046, align 16
  store <4 x i32> %2341, <4 x i32>* %1145, align 16
  %2342 = load <4 x i32>, <4 x i32>* %1301, align 16
  %2343 = load <4 x i32>, <4 x i32>* %812, align 16
  %2344 = add <4 x i32> %2343, %2342
  %2345 = sub <4 x i32> %2342, %2343
  %2346 = icmp sgt <4 x i32> %2344, %24
  %2347 = select <4 x i1> %2346, <4 x i32> %2344, <4 x i32> %24
  %2348 = icmp slt <4 x i32> %2347, %27
  %2349 = select <4 x i1> %2348, <4 x i32> %2347, <4 x i32> %27
  %2350 = icmp sgt <4 x i32> %2345, %24
  %2351 = select <4 x i1> %2350, <4 x i32> %2345, <4 x i32> %24
  %2352 = icmp slt <4 x i32> %2351, %27
  %2353 = select <4 x i1> %2352, <4 x i32> %2351, <4 x i32> %27
  store <4 x i32> %2349, <4 x i32>* %1609, align 16
  store <4 x i32> %2353, <4 x i32>* %777, align 16
  %2354 = load <4 x i32>, <4 x i32>* %1308, align 16
  %2355 = load <4 x i32>, <4 x i32>* %807, align 16
  %2356 = add <4 x i32> %2355, %2354
  %2357 = sub <4 x i32> %2354, %2355
  %2358 = icmp sgt <4 x i32> %2356, %24
  %2359 = select <4 x i1> %2358, <4 x i32> %2356, <4 x i32> %24
  %2360 = icmp slt <4 x i32> %2359, %27
  %2361 = select <4 x i1> %2360, <4 x i32> %2359, <4 x i32> %27
  %2362 = icmp sgt <4 x i32> %2357, %24
  %2363 = select <4 x i1> %2362, <4 x i32> %2357, <4 x i32> %24
  %2364 = icmp slt <4 x i32> %2363, %27
  %2365 = select <4 x i1> %2364, <4 x i32> %2363, <4 x i32> %27
  store <4 x i32> %2361, <4 x i32>* %1302, align 16
  store <4 x i32> %2365, <4 x i32>* %1131, align 16
  %2366 = load <4 x i32>, <4 x i32>* %1313, align 16
  %2367 = load <4 x i32>, <4 x i32>* %802, align 16
  %2368 = add <4 x i32> %2367, %2366
  %2369 = sub <4 x i32> %2366, %2367
  %2370 = icmp sgt <4 x i32> %2368, %24
  %2371 = select <4 x i1> %2370, <4 x i32> %2368, <4 x i32> %24
  %2372 = icmp slt <4 x i32> %2371, %27
  %2373 = select <4 x i1> %2372, <4 x i32> %2371, <4 x i32> %27
  %2374 = icmp sgt <4 x i32> %2369, %24
  %2375 = select <4 x i1> %2374, <4 x i32> %2369, <4 x i32> %24
  %2376 = icmp slt <4 x i32> %2375, %27
  %2377 = select <4 x i1> %2376, <4 x i32> %2375, <4 x i32> %27
  store <4 x i32> %2373, <4 x i32>* %1595, align 16
  store <4 x i32> %2377, <4 x i32>* %791, align 16
  %2378 = load <4 x i32>, <4 x i32>* %1066, align 16
  %2379 = load <4 x i32>, <4 x i32>* %797, align 16
  %2380 = add <4 x i32> %2379, %2378
  %2381 = sub <4 x i32> %2378, %2379
  %2382 = icmp sgt <4 x i32> %2380, %24
  %2383 = select <4 x i1> %2382, <4 x i32> %2380, <4 x i32> %24
  %2384 = icmp slt <4 x i32> %2383, %27
  %2385 = select <4 x i1> %2384, <4 x i32> %2383, <4 x i32> %27
  %2386 = icmp sgt <4 x i32> %2381, %24
  %2387 = select <4 x i1> %2386, <4 x i32> %2381, <4 x i32> %24
  %2388 = icmp slt <4 x i32> %2387, %27
  %2389 = select <4 x i1> %2388, <4 x i32> %2387, <4 x i32> %27
  store <4 x i32> %2385, <4 x i32>* %1072, align 16
  store <4 x i32> %2389, <4 x i32>* %1117, align 16
  %2390 = load <4 x i32>, <4 x i32>* %1327, align 16
  %2391 = load <4 x i32>, <4 x i32>* %790, align 16
  %2392 = add <4 x i32> %2391, %2390
  %2393 = sub <4 x i32> %2390, %2391
  %2394 = icmp sgt <4 x i32> %2392, %24
  %2395 = select <4 x i1> %2394, <4 x i32> %2392, <4 x i32> %24
  %2396 = icmp slt <4 x i32> %2395, %27
  %2397 = select <4 x i1> %2396, <4 x i32> %2395, <4 x i32> %27
  %2398 = icmp sgt <4 x i32> %2393, %24
  %2399 = select <4 x i1> %2398, <4 x i32> %2393, <4 x i32> %24
  %2400 = icmp slt <4 x i32> %2399, %27
  %2401 = select <4 x i1> %2400, <4 x i32> %2399, <4 x i32> %27
  store <4 x i32> %2397, <4 x i32>* %1079, align 16
  store <4 x i32> %2401, <4 x i32>* %784, align 16
  %2402 = load <4 x i32>, <4 x i32>* %1073, align 16
  %2403 = load <4 x i32>, <4 x i32>* %783, align 16
  %2404 = add <4 x i32> %2403, %2402
  %2405 = sub <4 x i32> %2402, %2403
  %2406 = icmp sgt <4 x i32> %2404, %24
  %2407 = select <4 x i1> %2406, <4 x i32> %2404, <4 x i32> %24
  %2408 = icmp slt <4 x i32> %2407, %27
  %2409 = select <4 x i1> %2408, <4 x i32> %2407, <4 x i32> %27
  %2410 = icmp sgt <4 x i32> %2405, %24
  %2411 = select <4 x i1> %2410, <4 x i32> %2405, <4 x i32> %24
  %2412 = icmp slt <4 x i32> %2411, %27
  %2413 = select <4 x i1> %2412, <4 x i32> %2411, <4 x i32> %27
  store <4 x i32> %2409, <4 x i32>* %1084, align 16
  store <4 x i32> %2413, <4 x i32>* %1103, align 16
  %2414 = load <4 x i32>, <4 x i32>* %1341, align 16
  %2415 = load <4 x i32>, <4 x i32>* %776, align 16
  %2416 = add <4 x i32> %2415, %2414
  %2417 = sub <4 x i32> %2414, %2415
  %2418 = icmp sgt <4 x i32> %2416, %24
  %2419 = select <4 x i1> %2418, <4 x i32> %2416, <4 x i32> %24
  %2420 = icmp slt <4 x i32> %2419, %27
  %2421 = select <4 x i1> %2420, <4 x i32> %2419, <4 x i32> %27
  %2422 = icmp sgt <4 x i32> %2417, %24
  %2423 = select <4 x i1> %2422, <4 x i32> %2417, <4 x i32> %24
  %2424 = icmp slt <4 x i32> %2423, %27
  %2425 = select <4 x i1> %2424, <4 x i32> %2423, <4 x i32> %27
  store <4 x i32> %2421, <4 x i32>* %1089, align 16
  store <4 x i32> %2425, <4 x i32>* %770, align 16
  %2426 = load <2 x i64>, <2 x i64>* %359, align 16
  store <2 x i64> %2426, <2 x i64>* %601, align 16
  %2427 = load <2 x i64>, <2 x i64>* %377, align 16
  store <2 x i64> %2427, <2 x i64>* %675, align 16
  %2428 = load <2 x i64>, <2 x i64>* %820, align 16
  store <2 x i64> %2428, <2 x i64>* %608, align 16
  %2429 = load <2 x i64>, <2 x i64>* %904, align 16
  store <2 x i64> %2429, <2 x i64>* %680, align 16
  %2430 = load <2 x i64>, <2 x i64>* %362, align 16
  store <2 x i64> %2430, <2 x i64>* %615, align 16
  %2431 = load <2 x i64>, <2 x i64>* %380, align 16
  store <2 x i64> %2431, <2 x i64>* %685, align 16
  %2432 = load <2 x i64>, <2 x i64>* %834, align 16
  store <2 x i64> %2432, <2 x i64>* %622, align 16
  %2433 = load <2 x i64>, <2 x i64>* %918, align 16
  store <2 x i64> %2433, <2 x i64>* %690, align 16
  %2434 = load <4 x i32>, <4 x i32>* %624, align 16
  %2435 = mul <4 x i32> %2434, %762
  %2436 = load <4 x i32>, <4 x i32>* %901, align 16
  %2437 = mul <4 x i32> %2436, %747
  %2438 = add <4 x i32> %2437, %14
  %2439 = add <4 x i32> %2438, %2435
  %2440 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2439, i32 %2) #8
  store <4 x i32> %2440, <4 x i32>* %630, align 16
  %2441 = load <4 x i32>, <4 x i32>* %859, align 16
  %2442 = mul <4 x i32> %2441, %762
  %2443 = load <4 x i32>, <4 x i32>* %631, align 16
  %2444 = mul <4 x i32> %2443, %747
  %2445 = add <4 x i32> %2444, %14
  %2446 = add <4 x i32> %2445, %2442
  %2447 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2446, i32 %2) #8
  store <4 x i32> %2447, <4 x i32>* %637, align 16
  %2448 = load <4 x i32>, <4 x i32>* %638, align 16
  %2449 = mul <4 x i32> %2448, %762
  %2450 = load <4 x i32>, <4 x i32>* %887, align 16
  %2451 = mul <4 x i32> %2450, %747
  %2452 = add <4 x i32> %2451, %14
  %2453 = add <4 x i32> %2452, %2449
  %2454 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2453, i32 %2) #8
  store <4 x i32> %2454, <4 x i32>* %644, align 16
  %2455 = load <4 x i32>, <4 x i32>* %873, align 16
  %2456 = mul <4 x i32> %2455, %762
  %2457 = load <4 x i32>, <4 x i32>* %645, align 16
  %2458 = mul <4 x i32> %2457, %747
  %2459 = add <4 x i32> %2458, %14
  %2460 = add <4 x i32> %2459, %2456
  %2461 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2460, i32 %2) #8
  store <4 x i32> %2461, <4 x i32>* %651, align 16
  %2462 = mul <4 x i32> %2455, %747
  %2463 = add <4 x i32> %2459, %2462
  %2464 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2463, i32 %2) #8
  store <4 x i32> %2464, <4 x i32>* %656, align 16
  %2465 = mul <4 x i32> %2448, %747
  %2466 = add <4 x i32> %2452, %2465
  %2467 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2466, i32 %2) #8
  store <4 x i32> %2467, <4 x i32>* %661, align 16
  %2468 = mul <4 x i32> %2441, %747
  %2469 = add <4 x i32> %2445, %2468
  %2470 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2469, i32 %2) #8
  store <4 x i32> %2470, <4 x i32>* %666, align 16
  %2471 = mul <4 x i32> %2434, %747
  %2472 = add <4 x i32> %2438, %2471
  %2473 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2472, i32 %2) #8
  store <4 x i32> %2473, <4 x i32>* %671, align 16
  %2474 = load <4 x i32>, <4 x i32>* %410, align 16
  %2475 = load <4 x i32>, <4 x i32>* %515, align 16
  %2476 = add <4 x i32> %2475, %2474
  %2477 = sub <4 x i32> %2474, %2475
  %2478 = icmp sgt <4 x i32> %2476, %24
  %2479 = select <4 x i1> %2478, <4 x i32> %2476, <4 x i32> %24
  %2480 = icmp slt <4 x i32> %2479, %27
  %2481 = select <4 x i1> %2480, <4 x i32> %2479, <4 x i32> %27
  %2482 = icmp sgt <4 x i32> %2477, %24
  %2483 = select <4 x i1> %2482, <4 x i32> %2477, <4 x i32> %24
  %2484 = icmp slt <4 x i32> %2483, %27
  %2485 = select <4 x i1> %2484, <4 x i32> %2483, <4 x i32> %27
  store <4 x i32> %2481, <4 x i32>* %404, align 16
  %2486 = bitcast <2 x i64>* %940 to <4 x i32>*
  store <4 x i32> %2485, <4 x i32>* %2486, align 16
  %2487 = load <4 x i32>, <4 x i32>* %417, align 16
  %2488 = load <4 x i32>, <4 x i32>* %508, align 16
  %2489 = add <4 x i32> %2488, %2487
  %2490 = sub <4 x i32> %2487, %2488
  %2491 = icmp sgt <4 x i32> %2489, %24
  %2492 = select <4 x i1> %2491, <4 x i32> %2489, <4 x i32> %24
  %2493 = icmp slt <4 x i32> %2492, %27
  %2494 = select <4 x i1> %2493, <4 x i32> %2492, <4 x i32> %27
  %2495 = icmp sgt <4 x i32> %2490, %24
  %2496 = select <4 x i1> %2495, <4 x i32> %2490, <4 x i32> %24
  %2497 = icmp slt <4 x i32> %2496, %27
  %2498 = select <4 x i1> %2497, <4 x i32> %2496, <4 x i32> %27
  store <4 x i32> %2494, <4 x i32>* %955, align 16
  store <4 x i32> %2498, <4 x i32>* %502, align 16
  %2499 = load <4 x i32>, <4 x i32>* %424, align 16
  %2500 = load <4 x i32>, <4 x i32>* %501, align 16
  %2501 = add <4 x i32> %2500, %2499
  %2502 = sub <4 x i32> %2499, %2500
  %2503 = icmp sgt <4 x i32> %2501, %24
  %2504 = select <4 x i1> %2503, <4 x i32> %2501, <4 x i32> %24
  %2505 = icmp slt <4 x i32> %2504, %27
  %2506 = select <4 x i1> %2505, <4 x i32> %2504, <4 x i32> %27
  %2507 = icmp sgt <4 x i32> %2502, %24
  %2508 = select <4 x i1> %2507, <4 x i32> %2502, <4 x i32> %24
  %2509 = icmp slt <4 x i32> %2508, %27
  %2510 = select <4 x i1> %2509, <4 x i32> %2508, <4 x i32> %27
  store <4 x i32> %2506, <4 x i32>* %418, align 16
  store <4 x i32> %2510, <4 x i32>* %1009, align 16
  %2511 = load <4 x i32>, <4 x i32>* %431, align 16
  %2512 = load <4 x i32>, <4 x i32>* %494, align 16
  %2513 = add <4 x i32> %2512, %2511
  %2514 = sub <4 x i32> %2511, %2512
  %2515 = icmp sgt <4 x i32> %2513, %24
  %2516 = select <4 x i1> %2515, <4 x i32> %2513, <4 x i32> %24
  %2517 = icmp slt <4 x i32> %2516, %27
  %2518 = select <4 x i1> %2517, <4 x i32> %2516, <4 x i32> %27
  %2519 = icmp sgt <4 x i32> %2514, %24
  %2520 = select <4 x i1> %2519, <4 x i32> %2514, <4 x i32> %24
  %2521 = icmp slt <4 x i32> %2520, %27
  %2522 = select <4 x i1> %2521, <4 x i32> %2520, <4 x i32> %27
  store <4 x i32> %2518, <4 x i32>* %1489, align 16
  store <4 x i32> %2522, <4 x i32>* %488, align 16
  %2523 = load <4 x i32>, <4 x i32>* %438, align 16
  %2524 = load <4 x i32>, <4 x i32>* %487, align 16
  %2525 = add <4 x i32> %2524, %2523
  %2526 = sub <4 x i32> %2523, %2524
  %2527 = icmp sgt <4 x i32> %2525, %24
  %2528 = select <4 x i1> %2527, <4 x i32> %2525, <4 x i32> %24
  %2529 = icmp slt <4 x i32> %2528, %27
  %2530 = select <4 x i1> %2529, <4 x i32> %2528, <4 x i32> %27
  %2531 = icmp sgt <4 x i32> %2526, %24
  %2532 = select <4 x i1> %2531, <4 x i32> %2526, <4 x i32> %24
  %2533 = icmp slt <4 x i32> %2532, %27
  %2534 = select <4 x i1> %2533, <4 x i32> %2532, <4 x i32> %27
  store <4 x i32> %2530, <4 x i32>* %432, align 16
  store <4 x i32> %2534, <4 x i32>* %1519, align 16
  %2535 = load <4 x i32>, <4 x i32>* %445, align 16
  %2536 = load <4 x i32>, <4 x i32>* %480, align 16
  %2537 = add <4 x i32> %2536, %2535
  %2538 = sub <4 x i32> %2535, %2536
  %2539 = icmp sgt <4 x i32> %2537, %24
  %2540 = select <4 x i1> %2539, <4 x i32> %2537, <4 x i32> %24
  %2541 = icmp slt <4 x i32> %2540, %27
  %2542 = select <4 x i1> %2541, <4 x i32> %2540, <4 x i32> %27
  %2543 = icmp sgt <4 x i32> %2538, %24
  %2544 = select <4 x i1> %2543, <4 x i32> %2538, <4 x i32> %24
  %2545 = icmp slt <4 x i32> %2544, %27
  %2546 = select <4 x i1> %2545, <4 x i32> %2544, <4 x i32> %27
  store <4 x i32> %2542, <4 x i32>* %973, align 16
  store <4 x i32> %2546, <4 x i32>* %474, align 16
  %2547 = load <4 x i32>, <4 x i32>* %452, align 16
  %2548 = load <4 x i32>, <4 x i32>* %473, align 16
  %2549 = add <4 x i32> %2548, %2547
  %2550 = sub <4 x i32> %2547, %2548
  %2551 = icmp sgt <4 x i32> %2549, %24
  %2552 = select <4 x i1> %2551, <4 x i32> %2549, <4 x i32> %24
  %2553 = icmp slt <4 x i32> %2552, %27
  %2554 = select <4 x i1> %2553, <4 x i32> %2552, <4 x i32> %27
  %2555 = icmp sgt <4 x i32> %2550, %24
  %2556 = select <4 x i1> %2555, <4 x i32> %2550, <4 x i32> %24
  %2557 = icmp slt <4 x i32> %2556, %27
  %2558 = select <4 x i1> %2557, <4 x i32> %2556, <4 x i32> %27
  store <4 x i32> %2554, <4 x i32>* %446, align 16
  store <4 x i32> %2558, <4 x i32>* %991, align 16
  %2559 = load <4 x i32>, <4 x i32>* %459, align 16
  %2560 = load <4 x i32>, <4 x i32>* %466, align 16
  %2561 = add <4 x i32> %2560, %2559
  %2562 = sub <4 x i32> %2559, %2560
  %2563 = icmp sgt <4 x i32> %2561, %24
  %2564 = select <4 x i1> %2563, <4 x i32> %2561, <4 x i32> %24
  %2565 = icmp slt <4 x i32> %2564, %27
  %2566 = select <4 x i1> %2565, <4 x i32> %2564, <4 x i32> %27
  %2567 = icmp sgt <4 x i32> %2562, %24
  %2568 = select <4 x i1> %2567, <4 x i32> %2562, <4 x i32> %24
  %2569 = icmp slt <4 x i32> %2568, %27
  %2570 = select <4 x i1> %2569, <4 x i32> %2568, <4 x i32> %27
  store <4 x i32> %2566, <4 x i32>* %2253, align 16
  store <4 x i32> %2570, <4 x i32>* %460, align 16
  %2571 = load <4 x i32>, <4 x i32>* %595, align 16
  %2572 = load <4 x i32>, <4 x i32>* %520, align 16
  %2573 = add <4 x i32> %2572, %2571
  %2574 = sub <4 x i32> %2571, %2572
  %2575 = icmp sgt <4 x i32> %2573, %24
  %2576 = select <4 x i1> %2575, <4 x i32> %2573, <4 x i32> %24
  %2577 = icmp slt <4 x i32> %2576, %27
  %2578 = select <4 x i1> %2577, <4 x i32> %2576, <4 x i32> %27
  %2579 = icmp sgt <4 x i32> %2574, %24
  %2580 = select <4 x i1> %2579, <4 x i32> %2574, <4 x i32> %24
  %2581 = icmp slt <4 x i32> %2580, %27
  %2582 = select <4 x i1> %2581, <4 x i32> %2580, <4 x i32> %27
  %2583 = bitcast <2 x i64>* %952 to <4 x i32>*
  store <4 x i32> %2578, <4 x i32>* %2583, align 16
  store <4 x i32> %2582, <4 x i32>* %509, align 16
  %2584 = load <4 x i32>, <4 x i32>* %590, align 16
  %2585 = load <4 x i32>, <4 x i32>* %525, align 16
  %2586 = add <4 x i32> %2585, %2584
  %2587 = sub <4 x i32> %2584, %2585
  %2588 = icmp sgt <4 x i32> %2586, %24
  %2589 = select <4 x i1> %2588, <4 x i32> %2586, <4 x i32> %24
  %2590 = icmp slt <4 x i32> %2589, %27
  %2591 = select <4 x i1> %2590, <4 x i32> %2589, <4 x i32> %27
  %2592 = icmp sgt <4 x i32> %2587, %24
  %2593 = select <4 x i1> %2592, <4 x i32> %2587, <4 x i32> %24
  %2594 = icmp slt <4 x i32> %2593, %27
  %2595 = select <4 x i1> %2594, <4 x i32> %2593, <4 x i32> %27
  store <4 x i32> %2591, <4 x i32>* %411, align 16
  store <4 x i32> %2595, <4 x i32>* %1020, align 16
  %2596 = load <4 x i32>, <4 x i32>* %585, align 16
  %2597 = load <4 x i32>, <4 x i32>* %530, align 16
  %2598 = add <4 x i32> %2597, %2596
  %2599 = sub <4 x i32> %2596, %2597
  %2600 = icmp sgt <4 x i32> %2598, %24
  %2601 = select <4 x i1> %2600, <4 x i32> %2598, <4 x i32> %24
  %2602 = icmp slt <4 x i32> %2601, %27
  %2603 = select <4 x i1> %2602, <4 x i32> %2601, <4 x i32> %27
  %2604 = icmp sgt <4 x i32> %2599, %24
  %2605 = select <4 x i1> %2604, <4 x i32> %2599, <4 x i32> %24
  %2606 = icmp slt <4 x i32> %2605, %27
  %2607 = select <4 x i1> %2606, <4 x i32> %2605, <4 x i32> %27
  store <4 x i32> %2603, <4 x i32>* %966, align 16
  store <4 x i32> %2607, <4 x i32>* %495, align 16
  %2608 = load <4 x i32>, <4 x i32>* %580, align 16
  %2609 = load <4 x i32>, <4 x i32>* %535, align 16
  %2610 = add <4 x i32> %2609, %2608
  %2611 = sub <4 x i32> %2608, %2609
  %2612 = icmp sgt <4 x i32> %2610, %24
  %2613 = select <4 x i1> %2612, <4 x i32> %2610, <4 x i32> %24
  %2614 = icmp slt <4 x i32> %2613, %27
  %2615 = select <4 x i1> %2614, <4 x i32> %2613, <4 x i32> %27
  %2616 = icmp sgt <4 x i32> %2611, %24
  %2617 = select <4 x i1> %2616, <4 x i32> %2611, <4 x i32> %24
  %2618 = icmp slt <4 x i32> %2617, %27
  %2619 = select <4 x i1> %2618, <4 x i32> %2617, <4 x i32> %27
  store <4 x i32> %2615, <4 x i32>* %425, align 16
  store <4 x i32> %2619, <4 x i32>* %1529, align 16
  %2620 = load <4 x i32>, <4 x i32>* %575, align 16
  %2621 = load <4 x i32>, <4 x i32>* %540, align 16
  %2622 = add <4 x i32> %2621, %2620
  %2623 = sub <4 x i32> %2620, %2621
  %2624 = icmp sgt <4 x i32> %2622, %24
  %2625 = select <4 x i1> %2624, <4 x i32> %2622, <4 x i32> %24
  %2626 = icmp slt <4 x i32> %2625, %27
  %2627 = select <4 x i1> %2626, <4 x i32> %2625, <4 x i32> %27
  %2628 = icmp sgt <4 x i32> %2623, %24
  %2629 = select <4 x i1> %2628, <4 x i32> %2623, <4 x i32> %24
  %2630 = icmp slt <4 x i32> %2629, %27
  %2631 = select <4 x i1> %2630, <4 x i32> %2629, <4 x i32> %27
  store <4 x i32> %2627, <4 x i32>* %1499, align 16
  store <4 x i32> %2631, <4 x i32>* %481, align 16
  %2632 = load <4 x i32>, <4 x i32>* %570, align 16
  %2633 = load <4 x i32>, <4 x i32>* %545, align 16
  %2634 = add <4 x i32> %2633, %2632
  %2635 = sub <4 x i32> %2632, %2633
  %2636 = icmp sgt <4 x i32> %2634, %24
  %2637 = select <4 x i1> %2636, <4 x i32> %2634, <4 x i32> %24
  %2638 = icmp slt <4 x i32> %2637, %27
  %2639 = select <4 x i1> %2638, <4 x i32> %2637, <4 x i32> %27
  %2640 = icmp sgt <4 x i32> %2635, %24
  %2641 = select <4 x i1> %2640, <4 x i32> %2635, <4 x i32> %24
  %2642 = icmp slt <4 x i32> %2641, %27
  %2643 = select <4 x i1> %2642, <4 x i32> %2641, <4 x i32> %27
  store <4 x i32> %2639, <4 x i32>* %439, align 16
  store <4 x i32> %2643, <4 x i32>* %1002, align 16
  %2644 = load <4 x i32>, <4 x i32>* %565, align 16
  %2645 = load <4 x i32>, <4 x i32>* %550, align 16
  %2646 = add <4 x i32> %2645, %2644
  %2647 = sub <4 x i32> %2644, %2645
  %2648 = icmp sgt <4 x i32> %2646, %24
  %2649 = select <4 x i1> %2648, <4 x i32> %2646, <4 x i32> %24
  %2650 = icmp slt <4 x i32> %2649, %27
  %2651 = select <4 x i1> %2650, <4 x i32> %2649, <4 x i32> %27
  %2652 = icmp sgt <4 x i32> %2647, %24
  %2653 = select <4 x i1> %2652, <4 x i32> %2647, <4 x i32> %24
  %2654 = icmp slt <4 x i32> %2653, %27
  %2655 = select <4 x i1> %2654, <4 x i32> %2653, <4 x i32> %27
  store <4 x i32> %2651, <4 x i32>* %984, align 16
  store <4 x i32> %2655, <4 x i32>* %467, align 16
  %2656 = load <4 x i32>, <4 x i32>* %560, align 16
  %2657 = load <4 x i32>, <4 x i32>* %555, align 16
  %2658 = add <4 x i32> %2657, %2656
  %2659 = sub <4 x i32> %2656, %2657
  %2660 = icmp sgt <4 x i32> %2658, %24
  %2661 = select <4 x i1> %2660, <4 x i32> %2658, <4 x i32> %24
  %2662 = icmp slt <4 x i32> %2661, %27
  %2663 = select <4 x i1> %2662, <4 x i32> %2661, <4 x i32> %27
  %2664 = icmp sgt <4 x i32> %2659, %24
  %2665 = select <4 x i1> %2664, <4 x i32> %2659, <4 x i32> %24
  %2666 = icmp slt <4 x i32> %2665, %27
  %2667 = select <4 x i1> %2666, <4 x i32> %2665, <4 x i32> %27
  store <4 x i32> %2663, <4 x i32>* %453, align 16
  store <4 x i32> %2667, <4 x i32>* %2263, align 16
  br label %2668

2668:                                             ; preds = %2668, %1293
  %2669 = phi i64 [ 0, %1293 ], [ %2691, %2668 ]
  %2670 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %2669
  %2671 = bitcast <2 x i64>* %2670 to <4 x i32>*
  %2672 = load <4 x i32>, <4 x i32>* %2671, align 16
  %2673 = sub nuw nsw i64 31, %2669
  %2674 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %2673
  %2675 = bitcast <2 x i64>* %2674 to <4 x i32>*
  %2676 = load <4 x i32>, <4 x i32>* %2675, align 16
  %2677 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %2669
  %2678 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %2673
  %2679 = add <4 x i32> %2676, %2672
  %2680 = sub <4 x i32> %2672, %2676
  %2681 = icmp sgt <4 x i32> %2679, %24
  %2682 = select <4 x i1> %2681, <4 x i32> %2679, <4 x i32> %24
  %2683 = icmp slt <4 x i32> %2682, %27
  %2684 = select <4 x i1> %2683, <4 x i32> %2682, <4 x i32> %27
  %2685 = icmp sgt <4 x i32> %2680, %24
  %2686 = select <4 x i1> %2685, <4 x i32> %2680, <4 x i32> %24
  %2687 = icmp slt <4 x i32> %2686, %27
  %2688 = select <4 x i1> %2687, <4 x i32> %2686, <4 x i32> %27
  %2689 = bitcast <2 x i64>* %2677 to <4 x i32>*
  store <4 x i32> %2684, <4 x i32>* %2689, align 16
  %2690 = bitcast <2 x i64>* %2678 to <4 x i32>*
  store <4 x i32> %2688, <4 x i32>* %2690, align 16
  %2691 = add nuw nsw i64 %2669, 1
  %2692 = icmp eq i64 %2691, 16
  br i1 %2692, label %2693, label %2668

2693:                                             ; preds = %2668
  %2694 = bitcast <2 x i64>* %409 to i8*
  %2695 = bitcast <2 x i64>* %311 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %2694, i8* align 16 %2695, i64 128, i1 false)
  %2696 = load <4 x i32>, <4 x i32>* %460, align 16
  %2697 = mul <4 x i32> %2696, %762
  %2698 = mul <4 x i32> %2667, %747
  %2699 = add <4 x i32> %2698, %14
  %2700 = add <4 x i32> %2699, %2697
  %2701 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2700, i32 %2) #8
  store <4 x i32> %2701, <4 x i32>* %466, align 16
  %2702 = load <4 x i32>, <4 x i32>* %991, align 16
  %2703 = mul <4 x i32> %2702, %762
  %2704 = mul <4 x i32> %2655, %747
  %2705 = add <4 x i32> %2704, %14
  %2706 = add <4 x i32> %2705, %2703
  %2707 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2706, i32 %2) #8
  store <4 x i32> %2707, <4 x i32>* %473, align 16
  %2708 = load <4 x i32>, <4 x i32>* %474, align 16
  %2709 = mul <4 x i32> %2708, %762
  %2710 = mul <4 x i32> %2643, %747
  %2711 = add <4 x i32> %2710, %14
  %2712 = add <4 x i32> %2711, %2709
  %2713 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2712, i32 %2) #8
  store <4 x i32> %2713, <4 x i32>* %480, align 16
  %2714 = load <4 x i32>, <4 x i32>* %1519, align 16
  %2715 = mul <4 x i32> %2714, %762
  %2716 = mul <4 x i32> %2631, %747
  %2717 = add <4 x i32> %2716, %14
  %2718 = add <4 x i32> %2717, %2715
  %2719 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2718, i32 %2) #8
  store <4 x i32> %2719, <4 x i32>* %487, align 16
  %2720 = load <4 x i32>, <4 x i32>* %488, align 16
  %2721 = mul <4 x i32> %2720, %762
  %2722 = mul <4 x i32> %2619, %747
  %2723 = add <4 x i32> %2722, %14
  %2724 = add <4 x i32> %2723, %2721
  %2725 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2724, i32 %2) #8
  store <4 x i32> %2725, <4 x i32>* %494, align 16
  %2726 = load <4 x i32>, <4 x i32>* %1009, align 16
  %2727 = mul <4 x i32> %2726, %762
  %2728 = mul <4 x i32> %2607, %747
  %2729 = add <4 x i32> %2728, %14
  %2730 = add <4 x i32> %2729, %2727
  %2731 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2730, i32 %2) #8
  store <4 x i32> %2731, <4 x i32>* %501, align 16
  %2732 = load <4 x i32>, <4 x i32>* %502, align 16
  %2733 = mul <4 x i32> %2732, %762
  %2734 = mul <4 x i32> %2595, %747
  %2735 = add <4 x i32> %2734, %14
  %2736 = add <4 x i32> %2735, %2733
  %2737 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2736, i32 %2) #8
  store <4 x i32> %2737, <4 x i32>* %508, align 16
  %2738 = load <4 x i32>, <4 x i32>* %2486, align 16
  %2739 = mul <4 x i32> %2738, %762
  %2740 = load <4 x i32>, <4 x i32>* %509, align 16
  %2741 = mul <4 x i32> %2740, %747
  %2742 = add <4 x i32> %2741, %14
  %2743 = add <4 x i32> %2742, %2739
  %2744 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2743, i32 %2) #8
  store <4 x i32> %2744, <4 x i32>* %515, align 16
  %2745 = mul <4 x i32> %2738, %747
  %2746 = add <4 x i32> %2742, %2745
  %2747 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2746, i32 %2) #8
  store <4 x i32> %2747, <4 x i32>* %520, align 16
  %2748 = mul <4 x i32> %2732, %747
  %2749 = add <4 x i32> %2735, %2748
  %2750 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2749, i32 %2) #8
  store <4 x i32> %2750, <4 x i32>* %525, align 16
  %2751 = mul <4 x i32> %2726, %747
  %2752 = add <4 x i32> %2729, %2751
  %2753 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2752, i32 %2) #8
  store <4 x i32> %2753, <4 x i32>* %530, align 16
  %2754 = mul <4 x i32> %2720, %747
  %2755 = add <4 x i32> %2723, %2754
  %2756 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2755, i32 %2) #8
  store <4 x i32> %2756, <4 x i32>* %535, align 16
  %2757 = mul <4 x i32> %2714, %747
  %2758 = add <4 x i32> %2717, %2757
  %2759 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2758, i32 %2) #8
  store <4 x i32> %2759, <4 x i32>* %540, align 16
  %2760 = mul <4 x i32> %2708, %747
  %2761 = add <4 x i32> %2711, %2760
  %2762 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2761, i32 %2) #8
  store <4 x i32> %2762, <4 x i32>* %545, align 16
  %2763 = mul <4 x i32> %2702, %747
  %2764 = add <4 x i32> %2705, %2763
  %2765 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2764, i32 %2) #8
  store <4 x i32> %2765, <4 x i32>* %550, align 16
  %2766 = mul <4 x i32> %2696, %747
  %2767 = add <4 x i32> %2699, %2766
  %2768 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2767, i32 %2) #8
  store <4 x i32> %2768, <4 x i32>* %555, align 16
  %2769 = bitcast <2 x i64>* %559 to i8*
  %2770 = bitcast <2 x i64>* %347 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %2769, i8* align 16 %2770, i64 128, i1 false)
  br label %2771

2771:                                             ; preds = %2771, %2693
  %2772 = phi i64 [ 0, %2693 ], [ %2794, %2771 ]
  %2773 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %2772
  %2774 = bitcast <2 x i64>* %2773 to <4 x i32>*
  %2775 = load <4 x i32>, <4 x i32>* %2774, align 16
  %2776 = sub nuw nsw i64 63, %2772
  %2777 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %8, i64 0, i64 %2776
  %2778 = bitcast <2 x i64>* %2777 to <4 x i32>*
  %2779 = load <4 x i32>, <4 x i32>* %2778, align 16
  %2780 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %2772
  %2781 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %2776
  %2782 = add <4 x i32> %2779, %2775
  %2783 = sub <4 x i32> %2775, %2779
  %2784 = icmp sgt <4 x i32> %2782, %24
  %2785 = select <4 x i1> %2784, <4 x i32> %2782, <4 x i32> %24
  %2786 = icmp slt <4 x i32> %2785, %27
  %2787 = select <4 x i1> %2786, <4 x i32> %2785, <4 x i32> %27
  %2788 = icmp sgt <4 x i32> %2783, %24
  %2789 = select <4 x i1> %2788, <4 x i32> %2783, <4 x i32> %24
  %2790 = icmp slt <4 x i32> %2789, %27
  %2791 = select <4 x i1> %2790, <4 x i32> %2789, <4 x i32> %27
  %2792 = bitcast <2 x i64>* %2780 to <4 x i32>*
  store <4 x i32> %2787, <4 x i32>* %2792, align 16
  %2793 = bitcast <2 x i64>* %2781 to <4 x i32>*
  store <4 x i32> %2791, <4 x i32>* %2793, align 16
  %2794 = add nuw nsw i64 %2772, 1
  %2795 = icmp eq i64 %2794, 32
  br i1 %2795, label %2796, label %2771

2796:                                             ; preds = %2771
  br i1 %15, label %2871, label %2797

2797:                                             ; preds = %2796
  %2798 = icmp sgt i32 %4, 10
  %2799 = select i1 %2798, i32 %4, i32 10
  %2800 = shl i32 32, %2799
  %2801 = sub nsw i32 0, %2800
  %2802 = insertelement <4 x i32> undef, i32 %2801, i32 0
  %2803 = shufflevector <4 x i32> %2802, <4 x i32> undef, <4 x i32> zeroinitializer
  %2804 = add nsw i32 %2800, -1
  %2805 = insertelement <4 x i32> undef, i32 %2804, i32 0
  %2806 = shufflevector <4 x i32> %2805, <4 x i32> undef, <4 x i32> zeroinitializer
  %2807 = icmp eq i32 %5, 0
  %2808 = add nsw i32 %5, -1
  %2809 = shl i32 1, %2808
  %2810 = insertelement <4 x i32> undef, i32 %2809, i32 0
  %2811 = shufflevector <4 x i32> %2810, <4 x i32> undef, <4 x i32> zeroinitializer
  br label %2812

2812:                                             ; preds = %2797, %2845
  %2813 = phi i64 [ 0, %2797 ], [ %2869, %2845 ]
  %2814 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %2813
  %2815 = bitcast <2 x i64>* %2814 to <4 x i32>*
  %2816 = load <4 x i32>, <4 x i32>* %2815, align 16
  br i1 %2807, label %2817, label %2827

2817:                                             ; preds = %2812
  %2818 = getelementptr inbounds <2 x i64>, <2 x i64>* %2814, i64 1
  %2819 = bitcast <2 x i64>* %2818 to <4 x i32>*
  %2820 = load <4 x i32>, <4 x i32>* %2819, align 16
  %2821 = getelementptr inbounds <2 x i64>, <2 x i64>* %2814, i64 2
  %2822 = bitcast <2 x i64>* %2821 to <4 x i32>*
  %2823 = load <4 x i32>, <4 x i32>* %2822, align 16
  %2824 = getelementptr inbounds <2 x i64>, <2 x i64>* %2814, i64 3
  %2825 = bitcast <2 x i64>* %2824 to <4 x i32>*
  %2826 = load <4 x i32>, <4 x i32>* %2825, align 16
  br label %2845

2827:                                             ; preds = %2812
  %2828 = add <4 x i32> %2816, %2811
  %2829 = getelementptr inbounds <2 x i64>, <2 x i64>* %2814, i64 1
  %2830 = bitcast <2 x i64>* %2829 to <4 x i32>*
  %2831 = load <4 x i32>, <4 x i32>* %2830, align 16
  %2832 = add <4 x i32> %2831, %2811
  %2833 = getelementptr inbounds <2 x i64>, <2 x i64>* %2814, i64 2
  %2834 = bitcast <2 x i64>* %2833 to <4 x i32>*
  %2835 = load <4 x i32>, <4 x i32>* %2834, align 16
  %2836 = add <4 x i32> %2835, %2811
  %2837 = getelementptr inbounds <2 x i64>, <2 x i64>* %2814, i64 3
  %2838 = bitcast <2 x i64>* %2837 to <4 x i32>*
  %2839 = load <4 x i32>, <4 x i32>* %2838, align 16
  %2840 = add <4 x i32> %2839, %2811
  %2841 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2828, i32 %5) #8
  store <4 x i32> %2841, <4 x i32>* %2815, align 16
  %2842 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2832, i32 %5) #8
  store <4 x i32> %2842, <4 x i32>* %2830, align 16
  %2843 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2836, i32 %5) #8
  store <4 x i32> %2843, <4 x i32>* %2834, align 16
  %2844 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2840, i32 %5) #8
  store <4 x i32> %2844, <4 x i32>* %2838, align 16
  br label %2845

2845:                                             ; preds = %2817, %2827
  %2846 = phi <4 x i32>* [ %2825, %2817 ], [ %2838, %2827 ]
  %2847 = phi <4 x i32>* [ %2822, %2817 ], [ %2834, %2827 ]
  %2848 = phi <4 x i32>* [ %2819, %2817 ], [ %2830, %2827 ]
  %2849 = phi <4 x i32> [ %2826, %2817 ], [ %2844, %2827 ]
  %2850 = phi <4 x i32> [ %2823, %2817 ], [ %2843, %2827 ]
  %2851 = phi <4 x i32> [ %2820, %2817 ], [ %2842, %2827 ]
  %2852 = phi <4 x i32> [ %2816, %2817 ], [ %2841, %2827 ]
  %2853 = icmp sgt <4 x i32> %2852, %2803
  %2854 = select <4 x i1> %2853, <4 x i32> %2852, <4 x i32> %2803
  %2855 = icmp slt <4 x i32> %2854, %2806
  %2856 = select <4 x i1> %2855, <4 x i32> %2854, <4 x i32> %2806
  store <4 x i32> %2856, <4 x i32>* %2815, align 16
  %2857 = icmp sgt <4 x i32> %2851, %2803
  %2858 = select <4 x i1> %2857, <4 x i32> %2851, <4 x i32> %2803
  %2859 = icmp slt <4 x i32> %2858, %2806
  %2860 = select <4 x i1> %2859, <4 x i32> %2858, <4 x i32> %2806
  store <4 x i32> %2860, <4 x i32>* %2848, align 16
  %2861 = icmp sgt <4 x i32> %2850, %2803
  %2862 = select <4 x i1> %2861, <4 x i32> %2850, <4 x i32> %2803
  %2863 = icmp slt <4 x i32> %2862, %2806
  %2864 = select <4 x i1> %2863, <4 x i32> %2862, <4 x i32> %2806
  store <4 x i32> %2864, <4 x i32>* %2847, align 16
  %2865 = icmp sgt <4 x i32> %2849, %2803
  %2866 = select <4 x i1> %2865, <4 x i32> %2849, <4 x i32> %2803
  %2867 = icmp slt <4 x i32> %2866, %2806
  %2868 = select <4 x i1> %2867, <4 x i32> %2866, <4 x i32> %2806
  store <4 x i32> %2868, <4 x i32>* %2846, align 16
  %2869 = add nuw nsw i64 %2813, 4
  %2870 = icmp ult i64 %2869, 64
  br i1 %2870, label %2812, label %2871

2871:                                             ; preds = %2845, %2796
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %308) #8
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %307) #8
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define internal fastcc void @idct32_stage9_sse4_1(<2 x i64>* readonly, <2 x i64>*, i32, i32, i32, <2 x i64>* nocapture readonly, <2 x i64>* nocapture readonly) unnamed_addr #6 {
  %8 = bitcast <2 x i64>* %0 to <4 x i32>*
  %9 = load <4 x i32>, <4 x i32>* %8, align 16
  %10 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 31
  %11 = bitcast <2 x i64>* %10 to <4 x i32>*
  %12 = load <4 x i32>, <4 x i32>* %11, align 16
  %13 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 31
  %14 = add <4 x i32> %12, %9
  %15 = sub <4 x i32> %9, %12
  %16 = bitcast <2 x i64>* %5 to <4 x i32>*
  %17 = load <4 x i32>, <4 x i32>* %16, align 16
  %18 = icmp sgt <4 x i32> %14, %17
  %19 = select <4 x i1> %18, <4 x i32> %14, <4 x i32> %17
  %20 = bitcast <2 x i64>* %6 to <4 x i32>*
  %21 = load <4 x i32>, <4 x i32>* %20, align 16
  %22 = icmp slt <4 x i32> %19, %21
  %23 = select <4 x i1> %22, <4 x i32> %19, <4 x i32> %21
  %24 = icmp sgt <4 x i32> %15, %17
  %25 = select <4 x i1> %24, <4 x i32> %15, <4 x i32> %17
  %26 = icmp slt <4 x i32> %25, %21
  %27 = select <4 x i1> %26, <4 x i32> %25, <4 x i32> %21
  %28 = bitcast <2 x i64>* %1 to <4 x i32>*
  store <4 x i32> %23, <4 x i32>* %28, align 16
  %29 = bitcast <2 x i64>* %13 to <4 x i32>*
  store <4 x i32> %27, <4 x i32>* %29, align 16
  %30 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %31 = bitcast <2 x i64>* %30 to <4 x i32>*
  %32 = load <4 x i32>, <4 x i32>* %31, align 16
  %33 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 30
  %34 = bitcast <2 x i64>* %33 to <4 x i32>*
  %35 = load <4 x i32>, <4 x i32>* %34, align 16
  %36 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %37 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 30
  %38 = add <4 x i32> %35, %32
  %39 = sub <4 x i32> %32, %35
  %40 = load <4 x i32>, <4 x i32>* %16, align 16
  %41 = icmp sgt <4 x i32> %38, %40
  %42 = select <4 x i1> %41, <4 x i32> %38, <4 x i32> %40
  %43 = load <4 x i32>, <4 x i32>* %20, align 16
  %44 = icmp slt <4 x i32> %42, %43
  %45 = select <4 x i1> %44, <4 x i32> %42, <4 x i32> %43
  %46 = icmp sgt <4 x i32> %39, %40
  %47 = select <4 x i1> %46, <4 x i32> %39, <4 x i32> %40
  %48 = icmp slt <4 x i32> %47, %43
  %49 = select <4 x i1> %48, <4 x i32> %47, <4 x i32> %43
  %50 = bitcast <2 x i64>* %36 to <4 x i32>*
  store <4 x i32> %45, <4 x i32>* %50, align 16
  %51 = bitcast <2 x i64>* %37 to <4 x i32>*
  store <4 x i32> %49, <4 x i32>* %51, align 16
  %52 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %53 = bitcast <2 x i64>* %52 to <4 x i32>*
  %54 = load <4 x i32>, <4 x i32>* %53, align 16
  %55 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 29
  %56 = bitcast <2 x i64>* %55 to <4 x i32>*
  %57 = load <4 x i32>, <4 x i32>* %56, align 16
  %58 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %59 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 29
  %60 = add <4 x i32> %57, %54
  %61 = sub <4 x i32> %54, %57
  %62 = load <4 x i32>, <4 x i32>* %16, align 16
  %63 = icmp sgt <4 x i32> %60, %62
  %64 = select <4 x i1> %63, <4 x i32> %60, <4 x i32> %62
  %65 = load <4 x i32>, <4 x i32>* %20, align 16
  %66 = icmp slt <4 x i32> %64, %65
  %67 = select <4 x i1> %66, <4 x i32> %64, <4 x i32> %65
  %68 = icmp sgt <4 x i32> %61, %62
  %69 = select <4 x i1> %68, <4 x i32> %61, <4 x i32> %62
  %70 = icmp slt <4 x i32> %69, %65
  %71 = select <4 x i1> %70, <4 x i32> %69, <4 x i32> %65
  %72 = bitcast <2 x i64>* %58 to <4 x i32>*
  store <4 x i32> %67, <4 x i32>* %72, align 16
  %73 = bitcast <2 x i64>* %59 to <4 x i32>*
  store <4 x i32> %71, <4 x i32>* %73, align 16
  %74 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %75 = bitcast <2 x i64>* %74 to <4 x i32>*
  %76 = load <4 x i32>, <4 x i32>* %75, align 16
  %77 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 28
  %78 = bitcast <2 x i64>* %77 to <4 x i32>*
  %79 = load <4 x i32>, <4 x i32>* %78, align 16
  %80 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %81 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 28
  %82 = add <4 x i32> %79, %76
  %83 = sub <4 x i32> %76, %79
  %84 = load <4 x i32>, <4 x i32>* %16, align 16
  %85 = icmp sgt <4 x i32> %82, %84
  %86 = select <4 x i1> %85, <4 x i32> %82, <4 x i32> %84
  %87 = load <4 x i32>, <4 x i32>* %20, align 16
  %88 = icmp slt <4 x i32> %86, %87
  %89 = select <4 x i1> %88, <4 x i32> %86, <4 x i32> %87
  %90 = icmp sgt <4 x i32> %83, %84
  %91 = select <4 x i1> %90, <4 x i32> %83, <4 x i32> %84
  %92 = icmp slt <4 x i32> %91, %87
  %93 = select <4 x i1> %92, <4 x i32> %91, <4 x i32> %87
  %94 = bitcast <2 x i64>* %80 to <4 x i32>*
  store <4 x i32> %89, <4 x i32>* %94, align 16
  %95 = bitcast <2 x i64>* %81 to <4 x i32>*
  store <4 x i32> %93, <4 x i32>* %95, align 16
  %96 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %97 = bitcast <2 x i64>* %96 to <4 x i32>*
  %98 = load <4 x i32>, <4 x i32>* %97, align 16
  %99 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 27
  %100 = bitcast <2 x i64>* %99 to <4 x i32>*
  %101 = load <4 x i32>, <4 x i32>* %100, align 16
  %102 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %103 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 27
  %104 = add <4 x i32> %101, %98
  %105 = sub <4 x i32> %98, %101
  %106 = load <4 x i32>, <4 x i32>* %16, align 16
  %107 = icmp sgt <4 x i32> %104, %106
  %108 = select <4 x i1> %107, <4 x i32> %104, <4 x i32> %106
  %109 = load <4 x i32>, <4 x i32>* %20, align 16
  %110 = icmp slt <4 x i32> %108, %109
  %111 = select <4 x i1> %110, <4 x i32> %108, <4 x i32> %109
  %112 = icmp sgt <4 x i32> %105, %106
  %113 = select <4 x i1> %112, <4 x i32> %105, <4 x i32> %106
  %114 = icmp slt <4 x i32> %113, %109
  %115 = select <4 x i1> %114, <4 x i32> %113, <4 x i32> %109
  %116 = bitcast <2 x i64>* %102 to <4 x i32>*
  store <4 x i32> %111, <4 x i32>* %116, align 16
  %117 = bitcast <2 x i64>* %103 to <4 x i32>*
  store <4 x i32> %115, <4 x i32>* %117, align 16
  %118 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %119 = bitcast <2 x i64>* %118 to <4 x i32>*
  %120 = load <4 x i32>, <4 x i32>* %119, align 16
  %121 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 26
  %122 = bitcast <2 x i64>* %121 to <4 x i32>*
  %123 = load <4 x i32>, <4 x i32>* %122, align 16
  %124 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %125 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 26
  %126 = add <4 x i32> %123, %120
  %127 = sub <4 x i32> %120, %123
  %128 = load <4 x i32>, <4 x i32>* %16, align 16
  %129 = icmp sgt <4 x i32> %126, %128
  %130 = select <4 x i1> %129, <4 x i32> %126, <4 x i32> %128
  %131 = load <4 x i32>, <4 x i32>* %20, align 16
  %132 = icmp slt <4 x i32> %130, %131
  %133 = select <4 x i1> %132, <4 x i32> %130, <4 x i32> %131
  %134 = icmp sgt <4 x i32> %127, %128
  %135 = select <4 x i1> %134, <4 x i32> %127, <4 x i32> %128
  %136 = icmp slt <4 x i32> %135, %131
  %137 = select <4 x i1> %136, <4 x i32> %135, <4 x i32> %131
  %138 = bitcast <2 x i64>* %124 to <4 x i32>*
  store <4 x i32> %133, <4 x i32>* %138, align 16
  %139 = bitcast <2 x i64>* %125 to <4 x i32>*
  store <4 x i32> %137, <4 x i32>* %139, align 16
  %140 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %141 = bitcast <2 x i64>* %140 to <4 x i32>*
  %142 = load <4 x i32>, <4 x i32>* %141, align 16
  %143 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 25
  %144 = bitcast <2 x i64>* %143 to <4 x i32>*
  %145 = load <4 x i32>, <4 x i32>* %144, align 16
  %146 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %147 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 25
  %148 = add <4 x i32> %145, %142
  %149 = sub <4 x i32> %142, %145
  %150 = load <4 x i32>, <4 x i32>* %16, align 16
  %151 = icmp sgt <4 x i32> %148, %150
  %152 = select <4 x i1> %151, <4 x i32> %148, <4 x i32> %150
  %153 = load <4 x i32>, <4 x i32>* %20, align 16
  %154 = icmp slt <4 x i32> %152, %153
  %155 = select <4 x i1> %154, <4 x i32> %152, <4 x i32> %153
  %156 = icmp sgt <4 x i32> %149, %150
  %157 = select <4 x i1> %156, <4 x i32> %149, <4 x i32> %150
  %158 = icmp slt <4 x i32> %157, %153
  %159 = select <4 x i1> %158, <4 x i32> %157, <4 x i32> %153
  %160 = bitcast <2 x i64>* %146 to <4 x i32>*
  store <4 x i32> %155, <4 x i32>* %160, align 16
  %161 = bitcast <2 x i64>* %147 to <4 x i32>*
  store <4 x i32> %159, <4 x i32>* %161, align 16
  %162 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %163 = bitcast <2 x i64>* %162 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 24
  %166 = bitcast <2 x i64>* %165 to <4 x i32>*
  %167 = load <4 x i32>, <4 x i32>* %166, align 16
  %168 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %169 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 24
  %170 = add <4 x i32> %167, %164
  %171 = sub <4 x i32> %164, %167
  %172 = load <4 x i32>, <4 x i32>* %16, align 16
  %173 = icmp sgt <4 x i32> %170, %172
  %174 = select <4 x i1> %173, <4 x i32> %170, <4 x i32> %172
  %175 = load <4 x i32>, <4 x i32>* %20, align 16
  %176 = icmp slt <4 x i32> %174, %175
  %177 = select <4 x i1> %176, <4 x i32> %174, <4 x i32> %175
  %178 = icmp sgt <4 x i32> %171, %172
  %179 = select <4 x i1> %178, <4 x i32> %171, <4 x i32> %172
  %180 = icmp slt <4 x i32> %179, %175
  %181 = select <4 x i1> %180, <4 x i32> %179, <4 x i32> %175
  %182 = bitcast <2 x i64>* %168 to <4 x i32>*
  store <4 x i32> %177, <4 x i32>* %182, align 16
  %183 = bitcast <2 x i64>* %169 to <4 x i32>*
  store <4 x i32> %181, <4 x i32>* %183, align 16
  %184 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %185 = bitcast <2 x i64>* %184 to <4 x i32>*
  %186 = load <4 x i32>, <4 x i32>* %185, align 16
  %187 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 23
  %188 = bitcast <2 x i64>* %187 to <4 x i32>*
  %189 = load <4 x i32>, <4 x i32>* %188, align 16
  %190 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %191 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 23
  %192 = add <4 x i32> %189, %186
  %193 = sub <4 x i32> %186, %189
  %194 = load <4 x i32>, <4 x i32>* %16, align 16
  %195 = icmp sgt <4 x i32> %192, %194
  %196 = select <4 x i1> %195, <4 x i32> %192, <4 x i32> %194
  %197 = load <4 x i32>, <4 x i32>* %20, align 16
  %198 = icmp slt <4 x i32> %196, %197
  %199 = select <4 x i1> %198, <4 x i32> %196, <4 x i32> %197
  %200 = icmp sgt <4 x i32> %193, %194
  %201 = select <4 x i1> %200, <4 x i32> %193, <4 x i32> %194
  %202 = icmp slt <4 x i32> %201, %197
  %203 = select <4 x i1> %202, <4 x i32> %201, <4 x i32> %197
  %204 = bitcast <2 x i64>* %190 to <4 x i32>*
  store <4 x i32> %199, <4 x i32>* %204, align 16
  %205 = bitcast <2 x i64>* %191 to <4 x i32>*
  store <4 x i32> %203, <4 x i32>* %205, align 16
  %206 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %207 = bitcast <2 x i64>* %206 to <4 x i32>*
  %208 = load <4 x i32>, <4 x i32>* %207, align 16
  %209 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 22
  %210 = bitcast <2 x i64>* %209 to <4 x i32>*
  %211 = load <4 x i32>, <4 x i32>* %210, align 16
  %212 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %213 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 22
  %214 = add <4 x i32> %211, %208
  %215 = sub <4 x i32> %208, %211
  %216 = load <4 x i32>, <4 x i32>* %16, align 16
  %217 = icmp sgt <4 x i32> %214, %216
  %218 = select <4 x i1> %217, <4 x i32> %214, <4 x i32> %216
  %219 = load <4 x i32>, <4 x i32>* %20, align 16
  %220 = icmp slt <4 x i32> %218, %219
  %221 = select <4 x i1> %220, <4 x i32> %218, <4 x i32> %219
  %222 = icmp sgt <4 x i32> %215, %216
  %223 = select <4 x i1> %222, <4 x i32> %215, <4 x i32> %216
  %224 = icmp slt <4 x i32> %223, %219
  %225 = select <4 x i1> %224, <4 x i32> %223, <4 x i32> %219
  %226 = bitcast <2 x i64>* %212 to <4 x i32>*
  store <4 x i32> %221, <4 x i32>* %226, align 16
  %227 = bitcast <2 x i64>* %213 to <4 x i32>*
  store <4 x i32> %225, <4 x i32>* %227, align 16
  %228 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %229 = bitcast <2 x i64>* %228 to <4 x i32>*
  %230 = load <4 x i32>, <4 x i32>* %229, align 16
  %231 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 21
  %232 = bitcast <2 x i64>* %231 to <4 x i32>*
  %233 = load <4 x i32>, <4 x i32>* %232, align 16
  %234 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %235 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 21
  %236 = add <4 x i32> %233, %230
  %237 = sub <4 x i32> %230, %233
  %238 = load <4 x i32>, <4 x i32>* %16, align 16
  %239 = icmp sgt <4 x i32> %236, %238
  %240 = select <4 x i1> %239, <4 x i32> %236, <4 x i32> %238
  %241 = load <4 x i32>, <4 x i32>* %20, align 16
  %242 = icmp slt <4 x i32> %240, %241
  %243 = select <4 x i1> %242, <4 x i32> %240, <4 x i32> %241
  %244 = icmp sgt <4 x i32> %237, %238
  %245 = select <4 x i1> %244, <4 x i32> %237, <4 x i32> %238
  %246 = icmp slt <4 x i32> %245, %241
  %247 = select <4 x i1> %246, <4 x i32> %245, <4 x i32> %241
  %248 = bitcast <2 x i64>* %234 to <4 x i32>*
  store <4 x i32> %243, <4 x i32>* %248, align 16
  %249 = bitcast <2 x i64>* %235 to <4 x i32>*
  store <4 x i32> %247, <4 x i32>* %249, align 16
  %250 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %251 = bitcast <2 x i64>* %250 to <4 x i32>*
  %252 = load <4 x i32>, <4 x i32>* %251, align 16
  %253 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 20
  %254 = bitcast <2 x i64>* %253 to <4 x i32>*
  %255 = load <4 x i32>, <4 x i32>* %254, align 16
  %256 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %257 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 20
  %258 = add <4 x i32> %255, %252
  %259 = sub <4 x i32> %252, %255
  %260 = load <4 x i32>, <4 x i32>* %16, align 16
  %261 = icmp sgt <4 x i32> %258, %260
  %262 = select <4 x i1> %261, <4 x i32> %258, <4 x i32> %260
  %263 = load <4 x i32>, <4 x i32>* %20, align 16
  %264 = icmp slt <4 x i32> %262, %263
  %265 = select <4 x i1> %264, <4 x i32> %262, <4 x i32> %263
  %266 = icmp sgt <4 x i32> %259, %260
  %267 = select <4 x i1> %266, <4 x i32> %259, <4 x i32> %260
  %268 = icmp slt <4 x i32> %267, %263
  %269 = select <4 x i1> %268, <4 x i32> %267, <4 x i32> %263
  %270 = bitcast <2 x i64>* %256 to <4 x i32>*
  store <4 x i32> %265, <4 x i32>* %270, align 16
  %271 = bitcast <2 x i64>* %257 to <4 x i32>*
  store <4 x i32> %269, <4 x i32>* %271, align 16
  %272 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %273 = bitcast <2 x i64>* %272 to <4 x i32>*
  %274 = load <4 x i32>, <4 x i32>* %273, align 16
  %275 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 19
  %276 = bitcast <2 x i64>* %275 to <4 x i32>*
  %277 = load <4 x i32>, <4 x i32>* %276, align 16
  %278 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %279 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 19
  %280 = add <4 x i32> %277, %274
  %281 = sub <4 x i32> %274, %277
  %282 = load <4 x i32>, <4 x i32>* %16, align 16
  %283 = icmp sgt <4 x i32> %280, %282
  %284 = select <4 x i1> %283, <4 x i32> %280, <4 x i32> %282
  %285 = load <4 x i32>, <4 x i32>* %20, align 16
  %286 = icmp slt <4 x i32> %284, %285
  %287 = select <4 x i1> %286, <4 x i32> %284, <4 x i32> %285
  %288 = icmp sgt <4 x i32> %281, %282
  %289 = select <4 x i1> %288, <4 x i32> %281, <4 x i32> %282
  %290 = icmp slt <4 x i32> %289, %285
  %291 = select <4 x i1> %290, <4 x i32> %289, <4 x i32> %285
  %292 = bitcast <2 x i64>* %278 to <4 x i32>*
  store <4 x i32> %287, <4 x i32>* %292, align 16
  %293 = bitcast <2 x i64>* %279 to <4 x i32>*
  store <4 x i32> %291, <4 x i32>* %293, align 16
  %294 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %295 = bitcast <2 x i64>* %294 to <4 x i32>*
  %296 = load <4 x i32>, <4 x i32>* %295, align 16
  %297 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 18
  %298 = bitcast <2 x i64>* %297 to <4 x i32>*
  %299 = load <4 x i32>, <4 x i32>* %298, align 16
  %300 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %301 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 18
  %302 = add <4 x i32> %299, %296
  %303 = sub <4 x i32> %296, %299
  %304 = load <4 x i32>, <4 x i32>* %16, align 16
  %305 = icmp sgt <4 x i32> %302, %304
  %306 = select <4 x i1> %305, <4 x i32> %302, <4 x i32> %304
  %307 = load <4 x i32>, <4 x i32>* %20, align 16
  %308 = icmp slt <4 x i32> %306, %307
  %309 = select <4 x i1> %308, <4 x i32> %306, <4 x i32> %307
  %310 = icmp sgt <4 x i32> %303, %304
  %311 = select <4 x i1> %310, <4 x i32> %303, <4 x i32> %304
  %312 = icmp slt <4 x i32> %311, %307
  %313 = select <4 x i1> %312, <4 x i32> %311, <4 x i32> %307
  %314 = bitcast <2 x i64>* %300 to <4 x i32>*
  store <4 x i32> %309, <4 x i32>* %314, align 16
  %315 = bitcast <2 x i64>* %301 to <4 x i32>*
  store <4 x i32> %313, <4 x i32>* %315, align 16
  %316 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %317 = bitcast <2 x i64>* %316 to <4 x i32>*
  %318 = load <4 x i32>, <4 x i32>* %317, align 16
  %319 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 17
  %320 = bitcast <2 x i64>* %319 to <4 x i32>*
  %321 = load <4 x i32>, <4 x i32>* %320, align 16
  %322 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %323 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 17
  %324 = add <4 x i32> %321, %318
  %325 = sub <4 x i32> %318, %321
  %326 = load <4 x i32>, <4 x i32>* %16, align 16
  %327 = icmp sgt <4 x i32> %324, %326
  %328 = select <4 x i1> %327, <4 x i32> %324, <4 x i32> %326
  %329 = load <4 x i32>, <4 x i32>* %20, align 16
  %330 = icmp slt <4 x i32> %328, %329
  %331 = select <4 x i1> %330, <4 x i32> %328, <4 x i32> %329
  %332 = icmp sgt <4 x i32> %325, %326
  %333 = select <4 x i1> %332, <4 x i32> %325, <4 x i32> %326
  %334 = icmp slt <4 x i32> %333, %329
  %335 = select <4 x i1> %334, <4 x i32> %333, <4 x i32> %329
  %336 = bitcast <2 x i64>* %322 to <4 x i32>*
  store <4 x i32> %331, <4 x i32>* %336, align 16
  %337 = bitcast <2 x i64>* %323 to <4 x i32>*
  store <4 x i32> %335, <4 x i32>* %337, align 16
  %338 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %339 = bitcast <2 x i64>* %338 to <4 x i32>*
  %340 = load <4 x i32>, <4 x i32>* %339, align 16
  %341 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 16
  %342 = bitcast <2 x i64>* %341 to <4 x i32>*
  %343 = load <4 x i32>, <4 x i32>* %342, align 16
  %344 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %345 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 16
  %346 = add <4 x i32> %343, %340
  %347 = sub <4 x i32> %340, %343
  %348 = load <4 x i32>, <4 x i32>* %16, align 16
  %349 = icmp sgt <4 x i32> %346, %348
  %350 = select <4 x i1> %349, <4 x i32> %346, <4 x i32> %348
  %351 = load <4 x i32>, <4 x i32>* %20, align 16
  %352 = icmp slt <4 x i32> %350, %351
  %353 = select <4 x i1> %352, <4 x i32> %350, <4 x i32> %351
  %354 = icmp sgt <4 x i32> %347, %348
  %355 = select <4 x i1> %354, <4 x i32> %347, <4 x i32> %348
  %356 = icmp slt <4 x i32> %355, %351
  %357 = select <4 x i1> %356, <4 x i32> %355, <4 x i32> %351
  %358 = bitcast <2 x i64>* %344 to <4 x i32>*
  store <4 x i32> %353, <4 x i32>* %358, align 16
  %359 = bitcast <2 x i64>* %345 to <4 x i32>*
  store <4 x i32> %357, <4 x i32>* %359, align 16
  %360 = icmp eq i32 %2, 0
  br i1 %360, label %361, label %409

361:                                              ; preds = %7
  %362 = icmp sgt i32 %3, 10
  %363 = select i1 %362, i32 %3, i32 10
  %364 = shl i32 32, %363
  %365 = sub nsw i32 0, %364
  %366 = insertelement <4 x i32> undef, i32 %365, i32 0
  %367 = add nsw i32 %364, -1
  %368 = insertelement <4 x i32> undef, i32 %367, i32 0
  %369 = icmp eq i32 %4, 0
  %370 = add nsw i32 %4, -1
  %371 = shl i32 1, %370
  %372 = insertelement <4 x i32> undef, i32 %371, i32 0
  %373 = shufflevector <4 x i32> %372, <4 x i32> undef, <4 x i32> zeroinitializer
  br i1 %369, label %546, label %410

374:                                              ; preds = %546, %374
  %375 = phi i64 [ %407, %374 ], [ 0, %546 ]
  %376 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %375
  %377 = bitcast <2 x i64>* %376 to <4 x i32>*
  %378 = load <4 x i32>, <4 x i32>* %377, align 16
  %379 = icmp sgt <4 x i32> %378, %547
  %380 = select <4 x i1> %379, <4 x i32> %378, <4 x i32> %547
  %381 = icmp slt <4 x i32> %380, %548
  %382 = select <4 x i1> %381, <4 x i32> %380, <4 x i32> %548
  store <4 x i32> %382, <4 x i32>* %377, align 16
  %383 = or i64 %375, 1
  %384 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %383
  %385 = bitcast <2 x i64>* %384 to <4 x i32>*
  %386 = load <4 x i32>, <4 x i32>* %385, align 16
  %387 = icmp sgt <4 x i32> %386, %547
  %388 = select <4 x i1> %387, <4 x i32> %386, <4 x i32> %547
  %389 = icmp slt <4 x i32> %388, %548
  %390 = select <4 x i1> %389, <4 x i32> %388, <4 x i32> %548
  store <4 x i32> %390, <4 x i32>* %385, align 16
  %391 = or i64 %375, 2
  %392 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %391
  %393 = bitcast <2 x i64>* %392 to <4 x i32>*
  %394 = load <4 x i32>, <4 x i32>* %393, align 16
  %395 = icmp sgt <4 x i32> %394, %547
  %396 = select <4 x i1> %395, <4 x i32> %394, <4 x i32> %547
  %397 = icmp slt <4 x i32> %396, %548
  %398 = select <4 x i1> %397, <4 x i32> %396, <4 x i32> %548
  store <4 x i32> %398, <4 x i32>* %393, align 16
  %399 = or i64 %375, 3
  %400 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %399
  %401 = bitcast <2 x i64>* %400 to <4 x i32>*
  %402 = load <4 x i32>, <4 x i32>* %401, align 16
  %403 = icmp sgt <4 x i32> %402, %547
  %404 = select <4 x i1> %403, <4 x i32> %402, <4 x i32> %547
  %405 = icmp slt <4 x i32> %404, %548
  %406 = select <4 x i1> %405, <4 x i32> %404, <4 x i32> %548
  store <4 x i32> %406, <4 x i32>* %401, align 16
  %407 = add nuw nsw i64 %375, 4
  %408 = icmp ult i64 %407, 32
  br i1 %408, label %374, label %409

409:                                              ; preds = %374, %7
  ret void

410:                                              ; preds = %361
  %411 = load <4 x i32>, <4 x i32>* %28, align 16
  %412 = add <4 x i32> %411, %373
  %413 = load <4 x i32>, <4 x i32>* %50, align 16
  %414 = add <4 x i32> %413, %373
  %415 = load <4 x i32>, <4 x i32>* %72, align 16
  %416 = add <4 x i32> %415, %373
  %417 = load <4 x i32>, <4 x i32>* %94, align 16
  %418 = add <4 x i32> %417, %373
  %419 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %412, i32 %4) #8
  store <4 x i32> %419, <4 x i32>* %28, align 16
  %420 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %414, i32 %4) #8
  store <4 x i32> %420, <4 x i32>* %50, align 16
  %421 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %416, i32 %4) #8
  store <4 x i32> %421, <4 x i32>* %72, align 16
  %422 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %418, i32 %4) #8
  store <4 x i32> %422, <4 x i32>* %94, align 16
  %423 = load <4 x i32>, <4 x i32>* %116, align 16
  %424 = add <4 x i32> %423, %373
  %425 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %426 = bitcast <2 x i64>* %425 to <4 x i32>*
  %427 = load <4 x i32>, <4 x i32>* %426, align 16
  %428 = add <4 x i32> %427, %373
  %429 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %430 = bitcast <2 x i64>* %429 to <4 x i32>*
  %431 = load <4 x i32>, <4 x i32>* %430, align 16
  %432 = add <4 x i32> %431, %373
  %433 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %434 = bitcast <2 x i64>* %433 to <4 x i32>*
  %435 = load <4 x i32>, <4 x i32>* %434, align 16
  %436 = add <4 x i32> %435, %373
  %437 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %424, i32 %4) #8
  store <4 x i32> %437, <4 x i32>* %116, align 16
  %438 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %428, i32 %4) #8
  store <4 x i32> %438, <4 x i32>* %426, align 16
  %439 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %432, i32 %4) #8
  store <4 x i32> %439, <4 x i32>* %430, align 16
  %440 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %436, i32 %4) #8
  store <4 x i32> %440, <4 x i32>* %434, align 16
  %441 = load <4 x i32>, <4 x i32>* %204, align 16
  %442 = add <4 x i32> %441, %373
  %443 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %444 = bitcast <2 x i64>* %443 to <4 x i32>*
  %445 = load <4 x i32>, <4 x i32>* %444, align 16
  %446 = add <4 x i32> %445, %373
  %447 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %448 = bitcast <2 x i64>* %447 to <4 x i32>*
  %449 = load <4 x i32>, <4 x i32>* %448, align 16
  %450 = add <4 x i32> %449, %373
  %451 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %452 = bitcast <2 x i64>* %451 to <4 x i32>*
  %453 = load <4 x i32>, <4 x i32>* %452, align 16
  %454 = add <4 x i32> %453, %373
  %455 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %442, i32 %4) #8
  store <4 x i32> %455, <4 x i32>* %204, align 16
  %456 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %446, i32 %4) #8
  store <4 x i32> %456, <4 x i32>* %444, align 16
  %457 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %450, i32 %4) #8
  store <4 x i32> %457, <4 x i32>* %448, align 16
  %458 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %454, i32 %4) #8
  store <4 x i32> %458, <4 x i32>* %452, align 16
  %459 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %460 = bitcast <2 x i64>* %459 to <4 x i32>*
  %461 = add <4 x i32> %287, %373
  %462 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %463 = bitcast <2 x i64>* %462 to <4 x i32>*
  %464 = add <4 x i32> %309, %373
  %465 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %466 = bitcast <2 x i64>* %465 to <4 x i32>*
  %467 = add <4 x i32> %331, %373
  %468 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %469 = bitcast <2 x i64>* %468 to <4 x i32>*
  %470 = add <4 x i32> %353, %373
  %471 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %461, i32 %4) #8
  store <4 x i32> %471, <4 x i32>* %460, align 16
  %472 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %464, i32 %4) #8
  store <4 x i32> %472, <4 x i32>* %463, align 16
  %473 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %467, i32 %4) #8
  store <4 x i32> %473, <4 x i32>* %466, align 16
  %474 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %470, i32 %4) #8
  store <4 x i32> %474, <4 x i32>* %469, align 16
  %475 = add <4 x i32> %357, %373
  %476 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 17
  %477 = bitcast <2 x i64>* %476 to <4 x i32>*
  %478 = add <4 x i32> %335, %373
  %479 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 18
  %480 = bitcast <2 x i64>* %479 to <4 x i32>*
  %481 = add <4 x i32> %313, %373
  %482 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 19
  %483 = bitcast <2 x i64>* %482 to <4 x i32>*
  %484 = add <4 x i32> %291, %373
  %485 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %475, i32 %4) #8
  store <4 x i32> %485, <4 x i32>* %359, align 16
  %486 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %478, i32 %4) #8
  store <4 x i32> %486, <4 x i32>* %477, align 16
  %487 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %481, i32 %4) #8
  store <4 x i32> %487, <4 x i32>* %480, align 16
  %488 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %484, i32 %4) #8
  store <4 x i32> %488, <4 x i32>* %483, align 16
  %489 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 20
  %490 = bitcast <2 x i64>* %489 to <4 x i32>*
  %491 = add <4 x i32> %269, %373
  %492 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 21
  %493 = bitcast <2 x i64>* %492 to <4 x i32>*
  %494 = load <4 x i32>, <4 x i32>* %493, align 16
  %495 = add <4 x i32> %494, %373
  %496 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 22
  %497 = bitcast <2 x i64>* %496 to <4 x i32>*
  %498 = load <4 x i32>, <4 x i32>* %497, align 16
  %499 = add <4 x i32> %498, %373
  %500 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 23
  %501 = bitcast <2 x i64>* %500 to <4 x i32>*
  %502 = load <4 x i32>, <4 x i32>* %501, align 16
  %503 = add <4 x i32> %502, %373
  %504 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %491, i32 %4) #8
  store <4 x i32> %504, <4 x i32>* %490, align 16
  %505 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %495, i32 %4) #8
  store <4 x i32> %505, <4 x i32>* %493, align 16
  %506 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %499, i32 %4) #8
  store <4 x i32> %506, <4 x i32>* %497, align 16
  %507 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %503, i32 %4) #8
  store <4 x i32> %507, <4 x i32>* %501, align 16
  %508 = load <4 x i32>, <4 x i32>* %183, align 16
  %509 = add <4 x i32> %508, %373
  %510 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 25
  %511 = bitcast <2 x i64>* %510 to <4 x i32>*
  %512 = load <4 x i32>, <4 x i32>* %511, align 16
  %513 = add <4 x i32> %512, %373
  %514 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 26
  %515 = bitcast <2 x i64>* %514 to <4 x i32>*
  %516 = load <4 x i32>, <4 x i32>* %515, align 16
  %517 = add <4 x i32> %516, %373
  %518 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 27
  %519 = bitcast <2 x i64>* %518 to <4 x i32>*
  %520 = load <4 x i32>, <4 x i32>* %519, align 16
  %521 = add <4 x i32> %520, %373
  %522 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %509, i32 %4) #8
  store <4 x i32> %522, <4 x i32>* %183, align 16
  %523 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %513, i32 %4) #8
  store <4 x i32> %523, <4 x i32>* %511, align 16
  %524 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %517, i32 %4) #8
  store <4 x i32> %524, <4 x i32>* %515, align 16
  %525 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %521, i32 %4) #8
  store <4 x i32> %525, <4 x i32>* %519, align 16
  %526 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 28
  %527 = bitcast <2 x i64>* %526 to <4 x i32>*
  %528 = load <4 x i32>, <4 x i32>* %527, align 16
  %529 = add <4 x i32> %528, %373
  %530 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 29
  %531 = bitcast <2 x i64>* %530 to <4 x i32>*
  %532 = load <4 x i32>, <4 x i32>* %531, align 16
  %533 = add <4 x i32> %532, %373
  %534 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 30
  %535 = bitcast <2 x i64>* %534 to <4 x i32>*
  %536 = load <4 x i32>, <4 x i32>* %535, align 16
  %537 = add <4 x i32> %536, %373
  %538 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 31
  %539 = bitcast <2 x i64>* %538 to <4 x i32>*
  %540 = load <4 x i32>, <4 x i32>* %539, align 16
  %541 = add <4 x i32> %540, %373
  %542 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %529, i32 %4) #8
  store <4 x i32> %542, <4 x i32>* %527, align 16
  %543 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %533, i32 %4) #8
  store <4 x i32> %543, <4 x i32>* %531, align 16
  %544 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %537, i32 %4) #8
  store <4 x i32> %544, <4 x i32>* %535, align 16
  %545 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %541, i32 %4) #8
  store <4 x i32> %545, <4 x i32>* %539, align 16
  br label %546

546:                                              ; preds = %361, %410
  %547 = shufflevector <4 x i32> %366, <4 x i32> undef, <4 x i32> zeroinitializer
  %548 = shufflevector <4 x i32> %368, <4 x i32> undef, <4 x i32> zeroinitializer
  br label %374
}

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pslli.d(<4 x i32>, i32) #5

; Function Attrs: inlinehint nofree nounwind ssp uwtable
define internal fastcc void @idct64_stage9_sse4_1(<2 x i64>* nocapture, <2 x i64>* nocapture readonly, <2 x i64>* nocapture readonly, <2 x i64>* nocapture readonly, <2 x i64>* nocapture readonly, <2 x i64>* nocapture readonly, i32) unnamed_addr #7 {
  %8 = bitcast <2 x i64>* %3 to <4 x i32>*
  %9 = bitcast <2 x i64>* %4 to <4 x i32>*
  %10 = bitcast <2 x i64>* %0 to <4 x i32>*
  %11 = load <4 x i32>, <4 x i32>* %10, align 16
  %12 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %13 = bitcast <2 x i64>* %12 to <4 x i32>*
  %14 = load <4 x i32>, <4 x i32>* %13, align 16
  %15 = add <4 x i32> %14, %11
  %16 = sub <4 x i32> %11, %14
  %17 = load <4 x i32>, <4 x i32>* %8, align 16
  %18 = icmp sgt <4 x i32> %15, %17
  %19 = select <4 x i1> %18, <4 x i32> %15, <4 x i32> %17
  %20 = load <4 x i32>, <4 x i32>* %9, align 16
  %21 = icmp slt <4 x i32> %19, %20
  %22 = select <4 x i1> %21, <4 x i32> %19, <4 x i32> %20
  %23 = icmp sgt <4 x i32> %16, %17
  %24 = select <4 x i1> %23, <4 x i32> %16, <4 x i32> %17
  %25 = icmp slt <4 x i32> %24, %20
  %26 = select <4 x i1> %25, <4 x i32> %24, <4 x i32> %20
  store <4 x i32> %22, <4 x i32>* %10, align 16
  store <4 x i32> %26, <4 x i32>* %13, align 16
  %27 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %28 = bitcast <2 x i64>* %27 to <4 x i32>*
  %29 = load <4 x i32>, <4 x i32>* %28, align 16
  %30 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %31 = bitcast <2 x i64>* %30 to <4 x i32>*
  %32 = load <4 x i32>, <4 x i32>* %31, align 16
  %33 = add <4 x i32> %32, %29
  %34 = sub <4 x i32> %29, %32
  %35 = load <4 x i32>, <4 x i32>* %8, align 16
  %36 = icmp sgt <4 x i32> %33, %35
  %37 = select <4 x i1> %36, <4 x i32> %33, <4 x i32> %35
  %38 = load <4 x i32>, <4 x i32>* %9, align 16
  %39 = icmp slt <4 x i32> %37, %38
  %40 = select <4 x i1> %39, <4 x i32> %37, <4 x i32> %38
  %41 = icmp sgt <4 x i32> %34, %35
  %42 = select <4 x i1> %41, <4 x i32> %34, <4 x i32> %35
  %43 = icmp slt <4 x i32> %42, %38
  %44 = select <4 x i1> %43, <4 x i32> %42, <4 x i32> %38
  store <4 x i32> %40, <4 x i32>* %28, align 16
  store <4 x i32> %44, <4 x i32>* %31, align 16
  %45 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %46 = bitcast <2 x i64>* %45 to <4 x i32>*
  %47 = load <4 x i32>, <4 x i32>* %46, align 16
  %48 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %49 = bitcast <2 x i64>* %48 to <4 x i32>*
  %50 = load <4 x i32>, <4 x i32>* %49, align 16
  %51 = add <4 x i32> %50, %47
  %52 = sub <4 x i32> %47, %50
  %53 = load <4 x i32>, <4 x i32>* %8, align 16
  %54 = icmp sgt <4 x i32> %51, %53
  %55 = select <4 x i1> %54, <4 x i32> %51, <4 x i32> %53
  %56 = load <4 x i32>, <4 x i32>* %9, align 16
  %57 = icmp slt <4 x i32> %55, %56
  %58 = select <4 x i1> %57, <4 x i32> %55, <4 x i32> %56
  %59 = icmp sgt <4 x i32> %52, %53
  %60 = select <4 x i1> %59, <4 x i32> %52, <4 x i32> %53
  %61 = icmp slt <4 x i32> %60, %56
  %62 = select <4 x i1> %61, <4 x i32> %60, <4 x i32> %56
  store <4 x i32> %58, <4 x i32>* %46, align 16
  store <4 x i32> %62, <4 x i32>* %49, align 16
  %63 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %64 = bitcast <2 x i64>* %63 to <4 x i32>*
  %65 = load <4 x i32>, <4 x i32>* %64, align 16
  %66 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %67 = bitcast <2 x i64>* %66 to <4 x i32>*
  %68 = load <4 x i32>, <4 x i32>* %67, align 16
  %69 = add <4 x i32> %68, %65
  %70 = sub <4 x i32> %65, %68
  %71 = load <4 x i32>, <4 x i32>* %8, align 16
  %72 = icmp sgt <4 x i32> %69, %71
  %73 = select <4 x i1> %72, <4 x i32> %69, <4 x i32> %71
  %74 = load <4 x i32>, <4 x i32>* %9, align 16
  %75 = icmp slt <4 x i32> %73, %74
  %76 = select <4 x i1> %75, <4 x i32> %73, <4 x i32> %74
  %77 = icmp sgt <4 x i32> %70, %71
  %78 = select <4 x i1> %77, <4 x i32> %70, <4 x i32> %71
  %79 = icmp slt <4 x i32> %78, %74
  %80 = select <4 x i1> %79, <4 x i32> %78, <4 x i32> %74
  store <4 x i32> %76, <4 x i32>* %64, align 16
  store <4 x i32> %80, <4 x i32>* %67, align 16
  %81 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %82 = bitcast <2 x i64>* %81 to <4 x i32>*
  %83 = load <4 x i32>, <4 x i32>* %82, align 16
  %84 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %85 = bitcast <2 x i64>* %84 to <4 x i32>*
  %86 = load <4 x i32>, <4 x i32>* %85, align 16
  %87 = add <4 x i32> %86, %83
  %88 = sub <4 x i32> %83, %86
  %89 = load <4 x i32>, <4 x i32>* %8, align 16
  %90 = icmp sgt <4 x i32> %87, %89
  %91 = select <4 x i1> %90, <4 x i32> %87, <4 x i32> %89
  %92 = load <4 x i32>, <4 x i32>* %9, align 16
  %93 = icmp slt <4 x i32> %91, %92
  %94 = select <4 x i1> %93, <4 x i32> %91, <4 x i32> %92
  %95 = icmp sgt <4 x i32> %88, %89
  %96 = select <4 x i1> %95, <4 x i32> %88, <4 x i32> %89
  %97 = icmp slt <4 x i32> %96, %92
  %98 = select <4 x i1> %97, <4 x i32> %96, <4 x i32> %92
  store <4 x i32> %94, <4 x i32>* %82, align 16
  store <4 x i32> %98, <4 x i32>* %85, align 16
  %99 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %100 = bitcast <2 x i64>* %99 to <4 x i32>*
  %101 = load <4 x i32>, <4 x i32>* %100, align 16
  %102 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %103 = bitcast <2 x i64>* %102 to <4 x i32>*
  %104 = load <4 x i32>, <4 x i32>* %103, align 16
  %105 = add <4 x i32> %104, %101
  %106 = sub <4 x i32> %101, %104
  %107 = load <4 x i32>, <4 x i32>* %8, align 16
  %108 = icmp sgt <4 x i32> %105, %107
  %109 = select <4 x i1> %108, <4 x i32> %105, <4 x i32> %107
  %110 = load <4 x i32>, <4 x i32>* %9, align 16
  %111 = icmp slt <4 x i32> %109, %110
  %112 = select <4 x i1> %111, <4 x i32> %109, <4 x i32> %110
  %113 = icmp sgt <4 x i32> %106, %107
  %114 = select <4 x i1> %113, <4 x i32> %106, <4 x i32> %107
  %115 = icmp slt <4 x i32> %114, %110
  %116 = select <4 x i1> %115, <4 x i32> %114, <4 x i32> %110
  store <4 x i32> %112, <4 x i32>* %100, align 16
  store <4 x i32> %116, <4 x i32>* %103, align 16
  %117 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %118 = bitcast <2 x i64>* %117 to <4 x i32>*
  %119 = load <4 x i32>, <4 x i32>* %118, align 16
  %120 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %121 = bitcast <2 x i64>* %120 to <4 x i32>*
  %122 = load <4 x i32>, <4 x i32>* %121, align 16
  %123 = add <4 x i32> %122, %119
  %124 = sub <4 x i32> %119, %122
  %125 = load <4 x i32>, <4 x i32>* %8, align 16
  %126 = icmp sgt <4 x i32> %123, %125
  %127 = select <4 x i1> %126, <4 x i32> %123, <4 x i32> %125
  %128 = load <4 x i32>, <4 x i32>* %9, align 16
  %129 = icmp slt <4 x i32> %127, %128
  %130 = select <4 x i1> %129, <4 x i32> %127, <4 x i32> %128
  %131 = icmp sgt <4 x i32> %124, %125
  %132 = select <4 x i1> %131, <4 x i32> %124, <4 x i32> %125
  %133 = icmp slt <4 x i32> %132, %128
  %134 = select <4 x i1> %133, <4 x i32> %132, <4 x i32> %128
  store <4 x i32> %130, <4 x i32>* %118, align 16
  store <4 x i32> %134, <4 x i32>* %121, align 16
  %135 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %136 = bitcast <2 x i64>* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 16
  %138 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %139 = bitcast <2 x i64>* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 16
  %141 = add <4 x i32> %140, %137
  %142 = sub <4 x i32> %137, %140
  %143 = load <4 x i32>, <4 x i32>* %8, align 16
  %144 = icmp sgt <4 x i32> %141, %143
  %145 = select <4 x i1> %144, <4 x i32> %141, <4 x i32> %143
  %146 = load <4 x i32>, <4 x i32>* %9, align 16
  %147 = icmp slt <4 x i32> %145, %146
  %148 = select <4 x i1> %147, <4 x i32> %145, <4 x i32> %146
  %149 = icmp sgt <4 x i32> %142, %143
  %150 = select <4 x i1> %149, <4 x i32> %142, <4 x i32> %143
  %151 = icmp slt <4 x i32> %150, %146
  %152 = select <4 x i1> %151, <4 x i32> %150, <4 x i32> %146
  store <4 x i32> %148, <4 x i32>* %136, align 16
  store <4 x i32> %152, <4 x i32>* %139, align 16
  %153 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 20
  %154 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 27
  %155 = bitcast <2 x i64>* %1 to <4 x i32>*
  %156 = load <4 x i32>, <4 x i32>* %155, align 16
  %157 = bitcast <2 x i64>* %153 to <4 x i32>*
  %158 = load <4 x i32>, <4 x i32>* %157, align 16
  %159 = mul <4 x i32> %158, %156
  %160 = bitcast <2 x i64>* %2 to <4 x i32>*
  %161 = load <4 x i32>, <4 x i32>* %160, align 16
  %162 = bitcast <2 x i64>* %154 to <4 x i32>*
  %163 = load <4 x i32>, <4 x i32>* %162, align 16
  %164 = mul <4 x i32> %163, %161
  %165 = add <4 x i32> %164, %159
  %166 = bitcast <2 x i64>* %5 to <4 x i32>*
  %167 = load <4 x i32>, <4 x i32>* %166, align 16
  %168 = add <4 x i32> %165, %167
  %169 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %168, i32 %6) #8
  %170 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 21
  %171 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 26
  %172 = bitcast <2 x i64>* %170 to <4 x i32>*
  %173 = load <4 x i32>, <4 x i32>* %172, align 16
  %174 = mul <4 x i32> %173, %156
  %175 = bitcast <2 x i64>* %171 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = mul <4 x i32> %176, %161
  %178 = add <4 x i32> %174, %167
  %179 = add <4 x i32> %178, %177
  %180 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %179, i32 %6) #8
  %181 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 22
  %182 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 25
  %183 = bitcast <2 x i64>* %181 to <4 x i32>*
  %184 = load <4 x i32>, <4 x i32>* %183, align 16
  %185 = mul <4 x i32> %184, %156
  %186 = bitcast <2 x i64>* %182 to <4 x i32>*
  %187 = load <4 x i32>, <4 x i32>* %186, align 16
  %188 = mul <4 x i32> %187, %161
  %189 = add <4 x i32> %185, %167
  %190 = add <4 x i32> %189, %188
  %191 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %190, i32 %6) #8
  %192 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 23
  %193 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 24
  %194 = bitcast <2 x i64>* %192 to <4 x i32>*
  %195 = load <4 x i32>, <4 x i32>* %194, align 16
  %196 = mul <4 x i32> %195, %156
  %197 = bitcast <2 x i64>* %193 to <4 x i32>*
  %198 = load <4 x i32>, <4 x i32>* %197, align 16
  %199 = mul <4 x i32> %198, %161
  %200 = add <4 x i32> %199, %167
  %201 = add <4 x i32> %200, %196
  %202 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %201, i32 %6) #8
  %203 = mul <4 x i32> %195, %161
  %204 = add <4 x i32> %200, %203
  %205 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %204, i32 %6) #8
  store <4 x i32> %205, <4 x i32>* %197, align 16
  %206 = load <4 x i32>, <4 x i32>* %160, align 16
  %207 = add <4 x i32> %187, %184
  %208 = mul <4 x i32> %206, %207
  %209 = load <4 x i32>, <4 x i32>* %166, align 16
  %210 = add <4 x i32> %208, %209
  %211 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %210, i32 %6) #8
  store <4 x i32> %211, <4 x i32>* %186, align 16
  %212 = load <4 x i32>, <4 x i32>* %160, align 16
  %213 = add <4 x i32> %176, %173
  %214 = mul <4 x i32> %212, %213
  %215 = load <4 x i32>, <4 x i32>* %166, align 16
  %216 = add <4 x i32> %214, %215
  %217 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %216, i32 %6) #8
  store <4 x i32> %217, <4 x i32>* %175, align 16
  %218 = load <4 x i32>, <4 x i32>* %160, align 16
  %219 = add <4 x i32> %163, %158
  %220 = mul <4 x i32> %218, %219
  %221 = load <4 x i32>, <4 x i32>* %166, align 16
  %222 = add <4 x i32> %220, %221
  %223 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %222, i32 %6) #8
  store <4 x i32> %223, <4 x i32>* %162, align 16
  store <4 x i32> %169, <4 x i32>* %157, align 16
  store <4 x i32> %180, <4 x i32>* %172, align 16
  store <4 x i32> %191, <4 x i32>* %183, align 16
  store <4 x i32> %202, <4 x i32>* %194, align 16
  %224 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 32
  %225 = bitcast <2 x i64>* %224 to <4 x i32>*
  %226 = load <4 x i32>, <4 x i32>* %225, align 16
  %227 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 47
  %228 = bitcast <2 x i64>* %227 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16
  %230 = add <4 x i32> %229, %226
  %231 = sub <4 x i32> %226, %229
  %232 = load <4 x i32>, <4 x i32>* %8, align 16
  %233 = icmp sgt <4 x i32> %230, %232
  %234 = select <4 x i1> %233, <4 x i32> %230, <4 x i32> %232
  %235 = load <4 x i32>, <4 x i32>* %9, align 16
  %236 = icmp slt <4 x i32> %234, %235
  %237 = select <4 x i1> %236, <4 x i32> %234, <4 x i32> %235
  %238 = icmp sgt <4 x i32> %231, %232
  %239 = select <4 x i1> %238, <4 x i32> %231, <4 x i32> %232
  %240 = icmp slt <4 x i32> %239, %235
  %241 = select <4 x i1> %240, <4 x i32> %239, <4 x i32> %235
  store <4 x i32> %237, <4 x i32>* %225, align 16
  store <4 x i32> %241, <4 x i32>* %228, align 16
  %242 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 33
  %243 = bitcast <2 x i64>* %242 to <4 x i32>*
  %244 = load <4 x i32>, <4 x i32>* %243, align 16
  %245 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 46
  %246 = bitcast <2 x i64>* %245 to <4 x i32>*
  %247 = load <4 x i32>, <4 x i32>* %246, align 16
  %248 = add <4 x i32> %247, %244
  %249 = sub <4 x i32> %244, %247
  %250 = load <4 x i32>, <4 x i32>* %8, align 16
  %251 = icmp sgt <4 x i32> %248, %250
  %252 = select <4 x i1> %251, <4 x i32> %248, <4 x i32> %250
  %253 = load <4 x i32>, <4 x i32>* %9, align 16
  %254 = icmp slt <4 x i32> %252, %253
  %255 = select <4 x i1> %254, <4 x i32> %252, <4 x i32> %253
  %256 = icmp sgt <4 x i32> %249, %250
  %257 = select <4 x i1> %256, <4 x i32> %249, <4 x i32> %250
  %258 = icmp slt <4 x i32> %257, %253
  %259 = select <4 x i1> %258, <4 x i32> %257, <4 x i32> %253
  store <4 x i32> %255, <4 x i32>* %243, align 16
  store <4 x i32> %259, <4 x i32>* %246, align 16
  %260 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 34
  %261 = bitcast <2 x i64>* %260 to <4 x i32>*
  %262 = load <4 x i32>, <4 x i32>* %261, align 16
  %263 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 45
  %264 = bitcast <2 x i64>* %263 to <4 x i32>*
  %265 = load <4 x i32>, <4 x i32>* %264, align 16
  %266 = add <4 x i32> %265, %262
  %267 = sub <4 x i32> %262, %265
  %268 = load <4 x i32>, <4 x i32>* %8, align 16
  %269 = icmp sgt <4 x i32> %266, %268
  %270 = select <4 x i1> %269, <4 x i32> %266, <4 x i32> %268
  %271 = load <4 x i32>, <4 x i32>* %9, align 16
  %272 = icmp slt <4 x i32> %270, %271
  %273 = select <4 x i1> %272, <4 x i32> %270, <4 x i32> %271
  %274 = icmp sgt <4 x i32> %267, %268
  %275 = select <4 x i1> %274, <4 x i32> %267, <4 x i32> %268
  %276 = icmp slt <4 x i32> %275, %271
  %277 = select <4 x i1> %276, <4 x i32> %275, <4 x i32> %271
  store <4 x i32> %273, <4 x i32>* %261, align 16
  store <4 x i32> %277, <4 x i32>* %264, align 16
  %278 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 35
  %279 = bitcast <2 x i64>* %278 to <4 x i32>*
  %280 = load <4 x i32>, <4 x i32>* %279, align 16
  %281 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 44
  %282 = bitcast <2 x i64>* %281 to <4 x i32>*
  %283 = load <4 x i32>, <4 x i32>* %282, align 16
  %284 = add <4 x i32> %283, %280
  %285 = sub <4 x i32> %280, %283
  %286 = load <4 x i32>, <4 x i32>* %8, align 16
  %287 = icmp sgt <4 x i32> %284, %286
  %288 = select <4 x i1> %287, <4 x i32> %284, <4 x i32> %286
  %289 = load <4 x i32>, <4 x i32>* %9, align 16
  %290 = icmp slt <4 x i32> %288, %289
  %291 = select <4 x i1> %290, <4 x i32> %288, <4 x i32> %289
  %292 = icmp sgt <4 x i32> %285, %286
  %293 = select <4 x i1> %292, <4 x i32> %285, <4 x i32> %286
  %294 = icmp slt <4 x i32> %293, %289
  %295 = select <4 x i1> %294, <4 x i32> %293, <4 x i32> %289
  store <4 x i32> %291, <4 x i32>* %279, align 16
  store <4 x i32> %295, <4 x i32>* %282, align 16
  %296 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 36
  %297 = bitcast <2 x i64>* %296 to <4 x i32>*
  %298 = load <4 x i32>, <4 x i32>* %297, align 16
  %299 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 43
  %300 = bitcast <2 x i64>* %299 to <4 x i32>*
  %301 = load <4 x i32>, <4 x i32>* %300, align 16
  %302 = add <4 x i32> %301, %298
  %303 = sub <4 x i32> %298, %301
  %304 = load <4 x i32>, <4 x i32>* %8, align 16
  %305 = icmp sgt <4 x i32> %302, %304
  %306 = select <4 x i1> %305, <4 x i32> %302, <4 x i32> %304
  %307 = load <4 x i32>, <4 x i32>* %9, align 16
  %308 = icmp slt <4 x i32> %306, %307
  %309 = select <4 x i1> %308, <4 x i32> %306, <4 x i32> %307
  %310 = icmp sgt <4 x i32> %303, %304
  %311 = select <4 x i1> %310, <4 x i32> %303, <4 x i32> %304
  %312 = icmp slt <4 x i32> %311, %307
  %313 = select <4 x i1> %312, <4 x i32> %311, <4 x i32> %307
  store <4 x i32> %309, <4 x i32>* %297, align 16
  store <4 x i32> %313, <4 x i32>* %300, align 16
  %314 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 37
  %315 = bitcast <2 x i64>* %314 to <4 x i32>*
  %316 = load <4 x i32>, <4 x i32>* %315, align 16
  %317 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 42
  %318 = bitcast <2 x i64>* %317 to <4 x i32>*
  %319 = load <4 x i32>, <4 x i32>* %318, align 16
  %320 = add <4 x i32> %319, %316
  %321 = sub <4 x i32> %316, %319
  %322 = load <4 x i32>, <4 x i32>* %8, align 16
  %323 = icmp sgt <4 x i32> %320, %322
  %324 = select <4 x i1> %323, <4 x i32> %320, <4 x i32> %322
  %325 = load <4 x i32>, <4 x i32>* %9, align 16
  %326 = icmp slt <4 x i32> %324, %325
  %327 = select <4 x i1> %326, <4 x i32> %324, <4 x i32> %325
  %328 = icmp sgt <4 x i32> %321, %322
  %329 = select <4 x i1> %328, <4 x i32> %321, <4 x i32> %322
  %330 = icmp slt <4 x i32> %329, %325
  %331 = select <4 x i1> %330, <4 x i32> %329, <4 x i32> %325
  store <4 x i32> %327, <4 x i32>* %315, align 16
  store <4 x i32> %331, <4 x i32>* %318, align 16
  %332 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 38
  %333 = bitcast <2 x i64>* %332 to <4 x i32>*
  %334 = load <4 x i32>, <4 x i32>* %333, align 16
  %335 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 41
  %336 = bitcast <2 x i64>* %335 to <4 x i32>*
  %337 = load <4 x i32>, <4 x i32>* %336, align 16
  %338 = add <4 x i32> %337, %334
  %339 = sub <4 x i32> %334, %337
  %340 = load <4 x i32>, <4 x i32>* %8, align 16
  %341 = icmp sgt <4 x i32> %338, %340
  %342 = select <4 x i1> %341, <4 x i32> %338, <4 x i32> %340
  %343 = load <4 x i32>, <4 x i32>* %9, align 16
  %344 = icmp slt <4 x i32> %342, %343
  %345 = select <4 x i1> %344, <4 x i32> %342, <4 x i32> %343
  %346 = icmp sgt <4 x i32> %339, %340
  %347 = select <4 x i1> %346, <4 x i32> %339, <4 x i32> %340
  %348 = icmp slt <4 x i32> %347, %343
  %349 = select <4 x i1> %348, <4 x i32> %347, <4 x i32> %343
  store <4 x i32> %345, <4 x i32>* %333, align 16
  store <4 x i32> %349, <4 x i32>* %336, align 16
  %350 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 39
  %351 = bitcast <2 x i64>* %350 to <4 x i32>*
  %352 = load <4 x i32>, <4 x i32>* %351, align 16
  %353 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 40
  %354 = bitcast <2 x i64>* %353 to <4 x i32>*
  %355 = load <4 x i32>, <4 x i32>* %354, align 16
  %356 = add <4 x i32> %355, %352
  %357 = sub <4 x i32> %352, %355
  %358 = load <4 x i32>, <4 x i32>* %8, align 16
  %359 = icmp sgt <4 x i32> %356, %358
  %360 = select <4 x i1> %359, <4 x i32> %356, <4 x i32> %358
  %361 = load <4 x i32>, <4 x i32>* %9, align 16
  %362 = icmp slt <4 x i32> %360, %361
  %363 = select <4 x i1> %362, <4 x i32> %360, <4 x i32> %361
  %364 = icmp sgt <4 x i32> %357, %358
  %365 = select <4 x i1> %364, <4 x i32> %357, <4 x i32> %358
  %366 = icmp slt <4 x i32> %365, %361
  %367 = select <4 x i1> %366, <4 x i32> %365, <4 x i32> %361
  store <4 x i32> %363, <4 x i32>* %351, align 16
  store <4 x i32> %367, <4 x i32>* %354, align 16
  %368 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 63
  %369 = bitcast <2 x i64>* %368 to <4 x i32>*
  %370 = load <4 x i32>, <4 x i32>* %369, align 16
  %371 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 48
  %372 = bitcast <2 x i64>* %371 to <4 x i32>*
  %373 = load <4 x i32>, <4 x i32>* %372, align 16
  %374 = add <4 x i32> %373, %370
  %375 = sub <4 x i32> %370, %373
  %376 = load <4 x i32>, <4 x i32>* %8, align 16
  %377 = icmp sgt <4 x i32> %374, %376
  %378 = select <4 x i1> %377, <4 x i32> %374, <4 x i32> %376
  %379 = load <4 x i32>, <4 x i32>* %9, align 16
  %380 = icmp slt <4 x i32> %378, %379
  %381 = select <4 x i1> %380, <4 x i32> %378, <4 x i32> %379
  %382 = icmp sgt <4 x i32> %375, %376
  %383 = select <4 x i1> %382, <4 x i32> %375, <4 x i32> %376
  %384 = icmp slt <4 x i32> %383, %379
  %385 = select <4 x i1> %384, <4 x i32> %383, <4 x i32> %379
  store <4 x i32> %381, <4 x i32>* %369, align 16
  store <4 x i32> %385, <4 x i32>* %372, align 16
  %386 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 62
  %387 = bitcast <2 x i64>* %386 to <4 x i32>*
  %388 = load <4 x i32>, <4 x i32>* %387, align 16
  %389 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 49
  %390 = bitcast <2 x i64>* %389 to <4 x i32>*
  %391 = load <4 x i32>, <4 x i32>* %390, align 16
  %392 = add <4 x i32> %391, %388
  %393 = sub <4 x i32> %388, %391
  %394 = load <4 x i32>, <4 x i32>* %8, align 16
  %395 = icmp sgt <4 x i32> %392, %394
  %396 = select <4 x i1> %395, <4 x i32> %392, <4 x i32> %394
  %397 = load <4 x i32>, <4 x i32>* %9, align 16
  %398 = icmp slt <4 x i32> %396, %397
  %399 = select <4 x i1> %398, <4 x i32> %396, <4 x i32> %397
  %400 = icmp sgt <4 x i32> %393, %394
  %401 = select <4 x i1> %400, <4 x i32> %393, <4 x i32> %394
  %402 = icmp slt <4 x i32> %401, %397
  %403 = select <4 x i1> %402, <4 x i32> %401, <4 x i32> %397
  store <4 x i32> %399, <4 x i32>* %387, align 16
  store <4 x i32> %403, <4 x i32>* %390, align 16
  %404 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 61
  %405 = bitcast <2 x i64>* %404 to <4 x i32>*
  %406 = load <4 x i32>, <4 x i32>* %405, align 16
  %407 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 50
  %408 = bitcast <2 x i64>* %407 to <4 x i32>*
  %409 = load <4 x i32>, <4 x i32>* %408, align 16
  %410 = add <4 x i32> %409, %406
  %411 = sub <4 x i32> %406, %409
  %412 = load <4 x i32>, <4 x i32>* %8, align 16
  %413 = icmp sgt <4 x i32> %410, %412
  %414 = select <4 x i1> %413, <4 x i32> %410, <4 x i32> %412
  %415 = load <4 x i32>, <4 x i32>* %9, align 16
  %416 = icmp slt <4 x i32> %414, %415
  %417 = select <4 x i1> %416, <4 x i32> %414, <4 x i32> %415
  %418 = icmp sgt <4 x i32> %411, %412
  %419 = select <4 x i1> %418, <4 x i32> %411, <4 x i32> %412
  %420 = icmp slt <4 x i32> %419, %415
  %421 = select <4 x i1> %420, <4 x i32> %419, <4 x i32> %415
  store <4 x i32> %417, <4 x i32>* %405, align 16
  store <4 x i32> %421, <4 x i32>* %408, align 16
  %422 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 60
  %423 = bitcast <2 x i64>* %422 to <4 x i32>*
  %424 = load <4 x i32>, <4 x i32>* %423, align 16
  %425 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 51
  %426 = bitcast <2 x i64>* %425 to <4 x i32>*
  %427 = load <4 x i32>, <4 x i32>* %426, align 16
  %428 = add <4 x i32> %427, %424
  %429 = sub <4 x i32> %424, %427
  %430 = load <4 x i32>, <4 x i32>* %8, align 16
  %431 = icmp sgt <4 x i32> %428, %430
  %432 = select <4 x i1> %431, <4 x i32> %428, <4 x i32> %430
  %433 = load <4 x i32>, <4 x i32>* %9, align 16
  %434 = icmp slt <4 x i32> %432, %433
  %435 = select <4 x i1> %434, <4 x i32> %432, <4 x i32> %433
  %436 = icmp sgt <4 x i32> %429, %430
  %437 = select <4 x i1> %436, <4 x i32> %429, <4 x i32> %430
  %438 = icmp slt <4 x i32> %437, %433
  %439 = select <4 x i1> %438, <4 x i32> %437, <4 x i32> %433
  store <4 x i32> %435, <4 x i32>* %423, align 16
  store <4 x i32> %439, <4 x i32>* %426, align 16
  %440 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 59
  %441 = bitcast <2 x i64>* %440 to <4 x i32>*
  %442 = load <4 x i32>, <4 x i32>* %441, align 16
  %443 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 52
  %444 = bitcast <2 x i64>* %443 to <4 x i32>*
  %445 = load <4 x i32>, <4 x i32>* %444, align 16
  %446 = add <4 x i32> %445, %442
  %447 = sub <4 x i32> %442, %445
  %448 = load <4 x i32>, <4 x i32>* %8, align 16
  %449 = icmp sgt <4 x i32> %446, %448
  %450 = select <4 x i1> %449, <4 x i32> %446, <4 x i32> %448
  %451 = load <4 x i32>, <4 x i32>* %9, align 16
  %452 = icmp slt <4 x i32> %450, %451
  %453 = select <4 x i1> %452, <4 x i32> %450, <4 x i32> %451
  %454 = icmp sgt <4 x i32> %447, %448
  %455 = select <4 x i1> %454, <4 x i32> %447, <4 x i32> %448
  %456 = icmp slt <4 x i32> %455, %451
  %457 = select <4 x i1> %456, <4 x i32> %455, <4 x i32> %451
  store <4 x i32> %453, <4 x i32>* %441, align 16
  store <4 x i32> %457, <4 x i32>* %444, align 16
  %458 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 58
  %459 = bitcast <2 x i64>* %458 to <4 x i32>*
  %460 = load <4 x i32>, <4 x i32>* %459, align 16
  %461 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 53
  %462 = bitcast <2 x i64>* %461 to <4 x i32>*
  %463 = load <4 x i32>, <4 x i32>* %462, align 16
  %464 = add <4 x i32> %463, %460
  %465 = sub <4 x i32> %460, %463
  %466 = load <4 x i32>, <4 x i32>* %8, align 16
  %467 = icmp sgt <4 x i32> %464, %466
  %468 = select <4 x i1> %467, <4 x i32> %464, <4 x i32> %466
  %469 = load <4 x i32>, <4 x i32>* %9, align 16
  %470 = icmp slt <4 x i32> %468, %469
  %471 = select <4 x i1> %470, <4 x i32> %468, <4 x i32> %469
  %472 = icmp sgt <4 x i32> %465, %466
  %473 = select <4 x i1> %472, <4 x i32> %465, <4 x i32> %466
  %474 = icmp slt <4 x i32> %473, %469
  %475 = select <4 x i1> %474, <4 x i32> %473, <4 x i32> %469
  store <4 x i32> %471, <4 x i32>* %459, align 16
  store <4 x i32> %475, <4 x i32>* %462, align 16
  %476 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 57
  %477 = bitcast <2 x i64>* %476 to <4 x i32>*
  %478 = load <4 x i32>, <4 x i32>* %477, align 16
  %479 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 54
  %480 = bitcast <2 x i64>* %479 to <4 x i32>*
  %481 = load <4 x i32>, <4 x i32>* %480, align 16
  %482 = add <4 x i32> %481, %478
  %483 = sub <4 x i32> %478, %481
  %484 = load <4 x i32>, <4 x i32>* %8, align 16
  %485 = icmp sgt <4 x i32> %482, %484
  %486 = select <4 x i1> %485, <4 x i32> %482, <4 x i32> %484
  %487 = load <4 x i32>, <4 x i32>* %9, align 16
  %488 = icmp slt <4 x i32> %486, %487
  %489 = select <4 x i1> %488, <4 x i32> %486, <4 x i32> %487
  %490 = icmp sgt <4 x i32> %483, %484
  %491 = select <4 x i1> %490, <4 x i32> %483, <4 x i32> %484
  %492 = icmp slt <4 x i32> %491, %487
  %493 = select <4 x i1> %492, <4 x i32> %491, <4 x i32> %487
  store <4 x i32> %489, <4 x i32>* %477, align 16
  store <4 x i32> %493, <4 x i32>* %480, align 16
  %494 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 56
  %495 = bitcast <2 x i64>* %494 to <4 x i32>*
  %496 = load <4 x i32>, <4 x i32>* %495, align 16
  %497 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 55
  %498 = bitcast <2 x i64>* %497 to <4 x i32>*
  %499 = load <4 x i32>, <4 x i32>* %498, align 16
  %500 = add <4 x i32> %499, %496
  %501 = sub <4 x i32> %496, %499
  %502 = load <4 x i32>, <4 x i32>* %8, align 16
  %503 = icmp sgt <4 x i32> %500, %502
  %504 = select <4 x i1> %503, <4 x i32> %500, <4 x i32> %502
  %505 = load <4 x i32>, <4 x i32>* %9, align 16
  %506 = icmp slt <4 x i32> %504, %505
  %507 = select <4 x i1> %506, <4 x i32> %504, <4 x i32> %505
  %508 = icmp sgt <4 x i32> %501, %502
  %509 = select <4 x i1> %508, <4 x i32> %501, <4 x i32> %502
  %510 = icmp slt <4 x i32> %509, %505
  %511 = select <4 x i1> %510, <4 x i32> %509, <4 x i32> %505
  store <4 x i32> %507, <4 x i32>* %495, align 16
  store <4 x i32> %511, <4 x i32>* %498, align 16
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #1

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nounwind readnone }
attributes #6 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { inlinehint nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = distinct !{!2, !3}
!3 = !{!"llvm.loop.unroll.disable"}
!4 = distinct !{!4, !3}
!5 = distinct !{!5, !3}
!6 = distinct !{!6, !3}
!7 = distinct !{!7, !3}
!8 = distinct !{!8, !3}
!9 = distinct !{!9, !3}
!10 = distinct !{!10, !3}
!11 = distinct !{!11, !3}
!12 = distinct !{!12, !3}
!13 = distinct !{!13, !3}
!14 = distinct !{!14, !3}
!15 = distinct !{!15, !3}
!16 = distinct !{!16, !3}
!17 = distinct !{!17, !3}
!18 = distinct !{!18, !3}
!19 = distinct !{!19, !3}
!20 = distinct !{!20, !3}
