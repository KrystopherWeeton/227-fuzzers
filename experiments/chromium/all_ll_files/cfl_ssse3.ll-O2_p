; ModuleID = '../../third_party/libaom/source/libaom/av1/common/x86/cfl_ssse3.c'
source_filename = "../../third_party/libaom/source/libaom/av1/common/x86/cfl_ssse3.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

@cfl_get_luma_subsampling_420_lbd_ssse3.subfn_420 = internal unnamed_addr constant [19 x void (i8*, i32, i16*)*] [void (i8*, i32, i16*)* @cfl_subsample_lbd_420_4x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_8x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_16x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_32x32_ssse3, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_4x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_8x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_8x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_16x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_16x32_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_32x16_ssse3, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_4x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_16x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_8x32_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_32x8_ssse3, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* null], align 16
@cfl_get_luma_subsampling_422_lbd_ssse3.subfn_422 = internal unnamed_addr constant [19 x void (i8*, i32, i16*)*] [void (i8*, i32, i16*)* @cfl_subsample_lbd_422_4x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_8x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_16x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_32x32_ssse3, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_4x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_8x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_8x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_16x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_16x32_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_32x16_ssse3, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_4x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_16x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_8x32_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_32x8_ssse3, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* null], align 16
@cfl_get_luma_subsampling_444_lbd_ssse3.subfn_444 = internal unnamed_addr constant [19 x void (i8*, i32, i16*)*] [void (i8*, i32, i16*)* @cfl_subsample_lbd_444_4x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_8x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_16x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_32x32_ssse3, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_4x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_8x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_8x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_16x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_16x32_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_32x16_ssse3, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_4x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_16x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_8x32_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_32x8_ssse3, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* null], align 16
@cfl_get_predict_lbd_fn_ssse3.pred = internal unnamed_addr constant [19 x void (i16*, i8*, i32, i32)*] [void (i16*, i8*, i32, i32)* @cfl_predict_lbd_4x4_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_8x8_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_16x16_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_32x32_ssse3, void (i16*, i8*, i32, i32)* null, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_4x8_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_8x4_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_8x16_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_16x8_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_16x32_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_32x16_ssse3, void (i16*, i8*, i32, i32)* null, void (i16*, i8*, i32, i32)* null, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_4x16_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_16x4_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_8x32_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_32x8_ssse3, void (i16*, i8*, i32, i32)* null, void (i16*, i8*, i32, i32)* null], align 16

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_4x4_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = sext i32 %1 to i64
  %6 = sext i32 %4 to i64
  %7 = bitcast i8* %0 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %8, i32 0
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %12 = getelementptr inbounds i8, i8* %0, i64 %5
  %13 = bitcast i8* %12 to i32*
  %14 = load i32, i32* %13, align 4
  %15 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %14, i32 0
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %16, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %18 = add <8 x i16> %17, %11
  %19 = bitcast <8 x i16> %18 to <4 x i32>
  %20 = extractelement <4 x i32> %19, i32 0
  %21 = bitcast i16* %2 to i32*
  store i32 %20, i32* %21, align 4
  %22 = getelementptr inbounds i8, i8* %0, i64 %6
  %23 = getelementptr inbounds i16, i16* %2, i64 32
  %24 = bitcast i8* %22 to i32*
  %25 = load i32, i32* %24, align 4
  %26 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %25, i32 0
  %27 = bitcast <4 x i32> %26 to <16 x i8>
  %28 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %27, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %29 = getelementptr inbounds i8, i8* %22, i64 %5
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %31, i32 0
  %33 = bitcast <4 x i32> %32 to <16 x i8>
  %34 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %33, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %35 = add <8 x i16> %34, %28
  %36 = bitcast <8 x i16> %35 to <4 x i32>
  %37 = extractelement <4 x i32> %36, i32 0
  %38 = bitcast i16* %23 to i32*
  store i32 %37, i32* %38, align 4
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_8x8_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = sext i32 %1 to i64
  %6 = sext i32 %4 to i64
  %7 = bitcast i8* %0 to i64*
  %8 = load i64, i64* %7, align 1
  %9 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %8, i32 0
  %10 = bitcast <2 x i64> %9 to <16 x i8>
  %11 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %12 = getelementptr inbounds i8, i8* %0, i64 %5
  %13 = bitcast i8* %12 to i64*
  %14 = load i64, i64* %13, align 1
  %15 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %14, i32 0
  %16 = bitcast <2 x i64> %15 to <16 x i8>
  %17 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %16, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %18 = add <8 x i16> %17, %11
  %19 = bitcast <8 x i16> %18 to <2 x i64>
  %20 = extractelement <2 x i64> %19, i32 0
  %21 = bitcast i16* %2 to i64*
  store i64 %20, i64* %21, align 1
  %22 = getelementptr inbounds i8, i8* %0, i64 %6
  %23 = getelementptr inbounds i16, i16* %2, i64 32
  %24 = bitcast i8* %22 to i64*
  %25 = load i64, i64* %24, align 1
  %26 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %25, i32 0
  %27 = bitcast <2 x i64> %26 to <16 x i8>
  %28 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %27, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %29 = getelementptr inbounds i8, i8* %22, i64 %5
  %30 = bitcast i8* %29 to i64*
  %31 = load i64, i64* %30, align 1
  %32 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %31, i32 0
  %33 = bitcast <2 x i64> %32 to <16 x i8>
  %34 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %33, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %35 = add <8 x i16> %34, %28
  %36 = bitcast <8 x i16> %35 to <2 x i64>
  %37 = extractelement <2 x i64> %36, i32 0
  %38 = bitcast i16* %23 to i64*
  store i64 %37, i64* %38, align 1
  %39 = getelementptr inbounds i8, i8* %22, i64 %6
  %40 = getelementptr inbounds i16, i16* %2, i64 64
  %41 = bitcast i8* %39 to i64*
  %42 = load i64, i64* %41, align 1
  %43 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %42, i32 0
  %44 = bitcast <2 x i64> %43 to <16 x i8>
  %45 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %44, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %46 = getelementptr inbounds i8, i8* %39, i64 %5
  %47 = bitcast i8* %46 to i64*
  %48 = load i64, i64* %47, align 1
  %49 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %48, i32 0
  %50 = bitcast <2 x i64> %49 to <16 x i8>
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %50, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %52 = add <8 x i16> %51, %45
  %53 = bitcast <8 x i16> %52 to <2 x i64>
  %54 = extractelement <2 x i64> %53, i32 0
  %55 = bitcast i16* %40 to i64*
  store i64 %54, i64* %55, align 1
  %56 = getelementptr inbounds i8, i8* %39, i64 %6
  %57 = getelementptr inbounds i16, i16* %2, i64 96
  %58 = bitcast i8* %56 to i64*
  %59 = load i64, i64* %58, align 1
  %60 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %59, i32 0
  %61 = bitcast <2 x i64> %60 to <16 x i8>
  %62 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %61, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %63 = getelementptr inbounds i8, i8* %56, i64 %5
  %64 = bitcast i8* %63 to i64*
  %65 = load i64, i64* %64, align 1
  %66 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %65, i32 0
  %67 = bitcast <2 x i64> %66 to <16 x i8>
  %68 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %67, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %69 = add <8 x i16> %68, %62
  %70 = bitcast <8 x i16> %69 to <2 x i64>
  %71 = extractelement <2 x i64> %70, i32 0
  %72 = bitcast i16* %57 to i64*
  store i64 %71, i64* %72, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_16x16_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = sext i32 %1 to i64
  %6 = sext i32 %4 to i64
  %7 = bitcast i8* %0 to <16 x i8>*
  %8 = load <16 x i8>, <16 x i8>* %7, align 1
  %9 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %8, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %10 = getelementptr inbounds i8, i8* %0, i64 %5
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %12, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %14 = add <8 x i16> %13, %9
  %15 = bitcast i16* %2 to <8 x i16>*
  store <8 x i16> %14, <8 x i16>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 %6
  %17 = getelementptr inbounds i16, i16* %2, i64 32
  %18 = bitcast i8* %16 to <16 x i8>*
  %19 = load <16 x i8>, <16 x i8>* %18, align 1
  %20 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %19, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %21 = getelementptr inbounds i8, i8* %16, i64 %5
  %22 = bitcast i8* %21 to <16 x i8>*
  %23 = load <16 x i8>, <16 x i8>* %22, align 1
  %24 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %23, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %25 = add <8 x i16> %24, %20
  %26 = bitcast i16* %17 to <8 x i16>*
  store <8 x i16> %25, <8 x i16>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %16, i64 %6
  %28 = getelementptr inbounds i16, i16* %2, i64 64
  %29 = bitcast i8* %27 to <16 x i8>*
  %30 = load <16 x i8>, <16 x i8>* %29, align 1
  %31 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %30, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %32 = getelementptr inbounds i8, i8* %27, i64 %5
  %33 = bitcast i8* %32 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %34, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %36 = add <8 x i16> %35, %31
  %37 = bitcast i16* %28 to <8 x i16>*
  store <8 x i16> %36, <8 x i16>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %27, i64 %6
  %39 = getelementptr inbounds i16, i16* %2, i64 96
  %40 = bitcast i8* %38 to <16 x i8>*
  %41 = load <16 x i8>, <16 x i8>* %40, align 1
  %42 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %41, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %43 = getelementptr inbounds i8, i8* %38, i64 %5
  %44 = bitcast i8* %43 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 1
  %46 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %45, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %47 = add <8 x i16> %46, %42
  %48 = bitcast i16* %39 to <8 x i16>*
  store <8 x i16> %47, <8 x i16>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %38, i64 %6
  %50 = getelementptr inbounds i16, i16* %2, i64 128
  %51 = bitcast i8* %49 to <16 x i8>*
  %52 = load <16 x i8>, <16 x i8>* %51, align 1
  %53 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %54 = getelementptr inbounds i8, i8* %49, i64 %5
  %55 = bitcast i8* %54 to <16 x i8>*
  %56 = load <16 x i8>, <16 x i8>* %55, align 1
  %57 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %56, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %58 = add <8 x i16> %57, %53
  %59 = bitcast i16* %50 to <8 x i16>*
  store <8 x i16> %58, <8 x i16>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %49, i64 %6
  %61 = getelementptr inbounds i16, i16* %2, i64 160
  %62 = bitcast i8* %60 to <16 x i8>*
  %63 = load <16 x i8>, <16 x i8>* %62, align 1
  %64 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %63, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %65 = getelementptr inbounds i8, i8* %60, i64 %5
  %66 = bitcast i8* %65 to <16 x i8>*
  %67 = load <16 x i8>, <16 x i8>* %66, align 1
  %68 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %67, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %69 = add <8 x i16> %68, %64
  %70 = bitcast i16* %61 to <8 x i16>*
  store <8 x i16> %69, <8 x i16>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %60, i64 %6
  %72 = getelementptr inbounds i16, i16* %2, i64 192
  %73 = bitcast i8* %71 to <16 x i8>*
  %74 = load <16 x i8>, <16 x i8>* %73, align 1
  %75 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %74, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %76 = getelementptr inbounds i8, i8* %71, i64 %5
  %77 = bitcast i8* %76 to <16 x i8>*
  %78 = load <16 x i8>, <16 x i8>* %77, align 1
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %78, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %80 = add <8 x i16> %79, %75
  %81 = bitcast i16* %72 to <8 x i16>*
  store <8 x i16> %80, <8 x i16>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %71, i64 %6
  %83 = getelementptr inbounds i16, i16* %2, i64 224
  %84 = bitcast i8* %82 to <16 x i8>*
  %85 = load <16 x i8>, <16 x i8>* %84, align 1
  %86 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %85, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %87 = getelementptr inbounds i8, i8* %82, i64 %5
  %88 = bitcast i8* %87 to <16 x i8>*
  %89 = load <16 x i8>, <16 x i8>* %88, align 1
  %90 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %89, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %91 = add <8 x i16> %90, %86
  %92 = bitcast i16* %83 to <8 x i16>*
  store <8 x i16> %91, <8 x i16>* %92, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_32x32_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 512
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = shl i32 %1, 1
  %8 = sext i32 %1 to i64
  %9 = sext i32 %7 to i64
  br label %10

10:                                               ; preds = %10, %3
  %11 = phi <2 x i64>* [ %4, %3 ], [ %34, %10 ]
  %12 = phi i8* [ %0, %3 ], [ %33, %10 ]
  %13 = bitcast i8* %12 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %14, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %16 = getelementptr inbounds i8, i8* %12, i64 %8
  %17 = bitcast i8* %16 to <16 x i8>*
  %18 = load <16 x i8>, <16 x i8>* %17, align 1
  %19 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %18, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %20 = add <8 x i16> %19, %15
  %21 = bitcast <2 x i64>* %11 to <8 x i16>*
  store <8 x i16> %20, <8 x i16>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %12, i64 16
  %23 = bitcast i8* %22 to <16 x i8>*
  %24 = load <16 x i8>, <16 x i8>* %23, align 1
  %25 = getelementptr inbounds i8, i8* %16, i64 16
  %26 = bitcast i8* %25 to <16 x i8>*
  %27 = load <16 x i8>, <16 x i8>* %26, align 1
  %28 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %24, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %27, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %30 = add <8 x i16> %29, %28
  %31 = getelementptr inbounds <2 x i64>, <2 x i64>* %11, i64 1
  %32 = bitcast <2 x i64>* %31 to <8 x i16>*
  store <8 x i16> %30, <8 x i16>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %12, i64 %9
  %34 = getelementptr inbounds <2 x i64>, <2 x i64>* %11, i64 4
  %35 = icmp ult <2 x i64>* %34, %6
  br i1 %35, label %10, label %36

36:                                               ; preds = %10
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_4x8_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = sext i32 %1 to i64
  %6 = sext i32 %4 to i64
  %7 = bitcast i8* %0 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %8, i32 0
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %12 = getelementptr inbounds i8, i8* %0, i64 %5
  %13 = bitcast i8* %12 to i32*
  %14 = load i32, i32* %13, align 4
  %15 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %14, i32 0
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %16, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %18 = add <8 x i16> %17, %11
  %19 = bitcast <8 x i16> %18 to <4 x i32>
  %20 = extractelement <4 x i32> %19, i32 0
  %21 = bitcast i16* %2 to i32*
  store i32 %20, i32* %21, align 4
  %22 = getelementptr inbounds i8, i8* %0, i64 %6
  %23 = getelementptr inbounds i16, i16* %2, i64 32
  %24 = bitcast i8* %22 to i32*
  %25 = load i32, i32* %24, align 4
  %26 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %25, i32 0
  %27 = bitcast <4 x i32> %26 to <16 x i8>
  %28 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %27, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %29 = getelementptr inbounds i8, i8* %22, i64 %5
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %31, i32 0
  %33 = bitcast <4 x i32> %32 to <16 x i8>
  %34 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %33, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %35 = add <8 x i16> %34, %28
  %36 = bitcast <8 x i16> %35 to <4 x i32>
  %37 = extractelement <4 x i32> %36, i32 0
  %38 = bitcast i16* %23 to i32*
  store i32 %37, i32* %38, align 4
  %39 = getelementptr inbounds i8, i8* %22, i64 %6
  %40 = getelementptr inbounds i16, i16* %2, i64 64
  %41 = bitcast i8* %39 to i32*
  %42 = load i32, i32* %41, align 4
  %43 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %42, i32 0
  %44 = bitcast <4 x i32> %43 to <16 x i8>
  %45 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %44, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %46 = getelementptr inbounds i8, i8* %39, i64 %5
  %47 = bitcast i8* %46 to i32*
  %48 = load i32, i32* %47, align 4
  %49 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %48, i32 0
  %50 = bitcast <4 x i32> %49 to <16 x i8>
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %50, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %52 = add <8 x i16> %51, %45
  %53 = bitcast <8 x i16> %52 to <4 x i32>
  %54 = extractelement <4 x i32> %53, i32 0
  %55 = bitcast i16* %40 to i32*
  store i32 %54, i32* %55, align 4
  %56 = getelementptr inbounds i8, i8* %39, i64 %6
  %57 = getelementptr inbounds i16, i16* %2, i64 96
  %58 = bitcast i8* %56 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %59, i32 0
  %61 = bitcast <4 x i32> %60 to <16 x i8>
  %62 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %61, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %63 = getelementptr inbounds i8, i8* %56, i64 %5
  %64 = bitcast i8* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %65, i32 0
  %67 = bitcast <4 x i32> %66 to <16 x i8>
  %68 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %67, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %69 = add <8 x i16> %68, %62
  %70 = bitcast <8 x i16> %69 to <4 x i32>
  %71 = extractelement <4 x i32> %70, i32 0
  %72 = bitcast i16* %57 to i32*
  store i32 %71, i32* %72, align 4
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_8x4_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = sext i32 %1 to i64
  %6 = sext i32 %4 to i64
  %7 = bitcast i8* %0 to i64*
  %8 = load i64, i64* %7, align 1
  %9 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %8, i32 0
  %10 = bitcast <2 x i64> %9 to <16 x i8>
  %11 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %12 = getelementptr inbounds i8, i8* %0, i64 %5
  %13 = bitcast i8* %12 to i64*
  %14 = load i64, i64* %13, align 1
  %15 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %14, i32 0
  %16 = bitcast <2 x i64> %15 to <16 x i8>
  %17 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %16, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %18 = add <8 x i16> %17, %11
  %19 = bitcast <8 x i16> %18 to <2 x i64>
  %20 = extractelement <2 x i64> %19, i32 0
  %21 = bitcast i16* %2 to i64*
  store i64 %20, i64* %21, align 1
  %22 = getelementptr inbounds i8, i8* %0, i64 %6
  %23 = getelementptr inbounds i16, i16* %2, i64 32
  %24 = bitcast i8* %22 to i64*
  %25 = load i64, i64* %24, align 1
  %26 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %25, i32 0
  %27 = bitcast <2 x i64> %26 to <16 x i8>
  %28 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %27, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %29 = getelementptr inbounds i8, i8* %22, i64 %5
  %30 = bitcast i8* %29 to i64*
  %31 = load i64, i64* %30, align 1
  %32 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %31, i32 0
  %33 = bitcast <2 x i64> %32 to <16 x i8>
  %34 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %33, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %35 = add <8 x i16> %34, %28
  %36 = bitcast <8 x i16> %35 to <2 x i64>
  %37 = extractelement <2 x i64> %36, i32 0
  %38 = bitcast i16* %23 to i64*
  store i64 %37, i64* %38, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_8x16_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = sext i32 %1 to i64
  %6 = sext i32 %4 to i64
  %7 = bitcast i8* %0 to i64*
  %8 = load i64, i64* %7, align 1
  %9 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %8, i32 0
  %10 = bitcast <2 x i64> %9 to <16 x i8>
  %11 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %12 = getelementptr inbounds i8, i8* %0, i64 %5
  %13 = bitcast i8* %12 to i64*
  %14 = load i64, i64* %13, align 1
  %15 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %14, i32 0
  %16 = bitcast <2 x i64> %15 to <16 x i8>
  %17 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %16, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %18 = add <8 x i16> %17, %11
  %19 = bitcast <8 x i16> %18 to <2 x i64>
  %20 = extractelement <2 x i64> %19, i32 0
  %21 = bitcast i16* %2 to i64*
  store i64 %20, i64* %21, align 1
  %22 = getelementptr inbounds i8, i8* %0, i64 %6
  %23 = getelementptr inbounds i16, i16* %2, i64 32
  %24 = bitcast i8* %22 to i64*
  %25 = load i64, i64* %24, align 1
  %26 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %25, i32 0
  %27 = bitcast <2 x i64> %26 to <16 x i8>
  %28 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %27, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %29 = getelementptr inbounds i8, i8* %22, i64 %5
  %30 = bitcast i8* %29 to i64*
  %31 = load i64, i64* %30, align 1
  %32 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %31, i32 0
  %33 = bitcast <2 x i64> %32 to <16 x i8>
  %34 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %33, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %35 = add <8 x i16> %34, %28
  %36 = bitcast <8 x i16> %35 to <2 x i64>
  %37 = extractelement <2 x i64> %36, i32 0
  %38 = bitcast i16* %23 to i64*
  store i64 %37, i64* %38, align 1
  %39 = getelementptr inbounds i8, i8* %22, i64 %6
  %40 = getelementptr inbounds i16, i16* %2, i64 64
  %41 = bitcast i8* %39 to i64*
  %42 = load i64, i64* %41, align 1
  %43 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %42, i32 0
  %44 = bitcast <2 x i64> %43 to <16 x i8>
  %45 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %44, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %46 = getelementptr inbounds i8, i8* %39, i64 %5
  %47 = bitcast i8* %46 to i64*
  %48 = load i64, i64* %47, align 1
  %49 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %48, i32 0
  %50 = bitcast <2 x i64> %49 to <16 x i8>
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %50, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %52 = add <8 x i16> %51, %45
  %53 = bitcast <8 x i16> %52 to <2 x i64>
  %54 = extractelement <2 x i64> %53, i32 0
  %55 = bitcast i16* %40 to i64*
  store i64 %54, i64* %55, align 1
  %56 = getelementptr inbounds i8, i8* %39, i64 %6
  %57 = getelementptr inbounds i16, i16* %2, i64 96
  %58 = bitcast i8* %56 to i64*
  %59 = load i64, i64* %58, align 1
  %60 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %59, i32 0
  %61 = bitcast <2 x i64> %60 to <16 x i8>
  %62 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %61, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %63 = getelementptr inbounds i8, i8* %56, i64 %5
  %64 = bitcast i8* %63 to i64*
  %65 = load i64, i64* %64, align 1
  %66 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %65, i32 0
  %67 = bitcast <2 x i64> %66 to <16 x i8>
  %68 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %67, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %69 = add <8 x i16> %68, %62
  %70 = bitcast <8 x i16> %69 to <2 x i64>
  %71 = extractelement <2 x i64> %70, i32 0
  %72 = bitcast i16* %57 to i64*
  store i64 %71, i64* %72, align 1
  %73 = getelementptr inbounds i8, i8* %56, i64 %6
  %74 = getelementptr inbounds i16, i16* %2, i64 128
  %75 = bitcast i8* %73 to i64*
  %76 = load i64, i64* %75, align 1
  %77 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %76, i32 0
  %78 = bitcast <2 x i64> %77 to <16 x i8>
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %78, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %80 = getelementptr inbounds i8, i8* %73, i64 %5
  %81 = bitcast i8* %80 to i64*
  %82 = load i64, i64* %81, align 1
  %83 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %82, i32 0
  %84 = bitcast <2 x i64> %83 to <16 x i8>
  %85 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %84, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %86 = add <8 x i16> %85, %79
  %87 = bitcast <8 x i16> %86 to <2 x i64>
  %88 = extractelement <2 x i64> %87, i32 0
  %89 = bitcast i16* %74 to i64*
  store i64 %88, i64* %89, align 1
  %90 = getelementptr inbounds i8, i8* %73, i64 %6
  %91 = getelementptr inbounds i16, i16* %2, i64 160
  %92 = bitcast i8* %90 to i64*
  %93 = load i64, i64* %92, align 1
  %94 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %93, i32 0
  %95 = bitcast <2 x i64> %94 to <16 x i8>
  %96 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %95, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %97 = getelementptr inbounds i8, i8* %90, i64 %5
  %98 = bitcast i8* %97 to i64*
  %99 = load i64, i64* %98, align 1
  %100 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %99, i32 0
  %101 = bitcast <2 x i64> %100 to <16 x i8>
  %102 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %101, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %103 = add <8 x i16> %102, %96
  %104 = bitcast <8 x i16> %103 to <2 x i64>
  %105 = extractelement <2 x i64> %104, i32 0
  %106 = bitcast i16* %91 to i64*
  store i64 %105, i64* %106, align 1
  %107 = getelementptr inbounds i8, i8* %90, i64 %6
  %108 = getelementptr inbounds i16, i16* %2, i64 192
  %109 = bitcast i8* %107 to i64*
  %110 = load i64, i64* %109, align 1
  %111 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %110, i32 0
  %112 = bitcast <2 x i64> %111 to <16 x i8>
  %113 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %112, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %114 = getelementptr inbounds i8, i8* %107, i64 %5
  %115 = bitcast i8* %114 to i64*
  %116 = load i64, i64* %115, align 1
  %117 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %116, i32 0
  %118 = bitcast <2 x i64> %117 to <16 x i8>
  %119 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %118, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %120 = add <8 x i16> %119, %113
  %121 = bitcast <8 x i16> %120 to <2 x i64>
  %122 = extractelement <2 x i64> %121, i32 0
  %123 = bitcast i16* %108 to i64*
  store i64 %122, i64* %123, align 1
  %124 = getelementptr inbounds i8, i8* %107, i64 %6
  %125 = getelementptr inbounds i16, i16* %2, i64 224
  %126 = bitcast i8* %124 to i64*
  %127 = load i64, i64* %126, align 1
  %128 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %127, i32 0
  %129 = bitcast <2 x i64> %128 to <16 x i8>
  %130 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %129, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %131 = getelementptr inbounds i8, i8* %124, i64 %5
  %132 = bitcast i8* %131 to i64*
  %133 = load i64, i64* %132, align 1
  %134 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %133, i32 0
  %135 = bitcast <2 x i64> %134 to <16 x i8>
  %136 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %135, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %137 = add <8 x i16> %136, %130
  %138 = bitcast <8 x i16> %137 to <2 x i64>
  %139 = extractelement <2 x i64> %138, i32 0
  %140 = bitcast i16* %125 to i64*
  store i64 %139, i64* %140, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_16x8_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = sext i32 %1 to i64
  %6 = sext i32 %4 to i64
  %7 = bitcast i8* %0 to <16 x i8>*
  %8 = load <16 x i8>, <16 x i8>* %7, align 1
  %9 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %8, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %10 = getelementptr inbounds i8, i8* %0, i64 %5
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %12, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %14 = add <8 x i16> %13, %9
  %15 = bitcast i16* %2 to <8 x i16>*
  store <8 x i16> %14, <8 x i16>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 %6
  %17 = getelementptr inbounds i16, i16* %2, i64 32
  %18 = bitcast i8* %16 to <16 x i8>*
  %19 = load <16 x i8>, <16 x i8>* %18, align 1
  %20 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %19, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %21 = getelementptr inbounds i8, i8* %16, i64 %5
  %22 = bitcast i8* %21 to <16 x i8>*
  %23 = load <16 x i8>, <16 x i8>* %22, align 1
  %24 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %23, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %25 = add <8 x i16> %24, %20
  %26 = bitcast i16* %17 to <8 x i16>*
  store <8 x i16> %25, <8 x i16>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %16, i64 %6
  %28 = getelementptr inbounds i16, i16* %2, i64 64
  %29 = bitcast i8* %27 to <16 x i8>*
  %30 = load <16 x i8>, <16 x i8>* %29, align 1
  %31 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %30, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %32 = getelementptr inbounds i8, i8* %27, i64 %5
  %33 = bitcast i8* %32 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %34, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %36 = add <8 x i16> %35, %31
  %37 = bitcast i16* %28 to <8 x i16>*
  store <8 x i16> %36, <8 x i16>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %27, i64 %6
  %39 = getelementptr inbounds i16, i16* %2, i64 96
  %40 = bitcast i8* %38 to <16 x i8>*
  %41 = load <16 x i8>, <16 x i8>* %40, align 1
  %42 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %41, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %43 = getelementptr inbounds i8, i8* %38, i64 %5
  %44 = bitcast i8* %43 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 1
  %46 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %45, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %47 = add <8 x i16> %46, %42
  %48 = bitcast i16* %39 to <8 x i16>*
  store <8 x i16> %47, <8 x i16>* %48, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_16x32_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 512
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = shl i32 %1, 1
  %8 = sext i32 %1 to i64
  %9 = sext i32 %7 to i64
  br label %10

10:                                               ; preds = %10, %3
  %11 = phi <2 x i64>* [ %4, %3 ], [ %23, %10 ]
  %12 = phi i8* [ %0, %3 ], [ %22, %10 ]
  %13 = bitcast i8* %12 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %14, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %16 = getelementptr inbounds i8, i8* %12, i64 %8
  %17 = bitcast i8* %16 to <16 x i8>*
  %18 = load <16 x i8>, <16 x i8>* %17, align 1
  %19 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %18, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %20 = add <8 x i16> %19, %15
  %21 = bitcast <2 x i64>* %11 to <8 x i16>*
  store <8 x i16> %20, <8 x i16>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %12, i64 %9
  %23 = getelementptr inbounds <2 x i64>, <2 x i64>* %11, i64 4
  %24 = icmp ult <2 x i64>* %23, %6
  br i1 %24, label %10, label %25

25:                                               ; preds = %10
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_32x16_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = sext i32 %1 to i64
  %6 = sext i32 %4 to i64
  %7 = bitcast i8* %0 to <16 x i8>*
  %8 = load <16 x i8>, <16 x i8>* %7, align 1
  %9 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %8, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %10 = getelementptr inbounds i8, i8* %0, i64 %5
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %12, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %14 = add <8 x i16> %13, %9
  %15 = bitcast i16* %2 to <8 x i16>*
  store <8 x i16> %14, <8 x i16>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 16
  %17 = bitcast i8* %16 to <16 x i8>*
  %18 = load <16 x i8>, <16 x i8>* %17, align 1
  %19 = getelementptr inbounds i8, i8* %10, i64 16
  %20 = bitcast i8* %19 to <16 x i8>*
  %21 = load <16 x i8>, <16 x i8>* %20, align 1
  %22 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %18, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %23 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %21, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %24 = add <8 x i16> %23, %22
  %25 = getelementptr inbounds i16, i16* %2, i64 8
  %26 = bitcast i16* %25 to <8 x i16>*
  store <8 x i16> %24, <8 x i16>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %0, i64 %6
  %28 = getelementptr inbounds i16, i16* %2, i64 32
  %29 = bitcast i8* %27 to <16 x i8>*
  %30 = load <16 x i8>, <16 x i8>* %29, align 1
  %31 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %30, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %32 = getelementptr inbounds i8, i8* %27, i64 %5
  %33 = bitcast i8* %32 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %34, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %36 = add <8 x i16> %35, %31
  %37 = bitcast i16* %28 to <8 x i16>*
  store <8 x i16> %36, <8 x i16>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %27, i64 16
  %39 = bitcast i8* %38 to <16 x i8>*
  %40 = load <16 x i8>, <16 x i8>* %39, align 1
  %41 = getelementptr inbounds i8, i8* %32, i64 16
  %42 = bitcast i8* %41 to <16 x i8>*
  %43 = load <16 x i8>, <16 x i8>* %42, align 1
  %44 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %40, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %45 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %43, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %46 = add <8 x i16> %45, %44
  %47 = getelementptr inbounds i16, i16* %2, i64 40
  %48 = bitcast i16* %47 to <8 x i16>*
  store <8 x i16> %46, <8 x i16>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %27, i64 %6
  %50 = getelementptr inbounds i16, i16* %2, i64 64
  %51 = bitcast i8* %49 to <16 x i8>*
  %52 = load <16 x i8>, <16 x i8>* %51, align 1
  %53 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %54 = getelementptr inbounds i8, i8* %49, i64 %5
  %55 = bitcast i8* %54 to <16 x i8>*
  %56 = load <16 x i8>, <16 x i8>* %55, align 1
  %57 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %56, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %58 = add <8 x i16> %57, %53
  %59 = bitcast i16* %50 to <8 x i16>*
  store <8 x i16> %58, <8 x i16>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %49, i64 16
  %61 = bitcast i8* %60 to <16 x i8>*
  %62 = load <16 x i8>, <16 x i8>* %61, align 1
  %63 = getelementptr inbounds i8, i8* %54, i64 16
  %64 = bitcast i8* %63 to <16 x i8>*
  %65 = load <16 x i8>, <16 x i8>* %64, align 1
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %62, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %67 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %68 = add <8 x i16> %67, %66
  %69 = getelementptr inbounds i16, i16* %2, i64 72
  %70 = bitcast i16* %69 to <8 x i16>*
  store <8 x i16> %68, <8 x i16>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %49, i64 %6
  %72 = getelementptr inbounds i16, i16* %2, i64 96
  %73 = bitcast i8* %71 to <16 x i8>*
  %74 = load <16 x i8>, <16 x i8>* %73, align 1
  %75 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %74, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %76 = getelementptr inbounds i8, i8* %71, i64 %5
  %77 = bitcast i8* %76 to <16 x i8>*
  %78 = load <16 x i8>, <16 x i8>* %77, align 1
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %78, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %80 = add <8 x i16> %79, %75
  %81 = bitcast i16* %72 to <8 x i16>*
  store <8 x i16> %80, <8 x i16>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %71, i64 16
  %83 = bitcast i8* %82 to <16 x i8>*
  %84 = load <16 x i8>, <16 x i8>* %83, align 1
  %85 = getelementptr inbounds i8, i8* %76, i64 16
  %86 = bitcast i8* %85 to <16 x i8>*
  %87 = load <16 x i8>, <16 x i8>* %86, align 1
  %88 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %84, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %89 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %87, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %90 = add <8 x i16> %89, %88
  %91 = getelementptr inbounds i16, i16* %2, i64 104
  %92 = bitcast i16* %91 to <8 x i16>*
  store <8 x i16> %90, <8 x i16>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %71, i64 %6
  %94 = getelementptr inbounds i16, i16* %2, i64 128
  %95 = bitcast i8* %93 to <16 x i8>*
  %96 = load <16 x i8>, <16 x i8>* %95, align 1
  %97 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %96, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %98 = getelementptr inbounds i8, i8* %93, i64 %5
  %99 = bitcast i8* %98 to <16 x i8>*
  %100 = load <16 x i8>, <16 x i8>* %99, align 1
  %101 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %100, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %102 = add <8 x i16> %101, %97
  %103 = bitcast i16* %94 to <8 x i16>*
  store <8 x i16> %102, <8 x i16>* %103, align 1
  %104 = getelementptr inbounds i8, i8* %93, i64 16
  %105 = bitcast i8* %104 to <16 x i8>*
  %106 = load <16 x i8>, <16 x i8>* %105, align 1
  %107 = getelementptr inbounds i8, i8* %98, i64 16
  %108 = bitcast i8* %107 to <16 x i8>*
  %109 = load <16 x i8>, <16 x i8>* %108, align 1
  %110 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %106, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %111 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %109, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %112 = add <8 x i16> %111, %110
  %113 = getelementptr inbounds i16, i16* %2, i64 136
  %114 = bitcast i16* %113 to <8 x i16>*
  store <8 x i16> %112, <8 x i16>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %93, i64 %6
  %116 = getelementptr inbounds i16, i16* %2, i64 160
  %117 = bitcast i8* %115 to <16 x i8>*
  %118 = load <16 x i8>, <16 x i8>* %117, align 1
  %119 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %118, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %120 = getelementptr inbounds i8, i8* %115, i64 %5
  %121 = bitcast i8* %120 to <16 x i8>*
  %122 = load <16 x i8>, <16 x i8>* %121, align 1
  %123 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %122, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %124 = add <8 x i16> %123, %119
  %125 = bitcast i16* %116 to <8 x i16>*
  store <8 x i16> %124, <8 x i16>* %125, align 1
  %126 = getelementptr inbounds i8, i8* %115, i64 16
  %127 = bitcast i8* %126 to <16 x i8>*
  %128 = load <16 x i8>, <16 x i8>* %127, align 1
  %129 = getelementptr inbounds i8, i8* %120, i64 16
  %130 = bitcast i8* %129 to <16 x i8>*
  %131 = load <16 x i8>, <16 x i8>* %130, align 1
  %132 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %128, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %133 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %131, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %134 = add <8 x i16> %133, %132
  %135 = getelementptr inbounds i16, i16* %2, i64 168
  %136 = bitcast i16* %135 to <8 x i16>*
  store <8 x i16> %134, <8 x i16>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %115, i64 %6
  %138 = getelementptr inbounds i16, i16* %2, i64 192
  %139 = bitcast i8* %137 to <16 x i8>*
  %140 = load <16 x i8>, <16 x i8>* %139, align 1
  %141 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %140, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %142 = getelementptr inbounds i8, i8* %137, i64 %5
  %143 = bitcast i8* %142 to <16 x i8>*
  %144 = load <16 x i8>, <16 x i8>* %143, align 1
  %145 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %144, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %146 = add <8 x i16> %145, %141
  %147 = bitcast i16* %138 to <8 x i16>*
  store <8 x i16> %146, <8 x i16>* %147, align 1
  %148 = getelementptr inbounds i8, i8* %137, i64 16
  %149 = bitcast i8* %148 to <16 x i8>*
  %150 = load <16 x i8>, <16 x i8>* %149, align 1
  %151 = getelementptr inbounds i8, i8* %142, i64 16
  %152 = bitcast i8* %151 to <16 x i8>*
  %153 = load <16 x i8>, <16 x i8>* %152, align 1
  %154 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %150, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %155 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %153, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %156 = add <8 x i16> %155, %154
  %157 = getelementptr inbounds i16, i16* %2, i64 200
  %158 = bitcast i16* %157 to <8 x i16>*
  store <8 x i16> %156, <8 x i16>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %137, i64 %6
  %160 = getelementptr inbounds i16, i16* %2, i64 224
  %161 = bitcast i8* %159 to <16 x i8>*
  %162 = load <16 x i8>, <16 x i8>* %161, align 1
  %163 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %162, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %164 = getelementptr inbounds i8, i8* %159, i64 %5
  %165 = bitcast i8* %164 to <16 x i8>*
  %166 = load <16 x i8>, <16 x i8>* %165, align 1
  %167 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %166, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %168 = add <8 x i16> %167, %163
  %169 = bitcast i16* %160 to <8 x i16>*
  store <8 x i16> %168, <8 x i16>* %169, align 1
  %170 = getelementptr inbounds i8, i8* %159, i64 16
  %171 = bitcast i8* %170 to <16 x i8>*
  %172 = load <16 x i8>, <16 x i8>* %171, align 1
  %173 = getelementptr inbounds i8, i8* %164, i64 16
  %174 = bitcast i8* %173 to <16 x i8>*
  %175 = load <16 x i8>, <16 x i8>* %174, align 1
  %176 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %172, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %177 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %175, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %178 = add <8 x i16> %177, %176
  %179 = getelementptr inbounds i16, i16* %2, i64 232
  %180 = bitcast i16* %179 to <8 x i16>*
  store <8 x i16> %178, <8 x i16>* %180, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_4x16_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = sext i32 %1 to i64
  %6 = sext i32 %4 to i64
  %7 = bitcast i8* %0 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %8, i32 0
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %10, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %12 = getelementptr inbounds i8, i8* %0, i64 %5
  %13 = bitcast i8* %12 to i32*
  %14 = load i32, i32* %13, align 4
  %15 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %14, i32 0
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %16, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %18 = add <8 x i16> %17, %11
  %19 = bitcast <8 x i16> %18 to <4 x i32>
  %20 = extractelement <4 x i32> %19, i32 0
  %21 = bitcast i16* %2 to i32*
  store i32 %20, i32* %21, align 4
  %22 = getelementptr inbounds i8, i8* %0, i64 %6
  %23 = getelementptr inbounds i16, i16* %2, i64 32
  %24 = bitcast i8* %22 to i32*
  %25 = load i32, i32* %24, align 4
  %26 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %25, i32 0
  %27 = bitcast <4 x i32> %26 to <16 x i8>
  %28 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %27, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %29 = getelementptr inbounds i8, i8* %22, i64 %5
  %30 = bitcast i8* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %31, i32 0
  %33 = bitcast <4 x i32> %32 to <16 x i8>
  %34 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %33, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %35 = add <8 x i16> %34, %28
  %36 = bitcast <8 x i16> %35 to <4 x i32>
  %37 = extractelement <4 x i32> %36, i32 0
  %38 = bitcast i16* %23 to i32*
  store i32 %37, i32* %38, align 4
  %39 = getelementptr inbounds i8, i8* %22, i64 %6
  %40 = getelementptr inbounds i16, i16* %2, i64 64
  %41 = bitcast i8* %39 to i32*
  %42 = load i32, i32* %41, align 4
  %43 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %42, i32 0
  %44 = bitcast <4 x i32> %43 to <16 x i8>
  %45 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %44, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %46 = getelementptr inbounds i8, i8* %39, i64 %5
  %47 = bitcast i8* %46 to i32*
  %48 = load i32, i32* %47, align 4
  %49 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %48, i32 0
  %50 = bitcast <4 x i32> %49 to <16 x i8>
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %50, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %52 = add <8 x i16> %51, %45
  %53 = bitcast <8 x i16> %52 to <4 x i32>
  %54 = extractelement <4 x i32> %53, i32 0
  %55 = bitcast i16* %40 to i32*
  store i32 %54, i32* %55, align 4
  %56 = getelementptr inbounds i8, i8* %39, i64 %6
  %57 = getelementptr inbounds i16, i16* %2, i64 96
  %58 = bitcast i8* %56 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %59, i32 0
  %61 = bitcast <4 x i32> %60 to <16 x i8>
  %62 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %61, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %63 = getelementptr inbounds i8, i8* %56, i64 %5
  %64 = bitcast i8* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %65, i32 0
  %67 = bitcast <4 x i32> %66 to <16 x i8>
  %68 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %67, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %69 = add <8 x i16> %68, %62
  %70 = bitcast <8 x i16> %69 to <4 x i32>
  %71 = extractelement <4 x i32> %70, i32 0
  %72 = bitcast i16* %57 to i32*
  store i32 %71, i32* %72, align 4
  %73 = getelementptr inbounds i8, i8* %56, i64 %6
  %74 = getelementptr inbounds i16, i16* %2, i64 128
  %75 = bitcast i8* %73 to i32*
  %76 = load i32, i32* %75, align 4
  %77 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %76, i32 0
  %78 = bitcast <4 x i32> %77 to <16 x i8>
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %78, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %80 = getelementptr inbounds i8, i8* %73, i64 %5
  %81 = bitcast i8* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %82, i32 0
  %84 = bitcast <4 x i32> %83 to <16 x i8>
  %85 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %84, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %86 = add <8 x i16> %85, %79
  %87 = bitcast <8 x i16> %86 to <4 x i32>
  %88 = extractelement <4 x i32> %87, i32 0
  %89 = bitcast i16* %74 to i32*
  store i32 %88, i32* %89, align 4
  %90 = getelementptr inbounds i8, i8* %73, i64 %6
  %91 = getelementptr inbounds i16, i16* %2, i64 160
  %92 = bitcast i8* %90 to i32*
  %93 = load i32, i32* %92, align 4
  %94 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %93, i32 0
  %95 = bitcast <4 x i32> %94 to <16 x i8>
  %96 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %95, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %97 = getelementptr inbounds i8, i8* %90, i64 %5
  %98 = bitcast i8* %97 to i32*
  %99 = load i32, i32* %98, align 4
  %100 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %99, i32 0
  %101 = bitcast <4 x i32> %100 to <16 x i8>
  %102 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %101, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %103 = add <8 x i16> %102, %96
  %104 = bitcast <8 x i16> %103 to <4 x i32>
  %105 = extractelement <4 x i32> %104, i32 0
  %106 = bitcast i16* %91 to i32*
  store i32 %105, i32* %106, align 4
  %107 = getelementptr inbounds i8, i8* %90, i64 %6
  %108 = getelementptr inbounds i16, i16* %2, i64 192
  %109 = bitcast i8* %107 to i32*
  %110 = load i32, i32* %109, align 4
  %111 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %110, i32 0
  %112 = bitcast <4 x i32> %111 to <16 x i8>
  %113 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %112, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %114 = getelementptr inbounds i8, i8* %107, i64 %5
  %115 = bitcast i8* %114 to i32*
  %116 = load i32, i32* %115, align 4
  %117 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %116, i32 0
  %118 = bitcast <4 x i32> %117 to <16 x i8>
  %119 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %118, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %120 = add <8 x i16> %119, %113
  %121 = bitcast <8 x i16> %120 to <4 x i32>
  %122 = extractelement <4 x i32> %121, i32 0
  %123 = bitcast i16* %108 to i32*
  store i32 %122, i32* %123, align 4
  %124 = getelementptr inbounds i8, i8* %107, i64 %6
  %125 = getelementptr inbounds i16, i16* %2, i64 224
  %126 = bitcast i8* %124 to i32*
  %127 = load i32, i32* %126, align 4
  %128 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %127, i32 0
  %129 = bitcast <4 x i32> %128 to <16 x i8>
  %130 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %129, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %131 = getelementptr inbounds i8, i8* %124, i64 %5
  %132 = bitcast i8* %131 to i32*
  %133 = load i32, i32* %132, align 4
  %134 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %133, i32 0
  %135 = bitcast <4 x i32> %134 to <16 x i8>
  %136 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %135, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %137 = add <8 x i16> %136, %130
  %138 = bitcast <8 x i16> %137 to <4 x i32>
  %139 = extractelement <4 x i32> %138, i32 0
  %140 = bitcast i16* %125 to i32*
  store i32 %139, i32* %140, align 4
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_16x4_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = sext i32 %1 to i64
  %6 = sext i32 %4 to i64
  %7 = bitcast i8* %0 to <16 x i8>*
  %8 = load <16 x i8>, <16 x i8>* %7, align 1
  %9 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %8, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %10 = getelementptr inbounds i8, i8* %0, i64 %5
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %12, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %14 = add <8 x i16> %13, %9
  %15 = bitcast i16* %2 to <8 x i16>*
  store <8 x i16> %14, <8 x i16>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 %6
  %17 = getelementptr inbounds i16, i16* %2, i64 32
  %18 = bitcast i8* %16 to <16 x i8>*
  %19 = load <16 x i8>, <16 x i8>* %18, align 1
  %20 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %19, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %21 = getelementptr inbounds i8, i8* %16, i64 %5
  %22 = bitcast i8* %21 to <16 x i8>*
  %23 = load <16 x i8>, <16 x i8>* %22, align 1
  %24 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %23, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %25 = add <8 x i16> %24, %20
  %26 = bitcast i16* %17 to <8 x i16>*
  store <8 x i16> %25, <8 x i16>* %26, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_8x32_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 512
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = shl i32 %1, 1
  %8 = sext i32 %1 to i64
  %9 = sext i32 %7 to i64
  br label %10

10:                                               ; preds = %10, %3
  %11 = phi <2 x i64>* [ %4, %3 ], [ %29, %10 ]
  %12 = phi i8* [ %0, %3 ], [ %28, %10 ]
  %13 = bitcast i8* %12 to i64*
  %14 = load i64, i64* %13, align 1
  %15 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %14, i32 0
  %16 = bitcast <2 x i64> %15 to <16 x i8>
  %17 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %16, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %18 = getelementptr inbounds i8, i8* %12, i64 %8
  %19 = bitcast i8* %18 to i64*
  %20 = load i64, i64* %19, align 1
  %21 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %20, i32 0
  %22 = bitcast <2 x i64> %21 to <16 x i8>
  %23 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %22, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %24 = add <8 x i16> %23, %17
  %25 = bitcast <8 x i16> %24 to <2 x i64>
  %26 = extractelement <2 x i64> %25, i32 0
  %27 = getelementptr inbounds <2 x i64>, <2 x i64>* %11, i64 0, i64 0
  store i64 %26, i64* %27, align 1
  %28 = getelementptr inbounds i8, i8* %12, i64 %9
  %29 = getelementptr inbounds <2 x i64>, <2 x i64>* %11, i64 4
  %30 = icmp ult <2 x i64>* %29, %6
  br i1 %30, label %10, label %31

31:                                               ; preds = %10
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_32x8_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = sext i32 %1 to i64
  %6 = sext i32 %4 to i64
  %7 = bitcast i8* %0 to <16 x i8>*
  %8 = load <16 x i8>, <16 x i8>* %7, align 1
  %9 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %8, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %10 = getelementptr inbounds i8, i8* %0, i64 %5
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %12, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %14 = add <8 x i16> %13, %9
  %15 = bitcast i16* %2 to <8 x i16>*
  store <8 x i16> %14, <8 x i16>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 16
  %17 = bitcast i8* %16 to <16 x i8>*
  %18 = load <16 x i8>, <16 x i8>* %17, align 1
  %19 = getelementptr inbounds i8, i8* %10, i64 16
  %20 = bitcast i8* %19 to <16 x i8>*
  %21 = load <16 x i8>, <16 x i8>* %20, align 1
  %22 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %18, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %23 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %21, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %24 = add <8 x i16> %23, %22
  %25 = getelementptr inbounds i16, i16* %2, i64 8
  %26 = bitcast i16* %25 to <8 x i16>*
  store <8 x i16> %24, <8 x i16>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %0, i64 %6
  %28 = getelementptr inbounds i16, i16* %2, i64 32
  %29 = bitcast i8* %27 to <16 x i8>*
  %30 = load <16 x i8>, <16 x i8>* %29, align 1
  %31 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %30, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %32 = getelementptr inbounds i8, i8* %27, i64 %5
  %33 = bitcast i8* %32 to <16 x i8>*
  %34 = load <16 x i8>, <16 x i8>* %33, align 1
  %35 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %34, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %36 = add <8 x i16> %35, %31
  %37 = bitcast i16* %28 to <8 x i16>*
  store <8 x i16> %36, <8 x i16>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %27, i64 16
  %39 = bitcast i8* %38 to <16 x i8>*
  %40 = load <16 x i8>, <16 x i8>* %39, align 1
  %41 = getelementptr inbounds i8, i8* %32, i64 16
  %42 = bitcast i8* %41 to <16 x i8>*
  %43 = load <16 x i8>, <16 x i8>* %42, align 1
  %44 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %40, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %45 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %43, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %46 = add <8 x i16> %45, %44
  %47 = getelementptr inbounds i16, i16* %2, i64 40
  %48 = bitcast i16* %47 to <8 x i16>*
  store <8 x i16> %46, <8 x i16>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %27, i64 %6
  %50 = getelementptr inbounds i16, i16* %2, i64 64
  %51 = bitcast i8* %49 to <16 x i8>*
  %52 = load <16 x i8>, <16 x i8>* %51, align 1
  %53 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %52, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %54 = getelementptr inbounds i8, i8* %49, i64 %5
  %55 = bitcast i8* %54 to <16 x i8>*
  %56 = load <16 x i8>, <16 x i8>* %55, align 1
  %57 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %56, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %58 = add <8 x i16> %57, %53
  %59 = bitcast i16* %50 to <8 x i16>*
  store <8 x i16> %58, <8 x i16>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %49, i64 16
  %61 = bitcast i8* %60 to <16 x i8>*
  %62 = load <16 x i8>, <16 x i8>* %61, align 1
  %63 = getelementptr inbounds i8, i8* %54, i64 16
  %64 = bitcast i8* %63 to <16 x i8>*
  %65 = load <16 x i8>, <16 x i8>* %64, align 1
  %66 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %62, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %67 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %65, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %68 = add <8 x i16> %67, %66
  %69 = getelementptr inbounds i16, i16* %2, i64 72
  %70 = bitcast i16* %69 to <8 x i16>*
  store <8 x i16> %68, <8 x i16>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %49, i64 %6
  %72 = getelementptr inbounds i16, i16* %2, i64 96
  %73 = bitcast i8* %71 to <16 x i8>*
  %74 = load <16 x i8>, <16 x i8>* %73, align 1
  %75 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %74, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %76 = getelementptr inbounds i8, i8* %71, i64 %5
  %77 = bitcast i8* %76 to <16 x i8>*
  %78 = load <16 x i8>, <16 x i8>* %77, align 1
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %78, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %80 = add <8 x i16> %79, %75
  %81 = bitcast i16* %72 to <8 x i16>*
  store <8 x i16> %80, <8 x i16>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %71, i64 16
  %83 = bitcast i8* %82 to <16 x i8>*
  %84 = load <16 x i8>, <16 x i8>* %83, align 1
  %85 = getelementptr inbounds i8, i8* %76, i64 16
  %86 = bitcast i8* %85 to <16 x i8>*
  %87 = load <16 x i8>, <16 x i8>* %86, align 1
  %88 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %84, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %89 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %87, <16 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #4
  %90 = add <8 x i16> %89, %88
  %91 = getelementptr inbounds i16, i16* %2, i64 104
  %92 = bitcast i16* %91 to <8 x i16>*
  store <8 x i16> %90, <8 x i16>* %92, align 1
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void (i8*, i32, i16*)* @cfl_get_luma_subsampling_420_lbd_ssse3(i8 zeroext) local_unnamed_addr #1 {
  %2 = zext i8 %0 to i64
  %3 = getelementptr inbounds [19 x void (i8*, i32, i16*)*], [19 x void (i8*, i32, i16*)*]* @cfl_get_luma_subsampling_420_lbd_ssse3.subfn_420, i64 0, i64 %2
  %4 = load void (i8*, i32, i16*)*, void (i8*, i32, i16*)** %3, align 8
  ret void (i8*, i32, i16*)* %4
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_4x4_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to i32*
  %6 = load i32, i32* %5, align 4
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %8, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %10 = bitcast <8 x i16> %9 to <4 x i32>
  %11 = extractelement <4 x i32> %10, i32 0
  %12 = bitcast i16* %2 to i32*
  store i32 %11, i32* %12, align 4
  %13 = getelementptr inbounds i8, i8* %0, i64 %4
  %14 = getelementptr inbounds i16, i16* %2, i64 32
  %15 = bitcast i8* %13 to i32*
  %16 = load i32, i32* %15, align 4
  %17 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %16, i32 0
  %18 = bitcast <4 x i32> %17 to <16 x i8>
  %19 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %18, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %20 = bitcast <8 x i16> %19 to <4 x i32>
  %21 = extractelement <4 x i32> %20, i32 0
  %22 = bitcast i16* %14 to i32*
  store i32 %21, i32* %22, align 4
  %23 = getelementptr inbounds i8, i8* %13, i64 %4
  %24 = getelementptr inbounds i16, i16* %2, i64 64
  %25 = bitcast i8* %23 to i32*
  %26 = load i32, i32* %25, align 4
  %27 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %26, i32 0
  %28 = bitcast <4 x i32> %27 to <16 x i8>
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %28, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %30 = bitcast <8 x i16> %29 to <4 x i32>
  %31 = extractelement <4 x i32> %30, i32 0
  %32 = bitcast i16* %24 to i32*
  store i32 %31, i32* %32, align 4
  %33 = getelementptr inbounds i8, i8* %23, i64 %4
  %34 = getelementptr inbounds i16, i16* %2, i64 96
  %35 = bitcast i8* %33 to i32*
  %36 = load i32, i32* %35, align 4
  %37 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %36, i32 0
  %38 = bitcast <4 x i32> %37 to <16 x i8>
  %39 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %38, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %40 = bitcast <8 x i16> %39 to <4 x i32>
  %41 = extractelement <4 x i32> %40, i32 0
  %42 = bitcast i16* %34 to i32*
  store i32 %41, i32* %42, align 4
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_8x8_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %8, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %10 = bitcast <8 x i16> %9 to <2 x i64>
  %11 = extractelement <2 x i64> %10, i32 0
  %12 = bitcast i16* %2 to i64*
  store i64 %11, i64* %12, align 1
  %13 = getelementptr inbounds i8, i8* %0, i64 %4
  %14 = getelementptr inbounds i16, i16* %2, i64 32
  %15 = bitcast i8* %13 to i64*
  %16 = load i64, i64* %15, align 1
  %17 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %16, i32 0
  %18 = bitcast <2 x i64> %17 to <16 x i8>
  %19 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %18, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %20 = bitcast <8 x i16> %19 to <2 x i64>
  %21 = extractelement <2 x i64> %20, i32 0
  %22 = bitcast i16* %14 to i64*
  store i64 %21, i64* %22, align 1
  %23 = getelementptr inbounds i8, i8* %13, i64 %4
  %24 = getelementptr inbounds i16, i16* %2, i64 64
  %25 = bitcast i8* %23 to i64*
  %26 = load i64, i64* %25, align 1
  %27 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %26, i32 0
  %28 = bitcast <2 x i64> %27 to <16 x i8>
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %28, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %30 = bitcast <8 x i16> %29 to <2 x i64>
  %31 = extractelement <2 x i64> %30, i32 0
  %32 = bitcast i16* %24 to i64*
  store i64 %31, i64* %32, align 1
  %33 = getelementptr inbounds i8, i8* %23, i64 %4
  %34 = getelementptr inbounds i16, i16* %2, i64 96
  %35 = bitcast i8* %33 to i64*
  %36 = load i64, i64* %35, align 1
  %37 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %36, i32 0
  %38 = bitcast <2 x i64> %37 to <16 x i8>
  %39 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %38, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %40 = bitcast <8 x i16> %39 to <2 x i64>
  %41 = extractelement <2 x i64> %40, i32 0
  %42 = bitcast i16* %34 to i64*
  store i64 %41, i64* %42, align 1
  %43 = getelementptr inbounds i8, i8* %33, i64 %4
  %44 = getelementptr inbounds i16, i16* %2, i64 128
  %45 = bitcast i8* %43 to i64*
  %46 = load i64, i64* %45, align 1
  %47 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %46, i32 0
  %48 = bitcast <2 x i64> %47 to <16 x i8>
  %49 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %48, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %50 = bitcast <8 x i16> %49 to <2 x i64>
  %51 = extractelement <2 x i64> %50, i32 0
  %52 = bitcast i16* %44 to i64*
  store i64 %51, i64* %52, align 1
  %53 = getelementptr inbounds i8, i8* %43, i64 %4
  %54 = getelementptr inbounds i16, i16* %2, i64 160
  %55 = bitcast i8* %53 to i64*
  %56 = load i64, i64* %55, align 1
  %57 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %56, i32 0
  %58 = bitcast <2 x i64> %57 to <16 x i8>
  %59 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %58, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %60 = bitcast <8 x i16> %59 to <2 x i64>
  %61 = extractelement <2 x i64> %60, i32 0
  %62 = bitcast i16* %54 to i64*
  store i64 %61, i64* %62, align 1
  %63 = getelementptr inbounds i8, i8* %53, i64 %4
  %64 = getelementptr inbounds i16, i16* %2, i64 192
  %65 = bitcast i8* %63 to i64*
  %66 = load i64, i64* %65, align 1
  %67 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %66, i32 0
  %68 = bitcast <2 x i64> %67 to <16 x i8>
  %69 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %68, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %70 = bitcast <8 x i16> %69 to <2 x i64>
  %71 = extractelement <2 x i64> %70, i32 0
  %72 = bitcast i16* %64 to i64*
  store i64 %71, i64* %72, align 1
  %73 = getelementptr inbounds i8, i8* %63, i64 %4
  %74 = getelementptr inbounds i16, i16* %2, i64 224
  %75 = bitcast i8* %73 to i64*
  %76 = load i64, i64* %75, align 1
  %77 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %76, i32 0
  %78 = bitcast <2 x i64> %77 to <16 x i8>
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %78, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %80 = bitcast <8 x i16> %79 to <2 x i64>
  %81 = extractelement <2 x i64> %80, i32 0
  %82 = bitcast i16* %74 to i64*
  store i64 %81, i64* %82, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_16x16_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 512
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %16, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %15, %8 ]
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %12, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %14 = bitcast <2 x i64>* %9 to <8 x i16>*
  store <8 x i16> %13, <8 x i16>* %14, align 1
  %15 = getelementptr inbounds i8, i8* %10, i64 %7
  %16 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %17 = icmp ult <2 x i64>* %16, %6
  br i1 %17, label %8, label %18

18:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_32x32_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 1024
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %22, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %21, %8 ]
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %12, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %14 = bitcast <2 x i64>* %9 to <8 x i16>*
  store <8 x i16> %13, <8 x i16>* %14, align 1
  %15 = getelementptr inbounds i8, i8* %10, i64 16
  %16 = bitcast i8* %15 to <16 x i8>*
  %17 = load <16 x i8>, <16 x i8>* %16, align 1
  %18 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %17, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %19 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 1
  %20 = bitcast <2 x i64>* %19 to <8 x i16>*
  store <8 x i16> %18, <8 x i16>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %10, i64 %7
  %22 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %23 = icmp ult <2 x i64>* %22, %6
  br i1 %23, label %8, label %24

24:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_4x8_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to i32*
  %6 = load i32, i32* %5, align 4
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %8, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %10 = bitcast <8 x i16> %9 to <4 x i32>
  %11 = extractelement <4 x i32> %10, i32 0
  %12 = bitcast i16* %2 to i32*
  store i32 %11, i32* %12, align 4
  %13 = getelementptr inbounds i8, i8* %0, i64 %4
  %14 = getelementptr inbounds i16, i16* %2, i64 32
  %15 = bitcast i8* %13 to i32*
  %16 = load i32, i32* %15, align 4
  %17 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %16, i32 0
  %18 = bitcast <4 x i32> %17 to <16 x i8>
  %19 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %18, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %20 = bitcast <8 x i16> %19 to <4 x i32>
  %21 = extractelement <4 x i32> %20, i32 0
  %22 = bitcast i16* %14 to i32*
  store i32 %21, i32* %22, align 4
  %23 = getelementptr inbounds i8, i8* %13, i64 %4
  %24 = getelementptr inbounds i16, i16* %2, i64 64
  %25 = bitcast i8* %23 to i32*
  %26 = load i32, i32* %25, align 4
  %27 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %26, i32 0
  %28 = bitcast <4 x i32> %27 to <16 x i8>
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %28, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %30 = bitcast <8 x i16> %29 to <4 x i32>
  %31 = extractelement <4 x i32> %30, i32 0
  %32 = bitcast i16* %24 to i32*
  store i32 %31, i32* %32, align 4
  %33 = getelementptr inbounds i8, i8* %23, i64 %4
  %34 = getelementptr inbounds i16, i16* %2, i64 96
  %35 = bitcast i8* %33 to i32*
  %36 = load i32, i32* %35, align 4
  %37 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %36, i32 0
  %38 = bitcast <4 x i32> %37 to <16 x i8>
  %39 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %38, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %40 = bitcast <8 x i16> %39 to <4 x i32>
  %41 = extractelement <4 x i32> %40, i32 0
  %42 = bitcast i16* %34 to i32*
  store i32 %41, i32* %42, align 4
  %43 = getelementptr inbounds i8, i8* %33, i64 %4
  %44 = getelementptr inbounds i16, i16* %2, i64 128
  %45 = bitcast i8* %43 to i32*
  %46 = load i32, i32* %45, align 4
  %47 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %46, i32 0
  %48 = bitcast <4 x i32> %47 to <16 x i8>
  %49 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %48, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %50 = bitcast <8 x i16> %49 to <4 x i32>
  %51 = extractelement <4 x i32> %50, i32 0
  %52 = bitcast i16* %44 to i32*
  store i32 %51, i32* %52, align 4
  %53 = getelementptr inbounds i8, i8* %43, i64 %4
  %54 = getelementptr inbounds i16, i16* %2, i64 160
  %55 = bitcast i8* %53 to i32*
  %56 = load i32, i32* %55, align 4
  %57 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %56, i32 0
  %58 = bitcast <4 x i32> %57 to <16 x i8>
  %59 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %58, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %60 = bitcast <8 x i16> %59 to <4 x i32>
  %61 = extractelement <4 x i32> %60, i32 0
  %62 = bitcast i16* %54 to i32*
  store i32 %61, i32* %62, align 4
  %63 = getelementptr inbounds i8, i8* %53, i64 %4
  %64 = getelementptr inbounds i16, i16* %2, i64 192
  %65 = bitcast i8* %63 to i32*
  %66 = load i32, i32* %65, align 4
  %67 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %66, i32 0
  %68 = bitcast <4 x i32> %67 to <16 x i8>
  %69 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %68, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %70 = bitcast <8 x i16> %69 to <4 x i32>
  %71 = extractelement <4 x i32> %70, i32 0
  %72 = bitcast i16* %64 to i32*
  store i32 %71, i32* %72, align 4
  %73 = getelementptr inbounds i8, i8* %63, i64 %4
  %74 = getelementptr inbounds i16, i16* %2, i64 224
  %75 = bitcast i8* %73 to i32*
  %76 = load i32, i32* %75, align 4
  %77 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %76, i32 0
  %78 = bitcast <4 x i32> %77 to <16 x i8>
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %78, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %80 = bitcast <8 x i16> %79 to <4 x i32>
  %81 = extractelement <4 x i32> %80, i32 0
  %82 = bitcast i16* %74 to i32*
  store i32 %81, i32* %82, align 4
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_8x4_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %8, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %10 = bitcast <8 x i16> %9 to <2 x i64>
  %11 = extractelement <2 x i64> %10, i32 0
  %12 = bitcast i16* %2 to i64*
  store i64 %11, i64* %12, align 1
  %13 = getelementptr inbounds i8, i8* %0, i64 %4
  %14 = getelementptr inbounds i16, i16* %2, i64 32
  %15 = bitcast i8* %13 to i64*
  %16 = load i64, i64* %15, align 1
  %17 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %16, i32 0
  %18 = bitcast <2 x i64> %17 to <16 x i8>
  %19 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %18, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %20 = bitcast <8 x i16> %19 to <2 x i64>
  %21 = extractelement <2 x i64> %20, i32 0
  %22 = bitcast i16* %14 to i64*
  store i64 %21, i64* %22, align 1
  %23 = getelementptr inbounds i8, i8* %13, i64 %4
  %24 = getelementptr inbounds i16, i16* %2, i64 64
  %25 = bitcast i8* %23 to i64*
  %26 = load i64, i64* %25, align 1
  %27 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %26, i32 0
  %28 = bitcast <2 x i64> %27 to <16 x i8>
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %28, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %30 = bitcast <8 x i16> %29 to <2 x i64>
  %31 = extractelement <2 x i64> %30, i32 0
  %32 = bitcast i16* %24 to i64*
  store i64 %31, i64* %32, align 1
  %33 = getelementptr inbounds i8, i8* %23, i64 %4
  %34 = getelementptr inbounds i16, i16* %2, i64 96
  %35 = bitcast i8* %33 to i64*
  %36 = load i64, i64* %35, align 1
  %37 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %36, i32 0
  %38 = bitcast <2 x i64> %37 to <16 x i8>
  %39 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %38, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %40 = bitcast <8 x i16> %39 to <2 x i64>
  %41 = extractelement <2 x i64> %40, i32 0
  %42 = bitcast i16* %34 to i64*
  store i64 %41, i64* %42, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_8x16_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 512
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %20, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %19, %8 ]
  %11 = bitcast i8* %10 to i64*
  %12 = load i64, i64* %11, align 1
  %13 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %12, i32 0
  %14 = bitcast <2 x i64> %13 to <16 x i8>
  %15 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %14, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %16 = bitcast <8 x i16> %15 to <2 x i64>
  %17 = extractelement <2 x i64> %16, i32 0
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 0, i64 0
  store i64 %17, i64* %18, align 1
  %19 = getelementptr inbounds i8, i8* %10, i64 %7
  %20 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %21 = icmp ult <2 x i64>* %20, %6
  br i1 %21, label %8, label %22

22:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_16x8_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %8 = bitcast i16* %2 to <8 x i16>*
  store <8 x i16> %7, <8 x i16>* %8, align 1
  %9 = getelementptr inbounds i8, i8* %0, i64 %4
  %10 = getelementptr inbounds i16, i16* %2, i64 32
  %11 = bitcast i8* %9 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %12, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %14 = bitcast i16* %10 to <8 x i16>*
  store <8 x i16> %13, <8 x i16>* %14, align 1
  %15 = getelementptr inbounds i8, i8* %9, i64 %4
  %16 = getelementptr inbounds i16, i16* %2, i64 64
  %17 = bitcast i8* %15 to <16 x i8>*
  %18 = load <16 x i8>, <16 x i8>* %17, align 1
  %19 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %18, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %20 = bitcast i16* %16 to <8 x i16>*
  store <8 x i16> %19, <8 x i16>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %15, i64 %4
  %22 = getelementptr inbounds i16, i16* %2, i64 96
  %23 = bitcast i8* %21 to <16 x i8>*
  %24 = load <16 x i8>, <16 x i8>* %23, align 1
  %25 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %24, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %26 = bitcast i16* %22 to <8 x i16>*
  store <8 x i16> %25, <8 x i16>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %21, i64 %4
  %28 = getelementptr inbounds i16, i16* %2, i64 128
  %29 = bitcast i8* %27 to <16 x i8>*
  %30 = load <16 x i8>, <16 x i8>* %29, align 1
  %31 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %30, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %32 = bitcast i16* %28 to <8 x i16>*
  store <8 x i16> %31, <8 x i16>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %27, i64 %4
  %34 = getelementptr inbounds i16, i16* %2, i64 160
  %35 = bitcast i8* %33 to <16 x i8>*
  %36 = load <16 x i8>, <16 x i8>* %35, align 1
  %37 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %36, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %38 = bitcast i16* %34 to <8 x i16>*
  store <8 x i16> %37, <8 x i16>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %33, i64 %4
  %40 = getelementptr inbounds i16, i16* %2, i64 192
  %41 = bitcast i8* %39 to <16 x i8>*
  %42 = load <16 x i8>, <16 x i8>* %41, align 1
  %43 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %42, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %44 = bitcast i16* %40 to <8 x i16>*
  store <8 x i16> %43, <8 x i16>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %39, i64 %4
  %46 = getelementptr inbounds i16, i16* %2, i64 224
  %47 = bitcast i8* %45 to <16 x i8>*
  %48 = load <16 x i8>, <16 x i8>* %47, align 1
  %49 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %48, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %50 = bitcast i16* %46 to <8 x i16>*
  store <8 x i16> %49, <8 x i16>* %50, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_16x32_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 1024
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %16, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %15, %8 ]
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %12, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %14 = bitcast <2 x i64>* %9 to <8 x i16>*
  store <8 x i16> %13, <8 x i16>* %14, align 1
  %15 = getelementptr inbounds i8, i8* %10, i64 %7
  %16 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %17 = icmp ult <2 x i64>* %16, %6
  br i1 %17, label %8, label %18

18:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_32x16_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 512
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %22, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %21, %8 ]
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %12, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %14 = bitcast <2 x i64>* %9 to <8 x i16>*
  store <8 x i16> %13, <8 x i16>* %14, align 1
  %15 = getelementptr inbounds i8, i8* %10, i64 16
  %16 = bitcast i8* %15 to <16 x i8>*
  %17 = load <16 x i8>, <16 x i8>* %16, align 1
  %18 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %17, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %19 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 1
  %20 = bitcast <2 x i64>* %19 to <8 x i16>*
  store <8 x i16> %18, <8 x i16>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %10, i64 %7
  %22 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %23 = icmp ult <2 x i64>* %22, %6
  br i1 %23, label %8, label %24

24:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_4x16_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 512
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %20, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %19, %8 ]
  %11 = bitcast i8* %10 to i32*
  %12 = load i32, i32* %11, align 4
  %13 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %12, i32 0
  %14 = bitcast <4 x i32> %13 to <16 x i8>
  %15 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %14, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %16 = bitcast <8 x i16> %15 to <4 x i32>
  %17 = extractelement <4 x i32> %16, i32 0
  %18 = bitcast <2 x i64>* %9 to i32*
  store i32 %17, i32* %18, align 4
  %19 = getelementptr inbounds i8, i8* %10, i64 %7
  %20 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %21 = icmp ult <2 x i64>* %20, %6
  br i1 %21, label %8, label %22

22:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_16x4_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %8 = bitcast i16* %2 to <8 x i16>*
  store <8 x i16> %7, <8 x i16>* %8, align 1
  %9 = getelementptr inbounds i8, i8* %0, i64 %4
  %10 = getelementptr inbounds i16, i16* %2, i64 32
  %11 = bitcast i8* %9 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %12, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %14 = bitcast i16* %10 to <8 x i16>*
  store <8 x i16> %13, <8 x i16>* %14, align 1
  %15 = getelementptr inbounds i8, i8* %9, i64 %4
  %16 = getelementptr inbounds i16, i16* %2, i64 64
  %17 = bitcast i8* %15 to <16 x i8>*
  %18 = load <16 x i8>, <16 x i8>* %17, align 1
  %19 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %18, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %20 = bitcast i16* %16 to <8 x i16>*
  store <8 x i16> %19, <8 x i16>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %15, i64 %4
  %22 = getelementptr inbounds i16, i16* %2, i64 96
  %23 = bitcast i8* %21 to <16 x i8>*
  %24 = load <16 x i8>, <16 x i8>* %23, align 1
  %25 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %24, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %26 = bitcast i16* %22 to <8 x i16>*
  store <8 x i16> %25, <8 x i16>* %26, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_8x32_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 1024
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %20, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %19, %8 ]
  %11 = bitcast i8* %10 to i64*
  %12 = load i64, i64* %11, align 1
  %13 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %12, i32 0
  %14 = bitcast <2 x i64> %13 to <16 x i8>
  %15 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %14, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %16 = bitcast <8 x i16> %15 to <2 x i64>
  %17 = extractelement <2 x i64> %16, i32 0
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 0, i64 0
  store i64 %17, i64* %18, align 1
  %19 = getelementptr inbounds i8, i8* %10, i64 %7
  %20 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %21 = icmp ult <2 x i64>* %20, %6
  br i1 %21, label %8, label %22

22:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_32x8_ssse3(i8* nocapture readonly, i32, i16*) #0 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %8 = bitcast i16* %2 to <8 x i16>*
  store <8 x i16> %7, <8 x i16>* %8, align 1
  %9 = getelementptr inbounds i8, i8* %0, i64 16
  %10 = bitcast i8* %9 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %11, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %13 = getelementptr inbounds i16, i16* %2, i64 8
  %14 = bitcast i16* %13 to <8 x i16>*
  store <8 x i16> %12, <8 x i16>* %14, align 1
  %15 = getelementptr inbounds i8, i8* %0, i64 %4
  %16 = getelementptr inbounds i16, i16* %2, i64 32
  %17 = bitcast i8* %15 to <16 x i8>*
  %18 = load <16 x i8>, <16 x i8>* %17, align 1
  %19 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %18, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %20 = bitcast i16* %16 to <8 x i16>*
  store <8 x i16> %19, <8 x i16>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %15, i64 16
  %22 = bitcast i8* %21 to <16 x i8>*
  %23 = load <16 x i8>, <16 x i8>* %22, align 1
  %24 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %23, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %25 = getelementptr inbounds i16, i16* %2, i64 40
  %26 = bitcast i16* %25 to <8 x i16>*
  store <8 x i16> %24, <8 x i16>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %15, i64 %4
  %28 = getelementptr inbounds i16, i16* %2, i64 64
  %29 = bitcast i8* %27 to <16 x i8>*
  %30 = load <16 x i8>, <16 x i8>* %29, align 1
  %31 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %30, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %32 = bitcast i16* %28 to <8 x i16>*
  store <8 x i16> %31, <8 x i16>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %27, i64 16
  %34 = bitcast i8* %33 to <16 x i8>*
  %35 = load <16 x i8>, <16 x i8>* %34, align 1
  %36 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %35, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %37 = getelementptr inbounds i16, i16* %2, i64 72
  %38 = bitcast i16* %37 to <8 x i16>*
  store <8 x i16> %36, <8 x i16>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %27, i64 %4
  %40 = getelementptr inbounds i16, i16* %2, i64 96
  %41 = bitcast i8* %39 to <16 x i8>*
  %42 = load <16 x i8>, <16 x i8>* %41, align 1
  %43 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %42, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %44 = bitcast i16* %40 to <8 x i16>*
  store <8 x i16> %43, <8 x i16>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %39, i64 16
  %46 = bitcast i8* %45 to <16 x i8>*
  %47 = load <16 x i8>, <16 x i8>* %46, align 1
  %48 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %47, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %49 = getelementptr inbounds i16, i16* %2, i64 104
  %50 = bitcast i16* %49 to <8 x i16>*
  store <8 x i16> %48, <8 x i16>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %39, i64 %4
  %52 = getelementptr inbounds i16, i16* %2, i64 128
  %53 = bitcast i8* %51 to <16 x i8>*
  %54 = load <16 x i8>, <16 x i8>* %53, align 1
  %55 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %54, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %56 = bitcast i16* %52 to <8 x i16>*
  store <8 x i16> %55, <8 x i16>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %51, i64 16
  %58 = bitcast i8* %57 to <16 x i8>*
  %59 = load <16 x i8>, <16 x i8>* %58, align 1
  %60 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %59, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %61 = getelementptr inbounds i16, i16* %2, i64 136
  %62 = bitcast i16* %61 to <8 x i16>*
  store <8 x i16> %60, <8 x i16>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %51, i64 %4
  %64 = getelementptr inbounds i16, i16* %2, i64 160
  %65 = bitcast i8* %63 to <16 x i8>*
  %66 = load <16 x i8>, <16 x i8>* %65, align 1
  %67 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %66, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %68 = bitcast i16* %64 to <8 x i16>*
  store <8 x i16> %67, <8 x i16>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %63, i64 16
  %70 = bitcast i8* %69 to <16 x i8>*
  %71 = load <16 x i8>, <16 x i8>* %70, align 1
  %72 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %71, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %73 = getelementptr inbounds i16, i16* %2, i64 168
  %74 = bitcast i16* %73 to <8 x i16>*
  store <8 x i16> %72, <8 x i16>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %63, i64 %4
  %76 = getelementptr inbounds i16, i16* %2, i64 192
  %77 = bitcast i8* %75 to <16 x i8>*
  %78 = load <16 x i8>, <16 x i8>* %77, align 1
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %78, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %80 = bitcast i16* %76 to <8 x i16>*
  store <8 x i16> %79, <8 x i16>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %75, i64 16
  %82 = bitcast i8* %81 to <16 x i8>*
  %83 = load <16 x i8>, <16 x i8>* %82, align 1
  %84 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %83, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %85 = getelementptr inbounds i16, i16* %2, i64 200
  %86 = bitcast i16* %85 to <8 x i16>*
  store <8 x i16> %84, <8 x i16>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %75, i64 %4
  %88 = getelementptr inbounds i16, i16* %2, i64 224
  %89 = bitcast i8* %87 to <16 x i8>*
  %90 = load <16 x i8>, <16 x i8>* %89, align 1
  %91 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %90, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %92 = bitcast i16* %88 to <8 x i16>*
  store <8 x i16> %91, <8 x i16>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %87, i64 16
  %94 = bitcast i8* %93 to <16 x i8>*
  %95 = load <16 x i8>, <16 x i8>* %94, align 1
  %96 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %95, <16 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #4
  %97 = getelementptr inbounds i16, i16* %2, i64 232
  %98 = bitcast i16* %97 to <8 x i16>*
  store <8 x i16> %96, <8 x i16>* %98, align 1
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void (i8*, i32, i16*)* @cfl_get_luma_subsampling_422_lbd_ssse3(i8 zeroext) local_unnamed_addr #1 {
  %2 = zext i8 %0 to i64
  %3 = getelementptr inbounds [19 x void (i8*, i32, i16*)*], [19 x void (i8*, i32, i16*)*]* @cfl_get_luma_subsampling_422_lbd_ssse3.subfn_422, i64 0, i64 %2
  %4 = load void (i8*, i32, i16*)*, void (i8*, i32, i16*)** %3, align 8
  ret void (i8*, i32, i16*)* %4
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_4x4_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to i32*
  %6 = load i32, i32* %5, align 4
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10 = bitcast <16 x i8> %9 to <8 x i16>
  %11 = shl <8 x i16> %10, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %12 = bitcast <8 x i16> %11 to <2 x i64>
  %13 = extractelement <2 x i64> %12, i32 0
  %14 = bitcast i16* %2 to i64*
  store i64 %13, i64* %14, align 1
  %15 = getelementptr inbounds i8, i8* %0, i64 %4
  %16 = getelementptr inbounds i16, i16* %2, i64 32
  %17 = bitcast i8* %15 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %18, i32 0
  %20 = bitcast <4 x i32> %19 to <16 x i8>
  %21 = shufflevector <16 x i8> %20, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %22 = bitcast <16 x i8> %21 to <8 x i16>
  %23 = shl <8 x i16> %22, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %24 = bitcast <8 x i16> %23 to <2 x i64>
  %25 = extractelement <2 x i64> %24, i32 0
  %26 = bitcast i16* %16 to i64*
  store i64 %25, i64* %26, align 1
  %27 = getelementptr inbounds i8, i8* %15, i64 %4
  %28 = getelementptr inbounds i16, i16* %2, i64 64
  %29 = bitcast i8* %27 to i32*
  %30 = load i32, i32* %29, align 4
  %31 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %30, i32 0
  %32 = bitcast <4 x i32> %31 to <16 x i8>
  %33 = shufflevector <16 x i8> %32, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %34 = bitcast <16 x i8> %33 to <8 x i16>
  %35 = shl <8 x i16> %34, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %36 = bitcast <8 x i16> %35 to <2 x i64>
  %37 = extractelement <2 x i64> %36, i32 0
  %38 = bitcast i16* %28 to i64*
  store i64 %37, i64* %38, align 1
  %39 = getelementptr inbounds i8, i8* %27, i64 %4
  %40 = getelementptr inbounds i16, i16* %2, i64 96
  %41 = bitcast i8* %39 to i32*
  %42 = load i32, i32* %41, align 4
  %43 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %42, i32 0
  %44 = bitcast <4 x i32> %43 to <16 x i8>
  %45 = shufflevector <16 x i8> %44, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %46 = bitcast <16 x i8> %45 to <8 x i16>
  %47 = shl <8 x i16> %46, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %48 = bitcast <8 x i16> %47 to <2 x i64>
  %49 = extractelement <2 x i64> %48, i32 0
  %50 = bitcast i16* %40 to i64*
  store i64 %49, i64* %50, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_8x8_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> undef, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10 = bitcast <16 x i8> %9 to <8 x i16>
  %11 = shl <8 x i16> %10, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %12 = bitcast i16* %2 to <8 x i16>*
  store <8 x i16> %11, <8 x i16>* %12, align 1
  %13 = getelementptr inbounds i8, i8* %0, i64 %4
  %14 = getelementptr inbounds i16, i16* %2, i64 32
  %15 = bitcast i8* %13 to i64*
  %16 = load i64, i64* %15, align 1
  %17 = insertelement <2 x i64> undef, i64 %16, i32 0
  %18 = bitcast <2 x i64> %17 to <16 x i8>
  %19 = shufflevector <16 x i8> %18, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %20 = bitcast <16 x i8> %19 to <8 x i16>
  %21 = shl <8 x i16> %20, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %22 = bitcast i16* %14 to <8 x i16>*
  store <8 x i16> %21, <8 x i16>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %13, i64 %4
  %24 = getelementptr inbounds i16, i16* %2, i64 64
  %25 = bitcast i8* %23 to i64*
  %26 = load i64, i64* %25, align 1
  %27 = insertelement <2 x i64> undef, i64 %26, i32 0
  %28 = bitcast <2 x i64> %27 to <16 x i8>
  %29 = shufflevector <16 x i8> %28, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %30 = bitcast <16 x i8> %29 to <8 x i16>
  %31 = shl <8 x i16> %30, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %32 = bitcast i16* %24 to <8 x i16>*
  store <8 x i16> %31, <8 x i16>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %23, i64 %4
  %34 = getelementptr inbounds i16, i16* %2, i64 96
  %35 = bitcast i8* %33 to i64*
  %36 = load i64, i64* %35, align 1
  %37 = insertelement <2 x i64> undef, i64 %36, i32 0
  %38 = bitcast <2 x i64> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %40 = bitcast <16 x i8> %39 to <8 x i16>
  %41 = shl <8 x i16> %40, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %42 = bitcast i16* %34 to <8 x i16>*
  store <8 x i16> %41, <8 x i16>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %33, i64 %4
  %44 = getelementptr inbounds i16, i16* %2, i64 128
  %45 = bitcast i8* %43 to i64*
  %46 = load i64, i64* %45, align 1
  %47 = insertelement <2 x i64> undef, i64 %46, i32 0
  %48 = bitcast <2 x i64> %47 to <16 x i8>
  %49 = shufflevector <16 x i8> %48, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %50 = bitcast <16 x i8> %49 to <8 x i16>
  %51 = shl <8 x i16> %50, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %52 = bitcast i16* %44 to <8 x i16>*
  store <8 x i16> %51, <8 x i16>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %43, i64 %4
  %54 = getelementptr inbounds i16, i16* %2, i64 160
  %55 = bitcast i8* %53 to i64*
  %56 = load i64, i64* %55, align 1
  %57 = insertelement <2 x i64> undef, i64 %56, i32 0
  %58 = bitcast <2 x i64> %57 to <16 x i8>
  %59 = shufflevector <16 x i8> %58, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %60 = bitcast <16 x i8> %59 to <8 x i16>
  %61 = shl <8 x i16> %60, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %62 = bitcast i16* %54 to <8 x i16>*
  store <8 x i16> %61, <8 x i16>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %53, i64 %4
  %64 = getelementptr inbounds i16, i16* %2, i64 192
  %65 = bitcast i8* %63 to i64*
  %66 = load i64, i64* %65, align 1
  %67 = insertelement <2 x i64> undef, i64 %66, i32 0
  %68 = bitcast <2 x i64> %67 to <16 x i8>
  %69 = shufflevector <16 x i8> %68, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %70 = bitcast <16 x i8> %69 to <8 x i16>
  %71 = shl <8 x i16> %70, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %72 = bitcast i16* %64 to <8 x i16>*
  store <8 x i16> %71, <8 x i16>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %63, i64 %4
  %74 = getelementptr inbounds i16, i16* %2, i64 224
  %75 = bitcast i8* %73 to i64*
  %76 = load i64, i64* %75, align 1
  %77 = insertelement <2 x i64> undef, i64 %76, i32 0
  %78 = bitcast <2 x i64> %77 to <16 x i8>
  %79 = shufflevector <16 x i8> %78, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %80 = bitcast <16 x i8> %79 to <8 x i16>
  %81 = shl <8 x i16> %80, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %82 = bitcast i16* %74 to <8 x i16>*
  store <8 x i16> %81, <8 x i16>* %82, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_16x16_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 512
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %23, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %22, %8 ]
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = shufflevector <16 x i8> %12, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %14 = shufflevector <16 x i8> %12, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %15 = bitcast <16 x i8> %13 to <8 x i16>
  %16 = shl <8 x i16> %15, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %17 = bitcast <2 x i64>* %9 to <8 x i16>*
  store <8 x i16> %16, <8 x i16>* %17, align 1
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 1
  %19 = bitcast <16 x i8> %14 to <8 x i16>
  %20 = shl <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = bitcast <2 x i64>* %18 to <8 x i16>*
  store <8 x i16> %20, <8 x i16>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %10, i64 %7
  %23 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %24 = icmp ult <2 x i64>* %23, %6
  br i1 %24, label %8, label %25

25:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_32x32_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 1024
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %36, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %35, %8 ]
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = shufflevector <16 x i8> %12, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %14 = shufflevector <16 x i8> %12, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %15 = bitcast <16 x i8> %13 to <8 x i16>
  %16 = shl <8 x i16> %15, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %17 = bitcast <2 x i64>* %9 to <8 x i16>*
  store <8 x i16> %16, <8 x i16>* %17, align 1
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 1
  %19 = bitcast <16 x i8> %14 to <8 x i16>
  %20 = shl <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = bitcast <2 x i64>* %18 to <8 x i16>*
  store <8 x i16> %20, <8 x i16>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %10, i64 16
  %23 = bitcast i8* %22 to <16 x i8>*
  %24 = load <16 x i8>, <16 x i8>* %23, align 1
  %25 = shufflevector <16 x i8> %24, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %26 = shufflevector <16 x i8> %24, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %27 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 2
  %28 = bitcast <16 x i8> %25 to <8 x i16>
  %29 = shl <8 x i16> %28, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %30 = bitcast <2 x i64>* %27 to <8 x i16>*
  store <8 x i16> %29, <8 x i16>* %30, align 1
  %31 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 3
  %32 = bitcast <16 x i8> %26 to <8 x i16>
  %33 = shl <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = bitcast <2 x i64>* %31 to <8 x i16>*
  store <8 x i16> %33, <8 x i16>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %10, i64 %7
  %36 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %37 = icmp ult <2 x i64>* %36, %6
  br i1 %37, label %8, label %38

38:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_4x8_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to i32*
  %6 = load i32, i32* %5, align 4
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10 = bitcast <16 x i8> %9 to <8 x i16>
  %11 = shl <8 x i16> %10, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %12 = bitcast <8 x i16> %11 to <2 x i64>
  %13 = extractelement <2 x i64> %12, i32 0
  %14 = bitcast i16* %2 to i64*
  store i64 %13, i64* %14, align 1
  %15 = getelementptr inbounds i8, i8* %0, i64 %4
  %16 = getelementptr inbounds i16, i16* %2, i64 32
  %17 = bitcast i8* %15 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %18, i32 0
  %20 = bitcast <4 x i32> %19 to <16 x i8>
  %21 = shufflevector <16 x i8> %20, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %22 = bitcast <16 x i8> %21 to <8 x i16>
  %23 = shl <8 x i16> %22, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %24 = bitcast <8 x i16> %23 to <2 x i64>
  %25 = extractelement <2 x i64> %24, i32 0
  %26 = bitcast i16* %16 to i64*
  store i64 %25, i64* %26, align 1
  %27 = getelementptr inbounds i8, i8* %15, i64 %4
  %28 = getelementptr inbounds i16, i16* %2, i64 64
  %29 = bitcast i8* %27 to i32*
  %30 = load i32, i32* %29, align 4
  %31 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %30, i32 0
  %32 = bitcast <4 x i32> %31 to <16 x i8>
  %33 = shufflevector <16 x i8> %32, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %34 = bitcast <16 x i8> %33 to <8 x i16>
  %35 = shl <8 x i16> %34, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %36 = bitcast <8 x i16> %35 to <2 x i64>
  %37 = extractelement <2 x i64> %36, i32 0
  %38 = bitcast i16* %28 to i64*
  store i64 %37, i64* %38, align 1
  %39 = getelementptr inbounds i8, i8* %27, i64 %4
  %40 = getelementptr inbounds i16, i16* %2, i64 96
  %41 = bitcast i8* %39 to i32*
  %42 = load i32, i32* %41, align 4
  %43 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %42, i32 0
  %44 = bitcast <4 x i32> %43 to <16 x i8>
  %45 = shufflevector <16 x i8> %44, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %46 = bitcast <16 x i8> %45 to <8 x i16>
  %47 = shl <8 x i16> %46, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %48 = bitcast <8 x i16> %47 to <2 x i64>
  %49 = extractelement <2 x i64> %48, i32 0
  %50 = bitcast i16* %40 to i64*
  store i64 %49, i64* %50, align 1
  %51 = getelementptr inbounds i8, i8* %39, i64 %4
  %52 = getelementptr inbounds i16, i16* %2, i64 128
  %53 = bitcast i8* %51 to i32*
  %54 = load i32, i32* %53, align 4
  %55 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %54, i32 0
  %56 = bitcast <4 x i32> %55 to <16 x i8>
  %57 = shufflevector <16 x i8> %56, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %58 = bitcast <16 x i8> %57 to <8 x i16>
  %59 = shl <8 x i16> %58, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %60 = bitcast <8 x i16> %59 to <2 x i64>
  %61 = extractelement <2 x i64> %60, i32 0
  %62 = bitcast i16* %52 to i64*
  store i64 %61, i64* %62, align 1
  %63 = getelementptr inbounds i8, i8* %51, i64 %4
  %64 = getelementptr inbounds i16, i16* %2, i64 160
  %65 = bitcast i8* %63 to i32*
  %66 = load i32, i32* %65, align 4
  %67 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %66, i32 0
  %68 = bitcast <4 x i32> %67 to <16 x i8>
  %69 = shufflevector <16 x i8> %68, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %70 = bitcast <16 x i8> %69 to <8 x i16>
  %71 = shl <8 x i16> %70, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %72 = bitcast <8 x i16> %71 to <2 x i64>
  %73 = extractelement <2 x i64> %72, i32 0
  %74 = bitcast i16* %64 to i64*
  store i64 %73, i64* %74, align 1
  %75 = getelementptr inbounds i8, i8* %63, i64 %4
  %76 = getelementptr inbounds i16, i16* %2, i64 192
  %77 = bitcast i8* %75 to i32*
  %78 = load i32, i32* %77, align 4
  %79 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %78, i32 0
  %80 = bitcast <4 x i32> %79 to <16 x i8>
  %81 = shufflevector <16 x i8> %80, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %82 = bitcast <16 x i8> %81 to <8 x i16>
  %83 = shl <8 x i16> %82, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %84 = bitcast <8 x i16> %83 to <2 x i64>
  %85 = extractelement <2 x i64> %84, i32 0
  %86 = bitcast i16* %76 to i64*
  store i64 %85, i64* %86, align 1
  %87 = getelementptr inbounds i8, i8* %75, i64 %4
  %88 = getelementptr inbounds i16, i16* %2, i64 224
  %89 = bitcast i8* %87 to i32*
  %90 = load i32, i32* %89, align 4
  %91 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %90, i32 0
  %92 = bitcast <4 x i32> %91 to <16 x i8>
  %93 = shufflevector <16 x i8> %92, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %94 = bitcast <16 x i8> %93 to <8 x i16>
  %95 = shl <8 x i16> %94, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %96 = bitcast <8 x i16> %95 to <2 x i64>
  %97 = extractelement <2 x i64> %96, i32 0
  %98 = bitcast i16* %88 to i64*
  store i64 %97, i64* %98, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_8x4_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> undef, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %10 = bitcast <16 x i8> %9 to <8 x i16>
  %11 = shl <8 x i16> %10, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %12 = bitcast i16* %2 to <8 x i16>*
  store <8 x i16> %11, <8 x i16>* %12, align 1
  %13 = getelementptr inbounds i8, i8* %0, i64 %4
  %14 = getelementptr inbounds i16, i16* %2, i64 32
  %15 = bitcast i8* %13 to i64*
  %16 = load i64, i64* %15, align 1
  %17 = insertelement <2 x i64> undef, i64 %16, i32 0
  %18 = bitcast <2 x i64> %17 to <16 x i8>
  %19 = shufflevector <16 x i8> %18, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %20 = bitcast <16 x i8> %19 to <8 x i16>
  %21 = shl <8 x i16> %20, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %22 = bitcast i16* %14 to <8 x i16>*
  store <8 x i16> %21, <8 x i16>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %13, i64 %4
  %24 = getelementptr inbounds i16, i16* %2, i64 64
  %25 = bitcast i8* %23 to i64*
  %26 = load i64, i64* %25, align 1
  %27 = insertelement <2 x i64> undef, i64 %26, i32 0
  %28 = bitcast <2 x i64> %27 to <16 x i8>
  %29 = shufflevector <16 x i8> %28, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %30 = bitcast <16 x i8> %29 to <8 x i16>
  %31 = shl <8 x i16> %30, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %32 = bitcast i16* %24 to <8 x i16>*
  store <8 x i16> %31, <8 x i16>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %23, i64 %4
  %34 = getelementptr inbounds i16, i16* %2, i64 96
  %35 = bitcast i8* %33 to i64*
  %36 = load i64, i64* %35, align 1
  %37 = insertelement <2 x i64> undef, i64 %36, i32 0
  %38 = bitcast <2 x i64> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %40 = bitcast <16 x i8> %39 to <8 x i16>
  %41 = shl <8 x i16> %40, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %42 = bitcast i16* %34 to <8 x i16>*
  store <8 x i16> %41, <8 x i16>* %42, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_8x16_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 512
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %20, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %19, %8 ]
  %11 = bitcast i8* %10 to i64*
  %12 = load i64, i64* %11, align 1
  %13 = insertelement <2 x i64> undef, i64 %12, i32 0
  %14 = bitcast <2 x i64> %13 to <16 x i8>
  %15 = shufflevector <16 x i8> %14, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %16 = bitcast <16 x i8> %15 to <8 x i16>
  %17 = shl <8 x i16> %16, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %18 = bitcast <2 x i64>* %9 to <8 x i16>*
  store <8 x i16> %17, <8 x i16>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %10, i64 %7
  %20 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %21 = icmp ult <2 x i64>* %20, %6
  br i1 %21, label %8, label %22

22:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_16x8_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8 = shufflevector <16 x i8> %6, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %9 = bitcast <16 x i8> %7 to <8 x i16>
  %10 = shl <8 x i16> %9, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %11 = bitcast i16* %2 to <8 x i16>*
  store <8 x i16> %10, <8 x i16>* %11, align 1
  %12 = getelementptr inbounds i16, i16* %2, i64 8
  %13 = bitcast <16 x i8> %8 to <8 x i16>
  %14 = shl <8 x i16> %13, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %15 = bitcast i16* %12 to <8 x i16>*
  store <8 x i16> %14, <8 x i16>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 %4
  %17 = getelementptr inbounds i16, i16* %2, i64 32
  %18 = bitcast i8* %16 to <16 x i8>*
  %19 = load <16 x i8>, <16 x i8>* %18, align 1
  %20 = shufflevector <16 x i8> %19, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %21 = shufflevector <16 x i8> %19, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %22 = bitcast <16 x i8> %20 to <8 x i16>
  %23 = shl <8 x i16> %22, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %24 = bitcast i16* %17 to <8 x i16>*
  store <8 x i16> %23, <8 x i16>* %24, align 1
  %25 = getelementptr inbounds i16, i16* %2, i64 40
  %26 = bitcast <16 x i8> %21 to <8 x i16>
  %27 = shl <8 x i16> %26, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %28 = bitcast i16* %25 to <8 x i16>*
  store <8 x i16> %27, <8 x i16>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %16, i64 %4
  %30 = getelementptr inbounds i16, i16* %2, i64 64
  %31 = bitcast i8* %29 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = shufflevector <16 x i8> %32, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %34 = shufflevector <16 x i8> %32, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %35 = bitcast <16 x i8> %33 to <8 x i16>
  %36 = shl <8 x i16> %35, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %37 = bitcast i16* %30 to <8 x i16>*
  store <8 x i16> %36, <8 x i16>* %37, align 1
  %38 = getelementptr inbounds i16, i16* %2, i64 72
  %39 = bitcast <16 x i8> %34 to <8 x i16>
  %40 = shl <8 x i16> %39, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %41 = bitcast i16* %38 to <8 x i16>*
  store <8 x i16> %40, <8 x i16>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %29, i64 %4
  %43 = getelementptr inbounds i16, i16* %2, i64 96
  %44 = bitcast i8* %42 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 1
  %46 = shufflevector <16 x i8> %45, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %47 = shufflevector <16 x i8> %45, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %48 = bitcast <16 x i8> %46 to <8 x i16>
  %49 = shl <8 x i16> %48, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %50 = bitcast i16* %43 to <8 x i16>*
  store <8 x i16> %49, <8 x i16>* %50, align 1
  %51 = getelementptr inbounds i16, i16* %2, i64 104
  %52 = bitcast <16 x i8> %47 to <8 x i16>
  %53 = shl <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = bitcast i16* %51 to <8 x i16>*
  store <8 x i16> %53, <8 x i16>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %42, i64 %4
  %56 = getelementptr inbounds i16, i16* %2, i64 128
  %57 = bitcast i8* %55 to <16 x i8>*
  %58 = load <16 x i8>, <16 x i8>* %57, align 1
  %59 = shufflevector <16 x i8> %58, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %60 = shufflevector <16 x i8> %58, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %61 = bitcast <16 x i8> %59 to <8 x i16>
  %62 = shl <8 x i16> %61, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %63 = bitcast i16* %56 to <8 x i16>*
  store <8 x i16> %62, <8 x i16>* %63, align 1
  %64 = getelementptr inbounds i16, i16* %2, i64 136
  %65 = bitcast <16 x i8> %60 to <8 x i16>
  %66 = shl <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = bitcast i16* %64 to <8 x i16>*
  store <8 x i16> %66, <8 x i16>* %67, align 1
  %68 = getelementptr inbounds i8, i8* %55, i64 %4
  %69 = getelementptr inbounds i16, i16* %2, i64 160
  %70 = bitcast i8* %68 to <16 x i8>*
  %71 = load <16 x i8>, <16 x i8>* %70, align 1
  %72 = shufflevector <16 x i8> %71, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %73 = shufflevector <16 x i8> %71, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %74 = bitcast <16 x i8> %72 to <8 x i16>
  %75 = shl <8 x i16> %74, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %76 = bitcast i16* %69 to <8 x i16>*
  store <8 x i16> %75, <8 x i16>* %76, align 1
  %77 = getelementptr inbounds i16, i16* %2, i64 168
  %78 = bitcast <16 x i8> %73 to <8 x i16>
  %79 = shl <8 x i16> %78, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %80 = bitcast i16* %77 to <8 x i16>*
  store <8 x i16> %79, <8 x i16>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %68, i64 %4
  %82 = getelementptr inbounds i16, i16* %2, i64 192
  %83 = bitcast i8* %81 to <16 x i8>*
  %84 = load <16 x i8>, <16 x i8>* %83, align 1
  %85 = shufflevector <16 x i8> %84, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %86 = shufflevector <16 x i8> %84, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %87 = bitcast <16 x i8> %85 to <8 x i16>
  %88 = shl <8 x i16> %87, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %89 = bitcast i16* %82 to <8 x i16>*
  store <8 x i16> %88, <8 x i16>* %89, align 1
  %90 = getelementptr inbounds i16, i16* %2, i64 200
  %91 = bitcast <16 x i8> %86 to <8 x i16>
  %92 = shl <8 x i16> %91, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %93 = bitcast i16* %90 to <8 x i16>*
  store <8 x i16> %92, <8 x i16>* %93, align 1
  %94 = getelementptr inbounds i8, i8* %81, i64 %4
  %95 = getelementptr inbounds i16, i16* %2, i64 224
  %96 = bitcast i8* %94 to <16 x i8>*
  %97 = load <16 x i8>, <16 x i8>* %96, align 1
  %98 = shufflevector <16 x i8> %97, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %99 = shufflevector <16 x i8> %97, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %100 = bitcast <16 x i8> %98 to <8 x i16>
  %101 = shl <8 x i16> %100, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %102 = bitcast i16* %95 to <8 x i16>*
  store <8 x i16> %101, <8 x i16>* %102, align 1
  %103 = getelementptr inbounds i16, i16* %2, i64 232
  %104 = bitcast <16 x i8> %99 to <8 x i16>
  %105 = shl <8 x i16> %104, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %106 = bitcast i16* %103 to <8 x i16>*
  store <8 x i16> %105, <8 x i16>* %106, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_16x32_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 1024
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %23, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %22, %8 ]
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = shufflevector <16 x i8> %12, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %14 = shufflevector <16 x i8> %12, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %15 = bitcast <16 x i8> %13 to <8 x i16>
  %16 = shl <8 x i16> %15, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %17 = bitcast <2 x i64>* %9 to <8 x i16>*
  store <8 x i16> %16, <8 x i16>* %17, align 1
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 1
  %19 = bitcast <16 x i8> %14 to <8 x i16>
  %20 = shl <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = bitcast <2 x i64>* %18 to <8 x i16>*
  store <8 x i16> %20, <8 x i16>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %10, i64 %7
  %23 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %24 = icmp ult <2 x i64>* %23, %6
  br i1 %24, label %8, label %25

25:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_32x16_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 512
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %36, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %35, %8 ]
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = shufflevector <16 x i8> %12, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %14 = shufflevector <16 x i8> %12, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %15 = bitcast <16 x i8> %13 to <8 x i16>
  %16 = shl <8 x i16> %15, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %17 = bitcast <2 x i64>* %9 to <8 x i16>*
  store <8 x i16> %16, <8 x i16>* %17, align 1
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 1
  %19 = bitcast <16 x i8> %14 to <8 x i16>
  %20 = shl <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = bitcast <2 x i64>* %18 to <8 x i16>*
  store <8 x i16> %20, <8 x i16>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %10, i64 16
  %23 = bitcast i8* %22 to <16 x i8>*
  %24 = load <16 x i8>, <16 x i8>* %23, align 1
  %25 = shufflevector <16 x i8> %24, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %26 = shufflevector <16 x i8> %24, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %27 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 2
  %28 = bitcast <16 x i8> %25 to <8 x i16>
  %29 = shl <8 x i16> %28, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %30 = bitcast <2 x i64>* %27 to <8 x i16>*
  store <8 x i16> %29, <8 x i16>* %30, align 1
  %31 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 3
  %32 = bitcast <16 x i8> %26 to <8 x i16>
  %33 = shl <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = bitcast <2 x i64>* %31 to <8 x i16>*
  store <8 x i16> %33, <8 x i16>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %10, i64 %7
  %36 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %37 = icmp ult <2 x i64>* %36, %6
  br i1 %37, label %8, label %38

38:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_4x16_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 512
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %22, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %21, %8 ]
  %11 = bitcast i8* %10 to i32*
  %12 = load i32, i32* %11, align 4
  %13 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %12, i32 0
  %14 = bitcast <4 x i32> %13 to <16 x i8>
  %15 = shufflevector <16 x i8> %14, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %16 = bitcast <16 x i8> %15 to <8 x i16>
  %17 = shl <8 x i16> %16, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %18 = bitcast <8 x i16> %17 to <2 x i64>
  %19 = extractelement <2 x i64> %18, i32 0
  %20 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 0, i64 0
  store i64 %19, i64* %20, align 1
  %21 = getelementptr inbounds i8, i8* %10, i64 %7
  %22 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %23 = icmp ult <2 x i64>* %22, %6
  br i1 %23, label %8, label %24

24:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_16x4_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8 = shufflevector <16 x i8> %6, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %9 = bitcast <16 x i8> %7 to <8 x i16>
  %10 = shl <8 x i16> %9, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %11 = bitcast i16* %2 to <8 x i16>*
  store <8 x i16> %10, <8 x i16>* %11, align 1
  %12 = getelementptr inbounds i16, i16* %2, i64 8
  %13 = bitcast <16 x i8> %8 to <8 x i16>
  %14 = shl <8 x i16> %13, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %15 = bitcast i16* %12 to <8 x i16>*
  store <8 x i16> %14, <8 x i16>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 %4
  %17 = getelementptr inbounds i16, i16* %2, i64 32
  %18 = bitcast i8* %16 to <16 x i8>*
  %19 = load <16 x i8>, <16 x i8>* %18, align 1
  %20 = shufflevector <16 x i8> %19, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %21 = shufflevector <16 x i8> %19, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %22 = bitcast <16 x i8> %20 to <8 x i16>
  %23 = shl <8 x i16> %22, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %24 = bitcast i16* %17 to <8 x i16>*
  store <8 x i16> %23, <8 x i16>* %24, align 1
  %25 = getelementptr inbounds i16, i16* %2, i64 40
  %26 = bitcast <16 x i8> %21 to <8 x i16>
  %27 = shl <8 x i16> %26, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %28 = bitcast i16* %25 to <8 x i16>*
  store <8 x i16> %27, <8 x i16>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %16, i64 %4
  %30 = getelementptr inbounds i16, i16* %2, i64 64
  %31 = bitcast i8* %29 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = shufflevector <16 x i8> %32, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %34 = shufflevector <16 x i8> %32, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %35 = bitcast <16 x i8> %33 to <8 x i16>
  %36 = shl <8 x i16> %35, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %37 = bitcast i16* %30 to <8 x i16>*
  store <8 x i16> %36, <8 x i16>* %37, align 1
  %38 = getelementptr inbounds i16, i16* %2, i64 72
  %39 = bitcast <16 x i8> %34 to <8 x i16>
  %40 = shl <8 x i16> %39, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %41 = bitcast i16* %38 to <8 x i16>*
  store <8 x i16> %40, <8 x i16>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %29, i64 %4
  %43 = getelementptr inbounds i16, i16* %2, i64 96
  %44 = bitcast i8* %42 to <16 x i8>*
  %45 = load <16 x i8>, <16 x i8>* %44, align 1
  %46 = shufflevector <16 x i8> %45, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %47 = shufflevector <16 x i8> %45, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %48 = bitcast <16 x i8> %46 to <8 x i16>
  %49 = shl <8 x i16> %48, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %50 = bitcast i16* %43 to <8 x i16>*
  store <8 x i16> %49, <8 x i16>* %50, align 1
  %51 = getelementptr inbounds i16, i16* %2, i64 104
  %52 = bitcast <16 x i8> %47 to <8 x i16>
  %53 = shl <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = bitcast i16* %51 to <8 x i16>*
  store <8 x i16> %53, <8 x i16>* %54, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_8x32_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = bitcast i16* %2 to <2 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 1024
  %6 = bitcast i16* %5 to <2 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <2 x i64>* [ %4, %3 ], [ %20, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %19, %8 ]
  %11 = bitcast i8* %10 to i64*
  %12 = load i64, i64* %11, align 1
  %13 = insertelement <2 x i64> undef, i64 %12, i32 0
  %14 = bitcast <2 x i64> %13 to <16 x i8>
  %15 = shufflevector <16 x i8> %14, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %16 = bitcast <16 x i8> %15 to <8 x i16>
  %17 = shl <8 x i16> %16, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %18 = bitcast <2 x i64>* %9 to <8 x i16>*
  store <8 x i16> %17, <8 x i16>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %10, i64 %7
  %20 = getelementptr inbounds <2 x i64>, <2 x i64>* %9, i64 4
  %21 = icmp ult <2 x i64>* %20, %6
  br i1 %21, label %8, label %22

22:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_32x8_ssse3(i8* nocapture readonly, i32, i16*) #2 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8 = shufflevector <16 x i8> %6, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %9 = bitcast <16 x i8> %7 to <8 x i16>
  %10 = shl <8 x i16> %9, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %11 = bitcast i16* %2 to <8 x i16>*
  store <8 x i16> %10, <8 x i16>* %11, align 1
  %12 = getelementptr inbounds i16, i16* %2, i64 8
  %13 = bitcast <16 x i8> %8 to <8 x i16>
  %14 = shl <8 x i16> %13, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %15 = bitcast i16* %12 to <8 x i16>*
  store <8 x i16> %14, <8 x i16>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 16
  %17 = bitcast i8* %16 to <16 x i8>*
  %18 = load <16 x i8>, <16 x i8>* %17, align 1
  %19 = shufflevector <16 x i8> %18, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %20 = shufflevector <16 x i8> %18, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %21 = getelementptr inbounds i16, i16* %2, i64 16
  %22 = bitcast <16 x i8> %19 to <8 x i16>
  %23 = shl <8 x i16> %22, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %24 = bitcast i16* %21 to <8 x i16>*
  store <8 x i16> %23, <8 x i16>* %24, align 1
  %25 = getelementptr inbounds i16, i16* %2, i64 24
  %26 = bitcast <16 x i8> %20 to <8 x i16>
  %27 = shl <8 x i16> %26, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %28 = bitcast i16* %25 to <8 x i16>*
  store <8 x i16> %27, <8 x i16>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %0, i64 %4
  %30 = getelementptr inbounds i16, i16* %2, i64 32
  %31 = bitcast i8* %29 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = shufflevector <16 x i8> %32, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %34 = shufflevector <16 x i8> %32, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %35 = bitcast <16 x i8> %33 to <8 x i16>
  %36 = shl <8 x i16> %35, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %37 = bitcast i16* %30 to <8 x i16>*
  store <8 x i16> %36, <8 x i16>* %37, align 1
  %38 = getelementptr inbounds i16, i16* %2, i64 40
  %39 = bitcast <16 x i8> %34 to <8 x i16>
  %40 = shl <8 x i16> %39, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %41 = bitcast i16* %38 to <8 x i16>*
  store <8 x i16> %40, <8 x i16>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %29, i64 16
  %43 = bitcast i8* %42 to <16 x i8>*
  %44 = load <16 x i8>, <16 x i8>* %43, align 1
  %45 = shufflevector <16 x i8> %44, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %46 = shufflevector <16 x i8> %44, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %47 = getelementptr inbounds i16, i16* %2, i64 48
  %48 = bitcast <16 x i8> %45 to <8 x i16>
  %49 = shl <8 x i16> %48, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %50 = bitcast i16* %47 to <8 x i16>*
  store <8 x i16> %49, <8 x i16>* %50, align 1
  %51 = getelementptr inbounds i16, i16* %2, i64 56
  %52 = bitcast <16 x i8> %46 to <8 x i16>
  %53 = shl <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = bitcast i16* %51 to <8 x i16>*
  store <8 x i16> %53, <8 x i16>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %29, i64 %4
  %56 = getelementptr inbounds i16, i16* %2, i64 64
  %57 = bitcast i8* %55 to <16 x i8>*
  %58 = load <16 x i8>, <16 x i8>* %57, align 1
  %59 = shufflevector <16 x i8> %58, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %60 = shufflevector <16 x i8> %58, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %61 = bitcast <16 x i8> %59 to <8 x i16>
  %62 = shl <8 x i16> %61, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %63 = bitcast i16* %56 to <8 x i16>*
  store <8 x i16> %62, <8 x i16>* %63, align 1
  %64 = getelementptr inbounds i16, i16* %2, i64 72
  %65 = bitcast <16 x i8> %60 to <8 x i16>
  %66 = shl <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = bitcast i16* %64 to <8 x i16>*
  store <8 x i16> %66, <8 x i16>* %67, align 1
  %68 = getelementptr inbounds i8, i8* %55, i64 16
  %69 = bitcast i8* %68 to <16 x i8>*
  %70 = load <16 x i8>, <16 x i8>* %69, align 1
  %71 = shufflevector <16 x i8> %70, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %72 = shufflevector <16 x i8> %70, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %73 = getelementptr inbounds i16, i16* %2, i64 80
  %74 = bitcast <16 x i8> %71 to <8 x i16>
  %75 = shl <8 x i16> %74, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %76 = bitcast i16* %73 to <8 x i16>*
  store <8 x i16> %75, <8 x i16>* %76, align 1
  %77 = getelementptr inbounds i16, i16* %2, i64 88
  %78 = bitcast <16 x i8> %72 to <8 x i16>
  %79 = shl <8 x i16> %78, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %80 = bitcast i16* %77 to <8 x i16>*
  store <8 x i16> %79, <8 x i16>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %55, i64 %4
  %82 = getelementptr inbounds i16, i16* %2, i64 96
  %83 = bitcast i8* %81 to <16 x i8>*
  %84 = load <16 x i8>, <16 x i8>* %83, align 1
  %85 = shufflevector <16 x i8> %84, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %86 = shufflevector <16 x i8> %84, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %87 = bitcast <16 x i8> %85 to <8 x i16>
  %88 = shl <8 x i16> %87, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %89 = bitcast i16* %82 to <8 x i16>*
  store <8 x i16> %88, <8 x i16>* %89, align 1
  %90 = getelementptr inbounds i16, i16* %2, i64 104
  %91 = bitcast <16 x i8> %86 to <8 x i16>
  %92 = shl <8 x i16> %91, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %93 = bitcast i16* %90 to <8 x i16>*
  store <8 x i16> %92, <8 x i16>* %93, align 1
  %94 = getelementptr inbounds i8, i8* %81, i64 16
  %95 = bitcast i8* %94 to <16 x i8>*
  %96 = load <16 x i8>, <16 x i8>* %95, align 1
  %97 = shufflevector <16 x i8> %96, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %98 = shufflevector <16 x i8> %96, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %99 = getelementptr inbounds i16, i16* %2, i64 112
  %100 = bitcast <16 x i8> %97 to <8 x i16>
  %101 = shl <8 x i16> %100, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %102 = bitcast i16* %99 to <8 x i16>*
  store <8 x i16> %101, <8 x i16>* %102, align 1
  %103 = getelementptr inbounds i16, i16* %2, i64 120
  %104 = bitcast <16 x i8> %98 to <8 x i16>
  %105 = shl <8 x i16> %104, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %106 = bitcast i16* %103 to <8 x i16>*
  store <8 x i16> %105, <8 x i16>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %81, i64 %4
  %108 = getelementptr inbounds i16, i16* %2, i64 128
  %109 = bitcast i8* %107 to <16 x i8>*
  %110 = load <16 x i8>, <16 x i8>* %109, align 1
  %111 = shufflevector <16 x i8> %110, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %112 = shufflevector <16 x i8> %110, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %113 = bitcast <16 x i8> %111 to <8 x i16>
  %114 = shl <8 x i16> %113, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %115 = bitcast i16* %108 to <8 x i16>*
  store <8 x i16> %114, <8 x i16>* %115, align 1
  %116 = getelementptr inbounds i16, i16* %2, i64 136
  %117 = bitcast <16 x i8> %112 to <8 x i16>
  %118 = shl <8 x i16> %117, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %119 = bitcast i16* %116 to <8 x i16>*
  store <8 x i16> %118, <8 x i16>* %119, align 1
  %120 = getelementptr inbounds i8, i8* %107, i64 16
  %121 = bitcast i8* %120 to <16 x i8>*
  %122 = load <16 x i8>, <16 x i8>* %121, align 1
  %123 = shufflevector <16 x i8> %122, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %124 = shufflevector <16 x i8> %122, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %125 = getelementptr inbounds i16, i16* %2, i64 144
  %126 = bitcast <16 x i8> %123 to <8 x i16>
  %127 = shl <8 x i16> %126, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %128 = bitcast i16* %125 to <8 x i16>*
  store <8 x i16> %127, <8 x i16>* %128, align 1
  %129 = getelementptr inbounds i16, i16* %2, i64 152
  %130 = bitcast <16 x i8> %124 to <8 x i16>
  %131 = shl <8 x i16> %130, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %132 = bitcast i16* %129 to <8 x i16>*
  store <8 x i16> %131, <8 x i16>* %132, align 1
  %133 = getelementptr inbounds i8, i8* %107, i64 %4
  %134 = getelementptr inbounds i16, i16* %2, i64 160
  %135 = bitcast i8* %133 to <16 x i8>*
  %136 = load <16 x i8>, <16 x i8>* %135, align 1
  %137 = shufflevector <16 x i8> %136, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %138 = shufflevector <16 x i8> %136, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %139 = bitcast <16 x i8> %137 to <8 x i16>
  %140 = shl <8 x i16> %139, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %141 = bitcast i16* %134 to <8 x i16>*
  store <8 x i16> %140, <8 x i16>* %141, align 1
  %142 = getelementptr inbounds i16, i16* %2, i64 168
  %143 = bitcast <16 x i8> %138 to <8 x i16>
  %144 = shl <8 x i16> %143, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %145 = bitcast i16* %142 to <8 x i16>*
  store <8 x i16> %144, <8 x i16>* %145, align 1
  %146 = getelementptr inbounds i8, i8* %133, i64 16
  %147 = bitcast i8* %146 to <16 x i8>*
  %148 = load <16 x i8>, <16 x i8>* %147, align 1
  %149 = shufflevector <16 x i8> %148, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %150 = shufflevector <16 x i8> %148, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %151 = getelementptr inbounds i16, i16* %2, i64 176
  %152 = bitcast <16 x i8> %149 to <8 x i16>
  %153 = shl <8 x i16> %152, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %154 = bitcast i16* %151 to <8 x i16>*
  store <8 x i16> %153, <8 x i16>* %154, align 1
  %155 = getelementptr inbounds i16, i16* %2, i64 184
  %156 = bitcast <16 x i8> %150 to <8 x i16>
  %157 = shl <8 x i16> %156, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %158 = bitcast i16* %155 to <8 x i16>*
  store <8 x i16> %157, <8 x i16>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %133, i64 %4
  %160 = getelementptr inbounds i16, i16* %2, i64 192
  %161 = bitcast i8* %159 to <16 x i8>*
  %162 = load <16 x i8>, <16 x i8>* %161, align 1
  %163 = shufflevector <16 x i8> %162, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %164 = shufflevector <16 x i8> %162, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %165 = bitcast <16 x i8> %163 to <8 x i16>
  %166 = shl <8 x i16> %165, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %167 = bitcast i16* %160 to <8 x i16>*
  store <8 x i16> %166, <8 x i16>* %167, align 1
  %168 = getelementptr inbounds i16, i16* %2, i64 200
  %169 = bitcast <16 x i8> %164 to <8 x i16>
  %170 = shl <8 x i16> %169, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %171 = bitcast i16* %168 to <8 x i16>*
  store <8 x i16> %170, <8 x i16>* %171, align 1
  %172 = getelementptr inbounds i8, i8* %159, i64 16
  %173 = bitcast i8* %172 to <16 x i8>*
  %174 = load <16 x i8>, <16 x i8>* %173, align 1
  %175 = shufflevector <16 x i8> %174, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %176 = shufflevector <16 x i8> %174, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %177 = getelementptr inbounds i16, i16* %2, i64 208
  %178 = bitcast <16 x i8> %175 to <8 x i16>
  %179 = shl <8 x i16> %178, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %180 = bitcast i16* %177 to <8 x i16>*
  store <8 x i16> %179, <8 x i16>* %180, align 1
  %181 = getelementptr inbounds i16, i16* %2, i64 216
  %182 = bitcast <16 x i8> %176 to <8 x i16>
  %183 = shl <8 x i16> %182, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %184 = bitcast i16* %181 to <8 x i16>*
  store <8 x i16> %183, <8 x i16>* %184, align 1
  %185 = getelementptr inbounds i8, i8* %159, i64 %4
  %186 = getelementptr inbounds i16, i16* %2, i64 224
  %187 = bitcast i8* %185 to <16 x i8>*
  %188 = load <16 x i8>, <16 x i8>* %187, align 1
  %189 = shufflevector <16 x i8> %188, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %190 = shufflevector <16 x i8> %188, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %191 = bitcast <16 x i8> %189 to <8 x i16>
  %192 = shl <8 x i16> %191, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %193 = bitcast i16* %186 to <8 x i16>*
  store <8 x i16> %192, <8 x i16>* %193, align 1
  %194 = getelementptr inbounds i16, i16* %2, i64 232
  %195 = bitcast <16 x i8> %190 to <8 x i16>
  %196 = shl <8 x i16> %195, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %197 = bitcast i16* %194 to <8 x i16>*
  store <8 x i16> %196, <8 x i16>* %197, align 1
  %198 = getelementptr inbounds i8, i8* %185, i64 16
  %199 = bitcast i8* %198 to <16 x i8>*
  %200 = load <16 x i8>, <16 x i8>* %199, align 1
  %201 = shufflevector <16 x i8> %200, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %202 = shufflevector <16 x i8> %200, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %203 = getelementptr inbounds i16, i16* %2, i64 240
  %204 = bitcast <16 x i8> %201 to <8 x i16>
  %205 = shl <8 x i16> %204, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %206 = bitcast i16* %203 to <8 x i16>*
  store <8 x i16> %205, <8 x i16>* %206, align 1
  %207 = getelementptr inbounds i16, i16* %2, i64 248
  %208 = bitcast <16 x i8> %202 to <8 x i16>
  %209 = shl <8 x i16> %208, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %210 = bitcast i16* %207 to <8 x i16>*
  store <8 x i16> %209, <8 x i16>* %210, align 1
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void (i8*, i32, i16*)* @cfl_get_luma_subsampling_444_lbd_ssse3(i8 zeroext) local_unnamed_addr #1 {
  %2 = zext i8 %0 to i64
  %3 = getelementptr inbounds [19 x void (i8*, i32, i16*)*], [19 x void (i8*, i32, i16*)*]* @cfl_get_luma_subsampling_444_lbd_ssse3.subfn_444, i64 0, i64 %2
  %4 = load void (i8*, i32, i16*)*, void (i8*, i32, i16*)** %3, align 8
  ret void (i8*, i32, i16*)* %4
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_4x4_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %16 = sext i32 %2 to i64
  %17 = bitcast i16* %0 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 1
  %19 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %18) #4
  %20 = sub <8 x i16> zeroinitializer, %18
  %21 = icmp slt <8 x i16> %18, zeroinitializer
  %22 = select <8 x i1> %21, <8 x i16> %20, <8 x i16> %18
  %23 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %22, <8 x i16> %11) #4
  %24 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %23, <8 x i16> %19) #4
  %25 = add <8 x i16> %24, %15
  %26 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %25, <8 x i16> undef) #4
  %27 = bitcast <16 x i8> %26 to <4 x i32>
  %28 = extractelement <4 x i32> %27, i32 0
  %29 = bitcast i8* %1 to i32*
  store i32 %28, i32* %29, align 4
  %30 = getelementptr inbounds i8, i8* %1, i64 %16
  %31 = getelementptr inbounds i16, i16* %0, i64 32
  %32 = bitcast i16* %31 to <8 x i16>*
  %33 = load <8 x i16>, <8 x i16>* %32, align 1
  %34 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %33) #4
  %35 = sub <8 x i16> zeroinitializer, %33
  %36 = icmp slt <8 x i16> %33, zeroinitializer
  %37 = select <8 x i1> %36, <8 x i16> %35, <8 x i16> %33
  %38 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %37, <8 x i16> %11) #4
  %39 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %38, <8 x i16> %34) #4
  %40 = add <8 x i16> %39, %15
  %41 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %40, <8 x i16> undef) #4
  %42 = bitcast <16 x i8> %41 to <4 x i32>
  %43 = extractelement <4 x i32> %42, i32 0
  %44 = bitcast i8* %30 to i32*
  store i32 %43, i32* %44, align 4
  %45 = getelementptr inbounds i8, i8* %30, i64 %16
  %46 = getelementptr inbounds i16, i16* %0, i64 64
  %47 = bitcast i16* %46 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 1
  %49 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %48) #4
  %50 = sub <8 x i16> zeroinitializer, %48
  %51 = icmp slt <8 x i16> %48, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %48
  %53 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %52, <8 x i16> %11) #4
  %54 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %53, <8 x i16> %49) #4
  %55 = add <8 x i16> %54, %15
  %56 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> undef) #4
  %57 = bitcast <16 x i8> %56 to <4 x i32>
  %58 = extractelement <4 x i32> %57, i32 0
  %59 = bitcast i8* %45 to i32*
  store i32 %58, i32* %59, align 4
  %60 = getelementptr inbounds i8, i8* %45, i64 %16
  %61 = getelementptr inbounds i16, i16* %0, i64 96
  %62 = bitcast i16* %61 to <8 x i16>*
  %63 = load <8 x i16>, <8 x i16>* %62, align 1
  %64 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %63) #4
  %65 = sub <8 x i16> zeroinitializer, %63
  %66 = icmp slt <8 x i16> %63, zeroinitializer
  %67 = select <8 x i1> %66, <8 x i16> %65, <8 x i16> %63
  %68 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %67, <8 x i16> %11) #4
  %69 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %68, <8 x i16> %64) #4
  %70 = add <8 x i16> %69, %15
  %71 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> undef) #4
  %72 = bitcast <16 x i8> %71 to <4 x i32>
  %73 = extractelement <4 x i32> %72, i32 0
  %74 = bitcast i8* %60 to i32*
  store i32 %73, i32* %74, align 4
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_4x8_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %16 = sext i32 %2 to i64
  %17 = bitcast i16* %0 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 1
  %19 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %18) #4
  %20 = sub <8 x i16> zeroinitializer, %18
  %21 = icmp slt <8 x i16> %18, zeroinitializer
  %22 = select <8 x i1> %21, <8 x i16> %20, <8 x i16> %18
  %23 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %22, <8 x i16> %11) #4
  %24 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %23, <8 x i16> %19) #4
  %25 = add <8 x i16> %24, %15
  %26 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %25, <8 x i16> undef) #4
  %27 = bitcast <16 x i8> %26 to <4 x i32>
  %28 = extractelement <4 x i32> %27, i32 0
  %29 = bitcast i8* %1 to i32*
  store i32 %28, i32* %29, align 4
  %30 = getelementptr inbounds i8, i8* %1, i64 %16
  %31 = getelementptr inbounds i16, i16* %0, i64 32
  %32 = bitcast i16* %31 to <8 x i16>*
  %33 = load <8 x i16>, <8 x i16>* %32, align 1
  %34 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %33) #4
  %35 = sub <8 x i16> zeroinitializer, %33
  %36 = icmp slt <8 x i16> %33, zeroinitializer
  %37 = select <8 x i1> %36, <8 x i16> %35, <8 x i16> %33
  %38 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %37, <8 x i16> %11) #4
  %39 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %38, <8 x i16> %34) #4
  %40 = add <8 x i16> %39, %15
  %41 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %40, <8 x i16> undef) #4
  %42 = bitcast <16 x i8> %41 to <4 x i32>
  %43 = extractelement <4 x i32> %42, i32 0
  %44 = bitcast i8* %30 to i32*
  store i32 %43, i32* %44, align 4
  %45 = getelementptr inbounds i8, i8* %30, i64 %16
  %46 = getelementptr inbounds i16, i16* %0, i64 64
  %47 = bitcast i16* %46 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 1
  %49 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %48) #4
  %50 = sub <8 x i16> zeroinitializer, %48
  %51 = icmp slt <8 x i16> %48, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %48
  %53 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %52, <8 x i16> %11) #4
  %54 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %53, <8 x i16> %49) #4
  %55 = add <8 x i16> %54, %15
  %56 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> undef) #4
  %57 = bitcast <16 x i8> %56 to <4 x i32>
  %58 = extractelement <4 x i32> %57, i32 0
  %59 = bitcast i8* %45 to i32*
  store i32 %58, i32* %59, align 4
  %60 = getelementptr inbounds i8, i8* %45, i64 %16
  %61 = getelementptr inbounds i16, i16* %0, i64 96
  %62 = bitcast i16* %61 to <8 x i16>*
  %63 = load <8 x i16>, <8 x i16>* %62, align 1
  %64 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %63) #4
  %65 = sub <8 x i16> zeroinitializer, %63
  %66 = icmp slt <8 x i16> %63, zeroinitializer
  %67 = select <8 x i1> %66, <8 x i16> %65, <8 x i16> %63
  %68 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %67, <8 x i16> %11) #4
  %69 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %68, <8 x i16> %64) #4
  %70 = add <8 x i16> %69, %15
  %71 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> undef) #4
  %72 = bitcast <16 x i8> %71 to <4 x i32>
  %73 = extractelement <4 x i32> %72, i32 0
  %74 = bitcast i8* %60 to i32*
  store i32 %73, i32* %74, align 4
  %75 = getelementptr inbounds i8, i8* %60, i64 %16
  %76 = getelementptr inbounds i16, i16* %0, i64 128
  %77 = bitcast i16* %76 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 1
  %79 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %78) #4
  %80 = sub <8 x i16> zeroinitializer, %78
  %81 = icmp slt <8 x i16> %78, zeroinitializer
  %82 = select <8 x i1> %81, <8 x i16> %80, <8 x i16> %78
  %83 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %82, <8 x i16> %11) #4
  %84 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %83, <8 x i16> %79) #4
  %85 = add <8 x i16> %84, %15
  %86 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %85, <8 x i16> undef) #4
  %87 = bitcast <16 x i8> %86 to <4 x i32>
  %88 = extractelement <4 x i32> %87, i32 0
  %89 = bitcast i8* %75 to i32*
  store i32 %88, i32* %89, align 4
  %90 = getelementptr inbounds i8, i8* %75, i64 %16
  %91 = getelementptr inbounds i16, i16* %0, i64 160
  %92 = bitcast i16* %91 to <8 x i16>*
  %93 = load <8 x i16>, <8 x i16>* %92, align 1
  %94 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %93) #4
  %95 = sub <8 x i16> zeroinitializer, %93
  %96 = icmp slt <8 x i16> %93, zeroinitializer
  %97 = select <8 x i1> %96, <8 x i16> %95, <8 x i16> %93
  %98 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %97, <8 x i16> %11) #4
  %99 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %98, <8 x i16> %94) #4
  %100 = add <8 x i16> %99, %15
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> undef) #4
  %102 = bitcast <16 x i8> %101 to <4 x i32>
  %103 = extractelement <4 x i32> %102, i32 0
  %104 = bitcast i8* %90 to i32*
  store i32 %103, i32* %104, align 4
  %105 = getelementptr inbounds i8, i8* %90, i64 %16
  %106 = getelementptr inbounds i16, i16* %0, i64 192
  %107 = bitcast i16* %106 to <8 x i16>*
  %108 = load <8 x i16>, <8 x i16>* %107, align 1
  %109 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %108) #4
  %110 = sub <8 x i16> zeroinitializer, %108
  %111 = icmp slt <8 x i16> %108, zeroinitializer
  %112 = select <8 x i1> %111, <8 x i16> %110, <8 x i16> %108
  %113 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %112, <8 x i16> %11) #4
  %114 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %113, <8 x i16> %109) #4
  %115 = add <8 x i16> %114, %15
  %116 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %115, <8 x i16> undef) #4
  %117 = bitcast <16 x i8> %116 to <4 x i32>
  %118 = extractelement <4 x i32> %117, i32 0
  %119 = bitcast i8* %105 to i32*
  store i32 %118, i32* %119, align 4
  %120 = getelementptr inbounds i8, i8* %105, i64 %16
  %121 = getelementptr inbounds i16, i16* %0, i64 224
  %122 = bitcast i16* %121 to <8 x i16>*
  %123 = load <8 x i16>, <8 x i16>* %122, align 1
  %124 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %123) #4
  %125 = sub <8 x i16> zeroinitializer, %123
  %126 = icmp slt <8 x i16> %123, zeroinitializer
  %127 = select <8 x i1> %126, <8 x i16> %125, <8 x i16> %123
  %128 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %127, <8 x i16> %11) #4
  %129 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %128, <8 x i16> %124) #4
  %130 = add <8 x i16> %129, %15
  %131 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %130, <8 x i16> undef) #4
  %132 = bitcast <16 x i8> %131 to <4 x i32>
  %133 = extractelement <4 x i32> %132, i32 0
  %134 = bitcast i8* %120 to i32*
  store i32 %133, i32* %134, align 4
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_4x16_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %16 = bitcast i16* %0 to <2 x i64>*
  %17 = getelementptr inbounds i16, i16* %0, i64 512
  %18 = bitcast i16* %17 to <2 x i64>*
  %19 = sext i32 %2 to i64
  br label %20

20:                                               ; preds = %20, %4
  %21 = phi i8* [ %1, %4 ], [ %36, %20 ]
  %22 = phi <2 x i64>* [ %16, %4 ], [ %37, %20 ]
  %23 = bitcast <2 x i64>* %22 to <8 x i16>*
  %24 = load <8 x i16>, <8 x i16>* %23, align 1
  %25 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %24) #4
  %26 = sub <8 x i16> zeroinitializer, %24
  %27 = icmp slt <8 x i16> %24, zeroinitializer
  %28 = select <8 x i1> %27, <8 x i16> %26, <8 x i16> %24
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %28, <8 x i16> %11) #4
  %30 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %29, <8 x i16> %25) #4
  %31 = add <8 x i16> %30, %15
  %32 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %31, <8 x i16> undef) #4
  %33 = bitcast <16 x i8> %32 to <4 x i32>
  %34 = extractelement <4 x i32> %33, i32 0
  %35 = bitcast i8* %21 to i32*
  store i32 %34, i32* %35, align 4
  %36 = getelementptr inbounds i8, i8* %21, i64 %19
  %37 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 4
  %38 = icmp ult <2 x i64>* %37, %18
  br i1 %38, label %20, label %39

39:                                               ; preds = %20
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_8x4_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> zeroinitializer
  %16 = sext i32 %2 to i64
  %17 = bitcast i16* %0 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 1
  %19 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %18) #4
  %20 = sub <8 x i16> zeroinitializer, %18
  %21 = icmp slt <8 x i16> %18, zeroinitializer
  %22 = select <8 x i1> %21, <8 x i16> %20, <8 x i16> %18
  %23 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %22, <8 x i16> %11) #4
  %24 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %23, <8 x i16> %19) #4
  %25 = add <8 x i16> %24, %15
  %26 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %25, <8 x i16> undef) #4
  %27 = bitcast <16 x i8> %26 to <2 x i64>
  %28 = extractelement <2 x i64> %27, i32 0
  %29 = bitcast i8* %1 to i64*
  store i64 %28, i64* %29, align 1
  %30 = getelementptr inbounds i8, i8* %1, i64 %16
  %31 = getelementptr inbounds i16, i16* %0, i64 32
  %32 = bitcast i16* %31 to <8 x i16>*
  %33 = load <8 x i16>, <8 x i16>* %32, align 1
  %34 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %33) #4
  %35 = sub <8 x i16> zeroinitializer, %33
  %36 = icmp slt <8 x i16> %33, zeroinitializer
  %37 = select <8 x i1> %36, <8 x i16> %35, <8 x i16> %33
  %38 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %37, <8 x i16> %11) #4
  %39 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %38, <8 x i16> %34) #4
  %40 = add <8 x i16> %39, %15
  %41 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %40, <8 x i16> undef) #4
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = extractelement <2 x i64> %42, i32 0
  %44 = bitcast i8* %30 to i64*
  store i64 %43, i64* %44, align 1
  %45 = getelementptr inbounds i8, i8* %30, i64 %16
  %46 = getelementptr inbounds i16, i16* %0, i64 64
  %47 = bitcast i16* %46 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 1
  %49 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %48) #4
  %50 = sub <8 x i16> zeroinitializer, %48
  %51 = icmp slt <8 x i16> %48, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %48
  %53 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %52, <8 x i16> %11) #4
  %54 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %53, <8 x i16> %49) #4
  %55 = add <8 x i16> %54, %15
  %56 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> undef) #4
  %57 = bitcast <16 x i8> %56 to <2 x i64>
  %58 = extractelement <2 x i64> %57, i32 0
  %59 = bitcast i8* %45 to i64*
  store i64 %58, i64* %59, align 1
  %60 = getelementptr inbounds i8, i8* %45, i64 %16
  %61 = getelementptr inbounds i16, i16* %0, i64 96
  %62 = bitcast i16* %61 to <8 x i16>*
  %63 = load <8 x i16>, <8 x i16>* %62, align 1
  %64 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %63) #4
  %65 = sub <8 x i16> zeroinitializer, %63
  %66 = icmp slt <8 x i16> %63, zeroinitializer
  %67 = select <8 x i1> %66, <8 x i16> %65, <8 x i16> %63
  %68 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %67, <8 x i16> %11) #4
  %69 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %68, <8 x i16> %64) #4
  %70 = add <8 x i16> %69, %15
  %71 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> undef) #4
  %72 = bitcast <16 x i8> %71 to <2 x i64>
  %73 = extractelement <2 x i64> %72, i32 0
  %74 = bitcast i8* %60 to i64*
  store i64 %73, i64* %74, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_8x8_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> zeroinitializer
  %16 = sext i32 %2 to i64
  %17 = bitcast i16* %0 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 1
  %19 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %18) #4
  %20 = sub <8 x i16> zeroinitializer, %18
  %21 = icmp slt <8 x i16> %18, zeroinitializer
  %22 = select <8 x i1> %21, <8 x i16> %20, <8 x i16> %18
  %23 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %22, <8 x i16> %11) #4
  %24 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %23, <8 x i16> %19) #4
  %25 = add <8 x i16> %24, %15
  %26 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %25, <8 x i16> undef) #4
  %27 = bitcast <16 x i8> %26 to <2 x i64>
  %28 = extractelement <2 x i64> %27, i32 0
  %29 = bitcast i8* %1 to i64*
  store i64 %28, i64* %29, align 1
  %30 = getelementptr inbounds i8, i8* %1, i64 %16
  %31 = getelementptr inbounds i16, i16* %0, i64 32
  %32 = bitcast i16* %31 to <8 x i16>*
  %33 = load <8 x i16>, <8 x i16>* %32, align 1
  %34 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %33) #4
  %35 = sub <8 x i16> zeroinitializer, %33
  %36 = icmp slt <8 x i16> %33, zeroinitializer
  %37 = select <8 x i1> %36, <8 x i16> %35, <8 x i16> %33
  %38 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %37, <8 x i16> %11) #4
  %39 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %38, <8 x i16> %34) #4
  %40 = add <8 x i16> %39, %15
  %41 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %40, <8 x i16> undef) #4
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = extractelement <2 x i64> %42, i32 0
  %44 = bitcast i8* %30 to i64*
  store i64 %43, i64* %44, align 1
  %45 = getelementptr inbounds i8, i8* %30, i64 %16
  %46 = getelementptr inbounds i16, i16* %0, i64 64
  %47 = bitcast i16* %46 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 1
  %49 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %48) #4
  %50 = sub <8 x i16> zeroinitializer, %48
  %51 = icmp slt <8 x i16> %48, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %48
  %53 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %52, <8 x i16> %11) #4
  %54 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %53, <8 x i16> %49) #4
  %55 = add <8 x i16> %54, %15
  %56 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> undef) #4
  %57 = bitcast <16 x i8> %56 to <2 x i64>
  %58 = extractelement <2 x i64> %57, i32 0
  %59 = bitcast i8* %45 to i64*
  store i64 %58, i64* %59, align 1
  %60 = getelementptr inbounds i8, i8* %45, i64 %16
  %61 = getelementptr inbounds i16, i16* %0, i64 96
  %62 = bitcast i16* %61 to <8 x i16>*
  %63 = load <8 x i16>, <8 x i16>* %62, align 1
  %64 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %63) #4
  %65 = sub <8 x i16> zeroinitializer, %63
  %66 = icmp slt <8 x i16> %63, zeroinitializer
  %67 = select <8 x i1> %66, <8 x i16> %65, <8 x i16> %63
  %68 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %67, <8 x i16> %11) #4
  %69 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %68, <8 x i16> %64) #4
  %70 = add <8 x i16> %69, %15
  %71 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %70, <8 x i16> undef) #4
  %72 = bitcast <16 x i8> %71 to <2 x i64>
  %73 = extractelement <2 x i64> %72, i32 0
  %74 = bitcast i8* %60 to i64*
  store i64 %73, i64* %74, align 1
  %75 = getelementptr inbounds i8, i8* %60, i64 %16
  %76 = getelementptr inbounds i16, i16* %0, i64 128
  %77 = bitcast i16* %76 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 1
  %79 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %78) #4
  %80 = sub <8 x i16> zeroinitializer, %78
  %81 = icmp slt <8 x i16> %78, zeroinitializer
  %82 = select <8 x i1> %81, <8 x i16> %80, <8 x i16> %78
  %83 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %82, <8 x i16> %11) #4
  %84 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %83, <8 x i16> %79) #4
  %85 = add <8 x i16> %84, %15
  %86 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %85, <8 x i16> undef) #4
  %87 = bitcast <16 x i8> %86 to <2 x i64>
  %88 = extractelement <2 x i64> %87, i32 0
  %89 = bitcast i8* %75 to i64*
  store i64 %88, i64* %89, align 1
  %90 = getelementptr inbounds i8, i8* %75, i64 %16
  %91 = getelementptr inbounds i16, i16* %0, i64 160
  %92 = bitcast i16* %91 to <8 x i16>*
  %93 = load <8 x i16>, <8 x i16>* %92, align 1
  %94 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %93) #4
  %95 = sub <8 x i16> zeroinitializer, %93
  %96 = icmp slt <8 x i16> %93, zeroinitializer
  %97 = select <8 x i1> %96, <8 x i16> %95, <8 x i16> %93
  %98 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %97, <8 x i16> %11) #4
  %99 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %98, <8 x i16> %94) #4
  %100 = add <8 x i16> %99, %15
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> undef) #4
  %102 = bitcast <16 x i8> %101 to <2 x i64>
  %103 = extractelement <2 x i64> %102, i32 0
  %104 = bitcast i8* %90 to i64*
  store i64 %103, i64* %104, align 1
  %105 = getelementptr inbounds i8, i8* %90, i64 %16
  %106 = getelementptr inbounds i16, i16* %0, i64 192
  %107 = bitcast i16* %106 to <8 x i16>*
  %108 = load <8 x i16>, <8 x i16>* %107, align 1
  %109 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %108) #4
  %110 = sub <8 x i16> zeroinitializer, %108
  %111 = icmp slt <8 x i16> %108, zeroinitializer
  %112 = select <8 x i1> %111, <8 x i16> %110, <8 x i16> %108
  %113 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %112, <8 x i16> %11) #4
  %114 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %113, <8 x i16> %109) #4
  %115 = add <8 x i16> %114, %15
  %116 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %115, <8 x i16> undef) #4
  %117 = bitcast <16 x i8> %116 to <2 x i64>
  %118 = extractelement <2 x i64> %117, i32 0
  %119 = bitcast i8* %105 to i64*
  store i64 %118, i64* %119, align 1
  %120 = getelementptr inbounds i8, i8* %105, i64 %16
  %121 = getelementptr inbounds i16, i16* %0, i64 224
  %122 = bitcast i16* %121 to <8 x i16>*
  %123 = load <8 x i16>, <8 x i16>* %122, align 1
  %124 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %123) #4
  %125 = sub <8 x i16> zeroinitializer, %123
  %126 = icmp slt <8 x i16> %123, zeroinitializer
  %127 = select <8 x i1> %126, <8 x i16> %125, <8 x i16> %123
  %128 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %127, <8 x i16> %11) #4
  %129 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %128, <8 x i16> %124) #4
  %130 = add <8 x i16> %129, %15
  %131 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %130, <8 x i16> undef) #4
  %132 = bitcast <16 x i8> %131 to <2 x i64>
  %133 = extractelement <2 x i64> %132, i32 0
  %134 = bitcast i8* %120 to i64*
  store i64 %133, i64* %134, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_8x16_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> zeroinitializer
  %16 = bitcast i16* %0 to <2 x i64>*
  %17 = getelementptr inbounds i16, i16* %0, i64 512
  %18 = bitcast i16* %17 to <2 x i64>*
  %19 = sext i32 %2 to i64
  br label %20

20:                                               ; preds = %20, %4
  %21 = phi i8* [ %1, %4 ], [ %36, %20 ]
  %22 = phi <2 x i64>* [ %16, %4 ], [ %37, %20 ]
  %23 = bitcast <2 x i64>* %22 to <8 x i16>*
  %24 = load <8 x i16>, <8 x i16>* %23, align 1
  %25 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %24) #4
  %26 = sub <8 x i16> zeroinitializer, %24
  %27 = icmp slt <8 x i16> %24, zeroinitializer
  %28 = select <8 x i1> %27, <8 x i16> %26, <8 x i16> %24
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %28, <8 x i16> %11) #4
  %30 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %29, <8 x i16> %25) #4
  %31 = add <8 x i16> %30, %15
  %32 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %31, <8 x i16> undef) #4
  %33 = bitcast <16 x i8> %32 to <2 x i64>
  %34 = extractelement <2 x i64> %33, i32 0
  %35 = bitcast i8* %21 to i64*
  store i64 %34, i64* %35, align 1
  %36 = getelementptr inbounds i8, i8* %21, i64 %19
  %37 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 4
  %38 = icmp ult <2 x i64>* %37, %18
  br i1 %38, label %20, label %39

39:                                               ; preds = %20
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_8x32_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> zeroinitializer
  %16 = bitcast i16* %0 to <2 x i64>*
  %17 = getelementptr inbounds i16, i16* %0, i64 1024
  %18 = bitcast i16* %17 to <2 x i64>*
  %19 = sext i32 %2 to i64
  br label %20

20:                                               ; preds = %20, %4
  %21 = phi i8* [ %1, %4 ], [ %36, %20 ]
  %22 = phi <2 x i64>* [ %16, %4 ], [ %37, %20 ]
  %23 = bitcast <2 x i64>* %22 to <8 x i16>*
  %24 = load <8 x i16>, <8 x i16>* %23, align 1
  %25 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %24) #4
  %26 = sub <8 x i16> zeroinitializer, %24
  %27 = icmp slt <8 x i16> %24, zeroinitializer
  %28 = select <8 x i1> %27, <8 x i16> %26, <8 x i16> %24
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %28, <8 x i16> %11) #4
  %30 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %29, <8 x i16> %25) #4
  %31 = add <8 x i16> %30, %15
  %32 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %31, <8 x i16> undef) #4
  %33 = bitcast <16 x i8> %32 to <2 x i64>
  %34 = extractelement <2 x i64> %33, i32 0
  %35 = bitcast i8* %21 to i64*
  store i64 %34, i64* %35, align 1
  %36 = getelementptr inbounds i8, i8* %21, i64 %19
  %37 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 4
  %38 = icmp ult <2 x i64>* %37, %18
  br i1 %38, label %20, label %39

39:                                               ; preds = %20
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_16x4_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> zeroinitializer
  %16 = sext i32 %2 to i64
  %17 = bitcast i16* %0 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 1
  %19 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %18) #4
  %20 = sub <8 x i16> zeroinitializer, %18
  %21 = icmp slt <8 x i16> %18, zeroinitializer
  %22 = select <8 x i1> %21, <8 x i16> %20, <8 x i16> %18
  %23 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %22, <8 x i16> %11) #4
  %24 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %23, <8 x i16> %19) #4
  %25 = add <8 x i16> %24, %15
  %26 = getelementptr inbounds i16, i16* %0, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 1
  %29 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %28) #4
  %30 = sub <8 x i16> zeroinitializer, %28
  %31 = icmp slt <8 x i16> %28, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %28
  %33 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %32, <8 x i16> %11) #4
  %34 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %33, <8 x i16> %29) #4
  %35 = add <8 x i16> %34, %15
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %25, <8 x i16> %35) #4
  %37 = bitcast i8* %1 to <16 x i8>*
  store <16 x i8> %36, <16 x i8>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %1, i64 %16
  %39 = getelementptr inbounds i16, i16* %0, i64 32
  %40 = bitcast i16* %39 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 1
  %42 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %41) #4
  %43 = sub <8 x i16> zeroinitializer, %41
  %44 = icmp slt <8 x i16> %41, zeroinitializer
  %45 = select <8 x i1> %44, <8 x i16> %43, <8 x i16> %41
  %46 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %45, <8 x i16> %11) #4
  %47 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %46, <8 x i16> %42) #4
  %48 = add <8 x i16> %47, %15
  %49 = getelementptr inbounds i16, i16* %0, i64 40
  %50 = bitcast i16* %49 to <8 x i16>*
  %51 = load <8 x i16>, <8 x i16>* %50, align 1
  %52 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %51) #4
  %53 = sub <8 x i16> zeroinitializer, %51
  %54 = icmp slt <8 x i16> %51, zeroinitializer
  %55 = select <8 x i1> %54, <8 x i16> %53, <8 x i16> %51
  %56 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %55, <8 x i16> %11) #4
  %57 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %56, <8 x i16> %52) #4
  %58 = add <8 x i16> %57, %15
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %48, <8 x i16> %58) #4
  %60 = bitcast i8* %38 to <16 x i8>*
  store <16 x i8> %59, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %38, i64 %16
  %62 = getelementptr inbounds i16, i16* %0, i64 64
  %63 = bitcast i16* %62 to <8 x i16>*
  %64 = load <8 x i16>, <8 x i16>* %63, align 1
  %65 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %64) #4
  %66 = sub <8 x i16> zeroinitializer, %64
  %67 = icmp slt <8 x i16> %64, zeroinitializer
  %68 = select <8 x i1> %67, <8 x i16> %66, <8 x i16> %64
  %69 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %68, <8 x i16> %11) #4
  %70 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %69, <8 x i16> %65) #4
  %71 = add <8 x i16> %70, %15
  %72 = getelementptr inbounds i16, i16* %0, i64 72
  %73 = bitcast i16* %72 to <8 x i16>*
  %74 = load <8 x i16>, <8 x i16>* %73, align 1
  %75 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %74) #4
  %76 = sub <8 x i16> zeroinitializer, %74
  %77 = icmp slt <8 x i16> %74, zeroinitializer
  %78 = select <8 x i1> %77, <8 x i16> %76, <8 x i16> %74
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %78, <8 x i16> %11) #4
  %80 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %79, <8 x i16> %75) #4
  %81 = add <8 x i16> %80, %15
  %82 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %71, <8 x i16> %81) #4
  %83 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %82, <16 x i8>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %61, i64 %16
  %85 = getelementptr inbounds i16, i16* %0, i64 96
  %86 = bitcast i16* %85 to <8 x i16>*
  %87 = load <8 x i16>, <8 x i16>* %86, align 1
  %88 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %87) #4
  %89 = sub <8 x i16> zeroinitializer, %87
  %90 = icmp slt <8 x i16> %87, zeroinitializer
  %91 = select <8 x i1> %90, <8 x i16> %89, <8 x i16> %87
  %92 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %91, <8 x i16> %11) #4
  %93 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %92, <8 x i16> %88) #4
  %94 = add <8 x i16> %93, %15
  %95 = getelementptr inbounds i16, i16* %0, i64 104
  %96 = bitcast i16* %95 to <8 x i16>*
  %97 = load <8 x i16>, <8 x i16>* %96, align 1
  %98 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %97) #4
  %99 = sub <8 x i16> zeroinitializer, %97
  %100 = icmp slt <8 x i16> %97, zeroinitializer
  %101 = select <8 x i1> %100, <8 x i16> %99, <8 x i16> %97
  %102 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %101, <8 x i16> %11) #4
  %103 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %102, <8 x i16> %98) #4
  %104 = add <8 x i16> %103, %15
  %105 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %94, <8 x i16> %104) #4
  %106 = bitcast i8* %84 to <16 x i8>*
  store <16 x i8> %105, <16 x i8>* %106, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_16x8_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> zeroinitializer
  %16 = sext i32 %2 to i64
  %17 = bitcast i16* %0 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 1
  %19 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %18) #4
  %20 = sub <8 x i16> zeroinitializer, %18
  %21 = icmp slt <8 x i16> %18, zeroinitializer
  %22 = select <8 x i1> %21, <8 x i16> %20, <8 x i16> %18
  %23 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %22, <8 x i16> %11) #4
  %24 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %23, <8 x i16> %19) #4
  %25 = add <8 x i16> %24, %15
  %26 = getelementptr inbounds i16, i16* %0, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 1
  %29 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %28) #4
  %30 = sub <8 x i16> zeroinitializer, %28
  %31 = icmp slt <8 x i16> %28, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %28
  %33 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %32, <8 x i16> %11) #4
  %34 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %33, <8 x i16> %29) #4
  %35 = add <8 x i16> %34, %15
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %25, <8 x i16> %35) #4
  %37 = bitcast i8* %1 to <16 x i8>*
  store <16 x i8> %36, <16 x i8>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %1, i64 %16
  %39 = getelementptr inbounds i16, i16* %0, i64 32
  %40 = bitcast i16* %39 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 1
  %42 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %41) #4
  %43 = sub <8 x i16> zeroinitializer, %41
  %44 = icmp slt <8 x i16> %41, zeroinitializer
  %45 = select <8 x i1> %44, <8 x i16> %43, <8 x i16> %41
  %46 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %45, <8 x i16> %11) #4
  %47 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %46, <8 x i16> %42) #4
  %48 = add <8 x i16> %47, %15
  %49 = getelementptr inbounds i16, i16* %0, i64 40
  %50 = bitcast i16* %49 to <8 x i16>*
  %51 = load <8 x i16>, <8 x i16>* %50, align 1
  %52 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %51) #4
  %53 = sub <8 x i16> zeroinitializer, %51
  %54 = icmp slt <8 x i16> %51, zeroinitializer
  %55 = select <8 x i1> %54, <8 x i16> %53, <8 x i16> %51
  %56 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %55, <8 x i16> %11) #4
  %57 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %56, <8 x i16> %52) #4
  %58 = add <8 x i16> %57, %15
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %48, <8 x i16> %58) #4
  %60 = bitcast i8* %38 to <16 x i8>*
  store <16 x i8> %59, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %38, i64 %16
  %62 = getelementptr inbounds i16, i16* %0, i64 64
  %63 = bitcast i16* %62 to <8 x i16>*
  %64 = load <8 x i16>, <8 x i16>* %63, align 1
  %65 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %64) #4
  %66 = sub <8 x i16> zeroinitializer, %64
  %67 = icmp slt <8 x i16> %64, zeroinitializer
  %68 = select <8 x i1> %67, <8 x i16> %66, <8 x i16> %64
  %69 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %68, <8 x i16> %11) #4
  %70 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %69, <8 x i16> %65) #4
  %71 = add <8 x i16> %70, %15
  %72 = getelementptr inbounds i16, i16* %0, i64 72
  %73 = bitcast i16* %72 to <8 x i16>*
  %74 = load <8 x i16>, <8 x i16>* %73, align 1
  %75 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %74) #4
  %76 = sub <8 x i16> zeroinitializer, %74
  %77 = icmp slt <8 x i16> %74, zeroinitializer
  %78 = select <8 x i1> %77, <8 x i16> %76, <8 x i16> %74
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %78, <8 x i16> %11) #4
  %80 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %79, <8 x i16> %75) #4
  %81 = add <8 x i16> %80, %15
  %82 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %71, <8 x i16> %81) #4
  %83 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %82, <16 x i8>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %61, i64 %16
  %85 = getelementptr inbounds i16, i16* %0, i64 96
  %86 = bitcast i16* %85 to <8 x i16>*
  %87 = load <8 x i16>, <8 x i16>* %86, align 1
  %88 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %87) #4
  %89 = sub <8 x i16> zeroinitializer, %87
  %90 = icmp slt <8 x i16> %87, zeroinitializer
  %91 = select <8 x i1> %90, <8 x i16> %89, <8 x i16> %87
  %92 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %91, <8 x i16> %11) #4
  %93 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %92, <8 x i16> %88) #4
  %94 = add <8 x i16> %93, %15
  %95 = getelementptr inbounds i16, i16* %0, i64 104
  %96 = bitcast i16* %95 to <8 x i16>*
  %97 = load <8 x i16>, <8 x i16>* %96, align 1
  %98 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %97) #4
  %99 = sub <8 x i16> zeroinitializer, %97
  %100 = icmp slt <8 x i16> %97, zeroinitializer
  %101 = select <8 x i1> %100, <8 x i16> %99, <8 x i16> %97
  %102 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %101, <8 x i16> %11) #4
  %103 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %102, <8 x i16> %98) #4
  %104 = add <8 x i16> %103, %15
  %105 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %94, <8 x i16> %104) #4
  %106 = bitcast i8* %84 to <16 x i8>*
  store <16 x i8> %105, <16 x i8>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %84, i64 %16
  %108 = getelementptr inbounds i16, i16* %0, i64 128
  %109 = bitcast i16* %108 to <8 x i16>*
  %110 = load <8 x i16>, <8 x i16>* %109, align 1
  %111 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %110) #4
  %112 = sub <8 x i16> zeroinitializer, %110
  %113 = icmp slt <8 x i16> %110, zeroinitializer
  %114 = select <8 x i1> %113, <8 x i16> %112, <8 x i16> %110
  %115 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %114, <8 x i16> %11) #4
  %116 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %115, <8 x i16> %111) #4
  %117 = add <8 x i16> %116, %15
  %118 = getelementptr inbounds i16, i16* %0, i64 136
  %119 = bitcast i16* %118 to <8 x i16>*
  %120 = load <8 x i16>, <8 x i16>* %119, align 1
  %121 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %120) #4
  %122 = sub <8 x i16> zeroinitializer, %120
  %123 = icmp slt <8 x i16> %120, zeroinitializer
  %124 = select <8 x i1> %123, <8 x i16> %122, <8 x i16> %120
  %125 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %124, <8 x i16> %11) #4
  %126 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %125, <8 x i16> %121) #4
  %127 = add <8 x i16> %126, %15
  %128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %117, <8 x i16> %127) #4
  %129 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %128, <16 x i8>* %129, align 1
  %130 = getelementptr inbounds i8, i8* %107, i64 %16
  %131 = getelementptr inbounds i16, i16* %0, i64 160
  %132 = bitcast i16* %131 to <8 x i16>*
  %133 = load <8 x i16>, <8 x i16>* %132, align 1
  %134 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %133) #4
  %135 = sub <8 x i16> zeroinitializer, %133
  %136 = icmp slt <8 x i16> %133, zeroinitializer
  %137 = select <8 x i1> %136, <8 x i16> %135, <8 x i16> %133
  %138 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %137, <8 x i16> %11) #4
  %139 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %138, <8 x i16> %134) #4
  %140 = add <8 x i16> %139, %15
  %141 = getelementptr inbounds i16, i16* %0, i64 168
  %142 = bitcast i16* %141 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 1
  %144 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %143) #4
  %145 = sub <8 x i16> zeroinitializer, %143
  %146 = icmp slt <8 x i16> %143, zeroinitializer
  %147 = select <8 x i1> %146, <8 x i16> %145, <8 x i16> %143
  %148 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %147, <8 x i16> %11) #4
  %149 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %148, <8 x i16> %144) #4
  %150 = add <8 x i16> %149, %15
  %151 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %140, <8 x i16> %150) #4
  %152 = bitcast i8* %130 to <16 x i8>*
  store <16 x i8> %151, <16 x i8>* %152, align 1
  %153 = getelementptr inbounds i8, i8* %130, i64 %16
  %154 = getelementptr inbounds i16, i16* %0, i64 192
  %155 = bitcast i16* %154 to <8 x i16>*
  %156 = load <8 x i16>, <8 x i16>* %155, align 1
  %157 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %156) #4
  %158 = sub <8 x i16> zeroinitializer, %156
  %159 = icmp slt <8 x i16> %156, zeroinitializer
  %160 = select <8 x i1> %159, <8 x i16> %158, <8 x i16> %156
  %161 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %160, <8 x i16> %11) #4
  %162 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %161, <8 x i16> %157) #4
  %163 = add <8 x i16> %162, %15
  %164 = getelementptr inbounds i16, i16* %0, i64 200
  %165 = bitcast i16* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 1
  %167 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %166) #4
  %168 = sub <8 x i16> zeroinitializer, %166
  %169 = icmp slt <8 x i16> %166, zeroinitializer
  %170 = select <8 x i1> %169, <8 x i16> %168, <8 x i16> %166
  %171 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %170, <8 x i16> %11) #4
  %172 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %171, <8 x i16> %167) #4
  %173 = add <8 x i16> %172, %15
  %174 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %163, <8 x i16> %173) #4
  %175 = bitcast i8* %153 to <16 x i8>*
  store <16 x i8> %174, <16 x i8>* %175, align 1
  %176 = getelementptr inbounds i8, i8* %153, i64 %16
  %177 = getelementptr inbounds i16, i16* %0, i64 224
  %178 = bitcast i16* %177 to <8 x i16>*
  %179 = load <8 x i16>, <8 x i16>* %178, align 1
  %180 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %179) #4
  %181 = sub <8 x i16> zeroinitializer, %179
  %182 = icmp slt <8 x i16> %179, zeroinitializer
  %183 = select <8 x i1> %182, <8 x i16> %181, <8 x i16> %179
  %184 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %183, <8 x i16> %11) #4
  %185 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %184, <8 x i16> %180) #4
  %186 = add <8 x i16> %185, %15
  %187 = getelementptr inbounds i16, i16* %0, i64 232
  %188 = bitcast i16* %187 to <8 x i16>*
  %189 = load <8 x i16>, <8 x i16>* %188, align 1
  %190 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %189) #4
  %191 = sub <8 x i16> zeroinitializer, %189
  %192 = icmp slt <8 x i16> %189, zeroinitializer
  %193 = select <8 x i1> %192, <8 x i16> %191, <8 x i16> %189
  %194 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %193, <8 x i16> %11) #4
  %195 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %194, <8 x i16> %190) #4
  %196 = add <8 x i16> %195, %15
  %197 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %186, <8 x i16> %196) #4
  %198 = bitcast i8* %176 to <16 x i8>*
  store <16 x i8> %197, <16 x i8>* %198, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_16x16_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> zeroinitializer
  %16 = bitcast i16* %0 to <2 x i64>*
  %17 = getelementptr inbounds i16, i16* %0, i64 512
  %18 = bitcast i16* %17 to <2 x i64>*
  %19 = sext i32 %2 to i64
  br label %20

20:                                               ; preds = %20, %4
  %21 = phi i8* [ %1, %4 ], [ %44, %20 ]
  %22 = phi <2 x i64>* [ %16, %4 ], [ %45, %20 ]
  %23 = bitcast <2 x i64>* %22 to <8 x i16>*
  %24 = load <8 x i16>, <8 x i16>* %23, align 1
  %25 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %24) #4
  %26 = sub <8 x i16> zeroinitializer, %24
  %27 = icmp slt <8 x i16> %24, zeroinitializer
  %28 = select <8 x i1> %27, <8 x i16> %26, <8 x i16> %24
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %28, <8 x i16> %11) #4
  %30 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %29, <8 x i16> %25) #4
  %31 = add <8 x i16> %30, %15
  %32 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 1
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = load <8 x i16>, <8 x i16>* %33, align 1
  %35 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %34) #4
  %36 = sub <8 x i16> zeroinitializer, %34
  %37 = icmp slt <8 x i16> %34, zeroinitializer
  %38 = select <8 x i1> %37, <8 x i16> %36, <8 x i16> %34
  %39 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %38, <8 x i16> %11) #4
  %40 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %39, <8 x i16> %35) #4
  %41 = add <8 x i16> %40, %15
  %42 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %31, <8 x i16> %41) #4
  %43 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %42, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %21, i64 %19
  %45 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 4
  %46 = icmp ult <2 x i64>* %45, %18
  br i1 %46, label %20, label %47

47:                                               ; preds = %20
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_16x32_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> zeroinitializer
  %16 = bitcast i16* %0 to <2 x i64>*
  %17 = getelementptr inbounds i16, i16* %0, i64 1024
  %18 = bitcast i16* %17 to <2 x i64>*
  %19 = sext i32 %2 to i64
  br label %20

20:                                               ; preds = %20, %4
  %21 = phi i8* [ %1, %4 ], [ %44, %20 ]
  %22 = phi <2 x i64>* [ %16, %4 ], [ %45, %20 ]
  %23 = bitcast <2 x i64>* %22 to <8 x i16>*
  %24 = load <8 x i16>, <8 x i16>* %23, align 1
  %25 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %24) #4
  %26 = sub <8 x i16> zeroinitializer, %24
  %27 = icmp slt <8 x i16> %24, zeroinitializer
  %28 = select <8 x i1> %27, <8 x i16> %26, <8 x i16> %24
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %28, <8 x i16> %11) #4
  %30 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %29, <8 x i16> %25) #4
  %31 = add <8 x i16> %30, %15
  %32 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 1
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = load <8 x i16>, <8 x i16>* %33, align 1
  %35 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %34) #4
  %36 = sub <8 x i16> zeroinitializer, %34
  %37 = icmp slt <8 x i16> %34, zeroinitializer
  %38 = select <8 x i1> %37, <8 x i16> %36, <8 x i16> %34
  %39 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %38, <8 x i16> %11) #4
  %40 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %39, <8 x i16> %35) #4
  %41 = add <8 x i16> %40, %15
  %42 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %31, <8 x i16> %41) #4
  %43 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %42, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %21, i64 %19
  %45 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 4
  %46 = icmp ult <2 x i64>* %45, %18
  br i1 %46, label %20, label %47

47:                                               ; preds = %20
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_32x8_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> zeroinitializer
  %16 = bitcast i16* %0 to <2 x i64>*
  %17 = getelementptr inbounds i16, i16* %0, i64 256
  %18 = bitcast i16* %17 to <2 x i64>*
  %19 = sext i32 %2 to i64
  br label %20

20:                                               ; preds = %20, %4
  %21 = phi i8* [ %1, %4 ], [ %67, %20 ]
  %22 = phi <2 x i64>* [ %16, %4 ], [ %68, %20 ]
  %23 = bitcast <2 x i64>* %22 to <8 x i16>*
  %24 = load <8 x i16>, <8 x i16>* %23, align 1
  %25 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %24) #4
  %26 = sub <8 x i16> zeroinitializer, %24
  %27 = icmp slt <8 x i16> %24, zeroinitializer
  %28 = select <8 x i1> %27, <8 x i16> %26, <8 x i16> %24
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %28, <8 x i16> %11) #4
  %30 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %29, <8 x i16> %25) #4
  %31 = add <8 x i16> %30, %15
  %32 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 1
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = load <8 x i16>, <8 x i16>* %33, align 1
  %35 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %34) #4
  %36 = sub <8 x i16> zeroinitializer, %34
  %37 = icmp slt <8 x i16> %34, zeroinitializer
  %38 = select <8 x i1> %37, <8 x i16> %36, <8 x i16> %34
  %39 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %38, <8 x i16> %11) #4
  %40 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %39, <8 x i16> %35) #4
  %41 = add <8 x i16> %40, %15
  %42 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %31, <8 x i16> %41) #4
  %43 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %42, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 2
  %45 = bitcast <2 x i64>* %44 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 1
  %47 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %46) #4
  %48 = sub <8 x i16> zeroinitializer, %46
  %49 = icmp slt <8 x i16> %46, zeroinitializer
  %50 = select <8 x i1> %49, <8 x i16> %48, <8 x i16> %46
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %50, <8 x i16> %11) #4
  %52 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %51, <8 x i16> %47) #4
  %53 = add <8 x i16> %52, %15
  %54 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 3
  %55 = bitcast <2 x i64>* %54 to <8 x i16>*
  %56 = load <8 x i16>, <8 x i16>* %55, align 1
  %57 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %56) #4
  %58 = sub <8 x i16> zeroinitializer, %56
  %59 = icmp slt <8 x i16> %56, zeroinitializer
  %60 = select <8 x i1> %59, <8 x i16> %58, <8 x i16> %56
  %61 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %60, <8 x i16> %11) #4
  %62 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %61, <8 x i16> %57) #4
  %63 = add <8 x i16> %62, %15
  %64 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %63) #4
  %65 = getelementptr inbounds i8, i8* %21, i64 16
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %64, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %21, i64 %19
  %68 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 4
  %69 = icmp ult <2 x i64>* %68, %18
  br i1 %69, label %20, label %70

70:                                               ; preds = %20
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_32x16_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> zeroinitializer
  %16 = bitcast i16* %0 to <2 x i64>*
  %17 = getelementptr inbounds i16, i16* %0, i64 512
  %18 = bitcast i16* %17 to <2 x i64>*
  %19 = sext i32 %2 to i64
  br label %20

20:                                               ; preds = %20, %4
  %21 = phi i8* [ %1, %4 ], [ %67, %20 ]
  %22 = phi <2 x i64>* [ %16, %4 ], [ %68, %20 ]
  %23 = bitcast <2 x i64>* %22 to <8 x i16>*
  %24 = load <8 x i16>, <8 x i16>* %23, align 1
  %25 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %24) #4
  %26 = sub <8 x i16> zeroinitializer, %24
  %27 = icmp slt <8 x i16> %24, zeroinitializer
  %28 = select <8 x i1> %27, <8 x i16> %26, <8 x i16> %24
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %28, <8 x i16> %11) #4
  %30 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %29, <8 x i16> %25) #4
  %31 = add <8 x i16> %30, %15
  %32 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 1
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = load <8 x i16>, <8 x i16>* %33, align 1
  %35 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %34) #4
  %36 = sub <8 x i16> zeroinitializer, %34
  %37 = icmp slt <8 x i16> %34, zeroinitializer
  %38 = select <8 x i1> %37, <8 x i16> %36, <8 x i16> %34
  %39 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %38, <8 x i16> %11) #4
  %40 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %39, <8 x i16> %35) #4
  %41 = add <8 x i16> %40, %15
  %42 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %31, <8 x i16> %41) #4
  %43 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %42, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 2
  %45 = bitcast <2 x i64>* %44 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 1
  %47 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %46) #4
  %48 = sub <8 x i16> zeroinitializer, %46
  %49 = icmp slt <8 x i16> %46, zeroinitializer
  %50 = select <8 x i1> %49, <8 x i16> %48, <8 x i16> %46
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %50, <8 x i16> %11) #4
  %52 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %51, <8 x i16> %47) #4
  %53 = add <8 x i16> %52, %15
  %54 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 3
  %55 = bitcast <2 x i64>* %54 to <8 x i16>*
  %56 = load <8 x i16>, <8 x i16>* %55, align 1
  %57 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %56) #4
  %58 = sub <8 x i16> zeroinitializer, %56
  %59 = icmp slt <8 x i16> %56, zeroinitializer
  %60 = select <8 x i1> %59, <8 x i16> %58, <8 x i16> %56
  %61 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %60, <8 x i16> %11) #4
  %62 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %61, <8 x i16> %57) #4
  %63 = add <8 x i16> %62, %15
  %64 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %63) #4
  %65 = getelementptr inbounds i8, i8* %21, i64 16
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %64, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %21, i64 %19
  %68 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 4
  %69 = icmp ult <2 x i64>* %68, %18
  br i1 %69, label %20, label %70

70:                                               ; preds = %20
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_32x32_ssse3(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <8 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> zeroinitializer
  %8 = sub <8 x i16> zeroinitializer, %7
  %9 = icmp slt <8 x i16> %7, zeroinitializer
  %10 = select <8 x i1> %9, <8 x i16> %8, <8 x i16> %7
  %11 = shl <8 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <8 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> zeroinitializer
  %16 = bitcast i16* %0 to <2 x i64>*
  %17 = getelementptr inbounds i16, i16* %0, i64 1024
  %18 = bitcast i16* %17 to <2 x i64>*
  %19 = sext i32 %2 to i64
  br label %20

20:                                               ; preds = %20, %4
  %21 = phi i8* [ %1, %4 ], [ %67, %20 ]
  %22 = phi <2 x i64>* [ %16, %4 ], [ %68, %20 ]
  %23 = bitcast <2 x i64>* %22 to <8 x i16>*
  %24 = load <8 x i16>, <8 x i16>* %23, align 1
  %25 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %24) #4
  %26 = sub <8 x i16> zeroinitializer, %24
  %27 = icmp slt <8 x i16> %24, zeroinitializer
  %28 = select <8 x i1> %27, <8 x i16> %26, <8 x i16> %24
  %29 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %28, <8 x i16> %11) #4
  %30 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %29, <8 x i16> %25) #4
  %31 = add <8 x i16> %30, %15
  %32 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 1
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = load <8 x i16>, <8 x i16>* %33, align 1
  %35 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %34) #4
  %36 = sub <8 x i16> zeroinitializer, %34
  %37 = icmp slt <8 x i16> %34, zeroinitializer
  %38 = select <8 x i1> %37, <8 x i16> %36, <8 x i16> %34
  %39 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %38, <8 x i16> %11) #4
  %40 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %39, <8 x i16> %35) #4
  %41 = add <8 x i16> %40, %15
  %42 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %31, <8 x i16> %41) #4
  %43 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %42, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 2
  %45 = bitcast <2 x i64>* %44 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 1
  %47 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %46) #4
  %48 = sub <8 x i16> zeroinitializer, %46
  %49 = icmp slt <8 x i16> %46, zeroinitializer
  %50 = select <8 x i1> %49, <8 x i16> %48, <8 x i16> %46
  %51 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %50, <8 x i16> %11) #4
  %52 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %51, <8 x i16> %47) #4
  %53 = add <8 x i16> %52, %15
  %54 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 3
  %55 = bitcast <2 x i64>* %54 to <8 x i16>*
  %56 = load <8 x i16>, <8 x i16>* %55, align 1
  %57 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %7, <8 x i16> %56) #4
  %58 = sub <8 x i16> zeroinitializer, %56
  %59 = icmp slt <8 x i16> %56, zeroinitializer
  %60 = select <8 x i1> %59, <8 x i16> %58, <8 x i16> %56
  %61 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %60, <8 x i16> %11) #4
  %62 = tail call <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16> %61, <8 x i16> %57) #4
  %63 = add <8 x i16> %62, %15
  %64 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %53, <8 x i16> %63) #4
  %65 = getelementptr inbounds i8, i8* %21, i64 16
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %64, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %21, i64 %19
  %68 = getelementptr inbounds <2 x i64>, <2 x i64>* %22, i64 4
  %69 = icmp ult <2 x i64>* %68, %18
  br i1 %69, label %20, label %70

70:                                               ; preds = %20
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void (i16*, i8*, i32, i32)* @cfl_get_predict_lbd_fn_ssse3(i8 zeroext) local_unnamed_addr #1 {
  %2 = urem i8 %0, 19
  %3 = zext i8 %2 to i64
  %4 = getelementptr inbounds [19 x void (i16*, i8*, i32, i32)*], [19 x void (i16*, i8*, i32, i32)*]* @cfl_get_predict_lbd_fn_ssse3.pred, i64 0, i64 %3
  %5 = load void (i16*, i8*, i32, i32)*, void (i16*, i8*, i32, i32)** %4, align 8
  ret void (i16*, i8*, i32, i32)* %5
}

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8>, <16 x i8>) #3

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.psign.w.128(<8 x i16>, <8 x i16>) #3

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16>, <8 x i16>) #3

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #3

attributes #0 = { nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { norecurse nounwind readnone ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind readnone }
attributes #4 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
