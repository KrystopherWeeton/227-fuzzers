; ModuleID = '../../third_party/swiftshader/src/WSI/VkSurfaceKHR.cpp'
source_filename = "../../third_party/swiftshader/src/WSI/VkSurfaceKHR.cpp"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%struct.VkSurfaceFormatKHR = type { i32, i32 }
%class.VkNonDispatchableHandle = type { i64 }
%class.VkNonDispatchableHandle.0 = type { i64 }
%class.VkNonDispatchableHandle.1 = type { i64 }
%class.VkNonDispatchableHandle.2 = type { i64 }
%class.VkNonDispatchableHandle.3 = type { i64 }
%class.VkNonDispatchableHandle.4 = type { i64 }
%class.VkNonDispatchableHandle.5 = type { i64 }
%class.VkNonDispatchableHandle.6 = type { i64 }
%class.VkNonDispatchableHandle.7 = type { i64 }
%class.VkNonDispatchableHandle.8 = type { i64 }
%class.VkNonDispatchableHandle.9 = type { i64 }
%class.VkNonDispatchableHandle.10 = type { i64 }
%class.VkNonDispatchableHandle.11 = type { i64 }
%class.VkNonDispatchableHandle.12 = type { i64 }
%class.VkNonDispatchableHandle.13 = type { i64 }
%class.VkNonDispatchableHandle.14 = type { i64 }
%class.VkNonDispatchableHandle.15 = type { i64 }
%class.VkNonDispatchableHandle.16 = type { i64 }
%class.VkNonDispatchableHandle.17 = type { i64 }
%class.VkNonDispatchableHandle.18 = type { i64 }
%class.VkNonDispatchableHandle.19 = type { i64 }
%class.VkNonDispatchableHandle.20 = type { i64 }
%class.VkNonDispatchableHandle.21 = type { i64 }
%class.VkNonDispatchableHandle.22 = type { i64 }
%class.VkNonDispatchableHandle.23 = type { i64 }
%class.VkNonDispatchableHandle.24 = type { i64 }
%class.VkNonDispatchableHandle.25 = type { i64 }
%class.VkNonDispatchableHandle.26 = type { i64 }
%class.VkNonDispatchableHandle.27 = type { i64 }
%class.VkNonDispatchableHandle.28 = type { i64 }
%class.VkNonDispatchableHandle.29 = type { i64 }
%class.VkNonDispatchableHandle.30 = type { i64 }
%class.VkNonDispatchableHandle.31 = type { i64 }
%class.VkNonDispatchableHandle.32 = type { i64 }
%class.VkNonDispatchableHandle.33 = type { i64 }
%class.VkNonDispatchableHandle.34 = type { i64 }
%class.VkNonDispatchableHandle.35 = type { i64 }
%"class.vk::PresentImage" = type <{ %"class.vk::Image"*, %"class.vk::DeviceMemory"*, i32, [4 x i8] }>
%"class.vk::Image" = type { %"class.vk::DeviceMemory"*, %"class.vk::Device"*, i64, i32, i32, %"class.vk::Format", %struct.VkExtent3D, i32, i32, i32, i32, i32, %"class.vk::Image"*, i32, %"class.marl::mutex", %"class.std::__1::unordered_set.407" }
%"class.vk::Device" = type { %"class.vk::PhysicalDevice"*, %"class.vk::Queue"*, i32, %"class.std::__1::unique_ptr.133", i32, [256 x i8]*, %struct.VkPhysicalDeviceFeatures, %"class.std::__1::shared_ptr.191", %"class.std::__1::unique_ptr.305", %"class.std::__1::unique_ptr.366", %"class.marl::mutex", %"class.std::__1::unordered_set.381" }
%"class.vk::PhysicalDevice" = type { i8 }
%"class.vk::Queue" = type { %union.VK_LOADER_DATA, %"class.vk::Device"*, %"class.std::__1::unique_ptr", %"class.sw::Chan", %"class.sw::Chan.119", %"class.std::__1::thread" }
%union.VK_LOADER_DATA = type { i64 }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { %"class.sw::Renderer"* }
%"class.sw::Renderer" = type { i32 (...)**, %"class.marl::BoundedPool", %"class.marl::BoundedPool.38", %"struct.std::__1::atomic", %"class.vk::Query"*, %"class.marl::Ticket::Queue", [16 x %"class.marl::Ticket::Queue"], %"class.sw::VertexProcessor", [8 x i8], %"class.sw::PixelProcessor", %"class.sw::SetupProcessor", %"struct.sw::VertexProcessor::State", %"struct.sw::SetupProcessor::State", [4 x i8], %"struct.sw::PixelProcessor::State", %"class.rr::RoutineT", %"class.rr::RoutineT.105", %"class.rr::RoutineT.106", %"class.vk::Device"* }
%"class.marl::BoundedPool" = type { %"class.std::__1::shared_ptr" }
%"class.std::__1::shared_ptr" = type { %"class.marl::BoundedPool<sw::DrawCall, 16, marl::PoolPolicy::Preserve>::Storage"*, %"class.std::__1::__shared_weak_count"* }
%"class.marl::BoundedPool<sw::DrawCall, 16, marl::PoolPolicy::Preserve>::Storage" = type opaque
%"class.std::__1::__shared_weak_count" = type { %"class.std::__1::__shared_count", i64 }
%"class.std::__1::__shared_count" = type { i32 (...)**, i64 }
%"class.marl::BoundedPool.38" = type { %"class.std::__1::shared_ptr.41" }
%"class.std::__1::shared_ptr.41" = type { %"class.marl::BoundedPool<sw::DrawCall::BatchData, 16, marl::PoolPolicy::Preserve>::Storage"*, %"class.std::__1::__shared_weak_count"* }
%"class.marl::BoundedPool<sw::DrawCall::BatchData, 16, marl::PoolPolicy::Preserve>::Storage" = type opaque
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__atomic_base.42" }
%"struct.std::__1::__atomic_base.42" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i32 }
%"class.vk::Query" = type { %"class.marl::WaitGroup", %"class.marl::Event", %"struct.std::__1::atomic.52", %"struct.std::__1::atomic.56", %"struct.std::__1::atomic.60" }
%"class.marl::WaitGroup" = type { %"class.std::__1::shared_ptr.43" }
%"class.std::__1::shared_ptr.43" = type { %"struct.marl::WaitGroup::Data"*, %"class.std::__1::__shared_weak_count"* }
%"struct.marl::WaitGroup::Data" = type { %"struct.std::__1::atomic.44", %"class.marl::ConditionVariable", %"class.marl::mutex" }
%"struct.std::__1::atomic.44" = type { %"struct.std::__1::__atomic_base.45" }
%"struct.std::__1::__atomic_base.45" = type { %"struct.std::__1::__atomic_base.46" }
%"struct.std::__1::__atomic_base.46" = type { %"struct.std::__1::__cxx_atomic_impl.47" }
%"struct.std::__1::__cxx_atomic_impl.47" = type { %"struct.std::__1::__cxx_atomic_base_impl.48" }
%"struct.std::__1::__cxx_atomic_base_impl.48" = type { i32 }
%"class.marl::ConditionVariable" = type { %"class.marl::mutex", %"class.marl::containers::list", %"class.std::__1::condition_variable", %"struct.std::__1::atomic", %"struct.std::__1::atomic" }
%"class.marl::containers::list" = type { %"class.marl::Allocator"*, i64, i64, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* }
%"class.marl::Allocator" = type { i32 (...)** }
%"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain" = type { %"struct.marl::Allocation", %"struct.marl::containers::list<marl::Scheduler::Fiber *>::AllocationChain"* }
%"struct.marl::Allocation" = type { i8*, %"struct.marl::Allocation::Request" }
%"struct.marl::Allocation::Request" = type <{ i64, i64, i8, i8, [6 x i8] }>
%"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry" = type { %"class.marl::Scheduler::Fiber"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"*, %"struct.marl::containers::list<marl::Scheduler::Fiber *>::Entry"* }
%"class.marl::Scheduler::Fiber" = type <{ i32, [4 x i8], %"class.std::__1::unique_ptr.198", %"class.marl::Scheduler::Worker"*, i32, [4 x i8] }>
%"class.std::__1::unique_ptr.198" = type { %"class.std::__1::__compressed_pair.199" }
%"class.std::__1::__compressed_pair.199" = type { %"struct.std::__1::__compressed_pair_elem.200", %"struct.std::__1::__compressed_pair_elem.201" }
%"struct.std::__1::__compressed_pair_elem.200" = type { %"class.marl::OSFiber"* }
%"class.marl::OSFiber" = type opaque
%"struct.std::__1::__compressed_pair_elem.201" = type { %"struct.marl::Allocator::Deleter" }
%"struct.marl::Allocator::Deleter" = type { %"class.marl::Allocator"*, i64 }
%"class.marl::Scheduler::Worker" = type <{ i32, i32, %"class.marl::Scheduler"*, %"class.std::__1::unique_ptr.195", %"class.marl::Scheduler::Fiber"*, %"class.marl::Thread", %"struct.marl::Scheduler::Worker::Work", %"class.std::__1::unordered_set.258", %"class.marl::containers::vector.278", %"class.marl::Scheduler::Worker::FastRnd", i8, [7 x i8] }>
%"class.marl::Scheduler" = type { %"struct.marl::Scheduler::Config", %"struct.std::__1::array.193", %"struct.std::__1::atomic.44", %"struct.std::__1::atomic.44", %"struct.std::__1::array.194", %"struct.marl::Scheduler::SingleThreadedWorkers" }
%"struct.marl::Scheduler::Config" = type { %"struct.marl::Scheduler::Config::WorkerThread", %"class.marl::Allocator"*, i64 }
%"struct.marl::Scheduler::Config::WorkerThread" = type { i32, %"class.std::__1::function", %"class.std::__1::shared_ptr.192" }
%"class.std::__1::function" = type { %"class.std::__1::__function::__policy_func" }
%"class.std::__1::__function::__policy_func" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker", %"struct.std::__1::__function::__policy"* }
%"union.std::__1::__function::__policy_storage" = type { i8*, [8 x i8] }
%"struct.std::__1::__function::__policy_invoker" = type { void (%"union.std::__1::__function::__policy_storage"*, i32)* }
%"struct.std::__1::__function::__policy" = type { i8* (i8*)*, void (i8*)*, i8, %"class.std::type_info"* }
%"class.std::type_info" = type { i32 (...)**, i8* }
%"class.std::__1::shared_ptr.192" = type { %"class.marl::Thread::Affinity::Policy"*, %"class.std::__1::__shared_weak_count"* }
%"class.marl::Thread::Affinity::Policy" = type { i32 (...)** }
%"struct.std::__1::array.193" = type { [8 x %"struct.std::__1::atomic"] }
%"struct.std::__1::array.194" = type { [256 x %"class.marl::Scheduler::Worker"*] }
%"struct.marl::Scheduler::SingleThreadedWorkers" = type { %"class.marl::mutex", %"class.std::__1::condition_variable", %"class.std::__1::unordered_map.279" }
%"class.std::__1::unordered_map.279" = type { %"class.std::__1::__hash_table.280" }
%"class.std::__1::__hash_table.280" = type <{ %"class.std::__1::unique_ptr.281", %"class.std::__1::__compressed_pair.290", %"class.std::__1::__compressed_pair.294", %"class.std::__1::__compressed_pair.299", [4 x i8] }>
%"class.std::__1::unique_ptr.281" = type { %"class.std::__1::__compressed_pair.282" }
%"class.std::__1::__compressed_pair.282" = type { %"struct.std::__1::__compressed_pair_elem.283", %"struct.std::__1::__compressed_pair_elem.285" }
%"struct.std::__1::__compressed_pair_elem.283" = type { %"struct.std::__1::__hash_node_base.284"** }
%"struct.std::__1::__hash_node_base.284" = type { %"struct.std::__1::__hash_node_base.284"* }
%"struct.std::__1::__compressed_pair_elem.285" = type { %"class.std::__1::__bucket_list_deallocator.286" }
%"class.std::__1::__bucket_list_deallocator.286" = type { %"class.std::__1::__compressed_pair.287" }
%"class.std::__1::__compressed_pair.287" = type { %"struct.std::__1::__compressed_pair_elem.115", %"struct.std::__1::__compressed_pair_elem.288" }
%"struct.std::__1::__compressed_pair_elem.115" = type { i64 }
%"struct.std::__1::__compressed_pair_elem.288" = type { %"struct.marl::StlAllocator.289" }
%"struct.marl::StlAllocator.289" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.290" = type { %"struct.std::__1::__compressed_pair_elem.291", %"struct.std::__1::__compressed_pair_elem.292" }
%"struct.std::__1::__compressed_pair_elem.291" = type { %"struct.std::__1::__hash_node_base.284" }
%"struct.std::__1::__compressed_pair_elem.292" = type { %"struct.marl::StlAllocator.293" }
%"struct.marl::StlAllocator.293" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.294" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.299" = type { %"struct.std::__1::__compressed_pair_elem.158" }
%"struct.std::__1::__compressed_pair_elem.158" = type { float }
%"class.std::__1::unique_ptr.195" = type { %"class.std::__1::__compressed_pair.196" }
%"class.std::__1::__compressed_pair.196" = type { %"struct.std::__1::__compressed_pair_elem.197", %"struct.std::__1::__compressed_pair_elem.201" }
%"struct.std::__1::__compressed_pair_elem.197" = type { %"class.marl::Scheduler::Fiber"* }
%"class.marl::Thread" = type { %"class.marl::Thread::Impl"* }
%"class.marl::Thread::Impl" = type opaque
%"struct.marl::Scheduler::Worker::Work" = type { %"struct.std::__1::atomic.202", i64, %"class.std::__1::deque.207", %"class.std::__1::deque.221", %"struct.marl::Scheduler::WaitingFibers", i8, %"class.std::__1::condition_variable", %"class.marl::mutex" }
%"struct.std::__1::atomic.202" = type { %"struct.std::__1::__atomic_base.203" }
%"struct.std::__1::__atomic_base.203" = type { %"struct.std::__1::__atomic_base.204" }
%"struct.std::__1::__atomic_base.204" = type { %"struct.std::__1::__cxx_atomic_impl.205" }
%"struct.std::__1::__cxx_atomic_impl.205" = type { %"struct.std::__1::__cxx_atomic_base_impl.206" }
%"struct.std::__1::__cxx_atomic_base_impl.206" = type { i64 }
%"class.std::__1::deque.207" = type { %"class.std::__1::__deque_base.208" }
%"class.std::__1::__deque_base.208" = type { %"struct.std::__1::__split_buffer.209", i64, %"class.std::__1::__compressed_pair.218" }
%"struct.std::__1::__split_buffer.209" = type { %"class.marl::Task"**, %"class.marl::Task"**, %"class.marl::Task"**, %"class.std::__1::__compressed_pair.215" }
%"class.marl::Task" = type <{ %"class.std::__1::function.210", i32, [4 x i8] }>
%"class.std::__1::function.210" = type { %"class.std::__1::__function::__policy_func.213" }
%"class.std::__1::__function::__policy_func.213" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker.214", %"struct.std::__1::__function::__policy"* }
%"struct.std::__1::__function::__policy_invoker.214" = type { void (%"union.std::__1::__function::__policy_storage"*)* }
%"class.std::__1::__compressed_pair.215" = type { %"struct.std::__1::__compressed_pair_elem.216", %"struct.std::__1::__compressed_pair_elem.217" }
%"struct.std::__1::__compressed_pair_elem.216" = type { %"class.marl::Task"** }
%"struct.std::__1::__compressed_pair_elem.217" = type { %"struct.marl::StlAllocator" }
%"struct.marl::StlAllocator" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.218" = type { %"struct.std::__1::__compressed_pair_elem.115", %"struct.std::__1::__compressed_pair_elem.219" }
%"struct.std::__1::__compressed_pair_elem.219" = type { %"struct.marl::StlAllocator.220" }
%"struct.marl::StlAllocator.220" = type { %"class.marl::Allocator"* }
%"class.std::__1::deque.221" = type { %"class.std::__1::__deque_base.222" }
%"class.std::__1::__deque_base.222" = type { %"struct.std::__1::__split_buffer.223", i64, %"class.std::__1::__compressed_pair.228" }
%"struct.std::__1::__split_buffer.223" = type { %"class.marl::Scheduler::Fiber"***, %"class.marl::Scheduler::Fiber"***, %"class.marl::Scheduler::Fiber"***, %"class.std::__1::__compressed_pair.224" }
%"class.std::__1::__compressed_pair.224" = type { %"struct.std::__1::__compressed_pair_elem.225", %"struct.std::__1::__compressed_pair_elem.226" }
%"struct.std::__1::__compressed_pair_elem.225" = type { %"class.marl::Scheduler::Fiber"*** }
%"struct.std::__1::__compressed_pair_elem.226" = type { %"struct.marl::StlAllocator.227" }
%"struct.marl::StlAllocator.227" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.228" = type { %"struct.std::__1::__compressed_pair_elem.115", %"struct.std::__1::__compressed_pair_elem.229" }
%"struct.std::__1::__compressed_pair_elem.229" = type { %"struct.marl::StlAllocator.230" }
%"struct.marl::StlAllocator.230" = type { %"class.marl::Allocator"* }
%"struct.marl::Scheduler::WaitingFibers" = type { %"class.std::__1::set", %"class.std::__1::unordered_map" }
%"class.std::__1::set" = type { %"class.std::__1::__tree" }
%"class.std::__1::__tree" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.231", %"class.std::__1::__compressed_pair.235" }
%"class.std::__1::__tree_end_node" = type { %"class.std::__1::__tree_node_base"* }
%"class.std::__1::__tree_node_base" = type <{ %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_end_node"*, i8, [7 x i8] }>
%"class.std::__1::__compressed_pair.231" = type { %"struct.std::__1::__compressed_pair_elem.232", %"struct.std::__1::__compressed_pair_elem.233" }
%"struct.std::__1::__compressed_pair_elem.232" = type { %"class.std::__1::__tree_end_node" }
%"struct.std::__1::__compressed_pair_elem.233" = type { %"struct.marl::StlAllocator.234" }
%"struct.marl::StlAllocator.234" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.235" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table.237" }
%"class.std::__1::__hash_table.237" = type <{ %"class.std::__1::unique_ptr.238", %"class.std::__1::__compressed_pair.247", %"class.std::__1::__compressed_pair.251", %"class.std::__1::__compressed_pair.254", [4 x i8] }>
%"class.std::__1::unique_ptr.238" = type { %"class.std::__1::__compressed_pair.239" }
%"class.std::__1::__compressed_pair.239" = type { %"struct.std::__1::__compressed_pair_elem.240", %"struct.std::__1::__compressed_pair_elem.242" }
%"struct.std::__1::__compressed_pair_elem.240" = type { %"struct.std::__1::__hash_node_base.241"** }
%"struct.std::__1::__hash_node_base.241" = type { %"struct.std::__1::__hash_node_base.241"* }
%"struct.std::__1::__compressed_pair_elem.242" = type { %"class.std::__1::__bucket_list_deallocator.243" }
%"class.std::__1::__bucket_list_deallocator.243" = type { %"class.std::__1::__compressed_pair.244" }
%"class.std::__1::__compressed_pair.244" = type { %"struct.std::__1::__compressed_pair_elem.115", %"struct.std::__1::__compressed_pair_elem.245" }
%"struct.std::__1::__compressed_pair_elem.245" = type { %"struct.marl::StlAllocator.246" }
%"struct.marl::StlAllocator.246" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.247" = type { %"struct.std::__1::__compressed_pair_elem.248", %"struct.std::__1::__compressed_pair_elem.249" }
%"struct.std::__1::__compressed_pair_elem.248" = type { %"struct.std::__1::__hash_node_base.241" }
%"struct.std::__1::__compressed_pair_elem.249" = type { %"struct.marl::StlAllocator.250" }
%"struct.marl::StlAllocator.250" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.251" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.254" = type { %"struct.std::__1::__compressed_pair_elem.158" }
%"class.std::__1::unordered_set.258" = type { %"class.std::__1::__hash_table.259" }
%"class.std::__1::__hash_table.259" = type <{ %"class.std::__1::unique_ptr.260", %"class.std::__1::__compressed_pair.269", %"class.std::__1::__compressed_pair.273", %"class.std::__1::__compressed_pair.275", [4 x i8] }>
%"class.std::__1::unique_ptr.260" = type { %"class.std::__1::__compressed_pair.261" }
%"class.std::__1::__compressed_pair.261" = type { %"struct.std::__1::__compressed_pair_elem.262", %"struct.std::__1::__compressed_pair_elem.264" }
%"struct.std::__1::__compressed_pair_elem.262" = type { %"struct.std::__1::__hash_node_base.263"** }
%"struct.std::__1::__hash_node_base.263" = type { %"struct.std::__1::__hash_node_base.263"* }
%"struct.std::__1::__compressed_pair_elem.264" = type { %"class.std::__1::__bucket_list_deallocator.265" }
%"class.std::__1::__bucket_list_deallocator.265" = type { %"class.std::__1::__compressed_pair.266" }
%"class.std::__1::__compressed_pair.266" = type { %"struct.std::__1::__compressed_pair_elem.115", %"struct.std::__1::__compressed_pair_elem.267" }
%"struct.std::__1::__compressed_pair_elem.267" = type { %"struct.marl::StlAllocator.268" }
%"struct.marl::StlAllocator.268" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.269" = type { %"struct.std::__1::__compressed_pair_elem.270", %"struct.std::__1::__compressed_pair_elem.271" }
%"struct.std::__1::__compressed_pair_elem.270" = type { %"struct.std::__1::__hash_node_base.263" }
%"struct.std::__1::__compressed_pair_elem.271" = type { %"struct.marl::StlAllocator.272" }
%"struct.marl::StlAllocator.272" = type { %"class.marl::Allocator"* }
%"class.std::__1::__compressed_pair.273" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.275" = type { %"struct.std::__1::__compressed_pair_elem.158" }
%"class.marl::containers::vector.278" = type { %"class.marl::Allocator"*, i64, i64, [16 x %"struct.marl::aligned_storage<24, 8>::type"], %"struct.marl::aligned_storage<24, 8>::type"*, %"struct.marl::Allocation" }
%"struct.marl::aligned_storage<24, 8>::type" = type { [24 x i8] }
%"class.marl::Scheduler::Worker::FastRnd" = type { i64 }
%"class.std::__1::condition_variable" = type { %union.pthread_cond_t }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon, %union.anon.49, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon = type { i64 }
%union.anon.49 = type { i64 }
%"class.marl::Event" = type { %"class.std::__1::shared_ptr.51" }
%"class.std::__1::shared_ptr.51" = type { %"struct.marl::Event::Shared"*, %"class.std::__1::__shared_weak_count"* }
%"struct.marl::Event::Shared" = type <{ %"class.marl::mutex", %"class.marl::ConditionVariable", %"class.marl::containers::vector", i8, i8, [6 x i8] }>
%"class.marl::containers::vector" = type { %"class.marl::Allocator"*, i64, i64, [1 x %"struct.marl::aligned_storage<16, 8>::type"], %"struct.marl::aligned_storage<16, 8>::type"*, %"struct.marl::Allocation" }
%"struct.marl::aligned_storage<16, 8>::type" = type { [16 x i8] }
%"struct.std::__1::atomic.52" = type { %"struct.std::__1::__atomic_base.53" }
%"struct.std::__1::__atomic_base.53" = type { %"struct.std::__1::__cxx_atomic_impl.54" }
%"struct.std::__1::__cxx_atomic_impl.54" = type { %"struct.std::__1::__cxx_atomic_base_impl.55" }
%"struct.std::__1::__cxx_atomic_base_impl.55" = type { i32 }
%"struct.std::__1::atomic.56" = type { %"struct.std::__1::__atomic_base.57" }
%"struct.std::__1::__atomic_base.57" = type { %"struct.std::__1::__cxx_atomic_impl.58" }
%"struct.std::__1::__cxx_atomic_impl.58" = type { %"struct.std::__1::__cxx_atomic_base_impl.59" }
%"struct.std::__1::__cxx_atomic_base_impl.59" = type { i32 }
%"struct.std::__1::atomic.60" = type { %"struct.std::__1::__atomic_base.61" }
%"struct.std::__1::__atomic_base.61" = type { %"struct.std::__1::__atomic_base.62" }
%"struct.std::__1::__atomic_base.62" = type { %"struct.std::__1::__cxx_atomic_impl.63" }
%"struct.std::__1::__cxx_atomic_impl.63" = type { %"struct.std::__1::__cxx_atomic_base_impl.64" }
%"struct.std::__1::__cxx_atomic_base_impl.64" = type { i64 }
%"class.marl::Ticket::Queue" = type { %"class.std::__1::shared_ptr.65", %"class.marl::UnboundedPool" }
%"class.std::__1::shared_ptr.65" = type { %"struct.marl::Ticket::Shared"*, %"class.std::__1::__shared_weak_count"* }
%"struct.marl::Ticket::Shared" = type { %"class.marl::mutex", %"struct.marl::Ticket::Record" }
%"struct.marl::Ticket::Record" = type <{ %"class.marl::ConditionVariable", %"class.std::__1::shared_ptr.65", %"struct.marl::Ticket::Record"*, %"struct.marl::Ticket::Record"*, %"class.std::__1::function.210", i8, %"struct.std::__1::atomic.431", [6 x i8] }>
%"struct.std::__1::atomic.431" = type { %"struct.std::__1::__atomic_base.432" }
%"struct.std::__1::__atomic_base.432" = type { %"struct.std::__1::__cxx_atomic_impl.433" }
%"struct.std::__1::__cxx_atomic_impl.433" = type { %"struct.std::__1::__cxx_atomic_base_impl.434" }
%"struct.std::__1::__cxx_atomic_base_impl.434" = type { i8 }
%"class.marl::UnboundedPool" = type { %"class.marl::Allocator"*, %"class.std::__1::shared_ptr.68" }
%"class.std::__1::shared_ptr.68" = type { %"class.marl::UnboundedPool<marl::Ticket::Record, marl::PoolPolicy::Reconstruct>::Storage"*, %"class.std::__1::__shared_weak_count"* }
%"class.marl::UnboundedPool<marl::Ticket::Record, marl::PoolPolicy::Reconstruct>::Storage" = type { %"class.marl::Pool<marl::Ticket::Record>::Storage", %"class.marl::Allocator"*, %"class.marl::mutex", %"class.marl::containers::vector.437", %"struct.marl::Pool<marl::Ticket::Record>::Item"* }
%"class.marl::Pool<marl::Ticket::Record>::Storage" = type { i32 (...)** }
%"class.marl::containers::vector.437" = type { %"class.marl::Allocator"*, i64, i64, [4 x %"struct.marl::aligned_storage<8, 8>::type"], %"struct.marl::aligned_storage<8, 8>::type"*, %"struct.marl::Allocation" }
%"struct.marl::aligned_storage<8, 8>::type" = type { [8 x i8] }
%"struct.marl::Pool<marl::Ticket::Record>::Item" = type { %"struct.marl::aligned_storage<216, 8>::type", %"struct.std::__1::atomic", %"struct.marl::Pool<marl::Ticket::Record>::Item"* }
%"struct.marl::aligned_storage<216, 8>::type" = type { [216 x i8] }
%"class.sw::VertexProcessor" = type { %"class.std::__1::unique_ptr.69" }
%"class.std::__1::unique_ptr.69" = type { %"class.std::__1::__compressed_pair.70" }
%"class.std::__1::__compressed_pair.70" = type { %"struct.std::__1::__compressed_pair_elem.71" }
%"struct.std::__1::__compressed_pair_elem.71" = type { %"class.sw::LRUCache"* }
%"class.sw::LRUCache" = type opaque
%"class.sw::PixelProcessor" = type { %"struct.sw::PixelProcessor::Factor", %"class.std::__1::unique_ptr.78", [8 x i8] }
%"struct.sw::PixelProcessor::Factor" = type { %"struct.sw::vec", [4 x %"struct.sw::vec"], [8 x i8], [4 x %"struct.sw::vec.75"], [4 x %"struct.sw::vec"], [4 x %"struct.sw::vec.75"] }
%"struct.sw::vec" = type { %union.anon.73 }
%union.anon.73 = type { [4 x i16] }
%"struct.sw::vec.75" = type { %union.anon.76 }
%union.anon.76 = type { [4 x float] }
%"class.std::__1::unique_ptr.78" = type { %"class.std::__1::__compressed_pair.79" }
%"class.std::__1::__compressed_pair.79" = type { %"struct.std::__1::__compressed_pair_elem.80" }
%"struct.std::__1::__compressed_pair_elem.80" = type { %"class.sw::LRUCache.81"* }
%"class.sw::LRUCache.81" = type opaque
%"class.sw::SetupProcessor" = type { %"class.std::__1::unique_ptr.85" }
%"class.std::__1::unique_ptr.85" = type { %"class.std::__1::__compressed_pair.86" }
%"class.std::__1::__compressed_pair.86" = type { %"struct.std::__1::__compressed_pair_elem.87" }
%"struct.std::__1::__compressed_pair_elem.87" = type { %"class.sw::LRUCache.88"* }
%"class.sw::LRUCache.88" = type opaque
%"struct.sw::VertexProcessor::State" = type { %"struct.sw::VertexProcessor::States.base", i32, [4 x i8] }
%"struct.sw::VertexProcessor::States.base" = type <{ i64, i32, [32 x %"struct.sw::VertexProcessor::States::Input"], i8 }>
%"struct.sw::VertexProcessor::States::Input" = type { i32, i8 }
%"struct.sw::SetupProcessor::State" = type { %"struct.sw::SetupProcessor::States.base", i32 }
%"struct.sw::SetupProcessor::States.base" = type <{ i16, [2 x i8], i32, i32, i16, [128 x %"struct.sw::SpirvShader::InterfaceComponent"] }>
%"struct.sw::SpirvShader::InterfaceComponent" = type { i8, %union.anon.94 }
%union.anon.94 = type { %struct.anon.95 }
%struct.anon.95 = type { i8 }
%"struct.sw::PixelProcessor::State" = type <{ %"struct.sw::PixelProcessor::States", i32, [4 x i8] }>
%"struct.sw::PixelProcessor::States" = type { i64, i32, i32, i32, i32, i8, i8, %"struct.sw::PixelProcessor::States::StencilOpState", %"struct.sw::PixelProcessor::States::StencilOpState", i8, i8, i8, i8, [8 x %"struct.vk::BlendState"], i32, [8 x %"class.vk::Format"], i32, i32, i8, i8, i8, i8, float, float, float, i32, %"class.vk::Format", i8, i8, float, float }
%"struct.sw::PixelProcessor::States::StencilOpState" = type { i32, i32, i32, i32, i32, i32 }
%"struct.vk::BlendState" = type { i8, i32, i32, i32, i32, i32, i32 }
%"class.rr::RoutineT" = type { %"class.std::__1::shared_ptr.100", void (%"struct.sw::Vertex"*, i32*, %"struct.sw::VertexTask"*, %"struct.sw::DrawData"*)* }
%"class.std::__1::shared_ptr.100" = type { %"class.rr::Routine"*, %"class.std::__1::__shared_weak_count"* }
%"class.rr::Routine" = type { i32 (...)** }
%"struct.sw::Vertex" = type { %union.anon.101, float, i32, i32, [8 x float], [8 x float], [4 x i8], %struct.anon.103, [128 x float] }
%union.anon.101 = type { %struct.anon.102 }
%struct.anon.102 = type { float, float, float, float }
%struct.anon.103 = type { i32, i32, float, float }
%"struct.sw::VertexTask" = type { i32, i32, [8 x i8], %"struct.sw::VertexCache" }
%"struct.sw::VertexCache" = type { [64 x %"struct.sw::Vertex"], [64 x i32], i32, [12 x i8] }
%"struct.sw::DrawData" = type { %"struct.sw::Constants"*, %"struct.std::__1::array", %"struct.std::__1::array.104", [32 x i8*], [32 x i32], [32 x i32], i8*, i32, i32, float, i32, [2 x %"struct.sw::PixelProcessor::Stencil"], %"struct.sw::PixelProcessor::Factor", [16 x i32], %"struct.sw::vec.75", %"struct.sw::vec.75", %"struct.sw::vec.75", %"struct.sw::vec.75", %"struct.sw::vec.75", %"struct.sw::vec.75", float, float, float, float, float, float, float, i8, [8 x i32*], [8 x i32], [8 x i32], float*, i32, i32, i8*, i32, i32, i32, i32, i32, i32, %"struct.sw::vec.75", %"struct.sw::vec.75", %"struct.sw::vec.75", %"struct.sw::vec.75", %"struct.vk::Pipeline::PushConstantStorage" }
%"struct.sw::Constants" = type opaque
%"struct.std::__1::array" = type { [4 x i8*] }
%"struct.std::__1::array.104" = type { [12 x i32] }
%"struct.sw::PixelProcessor::Stencil" = type { i64, i64, i64, i64, i64, i64 }
%"struct.vk::Pipeline::PushConstantStorage" = type { [128 x i8] }
%"class.rr::RoutineT.105" = type { %"class.std::__1::shared_ptr.100", i32 (%"struct.sw::Primitive"*, %"struct.sw::Triangle"*, %"struct.sw::Polygon"*, %"struct.sw::DrawData"*)* }
%"struct.sw::Primitive" = type { i32, i32, [8 x i8], %"struct.sw::vec.75", %"struct.sw::vec.75", float, float, float, [4 x i8], %"struct.sw::PlaneEquation", %"struct.sw::vec.75", %"struct.sw::PlaneEquation", [128 x %"struct.sw::PlaneEquation"], [8 x %"struct.sw::PlaneEquation"], [8 x %"struct.sw::PlaneEquation"], i64, i64, [2 x %"struct.sw::Primitive::Span"], [8192 x %"struct.sw::Primitive::Span"], [2 x %"struct.sw::Primitive::Span"] }
%"struct.sw::PlaneEquation" = type { %"struct.sw::vec.75", %"struct.sw::vec.75", %"struct.sw::vec.75" }
%"struct.sw::Primitive::Span" = type { i16, i16 }
%"struct.sw::Triangle" = type { %"struct.sw::Vertex", %"struct.sw::Vertex", %"struct.sw::Vertex" }
%"struct.sw::Polygon" = type opaque
%"class.rr::RoutineT.106" = type { %"class.std::__1::shared_ptr.100", void (%"struct.sw::Primitive"*, i32, i32, i32, %"struct.sw::DrawData"*)* }
%"class.sw::Chan" = type { %"class.marl::mutex", %"class.std::__1::queue", %"class.std::__1::condition_variable" }
%"class.std::__1::queue" = type { %"class.std::__1::deque" }
%"class.std::__1::deque" = type { %"class.std::__1::__deque_base" }
%"class.std::__1::__deque_base" = type { %"struct.std::__1::__split_buffer", i64, %"class.std::__1::__compressed_pair.114" }
%"struct.std::__1::__split_buffer" = type { %"struct.vk::Queue::Task"**, %"struct.vk::Queue::Task"**, %"struct.vk::Queue::Task"**, %"class.std::__1::__compressed_pair.111" }
%"struct.vk::Queue::Task" = type <{ i32, [4 x i8], %struct.VkSubmitInfo*, %"class.std::__1::shared_ptr.110", i32, [4 x i8] }>
%struct.VkSubmitInfo = type { i32, i8*, i32, %class.VkNonDispatchableHandle.1*, i32*, i32, %struct.VkCommandBuffer_T**, i32, %class.VkNonDispatchableHandle.1* }
%struct.VkCommandBuffer_T = type opaque
%"class.std::__1::shared_ptr.110" = type { %"class.sw::CountedEvent"*, %"class.std::__1::__shared_weak_count"* }
%"class.sw::CountedEvent" = type { %"class.marl::WaitGroup", %"class.marl::Event" }
%"class.std::__1::__compressed_pair.111" = type { %"struct.std::__1::__compressed_pair_elem.112" }
%"struct.std::__1::__compressed_pair_elem.112" = type { %"struct.vk::Queue::Task"** }
%"class.std::__1::__compressed_pair.114" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.sw::Chan.119" = type { %"class.marl::mutex", %"class.std::__1::queue.120", %"class.std::__1::condition_variable" }
%"class.std::__1::queue.120" = type { %"class.std::__1::deque.121" }
%"class.std::__1::deque.121" = type { %"class.std::__1::__deque_base.122" }
%"class.std::__1::__deque_base.122" = type { %"struct.std::__1::__split_buffer.123", i64, %"class.std::__1::__compressed_pair.129" }
%"struct.std::__1::__split_buffer.123" = type { %struct.VkSubmitInfo***, %struct.VkSubmitInfo***, %struct.VkSubmitInfo***, %"class.std::__1::__compressed_pair.124" }
%"class.std::__1::__compressed_pair.124" = type { %"struct.std::__1::__compressed_pair_elem.125" }
%"struct.std::__1::__compressed_pair_elem.125" = type { %struct.VkSubmitInfo*** }
%"class.std::__1::__compressed_pair.129" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::thread" = type { i64 }
%"class.std::__1::unique_ptr.133" = type { %"class.std::__1::__compressed_pair.134" }
%"class.std::__1::__compressed_pair.134" = type { %"struct.std::__1::__compressed_pair_elem.135" }
%"struct.std::__1::__compressed_pair_elem.135" = type { %"class.sw::Blitter"* }
%"class.sw::Blitter" = type { i32 (...)**, %"class.marl::mutex", %"class.sw::LRUCache.136", %"class.marl::mutex", %"class.sw::LRUCache.159" }
%"class.sw::LRUCache.136" = type { %"class.std::__1::vector", %"class.std::__1::unordered_set", %"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::BlitData *)>, std::__1::hash<sw::Blitter::State> >::Entry"*, %"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::BlitData *)>, std::__1::hash<sw::Blitter::State> >::Entry"*, %"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::BlitData *)>, std::__1::hash<sw::Blitter::State> >::Entry"* }
%"class.std::__1::vector" = type { %"class.std::__1::__vector_base" }
%"class.std::__1::__vector_base" = type { %"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::BlitData *)>, std::__1::hash<sw::Blitter::State> >::Entry"*, %"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::BlitData *)>, std::__1::hash<sw::Blitter::State> >::Entry"*, %"class.std::__1::__compressed_pair.137" }
%"class.std::__1::__compressed_pair.137" = type { %"struct.std::__1::__compressed_pair_elem.138" }
%"struct.std::__1::__compressed_pair_elem.138" = type { %"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::BlitData *)>, std::__1::hash<sw::Blitter::State> >::Entry"* }
%"class.std::__1::unordered_set" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr.142", %"class.std::__1::__compressed_pair.150", %"class.std::__1::__compressed_pair.155", %"class.std::__1::__compressed_pair.157", [4 x i8] }>
%"class.std::__1::unique_ptr.142" = type { %"class.std::__1::__compressed_pair.143" }
%"class.std::__1::__compressed_pair.143" = type { %"struct.std::__1::__compressed_pair_elem.144", %"struct.std::__1::__compressed_pair_elem.145" }
%"struct.std::__1::__compressed_pair_elem.144" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.145" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.146" }
%"class.std::__1::__compressed_pair.146" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.150" = type { %"struct.std::__1::__compressed_pair_elem.151" }
%"struct.std::__1::__compressed_pair_elem.151" = type { %"struct.std::__1::__hash_node_base" }
%"class.std::__1::__compressed_pair.155" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.157" = type { %"struct.std::__1::__compressed_pair_elem.158" }
%"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::BlitData *)>, std::__1::hash<sw::Blitter::State> >::Entry" = type opaque
%"class.sw::LRUCache.159" = type { %"class.std::__1::vector.160", %"class.std::__1::unordered_set.167", %"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::CubeBorderData *)>, std::__1::hash<sw::Blitter::State> >::Entry"*, %"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::CubeBorderData *)>, std::__1::hash<sw::Blitter::State> >::Entry"*, %"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::CubeBorderData *)>, std::__1::hash<sw::Blitter::State> >::Entry"* }
%"class.std::__1::vector.160" = type { %"class.std::__1::__vector_base.161" }
%"class.std::__1::__vector_base.161" = type { %"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::CubeBorderData *)>, std::__1::hash<sw::Blitter::State> >::Entry"*, %"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::CubeBorderData *)>, std::__1::hash<sw::Blitter::State> >::Entry"*, %"class.std::__1::__compressed_pair.162" }
%"class.std::__1::__compressed_pair.162" = type { %"struct.std::__1::__compressed_pair_elem.163" }
%"struct.std::__1::__compressed_pair_elem.163" = type { %"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::CubeBorderData *)>, std::__1::hash<sw::Blitter::State> >::Entry"* }
%"class.std::__1::unordered_set.167" = type { %"class.std::__1::__hash_table.168" }
%"class.std::__1::__hash_table.168" = type <{ %"class.std::__1::unique_ptr.169", %"class.std::__1::__compressed_pair.179", %"class.std::__1::__compressed_pair.184", %"class.std::__1::__compressed_pair.186", [4 x i8] }>
%"class.std::__1::unique_ptr.169" = type { %"class.std::__1::__compressed_pair.170" }
%"class.std::__1::__compressed_pair.170" = type { %"struct.std::__1::__compressed_pair_elem.171", %"struct.std::__1::__compressed_pair_elem.173" }
%"struct.std::__1::__compressed_pair_elem.171" = type { %"struct.std::__1::__hash_node_base.172"** }
%"struct.std::__1::__hash_node_base.172" = type { %"struct.std::__1::__hash_node_base.172"* }
%"struct.std::__1::__compressed_pair_elem.173" = type { %"class.std::__1::__bucket_list_deallocator.174" }
%"class.std::__1::__bucket_list_deallocator.174" = type { %"class.std::__1::__compressed_pair.175" }
%"class.std::__1::__compressed_pair.175" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.179" = type { %"struct.std::__1::__compressed_pair_elem.180" }
%"struct.std::__1::__compressed_pair_elem.180" = type { %"struct.std::__1::__hash_node_base.172" }
%"class.std::__1::__compressed_pair.184" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.186" = type { %"struct.std::__1::__compressed_pair_elem.158" }
%"struct.sw::LRUCache<sw::Blitter::State, rr::RoutineT<void (const sw::Blitter::CubeBorderData *)>, std::__1::hash<sw::Blitter::State> >::Entry" = type opaque
%struct.VkPhysicalDeviceFeatures = type { i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32 }
%"class.std::__1::shared_ptr.191" = type { %"class.marl::Scheduler"*, %"class.std::__1::__shared_weak_count"* }
%"class.std::__1::unique_ptr.305" = type { %"class.std::__1::__compressed_pair.306" }
%"class.std::__1::__compressed_pair.306" = type { %"struct.std::__1::__compressed_pair_elem.307" }
%"struct.std::__1::__compressed_pair_elem.307" = type { %"class.vk::Device::SamplingRoutineCache"* }
%"class.vk::Device::SamplingRoutineCache" = type { i8, [7 x i8], %"class.std::__1::unordered_map.308", %"class.marl::mutex", %"class.sw::LRUCache.334" }
%"class.std::__1::unordered_map.308" = type { %"class.std::__1::__hash_table.309" }
%"class.std::__1::__hash_table.309" = type <{ %"class.std::__1::unique_ptr.310", %"class.std::__1::__compressed_pair.320", %"class.std::__1::__compressed_pair.325", %"class.std::__1::__compressed_pair.328", [4 x i8] }>
%"class.std::__1::unique_ptr.310" = type { %"class.std::__1::__compressed_pair.311" }
%"class.std::__1::__compressed_pair.311" = type { %"struct.std::__1::__compressed_pair_elem.312", %"struct.std::__1::__compressed_pair_elem.314" }
%"struct.std::__1::__compressed_pair_elem.312" = type { %"struct.std::__1::__hash_node_base.313"** }
%"struct.std::__1::__hash_node_base.313" = type { %"struct.std::__1::__hash_node_base.313"* }
%"struct.std::__1::__compressed_pair_elem.314" = type { %"class.std::__1::__bucket_list_deallocator.315" }
%"class.std::__1::__bucket_list_deallocator.315" = type { %"class.std::__1::__compressed_pair.316" }
%"class.std::__1::__compressed_pair.316" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.320" = type { %"struct.std::__1::__compressed_pair_elem.321" }
%"struct.std::__1::__compressed_pair_elem.321" = type { %"struct.std::__1::__hash_node_base.313" }
%"class.std::__1::__compressed_pair.325" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.328" = type { %"struct.std::__1::__compressed_pair_elem.158" }
%"class.sw::LRUCache.334" = type { %"class.std::__1::vector.335", %"class.std::__1::unordered_set.342", %"struct.sw::LRUCache<vk::Device::SamplingRoutineCache::Key, std::__1::shared_ptr<rr::Routine>, vk::Device::SamplingRoutineCache::Key::Hash>::Entry"*, %"struct.sw::LRUCache<vk::Device::SamplingRoutineCache::Key, std::__1::shared_ptr<rr::Routine>, vk::Device::SamplingRoutineCache::Key::Hash>::Entry"*, %"struct.sw::LRUCache<vk::Device::SamplingRoutineCache::Key, std::__1::shared_ptr<rr::Routine>, vk::Device::SamplingRoutineCache::Key::Hash>::Entry"* }
%"class.std::__1::vector.335" = type { %"class.std::__1::__vector_base.336" }
%"class.std::__1::__vector_base.336" = type { %"struct.sw::LRUCache<vk::Device::SamplingRoutineCache::Key, std::__1::shared_ptr<rr::Routine>, vk::Device::SamplingRoutineCache::Key::Hash>::Entry"*, %"struct.sw::LRUCache<vk::Device::SamplingRoutineCache::Key, std::__1::shared_ptr<rr::Routine>, vk::Device::SamplingRoutineCache::Key::Hash>::Entry"*, %"class.std::__1::__compressed_pair.337" }
%"class.std::__1::__compressed_pair.337" = type { %"struct.std::__1::__compressed_pair_elem.338" }
%"struct.std::__1::__compressed_pair_elem.338" = type { %"struct.sw::LRUCache<vk::Device::SamplingRoutineCache::Key, std::__1::shared_ptr<rr::Routine>, vk::Device::SamplingRoutineCache::Key::Hash>::Entry"* }
%"class.std::__1::unordered_set.342" = type { %"class.std::__1::__hash_table.343" }
%"class.std::__1::__hash_table.343" = type <{ %"class.std::__1::unique_ptr.344", %"class.std::__1::__compressed_pair.354", %"class.std::__1::__compressed_pair.359", %"class.std::__1::__compressed_pair.361", [4 x i8] }>
%"class.std::__1::unique_ptr.344" = type { %"class.std::__1::__compressed_pair.345" }
%"class.std::__1::__compressed_pair.345" = type { %"struct.std::__1::__compressed_pair_elem.346", %"struct.std::__1::__compressed_pair_elem.348" }
%"struct.std::__1::__compressed_pair_elem.346" = type { %"struct.std::__1::__hash_node_base.347"** }
%"struct.std::__1::__hash_node_base.347" = type { %"struct.std::__1::__hash_node_base.347"* }
%"struct.std::__1::__compressed_pair_elem.348" = type { %"class.std::__1::__bucket_list_deallocator.349" }
%"class.std::__1::__bucket_list_deallocator.349" = type { %"class.std::__1::__compressed_pair.350" }
%"class.std::__1::__compressed_pair.350" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.354" = type { %"struct.std::__1::__compressed_pair_elem.355" }
%"struct.std::__1::__compressed_pair_elem.355" = type { %"struct.std::__1::__hash_node_base.347" }
%"class.std::__1::__compressed_pair.359" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.361" = type { %"struct.std::__1::__compressed_pair_elem.158" }
%"struct.sw::LRUCache<vk::Device::SamplingRoutineCache::Key, std::__1::shared_ptr<rr::Routine>, vk::Device::SamplingRoutineCache::Key::Hash>::Entry" = type { %"struct.sw::LRUCache<vk::Device::SamplingRoutineCache::Key, std::__1::shared_ptr<rr::Routine>, vk::Device::SamplingRoutineCache::Key::Hash>::Keyed", %"class.std::__1::shared_ptr.100", %"struct.sw::LRUCache<vk::Device::SamplingRoutineCache::Key, std::__1::shared_ptr<rr::Routine>, vk::Device::SamplingRoutineCache::Key::Hash>::Entry"*, %"struct.sw::LRUCache<vk::Device::SamplingRoutineCache::Key, std::__1::shared_ptr<rr::Routine>, vk::Device::SamplingRoutineCache::Key::Hash>::Entry"* }
%"struct.sw::LRUCache<vk::Device::SamplingRoutineCache::Key, std::__1::shared_ptr<rr::Routine>, vk::Device::SamplingRoutineCache::Key::Hash>::Keyed" = type { %"struct.vk::Device::SamplingRoutineCache::Key" }
%"struct.vk::Device::SamplingRoutineCache::Key" = type { i32, i32, i32 }
%"class.std::__1::unique_ptr.366" = type { %"class.std::__1::__compressed_pair.367" }
%"class.std::__1::__compressed_pair.367" = type { %"struct.std::__1::__compressed_pair_elem.368" }
%"struct.std::__1::__compressed_pair_elem.368" = type { %"class.vk::Device::SamplerIndexer"* }
%"class.vk::Device::SamplerIndexer" = type <{ %"class.marl::mutex", %"class.std::__1::map", i32, [4 x i8] }>
%"class.std::__1::map" = type { %"class.std::__1::__tree.369" }
%"class.std::__1::__tree.369" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.370", %"class.std::__1::__compressed_pair.374" }
%"class.std::__1::__compressed_pair.370" = type { %"struct.std::__1::__compressed_pair_elem.232" }
%"class.std::__1::__compressed_pair.374" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::unordered_set.381" = type { %"class.std::__1::__hash_table.382" }
%"class.std::__1::__hash_table.382" = type <{ %"class.std::__1::unique_ptr.383", %"class.std::__1::__compressed_pair.393", %"class.std::__1::__compressed_pair.398", %"class.std::__1::__compressed_pair.402", [4 x i8] }>
%"class.std::__1::unique_ptr.383" = type { %"class.std::__1::__compressed_pair.384" }
%"class.std::__1::__compressed_pair.384" = type { %"struct.std::__1::__compressed_pair_elem.385", %"struct.std::__1::__compressed_pair_elem.387" }
%"struct.std::__1::__compressed_pair_elem.385" = type { %"struct.std::__1::__hash_node_base.386"** }
%"struct.std::__1::__hash_node_base.386" = type { %"struct.std::__1::__hash_node_base.386"* }
%"struct.std::__1::__compressed_pair_elem.387" = type { %"class.std::__1::__bucket_list_deallocator.388" }
%"class.std::__1::__bucket_list_deallocator.388" = type { %"class.std::__1::__compressed_pair.389" }
%"class.std::__1::__compressed_pair.389" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.393" = type { %"struct.std::__1::__compressed_pair_elem.394" }
%"struct.std::__1::__compressed_pair_elem.394" = type { %"struct.std::__1::__hash_node_base.386" }
%"class.std::__1::__compressed_pair.398" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.402" = type { %"struct.std::__1::__compressed_pair_elem.158" }
%"class.vk::Format" = type { i32 }
%struct.VkExtent3D = type { i32, i32, i32 }
%"class.marl::mutex" = type { %"class.std::__1::mutex" }
%"class.std::__1::mutex" = type { %union.pthread_mutex_t }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"class.std::__1::unordered_set.407" = type { %"class.std::__1::__hash_table.408" }
%"class.std::__1::__hash_table.408" = type <{ %"class.std::__1::unique_ptr.409", %"class.std::__1::__compressed_pair.419", %"class.std::__1::__compressed_pair.424", %"class.std::__1::__compressed_pair.426", [4 x i8] }>
%"class.std::__1::unique_ptr.409" = type { %"class.std::__1::__compressed_pair.410" }
%"class.std::__1::__compressed_pair.410" = type { %"struct.std::__1::__compressed_pair_elem.411", %"struct.std::__1::__compressed_pair_elem.413" }
%"struct.std::__1::__compressed_pair_elem.411" = type { %"struct.std::__1::__hash_node_base.412"** }
%"struct.std::__1::__hash_node_base.412" = type { %"struct.std::__1::__hash_node_base.412"* }
%"struct.std::__1::__compressed_pair_elem.413" = type { %"class.std::__1::__bucket_list_deallocator.414" }
%"class.std::__1::__bucket_list_deallocator.414" = type { %"class.std::__1::__compressed_pair.415" }
%"class.std::__1::__compressed_pair.415" = type { %"struct.std::__1::__compressed_pair_elem.115" }
%"class.std::__1::__compressed_pair.419" = type { %"struct.std::__1::__compressed_pair_elem.420" }
%"struct.std::__1::__compressed_pair_elem.420" = type { %"struct.std::__1::__hash_node_base.412" }
%"class.std::__1::__compressed_pair.424" = type <{ %"struct.std::__1::__compressed_pair_elem.115", %"struct.std::__1::__compressed_pair_elem.425", [4 x i8] }>
%"struct.std::__1::__compressed_pair_elem.425" = type { %"class.vk::Image::Subresource" }
%"class.vk::Image::Subresource" = type { %struct.VkImageSubresource }
%struct.VkImageSubresource = type { i32, i32, i32 }
%"class.std::__1::__compressed_pair.426" = type { %"struct.std::__1::__compressed_pair_elem.158" }
%"class.vk::DeviceMemory" = type { i8*, i64, i32, %"class.vk::DeviceMemory::ExternalBase"*, %"class.vk::Device"* }
%"class.vk::DeviceMemory::ExternalBase" = type opaque
%struct.VkDevice_T = type opaque
%struct.VkImageCreateInfo = type { i32, i8*, i32, i32, i32, %struct.VkExtent3D, i32, i32, i32, i32, i32, i32, i32, i32*, i32 }
%struct.VkAllocationCallbacks = type { i8*, i8* (i8*, i64, i64, i32)*, i8* (i8*, i8*, i64, i64, i32)*, void (i8*, i8*)*, void (i8*, i64, i32, i32)*, void (i8*, i64, i32, i32)* }
%struct.VkMemoryAllocateInfo = type { i32, i8*, i64, i32 }
%"class.vk::SurfaceKHR" = type { i32 (...)**, %"class.vk::SwapchainKHR"* }
%"class.vk::SwapchainKHR" = type <{ %"class.vk::SurfaceKHR"*, %"class.vk::PresentImage"*, i32, i8, [3 x i8] }>
%struct.VkRect2D = type { %struct.VkOffset2D, %struct.VkExtent2D }
%struct.VkOffset2D = type { i32, i32 }
%struct.VkExtent2D = type { i32, i32 }
%struct.VkSurfaceCapabilitiesKHR = type { i32, i32, %struct.VkExtent2D, %struct.VkExtent2D, %struct.VkExtent2D, i32, i32, i32, i32, i32 }

$_ZNK23VkNonDispatchableHandleIP10VkBuffer_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP10VkBuffer_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkImage_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkImage_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkSemaphore_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkSemaphore_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkFence_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkFence_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkDeviceMemory_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkDeviceMemory_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkEvent_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkEvent_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkQueryPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkQueryPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkBufferView_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkBufferView_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkImageView_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkImageView_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkShaderModule_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkShaderModule_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkPipelineCache_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkPipelineCache_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkPipelineLayout_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkPipelineLayout_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP12VkPipeline_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP12VkPipeline_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkRenderPass_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkRenderPass_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP11VkSampler_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP11VkSampler_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkDescriptorSet_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkDescriptorSet_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkDescriptorPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkDescriptorPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkFramebuffer_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkFramebuffer_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkCommandPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkCommandPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkSurfaceKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkSurfaceKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkSwapchainKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkSwapchainKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkDisplayKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkDisplayKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkCuModuleNVX_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkCuModuleNVX_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEaSEm = comdat any

$_ZNSt3__112__hash_tableIN2vk5Image11SubresourceES3_NS_8equal_toIS3_EENS_9allocatorIS3_EEED2Ev = comdat any

@_ZN12_GLOBAL__N_114surfaceFormatsE = internal unnamed_addr constant [2 x %struct.VkSurfaceFormatKHR] [%struct.VkSurfaceFormatKHR { i32 44, i32 0 }, %struct.VkSurfaceFormatKHR { i32 50, i32 0 }], align 16
@_ZN12_GLOBAL__N_112presentModesE = internal unnamed_addr constant [2 x i32] [i32 2, i32 1], align 4

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP10VkBuffer_TEcvPvEv(%class.VkNonDispatchableHandle*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP10VkBuffer_TEaSEm(%class.VkNonDispatchableHandle*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle, %class.VkNonDispatchableHandle* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkImage_TEcvPvEv(%class.VkNonDispatchableHandle.0*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.0* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkImage_TEaSEm(%class.VkNonDispatchableHandle.0*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.0, %class.VkNonDispatchableHandle.0* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkSemaphore_TEcvPvEv(%class.VkNonDispatchableHandle.1*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.1* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkSemaphore_TEaSEm(%class.VkNonDispatchableHandle.1*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.1, %class.VkNonDispatchableHandle.1* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkFence_TEcvPvEv(%class.VkNonDispatchableHandle.2*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.2* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkFence_TEaSEm(%class.VkNonDispatchableHandle.2*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.2, %class.VkNonDispatchableHandle.2* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkDeviceMemory_TEcvPvEv(%class.VkNonDispatchableHandle.3*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.3* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkDeviceMemory_TEaSEm(%class.VkNonDispatchableHandle.3*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.3, %class.VkNonDispatchableHandle.3* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkEvent_TEcvPvEv(%class.VkNonDispatchableHandle.4*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.4* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkEvent_TEaSEm(%class.VkNonDispatchableHandle.4*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.4, %class.VkNonDispatchableHandle.4* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkQueryPool_TEcvPvEv(%class.VkNonDispatchableHandle.5*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.5* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkQueryPool_TEaSEm(%class.VkNonDispatchableHandle.5*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.5, %class.VkNonDispatchableHandle.5* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkBufferView_TEcvPvEv(%class.VkNonDispatchableHandle.6*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.6* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkBufferView_TEaSEm(%class.VkNonDispatchableHandle.6*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.6, %class.VkNonDispatchableHandle.6* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkImageView_TEcvPvEv(%class.VkNonDispatchableHandle.7*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.7* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkImageView_TEaSEm(%class.VkNonDispatchableHandle.7*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.7, %class.VkNonDispatchableHandle.7* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkShaderModule_TEcvPvEv(%class.VkNonDispatchableHandle.8*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.8* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkShaderModule_TEaSEm(%class.VkNonDispatchableHandle.8*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.8, %class.VkNonDispatchableHandle.8* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkPipelineCache_TEcvPvEv(%class.VkNonDispatchableHandle.9*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.9* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkPipelineCache_TEaSEm(%class.VkNonDispatchableHandle.9*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.9, %class.VkNonDispatchableHandle.9* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkPipelineLayout_TEcvPvEv(%class.VkNonDispatchableHandle.10*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.10* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkPipelineLayout_TEaSEm(%class.VkNonDispatchableHandle.10*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.10, %class.VkNonDispatchableHandle.10* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP12VkPipeline_TEcvPvEv(%class.VkNonDispatchableHandle.11*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.11* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP12VkPipeline_TEaSEm(%class.VkNonDispatchableHandle.11*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.11, %class.VkNonDispatchableHandle.11* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkRenderPass_TEcvPvEv(%class.VkNonDispatchableHandle.12*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.12* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkRenderPass_TEaSEm(%class.VkNonDispatchableHandle.12*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.12, %class.VkNonDispatchableHandle.12* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEcvPvEv(%class.VkNonDispatchableHandle.13*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.13* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEaSEm(%class.VkNonDispatchableHandle.13*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.13, %class.VkNonDispatchableHandle.13* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP11VkSampler_TEcvPvEv(%class.VkNonDispatchableHandle.14*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.14* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP11VkSampler_TEaSEm(%class.VkNonDispatchableHandle.14*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.14, %class.VkNonDispatchableHandle.14* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkDescriptorSet_TEcvPvEv(%class.VkNonDispatchableHandle.15*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.15* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkDescriptorSet_TEaSEm(%class.VkNonDispatchableHandle.15*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.15, %class.VkNonDispatchableHandle.15* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkDescriptorPool_TEcvPvEv(%class.VkNonDispatchableHandle.16*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.16* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkDescriptorPool_TEaSEm(%class.VkNonDispatchableHandle.16*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.16, %class.VkNonDispatchableHandle.16* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkFramebuffer_TEcvPvEv(%class.VkNonDispatchableHandle.17*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.17* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkFramebuffer_TEaSEm(%class.VkNonDispatchableHandle.17*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.17, %class.VkNonDispatchableHandle.17* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkCommandPool_TEcvPvEv(%class.VkNonDispatchableHandle.18*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.18* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkCommandPool_TEaSEm(%class.VkNonDispatchableHandle.18*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.18, %class.VkNonDispatchableHandle.18* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEcvPvEv(%class.VkNonDispatchableHandle.19*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.19* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEaSEm(%class.VkNonDispatchableHandle.19*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.19, %class.VkNonDispatchableHandle.19* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEcvPvEv(%class.VkNonDispatchableHandle.20*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.20* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEaSEm(%class.VkNonDispatchableHandle.20*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.20, %class.VkNonDispatchableHandle.20* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkSurfaceKHR_TEcvPvEv(%class.VkNonDispatchableHandle.21*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.21* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkSurfaceKHR_TEaSEm(%class.VkNonDispatchableHandle.21*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.21, %class.VkNonDispatchableHandle.21* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkSwapchainKHR_TEcvPvEv(%class.VkNonDispatchableHandle.22*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.22* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkSwapchainKHR_TEaSEm(%class.VkNonDispatchableHandle.22*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.22, %class.VkNonDispatchableHandle.22* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkDisplayKHR_TEcvPvEv(%class.VkNonDispatchableHandle.23*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.23* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkDisplayKHR_TEaSEm(%class.VkNonDispatchableHandle.23*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.23, %class.VkNonDispatchableHandle.23* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEcvPvEv(%class.VkNonDispatchableHandle.24*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.24* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEaSEm(%class.VkNonDispatchableHandle.24*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.24, %class.VkNonDispatchableHandle.24* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEcvPvEv(%class.VkNonDispatchableHandle.25*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.25* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEaSEm(%class.VkNonDispatchableHandle.25*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.25, %class.VkNonDispatchableHandle.25* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEcvPvEv(%class.VkNonDispatchableHandle.26*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.26* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEaSEm(%class.VkNonDispatchableHandle.26*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.26, %class.VkNonDispatchableHandle.26* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkCuModuleNVX_TEcvPvEv(%class.VkNonDispatchableHandle.27*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.27* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkCuModuleNVX_TEaSEm(%class.VkNonDispatchableHandle.27*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.27, %class.VkNonDispatchableHandle.27* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEcvPvEv(%class.VkNonDispatchableHandle.28*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.28* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEaSEm(%class.VkNonDispatchableHandle.28*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.28, %class.VkNonDispatchableHandle.28* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEcvPvEv(%class.VkNonDispatchableHandle.29*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.29* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEaSEm(%class.VkNonDispatchableHandle.29*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.29, %class.VkNonDispatchableHandle.29* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEcvPvEv(%class.VkNonDispatchableHandle.30*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.30* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEaSEm(%class.VkNonDispatchableHandle.30*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.30, %class.VkNonDispatchableHandle.30* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEcvPvEv(%class.VkNonDispatchableHandle.31*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.31* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEaSEm(%class.VkNonDispatchableHandle.31*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.31, %class.VkNonDispatchableHandle.31* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEcvPvEv(%class.VkNonDispatchableHandle.32*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.32* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEaSEm(%class.VkNonDispatchableHandle.32*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.32, %class.VkNonDispatchableHandle.32* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEcvPvEv(%class.VkNonDispatchableHandle.33*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.33* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEaSEm(%class.VkNonDispatchableHandle.33*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.33, %class.VkNonDispatchableHandle.33* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEcvPvEv(%class.VkNonDispatchableHandle.34*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.34* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEaSEm(%class.VkNonDispatchableHandle.34*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.34, %class.VkNonDispatchableHandle.34* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEcvPvEv(%class.VkNonDispatchableHandle.35*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.35* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEaSEm(%class.VkNonDispatchableHandle.35*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.35, %class.VkNonDispatchableHandle.35* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden i32 @_ZN2vk12PresentImage13allocateImageEP10VkDevice_TRK17VkImageCreateInfo(%"class.vk::PresentImage"* nocapture, %struct.VkDevice_T*, %struct.VkImageCreateInfo* dereferenceable(88)) local_unnamed_addr #0 align 2 {
  %4 = tail call i8* @_ZN2vk8allocateEmmPK21VkAllocationCallbacks23VkSystemAllocationScope(i64 8, i64 16, %struct.VkAllocationCallbacks* null, i32 1) #7
  %5 = icmp eq i8* %4, null
  br i1 %5, label %16, label %6

6:                                                ; preds = %3
  %7 = bitcast i8* %4 to %class.VkNonDispatchableHandle.0*
  %8 = tail call i32 @vkCreateImage(%struct.VkDevice_T* %1, %struct.VkImageCreateInfo* %2, %struct.VkAllocationCallbacks* null, %class.VkNonDispatchableHandle.0* nonnull %7) #7
  %9 = icmp eq i32 %8, 0
  br i1 %9, label %10, label %14

10:                                               ; preds = %6
  %11 = bitcast i8* %4 to i64*
  %12 = load i64, i64* %11, align 8
  %13 = bitcast %"class.vk::PresentImage"* %0 to i64*
  store i64 %12, i64* %13, align 8
  br label %14

14:                                               ; preds = %6, %10
  %15 = phi i32 [ 0, %10 ], [ %8, %6 ]
  tail call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* nonnull %4, %struct.VkAllocationCallbacks* null) #7
  br label %16

16:                                               ; preds = %14, %3
  %17 = phi i32 [ -2, %3 ], [ %15, %14 ]
  ret i32 %17
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: optsize
declare i8* @_ZN2vk8allocateEmmPK21VkAllocationCallbacks23VkSystemAllocationScope(i64, i64, %struct.VkAllocationCallbacks*, i32) local_unnamed_addr #2

; Function Attrs: optsize
declare i32 @vkCreateImage(%struct.VkDevice_T*, %struct.VkImageCreateInfo*, %struct.VkAllocationCallbacks*, %class.VkNonDispatchableHandle.0*) local_unnamed_addr #2

; Function Attrs: optsize
declare void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8*, %struct.VkAllocationCallbacks*) local_unnamed_addr #2

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind optsize ssp uwtable
define hidden i32 @_ZN2vk12PresentImage26allocateAndBindImageMemoryEP10VkDevice_TRK20VkMemoryAllocateInfo(%"class.vk::PresentImage"* nocapture, %struct.VkDevice_T*, %struct.VkMemoryAllocateInfo* dereferenceable(32)) local_unnamed_addr #0 align 2 {
  %4 = tail call i8* @_ZN2vk8allocateEmmPK21VkAllocationCallbacks23VkSystemAllocationScope(i64 8, i64 16, %struct.VkAllocationCallbacks* null, i32 1) #7
  %5 = icmp eq i8* %4, null
  br i1 %5, label %22, label %6

6:                                                ; preds = %3
  %7 = bitcast i8* %4 to %class.VkNonDispatchableHandle.3*
  %8 = tail call i32 @vkAllocateMemory(%struct.VkDevice_T* %1, %struct.VkMemoryAllocateInfo* %2, %struct.VkAllocationCallbacks* null, %class.VkNonDispatchableHandle.3* nonnull %7) #7
  %9 = icmp eq i32 %8, 0
  br i1 %9, label %10, label %20

10:                                               ; preds = %6
  %11 = bitcast i8* %4 to i64*
  %12 = load i64, i64* %11, align 8
  %13 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %0, i64 0, i32 1
  %14 = bitcast %"class.vk::DeviceMemory"** %13 to i64*
  store i64 %12, i64* %14, align 8
  %15 = bitcast %"class.vk::PresentImage"* %0 to i64*
  %16 = load i64, i64* %15, align 8
  %17 = load i64, i64* %11, align 8
  %18 = tail call i32 @vkBindImageMemory(%struct.VkDevice_T* %1, i64 %16, i64 %17, i64 0) #7
  %19 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %0, i64 0, i32 2
  store i32 1, i32* %19, align 8
  br label %20

20:                                               ; preds = %6, %10
  %21 = phi i32 [ 0, %10 ], [ %8, %6 ]
  tail call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* nonnull %4, %struct.VkAllocationCallbacks* null) #7
  br label %22

22:                                               ; preds = %20, %3
  %23 = phi i32 [ -2, %3 ], [ %21, %20 ]
  ret i32 %23
}

; Function Attrs: optsize
declare i32 @vkAllocateMemory(%struct.VkDevice_T*, %struct.VkMemoryAllocateInfo*, %struct.VkAllocationCallbacks*, %class.VkNonDispatchableHandle.3*) local_unnamed_addr #2

; Function Attrs: optsize
declare i32 @vkBindImageMemory(%struct.VkDevice_T*, i64, i64, i64) local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk12PresentImage5clearEv(%"class.vk::PresentImage"* nocapture) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %0, i64 0, i32 1
  %3 = load %"class.vk::DeviceMemory"*, %"class.vk::DeviceMemory"** %2, align 8
  %4 = icmp eq %"class.vk::DeviceMemory"* %3, null
  br i1 %4, label %7, label %5

5:                                                ; preds = %1
  tail call void @_ZN2vk12DeviceMemory7destroyEPK21VkAllocationCallbacks(%"class.vk::DeviceMemory"* nonnull %3, %struct.VkAllocationCallbacks* null) #7
  %6 = bitcast %"class.vk::DeviceMemory"* %3 to i8*
  tail call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* nonnull %6, %struct.VkAllocationCallbacks* null) #7
  store %"class.vk::DeviceMemory"* null, %"class.vk::DeviceMemory"** %2, align 8
  br label %7

7:                                                ; preds = %1, %5
  %8 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %0, i64 0, i32 0
  %9 = load %"class.vk::Image"*, %"class.vk::Image"** %8, align 8
  %10 = icmp eq %"class.vk::Image"* %9, null
  br i1 %10, label %14, label %11

11:                                               ; preds = %7
  tail call void @_ZN2vk5Image7destroyEPK21VkAllocationCallbacks(%"class.vk::Image"* nonnull %9, %struct.VkAllocationCallbacks* null) #7
  %12 = getelementptr inbounds %"class.vk::Image", %"class.vk::Image"* %9, i64 0, i32 15, i32 0
  tail call void @_ZNSt3__112__hash_tableIN2vk5Image11SubresourceES3_NS_8equal_toIS3_EENS_9allocatorIS3_EEED2Ev(%"class.std::__1::__hash_table.408"* %12) #7
  %13 = bitcast %"class.vk::Image"* %9 to i8*
  tail call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* nonnull %13, %struct.VkAllocationCallbacks* null) #7
  store %"class.vk::Image"* null, %"class.vk::Image"** %8, align 8
  br label %14

14:                                               ; preds = %7, %11
  %15 = getelementptr inbounds %"class.vk::PresentImage", %"class.vk::PresentImage"* %0, i64 0, i32 2
  store i32 0, i32* %15, align 8
  ret void
}

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define hidden i64 @_ZNK2vk12PresentImage9asVkImageEv(%"class.vk::PresentImage"* nocapture readonly) local_unnamed_addr #3 align 2 {
  %2 = bitcast %"class.vk::PresentImage"* %0 to i64*
  %3 = load i64, i64* %2, align 8
  ret i64 %3
}

; Function Attrs: norecurse nounwind optsize readnone ssp uwtable
define hidden i32 @_ZNK2vk10SurfaceKHR22getSurfaceFormatsCountEv(%"class.vk::SurfaceKHR"* nocapture readnone) local_unnamed_addr #4 align 2 {
  ret i32 2
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden i32 @_ZNK2vk10SurfaceKHR17getSurfaceFormatsEPjP18VkSurfaceFormatKHR(%"class.vk::SurfaceKHR"* nocapture readnone, i32* nocapture, %struct.VkSurfaceFormatKHR* nocapture) local_unnamed_addr #0 align 2 {
  %4 = load i32, i32* %1, align 4
  %5 = icmp eq i32 %4, 0
  br i1 %5, label %6, label %7

6:                                                ; preds = %3
  store i32 0, i32* %1, align 4
  br label %23

7:                                                ; preds = %3, %7
  %8 = phi i64 [ %14, %7 ], [ 0, %3 ]
  %9 = getelementptr inbounds [2 x %struct.VkSurfaceFormatKHR], [2 x %struct.VkSurfaceFormatKHR]* @_ZN12_GLOBAL__N_114surfaceFormatsE, i64 0, i64 %8
  %10 = getelementptr inbounds %struct.VkSurfaceFormatKHR, %struct.VkSurfaceFormatKHR* %2, i64 %8
  %11 = bitcast %struct.VkSurfaceFormatKHR* %9 to i64*
  %12 = bitcast %struct.VkSurfaceFormatKHR* %10 to i64*
  %13 = load i64, i64* %11, align 8
  store i64 %13, i64* %12, align 4
  %14 = add nuw nsw i64 %8, 1
  %15 = load i32, i32* %1, align 4
  %16 = icmp ult i32 %15, 2
  %17 = select i1 %16, i32 %15, i32 2
  %18 = zext i32 %17 to i64
  %19 = icmp ult i64 %14, %18
  br i1 %19, label %7, label %20

20:                                               ; preds = %7
  %21 = trunc i64 %14 to i32
  store i32 %21, i32* %1, align 4
  %22 = icmp ult i32 %21, 2
  br i1 %22, label %23, label %24

23:                                               ; preds = %6, %20
  br label %24

24:                                               ; preds = %20, %23
  %25 = phi i32 [ 5, %23 ], [ 0, %20 ]
  ret i32 %25
}

; Function Attrs: norecurse nounwind optsize readnone ssp uwtable
define hidden i32 @_ZNK2vk10SurfaceKHR19getPresentModeCountEv(%"class.vk::SurfaceKHR"* nocapture readnone) local_unnamed_addr #4 align 2 {
  ret i32 2
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden i32 @_ZNK2vk10SurfaceKHR15getPresentModesEPjP16VkPresentModeKHR(%"class.vk::SurfaceKHR"* nocapture readnone, i32* nocapture, i32* nocapture) local_unnamed_addr #0 align 2 {
  %4 = load i32, i32* %1, align 4
  %5 = icmp eq i32 %4, 0
  br i1 %5, label %6, label %7

6:                                                ; preds = %3
  store i32 0, i32* %1, align 4
  br label %21

7:                                                ; preds = %3, %7
  %8 = phi i64 [ %12, %7 ], [ 0, %3 ]
  %9 = getelementptr inbounds [2 x i32], [2 x i32]* @_ZN12_GLOBAL__N_112presentModesE, i64 0, i64 %8
  %10 = load i32, i32* %9, align 4
  %11 = getelementptr inbounds i32, i32* %2, i64 %8
  store i32 %10, i32* %11, align 4
  %12 = add nuw nsw i64 %8, 1
  %13 = load i32, i32* %1, align 4
  %14 = icmp ult i32 %13, 2
  %15 = select i1 %14, i32 %13, i32 2
  %16 = zext i32 %15 to i64
  %17 = icmp ult i64 %12, %16
  br i1 %17, label %7, label %18

18:                                               ; preds = %7
  %19 = trunc i64 %12 to i32
  store i32 %19, i32* %1, align 4
  %20 = icmp ult i32 %19, 2
  br i1 %20, label %21, label %22

21:                                               ; preds = %6, %18
  br label %22

22:                                               ; preds = %18, %21
  %23 = phi i32 [ 5, %21 ], [ 0, %18 ]
  ret i32 %23
}

; Function Attrs: nofree norecurse nounwind optsize ssp uwtable writeonly
define hidden void @_ZN2vk10SurfaceKHR18associateSwapchainEPNS_12SwapchainKHRE(%"class.vk::SurfaceKHR"* nocapture, %"class.vk::SwapchainKHR"*) local_unnamed_addr #5 align 2 {
  %3 = getelementptr inbounds %"class.vk::SurfaceKHR", %"class.vk::SurfaceKHR"* %0, i64 0, i32 1
  store %"class.vk::SwapchainKHR"* %1, %"class.vk::SwapchainKHR"** %3, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind optsize ssp uwtable writeonly
define hidden void @_ZN2vk10SurfaceKHR21disassociateSwapchainEv(%"class.vk::SurfaceKHR"* nocapture) local_unnamed_addr #5 align 2 {
  %2 = getelementptr inbounds %"class.vk::SurfaceKHR", %"class.vk::SurfaceKHR"* %0, i64 0, i32 1
  store %"class.vk::SwapchainKHR"* null, %"class.vk::SwapchainKHR"** %2, align 8
  ret void
}

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define hidden zeroext i1 @_ZN2vk10SurfaceKHR22hasAssociatedSwapchainEv(%"class.vk::SurfaceKHR"* nocapture readonly) local_unnamed_addr #3 align 2 {
  %2 = getelementptr inbounds %"class.vk::SurfaceKHR", %"class.vk::SurfaceKHR"* %0, i64 0, i32 1
  %3 = load %"class.vk::SwapchainKHR"*, %"class.vk::SwapchainKHR"** %2, align 8
  %4 = icmp ne %"class.vk::SwapchainKHR"* %3, null
  ret i1 %4
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden i32 @_ZNK2vk10SurfaceKHR20getPresentRectanglesEPjP8VkRect2D(%"class.vk::SurfaceKHR"*, i32* nocapture, %struct.VkRect2D*) local_unnamed_addr #0 align 2 {
  %4 = alloca %struct.VkSurfaceCapabilitiesKHR, align 4
  %5 = icmp eq %struct.VkRect2D* %2, null
  br i1 %5, label %6, label %7

6:                                                ; preds = %3
  store i32 1, i32* %1, align 4
  br label %24

7:                                                ; preds = %3
  %8 = load i32, i32* %1, align 4
  %9 = icmp eq i32 %8, 0
  br i1 %9, label %24, label %10

10:                                               ; preds = %7
  %11 = bitcast %struct.VkSurfaceCapabilitiesKHR* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 52, i8* nonnull %11) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %11, i8 -86, i64 52, i1 false)
  %12 = bitcast %"class.vk::SurfaceKHR"* %0 to i32 (%"class.vk::SurfaceKHR"*, %struct.VkSurfaceCapabilitiesKHR*)***
  %13 = load i32 (%"class.vk::SurfaceKHR"*, %struct.VkSurfaceCapabilitiesKHR*)**, i32 (%"class.vk::SurfaceKHR"*, %struct.VkSurfaceCapabilitiesKHR*)*** %12, align 8
  %14 = getelementptr inbounds i32 (%"class.vk::SurfaceKHR"*, %struct.VkSurfaceCapabilitiesKHR*)*, i32 (%"class.vk::SurfaceKHR"*, %struct.VkSurfaceCapabilitiesKHR*)** %13, i64 3
  %15 = load i32 (%"class.vk::SurfaceKHR"*, %struct.VkSurfaceCapabilitiesKHR*)*, i32 (%"class.vk::SurfaceKHR"*, %struct.VkSurfaceCapabilitiesKHR*)** %14, align 8
  %16 = call i32 %15(%"class.vk::SurfaceKHR"* %0, %struct.VkSurfaceCapabilitiesKHR* nonnull %4) #7
  %17 = getelementptr inbounds %struct.VkRect2D, %struct.VkRect2D* %2, i64 0, i32 0, i32 0
  store i32 0, i32* %17, align 4
  %18 = getelementptr inbounds %struct.VkRect2D, %struct.VkRect2D* %2, i64 0, i32 0, i32 1
  store i32 0, i32* %18, align 4
  %19 = getelementptr inbounds %struct.VkSurfaceCapabilitiesKHR, %struct.VkSurfaceCapabilitiesKHR* %4, i64 0, i32 2
  %20 = getelementptr inbounds %struct.VkRect2D, %struct.VkRect2D* %2, i64 0, i32 1
  %21 = bitcast %struct.VkExtent2D* %19 to i64*
  %22 = bitcast %struct.VkExtent2D* %20 to i64*
  %23 = load i64, i64* %21, align 4
  store i64 %23, i64* %22, align 4
  store i32 1, i32* %1, align 4
  call void @llvm.lifetime.end.p0i8(i64 52, i8* nonnull %11) #8
  br label %24

24:                                               ; preds = %7, %10, %6
  %25 = phi i32 [ 0, %10 ], [ 0, %6 ], [ 5, %7 ]
  ret i32 %25
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: nofree norecurse nounwind optsize ssp uwtable writeonly
define hidden void @_ZN2vk10SurfaceKHR28setCommonSurfaceCapabilitiesEP24VkSurfaceCapabilitiesKHR(%struct.VkSurfaceCapabilitiesKHR* nocapture) local_unnamed_addr #5 align 2 {
  %2 = getelementptr inbounds %struct.VkSurfaceCapabilitiesKHR, %struct.VkSurfaceCapabilitiesKHR* %0, i64 0, i32 0
  store i32 1, i32* %2, align 4
  %3 = getelementptr inbounds %struct.VkSurfaceCapabilitiesKHR, %struct.VkSurfaceCapabilitiesKHR* %0, i64 0, i32 1
  store i32 0, i32* %3, align 4
  %4 = getelementptr inbounds %struct.VkSurfaceCapabilitiesKHR, %struct.VkSurfaceCapabilitiesKHR* %0, i64 0, i32 5
  %5 = bitcast i32* %4 to <4 x i32>*
  store <4 x i32> <i32 1, i32 1, i32 1, i32 1>, <4 x i32>* %5, align 4
  %6 = getelementptr inbounds %struct.VkSurfaceCapabilitiesKHR, %struct.VkSurfaceCapabilitiesKHR* %0, i64 0, i32 9
  store i32 23, i32* %6, align 4
  ret void
}

; Function Attrs: optsize
declare void @_ZN2vk12DeviceMemory7destroyEPK21VkAllocationCallbacks(%"class.vk::DeviceMemory"*, %struct.VkAllocationCallbacks*) local_unnamed_addr #2

; Function Attrs: optsize
declare void @_ZN2vk5Image7destroyEPK21VkAllocationCallbacks(%"class.vk::Image"*, %struct.VkAllocationCallbacks*) local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define linkonce_odr hidden void @_ZNSt3__112__hash_tableIN2vk5Image11SubresourceES3_NS_8equal_toIS3_EENS_9allocatorIS3_EEED2Ev(%"class.std::__1::__hash_table.408"*) unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.std::__1::__hash_table.408", %"class.std::__1::__hash_table.408"* %0, i64 0, i32 1, i32 0, i32 0, i32 0
  %3 = load %"struct.std::__1::__hash_node_base.412"*, %"struct.std::__1::__hash_node_base.412"** %2, align 8
  %4 = icmp eq %"struct.std::__1::__hash_node_base.412"* %3, null
  br i1 %4, label %11, label %5

5:                                                ; preds = %1, %5
  %6 = phi %"struct.std::__1::__hash_node_base.412"* [ %8, %5 ], [ %3, %1 ]
  %7 = getelementptr inbounds %"struct.std::__1::__hash_node_base.412", %"struct.std::__1::__hash_node_base.412"* %6, i64 0, i32 0
  %8 = load %"struct.std::__1::__hash_node_base.412"*, %"struct.std::__1::__hash_node_base.412"** %7, align 8
  %9 = bitcast %"struct.std::__1::__hash_node_base.412"* %6 to i8*
  tail call void @_ZdlPv(i8* %9) #9
  %10 = icmp eq %"struct.std::__1::__hash_node_base.412"* %8, null
  br i1 %10, label %11, label %5

11:                                               ; preds = %5, %1
  %12 = getelementptr inbounds %"class.std::__1::__hash_table.408", %"class.std::__1::__hash_table.408"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %13 = load %"struct.std::__1::__hash_node_base.412"**, %"struct.std::__1::__hash_node_base.412"*** %12, align 8
  store %"struct.std::__1::__hash_node_base.412"** null, %"struct.std::__1::__hash_node_base.412"*** %12, align 8
  %14 = icmp eq %"struct.std::__1::__hash_node_base.412"** %13, null
  br i1 %14, label %17, label %15

15:                                               ; preds = %11
  %16 = bitcast %"struct.std::__1::__hash_node_base.412"** %13 to i8*
  tail call void @_ZdlPv(i8* %16) #9
  br label %17

17:                                               ; preds = %11, %15
  ret void
}

; Function Attrs: nobuiltin nounwind optsize
declare void @_ZdlPv(i8*) local_unnamed_addr #6

attributes #0 = { nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { norecurse nounwind optsize readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { norecurse nounwind optsize readnone ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nofree norecurse nounwind optsize ssp uwtable writeonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nobuiltin nounwind optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { nounwind optsize }
attributes #8 = { nounwind }
attributes #9 = { builtin nounwind optsize }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
