; ModuleID = '../../third_party/swiftshader/src/Vulkan/VkPipelineLayout.cpp'
source_filename = "../../third_party/swiftshader/src/Vulkan/VkPipelineLayout.cpp"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"class.vk::PipelineLayout" = type <{ i32, [4 x i8], [4 x %"struct.vk::PipelineLayout::DescriptorSet"], i32, i32, %struct.VkPushConstantRange*, %"struct.std::__1::atomic", [4 x i8] }>
%"struct.vk::PipelineLayout::DescriptorSet" = type { %"struct.vk::PipelineLayout::Binding"*, i32 }
%"struct.vk::PipelineLayout::Binding" = type { i32, i32, i32, i32 }
%struct.VkPushConstantRange = type { i32, i32, i32 }
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__atomic_base.36" }
%"struct.std::__1::__atomic_base.36" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i32 }
%struct.VkPipelineLayoutCreateInfo = type { i32, i8*, i32, i32, %class.VkNonDispatchableHandle.13*, i32, %struct.VkPushConstantRange* }
%class.VkNonDispatchableHandle.13 = type { i64 }
%class.VkNonDispatchableHandle = type { i64 }
%class.VkNonDispatchableHandle.0 = type { i64 }
%class.VkNonDispatchableHandle.1 = type { i64 }
%class.VkNonDispatchableHandle.2 = type { i64 }
%class.VkNonDispatchableHandle.3 = type { i64 }
%class.VkNonDispatchableHandle.4 = type { i64 }
%class.VkNonDispatchableHandle.5 = type { i64 }
%class.VkNonDispatchableHandle.6 = type { i64 }
%class.VkNonDispatchableHandle.7 = type { i64 }
%class.VkNonDispatchableHandle.8 = type { i64 }
%class.VkNonDispatchableHandle.9 = type { i64 }
%class.VkNonDispatchableHandle.10 = type { i64 }
%class.VkNonDispatchableHandle.11 = type { i64 }
%class.VkNonDispatchableHandle.12 = type { i64 }
%class.VkNonDispatchableHandle.14 = type { i64 }
%class.VkNonDispatchableHandle.15 = type { i64 }
%class.VkNonDispatchableHandle.16 = type { i64 }
%class.VkNonDispatchableHandle.17 = type { i64 }
%class.VkNonDispatchableHandle.18 = type { i64 }
%class.VkNonDispatchableHandle.19 = type { i64 }
%class.VkNonDispatchableHandle.20 = type { i64 }
%class.VkNonDispatchableHandle.21 = type { i64 }
%class.VkNonDispatchableHandle.22 = type { i64 }
%class.VkNonDispatchableHandle.23 = type { i64 }
%class.VkNonDispatchableHandle.24 = type { i64 }
%class.VkNonDispatchableHandle.25 = type { i64 }
%class.VkNonDispatchableHandle.26 = type { i64 }
%class.VkNonDispatchableHandle.27 = type { i64 }
%class.VkNonDispatchableHandle.28 = type { i64 }
%class.VkNonDispatchableHandle.29 = type { i64 }
%class.VkNonDispatchableHandle.30 = type { i64 }
%class.VkNonDispatchableHandle.31 = type { i64 }
%class.VkNonDispatchableHandle.32 = type { i64 }
%class.VkNonDispatchableHandle.33 = type { i64 }
%class.VkNonDispatchableHandle.34 = type { i64 }
%class.VkNonDispatchableHandle.35 = type { i64 }
%"class.vk::DescriptorSetLayout" = type { i32, i32, %"struct.vk::DescriptorSetLayout::Binding"* }
%"struct.vk::DescriptorSetLayout::Binding" = type { i32, i32, %"class.vk::Sampler"**, i32 }
%"class.vk::Sampler" = type { %"struct.vk::SamplerState.base", i32 }
%"struct.vk::SamplerState.base" = type <{ i32, i32, i32, i32, i32, i32, float, i32, float, i32, i32, float, float, i32, i32, i32, i32, i8, i8 }>
%struct.VkAllocationCallbacks = type { i8*, i8* (i8*, i64, i64, i32)*, i8* (i8*, i8*, i64, i64, i32)*, void (i8*, i8*)*, void (i8*, i64, i32, i32)*, void (i8*, i64, i32, i32)* }

$_ZNK23VkNonDispatchableHandleIP10VkBuffer_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP10VkBuffer_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkImage_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkImage_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkSemaphore_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkSemaphore_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkFence_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkFence_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkDeviceMemory_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkDeviceMemory_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP9VkEvent_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP9VkEvent_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkQueryPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkQueryPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkBufferView_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkBufferView_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP13VkImageView_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP13VkImageView_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkShaderModule_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkShaderModule_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkPipelineCache_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkPipelineCache_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkPipelineLayout_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkPipelineLayout_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP12VkPipeline_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP12VkPipeline_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkRenderPass_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkRenderPass_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP11VkSampler_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP11VkSampler_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkDescriptorSet_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkDescriptorSet_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkDescriptorPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkDescriptorPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkFramebuffer_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkFramebuffer_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkCommandPool_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkCommandPool_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkSurfaceKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkSurfaceKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP16VkSwapchainKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP16VkSwapchainKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP14VkDisplayKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP14VkDisplayKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP15VkCuModuleNVX_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP15VkCuModuleNVX_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEaSEm = comdat any

$_ZNK23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEcvPvEv = comdat any

$_ZN23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEaSEm = comdat any

@_ZN2vkL22layoutIdentifierSerialE = internal global { { i32 } } { { i32 } { i32 1 } }, align 4

@_ZN2vk14PipelineLayoutC1EPK26VkPipelineLayoutCreateInfoPv = hidden unnamed_addr alias void (%"class.vk::PipelineLayout"*, %struct.VkPipelineLayoutCreateInfo*, i8*), void (%"class.vk::PipelineLayout"*, %struct.VkPipelineLayoutCreateInfo*, i8*)* @_ZN2vk14PipelineLayoutC2EPK26VkPipelineLayoutCreateInfoPv

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP10VkBuffer_TEcvPvEv(%class.VkNonDispatchableHandle*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP10VkBuffer_TEaSEm(%class.VkNonDispatchableHandle*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle, %class.VkNonDispatchableHandle* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkImage_TEcvPvEv(%class.VkNonDispatchableHandle.0*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.0* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkImage_TEaSEm(%class.VkNonDispatchableHandle.0*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.0, %class.VkNonDispatchableHandle.0* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkSemaphore_TEcvPvEv(%class.VkNonDispatchableHandle.1*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.1* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkSemaphore_TEaSEm(%class.VkNonDispatchableHandle.1*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.1, %class.VkNonDispatchableHandle.1* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkFence_TEcvPvEv(%class.VkNonDispatchableHandle.2*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.2* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkFence_TEaSEm(%class.VkNonDispatchableHandle.2*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.2, %class.VkNonDispatchableHandle.2* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkDeviceMemory_TEcvPvEv(%class.VkNonDispatchableHandle.3*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.3* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkDeviceMemory_TEaSEm(%class.VkNonDispatchableHandle.3*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.3, %class.VkNonDispatchableHandle.3* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP9VkEvent_TEcvPvEv(%class.VkNonDispatchableHandle.4*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.4* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP9VkEvent_TEaSEm(%class.VkNonDispatchableHandle.4*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.4, %class.VkNonDispatchableHandle.4* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkQueryPool_TEcvPvEv(%class.VkNonDispatchableHandle.5*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.5* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkQueryPool_TEaSEm(%class.VkNonDispatchableHandle.5*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.5, %class.VkNonDispatchableHandle.5* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkBufferView_TEcvPvEv(%class.VkNonDispatchableHandle.6*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.6* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkBufferView_TEaSEm(%class.VkNonDispatchableHandle.6*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.6, %class.VkNonDispatchableHandle.6* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP13VkImageView_TEcvPvEv(%class.VkNonDispatchableHandle.7*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.7* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP13VkImageView_TEaSEm(%class.VkNonDispatchableHandle.7*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.7, %class.VkNonDispatchableHandle.7* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkShaderModule_TEcvPvEv(%class.VkNonDispatchableHandle.8*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.8* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkShaderModule_TEaSEm(%class.VkNonDispatchableHandle.8*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.8, %class.VkNonDispatchableHandle.8* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkPipelineCache_TEcvPvEv(%class.VkNonDispatchableHandle.9*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.9* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkPipelineCache_TEaSEm(%class.VkNonDispatchableHandle.9*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.9, %class.VkNonDispatchableHandle.9* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkPipelineLayout_TEcvPvEv(%class.VkNonDispatchableHandle.10*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.10* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkPipelineLayout_TEaSEm(%class.VkNonDispatchableHandle.10*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.10, %class.VkNonDispatchableHandle.10* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP12VkPipeline_TEcvPvEv(%class.VkNonDispatchableHandle.11*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.11* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP12VkPipeline_TEaSEm(%class.VkNonDispatchableHandle.11*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.11, %class.VkNonDispatchableHandle.11* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkRenderPass_TEcvPvEv(%class.VkNonDispatchableHandle.12*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.12* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkRenderPass_TEaSEm(%class.VkNonDispatchableHandle.12*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.12, %class.VkNonDispatchableHandle.12* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEcvPvEv(%class.VkNonDispatchableHandle.13*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.13* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP23VkDescriptorSetLayout_TEaSEm(%class.VkNonDispatchableHandle.13*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.13, %class.VkNonDispatchableHandle.13* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP11VkSampler_TEcvPvEv(%class.VkNonDispatchableHandle.14*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.14* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP11VkSampler_TEaSEm(%class.VkNonDispatchableHandle.14*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.14, %class.VkNonDispatchableHandle.14* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkDescriptorSet_TEcvPvEv(%class.VkNonDispatchableHandle.15*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.15* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkDescriptorSet_TEaSEm(%class.VkNonDispatchableHandle.15*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.15, %class.VkNonDispatchableHandle.15* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkDescriptorPool_TEcvPvEv(%class.VkNonDispatchableHandle.16*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.16* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkDescriptorPool_TEaSEm(%class.VkNonDispatchableHandle.16*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.16, %class.VkNonDispatchableHandle.16* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkFramebuffer_TEcvPvEv(%class.VkNonDispatchableHandle.17*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.17* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkFramebuffer_TEaSEm(%class.VkNonDispatchableHandle.17*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.17, %class.VkNonDispatchableHandle.17* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkCommandPool_TEcvPvEv(%class.VkNonDispatchableHandle.18*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.18* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkCommandPool_TEaSEm(%class.VkNonDispatchableHandle.18*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.18, %class.VkNonDispatchableHandle.18* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEcvPvEv(%class.VkNonDispatchableHandle.19*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.19* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkSamplerYcbcrConversion_TEaSEm(%class.VkNonDispatchableHandle.19*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.19, %class.VkNonDispatchableHandle.19* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEcvPvEv(%class.VkNonDispatchableHandle.20*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.20* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkDescriptorUpdateTemplate_TEaSEm(%class.VkNonDispatchableHandle.20*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.20, %class.VkNonDispatchableHandle.20* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkSurfaceKHR_TEcvPvEv(%class.VkNonDispatchableHandle.21*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.21* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkSurfaceKHR_TEaSEm(%class.VkNonDispatchableHandle.21*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.21, %class.VkNonDispatchableHandle.21* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP16VkSwapchainKHR_TEcvPvEv(%class.VkNonDispatchableHandle.22*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.22* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP16VkSwapchainKHR_TEaSEm(%class.VkNonDispatchableHandle.22*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.22, %class.VkNonDispatchableHandle.22* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP14VkDisplayKHR_TEcvPvEv(%class.VkNonDispatchableHandle.23*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.23* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP14VkDisplayKHR_TEaSEm(%class.VkNonDispatchableHandle.23*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.23, %class.VkNonDispatchableHandle.23* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEcvPvEv(%class.VkNonDispatchableHandle.24*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.24* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP18VkDisplayModeKHR_TEaSEm(%class.VkNonDispatchableHandle.24*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.24, %class.VkNonDispatchableHandle.24* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEcvPvEv(%class.VkNonDispatchableHandle.25*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.25* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP24VkDeferredOperationKHR_TEaSEm(%class.VkNonDispatchableHandle.25*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.25, %class.VkNonDispatchableHandle.25* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEcvPvEv(%class.VkNonDispatchableHandle.26*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.26* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkDebugReportCallbackEXT_TEaSEm(%class.VkNonDispatchableHandle.26*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.26, %class.VkNonDispatchableHandle.26* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP15VkCuModuleNVX_TEcvPvEv(%class.VkNonDispatchableHandle.27*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.27* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP15VkCuModuleNVX_TEaSEm(%class.VkNonDispatchableHandle.27*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.27, %class.VkNonDispatchableHandle.27* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEcvPvEv(%class.VkNonDispatchableHandle.28*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.28* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP17VkCuFunctionNVX_TEaSEm(%class.VkNonDispatchableHandle.28*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.28, %class.VkNonDispatchableHandle.28* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEcvPvEv(%class.VkNonDispatchableHandle.29*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.29* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP26VkDebugUtilsMessengerEXT_TEaSEm(%class.VkNonDispatchableHandle.29*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.29, %class.VkNonDispatchableHandle.29* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEcvPvEv(%class.VkNonDispatchableHandle.30*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.30* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP22VkValidationCacheEXT_TEaSEm(%class.VkNonDispatchableHandle.30*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.30, %class.VkNonDispatchableHandle.30* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEcvPvEv(%class.VkNonDispatchableHandle.31*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.31* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP27VkAccelerationStructureNV_TEaSEm(%class.VkNonDispatchableHandle.31*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.31, %class.VkNonDispatchableHandle.31* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEcvPvEv(%class.VkNonDispatchableHandle.32*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.32* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP33VkPerformanceConfigurationINTEL_TEaSEm(%class.VkNonDispatchableHandle.32*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.32, %class.VkNonDispatchableHandle.32* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEcvPvEv(%class.VkNonDispatchableHandle.33*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.33* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkIndirectCommandsLayoutNV_TEaSEm(%class.VkNonDispatchableHandle.33*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.33, %class.VkNonDispatchableHandle.33* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEcvPvEv(%class.VkNonDispatchableHandle.34*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.34* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP22VkPrivateDataSlotEXT_TEaSEm(%class.VkNonDispatchableHandle.34*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.34, %class.VkNonDispatchableHandle.34* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden i8* @_ZNK23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEcvPvEv(%class.VkNonDispatchableHandle.35*) local_unnamed_addr #0 comdat align 2 {
  %2 = bitcast %class.VkNonDispatchableHandle.35* %0 to i8**
  %3 = load i8*, i8** %2, align 8
  ret i8* %3
}

; Function Attrs: nounwind optsize ssp uwtable
define weak_odr hidden void @_ZN23VkNonDispatchableHandleIP28VkAccelerationStructureKHR_TEaSEm(%class.VkNonDispatchableHandle.35*, i64) local_unnamed_addr #0 comdat align 2 {
  %3 = getelementptr inbounds %class.VkNonDispatchableHandle.35, %class.VkNonDispatchableHandle.35* %0, i64 0, i32 0
  store i64 %1, i64* %3, align 8
  ret void
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk14PipelineLayoutC2EPK26VkPipelineLayoutCreateInfoPv(%"class.vk::PipelineLayout"* nocapture, %struct.VkPipelineLayoutCreateInfo* nocapture readonly, i8*) unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 0
  %5 = atomicrmw add i32* getelementptr inbounds ({ { i32 } }, { { i32 } }* @_ZN2vkL22layoutIdentifierSerialE, i64 0, i32 0, i32 0), i32 1 seq_cst
  store i32 %5, i32* %4, align 8
  %6 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 3
  %7 = getelementptr inbounds %struct.VkPipelineLayoutCreateInfo, %struct.VkPipelineLayoutCreateInfo* %1, i64 0, i32 3
  %8 = load i32, i32* %7, align 4
  store i32 %8, i32* %6, align 8
  %9 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 4
  %10 = getelementptr inbounds %struct.VkPipelineLayoutCreateInfo, %struct.VkPipelineLayoutCreateInfo* %1, i64 0, i32 5
  %11 = load i32, i32* %10, align 8
  store i32 %11, i32* %9, align 4
  %12 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 5
  store %struct.VkPushConstantRange* null, %struct.VkPushConstantRange** %12, align 8
  %13 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 0, i32* %13, align 4
  %14 = bitcast i8* %2 to %"struct.vk::PipelineLayout::Binding"*
  %15 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 2
  %16 = bitcast [4 x %"struct.vk::PipelineLayout::DescriptorSet"]* %15 to i8**
  store i8* %2, i8** %16, align 8
  %17 = load i32, i32* %7, align 4
  %18 = icmp eq i32 %17, 0
  br i1 %18, label %21, label %19

19:                                               ; preds = %3
  %20 = getelementptr inbounds %struct.VkPipelineLayoutCreateInfo, %struct.VkPipelineLayoutCreateInfo* %1, i64 0, i32 4
  br label %32

21:                                               ; preds = %47, %3
  %22 = phi %"struct.vk::PipelineLayout::Binding"* [ %14, %3 ], [ %44, %47 ]
  %23 = load i32, i32* %10, align 8
  %24 = zext i32 %23 to i64
  %25 = mul nuw nsw i64 %24, 12
  %26 = bitcast %struct.VkPushConstantRange** %12 to %"struct.vk::PipelineLayout::Binding"**
  store %"struct.vk::PipelineLayout::Binding"* %22, %"struct.vk::PipelineLayout::Binding"** %26, align 8
  %27 = bitcast %"struct.vk::PipelineLayout::Binding"* %22 to i8*
  %28 = getelementptr inbounds %struct.VkPipelineLayoutCreateInfo, %struct.VkPipelineLayoutCreateInfo* %1, i64 0, i32 6
  %29 = bitcast %struct.VkPushConstantRange** %28 to i8**
  %30 = load i8*, i8** %29, align 8
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %27, i8* align 4 %30, i64 %25, i1 false)
  %31 = atomicrmw add i32* %13, i32 1 seq_cst
  ret void

32:                                               ; preds = %19, %47
  %33 = phi i64 [ 0, %19 ], [ %49, %47 ]
  %34 = phi %"struct.vk::PipelineLayout::Binding"* [ %14, %19 ], [ %44, %47 ]
  %35 = phi i32 [ 0, %19 ], [ %48, %47 ]
  %36 = load %class.VkNonDispatchableHandle.13*, %class.VkNonDispatchableHandle.13** %20, align 8
  %37 = getelementptr inbounds %class.VkNonDispatchableHandle.13, %class.VkNonDispatchableHandle.13* %36, i64 %33, i32 0
  %38 = bitcast i64* %37 to %"class.vk::DescriptorSetLayout"**
  %39 = load %"class.vk::DescriptorSetLayout"*, %"class.vk::DescriptorSetLayout"** %38, align 8
  %40 = getelementptr inbounds %"class.vk::DescriptorSetLayout", %"class.vk::DescriptorSetLayout"* %39, i64 0, i32 1
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 2, i64 %33, i32 0
  store %"struct.vk::PipelineLayout::Binding"* %34, %"struct.vk::PipelineLayout::Binding"** %42, align 8
  %43 = zext i32 %41 to i64
  %44 = getelementptr inbounds %"struct.vk::PipelineLayout::Binding", %"struct.vk::PipelineLayout::Binding"* %34, i64 %43
  %45 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 2, i64 %33, i32 1
  store i32 %41, i32* %45, align 8
  %46 = icmp eq i32 %41, 0
  br i1 %46, label %47, label %53

47:                                               ; preds = %75, %32
  %48 = phi i32 [ %35, %32 ], [ %76, %75 ]
  %49 = add nuw nsw i64 %33, 1
  %50 = load i32, i32* %7, align 4
  %51 = zext i32 %50 to i64
  %52 = icmp ult i64 %49, %51
  br i1 %52, label %32, label %21

53:                                               ; preds = %32, %75
  %54 = phi i64 [ %77, %75 ], [ 0, %32 ]
  %55 = phi i32 [ %76, %75 ], [ %35, %32 ]
  %56 = trunc i64 %54 to i32
  %57 = tail call i32 @_ZNK2vk19DescriptorSetLayout17getDescriptorTypeEj(%"class.vk::DescriptorSetLayout"* %39, i32 %56) #5
  %58 = load %"struct.vk::PipelineLayout::Binding"*, %"struct.vk::PipelineLayout::Binding"** %42, align 8
  %59 = getelementptr inbounds %"struct.vk::PipelineLayout::Binding", %"struct.vk::PipelineLayout::Binding"* %58, i64 %54, i32 0
  store i32 %57, i32* %59, align 4
  %60 = tail call i32 @_ZNK2vk19DescriptorSetLayout16getBindingOffsetEj(%"class.vk::DescriptorSetLayout"* %39, i32 %56) #5
  %61 = load %"struct.vk::PipelineLayout::Binding"*, %"struct.vk::PipelineLayout::Binding"** %42, align 8
  %62 = getelementptr inbounds %"struct.vk::PipelineLayout::Binding", %"struct.vk::PipelineLayout::Binding"* %61, i64 %54, i32 1
  store i32 %60, i32* %62, align 4
  %63 = load %"struct.vk::PipelineLayout::Binding"*, %"struct.vk::PipelineLayout::Binding"** %42, align 8
  %64 = getelementptr inbounds %"struct.vk::PipelineLayout::Binding", %"struct.vk::PipelineLayout::Binding"* %63, i64 %54, i32 2
  store i32 %55, i32* %64, align 4
  %65 = tail call i32 @_ZNK2vk19DescriptorSetLayout18getDescriptorCountEj(%"class.vk::DescriptorSetLayout"* %39, i32 %56) #5
  %66 = load %"struct.vk::PipelineLayout::Binding"*, %"struct.vk::PipelineLayout::Binding"** %42, align 8
  %67 = getelementptr inbounds %"struct.vk::PipelineLayout::Binding", %"struct.vk::PipelineLayout::Binding"* %66, i64 %54, i32 3
  store i32 %65, i32* %67, align 4
  %68 = load %"struct.vk::PipelineLayout::Binding"*, %"struct.vk::PipelineLayout::Binding"** %42, align 8
  %69 = getelementptr inbounds %"struct.vk::PipelineLayout::Binding", %"struct.vk::PipelineLayout::Binding"* %68, i64 %54, i32 0
  %70 = load i32, i32* %69, align 4
  %71 = tail call zeroext i1 @_ZN2vk19DescriptorSetLayout19IsDescriptorDynamicE16VkDescriptorType(i32 %70) #5
  br i1 %71, label %72, label %75

72:                                               ; preds = %53
  %73 = tail call i32 @_ZNK2vk19DescriptorSetLayout18getDescriptorCountEj(%"class.vk::DescriptorSetLayout"* %39, i32 %56) #5
  %74 = add i32 %73, %55
  br label %75

75:                                               ; preds = %53, %72
  %76 = phi i32 [ %74, %72 ], [ %55, %53 ]
  %77 = add nuw nsw i64 %54, 1
  %78 = icmp eq i64 %77, %43
  br i1 %78, label %47, label %53
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #1

; Function Attrs: optsize
declare i32 @_ZNK2vk19DescriptorSetLayout17getDescriptorTypeEj(%"class.vk::DescriptorSetLayout"*, i32) local_unnamed_addr #2

; Function Attrs: optsize
declare i32 @_ZNK2vk19DescriptorSetLayout16getBindingOffsetEj(%"class.vk::DescriptorSetLayout"*, i32) local_unnamed_addr #2

; Function Attrs: optsize
declare i32 @_ZNK2vk19DescriptorSetLayout18getDescriptorCountEj(%"class.vk::DescriptorSetLayout"*, i32) local_unnamed_addr #2

; Function Attrs: optsize
declare zeroext i1 @_ZN2vk19DescriptorSetLayout19IsDescriptorDynamicE16VkDescriptorType(i32) local_unnamed_addr #2

; Function Attrs: nofree norecurse nounwind optsize ssp uwtable
define hidden i32 @_ZN2vk14PipelineLayout11incRefCountEv(%"class.vk::PipelineLayout"* nocapture) local_unnamed_addr #3 align 2 {
  %2 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = atomicrmw add i32* %2, i32 1 seq_cst
  %4 = add i32 %3, 1
  ret i32 %4
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden void @_ZN2vk14PipelineLayout7destroyEPK21VkAllocationCallbacks(%"class.vk::PipelineLayout"* nocapture readonly, %struct.VkAllocationCallbacks*) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 2, i64 0, i32 0
  %4 = bitcast %"struct.vk::PipelineLayout::Binding"** %3 to i8**
  %5 = load i8*, i8** %4, align 8
  tail call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* %5, %struct.VkAllocationCallbacks* %1) #5
  ret void
}

; Function Attrs: optsize
declare void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8*, %struct.VkAllocationCallbacks*) local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define hidden zeroext i1 @_ZN2vk14PipelineLayout7releaseEPK21VkAllocationCallbacks(%"class.vk::PipelineLayout"* nocapture, %struct.VkAllocationCallbacks*) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0
  %4 = atomicrmw sub i32* %3, i32 1 seq_cst
  %5 = icmp eq i32 %4, 1
  br i1 %5, label %6, label %10

6:                                                ; preds = %2
  %7 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 2, i64 0, i32 0
  %8 = bitcast %"struct.vk::PipelineLayout::Binding"** %7 to i8**
  %9 = load i8*, i8** %8, align 8
  tail call void @_ZN2vk10deallocateEPvPK21VkAllocationCallbacks(i8* %9, %struct.VkAllocationCallbacks* %1) #5
  br label %10

10:                                               ; preds = %2, %6
  %11 = phi i1 [ true, %6 ], [ false, %2 ]
  ret i1 %11
}

; Function Attrs: nofree norecurse nounwind optsize ssp uwtable
define hidden i32 @_ZN2vk14PipelineLayout11decRefCountEv(%"class.vk::PipelineLayout"* nocapture) local_unnamed_addr #3 align 2 {
  %2 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = atomicrmw sub i32* %2, i32 1 seq_cst
  %4 = add i32 %3, -1
  ret i32 %4
}

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define hidden i64 @_ZN2vk14PipelineLayout29ComputeRequiredAllocationSizeEPK26VkPipelineLayoutCreateInfo(%struct.VkPipelineLayoutCreateInfo* nocapture readonly) local_unnamed_addr #4 align 2 {
  %2 = getelementptr inbounds %struct.VkPipelineLayoutCreateInfo, %struct.VkPipelineLayoutCreateInfo* %0, i64 0, i32 3
  %3 = load i32, i32* %2, align 4
  %4 = icmp eq i32 %3, 0
  br i1 %4, label %12, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %struct.VkPipelineLayoutCreateInfo, %struct.VkPipelineLayoutCreateInfo* %0, i64 0, i32 4
  %7 = load %class.VkNonDispatchableHandle.13*, %class.VkNonDispatchableHandle.13** %6, align 8
  %8 = zext i32 %3 to i64
  br label %19

9:                                                ; preds = %19
  %10 = zext i32 %27 to i64
  %11 = shl nuw nsw i64 %10, 4
  br label %12

12:                                               ; preds = %9, %1
  %13 = phi i64 [ 0, %1 ], [ %11, %9 ]
  %14 = getelementptr inbounds %struct.VkPipelineLayoutCreateInfo, %struct.VkPipelineLayoutCreateInfo* %0, i64 0, i32 5
  %15 = load i32, i32* %14, align 8
  %16 = zext i32 %15 to i64
  %17 = mul nuw nsw i64 %16, 12
  %18 = add nuw nsw i64 %17, %13
  ret i64 %18

19:                                               ; preds = %5, %19
  %20 = phi i64 [ 0, %5 ], [ %28, %19 ]
  %21 = phi i32 [ 0, %5 ], [ %27, %19 ]
  %22 = getelementptr inbounds %class.VkNonDispatchableHandle.13, %class.VkNonDispatchableHandle.13* %7, i64 %20, i32 0
  %23 = bitcast i64* %22 to %"class.vk::DescriptorSetLayout"**
  %24 = load %"class.vk::DescriptorSetLayout"*, %"class.vk::DescriptorSetLayout"** %23, align 8
  %25 = getelementptr inbounds %"class.vk::DescriptorSetLayout", %"class.vk::DescriptorSetLayout"* %24, i64 0, i32 1
  %26 = load i32, i32* %25, align 4
  %27 = add i32 %26, %21
  %28 = add nuw nsw i64 %20, 1
  %29 = icmp ult i64 %28, %8
  br i1 %29, label %19, label %9
}

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define hidden i64 @_ZNK2vk14PipelineLayout21getDescriptorSetCountEv(%"class.vk::PipelineLayout"* nocapture readonly) local_unnamed_addr #4 align 2 {
  %2 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 3
  %3 = load i32, i32* %2, align 8
  %4 = zext i32 %3 to i64
  ret i64 %4
}

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define hidden i32 @_ZNK2vk14PipelineLayout15getBindingCountEj(%"class.vk::PipelineLayout"* nocapture readonly, i32) local_unnamed_addr #4 align 2 {
  %3 = zext i32 %1 to i64
  %4 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 2, i64 %3, i32 1
  %5 = load i32, i32* %4, align 8
  ret i32 %5
}

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define hidden i32 @_ZNK2vk14PipelineLayout21getDynamicOffsetIndexEjj(%"class.vk::PipelineLayout"* nocapture readonly, i32, i32) local_unnamed_addr #4 align 2 {
  %4 = zext i32 %1 to i64
  %5 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 2, i64 %4, i32 0
  %6 = load %"struct.vk::PipelineLayout::Binding"*, %"struct.vk::PipelineLayout::Binding"** %5, align 8
  %7 = zext i32 %2 to i64
  %8 = getelementptr inbounds %"struct.vk::PipelineLayout::Binding", %"struct.vk::PipelineLayout::Binding"* %6, i64 %7, i32 2
  %9 = load i32, i32* %8, align 4
  ret i32 %9
}

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define hidden i32 @_ZNK2vk14PipelineLayout18getDescriptorCountEjj(%"class.vk::PipelineLayout"* nocapture readonly, i32, i32) local_unnamed_addr #4 align 2 {
  %4 = zext i32 %1 to i64
  %5 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 2, i64 %4, i32 0
  %6 = load %"struct.vk::PipelineLayout::Binding"*, %"struct.vk::PipelineLayout::Binding"** %5, align 8
  %7 = zext i32 %2 to i64
  %8 = getelementptr inbounds %"struct.vk::PipelineLayout::Binding", %"struct.vk::PipelineLayout::Binding"* %6, i64 %7, i32 3
  %9 = load i32, i32* %8, align 4
  ret i32 %9
}

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define hidden i32 @_ZNK2vk14PipelineLayout16getBindingOffsetEjj(%"class.vk::PipelineLayout"* nocapture readonly, i32, i32) local_unnamed_addr #4 align 2 {
  %4 = zext i32 %1 to i64
  %5 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 2, i64 %4, i32 0
  %6 = load %"struct.vk::PipelineLayout::Binding"*, %"struct.vk::PipelineLayout::Binding"** %5, align 8
  %7 = zext i32 %2 to i64
  %8 = getelementptr inbounds %"struct.vk::PipelineLayout::Binding", %"struct.vk::PipelineLayout::Binding"* %6, i64 %7, i32 1
  %9 = load i32, i32* %8, align 4
  ret i32 %9
}

; Function Attrs: norecurse nounwind optsize readonly ssp uwtable
define hidden i32 @_ZNK2vk14PipelineLayout17getDescriptorTypeEjj(%"class.vk::PipelineLayout"* nocapture readonly, i32, i32) local_unnamed_addr #4 align 2 {
  %4 = zext i32 %1 to i64
  %5 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 2, i64 %4, i32 0
  %6 = load %"struct.vk::PipelineLayout::Binding"*, %"struct.vk::PipelineLayout::Binding"** %5, align 8
  %7 = zext i32 %2 to i64
  %8 = getelementptr inbounds %"struct.vk::PipelineLayout::Binding", %"struct.vk::PipelineLayout::Binding"* %6, i64 %7, i32 0
  %9 = load i32, i32* %8, align 4
  ret i32 %9
}

; Function Attrs: nounwind optsize ssp uwtable
define hidden i32 @_ZNK2vk14PipelineLayout17getDescriptorSizeEjj(%"class.vk::PipelineLayout"* nocapture readonly, i32, i32) local_unnamed_addr #0 align 2 {
  %4 = zext i32 %1 to i64
  %5 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 2, i64 %4, i32 0
  %6 = load %"struct.vk::PipelineLayout::Binding"*, %"struct.vk::PipelineLayout::Binding"** %5, align 8
  %7 = zext i32 %2 to i64
  %8 = getelementptr inbounds %"struct.vk::PipelineLayout::Binding", %"struct.vk::PipelineLayout::Binding"* %6, i64 %7, i32 0
  %9 = load i32, i32* %8, align 4
  %10 = tail call i32 @_ZN2vk19DescriptorSetLayout17GetDescriptorSizeE16VkDescriptorType(i32 %9) #5
  ret i32 %10
}

; Function Attrs: optsize
declare i32 @_ZN2vk19DescriptorSetLayout17GetDescriptorSizeE16VkDescriptorType(i32) local_unnamed_addr #2

; Function Attrs: nounwind optsize ssp uwtable
define hidden zeroext i1 @_ZNK2vk14PipelineLayout19isDescriptorDynamicEjj(%"class.vk::PipelineLayout"* nocapture readonly, i32, i32) local_unnamed_addr #0 align 2 {
  %4 = zext i32 %1 to i64
  %5 = getelementptr inbounds %"class.vk::PipelineLayout", %"class.vk::PipelineLayout"* %0, i64 0, i32 2, i64 %4, i32 0
  %6 = load %"struct.vk::PipelineLayout::Binding"*, %"struct.vk::PipelineLayout::Binding"** %5, align 8
  %7 = zext i32 %2 to i64
  %8 = getelementptr inbounds %"struct.vk::PipelineLayout::Binding", %"struct.vk::PipelineLayout::Binding"* %6, i64 %7, i32 0
  %9 = load i32, i32* %8, align 4
  %10 = tail call zeroext i1 @_ZN2vk19DescriptorSetLayout19IsDescriptorDynamicE16VkDescriptorType(i32 %9) #5
  ret i1 %10
}

attributes #0 = { nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { optsize "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nofree norecurse nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { norecurse nounwind optsize readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nounwind optsize }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
