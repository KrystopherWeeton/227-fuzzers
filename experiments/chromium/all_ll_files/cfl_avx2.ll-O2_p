; ModuleID = '../../third_party/libaom/source/libaom/av1/common/x86/cfl_avx2.c'
source_filename = "../../third_party/libaom/source/libaom/av1/common/x86/cfl_avx2.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

@cfl_get_luma_subsampling_420_lbd_avx2.subfn_420 = internal unnamed_addr constant [19 x void (i8*, i32, i16*)*] [void (i8*, i32, i16*)* @cfl_subsample_lbd_420_4x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_8x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_16x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_32x32_avx2, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_4x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_8x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_8x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_16x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_16x32_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_32x16_avx2, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_4x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_16x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_8x32_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_420_32x8_avx2, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* null], align 16
@cfl_get_luma_subsampling_422_lbd_avx2.subfn_422 = internal unnamed_addr constant [19 x void (i8*, i32, i16*)*] [void (i8*, i32, i16*)* @cfl_subsample_lbd_422_4x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_8x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_16x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_32x32_avx2, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_4x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_8x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_8x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_16x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_16x32_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_32x16_avx2, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_4x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_16x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_8x32_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_422_32x8_avx2, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* null], align 16
@cfl_get_luma_subsampling_444_lbd_avx2.subfn_444 = internal unnamed_addr constant [19 x void (i8*, i32, i16*)*] [void (i8*, i32, i16*)* @cfl_subsample_lbd_444_4x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_8x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_16x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_32x32_avx2, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_4x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_8x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_8x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_16x8_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_16x32_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_32x16_avx2, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_4x16_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_16x4_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_8x32_ssse3, void (i8*, i32, i16*)* @cfl_subsample_lbd_444_32x8_avx2, void (i8*, i32, i16*)* null, void (i8*, i32, i16*)* null], align 16
@cfl_get_predict_lbd_fn_avx2.pred = internal unnamed_addr constant [19 x void (i16*, i8*, i32, i32)*] [void (i16*, i8*, i32, i32)* @cfl_predict_lbd_4x4_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_8x8_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_16x16_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_32x32_avx2, void (i16*, i8*, i32, i32)* null, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_4x8_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_8x4_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_8x16_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_16x8_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_16x32_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_32x16_avx2, void (i16*, i8*, i32, i32)* null, void (i16*, i8*, i32, i32)* null, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_4x16_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_16x4_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_8x32_ssse3, void (i16*, i8*, i32, i32)* @cfl_predict_lbd_32x8_avx2, void (i16*, i8*, i32, i32)* null, void (i16*, i8*, i32, i32)* null], align 16
@cfl_get_subtract_average_fn_avx2.sub_avg = internal unnamed_addr constant [19 x void (i16*, i16*)*] [void (i16*, i16*)* @cfl_subtract_average_4x4_sse2, void (i16*, i16*)* @cfl_subtract_average_8x8_sse2, void (i16*, i16*)* @cfl_subtract_average_16x16_avx2, void (i16*, i16*)* @cfl_subtract_average_32x32_avx2, void (i16*, i16*)* null, void (i16*, i16*)* @cfl_subtract_average_4x8_sse2, void (i16*, i16*)* @cfl_subtract_average_8x4_sse2, void (i16*, i16*)* @cfl_subtract_average_8x16_sse2, void (i16*, i16*)* @cfl_subtract_average_16x8_avx2, void (i16*, i16*)* @cfl_subtract_average_16x32_avx2, void (i16*, i16*)* @cfl_subtract_average_32x16_avx2, void (i16*, i16*)* null, void (i16*, i16*)* null, void (i16*, i16*)* @cfl_subtract_average_4x16_sse2, void (i16*, i16*)* @cfl_subtract_average_16x4_avx2, void (i16*, i16*)* @cfl_subtract_average_8x32_sse2, void (i16*, i16*)* @cfl_subtract_average_32x8_avx2, void (i16*, i16*)* null, void (i16*, i16*)* null], align 16

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_32x32_avx2(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = bitcast i16* %2 to <4 x i64>*
  %6 = getelementptr inbounds i16, i16* %2, i64 512
  %7 = bitcast i16* %6 to <4 x i64>*
  %8 = sext i32 %1 to i64
  %9 = sext i32 %4 to i64
  br label %10

10:                                               ; preds = %10, %3
  %11 = phi <4 x i64>* [ %5, %3 ], [ %23, %10 ]
  %12 = phi i8* [ %0, %3 ], [ %22, %10 ]
  %13 = bitcast i8* %12 to <32 x i8>*
  %14 = load <32 x i8>, <32 x i8>* %13, align 1
  %15 = getelementptr inbounds i8, i8* %12, i64 %8
  %16 = bitcast i8* %15 to <32 x i8>*
  %17 = load <32 x i8>, <32 x i8>* %16, align 1
  %18 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %14, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %19 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %17, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %20 = add <16 x i16> %19, %18
  %21 = bitcast <4 x i64>* %11 to <16 x i16>*
  store <16 x i16> %20, <16 x i16>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %12, i64 %9
  %23 = getelementptr inbounds <4 x i64>, <4 x i64>* %11, i64 2
  %24 = icmp ult <4 x i64>* %23, %7
  br i1 %24, label %10, label %25

25:                                               ; preds = %10
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_32x16_avx2(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = sext i32 %1 to i64
  %6 = sext i32 %4 to i64
  %7 = bitcast i8* %0 to <32 x i8>*
  %8 = load <32 x i8>, <32 x i8>* %7, align 1
  %9 = getelementptr inbounds i8, i8* %0, i64 %5
  %10 = bitcast i8* %9 to <32 x i8>*
  %11 = load <32 x i8>, <32 x i8>* %10, align 1
  %12 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %8, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %13 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %11, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %14 = add <16 x i16> %13, %12
  %15 = bitcast i16* %2 to <16 x i16>*
  store <16 x i16> %14, <16 x i16>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 %6
  %17 = getelementptr inbounds i16, i16* %2, i64 32
  %18 = bitcast i8* %16 to <32 x i8>*
  %19 = load <32 x i8>, <32 x i8>* %18, align 1
  %20 = getelementptr inbounds i8, i8* %16, i64 %5
  %21 = bitcast i8* %20 to <32 x i8>*
  %22 = load <32 x i8>, <32 x i8>* %21, align 1
  %23 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %19, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %24 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %22, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %25 = add <16 x i16> %24, %23
  %26 = bitcast i16* %17 to <16 x i16>*
  store <16 x i16> %25, <16 x i16>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %16, i64 %6
  %28 = getelementptr inbounds i16, i16* %2, i64 64
  %29 = bitcast i8* %27 to <32 x i8>*
  %30 = load <32 x i8>, <32 x i8>* %29, align 1
  %31 = getelementptr inbounds i8, i8* %27, i64 %5
  %32 = bitcast i8* %31 to <32 x i8>*
  %33 = load <32 x i8>, <32 x i8>* %32, align 1
  %34 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %30, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %35 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %33, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %36 = add <16 x i16> %35, %34
  %37 = bitcast i16* %28 to <16 x i16>*
  store <16 x i16> %36, <16 x i16>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %27, i64 %6
  %39 = getelementptr inbounds i16, i16* %2, i64 96
  %40 = bitcast i8* %38 to <32 x i8>*
  %41 = load <32 x i8>, <32 x i8>* %40, align 1
  %42 = getelementptr inbounds i8, i8* %38, i64 %5
  %43 = bitcast i8* %42 to <32 x i8>*
  %44 = load <32 x i8>, <32 x i8>* %43, align 1
  %45 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %41, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %46 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %44, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %47 = add <16 x i16> %46, %45
  %48 = bitcast i16* %39 to <16 x i16>*
  store <16 x i16> %47, <16 x i16>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %38, i64 %6
  %50 = getelementptr inbounds i16, i16* %2, i64 128
  %51 = bitcast i8* %49 to <32 x i8>*
  %52 = load <32 x i8>, <32 x i8>* %51, align 1
  %53 = getelementptr inbounds i8, i8* %49, i64 %5
  %54 = bitcast i8* %53 to <32 x i8>*
  %55 = load <32 x i8>, <32 x i8>* %54, align 1
  %56 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %52, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %57 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %55, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %58 = add <16 x i16> %57, %56
  %59 = bitcast i16* %50 to <16 x i16>*
  store <16 x i16> %58, <16 x i16>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %49, i64 %6
  %61 = getelementptr inbounds i16, i16* %2, i64 160
  %62 = bitcast i8* %60 to <32 x i8>*
  %63 = load <32 x i8>, <32 x i8>* %62, align 1
  %64 = getelementptr inbounds i8, i8* %60, i64 %5
  %65 = bitcast i8* %64 to <32 x i8>*
  %66 = load <32 x i8>, <32 x i8>* %65, align 1
  %67 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %63, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %68 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %66, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %69 = add <16 x i16> %68, %67
  %70 = bitcast i16* %61 to <16 x i16>*
  store <16 x i16> %69, <16 x i16>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %60, i64 %6
  %72 = getelementptr inbounds i16, i16* %2, i64 192
  %73 = bitcast i8* %71 to <32 x i8>*
  %74 = load <32 x i8>, <32 x i8>* %73, align 1
  %75 = getelementptr inbounds i8, i8* %71, i64 %5
  %76 = bitcast i8* %75 to <32 x i8>*
  %77 = load <32 x i8>, <32 x i8>* %76, align 1
  %78 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %74, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %79 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %77, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %80 = add <16 x i16> %79, %78
  %81 = bitcast i16* %72 to <16 x i16>*
  store <16 x i16> %80, <16 x i16>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %71, i64 %6
  %83 = getelementptr inbounds i16, i16* %2, i64 224
  %84 = bitcast i8* %82 to <32 x i8>*
  %85 = load <32 x i8>, <32 x i8>* %84, align 1
  %86 = getelementptr inbounds i8, i8* %82, i64 %5
  %87 = bitcast i8* %86 to <32 x i8>*
  %88 = load <32 x i8>, <32 x i8>* %87, align 1
  %89 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %85, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %90 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %88, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %91 = add <16 x i16> %90, %89
  %92 = bitcast i16* %83 to <16 x i16>*
  store <16 x i16> %91, <16 x i16>* %92, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_420_32x8_avx2(i8* nocapture readonly, i32, i16*) #0 {
  %4 = shl i32 %1, 1
  %5 = sext i32 %1 to i64
  %6 = sext i32 %4 to i64
  %7 = bitcast i8* %0 to <32 x i8>*
  %8 = load <32 x i8>, <32 x i8>* %7, align 1
  %9 = getelementptr inbounds i8, i8* %0, i64 %5
  %10 = bitcast i8* %9 to <32 x i8>*
  %11 = load <32 x i8>, <32 x i8>* %10, align 1
  %12 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %8, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %13 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %11, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %14 = add <16 x i16> %13, %12
  %15 = bitcast i16* %2 to <16 x i16>*
  store <16 x i16> %14, <16 x i16>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 %6
  %17 = getelementptr inbounds i16, i16* %2, i64 32
  %18 = bitcast i8* %16 to <32 x i8>*
  %19 = load <32 x i8>, <32 x i8>* %18, align 1
  %20 = getelementptr inbounds i8, i8* %16, i64 %5
  %21 = bitcast i8* %20 to <32 x i8>*
  %22 = load <32 x i8>, <32 x i8>* %21, align 1
  %23 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %19, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %24 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %22, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %25 = add <16 x i16> %24, %23
  %26 = bitcast i16* %17 to <16 x i16>*
  store <16 x i16> %25, <16 x i16>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %16, i64 %6
  %28 = getelementptr inbounds i16, i16* %2, i64 64
  %29 = bitcast i8* %27 to <32 x i8>*
  %30 = load <32 x i8>, <32 x i8>* %29, align 1
  %31 = getelementptr inbounds i8, i8* %27, i64 %5
  %32 = bitcast i8* %31 to <32 x i8>*
  %33 = load <32 x i8>, <32 x i8>* %32, align 1
  %34 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %30, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %35 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %33, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %36 = add <16 x i16> %35, %34
  %37 = bitcast i16* %28 to <16 x i16>*
  store <16 x i16> %36, <16 x i16>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %27, i64 %6
  %39 = getelementptr inbounds i16, i16* %2, i64 96
  %40 = bitcast i8* %38 to <32 x i8>*
  %41 = load <32 x i8>, <32 x i8>* %40, align 1
  %42 = getelementptr inbounds i8, i8* %38, i64 %5
  %43 = bitcast i8* %42 to <32 x i8>*
  %44 = load <32 x i8>, <32 x i8>* %43, align 1
  %45 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %41, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %46 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %44, <32 x i8> <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>) #5
  %47 = add <16 x i16> %46, %45
  %48 = bitcast i16* %39 to <16 x i16>*
  store <16 x i16> %47, <16 x i16>* %48, align 1
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void (i8*, i32, i16*)* @cfl_get_luma_subsampling_420_lbd_avx2(i8 zeroext) local_unnamed_addr #1 {
  %2 = zext i8 %0 to i64
  %3 = getelementptr inbounds [19 x void (i8*, i32, i16*)*], [19 x void (i8*, i32, i16*)*]* @cfl_get_luma_subsampling_420_lbd_avx2.subfn_420, i64 0, i64 %2
  %4 = load void (i8*, i32, i16*)*, void (i8*, i32, i16*)** %3, align 8
  ret void (i8*, i32, i16*)* %4
}

declare void @cfl_subsample_lbd_420_4x4_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_420_8x8_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_420_16x16_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_420_4x8_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_420_8x4_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_420_8x16_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_420_16x8_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_420_16x32_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_420_4x16_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_420_16x4_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_420_8x32_ssse3(i8*, i32, i16*) #2

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_32x32_avx2(i8* nocapture readonly, i32, i16*) #0 {
  %4 = bitcast i16* %2 to <4 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 1024
  %6 = bitcast i16* %5 to <4 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <4 x i64>* [ %4, %3 ], [ %16, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %15, %8 ]
  %11 = bitcast i8* %10 to <32 x i8>*
  %12 = load <32 x i8>, <32 x i8>* %11, align 1
  %13 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %12, <32 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %14 = bitcast <4 x i64>* %9 to <16 x i16>*
  store <16 x i16> %13, <16 x i16>* %14, align 1
  %15 = getelementptr inbounds i8, i8* %10, i64 %7
  %16 = getelementptr inbounds <4 x i64>, <4 x i64>* %9, i64 2
  %17 = icmp ult <4 x i64>* %16, %6
  br i1 %17, label %8, label %18

18:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_32x16_avx2(i8* nocapture readonly, i32, i16*) #0 {
  %4 = bitcast i16* %2 to <4 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 512
  %6 = bitcast i16* %5 to <4 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <4 x i64>* [ %4, %3 ], [ %16, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %15, %8 ]
  %11 = bitcast i8* %10 to <32 x i8>*
  %12 = load <32 x i8>, <32 x i8>* %11, align 1
  %13 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %12, <32 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %14 = bitcast <4 x i64>* %9 to <16 x i16>*
  store <16 x i16> %13, <16 x i16>* %14, align 1
  %15 = getelementptr inbounds i8, i8* %10, i64 %7
  %16 = getelementptr inbounds <4 x i64>, <4 x i64>* %9, i64 2
  %17 = icmp ult <4 x i64>* %16, %6
  br i1 %17, label %8, label %18

18:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_422_32x8_avx2(i8* nocapture readonly, i32, i16*) #0 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to <32 x i8>*
  %6 = load <32 x i8>, <32 x i8>* %5, align 1
  %7 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %6, <32 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %8 = bitcast i16* %2 to <16 x i16>*
  store <16 x i16> %7, <16 x i16>* %8, align 1
  %9 = getelementptr inbounds i8, i8* %0, i64 %4
  %10 = getelementptr inbounds i16, i16* %2, i64 32
  %11 = bitcast i8* %9 to <32 x i8>*
  %12 = load <32 x i8>, <32 x i8>* %11, align 1
  %13 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %12, <32 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %14 = bitcast i16* %10 to <16 x i16>*
  store <16 x i16> %13, <16 x i16>* %14, align 1
  %15 = getelementptr inbounds i8, i8* %9, i64 %4
  %16 = getelementptr inbounds i16, i16* %2, i64 64
  %17 = bitcast i8* %15 to <32 x i8>*
  %18 = load <32 x i8>, <32 x i8>* %17, align 1
  %19 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %18, <32 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %20 = bitcast i16* %16 to <16 x i16>*
  store <16 x i16> %19, <16 x i16>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %15, i64 %4
  %22 = getelementptr inbounds i16, i16* %2, i64 96
  %23 = bitcast i8* %21 to <32 x i8>*
  %24 = load <32 x i8>, <32 x i8>* %23, align 1
  %25 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %24, <32 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %26 = bitcast i16* %22 to <16 x i16>*
  store <16 x i16> %25, <16 x i16>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %21, i64 %4
  %28 = getelementptr inbounds i16, i16* %2, i64 128
  %29 = bitcast i8* %27 to <32 x i8>*
  %30 = load <32 x i8>, <32 x i8>* %29, align 1
  %31 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %30, <32 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %32 = bitcast i16* %28 to <16 x i16>*
  store <16 x i16> %31, <16 x i16>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %27, i64 %4
  %34 = getelementptr inbounds i16, i16* %2, i64 160
  %35 = bitcast i8* %33 to <32 x i8>*
  %36 = load <32 x i8>, <32 x i8>* %35, align 1
  %37 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %36, <32 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %38 = bitcast i16* %34 to <16 x i16>*
  store <16 x i16> %37, <16 x i16>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %33, i64 %4
  %40 = getelementptr inbounds i16, i16* %2, i64 192
  %41 = bitcast i8* %39 to <32 x i8>*
  %42 = load <32 x i8>, <32 x i8>* %41, align 1
  %43 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %42, <32 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %44 = bitcast i16* %40 to <16 x i16>*
  store <16 x i16> %43, <16 x i16>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %39, i64 %4
  %46 = getelementptr inbounds i16, i16* %2, i64 224
  %47 = bitcast i8* %45 to <32 x i8>*
  %48 = load <32 x i8>, <32 x i8>* %47, align 1
  %49 = tail call <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8> %48, <32 x i8> <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>) #5
  %50 = bitcast i16* %46 to <16 x i16>*
  store <16 x i16> %49, <16 x i16>* %50, align 1
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void (i8*, i32, i16*)* @cfl_get_luma_subsampling_422_lbd_avx2(i8 zeroext) local_unnamed_addr #1 {
  %2 = zext i8 %0 to i64
  %3 = getelementptr inbounds [19 x void (i8*, i32, i16*)*], [19 x void (i8*, i32, i16*)*]* @cfl_get_luma_subsampling_422_lbd_avx2.subfn_422, i64 0, i64 %2
  %4 = load void (i8*, i32, i16*)*, void (i8*, i32, i16*)** %3, align 8
  ret void (i8*, i32, i16*)* %4
}

declare void @cfl_subsample_lbd_422_4x4_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_422_8x8_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_422_16x16_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_422_4x8_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_422_8x4_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_422_8x16_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_422_16x8_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_422_16x32_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_422_4x16_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_422_16x4_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_422_8x32_ssse3(i8*, i32, i16*) #2

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_32x32_avx2(i8* nocapture readonly, i32, i16*) #3 {
  %4 = bitcast i16* %2 to <4 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 1024
  %6 = bitcast i16* %5 to <4 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <4 x i64>* [ %4, %3 ], [ %25, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %24, %8 ]
  %11 = bitcast i8* %10 to <4 x i64>*
  %12 = load <4 x i64>, <4 x i64>* %11, align 1
  %13 = shufflevector <4 x i64> %12, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %14 = bitcast <4 x i64> %13 to <32 x i8>
  %15 = shufflevector <32 x i8> %14, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %16 = bitcast <32 x i8> %15 to <16 x i16>
  %17 = shl <16 x i16> %16, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %18 = shufflevector <32 x i8> %14, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %19 = bitcast <32 x i8> %18 to <16 x i16>
  %20 = shl <16 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = bitcast <4 x i64>* %9 to <16 x i16>*
  store <16 x i16> %17, <16 x i16>* %21, align 1
  %22 = getelementptr inbounds <4 x i64>, <4 x i64>* %9, i64 1
  %23 = bitcast <4 x i64>* %22 to <16 x i16>*
  store <16 x i16> %20, <16 x i16>* %23, align 1
  %24 = getelementptr inbounds i8, i8* %10, i64 %7
  %25 = getelementptr inbounds <4 x i64>, <4 x i64>* %9, i64 2
  %26 = icmp ult <4 x i64>* %25, %6
  br i1 %26, label %8, label %27

27:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_32x16_avx2(i8* nocapture readonly, i32, i16*) #3 {
  %4 = bitcast i16* %2 to <4 x i64>*
  %5 = getelementptr inbounds i16, i16* %2, i64 512
  %6 = bitcast i16* %5 to <4 x i64>*
  %7 = sext i32 %1 to i64
  br label %8

8:                                                ; preds = %8, %3
  %9 = phi <4 x i64>* [ %4, %3 ], [ %25, %8 ]
  %10 = phi i8* [ %0, %3 ], [ %24, %8 ]
  %11 = bitcast i8* %10 to <4 x i64>*
  %12 = load <4 x i64>, <4 x i64>* %11, align 1
  %13 = shufflevector <4 x i64> %12, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %14 = bitcast <4 x i64> %13 to <32 x i8>
  %15 = shufflevector <32 x i8> %14, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %16 = bitcast <32 x i8> %15 to <16 x i16>
  %17 = shl <16 x i16> %16, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %18 = shufflevector <32 x i8> %14, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %19 = bitcast <32 x i8> %18 to <16 x i16>
  %20 = shl <16 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = bitcast <4 x i64>* %9 to <16 x i16>*
  store <16 x i16> %17, <16 x i16>* %21, align 1
  %22 = getelementptr inbounds <4 x i64>, <4 x i64>* %9, i64 1
  %23 = bitcast <4 x i64>* %22 to <16 x i16>*
  store <16 x i16> %20, <16 x i16>* %23, align 1
  %24 = getelementptr inbounds i8, i8* %10, i64 %7
  %25 = getelementptr inbounds <4 x i64>, <4 x i64>* %9, i64 2
  %26 = icmp ult <4 x i64>* %25, %6
  br i1 %26, label %8, label %27

27:                                               ; preds = %8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden void @cfl_subsample_lbd_444_32x8_avx2(i8* nocapture readonly, i32, i16*) #3 {
  %4 = sext i32 %1 to i64
  %5 = bitcast i8* %0 to <4 x i64>*
  %6 = load <4 x i64>, <4 x i64>* %5, align 1
  %7 = shufflevector <4 x i64> %6, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %8 = bitcast <4 x i64> %7 to <32 x i8>
  %9 = shufflevector <32 x i8> %8, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %10 = bitcast <32 x i8> %9 to <16 x i16>
  %11 = shl <16 x i16> %10, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %12 = shufflevector <32 x i8> %8, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %13 = bitcast <32 x i8> %12 to <16 x i16>
  %14 = shl <16 x i16> %13, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %15 = bitcast i16* %2 to <16 x i16>*
  store <16 x i16> %11, <16 x i16>* %15, align 1
  %16 = getelementptr inbounds i16, i16* %2, i64 16
  %17 = bitcast i16* %16 to <16 x i16>*
  store <16 x i16> %14, <16 x i16>* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %4
  %19 = getelementptr inbounds i16, i16* %2, i64 32
  %20 = bitcast i8* %18 to <4 x i64>*
  %21 = load <4 x i64>, <4 x i64>* %20, align 1
  %22 = shufflevector <4 x i64> %21, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %23 = bitcast <4 x i64> %22 to <32 x i8>
  %24 = shufflevector <32 x i8> %23, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %25 = bitcast <32 x i8> %24 to <16 x i16>
  %26 = shl <16 x i16> %25, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %27 = shufflevector <32 x i8> %23, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %28 = bitcast <32 x i8> %27 to <16 x i16>
  %29 = shl <16 x i16> %28, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %30 = bitcast i16* %19 to <16 x i16>*
  store <16 x i16> %26, <16 x i16>* %30, align 1
  %31 = getelementptr inbounds i16, i16* %2, i64 48
  %32 = bitcast i16* %31 to <16 x i16>*
  store <16 x i16> %29, <16 x i16>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %18, i64 %4
  %34 = getelementptr inbounds i16, i16* %2, i64 64
  %35 = bitcast i8* %33 to <4 x i64>*
  %36 = load <4 x i64>, <4 x i64>* %35, align 1
  %37 = shufflevector <4 x i64> %36, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %38 = bitcast <4 x i64> %37 to <32 x i8>
  %39 = shufflevector <32 x i8> %38, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %40 = bitcast <32 x i8> %39 to <16 x i16>
  %41 = shl <16 x i16> %40, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %42 = shufflevector <32 x i8> %38, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %43 = bitcast <32 x i8> %42 to <16 x i16>
  %44 = shl <16 x i16> %43, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %45 = bitcast i16* %34 to <16 x i16>*
  store <16 x i16> %41, <16 x i16>* %45, align 1
  %46 = getelementptr inbounds i16, i16* %2, i64 80
  %47 = bitcast i16* %46 to <16 x i16>*
  store <16 x i16> %44, <16 x i16>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %33, i64 %4
  %49 = getelementptr inbounds i16, i16* %2, i64 96
  %50 = bitcast i8* %48 to <4 x i64>*
  %51 = load <4 x i64>, <4 x i64>* %50, align 1
  %52 = shufflevector <4 x i64> %51, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %53 = bitcast <4 x i64> %52 to <32 x i8>
  %54 = shufflevector <32 x i8> %53, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %55 = bitcast <32 x i8> %54 to <16 x i16>
  %56 = shl <16 x i16> %55, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %57 = shufflevector <32 x i8> %53, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %58 = bitcast <32 x i8> %57 to <16 x i16>
  %59 = shl <16 x i16> %58, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %60 = bitcast i16* %49 to <16 x i16>*
  store <16 x i16> %56, <16 x i16>* %60, align 1
  %61 = getelementptr inbounds i16, i16* %2, i64 112
  %62 = bitcast i16* %61 to <16 x i16>*
  store <16 x i16> %59, <16 x i16>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %48, i64 %4
  %64 = getelementptr inbounds i16, i16* %2, i64 128
  %65 = bitcast i8* %63 to <4 x i64>*
  %66 = load <4 x i64>, <4 x i64>* %65, align 1
  %67 = shufflevector <4 x i64> %66, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %68 = bitcast <4 x i64> %67 to <32 x i8>
  %69 = shufflevector <32 x i8> %68, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %70 = bitcast <32 x i8> %69 to <16 x i16>
  %71 = shl <16 x i16> %70, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %72 = shufflevector <32 x i8> %68, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %73 = bitcast <32 x i8> %72 to <16 x i16>
  %74 = shl <16 x i16> %73, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %75 = bitcast i16* %64 to <16 x i16>*
  store <16 x i16> %71, <16 x i16>* %75, align 1
  %76 = getelementptr inbounds i16, i16* %2, i64 144
  %77 = bitcast i16* %76 to <16 x i16>*
  store <16 x i16> %74, <16 x i16>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %63, i64 %4
  %79 = getelementptr inbounds i16, i16* %2, i64 160
  %80 = bitcast i8* %78 to <4 x i64>*
  %81 = load <4 x i64>, <4 x i64>* %80, align 1
  %82 = shufflevector <4 x i64> %81, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %83 = bitcast <4 x i64> %82 to <32 x i8>
  %84 = shufflevector <32 x i8> %83, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %85 = bitcast <32 x i8> %84 to <16 x i16>
  %86 = shl <16 x i16> %85, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %87 = shufflevector <32 x i8> %83, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %88 = bitcast <32 x i8> %87 to <16 x i16>
  %89 = shl <16 x i16> %88, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %90 = bitcast i16* %79 to <16 x i16>*
  store <16 x i16> %86, <16 x i16>* %90, align 1
  %91 = getelementptr inbounds i16, i16* %2, i64 176
  %92 = bitcast i16* %91 to <16 x i16>*
  store <16 x i16> %89, <16 x i16>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %78, i64 %4
  %94 = getelementptr inbounds i16, i16* %2, i64 192
  %95 = bitcast i8* %93 to <4 x i64>*
  %96 = load <4 x i64>, <4 x i64>* %95, align 1
  %97 = shufflevector <4 x i64> %96, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %98 = bitcast <4 x i64> %97 to <32 x i8>
  %99 = shufflevector <32 x i8> %98, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %100 = bitcast <32 x i8> %99 to <16 x i16>
  %101 = shl <16 x i16> %100, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %102 = shufflevector <32 x i8> %98, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %103 = bitcast <32 x i8> %102 to <16 x i16>
  %104 = shl <16 x i16> %103, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %105 = bitcast i16* %94 to <16 x i16>*
  store <16 x i16> %101, <16 x i16>* %105, align 1
  %106 = getelementptr inbounds i16, i16* %2, i64 208
  %107 = bitcast i16* %106 to <16 x i16>*
  store <16 x i16> %104, <16 x i16>* %107, align 1
  %108 = getelementptr inbounds i8, i8* %93, i64 %4
  %109 = getelementptr inbounds i16, i16* %2, i64 224
  %110 = bitcast i8* %108 to <4 x i64>*
  %111 = load <4 x i64>, <4 x i64>* %110, align 1
  %112 = shufflevector <4 x i64> %111, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %113 = bitcast <4 x i64> %112 to <32 x i8>
  %114 = shufflevector <32 x i8> %113, <32 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <32 x i32> <i32 0, i32 32, i32 1, i32 33, i32 2, i32 34, i32 3, i32 35, i32 4, i32 36, i32 5, i32 37, i32 6, i32 38, i32 7, i32 39, i32 16, i32 48, i32 17, i32 49, i32 18, i32 50, i32 19, i32 51, i32 20, i32 52, i32 21, i32 53, i32 22, i32 54, i32 23, i32 55>
  %115 = bitcast <32 x i8> %114 to <16 x i16>
  %116 = shl <16 x i16> %115, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %117 = shufflevector <32 x i8> %113, <32 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <32 x i32> <i32 8, i32 40, i32 9, i32 41, i32 10, i32 42, i32 11, i32 43, i32 12, i32 44, i32 13, i32 45, i32 14, i32 46, i32 15, i32 47, i32 24, i32 56, i32 25, i32 57, i32 26, i32 58, i32 27, i32 59, i32 28, i32 60, i32 29, i32 61, i32 30, i32 62, i32 31, i32 63>
  %118 = bitcast <32 x i8> %117 to <16 x i16>
  %119 = shl <16 x i16> %118, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %120 = bitcast i16* %109 to <16 x i16>*
  store <16 x i16> %116, <16 x i16>* %120, align 1
  %121 = getelementptr inbounds i16, i16* %2, i64 240
  %122 = bitcast i16* %121 to <16 x i16>*
  store <16 x i16> %119, <16 x i16>* %122, align 1
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void (i8*, i32, i16*)* @cfl_get_luma_subsampling_444_lbd_avx2(i8 zeroext) local_unnamed_addr #1 {
  %2 = zext i8 %0 to i64
  %3 = getelementptr inbounds [19 x void (i8*, i32, i16*)*], [19 x void (i8*, i32, i16*)*]* @cfl_get_luma_subsampling_444_lbd_avx2.subfn_444, i64 0, i64 %2
  %4 = load void (i8*, i32, i16*)*, void (i8*, i32, i16*)** %3, align 8
  ret void (i8*, i32, i16*)* %4
}

declare void @cfl_subsample_lbd_444_4x4_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_444_8x8_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_444_16x16_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_444_4x8_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_444_8x4_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_444_8x16_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_444_16x8_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_444_16x32_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_444_4x16_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_444_16x4_ssse3(i8*, i32, i16*) #2

declare void @cfl_subsample_lbd_444_8x32_ssse3(i8*, i32, i16*) #2

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_32x8_avx2(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <16 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <16 x i16> %6, <16 x i16> undef, <16 x i32> zeroinitializer
  %8 = sub <16 x i16> zeroinitializer, %7
  %9 = icmp slt <16 x i16> %7, zeroinitializer
  %10 = select <16 x i1> %9, <16 x i16> %8, <16 x i16> %7
  %11 = shl <16 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <16 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <16 x i16> %14, <16 x i16> undef, <16 x i32> zeroinitializer
  %16 = bitcast i16* %0 to <4 x i64>*
  %17 = getelementptr inbounds i16, i16* %0, i64 256
  %18 = bitcast i16* %17 to <4 x i64>*
  %19 = sext i32 %2 to i64
  br label %20

20:                                               ; preds = %20, %4
  %21 = phi <4 x i64>* [ %16, %4 ], [ %47, %20 ]
  %22 = phi i8* [ %1, %4 ], [ %46, %20 ]
  %23 = bitcast <4 x i64>* %21 to <16 x i16>*
  %24 = load <16 x i16>, <16 x i16>* %23, align 1
  %25 = tail call <16 x i16> @llvm.x86.avx2.psign.w(<16 x i16> %7, <16 x i16> %24) #5
  %26 = sub <16 x i16> zeroinitializer, %24
  %27 = icmp slt <16 x i16> %24, zeroinitializer
  %28 = select <16 x i1> %27, <16 x i16> %26, <16 x i16> %24
  %29 = tail call <16 x i16> @llvm.x86.avx2.pmul.hr.sw(<16 x i16> %28, <16 x i16> %11) #5
  %30 = tail call <16 x i16> @llvm.x86.avx2.psign.w(<16 x i16> %29, <16 x i16> %25) #5
  %31 = add <16 x i16> %30, %15
  %32 = getelementptr inbounds <4 x i64>, <4 x i64>* %21, i64 1
  %33 = bitcast <4 x i64>* %32 to <16 x i16>*
  %34 = load <16 x i16>, <16 x i16>* %33, align 1
  %35 = tail call <16 x i16> @llvm.x86.avx2.psign.w(<16 x i16> %7, <16 x i16> %34) #5
  %36 = sub <16 x i16> zeroinitializer, %34
  %37 = icmp slt <16 x i16> %34, zeroinitializer
  %38 = select <16 x i1> %37, <16 x i16> %36, <16 x i16> %34
  %39 = tail call <16 x i16> @llvm.x86.avx2.pmul.hr.sw(<16 x i16> %38, <16 x i16> %11) #5
  %40 = tail call <16 x i16> @llvm.x86.avx2.psign.w(<16 x i16> %39, <16 x i16> %35) #5
  %41 = add <16 x i16> %40, %15
  %42 = tail call <32 x i8> @llvm.x86.avx2.packuswb(<16 x i16> %31, <16 x i16> %41) #5
  %43 = bitcast <32 x i8> %42 to <4 x i64>
  %44 = shufflevector <4 x i64> %43, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %45 = bitcast i8* %22 to <4 x i64>*
  store <4 x i64> %44, <4 x i64>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %22, i64 %19
  %47 = getelementptr inbounds <4 x i64>, <4 x i64>* %21, i64 2
  %48 = icmp ult <4 x i64>* %47, %18
  br i1 %48, label %20, label %49

49:                                               ; preds = %20
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_32x16_avx2(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <16 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <16 x i16> %6, <16 x i16> undef, <16 x i32> zeroinitializer
  %8 = sub <16 x i16> zeroinitializer, %7
  %9 = icmp slt <16 x i16> %7, zeroinitializer
  %10 = select <16 x i1> %9, <16 x i16> %8, <16 x i16> %7
  %11 = shl <16 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <16 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <16 x i16> %14, <16 x i16> undef, <16 x i32> zeroinitializer
  %16 = bitcast i16* %0 to <4 x i64>*
  %17 = getelementptr inbounds i16, i16* %0, i64 512
  %18 = bitcast i16* %17 to <4 x i64>*
  %19 = sext i32 %2 to i64
  br label %20

20:                                               ; preds = %20, %4
  %21 = phi <4 x i64>* [ %16, %4 ], [ %47, %20 ]
  %22 = phi i8* [ %1, %4 ], [ %46, %20 ]
  %23 = bitcast <4 x i64>* %21 to <16 x i16>*
  %24 = load <16 x i16>, <16 x i16>* %23, align 1
  %25 = tail call <16 x i16> @llvm.x86.avx2.psign.w(<16 x i16> %7, <16 x i16> %24) #5
  %26 = sub <16 x i16> zeroinitializer, %24
  %27 = icmp slt <16 x i16> %24, zeroinitializer
  %28 = select <16 x i1> %27, <16 x i16> %26, <16 x i16> %24
  %29 = tail call <16 x i16> @llvm.x86.avx2.pmul.hr.sw(<16 x i16> %28, <16 x i16> %11) #5
  %30 = tail call <16 x i16> @llvm.x86.avx2.psign.w(<16 x i16> %29, <16 x i16> %25) #5
  %31 = add <16 x i16> %30, %15
  %32 = getelementptr inbounds <4 x i64>, <4 x i64>* %21, i64 1
  %33 = bitcast <4 x i64>* %32 to <16 x i16>*
  %34 = load <16 x i16>, <16 x i16>* %33, align 1
  %35 = tail call <16 x i16> @llvm.x86.avx2.psign.w(<16 x i16> %7, <16 x i16> %34) #5
  %36 = sub <16 x i16> zeroinitializer, %34
  %37 = icmp slt <16 x i16> %34, zeroinitializer
  %38 = select <16 x i1> %37, <16 x i16> %36, <16 x i16> %34
  %39 = tail call <16 x i16> @llvm.x86.avx2.pmul.hr.sw(<16 x i16> %38, <16 x i16> %11) #5
  %40 = tail call <16 x i16> @llvm.x86.avx2.psign.w(<16 x i16> %39, <16 x i16> %35) #5
  %41 = add <16 x i16> %40, %15
  %42 = tail call <32 x i8> @llvm.x86.avx2.packuswb(<16 x i16> %31, <16 x i16> %41) #5
  %43 = bitcast <32 x i8> %42 to <4 x i64>
  %44 = shufflevector <4 x i64> %43, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %45 = bitcast i8* %22 to <4 x i64>*
  store <4 x i64> %44, <4 x i64>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %22, i64 %19
  %47 = getelementptr inbounds <4 x i64>, <4 x i64>* %21, i64 2
  %48 = icmp ult <4 x i64>* %47, %18
  br i1 %48, label %20, label %49

49:                                               ; preds = %20
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_predict_lbd_32x32_avx2(i16* readonly, i8* nocapture, i32, i32) #0 {
  %5 = trunc i32 %3 to i16
  %6 = insertelement <16 x i16> undef, i16 %5, i32 0
  %7 = shufflevector <16 x i16> %6, <16 x i16> undef, <16 x i32> zeroinitializer
  %8 = sub <16 x i16> zeroinitializer, %7
  %9 = icmp slt <16 x i16> %7, zeroinitializer
  %10 = select <16 x i1> %9, <16 x i16> %8, <16 x i16> %7
  %11 = shl <16 x i16> %10, <i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9, i16 9>
  %12 = load i8, i8* %1, align 1
  %13 = zext i8 %12 to i16
  %14 = insertelement <16 x i16> undef, i16 %13, i32 0
  %15 = shufflevector <16 x i16> %14, <16 x i16> undef, <16 x i32> zeroinitializer
  %16 = bitcast i16* %0 to <4 x i64>*
  %17 = getelementptr inbounds i16, i16* %0, i64 1024
  %18 = bitcast i16* %17 to <4 x i64>*
  %19 = sext i32 %2 to i64
  br label %20

20:                                               ; preds = %20, %4
  %21 = phi <4 x i64>* [ %16, %4 ], [ %47, %20 ]
  %22 = phi i8* [ %1, %4 ], [ %46, %20 ]
  %23 = bitcast <4 x i64>* %21 to <16 x i16>*
  %24 = load <16 x i16>, <16 x i16>* %23, align 1
  %25 = tail call <16 x i16> @llvm.x86.avx2.psign.w(<16 x i16> %7, <16 x i16> %24) #5
  %26 = sub <16 x i16> zeroinitializer, %24
  %27 = icmp slt <16 x i16> %24, zeroinitializer
  %28 = select <16 x i1> %27, <16 x i16> %26, <16 x i16> %24
  %29 = tail call <16 x i16> @llvm.x86.avx2.pmul.hr.sw(<16 x i16> %28, <16 x i16> %11) #5
  %30 = tail call <16 x i16> @llvm.x86.avx2.psign.w(<16 x i16> %29, <16 x i16> %25) #5
  %31 = add <16 x i16> %30, %15
  %32 = getelementptr inbounds <4 x i64>, <4 x i64>* %21, i64 1
  %33 = bitcast <4 x i64>* %32 to <16 x i16>*
  %34 = load <16 x i16>, <16 x i16>* %33, align 1
  %35 = tail call <16 x i16> @llvm.x86.avx2.psign.w(<16 x i16> %7, <16 x i16> %34) #5
  %36 = sub <16 x i16> zeroinitializer, %34
  %37 = icmp slt <16 x i16> %34, zeroinitializer
  %38 = select <16 x i1> %37, <16 x i16> %36, <16 x i16> %34
  %39 = tail call <16 x i16> @llvm.x86.avx2.pmul.hr.sw(<16 x i16> %38, <16 x i16> %11) #5
  %40 = tail call <16 x i16> @llvm.x86.avx2.psign.w(<16 x i16> %39, <16 x i16> %35) #5
  %41 = add <16 x i16> %40, %15
  %42 = tail call <32 x i8> @llvm.x86.avx2.packuswb(<16 x i16> %31, <16 x i16> %41) #5
  %43 = bitcast <32 x i8> %42 to <4 x i64>
  %44 = shufflevector <4 x i64> %43, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %45 = bitcast i8* %22 to <4 x i64>*
  store <4 x i64> %44, <4 x i64>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %22, i64 %19
  %47 = getelementptr inbounds <4 x i64>, <4 x i64>* %21, i64 2
  %48 = icmp ult <4 x i64>* %47, %18
  br i1 %48, label %20, label %49

49:                                               ; preds = %20
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void (i16*, i8*, i32, i32)* @cfl_get_predict_lbd_fn_avx2(i8 zeroext) local_unnamed_addr #1 {
  %2 = urem i8 %0, 19
  %3 = zext i8 %2 to i64
  %4 = getelementptr inbounds [19 x void (i16*, i8*, i32, i32)*], [19 x void (i16*, i8*, i32, i32)*]* @cfl_get_predict_lbd_fn_avx2.pred, i64 0, i64 %3
  %5 = load void (i16*, i8*, i32, i32)*, void (i16*, i8*, i32, i32)** %4, align 8
  ret void (i16*, i8*, i32, i32)* %5
}

declare void @cfl_predict_lbd_4x4_ssse3(i16*, i8*, i32, i32) #2

declare void @cfl_predict_lbd_8x8_ssse3(i16*, i8*, i32, i32) #2

declare void @cfl_predict_lbd_16x16_ssse3(i16*, i8*, i32, i32) #2

declare void @cfl_predict_lbd_4x8_ssse3(i16*, i8*, i32, i32) #2

declare void @cfl_predict_lbd_8x4_ssse3(i16*, i8*, i32, i32) #2

declare void @cfl_predict_lbd_8x16_ssse3(i16*, i8*, i32, i32) #2

declare void @cfl_predict_lbd_16x8_ssse3(i16*, i8*, i32, i32) #2

declare void @cfl_predict_lbd_16x32_ssse3(i16*, i8*, i32, i32) #2

declare void @cfl_predict_lbd_4x16_ssse3(i16*, i8*, i32, i32) #2

declare void @cfl_predict_lbd_16x4_ssse3(i16*, i8*, i32, i32) #2

declare void @cfl_predict_lbd_8x32_ssse3(i16*, i8*, i32, i32) #2

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subtract_average_16x4_avx2(i16* readonly, i16* nocapture) #0 {
  %3 = bitcast i16* %0 to <16 x i16>*
  %4 = load <16 x i16>, <16 x i16>* %3, align 1
  %5 = getelementptr inbounds i16, i16* %0, i64 32
  %6 = bitcast i16* %5 to <16 x i16>*
  %7 = load <16 x i16>, <16 x i16>* %6, align 1
  %8 = add <16 x i16> %7, %4
  %9 = getelementptr inbounds i16, i16* %0, i64 64
  %10 = shufflevector <16 x i16> %8, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %11 = bitcast <16 x i16> %10 to <8 x i32>
  %12 = shufflevector <16 x i16> %8, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %13 = bitcast <16 x i16> %12 to <8 x i32>
  %14 = add <8 x i32> %11, %13
  %15 = bitcast i16* %9 to <16 x i16>*
  %16 = load <16 x i16>, <16 x i16>* %15, align 1
  %17 = getelementptr inbounds i16, i16* %0, i64 96
  %18 = bitcast i16* %17 to <16 x i16>*
  %19 = load <16 x i16>, <16 x i16>* %18, align 1
  %20 = add <16 x i16> %19, %16
  %21 = shufflevector <16 x i16> %20, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %22 = shufflevector <16 x i16> %20, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %23 = bitcast <16 x i16> %21 to <8 x i32>
  %24 = bitcast <16 x i16> %22 to <8 x i32>
  %25 = add <8 x i32> %14, %23
  %26 = add <8 x i32> %25, %24
  %27 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %26, <8 x i32> %26) #5
  %28 = bitcast <8 x i32> %27 to <4 x i64>
  %29 = shufflevector <4 x i64> %28, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %30 = bitcast <4 x i64> %29 to <8 x i32>
  %31 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %30, <8 x i32> %30) #5
  %32 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %31, <8 x i32> %31) #5
  %33 = add <8 x i32> %32, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %34 = lshr <8 x i32> %33, <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %35 = tail call <16 x i16> @llvm.x86.avx2.packssdw(<8 x i32> %34, <8 x i32> %34) #5
  %36 = sub <16 x i16> %4, %35
  %37 = bitcast i16* %1 to <16 x i16>*
  store <16 x i16> %36, <16 x i16>* %37, align 1
  %38 = getelementptr inbounds i16, i16* %1, i64 32
  %39 = load <16 x i16>, <16 x i16>* %6, align 1
  %40 = sub <16 x i16> %39, %35
  %41 = bitcast i16* %38 to <16 x i16>*
  store <16 x i16> %40, <16 x i16>* %41, align 1
  %42 = getelementptr inbounds i16, i16* %0, i64 64
  %43 = getelementptr inbounds i16, i16* %1, i64 64
  %44 = bitcast i16* %42 to <16 x i16>*
  %45 = load <16 x i16>, <16 x i16>* %44, align 1
  %46 = sub <16 x i16> %45, %35
  %47 = bitcast i16* %43 to <16 x i16>*
  store <16 x i16> %46, <16 x i16>* %47, align 1
  %48 = getelementptr inbounds i16, i16* %0, i64 96
  %49 = getelementptr inbounds i16, i16* %1, i64 96
  %50 = bitcast i16* %48 to <16 x i16>*
  %51 = load <16 x i16>, <16 x i16>* %50, align 1
  %52 = sub <16 x i16> %51, %35
  %53 = bitcast i16* %49 to <16 x i16>*
  store <16 x i16> %52, <16 x i16>* %53, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subtract_average_16x8_avx2(i16* readonly, i16* nocapture) #0 {
  %3 = bitcast i16* %0 to <16 x i16>*
  %4 = load <16 x i16>, <16 x i16>* %3, align 1
  %5 = getelementptr inbounds i16, i16* %0, i64 32
  %6 = bitcast i16* %5 to <16 x i16>*
  %7 = load <16 x i16>, <16 x i16>* %6, align 1
  %8 = add <16 x i16> %7, %4
  %9 = getelementptr inbounds i16, i16* %0, i64 64
  %10 = shufflevector <16 x i16> %8, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %11 = bitcast <16 x i16> %10 to <8 x i32>
  %12 = shufflevector <16 x i16> %8, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %13 = bitcast <16 x i16> %12 to <8 x i32>
  %14 = add <8 x i32> %11, %13
  %15 = bitcast i16* %9 to <16 x i16>*
  %16 = load <16 x i16>, <16 x i16>* %15, align 1
  %17 = getelementptr inbounds i16, i16* %0, i64 96
  %18 = bitcast i16* %17 to <16 x i16>*
  %19 = load <16 x i16>, <16 x i16>* %18, align 1
  %20 = add <16 x i16> %19, %16
  %21 = shufflevector <16 x i16> %20, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %22 = shufflevector <16 x i16> %20, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %23 = bitcast <16 x i16> %21 to <8 x i32>
  %24 = bitcast <16 x i16> %22 to <8 x i32>
  %25 = add <8 x i32> %14, %23
  %26 = add <8 x i32> %25, %24
  %27 = getelementptr inbounds i16, i16* %0, i64 128
  %28 = bitcast i16* %27 to <16 x i16>*
  %29 = load <16 x i16>, <16 x i16>* %28, align 1
  %30 = getelementptr inbounds i16, i16* %0, i64 160
  %31 = bitcast i16* %30 to <16 x i16>*
  %32 = load <16 x i16>, <16 x i16>* %31, align 1
  %33 = add <16 x i16> %32, %29
  %34 = shufflevector <16 x i16> %33, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %35 = shufflevector <16 x i16> %33, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %36 = bitcast <16 x i16> %34 to <8 x i32>
  %37 = bitcast <16 x i16> %35 to <8 x i32>
  %38 = add <8 x i32> %26, %36
  %39 = add <8 x i32> %38, %37
  %40 = getelementptr inbounds i16, i16* %0, i64 192
  %41 = bitcast i16* %40 to <16 x i16>*
  %42 = load <16 x i16>, <16 x i16>* %41, align 1
  %43 = getelementptr inbounds i16, i16* %0, i64 224
  %44 = bitcast i16* %43 to <16 x i16>*
  %45 = load <16 x i16>, <16 x i16>* %44, align 1
  %46 = add <16 x i16> %45, %42
  %47 = shufflevector <16 x i16> %46, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %48 = shufflevector <16 x i16> %46, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %49 = bitcast <16 x i16> %47 to <8 x i32>
  %50 = bitcast <16 x i16> %48 to <8 x i32>
  %51 = add <8 x i32> %39, %49
  %52 = add <8 x i32> %51, %50
  %53 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %52, <8 x i32> %52) #5
  %54 = bitcast <8 x i32> %53 to <4 x i64>
  %55 = shufflevector <4 x i64> %54, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %56 = bitcast <4 x i64> %55 to <8 x i32>
  %57 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %56, <8 x i32> %56) #5
  %58 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %57, <8 x i32> %57) #5
  %59 = add <8 x i32> %58, <i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64, i32 64>
  %60 = lshr <8 x i32> %59, <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %61 = tail call <16 x i16> @llvm.x86.avx2.packssdw(<8 x i32> %60, <8 x i32> %60) #5
  %62 = sub <16 x i16> %4, %61
  %63 = bitcast i16* %1 to <16 x i16>*
  store <16 x i16> %62, <16 x i16>* %63, align 1
  %64 = getelementptr inbounds i16, i16* %1, i64 32
  %65 = load <16 x i16>, <16 x i16>* %6, align 1
  %66 = sub <16 x i16> %65, %61
  %67 = bitcast i16* %64 to <16 x i16>*
  store <16 x i16> %66, <16 x i16>* %67, align 1
  %68 = getelementptr inbounds i16, i16* %0, i64 64
  %69 = getelementptr inbounds i16, i16* %1, i64 64
  %70 = bitcast i16* %68 to <16 x i16>*
  %71 = load <16 x i16>, <16 x i16>* %70, align 1
  %72 = sub <16 x i16> %71, %61
  %73 = bitcast i16* %69 to <16 x i16>*
  store <16 x i16> %72, <16 x i16>* %73, align 1
  %74 = getelementptr inbounds i16, i16* %0, i64 96
  %75 = getelementptr inbounds i16, i16* %1, i64 96
  %76 = bitcast i16* %74 to <16 x i16>*
  %77 = load <16 x i16>, <16 x i16>* %76, align 1
  %78 = sub <16 x i16> %77, %61
  %79 = bitcast i16* %75 to <16 x i16>*
  store <16 x i16> %78, <16 x i16>* %79, align 1
  %80 = getelementptr inbounds i16, i16* %0, i64 128
  %81 = getelementptr inbounds i16, i16* %1, i64 128
  %82 = bitcast i16* %80 to <16 x i16>*
  %83 = load <16 x i16>, <16 x i16>* %82, align 1
  %84 = sub <16 x i16> %83, %61
  %85 = bitcast i16* %81 to <16 x i16>*
  store <16 x i16> %84, <16 x i16>* %85, align 1
  %86 = getelementptr inbounds i16, i16* %0, i64 160
  %87 = getelementptr inbounds i16, i16* %1, i64 160
  %88 = bitcast i16* %86 to <16 x i16>*
  %89 = load <16 x i16>, <16 x i16>* %88, align 1
  %90 = sub <16 x i16> %89, %61
  %91 = bitcast i16* %87 to <16 x i16>*
  store <16 x i16> %90, <16 x i16>* %91, align 1
  %92 = getelementptr inbounds i16, i16* %0, i64 192
  %93 = getelementptr inbounds i16, i16* %1, i64 192
  %94 = bitcast i16* %92 to <16 x i16>*
  %95 = load <16 x i16>, <16 x i16>* %94, align 1
  %96 = sub <16 x i16> %95, %61
  %97 = bitcast i16* %93 to <16 x i16>*
  store <16 x i16> %96, <16 x i16>* %97, align 1
  %98 = getelementptr inbounds i16, i16* %0, i64 224
  %99 = getelementptr inbounds i16, i16* %1, i64 224
  %100 = bitcast i16* %98 to <16 x i16>*
  %101 = load <16 x i16>, <16 x i16>* %100, align 1
  %102 = sub <16 x i16> %101, %61
  %103 = bitcast i16* %99 to <16 x i16>*
  store <16 x i16> %102, <16 x i16>* %103, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subtract_average_16x16_avx2(i16* readonly, i16* nocapture) #0 {
  %3 = getelementptr inbounds i16, i16* %0, i64 512
  %4 = bitcast i16* %3 to <4 x i64>*
  %5 = bitcast i16* %0 to <16 x i16>*
  %6 = load <16 x i16>, <16 x i16>* %5, align 1
  %7 = getelementptr inbounds i16, i16* %0, i64 32
  %8 = bitcast i16* %7 to <16 x i16>*
  %9 = load <16 x i16>, <16 x i16>* %8, align 1
  %10 = add <16 x i16> %9, %6
  %11 = getelementptr inbounds i16, i16* %0, i64 64
  %12 = shufflevector <16 x i16> %10, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %13 = bitcast <16 x i16> %12 to <8 x i32>
  %14 = shufflevector <16 x i16> %10, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %15 = bitcast <16 x i16> %14 to <8 x i32>
  %16 = add <8 x i32> %13, %15
  %17 = bitcast i16* %11 to <16 x i16>*
  %18 = load <16 x i16>, <16 x i16>* %17, align 1
  %19 = getelementptr inbounds i16, i16* %0, i64 96
  %20 = bitcast i16* %19 to <16 x i16>*
  %21 = load <16 x i16>, <16 x i16>* %20, align 1
  %22 = add <16 x i16> %21, %18
  %23 = shufflevector <16 x i16> %22, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %24 = shufflevector <16 x i16> %22, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %25 = bitcast <16 x i16> %23 to <8 x i32>
  %26 = bitcast <16 x i16> %24 to <8 x i32>
  %27 = add <8 x i32> %16, %25
  %28 = add <8 x i32> %27, %26
  %29 = getelementptr inbounds i16, i16* %0, i64 128
  %30 = bitcast i16* %29 to <16 x i16>*
  %31 = load <16 x i16>, <16 x i16>* %30, align 1
  %32 = getelementptr inbounds i16, i16* %0, i64 160
  %33 = bitcast i16* %32 to <16 x i16>*
  %34 = load <16 x i16>, <16 x i16>* %33, align 1
  %35 = add <16 x i16> %34, %31
  %36 = shufflevector <16 x i16> %35, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %37 = shufflevector <16 x i16> %35, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %38 = bitcast <16 x i16> %36 to <8 x i32>
  %39 = bitcast <16 x i16> %37 to <8 x i32>
  %40 = add <8 x i32> %28, %38
  %41 = add <8 x i32> %40, %39
  %42 = getelementptr inbounds i16, i16* %0, i64 192
  %43 = bitcast i16* %42 to <16 x i16>*
  %44 = load <16 x i16>, <16 x i16>* %43, align 1
  %45 = getelementptr inbounds i16, i16* %0, i64 224
  %46 = bitcast i16* %45 to <16 x i16>*
  %47 = load <16 x i16>, <16 x i16>* %46, align 1
  %48 = add <16 x i16> %47, %44
  %49 = shufflevector <16 x i16> %48, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %50 = shufflevector <16 x i16> %48, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %51 = bitcast <16 x i16> %49 to <8 x i32>
  %52 = bitcast <16 x i16> %50 to <8 x i32>
  %53 = add <8 x i32> %41, %51
  %54 = add <8 x i32> %53, %52
  %55 = getelementptr inbounds i16, i16* %0, i64 256
  %56 = bitcast i16* %55 to <16 x i16>*
  %57 = load <16 x i16>, <16 x i16>* %56, align 1
  %58 = getelementptr inbounds i16, i16* %0, i64 288
  %59 = bitcast i16* %58 to <16 x i16>*
  %60 = load <16 x i16>, <16 x i16>* %59, align 1
  %61 = add <16 x i16> %60, %57
  %62 = shufflevector <16 x i16> %61, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %63 = shufflevector <16 x i16> %61, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %64 = bitcast <16 x i16> %62 to <8 x i32>
  %65 = bitcast <16 x i16> %63 to <8 x i32>
  %66 = add <8 x i32> %54, %64
  %67 = add <8 x i32> %66, %65
  %68 = getelementptr inbounds i16, i16* %0, i64 320
  %69 = bitcast i16* %68 to <16 x i16>*
  %70 = load <16 x i16>, <16 x i16>* %69, align 1
  %71 = getelementptr inbounds i16, i16* %0, i64 352
  %72 = bitcast i16* %71 to <16 x i16>*
  %73 = load <16 x i16>, <16 x i16>* %72, align 1
  %74 = add <16 x i16> %73, %70
  %75 = shufflevector <16 x i16> %74, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %76 = shufflevector <16 x i16> %74, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %77 = bitcast <16 x i16> %75 to <8 x i32>
  %78 = bitcast <16 x i16> %76 to <8 x i32>
  %79 = add <8 x i32> %67, %77
  %80 = add <8 x i32> %79, %78
  %81 = getelementptr inbounds i16, i16* %0, i64 384
  %82 = bitcast i16* %81 to <16 x i16>*
  %83 = load <16 x i16>, <16 x i16>* %82, align 1
  %84 = getelementptr inbounds i16, i16* %0, i64 416
  %85 = bitcast i16* %84 to <16 x i16>*
  %86 = load <16 x i16>, <16 x i16>* %85, align 1
  %87 = add <16 x i16> %86, %83
  %88 = shufflevector <16 x i16> %87, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %89 = shufflevector <16 x i16> %87, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %90 = bitcast <16 x i16> %88 to <8 x i32>
  %91 = bitcast <16 x i16> %89 to <8 x i32>
  %92 = add <8 x i32> %80, %90
  %93 = add <8 x i32> %92, %91
  %94 = getelementptr inbounds i16, i16* %0, i64 448
  %95 = bitcast i16* %94 to <16 x i16>*
  %96 = load <16 x i16>, <16 x i16>* %95, align 1
  %97 = getelementptr inbounds i16, i16* %0, i64 480
  %98 = bitcast i16* %97 to <16 x i16>*
  %99 = load <16 x i16>, <16 x i16>* %98, align 1
  %100 = add <16 x i16> %99, %96
  %101 = shufflevector <16 x i16> %100, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %102 = shufflevector <16 x i16> %100, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %103 = bitcast <16 x i16> %101 to <8 x i32>
  %104 = bitcast <16 x i16> %102 to <8 x i32>
  %105 = add <8 x i32> %93, %103
  %106 = add <8 x i32> %105, %104
  %107 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %106, <8 x i32> %106) #5
  %108 = bitcast <8 x i32> %107 to <4 x i64>
  %109 = shufflevector <4 x i64> %108, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %110 = bitcast <4 x i64> %109 to <8 x i32>
  %111 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %110, <8 x i32> %110) #5
  %112 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %111, <8 x i32> %111) #5
  %113 = add <8 x i32> %112, <i32 128, i32 128, i32 128, i32 128, i32 128, i32 128, i32 128, i32 128>
  %114 = lshr <8 x i32> %113, <i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8>
  %115 = tail call <16 x i16> @llvm.x86.avx2.packssdw(<8 x i32> %114, <8 x i32> %114) #5
  %116 = bitcast i16* %1 to <4 x i64>*
  %117 = sub <16 x i16> %6, %115
  %118 = bitcast i16* %1 to <16 x i16>*
  store <16 x i16> %117, <16 x i16>* %118, align 1
  %119 = getelementptr inbounds i16, i16* %0, i64 32
  %120 = bitcast i16* %119 to <4 x i64>*
  br label %121

121:                                              ; preds = %2, %121
  %122 = phi <4 x i64>* [ %120, %2 ], [ %129, %121 ]
  %123 = phi <4 x i64>* [ %116, %2 ], [ %124, %121 ]
  %124 = getelementptr inbounds <4 x i64>, <4 x i64>* %123, i64 2
  %125 = bitcast <4 x i64>* %122 to <16 x i16>*
  %126 = load <16 x i16>, <16 x i16>* %125, align 1
  %127 = sub <16 x i16> %126, %115
  %128 = bitcast <4 x i64>* %124 to <16 x i16>*
  store <16 x i16> %127, <16 x i16>* %128, align 1
  %129 = getelementptr inbounds <4 x i64>, <4 x i64>* %122, i64 2
  %130 = icmp ult <4 x i64>* %129, %4
  br i1 %130, label %121, label %131

131:                                              ; preds = %121
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subtract_average_16x32_avx2(i16* readonly, i16* nocapture) #0 {
  %3 = bitcast i16* %0 to <4 x i64>*
  %4 = getelementptr inbounds i16, i16* %0, i64 1024
  %5 = bitcast i16* %4 to <4 x i64>*
  br label %6

6:                                                ; preds = %6, %2
  %7 = phi <8 x i32> [ zeroinitializer, %2 ], [ %20, %6 ]
  %8 = phi <4 x i64>* [ %3, %2 ], [ %21, %6 ]
  %9 = bitcast <4 x i64>* %8 to <16 x i16>*
  %10 = load <16 x i16>, <16 x i16>* %9, align 1
  %11 = getelementptr inbounds <4 x i64>, <4 x i64>* %8, i64 2
  %12 = bitcast <4 x i64>* %11 to <16 x i16>*
  %13 = load <16 x i16>, <16 x i16>* %12, align 1
  %14 = add <16 x i16> %13, %10
  %15 = shufflevector <16 x i16> %14, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %16 = shufflevector <16 x i16> %14, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %17 = bitcast <16 x i16> %15 to <8 x i32>
  %18 = bitcast <16 x i16> %16 to <8 x i32>
  %19 = add <8 x i32> %7, %17
  %20 = add <8 x i32> %19, %18
  %21 = getelementptr inbounds <4 x i64>, <4 x i64>* %8, i64 4
  %22 = icmp ult <4 x i64>* %21, %5
  br i1 %22, label %6, label %23

23:                                               ; preds = %6
  %24 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %20, <8 x i32> %20) #5
  %25 = bitcast <8 x i32> %24 to <4 x i64>
  %26 = shufflevector <4 x i64> %25, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %27 = bitcast <4 x i64> %26 to <8 x i32>
  %28 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %27, <8 x i32> %27) #5
  %29 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %28, <8 x i32> %28) #5
  %30 = add <8 x i32> %29, <i32 256, i32 256, i32 256, i32 256, i32 256, i32 256, i32 256, i32 256>
  %31 = lshr <8 x i32> %30, <i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9>
  %32 = tail call <16 x i16> @llvm.x86.avx2.packssdw(<8 x i32> %31, <8 x i32> %31) #5
  %33 = bitcast i16* %1 to <4 x i64>*
  br label %34

34:                                               ; preds = %34, %23
  %35 = phi <4 x i64>* [ %3, %23 ], [ %41, %34 ]
  %36 = phi <4 x i64>* [ %33, %23 ], [ %42, %34 ]
  %37 = bitcast <4 x i64>* %35 to <16 x i16>*
  %38 = load <16 x i16>, <16 x i16>* %37, align 1
  %39 = sub <16 x i16> %38, %32
  %40 = bitcast <4 x i64>* %36 to <16 x i16>*
  store <16 x i16> %39, <16 x i16>* %40, align 1
  %41 = getelementptr inbounds <4 x i64>, <4 x i64>* %35, i64 2
  %42 = getelementptr inbounds <4 x i64>, <4 x i64>* %36, i64 2
  %43 = icmp ult <4 x i64>* %41, %5
  br i1 %43, label %34, label %44

44:                                               ; preds = %34
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subtract_average_32x8_avx2(i16* readonly, i16* nocapture) #0 {
  %3 = bitcast i16* %0 to <16 x i16>*
  %4 = load <16 x i16>, <16 x i16>* %3, align 1
  %5 = getelementptr inbounds i16, i16* %0, i64 32
  %6 = bitcast i16* %5 to <16 x i16>*
  %7 = load <16 x i16>, <16 x i16>* %6, align 1
  %8 = add <16 x i16> %7, %4
  %9 = getelementptr inbounds i16, i16* %0, i64 16
  %10 = bitcast i16* %9 to <16 x i16>*
  %11 = load <16 x i16>, <16 x i16>* %10, align 1
  %12 = getelementptr inbounds i16, i16* %0, i64 48
  %13 = bitcast i16* %12 to <16 x i16>*
  %14 = load <16 x i16>, <16 x i16>* %13, align 1
  %15 = add <16 x i16> %14, %11
  %16 = getelementptr inbounds i16, i16* %0, i64 64
  %17 = shufflevector <16 x i16> %15, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %18 = bitcast <16 x i16> %17 to <8 x i32>
  %19 = shufflevector <16 x i16> %15, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %20 = bitcast <16 x i16> %19 to <8 x i32>
  %21 = add <8 x i32> %18, %20
  %22 = shufflevector <16 x i16> %8, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %23 = bitcast <16 x i16> %22 to <8 x i32>
  %24 = shufflevector <16 x i16> %8, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %25 = bitcast <16 x i16> %24 to <8 x i32>
  %26 = add <8 x i32> %23, %25
  %27 = bitcast i16* %16 to <16 x i16>*
  %28 = load <16 x i16>, <16 x i16>* %27, align 1
  %29 = getelementptr inbounds i16, i16* %0, i64 96
  %30 = bitcast i16* %29 to <16 x i16>*
  %31 = load <16 x i16>, <16 x i16>* %30, align 1
  %32 = add <16 x i16> %31, %28
  %33 = shufflevector <16 x i16> %32, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %34 = shufflevector <16 x i16> %32, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %35 = bitcast <16 x i16> %33 to <8 x i32>
  %36 = bitcast <16 x i16> %34 to <8 x i32>
  %37 = add <8 x i32> %26, %35
  %38 = add <8 x i32> %37, %36
  %39 = getelementptr inbounds i16, i16* %0, i64 80
  %40 = bitcast i16* %39 to <16 x i16>*
  %41 = load <16 x i16>, <16 x i16>* %40, align 1
  %42 = getelementptr inbounds i16, i16* %0, i64 112
  %43 = bitcast i16* %42 to <16 x i16>*
  %44 = load <16 x i16>, <16 x i16>* %43, align 1
  %45 = add <16 x i16> %44, %41
  %46 = shufflevector <16 x i16> %45, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %47 = shufflevector <16 x i16> %45, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %48 = bitcast <16 x i16> %46 to <8 x i32>
  %49 = bitcast <16 x i16> %47 to <8 x i32>
  %50 = add <8 x i32> %21, %48
  %51 = add <8 x i32> %50, %49
  %52 = getelementptr inbounds i16, i16* %0, i64 128
  %53 = bitcast i16* %52 to <16 x i16>*
  %54 = load <16 x i16>, <16 x i16>* %53, align 1
  %55 = getelementptr inbounds i16, i16* %0, i64 160
  %56 = bitcast i16* %55 to <16 x i16>*
  %57 = load <16 x i16>, <16 x i16>* %56, align 1
  %58 = add <16 x i16> %57, %54
  %59 = shufflevector <16 x i16> %58, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %60 = shufflevector <16 x i16> %58, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %61 = bitcast <16 x i16> %59 to <8 x i32>
  %62 = bitcast <16 x i16> %60 to <8 x i32>
  %63 = add <8 x i32> %38, %61
  %64 = add <8 x i32> %63, %62
  %65 = getelementptr inbounds i16, i16* %0, i64 144
  %66 = bitcast i16* %65 to <16 x i16>*
  %67 = load <16 x i16>, <16 x i16>* %66, align 1
  %68 = getelementptr inbounds i16, i16* %0, i64 176
  %69 = bitcast i16* %68 to <16 x i16>*
  %70 = load <16 x i16>, <16 x i16>* %69, align 1
  %71 = add <16 x i16> %70, %67
  %72 = shufflevector <16 x i16> %71, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %73 = shufflevector <16 x i16> %71, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %74 = bitcast <16 x i16> %72 to <8 x i32>
  %75 = bitcast <16 x i16> %73 to <8 x i32>
  %76 = add <8 x i32> %51, %74
  %77 = add <8 x i32> %76, %75
  %78 = getelementptr inbounds i16, i16* %0, i64 192
  %79 = bitcast i16* %78 to <16 x i16>*
  %80 = load <16 x i16>, <16 x i16>* %79, align 1
  %81 = getelementptr inbounds i16, i16* %0, i64 224
  %82 = bitcast i16* %81 to <16 x i16>*
  %83 = load <16 x i16>, <16 x i16>* %82, align 1
  %84 = add <16 x i16> %83, %80
  %85 = shufflevector <16 x i16> %84, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %86 = shufflevector <16 x i16> %84, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %87 = bitcast <16 x i16> %85 to <8 x i32>
  %88 = bitcast <16 x i16> %86 to <8 x i32>
  %89 = add <8 x i32> %64, %87
  %90 = add <8 x i32> %89, %88
  %91 = getelementptr inbounds i16, i16* %0, i64 208
  %92 = bitcast i16* %91 to <16 x i16>*
  %93 = load <16 x i16>, <16 x i16>* %92, align 1
  %94 = getelementptr inbounds i16, i16* %0, i64 240
  %95 = bitcast i16* %94 to <16 x i16>*
  %96 = load <16 x i16>, <16 x i16>* %95, align 1
  %97 = add <16 x i16> %96, %93
  %98 = shufflevector <16 x i16> %97, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %99 = shufflevector <16 x i16> %97, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %100 = bitcast <16 x i16> %98 to <8 x i32>
  %101 = bitcast <16 x i16> %99 to <8 x i32>
  %102 = add <8 x i32> %77, %100
  %103 = add <8 x i32> %102, %101
  %104 = add <8 x i32> %103, %90
  %105 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %104, <8 x i32> %104) #5
  %106 = bitcast <8 x i32> %105 to <4 x i64>
  %107 = shufflevector <4 x i64> %106, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %108 = bitcast <4 x i64> %107 to <8 x i32>
  %109 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %108, <8 x i32> %108) #5
  %110 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %109, <8 x i32> %109) #5
  %111 = add <8 x i32> %110, <i32 128, i32 128, i32 128, i32 128, i32 128, i32 128, i32 128, i32 128>
  %112 = lshr <8 x i32> %111, <i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8>
  %113 = tail call <16 x i16> @llvm.x86.avx2.packssdw(<8 x i32> %112, <8 x i32> %112) #5
  %114 = sub <16 x i16> %4, %113
  %115 = bitcast i16* %1 to <16 x i16>*
  store <16 x i16> %114, <16 x i16>* %115, align 1
  %116 = getelementptr inbounds i16, i16* %1, i64 16
  %117 = load <16 x i16>, <16 x i16>* %10, align 1
  %118 = sub <16 x i16> %117, %113
  %119 = bitcast i16* %116 to <16 x i16>*
  store <16 x i16> %118, <16 x i16>* %119, align 1
  %120 = getelementptr inbounds i16, i16* %1, i64 32
  %121 = load <16 x i16>, <16 x i16>* %6, align 1
  %122 = sub <16 x i16> %121, %113
  %123 = bitcast i16* %120 to <16 x i16>*
  store <16 x i16> %122, <16 x i16>* %123, align 1
  %124 = getelementptr inbounds i16, i16* %1, i64 48
  %125 = getelementptr inbounds i16, i16* %0, i64 48
  %126 = bitcast i16* %125 to <16 x i16>*
  %127 = load <16 x i16>, <16 x i16>* %126, align 1
  %128 = sub <16 x i16> %127, %113
  %129 = bitcast i16* %124 to <16 x i16>*
  store <16 x i16> %128, <16 x i16>* %129, align 1
  %130 = getelementptr inbounds i16, i16* %0, i64 64
  %131 = getelementptr inbounds i16, i16* %1, i64 64
  %132 = bitcast i16* %130 to <16 x i16>*
  %133 = load <16 x i16>, <16 x i16>* %132, align 1
  %134 = sub <16 x i16> %133, %113
  %135 = bitcast i16* %131 to <16 x i16>*
  store <16 x i16> %134, <16 x i16>* %135, align 1
  %136 = getelementptr inbounds i16, i16* %1, i64 80
  %137 = getelementptr inbounds i16, i16* %0, i64 80
  %138 = bitcast i16* %137 to <16 x i16>*
  %139 = load <16 x i16>, <16 x i16>* %138, align 1
  %140 = sub <16 x i16> %139, %113
  %141 = bitcast i16* %136 to <16 x i16>*
  store <16 x i16> %140, <16 x i16>* %141, align 1
  %142 = getelementptr inbounds i16, i16* %0, i64 96
  %143 = getelementptr inbounds i16, i16* %1, i64 96
  %144 = bitcast i16* %142 to <16 x i16>*
  %145 = load <16 x i16>, <16 x i16>* %144, align 1
  %146 = sub <16 x i16> %145, %113
  %147 = bitcast i16* %143 to <16 x i16>*
  store <16 x i16> %146, <16 x i16>* %147, align 1
  %148 = getelementptr inbounds i16, i16* %1, i64 112
  %149 = getelementptr inbounds i16, i16* %0, i64 112
  %150 = bitcast i16* %149 to <16 x i16>*
  %151 = load <16 x i16>, <16 x i16>* %150, align 1
  %152 = sub <16 x i16> %151, %113
  %153 = bitcast i16* %148 to <16 x i16>*
  store <16 x i16> %152, <16 x i16>* %153, align 1
  %154 = getelementptr inbounds i16, i16* %0, i64 128
  %155 = getelementptr inbounds i16, i16* %1, i64 128
  %156 = bitcast i16* %154 to <16 x i16>*
  %157 = load <16 x i16>, <16 x i16>* %156, align 1
  %158 = sub <16 x i16> %157, %113
  %159 = bitcast i16* %155 to <16 x i16>*
  store <16 x i16> %158, <16 x i16>* %159, align 1
  %160 = getelementptr inbounds i16, i16* %1, i64 144
  %161 = getelementptr inbounds i16, i16* %0, i64 144
  %162 = bitcast i16* %161 to <16 x i16>*
  %163 = load <16 x i16>, <16 x i16>* %162, align 1
  %164 = sub <16 x i16> %163, %113
  %165 = bitcast i16* %160 to <16 x i16>*
  store <16 x i16> %164, <16 x i16>* %165, align 1
  %166 = getelementptr inbounds i16, i16* %0, i64 160
  %167 = getelementptr inbounds i16, i16* %1, i64 160
  %168 = bitcast i16* %166 to <16 x i16>*
  %169 = load <16 x i16>, <16 x i16>* %168, align 1
  %170 = sub <16 x i16> %169, %113
  %171 = bitcast i16* %167 to <16 x i16>*
  store <16 x i16> %170, <16 x i16>* %171, align 1
  %172 = getelementptr inbounds i16, i16* %1, i64 176
  %173 = getelementptr inbounds i16, i16* %0, i64 176
  %174 = bitcast i16* %173 to <16 x i16>*
  %175 = load <16 x i16>, <16 x i16>* %174, align 1
  %176 = sub <16 x i16> %175, %113
  %177 = bitcast i16* %172 to <16 x i16>*
  store <16 x i16> %176, <16 x i16>* %177, align 1
  %178 = getelementptr inbounds i16, i16* %0, i64 192
  %179 = getelementptr inbounds i16, i16* %1, i64 192
  %180 = bitcast i16* %178 to <16 x i16>*
  %181 = load <16 x i16>, <16 x i16>* %180, align 1
  %182 = sub <16 x i16> %181, %113
  %183 = bitcast i16* %179 to <16 x i16>*
  store <16 x i16> %182, <16 x i16>* %183, align 1
  %184 = getelementptr inbounds i16, i16* %1, i64 208
  %185 = getelementptr inbounds i16, i16* %0, i64 208
  %186 = bitcast i16* %185 to <16 x i16>*
  %187 = load <16 x i16>, <16 x i16>* %186, align 1
  %188 = sub <16 x i16> %187, %113
  %189 = bitcast i16* %184 to <16 x i16>*
  store <16 x i16> %188, <16 x i16>* %189, align 1
  %190 = getelementptr inbounds i16, i16* %0, i64 224
  %191 = getelementptr inbounds i16, i16* %1, i64 224
  %192 = bitcast i16* %190 to <16 x i16>*
  %193 = load <16 x i16>, <16 x i16>* %192, align 1
  %194 = sub <16 x i16> %193, %113
  %195 = bitcast i16* %191 to <16 x i16>*
  store <16 x i16> %194, <16 x i16>* %195, align 1
  %196 = getelementptr inbounds i16, i16* %1, i64 240
  %197 = getelementptr inbounds i16, i16* %0, i64 240
  %198 = bitcast i16* %197 to <16 x i16>*
  %199 = load <16 x i16>, <16 x i16>* %198, align 1
  %200 = sub <16 x i16> %199, %113
  %201 = bitcast i16* %196 to <16 x i16>*
  store <16 x i16> %200, <16 x i16>* %201, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subtract_average_32x16_avx2(i16* readonly, i16* nocapture) #0 {
  %3 = bitcast i16* %0 to <4 x i64>*
  %4 = getelementptr inbounds i16, i16* %0, i64 512
  %5 = bitcast i16* %4 to <4 x i64>*
  %6 = bitcast i16* %0 to <16 x i16>*
  %7 = load <16 x i16>, <16 x i16>* %6, align 1
  %8 = getelementptr inbounds i16, i16* %0, i64 32
  %9 = bitcast i16* %8 to <16 x i16>*
  %10 = load <16 x i16>, <16 x i16>* %9, align 1
  %11 = add <16 x i16> %10, %7
  %12 = getelementptr inbounds i16, i16* %0, i64 16
  %13 = bitcast i16* %12 to <16 x i16>*
  %14 = load <16 x i16>, <16 x i16>* %13, align 1
  %15 = getelementptr inbounds i16, i16* %0, i64 48
  %16 = bitcast i16* %15 to <16 x i16>*
  %17 = load <16 x i16>, <16 x i16>* %16, align 1
  %18 = add <16 x i16> %17, %14
  %19 = getelementptr inbounds i16, i16* %0, i64 64
  %20 = shufflevector <16 x i16> %18, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %21 = bitcast <16 x i16> %20 to <8 x i32>
  %22 = shufflevector <16 x i16> %18, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %23 = bitcast <16 x i16> %22 to <8 x i32>
  %24 = add <8 x i32> %21, %23
  %25 = shufflevector <16 x i16> %11, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %26 = bitcast <16 x i16> %25 to <8 x i32>
  %27 = shufflevector <16 x i16> %11, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %28 = bitcast <16 x i16> %27 to <8 x i32>
  %29 = add <8 x i32> %26, %28
  %30 = bitcast i16* %19 to <16 x i16>*
  %31 = load <16 x i16>, <16 x i16>* %30, align 1
  %32 = getelementptr inbounds i16, i16* %0, i64 96
  %33 = bitcast i16* %32 to <16 x i16>*
  %34 = load <16 x i16>, <16 x i16>* %33, align 1
  %35 = add <16 x i16> %34, %31
  %36 = shufflevector <16 x i16> %35, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %37 = shufflevector <16 x i16> %35, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %38 = bitcast <16 x i16> %36 to <8 x i32>
  %39 = bitcast <16 x i16> %37 to <8 x i32>
  %40 = add <8 x i32> %29, %38
  %41 = add <8 x i32> %40, %39
  %42 = getelementptr inbounds i16, i16* %0, i64 80
  %43 = bitcast i16* %42 to <16 x i16>*
  %44 = load <16 x i16>, <16 x i16>* %43, align 1
  %45 = getelementptr inbounds i16, i16* %0, i64 112
  %46 = bitcast i16* %45 to <16 x i16>*
  %47 = load <16 x i16>, <16 x i16>* %46, align 1
  %48 = add <16 x i16> %47, %44
  %49 = shufflevector <16 x i16> %48, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %50 = shufflevector <16 x i16> %48, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %51 = bitcast <16 x i16> %49 to <8 x i32>
  %52 = bitcast <16 x i16> %50 to <8 x i32>
  %53 = add <8 x i32> %24, %51
  %54 = add <8 x i32> %53, %52
  %55 = getelementptr inbounds i16, i16* %0, i64 128
  %56 = bitcast i16* %55 to <16 x i16>*
  %57 = load <16 x i16>, <16 x i16>* %56, align 1
  %58 = getelementptr inbounds i16, i16* %0, i64 160
  %59 = bitcast i16* %58 to <16 x i16>*
  %60 = load <16 x i16>, <16 x i16>* %59, align 1
  %61 = add <16 x i16> %60, %57
  %62 = shufflevector <16 x i16> %61, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %63 = shufflevector <16 x i16> %61, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %64 = bitcast <16 x i16> %62 to <8 x i32>
  %65 = bitcast <16 x i16> %63 to <8 x i32>
  %66 = add <8 x i32> %41, %64
  %67 = add <8 x i32> %66, %65
  %68 = getelementptr inbounds i16, i16* %0, i64 144
  %69 = bitcast i16* %68 to <16 x i16>*
  %70 = load <16 x i16>, <16 x i16>* %69, align 1
  %71 = getelementptr inbounds i16, i16* %0, i64 176
  %72 = bitcast i16* %71 to <16 x i16>*
  %73 = load <16 x i16>, <16 x i16>* %72, align 1
  %74 = add <16 x i16> %73, %70
  %75 = shufflevector <16 x i16> %74, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %76 = shufflevector <16 x i16> %74, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %77 = bitcast <16 x i16> %75 to <8 x i32>
  %78 = bitcast <16 x i16> %76 to <8 x i32>
  %79 = add <8 x i32> %54, %77
  %80 = add <8 x i32> %79, %78
  %81 = getelementptr inbounds i16, i16* %0, i64 192
  %82 = bitcast i16* %81 to <16 x i16>*
  %83 = load <16 x i16>, <16 x i16>* %82, align 1
  %84 = getelementptr inbounds i16, i16* %0, i64 224
  %85 = bitcast i16* %84 to <16 x i16>*
  %86 = load <16 x i16>, <16 x i16>* %85, align 1
  %87 = add <16 x i16> %86, %83
  %88 = shufflevector <16 x i16> %87, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %89 = shufflevector <16 x i16> %87, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %90 = bitcast <16 x i16> %88 to <8 x i32>
  %91 = bitcast <16 x i16> %89 to <8 x i32>
  %92 = add <8 x i32> %67, %90
  %93 = add <8 x i32> %92, %91
  %94 = getelementptr inbounds i16, i16* %0, i64 208
  %95 = bitcast i16* %94 to <16 x i16>*
  %96 = load <16 x i16>, <16 x i16>* %95, align 1
  %97 = getelementptr inbounds i16, i16* %0, i64 240
  %98 = bitcast i16* %97 to <16 x i16>*
  %99 = load <16 x i16>, <16 x i16>* %98, align 1
  %100 = add <16 x i16> %99, %96
  %101 = shufflevector <16 x i16> %100, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %102 = shufflevector <16 x i16> %100, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %103 = bitcast <16 x i16> %101 to <8 x i32>
  %104 = bitcast <16 x i16> %102 to <8 x i32>
  %105 = add <8 x i32> %80, %103
  %106 = add <8 x i32> %105, %104
  %107 = getelementptr inbounds i16, i16* %0, i64 256
  %108 = bitcast i16* %107 to <16 x i16>*
  %109 = load <16 x i16>, <16 x i16>* %108, align 1
  %110 = getelementptr inbounds i16, i16* %0, i64 288
  %111 = bitcast i16* %110 to <16 x i16>*
  %112 = load <16 x i16>, <16 x i16>* %111, align 1
  %113 = add <16 x i16> %112, %109
  %114 = shufflevector <16 x i16> %113, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %115 = shufflevector <16 x i16> %113, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %116 = bitcast <16 x i16> %114 to <8 x i32>
  %117 = bitcast <16 x i16> %115 to <8 x i32>
  %118 = add <8 x i32> %93, %116
  %119 = add <8 x i32> %118, %117
  %120 = getelementptr inbounds i16, i16* %0, i64 272
  %121 = bitcast i16* %120 to <16 x i16>*
  %122 = load <16 x i16>, <16 x i16>* %121, align 1
  %123 = getelementptr inbounds i16, i16* %0, i64 304
  %124 = bitcast i16* %123 to <16 x i16>*
  %125 = load <16 x i16>, <16 x i16>* %124, align 1
  %126 = add <16 x i16> %125, %122
  %127 = shufflevector <16 x i16> %126, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %128 = shufflevector <16 x i16> %126, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %129 = bitcast <16 x i16> %127 to <8 x i32>
  %130 = bitcast <16 x i16> %128 to <8 x i32>
  %131 = add <8 x i32> %106, %129
  %132 = add <8 x i32> %131, %130
  %133 = getelementptr inbounds i16, i16* %0, i64 320
  %134 = bitcast i16* %133 to <16 x i16>*
  %135 = load <16 x i16>, <16 x i16>* %134, align 1
  %136 = getelementptr inbounds i16, i16* %0, i64 352
  %137 = bitcast i16* %136 to <16 x i16>*
  %138 = load <16 x i16>, <16 x i16>* %137, align 1
  %139 = add <16 x i16> %138, %135
  %140 = shufflevector <16 x i16> %139, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %141 = shufflevector <16 x i16> %139, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %142 = bitcast <16 x i16> %140 to <8 x i32>
  %143 = bitcast <16 x i16> %141 to <8 x i32>
  %144 = add <8 x i32> %119, %142
  %145 = add <8 x i32> %144, %143
  %146 = getelementptr inbounds i16, i16* %0, i64 336
  %147 = bitcast i16* %146 to <16 x i16>*
  %148 = load <16 x i16>, <16 x i16>* %147, align 1
  %149 = getelementptr inbounds i16, i16* %0, i64 368
  %150 = bitcast i16* %149 to <16 x i16>*
  %151 = load <16 x i16>, <16 x i16>* %150, align 1
  %152 = add <16 x i16> %151, %148
  %153 = shufflevector <16 x i16> %152, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %154 = shufflevector <16 x i16> %152, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %155 = bitcast <16 x i16> %153 to <8 x i32>
  %156 = bitcast <16 x i16> %154 to <8 x i32>
  %157 = add <8 x i32> %132, %155
  %158 = add <8 x i32> %157, %156
  %159 = getelementptr inbounds i16, i16* %0, i64 384
  %160 = bitcast i16* %159 to <16 x i16>*
  %161 = load <16 x i16>, <16 x i16>* %160, align 1
  %162 = getelementptr inbounds i16, i16* %0, i64 416
  %163 = bitcast i16* %162 to <16 x i16>*
  %164 = load <16 x i16>, <16 x i16>* %163, align 1
  %165 = add <16 x i16> %164, %161
  %166 = shufflevector <16 x i16> %165, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %167 = shufflevector <16 x i16> %165, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %168 = bitcast <16 x i16> %166 to <8 x i32>
  %169 = bitcast <16 x i16> %167 to <8 x i32>
  %170 = add <8 x i32> %145, %168
  %171 = add <8 x i32> %170, %169
  %172 = getelementptr inbounds i16, i16* %0, i64 400
  %173 = bitcast i16* %172 to <16 x i16>*
  %174 = load <16 x i16>, <16 x i16>* %173, align 1
  %175 = getelementptr inbounds i16, i16* %0, i64 432
  %176 = bitcast i16* %175 to <16 x i16>*
  %177 = load <16 x i16>, <16 x i16>* %176, align 1
  %178 = add <16 x i16> %177, %174
  %179 = shufflevector <16 x i16> %178, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %180 = shufflevector <16 x i16> %178, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %181 = bitcast <16 x i16> %179 to <8 x i32>
  %182 = bitcast <16 x i16> %180 to <8 x i32>
  %183 = add <8 x i32> %158, %181
  %184 = add <8 x i32> %183, %182
  %185 = getelementptr inbounds i16, i16* %0, i64 448
  %186 = bitcast i16* %185 to <16 x i16>*
  %187 = load <16 x i16>, <16 x i16>* %186, align 1
  %188 = getelementptr inbounds i16, i16* %0, i64 480
  %189 = bitcast i16* %188 to <16 x i16>*
  %190 = load <16 x i16>, <16 x i16>* %189, align 1
  %191 = add <16 x i16> %190, %187
  %192 = shufflevector <16 x i16> %191, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %193 = shufflevector <16 x i16> %191, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %194 = bitcast <16 x i16> %192 to <8 x i32>
  %195 = bitcast <16 x i16> %193 to <8 x i32>
  %196 = add <8 x i32> %171, %194
  %197 = add <8 x i32> %196, %195
  %198 = getelementptr inbounds i16, i16* %0, i64 464
  %199 = bitcast i16* %198 to <16 x i16>*
  %200 = load <16 x i16>, <16 x i16>* %199, align 1
  %201 = getelementptr inbounds i16, i16* %0, i64 496
  %202 = bitcast i16* %201 to <16 x i16>*
  %203 = load <16 x i16>, <16 x i16>* %202, align 1
  %204 = add <16 x i16> %203, %200
  %205 = shufflevector <16 x i16> %204, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %206 = shufflevector <16 x i16> %204, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %207 = bitcast <16 x i16> %205 to <8 x i32>
  %208 = bitcast <16 x i16> %206 to <8 x i32>
  %209 = add <8 x i32> %184, %207
  %210 = add <8 x i32> %209, %208
  %211 = add <8 x i32> %210, %197
  %212 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %211, <8 x i32> %211) #5
  %213 = bitcast <8 x i32> %212 to <4 x i64>
  %214 = shufflevector <4 x i64> %213, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %215 = bitcast <4 x i64> %214 to <8 x i32>
  %216 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %215, <8 x i32> %215) #5
  %217 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %216, <8 x i32> %216) #5
  %218 = add <8 x i32> %217, <i32 256, i32 256, i32 256, i32 256, i32 256, i32 256, i32 256, i32 256>
  %219 = lshr <8 x i32> %218, <i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9>
  %220 = tail call <16 x i16> @llvm.x86.avx2.packssdw(<8 x i32> %219, <8 x i32> %219) #5
  %221 = bitcast i16* %1 to <4 x i64>*
  br label %222

222:                                              ; preds = %222, %2
  %223 = phi <4 x i64>* [ %3, %2 ], [ %235, %222 ]
  %224 = phi <4 x i64>* [ %221, %2 ], [ %236, %222 ]
  %225 = bitcast <4 x i64>* %223 to <16 x i16>*
  %226 = load <16 x i16>, <16 x i16>* %225, align 1
  %227 = sub <16 x i16> %226, %220
  %228 = bitcast <4 x i64>* %224 to <16 x i16>*
  store <16 x i16> %227, <16 x i16>* %228, align 1
  %229 = getelementptr inbounds <4 x i64>, <4 x i64>* %224, i64 1
  %230 = getelementptr inbounds <4 x i64>, <4 x i64>* %223, i64 1
  %231 = bitcast <4 x i64>* %230 to <16 x i16>*
  %232 = load <16 x i16>, <16 x i16>* %231, align 1
  %233 = sub <16 x i16> %232, %220
  %234 = bitcast <4 x i64>* %229 to <16 x i16>*
  store <16 x i16> %233, <16 x i16>* %234, align 1
  %235 = getelementptr inbounds <4 x i64>, <4 x i64>* %223, i64 2
  %236 = getelementptr inbounds <4 x i64>, <4 x i64>* %224, i64 2
  %237 = icmp ult <4 x i64>* %235, %5
  br i1 %237, label %222, label %238

238:                                              ; preds = %222
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @cfl_subtract_average_32x32_avx2(i16* readonly, i16* nocapture) #0 {
  %3 = bitcast i16* %0 to <4 x i64>*
  %4 = getelementptr inbounds i16, i16* %0, i64 1024
  %5 = bitcast i16* %4 to <4 x i64>*
  br label %6

6:                                                ; preds = %6, %2
  %7 = phi <8 x i32> [ zeroinitializer, %2 ], [ %34, %6 ]
  %8 = phi <8 x i32> [ zeroinitializer, %2 ], [ %21, %6 ]
  %9 = phi <4 x i64>* [ %3, %2 ], [ %35, %6 ]
  %10 = bitcast <4 x i64>* %9 to <16 x i16>*
  %11 = load <16 x i16>, <16 x i16>* %10, align 1
  %12 = getelementptr inbounds <4 x i64>, <4 x i64>* %9, i64 2
  %13 = bitcast <4 x i64>* %12 to <16 x i16>*
  %14 = load <16 x i16>, <16 x i16>* %13, align 1
  %15 = add <16 x i16> %14, %11
  %16 = shufflevector <16 x i16> %15, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %17 = shufflevector <16 x i16> %15, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %18 = bitcast <16 x i16> %16 to <8 x i32>
  %19 = bitcast <16 x i16> %17 to <8 x i32>
  %20 = add <8 x i32> %8, %18
  %21 = add <8 x i32> %20, %19
  %22 = getelementptr inbounds <4 x i64>, <4 x i64>* %9, i64 1
  %23 = bitcast <4 x i64>* %22 to <16 x i16>*
  %24 = load <16 x i16>, <16 x i16>* %23, align 1
  %25 = getelementptr inbounds <4 x i64>, <4 x i64>* %9, i64 3
  %26 = bitcast <4 x i64>* %25 to <16 x i16>*
  %27 = load <16 x i16>, <16 x i16>* %26, align 1
  %28 = add <16 x i16> %27, %24
  %29 = shufflevector <16 x i16> %28, <16 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27>
  %30 = shufflevector <16 x i16> %28, <16 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <16 x i32> <i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %31 = bitcast <16 x i16> %29 to <8 x i32>
  %32 = bitcast <16 x i16> %30 to <8 x i32>
  %33 = add <8 x i32> %7, %31
  %34 = add <8 x i32> %33, %32
  %35 = getelementptr inbounds <4 x i64>, <4 x i64>* %9, i64 4
  %36 = icmp ult <4 x i64>* %35, %5
  br i1 %36, label %6, label %37

37:                                               ; preds = %6
  %38 = add <8 x i32> %34, %21
  %39 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %38, <8 x i32> %38) #5
  %40 = bitcast <8 x i32> %39 to <4 x i64>
  %41 = shufflevector <4 x i64> %40, <4 x i64> undef, <4 x i32> <i32 0, i32 2, i32 1, i32 3>
  %42 = bitcast <4 x i64> %41 to <8 x i32>
  %43 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %42, <8 x i32> %42) #5
  %44 = tail call <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32> %43, <8 x i32> %43) #5
  %45 = add <8 x i32> %44, <i32 512, i32 512, i32 512, i32 512, i32 512, i32 512, i32 512, i32 512>
  %46 = lshr <8 x i32> %45, <i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10>
  %47 = tail call <16 x i16> @llvm.x86.avx2.packssdw(<8 x i32> %46, <8 x i32> %46) #5
  %48 = bitcast i16* %1 to <4 x i64>*
  br label %49

49:                                               ; preds = %49, %37
  %50 = phi <4 x i64>* [ %3, %37 ], [ %62, %49 ]
  %51 = phi <4 x i64>* [ %48, %37 ], [ %63, %49 ]
  %52 = bitcast <4 x i64>* %50 to <16 x i16>*
  %53 = load <16 x i16>, <16 x i16>* %52, align 1
  %54 = sub <16 x i16> %53, %47
  %55 = bitcast <4 x i64>* %51 to <16 x i16>*
  store <16 x i16> %54, <16 x i16>* %55, align 1
  %56 = getelementptr inbounds <4 x i64>, <4 x i64>* %51, i64 1
  %57 = getelementptr inbounds <4 x i64>, <4 x i64>* %50, i64 1
  %58 = bitcast <4 x i64>* %57 to <16 x i16>*
  %59 = load <16 x i16>, <16 x i16>* %58, align 1
  %60 = sub <16 x i16> %59, %47
  %61 = bitcast <4 x i64>* %56 to <16 x i16>*
  store <16 x i16> %60, <16 x i16>* %61, align 1
  %62 = getelementptr inbounds <4 x i64>, <4 x i64>* %50, i64 2
  %63 = getelementptr inbounds <4 x i64>, <4 x i64>* %51, i64 2
  %64 = icmp ult <4 x i64>* %62, %5
  br i1 %64, label %49, label %65

65:                                               ; preds = %49
  ret void
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void (i16*, i16*)* @cfl_get_subtract_average_fn_avx2(i8 zeroext) local_unnamed_addr #1 {
  %2 = urem i8 %0, 19
  %3 = zext i8 %2 to i64
  %4 = getelementptr inbounds [19 x void (i16*, i16*)*], [19 x void (i16*, i16*)*]* @cfl_get_subtract_average_fn_avx2.sub_avg, i64 0, i64 %3
  %5 = load void (i16*, i16*)*, void (i16*, i16*)** %4, align 8
  ret void (i16*, i16*)* %5
}

declare void @cfl_subtract_average_4x4_sse2(i16*, i16*) #2

declare void @cfl_subtract_average_8x8_sse2(i16*, i16*) #2

declare void @cfl_subtract_average_4x8_sse2(i16*, i16*) #2

declare void @cfl_subtract_average_8x4_sse2(i16*, i16*) #2

declare void @cfl_subtract_average_8x16_sse2(i16*, i16*) #2

declare void @cfl_subtract_average_4x16_sse2(i16*, i16*) #2

declare void @cfl_subtract_average_8x32_sse2(i16*, i16*) #2

; Function Attrs: nounwind readnone
declare <16 x i16> @llvm.x86.avx2.pmadd.ub.sw(<32 x i8>, <32 x i8>) #4

; Function Attrs: nounwind readnone
declare <16 x i16> @llvm.x86.avx2.psign.w(<16 x i16>, <16 x i16>) #4

; Function Attrs: nounwind readnone
declare <16 x i16> @llvm.x86.avx2.pmul.hr.sw(<16 x i16>, <16 x i16>) #4

; Function Attrs: nounwind readnone
declare <32 x i8> @llvm.x86.avx2.packuswb(<16 x i16>, <16 x i16>) #4

; Function Attrs: nounwind readnone
declare <8 x i32> @llvm.x86.avx2.phadd.d(<8 x i32>, <8 x i32>) #4

; Function Attrs: nounwind readnone
declare <16 x i16> @llvm.x86.avx2.packssdw(<8 x i32>, <8 x i32>) #4

attributes #0 = { nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="256" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { norecurse nounwind readnone ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="256" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+cx8,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind readnone }
attributes #5 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
