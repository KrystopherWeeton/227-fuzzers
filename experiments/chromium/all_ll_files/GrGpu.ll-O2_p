; ModuleID = '../../third_party/skia/src/gpu/GrGpu.cpp'
source_filename = "../../third_party/skia/src/gpu/GrGpu.cpp"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"struct.std::__1::atomic.255" = type { %"struct.std::__1::__atomic_base.256" }
%"struct.std::__1::__atomic_base.256" = type { %"struct.std::__1::__atomic_base.257" }
%"struct.std::__1::__atomic_base.257" = type { %"struct.std::__1::__cxx_atomic_impl.258" }
%"struct.std::__1::__cxx_atomic_impl.258" = type { %"struct.std::__1::__cxx_atomic_base_impl.259" }
%"struct.std::__1::__cxx_atomic_base_impl.259" = type { i64 }
%class.GrGpu = type { %class.SkRefCnt.base, %"class.GrGpu::Stats", %class.sk_sp, %"class.std::__1::unique_ptr", i32, %class.GrDirectContext*, %class.SkSTArray, i8, i32 }
%class.SkRefCnt.base = type { %class.SkRefCntBase.base }
%class.SkRefCntBase.base = type <{ i32 (...)**, %"struct.std::__1::atomic" }>
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__atomic_base.0" }
%"struct.std::__1::__atomic_base.0" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i32 }
%"class.GrGpu::Stats" = type { i8 }
%class.sk_sp = type { %class.GrCaps* }
%class.GrCaps = type <{ %class.SkRefCnt.base, [4 x i8], %class.sk_sp.1, i48, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, [4 x i8], i64, %class.GrDriverBugWorkarounds, i8, i8 }>
%class.sk_sp.1 = type { %class.GrShaderCaps* }
%class.GrShaderCaps = type <{ %class.SkRefCnt.base, i32, i56, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32, i32, i32, [4 x i8] }>
%class.GrDriverBugWorkarounds = type { i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8, i8 }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { %"class.SkSL::Compiler"* }
%"class.SkSL::Compiler" = type { %"class.SkSL::ErrorReporter", %"class.std::__1::shared_ptr", %"class.std::__1::shared_ptr.41", %"class.std::__1::shared_ptr.41", %"struct.SkSL::ParsedModule", %"struct.SkSL::ParsedModule", %"struct.SkSL::ParsedModule", %"struct.SkSL::ParsedModule", %"struct.SkSL::ParsedModule", %"struct.SkSL::ParsedModule", %"struct.SkSL::ParsedModule", %"struct.SkSL::ParsedModule", %"struct.SkSL::ParsedModule", %"struct.SkSL::ParsedModule", %"class.SkSL::ModifiersPool", %"class.SkSL::Inliner", %"class.std::__1::unique_ptr.43", %"class.SkSL::String"*, i32, %"class.SkSL::String", %"class.std::__1::vector.49" }
%"class.SkSL::ErrorReporter" = type { i32 (...)** }
%"class.std::__1::shared_ptr" = type { %"class.SkSL::Context"*, %"class.std::__1::__shared_weak_count"* }
%"class.SkSL::Context" = type { %"class.SkSL::BuiltinTypes", %"class.SkSL::ErrorReporter"*, %class.GrShaderCaps*, %"class.SkSL::ModifiersPool"*, %"struct.SkSL::ProgramConfig"* }
%"class.SkSL::BuiltinTypes" = type { %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2", %"class.std::__1::unique_ptr.2" }
%"class.std::__1::unique_ptr.2" = type { %"class.std::__1::__compressed_pair.3" }
%"class.std::__1::__compressed_pair.3" = type { %"struct.std::__1::__compressed_pair_elem.4" }
%"struct.std::__1::__compressed_pair_elem.4" = type { %"class.SkSL::Type"* }
%"class.SkSL::Type" = type { %"class.SkSL::Symbol", i8*, %"class.SkSL::String", i32, i32, i32, %"class.SkSL::Type"*, %"class.std::__1::vector", i32, i32, %"class.std::__1::vector.13", i32, i8, i8, i8, i8, i8, %"class.SkSL::Type"*, %"class.SkSL::Type"* }
%"class.SkSL::Symbol" = type { %"class.SkSL::IRNode", %"struct.SkSL::StringFragment", %"class.SkSL::Type"* }
%"class.SkSL::IRNode" = type { i32 (...)**, i32, i32 }
%"struct.SkSL::StringFragment" = type { i8*, i64 }
%"class.std::__1::vector" = type { %"class.std::__1::__vector_base" }
%"class.std::__1::__vector_base" = type { %"class.SkSL::Type"**, %"class.SkSL::Type"**, %"class.std::__1::__compressed_pair.8" }
%"class.std::__1::__compressed_pair.8" = type { %"struct.std::__1::__compressed_pair_elem.9" }
%"struct.std::__1::__compressed_pair_elem.9" = type { %"class.SkSL::Type"** }
%"class.std::__1::vector.13" = type { %"class.std::__1::__vector_base.14" }
%"class.std::__1::__vector_base.14" = type { %"struct.SkSL::Type::Field"*, %"struct.SkSL::Type::Field"*, %"class.std::__1::__compressed_pair.15" }
%"struct.SkSL::Type::Field" = type { %"struct.SkSL::Modifiers", %"struct.SkSL::StringFragment", %"class.SkSL::Type"* }
%"struct.SkSL::Modifiers" = type { %"struct.SkSL::Layout", i32, [4 x i8] }
%"struct.SkSL::Layout" = type <{ i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, [4 x i8], %"struct.SkSL::StringFragment", i32, [4 x i8] }>
%"class.std::__1::__compressed_pair.15" = type { %"struct.std::__1::__compressed_pair_elem.16" }
%"struct.std::__1::__compressed_pair_elem.16" = type { %"struct.SkSL::Type::Field"* }
%"struct.SkSL::ProgramConfig" = type { i8, %"struct.SkSL::ProgramSettings" }
%"struct.SkSL::ProgramSettings" = type { i8, i8, i8, i8, i8, i32, i32, i32, i32, i32, i8, i8, i8, i32, i8, i8, i8, i8, i8, i8, i8, i8, %"class.std::__1::vector.40"* }
%"class.std::__1::vector.40" = type opaque
%"class.std::__1::__shared_weak_count" = type { %"class.std::__1::__shared_count", i64 }
%"class.std::__1::__shared_count" = type { i32 (...)**, i64 }
%"class.std::__1::shared_ptr.41" = type { %"class.SkSL::SymbolTable"*, %"class.std::__1::__shared_weak_count"* }
%"class.SkSL::SymbolTable" = type { %"class.std::__1::shared_ptr.41", %"class.std::__1::vector.193", i8, %"class.std::__1::vector.201", %"class.std::__1::forward_list", %class.SkTHashMap.214, %"class.SkSL::ErrorReporter"* }
%"class.std::__1::vector.193" = type { %"class.std::__1::__vector_base.194" }
%"class.std::__1::__vector_base.194" = type { %"class.std::__1::unique_ptr.195"*, %"class.std::__1::unique_ptr.195"*, %"class.std::__1::__compressed_pair.196" }
%"class.std::__1::unique_ptr.195" = type { %"class.std::__1::__compressed_pair.307" }
%"class.std::__1::__compressed_pair.307" = type { %"struct.std::__1::__compressed_pair_elem.308" }
%"struct.std::__1::__compressed_pair_elem.308" = type { %"class.SkSL::Symbol"* }
%"class.std::__1::__compressed_pair.196" = type { %"struct.std::__1::__compressed_pair_elem.197" }
%"struct.std::__1::__compressed_pair_elem.197" = type { %"class.std::__1::unique_ptr.195"* }
%"class.std::__1::vector.201" = type { %"class.std::__1::__vector_base.202" }
%"class.std::__1::__vector_base.202" = type { %"class.std::__1::unique_ptr.203"*, %"class.std::__1::unique_ptr.203"*, %"class.std::__1::__compressed_pair.204" }
%"class.std::__1::unique_ptr.203" = type { %"class.std::__1::__compressed_pair.312" }
%"class.std::__1::__compressed_pair.312" = type { %"struct.std::__1::__compressed_pair_elem.313" }
%"struct.std::__1::__compressed_pair_elem.313" = type { %"class.SkSL::IRNode"* }
%"class.std::__1::__compressed_pair.204" = type { %"struct.std::__1::__compressed_pair_elem.205" }
%"struct.std::__1::__compressed_pair_elem.205" = type { %"class.std::__1::unique_ptr.203"* }
%"class.std::__1::forward_list" = type { %"class.std::__1::__forward_list_base" }
%"class.std::__1::__forward_list_base" = type { %"class.std::__1::__compressed_pair.209" }
%"class.std::__1::__compressed_pair.209" = type { %"struct.std::__1::__compressed_pair_elem.210" }
%"struct.std::__1::__compressed_pair_elem.210" = type { %"struct.std::__1::__forward_begin_node" }
%"struct.std::__1::__forward_begin_node" = type { %"struct.std::__1::__forward_list_node"* }
%"struct.std::__1::__forward_list_node" = type { %"struct.std::__1::__forward_begin_node", %"class.SkSL::String" }
%class.SkTHashMap.214 = type { %class.SkTHashTable.215 }
%class.SkTHashTable.215 = type { i32, i32, %class.SkAutoTArray.216 }
%class.SkAutoTArray.216 = type { %"class.std::__1::unique_ptr.217" }
%"class.std::__1::unique_ptr.217" = type { %"class.std::__1::__compressed_pair.218" }
%"class.std::__1::__compressed_pair.218" = type { %"struct.std::__1::__compressed_pair_elem.219" }
%"struct.std::__1::__compressed_pair_elem.219" = type { %"struct.SkTHashTable<SkTHashMap<SkSL::SymbolTable::SymbolKey, const SkSL::Symbol *, SkSL::SymbolTable::SymbolKey::Hash>::Pair, SkSL::SymbolTable::SymbolKey, SkTHashMap<SkSL::SymbolTable::SymbolKey, const SkSL::Symbol *, SkSL::SymbolTable::SymbolKey::Hash>::Pair>::Slot"* }
%"struct.SkTHashTable<SkTHashMap<SkSL::SymbolTable::SymbolKey, const SkSL::Symbol *, SkSL::SymbolTable::SymbolKey::Hash>::Pair, SkSL::SymbolTable::SymbolKey, SkTHashMap<SkSL::SymbolTable::SymbolKey, const SkSL::Symbol *, SkSL::SymbolTable::SymbolKey::Hash>::Pair>::Slot" = type <{ %"struct.SkTHashMap<SkSL::SymbolTable::SymbolKey, const SkSL::Symbol *, SkSL::SymbolTable::SymbolKey::Hash>::Pair", i32, [4 x i8] }>
%"struct.SkTHashMap<SkSL::SymbolTable::SymbolKey, const SkSL::Symbol *, SkSL::SymbolTable::SymbolKey::Hash>::Pair" = type { %"struct.std::__1::pair.317" }
%"struct.std::__1::pair.317" = type { %"struct.SkSL::SymbolTable::SymbolKey", %"class.SkSL::Symbol"* }
%"struct.SkSL::SymbolTable::SymbolKey" = type <{ %"struct.SkSL::StringFragment", i32, [4 x i8] }>
%"struct.SkSL::ParsedModule" = type { %"class.std::__1::shared_ptr.41", %"class.std::__1::shared_ptr.42" }
%"class.std::__1::shared_ptr.42" = type { %"class.SkSL::IRIntrinsicMap"*, %"class.std::__1::__shared_weak_count"* }
%"class.SkSL::IRIntrinsicMap" = type opaque
%"class.SkSL::ModifiersPool" = type { %"class.std::__1::unordered_set" }
%"class.std::__1::unordered_set" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr.21", %"class.std::__1::__compressed_pair.30", %"class.std::__1::__compressed_pair.35", %"class.std::__1::__compressed_pair.37", [4 x i8] }>
%"class.std::__1::unique_ptr.21" = type { %"class.std::__1::__compressed_pair.22" }
%"class.std::__1::__compressed_pair.22" = type { %"struct.std::__1::__compressed_pair_elem.23", %"struct.std::__1::__compressed_pair_elem.24" }
%"struct.std::__1::__compressed_pair_elem.23" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.24" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.25" }
%"class.std::__1::__compressed_pair.25" = type { %"struct.std::__1::__compressed_pair_elem.26" }
%"struct.std::__1::__compressed_pair_elem.26" = type { i64 }
%"class.std::__1::__compressed_pair.30" = type { %"struct.std::__1::__compressed_pair_elem.31" }
%"struct.std::__1::__compressed_pair_elem.31" = type { %"struct.std::__1::__hash_node_base" }
%"class.std::__1::__compressed_pair.35" = type { %"struct.std::__1::__compressed_pair_elem.26" }
%"class.std::__1::__compressed_pair.37" = type { %"struct.std::__1::__compressed_pair_elem.38" }
%"struct.std::__1::__compressed_pair_elem.38" = type { float }
%"class.SkSL::Inliner" = type { %"class.SkSL::Context"*, %"class.SkSL::Mangler", i32 }
%"class.SkSL::Mangler" = type { i32 }
%"class.std::__1::unique_ptr.43" = type { %"class.std::__1::__compressed_pair.44" }
%"class.std::__1::__compressed_pair.44" = type { %"struct.std::__1::__compressed_pair_elem.45" }
%"struct.std::__1::__compressed_pair_elem.45" = type { %"class.SkSL::IRGenerator"* }
%"class.SkSL::IRGenerator" = type opaque
%"class.SkSL::String" = type { %"class.std::__1::basic_string" }
%"class.std::__1::basic_string" = type { %"class.std::__1::__compressed_pair.5" }
%"class.std::__1::__compressed_pair.5" = type { %"struct.std::__1::__compressed_pair_elem.6" }
%"struct.std::__1::__compressed_pair_elem.6" = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" = type { %union.anon }
%union.anon = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" = type { i8*, i64, i64 }
%"class.std::__1::vector.49" = type { %"class.std::__1::__vector_base.50" }
%"class.std::__1::__vector_base.50" = type { i64*, i64*, %"class.std::__1::__compressed_pair.51" }
%"class.std::__1::__compressed_pair.51" = type { %"struct.std::__1::__compressed_pair_elem.52" }
%"struct.std::__1::__compressed_pair_elem.52" = type { i64* }
%class.GrDirectContext = type { %class.GrRecordingContext, %"class.GrDirectContext::DirectContextID", %"class.std::__1::unique_ptr.111", %"class.std::__1::unique_ptr.117", %class.sk_sp.123, %"class.std::__1::unique_ptr.124", %"class.std::__1::unique_ptr.167", i8, i8, %"class.GrContextOptions::PersistentCache"*, %"class.GrContextOptions::ShaderErrorHandler"*, %"class.std::__1::unique_ptr.174", %"class.std::__1::unique_ptr.180", %"class.std::__1::unique_ptr.186" }
%class.GrRecordingContext = type { %class.GrImageContext.base, %"class.GrRecordingContext::Stats", %"class.std::__1::unique_ptr.60", %"class.GrRecordingContext::OwnedArenas", %"class.std::__1::unique_ptr.99", %"class.std::__1::unique_ptr.105" }
%class.GrImageContext.base = type <{ %class.GrContext_Base, %class.GrSingleOwner }>
%class.GrContext_Base = type { %class.SkRefCnt.base, %class.sk_sp.59 }
%class.sk_sp.59 = type { %class.GrContextThreadSafeProxy* }
%class.GrContextThreadSafeProxy = type opaque
%class.GrSingleOwner = type { i8 }
%"class.GrRecordingContext::Stats" = type { i8 }
%"class.std::__1::unique_ptr.60" = type { %"class.std::__1::__compressed_pair.61" }
%"class.std::__1::__compressed_pair.61" = type { %"struct.std::__1::__compressed_pair_elem.62" }
%"struct.std::__1::__compressed_pair_elem.62" = type { %class.GrAuditTrail* }
%class.GrAuditTrail = type <{ %class.SkTArray, %class.SkTHashMap, %class.SkTHashMap.70, %class.SkTArray.79, %class.SkTArray.81, i32, i8, [3 x i8] }>
%class.SkTArray = type { %"class.std::__1::unique_ptr.63"*, i64 }
%"class.std::__1::unique_ptr.63" = type { %"class.std::__1::__compressed_pair.295" }
%"class.std::__1::__compressed_pair.295" = type { %"struct.std::__1::__compressed_pair_elem.296" }
%"struct.std::__1::__compressed_pair_elem.296" = type { %"struct.GrAuditTrail::Op"* }
%"struct.GrAuditTrail::Op" = type <{ %class.SkString, %class.SkTArray.81, %struct.SkRect, i32, i32, i32, [4 x i8] }>
%class.SkString = type { %class.sk_sp.82 }
%class.sk_sp.82 = type { %"struct.SkString::Rec"* }
%"struct.SkString::Rec" = type <{ i32, %"struct.std::__1::atomic", i8, [3 x i8] }>
%struct.SkRect = type { float, float, float, float }
%class.SkTHashMap = type { %class.SkTHashTable }
%class.SkTHashTable = type { i32, i32, %class.SkAutoTArray }
%class.SkAutoTArray = type { %"class.std::__1::unique_ptr.64" }
%"class.std::__1::unique_ptr.64" = type { %"class.std::__1::__compressed_pair.65" }
%"class.std::__1::__compressed_pair.65" = type { %"struct.std::__1::__compressed_pair_elem.66" }
%"struct.std::__1::__compressed_pair_elem.66" = type { %"struct.SkTHashTable<SkTHashMap<unsigned int, int, SkGoodHash>::Pair, unsigned int, SkTHashMap<unsigned int, int, SkGoodHash>::Pair>::Slot"* }
%"struct.SkTHashTable<SkTHashMap<unsigned int, int, SkGoodHash>::Pair, unsigned int, SkTHashMap<unsigned int, int, SkGoodHash>::Pair>::Slot" = type { %"struct.SkTHashMap<unsigned int, int, SkGoodHash>::Pair", i32 }
%"struct.SkTHashMap<unsigned int, int, SkGoodHash>::Pair" = type { %"struct.std::__1::pair" }
%"struct.std::__1::pair" = type { i32, i32 }
%class.SkTHashMap.70 = type { %class.SkTHashTable.71 }
%class.SkTHashTable.71 = type { i32, i32, %class.SkAutoTArray.72 }
%class.SkAutoTArray.72 = type { %"class.std::__1::unique_ptr.73" }
%"class.std::__1::unique_ptr.73" = type { %"class.std::__1::__compressed_pair.74" }
%"class.std::__1::__compressed_pair.74" = type { %"struct.std::__1::__compressed_pair_elem.75" }
%"struct.std::__1::__compressed_pair_elem.75" = type { %"struct.SkTHashTable<SkTHashMap<int, SkTArray<GrAuditTrail::Op *, false> *, SkGoodHash>::Pair, int, SkTHashMap<int, SkTArray<GrAuditTrail::Op *, false> *, SkGoodHash>::Pair>::Slot"* }
%"struct.SkTHashTable<SkTHashMap<int, SkTArray<GrAuditTrail::Op *, false> *, SkGoodHash>::Pair, int, SkTHashMap<int, SkTArray<GrAuditTrail::Op *, false> *, SkGoodHash>::Pair>::Slot" = type <{ %"struct.SkTHashMap<int, SkTArray<GrAuditTrail::Op *, false> *, SkGoodHash>::Pair", i32, [4 x i8] }>
%"struct.SkTHashMap<int, SkTArray<GrAuditTrail::Op *, false> *, SkGoodHash>::Pair" = type { %"struct.std::__1::pair.300" }
%"struct.std::__1::pair.300" = type { i32, %class.SkTArray.301* }
%class.SkTArray.301 = type { %"struct.GrAuditTrail::Op"**, i64 }
%class.SkTArray.79 = type { %"class.std::__1::unique_ptr.80"*, i64 }
%"class.std::__1::unique_ptr.80" = type { %"class.std::__1::__compressed_pair.302" }
%"class.std::__1::__compressed_pair.302" = type { %"struct.std::__1::__compressed_pair_elem.303" }
%"struct.std::__1::__compressed_pair_elem.303" = type { %"struct.GrAuditTrail::OpNode"* }
%"struct.GrAuditTrail::OpNode" = type <{ %struct.SkRect, %class.SkTArray.301, %"class.GrSurfaceProxy::UniqueID", [4 x i8] }>
%"class.GrSurfaceProxy::UniqueID" = type { i32 }
%class.SkTArray.81 = type { %class.SkString*, i64 }
%"class.GrRecordingContext::OwnedArenas" = type { i8, %"class.std::__1::unique_ptr.86", %"class.std::__1::unique_ptr.92" }
%"class.std::__1::unique_ptr.86" = type { %"class.std::__1::__compressed_pair.87" }
%"class.std::__1::__compressed_pair.87" = type { %"struct.std::__1::__compressed_pair_elem.88" }
%"struct.std::__1::__compressed_pair_elem.88" = type { %class.SkArenaAlloc* }
%class.SkArenaAlloc = type <{ i8*, i8*, i8*, %class.SkFibBlockSizes, [4 x i8] }>
%class.SkFibBlockSizes = type { i32 }
%"class.std::__1::unique_ptr.92" = type { %"class.std::__1::__compressed_pair.93" }
%"class.std::__1::__compressed_pair.93" = type { %"struct.std::__1::__compressed_pair_elem.94" }
%"struct.std::__1::__compressed_pair_elem.94" = type { %class.GrSubRunAllocator* }
%class.GrSubRunAllocator = type { %class.GrBagOfBytes }
%class.GrBagOfBytes = type { i8*, i32, %class.SkFibBlockSizes.95 }
%class.SkFibBlockSizes.95 = type { i32 }
%"class.std::__1::unique_ptr.99" = type { %"class.std::__1::__compressed_pair.100" }
%"class.std::__1::__compressed_pair.100" = type { %"struct.std::__1::__compressed_pair_elem.101" }
%"struct.std::__1::__compressed_pair_elem.101" = type { %class.GrDrawingManager* }
%class.GrDrawingManager = type opaque
%"class.std::__1::unique_ptr.105" = type { %"class.std::__1::__compressed_pair.106" }
%"class.std::__1::__compressed_pair.106" = type { %"struct.std::__1::__compressed_pair_elem.107" }
%"struct.std::__1::__compressed_pair_elem.107" = type { %class.GrProxyProvider* }
%class.GrProxyProvider = type opaque
%"class.GrDirectContext::DirectContextID" = type { i32 }
%"class.std::__1::unique_ptr.111" = type { %"class.std::__1::__compressed_pair.112" }
%"class.std::__1::__compressed_pair.112" = type { %"struct.std::__1::__compressed_pair_elem.113" }
%"struct.std::__1::__compressed_pair_elem.113" = type { %class.SkTaskGroup* }
%class.SkTaskGroup = type opaque
%"class.std::__1::unique_ptr.117" = type { %"class.std::__1::__compressed_pair.118" }
%"class.std::__1::__compressed_pair.118" = type { %"struct.std::__1::__compressed_pair_elem.119" }
%"struct.std::__1::__compressed_pair_elem.119" = type { %class.GrStrikeCache* }
%class.GrStrikeCache = type opaque
%class.sk_sp.123 = type { %class.GrGpu* }
%"class.std::__1::unique_ptr.124" = type { %"class.std::__1::__compressed_pair.125" }
%"class.std::__1::__compressed_pair.125" = type { %"struct.std::__1::__compressed_pair_elem.126" }
%"struct.std::__1::__compressed_pair_elem.126" = type { %class.GrResourceCache* }
%class.GrResourceCache = type { %class.GrProxyProvider*, %class.GrThreadSafeCache*, i32, %class.SkTDPQueue, %class.SkTDArray, %class.SkTMultiMap, %class.SkTDynamicHash.137, i64, i64, i32, i64, i64, i32, [4 x i8], %"class.SkMessageBus<GrUniqueKeyInvalidatedMessage, unsigned int, true>::Inbox", %"class.SkMessageBus<GrTextureFreedMessage, GrDirectContext::DirectContextID, true>::Inbox", %class.SkTHashMap.155, %"class.GrDirectContext::DirectContextID", i32, %class.GrSingleOwner* }
%class.GrThreadSafeCache = type opaque
%class.SkTDPQueue = type { %class.SkTDArray }
%class.SkTDArray = type { %class.GrGpuResource**, i32, i32 }
%class.GrGpuResource = type { i32 (...)**, %class.GrIORef, i32, i32, %"class.std::__1::chrono::time_point", %class.GrScratchKey, %class.GrUniqueKey, %class.GrGpu*, i64, i8, i8, %"class.GrGpuResource::UniqueID" }
%class.GrIORef = type { %"struct.std::__1::atomic", %"struct.std::__1::atomic" }
%"class.std::__1::chrono::time_point" = type { %"class.std::__1::chrono::duration" }
%"class.std::__1::chrono::duration" = type { i64 }
%class.GrScratchKey = type { %class.GrResourceKey }
%class.GrResourceKey = type { %class.SkAutoSTMalloc }
%class.SkAutoSTMalloc = type <{ i32*, %union.anon.127, [4 x i8] }>
%union.anon.127 = type { [7 x i32] }
%class.GrUniqueKey = type { %class.GrResourceKey, %class.sk_sp.128, i8* }
%class.sk_sp.128 = type { %class.SkData* }
%class.SkData = type { %class.SkNVRefCnt, void (i8*, i8*)*, i8*, i8*, i64 }
%class.SkNVRefCnt = type { %"struct.std::__1::atomic" }
%"class.GrGpuResource::UniqueID" = type { i32 }
%class.SkTMultiMap = type <{ %class.SkTDynamicHash, i32, [4 x i8] }>
%class.SkTDynamicHash = type { %class.SkTHashTable.129 }
%class.SkTHashTable.129 = type { i32, i32, %class.SkAutoTArray.130 }
%class.SkAutoTArray.130 = type { %"class.std::__1::unique_ptr.131" }
%"class.std::__1::unique_ptr.131" = type { %"class.std::__1::__compressed_pair.132" }
%"class.std::__1::__compressed_pair.132" = type { %"struct.std::__1::__compressed_pair_elem.133" }
%"struct.std::__1::__compressed_pair_elem.133" = type { %"struct.SkTHashTable<SkTMultiMap<GrGpuResource, GrScratchKey, GrResourceCache::ScratchMapTraits>::ValueList *, GrScratchKey, SkTDynamicHash<SkTMultiMap<GrGpuResource, GrScratchKey, GrResourceCache::ScratchMapTraits>::ValueList, GrScratchKey, SkTMultiMap<GrGpuResource, GrScratchKey, GrResourceCache::ScratchMapTraits>::ValueList>::AdaptedTraits>::Slot"* }
%"struct.SkTHashTable<SkTMultiMap<GrGpuResource, GrScratchKey, GrResourceCache::ScratchMapTraits>::ValueList *, GrScratchKey, SkTDynamicHash<SkTMultiMap<GrGpuResource, GrScratchKey, GrResourceCache::ScratchMapTraits>::ValueList, GrScratchKey, SkTMultiMap<GrGpuResource, GrScratchKey, GrResourceCache::ScratchMapTraits>::ValueList>::AdaptedTraits>::Slot" = type opaque
%class.SkTDynamicHash.137 = type { %class.SkTHashTable.138 }
%class.SkTHashTable.138 = type { i32, i32, %class.SkAutoTArray.139 }
%class.SkAutoTArray.139 = type { %"class.std::__1::unique_ptr.140" }
%"class.std::__1::unique_ptr.140" = type { %"class.std::__1::__compressed_pair.141" }
%"class.std::__1::__compressed_pair.141" = type { %"struct.std::__1::__compressed_pair_elem.142" }
%"struct.std::__1::__compressed_pair_elem.142" = type { %"struct.SkTHashTable<GrGpuResource *, GrUniqueKey, SkTDynamicHash<GrGpuResource, GrUniqueKey, GrResourceCache::UniqueHashTraits>::AdaptedTraits>::Slot"* }
%"struct.SkTHashTable<GrGpuResource *, GrUniqueKey, SkTDynamicHash<GrGpuResource, GrUniqueKey, GrResourceCache::UniqueHashTraits>::AdaptedTraits>::Slot" = type <{ %class.GrGpuResource*, i32, [4 x i8] }>
%"class.SkMessageBus<GrUniqueKeyInvalidatedMessage, unsigned int, true>::Inbox" = type <{ %class.SkTArray.146, %class.SkMutex, i32, [4 x i8] }>
%class.SkTArray.146 = type { %class.GrUniqueKeyInvalidatedMessage*, i64 }
%class.GrUniqueKeyInvalidatedMessage = type <{ %class.GrUniqueKey, i32, i8, [3 x i8] }>
%class.SkMutex = type { %class.SkSemaphore }
%class.SkSemaphore = type { %"struct.std::__1::atomic", %class.SkOnce, %"struct.SkSemaphore::OSSemaphore"* }
%class.SkOnce = type { %"struct.std::__1::atomic.147" }
%"struct.std::__1::atomic.147" = type { %"struct.std::__1::__atomic_base.148" }
%"struct.std::__1::__atomic_base.148" = type { %"struct.std::__1::__atomic_base.149" }
%"struct.std::__1::__atomic_base.149" = type { %"struct.std::__1::__cxx_atomic_impl.150" }
%"struct.std::__1::__cxx_atomic_impl.150" = type { %"struct.std::__1::__cxx_atomic_base_impl.151" }
%"struct.std::__1::__cxx_atomic_base_impl.151" = type { i8 }
%"struct.SkSemaphore::OSSemaphore" = type opaque
%"class.SkMessageBus<GrTextureFreedMessage, GrDirectContext::DirectContextID, true>::Inbox" = type <{ %class.SkTArray.152, %class.SkMutex, %"class.GrDirectContext::DirectContextID", [4 x i8] }>
%class.SkTArray.152 = type { %struct.GrTextureFreedMessage*, i64 }
%struct.GrTextureFreedMessage = type <{ %class.GrTexture*, %"class.GrDirectContext::DirectContextID", [4 x i8] }>
%class.GrTexture = type <{ i32 (...)**, i32, i32, i32, [4 x i8], %class.GrSurface }>
%class.GrSurface = type { %class.GrGpuResource, %struct.SkISize, i32, i8, %class.sk_sp.153 }
%struct.SkISize = type { i32, i32 }
%class.sk_sp.153 = type { %class.GrRefCntedCallback* }
%class.GrRefCntedCallback = type { %class.SkNVRefCnt.154, void (i8*)*, i8* }
%class.SkNVRefCnt.154 = type { %"struct.std::__1::atomic" }
%class.SkTHashMap.155 = type { %class.SkTHashTable.156 }
%class.SkTHashTable.156 = type { i32, i32, %class.SkAutoTArray.157 }
%class.SkAutoTArray.157 = type { %"class.std::__1::unique_ptr.158" }
%"class.std::__1::unique_ptr.158" = type { %"class.std::__1::__compressed_pair.159" }
%"class.std::__1::__compressed_pair.159" = type { %"struct.std::__1::__compressed_pair_elem.160" }
%"struct.std::__1::__compressed_pair_elem.160" = type { %"struct.SkTHashTable<SkTHashMap<unsigned int, GrResourceCache::TextureAwaitingUnref, SkGoodHash>::Pair, unsigned int, SkTHashMap<unsigned int, GrResourceCache::TextureAwaitingUnref, SkGoodHash>::Pair>::Slot"* }
%"struct.SkTHashTable<SkTHashMap<unsigned int, GrResourceCache::TextureAwaitingUnref, SkGoodHash>::Pair, unsigned int, SkTHashMap<unsigned int, GrResourceCache::TextureAwaitingUnref, SkGoodHash>::Pair>::Slot" = type opaque
%"class.std::__1::unique_ptr.167" = type { %"class.std::__1::__compressed_pair.168" }
%"class.std::__1::__compressed_pair.168" = type { %"struct.std::__1::__compressed_pair_elem.169" }
%"struct.std::__1::__compressed_pair_elem.169" = type { %class.GrResourceProvider* }
%class.GrResourceProvider = type { %class.GrResourceCache*, %class.GrGpu*, %class.sk_sp, %class.sk_sp.170, %class.sk_sp.170 }
%class.sk_sp.170 = type { %class.GrGpuBuffer* }
%class.GrGpuBuffer = type { %class.GrGpuResource, %class.GrBuffer, i8*, i64, i32, i32 }
%class.GrBuffer = type { i32 (...)** }
%"class.GrContextOptions::PersistentCache" = type { i32 (...)** }
%"class.GrContextOptions::ShaderErrorHandler" = type { i32 (...)** }
%"class.std::__1::unique_ptr.174" = type { %"class.std::__1::__compressed_pair.175" }
%"class.std::__1::__compressed_pair.175" = type { %"struct.std::__1::__compressed_pair_elem.176" }
%"struct.std::__1::__compressed_pair_elem.176" = type { %class.GrClientMappedBufferManager* }
%class.GrClientMappedBufferManager = type opaque
%"class.std::__1::unique_ptr.180" = type { %"class.std::__1::__compressed_pair.181" }
%"class.std::__1::__compressed_pair.181" = type { %"struct.std::__1::__compressed_pair_elem.182" }
%"struct.std::__1::__compressed_pair_elem.182" = type { %class.GrAtlasManager* }
%class.GrAtlasManager = type opaque
%"class.std::__1::unique_ptr.186" = type { %"class.std::__1::__compressed_pair.187" }
%"class.std::__1::__compressed_pair.187" = type { %"struct.std::__1::__compressed_pair_elem.188" }
%"struct.std::__1::__compressed_pair_elem.188" = type { %class.GrSmallPathAtlasMgr* }
%class.GrSmallPathAtlasMgr = type opaque
%class.SkSTArray = type { %class.SkAlignedSTStorage, %class.SkTArray.192 }
%class.SkAlignedSTStorage = type { [64 x i8] }
%class.SkTArray.192 = type { %"struct.GrGpu::SubmittedProc"*, i64 }
%"struct.GrGpu::SubmittedProc" = type { void (i8*, i1)*, i8* }
%class.SkRefCntBase = type <{ i32 (...)**, %"struct.std::__1::atomic", [4 x i8] }>
%class.sk_sp.226 = type { %class.GrTexture* }
%class.GrBackendFormat = type { i32, i8, %union.anon.223, i32, [4 x i8] }
%union.anon.223 = type { %struct.anon.224 }
%struct.anon.224 = type { i32, [4 x i8], %struct.GrVkYcbcrConversionInfo }
%struct.GrVkYcbcrConversionInfo = type <{ i32, [4 x i8], i64, i32, i32, i32, i32, i32, i32, i32, [4 x i8] }>
%class.GrRenderTarget = type <{ i32 (...)**, %class.sk_sp.227, %class.sk_sp.227, i32, [4 x i8], %class.GrSurface }>
%class.sk_sp.227 = type { %class.GrAttachment* }
%class.GrAttachment = type <{ %class.GrSurface, i8, [3 x i8], i32, i8, i8, [6 x i8] }>
%struct.GrMipLevel = type { i8*, i64, %class.sk_sp.128 }
%"class.skia::tracing_internals::ScopedTracer" = type { %"struct.skia::tracing_internals::ScopedTracer::Data"*, %"struct.skia::tracing_internals::ScopedTracer::Data" }
%"struct.skia::tracing_internals::ScopedTracer::Data" = type { i8*, i8*, i64 }
%class.SkEventTracer = type { i32 (...)** }
%class.SkTArray.233 = type opaque
%class.GrBackendTexture = type { i8, i32, i32, i8, i32, %union.anon.234, %class.sk_sp.236 }
%union.anon.234 = type { %class.GrGLBackendTextureInfo, [120 x i8] }
%class.GrGLBackendTextureInfo = type { %struct.GrGLTextureInfo, %class.GrGLTextureParameters* }
%struct.GrGLTextureInfo = type { i32, i32, i32 }
%class.GrGLTextureParameters = type { %class.SkNVRefCnt.235, %"struct.GrGLTextureParameters::SamplerOverriddenState", %"struct.GrGLTextureParameters::NonsamplerState", i64 }
%class.SkNVRefCnt.235 = type { %"struct.std::__1::atomic" }
%"struct.GrGLTextureParameters::SamplerOverriddenState" = type <{ i32, i32, i32, i32, float, float, i8, [3 x i8] }>
%"struct.GrGLTextureParameters::NonsamplerState" = type <{ i32, i32, i8, [3 x i8] }>
%class.sk_sp.236 = type { %class.GrBackendSurfaceMutableStateImpl* }
%class.GrBackendSurfaceMutableStateImpl = type { %class.SkRefCnt.base, %class.GrBackendSurfaceMutableState, [4 x i8] }
%class.GrBackendSurfaceMutableState = type <{ %union.anon.237, i32, i8, [3 x i8] }>
%union.anon.237 = type { %class.GrVkSharedImageInfo }
%class.GrVkSharedImageInfo = type { %"struct.std::__1::atomic.238", %"struct.std::__1::atomic.242" }
%"struct.std::__1::atomic.238" = type { %"struct.std::__1::__atomic_base.239" }
%"struct.std::__1::__atomic_base.239" = type { %"struct.std::__1::__cxx_atomic_impl.240" }
%"struct.std::__1::__cxx_atomic_impl.240" = type { %"struct.std::__1::__cxx_atomic_base_impl.241" }
%"struct.std::__1::__cxx_atomic_base_impl.241" = type { i32 }
%"struct.std::__1::atomic.242" = type { %"struct.std::__1::__atomic_base.243" }
%"struct.std::__1::__atomic_base.243" = type { %"struct.std::__1::__atomic_base.244" }
%"struct.std::__1::__atomic_base.244" = type { %"struct.std::__1::__cxx_atomic_impl.245" }
%"struct.std::__1::__cxx_atomic_impl.245" = type { %"struct.std::__1::__cxx_atomic_base_impl.246" }
%"struct.std::__1::__cxx_atomic_base_impl.246" = type { i32 }
%class.sk_sp.248 = type { %class.GrRenderTarget* }
%class.GrBackendRenderTarget = type { i8, i8, i32, i32, i32, i32, i32, %union.anon.247, %class.sk_sp.236 }
%union.anon.247 = type { %struct.GrGLFramebufferInfo, [136 x i8] }
%struct.GrGLFramebufferInfo = type { i32, i32 }
%struct.SkImageInfo = type { %class.SkColorInfo, %struct.SkISize }
%class.SkColorInfo = type { %class.sk_sp.249, i32, i32 }
%class.sk_sp.249 = type { %class.SkColorSpace* }
%class.SkColorSpace = type <{ %class.SkNVRefCnt.250, i32, i32, %struct.skcms_TransferFunction, %struct.skcms_Matrix3x3, %struct.skcms_TransferFunction, %struct.skcms_Matrix3x3, %class.SkOnce, [3 x i8] }>
%class.SkNVRefCnt.250 = type { %"struct.std::__1::atomic" }
%struct.skcms_TransferFunction = type { float, float, float, float, float, float, float }
%struct.skcms_Matrix3x3 = type { [3 x [3 x float]] }
%struct.GrVkDrawableInfo = type { %struct.VkCommandBuffer_T*, i32, %struct.VkRenderPass_T*, i32, %struct.VkRect2D*, %struct.VkImage_T* }
%struct.VkCommandBuffer_T = type opaque
%struct.VkRenderPass_T = type opaque
%struct.VkRect2D = type { %struct.VkOffset2D, %struct.VkExtent2D }
%struct.VkOffset2D = type { i32, i32 }
%struct.VkExtent2D = type { i32, i32 }
%struct.VkImage_T = type opaque
%class.sk_sp.251 = type { %class.GrGpuBuffer* }
%struct.SkIRect = type { i32, i32, i32, i32 }
%struct.SkIPoint = type { i32, i32 }
%class.GrSurfaceProxy = type { i32 (...)**, %class.SkNVRefCnt.252, %class.sk_sp.253, i32, [4 x i8], %class.GrBackendFormat, %struct.SkISize, i32, i8, i32, %"class.GrSurfaceProxy::UniqueID", %"class.std::__1::function", i8, i8, i8, i8, i32, %"struct.std::__1::atomic.255" }
%class.SkNVRefCnt.252 = type { %"struct.std::__1::atomic" }
%class.sk_sp.253 = type { %class.GrSurface* }
%"class.std::__1::function" = type { %"class.std::__1::__function::__policy_func" }
%"class.std::__1::__function::__policy_func" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker", %"struct.std::__1::__function::__policy"* }
%"union.std::__1::__function::__policy_storage" = type { i8*, [8 x i8] }
%"struct.std::__1::__function::__policy_invoker" = type { void (%"struct.GrSurfaceProxy::LazyCallbackResult"*, %"union.std::__1::__function::__policy_storage"*, %class.GrResourceProvider*, %"struct.GrSurfaceProxy::LazySurfaceDesc"*)* }
%"struct.GrSurfaceProxy::LazyCallbackResult" = type <{ %class.sk_sp.253, i32, i8, [3 x i8] }>
%"struct.GrSurfaceProxy::LazySurfaceDesc" = type <{ %struct.SkISize, i32, i8, i8, [2 x i8], i32, [4 x i8], %class.GrBackendFormat*, i8, i8, [6 x i8] }>
%"struct.std::__1::__function::__policy" = type { i8* (i8*)*, void (i8*)*, i8, %"class.std::type_info"* }
%"class.std::type_info" = type { i32 (...)**, i8* }
%struct.GrFlushInfo = type { i32, %class.GrBackendSemaphore*, void (i8*)*, i8*, void (i8*, i1)*, i8* }
%class.GrBackendSemaphore = type <{ i32, [4 x i8], %union.anon.260, i64, i8, [7 x i8] }>
%union.anon.260 = type { %struct.__GLsync* }
%struct.__GLsync = type opaque
%"class.std::__1::unique_ptr.264" = type { %"class.std::__1::__compressed_pair.265" }
%"class.std::__1::__compressed_pair.265" = type { %"struct.std::__1::__compressed_pair_elem.266" }
%"struct.std::__1::__compressed_pair_elem.266" = type { %class.GrSemaphore* }
%class.GrSemaphore = type { i32 (...)** }
%class.GrOpsRenderPass = type { i32 (...)**, i32, %class.GrRenderTarget*, %class.sk_sp.273, %class.sk_sp.273, %class.sk_sp.273, i32, i32 }
%class.sk_sp.273 = type { %class.GrBuffer* }
%"struct.GrOpsRenderPass::LoadAndStoreInfo" = type { i32, i32, %"struct.std::__1::array" }
%"struct.std::__1::array" = type { [4 x float] }
%"struct.GrOpsRenderPass::StencilLoadAndStoreInfo" = type { i32, i32 }
%class.SkTArray.274 = type opaque
%class.GrStagingBufferManager = type { %"class.std::__1::vector.275", %class.GrGpu* }
%"class.std::__1::vector.275" = type { %"class.std::__1::__vector_base.276" }
%"class.std::__1::__vector_base.276" = type { %"struct.GrStagingBufferManager::StagingBuffer"*, %"struct.GrStagingBufferManager::StagingBuffer"*, %"class.std::__1::__compressed_pair.277" }
%"struct.GrStagingBufferManager::StagingBuffer" = type { %class.sk_sp.251, i8*, i64 }
%"class.std::__1::__compressed_pair.277" = type { %"struct.std::__1::__compressed_pair_elem.278" }
%"struct.std::__1::__compressed_pair_elem.278" = type { %"struct.GrStagingBufferManager::StagingBuffer"* }
%class.GrRingBuffer = type { %class.GrGpu*, %class.sk_sp.251, %"class.std::__1::vector.282", i64, i64, i32, i64, i64, i64 }
%"class.std::__1::vector.282" = type { %"class.std::__1::__vector_base.283" }
%"class.std::__1::__vector_base.283" = type { %class.sk_sp.251*, %class.sk_sp.251*, %"class.std::__1::__compressed_pair.284" }
%"class.std::__1::__compressed_pair.284" = type { %"struct.std::__1::__compressed_pair_elem.285" }
%"struct.std::__1::__compressed_pair_elem.285" = type { %class.sk_sp.251* }
%class.SkJSONWriter = type { i8*, i8*, i8*, %class.SkWStream*, i32, i32, %class.SkSTArray.289, %class.SkSTArray.292 }
%class.SkWStream = type { i32 (...)** }
%class.SkSTArray.289 = type { %class.SkAlignedSTStorage.290, %class.SkTArray.291 }
%class.SkAlignedSTStorage.290 = type { [64 x i8] }
%class.SkTArray.291 = type { i32*, i64 }
%class.SkSTArray.292 = type { %class.SkAlignedSTStorage.293, %class.SkTArray.294 }
%class.SkAlignedSTStorage.293 = type { [16 x i8] }
%class.SkTArray.294 = type { i8*, i64 }

$_ZNK12SkRefCntBase16internal_disposeEv = comdat any

$_ZN5GrGpu20stagingBufferManagerEv = comdat any

$_ZN5GrGpu18uniformsRingBufferEv = comdat any

$_ZNK5GrGpu12isDeviceLostEv = comdat any

$_ZN5GrGpu21takeOwnershipOfBufferE5sk_spI11GrGpuBufferE = comdat any

$_ZN5GrGpu29releaseUnlockedBackendObjectsEv = comdat any

$_ZN5GrGpu22setBackendTextureStateERK16GrBackendTextureRK28GrBackendSurfaceMutableStatePS3_5sk_spI18GrRefCntedCallbackE = comdat any

$_ZN5GrGpu27setBackendRenderTargetStateERK21GrBackendRenderTargetRK28GrBackendSurfaceMutableStatePS3_5sk_spI18GrRefCntedCallbackE = comdat any

$_ZN5GrGpu16precompileShaderERK6SkDataS2_ = comdat any

$_ZN5GrGpu24storeVkPipelineCacheDataEv = comdat any

$_ZN5GrGpu30insertManualFramebufferBarrierEv = comdat any

$_ZN5GrGpu14onResetContextEj = comdat any

$_ZN5GrGpu22onResetTextureBindingsEv = comdat any

$_ZN5GrGpu46prepareSurfacesForBackendAccessAndStateUpdatesE6SkSpanIP14GrSurfaceProxyEN9SkSurface20BackendSurfaceAccessEPK28GrBackendSurfaceMutableState = comdat any

$_ZN5GrGpu24onReportSubmitHistogramsEv = comdat any

$_ZN8SkTArrayIN5GrGpu13SubmittedProcELb0EE12checkReallocEiNS2_11ReallocTypeE = comdat any

@_ZTV5GrGpu = hidden unnamed_addr constant { [61 x i8*] } { [61 x i8*] [i8* null, i8* null, i8* bitcast (void (%class.GrGpu*)* @_ZN5GrGpuD2Ev to i8*), i8* bitcast (void (%class.GrGpu*)* @_ZN5GrGpuD0Ev to i8*), i8* bitcast (void (%class.SkRefCntBase*)* @_ZNK12SkRefCntBase16internal_disposeEv to i8*), i8* bitcast (%class.GrStagingBufferManager* (%class.GrGpu*)* @_ZN5GrGpu20stagingBufferManagerEv to i8*), i8* bitcast (%class.GrRingBuffer* (%class.GrGpu*)* @_ZN5GrGpu18uniformsRingBufferEv to i8*), i8* bitcast (void (%class.GrGpu*, i32)* @_ZN5GrGpu10disconnectENS_14DisconnectTypeE to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (i1 (%class.GrGpu*)* @_ZNK5GrGpu12isDeviceLostEv to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void (%class.GrGpu*, %class.sk_sp.251*)* @_ZN5GrGpu21takeOwnershipOfBufferE5sk_spI11GrGpuBufferE to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void (%class.GrGpu*)* @_ZN5GrGpu29releaseUnlockedBackendObjectsEv to i8*), i8* bitcast (i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.GrBackendSurfaceMutableState*, %class.GrBackendSurfaceMutableState*, %class.sk_sp.153*)* @_ZN5GrGpu22setBackendTextureStateERK16GrBackendTextureRK28GrBackendSurfaceMutableStatePS3_5sk_spI18GrRefCntedCallbackE to i8*), i8* bitcast (i1 (%class.GrGpu*, %class.GrBackendRenderTarget*, %class.GrBackendSurfaceMutableState*, %class.GrBackendSurfaceMutableState*, %class.sk_sp.153*)* @_ZN5GrGpu27setBackendRenderTargetStateERK21GrBackendRenderTargetRK28GrBackendSurfaceMutableStatePS3_5sk_spI18GrRefCntedCallbackE to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (i1 (%class.GrGpu*, %class.SkData*, %class.SkData*)* @_ZN5GrGpu16precompileShaderERK6SkDataS2_ to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void (%class.GrGpu*)* @_ZN5GrGpu24storeVkPipelineCacheDataEv to i8*), i8* bitcast (void (%class.GrGpu*)* @_ZN5GrGpu30insertManualFramebufferBarrierEv to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void (%class.GrGpu*, i32)* @_ZN5GrGpu14onResetContextEj to i8*), i8* bitcast (void (%class.GrGpu*)* @_ZN5GrGpu22onResetTextureBindingsEv to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void (%class.sk_sp.248*, %class.GrGpu*, %struct.SkImageInfo*, %struct.GrVkDrawableInfo*)* @_ZN5GrGpu37onWrapVulkanSecondaryCBAsRenderTargetERK11SkImageInfoRK16GrVkDrawableInfo to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void (%class.GrGpu*, %class.GrSurfaceProxy**, i64, i32, %class.GrBackendSurfaceMutableState*)* @_ZN5GrGpu46prepareSurfacesForBackendAccessAndStateUpdatesE6SkSpanIP14GrSurfaceProxyEN9SkSurface20BackendSurfaceAccessEPK28GrBackendSurfaceMutableState to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*), i8* bitcast (void (%class.GrGpu*)* @_ZN5GrGpu24onReportSubmitHistogramsEv to i8*)] }, align 8
@.str = private unnamed_addr constant [29 x i8] c"disabled-by-default-skia.gpu\00", align 1
@__PRETTY_FUNCTION__._ZN5GrGpu13createTextureE7SkISizeRK15GrBackendFormat12GrRenderablei10SkBudgeted11GrProtected11GrColorTypeS7_PK10GrMipLeveli = private unnamed_addr constant [167 x i8] c"sk_sp<GrTexture> GrGpu::createTexture(SkISize, const GrBackendFormat &, GrRenderable, int, SkBudgeted, GrProtected, GrColorType, GrColorType, const GrMipLevel *, int)\00", align 1
@__PRETTY_FUNCTION__._ZN5GrGpu12createBufferEm15GrGpuBufferType15GrAccessPatternPKv = private unnamed_addr constant [95 x i8] c"sk_sp<GrGpuBuffer> GrGpu::createBuffer(size_t, GrGpuBufferType, GrAccessPattern, const void *)\00", align 1
@__PRETTY_FUNCTION__._ZN5GrGpu11copySurfaceEP9GrSurfaceS1_RK7SkIRectRK8SkIPoint = private unnamed_addr constant [85 x i8] c"bool GrGpu::copySurface(GrSurface *, GrSurface *, const SkIRect &, const SkIPoint &)\00", align 1
@__PRETTY_FUNCTION__._ZN5GrGpu10readPixelsEP9GrSurface7SkIRect11GrColorTypeS3_Pvm = private unnamed_addr constant [87 x i8] c"bool GrGpu::readPixels(GrSurface *, SkIRect, GrColorType, GrColorType, void *, size_t)\00", align 1
@__PRETTY_FUNCTION__._ZN5GrGpu11writePixelsEP9GrSurface7SkIRect11GrColorTypeS3_PK10GrMipLevelib = private unnamed_addr constant [103 x i8] c"bool GrGpu::writePixels(GrSurface *, SkIRect, GrColorType, GrColorType, const GrMipLevel *, int, bool)\00", align 1
@__PRETTY_FUNCTION__._ZN5GrGpu16transferPixelsToEP9GrTexture7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmm = private unnamed_addr constant [113 x i8] c"bool GrGpu::transferPixelsTo(GrTexture *, SkIRect, GrColorType, GrColorType, sk_sp<GrGpuBuffer>, size_t, size_t)\00", align 1
@__PRETTY_FUNCTION__._ZN5GrGpu18transferPixelsFromEP9GrSurface7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEm = private unnamed_addr constant [107 x i8] c"bool GrGpu::transferPixelsFrom(GrSurface *, SkIRect, GrColorType, GrColorType, sk_sp<GrGpuBuffer>, size_t)\00", align 1
@__PRETTY_FUNCTION__._ZN5GrGpu22regenerateMipMapLevelsEP9GrTexture = private unnamed_addr constant [48 x i8] c"bool GrGpu::regenerateMipMapLevels(GrTexture *)\00", align 1
@__PRETTY_FUNCTION__._ZN5GrGpu16executeFlushInfoE6SkSpanIP14GrSurfaceProxyEN9SkSurface20BackendSurfaceAccessERK11GrFlushInfoPK28GrBackendSurfaceMutableState = private unnamed_addr constant [147 x i8] c"void GrGpu::executeFlushInfo(SkSpan<GrSurfaceProxy *>, SkSurface::BackendSurfaceAccess, const GrFlushInfo &, const GrBackendSurfaceMutableState *)\00", align 1
@_ZZN5GrGpu22reportSubmitHistogramsEvE24atomic_histogram_pointer = internal global %"struct.std::__1::atomic.255" zeroinitializer, align 8
@.str.1 = private unnamed_addr constant [24 x i8] c"Skia.SubmitRenderPasses\00", align 1
@.str.2 = private unnamed_addr constant [39 x i8] c"../../third_party/skia/src/gpu/GrGpu.h\00", align 1
@.str.3 = private unnamed_addr constant [42 x i8] c"Manual framebuffer barrier not supported.\00", align 1
@_ZZN5GrGpu13createTextureE7SkISizeRK15GrBackendFormat12GrRenderablei10SkBudgeted11GrProtected11GrColorTypeS7_PK10GrMipLeveliE28trace_event_unique_atomic181.0.0 = internal unnamed_addr global i64 0, align 8
@_ZZN5GrGpu12createBufferEm15GrGpuBufferType15GrAccessPatternPKvE28trace_event_unique_atomic362.0.0 = internal unnamed_addr global i64 0, align 8
@_ZZN5GrGpu11copySurfaceEP9GrSurfaceS1_RK7SkIRectRK8SkIPointE28trace_event_unique_atomic373.0.0 = internal unnamed_addr global i64 0, align 8
@_ZZN5GrGpu10readPixelsEP9GrSurface7SkIRect11GrColorTypeS3_PvmE28trace_event_unique_atomic392.0.0 = internal unnamed_addr global i64 0, align 8
@_ZZN5GrGpu11writePixelsEP9GrSurface7SkIRect11GrColorTypeS3_PK10GrMipLevelibE28trace_event_unique_atomic427.0.0 = internal unnamed_addr global i64 0, align 8
@_ZZN5GrGpu16transferPixelsToEP9GrTexture7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmmE28trace_event_unique_atomic475.0.0 = internal unnamed_addr global i64 0, align 8
@_ZZN5GrGpu18transferPixelsFromEP9GrSurface7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmE28trace_event_unique_atomic524.0.0 = internal unnamed_addr global i64 0, align 8
@_ZZN5GrGpu22regenerateMipMapLevelsEP9GrTextureE28trace_event_unique_atomic555.0.0 = internal unnamed_addr global i64 0, align 8
@_ZZN5GrGpu16executeFlushInfoE6SkSpanIP14GrSurfaceProxyEN9SkSurface20BackendSurfaceAccessERK11GrFlushInfoPK28GrBackendSurfaceMutableStateE28trace_event_unique_atomic608.0.0 = internal unnamed_addr global i64 0, align 8
@switch.table._ZN5GrGpu16transferPixelsToEP9GrTexture7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmm = private unnamed_addr constant [31 x i64] [i64 0, i64 1, i64 2, i64 2, i64 4, i64 4, i64 4, i64 2, i64 4, i64 4, i64 4, i64 1, i64 2, i64 2, i64 8, i64 8, i64 16, i64 2, i64 4, i64 4, i64 8, i64 4, i64 16, i64 4, i64 3, i64 1, i64 2, i64 2, i64 2, i64 2, i64 2], align 8

@_ZN5GrGpuD1Ev = hidden unnamed_addr alias void (%class.GrGpu*), void (%class.GrGpu*)* @_ZN5GrGpuD2Ev

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define hidden void @_ZN5GrGpuC2EP15GrDirectContext(%class.GrGpu*, %class.GrDirectContext*) unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 1, i32* %3, align 4
  %4 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [61 x i8*] }, { [61 x i8*] }* @_ZTV5GrGpu, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %4, align 8
  %5 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 2, i32 0
  %6 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 4
  %7 = bitcast %class.GrCaps** %5 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %7, i8 0, i64 16, i1 false)
  store i32 -1, i32* %6, align 8
  %8 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 5
  store %class.GrDirectContext* %1, %class.GrDirectContext** %8, align 8
  %9 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 6, i32 0, i32 0, i64 64
  %10 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 6, i32 0, i32 0, i64 0
  %11 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 6, i32 0, i32 0, i64 72
  %12 = bitcast i8* %11 to i64*
  %13 = bitcast i8* %9 to i8**
  store i8* %10, i8** %13, align 8
  store i64 34359738368, i64* %12, align 8
  %14 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 7
  store i8 0, i8* %14, align 8
  %15 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 8
  store i32 0, i32* %15, align 4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpuD2Ev(%class.GrGpu*) unnamed_addr #1 align 2 {
  %2 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [61 x i8*] }, { [61 x i8*] }* @_ZTV5GrGpu, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 6, i32 0, i32 0, i64 64
  %4 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 6, i32 0, i32 0, i64 72
  %5 = bitcast i8* %4 to i64*
  %6 = load i64, i64* %5, align 8
  %7 = and i64 %6, 4294967294
  %8 = icmp eq i64 %7, 0
  br i1 %8, label %23, label %9

9:                                                ; preds = %1
  %10 = bitcast i8* %3 to %"struct.GrGpu::SubmittedProc"**
  br label %11

11:                                               ; preds = %11, %9
  %12 = phi i64 [ 0, %9 ], [ %18, %11 ]
  %13 = load %"struct.GrGpu::SubmittedProc"*, %"struct.GrGpu::SubmittedProc"** %10, align 8
  %14 = getelementptr inbounds %"struct.GrGpu::SubmittedProc", %"struct.GrGpu::SubmittedProc"* %13, i64 %12, i32 0
  %15 = load void (i8*, i1)*, void (i8*, i1)** %14, align 8
  %16 = getelementptr inbounds %"struct.GrGpu::SubmittedProc", %"struct.GrGpu::SubmittedProc"* %13, i64 %12, i32 1
  %17 = load i8*, i8** %16, align 8
  tail call void %15(i8* %17, i1 zeroext false) #14
  %18 = add nuw nsw i64 %12, 1
  %19 = load i64, i64* %5, align 8
  %20 = lshr i64 %19, 1
  %21 = and i64 %20, 2147483647
  %22 = icmp ult i64 %18, %21
  br i1 %22, label %11, label %23

23:                                               ; preds = %11, %1
  %24 = phi i64 [ %6, %1 ], [ %19, %11 ]
  %25 = bitcast i8* %3 to %class.SkTArray.192*
  %26 = and i64 %24, -4294967295
  store i64 %26, i64* %5, align 8
  tail call void @_ZN8SkTArrayIN5GrGpu13SubmittedProcELb0EE12checkReallocEiNS2_11ReallocTypeE(%class.SkTArray.192* %25, i32 0, i32 2) #14
  %27 = load i64, i64* %5, align 8
  %28 = and i64 %27, -4294967297
  store i64 %28, i64* %5, align 8
  %29 = and i64 %27, 1
  %30 = icmp eq i64 %29, 0
  br i1 %30, label %34, label %31

31:                                               ; preds = %23
  %32 = bitcast i8* %3 to i8**
  %33 = load i8*, i8** %32, align 8
  tail call void @_Z7sk_freePv(i8* %33) #14
  br label %34

34:                                               ; preds = %23, %31
  %35 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 3, i32 0, i32 0, i32 0
  %36 = load %"class.SkSL::Compiler"*, %"class.SkSL::Compiler"** %35, align 8
  store %"class.SkSL::Compiler"* null, %"class.SkSL::Compiler"** %35, align 8
  %37 = icmp eq %"class.SkSL::Compiler"* %36, null
  br i1 %37, label %43, label %38

38:                                               ; preds = %34
  %39 = bitcast %"class.SkSL::Compiler"* %36 to void (%"class.SkSL::Compiler"*)***
  %40 = load void (%"class.SkSL::Compiler"*)**, void (%"class.SkSL::Compiler"*)*** %39, align 8
  %41 = getelementptr inbounds void (%"class.SkSL::Compiler"*)*, void (%"class.SkSL::Compiler"*)** %40, i64 1
  %42 = load void (%"class.SkSL::Compiler"*)*, void (%"class.SkSL::Compiler"*)** %41, align 8
  tail call void %42(%"class.SkSL::Compiler"* nonnull %36) #14
  br label %43

43:                                               ; preds = %34, %38
  %44 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 2, i32 0
  %45 = load %class.GrCaps*, %class.GrCaps** %44, align 8
  %46 = icmp eq %class.GrCaps* %45, null
  br i1 %46, label %57, label %47

47:                                               ; preds = %43
  %48 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %45, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %49 = atomicrmw add i32* %48, i32 -1 acq_rel
  %50 = icmp eq i32 %49, 1
  br i1 %50, label %51, label %57

51:                                               ; preds = %47
  %52 = bitcast %class.GrCaps* %45 to %class.SkRefCntBase*
  %53 = bitcast %class.GrCaps* %45 to void (%class.SkRefCntBase*)***
  %54 = load void (%class.SkRefCntBase*)**, void (%class.SkRefCntBase*)*** %53, align 8
  %55 = getelementptr inbounds void (%class.SkRefCntBase*)*, void (%class.SkRefCntBase*)** %54, i64 2
  %56 = load void (%class.SkRefCntBase*)*, void (%class.SkRefCntBase*)** %55, align 8
  tail call void %56(%class.SkRefCntBase* nonnull %52) #14
  br label %57

57:                                               ; preds = %43, %47, %51
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu18callSubmittedProcsEb(%class.GrGpu*, i1 zeroext) local_unnamed_addr #1 align 2 {
  %3 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 6, i32 0, i32 0, i64 64
  %4 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 6, i32 0, i32 0, i64 72
  %5 = bitcast i8* %4 to i64*
  %6 = load i64, i64* %5, align 8
  %7 = and i64 %6, 4294967294
  %8 = icmp eq i64 %7, 0
  br i1 %8, label %11, label %9

9:                                                ; preds = %2
  %10 = bitcast i8* %3 to %"struct.GrGpu::SubmittedProc"**
  br label %17

11:                                               ; preds = %17, %2
  %12 = phi i64 [ %6, %2 ], [ %25, %17 ]
  %13 = bitcast i8* %3 to %class.SkTArray.192*
  %14 = and i64 %12, -4294967295
  store i64 %14, i64* %5, align 8
  tail call void @_ZN8SkTArrayIN5GrGpu13SubmittedProcELb0EE12checkReallocEiNS2_11ReallocTypeE(%class.SkTArray.192* %13, i32 0, i32 2) #14
  %15 = load i64, i64* %5, align 8
  %16 = and i64 %15, -4294967297
  store i64 %16, i64* %5, align 8
  ret void

17:                                               ; preds = %9, %17
  %18 = phi i64 [ 0, %9 ], [ %24, %17 ]
  %19 = load %"struct.GrGpu::SubmittedProc"*, %"struct.GrGpu::SubmittedProc"** %10, align 8
  %20 = getelementptr inbounds %"struct.GrGpu::SubmittedProc", %"struct.GrGpu::SubmittedProc"* %19, i64 %18, i32 0
  %21 = load void (i8*, i1)*, void (i8*, i1)** %20, align 8
  %22 = getelementptr inbounds %"struct.GrGpu::SubmittedProc", %"struct.GrGpu::SubmittedProc"* %19, i64 %18, i32 1
  %23 = load i8*, i8** %22, align 8
  tail call void %21(i8* %23, i1 zeroext %1) #14
  %24 = add nuw nsw i64 %18, 1
  %25 = load i64, i64* %5, align 8
  %26 = lshr i64 %25, 1
  %27 = and i64 %26, 2147483647
  %28 = icmp ult i64 %24, %27
  br i1 %28, label %17, label %11
}

; Function Attrs: noreturn nounwind ssp uwtable
define hidden void @_ZN5GrGpuD0Ev(%class.GrGpu* nocapture readnone) unnamed_addr #2 align 2 {
  tail call void @llvm.trap() #15
  unreachable
}

; Function Attrs: cold noreturn nounwind
declare void @llvm.trap() #3

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu19initCapsAndCompilerE5sk_spIK6GrCapsE(%class.GrGpu* nocapture, %class.sk_sp* nocapture) local_unnamed_addr #1 align 2 {
  %3 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 2
  %4 = getelementptr inbounds %class.sk_sp, %class.sk_sp* %1, i64 0, i32 0
  %5 = bitcast %class.sk_sp* %1 to i64*
  %6 = load i64, i64* %5, align 8
  store %class.GrCaps* null, %class.GrCaps** %4, align 8
  %7 = getelementptr inbounds %class.sk_sp, %class.sk_sp* %3, i64 0, i32 0
  %8 = load %class.GrCaps*, %class.GrCaps** %7, align 8
  %9 = bitcast %class.sk_sp* %3 to i64*
  store i64 %6, i64* %9, align 8
  %10 = icmp eq %class.GrCaps* %8, null
  br i1 %10, label %21, label %11

11:                                               ; preds = %2
  %12 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %8, i64 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
  %13 = atomicrmw add i32* %12, i32 -1 acq_rel
  %14 = icmp eq i32 %13, 1
  br i1 %14, label %15, label %21

15:                                               ; preds = %11
  %16 = bitcast %class.GrCaps* %8 to %class.SkRefCntBase*
  %17 = bitcast %class.GrCaps* %8 to void (%class.SkRefCntBase*)***
  %18 = load void (%class.SkRefCntBase*)**, void (%class.SkRefCntBase*)*** %17, align 8
  %19 = getelementptr inbounds void (%class.SkRefCntBase*)*, void (%class.SkRefCntBase*)** %18, i64 2
  %20 = load void (%class.SkRefCntBase*)*, void (%class.SkRefCntBase*)** %19, align 8
  tail call void %20(%class.SkRefCntBase* nonnull %16) #14
  br label %21

21:                                               ; preds = %2, %11, %15
  %22 = load %class.GrCaps*, %class.GrCaps** %7, align 8
  %23 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %22, i64 0, i32 2, i32 0
  %24 = load %class.GrShaderCaps*, %class.GrShaderCaps** %23, align 8
  %25 = tail call i8* @_Znwm(i64 504) #16
  %26 = bitcast i8* %25 to %"class.SkSL::Compiler"*
  tail call void @_ZN4SkSL8CompilerC1EPK12GrShaderCaps(%"class.SkSL::Compiler"* nonnull %26, %class.GrShaderCaps* %24) #14
  %27 = ptrtoint i8* %25 to i64
  %28 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 3
  %29 = getelementptr inbounds %"class.std::__1::unique_ptr", %"class.std::__1::unique_ptr"* %28, i64 0, i32 0, i32 0, i32 0
  %30 = load %"class.SkSL::Compiler"*, %"class.SkSL::Compiler"** %29, align 8
  %31 = bitcast %"class.std::__1::unique_ptr"* %28 to i64*
  store i64 %27, i64* %31, align 8
  %32 = icmp eq %"class.SkSL::Compiler"* %30, null
  br i1 %32, label %38, label %33

33:                                               ; preds = %21
  %34 = bitcast %"class.SkSL::Compiler"* %30 to void (%"class.SkSL::Compiler"*)***
  %35 = load void (%"class.SkSL::Compiler"*)**, void (%"class.SkSL::Compiler"*)*** %34, align 8
  %36 = getelementptr inbounds void (%"class.SkSL::Compiler"*)*, void (%"class.SkSL::Compiler"*)** %35, i64 1
  %37 = load void (%"class.SkSL::Compiler"*)*, void (%"class.SkSL::Compiler"*)** %36, align 8
  tail call void %37(%"class.SkSL::Compiler"* nonnull %30) #14
  br label %38

38:                                               ; preds = %33, %21
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #4

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #4

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void @_ZN5GrGpu10disconnectENS_14DisconnectTypeE(%class.GrGpu* nocapture, i32) unnamed_addr #5 align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu19createTextureCommonE7SkISizeRK15GrBackendFormat12GrRenderablei10SkBudgeted11GrProtectedij(%class.sk_sp.226* noalias nocapture sret, %class.GrGpu*, i64, %class.GrBackendFormat* dereferenceable(72), i1 zeroext, i32, i1 zeroext, i1 zeroext, i32, i32) local_unnamed_addr #1 align 2 {
  %11 = alloca i64, align 8
  %12 = alloca %class.sk_sp.226, align 8
  store i64 %2, i64* %11, align 8
  %13 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 2, i32 0
  %14 = load %class.GrCaps*, %class.GrCaps** %13, align 8
  %15 = tail call zeroext i1 @_ZNK6GrCaps18isFormatCompressedERK15GrBackendFormat(%class.GrCaps* %14, %class.GrBackendFormat* dereferenceable(72) %3) #14
  br i1 %15, label %16, label %18

16:                                               ; preds = %10
  %17 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %17, align 8
  br label %109

18:                                               ; preds = %10
  %19 = bitcast i64* %11 to %struct.SkISize*
  %20 = icmp sgt i32 %8, 1
  %21 = load %class.GrCaps*, %class.GrCaps** %13, align 8
  %22 = call zeroext i1 @_ZNK6GrCaps21validateSurfaceParamsERK7SkISizeRK15GrBackendFormat12GrRenderablei11GrMipmapped(%class.GrCaps* %21, %struct.SkISize* nonnull dereferenceable(8) %19, %class.GrBackendFormat* dereferenceable(72) %3, i1 zeroext %4, i32 %5, i1 zeroext %20) #14
  br i1 %22, label %25, label %23

23:                                               ; preds = %18
  %24 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %24, align 8
  br label %109

25:                                               ; preds = %18
  br i1 %4, label %26, label %33

26:                                               ; preds = %25
  %27 = load %class.GrCaps*, %class.GrCaps** %13, align 8
  %28 = bitcast %class.GrCaps* %27 to i32 (%class.GrCaps*, i32, %class.GrBackendFormat*)***
  %29 = load i32 (%class.GrCaps*, i32, %class.GrBackendFormat*)**, i32 (%class.GrCaps*, i32, %class.GrBackendFormat*)*** %28, align 8
  %30 = getelementptr inbounds i32 (%class.GrCaps*, i32, %class.GrBackendFormat*)*, i32 (%class.GrCaps*, i32, %class.GrBackendFormat*)** %29, i64 9
  %31 = load i32 (%class.GrCaps*, i32, %class.GrBackendFormat*)*, i32 (%class.GrCaps*, i32, %class.GrBackendFormat*)** %30, align 8
  %32 = call i32 %31(%class.GrCaps* %27, i32 %5, %class.GrBackendFormat* dereferenceable(72) %3) #14
  br label %33

33:                                               ; preds = %26, %25
  %34 = phi i32 [ %32, %26 ], [ %5, %25 ]
  %35 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 4
  %36 = load i32, i32* %35, align 8
  %37 = icmp eq i32 %36, 0
  br i1 %37, label %43, label %38

38:                                               ; preds = %33
  %39 = bitcast %class.GrGpu* %1 to void (%class.GrGpu*, i32)***
  %40 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %39, align 8
  %41 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %40, i64 38
  %42 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %41, align 8
  call void %42(%class.GrGpu* %1, i32 %36) #14
  store i32 0, i32* %35, align 8
  br label %43

43:                                               ; preds = %33, %38
  %44 = bitcast %class.sk_sp.226* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %44) #14
  %45 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %12, i64 0, i32 0
  store %class.GrTexture* inttoptr (i64 -6148914691236517206 to %class.GrTexture*), %class.GrTexture** %45, align 8
  %46 = load i64, i64* %11, align 8
  %47 = bitcast %class.GrGpu* %1 to void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i32, i1, i1, i32, i32)***
  %48 = load void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i32, i1, i1, i32, i32)**, void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i32, i1, i1, i32, i32)*** %47, align 8
  %49 = getelementptr inbounds void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i32, i1, i1, i32, i32)*, void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i32, i1, i1, i32, i32)** %48, i64 40
  %50 = load void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i32, i1, i1, i32, i32)*, void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i32, i1, i1, i32, i32)** %49, align 8
  call void %50(%class.sk_sp.226* nonnull sret %12, %class.GrGpu* %1, i64 %46, %class.GrBackendFormat* dereferenceable(72) %3, i1 zeroext %4, i32 %34, i1 zeroext %6, i1 zeroext %7, i32 %8, i32 %9) #14
  %51 = load %class.GrTexture*, %class.GrTexture** %45, align 8
  %52 = icmp eq %class.GrTexture* %51, null
  br i1 %52, label %105, label %53

53:                                               ; preds = %43
  %54 = load %class.GrCaps*, %class.GrCaps** %13, align 8
  %55 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %54, i64 0, i32 3
  %56 = bitcast i48* %55 to i64*
  %57 = load i64, i64* %56, align 8
  %58 = and i64 %57, 4
  %59 = icmp ne i64 %58, 0
  %60 = or i1 %59, %4
  br i1 %60, label %70, label %61

61:                                               ; preds = %53
  %62 = bitcast %class.GrTexture* %51 to i8**
  %63 = load i8*, i8** %62, align 8
  %64 = getelementptr i8, i8* %63, i64 -24
  %65 = bitcast i8* %64 to i64*
  %66 = load i64, i64* %65, align 8
  %67 = bitcast %class.GrTexture* %51 to i8*
  %68 = getelementptr inbounds i8, i8* %67, i64 %66
  %69 = bitcast i8* %68 to %class.GrGpuResource*
  call void @_ZN13GrGpuResource16removeScratchKeyEv(%class.GrGpuResource* %69) #14
  br label %70

70:                                               ; preds = %53, %61
  %71 = icmp sgt i32 %34, 1
  br i1 %71, label %72, label %105

72:                                               ; preds = %70
  %73 = load %class.GrCaps*, %class.GrCaps** %13, align 8
  %74 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %73, i64 0, i32 3
  %75 = bitcast i48* %74 to i64*
  %76 = load i64, i64* %75, align 8
  %77 = and i64 %76, 16384
  %78 = icmp eq i64 %77, 0
  br i1 %78, label %79, label %105

79:                                               ; preds = %72
  %80 = load %class.GrTexture*, %class.GrTexture** %45, align 8
  %81 = bitcast %class.GrTexture* %80 to i8**
  %82 = load i8*, i8** %81, align 8
  %83 = getelementptr i8, i8* %82, i64 -24
  %84 = bitcast i8* %83 to i64*
  %85 = load i64, i64* %84, align 8
  %86 = bitcast %class.GrTexture* %80 to i8*
  %87 = getelementptr inbounds i8, i8* %86, i64 %85
  %88 = bitcast i8* %87 to %class.GrSurface*
  %89 = bitcast i8* %87 to %class.GrRenderTarget* (%class.GrSurface*)***
  %90 = load %class.GrRenderTarget* (%class.GrSurface*)**, %class.GrRenderTarget* (%class.GrSurface*)*** %89, align 8
  %91 = getelementptr inbounds %class.GrRenderTarget* (%class.GrSurface*)*, %class.GrRenderTarget* (%class.GrSurface*)** %90, i64 12
  %92 = load %class.GrRenderTarget* (%class.GrSurface*)*, %class.GrRenderTarget* (%class.GrSurface*)** %91, align 8
  %93 = call %class.GrRenderTarget* %92(%class.GrSurface* %88) #14
  %94 = bitcast %class.GrRenderTarget* %93 to i8**
  %95 = load i8*, i8** %94, align 8
  %96 = getelementptr i8, i8* %95, i64 -24
  %97 = bitcast i8* %96 to i64*
  %98 = load i64, i64* %97, align 8
  %99 = bitcast %class.GrRenderTarget* %93 to i8*
  %100 = getelementptr inbounds i8, i8* %99, i64 %98
  %101 = getelementptr inbounds i8, i8* %100, i64 160
  %102 = bitcast i8* %101 to i32*
  %103 = load i32, i32* %102, align 4
  %104 = or i32 %103, 4
  store i32 %104, i32* %102, align 4
  br label %105

105:                                              ; preds = %72, %43, %79, %70
  %106 = bitcast %class.sk_sp.226* %12 to i64*
  %107 = load i64, i64* %106, align 8
  %108 = bitcast %class.sk_sp.226* %0 to i64*
  store i64 %107, i64* %108, align 8
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %44) #14
  br label %109

109:                                              ; preds = %23, %105, %16
  ret void
}

declare zeroext i1 @_ZNK6GrCaps18isFormatCompressedERK15GrBackendFormat(%class.GrCaps*, %class.GrBackendFormat* dereferenceable(72)) local_unnamed_addr #6

declare zeroext i1 @_ZNK6GrCaps21validateSurfaceParamsERK7SkISizeRK15GrBackendFormat12GrRenderablei11GrMipmapped(%class.GrCaps*, %struct.SkISize* dereferenceable(8), %class.GrBackendFormat* dereferenceable(72), i1 zeroext, i32, i1 zeroext) local_unnamed_addr #6

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #4

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu13createTextureE7SkISizeRK15GrBackendFormat12GrRenderablei11GrMipmapped10SkBudgeted11GrProtected(%class.sk_sp.226* noalias nocapture sret, %class.GrGpu*, i64, %class.GrBackendFormat* dereferenceable(72), i1 zeroext, i32, i1 zeroext, i1 zeroext, i1 zeroext) local_unnamed_addr #1 align 2 {
  %10 = trunc i64 %2 to i32
  %11 = lshr i64 %2, 32
  %12 = trunc i64 %11 to i32
  br i1 %6, label %13, label %18

13:                                               ; preds = %9
  %14 = icmp slt i32 %10, %12
  %15 = select i1 %14, i32 %12, i32 %10
  %16 = tail call i32 @llvm.ctlz.i32(i32 %15, i1 false) #14, !range !2
  %17 = sub nuw nsw i32 32, %16
  br label %18

18:                                               ; preds = %13, %9
  %19 = phi i32 [ %17, %13 ], [ 1, %9 ]
  %20 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 2, i32 0
  %21 = load %class.GrCaps*, %class.GrCaps** %20, align 8
  %22 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %21, i64 0, i32 3
  %23 = bitcast i48* %22 to i64*
  %24 = load i64, i64* %23, align 8
  %25 = and i64 %24, 1048576
  %26 = icmp eq i64 %25, 0
  %27 = shl nsw i32 -1, %19
  %28 = xor i32 %27, -1
  %29 = select i1 %26, i32 0, i32 %28
  %30 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* inttoptr (i64 -6148914691236517206 to %class.GrTexture*), %class.GrTexture** %30, align 8
  tail call void @_ZN5GrGpu19createTextureCommonE7SkISizeRK15GrBackendFormat12GrRenderablei10SkBudgeted11GrProtectedij(%class.sk_sp.226* sret %0, %class.GrGpu* %1, i64 %2, %class.GrBackendFormat* dereferenceable(72) %3, i1 zeroext %4, i32 %5, i1 zeroext %7, i1 zeroext %8, i32 %19, i32 %29)
  %31 = load %class.GrTexture*, %class.GrTexture** %30, align 8
  %32 = icmp ne %class.GrTexture* %31, null
  %33 = icmp ne i32 %29, 0
  %34 = and i1 %33, %6
  %35 = and i1 %32, %34
  br i1 %35, label %36, label %37

36:                                               ; preds = %18
  tail call void @_ZN9GrTexture16markMipmapsCleanEv(%class.GrTexture* nonnull %31) #14
  br label %37

37:                                               ; preds = %18, %36
  ret void
}

declare void @_ZN9GrTexture16markMipmapsCleanEv(%class.GrTexture*) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu13createTextureE7SkISizeRK15GrBackendFormat12GrRenderablei10SkBudgeted11GrProtected11GrColorTypeS7_PK10GrMipLeveli(%class.sk_sp.226* noalias nocapture sret, %class.GrGpu*, i64, %class.GrBackendFormat* dereferenceable(72), i1 zeroext, i32, i1 zeroext, i1 zeroext, i32, i32, %struct.GrMipLevel*, i32) local_unnamed_addr #1 align 2 {
  %13 = alloca %"class.skia::tracing_internals::ScopedTracer", align 8
  %14 = alloca %class.sk_sp.226, align 8
  %15 = load atomic i64, i64* @_ZZN5GrGpu13createTextureE7SkISizeRK15GrBackendFormat12GrRenderablei10SkBudgeted11GrProtected11GrColorTypeS7_PK10GrMipLeveliE28trace_event_unique_atomic181.0.0 monotonic, align 8
  %16 = inttoptr i64 %15 to i8*
  %17 = icmp eq i64 %15, 0
  br i1 %17, label %18, label %26

18:                                               ; preds = %12
  %19 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %20 = bitcast %class.SkEventTracer* %19 to i8* (%class.SkEventTracer*, i8*)***
  %21 = load i8* (%class.SkEventTracer*, i8*)**, i8* (%class.SkEventTracer*, i8*)*** %20, align 8
  %22 = getelementptr inbounds i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %21, i64 2
  %23 = load i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %22, align 8
  %24 = tail call i8* %23(%class.SkEventTracer* %19, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str, i64 0, i64 0)) #14
  %25 = ptrtoint i8* %24 to i64
  store atomic i64 %25, i64* @_ZZN5GrGpu13createTextureE7SkISizeRK15GrBackendFormat12GrRenderablei10SkBudgeted11GrProtected11GrColorTypeS7_PK10GrMipLeveliE28trace_event_unique_atomic181.0.0 monotonic, align 8
  br label %26

26:                                               ; preds = %12, %18
  %27 = phi i8* [ %16, %12 ], [ %24, %18 ]
  %28 = bitcast %"class.skia::tracing_internals::ScopedTracer"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %28) #14
  %29 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %13, i64 0, i32 0
  %30 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %13, i64 0, i32 1, i32 0
  %31 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %13, i64 0, i32 1, i32 1
  %32 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %13, i64 0, i32 1, i32 2
  %33 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %13, i64 0, i32 1
  %34 = bitcast %"struct.skia::tracing_internals::ScopedTracer::Data"* %33 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* null, %"struct.skia::tracing_internals::ScopedTracer::Data"** %29, align 8
  %35 = load i8, i8* %27, align 1
  %36 = and i8 %35, 5
  %37 = icmp eq i8 %36, 0
  br i1 %37, label %47, label %38

38:                                               ; preds = %26
  %39 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %40 = bitcast %class.SkEventTracer* %39 to i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)***
  %41 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)**, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*** %40, align 8
  %42 = getelementptr inbounds i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %41, i64 4
  %43 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %42, align 8
  %44 = tail call i64 %43(%class.SkEventTracer* %39, i8 signext 88, i8* %27, i8* getelementptr inbounds ([167 x i8], [167 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu13createTextureE7SkISizeRK15GrBackendFormat12GrRenderablei10SkBudgeted11GrProtected11GrColorTypeS7_PK10GrMipLeveli, i64 0, i64 0), i64 0, i32 0, i8** null, i8* null, i64* null, i8 zeroext 0) #14
  %45 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %13, i64 0, i32 1
  %46 = getelementptr inbounds %"struct.skia::tracing_internals::ScopedTracer::Data", %"struct.skia::tracing_internals::ScopedTracer::Data"* %45, i64 0, i32 0
  store i8* %27, i8** %46, align 8
  store i8* getelementptr inbounds ([167 x i8], [167 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu13createTextureE7SkISizeRK15GrBackendFormat12GrRenderablei10SkBudgeted11GrProtected11GrColorTypeS7_PK10GrMipLeveli, i64 0, i64 0), i8** %31, align 8
  store i64 %44, i64* %32, align 8
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* %45, %"struct.skia::tracing_internals::ScopedTracer::Data"** %29, align 8
  br label %47

47:                                               ; preds = %26, %38
  %48 = icmp eq i32 %11, 0
  br i1 %48, label %55, label %49

49:                                               ; preds = %47
  %50 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 2, i32 0
  %51 = load %class.GrCaps*, %class.GrCaps** %50, align 8
  %52 = call fastcc zeroext i1 @_ZL21validate_texel_levels7SkISize11GrColorTypePK10GrMipLeveliPK6GrCaps(i64 %2, i32 %9, %struct.GrMipLevel* %10, i32 %11, %class.GrCaps* %51)
  br i1 %52, label %55, label %53

53:                                               ; preds = %49
  %54 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %54, align 8
  br label %193

55:                                               ; preds = %47, %49
  %56 = icmp sgt i32 %11, 1
  %57 = select i1 %56, i32 %11, i32 1
  %58 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 2, i32 0
  %59 = load %class.GrCaps*, %class.GrCaps** %58, align 8
  %60 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %59, i64 0, i32 3
  %61 = bitcast i48* %60 to i64*
  %62 = load i64, i64* %61, align 8
  %63 = and i64 %62, 1048576
  %64 = icmp eq i64 %63, 0
  br i1 %64, label %142, label %65

65:                                               ; preds = %55
  br i1 %48, label %139, label %66

66:                                               ; preds = %65
  %67 = getelementptr inbounds %struct.GrMipLevel, %struct.GrMipLevel* %10, i64 0, i32 0
  %68 = load i8*, i8** %67, align 8
  %69 = icmp eq i8* %68, null
  %70 = icmp ult i32 %57, 8
  br i1 %70, label %128, label %71

71:                                               ; preds = %66
  %72 = and i32 %57, 2147483640
  %73 = add nsw i32 %72, -8
  %74 = lshr exact i32 %73, 3
  %75 = add nuw nsw i32 %74, 1
  %76 = and i32 %75, 1
  %77 = icmp eq i32 %73, 0
  br i1 %77, label %103, label %78

78:                                               ; preds = %71
  %79 = sub nuw nsw i32 %75, %76
  br label %80

80:                                               ; preds = %80, %78
  %81 = phi <4 x i32> [ <i32 0, i32 1, i32 2, i32 3>, %78 ], [ %100, %80 ]
  %82 = phi <4 x i32> [ zeroinitializer, %78 ], [ %98, %80 ]
  %83 = phi <4 x i32> [ zeroinitializer, %78 ], [ %99, %80 ]
  %84 = phi i32 [ %79, %78 ], [ %101, %80 ]
  %85 = add <4 x i32> %81, <i32 4, i32 4, i32 4, i32 4>
  %86 = shl <4 x i32> <i32 1, i32 1, i32 1, i32 1>, %81
  %87 = shl <4 x i32> <i32 1, i32 1, i32 1, i32 1>, %85
  %88 = select i1 %69, <4 x i32> %86, <4 x i32> zeroinitializer
  %89 = select i1 %69, <4 x i32> %87, <4 x i32> zeroinitializer
  %90 = or <4 x i32> %88, %82
  %91 = or <4 x i32> %89, %83
  %92 = add <4 x i32> %81, <i32 8, i32 8, i32 8, i32 8>
  %93 = add <4 x i32> %81, <i32 12, i32 12, i32 12, i32 12>
  %94 = shl <4 x i32> <i32 1, i32 1, i32 1, i32 1>, %92
  %95 = shl <4 x i32> <i32 1, i32 1, i32 1, i32 1>, %93
  %96 = select i1 %69, <4 x i32> %94, <4 x i32> zeroinitializer
  %97 = select i1 %69, <4 x i32> %95, <4 x i32> zeroinitializer
  %98 = or <4 x i32> %96, %90
  %99 = or <4 x i32> %97, %91
  %100 = add <4 x i32> %81, <i32 16, i32 16, i32 16, i32 16>
  %101 = add i32 %84, -2
  %102 = icmp eq i32 %101, 0
  br i1 %102, label %103, label %80, !llvm.loop !3

103:                                              ; preds = %80, %71
  %104 = phi <4 x i32> [ undef, %71 ], [ %98, %80 ]
  %105 = phi <4 x i32> [ undef, %71 ], [ %99, %80 ]
  %106 = phi <4 x i32> [ <i32 0, i32 1, i32 2, i32 3>, %71 ], [ %100, %80 ]
  %107 = phi <4 x i32> [ zeroinitializer, %71 ], [ %98, %80 ]
  %108 = phi <4 x i32> [ zeroinitializer, %71 ], [ %99, %80 ]
  %109 = icmp eq i32 %76, 0
  br i1 %109, label %118, label %110

110:                                              ; preds = %103
  %111 = add <4 x i32> %106, <i32 4, i32 4, i32 4, i32 4>
  %112 = shl <4 x i32> <i32 1, i32 1, i32 1, i32 1>, %111
  %113 = select i1 %69, <4 x i32> %112, <4 x i32> zeroinitializer
  %114 = or <4 x i32> %113, %108
  %115 = shl <4 x i32> <i32 1, i32 1, i32 1, i32 1>, %106
  %116 = select i1 %69, <4 x i32> %115, <4 x i32> zeroinitializer
  %117 = or <4 x i32> %116, %107
  br label %118

118:                                              ; preds = %103, %110
  %119 = phi <4 x i32> [ %104, %103 ], [ %117, %110 ]
  %120 = phi <4 x i32> [ %105, %103 ], [ %114, %110 ]
  %121 = or <4 x i32> %120, %119
  %122 = shufflevector <4 x i32> %121, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %123 = or <4 x i32> %121, %122
  %124 = shufflevector <4 x i32> %123, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %125 = or <4 x i32> %123, %124
  %126 = extractelement <4 x i32> %125, i32 0
  %127 = icmp eq i32 %57, %72
  br i1 %127, label %142, label %128

128:                                              ; preds = %118, %66
  %129 = phi i32 [ 0, %66 ], [ %72, %118 ]
  %130 = phi i32 [ 0, %66 ], [ %126, %118 ]
  br label %131

131:                                              ; preds = %128, %131
  %132 = phi i32 [ %137, %131 ], [ %129, %128 ]
  %133 = phi i32 [ %136, %131 ], [ %130, %128 ]
  %134 = shl i32 1, %132
  %135 = select i1 %69, i32 %134, i32 0
  %136 = or i32 %135, %133
  %137 = add nuw nsw i32 %132, 1
  %138 = icmp ult i32 %137, %57
  br i1 %138, label %131, label %142, !llvm.loop !5

139:                                              ; preds = %65
  %140 = shl nsw i32 -1, %57
  %141 = xor i32 %140, -1
  br label %142

142:                                              ; preds = %131, %118, %55, %139
  %143 = phi i32 [ %141, %139 ], [ 0, %55 ], [ %126, %118 ], [ %136, %131 ]
  %144 = bitcast %class.sk_sp.226* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %144) #14
  %145 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %14, i64 0, i32 0
  store %class.GrTexture* inttoptr (i64 -6148914691236517206 to %class.GrTexture*), %class.GrTexture** %145, align 8
  call void @_ZN5GrGpu19createTextureCommonE7SkISizeRK15GrBackendFormat12GrRenderablei10SkBudgeted11GrProtectedij(%class.sk_sp.226* nonnull sret %14, %class.GrGpu* %1, i64 %2, %class.GrBackendFormat* dereferenceable(72) %3, i1 zeroext %4, i32 %5, i1 zeroext %6, i1 zeroext %7, i32 %11, i32 %143)
  %146 = load %class.GrTexture*, %class.GrTexture** %145, align 8
  %147 = icmp eq %class.GrTexture* %146, null
  %148 = ptrtoint %class.GrTexture* %146 to i64
  br i1 %147, label %176, label %149

149:                                              ; preds = %142
  br i1 %48, label %168, label %150

150:                                              ; preds = %149
  %151 = getelementptr inbounds %struct.GrMipLevel, %struct.GrMipLevel* %10, i64 0, i32 0
  %152 = load i8*, i8** %151, align 8
  %153 = icmp eq i8* %152, null
  br i1 %153, label %168, label %154

154:                                              ; preds = %150
  %155 = bitcast %class.GrTexture* %146 to i8**
  %156 = load i8*, i8** %155, align 8
  %157 = getelementptr i8, i8* %156, i64 -24
  %158 = bitcast i8* %157 to i64*
  %159 = load i64, i64* %158, align 8
  %160 = bitcast %class.GrTexture* %146 to i8*
  %161 = getelementptr inbounds i8, i8* %160, i64 %159
  %162 = bitcast i8* %161 to %class.GrSurface*
  %163 = call zeroext i1 @_ZN5GrGpu11writePixelsEP9GrSurface7SkIRect11GrColorTypeS3_PK10GrMipLevelib(%class.GrGpu* %1, %class.GrSurface* %162, i64 0, i64 %2, i32 %8, i32 %9, %struct.GrMipLevel* %10, i32 %11, i1 zeroext false)
  br i1 %163, label %164, label %178

164:                                              ; preds = %154
  %165 = icmp slt i32 %11, 2
  %166 = icmp ne i32 %143, 0
  %167 = or i1 %165, %166
  br i1 %167, label %176, label %171

168:                                              ; preds = %150, %149
  %169 = icmp ne i32 %143, 0
  %170 = and i1 %56, %169
  br i1 %170, label %175, label %176

171:                                              ; preds = %164
  %172 = getelementptr inbounds %struct.GrMipLevel, %struct.GrMipLevel* %10, i64 1, i32 0
  %173 = load i8*, i8** %172, align 8
  %174 = icmp eq i8* %173, null
  br i1 %174, label %176, label %175

175:                                              ; preds = %171, %168
  call void @_ZN9GrTexture16markMipmapsCleanEv(%class.GrTexture* nonnull %146) #14
  br label %176

176:                                              ; preds = %171, %142, %175, %168, %164
  store %class.GrTexture* null, %class.GrTexture** %145, align 8
  %177 = bitcast %class.sk_sp.226* %0 to i64*
  store i64 %148, i64* %177, align 8
  br label %192

178:                                              ; preds = %154
  %179 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %179, align 8
  %180 = load i8*, i8** %155, align 8
  %181 = getelementptr i8, i8* %180, i64 -24
  %182 = bitcast i8* %181 to i64*
  %183 = load i64, i64* %182, align 8
  %184 = add i64 %183, 8
  %185 = getelementptr inbounds i8, i8* %160, i64 %184
  %186 = bitcast i8* %185 to i32*
  %187 = atomicrmw add i32* %186, i32 -1 acq_rel
  %188 = icmp eq i32 %187, 1
  br i1 %188, label %189, label %192

189:                                              ; preds = %178
  %190 = getelementptr inbounds i8, i8* %160, i64 %183
  %191 = bitcast i8* %190 to %class.GrGpuResource*
  call void @_ZNK13GrGpuResource19notifyARefCntIsZeroEN7GrIORefIS_E14LastRemovedRefE(%class.GrGpuResource* %191, i32 0) #14
  br label %192

192:                                              ; preds = %176, %178, %189
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %144) #14
  br label %193

193:                                              ; preds = %192, %53
  %194 = load %"struct.skia::tracing_internals::ScopedTracer::Data"*, %"struct.skia::tracing_internals::ScopedTracer::Data"** %29, align 8
  %195 = icmp eq %"struct.skia::tracing_internals::ScopedTracer::Data"* %194, null
  br i1 %195, label %209, label %196

196:                                              ; preds = %193
  %197 = load i8*, i8** %30, align 8
  %198 = load i8, i8* %197, align 1
  %199 = icmp eq i8 %198, 0
  br i1 %199, label %209, label %200

200:                                              ; preds = %196
  %201 = call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %202 = load i8*, i8** %30, align 8
  %203 = load i8*, i8** %31, align 8
  %204 = load i64, i64* %32, align 8
  %205 = bitcast %class.SkEventTracer* %201 to void (%class.SkEventTracer*, i8*, i8*, i64)***
  %206 = load void (%class.SkEventTracer*, i8*, i8*, i64)**, void (%class.SkEventTracer*, i8*, i8*, i64)*** %205, align 8
  %207 = getelementptr inbounds void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %206, i64 5
  %208 = load void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %207, align 8
  call void %208(%class.SkEventTracer* %201, i8* %202, i8* %203, i64 %204) #14
  br label %209

209:                                              ; preds = %193, %196, %200
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %28) #14
  ret void
}

declare %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define internal fastcc zeroext i1 @_ZL21validate_texel_levels7SkISize11GrColorTypePK10GrMipLeveliPK6GrCaps(i64, i32, %struct.GrMipLevel* nocapture readonly, i32, %class.GrCaps* nocapture readonly) unnamed_addr #1 {
  %6 = trunc i64 %0 to i32
  %7 = lshr i64 %0, 32
  %8 = trunc i64 %7 to i32
  %9 = getelementptr inbounds %struct.GrMipLevel, %struct.GrMipLevel* %2, i64 0, i32 0
  %10 = load i8*, i8** %9, align 8
  %11 = icmp eq i8* %10, null
  %12 = icmp ult i32 %1, 31
  br i1 %12, label %14, label %13

13:                                               ; preds = %5
  tail call void @llvm.trap() #14
  unreachable

14:                                               ; preds = %5
  %15 = sext i32 %1 to i64
  %16 = getelementptr inbounds [31 x i64], [31 x i64]* @switch.table._ZN5GrGpu16transferPixelsToEP9GrTexture7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmm, i64 0, i64 %15
  %17 = load i64, i64* %16, align 8
  %18 = icmp sgt i32 %3, 0
  br i1 %18, label %19, label %73

19:                                               ; preds = %14
  %20 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %4, i64 0, i32 3
  %21 = bitcast i48* %20 to i64*
  %22 = add nsw i32 %3, -1
  %23 = zext i32 %22 to i64
  %24 = zext i32 %3 to i64
  br label %25

25:                                               ; preds = %68, %19
  %26 = phi i8* [ %10, %19 ], [ %70, %68 ]
  %27 = phi i64 [ 0, %19 ], [ %66, %68 ]
  %28 = phi i32 [ %8, %19 ], [ %65, %68 ]
  %29 = phi i32 [ %6, %19 ], [ %64, %68 ]
  %30 = phi i32 [ 0, %19 ], [ %50, %68 ]
  %31 = icmp eq i8* %26, null
  br i1 %31, label %49, label %32

32:                                               ; preds = %25
  %33 = sext i32 %29 to i64
  %34 = mul nsw i64 %17, %33
  %35 = load i64, i64* %21, align 8
  %36 = and i64 %35, 1073741824
  %37 = icmp eq i64 %36, 0
  %38 = getelementptr inbounds %struct.GrMipLevel, %struct.GrMipLevel* %2, i64 %27, i32 1
  %39 = load i64, i64* %38, align 8
  br i1 %37, label %45, label %40

40:                                               ; preds = %32
  %41 = icmp ult i64 %39, %34
  br i1 %41, label %88, label %42

42:                                               ; preds = %40
  %43 = urem i64 %39, %17
  %44 = icmp eq i64 %43, 0
  br i1 %44, label %47, label %88

45:                                               ; preds = %32
  %46 = icmp eq i64 %39, %34
  br i1 %46, label %47, label %88

47:                                               ; preds = %45, %42
  %48 = add nsw i32 %30, 1
  br label %49

49:                                               ; preds = %47, %25
  %50 = phi i32 [ %48, %47 ], [ %30, %25 ]
  %51 = icmp eq i32 %29, 1
  %52 = icmp eq i32 %28, 1
  %53 = and i1 %51, %52
  br i1 %53, label %54, label %56

54:                                               ; preds = %49
  %55 = icmp eq i64 %27, %23
  br i1 %55, label %63, label %88

56:                                               ; preds = %49
  %57 = sdiv i32 %29, 2
  %58 = icmp sgt i32 %57, 1
  %59 = select i1 %58, i32 %57, i32 1
  %60 = sdiv i32 %28, 2
  %61 = icmp sgt i32 %60, 1
  %62 = select i1 %61, i32 %60, i32 1
  br label %63

63:                                               ; preds = %54, %56
  %64 = phi i32 [ 1, %54 ], [ %59, %56 ]
  %65 = phi i32 [ 1, %54 ], [ %62, %56 ]
  %66 = add nuw nsw i64 %27, 1
  %67 = icmp eq i64 %66, %24
  br i1 %67, label %71, label %68

68:                                               ; preds = %63
  %69 = getelementptr inbounds %struct.GrMipLevel, %struct.GrMipLevel* %2, i64 %66, i32 0
  %70 = load i8*, i8** %69, align 8
  br label %25

71:                                               ; preds = %63
  %72 = icmp eq i32 %3, 1
  br i1 %72, label %80, label %73

73:                                               ; preds = %14, %71
  %74 = phi i32 [ %65, %71 ], [ %8, %14 ]
  %75 = phi i32 [ %64, %71 ], [ %6, %14 ]
  %76 = phi i32 [ %50, %71 ], [ 0, %14 ]
  %77 = icmp ne i32 %75, 1
  %78 = icmp ne i32 %74, 1
  %79 = or i1 %77, %78
  br i1 %79, label %88, label %80

80:                                               ; preds = %71, %73
  %81 = phi i32 [ %50, %71 ], [ %76, %73 ]
  br i1 %11, label %82, label %84

82:                                               ; preds = %80
  %83 = icmp eq i32 %81, 0
  br label %88

84:                                               ; preds = %80
  %85 = icmp eq i32 %81, 1
  %86 = icmp eq i32 %81, %3
  %87 = or i1 %85, %86
  br label %88

88:                                               ; preds = %45, %42, %40, %54, %73, %84, %82
  %89 = phi i1 [ %87, %84 ], [ %83, %82 ], [ false, %73 ], [ false, %54 ], [ false, %40 ], [ false, %42 ], [ false, %45 ]
  ret i1 %89
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN5GrGpu11writePixelsEP9GrSurface7SkIRect11GrColorTypeS3_PK10GrMipLevelib(%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %struct.GrMipLevel*, i32, i1 zeroext) local_unnamed_addr #1 align 2 {
  %10 = alloca { i64, i64 }, align 8
  %11 = alloca %"class.skia::tracing_internals::ScopedTracer", align 8
  %12 = alloca { i64, i64 }, align 8
  %13 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %10, i64 0, i32 0
  store i64 %2, i64* %13, align 8
  %14 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %10, i64 0, i32 1
  store i64 %3, i64* %14, align 8
  %15 = load atomic i64, i64* @_ZZN5GrGpu11writePixelsEP9GrSurface7SkIRect11GrColorTypeS3_PK10GrMipLevelibE28trace_event_unique_atomic427.0.0 monotonic, align 8
  %16 = inttoptr i64 %15 to i8*
  %17 = icmp eq i64 %15, 0
  %18 = trunc i64 %3 to i32
  %19 = lshr i64 %3, 32
  %20 = trunc i64 %19 to i32
  %21 = lshr i64 %2, 32
  br i1 %17, label %22, label %30

22:                                               ; preds = %9
  %23 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %24 = bitcast %class.SkEventTracer* %23 to i8* (%class.SkEventTracer*, i8*)***
  %25 = load i8* (%class.SkEventTracer*, i8*)**, i8* (%class.SkEventTracer*, i8*)*** %24, align 8
  %26 = getelementptr inbounds i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %25, i64 2
  %27 = load i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %26, align 8
  %28 = tail call i8* %27(%class.SkEventTracer* %23, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str, i64 0, i64 0)) #14
  %29 = ptrtoint i8* %28 to i64
  store atomic i64 %29, i64* @_ZZN5GrGpu11writePixelsEP9GrSurface7SkIRect11GrColorTypeS3_PK10GrMipLevelibE28trace_event_unique_atomic427.0.0 monotonic, align 8
  br label %30

30:                                               ; preds = %9, %22
  %31 = phi i8* [ %16, %9 ], [ %28, %22 ]
  %32 = bitcast %"class.skia::tracing_internals::ScopedTracer"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %32) #14
  %33 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %11, i64 0, i32 0
  %34 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %11, i64 0, i32 1, i32 0
  %35 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %11, i64 0, i32 1, i32 1
  %36 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %11, i64 0, i32 1, i32 2
  %37 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %11, i64 0, i32 1
  %38 = bitcast %"struct.skia::tracing_internals::ScopedTracer::Data"* %37 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %38, i8 -86, i64 24, i1 false)
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* null, %"struct.skia::tracing_internals::ScopedTracer::Data"** %33, align 8
  %39 = load i8, i8* %31, align 1
  %40 = and i8 %39, 5
  %41 = icmp eq i8 %40, 0
  br i1 %41, label %51, label %42

42:                                               ; preds = %30
  %43 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %44 = bitcast %class.SkEventTracer* %43 to i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)***
  %45 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)**, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*** %44, align 8
  %46 = getelementptr inbounds i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %45, i64 4
  %47 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %46, align 8
  %48 = tail call i64 %47(%class.SkEventTracer* %43, i8 signext 88, i8* %31, i8* getelementptr inbounds ([103 x i8], [103 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu11writePixelsEP9GrSurface7SkIRect11GrColorTypeS3_PK10GrMipLevelib, i64 0, i64 0), i64 0, i32 0, i8** null, i8* null, i64* null, i8 zeroext 0) #14
  %49 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %11, i64 0, i32 1
  %50 = getelementptr inbounds %"struct.skia::tracing_internals::ScopedTracer::Data", %"struct.skia::tracing_internals::ScopedTracer::Data"* %49, i64 0, i32 0
  store i8* %31, i8** %50, align 8
  store i8* getelementptr inbounds ([103 x i8], [103 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu11writePixelsEP9GrSurface7SkIRect11GrColorTypeS3_PK10GrMipLevelib, i64 0, i64 0), i8** %35, align 8
  store i64 %48, i64* %36, align 8
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* %49, %"struct.skia::tracing_internals::ScopedTracer::Data"** %33, align 8
  br label %51

51:                                               ; preds = %30, %42
  %52 = getelementptr inbounds %class.GrSurface, %class.GrSurface* %1, i64 0, i32 2
  %53 = load i32, i32* %52, align 8
  %54 = and i32 %53, 1
  %55 = icmp eq i32 %54, 0
  br i1 %55, label %56, label %159

56:                                               ; preds = %51
  switch i32 %7, label %98 [
    i32 0, label %159
    i32 1, label %57
  ]

57:                                               ; preds = %56
  %58 = getelementptr inbounds %class.GrSurface, %class.GrSurface* %1, i64 0, i32 1
  %59 = bitcast %struct.SkISize* %58 to i64*
  %60 = load i64, i64* %59, align 8
  %61 = lshr i64 %60, 32
  %62 = trunc i64 %61 to i32
  %63 = shl i64 %3, 32
  %64 = ashr exact i64 %63, 32
  %65 = shl i64 %2, 32
  %66 = ashr exact i64 %65, 32
  %67 = sub nsw i64 %64, %66
  %68 = ashr i64 %3, 32
  %69 = ashr i64 %2, 32
  %70 = sub nsw i64 %68, %69
  %71 = icmp slt i64 %67, 1
  %72 = icmp slt i64 %70, 1
  %73 = or i1 %71, %72
  br i1 %73, label %159, label %74

74:                                               ; preds = %57
  %75 = or i64 %70, %67
  %76 = add nsw i64 %75, 2147483648
  %77 = icmp ugt i64 %76, 4294967295
  br i1 %77, label %159, label %78

78:                                               ; preds = %74
  %79 = shl i64 %60, 32
  %80 = icmp slt i64 %79, 4294967296
  %81 = icmp slt i64 %60, 4294967296
  %82 = or i1 %81, %80
  br i1 %82, label %159, label %83

83:                                               ; preds = %78
  %84 = trunc i64 %60 to i32
  %85 = or i64 %79, %60
  %86 = ashr i64 %85, 32
  %87 = add nsw i64 %86, 2147483648
  %88 = icmp ugt i64 %87, 4294967295
  %89 = or i64 %21, %2
  %90 = trunc i64 %89 to i32
  %91 = icmp slt i32 %90, 0
  %92 = or i1 %88, %91
  %93 = icmp sgt i32 %18, %84
  %94 = or i1 %93, %92
  %95 = icmp sle i32 %20, %62
  %96 = xor i1 %94, true
  %97 = and i1 %95, %96
  br i1 %97, label %108, label %159

98:                                               ; preds = %56
  %99 = bitcast { i64, i64 }* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %99) #14
  %100 = getelementptr inbounds %class.GrSurface, %class.GrSurface* %1, i64 0, i32 1
  %101 = bitcast %struct.SkISize* %100 to i64*
  %102 = load i64, i64* %101, align 8
  %103 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %12, i64 0, i32 0
  store i64 0, i64* %103, align 8
  %104 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %12, i64 0, i32 1
  store i64 %102, i64* %104, align 8
  %105 = bitcast { i64, i64 }* %10 to i8*
  %106 = call i32 @bcmp(i8* nonnull %105, i8* nonnull %99, i64 16) #14
  %107 = icmp eq i32 %106, 0
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %99) #14
  br i1 %107, label %108, label %159

108:                                              ; preds = %98, %83
  %109 = sub i64 %3, %2
  %110 = sub nsw i64 %19, %21
  %111 = shl i64 %110, 32
  %112 = and i64 %109, 4294967295
  %113 = or i64 %111, %112
  %114 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 2, i32 0
  %115 = load %class.GrCaps*, %class.GrCaps** %114, align 8
  %116 = call fastcc zeroext i1 @_ZL21validate_texel_levels7SkISize11GrColorTypePK10GrMipLeveliPK6GrCaps(i64 %113, i32 %5, %struct.GrMipLevel* %6, i32 %7, %class.GrCaps* %115)
  br i1 %116, label %117, label %159

117:                                              ; preds = %108
  %118 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 4
  %119 = load i32, i32* %118, align 8
  %120 = icmp eq i32 %119, 0
  br i1 %120, label %126, label %121

121:                                              ; preds = %117
  %122 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*, i32)***
  %123 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %122, align 8
  %124 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %123, i64 38
  %125 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %124, align 8
  call void %125(%class.GrGpu* %0, i32 %119) #14
  store i32 0, i32* %118, align 8
  br label %126

126:                                              ; preds = %117, %121
  %127 = bitcast %class.GrGpu* %0 to i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %struct.GrMipLevel*, i32, i1)***
  %128 = load i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %struct.GrMipLevel*, i32, i1)**, i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %struct.GrMipLevel*, i32, i1)*** %127, align 8
  %129 = getelementptr inbounds i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %struct.GrMipLevel*, i32, i1)*, i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %struct.GrMipLevel*, i32, i1)** %128, i64 49
  %130 = load i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %struct.GrMipLevel*, i32, i1)*, i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %struct.GrMipLevel*, i32, i1)** %129, align 8
  %131 = call zeroext i1 %130(%class.GrGpu* %0, %class.GrSurface* %1, i64 %2, i64 %3, i32 %4, i32 %5, %struct.GrMipLevel* %6, i32 %7, i1 zeroext %8) #14
  br i1 %131, label %132, label %159

132:                                              ; preds = %126
  %133 = shl i64 %3, 32
  %134 = ashr exact i64 %133, 32
  %135 = shl i64 %2, 32
  %136 = ashr exact i64 %135, 32
  %137 = sub nsw i64 %134, %136
  %138 = ashr i64 %3, 32
  %139 = ashr i64 %2, 32
  %140 = sub nsw i64 %138, %139
  %141 = icmp slt i64 %137, 1
  %142 = icmp slt i64 %140, 1
  %143 = or i1 %141, %142
  br i1 %143, label %159, label %144

144:                                              ; preds = %132
  %145 = or i64 %140, %137
  %146 = add nsw i64 %145, 2147483648
  %147 = icmp ugt i64 %146, 4294967295
  br i1 %147, label %159, label %148

148:                                              ; preds = %144
  %149 = bitcast %class.GrSurface* %1 to %class.GrTexture* (%class.GrSurface*)***
  %150 = load %class.GrTexture* (%class.GrSurface*)**, %class.GrTexture* (%class.GrSurface*)*** %149, align 8
  %151 = getelementptr inbounds %class.GrTexture* (%class.GrSurface*)*, %class.GrTexture* (%class.GrSurface*)** %150, i64 10
  %152 = load %class.GrTexture* (%class.GrSurface*)*, %class.GrTexture* (%class.GrSurface*)** %151, align 8
  %153 = call %class.GrTexture* %152(%class.GrSurface* %1) #14
  %154 = icmp eq %class.GrTexture* %153, null
  br i1 %154, label %159, label %155

155:                                              ; preds = %148
  %156 = icmp eq i32 %7, 1
  br i1 %156, label %157, label %158

157:                                              ; preds = %155
  call void @_ZN9GrTexture16markMipmapsDirtyEv(%class.GrTexture* nonnull %153) #14
  br label %159

158:                                              ; preds = %155
  call void @_ZN9GrTexture16markMipmapsCleanEv(%class.GrTexture* nonnull %153) #14
  br label %159

159:                                              ; preds = %98, %51, %57, %74, %78, %158, %157, %148, %144, %132, %126, %108, %83, %56
  %160 = phi i1 [ false, %51 ], [ false, %56 ], [ false, %83 ], [ false, %98 ], [ false, %108 ], [ false, %126 ], [ true, %132 ], [ true, %144 ], [ true, %148 ], [ true, %157 ], [ true, %158 ], [ false, %78 ], [ false, %74 ], [ false, %57 ]
  %161 = load %"struct.skia::tracing_internals::ScopedTracer::Data"*, %"struct.skia::tracing_internals::ScopedTracer::Data"** %33, align 8
  %162 = icmp eq %"struct.skia::tracing_internals::ScopedTracer::Data"* %161, null
  br i1 %162, label %176, label %163

163:                                              ; preds = %159
  %164 = load i8*, i8** %34, align 8
  %165 = load i8, i8* %164, align 1
  %166 = icmp eq i8 %165, 0
  br i1 %166, label %176, label %167

167:                                              ; preds = %163
  %168 = call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %169 = load i8*, i8** %34, align 8
  %170 = load i8*, i8** %35, align 8
  %171 = load i64, i64* %36, align 8
  %172 = bitcast %class.SkEventTracer* %168 to void (%class.SkEventTracer*, i8*, i8*, i64)***
  %173 = load void (%class.SkEventTracer*, i8*, i8*, i64)**, void (%class.SkEventTracer*, i8*, i8*, i64)*** %172, align 8
  %174 = getelementptr inbounds void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %173, i64 5
  %175 = load void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %174, align 8
  call void %175(%class.SkEventTracer* %168, i8* %169, i8* %170, i64 %171) #14
  br label %176

176:                                              ; preds = %159, %163, %167
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %32) #14
  ret i1 %160
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu23createCompressedTextureE7SkISizeRK15GrBackendFormat10SkBudgeted11GrMipmapped11GrProtectedPKvm(%class.sk_sp.226* noalias sret, %class.GrGpu*, i64, %class.GrBackendFormat* dereferenceable(72), i1 zeroext, i1 zeroext, i1 zeroext, i8*, i64) local_unnamed_addr #1 align 2 {
  %10 = trunc i64 %2 to i32
  %11 = lshr i64 %2, 32
  %12 = trunc i64 %11 to i32
  %13 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 4
  %14 = load i32, i32* %13, align 8
  %15 = icmp eq i32 %14, 0
  br i1 %15, label %21, label %16

16:                                               ; preds = %9
  %17 = bitcast %class.GrGpu* %1 to void (%class.GrGpu*, i32)***
  %18 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %17, align 8
  %19 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %18, i64 38
  %20 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %19, align 8
  tail call void %20(%class.GrGpu* %1, i32 %14) #14
  store i32 0, i32* %13, align 8
  br label %21

21:                                               ; preds = %9, %16
  %22 = icmp slt i32 %10, 1
  br i1 %22, label %33, label %23

23:                                               ; preds = %21
  %24 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 2, i32 0
  %25 = load %class.GrCaps*, %class.GrCaps** %24, align 8
  %26 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %25, i64 0, i32 11
  %27 = load i32, i32* %26, align 4
  %28 = icmp slt i32 %27, %10
  %29 = icmp slt i32 %12, 1
  %30 = or i1 %29, %28
  %31 = icmp slt i32 %27, %12
  %32 = or i1 %31, %30
  br i1 %32, label %33, label %35

33:                                               ; preds = %23, %21
  %34 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %34, align 8
  br label %58

35:                                               ; preds = %23
  %36 = icmp eq i8* %7, null
  br i1 %36, label %37, label %39

37:                                               ; preds = %35
  %38 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %38, align 8
  br label %58

39:                                               ; preds = %35
  %40 = bitcast %class.GrCaps* %25 to i1 (%class.GrCaps*, %class.GrBackendFormat*)***
  %41 = load i1 (%class.GrCaps*, %class.GrBackendFormat*)**, i1 (%class.GrCaps*, %class.GrBackendFormat*)*** %40, align 8
  %42 = getelementptr inbounds i1 (%class.GrCaps*, %class.GrBackendFormat*)*, i1 (%class.GrCaps*, %class.GrBackendFormat*)** %41, i64 4
  %43 = load i1 (%class.GrCaps*, %class.GrBackendFormat*)*, i1 (%class.GrCaps*, %class.GrBackendFormat*)** %42, align 8
  %44 = tail call zeroext i1 %43(%class.GrCaps* %25, %class.GrBackendFormat* dereferenceable(72) %3) #14
  br i1 %44, label %47, label %45

45:                                               ; preds = %39
  %46 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %46, align 8
  br label %58

47:                                               ; preds = %39
  %48 = tail call i32 @_Z32GrBackendFormatToCompressionTypeRK15GrBackendFormat(%class.GrBackendFormat* dereferenceable(72) %3) #14
  %49 = tail call i64 @_Z20SkCompressedDataSizeN7SkImage15CompressionTypeE7SkISizeP8SkTArrayImLb0EEb(i32 %48, i64 %2, %class.SkTArray.233* null, i1 zeroext %5) #14
  %50 = icmp ugt i64 %49, %8
  br i1 %50, label %51, label %53

51:                                               ; preds = %47
  %52 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %52, align 8
  br label %58

53:                                               ; preds = %47
  %54 = bitcast %class.GrGpu* %1 to void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1, i8*, i64)***
  %55 = load void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1, i8*, i64)**, void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1, i8*, i64)*** %54, align 8
  %56 = getelementptr inbounds void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1, i8*, i64)*, void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1, i8*, i64)** %55, i64 41
  %57 = load void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1, i8*, i64)*, void (%class.sk_sp.226*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1, i8*, i64)** %56, align 8
  tail call void %57(%class.sk_sp.226* sret %0, %class.GrGpu* %1, i64 %2, %class.GrBackendFormat* dereferenceable(72) %3, i1 zeroext %4, i1 zeroext %5, i1 zeroext %6, i8* nonnull %7, i64 %8) #14
  br label %58

58:                                               ; preds = %51, %53, %45, %37, %33
  ret void
}

declare i32 @_Z32GrBackendFormatToCompressionTypeRK15GrBackendFormat(%class.GrBackendFormat* dereferenceable(72)) local_unnamed_addr #6

declare i64 @_Z20SkCompressedDataSizeN7SkImage15CompressionTypeE7SkISizeP8SkTArrayImLb0EEb(i32, i64, %class.SkTArray.233*, i1 zeroext) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu18wrapBackendTextureERK16GrBackendTexture15GrWrapOwnership15GrWrapCacheable8GrIOType(%class.sk_sp.226* noalias sret, %class.GrGpu*, %class.GrBackendTexture* dereferenceable(176), i32, i1 zeroext, i32) local_unnamed_addr #1 align 2 {
  %7 = alloca %class.GrBackendFormat, align 8
  %8 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 4
  %9 = load i32, i32* %8, align 8
  %10 = icmp eq i32 %9, 0
  br i1 %10, label %16, label %11

11:                                               ; preds = %6
  %12 = bitcast %class.GrGpu* %1 to void (%class.GrGpu*, i32)***
  %13 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %12, align 8
  %14 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %13, i64 38
  %15 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %14, align 8
  tail call void %15(%class.GrGpu* %1, i32 %9) #14
  store i32 0, i32* %8, align 8
  br label %16

16:                                               ; preds = %6, %11
  %17 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 2, i32 0
  %18 = load %class.GrCaps*, %class.GrCaps** %17, align 8
  %19 = bitcast %class.GrBackendFormat* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 72, i8* nonnull %19) #14
  call void @_ZNK16GrBackendTexture16getBackendFormatEv(%class.GrBackendFormat* nonnull sret %7, %class.GrBackendTexture* %2) #14
  %20 = bitcast %class.GrCaps* %18 to i1 (%class.GrCaps*, %class.GrBackendFormat*)***
  %21 = load i1 (%class.GrCaps*, %class.GrBackendFormat*)**, i1 (%class.GrCaps*, %class.GrBackendFormat*)*** %20, align 8
  %22 = getelementptr inbounds i1 (%class.GrCaps*, %class.GrBackendFormat*)*, i1 (%class.GrCaps*, %class.GrBackendFormat*)** %21, i64 4
  %23 = load i1 (%class.GrCaps*, %class.GrBackendFormat*)*, i1 (%class.GrCaps*, %class.GrBackendFormat*)** %22, align 8
  %24 = call zeroext i1 %23(%class.GrCaps* %18, %class.GrBackendFormat* nonnull dereferenceable(72) %7) #14
  call void @llvm.lifetime.end.p0i8(i64 72, i8* nonnull %19) #14
  br i1 %24, label %27, label %25

25:                                               ; preds = %16
  %26 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %26, align 8
  br label %44

27:                                               ; preds = %16
  %28 = getelementptr inbounds %class.GrBackendTexture, %class.GrBackendTexture* %2, i64 0, i32 1
  %29 = load i32, i32* %28, align 4
  %30 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %18, i64 0, i32 11
  %31 = load i32, i32* %30, align 4
  %32 = icmp sgt i32 %29, %31
  br i1 %32, label %37, label %33

33:                                               ; preds = %27
  %34 = getelementptr inbounds %class.GrBackendTexture, %class.GrBackendTexture* %2, i64 0, i32 2
  %35 = load i32, i32* %34, align 8
  %36 = icmp sgt i32 %35, %31
  br i1 %36, label %37, label %39

37:                                               ; preds = %33, %27
  %38 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %38, align 8
  br label %44

39:                                               ; preds = %33
  %40 = bitcast %class.GrGpu* %1 to void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1, i32)***
  %41 = load void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1, i32)**, void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1, i32)*** %40, align 8
  %42 = getelementptr inbounds void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1, i32)*, void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1, i32)** %41, i64 42
  %43 = load void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1, i32)*, void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1, i32)** %42, align 8
  call void %43(%class.sk_sp.226* sret %0, %class.GrGpu* %1, %class.GrBackendTexture* dereferenceable(176) %2, i32 %3, i1 zeroext %4, i32 %5) #14
  br label %44

44:                                               ; preds = %39, %37, %25
  ret void
}

declare void @_ZNK16GrBackendTexture16getBackendFormatEv(%class.GrBackendFormat* sret, %class.GrBackendTexture*) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu28wrapCompressedBackendTextureERK16GrBackendTexture15GrWrapOwnership15GrWrapCacheable(%class.sk_sp.226* noalias sret, %class.GrGpu*, %class.GrBackendTexture* dereferenceable(176), i32, i1 zeroext) local_unnamed_addr #1 align 2 {
  %6 = alloca %class.GrBackendFormat, align 8
  %7 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 4
  %8 = load i32, i32* %7, align 8
  %9 = icmp eq i32 %8, 0
  br i1 %9, label %15, label %10

10:                                               ; preds = %5
  %11 = bitcast %class.GrGpu* %1 to void (%class.GrGpu*, i32)***
  %12 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %11, align 8
  %13 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %12, i64 38
  %14 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %13, align 8
  tail call void %14(%class.GrGpu* %1, i32 %8) #14
  store i32 0, i32* %7, align 8
  br label %15

15:                                               ; preds = %5, %10
  %16 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 2, i32 0
  %17 = load %class.GrCaps*, %class.GrCaps** %16, align 8
  %18 = bitcast %class.GrBackendFormat* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 72, i8* nonnull %18) #14
  call void @_ZNK16GrBackendTexture16getBackendFormatEv(%class.GrBackendFormat* nonnull sret %6, %class.GrBackendTexture* %2) #14
  %19 = bitcast %class.GrCaps* %17 to i1 (%class.GrCaps*, %class.GrBackendFormat*)***
  %20 = load i1 (%class.GrCaps*, %class.GrBackendFormat*)**, i1 (%class.GrCaps*, %class.GrBackendFormat*)*** %19, align 8
  %21 = getelementptr inbounds i1 (%class.GrCaps*, %class.GrBackendFormat*)*, i1 (%class.GrCaps*, %class.GrBackendFormat*)** %20, i64 4
  %22 = load i1 (%class.GrCaps*, %class.GrBackendFormat*)*, i1 (%class.GrCaps*, %class.GrBackendFormat*)** %21, align 8
  %23 = call zeroext i1 %22(%class.GrCaps* %17, %class.GrBackendFormat* nonnull dereferenceable(72) %6) #14
  call void @llvm.lifetime.end.p0i8(i64 72, i8* nonnull %18) #14
  br i1 %23, label %26, label %24

24:                                               ; preds = %15
  %25 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %25, align 8
  br label %43

26:                                               ; preds = %15
  %27 = getelementptr inbounds %class.GrBackendTexture, %class.GrBackendTexture* %2, i64 0, i32 1
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %17, i64 0, i32 11
  %30 = load i32, i32* %29, align 4
  %31 = icmp sgt i32 %28, %30
  br i1 %31, label %36, label %32

32:                                               ; preds = %26
  %33 = getelementptr inbounds %class.GrBackendTexture, %class.GrBackendTexture* %2, i64 0, i32 2
  %34 = load i32, i32* %33, align 8
  %35 = icmp sgt i32 %34, %30
  br i1 %35, label %36, label %38

36:                                               ; preds = %32, %26
  %37 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %37, align 8
  br label %43

38:                                               ; preds = %32
  %39 = bitcast %class.GrGpu* %1 to void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1)***
  %40 = load void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1)**, void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1)*** %39, align 8
  %41 = getelementptr inbounds void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1)*, void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1)** %40, i64 43
  %42 = load void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1)*, void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i1)** %41, align 8
  call void %42(%class.sk_sp.226* sret %0, %class.GrGpu* %1, %class.GrBackendTexture* dereferenceable(176) %2, i32 %3, i1 zeroext %4) #14
  br label %43

43:                                               ; preds = %38, %36, %24
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu28wrapRenderableBackendTextureERK16GrBackendTexturei15GrWrapOwnership15GrWrapCacheable(%class.sk_sp.226* noalias nocapture sret, %class.GrGpu*, %class.GrBackendTexture* dereferenceable(176), i32, i32, i1 zeroext) local_unnamed_addr #1 align 2 {
  %7 = alloca %class.GrBackendFormat, align 8
  %8 = alloca %class.GrBackendFormat, align 8
  %9 = alloca %class.sk_sp.226, align 8
  %10 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 4
  %11 = load i32, i32* %10, align 8
  %12 = icmp eq i32 %11, 0
  br i1 %12, label %18, label %13

13:                                               ; preds = %6
  %14 = bitcast %class.GrGpu* %1 to void (%class.GrGpu*, i32)***
  %15 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %14, align 8
  %16 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %15, i64 38
  %17 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %16, align 8
  tail call void %17(%class.GrGpu* %1, i32 %11) #14
  store i32 0, i32* %10, align 8
  br label %18

18:                                               ; preds = %6, %13
  %19 = icmp slt i32 %3, 1
  br i1 %19, label %20, label %22

20:                                               ; preds = %18
  %21 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %21, align 8
  br label %101

22:                                               ; preds = %18
  %23 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 2, i32 0
  %24 = load %class.GrCaps*, %class.GrCaps** %23, align 8
  %25 = bitcast %class.GrBackendFormat* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 72, i8* nonnull %25) #14
  call void @_ZNK16GrBackendTexture16getBackendFormatEv(%class.GrBackendFormat* nonnull sret %7, %class.GrBackendTexture* %2) #14
  %26 = bitcast %class.GrCaps* %24 to i1 (%class.GrCaps*, %class.GrBackendFormat*)***
  %27 = load i1 (%class.GrCaps*, %class.GrBackendFormat*)**, i1 (%class.GrCaps*, %class.GrBackendFormat*)*** %26, align 8
  %28 = getelementptr inbounds i1 (%class.GrCaps*, %class.GrBackendFormat*)*, i1 (%class.GrCaps*, %class.GrBackendFormat*)** %27, i64 4
  %29 = load i1 (%class.GrCaps*, %class.GrBackendFormat*)*, i1 (%class.GrCaps*, %class.GrBackendFormat*)** %28, align 8
  %30 = call zeroext i1 %29(%class.GrCaps* %24, %class.GrBackendFormat* nonnull dereferenceable(72) %7) #14
  %31 = bitcast %class.GrBackendFormat* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 72, i8* nonnull %31) #14
  br i1 %30, label %32, label %38

32:                                               ; preds = %22
  call void @_ZNK16GrBackendTexture16getBackendFormatEv(%class.GrBackendFormat* nonnull sret %8, %class.GrBackendTexture* %2) #14
  %33 = bitcast %class.GrCaps* %24 to i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)***
  %34 = load i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)**, i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)*** %33, align 8
  %35 = getelementptr inbounds i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)*, i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)** %34, i64 8
  %36 = load i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)*, i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)** %35, align 8
  %37 = call zeroext i1 %36(%class.GrCaps* %24, %class.GrBackendFormat* nonnull dereferenceable(72) %8, i32 %3) #14
  call void @llvm.lifetime.end.p0i8(i64 72, i8* nonnull %31) #14
  call void @llvm.lifetime.end.p0i8(i64 72, i8* nonnull %25) #14
  br i1 %37, label %41, label %39

38:                                               ; preds = %22
  call void @llvm.lifetime.end.p0i8(i64 72, i8* nonnull %31) #14
  call void @llvm.lifetime.end.p0i8(i64 72, i8* nonnull %25) #14
  br label %39

39:                                               ; preds = %32, %38
  %40 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %40, align 8
  br label %101

41:                                               ; preds = %32
  %42 = getelementptr inbounds %class.GrBackendTexture, %class.GrBackendTexture* %2, i64 0, i32 1
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %24, i64 0, i32 8
  %45 = load i32, i32* %44, align 8
  %46 = icmp sgt i32 %43, %45
  br i1 %46, label %51, label %47

47:                                               ; preds = %41
  %48 = getelementptr inbounds %class.GrBackendTexture, %class.GrBackendTexture* %2, i64 0, i32 2
  %49 = load i32, i32* %48, align 8
  %50 = icmp sgt i32 %49, %45
  br i1 %50, label %51, label %53

51:                                               ; preds = %47, %41
  %52 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %0, i64 0, i32 0
  store %class.GrTexture* null, %class.GrTexture** %52, align 8
  br label %101

53:                                               ; preds = %47
  %54 = bitcast %class.sk_sp.226* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %54) #14
  %55 = getelementptr inbounds %class.sk_sp.226, %class.sk_sp.226* %9, i64 0, i32 0
  store %class.GrTexture* inttoptr (i64 -6148914691236517206 to %class.GrTexture*), %class.GrTexture** %55, align 8
  %56 = bitcast %class.GrGpu* %1 to void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i32, i1)***
  %57 = load void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i32, i1)**, void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i32, i1)*** %56, align 8
  %58 = getelementptr inbounds void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i32, i1)*, void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i32, i1)** %57, i64 44
  %59 = load void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i32, i1)*, void (%class.sk_sp.226*, %class.GrGpu*, %class.GrBackendTexture*, i32, i32, i1)** %58, align 8
  call void %59(%class.sk_sp.226* nonnull sret %9, %class.GrGpu* %1, %class.GrBackendTexture* dereferenceable(176) %2, i32 %3, i32 %4, i1 zeroext %5) #14
  %60 = load %class.GrTexture*, %class.GrTexture** %55, align 8
  %61 = icmp ne %class.GrTexture* %60, null
  %62 = icmp sgt i32 %3, 1
  %63 = and i1 %62, %61
  %64 = ptrtoint %class.GrTexture* %60 to i64
  br i1 %63, label %65, label %98

65:                                               ; preds = %53
  %66 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %24, i64 0, i32 3
  %67 = bitcast i48* %66 to i64*
  %68 = load i64, i64* %67, align 8
  %69 = and i64 %68, 16384
  %70 = icmp eq i64 %69, 0
  br i1 %70, label %71, label %98

71:                                               ; preds = %65
  %72 = bitcast %class.GrTexture* %60 to i8**
  %73 = load i8*, i8** %72, align 8
  %74 = getelementptr i8, i8* %73, i64 -24
  %75 = bitcast i8* %74 to i64*
  %76 = load i64, i64* %75, align 8
  %77 = bitcast %class.GrTexture* %60 to i8*
  %78 = getelementptr inbounds i8, i8* %77, i64 %76
  %79 = bitcast i8* %78 to %class.GrSurface*
  %80 = bitcast i8* %78 to %class.GrRenderTarget* (%class.GrSurface*)***
  %81 = load %class.GrRenderTarget* (%class.GrSurface*)**, %class.GrRenderTarget* (%class.GrSurface*)*** %80, align 8
  %82 = getelementptr inbounds %class.GrRenderTarget* (%class.GrSurface*)*, %class.GrRenderTarget* (%class.GrSurface*)** %81, i64 12
  %83 = load %class.GrRenderTarget* (%class.GrSurface*)*, %class.GrRenderTarget* (%class.GrSurface*)** %82, align 8
  %84 = call %class.GrRenderTarget* %83(%class.GrSurface* %79) #14
  %85 = bitcast %class.GrRenderTarget* %84 to i8**
  %86 = load i8*, i8** %85, align 8
  %87 = getelementptr i8, i8* %86, i64 -24
  %88 = bitcast i8* %87 to i64*
  %89 = load i64, i64* %88, align 8
  %90 = bitcast %class.GrRenderTarget* %84 to i8*
  %91 = getelementptr inbounds i8, i8* %90, i64 %89
  %92 = getelementptr inbounds i8, i8* %91, i64 160
  %93 = bitcast i8* %92 to i32*
  %94 = load i32, i32* %93, align 4
  %95 = or i32 %94, 4
  store i32 %95, i32* %93, align 4
  %96 = bitcast %class.sk_sp.226* %9 to i64*
  %97 = load i64, i64* %96, align 8
  br label %98

98:                                               ; preds = %65, %53, %71
  %99 = phi i64 [ %64, %65 ], [ %64, %53 ], [ %97, %71 ]
  %100 = bitcast %class.sk_sp.226* %0 to i64*
  store i64 %99, i64* %100, align 8
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %54) #14
  br label %101

101:                                              ; preds = %39, %51, %98, %20
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu23wrapBackendRenderTargetERK21GrBackendRenderTarget(%class.sk_sp.248* noalias nocapture sret, %class.GrGpu*, %class.GrBackendRenderTarget* dereferenceable(176)) local_unnamed_addr #1 align 2 {
  %4 = alloca %class.GrBackendFormat, align 8
  %5 = alloca %class.sk_sp.248, align 8
  %6 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 4
  %7 = load i32, i32* %6, align 8
  %8 = icmp eq i32 %7, 0
  br i1 %8, label %14, label %9

9:                                                ; preds = %3
  %10 = bitcast %class.GrGpu* %1 to void (%class.GrGpu*, i32)***
  %11 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %10, align 8
  %12 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %11, i64 38
  %13 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %12, align 8
  tail call void %13(%class.GrGpu* %1, i32 %7) #14
  store i32 0, i32* %6, align 8
  br label %14

14:                                               ; preds = %3, %9
  %15 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 2, i32 0
  %16 = load %class.GrCaps*, %class.GrCaps** %15, align 8
  %17 = bitcast %class.GrBackendFormat* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 72, i8* nonnull %17) #14
  call void @_ZNK21GrBackendRenderTarget16getBackendFormatEv(%class.GrBackendFormat* nonnull sret %4, %class.GrBackendRenderTarget* %2) #14
  %18 = getelementptr inbounds %class.GrBackendRenderTarget, %class.GrBackendRenderTarget* %2, i64 0, i32 4
  %19 = load i32, i32* %18, align 4
  %20 = bitcast %class.GrCaps* %16 to i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)***
  %21 = load i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)**, i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)*** %20, align 8
  %22 = getelementptr inbounds i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)*, i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)** %21, i64 8
  %23 = load i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)*, i1 (%class.GrCaps*, %class.GrBackendFormat*, i32)** %22, align 8
  %24 = call zeroext i1 %23(%class.GrCaps* %16, %class.GrBackendFormat* nonnull dereferenceable(72) %4, i32 %19) #14
  call void @llvm.lifetime.end.p0i8(i64 72, i8* nonnull %17) #14
  br i1 %24, label %27, label %25

25:                                               ; preds = %14
  %26 = getelementptr inbounds %class.sk_sp.248, %class.sk_sp.248* %0, i64 0, i32 0
  store %class.GrRenderTarget* null, %class.GrRenderTarget** %26, align 8
  br label %54

27:                                               ; preds = %14
  %28 = bitcast %class.sk_sp.248* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %28) #14
  %29 = getelementptr inbounds %class.sk_sp.248, %class.sk_sp.248* %5, i64 0, i32 0
  store %class.GrRenderTarget* inttoptr (i64 -6148914691236517206 to %class.GrRenderTarget*), %class.GrRenderTarget** %29, align 8
  %30 = bitcast %class.GrGpu* %1 to void (%class.sk_sp.248*, %class.GrGpu*, %class.GrBackendRenderTarget*)***
  %31 = load void (%class.sk_sp.248*, %class.GrGpu*, %class.GrBackendRenderTarget*)**, void (%class.sk_sp.248*, %class.GrGpu*, %class.GrBackendRenderTarget*)*** %30, align 8
  %32 = getelementptr inbounds void (%class.sk_sp.248*, %class.GrGpu*, %class.GrBackendRenderTarget*)*, void (%class.sk_sp.248*, %class.GrGpu*, %class.GrBackendRenderTarget*)** %31, i64 45
  %33 = load void (%class.sk_sp.248*, %class.GrGpu*, %class.GrBackendRenderTarget*)*, void (%class.sk_sp.248*, %class.GrGpu*, %class.GrBackendRenderTarget*)** %32, align 8
  call void %33(%class.sk_sp.248* nonnull sret %5, %class.GrGpu* %1, %class.GrBackendRenderTarget* dereferenceable(176) %2) #14
  %34 = getelementptr inbounds %class.GrBackendRenderTarget, %class.GrBackendRenderTarget* %2, i64 0, i32 1
  %35 = load i8, i8* %34, align 1, !range !7
  %36 = icmp eq i8 %35, 0
  br i1 %36, label %50, label %37

37:                                               ; preds = %27
  %38 = load %class.GrRenderTarget*, %class.GrRenderTarget** %29, align 8
  %39 = bitcast %class.GrRenderTarget* %38 to i8**
  %40 = load i8*, i8** %39, align 8
  %41 = getelementptr i8, i8* %40, i64 -24
  %42 = bitcast i8* %41 to i64*
  %43 = load i64, i64* %42, align 8
  %44 = bitcast %class.GrRenderTarget* %38 to i8*
  %45 = getelementptr inbounds i8, i8* %44, i64 %43
  %46 = getelementptr inbounds i8, i8* %45, i64 160
  %47 = bitcast i8* %46 to i32*
  %48 = load i32, i32* %47, align 4
  %49 = or i32 %48, 8
  store i32 %49, i32* %47, align 4
  br label %50

50:                                               ; preds = %27, %37
  %51 = bitcast %class.sk_sp.248* %5 to i64*
  %52 = load i64, i64* %51, align 8
  %53 = bitcast %class.sk_sp.248* %0 to i64*
  store i64 %52, i64* %53, align 8
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %28) #14
  br label %54

54:                                               ; preds = %50, %25
  ret void
}

declare void @_ZNK21GrBackendRenderTarget16getBackendFormatEv(%class.GrBackendFormat* sret, %class.GrBackendRenderTarget*) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu35wrapVulkanSecondaryCBAsRenderTargetERK11SkImageInfoRK16GrVkDrawableInfo(%class.sk_sp.248* noalias sret, %class.GrGpu*, %struct.SkImageInfo* dereferenceable(24), %struct.GrVkDrawableInfo* dereferenceable(48)) local_unnamed_addr #1 align 2 {
  %5 = bitcast %class.GrGpu* %1 to void (%class.sk_sp.248*, %class.GrGpu*, %struct.SkImageInfo*, %struct.GrVkDrawableInfo*)***
  %6 = load void (%class.sk_sp.248*, %class.GrGpu*, %struct.SkImageInfo*, %struct.GrVkDrawableInfo*)**, void (%class.sk_sp.248*, %class.GrGpu*, %struct.SkImageInfo*, %struct.GrVkDrawableInfo*)*** %5, align 8
  %7 = getelementptr inbounds void (%class.sk_sp.248*, %class.GrGpu*, %struct.SkImageInfo*, %struct.GrVkDrawableInfo*)*, void (%class.sk_sp.248*, %class.GrGpu*, %struct.SkImageInfo*, %struct.GrVkDrawableInfo*)** %6, i64 46
  %8 = load void (%class.sk_sp.248*, %class.GrGpu*, %struct.SkImageInfo*, %struct.GrVkDrawableInfo*)*, void (%class.sk_sp.248*, %class.GrGpu*, %struct.SkImageInfo*, %struct.GrVkDrawableInfo*)** %7, align 8
  tail call void %8(%class.sk_sp.248* sret %0, %class.GrGpu* %1, %struct.SkImageInfo* dereferenceable(24) %2, %struct.GrVkDrawableInfo* dereferenceable(48) %3) #14
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define hidden void @_ZN5GrGpu37onWrapVulkanSecondaryCBAsRenderTargetERK11SkImageInfoRK16GrVkDrawableInfo(%class.sk_sp.248* noalias nocapture sret, %class.GrGpu* nocapture readnone, %struct.SkImageInfo* nocapture readnone dereferenceable(24), %struct.GrVkDrawableInfo* nocapture readnone dereferenceable(48)) unnamed_addr #0 align 2 {
  %5 = getelementptr inbounds %class.sk_sp.248, %class.sk_sp.248* %0, i64 0, i32 0
  store %class.GrRenderTarget* null, %class.GrRenderTarget** %5, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu12createBufferEm15GrGpuBufferType15GrAccessPatternPKv(%class.sk_sp.251* noalias sret, %class.GrGpu*, i64, i32, i32, i8*) local_unnamed_addr #1 align 2 {
  %7 = alloca %"class.skia::tracing_internals::ScopedTracer", align 8
  %8 = load atomic i64, i64* @_ZZN5GrGpu12createBufferEm15GrGpuBufferType15GrAccessPatternPKvE28trace_event_unique_atomic362.0.0 monotonic, align 8
  %9 = inttoptr i64 %8 to i8*
  %10 = icmp eq i64 %8, 0
  br i1 %10, label %11, label %19

11:                                               ; preds = %6
  %12 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %13 = bitcast %class.SkEventTracer* %12 to i8* (%class.SkEventTracer*, i8*)***
  %14 = load i8* (%class.SkEventTracer*, i8*)**, i8* (%class.SkEventTracer*, i8*)*** %13, align 8
  %15 = getelementptr inbounds i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %14, i64 2
  %16 = load i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %15, align 8
  %17 = tail call i8* %16(%class.SkEventTracer* %12, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str, i64 0, i64 0)) #14
  %18 = ptrtoint i8* %17 to i64
  store atomic i64 %18, i64* @_ZZN5GrGpu12createBufferEm15GrGpuBufferType15GrAccessPatternPKvE28trace_event_unique_atomic362.0.0 monotonic, align 8
  br label %19

19:                                               ; preds = %6, %11
  %20 = phi i8* [ %9, %6 ], [ %17, %11 ]
  %21 = bitcast %"class.skia::tracing_internals::ScopedTracer"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %21) #14
  %22 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %7, i64 0, i32 0
  %23 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %7, i64 0, i32 1, i32 0
  %24 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %7, i64 0, i32 1, i32 1
  %25 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %7, i64 0, i32 1, i32 2
  %26 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %7, i64 0, i32 1
  %27 = bitcast %"struct.skia::tracing_internals::ScopedTracer::Data"* %26 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %27, i8 -86, i64 24, i1 false)
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* null, %"struct.skia::tracing_internals::ScopedTracer::Data"** %22, align 8
  %28 = load i8, i8* %20, align 1
  %29 = and i8 %28, 5
  %30 = icmp eq i8 %29, 0
  br i1 %30, label %40, label %31

31:                                               ; preds = %19
  %32 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %33 = bitcast %class.SkEventTracer* %32 to i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)***
  %34 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)**, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*** %33, align 8
  %35 = getelementptr inbounds i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %34, i64 4
  %36 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %35, align 8
  %37 = tail call i64 %36(%class.SkEventTracer* %32, i8 signext 88, i8* %20, i8* getelementptr inbounds ([95 x i8], [95 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu12createBufferEm15GrGpuBufferType15GrAccessPatternPKv, i64 0, i64 0), i64 0, i32 0, i8** null, i8* null, i64* null, i8 zeroext 0) #14
  %38 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %7, i64 0, i32 1
  %39 = getelementptr inbounds %"struct.skia::tracing_internals::ScopedTracer::Data", %"struct.skia::tracing_internals::ScopedTracer::Data"* %38, i64 0, i32 0
  store i8* %20, i8** %39, align 8
  store i8* getelementptr inbounds ([95 x i8], [95 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu12createBufferEm15GrGpuBufferType15GrAccessPatternPKv, i64 0, i64 0), i8** %24, align 8
  store i64 %37, i64* %25, align 8
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* %38, %"struct.skia::tracing_internals::ScopedTracer::Data"** %22, align 8
  br label %40

40:                                               ; preds = %19, %31
  %41 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 4
  %42 = load i32, i32* %41, align 8
  %43 = icmp eq i32 %42, 0
  br i1 %43, label %49, label %44

44:                                               ; preds = %40
  %45 = bitcast %class.GrGpu* %1 to void (%class.GrGpu*, i32)***
  %46 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %45, align 8
  %47 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %46, i64 38
  %48 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %47, align 8
  call void %48(%class.GrGpu* %1, i32 %42) #14
  store i32 0, i32* %41, align 8
  br label %49

49:                                               ; preds = %40, %44
  %50 = getelementptr inbounds %class.sk_sp.251, %class.sk_sp.251* %0, i64 0, i32 0
  store %class.GrGpuBuffer* inttoptr (i64 -6148914691236517206 to %class.GrGpuBuffer*), %class.GrGpuBuffer** %50, align 8
  %51 = bitcast %class.GrGpu* %1 to void (%class.sk_sp.251*, %class.GrGpu*, i64, i32, i32, i8*)***
  %52 = load void (%class.sk_sp.251*, %class.GrGpu*, i64, i32, i32, i8*)**, void (%class.sk_sp.251*, %class.GrGpu*, i64, i32, i32, i8*)*** %51, align 8
  %53 = getelementptr inbounds void (%class.sk_sp.251*, %class.GrGpu*, i64, i32, i32, i8*)*, void (%class.sk_sp.251*, %class.GrGpu*, i64, i32, i32, i8*)** %52, i64 47
  %54 = load void (%class.sk_sp.251*, %class.GrGpu*, i64, i32, i32, i8*)*, void (%class.sk_sp.251*, %class.GrGpu*, i64, i32, i32, i8*)** %53, align 8
  call void %54(%class.sk_sp.251* sret %0, %class.GrGpu* %1, i64 %2, i32 %3, i32 %4, i8* %5) #14
  %55 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 2, i32 0
  %56 = load %class.GrCaps*, %class.GrCaps** %55, align 8
  %57 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %56, i64 0, i32 3
  %58 = bitcast i48* %57 to i64*
  %59 = load i64, i64* %58, align 8
  %60 = and i64 %59, 8
  %61 = icmp eq i64 %60, 0
  br i1 %61, label %62, label %65

62:                                               ; preds = %49
  %63 = load %class.GrGpuBuffer*, %class.GrGpuBuffer** %50, align 8
  %64 = getelementptr inbounds %class.GrGpuBuffer, %class.GrGpuBuffer* %63, i64 0, i32 0
  call void @_ZN13GrGpuResource16removeScratchKeyEv(%class.GrGpuResource* %64) #14
  br label %65

65:                                               ; preds = %49, %62
  %66 = load %"struct.skia::tracing_internals::ScopedTracer::Data"*, %"struct.skia::tracing_internals::ScopedTracer::Data"** %22, align 8
  %67 = icmp eq %"struct.skia::tracing_internals::ScopedTracer::Data"* %66, null
  br i1 %67, label %81, label %68

68:                                               ; preds = %65
  %69 = load i8*, i8** %23, align 8
  %70 = load i8, i8* %69, align 1
  %71 = icmp eq i8 %70, 0
  br i1 %71, label %81, label %72

72:                                               ; preds = %68
  %73 = call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %74 = load i8*, i8** %23, align 8
  %75 = load i8*, i8** %24, align 8
  %76 = load i64, i64* %25, align 8
  %77 = bitcast %class.SkEventTracer* %73 to void (%class.SkEventTracer*, i8*, i8*, i64)***
  %78 = load void (%class.SkEventTracer*, i8*, i8*, i64)**, void (%class.SkEventTracer*, i8*, i8*, i64)*** %77, align 8
  %79 = getelementptr inbounds void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %78, i64 5
  %80 = load void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %79, align 8
  call void %80(%class.SkEventTracer* %73, i8* %74, i8* %75, i64 %76) #14
  br label %81

81:                                               ; preds = %65, %68, %72
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %21) #14
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN5GrGpu11copySurfaceEP9GrSurfaceS1_RK7SkIRectRK8SkIPoint(%class.GrGpu*, %class.GrSurface*, %class.GrSurface*, %struct.SkIRect* dereferenceable(16), %struct.SkIPoint* dereferenceable(8)) local_unnamed_addr #1 align 2 {
  %6 = alloca %"class.skia::tracing_internals::ScopedTracer", align 8
  %7 = load atomic i64, i64* @_ZZN5GrGpu11copySurfaceEP9GrSurfaceS1_RK7SkIRectRK8SkIPointE28trace_event_unique_atomic373.0.0 monotonic, align 8
  %8 = inttoptr i64 %7 to i8*
  %9 = icmp eq i64 %7, 0
  br i1 %9, label %10, label %18

10:                                               ; preds = %5
  %11 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %12 = bitcast %class.SkEventTracer* %11 to i8* (%class.SkEventTracer*, i8*)***
  %13 = load i8* (%class.SkEventTracer*, i8*)**, i8* (%class.SkEventTracer*, i8*)*** %12, align 8
  %14 = getelementptr inbounds i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %13, i64 2
  %15 = load i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %14, align 8
  %16 = tail call i8* %15(%class.SkEventTracer* %11, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str, i64 0, i64 0)) #14
  %17 = ptrtoint i8* %16 to i64
  store atomic i64 %17, i64* @_ZZN5GrGpu11copySurfaceEP9GrSurfaceS1_RK7SkIRectRK8SkIPointE28trace_event_unique_atomic373.0.0 monotonic, align 8
  br label %18

18:                                               ; preds = %5, %10
  %19 = phi i8* [ %8, %5 ], [ %16, %10 ]
  %20 = bitcast %"class.skia::tracing_internals::ScopedTracer"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %20) #14
  %21 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %6, i64 0, i32 0
  %22 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %6, i64 0, i32 1, i32 0
  %23 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %6, i64 0, i32 1, i32 1
  %24 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %6, i64 0, i32 1, i32 2
  %25 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %6, i64 0, i32 1
  %26 = bitcast %"struct.skia::tracing_internals::ScopedTracer::Data"* %25 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %26, i8 -86, i64 24, i1 false)
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* null, %"struct.skia::tracing_internals::ScopedTracer::Data"** %21, align 8
  %27 = load i8, i8* %19, align 1
  %28 = and i8 %27, 5
  %29 = icmp eq i8 %28, 0
  br i1 %29, label %39, label %30

30:                                               ; preds = %18
  %31 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %32 = bitcast %class.SkEventTracer* %31 to i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)***
  %33 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)**, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*** %32, align 8
  %34 = getelementptr inbounds i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %33, i64 4
  %35 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %34, align 8
  %36 = tail call i64 %35(%class.SkEventTracer* %31, i8 signext 88, i8* %19, i8* getelementptr inbounds ([85 x i8], [85 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu11copySurfaceEP9GrSurfaceS1_RK7SkIRectRK8SkIPoint, i64 0, i64 0), i64 0, i32 0, i8** null, i8* null, i64* null, i8 zeroext 0) #14
  %37 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %6, i64 0, i32 1
  %38 = getelementptr inbounds %"struct.skia::tracing_internals::ScopedTracer::Data", %"struct.skia::tracing_internals::ScopedTracer::Data"* %37, i64 0, i32 0
  store i8* %19, i8** %38, align 8
  store i8* getelementptr inbounds ([85 x i8], [85 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu11copySurfaceEP9GrSurfaceS1_RK7SkIRectRK8SkIPoint, i64 0, i64 0), i8** %23, align 8
  store i64 %36, i64* %24, align 8
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* %37, %"struct.skia::tracing_internals::ScopedTracer::Data"** %21, align 8
  br label %39

39:                                               ; preds = %18, %30
  %40 = phi %"struct.skia::tracing_internals::ScopedTracer::Data"* [ null, %18 ], [ %37, %30 ]
  %41 = getelementptr inbounds %class.GrSurface, %class.GrSurface* %1, i64 0, i32 2
  %42 = load i32, i32* %41, align 8
  %43 = and i32 %42, 1
  %44 = icmp eq i32 %43, 0
  br i1 %44, label %45, label %61

45:                                               ; preds = %39
  %46 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 4
  %47 = load i32, i32* %46, align 8
  %48 = icmp eq i32 %47, 0
  br i1 %48, label %54, label %49

49:                                               ; preds = %45
  %50 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*, i32)***
  %51 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %50, align 8
  %52 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %51, i64 38
  %53 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %52, align 8
  call void %53(%class.GrGpu* %0, i32 %47) #14
  store i32 0, i32* %46, align 8
  br label %54

54:                                               ; preds = %45, %49
  %55 = bitcast %class.GrGpu* %0 to i1 (%class.GrGpu*, %class.GrSurface*, %class.GrSurface*, %struct.SkIRect*, %struct.SkIPoint*)***
  %56 = load i1 (%class.GrGpu*, %class.GrSurface*, %class.GrSurface*, %struct.SkIRect*, %struct.SkIPoint*)**, i1 (%class.GrGpu*, %class.GrSurface*, %class.GrSurface*, %struct.SkIRect*, %struct.SkIPoint*)*** %55, align 8
  %57 = getelementptr inbounds i1 (%class.GrGpu*, %class.GrSurface*, %class.GrSurface*, %struct.SkIRect*, %struct.SkIPoint*)*, i1 (%class.GrGpu*, %class.GrSurface*, %class.GrSurface*, %struct.SkIRect*, %struct.SkIPoint*)** %56, i64 54
  %58 = load i1 (%class.GrGpu*, %class.GrSurface*, %class.GrSurface*, %struct.SkIRect*, %struct.SkIPoint*)*, i1 (%class.GrGpu*, %class.GrSurface*, %class.GrSurface*, %struct.SkIRect*, %struct.SkIPoint*)** %57, align 8
  %59 = call zeroext i1 %58(%class.GrGpu* %0, %class.GrSurface* %1, %class.GrSurface* %2, %struct.SkIRect* dereferenceable(16) %3, %struct.SkIPoint* dereferenceable(8) %4) #14
  %60 = load %"struct.skia::tracing_internals::ScopedTracer::Data"*, %"struct.skia::tracing_internals::ScopedTracer::Data"** %21, align 8
  br label %61

61:                                               ; preds = %39, %54
  %62 = phi %"struct.skia::tracing_internals::ScopedTracer::Data"* [ %60, %54 ], [ %40, %39 ]
  %63 = phi i1 [ %59, %54 ], [ false, %39 ]
  %64 = icmp eq %"struct.skia::tracing_internals::ScopedTracer::Data"* %62, null
  br i1 %64, label %78, label %65

65:                                               ; preds = %61
  %66 = load i8*, i8** %22, align 8
  %67 = load i8, i8* %66, align 1
  %68 = icmp eq i8 %67, 0
  br i1 %68, label %78, label %69

69:                                               ; preds = %65
  %70 = call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %71 = load i8*, i8** %22, align 8
  %72 = load i8*, i8** %23, align 8
  %73 = load i64, i64* %24, align 8
  %74 = bitcast %class.SkEventTracer* %70 to void (%class.SkEventTracer*, i8*, i8*, i64)***
  %75 = load void (%class.SkEventTracer*, i8*, i8*, i64)**, void (%class.SkEventTracer*, i8*, i8*, i64)*** %74, align 8
  %76 = getelementptr inbounds void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %75, i64 5
  %77 = load void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %76, align 8
  call void %77(%class.SkEventTracer* %70, i8* %71, i8* %72, i64 %73) #14
  br label %78

78:                                               ; preds = %61, %65, %69
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %20) #14
  ret i1 %63
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN5GrGpu10readPixelsEP9GrSurface7SkIRect11GrColorTypeS3_Pvm(%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, i8*, i64) local_unnamed_addr #1 align 2 {
  %9 = alloca %"class.skia::tracing_internals::ScopedTracer", align 8
  %10 = lshr i64 %2, 32
  %11 = trunc i64 %3 to i32
  %12 = lshr i64 %3, 32
  %13 = trunc i64 %12 to i32
  %14 = load atomic i64, i64* @_ZZN5GrGpu10readPixelsEP9GrSurface7SkIRect11GrColorTypeS3_PvmE28trace_event_unique_atomic392.0.0 monotonic, align 8
  %15 = inttoptr i64 %14 to i8*
  %16 = icmp eq i64 %14, 0
  br i1 %16, label %17, label %25

17:                                               ; preds = %8
  %18 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %19 = bitcast %class.SkEventTracer* %18 to i8* (%class.SkEventTracer*, i8*)***
  %20 = load i8* (%class.SkEventTracer*, i8*)**, i8* (%class.SkEventTracer*, i8*)*** %19, align 8
  %21 = getelementptr inbounds i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %20, i64 2
  %22 = load i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %21, align 8
  %23 = tail call i8* %22(%class.SkEventTracer* %18, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str, i64 0, i64 0)) #14
  %24 = ptrtoint i8* %23 to i64
  store atomic i64 %24, i64* @_ZZN5GrGpu10readPixelsEP9GrSurface7SkIRect11GrColorTypeS3_PvmE28trace_event_unique_atomic392.0.0 monotonic, align 8
  br label %25

25:                                               ; preds = %8, %17
  %26 = phi i8* [ %15, %8 ], [ %23, %17 ]
  %27 = bitcast %"class.skia::tracing_internals::ScopedTracer"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %27) #14
  %28 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %9, i64 0, i32 0
  %29 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %9, i64 0, i32 1, i32 0
  %30 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %9, i64 0, i32 1, i32 1
  %31 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %9, i64 0, i32 1, i32 2
  %32 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %9, i64 0, i32 1
  %33 = bitcast %"struct.skia::tracing_internals::ScopedTracer::Data"* %32 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %33, i8 -86, i64 24, i1 false)
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* null, %"struct.skia::tracing_internals::ScopedTracer::Data"** %28, align 8
  %34 = load i8, i8* %26, align 1
  %35 = and i8 %34, 5
  %36 = icmp eq i8 %35, 0
  br i1 %36, label %46, label %37

37:                                               ; preds = %25
  %38 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %39 = bitcast %class.SkEventTracer* %38 to i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)***
  %40 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)**, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*** %39, align 8
  %41 = getelementptr inbounds i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %40, i64 4
  %42 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %41, align 8
  %43 = tail call i64 %42(%class.SkEventTracer* %38, i8 signext 88, i8* %26, i8* getelementptr inbounds ([87 x i8], [87 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu10readPixelsEP9GrSurface7SkIRect11GrColorTypeS3_Pvm, i64 0, i64 0), i64 0, i32 0, i8** null, i8* null, i64* null, i8 zeroext 0) #14
  %44 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %9, i64 0, i32 1
  %45 = getelementptr inbounds %"struct.skia::tracing_internals::ScopedTracer::Data", %"struct.skia::tracing_internals::ScopedTracer::Data"* %44, i64 0, i32 0
  store i8* %26, i8** %45, align 8
  store i8* getelementptr inbounds ([87 x i8], [87 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu10readPixelsEP9GrSurface7SkIRect11GrColorTypeS3_Pvm, i64 0, i64 0), i8** %30, align 8
  store i64 %43, i64* %31, align 8
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* %44, %"struct.skia::tracing_internals::ScopedTracer::Data"** %28, align 8
  br label %46

46:                                               ; preds = %25, %37
  %47 = phi %"struct.skia::tracing_internals::ScopedTracer::Data"* [ null, %25 ], [ %44, %37 ]
  %48 = getelementptr inbounds %class.GrSurface, %class.GrSurface* %1, i64 0, i32 1
  %49 = bitcast %struct.SkISize* %48 to i64*
  %50 = load i64, i64* %49, align 8
  %51 = lshr i64 %50, 32
  %52 = trunc i64 %51 to i32
  %53 = shl i64 %3, 32
  %54 = ashr exact i64 %53, 32
  %55 = shl i64 %2, 32
  %56 = ashr exact i64 %55, 32
  %57 = sub nsw i64 %54, %56
  %58 = ashr i64 %3, 32
  %59 = ashr i64 %2, 32
  %60 = sub nsw i64 %58, %59
  %61 = icmp slt i64 %57, 1
  %62 = icmp slt i64 %60, 1
  %63 = or i1 %62, %61
  br i1 %63, label %135, label %64

64:                                               ; preds = %46
  %65 = or i64 %57, %60
  %66 = add nsw i64 %65, 2147483648
  %67 = icmp ugt i64 %66, 4294967295
  br i1 %67, label %135, label %68

68:                                               ; preds = %64
  %69 = shl i64 %50, 32
  %70 = icmp slt i64 %69, 4294967296
  %71 = icmp slt i64 %50, 4294967296
  %72 = or i1 %71, %70
  br i1 %72, label %135, label %73

73:                                               ; preds = %68
  %74 = trunc i64 %50 to i32
  %75 = or i64 %69, %50
  %76 = ashr i64 %75, 32
  %77 = add nsw i64 %76, 2147483648
  %78 = icmp ugt i64 %77, 4294967295
  %79 = or i64 %10, %2
  %80 = trunc i64 %79 to i32
  %81 = icmp slt i32 %80, 0
  %82 = or i1 %81, %78
  %83 = icmp slt i32 %74, %11
  %84 = or i1 %83, %82
  %85 = icmp sge i32 %52, %13
  %86 = xor i1 %84, true
  %87 = and i1 %85, %86
  br i1 %87, label %88, label %135

88:                                               ; preds = %73
  %89 = icmp ult i32 %5, 31
  br i1 %89, label %91, label %90

90:                                               ; preds = %88
  call void @llvm.trap() #14
  unreachable

91:                                               ; preds = %88
  %92 = sext i32 %5 to i64
  %93 = getelementptr inbounds [31 x i64], [31 x i64]* @switch.table._ZN5GrGpu16transferPixelsToEP9GrTexture7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmm, i64 0, i64 %92
  %94 = load i64, i64* %93, align 8
  %95 = sub i64 %3, %2
  %96 = shl i64 %95, 32
  %97 = ashr exact i64 %96, 32
  %98 = mul nsw i64 %94, %97
  %99 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 2, i32 0
  %100 = load %class.GrCaps*, %class.GrCaps** %99, align 8
  %101 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %100, i64 0, i32 3
  %102 = bitcast i48* %101 to i64*
  %103 = load i64, i64* %102, align 8
  %104 = trunc i64 %103 to i32
  %105 = icmp slt i32 %104, 0
  br i1 %105, label %108, label %106

106:                                              ; preds = %91
  %107 = icmp eq i64 %98, %7
  br i1 %107, label %119, label %135

108:                                              ; preds = %91
  %109 = icmp ugt i64 %98, %7
  br i1 %109, label %135, label %110

110:                                              ; preds = %108
  %111 = icmp ult i32 %5, 31
  br i1 %111, label %113, label %112

112:                                              ; preds = %110
  call void @llvm.trap() #14
  unreachable

113:                                              ; preds = %110
  %114 = sext i32 %5 to i64
  %115 = getelementptr inbounds [31 x i64], [31 x i64]* @switch.table._ZN5GrGpu16transferPixelsToEP9GrTexture7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmm, i64 0, i64 %114
  %116 = load i64, i64* %115, align 8
  %117 = urem i64 %7, %116
  %118 = icmp eq i64 %117, 0
  br i1 %118, label %119, label %135

119:                                              ; preds = %113, %106
  %120 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 4
  %121 = load i32, i32* %120, align 8
  %122 = icmp eq i32 %121, 0
  br i1 %122, label %128, label %123

123:                                              ; preds = %119
  %124 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*, i32)***
  %125 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %124, align 8
  %126 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %125, i64 38
  %127 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %126, align 8
  call void %127(%class.GrGpu* %0, i32 %121) #14
  store i32 0, i32* %120, align 8
  br label %128

128:                                              ; preds = %119, %123
  %129 = bitcast %class.GrGpu* %0 to i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, i8*, i64)***
  %130 = load i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, i8*, i64)**, i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, i8*, i64)*** %129, align 8
  %131 = getelementptr inbounds i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, i8*, i64)*, i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, i8*, i64)** %130, i64 48
  %132 = load i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, i8*, i64)*, i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, i8*, i64)** %131, align 8
  %133 = call zeroext i1 %132(%class.GrGpu* %0, %class.GrSurface* %1, i64 %2, i64 %3, i32 %4, i32 %5, i8* %6, i64 %7) #14
  %134 = load %"struct.skia::tracing_internals::ScopedTracer::Data"*, %"struct.skia::tracing_internals::ScopedTracer::Data"** %28, align 8
  br label %135

135:                                              ; preds = %46, %64, %68, %128, %106, %108, %113, %73
  %136 = phi %"struct.skia::tracing_internals::ScopedTracer::Data"* [ %47, %73 ], [ %134, %128 ], [ %47, %106 ], [ %47, %108 ], [ %47, %113 ], [ %47, %68 ], [ %47, %64 ], [ %47, %46 ]
  %137 = phi i1 [ false, %73 ], [ %133, %128 ], [ false, %106 ], [ false, %108 ], [ false, %113 ], [ false, %68 ], [ false, %64 ], [ false, %46 ]
  %138 = icmp eq %"struct.skia::tracing_internals::ScopedTracer::Data"* %136, null
  br i1 %138, label %152, label %139

139:                                              ; preds = %135
  %140 = load i8*, i8** %29, align 8
  %141 = load i8, i8* %140, align 1
  %142 = icmp eq i8 %141, 0
  br i1 %142, label %152, label %143

143:                                              ; preds = %139
  %144 = call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %145 = load i8*, i8** %29, align 8
  %146 = load i8*, i8** %30, align 8
  %147 = load i64, i64* %31, align 8
  %148 = bitcast %class.SkEventTracer* %144 to void (%class.SkEventTracer*, i8*, i8*, i64)***
  %149 = load void (%class.SkEventTracer*, i8*, i8*, i64)**, void (%class.SkEventTracer*, i8*, i8*, i64)*** %148, align 8
  %150 = getelementptr inbounds void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %149, i64 5
  %151 = load void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %150, align 8
  call void %151(%class.SkEventTracer* %144, i8* %145, i8* %146, i64 %147) #14
  br label %152

152:                                              ; preds = %135, %139, %143
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %27) #14
  ret i1 %137
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZNK5GrGpu17didWriteToSurfaceEP9GrSurface15GrSurfaceOriginPK7SkIRectj(%class.GrGpu* nocapture readnone, %class.GrSurface*, i32, %struct.SkIRect* readonly, i32) local_unnamed_addr #1 align 2 {
  %6 = icmp eq %struct.SkIRect* %3, null
  br i1 %6, label %29, label %7

7:                                                ; preds = %5
  %8 = getelementptr inbounds %struct.SkIRect, %struct.SkIRect* %3, i64 0, i32 2
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds %struct.SkIRect, %struct.SkIRect* %3, i64 0, i32 0
  %12 = load i32, i32* %11, align 4
  %13 = sext i32 %12 to i64
  %14 = sub nsw i64 %10, %13
  %15 = getelementptr inbounds %struct.SkIRect, %struct.SkIRect* %3, i64 0, i32 3
  %16 = load i32, i32* %15, align 4
  %17 = sext i32 %16 to i64
  %18 = getelementptr inbounds %struct.SkIRect, %struct.SkIRect* %3, i64 0, i32 1
  %19 = load i32, i32* %18, align 4
  %20 = sext i32 %19 to i64
  %21 = sub nsw i64 %17, %20
  %22 = icmp slt i64 %14, 1
  %23 = icmp slt i64 %21, 1
  %24 = or i1 %22, %23
  br i1 %24, label %40, label %25

25:                                               ; preds = %7
  %26 = or i64 %21, %14
  %27 = add nsw i64 %26, 2147483648
  %28 = icmp ugt i64 %27, 4294967295
  br i1 %28, label %40, label %29

29:                                               ; preds = %25, %5
  %30 = bitcast %class.GrSurface* %1 to %class.GrTexture* (%class.GrSurface*)***
  %31 = load %class.GrTexture* (%class.GrSurface*)**, %class.GrTexture* (%class.GrSurface*)*** %30, align 8
  %32 = getelementptr inbounds %class.GrTexture* (%class.GrSurface*)*, %class.GrTexture* (%class.GrSurface*)** %31, i64 10
  %33 = load %class.GrTexture* (%class.GrSurface*)*, %class.GrTexture* (%class.GrSurface*)** %32, align 8
  %34 = tail call %class.GrTexture* %33(%class.GrSurface* %1) #14
  %35 = icmp eq %class.GrTexture* %34, null
  br i1 %35, label %40, label %36

36:                                               ; preds = %29
  %37 = icmp eq i32 %4, 1
  br i1 %37, label %38, label %39

38:                                               ; preds = %36
  tail call void @_ZN9GrTexture16markMipmapsDirtyEv(%class.GrTexture* nonnull %34) #14
  br label %40

39:                                               ; preds = %36
  tail call void @_ZN9GrTexture16markMipmapsCleanEv(%class.GrTexture* nonnull %34) #14
  br label %40

40:                                               ; preds = %7, %39, %38, %29, %25
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN5GrGpu16transferPixelsToEP9GrTexture7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmm(%class.GrGpu*, %class.GrTexture*, i64, i64, i32, i32, %class.sk_sp.251* nocapture, i64, i64) local_unnamed_addr #1 align 2 {
  %10 = alloca %"class.skia::tracing_internals::ScopedTracer", align 8
  %11 = alloca %class.sk_sp.251, align 8
  %12 = lshr i64 %2, 32
  %13 = trunc i64 %3 to i32
  %14 = lshr i64 %3, 32
  %15 = trunc i64 %14 to i32
  %16 = load atomic i64, i64* @_ZZN5GrGpu16transferPixelsToEP9GrTexture7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmmE28trace_event_unique_atomic475.0.0 monotonic, align 8
  %17 = inttoptr i64 %16 to i8*
  %18 = icmp eq i64 %16, 0
  br i1 %18, label %19, label %27

19:                                               ; preds = %9
  %20 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %21 = bitcast %class.SkEventTracer* %20 to i8* (%class.SkEventTracer*, i8*)***
  %22 = load i8* (%class.SkEventTracer*, i8*)**, i8* (%class.SkEventTracer*, i8*)*** %21, align 8
  %23 = getelementptr inbounds i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %22, i64 2
  %24 = load i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %23, align 8
  %25 = tail call i8* %24(%class.SkEventTracer* %20, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str, i64 0, i64 0)) #14
  %26 = ptrtoint i8* %25 to i64
  store atomic i64 %26, i64* @_ZZN5GrGpu16transferPixelsToEP9GrTexture7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmmE28trace_event_unique_atomic475.0.0 monotonic, align 8
  br label %27

27:                                               ; preds = %9, %19
  %28 = phi i8* [ %17, %9 ], [ %25, %19 ]
  %29 = bitcast %"class.skia::tracing_internals::ScopedTracer"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %29) #14
  %30 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %10, i64 0, i32 0
  %31 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %10, i64 0, i32 1, i32 0
  %32 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %10, i64 0, i32 1, i32 1
  %33 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %10, i64 0, i32 1, i32 2
  %34 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %10, i64 0, i32 1
  %35 = bitcast %"struct.skia::tracing_internals::ScopedTracer::Data"* %34 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %35, i8 -86, i64 24, i1 false)
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* null, %"struct.skia::tracing_internals::ScopedTracer::Data"** %30, align 8
  %36 = load i8, i8* %28, align 1
  %37 = and i8 %36, 5
  %38 = icmp eq i8 %37, 0
  br i1 %38, label %48, label %39

39:                                               ; preds = %27
  %40 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %41 = bitcast %class.SkEventTracer* %40 to i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)***
  %42 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)**, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*** %41, align 8
  %43 = getelementptr inbounds i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %42, i64 4
  %44 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %43, align 8
  %45 = tail call i64 %44(%class.SkEventTracer* %40, i8 signext 88, i8* %28, i8* getelementptr inbounds ([113 x i8], [113 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu16transferPixelsToEP9GrTexture7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmm, i64 0, i64 0), i64 0, i32 0, i8** null, i8* null, i64* null, i8 zeroext 0) #14
  %46 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %10, i64 0, i32 1
  %47 = getelementptr inbounds %"struct.skia::tracing_internals::ScopedTracer::Data", %"struct.skia::tracing_internals::ScopedTracer::Data"* %46, i64 0, i32 0
  store i8* %28, i8** %47, align 8
  store i8* getelementptr inbounds ([113 x i8], [113 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu16transferPixelsToEP9GrTexture7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmm, i64 0, i64 0), i8** %32, align 8
  store i64 %45, i64* %33, align 8
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* %46, %"struct.skia::tracing_internals::ScopedTracer::Data"** %30, align 8
  br label %48

48:                                               ; preds = %27, %39
  %49 = bitcast %class.GrTexture* %1 to i8**
  %50 = load i8*, i8** %49, align 8
  %51 = getelementptr i8, i8* %50, i64 -24
  %52 = bitcast i8* %51 to i64*
  %53 = load i64, i64* %52, align 8
  %54 = bitcast %class.GrTexture* %1 to i8*
  %55 = getelementptr inbounds i8, i8* %54, i64 %53
  %56 = getelementptr inbounds i8, i8* %55, i64 160
  %57 = bitcast i8* %56 to i32*
  %58 = load i32, i32* %57, align 8
  %59 = and i32 %58, 1
  %60 = icmp eq i32 %59, 0
  br i1 %60, label %61, label %176

61:                                               ; preds = %48
  %62 = getelementptr inbounds i8, i8* %55, i64 152
  %63 = bitcast i8* %62 to i64*
  %64 = load i64, i64* %63, align 8
  %65 = lshr i64 %64, 32
  %66 = trunc i64 %65 to i32
  %67 = shl i64 %3, 32
  %68 = ashr exact i64 %67, 32
  %69 = shl i64 %2, 32
  %70 = ashr exact i64 %69, 32
  %71 = sub nsw i64 %68, %70
  %72 = ashr i64 %3, 32
  %73 = ashr i64 %2, 32
  %74 = sub nsw i64 %72, %73
  %75 = icmp slt i64 %71, 1
  %76 = icmp slt i64 %74, 1
  %77 = or i1 %76, %75
  br i1 %77, label %176, label %78

78:                                               ; preds = %61
  %79 = or i64 %71, %74
  %80 = add nsw i64 %79, 2147483648
  %81 = icmp ugt i64 %80, 4294967295
  br i1 %81, label %176, label %82

82:                                               ; preds = %78
  %83 = shl i64 %64, 32
  %84 = icmp slt i64 %83, 4294967296
  %85 = icmp slt i64 %64, 4294967296
  %86 = or i1 %85, %84
  br i1 %86, label %176, label %87

87:                                               ; preds = %82
  %88 = trunc i64 %64 to i32
  %89 = or i64 %83, %64
  %90 = ashr i64 %89, 32
  %91 = add nsw i64 %90, 2147483648
  %92 = icmp ugt i64 %91, 4294967295
  %93 = or i64 %12, %2
  %94 = trunc i64 %93 to i32
  %95 = icmp slt i32 %94, 0
  %96 = or i1 %95, %92
  %97 = icmp slt i32 %88, %13
  %98 = or i1 %97, %96
  %99 = icmp sge i32 %66, %15
  %100 = xor i1 %98, true
  %101 = and i1 %99, %100
  br i1 %101, label %102, label %176

102:                                              ; preds = %87
  %103 = icmp ult i32 %5, 31
  br i1 %103, label %105, label %104

104:                                              ; preds = %102
  call void @llvm.trap() #14
  unreachable

105:                                              ; preds = %102
  %106 = sext i32 %5 to i64
  %107 = getelementptr inbounds [31 x i64], [31 x i64]* @switch.table._ZN5GrGpu16transferPixelsToEP9GrTexture7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmm, i64 0, i64 %106
  %108 = load i64, i64* %107, align 8
  %109 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 2, i32 0
  %110 = load %class.GrCaps*, %class.GrCaps** %109, align 8
  %111 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %110, i64 0, i32 3
  %112 = bitcast i48* %111 to i64*
  %113 = load i64, i64* %112, align 8
  %114 = and i64 %113, 1073741824
  %115 = icmp eq i64 %114, 0
  %116 = sub i64 %3, %2
  %117 = shl i64 %116, 32
  %118 = ashr exact i64 %117, 32
  %119 = mul nsw i64 %108, %118
  br i1 %115, label %125, label %120

120:                                              ; preds = %105
  %121 = icmp ugt i64 %119, %8
  br i1 %121, label %176, label %122

122:                                              ; preds = %120
  %123 = urem i64 %8, %108
  %124 = icmp eq i64 %123, 0
  br i1 %124, label %127, label %176

125:                                              ; preds = %105
  %126 = icmp eq i64 %119, %8
  br i1 %126, label %127, label %176

127:                                              ; preds = %122, %125
  %128 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 4
  %129 = load i32, i32* %128, align 8
  %130 = icmp eq i32 %129, 0
  br i1 %130, label %136, label %131

131:                                              ; preds = %127
  %132 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*, i32)***
  %133 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %132, align 8
  %134 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %133, i64 38
  %135 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %134, align 8
  call void %135(%class.GrGpu* %0, i32 %129) #14
  store i32 0, i32* %128, align 8
  br label %136

136:                                              ; preds = %127, %131
  %137 = getelementptr inbounds %class.sk_sp.251, %class.sk_sp.251* %6, i64 0, i32 0
  %138 = bitcast %class.sk_sp.251* %6 to i64*
  %139 = load i64, i64* %138, align 8
  store %class.GrGpuBuffer* null, %class.GrGpuBuffer** %137, align 8
  %140 = bitcast %class.sk_sp.251* %11 to i64*
  store i64 %139, i64* %140, align 8
  %141 = bitcast %class.GrGpu* %0 to i1 (%class.GrGpu*, %class.GrTexture*, i64, i64, i32, i32, %class.sk_sp.251*, i64, i64)***
  %142 = load i1 (%class.GrGpu*, %class.GrTexture*, i64, i64, i32, i32, %class.sk_sp.251*, i64, i64)**, i1 (%class.GrGpu*, %class.GrTexture*, i64, i64, i32, i32, %class.sk_sp.251*, i64, i64)*** %141, align 8
  %143 = getelementptr inbounds i1 (%class.GrGpu*, %class.GrTexture*, i64, i64, i32, i32, %class.sk_sp.251*, i64, i64)*, i1 (%class.GrGpu*, %class.GrTexture*, i64, i64, i32, i32, %class.sk_sp.251*, i64, i64)** %142, i64 50
  %144 = load i1 (%class.GrGpu*, %class.GrTexture*, i64, i64, i32, i32, %class.sk_sp.251*, i64, i64)*, i1 (%class.GrGpu*, %class.GrTexture*, i64, i64, i32, i32, %class.sk_sp.251*, i64, i64)** %143, align 8
  %145 = call zeroext i1 %144(%class.GrGpu* %0, %class.GrTexture* %1, i64 %2, i64 %3, i32 %4, i32 %5, %class.sk_sp.251* nonnull %11, i64 %7, i64 %8) #14
  %146 = getelementptr inbounds %class.sk_sp.251, %class.sk_sp.251* %11, i64 0, i32 0
  %147 = load %class.GrGpuBuffer*, %class.GrGpuBuffer** %146, align 8
  %148 = icmp eq %class.GrGpuBuffer* %147, null
  br i1 %148, label %157, label %149

149:                                              ; preds = %136
  %150 = getelementptr inbounds %class.GrGpuBuffer, %class.GrGpuBuffer* %147, i64 0, i32 0, i32 1
  %151 = getelementptr inbounds %class.GrIORef, %class.GrIORef* %150, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %152 = atomicrmw add i32* %151, i32 -1 acq_rel
  %153 = icmp eq i32 %152, 1
  br i1 %153, label %154, label %157

154:                                              ; preds = %149
  %155 = getelementptr inbounds %class.GrIORef, %class.GrIORef* %150, i64 -1
  %156 = bitcast %class.GrIORef* %155 to %class.GrGpuResource*
  call void @_ZNK13GrGpuResource19notifyARefCntIsZeroEN7GrIORefIS_E14LastRemovedRefE(%class.GrGpuResource* %156, i32 0) #14
  br label %157

157:                                              ; preds = %136, %149, %154
  br i1 %145, label %158, label %176

158:                                              ; preds = %157
  %159 = icmp eq %class.GrTexture* %1, null
  br i1 %159, label %167, label %160

160:                                              ; preds = %158
  %161 = load i8*, i8** %49, align 8
  %162 = getelementptr i8, i8* %161, i64 -24
  %163 = bitcast i8* %162 to i64*
  %164 = load i64, i64* %163, align 8
  %165 = getelementptr inbounds i8, i8* %54, i64 %164
  %166 = bitcast i8* %165 to %class.GrSurface*
  br label %167

167:                                              ; preds = %160, %158
  %168 = phi %class.GrSurface* [ %166, %160 ], [ null, %158 ]
  %169 = bitcast %class.GrSurface* %168 to %class.GrTexture* (%class.GrSurface*)***
  %170 = load %class.GrTexture* (%class.GrSurface*)**, %class.GrTexture* (%class.GrSurface*)*** %169, align 8
  %171 = getelementptr inbounds %class.GrTexture* (%class.GrSurface*)*, %class.GrTexture* (%class.GrSurface*)** %170, i64 10
  %172 = load %class.GrTexture* (%class.GrSurface*)*, %class.GrTexture* (%class.GrSurface*)** %171, align 8
  %173 = call %class.GrTexture* %172(%class.GrSurface* %168) #14
  %174 = icmp eq %class.GrTexture* %173, null
  br i1 %174, label %176, label %175

175:                                              ; preds = %167
  call void @_ZN9GrTexture16markMipmapsDirtyEv(%class.GrTexture* nonnull %173) #14
  br label %176

176:                                              ; preds = %48, %61, %78, %82, %175, %167, %120, %122, %125, %157, %87
  %177 = phi i1 [ false, %48 ], [ false, %87 ], [ false, %120 ], [ false, %122 ], [ false, %125 ], [ false, %157 ], [ true, %167 ], [ true, %175 ], [ false, %82 ], [ false, %78 ], [ false, %61 ]
  %178 = load %"struct.skia::tracing_internals::ScopedTracer::Data"*, %"struct.skia::tracing_internals::ScopedTracer::Data"** %30, align 8
  %179 = icmp eq %"struct.skia::tracing_internals::ScopedTracer::Data"* %178, null
  br i1 %179, label %193, label %180

180:                                              ; preds = %176
  %181 = load i8*, i8** %31, align 8
  %182 = load i8, i8* %181, align 1
  %183 = icmp eq i8 %182, 0
  br i1 %183, label %193, label %184

184:                                              ; preds = %180
  %185 = call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %186 = load i8*, i8** %31, align 8
  %187 = load i8*, i8** %32, align 8
  %188 = load i64, i64* %33, align 8
  %189 = bitcast %class.SkEventTracer* %185 to void (%class.SkEventTracer*, i8*, i8*, i64)***
  %190 = load void (%class.SkEventTracer*, i8*, i8*, i64)**, void (%class.SkEventTracer*, i8*, i8*, i64)*** %189, align 8
  %191 = getelementptr inbounds void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %190, i64 5
  %192 = load void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %191, align 8
  call void %192(%class.SkEventTracer* %185, i8* %186, i8* %187, i64 %188) #14
  br label %193

193:                                              ; preds = %176, %180, %184
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %29) #14
  ret i1 %177
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN5GrGpu18transferPixelsFromEP9GrSurface7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEm(%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %class.sk_sp.251* nocapture, i64) local_unnamed_addr #1 align 2 {
  %9 = alloca %"class.skia::tracing_internals::ScopedTracer", align 8
  %10 = alloca %class.sk_sp.251, align 8
  %11 = lshr i64 %2, 32
  %12 = trunc i64 %3 to i32
  %13 = lshr i64 %3, 32
  %14 = trunc i64 %13 to i32
  %15 = load atomic i64, i64* @_ZZN5GrGpu18transferPixelsFromEP9GrSurface7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmE28trace_event_unique_atomic524.0.0 monotonic, align 8
  %16 = inttoptr i64 %15 to i8*
  %17 = icmp eq i64 %15, 0
  br i1 %17, label %18, label %26

18:                                               ; preds = %8
  %19 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %20 = bitcast %class.SkEventTracer* %19 to i8* (%class.SkEventTracer*, i8*)***
  %21 = load i8* (%class.SkEventTracer*, i8*)**, i8* (%class.SkEventTracer*, i8*)*** %20, align 8
  %22 = getelementptr inbounds i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %21, i64 2
  %23 = load i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %22, align 8
  %24 = tail call i8* %23(%class.SkEventTracer* %19, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str, i64 0, i64 0)) #14
  %25 = ptrtoint i8* %24 to i64
  store atomic i64 %25, i64* @_ZZN5GrGpu18transferPixelsFromEP9GrSurface7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEmE28trace_event_unique_atomic524.0.0 monotonic, align 8
  br label %26

26:                                               ; preds = %8, %18
  %27 = phi i8* [ %16, %8 ], [ %24, %18 ]
  %28 = bitcast %"class.skia::tracing_internals::ScopedTracer"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %28) #14
  %29 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %9, i64 0, i32 0
  %30 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %9, i64 0, i32 1, i32 0
  %31 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %9, i64 0, i32 1, i32 1
  %32 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %9, i64 0, i32 1, i32 2
  %33 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %9, i64 0, i32 1
  %34 = bitcast %"struct.skia::tracing_internals::ScopedTracer::Data"* %33 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* null, %"struct.skia::tracing_internals::ScopedTracer::Data"** %29, align 8
  %35 = load i8, i8* %27, align 1
  %36 = and i8 %35, 5
  %37 = icmp eq i8 %36, 0
  br i1 %37, label %47, label %38

38:                                               ; preds = %26
  %39 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %40 = bitcast %class.SkEventTracer* %39 to i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)***
  %41 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)**, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*** %40, align 8
  %42 = getelementptr inbounds i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %41, i64 4
  %43 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %42, align 8
  %44 = tail call i64 %43(%class.SkEventTracer* %39, i8 signext 88, i8* %27, i8* getelementptr inbounds ([107 x i8], [107 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu18transferPixelsFromEP9GrSurface7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEm, i64 0, i64 0), i64 0, i32 0, i8** null, i8* null, i64* null, i8 zeroext 0) #14
  %45 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %9, i64 0, i32 1
  %46 = getelementptr inbounds %"struct.skia::tracing_internals::ScopedTracer::Data", %"struct.skia::tracing_internals::ScopedTracer::Data"* %45, i64 0, i32 0
  store i8* %27, i8** %46, align 8
  store i8* getelementptr inbounds ([107 x i8], [107 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu18transferPixelsFromEP9GrSurface7SkIRect11GrColorTypeS3_5sk_spI11GrGpuBufferEm, i64 0, i64 0), i8** %31, align 8
  store i64 %44, i64* %32, align 8
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* %45, %"struct.skia::tracing_internals::ScopedTracer::Data"** %29, align 8
  br label %47

47:                                               ; preds = %26, %38
  %48 = getelementptr inbounds %class.GrSurface, %class.GrSurface* %1, i64 0, i32 1
  %49 = bitcast %struct.SkISize* %48 to i64*
  %50 = load i64, i64* %49, align 8
  %51 = lshr i64 %50, 32
  %52 = trunc i64 %51 to i32
  %53 = shl i64 %3, 32
  %54 = ashr exact i64 %53, 32
  %55 = shl i64 %2, 32
  %56 = ashr exact i64 %55, 32
  %57 = sub nsw i64 %54, %56
  %58 = ashr i64 %3, 32
  %59 = ashr i64 %2, 32
  %60 = sub nsw i64 %58, %59
  %61 = icmp slt i64 %57, 1
  %62 = icmp slt i64 %60, 1
  %63 = or i1 %62, %61
  br i1 %63, label %118, label %64

64:                                               ; preds = %47
  %65 = or i64 %57, %60
  %66 = add nsw i64 %65, 2147483648
  %67 = icmp ugt i64 %66, 4294967295
  br i1 %67, label %118, label %68

68:                                               ; preds = %64
  %69 = shl i64 %50, 32
  %70 = icmp slt i64 %69, 4294967296
  %71 = icmp slt i64 %50, 4294967296
  %72 = or i1 %71, %70
  br i1 %72, label %118, label %73

73:                                               ; preds = %68
  %74 = trunc i64 %50 to i32
  %75 = or i64 %69, %50
  %76 = ashr i64 %75, 32
  %77 = add nsw i64 %76, 2147483648
  %78 = icmp ugt i64 %77, 4294967295
  %79 = or i64 %11, %2
  %80 = trunc i64 %79 to i32
  %81 = icmp slt i32 %80, 0
  %82 = or i1 %81, %78
  %83 = icmp slt i32 %74, %12
  %84 = or i1 %83, %82
  %85 = icmp sge i32 %52, %14
  %86 = xor i1 %84, true
  %87 = and i1 %85, %86
  br i1 %87, label %88, label %118

88:                                               ; preds = %73
  %89 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 4
  %90 = load i32, i32* %89, align 8
  %91 = icmp eq i32 %90, 0
  br i1 %91, label %97, label %92

92:                                               ; preds = %88
  %93 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*, i32)***
  %94 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %93, align 8
  %95 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %94, i64 38
  %96 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %95, align 8
  call void %96(%class.GrGpu* %0, i32 %90) #14
  store i32 0, i32* %89, align 8
  br label %97

97:                                               ; preds = %88, %92
  %98 = getelementptr inbounds %class.sk_sp.251, %class.sk_sp.251* %6, i64 0, i32 0
  %99 = bitcast %class.sk_sp.251* %6 to i64*
  %100 = load i64, i64* %99, align 8
  store %class.GrGpuBuffer* null, %class.GrGpuBuffer** %98, align 8
  %101 = bitcast %class.sk_sp.251* %10 to i64*
  store i64 %100, i64* %101, align 8
  %102 = bitcast %class.GrGpu* %0 to i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %class.sk_sp.251*, i64)***
  %103 = load i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %class.sk_sp.251*, i64)**, i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %class.sk_sp.251*, i64)*** %102, align 8
  %104 = getelementptr inbounds i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %class.sk_sp.251*, i64)*, i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %class.sk_sp.251*, i64)** %103, i64 51
  %105 = load i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %class.sk_sp.251*, i64)*, i1 (%class.GrGpu*, %class.GrSurface*, i64, i64, i32, i32, %class.sk_sp.251*, i64)** %104, align 8
  %106 = call zeroext i1 %105(%class.GrGpu* %0, %class.GrSurface* %1, i64 %2, i64 %3, i32 %4, i32 %5, %class.sk_sp.251* nonnull %10, i64 %7) #14
  %107 = getelementptr inbounds %class.sk_sp.251, %class.sk_sp.251* %10, i64 0, i32 0
  %108 = load %class.GrGpuBuffer*, %class.GrGpuBuffer** %107, align 8
  %109 = icmp eq %class.GrGpuBuffer* %108, null
  br i1 %109, label %118, label %110

110:                                              ; preds = %97
  %111 = getelementptr inbounds %class.GrGpuBuffer, %class.GrGpuBuffer* %108, i64 0, i32 0, i32 1
  %112 = getelementptr inbounds %class.GrIORef, %class.GrIORef* %111, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %113 = atomicrmw add i32* %112, i32 -1 acq_rel
  %114 = icmp eq i32 %113, 1
  br i1 %114, label %115, label %118

115:                                              ; preds = %110
  %116 = getelementptr inbounds %class.GrIORef, %class.GrIORef* %111, i64 -1
  %117 = bitcast %class.GrIORef* %116 to %class.GrGpuResource*
  call void @_ZNK13GrGpuResource19notifyARefCntIsZeroEN7GrIORefIS_E14LastRemovedRefE(%class.GrGpuResource* %117, i32 0) #14
  br label %118

118:                                              ; preds = %115, %110, %97, %47, %64, %68, %73
  %119 = phi i1 [ false, %73 ], [ false, %68 ], [ false, %64 ], [ false, %47 ], [ %106, %97 ], [ %106, %110 ], [ %106, %115 ]
  %120 = load %"struct.skia::tracing_internals::ScopedTracer::Data"*, %"struct.skia::tracing_internals::ScopedTracer::Data"** %29, align 8
  %121 = icmp eq %"struct.skia::tracing_internals::ScopedTracer::Data"* %120, null
  br i1 %121, label %135, label %122

122:                                              ; preds = %118
  %123 = load i8*, i8** %30, align 8
  %124 = load i8, i8* %123, align 1
  %125 = icmp eq i8 %124, 0
  br i1 %125, label %135, label %126

126:                                              ; preds = %122
  %127 = call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %128 = load i8*, i8** %30, align 8
  %129 = load i8*, i8** %31, align 8
  %130 = load i64, i64* %32, align 8
  %131 = bitcast %class.SkEventTracer* %127 to void (%class.SkEventTracer*, i8*, i8*, i64)***
  %132 = load void (%class.SkEventTracer*, i8*, i8*, i64)**, void (%class.SkEventTracer*, i8*, i8*, i64)*** %131, align 8
  %133 = getelementptr inbounds void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %132, i64 5
  %134 = load void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %133, align 8
  call void %134(%class.SkEventTracer* %127, i8* %128, i8* %129, i64 %130) #14
  br label %135

135:                                              ; preds = %118, %122, %126
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %28) #14
  ret i1 %119
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN5GrGpu22regenerateMipMapLevelsEP9GrTexture(%class.GrGpu*, %class.GrTexture*) local_unnamed_addr #1 align 2 {
  %3 = alloca %"class.skia::tracing_internals::ScopedTracer", align 8
  %4 = load atomic i64, i64* @_ZZN5GrGpu22regenerateMipMapLevelsEP9GrTextureE28trace_event_unique_atomic555.0.0 monotonic, align 8
  %5 = inttoptr i64 %4 to i8*
  %6 = icmp eq i64 %4, 0
  br i1 %6, label %7, label %15

7:                                                ; preds = %2
  %8 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %9 = bitcast %class.SkEventTracer* %8 to i8* (%class.SkEventTracer*, i8*)***
  %10 = load i8* (%class.SkEventTracer*, i8*)**, i8* (%class.SkEventTracer*, i8*)*** %9, align 8
  %11 = getelementptr inbounds i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %10, i64 2
  %12 = load i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %11, align 8
  %13 = tail call i8* %12(%class.SkEventTracer* %8, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str, i64 0, i64 0)) #14
  %14 = ptrtoint i8* %13 to i64
  store atomic i64 %14, i64* @_ZZN5GrGpu22regenerateMipMapLevelsEP9GrTextureE28trace_event_unique_atomic555.0.0 monotonic, align 8
  br label %15

15:                                               ; preds = %2, %7
  %16 = phi i8* [ %5, %2 ], [ %13, %7 ]
  %17 = bitcast %"class.skia::tracing_internals::ScopedTracer"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %17) #14
  %18 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %3, i64 0, i32 0
  %19 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %3, i64 0, i32 1, i32 0
  %20 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %3, i64 0, i32 1, i32 1
  %21 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %3, i64 0, i32 1, i32 2
  %22 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %3, i64 0, i32 1
  %23 = bitcast %"struct.skia::tracing_internals::ScopedTracer::Data"* %22 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %23, i8 -86, i64 24, i1 false)
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* null, %"struct.skia::tracing_internals::ScopedTracer::Data"** %18, align 8
  %24 = load i8, i8* %16, align 1
  %25 = and i8 %24, 5
  %26 = icmp eq i8 %25, 0
  br i1 %26, label %36, label %27

27:                                               ; preds = %15
  %28 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %29 = bitcast %class.SkEventTracer* %28 to i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)***
  %30 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)**, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*** %29, align 8
  %31 = getelementptr inbounds i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %30, i64 4
  %32 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %31, align 8
  %33 = tail call i64 %32(%class.SkEventTracer* %28, i8 signext 88, i8* %16, i8* getelementptr inbounds ([48 x i8], [48 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu22regenerateMipMapLevelsEP9GrTexture, i64 0, i64 0), i64 0, i32 0, i8** null, i8* null, i64* null, i8 zeroext 0) #14
  %34 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %3, i64 0, i32 1
  %35 = getelementptr inbounds %"struct.skia::tracing_internals::ScopedTracer::Data", %"struct.skia::tracing_internals::ScopedTracer::Data"* %34, i64 0, i32 0
  store i8* %16, i8** %35, align 8
  store i8* getelementptr inbounds ([48 x i8], [48 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu22regenerateMipMapLevelsEP9GrTexture, i64 0, i64 0), i8** %20, align 8
  store i64 %33, i64* %21, align 8
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* %34, %"struct.skia::tracing_internals::ScopedTracer::Data"** %18, align 8
  br label %36

36:                                               ; preds = %15, %27
  %37 = getelementptr inbounds %class.GrTexture, %class.GrTexture* %1, i64 0, i32 2
  %38 = load i32, i32* %37, align 4
  %39 = icmp eq i32 %38, 2
  br i1 %39, label %60, label %40

40:                                               ; preds = %36
  %41 = bitcast %class.GrTexture* %1 to i8**
  %42 = load i8*, i8** %41, align 8
  %43 = getelementptr i8, i8* %42, i64 -24
  %44 = bitcast i8* %43 to i64*
  %45 = load i64, i64* %44, align 8
  %46 = bitcast %class.GrTexture* %1 to i8*
  %47 = getelementptr inbounds i8, i8* %46, i64 %45
  %48 = getelementptr inbounds i8, i8* %47, i64 160
  %49 = bitcast i8* %48 to i32*
  %50 = load i32, i32* %49, align 8
  %51 = and i32 %50, 1
  %52 = icmp eq i32 %51, 0
  br i1 %52, label %53, label %60

53:                                               ; preds = %40
  %54 = bitcast %class.GrGpu* %0 to i1 (%class.GrGpu*, %class.GrTexture*)***
  %55 = load i1 (%class.GrGpu*, %class.GrTexture*)**, i1 (%class.GrGpu*, %class.GrTexture*)*** %54, align 8
  %56 = getelementptr inbounds i1 (%class.GrGpu*, %class.GrTexture*)*, i1 (%class.GrGpu*, %class.GrTexture*)** %55, i64 53
  %57 = load i1 (%class.GrGpu*, %class.GrTexture*)*, i1 (%class.GrGpu*, %class.GrTexture*)** %56, align 8
  %58 = call zeroext i1 %57(%class.GrGpu* %0, %class.GrTexture* %1) #14
  br i1 %58, label %59, label %60

59:                                               ; preds = %53
  call void @_ZN9GrTexture16markMipmapsCleanEv(%class.GrTexture* %1) #14
  br label %60

60:                                               ; preds = %40, %36, %53, %59
  %61 = phi i1 [ true, %59 ], [ true, %36 ], [ false, %40 ], [ false, %53 ]
  %62 = load %"struct.skia::tracing_internals::ScopedTracer::Data"*, %"struct.skia::tracing_internals::ScopedTracer::Data"** %18, align 8
  %63 = icmp eq %"struct.skia::tracing_internals::ScopedTracer::Data"* %62, null
  br i1 %63, label %77, label %64

64:                                               ; preds = %60
  %65 = load i8*, i8** %19, align 8
  %66 = load i8, i8* %65, align 1
  %67 = icmp eq i8 %66, 0
  br i1 %67, label %77, label %68

68:                                               ; preds = %64
  %69 = call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %70 = load i8*, i8** %19, align 8
  %71 = load i8*, i8** %20, align 8
  %72 = load i64, i64* %21, align 8
  %73 = bitcast %class.SkEventTracer* %69 to void (%class.SkEventTracer*, i8*, i8*, i64)***
  %74 = load void (%class.SkEventTracer*, i8*, i8*, i64)**, void (%class.SkEventTracer*, i8*, i8*, i64)*** %73, align 8
  %75 = getelementptr inbounds void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %74, i64 5
  %76 = load void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %75, align 8
  call void %76(%class.SkEventTracer* %69, i8* %70, i8* %71, i64 %72) #14
  br label %77

77:                                               ; preds = %60, %64, %68
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %17) #14
  ret i1 %61
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu20resetTextureBindingsEv(%class.GrGpu*) local_unnamed_addr #1 align 2 {
  %2 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 4
  %3 = load i32, i32* %2, align 8
  %4 = icmp eq i32 %3, 0
  br i1 %4, label %10, label %5

5:                                                ; preds = %1
  %6 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*, i32)***
  %7 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %6, align 8
  %8 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %7, i64 38
  %9 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %8, align 8
  tail call void %9(%class.GrGpu* %0, i32 %3) #14
  store i32 0, i32* %2, align 8
  br label %10

10:                                               ; preds = %1, %5
  %11 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*)***
  %12 = load void (%class.GrGpu*)**, void (%class.GrGpu*)*** %11, align 8
  %13 = getelementptr inbounds void (%class.GrGpu*)*, void (%class.GrGpu*)** %12, i64 39
  %14 = load void (%class.GrGpu*)*, void (%class.GrGpu*)** %13, align 8
  tail call void %14(%class.GrGpu* %0) #14
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu19resolveRenderTargetEP14GrRenderTargetRK7SkIRect(%class.GrGpu*, %class.GrRenderTarget*, %struct.SkIRect* dereferenceable(16)) local_unnamed_addr #1 align 2 {
  %4 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 4
  %5 = load i32, i32* %4, align 8
  %6 = icmp eq i32 %5, 0
  br i1 %6, label %12, label %7

7:                                                ; preds = %3
  %8 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*, i32)***
  %9 = load void (%class.GrGpu*, i32)**, void (%class.GrGpu*, i32)*** %8, align 8
  %10 = getelementptr inbounds void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %9, i64 38
  %11 = load void (%class.GrGpu*, i32)*, void (%class.GrGpu*, i32)** %10, align 8
  tail call void %11(%class.GrGpu* %0, i32 %5) #14
  store i32 0, i32* %4, align 8
  br label %12

12:                                               ; preds = %3, %7
  %13 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*, %class.GrRenderTarget*, %struct.SkIRect*)***
  %14 = load void (%class.GrGpu*, %class.GrRenderTarget*, %struct.SkIRect*)**, void (%class.GrGpu*, %class.GrRenderTarget*, %struct.SkIRect*)*** %13, align 8
  %15 = getelementptr inbounds void (%class.GrGpu*, %class.GrRenderTarget*, %struct.SkIRect*)*, void (%class.GrGpu*, %class.GrRenderTarget*, %struct.SkIRect*)** %14, i64 52
  %16 = load void (%class.GrGpu*, %class.GrRenderTarget*, %struct.SkIRect*)*, void (%class.GrGpu*, %class.GrRenderTarget*, %struct.SkIRect*)** %15, align 8
  tail call void %16(%class.GrGpu* %0, %class.GrRenderTarget* %1, %struct.SkIRect* dereferenceable(16) %2) #14
  ret void
}

declare void @_ZN9GrTexture16markMipmapsDirtyEv(%class.GrTexture*) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu16executeFlushInfoE6SkSpanIP14GrSurfaceProxyEN9SkSurface20BackendSurfaceAccessERK11GrFlushInfoPK28GrBackendSurfaceMutableState(%class.GrGpu*, %class.GrSurfaceProxy**, i64, i32, %struct.GrFlushInfo* nocapture readonly dereferenceable(48), %class.GrBackendSurfaceMutableState*) local_unnamed_addr #1 align 2 {
  %7 = alloca %"class.skia::tracing_internals::ScopedTracer", align 8
  %8 = alloca %class.GrBackendSemaphore, align 8
  %9 = load atomic i64, i64* @_ZZN5GrGpu16executeFlushInfoE6SkSpanIP14GrSurfaceProxyEN9SkSurface20BackendSurfaceAccessERK11GrFlushInfoPK28GrBackendSurfaceMutableStateE28trace_event_unique_atomic608.0.0 monotonic, align 8
  %10 = inttoptr i64 %9 to i8*
  %11 = icmp eq i64 %9, 0
  br i1 %11, label %12, label %20

12:                                               ; preds = %6
  %13 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %14 = bitcast %class.SkEventTracer* %13 to i8* (%class.SkEventTracer*, i8*)***
  %15 = load i8* (%class.SkEventTracer*, i8*)**, i8* (%class.SkEventTracer*, i8*)*** %14, align 8
  %16 = getelementptr inbounds i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %15, i64 2
  %17 = load i8* (%class.SkEventTracer*, i8*)*, i8* (%class.SkEventTracer*, i8*)** %16, align 8
  %18 = tail call i8* %17(%class.SkEventTracer* %13, i8* getelementptr inbounds ([29 x i8], [29 x i8]* @.str, i64 0, i64 0)) #14
  %19 = ptrtoint i8* %18 to i64
  store atomic i64 %19, i64* @_ZZN5GrGpu16executeFlushInfoE6SkSpanIP14GrSurfaceProxyEN9SkSurface20BackendSurfaceAccessERK11GrFlushInfoPK28GrBackendSurfaceMutableStateE28trace_event_unique_atomic608.0.0 monotonic, align 8
  br label %20

20:                                               ; preds = %6, %12
  %21 = phi i8* [ %10, %6 ], [ %18, %12 ]
  %22 = bitcast %"class.skia::tracing_internals::ScopedTracer"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %22) #14
  %23 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %7, i64 0, i32 0
  %24 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %7, i64 0, i32 1, i32 0
  %25 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %7, i64 0, i32 1, i32 1
  %26 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %7, i64 0, i32 1, i32 2
  %27 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %7, i64 0, i32 1
  %28 = bitcast %"struct.skia::tracing_internals::ScopedTracer::Data"* %27 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %28, i8 -86, i64 24, i1 false)
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* null, %"struct.skia::tracing_internals::ScopedTracer::Data"** %23, align 8
  %29 = load i8, i8* %21, align 1
  %30 = and i8 %29, 5
  %31 = icmp eq i8 %30, 0
  br i1 %31, label %41, label %32

32:                                               ; preds = %20
  %33 = tail call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %34 = bitcast %class.SkEventTracer* %33 to i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)***
  %35 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)**, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*** %34, align 8
  %36 = getelementptr inbounds i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %35, i64 4
  %37 = load i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)*, i64 (%class.SkEventTracer*, i8, i8*, i8*, i64, i32, i8**, i8*, i64*, i8)** %36, align 8
  %38 = tail call i64 %37(%class.SkEventTracer* %33, i8 signext 88, i8* %21, i8* getelementptr inbounds ([147 x i8], [147 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu16executeFlushInfoE6SkSpanIP14GrSurfaceProxyEN9SkSurface20BackendSurfaceAccessERK11GrFlushInfoPK28GrBackendSurfaceMutableState, i64 0, i64 0), i64 0, i32 0, i8** null, i8* null, i64* null, i8 zeroext 0) #14
  %39 = getelementptr inbounds %"class.skia::tracing_internals::ScopedTracer", %"class.skia::tracing_internals::ScopedTracer"* %7, i64 0, i32 1
  %40 = getelementptr inbounds %"struct.skia::tracing_internals::ScopedTracer::Data", %"struct.skia::tracing_internals::ScopedTracer::Data"* %39, i64 0, i32 0
  store i8* %21, i8** %40, align 8
  store i8* getelementptr inbounds ([147 x i8], [147 x i8]* @__PRETTY_FUNCTION__._ZN5GrGpu16executeFlushInfoE6SkSpanIP14GrSurfaceProxyEN9SkSurface20BackendSurfaceAccessERK11GrFlushInfoPK28GrBackendSurfaceMutableState, i64 0, i64 0), i8** %25, align 8
  store i64 %38, i64* %26, align 8
  store %"struct.skia::tracing_internals::ScopedTracer::Data"* %39, %"struct.skia::tracing_internals::ScopedTracer::Data"** %23, align 8
  br label %41

41:                                               ; preds = %20, %32
  %42 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 5
  %43 = load %class.GrDirectContext*, %class.GrDirectContext** %42, align 8
  %44 = getelementptr inbounds %class.GrDirectContext, %class.GrDirectContext* %43, i64 0, i32 6, i32 0, i32 0, i32 0
  %45 = load %class.GrResourceProvider*, %class.GrResourceProvider** %44, align 8
  %46 = getelementptr inbounds %struct.GrFlushInfo, %struct.GrFlushInfo* %4, i64 0, i32 0
  %47 = load i32, i32* %46, align 8
  %48 = sext i32 %47 to i64
  %49 = call { i64, i1 } @llvm.umul.with.overflow.i64(i64 %48, i64 8)
  %50 = extractvalue { i64, i1 } %49, 1
  %51 = extractvalue { i64, i1 } %49, 0
  %52 = call { i64, i1 } @llvm.uadd.with.overflow.i64(i64 %51, i64 8)
  %53 = extractvalue { i64, i1 } %52, 1
  %54 = or i1 %50, %53
  %55 = extractvalue { i64, i1 } %52, 0
  %56 = select i1 %54, i64 -1, i64 %55
  %57 = call i8* @_Znam(i64 %56) #16
  %58 = bitcast i8* %57 to i64*
  store i64 %48, i64* %58, align 8
  %59 = getelementptr inbounds i8, i8* %57, i64 8
  %60 = bitcast i8* %59 to %"class.std::__1::unique_ptr.264"*
  %61 = icmp eq i32 %47, 0
  br i1 %61, label %64, label %62

62:                                               ; preds = %41
  %63 = shl nsw i64 %48, 3
  call void @llvm.memset.p0i8.i64(i8* align 8 %59, i8 0, i64 %63, i1 false)
  br label %64

64:                                               ; preds = %62, %41
  %65 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 2, i32 0
  %66 = load %class.GrCaps*, %class.GrCaps** %65, align 8
  %67 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %66, i64 0, i32 3
  %68 = bitcast i48* %67 to i64*
  %69 = load i64, i64* %68, align 8
  %70 = and i64 %69, 8796093022208
  %71 = icmp ne i64 %70, 0
  %72 = icmp sgt i32 %47, 0
  %73 = and i1 %72, %71
  br i1 %73, label %74, label %140

74:                                               ; preds = %64
  %75 = getelementptr inbounds %struct.GrFlushInfo, %struct.GrFlushInfo* %4, i64 0, i32 1
  %76 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*, %class.GrSemaphore*)***
  %77 = bitcast %class.GrBackendSemaphore* %8 to i8*
  br label %78

78:                                               ; preds = %74, %135
  %79 = phi i64 [ 0, %74 ], [ %136, %135 ]
  %80 = load %class.GrBackendSemaphore*, %class.GrBackendSemaphore** %75, align 8
  %81 = getelementptr inbounds %class.GrBackendSemaphore, %class.GrBackendSemaphore* %80, i64 %79, i32 4
  %82 = load i8, i8* %81, align 8, !range !7
  %83 = icmp eq i8 %82, 0
  br i1 %83, label %106, label %84

84:                                               ; preds = %78
  %85 = getelementptr inbounds %class.GrBackendSemaphore, %class.GrBackendSemaphore* %80, i64 %79
  %86 = call %class.GrSemaphore* @_ZN18GrResourceProvider20wrapBackendSemaphoreERK18GrBackendSemaphoreNS_17SemaphoreWrapTypeE15GrWrapOwnership(%class.GrResourceProvider* %45, %class.GrBackendSemaphore* dereferenceable(32) %85, i32 0, i32 0) #14
  %87 = ptrtoint %class.GrSemaphore* %86 to i64
  %88 = getelementptr inbounds %"class.std::__1::unique_ptr.264", %"class.std::__1::unique_ptr.264"* %60, i64 %79
  %89 = getelementptr inbounds %"class.std::__1::unique_ptr.264", %"class.std::__1::unique_ptr.264"* %88, i64 0, i32 0, i32 0, i32 0
  %90 = load %class.GrSemaphore*, %class.GrSemaphore** %89, align 8
  %91 = bitcast %"class.std::__1::unique_ptr.264"* %88 to i64*
  store i64 %87, i64* %91, align 8
  %92 = icmp eq %class.GrSemaphore* %90, null
  br i1 %92, label %99, label %93

93:                                               ; preds = %84
  %94 = bitcast %class.GrSemaphore* %90 to void (%class.GrSemaphore*)***
  %95 = load void (%class.GrSemaphore*)**, void (%class.GrSemaphore*)*** %94, align 8
  %96 = getelementptr inbounds void (%class.GrSemaphore*)*, void (%class.GrSemaphore*)** %95, i64 1
  %97 = load void (%class.GrSemaphore*)*, void (%class.GrSemaphore*)** %96, align 8
  call void %97(%class.GrSemaphore* nonnull %90) #14
  %98 = load %class.GrSemaphore*, %class.GrSemaphore** %89, align 8
  br label %99

99:                                               ; preds = %93, %84
  %100 = phi %class.GrSemaphore* [ %98, %93 ], [ %86, %84 ]
  %101 = icmp eq %class.GrSemaphore* %100, null
  br i1 %101, label %135, label %102

102:                                              ; preds = %99
  %103 = load void (%class.GrGpu*, %class.GrSemaphore*)**, void (%class.GrGpu*, %class.GrSemaphore*)*** %76, align 8
  %104 = getelementptr inbounds void (%class.GrGpu*, %class.GrSemaphore*)*, void (%class.GrGpu*, %class.GrSemaphore*)** %103, i64 15
  %105 = load void (%class.GrGpu*, %class.GrSemaphore*)*, void (%class.GrGpu*, %class.GrSemaphore*)** %104, align 8
  call void %105(%class.GrGpu* %0, %class.GrSemaphore* nonnull %100) #14
  br label %135

106:                                              ; preds = %78
  %107 = call %class.GrSemaphore* @_ZN18GrResourceProvider13makeSemaphoreEb(%class.GrResourceProvider* %45, i1 zeroext false) #14
  %108 = ptrtoint %class.GrSemaphore* %107 to i64
  %109 = getelementptr inbounds %"class.std::__1::unique_ptr.264", %"class.std::__1::unique_ptr.264"* %60, i64 %79
  %110 = getelementptr inbounds %"class.std::__1::unique_ptr.264", %"class.std::__1::unique_ptr.264"* %109, i64 0, i32 0, i32 0, i32 0
  %111 = load %class.GrSemaphore*, %class.GrSemaphore** %110, align 8
  %112 = bitcast %"class.std::__1::unique_ptr.264"* %109 to i64*
  store i64 %108, i64* %112, align 8
  %113 = icmp eq %class.GrSemaphore* %111, null
  br i1 %113, label %120, label %114

114:                                              ; preds = %106
  %115 = bitcast %class.GrSemaphore* %111 to void (%class.GrSemaphore*)***
  %116 = load void (%class.GrSemaphore*)**, void (%class.GrSemaphore*)*** %115, align 8
  %117 = getelementptr inbounds void (%class.GrSemaphore*)*, void (%class.GrSemaphore*)** %116, i64 1
  %118 = load void (%class.GrSemaphore*)*, void (%class.GrSemaphore*)** %117, align 8
  call void %118(%class.GrSemaphore* nonnull %111) #14
  %119 = load %class.GrSemaphore*, %class.GrSemaphore** %110, align 8
  br label %120

120:                                              ; preds = %114, %106
  %121 = phi %class.GrSemaphore* [ %119, %114 ], [ %107, %106 ]
  %122 = icmp eq %class.GrSemaphore* %121, null
  br i1 %122, label %135, label %123

123:                                              ; preds = %120
  %124 = load void (%class.GrGpu*, %class.GrSemaphore*)**, void (%class.GrGpu*, %class.GrSemaphore*)*** %76, align 8
  %125 = getelementptr inbounds void (%class.GrGpu*, %class.GrSemaphore*)*, void (%class.GrGpu*, %class.GrSemaphore*)** %124, i64 15
  %126 = load void (%class.GrGpu*, %class.GrSemaphore*)*, void (%class.GrGpu*, %class.GrSemaphore*)** %125, align 8
  call void %126(%class.GrGpu* %0, %class.GrSemaphore* nonnull %121) #14
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %77) #14
  %127 = load %class.GrSemaphore*, %class.GrSemaphore** %110, align 8
  %128 = bitcast %class.GrSemaphore* %127 to void (%class.GrBackendSemaphore*, %class.GrSemaphore*)***
  %129 = load void (%class.GrBackendSemaphore*, %class.GrSemaphore*)**, void (%class.GrBackendSemaphore*, %class.GrSemaphore*)*** %128, align 8
  %130 = getelementptr inbounds void (%class.GrBackendSemaphore*, %class.GrSemaphore*)*, void (%class.GrBackendSemaphore*, %class.GrSemaphore*)** %129, i64 2
  %131 = load void (%class.GrBackendSemaphore*, %class.GrSemaphore*)*, void (%class.GrBackendSemaphore*, %class.GrSemaphore*)** %130, align 8
  call void %131(%class.GrBackendSemaphore* nonnull sret %8, %class.GrSemaphore* %127) #14
  %132 = load %class.GrBackendSemaphore*, %class.GrBackendSemaphore** %75, align 8
  %133 = getelementptr inbounds %class.GrBackendSemaphore, %class.GrBackendSemaphore* %132, i64 %79
  %134 = bitcast %class.GrBackendSemaphore* %133 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %134, i8* nonnull align 8 %77, i64 25, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %77) #14
  br label %135

135:                                              ; preds = %99, %120, %102, %123
  %136 = add nuw nsw i64 %79, 1
  %137 = load i32, i32* %46, align 8
  %138 = sext i32 %137 to i64
  %139 = icmp slt i64 %136, %138
  br i1 %139, label %78, label %140

140:                                              ; preds = %135, %64
  %141 = getelementptr inbounds %struct.GrFlushInfo, %struct.GrFlushInfo* %4, i64 0, i32 2
  %142 = load void (i8*)*, void (i8*)** %141, align 8
  %143 = icmp eq void (i8*)* %142, null
  br i1 %143, label %151, label %144

144:                                              ; preds = %140
  %145 = getelementptr inbounds %struct.GrFlushInfo, %struct.GrFlushInfo* %4, i64 0, i32 3
  %146 = load i8*, i8** %145, align 8
  %147 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*, void (i8*)*, i8*)***
  %148 = load void (%class.GrGpu*, void (i8*)*, i8*)**, void (%class.GrGpu*, void (i8*)*, i8*)*** %147, align 8
  %149 = getelementptr inbounds void (%class.GrGpu*, void (i8*)*, i8*)*, void (%class.GrGpu*, void (i8*)*, i8*)** %148, i64 17
  %150 = load void (%class.GrGpu*, void (i8*)*, i8*)*, void (%class.GrGpu*, void (i8*)*, i8*)** %149, align 8
  call void %150(%class.GrGpu* %0, void (i8*)* nonnull %142, i8* %146) #14
  br label %151

151:                                              ; preds = %140, %144
  %152 = getelementptr inbounds %struct.GrFlushInfo, %struct.GrFlushInfo* %4, i64 0, i32 4
  %153 = load void (i8*, i1)*, void (i8*, i1)** %152, align 8
  %154 = icmp eq void (i8*, i1)* %153, null
  br i1 %154, label %173, label %155

155:                                              ; preds = %151
  %156 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 6, i32 0, i32 0, i64 64
  %157 = bitcast i8* %156 to %class.SkTArray.192*
  call void @_ZN8SkTArrayIN5GrGpu13SubmittedProcELb0EE12checkReallocEiNS2_11ReallocTypeE(%class.SkTArray.192* %157, i32 1, i32 1) #14
  %158 = bitcast i8* %156 to %"struct.GrGpu::SubmittedProc"**
  %159 = load %"struct.GrGpu::SubmittedProc"*, %"struct.GrGpu::SubmittedProc"** %158, align 8
  %160 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 6, i32 0, i32 0, i64 72
  %161 = bitcast i8* %160 to i64*
  %162 = load i64, i64* %161, align 8
  %163 = lshr i64 %162, 1
  %164 = and i64 %163, 2147483647
  %165 = getelementptr inbounds %"struct.GrGpu::SubmittedProc", %"struct.GrGpu::SubmittedProc"* %159, i64 %164
  %166 = add i64 %162, 2
  %167 = and i64 %166, 4294967294
  %168 = and i64 %162, -4294967295
  %169 = or i64 %167, %168
  store i64 %169, i64* %161, align 8
  %170 = bitcast void (i8*, i1)** %152 to <2 x i64>*
  %171 = load <2 x i64>, <2 x i64>* %170, align 8
  %172 = bitcast %"struct.GrGpu::SubmittedProc"* %165 to <2 x i64>*
  store <2 x i64> %171, <2 x i64>* %172, align 8
  br label %173

173:                                              ; preds = %151, %155
  %174 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*, %class.GrSurfaceProxy**, i64, i32, %class.GrBackendSurfaceMutableState*)***
  %175 = load void (%class.GrGpu*, %class.GrSurfaceProxy**, i64, i32, %class.GrBackendSurfaceMutableState*)**, void (%class.GrGpu*, %class.GrSurfaceProxy**, i64, i32, %class.GrBackendSurfaceMutableState*)*** %174, align 8
  %176 = getelementptr inbounds void (%class.GrGpu*, %class.GrSurfaceProxy**, i64, i32, %class.GrBackendSurfaceMutableState*)*, void (%class.GrGpu*, %class.GrSurfaceProxy**, i64, i32, %class.GrBackendSurfaceMutableState*)** %175, i64 56
  %177 = load void (%class.GrGpu*, %class.GrSurfaceProxy**, i64, i32, %class.GrBackendSurfaceMutableState*)*, void (%class.GrGpu*, %class.GrSurfaceProxy**, i64, i32, %class.GrBackendSurfaceMutableState*)** %176, align 8
  call void %177(%class.GrGpu* %0, %class.GrSurfaceProxy** %1, i64 %2, i32 %3, %class.GrBackendSurfaceMutableState* %5) #14
  %178 = icmp eq i8* %59, null
  br i1 %178, label %198, label %179

179:                                              ; preds = %173
  %180 = load i64, i64* %58, align 8
  %181 = icmp eq i64 %180, 0
  br i1 %181, label %197, label %182

182:                                              ; preds = %179
  %183 = getelementptr inbounds %"class.std::__1::unique_ptr.264", %"class.std::__1::unique_ptr.264"* %60, i64 %180
  br label %184

184:                                              ; preds = %195, %182
  %185 = phi %"class.std::__1::unique_ptr.264"* [ %186, %195 ], [ %183, %182 ]
  %186 = getelementptr inbounds %"class.std::__1::unique_ptr.264", %"class.std::__1::unique_ptr.264"* %185, i64 -1
  %187 = getelementptr inbounds %"class.std::__1::unique_ptr.264", %"class.std::__1::unique_ptr.264"* %186, i64 0, i32 0, i32 0, i32 0
  %188 = load %class.GrSemaphore*, %class.GrSemaphore** %187, align 8
  store %class.GrSemaphore* null, %class.GrSemaphore** %187, align 8
  %189 = icmp eq %class.GrSemaphore* %188, null
  br i1 %189, label %195, label %190

190:                                              ; preds = %184
  %191 = bitcast %class.GrSemaphore* %188 to void (%class.GrSemaphore*)***
  %192 = load void (%class.GrSemaphore*)**, void (%class.GrSemaphore*)*** %191, align 8
  %193 = getelementptr inbounds void (%class.GrSemaphore*)*, void (%class.GrSemaphore*)** %192, i64 1
  %194 = load void (%class.GrSemaphore*)*, void (%class.GrSemaphore*)** %193, align 8
  call void %194(%class.GrSemaphore* nonnull %188) #14
  br label %195

195:                                              ; preds = %190, %184
  %196 = icmp eq %"class.std::__1::unique_ptr.264"* %186, %60
  br i1 %196, label %197, label %184

197:                                              ; preds = %195, %179
  call void @_ZdaPv(i8* nonnull %57) #16
  br label %198

198:                                              ; preds = %173, %197
  %199 = load %"struct.skia::tracing_internals::ScopedTracer::Data"*, %"struct.skia::tracing_internals::ScopedTracer::Data"** %23, align 8
  %200 = icmp eq %"struct.skia::tracing_internals::ScopedTracer::Data"* %199, null
  br i1 %200, label %214, label %201

201:                                              ; preds = %198
  %202 = load i8*, i8** %24, align 8
  %203 = load i8, i8* %202, align 1
  %204 = icmp eq i8 %203, 0
  br i1 %204, label %214, label %205

205:                                              ; preds = %201
  %206 = call %class.SkEventTracer* @_ZN13SkEventTracer11GetInstanceEv() #14
  %207 = load i8*, i8** %24, align 8
  %208 = load i8*, i8** %25, align 8
  %209 = load i64, i64* %26, align 8
  %210 = bitcast %class.SkEventTracer* %206 to void (%class.SkEventTracer*, i8*, i8*, i64)***
  %211 = load void (%class.SkEventTracer*, i8*, i8*, i64)**, void (%class.SkEventTracer*, i8*, i8*, i64)*** %210, align 8
  %212 = getelementptr inbounds void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %211, i64 5
  %213 = load void (%class.SkEventTracer*, i8*, i8*, i64)*, void (%class.SkEventTracer*, i8*, i8*, i64)** %212, align 8
  call void %213(%class.SkEventTracer* %206, i8* %207, i8* %208, i64 %209) #14
  br label %214

214:                                              ; preds = %198, %201, %205
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %22) #14
  ret void
}

; Function Attrs: nounwind readnone speculatable
declare { i64, i1 } @llvm.umul.with.overflow.i64(i64, i64) #7

; Function Attrs: nounwind readnone speculatable
declare { i64, i1 } @llvm.uadd.with.overflow.i64(i64, i64) #7

; Function Attrs: nobuiltin nofree
declare noalias nonnull i8* @_Znam(i64) local_unnamed_addr #8

declare %class.GrSemaphore* @_ZN18GrResourceProvider20wrapBackendSemaphoreERK18GrBackendSemaphoreNS_17SemaphoreWrapTypeE15GrWrapOwnership(%class.GrResourceProvider*, %class.GrBackendSemaphore* dereferenceable(32), i32, i32) local_unnamed_addr #6

declare %class.GrSemaphore* @_ZN18GrResourceProvider13makeSemaphoreEb(%class.GrResourceProvider*, i1 zeroext) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden %class.GrOpsRenderPass* @_ZN5GrGpu16getOpsRenderPassEP14GrRenderTargetbP12GrAttachment15GrSurfaceOriginRK7SkIRectRKN15GrOpsRenderPass16LoadAndStoreInfoERKNS8_23StencilLoadAndStoreInfoERK8SkTArrayIP14GrSurfaceProxyLb1EE18GrXferBarrierFlags(%class.GrGpu*, %class.GrRenderTarget*, i1 zeroext, %class.GrAttachment*, i32, %struct.SkIRect* dereferenceable(16), %"struct.GrOpsRenderPass::LoadAndStoreInfo"* dereferenceable(24), %"struct.GrOpsRenderPass::StencilLoadAndStoreInfo"* dereferenceable(8), %class.SkTArray.274*, i32) local_unnamed_addr #1 align 2 {
  %11 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 8
  %12 = load i32, i32* %11, align 4
  %13 = add nsw i32 %12, 1
  store i32 %13, i32* %11, align 4
  %14 = bitcast %class.GrGpu* %0 to %class.GrOpsRenderPass* (%class.GrGpu*, %class.GrRenderTarget*, i1, %class.GrAttachment*, i32, %struct.SkIRect*, %"struct.GrOpsRenderPass::LoadAndStoreInfo"*, %"struct.GrOpsRenderPass::StencilLoadAndStoreInfo"*, %class.SkTArray.274*, i32)***
  %15 = load %class.GrOpsRenderPass* (%class.GrGpu*, %class.GrRenderTarget*, i1, %class.GrAttachment*, i32, %struct.SkIRect*, %"struct.GrOpsRenderPass::LoadAndStoreInfo"*, %"struct.GrOpsRenderPass::StencilLoadAndStoreInfo"*, %class.SkTArray.274*, i32)**, %class.GrOpsRenderPass* (%class.GrGpu*, %class.GrRenderTarget*, i1, %class.GrAttachment*, i32, %struct.SkIRect*, %"struct.GrOpsRenderPass::LoadAndStoreInfo"*, %"struct.GrOpsRenderPass::StencilLoadAndStoreInfo"*, %class.SkTArray.274*, i32)*** %14, align 8
  %16 = getelementptr inbounds %class.GrOpsRenderPass* (%class.GrGpu*, %class.GrRenderTarget*, i1, %class.GrAttachment*, i32, %struct.SkIRect*, %"struct.GrOpsRenderPass::LoadAndStoreInfo"*, %"struct.GrOpsRenderPass::StencilLoadAndStoreInfo"*, %class.SkTArray.274*, i32)*, %class.GrOpsRenderPass* (%class.GrGpu*, %class.GrRenderTarget*, i1, %class.GrAttachment*, i32, %struct.SkIRect*, %"struct.GrOpsRenderPass::LoadAndStoreInfo"*, %"struct.GrOpsRenderPass::StencilLoadAndStoreInfo"*, %class.SkTArray.274*, i32)** %15, i64 55
  %17 = load %class.GrOpsRenderPass* (%class.GrGpu*, %class.GrRenderTarget*, i1, %class.GrAttachment*, i32, %struct.SkIRect*, %"struct.GrOpsRenderPass::LoadAndStoreInfo"*, %"struct.GrOpsRenderPass::StencilLoadAndStoreInfo"*, %class.SkTArray.274*, i32)*, %class.GrOpsRenderPass* (%class.GrGpu*, %class.GrRenderTarget*, i1, %class.GrAttachment*, i32, %struct.SkIRect*, %"struct.GrOpsRenderPass::LoadAndStoreInfo"*, %"struct.GrOpsRenderPass::StencilLoadAndStoreInfo"*, %class.SkTArray.274*, i32)** %16, align 8
  %18 = tail call %class.GrOpsRenderPass* %17(%class.GrGpu* %0, %class.GrRenderTarget* %1, i1 zeroext %2, %class.GrAttachment* %3, i32 %4, %struct.SkIRect* dereferenceable(16) %5, %"struct.GrOpsRenderPass::LoadAndStoreInfo"* dereferenceable(24) %6, %"struct.GrOpsRenderPass::StencilLoadAndStoreInfo"* dereferenceable(8) %7, %class.SkTArray.274* %8, i32 %9) #14
  ret %class.GrOpsRenderPass* %18
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN5GrGpu11submitToGpuEb(%class.GrGpu*, i1 zeroext) local_unnamed_addr #1 align 2 {
  %3 = bitcast %class.GrGpu* %0 to %class.GrStagingBufferManager* (%class.GrGpu*)***
  %4 = load %class.GrStagingBufferManager* (%class.GrGpu*)**, %class.GrStagingBufferManager* (%class.GrGpu*)*** %3, align 8
  %5 = getelementptr inbounds %class.GrStagingBufferManager* (%class.GrGpu*)*, %class.GrStagingBufferManager* (%class.GrGpu*)** %4, i64 3
  %6 = load %class.GrStagingBufferManager* (%class.GrGpu*)*, %class.GrStagingBufferManager* (%class.GrGpu*)** %5, align 8
  %7 = tail call %class.GrStagingBufferManager* %6(%class.GrGpu* %0) #14
  %8 = icmp eq %class.GrStagingBufferManager* %7, null
  br i1 %8, label %10, label %9

9:                                                ; preds = %2
  tail call void @_ZN22GrStagingBufferManager13detachBuffersEv(%class.GrStagingBufferManager* nonnull %7) #14
  br label %10

10:                                               ; preds = %2, %9
  %11 = bitcast %class.GrGpu* %0 to %class.GrRingBuffer* (%class.GrGpu*)***
  %12 = load %class.GrRingBuffer* (%class.GrGpu*)**, %class.GrRingBuffer* (%class.GrGpu*)*** %11, align 8
  %13 = getelementptr inbounds %class.GrRingBuffer* (%class.GrGpu*)*, %class.GrRingBuffer* (%class.GrGpu*)** %12, i64 4
  %14 = load %class.GrRingBuffer* (%class.GrGpu*)*, %class.GrRingBuffer* (%class.GrGpu*)** %13, align 8
  %15 = tail call %class.GrRingBuffer* %14(%class.GrGpu* %0) #14
  %16 = icmp eq %class.GrRingBuffer* %15, null
  br i1 %16, label %18, label %17

17:                                               ; preds = %10
  tail call void @_ZN12GrRingBuffer11startSubmitEP5GrGpu(%class.GrRingBuffer* nonnull %15, %class.GrGpu* %0) #14
  br label %18

18:                                               ; preds = %10, %17
  %19 = bitcast %class.GrGpu* %0 to i1 (%class.GrGpu*, i1)***
  %20 = load i1 (%class.GrGpu*, i1)**, i1 (%class.GrGpu*, i1)*** %19, align 8
  %21 = getelementptr inbounds i1 (%class.GrGpu*, i1)*, i1 (%class.GrGpu*, i1)** %20, i64 57
  %22 = load i1 (%class.GrGpu*, i1)*, i1 (%class.GrGpu*, i1)** %21, align 8
  %23 = tail call zeroext i1 %22(%class.GrGpu* %0, i1 zeroext %1) #14
  %24 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 6, i32 0, i32 0, i64 64
  %25 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 6, i32 0, i32 0, i64 72
  %26 = bitcast i8* %25 to i64*
  %27 = load i64, i64* %26, align 8
  %28 = and i64 %27, 4294967294
  %29 = icmp eq i64 %28, 0
  br i1 %29, label %44, label %30

30:                                               ; preds = %18
  %31 = bitcast i8* %24 to %"struct.GrGpu::SubmittedProc"**
  br label %32

32:                                               ; preds = %32, %30
  %33 = phi i64 [ 0, %30 ], [ %39, %32 ]
  %34 = load %"struct.GrGpu::SubmittedProc"*, %"struct.GrGpu::SubmittedProc"** %31, align 8
  %35 = getelementptr inbounds %"struct.GrGpu::SubmittedProc", %"struct.GrGpu::SubmittedProc"* %34, i64 %33, i32 0
  %36 = load void (i8*, i1)*, void (i8*, i1)** %35, align 8
  %37 = getelementptr inbounds %"struct.GrGpu::SubmittedProc", %"struct.GrGpu::SubmittedProc"* %34, i64 %33, i32 1
  %38 = load i8*, i8** %37, align 8
  tail call void %36(i8* %38, i1 zeroext %23) #14
  %39 = add nuw nsw i64 %33, 1
  %40 = load i64, i64* %26, align 8
  %41 = lshr i64 %40, 1
  %42 = and i64 %41, 2147483647
  %43 = icmp ult i64 %39, %42
  br i1 %43, label %32, label %44

44:                                               ; preds = %32, %18
  %45 = phi i64 [ %27, %18 ], [ %40, %32 ]
  %46 = bitcast i8* %24 to %class.SkTArray.192*
  %47 = and i64 %45, -4294967295
  store i64 %47, i64* %26, align 8
  tail call void @_ZN8SkTArrayIN5GrGpu13SubmittedProcELb0EE12checkReallocEiNS2_11ReallocTypeE(%class.SkTArray.192* %46, i32 0, i32 2) #14
  %48 = load i64, i64* %26, align 8
  %49 = and i64 %48, -4294967297
  store i64 %49, i64* %26, align 8
  %50 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 8
  %51 = load i32, i32* %50, align 4
  %52 = icmp slt i32 %51, 100
  %53 = select i1 %52, i32 %51, i32 100
  tail call void @_ZN4skia20HistogramExactLinearEPNSt3__16atomicImEEPKcii(%"struct.std::__1::atomic.255"* nonnull @_ZZN5GrGpu22reportSubmitHistogramsEvE24atomic_histogram_pointer, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.1, i64 0, i64 0), i32 %53, i32 100) #14
  store i32 0, i32* %50, align 4
  %54 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*)***
  %55 = load void (%class.GrGpu*)**, void (%class.GrGpu*)*** %54, align 8
  %56 = getelementptr inbounds void (%class.GrGpu*)*, void (%class.GrGpu*)** %55, i64 58
  %57 = load void (%class.GrGpu*)*, void (%class.GrGpu*)** %56, align 8
  tail call void %57(%class.GrGpu* %0) #14
  ret i1 %23
}

declare void @_ZN22GrStagingBufferManager13detachBuffersEv(%class.GrStagingBufferManager*) local_unnamed_addr #6

declare void @_ZN12GrRingBuffer11startSubmitEP5GrGpu(%class.GrRingBuffer*, %class.GrGpu*) local_unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu22reportSubmitHistogramsEv(%class.GrGpu*) local_unnamed_addr #1 align 2 {
  %2 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 8
  %3 = load i32, i32* %2, align 4
  %4 = icmp slt i32 %3, 100
  %5 = select i1 %4, i32 %3, i32 100
  tail call void @_ZN4skia20HistogramExactLinearEPNSt3__16atomicImEEPKcii(%"struct.std::__1::atomic.255"* nonnull @_ZZN5GrGpu22reportSubmitHistogramsEvE24atomic_histogram_pointer, i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.1, i64 0, i64 0), i32 %5, i32 100) #14
  store i32 0, i32* %2, align 4
  %6 = bitcast %class.GrGpu* %0 to void (%class.GrGpu*)***
  %7 = load void (%class.GrGpu*)**, void (%class.GrGpu*)*** %6, align 8
  %8 = getelementptr inbounds void (%class.GrGpu*)*, void (%class.GrGpu*)** %7, i64 58
  %9 = load void (%class.GrGpu*)*, void (%class.GrGpu*)** %8, align 8
  tail call void %9(%class.GrGpu* %0) #14
  ret void
}

declare void @_ZN4skia20HistogramExactLinearEPNSt3__16atomicImEEPKcii(%"struct.std::__1::atomic.255"*, i8*, i32, i32) local_unnamed_addr #6

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden zeroext i1 @_ZN5GrGpu18checkAndResetOOMedEv(%class.GrGpu* nocapture) local_unnamed_addr #9 align 2 {
  %2 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 7
  %3 = load i8, i8* %2, align 8, !range !7
  %4 = icmp eq i8 %3, 0
  br i1 %4, label %6, label %5

5:                                                ; preds = %1
  store i8 0, i8* %2, align 8
  br label %6

6:                                                ; preds = %1, %5
  %7 = phi i1 [ true, %5 ], [ false, %1 ]
  ret i1 %7
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden void @_ZNK5GrGpu8dumpJSONEP12SkJSONWriter(%class.GrGpu* nocapture, %class.SkJSONWriter* nocapture) local_unnamed_addr #5 align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN5GrGpu23CompressedDataIsCorrectE7SkISizeN7SkImage15CompressionTypeE11GrMipmappedPKvm(i64, i32, i1 zeroext, i8* nocapture readnone, i64) local_unnamed_addr #1 align 2 {
  %6 = tail call i64 @_Z20SkCompressedDataSizeN7SkImage15CompressionTypeE7SkISizeP8SkTArrayImLb0EEb(i32 %1, i64 %0, %class.SkTArray.233* null, i1 zeroext %2) #14
  %7 = icmp eq i64 %6, %4
  ret i1 %7
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu20createBackendTextureE7SkISizeRK15GrBackendFormat12GrRenderable11GrMipmapped11GrProtected(%class.GrBackendTexture* noalias sret, %class.GrGpu*, i64, %class.GrBackendFormat* dereferenceable(72), i1 zeroext, i1 zeroext, i1 zeroext) local_unnamed_addr #1 align 2 {
  %8 = trunc i64 %2 to i32
  %9 = lshr i64 %2, 32
  %10 = trunc i64 %9 to i32
  %11 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 2, i32 0
  %12 = load %class.GrCaps*, %class.GrCaps** %11, align 8
  %13 = getelementptr inbounds %class.GrBackendFormat, %class.GrBackendFormat* %3, i64 0, i32 1
  %14 = load i8, i8* %13, align 4, !range !7
  %15 = icmp eq i8 %14, 0
  br i1 %15, label %16, label %17

16:                                               ; preds = %7
  tail call void @_ZN16GrBackendTextureC1Ev(%class.GrBackendTexture* %0) #14
  br label %45

17:                                               ; preds = %7
  %18 = tail call zeroext i1 @_ZNK6GrCaps18isFormatCompressedERK15GrBackendFormat(%class.GrCaps* %12, %class.GrBackendFormat* dereferenceable(72) %3) #14
  br i1 %18, label %19, label %20

19:                                               ; preds = %17
  tail call void @_ZN16GrBackendTextureC1Ev(%class.GrBackendTexture* %0) #14
  br label %45

20:                                               ; preds = %17
  %21 = icmp slt i32 %8, 1
  %22 = icmp slt i32 %10, 1
  %23 = or i1 %21, %22
  br i1 %23, label %30, label %24

24:                                               ; preds = %20
  %25 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %12, i64 0, i32 11
  %26 = load i32, i32* %25, align 4
  %27 = icmp slt i32 %26, %8
  %28 = icmp slt i32 %26, %10
  %29 = or i1 %27, %28
  br i1 %29, label %30, label %31

30:                                               ; preds = %20, %24
  tail call void @_ZN16GrBackendTextureC1Ev(%class.GrBackendTexture* %0) #14
  br label %45

31:                                               ; preds = %24
  br i1 %5, label %32, label %40

32:                                               ; preds = %31
  %33 = load %class.GrCaps*, %class.GrCaps** %11, align 8
  %34 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %33, i64 0, i32 3
  %35 = bitcast i48* %34 to i64*
  %36 = load i64, i64* %35, align 8
  %37 = and i64 %36, 2
  %38 = icmp eq i64 %37, 0
  br i1 %38, label %39, label %40

39:                                               ; preds = %32
  tail call void @_ZN16GrBackendTextureC1Ev(%class.GrBackendTexture* %0) #14
  br label %45

40:                                               ; preds = %32, %31
  %41 = bitcast %class.GrGpu* %1 to void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1)***
  %42 = load void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1)**, void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1)*** %41, align 8
  %43 = getelementptr inbounds void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1)*, void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1)** %42, i64 34
  %44 = load void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1)*, void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1, i1)** %43, align 8
  tail call void %44(%class.GrBackendTexture* sret %0, %class.GrGpu* %1, i64 %2, %class.GrBackendFormat* dereferenceable(72) %3, i1 zeroext %4, i1 zeroext %5, i1 zeroext %6) #14
  br label %45

45:                                               ; preds = %40, %39, %30, %19, %16
  ret void
}

declare void @_ZN16GrBackendTextureC1Ev(%class.GrBackendTexture*) unnamed_addr #6

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN5GrGpu19clearBackendTextureERK16GrBackendTexture5sk_spI18GrRefCntedCallbackENSt3__15arrayIfLm4EEE(%class.GrGpu*, %class.GrBackendTexture* dereferenceable(176), %class.sk_sp.153* nocapture, <2 x float>, <2 x float>) local_unnamed_addr #10 align 2 {
  %6 = alloca %class.sk_sp.153, align 8
  %7 = getelementptr inbounds %class.GrBackendTexture, %class.GrBackendTexture* %1, i64 0, i32 0
  %8 = load i8, i8* %7, align 8, !range !7
  %9 = icmp eq i8 %8, 0
  br i1 %9, label %48, label %10

10:                                               ; preds = %5
  %11 = getelementptr inbounds %class.GrBackendTexture, %class.GrBackendTexture* %1, i64 0, i32 3
  %12 = load i8, i8* %11, align 4, !range !7
  %13 = icmp eq i8 %12, 0
  br i1 %13, label %22, label %14

14:                                               ; preds = %10
  %15 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 2, i32 0
  %16 = load %class.GrCaps*, %class.GrCaps** %15, align 8
  %17 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %16, i64 0, i32 3
  %18 = bitcast i48* %17 to i64*
  %19 = load i64, i64* %18, align 8
  %20 = and i64 %19, 2
  %21 = icmp eq i64 %20, 0
  br i1 %21, label %48, label %22

22:                                               ; preds = %14, %10
  %23 = getelementptr inbounds %class.sk_sp.153, %class.sk_sp.153* %2, i64 0, i32 0
  %24 = bitcast %class.sk_sp.153* %2 to i64*
  %25 = load i64, i64* %24, align 8
  store %class.GrRefCntedCallback* null, %class.GrRefCntedCallback** %23, align 8
  %26 = bitcast %class.sk_sp.153* %6 to i64*
  store i64 %25, i64* %26, align 8
  %27 = bitcast %class.GrGpu* %0 to i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, <2 x float>, <2 x float>)***
  %28 = load i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, <2 x float>, <2 x float>)**, i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, <2 x float>, <2 x float>)*** %27, align 8
  %29 = getelementptr inbounds i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, <2 x float>, <2 x float>)*, i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, <2 x float>, <2 x float>)** %28, i64 36
  %30 = load i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, <2 x float>, <2 x float>)*, i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, <2 x float>, <2 x float>)** %29, align 8
  %31 = call zeroext i1 %30(%class.GrGpu* %0, %class.GrBackendTexture* dereferenceable(176) %1, %class.sk_sp.153* nonnull %6, <2 x float> %3, <2 x float> %4) #14
  %32 = getelementptr inbounds %class.sk_sp.153, %class.sk_sp.153* %6, i64 0, i32 0
  %33 = load %class.GrRefCntedCallback*, %class.GrRefCntedCallback** %32, align 8
  %34 = icmp eq %class.GrRefCntedCallback* %33, null
  br i1 %34, label %48, label %35

35:                                               ; preds = %22
  %36 = getelementptr inbounds %class.GrRefCntedCallback, %class.GrRefCntedCallback* %33, i64 0, i32 0
  %37 = getelementptr inbounds %class.GrRefCntedCallback, %class.GrRefCntedCallback* %33, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %38 = atomicrmw add i32* %37, i32 -1 acq_rel
  %39 = icmp eq i32 %38, 1
  br i1 %39, label %40, label %48

40:                                               ; preds = %35
  %41 = getelementptr inbounds %class.SkNVRefCnt.154, %class.SkNVRefCnt.154* %36, i64 2
  %42 = bitcast %class.SkNVRefCnt.154* %41 to void (i8*)**
  %43 = load void (i8*)*, void (i8*)** %42, align 8
  %44 = getelementptr inbounds %class.SkNVRefCnt.154, %class.SkNVRefCnt.154* %36, i64 4
  %45 = bitcast %class.SkNVRefCnt.154* %44 to i8**
  %46 = load i8*, i8** %45, align 8
  call void %43(i8* %46) #14
  %47 = bitcast %class.GrRefCntedCallback* %33 to i8*
  call void @_ZdlPv(i8* %47) #16
  br label %48

48:                                               ; preds = %14, %5, %40, %35, %22
  %49 = phi i1 [ false, %5 ], [ false, %14 ], [ %31, %22 ], [ %31, %35 ], [ %31, %40 ]
  ret i1 %49
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN5GrGpu30createCompressedBackendTextureE7SkISizeRK15GrBackendFormat11GrMipmapped11GrProtected(%class.GrBackendTexture* noalias sret, %class.GrGpu*, i64, %class.GrBackendFormat* dereferenceable(72), i1 zeroext, i1 zeroext) local_unnamed_addr #1 align 2 {
  %7 = trunc i64 %2 to i32
  %8 = lshr i64 %2, 32
  %9 = trunc i64 %8 to i32
  %10 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %1, i64 0, i32 2, i32 0
  %11 = load %class.GrCaps*, %class.GrCaps** %10, align 8
  %12 = getelementptr inbounds %class.GrBackendFormat, %class.GrBackendFormat* %3, i64 0, i32 1
  %13 = load i8, i8* %12, align 4, !range !7
  %14 = icmp eq i8 %13, 0
  br i1 %14, label %15, label %16

15:                                               ; preds = %6
  tail call void @_ZN16GrBackendTextureC1Ev(%class.GrBackendTexture* %0) #14
  br label %45

16:                                               ; preds = %6
  %17 = tail call i32 @_Z32GrBackendFormatToCompressionTypeRK15GrBackendFormat(%class.GrBackendFormat* dereferenceable(72) %3) #14
  %18 = icmp eq i32 %17, 0
  br i1 %18, label %19, label %20

19:                                               ; preds = %16
  tail call void @_ZN16GrBackendTextureC1Ev(%class.GrBackendTexture* %0) #14
  br label %45

20:                                               ; preds = %16
  %21 = icmp slt i32 %7, 1
  %22 = icmp slt i32 %9, 1
  %23 = or i1 %21, %22
  br i1 %23, label %30, label %24

24:                                               ; preds = %20
  %25 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %11, i64 0, i32 11
  %26 = load i32, i32* %25, align 4
  %27 = icmp slt i32 %26, %7
  %28 = icmp slt i32 %26, %9
  %29 = or i1 %27, %28
  br i1 %29, label %30, label %31

30:                                               ; preds = %20, %24
  tail call void @_ZN16GrBackendTextureC1Ev(%class.GrBackendTexture* %0) #14
  br label %45

31:                                               ; preds = %24
  br i1 %4, label %32, label %40

32:                                               ; preds = %31
  %33 = load %class.GrCaps*, %class.GrCaps** %10, align 8
  %34 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %33, i64 0, i32 3
  %35 = bitcast i48* %34 to i64*
  %36 = load i64, i64* %35, align 8
  %37 = and i64 %36, 2
  %38 = icmp eq i64 %37, 0
  br i1 %38, label %39, label %40

39:                                               ; preds = %32
  tail call void @_ZN16GrBackendTextureC1Ev(%class.GrBackendTexture* %0) #14
  br label %45

40:                                               ; preds = %32, %31
  %41 = bitcast %class.GrGpu* %1 to void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1)***
  %42 = load void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1)**, void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1)*** %41, align 8
  %43 = getelementptr inbounds void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1)*, void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1)** %42, i64 35
  %44 = load void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1)*, void (%class.GrBackendTexture*, %class.GrGpu*, i64, %class.GrBackendFormat*, i1, i1)** %43, align 8
  tail call void %44(%class.GrBackendTexture* sret %0, %class.GrGpu* %1, i64 %2, %class.GrBackendFormat* dereferenceable(72) %3, i1 zeroext %4, i1 zeroext %5) #14
  br label %45

45:                                               ; preds = %19, %30, %39, %40, %15
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN5GrGpu30updateCompressedBackendTextureERK16GrBackendTexture5sk_spI18GrRefCntedCallbackEPKvm(%class.GrGpu*, %class.GrBackendTexture* dereferenceable(176), %class.sk_sp.153* nocapture, i8*, i64) local_unnamed_addr #1 align 2 {
  %6 = alloca %class.GrBackendFormat, align 8
  %7 = alloca %class.sk_sp.153, align 8
  %8 = getelementptr inbounds %class.GrBackendTexture, %class.GrBackendTexture* %1, i64 0, i32 0
  %9 = load i8, i8* %8, align 8, !range !7
  %10 = icmp eq i8 %9, 0
  br i1 %10, label %66, label %11

11:                                               ; preds = %5
  %12 = bitcast %class.GrBackendFormat* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 72, i8* nonnull %12) #14
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %12, i8 -86, i64 72, i1 false)
  call void @_ZNK16GrBackendTexture16getBackendFormatEv(%class.GrBackendFormat* nonnull sret %6, %class.GrBackendTexture* %1) #14
  %13 = call i32 @_Z32GrBackendFormatToCompressionTypeRK15GrBackendFormat(%class.GrBackendFormat* nonnull dereferenceable(72) %6) #14
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %64, label %15

15:                                               ; preds = %11
  %16 = getelementptr inbounds %class.GrBackendTexture, %class.GrBackendTexture* %1, i64 0, i32 3
  %17 = load i8, i8* %16, align 4, !range !7
  %18 = icmp ne i8 %17, 0
  br i1 %18, label %19, label %27

19:                                               ; preds = %15
  %20 = getelementptr inbounds %class.GrGpu, %class.GrGpu* %0, i64 0, i32 2, i32 0
  %21 = load %class.GrCaps*, %class.GrCaps** %20, align 8
  %22 = getelementptr inbounds %class.GrCaps, %class.GrCaps* %21, i64 0, i32 3
  %23 = bitcast i48* %22 to i64*
  %24 = load i64, i64* %23, align 8
  %25 = and i64 %24, 2
  %26 = icmp eq i64 %25, 0
  br i1 %26, label %64, label %27

27:                                               ; preds = %19, %15
  %28 = getelementptr inbounds %class.GrBackendTexture, %class.GrBackendTexture* %1, i64 0, i32 1
  %29 = load i32, i32* %28, align 4
  %30 = getelementptr inbounds %class.GrBackendTexture, %class.GrBackendTexture* %1, i64 0, i32 2
  %31 = load i32, i32* %30, align 8
  %32 = zext i32 %31 to i64
  %33 = shl nuw i64 %32, 32
  %34 = zext i32 %29 to i64
  %35 = or i64 %33, %34
  %36 = call i64 @_Z20SkCompressedDataSizeN7SkImage15CompressionTypeE7SkISizeP8SkTArrayImLb0EEb(i32 %13, i64 %35, %class.SkTArray.233* null, i1 zeroext %18) #14
  %37 = icmp eq i64 %36, %4
  br i1 %37, label %38, label %64

38:                                               ; preds = %27
  %39 = getelementptr inbounds %class.sk_sp.153, %class.sk_sp.153* %2, i64 0, i32 0
  %40 = bitcast %class.sk_sp.153* %2 to i64*
  %41 = load i64, i64* %40, align 8
  store %class.GrRefCntedCallback* null, %class.GrRefCntedCallback** %39, align 8
  %42 = bitcast %class.sk_sp.153* %7 to i64*
  store i64 %41, i64* %42, align 8
  %43 = bitcast %class.GrGpu* %0 to i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, i8*, i64)***
  %44 = load i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, i8*, i64)**, i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, i8*, i64)*** %43, align 8
  %45 = getelementptr inbounds i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, i8*, i64)*, i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, i8*, i64)** %44, i64 37
  %46 = load i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, i8*, i64)*, i1 (%class.GrGpu*, %class.GrBackendTexture*, %class.sk_sp.153*, i8*, i64)** %45, align 8
  %47 = call zeroext i1 %46(%class.GrGpu* %0, %class.GrBackendTexture* dereferenceable(176) %1, %class.sk_sp.153* nonnull %7, i8* %3, i64 %4) #14
  %48 = getelementptr inbounds %class.sk_sp.153, %class.sk_sp.153* %7, i64 0, i32 0
  %49 = load %class.GrRefCntedCallback*, %class.GrRefCntedCallback** %48, align 8
  %50 = icmp eq %class.GrRefCntedCallback* %49, null
  br i1 %50, label %64, label %51

51:                                               ; preds = %38
  %52 = getelementptr inbounds %class.GrRefCntedCallback, %class.GrRefCntedCallback* %49, i64 0, i32 0
  %53 = getelementptr inbounds %class.GrRefCntedCallback, %class.GrRefCntedCallback* %49, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %54 = atomicrmw add i32* %53, i32 -1 acq_rel
  %55 = icmp eq i32 %54, 1
  br i1 %55, label %56, label %64

56:                                               ; preds = %51
  %57 = getelementptr inbounds %class.SkNVRefCnt.154, %class.SkNVRefCnt.154* %52, i64 2
  %58 = bitcast %class.SkNVRefCnt.154* %57 to void (i8*)**
  %59 = load void (i8*)*, void (i8*)** %58, align 8
  %60 = getelementptr inbounds %class.SkNVRefCnt.154, %class.SkNVRefCnt.154* %52, i64 4
  %61 = bitcast %class.SkNVRefCnt.154* %60 to i8**
  %62 = load i8*, i8** %61, align 8
  call void %59(i8* %62) #14
  %63 = bitcast %class.GrRefCntedCallback* %49 to i8*
  call void @_ZdlPv(i8* %63) #16
  br label %64

64:                                               ; preds = %19, %56, %51, %38, %27, %11
  %65 = phi i1 [ false, %11 ], [ false, %19 ], [ false, %27 ], [ %47, %38 ], [ %47, %51 ], [ %47, %56 ]
  call void @llvm.lifetime.end.p0i8(i64 72, i8* nonnull %12) #14
  br label %66

66:                                               ; preds = %5, %64
  %67 = phi i1 [ %65, %64 ], [ false, %5 ]
  ret i1 %67
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #4

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK12SkRefCntBase16internal_disposeEv(%class.SkRefCntBase*) unnamed_addr #1 comdat align 2 {
  %2 = icmp eq %class.SkRefCntBase* %0, null
  br i1 %2, label %8, label %3

3:                                                ; preds = %1
  %4 = bitcast %class.SkRefCntBase* %0 to void (%class.SkRefCntBase*)***
  %5 = load void (%class.SkRefCntBase*)**, void (%class.SkRefCntBase*)*** %4, align 8
  %6 = getelementptr inbounds void (%class.SkRefCntBase*)*, void (%class.SkRefCntBase*)** %5, i64 1
  %7 = load void (%class.SkRefCntBase*)*, void (%class.SkRefCntBase*)** %6, align 8
  tail call void %7(%class.SkRefCntBase* nonnull %0) #14
  br label %8

8:                                                ; preds = %3, %1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden %class.GrStagingBufferManager* @_ZN5GrGpu20stagingBufferManagerEv(%class.GrGpu*) unnamed_addr #1 comdat align 2 {
  ret %class.GrStagingBufferManager* null
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden %class.GrRingBuffer* @_ZN5GrGpu18uniformsRingBufferEv(%class.GrGpu*) unnamed_addr #1 comdat align 2 {
  ret %class.GrRingBuffer* null
}

declare void @__cxa_pure_virtual() unnamed_addr

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZNK5GrGpu12isDeviceLostEv(%class.GrGpu*) unnamed_addr #1 comdat align 2 {
  ret i1 false
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5GrGpu21takeOwnershipOfBufferE5sk_spI11GrGpuBufferE(%class.GrGpu*, %class.sk_sp.251*) unnamed_addr #1 comdat align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5GrGpu29releaseUnlockedBackendObjectsEv(%class.GrGpu*) unnamed_addr #1 comdat align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZN5GrGpu22setBackendTextureStateERK16GrBackendTextureRK28GrBackendSurfaceMutableStatePS3_5sk_spI18GrRefCntedCallbackE(%class.GrGpu*, %class.GrBackendTexture* dereferenceable(176), %class.GrBackendSurfaceMutableState* dereferenceable(16), %class.GrBackendSurfaceMutableState*, %class.sk_sp.153*) unnamed_addr #1 comdat align 2 {
  ret i1 false
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZN5GrGpu27setBackendRenderTargetStateERK21GrBackendRenderTargetRK28GrBackendSurfaceMutableStatePS3_5sk_spI18GrRefCntedCallbackE(%class.GrGpu*, %class.GrBackendRenderTarget* dereferenceable(176), %class.GrBackendSurfaceMutableState* dereferenceable(16), %class.GrBackendSurfaceMutableState*, %class.sk_sp.153*) unnamed_addr #1 comdat align 2 {
  ret i1 false
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZN5GrGpu16precompileShaderERK6SkDataS2_(%class.GrGpu*, %class.SkData* dereferenceable(40), %class.SkData* dereferenceable(40)) unnamed_addr #1 comdat align 2 {
  ret i1 false
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5GrGpu24storeVkPipelineCacheDataEv(%class.GrGpu*) unnamed_addr #1 comdat align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5GrGpu30insertManualFramebufferBarrierEv(%class.GrGpu*) unnamed_addr #1 comdat align 2 {
  tail call void (i8*, i32, i8*, ...) @_Z16SkAbort_FileLinePKciS0_z(i8* getelementptr inbounds ([39 x i8], [39 x i8]* @.str.2, i64 0, i64 0), i32 641, i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.3, i64 0, i64 0)) #15
  unreachable
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5GrGpu14onResetContextEj(%class.GrGpu*, i32) unnamed_addr #1 comdat align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5GrGpu22onResetTextureBindingsEv(%class.GrGpu*) unnamed_addr #1 comdat align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5GrGpu46prepareSurfacesForBackendAccessAndStateUpdatesE6SkSpanIP14GrSurfaceProxyEN9SkSurface20BackendSurfaceAccessEPK28GrBackendSurfaceMutableState(%class.GrGpu*, %class.GrSurfaceProxy**, i64, i32, %class.GrBackendSurfaceMutableState*) unnamed_addr #1 comdat align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5GrGpu24onReportSubmitHistogramsEv(%class.GrGpu*) unnamed_addr #1 comdat align 2 {
  ret void
}

; Function Attrs: nobuiltin nounwind
declare void @_ZdlPv(i8*) local_unnamed_addr #11

declare void @_Z7sk_freePv(i8*) local_unnamed_addr #6

declare void @_ZN13GrGpuResource16removeScratchKeyEv(%class.GrGpuResource*) local_unnamed_addr #6

; Function Attrs: nounwind readnone speculatable
declare i32 @llvm.ctlz.i32(i32, i1 immarg) #7

; Function Attrs: noreturn
declare void @_Z16SkAbort_FileLinePKciS0_z(i8*, i32, i8*, ...) local_unnamed_addr #12

declare void @_ZNK13GrGpuResource19notifyARefCntIsZeroEN7GrIORefIS_E14LastRemovedRefE(%class.GrGpuResource*, i32) local_unnamed_addr #6

declare i8* @_Z15sk_malloc_throwmm(i64, i64) local_unnamed_addr #6

; Function Attrs: nobuiltin nofree
declare noalias nonnull i8* @_Znwm(i64) local_unnamed_addr #8

declare void @_ZN4SkSL8CompilerC1EPK12GrShaderCaps(%"class.SkSL::Compiler"*, %class.GrShaderCaps*) unnamed_addr #6

; Function Attrs: nobuiltin nounwind
declare void @_ZdaPv(i8*) local_unnamed_addr #11

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8SkTArrayIN5GrGpu13SubmittedProcELb0EE12checkReallocEiNS2_11ReallocTypeE(%class.SkTArray.192*, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %4 = getelementptr inbounds %class.SkTArray.192, %class.SkTArray.192* %0, i64 0, i32 1
  %5 = load i64, i64* %4, align 8
  %6 = lshr i64 %5, 1
  %7 = trunc i64 %6 to i32
  %8 = and i32 %7, 2147483647
  %9 = add nsw i32 %8, %1
  %10 = sext i32 %9 to i64
  %11 = lshr i64 %5, 33
  %12 = icmp slt i64 %11, %10
  %13 = mul nsw i64 %10, 3
  %14 = icmp sle i64 %11, %13
  %15 = and i64 %5, 1
  %16 = icmp eq i64 %15, 0
  %17 = or i1 %16, %14
  br i1 %17, label %21, label %18

18:                                               ; preds = %3
  %19 = and i64 %5, 4294967296
  %20 = icmp eq i64 %19, 0
  br label %21

21:                                               ; preds = %3, %18
  %22 = phi i1 [ false, %3 ], [ %20, %18 ]
  %23 = or i1 %12, %22
  br i1 %23, label %24, label %74

24:                                               ; preds = %21
  %25 = icmp eq i32 %2, 0
  br i1 %25, label %32, label %26

26:                                               ; preds = %24
  %27 = add nsw i64 %10, 1
  %28 = ashr i64 %27, 1
  %29 = add nsw i64 %10, 7
  %30 = add nsw i64 %29, %28
  %31 = and i64 %30, -8
  br label %32

32:                                               ; preds = %24, %26
  %33 = phi i64 [ %31, %26 ], [ %10, %24 ]
  %34 = icmp eq i64 %33, %11
  br i1 %34, label %74, label %35

35:                                               ; preds = %32
  %36 = icmp slt i64 %33, 2147483647
  %37 = select i1 %36, i64 %33, i64 2147483647
  %38 = icmp sgt i64 %37, -2147483647
  %39 = select i1 %38, i64 %37, i64 -2147483647
  %40 = shl i64 %39, 33
  %41 = and i64 %5, 8589934591
  %42 = or i64 %40, %41
  store i64 %42, i64* %4, align 8
  %43 = and i64 %39, 2147483647
  %44 = tail call i8* @_Z15sk_malloc_throwmm(i64 %43, i64 16) #14
  %45 = load i64, i64* %4, align 8
  %46 = and i64 %45, 4294967294
  %47 = icmp eq i64 %46, 0
  br i1 %47, label %62, label %48

48:                                               ; preds = %35
  %49 = getelementptr inbounds %class.SkTArray.192, %class.SkTArray.192* %0, i64 0, i32 0
  br label %50

50:                                               ; preds = %50, %48
  %51 = phi i64 [ 0, %48 ], [ %57, %50 ]
  %52 = shl nuw nsw i64 %51, 4
  %53 = getelementptr inbounds i8, i8* %44, i64 %52
  %54 = load %"struct.GrGpu::SubmittedProc"*, %"struct.GrGpu::SubmittedProc"** %49, align 8
  %55 = getelementptr inbounds %"struct.GrGpu::SubmittedProc", %"struct.GrGpu::SubmittedProc"* %54, i64 %51
  %56 = bitcast %"struct.GrGpu::SubmittedProc"* %55 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %53, i8* align 8 %56, i64 16, i1 false) #14
  %57 = add nuw nsw i64 %51, 1
  %58 = load i64, i64* %4, align 8
  %59 = lshr i64 %58, 1
  %60 = and i64 %59, 2147483647
  %61 = icmp ult i64 %57, %60
  br i1 %61, label %50, label %62

62:                                               ; preds = %50, %35
  %63 = phi i64 [ %45, %35 ], [ %58, %50 ]
  %64 = and i64 %63, 1
  %65 = icmp eq i64 %64, 0
  %66 = bitcast %class.SkTArray.192* %0 to i8**
  br i1 %65, label %70, label %67

67:                                               ; preds = %62
  %68 = load i8*, i8** %66, align 8
  tail call void @_Z7sk_freePv(i8* %68) #14
  %69 = load i64, i64* %4, align 8
  br label %70

70:                                               ; preds = %62, %67
  %71 = phi i64 [ %69, %67 ], [ %63, %62 ]
  store i8* %44, i8** %66, align 8
  %72 = and i64 %71, -4294967298
  %73 = or i64 %72, 1
  store i64 %73, i64* %4, align 8
  br label %74

74:                                               ; preds = %70, %32, %21
  ret void
}

; Function Attrs: nofree nounwind readonly
declare i32 @bcmp(i8* nocapture, i8* nocapture, i64) local_unnamed_addr #13

attributes #0 = { nofree norecurse nounwind ssp uwtable writeonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { noreturn nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { cold noreturn nounwind }
attributes #4 = { argmemonly nounwind }
attributes #5 = { norecurse nounwind readnone ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { nounwind readnone speculatable }
attributes #8 = { nobuiltin nofree "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="64" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #11 = { nobuiltin nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #12 = { noreturn "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #13 = { nofree nounwind readonly }
attributes #14 = { nounwind }
attributes #15 = { noreturn nounwind }
attributes #16 = { builtin nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 0, i32 33}
!3 = distinct !{!3, !4}
!4 = !{!"llvm.loop.isvectorized", i32 1}
!5 = distinct !{!5, !6, !4}
!6 = !{!"llvm.loop.unroll.runtime.disable"}
!7 = !{i8 0, i8 2}
