; ModuleID = '../../v8/src/objects/transitions.cc'
source_filename = "../../v8/src/objects/transitions.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"class.v8::internal::SoleReadOnlyHeap" = type { %"class.v8::internal::ReadOnlyHeap", [587 x i64] }
%"class.v8::internal::ReadOnlyHeap" = type { i32 (...)**, i8, %"class.v8::internal::ReadOnlySpace"*, %"class.std::__1::vector.541" }
%"class.v8::internal::ReadOnlySpace" = type { %"class.v8::internal::BaseSpace", i8, %"class.v8::internal::AllocationStats", %"class.std::__1::vector.139", i64, i64, i8, i64, i64 }
%"class.v8::internal::BaseSpace" = type { i32 (...)**, %"class.v8::internal::Heap"*, i32, %"struct.std::__1::atomic.19", i64 }
%"class.v8::internal::Heap" = type { %"class.std::__1::unordered_map", %"struct.std::__1::atomic.19", %"class.v8::internal::Heap::ExternalMemoryAccounting", %"class.v8::internal::Isolate"*, i64, i64, i64, i64, %"struct.std::__1::atomic.19", i64, i64, i64, i64, i64, i8, i64, i64, %"struct.std::__1::atomic.19", i64, i64, %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.29", %"class.std::__1::vector", i32, %"class.v8::internal::NewSpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::CodeSpace"*, %"class.v8::internal::MapSpace"*, %"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::NewLargeObjectSpace"*, %"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::MapSpace"*, %"class.std::__1::unique_ptr.146", %"class.std::__1::unique_ptr.146", [8 x %"class.v8::internal::Space"*], %"class.v8::internal::LocalHeap"*, %"class.v8::internal::ArrayBufferExtension"*, %"class.v8::internal::ArrayBufferExtension"*, i8, i64, %"struct.std::__1::atomic.161", i32, i32, i32, i32, %"class.v8::internal::AllocationObserver"*, %"class.v8::internal::StressScavengeObserver"*, double, i32, i32, i32, i64, i32, [128 x i64], %"struct.std::__1::atomic.19", i64, i8, %"struct.std::__1::atomic.19", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.std::__1::vector.165", %"class.std::__1::vector.165", i64 ()*, [113 x i32], i64, double, double, i64, i64, double, i32, i32, i32, i32, double, double, double, %"class.std::__1::unique_ptr.172", %"class.std::__1::unique_ptr.178", %"class.v8::internal::MinorMarkCompactCollector"*, %"class.std::__1::unique_ptr.308", %"class.std::__1::unique_ptr.314", %"class.std::__1::unique_ptr.320", %"class.std::__1::unique_ptr.359", %"class.std::__1::unique_ptr.398", %"class.std::__1::unique_ptr.428", %"class.std::__1::unique_ptr.434", %"class.std::__1::unique_ptr.444", %"class.std::__1::unique_ptr.450", %"class.std::__1::unique_ptr.450", %"class.std::__1::unique_ptr.456", %"class.std::__1::unique_ptr.462", %"class.std::__1::unique_ptr.462", %"class.std::__1::unique_ptr.468", %"class.std::__1::unique_ptr.474", %"class.std::__1::shared_ptr.480", %"class.v8::CppHeap"*, %"class.v8::EmbedderRootsHandler"*, %"class.v8::internal::StrongRootsEntry"*, %"class.v8::base::Mutex", i8, i64, i64, i64, i64, %"class.std::__1::unordered_map.503", %"class.std::__1::unique_ptr.529", [512 x i8], i8, i8, i64, i8, i32, i32, %"class.std::__1::unique_ptr.535", i8, %"class.v8::internal::Heap::ExternalStringTable", %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.548", i32, i8, i8, i8, i8, i8, %"class.v8::internal::HeapObject", %"class.v8::base::SharedMutex", %"class.v8::base::Mutex", %"class.std::__1::unordered_set.330", i8, [7 x i8], %"class.std::__1::unordered_map.554", %"class.std::__1::unordered_map.580", %"class.std::__1::unordered_map.554", %"class.std::__1::unordered_map.604", %"class.std::__1::vector.632", i8, %"class.std::__1::unique_ptr.639", i32, i32 }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr.2", %"class.std::__1::__compressed_pair.9", %"class.std::__1::__compressed_pair.14", %"class.std::__1::__compressed_pair.16", [4 x i8] }>
%"class.std::__1::unique_ptr.2" = type { %"class.std::__1::__compressed_pair.3" }
%"class.std::__1::__compressed_pair.3" = type { %"struct.std::__1::__compressed_pair_elem.4", %"struct.std::__1::__compressed_pair_elem.5" }
%"struct.std::__1::__compressed_pair_elem.4" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.5" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.6" }
%"class.std::__1::__compressed_pair.6" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::__compressed_pair_elem.7" = type { i64 }
%"class.std::__1::__compressed_pair.9" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"struct.std::__1::__compressed_pair_elem.10" = type { %"struct.std::__1::__hash_node_base" }
%"class.std::__1::__compressed_pair.14" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.16" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"struct.std::__1::__compressed_pair_elem.17" = type { float }
%"class.v8::internal::Heap::ExternalMemoryAccounting" = type { %"struct.std::__1::atomic.24", %"struct.std::__1::atomic.24", %"struct.std::__1::atomic.24" }
%"struct.std::__1::atomic.24" = type { %"struct.std::__1::__atomic_base.25" }
%"struct.std::__1::__atomic_base.25" = type { %"struct.std::__1::__atomic_base.26" }
%"struct.std::__1::__atomic_base.26" = type { %"struct.std::__1::__cxx_atomic_impl.27" }
%"struct.std::__1::__cxx_atomic_impl.27" = type { %"struct.std::__1::__cxx_atomic_base_impl.28" }
%"struct.std::__1::__cxx_atomic_base_impl.28" = type { i64 }
%"class.v8::internal::Isolate" = type { %"class.v8::internal::IsolateData", %"class.std::__1::unique_ptr", %"class.v8::internal::Heap", %"class.v8::internal::ReadOnlyHeap"*, %"class.std::__1::shared_ptr.645", %"class.std::__1::unique_ptr.666", i32, %"class.v8::internal::Isolate::EntryStackItem"*, i32, %"class.v8::internal::StringStream"*, [13 x i64], %"class.v8::internal::Bootstrapper"*, %"class.v8::internal::RuntimeProfiler"*, %"class.v8::internal::CompilationCache"*, %"class.std::__1::shared_ptr.676", %"class.v8::base::RecursiveMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::internal::Logger"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::Deoptimizer"*, i8, %"class.v8::internal::MaterializedObjectStore"*, i8, i32, i32, %"class.v8::internal::DescriptorLookupCache"*, %"struct.v8::internal::HandleScopeData", %"class.v8::internal::HandleScopeImplementer"*, %"class.v8::internal::UnicodeCache"*, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::InnerPointerToCodeCache"*, %"class.v8::internal::GlobalHandles"*, %"class.v8::internal::EternalHandles"*, %"class.v8::internal::ThreadManager"*, %"class.v8::bigint::Processor"*, %"class.v8::internal::RuntimeState", %"class.v8::internal::Builtins", %"class.v8::internal::SetupIsolateDelegate"*, %"class.v8::internal::RegExpStack"*, %"class.std::__1::vector.815", %"class.v8::internal::DateCache"*, %"class.v8::base::RandomNumberGenerator"*, %"class.v8::base::RandomNumberGenerator"*, %"struct.std::__1::atomic.828", {}*, i8*, void (i32, %"class.v8::Promise"*, %"class.v8::Value"*)*, {}*, {}*, %"struct.std::__1::atomic.838", {}*, %"class.v8::base::Mutex", double, %"class.std::__1::basic_string", %"class.std::__1::unordered_map.849", %"struct.std::__1::atomic.152", i8, i8, i8, i8, i8, i8, double, %"class.v8::internal::Debug"*, %"class.v8::internal::HeapProfiler"*, %"class.std::__1::unique_ptr.924", %"class.v8::internal::AstStringConstants"*, %"class.v8::internal::interpreter::Interpreter"*, %"class.v8::internal::compiler::PerIsolateCompilerCache"*, %"class.v8::internal::Zone"*, %"class.v8::internal::CompilerDispatcher"*, %"class.std::__1::queue", void (i8*, i8*)*, void (i8*, i1)*, void (i8*, i32)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*, i1)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::Context"*)*, void (%"class.v8::FunctionCallbackInfo"*)*, %"class.v8::String"* (%"class.v8::Isolate"*, i8*)*, i1 (%"class.v8::Context"*)*, i1 (%"class.v8::Context"*)*, %"class.v8::internal::Relocatable"*, %"class.std::__1::vector.967"*, %"class.v8::internal::Object", i64*, %"class.v8::internal::AddressToIndexHashMap"*, %"class.v8::internal::HeapObjectToIndexHashMap"*, %"class.v8::internal::MicrotaskQueue"*, %"class.v8::internal::CompilationStatistics"*, %"class.v8::internal::CodeTracer"*, i32, void (%"class.v8::PromiseRejectMessage"*)*, %"class.v8::StartupData"*, i32, i32, i32, i64, i8, i8, i32, i8, i32, %"class.v8_inspector::V8Inspector"*, i8, i8, i8, i32, i32, %"class.v8::internal::compiler::NodeObserver"*, i8, [128 x i32], [256 x i32], [251 x i32], [251 x i32], %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.std::__1::unique_ptr.975", i32, i8, i8, i32, i32, %"class.std::__1::vector.981", %"class.std::__1::vector.981", void (%"class.v8::Isolate"*, i32)*, %"class.std::__1::shared_ptr.988", i64, %"class.std::__1::unordered_map.989", i64, %"struct.v8::metrics::LongTaskStats", %"class.std::__1::vector.541", %"class.v8::internal::BuiltinsConstantsTableBuilder"*, i8*, i32, i8*, i32, %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::shared_ptr.160", %"class.v8::internal::FutexWaitListNode", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::debug::ConsoleDelegate"*, %"class.v8::debug::AsyncEventDelegate"*, i32, i32, %"class.std::__1::unique_ptr.1045", i1 (%"class.v8::Isolate"*)*, i8, %"class.v8::base::Mutex", %"struct.v8::internal::ManagedPtrDestructor"*, i64, i64, %"class.v8::internal::wasm::WasmEngine"*, %"class.std::__1::unique_ptr.1083", %"class.v8::internal::EmbeddedFileWriterInterface"*, %"class.v8::Context::BackupIncumbentScope"*, {}*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate::ThreadDataTable", i8, %"class.v8::internal::Isolate"*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"struct.std::__1::atomic.1117", %"class.std::__1::vector.1121", %"class.std::__1::vector.1121", void (i32, %"class.std::__1::basic_string"*)* }
%"class.v8::internal::IsolateData" = type { [4 x i8*], i64, i64, i64, i64, i64, %"class.v8::internal::StackGuard", %"class.v8::internal::RootsTable", %"class.v8::internal::ExternalReferenceTable", %"class.v8::internal::ThreadLocalTop", [1711 x i64], [1711 x i64], i8, [15 x i8] }
%"class.v8::internal::StackGuard" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::StackGuard::ThreadLocal" }
%"class.v8::internal::StackGuard::ThreadLocal" = type { i64, i64, i64, i64, %"class.v8::internal::InterruptsScope"*, i64 }
%"class.v8::internal::InterruptsScope" = type { i32 (...)**, %"class.v8::internal::StackGuard"*, i64, i64, i32, %"class.v8::internal::InterruptsScope"* }
%"class.v8::internal::RootsTable" = type { [669 x i64] }
%"class.v8::internal::ExternalReferenceTable" = type { [1042 x i64], i32, i32 }
%"class.v8::internal::ThreadLocalTop" = type { %"class.v8::TryCatch"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Context", %"struct.std::__1::atomic", %"class.v8::internal::Object", %"class.v8::internal::Context", i64, i64, i64, i64, i64, %"class.v8::internal::Object", i8, i8, %"class.v8::internal::Object", i64, i64, i64, %"class.v8::internal::PromiseOnStack"*, %"class.v8::internal::Simulator"*, i64, %"class.v8::internal::ExternalCallbackScope"*, i32, void (%"class.v8::Object"*, i32, %"class.v8::Value"*)*, i64 }
%"class.v8::TryCatch" = type <{ %"class.v8::internal::Isolate"*, %"class.v8::TryCatch"*, i8*, i8*, i8*, i8, [7 x i8] }>
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { %"class.v8::internal::ThreadId" }
%"class.v8::internal::ThreadId" = type { i32 }
%"class.v8::internal::Context" = type { %"class.v8::internal::TorqueGeneratedContext" }
%"class.v8::internal::TorqueGeneratedContext" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::PromiseOnStack" = type { %"class.v8::internal::Handle", %"class.v8::internal::PromiseOnStack"* }
%"class.v8::internal::Handle" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HandleBase" = type { i64* }
%"class.v8::internal::Simulator" = type opaque
%"class.v8::internal::ExternalCallbackScope" = type opaque
%"class.v8::Object" = type { i8 }
%"class.v8::Value" = type { i8 }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { %"class.v8::internal::IsolateAllocator"* }
%"class.v8::internal::IsolateAllocator" = type { i8*, %"class.v8::PageAllocator"* }
%"class.v8::PageAllocator" = type { i32 (...)** }
%"class.std::__1::shared_ptr.645" = type { %"class.v8::internal::ReadOnlyArtifacts"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::ReadOnlyArtifacts" = type { i32 (...)**, %"class.std::__1::vector.139", %"class.v8::internal::AllocationStats", %"class.std::__1::unique_ptr.646", %"class.std::__1::unique_ptr.660" }
%"class.std::__1::unique_ptr.646" = type { %"class.std::__1::__compressed_pair.647" }
%"class.std::__1::__compressed_pair.647" = type { %"struct.std::__1::__compressed_pair_elem.648" }
%"struct.std::__1::__compressed_pair_elem.648" = type { %"class.v8::internal::SharedReadOnlySpace"* }
%"class.v8::internal::SharedReadOnlySpace" = type { %"class.v8::internal::ReadOnlySpace", %"class.std::__1::vector.649" }
%"class.std::__1::vector.649" = type { %"class.std::__1::__vector_base.650" }
%"class.std::__1::__vector_base.650" = type { %"class.std::__1::unique_ptr.651"*, %"class.std::__1::unique_ptr.651"*, %"class.std::__1::__compressed_pair.652" }
%"class.std::__1::unique_ptr.651" = type { %"class.std::__1::__compressed_pair.1149" }
%"class.std::__1::__compressed_pair.1149" = type { %"struct.std::__1::__compressed_pair_elem.1150" }
%"struct.std::__1::__compressed_pair_elem.1150" = type { %"class.v8::PageAllocator::SharedMemoryMapping"* }
%"class.v8::PageAllocator::SharedMemoryMapping" = type { i32 (...)** }
%"class.std::__1::__compressed_pair.652" = type { %"struct.std::__1::__compressed_pair_elem.653" }
%"struct.std::__1::__compressed_pair_elem.653" = type { %"class.std::__1::unique_ptr.651"* }
%"class.std::__1::unique_ptr.660" = type { %"class.std::__1::__compressed_pair.661" }
%"class.std::__1::__compressed_pair.661" = type { %"struct.std::__1::__compressed_pair_elem.662" }
%"struct.std::__1::__compressed_pair_elem.662" = type { %"class.v8::internal::ReadOnlyHeap"* }
%"class.std::__1::__shared_weak_count" = type { %"class.std::__1::__shared_count", i64 }
%"class.std::__1::__shared_count" = type { i32 (...)**, i64 }
%"class.std::__1::unique_ptr.666" = type { %"class.std::__1::__compressed_pair.667" }
%"class.std::__1::__compressed_pair.667" = type { %"struct.std::__1::__compressed_pair_elem.668" }
%"struct.std::__1::__compressed_pair_elem.668" = type { %"class.v8::internal::StringTable"* }
%"class.v8::internal::StringTable" = type { %"struct.std::__1::atomic.669", %"class.v8::base::Mutex" }
%"struct.std::__1::atomic.669" = type { %"struct.std::__1::__atomic_base.670" }
%"struct.std::__1::__atomic_base.670" = type { %"struct.std::__1::__cxx_atomic_impl.671" }
%"struct.std::__1::__cxx_atomic_impl.671" = type { %"struct.std::__1::__cxx_atomic_base_impl.672" }
%"struct.std::__1::__cxx_atomic_base_impl.672" = type { %"class.v8::internal::StringTable::Data"* }
%"class.v8::internal::StringTable::Data" = type opaque
%"class.v8::internal::Isolate::EntryStackItem" = type { i32, %"class.v8::internal::Isolate::PerIsolateThreadData"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate::EntryStackItem"* }
%"class.v8::internal::Isolate::PerIsolateThreadData" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::ThreadId", i64, %"class.v8::internal::ThreadState"* }
%"class.v8::internal::ThreadState" = type opaque
%"class.v8::internal::StringStream" = type opaque
%"class.v8::internal::Bootstrapper" = type { %"class.v8::internal::Isolate"*, i32, %"class.v8::internal::SourceCodeCache" }
%"class.v8::internal::SourceCodeCache" = type { i32, %"class.v8::internal::FixedArray" }
%"class.v8::internal::FixedArray" = type { %"class.v8::internal::TorqueGeneratedFixedArray" }
%"class.v8::internal::TorqueGeneratedFixedArray" = type { %"class.v8::internal::FixedArrayBase" }
%"class.v8::internal::FixedArrayBase" = type { %"class.v8::internal::TorqueGeneratedFixedArrayBase" }
%"class.v8::internal::TorqueGeneratedFixedArrayBase" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::RuntimeProfiler" = type opaque
%"class.v8::internal::CompilationCache" = type opaque
%"class.std::__1::shared_ptr.676" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::Counters" = type { %"class.std::__1::enable_shared_from_this", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::AggregatableHistogramTimer", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::RuntimeCallStats", %"class.v8::internal::WorkerThreadRuntimeCallStats", %"class.v8::internal::Isolate"*, %"class.v8::internal::StatsTable" }
%"class.std::__1::enable_shared_from_this" = type { %"class.std::__1::weak_ptr" }
%"class.std::__1::weak_ptr" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::HistogramTimer" = type { %"class.v8::internal::TimedHistogram.base", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::TimedHistogram.base" = type <{ %"class.v8::internal::Histogram", i32 }>
%"class.v8::base::ElapsedTimer" = type { %"class.v8::base::TimeTicks" }
%"class.v8::base::TimeTicks" = type { %"class.v8::base::time_internal::TimeBase" }
%"class.v8::base::time_internal::TimeBase" = type { i64 }
%"class.v8::internal::TimedHistogram" = type <{ %"class.v8::internal::Histogram", i32, [4 x i8] }>
%"class.v8::internal::AggregatableHistogramTimer" = type { %"class.v8::internal::Histogram", %"class.v8::base::TimeDelta" }
%"class.v8::base::TimeDelta" = type { i64 }
%"class.v8::internal::Histogram" = type { i8*, i32, i32, i32, i8*, %"class.v8::internal::Counters"* }
%"class.v8::internal::StatsCounterThreadSafe" = type { %"class.v8::internal::StatsCounterBase", %"class.v8::base::Mutex" }
%"class.v8::internal::StatsCounterBase" = type { %"class.v8::internal::Counters"*, i8*, i32* }
%"class.v8::internal::StatsCounter" = type <{ %"class.v8::internal::StatsCounterBase", i8, [7 x i8] }>
%"class.v8::internal::RuntimeCallStats" = type { %"class.v8::base::AtomicValue", %"class.v8::base::AtomicValue.677", i8, i32, %"class.v8::internal::ThreadId", [1370 x %"class.v8::internal::RuntimeCallCounter"] }
%"class.v8::base::AtomicValue" = type { i64 }
%"class.v8::base::AtomicValue.677" = type { i64 }
%"class.v8::internal::RuntimeCallCounter" = type { i8*, i64, i64 }
%"class.v8::internal::WorkerThreadRuntimeCallStats" = type <{ %"class.v8::base::Mutex", %"class.std::__1::vector.678", %"class.v8::base::Optional", %"class.v8::internal::ThreadId", [4 x i8] }>
%"class.std::__1::vector.678" = type { %"class.std::__1::__vector_base.679" }
%"class.std::__1::__vector_base.679" = type { %"class.std::__1::unique_ptr.680"*, %"class.std::__1::unique_ptr.680"*, %"class.std::__1::__compressed_pair.681" }
%"class.std::__1::unique_ptr.680" = type opaque
%"class.std::__1::__compressed_pair.681" = type { %"struct.std::__1::__compressed_pair_elem.682" }
%"struct.std::__1::__compressed_pair_elem.682" = type { %"class.std::__1::unique_ptr.680"* }
%"class.v8::base::Optional" = type { %"class.v8::base::internal::OptionalBase" }
%"class.v8::base::internal::OptionalBase" = type { %"struct.v8::base::internal::OptionalStorage" }
%"struct.v8::base::internal::OptionalStorage" = type { %"struct.v8::base::internal::OptionalStorageBase" }
%"struct.v8::base::internal::OptionalStorageBase" = type { i8, %union.anon }
%union.anon = type { i32 }
%"class.v8::internal::StatsTable" = type { i32* (i8*)*, i8* (i8*, i32, i32, i64)*, void (i8*, i32)* }
%"class.v8::base::RecursiveMutex" = type { %union.pthread_mutex_t }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"class.v8::internal::Logger" = type { %"class.v8::internal::CodeEventListener", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.686", %"class.std::__1::unique_ptr.692", %"struct.std::__1::atomic.152", %"class.std::__1::unique_ptr.698", %"class.std::__1::unique_ptr.704", %"class.std::__1::unique_ptr.710", %"class.std::__1::unique_ptr.716", %"class.std::__1::unique_ptr.722", %"class.std::__1::set.728", i32, i8, %"class.v8::internal::ExistingCodeLogger", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::CodeEventListener" = type { i32 (...)** }
%"class.std::__1::unique_ptr.686" = type { %"class.std::__1::__compressed_pair.687" }
%"class.std::__1::__compressed_pair.687" = type { %"struct.std::__1::__compressed_pair_elem.688" }
%"struct.std::__1::__compressed_pair_elem.688" = type { %"class.v8::internal::Ticker"* }
%"class.v8::internal::Ticker" = type opaque
%"class.std::__1::unique_ptr.692" = type { %"class.std::__1::__compressed_pair.693" }
%"class.std::__1::__compressed_pair.693" = type { %"struct.std::__1::__compressed_pair_elem.694" }
%"struct.std::__1::__compressed_pair_elem.694" = type { %"class.v8::internal::Profiler"* }
%"class.v8::internal::Profiler" = type opaque
%"class.std::__1::unique_ptr.698" = type { %"class.std::__1::__compressed_pair.699" }
%"class.std::__1::__compressed_pair.699" = type { %"struct.std::__1::__compressed_pair_elem.700" }
%"struct.std::__1::__compressed_pair_elem.700" = type { %"class.v8::internal::Log"* }
%"class.v8::internal::Log" = type opaque
%"class.std::__1::unique_ptr.704" = type { %"class.std::__1::__compressed_pair.705" }
%"class.std::__1::__compressed_pair.705" = type { %"struct.std::__1::__compressed_pair_elem.706" }
%"struct.std::__1::__compressed_pair_elem.706" = type { %"class.v8::internal::PerfBasicLogger"* }
%"class.v8::internal::PerfBasicLogger" = type opaque
%"class.std::__1::unique_ptr.710" = type { %"class.std::__1::__compressed_pair.711" }
%"class.std::__1::__compressed_pair.711" = type { %"struct.std::__1::__compressed_pair_elem.712" }
%"struct.std::__1::__compressed_pair_elem.712" = type { %"class.v8::internal::PerfJitLogger"* }
%"class.v8::internal::PerfJitLogger" = type opaque
%"class.std::__1::unique_ptr.716" = type { %"class.std::__1::__compressed_pair.717" }
%"class.std::__1::__compressed_pair.717" = type { %"struct.std::__1::__compressed_pair_elem.718" }
%"struct.std::__1::__compressed_pair_elem.718" = type { %"class.v8::internal::LowLevelLogger"* }
%"class.v8::internal::LowLevelLogger" = type opaque
%"class.std::__1::unique_ptr.722" = type { %"class.std::__1::__compressed_pair.723" }
%"class.std::__1::__compressed_pair.723" = type { %"struct.std::__1::__compressed_pair_elem.724" }
%"struct.std::__1::__compressed_pair_elem.724" = type { %"class.v8::internal::JitLogger"* }
%"class.v8::internal::JitLogger" = type opaque
%"class.std::__1::set.728" = type { %"class.std::__1::__tree.729" }
%"class.std::__1::__tree.729" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.730", %"class.std::__1::__compressed_pair.734" }
%"class.std::__1::__tree_end_node" = type { %"class.std::__1::__tree_node_base"* }
%"class.std::__1::__tree_node_base" = type <{ %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_end_node"*, i8, [7 x i8] }>
%"class.std::__1::__compressed_pair.730" = type { %"struct.std::__1::__compressed_pair_elem.80" }
%"struct.std::__1::__compressed_pair_elem.80" = type { %"class.std::__1::__tree_end_node" }
%"class.std::__1::__compressed_pair.734" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.v8::internal::ExistingCodeLogger" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::CodeEventListener"* }
%"class.v8::internal::StubCache" = type { [2048 x %"struct.v8::internal::StubCache::Entry"], [512 x %"struct.v8::internal::StubCache::Entry"], %"class.v8::internal::Isolate"* }
%"struct.v8::internal::StubCache::Entry" = type { %"class.v8::internal::StrongTaggedValue", %"class.v8::internal::TaggedValue", %"class.v8::internal::StrongTaggedValue" }
%"class.v8::internal::TaggedValue" = type { %"class.v8::internal::TaggedImpl.737" }
%"class.v8::internal::TaggedImpl.737" = type { i32 }
%"class.v8::internal::StrongTaggedValue" = type { %"class.v8::internal::TaggedImpl.736" }
%"class.v8::internal::TaggedImpl.736" = type { i32 }
%"class.v8::internal::Deoptimizer" = type opaque
%"class.v8::internal::MaterializedObjectStore" = type opaque
%"class.v8::internal::DescriptorLookupCache" = type { [64 x %"struct.v8::internal::DescriptorLookupCache::Key"], [64 x i32] }
%"struct.v8::internal::DescriptorLookupCache::Key" = type { %"class.v8::internal::Map", %"class.v8::internal::Name" }
%"class.v8::internal::Map" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Name" = type { %"class.v8::internal::TorqueGeneratedName" }
%"class.v8::internal::TorqueGeneratedName" = type { %"class.v8::internal::PrimitiveHeapObject" }
%"class.v8::internal::PrimitiveHeapObject" = type { %"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" }
%"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" = type { %"class.v8::internal::HeapObject" }
%"struct.v8::internal::HandleScopeData" = type { i64*, i64*, i32, i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::CanonicalHandleScope" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::OptimizedCompilationInfo"*, %"class.v8::internal::Zone"*, %"class.v8::internal::RootIndexMap"*, %"class.std::__1::unique_ptr.744", i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::OptimizedCompilationInfo" = type opaque
%"class.v8::internal::RootIndexMap" = type opaque
%"class.std::__1::unique_ptr.744" = type { %"class.std::__1::__compressed_pair.745" }
%"class.std::__1::__compressed_pair.745" = type { %"struct.std::__1::__compressed_pair_elem.746" }
%"struct.std::__1::__compressed_pair_elem.746" = type { %"class.v8::internal::IdentityMap"* }
%"class.v8::internal::IdentityMap" = type opaque
%"class.v8::internal::HandleScopeImplementer" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::DetachableVector", %"class.v8::internal::DetachableVector.750", %"class.v8::internal::DetachableVector.751", %"class.v8::internal::DetachableVector.750", i64*, i64*, %"struct.v8::internal::HandleScopeData" }
%"class.v8::internal::DetachableVector" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVectorBase" = type { i8*, i64, i64 }
%"class.v8::internal::DetachableVector.751" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVector.750" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::UnicodeCache" = type opaque
%"class.v8::internal::AccountingAllocator" = type { i32 (...)**, %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"class.std::__1::unique_ptr.738", %"class.std::__1::unique_ptr.481" }
%"class.std::__1::unique_ptr.738" = type { %"class.std::__1::__compressed_pair.739" }
%"class.std::__1::__compressed_pair.739" = type { %"struct.std::__1::__compressed_pair_elem.740" }
%"struct.std::__1::__compressed_pair_elem.740" = type { %"class.v8::internal::VirtualMemory"* }
%"class.v8::internal::VirtualMemory" = type { %"class.v8::PageAllocator"*, %"class.v8::base::AddressRegion" }
%"class.v8::base::AddressRegion" = type { i64, i64 }
%"class.std::__1::unique_ptr.481" = type { %"class.std::__1::__compressed_pair.482" }
%"class.std::__1::__compressed_pair.482" = type { %"struct.std::__1::__compressed_pair_elem.483" }
%"struct.std::__1::__compressed_pair_elem.483" = type { %"class.v8::base::BoundedPageAllocator"* }
%"class.v8::base::BoundedPageAllocator" = type { %"class.v8::PageAllocator", %"class.v8::base::Mutex", i64, i64, %"class.v8::PageAllocator"*, %"class.v8::base::RegionAllocator" }
%"class.v8::base::RegionAllocator" = type { %"class.v8::base::RegionAllocator::Region", i64, i64, i64, i64, %"class.std::__1::set.484", %"class.std::__1::set.492" }
%"class.v8::base::RegionAllocator::Region" = type <{ %"class.v8::base::AddressRegion", i32, [4 x i8] }>
%"class.std::__1::set.484" = type { %"class.std::__1::__tree.485" }
%"class.std::__1::__tree.485" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.486", %"class.std::__1::__compressed_pair.490" }
%"class.std::__1::__compressed_pair.486" = type { %"struct.std::__1::__compressed_pair_elem.80" }
%"class.std::__1::__compressed_pair.490" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::set.492" = type { %"class.std::__1::__tree.493" }
%"class.std::__1::__tree.493" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.486", %"class.std::__1::__compressed_pair.494" }
%"class.std::__1::__compressed_pair.494" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.v8::internal::InnerPointerToCodeCache" = type opaque
%"class.v8::internal::GlobalHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.752", %"class.std::__1::vector.758", %"class.std::__1::unique_ptr.765", %"class.std::__1::vector.772", %"class.std::__1::unique_ptr.779", i64, %"class.std::__1::vector.785", %"class.std::__1::vector.793", %"class.std::__1::vector.801", i8, i8, i32 }
%"class.std::__1::unique_ptr.752" = type { %"class.std::__1::__compressed_pair.753" }
%"class.std::__1::__compressed_pair.753" = type { %"struct.std::__1::__compressed_pair_elem.754" }
%"struct.std::__1::__compressed_pair_elem.754" = type { %"class.v8::internal::GlobalHandles::NodeSpace"* }
%"class.v8::internal::GlobalHandles::NodeSpace" = type opaque
%"class.std::__1::vector.758" = type { %"class.std::__1::__vector_base.759" }
%"class.std::__1::__vector_base.759" = type { %"class.v8::internal::GlobalHandles::Node"**, %"class.v8::internal::GlobalHandles::Node"**, %"class.std::__1::__compressed_pair.760" }
%"class.v8::internal::GlobalHandles::Node" = type opaque
%"class.std::__1::__compressed_pair.760" = type { %"struct.std::__1::__compressed_pair_elem.761" }
%"struct.std::__1::__compressed_pair_elem.761" = type { %"class.v8::internal::GlobalHandles::Node"** }
%"class.std::__1::unique_ptr.765" = type { %"class.std::__1::__compressed_pair.766" }
%"class.std::__1::__compressed_pair.766" = type { %"struct.std::__1::__compressed_pair_elem.767" }
%"struct.std::__1::__compressed_pair_elem.767" = type { %"class.v8::internal::GlobalHandles::NodeSpace.768"* }
%"class.v8::internal::GlobalHandles::NodeSpace.768" = type opaque
%"class.std::__1::vector.772" = type { %"class.std::__1::__vector_base.773" }
%"class.std::__1::__vector_base.773" = type { %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.std::__1::__compressed_pair.774" }
%"class.v8::internal::GlobalHandles::TracedNode" = type opaque
%"class.std::__1::__compressed_pair.774" = type { %"struct.std::__1::__compressed_pair_elem.775" }
%"struct.std::__1::__compressed_pair_elem.775" = type { %"class.v8::internal::GlobalHandles::TracedNode"** }
%"class.std::__1::unique_ptr.779" = type { %"class.std::__1::__compressed_pair.780" }
%"class.std::__1::__compressed_pair.780" = type { %"struct.std::__1::__compressed_pair_elem.781" }
%"struct.std::__1::__compressed_pair_elem.781" = type { %"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace"* }
%"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace" = type opaque
%"class.std::__1::vector.785" = type { %"class.std::__1::__vector_base.786" }
%"class.std::__1::__vector_base.786" = type { %"struct.std::__1::pair.787"*, %"struct.std::__1::pair.787"*, %"class.std::__1::__compressed_pair.788" }
%"struct.std::__1::pair.787" = type opaque
%"class.std::__1::__compressed_pair.788" = type { %"struct.std::__1::__compressed_pair_elem.789" }
%"struct.std::__1::__compressed_pair_elem.789" = type { %"struct.std::__1::pair.787"* }
%"class.std::__1::vector.793" = type { %"class.std::__1::__vector_base.794" }
%"class.std::__1::__vector_base.794" = type { %"struct.std::__1::pair.795"*, %"struct.std::__1::pair.795"*, %"class.std::__1::__compressed_pair.796" }
%"struct.std::__1::pair.795" = type opaque
%"class.std::__1::__compressed_pair.796" = type { %"struct.std::__1::__compressed_pair_elem.797" }
%"struct.std::__1::__compressed_pair_elem.797" = type { %"struct.std::__1::pair.795"* }
%"class.std::__1::vector.801" = type { %"class.std::__1::__vector_base.802" }
%"class.std::__1::__vector_base.802" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.std::__1::__compressed_pair.803" }
%"class.v8::internal::GlobalHandles::PendingPhantomCallback" = type { void (%"class.v8::WeakCallbackInfo"*)*, i8*, [2 x i8*] }
%"class.v8::WeakCallbackInfo" = type { %"class.v8::Isolate"*, i8*, {}**, [2 x i8*] }
%"class.v8::Isolate" = type { i8 }
%"class.std::__1::__compressed_pair.803" = type { %"struct.std::__1::__compressed_pair_elem.804" }
%"struct.std::__1::__compressed_pair_elem.804" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"* }
%"class.v8::internal::EternalHandles" = type { i32, %"class.std::__1::vector.808", %"class.std::__1::vector.815" }
%"class.std::__1::vector.808" = type { %"class.std::__1::__vector_base.809" }
%"class.std::__1::__vector_base.809" = type { i64**, i64**, %"class.std::__1::__compressed_pair.810" }
%"class.std::__1::__compressed_pair.810" = type { %"struct.std::__1::__compressed_pair_elem.811" }
%"struct.std::__1::__compressed_pair_elem.811" = type { i64** }
%"class.v8::internal::ThreadManager" = type opaque
%"class.v8::bigint::Processor" = type opaque
%"class.v8::internal::RuntimeState" = type { %"class.std::__1::unique_ptr.822" }
%"class.std::__1::unique_ptr.822" = type { %"class.std::__1::__compressed_pair.823" }
%"class.std::__1::__compressed_pair.823" = type { %"struct.std::__1::__compressed_pair_elem.824" }
%"struct.std::__1::__compressed_pair_elem.824" = type { %"struct.v8::internal::Runtime::Function"* }
%"struct.v8::internal::Runtime::Function" = type { i32, i32, i8*, i64, i8, i8 }
%"class.v8::internal::Builtins" = type { %"class.v8::internal::Isolate"*, i8, i32 }
%"class.v8::internal::SetupIsolateDelegate" = type opaque
%"class.v8::internal::RegExpStack" = type opaque
%"class.std::__1::vector.815" = type { %"class.std::__1::__vector_base.816" }
%"class.std::__1::__vector_base.816" = type { i32*, i32*, %"class.std::__1::__compressed_pair.817" }
%"class.std::__1::__compressed_pair.817" = type { %"struct.std::__1::__compressed_pair_elem.818" }
%"struct.std::__1::__compressed_pair_elem.818" = type { i32* }
%"class.v8::internal::DateCache" = type opaque
%"class.v8::base::RandomNumberGenerator" = type { i64, i64, i64 }
%"struct.std::__1::atomic.828" = type { %"struct.std::__1::__atomic_base.829" }
%"struct.std::__1::__atomic_base.829" = type { %"struct.std::__1::__cxx_atomic_impl.830" }
%"struct.std::__1::__cxx_atomic_impl.830" = type { %"struct.std::__1::__cxx_atomic_base_impl.831" }
%"struct.std::__1::__cxx_atomic_base_impl.831" = type { i32 }
%"class.v8::Promise" = type { i8 }
%"struct.std::__1::atomic.838" = type { %"struct.std::__1::__atomic_base.839" }
%"struct.std::__1::__atomic_base.839" = type { %"struct.std::__1::__cxx_atomic_impl.840" }
%"struct.std::__1::__cxx_atomic_impl.840" = type { %"struct.std::__1::__cxx_atomic_base_impl.841" }
%"struct.std::__1::__cxx_atomic_base_impl.841" = type { i32 }
%"class.std::__1::basic_string" = type { %"class.std::__1::__compressed_pair.843" }
%"class.std::__1::__compressed_pair.843" = type { %"struct.std::__1::__compressed_pair_elem.844" }
%"struct.std::__1::__compressed_pair_elem.844" = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" = type { %union.anon.845 }
%union.anon.845 = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" = type { i8*, i64, i64 }
%"class.std::__1::unordered_map.849" = type { %"class.std::__1::__hash_table.850" }
%"class.std::__1::__hash_table.850" = type <{ %"class.std::__1::unique_ptr.851", %"class.std::__1::__compressed_pair.861", %"class.std::__1::__compressed_pair.866", %"class.std::__1::__compressed_pair.869", [4 x i8] }>
%"class.std::__1::unique_ptr.851" = type { %"class.std::__1::__compressed_pair.852" }
%"class.std::__1::__compressed_pair.852" = type { %"struct.std::__1::__compressed_pair_elem.853", %"struct.std::__1::__compressed_pair_elem.855" }
%"struct.std::__1::__compressed_pair_elem.853" = type { %"struct.std::__1::__hash_node_base.854"** }
%"struct.std::__1::__hash_node_base.854" = type { %"struct.std::__1::__hash_node_base.854"* }
%"struct.std::__1::__compressed_pair_elem.855" = type { %"class.std::__1::__bucket_list_deallocator.856" }
%"class.std::__1::__bucket_list_deallocator.856" = type { %"class.std::__1::__compressed_pair.857" }
%"class.std::__1::__compressed_pair.857" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.861" = type { %"struct.std::__1::__compressed_pair_elem.862" }
%"struct.std::__1::__compressed_pair_elem.862" = type { %"struct.std::__1::__hash_node_base.854" }
%"class.std::__1::__compressed_pair.866" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.869" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"struct.std::__1::atomic.152" = type { %"struct.std::__1::__atomic_base.153" }
%"struct.std::__1::__atomic_base.153" = type { %"struct.std::__1::__cxx_atomic_impl.154" }
%"struct.std::__1::__cxx_atomic_impl.154" = type { %"struct.std::__1::__cxx_atomic_base_impl.155" }
%"struct.std::__1::__cxx_atomic_base_impl.155" = type { i8 }
%"class.v8::internal::Debug" = type { %"class.v8::debug::DebugDelegate"*, i8, i8, i8, i8, i8, i8, i8, i8, i8, %"class.v8::internal::DebugInfoListNode"*, %"class.std::__1::unique_ptr.875", %"class.v8::internal::Handle.881", %"class.v8::internal::DebugFeatureTracker", %"class.v8::internal::Debug::ThreadLocal", %"class.v8::internal::Handle.882", %"class.v8::internal::Isolate"* }
%"class.v8::debug::DebugDelegate" = type { i32 (...)** }
%"class.v8::internal::DebugInfoListNode" = type { i64*, %"class.v8::internal::DebugInfoListNode"* }
%"class.std::__1::unique_ptr.875" = type { %"class.std::__1::__compressed_pair.876" }
%"class.std::__1::__compressed_pair.876" = type { %"struct.std::__1::__compressed_pair_elem.877" }
%"struct.std::__1::__compressed_pair_elem.877" = type { %"class.v8::internal::Debug::TemporaryObjectsTracker"* }
%"class.v8::internal::Debug::TemporaryObjectsTracker" = type opaque
%"class.v8::internal::Handle.881" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::DebugFeatureTracker" = type <{ %"class.v8::internal::Isolate"*, i32, [4 x i8] }>
%"class.v8::internal::Debug::ThreadLocal" = type <{ i64, i32, i8, [3 x i8], %"class.v8::internal::Object", i8, [3 x i8], i32, i32, i32, %"class.v8::internal::Object", %"class.v8::internal::Object", i32, i8, [3 x i8] }>
%"class.v8::internal::Handle.882" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HeapProfiler" = type { %"class.v8::internal::HeapObjectAllocationTracker", %"class.std::__1::unique_ptr.883", %"class.std::__1::vector.889", %"class.std::__1::unique_ptr.897", %"class.std::__1::unique_ptr.903", i8, i8, %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.909", %"class.std::__1::vector.915", %"struct.std::__1::pair.923" }
%"class.v8::internal::HeapObjectAllocationTracker" = type { i32 (...)** }
%"class.std::__1::unique_ptr.883" = type { %"class.std::__1::__compressed_pair.884" }
%"class.std::__1::__compressed_pair.884" = type { %"struct.std::__1::__compressed_pair_elem.885" }
%"struct.std::__1::__compressed_pair_elem.885" = type { %"class.v8::internal::HeapObjectsMap"* }
%"class.v8::internal::HeapObjectsMap" = type opaque
%"class.std::__1::vector.889" = type { %"class.std::__1::__vector_base.890" }
%"class.std::__1::__vector_base.890" = type { %"class.std::__1::unique_ptr.891"*, %"class.std::__1::unique_ptr.891"*, %"class.std::__1::__compressed_pair.892" }
%"class.std::__1::unique_ptr.891" = type opaque
%"class.std::__1::__compressed_pair.892" = type { %"struct.std::__1::__compressed_pair_elem.893" }
%"struct.std::__1::__compressed_pair_elem.893" = type { %"class.std::__1::unique_ptr.891"* }
%"class.std::__1::unique_ptr.897" = type { %"class.std::__1::__compressed_pair.898" }
%"class.std::__1::__compressed_pair.898" = type { %"struct.std::__1::__compressed_pair_elem.899" }
%"struct.std::__1::__compressed_pair_elem.899" = type { %"class.v8::internal::StringsStorage"* }
%"class.v8::internal::StringsStorage" = type opaque
%"class.std::__1::unique_ptr.903" = type { %"class.std::__1::__compressed_pair.904" }
%"class.std::__1::__compressed_pair.904" = type { %"struct.std::__1::__compressed_pair_elem.905" }
%"struct.std::__1::__compressed_pair_elem.905" = type { %"class.v8::internal::AllocationTracker"* }
%"class.v8::internal::AllocationTracker" = type opaque
%"class.std::__1::unique_ptr.909" = type { %"class.std::__1::__compressed_pair.910" }
%"class.std::__1::__compressed_pair.910" = type { %"struct.std::__1::__compressed_pair_elem.911" }
%"struct.std::__1::__compressed_pair_elem.911" = type { %"class.v8::internal::SamplingHeapProfiler"* }
%"class.v8::internal::SamplingHeapProfiler" = type opaque
%"class.std::__1::vector.915" = type { %"class.std::__1::__vector_base.916" }
%"class.std::__1::__vector_base.916" = type { %"struct.std::__1::pair.917"*, %"struct.std::__1::pair.917"*, %"class.std::__1::__compressed_pair.918" }
%"struct.std::__1::pair.917" = type opaque
%"class.std::__1::__compressed_pair.918" = type { %"struct.std::__1::__compressed_pair_elem.919" }
%"struct.std::__1::__compressed_pair_elem.919" = type { %"struct.std::__1::pair.917"* }
%"struct.std::__1::pair.923" = type { i8 (%"class.v8::Isolate"*, %"class.v8::Local.0"*, i16, i8*)*, i8* }
%"class.v8::Local.0" = type { %"class.v8::Value"* }
%"class.std::__1::unique_ptr.924" = type { %"class.std::__1::__compressed_pair.925" }
%"class.std::__1::__compressed_pair.925" = type { %"struct.std::__1::__compressed_pair_elem.926" }
%"struct.std::__1::__compressed_pair_elem.926" = type { %"class.v8::internal::CodeEventDispatcher"* }
%"class.v8::internal::CodeEventDispatcher" = type { %"class.v8::internal::CodeEventListener", %"class.std::__1::unordered_set.927", %"class.v8::base::Mutex" }
%"class.std::__1::unordered_set.927" = type { %"class.std::__1::__hash_table.928" }
%"class.std::__1::__hash_table.928" = type <{ %"class.std::__1::unique_ptr.929", %"class.std::__1::__compressed_pair.939", %"class.std::__1::__compressed_pair.944", %"class.std::__1::__compressed_pair.948", [4 x i8] }>
%"class.std::__1::unique_ptr.929" = type { %"class.std::__1::__compressed_pair.930" }
%"class.std::__1::__compressed_pair.930" = type { %"struct.std::__1::__compressed_pair_elem.931", %"struct.std::__1::__compressed_pair_elem.933" }
%"struct.std::__1::__compressed_pair_elem.931" = type { %"struct.std::__1::__hash_node_base.932"** }
%"struct.std::__1::__hash_node_base.932" = type { %"struct.std::__1::__hash_node_base.932"* }
%"struct.std::__1::__compressed_pair_elem.933" = type { %"class.std::__1::__bucket_list_deallocator.934" }
%"class.std::__1::__bucket_list_deallocator.934" = type { %"class.std::__1::__compressed_pair.935" }
%"class.std::__1::__compressed_pair.935" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.939" = type { %"struct.std::__1::__compressed_pair_elem.940" }
%"struct.std::__1::__compressed_pair_elem.940" = type { %"struct.std::__1::__hash_node_base.932" }
%"class.std::__1::__compressed_pair.944" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.948" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::internal::AstStringConstants" = type opaque
%"class.v8::internal::interpreter::Interpreter" = type opaque
%"class.v8::internal::compiler::PerIsolateCompilerCache" = type opaque
%"class.v8::internal::Zone" = type <{ i64, i64, i64, i64, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::Segment"*, i8*, i8, i8, [6 x i8] }>
%"class.v8::internal::Segment" = type { %"class.v8::internal::Zone"*, %"class.v8::internal::Segment"*, i64 }
%"class.v8::internal::CompilerDispatcher" = type opaque
%"class.std::__1::queue" = type { %"class.std::__1::deque" }
%"class.std::__1::deque" = type { %"class.std::__1::__deque_base" }
%"class.std::__1::__deque_base" = type { %"struct.std::__1::__split_buffer", i64, %"class.std::__1::__compressed_pair.962" }
%"struct.std::__1::__split_buffer" = type { %"struct.std::__1::pair.956"**, %"struct.std::__1::pair.956"**, %"struct.std::__1::pair.956"**, %"class.std::__1::__compressed_pair.957" }
%"struct.std::__1::pair.956" = type opaque
%"class.std::__1::__compressed_pair.957" = type { %"struct.std::__1::__compressed_pair_elem.958" }
%"struct.std::__1::__compressed_pair_elem.958" = type { %"struct.std::__1::pair.956"** }
%"class.std::__1::__compressed_pair.962" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.v8::String" = type { i8 }
%"class.v8::Context" = type { i8 }
%"class.v8::FunctionCallbackInfo" = type <{ i64*, i64*, i32, [4 x i8] }>
%"class.v8::internal::Relocatable" = type { i32 (...)**, %"class.v8::internal::Isolate"*, %"class.v8::internal::Relocatable"* }
%"class.std::__1::vector.967" = type { %"class.std::__1::__vector_base.968" }
%"class.std::__1::__vector_base.968" = type { %"class.v8::internal::Handle.969"*, %"class.v8::internal::Handle.969"*, %"class.std::__1::__compressed_pair.970" }
%"class.v8::internal::Handle.969" = type { %"class.v8::internal::HandleBase" }
%"class.std::__1::__compressed_pair.970" = type { %"struct.std::__1::__compressed_pair_elem.971" }
%"struct.std::__1::__compressed_pair_elem.971" = type { %"class.v8::internal::Handle.969"* }
%"class.v8::internal::AddressToIndexHashMap" = type opaque
%"class.v8::internal::HeapObjectToIndexHashMap" = type opaque
%"class.v8::internal::MicrotaskQueue" = type opaque
%"class.v8::internal::CompilationStatistics" = type opaque
%"class.v8::internal::CodeTracer" = type <{ %"class.v8::internal::EmbeddedVector", %struct._IO_FILE*, i32, [4 x i8] }>
%"class.v8::internal::EmbeddedVector" = type { %"class.v8::internal::Vector", [128 x i8] }
%"class.v8::internal::Vector" = type { i8*, i64 }
%struct._IO_FILE = type { i32, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, %struct._IO_marker*, %struct._IO_FILE*, i32, i32, i64, i16, i8, [1 x i8], i8*, i64, %struct._IO_codecvt*, %struct._IO_wide_data*, %struct._IO_FILE*, i8*, i64, i32, [20 x i8] }
%struct._IO_marker = type opaque
%struct._IO_codecvt = type opaque
%struct._IO_wide_data = type opaque
%"class.v8::PromiseRejectMessage" = type { %"class.v8::Local.833", i32, %"class.v8::Local.0" }
%"class.v8::Local.833" = type { %"class.v8::Promise"* }
%"class.v8::StartupData" = type { i8*, i32 }
%"class.v8_inspector::V8Inspector" = type opaque
%"class.v8::internal::compiler::NodeObserver" = type opaque
%"class.v8::internal::OptimizingCompileDispatcher" = type opaque
%"class.std::__1::unique_ptr.975" = type { %"class.std::__1::__compressed_pair.976" }
%"class.std::__1::__compressed_pair.976" = type { %"struct.std::__1::__compressed_pair_elem.977" }
%"struct.std::__1::__compressed_pair_elem.977" = type { %"class.v8::internal::PersistentHandlesList"* }
%"class.v8::internal::PersistentHandlesList" = type { %"class.v8::base::Mutex", %"class.v8::internal::PersistentHandles"* }
%"class.v8::internal::PersistentHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::vector.808", i64*, i64*, %"class.v8::internal::PersistentHandles"*, %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.981" = type { %"class.std::__1::__vector_base.982" }
%"class.std::__1::__vector_base.982" = type { void (%"class.v8::Isolate"*)**, void (%"class.v8::Isolate"*)**, %"class.std::__1::__compressed_pair.983" }
%"class.std::__1::__compressed_pair.983" = type { %"struct.std::__1::__compressed_pair_elem.984" }
%"struct.std::__1::__compressed_pair_elem.984" = type { void (%"class.v8::Isolate"*)** }
%"class.std::__1::shared_ptr.988" = type { %"class.v8::internal::metrics::Recorder"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::metrics::Recorder" = type opaque
%"class.std::__1::unordered_map.989" = type { %"class.std::__1::__hash_table.990" }
%"class.std::__1::__hash_table.990" = type <{ %"class.std::__1::unique_ptr.991", %"class.std::__1::__compressed_pair.1001", %"class.std::__1::__compressed_pair.1006", %"class.std::__1::__compressed_pair.1009", [4 x i8] }>
%"class.std::__1::unique_ptr.991" = type { %"class.std::__1::__compressed_pair.992" }
%"class.std::__1::__compressed_pair.992" = type { %"struct.std::__1::__compressed_pair_elem.993", %"struct.std::__1::__compressed_pair_elem.995" }
%"struct.std::__1::__compressed_pair_elem.993" = type { %"struct.std::__1::__hash_node_base.994"** }
%"struct.std::__1::__hash_node_base.994" = type { %"struct.std::__1::__hash_node_base.994"* }
%"struct.std::__1::__compressed_pair_elem.995" = type { %"class.std::__1::__bucket_list_deallocator.996" }
%"class.std::__1::__bucket_list_deallocator.996" = type { %"class.std::__1::__compressed_pair.997" }
%"class.std::__1::__compressed_pair.997" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1001" = type { %"struct.std::__1::__compressed_pair_elem.1002" }
%"struct.std::__1::__compressed_pair_elem.1002" = type { %"struct.std::__1::__hash_node_base.994" }
%"class.std::__1::__compressed_pair.1006" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1009" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"struct.v8::metrics::LongTaskStats" = type { i64, i64, i64 }
%"class.v8::internal::BuiltinsConstantsTableBuilder" = type opaque
%"class.v8::ArrayBuffer::Allocator" = type { i32 (...)** }
%"class.std::__1::shared_ptr.160" = type { %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::FutexWaitListNode" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::shared_ptr.1013", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::base::ConditionVariable", %"class.v8::internal::FutexWaitListNode"*, %"class.v8::internal::FutexWaitListNode"*, %"class.std::__1::weak_ptr.1042", i64, i8*, i8, i8, %"class.v8::Global", %"class.v8::Global.1043", %"class.v8::base::TimeTicks", i64 }
%"class.std::__1::shared_ptr.1013" = type { %"class.v8::TaskRunner"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::TaskRunner" = type { i32 (...)** }
%"class.v8::base::ConditionVariable" = type { %union.pthread_cond_t }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon.1038, %union.anon.1040, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon.1038 = type { i64 }
%union.anon.1040 = type { i64 }
%"class.std::__1::weak_ptr.1042" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::BackingStore" = type <{ i8*, %"struct.std::__1::atomic.19", i64, %"union.v8::internal::BackingStore::TypeSpecificData", i16, [6 x i8] }>
%"union.v8::internal::BackingStore::TypeSpecificData" = type { %"class.std::__1::shared_ptr.160" }
%"class.v8::Global" = type { %"class.v8::PersistentBase" }
%"class.v8::PersistentBase" = type { %"class.v8::Promise"* }
%"class.v8::Global.1043" = type { %"class.v8::PersistentBase.1044" }
%"class.v8::PersistentBase.1044" = type { %"class.v8::Context"* }
%"class.v8::internal::CancelableTaskManager" = type <{ i64, %"class.std::__1::unordered_map.1014", %"class.v8::base::ConditionVariable", %"class.v8::base::Mutex", i8, [7 x i8] }>
%"class.std::__1::unordered_map.1014" = type { %"class.std::__1::__hash_table.1015" }
%"class.std::__1::__hash_table.1015" = type <{ %"class.std::__1::unique_ptr.1016", %"class.std::__1::__compressed_pair.1026", %"class.std::__1::__compressed_pair.1031", %"class.std::__1::__compressed_pair.1034", [4 x i8] }>
%"class.std::__1::unique_ptr.1016" = type { %"class.std::__1::__compressed_pair.1017" }
%"class.std::__1::__compressed_pair.1017" = type { %"struct.std::__1::__compressed_pair_elem.1018", %"struct.std::__1::__compressed_pair_elem.1020" }
%"struct.std::__1::__compressed_pair_elem.1018" = type { %"struct.std::__1::__hash_node_base.1019"** }
%"struct.std::__1::__hash_node_base.1019" = type { %"struct.std::__1::__hash_node_base.1019"* }
%"struct.std::__1::__compressed_pair_elem.1020" = type { %"class.std::__1::__bucket_list_deallocator.1021" }
%"class.std::__1::__bucket_list_deallocator.1021" = type { %"class.std::__1::__compressed_pair.1022" }
%"class.std::__1::__compressed_pair.1022" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1026" = type { %"struct.std::__1::__compressed_pair_elem.1027" }
%"struct.std::__1::__compressed_pair_elem.1027" = type { %"struct.std::__1::__hash_node_base.1019" }
%"class.std::__1::__compressed_pair.1031" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1034" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::debug::ConsoleDelegate" = type { i32 (...)** }
%"class.v8::debug::AsyncEventDelegate" = type { i32 (...)** }
%"class.std::__1::unique_ptr.1045" = type { %"class.std::__1::__compressed_pair.1046" }
%"class.std::__1::__compressed_pair.1046" = type { %"struct.std::__1::__compressed_pair_elem.1047" }
%"struct.std::__1::__compressed_pair_elem.1047" = type { %"class.v8::internal::LocalIsolate"* }
%"class.v8::internal::LocalIsolate" = type { %"class.v8::internal::HiddenLocalFactory", %"class.v8::internal::LocalHeap", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.1074", %"class.v8::internal::ThreadId", i64, %"class.v8::internal::RuntimeCallStats"* }
%"class.v8::internal::HiddenLocalFactory" = type { %"class.v8::internal::LocalFactory" }
%"class.v8::internal::LocalFactory" = type { %"class.v8::internal::ReadOnlyRoots" }
%"class.v8::internal::ReadOnlyRoots" = type { i64* }
%"class.v8::internal::LocalHeap" = type { %"class.v8::internal::Heap"*, i8, %"struct.std::__1::atomic.1050", i8, i8, %"class.v8::internal::LocalHeap"*, %"class.v8::internal::LocalHeap"*, %"class.std::__1::unique_ptr.1054", %"class.std::__1::unique_ptr.1060", %"class.std::__1::unique_ptr.474", %"class.std::__1::vector.1066", %"class.v8::internal::ConcurrentAllocator" }
%"struct.std::__1::atomic.1050" = type { %"struct.std::__1::__atomic_base.1051" }
%"struct.std::__1::__atomic_base.1051" = type { %"struct.std::__1::__cxx_atomic_impl.1052" }
%"struct.std::__1::__cxx_atomic_impl.1052" = type { %"struct.std::__1::__cxx_atomic_base_impl.1053" }
%"struct.std::__1::__cxx_atomic_base_impl.1053" = type { i32 }
%"class.std::__1::unique_ptr.1054" = type { %"class.std::__1::__compressed_pair.1055" }
%"class.std::__1::__compressed_pair.1055" = type { %"struct.std::__1::__compressed_pair_elem.1056" }
%"struct.std::__1::__compressed_pair_elem.1056" = type { %"class.v8::internal::LocalHandles"* }
%"class.v8::internal::LocalHandles" = type { %"struct.v8::internal::HandleScopeData", %"class.std::__1::vector.808" }
%"class.std::__1::unique_ptr.1060" = type { %"class.std::__1::__compressed_pair.1061" }
%"class.std::__1::__compressed_pair.1061" = type { %"struct.std::__1::__compressed_pair_elem.1062" }
%"struct.std::__1::__compressed_pair_elem.1062" = type { %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.1066" = type { %"class.std::__1::__vector_base.1067" }
%"class.std::__1::__vector_base.1067" = type { %"struct.std::__1::pair.1068"*, %"struct.std::__1::pair.1068"*, %"class.std::__1::__compressed_pair.1069" }
%"struct.std::__1::pair.1068" = type opaque
%"class.std::__1::__compressed_pair.1069" = type { %"struct.std::__1::__compressed_pair_elem.1070" }
%"struct.std::__1::__compressed_pair_elem.1070" = type { %"struct.std::__1::pair.1068"* }
%"class.v8::internal::ConcurrentAllocator" = type { %"class.v8::internal::LocalHeap"*, %"class.v8::internal::PagedSpace"*, %"class.v8::internal::LocalAllocationBuffer" }
%"class.v8::internal::PagedSpace" = type { %"class.v8::internal::SpaceWithLinearArea", i32, i32, i64, %"class.v8::internal::AllocationStats", %"class.v8::base::Mutex", i64, i64 }
%"class.v8::internal::SpaceWithLinearArea" = type { %"class.v8::internal::Space", %"class.v8::internal::LinearAllocationArea", [3 x i64] }
%"class.v8::internal::Space" = type { %"class.v8::internal::BaseSpace", %"class.v8::internal::AllocationCounter", %"class.v8::internal::heap::List", %"struct.std::__1::atomic.19"*, %"class.std::__1::unique_ptr.97" }
%"class.v8::internal::AllocationCounter" = type <{ %"class.std::__1::vector.38", %"class.std::__1::vector.38", %"class.std::__1::unordered_set", i8, [7 x i8], i64, i64, i8, [7 x i8] }>
%"class.std::__1::vector.38" = type { %"class.std::__1::__vector_base.39" }
%"class.std::__1::__vector_base.39" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"class.std::__1::__compressed_pair.40" }
%"struct.v8::internal::AllocationCounter::AllocationObserverCounter" = type { %"class.v8::internal::AllocationObserver"*, i64, i64 }
%"class.std::__1::__compressed_pair.40" = type { %"struct.std::__1::__compressed_pair_elem.41" }
%"struct.std::__1::__compressed_pair_elem.41" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* }
%"class.std::__1::unordered_set" = type { %"class.std::__1::__hash_table.45" }
%"class.std::__1::__hash_table.45" = type <{ %"class.std::__1::unique_ptr.46", %"class.std::__1::__compressed_pair.56", %"class.std::__1::__compressed_pair.61", %"class.std::__1::__compressed_pair.63", [4 x i8] }>
%"class.std::__1::unique_ptr.46" = type { %"class.std::__1::__compressed_pair.47" }
%"class.std::__1::__compressed_pair.47" = type { %"struct.std::__1::__compressed_pair_elem.48", %"struct.std::__1::__compressed_pair_elem.50" }
%"struct.std::__1::__compressed_pair_elem.48" = type { %"struct.std::__1::__hash_node_base.49"** }
%"struct.std::__1::__hash_node_base.49" = type { %"struct.std::__1::__hash_node_base.49"* }
%"struct.std::__1::__compressed_pair_elem.50" = type { %"class.std::__1::__bucket_list_deallocator.51" }
%"class.std::__1::__bucket_list_deallocator.51" = type { %"class.std::__1::__compressed_pair.52" }
%"class.std::__1::__compressed_pair.52" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.56" = type { %"struct.std::__1::__compressed_pair_elem.57" }
%"struct.std::__1::__compressed_pair_elem.57" = type { %"struct.std::__1::__hash_node_base.49" }
%"class.std::__1::__compressed_pair.61" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.63" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::internal::heap::List" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.v8::internal::MemoryChunk" = type { %"class.v8::internal::BasicMemoryChunk", [2 x %"class.v8::internal::SlotSet"*], %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.24", %"class.v8::internal::SlotSet"*, [2 x %"class.v8::internal::TypedSlotSet"*], [2 x %"class.std::__1::set"*], %"class.v8::base::Mutex"*, %"struct.std::__1::atomic.86", %"class.v8::base::Mutex"*, i64, [2 x %"struct.std::__1::atomic.19"], %"class.v8::internal::heap::ListNode", %"class.v8::internal::FreeListCategory"**, %"struct.std::__1::atomic.24", %"class.v8::internal::Bitmap"*, %"class.v8::internal::CodeObjectRegistry"*, %"class.v8::internal::PossiblyEmptyBuckets" }
%"class.v8::internal::BasicMemoryChunk" = type { i64, i64, %"class.v8::internal::Heap"*, i64, i64, i64, i64, %"struct.std::__1::atomic.24", %"struct.std::__1::atomic.68", %"class.v8::internal::VirtualMemory" }
%"struct.std::__1::atomic.68" = type { %"struct.std::__1::__atomic_base.69" }
%"struct.std::__1::__atomic_base.69" = type { %"struct.std::__1::__cxx_atomic_impl.70" }
%"struct.std::__1::__cxx_atomic_impl.70" = type { %"struct.std::__1::__cxx_atomic_base_impl.71" }
%"struct.std::__1::__cxx_atomic_base_impl.71" = type { %"class.v8::internal::BaseSpace"* }
%"class.v8::internal::SlotSet" = type { i8 }
%"class.v8::internal::TypedSlotSet" = type { %"class.v8::internal::TypedSlots", i64 }
%"class.v8::internal::TypedSlots" = type { i32 (...)**, %"struct.v8::internal::TypedSlots::Chunk"*, %"struct.v8::internal::TypedSlots::Chunk"* }
%"struct.v8::internal::TypedSlots::Chunk" = type { %"struct.v8::internal::TypedSlots::Chunk"*, %"class.std::__1::vector.72" }
%"class.std::__1::vector.72" = type { %"class.std::__1::__vector_base.73" }
%"class.std::__1::__vector_base.73" = type { %"struct.v8::internal::TypedSlots::TypedSlot"*, %"struct.v8::internal::TypedSlots::TypedSlot"*, %"class.std::__1::__compressed_pair.74" }
%"struct.v8::internal::TypedSlots::TypedSlot" = type { i32 }
%"class.std::__1::__compressed_pair.74" = type { %"struct.std::__1::__compressed_pair_elem.75" }
%"struct.std::__1::__compressed_pair_elem.75" = type { %"struct.v8::internal::TypedSlots::TypedSlot"* }
%"class.std::__1::set" = type { %"class.std::__1::__tree" }
%"class.std::__1::__tree" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.79", %"class.std::__1::__compressed_pair.84" }
%"class.std::__1::__compressed_pair.79" = type { %"struct.std::__1::__compressed_pair_elem.80" }
%"class.std::__1::__compressed_pair.84" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::atomic.86" = type { %"struct.std::__1::__atomic_base.87" }
%"struct.std::__1::__atomic_base.87" = type { %"struct.std::__1::__cxx_atomic_impl.88" }
%"struct.std::__1::__cxx_atomic_impl.88" = type { %"struct.std::__1::__cxx_atomic_base_impl.89" }
%"struct.std::__1::__cxx_atomic_base_impl.89" = type { i64 }
%"class.v8::internal::heap::ListNode" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.v8::internal::FreeListCategory" = type { i32, i32, %"class.v8::internal::FreeSpace", %"class.v8::internal::FreeListCategory"*, %"class.v8::internal::FreeListCategory"* }
%"class.v8::internal::FreeSpace" = type { %"class.v8::internal::TorqueGeneratedFreeSpace" }
%"class.v8::internal::TorqueGeneratedFreeSpace" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Bitmap" = type { i8 }
%"class.v8::internal::CodeObjectRegistry" = type <{ %"class.std::__1::vector.90", i8, [7 x i8] }>
%"class.std::__1::vector.90" = type { %"class.std::__1::__vector_base.91" }
%"class.std::__1::__vector_base.91" = type { i64*, i64*, %"class.std::__1::__compressed_pair.92" }
%"class.std::__1::__compressed_pair.92" = type { %"struct.std::__1::__compressed_pair_elem.93" }
%"struct.std::__1::__compressed_pair_elem.93" = type { i64* }
%"class.v8::internal::PossiblyEmptyBuckets" = type { i64 }
%"class.std::__1::unique_ptr.97" = type { %"class.std::__1::__compressed_pair.98" }
%"class.std::__1::__compressed_pair.98" = type { %"struct.std::__1::__compressed_pair_elem.99" }
%"struct.std::__1::__compressed_pair_elem.99" = type { %"class.v8::internal::FreeList"* }
%"class.v8::internal::FreeList" = type { i32 (...)**, i32, i32, i64, %"struct.std::__1::atomic.19", %"class.v8::internal::FreeListCategory"**, i64 }
%"class.v8::internal::LinearAllocationArea" = type { i64, i64, i64 }
%"class.v8::internal::LocalAllocationBuffer" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::LinearAllocationArea" }
%"class.std::__1::unique_ptr.1074" = type { %"class.std::__1::__compressed_pair.1075" }
%"class.std::__1::__compressed_pair.1075" = type { %"struct.std::__1::__compressed_pair_elem.1076" }
%"struct.std::__1::__compressed_pair_elem.1076" = type { %"class.v8::internal::LocalLogger"* }
%"class.v8::internal::LocalLogger" = type opaque
%"struct.v8::internal::ManagedPtrDestructor" = type { i64, %"struct.v8::internal::ManagedPtrDestructor"*, %"struct.v8::internal::ManagedPtrDestructor"*, i8*, void (i8*)*, i64* }
%"class.v8::internal::wasm::WasmEngine" = type opaque
%"class.std::__1::unique_ptr.1083" = type { %"class.std::__1::__compressed_pair.1084" }
%"class.std::__1::__compressed_pair.1084" = type { %"struct.std::__1::__compressed_pair_elem.1085" }
%"struct.std::__1::__compressed_pair_elem.1085" = type { %"class.v8::internal::TracingCpuProfilerImpl"* }
%"class.v8::internal::TracingCpuProfilerImpl" = type opaque
%"class.v8::internal::EmbeddedFileWriterInterface" = type opaque
%"class.v8::Context::BackupIncumbentScope" = type { %"class.v8::Local.834", i64, %"class.v8::Context::BackupIncumbentScope"* }
%"class.v8::Local.834" = type { %"class.v8::Context"* }
%"class.v8::internal::Isolate::ThreadDataTable" = type { %"class.std::__1::unordered_map.1091" }
%"class.std::__1::unordered_map.1091" = type { %"class.std::__1::__hash_table.1092" }
%"class.std::__1::__hash_table.1092" = type <{ %"class.std::__1::unique_ptr.1093", %"class.std::__1::__compressed_pair.1103", %"class.std::__1::__compressed_pair.1108", %"class.std::__1::__compressed_pair.1111", [4 x i8] }>
%"class.std::__1::unique_ptr.1093" = type { %"class.std::__1::__compressed_pair.1094" }
%"class.std::__1::__compressed_pair.1094" = type { %"struct.std::__1::__compressed_pair_elem.1095", %"struct.std::__1::__compressed_pair_elem.1097" }
%"struct.std::__1::__compressed_pair_elem.1095" = type { %"struct.std::__1::__hash_node_base.1096"** }
%"struct.std::__1::__hash_node_base.1096" = type { %"struct.std::__1::__hash_node_base.1096"* }
%"struct.std::__1::__compressed_pair_elem.1097" = type { %"class.std::__1::__bucket_list_deallocator.1098" }
%"class.std::__1::__bucket_list_deallocator.1098" = type { %"class.std::__1::__compressed_pair.1099" }
%"class.std::__1::__compressed_pair.1099" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1103" = type { %"struct.std::__1::__compressed_pair_elem.1104" }
%"struct.std::__1::__compressed_pair_elem.1104" = type { %"struct.std::__1::__hash_node_base.1096" }
%"class.std::__1::__compressed_pair.1108" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1111" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"struct.std::__1::atomic.1117" = type { %"struct.std::__1::__atomic_base.1118" }
%"struct.std::__1::__atomic_base.1118" = type { %"struct.std::__1::__cxx_atomic_impl.1119" }
%"struct.std::__1::__cxx_atomic_impl.1119" = type { %"struct.std::__1::__cxx_atomic_base_impl.1120" }
%"struct.std::__1::__cxx_atomic_base_impl.1120" = type { %"class.std::__1::vector.1121"* }
%"class.std::__1::vector.1121" = type { %"class.std::__1::__vector_base.1122" }
%"class.std::__1::__vector_base.1122" = type { %"struct.v8::MemoryRange"*, %"struct.v8::MemoryRange"*, %"class.std::__1::__compressed_pair.1123" }
%"struct.v8::MemoryRange" = type { i8*, i64 }
%"class.std::__1::__compressed_pair.1123" = type { %"struct.std::__1::__compressed_pair_elem.1124" }
%"struct.std::__1::__compressed_pair_elem.1124" = type { %"struct.v8::MemoryRange"* }
%"struct.std::__1::atomic.29" = type { %"struct.std::__1::__atomic_base.30" }
%"struct.std::__1::__atomic_base.30" = type { %"struct.std::__1::__cxx_atomic_impl.31" }
%"struct.std::__1::__cxx_atomic_impl.31" = type { %"struct.std::__1::__cxx_atomic_base_impl.32" }
%"struct.std::__1::__cxx_atomic_base_impl.32" = type { i32 }
%"class.std::__1::vector" = type { %"class.std::__1::__vector_base" }
%"class.std::__1::__vector_base" = type { %"struct.std::__1::pair"*, %"struct.std::__1::pair"*, %"class.std::__1::__compressed_pair.33" }
%"struct.std::__1::pair" = type opaque
%"class.std::__1::__compressed_pair.33" = type { %"struct.std::__1::__compressed_pair_elem.34" }
%"struct.std::__1::__compressed_pair_elem.34" = type { %"struct.std::__1::pair"* }
%"class.v8::internal::NewSpace" = type { %"class.v8::internal::SpaceWithLinearArea", %"class.v8::base::Mutex", %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace", %"class.v8::internal::VirtualMemory", %"class.std::__1::vector.103" }
%"class.v8::internal::SemiSpace" = type { %"class.v8::internal::Space", i64, i64, i64, i64, i64, i32, %"class.v8::internal::Page"* }
%"class.v8::internal::Page" = type { %"class.v8::internal::MemoryChunk" }
%"class.std::__1::vector.103" = type { %"class.std::__1::__vector_base.104" }
%"class.std::__1::__vector_base.104" = type { %"struct.std::__1::pair.105"*, %"struct.std::__1::pair.105"*, %"class.std::__1::__compressed_pair.106" }
%"struct.std::__1::pair.105" = type { i32, i64 }
%"class.std::__1::__compressed_pair.106" = type { %"struct.std::__1::__compressed_pair_elem.107" }
%"struct.std::__1::__compressed_pair_elem.107" = type { %"struct.std::__1::pair.105"* }
%"class.v8::internal::CodeSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::OldLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace" }
%"class.v8::internal::LargeObjectSpace" = type { %"class.v8::internal::Space", %"struct.std::__1::atomic.19", i32, %"struct.std::__1::atomic.19", %"class.v8::base::Mutex", %"struct.std::__1::atomic.19" }
%"class.v8::internal::CodeLargeObjectSpace" = type { %"class.v8::internal::OldLargeObjectSpace", %"class.std::__1::unordered_map.111" }
%"class.std::__1::unordered_map.111" = type { %"class.std::__1::__hash_table.112" }
%"class.std::__1::__hash_table.112" = type <{ %"class.std::__1::unique_ptr.113", %"class.std::__1::__compressed_pair.123", %"class.std::__1::__compressed_pair.128", %"class.std::__1::__compressed_pair.133", [4 x i8] }>
%"class.std::__1::unique_ptr.113" = type { %"class.std::__1::__compressed_pair.114" }
%"class.std::__1::__compressed_pair.114" = type { %"struct.std::__1::__compressed_pair_elem.115", %"struct.std::__1::__compressed_pair_elem.117" }
%"struct.std::__1::__compressed_pair_elem.115" = type { %"struct.std::__1::__hash_node_base.116"** }
%"struct.std::__1::__hash_node_base.116" = type { %"struct.std::__1::__hash_node_base.116"* }
%"struct.std::__1::__compressed_pair_elem.117" = type { %"class.std::__1::__bucket_list_deallocator.118" }
%"class.std::__1::__bucket_list_deallocator.118" = type { %"class.std::__1::__compressed_pair.119" }
%"class.std::__1::__compressed_pair.119" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.123" = type { %"struct.std::__1::__compressed_pair_elem.124" }
%"struct.std::__1::__compressed_pair_elem.124" = type { %"struct.std::__1::__hash_node_base.116" }
%"class.std::__1::__compressed_pair.128" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.133" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::internal::NewLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace", i64 }
%"class.v8::internal::OldSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::MapSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.std::__1::unique_ptr.146" = type { %"class.std::__1::__compressed_pair.147" }
%"class.std::__1::__compressed_pair.147" = type { %"struct.std::__1::__compressed_pair_elem.148" }
%"struct.std::__1::__compressed_pair_elem.148" = type { %"class.v8::internal::ConcurrentAllocator"* }
%"class.v8::internal::ArrayBufferExtension" = type { %"struct.std::__1::atomic.152", %"struct.std::__1::atomic.156", %"class.std::__1::shared_ptr", %"class.v8::internal::ArrayBufferExtension"*, %"struct.std::__1::atomic.19" }
%"struct.std::__1::atomic.156" = type { %"struct.std::__1::__atomic_base.157" }
%"struct.std::__1::__atomic_base.157" = type { %"struct.std::__1::__cxx_atomic_impl.158" }
%"struct.std::__1::__cxx_atomic_impl.158" = type { %"struct.std::__1::__cxx_atomic_base_impl.159" }
%"struct.std::__1::__cxx_atomic_base_impl.159" = type { i8 }
%"class.std::__1::shared_ptr" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"struct.std::__1::atomic.161" = type { %"struct.std::__1::__atomic_base.162" }
%"struct.std::__1::__atomic_base.162" = type { %"struct.std::__1::__cxx_atomic_impl.163" }
%"struct.std::__1::__cxx_atomic_impl.163" = type { %"struct.std::__1::__cxx_atomic_base_impl.164" }
%"struct.std::__1::__cxx_atomic_base_impl.164" = type { i32 }
%"class.v8::internal::AllocationObserver" = type { i32 (...)**, i64 }
%"class.v8::internal::StressScavengeObserver" = type opaque
%"class.v8::internal::Object" = type { %"class.v8::internal::TaggedImpl" }
%"class.v8::internal::TaggedImpl" = type { i64 }
%"class.std::__1::vector.165" = type { %"class.std::__1::__vector_base.166" }
%"class.std::__1::__vector_base.166" = type { %"struct.v8::internal::Heap::GCCallbackTuple"*, %"struct.v8::internal::Heap::GCCallbackTuple"*, %"class.std::__1::__compressed_pair.167" }
%"struct.v8::internal::Heap::GCCallbackTuple" = type { void (%"class.v8::Isolate"*, i32, i32, i8*)*, i32, i8* }
%"class.std::__1::__compressed_pair.167" = type { %"struct.std::__1::__compressed_pair_elem.168" }
%"struct.std::__1::__compressed_pair_elem.168" = type { %"struct.v8::internal::Heap::GCCallbackTuple"* }
%"class.std::__1::unique_ptr.172" = type { %"class.std::__1::__compressed_pair.173" }
%"class.std::__1::__compressed_pair.173" = type { %"struct.std::__1::__compressed_pair_elem.174" }
%"struct.std::__1::__compressed_pair_elem.174" = type { %"class.v8::internal::GCTracer"* }
%"class.v8::internal::GCTracer" = type opaque
%"class.std::__1::unique_ptr.178" = type { %"class.std::__1::__compressed_pair.179" }
%"class.std::__1::__compressed_pair.179" = type { %"struct.std::__1::__compressed_pair_elem.180" }
%"struct.std::__1::__compressed_pair_elem.180" = type { %"class.v8::internal::MarkCompactCollector"* }
%"class.v8::internal::MarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::base::Mutex", %"class.v8::base::Semaphore", i8, i8, i8, i8, i8, i8, [2 x i8], %"class.v8::internal::MarkingWorklists", %"class.v8::internal::WeakObjects", %"struct.v8::internal::EphemeronMarking", %"class.std::__1::unique_ptr.220", %"class.std::__1::unique_ptr.226", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", %"class.std::__1::vector.280", %"class.std::__1::vector.280", %"class.std::__1::vector.280", %"class.std::__1::vector.287", %"class.v8::internal::Sweeper"*, %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", [2 x i8], i32, i32, [4 x i8] }>
%"class.v8::internal::MarkCompactCollectorBase" = type { i32 (...)**, %"class.v8::internal::Heap"* }
%"class.v8::base::Semaphore" = type { %union.sem_t }
%union.sem_t = type { i64, [24 x i8] }
%"class.v8::internal::MarkingWorklists" = type { %"class.heap::base::Worklist", %"class.heap::base::Worklist", %"class.heap::base::Worklist.181", %"class.std::__1::vector.182", %"class.std::__1::vector.189", %"class.heap::base::Worklist" }
%"class.heap::base::Worklist.181" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment" = type opaque
%"class.std::__1::vector.182" = type { %"class.std::__1::__vector_base.183" }
%"class.std::__1::__vector_base.183" = type { %"struct.v8::internal::ContextWorklistPair"*, %"struct.v8::internal::ContextWorklistPair"*, %"class.std::__1::__compressed_pair.184" }
%"struct.v8::internal::ContextWorklistPair" = type { i64, %"class.heap::base::Worklist"* }
%"class.std::__1::__compressed_pair.184" = type { %"struct.std::__1::__compressed_pair_elem.185" }
%"struct.std::__1::__compressed_pair_elem.185" = type { %"struct.v8::internal::ContextWorklistPair"* }
%"class.std::__1::vector.189" = type { %"class.std::__1::__vector_base.190" }
%"class.std::__1::__vector_base.190" = type { %"class.std::__1::unique_ptr.191"*, %"class.std::__1::unique_ptr.191"*, %"class.std::__1::__compressed_pair.192" }
%"class.std::__1::unique_ptr.191" = type opaque
%"class.std::__1::__compressed_pair.192" = type { %"struct.std::__1::__compressed_pair_elem.193" }
%"struct.std::__1::__compressed_pair_elem.193" = type { %"class.std::__1::unique_ptr.191"* }
%"class.heap::base::Worklist" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment" = type opaque
%"class.v8::internal::WeakObjects" = type { %"class.v8::internal::Worklist", %"class.v8::internal::Worklist.197", %"class.v8::internal::Worklist.199", %"class.v8::internal::Worklist.199", %"class.v8::internal::Worklist.199", %"class.v8::internal::Worklist.201", %"class.v8::internal::Worklist.203", %"class.v8::internal::Worklist.205", %"class.v8::internal::Worklist.207", %"class.v8::internal::Worklist.209", %"class.v8::internal::Worklist.211" }
%"class.v8::internal::Worklist" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.197" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.199" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.201" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.203" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.205" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.207" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.209" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.211" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"struct.v8::internal::EphemeronMarking" = type { %"class.std::__1::vector.213", i8, i64 }
%"class.std::__1::vector.213" = type { %"class.std::__1::__vector_base.214" }
%"class.std::__1::__vector_base.214" = type { %"class.v8::internal::HeapObject"*, %"class.v8::internal::HeapObject"*, %"class.std::__1::__compressed_pair.215" }
%"class.std::__1::__compressed_pair.215" = type { %"struct.std::__1::__compressed_pair_elem.216" }
%"struct.std::__1::__compressed_pair_elem.216" = type { %"class.v8::internal::HeapObject"* }
%"class.std::__1::unique_ptr.220" = type { %"class.std::__1::__compressed_pair.221" }
%"class.std::__1::__compressed_pair.221" = type { %"struct.std::__1::__compressed_pair_elem.222" }
%"struct.std::__1::__compressed_pair_elem.222" = type { %"class.v8::internal::MainMarkingVisitor"* }
%"class.v8::internal::MainMarkingVisitor" = type opaque
%"class.std::__1::unique_ptr.226" = type { %"class.std::__1::__compressed_pair.227" }
%"class.std::__1::__compressed_pair.227" = type { %"struct.std::__1::__compressed_pair_elem.228" }
%"struct.std::__1::__compressed_pair_elem.228" = type { %"class.v8::internal::MarkingWorklists::Local"* }
%"class.v8::internal::MarkingWorklists::Local" = type { %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", i64, %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local"*, i8, [7 x i8], %"class.std::__1::unordered_map.229" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local" = type { %"class.heap::base::Worklist.181"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.heap::base::internal::SegmentBase" = type { i16, i16 }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local" = type { %"class.heap::base::Worklist"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.std::__1::unordered_map.229" = type { %"class.std::__1::__hash_table.230" }
%"class.std::__1::__hash_table.230" = type <{ %"class.std::__1::unique_ptr.231", %"class.std::__1::__compressed_pair.241", %"class.std::__1::__compressed_pair.246", %"class.std::__1::__compressed_pair.249", [4 x i8] }>
%"class.std::__1::unique_ptr.231" = type { %"class.std::__1::__compressed_pair.232" }
%"class.std::__1::__compressed_pair.232" = type { %"struct.std::__1::__compressed_pair_elem.233", %"struct.std::__1::__compressed_pair_elem.235" }
%"struct.std::__1::__compressed_pair_elem.233" = type { %"struct.std::__1::__hash_node_base.234"** }
%"struct.std::__1::__hash_node_base.234" = type { %"struct.std::__1::__hash_node_base.234"* }
%"struct.std::__1::__compressed_pair_elem.235" = type { %"class.std::__1::__bucket_list_deallocator.236" }
%"class.std::__1::__bucket_list_deallocator.236" = type { %"class.std::__1::__compressed_pair.237" }
%"class.std::__1::__compressed_pair.237" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.241" = type { %"struct.std::__1::__compressed_pair_elem.242" }
%"struct.std::__1::__compressed_pair_elem.242" = type { %"struct.std::__1::__hash_node_base.234" }
%"class.std::__1::__compressed_pair.246" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.249" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::internal::NativeContextInferrer" = type { i8 }
%"class.v8::internal::NativeContextStats" = type { %"class.std::__1::unordered_map.256" }
%"class.std::__1::unordered_map.256" = type { %"class.std::__1::__hash_table.257" }
%"class.std::__1::__hash_table.257" = type <{ %"class.std::__1::unique_ptr.258", %"class.std::__1::__compressed_pair.268", %"class.std::__1::__compressed_pair.273", %"class.std::__1::__compressed_pair.276", [4 x i8] }>
%"class.std::__1::unique_ptr.258" = type { %"class.std::__1::__compressed_pair.259" }
%"class.std::__1::__compressed_pair.259" = type { %"struct.std::__1::__compressed_pair_elem.260", %"struct.std::__1::__compressed_pair_elem.262" }
%"struct.std::__1::__compressed_pair_elem.260" = type { %"struct.std::__1::__hash_node_base.261"** }
%"struct.std::__1::__hash_node_base.261" = type { %"struct.std::__1::__hash_node_base.261"* }
%"struct.std::__1::__compressed_pair_elem.262" = type { %"class.std::__1::__bucket_list_deallocator.263" }
%"class.std::__1::__bucket_list_deallocator.263" = type { %"class.std::__1::__compressed_pair.264" }
%"class.std::__1::__compressed_pair.264" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.268" = type { %"struct.std::__1::__compressed_pair_elem.269" }
%"struct.std::__1::__compressed_pair_elem.269" = type { %"struct.std::__1::__hash_node_base.261" }
%"class.std::__1::__compressed_pair.273" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.276" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::vector.280" = type { %"class.std::__1::__vector_base.281" }
%"class.std::__1::__vector_base.281" = type { %"class.v8::internal::Page"**, %"class.v8::internal::Page"**, %"class.std::__1::__compressed_pair.282" }
%"class.std::__1::__compressed_pair.282" = type { %"struct.std::__1::__compressed_pair_elem.283" }
%"struct.std::__1::__compressed_pair_elem.283" = type { %"class.v8::internal::Page"** }
%"class.std::__1::vector.287" = type { %"class.std::__1::__vector_base.288" }
%"class.std::__1::__vector_base.288" = type { %"struct.std::__1::pair.289"*, %"struct.std::__1::pair.289"*, %"class.std::__1::__compressed_pair.290" }
%"struct.std::__1::pair.289" = type opaque
%"class.std::__1::__compressed_pair.290" = type { %"struct.std::__1::__compressed_pair_elem.291" }
%"struct.std::__1::__compressed_pair_elem.291" = type { %"struct.std::__1::pair.289"* }
%"class.v8::internal::Sweeper" = type <{ %"class.v8::internal::Heap"*, %"class.v8::internal::MajorNonAtomicMarkingState"*, %"class.std::__1::unique_ptr.295", %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.280"], [3 x %"class.std::__1::vector.280"], i8, %"struct.std::__1::atomic.152", [6 x i8], %"class.std::__1::vector.280", i64, %"class.v8::base::Semaphore", i8, i8, i8, [5 x i8] }>
%"class.std::__1::unique_ptr.295" = type { %"class.std::__1::__compressed_pair.296" }
%"class.std::__1::__compressed_pair.296" = type { %"struct.std::__1::__compressed_pair_elem.297" }
%"struct.std::__1::__compressed_pair_elem.297" = type { %"class.v8::JobHandle"* }
%"class.v8::JobHandle" = type { i32 (...)** }
%"class.v8::internal::MajorMarkingState" = type { i8 }
%"class.v8::internal::MajorNonAtomicMarkingState" = type { i8 }
%"class.v8::internal::MinorMarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::internal::Worklist.305"*, %"class.v8::internal::YoungGenerationMarkingVisitor"*, %"class.v8::base::Semaphore", %"class.std::__1::vector.280", %"class.std::__1::vector.280", %"class.v8::internal::MinorMarkingState", %"class.v8::internal::MinorNonAtomicMarkingState", [6 x i8] }>
%"class.v8::internal::Worklist.305" = type opaque
%"class.v8::internal::YoungGenerationMarkingVisitor" = type opaque
%"class.v8::internal::MinorMarkingState" = type { i8 }
%"class.v8::internal::MinorNonAtomicMarkingState" = type { i8 }
%"class.std::__1::unique_ptr.308" = type { %"class.std::__1::__compressed_pair.309" }
%"class.std::__1::__compressed_pair.309" = type { %"struct.std::__1::__compressed_pair_elem.310" }
%"struct.std::__1::__compressed_pair_elem.310" = type { %"class.v8::internal::ScavengerCollector"* }
%"class.v8::internal::ScavengerCollector" = type opaque
%"class.std::__1::unique_ptr.314" = type { %"class.std::__1::__compressed_pair.315" }
%"class.std::__1::__compressed_pair.315" = type { %"struct.std::__1::__compressed_pair_elem.316" }
%"struct.std::__1::__compressed_pair_elem.316" = type { %"class.v8::internal::ArrayBufferSweeper"* }
%"class.v8::internal::ArrayBufferSweeper" = type opaque
%"class.std::__1::unique_ptr.320" = type { %"class.std::__1::__compressed_pair.321" }
%"class.std::__1::__compressed_pair.321" = type { %"struct.std::__1::__compressed_pair_elem.322" }
%"struct.std::__1::__compressed_pair_elem.322" = type { %"class.v8::internal::MemoryAllocator"* }
%"class.v8::internal::MemoryAllocator" = type { %"class.v8::internal::Isolate"*, %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"*, i64, %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"class.v8::internal::VirtualMemory", %"class.v8::internal::MemoryAllocator::Unmapper", %"class.std::__1::unordered_set.330", %"class.v8::base::Mutex" }
%"class.v8::internal::MemoryAllocator::Unmapper" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MemoryAllocator"*, %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.323"], %"class.std::__1::unique_ptr.295" }
%"class.std::__1::vector.323" = type { %"class.std::__1::__vector_base.324" }
%"class.std::__1::__vector_base.324" = type { %"class.v8::internal::MemoryChunk"**, %"class.v8::internal::MemoryChunk"**, %"class.std::__1::__compressed_pair.325" }
%"class.std::__1::__compressed_pair.325" = type { %"struct.std::__1::__compressed_pair_elem.326" }
%"struct.std::__1::__compressed_pair_elem.326" = type { %"class.v8::internal::MemoryChunk"** }
%"class.std::__1::unique_ptr.359" = type { %"class.std::__1::__compressed_pair.360" }
%"class.std::__1::__compressed_pair.360" = type { %"struct.std::__1::__compressed_pair_elem.361" }
%"struct.std::__1::__compressed_pair_elem.361" = type { %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::IncrementalMarking" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MarkCompactCollector"*, %"class.v8::internal::WeakObjects"*, double, double, i64, i64, i64, i64, double, i64, %"struct.std::__1::atomic.362", i8, i8, i8, i8, [3 x i8], %"class.v8::internal::IncrementalMarkingJob", %"struct.std::__1::atomic.366", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorAtomicMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", %"class.v8::base::Mutex", %"class.std::__1::unordered_map.371" }
%"struct.std::__1::atomic.362" = type { %"struct.std::__1::__atomic_base.363" }
%"struct.std::__1::__atomic_base.363" = type { %"struct.std::__1::__cxx_atomic_impl.364" }
%"struct.std::__1::__cxx_atomic_impl.364" = type { %"struct.std::__1::__cxx_atomic_base_impl.365" }
%"struct.std::__1::__cxx_atomic_base_impl.365" = type { i8 }
%"class.v8::internal::IncrementalMarkingJob" = type <{ %"class.v8::base::Mutex", double, i8, i8, [6 x i8] }>
%"struct.std::__1::atomic.366" = type { %"struct.std::__1::__atomic_base.367" }
%"struct.std::__1::__atomic_base.367" = type { %"struct.std::__1::__cxx_atomic_impl.368" }
%"struct.std::__1::__cxx_atomic_impl.368" = type { %"struct.std::__1::__cxx_atomic_base_impl.369" }
%"struct.std::__1::__cxx_atomic_base_impl.369" = type { i32 }
%"class.v8::internal::IncrementalMarking::Observer" = type { %"class.v8::internal::AllocationObserver", %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::MajorAtomicMarkingState" = type { i8 }
%"class.std::__1::unordered_map.371" = type { %"class.std::__1::__hash_table.372" }
%"class.std::__1::__hash_table.372" = type <{ %"class.std::__1::unique_ptr.373", %"class.std::__1::__compressed_pair.383", %"class.std::__1::__compressed_pair.388", %"class.std::__1::__compressed_pair.391", [4 x i8] }>
%"class.std::__1::unique_ptr.373" = type { %"class.std::__1::__compressed_pair.374" }
%"class.std::__1::__compressed_pair.374" = type { %"struct.std::__1::__compressed_pair_elem.375", %"struct.std::__1::__compressed_pair_elem.377" }
%"struct.std::__1::__compressed_pair_elem.375" = type { %"struct.std::__1::__hash_node_base.376"** }
%"struct.std::__1::__hash_node_base.376" = type { %"struct.std::__1::__hash_node_base.376"* }
%"struct.std::__1::__compressed_pair_elem.377" = type { %"class.std::__1::__bucket_list_deallocator.378" }
%"class.std::__1::__bucket_list_deallocator.378" = type { %"class.std::__1::__compressed_pair.379" }
%"class.std::__1::__compressed_pair.379" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.383" = type { %"struct.std::__1::__compressed_pair_elem.384" }
%"struct.std::__1::__compressed_pair_elem.384" = type { %"struct.std::__1::__hash_node_base.376" }
%"class.std::__1::__compressed_pair.388" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.391" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unique_ptr.398" = type { %"class.std::__1::__compressed_pair.399" }
%"class.std::__1::__compressed_pair.399" = type { %"struct.std::__1::__compressed_pair_elem.400" }
%"struct.std::__1::__compressed_pair_elem.400" = type { %"class.v8::internal::ConcurrentMarking"* }
%"class.v8::internal::ConcurrentMarking" = type <{ %"class.std::__1::unique_ptr.295", %"class.v8::internal::Heap"*, %"class.v8::internal::MarkingWorklists"*, %"class.v8::internal::WeakObjects"*, [8 x %"struct.v8::internal::ConcurrentMarking::TaskState"], %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.152", [7 x i8] }>
%"struct.v8::internal::ConcurrentMarking::TaskState" = type { i64, %"class.std::__1::unordered_map.401", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", [64 x i8] }
%"class.std::__1::unordered_map.401" = type { %"class.std::__1::__hash_table.402" }
%"class.std::__1::__hash_table.402" = type <{ %"class.std::__1::unique_ptr.403", %"class.std::__1::__compressed_pair.413", %"class.std::__1::__compressed_pair.418", %"class.std::__1::__compressed_pair.421", [4 x i8] }>
%"class.std::__1::unique_ptr.403" = type { %"class.std::__1::__compressed_pair.404" }
%"class.std::__1::__compressed_pair.404" = type { %"struct.std::__1::__compressed_pair_elem.405", %"struct.std::__1::__compressed_pair_elem.407" }
%"struct.std::__1::__compressed_pair_elem.405" = type { %"struct.std::__1::__hash_node_base.406"** }
%"struct.std::__1::__hash_node_base.406" = type { %"struct.std::__1::__hash_node_base.406"* }
%"struct.std::__1::__compressed_pair_elem.407" = type { %"class.std::__1::__bucket_list_deallocator.408" }
%"class.std::__1::__bucket_list_deallocator.408" = type { %"class.std::__1::__compressed_pair.409" }
%"class.std::__1::__compressed_pair.409" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.413" = type { %"struct.std::__1::__compressed_pair_elem.414" }
%"struct.std::__1::__compressed_pair_elem.414" = type { %"struct.std::__1::__hash_node_base.406" }
%"class.std::__1::__compressed_pair.418" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.421" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unique_ptr.428" = type { %"class.std::__1::__compressed_pair.429" }
%"class.std::__1::__compressed_pair.429" = type { %"struct.std::__1::__compressed_pair_elem.430" }
%"struct.std::__1::__compressed_pair_elem.430" = type { %"class.v8::internal::GCIdleTimeHandler"* }
%"class.v8::internal::GCIdleTimeHandler" = type opaque
%"class.std::__1::unique_ptr.434" = type { %"class.std::__1::__compressed_pair.435" }
%"class.std::__1::__compressed_pair.435" = type { %"struct.std::__1::__compressed_pair_elem.436" }
%"struct.std::__1::__compressed_pair_elem.436" = type { %"class.v8::internal::MemoryMeasurement"* }
%"class.v8::internal::MemoryMeasurement" = type { %"class.std::__1::list", %"class.std::__1::list", %"class.std::__1::list", %"class.v8::internal::Isolate"*, i8, i8, i8, %"class.v8::base::RandomNumberGenerator" }
%"class.std::__1::list" = type { %"class.std::__1::__list_imp" }
%"class.std::__1::__list_imp" = type { %"struct.std::__1::__list_node_base", %"class.std::__1::__compressed_pair.437" }
%"struct.std::__1::__list_node_base" = type { %"struct.std::__1::__list_node_base"*, %"struct.std::__1::__list_node_base"* }
%"class.std::__1::__compressed_pair.437" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::unique_ptr.444" = type { %"class.std::__1::__compressed_pair.445" }
%"class.std::__1::__compressed_pair.445" = type { %"struct.std::__1::__compressed_pair_elem.446" }
%"struct.std::__1::__compressed_pair_elem.446" = type { %"class.v8::internal::MemoryReducer"* }
%"class.v8::internal::MemoryReducer" = type opaque
%"class.std::__1::unique_ptr.450" = type { %"class.std::__1::__compressed_pair.451" }
%"class.std::__1::__compressed_pair.451" = type { %"struct.std::__1::__compressed_pair_elem.452" }
%"struct.std::__1::__compressed_pair_elem.452" = type { %"class.v8::internal::ObjectStats"* }
%"class.v8::internal::ObjectStats" = type opaque
%"class.std::__1::unique_ptr.456" = type { %"class.std::__1::__compressed_pair.457" }
%"class.std::__1::__compressed_pair.457" = type { %"struct.std::__1::__compressed_pair_elem.458" }
%"struct.std::__1::__compressed_pair_elem.458" = type { %"class.v8::internal::ScavengeJob"* }
%"class.v8::internal::ScavengeJob" = type opaque
%"class.std::__1::unique_ptr.462" = type { %"class.std::__1::__compressed_pair.463" }
%"class.std::__1::__compressed_pair.463" = type { %"struct.std::__1::__compressed_pair_elem.464" }
%"struct.std::__1::__compressed_pair_elem.464" = type { %"class.v8::internal::AllocationObserver"* }
%"class.std::__1::unique_ptr.468" = type { %"class.std::__1::__compressed_pair.469" }
%"class.std::__1::__compressed_pair.469" = type { %"struct.std::__1::__compressed_pair_elem.470" }
%"struct.std::__1::__compressed_pair_elem.470" = type { %"class.v8::internal::LocalEmbedderHeapTracer"* }
%"class.v8::internal::LocalEmbedderHeapTracer" = type opaque
%"class.std::__1::unique_ptr.474" = type { %"class.std::__1::__compressed_pair.475" }
%"class.std::__1::__compressed_pair.475" = type { %"struct.std::__1::__compressed_pair_elem.476" }
%"struct.std::__1::__compressed_pair_elem.476" = type { %"class.v8::internal::MarkingBarrier"* }
%"class.v8::internal::MarkingBarrier" = type opaque
%"class.std::__1::shared_ptr.480" = type { %"class.v8::internal::CodeRange"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::CodeRange" = type { %"class.v8::internal::VirtualMemoryCage", %"struct.std::__1::atomic.499", %"class.v8::base::Mutex" }
%"class.v8::internal::VirtualMemoryCage" = type { i32 (...)**, i64, %"class.std::__1::unique_ptr.481", %"class.v8::internal::VirtualMemory" }
%"struct.std::__1::atomic.499" = type { %"struct.std::__1::__atomic_base.500" }
%"struct.std::__1::__atomic_base.500" = type { %"struct.std::__1::__cxx_atomic_impl.501" }
%"struct.std::__1::__cxx_atomic_impl.501" = type { %"struct.std::__1::__cxx_atomic_base_impl.502" }
%"struct.std::__1::__cxx_atomic_base_impl.502" = type { i8* }
%"class.v8::CppHeap" = type opaque
%"class.v8::EmbedderRootsHandler" = type { i32 (...)** }
%"class.v8::internal::StrongRootsEntry" = type { %"class.v8::internal::FullObjectSlot", %"class.v8::internal::FullObjectSlot", %"class.v8::internal::StrongRootsEntry"*, %"class.v8::internal::StrongRootsEntry"* }
%"class.v8::internal::FullObjectSlot" = type { %"class.v8::internal::SlotBase" }
%"class.v8::internal::SlotBase" = type { i64 }
%"class.std::__1::unordered_map.503" = type { %"class.std::__1::__hash_table.504" }
%"class.std::__1::__hash_table.504" = type <{ %"class.std::__1::unique_ptr.505", %"class.std::__1::__compressed_pair.515", %"class.std::__1::__compressed_pair.520", %"class.std::__1::__compressed_pair.523", [4 x i8] }>
%"class.std::__1::unique_ptr.505" = type { %"class.std::__1::__compressed_pair.506" }
%"class.std::__1::__compressed_pair.506" = type { %"struct.std::__1::__compressed_pair_elem.507", %"struct.std::__1::__compressed_pair_elem.509" }
%"struct.std::__1::__compressed_pair_elem.507" = type { %"struct.std::__1::__hash_node_base.508"** }
%"struct.std::__1::__hash_node_base.508" = type { %"struct.std::__1::__hash_node_base.508"* }
%"struct.std::__1::__compressed_pair_elem.509" = type { %"class.std::__1::__bucket_list_deallocator.510" }
%"class.std::__1::__bucket_list_deallocator.510" = type { %"class.std::__1::__compressed_pair.511" }
%"class.std::__1::__compressed_pair.511" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.515" = type { %"struct.std::__1::__compressed_pair_elem.516" }
%"struct.std::__1::__compressed_pair_elem.516" = type { %"struct.std::__1::__hash_node_base.508" }
%"class.std::__1::__compressed_pair.520" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.523" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unique_ptr.529" = type { %"class.std::__1::__compressed_pair.530" }
%"class.std::__1::__compressed_pair.530" = type { %"struct.std::__1::__compressed_pair_elem.531" }
%"struct.std::__1::__compressed_pair_elem.531" = type { %"class.v8::internal::GlobalHandleVector"* }
%"class.v8::internal::GlobalHandleVector" = type opaque
%"class.std::__1::unique_ptr.535" = type { %"class.std::__1::__compressed_pair.536" }
%"class.std::__1::__compressed_pair.536" = type { %"struct.std::__1::__compressed_pair_elem.537" }
%"struct.std::__1::__compressed_pair_elem.537" = type { %"class.v8::internal::GlobalSafepoint"* }
%"class.v8::internal::GlobalSafepoint" = type opaque
%"class.v8::internal::Heap::ExternalStringTable" = type { %"class.v8::internal::Heap"*, %"class.std::__1::vector.541", %"class.std::__1::vector.541" }
%"class.std::__1::unique_ptr.548" = type { %"class.std::__1::__compressed_pair.549" }
%"class.std::__1::__compressed_pair.549" = type { %"struct.std::__1::__compressed_pair_elem.550" }
%"struct.std::__1::__compressed_pair_elem.550" = type { %"class.v8::internal::CollectionBarrier"* }
%"class.v8::internal::CollectionBarrier" = type opaque
%"class.v8::internal::HeapObject" = type { %"class.v8::internal::Object" }
%"class.v8::base::SharedMutex" = type { %union.pthread_rwlock_t }
%union.pthread_rwlock_t = type { %struct.__pthread_rwlock_arch_t }
%struct.__pthread_rwlock_arch_t = type { i32, i32, i32, i32, i32, i32, i32, i32, i8, [7 x i8], i64, i32 }
%"class.v8::base::Mutex" = type { %union.pthread_mutex_t }
%"class.std::__1::unordered_set.330" = type { %"class.std::__1::__hash_table.331" }
%"class.std::__1::__hash_table.331" = type <{ %"class.std::__1::unique_ptr.332", %"class.std::__1::__compressed_pair.342", %"class.std::__1::__compressed_pair.347", %"class.std::__1::__compressed_pair.351", [4 x i8] }>
%"class.std::__1::unique_ptr.332" = type { %"class.std::__1::__compressed_pair.333" }
%"class.std::__1::__compressed_pair.333" = type { %"struct.std::__1::__compressed_pair_elem.334", %"struct.std::__1::__compressed_pair_elem.336" }
%"struct.std::__1::__compressed_pair_elem.334" = type { %"struct.std::__1::__hash_node_base.335"** }
%"struct.std::__1::__hash_node_base.335" = type { %"struct.std::__1::__hash_node_base.335"* }
%"struct.std::__1::__compressed_pair_elem.336" = type { %"class.std::__1::__bucket_list_deallocator.337" }
%"class.std::__1::__bucket_list_deallocator.337" = type { %"class.std::__1::__compressed_pair.338" }
%"class.std::__1::__compressed_pair.338" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.342" = type { %"struct.std::__1::__compressed_pair_elem.343" }
%"struct.std::__1::__compressed_pair_elem.343" = type { %"struct.std::__1::__hash_node_base.335" }
%"class.std::__1::__compressed_pair.347" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.351" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unordered_map.580" = type { %"class.std::__1::__hash_table.581" }
%"class.std::__1::__hash_table.581" = type <{ %"class.std::__1::unique_ptr.582", %"class.std::__1::__compressed_pair.592", %"class.std::__1::__compressed_pair.597", %"class.std::__1::__compressed_pair.600", [4 x i8] }>
%"class.std::__1::unique_ptr.582" = type { %"class.std::__1::__compressed_pair.583" }
%"class.std::__1::__compressed_pair.583" = type { %"struct.std::__1::__compressed_pair_elem.584", %"struct.std::__1::__compressed_pair_elem.586" }
%"struct.std::__1::__compressed_pair_elem.584" = type { %"struct.std::__1::__hash_node_base.585"** }
%"struct.std::__1::__hash_node_base.585" = type { %"struct.std::__1::__hash_node_base.585"* }
%"struct.std::__1::__compressed_pair_elem.586" = type { %"class.std::__1::__bucket_list_deallocator.587" }
%"class.std::__1::__bucket_list_deallocator.587" = type { %"class.std::__1::__compressed_pair.588" }
%"class.std::__1::__compressed_pair.588" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.592" = type { %"struct.std::__1::__compressed_pair_elem.593" }
%"struct.std::__1::__compressed_pair_elem.593" = type { %"struct.std::__1::__hash_node_base.585" }
%"class.std::__1::__compressed_pair.597" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.600" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unordered_map.554" = type { %"class.std::__1::__hash_table.555" }
%"class.std::__1::__hash_table.555" = type <{ %"class.std::__1::unique_ptr.556", %"class.std::__1::__compressed_pair.566", %"class.std::__1::__compressed_pair.571", %"class.std::__1::__compressed_pair.574", [4 x i8] }>
%"class.std::__1::unique_ptr.556" = type { %"class.std::__1::__compressed_pair.557" }
%"class.std::__1::__compressed_pair.557" = type { %"struct.std::__1::__compressed_pair_elem.558", %"struct.std::__1::__compressed_pair_elem.560" }
%"struct.std::__1::__compressed_pair_elem.558" = type { %"struct.std::__1::__hash_node_base.559"** }
%"struct.std::__1::__hash_node_base.559" = type { %"struct.std::__1::__hash_node_base.559"* }
%"struct.std::__1::__compressed_pair_elem.560" = type { %"class.std::__1::__bucket_list_deallocator.561" }
%"class.std::__1::__bucket_list_deallocator.561" = type { %"class.std::__1::__compressed_pair.562" }
%"class.std::__1::__compressed_pair.562" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.566" = type { %"struct.std::__1::__compressed_pair_elem.567" }
%"struct.std::__1::__compressed_pair_elem.567" = type { %"struct.std::__1::__hash_node_base.559" }
%"class.std::__1::__compressed_pair.571" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.574" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unordered_map.604" = type { %"class.std::__1::__hash_table.605" }
%"class.std::__1::__hash_table.605" = type <{ %"class.std::__1::unique_ptr.606", %"class.std::__1::__compressed_pair.616", %"class.std::__1::__compressed_pair.621", %"class.std::__1::__compressed_pair.626", [4 x i8] }>
%"class.std::__1::unique_ptr.606" = type { %"class.std::__1::__compressed_pair.607" }
%"class.std::__1::__compressed_pair.607" = type { %"struct.std::__1::__compressed_pair_elem.608", %"struct.std::__1::__compressed_pair_elem.610" }
%"struct.std::__1::__compressed_pair_elem.608" = type { %"struct.std::__1::__hash_node_base.609"** }
%"struct.std::__1::__hash_node_base.609" = type { %"struct.std::__1::__hash_node_base.609"* }
%"struct.std::__1::__compressed_pair_elem.610" = type { %"class.std::__1::__bucket_list_deallocator.611" }
%"class.std::__1::__bucket_list_deallocator.611" = type { %"class.std::__1::__compressed_pair.612" }
%"class.std::__1::__compressed_pair.612" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.616" = type { %"struct.std::__1::__compressed_pair_elem.617" }
%"struct.std::__1::__compressed_pair_elem.617" = type { %"struct.std::__1::__hash_node_base.609" }
%"class.std::__1::__compressed_pair.621" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.626" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::vector.632" = type { %"class.std::__1::__vector_base.633" }
%"class.std::__1::__vector_base.633" = type { %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.std::__1::__compressed_pair.634" }
%"class.std::__1::__compressed_pair.634" = type { %"struct.std::__1::__compressed_pair_elem.635" }
%"struct.std::__1::__compressed_pair_elem.635" = type { %"class.v8::internal::HeapObjectAllocationTracker"** }
%"class.std::__1::unique_ptr.639" = type { %"class.std::__1::__compressed_pair.640" }
%"class.std::__1::__compressed_pair.640" = type { %"struct.std::__1::__compressed_pair_elem.641" }
%"struct.std::__1::__compressed_pair_elem.641" = type { %"class.v8::internal::third_party_heap::Heap"* }
%"class.v8::internal::third_party_heap::Heap" = type { i8 }
%"struct.std::__1::atomic.19" = type { %"struct.std::__1::__atomic_base.20" }
%"struct.std::__1::__atomic_base.20" = type { %"struct.std::__1::__atomic_base.21" }
%"struct.std::__1::__atomic_base.21" = type { %"struct.std::__1::__cxx_atomic_impl.22" }
%"struct.std::__1::__cxx_atomic_impl.22" = type { %"struct.std::__1::__cxx_atomic_base_impl.23" }
%"struct.std::__1::__cxx_atomic_base_impl.23" = type { i64 }
%"class.v8::internal::AllocationStats" = type { %"struct.std::__1::atomic.19", i64, %"struct.std::__1::atomic.19" }
%"class.std::__1::vector.139" = type { %"class.std::__1::__vector_base.140" }
%"class.std::__1::__vector_base.140" = type { %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"**, %"class.std::__1::__compressed_pair.141" }
%"class.v8::internal::ReadOnlyPage" = type { %"class.v8::internal::BasicMemoryChunk" }
%"class.std::__1::__compressed_pair.141" = type { %"struct.std::__1::__compressed_pair_elem.142" }
%"struct.std::__1::__compressed_pair_elem.142" = type { %"class.v8::internal::ReadOnlyPage"** }
%"class.std::__1::vector.541" = type { %"class.std::__1::__vector_base.542" }
%"class.std::__1::__vector_base.542" = type { %"class.v8::internal::Object"*, %"class.v8::internal::Object"*, %"class.std::__1::__compressed_pair.543" }
%"class.std::__1::__compressed_pair.543" = type { %"struct.std::__1::__compressed_pair_elem.544" }
%"struct.std::__1::__compressed_pair_elem.544" = type { %"class.v8::internal::Object"* }
%"class.v8::internal::TransitionsAccessor" = type <{ %"class.v8::internal::Isolate"*, %"class.v8::internal::Handle.1128", %"class.v8::internal::Map", %"class.v8::internal::MaybeObject", i32, i8, [3 x i8] }>
%"class.v8::internal::Handle.1128" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::MaybeObject" = type { %"class.v8::internal::TaggedImpl.1129" }
%"class.v8::internal::TaggedImpl.1129" = type { i64 }
%"class.v8::internal::String" = type { %"class.v8::internal::TorqueGeneratedString" }
%"class.v8::internal::TorqueGeneratedString" = type { %"class.v8::internal::Name" }
%"class.v8::internal::Handle<v8::internal::Map>::ObjectRef" = type { %"class.v8::internal::Map" }
%"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef" = type { %"class.v8::internal::TransitionArray" }
%"class.v8::internal::TransitionArray" = type { %"class.v8::internal::WeakFixedArray" }
%"class.v8::internal::WeakFixedArray" = type { %"class.v8::internal::TorqueGeneratedWeakFixedArray" }
%"class.v8::internal::TorqueGeneratedWeakFixedArray" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Factory" = type { i8 }
%"class.std::__1::function" = type { %"class.std::__1::__function::__policy_func" }
%"class.std::__1::__function::__policy_func" = type { %"union.std::__1::__function::__policy_storage", %"struct.std::__1::__function::__policy_invoker", %"struct.std::__1::__function::__policy"* }
%"union.std::__1::__function::__policy_storage" = type { i8*, [8 x i8] }
%"struct.std::__1::__function::__policy_invoker" = type { void (%"union.std::__1::__function::__policy_storage"*, %"class.v8::internal::Map"*)* }
%"struct.std::__1::__function::__policy" = type { i8* (i8*)*, void (i8*)*, i8, %"class.std::type_info"* }
%"class.std::type_info" = type { i32 (...)**, i8* }
%"class.v8::internal::CombinationAssertScope" = type { i8 }
%"class.v8::internal::Symbol" = type { %"class.v8::internal::TorqueGeneratedSymbol" }
%"class.v8::internal::TorqueGeneratedSymbol" = type { %"class.v8::internal::Name" }

$_ZN2v88internal3Map14SetBackPointerENS0_10HeapObjectENS0_16WriteBarrierModeE = comdat any

$_ZN2v88internal15TransitionArray3SetEiNS0_4NameENS0_11MaybeObjectE = comdat any

$_ZN2v88internal12BinarySearchILNS0_10SearchModeE0ENS0_15TransitionArrayEEEiPT0_NS0_4NameEiPi = comdat any

@.str = private unnamed_addr constant [17 x i8] c"unreachable code\00", align 1
@.str.1 = private unnamed_addr constant [18 x i8] c"Check failed: %s.\00", align 1
@.str.2 = private unnamed_addr constant [35 x i8] c"new_nof <= kMaxNumberOfTransitions\00", align 1
@.str.3 = private unnamed_addr constant [19 x i8] c"index == kNotFound\00", align 1
@_ZN2v88internal32FLAG_cache_prototype_transitionsE = external local_unnamed_addr global i8, align 1
@.str.4 = private unnamed_addr constant [42 x i8] c"instance_type() >= FIRST_JS_RECEIVER_TYPE\00", align 1
@.str.5 = private unnamed_addr constant [14 x i8] c"value.IsMap()\00", align 1
@.str.6 = private unnamed_addr constant [31 x i8] c"GetBackPointer().IsUndefined()\00", align 1
@.str.7 = private unnamed_addr constant [67 x i8] c"Map::cast(value).GetConstructor() == constructor_or_back_pointer()\00", align 1
@.str.8 = private unnamed_addr constant [15 x i8] c"0 <= max_slack\00", align 1
@_ZN2v88internal16SoleReadOnlyHeap15shared_ro_heap_E = external local_unnamed_addr global %"class.v8::internal::SoleReadOnlyHeap"*, align 8

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal19TransitionsAccessor21HasSimpleTransitionToENS0_3MapE(%"class.v8::internal::TransitionsAccessor"* nocapture readonly, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %4 = load i32, i32* %3, align 8
  switch i32 %4, label %12 [
    i32 3, label %5
    i32 0, label %13
    i32 1, label %13
    i32 2, label %13
    i32 4, label %13
  ]

5:                                                ; preds = %2
  %6 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = trunc i64 %7 to i32
  %9 = and i32 %8, -3
  %10 = trunc i64 %1 to i32
  %11 = icmp eq i32 %9, %10
  br label %13

12:                                               ; preds = %2
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

13:                                               ; preds = %2, %2, %2, %2, %5
  %14 = phi i1 [ %11, %5 ], [ false, %2 ], [ false, %2 ], [ false, %2 ], [ false, %2 ]
  ret i1 %14
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: noreturn
declare void @_Z8V8_FatalPKcz(i8*, ...) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19TransitionsAccessor6InsertENS0_6HandleINS0_4NameEEENS2_INS0_3MapEEENS0_20SimpleTransitionFlagE(%"class.v8::internal::TransitionsAccessor"*, i64*, i64*, i32) local_unnamed_addr #0 align 2 {
  %5 = alloca %"class.v8::internal::String", align 8
  %6 = alloca %"class.v8::internal::Handle<v8::internal::Map>::ObjectRef", align 8
  %7 = alloca %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", align 8
  %8 = alloca %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", align 8
  %9 = alloca %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", align 8
  %10 = alloca i32, align 4
  %11 = alloca %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", align 8
  %12 = alloca %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", align 8
  %13 = alloca %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", align 8
  %14 = alloca i32, align 4
  %15 = alloca %"class.v8::internal::TransitionArray", align 8
  %16 = alloca %"class.v8::internal::TransitionArray", align 8
  %17 = alloca %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", align 8
  %18 = alloca %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", align 8
  %19 = alloca %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", align 8
  %20 = bitcast %"class.v8::internal::Handle<v8::internal::Map>::ObjectRef"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %20) #6
  %21 = load i64, i64* %2, align 8
  %22 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::Map>::ObjectRef", %"class.v8::internal::Handle<v8::internal::Map>::ObjectRef"* %6, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %21, i64* %22, align 8
  %23 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::Map>::ObjectRef", %"class.v8::internal::Handle<v8::internal::Map>::ObjectRef"* %6, i64 0, i32 0
  %24 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %25 = load i64, i64* %24, align 8
  call void @_ZN2v88internal3Map14SetBackPointerENS0_10HeapObjectENS0_16WriteBarrierModeE(%"class.v8::internal::Map"* nonnull %23, i64 %25, i32 4)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %20) #6
  %26 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %27 = load i32, i32* %26, align 8
  switch i32 %27, label %811 [
    i32 1, label %28
    i32 2, label %28
    i32 3, label %173
  ]

28:                                               ; preds = %4, %4
  %29 = icmp eq i32 %3, 0
  br i1 %29, label %30, label %74

30:                                               ; preds = %28
  %31 = load i64, i64* %2, align 8
  %32 = load i64, i64* %24, align 8
  %33 = add i64 %32, 35
  %34 = inttoptr i64 %33 to i32*
  %35 = trunc i64 %31 to i32
  %36 = or i32 %35, 2
  store atomic volatile i32 %36, i32* %34 release, align 4
  %37 = load i64, i64* %24, align 8
  %38 = add i64 %37, 35
  %39 = and i64 %31, 1
  %40 = icmp ne i64 %39, 0
  %41 = icmp ne i32 %36, 3
  %42 = and i1 %40, %41
  br i1 %42, label %43, label %1531

43:                                               ; preds = %30
  %44 = and i64 %37, -262144
  %45 = or i64 %44, 8
  %46 = inttoptr i64 %45 to i64*
  %47 = load i64, i64* %46, align 8
  %48 = and i64 %47, 262144
  %49 = icmp eq i64 %48, 0
  %50 = and i64 %31, -3
  br i1 %49, label %57, label %51

51:                                               ; preds = %43
  %52 = or i64 %44, 16
  %53 = inttoptr i64 %52 to %"class.v8::internal::Heap"**
  %54 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %53, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %54, i64 %37, i64 %38, i64 %50) #6
  %55 = load i64, i64* %24, align 8
  %56 = add i64 %55, 35
  br label %57

57:                                               ; preds = %43, %51
  %58 = phi i64 [ %56, %51 ], [ %38, %43 ]
  %59 = phi i64 [ %55, %51 ], [ %37, %43 ]
  %60 = and i64 %31, -262144
  %61 = or i64 %60, 8
  %62 = inttoptr i64 %61 to i64*
  %63 = load i64, i64* %62, align 8
  %64 = and i64 %63, 24
  %65 = icmp eq i64 %64, 0
  br i1 %65, label %1531, label %66

66:                                               ; preds = %57
  %67 = and i64 %59, -262144
  %68 = or i64 %67, 8
  %69 = inttoptr i64 %68 to i64*
  %70 = load i64, i64* %69, align 8
  %71 = and i64 %70, 24
  %72 = icmp eq i64 %71, 0
  br i1 %72, label %73, label %1531

73:                                               ; preds = %66
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %59, i64 %58, i64 %50) #6
  br label %1531

74:                                               ; preds = %28
  %75 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %76 = bitcast %"class.v8::internal::TransitionsAccessor"* %0 to %"class.v8::internal::Factory"**
  %77 = load %"class.v8::internal::Factory"*, %"class.v8::internal::Factory"** %76, align 8
  %78 = call i64* @_ZN2v88internal7Factory18NewTransitionArrayEii(%"class.v8::internal::Factory"* %77, i32 1, i32 0) #6
  %79 = bitcast %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %79) #6
  %80 = load i64, i64* %78, align 8
  %81 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %7, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %80, i64* %81, align 8
  %82 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %7, i64 0, i32 0
  %83 = load i64, i64* %1, align 8
  %84 = load i64, i64* %2, align 8
  %85 = or i64 %84, 2
  call void @_ZN2v88internal15TransitionArray3SetEiNS0_4NameENS0_11MaybeObjectE(%"class.v8::internal::TransitionArray"* nonnull %82, i32 0, i64 %83, i64 %85)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %79) #6
  %86 = load i64, i64* %78, align 8
  %87 = load i64, i64* %24, align 8
  %88 = add i64 %87, 35
  %89 = inttoptr i64 %88 to i32*
  %90 = trunc i64 %86 to i32
  store atomic volatile i32 %90, i32* %89 release, align 4
  %91 = load i64, i64* %24, align 8
  %92 = add i64 %91, 35
  %93 = and i64 %86, 1
  %94 = icmp ne i64 %93, 0
  %95 = icmp ne i32 %90, 3
  %96 = and i1 %95, %94
  br i1 %96, label %97, label %128

97:                                               ; preds = %74
  %98 = and i64 %91, -262144
  %99 = or i64 %98, 8
  %100 = inttoptr i64 %99 to i64*
  %101 = load i64, i64* %100, align 8
  %102 = and i64 %101, 262144
  %103 = icmp eq i64 %102, 0
  %104 = and i64 %86, -3
  br i1 %103, label %111, label %105

105:                                              ; preds = %97
  %106 = or i64 %98, 16
  %107 = inttoptr i64 %106 to %"class.v8::internal::Heap"**
  %108 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %107, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %108, i64 %91, i64 %92, i64 %104) #6
  %109 = load i64, i64* %24, align 8
  %110 = add i64 %109, 35
  br label %111

111:                                              ; preds = %97, %105
  %112 = phi i64 [ %110, %105 ], [ %92, %97 ]
  %113 = phi i64 [ %109, %105 ], [ %91, %97 ]
  %114 = and i64 %86, -262144
  %115 = or i64 %114, 8
  %116 = inttoptr i64 %115 to i64*
  %117 = load i64, i64* %116, align 8
  %118 = and i64 %117, 24
  %119 = icmp eq i64 %118, 0
  br i1 %119, label %128, label %120

120:                                              ; preds = %111
  %121 = and i64 %113, -262144
  %122 = or i64 %121, 8
  %123 = inttoptr i64 %122 to i64*
  %124 = load i64, i64* %123, align 8
  %125 = and i64 %124, 24
  %126 = icmp eq i64 %125, 0
  br i1 %126, label %127, label %128

127:                                              ; preds = %120
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %113, i64 %112, i64 %104) #6
  br label %128

128:                                              ; preds = %74, %111, %120, %127
  %129 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 1, i32 0, i32 0
  %130 = load i64*, i64** %129, align 8
  %131 = load i64, i64* %130, align 8
  store i64 %131, i64* %24, align 8
  %132 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %75, align 8
  %133 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %132, i64 0, i32 0, i32 4
  %134 = load i64, i64* %133, align 8
  %135 = add i64 %131, 35
  %136 = inttoptr i64 %135 to i32*
  %137 = load atomic i32, i32* %136 acquire, align 4
  %138 = and i64 %134, 4294967295
  %139 = icmp eq i64 %138, 0
  call void @llvm.assume(i1 %139) #6
  %140 = zext i32 %137 to i64
  %141 = or i64 %134, %140
  %142 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  store i64 %141, i64* %142, align 8
  %143 = and i64 %140, 1
  %144 = icmp eq i64 %143, 0
  %145 = icmp eq i32 %137, 3
  %146 = or i1 %145, %144
  br i1 %146, label %147, label %148

147:                                              ; preds = %128
  store i32 1, i32* %26, align 8
  br label %1531

148:                                              ; preds = %128
  %149 = and i64 %140, 3
  switch i64 %149, label %172 [
    i64 3, label %150
    i64 1, label %151
  ]

150:                                              ; preds = %148
  store i32 3, i32* %26, align 8
  br label %1531

151:                                              ; preds = %148
  %152 = add i64 %141, -1
  %153 = inttoptr i64 %152 to i32*
  %154 = load atomic i32, i32* %153 monotonic, align 4
  %155 = zext i32 %154 to i64
  %156 = or i64 %134, %155
  %157 = add i64 %156, 7
  %158 = inttoptr i64 %157 to i16*
  %159 = load atomic i16, i16* %158 monotonic, align 2
  %160 = icmp eq i16 %159, 160
  br i1 %160, label %161, label %162

161:                                              ; preds = %151
  store i32 4, i32* %26, align 8
  br label %1531

162:                                              ; preds = %151
  %163 = load atomic i32, i32* %153 monotonic, align 4
  %164 = zext i32 %163 to i64
  %165 = or i64 %134, %164
  %166 = add i64 %165, 7
  %167 = inttoptr i64 %166 to i16*
  %168 = load atomic i16, i16* %167 monotonic, align 2
  %169 = icmp eq i16 %168, 110
  br i1 %169, label %170, label %171

170:                                              ; preds = %162
  store i32 0, i32* %26, align 8
  br label %1531

171:                                              ; preds = %162
  store i32 2, i32* %26, align 8
  br label %1531

172:                                              ; preds = %148
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

173:                                              ; preds = %4
  %174 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %175 = load i64, i64* %174, align 8
  %176 = and i64 %175, -3
  %177 = icmp eq i32 %3, 0
  br i1 %177, label %178, label %336

178:                                              ; preds = %173
  %179 = add i64 %176, 11
  %180 = inttoptr i64 %179 to i32*
  %181 = load atomic i32, i32* %180 acquire, align 4
  %182 = lshr i32 %181, 10
  %183 = and i32 %182, 1023
  %184 = add nsw i32 %183, -1
  %185 = sext i32 %184 to i64
  %186 = and i64 %175, -4294967296
  %187 = add i64 %176, 23
  %188 = inttoptr i64 %187 to i32*
  %189 = load i32, i32* %188, align 4
  %190 = zext i32 %189 to i64
  %191 = or i64 %186, %190
  %192 = mul nsw i64 %185, 51539607552
  %193 = add nsw i64 %192, 68719476736
  %194 = ashr exact i64 %193, 32
  %195 = add i64 %191, -1
  %196 = add i64 %195, %194
  %197 = inttoptr i64 %196 to i32*
  %198 = load atomic i32, i32* %197 monotonic, align 4
  %199 = zext i32 %198 to i64
  %200 = or i64 %186, %199
  %201 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %202 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %201, align 8
  %203 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %202, i64 0, i32 0, i32 4
  %204 = load i64, i64* %203, align 8
  %205 = and i64 %204, 4294967295
  %206 = icmp eq i64 %205, 0
  call void @llvm.assume(i1 %206) #6
  %207 = or i64 %204, %190
  %208 = load atomic i32, i32* %180 acquire, align 4
  %209 = lshr i32 %208, 10
  %210 = and i32 %209, 1023
  %211 = add nsw i32 %210, -1
  %212 = sext i32 %211 to i64
  %213 = mul nsw i64 %212, 51539607552
  %214 = add nsw i64 %213, 68719476736
  %215 = ashr exact i64 %214, 32
  %216 = or i64 %215, 3
  %217 = add i64 %216, %207
  %218 = inttoptr i64 %217 to i32*
  %219 = load atomic i32, i32* %218 monotonic, align 4
  %220 = load i64, i64* %2, align 8
  %221 = add i64 %220, 11
  %222 = inttoptr i64 %221 to i32*
  %223 = load atomic i32, i32* %222 acquire, align 4
  %224 = lshr i32 %223, 10
  %225 = and i32 %224, 1023
  %226 = add nsw i32 %225, -1
  %227 = sext i32 %226 to i64
  %228 = and i64 %220, -4294967296
  %229 = add i64 %220, 23
  %230 = inttoptr i64 %229 to i32*
  %231 = load atomic i32, i32* %230 monotonic, align 4
  %232 = zext i32 %231 to i64
  %233 = or i64 %228, %232
  %234 = mul nsw i64 %227, 51539607552
  %235 = add nsw i64 %234, 68719476736
  %236 = ashr exact i64 %235, 32
  %237 = or i64 %236, 3
  %238 = add i64 %237, %233
  %239 = inttoptr i64 %238 to i32*
  %240 = load atomic i32, i32* %239 monotonic, align 4
  %241 = load i64, i64* %1, align 8
  %242 = trunc i64 %241 to i32
  %243 = icmp eq i32 %198, %242
  br i1 %243, label %288, label %244

244:                                              ; preds = %178
  %245 = add i64 %200, -1
  %246 = inttoptr i64 %245 to i32*
  %247 = load atomic i32, i32* %246 monotonic, align 4
  %248 = zext i32 %247 to i64
  %249 = or i64 %186, %248
  %250 = add i64 %249, 7
  %251 = inttoptr i64 %250 to i16*
  %252 = load atomic i16, i16* %251 monotonic, align 2
  %253 = icmp ult i16 %252, 32
  br i1 %253, label %254, label %265

254:                                              ; preds = %244
  %255 = and i64 %241, -4294967296
  %256 = add i64 %241, -1
  %257 = inttoptr i64 %256 to i32*
  %258 = load atomic i32, i32* %257 monotonic, align 4
  %259 = zext i32 %258 to i64
  %260 = or i64 %255, %259
  %261 = add i64 %260, 7
  %262 = inttoptr i64 %261 to i16*
  %263 = load atomic i16, i16* %262 monotonic, align 2
  %264 = icmp ult i16 %263, 32
  br i1 %264, label %336, label %265

265:                                              ; preds = %254, %244
  %266 = load atomic i32, i32* %246 monotonic, align 4
  %267 = zext i32 %266 to i64
  %268 = or i64 %186, %267
  %269 = add i64 %268, 7
  %270 = inttoptr i64 %269 to i16*
  %271 = load atomic i16, i16* %270 monotonic, align 2
  %272 = icmp eq i16 %271, 64
  br i1 %272, label %336, label %273

273:                                              ; preds = %265
  %274 = and i64 %241, -4294967296
  %275 = add i64 %241, -1
  %276 = inttoptr i64 %275 to i32*
  %277 = load atomic i32, i32* %276 monotonic, align 4
  %278 = zext i32 %277 to i64
  %279 = or i64 %274, %278
  %280 = add i64 %279, 7
  %281 = inttoptr i64 %280 to i16*
  %282 = load atomic i16, i16* %281 monotonic, align 2
  %283 = icmp eq i16 %282, 64
  br i1 %283, label %336, label %284

284:                                              ; preds = %273
  %285 = bitcast %"class.v8::internal::String"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %285) #6
  %286 = getelementptr inbounds %"class.v8::internal::String", %"class.v8::internal::String"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %200, i64* %286, align 8
  %287 = call zeroext i1 @_ZNK2v88internal6String10SlowEqualsES1_(%"class.v8::internal::String"* nonnull %5, i64 %241) #6
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %285) #6
  br i1 %287, label %288, label %336

288:                                              ; preds = %178, %284
  %289 = xor i32 %240, %219
  %290 = and i32 %289, 114
  %291 = icmp eq i32 %290, 0
  br i1 %291, label %292, label %336

292:                                              ; preds = %288
  %293 = load i64, i64* %2, align 8
  %294 = load i64, i64* %24, align 8
  %295 = add i64 %294, 35
  %296 = inttoptr i64 %295 to i32*
  %297 = trunc i64 %293 to i32
  %298 = or i32 %297, 2
  store atomic volatile i32 %298, i32* %296 release, align 4
  %299 = load i64, i64* %24, align 8
  %300 = add i64 %299, 35
  %301 = and i64 %293, 1
  %302 = icmp ne i64 %301, 0
  %303 = icmp ne i32 %298, 3
  %304 = and i1 %302, %303
  br i1 %304, label %305, label %1531

305:                                              ; preds = %292
  %306 = and i64 %299, -262144
  %307 = or i64 %306, 8
  %308 = inttoptr i64 %307 to i64*
  %309 = load i64, i64* %308, align 8
  %310 = and i64 %309, 262144
  %311 = icmp eq i64 %310, 0
  %312 = and i64 %293, -3
  br i1 %311, label %319, label %313

313:                                              ; preds = %305
  %314 = or i64 %306, 16
  %315 = inttoptr i64 %314 to %"class.v8::internal::Heap"**
  %316 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %315, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %316, i64 %299, i64 %300, i64 %312) #6
  %317 = load i64, i64* %24, align 8
  %318 = add i64 %317, 35
  br label %319

319:                                              ; preds = %305, %313
  %320 = phi i64 [ %318, %313 ], [ %300, %305 ]
  %321 = phi i64 [ %317, %313 ], [ %299, %305 ]
  %322 = and i64 %293, -262144
  %323 = or i64 %322, 8
  %324 = inttoptr i64 %323 to i64*
  %325 = load i64, i64* %324, align 8
  %326 = and i64 %325, 24
  %327 = icmp eq i64 %326, 0
  br i1 %327, label %1531, label %328

328:                                              ; preds = %319
  %329 = and i64 %321, -262144
  %330 = or i64 %329, 8
  %331 = inttoptr i64 %330 to i64*
  %332 = load i64, i64* %331, align 8
  %333 = and i64 %332, 24
  %334 = icmp eq i64 %333, 0
  br i1 %334, label %335, label %1531

335:                                              ; preds = %328
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %321, i64 %320, i64 %312) #6
  br label %1531

336:                                              ; preds = %254, %265, %273, %284, %288, %173
  %337 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %338 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %337, align 8
  %339 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %338, i64 0, i32 31, i32 4
  %340 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %339, align 8
  %341 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %340, null
  br i1 %341, label %344, label %342

342:                                              ; preds = %336
  %343 = call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %340, i64 %176) #6
  br label %357

344:                                              ; preds = %336
  %345 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %338, i64 0, i32 31, i32 0
  %346 = load i64*, i64** %345, align 8
  %347 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %338, i64 0, i32 31, i32 1
  %348 = load i64*, i64** %347, align 8
  %349 = icmp eq i64* %346, %348
  br i1 %349, label %350, label %352

350:                                              ; preds = %344
  %351 = call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %338) #6
  br label %352

352:                                              ; preds = %350, %344
  %353 = phi i64* [ %351, %350 ], [ %346, %344 ]
  %354 = ptrtoint i64* %353 to i64
  %355 = add i64 %354, 8
  %356 = inttoptr i64 %355 to i64*
  store i64* %356, i64** %345, align 8
  store i64 %176, i64* %353, align 8
  br label %357

357:                                              ; preds = %342, %352
  %358 = bitcast %"class.v8::internal::TransitionsAccessor"* %0 to %"class.v8::internal::Factory"**
  %359 = load %"class.v8::internal::Factory"*, %"class.v8::internal::Factory"** %358, align 8
  %360 = call i64* @_ZN2v88internal7Factory18NewTransitionArrayEii(%"class.v8::internal::Factory"* %359, i32 1, i32 1) #6
  %361 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 1, i32 0, i32 0
  %362 = load i64*, i64** %361, align 8
  %363 = load i64, i64* %362, align 8
  store i64 %363, i64* %24, align 8
  %364 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %337, align 8
  %365 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %364, i64 0, i32 0, i32 4
  %366 = load i64, i64* %365, align 8
  %367 = add i64 %363, 35
  %368 = inttoptr i64 %367 to i32*
  %369 = load atomic i32, i32* %368 acquire, align 4
  %370 = and i64 %366, 4294967295
  %371 = icmp eq i64 %370, 0
  call void @llvm.assume(i1 %371) #6
  %372 = zext i32 %369 to i64
  %373 = or i64 %366, %372
  store i64 %373, i64* %174, align 8
  %374 = and i64 %372, 1
  %375 = icmp eq i64 %374, 0
  %376 = icmp eq i32 %369, 3
  %377 = or i1 %376, %375
  br i1 %377, label %404, label %378

378:                                              ; preds = %357
  %379 = and i64 %372, 3
  switch i64 %379, label %399 [
    i64 3, label %400
    i64 1, label %380
  ]

380:                                              ; preds = %378
  %381 = add i64 %373, -1
  %382 = inttoptr i64 %381 to i32*
  %383 = load atomic i32, i32* %382 monotonic, align 4
  %384 = zext i32 %383 to i64
  %385 = or i64 %366, %384
  %386 = add i64 %385, 7
  %387 = inttoptr i64 %386 to i16*
  %388 = load atomic i16, i16* %387 monotonic, align 2
  %389 = icmp eq i16 %388, 160
  br i1 %389, label %404, label %390

390:                                              ; preds = %380
  %391 = load atomic i32, i32* %382 monotonic, align 4
  %392 = zext i32 %391 to i64
  %393 = or i64 %366, %392
  %394 = add i64 %393, 7
  %395 = inttoptr i64 %394 to i16*
  %396 = load atomic i16, i16* %395 monotonic, align 2
  %397 = icmp eq i16 %396, 110
  %398 = select i1 %397, i32 0, i32 2
  br label %404

399:                                              ; preds = %378
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

400:                                              ; preds = %378
  store i32 3, i32* %26, align 8
  %401 = and i64 %373, -3
  %402 = trunc i64 %401 to i32
  %403 = icmp eq i32 %402, 0
  br i1 %403, label %406, label %499

404:                                              ; preds = %390, %380, %357
  %405 = phi i32 [ 1, %357 ], [ 4, %380 ], [ %398, %390 ]
  store i32 %405, i32* %26, align 8
  br label %406

406:                                              ; preds = %404, %400
  %407 = bitcast %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %407) #6
  %408 = load i64, i64* %360, align 8
  %409 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %8, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %408, i64* %409, align 8
  %410 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %8, i64 0, i32 0
  %411 = load i64, i64* %1, align 8
  %412 = load i64, i64* %2, align 8
  %413 = or i64 %412, 2
  call void @_ZN2v88internal15TransitionArray3SetEiNS0_4NameENS0_11MaybeObjectE(%"class.v8::internal::TransitionArray"* nonnull %410, i32 0, i64 %411, i64 %413)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %407) #6
  %414 = load i64, i64* %360, align 8
  %415 = load i64, i64* %24, align 8
  %416 = add i64 %415, 35
  %417 = inttoptr i64 %416 to i32*
  %418 = trunc i64 %414 to i32
  store atomic volatile i32 %418, i32* %417 release, align 4
  %419 = load i64, i64* %24, align 8
  %420 = add i64 %419, 35
  %421 = and i64 %414, 1
  %422 = icmp ne i64 %421, 0
  %423 = icmp ne i32 %418, 3
  %424 = and i1 %423, %422
  br i1 %424, label %425, label %456

425:                                              ; preds = %406
  %426 = and i64 %419, -262144
  %427 = or i64 %426, 8
  %428 = inttoptr i64 %427 to i64*
  %429 = load i64, i64* %428, align 8
  %430 = and i64 %429, 262144
  %431 = icmp eq i64 %430, 0
  %432 = and i64 %414, -3
  br i1 %431, label %439, label %433

433:                                              ; preds = %425
  %434 = or i64 %426, 16
  %435 = inttoptr i64 %434 to %"class.v8::internal::Heap"**
  %436 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %435, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %436, i64 %419, i64 %420, i64 %432) #6
  %437 = load i64, i64* %24, align 8
  %438 = add i64 %437, 35
  br label %439

439:                                              ; preds = %425, %433
  %440 = phi i64 [ %438, %433 ], [ %420, %425 ]
  %441 = phi i64 [ %437, %433 ], [ %419, %425 ]
  %442 = and i64 %414, -262144
  %443 = or i64 %442, 8
  %444 = inttoptr i64 %443 to i64*
  %445 = load i64, i64* %444, align 8
  %446 = and i64 %445, 24
  %447 = icmp eq i64 %446, 0
  br i1 %447, label %456, label %448

448:                                              ; preds = %439
  %449 = and i64 %441, -262144
  %450 = or i64 %449, 8
  %451 = inttoptr i64 %450 to i64*
  %452 = load i64, i64* %451, align 8
  %453 = and i64 %452, 24
  %454 = icmp eq i64 %453, 0
  br i1 %454, label %455, label %456

455:                                              ; preds = %448
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %441, i64 %440, i64 %432) #6
  br label %456

456:                                              ; preds = %406, %439, %448, %455
  %457 = load i64*, i64** %361, align 8
  %458 = load i64, i64* %457, align 8
  store i64 %458, i64* %24, align 8
  %459 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %337, align 8
  %460 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %459, i64 0, i32 0, i32 4
  %461 = load i64, i64* %460, align 8
  %462 = add i64 %458, 35
  %463 = inttoptr i64 %462 to i32*
  %464 = load atomic i32, i32* %463 acquire, align 4
  %465 = and i64 %461, 4294967295
  %466 = icmp eq i64 %465, 0
  call void @llvm.assume(i1 %466) #6
  %467 = zext i32 %464 to i64
  %468 = or i64 %461, %467
  store i64 %468, i64* %174, align 8
  %469 = and i64 %467, 1
  %470 = icmp eq i64 %469, 0
  %471 = icmp eq i32 %464, 3
  %472 = or i1 %471, %470
  br i1 %472, label %473, label %474

473:                                              ; preds = %456
  store i32 1, i32* %26, align 8
  br label %1531

474:                                              ; preds = %456
  %475 = and i64 %467, 3
  switch i64 %475, label %498 [
    i64 3, label %476
    i64 1, label %477
  ]

476:                                              ; preds = %474
  store i32 3, i32* %26, align 8
  br label %1531

477:                                              ; preds = %474
  %478 = add i64 %468, -1
  %479 = inttoptr i64 %478 to i32*
  %480 = load atomic i32, i32* %479 monotonic, align 4
  %481 = zext i32 %480 to i64
  %482 = or i64 %461, %481
  %483 = add i64 %482, 7
  %484 = inttoptr i64 %483 to i16*
  %485 = load atomic i16, i16* %484 monotonic, align 2
  %486 = icmp eq i16 %485, 160
  br i1 %486, label %487, label %488

487:                                              ; preds = %477
  store i32 4, i32* %26, align 8
  br label %1531

488:                                              ; preds = %477
  %489 = load atomic i32, i32* %479 monotonic, align 4
  %490 = zext i32 %489 to i64
  %491 = or i64 %461, %490
  %492 = add i64 %491, 7
  %493 = inttoptr i64 %492 to i16*
  %494 = load atomic i16, i16* %493 monotonic, align 2
  %495 = icmp eq i16 %494, 110
  br i1 %495, label %496, label %497

496:                                              ; preds = %488
  store i32 0, i32* %26, align 8
  br label %1531

497:                                              ; preds = %488
  store i32 2, i32* %26, align 8
  br label %1531

498:                                              ; preds = %474
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

499:                                              ; preds = %400
  %500 = bitcast %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %500) #6
  %501 = load i64, i64* %360, align 8
  %502 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %9, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %501, i64* %502, align 8
  %503 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %9, i64 0, i32 0
  %504 = add i64 %401, 11
  %505 = inttoptr i64 %504 to i32*
  %506 = load atomic i32, i32* %505 acquire, align 4
  %507 = lshr i32 %506, 10
  %508 = and i32 %507, 1023
  %509 = add nsw i32 %508, -1
  %510 = sext i32 %509 to i64
  %511 = add i64 %401, 23
  %512 = inttoptr i64 %511 to i32*
  %513 = load i32, i32* %512, align 4
  %514 = zext i32 %513 to i64
  %515 = or i64 %366, %514
  %516 = mul nsw i64 %510, 51539607552
  %517 = add nsw i64 %516, 68719476736
  %518 = ashr exact i64 %517, 32
  %519 = add i64 %515, -1
  %520 = add i64 %519, %518
  %521 = inttoptr i64 %520 to i32*
  %522 = load atomic i32, i32* %521 monotonic, align 4
  %523 = zext i32 %522 to i64
  %524 = or i64 %366, %523
  %525 = or i64 %373, 2
  call void @_ZN2v88internal15TransitionArray3SetEiNS0_4NameENS0_11MaybeObjectE(%"class.v8::internal::TransitionArray"* nonnull %503, i32 0, i64 %524, i64 %525)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %500) #6
  %526 = bitcast i32* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %526) #6
  %527 = icmp eq i32 %3, 2
  br i1 %527, label %528, label %586

528:                                              ; preds = %499
  %529 = bitcast %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %529) #6
  %530 = load i64, i64* %360, align 8
  %531 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %11, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %530, i64* %531, align 8
  %532 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %11, i64 0, i32 0
  %533 = load i64, i64* %1, align 8
  %534 = add i64 %530, 3
  %535 = inttoptr i64 %534 to i32*
  %536 = load i32, i32* %535, align 4
  %537 = icmp slt i32 %536, 4
  br i1 %537, label %544, label %538

538:                                              ; preds = %528
  %539 = add i64 %530, 11
  %540 = inttoptr i64 %539 to i32*
  %541 = load atomic i32, i32* %540 monotonic, align 4
  %542 = ashr i32 %541, 1
  %543 = icmp eq i32 %542, 0
  br i1 %543, label %544, label %545

544:                                              ; preds = %538, %528
  store i32 0, i32* %10, align 4
  br label %618

545:                                              ; preds = %538
  %546 = icmp slt i32 %541, 18
  br i1 %546, label %547, label %584

547:                                              ; preds = %545
  %548 = add i64 %533, 3
  %549 = inttoptr i64 %548 to i32*
  %550 = load i32, i32* %549, align 4
  %551 = lshr i32 %550, 2
  %552 = load atomic i32, i32* %540 monotonic, align 4
  %553 = ashr i32 %552, 1
  %554 = icmp sgt i32 %552, 1
  br i1 %554, label %555, label %583

555:                                              ; preds = %547
  %556 = and i64 %530, -4294967296
  %557 = trunc i64 %533 to i32
  %558 = zext i32 %553 to i64
  br label %559

559:                                              ; preds = %580, %555
  %560 = phi i64 [ 0, %555 ], [ %581, %580 ]
  %561 = trunc i64 %560 to i32
  %562 = shl i32 %561, 3
  %563 = add i32 %562, 8
  %564 = or i32 %563, 7
  %565 = sext i32 %564 to i64
  %566 = add i64 %530, %565
  %567 = inttoptr i64 %566 to i32*
  %568 = load atomic i32, i32* %567 monotonic, align 4
  %569 = zext i32 %568 to i64
  %570 = or i64 %556, %569
  %571 = add i64 %570, 3
  %572 = inttoptr i64 %571 to i32*
  %573 = load i32, i32* %572, align 4
  %574 = lshr i32 %573, 2
  %575 = icmp ugt i32 %574, %551
  br i1 %575, label %576, label %578

576:                                              ; preds = %559
  %577 = trunc i64 %560 to i32
  store i32 %577, i32* %10, align 4
  br label %618

578:                                              ; preds = %559
  %579 = icmp eq i32 %568, %557
  br i1 %579, label %618, label %580

580:                                              ; preds = %578
  %581 = add nuw nsw i64 %560, 1
  %582 = icmp eq i64 %581, %558
  br i1 %582, label %583, label %559

583:                                              ; preds = %580, %547
  store i32 %553, i32* %10, align 4
  br label %618

584:                                              ; preds = %545
  %585 = call i32 @_ZN2v88internal12BinarySearchILNS0_10SearchModeE0ENS0_15TransitionArrayEEEiPT0_NS0_4NameEiPi(%"class.v8::internal::TransitionArray"* nonnull %532, i64 %533, i32 %542, i32* nonnull %10) #6
  br label %618

586:                                              ; preds = %499
  %587 = load i64, i64* %2, align 8
  %588 = add i64 %587, 11
  %589 = inttoptr i64 %588 to i32*
  %590 = load atomic i32, i32* %589 acquire, align 4
  %591 = lshr i32 %590, 10
  %592 = and i32 %591, 1023
  %593 = add nsw i32 %592, -1
  %594 = sext i32 %593 to i64
  %595 = and i64 %587, -4294967296
  %596 = add i64 %587, 23
  %597 = inttoptr i64 %596 to i32*
  %598 = load atomic i32, i32* %597 monotonic, align 4
  %599 = zext i32 %598 to i64
  %600 = or i64 %595, %599
  %601 = mul nsw i64 %594, 51539607552
  %602 = add nsw i64 %601, 68719476736
  %603 = ashr exact i64 %602, 32
  %604 = or i64 %603, 3
  %605 = add i64 %604, %600
  %606 = inttoptr i64 %605 to i32*
  %607 = load atomic i32, i32* %606 monotonic, align 4
  %608 = ashr i32 %607, 1
  %609 = bitcast %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %609) #6
  %610 = load i64, i64* %360, align 8
  %611 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %12, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %610, i64* %611, align 8
  %612 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %12, i64 0, i32 0
  %613 = and i32 %608, 1
  %614 = load i64, i64* %1, align 8
  %615 = lshr i32 %608, 3
  %616 = and i32 %615, 7
  %617 = call i32 @_ZN2v88internal15TransitionArray6SearchENS0_12PropertyKindENS0_4NameENS0_18PropertyAttributesEPi(%"class.v8::internal::TransitionArray"* nonnull %612, i32 %613, i64 %614, i32 %616, i32* nonnull %10)
  br label %618

618:                                              ; preds = %578, %584, %583, %576, %544, %586
  %619 = phi i8* [ %609, %586 ], [ %529, %544 ], [ %529, %576 ], [ %529, %583 ], [ %529, %584 ], [ %529, %578 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %619) #6
  %620 = load i64, i64* %360, align 8
  %621 = add i64 %620, 11
  %622 = inttoptr i64 %621 to i32*
  store atomic volatile i32 4, i32* %622 monotonic, align 4
  %623 = load i32, i32* %10, align 4
  %624 = icmp eq i32 %623, 0
  br i1 %624, label %625, label %648

625:                                              ; preds = %618
  %626 = bitcast %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %626) #6
  %627 = load i64, i64* %360, align 8
  %628 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %627, i64* %628, align 8
  %629 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %13, i64 0, i32 0
  %630 = load atomic i32, i32* %505 acquire, align 4
  %631 = lshr i32 %630, 10
  %632 = and i32 %631, 1023
  %633 = add nsw i32 %632, -1
  %634 = sext i32 %633 to i64
  %635 = load i32, i32* %512, align 4
  %636 = zext i32 %635 to i64
  %637 = or i64 %366, %636
  %638 = mul nsw i64 %634, 51539607552
  %639 = add nsw i64 %638, 68719476736
  %640 = ashr exact i64 %639, 32
  %641 = add i64 %637, -1
  %642 = add i64 %641, %640
  %643 = inttoptr i64 %642 to i32*
  %644 = load atomic i32, i32* %643 monotonic, align 4
  %645 = zext i32 %644 to i64
  %646 = or i64 %366, %645
  call void @_ZN2v88internal15TransitionArray3SetEiNS0_4NameENS0_11MaybeObjectE(%"class.v8::internal::TransitionArray"* nonnull %629, i32 1, i64 %646, i64 %525)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %626) #6
  %647 = load i32, i32* %10, align 4
  br label %648

648:                                              ; preds = %625, %618
  %649 = phi i32 [ %647, %625 ], [ %623, %618 ]
  %650 = load i64, i64* %360, align 8
  %651 = load i64, i64* %1, align 8
  %652 = shl i32 %649, 3
  %653 = add i32 %652, 8
  %654 = or i32 %653, 7
  %655 = sext i32 %654 to i64
  %656 = add i64 %650, %655
  %657 = inttoptr i64 %656 to i32*
  %658 = trunc i64 %651 to i32
  store atomic volatile i32 %658, i32* %657 monotonic, align 4
  %659 = and i64 %651, 1
  %660 = icmp ne i64 %659, 0
  %661 = icmp ne i32 %658, 3
  %662 = and i1 %661, %660
  br i1 %662, label %663, label %687

663:                                              ; preds = %648
  %664 = and i64 %650, -262144
  %665 = or i64 %664, 8
  %666 = inttoptr i64 %665 to i64*
  %667 = load i64, i64* %666, align 8
  %668 = and i64 %667, 262144
  %669 = icmp eq i64 %668, 0
  %670 = and i64 %651, -3
  br i1 %669, label %675, label %671

671:                                              ; preds = %663
  %672 = or i64 %664, 16
  %673 = inttoptr i64 %672 to %"class.v8::internal::Heap"**
  %674 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %673, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %674, i64 %650, i64 %656, i64 %670) #6
  br label %675

675:                                              ; preds = %663, %671
  %676 = and i64 %651, -262144
  %677 = or i64 %676, 8
  %678 = inttoptr i64 %677 to i64*
  %679 = load i64, i64* %678, align 8
  %680 = and i64 %679, 24
  %681 = icmp eq i64 %680, 0
  br i1 %681, label %687, label %682

682:                                              ; preds = %675
  %683 = load i64, i64* %666, align 8
  %684 = and i64 %683, 24
  %685 = icmp eq i64 %684, 0
  br i1 %685, label %686, label %687

686:                                              ; preds = %682
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %650, i64 %656, i64 %670) #6
  br label %687

687:                                              ; preds = %648, %675, %682, %686
  %688 = load i64, i64* %360, align 8
  %689 = load i32, i32* %10, align 4
  %690 = load i64, i64* %2, align 8
  %691 = shl i32 %689, 3
  %692 = add i32 %691, 12
  %693 = sext i32 %692 to i64
  %694 = add i64 %688, 7
  %695 = add i64 %694, %693
  %696 = inttoptr i64 %695 to i32*
  %697 = trunc i64 %690 to i32
  %698 = or i32 %697, 2
  store atomic volatile i32 %698, i32* %696 monotonic, align 4
  %699 = and i64 %690, 1
  %700 = icmp ne i64 %699, 0
  %701 = icmp ne i32 %698, 3
  %702 = and i1 %700, %701
  br i1 %702, label %703, label %727

703:                                              ; preds = %687
  %704 = and i64 %688, -262144
  %705 = or i64 %704, 8
  %706 = inttoptr i64 %705 to i64*
  %707 = load i64, i64* %706, align 8
  %708 = and i64 %707, 262144
  %709 = icmp eq i64 %708, 0
  %710 = and i64 %690, -3
  br i1 %709, label %715, label %711

711:                                              ; preds = %703
  %712 = or i64 %704, 16
  %713 = inttoptr i64 %712 to %"class.v8::internal::Heap"**
  %714 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %713, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %714, i64 %688, i64 %695, i64 %710) #6
  br label %715

715:                                              ; preds = %703, %711
  %716 = and i64 %690, -262144
  %717 = or i64 %716, 8
  %718 = inttoptr i64 %717 to i64*
  %719 = load i64, i64* %718, align 8
  %720 = and i64 %719, 24
  %721 = icmp eq i64 %720, 0
  br i1 %721, label %727, label %722

722:                                              ; preds = %715
  %723 = load i64, i64* %706, align 8
  %724 = and i64 %723, 24
  %725 = icmp eq i64 %724, 0
  br i1 %725, label %726, label %727

726:                                              ; preds = %722
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %688, i64 %695, i64 %710) #6
  br label %727

727:                                              ; preds = %687, %715, %722, %726
  %728 = load i64, i64* %360, align 8
  %729 = load i64, i64* %24, align 8
  %730 = add i64 %729, 35
  %731 = inttoptr i64 %730 to i32*
  %732 = trunc i64 %728 to i32
  store atomic volatile i32 %732, i32* %731 release, align 4
  %733 = load i64, i64* %24, align 8
  %734 = add i64 %733, 35
  %735 = and i64 %728, 1
  %736 = icmp ne i64 %735, 0
  %737 = icmp ne i32 %732, 3
  %738 = and i1 %737, %736
  br i1 %738, label %739, label %770

739:                                              ; preds = %727
  %740 = and i64 %733, -262144
  %741 = or i64 %740, 8
  %742 = inttoptr i64 %741 to i64*
  %743 = load i64, i64* %742, align 8
  %744 = and i64 %743, 262144
  %745 = icmp eq i64 %744, 0
  %746 = and i64 %728, -3
  br i1 %745, label %753, label %747

747:                                              ; preds = %739
  %748 = or i64 %740, 16
  %749 = inttoptr i64 %748 to %"class.v8::internal::Heap"**
  %750 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %749, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %750, i64 %733, i64 %734, i64 %746) #6
  %751 = load i64, i64* %24, align 8
  %752 = add i64 %751, 35
  br label %753

753:                                              ; preds = %739, %747
  %754 = phi i64 [ %752, %747 ], [ %734, %739 ]
  %755 = phi i64 [ %751, %747 ], [ %733, %739 ]
  %756 = and i64 %728, -262144
  %757 = or i64 %756, 8
  %758 = inttoptr i64 %757 to i64*
  %759 = load i64, i64* %758, align 8
  %760 = and i64 %759, 24
  %761 = icmp eq i64 %760, 0
  br i1 %761, label %770, label %762

762:                                              ; preds = %753
  %763 = and i64 %755, -262144
  %764 = or i64 %763, 8
  %765 = inttoptr i64 %764 to i64*
  %766 = load i64, i64* %765, align 8
  %767 = and i64 %766, 24
  %768 = icmp eq i64 %767, 0
  br i1 %768, label %769, label %770

769:                                              ; preds = %762
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %755, i64 %754, i64 %746) #6
  br label %770

770:                                              ; preds = %727, %753, %762, %769
  %771 = load i64*, i64** %361, align 8
  %772 = load i64, i64* %771, align 8
  store i64 %772, i64* %24, align 8
  %773 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %337, align 8
  %774 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %773, i64 0, i32 0, i32 4
  %775 = load i64, i64* %774, align 8
  %776 = add i64 %772, 35
  %777 = inttoptr i64 %776 to i32*
  %778 = load atomic i32, i32* %777 acquire, align 4
  %779 = and i64 %775, 4294967295
  %780 = icmp eq i64 %779, 0
  call void @llvm.assume(i1 %780) #6
  %781 = zext i32 %778 to i64
  %782 = or i64 %775, %781
  store i64 %782, i64* %174, align 8
  %783 = and i64 %781, 1
  %784 = icmp eq i64 %783, 0
  %785 = icmp eq i32 %778, 3
  %786 = or i1 %785, %784
  br i1 %786, label %809, label %787

787:                                              ; preds = %770
  %788 = and i64 %781, 3
  switch i64 %788, label %808 [
    i64 3, label %809
    i64 1, label %789
  ]

789:                                              ; preds = %787
  %790 = add i64 %782, -1
  %791 = inttoptr i64 %790 to i32*
  %792 = load atomic i32, i32* %791 monotonic, align 4
  %793 = zext i32 %792 to i64
  %794 = or i64 %775, %793
  %795 = add i64 %794, 7
  %796 = inttoptr i64 %795 to i16*
  %797 = load atomic i16, i16* %796 monotonic, align 2
  %798 = icmp eq i16 %797, 160
  br i1 %798, label %809, label %799

799:                                              ; preds = %789
  %800 = load atomic i32, i32* %791 monotonic, align 4
  %801 = zext i32 %800 to i64
  %802 = or i64 %775, %801
  %803 = add i64 %802, 7
  %804 = inttoptr i64 %803 to i16*
  %805 = load atomic i16, i16* %804 monotonic, align 2
  %806 = icmp eq i16 %805, 110
  %807 = select i1 %806, i32 0, i32 2
  br label %809

808:                                              ; preds = %787
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

809:                                              ; preds = %799, %789, %787, %770
  %810 = phi i32 [ 1, %770 ], [ 3, %787 ], [ 4, %789 ], [ %807, %799 ]
  store i32 %810, i32* %26, align 8
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %526) #6
  br label %1531

811:                                              ; preds = %4
  %812 = bitcast i32* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %812) #6
  store i32 -1, i32* %14, align 4
  %813 = icmp eq i32 %3, 2
  br i1 %813, label %837, label %814

814:                                              ; preds = %811
  %815 = load i64, i64* %2, align 8
  %816 = add i64 %815, 11
  %817 = inttoptr i64 %816 to i32*
  %818 = load atomic i32, i32* %817 acquire, align 4
  %819 = lshr i32 %818, 10
  %820 = and i32 %819, 1023
  %821 = add nsw i32 %820, -1
  %822 = sext i32 %821 to i64
  %823 = and i64 %815, -4294967296
  %824 = add i64 %815, 23
  %825 = inttoptr i64 %824 to i32*
  %826 = load atomic i32, i32* %825 monotonic, align 4
  %827 = zext i32 %826 to i64
  %828 = or i64 %823, %827
  %829 = mul nsw i64 %822, 51539607552
  %830 = add nsw i64 %829, 68719476736
  %831 = ashr exact i64 %830, 32
  %832 = or i64 %831, 3
  %833 = add i64 %832, %828
  %834 = inttoptr i64 %833 to i32*
  %835 = load atomic i32, i32* %834 monotonic, align 4
  %836 = ashr i32 %835, 1
  br label %837

837:                                              ; preds = %811, %814
  %838 = phi i32 [ %836, %814 ], [ 0, %811 ]
  %839 = bitcast %"class.v8::internal::TransitionArray"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %839) #6
  %840 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %841 = load i64, i64* %840, align 8
  %842 = getelementptr inbounds %"class.v8::internal::TransitionArray", %"class.v8::internal::TransitionArray"* %15, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %841, i64* %842, align 8
  %843 = add i64 %841, 3
  %844 = inttoptr i64 %843 to i32*
  %845 = load i32, i32* %844, align 4
  %846 = icmp slt i32 %845, 4
  br i1 %846, label %852, label %847

847:                                              ; preds = %837
  %848 = add i64 %841, 11
  %849 = inttoptr i64 %848 to i32*
  %850 = load atomic i32, i32* %849 monotonic, align 4
  %851 = ashr i32 %850, 1
  br label %852

852:                                              ; preds = %837, %847
  %853 = phi i32 [ %851, %847 ], [ 0, %837 ]
  br i1 %813, label %854, label %904

854:                                              ; preds = %852
  %855 = load i64, i64* %1, align 8
  br i1 %846, label %862, label %856

856:                                              ; preds = %854
  %857 = add i64 %841, 11
  %858 = inttoptr i64 %857 to i32*
  %859 = load atomic i32, i32* %858 monotonic, align 4
  %860 = ashr i32 %859, 1
  %861 = icmp eq i32 %860, 0
  br i1 %861, label %862, label %863

862:                                              ; preds = %856, %854
  store i32 0, i32* %14, align 4
  br label %966

863:                                              ; preds = %856
  %864 = icmp slt i32 %859, 18
  br i1 %864, label %865, label %902

865:                                              ; preds = %863
  %866 = add i64 %855, 3
  %867 = inttoptr i64 %866 to i32*
  %868 = load i32, i32* %867, align 4
  %869 = lshr i32 %868, 2
  %870 = load atomic i32, i32* %858 monotonic, align 4
  %871 = ashr i32 %870, 1
  %872 = icmp sgt i32 %870, 1
  br i1 %872, label %873, label %901

873:                                              ; preds = %865
  %874 = and i64 %841, -4294967296
  %875 = trunc i64 %855 to i32
  %876 = zext i32 %871 to i64
  br label %877

877:                                              ; preds = %898, %873
  %878 = phi i64 [ 0, %873 ], [ %899, %898 ]
  %879 = trunc i64 %878 to i32
  %880 = shl i32 %879, 3
  %881 = add i32 %880, 8
  %882 = or i32 %881, 7
  %883 = sext i32 %882 to i64
  %884 = add i64 %841, %883
  %885 = inttoptr i64 %884 to i32*
  %886 = load atomic i32, i32* %885 monotonic, align 4
  %887 = zext i32 %886 to i64
  %888 = or i64 %874, %887
  %889 = add i64 %888, 3
  %890 = inttoptr i64 %889 to i32*
  %891 = load i32, i32* %890, align 4
  %892 = lshr i32 %891, 2
  %893 = icmp ugt i32 %892, %869
  br i1 %893, label %894, label %896

894:                                              ; preds = %877
  %895 = trunc i64 %878 to i32
  store i32 %895, i32* %14, align 4
  br label %966

896:                                              ; preds = %877
  %897 = icmp eq i32 %886, %875
  br i1 %897, label %910, label %898

898:                                              ; preds = %896
  %899 = add nuw nsw i64 %878, 1
  %900 = icmp eq i64 %899, %876
  br i1 %900, label %901, label %877

901:                                              ; preds = %898, %865
  store i32 %871, i32* %14, align 4
  br label %966

902:                                              ; preds = %863
  %903 = call i32 @_ZN2v88internal12BinarySearchILNS0_10SearchModeE0ENS0_15TransitionArrayEEEiPT0_NS0_4NameEiPi(%"class.v8::internal::TransitionArray"* nonnull %15, i64 %855, i32 %860, i32* nonnull %14) #6
  br label %912

904:                                              ; preds = %852
  %905 = and i32 %838, 1
  %906 = load i64, i64* %1, align 8
  %907 = lshr i32 %838, 3
  %908 = and i32 %907, 7
  %909 = call i32 @_ZN2v88internal15TransitionArray6SearchENS0_12PropertyKindENS0_4NameENS0_18PropertyAttributesEPi(%"class.v8::internal::TransitionArray"* nonnull %15, i32 %905, i64 %906, i32 %908, i32* nonnull %14)
  br label %912

910:                                              ; preds = %896
  %911 = trunc i64 %878 to i32
  br label %912

912:                                              ; preds = %910, %902, %904
  %913 = phi i32 [ %909, %904 ], [ %903, %902 ], [ %911, %910 ]
  %914 = icmp eq i32 %913, -1
  br i1 %914, label %966, label %915

915:                                              ; preds = %912
  %916 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %917 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %916, align 8
  %918 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %917, i64 0, i32 18
  call void @_ZN2v84base11SharedMutex13LockExclusiveEv(%"class.v8::base::SharedMutex"* %918) #6
  %919 = load i64, i64* %2, align 8
  %920 = shl i32 %913, 3
  %921 = add i32 %920, 12
  %922 = load i64, i64* %842, align 8
  %923 = sext i32 %921 to i64
  %924 = add nsw i64 %923, 7
  %925 = add i64 %922, %924
  %926 = inttoptr i64 %925 to i32*
  %927 = trunc i64 %919 to i32
  %928 = or i32 %927, 2
  store atomic volatile i32 %928, i32* %926 monotonic, align 4
  %929 = load i64, i64* %842, align 8
  %930 = add i64 %929, %924
  %931 = and i64 %919, 1
  %932 = icmp ne i64 %931, 0
  %933 = icmp ne i32 %928, 3
  %934 = and i1 %932, %933
  br i1 %934, label %935, label %1210

935:                                              ; preds = %915
  %936 = and i64 %929, -262144
  %937 = or i64 %936, 8
  %938 = inttoptr i64 %937 to i64*
  %939 = load i64, i64* %938, align 8
  %940 = and i64 %939, 262144
  %941 = icmp eq i64 %940, 0
  %942 = and i64 %919, -3
  br i1 %941, label %949, label %943

943:                                              ; preds = %935
  %944 = or i64 %936, 16
  %945 = inttoptr i64 %944 to %"class.v8::internal::Heap"**
  %946 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %945, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %946, i64 %929, i64 %930, i64 %942) #6
  %947 = load i64, i64* %842, align 8
  %948 = add i64 %947, %924
  br label %949

949:                                              ; preds = %935, %943
  %950 = phi i64 [ %948, %943 ], [ %930, %935 ]
  %951 = phi i64 [ %947, %943 ], [ %929, %935 ]
  %952 = and i64 %919, -262144
  %953 = or i64 %952, 8
  %954 = inttoptr i64 %953 to i64*
  %955 = load i64, i64* %954, align 8
  %956 = and i64 %955, 24
  %957 = icmp eq i64 %956, 0
  br i1 %957, label %1210, label %958

958:                                              ; preds = %949
  %959 = and i64 %951, -262144
  %960 = or i64 %959, 8
  %961 = inttoptr i64 %960 to i64*
  %962 = load i64, i64* %961, align 8
  %963 = and i64 %962, 24
  %964 = icmp eq i64 %963, 0
  br i1 %964, label %965, label %1210

965:                                              ; preds = %958
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %951, i64 %950, i64 %942) #6
  br label %1210

966:                                              ; preds = %894, %901, %862, %912
  %967 = add nsw i32 %853, 1
  %968 = icmp slt i32 %967, 1537
  br i1 %968, label %970, label %969, !prof !2

969:                                              ; preds = %966
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.1, i64 0, i64 0), i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.2, i64 0, i64 0)) #7
  unreachable

970:                                              ; preds = %966
  %971 = load i64, i64* %842, align 8
  %972 = add i64 %971, 3
  %973 = inttoptr i64 %972 to i32*
  %974 = load i32, i32* %973, align 4
  %975 = icmp slt i32 %974, 6
  br i1 %975, label %980, label %976

976:                                              ; preds = %970
  %977 = lshr i32 %974, 1
  %978 = add nsw i32 %977, -2
  %979 = sdiv i32 %978, 2
  br label %980

980:                                              ; preds = %970, %976
  %981 = phi i32 [ %979, %976 ], [ 0, %970 ]
  %982 = icmp slt i32 %853, %981
  br i1 %982, label %983, label %1212

983:                                              ; preds = %980
  %984 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %985 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %984, align 8
  %986 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %985, i64 0, i32 18
  call void @_ZN2v84base11SharedMutex13LockExclusiveEv(%"class.v8::base::SharedMutex"* %986) #6
  %987 = shl i32 %967, 1
  %988 = load i64, i64* %842, align 8
  %989 = add i64 %988, 11
  %990 = inttoptr i64 %989 to i32*
  store atomic volatile i32 %987, i32* %990 monotonic, align 4
  %991 = load i32, i32* %14, align 4
  %992 = icmp sgt i32 %853, %991
  br i1 %992, label %993, label %995

993:                                              ; preds = %983
  %994 = sext i32 %853 to i64
  br label %1093

995:                                              ; preds = %1206, %983
  %996 = phi i32 [ %991, %983 ], [ %1207, %1206 ]
  %997 = load i64, i64* %1, align 8
  %998 = shl i32 %996, 3
  %999 = add i32 %998, 8
  %1000 = load i64, i64* %842, align 8
  %1001 = or i32 %999, 7
  %1002 = sext i32 %1001 to i64
  %1003 = add i64 %1000, %1002
  %1004 = inttoptr i64 %1003 to i32*
  %1005 = trunc i64 %997 to i32
  store atomic volatile i32 %1005, i32* %1004 monotonic, align 4
  %1006 = load i64, i64* %842, align 8
  %1007 = add i64 %1006, %1002
  %1008 = and i64 %997, 1
  %1009 = icmp ne i64 %1008, 0
  %1010 = icmp ne i32 %1005, 3
  %1011 = and i1 %1010, %1009
  br i1 %1011, label %1012, label %1044

1012:                                             ; preds = %995
  %1013 = and i64 %1006, -262144
  %1014 = or i64 %1013, 8
  %1015 = inttoptr i64 %1014 to i64*
  %1016 = load i64, i64* %1015, align 8
  %1017 = and i64 %1016, 262144
  %1018 = icmp eq i64 %1017, 0
  %1019 = and i64 %997, -3
  br i1 %1018, label %1026, label %1020

1020:                                             ; preds = %1012
  %1021 = or i64 %1013, 16
  %1022 = inttoptr i64 %1021 to %"class.v8::internal::Heap"**
  %1023 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %1022, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %1023, i64 %1006, i64 %1007, i64 %1019) #6
  %1024 = load i64, i64* %842, align 8
  %1025 = add i64 %1024, %1002
  br label %1026

1026:                                             ; preds = %1012, %1020
  %1027 = phi i64 [ %1025, %1020 ], [ %1007, %1012 ]
  %1028 = phi i64 [ %1024, %1020 ], [ %1006, %1012 ]
  %1029 = and i64 %997, -262144
  %1030 = or i64 %1029, 8
  %1031 = inttoptr i64 %1030 to i64*
  %1032 = load i64, i64* %1031, align 8
  %1033 = and i64 %1032, 24
  %1034 = icmp eq i64 %1033, 0
  br i1 %1034, label %1044, label %1035

1035:                                             ; preds = %1026
  %1036 = and i64 %1028, -262144
  %1037 = or i64 %1036, 8
  %1038 = inttoptr i64 %1037 to i64*
  %1039 = load i64, i64* %1038, align 8
  %1040 = and i64 %1039, 24
  %1041 = icmp eq i64 %1040, 0
  br i1 %1041, label %1042, label %1044

1042:                                             ; preds = %1035
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1028, i64 %1027, i64 %1019) #6
  %1043 = load i64, i64* %842, align 8
  br label %1044

1044:                                             ; preds = %995, %1026, %1035, %1042
  %1045 = phi i64 [ %1006, %995 ], [ %1028, %1026 ], [ %1028, %1035 ], [ %1043, %1042 ]
  %1046 = load i32, i32* %14, align 4
  %1047 = load i64, i64* %2, align 8
  %1048 = shl i32 %1046, 3
  %1049 = add i32 %1048, 12
  %1050 = sext i32 %1049 to i64
  %1051 = add nsw i64 %1050, 7
  %1052 = add i64 %1051, %1045
  %1053 = inttoptr i64 %1052 to i32*
  %1054 = trunc i64 %1047 to i32
  %1055 = or i32 %1054, 2
  store atomic volatile i32 %1055, i32* %1053 monotonic, align 4
  %1056 = load i64, i64* %842, align 8
  %1057 = add i64 %1056, %1051
  %1058 = and i64 %1047, 1
  %1059 = icmp ne i64 %1058, 0
  %1060 = icmp ne i32 %1055, 3
  %1061 = and i1 %1059, %1060
  br i1 %1061, label %1062, label %1210

1062:                                             ; preds = %1044
  %1063 = and i64 %1056, -262144
  %1064 = or i64 %1063, 8
  %1065 = inttoptr i64 %1064 to i64*
  %1066 = load i64, i64* %1065, align 8
  %1067 = and i64 %1066, 262144
  %1068 = icmp eq i64 %1067, 0
  %1069 = and i64 %1047, -3
  br i1 %1068, label %1076, label %1070

1070:                                             ; preds = %1062
  %1071 = or i64 %1063, 16
  %1072 = inttoptr i64 %1071 to %"class.v8::internal::Heap"**
  %1073 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %1072, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %1073, i64 %1056, i64 %1057, i64 %1069) #6
  %1074 = load i64, i64* %842, align 8
  %1075 = add i64 %1074, %1051
  br label %1076

1076:                                             ; preds = %1062, %1070
  %1077 = phi i64 [ %1075, %1070 ], [ %1057, %1062 ]
  %1078 = phi i64 [ %1074, %1070 ], [ %1056, %1062 ]
  %1079 = and i64 %1047, -262144
  %1080 = or i64 %1079, 8
  %1081 = inttoptr i64 %1080 to i64*
  %1082 = load i64, i64* %1081, align 8
  %1083 = and i64 %1082, 24
  %1084 = icmp eq i64 %1083, 0
  br i1 %1084, label %1210, label %1085

1085:                                             ; preds = %1076
  %1086 = and i64 %1078, -262144
  %1087 = or i64 %1086, 8
  %1088 = inttoptr i64 %1087 to i64*
  %1089 = load i64, i64* %1088, align 8
  %1090 = and i64 %1089, 24
  %1091 = icmp eq i64 %1090, 0
  br i1 %1091, label %1092, label %1210

1092:                                             ; preds = %1085
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1078, i64 %1077, i64 %1069) #6
  br label %1210

1093:                                             ; preds = %993, %1206
  %1094 = phi i64 [ %994, %993 ], [ %1095, %1206 ]
  %1095 = add nsw i64 %1094, -1
  %1096 = trunc i64 %1095 to i32
  %1097 = shl i32 %1096, 3
  %1098 = load i64, i64* %842, align 8
  %1099 = and i64 %1098, -4294967296
  %1100 = add i32 %1097, 8
  %1101 = or i32 %1100, 7
  %1102 = sext i32 %1101 to i64
  %1103 = add i64 %1098, %1102
  %1104 = inttoptr i64 %1103 to i32*
  %1105 = load atomic i32, i32* %1104 monotonic, align 4
  %1106 = zext i32 %1105 to i64
  %1107 = or i64 %1099, %1106
  %1108 = trunc i64 %1094 to i32
  %1109 = shl i32 %1108, 3
  %1110 = add i32 %1109, 8
  %1111 = or i32 %1110, 7
  %1112 = sext i32 %1111 to i64
  %1113 = add i64 %1098, %1112
  %1114 = inttoptr i64 %1113 to i32*
  store atomic volatile i32 %1105, i32* %1114 monotonic, align 4
  %1115 = load i64, i64* %842, align 8
  %1116 = add i64 %1115, %1112
  %1117 = and i64 %1106, 1
  %1118 = icmp ne i64 %1117, 0
  %1119 = icmp ne i32 %1105, 3
  %1120 = and i1 %1119, %1118
  br i1 %1120, label %1121, label %1153

1121:                                             ; preds = %1093
  %1122 = and i64 %1115, -262144
  %1123 = or i64 %1122, 8
  %1124 = inttoptr i64 %1123 to i64*
  %1125 = load i64, i64* %1124, align 8
  %1126 = and i64 %1125, 262144
  %1127 = icmp eq i64 %1126, 0
  %1128 = and i64 %1107, -3
  br i1 %1127, label %1135, label %1129

1129:                                             ; preds = %1121
  %1130 = or i64 %1122, 16
  %1131 = inttoptr i64 %1130 to %"class.v8::internal::Heap"**
  %1132 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %1131, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %1132, i64 %1115, i64 %1116, i64 %1128) #6
  %1133 = load i64, i64* %842, align 8
  %1134 = add i64 %1133, %1112
  br label %1135

1135:                                             ; preds = %1121, %1129
  %1136 = phi i64 [ %1134, %1129 ], [ %1116, %1121 ]
  %1137 = phi i64 [ %1133, %1129 ], [ %1115, %1121 ]
  %1138 = and i64 %1107, -262144
  %1139 = or i64 %1138, 8
  %1140 = inttoptr i64 %1139 to i64*
  %1141 = load i64, i64* %1140, align 8
  %1142 = and i64 %1141, 24
  %1143 = icmp eq i64 %1142, 0
  br i1 %1143, label %1153, label %1144

1144:                                             ; preds = %1135
  %1145 = and i64 %1137, -262144
  %1146 = or i64 %1145, 8
  %1147 = inttoptr i64 %1146 to i64*
  %1148 = load i64, i64* %1147, align 8
  %1149 = and i64 %1148, 24
  %1150 = icmp eq i64 %1149, 0
  br i1 %1150, label %1151, label %1153

1151:                                             ; preds = %1144
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1137, i64 %1136, i64 %1128) #6
  %1152 = load i64, i64* %842, align 8
  br label %1153

1153:                                             ; preds = %1093, %1135, %1144, %1151
  %1154 = phi i64 [ %1115, %1093 ], [ %1137, %1135 ], [ %1137, %1144 ], [ %1152, %1151 ]
  %1155 = and i64 %1154, -4294967296
  %1156 = add i32 %1097, 12
  %1157 = sext i32 %1156 to i64
  %1158 = add nsw i64 %1157, 7
  %1159 = add i64 %1158, %1154
  %1160 = inttoptr i64 %1159 to i32*
  %1161 = load atomic i32, i32* %1160 monotonic, align 4
  %1162 = zext i32 %1161 to i64
  %1163 = or i64 %1155, %1162
  %1164 = add i32 %1109, 12
  %1165 = sext i32 %1164 to i64
  %1166 = add nsw i64 %1165, 7
  %1167 = add i64 %1154, %1166
  %1168 = inttoptr i64 %1167 to i32*
  store atomic volatile i32 %1161, i32* %1168 monotonic, align 4
  %1169 = load i64, i64* %842, align 8
  %1170 = add i64 %1169, %1166
  %1171 = and i64 %1162, 1
  %1172 = icmp ne i64 %1171, 0
  %1173 = icmp ne i32 %1161, 3
  %1174 = and i1 %1173, %1172
  br i1 %1174, label %1175, label %1206

1175:                                             ; preds = %1153
  %1176 = and i64 %1169, -262144
  %1177 = or i64 %1176, 8
  %1178 = inttoptr i64 %1177 to i64*
  %1179 = load i64, i64* %1178, align 8
  %1180 = and i64 %1179, 262144
  %1181 = icmp eq i64 %1180, 0
  %1182 = and i64 %1163, -3
  br i1 %1181, label %1189, label %1183

1183:                                             ; preds = %1175
  %1184 = or i64 %1176, 16
  %1185 = inttoptr i64 %1184 to %"class.v8::internal::Heap"**
  %1186 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %1185, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %1186, i64 %1169, i64 %1170, i64 %1182) #6
  %1187 = load i64, i64* %842, align 8
  %1188 = add i64 %1187, %1166
  br label %1189

1189:                                             ; preds = %1175, %1183
  %1190 = phi i64 [ %1188, %1183 ], [ %1170, %1175 ]
  %1191 = phi i64 [ %1187, %1183 ], [ %1169, %1175 ]
  %1192 = and i64 %1163, -262144
  %1193 = or i64 %1192, 8
  %1194 = inttoptr i64 %1193 to i64*
  %1195 = load i64, i64* %1194, align 8
  %1196 = and i64 %1195, 24
  %1197 = icmp eq i64 %1196, 0
  br i1 %1197, label %1206, label %1198

1198:                                             ; preds = %1189
  %1199 = and i64 %1191, -262144
  %1200 = or i64 %1199, 8
  %1201 = inttoptr i64 %1200 to i64*
  %1202 = load i64, i64* %1201, align 8
  %1203 = and i64 %1202, 24
  %1204 = icmp eq i64 %1203, 0
  br i1 %1204, label %1205, label %1206

1205:                                             ; preds = %1198
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1191, i64 %1190, i64 %1182) #6
  br label %1206

1206:                                             ; preds = %1153, %1189, %1198, %1205
  %1207 = load i32, i32* %14, align 4
  %1208 = sext i32 %1207 to i64
  %1209 = icmp sgt i64 %1095, %1208
  br i1 %1209, label %1093, label %995

1210:                                             ; preds = %1092, %1085, %1076, %1044, %965, %958, %949, %915
  %1211 = phi %"class.v8::base::SharedMutex"* [ %918, %915 ], [ %918, %949 ], [ %918, %958 ], [ %918, %965 ], [ %986, %1044 ], [ %986, %1076 ], [ %986, %1085 ], [ %986, %1092 ]
  call void @_ZN2v84base11SharedMutex15UnlockExclusiveEv(%"class.v8::base::SharedMutex"* %1211) #6
  br label %1529

1212:                                             ; preds = %980
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %839) #6
  %1213 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %1214 = bitcast %"class.v8::internal::TransitionsAccessor"* %0 to %"class.v8::internal::Factory"**
  %1215 = load %"class.v8::internal::Factory"*, %"class.v8::internal::Factory"** %1214, align 8
  %1216 = sub nsw i32 1536, %853
  %1217 = icmp slt i32 %853, 1537
  br i1 %1217, label %1219, label %1218, !prof !2

1218:                                             ; preds = %1212
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.1, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.8, i64 0, i64 0)) #7
  unreachable

1219:                                             ; preds = %1212
  %1220 = icmp slt i32 %853, 4
  br i1 %1220, label %1225, label %1221

1221:                                             ; preds = %1219
  %1222 = lshr i32 %853, 2
  %1223 = icmp slt i32 %1222, %1216
  %1224 = select i1 %1223, i32 %1222, i32 %1216
  br label %1225

1225:                                             ; preds = %1219, %1221
  %1226 = phi i32 [ %1224, %1221 ], [ 1, %1219 ]
  %1227 = call i64* @_ZN2v88internal7Factory18NewTransitionArrayEii(%"class.v8::internal::Factory"* %1215, i32 %967, i32 %1226) #6
  %1228 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 1, i32 0, i32 0
  %1229 = load i64*, i64** %1228, align 8
  %1230 = load i64, i64* %1229, align 8
  store i64 %1230, i64* %24, align 8
  %1231 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %1213, align 8
  %1232 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1231, i64 0, i32 0, i32 4
  %1233 = load i64, i64* %1232, align 8
  %1234 = add i64 %1230, 35
  %1235 = inttoptr i64 %1234 to i32*
  %1236 = load atomic i32, i32* %1235 acquire, align 4
  %1237 = and i64 %1233, 4294967295
  %1238 = icmp eq i64 %1237, 0
  call void @llvm.assume(i1 %1238) #6
  %1239 = zext i32 %1236 to i64
  %1240 = or i64 %1233, %1239
  store i64 %1240, i64* %840, align 8
  %1241 = and i64 %1239, 1
  %1242 = icmp eq i64 %1241, 0
  %1243 = icmp eq i32 %1236, 3
  %1244 = or i1 %1243, %1242
  br i1 %1244, label %1267, label %1245

1245:                                             ; preds = %1225
  %1246 = and i64 %1239, 3
  switch i64 %1246, label %1266 [
    i64 3, label %1267
    i64 1, label %1247
  ]

1247:                                             ; preds = %1245
  %1248 = add i64 %1240, -1
  %1249 = inttoptr i64 %1248 to i32*
  %1250 = load atomic i32, i32* %1249 monotonic, align 4
  %1251 = zext i32 %1250 to i64
  %1252 = or i64 %1233, %1251
  %1253 = add i64 %1252, 7
  %1254 = inttoptr i64 %1253 to i16*
  %1255 = load atomic i16, i16* %1254 monotonic, align 2
  %1256 = icmp eq i16 %1255, 160
  br i1 %1256, label %1267, label %1257

1257:                                             ; preds = %1247
  %1258 = load atomic i32, i32* %1249 monotonic, align 4
  %1259 = zext i32 %1258 to i64
  %1260 = or i64 %1233, %1259
  %1261 = add i64 %1260, 7
  %1262 = inttoptr i64 %1261 to i16*
  %1263 = load atomic i16, i16* %1262 monotonic, align 2
  %1264 = icmp eq i16 %1263, 110
  %1265 = select i1 %1264, i32 0, i32 2
  br label %1267

1266:                                             ; preds = %1245
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

1267:                                             ; preds = %1257, %1247, %1245, %1225
  %1268 = phi i32 [ 1, %1225 ], [ 3, %1245 ], [ 4, %1247 ], [ %1265, %1257 ]
  store i32 %1268, i32* %26, align 8
  %1269 = bitcast %"class.v8::internal::TransitionArray"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %1269) #6
  %1270 = getelementptr inbounds %"class.v8::internal::TransitionArray", %"class.v8::internal::TransitionArray"* %16, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %1240, i64* %1270, align 8
  %1271 = add i64 %1240, 3
  %1272 = inttoptr i64 %1271 to i32*
  %1273 = load i32, i32* %1272, align 4
  %1274 = icmp slt i32 %1273, 4
  br i1 %1274, label %1280, label %1275

1275:                                             ; preds = %1267
  %1276 = add i64 %1240, 11
  %1277 = inttoptr i64 %1276 to i32*
  %1278 = load atomic i32, i32* %1277 monotonic, align 4
  %1279 = ashr i32 %1278, 1
  br label %1280

1280:                                             ; preds = %1267, %1275
  %1281 = phi i32 [ %1279, %1275 ], [ 0, %1267 ]
  %1282 = icmp eq i32 %1281, %853
  br i1 %1282, label %1367, label %1283

1283:                                             ; preds = %1280
  br i1 %813, label %1284, label %1333

1284:                                             ; preds = %1283
  %1285 = load i64, i64* %1, align 8
  br i1 %1274, label %1292, label %1286

1286:                                             ; preds = %1284
  %1287 = add i64 %1240, 11
  %1288 = inttoptr i64 %1287 to i32*
  %1289 = load atomic i32, i32* %1288 monotonic, align 4
  %1290 = ashr i32 %1289, 1
  %1291 = icmp eq i32 %1290, 0
  br i1 %1291, label %1292, label %1293

1292:                                             ; preds = %1286, %1284
  store i32 0, i32* %14, align 4
  br label %1349

1293:                                             ; preds = %1286
  %1294 = icmp slt i32 %1289, 18
  br i1 %1294, label %1295, label %1331

1295:                                             ; preds = %1293
  %1296 = add i64 %1285, 3
  %1297 = inttoptr i64 %1296 to i32*
  %1298 = load i32, i32* %1297, align 4
  %1299 = lshr i32 %1298, 2
  %1300 = load atomic i32, i32* %1288 monotonic, align 4
  %1301 = ashr i32 %1300, 1
  %1302 = icmp sgt i32 %1300, 1
  br i1 %1302, label %1303, label %1330

1303:                                             ; preds = %1295
  %1304 = trunc i64 %1285 to i32
  %1305 = zext i32 %1301 to i64
  br label %1306

1306:                                             ; preds = %1327, %1303
  %1307 = phi i64 [ 0, %1303 ], [ %1328, %1327 ]
  %1308 = trunc i64 %1307 to i32
  %1309 = shl i32 %1308, 3
  %1310 = add i32 %1309, 8
  %1311 = or i32 %1310, 7
  %1312 = sext i32 %1311 to i64
  %1313 = add i64 %1240, %1312
  %1314 = inttoptr i64 %1313 to i32*
  %1315 = load atomic i32, i32* %1314 monotonic, align 4
  %1316 = zext i32 %1315 to i64
  %1317 = or i64 %1233, %1316
  %1318 = add i64 %1317, 3
  %1319 = inttoptr i64 %1318 to i32*
  %1320 = load i32, i32* %1319, align 4
  %1321 = lshr i32 %1320, 2
  %1322 = icmp ugt i32 %1321, %1299
  br i1 %1322, label %1323, label %1325

1323:                                             ; preds = %1306
  %1324 = trunc i64 %1307 to i32
  store i32 %1324, i32* %14, align 4
  br label %1349

1325:                                             ; preds = %1306
  %1326 = icmp eq i32 %1315, %1304
  br i1 %1326, label %1339, label %1327

1327:                                             ; preds = %1325
  %1328 = add nuw nsw i64 %1307, 1
  %1329 = icmp eq i64 %1328, %1305
  br i1 %1329, label %1330, label %1306

1330:                                             ; preds = %1327, %1295
  store i32 %1301, i32* %14, align 4
  br label %1349

1331:                                             ; preds = %1293
  %1332 = call i32 @_ZN2v88internal12BinarySearchILNS0_10SearchModeE0ENS0_15TransitionArrayEEEiPT0_NS0_4NameEiPi(%"class.v8::internal::TransitionArray"* nonnull %16, i64 %1285, i32 %1290, i32* nonnull %14) #6
  br label %1341

1333:                                             ; preds = %1283
  %1334 = and i32 %838, 1
  %1335 = load i64, i64* %1, align 8
  %1336 = lshr i32 %838, 3
  %1337 = and i32 %1336, 7
  %1338 = call i32 @_ZN2v88internal15TransitionArray6SearchENS0_12PropertyKindENS0_4NameENS0_18PropertyAttributesEPi(%"class.v8::internal::TransitionArray"* nonnull %16, i32 %1334, i64 %1335, i32 %1337, i32* nonnull %14)
  br label %1341

1339:                                             ; preds = %1325
  %1340 = trunc i64 %1307 to i32
  br label %1341

1341:                                             ; preds = %1339, %1331, %1333
  %1342 = phi i32 [ %1338, %1333 ], [ %1332, %1331 ], [ %1340, %1339 ]
  %1343 = icmp eq i32 %1342, -1
  br i1 %1343, label %1344, label %1348, !prof !2

1344:                                             ; preds = %1341
  %1345 = load i64, i64* %1270, align 8
  %1346 = add i64 %1345, 3
  %1347 = inttoptr i64 %1346 to i32*
  br label %1349

1348:                                             ; preds = %1341
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.1, i64 0, i64 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.3, i64 0, i64 0)) #7
  unreachable

1349:                                             ; preds = %1344, %1323, %1330, %1292
  %1350 = phi i32* [ %1347, %1344 ], [ %1272, %1323 ], [ %1272, %1330 ], [ %1272, %1292 ]
  %1351 = phi i64 [ %1345, %1344 ], [ %1240, %1323 ], [ %1240, %1330 ], [ %1240, %1292 ]
  %1352 = load i32, i32* %1350, align 4
  %1353 = icmp slt i32 %1352, 4
  br i1 %1353, label %1359, label %1354

1354:                                             ; preds = %1349
  %1355 = add i64 %1351, 11
  %1356 = inttoptr i64 %1355 to i32*
  %1357 = load atomic i32, i32* %1356 monotonic, align 4
  %1358 = ashr i32 %1357, 1
  br label %1359

1359:                                             ; preds = %1349, %1354
  %1360 = phi i32 [ %1358, %1354 ], [ 0, %1349 ]
  %1361 = load i64, i64* %1227, align 8
  %1362 = shl nsw i32 %1360, 1
  %1363 = add i32 %1362, 2
  %1364 = add i64 %1361, 11
  %1365 = inttoptr i64 %1364 to i32*
  store atomic volatile i32 %1363, i32* %1365 monotonic, align 4
  %1366 = load i64, i64* %1270, align 8
  br label %1367

1367:                                             ; preds = %1280, %1359
  %1368 = phi i64 [ %1366, %1359 ], [ %1240, %1280 ]
  %1369 = phi i32 [ %1360, %1359 ], [ %853, %1280 ]
  %1370 = add i64 %1368, 7
  %1371 = inttoptr i64 %1370 to i32*
  %1372 = load atomic i32, i32* %1371 monotonic, align 4
  %1373 = icmp eq i32 %1372, 0
  br i1 %1373, label %1410, label %1374

1374:                                             ; preds = %1367
  %1375 = load i64, i64* %1227, align 8
  %1376 = and i64 %1368, -4294967296
  %1377 = load atomic i32, i32* %1371 monotonic, align 4
  %1378 = zext i32 %1377 to i64
  %1379 = or i64 %1376, %1378
  %1380 = add i64 %1375, 7
  %1381 = inttoptr i64 %1380 to i32*
  store atomic volatile i32 %1377, i32* %1381 monotonic, align 4
  %1382 = and i64 %1378, 1
  %1383 = icmp ne i64 %1382, 0
  %1384 = icmp ne i32 %1377, 3
  %1385 = and i1 %1384, %1383
  br i1 %1385, label %1386, label %1410

1386:                                             ; preds = %1374
  %1387 = and i64 %1375, -262144
  %1388 = or i64 %1387, 8
  %1389 = inttoptr i64 %1388 to i64*
  %1390 = load i64, i64* %1389, align 8
  %1391 = and i64 %1390, 262144
  %1392 = icmp eq i64 %1391, 0
  %1393 = and i64 %1379, -3
  br i1 %1392, label %1398, label %1394

1394:                                             ; preds = %1386
  %1395 = or i64 %1387, 16
  %1396 = inttoptr i64 %1395 to %"class.v8::internal::Heap"**
  %1397 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %1396, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %1397, i64 %1375, i64 %1380, i64 %1393) #6
  br label %1398

1398:                                             ; preds = %1386, %1394
  %1399 = and i64 %1379, -262144
  %1400 = or i64 %1399, 8
  %1401 = inttoptr i64 %1400 to i64*
  %1402 = load i64, i64* %1401, align 8
  %1403 = and i64 %1402, 24
  %1404 = icmp eq i64 %1403, 0
  br i1 %1404, label %1410, label %1405

1405:                                             ; preds = %1398
  %1406 = load i64, i64* %1389, align 8
  %1407 = and i64 %1406, 24
  %1408 = icmp eq i64 %1407, 0
  br i1 %1408, label %1409, label %1410

1409:                                             ; preds = %1405
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1375, i64 %1380, i64 %1393) #6
  br label %1410

1410:                                             ; preds = %1367, %1409, %1405, %1398, %1374
  %1411 = load i32, i32* %14, align 4
  %1412 = icmp sgt i32 %1411, 0
  br i1 %1412, label %1413, label %1417

1413:                                             ; preds = %1410
  %1414 = bitcast %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %17 to i8*
  %1415 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %17, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %1416 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %17, i64 0, i32 0
  br label %1433

1417:                                             ; preds = %1433, %1410
  %1418 = phi i32 [ %1411, %1410 ], [ %1457, %1433 ]
  %1419 = bitcast %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %1419) #6
  %1420 = load i64, i64* %1227, align 8
  %1421 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %18, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %1420, i64* %1421, align 8
  %1422 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %18, i64 0, i32 0
  %1423 = load i64, i64* %1, align 8
  %1424 = load i64, i64* %2, align 8
  %1425 = or i64 %1424, 2
  call void @_ZN2v88internal15TransitionArray3SetEiNS0_4NameENS0_11MaybeObjectE(%"class.v8::internal::TransitionArray"* nonnull %1422, i32 %1418, i64 %1423, i64 %1425)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %1419) #6
  %1426 = load i32, i32* %14, align 4
  %1427 = icmp slt i32 %1426, %1369
  br i1 %1427, label %1428, label %1460

1428:                                             ; preds = %1417
  %1429 = bitcast %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %19 to i8*
  %1430 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %19, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %1431 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %19, i64 0, i32 0
  %1432 = sext i32 %1426 to i64
  br label %1503

1433:                                             ; preds = %1413, %1433
  %1434 = phi i64 [ 0, %1413 ], [ %1456, %1433 ]
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %1414) #6
  %1435 = load i64, i64* %1227, align 8
  store i64 %1435, i64* %1415, align 8
  %1436 = trunc i64 %1434 to i32
  %1437 = shl i32 %1436, 3
  %1438 = load i64, i64* %1270, align 8
  %1439 = and i64 %1438, -4294967296
  %1440 = add i32 %1437, 8
  %1441 = or i32 %1440, 7
  %1442 = sext i32 %1441 to i64
  %1443 = add i64 %1438, %1442
  %1444 = inttoptr i64 %1443 to i32*
  %1445 = load atomic i32, i32* %1444 monotonic, align 4
  %1446 = zext i32 %1445 to i64
  %1447 = or i64 %1439, %1446
  %1448 = add i32 %1437, 12
  %1449 = sext i32 %1448 to i64
  %1450 = add nsw i64 %1449, 7
  %1451 = add i64 %1450, %1438
  %1452 = inttoptr i64 %1451 to i32*
  %1453 = load atomic i32, i32* %1452 monotonic, align 4
  %1454 = zext i32 %1453 to i64
  %1455 = or i64 %1439, %1454
  call void @_ZN2v88internal15TransitionArray3SetEiNS0_4NameENS0_11MaybeObjectE(%"class.v8::internal::TransitionArray"* nonnull %1416, i32 %1436, i64 %1447, i64 %1455)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %1414) #6
  %1456 = add nuw nsw i64 %1434, 1
  %1457 = load i32, i32* %14, align 4
  %1458 = sext i32 %1457 to i64
  %1459 = icmp slt i64 %1456, %1458
  br i1 %1459, label %1433, label %1417

1460:                                             ; preds = %1503, %1417
  %1461 = load i64, i64* %1227, align 8
  %1462 = load i64, i64* %24, align 8
  %1463 = add i64 %1462, 35
  %1464 = inttoptr i64 %1463 to i32*
  %1465 = trunc i64 %1461 to i32
  store atomic volatile i32 %1465, i32* %1464 release, align 4
  %1466 = load i64, i64* %24, align 8
  %1467 = add i64 %1466, 35
  %1468 = and i64 %1461, 1
  %1469 = icmp ne i64 %1468, 0
  %1470 = icmp ne i32 %1465, 3
  %1471 = and i1 %1470, %1469
  br i1 %1471, label %1472, label %1529

1472:                                             ; preds = %1460
  %1473 = and i64 %1466, -262144
  %1474 = or i64 %1473, 8
  %1475 = inttoptr i64 %1474 to i64*
  %1476 = load i64, i64* %1475, align 8
  %1477 = and i64 %1476, 262144
  %1478 = icmp eq i64 %1477, 0
  %1479 = and i64 %1461, -3
  br i1 %1478, label %1486, label %1480

1480:                                             ; preds = %1472
  %1481 = or i64 %1473, 16
  %1482 = inttoptr i64 %1481 to %"class.v8::internal::Heap"**
  %1483 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %1482, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %1483, i64 %1466, i64 %1467, i64 %1479) #6
  %1484 = load i64, i64* %24, align 8
  %1485 = add i64 %1484, 35
  br label %1486

1486:                                             ; preds = %1472, %1480
  %1487 = phi i64 [ %1485, %1480 ], [ %1467, %1472 ]
  %1488 = phi i64 [ %1484, %1480 ], [ %1466, %1472 ]
  %1489 = and i64 %1461, -262144
  %1490 = or i64 %1489, 8
  %1491 = inttoptr i64 %1490 to i64*
  %1492 = load i64, i64* %1491, align 8
  %1493 = and i64 %1492, 24
  %1494 = icmp eq i64 %1493, 0
  br i1 %1494, label %1529, label %1495

1495:                                             ; preds = %1486
  %1496 = and i64 %1488, -262144
  %1497 = or i64 %1496, 8
  %1498 = inttoptr i64 %1497 to i64*
  %1499 = load i64, i64* %1498, align 8
  %1500 = and i64 %1499, 24
  %1501 = icmp eq i64 %1500, 0
  br i1 %1501, label %1502, label %1529

1502:                                             ; preds = %1495
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1488, i64 %1487, i64 %1479) #6
  br label %1529

1503:                                             ; preds = %1503, %1428
  %1504 = phi i64 [ %1432, %1428 ], [ %1506, %1503 ]
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %1429) #6
  %1505 = load i64, i64* %1227, align 8
  store i64 %1505, i64* %1430, align 8
  %1506 = add nsw i64 %1504, 1
  %1507 = trunc i64 %1504 to i32
  %1508 = shl i32 %1507, 3
  %1509 = load i64, i64* %1270, align 8
  %1510 = and i64 %1509, -4294967296
  %1511 = add i32 %1508, 8
  %1512 = or i32 %1511, 7
  %1513 = sext i32 %1512 to i64
  %1514 = add i64 %1509, %1513
  %1515 = inttoptr i64 %1514 to i32*
  %1516 = load atomic i32, i32* %1515 monotonic, align 4
  %1517 = zext i32 %1516 to i64
  %1518 = or i64 %1510, %1517
  %1519 = add i32 %1508, 12
  %1520 = sext i32 %1519 to i64
  %1521 = add nsw i64 %1520, 7
  %1522 = add i64 %1521, %1509
  %1523 = inttoptr i64 %1522 to i32*
  %1524 = load atomic i32, i32* %1523 monotonic, align 4
  %1525 = zext i32 %1524 to i64
  %1526 = or i64 %1510, %1525
  %1527 = trunc i64 %1506 to i32
  call void @_ZN2v88internal15TransitionArray3SetEiNS0_4NameENS0_11MaybeObjectE(%"class.v8::internal::TransitionArray"* nonnull %1431, i32 %1527, i64 %1518, i64 %1526)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %1429) #6
  %1528 = icmp eq i32 %1369, %1527
  br i1 %1528, label %1460, label %1503

1529:                                             ; preds = %1502, %1495, %1486, %1460, %1210
  %1530 = phi i8* [ %839, %1210 ], [ %1269, %1460 ], [ %1269, %1486 ], [ %1269, %1495 ], [ %1269, %1502 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %1530) #6
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %812) #6
  br label %1531

1531:                                             ; preds = %292, %319, %328, %335, %497, %496, %487, %476, %473, %809, %171, %170, %161, %150, %147, %73, %66, %57, %30, %1529
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal3Map14SetBackPointerENS0_10HeapObjectENS0_16WriteBarrierModeE(%"class.v8::internal::Map"*, i64, i32) local_unnamed_addr #3 comdat align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::Map", %"class.v8::internal::Map"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %5 = load i64, i64* %4, align 8
  %6 = add i64 %5, 7
  %7 = inttoptr i64 %6 to i16*
  %8 = load atomic i16, i16* %7 monotonic, align 2
  %9 = icmp ugt i16 %8, 185
  br i1 %9, label %11, label %10, !prof !2

10:                                               ; preds = %3
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.1, i64 0, i64 0), i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.4, i64 0, i64 0)) #7
  unreachable

11:                                               ; preds = %3
  %12 = and i64 %1, -4294967296
  %13 = add i64 %1, -1
  %14 = inttoptr i64 %13 to i32*
  %15 = load atomic i32, i32* %14 monotonic, align 4
  %16 = zext i32 %15 to i64
  %17 = or i64 %12, %16
  %18 = add i64 %17, 7
  %19 = inttoptr i64 %18 to i16*
  %20 = load atomic i16, i16* %19 monotonic, align 2
  %21 = icmp eq i16 %20, 172
  br i1 %21, label %23, label %22, !prof !2

22:                                               ; preds = %11
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.1, i64 0, i64 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.5, i64 0, i64 0)) #7
  unreachable

23:                                               ; preds = %11
  %24 = and i64 %5, -4294967296
  %25 = add i64 %5, 19
  %26 = inttoptr i64 %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = zext i32 %27 to i64
  %29 = or i64 %24, %28
  %30 = and i64 %28, 1
  %31 = icmp eq i64 %30, 0
  br i1 %31, label %32, label %34

32:                                               ; preds = %23
  %33 = load %"class.v8::internal::SoleReadOnlyHeap"*, %"class.v8::internal::SoleReadOnlyHeap"** @_ZN2v88internal16SoleReadOnlyHeap15shared_ro_heap_E, align 8
  br label %60

34:                                               ; preds = %23
  %35 = add i64 %29, -1
  %36 = inttoptr i64 %35 to i32*
  %37 = load atomic i32, i32* %36 monotonic, align 4
  %38 = load %"class.v8::internal::SoleReadOnlyHeap"*, %"class.v8::internal::SoleReadOnlyHeap"** @_ZN2v88internal16SoleReadOnlyHeap15shared_ro_heap_E, align 8
  %39 = icmp eq %"class.v8::internal::SoleReadOnlyHeap"* %38, null
  br i1 %39, label %46, label %40

40:                                               ; preds = %34
  %41 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %38, i64 0, i32 0, i32 1
  %42 = load i8, i8* %41, align 8, !range !3
  %43 = icmp eq i8 %42, 0
  br i1 %43, label %46, label %44

44:                                               ; preds = %40
  %45 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %38, i64 0, i32 1, i64 0
  br label %54

46:                                               ; preds = %40, %34
  %47 = and i64 %5, -262144
  %48 = or i64 %47, 16
  %49 = inttoptr i64 %48 to i64*
  %50 = load i64, i64* %49, align 16
  %51 = add i64 %50, -41416
  %52 = inttoptr i64 %51 to %"class.v8::internal::Isolate"*
  %53 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %52, i64 0, i32 0, i32 7, i32 0, i64 0
  br label %54

54:                                               ; preds = %46, %44
  %55 = phi i64* [ %53, %46 ], [ %45, %44 ]
  %56 = getelementptr inbounds i64, i64* %55, i64 10
  %57 = load i64, i64* %56, align 8
  %58 = trunc i64 %57 to i32
  %59 = icmp eq i32 %37, %58
  br i1 %59, label %81, label %60

60:                                               ; preds = %54, %32
  %61 = phi %"class.v8::internal::SoleReadOnlyHeap"* [ %33, %32 ], [ %38, %54 ]
  %62 = icmp eq %"class.v8::internal::SoleReadOnlyHeap"* %61, null
  br i1 %62, label %69, label %63

63:                                               ; preds = %60
  %64 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %61, i64 0, i32 0, i32 1
  %65 = load i8, i8* %64, align 8, !range !3
  %66 = icmp eq i8 %65, 0
  br i1 %66, label %69, label %67

67:                                               ; preds = %63
  %68 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %61, i64 0, i32 1, i64 0
  br label %77

69:                                               ; preds = %63, %60
  %70 = and i64 %5, -262144
  %71 = or i64 %70, 16
  %72 = inttoptr i64 %71 to i64*
  %73 = load i64, i64* %72, align 16
  %74 = add i64 %73, -41416
  %75 = inttoptr i64 %74 to %"class.v8::internal::Isolate"*
  %76 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %75, i64 0, i32 0, i32 7, i32 0, i64 0
  br label %77

77:                                               ; preds = %69, %67
  %78 = phi i64* [ %76, %69 ], [ %68, %67 ]
  %79 = getelementptr inbounds i64, i64* %78, i64 4
  %80 = load i64, i64* %79, align 8
  br label %81

81:                                               ; preds = %54, %77
  %82 = phi %"class.v8::internal::SoleReadOnlyHeap"* [ %61, %77 ], [ %38, %54 ]
  %83 = phi i64 [ %80, %77 ], [ %29, %54 ]
  %84 = icmp eq %"class.v8::internal::SoleReadOnlyHeap"* %82, null
  br i1 %84, label %91, label %85

85:                                               ; preds = %81
  %86 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %82, i64 0, i32 0, i32 1
  %87 = load i8, i8* %86, align 8, !range !3
  %88 = icmp eq i8 %87, 0
  br i1 %88, label %91, label %89

89:                                               ; preds = %85
  %90 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %82, i64 0, i32 1, i64 0
  br label %99

91:                                               ; preds = %85, %81
  %92 = and i64 %83, -262144
  %93 = or i64 %92, 16
  %94 = inttoptr i64 %93 to i64*
  %95 = load i64, i64* %94, align 16
  %96 = add i64 %95, -41416
  %97 = inttoptr i64 %96 to %"class.v8::internal::Isolate"*
  %98 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %97, i64 0, i32 0, i32 7, i32 0, i64 0
  br label %99

99:                                               ; preds = %89, %91
  %100 = phi i64* [ %98, %91 ], [ %90, %89 ]
  %101 = getelementptr inbounds i64, i64* %100, i64 4
  %102 = load i64, i64* %101, align 8
  %103 = trunc i64 %83 to i32
  %104 = trunc i64 %102 to i32
  %105 = icmp eq i32 %103, %104
  br i1 %105, label %107, label %106, !prof !2

106:                                              ; preds = %99
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.1, i64 0, i64 0), i8* getelementptr inbounds ([31 x i8], [31 x i8]* @.str.6, i64 0, i64 0)) #7
  unreachable

107:                                              ; preds = %99
  %108 = add i64 %1, 19
  %109 = inttoptr i64 %108 to i32*
  %110 = load i32, i32* %109, align 4
  %111 = zext i32 %110 to i64
  %112 = or i64 %12, %111
  %113 = and i64 %111, 1
  %114 = icmp eq i64 %113, 0
  br i1 %114, label %183, label %115

115:                                              ; preds = %107
  %116 = and i64 %1, -262144
  %117 = or i64 %116, 16
  %118 = inttoptr i64 %117 to i64*
  br i1 %84, label %148, label %119

119:                                              ; preds = %115
  %120 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %82, i64 0, i32 0, i32 1
  %121 = load i8, i8* %120, align 8, !range !3
  %122 = icmp eq i8 %121, 0
  br i1 %122, label %127, label %123

123:                                              ; preds = %119
  %124 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %82, i64 0, i32 1, i64 10
  %125 = load i64, i64* %124, align 8
  %126 = trunc i64 %125 to i32
  br label %169

127:                                              ; preds = %119
  %128 = load i64, i64* %118, align 16
  %129 = add i64 %128, -41416
  %130 = inttoptr i64 %129 to %"class.v8::internal::Isolate"*
  %131 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %130, i64 0, i32 0, i32 7, i32 0, i64 10
  %132 = load i64, i64* %131, align 8
  %133 = trunc i64 %132 to i32
  br label %134

134:                                              ; preds = %140, %127
  %135 = phi i64 [ %145, %140 ], [ %112, %127 ]
  %136 = add i64 %135, -1
  %137 = inttoptr i64 %136 to i32*
  %138 = load atomic i32, i32* %137 monotonic, align 4
  %139 = icmp eq i32 %138, %133
  br i1 %139, label %140, label %183

140:                                              ; preds = %134
  %141 = add i64 %135, 19
  %142 = inttoptr i64 %141 to i32*
  %143 = load i32, i32* %142, align 4
  %144 = zext i32 %143 to i64
  %145 = or i64 %12, %144
  %146 = and i64 %144, 1
  %147 = icmp eq i64 %146, 0
  br i1 %147, label %183, label %134

148:                                              ; preds = %115
  %149 = load i64, i64* %118, align 16
  %150 = add i64 %149, -41416
  %151 = inttoptr i64 %150 to %"class.v8::internal::Isolate"*
  %152 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %151, i64 0, i32 0, i32 7, i32 0, i64 10
  %153 = load i64, i64* %152, align 8
  %154 = trunc i64 %153 to i32
  br label %155

155:                                              ; preds = %161, %148
  %156 = phi i64 [ %166, %161 ], [ %112, %148 ]
  %157 = add i64 %156, -1
  %158 = inttoptr i64 %157 to i32*
  %159 = load atomic i32, i32* %158 monotonic, align 4
  %160 = icmp eq i32 %159, %154
  br i1 %160, label %161, label %183

161:                                              ; preds = %155
  %162 = add i64 %156, 19
  %163 = inttoptr i64 %162 to i32*
  %164 = load i32, i32* %163, align 4
  %165 = zext i32 %164 to i64
  %166 = or i64 %12, %165
  %167 = and i64 %165, 1
  %168 = icmp eq i64 %167, 0
  br i1 %168, label %183, label %155

169:                                              ; preds = %175, %123
  %170 = phi i64 [ %180, %175 ], [ %112, %123 ]
  %171 = add i64 %170, -1
  %172 = inttoptr i64 %171 to i32*
  %173 = load atomic i32, i32* %172 monotonic, align 4
  %174 = icmp eq i32 %173, %126
  br i1 %174, label %175, label %183

175:                                              ; preds = %169
  %176 = add i64 %170, 19
  %177 = inttoptr i64 %176 to i32*
  %178 = load i32, i32* %177, align 4
  %179 = zext i32 %178 to i64
  %180 = or i64 %12, %179
  %181 = and i64 %179, 1
  %182 = icmp eq i64 %181, 0
  br i1 %182, label %183, label %169

183:                                              ; preds = %169, %175, %134, %140, %155, %161, %107
  %184 = phi i64 [ %112, %107 ], [ %166, %161 ], [ %156, %155 ], [ %135, %134 ], [ %145, %140 ], [ %170, %169 ], [ %180, %175 ]
  %185 = trunc i64 %184 to i32
  %186 = icmp eq i32 %27, %185
  br i1 %186, label %188, label %187, !prof !2

187:                                              ; preds = %183
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.1, i64 0, i64 0), i8* getelementptr inbounds ([67 x i8], [67 x i8]* @.str.7, i64 0, i64 0)) #7
  unreachable

188:                                              ; preds = %183
  %189 = trunc i64 %1 to i32
  store atomic volatile i32 %189, i32* %26 monotonic, align 4
  switch i32 %2, label %206 [
    i32 0, label %226
    i32 4, label %190
  ]

190:                                              ; preds = %188
  %191 = load i64, i64* %4, align 8
  %192 = add i64 %191, 19
  %193 = and i64 %1, 1
  %194 = icmp eq i64 %193, 0
  br i1 %194, label %226, label %195

195:                                              ; preds = %190
  %196 = and i64 %191, -262144
  %197 = or i64 %196, 8
  %198 = inttoptr i64 %197 to i64*
  %199 = load i64, i64* %198, align 8
  %200 = and i64 %199, 262144
  %201 = icmp eq i64 %200, 0
  br i1 %201, label %209, label %202

202:                                              ; preds = %195
  %203 = or i64 %196, 16
  %204 = inttoptr i64 %203 to %"class.v8::internal::Heap"**
  %205 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %204, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %205, i64 %191, i64 %192, i64 %1) #6
  br label %209

206:                                              ; preds = %188
  %207 = and i64 %1, 1
  %208 = icmp eq i64 %207, 0
  br i1 %208, label %226, label %209

209:                                              ; preds = %195, %202, %206
  %210 = load i64, i64* %4, align 8
  %211 = add i64 %210, 19
  %212 = and i64 %1, -262144
  %213 = or i64 %212, 8
  %214 = inttoptr i64 %213 to i64*
  %215 = load i64, i64* %214, align 8
  %216 = and i64 %215, 24
  %217 = icmp eq i64 %216, 0
  br i1 %217, label %226, label %218

218:                                              ; preds = %209
  %219 = and i64 %210, -262144
  %220 = or i64 %219, 8
  %221 = inttoptr i64 %220 to i64*
  %222 = load i64, i64* %221, align 8
  %223 = and i64 %222, 24
  %224 = icmp eq i64 %223, 0
  br i1 %224, label %225, label %226

225:                                              ; preds = %218
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %210, i64 %211, i64 %1) #6
  br label %226

226:                                              ; preds = %188, %190, %206, %209, %218, %225
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19TransitionsAccessor18ReplaceTransitionsENS0_11MaybeObjectE(%"class.v8::internal::TransitionsAccessor"* nocapture readonly, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %4 = load i64, i64* %3, align 8
  %5 = add i64 %4, 35
  %6 = inttoptr i64 %5 to i32*
  %7 = trunc i64 %1 to i32
  store atomic volatile i32 %7, i32* %6 release, align 4
  %8 = load i64, i64* %3, align 8
  %9 = add i64 %8, 35
  %10 = and i64 %1, 1
  %11 = icmp ne i64 %10, 0
  %12 = icmp ne i32 %7, 3
  %13 = and i1 %12, %11
  br i1 %13, label %14, label %46

14:                                               ; preds = %2
  %15 = and i64 %8, -262144
  %16 = or i64 %15, 8
  %17 = inttoptr i64 %16 to i64*
  %18 = load i64, i64* %17, align 8
  %19 = and i64 %18, 262144
  %20 = icmp eq i64 %19, 0
  br i1 %20, label %28, label %21

21:                                               ; preds = %14
  %22 = and i64 %1, -3
  %23 = or i64 %15, 16
  %24 = inttoptr i64 %23 to %"class.v8::internal::Heap"**
  %25 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %24, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %25, i64 %8, i64 %9, i64 %22) #6
  %26 = load i64, i64* %3, align 8
  %27 = add i64 %26, 35
  br label %28

28:                                               ; preds = %21, %14
  %29 = phi i64 [ %9, %14 ], [ %27, %21 ]
  %30 = phi i64 [ %8, %14 ], [ %26, %21 ]
  %31 = and i64 %1, -3
  %32 = and i64 %1, -262144
  %33 = or i64 %32, 8
  %34 = inttoptr i64 %33 to i64*
  %35 = load i64, i64* %34, align 8
  %36 = and i64 %35, 24
  %37 = icmp eq i64 %36, 0
  br i1 %37, label %46, label %38

38:                                               ; preds = %28
  %39 = and i64 %30, -262144
  %40 = or i64 %39, 8
  %41 = inttoptr i64 %40 to i64*
  %42 = load i64, i64* %41, align 8
  %43 = and i64 %42, 24
  %44 = icmp eq i64 %43, 0
  br i1 %44, label %45, label %46

45:                                               ; preds = %38
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %30, i64 %29, i64 %31) #6
  br label %46

46:                                               ; preds = %2, %28, %38, %45
  ret void
}

declare i64* @_ZN2v88internal7Factory18NewTransitionArrayEii(%"class.v8::internal::Factory"*, i32, i32) local_unnamed_addr #4

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN2v88internal15TransitionArray3SetEiNS0_4NameENS0_11MaybeObjectE(%"class.v8::internal::TransitionArray"*, i32, i64, i64) local_unnamed_addr #3 comdat align 2 {
  %5 = shl i32 %1, 3
  %6 = add i32 %5, 8
  %7 = getelementptr inbounds %"class.v8::internal::TransitionArray", %"class.v8::internal::TransitionArray"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %8 = load i64, i64* %7, align 8
  %9 = or i32 %6, 7
  %10 = sext i32 %9 to i64
  %11 = add i64 %8, %10
  %12 = inttoptr i64 %11 to i32*
  %13 = trunc i64 %2 to i32
  store atomic volatile i32 %13, i32* %12 monotonic, align 4
  %14 = load i64, i64* %7, align 8
  %15 = add i64 %14, %10
  %16 = and i64 %2, 1
  %17 = icmp ne i64 %16, 0
  %18 = icmp ne i32 %13, 3
  %19 = and i1 %18, %17
  br i1 %19, label %20, label %53

20:                                               ; preds = %4
  %21 = and i64 %14, -262144
  %22 = or i64 %21, 8
  %23 = inttoptr i64 %22 to i64*
  %24 = load i64, i64* %23, align 8
  %25 = and i64 %24, 262144
  %26 = icmp eq i64 %25, 0
  br i1 %26, label %34, label %27

27:                                               ; preds = %20
  %28 = and i64 %2, -3
  %29 = or i64 %21, 16
  %30 = inttoptr i64 %29 to %"class.v8::internal::Heap"**
  %31 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %30, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %31, i64 %14, i64 %15, i64 %28) #6
  %32 = load i64, i64* %7, align 8
  %33 = add i64 %32, %10
  br label %34

34:                                               ; preds = %27, %20
  %35 = phi i64 [ %15, %20 ], [ %33, %27 ]
  %36 = phi i64 [ %14, %20 ], [ %32, %27 ]
  %37 = and i64 %2, -3
  %38 = and i64 %2, -262144
  %39 = or i64 %38, 8
  %40 = inttoptr i64 %39 to i64*
  %41 = load i64, i64* %40, align 8
  %42 = and i64 %41, 24
  %43 = icmp eq i64 %42, 0
  br i1 %43, label %53, label %44

44:                                               ; preds = %34
  %45 = and i64 %36, -262144
  %46 = or i64 %45, 8
  %47 = inttoptr i64 %46 to i64*
  %48 = load i64, i64* %47, align 8
  %49 = and i64 %48, 24
  %50 = icmp eq i64 %49, 0
  br i1 %50, label %51, label %53

51:                                               ; preds = %44
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %36, i64 %35, i64 %37) #6
  %52 = load i64, i64* %7, align 8
  br label %53

53:                                               ; preds = %4, %34, %44, %51
  %54 = phi i64 [ %36, %34 ], [ %36, %44 ], [ %52, %51 ], [ %14, %4 ]
  %55 = add i32 %5, 12
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 7
  %58 = add i64 %54, %57
  %59 = inttoptr i64 %58 to i32*
  %60 = trunc i64 %3 to i32
  store atomic volatile i32 %60, i32* %59 monotonic, align 4
  %61 = load i64, i64* %7, align 8
  %62 = add i64 %61, %57
  %63 = and i64 %3, 1
  %64 = icmp ne i64 %63, 0
  %65 = icmp ne i32 %60, 3
  %66 = and i1 %65, %64
  br i1 %66, label %67, label %99

67:                                               ; preds = %53
  %68 = and i64 %61, -262144
  %69 = or i64 %68, 8
  %70 = inttoptr i64 %69 to i64*
  %71 = load i64, i64* %70, align 8
  %72 = and i64 %71, 262144
  %73 = icmp eq i64 %72, 0
  br i1 %73, label %81, label %74

74:                                               ; preds = %67
  %75 = and i64 %3, -3
  %76 = or i64 %68, 16
  %77 = inttoptr i64 %76 to %"class.v8::internal::Heap"**
  %78 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %77, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %78, i64 %61, i64 %62, i64 %75) #6
  %79 = load i64, i64* %7, align 8
  %80 = add i64 %79, %57
  br label %81

81:                                               ; preds = %74, %67
  %82 = phi i64 [ %62, %67 ], [ %80, %74 ]
  %83 = phi i64 [ %61, %67 ], [ %79, %74 ]
  %84 = and i64 %3, -3
  %85 = and i64 %3, -262144
  %86 = or i64 %85, 8
  %87 = inttoptr i64 %86 to i64*
  %88 = load i64, i64* %87, align 8
  %89 = and i64 %88, 24
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %99, label %91

91:                                               ; preds = %81
  %92 = and i64 %83, -262144
  %93 = or i64 %92, 8
  %94 = inttoptr i64 %93 to i64*
  %95 = load i64, i64* %94, align 8
  %96 = and i64 %95, 24
  %97 = icmp eq i64 %96, 0
  br i1 %97, label %98, label %99

98:                                               ; preds = %91
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %83, i64 %82, i64 %84) #6
  br label %99

99:                                               ; preds = %53, %81, %91, %98
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN2v88internal15TransitionArray6SearchENS0_12PropertyKindENS0_4NameENS0_18PropertyAttributesEPi(%"class.v8::internal::TransitionArray"*, i32, i64, i32, i32*) local_unnamed_addr #0 align 2 {
  %6 = getelementptr inbounds %"class.v8::internal::TransitionArray", %"class.v8::internal::TransitionArray"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, 3
  %9 = inttoptr i64 %8 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = icmp slt i32 %10, 4
  br i1 %11, label %18, label %12

12:                                               ; preds = %5
  %13 = add i64 %7, 11
  %14 = inttoptr i64 %13 to i32*
  %15 = load atomic i32, i32* %14 monotonic, align 4
  %16 = ashr i32 %15, 1
  %17 = icmp eq i32 %16, 0
  br i1 %17, label %18, label %21

18:                                               ; preds = %12, %5
  %19 = icmp eq i32* %4, null
  br i1 %19, label %92, label %20

20:                                               ; preds = %18
  store i32 0, i32* %4, align 4
  br label %92

21:                                               ; preds = %12
  %22 = icmp slt i32 %15, 18
  br i1 %22, label %23, label %81

23:                                               ; preds = %21
  %24 = icmp eq i32* %4, null
  br i1 %24, label %25, label %30

25:                                               ; preds = %23
  %26 = icmp sgt i32 %15, 1
  br i1 %26, label %27, label %92

27:                                               ; preds = %25
  %28 = trunc i64 %2 to i32
  %29 = zext i32 %16 to i64
  br label %67

30:                                               ; preds = %23
  %31 = add i64 %2, 3
  %32 = inttoptr i64 %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = lshr i32 %33, 2
  %35 = load atomic i32, i32* %14 monotonic, align 4
  %36 = ashr i32 %35, 1
  %37 = icmp sgt i32 %35, 1
  br i1 %37, label %38, label %66

38:                                               ; preds = %30
  %39 = and i64 %7, -4294967296
  %40 = trunc i64 %2 to i32
  %41 = zext i32 %36 to i64
  br label %42

42:                                               ; preds = %63, %38
  %43 = phi i64 [ 0, %38 ], [ %64, %63 ]
  %44 = trunc i64 %43 to i32
  %45 = shl i32 %44, 3
  %46 = add i32 %45, 8
  %47 = or i32 %46, 7
  %48 = sext i32 %47 to i64
  %49 = add i64 %7, %48
  %50 = inttoptr i64 %49 to i32*
  %51 = load atomic i32, i32* %50 monotonic, align 4
  %52 = zext i32 %51 to i64
  %53 = or i64 %39, %52
  %54 = add i64 %53, 3
  %55 = inttoptr i64 %54 to i32*
  %56 = load i32, i32* %55, align 4
  %57 = lshr i32 %56, 2
  %58 = icmp ugt i32 %57, %34
  br i1 %58, label %59, label %61

59:                                               ; preds = %42
  %60 = trunc i64 %43 to i32
  store i32 %60, i32* %4, align 4
  br label %92

61:                                               ; preds = %42
  %62 = icmp eq i32 %51, %40
  br i1 %62, label %85, label %63

63:                                               ; preds = %61
  %64 = add nuw nsw i64 %43, 1
  %65 = icmp eq i64 %64, %41
  br i1 %65, label %66, label %42

66:                                               ; preds = %63, %30
  store i32 %36, i32* %4, align 4
  br label %92

67:                                               ; preds = %78, %27
  %68 = phi i64 [ 0, %27 ], [ %79, %78 ]
  %69 = trunc i64 %68 to i32
  %70 = shl i32 %69, 3
  %71 = add i32 %70, 8
  %72 = or i32 %71, 7
  %73 = sext i32 %72 to i64
  %74 = add i64 %7, %73
  %75 = inttoptr i64 %74 to i32*
  %76 = load atomic i32, i32* %75 monotonic, align 4
  %77 = icmp eq i32 %76, %28
  br i1 %77, label %83, label %78

78:                                               ; preds = %67
  %79 = add nuw nsw i64 %68, 1
  %80 = icmp eq i64 %79, %29
  br i1 %80, label %92, label %67

81:                                               ; preds = %21
  %82 = tail call i32 @_ZN2v88internal12BinarySearchILNS0_10SearchModeE0ENS0_15TransitionArrayEEEiPT0_NS0_4NameEiPi(%"class.v8::internal::TransitionArray"* %0, i64 %2, i32 %16, i32* %4) #6
  br label %87

83:                                               ; preds = %67
  %84 = trunc i64 %68 to i32
  br label %87

85:                                               ; preds = %61
  %86 = trunc i64 %43 to i32
  br label %87

87:                                               ; preds = %85, %83, %81
  %88 = phi i32 [ %82, %81 ], [ %84, %83 ], [ %86, %85 ]
  %89 = icmp eq i32 %88, -1
  br i1 %89, label %92, label %90

90:                                               ; preds = %87
  %91 = tail call i32 @_ZN2v88internal15TransitionArray13SearchDetailsEiNS0_12PropertyKindENS0_18PropertyAttributesEPi(%"class.v8::internal::TransitionArray"* %0, i32 %88, i32 %1, i32 %3, i32* %4)
  br label %92

92:                                               ; preds = %78, %25, %59, %66, %20, %18, %87, %90
  %93 = phi i32 [ %91, %90 ], [ -1, %87 ], [ -1, %18 ], [ -1, %20 ], [ -1, %66 ], [ -1, %59 ], [ -1, %25 ], [ -1, %78 ]
  ret i32 %93
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal19TransitionsAccessor16SearchTransitionENS0_4NameENS0_12PropertyKindENS0_18PropertyAttributesE(%"class.v8::internal::TransitionsAccessor"* nocapture readonly, i64, i32, i32) local_unnamed_addr #0 align 2 {
  %5 = alloca %"class.v8::internal::TransitionArray", align 8
  %6 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %7 = load i32, i32* %6, align 8
  switch i32 %7, label %62 [
    i32 0, label %63
    i32 1, label %63
    i32 2, label %63
    i32 3, label %8
    i32 4, label %45
  ]

8:                                                ; preds = %4
  %9 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %10 = load i64, i64* %9, align 8
  %11 = and i64 %10, -3
  %12 = add i64 %11, 11
  %13 = inttoptr i64 %12 to i32*
  %14 = load atomic i32, i32* %13 acquire, align 4
  %15 = lshr i32 %14, 10
  %16 = and i32 %15, 1023
  %17 = add nsw i32 %16, -1
  %18 = sext i32 %17 to i64
  %19 = and i64 %10, -4294967296
  %20 = add i64 %11, 23
  %21 = inttoptr i64 %20 to i32*
  %22 = load atomic i32, i32* %21 monotonic, align 4
  %23 = zext i32 %22 to i64
  %24 = or i64 %19, %23
  %25 = mul nsw i64 %18, 51539607552
  %26 = add nsw i64 %25, 68719476736
  %27 = ashr exact i64 %26, 32
  %28 = add i64 %24, -1
  %29 = add i64 %28, %27
  %30 = inttoptr i64 %29 to i32*
  %31 = load atomic i32, i32* %30 monotonic, align 4
  %32 = trunc i64 %1 to i32
  %33 = icmp eq i32 %31, %32
  br i1 %33, label %34, label %63

34:                                               ; preds = %8
  %35 = or i64 %27, 3
  %36 = add i64 %35, %24
  %37 = inttoptr i64 %36 to i32*
  %38 = load atomic i32, i32* %37 monotonic, align 4
  %39 = lshr i32 %38, 1
  %40 = and i32 %39, 57
  %41 = shl i32 %3, 3
  %42 = or i32 %41, %2
  %43 = icmp eq i32 %40, %42
  %44 = select i1 %43, i64 %11, i64 0
  ret i64 %44

45:                                               ; preds = %4
  %46 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %47 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %46, align 8
  %48 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %47, i64 0, i32 18
  %49 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 5
  %50 = load i8, i8* %49, align 4, !range !3
  %51 = icmp eq i8 %50, 0
  br i1 %51, label %53, label %52

52:                                               ; preds = %45
  tail call void @_ZN2v84base11SharedMutex10LockSharedEv(%"class.v8::base::SharedMutex"* %48) #6
  br label %53

53:                                               ; preds = %45, %52
  %54 = phi %"class.v8::base::SharedMutex"* [ %48, %52 ], [ null, %45 ]
  %55 = phi i1 [ false, %52 ], [ true, %45 ]
  %56 = bitcast %"class.v8::internal::TransitionArray"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %56) #6
  %57 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %58 = load i64, i64* %57, align 8
  %59 = getelementptr inbounds %"class.v8::internal::TransitionArray", %"class.v8::internal::TransitionArray"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %58, i64* %59, align 8
  %60 = call i64 @_ZN2v88internal15TransitionArray18SearchAndGetTargetENS0_12PropertyKindENS0_4NameENS0_18PropertyAttributesE(%"class.v8::internal::TransitionArray"* nonnull %5, i32 %2, i64 %1, i32 %3)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %56) #6
  br i1 %55, label %63, label %61

61:                                               ; preds = %53
  tail call void @_ZN2v84base11SharedMutex12UnlockSharedEv(%"class.v8::base::SharedMutex"* %54) #6
  br label %63

62:                                               ; preds = %4
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

63:                                               ; preds = %8, %61, %53, %4, %4, %4
  %64 = phi i64 [ 0, %4 ], [ 0, %4 ], [ 0, %4 ], [ %60, %53 ], [ %60, %61 ], [ 0, %8 ]
  ret i64 %64
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal19TransitionsAccessor13IsMatchingMapENS0_3MapENS0_4NameENS0_12PropertyKindENS0_18PropertyAttributesE(i64, i64, i32, i32) local_unnamed_addr #0 align 2 {
  %5 = add i64 %0, 11
  %6 = inttoptr i64 %5 to i32*
  %7 = load atomic i32, i32* %6 acquire, align 4
  %8 = lshr i32 %7, 10
  %9 = and i32 %8, 1023
  %10 = add nsw i32 %9, -1
  %11 = sext i32 %10 to i64
  %12 = and i64 %0, -4294967296
  %13 = add i64 %0, 23
  %14 = inttoptr i64 %13 to i32*
  %15 = load atomic i32, i32* %14 monotonic, align 4
  %16 = zext i32 %15 to i64
  %17 = or i64 %12, %16
  %18 = mul nsw i64 %11, 51539607552
  %19 = add nsw i64 %18, 68719476736
  %20 = ashr exact i64 %19, 32
  %21 = add i64 %17, -1
  %22 = add i64 %21, %20
  %23 = inttoptr i64 %22 to i32*
  %24 = load atomic i32, i32* %23 monotonic, align 4
  %25 = trunc i64 %1 to i32
  %26 = icmp eq i32 %24, %25
  br i1 %26, label %27, label %37

27:                                               ; preds = %4
  %28 = or i64 %20, 3
  %29 = add i64 %28, %17
  %30 = inttoptr i64 %29 to i32*
  %31 = load atomic i32, i32* %30 monotonic, align 4
  %32 = lshr i32 %31, 1
  %33 = and i32 %32, 57
  %34 = shl i32 %3, 3
  %35 = or i32 %34, %2
  %36 = icmp eq i32 %33, %35
  br label %37

37:                                               ; preds = %4, %27
  %38 = phi i1 [ %36, %27 ], [ false, %4 ]
  ret i1 %38
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal15TransitionArray18SearchAndGetTargetENS0_12PropertyKindENS0_4NameENS0_18PropertyAttributesE(%"class.v8::internal::TransitionArray"* nocapture readonly, i32, i64, i32) local_unnamed_addr #0 align 2 {
  %5 = getelementptr inbounds %"class.v8::internal::TransitionArray", %"class.v8::internal::TransitionArray"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 3
  %8 = inttoptr i64 %7 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = icmp slt i32 %9, 4
  br i1 %10, label %107, label %11

11:                                               ; preds = %4
  %12 = add i64 %6, 11
  %13 = inttoptr i64 %12 to i32*
  %14 = load atomic i32, i32* %13 monotonic, align 4
  %15 = ashr i32 %14, 1
  %16 = icmp eq i32 %15, 0
  br i1 %16, label %107, label %17

17:                                               ; preds = %11
  %18 = icmp slt i32 %14, 18
  br i1 %18, label %19, label %38

19:                                               ; preds = %17
  %20 = icmp sgt i32 %14, 1
  br i1 %20, label %21, label %107

21:                                               ; preds = %19
  %22 = trunc i64 %2 to i32
  %23 = zext i32 %15 to i64
  br label %24

24:                                               ; preds = %35, %21
  %25 = phi i64 [ 0, %21 ], [ %36, %35 ]
  %26 = trunc i64 %25 to i32
  %27 = shl i32 %26, 3
  %28 = add i32 %27, 8
  %29 = or i32 %28, 7
  %30 = sext i32 %29 to i64
  %31 = add i64 %6, %30
  %32 = inttoptr i64 %31 to i32*
  %33 = load atomic i32, i32* %32 monotonic, align 4
  %34 = icmp eq i32 %33, %22
  br i1 %34, label %101, label %35

35:                                               ; preds = %24
  %36 = add nuw nsw i64 %25, 1
  %37 = icmp eq i64 %36, %23
  br i1 %37, label %107, label %24

38:                                               ; preds = %17
  %39 = load atomic i32, i32* %13 monotonic, align 4
  %40 = ashr i32 %39, 1
  %41 = add nsw i32 %40, -1
  %42 = add i64 %2, 3
  %43 = inttoptr i64 %42 to i32*
  %44 = load i32, i32* %43, align 4
  %45 = lshr i32 %44, 2
  %46 = icmp eq i32 %41, 0
  %47 = and i64 %6, -4294967296
  br i1 %46, label %50, label %54

48:                                               ; preds = %54
  %49 = icmp slt i32 %75, %40
  br i1 %49, label %50, label %107

50:                                               ; preds = %38, %48
  %51 = phi i32 [ %75, %48 ], [ 0, %38 ]
  %52 = trunc i64 %2 to i32
  %53 = sext i32 %51 to i64
  br label %78

54:                                               ; preds = %38, %54
  %55 = phi i32 [ %76, %54 ], [ 0, %38 ]
  %56 = phi i32 [ %75, %54 ], [ %41, %38 ]
  %57 = sub nsw i32 %56, %55
  %58 = sdiv i32 %57, 2
  %59 = add nsw i32 %58, %55
  %60 = shl i32 %59, 3
  %61 = add i32 %60, 8
  %62 = or i32 %61, 7
  %63 = sext i32 %62 to i64
  %64 = add i64 %6, %63
  %65 = inttoptr i64 %64 to i32*
  %66 = load atomic i32, i32* %65 monotonic, align 4
  %67 = zext i32 %66 to i64
  %68 = or i64 %47, %67
  %69 = add i64 %68, 3
  %70 = inttoptr i64 %69 to i32*
  %71 = load i32, i32* %70, align 4
  %72 = lshr i32 %71, 2
  %73 = icmp ult i32 %72, %45
  %74 = add nsw i32 %59, 1
  %75 = select i1 %73, i32 %56, i32 %59
  %76 = select i1 %73, i32 %74, i32 %55
  %77 = icmp eq i32 %75, %76
  br i1 %77, label %48, label %54

78:                                               ; preds = %97, %50
  %79 = phi i64 [ %53, %50 ], [ %98, %97 ]
  %80 = trunc i64 %79 to i32
  %81 = shl i32 %80, 3
  %82 = add i32 %81, 8
  %83 = or i32 %82, 7
  %84 = sext i32 %83 to i64
  %85 = add i64 %6, %84
  %86 = inttoptr i64 %85 to i32*
  %87 = load atomic i32, i32* %86 monotonic, align 4
  %88 = zext i32 %87 to i64
  %89 = or i64 %47, %88
  %90 = add i64 %89, 3
  %91 = inttoptr i64 %90 to i32*
  %92 = load i32, i32* %91, align 4
  %93 = lshr i32 %92, 2
  %94 = icmp eq i32 %93, %45
  br i1 %94, label %95, label %107

95:                                               ; preds = %78
  %96 = icmp eq i32 %87, %52
  br i1 %96, label %101, label %97

97:                                               ; preds = %95
  %98 = add nsw i64 %79, 1
  %99 = trunc i64 %98 to i32
  %100 = icmp eq i32 %40, %99
  br i1 %100, label %107, label %78

101:                                              ; preds = %95, %24
  %102 = phi i64 [ %25, %24 ], [ %79, %95 ]
  %103 = trunc i64 %102 to i32
  %104 = icmp eq i32 %103, -1
  br i1 %104, label %107, label %105

105:                                              ; preds = %101
  %106 = tail call i64 @_ZN2v88internal15TransitionArray25SearchDetailsAndGetTargetEiNS0_12PropertyKindENS0_18PropertyAttributesE(%"class.v8::internal::TransitionArray"* %0, i32 %103, i32 %1, i32 %3)
  br label %107

107:                                              ; preds = %97, %78, %35, %48, %4, %11, %19, %101, %105
  %108 = phi i64 [ %106, %105 ], [ 0, %101 ], [ 0, %19 ], [ 0, %11 ], [ 0, %4 ], [ 0, %48 ], [ 0, %35 ], [ 0, %78 ], [ 0, %97 ]
  ret i64 %108
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal19TransitionsAccessor13SearchSpecialENS0_6SymbolE(%"class.v8::internal::TransitionsAccessor"* nocapture readonly, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %4 = load i32, i32* %3, align 8
  %5 = icmp eq i32 %4, 4
  br i1 %5, label %6, label %119

6:                                                ; preds = %2
  %7 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %8 = load i64, i64* %7, align 8
  %9 = add i64 %8, 3
  %10 = inttoptr i64 %9 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = icmp slt i32 %11, 4
  br i1 %12, label %119, label %13

13:                                               ; preds = %6
  %14 = add i64 %8, 11
  %15 = inttoptr i64 %14 to i32*
  %16 = load atomic i32, i32* %15 monotonic, align 4
  %17 = ashr i32 %16, 1
  %18 = icmp eq i32 %17, 0
  br i1 %18, label %119, label %19

19:                                               ; preds = %13
  %20 = icmp slt i32 %16, 18
  br i1 %20, label %21, label %40

21:                                               ; preds = %19
  %22 = icmp sgt i32 %16, 1
  br i1 %22, label %23, label %119

23:                                               ; preds = %21
  %24 = trunc i64 %1 to i32
  %25 = zext i32 %17 to i64
  br label %26

26:                                               ; preds = %37, %23
  %27 = phi i64 [ 0, %23 ], [ %38, %37 ]
  %28 = trunc i64 %27 to i32
  %29 = shl i32 %28, 3
  %30 = add i32 %29, 8
  %31 = or i32 %30, 7
  %32 = sext i32 %31 to i64
  %33 = add i64 %8, %32
  %34 = inttoptr i64 %33 to i32*
  %35 = load atomic i32, i32* %34 monotonic, align 4
  %36 = icmp eq i32 %35, %24
  br i1 %36, label %103, label %37

37:                                               ; preds = %26
  %38 = add nuw nsw i64 %27, 1
  %39 = icmp eq i64 %38, %25
  br i1 %39, label %119, label %26

40:                                               ; preds = %19
  %41 = load atomic i32, i32* %15 monotonic, align 4
  %42 = ashr i32 %41, 1
  %43 = add nsw i32 %42, -1
  %44 = add i64 %1, 3
  %45 = inttoptr i64 %44 to i32*
  %46 = load i32, i32* %45, align 4
  %47 = lshr i32 %46, 2
  %48 = icmp eq i32 %43, 0
  %49 = and i64 %8, -4294967296
  br i1 %48, label %52, label %56

50:                                               ; preds = %56
  %51 = icmp slt i32 %77, %42
  br i1 %51, label %52, label %119

52:                                               ; preds = %40, %50
  %53 = phi i32 [ %77, %50 ], [ 0, %40 ]
  %54 = trunc i64 %1 to i32
  %55 = sext i32 %53 to i64
  br label %80

56:                                               ; preds = %40, %56
  %57 = phi i32 [ %78, %56 ], [ 0, %40 ]
  %58 = phi i32 [ %77, %56 ], [ %43, %40 ]
  %59 = sub nsw i32 %58, %57
  %60 = sdiv i32 %59, 2
  %61 = add nsw i32 %60, %57
  %62 = shl i32 %61, 3
  %63 = add i32 %62, 8
  %64 = or i32 %63, 7
  %65 = sext i32 %64 to i64
  %66 = add i64 %8, %65
  %67 = inttoptr i64 %66 to i32*
  %68 = load atomic i32, i32* %67 monotonic, align 4
  %69 = zext i32 %68 to i64
  %70 = or i64 %49, %69
  %71 = add i64 %70, 3
  %72 = inttoptr i64 %71 to i32*
  %73 = load i32, i32* %72, align 4
  %74 = lshr i32 %73, 2
  %75 = icmp ult i32 %74, %47
  %76 = add nsw i32 %61, 1
  %77 = select i1 %75, i32 %58, i32 %61
  %78 = select i1 %75, i32 %76, i32 %57
  %79 = icmp eq i32 %77, %78
  br i1 %79, label %50, label %56

80:                                               ; preds = %99, %52
  %81 = phi i64 [ %55, %52 ], [ %100, %99 ]
  %82 = trunc i64 %81 to i32
  %83 = shl i32 %82, 3
  %84 = add i32 %83, 8
  %85 = or i32 %84, 7
  %86 = sext i32 %85 to i64
  %87 = add i64 %8, %86
  %88 = inttoptr i64 %87 to i32*
  %89 = load atomic i32, i32* %88 monotonic, align 4
  %90 = zext i32 %89 to i64
  %91 = or i64 %49, %90
  %92 = add i64 %91, 3
  %93 = inttoptr i64 %92 to i32*
  %94 = load i32, i32* %93, align 4
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %95, %47
  br i1 %96, label %97, label %119

97:                                               ; preds = %80
  %98 = icmp eq i32 %89, %54
  br i1 %98, label %103, label %99

99:                                               ; preds = %97
  %100 = add nsw i64 %81, 1
  %101 = trunc i64 %100 to i32
  %102 = icmp eq i32 %42, %101
  br i1 %102, label %119, label %80

103:                                              ; preds = %97, %26
  %104 = phi i64 [ %27, %26 ], [ %81, %97 ]
  %105 = trunc i64 %104 to i32
  %106 = icmp eq i32 %105, -1
  br i1 %106, label %119, label %107

107:                                              ; preds = %103
  %108 = shl i32 %105, 3
  %109 = and i64 %8, -4294967296
  %110 = add i32 %108, 12
  %111 = sext i32 %110 to i64
  %112 = add i64 %8, 7
  %113 = add i64 %112, %111
  %114 = inttoptr i64 %113 to i32*
  %115 = load atomic i32, i32* %114 monotonic, align 4
  %116 = and i32 %115, -3
  %117 = zext i32 %116 to i64
  %118 = or i64 %109, %117
  br label %119

119:                                              ; preds = %99, %80, %37, %50, %6, %13, %21, %103, %2, %107
  %120 = phi i64 [ %118, %107 ], [ 0, %2 ], [ 0, %103 ], [ 0, %21 ], [ 0, %13 ], [ 0, %6 ], [ 0, %50 ], [ 0, %37 ], [ 0, %80 ], [ 0, %99 ]
  ret i64 %120
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal19TransitionsAccessor19IsSpecialTransitionENS0_13ReadOnlyRootsENS0_4NameE(i64*, i64) local_unnamed_addr #5 align 2 {
  %3 = and i64 %1, -4294967296
  %4 = add i64 %1, -1
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = zext i32 %6 to i64
  %8 = or i64 %3, %7
  %9 = add i64 %8, 7
  %10 = inttoptr i64 %9 to i16*
  %11 = load atomic i16, i16* %10 monotonic, align 2
  %12 = icmp eq i16 %11, 64
  br i1 %12, label %13, label %39

13:                                               ; preds = %2
  %14 = getelementptr inbounds i64, i64* %0, i64 490
  %15 = load i64, i64* %14, align 8
  %16 = trunc i64 %1 to i32
  %17 = trunc i64 %15 to i32
  %18 = icmp eq i32 %16, %17
  br i1 %18, label %39, label %19

19:                                               ; preds = %13
  %20 = getelementptr inbounds i64, i64* %0, i64 499
  %21 = load i64, i64* %20, align 8
  %22 = trunc i64 %21 to i32
  %23 = icmp eq i32 %16, %22
  br i1 %23, label %39, label %24

24:                                               ; preds = %19
  %25 = getelementptr inbounds i64, i64* %0, i64 485
  %26 = load i64, i64* %25, align 8
  %27 = trunc i64 %26 to i32
  %28 = icmp eq i32 %16, %27
  br i1 %28, label %39, label %29

29:                                               ; preds = %24
  %30 = getelementptr inbounds i64, i64* %0, i64 481
  %31 = load i64, i64* %30, align 8
  %32 = trunc i64 %31 to i32
  %33 = icmp eq i32 %16, %32
  br i1 %33, label %39, label %34

34:                                               ; preds = %29
  %35 = getelementptr inbounds i64, i64* %0, i64 501
  %36 = load i64, i64* %35, align 8
  %37 = trunc i64 %36 to i32
  %38 = icmp eq i32 %16, %37
  br label %39

39:                                               ; preds = %13, %19, %24, %29, %34, %2
  %40 = phi i1 [ false, %2 ], [ true, %29 ], [ true, %24 ], [ true, %19 ], [ true, %13 ], [ %38, %34 ]
  ret i1 %40
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal19TransitionsAccessor28FindTransitionToDataPropertyENS0_6HandleINS0_4NameEEENS1_17RequestedLocationE(%"class.v8::internal::TransitionsAccessor"* nocapture readonly, i64*, i32) local_unnamed_addr #0 align 2 {
  %4 = load i64, i64* %1, align 8
  %5 = and i64 %4, -4294967296
  %6 = add i64 %4, -1
  %7 = inttoptr i64 %6 to i32*
  %8 = load atomic i32, i32* %7 monotonic, align 4
  %9 = zext i32 %8 to i64
  %10 = or i64 %5, %9
  %11 = add i64 %10, 7
  %12 = inttoptr i64 %11 to i16*
  %13 = load atomic i16, i16* %12 monotonic, align 2
  %14 = icmp eq i16 %13, 64
  br i1 %14, label %15, label %21

15:                                               ; preds = %3
  %16 = add i64 %4, 7
  %17 = inttoptr i64 %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = shl i32 %18, 1
  %20 = and i32 %19, 2
  br label %21

21:                                               ; preds = %15, %3
  %22 = phi i32 [ 0, %3 ], [ %20, %15 ]
  %23 = tail call i64 @_ZN2v88internal19TransitionsAccessor16SearchTransitionENS0_4NameENS0_12PropertyKindENS0_18PropertyAttributesE(%"class.v8::internal::TransitionsAccessor"* %0, i64 %4, i32 0, i32 %22)
  %24 = trunc i64 %23 to i32
  %25 = icmp eq i32 %24, 0
  br i1 %25, label %76, label %26

26:                                               ; preds = %21
  %27 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %28 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %27, align 8
  %29 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %28, i64 0, i32 0, i32 4
  %30 = load i64, i64* %29, align 8
  %31 = add i64 %23, 23
  %32 = inttoptr i64 %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = and i64 %30, 4294967295
  %35 = icmp eq i64 %34, 0
  tail call void @llvm.assume(i1 %35) #6
  %36 = zext i32 %33 to i64
  %37 = or i64 %30, %36
  %38 = add i64 %23, 11
  %39 = inttoptr i64 %38 to i32*
  %40 = load atomic i32, i32* %39 acquire, align 4
  %41 = lshr i32 %40, 10
  %42 = and i32 %41, 1023
  %43 = add nsw i32 %42, -1
  %44 = sext i32 %43 to i64
  %45 = mul nsw i64 %44, 51539607552
  %46 = add nsw i64 %45, 68719476736
  %47 = ashr exact i64 %46, 32
  %48 = or i64 %47, 3
  %49 = add i64 %48, %37
  %50 = inttoptr i64 %49 to i32*
  %51 = load atomic i32, i32* %50 monotonic, align 4
  %52 = icmp ne i32 %2, 1
  %53 = and i32 %51, 4
  %54 = icmp eq i32 %53, 0
  %55 = or i1 %52, %54
  br i1 %55, label %56, label %76

56:                                               ; preds = %26
  %57 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %27, align 8
  %58 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %57, i64 0, i32 31, i32 4
  %59 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %58, align 8
  %60 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %59, null
  br i1 %60, label %63, label %61

61:                                               ; preds = %56
  %62 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %59, i64 %23) #6
  br label %76

63:                                               ; preds = %56
  %64 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %57, i64 0, i32 31, i32 0
  %65 = load i64*, i64** %64, align 8
  %66 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %57, i64 0, i32 31, i32 1
  %67 = load i64*, i64** %66, align 8
  %68 = icmp eq i64* %65, %67
  br i1 %68, label %69, label %71

69:                                               ; preds = %63
  %70 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %57) #6
  br label %71

71:                                               ; preds = %69, %63
  %72 = phi i64* [ %70, %69 ], [ %65, %63 ]
  %73 = ptrtoint i64* %72 to i64
  %74 = add i64 %73, 8
  %75 = inttoptr i64 %74 to i64*
  store i64* %75, i64** %64, align 8
  store i64 %23, i64* %72, align 8
  br label %76

76:                                               ; preds = %71, %61, %26, %21
  %77 = phi i64* [ null, %21 ], [ null, %26 ], [ %62, %61 ], [ %72, %71 ]
  ret i64* %77
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19TransitionsAccessor19ForEachTransitionToENS0_4NameERKNSt3__18functionIFvNS0_3MapEEEEPNS0_22CombinationAssertScopeIJNS0_29PerThreadAssertScopeDebugOnlyILNS0_19PerThreadAssertTypeE0ELb0EEENSB_ILSC_1ELb0EEEEEE(%"class.v8::internal::TransitionsAccessor"* nocapture readonly, i64, %"class.std::__1::function"* dereferenceable(32), %"class.v8::internal::CombinationAssertScope"* nocapture readnone) local_unnamed_addr #0 align 2 {
  %5 = alloca %"class.v8::internal::Map", align 8
  %6 = alloca %"class.v8::internal::TransitionArray", align 8
  %7 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %8 = load i32, i32* %7, align 8
  switch i32 %8, label %57 [
    i32 0, label %58
    i32 1, label %58
    i32 2, label %58
    i32 3, label %9
    i32 4, label %41
  ]

9:                                                ; preds = %4
  %10 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %11 = load i64, i64* %10, align 8
  %12 = and i64 %11, -3
  %13 = add i64 %12, 11
  %14 = inttoptr i64 %13 to i32*
  %15 = load atomic i32, i32* %14 acquire, align 4
  %16 = lshr i32 %15, 10
  %17 = and i32 %16, 1023
  %18 = add nsw i32 %17, -1
  %19 = sext i32 %18 to i64
  %20 = and i64 %11, -4294967296
  %21 = add i64 %12, 23
  %22 = inttoptr i64 %21 to i32*
  %23 = load atomic i32, i32* %22 monotonic, align 4
  %24 = zext i32 %23 to i64
  %25 = or i64 %20, %24
  %26 = mul nsw i64 %19, 51539607552
  %27 = add nsw i64 %26, 68719476736
  %28 = ashr exact i64 %27, 32
  %29 = add i64 %25, -1
  %30 = add i64 %29, %28
  %31 = inttoptr i64 %30 to i32*
  %32 = load atomic i32, i32* %31 monotonic, align 4
  %33 = trunc i64 %1 to i32
  %34 = icmp eq i32 %32, %33
  br i1 %34, label %35, label %58

35:                                               ; preds = %9
  %36 = bitcast %"class.v8::internal::Map"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %36)
  %37 = getelementptr inbounds %"class.v8::internal::Map", %"class.v8::internal::Map"* %5, i64 0, i32 0, i32 0, i32 0, i32 0
  store i64 %12, i64* %37, align 8
  %38 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %2, i64 0, i32 0, i32 1, i32 0
  %39 = load void (%"union.std::__1::__function::__policy_storage"*, %"class.v8::internal::Map"*)*, void (%"union.std::__1::__function::__policy_storage"*, %"class.v8::internal::Map"*)** %38, align 8
  %40 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %2, i64 0, i32 0, i32 0
  call void %39(%"union.std::__1::__function::__policy_storage"* %40, %"class.v8::internal::Map"* nonnull dereferenceable(8) %5) #6
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %36)
  br label %58

41:                                               ; preds = %4
  %42 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %43 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %42, align 8
  %44 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %43, i64 0, i32 18
  %45 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 5
  %46 = load i8, i8* %45, align 4, !range !3
  %47 = icmp eq i8 %46, 0
  br i1 %47, label %49, label %48

48:                                               ; preds = %41
  tail call void @_ZN2v84base11SharedMutex10LockSharedEv(%"class.v8::base::SharedMutex"* %44) #6
  br label %49

49:                                               ; preds = %41, %48
  %50 = phi %"class.v8::base::SharedMutex"* [ %44, %48 ], [ null, %41 ]
  %51 = phi i1 [ false, %48 ], [ true, %41 ]
  %52 = bitcast %"class.v8::internal::TransitionArray"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %52) #6
  %53 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %54 = load i64, i64* %53, align 8
  %55 = getelementptr inbounds %"class.v8::internal::TransitionArray", %"class.v8::internal::TransitionArray"* %6, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %54, i64* %55, align 8
  call void @_ZN2v88internal15TransitionArray19ForEachTransitionToENS0_4NameERKNSt3__18functionIFvNS0_3MapEEEE(%"class.v8::internal::TransitionArray"* nonnull %6, i64 %1, %"class.std::__1::function"* dereferenceable(32) %2)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %52) #6
  br i1 %51, label %58, label %56

56:                                               ; preds = %49
  tail call void @_ZN2v84base11SharedMutex12UnlockSharedEv(%"class.v8::base::SharedMutex"* %50) #6
  br label %58

57:                                               ; preds = %4
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

58:                                               ; preds = %56, %49, %9, %35, %4, %4, %4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal15TransitionArray19ForEachTransitionToENS0_4NameERKNSt3__18functionIFvNS0_3MapEEEE(%"class.v8::internal::TransitionArray"* nocapture readonly, i64, %"class.std::__1::function"* dereferenceable(32)) local_unnamed_addr #0 align 2 {
  %4 = alloca %"class.v8::internal::Map", align 8
  %5 = getelementptr inbounds %"class.v8::internal::TransitionArray", %"class.v8::internal::TransitionArray"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 3
  %8 = inttoptr i64 %7 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = icmp slt i32 %9, 4
  br i1 %10, label %163, label %11

11:                                               ; preds = %3
  %12 = add i64 %6, 11
  %13 = inttoptr i64 %12 to i32*
  %14 = load atomic i32, i32* %13 monotonic, align 4
  %15 = ashr i32 %14, 1
  %16 = icmp eq i32 %15, 0
  br i1 %16, label %163, label %17

17:                                               ; preds = %11
  %18 = icmp slt i32 %14, 18
  br i1 %18, label %19, label %38

19:                                               ; preds = %17
  %20 = icmp sgt i32 %14, 1
  br i1 %20, label %21, label %163

21:                                               ; preds = %19
  %22 = trunc i64 %1 to i32
  %23 = zext i32 %15 to i64
  br label %24

24:                                               ; preds = %35, %21
  %25 = phi i64 [ 0, %21 ], [ %36, %35 ]
  %26 = trunc i64 %25 to i32
  %27 = shl i32 %26, 3
  %28 = add i32 %27, 8
  %29 = or i32 %28, 7
  %30 = sext i32 %29 to i64
  %31 = add i64 %6, %30
  %32 = inttoptr i64 %31 to i32*
  %33 = load atomic i32, i32* %32 monotonic, align 4
  %34 = icmp eq i32 %33, %22
  br i1 %34, label %101, label %35

35:                                               ; preds = %24
  %36 = add nuw nsw i64 %25, 1
  %37 = icmp eq i64 %36, %23
  br i1 %37, label %163, label %24

38:                                               ; preds = %17
  %39 = load atomic i32, i32* %13 monotonic, align 4
  %40 = ashr i32 %39, 1
  %41 = add nsw i32 %40, -1
  %42 = add i64 %1, 3
  %43 = inttoptr i64 %42 to i32*
  %44 = load i32, i32* %43, align 4
  %45 = lshr i32 %44, 2
  %46 = icmp eq i32 %41, 0
  %47 = and i64 %6, -4294967296
  br i1 %46, label %50, label %54

48:                                               ; preds = %54
  %49 = icmp slt i32 %75, %40
  br i1 %49, label %50, label %163

50:                                               ; preds = %38, %48
  %51 = phi i32 [ %75, %48 ], [ 0, %38 ]
  %52 = trunc i64 %1 to i32
  %53 = sext i32 %51 to i64
  br label %78

54:                                               ; preds = %38, %54
  %55 = phi i32 [ %76, %54 ], [ 0, %38 ]
  %56 = phi i32 [ %75, %54 ], [ %41, %38 ]
  %57 = sub nsw i32 %56, %55
  %58 = sdiv i32 %57, 2
  %59 = add nsw i32 %58, %55
  %60 = shl i32 %59, 3
  %61 = add i32 %60, 8
  %62 = or i32 %61, 7
  %63 = sext i32 %62 to i64
  %64 = add i64 %6, %63
  %65 = inttoptr i64 %64 to i32*
  %66 = load atomic i32, i32* %65 monotonic, align 4
  %67 = zext i32 %66 to i64
  %68 = or i64 %47, %67
  %69 = add i64 %68, 3
  %70 = inttoptr i64 %69 to i32*
  %71 = load i32, i32* %70, align 4
  %72 = lshr i32 %71, 2
  %73 = icmp ult i32 %72, %45
  %74 = add nsw i32 %59, 1
  %75 = select i1 %73, i32 %56, i32 %59
  %76 = select i1 %73, i32 %74, i32 %55
  %77 = icmp eq i32 %75, %76
  br i1 %77, label %48, label %54

78:                                               ; preds = %97, %50
  %79 = phi i64 [ %53, %50 ], [ %98, %97 ]
  %80 = trunc i64 %79 to i32
  %81 = shl i32 %80, 3
  %82 = add i32 %81, 8
  %83 = or i32 %82, 7
  %84 = sext i32 %83 to i64
  %85 = add i64 %6, %84
  %86 = inttoptr i64 %85 to i32*
  %87 = load atomic i32, i32* %86 monotonic, align 4
  %88 = zext i32 %87 to i64
  %89 = or i64 %47, %88
  %90 = add i64 %89, 3
  %91 = inttoptr i64 %90 to i32*
  %92 = load i32, i32* %91, align 4
  %93 = lshr i32 %92, 2
  %94 = icmp eq i32 %93, %45
  br i1 %94, label %95, label %163

95:                                               ; preds = %78
  %96 = icmp eq i32 %87, %52
  br i1 %96, label %101, label %97

97:                                               ; preds = %95
  %98 = add nsw i64 %79, 1
  %99 = trunc i64 %98 to i32
  %100 = icmp eq i32 %40, %99
  br i1 %100, label %163, label %78

101:                                              ; preds = %95, %24
  %102 = phi i64 [ %25, %24 ], [ %79, %95 ]
  %103 = trunc i64 %102 to i32
  %104 = icmp eq i32 %103, -1
  br i1 %104, label %163, label %105

105:                                              ; preds = %101
  %106 = load atomic i32, i32* %13 monotonic, align 4
  %107 = ashr i32 %106, 1
  %108 = shl i32 %103, 3
  %109 = add i32 %108, 8
  %110 = or i32 %109, 7
  %111 = sext i32 %110 to i64
  %112 = add i64 %6, %111
  %113 = inttoptr i64 %112 to i32*
  %114 = load atomic i32, i32* %113 monotonic, align 4
  %115 = icmp sgt i32 %107, %103
  br i1 %115, label %116, label %163

116:                                              ; preds = %105
  %117 = bitcast %"class.v8::internal::Map"* %4 to i8*
  %118 = getelementptr inbounds %"class.v8::internal::Map", %"class.v8::internal::Map"* %4, i64 0, i32 0, i32 0, i32 0, i32 0
  %119 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %2, i64 0, i32 0, i32 1, i32 0
  %120 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %2, i64 0, i32 0, i32 0
  %121 = shl i64 %102, 35
  %122 = add i64 %121, 34359738368
  %123 = ashr exact i64 %122, 32
  %124 = or i64 %123, 7
  %125 = add i64 %6, %124
  %126 = inttoptr i64 %125 to i32*
  %127 = load atomic i32, i32* %126 monotonic, align 4
  %128 = icmp eq i32 %127, %114
  br i1 %128, label %129, label %163

129:                                              ; preds = %116
  %130 = shl i64 %102, 32
  %131 = trunc i64 %102 to i32
  %132 = shl i32 %131, 3
  %133 = ashr exact i64 %130, 32
  br label %134

134:                                              ; preds = %129, %152
  %135 = phi i32 [ %132, %129 ], [ %155, %152 ]
  %136 = phi i64 [ %133, %129 ], [ %149, %152 ]
  %137 = phi i64 [ %6, %129 ], [ %153, %152 ]
  %138 = and i64 %137, -4294967296
  %139 = add i32 %135, 12
  %140 = sext i32 %139 to i64
  %141 = add nsw i64 %140, 7
  %142 = add i64 %141, %137
  %143 = inttoptr i64 %142 to i32*
  %144 = load atomic i32, i32* %143 monotonic, align 4
  %145 = and i32 %144, -3
  %146 = zext i32 %145 to i64
  %147 = or i64 %138, %146
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %117)
  store i64 %147, i64* %118, align 8
  %148 = load void (%"union.std::__1::__function::__policy_storage"*, %"class.v8::internal::Map"*)*, void (%"union.std::__1::__function::__policy_storage"*, %"class.v8::internal::Map"*)** %119, align 8
  call void %148(%"union.std::__1::__function::__policy_storage"* %120, %"class.v8::internal::Map"* nonnull dereferenceable(8) %4) #6
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %117)
  %149 = add nsw i64 %136, 1
  %150 = trunc i64 %149 to i32
  %151 = icmp eq i32 %107, %150
  br i1 %151, label %163, label %152

152:                                              ; preds = %134
  %153 = load i64, i64* %5, align 8
  %154 = trunc i64 %149 to i32
  %155 = shl i32 %154, 3
  %156 = add i32 %155, 8
  %157 = or i32 %156, 7
  %158 = sext i32 %157 to i64
  %159 = add i64 %153, %158
  %160 = inttoptr i64 %159 to i32*
  %161 = load atomic i32, i32* %160 monotonic, align 4
  %162 = icmp eq i32 %161, %114
  br i1 %162, label %134, label %163

163:                                              ; preds = %97, %78, %35, %134, %152, %116, %105, %48, %3, %11, %19, %101
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal19TransitionsAccessor22CanHaveMoreTransitionsEv(%"class.v8::internal::TransitionsAccessor"* nocapture readonly) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %3 = load i64, i64* %2, align 8
  %4 = add i64 %3, 11
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = and i32 %6, 2097152
  %8 = icmp eq i32 %7, 0
  br i1 %8, label %9, label %25

9:                                                ; preds = %1
  %10 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %11 = load i32, i32* %10, align 8
  %12 = icmp eq i32 %11, 4
  br i1 %12, label %13, label %25

13:                                               ; preds = %9
  %14 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %15 = load i64, i64* %14, align 8
  %16 = add i64 %15, 3
  %17 = inttoptr i64 %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = icmp slt i32 %18, 4
  br i1 %19, label %25, label %20

20:                                               ; preds = %13
  %21 = add i64 %15, 11
  %22 = inttoptr i64 %21 to i32*
  %23 = load atomic i32, i32* %22 monotonic, align 4
  %24 = icmp slt i32 %23, 3072
  br label %25

25:                                               ; preds = %20, %13, %1, %9
  %26 = phi i1 [ false, %1 ], [ true, %9 ], [ %24, %20 ], [ true, %13 ]
  ret i1 %26
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal15TransitionArray31CompactPrototypeTransitionArrayEPNS0_7IsolateENS0_14WeakFixedArrayE(%"class.v8::internal::Isolate"*, i64) local_unnamed_addr #0 align 2 {
  %3 = add i64 %1, 3
  %4 = inttoptr i64 %3 to i32*
  %5 = load i32, i32* %4, align 4
  %6 = icmp ult i32 %5, 2
  br i1 %6, label %168, label %7

7:                                                ; preds = %2
  %8 = add i64 %1, 7
  %9 = inttoptr i64 %8 to i32*
  %10 = load atomic i32, i32* %9 monotonic, align 4
  %11 = ashr i32 %10, 1
  %12 = icmp eq i32 %11, 0
  br i1 %12, label %168, label %13

13:                                               ; preds = %7
  %14 = icmp sgt i32 %10, 1
  br i1 %14, label %15, label %23

15:                                               ; preds = %13
  %16 = and i64 %1, -4294967296
  %17 = and i64 %1, -262144
  %18 = or i64 %17, 8
  %19 = inttoptr i64 %18 to i64*
  %20 = or i64 %17, 16
  %21 = inttoptr i64 %20 to %"class.v8::internal::Heap"**
  %22 = sext i32 %11 to i64
  br label %88

23:                                               ; preds = %134, %13
  %24 = phi i32 [ 0, %13 ], [ %135, %134 ]
  %25 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 4
  %26 = load i64, i64* %25, align 8
  %27 = icmp sgt i32 %11, %24
  br i1 %27, label %28, label %137

28:                                               ; preds = %23
  %29 = trunc i64 %26 to i32
  %30 = and i64 %26, 1
  %31 = icmp ne i64 %30, 0
  %32 = icmp ne i32 %29, 3
  %33 = and i1 %32, %31
  %34 = and i64 %1, -262144
  %35 = or i64 %34, 8
  %36 = inttoptr i64 %35 to i64*
  %37 = and i64 %26, -3
  %38 = or i64 %34, 16
  %39 = inttoptr i64 %38 to %"class.v8::internal::Heap"**
  %40 = and i64 %26, -262144
  %41 = or i64 %40, 8
  %42 = inttoptr i64 %41 to i64*
  %43 = sext i32 %24 to i64
  br i1 %33, label %64, label %44

44:                                               ; preds = %28
  %45 = sub i32 %11, %24
  %46 = xor i32 %24, -1
  %47 = add i32 %11, %46
  %48 = and i32 %45, 3
  %49 = icmp eq i32 %48, 0
  br i1 %49, label %61, label %50

50:                                               ; preds = %44, %50
  %51 = phi i64 [ %53, %50 ], [ %43, %44 ]
  %52 = phi i32 [ %59, %50 ], [ %48, %44 ]
  %53 = add nsw i64 %51, 1
  %54 = trunc i64 %53 to i32
  %55 = shl i32 %54, 2
  %56 = sext i32 %55 to i64
  %57 = add i64 %8, %56
  %58 = inttoptr i64 %57 to i32*
  store atomic volatile i32 %29, i32* %58 monotonic, align 4
  %59 = add i32 %52, -1
  %60 = icmp eq i32 %59, 0
  br i1 %60, label %61, label %50, !llvm.loop !4

61:                                               ; preds = %50, %44
  %62 = phi i64 [ %43, %44 ], [ %53, %50 ]
  %63 = icmp ult i32 %47, 3
  br i1 %63, label %137, label %139

64:                                               ; preds = %28, %86
  %65 = phi i64 [ %66, %86 ], [ %43, %28 ]
  %66 = add nsw i64 %65, 1
  %67 = trunc i64 %66 to i32
  %68 = shl i32 %67, 2
  %69 = sext i32 %68 to i64
  %70 = add i64 %8, %69
  %71 = inttoptr i64 %70 to i32*
  store atomic volatile i32 %29, i32* %71 monotonic, align 4
  %72 = load i64, i64* %36, align 8
  %73 = and i64 %72, 262144
  %74 = icmp eq i64 %73, 0
  br i1 %74, label %77, label %75

75:                                               ; preds = %64
  %76 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %39, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %76, i64 %1, i64 %70, i64 %37) #6
  br label %77

77:                                               ; preds = %64, %75
  %78 = load i64, i64* %42, align 8
  %79 = and i64 %78, 24
  %80 = icmp eq i64 %79, 0
  br i1 %80, label %86, label %81

81:                                               ; preds = %77
  %82 = load i64, i64* %36, align 8
  %83 = and i64 %82, 24
  %84 = icmp eq i64 %83, 0
  br i1 %84, label %85, label %86

85:                                               ; preds = %81
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1, i64 %70, i64 %37) #6
  br label %86

86:                                               ; preds = %85, %81, %77
  %87 = icmp eq i32 %11, %67
  br i1 %87, label %137, label %64

88:                                               ; preds = %15, %134
  %89 = phi i64 [ 0, %15 ], [ %91, %134 ]
  %90 = phi i32 [ 0, %15 ], [ %135, %134 ]
  %91 = add nuw nsw i64 %89, 1
  %92 = trunc i64 %91 to i32
  %93 = shl i32 %92, 2
  %94 = sext i32 %93 to i64
  %95 = add i64 %8, %94
  %96 = inttoptr i64 %95 to i32*
  %97 = load atomic i32, i32* %96 monotonic, align 4
  %98 = zext i32 %97 to i64
  %99 = or i64 %16, %98
  %100 = icmp eq i32 %97, 3
  br i1 %100, label %134, label %101

101:                                              ; preds = %88
  %102 = zext i32 %90 to i64
  %103 = icmp eq i64 %89, %102
  br i1 %103, label %132, label %104

104:                                              ; preds = %101
  %105 = shl i32 %90, 2
  %106 = add i32 %105, 4
  %107 = sext i32 %106 to i64
  %108 = add i64 %8, %107
  %109 = inttoptr i64 %108 to i32*
  store atomic volatile i32 %97, i32* %109 monotonic, align 4
  %110 = and i64 %98, 1
  %111 = icmp eq i64 %110, 0
  br i1 %111, label %132, label %112

112:                                              ; preds = %104
  %113 = load i64, i64* %19, align 8
  %114 = and i64 %113, 262144
  %115 = icmp eq i64 %114, 0
  br i1 %115, label %119, label %116

116:                                              ; preds = %112
  %117 = and i64 %99, -3
  %118 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %21, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %118, i64 %1, i64 %108, i64 %117) #6
  br label %119

119:                                              ; preds = %112, %116
  %120 = and i64 %99, -3
  %121 = and i64 %99, -262144
  %122 = or i64 %121, 8
  %123 = inttoptr i64 %122 to i64*
  %124 = load i64, i64* %123, align 8
  %125 = and i64 %124, 24
  %126 = icmp eq i64 %125, 0
  br i1 %126, label %132, label %127

127:                                              ; preds = %119
  %128 = load i64, i64* %19, align 8
  %129 = and i64 %128, 24
  %130 = icmp eq i64 %129, 0
  br i1 %130, label %131, label %132

131:                                              ; preds = %127
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1, i64 %108, i64 %120) #6
  br label %132

132:                                              ; preds = %104, %131, %127, %119, %101
  %133 = add nsw i32 %90, 1
  br label %134

134:                                              ; preds = %132, %88
  %135 = phi i32 [ %90, %88 ], [ %133, %132 ]
  %136 = icmp slt i64 %91, %22
  br i1 %136, label %88, label %23

137:                                              ; preds = %61, %139, %86, %23
  %138 = icmp eq i32 %11, %24
  br i1 %138, label %168, label %166

139:                                              ; preds = %61, %139
  %140 = phi i64 [ %159, %139 ], [ %62, %61 ]
  %141 = trunc i64 %140 to i32
  %142 = shl i32 %141, 2
  %143 = add i32 %142, 4
  %144 = sext i32 %143 to i64
  %145 = add i64 %8, %144
  %146 = inttoptr i64 %145 to i32*
  store atomic volatile i32 %29, i32* %146 monotonic, align 4
  %147 = trunc i64 %140 to i32
  %148 = shl i32 %147, 2
  %149 = add i32 %148, 8
  %150 = sext i32 %149 to i64
  %151 = add i64 %8, %150
  %152 = inttoptr i64 %151 to i32*
  store atomic volatile i32 %29, i32* %152 monotonic, align 4
  %153 = trunc i64 %140 to i32
  %154 = shl i32 %153, 2
  %155 = add i32 %154, 12
  %156 = sext i32 %155 to i64
  %157 = add i64 %8, %156
  %158 = inttoptr i64 %157 to i32*
  store atomic volatile i32 %29, i32* %158 monotonic, align 4
  %159 = add nsw i64 %140, 4
  %160 = trunc i64 %159 to i32
  %161 = shl i32 %160, 2
  %162 = sext i32 %161 to i64
  %163 = add i64 %8, %162
  %164 = inttoptr i64 %163 to i32*
  store atomic volatile i32 %29, i32* %164 monotonic, align 4
  %165 = icmp eq i32 %11, %160
  br i1 %165, label %137, label %139

166:                                              ; preds = %137
  %167 = shl i32 %24, 1
  store atomic volatile i32 %167, i32* %9 monotonic, align 4
  br label %168

168:                                              ; preds = %166, %137, %2, %7
  %169 = phi i1 [ false, %7 ], [ false, %2 ], [ %27, %137 ], [ %27, %166 ]
  ret i1 %169
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal15TransitionArray31SetNumberOfPrototypeTransitionsENS0_14WeakFixedArrayEi(i64, i32) local_unnamed_addr #0 align 2 {
  %3 = shl i32 %1, 1
  %4 = add i64 %0, 7
  %5 = inttoptr i64 %4 to i32*
  store atomic volatile i32 %3, i32* %5 monotonic, align 4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal15TransitionArray28GrowPrototypeTransitionArrayENS0_6HandleINS0_14WeakFixedArrayEEEiPNS0_7IsolateE(i64*, i32, %"class.v8::internal::Isolate"*) local_unnamed_addr #0 align 2 {
  %4 = load i64, i64* %0, align 8
  %5 = add i64 %4, 3
  %6 = inttoptr i64 %5 to i32*
  %7 = load i32, i32* %6, align 4
  %8 = icmp slt i32 %1, 256
  %9 = ashr i32 %7, 1
  %10 = select i1 %8, i32 %1, i32 256
  %11 = sub nsw i32 1, %9
  %12 = add i32 %11, %10
  %13 = bitcast %"class.v8::internal::Isolate"* %2 to %"class.v8::internal::Factory"*
  %14 = call i64* @_ZN2v88internal7Factory25CopyWeakFixedArrayAndGrowENS0_6HandleINS0_14WeakFixedArrayEEEi(%"class.v8::internal::Factory"* %13, i64* %0, i32 %12) #6
  %15 = icmp slt i32 %7, 2
  br i1 %15, label %16, label %20

16:                                               ; preds = %3
  %17 = load i64, i64* %14, align 8
  %18 = add i64 %17, 7
  %19 = inttoptr i64 %18 to i32*
  store atomic volatile i32 0, i32* %19 monotonic, align 4
  br label %20

20:                                               ; preds = %16, %3
  ret i64* %14
}

declare i64* @_ZN2v88internal7Factory25CopyWeakFixedArrayAndGrowENS0_6HandleINS0_14WeakFixedArrayEEEi(%"class.v8::internal::Factory"*, i64*, i32) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19TransitionsAccessor22PutPrototypeTransitionENS0_6HandleINS0_6ObjectEEENS2_INS0_3MapEEE(%"class.v8::internal::TransitionsAccessor"*, i64* nocapture readnone, i64*) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %5 = load i64, i64* %4, align 8
  %6 = add i64 %5, 11
  %7 = inttoptr i64 %6 to i32*
  %8 = load atomic i32, i32* %7 acquire, align 4
  %9 = and i32 %8, 1048576
  %10 = icmp eq i32 %9, 0
  br i1 %10, label %11, label %244

11:                                               ; preds = %3
  %12 = load i64, i64* %4, align 8
  %13 = add i64 %12, 11
  %14 = inttoptr i64 %13 to i32*
  %15 = load atomic i32, i32* %14 monotonic, align 4
  %16 = and i32 %15, 2097152
  %17 = icmp ne i32 %16, 0
  %18 = load i8, i8* @_ZN2v88internal32FLAG_cache_prototype_transitionsE, align 1
  %19 = icmp eq i8 %18, 0
  %20 = or i1 %17, %19
  br i1 %20, label %244, label %21

21:                                               ; preds = %11
  %22 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %23 = load i32, i32* %22, align 8
  %24 = icmp eq i32 %23, 4
  br i1 %24, label %25, label %32

25:                                               ; preds = %21
  %26 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %27 = load i64, i64* %26, align 8
  %28 = add i64 %27, 7
  %29 = inttoptr i64 %28 to i32*
  %30 = load atomic i32, i32* %29 monotonic, align 4
  %31 = icmp eq i32 %30, 0
  br i1 %31, label %32, label %37

32:                                               ; preds = %25, %21
  %33 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %34 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %33, align 8
  %35 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %34, i64 0, i32 0, i32 7, i32 0, i64 119
  %36 = load i64, i64* %35, align 8
  br label %44

37:                                               ; preds = %25
  %38 = and i64 %27, -4294967296
  %39 = load atomic i32, i32* %29 monotonic, align 4
  %40 = zext i32 %39 to i64
  %41 = or i64 %38, %40
  %42 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %43 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %42, align 8
  br label %44

44:                                               ; preds = %32, %37
  %45 = phi %"class.v8::internal::Isolate"* [ %34, %32 ], [ %43, %37 ]
  %46 = phi i64 [ %36, %32 ], [ %41, %37 ]
  %47 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %48 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %45, i64 0, i32 31, i32 4
  %49 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %48, align 8
  %50 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %49, null
  br i1 %50, label %54, label %51

51:                                               ; preds = %44
  %52 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %49, i64 %46) #6
  %53 = load i64, i64* %52, align 8
  br label %67

54:                                               ; preds = %44
  %55 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %45, i64 0, i32 31, i32 0
  %56 = load i64*, i64** %55, align 8
  %57 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %45, i64 0, i32 31, i32 1
  %58 = load i64*, i64** %57, align 8
  %59 = icmp eq i64* %56, %58
  br i1 %59, label %60, label %62

60:                                               ; preds = %54
  %61 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %45) #6
  br label %62

62:                                               ; preds = %60, %54
  %63 = phi i64* [ %61, %60 ], [ %56, %54 ]
  %64 = ptrtoint i64* %63 to i64
  %65 = add i64 %64, 8
  %66 = inttoptr i64 %65 to i64*
  store i64* %66, i64** %55, align 8
  store i64 %46, i64* %63, align 8
  br label %67

67:                                               ; preds = %51, %62
  %68 = phi i64 [ %53, %51 ], [ %46, %62 ]
  %69 = phi i64* [ %52, %51 ], [ %63, %62 ]
  %70 = add i64 %68, 3
  %71 = inttoptr i64 %70 to i32*
  %72 = load i32, i32* %71, align 4
  %73 = ashr i32 %72, 1
  %74 = add nsw i32 %73, -1
  %75 = icmp ult i32 %72, 2
  br i1 %75, label %81, label %76

76:                                               ; preds = %67
  %77 = add i64 %68, 7
  %78 = inttoptr i64 %77 to i32*
  %79 = load atomic i32, i32* %78 monotonic, align 4
  %80 = ashr i32 %79, 1
  br label %81

81:                                               ; preds = %67, %76
  %82 = phi i32 [ %80, %76 ], [ 0, %67 ]
  %83 = icmp slt i32 %82, %74
  br i1 %83, label %185, label %84

84:                                               ; preds = %81
  %85 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %47, align 8
  %86 = tail call zeroext i1 @_ZN2v88internal15TransitionArray31CompactPrototypeTransitionArrayEPNS0_7IsolateENS0_14WeakFixedArrayE(%"class.v8::internal::Isolate"* %85, i64 %68)
  br i1 %86, label %185, label %87

87:                                               ; preds = %84
  %88 = icmp eq i32 %74, 256
  br i1 %88, label %244, label %89

89:                                               ; preds = %87
  %90 = shl nsw i32 %82, 1
  %91 = add i32 %90, 2
  %92 = bitcast %"class.v8::internal::TransitionsAccessor"* %0 to %"class.v8::internal::Factory"**
  %93 = load %"class.v8::internal::Factory"*, %"class.v8::internal::Factory"** %92, align 8
  %94 = load i64, i64* %69, align 8
  %95 = add i64 %94, 3
  %96 = inttoptr i64 %95 to i32*
  %97 = load i32, i32* %96, align 4
  %98 = icmp slt i32 %91, 256
  %99 = ashr i32 %97, 1
  %100 = select i1 %98, i32 %91, i32 256
  %101 = or i32 %100, 1
  %102 = sub i32 %101, %99
  %103 = tail call i64* @_ZN2v88internal7Factory25CopyWeakFixedArrayAndGrowENS0_6HandleINS0_14WeakFixedArrayEEEi(%"class.v8::internal::Factory"* %93, i64* %69, i32 %102) #6
  %104 = icmp slt i32 %97, 2
  br i1 %104, label %105, label %109

105:                                              ; preds = %89
  %106 = load i64, i64* %103, align 8
  %107 = add i64 %106, 7
  %108 = inttoptr i64 %107 to i32*
  store atomic volatile i32 0, i32* %108 monotonic, align 4
  br label %109

109:                                              ; preds = %89, %105
  %110 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 1, i32 0, i32 0
  %111 = load i64*, i64** %110, align 8
  %112 = load i64, i64* %111, align 8
  store i64 %112, i64* %4, align 8
  %113 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %47, align 8
  %114 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %113, i64 0, i32 0, i32 4
  %115 = load i64, i64* %114, align 8
  %116 = add i64 %112, 35
  %117 = inttoptr i64 %116 to i32*
  %118 = load atomic i32, i32* %117 acquire, align 4
  %119 = and i64 %115, 4294967295
  %120 = icmp eq i64 %119, 0
  tail call void @llvm.assume(i1 %120) #6
  %121 = zext i32 %118 to i64
  %122 = or i64 %115, %121
  %123 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  store i64 %122, i64* %123, align 8
  %124 = and i64 %121, 1
  %125 = icmp eq i64 %124, 0
  %126 = icmp eq i32 %118, 3
  %127 = or i1 %126, %125
  br i1 %127, label %150, label %128

128:                                              ; preds = %109
  %129 = and i64 %121, 3
  switch i64 %129, label %149 [
    i64 3, label %150
    i64 1, label %130
  ]

130:                                              ; preds = %128
  %131 = add i64 %122, -1
  %132 = inttoptr i64 %131 to i32*
  %133 = load atomic i32, i32* %132 monotonic, align 4
  %134 = zext i32 %133 to i64
  %135 = or i64 %115, %134
  %136 = add i64 %135, 7
  %137 = inttoptr i64 %136 to i16*
  %138 = load atomic i16, i16* %137 monotonic, align 2
  %139 = icmp eq i16 %138, 160
  br i1 %139, label %150, label %140

140:                                              ; preds = %130
  %141 = load atomic i32, i32* %132 monotonic, align 4
  %142 = zext i32 %141 to i64
  %143 = or i64 %115, %142
  %144 = add i64 %143, 7
  %145 = inttoptr i64 %144 to i16*
  %146 = load atomic i16, i16* %145 monotonic, align 2
  %147 = icmp eq i16 %146, 110
  %148 = select i1 %147, i32 0, i32 2
  br label %150

149:                                              ; preds = %128
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

150:                                              ; preds = %140, %130, %128, %109
  %151 = phi i32 [ 1, %109 ], [ 3, %128 ], [ 4, %130 ], [ %148, %140 ]
  store i32 %151, i32* %22, align 8
  tail call void @_ZN2v88internal19TransitionsAccessor28EnsureHasFullTransitionArrayEv(%"class.v8::internal::TransitionsAccessor"* %0) #6
  %152 = load i64, i64* %123, align 8
  %153 = load i64, i64* %103, align 8
  %154 = add i64 %152, 7
  %155 = inttoptr i64 %154 to i32*
  %156 = trunc i64 %153 to i32
  store atomic volatile i32 %156, i32* %155 monotonic, align 4
  %157 = and i64 %153, 1
  %158 = icmp ne i64 %157, 0
  %159 = icmp ne i32 %156, 3
  %160 = and i1 %159, %158
  br i1 %160, label %161, label %185

161:                                              ; preds = %150
  %162 = and i64 %152, -262144
  %163 = or i64 %162, 8
  %164 = inttoptr i64 %163 to i64*
  %165 = load i64, i64* %164, align 8
  %166 = and i64 %165, 262144
  %167 = icmp eq i64 %166, 0
  %168 = and i64 %153, -3
  br i1 %167, label %173, label %169

169:                                              ; preds = %161
  %170 = or i64 %162, 16
  %171 = inttoptr i64 %170 to %"class.v8::internal::Heap"**
  %172 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %171, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %172, i64 %152, i64 %154, i64 %168) #6
  br label %173

173:                                              ; preds = %169, %161
  %174 = and i64 %153, -262144
  %175 = or i64 %174, 8
  %176 = inttoptr i64 %175 to i64*
  %177 = load i64, i64* %176, align 8
  %178 = and i64 %177, 24
  %179 = icmp eq i64 %178, 0
  br i1 %179, label %185, label %180

180:                                              ; preds = %173
  %181 = load i64, i64* %164, align 8
  %182 = and i64 %181, 24
  %183 = icmp eq i64 %182, 0
  br i1 %183, label %184, label %185

184:                                              ; preds = %180
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %152, i64 %154, i64 %168) #6
  br label %185

185:                                              ; preds = %184, %180, %173, %150, %84, %81
  %186 = phi i64* [ %69, %81 ], [ %69, %84 ], [ %103, %150 ], [ %103, %173 ], [ %103, %180 ], [ %103, %184 ]
  %187 = load i64, i64* %186, align 8
  %188 = add i64 %187, 3
  %189 = inttoptr i64 %188 to i32*
  %190 = load i32, i32* %189, align 4
  %191 = icmp ult i32 %190, 2
  %192 = add i64 %187, 7
  br i1 %191, label %198, label %193

193:                                              ; preds = %185
  %194 = inttoptr i64 %192 to i32*
  %195 = load atomic i32, i32* %194 monotonic, align 4
  %196 = ashr i32 %195, 1
  %197 = add nsw i32 %196, 1
  br label %198

198:                                              ; preds = %185, %193
  %199 = phi i32 [ %197, %193 ], [ 1, %185 ]
  %200 = load i64, i64* %2, align 8
  %201 = shl i32 %199, 2
  %202 = sext i32 %201 to i64
  %203 = add i64 %192, %202
  %204 = inttoptr i64 %203 to i32*
  %205 = trunc i64 %200 to i32
  %206 = or i32 %205, 2
  store atomic volatile i32 %206, i32* %204 monotonic, align 4
  %207 = and i64 %200, 1
  %208 = icmp ne i64 %207, 0
  %209 = icmp ne i32 %206, 3
  %210 = and i1 %208, %209
  br i1 %210, label %211, label %239

211:                                              ; preds = %198
  %212 = and i64 %187, -262144
  %213 = or i64 %212, 8
  %214 = inttoptr i64 %213 to i64*
  %215 = load i64, i64* %214, align 8
  %216 = and i64 %215, 262144
  %217 = icmp eq i64 %216, 0
  br i1 %217, label %223, label %218

218:                                              ; preds = %211
  %219 = and i64 %200, -3
  %220 = or i64 %212, 16
  %221 = inttoptr i64 %220 to %"class.v8::internal::Heap"**
  %222 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %221, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %222, i64 %187, i64 %203, i64 %219) #6
  br label %223

223:                                              ; preds = %218, %211
  %224 = and i64 %200, -3
  %225 = and i64 %200, -262144
  %226 = or i64 %225, 8
  %227 = inttoptr i64 %226 to i64*
  %228 = load i64, i64* %227, align 8
  %229 = and i64 %228, 24
  %230 = icmp eq i64 %229, 0
  br i1 %230, label %239, label %231

231:                                              ; preds = %223
  %232 = and i64 %187, -262144
  %233 = or i64 %232, 8
  %234 = inttoptr i64 %233 to i64*
  %235 = load i64, i64* %234, align 8
  %236 = and i64 %235, 24
  %237 = icmp eq i64 %236, 0
  br i1 %237, label %238, label %239

238:                                              ; preds = %231
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %187, i64 %203, i64 %224) #6
  br label %239

239:                                              ; preds = %198, %223, %231, %238
  %240 = load i64, i64* %186, align 8
  %241 = shl i32 %199, 1
  %242 = add i64 %240, 7
  %243 = inttoptr i64 %242 to i32*
  store atomic volatile i32 %241, i32* %243 monotonic, align 4
  br label %244

244:                                              ; preds = %3, %239, %87, %11
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal19TransitionsAccessor23GetPrototypeTransitionsEv(%"class.v8::internal::TransitionsAccessor"* nocapture readonly) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %3 = load i32, i32* %2, align 8
  %4 = icmp eq i32 %3, 4
  br i1 %4, label %5, label %12

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, 7
  %9 = inttoptr i64 %8 to i32*
  %10 = load atomic i32, i32* %9 monotonic, align 4
  %11 = icmp eq i32 %10, 0
  br i1 %11, label %12, label %17

12:                                               ; preds = %5, %1
  %13 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %14 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %13, align 8
  %15 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %14, i64 0, i32 0, i32 7, i32 0, i64 119
  %16 = load i64, i64* %15, align 8
  br label %22

17:                                               ; preds = %5
  %18 = and i64 %7, -4294967296
  %19 = load atomic i32, i32* %9 monotonic, align 4
  %20 = zext i32 %19 to i64
  %21 = or i64 %18, %20
  br label %22

22:                                               ; preds = %17, %12
  %23 = phi i64 [ %16, %12 ], [ %21, %17 ]
  ret i64 %23
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19TransitionsAccessor23SetPrototypeTransitionsENS0_6HandleINS0_14WeakFixedArrayEEE(%"class.v8::internal::TransitionsAccessor"*, i64*) local_unnamed_addr #0 align 2 {
  tail call void @_ZN2v88internal19TransitionsAccessor28EnsureHasFullTransitionArrayEv(%"class.v8::internal::TransitionsAccessor"* %0)
  %3 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %4 = load i64, i64* %3, align 8
  %5 = load i64, i64* %1, align 8
  %6 = add i64 %4, 7
  %7 = inttoptr i64 %6 to i32*
  %8 = trunc i64 %5 to i32
  store atomic volatile i32 %8, i32* %7 monotonic, align 4
  %9 = and i64 %5, 1
  %10 = icmp ne i64 %9, 0
  %11 = icmp ne i32 %8, 3
  %12 = and i1 %11, %10
  br i1 %12, label %13, label %37

13:                                               ; preds = %2
  %14 = and i64 %4, -262144
  %15 = or i64 %14, 8
  %16 = inttoptr i64 %15 to i64*
  %17 = load i64, i64* %16, align 8
  %18 = and i64 %17, 262144
  %19 = icmp eq i64 %18, 0
  %20 = and i64 %5, -3
  br i1 %19, label %25, label %21

21:                                               ; preds = %13
  %22 = or i64 %14, 16
  %23 = inttoptr i64 %22 to %"class.v8::internal::Heap"**
  %24 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %23, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %24, i64 %4, i64 %6, i64 %20) #6
  br label %25

25:                                               ; preds = %13, %21
  %26 = and i64 %5, -262144
  %27 = or i64 %26, 8
  %28 = inttoptr i64 %27 to i64*
  %29 = load i64, i64* %28, align 8
  %30 = and i64 %29, 24
  %31 = icmp eq i64 %30, 0
  br i1 %31, label %37, label %32

32:                                               ; preds = %25
  %33 = load i64, i64* %16, align 8
  %34 = and i64 %33, 24
  %35 = icmp eq i64 %34, 0
  br i1 %35, label %36, label %37

36:                                               ; preds = %32
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %4, i64 %6, i64 %20) #6
  br label %37

37:                                               ; preds = %2, %25, %32, %36
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal19TransitionsAccessor22GetPrototypeTransitionENS0_6HandleINS0_6ObjectEEE(%"class.v8::internal::TransitionsAccessor"* nocapture readonly, i64*) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %4 = load i32, i32* %3, align 8
  %5 = icmp eq i32 %4, 4
  br i1 %5, label %6, label %13

6:                                                ; preds = %2
  %7 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %8 = load i64, i64* %7, align 8
  %9 = add i64 %8, 7
  %10 = inttoptr i64 %9 to i32*
  %11 = load atomic i32, i32* %10 monotonic, align 4
  %12 = icmp eq i32 %11, 0
  br i1 %12, label %13, label %18

13:                                               ; preds = %6, %2
  %14 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %15 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %14, align 8
  %16 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %15, i64 0, i32 0, i32 7, i32 0, i64 119
  %17 = load i64, i64* %16, align 8
  br label %23

18:                                               ; preds = %6
  %19 = and i64 %8, -4294967296
  %20 = load atomic i32, i32* %10 monotonic, align 4
  %21 = zext i32 %20 to i64
  %22 = or i64 %19, %21
  br label %23

23:                                               ; preds = %13, %18
  %24 = phi i64 [ %17, %13 ], [ %22, %18 ]
  %25 = add i64 %24, 3
  %26 = inttoptr i64 %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = icmp ult i32 %27, 2
  br i1 %28, label %85, label %29

29:                                               ; preds = %23
  %30 = add i64 %24, 7
  %31 = inttoptr i64 %30 to i32*
  %32 = load atomic i32, i32* %31 monotonic, align 4
  %33 = icmp sgt i32 %32, 1
  br i1 %33, label %34, label %85

34:                                               ; preds = %29
  %35 = ashr i32 %32, 1
  %36 = add i64 %24, 7
  %37 = and i64 %24, -4294967296
  %38 = zext i32 %35 to i64
  br label %39

39:                                               ; preds = %83, %34
  %40 = phi i64 [ 0, %34 ], [ %41, %83 ]
  %41 = add nuw nsw i64 %40, 1
  %42 = trunc i64 %41 to i32
  %43 = shl i32 %42, 2
  %44 = sext i32 %43 to i64
  %45 = add i64 %36, %44
  %46 = inttoptr i64 %45 to i32*
  %47 = load atomic i32, i32* %46 monotonic, align 4
  %48 = zext i32 %47 to i64
  %49 = and i64 %48, 3
  %50 = icmp eq i64 %49, 3
  %51 = icmp ne i32 %47, 3
  %52 = and i1 %51, %50
  br i1 %52, label %53, label %83

53:                                               ; preds = %39
  %54 = and i64 %48, 4294967293
  %55 = or i64 %54, %37
  %56 = add i64 %55, 15
  %57 = inttoptr i64 %56 to i32*
  %58 = load i32, i32* %57, align 4
  %59 = load i64, i64* %1, align 8
  %60 = trunc i64 %59 to i32
  %61 = icmp eq i32 %58, %60
  br i1 %61, label %62, label %83

62:                                               ; preds = %53
  %63 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %64 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %63, align 8
  %65 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %64, i64 0, i32 31, i32 4
  %66 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %65, align 8
  %67 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %66, null
  br i1 %67, label %70, label %68

68:                                               ; preds = %62
  %69 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %66, i64 %55) #6
  br label %85

70:                                               ; preds = %62
  %71 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %64, i64 0, i32 31, i32 0
  %72 = load i64*, i64** %71, align 8
  %73 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %64, i64 0, i32 31, i32 1
  %74 = load i64*, i64** %73, align 8
  %75 = icmp eq i64* %72, %74
  br i1 %75, label %76, label %78

76:                                               ; preds = %70
  %77 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %64) #6
  br label %78

78:                                               ; preds = %76, %70
  %79 = phi i64* [ %77, %76 ], [ %72, %70 ]
  %80 = ptrtoint i64* %79 to i64
  %81 = add i64 %80, 8
  %82 = inttoptr i64 %81 to i64*
  store i64* %82, i64** %71, align 8
  store i64 %55, i64* %79, align 8
  br label %85

83:                                               ; preds = %39, %53
  %84 = icmp eq i64 %41, %38
  br i1 %84, label %85, label %39

85:                                               ; preds = %83, %23, %29, %78, %68
  %86 = phi i64* [ %79, %78 ], [ %69, %68 ], [ null, %29 ], [ null, %23 ], [ null, %83 ]
  ret i64* %86
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN2v88internal19TransitionsAccessor19NumberOfTransitionsEv(%"class.v8::internal::TransitionsAccessor"* nocapture readonly) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %3 = load i32, i32* %2, align 8
  switch i32 %3, label %17 [
    i32 0, label %18
    i32 1, label %18
    i32 2, label %18
    i32 3, label %4
    i32 4, label %5
  ]

4:                                                ; preds = %1
  br label %18

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, 3
  %9 = inttoptr i64 %8 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = icmp slt i32 %10, 4
  br i1 %11, label %18, label %12

12:                                               ; preds = %5
  %13 = add i64 %7, 11
  %14 = inttoptr i64 %13 to i32*
  %15 = load atomic i32, i32* %14 monotonic, align 4
  %16 = ashr i32 %15, 1
  br label %18

17:                                               ; preds = %1
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

18:                                               ; preds = %12, %5, %1, %1, %1, %4
  %19 = phi i32 [ 1, %4 ], [ 0, %1 ], [ 0, %1 ], [ 0, %1 ], [ %16, %12 ], [ 0, %5 ]
  ret i32 %19
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19TransitionsAccessor18SetMigrationTargetENS0_3MapE(%"class.v8::internal::TransitionsAccessor"* nocapture readonly, i64) local_unnamed_addr #0 align 2 {
  %3 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %4 = load i32, i32* %3, align 8
  %5 = icmp eq i32 %4, 1
  br i1 %5, label %6, label %50

6:                                                ; preds = %2
  %7 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %8 = load i64, i64* %7, align 8
  %9 = add i64 %8, 35
  %10 = inttoptr i64 %9 to i32*
  %11 = trunc i64 %1 to i32
  store atomic volatile i32 %11, i32* %10 release, align 4
  %12 = load i64, i64* %7, align 8
  %13 = add i64 %12, 35
  %14 = and i64 %1, 1
  %15 = icmp ne i64 %14, 0
  %16 = icmp ne i32 %11, 3
  %17 = and i1 %16, %15
  br i1 %17, label %18, label %50

18:                                               ; preds = %6
  %19 = and i64 %12, -262144
  %20 = or i64 %19, 8
  %21 = inttoptr i64 %20 to i64*
  %22 = load i64, i64* %21, align 8
  %23 = and i64 %22, 262144
  %24 = icmp eq i64 %23, 0
  br i1 %24, label %32, label %25

25:                                               ; preds = %18
  %26 = and i64 %1, -3
  %27 = or i64 %19, 16
  %28 = inttoptr i64 %27 to %"class.v8::internal::Heap"**
  %29 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %28, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %29, i64 %12, i64 %13, i64 %26) #6
  %30 = load i64, i64* %7, align 8
  %31 = add i64 %30, 35
  br label %32

32:                                               ; preds = %25, %18
  %33 = phi i64 [ %13, %18 ], [ %31, %25 ]
  %34 = phi i64 [ %12, %18 ], [ %30, %25 ]
  %35 = and i64 %1, -3
  %36 = and i64 %1, -262144
  %37 = or i64 %36, 8
  %38 = inttoptr i64 %37 to i64*
  %39 = load i64, i64* %38, align 8
  %40 = and i64 %39, 24
  %41 = icmp eq i64 %40, 0
  br i1 %41, label %50, label %42

42:                                               ; preds = %32
  %43 = and i64 %34, -262144
  %44 = or i64 %43, 8
  %45 = inttoptr i64 %44 to i64*
  %46 = load i64, i64* %45, align 8
  %47 = and i64 %46, 24
  %48 = icmp eq i64 %47, 0
  br i1 %48, label %49, label %50

49:                                               ; preds = %42
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %34, i64 %33, i64 %35) #6
  br label %50

50:                                               ; preds = %6, %49, %42, %32, %2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal19TransitionsAccessor18GetMigrationTargetEv(%"class.v8::internal::TransitionsAccessor"* nocapture readonly) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %3 = load i32, i32* %2, align 8
  %4 = icmp eq i32 %3, 2
  br i1 %4, label %5, label %14

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = and i64 %7, -4294967296
  %9 = add i64 %7, 35
  %10 = inttoptr i64 %9 to i32*
  %11 = load atomic i32, i32* %10 acquire, align 4
  %12 = zext i32 %11 to i64
  %13 = or i64 %8, %12
  br label %14

14:                                               ; preds = %1, %5
  %15 = phi i64 [ %13, %5 ], [ 0, %1 ]
  ret i64 %15
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19TransitionsAccessor28EnsureHasFullTransitionArrayEv(%"class.v8::internal::TransitionsAccessor"*) local_unnamed_addr #0 align 2 {
  %2 = alloca %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", align 8
  %3 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %4 = load i32, i32* %3, align 8
  switch i32 %4, label %5 [
    i32 4, label %202
    i32 1, label %8
  ]

5:                                                ; preds = %1
  %6 = icmp ne i32 %4, 2
  %7 = zext i1 %6 to i32
  br label %8

8:                                                ; preds = %1, %5
  %9 = phi i32 [ %7, %5 ], [ 0, %1 ]
  %10 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %11 = bitcast %"class.v8::internal::TransitionsAccessor"* %0 to %"class.v8::internal::Factory"**
  %12 = load %"class.v8::internal::Factory"*, %"class.v8::internal::Factory"** %11, align 8
  %13 = tail call i64* @_ZN2v88internal7Factory18NewTransitionArrayEii(%"class.v8::internal::Factory"* %12, i32 %9, i32 0) #6
  %14 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 1, i32 0, i32 0
  %15 = load i64*, i64** %14, align 8
  %16 = load i64, i64* %15, align 8
  %17 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  store i64 %16, i64* %17, align 8
  %18 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %10, align 8
  %19 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %18, i64 0, i32 0, i32 4
  %20 = load i64, i64* %19, align 8
  %21 = add i64 %16, 35
  %22 = inttoptr i64 %21 to i32*
  %23 = load atomic i32, i32* %22 acquire, align 4
  %24 = and i64 %20, 4294967295
  %25 = icmp eq i64 %24, 0
  tail call void @llvm.assume(i1 %25) #6
  %26 = zext i32 %23 to i64
  %27 = or i64 %20, %26
  %28 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  store i64 %27, i64* %28, align 8
  %29 = and i64 %26, 1
  %30 = icmp eq i64 %29, 0
  %31 = icmp eq i32 %23, 3
  %32 = or i1 %31, %30
  br i1 %32, label %55, label %33

33:                                               ; preds = %8
  %34 = and i64 %26, 3
  switch i64 %34, label %54 [
    i64 3, label %55
    i64 1, label %35
  ]

35:                                               ; preds = %33
  %36 = add i64 %27, -1
  %37 = inttoptr i64 %36 to i32*
  %38 = load atomic i32, i32* %37 monotonic, align 4
  %39 = zext i32 %38 to i64
  %40 = or i64 %20, %39
  %41 = add i64 %40, 7
  %42 = inttoptr i64 %41 to i16*
  %43 = load atomic i16, i16* %42 monotonic, align 2
  %44 = icmp eq i16 %43, 160
  br i1 %44, label %55, label %45

45:                                               ; preds = %35
  %46 = load atomic i32, i32* %37 monotonic, align 4
  %47 = zext i32 %46 to i64
  %48 = or i64 %20, %47
  %49 = add i64 %48, 7
  %50 = inttoptr i64 %49 to i16*
  %51 = load atomic i16, i16* %50 monotonic, align 2
  %52 = icmp eq i16 %51, 110
  %53 = select i1 %52, i32 0, i32 2
  br label %55

54:                                               ; preds = %33
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

55:                                               ; preds = %45, %35, %33, %8
  %56 = phi i32 [ 1, %8 ], [ 3, %33 ], [ 4, %35 ], [ %53, %45 ]
  store i32 %56, i32* %3, align 8
  %57 = icmp eq i32 %9, 1
  br i1 %57, label %58, label %118

58:                                               ; preds = %55
  switch i32 %56, label %65 [
    i32 1, label %59
    i32 3, label %63
  ]

59:                                               ; preds = %58
  %60 = load i64, i64* %13, align 8
  %61 = add i64 %60, 11
  %62 = inttoptr i64 %61 to i32*
  store atomic volatile i32 0, i32* %62 monotonic, align 4
  br label %118

63:                                               ; preds = %58
  %64 = and i64 %27, -3
  br label %65

65:                                               ; preds = %58, %63
  %66 = phi i64 [ %64, %63 ], [ 0, %58 ]
  %67 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %10, align 8
  %68 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %67, i64 0, i32 31, i32 4
  %69 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %68, align 8
  %70 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %69, null
  br i1 %70, label %74, label %71

71:                                               ; preds = %65
  %72 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %69, i64 %66) #6
  %73 = load i64, i64* %72, align 8
  br label %87

74:                                               ; preds = %65
  %75 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %67, i64 0, i32 31, i32 0
  %76 = load i64*, i64** %75, align 8
  %77 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %67, i64 0, i32 31, i32 1
  %78 = load i64*, i64** %77, align 8
  %79 = icmp eq i64* %76, %78
  br i1 %79, label %80, label %82

80:                                               ; preds = %74
  %81 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %67) #6
  br label %82

82:                                               ; preds = %80, %74
  %83 = phi i64* [ %81, %80 ], [ %76, %74 ]
  %84 = ptrtoint i64* %83 to i64
  %85 = add i64 %84, 8
  %86 = inttoptr i64 %85 to i64*
  store i64* %86, i64** %75, align 8
  store i64 %66, i64* %83, align 8
  br label %87

87:                                               ; preds = %71, %82
  %88 = phi i64 [ %73, %71 ], [ %66, %82 ]
  %89 = phi i64* [ %72, %71 ], [ %83, %82 ]
  %90 = add i64 %88, 11
  %91 = inttoptr i64 %90 to i32*
  %92 = load atomic i32, i32* %91 acquire, align 4
  %93 = lshr i32 %92, 10
  %94 = and i32 %93, 1023
  %95 = add nsw i32 %94, -1
  %96 = sext i32 %95 to i64
  %97 = and i64 %88, -4294967296
  %98 = add i64 %88, 23
  %99 = inttoptr i64 %98 to i32*
  %100 = load i32, i32* %99, align 4
  %101 = zext i32 %100 to i64
  %102 = or i64 %97, %101
  %103 = mul nsw i64 %96, 51539607552
  %104 = add nsw i64 %103, 68719476736
  %105 = ashr exact i64 %104, 32
  %106 = add i64 %102, -1
  %107 = add i64 %106, %105
  %108 = inttoptr i64 %107 to i32*
  %109 = load atomic i32, i32* %108 monotonic, align 4
  %110 = zext i32 %109 to i64
  %111 = or i64 %97, %110
  %112 = bitcast %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %112) #6
  %113 = load i64, i64* %13, align 8
  %114 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %113, i64* %114, align 8
  %115 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef", %"class.v8::internal::Handle<v8::internal::TransitionArray>::ObjectRef"* %2, i64 0, i32 0
  %116 = load i64, i64* %89, align 8
  %117 = or i64 %116, 2
  call void @_ZN2v88internal15TransitionArray3SetEiNS0_4NameENS0_11MaybeObjectE(%"class.v8::internal::TransitionArray"* nonnull %115, i32 0, i64 %111, i64 %117)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %112) #6
  br label %118

118:                                              ; preds = %59, %87, %55
  %119 = load i64, i64* %13, align 8
  %120 = load i64, i64* %17, align 8
  %121 = add i64 %120, 35
  %122 = inttoptr i64 %121 to i32*
  %123 = trunc i64 %119 to i32
  store atomic volatile i32 %123, i32* %122 release, align 4
  %124 = load i64, i64* %17, align 8
  %125 = add i64 %124, 35
  %126 = and i64 %119, 1
  %127 = icmp ne i64 %126, 0
  %128 = icmp ne i32 %123, 3
  %129 = and i1 %128, %127
  br i1 %129, label %130, label %161

130:                                              ; preds = %118
  %131 = and i64 %124, -262144
  %132 = or i64 %131, 8
  %133 = inttoptr i64 %132 to i64*
  %134 = load i64, i64* %133, align 8
  %135 = and i64 %134, 262144
  %136 = icmp eq i64 %135, 0
  %137 = and i64 %119, -3
  br i1 %136, label %144, label %138

138:                                              ; preds = %130
  %139 = or i64 %131, 16
  %140 = inttoptr i64 %139 to %"class.v8::internal::Heap"**
  %141 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %140, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %141, i64 %124, i64 %125, i64 %137) #6
  %142 = load i64, i64* %17, align 8
  %143 = add i64 %142, 35
  br label %144

144:                                              ; preds = %130, %138
  %145 = phi i64 [ %143, %138 ], [ %125, %130 ]
  %146 = phi i64 [ %142, %138 ], [ %124, %130 ]
  %147 = and i64 %119, -262144
  %148 = or i64 %147, 8
  %149 = inttoptr i64 %148 to i64*
  %150 = load i64, i64* %149, align 8
  %151 = and i64 %150, 24
  %152 = icmp eq i64 %151, 0
  br i1 %152, label %161, label %153

153:                                              ; preds = %144
  %154 = and i64 %146, -262144
  %155 = or i64 %154, 8
  %156 = inttoptr i64 %155 to i64*
  %157 = load i64, i64* %156, align 8
  %158 = and i64 %157, 24
  %159 = icmp eq i64 %158, 0
  br i1 %159, label %160, label %161

160:                                              ; preds = %153
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %146, i64 %145, i64 %137) #6
  br label %161

161:                                              ; preds = %118, %144, %153, %160
  %162 = load i64*, i64** %14, align 8
  %163 = load i64, i64* %162, align 8
  store i64 %163, i64* %17, align 8
  %164 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %10, align 8
  %165 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %164, i64 0, i32 0, i32 4
  %166 = load i64, i64* %165, align 8
  %167 = add i64 %163, 35
  %168 = inttoptr i64 %167 to i32*
  %169 = load atomic i32, i32* %168 acquire, align 4
  %170 = and i64 %166, 4294967295
  %171 = icmp eq i64 %170, 0
  call void @llvm.assume(i1 %171) #6
  %172 = zext i32 %169 to i64
  %173 = or i64 %166, %172
  store i64 %173, i64* %28, align 8
  %174 = and i64 %172, 1
  %175 = icmp eq i64 %174, 0
  %176 = icmp eq i32 %169, 3
  %177 = or i1 %176, %175
  br i1 %177, label %200, label %178

178:                                              ; preds = %161
  %179 = and i64 %172, 3
  switch i64 %179, label %199 [
    i64 3, label %200
    i64 1, label %180
  ]

180:                                              ; preds = %178
  %181 = add i64 %173, -1
  %182 = inttoptr i64 %181 to i32*
  %183 = load atomic i32, i32* %182 monotonic, align 4
  %184 = zext i32 %183 to i64
  %185 = or i64 %166, %184
  %186 = add i64 %185, 7
  %187 = inttoptr i64 %186 to i16*
  %188 = load atomic i16, i16* %187 monotonic, align 2
  %189 = icmp eq i16 %188, 160
  br i1 %189, label %200, label %190

190:                                              ; preds = %180
  %191 = load atomic i32, i32* %182 monotonic, align 4
  %192 = zext i32 %191 to i64
  %193 = or i64 %166, %192
  %194 = add i64 %193, 7
  %195 = inttoptr i64 %194 to i16*
  %196 = load atomic i16, i16* %195 monotonic, align 2
  %197 = icmp eq i16 %196, 110
  %198 = select i1 %197, i32 0, i32 2
  br label %200

199:                                              ; preds = %178
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

200:                                              ; preds = %190, %180, %178, %161
  %201 = phi i32 [ 1, %161 ], [ 3, %178 ], [ 4, %180 ], [ %198, %190 ]
  store i32 %201, i32* %3, align 8
  br label %202

202:                                              ; preds = %200, %1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal19TransitionsAccessor30TraverseTransitionTreeInternalENSt3__18functionIFvNS0_3MapEEEEPNS0_22CombinationAssertScopeIJNS0_29PerThreadAssertScopeDebugOnlyILNS0_19PerThreadAssertTypeE0ELb0EEENS8_ILS9_1ELb0EEEEEE(%"class.v8::internal::TransitionsAccessor"* nocapture readonly, %"class.std::__1::function"*, %"class.v8::internal::CombinationAssertScope"* readnone) local_unnamed_addr #0 align 2 {
  %4 = alloca %"class.v8::internal::Map", align 8
  %5 = alloca %"class.v8::internal::TransitionsAccessor", align 8
  %6 = alloca %"class.std::__1::function", align 8
  %7 = alloca %"class.v8::internal::TransitionsAccessor", align 8
  %8 = alloca %"class.std::__1::function", align 8
  %9 = alloca %"class.v8::internal::TransitionsAccessor", align 8
  %10 = alloca %"class.std::__1::function", align 8
  %11 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 4
  %12 = load i32, i32* %11, align 8
  switch i32 %12, label %315 [
    i32 4, label %96
    i32 3, label %13
  ]

13:                                               ; preds = %3
  %14 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %15 = load i64, i64* %14, align 8
  %16 = and i64 %15, -3
  %17 = bitcast %"class.v8::internal::TransitionsAccessor"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %17) #6
  %18 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %19 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %18, align 8
  %20 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %5, i64 0, i32 0
  store %"class.v8::internal::Isolate"* %19, %"class.v8::internal::Isolate"** %20, align 8
  %21 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %5, i64 0, i32 1, i32 0, i32 0
  store i64* null, i64** %21, align 8
  %22 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %5, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  store i64 %16, i64* %22, align 8
  %23 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %5, i64 0, i32 3, i32 0, i32 0
  store i64 0, i64* %23, align 8
  %24 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %5, i64 0, i32 5
  store i8 0, i8* %24, align 4
  %25 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %19, i64 0, i32 0, i32 4
  %26 = load i64, i64* %25, align 8
  %27 = add i64 %16, 35
  %28 = inttoptr i64 %27 to i32*
  %29 = load atomic i32, i32* %28 acquire, align 4
  %30 = and i64 %26, 4294967295
  %31 = icmp eq i64 %30, 0
  tail call void @llvm.assume(i1 %31) #6
  %32 = zext i32 %29 to i64
  %33 = or i64 %26, %32
  store i64 %33, i64* %23, align 8
  %34 = and i64 %32, 1
  %35 = icmp eq i64 %34, 0
  %36 = icmp eq i32 %29, 3
  %37 = or i1 %36, %35
  br i1 %37, label %38, label %40

38:                                               ; preds = %13
  %39 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %5, i64 0, i32 4
  store i32 1, i32* %39, align 8
  br label %68

40:                                               ; preds = %13
  %41 = and i64 %32, 3
  switch i64 %41, label %67 [
    i64 3, label %42
    i64 1, label %44
  ]

42:                                               ; preds = %40
  %43 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %5, i64 0, i32 4
  store i32 3, i32* %43, align 8
  br label %68

44:                                               ; preds = %40
  %45 = add i64 %33, -1
  %46 = inttoptr i64 %45 to i32*
  %47 = load atomic i32, i32* %46 monotonic, align 4
  %48 = zext i32 %47 to i64
  %49 = or i64 %26, %48
  %50 = add i64 %49, 7
  %51 = inttoptr i64 %50 to i16*
  %52 = load atomic i16, i16* %51 monotonic, align 2
  %53 = icmp eq i16 %52, 160
  br i1 %53, label %54, label %56

54:                                               ; preds = %44
  %55 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %5, i64 0, i32 4
  store i32 4, i32* %55, align 8
  br label %68

56:                                               ; preds = %44
  %57 = load atomic i32, i32* %46 monotonic, align 4
  %58 = zext i32 %57 to i64
  %59 = or i64 %26, %58
  %60 = add i64 %59, 7
  %61 = inttoptr i64 %60 to i16*
  %62 = load atomic i16, i16* %61 monotonic, align 2
  %63 = icmp eq i16 %62, 110
  %64 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %5, i64 0, i32 4
  br i1 %63, label %65, label %66

65:                                               ; preds = %56
  store i32 0, i32* %64, align 8
  br label %68

66:                                               ; preds = %56
  store i32 2, i32* %64, align 8
  br label %68

67:                                               ; preds = %40
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

68:                                               ; preds = %38, %42, %54, %65, %66
  %69 = bitcast %"class.std::__1::function"* %6 to i8*
  %70 = bitcast %"class.std::__1::function"* %1 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %69, i8* align 8 %70, i64 16, i1 false) #6
  %71 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %6, i64 0, i32 0, i32 1
  %72 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %1, i64 0, i32 0, i32 1
  %73 = bitcast %"struct.std::__1::__function::__policy_invoker"* %72 to i64*
  %74 = bitcast %"struct.std::__1::__function::__policy_invoker"* %71 to i64*
  %75 = load i64, i64* %73, align 8
  store i64 %75, i64* %74, align 8
  %76 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %6, i64 0, i32 0, i32 2
  %77 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %1, i64 0, i32 0, i32 2
  %78 = load %"struct.std::__1::__function::__policy"*, %"struct.std::__1::__function::__policy"** %77, align 8
  store %"struct.std::__1::__function::__policy"* %78, %"struct.std::__1::__function::__policy"** %76, align 8
  %79 = getelementptr inbounds %"struct.std::__1::__function::__policy", %"struct.std::__1::__function::__policy"* %78, i64 0, i32 0
  %80 = load i8* (i8*)*, i8* (i8*)** %79, align 8
  %81 = icmp eq i8* (i8*)* %80, null
  br i1 %81, label %87, label %82

82:                                               ; preds = %68
  %83 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %1, i64 0, i32 0, i32 0, i32 0
  %84 = load i8*, i8** %83, align 8
  %85 = tail call i8* %80(i8* %84) #6
  %86 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %6, i64 0, i32 0, i32 0, i32 0
  store i8* %85, i8** %86, align 8
  br label %87

87:                                               ; preds = %68, %82
  call void @_ZN2v88internal19TransitionsAccessor30TraverseTransitionTreeInternalENSt3__18functionIFvNS0_3MapEEEEPNS0_22CombinationAssertScopeIJNS0_29PerThreadAssertScopeDebugOnlyILNS0_19PerThreadAssertTypeE0ELb0EEENS8_ILS9_1ELb0EEEEEE(%"class.v8::internal::TransitionsAccessor"* nonnull %5, %"class.std::__1::function"* nonnull %6, %"class.v8::internal::CombinationAssertScope"* %2)
  %88 = load %"struct.std::__1::__function::__policy"*, %"struct.std::__1::__function::__policy"** %76, align 8
  %89 = getelementptr inbounds %"struct.std::__1::__function::__policy", %"struct.std::__1::__function::__policy"* %88, i64 0, i32 1
  %90 = load void (i8*)*, void (i8*)** %89, align 8
  %91 = icmp eq void (i8*)* %90, null
  br i1 %91, label %95, label %92

92:                                               ; preds = %87
  %93 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %6, i64 0, i32 0, i32 0, i32 0
  %94 = load i8*, i8** %93, align 8
  call void %90(i8* %94) #6
  br label %95

95:                                               ; preds = %87, %92
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %17) #6
  br label %315

96:                                               ; preds = %3
  %97 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 3, i32 0, i32 0
  %98 = load i64, i64* %97, align 8
  %99 = add i64 %98, 7
  %100 = inttoptr i64 %99 to i32*
  %101 = load atomic i32, i32* %100 monotonic, align 4
  %102 = icmp eq i32 %101, 0
  br i1 %102, label %212, label %103

103:                                              ; preds = %96
  %104 = and i64 %98, -4294967296
  %105 = load atomic i32, i32* %100 monotonic, align 4
  %106 = zext i32 %105 to i64
  %107 = or i64 %104, %106
  %108 = add i64 %107, 3
  %109 = inttoptr i64 %108 to i32*
  %110 = load i32, i32* %109, align 4
  %111 = icmp ult i32 %110, 2
  br i1 %111, label %212, label %112

112:                                              ; preds = %103
  %113 = add i64 %107, 7
  %114 = inttoptr i64 %113 to i32*
  %115 = load atomic i32, i32* %114 monotonic, align 4
  %116 = icmp sgt i32 %115, 1
  br i1 %116, label %117, label %212

117:                                              ; preds = %112
  %118 = ashr i32 %115, 1
  %119 = add i64 %107, 7
  %120 = bitcast %"class.v8::internal::TransitionsAccessor"* %7 to i8*
  %121 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %122 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %7, i64 0, i32 0
  %123 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %7, i64 0, i32 1, i32 0, i32 0
  %124 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %7, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %125 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %7, i64 0, i32 3, i32 0, i32 0
  %126 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %7, i64 0, i32 5
  %127 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %7, i64 0, i32 4
  %128 = bitcast %"class.std::__1::function"* %8 to i8*
  %129 = bitcast %"class.std::__1::function"* %1 to i8*
  %130 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %8, i64 0, i32 0, i32 1
  %131 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %1, i64 0, i32 0, i32 1
  %132 = bitcast %"struct.std::__1::__function::__policy_invoker"* %131 to i64*
  %133 = bitcast %"struct.std::__1::__function::__policy_invoker"* %130 to i64*
  %134 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %8, i64 0, i32 0, i32 2
  %135 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %1, i64 0, i32 0, i32 2
  %136 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %1, i64 0, i32 0, i32 0, i32 0
  %137 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %8, i64 0, i32 0, i32 0, i32 0
  %138 = zext i32 %118 to i64
  br label %139

139:                                              ; preds = %210, %117
  %140 = phi i64 [ 0, %117 ], [ %141, %210 ]
  %141 = add nuw nsw i64 %140, 1
  %142 = trunc i64 %141 to i32
  %143 = shl i32 %142, 2
  %144 = sext i32 %143 to i64
  %145 = add i64 %119, %144
  %146 = inttoptr i64 %145 to i32*
  %147 = load atomic i32, i32* %146 monotonic, align 4
  %148 = zext i32 %147 to i64
  %149 = and i64 %148, 3
  %150 = icmp eq i64 %149, 3
  %151 = icmp ne i32 %147, 3
  %152 = and i1 %151, %150
  br i1 %152, label %153, label %210

153:                                              ; preds = %139
  %154 = and i64 %148, 4294967293
  %155 = or i64 %154, %104
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %120) #6
  %156 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %121, align 8
  store %"class.v8::internal::Isolate"* %156, %"class.v8::internal::Isolate"** %122, align 8
  store i64* null, i64** %123, align 8
  store i64 %155, i64* %124, align 8
  store i64 0, i64* %125, align 8
  store i8 0, i8* %126, align 4
  %157 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %156, i64 0, i32 0, i32 4
  %158 = load i64, i64* %157, align 8
  %159 = add i64 %155, 35
  %160 = inttoptr i64 %159 to i32*
  %161 = load atomic i32, i32* %160 acquire, align 4
  %162 = and i64 %158, 4294967295
  %163 = icmp eq i64 %162, 0
  call void @llvm.assume(i1 %163) #6
  %164 = zext i32 %161 to i64
  %165 = or i64 %158, %164
  store i64 %165, i64* %125, align 8
  %166 = and i64 %164, 1
  %167 = icmp eq i64 %166, 0
  %168 = icmp eq i32 %161, 3
  %169 = or i1 %168, %167
  br i1 %169, label %192, label %170

170:                                              ; preds = %153
  %171 = and i64 %164, 3
  switch i64 %171, label %191 [
    i64 3, label %192
    i64 1, label %172
  ]

172:                                              ; preds = %170
  %173 = add i64 %165, -1
  %174 = inttoptr i64 %173 to i32*
  %175 = load atomic i32, i32* %174 monotonic, align 4
  %176 = zext i32 %175 to i64
  %177 = or i64 %158, %176
  %178 = add i64 %177, 7
  %179 = inttoptr i64 %178 to i16*
  %180 = load atomic i16, i16* %179 monotonic, align 2
  %181 = icmp eq i16 %180, 160
  br i1 %181, label %192, label %182

182:                                              ; preds = %172
  %183 = load atomic i32, i32* %174 monotonic, align 4
  %184 = zext i32 %183 to i64
  %185 = or i64 %158, %184
  %186 = add i64 %185, 7
  %187 = inttoptr i64 %186 to i16*
  %188 = load atomic i16, i16* %187 monotonic, align 2
  %189 = icmp eq i16 %188, 110
  %190 = select i1 %189, i32 0, i32 2
  br label %192

191:                                              ; preds = %170
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

192:                                              ; preds = %182, %172, %170, %153
  %193 = phi i32 [ 1, %153 ], [ 3, %170 ], [ 4, %172 ], [ %190, %182 ]
  store i32 %193, i32* %127, align 8
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %128, i8* align 8 %129, i64 16, i1 false) #6
  %194 = load i64, i64* %132, align 8
  store i64 %194, i64* %133, align 8
  %195 = load %"struct.std::__1::__function::__policy"*, %"struct.std::__1::__function::__policy"** %135, align 8
  store %"struct.std::__1::__function::__policy"* %195, %"struct.std::__1::__function::__policy"** %134, align 8
  %196 = getelementptr inbounds %"struct.std::__1::__function::__policy", %"struct.std::__1::__function::__policy"* %195, i64 0, i32 0
  %197 = load i8* (i8*)*, i8* (i8*)** %196, align 8
  %198 = icmp eq i8* (i8*)* %197, null
  br i1 %198, label %202, label %199

199:                                              ; preds = %192
  %200 = load i8*, i8** %136, align 8
  %201 = call i8* %197(i8* %200) #6
  store i8* %201, i8** %137, align 8
  br label %202

202:                                              ; preds = %192, %199
  call void @_ZN2v88internal19TransitionsAccessor30TraverseTransitionTreeInternalENSt3__18functionIFvNS0_3MapEEEEPNS0_22CombinationAssertScopeIJNS0_29PerThreadAssertScopeDebugOnlyILNS0_19PerThreadAssertTypeE0ELb0EEENS8_ILS9_1ELb0EEEEEE(%"class.v8::internal::TransitionsAccessor"* nonnull %7, %"class.std::__1::function"* nonnull %8, %"class.v8::internal::CombinationAssertScope"* %2)
  %203 = load %"struct.std::__1::__function::__policy"*, %"struct.std::__1::__function::__policy"** %134, align 8
  %204 = getelementptr inbounds %"struct.std::__1::__function::__policy", %"struct.std::__1::__function::__policy"* %203, i64 0, i32 1
  %205 = load void (i8*)*, void (i8*)** %204, align 8
  %206 = icmp eq void (i8*)* %205, null
  br i1 %206, label %209, label %207

207:                                              ; preds = %202
  %208 = load i8*, i8** %137, align 8
  call void %205(i8* %208) #6
  br label %209

209:                                              ; preds = %202, %207
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %120) #6
  br label %210

210:                                              ; preds = %139, %209
  %211 = icmp eq i64 %141, %138
  br i1 %211, label %212, label %139

212:                                              ; preds = %210, %103, %112, %96
  %213 = bitcast %"class.v8::internal::TransitionsAccessor"* %9 to i8*
  %214 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %215 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %9, i64 0, i32 0
  %216 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %9, i64 0, i32 1, i32 0, i32 0
  %217 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %9, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %218 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %9, i64 0, i32 3, i32 0, i32 0
  %219 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %9, i64 0, i32 5
  %220 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %9, i64 0, i32 4
  %221 = bitcast %"class.std::__1::function"* %10 to i8*
  %222 = bitcast %"class.std::__1::function"* %1 to i8*
  %223 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %10, i64 0, i32 0, i32 1
  %224 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %1, i64 0, i32 0, i32 1
  %225 = bitcast %"struct.std::__1::__function::__policy_invoker"* %224 to i64*
  %226 = bitcast %"struct.std::__1::__function::__policy_invoker"* %223 to i64*
  %227 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %10, i64 0, i32 0, i32 2
  %228 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %1, i64 0, i32 0, i32 2
  %229 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %1, i64 0, i32 0, i32 0, i32 0
  %230 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %10, i64 0, i32 0, i32 0, i32 0
  br label %231

231:                                              ; preds = %313, %212
  %232 = phi i64 [ %314, %313 ], [ 0, %212 ]
  %233 = load i64, i64* %97, align 8
  %234 = add i64 %233, 3
  %235 = inttoptr i64 %234 to i32*
  %236 = load i32, i32* %235, align 4
  %237 = icmp slt i32 %236, 4
  br i1 %237, label %243, label %238

238:                                              ; preds = %231
  %239 = add i64 %233, 11
  %240 = inttoptr i64 %239 to i32*
  %241 = load atomic i32, i32* %240 monotonic, align 4
  %242 = ashr i32 %241, 1
  br label %243

243:                                              ; preds = %231, %238
  %244 = phi i32 [ %242, %238 ], [ 0, %231 ]
  %245 = sext i32 %244 to i64
  %246 = icmp slt i64 %232, %245
  br i1 %246, label %247, label %315

247:                                              ; preds = %243
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %213) #6
  %248 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %214, align 8
  %249 = trunc i64 %232 to i32
  %250 = shl i32 %249, 3
  %251 = and i64 %233, -4294967296
  %252 = add i32 %250, 12
  %253 = sext i32 %252 to i64
  %254 = add i64 %233, 7
  %255 = add i64 %254, %253
  %256 = inttoptr i64 %255 to i32*
  %257 = load atomic i32, i32* %256 monotonic, align 4
  %258 = and i32 %257, -3
  %259 = zext i32 %258 to i64
  %260 = or i64 %251, %259
  store %"class.v8::internal::Isolate"* %248, %"class.v8::internal::Isolate"** %215, align 8
  store i64* null, i64** %216, align 8
  store i64 %260, i64* %217, align 8
  store i64 0, i64* %218, align 8
  store i8 0, i8* %219, align 4
  %261 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %248, i64 0, i32 0, i32 4
  %262 = load i64, i64* %261, align 8
  %263 = add i64 %260, 35
  %264 = inttoptr i64 %263 to i32*
  %265 = load atomic i32, i32* %264 acquire, align 4
  %266 = and i64 %262, 4294967295
  %267 = icmp eq i64 %266, 0
  call void @llvm.assume(i1 %267) #6
  %268 = zext i32 %265 to i64
  %269 = or i64 %262, %268
  store i64 %269, i64* %218, align 8
  %270 = and i64 %268, 1
  %271 = icmp eq i64 %270, 0
  %272 = icmp eq i32 %265, 3
  %273 = or i1 %272, %271
  br i1 %273, label %296, label %274

274:                                              ; preds = %247
  %275 = and i64 %268, 3
  switch i64 %275, label %295 [
    i64 3, label %296
    i64 1, label %276
  ]

276:                                              ; preds = %274
  %277 = add i64 %269, -1
  %278 = inttoptr i64 %277 to i32*
  %279 = load atomic i32, i32* %278 monotonic, align 4
  %280 = zext i32 %279 to i64
  %281 = or i64 %262, %280
  %282 = add i64 %281, 7
  %283 = inttoptr i64 %282 to i16*
  %284 = load atomic i16, i16* %283 monotonic, align 2
  %285 = icmp eq i16 %284, 160
  br i1 %285, label %296, label %286

286:                                              ; preds = %276
  %287 = load atomic i32, i32* %278 monotonic, align 4
  %288 = zext i32 %287 to i64
  %289 = or i64 %262, %288
  %290 = add i64 %289, 7
  %291 = inttoptr i64 %290 to i16*
  %292 = load atomic i16, i16* %291 monotonic, align 2
  %293 = icmp eq i16 %292, 110
  %294 = select i1 %293, i32 0, i32 2
  br label %296

295:                                              ; preds = %274
  call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str, i64 0, i64 0)) #7
  unreachable

296:                                              ; preds = %286, %276, %274, %247
  %297 = phi i32 [ 1, %247 ], [ 3, %274 ], [ 4, %276 ], [ %294, %286 ]
  store i32 %297, i32* %220, align 8
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %221, i8* align 8 %222, i64 16, i1 false) #6
  %298 = load i64, i64* %225, align 8
  store i64 %298, i64* %226, align 8
  %299 = load %"struct.std::__1::__function::__policy"*, %"struct.std::__1::__function::__policy"** %228, align 8
  store %"struct.std::__1::__function::__policy"* %299, %"struct.std::__1::__function::__policy"** %227, align 8
  %300 = getelementptr inbounds %"struct.std::__1::__function::__policy", %"struct.std::__1::__function::__policy"* %299, i64 0, i32 0
  %301 = load i8* (i8*)*, i8* (i8*)** %300, align 8
  %302 = icmp eq i8* (i8*)* %301, null
  br i1 %302, label %306, label %303

303:                                              ; preds = %296
  %304 = load i8*, i8** %229, align 8
  %305 = call i8* %301(i8* %304) #6
  store i8* %305, i8** %230, align 8
  br label %306

306:                                              ; preds = %296, %303
  call void @_ZN2v88internal19TransitionsAccessor30TraverseTransitionTreeInternalENSt3__18functionIFvNS0_3MapEEEEPNS0_22CombinationAssertScopeIJNS0_29PerThreadAssertScopeDebugOnlyILNS0_19PerThreadAssertTypeE0ELb0EEENS8_ILS9_1ELb0EEEEEE(%"class.v8::internal::TransitionsAccessor"* nonnull %9, %"class.std::__1::function"* nonnull %10, %"class.v8::internal::CombinationAssertScope"* %2)
  %307 = load %"struct.std::__1::__function::__policy"*, %"struct.std::__1::__function::__policy"** %227, align 8
  %308 = getelementptr inbounds %"struct.std::__1::__function::__policy", %"struct.std::__1::__function::__policy"* %307, i64 0, i32 1
  %309 = load void (i8*)*, void (i8*)** %308, align 8
  %310 = icmp eq void (i8*)* %309, null
  br i1 %310, label %313, label %311

311:                                              ; preds = %306
  %312 = load i8*, i8** %230, align 8
  call void %309(i8* %312) #6
  br label %313

313:                                              ; preds = %306, %311
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %213) #6
  %314 = add nuw nsw i64 %232, 1
  br label %231

315:                                              ; preds = %243, %3, %95
  %316 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
  %317 = load i64, i64* %316, align 8
  %318 = bitcast %"class.v8::internal::Map"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %318)
  %319 = getelementptr inbounds %"class.v8::internal::Map", %"class.v8::internal::Map"* %4, i64 0, i32 0, i32 0, i32 0, i32 0
  store i64 %317, i64* %319, align 8
  %320 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %1, i64 0, i32 0, i32 1, i32 0
  %321 = load void (%"union.std::__1::__function::__policy_storage"*, %"class.v8::internal::Map"*)*, void (%"union.std::__1::__function::__policy_storage"*, %"class.v8::internal::Map"*)** %320, align 8
  %322 = getelementptr inbounds %"class.std::__1::function", %"class.std::__1::function"* %1, i64 0, i32 0, i32 0
  call void %321(%"union.std::__1::__function::__policy_storage"* %322, %"class.v8::internal::Map"* nonnull dereferenceable(8) %4) #6
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %318)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN2v88internal15TransitionArray13SearchDetailsEiNS0_12PropertyKindENS0_18PropertyAttributesEPi(%"class.v8::internal::TransitionArray"* nocapture readonly, i32, i32, i32, i32*) local_unnamed_addr #0 align 2 {
  %6 = getelementptr inbounds %"class.v8::internal::TransitionArray", %"class.v8::internal::TransitionArray"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, 3
  %9 = inttoptr i64 %8 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = icmp slt i32 %10, 4
  br i1 %11, label %17, label %12

12:                                               ; preds = %5
  %13 = add i64 %7, 11
  %14 = inttoptr i64 %13 to i32*
  %15 = load atomic i32, i32* %14 monotonic, align 4
  %16 = ashr i32 %15, 1
  br label %17

17:                                               ; preds = %5, %12
  %18 = phi i32 [ %16, %12 ], [ 0, %5 ]
  %19 = shl i32 %1, 3
  %20 = add i32 %19, 8
  %21 = or i32 %20, 7
  %22 = sext i32 %21 to i64
  %23 = add i64 %7, %22
  %24 = inttoptr i64 %23 to i32*
  %25 = load atomic i32, i32* %24 monotonic, align 4
  %26 = icmp sgt i32 %18, %1
  br i1 %26, label %27, label %105

27:                                               ; preds = %17
  %28 = sext i32 %1 to i64
  %29 = shl i32 %1, 3
  %30 = add i32 %29, 8
  %31 = or i32 %30, 7
  %32 = sext i32 %31 to i64
  %33 = add i64 %7, %32
  %34 = inttoptr i64 %33 to i32*
  %35 = load atomic i32, i32* %34 monotonic, align 4
  %36 = icmp eq i32 %35, %25
  br i1 %36, label %37, label %102

37:                                               ; preds = %27, %87
  %38 = phi i64 [ %88, %87 ], [ %7, %27 ]
  %39 = phi i32 [ %90, %87 ], [ %29, %27 ]
  %40 = phi i32 [ %84, %87 ], [ %1, %27 ]
  %41 = phi i64 [ %83, %87 ], [ %28, %27 ]
  %42 = and i64 %38, -4294967296
  %43 = add i32 %39, 12
  %44 = sext i32 %43 to i64
  %45 = add nsw i64 %44, 7
  %46 = add i64 %45, %38
  %47 = inttoptr i64 %46 to i32*
  %48 = load atomic i32, i32* %47 monotonic, align 4
  %49 = and i32 %48, -3
  %50 = zext i32 %49 to i64
  %51 = or i64 %42, %50
  %52 = add i64 %51, 11
  %53 = inttoptr i64 %52 to i32*
  %54 = load atomic i32, i32* %53 acquire, align 4
  %55 = lshr i32 %54, 10
  %56 = and i32 %55, 1023
  %57 = add nsw i32 %56, -1
  %58 = sext i32 %57 to i64
  %59 = add i64 %51, 23
  %60 = inttoptr i64 %59 to i32*
  %61 = load atomic i32, i32* %60 monotonic, align 4
  %62 = zext i32 %61 to i64
  %63 = or i64 %42, %62
  %64 = mul nsw i64 %58, 51539607552
  %65 = add nsw i64 %64, 68719476736
  %66 = ashr exact i64 %65, 32
  %67 = or i64 %66, 3
  %68 = add i64 %67, %63
  %69 = inttoptr i64 %68 to i32*
  %70 = load atomic i32, i32* %69 monotonic, align 4
  %71 = ashr i32 %70, 1
  %72 = and i32 %71, 1
  %73 = lshr i32 %71, 3
  %74 = and i32 %73, 7
  %75 = icmp eq i32 %72, %2
  br i1 %75, label %78, label %76

76:                                               ; preds = %37
  %77 = icmp sgt i32 %72, %2
  br i1 %77, label %98, label %82

78:                                               ; preds = %37
  %79 = icmp eq i32 %74, %3
  br i1 %79, label %109, label %80

80:                                               ; preds = %78
  %81 = icmp sgt i32 %74, %3
  br i1 %81, label %100, label %82

82:                                               ; preds = %80, %76
  %83 = add nsw i64 %41, 1
  %84 = add nsw i32 %40, 1
  %85 = trunc i64 %83 to i32
  %86 = icmp eq i32 %18, %85
  br i1 %86, label %105, label %87

87:                                               ; preds = %82
  %88 = load i64, i64* %6, align 8
  %89 = trunc i64 %83 to i32
  %90 = shl i32 %89, 3
  %91 = add i32 %90, 8
  %92 = or i32 %91, 7
  %93 = sext i32 %92 to i64
  %94 = add i64 %88, %93
  %95 = inttoptr i64 %94 to i32*
  %96 = load atomic i32, i32* %95 monotonic, align 4
  %97 = icmp eq i32 %96, %25
  br i1 %97, label %37, label %102

98:                                               ; preds = %76
  %99 = trunc i64 %41 to i32
  br label %105

100:                                              ; preds = %80
  %101 = trunc i64 %41 to i32
  br label %105

102:                                              ; preds = %87, %27
  %103 = phi i64 [ %28, %27 ], [ %83, %87 ]
  %104 = trunc i64 %103 to i32
  br label %105

105:                                              ; preds = %82, %98, %100, %102, %17
  %106 = phi i32 [ %1, %17 ], [ %99, %98 ], [ %101, %100 ], [ %104, %102 ], [ %84, %82 ]
  %107 = icmp eq i32* %4, null
  br i1 %107, label %111, label %108

108:                                              ; preds = %105
  store i32 %106, i32* %4, align 4
  br label %111

109:                                              ; preds = %78
  %110 = trunc i64 %41 to i32
  br label %111

111:                                              ; preds = %109, %108, %105
  %112 = phi i32 [ -1, %105 ], [ -1, %108 ], [ %110, %109 ]
  ret i32 %112
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal15TransitionArray25SearchDetailsAndGetTargetEiNS0_12PropertyKindENS0_18PropertyAttributesE(%"class.v8::internal::TransitionArray"* nocapture readonly, i32, i32, i32) local_unnamed_addr #0 align 2 {
  %5 = getelementptr inbounds %"class.v8::internal::TransitionArray", %"class.v8::internal::TransitionArray"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 3
  %8 = inttoptr i64 %7 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = icmp slt i32 %9, 4
  br i1 %10, label %16, label %11

11:                                               ; preds = %4
  %12 = add i64 %6, 11
  %13 = inttoptr i64 %12 to i32*
  %14 = load atomic i32, i32* %13 monotonic, align 4
  %15 = ashr i32 %14, 1
  br label %16

16:                                               ; preds = %4, %11
  %17 = phi i32 [ %15, %11 ], [ 0, %4 ]
  %18 = shl i32 %1, 3
  %19 = add i32 %18, 8
  %20 = or i32 %19, 7
  %21 = sext i32 %20 to i64
  %22 = add i64 %6, %21
  %23 = inttoptr i64 %22 to i32*
  %24 = load atomic i32, i32* %23 monotonic, align 4
  %25 = icmp sgt i32 %17, %1
  br i1 %25, label %26, label %96

26:                                               ; preds = %16
  %27 = shl i32 %1, 3
  %28 = add i32 %27, 8
  %29 = or i32 %28, 7
  %30 = sext i32 %29 to i64
  %31 = add i64 %6, %30
  %32 = inttoptr i64 %31 to i32*
  %33 = load atomic i32, i32* %32 monotonic, align 4
  %34 = icmp eq i32 %33, %24
  br i1 %34, label %35, label %96

35:                                               ; preds = %26
  %36 = sext i32 %1 to i64
  br label %37

37:                                               ; preds = %35, %85
  %38 = phi i64 [ %6, %35 ], [ %86, %85 ]
  %39 = phi i32 [ %27, %35 ], [ %88, %85 ]
  %40 = phi i64 [ %36, %35 ], [ %82, %85 ]
  %41 = and i64 %38, -4294967296
  %42 = add i32 %39, 12
  %43 = sext i32 %42 to i64
  %44 = add nsw i64 %43, 7
  %45 = add i64 %44, %38
  %46 = inttoptr i64 %45 to i32*
  %47 = load atomic i32, i32* %46 monotonic, align 4
  %48 = and i32 %47, -3
  %49 = zext i32 %48 to i64
  %50 = or i64 %41, %49
  %51 = add i64 %50, 11
  %52 = inttoptr i64 %51 to i32*
  %53 = load atomic i32, i32* %52 acquire, align 4
  %54 = lshr i32 %53, 10
  %55 = and i32 %54, 1023
  %56 = add nsw i32 %55, -1
  %57 = sext i32 %56 to i64
  %58 = add i64 %50, 23
  %59 = inttoptr i64 %58 to i32*
  %60 = load atomic i32, i32* %59 monotonic, align 4
  %61 = zext i32 %60 to i64
  %62 = or i64 %41, %61
  %63 = mul nsw i64 %57, 51539607552
  %64 = add nsw i64 %63, 68719476736
  %65 = ashr exact i64 %64, 32
  %66 = or i64 %65, 3
  %67 = add i64 %66, %62
  %68 = inttoptr i64 %67 to i32*
  %69 = load atomic i32, i32* %68 monotonic, align 4
  %70 = ashr i32 %69, 1
  %71 = and i32 %70, 1
  %72 = lshr i32 %70, 3
  %73 = and i32 %72, 7
  %74 = icmp eq i32 %71, %2
  br i1 %74, label %77, label %75

75:                                               ; preds = %37
  %76 = icmp sgt i32 %71, %2
  br i1 %76, label %96, label %81

77:                                               ; preds = %37
  %78 = icmp eq i32 %73, %3
  br i1 %78, label %96, label %79

79:                                               ; preds = %77
  %80 = icmp sgt i32 %73, %3
  br i1 %80, label %96, label %81

81:                                               ; preds = %79, %75
  %82 = add nsw i64 %40, 1
  %83 = trunc i64 %82 to i32
  %84 = icmp eq i32 %17, %83
  br i1 %84, label %96, label %85

85:                                               ; preds = %81
  %86 = load i64, i64* %5, align 8
  %87 = trunc i64 %82 to i32
  %88 = shl i32 %87, 3
  %89 = add i32 %88, 8
  %90 = or i32 %89, 7
  %91 = sext i32 %90 to i64
  %92 = add i64 %86, %91
  %93 = inttoptr i64 %92 to i32*
  %94 = load atomic i32, i32* %93 monotonic, align 4
  %95 = icmp eq i32 %94, %24
  br i1 %95, label %37, label %96

96:                                               ; preds = %81, %77, %75, %79, %85, %26, %16
  %97 = phi i64 [ 0, %16 ], [ 0, %26 ], [ 0, %85 ], [ 0, %79 ], [ 0, %75 ], [ %50, %77 ], [ 0, %81 ]
  ret i64 %97
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal15TransitionArray4SortEv(%"class.v8::internal::TransitionArray"* nocapture readonly) local_unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::TransitionArray", %"class.v8::internal::TransitionArray"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load i64, i64* %2, align 8
  %4 = add i64 %3, 3
  %5 = inttoptr i64 %4 to i32*
  %6 = load i32, i32* %5, align 4
  %7 = icmp slt i32 %6, 4
  br i1 %7, label %13, label %8

8:                                                ; preds = %1
  %9 = add i64 %3, 11
  %10 = inttoptr i64 %9 to i32*
  %11 = load atomic i32, i32* %10 monotonic, align 4
  %12 = ashr i32 %11, 1
  br label %13

13:                                               ; preds = %1, %8
  %14 = phi i32 [ %12, %8 ], [ 0, %1 ]
  %15 = load %"class.v8::internal::SoleReadOnlyHeap"*, %"class.v8::internal::SoleReadOnlyHeap"** @_ZN2v88internal16SoleReadOnlyHeap15shared_ro_heap_E, align 8
  %16 = icmp eq %"class.v8::internal::SoleReadOnlyHeap"* %15, null
  br i1 %16, label %23, label %17

17:                                               ; preds = %13
  %18 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %15, i64 0, i32 0, i32 1
  %19 = load i8, i8* %18, align 8, !range !3
  %20 = icmp eq i8 %19, 0
  br i1 %20, label %23, label %21

21:                                               ; preds = %17
  %22 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %15, i64 0, i32 1, i64 0
  br label %31

23:                                               ; preds = %17, %13
  %24 = and i64 %3, -262144
  %25 = or i64 %24, 16
  %26 = inttoptr i64 %25 to i64*
  %27 = load i64, i64* %26, align 16
  %28 = add i64 %27, -41416
  %29 = inttoptr i64 %28 to %"class.v8::internal::Isolate"*
  %30 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %29, i64 0, i32 0, i32 7, i32 0, i64 0
  br label %31

31:                                               ; preds = %21, %23
  %32 = phi i64* [ %30, %23 ], [ %22, %21 ]
  %33 = icmp sgt i32 %14, 1
  br i1 %33, label %34, label %41

34:                                               ; preds = %31
  %35 = getelementptr inbounds i64, i64* %32, i64 490
  %36 = getelementptr inbounds i64, i64* %32, i64 499
  %37 = getelementptr inbounds i64, i64* %32, i64 485
  %38 = getelementptr inbounds i64, i64* %32, i64 481
  %39 = getelementptr inbounds i64, i64* %32, i64 501
  %40 = zext i32 %14 to i64
  br label %42

41:                                               ; preds = %403, %31
  ret void

42:                                               ; preds = %406, %34
  %43 = phi i64 [ %3, %34 ], [ %407, %406 ]
  %44 = phi i64 [ 1, %34 ], [ %404, %406 ]
  %45 = trunc i64 %44 to i32
  %46 = shl i32 %45, 3
  %47 = and i64 %43, -4294967296
  %48 = add i32 %46, 8
  %49 = or i32 %48, 7
  %50 = sext i32 %49 to i64
  %51 = add i64 %43, %50
  %52 = inttoptr i64 %51 to i32*
  %53 = load atomic i32, i32* %52 monotonic, align 4
  %54 = zext i32 %53 to i64
  %55 = or i64 %47, %54
  %56 = add i32 %46, 12
  %57 = sext i32 %56 to i64
  %58 = add nsw i64 %57, 7
  %59 = add i64 %58, %43
  %60 = inttoptr i64 %59 to i32*
  %61 = load atomic i32, i32* %60 monotonic, align 4
  %62 = zext i32 %61 to i64
  %63 = or i64 %47, %62
  %64 = add i64 %55, -1
  %65 = inttoptr i64 %64 to i32*
  %66 = load atomic i32, i32* %65 monotonic, align 4
  %67 = zext i32 %66 to i64
  %68 = or i64 %47, %67
  %69 = add i64 %68, 7
  %70 = inttoptr i64 %69 to i16*
  %71 = load atomic i16, i16* %70 monotonic, align 2
  %72 = icmp eq i16 %71, 64
  br i1 %72, label %73, label %93

73:                                               ; preds = %42
  %74 = load i64, i64* %35, align 8
  %75 = trunc i64 %74 to i32
  %76 = icmp eq i32 %53, %75
  br i1 %76, label %118, label %77

77:                                               ; preds = %73
  %78 = load i64, i64* %36, align 8
  %79 = trunc i64 %78 to i32
  %80 = icmp eq i32 %53, %79
  br i1 %80, label %118, label %81

81:                                               ; preds = %77
  %82 = load i64, i64* %37, align 8
  %83 = trunc i64 %82 to i32
  %84 = icmp eq i32 %53, %83
  br i1 %84, label %118, label %85

85:                                               ; preds = %81
  %86 = load i64, i64* %38, align 8
  %87 = trunc i64 %86 to i32
  %88 = icmp eq i32 %53, %87
  br i1 %88, label %118, label %89

89:                                               ; preds = %85
  %90 = load i64, i64* %39, align 8
  %91 = trunc i64 %90 to i32
  %92 = icmp eq i32 %53, %91
  br i1 %92, label %118, label %93

93:                                               ; preds = %42, %89
  %94 = and i64 %63, -3
  %95 = add i64 %94, 11
  %96 = inttoptr i64 %95 to i32*
  %97 = load atomic i32, i32* %96 acquire, align 4
  %98 = lshr i32 %97, 10
  %99 = and i32 %98, 1023
  %100 = add nsw i32 %99, -1
  %101 = sext i32 %100 to i64
  %102 = add i64 %94, 23
  %103 = inttoptr i64 %102 to i32*
  %104 = load atomic i32, i32* %103 monotonic, align 4
  %105 = zext i32 %104 to i64
  %106 = or i64 %47, %105
  %107 = mul nsw i64 %101, 51539607552
  %108 = add nsw i64 %107, 68719476736
  %109 = ashr exact i64 %108, 32
  %110 = or i64 %109, 3
  %111 = add i64 %110, %106
  %112 = inttoptr i64 %111 to i32*
  %113 = load atomic i32, i32* %112 monotonic, align 4
  %114 = ashr i32 %113, 1
  %115 = and i32 %114, 1
  %116 = lshr i32 %114, 3
  %117 = and i32 %116, 7
  br label %118

118:                                              ; preds = %73, %77, %81, %85, %93, %89
  %119 = phi i32 [ 0, %89 ], [ %117, %93 ], [ 0, %85 ], [ 0, %81 ], [ 0, %77 ], [ 0, %73 ]
  %120 = phi i32 [ 0, %89 ], [ %115, %93 ], [ 0, %85 ], [ 0, %81 ], [ 0, %77 ], [ 0, %73 ]
  %121 = add i64 %55, 3
  %122 = inttoptr i64 %121 to i32*
  br label %123

123:                                              ; preds = %118, %309
  %124 = phi i64 [ %44, %118 ], [ %125, %309 ]
  %125 = add nsw i64 %124, -1
  %126 = trunc i64 %125 to i32
  %127 = shl i32 %126, 3
  %128 = load i64, i64* %2, align 8
  %129 = and i64 %128, -4294967296
  %130 = add i32 %127, 8
  %131 = or i32 %130, 7
  %132 = sext i32 %131 to i64
  %133 = add i64 %128, %132
  %134 = inttoptr i64 %133 to i32*
  %135 = load atomic i32, i32* %134 monotonic, align 4
  %136 = zext i32 %135 to i64
  %137 = or i64 %129, %136
  %138 = add i32 %127, 12
  %139 = sext i32 %138 to i64
  %140 = add nsw i64 %139, 7
  %141 = add i64 %140, %128
  %142 = inttoptr i64 %141 to i32*
  %143 = load atomic i32, i32* %142 monotonic, align 4
  %144 = zext i32 %143 to i64
  %145 = or i64 %129, %144
  %146 = add i64 %137, -1
  %147 = inttoptr i64 %146 to i32*
  %148 = load atomic i32, i32* %147 monotonic, align 4
  %149 = zext i32 %148 to i64
  %150 = or i64 %129, %149
  %151 = add i64 %150, 7
  %152 = inttoptr i64 %151 to i16*
  %153 = load atomic i16, i16* %152 monotonic, align 2
  %154 = icmp eq i16 %153, 64
  br i1 %154, label %155, label %175

155:                                              ; preds = %123
  %156 = load i64, i64* %35, align 8
  %157 = trunc i64 %156 to i32
  %158 = icmp eq i32 %135, %157
  br i1 %158, label %200, label %159

159:                                              ; preds = %155
  %160 = load i64, i64* %36, align 8
  %161 = trunc i64 %160 to i32
  %162 = icmp eq i32 %135, %161
  br i1 %162, label %200, label %163

163:                                              ; preds = %159
  %164 = load i64, i64* %37, align 8
  %165 = trunc i64 %164 to i32
  %166 = icmp eq i32 %135, %165
  br i1 %166, label %200, label %167

167:                                              ; preds = %163
  %168 = load i64, i64* %38, align 8
  %169 = trunc i64 %168 to i32
  %170 = icmp eq i32 %135, %169
  br i1 %170, label %200, label %171

171:                                              ; preds = %167
  %172 = load i64, i64* %39, align 8
  %173 = trunc i64 %172 to i32
  %174 = icmp eq i32 %135, %173
  br i1 %174, label %200, label %175

175:                                              ; preds = %123, %171
  %176 = and i64 %145, -3
  %177 = add i64 %176, 11
  %178 = inttoptr i64 %177 to i32*
  %179 = load atomic i32, i32* %178 acquire, align 4
  %180 = lshr i32 %179, 10
  %181 = and i32 %180, 1023
  %182 = add nsw i32 %181, -1
  %183 = sext i32 %182 to i64
  %184 = add i64 %176, 23
  %185 = inttoptr i64 %184 to i32*
  %186 = load atomic i32, i32* %185 monotonic, align 4
  %187 = zext i32 %186 to i64
  %188 = or i64 %129, %187
  %189 = mul nsw i64 %183, 51539607552
  %190 = add nsw i64 %189, 68719476736
  %191 = ashr exact i64 %190, 32
  %192 = or i64 %191, 3
  %193 = add i64 %192, %188
  %194 = inttoptr i64 %193 to i32*
  %195 = load atomic i32, i32* %194 monotonic, align 4
  %196 = ashr i32 %195, 1
  %197 = and i32 %196, 1
  %198 = lshr i32 %196, 3
  %199 = and i32 %198, 7
  br label %200

200:                                              ; preds = %155, %159, %163, %167, %175, %171
  %201 = phi i32 [ 0, %171 ], [ %199, %175 ], [ 0, %167 ], [ 0, %163 ], [ 0, %159 ], [ 0, %155 ]
  %202 = phi i32 [ 0, %171 ], [ %197, %175 ], [ 0, %167 ], [ 0, %163 ], [ 0, %159 ], [ 0, %155 ]
  %203 = icmp eq i32 %135, %53
  %204 = trunc i64 %124 to i32
  br i1 %203, label %205, label %211

205:                                              ; preds = %200
  %206 = icmp eq i32 %202, %120
  br i1 %206, label %209, label %207

207:                                              ; preds = %205
  %208 = icmp ult i32 %202, %120
  br i1 %208, label %311, label %219

209:                                              ; preds = %205
  %210 = icmp ugt i32 %201, %119
  br i1 %210, label %219, label %311

211:                                              ; preds = %200
  %212 = add i64 %137, 3
  %213 = inttoptr i64 %212 to i32*
  %214 = load i32, i32* %213, align 4
  %215 = lshr i32 %214, 2
  %216 = load i32, i32* %122, align 4
  %217 = lshr i32 %216, 2
  %218 = icmp ugt i32 %215, %217
  br i1 %218, label %219, label %311

219:                                              ; preds = %209, %207, %211
  %220 = shl i32 %204, 3
  %221 = add i32 %220, 8
  %222 = load i64, i64* %2, align 8
  %223 = or i32 %221, 7
  %224 = sext i32 %223 to i64
  %225 = add i64 %222, %224
  %226 = inttoptr i64 %225 to i32*
  store atomic volatile i32 %135, i32* %226 monotonic, align 4
  %227 = load i64, i64* %2, align 8
  %228 = add i64 %227, %224
  %229 = and i64 %136, 1
  %230 = icmp ne i64 %229, 0
  %231 = icmp ne i32 %135, 3
  %232 = and i1 %231, %230
  br i1 %232, label %233, label %265

233:                                              ; preds = %219
  %234 = and i64 %227, -262144
  %235 = or i64 %234, 8
  %236 = inttoptr i64 %235 to i64*
  %237 = load i64, i64* %236, align 8
  %238 = and i64 %237, 262144
  %239 = icmp eq i64 %238, 0
  %240 = and i64 %137, -3
  br i1 %239, label %247, label %241

241:                                              ; preds = %233
  %242 = or i64 %234, 16
  %243 = inttoptr i64 %242 to %"class.v8::internal::Heap"**
  %244 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %243, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %244, i64 %227, i64 %228, i64 %240) #6
  %245 = load i64, i64* %2, align 8
  %246 = add i64 %245, %224
  br label %247

247:                                              ; preds = %233, %241
  %248 = phi i64 [ %246, %241 ], [ %228, %233 ]
  %249 = phi i64 [ %245, %241 ], [ %227, %233 ]
  %250 = and i64 %137, -262144
  %251 = or i64 %250, 8
  %252 = inttoptr i64 %251 to i64*
  %253 = load i64, i64* %252, align 8
  %254 = and i64 %253, 24
  %255 = icmp eq i64 %254, 0
  br i1 %255, label %265, label %256

256:                                              ; preds = %247
  %257 = and i64 %249, -262144
  %258 = or i64 %257, 8
  %259 = inttoptr i64 %258 to i64*
  %260 = load i64, i64* %259, align 8
  %261 = and i64 %260, 24
  %262 = icmp eq i64 %261, 0
  br i1 %262, label %263, label %265

263:                                              ; preds = %256
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %249, i64 %248, i64 %240) #6
  %264 = load i64, i64* %2, align 8
  br label %265

265:                                              ; preds = %219, %247, %256, %263
  %266 = phi i64 [ %227, %219 ], [ %249, %247 ], [ %249, %256 ], [ %264, %263 ]
  %267 = add i32 %220, 12
  %268 = sext i32 %267 to i64
  %269 = add nsw i64 %268, 7
  %270 = add i64 %266, %269
  %271 = inttoptr i64 %270 to i32*
  store atomic volatile i32 %143, i32* %271 monotonic, align 4
  %272 = load i64, i64* %2, align 8
  %273 = add i64 %272, %269
  %274 = and i64 %144, 1
  %275 = icmp ne i64 %274, 0
  %276 = icmp ne i32 %143, 3
  %277 = and i1 %276, %275
  br i1 %277, label %278, label %309

278:                                              ; preds = %265
  %279 = and i64 %272, -262144
  %280 = or i64 %279, 8
  %281 = inttoptr i64 %280 to i64*
  %282 = load i64, i64* %281, align 8
  %283 = and i64 %282, 262144
  %284 = icmp eq i64 %283, 0
  %285 = and i64 %145, -3
  br i1 %284, label %292, label %286

286:                                              ; preds = %278
  %287 = or i64 %279, 16
  %288 = inttoptr i64 %287 to %"class.v8::internal::Heap"**
  %289 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %288, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %289, i64 %272, i64 %273, i64 %285) #6
  %290 = load i64, i64* %2, align 8
  %291 = add i64 %290, %269
  br label %292

292:                                              ; preds = %278, %286
  %293 = phi i64 [ %291, %286 ], [ %273, %278 ]
  %294 = phi i64 [ %290, %286 ], [ %272, %278 ]
  %295 = and i64 %145, -262144
  %296 = or i64 %295, 8
  %297 = inttoptr i64 %296 to i64*
  %298 = load i64, i64* %297, align 8
  %299 = and i64 %298, 24
  %300 = icmp eq i64 %299, 0
  br i1 %300, label %309, label %301

301:                                              ; preds = %292
  %302 = and i64 %294, -262144
  %303 = or i64 %302, 8
  %304 = inttoptr i64 %303 to i64*
  %305 = load i64, i64* %304, align 8
  %306 = and i64 %305, 24
  %307 = icmp eq i64 %306, 0
  br i1 %307, label %308, label %309

308:                                              ; preds = %301
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %294, i64 %293, i64 %285) #6
  br label %309

309:                                              ; preds = %265, %292, %301, %308
  %310 = icmp sgt i64 %125, 0
  br i1 %310, label %123, label %311

311:                                              ; preds = %309, %211, %207, %209
  %312 = phi i64 [ %124, %209 ], [ %124, %207 ], [ %124, %211 ], [ %125, %309 ]
  %313 = trunc i64 %312 to i32
  %314 = shl i32 %313, 3
  %315 = add i32 %314, 8
  %316 = load i64, i64* %2, align 8
  %317 = or i32 %315, 7
  %318 = sext i32 %317 to i64
  %319 = add i64 %316, %318
  %320 = inttoptr i64 %319 to i32*
  store atomic volatile i32 %53, i32* %320 monotonic, align 4
  %321 = load i64, i64* %2, align 8
  %322 = add i64 %321, %318
  %323 = and i64 %54, 1
  %324 = icmp ne i64 %323, 0
  %325 = icmp ne i32 %53, 3
  %326 = and i1 %325, %324
  br i1 %326, label %327, label %359

327:                                              ; preds = %311
  %328 = and i64 %321, -262144
  %329 = or i64 %328, 8
  %330 = inttoptr i64 %329 to i64*
  %331 = load i64, i64* %330, align 8
  %332 = and i64 %331, 262144
  %333 = icmp eq i64 %332, 0
  %334 = and i64 %55, -3
  br i1 %333, label %341, label %335

335:                                              ; preds = %327
  %336 = or i64 %328, 16
  %337 = inttoptr i64 %336 to %"class.v8::internal::Heap"**
  %338 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %337, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %338, i64 %321, i64 %322, i64 %334) #6
  %339 = load i64, i64* %2, align 8
  %340 = add i64 %339, %318
  br label %341

341:                                              ; preds = %327, %335
  %342 = phi i64 [ %340, %335 ], [ %322, %327 ]
  %343 = phi i64 [ %339, %335 ], [ %321, %327 ]
  %344 = and i64 %55, -262144
  %345 = or i64 %344, 8
  %346 = inttoptr i64 %345 to i64*
  %347 = load i64, i64* %346, align 8
  %348 = and i64 %347, 24
  %349 = icmp eq i64 %348, 0
  br i1 %349, label %359, label %350

350:                                              ; preds = %341
  %351 = and i64 %343, -262144
  %352 = or i64 %351, 8
  %353 = inttoptr i64 %352 to i64*
  %354 = load i64, i64* %353, align 8
  %355 = and i64 %354, 24
  %356 = icmp eq i64 %355, 0
  br i1 %356, label %357, label %359

357:                                              ; preds = %350
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %343, i64 %342, i64 %334) #6
  %358 = load i64, i64* %2, align 8
  br label %359

359:                                              ; preds = %311, %341, %350, %357
  %360 = phi i64 [ %321, %311 ], [ %343, %341 ], [ %343, %350 ], [ %358, %357 ]
  %361 = add i32 %314, 12
  %362 = sext i32 %361 to i64
  %363 = add nsw i64 %362, 7
  %364 = add i64 %360, %363
  %365 = inttoptr i64 %364 to i32*
  store atomic volatile i32 %61, i32* %365 monotonic, align 4
  %366 = load i64, i64* %2, align 8
  %367 = add i64 %366, %363
  %368 = and i64 %62, 1
  %369 = icmp ne i64 %368, 0
  %370 = icmp ne i32 %61, 3
  %371 = and i1 %370, %369
  br i1 %371, label %372, label %403

372:                                              ; preds = %359
  %373 = and i64 %366, -262144
  %374 = or i64 %373, 8
  %375 = inttoptr i64 %374 to i64*
  %376 = load i64, i64* %375, align 8
  %377 = and i64 %376, 262144
  %378 = icmp eq i64 %377, 0
  %379 = and i64 %63, -3
  br i1 %378, label %386, label %380

380:                                              ; preds = %372
  %381 = or i64 %373, 16
  %382 = inttoptr i64 %381 to %"class.v8::internal::Heap"**
  %383 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %382, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %383, i64 %366, i64 %367, i64 %379) #6
  %384 = load i64, i64* %2, align 8
  %385 = add i64 %384, %363
  br label %386

386:                                              ; preds = %372, %380
  %387 = phi i64 [ %385, %380 ], [ %367, %372 ]
  %388 = phi i64 [ %384, %380 ], [ %366, %372 ]
  %389 = and i64 %63, -262144
  %390 = or i64 %389, 8
  %391 = inttoptr i64 %390 to i64*
  %392 = load i64, i64* %391, align 8
  %393 = and i64 %392, 24
  %394 = icmp eq i64 %393, 0
  br i1 %394, label %403, label %395

395:                                              ; preds = %386
  %396 = and i64 %388, -262144
  %397 = or i64 %396, 8
  %398 = inttoptr i64 %397 to i64*
  %399 = load i64, i64* %398, align 8
  %400 = and i64 %399, 24
  %401 = icmp eq i64 %400, 0
  br i1 %401, label %402, label %403

402:                                              ; preds = %395
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %388, i64 %387, i64 %379) #6
  br label %403

403:                                              ; preds = %359, %386, %395, %402
  %404 = add nuw nsw i64 %44, 1
  %405 = icmp eq i64 %404, %40
  br i1 %405, label %41, label %406

406:                                              ; preds = %403
  %407 = load i64, i64* %2, align 8
  br label %42
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal19TransitionsAccessor29HasIntegrityLevelTransitionToENS0_3MapEPNS0_6SymbolEPNS0_18PropertyAttributesE(%"class.v8::internal::TransitionsAccessor"* nocapture readonly, i64, %"class.v8::internal::Symbol"*, i32*) local_unnamed_addr #0 align 2 {
  %5 = getelementptr inbounds %"class.v8::internal::TransitionsAccessor", %"class.v8::internal::TransitionsAccessor"* %0, i64 0, i32 0
  %6 = load %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"** %5, align 8
  %7 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %6, i64 0, i32 0, i32 7, i32 0, i64 485
  %8 = load i64, i64* %7, align 8
  %9 = tail call i64 @_ZN2v88internal19TransitionsAccessor13SearchSpecialENS0_6SymbolE(%"class.v8::internal::TransitionsAccessor"* %0, i64 %8)
  %10 = trunc i64 %9 to i32
  %11 = trunc i64 %1 to i32
  %12 = icmp eq i32 %10, %11
  br i1 %12, label %13, label %21

13:                                               ; preds = %4
  %14 = icmp eq i32* %3, null
  br i1 %14, label %16, label %15

15:                                               ; preds = %13
  store i32 5, i32* %3, align 4
  br label %16

16:                                               ; preds = %13, %15
  %17 = icmp eq %"class.v8::internal::Symbol"* %2, null
  br i1 %17, label %49, label %18

18:                                               ; preds = %16
  %19 = load i64, i64* %7, align 8
  %20 = getelementptr inbounds %"class.v8::internal::Symbol", %"class.v8::internal::Symbol"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %19, i64* %20, align 8
  br label %49

21:                                               ; preds = %4
  %22 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %6, i64 0, i32 0, i32 7, i32 0, i64 499
  %23 = load i64, i64* %22, align 8
  %24 = tail call i64 @_ZN2v88internal19TransitionsAccessor13SearchSpecialENS0_6SymbolE(%"class.v8::internal::TransitionsAccessor"* %0, i64 %23)
  %25 = trunc i64 %24 to i32
  %26 = icmp eq i32 %25, %11
  br i1 %26, label %27, label %35

27:                                               ; preds = %21
  %28 = icmp eq i32* %3, null
  br i1 %28, label %30, label %29

29:                                               ; preds = %27
  store i32 4, i32* %3, align 4
  br label %30

30:                                               ; preds = %27, %29
  %31 = icmp eq %"class.v8::internal::Symbol"* %2, null
  br i1 %31, label %49, label %32

32:                                               ; preds = %30
  %33 = load i64, i64* %22, align 8
  %34 = getelementptr inbounds %"class.v8::internal::Symbol", %"class.v8::internal::Symbol"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %33, i64* %34, align 8
  br label %49

35:                                               ; preds = %21
  %36 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %6, i64 0, i32 0, i32 7, i32 0, i64 490
  %37 = load i64, i64* %36, align 8
  %38 = tail call i64 @_ZN2v88internal19TransitionsAccessor13SearchSpecialENS0_6SymbolE(%"class.v8::internal::TransitionsAccessor"* %0, i64 %37)
  %39 = trunc i64 %38 to i32
  %40 = icmp eq i32 %39, %11
  br i1 %40, label %41, label %49

41:                                               ; preds = %35
  %42 = icmp eq i32* %3, null
  br i1 %42, label %44, label %43

43:                                               ; preds = %41
  store i32 0, i32* %3, align 4
  br label %44

44:                                               ; preds = %41, %43
  %45 = icmp eq %"class.v8::internal::Symbol"* %2, null
  br i1 %45, label %49, label %46

46:                                               ; preds = %44
  %47 = load i64, i64* %36, align 8
  %48 = getelementptr inbounds %"class.v8::internal::Symbol", %"class.v8::internal::Symbol"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %47, i64* %48, align 8
  br label %49

49:                                               ; preds = %18, %46, %32, %44, %30, %16, %35
  %50 = phi i1 [ false, %35 ], [ true, %16 ], [ true, %30 ], [ true, %44 ], [ true, %32 ], [ true, %46 ], [ true, %18 ]
  ret i1 %50
}

; Function Attrs: nounwind
declare void @llvm.assume(i1) #6

declare void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"*, i64, i64, i64) local_unnamed_addr #4

declare void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64, i64, i64) local_unnamed_addr #4

declare zeroext i1 @_ZNK2v88internal6String10SlowEqualsES1_(%"class.v8::internal::String"*, i64) local_unnamed_addr #4

declare void @_ZN2v84base11SharedMutex12UnlockSharedEv(%"class.v8::base::SharedMutex"*) local_unnamed_addr #4

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN2v88internal12BinarySearchILNS0_10SearchModeE0ENS0_15TransitionArrayEEEiPT0_NS0_4NameEiPi(%"class.v8::internal::TransitionArray"*, i64, i32, i32*) local_unnamed_addr #0 comdat {
  %5 = getelementptr inbounds %"class.v8::internal::TransitionArray", %"class.v8::internal::TransitionArray"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 3
  %8 = inttoptr i64 %7 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = icmp slt i32 %9, 4
  br i1 %10, label %11, label %16

11:                                               ; preds = %4
  %12 = add i64 %1, 3
  %13 = inttoptr i64 %12 to i32*
  %14 = load i32, i32* %13, align 4
  %15 = lshr i32 %14, 2
  br label %27

16:                                               ; preds = %4
  %17 = add i64 %6, 11
  %18 = inttoptr i64 %17 to i32*
  %19 = load atomic i32, i32* %18 monotonic, align 4
  %20 = ashr i32 %19, 1
  %21 = add nsw i32 %20, -1
  %22 = add i64 %1, 3
  %23 = inttoptr i64 %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = lshr i32 %24, 2
  %26 = icmp eq i32 %21, 0
  br i1 %26, label %32, label %27

27:                                               ; preds = %11, %16
  %28 = phi i32 [ %15, %11 ], [ %25, %16 ]
  %29 = phi i32 [ -1, %11 ], [ %21, %16 ]
  %30 = phi i32 [ 0, %11 ], [ %20, %16 ]
  %31 = and i64 %6, -4294967296
  br label %41

32:                                               ; preds = %41, %16
  %33 = phi i32 [ %25, %16 ], [ %28, %41 ]
  %34 = phi i32 [ 1, %16 ], [ %30, %41 ]
  %35 = phi i32 [ 0, %16 ], [ %62, %41 ]
  %36 = icmp slt i32 %35, %34
  br i1 %36, label %37, label %95

37:                                               ; preds = %32
  %38 = and i64 %6, -4294967296
  %39 = trunc i64 %1 to i32
  %40 = sext i32 %35 to i64
  br label %65

41:                                               ; preds = %27, %41
  %42 = phi i32 [ 0, %27 ], [ %63, %41 ]
  %43 = phi i32 [ %29, %27 ], [ %62, %41 ]
  %44 = sub nsw i32 %43, %42
  %45 = sdiv i32 %44, 2
  %46 = add nsw i32 %45, %42
  %47 = shl i32 %46, 3
  %48 = add i32 %47, 8
  %49 = or i32 %48, 7
  %50 = sext i32 %49 to i64
  %51 = add i64 %6, %50
  %52 = inttoptr i64 %51 to i32*
  %53 = load atomic i32, i32* %52 monotonic, align 4
  %54 = zext i32 %53 to i64
  %55 = or i64 %31, %54
  %56 = add i64 %55, 3
  %57 = inttoptr i64 %56 to i32*
  %58 = load i32, i32* %57, align 4
  %59 = lshr i32 %58, 2
  %60 = icmp ult i32 %59, %28
  %61 = add nsw i32 %46, 1
  %62 = select i1 %60, i32 %43, i32 %46
  %63 = select i1 %60, i32 %61, i32 %42
  %64 = icmp eq i32 %62, %63
  br i1 %64, label %32, label %41

65:                                               ; preds = %91, %37
  %66 = phi i64 [ %40, %37 ], [ %92, %91 ]
  %67 = trunc i64 %66 to i32
  %68 = shl i32 %67, 3
  %69 = add i32 %68, 8
  %70 = or i32 %69, 7
  %71 = sext i32 %70 to i64
  %72 = add i64 %6, %71
  %73 = inttoptr i64 %72 to i32*
  %74 = load atomic i32, i32* %73 monotonic, align 4
  %75 = zext i32 %74 to i64
  %76 = or i64 %38, %75
  %77 = add i64 %76, 3
  %78 = inttoptr i64 %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = lshr i32 %79, 2
  %81 = icmp eq i32 %80, %33
  br i1 %81, label %89, label %82

82:                                               ; preds = %65
  %83 = icmp eq i32* %3, null
  br i1 %83, label %100, label %84

84:                                               ; preds = %82
  %85 = trunc i64 %66 to i32
  %86 = icmp ule i32 %80, %33
  %87 = zext i1 %86 to i32
  %88 = add nsw i32 %85, %87
  store i32 %88, i32* %3, align 4
  br label %100

89:                                               ; preds = %65
  %90 = icmp eq i32 %74, %39
  br i1 %90, label %98, label %91

91:                                               ; preds = %89
  %92 = add nsw i64 %66, 1
  %93 = trunc i64 %92 to i32
  %94 = icmp eq i32 %34, %93
  br i1 %94, label %95, label %65

95:                                               ; preds = %91, %32
  %96 = icmp eq i32* %3, null
  br i1 %96, label %100, label %97

97:                                               ; preds = %95
  store i32 %34, i32* %3, align 4
  br label %100

98:                                               ; preds = %89
  %99 = trunc i64 %66 to i32
  br label %100

100:                                              ; preds = %98, %84, %82, %97, %95
  %101 = phi i32 [ -1, %95 ], [ -1, %97 ], [ -1, %82 ], [ -1, %84 ], [ %99, %98 ]
  ret i32 %101
}

declare void @_ZN2v84base11SharedMutex13LockExclusiveEv(%"class.v8::base::SharedMutex"*) local_unnamed_addr #4

declare void @_ZN2v84base11SharedMutex15UnlockExclusiveEv(%"class.v8::base::SharedMutex"*) local_unnamed_addr #4

declare i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"*, i64) local_unnamed_addr #4

declare i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"*) local_unnamed_addr #4

declare void @_ZN2v84base11SharedMutex10LockSharedEv(%"class.v8::base::SharedMutex"*) local_unnamed_addr #4

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { noreturn "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nounwind }
attributes #7 = { noreturn nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{!"branch_weights", i32 2000, i32 1}
!3 = !{i8 0, i8 2}
!4 = distinct !{!4, !5}
!5 = !{!"llvm.loop.unroll.disable"}
