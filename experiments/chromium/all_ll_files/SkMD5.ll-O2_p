; ModuleID = '../../third_party/skia/src/core/SkMD5.cpp'
source_filename = "../../third_party/skia/src/core/SkMD5.cpp"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%class.SkMD5 = type { %class.SkWStream, i64, [4 x i32], [64 x i8] }
%class.SkWStream = type { i32 (...)** }

$_ZN5SkMD5D0Ev = comdat any

$_ZNK5SkMD512bytesWrittenEv = comdat any

@_ZTV5SkMD5 = hidden unnamed_addr constant { [7 x i8*] } { [7 x i8*] [i8* null, i8* null, i8* bitcast (void (%class.SkWStream*)* @_ZN9SkWStreamD2Ev to i8*), i8* bitcast (void (%class.SkMD5*)* @_ZN5SkMD5D0Ev to i8*), i8* bitcast (i1 (%class.SkMD5*, i8*, i64)* @_ZN5SkMD55writeEPKvm to i8*), i8* bitcast (void (%class.SkWStream*)* @_ZN9SkWStream5flushEv to i8*), i8* bitcast (i64 (%class.SkMD5*)* @_ZNK5SkMD512bytesWrittenEv to i8*)] }, align 8
@_ZZN5SkMD56finishEvE7PADDING = internal constant <{ i8, [63 x i8] }> <{ i8 -128, [63 x i8] zeroinitializer }>, align 16

@_ZN5SkMD5C1Ev = hidden unnamed_addr alias void (%class.SkMD5*), void (%class.SkMD5*)* @_ZN5SkMD5C2Ev

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define hidden void @_ZN5SkMD5C2Ev(%class.SkMD5* nocapture) unnamed_addr #0 align 2 {
  %2 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTV5SkMD5, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8
  %3 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 1
  store i64 0, i64* %3, align 8
  %4 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 2, i64 0
  %5 = bitcast i32* %4 to <4 x i32>*
  store <4 x i32> <i32 1732584193, i32 -271733879, i32 -1732584194, i32 271733878>, <4 x i32>* %5, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN5SkMD55writeEPKvm(%class.SkMD5*, i8*, i64) unnamed_addr #1 align 2 {
  %4 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 1
  %5 = load i64, i64* %4, align 8
  %6 = trunc i64 %5 to i32
  %7 = and i32 %6, 63
  %8 = sub nuw nsw i32 64, %7
  %9 = zext i32 %8 to i64
  %10 = icmp ugt i64 %9, %2
  br i1 %10, label %33, label %11

11:                                               ; preds = %3
  %12 = icmp eq i32 %7, 0
  br i1 %12, label %18, label %13

13:                                               ; preds = %11
  %14 = zext i32 %7 to i64
  %15 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 3, i64 %14
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %15, i8* align 1 %1, i64 %9, i1 false)
  %16 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 2, i64 0
  %17 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 3, i64 0
  tail call fastcc void @_ZL9transformPjPKh(i32* %16, i8* %17)
  br label %18

18:                                               ; preds = %11, %13
  %19 = phi i32 [ %8, %13 ], [ 0, %11 ]
  %20 = add nuw nsw i32 %19, 63
  %21 = zext i32 %20 to i64
  %22 = icmp ult i64 %21, %2
  br i1 %22, label %23, label %35

23:                                               ; preds = %18
  %24 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 2, i64 0
  br label %25

25:                                               ; preds = %23, %25
  %26 = phi i32 [ %19, %23 ], [ %29, %25 ]
  %27 = zext i32 %26 to i64
  %28 = getelementptr inbounds i8, i8* %1, i64 %27
  tail call fastcc void @_ZL9transformPjPKh(i32* %24, i8* %28)
  %29 = add i32 %26, 64
  %30 = add i32 %26, 127
  %31 = zext i32 %30 to i64
  %32 = icmp ult i64 %31, %2
  br i1 %32, label %25, label %35

33:                                               ; preds = %3
  %34 = zext i32 %7 to i64
  br label %35

35:                                               ; preds = %25, %18, %33
  %36 = phi i64 [ %34, %33 ], [ 0, %18 ], [ 0, %25 ]
  %37 = phi i32 [ 0, %33 ], [ %19, %18 ], [ %29, %25 ]
  %38 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 3, i64 %36
  %39 = zext i32 %37 to i64
  %40 = getelementptr inbounds i8, i8* %1, i64 %39
  %41 = sub i64 %2, %39
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %38, i8* align 1 %40, i64 %41, i1 false)
  %42 = load i64, i64* %4, align 8
  %43 = add i64 %42, %2
  store i64 %43, i64* %4, align 8
  ret i1 true
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #2

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #2

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @_ZL9transformPjPKh(i32* nocapture, i8*) unnamed_addr #1 {
  %3 = alloca [16 x i32], align 16
  %4 = load i32, i32* %0, align 4
  %5 = getelementptr inbounds i32, i32* %0, i64 1
  %6 = load i32, i32* %5, align 4
  %7 = getelementptr inbounds i32, i32* %0, i64 2
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds i32, i32* %0, i64 3
  %10 = load i32, i32* %9, align 4
  %11 = bitcast [16 x i32]* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %11) #7
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 -86, i64 64, i1 false)
  %12 = getelementptr inbounds [16 x i32], [16 x i32]* %3, i64 0, i64 0
  %13 = ptrtoint i8* %1 to i64
  %14 = and i64 %13, 3
  %15 = icmp eq i64 %14, 0
  br i1 %15, label %91, label %16

16:                                               ; preds = %2
  %17 = bitcast i8* %1 to <16 x i8>*
  %18 = load <16 x i8>, <16 x i8>* %17, align 1
  %19 = shufflevector <16 x i8> %18, <16 x i8> undef, <4 x i32> <i32 0, i32 4, i32 8, i32 12>
  %20 = shufflevector <16 x i8> %18, <16 x i8> undef, <4 x i32> <i32 1, i32 5, i32 9, i32 13>
  %21 = shufflevector <16 x i8> %18, <16 x i8> undef, <4 x i32> <i32 2, i32 6, i32 10, i32 14>
  %22 = shufflevector <16 x i8> %18, <16 x i8> undef, <4 x i32> <i32 3, i32 7, i32 11, i32 15>
  %23 = zext <4 x i8> %19 to <4 x i32>
  %24 = zext <4 x i8> %20 to <4 x i32>
  %25 = shl nuw nsw <4 x i32> %24, <i32 8, i32 8, i32 8, i32 8>
  %26 = or <4 x i32> %25, %23
  %27 = zext <4 x i8> %21 to <4 x i32>
  %28 = shl nuw nsw <4 x i32> %27, <i32 16, i32 16, i32 16, i32 16>
  %29 = or <4 x i32> %26, %28
  %30 = zext <4 x i8> %22 to <4 x i32>
  %31 = shl nuw <4 x i32> %30, <i32 24, i32 24, i32 24, i32 24>
  %32 = or <4 x i32> %29, %31
  %33 = bitcast [16 x i32]* %3 to <4 x i32>*
  store <4 x i32> %32, <4 x i32>* %33, align 16
  %34 = getelementptr inbounds i8, i8* %1, i64 16
  %35 = bitcast i8* %34 to <16 x i8>*
  %36 = load <16 x i8>, <16 x i8>* %35, align 1
  %37 = shufflevector <16 x i8> %36, <16 x i8> undef, <4 x i32> <i32 0, i32 4, i32 8, i32 12>
  %38 = shufflevector <16 x i8> %36, <16 x i8> undef, <4 x i32> <i32 1, i32 5, i32 9, i32 13>
  %39 = shufflevector <16 x i8> %36, <16 x i8> undef, <4 x i32> <i32 2, i32 6, i32 10, i32 14>
  %40 = shufflevector <16 x i8> %36, <16 x i8> undef, <4 x i32> <i32 3, i32 7, i32 11, i32 15>
  %41 = zext <4 x i8> %37 to <4 x i32>
  %42 = zext <4 x i8> %38 to <4 x i32>
  %43 = shl nuw nsw <4 x i32> %42, <i32 8, i32 8, i32 8, i32 8>
  %44 = or <4 x i32> %43, %41
  %45 = zext <4 x i8> %39 to <4 x i32>
  %46 = shl nuw nsw <4 x i32> %45, <i32 16, i32 16, i32 16, i32 16>
  %47 = or <4 x i32> %44, %46
  %48 = zext <4 x i8> %40 to <4 x i32>
  %49 = shl nuw <4 x i32> %48, <i32 24, i32 24, i32 24, i32 24>
  %50 = or <4 x i32> %47, %49
  %51 = getelementptr inbounds [16 x i32], [16 x i32]* %3, i64 0, i64 4
  %52 = bitcast i32* %51 to <4 x i32>*
  store <4 x i32> %50, <4 x i32>* %52, align 16
  %53 = getelementptr inbounds i8, i8* %1, i64 32
  %54 = bitcast i8* %53 to <16 x i8>*
  %55 = load <16 x i8>, <16 x i8>* %54, align 1
  %56 = shufflevector <16 x i8> %55, <16 x i8> undef, <4 x i32> <i32 0, i32 4, i32 8, i32 12>
  %57 = shufflevector <16 x i8> %55, <16 x i8> undef, <4 x i32> <i32 1, i32 5, i32 9, i32 13>
  %58 = shufflevector <16 x i8> %55, <16 x i8> undef, <4 x i32> <i32 2, i32 6, i32 10, i32 14>
  %59 = shufflevector <16 x i8> %55, <16 x i8> undef, <4 x i32> <i32 3, i32 7, i32 11, i32 15>
  %60 = zext <4 x i8> %56 to <4 x i32>
  %61 = zext <4 x i8> %57 to <4 x i32>
  %62 = shl nuw nsw <4 x i32> %61, <i32 8, i32 8, i32 8, i32 8>
  %63 = or <4 x i32> %62, %60
  %64 = zext <4 x i8> %58 to <4 x i32>
  %65 = shl nuw nsw <4 x i32> %64, <i32 16, i32 16, i32 16, i32 16>
  %66 = or <4 x i32> %63, %65
  %67 = zext <4 x i8> %59 to <4 x i32>
  %68 = shl nuw <4 x i32> %67, <i32 24, i32 24, i32 24, i32 24>
  %69 = or <4 x i32> %66, %68
  %70 = getelementptr inbounds [16 x i32], [16 x i32]* %3, i64 0, i64 8
  %71 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %69, <4 x i32>* %71, align 16
  %72 = getelementptr inbounds i8, i8* %1, i64 48
  %73 = bitcast i8* %72 to <16 x i8>*
  %74 = load <16 x i8>, <16 x i8>* %73, align 1
  %75 = shufflevector <16 x i8> %74, <16 x i8> undef, <4 x i32> <i32 0, i32 4, i32 8, i32 12>
  %76 = shufflevector <16 x i8> %74, <16 x i8> undef, <4 x i32> <i32 1, i32 5, i32 9, i32 13>
  %77 = shufflevector <16 x i8> %74, <16 x i8> undef, <4 x i32> <i32 2, i32 6, i32 10, i32 14>
  %78 = shufflevector <16 x i8> %74, <16 x i8> undef, <4 x i32> <i32 3, i32 7, i32 11, i32 15>
  %79 = zext <4 x i8> %75 to <4 x i32>
  %80 = zext <4 x i8> %76 to <4 x i32>
  %81 = shl nuw nsw <4 x i32> %80, <i32 8, i32 8, i32 8, i32 8>
  %82 = or <4 x i32> %81, %79
  %83 = zext <4 x i8> %77 to <4 x i32>
  %84 = shl nuw nsw <4 x i32> %83, <i32 16, i32 16, i32 16, i32 16>
  %85 = or <4 x i32> %82, %84
  %86 = zext <4 x i8> %78 to <4 x i32>
  %87 = shl nuw <4 x i32> %86, <i32 24, i32 24, i32 24, i32 24>
  %88 = or <4 x i32> %85, %87
  %89 = getelementptr inbounds [16 x i32], [16 x i32]* %3, i64 0, i64 12
  %90 = bitcast i32* %89 to <4 x i32>*
  store <4 x i32> %88, <4 x i32>* %90, align 16
  br label %93

91:                                               ; preds = %2
  %92 = bitcast i8* %1 to i32*
  br label %93

93:                                               ; preds = %16, %91
  %94 = phi i32* [ %92, %91 ], [ %12, %16 ]
  %95 = load i32, i32* %94, align 4
  %96 = xor i32 %10, %8
  %97 = and i32 %96, %6
  %98 = xor i32 %97, %10
  %99 = add i32 %4, -680876936
  %100 = add i32 %99, %98
  %101 = add i32 %100, %95
  %102 = shl i32 %101, 7
  %103 = lshr i32 %101, 25
  %104 = or i32 %103, %102
  %105 = add i32 %104, %6
  %106 = getelementptr inbounds i32, i32* %94, i64 1
  %107 = load i32, i32* %106, align 4
  %108 = xor i32 %8, %6
  %109 = and i32 %105, %108
  %110 = xor i32 %109, %8
  %111 = add i32 %10, -389564586
  %112 = add i32 %111, %107
  %113 = add i32 %112, %110
  %114 = shl i32 %113, 12
  %115 = lshr i32 %113, 20
  %116 = or i32 %115, %114
  %117 = add i32 %116, %105
  %118 = getelementptr inbounds i32, i32* %94, i64 2
  %119 = load i32, i32* %118, align 4
  %120 = xor i32 %105, %6
  %121 = and i32 %117, %120
  %122 = xor i32 %121, %6
  %123 = add i32 %8, 606105819
  %124 = add i32 %123, %119
  %125 = add i32 %124, %122
  %126 = shl i32 %125, 17
  %127 = lshr i32 %125, 15
  %128 = or i32 %127, %126
  %129 = add i32 %128, %117
  %130 = getelementptr inbounds i32, i32* %94, i64 3
  %131 = load i32, i32* %130, align 4
  %132 = xor i32 %117, %105
  %133 = and i32 %129, %132
  %134 = xor i32 %133, %105
  %135 = add i32 %6, -1044525330
  %136 = add i32 %135, %131
  %137 = add i32 %136, %134
  %138 = shl i32 %137, 22
  %139 = lshr i32 %137, 10
  %140 = or i32 %139, %138
  %141 = add i32 %140, %129
  %142 = getelementptr inbounds i32, i32* %94, i64 4
  %143 = load i32, i32* %142, align 4
  %144 = xor i32 %129, %117
  %145 = and i32 %141, %144
  %146 = xor i32 %145, %117
  %147 = add i32 %143, -176418897
  %148 = add i32 %147, %105
  %149 = add i32 %148, %146
  %150 = shl i32 %149, 7
  %151 = lshr i32 %149, 25
  %152 = or i32 %151, %150
  %153 = add i32 %152, %141
  %154 = getelementptr inbounds i32, i32* %94, i64 5
  %155 = load i32, i32* %154, align 4
  %156 = xor i32 %141, %129
  %157 = and i32 %153, %156
  %158 = xor i32 %157, %129
  %159 = add i32 %155, 1200080426
  %160 = add i32 %159, %117
  %161 = add i32 %160, %158
  %162 = shl i32 %161, 12
  %163 = lshr i32 %161, 20
  %164 = or i32 %163, %162
  %165 = add i32 %164, %153
  %166 = getelementptr inbounds i32, i32* %94, i64 6
  %167 = load i32, i32* %166, align 4
  %168 = xor i32 %153, %141
  %169 = and i32 %165, %168
  %170 = xor i32 %169, %141
  %171 = add i32 %167, -1473231341
  %172 = add i32 %171, %129
  %173 = add i32 %172, %170
  %174 = shl i32 %173, 17
  %175 = lshr i32 %173, 15
  %176 = or i32 %175, %174
  %177 = add i32 %176, %165
  %178 = getelementptr inbounds i32, i32* %94, i64 7
  %179 = load i32, i32* %178, align 4
  %180 = xor i32 %165, %153
  %181 = and i32 %177, %180
  %182 = xor i32 %181, %153
  %183 = add i32 %179, -45705983
  %184 = add i32 %183, %141
  %185 = add i32 %184, %182
  %186 = shl i32 %185, 22
  %187 = lshr i32 %185, 10
  %188 = or i32 %187, %186
  %189 = add i32 %188, %177
  %190 = getelementptr inbounds i32, i32* %94, i64 8
  %191 = load i32, i32* %190, align 4
  %192 = xor i32 %177, %165
  %193 = and i32 %189, %192
  %194 = xor i32 %193, %165
  %195 = add i32 %191, 1770035416
  %196 = add i32 %195, %153
  %197 = add i32 %196, %194
  %198 = shl i32 %197, 7
  %199 = lshr i32 %197, 25
  %200 = or i32 %199, %198
  %201 = add i32 %200, %189
  %202 = getelementptr inbounds i32, i32* %94, i64 9
  %203 = load i32, i32* %202, align 4
  %204 = xor i32 %189, %177
  %205 = and i32 %201, %204
  %206 = xor i32 %205, %177
  %207 = add i32 %203, -1958414417
  %208 = add i32 %207, %165
  %209 = add i32 %208, %206
  %210 = shl i32 %209, 12
  %211 = lshr i32 %209, 20
  %212 = or i32 %211, %210
  %213 = add i32 %212, %201
  %214 = getelementptr inbounds i32, i32* %94, i64 10
  %215 = load i32, i32* %214, align 4
  %216 = xor i32 %201, %189
  %217 = and i32 %213, %216
  %218 = xor i32 %217, %189
  %219 = add i32 %215, -42063
  %220 = add i32 %219, %177
  %221 = add i32 %220, %218
  %222 = shl i32 %221, 17
  %223 = lshr i32 %221, 15
  %224 = or i32 %223, %222
  %225 = add i32 %224, %213
  %226 = getelementptr inbounds i32, i32* %94, i64 11
  %227 = load i32, i32* %226, align 4
  %228 = xor i32 %213, %201
  %229 = and i32 %225, %228
  %230 = xor i32 %229, %201
  %231 = add i32 %227, -1990404162
  %232 = add i32 %231, %189
  %233 = add i32 %232, %230
  %234 = shl i32 %233, 22
  %235 = lshr i32 %233, 10
  %236 = or i32 %235, %234
  %237 = add i32 %236, %225
  %238 = getelementptr inbounds i32, i32* %94, i64 12
  %239 = load i32, i32* %238, align 4
  %240 = xor i32 %225, %213
  %241 = and i32 %237, %240
  %242 = xor i32 %241, %213
  %243 = add i32 %239, 1804603682
  %244 = add i32 %243, %201
  %245 = add i32 %244, %242
  %246 = shl i32 %245, 7
  %247 = lshr i32 %245, 25
  %248 = or i32 %247, %246
  %249 = add i32 %248, %237
  %250 = getelementptr inbounds i32, i32* %94, i64 13
  %251 = load i32, i32* %250, align 4
  %252 = xor i32 %237, %225
  %253 = and i32 %249, %252
  %254 = xor i32 %253, %225
  %255 = add i32 %251, -40341101
  %256 = add i32 %255, %213
  %257 = add i32 %256, %254
  %258 = shl i32 %257, 12
  %259 = lshr i32 %257, 20
  %260 = or i32 %259, %258
  %261 = add i32 %260, %249
  %262 = getelementptr inbounds i32, i32* %94, i64 14
  %263 = load i32, i32* %262, align 4
  %264 = xor i32 %249, %237
  %265 = and i32 %261, %264
  %266 = xor i32 %265, %237
  %267 = add i32 %263, -1502002290
  %268 = add i32 %267, %225
  %269 = add i32 %268, %266
  %270 = shl i32 %269, 17
  %271 = lshr i32 %269, 15
  %272 = or i32 %271, %270
  %273 = add i32 %272, %261
  %274 = getelementptr inbounds i32, i32* %94, i64 15
  %275 = load i32, i32* %274, align 4
  %276 = xor i32 %261, %249
  %277 = and i32 %273, %276
  %278 = xor i32 %277, %249
  %279 = add i32 %275, 1236535329
  %280 = add i32 %279, %237
  %281 = add i32 %280, %278
  %282 = shl i32 %281, 22
  %283 = lshr i32 %281, 10
  %284 = or i32 %283, %282
  %285 = add i32 %284, %273
  %286 = and i32 %285, %261
  %287 = xor i32 %261, -1
  %288 = and i32 %273, %287
  %289 = or i32 %286, %288
  %290 = add i32 %107, -165796510
  %291 = add i32 %290, %249
  %292 = add i32 %291, %289
  %293 = shl i32 %292, 5
  %294 = lshr i32 %292, 27
  %295 = or i32 %294, %293
  %296 = add i32 %295, %285
  %297 = and i32 %296, %273
  %298 = xor i32 %273, -1
  %299 = and i32 %285, %298
  %300 = or i32 %297, %299
  %301 = add i32 %167, -1069501632
  %302 = add i32 %301, %261
  %303 = add i32 %302, %300
  %304 = shl i32 %303, 9
  %305 = lshr i32 %303, 23
  %306 = or i32 %305, %304
  %307 = add i32 %306, %296
  %308 = and i32 %307, %285
  %309 = xor i32 %285, -1
  %310 = and i32 %296, %309
  %311 = or i32 %308, %310
  %312 = add i32 %227, 643717713
  %313 = add i32 %312, %273
  %314 = add i32 %313, %311
  %315 = shl i32 %314, 14
  %316 = lshr i32 %314, 18
  %317 = or i32 %316, %315
  %318 = add i32 %317, %307
  %319 = and i32 %318, %296
  %320 = xor i32 %296, -1
  %321 = and i32 %307, %320
  %322 = or i32 %319, %321
  %323 = add i32 %95, -373897302
  %324 = add i32 %323, %285
  %325 = add i32 %324, %322
  %326 = shl i32 %325, 20
  %327 = lshr i32 %325, 12
  %328 = or i32 %327, %326
  %329 = add i32 %328, %318
  %330 = and i32 %329, %307
  %331 = xor i32 %307, -1
  %332 = and i32 %318, %331
  %333 = or i32 %330, %332
  %334 = add i32 %155, -701558691
  %335 = add i32 %334, %296
  %336 = add i32 %335, %333
  %337 = shl i32 %336, 5
  %338 = lshr i32 %336, 27
  %339 = or i32 %338, %337
  %340 = add i32 %339, %329
  %341 = and i32 %340, %318
  %342 = xor i32 %318, -1
  %343 = and i32 %329, %342
  %344 = or i32 %341, %343
  %345 = add i32 %215, 38016083
  %346 = add i32 %345, %307
  %347 = add i32 %346, %344
  %348 = shl i32 %347, 9
  %349 = lshr i32 %347, 23
  %350 = or i32 %349, %348
  %351 = add i32 %350, %340
  %352 = and i32 %351, %329
  %353 = xor i32 %329, -1
  %354 = and i32 %340, %353
  %355 = or i32 %352, %354
  %356 = add i32 %275, -660478335
  %357 = add i32 %356, %318
  %358 = add i32 %357, %355
  %359 = shl i32 %358, 14
  %360 = lshr i32 %358, 18
  %361 = or i32 %360, %359
  %362 = add i32 %361, %351
  %363 = and i32 %362, %340
  %364 = xor i32 %340, -1
  %365 = and i32 %351, %364
  %366 = or i32 %363, %365
  %367 = add i32 %143, -405537848
  %368 = add i32 %367, %329
  %369 = add i32 %368, %366
  %370 = shl i32 %369, 20
  %371 = lshr i32 %369, 12
  %372 = or i32 %371, %370
  %373 = add i32 %372, %362
  %374 = and i32 %373, %351
  %375 = xor i32 %351, -1
  %376 = and i32 %362, %375
  %377 = or i32 %374, %376
  %378 = add i32 %203, 568446438
  %379 = add i32 %378, %340
  %380 = add i32 %379, %377
  %381 = shl i32 %380, 5
  %382 = lshr i32 %380, 27
  %383 = or i32 %382, %381
  %384 = add i32 %383, %373
  %385 = and i32 %384, %362
  %386 = xor i32 %362, -1
  %387 = and i32 %373, %386
  %388 = or i32 %385, %387
  %389 = add i32 %263, -1019803690
  %390 = add i32 %389, %351
  %391 = add i32 %390, %388
  %392 = shl i32 %391, 9
  %393 = lshr i32 %391, 23
  %394 = or i32 %393, %392
  %395 = add i32 %394, %384
  %396 = and i32 %395, %373
  %397 = xor i32 %373, -1
  %398 = and i32 %384, %397
  %399 = or i32 %396, %398
  %400 = add i32 %131, -187363961
  %401 = add i32 %400, %362
  %402 = add i32 %401, %399
  %403 = shl i32 %402, 14
  %404 = lshr i32 %402, 18
  %405 = or i32 %404, %403
  %406 = add i32 %405, %395
  %407 = and i32 %406, %384
  %408 = xor i32 %384, -1
  %409 = and i32 %395, %408
  %410 = or i32 %407, %409
  %411 = add i32 %191, 1163531501
  %412 = add i32 %411, %373
  %413 = add i32 %412, %410
  %414 = shl i32 %413, 20
  %415 = lshr i32 %413, 12
  %416 = or i32 %415, %414
  %417 = add i32 %416, %406
  %418 = and i32 %417, %395
  %419 = xor i32 %395, -1
  %420 = and i32 %406, %419
  %421 = or i32 %418, %420
  %422 = add i32 %251, -1444681467
  %423 = add i32 %422, %384
  %424 = add i32 %423, %421
  %425 = shl i32 %424, 5
  %426 = lshr i32 %424, 27
  %427 = or i32 %426, %425
  %428 = add i32 %427, %417
  %429 = and i32 %428, %406
  %430 = xor i32 %406, -1
  %431 = and i32 %417, %430
  %432 = or i32 %429, %431
  %433 = add i32 %119, -51403784
  %434 = add i32 %433, %395
  %435 = add i32 %434, %432
  %436 = shl i32 %435, 9
  %437 = lshr i32 %435, 23
  %438 = or i32 %437, %436
  %439 = add i32 %438, %428
  %440 = and i32 %439, %417
  %441 = xor i32 %417, -1
  %442 = and i32 %428, %441
  %443 = or i32 %440, %442
  %444 = add i32 %179, 1735328473
  %445 = add i32 %444, %406
  %446 = add i32 %445, %443
  %447 = shl i32 %446, 14
  %448 = lshr i32 %446, 18
  %449 = or i32 %448, %447
  %450 = add i32 %449, %439
  %451 = and i32 %450, %428
  %452 = xor i32 %428, -1
  %453 = and i32 %439, %452
  %454 = or i32 %451, %453
  %455 = add i32 %239, -1926607734
  %456 = add i32 %455, %417
  %457 = add i32 %456, %454
  %458 = shl i32 %457, 20
  %459 = lshr i32 %457, 12
  %460 = or i32 %459, %458
  %461 = add i32 %460, %450
  %462 = xor i32 %461, %450
  %463 = xor i32 %462, %439
  %464 = add i32 %155, -378558
  %465 = add i32 %464, %428
  %466 = add i32 %465, %463
  %467 = shl i32 %466, 4
  %468 = lshr i32 %466, 28
  %469 = or i32 %468, %467
  %470 = add i32 %469, %461
  %471 = xor i32 %462, %470
  %472 = add i32 %191, -2022574463
  %473 = add i32 %472, %439
  %474 = add i32 %473, %471
  %475 = shl i32 %474, 11
  %476 = lshr i32 %474, 21
  %477 = or i32 %476, %475
  %478 = add i32 %477, %470
  %479 = xor i32 %470, %461
  %480 = xor i32 %479, %478
  %481 = add i32 %227, 1839030562
  %482 = add i32 %481, %450
  %483 = add i32 %482, %480
  %484 = shl i32 %483, 16
  %485 = lshr i32 %483, 16
  %486 = or i32 %485, %484
  %487 = add i32 %486, %478
  %488 = xor i32 %478, %470
  %489 = xor i32 %488, %487
  %490 = add i32 %263, -35309556
  %491 = add i32 %490, %461
  %492 = add i32 %491, %489
  %493 = shl i32 %492, 23
  %494 = lshr i32 %492, 9
  %495 = or i32 %494, %493
  %496 = add i32 %495, %487
  %497 = xor i32 %487, %478
  %498 = xor i32 %497, %496
  %499 = add i32 %107, -1530992060
  %500 = add i32 %499, %470
  %501 = add i32 %500, %498
  %502 = shl i32 %501, 4
  %503 = lshr i32 %501, 28
  %504 = or i32 %503, %502
  %505 = add i32 %504, %496
  %506 = xor i32 %496, %487
  %507 = xor i32 %506, %505
  %508 = add i32 %143, 1272893353
  %509 = add i32 %508, %478
  %510 = add i32 %509, %507
  %511 = shl i32 %510, 11
  %512 = lshr i32 %510, 21
  %513 = or i32 %512, %511
  %514 = add i32 %513, %505
  %515 = xor i32 %505, %496
  %516 = xor i32 %515, %514
  %517 = add i32 %179, -155497632
  %518 = add i32 %517, %487
  %519 = add i32 %518, %516
  %520 = shl i32 %519, 16
  %521 = lshr i32 %519, 16
  %522 = or i32 %521, %520
  %523 = add i32 %522, %514
  %524 = xor i32 %514, %505
  %525 = xor i32 %524, %523
  %526 = add i32 %215, -1094730640
  %527 = add i32 %526, %496
  %528 = add i32 %527, %525
  %529 = shl i32 %528, 23
  %530 = lshr i32 %528, 9
  %531 = or i32 %530, %529
  %532 = add i32 %531, %523
  %533 = xor i32 %523, %514
  %534 = xor i32 %533, %532
  %535 = add i32 %251, 681279174
  %536 = add i32 %535, %505
  %537 = add i32 %536, %534
  %538 = shl i32 %537, 4
  %539 = lshr i32 %537, 28
  %540 = or i32 %539, %538
  %541 = add i32 %540, %532
  %542 = xor i32 %532, %523
  %543 = xor i32 %542, %541
  %544 = add i32 %95, -358537222
  %545 = add i32 %544, %514
  %546 = add i32 %545, %543
  %547 = shl i32 %546, 11
  %548 = lshr i32 %546, 21
  %549 = or i32 %548, %547
  %550 = add i32 %549, %541
  %551 = xor i32 %541, %532
  %552 = xor i32 %551, %550
  %553 = add i32 %131, -722521979
  %554 = add i32 %553, %523
  %555 = add i32 %554, %552
  %556 = shl i32 %555, 16
  %557 = lshr i32 %555, 16
  %558 = or i32 %557, %556
  %559 = add i32 %558, %550
  %560 = xor i32 %550, %541
  %561 = xor i32 %560, %559
  %562 = add i32 %167, 76029189
  %563 = add i32 %562, %532
  %564 = add i32 %563, %561
  %565 = shl i32 %564, 23
  %566 = lshr i32 %564, 9
  %567 = or i32 %566, %565
  %568 = add i32 %567, %559
  %569 = xor i32 %559, %550
  %570 = xor i32 %569, %568
  %571 = add i32 %203, -640364487
  %572 = add i32 %571, %541
  %573 = add i32 %572, %570
  %574 = shl i32 %573, 4
  %575 = lshr i32 %573, 28
  %576 = or i32 %575, %574
  %577 = add i32 %576, %568
  %578 = xor i32 %568, %559
  %579 = xor i32 %578, %577
  %580 = add i32 %239, -421815835
  %581 = add i32 %580, %550
  %582 = add i32 %581, %579
  %583 = shl i32 %582, 11
  %584 = lshr i32 %582, 21
  %585 = or i32 %584, %583
  %586 = add i32 %585, %577
  %587 = xor i32 %577, %568
  %588 = xor i32 %587, %586
  %589 = add i32 %275, 530742520
  %590 = add i32 %589, %559
  %591 = add i32 %590, %588
  %592 = shl i32 %591, 16
  %593 = lshr i32 %591, 16
  %594 = or i32 %593, %592
  %595 = add i32 %594, %586
  %596 = xor i32 %586, %577
  %597 = xor i32 %596, %595
  %598 = add i32 %119, -995338651
  %599 = add i32 %598, %568
  %600 = add i32 %599, %597
  %601 = shl i32 %600, 23
  %602 = lshr i32 %600, 9
  %603 = or i32 %602, %601
  %604 = add i32 %603, %595
  %605 = xor i32 %586, -1
  %606 = or i32 %604, %605
  %607 = xor i32 %606, %595
  %608 = add i32 %95, -198630844
  %609 = add i32 %608, %577
  %610 = add i32 %609, %607
  %611 = shl i32 %610, 6
  %612 = lshr i32 %610, 26
  %613 = or i32 %612, %611
  %614 = add i32 %613, %604
  %615 = xor i32 %595, -1
  %616 = or i32 %614, %615
  %617 = xor i32 %616, %604
  %618 = add i32 %179, 1126891415
  %619 = add i32 %618, %586
  %620 = add i32 %619, %617
  %621 = shl i32 %620, 10
  %622 = lshr i32 %620, 22
  %623 = or i32 %622, %621
  %624 = add i32 %623, %614
  %625 = xor i32 %604, -1
  %626 = or i32 %624, %625
  %627 = xor i32 %626, %614
  %628 = add i32 %263, -1416354905
  %629 = add i32 %628, %595
  %630 = add i32 %629, %627
  %631 = shl i32 %630, 15
  %632 = lshr i32 %630, 17
  %633 = or i32 %632, %631
  %634 = add i32 %633, %624
  %635 = xor i32 %614, -1
  %636 = or i32 %634, %635
  %637 = xor i32 %636, %624
  %638 = add i32 %155, -57434055
  %639 = add i32 %638, %604
  %640 = add i32 %639, %637
  %641 = shl i32 %640, 21
  %642 = lshr i32 %640, 11
  %643 = or i32 %642, %641
  %644 = add i32 %643, %634
  %645 = xor i32 %624, -1
  %646 = or i32 %644, %645
  %647 = xor i32 %646, %634
  %648 = add i32 %239, 1700485571
  %649 = add i32 %648, %614
  %650 = add i32 %649, %647
  %651 = shl i32 %650, 6
  %652 = lshr i32 %650, 26
  %653 = or i32 %652, %651
  %654 = add i32 %653, %644
  %655 = xor i32 %634, -1
  %656 = or i32 %654, %655
  %657 = xor i32 %656, %644
  %658 = add i32 %131, -1894986606
  %659 = add i32 %658, %624
  %660 = add i32 %659, %657
  %661 = shl i32 %660, 10
  %662 = lshr i32 %660, 22
  %663 = or i32 %662, %661
  %664 = add i32 %663, %654
  %665 = xor i32 %644, -1
  %666 = or i32 %664, %665
  %667 = xor i32 %666, %654
  %668 = add i32 %215, -1051523
  %669 = add i32 %668, %634
  %670 = add i32 %669, %667
  %671 = shl i32 %670, 15
  %672 = lshr i32 %670, 17
  %673 = or i32 %672, %671
  %674 = add i32 %673, %664
  %675 = xor i32 %654, -1
  %676 = or i32 %674, %675
  %677 = xor i32 %676, %664
  %678 = add i32 %107, -2054922799
  %679 = add i32 %678, %644
  %680 = add i32 %679, %677
  %681 = shl i32 %680, 21
  %682 = lshr i32 %680, 11
  %683 = or i32 %682, %681
  %684 = add i32 %683, %674
  %685 = xor i32 %664, -1
  %686 = or i32 %684, %685
  %687 = xor i32 %686, %674
  %688 = add i32 %191, 1873313359
  %689 = add i32 %688, %654
  %690 = add i32 %689, %687
  %691 = shl i32 %690, 6
  %692 = lshr i32 %690, 26
  %693 = or i32 %692, %691
  %694 = add i32 %693, %684
  %695 = xor i32 %674, -1
  %696 = or i32 %694, %695
  %697 = xor i32 %696, %684
  %698 = add i32 %275, -30611744
  %699 = add i32 %698, %664
  %700 = add i32 %699, %697
  %701 = shl i32 %700, 10
  %702 = lshr i32 %700, 22
  %703 = or i32 %702, %701
  %704 = add i32 %703, %694
  %705 = xor i32 %684, -1
  %706 = or i32 %704, %705
  %707 = xor i32 %706, %694
  %708 = add i32 %167, -1560198380
  %709 = add i32 %708, %674
  %710 = add i32 %709, %707
  %711 = shl i32 %710, 15
  %712 = lshr i32 %710, 17
  %713 = or i32 %712, %711
  %714 = add i32 %713, %704
  %715 = xor i32 %694, -1
  %716 = or i32 %714, %715
  %717 = xor i32 %716, %704
  %718 = add i32 %251, 1309151649
  %719 = add i32 %718, %684
  %720 = add i32 %719, %717
  %721 = shl i32 %720, 21
  %722 = lshr i32 %720, 11
  %723 = or i32 %722, %721
  %724 = add i32 %723, %714
  %725 = xor i32 %704, -1
  %726 = or i32 %724, %725
  %727 = xor i32 %726, %714
  %728 = add i32 %143, -145523070
  %729 = add i32 %728, %694
  %730 = add i32 %729, %727
  %731 = shl i32 %730, 6
  %732 = lshr i32 %730, 26
  %733 = or i32 %732, %731
  %734 = add i32 %733, %724
  %735 = xor i32 %714, -1
  %736 = or i32 %734, %735
  %737 = xor i32 %736, %724
  %738 = add i32 %227, -1120210379
  %739 = add i32 %738, %704
  %740 = add i32 %739, %737
  %741 = shl i32 %740, 10
  %742 = lshr i32 %740, 22
  %743 = or i32 %742, %741
  %744 = add i32 %743, %734
  %745 = xor i32 %724, -1
  %746 = or i32 %744, %745
  %747 = xor i32 %746, %734
  %748 = add i32 %119, 718787259
  %749 = add i32 %748, %714
  %750 = add i32 %749, %747
  %751 = shl i32 %750, 15
  %752 = lshr i32 %750, 17
  %753 = or i32 %752, %751
  %754 = add i32 %753, %744
  %755 = xor i32 %734, -1
  %756 = or i32 %754, %755
  %757 = xor i32 %756, %744
  %758 = add i32 %203, -343485551
  %759 = add i32 %758, %724
  %760 = add i32 %759, %757
  %761 = shl i32 %760, 21
  %762 = lshr i32 %760, 11
  %763 = or i32 %762, %761
  %764 = add i32 %734, %4
  store i32 %764, i32* %0, align 4
  %765 = add i32 %754, %6
  %766 = add i32 %765, %763
  store i32 %766, i32* %5, align 4
  %767 = add i32 %754, %8
  store i32 %767, i32* %7, align 4
  %768 = add i32 %744, %10
  store i32 %768, i32* %9, align 4
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %11) #7
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #2

; Function Attrs: nounwind ssp uwtable
define hidden { i64, i64 } @_ZN5SkMD56finishEv(%class.SkMD5*) local_unnamed_addr #1 align 2 {
  %2 = alloca i64, align 8
  %3 = bitcast i64* %2 to [8 x i8]*
  %4 = bitcast i64* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %4) #7
  %5 = getelementptr inbounds [8 x i8], [8 x i8]* %3, i64 0, i64 1
  %6 = getelementptr inbounds [8 x i8], [8 x i8]* %3, i64 0, i64 2
  %7 = getelementptr inbounds [8 x i8], [8 x i8]* %3, i64 0, i64 3
  %8 = getelementptr inbounds [8 x i8], [8 x i8]* %3, i64 0, i64 4
  %9 = getelementptr inbounds [8 x i8], [8 x i8]* %3, i64 0, i64 5
  %10 = getelementptr inbounds [8 x i8], [8 x i8]* %3, i64 0, i64 6
  %11 = getelementptr inbounds [8 x i8], [8 x i8]* %3, i64 0, i64 7
  %12 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 1
  %13 = load i64, i64* %12, align 8
  %14 = trunc i64 %13 to i8
  %15 = shl i8 %14, 3
  store i8 %15, i8* %4, align 8
  %16 = lshr i64 %13, 5
  %17 = trunc i64 %16 to i8
  store i8 %17, i8* %5, align 1
  %18 = lshr i64 %13, 13
  %19 = trunc i64 %18 to i8
  store i8 %19, i8* %6, align 2
  %20 = lshr i64 %13, 21
  %21 = trunc i64 %20 to i8
  store i8 %21, i8* %7, align 1
  %22 = lshr i64 %13, 29
  %23 = trunc i64 %22 to i8
  store i8 %23, i8* %8, align 4
  %24 = lshr i64 %13, 37
  %25 = trunc i64 %24 to i8
  store i8 %25, i8* %9, align 1
  %26 = lshr i64 %13, 45
  %27 = trunc i64 %26 to i8
  store i8 %27, i8* %10, align 2
  %28 = lshr i64 %13, 53
  %29 = trunc i64 %28 to i8
  store i8 %29, i8* %11, align 1
  %30 = trunc i64 %13 to i32
  %31 = and i32 %30, 63
  %32 = icmp ult i32 %31, 56
  %33 = select i1 %32, i32 56, i32 120
  %34 = sub nsw i32 %33, %31
  %35 = zext i32 %34 to i64
  %36 = sub nuw nsw i32 64, %31
  %37 = zext i32 %36 to i64
  %38 = icmp ugt i32 %36, %34
  br i1 %38, label %59, label %39

39:                                               ; preds = %1
  %40 = icmp eq i32 %31, 0
  br i1 %40, label %46, label %41

41:                                               ; preds = %39
  %42 = zext i32 %31 to i64
  %43 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 3, i64 %42
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %43, i8* align 16 getelementptr inbounds (<{ i8, [63 x i8] }>, <{ i8, [63 x i8] }>* @_ZZN5SkMD56finishEvE7PADDING, i64 0, i32 0), i64 %37, i1 false) #7
  %44 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 2, i64 0
  %45 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 3, i64 0
  tail call fastcc void @_ZL9transformPjPKh(i32* %44, i8* %45) #7
  br label %46

46:                                               ; preds = %41, %39
  %47 = phi i32 [ %36, %41 ], [ 0, %39 ]
  %48 = add nuw nsw i32 %47, 63
  %49 = icmp ult i32 %48, %34
  br i1 %49, label %50, label %61

50:                                               ; preds = %46
  %51 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 2, i64 0
  br label %52

52:                                               ; preds = %52, %50
  %53 = phi i32 [ %47, %50 ], [ %56, %52 ]
  %54 = zext i32 %53 to i64
  %55 = getelementptr inbounds i8, i8* getelementptr inbounds (<{ i8, [63 x i8] }>, <{ i8, [63 x i8] }>* @_ZZN5SkMD56finishEvE7PADDING, i64 0, i32 0), i64 %54
  tail call fastcc void @_ZL9transformPjPKh(i32* %51, i8* %55) #7
  %56 = add i32 %53, 64
  %57 = add i32 %53, 127
  %58 = icmp ult i32 %57, %34
  br i1 %58, label %52, label %61

59:                                               ; preds = %1
  %60 = zext i32 %31 to i64
  br label %61

61:                                               ; preds = %52, %46, %59
  %62 = phi i64 [ %60, %59 ], [ 0, %46 ], [ 0, %52 ]
  %63 = phi i32 [ 0, %59 ], [ %47, %46 ], [ %56, %52 ]
  %64 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 3, i64 %62
  %65 = zext i32 %63 to i64
  %66 = getelementptr inbounds i8, i8* getelementptr inbounds (<{ i8, [63 x i8] }>, <{ i8, [63 x i8] }>* @_ZZN5SkMD56finishEvE7PADDING, i64 0, i32 0), i64 %65
  %67 = sub nsw i64 %35, %65
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %64, i8* align 1 %66, i64 %67, i1 false) #7
  %68 = load i64, i64* %12, align 8
  %69 = add i64 %68, %35
  store i64 %69, i64* %12, align 8
  %70 = trunc i64 %69 to i32
  %71 = and i32 %70, 63
  %72 = icmp ult i32 %71, 56
  %73 = zext i32 %71 to i64
  br i1 %72, label %81, label %74

74:                                               ; preds = %61
  %75 = sub nuw nsw i32 64, %71
  %76 = zext i32 %75 to i64
  %77 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 3, i64 %73
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %77, i8* nonnull align 8 %4, i64 %76, i1 false) #7
  %78 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 2, i64 0
  %79 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 3, i64 0
  tail call fastcc void @_ZL9transformPjPKh(i32* %78, i8* %79) #7
  %80 = load i64, i64* %12, align 8
  br label %81

81:                                               ; preds = %61, %74
  %82 = phi i64 [ %80, %74 ], [ %69, %61 ]
  %83 = phi i64 [ 0, %74 ], [ %73, %61 ]
  %84 = phi i64 [ %76, %74 ], [ 0, %61 ]
  %85 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 3, i64 %83
  %86 = getelementptr inbounds [8 x i8], [8 x i8]* %3, i64 0, i64 %84
  %87 = sub nuw nsw i64 8, %84
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %85, i8* align 1 %86, i64 %87, i1 false) #7
  %88 = add i64 %82, 8
  store i64 %88, i64* %12, align 8
  %89 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 2, i64 0
  %90 = load i32, i32* %89, align 4
  %91 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 2, i64 1
  %92 = load i32, i32* %91, align 4
  %93 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 2, i64 2
  %94 = load i32, i32* %93, align 4
  %95 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 2, i64 3
  %96 = load i32, i32* %95, align 4
  %97 = insertelement <2 x i32> undef, i32 %92, i32 0
  %98 = insertelement <2 x i32> %97, i32 %96, i32 1
  %99 = lshr <2 x i32> %98, <i32 8, i32 8>
  %100 = lshr <2 x i32> %98, <i32 16, i32 16>
  %101 = lshr <2 x i32> %98, <i32 24, i32 24>
  %102 = zext <2 x i32> %101 to <2 x i64>
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %4) #7
  %103 = shl nuw <2 x i64> %102, <i64 56, i64 56>
  %104 = and <2 x i32> %100, <i32 255, i32 255>
  %105 = zext <2 x i32> %104 to <2 x i64>
  %106 = shl nuw nsw <2 x i64> %105, <i64 48, i64 48>
  %107 = and <2 x i32> %99, <i32 255, i32 255>
  %108 = zext <2 x i32> %107 to <2 x i64>
  %109 = shl nuw nsw <2 x i64> %108, <i64 40, i64 40>
  %110 = and <2 x i32> %98, <i32 255, i32 255>
  %111 = zext <2 x i32> %110 to <2 x i64>
  %112 = shl nuw nsw <2 x i64> %111, <i64 32, i64 32>
  %113 = insertelement <2 x i32> undef, i32 %90, i32 0
  %114 = insertelement <2 x i32> %113, i32 %94, i32 1
  %115 = zext <2 x i32> %114 to <2 x i64>
  %116 = or <2 x i64> %103, %115
  %117 = or <2 x i64> %116, %112
  %118 = or <2 x i64> %117, %106
  %119 = or <2 x i64> %118, %109
  %120 = extractelement <2 x i64> %119, i32 0
  %121 = insertvalue { i64, i64 } undef, i64 %120, 0
  %122 = extractelement <2 x i64> %119, i32 1
  %123 = insertvalue { i64, i64 } %121, i64 %122, 1
  ret { i64, i64 } %123
}

; Function Attrs: nounwind
declare void @_ZN9SkWStreamD2Ev(%class.SkWStream*) unnamed_addr #3

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5SkMD5D0Ev(%class.SkMD5*) unnamed_addr #4 comdat align 2 {
  %2 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 0
  tail call void @_ZN9SkWStreamD2Ev(%class.SkWStream* %2) #7
  %3 = bitcast %class.SkMD5* %0 to i8*
  tail call void @_ZdlPv(i8* %3) #8
  ret void
}

declare void @_ZN9SkWStream5flushEv(%class.SkWStream*) unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZNK5SkMD512bytesWrittenEv(%class.SkMD5*) unnamed_addr #1 comdat align 2 {
  %2 = getelementptr inbounds %class.SkMD5, %class.SkMD5* %0, i64 0, i32 1
  %3 = load i64, i64* %2, align 8
  ret i64 %3
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #2

; Function Attrs: nobuiltin nounwind
declare void @_ZdlPv(i8*) local_unnamed_addr #6

attributes #0 = { nofree norecurse nounwind ssp uwtable writeonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { argmemonly nounwind }
attributes #3 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nobuiltin nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { nounwind }
attributes #8 = { builtin nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
