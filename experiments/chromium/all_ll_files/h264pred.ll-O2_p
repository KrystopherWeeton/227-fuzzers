; ModuleID = '../../third_party/ffmpeg/libavcodec/h264pred.c'
source_filename = "../../third_party/ffmpeg/libavcodec/h264pred.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"
module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"
module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%struct.H264PredContext = type { [15 x void (i8*, i8*, i64)*], [12 x void (i8*, i32, i32, i64)*], [11 x void (i8*, i64)*], [9 x void (i8*, i64)*], [2 x void (i8*, i16*, i64)*], [2 x void (i8*, i16*, i64)*], [2 x void (i8*, i16*, i32, i32, i64)*], [3 x void (i8*, i32*, i16*, i64)*], [3 x void (i8*, i32*, i16*, i64)*] }

@.str = private unnamed_addr constant [30 x i8] c"Assertion %s failed at %s:%d\0A\00", align 1
@.str.1 = private unnamed_addr constant [13 x i8] c"bit_depth<=8\00", align 1
@.str.2 = private unnamed_addr constant [47 x i8] c"../../third_party/ffmpeg/libavcodec/h264pred.c\00", align 1
@ff_crop_tab = external local_unnamed_addr constant [2304 x i8], align 16

; Function Attrs: cold nounwind optsize ssp uwtable
define hidden void @ff_h264_pred_init(%struct.H264PredContext*, i32, i32, i32) local_unnamed_addr #0 {
  switch i32 %2, label %497 [
    i32 9, label %5
    i32 10, label %128
    i32 12, label %251
    i32 14, label %374
  ]

5:                                                ; preds = %4
  %6 = icmp eq i32 %1, 69
  br i1 %6, label %36, label %7

7:                                                ; preds = %5
  %8 = icmp eq i32 %1, 179
  %9 = icmp eq i32 %1, 139
  %10 = or i1 %8, %9
  switch i32 %1, label %11 [
    i32 179, label %12
    i32 139, label %12
  ]

11:                                               ; preds = %7
  br label %12

12:                                               ; preds = %7, %7, %11
  %13 = phi <2 x void (i8*, i8*, i64)*> [ <void (i8*, i8*, i64)* @pred4x4_vertical_9_c, void (i8*, i8*, i64)* @pred4x4_horizontal_9_c>, %11 ], [ <void (i8*, i8*, i64)* @pred4x4_vertical_vp8_c, void (i8*, i8*, i64)* @pred4x4_horizontal_vp8_c>, %7 ], [ <void (i8*, i8*, i64)* @pred4x4_vertical_vp8_c, void (i8*, i8*, i64)* @pred4x4_horizontal_vp8_c>, %7 ]
  %14 = bitcast %struct.H264PredContext* %0 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> %13, <2 x void (i8*, i8*, i64)*>* %14, align 8
  %15 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 2
  store void (i8*, i8*, i64)* @pred4x4_dc_9_c, void (i8*, i8*, i64)** %15, align 8
  %16 = icmp eq i32 %1, 23
  %17 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 3
  %18 = select i1 %16, void (i8*, i8*, i64)* @pred4x4_down_left_svq3_c, void (i8*, i8*, i64)* @pred4x4_down_left_9_c
  store void (i8*, i8*, i64)* %18, void (i8*, i8*, i64)** %17, align 8
  %19 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 4
  %20 = bitcast void (i8*, i8*, i64)** %19 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_right_9_c, void (i8*, i8*, i64)* @pred4x4_vertical_right_9_c>, <2 x void (i8*, i8*, i64)*>* %20, align 8
  %21 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 6
  store void (i8*, i8*, i64)* @pred4x4_horizontal_down_9_c, void (i8*, i8*, i64)** %21, align 8
  %22 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 7
  %23 = select i1 %10, void (i8*, i8*, i64)* @pred4x4_vertical_left_vp8_c, void (i8*, i8*, i64)* @pred4x4_vertical_left_9_c
  store void (i8*, i8*, i64)* %23, void (i8*, i8*, i64)** %22, align 8
  %24 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 8
  store void (i8*, i8*, i64)* @pred4x4_horizontal_up_9_c, void (i8*, i8*, i64)** %24, align 8
  %25 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 9
  switch i32 %1, label %26 [
    i32 179, label %28
    i32 139, label %28
  ]

26:                                               ; preds = %12
  %27 = bitcast void (i8*, i8*, i64)** %25 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_left_dc_9_c, void (i8*, i8*, i64)* @pred4x4_top_dc_9_c>, <2 x void (i8*, i8*, i64)*>* %27, align 8
  br label %33

28:                                               ; preds = %12, %12
  %29 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 12
  %30 = bitcast void (i8*, i8*, i64)** %29 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_127_dc_9_c, void (i8*, i8*, i64)* @pred4x4_129_dc_9_c>, <2 x void (i8*, i8*, i64)*>* %30, align 8
  %31 = bitcast void (i8*, i8*, i64)** %25 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_tm_vp8_c, void (i8*, i8*, i64)* @pred4x4_vertical_9_c>, <2 x void (i8*, i8*, i64)*>* %31, align 8
  %32 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 14
  store void (i8*, i8*, i64)* @pred4x4_horizontal_9_c, void (i8*, i8*, i64)** %32, align 8
  br label %33

33:                                               ; preds = %28, %26
  br i1 %9, label %51, label %34

34:                                               ; preds = %33
  %35 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 11
  store void (i8*, i8*, i64)* @pred4x4_128_dc_9_c, void (i8*, i8*, i64)** %35, align 8
  br label %51

36:                                               ; preds = %5
  %37 = bitcast %struct.H264PredContext* %0 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_vertical_9_c, void (i8*, i8*, i64)* @pred4x4_horizontal_9_c>, <2 x void (i8*, i8*, i64)*>* %37, align 8
  %38 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 2
  %39 = bitcast void (i8*, i8*, i64)** %38 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_dc_9_c, void (i8*, i8*, i64)* @pred4x4_down_left_rv40_c>, <2 x void (i8*, i8*, i64)*>* %39, align 8
  %40 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 4
  %41 = bitcast void (i8*, i8*, i64)** %40 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_right_9_c, void (i8*, i8*, i64)* @pred4x4_vertical_right_9_c>, <2 x void (i8*, i8*, i64)*>* %41, align 8
  %42 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 6
  %43 = bitcast void (i8*, i8*, i64)** %42 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_horizontal_down_9_c, void (i8*, i8*, i64)* @pred4x4_vertical_left_rv40_c>, <2 x void (i8*, i8*, i64)*>* %43, align 8
  %44 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 8
  %45 = bitcast void (i8*, i8*, i64)** %44 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_horizontal_up_rv40_c, void (i8*, i8*, i64)* @pred4x4_left_dc_9_c>, <2 x void (i8*, i8*, i64)*>* %45, align 8
  %46 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 10
  %47 = bitcast void (i8*, i8*, i64)** %46 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_top_dc_9_c, void (i8*, i8*, i64)* @pred4x4_128_dc_9_c>, <2 x void (i8*, i8*, i64)*>* %47, align 8
  %48 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 12
  %49 = bitcast void (i8*, i8*, i64)** %48 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_left_rv40_nodown_c, void (i8*, i8*, i64)* @pred4x4_horizontal_up_rv40_nodown_c>, <2 x void (i8*, i8*, i64)*>* %49, align 8
  %50 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 14
  store void (i8*, i8*, i64)* @pred4x4_vertical_left_rv40_nodown_c, void (i8*, i8*, i64)** %50, align 8
  br label %51

51:                                               ; preds = %33, %34, %36
  %52 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 0
  %53 = bitcast void (i8*, i32, i32, i64)** %52 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_vertical_9_c, void (i8*, i32, i32, i64)* @pred8x8l_horizontal_9_c>, <2 x void (i8*, i32, i32, i64)*>* %53, align 8
  %54 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 2
  %55 = bitcast void (i8*, i32, i32, i64)** %54 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_dc_9_c, void (i8*, i32, i32, i64)* @pred8x8l_down_left_9_c>, <2 x void (i8*, i32, i32, i64)*>* %55, align 8
  %56 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 4
  %57 = bitcast void (i8*, i32, i32, i64)** %56 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_down_right_9_c, void (i8*, i32, i32, i64)* @pred8x8l_vertical_right_9_c>, <2 x void (i8*, i32, i32, i64)*>* %57, align 8
  %58 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 6
  %59 = bitcast void (i8*, i32, i32, i64)** %58 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_horizontal_down_9_c, void (i8*, i32, i32, i64)* @pred8x8l_vertical_left_9_c>, <2 x void (i8*, i32, i32, i64)*>* %59, align 8
  %60 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 8
  %61 = bitcast void (i8*, i32, i32, i64)** %60 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_horizontal_up_9_c, void (i8*, i32, i32, i64)* @pred8x8l_left_dc_9_c>, <2 x void (i8*, i32, i32, i64)*>* %61, align 8
  %62 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 10
  %63 = bitcast void (i8*, i32, i32, i64)** %62 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_top_dc_9_c, void (i8*, i32, i32, i64)* @pred8x8l_128_dc_9_c>, <2 x void (i8*, i32, i32, i64)*>* %63, align 8
  %64 = icmp slt i32 %3, 2
  %65 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2
  %66 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 2
  %67 = select i1 %64, void (i8*, i64)* @pred8x8_vertical_9_c, void (i8*, i64)* @pred8x16_vertical_9_c
  %68 = select i1 %64, void (i8*, i64)* @pred8x8_horizontal_9_c, void (i8*, i64)* @pred8x16_horizontal_9_c
  store void (i8*, i64)* %67, void (i8*, i64)** %66, align 8
  %69 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 1
  store void (i8*, i64)* %68, void (i8*, i64)** %69, align 8
  switch i32 %1, label %70 [
    i32 179, label %74
    i32 139, label %74
  ]

70:                                               ; preds = %51
  %71 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 3
  br i1 %64, label %72, label %73

72:                                               ; preds = %70
  store void (i8*, i64)* @pred8x8_plane_9_c, void (i8*, i64)** %71, align 8
  br label %76

73:                                               ; preds = %70
  store void (i8*, i64)* @pred8x16_plane_9_c, void (i8*, i64)** %71, align 8
  br label %76

74:                                               ; preds = %51, %51
  %75 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 3
  store void (i8*, i64)* @pred8x8_tm_vp8_c, void (i8*, i64)** %75, align 8
  br label %76

76:                                               ; preds = %72, %73, %74
  switch i32 %1, label %77 [
    i32 179, label %93
    i32 139, label %93
    i32 69, label %93
  ]

77:                                               ; preds = %76
  %78 = getelementptr inbounds [11 x void (i8*, i64)*], [11 x void (i8*, i64)*]* %65, i64 0, i64 0
  br i1 %64, label %79, label %86

79:                                               ; preds = %77
  store void (i8*, i64)* @pred8x8_dc_9_c, void (i8*, i64)** %78, align 8
  %80 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %81 = bitcast void (i8*, i64)** %80 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_left_dc_9_c, void (i8*, i64)* @pred8x8_top_dc_9_c>, <2 x void (i8*, i64)*>* %81, align 8
  %82 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %83 = bitcast void (i8*, i64)** %82 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_mad_cow_dc_l0t_9, void (i8*, i64)* @pred8x8_mad_cow_dc_0lt_9>, <2 x void (i8*, i64)*>* %83, align 8
  %84 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 9
  %85 = bitcast void (i8*, i64)** %84 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_mad_cow_dc_l00_9, void (i8*, i64)* @pred8x8_mad_cow_dc_0l0_9>, <2 x void (i8*, i64)*>* %85, align 8
  br label %100

86:                                               ; preds = %77
  store void (i8*, i64)* @pred8x16_dc_9_c, void (i8*, i64)** %78, align 8
  %87 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %88 = bitcast void (i8*, i64)** %87 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_left_dc_9_c, void (i8*, i64)* @pred8x16_top_dc_9_c>, <2 x void (i8*, i64)*>* %88, align 8
  %89 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %90 = bitcast void (i8*, i64)** %89 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_mad_cow_dc_l0t_9, void (i8*, i64)* @pred8x16_mad_cow_dc_0lt_9>, <2 x void (i8*, i64)*>* %90, align 8
  %91 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 9
  %92 = bitcast void (i8*, i64)** %91 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_mad_cow_dc_l00_9, void (i8*, i64)* @pred8x16_mad_cow_dc_0l0_9>, <2 x void (i8*, i64)*>* %92, align 8
  br label %100

93:                                               ; preds = %76, %76, %76
  %94 = getelementptr inbounds [11 x void (i8*, i64)*], [11 x void (i8*, i64)*]* %65, i64 0, i64 0
  store void (i8*, i64)* @pred8x8_dc_rv40_c, void (i8*, i64)** %94, align 8
  %95 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %96 = bitcast void (i8*, i64)** %95 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_left_dc_rv40_c, void (i8*, i64)* @pred8x8_top_dc_rv40_c>, <2 x void (i8*, i64)*>* %96, align 8
  switch i32 %1, label %100 [
    i32 179, label %97
    i32 139, label %97
  ]

97:                                               ; preds = %93, %93
  %98 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %99 = bitcast void (i8*, i64)** %98 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_127_dc_9_c, void (i8*, i64)* @pred8x8_129_dc_9_c>, <2 x void (i8*, i64)*>* %99, align 8
  br label %100

100:                                              ; preds = %93, %97, %79, %86
  %101 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 6
  %102 = select i1 %64, void (i8*, i64)* @pred8x8_128_dc_9_c, void (i8*, i64)* @pred8x16_128_dc_9_c
  store void (i8*, i64)* %102, void (i8*, i64)** %101, align 8
  %103 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 0
  %104 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 2
  store void (i8*, i64)* @pred16x16_vertical_9_c, void (i8*, i64)** %104, align 8
  %105 = bitcast void (i8*, i64)** %103 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_dc_9_c, void (i8*, i64)* @pred16x16_horizontal_9_c>, <2 x void (i8*, i64)*>* %105, align 8
  switch i32 %1, label %114 [
    i32 23, label %106
    i32 69, label %108
    i32 179, label %110
    i32 139, label %110
  ]

106:                                              ; preds = %100
  %107 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_svq3_c, void (i8*, i64)** %107, align 8
  br label %116

108:                                              ; preds = %100
  %109 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_rv40_c, void (i8*, i64)** %109, align 8
  br label %116

110:                                              ; preds = %100, %100
  %111 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_tm_vp8_c, void (i8*, i64)** %111, align 8
  %112 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 7
  %113 = bitcast void (i8*, i64)** %112 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_127_dc_9_c, void (i8*, i64)* @pred16x16_129_dc_9_c>, <2 x void (i8*, i64)*>* %113, align 8
  br label %116

114:                                              ; preds = %100
  %115 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_9_c, void (i8*, i64)** %115, align 8
  br label %116

116:                                              ; preds = %114, %110, %108, %106
  %117 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 4
  %118 = bitcast void (i8*, i64)** %117 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_left_dc_9_c, void (i8*, i64)* @pred16x16_top_dc_9_c>, <2 x void (i8*, i64)*>* %118, align 8
  %119 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 6
  store void (i8*, i64)* @pred16x16_128_dc_9_c, void (i8*, i64)** %119, align 8
  %120 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 4, i64 0
  %121 = bitcast void (i8*, i16*, i64)** %120 to <2 x void (i8*, i16*, i64)*>*
  store <2 x void (i8*, i16*, i64)*> <void (i8*, i16*, i64)* @pred4x4_vertical_add_9_c, void (i8*, i16*, i64)* @pred4x4_horizontal_add_9_c>, <2 x void (i8*, i16*, i64)*>* %121, align 8
  %122 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 5, i64 0
  %123 = bitcast void (i8*, i16*, i64)** %122 to <2 x void (i8*, i16*, i64)*>*
  store <2 x void (i8*, i16*, i64)*> <void (i8*, i16*, i64)* @pred8x8l_vertical_add_9_c, void (i8*, i16*, i64)* @pred8x8l_horizontal_add_9_c>, <2 x void (i8*, i16*, i64)*>* %123, align 8
  %124 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 6, i64 0
  %125 = bitcast void (i8*, i16*, i32, i32, i64)** %124 to <2 x void (i8*, i16*, i32, i32, i64)*>*
  store <2 x void (i8*, i16*, i32, i32, i64)*> <void (i8*, i16*, i32, i32, i64)* @pred8x8l_vertical_filter_add_9_c, void (i8*, i16*, i32, i32, i64)* @pred8x8l_horizontal_filter_add_9_c>, <2 x void (i8*, i16*, i32, i32, i64)*>* %125, align 8
  %126 = select i1 %64, void (i8*, i32*, i16*, i64)* @pred8x8_vertical_add_9_c, void (i8*, i32*, i16*, i64)* @pred8x16_vertical_add_9_c
  %127 = select i1 %64, void (i8*, i32*, i16*, i64)* @pred8x8_horizontal_add_9_c, void (i8*, i32*, i16*, i64)* @pred8x16_horizontal_add_9_c
  br label %623

128:                                              ; preds = %4
  %129 = icmp eq i32 %1, 69
  br i1 %129, label %159, label %130

130:                                              ; preds = %128
  %131 = icmp eq i32 %1, 179
  %132 = icmp eq i32 %1, 139
  %133 = or i1 %131, %132
  switch i32 %1, label %134 [
    i32 179, label %135
    i32 139, label %135
  ]

134:                                              ; preds = %130
  br label %135

135:                                              ; preds = %130, %130, %134
  %136 = phi <2 x void (i8*, i8*, i64)*> [ <void (i8*, i8*, i64)* @pred4x4_vertical_10_c, void (i8*, i8*, i64)* @pred4x4_horizontal_10_c>, %134 ], [ <void (i8*, i8*, i64)* @pred4x4_vertical_vp8_c, void (i8*, i8*, i64)* @pred4x4_horizontal_vp8_c>, %130 ], [ <void (i8*, i8*, i64)* @pred4x4_vertical_vp8_c, void (i8*, i8*, i64)* @pred4x4_horizontal_vp8_c>, %130 ]
  %137 = bitcast %struct.H264PredContext* %0 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> %136, <2 x void (i8*, i8*, i64)*>* %137, align 8
  %138 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 2
  store void (i8*, i8*, i64)* @pred4x4_dc_10_c, void (i8*, i8*, i64)** %138, align 8
  %139 = icmp eq i32 %1, 23
  %140 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 3
  %141 = select i1 %139, void (i8*, i8*, i64)* @pred4x4_down_left_svq3_c, void (i8*, i8*, i64)* @pred4x4_down_left_10_c
  store void (i8*, i8*, i64)* %141, void (i8*, i8*, i64)** %140, align 8
  %142 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 4
  %143 = bitcast void (i8*, i8*, i64)** %142 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_right_10_c, void (i8*, i8*, i64)* @pred4x4_vertical_right_10_c>, <2 x void (i8*, i8*, i64)*>* %143, align 8
  %144 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 6
  store void (i8*, i8*, i64)* @pred4x4_horizontal_down_10_c, void (i8*, i8*, i64)** %144, align 8
  %145 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 7
  %146 = select i1 %133, void (i8*, i8*, i64)* @pred4x4_vertical_left_vp8_c, void (i8*, i8*, i64)* @pred4x4_vertical_left_10_c
  store void (i8*, i8*, i64)* %146, void (i8*, i8*, i64)** %145, align 8
  %147 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 8
  store void (i8*, i8*, i64)* @pred4x4_horizontal_up_10_c, void (i8*, i8*, i64)** %147, align 8
  %148 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 9
  switch i32 %1, label %149 [
    i32 179, label %151
    i32 139, label %151
  ]

149:                                              ; preds = %135
  %150 = bitcast void (i8*, i8*, i64)** %148 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_left_dc_10_c, void (i8*, i8*, i64)* @pred4x4_top_dc_10_c>, <2 x void (i8*, i8*, i64)*>* %150, align 8
  br label %156

151:                                              ; preds = %135, %135
  %152 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 12
  %153 = bitcast void (i8*, i8*, i64)** %152 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_127_dc_10_c, void (i8*, i8*, i64)* @pred4x4_129_dc_10_c>, <2 x void (i8*, i8*, i64)*>* %153, align 8
  %154 = bitcast void (i8*, i8*, i64)** %148 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_tm_vp8_c, void (i8*, i8*, i64)* @pred4x4_vertical_10_c>, <2 x void (i8*, i8*, i64)*>* %154, align 8
  %155 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 14
  store void (i8*, i8*, i64)* @pred4x4_horizontal_10_c, void (i8*, i8*, i64)** %155, align 8
  br label %156

156:                                              ; preds = %151, %149
  br i1 %132, label %174, label %157

157:                                              ; preds = %156
  %158 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 11
  store void (i8*, i8*, i64)* @pred4x4_128_dc_10_c, void (i8*, i8*, i64)** %158, align 8
  br label %174

159:                                              ; preds = %128
  %160 = bitcast %struct.H264PredContext* %0 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_vertical_10_c, void (i8*, i8*, i64)* @pred4x4_horizontal_10_c>, <2 x void (i8*, i8*, i64)*>* %160, align 8
  %161 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 2
  %162 = bitcast void (i8*, i8*, i64)** %161 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_dc_10_c, void (i8*, i8*, i64)* @pred4x4_down_left_rv40_c>, <2 x void (i8*, i8*, i64)*>* %162, align 8
  %163 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 4
  %164 = bitcast void (i8*, i8*, i64)** %163 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_right_10_c, void (i8*, i8*, i64)* @pred4x4_vertical_right_10_c>, <2 x void (i8*, i8*, i64)*>* %164, align 8
  %165 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 6
  %166 = bitcast void (i8*, i8*, i64)** %165 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_horizontal_down_10_c, void (i8*, i8*, i64)* @pred4x4_vertical_left_rv40_c>, <2 x void (i8*, i8*, i64)*>* %166, align 8
  %167 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 8
  %168 = bitcast void (i8*, i8*, i64)** %167 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_horizontal_up_rv40_c, void (i8*, i8*, i64)* @pred4x4_left_dc_10_c>, <2 x void (i8*, i8*, i64)*>* %168, align 8
  %169 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 10
  %170 = bitcast void (i8*, i8*, i64)** %169 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_top_dc_10_c, void (i8*, i8*, i64)* @pred4x4_128_dc_10_c>, <2 x void (i8*, i8*, i64)*>* %170, align 8
  %171 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 12
  %172 = bitcast void (i8*, i8*, i64)** %171 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_left_rv40_nodown_c, void (i8*, i8*, i64)* @pred4x4_horizontal_up_rv40_nodown_c>, <2 x void (i8*, i8*, i64)*>* %172, align 8
  %173 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 14
  store void (i8*, i8*, i64)* @pred4x4_vertical_left_rv40_nodown_c, void (i8*, i8*, i64)** %173, align 8
  br label %174

174:                                              ; preds = %156, %157, %159
  %175 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 0
  %176 = bitcast void (i8*, i32, i32, i64)** %175 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_vertical_10_c, void (i8*, i32, i32, i64)* @pred8x8l_horizontal_10_c>, <2 x void (i8*, i32, i32, i64)*>* %176, align 8
  %177 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 2
  %178 = bitcast void (i8*, i32, i32, i64)** %177 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_dc_10_c, void (i8*, i32, i32, i64)* @pred8x8l_down_left_10_c>, <2 x void (i8*, i32, i32, i64)*>* %178, align 8
  %179 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 4
  %180 = bitcast void (i8*, i32, i32, i64)** %179 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_down_right_10_c, void (i8*, i32, i32, i64)* @pred8x8l_vertical_right_10_c>, <2 x void (i8*, i32, i32, i64)*>* %180, align 8
  %181 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 6
  %182 = bitcast void (i8*, i32, i32, i64)** %181 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_horizontal_down_10_c, void (i8*, i32, i32, i64)* @pred8x8l_vertical_left_10_c>, <2 x void (i8*, i32, i32, i64)*>* %182, align 8
  %183 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 8
  %184 = bitcast void (i8*, i32, i32, i64)** %183 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_horizontal_up_10_c, void (i8*, i32, i32, i64)* @pred8x8l_left_dc_10_c>, <2 x void (i8*, i32, i32, i64)*>* %184, align 8
  %185 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 10
  %186 = bitcast void (i8*, i32, i32, i64)** %185 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_top_dc_10_c, void (i8*, i32, i32, i64)* @pred8x8l_128_dc_10_c>, <2 x void (i8*, i32, i32, i64)*>* %186, align 8
  %187 = icmp slt i32 %3, 2
  %188 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2
  %189 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 2
  %190 = select i1 %187, void (i8*, i64)* @pred8x8_vertical_10_c, void (i8*, i64)* @pred8x16_vertical_10_c
  %191 = select i1 %187, void (i8*, i64)* @pred8x8_horizontal_10_c, void (i8*, i64)* @pred8x16_horizontal_10_c
  store void (i8*, i64)* %190, void (i8*, i64)** %189, align 8
  %192 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 1
  store void (i8*, i64)* %191, void (i8*, i64)** %192, align 8
  switch i32 %1, label %193 [
    i32 179, label %197
    i32 139, label %197
  ]

193:                                              ; preds = %174
  %194 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 3
  br i1 %187, label %195, label %196

195:                                              ; preds = %193
  store void (i8*, i64)* @pred8x8_plane_10_c, void (i8*, i64)** %194, align 8
  br label %199

196:                                              ; preds = %193
  store void (i8*, i64)* @pred8x16_plane_10_c, void (i8*, i64)** %194, align 8
  br label %199

197:                                              ; preds = %174, %174
  %198 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 3
  store void (i8*, i64)* @pred8x8_tm_vp8_c, void (i8*, i64)** %198, align 8
  br label %199

199:                                              ; preds = %195, %196, %197
  switch i32 %1, label %200 [
    i32 179, label %216
    i32 139, label %216
    i32 69, label %216
  ]

200:                                              ; preds = %199
  %201 = getelementptr inbounds [11 x void (i8*, i64)*], [11 x void (i8*, i64)*]* %188, i64 0, i64 0
  br i1 %187, label %202, label %209

202:                                              ; preds = %200
  store void (i8*, i64)* @pred8x8_dc_10_c, void (i8*, i64)** %201, align 8
  %203 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %204 = bitcast void (i8*, i64)** %203 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_left_dc_10_c, void (i8*, i64)* @pred8x8_top_dc_10_c>, <2 x void (i8*, i64)*>* %204, align 8
  %205 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %206 = bitcast void (i8*, i64)** %205 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_mad_cow_dc_l0t_10, void (i8*, i64)* @pred8x8_mad_cow_dc_0lt_10>, <2 x void (i8*, i64)*>* %206, align 8
  %207 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 9
  %208 = bitcast void (i8*, i64)** %207 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_mad_cow_dc_l00_10, void (i8*, i64)* @pred8x8_mad_cow_dc_0l0_10>, <2 x void (i8*, i64)*>* %208, align 8
  br label %223

209:                                              ; preds = %200
  store void (i8*, i64)* @pred8x16_dc_10_c, void (i8*, i64)** %201, align 8
  %210 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %211 = bitcast void (i8*, i64)** %210 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_left_dc_10_c, void (i8*, i64)* @pred8x16_top_dc_10_c>, <2 x void (i8*, i64)*>* %211, align 8
  %212 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %213 = bitcast void (i8*, i64)** %212 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_mad_cow_dc_l0t_10, void (i8*, i64)* @pred8x16_mad_cow_dc_0lt_10>, <2 x void (i8*, i64)*>* %213, align 8
  %214 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 9
  %215 = bitcast void (i8*, i64)** %214 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_mad_cow_dc_l00_10, void (i8*, i64)* @pred8x16_mad_cow_dc_0l0_10>, <2 x void (i8*, i64)*>* %215, align 8
  br label %223

216:                                              ; preds = %199, %199, %199
  %217 = getelementptr inbounds [11 x void (i8*, i64)*], [11 x void (i8*, i64)*]* %188, i64 0, i64 0
  store void (i8*, i64)* @pred8x8_dc_rv40_c, void (i8*, i64)** %217, align 8
  %218 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %219 = bitcast void (i8*, i64)** %218 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_left_dc_rv40_c, void (i8*, i64)* @pred8x8_top_dc_rv40_c>, <2 x void (i8*, i64)*>* %219, align 8
  switch i32 %1, label %223 [
    i32 179, label %220
    i32 139, label %220
  ]

220:                                              ; preds = %216, %216
  %221 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %222 = bitcast void (i8*, i64)** %221 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_127_dc_10_c, void (i8*, i64)* @pred8x8_129_dc_10_c>, <2 x void (i8*, i64)*>* %222, align 8
  br label %223

223:                                              ; preds = %216, %220, %202, %209
  %224 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 6
  %225 = select i1 %187, void (i8*, i64)* @pred8x8_128_dc_10_c, void (i8*, i64)* @pred8x16_128_dc_10_c
  store void (i8*, i64)* %225, void (i8*, i64)** %224, align 8
  %226 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 0
  %227 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 2
  store void (i8*, i64)* @pred16x16_vertical_10_c, void (i8*, i64)** %227, align 8
  %228 = bitcast void (i8*, i64)** %226 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_dc_10_c, void (i8*, i64)* @pred16x16_horizontal_10_c>, <2 x void (i8*, i64)*>* %228, align 8
  switch i32 %1, label %237 [
    i32 23, label %229
    i32 69, label %231
    i32 179, label %233
    i32 139, label %233
  ]

229:                                              ; preds = %223
  %230 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_svq3_c, void (i8*, i64)** %230, align 8
  br label %239

231:                                              ; preds = %223
  %232 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_rv40_c, void (i8*, i64)** %232, align 8
  br label %239

233:                                              ; preds = %223, %223
  %234 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_tm_vp8_c, void (i8*, i64)** %234, align 8
  %235 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 7
  %236 = bitcast void (i8*, i64)** %235 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_127_dc_10_c, void (i8*, i64)* @pred16x16_129_dc_10_c>, <2 x void (i8*, i64)*>* %236, align 8
  br label %239

237:                                              ; preds = %223
  %238 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_10_c, void (i8*, i64)** %238, align 8
  br label %239

239:                                              ; preds = %237, %233, %231, %229
  %240 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 4
  %241 = bitcast void (i8*, i64)** %240 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_left_dc_10_c, void (i8*, i64)* @pred16x16_top_dc_10_c>, <2 x void (i8*, i64)*>* %241, align 8
  %242 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 6
  store void (i8*, i64)* @pred16x16_128_dc_10_c, void (i8*, i64)** %242, align 8
  %243 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 4, i64 0
  %244 = bitcast void (i8*, i16*, i64)** %243 to <2 x void (i8*, i16*, i64)*>*
  store <2 x void (i8*, i16*, i64)*> <void (i8*, i16*, i64)* @pred4x4_vertical_add_10_c, void (i8*, i16*, i64)* @pred4x4_horizontal_add_10_c>, <2 x void (i8*, i16*, i64)*>* %244, align 8
  %245 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 5, i64 0
  %246 = bitcast void (i8*, i16*, i64)** %245 to <2 x void (i8*, i16*, i64)*>*
  store <2 x void (i8*, i16*, i64)*> <void (i8*, i16*, i64)* @pred8x8l_vertical_add_10_c, void (i8*, i16*, i64)* @pred8x8l_horizontal_add_10_c>, <2 x void (i8*, i16*, i64)*>* %246, align 8
  %247 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 6, i64 0
  %248 = bitcast void (i8*, i16*, i32, i32, i64)** %247 to <2 x void (i8*, i16*, i32, i32, i64)*>*
  store <2 x void (i8*, i16*, i32, i32, i64)*> <void (i8*, i16*, i32, i32, i64)* @pred8x8l_vertical_filter_add_10_c, void (i8*, i16*, i32, i32, i64)* @pred8x8l_horizontal_filter_add_10_c>, <2 x void (i8*, i16*, i32, i32, i64)*>* %248, align 8
  %249 = select i1 %187, void (i8*, i32*, i16*, i64)* @pred8x8_vertical_add_10_c, void (i8*, i32*, i16*, i64)* @pred8x16_vertical_add_10_c
  %250 = select i1 %187, void (i8*, i32*, i16*, i64)* @pred8x8_horizontal_add_10_c, void (i8*, i32*, i16*, i64)* @pred8x16_horizontal_add_10_c
  br label %623

251:                                              ; preds = %4
  %252 = icmp eq i32 %1, 69
  br i1 %252, label %282, label %253

253:                                              ; preds = %251
  %254 = icmp eq i32 %1, 179
  %255 = icmp eq i32 %1, 139
  %256 = or i1 %254, %255
  switch i32 %1, label %257 [
    i32 179, label %258
    i32 139, label %258
  ]

257:                                              ; preds = %253
  br label %258

258:                                              ; preds = %253, %253, %257
  %259 = phi <2 x void (i8*, i8*, i64)*> [ <void (i8*, i8*, i64)* @pred4x4_vertical_12_c, void (i8*, i8*, i64)* @pred4x4_horizontal_12_c>, %257 ], [ <void (i8*, i8*, i64)* @pred4x4_vertical_vp8_c, void (i8*, i8*, i64)* @pred4x4_horizontal_vp8_c>, %253 ], [ <void (i8*, i8*, i64)* @pred4x4_vertical_vp8_c, void (i8*, i8*, i64)* @pred4x4_horizontal_vp8_c>, %253 ]
  %260 = bitcast %struct.H264PredContext* %0 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> %259, <2 x void (i8*, i8*, i64)*>* %260, align 8
  %261 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 2
  store void (i8*, i8*, i64)* @pred4x4_dc_12_c, void (i8*, i8*, i64)** %261, align 8
  %262 = icmp eq i32 %1, 23
  %263 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 3
  %264 = select i1 %262, void (i8*, i8*, i64)* @pred4x4_down_left_svq3_c, void (i8*, i8*, i64)* @pred4x4_down_left_12_c
  store void (i8*, i8*, i64)* %264, void (i8*, i8*, i64)** %263, align 8
  %265 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 4
  %266 = bitcast void (i8*, i8*, i64)** %265 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_right_12_c, void (i8*, i8*, i64)* @pred4x4_vertical_right_12_c>, <2 x void (i8*, i8*, i64)*>* %266, align 8
  %267 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 6
  store void (i8*, i8*, i64)* @pred4x4_horizontal_down_12_c, void (i8*, i8*, i64)** %267, align 8
  %268 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 7
  %269 = select i1 %256, void (i8*, i8*, i64)* @pred4x4_vertical_left_vp8_c, void (i8*, i8*, i64)* @pred4x4_vertical_left_12_c
  store void (i8*, i8*, i64)* %269, void (i8*, i8*, i64)** %268, align 8
  %270 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 8
  store void (i8*, i8*, i64)* @pred4x4_horizontal_up_12_c, void (i8*, i8*, i64)** %270, align 8
  %271 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 9
  switch i32 %1, label %272 [
    i32 179, label %274
    i32 139, label %274
  ]

272:                                              ; preds = %258
  %273 = bitcast void (i8*, i8*, i64)** %271 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_left_dc_12_c, void (i8*, i8*, i64)* @pred4x4_top_dc_12_c>, <2 x void (i8*, i8*, i64)*>* %273, align 8
  br label %279

274:                                              ; preds = %258, %258
  %275 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 12
  %276 = bitcast void (i8*, i8*, i64)** %275 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_127_dc_12_c, void (i8*, i8*, i64)* @pred4x4_129_dc_12_c>, <2 x void (i8*, i8*, i64)*>* %276, align 8
  %277 = bitcast void (i8*, i8*, i64)** %271 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_tm_vp8_c, void (i8*, i8*, i64)* @pred4x4_vertical_12_c>, <2 x void (i8*, i8*, i64)*>* %277, align 8
  %278 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 14
  store void (i8*, i8*, i64)* @pred4x4_horizontal_12_c, void (i8*, i8*, i64)** %278, align 8
  br label %279

279:                                              ; preds = %274, %272
  br i1 %255, label %297, label %280

280:                                              ; preds = %279
  %281 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 11
  store void (i8*, i8*, i64)* @pred4x4_128_dc_12_c, void (i8*, i8*, i64)** %281, align 8
  br label %297

282:                                              ; preds = %251
  %283 = bitcast %struct.H264PredContext* %0 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_vertical_12_c, void (i8*, i8*, i64)* @pred4x4_horizontal_12_c>, <2 x void (i8*, i8*, i64)*>* %283, align 8
  %284 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 2
  %285 = bitcast void (i8*, i8*, i64)** %284 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_dc_12_c, void (i8*, i8*, i64)* @pred4x4_down_left_rv40_c>, <2 x void (i8*, i8*, i64)*>* %285, align 8
  %286 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 4
  %287 = bitcast void (i8*, i8*, i64)** %286 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_right_12_c, void (i8*, i8*, i64)* @pred4x4_vertical_right_12_c>, <2 x void (i8*, i8*, i64)*>* %287, align 8
  %288 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 6
  %289 = bitcast void (i8*, i8*, i64)** %288 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_horizontal_down_12_c, void (i8*, i8*, i64)* @pred4x4_vertical_left_rv40_c>, <2 x void (i8*, i8*, i64)*>* %289, align 8
  %290 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 8
  %291 = bitcast void (i8*, i8*, i64)** %290 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_horizontal_up_rv40_c, void (i8*, i8*, i64)* @pred4x4_left_dc_12_c>, <2 x void (i8*, i8*, i64)*>* %291, align 8
  %292 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 10
  %293 = bitcast void (i8*, i8*, i64)** %292 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_top_dc_12_c, void (i8*, i8*, i64)* @pred4x4_128_dc_12_c>, <2 x void (i8*, i8*, i64)*>* %293, align 8
  %294 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 12
  %295 = bitcast void (i8*, i8*, i64)** %294 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_left_rv40_nodown_c, void (i8*, i8*, i64)* @pred4x4_horizontal_up_rv40_nodown_c>, <2 x void (i8*, i8*, i64)*>* %295, align 8
  %296 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 14
  store void (i8*, i8*, i64)* @pred4x4_vertical_left_rv40_nodown_c, void (i8*, i8*, i64)** %296, align 8
  br label %297

297:                                              ; preds = %279, %280, %282
  %298 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 0
  %299 = bitcast void (i8*, i32, i32, i64)** %298 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_vertical_12_c, void (i8*, i32, i32, i64)* @pred8x8l_horizontal_12_c>, <2 x void (i8*, i32, i32, i64)*>* %299, align 8
  %300 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 2
  %301 = bitcast void (i8*, i32, i32, i64)** %300 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_dc_12_c, void (i8*, i32, i32, i64)* @pred8x8l_down_left_12_c>, <2 x void (i8*, i32, i32, i64)*>* %301, align 8
  %302 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 4
  %303 = bitcast void (i8*, i32, i32, i64)** %302 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_down_right_12_c, void (i8*, i32, i32, i64)* @pred8x8l_vertical_right_12_c>, <2 x void (i8*, i32, i32, i64)*>* %303, align 8
  %304 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 6
  %305 = bitcast void (i8*, i32, i32, i64)** %304 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_horizontal_down_12_c, void (i8*, i32, i32, i64)* @pred8x8l_vertical_left_12_c>, <2 x void (i8*, i32, i32, i64)*>* %305, align 8
  %306 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 8
  %307 = bitcast void (i8*, i32, i32, i64)** %306 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_horizontal_up_12_c, void (i8*, i32, i32, i64)* @pred8x8l_left_dc_12_c>, <2 x void (i8*, i32, i32, i64)*>* %307, align 8
  %308 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 10
  %309 = bitcast void (i8*, i32, i32, i64)** %308 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_top_dc_12_c, void (i8*, i32, i32, i64)* @pred8x8l_128_dc_12_c>, <2 x void (i8*, i32, i32, i64)*>* %309, align 8
  %310 = icmp slt i32 %3, 2
  %311 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2
  %312 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 2
  %313 = select i1 %310, void (i8*, i64)* @pred8x8_vertical_12_c, void (i8*, i64)* @pred8x16_vertical_12_c
  %314 = select i1 %310, void (i8*, i64)* @pred8x8_horizontal_12_c, void (i8*, i64)* @pred8x16_horizontal_12_c
  store void (i8*, i64)* %313, void (i8*, i64)** %312, align 8
  %315 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 1
  store void (i8*, i64)* %314, void (i8*, i64)** %315, align 8
  switch i32 %1, label %316 [
    i32 179, label %320
    i32 139, label %320
  ]

316:                                              ; preds = %297
  %317 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 3
  br i1 %310, label %318, label %319

318:                                              ; preds = %316
  store void (i8*, i64)* @pred8x8_plane_12_c, void (i8*, i64)** %317, align 8
  br label %322

319:                                              ; preds = %316
  store void (i8*, i64)* @pred8x16_plane_12_c, void (i8*, i64)** %317, align 8
  br label %322

320:                                              ; preds = %297, %297
  %321 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 3
  store void (i8*, i64)* @pred8x8_tm_vp8_c, void (i8*, i64)** %321, align 8
  br label %322

322:                                              ; preds = %318, %319, %320
  switch i32 %1, label %323 [
    i32 179, label %339
    i32 139, label %339
    i32 69, label %339
  ]

323:                                              ; preds = %322
  %324 = getelementptr inbounds [11 x void (i8*, i64)*], [11 x void (i8*, i64)*]* %311, i64 0, i64 0
  br i1 %310, label %325, label %332

325:                                              ; preds = %323
  store void (i8*, i64)* @pred8x8_dc_12_c, void (i8*, i64)** %324, align 8
  %326 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %327 = bitcast void (i8*, i64)** %326 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_left_dc_12_c, void (i8*, i64)* @pred8x8_top_dc_12_c>, <2 x void (i8*, i64)*>* %327, align 8
  %328 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %329 = bitcast void (i8*, i64)** %328 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_mad_cow_dc_l0t_12, void (i8*, i64)* @pred8x8_mad_cow_dc_0lt_12>, <2 x void (i8*, i64)*>* %329, align 8
  %330 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 9
  %331 = bitcast void (i8*, i64)** %330 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_mad_cow_dc_l00_12, void (i8*, i64)* @pred8x8_mad_cow_dc_0l0_12>, <2 x void (i8*, i64)*>* %331, align 8
  br label %346

332:                                              ; preds = %323
  store void (i8*, i64)* @pred8x16_dc_12_c, void (i8*, i64)** %324, align 8
  %333 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %334 = bitcast void (i8*, i64)** %333 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_left_dc_12_c, void (i8*, i64)* @pred8x16_top_dc_12_c>, <2 x void (i8*, i64)*>* %334, align 8
  %335 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %336 = bitcast void (i8*, i64)** %335 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_mad_cow_dc_l0t_12, void (i8*, i64)* @pred8x16_mad_cow_dc_0lt_12>, <2 x void (i8*, i64)*>* %336, align 8
  %337 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 9
  %338 = bitcast void (i8*, i64)** %337 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_mad_cow_dc_l00_12, void (i8*, i64)* @pred8x16_mad_cow_dc_0l0_12>, <2 x void (i8*, i64)*>* %338, align 8
  br label %346

339:                                              ; preds = %322, %322, %322
  %340 = getelementptr inbounds [11 x void (i8*, i64)*], [11 x void (i8*, i64)*]* %311, i64 0, i64 0
  store void (i8*, i64)* @pred8x8_dc_rv40_c, void (i8*, i64)** %340, align 8
  %341 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %342 = bitcast void (i8*, i64)** %341 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_left_dc_rv40_c, void (i8*, i64)* @pred8x8_top_dc_rv40_c>, <2 x void (i8*, i64)*>* %342, align 8
  switch i32 %1, label %346 [
    i32 179, label %343
    i32 139, label %343
  ]

343:                                              ; preds = %339, %339
  %344 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %345 = bitcast void (i8*, i64)** %344 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_127_dc_12_c, void (i8*, i64)* @pred8x8_129_dc_12_c>, <2 x void (i8*, i64)*>* %345, align 8
  br label %346

346:                                              ; preds = %339, %343, %325, %332
  %347 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 6
  %348 = select i1 %310, void (i8*, i64)* @pred8x8_128_dc_12_c, void (i8*, i64)* @pred8x16_128_dc_12_c
  store void (i8*, i64)* %348, void (i8*, i64)** %347, align 8
  %349 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 0
  %350 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 2
  store void (i8*, i64)* @pred16x16_vertical_12_c, void (i8*, i64)** %350, align 8
  %351 = bitcast void (i8*, i64)** %349 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_dc_12_c, void (i8*, i64)* @pred16x16_horizontal_12_c>, <2 x void (i8*, i64)*>* %351, align 8
  switch i32 %1, label %360 [
    i32 23, label %352
    i32 69, label %354
    i32 179, label %356
    i32 139, label %356
  ]

352:                                              ; preds = %346
  %353 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_svq3_c, void (i8*, i64)** %353, align 8
  br label %362

354:                                              ; preds = %346
  %355 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_rv40_c, void (i8*, i64)** %355, align 8
  br label %362

356:                                              ; preds = %346, %346
  %357 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_tm_vp8_c, void (i8*, i64)** %357, align 8
  %358 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 7
  %359 = bitcast void (i8*, i64)** %358 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_127_dc_12_c, void (i8*, i64)* @pred16x16_129_dc_12_c>, <2 x void (i8*, i64)*>* %359, align 8
  br label %362

360:                                              ; preds = %346
  %361 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_12_c, void (i8*, i64)** %361, align 8
  br label %362

362:                                              ; preds = %360, %356, %354, %352
  %363 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 4
  %364 = bitcast void (i8*, i64)** %363 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_left_dc_12_c, void (i8*, i64)* @pred16x16_top_dc_12_c>, <2 x void (i8*, i64)*>* %364, align 8
  %365 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 6
  store void (i8*, i64)* @pred16x16_128_dc_12_c, void (i8*, i64)** %365, align 8
  %366 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 4, i64 0
  %367 = bitcast void (i8*, i16*, i64)** %366 to <2 x void (i8*, i16*, i64)*>*
  store <2 x void (i8*, i16*, i64)*> <void (i8*, i16*, i64)* @pred4x4_vertical_add_12_c, void (i8*, i16*, i64)* @pred4x4_horizontal_add_12_c>, <2 x void (i8*, i16*, i64)*>* %367, align 8
  %368 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 5, i64 0
  %369 = bitcast void (i8*, i16*, i64)** %368 to <2 x void (i8*, i16*, i64)*>*
  store <2 x void (i8*, i16*, i64)*> <void (i8*, i16*, i64)* @pred8x8l_vertical_add_12_c, void (i8*, i16*, i64)* @pred8x8l_horizontal_add_12_c>, <2 x void (i8*, i16*, i64)*>* %369, align 8
  %370 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 6, i64 0
  %371 = bitcast void (i8*, i16*, i32, i32, i64)** %370 to <2 x void (i8*, i16*, i32, i32, i64)*>*
  store <2 x void (i8*, i16*, i32, i32, i64)*> <void (i8*, i16*, i32, i32, i64)* @pred8x8l_vertical_filter_add_12_c, void (i8*, i16*, i32, i32, i64)* @pred8x8l_horizontal_filter_add_12_c>, <2 x void (i8*, i16*, i32, i32, i64)*>* %371, align 8
  %372 = select i1 %310, void (i8*, i32*, i16*, i64)* @pred8x8_vertical_add_12_c, void (i8*, i32*, i16*, i64)* @pred8x16_vertical_add_12_c
  %373 = select i1 %310, void (i8*, i32*, i16*, i64)* @pred8x8_horizontal_add_12_c, void (i8*, i32*, i16*, i64)* @pred8x16_horizontal_add_12_c
  br label %623

374:                                              ; preds = %4
  %375 = icmp eq i32 %1, 69
  br i1 %375, label %405, label %376

376:                                              ; preds = %374
  %377 = icmp eq i32 %1, 179
  %378 = icmp eq i32 %1, 139
  %379 = or i1 %377, %378
  switch i32 %1, label %380 [
    i32 179, label %381
    i32 139, label %381
  ]

380:                                              ; preds = %376
  br label %381

381:                                              ; preds = %376, %376, %380
  %382 = phi <2 x void (i8*, i8*, i64)*> [ <void (i8*, i8*, i64)* @pred4x4_vertical_14_c, void (i8*, i8*, i64)* @pred4x4_horizontal_14_c>, %380 ], [ <void (i8*, i8*, i64)* @pred4x4_vertical_vp8_c, void (i8*, i8*, i64)* @pred4x4_horizontal_vp8_c>, %376 ], [ <void (i8*, i8*, i64)* @pred4x4_vertical_vp8_c, void (i8*, i8*, i64)* @pred4x4_horizontal_vp8_c>, %376 ]
  %383 = bitcast %struct.H264PredContext* %0 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> %382, <2 x void (i8*, i8*, i64)*>* %383, align 8
  %384 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 2
  store void (i8*, i8*, i64)* @pred4x4_dc_14_c, void (i8*, i8*, i64)** %384, align 8
  %385 = icmp eq i32 %1, 23
  %386 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 3
  %387 = select i1 %385, void (i8*, i8*, i64)* @pred4x4_down_left_svq3_c, void (i8*, i8*, i64)* @pred4x4_down_left_14_c
  store void (i8*, i8*, i64)* %387, void (i8*, i8*, i64)** %386, align 8
  %388 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 4
  %389 = bitcast void (i8*, i8*, i64)** %388 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_right_14_c, void (i8*, i8*, i64)* @pred4x4_vertical_right_14_c>, <2 x void (i8*, i8*, i64)*>* %389, align 8
  %390 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 6
  store void (i8*, i8*, i64)* @pred4x4_horizontal_down_14_c, void (i8*, i8*, i64)** %390, align 8
  %391 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 7
  %392 = select i1 %379, void (i8*, i8*, i64)* @pred4x4_vertical_left_vp8_c, void (i8*, i8*, i64)* @pred4x4_vertical_left_14_c
  store void (i8*, i8*, i64)* %392, void (i8*, i8*, i64)** %391, align 8
  %393 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 8
  store void (i8*, i8*, i64)* @pred4x4_horizontal_up_14_c, void (i8*, i8*, i64)** %393, align 8
  %394 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 9
  switch i32 %1, label %395 [
    i32 179, label %397
    i32 139, label %397
  ]

395:                                              ; preds = %381
  %396 = bitcast void (i8*, i8*, i64)** %394 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_left_dc_14_c, void (i8*, i8*, i64)* @pred4x4_top_dc_14_c>, <2 x void (i8*, i8*, i64)*>* %396, align 8
  br label %402

397:                                              ; preds = %381, %381
  %398 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 12
  %399 = bitcast void (i8*, i8*, i64)** %398 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_127_dc_14_c, void (i8*, i8*, i64)* @pred4x4_129_dc_14_c>, <2 x void (i8*, i8*, i64)*>* %399, align 8
  %400 = bitcast void (i8*, i8*, i64)** %394 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_tm_vp8_c, void (i8*, i8*, i64)* @pred4x4_vertical_14_c>, <2 x void (i8*, i8*, i64)*>* %400, align 8
  %401 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 14
  store void (i8*, i8*, i64)* @pred4x4_horizontal_14_c, void (i8*, i8*, i64)** %401, align 8
  br label %402

402:                                              ; preds = %397, %395
  br i1 %378, label %420, label %403

403:                                              ; preds = %402
  %404 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 11
  store void (i8*, i8*, i64)* @pred4x4_128_dc_14_c, void (i8*, i8*, i64)** %404, align 8
  br label %420

405:                                              ; preds = %374
  %406 = bitcast %struct.H264PredContext* %0 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_vertical_14_c, void (i8*, i8*, i64)* @pred4x4_horizontal_14_c>, <2 x void (i8*, i8*, i64)*>* %406, align 8
  %407 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 2
  %408 = bitcast void (i8*, i8*, i64)** %407 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_dc_14_c, void (i8*, i8*, i64)* @pred4x4_down_left_rv40_c>, <2 x void (i8*, i8*, i64)*>* %408, align 8
  %409 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 4
  %410 = bitcast void (i8*, i8*, i64)** %409 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_right_14_c, void (i8*, i8*, i64)* @pred4x4_vertical_right_14_c>, <2 x void (i8*, i8*, i64)*>* %410, align 8
  %411 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 6
  %412 = bitcast void (i8*, i8*, i64)** %411 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_horizontal_down_14_c, void (i8*, i8*, i64)* @pred4x4_vertical_left_rv40_c>, <2 x void (i8*, i8*, i64)*>* %412, align 8
  %413 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 8
  %414 = bitcast void (i8*, i8*, i64)** %413 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_horizontal_up_rv40_c, void (i8*, i8*, i64)* @pred4x4_left_dc_14_c>, <2 x void (i8*, i8*, i64)*>* %414, align 8
  %415 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 10
  %416 = bitcast void (i8*, i8*, i64)** %415 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_top_dc_14_c, void (i8*, i8*, i64)* @pred4x4_128_dc_14_c>, <2 x void (i8*, i8*, i64)*>* %416, align 8
  %417 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 12
  %418 = bitcast void (i8*, i8*, i64)** %417 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_left_rv40_nodown_c, void (i8*, i8*, i64)* @pred4x4_horizontal_up_rv40_nodown_c>, <2 x void (i8*, i8*, i64)*>* %418, align 8
  %419 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 14
  store void (i8*, i8*, i64)* @pred4x4_vertical_left_rv40_nodown_c, void (i8*, i8*, i64)** %419, align 8
  br label %420

420:                                              ; preds = %402, %403, %405
  %421 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 0
  %422 = bitcast void (i8*, i32, i32, i64)** %421 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_vertical_14_c, void (i8*, i32, i32, i64)* @pred8x8l_horizontal_14_c>, <2 x void (i8*, i32, i32, i64)*>* %422, align 8
  %423 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 2
  %424 = bitcast void (i8*, i32, i32, i64)** %423 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_dc_14_c, void (i8*, i32, i32, i64)* @pred8x8l_down_left_14_c>, <2 x void (i8*, i32, i32, i64)*>* %424, align 8
  %425 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 4
  %426 = bitcast void (i8*, i32, i32, i64)** %425 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_down_right_14_c, void (i8*, i32, i32, i64)* @pred8x8l_vertical_right_14_c>, <2 x void (i8*, i32, i32, i64)*>* %426, align 8
  %427 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 6
  %428 = bitcast void (i8*, i32, i32, i64)** %427 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_horizontal_down_14_c, void (i8*, i32, i32, i64)* @pred8x8l_vertical_left_14_c>, <2 x void (i8*, i32, i32, i64)*>* %428, align 8
  %429 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 8
  %430 = bitcast void (i8*, i32, i32, i64)** %429 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_horizontal_up_14_c, void (i8*, i32, i32, i64)* @pred8x8l_left_dc_14_c>, <2 x void (i8*, i32, i32, i64)*>* %430, align 8
  %431 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 10
  %432 = bitcast void (i8*, i32, i32, i64)** %431 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_top_dc_14_c, void (i8*, i32, i32, i64)* @pred8x8l_128_dc_14_c>, <2 x void (i8*, i32, i32, i64)*>* %432, align 8
  %433 = icmp slt i32 %3, 2
  %434 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2
  %435 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 2
  %436 = select i1 %433, void (i8*, i64)* @pred8x8_vertical_14_c, void (i8*, i64)* @pred8x16_vertical_14_c
  %437 = select i1 %433, void (i8*, i64)* @pred8x8_horizontal_14_c, void (i8*, i64)* @pred8x16_horizontal_14_c
  store void (i8*, i64)* %436, void (i8*, i64)** %435, align 8
  %438 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 1
  store void (i8*, i64)* %437, void (i8*, i64)** %438, align 8
  switch i32 %1, label %439 [
    i32 179, label %443
    i32 139, label %443
  ]

439:                                              ; preds = %420
  %440 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 3
  br i1 %433, label %441, label %442

441:                                              ; preds = %439
  store void (i8*, i64)* @pred8x8_plane_14_c, void (i8*, i64)** %440, align 8
  br label %445

442:                                              ; preds = %439
  store void (i8*, i64)* @pred8x16_plane_14_c, void (i8*, i64)** %440, align 8
  br label %445

443:                                              ; preds = %420, %420
  %444 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 3
  store void (i8*, i64)* @pred8x8_tm_vp8_c, void (i8*, i64)** %444, align 8
  br label %445

445:                                              ; preds = %441, %442, %443
  switch i32 %1, label %446 [
    i32 179, label %462
    i32 139, label %462
    i32 69, label %462
  ]

446:                                              ; preds = %445
  %447 = getelementptr inbounds [11 x void (i8*, i64)*], [11 x void (i8*, i64)*]* %434, i64 0, i64 0
  br i1 %433, label %448, label %455

448:                                              ; preds = %446
  store void (i8*, i64)* @pred8x8_dc_14_c, void (i8*, i64)** %447, align 8
  %449 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %450 = bitcast void (i8*, i64)** %449 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_left_dc_14_c, void (i8*, i64)* @pred8x8_top_dc_14_c>, <2 x void (i8*, i64)*>* %450, align 8
  %451 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %452 = bitcast void (i8*, i64)** %451 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_mad_cow_dc_l0t_14, void (i8*, i64)* @pred8x8_mad_cow_dc_0lt_14>, <2 x void (i8*, i64)*>* %452, align 8
  %453 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 9
  %454 = bitcast void (i8*, i64)** %453 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_mad_cow_dc_l00_14, void (i8*, i64)* @pred8x8_mad_cow_dc_0l0_14>, <2 x void (i8*, i64)*>* %454, align 8
  br label %469

455:                                              ; preds = %446
  store void (i8*, i64)* @pred8x16_dc_14_c, void (i8*, i64)** %447, align 8
  %456 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %457 = bitcast void (i8*, i64)** %456 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_left_dc_14_c, void (i8*, i64)* @pred8x16_top_dc_14_c>, <2 x void (i8*, i64)*>* %457, align 8
  %458 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %459 = bitcast void (i8*, i64)** %458 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_mad_cow_dc_l0t_14, void (i8*, i64)* @pred8x16_mad_cow_dc_0lt_14>, <2 x void (i8*, i64)*>* %459, align 8
  %460 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 9
  %461 = bitcast void (i8*, i64)** %460 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_mad_cow_dc_l00_14, void (i8*, i64)* @pred8x16_mad_cow_dc_0l0_14>, <2 x void (i8*, i64)*>* %461, align 8
  br label %469

462:                                              ; preds = %445, %445, %445
  %463 = getelementptr inbounds [11 x void (i8*, i64)*], [11 x void (i8*, i64)*]* %434, i64 0, i64 0
  store void (i8*, i64)* @pred8x8_dc_rv40_c, void (i8*, i64)** %463, align 8
  %464 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %465 = bitcast void (i8*, i64)** %464 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_left_dc_rv40_c, void (i8*, i64)* @pred8x8_top_dc_rv40_c>, <2 x void (i8*, i64)*>* %465, align 8
  switch i32 %1, label %469 [
    i32 179, label %466
    i32 139, label %466
  ]

466:                                              ; preds = %462, %462
  %467 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %468 = bitcast void (i8*, i64)** %467 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_127_dc_14_c, void (i8*, i64)* @pred8x8_129_dc_14_c>, <2 x void (i8*, i64)*>* %468, align 8
  br label %469

469:                                              ; preds = %462, %466, %448, %455
  %470 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 6
  %471 = select i1 %433, void (i8*, i64)* @pred8x8_128_dc_14_c, void (i8*, i64)* @pred8x16_128_dc_14_c
  store void (i8*, i64)* %471, void (i8*, i64)** %470, align 8
  %472 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 0
  %473 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 2
  store void (i8*, i64)* @pred16x16_vertical_14_c, void (i8*, i64)** %473, align 8
  %474 = bitcast void (i8*, i64)** %472 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_dc_14_c, void (i8*, i64)* @pred16x16_horizontal_14_c>, <2 x void (i8*, i64)*>* %474, align 8
  switch i32 %1, label %483 [
    i32 23, label %475
    i32 69, label %477
    i32 179, label %479
    i32 139, label %479
  ]

475:                                              ; preds = %469
  %476 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_svq3_c, void (i8*, i64)** %476, align 8
  br label %485

477:                                              ; preds = %469
  %478 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_rv40_c, void (i8*, i64)** %478, align 8
  br label %485

479:                                              ; preds = %469, %469
  %480 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_tm_vp8_c, void (i8*, i64)** %480, align 8
  %481 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 7
  %482 = bitcast void (i8*, i64)** %481 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_127_dc_14_c, void (i8*, i64)* @pred16x16_129_dc_14_c>, <2 x void (i8*, i64)*>* %482, align 8
  br label %485

483:                                              ; preds = %469
  %484 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_14_c, void (i8*, i64)** %484, align 8
  br label %485

485:                                              ; preds = %483, %479, %477, %475
  %486 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 4
  %487 = bitcast void (i8*, i64)** %486 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_left_dc_14_c, void (i8*, i64)* @pred16x16_top_dc_14_c>, <2 x void (i8*, i64)*>* %487, align 8
  %488 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 6
  store void (i8*, i64)* @pred16x16_128_dc_14_c, void (i8*, i64)** %488, align 8
  %489 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 4, i64 0
  %490 = bitcast void (i8*, i16*, i64)** %489 to <2 x void (i8*, i16*, i64)*>*
  store <2 x void (i8*, i16*, i64)*> <void (i8*, i16*, i64)* @pred4x4_vertical_add_14_c, void (i8*, i16*, i64)* @pred4x4_horizontal_add_14_c>, <2 x void (i8*, i16*, i64)*>* %490, align 8
  %491 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 5, i64 0
  %492 = bitcast void (i8*, i16*, i64)** %491 to <2 x void (i8*, i16*, i64)*>*
  store <2 x void (i8*, i16*, i64)*> <void (i8*, i16*, i64)* @pred8x8l_vertical_add_14_c, void (i8*, i16*, i64)* @pred8x8l_horizontal_add_14_c>, <2 x void (i8*, i16*, i64)*>* %492, align 8
  %493 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 6, i64 0
  %494 = bitcast void (i8*, i16*, i32, i32, i64)** %493 to <2 x void (i8*, i16*, i32, i32, i64)*>*
  store <2 x void (i8*, i16*, i32, i32, i64)*> <void (i8*, i16*, i32, i32, i64)* @pred8x8l_vertical_filter_add_14_c, void (i8*, i16*, i32, i32, i64)* @pred8x8l_horizontal_filter_add_14_c>, <2 x void (i8*, i16*, i32, i32, i64)*>* %494, align 8
  %495 = select i1 %433, void (i8*, i32*, i16*, i64)* @pred8x8_vertical_add_14_c, void (i8*, i32*, i16*, i64)* @pred8x16_vertical_add_14_c
  %496 = select i1 %433, void (i8*, i32*, i16*, i64)* @pred8x8_horizontal_add_14_c, void (i8*, i32*, i16*, i64)* @pred8x16_horizontal_add_14_c
  br label %623

497:                                              ; preds = %4
  %498 = icmp slt i32 %2, 9
  br i1 %498, label %500, label %499

499:                                              ; preds = %497
  tail call void (i8*, i32, i8*, ...) @av_log(i8* null, i32 0, i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.1, i64 0, i64 0), i8* getelementptr inbounds ([47 x i8], [47 x i8]* @.str.2, i64 0, i64 0), i32 590) #8
  tail call void @abort() #9
  unreachable

500:                                              ; preds = %497
  %501 = icmp eq i32 %1, 69
  br i1 %501, label %531, label %502

502:                                              ; preds = %500
  %503 = icmp eq i32 %1, 179
  %504 = icmp eq i32 %1, 139
  %505 = or i1 %503, %504
  switch i32 %1, label %506 [
    i32 179, label %507
    i32 139, label %507
  ]

506:                                              ; preds = %502
  br label %507

507:                                              ; preds = %502, %502, %506
  %508 = phi <2 x void (i8*, i8*, i64)*> [ <void (i8*, i8*, i64)* @pred4x4_vertical_8_c, void (i8*, i8*, i64)* @pred4x4_horizontal_8_c>, %506 ], [ <void (i8*, i8*, i64)* @pred4x4_vertical_vp8_c, void (i8*, i8*, i64)* @pred4x4_horizontal_vp8_c>, %502 ], [ <void (i8*, i8*, i64)* @pred4x4_vertical_vp8_c, void (i8*, i8*, i64)* @pred4x4_horizontal_vp8_c>, %502 ]
  %509 = bitcast %struct.H264PredContext* %0 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> %508, <2 x void (i8*, i8*, i64)*>* %509, align 8
  %510 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 2
  store void (i8*, i8*, i64)* @pred4x4_dc_8_c, void (i8*, i8*, i64)** %510, align 8
  %511 = icmp eq i32 %1, 23
  %512 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 3
  %513 = select i1 %511, void (i8*, i8*, i64)* @pred4x4_down_left_svq3_c, void (i8*, i8*, i64)* @pred4x4_down_left_8_c
  store void (i8*, i8*, i64)* %513, void (i8*, i8*, i64)** %512, align 8
  %514 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 4
  %515 = bitcast void (i8*, i8*, i64)** %514 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_right_8_c, void (i8*, i8*, i64)* @pred4x4_vertical_right_8_c>, <2 x void (i8*, i8*, i64)*>* %515, align 8
  %516 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 6
  store void (i8*, i8*, i64)* @pred4x4_horizontal_down_8_c, void (i8*, i8*, i64)** %516, align 8
  %517 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 7
  %518 = select i1 %505, void (i8*, i8*, i64)* @pred4x4_vertical_left_vp8_c, void (i8*, i8*, i64)* @pred4x4_vertical_left_8_c
  store void (i8*, i8*, i64)* %518, void (i8*, i8*, i64)** %517, align 8
  %519 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 8
  store void (i8*, i8*, i64)* @pred4x4_horizontal_up_8_c, void (i8*, i8*, i64)** %519, align 8
  %520 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 9
  switch i32 %1, label %521 [
    i32 179, label %523
    i32 139, label %523
  ]

521:                                              ; preds = %507
  %522 = bitcast void (i8*, i8*, i64)** %520 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_left_dc_8_c, void (i8*, i8*, i64)* @pred4x4_top_dc_8_c>, <2 x void (i8*, i8*, i64)*>* %522, align 8
  br label %528

523:                                              ; preds = %507, %507
  %524 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 12
  %525 = bitcast void (i8*, i8*, i64)** %524 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_127_dc_8_c, void (i8*, i8*, i64)* @pred4x4_129_dc_8_c>, <2 x void (i8*, i8*, i64)*>* %525, align 8
  %526 = bitcast void (i8*, i8*, i64)** %520 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_tm_vp8_c, void (i8*, i8*, i64)* @pred4x4_vertical_8_c>, <2 x void (i8*, i8*, i64)*>* %526, align 8
  %527 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 14
  store void (i8*, i8*, i64)* @pred4x4_horizontal_8_c, void (i8*, i8*, i64)** %527, align 8
  br label %528

528:                                              ; preds = %523, %521
  br i1 %504, label %546, label %529

529:                                              ; preds = %528
  %530 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 11
  store void (i8*, i8*, i64)* @pred4x4_128_dc_8_c, void (i8*, i8*, i64)** %530, align 8
  br label %546

531:                                              ; preds = %500
  %532 = bitcast %struct.H264PredContext* %0 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_vertical_8_c, void (i8*, i8*, i64)* @pred4x4_horizontal_8_c>, <2 x void (i8*, i8*, i64)*>* %532, align 8
  %533 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 2
  %534 = bitcast void (i8*, i8*, i64)** %533 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_dc_8_c, void (i8*, i8*, i64)* @pred4x4_down_left_rv40_c>, <2 x void (i8*, i8*, i64)*>* %534, align 8
  %535 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 4
  %536 = bitcast void (i8*, i8*, i64)** %535 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_right_8_c, void (i8*, i8*, i64)* @pred4x4_vertical_right_8_c>, <2 x void (i8*, i8*, i64)*>* %536, align 8
  %537 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 6
  %538 = bitcast void (i8*, i8*, i64)** %537 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_horizontal_down_8_c, void (i8*, i8*, i64)* @pred4x4_vertical_left_rv40_c>, <2 x void (i8*, i8*, i64)*>* %538, align 8
  %539 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 8
  %540 = bitcast void (i8*, i8*, i64)** %539 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_horizontal_up_rv40_c, void (i8*, i8*, i64)* @pred4x4_left_dc_8_c>, <2 x void (i8*, i8*, i64)*>* %540, align 8
  %541 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 10
  %542 = bitcast void (i8*, i8*, i64)** %541 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_top_dc_8_c, void (i8*, i8*, i64)* @pred4x4_128_dc_8_c>, <2 x void (i8*, i8*, i64)*>* %542, align 8
  %543 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 12
  %544 = bitcast void (i8*, i8*, i64)** %543 to <2 x void (i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i64)*> <void (i8*, i8*, i64)* @pred4x4_down_left_rv40_nodown_c, void (i8*, i8*, i64)* @pred4x4_horizontal_up_rv40_nodown_c>, <2 x void (i8*, i8*, i64)*>* %544, align 8
  %545 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 0, i64 14
  store void (i8*, i8*, i64)* @pred4x4_vertical_left_rv40_nodown_c, void (i8*, i8*, i64)** %545, align 8
  br label %546

546:                                              ; preds = %528, %529, %531
  %547 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 0
  %548 = bitcast void (i8*, i32, i32, i64)** %547 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_vertical_8_c, void (i8*, i32, i32, i64)* @pred8x8l_horizontal_8_c>, <2 x void (i8*, i32, i32, i64)*>* %548, align 8
  %549 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 2
  %550 = bitcast void (i8*, i32, i32, i64)** %549 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_dc_8_c, void (i8*, i32, i32, i64)* @pred8x8l_down_left_8_c>, <2 x void (i8*, i32, i32, i64)*>* %550, align 8
  %551 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 4
  %552 = bitcast void (i8*, i32, i32, i64)** %551 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_down_right_8_c, void (i8*, i32, i32, i64)* @pred8x8l_vertical_right_8_c>, <2 x void (i8*, i32, i32, i64)*>* %552, align 8
  %553 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 6
  %554 = bitcast void (i8*, i32, i32, i64)** %553 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_horizontal_down_8_c, void (i8*, i32, i32, i64)* @pred8x8l_vertical_left_8_c>, <2 x void (i8*, i32, i32, i64)*>* %554, align 8
  %555 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 8
  %556 = bitcast void (i8*, i32, i32, i64)** %555 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_horizontal_up_8_c, void (i8*, i32, i32, i64)* @pred8x8l_left_dc_8_c>, <2 x void (i8*, i32, i32, i64)*>* %556, align 8
  %557 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 1, i64 10
  %558 = bitcast void (i8*, i32, i32, i64)** %557 to <2 x void (i8*, i32, i32, i64)*>*
  store <2 x void (i8*, i32, i32, i64)*> <void (i8*, i32, i32, i64)* @pred8x8l_top_dc_8_c, void (i8*, i32, i32, i64)* @pred8x8l_128_dc_8_c>, <2 x void (i8*, i32, i32, i64)*>* %558, align 8
  %559 = icmp slt i32 %3, 2
  %560 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2
  %561 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 2
  %562 = select i1 %559, void (i8*, i64)* @pred8x8_vertical_8_c, void (i8*, i64)* @pred8x16_vertical_8_c
  %563 = select i1 %559, void (i8*, i64)* @pred8x8_horizontal_8_c, void (i8*, i64)* @pred8x16_horizontal_8_c
  store void (i8*, i64)* %562, void (i8*, i64)** %561, align 8
  %564 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 1
  store void (i8*, i64)* %563, void (i8*, i64)** %564, align 8
  switch i32 %1, label %565 [
    i32 179, label %569
    i32 139, label %569
  ]

565:                                              ; preds = %546
  %566 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 3
  br i1 %559, label %567, label %568

567:                                              ; preds = %565
  store void (i8*, i64)* @pred8x8_plane_8_c, void (i8*, i64)** %566, align 8
  br label %571

568:                                              ; preds = %565
  store void (i8*, i64)* @pred8x16_plane_8_c, void (i8*, i64)** %566, align 8
  br label %571

569:                                              ; preds = %546, %546
  %570 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 3
  store void (i8*, i64)* @pred8x8_tm_vp8_c, void (i8*, i64)** %570, align 8
  br label %571

571:                                              ; preds = %567, %568, %569
  switch i32 %1, label %572 [
    i32 179, label %588
    i32 139, label %588
    i32 69, label %588
  ]

572:                                              ; preds = %571
  %573 = getelementptr inbounds [11 x void (i8*, i64)*], [11 x void (i8*, i64)*]* %560, i64 0, i64 0
  br i1 %559, label %574, label %581

574:                                              ; preds = %572
  store void (i8*, i64)* @pred8x8_dc_8_c, void (i8*, i64)** %573, align 8
  %575 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %576 = bitcast void (i8*, i64)** %575 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_left_dc_8_c, void (i8*, i64)* @pred8x8_top_dc_8_c>, <2 x void (i8*, i64)*>* %576, align 8
  %577 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %578 = bitcast void (i8*, i64)** %577 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_mad_cow_dc_l0t_8, void (i8*, i64)* @pred8x8_mad_cow_dc_0lt_8>, <2 x void (i8*, i64)*>* %578, align 8
  %579 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 9
  %580 = bitcast void (i8*, i64)** %579 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_mad_cow_dc_l00_8, void (i8*, i64)* @pred8x8_mad_cow_dc_0l0_8>, <2 x void (i8*, i64)*>* %580, align 8
  br label %595

581:                                              ; preds = %572
  store void (i8*, i64)* @pred8x16_dc_8_c, void (i8*, i64)** %573, align 8
  %582 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %583 = bitcast void (i8*, i64)** %582 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_left_dc_8_c, void (i8*, i64)* @pred8x16_top_dc_8_c>, <2 x void (i8*, i64)*>* %583, align 8
  %584 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %585 = bitcast void (i8*, i64)** %584 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_mad_cow_dc_l0t_8, void (i8*, i64)* @pred8x16_mad_cow_dc_0lt_8>, <2 x void (i8*, i64)*>* %585, align 8
  %586 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 9
  %587 = bitcast void (i8*, i64)** %586 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x16_mad_cow_dc_l00_8, void (i8*, i64)* @pred8x16_mad_cow_dc_0l0_8>, <2 x void (i8*, i64)*>* %587, align 8
  br label %595

588:                                              ; preds = %571, %571, %571
  %589 = getelementptr inbounds [11 x void (i8*, i64)*], [11 x void (i8*, i64)*]* %560, i64 0, i64 0
  store void (i8*, i64)* @pred8x8_dc_rv40_c, void (i8*, i64)** %589, align 8
  %590 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 4
  %591 = bitcast void (i8*, i64)** %590 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_left_dc_rv40_c, void (i8*, i64)* @pred8x8_top_dc_rv40_c>, <2 x void (i8*, i64)*>* %591, align 8
  switch i32 %1, label %595 [
    i32 179, label %592
    i32 139, label %592
  ]

592:                                              ; preds = %588, %588
  %593 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 7
  %594 = bitcast void (i8*, i64)** %593 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred8x8_127_dc_8_c, void (i8*, i64)* @pred8x8_129_dc_8_c>, <2 x void (i8*, i64)*>* %594, align 8
  br label %595

595:                                              ; preds = %588, %592, %574, %581
  %596 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 2, i64 6
  %597 = select i1 %559, void (i8*, i64)* @pred8x8_128_dc_8_c, void (i8*, i64)* @pred8x16_128_dc_8_c
  store void (i8*, i64)* %597, void (i8*, i64)** %596, align 8
  %598 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 0
  %599 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 2
  store void (i8*, i64)* @pred16x16_vertical_8_c, void (i8*, i64)** %599, align 8
  %600 = bitcast void (i8*, i64)** %598 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_dc_8_c, void (i8*, i64)* @pred16x16_horizontal_8_c>, <2 x void (i8*, i64)*>* %600, align 8
  switch i32 %1, label %609 [
    i32 23, label %601
    i32 69, label %603
    i32 179, label %605
    i32 139, label %605
  ]

601:                                              ; preds = %595
  %602 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_svq3_c, void (i8*, i64)** %602, align 8
  br label %611

603:                                              ; preds = %595
  %604 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_rv40_c, void (i8*, i64)** %604, align 8
  br label %611

605:                                              ; preds = %595, %595
  %606 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_tm_vp8_c, void (i8*, i64)** %606, align 8
  %607 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 7
  %608 = bitcast void (i8*, i64)** %607 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_127_dc_8_c, void (i8*, i64)* @pred16x16_129_dc_8_c>, <2 x void (i8*, i64)*>* %608, align 8
  br label %611

609:                                              ; preds = %595
  %610 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 3
  store void (i8*, i64)* @pred16x16_plane_8_c, void (i8*, i64)** %610, align 8
  br label %611

611:                                              ; preds = %609, %605, %603, %601
  %612 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 4
  %613 = bitcast void (i8*, i64)** %612 to <2 x void (i8*, i64)*>*
  store <2 x void (i8*, i64)*> <void (i8*, i64)* @pred16x16_left_dc_8_c, void (i8*, i64)* @pred16x16_top_dc_8_c>, <2 x void (i8*, i64)*>* %613, align 8
  %614 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 3, i64 6
  store void (i8*, i64)* @pred16x16_128_dc_8_c, void (i8*, i64)** %614, align 8
  %615 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 4, i64 0
  %616 = bitcast void (i8*, i16*, i64)** %615 to <2 x void (i8*, i16*, i64)*>*
  store <2 x void (i8*, i16*, i64)*> <void (i8*, i16*, i64)* @pred4x4_vertical_add_8_c, void (i8*, i16*, i64)* @pred4x4_horizontal_add_8_c>, <2 x void (i8*, i16*, i64)*>* %616, align 8
  %617 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 5, i64 0
  %618 = bitcast void (i8*, i16*, i64)** %617 to <2 x void (i8*, i16*, i64)*>*
  store <2 x void (i8*, i16*, i64)*> <void (i8*, i16*, i64)* @pred8x8l_vertical_add_8_c, void (i8*, i16*, i64)* @pred8x8l_horizontal_add_8_c>, <2 x void (i8*, i16*, i64)*>* %618, align 8
  %619 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 6, i64 0
  %620 = bitcast void (i8*, i16*, i32, i32, i64)** %619 to <2 x void (i8*, i16*, i32, i32, i64)*>*
  store <2 x void (i8*, i16*, i32, i32, i64)*> <void (i8*, i16*, i32, i32, i64)* @pred8x8l_vertical_filter_add_8_c, void (i8*, i16*, i32, i32, i64)* @pred8x8l_horizontal_filter_add_8_c>, <2 x void (i8*, i16*, i32, i32, i64)*>* %620, align 8
  %621 = select i1 %559, void (i8*, i32*, i16*, i64)* @pred8x8_vertical_add_8_c, void (i8*, i32*, i16*, i64)* @pred8x16_vertical_add_8_c
  %622 = select i1 %559, void (i8*, i32*, i16*, i64)* @pred8x8_horizontal_add_8_c, void (i8*, i32*, i16*, i64)* @pred8x16_horizontal_add_8_c
  br label %623

623:                                              ; preds = %611, %485, %362, %239, %116
  %624 = phi void (i8*, i32*, i16*, i64)* [ %621, %611 ], [ %495, %485 ], [ %372, %362 ], [ %249, %239 ], [ %126, %116 ]
  %625 = phi void (i8*, i32*, i16*, i64)* [ %622, %611 ], [ %496, %485 ], [ %373, %362 ], [ %250, %239 ], [ %127, %116 ]
  %626 = phi <2 x void (i8*, i32*, i16*, i64)*> [ <void (i8*, i32*, i16*, i64)* @pred16x16_horizontal_add_8_c, void (i8*, i32*, i16*, i64)* @pred16x16_vertical_add_8_c>, %611 ], [ <void (i8*, i32*, i16*, i64)* @pred16x16_horizontal_add_14_c, void (i8*, i32*, i16*, i64)* @pred16x16_vertical_add_14_c>, %485 ], [ <void (i8*, i32*, i16*, i64)* @pred16x16_horizontal_add_12_c, void (i8*, i32*, i16*, i64)* @pred16x16_vertical_add_12_c>, %362 ], [ <void (i8*, i32*, i16*, i64)* @pred16x16_horizontal_add_10_c, void (i8*, i32*, i16*, i64)* @pred16x16_vertical_add_10_c>, %239 ], [ <void (i8*, i32*, i16*, i64)* @pred16x16_horizontal_add_9_c, void (i8*, i32*, i16*, i64)* @pred16x16_vertical_add_9_c>, %116 ]
  %627 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 7, i64 2
  store void (i8*, i32*, i16*, i64)* %624, void (i8*, i32*, i16*, i64)** %627, align 8
  %628 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 7, i64 1
  store void (i8*, i32*, i16*, i64)* %625, void (i8*, i32*, i16*, i64)** %628, align 8
  %629 = getelementptr inbounds %struct.H264PredContext, %struct.H264PredContext* %0, i64 0, i32 8, i64 1
  %630 = bitcast void (i8*, i32*, i16*, i64)** %629 to <2 x void (i8*, i32*, i16*, i64)*>*
  store <2 x void (i8*, i32*, i16*, i64)*> %626, <2 x void (i8*, i32*, i16*, i64)*>* %630, align 8
  tail call void @ff_h264_pred_init_x86(%struct.H264PredContext* %0, i32 %1, i32 %2, i32 %3) #8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_vp8_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = xor i64 %2, -1
  %5 = getelementptr inbounds i8, i8* %0, i64 %4
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = sub nsw i64 0, %2
  %9 = getelementptr inbounds i8, i8* %0, i64 %8
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i32
  %12 = sub nsw i64 1, %2
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = sub nsw i64 2, %2
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = sub nsw i64 3, %2
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = load i8, i8* %21, align 1
  %23 = zext i8 %22 to i32
  %24 = load i8, i8* %1, align 1
  %25 = zext i8 %24 to i32
  %26 = shl nuw nsw i32 %23, 1
  %27 = add nuw nsw i32 %19, 2
  %28 = add nuw nsw i32 %27, %26
  %29 = add nuw nsw i32 %28, %25
  %30 = lshr i32 %29, 2
  %31 = shl i32 %30, 24
  %32 = shl nuw nsw i32 %19, 1
  %33 = add nuw nsw i32 %15, 2
  %34 = add nuw nsw i32 %33, %32
  %35 = add nuw nsw i32 %34, %23
  %36 = lshr i32 %35, 2
  %37 = shl nuw nsw i32 %36, 16
  %38 = shl nuw nsw i32 %15, 1
  %39 = add nuw nsw i32 %27, %11
  %40 = add nuw nsw i32 %39, %38
  %41 = lshr i32 %40, 2
  %42 = shl nuw nsw i32 %41, 8
  %43 = shl nuw nsw i32 %11, 1
  %44 = add nuw nsw i32 %33, %7
  %45 = add nuw nsw i32 %44, %43
  %46 = lshr i32 %45, 2
  %47 = or i32 %42, %46
  %48 = or i32 %47, %37
  %49 = or i32 %48, %31
  %50 = bitcast i8* %0 to i32*
  store i32 %49, i32* %50, align 4
  %51 = getelementptr inbounds i8, i8* %0, i64 %2
  %52 = bitcast i8* %51 to i32*
  store i32 %49, i32* %52, align 4
  %53 = shl nsw i64 %2, 1
  %54 = getelementptr inbounds i8, i8* %0, i64 %53
  %55 = bitcast i8* %54 to i32*
  store i32 %49, i32* %55, align 4
  %56 = mul nsw i64 %2, 3
  %57 = getelementptr inbounds i8, i8* %0, i64 %56
  %58 = bitcast i8* %57 to i32*
  store i32 %49, i32* %58, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_vp8_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = xor i64 %2, -1
  %5 = getelementptr inbounds i8, i8* %0, i64 %4
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = getelementptr inbounds i8, i8* %0, i64 -1
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = add nsw i64 %2, -1
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = shl nsw i64 %2, 1
  %16 = add nsw i64 %15, -1
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = mul nsw i64 %2, 3
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = shl nuw nsw i32 %10, 1
  %26 = add nuw nsw i32 %14, 2
  %27 = add nuw nsw i32 %26, %7
  %28 = add nuw nsw i32 %27, %25
  %29 = lshr i32 %28, 2
  %30 = mul i32 %29, 16843009
  %31 = bitcast i8* %0 to i32*
  store i32 %30, i32* %31, align 4
  %32 = shl nuw nsw i32 %14, 1
  %33 = add nuw nsw i32 %19, 2
  %34 = add nuw nsw i32 %33, %10
  %35 = add nuw nsw i32 %34, %32
  %36 = lshr i32 %35, 2
  %37 = mul i32 %36, 16843009
  %38 = getelementptr inbounds i8, i8* %0, i64 %2
  %39 = bitcast i8* %38 to i32*
  store i32 %37, i32* %39, align 4
  %40 = shl nuw nsw i32 %19, 1
  %41 = add nuw nsw i32 %26, %40
  %42 = add nuw nsw i32 %41, %24
  %43 = lshr i32 %42, 2
  %44 = mul i32 %43, 16843009
  %45 = getelementptr inbounds i8, i8* %0, i64 %15
  %46 = bitcast i8* %45 to i32*
  store i32 %44, i32* %46, align 4
  %47 = shl nuw nsw i32 %24, 1
  %48 = add nuw nsw i32 %33, %24
  %49 = add nuw nsw i32 %48, %47
  %50 = lshr i32 %49, 2
  %51 = mul i32 %50, 16843009
  %52 = getelementptr inbounds i8, i8* %0, i64 %20
  %53 = bitcast i8* %52 to i32*
  store i32 %51, i32* %53, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_9_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = shl i64 %5, 32
  %7 = ashr exact i64 %6, 32
  %8 = sub nsw i64 0, %7
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  %11 = load i64, i64* %10, align 8
  %12 = bitcast i8* %0 to i64*
  store i64 %11, i64* %12, align 8
  %13 = getelementptr inbounds i16, i16* %4, i64 %7
  %14 = bitcast i16* %13 to i64*
  store i64 %11, i64* %14, align 8
  %15 = shl i64 %2, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 %11, i64* %19, align 8
  %20 = mul i64 %5, 12884901888
  %21 = ashr exact i64 %20, 32
  %22 = getelementptr inbounds i16, i16* %4, i64 %21
  %23 = bitcast i16* %22 to i64*
  store i64 %11, i64* %23, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_9_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = mul nuw i64 %10, 281479271743489
  %12 = bitcast i8* %0 to i64*
  store i64 %11, i64* %12, align 8
  %13 = shl i64 %5, 32
  %14 = add i64 %13, -4294967296
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i16, i16* %4, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i64
  %19 = mul nuw i64 %18, 281479271743489
  %20 = ashr exact i64 %13, 32
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = bitcast i16* %21 to i64*
  store i64 %19, i64* %22, align 8
  %23 = trunc i64 %2 to i32
  %24 = and i32 %23, -2
  %25 = add nsw i32 %24, -1
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds i16, i16* %4, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i64
  %30 = mul nuw i64 %29, 281479271743489
  %31 = sext i32 %24 to i64
  %32 = getelementptr inbounds i16, i16* %4, i64 %31
  %33 = bitcast i16* %32 to i64*
  store i64 %30, i64* %33, align 8
  %34 = mul nsw i32 %6, 3
  %35 = add nsw i32 %34, -1
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds i16, i16* %4, i64 %36
  %38 = load i16, i16* %37, align 2
  %39 = zext i16 %38 to i64
  %40 = mul nuw i64 %39, 281479271743489
  %41 = sext i32 %34 to i64
  %42 = getelementptr inbounds i16, i16* %4, i64 %41
  %43 = bitcast i16* %42 to i64*
  store i64 %40, i64* %43, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_dc_9_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = sub i64 0, %7
  %9 = ashr exact i64 %8, 32
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 4294967296, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 8589934592, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 12884901888, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = getelementptr inbounds i8, i8* %0, i64 -2
  %29 = bitcast i8* %28 to i16*
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i32
  %32 = add i64 %7, -4294967296
  %33 = ashr exact i64 %32, 32
  %34 = getelementptr inbounds i16, i16* %4, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = trunc i64 %2 to i32
  %38 = and i32 %37, -2
  %39 = add nsw i32 %38, -1
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds i16, i16* %4, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = mul nsw i32 %6, 3
  %45 = add nsw i32 %44, -1
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds i16, i16* %4, i64 %46
  %48 = load i16, i16* %47, align 2
  %49 = zext i16 %48 to i32
  %50 = add nuw nsw i32 %12, 4
  %51 = add nuw nsw i32 %50, %17
  %52 = add nuw nsw i32 %51, %22
  %53 = add nuw nsw i32 %52, %27
  %54 = add nuw nsw i32 %53, %31
  %55 = add nuw nsw i32 %54, %36
  %56 = add nuw nsw i32 %55, %43
  %57 = add nuw nsw i32 %56, %49
  %58 = ashr i32 %57, 3
  %59 = sext i32 %58 to i64
  %60 = mul i64 %59, 281479271743489
  %61 = bitcast i8* %0 to i64*
  store i64 %60, i64* %61, align 8
  %62 = ashr exact i64 %7, 32
  %63 = getelementptr inbounds i16, i16* %4, i64 %62
  %64 = bitcast i16* %63 to i64*
  store i64 %60, i64* %64, align 8
  %65 = sext i32 %38 to i64
  %66 = getelementptr inbounds i16, i16* %4, i64 %65
  %67 = bitcast i16* %66 to i64*
  store i64 %60, i64* %67, align 8
  %68 = sext i32 %44 to i64
  %69 = getelementptr inbounds i16, i16* %4, i64 %68
  %70 = bitcast i16* %69 to i64*
  store i64 %60, i64* %70, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_down_left_svq3_c(i8*, i8* nocapture readnone, i64) #1 {
  %4 = sub nsw i64 1, %2
  %5 = getelementptr inbounds i8, i8* %0, i64 %4
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = sub nsw i64 2, %2
  %9 = getelementptr inbounds i8, i8* %0, i64 %8
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i32
  %12 = sub nsw i64 3, %2
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = add nsw i64 %2, -1
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = shl nsw i64 %2, 1
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = mul nsw i64 %2, 3
  %26 = add nsw i64 %25, -1
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i32
  %30 = add nuw nsw i32 %19, %7
  %31 = lshr i32 %30, 1
  %32 = trunc i32 %31 to i8
  store i8 %32, i8* %0, align 1
  %33 = add nuw nsw i32 %24, %11
  %34 = lshr i32 %33, 1
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds i8, i8* %0, i64 %2
  store i8 %35, i8* %36, align 1
  %37 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %35, i8* %37, align 1
  %38 = add nuw nsw i32 %29, %15
  %39 = lshr i32 %38, 1
  %40 = trunc i32 %39 to i8
  %41 = add nsw i64 %25, 3
  %42 = getelementptr inbounds i8, i8* %0, i64 %41
  store i8 %40, i8* %42, align 1
  %43 = add nsw i64 %25, 2
  %44 = getelementptr inbounds i8, i8* %0, i64 %43
  store i8 %40, i8* %44, align 1
  %45 = add nsw i64 %20, 3
  %46 = getelementptr inbounds i8, i8* %0, i64 %45
  store i8 %40, i8* %46, align 1
  %47 = add nsw i64 %25, 1
  %48 = getelementptr inbounds i8, i8* %0, i64 %47
  store i8 %40, i8* %48, align 1
  %49 = add nsw i64 %20, 2
  %50 = getelementptr inbounds i8, i8* %0, i64 %49
  store i8 %40, i8* %50, align 1
  %51 = add nsw i64 %2, 3
  %52 = getelementptr inbounds i8, i8* %0, i64 %51
  store i8 %40, i8* %52, align 1
  %53 = getelementptr inbounds i8, i8* %0, i64 %25
  store i8 %40, i8* %53, align 1
  %54 = or i64 %20, 1
  %55 = getelementptr inbounds i8, i8* %0, i64 %54
  store i8 %40, i8* %55, align 1
  %56 = add nsw i64 %2, 2
  %57 = getelementptr inbounds i8, i8* %0, i64 %56
  store i8 %40, i8* %57, align 1
  %58 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %40, i8* %58, align 1
  %59 = getelementptr inbounds i8, i8* %0, i64 %20
  store i8 %40, i8* %59, align 1
  %60 = add nsw i64 %2, 1
  %61 = getelementptr inbounds i8, i8* %0, i64 %60
  store i8 %40, i8* %61, align 1
  %62 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %40, i8* %62, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_down_left_9_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i8* %1 to i16*
  %6 = lshr i64 %2, 1
  %7 = trunc i64 %6 to i32
  %8 = shl i64 %6, 32
  %9 = sub i64 0, %8
  %10 = ashr exact i64 %9, 32
  %11 = getelementptr inbounds i16, i16* %4, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i32
  %14 = sub i64 4294967296, %8
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i16, i16* %4, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i32
  %19 = sub i64 8589934592, %8
  %20 = ashr exact i64 %19, 32
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = sub i64 12884901888, %8
  %25 = ashr exact i64 %24, 32
  %26 = getelementptr inbounds i16, i16* %4, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %5, align 2
  %30 = zext i16 %29 to i32
  %31 = getelementptr inbounds i8, i8* %1, i64 2
  %32 = bitcast i8* %31 to i16*
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = getelementptr inbounds i8, i8* %1, i64 4
  %36 = bitcast i8* %35 to i16*
  %37 = load i16, i16* %36, align 2
  %38 = zext i16 %37 to i32
  %39 = getelementptr inbounds i8, i8* %1, i64 6
  %40 = bitcast i8* %39 to i16*
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i32
  %43 = shl nuw nsw i32 %18, 1
  %44 = add nuw nsw i32 %23, 2
  %45 = add nuw nsw i32 %44, %13
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = trunc i32 %47 to i16
  store i16 %48, i16* %4, align 2
  %49 = shl nuw nsw i32 %23, 1
  %50 = add nuw nsw i32 %28, 2
  %51 = add nuw nsw i32 %50, %18
  %52 = add nuw nsw i32 %51, %49
  %53 = lshr i32 %52, 2
  %54 = trunc i32 %53 to i16
  %55 = ashr exact i64 %8, 32
  %56 = getelementptr inbounds i16, i16* %4, i64 %55
  store i16 %54, i16* %56, align 2
  %57 = getelementptr inbounds i8, i8* %0, i64 2
  %58 = bitcast i8* %57 to i16*
  store i16 %54, i16* %58, align 2
  %59 = shl nuw nsw i32 %28, 1
  %60 = add nuw nsw i32 %44, %30
  %61 = add nuw nsw i32 %60, %59
  %62 = lshr i32 %61, 2
  %63 = trunc i32 %62 to i16
  %64 = trunc i64 %2 to i32
  %65 = and i32 %64, -2
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds i16, i16* %4, i64 %66
  store i16 %63, i16* %67, align 2
  %68 = add i64 %8, 4294967296
  %69 = ashr exact i64 %68, 32
  %70 = getelementptr inbounds i16, i16* %4, i64 %69
  store i16 %63, i16* %70, align 2
  %71 = getelementptr inbounds i8, i8* %0, i64 4
  %72 = bitcast i8* %71 to i16*
  store i16 %63, i16* %72, align 2
  %73 = shl nuw nsw i32 %30, 1
  %74 = add nuw nsw i32 %50, %34
  %75 = add nuw nsw i32 %74, %73
  %76 = lshr i32 %75, 2
  %77 = trunc i32 %76 to i16
  %78 = mul nsw i32 %7, 3
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i16, i16* %4, i64 %79
  store i16 %77, i16* %80, align 2
  %81 = shl i64 %2, 32
  %82 = ashr exact i64 %81, 32
  %83 = or i64 %82, 1
  %84 = getelementptr inbounds i16, i16* %4, i64 %83
  store i16 %77, i16* %84, align 2
  %85 = add i64 %8, 8589934592
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i16, i16* %4, i64 %86
  store i16 %77, i16* %87, align 2
  %88 = getelementptr inbounds i8, i8* %0, i64 6
  %89 = bitcast i8* %88 to i16*
  store i16 %77, i16* %89, align 2
  %90 = shl nuw nsw i32 %34, 1
  %91 = add nuw nsw i32 %30, 2
  %92 = add nuw nsw i32 %91, %38
  %93 = add nuw nsw i32 %92, %90
  %94 = lshr i32 %93, 2
  %95 = trunc i32 %94 to i16
  %96 = add nsw i32 %78, 1
  %97 = sext i32 %96 to i64
  %98 = getelementptr inbounds i16, i16* %4, i64 %97
  store i16 %95, i16* %98, align 2
  %99 = add nsw i32 %65, 2
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds i16, i16* %4, i64 %100
  store i16 %95, i16* %101, align 2
  %102 = add i64 %8, 12884901888
  %103 = ashr exact i64 %102, 32
  %104 = getelementptr inbounds i16, i16* %4, i64 %103
  store i16 %95, i16* %104, align 2
  %105 = shl nuw nsw i32 %38, 1
  %106 = add nuw nsw i32 %34, 2
  %107 = add nuw nsw i32 %106, %42
  %108 = add nuw nsw i32 %107, %105
  %109 = lshr i32 %108, 2
  %110 = trunc i32 %109 to i16
  %111 = add nsw i32 %78, 2
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds i16, i16* %4, i64 %112
  store i16 %110, i16* %113, align 2
  %114 = add nsw i32 %65, 3
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds i16, i16* %4, i64 %115
  store i16 %110, i16* %116, align 2
  %117 = mul nuw nsw i32 %42, 3
  %118 = add nuw nsw i32 %38, 2
  %119 = add nuw nsw i32 %118, %117
  %120 = lshr i32 %119, 2
  %121 = trunc i32 %120 to i16
  %122 = add nsw i32 %78, 3
  %123 = sext i32 %122 to i64
  %124 = getelementptr inbounds i16, i16* %4, i64 %123
  store i16 %121, i16* %124, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_down_right_9_c(i8*, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = xor i64 %8, -1
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 0, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 4294967296, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 8589934592, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = sub i64 12884901888, %7
  %29 = ashr exact i64 %28, 32
  %30 = getelementptr inbounds i16, i16* %4, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i32
  %33 = getelementptr inbounds i8, i8* %0, i64 -2
  %34 = bitcast i8* %33 to i16*
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = add i64 %7, -4294967296
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i16, i16* %4, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i32
  %42 = trunc i64 %2 to i32
  %43 = and i32 %42, -2
  %44 = add nsw i32 %43, -1
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i16, i16* %4, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i32
  %49 = mul nsw i32 %6, 3
  %50 = add nsw i32 %49, -1
  %51 = sext i32 %50 to i64
  %52 = getelementptr inbounds i16, i16* %4, i64 %51
  %53 = load i16, i16* %52, align 2
  %54 = zext i16 %53 to i32
  %55 = shl nuw nsw i32 %48, 1
  %56 = add nuw nsw i32 %41, 2
  %57 = add nuw nsw i32 %56, %54
  %58 = add nuw nsw i32 %57, %55
  %59 = lshr i32 %58, 2
  %60 = trunc i32 %59 to i16
  %61 = sext i32 %49 to i64
  %62 = getelementptr inbounds i16, i16* %4, i64 %61
  store i16 %60, i16* %62, align 2
  %63 = shl nuw nsw i32 %41, 1
  %64 = add nuw nsw i32 %36, 2
  %65 = add nuw nsw i32 %64, %48
  %66 = add nuw nsw i32 %65, %63
  %67 = lshr i32 %66, 2
  %68 = trunc i32 %67 to i16
  %69 = add nsw i32 %49, 1
  %70 = sext i32 %69 to i64
  %71 = getelementptr inbounds i16, i16* %4, i64 %70
  store i16 %68, i16* %71, align 2
  %72 = sext i32 %43 to i64
  %73 = getelementptr inbounds i16, i16* %4, i64 %72
  store i16 %68, i16* %73, align 2
  %74 = shl nuw nsw i32 %36, 1
  %75 = add nuw nsw i32 %12, 2
  %76 = add nuw nsw i32 %75, %41
  %77 = add nuw nsw i32 %76, %74
  %78 = lshr i32 %77, 2
  %79 = trunc i32 %78 to i16
  %80 = add nsw i32 %49, 2
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds i16, i16* %4, i64 %81
  store i16 %79, i16* %82, align 2
  %83 = shl i64 %2, 32
  %84 = ashr exact i64 %83, 32
  %85 = or i64 %84, 1
  %86 = getelementptr inbounds i16, i16* %4, i64 %85
  store i16 %79, i16* %86, align 2
  %87 = getelementptr inbounds i16, i16* %4, i64 %8
  store i16 %79, i16* %87, align 2
  %88 = shl nuw nsw i32 %12, 1
  %89 = add nuw nsw i32 %17, 2
  %90 = add nuw nsw i32 %89, %88
  %91 = add nuw nsw i32 %90, %36
  %92 = lshr i32 %91, 2
  %93 = trunc i32 %92 to i16
  %94 = add nsw i32 %49, 3
  %95 = sext i32 %94 to i64
  %96 = getelementptr inbounds i16, i16* %4, i64 %95
  store i16 %93, i16* %96, align 2
  %97 = add nsw i32 %43, 2
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds i16, i16* %4, i64 %98
  store i16 %93, i16* %99, align 2
  %100 = add i64 %7, 4294967296
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %4, i64 %101
  store i16 %93, i16* %102, align 2
  store i16 %93, i16* %4, align 2
  %103 = shl nuw nsw i32 %17, 1
  %104 = add nuw nsw i32 %75, %103
  %105 = add nuw nsw i32 %104, %22
  %106 = lshr i32 %105, 2
  %107 = trunc i32 %106 to i16
  %108 = add nsw i32 %43, 3
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds i16, i16* %4, i64 %109
  store i16 %107, i16* %110, align 2
  %111 = add i64 %7, 8589934592
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds i16, i16* %4, i64 %112
  store i16 %107, i16* %113, align 2
  %114 = getelementptr inbounds i8, i8* %0, i64 2
  %115 = bitcast i8* %114 to i16*
  store i16 %107, i16* %115, align 2
  %116 = shl nuw nsw i32 %22, 1
  %117 = add nuw nsw i32 %89, %116
  %118 = add nuw nsw i32 %117, %27
  %119 = lshr i32 %118, 2
  %120 = trunc i32 %119 to i16
  %121 = add i64 %7, 12884901888
  %122 = ashr exact i64 %121, 32
  %123 = getelementptr inbounds i16, i16* %4, i64 %122
  store i16 %120, i16* %123, align 2
  %124 = getelementptr inbounds i8, i8* %0, i64 4
  %125 = bitcast i8* %124 to i16*
  store i16 %120, i16* %125, align 2
  %126 = shl nuw nsw i32 %27, 1
  %127 = add nuw nsw i32 %22, 2
  %128 = add nuw nsw i32 %127, %126
  %129 = add nuw nsw i32 %128, %32
  %130 = lshr i32 %129, 2
  %131 = trunc i32 %130 to i16
  %132 = getelementptr inbounds i8, i8* %0, i64 6
  %133 = bitcast i8* %132 to i16*
  store i16 %131, i16* %133, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_right_9_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = xor i64 %8, -1
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 0, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 4294967296, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 8589934592, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = sub i64 12884901888, %7
  %29 = ashr exact i64 %28, 32
  %30 = getelementptr inbounds i16, i16* %4, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i32
  %33 = getelementptr inbounds i8, i8* %0, i64 -2
  %34 = bitcast i8* %33 to i16*
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = add i64 %7, -4294967296
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i16, i16* %4, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i32
  %42 = trunc i64 %2 to i32
  %43 = and i32 %42, -2
  %44 = add nsw i32 %43, -1
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i16, i16* %4, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i32
  %49 = mul nsw i32 %6, 3
  %50 = add nuw nsw i32 %17, 1
  %51 = add nuw nsw i32 %50, %12
  %52 = lshr i32 %51, 1
  %53 = trunc i32 %52 to i16
  %54 = shl i64 %2, 32
  %55 = ashr exact i64 %54, 32
  %56 = or i64 %55, 1
  %57 = getelementptr inbounds i16, i16* %4, i64 %56
  store i16 %53, i16* %57, align 2
  store i16 %53, i16* %4, align 2
  %58 = add nuw nsw i32 %50, %22
  %59 = lshr i32 %58, 1
  %60 = trunc i32 %59 to i16
  %61 = add nsw i32 %43, 2
  %62 = sext i32 %61 to i64
  %63 = getelementptr inbounds i16, i16* %4, i64 %62
  store i16 %60, i16* %63, align 2
  %64 = getelementptr inbounds i8, i8* %0, i64 2
  %65 = bitcast i8* %64 to i16*
  store i16 %60, i16* %65, align 2
  %66 = add nuw nsw i32 %22, 1
  %67 = add nuw nsw i32 %66, %27
  %68 = lshr i32 %67, 1
  %69 = trunc i32 %68 to i16
  %70 = add nsw i32 %43, 3
  %71 = sext i32 %70 to i64
  %72 = getelementptr inbounds i16, i16* %4, i64 %71
  store i16 %69, i16* %72, align 2
  %73 = getelementptr inbounds i8, i8* %0, i64 4
  %74 = bitcast i8* %73 to i16*
  store i16 %69, i16* %74, align 2
  %75 = add nuw nsw i32 %27, 1
  %76 = add nuw nsw i32 %75, %32
  %77 = lshr i32 %76, 1
  %78 = trunc i32 %77 to i16
  %79 = getelementptr inbounds i8, i8* %0, i64 6
  %80 = bitcast i8* %79 to i16*
  store i16 %78, i16* %80, align 2
  %81 = shl nuw nsw i32 %12, 1
  %82 = add nuw nsw i32 %17, 2
  %83 = add nuw nsw i32 %82, %81
  %84 = add nuw nsw i32 %83, %36
  %85 = lshr i32 %84, 2
  %86 = trunc i32 %85 to i16
  %87 = add nsw i32 %49, 1
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds i16, i16* %4, i64 %88
  store i16 %86, i16* %89, align 2
  %90 = getelementptr inbounds i16, i16* %4, i64 %8
  store i16 %86, i16* %90, align 2
  %91 = shl nuw nsw i32 %17, 1
  %92 = add nuw nsw i32 %12, 2
  %93 = add nuw nsw i32 %92, %91
  %94 = add nuw nsw i32 %93, %22
  %95 = lshr i32 %94, 2
  %96 = trunc i32 %95 to i16
  %97 = add nsw i32 %49, 2
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds i16, i16* %4, i64 %98
  store i16 %96, i16* %99, align 2
  %100 = add i64 %7, 4294967296
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %4, i64 %101
  store i16 %96, i16* %102, align 2
  %103 = shl nuw nsw i32 %22, 1
  %104 = add nuw nsw i32 %82, %103
  %105 = add nuw nsw i32 %104, %27
  %106 = lshr i32 %105, 2
  %107 = trunc i32 %106 to i16
  %108 = add nsw i32 %49, 3
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds i16, i16* %4, i64 %109
  store i16 %107, i16* %110, align 2
  %111 = add i64 %7, 8589934592
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds i16, i16* %4, i64 %112
  store i16 %107, i16* %113, align 2
  %114 = shl nuw nsw i32 %27, 1
  %115 = add nuw nsw i32 %22, 2
  %116 = add nuw nsw i32 %115, %114
  %117 = add nuw nsw i32 %116, %32
  %118 = lshr i32 %117, 2
  %119 = trunc i32 %118 to i16
  %120 = add i64 %7, 12884901888
  %121 = ashr exact i64 %120, 32
  %122 = getelementptr inbounds i16, i16* %4, i64 %121
  store i16 %119, i16* %122, align 2
  %123 = shl nuw nsw i32 %36, 1
  %124 = add nuw nsw i32 %92, %123
  %125 = add nuw nsw i32 %124, %41
  %126 = lshr i32 %125, 2
  %127 = trunc i32 %126 to i16
  %128 = sext i32 %43 to i64
  %129 = getelementptr inbounds i16, i16* %4, i64 %128
  store i16 %127, i16* %129, align 2
  %130 = shl nuw nsw i32 %41, 1
  %131 = add nuw nsw i32 %36, 2
  %132 = add nuw nsw i32 %131, %130
  %133 = add nuw nsw i32 %132, %48
  %134 = lshr i32 %133, 2
  %135 = trunc i32 %134 to i16
  %136 = sext i32 %49 to i64
  %137 = getelementptr inbounds i16, i16* %4, i64 %136
  store i16 %135, i16* %137, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_down_9_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = xor i64 %8, -1
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 0, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 4294967296, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 8589934592, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = getelementptr inbounds i8, i8* %0, i64 -2
  %29 = bitcast i8* %28 to i16*
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i32
  %32 = add i64 %7, -4294967296
  %33 = ashr exact i64 %32, 32
  %34 = getelementptr inbounds i16, i16* %4, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = trunc i64 %2 to i32
  %38 = and i32 %37, -2
  %39 = add nsw i32 %38, -1
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds i16, i16* %4, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = mul nsw i32 %6, 3
  %45 = add nsw i32 %44, -1
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds i16, i16* %4, i64 %46
  %48 = load i16, i16* %47, align 2
  %49 = zext i16 %48 to i32
  %50 = add nuw nsw i32 %31, 1
  %51 = add nuw nsw i32 %50, %12
  %52 = lshr i32 %51, 1
  %53 = trunc i32 %52 to i16
  %54 = add i64 %7, 8589934592
  %55 = ashr exact i64 %54, 32
  %56 = getelementptr inbounds i16, i16* %4, i64 %55
  store i16 %53, i16* %56, align 2
  store i16 %53, i16* %4, align 2
  %57 = shl nuw nsw i32 %12, 1
  %58 = add nuw nsw i32 %17, 2
  %59 = add nuw nsw i32 %58, %57
  %60 = add nuw nsw i32 %59, %31
  %61 = lshr i32 %60, 2
  %62 = trunc i32 %61 to i16
  %63 = add i64 %7, 12884901888
  %64 = ashr exact i64 %63, 32
  %65 = getelementptr inbounds i16, i16* %4, i64 %64
  store i16 %62, i16* %65, align 2
  %66 = getelementptr inbounds i8, i8* %0, i64 2
  %67 = bitcast i8* %66 to i16*
  store i16 %62, i16* %67, align 2
  %68 = shl nuw nsw i32 %17, 1
  %69 = add nuw nsw i32 %12, 2
  %70 = add nuw nsw i32 %69, %68
  %71 = add nuw nsw i32 %70, %22
  %72 = lshr i32 %71, 2
  %73 = trunc i32 %72 to i16
  %74 = getelementptr inbounds i8, i8* %0, i64 4
  %75 = bitcast i8* %74 to i16*
  store i16 %73, i16* %75, align 2
  %76 = shl nuw nsw i32 %22, 1
  %77 = add nuw nsw i32 %58, %76
  %78 = add nuw nsw i32 %77, %27
  %79 = lshr i32 %78, 2
  %80 = trunc i32 %79 to i16
  %81 = getelementptr inbounds i8, i8* %0, i64 6
  %82 = bitcast i8* %81 to i16*
  store i16 %80, i16* %82, align 2
  %83 = add nuw nsw i32 %50, %36
  %84 = lshr i32 %83, 1
  %85 = trunc i32 %84 to i16
  %86 = add nsw i32 %38, 2
  %87 = sext i32 %86 to i64
  %88 = getelementptr inbounds i16, i16* %4, i64 %87
  store i16 %85, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %4, i64 %8
  store i16 %85, i16* %89, align 2
  %90 = shl nuw nsw i32 %31, 1
  %91 = add nuw nsw i32 %69, %90
  %92 = add nuw nsw i32 %91, %36
  %93 = lshr i32 %92, 2
  %94 = trunc i32 %93 to i16
  %95 = add nsw i32 %38, 3
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %4, i64 %96
  store i16 %94, i16* %97, align 2
  %98 = add i64 %7, 4294967296
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i16, i16* %4, i64 %99
  store i16 %94, i16* %100, align 2
  %101 = add nuw nsw i32 %36, 1
  %102 = add nuw nsw i32 %101, %43
  %103 = lshr i32 %102, 1
  %104 = trunc i32 %103 to i16
  %105 = add nsw i32 %44, 2
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i16, i16* %4, i64 %106
  store i16 %104, i16* %107, align 2
  %108 = sext i32 %38 to i64
  %109 = getelementptr inbounds i16, i16* %4, i64 %108
  store i16 %104, i16* %109, align 2
  %110 = shl nuw nsw i32 %36, 1
  %111 = add nuw nsw i32 %31, 2
  %112 = add nuw nsw i32 %111, %110
  %113 = add nuw nsw i32 %112, %43
  %114 = lshr i32 %113, 2
  %115 = trunc i32 %114 to i16
  %116 = add nsw i32 %44, 3
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds i16, i16* %4, i64 %117
  store i16 %115, i16* %118, align 2
  %119 = shl i64 %2, 32
  %120 = ashr exact i64 %119, 32
  %121 = or i64 %120, 1
  %122 = getelementptr inbounds i16, i16* %4, i64 %121
  store i16 %115, i16* %122, align 2
  %123 = add nuw nsw i32 %43, 1
  %124 = add nuw nsw i32 %123, %49
  %125 = lshr i32 %124, 1
  %126 = trunc i32 %125 to i16
  %127 = sext i32 %44 to i64
  %128 = getelementptr inbounds i16, i16* %4, i64 %127
  store i16 %126, i16* %128, align 2
  %129 = shl nuw nsw i32 %43, 1
  %130 = add nuw nsw i32 %36, 2
  %131 = add nuw nsw i32 %130, %129
  %132 = add nuw nsw i32 %131, %49
  %133 = lshr i32 %132, 2
  %134 = trunc i32 %133 to i16
  %135 = add nsw i32 %44, 1
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds i16, i16* %4, i64 %136
  store i16 %134, i16* %137, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_left_vp8_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = sub nsw i64 0, %2
  %5 = getelementptr inbounds i8, i8* %0, i64 %4
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = sub nsw i64 1, %2
  %9 = getelementptr inbounds i8, i8* %0, i64 %8
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i32
  %12 = sub nsw i64 2, %2
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = sub nsw i64 3, %2
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = load i8, i8* %1, align 1
  %21 = zext i8 %20 to i32
  %22 = getelementptr inbounds i8, i8* %1, i64 1
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = getelementptr inbounds i8, i8* %1, i64 2
  %26 = load i8, i8* %25, align 1
  %27 = zext i8 %26 to i32
  %28 = getelementptr inbounds i8, i8* %1, i64 3
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = add nuw nsw i32 %11, 1
  %32 = add nuw nsw i32 %31, %7
  %33 = lshr i32 %32, 1
  %34 = trunc i32 %33 to i8
  store i8 %34, i8* %0, align 1
  %35 = add nuw nsw i32 %31, %15
  %36 = lshr i32 %35, 1
  %37 = trunc i32 %36 to i8
  %38 = shl nsw i64 %2, 1
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  store i8 %37, i8* %39, align 1
  %40 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %37, i8* %40, align 1
  %41 = add nuw nsw i32 %15, 1
  %42 = add nuw nsw i32 %41, %19
  %43 = lshr i32 %42, 1
  %44 = trunc i32 %43 to i8
  %45 = or i64 %38, 1
  %46 = getelementptr inbounds i8, i8* %0, i64 %45
  store i8 %44, i8* %46, align 1
  %47 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %44, i8* %47, align 1
  %48 = add nuw nsw i32 %19, 1
  %49 = add nuw nsw i32 %48, %21
  %50 = lshr i32 %49, 1
  %51 = trunc i32 %50 to i8
  %52 = add nsw i64 %38, 2
  %53 = getelementptr inbounds i8, i8* %0, i64 %52
  store i8 %51, i8* %53, align 1
  %54 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %51, i8* %54, align 1
  %55 = shl nuw nsw i32 %11, 1
  %56 = add nuw nsw i32 %15, 2
  %57 = add nuw nsw i32 %56, %7
  %58 = add nuw nsw i32 %57, %55
  %59 = lshr i32 %58, 2
  %60 = trunc i32 %59 to i8
  %61 = getelementptr inbounds i8, i8* %0, i64 %2
  store i8 %60, i8* %61, align 1
  %62 = shl nuw nsw i32 %15, 1
  %63 = add nuw nsw i32 %19, 2
  %64 = add nuw nsw i32 %63, %11
  %65 = add nuw nsw i32 %64, %62
  %66 = lshr i32 %65, 2
  %67 = trunc i32 %66 to i8
  %68 = mul nsw i64 %2, 3
  %69 = getelementptr inbounds i8, i8* %0, i64 %68
  store i8 %67, i8* %69, align 1
  %70 = add nsw i64 %2, 1
  %71 = getelementptr inbounds i8, i8* %0, i64 %70
  store i8 %67, i8* %71, align 1
  %72 = shl nuw nsw i32 %19, 1
  %73 = add nuw nsw i32 %56, %72
  %74 = add nuw nsw i32 %73, %21
  %75 = lshr i32 %74, 2
  %76 = trunc i32 %75 to i8
  %77 = add nsw i64 %68, 1
  %78 = getelementptr inbounds i8, i8* %0, i64 %77
  store i8 %76, i8* %78, align 1
  %79 = add nsw i64 %2, 2
  %80 = getelementptr inbounds i8, i8* %0, i64 %79
  store i8 %76, i8* %80, align 1
  %81 = shl nuw nsw i32 %21, 1
  %82 = add nuw nsw i32 %63, %81
  %83 = add nuw nsw i32 %82, %24
  %84 = lshr i32 %83, 2
  %85 = trunc i32 %84 to i8
  %86 = add nsw i64 %68, 2
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  store i8 %85, i8* %87, align 1
  %88 = add nsw i64 %2, 3
  %89 = getelementptr inbounds i8, i8* %0, i64 %88
  store i8 %85, i8* %89, align 1
  %90 = shl nuw nsw i32 %24, 1
  %91 = add nuw nsw i32 %21, 2
  %92 = add nuw nsw i32 %91, %90
  %93 = add nuw nsw i32 %92, %27
  %94 = lshr i32 %93, 2
  %95 = trunc i32 %94 to i8
  %96 = add nsw i64 %38, 3
  %97 = getelementptr inbounds i8, i8* %0, i64 %96
  store i8 %95, i8* %97, align 1
  %98 = shl nuw nsw i32 %27, 1
  %99 = add nuw nsw i32 %24, 2
  %100 = add nuw nsw i32 %99, %98
  %101 = add nuw nsw i32 %100, %30
  %102 = lshr i32 %101, 2
  %103 = trunc i32 %102 to i8
  %104 = add nsw i64 %68, 3
  %105 = getelementptr inbounds i8, i8* %0, i64 %104
  store i8 %103, i8* %105, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_left_9_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i8* %1 to i16*
  %6 = lshr i64 %2, 1
  %7 = trunc i64 %6 to i32
  %8 = shl i64 %6, 32
  %9 = sub i64 0, %8
  %10 = ashr exact i64 %9, 32
  %11 = getelementptr inbounds i16, i16* %4, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i32
  %14 = sub i64 4294967296, %8
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i16, i16* %4, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i32
  %19 = sub i64 8589934592, %8
  %20 = ashr exact i64 %19, 32
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = sub i64 12884901888, %8
  %25 = ashr exact i64 %24, 32
  %26 = getelementptr inbounds i16, i16* %4, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %5, align 2
  %30 = zext i16 %29 to i32
  %31 = getelementptr inbounds i8, i8* %1, i64 2
  %32 = bitcast i8* %31 to i16*
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = getelementptr inbounds i8, i8* %1, i64 4
  %36 = bitcast i8* %35 to i16*
  %37 = load i16, i16* %36, align 2
  %38 = zext i16 %37 to i32
  %39 = add nuw nsw i32 %18, 1
  %40 = add nuw nsw i32 %39, %13
  %41 = lshr i32 %40, 1
  %42 = trunc i32 %41 to i16
  store i16 %42, i16* %4, align 2
  %43 = add nuw nsw i32 %39, %23
  %44 = lshr i32 %43, 1
  %45 = trunc i32 %44 to i16
  %46 = trunc i64 %2 to i32
  %47 = and i32 %46, -2
  %48 = sext i32 %47 to i64
  %49 = getelementptr inbounds i16, i16* %4, i64 %48
  store i16 %45, i16* %49, align 2
  %50 = getelementptr inbounds i8, i8* %0, i64 2
  %51 = bitcast i8* %50 to i16*
  store i16 %45, i16* %51, align 2
  %52 = add nuw nsw i32 %23, 1
  %53 = add nuw nsw i32 %52, %28
  %54 = lshr i32 %53, 1
  %55 = trunc i32 %54 to i16
  %56 = shl i64 %2, 32
  %57 = ashr exact i64 %56, 32
  %58 = or i64 %57, 1
  %59 = getelementptr inbounds i16, i16* %4, i64 %58
  store i16 %55, i16* %59, align 2
  %60 = getelementptr inbounds i8, i8* %0, i64 4
  %61 = bitcast i8* %60 to i16*
  store i16 %55, i16* %61, align 2
  %62 = add nuw nsw i32 %28, 1
  %63 = add nuw nsw i32 %62, %30
  %64 = lshr i32 %63, 1
  %65 = trunc i32 %64 to i16
  %66 = add nsw i32 %47, 2
  %67 = sext i32 %66 to i64
  %68 = getelementptr inbounds i16, i16* %4, i64 %67
  store i16 %65, i16* %68, align 2
  %69 = getelementptr inbounds i8, i8* %0, i64 6
  %70 = bitcast i8* %69 to i16*
  store i16 %65, i16* %70, align 2
  %71 = add nuw nsw i32 %30, 1
  %72 = add nuw nsw i32 %71, %34
  %73 = lshr i32 %72, 1
  %74 = trunc i32 %73 to i16
  %75 = add nsw i32 %47, 3
  %76 = sext i32 %75 to i64
  %77 = getelementptr inbounds i16, i16* %4, i64 %76
  store i16 %74, i16* %77, align 2
  %78 = shl nuw nsw i32 %18, 1
  %79 = add nuw nsw i32 %23, 2
  %80 = add nuw nsw i32 %79, %13
  %81 = add nuw nsw i32 %80, %78
  %82 = lshr i32 %81, 2
  %83 = trunc i32 %82 to i16
  %84 = ashr exact i64 %8, 32
  %85 = getelementptr inbounds i16, i16* %4, i64 %84
  store i16 %83, i16* %85, align 2
  %86 = shl nuw nsw i32 %23, 1
  %87 = add nuw nsw i32 %28, 2
  %88 = add nuw nsw i32 %87, %18
  %89 = add nuw nsw i32 %88, %86
  %90 = lshr i32 %89, 2
  %91 = trunc i32 %90 to i16
  %92 = mul nsw i32 %7, 3
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds i16, i16* %4, i64 %93
  store i16 %91, i16* %94, align 2
  %95 = add i64 %8, 4294967296
  %96 = ashr exact i64 %95, 32
  %97 = getelementptr inbounds i16, i16* %4, i64 %96
  store i16 %91, i16* %97, align 2
  %98 = shl nuw nsw i32 %28, 1
  %99 = add nuw nsw i32 %79, %98
  %100 = add nuw nsw i32 %99, %30
  %101 = lshr i32 %100, 2
  %102 = trunc i32 %101 to i16
  %103 = add nsw i32 %92, 1
  %104 = sext i32 %103 to i64
  %105 = getelementptr inbounds i16, i16* %4, i64 %104
  store i16 %102, i16* %105, align 2
  %106 = add i64 %8, 8589934592
  %107 = ashr exact i64 %106, 32
  %108 = getelementptr inbounds i16, i16* %4, i64 %107
  store i16 %102, i16* %108, align 2
  %109 = shl nuw nsw i32 %30, 1
  %110 = add nuw nsw i32 %87, %109
  %111 = add nuw nsw i32 %110, %34
  %112 = lshr i32 %111, 2
  %113 = trunc i32 %112 to i16
  %114 = add nsw i32 %92, 2
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds i16, i16* %4, i64 %115
  store i16 %113, i16* %116, align 2
  %117 = add i64 %8, 12884901888
  %118 = ashr exact i64 %117, 32
  %119 = getelementptr inbounds i16, i16* %4, i64 %118
  store i16 %113, i16* %119, align 2
  %120 = shl nuw nsw i32 %34, 1
  %121 = add nuw nsw i32 %30, 2
  %122 = add nuw nsw i32 %121, %120
  %123 = add nuw nsw i32 %122, %38
  %124 = lshr i32 %123, 2
  %125 = trunc i32 %124 to i16
  %126 = add nsw i32 %92, 3
  %127 = sext i32 %126 to i64
  %128 = getelementptr inbounds i16, i16* %4, i64 %127
  store i16 %125, i16* %128, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_up_9_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i32
  %11 = shl i64 %5, 32
  %12 = add i64 %11, -4294967296
  %13 = ashr exact i64 %12, 32
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i32
  %17 = trunc i64 %2 to i32
  %18 = and i32 %17, -2
  %19 = add nsw i32 %18, -1
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = mul nsw i32 %6, 3
  %25 = add nsw i32 %24, -1
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds i16, i16* %4, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i32
  %30 = add nuw nsw i32 %16, 1
  %31 = add nuw nsw i32 %30, %10
  %32 = lshr i32 %31, 1
  %33 = trunc i32 %32 to i16
  store i16 %33, i16* %4, align 2
  %34 = shl nuw nsw i32 %16, 1
  %35 = add nuw nsw i32 %23, 2
  %36 = add nuw nsw i32 %35, %10
  %37 = add nuw nsw i32 %36, %34
  %38 = lshr i32 %37, 2
  %39 = trunc i32 %38 to i16
  %40 = getelementptr inbounds i8, i8* %0, i64 2
  %41 = bitcast i8* %40 to i16*
  store i16 %39, i16* %41, align 2
  %42 = add nuw nsw i32 %30, %23
  %43 = lshr i32 %42, 1
  %44 = trunc i32 %43 to i16
  %45 = ashr exact i64 %11, 32
  %46 = getelementptr inbounds i16, i16* %4, i64 %45
  store i16 %44, i16* %46, align 2
  %47 = getelementptr inbounds i8, i8* %0, i64 4
  %48 = bitcast i8* %47 to i16*
  store i16 %44, i16* %48, align 2
  %49 = shl nuw nsw i32 %23, 1
  %50 = add nuw nsw i32 %29, 2
  %51 = add nuw nsw i32 %50, %16
  %52 = add nuw nsw i32 %51, %49
  %53 = lshr i32 %52, 2
  %54 = trunc i32 %53 to i16
  %55 = add i64 %11, 4294967296
  %56 = ashr exact i64 %55, 32
  %57 = getelementptr inbounds i16, i16* %4, i64 %56
  store i16 %54, i16* %57, align 2
  %58 = getelementptr inbounds i8, i8* %0, i64 6
  %59 = bitcast i8* %58 to i16*
  store i16 %54, i16* %59, align 2
  %60 = add nuw nsw i32 %23, 1
  %61 = add nuw nsw i32 %60, %29
  %62 = lshr i32 %61, 1
  %63 = trunc i32 %62 to i16
  %64 = sext i32 %18 to i64
  %65 = getelementptr inbounds i16, i16* %4, i64 %64
  store i16 %63, i16* %65, align 2
  %66 = add i64 %11, 8589934592
  %67 = ashr exact i64 %66, 32
  %68 = getelementptr inbounds i16, i16* %4, i64 %67
  store i16 %63, i16* %68, align 2
  %69 = shl nuw nsw i32 %29, 1
  %70 = add nuw nsw i32 %35, %29
  %71 = add nuw nsw i32 %70, %69
  %72 = lshr i32 %71, 2
  %73 = trunc i32 %72 to i16
  %74 = shl i64 %2, 32
  %75 = ashr exact i64 %74, 32
  %76 = or i64 %75, 1
  %77 = getelementptr inbounds i16, i16* %4, i64 %76
  store i16 %73, i16* %77, align 2
  %78 = add i64 %11, 12884901888
  %79 = ashr exact i64 %78, 32
  %80 = getelementptr inbounds i16, i16* %4, i64 %79
  store i16 %73, i16* %80, align 2
  %81 = add nsw i32 %24, 3
  %82 = sext i32 %81 to i64
  %83 = getelementptr inbounds i16, i16* %4, i64 %82
  store i16 %28, i16* %83, align 2
  %84 = add nsw i32 %24, 2
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i16, i16* %4, i64 %85
  store i16 %28, i16* %86, align 2
  %87 = add nsw i32 %18, 2
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds i16, i16* %4, i64 %88
  store i16 %28, i16* %89, align 2
  %90 = sext i32 %24 to i64
  %91 = getelementptr inbounds i16, i16* %4, i64 %90
  store i16 %28, i16* %91, align 2
  %92 = add nsw i32 %24, 1
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds i16, i16* %4, i64 %93
  store i16 %28, i16* %94, align 2
  %95 = add nsw i32 %18, 3
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %4, i64 %96
  store i16 %28, i16* %97, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_left_dc_9_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = shl i64 %5, 32
  %12 = add i64 %11, -4294967296
  %13 = ashr exact i64 %12, 32
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = trunc i64 %2 to i32
  %18 = and i32 %17, -2
  %19 = add nsw i32 %18, -1
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i64
  %24 = mul nsw i32 %6, 3
  %25 = add nsw i32 %24, -1
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds i16, i16* %4, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i64
  %30 = add nuw nsw i64 %10, 2
  %31 = add nuw nsw i64 %30, %16
  %32 = add nuw nsw i64 %31, %23
  %33 = add nuw nsw i64 %32, %29
  %34 = lshr i64 %33, 2
  %35 = mul i64 %34, 281479271743489
  %36 = bitcast i8* %0 to i64*
  store i64 %35, i64* %36, align 8
  %37 = ashr exact i64 %11, 32
  %38 = getelementptr inbounds i16, i16* %4, i64 %37
  %39 = bitcast i16* %38 to i64*
  store i64 %35, i64* %39, align 8
  %40 = sext i32 %18 to i64
  %41 = getelementptr inbounds i16, i16* %4, i64 %40
  %42 = bitcast i16* %41 to i64*
  store i64 %35, i64* %42, align 8
  %43 = sext i32 %24 to i64
  %44 = getelementptr inbounds i16, i16* %4, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %35, i64* %45, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_top_dc_9_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = shl i64 %5, 32
  %7 = sub i64 0, %6
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  %12 = sub i64 4294967296, %6
  %13 = ashr exact i64 %12, 32
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = sub i64 8589934592, %6
  %18 = ashr exact i64 %17, 32
  %19 = getelementptr inbounds i16, i16* %4, i64 %18
  %20 = load i16, i16* %19, align 2
  %21 = zext i16 %20 to i64
  %22 = sub i64 12884901888, %6
  %23 = ashr exact i64 %22, 32
  %24 = getelementptr inbounds i16, i16* %4, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = add nuw nsw i64 %11, 2
  %28 = add nuw nsw i64 %27, %16
  %29 = add nuw nsw i64 %28, %21
  %30 = add nuw nsw i64 %29, %26
  %31 = lshr i64 %30, 2
  %32 = mul i64 %31, 281479271743489
  %33 = bitcast i8* %0 to i64*
  store i64 %32, i64* %33, align 8
  %34 = ashr exact i64 %6, 32
  %35 = getelementptr inbounds i16, i16* %4, i64 %34
  %36 = bitcast i16* %35 to i64*
  store i64 %32, i64* %36, align 8
  %37 = shl i64 %2, 32
  %38 = ashr exact i64 %37, 32
  %39 = and i64 %38, -2
  %40 = getelementptr inbounds i16, i16* %4, i64 %39
  %41 = bitcast i16* %40 to i64*
  store i64 %32, i64* %41, align 8
  %42 = mul i64 %5, 12884901888
  %43 = ashr exact i64 %42, 32
  %44 = getelementptr inbounds i16, i16* %4, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %32, i64* %45, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_tm_vp8_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = xor i64 %2, -1
  %5 = getelementptr inbounds i8, i8* %0, i64 %4
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i64
  %8 = sub nsw i64 0, %7
  %9 = getelementptr inbounds i8, i8* getelementptr inbounds ([2304 x i8], [2304 x i8]* @ff_crop_tab, i64 0, i64 1024), i64 %8
  %10 = sub i64 0, %2
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = getelementptr inbounds i8, i8* %11, i64 1
  %13 = getelementptr inbounds i8, i8* %11, i64 2
  %14 = getelementptr inbounds i8, i8* %11, i64 3
  %15 = getelementptr inbounds i8, i8* %0, i64 -1
  %16 = load i8, i8* %15, align 1
  %17 = zext i8 %16 to i64
  %18 = getelementptr inbounds i8, i8* %9, i64 %17
  %19 = load i8, i8* %11, align 1
  %20 = zext i8 %19 to i64
  %21 = getelementptr inbounds i8, i8* %18, i64 %20
  %22 = load i8, i8* %21, align 1
  store i8 %22, i8* %0, align 1
  %23 = load i8, i8* %12, align 1
  %24 = zext i8 %23 to i64
  %25 = getelementptr inbounds i8, i8* %18, i64 %24
  %26 = load i8, i8* %25, align 1
  %27 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %26, i8* %27, align 1
  %28 = load i8, i8* %13, align 1
  %29 = zext i8 %28 to i64
  %30 = getelementptr inbounds i8, i8* %18, i64 %29
  %31 = load i8, i8* %30, align 1
  %32 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %31, i8* %32, align 1
  %33 = load i8, i8* %14, align 1
  %34 = zext i8 %33 to i64
  %35 = getelementptr inbounds i8, i8* %18, i64 %34
  %36 = load i8, i8* %35, align 1
  %37 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %36, i8* %37, align 1
  %38 = getelementptr inbounds i8, i8* %0, i64 %2
  %39 = getelementptr inbounds i8, i8* %38, i64 -1
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i64
  %42 = getelementptr inbounds i8, i8* %9, i64 %41
  %43 = load i8, i8* %11, align 1
  %44 = zext i8 %43 to i64
  %45 = getelementptr inbounds i8, i8* %42, i64 %44
  %46 = load i8, i8* %45, align 1
  store i8 %46, i8* %38, align 1
  %47 = load i8, i8* %12, align 1
  %48 = zext i8 %47 to i64
  %49 = getelementptr inbounds i8, i8* %42, i64 %48
  %50 = load i8, i8* %49, align 1
  %51 = getelementptr inbounds i8, i8* %38, i64 1
  store i8 %50, i8* %51, align 1
  %52 = load i8, i8* %13, align 1
  %53 = zext i8 %52 to i64
  %54 = getelementptr inbounds i8, i8* %42, i64 %53
  %55 = load i8, i8* %54, align 1
  %56 = getelementptr inbounds i8, i8* %38, i64 2
  store i8 %55, i8* %56, align 1
  %57 = load i8, i8* %14, align 1
  %58 = zext i8 %57 to i64
  %59 = getelementptr inbounds i8, i8* %42, i64 %58
  %60 = load i8, i8* %59, align 1
  %61 = getelementptr inbounds i8, i8* %38, i64 3
  store i8 %60, i8* %61, align 1
  %62 = getelementptr inbounds i8, i8* %38, i64 %2
  %63 = getelementptr inbounds i8, i8* %62, i64 -1
  %64 = load i8, i8* %63, align 1
  %65 = zext i8 %64 to i64
  %66 = getelementptr inbounds i8, i8* %9, i64 %65
  %67 = load i8, i8* %11, align 1
  %68 = zext i8 %67 to i64
  %69 = getelementptr inbounds i8, i8* %66, i64 %68
  %70 = load i8, i8* %69, align 1
  store i8 %70, i8* %62, align 1
  %71 = load i8, i8* %12, align 1
  %72 = zext i8 %71 to i64
  %73 = getelementptr inbounds i8, i8* %66, i64 %72
  %74 = load i8, i8* %73, align 1
  %75 = getelementptr inbounds i8, i8* %62, i64 1
  store i8 %74, i8* %75, align 1
  %76 = load i8, i8* %13, align 1
  %77 = zext i8 %76 to i64
  %78 = getelementptr inbounds i8, i8* %66, i64 %77
  %79 = load i8, i8* %78, align 1
  %80 = getelementptr inbounds i8, i8* %62, i64 2
  store i8 %79, i8* %80, align 1
  %81 = load i8, i8* %14, align 1
  %82 = zext i8 %81 to i64
  %83 = getelementptr inbounds i8, i8* %66, i64 %82
  %84 = load i8, i8* %83, align 1
  %85 = getelementptr inbounds i8, i8* %62, i64 3
  store i8 %84, i8* %85, align 1
  %86 = getelementptr inbounds i8, i8* %62, i64 %2
  %87 = getelementptr inbounds i8, i8* %86, i64 -1
  %88 = load i8, i8* %87, align 1
  %89 = zext i8 %88 to i64
  %90 = getelementptr inbounds i8, i8* %9, i64 %89
  %91 = load i8, i8* %11, align 1
  %92 = zext i8 %91 to i64
  %93 = getelementptr inbounds i8, i8* %90, i64 %92
  %94 = load i8, i8* %93, align 1
  store i8 %94, i8* %86, align 1
  %95 = load i8, i8* %12, align 1
  %96 = zext i8 %95 to i64
  %97 = getelementptr inbounds i8, i8* %90, i64 %96
  %98 = load i8, i8* %97, align 1
  %99 = getelementptr inbounds i8, i8* %86, i64 1
  store i8 %98, i8* %99, align 1
  %100 = load i8, i8* %13, align 1
  %101 = zext i8 %100 to i64
  %102 = getelementptr inbounds i8, i8* %90, i64 %101
  %103 = load i8, i8* %102, align 1
  %104 = getelementptr inbounds i8, i8* %86, i64 2
  store i8 %103, i8* %104, align 1
  %105 = load i8, i8* %14, align 1
  %106 = zext i8 %105 to i64
  %107 = getelementptr inbounds i8, i8* %90, i64 %106
  %108 = load i8, i8* %107, align 1
  %109 = getelementptr inbounds i8, i8* %86, i64 3
  store i8 %108, i8* %109, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_127_dc_9_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = bitcast i8* %0 to i64*
  store i64 71777214294589695, i64* %6, align 8
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  store i64 71777214294589695, i64* %10, align 8
  %11 = shl i64 %2, 32
  %12 = ashr exact i64 %11, 32
  %13 = and i64 %12, -2
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = bitcast i16* %14 to i64*
  store i64 71777214294589695, i64* %15, align 8
  %16 = mul i64 %5, 12884901888
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 71777214294589695, i64* %19, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_129_dc_9_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = bitcast i8* %0 to i64*
  store i64 72340172838076673, i64* %6, align 8
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  store i64 72340172838076673, i64* %10, align 8
  %11 = shl i64 %2, 32
  %12 = ashr exact i64 %11, 32
  %13 = and i64 %12, -2
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = bitcast i16* %14 to i64*
  store i64 72340172838076673, i64* %15, align 8
  %16 = mul i64 %5, 12884901888
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 72340172838076673, i64* %19, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_128_dc_9_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = bitcast i8* %0 to i64*
  store i64 72058693566333184, i64* %6, align 8
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  store i64 72058693566333184, i64* %10, align 8
  %11 = shl i64 %2, 32
  %12 = ashr exact i64 %11, 32
  %13 = and i64 %12, -2
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = bitcast i16* %14 to i64*
  store i64 72058693566333184, i64* %15, align 8
  %16 = mul i64 %5, 12884901888
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 72058693566333184, i64* %19, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_down_left_rv40_c(i8*, i8* nocapture readonly, i64) #1 {
  %4 = sub nsw i64 0, %2
  %5 = getelementptr inbounds i8, i8* %0, i64 %4
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = sub nsw i64 1, %2
  %9 = getelementptr inbounds i8, i8* %0, i64 %8
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i32
  %12 = sub nsw i64 2, %2
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = sub nsw i64 3, %2
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = load i8, i8* %1, align 1
  %21 = zext i8 %20 to i32
  %22 = getelementptr inbounds i8, i8* %1, i64 1
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = getelementptr inbounds i8, i8* %1, i64 2
  %26 = load i8, i8* %25, align 1
  %27 = zext i8 %26 to i32
  %28 = getelementptr inbounds i8, i8* %1, i64 3
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = getelementptr inbounds i8, i8* %0, i64 -1
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = add nsw i64 %2, -1
  %35 = getelementptr inbounds i8, i8* %0, i64 %34
  %36 = load i8, i8* %35, align 1
  %37 = zext i8 %36 to i32
  %38 = shl nsw i64 %2, 1
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i8, i8* %0, i64 %39
  %41 = load i8, i8* %40, align 1
  %42 = zext i8 %41 to i32
  %43 = mul nsw i64 %2, 3
  %44 = add nsw i64 %43, -1
  %45 = getelementptr inbounds i8, i8* %0, i64 %44
  %46 = load i8, i8* %45, align 1
  %47 = zext i8 %46 to i32
  %48 = shl i64 %2, 2
  %49 = add nsw i64 %48, -1
  %50 = getelementptr inbounds i8, i8* %0, i64 %49
  %51 = load i8, i8* %50, align 1
  %52 = zext i8 %51 to i32
  %53 = mul nsw i64 %2, 5
  %54 = add nsw i64 %53, -1
  %55 = getelementptr inbounds i8, i8* %0, i64 %54
  %56 = load i8, i8* %55, align 1
  %57 = zext i8 %56 to i32
  %58 = mul nsw i64 %2, 6
  %59 = add nsw i64 %58, -1
  %60 = getelementptr inbounds i8, i8* %0, i64 %59
  %61 = load i8, i8* %60, align 1
  %62 = zext i8 %61 to i32
  %63 = mul nsw i64 %2, 7
  %64 = add nsw i64 %63, -1
  %65 = getelementptr inbounds i8, i8* %0, i64 %64
  %66 = load i8, i8* %65, align 1
  %67 = zext i8 %66 to i32
  %68 = add nuw nsw i32 %37, %11
  %69 = shl nuw nsw i32 %68, 1
  %70 = add nuw nsw i32 %42, %15
  %71 = add nuw nsw i32 %70, 4
  %72 = add nuw nsw i32 %71, %7
  %73 = add nuw nsw i32 %72, %33
  %74 = add nuw nsw i32 %73, %69
  %75 = lshr i32 %74, 3
  %76 = trunc i32 %75 to i8
  store i8 %76, i8* %0, align 1
  %77 = shl nuw nsw i32 %70, 1
  %78 = add nuw nsw i32 %47, %19
  %79 = add nuw nsw i32 %78, 4
  %80 = add nuw nsw i32 %79, %11
  %81 = add nuw nsw i32 %80, %37
  %82 = add nuw nsw i32 %81, %77
  %83 = lshr i32 %82, 3
  %84 = trunc i32 %83 to i8
  %85 = getelementptr inbounds i8, i8* %0, i64 %2
  store i8 %84, i8* %85, align 1
  %86 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %84, i8* %86, align 1
  %87 = shl nuw nsw i32 %78, 1
  %88 = add nuw nsw i32 %71, %21
  %89 = add nuw nsw i32 %88, %52
  %90 = add nuw nsw i32 %89, %87
  %91 = lshr i32 %90, 3
  %92 = trunc i32 %91 to i8
  %93 = getelementptr inbounds i8, i8* %0, i64 %38
  store i8 %92, i8* %93, align 1
  %94 = add nsw i64 %2, 1
  %95 = getelementptr inbounds i8, i8* %0, i64 %94
  store i8 %92, i8* %95, align 1
  %96 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %92, i8* %96, align 1
  %97 = add nuw nsw i32 %52, %21
  %98 = shl nuw nsw i32 %97, 1
  %99 = add nuw nsw i32 %79, %24
  %100 = add nuw nsw i32 %99, %57
  %101 = add nuw nsw i32 %100, %98
  %102 = lshr i32 %101, 3
  %103 = trunc i32 %102 to i8
  %104 = getelementptr inbounds i8, i8* %0, i64 %43
  store i8 %103, i8* %104, align 1
  %105 = or i64 %38, 1
  %106 = getelementptr inbounds i8, i8* %0, i64 %105
  store i8 %103, i8* %106, align 1
  %107 = add nsw i64 %2, 2
  %108 = getelementptr inbounds i8, i8* %0, i64 %107
  store i8 %103, i8* %108, align 1
  %109 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %103, i8* %109, align 1
  %110 = add nuw nsw i32 %57, %24
  %111 = shl nuw nsw i32 %110, 1
  %112 = add nuw nsw i32 %97, 4
  %113 = add nuw nsw i32 %112, %27
  %114 = add nuw nsw i32 %113, %62
  %115 = add nuw nsw i32 %114, %111
  %116 = lshr i32 %115, 3
  %117 = trunc i32 %116 to i8
  %118 = add nsw i64 %43, 1
  %119 = getelementptr inbounds i8, i8* %0, i64 %118
  store i8 %117, i8* %119, align 1
  %120 = add nsw i64 %38, 2
  %121 = getelementptr inbounds i8, i8* %0, i64 %120
  store i8 %117, i8* %121, align 1
  %122 = add nsw i64 %2, 3
  %123 = getelementptr inbounds i8, i8* %0, i64 %122
  store i8 %117, i8* %123, align 1
  %124 = add nuw nsw i32 %62, %27
  %125 = shl nuw nsw i32 %124, 1
  %126 = add nuw nsw i32 %110, 4
  %127 = add nuw nsw i32 %126, %30
  %128 = add nuw nsw i32 %127, %67
  %129 = add nuw nsw i32 %128, %125
  %130 = lshr i32 %129, 3
  %131 = trunc i32 %130 to i8
  %132 = add nsw i64 %43, 2
  %133 = getelementptr inbounds i8, i8* %0, i64 %132
  store i8 %131, i8* %133, align 1
  %134 = add nsw i64 %38, 3
  %135 = getelementptr inbounds i8, i8* %0, i64 %134
  store i8 %131, i8* %135, align 1
  %136 = add nuw nsw i32 %124, 2
  %137 = add nuw nsw i32 %136, %30
  %138 = add nuw nsw i32 %137, %67
  %139 = lshr i32 %138, 2
  %140 = trunc i32 %139 to i8
  %141 = add nsw i64 %43, 3
  %142 = getelementptr inbounds i8, i8* %0, i64 %141
  store i8 %140, i8* %142, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_left_rv40_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = add nsw i64 %2, -1
  %5 = getelementptr inbounds i8, i8* %0, i64 %4
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = shl i64 %2, 1
  %9 = add nsw i64 %8, -1
  %10 = getelementptr inbounds i8, i8* %0, i64 %9
  %11 = load i8, i8* %10, align 1
  %12 = zext i8 %11 to i32
  %13 = mul nsw i64 %2, 3
  %14 = add nsw i64 %13, -1
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = load i8, i8* %15, align 1
  %17 = zext i8 %16 to i32
  %18 = shl i64 %2, 2
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i8, i8* %0, i64 %19
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  tail call fastcc void @pred4x4_vertical_left_rv40(i8* %0, i8* %1, i64 %2, i32 %7, i32 %12, i32 %17, i32 %22)
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_up_rv40_c(i8*, i8* nocapture readonly, i64) #1 {
  %4 = getelementptr inbounds i8, i8* %0, i64 -1
  %5 = load i8, i8* %4, align 1
  %6 = zext i8 %5 to i32
  %7 = add nsw i64 %2, -1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = shl nsw i64 %2, 1
  %12 = add nsw i64 %11, -1
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = mul nsw i64 %2, 3
  %17 = add nsw i64 %16, -1
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = shl i64 %2, 2
  %22 = add nsw i64 %21, -1
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = mul nsw i64 %2, 5
  %27 = add nsw i64 %26, -1
  %28 = getelementptr inbounds i8, i8* %0, i64 %27
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = mul nsw i64 %2, 6
  %32 = add nsw i64 %31, -1
  %33 = getelementptr inbounds i8, i8* %0, i64 %32
  %34 = load i8, i8* %33, align 1
  %35 = zext i8 %34 to i32
  %36 = sub nsw i64 1, %2
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = load i8, i8* %37, align 1
  %39 = zext i8 %38 to i32
  %40 = sub nsw i64 2, %2
  %41 = getelementptr inbounds i8, i8* %0, i64 %40
  %42 = load i8, i8* %41, align 1
  %43 = zext i8 %42 to i32
  %44 = sub nsw i64 3, %2
  %45 = getelementptr inbounds i8, i8* %0, i64 %44
  %46 = load i8, i8* %45, align 1
  %47 = zext i8 %46 to i32
  %48 = load i8, i8* %1, align 1
  %49 = zext i8 %48 to i32
  %50 = getelementptr inbounds i8, i8* %1, i64 1
  %51 = load i8, i8* %50, align 1
  %52 = zext i8 %51 to i32
  %53 = getelementptr inbounds i8, i8* %1, i64 2
  %54 = load i8, i8* %53, align 1
  %55 = zext i8 %54 to i32
  %56 = getelementptr inbounds i8, i8* %1, i64 3
  %57 = load i8, i8* %56, align 1
  %58 = zext i8 %57 to i32
  %59 = shl nuw nsw i32 %10, 1
  %60 = add nuw nsw i32 %43, %6
  %61 = shl nuw nsw i32 %60, 1
  %62 = add nuw nsw i32 %59, 4
  %63 = add nuw nsw i32 %62, %39
  %64 = add nuw nsw i32 %63, %47
  %65 = add nuw nsw i32 %64, %61
  %66 = lshr i32 %65, 3
  %67 = trunc i32 %66 to i8
  store i8 %67, i8* %0, align 1
  %68 = shl nuw nsw i32 %47, 1
  %69 = add nuw nsw i32 %62, %6
  %70 = add nuw nsw i32 %69, %15
  %71 = add nuw nsw i32 %70, %43
  %72 = add nuw nsw i32 %71, %68
  %73 = add nuw nsw i32 %72, %49
  %74 = lshr i32 %73, 3
  %75 = trunc i32 %74 to i8
  %76 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %75, i8* %76, align 1
  %77 = shl nuw nsw i32 %49, 1
  %78 = shl nuw nsw i32 %15, 1
  %79 = add nuw nsw i32 %62, %78
  %80 = add nuw nsw i32 %79, %47
  %81 = add nuw nsw i32 %80, %77
  %82 = add nuw nsw i32 %81, %52
  %83 = lshr i32 %82, 3
  %84 = trunc i32 %83 to i8
  %85 = getelementptr inbounds i8, i8* %0, i64 %2
  store i8 %84, i8* %85, align 1
  %86 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %84, i8* %86, align 1
  %87 = shl nuw nsw i32 %52, 1
  %88 = add nuw nsw i32 %78, 4
  %89 = add nuw nsw i32 %88, %10
  %90 = add nuw nsw i32 %89, %20
  %91 = add nuw nsw i32 %90, %49
  %92 = add nuw nsw i32 %91, %87
  %93 = add nuw nsw i32 %92, %55
  %94 = lshr i32 %93, 3
  %95 = trunc i32 %94 to i8
  %96 = add nsw i64 %2, 1
  %97 = getelementptr inbounds i8, i8* %0, i64 %96
  store i8 %95, i8* %97, align 1
  %98 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %95, i8* %98, align 1
  %99 = add nuw nsw i32 %55, %20
  %100 = shl nuw nsw i32 %99, 1
  %101 = add nuw nsw i32 %88, %52
  %102 = add nuw nsw i32 %101, %58
  %103 = add nuw nsw i32 %102, %100
  %104 = lshr i32 %103, 3
  %105 = trunc i32 %104 to i8
  %106 = getelementptr inbounds i8, i8* %0, i64 %11
  store i8 %105, i8* %106, align 1
  %107 = add nsw i64 %2, 2
  %108 = getelementptr inbounds i8, i8* %0, i64 %107
  store i8 %105, i8* %108, align 1
  %109 = add nuw nsw i32 %58, %20
  %110 = mul nuw nsw i32 %109, 3
  %111 = add nuw nsw i32 %15, 4
  %112 = add nuw nsw i32 %111, %55
  %113 = add nuw nsw i32 %112, %110
  %114 = lshr i32 %113, 3
  %115 = trunc i32 %114 to i8
  %116 = or i64 %11, 1
  %117 = getelementptr inbounds i8, i8* %0, i64 %116
  store i8 %115, i8* %117, align 1
  %118 = add nsw i64 %2, 3
  %119 = getelementptr inbounds i8, i8* %0, i64 %118
  store i8 %115, i8* %119, align 1
  %120 = shl nuw nsw i32 %25, 1
  %121 = add nuw nsw i32 %20, 2
  %122 = add nuw nsw i32 %121, %120
  %123 = add nuw nsw i32 %122, %30
  %124 = lshr i32 %123, 2
  %125 = trunc i32 %124 to i8
  %126 = add nsw i64 %16, 1
  %127 = getelementptr inbounds i8, i8* %0, i64 %126
  store i8 %125, i8* %127, align 1
  %128 = add nsw i64 %11, 3
  %129 = getelementptr inbounds i8, i8* %0, i64 %128
  store i8 %125, i8* %129, align 1
  %130 = add nuw nsw i32 %121, %25
  %131 = add nuw nsw i32 %130, %55
  %132 = add nuw nsw i32 %131, %58
  %133 = lshr i32 %132, 2
  %134 = trunc i32 %133 to i8
  %135 = add nsw i64 %11, 2
  %136 = getelementptr inbounds i8, i8* %0, i64 %135
  store i8 %134, i8* %136, align 1
  %137 = getelementptr inbounds i8, i8* %0, i64 %16
  store i8 %134, i8* %137, align 1
  %138 = add nuw nsw i32 %25, 1
  %139 = add nuw nsw i32 %138, %30
  %140 = lshr i32 %139, 1
  %141 = trunc i32 %140 to i8
  %142 = add nsw i64 %16, 2
  %143 = getelementptr inbounds i8, i8* %0, i64 %142
  store i8 %141, i8* %143, align 1
  %144 = shl nuw nsw i32 %30, 1
  %145 = add nuw nsw i32 %25, 2
  %146 = add nuw nsw i32 %145, %144
  %147 = add nuw nsw i32 %146, %35
  %148 = lshr i32 %147, 2
  %149 = trunc i32 %148 to i8
  %150 = add nsw i64 %16, 3
  %151 = getelementptr inbounds i8, i8* %0, i64 %150
  store i8 %149, i8* %151, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_down_left_rv40_nodown_c(i8*, i8* nocapture readonly, i64) #1 {
  %4 = sub nsw i64 0, %2
  %5 = getelementptr inbounds i8, i8* %0, i64 %4
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = sub nsw i64 1, %2
  %9 = getelementptr inbounds i8, i8* %0, i64 %8
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i32
  %12 = sub nsw i64 2, %2
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = sub nsw i64 3, %2
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = load i8, i8* %1, align 1
  %21 = zext i8 %20 to i32
  %22 = getelementptr inbounds i8, i8* %1, i64 1
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = getelementptr inbounds i8, i8* %1, i64 2
  %26 = load i8, i8* %25, align 1
  %27 = zext i8 %26 to i32
  %28 = getelementptr inbounds i8, i8* %1, i64 3
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = getelementptr inbounds i8, i8* %0, i64 -1
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = add nsw i64 %2, -1
  %35 = getelementptr inbounds i8, i8* %0, i64 %34
  %36 = load i8, i8* %35, align 1
  %37 = zext i8 %36 to i32
  %38 = shl nsw i64 %2, 1
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i8, i8* %0, i64 %39
  %41 = load i8, i8* %40, align 1
  %42 = zext i8 %41 to i32
  %43 = mul nsw i64 %2, 3
  %44 = add nsw i64 %43, -1
  %45 = getelementptr inbounds i8, i8* %0, i64 %44
  %46 = load i8, i8* %45, align 1
  %47 = zext i8 %46 to i32
  %48 = add nuw nsw i32 %37, %11
  %49 = shl nuw nsw i32 %48, 1
  %50 = add nuw nsw i32 %42, %15
  %51 = add nuw nsw i32 %50, 4
  %52 = add nuw nsw i32 %51, %7
  %53 = add nuw nsw i32 %52, %33
  %54 = add nuw nsw i32 %53, %49
  %55 = lshr i32 %54, 3
  %56 = trunc i32 %55 to i8
  store i8 %56, i8* %0, align 1
  %57 = shl nuw nsw i32 %50, 1
  %58 = add nuw nsw i32 %11, 4
  %59 = add nuw nsw i32 %58, %19
  %60 = add nuw nsw i32 %59, %37
  %61 = add nuw nsw i32 %60, %47
  %62 = add nuw nsw i32 %61, %57
  %63 = lshr i32 %62, 3
  %64 = trunc i32 %63 to i8
  %65 = getelementptr inbounds i8, i8* %0, i64 %2
  store i8 %64, i8* %65, align 1
  %66 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %64, i8* %66, align 1
  %67 = shl nuw nsw i32 %19, 1
  %68 = mul nuw nsw i32 %47, 3
  %69 = add nuw nsw i32 %51, %21
  %70 = add nuw nsw i32 %69, %67
  %71 = add nuw nsw i32 %70, %68
  %72 = lshr i32 %71, 3
  %73 = trunc i32 %72 to i8
  %74 = getelementptr inbounds i8, i8* %0, i64 %38
  store i8 %73, i8* %74, align 1
  %75 = add nsw i64 %2, 1
  %76 = getelementptr inbounds i8, i8* %0, i64 %75
  store i8 %73, i8* %76, align 1
  %77 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %73, i8* %77, align 1
  %78 = shl nuw nsw i32 %21, 1
  %79 = shl nuw nsw i32 %47, 2
  %80 = add nuw nsw i32 %79, %24
  %81 = add nuw nsw i32 %80, 4
  %82 = add nuw nsw i32 %81, %19
  %83 = add nuw nsw i32 %82, %78
  %84 = lshr i32 %83, 3
  %85 = trunc i32 %84 to i8
  %86 = getelementptr inbounds i8, i8* %0, i64 %43
  store i8 %85, i8* %86, align 1
  %87 = or i64 %38, 1
  %88 = getelementptr inbounds i8, i8* %0, i64 %87
  store i8 %85, i8* %88, align 1
  %89 = add nsw i64 %2, 2
  %90 = getelementptr inbounds i8, i8* %0, i64 %89
  store i8 %85, i8* %90, align 1
  %91 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %85, i8* %91, align 1
  %92 = shl nuw nsw i32 %24, 1
  %93 = add nuw nsw i32 %21, 4
  %94 = add nuw nsw i32 %93, %27
  %95 = add nuw nsw i32 %94, %92
  %96 = add nuw nsw i32 %95, %79
  %97 = lshr i32 %96, 3
  %98 = trunc i32 %97 to i8
  %99 = add nsw i64 %43, 1
  %100 = getelementptr inbounds i8, i8* %0, i64 %99
  store i8 %98, i8* %100, align 1
  %101 = add nsw i64 %38, 2
  %102 = getelementptr inbounds i8, i8* %0, i64 %101
  store i8 %98, i8* %102, align 1
  %103 = add nsw i64 %2, 3
  %104 = getelementptr inbounds i8, i8* %0, i64 %103
  store i8 %98, i8* %104, align 1
  %105 = shl nuw nsw i32 %27, 1
  %106 = add nuw nsw i32 %81, %30
  %107 = add nuw nsw i32 %106, %105
  %108 = lshr i32 %107, 3
  %109 = trunc i32 %108 to i8
  %110 = add nsw i64 %43, 2
  %111 = getelementptr inbounds i8, i8* %0, i64 %110
  store i8 %109, i8* %111, align 1
  %112 = add nsw i64 %38, 3
  %113 = getelementptr inbounds i8, i8* %0, i64 %112
  store i8 %109, i8* %113, align 1
  %114 = shl nuw nsw i32 %47, 1
  %115 = add nuw nsw i32 %27, 2
  %116 = add nuw nsw i32 %115, %30
  %117 = add nuw nsw i32 %116, %114
  %118 = lshr i32 %117, 2
  %119 = trunc i32 %118 to i8
  %120 = add nsw i64 %43, 3
  %121 = getelementptr inbounds i8, i8* %0, i64 %120
  store i8 %119, i8* %121, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_up_rv40_nodown_c(i8*, i8* nocapture readonly, i64) #1 {
  %4 = getelementptr inbounds i8, i8* %0, i64 -1
  %5 = load i8, i8* %4, align 1
  %6 = zext i8 %5 to i32
  %7 = add nsw i64 %2, -1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = shl nsw i64 %2, 1
  %12 = add nsw i64 %11, -1
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = mul nsw i64 %2, 3
  %17 = add nsw i64 %16, -1
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = sub nsw i64 1, %2
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = sub nsw i64 2, %2
  %26 = getelementptr inbounds i8, i8* %0, i64 %25
  %27 = load i8, i8* %26, align 1
  %28 = zext i8 %27 to i32
  %29 = sub nsw i64 3, %2
  %30 = getelementptr inbounds i8, i8* %0, i64 %29
  %31 = load i8, i8* %30, align 1
  %32 = zext i8 %31 to i32
  %33 = load i8, i8* %1, align 1
  %34 = zext i8 %33 to i32
  %35 = getelementptr inbounds i8, i8* %1, i64 1
  %36 = load i8, i8* %35, align 1
  %37 = zext i8 %36 to i32
  %38 = getelementptr inbounds i8, i8* %1, i64 2
  %39 = load i8, i8* %38, align 1
  %40 = zext i8 %39 to i32
  %41 = getelementptr inbounds i8, i8* %1, i64 3
  %42 = load i8, i8* %41, align 1
  %43 = zext i8 %42 to i32
  %44 = shl nuw nsw i32 %10, 1
  %45 = add nuw nsw i32 %28, %6
  %46 = shl nuw nsw i32 %45, 1
  %47 = add nuw nsw i32 %44, 4
  %48 = add nuw nsw i32 %47, %24
  %49 = add nuw nsw i32 %48, %32
  %50 = add nuw nsw i32 %49, %46
  %51 = lshr i32 %50, 3
  %52 = trunc i32 %51 to i8
  store i8 %52, i8* %0, align 1
  %53 = shl nuw nsw i32 %32, 1
  %54 = add nuw nsw i32 %47, %6
  %55 = add nuw nsw i32 %54, %15
  %56 = add nuw nsw i32 %55, %28
  %57 = add nuw nsw i32 %56, %53
  %58 = add nuw nsw i32 %57, %34
  %59 = lshr i32 %58, 3
  %60 = trunc i32 %59 to i8
  %61 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %60, i8* %61, align 1
  %62 = shl nuw nsw i32 %34, 1
  %63 = shl nuw nsw i32 %15, 1
  %64 = add nuw nsw i32 %47, %63
  %65 = add nuw nsw i32 %64, %32
  %66 = add nuw nsw i32 %65, %62
  %67 = add nuw nsw i32 %66, %37
  %68 = lshr i32 %67, 3
  %69 = trunc i32 %68 to i8
  %70 = getelementptr inbounds i8, i8* %0, i64 %2
  store i8 %69, i8* %70, align 1
  %71 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %69, i8* %71, align 1
  %72 = shl nuw nsw i32 %37, 1
  %73 = add nuw nsw i32 %63, 4
  %74 = add nuw nsw i32 %73, %10
  %75 = add nuw nsw i32 %74, %20
  %76 = add nuw nsw i32 %75, %34
  %77 = add nuw nsw i32 %76, %72
  %78 = add nuw nsw i32 %77, %40
  %79 = lshr i32 %78, 3
  %80 = trunc i32 %79 to i8
  %81 = add nsw i64 %2, 1
  %82 = getelementptr inbounds i8, i8* %0, i64 %81
  store i8 %80, i8* %82, align 1
  %83 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %80, i8* %83, align 1
  %84 = shl nuw nsw i32 %40, 1
  %85 = shl nuw nsw i32 %20, 1
  %86 = add nuw nsw i32 %73, %85
  %87 = add nuw nsw i32 %86, %37
  %88 = add nuw nsw i32 %87, %84
  %89 = add nuw nsw i32 %88, %43
  %90 = lshr i32 %89, 3
  %91 = trunc i32 %90 to i8
  %92 = getelementptr inbounds i8, i8* %0, i64 %11
  store i8 %91, i8* %92, align 1
  %93 = add nsw i64 %2, 2
  %94 = getelementptr inbounds i8, i8* %0, i64 %93
  store i8 %91, i8* %94, align 1
  %95 = add nuw nsw i32 %43, %20
  %96 = mul nuw nsw i32 %95, 3
  %97 = add nuw nsw i32 %15, 4
  %98 = add nuw nsw i32 %97, %40
  %99 = add nuw nsw i32 %98, %96
  %100 = lshr i32 %99, 3
  %101 = trunc i32 %100 to i8
  %102 = or i64 %11, 1
  %103 = getelementptr inbounds i8, i8* %0, i64 %102
  store i8 %101, i8* %103, align 1
  %104 = add nsw i64 %2, 3
  %105 = getelementptr inbounds i8, i8* %0, i64 %104
  store i8 %101, i8* %105, align 1
  %106 = add nsw i64 %16, 1
  %107 = getelementptr inbounds i8, i8* %0, i64 %106
  store i8 %19, i8* %107, align 1
  %108 = add nsw i64 %11, 3
  %109 = getelementptr inbounds i8, i8* %0, i64 %108
  store i8 %19, i8* %109, align 1
  %110 = add nuw nsw i32 %85, %43
  %111 = add nuw nsw i32 %110, 2
  %112 = add nuw nsw i32 %111, %40
  %113 = lshr i32 %112, 2
  %114 = trunc i32 %113 to i8
  %115 = add nsw i64 %11, 2
  %116 = getelementptr inbounds i8, i8* %0, i64 %115
  store i8 %114, i8* %116, align 1
  %117 = getelementptr inbounds i8, i8* %0, i64 %16
  store i8 %114, i8* %117, align 1
  %118 = add nsw i64 %16, 3
  %119 = getelementptr inbounds i8, i8* %0, i64 %118
  store i8 %19, i8* %119, align 1
  %120 = add nsw i64 %16, 2
  %121 = getelementptr inbounds i8, i8* %0, i64 %120
  store i8 %19, i8* %121, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_left_rv40_nodown_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = add nsw i64 %2, -1
  %5 = getelementptr inbounds i8, i8* %0, i64 %4
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = shl i64 %2, 1
  %9 = add nsw i64 %8, -1
  %10 = getelementptr inbounds i8, i8* %0, i64 %9
  %11 = load i8, i8* %10, align 1
  %12 = zext i8 %11 to i32
  %13 = mul nsw i64 %2, 3
  %14 = add nsw i64 %13, -1
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = load i8, i8* %15, align 1
  %17 = zext i8 %16 to i32
  tail call fastcc void @pred4x4_vertical_left_rv40(i8* %0, i8* %1, i64 %2, i32 %7, i32 %12, i32 %17, i32 %17)
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_9_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %103, label %97

97:                                               ; preds = %18
  %98 = sub i64 34359738368, %19
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i16, i16* %5, i64 %99
  %101 = load i16, i16* %100, align 2
  %102 = zext i16 %101 to i32
  br label %103

103:                                              ; preds = %18, %97
  %104 = phi i32 [ %102, %97 ], [ %91, %18 ]
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %81, 2
  %107 = add nuw nsw i32 %106, %105
  %108 = add nuw nsw i32 %107, %104
  %109 = lshr i32 %108, 2
  %110 = trunc i32 %37 to i16
  store i16 %110, i16* %5, align 2
  %111 = trunc i32 %47 to i16
  %112 = getelementptr inbounds i8, i8* %0, i64 2
  %113 = bitcast i8* %112 to i16*
  store i16 %111, i16* %113, align 2
  %114 = trunc i32 %56 to i16
  %115 = getelementptr inbounds i8, i8* %0, i64 4
  %116 = bitcast i8* %115 to i16*
  store i16 %114, i16* %116, align 2
  %117 = trunc i32 %65 to i16
  %118 = getelementptr inbounds i8, i8* %0, i64 6
  %119 = bitcast i8* %118 to i16*
  store i16 %117, i16* %119, align 2
  %120 = trunc i32 %75 to i16
  %121 = getelementptr inbounds i8, i8* %0, i64 8
  %122 = bitcast i8* %121 to i16*
  store i16 %120, i16* %122, align 2
  %123 = trunc i32 %85 to i16
  %124 = getelementptr inbounds i8, i8* %0, i64 10
  %125 = bitcast i8* %124 to i16*
  store i16 %123, i16* %125, align 2
  %126 = trunc i32 %95 to i16
  %127 = getelementptr inbounds i8, i8* %0, i64 12
  %128 = bitcast i8* %127 to i16*
  store i16 %126, i16* %128, align 2
  %129 = trunc i32 %109 to i16
  %130 = getelementptr inbounds i8, i8* %0, i64 14
  %131 = bitcast i8* %130 to i16*
  store i16 %129, i16* %131, align 2
  %132 = bitcast i8* %0 to i64*
  %133 = load i64, i64* %132, align 8
  %134 = bitcast i8* %121 to i64*
  %135 = load i64, i64* %134, align 8
  %136 = shl i64 %6, 32
  %137 = ashr exact i64 %136, 32
  %138 = getelementptr inbounds i16, i16* %5, i64 %137
  %139 = bitcast i16* %138 to i64*
  store i64 %133, i64* %139, align 8
  %140 = getelementptr inbounds i16, i16* %138, i64 4
  %141 = bitcast i16* %140 to i64*
  store i64 %135, i64* %141, align 8
  %142 = ashr exact i64 %136, 31
  %143 = getelementptr inbounds i16, i16* %5, i64 %142
  %144 = bitcast i16* %143 to i64*
  store i64 %133, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %143, i64 4
  %146 = bitcast i16* %145 to i64*
  store i64 %135, i64* %146, align 8
  %147 = mul nsw i64 %137, 3
  %148 = getelementptr inbounds i16, i16* %5, i64 %147
  %149 = bitcast i16* %148 to i64*
  store i64 %133, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %148, i64 4
  %151 = bitcast i16* %150 to i64*
  store i64 %135, i64* %151, align 8
  %152 = ashr exact i64 %136, 30
  %153 = getelementptr inbounds i16, i16* %5, i64 %152
  %154 = bitcast i16* %153 to i64*
  store i64 %133, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %153, i64 4
  %156 = bitcast i16* %155 to i64*
  store i64 %135, i64* %156, align 8
  %157 = mul nsw i64 %137, 5
  %158 = getelementptr inbounds i16, i16* %5, i64 %157
  %159 = bitcast i16* %158 to i64*
  store i64 %133, i64* %159, align 8
  %160 = getelementptr inbounds i16, i16* %158, i64 4
  %161 = bitcast i16* %160 to i64*
  store i64 %135, i64* %161, align 8
  %162 = mul nsw i64 %137, 6
  %163 = getelementptr inbounds i16, i16* %5, i64 %162
  %164 = bitcast i16* %163 to i64*
  store i64 %133, i64* %164, align 8
  %165 = getelementptr inbounds i16, i16* %163, i64 4
  %166 = bitcast i16* %165 to i64*
  store i64 %135, i64* %166, align 8
  %167 = mul nsw i64 %137, 7
  %168 = getelementptr inbounds i16, i16* %5, i64 %167
  %169 = bitcast i16* %168 to i64*
  store i64 %133, i64* %169, align 8
  %170 = getelementptr inbounds i16, i16* %168, i64 4
  %171 = bitcast i16* %170 to i64*
  store i64 %135, i64* %171, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_9_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  br i1 %8, label %14, label %9

9:                                                ; preds = %4
  %10 = shl i64 %6, 32
  %11 = ashr exact i64 %10, 32
  %12 = xor i64 %11, -1
  %13 = getelementptr inbounds i16, i16* %5, i64 %12
  br label %19

14:                                               ; preds = %4
  %15 = getelementptr inbounds i8, i8* %0, i64 -2
  %16 = bitcast i8* %15 to i16*
  %17 = shl i64 %6, 32
  %18 = ashr exact i64 %17, 32
  br label %19

19:                                               ; preds = %14, %9
  %20 = phi i64 [ %18, %14 ], [ %11, %9 ]
  %21 = phi i64 [ %17, %14 ], [ %10, %9 ]
  %22 = phi i16* [ %16, %14 ], [ %13, %9 ]
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i8, i8* %0, i64 -2
  %26 = bitcast i8* %25 to i16*
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = shl nuw nsw i32 %28, 1
  %30 = add i64 %21, -4294967296
  %31 = ashr exact i64 %30, 32
  %32 = getelementptr inbounds i16, i16* %5, i64 %31
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = add nuw nsw i32 %34, 2
  %36 = add nuw nsw i32 %35, %24
  %37 = add nuw nsw i32 %36, %29
  %38 = lshr i32 %37, 2
  %39 = shl nuw nsw i32 %34, 1
  %40 = trunc i64 %3 to i32
  %41 = and i32 %40, -2
  %42 = add nsw i32 %41, -1
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i16, i16* %5, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %28
  %49 = add nuw nsw i32 %48, %39
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = mul nsw i32 %7, 3
  %53 = add nsw i32 %52, -1
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i16, i16* %5, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i32
  %58 = add nuw nsw i32 %35, %51
  %59 = add nuw nsw i32 %58, %57
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %57, 1
  %62 = shl i64 %6, 34
  %63 = add i64 %62, -4294967296
  %64 = ashr exact i64 %63, 32
  %65 = getelementptr inbounds i16, i16* %5, i64 %64
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = add nuw nsw i32 %47, %61
  %69 = add nuw nsw i32 %68, %67
  %70 = lshr i32 %69, 2
  %71 = shl nuw nsw i32 %67, 1
  %72 = mul nsw i32 %7, 5
  %73 = add nsw i32 %72, -1
  %74 = sext i32 %73 to i64
  %75 = getelementptr inbounds i16, i16* %5, i64 %74
  %76 = load i16, i16* %75, align 2
  %77 = zext i16 %76 to i32
  %78 = add nuw nsw i32 %57, 2
  %79 = add nuw nsw i32 %78, %71
  %80 = add nuw nsw i32 %79, %77
  %81 = lshr i32 %80, 2
  %82 = shl nuw nsw i32 %77, 1
  %83 = mul nsw i32 %7, 6
  %84 = add nsw i32 %83, -1
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i16, i16* %5, i64 %85
  %87 = load i16, i16* %86, align 2
  %88 = zext i16 %87 to i32
  %89 = add nuw nsw i32 %67, 2
  %90 = add nuw nsw i32 %89, %82
  %91 = add nuw nsw i32 %90, %88
  %92 = lshr i32 %91, 2
  %93 = shl nuw nsw i32 %88, 1
  %94 = mul nsw i32 %7, 7
  %95 = add nsw i32 %94, -1
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %5, i64 %96
  %98 = load i16, i16* %97, align 2
  %99 = zext i16 %98 to i32
  %100 = add nuw nsw i32 %77, 2
  %101 = add nuw nsw i32 %100, %93
  %102 = add nuw nsw i32 %101, %99
  %103 = lshr i32 %102, 2
  %104 = mul nuw nsw i32 %99, 3
  %105 = add nuw nsw i32 %88, 2
  %106 = add nuw nsw i32 %105, %104
  %107 = lshr i32 %106, 2
  %108 = zext i32 %38 to i64
  %109 = mul i64 %108, 281479271743489
  %110 = bitcast i8* %0 to i64*
  store i64 %109, i64* %110, align 8
  %111 = getelementptr inbounds i8, i8* %0, i64 8
  %112 = bitcast i8* %111 to i64*
  store i64 %109, i64* %112, align 8
  %113 = zext i32 %50 to i64
  %114 = mul i64 %113, 281479271743489
  %115 = getelementptr inbounds i16, i16* %5, i64 %20
  %116 = bitcast i16* %115 to i64*
  store i64 %114, i64* %116, align 8
  %117 = getelementptr inbounds i16, i16* %115, i64 4
  %118 = bitcast i16* %117 to i64*
  store i64 %114, i64* %118, align 8
  %119 = zext i32 %60 to i64
  %120 = mul i64 %119, 281479271743489
  %121 = sext i32 %41 to i64
  %122 = getelementptr inbounds i16, i16* %5, i64 %121
  %123 = bitcast i16* %122 to i64*
  store i64 %120, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %122, i64 4
  %125 = bitcast i16* %124 to i64*
  store i64 %120, i64* %125, align 8
  %126 = zext i32 %70 to i64
  %127 = mul i64 %126, 281479271743489
  %128 = sext i32 %52 to i64
  %129 = getelementptr inbounds i16, i16* %5, i64 %128
  %130 = bitcast i16* %129 to i64*
  store i64 %127, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %129, i64 4
  %132 = bitcast i16* %131 to i64*
  store i64 %127, i64* %132, align 8
  %133 = zext i32 %81 to i64
  %134 = mul i64 %133, 281479271743489
  %135 = ashr exact i64 %62, 32
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  %137 = bitcast i16* %136 to i64*
  store i64 %134, i64* %137, align 8
  %138 = getelementptr inbounds i16, i16* %136, i64 4
  %139 = bitcast i16* %138 to i64*
  store i64 %134, i64* %139, align 8
  %140 = zext i32 %92 to i64
  %141 = mul i64 %140, 281479271743489
  %142 = sext i32 %72 to i64
  %143 = getelementptr inbounds i16, i16* %5, i64 %142
  %144 = bitcast i16* %143 to i64*
  store i64 %141, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %143, i64 4
  %146 = bitcast i16* %145 to i64*
  store i64 %141, i64* %146, align 8
  %147 = zext i32 %103 to i64
  %148 = mul i64 %147, 281479271743489
  %149 = sext i32 %83 to i64
  %150 = getelementptr inbounds i16, i16* %5, i64 %149
  %151 = bitcast i16* %150 to i64*
  store i64 %148, i64* %151, align 8
  %152 = getelementptr inbounds i16, i16* %150, i64 4
  %153 = bitcast i16* %152 to i64*
  store i64 %148, i64* %153, align 8
  %154 = zext i32 %107 to i64
  %155 = mul i64 %154, 281479271743489
  %156 = sext i32 %94 to i64
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  %158 = bitcast i16* %157 to i64*
  store i64 %155, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %157, i64 4
  %160 = bitcast i16* %159 to i64*
  store i64 %155, i64* %160, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_dc_9_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = icmp ne i32 %1, 0
  br i1 %7, label %8, label %13

8:                                                ; preds = %4
  %9 = shl i64 %6, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = getelementptr inbounds i16, i16* %5, i64 %11
  br label %19

13:                                               ; preds = %4
  %14 = getelementptr inbounds i8, i8* %0, i64 -2
  %15 = bitcast i8* %14 to i16*
  %16 = shl i64 %6, 32
  %17 = ashr exact i64 %16, 32
  %18 = xor i64 %17, -1
  br label %19

19:                                               ; preds = %13, %8
  %20 = phi i64 [ %18, %13 ], [ %11, %8 ]
  %21 = phi i64 [ %17, %13 ], [ %10, %8 ]
  %22 = phi i64 [ %16, %13 ], [ %9, %8 ]
  %23 = phi i16* [ %15, %13 ], [ %12, %8 ]
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = getelementptr inbounds i8, i8* %0, i64 -2
  %27 = bitcast i8* %26 to i16*
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i32
  %30 = shl nuw nsw i32 %29, 1
  %31 = add i64 %22, -4294967296
  %32 = ashr exact i64 %31, 32
  %33 = getelementptr inbounds i16, i16* %5, i64 %32
  %34 = load i16, i16* %33, align 2
  %35 = zext i16 %34 to i32
  %36 = add nuw nsw i32 %35, 2
  %37 = add nuw nsw i32 %36, %25
  %38 = add nuw nsw i32 %37, %30
  %39 = lshr i32 %38, 2
  %40 = shl nuw nsw i32 %35, 1
  %41 = shl i64 %3, 32
  %42 = and i64 %41, -8589934592
  %43 = add i64 %42, -4294967296
  %44 = ashr exact i64 %43, 32
  %45 = getelementptr inbounds i16, i16* %5, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i32
  %48 = add nuw nsw i32 %47, 2
  %49 = add nuw nsw i32 %48, %29
  %50 = add nuw nsw i32 %49, %40
  %51 = lshr i32 %50, 2
  %52 = shl nuw nsw i32 %47, 1
  %53 = mul i64 %6, 12884901888
  %54 = add i64 %53, -4294967296
  %55 = ashr exact i64 %54, 32
  %56 = getelementptr inbounds i16, i16* %5, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %36, %52
  %60 = add nuw nsw i32 %59, %58
  %61 = lshr i32 %60, 2
  %62 = shl nuw nsw i32 %58, 1
  %63 = shl i64 %6, 34
  %64 = add i64 %63, -4294967296
  %65 = ashr exact i64 %64, 32
  %66 = getelementptr inbounds i16, i16* %5, i64 %65
  %67 = load i16, i16* %66, align 2
  %68 = zext i16 %67 to i32
  %69 = add nuw nsw i32 %48, %62
  %70 = add nuw nsw i32 %69, %68
  %71 = lshr i32 %70, 2
  %72 = shl nuw nsw i32 %68, 1
  %73 = mul i64 %6, 21474836480
  %74 = add i64 %73, -4294967296
  %75 = ashr exact i64 %74, 32
  %76 = getelementptr inbounds i16, i16* %5, i64 %75
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i32
  %79 = add nuw nsw i32 %58, 2
  %80 = add nuw nsw i32 %79, %72
  %81 = add nuw nsw i32 %80, %78
  %82 = lshr i32 %81, 2
  %83 = shl nuw nsw i32 %78, 1
  %84 = mul i64 %6, 25769803776
  %85 = add i64 %84, -4294967296
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i16, i16* %5, i64 %86
  %88 = load i16, i16* %87, align 2
  %89 = zext i16 %88 to i32
  %90 = add nuw nsw i32 %68, 2
  %91 = add nuw nsw i32 %90, %83
  %92 = add nuw nsw i32 %91, %89
  %93 = lshr i32 %92, 2
  %94 = shl nuw nsw i32 %89, 1
  %95 = mul i64 %6, 30064771072
  %96 = add i64 %95, -4294967296
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i16, i16* %5, i64 %97
  %99 = load i16, i16* %98, align 2
  %100 = zext i16 %99 to i32
  %101 = add nuw nsw i32 %78, 2
  %102 = add nuw nsw i32 %101, %94
  %103 = add nuw nsw i32 %102, %100
  %104 = lshr i32 %103, 2
  %105 = mul nuw nsw i32 %100, 3
  %106 = add nuw nsw i32 %89, 2
  %107 = add nuw nsw i32 %106, %105
  %108 = lshr i32 %107, 2
  %109 = shl i64 %6, 32
  %110 = sub i64 0, %109
  %111 = ashr exact i64 %110, 32
  %112 = select i1 %7, i64 %20, i64 %111
  %113 = getelementptr inbounds i16, i16* %5, i64 %112
  %114 = load i16, i16* %113, align 2
  %115 = zext i16 %114 to i32
  %116 = getelementptr inbounds i16, i16* %5, i64 %111
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = shl nuw nsw i32 %118, 1
  %120 = sub i64 4294967296, %22
  %121 = ashr exact i64 %120, 32
  %122 = getelementptr inbounds i16, i16* %5, i64 %121
  %123 = load i16, i16* %122, align 2
  %124 = zext i16 %123 to i32
  %125 = add nuw nsw i32 %124, 2
  %126 = add nuw nsw i32 %125, %115
  %127 = add nuw nsw i32 %126, %119
  %128 = lshr i32 %127, 2
  %129 = shl nuw nsw i32 %124, 1
  %130 = sub i64 8589934592, %22
  %131 = ashr exact i64 %130, 32
  %132 = getelementptr inbounds i16, i16* %5, i64 %131
  %133 = load i16, i16* %132, align 2
  %134 = zext i16 %133 to i32
  %135 = add nuw nsw i32 %134, 2
  %136 = add nuw nsw i32 %135, %118
  %137 = add nuw nsw i32 %136, %129
  %138 = lshr i32 %137, 2
  %139 = shl nuw nsw i32 %134, 1
  %140 = sub i64 12884901888, %22
  %141 = ashr exact i64 %140, 32
  %142 = getelementptr inbounds i16, i16* %5, i64 %141
  %143 = load i16, i16* %142, align 2
  %144 = zext i16 %143 to i32
  %145 = add nuw nsw i32 %125, %139
  %146 = add nuw nsw i32 %145, %144
  %147 = lshr i32 %146, 2
  %148 = shl nuw nsw i32 %144, 1
  %149 = sub i64 17179869184, %22
  %150 = ashr exact i64 %149, 32
  %151 = getelementptr inbounds i16, i16* %5, i64 %150
  %152 = load i16, i16* %151, align 2
  %153 = zext i16 %152 to i32
  %154 = add nuw nsw i32 %135, %148
  %155 = add nuw nsw i32 %154, %153
  %156 = lshr i32 %155, 2
  %157 = shl nuw nsw i32 %153, 1
  %158 = sub i64 21474836480, %22
  %159 = ashr exact i64 %158, 32
  %160 = getelementptr inbounds i16, i16* %5, i64 %159
  %161 = load i16, i16* %160, align 2
  %162 = zext i16 %161 to i32
  %163 = add nuw nsw i32 %144, 2
  %164 = add nuw nsw i32 %163, %157
  %165 = add nuw nsw i32 %164, %162
  %166 = lshr i32 %165, 2
  %167 = shl nuw nsw i32 %162, 1
  %168 = sub i64 25769803776, %22
  %169 = ashr exact i64 %168, 32
  %170 = getelementptr inbounds i16, i16* %5, i64 %169
  %171 = load i16, i16* %170, align 2
  %172 = zext i16 %171 to i32
  %173 = add nuw nsw i32 %153, 2
  %174 = add nuw nsw i32 %173, %167
  %175 = add nuw nsw i32 %174, %172
  %176 = lshr i32 %175, 2
  %177 = shl nuw nsw i32 %172, 1
  %178 = sub i64 30064771072, %22
  %179 = ashr exact i64 %178, 32
  %180 = getelementptr inbounds i16, i16* %5, i64 %179
  %181 = load i16, i16* %180, align 2
  %182 = zext i16 %181 to i32
  %183 = add nuw nsw i32 %162, 2
  %184 = add nuw nsw i32 %183, %177
  %185 = add nuw nsw i32 %184, %182
  %186 = lshr i32 %185, 2
  %187 = icmp eq i32 %2, 0
  br i1 %187, label %194, label %188

188:                                              ; preds = %19
  %189 = sub i64 34359738368, %22
  %190 = ashr exact i64 %189, 32
  %191 = getelementptr inbounds i16, i16* %5, i64 %190
  %192 = load i16, i16* %191, align 2
  %193 = zext i16 %192 to i32
  br label %194

194:                                              ; preds = %19, %188
  %195 = phi i32 [ %193, %188 ], [ %182, %19 ]
  %196 = shl nuw nsw i32 %182, 1
  %197 = add nuw nsw i32 %172, 2
  %198 = add nuw nsw i32 %197, %196
  %199 = add nuw nsw i32 %198, %195
  %200 = lshr i32 %199, 2
  %201 = add nuw nsw i32 %39, 8
  %202 = add nuw nsw i32 %201, %51
  %203 = add nuw nsw i32 %202, %61
  %204 = add nuw nsw i32 %203, %71
  %205 = add nuw nsw i32 %204, %82
  %206 = add nuw nsw i32 %205, %93
  %207 = add nuw nsw i32 %206, %108
  %208 = add nuw nsw i32 %207, %104
  %209 = add nuw nsw i32 %208, %128
  %210 = add nuw nsw i32 %209, %138
  %211 = add nuw nsw i32 %210, %147
  %212 = add nuw nsw i32 %211, %156
  %213 = add nuw nsw i32 %212, %166
  %214 = add nuw nsw i32 %213, %176
  %215 = add nuw nsw i32 %214, %186
  %216 = add nuw nsw i32 %215, %200
  %217 = ashr i32 %216, 4
  %218 = sext i32 %217 to i64
  %219 = mul i64 %218, 281479271743489
  %220 = bitcast i8* %0 to i64*
  store i64 %219, i64* %220, align 8
  %221 = getelementptr inbounds i8, i8* %0, i64 8
  %222 = bitcast i8* %221 to i64*
  store i64 %219, i64* %222, align 8
  %223 = getelementptr inbounds i16, i16* %5, i64 %21
  %224 = bitcast i16* %223 to i64*
  store i64 %219, i64* %224, align 8
  %225 = getelementptr inbounds i16, i16* %223, i64 4
  %226 = bitcast i16* %225 to i64*
  store i64 %219, i64* %226, align 8
  %227 = getelementptr inbounds i16, i16* %223, i64 %21
  %228 = bitcast i16* %227 to i64*
  store i64 %219, i64* %228, align 8
  %229 = getelementptr inbounds i16, i16* %227, i64 4
  %230 = bitcast i16* %229 to i64*
  store i64 %219, i64* %230, align 8
  %231 = getelementptr inbounds i16, i16* %227, i64 %21
  %232 = bitcast i16* %231 to i64*
  store i64 %219, i64* %232, align 8
  %233 = getelementptr inbounds i16, i16* %231, i64 4
  %234 = bitcast i16* %233 to i64*
  store i64 %219, i64* %234, align 8
  %235 = getelementptr inbounds i16, i16* %231, i64 %21
  %236 = bitcast i16* %235 to i64*
  store i64 %219, i64* %236, align 8
  %237 = getelementptr inbounds i16, i16* %235, i64 4
  %238 = bitcast i16* %237 to i64*
  store i64 %219, i64* %238, align 8
  %239 = getelementptr inbounds i16, i16* %235, i64 %21
  %240 = bitcast i16* %239 to i64*
  store i64 %219, i64* %240, align 8
  %241 = getelementptr inbounds i16, i16* %239, i64 4
  %242 = bitcast i16* %241 to i64*
  store i64 %219, i64* %242, align 8
  %243 = getelementptr inbounds i16, i16* %239, i64 %21
  %244 = bitcast i16* %243 to i64*
  store i64 %219, i64* %244, align 8
  %245 = getelementptr inbounds i16, i16* %243, i64 4
  %246 = bitcast i16* %245 to i64*
  store i64 %219, i64* %246, align 8
  %247 = getelementptr inbounds i16, i16* %243, i64 %21
  %248 = bitcast i16* %247 to i64*
  store i64 %219, i64* %248, align 8
  %249 = getelementptr inbounds i16, i16* %247, i64 4
  %250 = bitcast i16* %249 to i64*
  store i64 %219, i64* %250, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_down_left_9_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %97, label %99

97:                                               ; preds = %18
  %98 = mul nuw nsw i32 %91, 3
  br label %181

99:                                               ; preds = %18
  %100 = sub i64 34359738368, %19
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %5, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i32
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %105, %104
  %107 = shl nuw nsw i32 %104, 1
  %108 = sub i64 38654705664, %19
  %109 = ashr exact i64 %108, 32
  %110 = getelementptr inbounds i16, i16* %5, i64 %109
  %111 = load i16, i16* %110, align 2
  %112 = zext i16 %111 to i32
  %113 = add nuw nsw i32 %91, 2
  %114 = add nuw nsw i32 %113, %107
  %115 = add nuw nsw i32 %114, %112
  %116 = lshr i32 %115, 2
  %117 = shl nuw nsw i32 %112, 1
  %118 = sub i64 42949672960, %19
  %119 = ashr exact i64 %118, 32
  %120 = getelementptr inbounds i16, i16* %5, i64 %119
  %121 = load i16, i16* %120, align 2
  %122 = zext i16 %121 to i32
  %123 = add nuw nsw i32 %122, 2
  %124 = add nuw nsw i32 %123, %104
  %125 = add nuw nsw i32 %124, %117
  %126 = lshr i32 %125, 2
  %127 = shl nuw nsw i32 %122, 1
  %128 = sub i64 47244640256, %19
  %129 = ashr exact i64 %128, 32
  %130 = getelementptr inbounds i16, i16* %5, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i32
  %133 = add nuw nsw i32 %112, 2
  %134 = add nuw nsw i32 %133, %127
  %135 = add nuw nsw i32 %134, %132
  %136 = lshr i32 %135, 2
  %137 = shl nuw nsw i32 %132, 1
  %138 = sub i64 51539607552, %19
  %139 = ashr exact i64 %138, 32
  %140 = getelementptr inbounds i16, i16* %5, i64 %139
  %141 = load i16, i16* %140, align 2
  %142 = zext i16 %141 to i32
  %143 = add nuw nsw i32 %123, %137
  %144 = add nuw nsw i32 %143, %142
  %145 = lshr i32 %144, 2
  %146 = shl nuw nsw i32 %142, 1
  %147 = sub i64 55834574848, %19
  %148 = ashr exact i64 %147, 32
  %149 = getelementptr inbounds i16, i16* %5, i64 %148
  %150 = load i16, i16* %149, align 2
  %151 = zext i16 %150 to i32
  %152 = add nuw nsw i32 %132, 2
  %153 = add nuw nsw i32 %152, %146
  %154 = add nuw nsw i32 %153, %151
  %155 = lshr i32 %154, 2
  %156 = shl nuw nsw i32 %151, 1
  %157 = sub i64 60129542144, %19
  %158 = ashr exact i64 %157, 32
  %159 = getelementptr inbounds i16, i16* %5, i64 %158
  %160 = load i16, i16* %159, align 2
  %161 = zext i16 %160 to i32
  %162 = add nuw nsw i32 %142, 2
  %163 = add nuw nsw i32 %162, %156
  %164 = add nuw nsw i32 %163, %161
  %165 = lshr i32 %164, 2
  %166 = shl nuw nsw i32 %161, 1
  %167 = sub i64 64424509440, %19
  %168 = ashr exact i64 %167, 32
  %169 = getelementptr inbounds i16, i16* %5, i64 %168
  %170 = load i16, i16* %169, align 2
  %171 = zext i16 %170 to i32
  %172 = add nuw nsw i32 %151, 2
  %173 = add nuw nsw i32 %172, %166
  %174 = add nuw nsw i32 %173, %171
  %175 = lshr i32 %174, 2
  %176 = mul nuw nsw i32 %171, 3
  %177 = add nuw nsw i32 %161, 2
  %178 = add nuw nsw i32 %177, %176
  %179 = lshr i32 %178, 2
  %180 = mul nuw nsw i32 %179, 3
  br label %181

181:                                              ; preds = %97, %99
  %182 = phi i32 [ %98, %97 ], [ %180, %99 ]
  %183 = phi i32 [ %98, %97 ], [ %106, %99 ]
  %184 = phi i32 [ %91, %97 ], [ %116, %99 ]
  %185 = phi i32 [ %91, %97 ], [ %126, %99 ]
  %186 = phi i32 [ %91, %97 ], [ %136, %99 ]
  %187 = phi i32 [ %91, %97 ], [ %145, %99 ]
  %188 = phi i32 [ %91, %97 ], [ %155, %99 ]
  %189 = phi i32 [ %91, %97 ], [ %165, %99 ]
  %190 = phi i32 [ %91, %97 ], [ %175, %99 ]
  %191 = phi i32 [ %91, %97 ], [ %179, %99 ]
  %192 = add nuw nsw i32 %81, 2
  %193 = add nuw nsw i32 %192, %183
  %194 = lshr i32 %193, 2
  %195 = shl nuw nsw i32 %47, 1
  %196 = add nuw nsw i32 %56, 2
  %197 = add nuw nsw i32 %196, %37
  %198 = add nuw nsw i32 %197, %195
  %199 = lshr i32 %198, 2
  %200 = trunc i32 %199 to i16
  store i16 %200, i16* %5, align 2
  %201 = shl nuw nsw i32 %56, 1
  %202 = add nuw nsw i32 %65, 2
  %203 = add nuw nsw i32 %202, %47
  %204 = add nuw nsw i32 %203, %201
  %205 = lshr i32 %204, 2
  %206 = trunc i32 %205 to i16
  %207 = getelementptr inbounds i8, i8* %0, i64 2
  %208 = bitcast i8* %207 to i16*
  store i16 %206, i16* %208, align 2
  %209 = ashr exact i64 %19, 32
  %210 = getelementptr inbounds i16, i16* %5, i64 %209
  store i16 %206, i16* %210, align 2
  %211 = shl nuw nsw i32 %65, 1
  %212 = add nuw nsw i32 %196, %211
  %213 = add nuw nsw i32 %212, %75
  %214 = lshr i32 %213, 2
  %215 = trunc i32 %214 to i16
  %216 = getelementptr inbounds i8, i8* %0, i64 4
  %217 = bitcast i8* %216 to i16*
  store i16 %215, i16* %217, align 2
  %218 = add i64 %19, 4294967296
  %219 = ashr exact i64 %218, 32
  %220 = getelementptr inbounds i16, i16* %5, i64 %219
  store i16 %215, i16* %220, align 2
  %221 = trunc i64 %3 to i32
  %222 = and i32 %221, -2
  %223 = sext i32 %222 to i64
  %224 = getelementptr inbounds i16, i16* %5, i64 %223
  store i16 %215, i16* %224, align 2
  %225 = shl nuw nsw i32 %75, 1
  %226 = add nuw nsw i32 %202, %225
  %227 = add nuw nsw i32 %226, %85
  %228 = lshr i32 %227, 2
  %229 = trunc i32 %228 to i16
  %230 = getelementptr inbounds i8, i8* %0, i64 6
  %231 = bitcast i8* %230 to i16*
  store i16 %229, i16* %231, align 2
  %232 = add i64 %19, 8589934592
  %233 = ashr exact i64 %232, 32
  %234 = getelementptr inbounds i16, i16* %5, i64 %233
  store i16 %229, i16* %234, align 2
  %235 = shl i64 %3, 32
  %236 = ashr exact i64 %235, 32
  %237 = or i64 %236, 1
  %238 = getelementptr inbounds i16, i16* %5, i64 %237
  store i16 %229, i16* %238, align 2
  %239 = mul nsw i32 %7, 3
  %240 = sext i32 %239 to i64
  %241 = getelementptr inbounds i16, i16* %5, i64 %240
  store i16 %229, i16* %241, align 2
  %242 = shl nuw nsw i32 %85, 1
  %243 = add nuw nsw i32 %75, 2
  %244 = add nuw nsw i32 %243, %242
  %245 = add nuw nsw i32 %244, %95
  %246 = lshr i32 %245, 2
  %247 = trunc i32 %246 to i16
  %248 = getelementptr inbounds i8, i8* %0, i64 8
  %249 = bitcast i8* %248 to i16*
  store i16 %247, i16* %249, align 2
  %250 = add i64 %19, 12884901888
  %251 = ashr exact i64 %250, 32
  %252 = getelementptr inbounds i16, i16* %5, i64 %251
  store i16 %247, i16* %252, align 2
  %253 = add nsw i32 %222, 2
  %254 = sext i32 %253 to i64
  %255 = getelementptr inbounds i16, i16* %5, i64 %254
  store i16 %247, i16* %255, align 2
  %256 = add nsw i32 %239, 1
  %257 = sext i32 %256 to i64
  %258 = getelementptr inbounds i16, i16* %5, i64 %257
  store i16 %247, i16* %258, align 2
  %259 = shl i64 %6, 34
  %260 = ashr exact i64 %259, 32
  %261 = getelementptr inbounds i16, i16* %5, i64 %260
  store i16 %247, i16* %261, align 2
  %262 = shl nuw nsw i32 %95, 1
  %263 = add nuw nsw i32 %85, 2
  %264 = add nuw nsw i32 %263, %262
  %265 = add nuw nsw i32 %264, %194
  %266 = lshr i32 %265, 2
  %267 = trunc i32 %266 to i16
  %268 = getelementptr inbounds i8, i8* %0, i64 10
  %269 = bitcast i8* %268 to i16*
  store i16 %267, i16* %269, align 2
  %270 = add i64 %19, 17179869184
  %271 = ashr exact i64 %270, 32
  %272 = getelementptr inbounds i16, i16* %5, i64 %271
  store i16 %267, i16* %272, align 2
  %273 = add nsw i32 %222, 3
  %274 = sext i32 %273 to i64
  %275 = getelementptr inbounds i16, i16* %5, i64 %274
  store i16 %267, i16* %275, align 2
  %276 = add nsw i32 %239, 2
  %277 = sext i32 %276 to i64
  %278 = getelementptr inbounds i16, i16* %5, i64 %277
  store i16 %267, i16* %278, align 2
  %279 = or i64 %260, 1
  %280 = getelementptr inbounds i16, i16* %5, i64 %279
  store i16 %267, i16* %280, align 2
  %281 = mul nsw i32 %7, 5
  %282 = sext i32 %281 to i64
  %283 = getelementptr inbounds i16, i16* %5, i64 %282
  store i16 %267, i16* %283, align 2
  %284 = shl nuw nsw i32 %194, 1
  %285 = add nuw nsw i32 %95, 2
  %286 = add nuw nsw i32 %285, %184
  %287 = add nuw nsw i32 %286, %284
  %288 = lshr i32 %287, 2
  %289 = trunc i32 %288 to i16
  %290 = getelementptr inbounds i8, i8* %0, i64 12
  %291 = bitcast i8* %290 to i16*
  store i16 %289, i16* %291, align 2
  %292 = add i64 %19, 21474836480
  %293 = ashr exact i64 %292, 32
  %294 = getelementptr inbounds i16, i16* %5, i64 %293
  store i16 %289, i16* %294, align 2
  %295 = add nsw i32 %222, 4
  %296 = sext i32 %295 to i64
  %297 = getelementptr inbounds i16, i16* %5, i64 %296
  store i16 %289, i16* %297, align 2
  %298 = add nsw i32 %239, 3
  %299 = sext i32 %298 to i64
  %300 = getelementptr inbounds i16, i16* %5, i64 %299
  store i16 %289, i16* %300, align 2
  %301 = or i64 %260, 2
  %302 = getelementptr inbounds i16, i16* %5, i64 %301
  store i16 %289, i16* %302, align 2
  %303 = add nsw i32 %281, 1
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds i16, i16* %5, i64 %304
  store i16 %289, i16* %305, align 2
  %306 = mul nsw i32 %7, 6
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i16, i16* %5, i64 %307
  store i16 %289, i16* %308, align 2
  %309 = shl nuw nsw i32 %184, 1
  %310 = add nuw nsw i32 %194, 2
  %311 = add nuw nsw i32 %310, %185
  %312 = add nuw nsw i32 %311, %309
  %313 = lshr i32 %312, 2
  %314 = trunc i32 %313 to i16
  %315 = getelementptr inbounds i8, i8* %0, i64 14
  %316 = bitcast i8* %315 to i16*
  store i16 %314, i16* %316, align 2
  %317 = add i64 %19, 25769803776
  %318 = ashr exact i64 %317, 32
  %319 = getelementptr inbounds i16, i16* %5, i64 %318
  store i16 %314, i16* %319, align 2
  %320 = add nsw i32 %222, 5
  %321 = sext i32 %320 to i64
  %322 = getelementptr inbounds i16, i16* %5, i64 %321
  store i16 %314, i16* %322, align 2
  %323 = add nsw i32 %239, 4
  %324 = sext i32 %323 to i64
  %325 = getelementptr inbounds i16, i16* %5, i64 %324
  store i16 %314, i16* %325, align 2
  %326 = or i64 %260, 3
  %327 = getelementptr inbounds i16, i16* %5, i64 %326
  store i16 %314, i16* %327, align 2
  %328 = add nsw i32 %281, 2
  %329 = sext i32 %328 to i64
  %330 = getelementptr inbounds i16, i16* %5, i64 %329
  store i16 %314, i16* %330, align 2
  %331 = or i32 %306, 1
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds i16, i16* %5, i64 %332
  store i16 %314, i16* %333, align 2
  %334 = mul nsw i32 %7, 7
  %335 = sext i32 %334 to i64
  %336 = getelementptr inbounds i16, i16* %5, i64 %335
  store i16 %314, i16* %336, align 2
  %337 = shl nuw nsw i32 %185, 1
  %338 = add nuw nsw i32 %184, 2
  %339 = add nuw nsw i32 %338, %337
  %340 = add nuw nsw i32 %339, %186
  %341 = lshr i32 %340, 2
  %342 = trunc i32 %341 to i16
  %343 = add i64 %19, 30064771072
  %344 = ashr exact i64 %343, 32
  %345 = getelementptr inbounds i16, i16* %5, i64 %344
  store i16 %342, i16* %345, align 2
  %346 = add nsw i32 %222, 6
  %347 = sext i32 %346 to i64
  %348 = getelementptr inbounds i16, i16* %5, i64 %347
  store i16 %342, i16* %348, align 2
  %349 = add nsw i32 %239, 5
  %350 = sext i32 %349 to i64
  %351 = getelementptr inbounds i16, i16* %5, i64 %350
  store i16 %342, i16* %351, align 2
  %352 = add i64 %259, 17179869184
  %353 = ashr exact i64 %352, 32
  %354 = getelementptr inbounds i16, i16* %5, i64 %353
  store i16 %342, i16* %354, align 2
  %355 = add nsw i32 %281, 3
  %356 = sext i32 %355 to i64
  %357 = getelementptr inbounds i16, i16* %5, i64 %356
  store i16 %342, i16* %357, align 2
  %358 = add nsw i32 %306, 2
  %359 = sext i32 %358 to i64
  %360 = getelementptr inbounds i16, i16* %5, i64 %359
  store i16 %342, i16* %360, align 2
  %361 = add nsw i32 %334, 1
  %362 = sext i32 %361 to i64
  %363 = getelementptr inbounds i16, i16* %5, i64 %362
  store i16 %342, i16* %363, align 2
  %364 = shl nuw nsw i32 %186, 1
  %365 = add nuw nsw i32 %185, 2
  %366 = add nuw nsw i32 %365, %364
  %367 = add nuw nsw i32 %366, %187
  %368 = lshr i32 %367, 2
  %369 = trunc i32 %368 to i16
  %370 = add nsw i32 %222, 7
  %371 = sext i32 %370 to i64
  %372 = getelementptr inbounds i16, i16* %5, i64 %371
  store i16 %369, i16* %372, align 2
  %373 = add nsw i32 %239, 6
  %374 = sext i32 %373 to i64
  %375 = getelementptr inbounds i16, i16* %5, i64 %374
  store i16 %369, i16* %375, align 2
  %376 = add i64 %259, 21474836480
  %377 = ashr exact i64 %376, 32
  %378 = getelementptr inbounds i16, i16* %5, i64 %377
  store i16 %369, i16* %378, align 2
  %379 = add nsw i32 %281, 4
  %380 = sext i32 %379 to i64
  %381 = getelementptr inbounds i16, i16* %5, i64 %380
  store i16 %369, i16* %381, align 2
  %382 = add nsw i32 %306, 3
  %383 = sext i32 %382 to i64
  %384 = getelementptr inbounds i16, i16* %5, i64 %383
  store i16 %369, i16* %384, align 2
  %385 = add nsw i32 %334, 2
  %386 = sext i32 %385 to i64
  %387 = getelementptr inbounds i16, i16* %5, i64 %386
  store i16 %369, i16* %387, align 2
  %388 = shl nuw nsw i32 %187, 1
  %389 = add nuw nsw i32 %186, 2
  %390 = add nuw nsw i32 %389, %388
  %391 = add nuw nsw i32 %390, %188
  %392 = lshr i32 %391, 2
  %393 = trunc i32 %392 to i16
  %394 = add nsw i32 %239, 7
  %395 = sext i32 %394 to i64
  %396 = getelementptr inbounds i16, i16* %5, i64 %395
  store i16 %393, i16* %396, align 2
  %397 = add i64 %259, 25769803776
  %398 = ashr exact i64 %397, 32
  %399 = getelementptr inbounds i16, i16* %5, i64 %398
  store i16 %393, i16* %399, align 2
  %400 = add nsw i32 %281, 5
  %401 = sext i32 %400 to i64
  %402 = getelementptr inbounds i16, i16* %5, i64 %401
  store i16 %393, i16* %402, align 2
  %403 = add nsw i32 %306, 4
  %404 = sext i32 %403 to i64
  %405 = getelementptr inbounds i16, i16* %5, i64 %404
  store i16 %393, i16* %405, align 2
  %406 = add nsw i32 %334, 3
  %407 = sext i32 %406 to i64
  %408 = getelementptr inbounds i16, i16* %5, i64 %407
  store i16 %393, i16* %408, align 2
  %409 = shl nuw nsw i32 %188, 1
  %410 = add nuw nsw i32 %187, 2
  %411 = add nuw nsw i32 %410, %409
  %412 = add nuw nsw i32 %411, %189
  %413 = lshr i32 %412, 2
  %414 = trunc i32 %413 to i16
  %415 = add i64 %259, 30064771072
  %416 = ashr exact i64 %415, 32
  %417 = getelementptr inbounds i16, i16* %5, i64 %416
  store i16 %414, i16* %417, align 2
  %418 = add nsw i32 %281, 6
  %419 = sext i32 %418 to i64
  %420 = getelementptr inbounds i16, i16* %5, i64 %419
  store i16 %414, i16* %420, align 2
  %421 = add nsw i32 %306, 5
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds i16, i16* %5, i64 %422
  store i16 %414, i16* %423, align 2
  %424 = add nsw i32 %334, 4
  %425 = sext i32 %424 to i64
  %426 = getelementptr inbounds i16, i16* %5, i64 %425
  store i16 %414, i16* %426, align 2
  %427 = shl nuw nsw i32 %189, 1
  %428 = add nuw nsw i32 %188, 2
  %429 = add nuw nsw i32 %428, %427
  %430 = add nuw nsw i32 %429, %190
  %431 = lshr i32 %430, 2
  %432 = trunc i32 %431 to i16
  %433 = add nsw i32 %281, 7
  %434 = sext i32 %433 to i64
  %435 = getelementptr inbounds i16, i16* %5, i64 %434
  store i16 %432, i16* %435, align 2
  %436 = add nsw i32 %306, 6
  %437 = sext i32 %436 to i64
  %438 = getelementptr inbounds i16, i16* %5, i64 %437
  store i16 %432, i16* %438, align 2
  %439 = add nsw i32 %334, 5
  %440 = sext i32 %439 to i64
  %441 = getelementptr inbounds i16, i16* %5, i64 %440
  store i16 %432, i16* %441, align 2
  %442 = shl nuw nsw i32 %190, 1
  %443 = add nuw nsw i32 %189, 2
  %444 = add nuw nsw i32 %443, %442
  %445 = add nuw nsw i32 %444, %191
  %446 = lshr i32 %445, 2
  %447 = trunc i32 %446 to i16
  %448 = add nsw i32 %306, 7
  %449 = sext i32 %448 to i64
  %450 = getelementptr inbounds i16, i16* %5, i64 %449
  store i16 %447, i16* %450, align 2
  %451 = add nsw i32 %334, 6
  %452 = sext i32 %451 to i64
  %453 = getelementptr inbounds i16, i16* %5, i64 %452
  store i16 %447, i16* %453, align 2
  %454 = add nuw nsw i32 %190, 2
  %455 = add nuw nsw i32 %454, %182
  %456 = lshr i32 %455, 2
  %457 = trunc i32 %456 to i16
  %458 = add nsw i32 %334, 7
  %459 = sext i32 %458 to i64
  %460 = getelementptr inbounds i16, i16* %5, i64 %459
  store i16 %457, i16* %460, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_down_right_9_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp ne i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %10, label %15

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %27, 2
  %45 = add nuw nsw i32 %44, %38
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %43, 2
  %64 = add nuw nsw i32 %63, %57
  %65 = add nuw nsw i32 %64, %62
  %66 = lshr i32 %65, 2
  %67 = shl nuw nsw i32 %62, 1
  %68 = sub i64 21474836480, %19
  %69 = ashr exact i64 %68, 32
  %70 = getelementptr inbounds i16, i16* %5, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i32
  %73 = add nuw nsw i32 %53, 2
  %74 = add nuw nsw i32 %73, %67
  %75 = add nuw nsw i32 %74, %72
  %76 = lshr i32 %75, 2
  %77 = shl nuw nsw i32 %72, 1
  %78 = sub i64 25769803776, %19
  %79 = ashr exact i64 %78, 32
  %80 = getelementptr inbounds i16, i16* %5, i64 %79
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i32
  %83 = add nuw nsw i32 %62, 2
  %84 = add nuw nsw i32 %83, %77
  %85 = add nuw nsw i32 %84, %82
  %86 = lshr i32 %85, 2
  %87 = shl nuw nsw i32 %82, 1
  %88 = sub i64 30064771072, %19
  %89 = ashr exact i64 %88, 32
  %90 = getelementptr inbounds i16, i16* %5, i64 %89
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i32
  %93 = add nuw nsw i32 %72, 2
  %94 = add nuw nsw i32 %93, %87
  %95 = add nuw nsw i32 %94, %92
  %96 = lshr i32 %95, 2
  %97 = icmp eq i32 %2, 0
  br i1 %97, label %104, label %98

98:                                               ; preds = %18
  %99 = sub i64 34359738368, %19
  %100 = ashr exact i64 %99, 32
  %101 = getelementptr inbounds i16, i16* %5, i64 %100
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  br label %104

104:                                              ; preds = %18, %98
  %105 = phi i32 [ %103, %98 ], [ %92, %18 ]
  %106 = shl nuw nsw i32 %92, 1
  %107 = add nuw nsw i32 %82, 2
  %108 = add nuw nsw i32 %107, %106
  %109 = add nuw nsw i32 %108, %105
  %110 = lshr i32 %109, 2
  %111 = ashr exact i64 %19, 32
  %112 = xor i64 %111, -1
  %113 = getelementptr inbounds i16, i16* %5, i64 %112
  %114 = getelementptr inbounds i8, i8* %0, i64 -2
  %115 = bitcast i8* %114 to i16*
  %116 = select i1 %8, i16* %113, i16* %115
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = load i16, i16* %115, align 2
  %120 = zext i16 %119 to i32
  %121 = shl nuw nsw i32 %120, 1
  %122 = add i64 %19, -4294967296
  %123 = ashr exact i64 %122, 32
  %124 = getelementptr inbounds i16, i16* %5, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %126, 2
  %128 = add nuw nsw i32 %127, %118
  %129 = add nuw nsw i32 %128, %121
  %130 = lshr i32 %129, 2
  %131 = shl nuw nsw i32 %126, 1
  %132 = trunc i64 %3 to i32
  %133 = and i32 %132, -2
  %134 = add nsw i32 %133, -1
  %135 = sext i32 %134 to i64
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  %137 = load i16, i16* %136, align 2
  %138 = zext i16 %137 to i32
  %139 = add nuw nsw i32 %120, 2
  %140 = add nuw nsw i32 %139, %131
  %141 = add nuw nsw i32 %140, %138
  %142 = lshr i32 %141, 2
  %143 = shl nuw nsw i32 %138, 1
  %144 = mul nsw i32 %7, 3
  %145 = add nsw i32 %144, -1
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds i16, i16* %5, i64 %146
  %148 = load i16, i16* %147, align 2
  %149 = zext i16 %148 to i32
  %150 = add nuw nsw i32 %127, %143
  %151 = add nuw nsw i32 %150, %149
  %152 = lshr i32 %151, 2
  %153 = shl nuw nsw i32 %149, 1
  %154 = shl i64 %6, 34
  %155 = add i64 %154, -4294967296
  %156 = ashr exact i64 %155, 32
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  %158 = load i16, i16* %157, align 2
  %159 = zext i16 %158 to i32
  %160 = add nuw nsw i32 %138, 2
  %161 = add nuw nsw i32 %160, %153
  %162 = add nuw nsw i32 %161, %159
  %163 = lshr i32 %162, 2
  %164 = shl nuw nsw i32 %159, 1
  %165 = mul nsw i32 %7, 5
  %166 = add nsw i32 %165, -1
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds i16, i16* %5, i64 %167
  %169 = load i16, i16* %168, align 2
  %170 = zext i16 %169 to i32
  %171 = add nuw nsw i32 %149, 2
  %172 = add nuw nsw i32 %171, %164
  %173 = add nuw nsw i32 %172, %170
  %174 = lshr i32 %173, 2
  %175 = shl nuw nsw i32 %170, 1
  %176 = mul nsw i32 %7, 6
  %177 = add nsw i32 %176, -1
  %178 = sext i32 %177 to i64
  %179 = getelementptr inbounds i16, i16* %5, i64 %178
  %180 = load i16, i16* %179, align 2
  %181 = zext i16 %180 to i32
  %182 = add nuw nsw i32 %159, 2
  %183 = add nuw nsw i32 %182, %175
  %184 = add nuw nsw i32 %183, %181
  %185 = lshr i32 %184, 2
  %186 = shl nuw nsw i32 %181, 1
  %187 = mul nsw i32 %7, 7
  %188 = add nsw i32 %187, -1
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds i16, i16* %5, i64 %189
  %191 = load i16, i16* %190, align 2
  %192 = zext i16 %191 to i32
  %193 = add nuw nsw i32 %170, 2
  %194 = add nuw nsw i32 %193, %186
  %195 = add nuw nsw i32 %194, %192
  %196 = lshr i32 %195, 2
  %197 = mul nuw nsw i32 %192, 3
  %198 = add nuw nsw i32 %181, 2
  %199 = add nuw nsw i32 %198, %197
  %200 = lshr i32 %199, 2
  %201 = load i16, i16* %113, align 2
  %202 = zext i16 %201 to i32
  %203 = shl nuw nsw i32 %202, 1
  %204 = add nuw nsw i32 %44, %120
  %205 = add nuw nsw i32 %204, %203
  %206 = lshr i32 %205, 2
  %207 = shl nuw nsw i32 %196, 1
  %208 = add nuw nsw i32 %185, 2
  %209 = add nuw nsw i32 %208, %200
  %210 = add nuw nsw i32 %209, %207
  %211 = lshr i32 %210, 2
  %212 = trunc i32 %211 to i16
  %213 = sext i32 %187 to i64
  %214 = getelementptr inbounds i16, i16* %5, i64 %213
  store i16 %212, i16* %214, align 2
  %215 = shl nuw nsw i32 %185, 1
  %216 = add nuw nsw i32 %174, 2
  %217 = add nuw nsw i32 %216, %215
  %218 = add nuw nsw i32 %217, %196
  %219 = lshr i32 %218, 2
  %220 = trunc i32 %219 to i16
  %221 = add nsw i32 %187, 1
  %222 = sext i32 %221 to i64
  %223 = getelementptr inbounds i16, i16* %5, i64 %222
  store i16 %220, i16* %223, align 2
  %224 = sext i32 %176 to i64
  %225 = getelementptr inbounds i16, i16* %5, i64 %224
  store i16 %220, i16* %225, align 2
  %226 = shl nuw nsw i32 %174, 1
  %227 = add nuw nsw i32 %163, 2
  %228 = add nuw nsw i32 %227, %226
  %229 = add nuw nsw i32 %228, %185
  %230 = lshr i32 %229, 2
  %231 = trunc i32 %230 to i16
  %232 = add nsw i32 %187, 2
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds i16, i16* %5, i64 %233
  store i16 %231, i16* %234, align 2
  %235 = or i32 %176, 1
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds i16, i16* %5, i64 %236
  store i16 %231, i16* %237, align 2
  %238 = sext i32 %165 to i64
  %239 = getelementptr inbounds i16, i16* %5, i64 %238
  store i16 %231, i16* %239, align 2
  %240 = shl nuw nsw i32 %163, 1
  %241 = add nuw nsw i32 %152, 2
  %242 = add nuw nsw i32 %241, %240
  %243 = add nuw nsw i32 %242, %174
  %244 = lshr i32 %243, 2
  %245 = trunc i32 %244 to i16
  %246 = add nsw i32 %187, 3
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds i16, i16* %5, i64 %247
  store i16 %245, i16* %248, align 2
  %249 = add nsw i32 %176, 2
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds i16, i16* %5, i64 %250
  store i16 %245, i16* %251, align 2
  %252 = add nsw i32 %165, 1
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i16, i16* %5, i64 %253
  store i16 %245, i16* %254, align 2
  %255 = ashr exact i64 %154, 32
  %256 = getelementptr inbounds i16, i16* %5, i64 %255
  store i16 %245, i16* %256, align 2
  %257 = shl nuw nsw i32 %152, 1
  %258 = add nuw nsw i32 %142, 2
  %259 = add nuw nsw i32 %258, %257
  %260 = add nuw nsw i32 %259, %163
  %261 = lshr i32 %260, 2
  %262 = trunc i32 %261 to i16
  %263 = add nsw i32 %187, 4
  %264 = sext i32 %263 to i64
  %265 = getelementptr inbounds i16, i16* %5, i64 %264
  store i16 %262, i16* %265, align 2
  %266 = add nsw i32 %176, 3
  %267 = sext i32 %266 to i64
  %268 = getelementptr inbounds i16, i16* %5, i64 %267
  store i16 %262, i16* %268, align 2
  %269 = add nsw i32 %165, 2
  %270 = sext i32 %269 to i64
  %271 = getelementptr inbounds i16, i16* %5, i64 %270
  store i16 %262, i16* %271, align 2
  %272 = or i64 %255, 1
  %273 = getelementptr inbounds i16, i16* %5, i64 %272
  store i16 %262, i16* %273, align 2
  %274 = sext i32 %144 to i64
  %275 = getelementptr inbounds i16, i16* %5, i64 %274
  store i16 %262, i16* %275, align 2
  %276 = shl nuw nsw i32 %142, 1
  %277 = add nuw nsw i32 %130, 2
  %278 = add nuw nsw i32 %277, %276
  %279 = add nuw nsw i32 %278, %152
  %280 = lshr i32 %279, 2
  %281 = trunc i32 %280 to i16
  %282 = add nsw i32 %187, 5
  %283 = sext i32 %282 to i64
  %284 = getelementptr inbounds i16, i16* %5, i64 %283
  store i16 %281, i16* %284, align 2
  %285 = add nsw i32 %176, 4
  %286 = sext i32 %285 to i64
  %287 = getelementptr inbounds i16, i16* %5, i64 %286
  store i16 %281, i16* %287, align 2
  %288 = add nsw i32 %165, 3
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds i16, i16* %5, i64 %289
  store i16 %281, i16* %290, align 2
  %291 = or i64 %255, 2
  %292 = getelementptr inbounds i16, i16* %5, i64 %291
  store i16 %281, i16* %292, align 2
  %293 = add nsw i32 %144, 1
  %294 = sext i32 %293 to i64
  %295 = getelementptr inbounds i16, i16* %5, i64 %294
  store i16 %281, i16* %295, align 2
  %296 = sext i32 %133 to i64
  %297 = getelementptr inbounds i16, i16* %5, i64 %296
  store i16 %281, i16* %297, align 2
  %298 = shl nuw nsw i32 %130, 1
  %299 = add nuw nsw i32 %258, %298
  %300 = add nuw nsw i32 %299, %206
  %301 = lshr i32 %300, 2
  %302 = trunc i32 %301 to i16
  %303 = add nsw i32 %187, 6
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds i16, i16* %5, i64 %304
  store i16 %302, i16* %305, align 2
  %306 = add nsw i32 %176, 5
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i16, i16* %5, i64 %307
  store i16 %302, i16* %308, align 2
  %309 = add nsw i32 %165, 4
  %310 = sext i32 %309 to i64
  %311 = getelementptr inbounds i16, i16* %5, i64 %310
  store i16 %302, i16* %311, align 2
  %312 = or i64 %255, 3
  %313 = getelementptr inbounds i16, i16* %5, i64 %312
  store i16 %302, i16* %313, align 2
  %314 = add nsw i32 %144, 2
  %315 = sext i32 %314 to i64
  %316 = getelementptr inbounds i16, i16* %5, i64 %315
  store i16 %302, i16* %316, align 2
  %317 = shl i64 %3, 32
  %318 = ashr exact i64 %317, 32
  %319 = or i64 %318, 1
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %302, i16* %320, align 2
  %321 = getelementptr inbounds i16, i16* %5, i64 %111
  store i16 %302, i16* %321, align 2
  %322 = shl nuw nsw i32 %206, 1
  %323 = add nuw nsw i32 %37, 2
  %324 = add nuw nsw i32 %323, %130
  %325 = add nuw nsw i32 %324, %322
  %326 = lshr i32 %325, 2
  %327 = trunc i32 %326 to i16
  %328 = add nsw i32 %187, 7
  %329 = sext i32 %328 to i64
  %330 = getelementptr inbounds i16, i16* %5, i64 %329
  store i16 %327, i16* %330, align 2
  %331 = add nsw i32 %176, 6
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds i16, i16* %5, i64 %332
  store i16 %327, i16* %333, align 2
  %334 = add nsw i32 %165, 5
  %335 = sext i32 %334 to i64
  %336 = getelementptr inbounds i16, i16* %5, i64 %335
  store i16 %327, i16* %336, align 2
  %337 = add i64 %154, 17179869184
  %338 = ashr exact i64 %337, 32
  %339 = getelementptr inbounds i16, i16* %5, i64 %338
  store i16 %327, i16* %339, align 2
  %340 = add nsw i32 %144, 3
  %341 = sext i32 %340 to i64
  %342 = getelementptr inbounds i16, i16* %5, i64 %341
  store i16 %327, i16* %342, align 2
  %343 = add nsw i32 %133, 2
  %344 = sext i32 %343 to i64
  %345 = getelementptr inbounds i16, i16* %5, i64 %344
  store i16 %327, i16* %345, align 2
  %346 = add i64 %19, 4294967296
  %347 = ashr exact i64 %346, 32
  %348 = getelementptr inbounds i16, i16* %5, i64 %347
  store i16 %327, i16* %348, align 2
  store i16 %327, i16* %5, align 2
  %349 = shl nuw nsw i32 %37, 1
  %350 = add nuw nsw i32 %47, 2
  %351 = add nuw nsw i32 %350, %349
  %352 = add nuw nsw i32 %351, %206
  %353 = lshr i32 %352, 2
  %354 = trunc i32 %353 to i16
  %355 = add nsw i32 %176, 7
  %356 = sext i32 %355 to i64
  %357 = getelementptr inbounds i16, i16* %5, i64 %356
  store i16 %354, i16* %357, align 2
  %358 = add nsw i32 %165, 6
  %359 = sext i32 %358 to i64
  %360 = getelementptr inbounds i16, i16* %5, i64 %359
  store i16 %354, i16* %360, align 2
  %361 = add i64 %154, 21474836480
  %362 = ashr exact i64 %361, 32
  %363 = getelementptr inbounds i16, i16* %5, i64 %362
  store i16 %354, i16* %363, align 2
  %364 = add nsw i32 %144, 4
  %365 = sext i32 %364 to i64
  %366 = getelementptr inbounds i16, i16* %5, i64 %365
  store i16 %354, i16* %366, align 2
  %367 = add nsw i32 %133, 3
  %368 = sext i32 %367 to i64
  %369 = getelementptr inbounds i16, i16* %5, i64 %368
  store i16 %354, i16* %369, align 2
  %370 = add i64 %19, 8589934592
  %371 = ashr exact i64 %370, 32
  %372 = getelementptr inbounds i16, i16* %5, i64 %371
  store i16 %354, i16* %372, align 2
  %373 = getelementptr inbounds i8, i8* %0, i64 2
  %374 = bitcast i8* %373 to i16*
  store i16 %354, i16* %374, align 2
  %375 = shl nuw nsw i32 %47, 1
  %376 = add nuw nsw i32 %323, %375
  %377 = add nuw nsw i32 %376, %56
  %378 = lshr i32 %377, 2
  %379 = trunc i32 %378 to i16
  %380 = add nsw i32 %165, 7
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i16, i16* %5, i64 %381
  store i16 %379, i16* %382, align 2
  %383 = add i64 %154, 25769803776
  %384 = ashr exact i64 %383, 32
  %385 = getelementptr inbounds i16, i16* %5, i64 %384
  store i16 %379, i16* %385, align 2
  %386 = add nsw i32 %144, 5
  %387 = sext i32 %386 to i64
  %388 = getelementptr inbounds i16, i16* %5, i64 %387
  store i16 %379, i16* %388, align 2
  %389 = add nsw i32 %133, 4
  %390 = sext i32 %389 to i64
  %391 = getelementptr inbounds i16, i16* %5, i64 %390
  store i16 %379, i16* %391, align 2
  %392 = add i64 %19, 12884901888
  %393 = ashr exact i64 %392, 32
  %394 = getelementptr inbounds i16, i16* %5, i64 %393
  store i16 %379, i16* %394, align 2
  %395 = getelementptr inbounds i8, i8* %0, i64 4
  %396 = bitcast i8* %395 to i16*
  store i16 %379, i16* %396, align 2
  %397 = shl nuw nsw i32 %56, 1
  %398 = add nuw nsw i32 %350, %397
  %399 = add nuw nsw i32 %398, %66
  %400 = lshr i32 %399, 2
  %401 = trunc i32 %400 to i16
  %402 = add i64 %154, 30064771072
  %403 = ashr exact i64 %402, 32
  %404 = getelementptr inbounds i16, i16* %5, i64 %403
  store i16 %401, i16* %404, align 2
  %405 = add nsw i32 %144, 6
  %406 = sext i32 %405 to i64
  %407 = getelementptr inbounds i16, i16* %5, i64 %406
  store i16 %401, i16* %407, align 2
  %408 = add nsw i32 %133, 5
  %409 = sext i32 %408 to i64
  %410 = getelementptr inbounds i16, i16* %5, i64 %409
  store i16 %401, i16* %410, align 2
  %411 = add i64 %19, 17179869184
  %412 = ashr exact i64 %411, 32
  %413 = getelementptr inbounds i16, i16* %5, i64 %412
  store i16 %401, i16* %413, align 2
  %414 = getelementptr inbounds i8, i8* %0, i64 6
  %415 = bitcast i8* %414 to i16*
  store i16 %401, i16* %415, align 2
  %416 = shl nuw nsw i32 %66, 1
  %417 = add nuw nsw i32 %56, 2
  %418 = add nuw nsw i32 %417, %416
  %419 = add nuw nsw i32 %418, %76
  %420 = lshr i32 %419, 2
  %421 = trunc i32 %420 to i16
  %422 = add nsw i32 %144, 7
  %423 = sext i32 %422 to i64
  %424 = getelementptr inbounds i16, i16* %5, i64 %423
  store i16 %421, i16* %424, align 2
  %425 = add nsw i32 %133, 6
  %426 = sext i32 %425 to i64
  %427 = getelementptr inbounds i16, i16* %5, i64 %426
  store i16 %421, i16* %427, align 2
  %428 = add i64 %19, 21474836480
  %429 = ashr exact i64 %428, 32
  %430 = getelementptr inbounds i16, i16* %5, i64 %429
  store i16 %421, i16* %430, align 2
  %431 = getelementptr inbounds i8, i8* %0, i64 8
  %432 = bitcast i8* %431 to i16*
  store i16 %421, i16* %432, align 2
  %433 = shl nuw nsw i32 %76, 1
  %434 = add nuw nsw i32 %66, 2
  %435 = add nuw nsw i32 %434, %433
  %436 = add nuw nsw i32 %435, %86
  %437 = lshr i32 %436, 2
  %438 = trunc i32 %437 to i16
  %439 = add nsw i32 %133, 7
  %440 = sext i32 %439 to i64
  %441 = getelementptr inbounds i16, i16* %5, i64 %440
  store i16 %438, i16* %441, align 2
  %442 = add i64 %19, 25769803776
  %443 = ashr exact i64 %442, 32
  %444 = getelementptr inbounds i16, i16* %5, i64 %443
  store i16 %438, i16* %444, align 2
  %445 = getelementptr inbounds i8, i8* %0, i64 10
  %446 = bitcast i8* %445 to i16*
  store i16 %438, i16* %446, align 2
  %447 = shl nuw nsw i32 %86, 1
  %448 = add nuw nsw i32 %76, 2
  %449 = add nuw nsw i32 %448, %447
  %450 = add nuw nsw i32 %449, %96
  %451 = lshr i32 %450, 2
  %452 = trunc i32 %451 to i16
  %453 = add i64 %19, 30064771072
  %454 = ashr exact i64 %453, 32
  %455 = getelementptr inbounds i16, i16* %5, i64 %454
  store i16 %452, i16* %455, align 2
  %456 = getelementptr inbounds i8, i8* %0, i64 12
  %457 = bitcast i8* %456 to i16*
  store i16 %452, i16* %457, align 2
  %458 = shl nuw nsw i32 %96, 1
  %459 = add nuw nsw i32 %86, 2
  %460 = add nuw nsw i32 %459, %458
  %461 = add nuw nsw i32 %460, %110
  %462 = lshr i32 %461, 2
  %463 = trunc i32 %462 to i16
  %464 = getelementptr inbounds i8, i8* %0, i64 14
  %465 = bitcast i8* %464 to i16*
  store i16 %463, i16* %465, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_right_9_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp ne i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %10, label %15

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %27, 2
  %45 = add nuw nsw i32 %44, %38
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %43, 2
  %64 = add nuw nsw i32 %63, %57
  %65 = add nuw nsw i32 %64, %62
  %66 = lshr i32 %65, 2
  %67 = shl nuw nsw i32 %62, 1
  %68 = sub i64 21474836480, %19
  %69 = ashr exact i64 %68, 32
  %70 = getelementptr inbounds i16, i16* %5, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i32
  %73 = add nuw nsw i32 %53, 2
  %74 = add nuw nsw i32 %73, %67
  %75 = add nuw nsw i32 %74, %72
  %76 = lshr i32 %75, 2
  %77 = shl nuw nsw i32 %72, 1
  %78 = sub i64 25769803776, %19
  %79 = ashr exact i64 %78, 32
  %80 = getelementptr inbounds i16, i16* %5, i64 %79
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i32
  %83 = add nuw nsw i32 %62, 2
  %84 = add nuw nsw i32 %83, %77
  %85 = add nuw nsw i32 %84, %82
  %86 = lshr i32 %85, 2
  %87 = shl nuw nsw i32 %82, 1
  %88 = sub i64 30064771072, %19
  %89 = ashr exact i64 %88, 32
  %90 = getelementptr inbounds i16, i16* %5, i64 %89
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i32
  %93 = add nuw nsw i32 %72, 2
  %94 = add nuw nsw i32 %93, %87
  %95 = add nuw nsw i32 %94, %92
  %96 = lshr i32 %95, 2
  %97 = icmp eq i32 %2, 0
  br i1 %97, label %104, label %98

98:                                               ; preds = %18
  %99 = sub i64 34359738368, %19
  %100 = ashr exact i64 %99, 32
  %101 = getelementptr inbounds i16, i16* %5, i64 %100
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  br label %104

104:                                              ; preds = %18, %98
  %105 = phi i32 [ %103, %98 ], [ %92, %18 ]
  %106 = shl nuw nsw i32 %92, 1
  %107 = add nuw nsw i32 %82, 2
  %108 = add nuw nsw i32 %107, %106
  %109 = add nuw nsw i32 %108, %105
  %110 = lshr i32 %109, 2
  %111 = ashr exact i64 %19, 32
  %112 = xor i64 %111, -1
  %113 = getelementptr inbounds i16, i16* %5, i64 %112
  %114 = getelementptr inbounds i8, i8* %0, i64 -2
  %115 = bitcast i8* %114 to i16*
  %116 = select i1 %8, i16* %113, i16* %115
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = load i16, i16* %115, align 2
  %120 = zext i16 %119 to i32
  %121 = shl nuw nsw i32 %120, 1
  %122 = add i64 %19, -4294967296
  %123 = ashr exact i64 %122, 32
  %124 = getelementptr inbounds i16, i16* %5, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %126, 2
  %128 = add nuw nsw i32 %127, %118
  %129 = add nuw nsw i32 %128, %121
  %130 = lshr i32 %129, 2
  %131 = shl nuw nsw i32 %126, 1
  %132 = trunc i64 %3 to i32
  %133 = and i32 %132, -2
  %134 = add nsw i32 %133, -1
  %135 = sext i32 %134 to i64
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  %137 = load i16, i16* %136, align 2
  %138 = zext i16 %137 to i32
  %139 = add nuw nsw i32 %120, 2
  %140 = add nuw nsw i32 %139, %131
  %141 = add nuw nsw i32 %140, %138
  %142 = lshr i32 %141, 2
  %143 = shl nuw nsw i32 %138, 1
  %144 = mul nsw i32 %7, 3
  %145 = add nsw i32 %144, -1
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds i16, i16* %5, i64 %146
  %148 = load i16, i16* %147, align 2
  %149 = zext i16 %148 to i32
  %150 = add nuw nsw i32 %127, %143
  %151 = add nuw nsw i32 %150, %149
  %152 = lshr i32 %151, 2
  %153 = shl nuw nsw i32 %149, 1
  %154 = shl i64 %6, 34
  %155 = add i64 %154, -4294967296
  %156 = ashr exact i64 %155, 32
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  %158 = load i16, i16* %157, align 2
  %159 = zext i16 %158 to i32
  %160 = add nuw nsw i32 %138, 2
  %161 = add nuw nsw i32 %160, %153
  %162 = add nuw nsw i32 %161, %159
  %163 = lshr i32 %162, 2
  %164 = shl nuw nsw i32 %159, 1
  %165 = mul nsw i32 %7, 5
  %166 = add nsw i32 %165, -1
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds i16, i16* %5, i64 %167
  %169 = load i16, i16* %168, align 2
  %170 = zext i16 %169 to i32
  %171 = add nuw nsw i32 %149, 2
  %172 = add nuw nsw i32 %171, %164
  %173 = add nuw nsw i32 %172, %170
  %174 = lshr i32 %173, 2
  %175 = shl nuw nsw i32 %170, 1
  %176 = mul nsw i32 %7, 6
  %177 = add nsw i32 %176, -1
  %178 = sext i32 %177 to i64
  %179 = getelementptr inbounds i16, i16* %5, i64 %178
  %180 = load i16, i16* %179, align 2
  %181 = zext i16 %180 to i32
  %182 = add nuw nsw i32 %159, 2
  %183 = add nuw nsw i32 %182, %175
  %184 = add nuw nsw i32 %183, %181
  %185 = lshr i32 %184, 2
  %186 = shl nuw nsw i32 %181, 1
  %187 = mul nsw i32 %7, 7
  %188 = add nsw i32 %187, -1
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds i16, i16* %5, i64 %189
  %191 = load i16, i16* %190, align 2
  %192 = zext i16 %191 to i32
  %193 = add nuw nsw i32 %170, 2
  %194 = add nuw nsw i32 %193, %186
  %195 = add nuw nsw i32 %194, %192
  %196 = lshr i32 %195, 2
  %197 = load i16, i16* %113, align 2
  %198 = zext i16 %197 to i32
  %199 = shl nuw nsw i32 %198, 1
  %200 = add nuw nsw i32 %44, %120
  %201 = add nuw nsw i32 %200, %199
  %202 = lshr i32 %201, 2
  %203 = shl nuw nsw i32 %174, 1
  %204 = add nuw nsw i32 %163, 2
  %205 = add nuw nsw i32 %204, %203
  %206 = add nuw nsw i32 %205, %185
  %207 = lshr i32 %206, 2
  %208 = trunc i32 %207 to i16
  %209 = sext i32 %176 to i64
  %210 = getelementptr inbounds i16, i16* %5, i64 %209
  store i16 %208, i16* %210, align 2
  %211 = shl nuw nsw i32 %185, 1
  %212 = add nuw nsw i32 %174, 2
  %213 = add nuw nsw i32 %212, %211
  %214 = add nuw nsw i32 %213, %196
  %215 = lshr i32 %214, 2
  %216 = trunc i32 %215 to i16
  %217 = sext i32 %187 to i64
  %218 = getelementptr inbounds i16, i16* %5, i64 %217
  store i16 %216, i16* %218, align 2
  %219 = shl nuw nsw i32 %152, 1
  %220 = add nuw nsw i32 %142, 2
  %221 = add nuw nsw i32 %220, %219
  %222 = add nuw nsw i32 %221, %163
  %223 = lshr i32 %222, 2
  %224 = trunc i32 %223 to i16
  %225 = or i32 %176, 1
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds i16, i16* %5, i64 %226
  store i16 %224, i16* %227, align 2
  %228 = ashr exact i64 %154, 32
  %229 = getelementptr inbounds i16, i16* %5, i64 %228
  store i16 %224, i16* %229, align 2
  %230 = shl nuw nsw i32 %163, 1
  %231 = add nuw nsw i32 %152, 2
  %232 = add nuw nsw i32 %231, %230
  %233 = add nuw nsw i32 %232, %174
  %234 = lshr i32 %233, 2
  %235 = trunc i32 %234 to i16
  %236 = add nsw i32 %187, 1
  %237 = sext i32 %236 to i64
  %238 = getelementptr inbounds i16, i16* %5, i64 %237
  store i16 %235, i16* %238, align 2
  %239 = sext i32 %165 to i64
  %240 = getelementptr inbounds i16, i16* %5, i64 %239
  store i16 %235, i16* %240, align 2
  %241 = shl nuw nsw i32 %130, 1
  %242 = add nuw nsw i32 %220, %241
  %243 = add nuw nsw i32 %242, %202
  %244 = lshr i32 %243, 2
  %245 = trunc i32 %244 to i16
  %246 = add nsw i32 %176, 2
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds i16, i16* %5, i64 %247
  store i16 %245, i16* %248, align 2
  %249 = or i64 %228, 1
  %250 = getelementptr inbounds i16, i16* %5, i64 %249
  store i16 %245, i16* %250, align 2
  %251 = sext i32 %133 to i64
  %252 = getelementptr inbounds i16, i16* %5, i64 %251
  store i16 %245, i16* %252, align 2
  %253 = shl nuw nsw i32 %142, 1
  %254 = add nuw nsw i32 %130, 2
  %255 = add nuw nsw i32 %254, %253
  %256 = add nuw nsw i32 %255, %152
  %257 = lshr i32 %256, 2
  %258 = trunc i32 %257 to i16
  %259 = add nsw i32 %187, 2
  %260 = sext i32 %259 to i64
  %261 = getelementptr inbounds i16, i16* %5, i64 %260
  store i16 %258, i16* %261, align 2
  %262 = add nsw i32 %165, 1
  %263 = sext i32 %262 to i64
  %264 = getelementptr inbounds i16, i16* %5, i64 %263
  store i16 %258, i16* %264, align 2
  %265 = sext i32 %144 to i64
  %266 = getelementptr inbounds i16, i16* %5, i64 %265
  store i16 %258, i16* %266, align 2
  %267 = shl nuw nsw i32 %202, 1
  %268 = add nuw nsw i32 %37, 2
  %269 = add nuw nsw i32 %268, %130
  %270 = add nuw nsw i32 %269, %267
  %271 = lshr i32 %270, 2
  %272 = trunc i32 %271 to i16
  %273 = add nsw i32 %187, 3
  %274 = sext i32 %273 to i64
  %275 = getelementptr inbounds i16, i16* %5, i64 %274
  store i16 %272, i16* %275, align 2
  %276 = add nsw i32 %165, 2
  %277 = sext i32 %276 to i64
  %278 = getelementptr inbounds i16, i16* %5, i64 %277
  store i16 %272, i16* %278, align 2
  %279 = add nsw i32 %144, 1
  %280 = sext i32 %279 to i64
  %281 = getelementptr inbounds i16, i16* %5, i64 %280
  store i16 %272, i16* %281, align 2
  %282 = getelementptr inbounds i16, i16* %5, i64 %111
  store i16 %272, i16* %282, align 2
  %283 = add nuw nsw i32 %37, 1
  %284 = add nuw nsw i32 %283, %202
  %285 = lshr i32 %284, 1
  %286 = trunc i32 %285 to i16
  %287 = add nsw i32 %176, 3
  %288 = sext i32 %287 to i64
  %289 = getelementptr inbounds i16, i16* %5, i64 %288
  store i16 %286, i16* %289, align 2
  %290 = or i64 %228, 2
  %291 = getelementptr inbounds i16, i16* %5, i64 %290
  store i16 %286, i16* %291, align 2
  %292 = shl i64 %3, 32
  %293 = ashr exact i64 %292, 32
  %294 = or i64 %293, 1
  %295 = getelementptr inbounds i16, i16* %5, i64 %294
  store i16 %286, i16* %295, align 2
  store i16 %286, i16* %5, align 2
  %296 = shl nuw nsw i32 %37, 1
  %297 = add nuw nsw i32 %47, 2
  %298 = add nuw nsw i32 %297, %296
  %299 = add nuw nsw i32 %298, %202
  %300 = lshr i32 %299, 2
  %301 = trunc i32 %300 to i16
  %302 = add nsw i32 %187, 4
  %303 = sext i32 %302 to i64
  %304 = getelementptr inbounds i16, i16* %5, i64 %303
  store i16 %301, i16* %304, align 2
  %305 = add nsw i32 %165, 3
  %306 = sext i32 %305 to i64
  %307 = getelementptr inbounds i16, i16* %5, i64 %306
  store i16 %301, i16* %307, align 2
  %308 = add nsw i32 %144, 2
  %309 = sext i32 %308 to i64
  %310 = getelementptr inbounds i16, i16* %5, i64 %309
  store i16 %301, i16* %310, align 2
  %311 = add i64 %19, 4294967296
  %312 = ashr exact i64 %311, 32
  %313 = getelementptr inbounds i16, i16* %5, i64 %312
  store i16 %301, i16* %313, align 2
  %314 = add nuw nsw i32 %283, %47
  %315 = lshr i32 %314, 1
  %316 = trunc i32 %315 to i16
  %317 = add nsw i32 %176, 4
  %318 = sext i32 %317 to i64
  %319 = getelementptr inbounds i16, i16* %5, i64 %318
  store i16 %316, i16* %319, align 2
  %320 = or i64 %228, 3
  %321 = getelementptr inbounds i16, i16* %5, i64 %320
  store i16 %316, i16* %321, align 2
  %322 = add nsw i32 %133, 2
  %323 = sext i32 %322 to i64
  %324 = getelementptr inbounds i16, i16* %5, i64 %323
  store i16 %316, i16* %324, align 2
  %325 = getelementptr inbounds i8, i8* %0, i64 2
  %326 = bitcast i8* %325 to i16*
  store i16 %316, i16* %326, align 2
  %327 = shl nuw nsw i32 %47, 1
  %328 = add nuw nsw i32 %268, %327
  %329 = add nuw nsw i32 %328, %56
  %330 = lshr i32 %329, 2
  %331 = trunc i32 %330 to i16
  %332 = add nsw i32 %187, 5
  %333 = sext i32 %332 to i64
  %334 = getelementptr inbounds i16, i16* %5, i64 %333
  store i16 %331, i16* %334, align 2
  %335 = add nsw i32 %165, 4
  %336 = sext i32 %335 to i64
  %337 = getelementptr inbounds i16, i16* %5, i64 %336
  store i16 %331, i16* %337, align 2
  %338 = add nsw i32 %144, 3
  %339 = sext i32 %338 to i64
  %340 = getelementptr inbounds i16, i16* %5, i64 %339
  store i16 %331, i16* %340, align 2
  %341 = add i64 %19, 8589934592
  %342 = ashr exact i64 %341, 32
  %343 = getelementptr inbounds i16, i16* %5, i64 %342
  store i16 %331, i16* %343, align 2
  %344 = add nuw nsw i32 %47, 1
  %345 = add nuw nsw i32 %344, %56
  %346 = lshr i32 %345, 1
  %347 = trunc i32 %346 to i16
  %348 = add nsw i32 %176, 5
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i16, i16* %5, i64 %349
  store i16 %347, i16* %350, align 2
  %351 = add i64 %154, 17179869184
  %352 = ashr exact i64 %351, 32
  %353 = getelementptr inbounds i16, i16* %5, i64 %352
  store i16 %347, i16* %353, align 2
  %354 = add nsw i32 %133, 3
  %355 = sext i32 %354 to i64
  %356 = getelementptr inbounds i16, i16* %5, i64 %355
  store i16 %347, i16* %356, align 2
  %357 = getelementptr inbounds i8, i8* %0, i64 4
  %358 = bitcast i8* %357 to i16*
  store i16 %347, i16* %358, align 2
  %359 = shl nuw nsw i32 %56, 1
  %360 = add nuw nsw i32 %297, %359
  %361 = add nuw nsw i32 %360, %66
  %362 = lshr i32 %361, 2
  %363 = trunc i32 %362 to i16
  %364 = add nsw i32 %187, 6
  %365 = sext i32 %364 to i64
  %366 = getelementptr inbounds i16, i16* %5, i64 %365
  store i16 %363, i16* %366, align 2
  %367 = add nsw i32 %165, 5
  %368 = sext i32 %367 to i64
  %369 = getelementptr inbounds i16, i16* %5, i64 %368
  store i16 %363, i16* %369, align 2
  %370 = add nsw i32 %144, 4
  %371 = sext i32 %370 to i64
  %372 = getelementptr inbounds i16, i16* %5, i64 %371
  store i16 %363, i16* %372, align 2
  %373 = add i64 %19, 12884901888
  %374 = ashr exact i64 %373, 32
  %375 = getelementptr inbounds i16, i16* %5, i64 %374
  store i16 %363, i16* %375, align 2
  %376 = add nuw nsw i32 %56, 1
  %377 = add nuw nsw i32 %376, %66
  %378 = lshr i32 %377, 1
  %379 = trunc i32 %378 to i16
  %380 = add nsw i32 %176, 6
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i16, i16* %5, i64 %381
  store i16 %379, i16* %382, align 2
  %383 = add i64 %154, 21474836480
  %384 = ashr exact i64 %383, 32
  %385 = getelementptr inbounds i16, i16* %5, i64 %384
  store i16 %379, i16* %385, align 2
  %386 = add nsw i32 %133, 4
  %387 = sext i32 %386 to i64
  %388 = getelementptr inbounds i16, i16* %5, i64 %387
  store i16 %379, i16* %388, align 2
  %389 = getelementptr inbounds i8, i8* %0, i64 6
  %390 = bitcast i8* %389 to i16*
  store i16 %379, i16* %390, align 2
  %391 = shl nuw nsw i32 %66, 1
  %392 = add nuw nsw i32 %56, 2
  %393 = add nuw nsw i32 %392, %391
  %394 = add nuw nsw i32 %393, %76
  %395 = lshr i32 %394, 2
  %396 = trunc i32 %395 to i16
  %397 = add nsw i32 %187, 7
  %398 = sext i32 %397 to i64
  %399 = getelementptr inbounds i16, i16* %5, i64 %398
  store i16 %396, i16* %399, align 2
  %400 = add nsw i32 %165, 6
  %401 = sext i32 %400 to i64
  %402 = getelementptr inbounds i16, i16* %5, i64 %401
  store i16 %396, i16* %402, align 2
  %403 = add nsw i32 %144, 5
  %404 = sext i32 %403 to i64
  %405 = getelementptr inbounds i16, i16* %5, i64 %404
  store i16 %396, i16* %405, align 2
  %406 = add i64 %19, 17179869184
  %407 = ashr exact i64 %406, 32
  %408 = getelementptr inbounds i16, i16* %5, i64 %407
  store i16 %396, i16* %408, align 2
  %409 = add nuw nsw i32 %66, 1
  %410 = add nuw nsw i32 %409, %76
  %411 = lshr i32 %410, 1
  %412 = trunc i32 %411 to i16
  %413 = add nsw i32 %176, 7
  %414 = sext i32 %413 to i64
  %415 = getelementptr inbounds i16, i16* %5, i64 %414
  store i16 %412, i16* %415, align 2
  %416 = add i64 %154, 25769803776
  %417 = ashr exact i64 %416, 32
  %418 = getelementptr inbounds i16, i16* %5, i64 %417
  store i16 %412, i16* %418, align 2
  %419 = add nsw i32 %133, 5
  %420 = sext i32 %419 to i64
  %421 = getelementptr inbounds i16, i16* %5, i64 %420
  store i16 %412, i16* %421, align 2
  %422 = getelementptr inbounds i8, i8* %0, i64 8
  %423 = bitcast i8* %422 to i16*
  store i16 %412, i16* %423, align 2
  %424 = shl nuw nsw i32 %76, 1
  %425 = add nuw nsw i32 %66, 2
  %426 = add nuw nsw i32 %425, %424
  %427 = add nuw nsw i32 %426, %86
  %428 = lshr i32 %427, 2
  %429 = trunc i32 %428 to i16
  %430 = add nsw i32 %165, 7
  %431 = sext i32 %430 to i64
  %432 = getelementptr inbounds i16, i16* %5, i64 %431
  store i16 %429, i16* %432, align 2
  %433 = add nsw i32 %144, 6
  %434 = sext i32 %433 to i64
  %435 = getelementptr inbounds i16, i16* %5, i64 %434
  store i16 %429, i16* %435, align 2
  %436 = add i64 %19, 21474836480
  %437 = ashr exact i64 %436, 32
  %438 = getelementptr inbounds i16, i16* %5, i64 %437
  store i16 %429, i16* %438, align 2
  %439 = add nuw nsw i32 %76, 1
  %440 = add nuw nsw i32 %439, %86
  %441 = lshr i32 %440, 1
  %442 = trunc i32 %441 to i16
  %443 = add i64 %154, 30064771072
  %444 = ashr exact i64 %443, 32
  %445 = getelementptr inbounds i16, i16* %5, i64 %444
  store i16 %442, i16* %445, align 2
  %446 = add nsw i32 %133, 6
  %447 = sext i32 %446 to i64
  %448 = getelementptr inbounds i16, i16* %5, i64 %447
  store i16 %442, i16* %448, align 2
  %449 = getelementptr inbounds i8, i8* %0, i64 10
  %450 = bitcast i8* %449 to i16*
  store i16 %442, i16* %450, align 2
  %451 = shl nuw nsw i32 %86, 1
  %452 = add nuw nsw i32 %76, 2
  %453 = add nuw nsw i32 %452, %451
  %454 = add nuw nsw i32 %453, %96
  %455 = lshr i32 %454, 2
  %456 = trunc i32 %455 to i16
  %457 = add nsw i32 %144, 7
  %458 = sext i32 %457 to i64
  %459 = getelementptr inbounds i16, i16* %5, i64 %458
  store i16 %456, i16* %459, align 2
  %460 = add i64 %19, 25769803776
  %461 = ashr exact i64 %460, 32
  %462 = getelementptr inbounds i16, i16* %5, i64 %461
  store i16 %456, i16* %462, align 2
  %463 = add nuw nsw i32 %86, 1
  %464 = add nuw nsw i32 %463, %96
  %465 = lshr i32 %464, 1
  %466 = trunc i32 %465 to i16
  %467 = add nsw i32 %133, 7
  %468 = sext i32 %467 to i64
  %469 = getelementptr inbounds i16, i16* %5, i64 %468
  store i16 %466, i16* %469, align 2
  %470 = getelementptr inbounds i8, i8* %0, i64 12
  %471 = bitcast i8* %470 to i16*
  store i16 %466, i16* %471, align 2
  %472 = shl nuw nsw i32 %96, 1
  %473 = add nuw nsw i32 %86, 2
  %474 = add nuw nsw i32 %473, %472
  %475 = add nuw nsw i32 %474, %110
  %476 = lshr i32 %475, 2
  %477 = trunc i32 %476 to i16
  %478 = add i64 %19, 30064771072
  %479 = ashr exact i64 %478, 32
  %480 = getelementptr inbounds i16, i16* %5, i64 %479
  store i16 %477, i16* %480, align 2
  %481 = add nuw nsw i32 %96, 1
  %482 = add nuw nsw i32 %481, %110
  %483 = lshr i32 %482, 1
  %484 = trunc i32 %483 to i16
  %485 = getelementptr inbounds i8, i8* %0, i64 14
  %486 = bitcast i8* %485 to i16*
  store i16 %484, i16* %486, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_down_9_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp ne i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %10, label %15

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %20

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  %18 = ashr exact i64 %17, 32
  %19 = xor i64 %18, -1
  br label %20

20:                                               ; preds = %15, %10
  %21 = phi i64 [ %19, %15 ], [ %13, %10 ]
  %22 = phi i64 [ %18, %15 ], [ %12, %10 ]
  %23 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %24 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %25 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %26 = getelementptr inbounds i16, i16* %5, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = getelementptr inbounds i16, i16* %5, i64 %24
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i32
  %32 = shl nuw nsw i32 %31, 1
  %33 = sub i64 4294967296, %23
  %34 = ashr exact i64 %33, 32
  %35 = getelementptr inbounds i16, i16* %5, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i32
  %38 = add nuw nsw i32 %37, 2
  %39 = add nuw nsw i32 %38, %28
  %40 = add nuw nsw i32 %39, %32
  %41 = lshr i32 %40, 2
  %42 = shl nuw nsw i32 %37, 1
  %43 = sub i64 8589934592, %23
  %44 = ashr exact i64 %43, 32
  %45 = getelementptr inbounds i16, i16* %5, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i32
  %48 = add nuw nsw i32 %31, 2
  %49 = add nuw nsw i32 %48, %42
  %50 = add nuw nsw i32 %49, %47
  %51 = lshr i32 %50, 2
  %52 = shl nuw nsw i32 %47, 1
  %53 = sub i64 12884901888, %23
  %54 = ashr exact i64 %53, 32
  %55 = getelementptr inbounds i16, i16* %5, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i32
  %58 = add nuw nsw i32 %38, %52
  %59 = add nuw nsw i32 %58, %57
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %57, 1
  %62 = sub i64 17179869184, %23
  %63 = ashr exact i64 %62, 32
  %64 = getelementptr inbounds i16, i16* %5, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i32
  %67 = add nuw nsw i32 %47, 2
  %68 = add nuw nsw i32 %67, %61
  %69 = add nuw nsw i32 %68, %66
  %70 = lshr i32 %69, 2
  %71 = shl nuw nsw i32 %66, 1
  %72 = sub i64 21474836480, %23
  %73 = ashr exact i64 %72, 32
  %74 = getelementptr inbounds i16, i16* %5, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i32
  %77 = add nuw nsw i32 %57, 2
  %78 = add nuw nsw i32 %77, %71
  %79 = add nuw nsw i32 %78, %76
  %80 = lshr i32 %79, 2
  %81 = shl nuw nsw i32 %76, 1
  %82 = sub i64 25769803776, %23
  %83 = ashr exact i64 %82, 32
  %84 = getelementptr inbounds i16, i16* %5, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i32
  %87 = add nuw nsw i32 %66, 2
  %88 = add nuw nsw i32 %87, %81
  %89 = add nuw nsw i32 %88, %86
  %90 = lshr i32 %89, 2
  %91 = shl nuw nsw i32 %86, 1
  %92 = sub i64 30064771072, %23
  %93 = ashr exact i64 %92, 32
  %94 = getelementptr inbounds i16, i16* %5, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i32
  %97 = add nuw nsw i32 %76, 2
  %98 = add nuw nsw i32 %97, %91
  %99 = add nuw nsw i32 %98, %96
  %100 = lshr i32 %99, 2
  %101 = getelementptr inbounds i16, i16* %5, i64 %21
  %102 = getelementptr inbounds i8, i8* %0, i64 -2
  %103 = bitcast i8* %102 to i16*
  %104 = select i1 %8, i16* %101, i16* %103
  %105 = load i16, i16* %104, align 2
  %106 = zext i16 %105 to i32
  %107 = load i16, i16* %103, align 2
  %108 = zext i16 %107 to i32
  %109 = shl nuw nsw i32 %108, 1
  %110 = add i64 %23, -4294967296
  %111 = ashr exact i64 %110, 32
  %112 = getelementptr inbounds i16, i16* %5, i64 %111
  %113 = load i16, i16* %112, align 2
  %114 = zext i16 %113 to i32
  %115 = add nuw nsw i32 %114, 2
  %116 = add nuw nsw i32 %115, %106
  %117 = add nuw nsw i32 %116, %109
  %118 = lshr i32 %117, 2
  %119 = shl nuw nsw i32 %114, 1
  %120 = trunc i64 %3 to i32
  %121 = and i32 %120, -2
  %122 = add nsw i32 %121, -1
  %123 = sext i32 %122 to i64
  %124 = getelementptr inbounds i16, i16* %5, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %108, 2
  %128 = add nuw nsw i32 %127, %119
  %129 = add nuw nsw i32 %128, %126
  %130 = lshr i32 %129, 2
  %131 = shl nuw nsw i32 %126, 1
  %132 = mul nsw i32 %7, 3
  %133 = add nsw i32 %132, -1
  %134 = sext i32 %133 to i64
  %135 = getelementptr inbounds i16, i16* %5, i64 %134
  %136 = load i16, i16* %135, align 2
  %137 = zext i16 %136 to i32
  %138 = add nuw nsw i32 %115, %131
  %139 = add nuw nsw i32 %138, %137
  %140 = lshr i32 %139, 2
  %141 = shl nuw nsw i32 %137, 1
  %142 = shl i64 %6, 34
  %143 = add i64 %142, -4294967296
  %144 = ashr exact i64 %143, 32
  %145 = getelementptr inbounds i16, i16* %5, i64 %144
  %146 = load i16, i16* %145, align 2
  %147 = zext i16 %146 to i32
  %148 = add nuw nsw i32 %126, 2
  %149 = add nuw nsw i32 %148, %141
  %150 = add nuw nsw i32 %149, %147
  %151 = lshr i32 %150, 2
  %152 = shl nuw nsw i32 %147, 1
  %153 = mul nsw i32 %7, 5
  %154 = add nsw i32 %153, -1
  %155 = sext i32 %154 to i64
  %156 = getelementptr inbounds i16, i16* %5, i64 %155
  %157 = load i16, i16* %156, align 2
  %158 = zext i16 %157 to i32
  %159 = add nuw nsw i32 %137, 2
  %160 = add nuw nsw i32 %159, %152
  %161 = add nuw nsw i32 %160, %158
  %162 = lshr i32 %161, 2
  %163 = shl nuw nsw i32 %158, 1
  %164 = mul nsw i32 %7, 6
  %165 = add nsw i32 %164, -1
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds i16, i16* %5, i64 %166
  %168 = load i16, i16* %167, align 2
  %169 = zext i16 %168 to i32
  %170 = add nuw nsw i32 %147, 2
  %171 = add nuw nsw i32 %170, %163
  %172 = add nuw nsw i32 %171, %169
  %173 = lshr i32 %172, 2
  %174 = shl nuw nsw i32 %169, 1
  %175 = mul nsw i32 %7, 7
  %176 = add nsw i32 %175, -1
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds i16, i16* %5, i64 %177
  %179 = load i16, i16* %178, align 2
  %180 = zext i16 %179 to i32
  %181 = add nuw nsw i32 %158, 2
  %182 = add nuw nsw i32 %181, %174
  %183 = add nuw nsw i32 %182, %180
  %184 = lshr i32 %183, 2
  %185 = mul nuw nsw i32 %180, 3
  %186 = add nuw nsw i32 %169, 2
  %187 = add nuw nsw i32 %186, %185
  %188 = lshr i32 %187, 2
  %189 = load i16, i16* %101, align 2
  %190 = zext i16 %189 to i32
  %191 = shl nuw nsw i32 %190, 1
  %192 = add nuw nsw i32 %48, %108
  %193 = add nuw nsw i32 %192, %191
  %194 = lshr i32 %193, 2
  %195 = add nuw nsw i32 %184, 1
  %196 = add nuw nsw i32 %195, %188
  %197 = lshr i32 %196, 1
  %198 = trunc i32 %197 to i16
  %199 = sext i32 %175 to i64
  %200 = getelementptr inbounds i16, i16* %5, i64 %199
  store i16 %198, i16* %200, align 2
  %201 = shl nuw nsw i32 %184, 1
  %202 = add nuw nsw i32 %173, 2
  %203 = add nuw nsw i32 %202, %188
  %204 = add nuw nsw i32 %203, %201
  %205 = lshr i32 %204, 2
  %206 = trunc i32 %205 to i16
  %207 = add nsw i32 %175, 1
  %208 = sext i32 %207 to i64
  %209 = getelementptr inbounds i16, i16* %5, i64 %208
  store i16 %206, i16* %209, align 2
  %210 = add nuw nsw i32 %173, 1
  %211 = add nuw nsw i32 %210, %184
  %212 = lshr i32 %211, 1
  %213 = trunc i32 %212 to i16
  %214 = add nsw i32 %175, 2
  %215 = sext i32 %214 to i64
  %216 = getelementptr inbounds i16, i16* %5, i64 %215
  store i16 %213, i16* %216, align 2
  %217 = sext i32 %164 to i64
  %218 = getelementptr inbounds i16, i16* %5, i64 %217
  store i16 %213, i16* %218, align 2
  %219 = shl nuw nsw i32 %173, 1
  %220 = add nuw nsw i32 %162, 2
  %221 = add nuw nsw i32 %220, %219
  %222 = add nuw nsw i32 %221, %184
  %223 = lshr i32 %222, 2
  %224 = trunc i32 %223 to i16
  %225 = add nsw i32 %175, 3
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds i16, i16* %5, i64 %226
  store i16 %224, i16* %227, align 2
  %228 = or i32 %164, 1
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds i16, i16* %5, i64 %229
  store i16 %224, i16* %230, align 2
  %231 = add nuw nsw i32 %162, 1
  %232 = add nuw nsw i32 %231, %173
  %233 = lshr i32 %232, 1
  %234 = trunc i32 %233 to i16
  %235 = add nsw i32 %175, 4
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds i16, i16* %5, i64 %236
  store i16 %234, i16* %237, align 2
  %238 = add nsw i32 %164, 2
  %239 = sext i32 %238 to i64
  %240 = getelementptr inbounds i16, i16* %5, i64 %239
  store i16 %234, i16* %240, align 2
  %241 = sext i32 %153 to i64
  %242 = getelementptr inbounds i16, i16* %5, i64 %241
  store i16 %234, i16* %242, align 2
  %243 = shl nuw nsw i32 %162, 1
  %244 = add nuw nsw i32 %151, 2
  %245 = add nuw nsw i32 %244, %243
  %246 = add nuw nsw i32 %245, %173
  %247 = lshr i32 %246, 2
  %248 = trunc i32 %247 to i16
  %249 = add nsw i32 %175, 5
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds i16, i16* %5, i64 %250
  store i16 %248, i16* %251, align 2
  %252 = add nsw i32 %164, 3
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i16, i16* %5, i64 %253
  store i16 %248, i16* %254, align 2
  %255 = add nsw i32 %153, 1
  %256 = sext i32 %255 to i64
  %257 = getelementptr inbounds i16, i16* %5, i64 %256
  store i16 %248, i16* %257, align 2
  %258 = add nuw nsw i32 %151, 1
  %259 = add nuw nsw i32 %258, %162
  %260 = lshr i32 %259, 1
  %261 = trunc i32 %260 to i16
  %262 = add nsw i32 %175, 6
  %263 = sext i32 %262 to i64
  %264 = getelementptr inbounds i16, i16* %5, i64 %263
  store i16 %261, i16* %264, align 2
  %265 = add nsw i32 %164, 4
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds i16, i16* %5, i64 %266
  store i16 %261, i16* %267, align 2
  %268 = add nsw i32 %153, 2
  %269 = sext i32 %268 to i64
  %270 = getelementptr inbounds i16, i16* %5, i64 %269
  store i16 %261, i16* %270, align 2
  %271 = ashr exact i64 %142, 32
  %272 = getelementptr inbounds i16, i16* %5, i64 %271
  store i16 %261, i16* %272, align 2
  %273 = shl nuw nsw i32 %151, 1
  %274 = add nuw nsw i32 %140, 2
  %275 = add nuw nsw i32 %274, %273
  %276 = add nuw nsw i32 %275, %162
  %277 = lshr i32 %276, 2
  %278 = trunc i32 %277 to i16
  %279 = add nsw i32 %175, 7
  %280 = sext i32 %279 to i64
  %281 = getelementptr inbounds i16, i16* %5, i64 %280
  store i16 %278, i16* %281, align 2
  %282 = add nsw i32 %164, 5
  %283 = sext i32 %282 to i64
  %284 = getelementptr inbounds i16, i16* %5, i64 %283
  store i16 %278, i16* %284, align 2
  %285 = add nsw i32 %153, 3
  %286 = sext i32 %285 to i64
  %287 = getelementptr inbounds i16, i16* %5, i64 %286
  store i16 %278, i16* %287, align 2
  %288 = or i64 %271, 1
  %289 = getelementptr inbounds i16, i16* %5, i64 %288
  store i16 %278, i16* %289, align 2
  %290 = add nuw nsw i32 %140, 1
  %291 = add nuw nsw i32 %290, %151
  %292 = lshr i32 %291, 1
  %293 = trunc i32 %292 to i16
  %294 = add nsw i32 %164, 6
  %295 = sext i32 %294 to i64
  %296 = getelementptr inbounds i16, i16* %5, i64 %295
  store i16 %293, i16* %296, align 2
  %297 = add nsw i32 %153, 4
  %298 = sext i32 %297 to i64
  %299 = getelementptr inbounds i16, i16* %5, i64 %298
  store i16 %293, i16* %299, align 2
  %300 = or i64 %271, 2
  %301 = getelementptr inbounds i16, i16* %5, i64 %300
  store i16 %293, i16* %301, align 2
  %302 = sext i32 %132 to i64
  %303 = getelementptr inbounds i16, i16* %5, i64 %302
  store i16 %293, i16* %303, align 2
  %304 = shl nuw nsw i32 %140, 1
  %305 = add nuw nsw i32 %130, 2
  %306 = add nuw nsw i32 %305, %304
  %307 = add nuw nsw i32 %306, %151
  %308 = lshr i32 %307, 2
  %309 = trunc i32 %308 to i16
  %310 = add nsw i32 %164, 7
  %311 = sext i32 %310 to i64
  %312 = getelementptr inbounds i16, i16* %5, i64 %311
  store i16 %309, i16* %312, align 2
  %313 = add nsw i32 %153, 5
  %314 = sext i32 %313 to i64
  %315 = getelementptr inbounds i16, i16* %5, i64 %314
  store i16 %309, i16* %315, align 2
  %316 = or i64 %271, 3
  %317 = getelementptr inbounds i16, i16* %5, i64 %316
  store i16 %309, i16* %317, align 2
  %318 = add nsw i32 %132, 1
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %309, i16* %320, align 2
  %321 = add nuw nsw i32 %130, 1
  %322 = add nuw nsw i32 %321, %140
  %323 = lshr i32 %322, 1
  %324 = trunc i32 %323 to i16
  %325 = add nsw i32 %153, 6
  %326 = sext i32 %325 to i64
  %327 = getelementptr inbounds i16, i16* %5, i64 %326
  store i16 %324, i16* %327, align 2
  %328 = add i64 %142, 17179869184
  %329 = ashr exact i64 %328, 32
  %330 = getelementptr inbounds i16, i16* %5, i64 %329
  store i16 %324, i16* %330, align 2
  %331 = add nsw i32 %132, 2
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds i16, i16* %5, i64 %332
  store i16 %324, i16* %333, align 2
  %334 = sext i32 %121 to i64
  %335 = getelementptr inbounds i16, i16* %5, i64 %334
  store i16 %324, i16* %335, align 2
  %336 = shl nuw nsw i32 %130, 1
  %337 = add nuw nsw i32 %118, 2
  %338 = add nuw nsw i32 %337, %336
  %339 = add nuw nsw i32 %338, %140
  %340 = lshr i32 %339, 2
  %341 = trunc i32 %340 to i16
  %342 = add nsw i32 %153, 7
  %343 = sext i32 %342 to i64
  %344 = getelementptr inbounds i16, i16* %5, i64 %343
  store i16 %341, i16* %344, align 2
  %345 = add i64 %142, 21474836480
  %346 = ashr exact i64 %345, 32
  %347 = getelementptr inbounds i16, i16* %5, i64 %346
  store i16 %341, i16* %347, align 2
  %348 = add nsw i32 %132, 3
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i16, i16* %5, i64 %349
  store i16 %341, i16* %350, align 2
  %351 = shl i64 %3, 32
  %352 = ashr exact i64 %351, 32
  %353 = or i64 %352, 1
  %354 = getelementptr inbounds i16, i16* %5, i64 %353
  store i16 %341, i16* %354, align 2
  %355 = add nuw nsw i32 %118, 1
  %356 = add nuw nsw i32 %355, %130
  %357 = lshr i32 %356, 1
  %358 = trunc i32 %357 to i16
  %359 = add i64 %142, 25769803776
  %360 = ashr exact i64 %359, 32
  %361 = getelementptr inbounds i16, i16* %5, i64 %360
  store i16 %358, i16* %361, align 2
  %362 = add nsw i32 %132, 4
  %363 = sext i32 %362 to i64
  %364 = getelementptr inbounds i16, i16* %5, i64 %363
  store i16 %358, i16* %364, align 2
  %365 = add nsw i32 %121, 2
  %366 = sext i32 %365 to i64
  %367 = getelementptr inbounds i16, i16* %5, i64 %366
  store i16 %358, i16* %367, align 2
  %368 = getelementptr inbounds i16, i16* %5, i64 %22
  store i16 %358, i16* %368, align 2
  %369 = shl nuw nsw i32 %118, 1
  %370 = add nuw nsw i32 %305, %369
  %371 = add nuw nsw i32 %370, %194
  %372 = lshr i32 %371, 2
  %373 = trunc i32 %372 to i16
  %374 = add i64 %142, 30064771072
  %375 = ashr exact i64 %374, 32
  %376 = getelementptr inbounds i16, i16* %5, i64 %375
  store i16 %373, i16* %376, align 2
  %377 = add nsw i32 %132, 5
  %378 = sext i32 %377 to i64
  %379 = getelementptr inbounds i16, i16* %5, i64 %378
  store i16 %373, i16* %379, align 2
  %380 = add nsw i32 %121, 3
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i16, i16* %5, i64 %381
  store i16 %373, i16* %382, align 2
  %383 = add i64 %23, 4294967296
  %384 = ashr exact i64 %383, 32
  %385 = getelementptr inbounds i16, i16* %5, i64 %384
  store i16 %373, i16* %385, align 2
  %386 = add nuw nsw i32 %355, %194
  %387 = lshr i32 %386, 1
  %388 = trunc i32 %387 to i16
  %389 = add nsw i32 %132, 6
  %390 = sext i32 %389 to i64
  %391 = getelementptr inbounds i16, i16* %5, i64 %390
  store i16 %388, i16* %391, align 2
  %392 = add nsw i32 %121, 4
  %393 = sext i32 %392 to i64
  %394 = getelementptr inbounds i16, i16* %5, i64 %393
  store i16 %388, i16* %394, align 2
  %395 = add i64 %23, 8589934592
  %396 = ashr exact i64 %395, 32
  %397 = getelementptr inbounds i16, i16* %5, i64 %396
  store i16 %388, i16* %397, align 2
  store i16 %388, i16* %5, align 2
  %398 = shl nuw nsw i32 %194, 1
  %399 = add nuw nsw i32 %41, 2
  %400 = add nuw nsw i32 %399, %118
  %401 = add nuw nsw i32 %400, %398
  %402 = lshr i32 %401, 2
  %403 = trunc i32 %402 to i16
  %404 = add nsw i32 %132, 7
  %405 = sext i32 %404 to i64
  %406 = getelementptr inbounds i16, i16* %5, i64 %405
  store i16 %403, i16* %406, align 2
  %407 = add nsw i32 %121, 5
  %408 = sext i32 %407 to i64
  %409 = getelementptr inbounds i16, i16* %5, i64 %408
  store i16 %403, i16* %409, align 2
  %410 = add i64 %23, 12884901888
  %411 = ashr exact i64 %410, 32
  %412 = getelementptr inbounds i16, i16* %5, i64 %411
  store i16 %403, i16* %412, align 2
  %413 = getelementptr inbounds i8, i8* %0, i64 2
  %414 = bitcast i8* %413 to i16*
  store i16 %403, i16* %414, align 2
  %415 = shl nuw nsw i32 %41, 1
  %416 = add nuw nsw i32 %51, 2
  %417 = add nuw nsw i32 %416, %415
  %418 = add nuw nsw i32 %417, %194
  %419 = lshr i32 %418, 2
  %420 = trunc i32 %419 to i16
  %421 = add nsw i32 %121, 6
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds i16, i16* %5, i64 %422
  store i16 %420, i16* %423, align 2
  %424 = add i64 %23, 17179869184
  %425 = ashr exact i64 %424, 32
  %426 = getelementptr inbounds i16, i16* %5, i64 %425
  store i16 %420, i16* %426, align 2
  %427 = getelementptr inbounds i8, i8* %0, i64 4
  %428 = bitcast i8* %427 to i16*
  store i16 %420, i16* %428, align 2
  %429 = shl nuw nsw i32 %51, 1
  %430 = add nuw nsw i32 %399, %429
  %431 = add nuw nsw i32 %430, %60
  %432 = lshr i32 %431, 2
  %433 = trunc i32 %432 to i16
  %434 = add nsw i32 %121, 7
  %435 = sext i32 %434 to i64
  %436 = getelementptr inbounds i16, i16* %5, i64 %435
  store i16 %433, i16* %436, align 2
  %437 = add i64 %23, 21474836480
  %438 = ashr exact i64 %437, 32
  %439 = getelementptr inbounds i16, i16* %5, i64 %438
  store i16 %433, i16* %439, align 2
  %440 = getelementptr inbounds i8, i8* %0, i64 6
  %441 = bitcast i8* %440 to i16*
  store i16 %433, i16* %441, align 2
  %442 = shl nuw nsw i32 %60, 1
  %443 = add nuw nsw i32 %416, %442
  %444 = add nuw nsw i32 %443, %70
  %445 = lshr i32 %444, 2
  %446 = trunc i32 %445 to i16
  %447 = add i64 %23, 25769803776
  %448 = ashr exact i64 %447, 32
  %449 = getelementptr inbounds i16, i16* %5, i64 %448
  store i16 %446, i16* %449, align 2
  %450 = getelementptr inbounds i8, i8* %0, i64 8
  %451 = bitcast i8* %450 to i16*
  store i16 %446, i16* %451, align 2
  %452 = shl nuw nsw i32 %70, 1
  %453 = add nuw nsw i32 %60, 2
  %454 = add nuw nsw i32 %453, %452
  %455 = add nuw nsw i32 %454, %80
  %456 = lshr i32 %455, 2
  %457 = trunc i32 %456 to i16
  %458 = add i64 %23, 30064771072
  %459 = ashr exact i64 %458, 32
  %460 = getelementptr inbounds i16, i16* %5, i64 %459
  store i16 %457, i16* %460, align 2
  %461 = getelementptr inbounds i8, i8* %0, i64 10
  %462 = bitcast i8* %461 to i16*
  store i16 %457, i16* %462, align 2
  %463 = shl nuw nsw i32 %80, 1
  %464 = add nuw nsw i32 %70, 2
  %465 = add nuw nsw i32 %464, %463
  %466 = add nuw nsw i32 %465, %90
  %467 = lshr i32 %466, 2
  %468 = trunc i32 %467 to i16
  %469 = getelementptr inbounds i8, i8* %0, i64 12
  %470 = bitcast i8* %469 to i16*
  store i16 %468, i16* %470, align 2
  %471 = shl nuw nsw i32 %90, 1
  %472 = add nuw nsw i32 %80, 2
  %473 = add nuw nsw i32 %472, %471
  %474 = add nuw nsw i32 %473, %100
  %475 = lshr i32 %474, 2
  %476 = trunc i32 %475 to i16
  %477 = getelementptr inbounds i8, i8* %0, i64 14
  %478 = bitcast i8* %477 to i16*
  store i16 %476, i16* %478, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_left_9_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %97, label %99

97:                                               ; preds = %18
  %98 = mul nuw nsw i32 %91, 3
  br label %156

99:                                               ; preds = %18
  %100 = sub i64 34359738368, %19
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %5, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i32
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %105, %104
  %107 = shl nuw nsw i32 %104, 1
  %108 = sub i64 38654705664, %19
  %109 = ashr exact i64 %108, 32
  %110 = getelementptr inbounds i16, i16* %5, i64 %109
  %111 = load i16, i16* %110, align 2
  %112 = zext i16 %111 to i32
  %113 = add nuw nsw i32 %91, 2
  %114 = add nuw nsw i32 %113, %107
  %115 = add nuw nsw i32 %114, %112
  %116 = lshr i32 %115, 2
  %117 = shl nuw nsw i32 %112, 1
  %118 = sub i64 42949672960, %19
  %119 = ashr exact i64 %118, 32
  %120 = getelementptr inbounds i16, i16* %5, i64 %119
  %121 = load i16, i16* %120, align 2
  %122 = zext i16 %121 to i32
  %123 = add nuw nsw i32 %122, 2
  %124 = add nuw nsw i32 %123, %104
  %125 = add nuw nsw i32 %124, %117
  %126 = lshr i32 %125, 2
  %127 = shl nuw nsw i32 %122, 1
  %128 = sub i64 47244640256, %19
  %129 = ashr exact i64 %128, 32
  %130 = getelementptr inbounds i16, i16* %5, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i32
  %133 = add nuw nsw i32 %112, 2
  %134 = add nuw nsw i32 %133, %127
  %135 = add nuw nsw i32 %134, %132
  %136 = lshr i32 %135, 2
  %137 = shl nuw nsw i32 %132, 1
  %138 = sub i64 51539607552, %19
  %139 = ashr exact i64 %138, 32
  %140 = getelementptr inbounds i16, i16* %5, i64 %139
  %141 = load i16, i16* %140, align 2
  %142 = zext i16 %141 to i32
  %143 = add nuw nsw i32 %123, %137
  %144 = add nuw nsw i32 %143, %142
  %145 = lshr i32 %144, 2
  %146 = shl nuw nsw i32 %142, 1
  %147 = sub i64 55834574848, %19
  %148 = ashr exact i64 %147, 32
  %149 = getelementptr inbounds i16, i16* %5, i64 %148
  %150 = load i16, i16* %149, align 2
  %151 = zext i16 %150 to i32
  %152 = add nuw nsw i32 %132, 2
  %153 = add nuw nsw i32 %152, %146
  %154 = add nuw nsw i32 %153, %151
  %155 = lshr i32 %154, 2
  br label %156

156:                                              ; preds = %97, %99
  %157 = phi i32 [ %106, %99 ], [ %98, %97 ]
  %158 = phi i32 [ %116, %99 ], [ %91, %97 ]
  %159 = phi i32 [ %126, %99 ], [ %91, %97 ]
  %160 = phi i32 [ %136, %99 ], [ %91, %97 ]
  %161 = phi i32 [ %145, %99 ], [ %91, %97 ]
  %162 = phi i32 [ %155, %99 ], [ %91, %97 ]
  %163 = add nuw nsw i32 %81, 2
  %164 = add nuw nsw i32 %163, %157
  %165 = lshr i32 %164, 2
  %166 = add nuw nsw i32 %47, 1
  %167 = add nuw nsw i32 %166, %37
  %168 = lshr i32 %167, 1
  %169 = trunc i32 %168 to i16
  store i16 %169, i16* %5, align 2
  %170 = shl nuw nsw i32 %47, 1
  %171 = add nuw nsw i32 %56, 2
  %172 = add nuw nsw i32 %171, %37
  %173 = add nuw nsw i32 %172, %170
  %174 = lshr i32 %173, 2
  %175 = trunc i32 %174 to i16
  %176 = ashr exact i64 %19, 32
  %177 = getelementptr inbounds i16, i16* %5, i64 %176
  store i16 %175, i16* %177, align 2
  %178 = add nuw nsw i32 %166, %56
  %179 = lshr i32 %178, 1
  %180 = trunc i32 %179 to i16
  %181 = getelementptr inbounds i8, i8* %0, i64 2
  %182 = bitcast i8* %181 to i16*
  store i16 %180, i16* %182, align 2
  %183 = trunc i64 %3 to i32
  %184 = and i32 %183, -2
  %185 = sext i32 %184 to i64
  %186 = getelementptr inbounds i16, i16* %5, i64 %185
  store i16 %180, i16* %186, align 2
  %187 = shl nuw nsw i32 %56, 1
  %188 = add nuw nsw i32 %65, 2
  %189 = add nuw nsw i32 %188, %47
  %190 = add nuw nsw i32 %189, %187
  %191 = lshr i32 %190, 2
  %192 = trunc i32 %191 to i16
  %193 = add i64 %19, 4294967296
  %194 = ashr exact i64 %193, 32
  %195 = getelementptr inbounds i16, i16* %5, i64 %194
  store i16 %192, i16* %195, align 2
  %196 = mul nsw i32 %7, 3
  %197 = sext i32 %196 to i64
  %198 = getelementptr inbounds i16, i16* %5, i64 %197
  store i16 %192, i16* %198, align 2
  %199 = add nuw nsw i32 %56, 1
  %200 = add nuw nsw i32 %199, %65
  %201 = lshr i32 %200, 1
  %202 = trunc i32 %201 to i16
  %203 = getelementptr inbounds i8, i8* %0, i64 4
  %204 = bitcast i8* %203 to i16*
  store i16 %202, i16* %204, align 2
  %205 = shl i64 %3, 32
  %206 = ashr exact i64 %205, 32
  %207 = or i64 %206, 1
  %208 = getelementptr inbounds i16, i16* %5, i64 %207
  store i16 %202, i16* %208, align 2
  %209 = shl i64 %6, 34
  %210 = ashr exact i64 %209, 32
  %211 = getelementptr inbounds i16, i16* %5, i64 %210
  store i16 %202, i16* %211, align 2
  %212 = shl nuw nsw i32 %65, 1
  %213 = add nuw nsw i32 %171, %212
  %214 = add nuw nsw i32 %213, %75
  %215 = lshr i32 %214, 2
  %216 = trunc i32 %215 to i16
  %217 = add i64 %19, 8589934592
  %218 = ashr exact i64 %217, 32
  %219 = getelementptr inbounds i16, i16* %5, i64 %218
  store i16 %216, i16* %219, align 2
  %220 = add nsw i32 %196, 1
  %221 = sext i32 %220 to i64
  %222 = getelementptr inbounds i16, i16* %5, i64 %221
  store i16 %216, i16* %222, align 2
  %223 = mul nsw i32 %7, 5
  %224 = sext i32 %223 to i64
  %225 = getelementptr inbounds i16, i16* %5, i64 %224
  store i16 %216, i16* %225, align 2
  %226 = add nuw nsw i32 %65, 1
  %227 = add nuw nsw i32 %226, %75
  %228 = lshr i32 %227, 1
  %229 = trunc i32 %228 to i16
  %230 = getelementptr inbounds i8, i8* %0, i64 6
  %231 = bitcast i8* %230 to i16*
  store i16 %229, i16* %231, align 2
  %232 = add nsw i32 %184, 2
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds i16, i16* %5, i64 %233
  store i16 %229, i16* %234, align 2
  %235 = or i64 %210, 1
  %236 = getelementptr inbounds i16, i16* %5, i64 %235
  store i16 %229, i16* %236, align 2
  %237 = mul nsw i32 %7, 6
  %238 = sext i32 %237 to i64
  %239 = getelementptr inbounds i16, i16* %5, i64 %238
  store i16 %229, i16* %239, align 2
  %240 = shl nuw nsw i32 %75, 1
  %241 = add nuw nsw i32 %188, %240
  %242 = add nuw nsw i32 %241, %85
  %243 = lshr i32 %242, 2
  %244 = trunc i32 %243 to i16
  %245 = add i64 %19, 12884901888
  %246 = ashr exact i64 %245, 32
  %247 = getelementptr inbounds i16, i16* %5, i64 %246
  store i16 %244, i16* %247, align 2
  %248 = add nsw i32 %196, 2
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i16, i16* %5, i64 %249
  store i16 %244, i16* %250, align 2
  %251 = add nsw i32 %223, 1
  %252 = sext i32 %251 to i64
  %253 = getelementptr inbounds i16, i16* %5, i64 %252
  store i16 %244, i16* %253, align 2
  %254 = mul nsw i32 %7, 7
  %255 = sext i32 %254 to i64
  %256 = getelementptr inbounds i16, i16* %5, i64 %255
  store i16 %244, i16* %256, align 2
  %257 = add nuw nsw i32 %75, 1
  %258 = add nuw nsw i32 %257, %85
  %259 = lshr i32 %258, 1
  %260 = trunc i32 %259 to i16
  %261 = getelementptr inbounds i8, i8* %0, i64 8
  %262 = bitcast i8* %261 to i16*
  store i16 %260, i16* %262, align 2
  %263 = add nsw i32 %184, 3
  %264 = sext i32 %263 to i64
  %265 = getelementptr inbounds i16, i16* %5, i64 %264
  store i16 %260, i16* %265, align 2
  %266 = or i64 %210, 2
  %267 = getelementptr inbounds i16, i16* %5, i64 %266
  store i16 %260, i16* %267, align 2
  %268 = or i32 %237, 1
  %269 = sext i32 %268 to i64
  %270 = getelementptr inbounds i16, i16* %5, i64 %269
  store i16 %260, i16* %270, align 2
  %271 = shl nuw nsw i32 %85, 1
  %272 = add nuw nsw i32 %75, 2
  %273 = add nuw nsw i32 %272, %271
  %274 = add nuw nsw i32 %273, %95
  %275 = lshr i32 %274, 2
  %276 = trunc i32 %275 to i16
  %277 = add i64 %19, 17179869184
  %278 = ashr exact i64 %277, 32
  %279 = getelementptr inbounds i16, i16* %5, i64 %278
  store i16 %276, i16* %279, align 2
  %280 = add nsw i32 %196, 3
  %281 = sext i32 %280 to i64
  %282 = getelementptr inbounds i16, i16* %5, i64 %281
  store i16 %276, i16* %282, align 2
  %283 = add nsw i32 %223, 2
  %284 = sext i32 %283 to i64
  %285 = getelementptr inbounds i16, i16* %5, i64 %284
  store i16 %276, i16* %285, align 2
  %286 = add nsw i32 %254, 1
  %287 = sext i32 %286 to i64
  %288 = getelementptr inbounds i16, i16* %5, i64 %287
  store i16 %276, i16* %288, align 2
  %289 = add nuw nsw i32 %85, 1
  %290 = add nuw nsw i32 %289, %95
  %291 = lshr i32 %290, 1
  %292 = trunc i32 %291 to i16
  %293 = getelementptr inbounds i8, i8* %0, i64 10
  %294 = bitcast i8* %293 to i16*
  store i16 %292, i16* %294, align 2
  %295 = add nsw i32 %184, 4
  %296 = sext i32 %295 to i64
  %297 = getelementptr inbounds i16, i16* %5, i64 %296
  store i16 %292, i16* %297, align 2
  %298 = or i64 %210, 3
  %299 = getelementptr inbounds i16, i16* %5, i64 %298
  store i16 %292, i16* %299, align 2
  %300 = add nsw i32 %237, 2
  %301 = sext i32 %300 to i64
  %302 = getelementptr inbounds i16, i16* %5, i64 %301
  store i16 %292, i16* %302, align 2
  %303 = shl nuw nsw i32 %95, 1
  %304 = add nuw nsw i32 %85, 2
  %305 = add nuw nsw i32 %304, %303
  %306 = add nuw nsw i32 %305, %165
  %307 = lshr i32 %306, 2
  %308 = trunc i32 %307 to i16
  %309 = add i64 %19, 21474836480
  %310 = ashr exact i64 %309, 32
  %311 = getelementptr inbounds i16, i16* %5, i64 %310
  store i16 %308, i16* %311, align 2
  %312 = add nsw i32 %196, 4
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds i16, i16* %5, i64 %313
  store i16 %308, i16* %314, align 2
  %315 = add nsw i32 %223, 3
  %316 = sext i32 %315 to i64
  %317 = getelementptr inbounds i16, i16* %5, i64 %316
  store i16 %308, i16* %317, align 2
  %318 = add nsw i32 %254, 2
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %308, i16* %320, align 2
  %321 = add nuw nsw i32 %95, 1
  %322 = add nuw nsw i32 %321, %165
  %323 = lshr i32 %322, 1
  %324 = trunc i32 %323 to i16
  %325 = getelementptr inbounds i8, i8* %0, i64 12
  %326 = bitcast i8* %325 to i16*
  store i16 %324, i16* %326, align 2
  %327 = add nsw i32 %184, 5
  %328 = sext i32 %327 to i64
  %329 = getelementptr inbounds i16, i16* %5, i64 %328
  store i16 %324, i16* %329, align 2
  %330 = add i64 %209, 17179869184
  %331 = ashr exact i64 %330, 32
  %332 = getelementptr inbounds i16, i16* %5, i64 %331
  store i16 %324, i16* %332, align 2
  %333 = add nsw i32 %237, 3
  %334 = sext i32 %333 to i64
  %335 = getelementptr inbounds i16, i16* %5, i64 %334
  store i16 %324, i16* %335, align 2
  %336 = shl nuw nsw i32 %165, 1
  %337 = add nuw nsw i32 %95, 2
  %338 = add nuw nsw i32 %337, %158
  %339 = add nuw nsw i32 %338, %336
  %340 = lshr i32 %339, 2
  %341 = trunc i32 %340 to i16
  %342 = add i64 %19, 25769803776
  %343 = ashr exact i64 %342, 32
  %344 = getelementptr inbounds i16, i16* %5, i64 %343
  store i16 %341, i16* %344, align 2
  %345 = add nsw i32 %196, 5
  %346 = sext i32 %345 to i64
  %347 = getelementptr inbounds i16, i16* %5, i64 %346
  store i16 %341, i16* %347, align 2
  %348 = add nsw i32 %223, 4
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i16, i16* %5, i64 %349
  store i16 %341, i16* %350, align 2
  %351 = add nsw i32 %254, 3
  %352 = sext i32 %351 to i64
  %353 = getelementptr inbounds i16, i16* %5, i64 %352
  store i16 %341, i16* %353, align 2
  %354 = add nuw nsw i32 %158, 1
  %355 = add nuw nsw i32 %354, %165
  %356 = lshr i32 %355, 1
  %357 = trunc i32 %356 to i16
  %358 = getelementptr inbounds i8, i8* %0, i64 14
  %359 = bitcast i8* %358 to i16*
  store i16 %357, i16* %359, align 2
  %360 = add nsw i32 %184, 6
  %361 = sext i32 %360 to i64
  %362 = getelementptr inbounds i16, i16* %5, i64 %361
  store i16 %357, i16* %362, align 2
  %363 = add i64 %209, 21474836480
  %364 = ashr exact i64 %363, 32
  %365 = getelementptr inbounds i16, i16* %5, i64 %364
  store i16 %357, i16* %365, align 2
  %366 = add nsw i32 %237, 4
  %367 = sext i32 %366 to i64
  %368 = getelementptr inbounds i16, i16* %5, i64 %367
  store i16 %357, i16* %368, align 2
  %369 = shl nuw nsw i32 %158, 1
  %370 = add nuw nsw i32 %165, 2
  %371 = add nuw nsw i32 %370, %159
  %372 = add nuw nsw i32 %371, %369
  %373 = lshr i32 %372, 2
  %374 = trunc i32 %373 to i16
  %375 = add i64 %19, 30064771072
  %376 = ashr exact i64 %375, 32
  %377 = getelementptr inbounds i16, i16* %5, i64 %376
  store i16 %374, i16* %377, align 2
  %378 = add nsw i32 %196, 6
  %379 = sext i32 %378 to i64
  %380 = getelementptr inbounds i16, i16* %5, i64 %379
  store i16 %374, i16* %380, align 2
  %381 = add nsw i32 %223, 5
  %382 = sext i32 %381 to i64
  %383 = getelementptr inbounds i16, i16* %5, i64 %382
  store i16 %374, i16* %383, align 2
  %384 = add nsw i32 %254, 4
  %385 = sext i32 %384 to i64
  %386 = getelementptr inbounds i16, i16* %5, i64 %385
  store i16 %374, i16* %386, align 2
  %387 = add nuw nsw i32 %354, %159
  %388 = lshr i32 %387, 1
  %389 = trunc i32 %388 to i16
  %390 = add nsw i32 %184, 7
  %391 = sext i32 %390 to i64
  %392 = getelementptr inbounds i16, i16* %5, i64 %391
  store i16 %389, i16* %392, align 2
  %393 = add i64 %209, 25769803776
  %394 = ashr exact i64 %393, 32
  %395 = getelementptr inbounds i16, i16* %5, i64 %394
  store i16 %389, i16* %395, align 2
  %396 = add nsw i32 %237, 5
  %397 = sext i32 %396 to i64
  %398 = getelementptr inbounds i16, i16* %5, i64 %397
  store i16 %389, i16* %398, align 2
  %399 = shl nuw nsw i32 %159, 1
  %400 = add nuw nsw i32 %158, 2
  %401 = add nuw nsw i32 %400, %399
  %402 = add nuw nsw i32 %401, %160
  %403 = lshr i32 %402, 2
  %404 = trunc i32 %403 to i16
  %405 = add nsw i32 %196, 7
  %406 = sext i32 %405 to i64
  %407 = getelementptr inbounds i16, i16* %5, i64 %406
  store i16 %404, i16* %407, align 2
  %408 = add nsw i32 %223, 6
  %409 = sext i32 %408 to i64
  %410 = getelementptr inbounds i16, i16* %5, i64 %409
  store i16 %404, i16* %410, align 2
  %411 = add nsw i32 %254, 5
  %412 = sext i32 %411 to i64
  %413 = getelementptr inbounds i16, i16* %5, i64 %412
  store i16 %404, i16* %413, align 2
  %414 = add nuw nsw i32 %159, 1
  %415 = add nuw nsw i32 %414, %160
  %416 = lshr i32 %415, 1
  %417 = trunc i32 %416 to i16
  %418 = add i64 %209, 30064771072
  %419 = ashr exact i64 %418, 32
  %420 = getelementptr inbounds i16, i16* %5, i64 %419
  store i16 %417, i16* %420, align 2
  %421 = add nsw i32 %237, 6
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds i16, i16* %5, i64 %422
  store i16 %417, i16* %423, align 2
  %424 = shl nuw nsw i32 %160, 1
  %425 = add nuw nsw i32 %159, 2
  %426 = add nuw nsw i32 %425, %424
  %427 = add nuw nsw i32 %426, %161
  %428 = lshr i32 %427, 2
  %429 = trunc i32 %428 to i16
  %430 = add nsw i32 %223, 7
  %431 = sext i32 %430 to i64
  %432 = getelementptr inbounds i16, i16* %5, i64 %431
  store i16 %429, i16* %432, align 2
  %433 = add nsw i32 %254, 6
  %434 = sext i32 %433 to i64
  %435 = getelementptr inbounds i16, i16* %5, i64 %434
  store i16 %429, i16* %435, align 2
  %436 = add nuw nsw i32 %160, 1
  %437 = add nuw nsw i32 %436, %161
  %438 = lshr i32 %437, 1
  %439 = trunc i32 %438 to i16
  %440 = add nsw i32 %237, 7
  %441 = sext i32 %440 to i64
  %442 = getelementptr inbounds i16, i16* %5, i64 %441
  store i16 %439, i16* %442, align 2
  %443 = shl nuw nsw i32 %161, 1
  %444 = add nuw nsw i32 %160, 2
  %445 = add nuw nsw i32 %444, %443
  %446 = add nuw nsw i32 %445, %162
  %447 = lshr i32 %446, 2
  %448 = trunc i32 %447 to i16
  %449 = add nsw i32 %254, 7
  %450 = sext i32 %449 to i64
  %451 = getelementptr inbounds i16, i16* %5, i64 %450
  store i16 %448, i16* %451, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_up_9_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  br i1 %8, label %14, label %9

9:                                                ; preds = %4
  %10 = shl i64 %6, 32
  %11 = ashr exact i64 %10, 32
  %12 = xor i64 %11, -1
  %13 = getelementptr inbounds i16, i16* %5, i64 %12
  br label %19

14:                                               ; preds = %4
  %15 = getelementptr inbounds i8, i8* %0, i64 -2
  %16 = bitcast i8* %15 to i16*
  %17 = shl i64 %6, 32
  %18 = ashr exact i64 %17, 32
  br label %19

19:                                               ; preds = %14, %9
  %20 = phi i64 [ %18, %14 ], [ %11, %9 ]
  %21 = phi i64 [ %17, %14 ], [ %10, %9 ]
  %22 = phi i16* [ %16, %14 ], [ %13, %9 ]
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i8, i8* %0, i64 -2
  %26 = bitcast i8* %25 to i16*
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = shl nuw nsw i32 %28, 1
  %30 = add i64 %21, -4294967296
  %31 = ashr exact i64 %30, 32
  %32 = getelementptr inbounds i16, i16* %5, i64 %31
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = add nuw nsw i32 %34, 2
  %36 = add nuw nsw i32 %35, %24
  %37 = add nuw nsw i32 %36, %29
  %38 = lshr i32 %37, 2
  %39 = shl nuw nsw i32 %34, 1
  %40 = trunc i64 %3 to i32
  %41 = and i32 %40, -2
  %42 = add nsw i32 %41, -1
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i16, i16* %5, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %28
  %49 = add nuw nsw i32 %48, %39
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = mul nsw i32 %7, 3
  %53 = add nsw i32 %52, -1
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i16, i16* %5, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i32
  %58 = add nuw nsw i32 %35, %51
  %59 = add nuw nsw i32 %58, %57
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %57, 1
  %62 = shl i64 %6, 34
  %63 = add i64 %62, -4294967296
  %64 = ashr exact i64 %63, 32
  %65 = getelementptr inbounds i16, i16* %5, i64 %64
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = add nuw nsw i32 %47, %61
  %69 = add nuw nsw i32 %68, %67
  %70 = lshr i32 %69, 2
  %71 = shl nuw nsw i32 %67, 1
  %72 = mul nsw i32 %7, 5
  %73 = add nsw i32 %72, -1
  %74 = sext i32 %73 to i64
  %75 = getelementptr inbounds i16, i16* %5, i64 %74
  %76 = load i16, i16* %75, align 2
  %77 = zext i16 %76 to i32
  %78 = add nuw nsw i32 %57, 2
  %79 = add nuw nsw i32 %78, %71
  %80 = add nuw nsw i32 %79, %77
  %81 = lshr i32 %80, 2
  %82 = shl nuw nsw i32 %77, 1
  %83 = mul nsw i32 %7, 6
  %84 = add nsw i32 %83, -1
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i16, i16* %5, i64 %85
  %87 = load i16, i16* %86, align 2
  %88 = zext i16 %87 to i32
  %89 = add nuw nsw i32 %67, 2
  %90 = add nuw nsw i32 %89, %82
  %91 = add nuw nsw i32 %90, %88
  %92 = lshr i32 %91, 2
  %93 = shl nuw nsw i32 %88, 1
  %94 = mul nsw i32 %7, 7
  %95 = add nsw i32 %94, -1
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %5, i64 %96
  %98 = load i16, i16* %97, align 2
  %99 = zext i16 %98 to i32
  %100 = add nuw nsw i32 %77, 2
  %101 = add nuw nsw i32 %100, %93
  %102 = add nuw nsw i32 %101, %99
  %103 = lshr i32 %102, 2
  %104 = mul nuw nsw i32 %99, 3
  %105 = add nuw nsw i32 %88, 2
  %106 = add nuw nsw i32 %105, %104
  %107 = lshr i32 %106, 2
  %108 = add nuw nsw i32 %50, 1
  %109 = add nuw nsw i32 %108, %38
  %110 = lshr i32 %109, 1
  %111 = trunc i32 %110 to i16
  store i16 %111, i16* %5, align 2
  %112 = shl nuw nsw i32 %50, 1
  %113 = add nuw nsw i32 %60, 2
  %114 = add nuw nsw i32 %113, %38
  %115 = add nuw nsw i32 %114, %112
  %116 = lshr i32 %115, 2
  %117 = trunc i32 %116 to i16
  %118 = getelementptr inbounds i8, i8* %0, i64 2
  %119 = bitcast i8* %118 to i16*
  store i16 %117, i16* %119, align 2
  %120 = add nuw nsw i32 %108, %60
  %121 = lshr i32 %120, 1
  %122 = trunc i32 %121 to i16
  %123 = getelementptr inbounds i8, i8* %0, i64 4
  %124 = bitcast i8* %123 to i16*
  store i16 %122, i16* %124, align 2
  %125 = getelementptr inbounds i16, i16* %5, i64 %20
  store i16 %122, i16* %125, align 2
  %126 = shl nuw nsw i32 %60, 1
  %127 = add nuw nsw i32 %70, 2
  %128 = add nuw nsw i32 %127, %50
  %129 = add nuw nsw i32 %128, %126
  %130 = lshr i32 %129, 2
  %131 = trunc i32 %130 to i16
  %132 = getelementptr inbounds i8, i8* %0, i64 6
  %133 = bitcast i8* %132 to i16*
  store i16 %131, i16* %133, align 2
  %134 = add i64 %21, 4294967296
  %135 = ashr exact i64 %134, 32
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  store i16 %131, i16* %136, align 2
  %137 = add nuw nsw i32 %60, 1
  %138 = add nuw nsw i32 %137, %70
  %139 = lshr i32 %138, 1
  %140 = trunc i32 %139 to i16
  %141 = getelementptr inbounds i8, i8* %0, i64 8
  %142 = bitcast i8* %141 to i16*
  store i16 %140, i16* %142, align 2
  %143 = add i64 %21, 8589934592
  %144 = ashr exact i64 %143, 32
  %145 = getelementptr inbounds i16, i16* %5, i64 %144
  store i16 %140, i16* %145, align 2
  %146 = sext i32 %41 to i64
  %147 = getelementptr inbounds i16, i16* %5, i64 %146
  store i16 %140, i16* %147, align 2
  %148 = shl nuw nsw i32 %70, 1
  %149 = add nuw nsw i32 %113, %148
  %150 = add nuw nsw i32 %149, %81
  %151 = lshr i32 %150, 2
  %152 = trunc i32 %151 to i16
  %153 = getelementptr inbounds i8, i8* %0, i64 10
  %154 = bitcast i8* %153 to i16*
  store i16 %152, i16* %154, align 2
  %155 = add i64 %21, 12884901888
  %156 = ashr exact i64 %155, 32
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  store i16 %152, i16* %157, align 2
  %158 = shl i64 %3, 32
  %159 = ashr exact i64 %158, 32
  %160 = or i64 %159, 1
  %161 = getelementptr inbounds i16, i16* %5, i64 %160
  store i16 %152, i16* %161, align 2
  %162 = add nuw nsw i32 %70, 1
  %163 = add nuw nsw i32 %162, %81
  %164 = lshr i32 %163, 1
  %165 = trunc i32 %164 to i16
  %166 = getelementptr inbounds i8, i8* %0, i64 12
  %167 = bitcast i8* %166 to i16*
  store i16 %165, i16* %167, align 2
  %168 = add i64 %21, 17179869184
  %169 = ashr exact i64 %168, 32
  %170 = getelementptr inbounds i16, i16* %5, i64 %169
  store i16 %165, i16* %170, align 2
  %171 = add nsw i32 %41, 2
  %172 = sext i32 %171 to i64
  %173 = getelementptr inbounds i16, i16* %5, i64 %172
  store i16 %165, i16* %173, align 2
  %174 = sext i32 %52 to i64
  %175 = getelementptr inbounds i16, i16* %5, i64 %174
  store i16 %165, i16* %175, align 2
  %176 = shl nuw nsw i32 %81, 1
  %177 = add nuw nsw i32 %127, %176
  %178 = add nuw nsw i32 %177, %92
  %179 = lshr i32 %178, 2
  %180 = trunc i32 %179 to i16
  %181 = getelementptr inbounds i8, i8* %0, i64 14
  %182 = bitcast i8* %181 to i16*
  store i16 %180, i16* %182, align 2
  %183 = add i64 %21, 21474836480
  %184 = ashr exact i64 %183, 32
  %185 = getelementptr inbounds i16, i16* %5, i64 %184
  store i16 %180, i16* %185, align 2
  %186 = add nsw i32 %41, 3
  %187 = sext i32 %186 to i64
  %188 = getelementptr inbounds i16, i16* %5, i64 %187
  store i16 %180, i16* %188, align 2
  %189 = add nsw i32 %52, 1
  %190 = sext i32 %189 to i64
  %191 = getelementptr inbounds i16, i16* %5, i64 %190
  store i16 %180, i16* %191, align 2
  %192 = add nuw nsw i32 %81, 1
  %193 = add nuw nsw i32 %192, %92
  %194 = lshr i32 %193, 1
  %195 = trunc i32 %194 to i16
  %196 = add i64 %21, 25769803776
  %197 = ashr exact i64 %196, 32
  %198 = getelementptr inbounds i16, i16* %5, i64 %197
  store i16 %195, i16* %198, align 2
  %199 = add nsw i32 %41, 4
  %200 = sext i32 %199 to i64
  %201 = getelementptr inbounds i16, i16* %5, i64 %200
  store i16 %195, i16* %201, align 2
  %202 = add nsw i32 %52, 2
  %203 = sext i32 %202 to i64
  %204 = getelementptr inbounds i16, i16* %5, i64 %203
  store i16 %195, i16* %204, align 2
  %205 = ashr exact i64 %62, 32
  %206 = getelementptr inbounds i16, i16* %5, i64 %205
  store i16 %195, i16* %206, align 2
  %207 = shl nuw nsw i32 %92, 1
  %208 = add nuw nsw i32 %81, 2
  %209 = add nuw nsw i32 %208, %207
  %210 = add nuw nsw i32 %209, %103
  %211 = lshr i32 %210, 2
  %212 = trunc i32 %211 to i16
  %213 = add i64 %21, 30064771072
  %214 = ashr exact i64 %213, 32
  %215 = getelementptr inbounds i16, i16* %5, i64 %214
  store i16 %212, i16* %215, align 2
  %216 = add nsw i32 %41, 5
  %217 = sext i32 %216 to i64
  %218 = getelementptr inbounds i16, i16* %5, i64 %217
  store i16 %212, i16* %218, align 2
  %219 = add nsw i32 %52, 3
  %220 = sext i32 %219 to i64
  %221 = getelementptr inbounds i16, i16* %5, i64 %220
  store i16 %212, i16* %221, align 2
  %222 = or i64 %205, 1
  %223 = getelementptr inbounds i16, i16* %5, i64 %222
  store i16 %212, i16* %223, align 2
  %224 = add nuw nsw i32 %92, 1
  %225 = add nuw nsw i32 %224, %103
  %226 = lshr i32 %225, 1
  %227 = trunc i32 %226 to i16
  %228 = add nsw i32 %41, 6
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds i16, i16* %5, i64 %229
  store i16 %227, i16* %230, align 2
  %231 = add nsw i32 %52, 4
  %232 = sext i32 %231 to i64
  %233 = getelementptr inbounds i16, i16* %5, i64 %232
  store i16 %227, i16* %233, align 2
  %234 = or i64 %205, 2
  %235 = getelementptr inbounds i16, i16* %5, i64 %234
  store i16 %227, i16* %235, align 2
  %236 = sext i32 %72 to i64
  %237 = getelementptr inbounds i16, i16* %5, i64 %236
  store i16 %227, i16* %237, align 2
  %238 = shl nuw nsw i32 %103, 1
  %239 = add nuw nsw i32 %92, 2
  %240 = add nuw nsw i32 %239, %107
  %241 = add nuw nsw i32 %240, %238
  %242 = lshr i32 %241, 2
  %243 = trunc i32 %242 to i16
  %244 = add nsw i32 %41, 7
  %245 = sext i32 %244 to i64
  %246 = getelementptr inbounds i16, i16* %5, i64 %245
  store i16 %243, i16* %246, align 2
  %247 = add nsw i32 %52, 5
  %248 = sext i32 %247 to i64
  %249 = getelementptr inbounds i16, i16* %5, i64 %248
  store i16 %243, i16* %249, align 2
  %250 = or i64 %205, 3
  %251 = getelementptr inbounds i16, i16* %5, i64 %250
  store i16 %243, i16* %251, align 2
  %252 = add nsw i32 %72, 1
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i16, i16* %5, i64 %253
  store i16 %243, i16* %254, align 2
  %255 = add nuw nsw i32 %103, 1
  %256 = add nuw nsw i32 %255, %107
  %257 = lshr i32 %256, 1
  %258 = trunc i32 %257 to i16
  %259 = add nsw i32 %52, 6
  %260 = sext i32 %259 to i64
  %261 = getelementptr inbounds i16, i16* %5, i64 %260
  store i16 %258, i16* %261, align 2
  %262 = add i64 %62, 17179869184
  %263 = ashr exact i64 %262, 32
  %264 = getelementptr inbounds i16, i16* %5, i64 %263
  store i16 %258, i16* %264, align 2
  %265 = add nsw i32 %72, 2
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds i16, i16* %5, i64 %266
  store i16 %258, i16* %267, align 2
  %268 = sext i32 %83 to i64
  %269 = getelementptr inbounds i16, i16* %5, i64 %268
  store i16 %258, i16* %269, align 2
  %270 = mul nuw nsw i32 %107, 3
  %271 = add nuw nsw i32 %103, 2
  %272 = add nuw nsw i32 %271, %270
  %273 = lshr i32 %272, 2
  %274 = trunc i32 %273 to i16
  %275 = add nsw i32 %52, 7
  %276 = sext i32 %275 to i64
  %277 = getelementptr inbounds i16, i16* %5, i64 %276
  store i16 %274, i16* %277, align 2
  %278 = add i64 %62, 21474836480
  %279 = ashr exact i64 %278, 32
  %280 = getelementptr inbounds i16, i16* %5, i64 %279
  store i16 %274, i16* %280, align 2
  %281 = add nsw i32 %72, 3
  %282 = sext i32 %281 to i64
  %283 = getelementptr inbounds i16, i16* %5, i64 %282
  store i16 %274, i16* %283, align 2
  %284 = or i32 %83, 1
  %285 = sext i32 %284 to i64
  %286 = getelementptr inbounds i16, i16* %5, i64 %285
  store i16 %274, i16* %286, align 2
  %287 = trunc i32 %107 to i16
  %288 = add nsw i32 %94, 7
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds i16, i16* %5, i64 %289
  store i16 %287, i16* %290, align 2
  %291 = add nsw i32 %83, 7
  %292 = sext i32 %291 to i64
  %293 = getelementptr inbounds i16, i16* %5, i64 %292
  store i16 %287, i16* %293, align 2
  %294 = add nsw i32 %72, 7
  %295 = sext i32 %294 to i64
  %296 = getelementptr inbounds i16, i16* %5, i64 %295
  store i16 %287, i16* %296, align 2
  %297 = add i64 %62, 30064771072
  %298 = ashr exact i64 %297, 32
  %299 = getelementptr inbounds i16, i16* %5, i64 %298
  store i16 %287, i16* %299, align 2
  %300 = add nsw i32 %94, 6
  %301 = sext i32 %300 to i64
  %302 = getelementptr inbounds i16, i16* %5, i64 %301
  store i16 %287, i16* %302, align 2
  %303 = add nsw i32 %83, 6
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds i16, i16* %5, i64 %304
  store i16 %287, i16* %305, align 2
  %306 = add nsw i32 %72, 6
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i16, i16* %5, i64 %307
  store i16 %287, i16* %308, align 2
  %309 = add i64 %62, 25769803776
  %310 = ashr exact i64 %309, 32
  %311 = getelementptr inbounds i16, i16* %5, i64 %310
  store i16 %287, i16* %311, align 2
  %312 = add nsw i32 %94, 5
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds i16, i16* %5, i64 %313
  store i16 %287, i16* %314, align 2
  %315 = add nsw i32 %83, 5
  %316 = sext i32 %315 to i64
  %317 = getelementptr inbounds i16, i16* %5, i64 %316
  store i16 %287, i16* %317, align 2
  %318 = add nsw i32 %72, 5
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %287, i16* %320, align 2
  %321 = add nsw i32 %94, 4
  %322 = sext i32 %321 to i64
  %323 = getelementptr inbounds i16, i16* %5, i64 %322
  store i16 %287, i16* %323, align 2
  %324 = add nsw i32 %83, 4
  %325 = sext i32 %324 to i64
  %326 = getelementptr inbounds i16, i16* %5, i64 %325
  store i16 %287, i16* %326, align 2
  %327 = add nsw i32 %72, 4
  %328 = sext i32 %327 to i64
  %329 = getelementptr inbounds i16, i16* %5, i64 %328
  store i16 %287, i16* %329, align 2
  %330 = add nsw i32 %94, 3
  %331 = sext i32 %330 to i64
  %332 = getelementptr inbounds i16, i16* %5, i64 %331
  store i16 %287, i16* %332, align 2
  %333 = add nsw i32 %83, 3
  %334 = sext i32 %333 to i64
  %335 = getelementptr inbounds i16, i16* %5, i64 %334
  store i16 %287, i16* %335, align 2
  %336 = add nsw i32 %94, 2
  %337 = sext i32 %336 to i64
  %338 = getelementptr inbounds i16, i16* %5, i64 %337
  store i16 %287, i16* %338, align 2
  %339 = add nsw i32 %83, 2
  %340 = sext i32 %339 to i64
  %341 = getelementptr inbounds i16, i16* %5, i64 %340
  store i16 %287, i16* %341, align 2
  %342 = add nsw i32 %94, 1
  %343 = sext i32 %342 to i64
  %344 = getelementptr inbounds i16, i16* %5, i64 %343
  store i16 %287, i16* %344, align 2
  %345 = sext i32 %94 to i64
  %346 = getelementptr inbounds i16, i16* %5, i64 %345
  store i16 %287, i16* %346, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_left_dc_9_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = icmp eq i32 %1, 0
  br i1 %7, label %13, label %8

8:                                                ; preds = %4
  %9 = shl i64 %6, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = getelementptr inbounds i16, i16* %5, i64 %11
  br label %18

13:                                               ; preds = %4
  %14 = getelementptr inbounds i8, i8* %0, i64 -2
  %15 = bitcast i8* %14 to i16*
  %16 = shl i64 %6, 32
  %17 = ashr exact i64 %16, 32
  br label %18

18:                                               ; preds = %13, %8
  %19 = phi i64 [ %17, %13 ], [ %10, %8 ]
  %20 = phi i64 [ %16, %13 ], [ %9, %8 ]
  %21 = phi i16* [ %15, %13 ], [ %12, %8 ]
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = getelementptr inbounds i8, i8* %0, i64 -2
  %25 = bitcast i8* %24 to i16*
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = add i64 %20, -4294967296
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %23
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = shl i64 %3, 32
  %40 = and i64 %39, -8589934592
  %41 = add i64 %40, -4294967296
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds i16, i16* %5, i64 %42
  %44 = load i16, i16* %43, align 2
  %45 = zext i16 %44 to i32
  %46 = add nuw nsw i32 %45, 2
  %47 = add nuw nsw i32 %46, %27
  %48 = add nuw nsw i32 %47, %38
  %49 = lshr i32 %48, 2
  %50 = shl nuw nsw i32 %45, 1
  %51 = mul i64 %6, 12884901888
  %52 = add i64 %51, -4294967296
  %53 = ashr exact i64 %52, 32
  %54 = getelementptr inbounds i16, i16* %5, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i32
  %57 = add nuw nsw i32 %34, %50
  %58 = add nuw nsw i32 %57, %56
  %59 = lshr i32 %58, 2
  %60 = shl nuw nsw i32 %56, 1
  %61 = shl i64 %6, 34
  %62 = add i64 %61, -4294967296
  %63 = ashr exact i64 %62, 32
  %64 = getelementptr inbounds i16, i16* %5, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i32
  %67 = add nuw nsw i32 %46, %60
  %68 = add nuw nsw i32 %67, %66
  %69 = lshr i32 %68, 2
  %70 = shl nuw nsw i32 %66, 1
  %71 = mul i64 %6, 21474836480
  %72 = add i64 %71, -4294967296
  %73 = ashr exact i64 %72, 32
  %74 = getelementptr inbounds i16, i16* %5, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i32
  %77 = add nuw nsw i32 %56, 2
  %78 = add nuw nsw i32 %77, %70
  %79 = add nuw nsw i32 %78, %76
  %80 = lshr i32 %79, 2
  %81 = shl nuw nsw i32 %76, 1
  %82 = mul i64 %6, 25769803776
  %83 = add i64 %82, -4294967296
  %84 = ashr exact i64 %83, 32
  %85 = getelementptr inbounds i16, i16* %5, i64 %84
  %86 = load i16, i16* %85, align 2
  %87 = zext i16 %86 to i32
  %88 = add nuw nsw i32 %66, 2
  %89 = add nuw nsw i32 %88, %81
  %90 = add nuw nsw i32 %89, %87
  %91 = lshr i32 %90, 2
  %92 = shl nuw nsw i32 %87, 1
  %93 = mul i64 %6, 30064771072
  %94 = add i64 %93, -4294967296
  %95 = ashr exact i64 %94, 32
  %96 = getelementptr inbounds i16, i16* %5, i64 %95
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i32
  %99 = add nuw nsw i32 %76, 2
  %100 = add nuw nsw i32 %99, %92
  %101 = add nuw nsw i32 %100, %98
  %102 = lshr i32 %101, 2
  %103 = mul nuw nsw i32 %98, 3
  %104 = add nuw nsw i32 %87, 2
  %105 = add nuw nsw i32 %104, %103
  %106 = lshr i32 %105, 2
  %107 = add nuw nsw i32 %37, 4
  %108 = add nuw nsw i32 %107, %49
  %109 = add nuw nsw i32 %108, %59
  %110 = add nuw nsw i32 %109, %69
  %111 = add nuw nsw i32 %110, %80
  %112 = add nuw nsw i32 %111, %91
  %113 = add nuw nsw i32 %112, %106
  %114 = add nuw nsw i32 %113, %102
  %115 = ashr i32 %114, 3
  %116 = sext i32 %115 to i64
  %117 = mul i64 %116, 281479271743489
  %118 = bitcast i8* %0 to i64*
  store i64 %117, i64* %118, align 8
  %119 = getelementptr inbounds i8, i8* %0, i64 8
  %120 = bitcast i8* %119 to i64*
  store i64 %117, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %5, i64 %19
  %122 = bitcast i16* %121 to i64*
  store i64 %117, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %121, i64 4
  %124 = bitcast i16* %123 to i64*
  store i64 %117, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %121, i64 %19
  %126 = bitcast i16* %125 to i64*
  store i64 %117, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %125, i64 4
  %128 = bitcast i16* %127 to i64*
  store i64 %117, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %125, i64 %19
  %130 = bitcast i16* %129 to i64*
  store i64 %117, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %129, i64 4
  %132 = bitcast i16* %131 to i64*
  store i64 %117, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %129, i64 %19
  %134 = bitcast i16* %133 to i64*
  store i64 %117, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %133, i64 4
  %136 = bitcast i16* %135 to i64*
  store i64 %117, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %133, i64 %19
  %138 = bitcast i16* %137 to i64*
  store i64 %117, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %137, i64 4
  %140 = bitcast i16* %139 to i64*
  store i64 %117, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %137, i64 %19
  %142 = bitcast i16* %141 to i64*
  store i64 %117, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %117, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %141, i64 %19
  %146 = bitcast i16* %145 to i64*
  store i64 %117, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %145, i64 4
  %148 = bitcast i16* %147 to i64*
  store i64 %117, i64* %148, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_top_dc_9_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %103, label %97

97:                                               ; preds = %18
  %98 = sub i64 34359738368, %19
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i16, i16* %5, i64 %99
  %101 = load i16, i16* %100, align 2
  %102 = zext i16 %101 to i32
  br label %103

103:                                              ; preds = %18, %97
  %104 = phi i32 [ %102, %97 ], [ %91, %18 ]
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %81, 2
  %107 = add nuw nsw i32 %106, %105
  %108 = add nuw nsw i32 %107, %104
  %109 = lshr i32 %108, 2
  %110 = add nuw nsw i32 %37, 4
  %111 = add nuw nsw i32 %110, %47
  %112 = add nuw nsw i32 %111, %56
  %113 = add nuw nsw i32 %112, %65
  %114 = add nuw nsw i32 %113, %75
  %115 = add nuw nsw i32 %114, %85
  %116 = add nuw nsw i32 %115, %95
  %117 = add nuw nsw i32 %116, %109
  %118 = ashr i32 %117, 3
  %119 = sext i32 %118 to i64
  %120 = mul i64 %119, 281479271743489
  %121 = ashr exact i64 %19, 32
  %122 = bitcast i8* %0 to i64*
  store i64 %120, i64* %122, align 8
  %123 = getelementptr inbounds i8, i8* %0, i64 8
  %124 = bitcast i8* %123 to i64*
  store i64 %120, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %5, i64 %121
  %126 = bitcast i16* %125 to i64*
  store i64 %120, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %125, i64 4
  %128 = bitcast i16* %127 to i64*
  store i64 %120, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %125, i64 %121
  %130 = bitcast i16* %129 to i64*
  store i64 %120, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %129, i64 4
  %132 = bitcast i16* %131 to i64*
  store i64 %120, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %129, i64 %121
  %134 = bitcast i16* %133 to i64*
  store i64 %120, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %133, i64 4
  %136 = bitcast i16* %135 to i64*
  store i64 %120, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %133, i64 %121
  %138 = bitcast i16* %137 to i64*
  store i64 %120, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %137, i64 4
  %140 = bitcast i16* %139 to i64*
  store i64 %120, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %137, i64 %121
  %142 = bitcast i16* %141 to i64*
  store i64 %120, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %120, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %141, i64 %121
  %146 = bitcast i16* %145 to i64*
  store i64 %120, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %145, i64 4
  %148 = bitcast i16* %147 to i64*
  store i64 %120, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %145, i64 %121
  %150 = bitcast i16* %149 to i64*
  store i64 %120, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %149, i64 4
  %152 = bitcast i16* %151 to i64*
  store i64 %120, i64* %152, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8l_128_dc_9_c(i8* nocapture, i32, i32, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = shl i64 %3, 31
  %7 = ashr i64 %6, 32
  %8 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %8, align 8
  %9 = getelementptr inbounds i16, i16* %5, i64 %7
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %10, align 8
  %11 = getelementptr inbounds i16, i16* %9, i64 %7
  %12 = bitcast i16* %11 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %12, align 8
  %13 = getelementptr inbounds i16, i16* %11, i64 %7
  %14 = bitcast i16* %13 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %14, align 8
  %15 = getelementptr inbounds i16, i16* %13, i64 %7
  %16 = bitcast i16* %15 to i64*
  store i64 72058693566333184, i64* %16, align 8
  %17 = getelementptr inbounds i16, i16* %15, i64 4
  %18 = bitcast i16* %17 to i64*
  store i64 72058693566333184, i64* %18, align 8
  %19 = getelementptr inbounds i16, i16* %15, i64 %7
  %20 = bitcast i16* %19 to i64*
  store i64 72058693566333184, i64* %20, align 8
  %21 = getelementptr inbounds i16, i16* %19, i64 4
  %22 = bitcast i16* %21 to i64*
  store i64 72058693566333184, i64* %22, align 8
  %23 = getelementptr inbounds i16, i16* %19, i64 %7
  %24 = bitcast i16* %23 to i64*
  store i64 72058693566333184, i64* %24, align 8
  %25 = getelementptr inbounds i16, i16* %23, i64 4
  %26 = bitcast i16* %25 to i64*
  store i64 72058693566333184, i64* %26, align 8
  %27 = getelementptr inbounds i16, i16* %23, i64 %7
  %28 = bitcast i16* %27 to i64*
  store i64 72058693566333184, i64* %28, align 8
  %29 = getelementptr inbounds i16, i16* %27, i64 4
  %30 = bitcast i16* %29 to i64*
  store i64 72058693566333184, i64* %30, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_vertical_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds i16, i16* %8, i64 4
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = shl i64 %4, 32
  %15 = ashr exact i64 %14, 32
  %16 = bitcast i8* %0 to i64*
  store i64 %10, i64* %16, align 8
  %17 = getelementptr inbounds i8, i8* %0, i64 8
  %18 = bitcast i8* %17 to i64*
  store i64 %13, i64* %18, align 8
  %19 = getelementptr inbounds i16, i16* %3, i64 %15
  %20 = bitcast i16* %19 to i64*
  store i64 %10, i64* %20, align 8
  %21 = getelementptr inbounds i16, i16* %19, i64 4
  %22 = bitcast i16* %21 to i64*
  store i64 %13, i64* %22, align 8
  %23 = ashr exact i64 %14, 31
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to i64*
  store i64 %10, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %24, i64 4
  %27 = bitcast i16* %26 to i64*
  store i64 %13, i64* %27, align 8
  %28 = mul nsw i64 %15, 3
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = bitcast i16* %29 to i64*
  store i64 %10, i64* %30, align 8
  %31 = getelementptr inbounds i16, i16* %29, i64 4
  %32 = bitcast i16* %31 to i64*
  store i64 %13, i64* %32, align 8
  %33 = ashr exact i64 %14, 30
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %10, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %34, i64 4
  %37 = bitcast i16* %36 to i64*
  store i64 %13, i64* %37, align 8
  %38 = mul nsw i64 %15, 5
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %10, i64* %40, align 8
  %41 = getelementptr inbounds i16, i16* %39, i64 4
  %42 = bitcast i16* %41 to i64*
  store i64 %13, i64* %42, align 8
  %43 = mul nsw i64 %15, 6
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %10, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 %13, i64* %47, align 8
  %48 = mul nsw i64 %15, 7
  %49 = getelementptr inbounds i16, i16* %3, i64 %48
  %50 = bitcast i16* %49 to i64*
  store i64 %10, i64* %50, align 8
  %51 = getelementptr inbounds i16, i16* %49, i64 4
  %52 = bitcast i16* %51 to i64*
  store i64 %13, i64* %52, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_horizontal_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = mul nuw i64 %8, 281479271743489
  %10 = bitcast i8* %0 to i64*
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to i64*
  store i64 %9, i64* %12, align 8
  %13 = add nsw i64 %4, -1
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = mul nuw i64 %16, 281479271743489
  %18 = getelementptr inbounds i16, i16* %3, i64 %4
  %19 = bitcast i16* %18 to i64*
  store i64 %17, i64* %19, align 8
  %20 = getelementptr inbounds i16, i16* %18, i64 4
  %21 = bitcast i16* %20 to i64*
  store i64 %17, i64* %21, align 8
  %22 = and i64 %1, -2
  %23 = add nsw i64 %22, -1
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = mul nuw i64 %26, 281479271743489
  %28 = getelementptr inbounds i16, i16* %3, i64 %22
  %29 = bitcast i16* %28 to i64*
  store i64 %27, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 %27, i64* %31, align 8
  %32 = mul nsw i64 %4, 3
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = mul nuw i64 %36, 281479271743489
  %38 = getelementptr inbounds i16, i16* %3, i64 %32
  %39 = bitcast i16* %38 to i64*
  store i64 %37, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %38, i64 4
  %41 = bitcast i16* %40 to i64*
  store i64 %37, i64* %41, align 8
  %42 = shl nsw i64 %4, 2
  %43 = add nsw i64 %42, -1
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i64
  %47 = mul nuw i64 %46, 281479271743489
  %48 = getelementptr inbounds i16, i16* %3, i64 %42
  %49 = bitcast i16* %48 to i64*
  store i64 %47, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %48, i64 4
  %51 = bitcast i16* %50 to i64*
  store i64 %47, i64* %51, align 8
  %52 = mul nsw i64 %4, 5
  %53 = add nsw i64 %52, -1
  %54 = getelementptr inbounds i16, i16* %3, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i64
  %57 = mul nuw i64 %56, 281479271743489
  %58 = getelementptr inbounds i16, i16* %3, i64 %52
  %59 = bitcast i16* %58 to i64*
  store i64 %57, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %58, i64 4
  %61 = bitcast i16* %60 to i64*
  store i64 %57, i64* %61, align 8
  %62 = mul nsw i64 %4, 6
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = mul nuw i64 %66, 281479271743489
  %68 = getelementptr inbounds i16, i16* %3, i64 %62
  %69 = bitcast i16* %68 to i64*
  store i64 %67, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 %67, i64* %71, align 8
  %72 = mul nsw i64 %4, 7
  %73 = add nsw i64 %72, -1
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i64
  %77 = mul nuw i64 %76, 281479271743489
  %78 = getelementptr inbounds i16, i16* %3, i64 %72
  %79 = bitcast i16* %78 to i64*
  store i64 %77, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %77, i64* %81, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_vertical_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds i16, i16* %8, i64 4
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = shl i64 %4, 32
  %15 = ashr exact i64 %14, 32
  %16 = bitcast i8* %0 to i64*
  store i64 %10, i64* %16, align 8
  %17 = getelementptr inbounds i8, i8* %0, i64 8
  %18 = bitcast i8* %17 to i64*
  store i64 %13, i64* %18, align 8
  %19 = getelementptr inbounds i16, i16* %3, i64 %15
  %20 = bitcast i16* %19 to i64*
  store i64 %10, i64* %20, align 8
  %21 = getelementptr inbounds i16, i16* %19, i64 4
  %22 = bitcast i16* %21 to i64*
  store i64 %13, i64* %22, align 8
  %23 = ashr exact i64 %14, 31
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to i64*
  store i64 %10, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %24, i64 4
  %27 = bitcast i16* %26 to i64*
  store i64 %13, i64* %27, align 8
  %28 = mul nsw i64 %15, 3
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = bitcast i16* %29 to i64*
  store i64 %10, i64* %30, align 8
  %31 = getelementptr inbounds i16, i16* %29, i64 4
  %32 = bitcast i16* %31 to i64*
  store i64 %13, i64* %32, align 8
  %33 = ashr exact i64 %14, 30
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %10, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %34, i64 4
  %37 = bitcast i16* %36 to i64*
  store i64 %13, i64* %37, align 8
  %38 = mul nsw i64 %15, 5
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %10, i64* %40, align 8
  %41 = getelementptr inbounds i16, i16* %39, i64 4
  %42 = bitcast i16* %41 to i64*
  store i64 %13, i64* %42, align 8
  %43 = mul nsw i64 %15, 6
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %10, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 %13, i64* %47, align 8
  %48 = mul nsw i64 %15, 7
  %49 = getelementptr inbounds i16, i16* %3, i64 %48
  %50 = bitcast i16* %49 to i64*
  store i64 %10, i64* %50, align 8
  %51 = getelementptr inbounds i16, i16* %49, i64 4
  %52 = bitcast i16* %51 to i64*
  store i64 %13, i64* %52, align 8
  %53 = ashr exact i64 %14, 29
  %54 = getelementptr inbounds i16, i16* %3, i64 %53
  %55 = bitcast i16* %54 to i64*
  store i64 %10, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %54, i64 4
  %57 = bitcast i16* %56 to i64*
  store i64 %13, i64* %57, align 8
  %58 = mul nsw i64 %15, 9
  %59 = getelementptr inbounds i16, i16* %3, i64 %58
  %60 = bitcast i16* %59 to i64*
  store i64 %10, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %59, i64 4
  %62 = bitcast i16* %61 to i64*
  store i64 %13, i64* %62, align 8
  %63 = mul nsw i64 %15, 10
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = bitcast i16* %64 to i64*
  store i64 %10, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %64, i64 4
  %67 = bitcast i16* %66 to i64*
  store i64 %13, i64* %67, align 8
  %68 = mul nsw i64 %15, 11
  %69 = getelementptr inbounds i16, i16* %3, i64 %68
  %70 = bitcast i16* %69 to i64*
  store i64 %10, i64* %70, align 8
  %71 = getelementptr inbounds i16, i16* %69, i64 4
  %72 = bitcast i16* %71 to i64*
  store i64 %13, i64* %72, align 8
  %73 = mul nsw i64 %15, 12
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = bitcast i16* %74 to i64*
  store i64 %10, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %13, i64* %77, align 8
  %78 = mul nsw i64 %15, 13
  %79 = getelementptr inbounds i16, i16* %3, i64 %78
  %80 = bitcast i16* %79 to i64*
  store i64 %10, i64* %80, align 8
  %81 = getelementptr inbounds i16, i16* %79, i64 4
  %82 = bitcast i16* %81 to i64*
  store i64 %13, i64* %82, align 8
  %83 = mul nsw i64 %15, 14
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = bitcast i16* %84 to i64*
  store i64 %10, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 %13, i64* %87, align 8
  %88 = mul nsw i64 %15, 15
  %89 = getelementptr inbounds i16, i16* %3, i64 %88
  %90 = bitcast i16* %89 to i64*
  store i64 %10, i64* %90, align 8
  %91 = getelementptr inbounds i16, i16* %89, i64 4
  %92 = bitcast i16* %91 to i64*
  store i64 %13, i64* %92, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_horizontal_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = mul nuw i64 %8, 281479271743489
  %10 = bitcast i8* %0 to i64*
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to i64*
  store i64 %9, i64* %12, align 8
  %13 = add nsw i64 %4, -1
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = mul nuw i64 %16, 281479271743489
  %18 = getelementptr inbounds i16, i16* %3, i64 %4
  %19 = bitcast i16* %18 to i64*
  store i64 %17, i64* %19, align 8
  %20 = getelementptr inbounds i16, i16* %18, i64 4
  %21 = bitcast i16* %20 to i64*
  store i64 %17, i64* %21, align 8
  %22 = and i64 %1, -2
  %23 = add nsw i64 %22, -1
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = mul nuw i64 %26, 281479271743489
  %28 = getelementptr inbounds i16, i16* %3, i64 %22
  %29 = bitcast i16* %28 to i64*
  store i64 %27, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 %27, i64* %31, align 8
  %32 = mul nsw i64 %4, 3
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = mul nuw i64 %36, 281479271743489
  %38 = getelementptr inbounds i16, i16* %3, i64 %32
  %39 = bitcast i16* %38 to i64*
  store i64 %37, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %38, i64 4
  %41 = bitcast i16* %40 to i64*
  store i64 %37, i64* %41, align 8
  %42 = shl nsw i64 %4, 2
  %43 = add nsw i64 %42, -1
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i64
  %47 = mul nuw i64 %46, 281479271743489
  %48 = getelementptr inbounds i16, i16* %3, i64 %42
  %49 = bitcast i16* %48 to i64*
  store i64 %47, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %48, i64 4
  %51 = bitcast i16* %50 to i64*
  store i64 %47, i64* %51, align 8
  %52 = mul nsw i64 %4, 5
  %53 = add nsw i64 %52, -1
  %54 = getelementptr inbounds i16, i16* %3, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i64
  %57 = mul nuw i64 %56, 281479271743489
  %58 = getelementptr inbounds i16, i16* %3, i64 %52
  %59 = bitcast i16* %58 to i64*
  store i64 %57, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %58, i64 4
  %61 = bitcast i16* %60 to i64*
  store i64 %57, i64* %61, align 8
  %62 = mul nsw i64 %4, 6
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = mul nuw i64 %66, 281479271743489
  %68 = getelementptr inbounds i16, i16* %3, i64 %62
  %69 = bitcast i16* %68 to i64*
  store i64 %67, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 %67, i64* %71, align 8
  %72 = mul nsw i64 %4, 7
  %73 = add nsw i64 %72, -1
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i64
  %77 = mul nuw i64 %76, 281479271743489
  %78 = getelementptr inbounds i16, i16* %3, i64 %72
  %79 = bitcast i16* %78 to i64*
  store i64 %77, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %77, i64* %81, align 8
  %82 = shl nsw i64 %4, 3
  %83 = add nsw i64 %82, -1
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i64
  %87 = mul nuw i64 %86, 281479271743489
  %88 = getelementptr inbounds i16, i16* %3, i64 %82
  %89 = bitcast i16* %88 to i64*
  store i64 %87, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %88, i64 4
  %91 = bitcast i16* %90 to i64*
  store i64 %87, i64* %91, align 8
  %92 = mul nsw i64 %4, 9
  %93 = add nsw i64 %92, -1
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i64
  %97 = mul nuw i64 %96, 281479271743489
  %98 = getelementptr inbounds i16, i16* %3, i64 %92
  %99 = bitcast i16* %98 to i64*
  store i64 %97, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %98, i64 4
  %101 = bitcast i16* %100 to i64*
  store i64 %97, i64* %101, align 8
  %102 = mul nsw i64 %4, 10
  %103 = add nsw i64 %102, -1
  %104 = getelementptr inbounds i16, i16* %3, i64 %103
  %105 = load i16, i16* %104, align 2
  %106 = zext i16 %105 to i64
  %107 = mul nuw i64 %106, 281479271743489
  %108 = getelementptr inbounds i16, i16* %3, i64 %102
  %109 = bitcast i16* %108 to i64*
  store i64 %107, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 %107, i64* %111, align 8
  %112 = mul nsw i64 %4, 11
  %113 = add nsw i64 %112, -1
  %114 = getelementptr inbounds i16, i16* %3, i64 %113
  %115 = load i16, i16* %114, align 2
  %116 = zext i16 %115 to i64
  %117 = mul nuw i64 %116, 281479271743489
  %118 = getelementptr inbounds i16, i16* %3, i64 %112
  %119 = bitcast i16* %118 to i64*
  store i64 %117, i64* %119, align 8
  %120 = getelementptr inbounds i16, i16* %118, i64 4
  %121 = bitcast i16* %120 to i64*
  store i64 %117, i64* %121, align 8
  %122 = mul nsw i64 %4, 12
  %123 = add nsw i64 %122, -1
  %124 = getelementptr inbounds i16, i16* %3, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i64
  %127 = mul nuw i64 %126, 281479271743489
  %128 = getelementptr inbounds i16, i16* %3, i64 %122
  %129 = bitcast i16* %128 to i64*
  store i64 %127, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %127, i64* %131, align 8
  %132 = mul nsw i64 %4, 13
  %133 = add nsw i64 %132, -1
  %134 = getelementptr inbounds i16, i16* %3, i64 %133
  %135 = load i16, i16* %134, align 2
  %136 = zext i16 %135 to i64
  %137 = mul nuw i64 %136, 281479271743489
  %138 = getelementptr inbounds i16, i16* %3, i64 %132
  %139 = bitcast i16* %138 to i64*
  store i64 %137, i64* %139, align 8
  %140 = getelementptr inbounds i16, i16* %138, i64 4
  %141 = bitcast i16* %140 to i64*
  store i64 %137, i64* %141, align 8
  %142 = mul nsw i64 %4, 14
  %143 = add nsw i64 %142, -1
  %144 = getelementptr inbounds i16, i16* %3, i64 %143
  %145 = load i16, i16* %144, align 2
  %146 = zext i16 %145 to i64
  %147 = mul nuw i64 %146, 281479271743489
  %148 = getelementptr inbounds i16, i16* %3, i64 %142
  %149 = bitcast i16* %148 to i64*
  store i64 %147, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %148, i64 4
  %151 = bitcast i16* %150 to i64*
  store i64 %147, i64* %151, align 8
  %152 = mul nsw i64 %4, 15
  %153 = add nsw i64 %152, -1
  %154 = getelementptr inbounds i16, i16* %3, i64 %153
  %155 = load i16, i16* %154, align 2
  %156 = zext i16 %155 to i64
  %157 = mul nuw i64 %156, 281479271743489
  %158 = getelementptr inbounds i16, i16* %3, i64 %152
  %159 = bitcast i16* %158 to i64*
  store i64 %157, i64* %159, align 8
  %160 = getelementptr inbounds i16, i16* %158, i64 4
  %161 = bitcast i16* %160 to i64*
  store i64 %157, i64* %161, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_plane_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 6
  %6 = bitcast i8* %5 to i16*
  %7 = shl i64 %4, 32
  %8 = ashr exact i64 %7, 32
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i16, i16* %6, i64 %9
  %11 = shl i64 %4, 34
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = getelementptr inbounds i16, i16* %13, i64 -1
  %15 = shl i64 %1, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = sub nsw i64 0, %17
  %19 = getelementptr inbounds i16, i16* %14, i64 %18
  %20 = getelementptr inbounds i16, i16* %10, i64 1
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = getelementptr inbounds i16, i16* %10, i64 -1
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = sub nsw i32 %22, %25
  %27 = load i16, i16* %14, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %19, align 2
  %30 = zext i16 %29 to i32
  %31 = sub nsw i32 %28, %30
  %32 = shl i64 %4, 32
  %33 = ashr exact i64 %32, 32
  %34 = mul nsw i64 %33, 6
  %35 = shl i64 %4, 34
  %36 = ashr exact i64 %35, 31
  %37 = add nsw i64 %34, %36
  %38 = add nsw i64 %37, -2
  %39 = getelementptr i8, i8* %0, i64 %38
  %40 = add nsw i64 %36, -2
  %41 = shl i64 %1, 32
  %42 = ashr exact i64 %41, 32
  %43 = lshr i64 %42, 1
  %44 = shl i64 %43, 2
  %45 = sub i64 %40, %44
  %46 = sub i64 %45, %34
  %47 = getelementptr i8, i8* %0, i64 %46
  %48 = getelementptr inbounds i16, i16* %14, i64 %8
  %49 = getelementptr inbounds i16, i16* %19, i64 %9
  %50 = getelementptr inbounds i16, i16* %10, i64 2
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i32
  %53 = getelementptr inbounds i16, i16* %10, i64 -2
  %54 = load i16, i16* %53, align 2
  %55 = zext i16 %54 to i32
  %56 = sub nsw i32 %52, %55
  %57 = shl nsw i32 %56, 1
  %58 = add nsw i32 %57, %26
  %59 = load i16, i16* %48, align 2
  %60 = zext i16 %59 to i32
  %61 = load i16, i16* %49, align 2
  %62 = zext i16 %61 to i32
  %63 = sub nsw i32 %60, %62
  %64 = shl nsw i32 %63, 1
  %65 = add nsw i32 %64, %31
  %66 = getelementptr inbounds i16, i16* %48, i64 %8
  %67 = getelementptr inbounds i16, i16* %49, i64 %9
  %68 = getelementptr inbounds i16, i16* %10, i64 3
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i32
  %71 = getelementptr inbounds i16, i16* %10, i64 -3
  %72 = load i16, i16* %71, align 2
  %73 = zext i16 %72 to i32
  %74 = sub nsw i32 %70, %73
  %75 = mul nsw i32 %74, 3
  %76 = add nsw i32 %75, %58
  %77 = load i16, i16* %66, align 2
  %78 = zext i16 %77 to i32
  %79 = load i16, i16* %67, align 2
  %80 = zext i16 %79 to i32
  %81 = sub nsw i32 %78, %80
  %82 = mul nsw i32 %81, 3
  %83 = add nsw i32 %82, %65
  %84 = getelementptr inbounds i16, i16* %66, i64 %8
  %85 = getelementptr inbounds i16, i16* %67, i64 %9
  %86 = getelementptr inbounds i16, i16* %10, i64 4
  %87 = load i16, i16* %86, align 2
  %88 = zext i16 %87 to i32
  %89 = getelementptr inbounds i16, i16* %10, i64 -4
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = sub nsw i32 %88, %91
  %93 = shl nsw i32 %92, 2
  %94 = add nsw i32 %93, %76
  %95 = load i16, i16* %84, align 2
  %96 = zext i16 %95 to i32
  %97 = load i16, i16* %85, align 2
  %98 = zext i16 %97 to i32
  %99 = sub nsw i32 %96, %98
  %100 = shl nsw i32 %99, 2
  %101 = add nsw i32 %100, %83
  %102 = bitcast i8* %39 to i16*
  %103 = mul nsw i32 %94, 17
  %104 = add nsw i32 %103, 16
  %105 = ashr i32 %104, 5
  %106 = mul nsw i32 %101, 17
  %107 = add nsw i32 %106, 16
  %108 = ashr i32 %107, 5
  %109 = load i16, i16* %102, align 2
  %110 = zext i16 %109 to i32
  %111 = getelementptr inbounds i8, i8* %47, i64 16
  %112 = bitcast i8* %111 to i16*
  %113 = load i16, i16* %112, align 2
  %114 = zext i16 %113 to i32
  %115 = add nuw nsw i32 %114, %110
  %116 = shl nuw nsw i32 %115, 4
  %117 = add nsw i32 %108, %105
  %118 = mul nsw i32 %117, -3
  %119 = add nsw i32 %118, 16
  %120 = add nsw i32 %119, %116
  %121 = shl nsw i32 %105, 1
  %122 = mul nsw i32 %105, 3
  %123 = shl nsw i32 %105, 2
  %124 = mul nsw i32 %105, 5
  %125 = mul nsw i32 %105, 6
  %126 = mul nsw i32 %105, 7
  br label %127

127:                                              ; preds = %214, %2
  %128 = phi i32 [ 8, %2 ], [ %219, %214 ]
  %129 = phi i16* [ %3, %2 ], [ %218, %214 ]
  %130 = phi i32 [ %120, %2 ], [ %131, %214 ]
  %131 = add nsw i32 %130, %108
  %132 = ashr i32 %130, 5
  %133 = icmp ult i32 %132, 512
  br i1 %133, label %138, label %134

134:                                              ; preds = %127
  %135 = ashr i32 %130, 31
  %136 = or i32 %135, -512
  %137 = xor i32 %136, -1
  br label %138

138:                                              ; preds = %127, %134
  %139 = phi i32 [ %137, %134 ], [ %132, %127 ]
  %140 = trunc i32 %139 to i16
  store i16 %140, i16* %129, align 2
  %141 = add nsw i32 %130, %105
  %142 = ashr i32 %141, 5
  %143 = icmp ult i32 %142, 512
  br i1 %143, label %148, label %144

144:                                              ; preds = %138
  %145 = ashr i32 %141, 31
  %146 = or i32 %145, -512
  %147 = xor i32 %146, -1
  br label %148

148:                                              ; preds = %138, %144
  %149 = phi i32 [ %147, %144 ], [ %142, %138 ]
  %150 = trunc i32 %149 to i16
  %151 = getelementptr inbounds i16, i16* %129, i64 1
  store i16 %150, i16* %151, align 2
  %152 = add nsw i32 %130, %121
  %153 = ashr i32 %152, 5
  %154 = icmp ult i32 %153, 512
  br i1 %154, label %159, label %155

155:                                              ; preds = %148
  %156 = ashr i32 %152, 31
  %157 = or i32 %156, -512
  %158 = xor i32 %157, -1
  br label %159

159:                                              ; preds = %148, %155
  %160 = phi i32 [ %158, %155 ], [ %153, %148 ]
  %161 = trunc i32 %160 to i16
  %162 = getelementptr inbounds i16, i16* %129, i64 2
  store i16 %161, i16* %162, align 2
  %163 = add nsw i32 %130, %122
  %164 = ashr i32 %163, 5
  %165 = icmp ult i32 %164, 512
  br i1 %165, label %170, label %166

166:                                              ; preds = %159
  %167 = ashr i32 %163, 31
  %168 = or i32 %167, -512
  %169 = xor i32 %168, -1
  br label %170

170:                                              ; preds = %159, %166
  %171 = phi i32 [ %169, %166 ], [ %164, %159 ]
  %172 = trunc i32 %171 to i16
  %173 = getelementptr inbounds i16, i16* %129, i64 3
  store i16 %172, i16* %173, align 2
  %174 = add nsw i32 %130, %123
  %175 = ashr i32 %174, 5
  %176 = icmp ult i32 %175, 512
  br i1 %176, label %181, label %177

177:                                              ; preds = %170
  %178 = ashr i32 %174, 31
  %179 = or i32 %178, -512
  %180 = xor i32 %179, -1
  br label %181

181:                                              ; preds = %170, %177
  %182 = phi i32 [ %180, %177 ], [ %175, %170 ]
  %183 = trunc i32 %182 to i16
  %184 = getelementptr inbounds i16, i16* %129, i64 4
  store i16 %183, i16* %184, align 2
  %185 = add nsw i32 %130, %124
  %186 = ashr i32 %185, 5
  %187 = icmp ult i32 %186, 512
  br i1 %187, label %192, label %188

188:                                              ; preds = %181
  %189 = ashr i32 %185, 31
  %190 = or i32 %189, -512
  %191 = xor i32 %190, -1
  br label %192

192:                                              ; preds = %181, %188
  %193 = phi i32 [ %191, %188 ], [ %186, %181 ]
  %194 = trunc i32 %193 to i16
  %195 = getelementptr inbounds i16, i16* %129, i64 5
  store i16 %194, i16* %195, align 2
  %196 = add nsw i32 %130, %125
  %197 = ashr i32 %196, 5
  %198 = icmp ult i32 %197, 512
  br i1 %198, label %203, label %199

199:                                              ; preds = %192
  %200 = ashr i32 %196, 31
  %201 = or i32 %200, -512
  %202 = xor i32 %201, -1
  br label %203

203:                                              ; preds = %192, %199
  %204 = phi i32 [ %202, %199 ], [ %197, %192 ]
  %205 = trunc i32 %204 to i16
  %206 = getelementptr inbounds i16, i16* %129, i64 6
  store i16 %205, i16* %206, align 2
  %207 = add nsw i32 %130, %126
  %208 = ashr i32 %207, 5
  %209 = icmp ult i32 %208, 512
  br i1 %209, label %214, label %210

210:                                              ; preds = %203
  %211 = ashr i32 %207, 31
  %212 = or i32 %211, -512
  %213 = xor i32 %212, -1
  br label %214

214:                                              ; preds = %203, %210
  %215 = phi i32 [ %213, %210 ], [ %208, %203 ]
  %216 = trunc i32 %215 to i16
  %217 = getelementptr inbounds i16, i16* %129, i64 7
  store i16 %216, i16* %217, align 2
  %218 = getelementptr inbounds i16, i16* %129, i64 %8
  %219 = add nsw i32 %128, -1
  %220 = icmp eq i32 %219, 0
  br i1 %220, label %221, label %127

221:                                              ; preds = %214
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_plane_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 6
  %6 = bitcast i8* %5 to i16*
  %7 = shl i64 %4, 32
  %8 = ashr exact i64 %7, 32
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i16, i16* %6, i64 %9
  %11 = shl i64 %4, 35
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = getelementptr inbounds i16, i16* %13, i64 -1
  %15 = shl i64 %1, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = sub nsw i64 0, %17
  %19 = getelementptr inbounds i16, i16* %14, i64 %18
  %20 = getelementptr inbounds i16, i16* %10, i64 1
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = getelementptr inbounds i16, i16* %10, i64 -1
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = sub nsw i32 %22, %25
  %27 = shl i64 %4, 35
  %28 = ashr exact i64 %27, 31
  %29 = add nsw i64 %28, -2
  %30 = shl i64 %1, 32
  %31 = ashr exact i64 %30, 32
  %32 = lshr i64 %31, 1
  %33 = shl i64 %32, 2
  %34 = sub i64 %29, %33
  %35 = shl i64 %4, 32
  %36 = ashr exact i64 %35, 32
  %37 = mul nsw i64 %36, 6
  %38 = add nsw i64 %37, %28
  %39 = add nsw i64 %38, -2
  %40 = getelementptr i8, i8* %0, i64 %39
  %41 = sub i64 %34, %37
  %42 = getelementptr i8, i8* %0, i64 %41
  %43 = getelementptr inbounds i16, i16* %14, i64 %8
  %44 = getelementptr inbounds i16, i16* %19, i64 %9
  %45 = getelementptr inbounds i16, i16* %10, i64 2
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i32
  %48 = getelementptr inbounds i16, i16* %10, i64 -2
  %49 = load i16, i16* %48, align 2
  %50 = zext i16 %49 to i32
  %51 = sub nsw i32 %47, %50
  %52 = shl nsw i32 %51, 1
  %53 = add nsw i32 %52, %26
  %54 = getelementptr inbounds i16, i16* %43, i64 %8
  %55 = getelementptr inbounds i16, i16* %44, i64 %9
  %56 = getelementptr inbounds i16, i16* %10, i64 3
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = getelementptr inbounds i16, i16* %10, i64 -3
  %60 = load i16, i16* %59, align 2
  %61 = zext i16 %60 to i32
  %62 = sub nsw i32 %58, %61
  %63 = mul nsw i32 %62, 3
  %64 = add nsw i32 %63, %53
  %65 = getelementptr inbounds i16, i16* %10, i64 4
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = getelementptr inbounds i16, i16* %10, i64 -4
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i32
  %71 = sub nsw i32 %67, %70
  %72 = shl nsw i32 %71, 2
  %73 = add nsw i32 %72, %64
  %74 = bitcast i8* %40 to i16*
  %75 = bitcast i8* %42 to i16*
  %76 = getelementptr inbounds i16, i16* %54, i64 %8
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i32
  %79 = getelementptr inbounds i16, i16* %55, i64 %9
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = sub nsw i32 %78, %81
  %83 = shl nsw i32 %82, 2
  %84 = load i16, i16* %54, align 2
  %85 = zext i16 %84 to i32
  %86 = load i16, i16* %55, align 2
  %87 = zext i16 %86 to i32
  %88 = sub nsw i32 %85, %87
  %89 = mul nsw i32 %88, 3
  %90 = load i16, i16* %43, align 2
  %91 = zext i16 %90 to i32
  %92 = load i16, i16* %44, align 2
  %93 = zext i16 %92 to i32
  %94 = sub nsw i32 %91, %93
  %95 = shl nsw i32 %94, 1
  %96 = load i16, i16* %14, align 2
  %97 = zext i16 %96 to i32
  %98 = load i16, i16* %19, align 2
  %99 = zext i16 %98 to i32
  %100 = sub nsw i32 %97, %99
  %101 = add nsw i32 %95, %100
  %102 = add nsw i32 %89, %101
  %103 = add nsw i32 %83, %102
  %104 = ashr exact i64 %35, 30
  %105 = mul nsw i64 %36, -3
  %106 = getelementptr inbounds i16, i16* %74, i64 %8
  %107 = getelementptr inbounds i16, i16* %75, i64 %9
  %108 = load i16, i16* %106, align 2
  %109 = zext i16 %108 to i32
  %110 = load i16, i16* %107, align 2
  %111 = zext i16 %110 to i32
  %112 = sub nsw i32 %109, %111
  %113 = mul nsw i32 %112, 5
  %114 = add nsw i32 %113, %103
  %115 = getelementptr inbounds i16, i16* %106, i64 %8
  %116 = getelementptr inbounds i16, i16* %107, i64 %9
  %117 = load i16, i16* %115, align 2
  %118 = zext i16 %117 to i32
  %119 = load i16, i16* %116, align 2
  %120 = zext i16 %119 to i32
  %121 = sub nsw i32 %118, %120
  %122 = mul nsw i32 %121, 6
  %123 = add nsw i32 %122, %114
  %124 = getelementptr inbounds i16, i16* %115, i64 %8
  %125 = getelementptr inbounds i16, i16* %116, i64 %9
  %126 = load i16, i16* %124, align 2
  %127 = zext i16 %126 to i32
  %128 = load i16, i16* %125, align 2
  %129 = zext i16 %128 to i32
  %130 = sub nsw i32 %127, %129
  %131 = mul nsw i32 %130, 7
  %132 = add nsw i32 %131, %123
  %133 = getelementptr inbounds i16, i16* %124, i64 %8
  %134 = getelementptr inbounds i16, i16* %125, i64 %9
  %135 = load i16, i16* %133, align 2
  %136 = zext i16 %135 to i32
  %137 = load i16, i16* %134, align 2
  %138 = zext i16 %137 to i32
  %139 = sub nsw i32 %136, %138
  %140 = shl nsw i32 %139, 3
  %141 = add nsw i32 %140, %132
  %142 = getelementptr i16, i16* %75, i64 %105
  %143 = getelementptr i16, i16* %74, i64 %104
  %144 = mul i32 %141, 5
  %145 = add i32 %144, 32
  %146 = ashr i32 %145, 6
  %147 = getelementptr inbounds i16, i16* %142, i64 %9
  %148 = mul nsw i32 %73, 17
  %149 = add nsw i32 %148, 16
  %150 = ashr i32 %149, 5
  %151 = load i16, i16* %143, align 2
  %152 = zext i16 %151 to i32
  %153 = getelementptr inbounds i16, i16* %147, i64 8
  %154 = load i16, i16* %153, align 2
  %155 = zext i16 %154 to i32
  %156 = add nuw nsw i32 %155, %152
  %157 = shl nuw nsw i32 %156, 4
  %158 = mul nsw i32 %146, -7
  %159 = mul nsw i32 %150, 3
  %160 = sub nsw i32 16, %159
  %161 = add nsw i32 %160, %158
  %162 = add nsw i32 %161, %157
  %163 = shl nsw i32 %150, 1
  %164 = shl nsw i32 %150, 2
  %165 = mul nsw i32 %150, 5
  %166 = mul nsw i32 %150, 6
  %167 = mul nsw i32 %150, 7
  br label %168

168:                                              ; preds = %255, %2
  %169 = phi i32 [ 16, %2 ], [ %260, %255 ]
  %170 = phi i16* [ %3, %2 ], [ %259, %255 ]
  %171 = phi i32 [ %162, %2 ], [ %172, %255 ]
  %172 = add nsw i32 %171, %146
  %173 = ashr i32 %171, 5
  %174 = icmp ult i32 %173, 512
  br i1 %174, label %179, label %175

175:                                              ; preds = %168
  %176 = ashr i32 %171, 31
  %177 = or i32 %176, -512
  %178 = xor i32 %177, -1
  br label %179

179:                                              ; preds = %168, %175
  %180 = phi i32 [ %178, %175 ], [ %173, %168 ]
  %181 = trunc i32 %180 to i16
  store i16 %181, i16* %170, align 2
  %182 = add nsw i32 %171, %150
  %183 = ashr i32 %182, 5
  %184 = icmp ult i32 %183, 512
  br i1 %184, label %189, label %185

185:                                              ; preds = %179
  %186 = ashr i32 %182, 31
  %187 = or i32 %186, -512
  %188 = xor i32 %187, -1
  br label %189

189:                                              ; preds = %179, %185
  %190 = phi i32 [ %188, %185 ], [ %183, %179 ]
  %191 = trunc i32 %190 to i16
  %192 = getelementptr inbounds i16, i16* %170, i64 1
  store i16 %191, i16* %192, align 2
  %193 = add nsw i32 %171, %163
  %194 = ashr i32 %193, 5
  %195 = icmp ult i32 %194, 512
  br i1 %195, label %200, label %196

196:                                              ; preds = %189
  %197 = ashr i32 %193, 31
  %198 = or i32 %197, -512
  %199 = xor i32 %198, -1
  br label %200

200:                                              ; preds = %189, %196
  %201 = phi i32 [ %199, %196 ], [ %194, %189 ]
  %202 = trunc i32 %201 to i16
  %203 = getelementptr inbounds i16, i16* %170, i64 2
  store i16 %202, i16* %203, align 2
  %204 = add nsw i32 %171, %159
  %205 = ashr i32 %204, 5
  %206 = icmp ult i32 %205, 512
  br i1 %206, label %211, label %207

207:                                              ; preds = %200
  %208 = ashr i32 %204, 31
  %209 = or i32 %208, -512
  %210 = xor i32 %209, -1
  br label %211

211:                                              ; preds = %200, %207
  %212 = phi i32 [ %210, %207 ], [ %205, %200 ]
  %213 = trunc i32 %212 to i16
  %214 = getelementptr inbounds i16, i16* %170, i64 3
  store i16 %213, i16* %214, align 2
  %215 = add nsw i32 %171, %164
  %216 = ashr i32 %215, 5
  %217 = icmp ult i32 %216, 512
  br i1 %217, label %222, label %218

218:                                              ; preds = %211
  %219 = ashr i32 %215, 31
  %220 = or i32 %219, -512
  %221 = xor i32 %220, -1
  br label %222

222:                                              ; preds = %211, %218
  %223 = phi i32 [ %221, %218 ], [ %216, %211 ]
  %224 = trunc i32 %223 to i16
  %225 = getelementptr inbounds i16, i16* %170, i64 4
  store i16 %224, i16* %225, align 2
  %226 = add nsw i32 %171, %165
  %227 = ashr i32 %226, 5
  %228 = icmp ult i32 %227, 512
  br i1 %228, label %233, label %229

229:                                              ; preds = %222
  %230 = ashr i32 %226, 31
  %231 = or i32 %230, -512
  %232 = xor i32 %231, -1
  br label %233

233:                                              ; preds = %222, %229
  %234 = phi i32 [ %232, %229 ], [ %227, %222 ]
  %235 = trunc i32 %234 to i16
  %236 = getelementptr inbounds i16, i16* %170, i64 5
  store i16 %235, i16* %236, align 2
  %237 = add nsw i32 %171, %166
  %238 = ashr i32 %237, 5
  %239 = icmp ult i32 %238, 512
  br i1 %239, label %244, label %240

240:                                              ; preds = %233
  %241 = ashr i32 %237, 31
  %242 = or i32 %241, -512
  %243 = xor i32 %242, -1
  br label %244

244:                                              ; preds = %233, %240
  %245 = phi i32 [ %243, %240 ], [ %238, %233 ]
  %246 = trunc i32 %245 to i16
  %247 = getelementptr inbounds i16, i16* %170, i64 6
  store i16 %246, i16* %247, align 2
  %248 = add nsw i32 %171, %167
  %249 = ashr i32 %248, 5
  %250 = icmp ult i32 %249, 512
  br i1 %250, label %255, label %251

251:                                              ; preds = %244
  %252 = ashr i32 %248, 31
  %253 = or i32 %252, -512
  %254 = xor i32 %253, -1
  br label %255

255:                                              ; preds = %244, %251
  %256 = phi i32 [ %254, %251 ], [ %249, %244 ]
  %257 = trunc i32 %256 to i16
  %258 = getelementptr inbounds i16, i16* %170, i64 7
  store i16 %257, i16* %258, align 2
  %259 = getelementptr inbounds i16, i16* %170, i64 %8
  %260 = add nsw i32 %169, -1
  %261 = icmp eq i32 %260, 0
  br i1 %261, label %262, label %168

262:                                              ; preds = %255
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_tm_vp8_c(i8* nocapture, i64) #1 {
  %3 = xor i64 %1, -1
  %4 = getelementptr inbounds i8, i8* %0, i64 %3
  %5 = load i8, i8* %4, align 1
  %6 = zext i8 %5 to i64
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i8, i8* getelementptr inbounds ([2304 x i8], [2304 x i8]* @ff_crop_tab, i64 0, i64 1024), i64 %7
  %9 = sub i64 0, %1
  %10 = getelementptr inbounds i8, i8* %0, i64 %9
  %11 = getelementptr inbounds i8, i8* %10, i64 1
  %12 = getelementptr inbounds i8, i8* %10, i64 2
  %13 = getelementptr inbounds i8, i8* %10, i64 3
  %14 = getelementptr inbounds i8, i8* %10, i64 4
  %15 = getelementptr inbounds i8, i8* %10, i64 5
  %16 = getelementptr inbounds i8, i8* %10, i64 6
  %17 = getelementptr inbounds i8, i8* %10, i64 7
  br label %18

18:                                               ; preds = %18, %2
  %19 = phi i8* [ %0, %2 ], [ %64, %18 ]
  %20 = phi i32 [ 0, %2 ], [ %65, %18 ]
  %21 = getelementptr inbounds i8, i8* %19, i64 -1
  %22 = load i8, i8* %21, align 1
  %23 = zext i8 %22 to i64
  %24 = getelementptr inbounds i8, i8* %8, i64 %23
  %25 = load i8, i8* %10, align 1
  %26 = zext i8 %25 to i64
  %27 = getelementptr inbounds i8, i8* %24, i64 %26
  %28 = load i8, i8* %27, align 1
  store i8 %28, i8* %19, align 1
  %29 = load i8, i8* %11, align 1
  %30 = zext i8 %29 to i64
  %31 = getelementptr inbounds i8, i8* %24, i64 %30
  %32 = load i8, i8* %31, align 1
  %33 = getelementptr inbounds i8, i8* %19, i64 1
  store i8 %32, i8* %33, align 1
  %34 = load i8, i8* %12, align 1
  %35 = zext i8 %34 to i64
  %36 = getelementptr inbounds i8, i8* %24, i64 %35
  %37 = load i8, i8* %36, align 1
  %38 = getelementptr inbounds i8, i8* %19, i64 2
  store i8 %37, i8* %38, align 1
  %39 = load i8, i8* %13, align 1
  %40 = zext i8 %39 to i64
  %41 = getelementptr inbounds i8, i8* %24, i64 %40
  %42 = load i8, i8* %41, align 1
  %43 = getelementptr inbounds i8, i8* %19, i64 3
  store i8 %42, i8* %43, align 1
  %44 = load i8, i8* %14, align 1
  %45 = zext i8 %44 to i64
  %46 = getelementptr inbounds i8, i8* %24, i64 %45
  %47 = load i8, i8* %46, align 1
  %48 = getelementptr inbounds i8, i8* %19, i64 4
  store i8 %47, i8* %48, align 1
  %49 = load i8, i8* %15, align 1
  %50 = zext i8 %49 to i64
  %51 = getelementptr inbounds i8, i8* %24, i64 %50
  %52 = load i8, i8* %51, align 1
  %53 = getelementptr inbounds i8, i8* %19, i64 5
  store i8 %52, i8* %53, align 1
  %54 = load i8, i8* %16, align 1
  %55 = zext i8 %54 to i64
  %56 = getelementptr inbounds i8, i8* %24, i64 %55
  %57 = load i8, i8* %56, align 1
  %58 = getelementptr inbounds i8, i8* %19, i64 6
  store i8 %57, i8* %58, align 1
  %59 = load i8, i8* %17, align 1
  %60 = zext i8 %59 to i64
  %61 = getelementptr inbounds i8, i8* %24, i64 %60
  %62 = load i8, i8* %61, align 1
  %63 = getelementptr inbounds i8, i8* %19, i64 7
  store i8 %62, i8* %63, align 1
  %64 = getelementptr inbounds i8, i8* %19, i64 %1
  %65 = add nuw nsw i32 %20, 1
  %66 = icmp eq i32 %65, 8
  br i1 %66, label %67, label %18

67:                                               ; preds = %18
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_dc_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 0, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = sub nsw i64 4, %4
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = shl nsw i64 %4, 2
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = add nsw i64 %4, -1
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = sub nsw i64 1, %4
  %28 = getelementptr inbounds i16, i16* %3, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = zext i16 %29 to i64
  %31 = add nuw nsw i64 %13, %26
  %32 = add nuw nsw i64 %31, %30
  %33 = sub nsw i64 5, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = add nuw nsw i32 %17, %36
  %38 = mul nsw i64 %4, 5
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i32
  %43 = add nuw nsw i32 %22, %42
  %44 = and i64 %1, -2
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = sub nsw i64 2, %4
  %50 = getelementptr inbounds i16, i16* %3, i64 %49
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i64
  %53 = add nuw nsw i64 %32, %48
  %54 = add nuw nsw i64 %53, %52
  %55 = sub nsw i64 6, %4
  %56 = getelementptr inbounds i16, i16* %3, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %37, %58
  %60 = mul nsw i64 %4, 6
  %61 = add nsw i64 %60, -1
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = load i16, i16* %62, align 2
  %64 = zext i16 %63 to i32
  %65 = add nuw nsw i32 %43, %64
  %66 = mul nsw i64 %4, 3
  %67 = add nsw i64 %66, -1
  %68 = getelementptr inbounds i16, i16* %3, i64 %67
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i64
  %71 = sub nsw i64 3, %4
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = load i16, i16* %72, align 2
  %74 = zext i16 %73 to i64
  %75 = add nuw nsw i64 %54, %70
  %76 = add nuw nsw i64 %75, %74
  %77 = sub nsw i64 7, %4
  %78 = getelementptr inbounds i16, i16* %3, i64 %77
  %79 = load i16, i16* %78, align 2
  %80 = zext i16 %79 to i32
  %81 = add nuw nsw i32 %59, %80
  %82 = mul nsw i64 %4, 7
  %83 = add nsw i64 %82, -1
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i32
  %87 = add nuw nsw i32 %65, %86
  %88 = add nuw nsw i64 %76, 4
  %89 = lshr i64 %88, 3
  %90 = and i64 %89, 536870911
  %91 = mul i64 %90, 281479271743489
  %92 = add nuw nsw i32 %81, 2
  %93 = lshr i32 %92, 2
  %94 = zext i32 %93 to i64
  %95 = mul i64 %94, 281479271743489
  %96 = add nuw nsw i32 %87, 2
  %97 = lshr i32 %96, 2
  %98 = zext i32 %97 to i64
  %99 = add nuw nsw i32 %81, 4
  %100 = add nuw nsw i32 %99, %87
  %101 = lshr i32 %100, 3
  %102 = zext i32 %101 to i64
  %103 = bitcast i8* %0 to i64*
  store i64 %91, i64* %103, align 8
  %104 = getelementptr inbounds i8, i8* %0, i64 8
  %105 = bitcast i8* %104 to i64*
  store i64 %95, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %3, i64 %4
  %107 = bitcast i16* %106 to i64*
  store i64 %91, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %106, i64 4
  %109 = bitcast i16* %108 to i64*
  store i64 %95, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %3, i64 %44
  %111 = bitcast i16* %110 to i64*
  store i64 %91, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %110, i64 4
  %113 = bitcast i16* %112 to i64*
  store i64 %95, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %3, i64 %66
  %115 = bitcast i16* %114 to i64*
  store i64 %91, i64* %115, align 8
  %116 = getelementptr inbounds i16, i16* %114, i64 4
  %117 = bitcast i16* %116 to i64*
  store i64 %95, i64* %117, align 8
  %118 = mul i64 %98, 281479271743489
  %119 = mul i64 %102, 281479271743489
  %120 = getelementptr inbounds i16, i16* %3, i64 %18
  %121 = bitcast i16* %120 to i64*
  store i64 %118, i64* %121, align 8
  %122 = getelementptr inbounds i16, i16* %120, i64 4
  %123 = bitcast i16* %122 to i64*
  store i64 %119, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %3, i64 %38
  %125 = bitcast i16* %124 to i64*
  store i64 %118, i64* %125, align 8
  %126 = getelementptr inbounds i16, i16* %124, i64 4
  %127 = bitcast i16* %126 to i64*
  store i64 %119, i64* %127, align 8
  %128 = getelementptr inbounds i16, i16* %3, i64 %60
  %129 = bitcast i16* %128 to i64*
  store i64 %118, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %119, i64* %131, align 8
  %132 = getelementptr inbounds i16, i16* %3, i64 %82
  %133 = bitcast i16* %132 to i64*
  store i64 %118, i64* %133, align 8
  %134 = getelementptr inbounds i16, i16* %132, i64 4
  %135 = bitcast i16* %134 to i64*
  store i64 %119, i64* %135, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_left_dc_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = add nuw nsw i64 %8, %17
  %19 = mul nsw i64 %4, 5
  %20 = add nsw i64 %19, -1
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i64
  %24 = add nuw nsw i64 %13, %23
  %25 = and i64 %1, -2
  %26 = add nsw i64 %25, -1
  %27 = getelementptr inbounds i16, i16* %3, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i64
  %30 = add nuw nsw i64 %18, %29
  %31 = mul nsw i64 %4, 6
  %32 = add nsw i64 %31, -1
  %33 = getelementptr inbounds i16, i16* %3, i64 %32
  %34 = load i16, i16* %33, align 2
  %35 = zext i16 %34 to i64
  %36 = add nuw nsw i64 %24, %35
  %37 = mul nsw i64 %4, 3
  %38 = add nsw i64 %37, -1
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i64
  %42 = add nuw nsw i64 %30, %41
  %43 = mul nsw i64 %4, 7
  %44 = add nsw i64 %43, -1
  %45 = getelementptr inbounds i16, i16* %3, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i64
  %48 = add nuw nsw i64 %36, %47
  %49 = add nuw nsw i64 %42, 2
  %50 = lshr i64 %49, 2
  %51 = mul i64 %50, 281479271743489
  %52 = add nuw nsw i64 %48, 2
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  store i64 %51, i64* %54, align 8
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  store i64 %51, i64* %56, align 8
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %51, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %51, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %25
  %62 = bitcast i16* %61 to i64*
  store i64 %51, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %51, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %37
  %66 = bitcast i16* %65 to i64*
  store i64 %51, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %51, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %19
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %31
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %43
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_top_dc_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = add nuw nsw i64 %8, %16
  %18 = sub nsw i64 5, %4
  %19 = getelementptr inbounds i16, i16* %3, i64 %18
  %20 = load i16, i16* %19, align 2
  %21 = zext i16 %20 to i64
  %22 = add nuw nsw i64 %12, %21
  %23 = sub nsw i64 2, %4
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = add nuw nsw i64 %17, %26
  %28 = sub nsw i64 6, %4
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i64
  %32 = add nuw nsw i64 %22, %31
  %33 = sub nsw i64 3, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %27, %36
  %38 = sub nsw i64 7, %4
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i64
  %42 = add nuw nsw i64 %32, %41
  %43 = add nuw nsw i64 %37, 2
  %44 = lshr i64 %43, 2
  %45 = mul i64 %44, 281479271743489
  %46 = add nuw nsw i64 %42, 2
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %45, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %45, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %45, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %45, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %45, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %45, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %45, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %45, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_l0t_9(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = sub nsw i64 5, %4
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub nsw i64 2, %4
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = sub nsw i64 6, %4
  %26 = getelementptr inbounds i16, i16* %3, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i64
  %29 = sub nsw i64 3, %4
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = sub nsw i64 7, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %8, 2
  %38 = add nuw nsw i64 %37, %16
  %39 = add nuw nsw i64 %38, %24
  %40 = add nuw nsw i64 %39, %32
  %41 = lshr i64 %40, 2
  %42 = mul i64 %41, 281479271743489
  %43 = add nuw nsw i64 %12, 2
  %44 = add nuw nsw i64 %43, %20
  %45 = add nuw nsw i64 %44, %28
  %46 = add nuw nsw i64 %45, %36
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %42, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %42, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %42, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %42, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %42, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %42, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %42, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %42, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  %86 = lshr i64 %1, 1
  %87 = trunc i64 %86 to i32
  %88 = shl i64 %86, 32
  %89 = sub i64 0, %88
  %90 = ashr exact i64 %89, 32
  %91 = getelementptr inbounds i16, i16* %3, i64 %90
  %92 = load i16, i16* %91, align 2
  %93 = zext i16 %92 to i32
  %94 = sub i64 4294967296, %88
  %95 = ashr exact i64 %94, 32
  %96 = getelementptr inbounds i16, i16* %3, i64 %95
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i32
  %99 = sub i64 8589934592, %88
  %100 = ashr exact i64 %99, 32
  %101 = getelementptr inbounds i16, i16* %3, i64 %100
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  %104 = sub i64 12884901888, %88
  %105 = ashr exact i64 %104, 32
  %106 = getelementptr inbounds i16, i16* %3, i64 %105
  %107 = load i16, i16* %106, align 2
  %108 = zext i16 %107 to i32
  %109 = getelementptr inbounds i8, i8* %0, i64 -2
  %110 = bitcast i8* %109 to i16*
  %111 = load i16, i16* %110, align 2
  %112 = zext i16 %111 to i32
  %113 = add i64 %88, -4294967296
  %114 = ashr exact i64 %113, 32
  %115 = getelementptr inbounds i16, i16* %3, i64 %114
  %116 = load i16, i16* %115, align 2
  %117 = zext i16 %116 to i32
  %118 = trunc i64 %1 to i32
  %119 = and i32 %118, -2
  %120 = add nsw i32 %119, -1
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds i16, i16* %3, i64 %121
  %123 = load i16, i16* %122, align 2
  %124 = zext i16 %123 to i32
  %125 = mul nsw i32 %87, 3
  %126 = add nsw i32 %125, -1
  %127 = sext i32 %126 to i64
  %128 = getelementptr inbounds i16, i16* %3, i64 %127
  %129 = load i16, i16* %128, align 2
  %130 = zext i16 %129 to i32
  %131 = add nuw nsw i32 %93, 4
  %132 = add nuw nsw i32 %131, %98
  %133 = add nuw nsw i32 %132, %103
  %134 = add nuw nsw i32 %133, %108
  %135 = add nuw nsw i32 %134, %112
  %136 = add nuw nsw i32 %135, %117
  %137 = add nuw nsw i32 %136, %124
  %138 = add nuw nsw i32 %137, %130
  %139 = ashr i32 %138, 3
  %140 = sext i32 %139 to i64
  %141 = mul i64 %140, 281479271743489
  store i64 %141, i64* %49, align 8
  %142 = ashr exact i64 %88, 32
  %143 = getelementptr inbounds i16, i16* %3, i64 %142
  %144 = bitcast i16* %143 to i64*
  store i64 %141, i64* %144, align 8
  %145 = sext i32 %119 to i64
  %146 = getelementptr inbounds i16, i16* %3, i64 %145
  %147 = bitcast i16* %146 to i64*
  store i64 %141, i64* %147, align 8
  %148 = sext i32 %125 to i64
  %149 = getelementptr inbounds i16, i16* %3, i64 %148
  %150 = bitcast i16* %149 to i64*
  store i64 %141, i64* %150, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_0lt_9(i8* nocapture, i64) #1 {
  tail call void @pred8x8_dc_9_c(i8* %0, i64 %1)
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = sub i64 0, %5
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = sub i64 4294967296, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = load i16, i16* %13, align 2
  %15 = zext i16 %14 to i64
  %16 = sub i64 8589934592, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub i64 12884901888, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i16, i16* %3, i64 %22
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i64
  %26 = add nuw nsw i64 %10, 2
  %27 = add nuw nsw i64 %26, %15
  %28 = add nuw nsw i64 %27, %20
  %29 = add nuw nsw i64 %28, %25
  %30 = lshr i64 %29, 2
  %31 = mul i64 %30, 281479271743489
  %32 = bitcast i8* %0 to i64*
  store i64 %31, i64* %32, align 8
  %33 = ashr exact i64 %5, 32
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %31, i64* %35, align 8
  %36 = shl i64 %1, 32
  %37 = ashr exact i64 %36, 32
  %38 = and i64 %37, -2
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %31, i64* %40, align 8
  %41 = mul i64 %4, 12884901888
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds i16, i16* %3, i64 %42
  %44 = bitcast i16* %43 to i64*
  store i64 %31, i64* %44, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_l00_9(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = mul nsw i64 %4, 5
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = and i64 %1, -2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = mul nsw i64 %4, 6
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = mul nsw i64 %4, 3
  %34 = add nsw i64 %33, -1
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = mul nsw i64 %4, 7
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %8, 2
  %44 = add nuw nsw i64 %43, %17
  %45 = add nuw nsw i64 %44, %27
  %46 = add nuw nsw i64 %45, %37
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = add nuw nsw i64 %13, 2
  %50 = add nuw nsw i64 %49, %22
  %51 = add nuw nsw i64 %50, %32
  %52 = add nuw nsw i64 %51, %42
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  store i64 %48, i64* %54, align 8
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  store i64 %48, i64* %56, align 8
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %48, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %23
  %62 = bitcast i16* %61 to i64*
  store i64 %48, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %48, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %33
  %66 = bitcast i16* %65 to i64*
  store i64 %48, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %48, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %18
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %28
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %38
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  %86 = shl nsw i64 %1, 2
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = bitcast i8* %87 to i16*
  %89 = lshr i64 %1, 1
  %90 = bitcast i8* %87 to i64*
  store i64 72058693566333184, i64* %90, align 8
  %91 = shl i64 %89, 32
  %92 = ashr exact i64 %91, 32
  %93 = getelementptr inbounds i16, i16* %88, i64 %92
  %94 = bitcast i16* %93 to i64*
  store i64 72058693566333184, i64* %94, align 8
  %95 = shl i64 %1, 32
  %96 = ashr exact i64 %95, 32
  %97 = and i64 %96, -2
  %98 = getelementptr inbounds i16, i16* %88, i64 %97
  %99 = bitcast i16* %98 to i64*
  store i64 72058693566333184, i64* %99, align 8
  %100 = mul i64 %89, 12884901888
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %88, i64 %101
  %103 = bitcast i16* %102 to i64*
  store i64 72058693566333184, i64* %103, align 8
  %104 = getelementptr inbounds i8, i8* %87, i64 8
  %105 = bitcast i8* %104 to i16*
  %106 = bitcast i8* %104 to i64*
  store i64 72058693566333184, i64* %106, align 8
  %107 = getelementptr inbounds i16, i16* %105, i64 %92
  %108 = bitcast i16* %107 to i64*
  store i64 72058693566333184, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %105, i64 %97
  %110 = bitcast i16* %109 to i64*
  store i64 72058693566333184, i64* %110, align 8
  %111 = getelementptr inbounds i16, i16* %105, i64 %101
  %112 = bitcast i16* %111 to i64*
  store i64 72058693566333184, i64* %112, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_0l0_9(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = mul nsw i64 %4, 5
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = and i64 %1, -2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = mul nsw i64 %4, 6
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = mul nsw i64 %4, 3
  %34 = add nsw i64 %33, -1
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = mul nsw i64 %4, 7
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %8, 2
  %44 = add nuw nsw i64 %43, %17
  %45 = add nuw nsw i64 %44, %27
  %46 = add nuw nsw i64 %45, %37
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = add nuw nsw i64 %13, 2
  %50 = add nuw nsw i64 %49, %22
  %51 = add nuw nsw i64 %50, %32
  %52 = add nuw nsw i64 %51, %42
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %48, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %23
  %62 = bitcast i16* %61 to i64*
  store i64 %48, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %48, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %33
  %66 = bitcast i16* %65 to i64*
  store i64 %48, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %48, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %18
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %28
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %38
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  %86 = lshr i64 %1, 1
  store i64 72058693566333184, i64* %54, align 8
  %87 = shl i64 %86, 32
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %3, i64 %88
  %90 = bitcast i16* %89 to i64*
  store i64 72058693566333184, i64* %90, align 8
  %91 = shl i64 %1, 32
  %92 = ashr exact i64 %91, 32
  %93 = and i64 %92, -2
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = bitcast i16* %94 to i64*
  store i64 72058693566333184, i64* %95, align 8
  %96 = mul i64 %86, 12884901888
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i16, i16* %3, i64 %97
  %99 = bitcast i16* %98 to i64*
  store i64 72058693566333184, i64* %99, align 8
  %100 = bitcast i8* %55 to i16*
  store i64 72058693566333184, i64* %56, align 8
  %101 = getelementptr inbounds i16, i16* %100, i64 %88
  %102 = bitcast i16* %101 to i64*
  store i64 72058693566333184, i64* %102, align 8
  %103 = getelementptr inbounds i16, i16* %100, i64 %93
  %104 = bitcast i16* %103 to i64*
  store i64 72058693566333184, i64* %104, align 8
  %105 = getelementptr inbounds i16, i16* %100, i64 %97
  %106 = bitcast i16* %105 to i64*
  store i64 72058693566333184, i64* %106, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_dc_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 0, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = sub nsw i64 4, %4
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = shl nsw i64 %4, 2
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = shl nsw i64 %4, 3
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = mul nsw i64 %4, 12
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i32
  %33 = add nsw i64 %4, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = sub nsw i64 1, %4
  %38 = getelementptr inbounds i16, i16* %3, i64 %37
  %39 = load i16, i16* %38, align 2
  %40 = zext i16 %39 to i64
  %41 = add nuw nsw i64 %13, %36
  %42 = add nuw nsw i64 %41, %40
  %43 = sub nsw i64 5, %4
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %17, %46
  %48 = mul nsw i64 %4, 5
  %49 = add nsw i64 %48, -1
  %50 = getelementptr inbounds i16, i16* %3, i64 %49
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i32
  %53 = add nuw nsw i32 %22, %52
  %54 = mul nsw i64 %4, 9
  %55 = add nsw i64 %54, -1
  %56 = getelementptr inbounds i16, i16* %3, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %27, %58
  %60 = mul nsw i64 %4, 13
  %61 = add nsw i64 %60, -1
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = load i16, i16* %62, align 2
  %64 = zext i16 %63 to i32
  %65 = add nuw nsw i32 %32, %64
  %66 = and i64 %1, -2
  %67 = add nsw i64 %66, -1
  %68 = getelementptr inbounds i16, i16* %3, i64 %67
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i64
  %71 = sub nsw i64 2, %4
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = load i16, i16* %72, align 2
  %74 = zext i16 %73 to i64
  %75 = add nuw nsw i64 %42, %70
  %76 = add nuw nsw i64 %75, %74
  %77 = sub nsw i64 6, %4
  %78 = getelementptr inbounds i16, i16* %3, i64 %77
  %79 = load i16, i16* %78, align 2
  %80 = zext i16 %79 to i32
  %81 = add nuw nsw i32 %47, %80
  %82 = mul nsw i64 %4, 6
  %83 = add nsw i64 %82, -1
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i32
  %87 = add nuw nsw i32 %53, %86
  %88 = mul nsw i64 %4, 10
  %89 = add nsw i64 %88, -1
  %90 = getelementptr inbounds i16, i16* %3, i64 %89
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i32
  %93 = add nuw nsw i32 %59, %92
  %94 = mul nsw i64 %4, 14
  %95 = add nsw i64 %94, -1
  %96 = getelementptr inbounds i16, i16* %3, i64 %95
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i32
  %99 = add nuw nsw i32 %65, %98
  %100 = mul nsw i64 %4, 3
  %101 = add nsw i64 %100, -1
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i64
  %105 = sub nsw i64 3, %4
  %106 = getelementptr inbounds i16, i16* %3, i64 %105
  %107 = load i16, i16* %106, align 2
  %108 = zext i16 %107 to i64
  %109 = add nuw nsw i64 %76, %104
  %110 = add nuw nsw i64 %109, %108
  %111 = sub nsw i64 7, %4
  %112 = getelementptr inbounds i16, i16* %3, i64 %111
  %113 = load i16, i16* %112, align 2
  %114 = zext i16 %113 to i32
  %115 = add nuw nsw i32 %81, %114
  %116 = mul nsw i64 %4, 7
  %117 = add nsw i64 %116, -1
  %118 = getelementptr inbounds i16, i16* %3, i64 %117
  %119 = load i16, i16* %118, align 2
  %120 = zext i16 %119 to i32
  %121 = add nuw nsw i32 %87, %120
  %122 = mul nsw i64 %4, 11
  %123 = add nsw i64 %122, -1
  %124 = getelementptr inbounds i16, i16* %3, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %93, %126
  %128 = mul nsw i64 %4, 15
  %129 = add nsw i64 %128, -1
  %130 = getelementptr inbounds i16, i16* %3, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i32
  %133 = add nuw nsw i32 %99, %132
  %134 = add nuw nsw i64 %110, 4
  %135 = lshr i64 %134, 3
  %136 = and i64 %135, 536870911
  %137 = mul i64 %136, 281479271743489
  %138 = add nuw nsw i32 %115, 2
  %139 = lshr i32 %138, 2
  %140 = zext i32 %139 to i64
  %141 = mul i64 %140, 281479271743489
  %142 = add nuw nsw i32 %121, 2
  %143 = lshr i32 %142, 2
  %144 = zext i32 %143 to i64
  %145 = add nuw nsw i32 %115, 4
  %146 = add nuw nsw i32 %145, %121
  %147 = lshr i32 %146, 3
  %148 = zext i32 %147 to i64
  %149 = add nuw nsw i32 %127, 2
  %150 = lshr i32 %149, 2
  %151 = zext i32 %150 to i64
  %152 = add nuw nsw i32 %145, %127
  %153 = lshr i32 %152, 3
  %154 = zext i32 %153 to i64
  %155 = add nuw nsw i32 %133, 2
  %156 = lshr i32 %155, 2
  %157 = zext i32 %156 to i64
  %158 = add nuw nsw i32 %145, %133
  %159 = lshr i32 %158, 3
  %160 = zext i32 %159 to i64
  %161 = bitcast i8* %0 to i64*
  store i64 %137, i64* %161, align 8
  %162 = getelementptr inbounds i8, i8* %0, i64 8
  %163 = bitcast i8* %162 to i64*
  store i64 %141, i64* %163, align 8
  %164 = getelementptr inbounds i16, i16* %3, i64 %4
  %165 = bitcast i16* %164 to i64*
  store i64 %137, i64* %165, align 8
  %166 = getelementptr inbounds i16, i16* %164, i64 4
  %167 = bitcast i16* %166 to i64*
  store i64 %141, i64* %167, align 8
  %168 = getelementptr inbounds i16, i16* %3, i64 %66
  %169 = bitcast i16* %168 to i64*
  store i64 %137, i64* %169, align 8
  %170 = getelementptr inbounds i16, i16* %168, i64 4
  %171 = bitcast i16* %170 to i64*
  store i64 %141, i64* %171, align 8
  %172 = getelementptr inbounds i16, i16* %3, i64 %100
  %173 = bitcast i16* %172 to i64*
  store i64 %137, i64* %173, align 8
  %174 = getelementptr inbounds i16, i16* %172, i64 4
  %175 = bitcast i16* %174 to i64*
  store i64 %141, i64* %175, align 8
  %176 = mul i64 %144, 281479271743489
  %177 = mul i64 %148, 281479271743489
  %178 = mul i64 %151, 281479271743489
  %179 = mul i64 %154, 281479271743489
  %180 = mul i64 %157, 281479271743489
  %181 = mul i64 %160, 281479271743489
  %182 = getelementptr inbounds i16, i16* %3, i64 %18
  %183 = bitcast i16* %182 to i64*
  store i64 %176, i64* %183, align 8
  %184 = getelementptr inbounds i16, i16* %182, i64 4
  %185 = bitcast i16* %184 to i64*
  store i64 %177, i64* %185, align 8
  %186 = getelementptr inbounds i16, i16* %3, i64 %48
  %187 = bitcast i16* %186 to i64*
  store i64 %176, i64* %187, align 8
  %188 = getelementptr inbounds i16, i16* %186, i64 4
  %189 = bitcast i16* %188 to i64*
  store i64 %177, i64* %189, align 8
  %190 = getelementptr inbounds i16, i16* %3, i64 %82
  %191 = bitcast i16* %190 to i64*
  store i64 %176, i64* %191, align 8
  %192 = getelementptr inbounds i16, i16* %190, i64 4
  %193 = bitcast i16* %192 to i64*
  store i64 %177, i64* %193, align 8
  %194 = getelementptr inbounds i16, i16* %3, i64 %116
  %195 = bitcast i16* %194 to i64*
  store i64 %176, i64* %195, align 8
  %196 = getelementptr inbounds i16, i16* %194, i64 4
  %197 = bitcast i16* %196 to i64*
  store i64 %177, i64* %197, align 8
  %198 = getelementptr inbounds i16, i16* %3, i64 %23
  %199 = bitcast i16* %198 to i64*
  store i64 %178, i64* %199, align 8
  %200 = getelementptr inbounds i16, i16* %198, i64 4
  %201 = bitcast i16* %200 to i64*
  store i64 %179, i64* %201, align 8
  %202 = getelementptr inbounds i16, i16* %3, i64 %54
  %203 = bitcast i16* %202 to i64*
  store i64 %178, i64* %203, align 8
  %204 = getelementptr inbounds i16, i16* %202, i64 4
  %205 = bitcast i16* %204 to i64*
  store i64 %179, i64* %205, align 8
  %206 = getelementptr inbounds i16, i16* %3, i64 %88
  %207 = bitcast i16* %206 to i64*
  store i64 %178, i64* %207, align 8
  %208 = getelementptr inbounds i16, i16* %206, i64 4
  %209 = bitcast i16* %208 to i64*
  store i64 %179, i64* %209, align 8
  %210 = getelementptr inbounds i16, i16* %3, i64 %122
  %211 = bitcast i16* %210 to i64*
  store i64 %178, i64* %211, align 8
  %212 = getelementptr inbounds i16, i16* %210, i64 4
  %213 = bitcast i16* %212 to i64*
  store i64 %179, i64* %213, align 8
  %214 = getelementptr inbounds i16, i16* %3, i64 %28
  %215 = bitcast i16* %214 to i64*
  store i64 %180, i64* %215, align 8
  %216 = getelementptr inbounds i16, i16* %214, i64 4
  %217 = bitcast i16* %216 to i64*
  store i64 %181, i64* %217, align 8
  %218 = getelementptr inbounds i16, i16* %3, i64 %60
  %219 = bitcast i16* %218 to i64*
  store i64 %180, i64* %219, align 8
  %220 = getelementptr inbounds i16, i16* %218, i64 4
  %221 = bitcast i16* %220 to i64*
  store i64 %181, i64* %221, align 8
  %222 = getelementptr inbounds i16, i16* %3, i64 %94
  %223 = bitcast i16* %222 to i64*
  store i64 %180, i64* %223, align 8
  %224 = getelementptr inbounds i16, i16* %222, i64 4
  %225 = bitcast i16* %224 to i64*
  store i64 %181, i64* %225, align 8
  %226 = getelementptr inbounds i16, i16* %3, i64 %128
  %227 = bitcast i16* %226 to i64*
  store i64 %180, i64* %227, align 8
  %228 = getelementptr inbounds i16, i16* %226, i64 4
  %229 = bitcast i16* %228 to i64*
  store i64 %181, i64* %229, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_left_dc_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = mul nsw i64 %4, 5
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = and i64 %1, -2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = mul nsw i64 %4, 6
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = mul nsw i64 %4, 3
  %34 = add nsw i64 %33, -1
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = mul nsw i64 %4, 7
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %8, 2
  %44 = add nuw nsw i64 %43, %17
  %45 = add nuw nsw i64 %44, %27
  %46 = add nuw nsw i64 %45, %37
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = add nuw nsw i64 %13, 2
  %50 = add nuw nsw i64 %49, %22
  %51 = add nuw nsw i64 %50, %32
  %52 = add nuw nsw i64 %51, %42
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  store i64 %48, i64* %54, align 8
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  store i64 %48, i64* %56, align 8
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %48, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %23
  %62 = bitcast i16* %61 to i64*
  store i64 %48, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %48, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %33
  %66 = bitcast i16* %65 to i64*
  store i64 %48, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %48, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %18
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %28
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %38
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  %86 = shl nsw i64 %1, 3
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = bitcast i8* %87 to i16*
  %89 = getelementptr inbounds i8, i8* %87, i64 -2
  %90 = bitcast i8* %89 to i16*
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i64
  %93 = getelementptr inbounds i16, i16* %88, i64 %10
  %94 = load i16, i16* %93, align 2
  %95 = zext i16 %94 to i64
  %96 = getelementptr inbounds i16, i16* %88, i64 %14
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i64
  %99 = getelementptr inbounds i16, i16* %88, i64 %19
  %100 = load i16, i16* %99, align 2
  %101 = zext i16 %100 to i64
  %102 = getelementptr inbounds i16, i16* %88, i64 %24
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i64
  %105 = getelementptr inbounds i16, i16* %88, i64 %29
  %106 = load i16, i16* %105, align 2
  %107 = zext i16 %106 to i64
  %108 = getelementptr inbounds i16, i16* %88, i64 %34
  %109 = load i16, i16* %108, align 2
  %110 = zext i16 %109 to i64
  %111 = getelementptr inbounds i16, i16* %88, i64 %39
  %112 = load i16, i16* %111, align 2
  %113 = zext i16 %112 to i64
  %114 = add nuw nsw i64 %92, 2
  %115 = add nuw nsw i64 %114, %98
  %116 = add nuw nsw i64 %115, %104
  %117 = add nuw nsw i64 %116, %110
  %118 = lshr i64 %117, 2
  %119 = mul i64 %118, 281479271743489
  %120 = add nuw nsw i64 %95, 2
  %121 = add nuw nsw i64 %120, %101
  %122 = add nuw nsw i64 %121, %107
  %123 = add nuw nsw i64 %122, %113
  %124 = lshr i64 %123, 2
  %125 = bitcast i8* %87 to i64*
  store i64 %119, i64* %125, align 8
  %126 = getelementptr inbounds i8, i8* %87, i64 8
  %127 = bitcast i8* %126 to i64*
  store i64 %119, i64* %127, align 8
  %128 = getelementptr inbounds i16, i16* %88, i64 %4
  %129 = bitcast i16* %128 to i64*
  store i64 %119, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %119, i64* %131, align 8
  %132 = getelementptr inbounds i16, i16* %88, i64 %23
  %133 = bitcast i16* %132 to i64*
  store i64 %119, i64* %133, align 8
  %134 = getelementptr inbounds i16, i16* %132, i64 4
  %135 = bitcast i16* %134 to i64*
  store i64 %119, i64* %135, align 8
  %136 = getelementptr inbounds i16, i16* %88, i64 %33
  %137 = bitcast i16* %136 to i64*
  store i64 %119, i64* %137, align 8
  %138 = getelementptr inbounds i16, i16* %136, i64 4
  %139 = bitcast i16* %138 to i64*
  store i64 %119, i64* %139, align 8
  %140 = mul i64 %124, 281479271743489
  %141 = getelementptr inbounds i16, i16* %88, i64 %9
  %142 = bitcast i16* %141 to i64*
  store i64 %140, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %140, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %88, i64 %18
  %146 = bitcast i16* %145 to i64*
  store i64 %140, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %145, i64 4
  %148 = bitcast i16* %147 to i64*
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %88, i64 %28
  %150 = bitcast i16* %149 to i64*
  store i64 %140, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %149, i64 4
  %152 = bitcast i16* %151 to i64*
  store i64 %140, i64* %152, align 8
  %153 = getelementptr inbounds i16, i16* %88, i64 %38
  %154 = bitcast i16* %153 to i64*
  store i64 %140, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %153, i64 4
  %156 = bitcast i16* %155 to i64*
  store i64 %140, i64* %156, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_top_dc_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = add nuw nsw i64 %8, %16
  %18 = sub nsw i64 5, %4
  %19 = getelementptr inbounds i16, i16* %3, i64 %18
  %20 = load i16, i16* %19, align 2
  %21 = zext i16 %20 to i64
  %22 = add nuw nsw i64 %12, %21
  %23 = sub nsw i64 2, %4
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = add nuw nsw i64 %17, %26
  %28 = sub nsw i64 6, %4
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i64
  %32 = add nuw nsw i64 %22, %31
  %33 = sub nsw i64 3, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %27, %36
  %38 = sub nsw i64 7, %4
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i64
  %42 = add nuw nsw i64 %32, %41
  %43 = add nuw nsw i64 %37, 2
  %44 = lshr i64 %43, 2
  %45 = mul i64 %44, 281479271743489
  %46 = add nuw nsw i64 %42, 2
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %45, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %45, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %45, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %45, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %45, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %45, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %45, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %45, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  %86 = shl nsw i64 %4, 3
  %87 = getelementptr inbounds i16, i16* %3, i64 %86
  %88 = bitcast i16* %87 to i64*
  store i64 %45, i64* %88, align 8
  %89 = getelementptr inbounds i16, i16* %87, i64 4
  %90 = bitcast i16* %89 to i64*
  store i64 %48, i64* %90, align 8
  %91 = mul nsw i64 %4, 9
  %92 = getelementptr inbounds i16, i16* %3, i64 %91
  %93 = bitcast i16* %92 to i64*
  store i64 %45, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %48, i64* %95, align 8
  %96 = mul nsw i64 %4, 10
  %97 = getelementptr inbounds i16, i16* %3, i64 %96
  %98 = bitcast i16* %97 to i64*
  store i64 %45, i64* %98, align 8
  %99 = getelementptr inbounds i16, i16* %97, i64 4
  %100 = bitcast i16* %99 to i64*
  store i64 %48, i64* %100, align 8
  %101 = mul nsw i64 %4, 11
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = bitcast i16* %102 to i64*
  store i64 %45, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %102, i64 4
  %105 = bitcast i16* %104 to i64*
  store i64 %48, i64* %105, align 8
  %106 = mul nsw i64 %4, 12
  %107 = getelementptr inbounds i16, i16* %3, i64 %106
  %108 = bitcast i16* %107 to i64*
  store i64 %45, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %107, i64 4
  %110 = bitcast i16* %109 to i64*
  store i64 %48, i64* %110, align 8
  %111 = mul nsw i64 %4, 13
  %112 = getelementptr inbounds i16, i16* %3, i64 %111
  %113 = bitcast i16* %112 to i64*
  store i64 %45, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %112, i64 4
  %115 = bitcast i16* %114 to i64*
  store i64 %48, i64* %115, align 8
  %116 = mul nsw i64 %4, 14
  %117 = getelementptr inbounds i16, i16* %3, i64 %116
  %118 = bitcast i16* %117 to i64*
  store i64 %45, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %117, i64 4
  %120 = bitcast i16* %119 to i64*
  store i64 %48, i64* %120, align 8
  %121 = mul nsw i64 %4, 15
  %122 = getelementptr inbounds i16, i16* %3, i64 %121
  %123 = bitcast i16* %122 to i64*
  store i64 %45, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %122, i64 4
  %125 = bitcast i16* %124 to i64*
  store i64 %48, i64* %125, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_l0t_9(i8*, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = sub nsw i64 5, %4
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub nsw i64 2, %4
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = sub nsw i64 6, %4
  %26 = getelementptr inbounds i16, i16* %3, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i64
  %29 = sub nsw i64 3, %4
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = sub nsw i64 7, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %8, 2
  %38 = add nuw nsw i64 %37, %16
  %39 = add nuw nsw i64 %38, %24
  %40 = add nuw nsw i64 %39, %32
  %41 = lshr i64 %40, 2
  %42 = mul i64 %41, 281479271743489
  %43 = add nuw nsw i64 %12, 2
  %44 = add nuw nsw i64 %43, %20
  %45 = add nuw nsw i64 %44, %28
  %46 = add nuw nsw i64 %45, %36
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %42, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %42, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %42, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %42, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %42, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %42, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %42, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %42, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  %86 = shl nsw i64 %4, 3
  %87 = getelementptr inbounds i16, i16* %3, i64 %86
  %88 = bitcast i16* %87 to i64*
  store i64 %42, i64* %88, align 8
  %89 = getelementptr inbounds i16, i16* %87, i64 4
  %90 = bitcast i16* %89 to i64*
  store i64 %48, i64* %90, align 8
  %91 = mul nsw i64 %4, 9
  %92 = getelementptr inbounds i16, i16* %3, i64 %91
  %93 = bitcast i16* %92 to i64*
  store i64 %42, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %48, i64* %95, align 8
  %96 = mul nsw i64 %4, 10
  %97 = getelementptr inbounds i16, i16* %3, i64 %96
  %98 = bitcast i16* %97 to i64*
  store i64 %42, i64* %98, align 8
  %99 = getelementptr inbounds i16, i16* %97, i64 4
  %100 = bitcast i16* %99 to i64*
  store i64 %48, i64* %100, align 8
  %101 = mul nsw i64 %4, 11
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = bitcast i16* %102 to i64*
  store i64 %42, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %102, i64 4
  %105 = bitcast i16* %104 to i64*
  store i64 %48, i64* %105, align 8
  %106 = mul nsw i64 %4, 12
  %107 = getelementptr inbounds i16, i16* %3, i64 %106
  %108 = bitcast i16* %107 to i64*
  store i64 %42, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %107, i64 4
  %110 = bitcast i16* %109 to i64*
  store i64 %48, i64* %110, align 8
  %111 = mul nsw i64 %4, 13
  %112 = getelementptr inbounds i16, i16* %3, i64 %111
  %113 = bitcast i16* %112 to i64*
  store i64 %42, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %112, i64 4
  %115 = bitcast i16* %114 to i64*
  store i64 %48, i64* %115, align 8
  %116 = mul nsw i64 %4, 14
  %117 = getelementptr inbounds i16, i16* %3, i64 %116
  %118 = bitcast i16* %117 to i64*
  store i64 %42, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %117, i64 4
  %120 = bitcast i16* %119 to i64*
  store i64 %48, i64* %120, align 8
  %121 = mul nsw i64 %4, 15
  %122 = getelementptr inbounds i16, i16* %3, i64 %121
  %123 = bitcast i16* %122 to i64*
  store i64 %42, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %122, i64 4
  %125 = bitcast i16* %124 to i64*
  store i64 %48, i64* %125, align 8
  %126 = lshr i64 %1, 1
  %127 = trunc i64 %126 to i32
  %128 = shl i64 %126, 32
  %129 = sub i64 0, %128
  %130 = ashr exact i64 %129, 32
  %131 = getelementptr inbounds i16, i16* %3, i64 %130
  %132 = load i16, i16* %131, align 2
  %133 = zext i16 %132 to i32
  %134 = sub i64 4294967296, %128
  %135 = ashr exact i64 %134, 32
  %136 = getelementptr inbounds i16, i16* %3, i64 %135
  %137 = load i16, i16* %136, align 2
  %138 = zext i16 %137 to i32
  %139 = sub i64 8589934592, %128
  %140 = ashr exact i64 %139, 32
  %141 = getelementptr inbounds i16, i16* %3, i64 %140
  %142 = load i16, i16* %141, align 2
  %143 = zext i16 %142 to i32
  %144 = sub i64 12884901888, %128
  %145 = ashr exact i64 %144, 32
  %146 = getelementptr inbounds i16, i16* %3, i64 %145
  %147 = load i16, i16* %146, align 2
  %148 = zext i16 %147 to i32
  %149 = getelementptr inbounds i8, i8* %0, i64 -2
  %150 = bitcast i8* %149 to i16*
  %151 = load i16, i16* %150, align 2
  %152 = zext i16 %151 to i32
  %153 = add i64 %128, -4294967296
  %154 = ashr exact i64 %153, 32
  %155 = getelementptr inbounds i16, i16* %3, i64 %154
  %156 = load i16, i16* %155, align 2
  %157 = zext i16 %156 to i32
  %158 = trunc i64 %1 to i32
  %159 = and i32 %158, -2
  %160 = add nsw i32 %159, -1
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds i16, i16* %3, i64 %161
  %163 = load i16, i16* %162, align 2
  %164 = zext i16 %163 to i32
  %165 = mul nsw i32 %127, 3
  %166 = add nsw i32 %165, -1
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds i16, i16* %3, i64 %167
  %169 = load i16, i16* %168, align 2
  %170 = zext i16 %169 to i32
  %171 = add nuw nsw i32 %133, 4
  %172 = add nuw nsw i32 %171, %138
  %173 = add nuw nsw i32 %172, %143
  %174 = add nuw nsw i32 %173, %148
  %175 = add nuw nsw i32 %174, %152
  %176 = add nuw nsw i32 %175, %157
  %177 = add nuw nsw i32 %176, %164
  %178 = add nuw nsw i32 %177, %170
  %179 = ashr i32 %178, 3
  %180 = sext i32 %179 to i64
  %181 = mul i64 %180, 281479271743489
  store i64 %181, i64* %49, align 8
  %182 = ashr exact i64 %128, 32
  %183 = getelementptr inbounds i16, i16* %3, i64 %182
  %184 = bitcast i16* %183 to i64*
  store i64 %181, i64* %184, align 8
  %185 = sext i32 %159 to i64
  %186 = getelementptr inbounds i16, i16* %3, i64 %185
  %187 = bitcast i16* %186 to i64*
  store i64 %181, i64* %187, align 8
  %188 = sext i32 %165 to i64
  %189 = getelementptr inbounds i16, i16* %3, i64 %188
  %190 = bitcast i16* %189 to i64*
  store i64 %181, i64* %190, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_0lt_9(i8* nocapture, i64) #1 {
  tail call void @pred8x16_dc_9_c(i8* %0, i64 %1)
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = sub i64 0, %5
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = sub i64 4294967296, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = load i16, i16* %13, align 2
  %15 = zext i16 %14 to i64
  %16 = sub i64 8589934592, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub i64 12884901888, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i16, i16* %3, i64 %22
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i64
  %26 = add nuw nsw i64 %10, 2
  %27 = add nuw nsw i64 %26, %15
  %28 = add nuw nsw i64 %27, %20
  %29 = add nuw nsw i64 %28, %25
  %30 = lshr i64 %29, 2
  %31 = mul i64 %30, 281479271743489
  %32 = bitcast i8* %0 to i64*
  store i64 %31, i64* %32, align 8
  %33 = ashr exact i64 %5, 32
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %31, i64* %35, align 8
  %36 = shl i64 %1, 32
  %37 = ashr exact i64 %36, 32
  %38 = and i64 %37, -2
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %31, i64* %40, align 8
  %41 = mul i64 %4, 12884901888
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds i16, i16* %3, i64 %42
  %44 = bitcast i16* %43 to i64*
  store i64 %31, i64* %44, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_l00_9(i8* nocapture, i64) #1 {
  tail call void @pred8x16_left_dc_9_c(i8* %0, i64 %1)
  %3 = shl nsw i64 %1, 2
  %4 = getelementptr inbounds i8, i8* %0, i64 %3
  %5 = bitcast i8* %4 to i16*
  %6 = lshr i64 %1, 1
  %7 = bitcast i8* %4 to i64*
  store i64 72058693566333184, i64* %7, align 8
  %8 = shl i64 %6, 32
  %9 = ashr exact i64 %8, 32
  %10 = getelementptr inbounds i16, i16* %5, i64 %9
  %11 = bitcast i16* %10 to i64*
  store i64 72058693566333184, i64* %11, align 8
  %12 = shl i64 %1, 32
  %13 = ashr exact i64 %12, 32
  %14 = and i64 %13, -2
  %15 = getelementptr inbounds i16, i16* %5, i64 %14
  %16 = bitcast i16* %15 to i64*
  store i64 72058693566333184, i64* %16, align 8
  %17 = mul i64 %6, 12884901888
  %18 = ashr exact i64 %17, 32
  %19 = getelementptr inbounds i16, i16* %5, i64 %18
  %20 = bitcast i16* %19 to i64*
  store i64 72058693566333184, i64* %20, align 8
  %21 = getelementptr inbounds i8, i8* %4, i64 8
  %22 = bitcast i8* %21 to i16*
  %23 = bitcast i8* %21 to i64*
  store i64 72058693566333184, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %22, i64 %9
  %25 = bitcast i16* %24 to i64*
  store i64 72058693566333184, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %22, i64 %14
  %27 = bitcast i16* %26 to i64*
  store i64 72058693566333184, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %22, i64 %18
  %29 = bitcast i16* %28 to i64*
  store i64 72058693566333184, i64* %29, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_0l0_9(i8* nocapture, i64) #1 {
  tail call void @pred8x16_left_dc_9_c(i8* %0, i64 %1)
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = bitcast i8* %0 to i64*
  store i64 72058693566333184, i64* %5, align 8
  %6 = shl i64 %4, 32
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  store i64 72058693566333184, i64* %9, align 8
  %10 = shl i64 %1, 32
  %11 = ashr exact i64 %10, 32
  %12 = and i64 %11, -2
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = bitcast i16* %13 to i64*
  store i64 72058693566333184, i64* %14, align 8
  %15 = mul i64 %4, 12884901888
  %16 = ashr exact i64 %15, 32
  %17 = getelementptr inbounds i16, i16* %3, i64 %16
  %18 = bitcast i16* %17 to i64*
  store i64 72058693566333184, i64* %18, align 8
  %19 = getelementptr inbounds i8, i8* %0, i64 8
  %20 = bitcast i8* %19 to i16*
  %21 = bitcast i8* %19 to i64*
  store i64 72058693566333184, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 %7
  %23 = bitcast i16* %22 to i64*
  store i64 72058693566333184, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 %12
  %25 = bitcast i16* %24 to i64*
  store i64 72058693566333184, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 %16
  %27 = bitcast i16* %26 to i64*
  store i64 72058693566333184, i64* %27, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_dc_rv40_c(i8* nocapture, i64) #1 {
  %3 = getelementptr inbounds i8, i8* %0, i64 -1
  %4 = load i8, i8* %3, align 1
  %5 = zext i8 %4 to i32
  %6 = sub nsw i64 0, %1
  %7 = getelementptr inbounds i8, i8* %0, i64 %6
  %8 = load i8, i8* %7, align 1
  %9 = zext i8 %8 to i32
  %10 = sub nsw i64 4, %1
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = load i8, i8* %11, align 1
  %13 = zext i8 %12 to i32
  %14 = shl nsw i64 %1, 2
  %15 = add nsw i64 %14, -1
  %16 = getelementptr inbounds i8, i8* %0, i64 %15
  %17 = load i8, i8* %16, align 1
  %18 = zext i8 %17 to i32
  %19 = add nuw nsw i32 %5, %9
  %20 = add nuw nsw i32 %19, %13
  %21 = add nuw nsw i32 %20, %18
  %22 = add nsw i64 %1, -1
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = sub nsw i64 1, %1
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i32
  %30 = sub nsw i64 5, %1
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = mul nsw i64 %1, 5
  %35 = add nsw i64 %34, -1
  %36 = getelementptr inbounds i8, i8* %0, i64 %35
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i32
  %39 = add nuw nsw i32 %21, %25
  %40 = add nuw nsw i32 %39, %29
  %41 = add nuw nsw i32 %40, %33
  %42 = add nuw nsw i32 %41, %38
  %43 = shl nsw i64 %1, 1
  %44 = add nsw i64 %43, -1
  %45 = getelementptr inbounds i8, i8* %0, i64 %44
  %46 = load i8, i8* %45, align 1
  %47 = zext i8 %46 to i32
  %48 = sub nsw i64 2, %1
  %49 = getelementptr inbounds i8, i8* %0, i64 %48
  %50 = load i8, i8* %49, align 1
  %51 = zext i8 %50 to i32
  %52 = sub nsw i64 6, %1
  %53 = getelementptr inbounds i8, i8* %0, i64 %52
  %54 = load i8, i8* %53, align 1
  %55 = zext i8 %54 to i32
  %56 = mul nsw i64 %1, 6
  %57 = add nsw i64 %56, -1
  %58 = getelementptr inbounds i8, i8* %0, i64 %57
  %59 = load i8, i8* %58, align 1
  %60 = zext i8 %59 to i32
  %61 = add nuw nsw i32 %42, %47
  %62 = add nuw nsw i32 %61, %51
  %63 = add nuw nsw i32 %62, %55
  %64 = add nuw nsw i32 %63, %60
  %65 = mul nsw i64 %1, 3
  %66 = add nsw i64 %65, -1
  %67 = getelementptr inbounds i8, i8* %0, i64 %66
  %68 = load i8, i8* %67, align 1
  %69 = zext i8 %68 to i32
  %70 = sub nsw i64 3, %1
  %71 = getelementptr inbounds i8, i8* %0, i64 %70
  %72 = load i8, i8* %71, align 1
  %73 = zext i8 %72 to i32
  %74 = sub nsw i64 7, %1
  %75 = getelementptr inbounds i8, i8* %0, i64 %74
  %76 = load i8, i8* %75, align 1
  %77 = zext i8 %76 to i32
  %78 = mul nsw i64 %1, 7
  %79 = add nsw i64 %78, -1
  %80 = getelementptr inbounds i8, i8* %0, i64 %79
  %81 = load i8, i8* %80, align 1
  %82 = zext i8 %81 to i32
  %83 = add nuw nsw i32 %64, %69
  %84 = add nuw nsw i32 %83, %73
  %85 = add nuw nsw i32 %84, %77
  %86 = add nuw nsw i32 %85, %82
  %87 = add nuw nsw i32 %86, 8
  %88 = lshr i32 %87, 4
  %89 = mul i32 %88, 16843009
  %90 = bitcast i8* %0 to i32*
  store i32 %89, i32* %90, align 4
  %91 = getelementptr inbounds i8, i8* %0, i64 4
  %92 = bitcast i8* %91 to i32*
  store i32 %89, i32* %92, align 4
  %93 = getelementptr inbounds i8, i8* %0, i64 %1
  %94 = bitcast i8* %93 to i32*
  store i32 %89, i32* %94, align 4
  %95 = getelementptr inbounds i8, i8* %93, i64 4
  %96 = bitcast i8* %95 to i32*
  store i32 %89, i32* %96, align 4
  %97 = getelementptr inbounds i8, i8* %0, i64 %43
  %98 = bitcast i8* %97 to i32*
  store i32 %89, i32* %98, align 4
  %99 = getelementptr inbounds i8, i8* %97, i64 4
  %100 = bitcast i8* %99 to i32*
  store i32 %89, i32* %100, align 4
  %101 = getelementptr inbounds i8, i8* %0, i64 %65
  %102 = bitcast i8* %101 to i32*
  store i32 %89, i32* %102, align 4
  %103 = getelementptr inbounds i8, i8* %101, i64 4
  %104 = bitcast i8* %103 to i32*
  store i32 %89, i32* %104, align 4
  %105 = getelementptr inbounds i8, i8* %0, i64 %14
  %106 = bitcast i8* %105 to i32*
  store i32 %89, i32* %106, align 4
  %107 = getelementptr inbounds i8, i8* %105, i64 4
  %108 = bitcast i8* %107 to i32*
  store i32 %89, i32* %108, align 4
  %109 = getelementptr inbounds i8, i8* %0, i64 %34
  %110 = bitcast i8* %109 to i32*
  store i32 %89, i32* %110, align 4
  %111 = getelementptr inbounds i8, i8* %109, i64 4
  %112 = bitcast i8* %111 to i32*
  store i32 %89, i32* %112, align 4
  %113 = getelementptr inbounds i8, i8* %0, i64 %56
  %114 = bitcast i8* %113 to i32*
  store i32 %89, i32* %114, align 4
  %115 = getelementptr inbounds i8, i8* %113, i64 4
  %116 = bitcast i8* %115 to i32*
  store i32 %89, i32* %116, align 4
  %117 = getelementptr inbounds i8, i8* %0, i64 %78
  %118 = bitcast i8* %117 to i32*
  store i32 %89, i32* %118, align 4
  %119 = getelementptr inbounds i8, i8* %117, i64 4
  %120 = bitcast i8* %119 to i32*
  store i32 %89, i32* %120, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_left_dc_rv40_c(i8* nocapture, i64) #1 {
  %3 = getelementptr inbounds i8, i8* %0, i64 -1
  %4 = load i8, i8* %3, align 1
  %5 = zext i8 %4 to i32
  %6 = add nsw i64 %1, -1
  %7 = getelementptr inbounds i8, i8* %0, i64 %6
  %8 = load i8, i8* %7, align 1
  %9 = zext i8 %8 to i32
  %10 = add nuw nsw i32 %5, %9
  %11 = shl nsw i64 %1, 1
  %12 = add nsw i64 %11, -1
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = add nuw nsw i32 %10, %15
  %17 = mul nsw i64 %1, 3
  %18 = add nsw i64 %17, -1
  %19 = getelementptr inbounds i8, i8* %0, i64 %18
  %20 = load i8, i8* %19, align 1
  %21 = zext i8 %20 to i32
  %22 = add nuw nsw i32 %16, %21
  %23 = shl nsw i64 %1, 2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i8, i8* %0, i64 %24
  %26 = load i8, i8* %25, align 1
  %27 = zext i8 %26 to i32
  %28 = add nuw nsw i32 %22, %27
  %29 = mul nsw i64 %1, 5
  %30 = add nsw i64 %29, -1
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = add nuw nsw i32 %28, %33
  %35 = mul nsw i64 %1, 6
  %36 = add nsw i64 %35, -1
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = load i8, i8* %37, align 1
  %39 = zext i8 %38 to i32
  %40 = add nuw nsw i32 %34, %39
  %41 = mul nsw i64 %1, 7
  %42 = add nsw i64 %41, -1
  %43 = getelementptr inbounds i8, i8* %0, i64 %42
  %44 = load i8, i8* %43, align 1
  %45 = zext i8 %44 to i32
  %46 = add nuw nsw i32 %40, %45
  %47 = add nuw nsw i32 %46, 4
  %48 = lshr i32 %47, 3
  %49 = mul i32 %48, 16843009
  %50 = bitcast i8* %0 to i32*
  %51 = getelementptr inbounds i8, i8* %0, i64 4
  %52 = bitcast i8* %51 to i32*
  store i32 %49, i32* %52, align 4
  store i32 %49, i32* %50, align 4
  %53 = getelementptr inbounds i8, i8* %0, i64 %1
  %54 = bitcast i8* %53 to i32*
  %55 = getelementptr inbounds i8, i8* %53, i64 4
  %56 = bitcast i8* %55 to i32*
  store i32 %49, i32* %56, align 4
  store i32 %49, i32* %54, align 4
  %57 = getelementptr inbounds i8, i8* %0, i64 %11
  %58 = bitcast i8* %57 to i32*
  %59 = getelementptr inbounds i8, i8* %57, i64 4
  %60 = bitcast i8* %59 to i32*
  store i32 %49, i32* %60, align 4
  store i32 %49, i32* %58, align 4
  %61 = getelementptr inbounds i8, i8* %0, i64 %17
  %62 = bitcast i8* %61 to i32*
  %63 = getelementptr inbounds i8, i8* %61, i64 4
  %64 = bitcast i8* %63 to i32*
  store i32 %49, i32* %64, align 4
  store i32 %49, i32* %62, align 4
  %65 = getelementptr inbounds i8, i8* %0, i64 %23
  %66 = bitcast i8* %65 to i32*
  %67 = getelementptr inbounds i8, i8* %65, i64 4
  %68 = bitcast i8* %67 to i32*
  store i32 %49, i32* %68, align 4
  store i32 %49, i32* %66, align 4
  %69 = getelementptr inbounds i8, i8* %0, i64 %29
  %70 = bitcast i8* %69 to i32*
  %71 = getelementptr inbounds i8, i8* %69, i64 4
  %72 = bitcast i8* %71 to i32*
  store i32 %49, i32* %72, align 4
  store i32 %49, i32* %70, align 4
  %73 = getelementptr inbounds i8, i8* %0, i64 %35
  %74 = bitcast i8* %73 to i32*
  %75 = getelementptr inbounds i8, i8* %73, i64 4
  %76 = bitcast i8* %75 to i32*
  store i32 %49, i32* %76, align 4
  store i32 %49, i32* %74, align 4
  %77 = getelementptr inbounds i8, i8* %0, i64 %41
  %78 = bitcast i8* %77 to i32*
  %79 = getelementptr inbounds i8, i8* %77, i64 4
  %80 = bitcast i8* %79 to i32*
  store i32 %49, i32* %80, align 4
  store i32 %49, i32* %78, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_top_dc_rv40_c(i8* nocapture, i64) #1 {
  %3 = sub nsw i64 0, %1
  %4 = getelementptr inbounds i8, i8* %0, i64 %3
  %5 = load i8, i8* %4, align 1
  %6 = zext i8 %5 to i32
  %7 = sub nsw i64 1, %1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = add nuw nsw i32 %6, %10
  %12 = sub nsw i64 2, %1
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = add nuw nsw i32 %11, %15
  %17 = sub nsw i64 3, %1
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = add nuw nsw i32 %16, %20
  %22 = sub nsw i64 4, %1
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = add nuw nsw i32 %21, %25
  %27 = sub nsw i64 5, %1
  %28 = getelementptr inbounds i8, i8* %0, i64 %27
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = add nuw nsw i32 %26, %30
  %32 = sub nsw i64 6, %1
  %33 = getelementptr inbounds i8, i8* %0, i64 %32
  %34 = load i8, i8* %33, align 1
  %35 = zext i8 %34 to i32
  %36 = add nuw nsw i32 %31, %35
  %37 = sub nsw i64 7, %1
  %38 = getelementptr inbounds i8, i8* %0, i64 %37
  %39 = load i8, i8* %38, align 1
  %40 = zext i8 %39 to i32
  %41 = add nuw nsw i32 %36, %40
  %42 = add nuw nsw i32 %41, 4
  %43 = lshr i32 %42, 3
  %44 = mul i32 %43, 16843009
  %45 = bitcast i8* %0 to i32*
  %46 = getelementptr inbounds i8, i8* %0, i64 4
  %47 = bitcast i8* %46 to i32*
  store i32 %44, i32* %47, align 4
  store i32 %44, i32* %45, align 4
  %48 = getelementptr inbounds i8, i8* %0, i64 %1
  %49 = bitcast i8* %48 to i32*
  %50 = getelementptr inbounds i8, i8* %48, i64 4
  %51 = bitcast i8* %50 to i32*
  store i32 %44, i32* %51, align 4
  store i32 %44, i32* %49, align 4
  %52 = shl nsw i64 %1, 1
  %53 = getelementptr inbounds i8, i8* %0, i64 %52
  %54 = bitcast i8* %53 to i32*
  %55 = getelementptr inbounds i8, i8* %53, i64 4
  %56 = bitcast i8* %55 to i32*
  store i32 %44, i32* %56, align 4
  store i32 %44, i32* %54, align 4
  %57 = mul nsw i64 %1, 3
  %58 = getelementptr inbounds i8, i8* %0, i64 %57
  %59 = bitcast i8* %58 to i32*
  %60 = getelementptr inbounds i8, i8* %58, i64 4
  %61 = bitcast i8* %60 to i32*
  store i32 %44, i32* %61, align 4
  store i32 %44, i32* %59, align 4
  %62 = shl nsw i64 %1, 2
  %63 = getelementptr inbounds i8, i8* %0, i64 %62
  %64 = bitcast i8* %63 to i32*
  %65 = getelementptr inbounds i8, i8* %63, i64 4
  %66 = bitcast i8* %65 to i32*
  store i32 %44, i32* %66, align 4
  store i32 %44, i32* %64, align 4
  %67 = mul nsw i64 %1, 5
  %68 = getelementptr inbounds i8, i8* %0, i64 %67
  %69 = bitcast i8* %68 to i32*
  %70 = getelementptr inbounds i8, i8* %68, i64 4
  %71 = bitcast i8* %70 to i32*
  store i32 %44, i32* %71, align 4
  store i32 %44, i32* %69, align 4
  %72 = mul nsw i64 %1, 6
  %73 = getelementptr inbounds i8, i8* %0, i64 %72
  %74 = bitcast i8* %73 to i32*
  %75 = getelementptr inbounds i8, i8* %73, i64 4
  %76 = bitcast i8* %75 to i32*
  store i32 %44, i32* %76, align 4
  store i32 %44, i32* %74, align 4
  %77 = mul nsw i64 %1, 7
  %78 = getelementptr inbounds i8, i8* %0, i64 %77
  %79 = bitcast i8* %78 to i32*
  %80 = getelementptr inbounds i8, i8* %78, i64 4
  %81 = bitcast i8* %80 to i32*
  store i32 %44, i32* %81, align 4
  store i32 %44, i32* %79, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_127_dc_9_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %25, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_129_dc_9_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i16, i16* %3, i64 %4
  call void @llvm.memset.p0i8.i64(i8* align 8 %0, i8 1, i64 16, i1 false)
  %6 = bitcast i16* %5 to <2 x i64>*
  store <2 x i64> <i64 72340172838076673, i64 72340172838076673>, <2 x i64>* %6, align 8
  %7 = and i64 %1, -2
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to <2 x i64>*
  store <2 x i64> <i64 72340172838076673, i64 72340172838076673>, <2 x i64>* %9, align 8
  %10 = mul nsw i64 %4, 3
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = bitcast i16* %11 to <2 x i64>*
  store <2 x i64> <i64 72340172838076673, i64 72340172838076673>, <2 x i64>* %12, align 8
  %13 = shl nsw i64 %4, 2
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = bitcast i16* %14 to <2 x i64>*
  store <2 x i64> <i64 72340172838076673, i64 72340172838076673>, <2 x i64>* %15, align 8
  %16 = mul nsw i64 %4, 5
  %17 = getelementptr inbounds i16, i16* %3, i64 %16
  %18 = bitcast i16* %17 to <2 x i64>*
  store <2 x i64> <i64 72340172838076673, i64 72340172838076673>, <2 x i64>* %18, align 8
  %19 = mul nsw i64 %4, 6
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = bitcast i16* %20 to <2 x i64>*
  store <2 x i64> <i64 72340172838076673, i64 72340172838076673>, <2 x i64>* %21, align 8
  %22 = mul nsw i64 %4, 7
  %23 = getelementptr inbounds i16, i16* %3, i64 %22
  %24 = bitcast i16* %23 to <2 x i64>*
  store <2 x i64> <i64 72340172838076673, i64 72340172838076673>, <2 x i64>* %24, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_128_dc_9_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %25, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x16_128_dc_9_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %25, align 8
  %26 = shl nsw i64 %1, 3
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = bitcast i8* %27 to i16*
  %29 = bitcast i8* %27 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 %4
  %31 = bitcast i16* %30 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 %8
  %33 = bitcast i16* %32 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 %11
  %35 = bitcast i16* %34 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %14
  %37 = bitcast i16* %36 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %37, align 8
  %38 = getelementptr inbounds i16, i16* %28, i64 %17
  %39 = bitcast i16* %38 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %39, align 8
  %40 = getelementptr inbounds i16, i16* %28, i64 %20
  %41 = bitcast i16* %40 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %41, align 8
  %42 = getelementptr inbounds i16, i16* %28, i64 %23
  %43 = bitcast i16* %42 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %43, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_dc_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = add nsw i64 %4, -1
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = and i64 %1, -2
  %15 = add nsw i64 %14, -1
  %16 = getelementptr inbounds i16, i16* %3, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i64
  %19 = add nuw nsw i64 %13, %18
  %20 = mul nsw i64 %4, 3
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = add nuw nsw i64 %19, %24
  %26 = shl nsw i64 %4, 2
  %27 = add nsw i64 %26, -1
  %28 = getelementptr inbounds i16, i16* %3, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = zext i16 %29 to i64
  %31 = add nuw nsw i64 %25, %30
  %32 = mul nsw i64 %4, 5
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %31, %36
  %38 = mul nsw i64 %4, 6
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %37, %42
  %44 = mul nsw i64 %4, 7
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = add nuw nsw i64 %43, %48
  %50 = shl nsw i64 %4, 3
  %51 = add nsw i64 %50, -1
  %52 = getelementptr inbounds i16, i16* %3, i64 %51
  %53 = load i16, i16* %52, align 2
  %54 = zext i16 %53 to i64
  %55 = add nuw nsw i64 %49, %54
  %56 = mul nsw i64 %4, 9
  %57 = add nsw i64 %56, -1
  %58 = getelementptr inbounds i16, i16* %3, i64 %57
  %59 = load i16, i16* %58, align 2
  %60 = zext i16 %59 to i64
  %61 = add nuw nsw i64 %55, %60
  %62 = mul nsw i64 %4, 10
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = add nuw nsw i64 %61, %66
  %68 = mul nsw i64 %4, 11
  %69 = add nsw i64 %68, -1
  %70 = getelementptr inbounds i16, i16* %3, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i64
  %73 = add nuw nsw i64 %67, %72
  %74 = mul nsw i64 %4, 12
  %75 = add nsw i64 %74, -1
  %76 = getelementptr inbounds i16, i16* %3, i64 %75
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i64
  %79 = add nuw nsw i64 %73, %78
  %80 = mul nsw i64 %4, 13
  %81 = add nsw i64 %80, -1
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = zext i16 %83 to i64
  %85 = add nuw nsw i64 %79, %84
  %86 = mul nsw i64 %4, 14
  %87 = add nsw i64 %86, -1
  %88 = getelementptr inbounds i16, i16* %3, i64 %87
  %89 = load i16, i16* %88, align 2
  %90 = zext i16 %89 to i64
  %91 = add nuw nsw i64 %85, %90
  %92 = mul nsw i64 %4, 15
  %93 = add nsw i64 %92, -1
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i64
  %97 = add nuw nsw i64 %91, %96
  %98 = sub nsw i64 0, %4
  %99 = getelementptr inbounds i16, i16* %3, i64 %98
  %100 = load i16, i16* %99, align 2
  %101 = zext i16 %100 to i64
  %102 = add nuw nsw i64 %97, %101
  %103 = sub nsw i64 1, %4
  %104 = getelementptr inbounds i16, i16* %3, i64 %103
  %105 = load i16, i16* %104, align 2
  %106 = zext i16 %105 to i64
  %107 = add nuw nsw i64 %102, %106
  %108 = sub nsw i64 2, %4
  %109 = getelementptr inbounds i16, i16* %3, i64 %108
  %110 = load i16, i16* %109, align 2
  %111 = zext i16 %110 to i64
  %112 = add nuw nsw i64 %107, %111
  %113 = sub nsw i64 3, %4
  %114 = getelementptr inbounds i16, i16* %3, i64 %113
  %115 = load i16, i16* %114, align 2
  %116 = zext i16 %115 to i64
  %117 = add nuw nsw i64 %112, %116
  %118 = sub nsw i64 4, %4
  %119 = getelementptr inbounds i16, i16* %3, i64 %118
  %120 = load i16, i16* %119, align 2
  %121 = zext i16 %120 to i64
  %122 = add nuw nsw i64 %117, %121
  %123 = sub nsw i64 5, %4
  %124 = getelementptr inbounds i16, i16* %3, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i64
  %127 = add nuw nsw i64 %122, %126
  %128 = sub nsw i64 6, %4
  %129 = getelementptr inbounds i16, i16* %3, i64 %128
  %130 = load i16, i16* %129, align 2
  %131 = zext i16 %130 to i64
  %132 = add nuw nsw i64 %127, %131
  %133 = sub nsw i64 7, %4
  %134 = getelementptr inbounds i16, i16* %3, i64 %133
  %135 = load i16, i16* %134, align 2
  %136 = zext i16 %135 to i64
  %137 = add nuw nsw i64 %132, %136
  %138 = sub nsw i64 8, %4
  %139 = getelementptr inbounds i16, i16* %3, i64 %138
  %140 = load i16, i16* %139, align 2
  %141 = zext i16 %140 to i64
  %142 = add nuw nsw i64 %137, %141
  %143 = sub nsw i64 9, %4
  %144 = getelementptr inbounds i16, i16* %3, i64 %143
  %145 = load i16, i16* %144, align 2
  %146 = zext i16 %145 to i64
  %147 = add nuw nsw i64 %142, %146
  %148 = sub nsw i64 10, %4
  %149 = getelementptr inbounds i16, i16* %3, i64 %148
  %150 = load i16, i16* %149, align 2
  %151 = zext i16 %150 to i64
  %152 = add nuw nsw i64 %147, %151
  %153 = sub nsw i64 11, %4
  %154 = getelementptr inbounds i16, i16* %3, i64 %153
  %155 = load i16, i16* %154, align 2
  %156 = zext i16 %155 to i64
  %157 = add nuw nsw i64 %152, %156
  %158 = sub nsw i64 12, %4
  %159 = getelementptr inbounds i16, i16* %3, i64 %158
  %160 = load i16, i16* %159, align 2
  %161 = zext i16 %160 to i64
  %162 = add nuw nsw i64 %157, %161
  %163 = sub nsw i64 13, %4
  %164 = getelementptr inbounds i16, i16* %3, i64 %163
  %165 = load i16, i16* %164, align 2
  %166 = zext i16 %165 to i64
  %167 = add nuw nsw i64 %162, %166
  %168 = sub nsw i64 14, %4
  %169 = getelementptr inbounds i16, i16* %3, i64 %168
  %170 = load i16, i16* %169, align 2
  %171 = zext i16 %170 to i64
  %172 = add nuw nsw i64 %167, %171
  %173 = sub nsw i64 15, %4
  %174 = getelementptr inbounds i16, i16* %3, i64 %173
  %175 = load i16, i16* %174, align 2
  %176 = zext i16 %175 to i64
  %177 = add nuw nsw i64 %172, %176
  %178 = add nuw nsw i64 %177, 16
  %179 = lshr i64 %178, 5
  %180 = and i64 %179, 134217727
  %181 = mul i64 %180, 281479271743489
  %182 = bitcast i8* %0 to i64*
  store i64 %181, i64* %182, align 8
  %183 = getelementptr inbounds i8, i8* %0, i64 8
  %184 = bitcast i8* %183 to i64*
  store i64 %181, i64* %184, align 8
  %185 = getelementptr inbounds i8, i8* %0, i64 16
  %186 = bitcast i8* %185 to i64*
  store i64 %181, i64* %186, align 8
  %187 = getelementptr inbounds i8, i8* %0, i64 24
  %188 = bitcast i8* %187 to i64*
  store i64 %181, i64* %188, align 8
  %189 = getelementptr inbounds i16, i16* %3, i64 %4
  %190 = bitcast i16* %189 to i64*
  store i64 %181, i64* %190, align 8
  %191 = getelementptr inbounds i16, i16* %189, i64 4
  %192 = bitcast i16* %191 to i64*
  store i64 %181, i64* %192, align 8
  %193 = getelementptr inbounds i16, i16* %189, i64 8
  %194 = bitcast i16* %193 to i64*
  store i64 %181, i64* %194, align 8
  %195 = getelementptr inbounds i16, i16* %189, i64 12
  %196 = bitcast i16* %195 to i64*
  store i64 %181, i64* %196, align 8
  %197 = getelementptr inbounds i16, i16* %189, i64 %4
  %198 = bitcast i16* %197 to i64*
  store i64 %181, i64* %198, align 8
  %199 = getelementptr inbounds i16, i16* %197, i64 4
  %200 = bitcast i16* %199 to i64*
  store i64 %181, i64* %200, align 8
  %201 = getelementptr inbounds i16, i16* %197, i64 8
  %202 = bitcast i16* %201 to i64*
  store i64 %181, i64* %202, align 8
  %203 = getelementptr inbounds i16, i16* %197, i64 12
  %204 = bitcast i16* %203 to i64*
  store i64 %181, i64* %204, align 8
  %205 = getelementptr inbounds i16, i16* %197, i64 %4
  %206 = bitcast i16* %205 to i64*
  store i64 %181, i64* %206, align 8
  %207 = getelementptr inbounds i16, i16* %205, i64 4
  %208 = bitcast i16* %207 to i64*
  store i64 %181, i64* %208, align 8
  %209 = getelementptr inbounds i16, i16* %205, i64 8
  %210 = bitcast i16* %209 to i64*
  store i64 %181, i64* %210, align 8
  %211 = getelementptr inbounds i16, i16* %205, i64 12
  %212 = bitcast i16* %211 to i64*
  store i64 %181, i64* %212, align 8
  %213 = getelementptr inbounds i16, i16* %205, i64 %4
  %214 = bitcast i16* %213 to i64*
  store i64 %181, i64* %214, align 8
  %215 = getelementptr inbounds i16, i16* %213, i64 4
  %216 = bitcast i16* %215 to i64*
  store i64 %181, i64* %216, align 8
  %217 = getelementptr inbounds i16, i16* %213, i64 8
  %218 = bitcast i16* %217 to i64*
  store i64 %181, i64* %218, align 8
  %219 = getelementptr inbounds i16, i16* %213, i64 12
  %220 = bitcast i16* %219 to i64*
  store i64 %181, i64* %220, align 8
  %221 = getelementptr inbounds i16, i16* %213, i64 %4
  %222 = bitcast i16* %221 to i64*
  store i64 %181, i64* %222, align 8
  %223 = getelementptr inbounds i16, i16* %221, i64 4
  %224 = bitcast i16* %223 to i64*
  store i64 %181, i64* %224, align 8
  %225 = getelementptr inbounds i16, i16* %221, i64 8
  %226 = bitcast i16* %225 to i64*
  store i64 %181, i64* %226, align 8
  %227 = getelementptr inbounds i16, i16* %221, i64 12
  %228 = bitcast i16* %227 to i64*
  store i64 %181, i64* %228, align 8
  %229 = getelementptr inbounds i16, i16* %221, i64 %4
  %230 = bitcast i16* %229 to i64*
  store i64 %181, i64* %230, align 8
  %231 = getelementptr inbounds i16, i16* %229, i64 4
  %232 = bitcast i16* %231 to i64*
  store i64 %181, i64* %232, align 8
  %233 = getelementptr inbounds i16, i16* %229, i64 8
  %234 = bitcast i16* %233 to i64*
  store i64 %181, i64* %234, align 8
  %235 = getelementptr inbounds i16, i16* %229, i64 12
  %236 = bitcast i16* %235 to i64*
  store i64 %181, i64* %236, align 8
  %237 = getelementptr inbounds i16, i16* %229, i64 %4
  %238 = bitcast i16* %237 to i64*
  store i64 %181, i64* %238, align 8
  %239 = getelementptr inbounds i16, i16* %237, i64 4
  %240 = bitcast i16* %239 to i64*
  store i64 %181, i64* %240, align 8
  %241 = getelementptr inbounds i16, i16* %237, i64 8
  %242 = bitcast i16* %241 to i64*
  store i64 %181, i64* %242, align 8
  %243 = getelementptr inbounds i16, i16* %237, i64 12
  %244 = bitcast i16* %243 to i64*
  store i64 %181, i64* %244, align 8
  %245 = getelementptr inbounds i16, i16* %237, i64 %4
  %246 = bitcast i16* %245 to i64*
  store i64 %181, i64* %246, align 8
  %247 = getelementptr inbounds i16, i16* %245, i64 4
  %248 = bitcast i16* %247 to i64*
  store i64 %181, i64* %248, align 8
  %249 = getelementptr inbounds i16, i16* %245, i64 8
  %250 = bitcast i16* %249 to i64*
  store i64 %181, i64* %250, align 8
  %251 = getelementptr inbounds i16, i16* %245, i64 12
  %252 = bitcast i16* %251 to i64*
  store i64 %181, i64* %252, align 8
  %253 = getelementptr inbounds i16, i16* %245, i64 %4
  %254 = bitcast i16* %253 to i64*
  store i64 %181, i64* %254, align 8
  %255 = getelementptr inbounds i16, i16* %253, i64 4
  %256 = bitcast i16* %255 to i64*
  store i64 %181, i64* %256, align 8
  %257 = getelementptr inbounds i16, i16* %253, i64 8
  %258 = bitcast i16* %257 to i64*
  store i64 %181, i64* %258, align 8
  %259 = getelementptr inbounds i16, i16* %253, i64 12
  %260 = bitcast i16* %259 to i64*
  store i64 %181, i64* %260, align 8
  %261 = getelementptr inbounds i16, i16* %253, i64 %4
  %262 = bitcast i16* %261 to i64*
  store i64 %181, i64* %262, align 8
  %263 = getelementptr inbounds i16, i16* %261, i64 4
  %264 = bitcast i16* %263 to i64*
  store i64 %181, i64* %264, align 8
  %265 = getelementptr inbounds i16, i16* %261, i64 8
  %266 = bitcast i16* %265 to i64*
  store i64 %181, i64* %266, align 8
  %267 = getelementptr inbounds i16, i16* %261, i64 12
  %268 = bitcast i16* %267 to i64*
  store i64 %181, i64* %268, align 8
  %269 = getelementptr inbounds i16, i16* %261, i64 %4
  %270 = bitcast i16* %269 to i64*
  store i64 %181, i64* %270, align 8
  %271 = getelementptr inbounds i16, i16* %269, i64 4
  %272 = bitcast i16* %271 to i64*
  store i64 %181, i64* %272, align 8
  %273 = getelementptr inbounds i16, i16* %269, i64 8
  %274 = bitcast i16* %273 to i64*
  store i64 %181, i64* %274, align 8
  %275 = getelementptr inbounds i16, i16* %269, i64 12
  %276 = bitcast i16* %275 to i64*
  store i64 %181, i64* %276, align 8
  %277 = getelementptr inbounds i16, i16* %269, i64 %4
  %278 = bitcast i16* %277 to i64*
  store i64 %181, i64* %278, align 8
  %279 = getelementptr inbounds i16, i16* %277, i64 4
  %280 = bitcast i16* %279 to i64*
  store i64 %181, i64* %280, align 8
  %281 = getelementptr inbounds i16, i16* %277, i64 8
  %282 = bitcast i16* %281 to i64*
  store i64 %181, i64* %282, align 8
  %283 = getelementptr inbounds i16, i16* %277, i64 12
  %284 = bitcast i16* %283 to i64*
  store i64 %181, i64* %284, align 8
  %285 = getelementptr inbounds i16, i16* %277, i64 %4
  %286 = bitcast i16* %285 to i64*
  store i64 %181, i64* %286, align 8
  %287 = getelementptr inbounds i16, i16* %285, i64 4
  %288 = bitcast i16* %287 to i64*
  store i64 %181, i64* %288, align 8
  %289 = getelementptr inbounds i16, i16* %285, i64 8
  %290 = bitcast i16* %289 to i64*
  store i64 %181, i64* %290, align 8
  %291 = getelementptr inbounds i16, i16* %285, i64 12
  %292 = bitcast i16* %291 to i64*
  store i64 %181, i64* %292, align 8
  %293 = getelementptr inbounds i16, i16* %285, i64 %4
  %294 = bitcast i16* %293 to i64*
  store i64 %181, i64* %294, align 8
  %295 = getelementptr inbounds i16, i16* %293, i64 4
  %296 = bitcast i16* %295 to i64*
  store i64 %181, i64* %296, align 8
  %297 = getelementptr inbounds i16, i16* %293, i64 8
  %298 = bitcast i16* %297 to i64*
  store i64 %181, i64* %298, align 8
  %299 = getelementptr inbounds i16, i16* %293, i64 12
  %300 = bitcast i16* %299 to i64*
  store i64 %181, i64* %300, align 8
  %301 = getelementptr inbounds i16, i16* %293, i64 %4
  %302 = bitcast i16* %301 to i64*
  store i64 %181, i64* %302, align 8
  %303 = getelementptr inbounds i16, i16* %301, i64 4
  %304 = bitcast i16* %303 to i64*
  store i64 %181, i64* %304, align 8
  %305 = getelementptr inbounds i16, i16* %301, i64 8
  %306 = bitcast i16* %305 to i64*
  store i64 %181, i64* %306, align 8
  %307 = getelementptr inbounds i16, i16* %301, i64 12
  %308 = bitcast i16* %307 to i64*
  store i64 %181, i64* %308, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_vertical_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds i16, i16* %8, i64 4
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = getelementptr inbounds i16, i16* %8, i64 8
  %15 = bitcast i16* %14 to i64*
  %16 = load i64, i64* %15, align 8
  %17 = getelementptr inbounds i16, i16* %8, i64 12
  %18 = bitcast i16* %17 to i64*
  %19 = load i64, i64* %18, align 8
  %20 = shl i64 %4, 32
  %21 = ashr exact i64 %20, 32
  %22 = bitcast i8* %0 to i64*
  store i64 %10, i64* %22, align 8
  %23 = getelementptr inbounds i8, i8* %0, i64 8
  %24 = bitcast i8* %23 to i64*
  store i64 %13, i64* %24, align 8
  %25 = getelementptr inbounds i8, i8* %0, i64 16
  %26 = bitcast i8* %25 to i64*
  store i64 %16, i64* %26, align 8
  %27 = getelementptr inbounds i8, i8* %0, i64 24
  %28 = bitcast i8* %27 to i64*
  store i64 %19, i64* %28, align 8
  %29 = getelementptr inbounds i16, i16* %3, i64 %21
  %30 = bitcast i16* %29 to i64*
  store i64 %10, i64* %30, align 8
  %31 = getelementptr inbounds i16, i16* %29, i64 4
  %32 = bitcast i16* %31 to i64*
  store i64 %13, i64* %32, align 8
  %33 = getelementptr inbounds i16, i16* %29, i64 8
  %34 = bitcast i16* %33 to i64*
  store i64 %16, i64* %34, align 8
  %35 = getelementptr inbounds i16, i16* %29, i64 12
  %36 = bitcast i16* %35 to i64*
  store i64 %19, i64* %36, align 8
  %37 = ashr exact i64 %20, 31
  %38 = getelementptr inbounds i16, i16* %3, i64 %37
  %39 = bitcast i16* %38 to i64*
  store i64 %10, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %38, i64 4
  %41 = bitcast i16* %40 to i64*
  store i64 %13, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %38, i64 8
  %43 = bitcast i16* %42 to i64*
  store i64 %16, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %38, i64 12
  %45 = bitcast i16* %44 to i64*
  store i64 %19, i64* %45, align 8
  %46 = mul nsw i64 %21, 3
  %47 = getelementptr inbounds i16, i16* %3, i64 %46
  %48 = bitcast i16* %47 to i64*
  store i64 %10, i64* %48, align 8
  %49 = getelementptr inbounds i16, i16* %47, i64 4
  %50 = bitcast i16* %49 to i64*
  store i64 %13, i64* %50, align 8
  %51 = getelementptr inbounds i16, i16* %47, i64 8
  %52 = bitcast i16* %51 to i64*
  store i64 %16, i64* %52, align 8
  %53 = getelementptr inbounds i16, i16* %47, i64 12
  %54 = bitcast i16* %53 to i64*
  store i64 %19, i64* %54, align 8
  %55 = ashr exact i64 %20, 30
  %56 = getelementptr inbounds i16, i16* %3, i64 %55
  %57 = bitcast i16* %56 to i64*
  store i64 %10, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %56, i64 4
  %59 = bitcast i16* %58 to i64*
  store i64 %13, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %56, i64 8
  %61 = bitcast i16* %60 to i64*
  store i64 %16, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %56, i64 12
  %63 = bitcast i16* %62 to i64*
  store i64 %19, i64* %63, align 8
  %64 = mul nsw i64 %21, 5
  %65 = getelementptr inbounds i16, i16* %3, i64 %64
  %66 = bitcast i16* %65 to i64*
  store i64 %10, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %13, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %65, i64 8
  %70 = bitcast i16* %69 to i64*
  store i64 %16, i64* %70, align 8
  %71 = getelementptr inbounds i16, i16* %65, i64 12
  %72 = bitcast i16* %71 to i64*
  store i64 %19, i64* %72, align 8
  %73 = mul nsw i64 %21, 6
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = bitcast i16* %74 to i64*
  store i64 %10, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %13, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %74, i64 8
  %79 = bitcast i16* %78 to i64*
  store i64 %16, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %74, i64 12
  %81 = bitcast i16* %80 to i64*
  store i64 %19, i64* %81, align 8
  %82 = mul nsw i64 %21, 7
  %83 = getelementptr inbounds i16, i16* %3, i64 %82
  %84 = bitcast i16* %83 to i64*
  store i64 %10, i64* %84, align 8
  %85 = getelementptr inbounds i16, i16* %83, i64 4
  %86 = bitcast i16* %85 to i64*
  store i64 %13, i64* %86, align 8
  %87 = getelementptr inbounds i16, i16* %83, i64 8
  %88 = bitcast i16* %87 to i64*
  store i64 %16, i64* %88, align 8
  %89 = getelementptr inbounds i16, i16* %83, i64 12
  %90 = bitcast i16* %89 to i64*
  store i64 %19, i64* %90, align 8
  %91 = ashr exact i64 %20, 29
  %92 = getelementptr inbounds i16, i16* %3, i64 %91
  %93 = bitcast i16* %92 to i64*
  store i64 %10, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %13, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 %16, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 %19, i64* %99, align 8
  %100 = mul nsw i64 %21, 9
  %101 = getelementptr inbounds i16, i16* %3, i64 %100
  %102 = bitcast i16* %101 to i64*
  store i64 %10, i64* %102, align 8
  %103 = getelementptr inbounds i16, i16* %101, i64 4
  %104 = bitcast i16* %103 to i64*
  store i64 %13, i64* %104, align 8
  %105 = getelementptr inbounds i16, i16* %101, i64 8
  %106 = bitcast i16* %105 to i64*
  store i64 %16, i64* %106, align 8
  %107 = getelementptr inbounds i16, i16* %101, i64 12
  %108 = bitcast i16* %107 to i64*
  store i64 %19, i64* %108, align 8
  %109 = mul nsw i64 %21, 10
  %110 = getelementptr inbounds i16, i16* %3, i64 %109
  %111 = bitcast i16* %110 to i64*
  store i64 %10, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %110, i64 4
  %113 = bitcast i16* %112 to i64*
  store i64 %13, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %110, i64 8
  %115 = bitcast i16* %114 to i64*
  store i64 %16, i64* %115, align 8
  %116 = getelementptr inbounds i16, i16* %110, i64 12
  %117 = bitcast i16* %116 to i64*
  store i64 %19, i64* %117, align 8
  %118 = mul nsw i64 %21, 11
  %119 = getelementptr inbounds i16, i16* %3, i64 %118
  %120 = bitcast i16* %119 to i64*
  store i64 %10, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %119, i64 4
  %122 = bitcast i16* %121 to i64*
  store i64 %13, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %119, i64 8
  %124 = bitcast i16* %123 to i64*
  store i64 %16, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %119, i64 12
  %126 = bitcast i16* %125 to i64*
  store i64 %19, i64* %126, align 8
  %127 = mul nsw i64 %21, 12
  %128 = getelementptr inbounds i16, i16* %3, i64 %127
  %129 = bitcast i16* %128 to i64*
  store i64 %10, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %13, i64* %131, align 8
  %132 = getelementptr inbounds i16, i16* %128, i64 8
  %133 = bitcast i16* %132 to i64*
  store i64 %16, i64* %133, align 8
  %134 = getelementptr inbounds i16, i16* %128, i64 12
  %135 = bitcast i16* %134 to i64*
  store i64 %19, i64* %135, align 8
  %136 = mul nsw i64 %21, 13
  %137 = getelementptr inbounds i16, i16* %3, i64 %136
  %138 = bitcast i16* %137 to i64*
  store i64 %10, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %137, i64 4
  %140 = bitcast i16* %139 to i64*
  store i64 %13, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %137, i64 8
  %142 = bitcast i16* %141 to i64*
  store i64 %16, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %137, i64 12
  %144 = bitcast i16* %143 to i64*
  store i64 %19, i64* %144, align 8
  %145 = mul nsw i64 %21, 14
  %146 = getelementptr inbounds i16, i16* %3, i64 %145
  %147 = bitcast i16* %146 to i64*
  store i64 %10, i64* %147, align 8
  %148 = getelementptr inbounds i16, i16* %146, i64 4
  %149 = bitcast i16* %148 to i64*
  store i64 %13, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %146, i64 8
  %151 = bitcast i16* %150 to i64*
  store i64 %16, i64* %151, align 8
  %152 = getelementptr inbounds i16, i16* %146, i64 12
  %153 = bitcast i16* %152 to i64*
  store i64 %19, i64* %153, align 8
  %154 = mul nsw i64 %21, 15
  %155 = getelementptr inbounds i16, i16* %3, i64 %154
  %156 = bitcast i16* %155 to i64*
  store i64 %10, i64* %156, align 8
  %157 = getelementptr inbounds i16, i16* %155, i64 4
  %158 = bitcast i16* %157 to i64*
  store i64 %13, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %155, i64 8
  %160 = bitcast i16* %159 to i64*
  store i64 %16, i64* %160, align 8
  %161 = getelementptr inbounds i16, i16* %155, i64 12
  %162 = bitcast i16* %161 to i64*
  store i64 %19, i64* %162, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_horizontal_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = mul nuw i64 %8, 281479271743489
  %10 = bitcast i8* %0 to i64*
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to i64*
  store i64 %9, i64* %12, align 8
  %13 = getelementptr inbounds i8, i8* %0, i64 16
  %14 = bitcast i8* %13 to i64*
  store i64 %9, i64* %14, align 8
  %15 = getelementptr inbounds i8, i8* %0, i64 24
  %16 = bitcast i8* %15 to i64*
  store i64 %9, i64* %16, align 8
  %17 = add nsw i64 %4, -1
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = mul nuw i64 %20, 281479271743489
  %22 = getelementptr inbounds i16, i16* %3, i64 %4
  %23 = bitcast i16* %22 to i64*
  store i64 %21, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %22, i64 4
  %25 = bitcast i16* %24 to i64*
  store i64 %21, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %22, i64 8
  %27 = bitcast i16* %26 to i64*
  store i64 %21, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %22, i64 12
  %29 = bitcast i16* %28 to i64*
  store i64 %21, i64* %29, align 8
  %30 = and i64 %1, -2
  %31 = add nsw i64 %30, -1
  %32 = getelementptr inbounds i16, i16* %3, i64 %31
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i64
  %35 = mul nuw i64 %34, 281479271743489
  %36 = getelementptr inbounds i16, i16* %3, i64 %30
  %37 = bitcast i16* %36 to i64*
  store i64 %35, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 %35, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 %35, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 %35, i64* %43, align 8
  %44 = mul nsw i64 %4, 3
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = mul nuw i64 %48, 281479271743489
  %50 = getelementptr inbounds i16, i16* %3, i64 %44
  %51 = bitcast i16* %50 to i64*
  store i64 %49, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %50, i64 4
  %53 = bitcast i16* %52 to i64*
  store i64 %49, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %50, i64 8
  %55 = bitcast i16* %54 to i64*
  store i64 %49, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %50, i64 12
  %57 = bitcast i16* %56 to i64*
  store i64 %49, i64* %57, align 8
  %58 = shl nsw i64 %4, 2
  %59 = add nsw i64 %58, -1
  %60 = getelementptr inbounds i16, i16* %3, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i64
  %63 = mul nuw i64 %62, 281479271743489
  %64 = getelementptr inbounds i16, i16* %3, i64 %58
  %65 = bitcast i16* %64 to i64*
  store i64 %63, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %64, i64 4
  %67 = bitcast i16* %66 to i64*
  store i64 %63, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %64, i64 8
  %69 = bitcast i16* %68 to i64*
  store i64 %63, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %64, i64 12
  %71 = bitcast i16* %70 to i64*
  store i64 %63, i64* %71, align 8
  %72 = mul nsw i64 %4, 5
  %73 = add nsw i64 %72, -1
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i64
  %77 = mul nuw i64 %76, 281479271743489
  %78 = getelementptr inbounds i16, i16* %3, i64 %72
  %79 = bitcast i16* %78 to i64*
  store i64 %77, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %77, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %78, i64 8
  %83 = bitcast i16* %82 to i64*
  store i64 %77, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %78, i64 12
  %85 = bitcast i16* %84 to i64*
  store i64 %77, i64* %85, align 8
  %86 = mul nsw i64 %4, 6
  %87 = add nsw i64 %86, -1
  %88 = getelementptr inbounds i16, i16* %3, i64 %87
  %89 = load i16, i16* %88, align 2
  %90 = zext i16 %89 to i64
  %91 = mul nuw i64 %90, 281479271743489
  %92 = getelementptr inbounds i16, i16* %3, i64 %86
  %93 = bitcast i16* %92 to i64*
  store i64 %91, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %91, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 %91, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 %91, i64* %99, align 8
  %100 = mul nsw i64 %4, 7
  %101 = add nsw i64 %100, -1
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i64
  %105 = mul nuw i64 %104, 281479271743489
  %106 = getelementptr inbounds i16, i16* %3, i64 %100
  %107 = bitcast i16* %106 to i64*
  store i64 %105, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %106, i64 4
  %109 = bitcast i16* %108 to i64*
  store i64 %105, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %106, i64 8
  %111 = bitcast i16* %110 to i64*
  store i64 %105, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %106, i64 12
  %113 = bitcast i16* %112 to i64*
  store i64 %105, i64* %113, align 8
  %114 = shl nsw i64 %4, 3
  %115 = add nsw i64 %114, -1
  %116 = getelementptr inbounds i16, i16* %3, i64 %115
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i64
  %119 = mul nuw i64 %118, 281479271743489
  %120 = getelementptr inbounds i16, i16* %3, i64 %114
  %121 = bitcast i16* %120 to i64*
  store i64 %119, i64* %121, align 8
  %122 = getelementptr inbounds i16, i16* %120, i64 4
  %123 = bitcast i16* %122 to i64*
  store i64 %119, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %120, i64 8
  %125 = bitcast i16* %124 to i64*
  store i64 %119, i64* %125, align 8
  %126 = getelementptr inbounds i16, i16* %120, i64 12
  %127 = bitcast i16* %126 to i64*
  store i64 %119, i64* %127, align 8
  %128 = mul nsw i64 %4, 9
  %129 = add nsw i64 %128, -1
  %130 = getelementptr inbounds i16, i16* %3, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i64
  %133 = mul nuw i64 %132, 281479271743489
  %134 = getelementptr inbounds i16, i16* %3, i64 %128
  %135 = bitcast i16* %134 to i64*
  store i64 %133, i64* %135, align 8
  %136 = getelementptr inbounds i16, i16* %134, i64 4
  %137 = bitcast i16* %136 to i64*
  store i64 %133, i64* %137, align 8
  %138 = getelementptr inbounds i16, i16* %134, i64 8
  %139 = bitcast i16* %138 to i64*
  store i64 %133, i64* %139, align 8
  %140 = getelementptr inbounds i16, i16* %134, i64 12
  %141 = bitcast i16* %140 to i64*
  store i64 %133, i64* %141, align 8
  %142 = mul nsw i64 %4, 10
  %143 = add nsw i64 %142, -1
  %144 = getelementptr inbounds i16, i16* %3, i64 %143
  %145 = load i16, i16* %144, align 2
  %146 = zext i16 %145 to i64
  %147 = mul nuw i64 %146, 281479271743489
  %148 = getelementptr inbounds i16, i16* %3, i64 %142
  %149 = bitcast i16* %148 to i64*
  store i64 %147, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %148, i64 4
  %151 = bitcast i16* %150 to i64*
  store i64 %147, i64* %151, align 8
  %152 = getelementptr inbounds i16, i16* %148, i64 8
  %153 = bitcast i16* %152 to i64*
  store i64 %147, i64* %153, align 8
  %154 = getelementptr inbounds i16, i16* %148, i64 12
  %155 = bitcast i16* %154 to i64*
  store i64 %147, i64* %155, align 8
  %156 = mul nsw i64 %4, 11
  %157 = add nsw i64 %156, -1
  %158 = getelementptr inbounds i16, i16* %3, i64 %157
  %159 = load i16, i16* %158, align 2
  %160 = zext i16 %159 to i64
  %161 = mul nuw i64 %160, 281479271743489
  %162 = getelementptr inbounds i16, i16* %3, i64 %156
  %163 = bitcast i16* %162 to i64*
  store i64 %161, i64* %163, align 8
  %164 = getelementptr inbounds i16, i16* %162, i64 4
  %165 = bitcast i16* %164 to i64*
  store i64 %161, i64* %165, align 8
  %166 = getelementptr inbounds i16, i16* %162, i64 8
  %167 = bitcast i16* %166 to i64*
  store i64 %161, i64* %167, align 8
  %168 = getelementptr inbounds i16, i16* %162, i64 12
  %169 = bitcast i16* %168 to i64*
  store i64 %161, i64* %169, align 8
  %170 = mul nsw i64 %4, 12
  %171 = add nsw i64 %170, -1
  %172 = getelementptr inbounds i16, i16* %3, i64 %171
  %173 = load i16, i16* %172, align 2
  %174 = zext i16 %173 to i64
  %175 = mul nuw i64 %174, 281479271743489
  %176 = getelementptr inbounds i16, i16* %3, i64 %170
  %177 = bitcast i16* %176 to i64*
  store i64 %175, i64* %177, align 8
  %178 = getelementptr inbounds i16, i16* %176, i64 4
  %179 = bitcast i16* %178 to i64*
  store i64 %175, i64* %179, align 8
  %180 = getelementptr inbounds i16, i16* %176, i64 8
  %181 = bitcast i16* %180 to i64*
  store i64 %175, i64* %181, align 8
  %182 = getelementptr inbounds i16, i16* %176, i64 12
  %183 = bitcast i16* %182 to i64*
  store i64 %175, i64* %183, align 8
  %184 = mul nsw i64 %4, 13
  %185 = add nsw i64 %184, -1
  %186 = getelementptr inbounds i16, i16* %3, i64 %185
  %187 = load i16, i16* %186, align 2
  %188 = zext i16 %187 to i64
  %189 = mul nuw i64 %188, 281479271743489
  %190 = getelementptr inbounds i16, i16* %3, i64 %184
  %191 = bitcast i16* %190 to i64*
  store i64 %189, i64* %191, align 8
  %192 = getelementptr inbounds i16, i16* %190, i64 4
  %193 = bitcast i16* %192 to i64*
  store i64 %189, i64* %193, align 8
  %194 = getelementptr inbounds i16, i16* %190, i64 8
  %195 = bitcast i16* %194 to i64*
  store i64 %189, i64* %195, align 8
  %196 = getelementptr inbounds i16, i16* %190, i64 12
  %197 = bitcast i16* %196 to i64*
  store i64 %189, i64* %197, align 8
  %198 = mul nsw i64 %4, 14
  %199 = add nsw i64 %198, -1
  %200 = getelementptr inbounds i16, i16* %3, i64 %199
  %201 = load i16, i16* %200, align 2
  %202 = zext i16 %201 to i64
  %203 = mul nuw i64 %202, 281479271743489
  %204 = getelementptr inbounds i16, i16* %3, i64 %198
  %205 = bitcast i16* %204 to i64*
  store i64 %203, i64* %205, align 8
  %206 = getelementptr inbounds i16, i16* %204, i64 4
  %207 = bitcast i16* %206 to i64*
  store i64 %203, i64* %207, align 8
  %208 = getelementptr inbounds i16, i16* %204, i64 8
  %209 = bitcast i16* %208 to i64*
  store i64 %203, i64* %209, align 8
  %210 = getelementptr inbounds i16, i16* %204, i64 12
  %211 = bitcast i16* %210 to i64*
  store i64 %203, i64* %211, align 8
  %212 = mul nsw i64 %4, 15
  %213 = add nsw i64 %212, -1
  %214 = getelementptr inbounds i16, i16* %3, i64 %213
  %215 = load i16, i16* %214, align 2
  %216 = zext i16 %215 to i64
  %217 = mul nuw i64 %216, 281479271743489
  %218 = getelementptr inbounds i16, i16* %3, i64 %212
  %219 = bitcast i16* %218 to i64*
  store i64 %217, i64* %219, align 8
  %220 = getelementptr inbounds i16, i16* %218, i64 4
  %221 = bitcast i16* %220 to i64*
  store i64 %217, i64* %221, align 8
  %222 = getelementptr inbounds i16, i16* %218, i64 8
  %223 = bitcast i16* %222 to i64*
  store i64 %217, i64* %223, align 8
  %224 = getelementptr inbounds i16, i16* %218, i64 12
  %225 = bitcast i16* %224 to i64*
  store i64 %217, i64* %225, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_plane_svq3_c(i8* nocapture, i64) #1 {
  tail call fastcc void @pred16x16_plane_compat_8_c(i8* %0, i64 %1, i32 1, i32 0)
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_plane_rv40_c(i8* nocapture, i64) #1 {
  tail call fastcc void @pred16x16_plane_compat_8_c(i8* %0, i64 %1, i32 0, i32 1)
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_tm_vp8_c(i8* nocapture, i64) #1 {
  %3 = xor i64 %1, -1
  %4 = getelementptr inbounds i8, i8* %0, i64 %3
  %5 = load i8, i8* %4, align 1
  %6 = zext i8 %5 to i64
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i8, i8* getelementptr inbounds ([2304 x i8], [2304 x i8]* @ff_crop_tab, i64 0, i64 1024), i64 %7
  %9 = sub i64 0, %1
  %10 = getelementptr inbounds i8, i8* %0, i64 %9
  %11 = getelementptr inbounds i8, i8* %10, i64 1
  %12 = getelementptr inbounds i8, i8* %10, i64 2
  %13 = getelementptr inbounds i8, i8* %10, i64 3
  %14 = getelementptr inbounds i8, i8* %10, i64 4
  %15 = getelementptr inbounds i8, i8* %10, i64 5
  %16 = getelementptr inbounds i8, i8* %10, i64 6
  %17 = getelementptr inbounds i8, i8* %10, i64 7
  %18 = getelementptr inbounds i8, i8* %10, i64 8
  %19 = getelementptr inbounds i8, i8* %10, i64 9
  %20 = getelementptr inbounds i8, i8* %10, i64 10
  %21 = getelementptr inbounds i8, i8* %10, i64 11
  %22 = getelementptr inbounds i8, i8* %10, i64 12
  %23 = getelementptr inbounds i8, i8* %10, i64 13
  %24 = getelementptr inbounds i8, i8* %10, i64 14
  %25 = getelementptr inbounds i8, i8* %10, i64 15
  br label %26

26:                                               ; preds = %26, %2
  %27 = phi i8* [ %0, %2 ], [ %112, %26 ]
  %28 = phi i32 [ 0, %2 ], [ %113, %26 ]
  %29 = getelementptr inbounds i8, i8* %27, i64 -1
  %30 = load i8, i8* %29, align 1
  %31 = zext i8 %30 to i64
  %32 = getelementptr inbounds i8, i8* %8, i64 %31
  %33 = load i8, i8* %10, align 1
  %34 = zext i8 %33 to i64
  %35 = getelementptr inbounds i8, i8* %32, i64 %34
  %36 = load i8, i8* %35, align 1
  store i8 %36, i8* %27, align 1
  %37 = load i8, i8* %11, align 1
  %38 = zext i8 %37 to i64
  %39 = getelementptr inbounds i8, i8* %32, i64 %38
  %40 = load i8, i8* %39, align 1
  %41 = getelementptr inbounds i8, i8* %27, i64 1
  store i8 %40, i8* %41, align 1
  %42 = load i8, i8* %12, align 1
  %43 = zext i8 %42 to i64
  %44 = getelementptr inbounds i8, i8* %32, i64 %43
  %45 = load i8, i8* %44, align 1
  %46 = getelementptr inbounds i8, i8* %27, i64 2
  store i8 %45, i8* %46, align 1
  %47 = load i8, i8* %13, align 1
  %48 = zext i8 %47 to i64
  %49 = getelementptr inbounds i8, i8* %32, i64 %48
  %50 = load i8, i8* %49, align 1
  %51 = getelementptr inbounds i8, i8* %27, i64 3
  store i8 %50, i8* %51, align 1
  %52 = load i8, i8* %14, align 1
  %53 = zext i8 %52 to i64
  %54 = getelementptr inbounds i8, i8* %32, i64 %53
  %55 = load i8, i8* %54, align 1
  %56 = getelementptr inbounds i8, i8* %27, i64 4
  store i8 %55, i8* %56, align 1
  %57 = load i8, i8* %15, align 1
  %58 = zext i8 %57 to i64
  %59 = getelementptr inbounds i8, i8* %32, i64 %58
  %60 = load i8, i8* %59, align 1
  %61 = getelementptr inbounds i8, i8* %27, i64 5
  store i8 %60, i8* %61, align 1
  %62 = load i8, i8* %16, align 1
  %63 = zext i8 %62 to i64
  %64 = getelementptr inbounds i8, i8* %32, i64 %63
  %65 = load i8, i8* %64, align 1
  %66 = getelementptr inbounds i8, i8* %27, i64 6
  store i8 %65, i8* %66, align 1
  %67 = load i8, i8* %17, align 1
  %68 = zext i8 %67 to i64
  %69 = getelementptr inbounds i8, i8* %32, i64 %68
  %70 = load i8, i8* %69, align 1
  %71 = getelementptr inbounds i8, i8* %27, i64 7
  store i8 %70, i8* %71, align 1
  %72 = load i8, i8* %18, align 1
  %73 = zext i8 %72 to i64
  %74 = getelementptr inbounds i8, i8* %32, i64 %73
  %75 = load i8, i8* %74, align 1
  %76 = getelementptr inbounds i8, i8* %27, i64 8
  store i8 %75, i8* %76, align 1
  %77 = load i8, i8* %19, align 1
  %78 = zext i8 %77 to i64
  %79 = getelementptr inbounds i8, i8* %32, i64 %78
  %80 = load i8, i8* %79, align 1
  %81 = getelementptr inbounds i8, i8* %27, i64 9
  store i8 %80, i8* %81, align 1
  %82 = load i8, i8* %20, align 1
  %83 = zext i8 %82 to i64
  %84 = getelementptr inbounds i8, i8* %32, i64 %83
  %85 = load i8, i8* %84, align 1
  %86 = getelementptr inbounds i8, i8* %27, i64 10
  store i8 %85, i8* %86, align 1
  %87 = load i8, i8* %21, align 1
  %88 = zext i8 %87 to i64
  %89 = getelementptr inbounds i8, i8* %32, i64 %88
  %90 = load i8, i8* %89, align 1
  %91 = getelementptr inbounds i8, i8* %27, i64 11
  store i8 %90, i8* %91, align 1
  %92 = load i8, i8* %22, align 1
  %93 = zext i8 %92 to i64
  %94 = getelementptr inbounds i8, i8* %32, i64 %93
  %95 = load i8, i8* %94, align 1
  %96 = getelementptr inbounds i8, i8* %27, i64 12
  store i8 %95, i8* %96, align 1
  %97 = load i8, i8* %23, align 1
  %98 = zext i8 %97 to i64
  %99 = getelementptr inbounds i8, i8* %32, i64 %98
  %100 = load i8, i8* %99, align 1
  %101 = getelementptr inbounds i8, i8* %27, i64 13
  store i8 %100, i8* %101, align 1
  %102 = load i8, i8* %24, align 1
  %103 = zext i8 %102 to i64
  %104 = getelementptr inbounds i8, i8* %32, i64 %103
  %105 = load i8, i8* %104, align 1
  %106 = getelementptr inbounds i8, i8* %27, i64 14
  store i8 %105, i8* %106, align 1
  %107 = load i8, i8* %25, align 1
  %108 = zext i8 %107 to i64
  %109 = getelementptr inbounds i8, i8* %32, i64 %108
  %110 = load i8, i8* %109, align 1
  %111 = getelementptr inbounds i8, i8* %27, i64 15
  store i8 %110, i8* %111, align 1
  %112 = getelementptr inbounds i8, i8* %27, i64 %1
  %113 = add nuw nsw i32 %28, 1
  %114 = icmp eq i32 %113, 16
  br i1 %114, label %115, label %26

115:                                              ; preds = %26
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_127_dc_9_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i8, i8* %0, i64 16
  %7 = bitcast i8* %6 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %7, align 8
  %8 = getelementptr inbounds i16, i16* %3, i64 %4
  %9 = bitcast i16* %8 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %9, align 8
  %10 = getelementptr inbounds i16, i16* %8, i64 8
  %11 = bitcast i16* %10 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %11, align 8
  %12 = getelementptr inbounds i16, i16* %8, i64 %4
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %13, align 8
  %14 = getelementptr inbounds i16, i16* %12, i64 8
  %15 = bitcast i16* %14 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %15, align 8
  %16 = getelementptr inbounds i16, i16* %12, i64 %4
  %17 = bitcast i16* %16 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %17, align 8
  %18 = getelementptr inbounds i16, i16* %16, i64 8
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 71777214294589695, i64 71777214294589695>, <2 x i64>* %19, align 8
  %20 = getelementptr inbounds i16, i16* %16, i64 %4
  %21 = bitcast i16* %20 to i64*
  store i64 71777214294589695, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 4
  %23 = bitcast i16* %22 to i64*
  store i64 71777214294589695, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 8
  %25 = bitcast i16* %24 to i64*
  store i64 71777214294589695, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 12
  %27 = bitcast i16* %26 to i64*
  store i64 71777214294589695, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %20, i64 %4
  %29 = bitcast i16* %28 to i64*
  store i64 71777214294589695, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 71777214294589695, i64* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 8
  %33 = bitcast i16* %32 to i64*
  store i64 71777214294589695, i64* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 12
  %35 = bitcast i16* %34 to i64*
  store i64 71777214294589695, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %4
  %37 = bitcast i16* %36 to i64*
  store i64 71777214294589695, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 71777214294589695, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 71777214294589695, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 71777214294589695, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %36, i64 %4
  %45 = bitcast i16* %44 to i64*
  store i64 71777214294589695, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 71777214294589695, i64* %47, align 8
  %48 = getelementptr inbounds i16, i16* %44, i64 8
  %49 = bitcast i16* %48 to i64*
  store i64 71777214294589695, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %44, i64 12
  %51 = bitcast i16* %50 to i64*
  store i64 71777214294589695, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %44, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 71777214294589695, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 71777214294589695, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %52, i64 8
  %57 = bitcast i16* %56 to i64*
  store i64 71777214294589695, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %52, i64 12
  %59 = bitcast i16* %58 to i64*
  store i64 71777214294589695, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %52, i64 %4
  %61 = bitcast i16* %60 to i64*
  store i64 71777214294589695, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %60, i64 4
  %63 = bitcast i16* %62 to i64*
  store i64 71777214294589695, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %60, i64 8
  %65 = bitcast i16* %64 to i64*
  store i64 71777214294589695, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %60, i64 12
  %67 = bitcast i16* %66 to i64*
  store i64 71777214294589695, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %60, i64 %4
  %69 = bitcast i16* %68 to i64*
  store i64 71777214294589695, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 71777214294589695, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %68, i64 8
  %73 = bitcast i16* %72 to i64*
  store i64 71777214294589695, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %68, i64 12
  %75 = bitcast i16* %74 to i64*
  store i64 71777214294589695, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %68, i64 %4
  %77 = bitcast i16* %76 to i64*
  store i64 71777214294589695, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %76, i64 4
  %79 = bitcast i16* %78 to i64*
  store i64 71777214294589695, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %76, i64 8
  %81 = bitcast i16* %80 to i64*
  store i64 71777214294589695, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %76, i64 12
  %83 = bitcast i16* %82 to i64*
  store i64 71777214294589695, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %76, i64 %4
  %85 = bitcast i16* %84 to i64*
  store i64 71777214294589695, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 71777214294589695, i64* %87, align 8
  %88 = getelementptr inbounds i16, i16* %84, i64 8
  %89 = bitcast i16* %88 to i64*
  store i64 71777214294589695, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %84, i64 12
  %91 = bitcast i16* %90 to i64*
  store i64 71777214294589695, i64* %91, align 8
  %92 = getelementptr inbounds i16, i16* %84, i64 %4
  %93 = bitcast i16* %92 to i64*
  store i64 71777214294589695, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 71777214294589695, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 71777214294589695, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 71777214294589695, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %92, i64 %4
  %101 = bitcast i16* %100 to i64*
  store i64 71777214294589695, i64* %101, align 8
  %102 = getelementptr inbounds i16, i16* %100, i64 4
  %103 = bitcast i16* %102 to i64*
  store i64 71777214294589695, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %100, i64 8
  %105 = bitcast i16* %104 to i64*
  store i64 71777214294589695, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %100, i64 12
  %107 = bitcast i16* %106 to i64*
  store i64 71777214294589695, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %100, i64 %4
  %109 = bitcast i16* %108 to i64*
  store i64 71777214294589695, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 71777214294589695, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %108, i64 8
  %113 = bitcast i16* %112 to i64*
  store i64 71777214294589695, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %108, i64 12
  %115 = bitcast i16* %114 to i64*
  store i64 71777214294589695, i64* %115, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_129_dc_9_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i16, i16* %3, i64 %4
  %6 = bitcast i16* %5 to i64*
  call void @llvm.memset.p0i8.i64(i8* align 8 %0, i8 1, i64 32, i1 false)
  store i64 72340172838076673, i64* %6, align 8
  %7 = getelementptr inbounds i16, i16* %5, i64 4
  %8 = getelementptr inbounds i16, i16* %5, i64 %4
  %9 = bitcast i16* %8 to i64*
  %10 = bitcast i16* %7 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %10, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %9, align 8
  %11 = getelementptr inbounds i16, i16* %8, i64 4
  %12 = getelementptr inbounds i16, i16* %8, i64 %4
  %13 = bitcast i16* %12 to i64*
  %14 = bitcast i16* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %14, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %13, align 8
  %15 = getelementptr inbounds i16, i16* %12, i64 4
  %16 = getelementptr inbounds i16, i16* %12, i64 %4
  %17 = bitcast i16* %16 to i64*
  %18 = bitcast i16* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %18, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %17, align 8
  %19 = getelementptr inbounds i16, i16* %16, i64 4
  %20 = getelementptr inbounds i16, i16* %16, i64 %4
  %21 = bitcast i16* %20 to i64*
  %22 = bitcast i16* %19 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %22, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %21, align 8
  %23 = getelementptr inbounds i16, i16* %20, i64 4
  %24 = getelementptr inbounds i16, i16* %20, i64 %4
  %25 = bitcast i16* %24 to i64*
  %26 = bitcast i16* %23 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %26, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %25, align 8
  %27 = getelementptr inbounds i16, i16* %24, i64 4
  %28 = getelementptr inbounds i16, i16* %24, i64 %4
  %29 = bitcast i16* %28 to i64*
  %30 = bitcast i16* %27 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %30, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %29, align 8
  %31 = getelementptr inbounds i16, i16* %28, i64 4
  %32 = getelementptr inbounds i16, i16* %28, i64 %4
  %33 = bitcast i16* %32 to i64*
  %34 = bitcast i16* %31 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %34, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %33, align 8
  %35 = getelementptr inbounds i16, i16* %32, i64 4
  %36 = getelementptr inbounds i16, i16* %32, i64 %4
  %37 = bitcast i16* %36 to i64*
  %38 = bitcast i16* %35 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %38, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %37, align 8
  %39 = getelementptr inbounds i16, i16* %36, i64 4
  %40 = getelementptr inbounds i16, i16* %36, i64 %4
  %41 = bitcast i16* %40 to i64*
  %42 = bitcast i16* %39 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %42, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %41, align 8
  %43 = getelementptr inbounds i16, i16* %40, i64 4
  %44 = getelementptr inbounds i16, i16* %40, i64 %4
  %45 = bitcast i16* %44 to i64*
  %46 = bitcast i16* %43 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %46, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %45, align 8
  %47 = getelementptr inbounds i16, i16* %44, i64 4
  %48 = getelementptr inbounds i16, i16* %44, i64 %4
  %49 = bitcast i16* %48 to i64*
  %50 = bitcast i16* %47 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %50, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %49, align 8
  %51 = getelementptr inbounds i16, i16* %48, i64 4
  %52 = getelementptr inbounds i16, i16* %48, i64 %4
  %53 = bitcast i16* %52 to i64*
  %54 = bitcast i16* %51 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %54, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %53, align 8
  %55 = getelementptr inbounds i16, i16* %52, i64 4
  %56 = getelementptr inbounds i16, i16* %52, i64 %4
  %57 = bitcast i16* %56 to i64*
  %58 = bitcast i16* %55 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %58, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %57, align 8
  %59 = getelementptr inbounds i16, i16* %56, i64 4
  %60 = getelementptr inbounds i16, i16* %56, i64 %4
  %61 = bitcast i16* %60 to i64*
  %62 = bitcast i16* %59 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %62, i8 1, i64 24, i1 false)
  store i64 72340172838076673, i64* %61, align 8
  %63 = getelementptr inbounds i16, i16* %60, i64 4
  %64 = bitcast i16* %63 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %64, i8 1, i64 24, i1 false)
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_plane_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 14
  %6 = bitcast i8* %5 to i16*
  %7 = shl i64 %4, 32
  %8 = ashr exact i64 %7, 32
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i16, i16* %6, i64 %9
  %11 = shl i64 %4, 35
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = getelementptr inbounds i16, i16* %13, i64 -1
  %15 = shl i64 %1, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = sub nsw i64 0, %17
  %19 = getelementptr inbounds i16, i16* %14, i64 %18
  %20 = getelementptr inbounds i16, i16* %10, i64 1
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = getelementptr inbounds i16, i16* %10, i64 -1
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = sub nsw i32 %22, %25
  %27 = load i16, i16* %14, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %19, align 2
  %30 = zext i16 %29 to i32
  %31 = sub nsw i32 %28, %30
  %32 = mul nsw i64 %8, 14
  %33 = ashr exact i64 %11, 31
  %34 = add nsw i64 %33, -2
  %35 = add nsw i64 %34, %32
  %36 = getelementptr i8, i8* %0, i64 %35
  %37 = lshr i64 %16, 1
  %38 = shl i64 %37, 2
  %39 = sub i64 %34, %38
  %40 = sub i64 %39, %32
  %41 = getelementptr i8, i8* %0, i64 %40
  %42 = getelementptr inbounds i16, i16* %14, i64 %8
  %43 = getelementptr inbounds i16, i16* %19, i64 %9
  %44 = getelementptr inbounds i16, i16* %10, i64 2
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = getelementptr inbounds i16, i16* %10, i64 -2
  %48 = load i16, i16* %47, align 2
  %49 = zext i16 %48 to i32
  %50 = sub nsw i32 %46, %49
  %51 = shl nsw i32 %50, 1
  %52 = add nsw i32 %26, %51
  %53 = load i16, i16* %42, align 2
  %54 = zext i16 %53 to i32
  %55 = load i16, i16* %43, align 2
  %56 = zext i16 %55 to i32
  %57 = sub nsw i32 %54, %56
  %58 = shl nsw i32 %57, 1
  %59 = add nsw i32 %31, %58
  %60 = getelementptr inbounds i16, i16* %42, i64 %8
  %61 = getelementptr inbounds i16, i16* %43, i64 %9
  %62 = getelementptr inbounds i16, i16* %10, i64 3
  %63 = load i16, i16* %62, align 2
  %64 = zext i16 %63 to i32
  %65 = getelementptr inbounds i16, i16* %10, i64 -3
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = sub nsw i32 %64, %67
  %69 = mul nsw i32 %68, 3
  %70 = add nsw i32 %52, %69
  %71 = load i16, i16* %60, align 2
  %72 = zext i16 %71 to i32
  %73 = load i16, i16* %61, align 2
  %74 = zext i16 %73 to i32
  %75 = sub nsw i32 %72, %74
  %76 = mul nsw i32 %75, 3
  %77 = add nsw i32 %59, %76
  %78 = getelementptr inbounds i16, i16* %60, i64 %8
  %79 = getelementptr inbounds i16, i16* %61, i64 %9
  %80 = getelementptr inbounds i16, i16* %10, i64 4
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i32
  %83 = getelementptr inbounds i16, i16* %10, i64 -4
  %84 = load i16, i16* %83, align 2
  %85 = zext i16 %84 to i32
  %86 = sub nsw i32 %82, %85
  %87 = shl nsw i32 %86, 2
  %88 = add nsw i32 %70, %87
  %89 = load i16, i16* %78, align 2
  %90 = zext i16 %89 to i32
  %91 = load i16, i16* %79, align 2
  %92 = zext i16 %91 to i32
  %93 = sub nsw i32 %90, %92
  %94 = shl nsw i32 %93, 2
  %95 = add nsw i32 %77, %94
  %96 = getelementptr inbounds i16, i16* %78, i64 %8
  %97 = getelementptr inbounds i16, i16* %79, i64 %9
  %98 = getelementptr inbounds i16, i16* %10, i64 5
  %99 = load i16, i16* %98, align 2
  %100 = zext i16 %99 to i32
  %101 = getelementptr inbounds i16, i16* %10, i64 -5
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  %104 = sub nsw i32 %100, %103
  %105 = mul nsw i32 %104, 5
  %106 = add nsw i32 %88, %105
  %107 = load i16, i16* %96, align 2
  %108 = zext i16 %107 to i32
  %109 = load i16, i16* %97, align 2
  %110 = zext i16 %109 to i32
  %111 = sub nsw i32 %108, %110
  %112 = mul nsw i32 %111, 5
  %113 = add nsw i32 %95, %112
  %114 = getelementptr inbounds i16, i16* %96, i64 %8
  %115 = getelementptr inbounds i16, i16* %97, i64 %9
  %116 = getelementptr inbounds i16, i16* %10, i64 6
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = getelementptr inbounds i16, i16* %10, i64 -6
  %120 = load i16, i16* %119, align 2
  %121 = zext i16 %120 to i32
  %122 = sub nsw i32 %118, %121
  %123 = mul nsw i32 %122, 6
  %124 = add nsw i32 %106, %123
  %125 = load i16, i16* %114, align 2
  %126 = zext i16 %125 to i32
  %127 = load i16, i16* %115, align 2
  %128 = zext i16 %127 to i32
  %129 = sub nsw i32 %126, %128
  %130 = mul nsw i32 %129, 6
  %131 = add nsw i32 %113, %130
  %132 = getelementptr inbounds i16, i16* %114, i64 %8
  %133 = getelementptr inbounds i16, i16* %115, i64 %9
  %134 = getelementptr inbounds i16, i16* %10, i64 7
  %135 = load i16, i16* %134, align 2
  %136 = zext i16 %135 to i32
  %137 = getelementptr inbounds i16, i16* %10, i64 -7
  %138 = load i16, i16* %137, align 2
  %139 = zext i16 %138 to i32
  %140 = sub nsw i32 %136, %139
  %141 = mul nsw i32 %140, 7
  %142 = add nsw i32 %124, %141
  %143 = load i16, i16* %132, align 2
  %144 = zext i16 %143 to i32
  %145 = load i16, i16* %133, align 2
  %146 = zext i16 %145 to i32
  %147 = sub nsw i32 %144, %146
  %148 = mul nsw i32 %147, 7
  %149 = add nsw i32 %131, %148
  %150 = getelementptr inbounds i16, i16* %132, i64 %8
  %151 = getelementptr inbounds i16, i16* %133, i64 %9
  %152 = getelementptr inbounds i16, i16* %10, i64 8
  %153 = load i16, i16* %152, align 2
  %154 = zext i16 %153 to i32
  %155 = getelementptr inbounds i16, i16* %10, i64 -8
  %156 = load i16, i16* %155, align 2
  %157 = zext i16 %156 to i32
  %158 = sub nsw i32 %154, %157
  %159 = shl nsw i32 %158, 3
  %160 = add nsw i32 %142, %159
  %161 = load i16, i16* %150, align 2
  %162 = zext i16 %161 to i32
  %163 = load i16, i16* %151, align 2
  %164 = zext i16 %163 to i32
  %165 = sub nsw i32 %162, %164
  %166 = shl nsw i32 %165, 3
  %167 = add nsw i32 %149, %166
  %168 = bitcast i8* %36 to i16*
  %169 = mul nsw i32 %160, 5
  %170 = add nsw i32 %169, 32
  %171 = ashr i32 %170, 6
  %172 = mul nsw i32 %167, 5
  %173 = add nsw i32 %172, 32
  %174 = ashr i32 %173, 6
  %175 = load i16, i16* %168, align 2
  %176 = zext i16 %175 to i32
  %177 = getelementptr inbounds i8, i8* %41, i64 32
  %178 = bitcast i8* %177 to i16*
  %179 = load i16, i16* %178, align 2
  %180 = zext i16 %179 to i32
  %181 = add nuw nsw i32 %180, %176
  %182 = shl nuw nsw i32 %181, 4
  %183 = add nsw i32 %174, %171
  %184 = mul nsw i32 %183, -7
  %185 = add nuw nsw i32 %182, 16
  %186 = add nsw i32 %185, %184
  %187 = shl nsw i32 %171, 1
  %188 = mul nsw i32 %171, 3
  %189 = shl nsw i32 %171, 2
  br label %190

190:                                              ; preds = %364, %2
  %191 = phi i16* [ %3, %2 ], [ %369, %364 ]
  %192 = phi i32 [ %186, %2 ], [ %368, %364 ]
  %193 = phi i32 [ 16, %2 ], [ %370, %364 ]
  %194 = ashr i32 %192, 5
  %195 = icmp ult i32 %194, 512
  br i1 %195, label %200, label %196

196:                                              ; preds = %190
  %197 = ashr i32 %192, 31
  %198 = or i32 %197, -512
  %199 = xor i32 %198, -1
  br label %200

200:                                              ; preds = %196, %190
  %201 = phi i32 [ %199, %196 ], [ %194, %190 ]
  %202 = trunc i32 %201 to i16
  store i16 %202, i16* %191, align 2
  %203 = add nsw i32 %192, %171
  %204 = ashr i32 %203, 5
  %205 = icmp ult i32 %204, 512
  br i1 %205, label %210, label %206

206:                                              ; preds = %200
  %207 = ashr i32 %203, 31
  %208 = or i32 %207, -512
  %209 = xor i32 %208, -1
  br label %210

210:                                              ; preds = %206, %200
  %211 = phi i32 [ %209, %206 ], [ %204, %200 ]
  %212 = trunc i32 %211 to i16
  %213 = getelementptr inbounds i16, i16* %191, i64 1
  store i16 %212, i16* %213, align 2
  %214 = add nsw i32 %192, %187
  %215 = ashr i32 %214, 5
  %216 = icmp ult i32 %215, 512
  br i1 %216, label %221, label %217

217:                                              ; preds = %210
  %218 = ashr i32 %214, 31
  %219 = or i32 %218, -512
  %220 = xor i32 %219, -1
  br label %221

221:                                              ; preds = %217, %210
  %222 = phi i32 [ %220, %217 ], [ %215, %210 ]
  %223 = trunc i32 %222 to i16
  %224 = getelementptr inbounds i16, i16* %191, i64 2
  store i16 %223, i16* %224, align 2
  %225 = add nsw i32 %192, %188
  %226 = ashr i32 %225, 5
  %227 = icmp ult i32 %226, 512
  br i1 %227, label %232, label %228

228:                                              ; preds = %221
  %229 = ashr i32 %225, 31
  %230 = or i32 %229, -512
  %231 = xor i32 %230, -1
  br label %232

232:                                              ; preds = %228, %221
  %233 = phi i32 [ %231, %228 ], [ %226, %221 ]
  %234 = trunc i32 %233 to i16
  %235 = getelementptr inbounds i16, i16* %191, i64 3
  store i16 %234, i16* %235, align 2
  %236 = add nsw i32 %192, %189
  %237 = ashr i32 %236, 5
  %238 = icmp ult i32 %237, 512
  br i1 %238, label %243, label %239

239:                                              ; preds = %232
  %240 = ashr i32 %236, 31
  %241 = or i32 %240, -512
  %242 = xor i32 %241, -1
  br label %243

243:                                              ; preds = %239, %232
  %244 = phi i32 [ %242, %239 ], [ %237, %232 ]
  %245 = trunc i32 %244 to i16
  %246 = getelementptr inbounds i16, i16* %191, i64 4
  store i16 %245, i16* %246, align 2
  %247 = add nsw i32 %236, %171
  %248 = ashr i32 %247, 5
  %249 = icmp ult i32 %248, 512
  br i1 %249, label %254, label %250

250:                                              ; preds = %243
  %251 = ashr i32 %247, 31
  %252 = or i32 %251, -512
  %253 = xor i32 %252, -1
  br label %254

254:                                              ; preds = %250, %243
  %255 = phi i32 [ %253, %250 ], [ %248, %243 ]
  %256 = trunc i32 %255 to i16
  %257 = getelementptr inbounds i16, i16* %191, i64 5
  store i16 %256, i16* %257, align 2
  %258 = add nsw i32 %236, %187
  %259 = ashr i32 %258, 5
  %260 = icmp ult i32 %259, 512
  br i1 %260, label %265, label %261

261:                                              ; preds = %254
  %262 = ashr i32 %258, 31
  %263 = or i32 %262, -512
  %264 = xor i32 %263, -1
  br label %265

265:                                              ; preds = %261, %254
  %266 = phi i32 [ %264, %261 ], [ %259, %254 ]
  %267 = trunc i32 %266 to i16
  %268 = getelementptr inbounds i16, i16* %191, i64 6
  store i16 %267, i16* %268, align 2
  %269 = add nsw i32 %236, %188
  %270 = ashr i32 %269, 5
  %271 = icmp ult i32 %270, 512
  br i1 %271, label %276, label %272

272:                                              ; preds = %265
  %273 = ashr i32 %269, 31
  %274 = or i32 %273, -512
  %275 = xor i32 %274, -1
  br label %276

276:                                              ; preds = %272, %265
  %277 = phi i32 [ %275, %272 ], [ %270, %265 ]
  %278 = trunc i32 %277 to i16
  %279 = getelementptr inbounds i16, i16* %191, i64 7
  store i16 %278, i16* %279, align 2
  %280 = add nsw i32 %236, %189
  %281 = ashr i32 %280, 5
  %282 = icmp ult i32 %281, 512
  br i1 %282, label %287, label %283

283:                                              ; preds = %276
  %284 = ashr i32 %280, 31
  %285 = or i32 %284, -512
  %286 = xor i32 %285, -1
  br label %287

287:                                              ; preds = %283, %276
  %288 = phi i32 [ %286, %283 ], [ %281, %276 ]
  %289 = trunc i32 %288 to i16
  %290 = getelementptr inbounds i16, i16* %191, i64 8
  store i16 %289, i16* %290, align 2
  %291 = add nsw i32 %280, %171
  %292 = ashr i32 %291, 5
  %293 = icmp ult i32 %292, 512
  br i1 %293, label %298, label %294

294:                                              ; preds = %287
  %295 = ashr i32 %291, 31
  %296 = or i32 %295, -512
  %297 = xor i32 %296, -1
  br label %298

298:                                              ; preds = %294, %287
  %299 = phi i32 [ %297, %294 ], [ %292, %287 ]
  %300 = trunc i32 %299 to i16
  %301 = getelementptr inbounds i16, i16* %191, i64 9
  store i16 %300, i16* %301, align 2
  %302 = add nsw i32 %280, %187
  %303 = ashr i32 %302, 5
  %304 = icmp ult i32 %303, 512
  br i1 %304, label %309, label %305

305:                                              ; preds = %298
  %306 = ashr i32 %302, 31
  %307 = or i32 %306, -512
  %308 = xor i32 %307, -1
  br label %309

309:                                              ; preds = %305, %298
  %310 = phi i32 [ %308, %305 ], [ %303, %298 ]
  %311 = trunc i32 %310 to i16
  %312 = getelementptr inbounds i16, i16* %191, i64 10
  store i16 %311, i16* %312, align 2
  %313 = add nsw i32 %280, %188
  %314 = ashr i32 %313, 5
  %315 = icmp ult i32 %314, 512
  br i1 %315, label %320, label %316

316:                                              ; preds = %309
  %317 = ashr i32 %313, 31
  %318 = or i32 %317, -512
  %319 = xor i32 %318, -1
  br label %320

320:                                              ; preds = %316, %309
  %321 = phi i32 [ %319, %316 ], [ %314, %309 ]
  %322 = trunc i32 %321 to i16
  %323 = getelementptr inbounds i16, i16* %191, i64 11
  store i16 %322, i16* %323, align 2
  %324 = add nsw i32 %280, %189
  %325 = ashr i32 %324, 5
  %326 = icmp ult i32 %325, 512
  br i1 %326, label %331, label %327

327:                                              ; preds = %320
  %328 = ashr i32 %324, 31
  %329 = or i32 %328, -512
  %330 = xor i32 %329, -1
  br label %331

331:                                              ; preds = %327, %320
  %332 = phi i32 [ %330, %327 ], [ %325, %320 ]
  %333 = trunc i32 %332 to i16
  %334 = getelementptr inbounds i16, i16* %191, i64 12
  store i16 %333, i16* %334, align 2
  %335 = add nsw i32 %324, %171
  %336 = ashr i32 %335, 5
  %337 = icmp ult i32 %336, 512
  br i1 %337, label %342, label %338

338:                                              ; preds = %331
  %339 = ashr i32 %335, 31
  %340 = or i32 %339, -512
  %341 = xor i32 %340, -1
  br label %342

342:                                              ; preds = %338, %331
  %343 = phi i32 [ %341, %338 ], [ %336, %331 ]
  %344 = trunc i32 %343 to i16
  %345 = getelementptr inbounds i16, i16* %191, i64 13
  store i16 %344, i16* %345, align 2
  %346 = add nsw i32 %324, %187
  %347 = ashr i32 %346, 5
  %348 = icmp ult i32 %347, 512
  br i1 %348, label %353, label %349

349:                                              ; preds = %342
  %350 = ashr i32 %346, 31
  %351 = or i32 %350, -512
  %352 = xor i32 %351, -1
  br label %353

353:                                              ; preds = %349, %342
  %354 = phi i32 [ %352, %349 ], [ %347, %342 ]
  %355 = trunc i32 %354 to i16
  %356 = getelementptr inbounds i16, i16* %191, i64 14
  store i16 %355, i16* %356, align 2
  %357 = add nsw i32 %324, %188
  %358 = ashr i32 %357, 5
  %359 = icmp ult i32 %358, 512
  br i1 %359, label %364, label %360

360:                                              ; preds = %353
  %361 = ashr i32 %357, 31
  %362 = or i32 %361, -512
  %363 = xor i32 %362, -1
  br label %364

364:                                              ; preds = %360, %353
  %365 = phi i32 [ %363, %360 ], [ %358, %353 ]
  %366 = trunc i32 %365 to i16
  %367 = getelementptr inbounds i16, i16* %191, i64 15
  store i16 %366, i16* %367, align 2
  %368 = add nsw i32 %192, %174
  %369 = getelementptr inbounds i16, i16* %191, i64 %8
  %370 = add nsw i32 %193, -1
  %371 = icmp eq i32 %370, 0
  br i1 %371, label %372, label %190

372:                                              ; preds = %364
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_left_dc_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = add nsw i64 %4, -1
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = and i64 %1, -2
  %15 = add nsw i64 %14, -1
  %16 = getelementptr inbounds i16, i16* %3, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i64
  %19 = add nuw nsw i64 %13, %18
  %20 = mul nsw i64 %4, 3
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = add nuw nsw i64 %19, %24
  %26 = shl nsw i64 %4, 2
  %27 = add nsw i64 %26, -1
  %28 = getelementptr inbounds i16, i16* %3, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = zext i16 %29 to i64
  %31 = add nuw nsw i64 %25, %30
  %32 = mul nsw i64 %4, 5
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %31, %36
  %38 = mul nsw i64 %4, 6
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %37, %42
  %44 = mul nsw i64 %4, 7
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = add nuw nsw i64 %43, %48
  %50 = shl nsw i64 %4, 3
  %51 = add nsw i64 %50, -1
  %52 = getelementptr inbounds i16, i16* %3, i64 %51
  %53 = load i16, i16* %52, align 2
  %54 = zext i16 %53 to i64
  %55 = add nuw nsw i64 %49, %54
  %56 = mul nsw i64 %4, 9
  %57 = add nsw i64 %56, -1
  %58 = getelementptr inbounds i16, i16* %3, i64 %57
  %59 = load i16, i16* %58, align 2
  %60 = zext i16 %59 to i64
  %61 = add nuw nsw i64 %55, %60
  %62 = mul nsw i64 %4, 10
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = add nuw nsw i64 %61, %66
  %68 = mul nsw i64 %4, 11
  %69 = add nsw i64 %68, -1
  %70 = getelementptr inbounds i16, i16* %3, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i64
  %73 = add nuw nsw i64 %67, %72
  %74 = mul nsw i64 %4, 12
  %75 = add nsw i64 %74, -1
  %76 = getelementptr inbounds i16, i16* %3, i64 %75
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i64
  %79 = add nuw nsw i64 %73, %78
  %80 = mul nsw i64 %4, 13
  %81 = add nsw i64 %80, -1
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = zext i16 %83 to i64
  %85 = add nuw nsw i64 %79, %84
  %86 = mul nsw i64 %4, 14
  %87 = add nsw i64 %86, -1
  %88 = getelementptr inbounds i16, i16* %3, i64 %87
  %89 = load i16, i16* %88, align 2
  %90 = zext i16 %89 to i64
  %91 = add nuw nsw i64 %85, %90
  %92 = mul nsw i64 %4, 15
  %93 = add nsw i64 %92, -1
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i64
  %97 = add nuw nsw i64 %91, %96
  %98 = add nuw nsw i64 %97, 8
  %99 = lshr i64 %98, 4
  %100 = and i64 %99, 268435455
  %101 = mul i64 %100, 281479271743489
  %102 = bitcast i8* %0 to i64*
  store i64 %101, i64* %102, align 8
  %103 = getelementptr inbounds i8, i8* %0, i64 8
  %104 = bitcast i8* %103 to i64*
  store i64 %101, i64* %104, align 8
  %105 = getelementptr inbounds i8, i8* %0, i64 16
  %106 = bitcast i8* %105 to i64*
  store i64 %101, i64* %106, align 8
  %107 = getelementptr inbounds i8, i8* %0, i64 24
  %108 = bitcast i8* %107 to i64*
  store i64 %101, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %3, i64 %4
  %110 = bitcast i16* %109 to i64*
  store i64 %101, i64* %110, align 8
  %111 = getelementptr inbounds i16, i16* %109, i64 4
  %112 = bitcast i16* %111 to i64*
  store i64 %101, i64* %112, align 8
  %113 = getelementptr inbounds i16, i16* %109, i64 8
  %114 = bitcast i16* %113 to i64*
  store i64 %101, i64* %114, align 8
  %115 = getelementptr inbounds i16, i16* %109, i64 12
  %116 = bitcast i16* %115 to i64*
  store i64 %101, i64* %116, align 8
  %117 = getelementptr inbounds i16, i16* %109, i64 %4
  %118 = bitcast i16* %117 to i64*
  store i64 %101, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %117, i64 4
  %120 = bitcast i16* %119 to i64*
  store i64 %101, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %117, i64 8
  %122 = bitcast i16* %121 to i64*
  store i64 %101, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %117, i64 12
  %124 = bitcast i16* %123 to i64*
  store i64 %101, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %117, i64 %4
  %126 = bitcast i16* %125 to i64*
  store i64 %101, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %125, i64 4
  %128 = bitcast i16* %127 to i64*
  store i64 %101, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %125, i64 8
  %130 = bitcast i16* %129 to i64*
  store i64 %101, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %125, i64 12
  %132 = bitcast i16* %131 to i64*
  store i64 %101, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %125, i64 %4
  %134 = bitcast i16* %133 to i64*
  store i64 %101, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %133, i64 4
  %136 = bitcast i16* %135 to i64*
  store i64 %101, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %133, i64 8
  %138 = bitcast i16* %137 to i64*
  store i64 %101, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %133, i64 12
  %140 = bitcast i16* %139 to i64*
  store i64 %101, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %133, i64 %4
  %142 = bitcast i16* %141 to i64*
  store i64 %101, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %101, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %141, i64 8
  %146 = bitcast i16* %145 to i64*
  store i64 %101, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %141, i64 12
  %148 = bitcast i16* %147 to i64*
  store i64 %101, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %141, i64 %4
  %150 = bitcast i16* %149 to i64*
  store i64 %101, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %149, i64 4
  %152 = bitcast i16* %151 to i64*
  store i64 %101, i64* %152, align 8
  %153 = getelementptr inbounds i16, i16* %149, i64 8
  %154 = bitcast i16* %153 to i64*
  store i64 %101, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %149, i64 12
  %156 = bitcast i16* %155 to i64*
  store i64 %101, i64* %156, align 8
  %157 = getelementptr inbounds i16, i16* %149, i64 %4
  %158 = bitcast i16* %157 to i64*
  store i64 %101, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %157, i64 4
  %160 = bitcast i16* %159 to i64*
  store i64 %101, i64* %160, align 8
  %161 = getelementptr inbounds i16, i16* %157, i64 8
  %162 = bitcast i16* %161 to i64*
  store i64 %101, i64* %162, align 8
  %163 = getelementptr inbounds i16, i16* %157, i64 12
  %164 = bitcast i16* %163 to i64*
  store i64 %101, i64* %164, align 8
  %165 = getelementptr inbounds i16, i16* %157, i64 %4
  %166 = bitcast i16* %165 to i64*
  store i64 %101, i64* %166, align 8
  %167 = getelementptr inbounds i16, i16* %165, i64 4
  %168 = bitcast i16* %167 to i64*
  store i64 %101, i64* %168, align 8
  %169 = getelementptr inbounds i16, i16* %165, i64 8
  %170 = bitcast i16* %169 to i64*
  store i64 %101, i64* %170, align 8
  %171 = getelementptr inbounds i16, i16* %165, i64 12
  %172 = bitcast i16* %171 to i64*
  store i64 %101, i64* %172, align 8
  %173 = getelementptr inbounds i16, i16* %165, i64 %4
  %174 = bitcast i16* %173 to i64*
  store i64 %101, i64* %174, align 8
  %175 = getelementptr inbounds i16, i16* %173, i64 4
  %176 = bitcast i16* %175 to i64*
  store i64 %101, i64* %176, align 8
  %177 = getelementptr inbounds i16, i16* %173, i64 8
  %178 = bitcast i16* %177 to i64*
  store i64 %101, i64* %178, align 8
  %179 = getelementptr inbounds i16, i16* %173, i64 12
  %180 = bitcast i16* %179 to i64*
  store i64 %101, i64* %180, align 8
  %181 = getelementptr inbounds i16, i16* %173, i64 %4
  %182 = bitcast i16* %181 to i64*
  store i64 %101, i64* %182, align 8
  %183 = getelementptr inbounds i16, i16* %181, i64 4
  %184 = bitcast i16* %183 to i64*
  store i64 %101, i64* %184, align 8
  %185 = getelementptr inbounds i16, i16* %181, i64 8
  %186 = bitcast i16* %185 to i64*
  store i64 %101, i64* %186, align 8
  %187 = getelementptr inbounds i16, i16* %181, i64 12
  %188 = bitcast i16* %187 to i64*
  store i64 %101, i64* %188, align 8
  %189 = getelementptr inbounds i16, i16* %181, i64 %4
  %190 = bitcast i16* %189 to i64*
  store i64 %101, i64* %190, align 8
  %191 = getelementptr inbounds i16, i16* %189, i64 4
  %192 = bitcast i16* %191 to i64*
  store i64 %101, i64* %192, align 8
  %193 = getelementptr inbounds i16, i16* %189, i64 8
  %194 = bitcast i16* %193 to i64*
  store i64 %101, i64* %194, align 8
  %195 = getelementptr inbounds i16, i16* %189, i64 12
  %196 = bitcast i16* %195 to i64*
  store i64 %101, i64* %196, align 8
  %197 = getelementptr inbounds i16, i16* %189, i64 %4
  %198 = bitcast i16* %197 to i64*
  store i64 %101, i64* %198, align 8
  %199 = getelementptr inbounds i16, i16* %197, i64 4
  %200 = bitcast i16* %199 to i64*
  store i64 %101, i64* %200, align 8
  %201 = getelementptr inbounds i16, i16* %197, i64 8
  %202 = bitcast i16* %201 to i64*
  store i64 %101, i64* %202, align 8
  %203 = getelementptr inbounds i16, i16* %197, i64 12
  %204 = bitcast i16* %203 to i64*
  store i64 %101, i64* %204, align 8
  %205 = getelementptr inbounds i16, i16* %197, i64 %4
  %206 = bitcast i16* %205 to i64*
  store i64 %101, i64* %206, align 8
  %207 = getelementptr inbounds i16, i16* %205, i64 4
  %208 = bitcast i16* %207 to i64*
  store i64 %101, i64* %208, align 8
  %209 = getelementptr inbounds i16, i16* %205, i64 8
  %210 = bitcast i16* %209 to i64*
  store i64 %101, i64* %210, align 8
  %211 = getelementptr inbounds i16, i16* %205, i64 12
  %212 = bitcast i16* %211 to i64*
  store i64 %101, i64* %212, align 8
  %213 = getelementptr inbounds i16, i16* %205, i64 %4
  %214 = bitcast i16* %213 to i64*
  store i64 %101, i64* %214, align 8
  %215 = getelementptr inbounds i16, i16* %213, i64 4
  %216 = bitcast i16* %215 to i64*
  store i64 %101, i64* %216, align 8
  %217 = getelementptr inbounds i16, i16* %213, i64 8
  %218 = bitcast i16* %217 to i64*
  store i64 %101, i64* %218, align 8
  %219 = getelementptr inbounds i16, i16* %213, i64 12
  %220 = bitcast i16* %219 to i64*
  store i64 %101, i64* %220, align 8
  %221 = getelementptr inbounds i16, i16* %213, i64 %4
  %222 = bitcast i16* %221 to i64*
  store i64 %101, i64* %222, align 8
  %223 = getelementptr inbounds i16, i16* %221, i64 4
  %224 = bitcast i16* %223 to i64*
  store i64 %101, i64* %224, align 8
  %225 = getelementptr inbounds i16, i16* %221, i64 8
  %226 = bitcast i16* %225 to i64*
  store i64 %101, i64* %226, align 8
  %227 = getelementptr inbounds i16, i16* %221, i64 12
  %228 = bitcast i16* %227 to i64*
  store i64 %101, i64* %228, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_top_dc_9_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 1, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = sub nsw i64 2, %4
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = add nuw nsw i64 %13, %17
  %19 = sub nsw i64 3, %4
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = add nuw nsw i64 %18, %22
  %24 = sub nsw i64 4, %4
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = add nuw nsw i64 %23, %27
  %29 = sub nsw i64 5, %4
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = add nuw nsw i64 %28, %32
  %34 = sub nsw i64 6, %4
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = add nuw nsw i64 %33, %37
  %39 = sub nsw i64 7, %4
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %38, %42
  %44 = sub nsw i64 8, %4
  %45 = getelementptr inbounds i16, i16* %3, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i64
  %48 = add nuw nsw i64 %43, %47
  %49 = sub nsw i64 9, %4
  %50 = getelementptr inbounds i16, i16* %3, i64 %49
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i64
  %53 = add nuw nsw i64 %48, %52
  %54 = sub nsw i64 10, %4
  %55 = getelementptr inbounds i16, i16* %3, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i64
  %58 = add nuw nsw i64 %53, %57
  %59 = sub nsw i64 11, %4
  %60 = getelementptr inbounds i16, i16* %3, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i64
  %63 = add nuw nsw i64 %58, %62
  %64 = sub nsw i64 12, %4
  %65 = getelementptr inbounds i16, i16* %3, i64 %64
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i64
  %68 = add nuw nsw i64 %63, %67
  %69 = sub nsw i64 13, %4
  %70 = getelementptr inbounds i16, i16* %3, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i64
  %73 = add nuw nsw i64 %68, %72
  %74 = sub nsw i64 14, %4
  %75 = getelementptr inbounds i16, i16* %3, i64 %74
  %76 = load i16, i16* %75, align 2
  %77 = zext i16 %76 to i64
  %78 = add nuw nsw i64 %73, %77
  %79 = sub nsw i64 15, %4
  %80 = getelementptr inbounds i16, i16* %3, i64 %79
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i64
  %83 = add nuw nsw i64 %78, %82
  %84 = add nuw nsw i64 %83, 8
  %85 = lshr i64 %84, 4
  %86 = and i64 %85, 268435455
  %87 = mul i64 %86, 281479271743489
  %88 = bitcast i8* %0 to i64*
  store i64 %87, i64* %88, align 8
  %89 = getelementptr inbounds i8, i8* %0, i64 8
  %90 = bitcast i8* %89 to i64*
  store i64 %87, i64* %90, align 8
  %91 = getelementptr inbounds i8, i8* %0, i64 16
  %92 = bitcast i8* %91 to i64*
  store i64 %87, i64* %92, align 8
  %93 = getelementptr inbounds i8, i8* %0, i64 24
  %94 = bitcast i8* %93 to i64*
  store i64 %87, i64* %94, align 8
  %95 = getelementptr inbounds i16, i16* %3, i64 %4
  %96 = bitcast i16* %95 to i64*
  store i64 %87, i64* %96, align 8
  %97 = getelementptr inbounds i16, i16* %95, i64 4
  %98 = bitcast i16* %97 to i64*
  store i64 %87, i64* %98, align 8
  %99 = getelementptr inbounds i16, i16* %95, i64 8
  %100 = bitcast i16* %99 to i64*
  store i64 %87, i64* %100, align 8
  %101 = getelementptr inbounds i16, i16* %95, i64 12
  %102 = bitcast i16* %101 to i64*
  store i64 %87, i64* %102, align 8
  %103 = getelementptr inbounds i16, i16* %95, i64 %4
  %104 = bitcast i16* %103 to i64*
  store i64 %87, i64* %104, align 8
  %105 = getelementptr inbounds i16, i16* %103, i64 4
  %106 = bitcast i16* %105 to i64*
  store i64 %87, i64* %106, align 8
  %107 = getelementptr inbounds i16, i16* %103, i64 8
  %108 = bitcast i16* %107 to i64*
  store i64 %87, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %103, i64 12
  %110 = bitcast i16* %109 to i64*
  store i64 %87, i64* %110, align 8
  %111 = getelementptr inbounds i16, i16* %103, i64 %4
  %112 = bitcast i16* %111 to i64*
  store i64 %87, i64* %112, align 8
  %113 = getelementptr inbounds i16, i16* %111, i64 4
  %114 = bitcast i16* %113 to i64*
  store i64 %87, i64* %114, align 8
  %115 = getelementptr inbounds i16, i16* %111, i64 8
  %116 = bitcast i16* %115 to i64*
  store i64 %87, i64* %116, align 8
  %117 = getelementptr inbounds i16, i16* %111, i64 12
  %118 = bitcast i16* %117 to i64*
  store i64 %87, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %111, i64 %4
  %120 = bitcast i16* %119 to i64*
  store i64 %87, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %119, i64 4
  %122 = bitcast i16* %121 to i64*
  store i64 %87, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %119, i64 8
  %124 = bitcast i16* %123 to i64*
  store i64 %87, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %119, i64 12
  %126 = bitcast i16* %125 to i64*
  store i64 %87, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %119, i64 %4
  %128 = bitcast i16* %127 to i64*
  store i64 %87, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %127, i64 4
  %130 = bitcast i16* %129 to i64*
  store i64 %87, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %127, i64 8
  %132 = bitcast i16* %131 to i64*
  store i64 %87, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %127, i64 12
  %134 = bitcast i16* %133 to i64*
  store i64 %87, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %127, i64 %4
  %136 = bitcast i16* %135 to i64*
  store i64 %87, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %135, i64 4
  %138 = bitcast i16* %137 to i64*
  store i64 %87, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %135, i64 8
  %140 = bitcast i16* %139 to i64*
  store i64 %87, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %135, i64 12
  %142 = bitcast i16* %141 to i64*
  store i64 %87, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %135, i64 %4
  %144 = bitcast i16* %143 to i64*
  store i64 %87, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %143, i64 4
  %146 = bitcast i16* %145 to i64*
  store i64 %87, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %143, i64 8
  %148 = bitcast i16* %147 to i64*
  store i64 %87, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %143, i64 12
  %150 = bitcast i16* %149 to i64*
  store i64 %87, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %143, i64 %4
  %152 = bitcast i16* %151 to i64*
  store i64 %87, i64* %152, align 8
  %153 = getelementptr inbounds i16, i16* %151, i64 4
  %154 = bitcast i16* %153 to i64*
  store i64 %87, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %151, i64 8
  %156 = bitcast i16* %155 to i64*
  store i64 %87, i64* %156, align 8
  %157 = getelementptr inbounds i16, i16* %151, i64 12
  %158 = bitcast i16* %157 to i64*
  store i64 %87, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %151, i64 %4
  %160 = bitcast i16* %159 to i64*
  store i64 %87, i64* %160, align 8
  %161 = getelementptr inbounds i16, i16* %159, i64 4
  %162 = bitcast i16* %161 to i64*
  store i64 %87, i64* %162, align 8
  %163 = getelementptr inbounds i16, i16* %159, i64 8
  %164 = bitcast i16* %163 to i64*
  store i64 %87, i64* %164, align 8
  %165 = getelementptr inbounds i16, i16* %159, i64 12
  %166 = bitcast i16* %165 to i64*
  store i64 %87, i64* %166, align 8
  %167 = getelementptr inbounds i16, i16* %159, i64 %4
  %168 = bitcast i16* %167 to i64*
  store i64 %87, i64* %168, align 8
  %169 = getelementptr inbounds i16, i16* %167, i64 4
  %170 = bitcast i16* %169 to i64*
  store i64 %87, i64* %170, align 8
  %171 = getelementptr inbounds i16, i16* %167, i64 8
  %172 = bitcast i16* %171 to i64*
  store i64 %87, i64* %172, align 8
  %173 = getelementptr inbounds i16, i16* %167, i64 12
  %174 = bitcast i16* %173 to i64*
  store i64 %87, i64* %174, align 8
  %175 = getelementptr inbounds i16, i16* %167, i64 %4
  %176 = bitcast i16* %175 to i64*
  store i64 %87, i64* %176, align 8
  %177 = getelementptr inbounds i16, i16* %175, i64 4
  %178 = bitcast i16* %177 to i64*
  store i64 %87, i64* %178, align 8
  %179 = getelementptr inbounds i16, i16* %175, i64 8
  %180 = bitcast i16* %179 to i64*
  store i64 %87, i64* %180, align 8
  %181 = getelementptr inbounds i16, i16* %175, i64 12
  %182 = bitcast i16* %181 to i64*
  store i64 %87, i64* %182, align 8
  %183 = getelementptr inbounds i16, i16* %175, i64 %4
  %184 = bitcast i16* %183 to i64*
  store i64 %87, i64* %184, align 8
  %185 = getelementptr inbounds i16, i16* %183, i64 4
  %186 = bitcast i16* %185 to i64*
  store i64 %87, i64* %186, align 8
  %187 = getelementptr inbounds i16, i16* %183, i64 8
  %188 = bitcast i16* %187 to i64*
  store i64 %87, i64* %188, align 8
  %189 = getelementptr inbounds i16, i16* %183, i64 12
  %190 = bitcast i16* %189 to i64*
  store i64 %87, i64* %190, align 8
  %191 = getelementptr inbounds i16, i16* %183, i64 %4
  %192 = bitcast i16* %191 to i64*
  store i64 %87, i64* %192, align 8
  %193 = getelementptr inbounds i16, i16* %191, i64 4
  %194 = bitcast i16* %193 to i64*
  store i64 %87, i64* %194, align 8
  %195 = getelementptr inbounds i16, i16* %191, i64 8
  %196 = bitcast i16* %195 to i64*
  store i64 %87, i64* %196, align 8
  %197 = getelementptr inbounds i16, i16* %191, i64 12
  %198 = bitcast i16* %197 to i64*
  store i64 %87, i64* %198, align 8
  %199 = getelementptr inbounds i16, i16* %191, i64 %4
  %200 = bitcast i16* %199 to i64*
  store i64 %87, i64* %200, align 8
  %201 = getelementptr inbounds i16, i16* %199, i64 4
  %202 = bitcast i16* %201 to i64*
  store i64 %87, i64* %202, align 8
  %203 = getelementptr inbounds i16, i16* %199, i64 8
  %204 = bitcast i16* %203 to i64*
  store i64 %87, i64* %204, align 8
  %205 = getelementptr inbounds i16, i16* %199, i64 12
  %206 = bitcast i16* %205 to i64*
  store i64 %87, i64* %206, align 8
  %207 = getelementptr inbounds i16, i16* %199, i64 %4
  %208 = bitcast i16* %207 to i64*
  store i64 %87, i64* %208, align 8
  %209 = getelementptr inbounds i16, i16* %207, i64 4
  %210 = bitcast i16* %209 to i64*
  store i64 %87, i64* %210, align 8
  %211 = getelementptr inbounds i16, i16* %207, i64 8
  %212 = bitcast i16* %211 to i64*
  store i64 %87, i64* %212, align 8
  %213 = getelementptr inbounds i16, i16* %207, i64 12
  %214 = bitcast i16* %213 to i64*
  store i64 %87, i64* %214, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_128_dc_9_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i8, i8* %0, i64 16
  %7 = bitcast i8* %6 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %7, align 8
  %8 = getelementptr inbounds i16, i16* %3, i64 %4
  %9 = bitcast i16* %8 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %9, align 8
  %10 = getelementptr inbounds i16, i16* %8, i64 8
  %11 = bitcast i16* %10 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %11, align 8
  %12 = getelementptr inbounds i16, i16* %8, i64 %4
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %13, align 8
  %14 = getelementptr inbounds i16, i16* %12, i64 8
  %15 = bitcast i16* %14 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %15, align 8
  %16 = getelementptr inbounds i16, i16* %12, i64 %4
  %17 = bitcast i16* %16 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %17, align 8
  %18 = getelementptr inbounds i16, i16* %16, i64 8
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 72058693566333184, i64 72058693566333184>, <2 x i64>* %19, align 8
  %20 = getelementptr inbounds i16, i16* %16, i64 %4
  %21 = bitcast i16* %20 to i64*
  store i64 72058693566333184, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 4
  %23 = bitcast i16* %22 to i64*
  store i64 72058693566333184, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 8
  %25 = bitcast i16* %24 to i64*
  store i64 72058693566333184, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 12
  %27 = bitcast i16* %26 to i64*
  store i64 72058693566333184, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %20, i64 %4
  %29 = bitcast i16* %28 to i64*
  store i64 72058693566333184, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 72058693566333184, i64* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 8
  %33 = bitcast i16* %32 to i64*
  store i64 72058693566333184, i64* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 12
  %35 = bitcast i16* %34 to i64*
  store i64 72058693566333184, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %4
  %37 = bitcast i16* %36 to i64*
  store i64 72058693566333184, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 72058693566333184, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 72058693566333184, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 72058693566333184, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %36, i64 %4
  %45 = bitcast i16* %44 to i64*
  store i64 72058693566333184, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 72058693566333184, i64* %47, align 8
  %48 = getelementptr inbounds i16, i16* %44, i64 8
  %49 = bitcast i16* %48 to i64*
  store i64 72058693566333184, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %44, i64 12
  %51 = bitcast i16* %50 to i64*
  store i64 72058693566333184, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %44, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 72058693566333184, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 72058693566333184, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %52, i64 8
  %57 = bitcast i16* %56 to i64*
  store i64 72058693566333184, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %52, i64 12
  %59 = bitcast i16* %58 to i64*
  store i64 72058693566333184, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %52, i64 %4
  %61 = bitcast i16* %60 to i64*
  store i64 72058693566333184, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %60, i64 4
  %63 = bitcast i16* %62 to i64*
  store i64 72058693566333184, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %60, i64 8
  %65 = bitcast i16* %64 to i64*
  store i64 72058693566333184, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %60, i64 12
  %67 = bitcast i16* %66 to i64*
  store i64 72058693566333184, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %60, i64 %4
  %69 = bitcast i16* %68 to i64*
  store i64 72058693566333184, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 72058693566333184, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %68, i64 8
  %73 = bitcast i16* %72 to i64*
  store i64 72058693566333184, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %68, i64 12
  %75 = bitcast i16* %74 to i64*
  store i64 72058693566333184, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %68, i64 %4
  %77 = bitcast i16* %76 to i64*
  store i64 72058693566333184, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %76, i64 4
  %79 = bitcast i16* %78 to i64*
  store i64 72058693566333184, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %76, i64 8
  %81 = bitcast i16* %80 to i64*
  store i64 72058693566333184, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %76, i64 12
  %83 = bitcast i16* %82 to i64*
  store i64 72058693566333184, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %76, i64 %4
  %85 = bitcast i16* %84 to i64*
  store i64 72058693566333184, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 72058693566333184, i64* %87, align 8
  %88 = getelementptr inbounds i16, i16* %84, i64 8
  %89 = bitcast i16* %88 to i64*
  store i64 72058693566333184, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %84, i64 12
  %91 = bitcast i16* %90 to i64*
  store i64 72058693566333184, i64* %91, align 8
  %92 = getelementptr inbounds i16, i16* %84, i64 %4
  %93 = bitcast i16* %92 to i64*
  store i64 72058693566333184, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 72058693566333184, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 72058693566333184, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 72058693566333184, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %92, i64 %4
  %101 = bitcast i16* %100 to i64*
  store i64 72058693566333184, i64* %101, align 8
  %102 = getelementptr inbounds i16, i16* %100, i64 4
  %103 = bitcast i16* %102 to i64*
  store i64 72058693566333184, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %100, i64 8
  %105 = bitcast i16* %104 to i64*
  store i64 72058693566333184, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %100, i64 12
  %107 = bitcast i16* %106 to i64*
  store i64 72058693566333184, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %100, i64 %4
  %109 = bitcast i16* %108 to i64*
  store i64 72058693566333184, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 72058693566333184, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %108, i64 8
  %113 = bitcast i16* %112 to i64*
  store i64 72058693566333184, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %108, i64 12
  %115 = bitcast i16* %114 to i64*
  store i64 72058693566333184, i64* %115, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred4x4_vertical_add_9_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %4, i64 %7
  %9 = and i64 %2, -2
  %10 = mul nsw i64 %6, 3
  %11 = shl nsw i64 %6, 2
  %12 = load i16, i16* %8, align 2
  %13 = load i32, i32* %5, align 4
  %14 = trunc i32 %13 to i16
  %15 = add i16 %12, %14
  store i16 %15, i16* %4, align 2
  %16 = getelementptr inbounds i16, i16* %1, i64 8
  %17 = bitcast i16* %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = trunc i32 %18 to i16
  %20 = add i16 %15, %19
  %21 = getelementptr inbounds i16, i16* %8, i64 %9
  store i16 %20, i16* %21, align 2
  %22 = getelementptr inbounds i16, i16* %1, i64 16
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %20, %25
  %27 = getelementptr inbounds i16, i16* %8, i64 %10
  store i16 %26, i16* %27, align 2
  %28 = getelementptr inbounds i16, i16* %1, i64 24
  %29 = bitcast i16* %28 to i32*
  %30 = load i32, i32* %29, align 4
  %31 = trunc i32 %30 to i16
  %32 = add i16 %26, %31
  %33 = getelementptr inbounds i16, i16* %8, i64 %11
  store i16 %32, i16* %33, align 2
  %34 = getelementptr inbounds i16, i16* %8, i64 1
  %35 = getelementptr inbounds i16, i16* %1, i64 2
  %36 = bitcast i16* %35 to i32*
  %37 = load i16, i16* %34, align 2
  %38 = load i32, i32* %36, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %37, %39
  %41 = getelementptr inbounds i16, i16* %34, i64 %6
  store i16 %40, i16* %41, align 2
  %42 = getelementptr inbounds i16, i16* %1, i64 10
  %43 = bitcast i16* %42 to i32*
  %44 = load i32, i32* %43, align 4
  %45 = trunc i32 %44 to i16
  %46 = add i16 %40, %45
  %47 = getelementptr inbounds i16, i16* %34, i64 %9
  store i16 %46, i16* %47, align 2
  %48 = getelementptr inbounds i16, i16* %1, i64 18
  %49 = bitcast i16* %48 to i32*
  %50 = load i32, i32* %49, align 4
  %51 = trunc i32 %50 to i16
  %52 = add i16 %46, %51
  %53 = getelementptr inbounds i16, i16* %34, i64 %10
  store i16 %52, i16* %53, align 2
  %54 = getelementptr inbounds i16, i16* %1, i64 26
  %55 = bitcast i16* %54 to i32*
  %56 = load i32, i32* %55, align 4
  %57 = trunc i32 %56 to i16
  %58 = add i16 %52, %57
  %59 = getelementptr inbounds i16, i16* %34, i64 %11
  store i16 %58, i16* %59, align 2
  %60 = getelementptr inbounds i16, i16* %34, i64 1
  %61 = getelementptr inbounds i16, i16* %1, i64 4
  %62 = bitcast i16* %61 to i32*
  %63 = load i16, i16* %60, align 2
  %64 = load i32, i32* %62, align 4
  %65 = trunc i32 %64 to i16
  %66 = add i16 %63, %65
  %67 = getelementptr inbounds i16, i16* %60, i64 %6
  store i16 %66, i16* %67, align 2
  %68 = getelementptr inbounds i16, i16* %1, i64 12
  %69 = bitcast i16* %68 to i32*
  %70 = load i32, i32* %69, align 4
  %71 = trunc i32 %70 to i16
  %72 = add i16 %66, %71
  %73 = getelementptr inbounds i16, i16* %60, i64 %9
  store i16 %72, i16* %73, align 2
  %74 = getelementptr inbounds i16, i16* %1, i64 20
  %75 = bitcast i16* %74 to i32*
  %76 = load i32, i32* %75, align 4
  %77 = trunc i32 %76 to i16
  %78 = add i16 %72, %77
  %79 = getelementptr inbounds i16, i16* %60, i64 %10
  store i16 %78, i16* %79, align 2
  %80 = getelementptr inbounds i16, i16* %1, i64 28
  %81 = bitcast i16* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = trunc i32 %82 to i16
  %84 = add i16 %78, %83
  %85 = getelementptr inbounds i16, i16* %60, i64 %11
  store i16 %84, i16* %85, align 2
  %86 = getelementptr inbounds i16, i16* %60, i64 1
  %87 = getelementptr inbounds i16, i16* %1, i64 6
  %88 = bitcast i16* %87 to i32*
  %89 = load i16, i16* %86, align 2
  %90 = load i32, i32* %88, align 4
  %91 = trunc i32 %90 to i16
  %92 = add i16 %89, %91
  %93 = getelementptr inbounds i16, i16* %86, i64 %6
  store i16 %92, i16* %93, align 2
  %94 = getelementptr inbounds i16, i16* %1, i64 14
  %95 = bitcast i16* %94 to i32*
  %96 = load i32, i32* %95, align 4
  %97 = trunc i32 %96 to i16
  %98 = add i16 %92, %97
  %99 = getelementptr inbounds i16, i16* %86, i64 %9
  store i16 %98, i16* %99, align 2
  %100 = getelementptr inbounds i16, i16* %1, i64 22
  %101 = bitcast i16* %100 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = trunc i32 %102 to i16
  %104 = add i16 %98, %103
  %105 = getelementptr inbounds i16, i16* %86, i64 %10
  store i16 %104, i16* %105, align 2
  %106 = getelementptr inbounds i16, i16* %1, i64 30
  %107 = bitcast i16* %106 to i32*
  %108 = load i32, i32* %107, align 4
  %109 = trunc i32 %108 to i16
  %110 = add i16 %104, %109
  %111 = getelementptr inbounds i16, i16* %86, i64 %11
  store i16 %110, i16* %111, align 2
  %112 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %112, i8 0, i64 64, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred4x4_horizontal_add_9_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = load i32, i32* %5, align 4
  %11 = trunc i32 %10 to i16
  %12 = add i16 %9, %11
  store i16 %12, i16* %4, align 2
  %13 = getelementptr inbounds i16, i16* %1, i64 2
  %14 = bitcast i16* %13 to i32*
  %15 = load i32, i32* %14, align 4
  %16 = trunc i32 %15 to i16
  %17 = add i16 %12, %16
  %18 = getelementptr inbounds i8, i8* %0, i64 2
  %19 = bitcast i8* %18 to i16*
  store i16 %17, i16* %19, align 2
  %20 = getelementptr inbounds i16, i16* %1, i64 4
  %21 = bitcast i16* %20 to i32*
  %22 = load i32, i32* %21, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %17, %23
  %25 = getelementptr inbounds i8, i8* %0, i64 4
  %26 = bitcast i8* %25 to i16*
  store i16 %24, i16* %26, align 2
  %27 = getelementptr inbounds i16, i16* %1, i64 6
  %28 = bitcast i16* %27 to i32*
  %29 = load i32, i32* %28, align 4
  %30 = trunc i32 %29 to i16
  %31 = add i16 %24, %30
  %32 = getelementptr inbounds i8, i8* %0, i64 6
  %33 = bitcast i8* %32 to i16*
  store i16 %31, i16* %33, align 2
  %34 = getelementptr inbounds i16, i16* %4, i64 %6
  %35 = getelementptr inbounds i16, i16* %1, i64 8
  %36 = bitcast i16* %35 to i32*
  %37 = getelementptr inbounds i16, i16* %34, i64 -1
  %38 = load i16, i16* %37, align 2
  %39 = load i32, i32* %36, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %38, %40
  store i16 %41, i16* %34, align 2
  %42 = getelementptr inbounds i16, i16* %1, i64 10
  %43 = bitcast i16* %42 to i32*
  %44 = load i32, i32* %43, align 4
  %45 = trunc i32 %44 to i16
  %46 = add i16 %41, %45
  %47 = getelementptr inbounds i16, i16* %34, i64 1
  store i16 %46, i16* %47, align 2
  %48 = getelementptr inbounds i16, i16* %1, i64 12
  %49 = bitcast i16* %48 to i32*
  %50 = load i32, i32* %49, align 4
  %51 = trunc i32 %50 to i16
  %52 = add i16 %46, %51
  %53 = getelementptr inbounds i16, i16* %34, i64 2
  store i16 %52, i16* %53, align 2
  %54 = getelementptr inbounds i16, i16* %1, i64 14
  %55 = bitcast i16* %54 to i32*
  %56 = load i32, i32* %55, align 4
  %57 = trunc i32 %56 to i16
  %58 = add i16 %52, %57
  %59 = getelementptr inbounds i16, i16* %34, i64 3
  store i16 %58, i16* %59, align 2
  %60 = getelementptr inbounds i16, i16* %34, i64 %6
  %61 = getelementptr inbounds i16, i16* %1, i64 16
  %62 = bitcast i16* %61 to i32*
  %63 = getelementptr inbounds i16, i16* %60, i64 -1
  %64 = load i16, i16* %63, align 2
  %65 = load i32, i32* %62, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %64, %66
  store i16 %67, i16* %60, align 2
  %68 = getelementptr inbounds i16, i16* %1, i64 18
  %69 = bitcast i16* %68 to i32*
  %70 = load i32, i32* %69, align 4
  %71 = trunc i32 %70 to i16
  %72 = add i16 %67, %71
  %73 = getelementptr inbounds i16, i16* %60, i64 1
  store i16 %72, i16* %73, align 2
  %74 = getelementptr inbounds i16, i16* %1, i64 20
  %75 = bitcast i16* %74 to i32*
  %76 = load i32, i32* %75, align 4
  %77 = trunc i32 %76 to i16
  %78 = add i16 %72, %77
  %79 = getelementptr inbounds i16, i16* %60, i64 2
  store i16 %78, i16* %79, align 2
  %80 = getelementptr inbounds i16, i16* %1, i64 22
  %81 = bitcast i16* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = trunc i32 %82 to i16
  %84 = add i16 %78, %83
  %85 = getelementptr inbounds i16, i16* %60, i64 3
  store i16 %84, i16* %85, align 2
  %86 = getelementptr inbounds i16, i16* %60, i64 %6
  %87 = getelementptr inbounds i16, i16* %1, i64 24
  %88 = bitcast i16* %87 to i32*
  %89 = getelementptr inbounds i16, i16* %86, i64 -1
  %90 = load i16, i16* %89, align 2
  %91 = load i32, i32* %88, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %90, %92
  store i16 %93, i16* %86, align 2
  %94 = getelementptr inbounds i16, i16* %1, i64 26
  %95 = bitcast i16* %94 to i32*
  %96 = load i32, i32* %95, align 4
  %97 = trunc i32 %96 to i16
  %98 = add i16 %93, %97
  %99 = getelementptr inbounds i16, i16* %86, i64 1
  store i16 %98, i16* %99, align 2
  %100 = getelementptr inbounds i16, i16* %1, i64 28
  %101 = bitcast i16* %100 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = trunc i32 %102 to i16
  %104 = add i16 %98, %103
  %105 = getelementptr inbounds i16, i16* %86, i64 2
  store i16 %104, i16* %105, align 2
  %106 = getelementptr inbounds i16, i16* %1, i64 30
  %107 = bitcast i16* %106 to i32*
  %108 = load i32, i32* %107, align 4
  %109 = trunc i32 %108 to i16
  %110 = add i16 %104, %109
  %111 = getelementptr inbounds i16, i16* %86, i64 3
  store i16 %110, i16* %111, align 2
  %112 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %112, i8 0, i64 64, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_vertical_add_9_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %4, i64 %7
  %9 = and i64 %2, -2
  %10 = mul nsw i64 %6, 3
  %11 = shl nsw i64 %6, 2
  %12 = mul nsw i64 %6, 5
  %13 = mul nsw i64 %6, 6
  %14 = mul nsw i64 %6, 7
  %15 = shl nsw i64 %6, 3
  br label %16

16:                                               ; preds = %16, %3
  %17 = phi i32* [ %5, %3 ], [ %61, %16 ]
  %18 = phi i16* [ %8, %3 ], [ %60, %16 ]
  %19 = phi i32 [ 0, %3 ], [ %62, %16 ]
  %20 = load i16, i16* %18, align 2
  %21 = load i32, i32* %17, align 4
  %22 = trunc i32 %21 to i16
  %23 = add i16 %20, %22
  %24 = getelementptr inbounds i16, i16* %18, i64 %6
  store i16 %23, i16* %24, align 2
  %25 = getelementptr inbounds i32, i32* %17, i64 8
  %26 = load i32, i32* %25, align 4
  %27 = trunc i32 %26 to i16
  %28 = add i16 %23, %27
  %29 = getelementptr inbounds i16, i16* %18, i64 %9
  store i16 %28, i16* %29, align 2
  %30 = getelementptr inbounds i32, i32* %17, i64 16
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %28, %32
  %34 = getelementptr inbounds i16, i16* %18, i64 %10
  store i16 %33, i16* %34, align 2
  %35 = getelementptr inbounds i32, i32* %17, i64 24
  %36 = load i32, i32* %35, align 4
  %37 = trunc i32 %36 to i16
  %38 = add i16 %33, %37
  %39 = getelementptr inbounds i16, i16* %18, i64 %11
  store i16 %38, i16* %39, align 2
  %40 = getelementptr inbounds i32, i32* %17, i64 32
  %41 = load i32, i32* %40, align 4
  %42 = trunc i32 %41 to i16
  %43 = add i16 %38, %42
  %44 = getelementptr inbounds i16, i16* %18, i64 %12
  store i16 %43, i16* %44, align 2
  %45 = getelementptr inbounds i32, i32* %17, i64 40
  %46 = load i32, i32* %45, align 4
  %47 = trunc i32 %46 to i16
  %48 = add i16 %43, %47
  %49 = getelementptr inbounds i16, i16* %18, i64 %13
  store i16 %48, i16* %49, align 2
  %50 = getelementptr inbounds i32, i32* %17, i64 48
  %51 = load i32, i32* %50, align 4
  %52 = trunc i32 %51 to i16
  %53 = add i16 %48, %52
  %54 = getelementptr inbounds i16, i16* %18, i64 %14
  store i16 %53, i16* %54, align 2
  %55 = getelementptr inbounds i32, i32* %17, i64 56
  %56 = load i32, i32* %55, align 4
  %57 = trunc i32 %56 to i16
  %58 = add i16 %53, %57
  %59 = getelementptr inbounds i16, i16* %18, i64 %15
  store i16 %58, i16* %59, align 2
  %60 = getelementptr inbounds i16, i16* %18, i64 1
  %61 = getelementptr inbounds i32, i32* %17, i64 1
  %62 = add nuw nsw i32 %19, 1
  %63 = icmp eq i32 %62, 8
  br i1 %63, label %64, label %16

64:                                               ; preds = %16
  %65 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %65, i8 0, i64 256, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_horizontal_add_9_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  br label %7

7:                                                ; preds = %7, %3
  %8 = phi i32* [ %5, %3 ], [ %52, %7 ]
  %9 = phi i16* [ %4, %3 ], [ %51, %7 ]
  %10 = phi i32 [ 0, %3 ], [ %53, %7 ]
  %11 = getelementptr inbounds i16, i16* %9, i64 -1
  %12 = load i16, i16* %11, align 2
  %13 = load i32, i32* %8, align 4
  %14 = trunc i32 %13 to i16
  %15 = add i16 %12, %14
  store i16 %15, i16* %9, align 2
  %16 = getelementptr inbounds i32, i32* %8, i64 1
  %17 = load i32, i32* %16, align 4
  %18 = trunc i32 %17 to i16
  %19 = add i16 %15, %18
  %20 = getelementptr inbounds i16, i16* %9, i64 1
  store i16 %19, i16* %20, align 2
  %21 = getelementptr inbounds i32, i32* %8, i64 2
  %22 = load i32, i32* %21, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %19, %23
  %25 = getelementptr inbounds i16, i16* %9, i64 2
  store i16 %24, i16* %25, align 2
  %26 = getelementptr inbounds i32, i32* %8, i64 3
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %9, i64 3
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i32, i32* %8, i64 4
  %32 = load i32, i32* %31, align 4
  %33 = trunc i32 %32 to i16
  %34 = add i16 %29, %33
  %35 = getelementptr inbounds i16, i16* %9, i64 4
  store i16 %34, i16* %35, align 2
  %36 = getelementptr inbounds i32, i32* %8, i64 5
  %37 = load i32, i32* %36, align 4
  %38 = trunc i32 %37 to i16
  %39 = add i16 %34, %38
  %40 = getelementptr inbounds i16, i16* %9, i64 5
  store i16 %39, i16* %40, align 2
  %41 = getelementptr inbounds i32, i32* %8, i64 6
  %42 = load i32, i32* %41, align 4
  %43 = trunc i32 %42 to i16
  %44 = add i16 %39, %43
  %45 = getelementptr inbounds i16, i16* %9, i64 6
  store i16 %44, i16* %45, align 2
  %46 = getelementptr inbounds i32, i32* %8, i64 7
  %47 = load i32, i32* %46, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %44, %48
  %50 = getelementptr inbounds i16, i16* %9, i64 7
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %9, i64 %6
  %52 = getelementptr inbounds i32, i32* %8, i64 8
  %53 = add nuw nsw i32 %10, 1
  %54 = icmp eq i32 %53, 8
  br i1 %54, label %55, label %7

55:                                               ; preds = %7
  %56 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %56, i8 0, i64 256, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_vertical_filter_add_9_c(i8* nocapture, i16* nocapture, i32, i32, i64) #3 {
  %6 = alloca [8 x i16], align 16
  %7 = bitcast i8* %0 to i16*
  %8 = bitcast i16* %1 to i32*
  %9 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %9) #8
  %10 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 0
  %11 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 1
  %12 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 2
  %13 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 3
  %14 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 4
  %15 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 5
  %16 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 6
  %17 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 7
  %18 = lshr i64 %4, 1
  %19 = trunc i64 %18 to i32
  %20 = icmp eq i32 %2, 0
  %21 = sub nsw i32 0, %19
  %22 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 16, i1 false)
  br i1 %20, label %28, label %23

23:                                               ; preds = %5
  %24 = shl i64 %18, 32
  %25 = ashr exact i64 %24, 32
  %26 = xor i64 %25, -1
  %27 = sext i32 %21 to i64
  br label %31

28:                                               ; preds = %5
  %29 = sext i32 %21 to i64
  %30 = shl i64 %18, 32
  br label %31

31:                                               ; preds = %28, %23
  %32 = phi i64 [ %30, %28 ], [ %24, %23 ]
  %33 = phi i64 [ %29, %28 ], [ %27, %23 ]
  %34 = phi i64 [ %29, %28 ], [ %26, %23 ]
  %35 = getelementptr inbounds i16, i16* %7, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i32
  %38 = getelementptr inbounds i16, i16* %7, i64 %33
  %39 = load i16, i16* %38, align 2
  %40 = zext i16 %39 to i32
  %41 = shl nuw nsw i32 %40, 1
  %42 = sub i64 4294967296, %32
  %43 = ashr exact i64 %42, 32
  %44 = getelementptr inbounds i16, i16* %7, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %37
  %49 = add nuw nsw i32 %48, %41
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = sub i64 8589934592, %32
  %53 = ashr exact i64 %52, 32
  %54 = getelementptr inbounds i16, i16* %7, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i32
  %57 = add nuw nsw i32 %56, 2
  %58 = add nuw nsw i32 %57, %40
  %59 = add nuw nsw i32 %58, %51
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %56, 1
  %62 = sub i64 12884901888, %32
  %63 = ashr exact i64 %62, 32
  %64 = getelementptr inbounds i16, i16* %7, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i32
  %67 = add nuw nsw i32 %47, %61
  %68 = add nuw nsw i32 %67, %66
  %69 = lshr i32 %68, 2
  %70 = shl nuw nsw i32 %66, 1
  %71 = sub i64 17179869184, %32
  %72 = ashr exact i64 %71, 32
  %73 = getelementptr inbounds i16, i16* %7, i64 %72
  %74 = load i16, i16* %73, align 2
  %75 = zext i16 %74 to i32
  %76 = add nuw nsw i32 %57, %70
  %77 = add nuw nsw i32 %76, %75
  %78 = lshr i32 %77, 2
  %79 = shl nuw nsw i32 %75, 1
  %80 = sub i64 21474836480, %32
  %81 = ashr exact i64 %80, 32
  %82 = getelementptr inbounds i16, i16* %7, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = zext i16 %83 to i32
  %85 = add nuw nsw i32 %66, 2
  %86 = add nuw nsw i32 %85, %79
  %87 = add nuw nsw i32 %86, %84
  %88 = lshr i32 %87, 2
  %89 = shl nuw nsw i32 %84, 1
  %90 = sub i64 25769803776, %32
  %91 = ashr exact i64 %90, 32
  %92 = getelementptr inbounds i16, i16* %7, i64 %91
  %93 = load i16, i16* %92, align 2
  %94 = zext i16 %93 to i32
  %95 = add nuw nsw i32 %75, 2
  %96 = add nuw nsw i32 %95, %89
  %97 = add nuw nsw i32 %96, %94
  %98 = lshr i32 %97, 2
  %99 = shl nuw nsw i32 %94, 1
  %100 = sub i64 30064771072, %32
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %7, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i32
  %105 = add nuw nsw i32 %84, 2
  %106 = add nuw nsw i32 %105, %99
  %107 = add nuw nsw i32 %106, %104
  %108 = lshr i32 %107, 2
  %109 = icmp eq i32 %3, 0
  br i1 %109, label %116, label %110

110:                                              ; preds = %31
  %111 = sub i64 34359738368, %32
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds i16, i16* %7, i64 %112
  %114 = load i16, i16* %113, align 2
  %115 = zext i16 %114 to i32
  br label %116

116:                                              ; preds = %31, %110
  %117 = phi i32 [ %115, %110 ], [ %104, %31 ]
  %118 = shl nuw nsw i32 %104, 1
  %119 = add nuw nsw i32 %94, 2
  %120 = add nuw nsw i32 %119, %118
  %121 = add nuw nsw i32 %120, %117
  %122 = lshr i32 %121, 2
  %123 = trunc i32 %50 to i16
  store i16 %123, i16* %10, align 16
  %124 = trunc i32 %60 to i16
  store i16 %124, i16* %11, align 2
  %125 = trunc i32 %69 to i16
  store i16 %125, i16* %12, align 4
  %126 = trunc i32 %78 to i16
  store i16 %126, i16* %13, align 2
  %127 = trunc i32 %88 to i16
  store i16 %127, i16* %14, align 8
  %128 = trunc i32 %98 to i16
  store i16 %128, i16* %15, align 2
  %129 = trunc i32 %108 to i16
  store i16 %129, i16* %16, align 4
  %130 = trunc i32 %122 to i16
  store i16 %130, i16* %17, align 2
  %131 = ashr exact i64 %32, 32
  %132 = shl i64 %4, 32
  %133 = ashr exact i64 %132, 32
  %134 = and i64 %133, -2
  %135 = mul i64 %18, 12884901888
  %136 = ashr exact i64 %135, 32
  %137 = shl i64 %18, 34
  %138 = ashr exact i64 %137, 32
  %139 = mul i64 %18, 21474836480
  %140 = ashr exact i64 %139, 32
  %141 = mul i64 %18, 25769803776
  %142 = ashr exact i64 %141, 32
  %143 = mul i64 %18, 30064771072
  %144 = ashr exact i64 %143, 32
  br label %145

145:                                              ; preds = %190, %116
  %146 = phi i16 [ %123, %116 ], [ %194, %190 ]
  %147 = phi i64 [ 0, %116 ], [ %188, %190 ]
  %148 = phi i32* [ %8, %116 ], [ %191, %190 ]
  %149 = phi i16* [ %7, %116 ], [ %192, %190 ]
  %150 = load i32, i32* %148, align 4
  %151 = trunc i32 %150 to i16
  %152 = add i16 %146, %151
  store i16 %152, i16* %149, align 2
  %153 = getelementptr inbounds i32, i32* %148, i64 8
  %154 = load i32, i32* %153, align 4
  %155 = trunc i32 %154 to i16
  %156 = add i16 %152, %155
  %157 = getelementptr inbounds i16, i16* %149, i64 %131
  store i16 %156, i16* %157, align 2
  %158 = getelementptr inbounds i32, i32* %148, i64 16
  %159 = load i32, i32* %158, align 4
  %160 = trunc i32 %159 to i16
  %161 = add i16 %156, %160
  %162 = getelementptr inbounds i16, i16* %149, i64 %134
  store i16 %161, i16* %162, align 2
  %163 = getelementptr inbounds i32, i32* %148, i64 24
  %164 = load i32, i32* %163, align 4
  %165 = trunc i32 %164 to i16
  %166 = add i16 %161, %165
  %167 = getelementptr inbounds i16, i16* %149, i64 %136
  store i16 %166, i16* %167, align 2
  %168 = getelementptr inbounds i32, i32* %148, i64 32
  %169 = load i32, i32* %168, align 4
  %170 = trunc i32 %169 to i16
  %171 = add i16 %166, %170
  %172 = getelementptr inbounds i16, i16* %149, i64 %138
  store i16 %171, i16* %172, align 2
  %173 = getelementptr inbounds i32, i32* %148, i64 40
  %174 = load i32, i32* %173, align 4
  %175 = trunc i32 %174 to i16
  %176 = add i16 %171, %175
  %177 = getelementptr inbounds i16, i16* %149, i64 %140
  store i16 %176, i16* %177, align 2
  %178 = getelementptr inbounds i32, i32* %148, i64 48
  %179 = load i32, i32* %178, align 4
  %180 = trunc i32 %179 to i16
  %181 = add i16 %176, %180
  %182 = getelementptr inbounds i16, i16* %149, i64 %142
  store i16 %181, i16* %182, align 2
  %183 = getelementptr inbounds i32, i32* %148, i64 56
  %184 = load i32, i32* %183, align 4
  %185 = trunc i32 %184 to i16
  %186 = add i16 %181, %185
  %187 = getelementptr inbounds i16, i16* %149, i64 %144
  store i16 %186, i16* %187, align 2
  %188 = add nuw nsw i64 %147, 1
  %189 = icmp eq i64 %188, 8
  br i1 %189, label %195, label %190

190:                                              ; preds = %145
  %191 = getelementptr inbounds i32, i32* %148, i64 1
  %192 = getelementptr inbounds i16, i16* %149, i64 1
  %193 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 %188
  %194 = load i16, i16* %193, align 2
  br label %145

195:                                              ; preds = %145
  %196 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %196, i8 0, i64 256, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %9) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_horizontal_filter_add_9_c(i8* nocapture, i16* nocapture, i32, i32, i64) #3 {
  %6 = alloca [8 x i16], align 16
  %7 = bitcast i8* %0 to i16*
  %8 = bitcast i16* %1 to i32*
  %9 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %9) #8
  %10 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 0
  %11 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 1
  %12 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 2
  %13 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 3
  %14 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 4
  %15 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 5
  %16 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 6
  %17 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 7
  %18 = lshr i64 %4, 1
  %19 = icmp eq i32 %2, 0
  %20 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 16, i1 false)
  br i1 %19, label %26, label %21

21:                                               ; preds = %5
  %22 = shl i64 %18, 32
  %23 = ashr exact i64 %22, 32
  %24 = xor i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %7, i64 %24
  br label %31

26:                                               ; preds = %5
  %27 = getelementptr inbounds i8, i8* %0, i64 -2
  %28 = bitcast i8* %27 to i16*
  %29 = shl i64 %18, 32
  %30 = ashr exact i64 %29, 32
  br label %31

31:                                               ; preds = %26, %21
  %32 = phi i64 [ %30, %26 ], [ %23, %21 ]
  %33 = phi i64 [ %29, %26 ], [ %22, %21 ]
  %34 = phi i16* [ %28, %26 ], [ %25, %21 ]
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = getelementptr inbounds i8, i8* %0, i64 -2
  %38 = bitcast i8* %37 to i16*
  %39 = load i16, i16* %38, align 2
  %40 = zext i16 %39 to i32
  %41 = shl nuw nsw i32 %40, 1
  %42 = add i64 %33, -4294967296
  %43 = ashr exact i64 %42, 32
  %44 = getelementptr inbounds i16, i16* %7, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %36
  %49 = add nuw nsw i32 %48, %41
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = shl i64 %4, 32
  %53 = and i64 %52, -8589934592
  %54 = add i64 %53, -4294967296
  %55 = ashr exact i64 %54, 32
  %56 = getelementptr inbounds i16, i16* %7, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %58, 2
  %60 = add nuw nsw i32 %59, %40
  %61 = add nuw nsw i32 %60, %51
  %62 = lshr i32 %61, 2
  %63 = shl nuw nsw i32 %58, 1
  %64 = mul i64 %18, 12884901888
  %65 = add i64 %64, -4294967296
  %66 = ashr exact i64 %65, 32
  %67 = getelementptr inbounds i16, i16* %7, i64 %66
  %68 = load i16, i16* %67, align 2
  %69 = zext i16 %68 to i32
  %70 = add nuw nsw i32 %47, %63
  %71 = add nuw nsw i32 %70, %69
  %72 = lshr i32 %71, 2
  %73 = shl nuw nsw i32 %69, 1
  %74 = shl i64 %18, 34
  %75 = add i64 %74, -4294967296
  %76 = ashr exact i64 %75, 32
  %77 = getelementptr inbounds i16, i16* %7, i64 %76
  %78 = load i16, i16* %77, align 2
  %79 = zext i16 %78 to i32
  %80 = add nuw nsw i32 %59, %73
  %81 = add nuw nsw i32 %80, %79
  %82 = lshr i32 %81, 2
  %83 = shl nuw nsw i32 %79, 1
  %84 = mul i64 %18, 21474836480
  %85 = add i64 %84, -4294967296
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i16, i16* %7, i64 %86
  %88 = load i16, i16* %87, align 2
  %89 = zext i16 %88 to i32
  %90 = add nuw nsw i32 %69, 2
  %91 = add nuw nsw i32 %90, %83
  %92 = add nuw nsw i32 %91, %89
  %93 = lshr i32 %92, 2
  %94 = shl nuw nsw i32 %89, 1
  %95 = mul i64 %18, 25769803776
  %96 = add i64 %95, -4294967296
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i16, i16* %7, i64 %97
  %99 = load i16, i16* %98, align 2
  %100 = zext i16 %99 to i32
  %101 = add nuw nsw i32 %79, 2
  %102 = add nuw nsw i32 %101, %94
  %103 = add nuw nsw i32 %102, %100
  %104 = lshr i32 %103, 2
  %105 = shl nuw nsw i32 %100, 1
  %106 = mul i64 %18, 30064771072
  %107 = add i64 %106, -4294967296
  %108 = ashr exact i64 %107, 32
  %109 = getelementptr inbounds i16, i16* %7, i64 %108
  %110 = load i16, i16* %109, align 2
  %111 = zext i16 %110 to i32
  %112 = add nuw nsw i32 %89, 2
  %113 = add nuw nsw i32 %112, %105
  %114 = add nuw nsw i32 %113, %111
  %115 = lshr i32 %114, 2
  %116 = mul nuw nsw i32 %111, 3
  %117 = add nuw nsw i32 %100, 2
  %118 = add nuw nsw i32 %117, %116
  %119 = lshr i32 %118, 2
  %120 = trunc i32 %50 to i16
  store i16 %120, i16* %10, align 16
  %121 = trunc i32 %62 to i16
  store i16 %121, i16* %11, align 2
  %122 = trunc i32 %72 to i16
  store i16 %122, i16* %12, align 4
  %123 = trunc i32 %82 to i16
  store i16 %123, i16* %13, align 2
  %124 = trunc i32 %93 to i16
  store i16 %124, i16* %14, align 8
  %125 = trunc i32 %104 to i16
  store i16 %125, i16* %15, align 2
  %126 = trunc i32 %115 to i16
  store i16 %126, i16* %16, align 4
  %127 = trunc i32 %119 to i16
  store i16 %127, i16* %17, align 2
  br label %128

128:                                              ; preds = %173, %31
  %129 = phi i16 [ %120, %31 ], [ %177, %173 ]
  %130 = phi i64 [ 0, %31 ], [ %171, %173 ]
  %131 = phi i16* [ %7, %31 ], [ %175, %173 ]
  %132 = phi i32* [ %8, %31 ], [ %174, %173 ]
  %133 = load i32, i32* %132, align 4
  %134 = trunc i32 %133 to i16
  %135 = add i16 %129, %134
  store i16 %135, i16* %131, align 2
  %136 = getelementptr inbounds i32, i32* %132, i64 1
  %137 = load i32, i32* %136, align 4
  %138 = trunc i32 %137 to i16
  %139 = add i16 %135, %138
  %140 = getelementptr inbounds i16, i16* %131, i64 1
  store i16 %139, i16* %140, align 2
  %141 = getelementptr inbounds i32, i32* %132, i64 2
  %142 = load i32, i32* %141, align 4
  %143 = trunc i32 %142 to i16
  %144 = add i16 %139, %143
  %145 = getelementptr inbounds i16, i16* %131, i64 2
  store i16 %144, i16* %145, align 2
  %146 = getelementptr inbounds i32, i32* %132, i64 3
  %147 = load i32, i32* %146, align 4
  %148 = trunc i32 %147 to i16
  %149 = add i16 %144, %148
  %150 = getelementptr inbounds i16, i16* %131, i64 3
  store i16 %149, i16* %150, align 2
  %151 = getelementptr inbounds i32, i32* %132, i64 4
  %152 = load i32, i32* %151, align 4
  %153 = trunc i32 %152 to i16
  %154 = add i16 %149, %153
  %155 = getelementptr inbounds i16, i16* %131, i64 4
  store i16 %154, i16* %155, align 2
  %156 = getelementptr inbounds i32, i32* %132, i64 5
  %157 = load i32, i32* %156, align 4
  %158 = trunc i32 %157 to i16
  %159 = add i16 %154, %158
  %160 = getelementptr inbounds i16, i16* %131, i64 5
  store i16 %159, i16* %160, align 2
  %161 = getelementptr inbounds i32, i32* %132, i64 6
  %162 = load i32, i32* %161, align 4
  %163 = trunc i32 %162 to i16
  %164 = add i16 %159, %163
  %165 = getelementptr inbounds i16, i16* %131, i64 6
  store i16 %164, i16* %165, align 2
  %166 = getelementptr inbounds i32, i32* %132, i64 7
  %167 = load i32, i32* %166, align 4
  %168 = trunc i32 %167 to i16
  %169 = add i16 %164, %168
  %170 = getelementptr inbounds i16, i16* %131, i64 7
  store i16 %169, i16* %170, align 2
  %171 = add nuw nsw i64 %130, 1
  %172 = icmp eq i64 %171, 8
  br i1 %172, label %178, label %173

173:                                              ; preds = %128
  %174 = getelementptr inbounds i32, i32* %132, i64 8
  %175 = getelementptr inbounds i16, i16* %131, i64 %32
  %176 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 %171
  %177 = load i16, i16* %176, align 2
  br label %128

178:                                              ; preds = %128
  %179 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %179, i8 0, i64 256, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %9) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8_vertical_add_9_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  %6 = sub nsw i64 0, %5
  %7 = and i64 %3, -2
  %8 = mul nsw i64 %5, 3
  %9 = shl nsw i64 %5, 2
  br label %10

10:                                               ; preds = %10, %4
  %11 = phi i64 [ 0, %4 ], [ %122, %10 ]
  %12 = getelementptr inbounds i32, i32* %1, i64 %11
  %13 = load i32, i32* %12, align 4
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = shl i64 %11, 5
  %17 = getelementptr inbounds i16, i16* %2, i64 %16
  %18 = bitcast i8* %15 to i16*
  %19 = bitcast i16* %17 to i32*
  %20 = getelementptr inbounds i16, i16* %18, i64 %6
  %21 = load i16, i16* %20, align 2
  %22 = load i32, i32* %19, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %21, %23
  store i16 %24, i16* %18, align 2
  %25 = getelementptr inbounds i16, i16* %17, i64 8
  %26 = bitcast i16* %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %20, i64 %7
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i16, i16* %17, i64 16
  %32 = bitcast i16* %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = trunc i32 %33 to i16
  %35 = add i16 %29, %34
  %36 = getelementptr inbounds i16, i16* %20, i64 %8
  store i16 %35, i16* %36, align 2
  %37 = getelementptr inbounds i16, i16* %17, i64 24
  %38 = bitcast i16* %37 to i32*
  %39 = load i32, i32* %38, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %35, %40
  %42 = getelementptr inbounds i16, i16* %20, i64 %9
  store i16 %41, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %20, i64 1
  %44 = getelementptr inbounds i16, i16* %17, i64 2
  %45 = bitcast i16* %44 to i32*
  %46 = load i16, i16* %43, align 2
  %47 = load i32, i32* %45, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %46, %48
  %50 = getelementptr inbounds i16, i16* %43, i64 %5
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %17, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %49, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 %7
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %17, i64 18
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 %8
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %17, i64 26
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 %9
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 1
  %70 = getelementptr inbounds i16, i16* %17, i64 4
  %71 = bitcast i16* %70 to i32*
  %72 = load i16, i16* %69, align 2
  %73 = load i32, i32* %71, align 4
  %74 = trunc i32 %73 to i16
  %75 = add i16 %72, %74
  %76 = getelementptr inbounds i16, i16* %69, i64 %5
  store i16 %75, i16* %76, align 2
  %77 = getelementptr inbounds i16, i16* %17, i64 12
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %75, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 %7
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %17, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 %8
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %17, i64 28
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 %9
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 1
  %96 = getelementptr inbounds i16, i16* %17, i64 6
  %97 = bitcast i16* %96 to i32*
  %98 = load i16, i16* %95, align 2
  %99 = load i32, i32* %97, align 4
  %100 = trunc i32 %99 to i16
  %101 = add i16 %98, %100
  %102 = getelementptr inbounds i16, i16* %95, i64 %5
  store i16 %101, i16* %102, align 2
  %103 = getelementptr inbounds i16, i16* %17, i64 14
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %101, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 %7
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %17, i64 22
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 %8
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %17, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 %9
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %11, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %10

124:                                              ; preds = %10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8_horizontal_add_9_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %122, %6 ]
  %8 = getelementptr inbounds i32, i32* %1, i64 %7
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = shl i64 %7, 5
  %13 = getelementptr inbounds i16, i16* %2, i64 %12
  %14 = bitcast i8* %11 to i16*
  %15 = bitcast i16* %13 to i32*
  %16 = getelementptr inbounds i8, i8* %11, i64 -2
  %17 = bitcast i8* %16 to i16*
  %18 = load i16, i16* %17, align 2
  %19 = load i32, i32* %15, align 4
  %20 = trunc i32 %19 to i16
  %21 = add i16 %18, %20
  store i16 %21, i16* %14, align 2
  %22 = getelementptr inbounds i16, i16* %13, i64 2
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %21, %25
  %27 = getelementptr inbounds i8, i8* %11, i64 2
  %28 = bitcast i8* %27 to i16*
  store i16 %26, i16* %28, align 2
  %29 = getelementptr inbounds i16, i16* %13, i64 4
  %30 = bitcast i16* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %26, %32
  %34 = getelementptr inbounds i8, i8* %11, i64 4
  %35 = bitcast i8* %34 to i16*
  store i16 %33, i16* %35, align 2
  %36 = getelementptr inbounds i16, i16* %13, i64 6
  %37 = bitcast i16* %36 to i32*
  %38 = load i32, i32* %37, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %33, %39
  %41 = getelementptr inbounds i8, i8* %11, i64 6
  %42 = bitcast i8* %41 to i16*
  store i16 %40, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %14, i64 %5
  %44 = getelementptr inbounds i16, i16* %13, i64 8
  %45 = bitcast i16* %44 to i32*
  %46 = getelementptr inbounds i16, i16* %43, i64 -1
  %47 = load i16, i16* %46, align 2
  %48 = load i32, i32* %45, align 4
  %49 = trunc i32 %48 to i16
  %50 = add i16 %47, %49
  store i16 %50, i16* %43, align 2
  %51 = getelementptr inbounds i16, i16* %13, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %50, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 1
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %13, i64 12
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 2
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %13, i64 14
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 3
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 %5
  %70 = getelementptr inbounds i16, i16* %13, i64 16
  %71 = bitcast i16* %70 to i32*
  %72 = getelementptr inbounds i16, i16* %69, i64 -1
  %73 = load i16, i16* %72, align 2
  %74 = load i32, i32* %71, align 4
  %75 = trunc i32 %74 to i16
  %76 = add i16 %73, %75
  store i16 %76, i16* %69, align 2
  %77 = getelementptr inbounds i16, i16* %13, i64 18
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %76, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 1
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %13, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 2
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %13, i64 22
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 3
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 %5
  %96 = getelementptr inbounds i16, i16* %13, i64 24
  %97 = bitcast i16* %96 to i32*
  %98 = getelementptr inbounds i16, i16* %95, i64 -1
  %99 = load i16, i16* %98, align 2
  %100 = load i32, i32* %97, align 4
  %101 = trunc i32 %100 to i16
  %102 = add i16 %99, %101
  store i16 %102, i16* %95, align 2
  %103 = getelementptr inbounds i16, i16* %13, i64 26
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %102, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 1
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %13, i64 28
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 2
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %13, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 3
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %7, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %6

124:                                              ; preds = %6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x16_vertical_add_9_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  %6 = sub nsw i64 0, %5
  %7 = and i64 %3, -2
  %8 = mul nsw i64 %5, 3
  %9 = shl nsw i64 %5, 2
  br label %10

10:                                               ; preds = %10, %4
  %11 = phi i64 [ 0, %4 ], [ %122, %10 ]
  %12 = getelementptr inbounds i32, i32* %1, i64 %11
  %13 = load i32, i32* %12, align 4
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = shl i64 %11, 5
  %17 = getelementptr inbounds i16, i16* %2, i64 %16
  %18 = bitcast i8* %15 to i16*
  %19 = bitcast i16* %17 to i32*
  %20 = getelementptr inbounds i16, i16* %18, i64 %6
  %21 = load i16, i16* %20, align 2
  %22 = load i32, i32* %19, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %21, %23
  store i16 %24, i16* %18, align 2
  %25 = getelementptr inbounds i16, i16* %17, i64 8
  %26 = bitcast i16* %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %20, i64 %7
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i16, i16* %17, i64 16
  %32 = bitcast i16* %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = trunc i32 %33 to i16
  %35 = add i16 %29, %34
  %36 = getelementptr inbounds i16, i16* %20, i64 %8
  store i16 %35, i16* %36, align 2
  %37 = getelementptr inbounds i16, i16* %17, i64 24
  %38 = bitcast i16* %37 to i32*
  %39 = load i32, i32* %38, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %35, %40
  %42 = getelementptr inbounds i16, i16* %20, i64 %9
  store i16 %41, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %20, i64 1
  %44 = getelementptr inbounds i16, i16* %17, i64 2
  %45 = bitcast i16* %44 to i32*
  %46 = load i16, i16* %43, align 2
  %47 = load i32, i32* %45, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %46, %48
  %50 = getelementptr inbounds i16, i16* %43, i64 %5
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %17, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %49, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 %7
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %17, i64 18
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 %8
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %17, i64 26
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 %9
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 1
  %70 = getelementptr inbounds i16, i16* %17, i64 4
  %71 = bitcast i16* %70 to i32*
  %72 = load i16, i16* %69, align 2
  %73 = load i32, i32* %71, align 4
  %74 = trunc i32 %73 to i16
  %75 = add i16 %72, %74
  %76 = getelementptr inbounds i16, i16* %69, i64 %5
  store i16 %75, i16* %76, align 2
  %77 = getelementptr inbounds i16, i16* %17, i64 12
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %75, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 %7
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %17, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 %8
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %17, i64 28
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 %9
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 1
  %96 = getelementptr inbounds i16, i16* %17, i64 6
  %97 = bitcast i16* %96 to i32*
  %98 = load i16, i16* %95, align 2
  %99 = load i32, i32* %97, align 4
  %100 = trunc i32 %99 to i16
  %101 = add i16 %98, %100
  %102 = getelementptr inbounds i16, i16* %95, i64 %5
  store i16 %101, i16* %102, align 2
  %103 = getelementptr inbounds i16, i16* %17, i64 14
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %101, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 %7
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %17, i64 22
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 %8
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %17, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 %9
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %11, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %10

124:                                              ; preds = %10, %124
  %125 = phi i64 [ %237, %124 ], [ 4, %10 ]
  %126 = add nuw nsw i64 %125, 4
  %127 = getelementptr inbounds i32, i32* %1, i64 %126
  %128 = load i32, i32* %127, align 4
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds i8, i8* %0, i64 %129
  %131 = shl i64 %125, 5
  %132 = getelementptr inbounds i16, i16* %2, i64 %131
  %133 = bitcast i8* %130 to i16*
  %134 = bitcast i16* %132 to i32*
  %135 = getelementptr inbounds i16, i16* %133, i64 %6
  %136 = load i16, i16* %135, align 2
  %137 = load i32, i32* %134, align 4
  %138 = trunc i32 %137 to i16
  %139 = add i16 %136, %138
  store i16 %139, i16* %133, align 2
  %140 = getelementptr inbounds i16, i16* %132, i64 8
  %141 = bitcast i16* %140 to i32*
  %142 = load i32, i32* %141, align 4
  %143 = trunc i32 %142 to i16
  %144 = add i16 %139, %143
  %145 = getelementptr inbounds i16, i16* %135, i64 %7
  store i16 %144, i16* %145, align 2
  %146 = getelementptr inbounds i16, i16* %132, i64 16
  %147 = bitcast i16* %146 to i32*
  %148 = load i32, i32* %147, align 4
  %149 = trunc i32 %148 to i16
  %150 = add i16 %144, %149
  %151 = getelementptr inbounds i16, i16* %135, i64 %8
  store i16 %150, i16* %151, align 2
  %152 = getelementptr inbounds i16, i16* %132, i64 24
  %153 = bitcast i16* %152 to i32*
  %154 = load i32, i32* %153, align 4
  %155 = trunc i32 %154 to i16
  %156 = add i16 %150, %155
  %157 = getelementptr inbounds i16, i16* %135, i64 %9
  store i16 %156, i16* %157, align 2
  %158 = getelementptr inbounds i16, i16* %135, i64 1
  %159 = getelementptr inbounds i16, i16* %132, i64 2
  %160 = bitcast i16* %159 to i32*
  %161 = load i16, i16* %158, align 2
  %162 = load i32, i32* %160, align 4
  %163 = trunc i32 %162 to i16
  %164 = add i16 %161, %163
  %165 = getelementptr inbounds i16, i16* %158, i64 %5
  store i16 %164, i16* %165, align 2
  %166 = getelementptr inbounds i16, i16* %132, i64 10
  %167 = bitcast i16* %166 to i32*
  %168 = load i32, i32* %167, align 4
  %169 = trunc i32 %168 to i16
  %170 = add i16 %164, %169
  %171 = getelementptr inbounds i16, i16* %158, i64 %7
  store i16 %170, i16* %171, align 2
  %172 = getelementptr inbounds i16, i16* %132, i64 18
  %173 = bitcast i16* %172 to i32*
  %174 = load i32, i32* %173, align 4
  %175 = trunc i32 %174 to i16
  %176 = add i16 %170, %175
  %177 = getelementptr inbounds i16, i16* %158, i64 %8
  store i16 %176, i16* %177, align 2
  %178 = getelementptr inbounds i16, i16* %132, i64 26
  %179 = bitcast i16* %178 to i32*
  %180 = load i32, i32* %179, align 4
  %181 = trunc i32 %180 to i16
  %182 = add i16 %176, %181
  %183 = getelementptr inbounds i16, i16* %158, i64 %9
  store i16 %182, i16* %183, align 2
  %184 = getelementptr inbounds i16, i16* %158, i64 1
  %185 = getelementptr inbounds i16, i16* %132, i64 4
  %186 = bitcast i16* %185 to i32*
  %187 = load i16, i16* %184, align 2
  %188 = load i32, i32* %186, align 4
  %189 = trunc i32 %188 to i16
  %190 = add i16 %187, %189
  %191 = getelementptr inbounds i16, i16* %184, i64 %5
  store i16 %190, i16* %191, align 2
  %192 = getelementptr inbounds i16, i16* %132, i64 12
  %193 = bitcast i16* %192 to i32*
  %194 = load i32, i32* %193, align 4
  %195 = trunc i32 %194 to i16
  %196 = add i16 %190, %195
  %197 = getelementptr inbounds i16, i16* %184, i64 %7
  store i16 %196, i16* %197, align 2
  %198 = getelementptr inbounds i16, i16* %132, i64 20
  %199 = bitcast i16* %198 to i32*
  %200 = load i32, i32* %199, align 4
  %201 = trunc i32 %200 to i16
  %202 = add i16 %196, %201
  %203 = getelementptr inbounds i16, i16* %184, i64 %8
  store i16 %202, i16* %203, align 2
  %204 = getelementptr inbounds i16, i16* %132, i64 28
  %205 = bitcast i16* %204 to i32*
  %206 = load i32, i32* %205, align 4
  %207 = trunc i32 %206 to i16
  %208 = add i16 %202, %207
  %209 = getelementptr inbounds i16, i16* %184, i64 %9
  store i16 %208, i16* %209, align 2
  %210 = getelementptr inbounds i16, i16* %184, i64 1
  %211 = getelementptr inbounds i16, i16* %132, i64 6
  %212 = bitcast i16* %211 to i32*
  %213 = load i16, i16* %210, align 2
  %214 = load i32, i32* %212, align 4
  %215 = trunc i32 %214 to i16
  %216 = add i16 %213, %215
  %217 = getelementptr inbounds i16, i16* %210, i64 %5
  store i16 %216, i16* %217, align 2
  %218 = getelementptr inbounds i16, i16* %132, i64 14
  %219 = bitcast i16* %218 to i32*
  %220 = load i32, i32* %219, align 4
  %221 = trunc i32 %220 to i16
  %222 = add i16 %216, %221
  %223 = getelementptr inbounds i16, i16* %210, i64 %7
  store i16 %222, i16* %223, align 2
  %224 = getelementptr inbounds i16, i16* %132, i64 22
  %225 = bitcast i16* %224 to i32*
  %226 = load i32, i32* %225, align 4
  %227 = trunc i32 %226 to i16
  %228 = add i16 %222, %227
  %229 = getelementptr inbounds i16, i16* %210, i64 %8
  store i16 %228, i16* %229, align 2
  %230 = getelementptr inbounds i16, i16* %132, i64 30
  %231 = bitcast i16* %230 to i32*
  %232 = load i32, i32* %231, align 4
  %233 = trunc i32 %232 to i16
  %234 = add i16 %228, %233
  %235 = getelementptr inbounds i16, i16* %210, i64 %9
  store i16 %234, i16* %235, align 2
  %236 = bitcast i16* %132 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %236, i8 0, i64 64, i1 false) #8
  %237 = add nuw nsw i64 %125, 1
  %238 = icmp eq i64 %237, 8
  br i1 %238, label %239, label %124

239:                                              ; preds = %124
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x16_horizontal_add_9_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %122, %6 ]
  %8 = getelementptr inbounds i32, i32* %1, i64 %7
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = shl i64 %7, 5
  %13 = getelementptr inbounds i16, i16* %2, i64 %12
  %14 = bitcast i8* %11 to i16*
  %15 = bitcast i16* %13 to i32*
  %16 = getelementptr inbounds i8, i8* %11, i64 -2
  %17 = bitcast i8* %16 to i16*
  %18 = load i16, i16* %17, align 2
  %19 = load i32, i32* %15, align 4
  %20 = trunc i32 %19 to i16
  %21 = add i16 %18, %20
  store i16 %21, i16* %14, align 2
  %22 = getelementptr inbounds i16, i16* %13, i64 2
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %21, %25
  %27 = getelementptr inbounds i8, i8* %11, i64 2
  %28 = bitcast i8* %27 to i16*
  store i16 %26, i16* %28, align 2
  %29 = getelementptr inbounds i16, i16* %13, i64 4
  %30 = bitcast i16* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %26, %32
  %34 = getelementptr inbounds i8, i8* %11, i64 4
  %35 = bitcast i8* %34 to i16*
  store i16 %33, i16* %35, align 2
  %36 = getelementptr inbounds i16, i16* %13, i64 6
  %37 = bitcast i16* %36 to i32*
  %38 = load i32, i32* %37, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %33, %39
  %41 = getelementptr inbounds i8, i8* %11, i64 6
  %42 = bitcast i8* %41 to i16*
  store i16 %40, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %14, i64 %5
  %44 = getelementptr inbounds i16, i16* %13, i64 8
  %45 = bitcast i16* %44 to i32*
  %46 = getelementptr inbounds i16, i16* %43, i64 -1
  %47 = load i16, i16* %46, align 2
  %48 = load i32, i32* %45, align 4
  %49 = trunc i32 %48 to i16
  %50 = add i16 %47, %49
  store i16 %50, i16* %43, align 2
  %51 = getelementptr inbounds i16, i16* %13, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %50, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 1
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %13, i64 12
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 2
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %13, i64 14
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 3
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 %5
  %70 = getelementptr inbounds i16, i16* %13, i64 16
  %71 = bitcast i16* %70 to i32*
  %72 = getelementptr inbounds i16, i16* %69, i64 -1
  %73 = load i16, i16* %72, align 2
  %74 = load i32, i32* %71, align 4
  %75 = trunc i32 %74 to i16
  %76 = add i16 %73, %75
  store i16 %76, i16* %69, align 2
  %77 = getelementptr inbounds i16, i16* %13, i64 18
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %76, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 1
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %13, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 2
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %13, i64 22
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 3
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 %5
  %96 = getelementptr inbounds i16, i16* %13, i64 24
  %97 = bitcast i16* %96 to i32*
  %98 = getelementptr inbounds i16, i16* %95, i64 -1
  %99 = load i16, i16* %98, align 2
  %100 = load i32, i32* %97, align 4
  %101 = trunc i32 %100 to i16
  %102 = add i16 %99, %101
  store i16 %102, i16* %95, align 2
  %103 = getelementptr inbounds i16, i16* %13, i64 26
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %102, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 1
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %13, i64 28
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 2
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %13, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 3
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %7, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %6

124:                                              ; preds = %6, %124
  %125 = phi i64 [ %241, %124 ], [ 4, %6 ]
  %126 = add nuw nsw i64 %125, 4
  %127 = getelementptr inbounds i32, i32* %1, i64 %126
  %128 = load i32, i32* %127, align 4
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds i8, i8* %0, i64 %129
  %131 = shl i64 %125, 5
  %132 = getelementptr inbounds i16, i16* %2, i64 %131
  %133 = bitcast i8* %130 to i16*
  %134 = bitcast i16* %132 to i32*
  %135 = getelementptr inbounds i8, i8* %130, i64 -2
  %136 = bitcast i8* %135 to i16*
  %137 = load i16, i16* %136, align 2
  %138 = load i32, i32* %134, align 4
  %139 = trunc i32 %138 to i16
  %140 = add i16 %137, %139
  store i16 %140, i16* %133, align 2
  %141 = getelementptr inbounds i16, i16* %132, i64 2
  %142 = bitcast i16* %141 to i32*
  %143 = load i32, i32* %142, align 4
  %144 = trunc i32 %143 to i16
  %145 = add i16 %140, %144
  %146 = getelementptr inbounds i8, i8* %130, i64 2
  %147 = bitcast i8* %146 to i16*
  store i16 %145, i16* %147, align 2
  %148 = getelementptr inbounds i16, i16* %132, i64 4
  %149 = bitcast i16* %148 to i32*
  %150 = load i32, i32* %149, align 4
  %151 = trunc i32 %150 to i16
  %152 = add i16 %145, %151
  %153 = getelementptr inbounds i8, i8* %130, i64 4
  %154 = bitcast i8* %153 to i16*
  store i16 %152, i16* %154, align 2
  %155 = getelementptr inbounds i16, i16* %132, i64 6
  %156 = bitcast i16* %155 to i32*
  %157 = load i32, i32* %156, align 4
  %158 = trunc i32 %157 to i16
  %159 = add i16 %152, %158
  %160 = getelementptr inbounds i8, i8* %130, i64 6
  %161 = bitcast i8* %160 to i16*
  store i16 %159, i16* %161, align 2
  %162 = getelementptr inbounds i16, i16* %133, i64 %5
  %163 = getelementptr inbounds i16, i16* %132, i64 8
  %164 = bitcast i16* %163 to i32*
  %165 = getelementptr inbounds i16, i16* %162, i64 -1
  %166 = load i16, i16* %165, align 2
  %167 = load i32, i32* %164, align 4
  %168 = trunc i32 %167 to i16
  %169 = add i16 %166, %168
  store i16 %169, i16* %162, align 2
  %170 = getelementptr inbounds i16, i16* %132, i64 10
  %171 = bitcast i16* %170 to i32*
  %172 = load i32, i32* %171, align 4
  %173 = trunc i32 %172 to i16
  %174 = add i16 %169, %173
  %175 = getelementptr inbounds i16, i16* %162, i64 1
  store i16 %174, i16* %175, align 2
  %176 = getelementptr inbounds i16, i16* %132, i64 12
  %177 = bitcast i16* %176 to i32*
  %178 = load i32, i32* %177, align 4
  %179 = trunc i32 %178 to i16
  %180 = add i16 %174, %179
  %181 = getelementptr inbounds i16, i16* %162, i64 2
  store i16 %180, i16* %181, align 2
  %182 = getelementptr inbounds i16, i16* %132, i64 14
  %183 = bitcast i16* %182 to i32*
  %184 = load i32, i32* %183, align 4
  %185 = trunc i32 %184 to i16
  %186 = add i16 %180, %185
  %187 = getelementptr inbounds i16, i16* %162, i64 3
  store i16 %186, i16* %187, align 2
  %188 = getelementptr inbounds i16, i16* %162, i64 %5
  %189 = getelementptr inbounds i16, i16* %132, i64 16
  %190 = bitcast i16* %189 to i32*
  %191 = getelementptr inbounds i16, i16* %188, i64 -1
  %192 = load i16, i16* %191, align 2
  %193 = load i32, i32* %190, align 4
  %194 = trunc i32 %193 to i16
  %195 = add i16 %192, %194
  store i16 %195, i16* %188, align 2
  %196 = getelementptr inbounds i16, i16* %132, i64 18
  %197 = bitcast i16* %196 to i32*
  %198 = load i32, i32* %197, align 4
  %199 = trunc i32 %198 to i16
  %200 = add i16 %195, %199
  %201 = getelementptr inbounds i16, i16* %188, i64 1
  store i16 %200, i16* %201, align 2
  %202 = getelementptr inbounds i16, i16* %132, i64 20
  %203 = bitcast i16* %202 to i32*
  %204 = load i32, i32* %203, align 4
  %205 = trunc i32 %204 to i16
  %206 = add i16 %200, %205
  %207 = getelementptr inbounds i16, i16* %188, i64 2
  store i16 %206, i16* %207, align 2
  %208 = getelementptr inbounds i16, i16* %132, i64 22
  %209 = bitcast i16* %208 to i32*
  %210 = load i32, i32* %209, align 4
  %211 = trunc i32 %210 to i16
  %212 = add i16 %206, %211
  %213 = getelementptr inbounds i16, i16* %188, i64 3
  store i16 %212, i16* %213, align 2
  %214 = getelementptr inbounds i16, i16* %188, i64 %5
  %215 = getelementptr inbounds i16, i16* %132, i64 24
  %216 = bitcast i16* %215 to i32*
  %217 = getelementptr inbounds i16, i16* %214, i64 -1
  %218 = load i16, i16* %217, align 2
  %219 = load i32, i32* %216, align 4
  %220 = trunc i32 %219 to i16
  %221 = add i16 %218, %220
  store i16 %221, i16* %214, align 2
  %222 = getelementptr inbounds i16, i16* %132, i64 26
  %223 = bitcast i16* %222 to i32*
  %224 = load i32, i32* %223, align 4
  %225 = trunc i32 %224 to i16
  %226 = add i16 %221, %225
  %227 = getelementptr inbounds i16, i16* %214, i64 1
  store i16 %226, i16* %227, align 2
  %228 = getelementptr inbounds i16, i16* %132, i64 28
  %229 = bitcast i16* %228 to i32*
  %230 = load i32, i32* %229, align 4
  %231 = trunc i32 %230 to i16
  %232 = add i16 %226, %231
  %233 = getelementptr inbounds i16, i16* %214, i64 2
  store i16 %232, i16* %233, align 2
  %234 = getelementptr inbounds i16, i16* %132, i64 30
  %235 = bitcast i16* %234 to i32*
  %236 = load i32, i32* %235, align 4
  %237 = trunc i32 %236 to i16
  %238 = add i16 %232, %237
  %239 = getelementptr inbounds i16, i16* %214, i64 3
  store i16 %238, i16* %239, align 2
  %240 = bitcast i16* %132 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %240, i8 0, i64 64, i1 false) #8
  %241 = add nuw nsw i64 %125, 1
  %242 = icmp eq i64 %241, 8
  br i1 %242, label %243, label %124

243:                                              ; preds = %124
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred16x16_vertical_add_9_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  %6 = sub nsw i64 0, %5
  %7 = and i64 %3, -2
  %8 = mul nsw i64 %5, 3
  %9 = shl nsw i64 %5, 2
  br label %10

10:                                               ; preds = %10, %4
  %11 = phi i64 [ 0, %4 ], [ %122, %10 ]
  %12 = getelementptr inbounds i32, i32* %1, i64 %11
  %13 = load i32, i32* %12, align 4
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = shl i64 %11, 5
  %17 = getelementptr inbounds i16, i16* %2, i64 %16
  %18 = bitcast i8* %15 to i16*
  %19 = bitcast i16* %17 to i32*
  %20 = getelementptr inbounds i16, i16* %18, i64 %6
  %21 = load i16, i16* %20, align 2
  %22 = load i32, i32* %19, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %21, %23
  store i16 %24, i16* %18, align 2
  %25 = getelementptr inbounds i16, i16* %17, i64 8
  %26 = bitcast i16* %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %20, i64 %7
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i16, i16* %17, i64 16
  %32 = bitcast i16* %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = trunc i32 %33 to i16
  %35 = add i16 %29, %34
  %36 = getelementptr inbounds i16, i16* %20, i64 %8
  store i16 %35, i16* %36, align 2
  %37 = getelementptr inbounds i16, i16* %17, i64 24
  %38 = bitcast i16* %37 to i32*
  %39 = load i32, i32* %38, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %35, %40
  %42 = getelementptr inbounds i16, i16* %20, i64 %9
  store i16 %41, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %20, i64 1
  %44 = getelementptr inbounds i16, i16* %17, i64 2
  %45 = bitcast i16* %44 to i32*
  %46 = load i16, i16* %43, align 2
  %47 = load i32, i32* %45, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %46, %48
  %50 = getelementptr inbounds i16, i16* %43, i64 %5
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %17, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %49, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 %7
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %17, i64 18
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 %8
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %17, i64 26
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 %9
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 1
  %70 = getelementptr inbounds i16, i16* %17, i64 4
  %71 = bitcast i16* %70 to i32*
  %72 = load i16, i16* %69, align 2
  %73 = load i32, i32* %71, align 4
  %74 = trunc i32 %73 to i16
  %75 = add i16 %72, %74
  %76 = getelementptr inbounds i16, i16* %69, i64 %5
  store i16 %75, i16* %76, align 2
  %77 = getelementptr inbounds i16, i16* %17, i64 12
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %75, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 %7
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %17, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 %8
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %17, i64 28
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 %9
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 1
  %96 = getelementptr inbounds i16, i16* %17, i64 6
  %97 = bitcast i16* %96 to i32*
  %98 = load i16, i16* %95, align 2
  %99 = load i32, i32* %97, align 4
  %100 = trunc i32 %99 to i16
  %101 = add i16 %98, %100
  %102 = getelementptr inbounds i16, i16* %95, i64 %5
  store i16 %101, i16* %102, align 2
  %103 = getelementptr inbounds i16, i16* %17, i64 14
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %101, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 %7
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %17, i64 22
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 %8
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %17, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 %9
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %11, 1
  %123 = icmp eq i64 %122, 16
  br i1 %123, label %124, label %10

124:                                              ; preds = %10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred16x16_horizontal_add_9_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %122, %6 ]
  %8 = getelementptr inbounds i32, i32* %1, i64 %7
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = shl i64 %7, 5
  %13 = getelementptr inbounds i16, i16* %2, i64 %12
  %14 = bitcast i8* %11 to i16*
  %15 = bitcast i16* %13 to i32*
  %16 = getelementptr inbounds i8, i8* %11, i64 -2
  %17 = bitcast i8* %16 to i16*
  %18 = load i16, i16* %17, align 2
  %19 = load i32, i32* %15, align 4
  %20 = trunc i32 %19 to i16
  %21 = add i16 %18, %20
  store i16 %21, i16* %14, align 2
  %22 = getelementptr inbounds i16, i16* %13, i64 2
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %21, %25
  %27 = getelementptr inbounds i8, i8* %11, i64 2
  %28 = bitcast i8* %27 to i16*
  store i16 %26, i16* %28, align 2
  %29 = getelementptr inbounds i16, i16* %13, i64 4
  %30 = bitcast i16* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %26, %32
  %34 = getelementptr inbounds i8, i8* %11, i64 4
  %35 = bitcast i8* %34 to i16*
  store i16 %33, i16* %35, align 2
  %36 = getelementptr inbounds i16, i16* %13, i64 6
  %37 = bitcast i16* %36 to i32*
  %38 = load i32, i32* %37, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %33, %39
  %41 = getelementptr inbounds i8, i8* %11, i64 6
  %42 = bitcast i8* %41 to i16*
  store i16 %40, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %14, i64 %5
  %44 = getelementptr inbounds i16, i16* %13, i64 8
  %45 = bitcast i16* %44 to i32*
  %46 = getelementptr inbounds i16, i16* %43, i64 -1
  %47 = load i16, i16* %46, align 2
  %48 = load i32, i32* %45, align 4
  %49 = trunc i32 %48 to i16
  %50 = add i16 %47, %49
  store i16 %50, i16* %43, align 2
  %51 = getelementptr inbounds i16, i16* %13, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %50, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 1
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %13, i64 12
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 2
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %13, i64 14
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 3
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 %5
  %70 = getelementptr inbounds i16, i16* %13, i64 16
  %71 = bitcast i16* %70 to i32*
  %72 = getelementptr inbounds i16, i16* %69, i64 -1
  %73 = load i16, i16* %72, align 2
  %74 = load i32, i32* %71, align 4
  %75 = trunc i32 %74 to i16
  %76 = add i16 %73, %75
  store i16 %76, i16* %69, align 2
  %77 = getelementptr inbounds i16, i16* %13, i64 18
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %76, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 1
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %13, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 2
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %13, i64 22
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 3
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 %5
  %96 = getelementptr inbounds i16, i16* %13, i64 24
  %97 = bitcast i16* %96 to i32*
  %98 = getelementptr inbounds i16, i16* %95, i64 -1
  %99 = load i16, i16* %98, align 2
  %100 = load i32, i32* %97, align 4
  %101 = trunc i32 %100 to i16
  %102 = add i16 %99, %101
  store i16 %102, i16* %95, align 2
  %103 = getelementptr inbounds i16, i16* %13, i64 26
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %102, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 1
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %13, i64 28
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 2
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %13, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 3
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %7, 1
  %123 = icmp eq i64 %122, 16
  br i1 %123, label %124, label %6

124:                                              ; preds = %6
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_10_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = shl i64 %5, 32
  %7 = ashr exact i64 %6, 32
  %8 = sub nsw i64 0, %7
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  %11 = load i64, i64* %10, align 8
  %12 = bitcast i8* %0 to i64*
  store i64 %11, i64* %12, align 8
  %13 = getelementptr inbounds i16, i16* %4, i64 %7
  %14 = bitcast i16* %13 to i64*
  store i64 %11, i64* %14, align 8
  %15 = shl i64 %2, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 %11, i64* %19, align 8
  %20 = mul i64 %5, 12884901888
  %21 = ashr exact i64 %20, 32
  %22 = getelementptr inbounds i16, i16* %4, i64 %21
  %23 = bitcast i16* %22 to i64*
  store i64 %11, i64* %23, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_10_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = mul nuw i64 %10, 281479271743489
  %12 = bitcast i8* %0 to i64*
  store i64 %11, i64* %12, align 8
  %13 = shl i64 %5, 32
  %14 = add i64 %13, -4294967296
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i16, i16* %4, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i64
  %19 = mul nuw i64 %18, 281479271743489
  %20 = ashr exact i64 %13, 32
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = bitcast i16* %21 to i64*
  store i64 %19, i64* %22, align 8
  %23 = trunc i64 %2 to i32
  %24 = and i32 %23, -2
  %25 = add nsw i32 %24, -1
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds i16, i16* %4, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i64
  %30 = mul nuw i64 %29, 281479271743489
  %31 = sext i32 %24 to i64
  %32 = getelementptr inbounds i16, i16* %4, i64 %31
  %33 = bitcast i16* %32 to i64*
  store i64 %30, i64* %33, align 8
  %34 = mul nsw i32 %6, 3
  %35 = add nsw i32 %34, -1
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds i16, i16* %4, i64 %36
  %38 = load i16, i16* %37, align 2
  %39 = zext i16 %38 to i64
  %40 = mul nuw i64 %39, 281479271743489
  %41 = sext i32 %34 to i64
  %42 = getelementptr inbounds i16, i16* %4, i64 %41
  %43 = bitcast i16* %42 to i64*
  store i64 %40, i64* %43, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_dc_10_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = sub i64 0, %7
  %9 = ashr exact i64 %8, 32
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 4294967296, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 8589934592, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 12884901888, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = getelementptr inbounds i8, i8* %0, i64 -2
  %29 = bitcast i8* %28 to i16*
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i32
  %32 = add i64 %7, -4294967296
  %33 = ashr exact i64 %32, 32
  %34 = getelementptr inbounds i16, i16* %4, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = trunc i64 %2 to i32
  %38 = and i32 %37, -2
  %39 = add nsw i32 %38, -1
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds i16, i16* %4, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = mul nsw i32 %6, 3
  %45 = add nsw i32 %44, -1
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds i16, i16* %4, i64 %46
  %48 = load i16, i16* %47, align 2
  %49 = zext i16 %48 to i32
  %50 = add nuw nsw i32 %12, 4
  %51 = add nuw nsw i32 %50, %17
  %52 = add nuw nsw i32 %51, %22
  %53 = add nuw nsw i32 %52, %27
  %54 = add nuw nsw i32 %53, %31
  %55 = add nuw nsw i32 %54, %36
  %56 = add nuw nsw i32 %55, %43
  %57 = add nuw nsw i32 %56, %49
  %58 = ashr i32 %57, 3
  %59 = sext i32 %58 to i64
  %60 = mul i64 %59, 281479271743489
  %61 = bitcast i8* %0 to i64*
  store i64 %60, i64* %61, align 8
  %62 = ashr exact i64 %7, 32
  %63 = getelementptr inbounds i16, i16* %4, i64 %62
  %64 = bitcast i16* %63 to i64*
  store i64 %60, i64* %64, align 8
  %65 = sext i32 %38 to i64
  %66 = getelementptr inbounds i16, i16* %4, i64 %65
  %67 = bitcast i16* %66 to i64*
  store i64 %60, i64* %67, align 8
  %68 = sext i32 %44 to i64
  %69 = getelementptr inbounds i16, i16* %4, i64 %68
  %70 = bitcast i16* %69 to i64*
  store i64 %60, i64* %70, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_down_left_10_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i8* %1 to i16*
  %6 = lshr i64 %2, 1
  %7 = trunc i64 %6 to i32
  %8 = shl i64 %6, 32
  %9 = sub i64 0, %8
  %10 = ashr exact i64 %9, 32
  %11 = getelementptr inbounds i16, i16* %4, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i32
  %14 = sub i64 4294967296, %8
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i16, i16* %4, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i32
  %19 = sub i64 8589934592, %8
  %20 = ashr exact i64 %19, 32
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = sub i64 12884901888, %8
  %25 = ashr exact i64 %24, 32
  %26 = getelementptr inbounds i16, i16* %4, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %5, align 2
  %30 = zext i16 %29 to i32
  %31 = getelementptr inbounds i8, i8* %1, i64 2
  %32 = bitcast i8* %31 to i16*
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = getelementptr inbounds i8, i8* %1, i64 4
  %36 = bitcast i8* %35 to i16*
  %37 = load i16, i16* %36, align 2
  %38 = zext i16 %37 to i32
  %39 = getelementptr inbounds i8, i8* %1, i64 6
  %40 = bitcast i8* %39 to i16*
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i32
  %43 = shl nuw nsw i32 %18, 1
  %44 = add nuw nsw i32 %23, 2
  %45 = add nuw nsw i32 %44, %13
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = trunc i32 %47 to i16
  store i16 %48, i16* %4, align 2
  %49 = shl nuw nsw i32 %23, 1
  %50 = add nuw nsw i32 %28, 2
  %51 = add nuw nsw i32 %50, %18
  %52 = add nuw nsw i32 %51, %49
  %53 = lshr i32 %52, 2
  %54 = trunc i32 %53 to i16
  %55 = ashr exact i64 %8, 32
  %56 = getelementptr inbounds i16, i16* %4, i64 %55
  store i16 %54, i16* %56, align 2
  %57 = getelementptr inbounds i8, i8* %0, i64 2
  %58 = bitcast i8* %57 to i16*
  store i16 %54, i16* %58, align 2
  %59 = shl nuw nsw i32 %28, 1
  %60 = add nuw nsw i32 %44, %30
  %61 = add nuw nsw i32 %60, %59
  %62 = lshr i32 %61, 2
  %63 = trunc i32 %62 to i16
  %64 = trunc i64 %2 to i32
  %65 = and i32 %64, -2
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds i16, i16* %4, i64 %66
  store i16 %63, i16* %67, align 2
  %68 = add i64 %8, 4294967296
  %69 = ashr exact i64 %68, 32
  %70 = getelementptr inbounds i16, i16* %4, i64 %69
  store i16 %63, i16* %70, align 2
  %71 = getelementptr inbounds i8, i8* %0, i64 4
  %72 = bitcast i8* %71 to i16*
  store i16 %63, i16* %72, align 2
  %73 = shl nuw nsw i32 %30, 1
  %74 = add nuw nsw i32 %50, %34
  %75 = add nuw nsw i32 %74, %73
  %76 = lshr i32 %75, 2
  %77 = trunc i32 %76 to i16
  %78 = mul nsw i32 %7, 3
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i16, i16* %4, i64 %79
  store i16 %77, i16* %80, align 2
  %81 = shl i64 %2, 32
  %82 = ashr exact i64 %81, 32
  %83 = or i64 %82, 1
  %84 = getelementptr inbounds i16, i16* %4, i64 %83
  store i16 %77, i16* %84, align 2
  %85 = add i64 %8, 8589934592
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i16, i16* %4, i64 %86
  store i16 %77, i16* %87, align 2
  %88 = getelementptr inbounds i8, i8* %0, i64 6
  %89 = bitcast i8* %88 to i16*
  store i16 %77, i16* %89, align 2
  %90 = shl nuw nsw i32 %34, 1
  %91 = add nuw nsw i32 %30, 2
  %92 = add nuw nsw i32 %91, %38
  %93 = add nuw nsw i32 %92, %90
  %94 = lshr i32 %93, 2
  %95 = trunc i32 %94 to i16
  %96 = add nsw i32 %78, 1
  %97 = sext i32 %96 to i64
  %98 = getelementptr inbounds i16, i16* %4, i64 %97
  store i16 %95, i16* %98, align 2
  %99 = add nsw i32 %65, 2
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds i16, i16* %4, i64 %100
  store i16 %95, i16* %101, align 2
  %102 = add i64 %8, 12884901888
  %103 = ashr exact i64 %102, 32
  %104 = getelementptr inbounds i16, i16* %4, i64 %103
  store i16 %95, i16* %104, align 2
  %105 = shl nuw nsw i32 %38, 1
  %106 = add nuw nsw i32 %34, 2
  %107 = add nuw nsw i32 %106, %42
  %108 = add nuw nsw i32 %107, %105
  %109 = lshr i32 %108, 2
  %110 = trunc i32 %109 to i16
  %111 = add nsw i32 %78, 2
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds i16, i16* %4, i64 %112
  store i16 %110, i16* %113, align 2
  %114 = add nsw i32 %65, 3
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds i16, i16* %4, i64 %115
  store i16 %110, i16* %116, align 2
  %117 = mul nuw nsw i32 %42, 3
  %118 = add nuw nsw i32 %38, 2
  %119 = add nuw nsw i32 %118, %117
  %120 = lshr i32 %119, 2
  %121 = trunc i32 %120 to i16
  %122 = add nsw i32 %78, 3
  %123 = sext i32 %122 to i64
  %124 = getelementptr inbounds i16, i16* %4, i64 %123
  store i16 %121, i16* %124, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_down_right_10_c(i8*, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = xor i64 %8, -1
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 0, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 4294967296, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 8589934592, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = sub i64 12884901888, %7
  %29 = ashr exact i64 %28, 32
  %30 = getelementptr inbounds i16, i16* %4, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i32
  %33 = getelementptr inbounds i8, i8* %0, i64 -2
  %34 = bitcast i8* %33 to i16*
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = add i64 %7, -4294967296
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i16, i16* %4, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i32
  %42 = trunc i64 %2 to i32
  %43 = and i32 %42, -2
  %44 = add nsw i32 %43, -1
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i16, i16* %4, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i32
  %49 = mul nsw i32 %6, 3
  %50 = add nsw i32 %49, -1
  %51 = sext i32 %50 to i64
  %52 = getelementptr inbounds i16, i16* %4, i64 %51
  %53 = load i16, i16* %52, align 2
  %54 = zext i16 %53 to i32
  %55 = shl nuw nsw i32 %48, 1
  %56 = add nuw nsw i32 %41, 2
  %57 = add nuw nsw i32 %56, %54
  %58 = add nuw nsw i32 %57, %55
  %59 = lshr i32 %58, 2
  %60 = trunc i32 %59 to i16
  %61 = sext i32 %49 to i64
  %62 = getelementptr inbounds i16, i16* %4, i64 %61
  store i16 %60, i16* %62, align 2
  %63 = shl nuw nsw i32 %41, 1
  %64 = add nuw nsw i32 %36, 2
  %65 = add nuw nsw i32 %64, %48
  %66 = add nuw nsw i32 %65, %63
  %67 = lshr i32 %66, 2
  %68 = trunc i32 %67 to i16
  %69 = add nsw i32 %49, 1
  %70 = sext i32 %69 to i64
  %71 = getelementptr inbounds i16, i16* %4, i64 %70
  store i16 %68, i16* %71, align 2
  %72 = sext i32 %43 to i64
  %73 = getelementptr inbounds i16, i16* %4, i64 %72
  store i16 %68, i16* %73, align 2
  %74 = shl nuw nsw i32 %36, 1
  %75 = add nuw nsw i32 %12, 2
  %76 = add nuw nsw i32 %75, %41
  %77 = add nuw nsw i32 %76, %74
  %78 = lshr i32 %77, 2
  %79 = trunc i32 %78 to i16
  %80 = add nsw i32 %49, 2
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds i16, i16* %4, i64 %81
  store i16 %79, i16* %82, align 2
  %83 = shl i64 %2, 32
  %84 = ashr exact i64 %83, 32
  %85 = or i64 %84, 1
  %86 = getelementptr inbounds i16, i16* %4, i64 %85
  store i16 %79, i16* %86, align 2
  %87 = getelementptr inbounds i16, i16* %4, i64 %8
  store i16 %79, i16* %87, align 2
  %88 = shl nuw nsw i32 %12, 1
  %89 = add nuw nsw i32 %17, 2
  %90 = add nuw nsw i32 %89, %88
  %91 = add nuw nsw i32 %90, %36
  %92 = lshr i32 %91, 2
  %93 = trunc i32 %92 to i16
  %94 = add nsw i32 %49, 3
  %95 = sext i32 %94 to i64
  %96 = getelementptr inbounds i16, i16* %4, i64 %95
  store i16 %93, i16* %96, align 2
  %97 = add nsw i32 %43, 2
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds i16, i16* %4, i64 %98
  store i16 %93, i16* %99, align 2
  %100 = add i64 %7, 4294967296
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %4, i64 %101
  store i16 %93, i16* %102, align 2
  store i16 %93, i16* %4, align 2
  %103 = shl nuw nsw i32 %17, 1
  %104 = add nuw nsw i32 %75, %103
  %105 = add nuw nsw i32 %104, %22
  %106 = lshr i32 %105, 2
  %107 = trunc i32 %106 to i16
  %108 = add nsw i32 %43, 3
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds i16, i16* %4, i64 %109
  store i16 %107, i16* %110, align 2
  %111 = add i64 %7, 8589934592
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds i16, i16* %4, i64 %112
  store i16 %107, i16* %113, align 2
  %114 = getelementptr inbounds i8, i8* %0, i64 2
  %115 = bitcast i8* %114 to i16*
  store i16 %107, i16* %115, align 2
  %116 = shl nuw nsw i32 %22, 1
  %117 = add nuw nsw i32 %89, %116
  %118 = add nuw nsw i32 %117, %27
  %119 = lshr i32 %118, 2
  %120 = trunc i32 %119 to i16
  %121 = add i64 %7, 12884901888
  %122 = ashr exact i64 %121, 32
  %123 = getelementptr inbounds i16, i16* %4, i64 %122
  store i16 %120, i16* %123, align 2
  %124 = getelementptr inbounds i8, i8* %0, i64 4
  %125 = bitcast i8* %124 to i16*
  store i16 %120, i16* %125, align 2
  %126 = shl nuw nsw i32 %27, 1
  %127 = add nuw nsw i32 %22, 2
  %128 = add nuw nsw i32 %127, %126
  %129 = add nuw nsw i32 %128, %32
  %130 = lshr i32 %129, 2
  %131 = trunc i32 %130 to i16
  %132 = getelementptr inbounds i8, i8* %0, i64 6
  %133 = bitcast i8* %132 to i16*
  store i16 %131, i16* %133, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_right_10_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = xor i64 %8, -1
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 0, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 4294967296, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 8589934592, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = sub i64 12884901888, %7
  %29 = ashr exact i64 %28, 32
  %30 = getelementptr inbounds i16, i16* %4, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i32
  %33 = getelementptr inbounds i8, i8* %0, i64 -2
  %34 = bitcast i8* %33 to i16*
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = add i64 %7, -4294967296
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i16, i16* %4, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i32
  %42 = trunc i64 %2 to i32
  %43 = and i32 %42, -2
  %44 = add nsw i32 %43, -1
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i16, i16* %4, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i32
  %49 = mul nsw i32 %6, 3
  %50 = add nuw nsw i32 %17, 1
  %51 = add nuw nsw i32 %50, %12
  %52 = lshr i32 %51, 1
  %53 = trunc i32 %52 to i16
  %54 = shl i64 %2, 32
  %55 = ashr exact i64 %54, 32
  %56 = or i64 %55, 1
  %57 = getelementptr inbounds i16, i16* %4, i64 %56
  store i16 %53, i16* %57, align 2
  store i16 %53, i16* %4, align 2
  %58 = add nuw nsw i32 %50, %22
  %59 = lshr i32 %58, 1
  %60 = trunc i32 %59 to i16
  %61 = add nsw i32 %43, 2
  %62 = sext i32 %61 to i64
  %63 = getelementptr inbounds i16, i16* %4, i64 %62
  store i16 %60, i16* %63, align 2
  %64 = getelementptr inbounds i8, i8* %0, i64 2
  %65 = bitcast i8* %64 to i16*
  store i16 %60, i16* %65, align 2
  %66 = add nuw nsw i32 %22, 1
  %67 = add nuw nsw i32 %66, %27
  %68 = lshr i32 %67, 1
  %69 = trunc i32 %68 to i16
  %70 = add nsw i32 %43, 3
  %71 = sext i32 %70 to i64
  %72 = getelementptr inbounds i16, i16* %4, i64 %71
  store i16 %69, i16* %72, align 2
  %73 = getelementptr inbounds i8, i8* %0, i64 4
  %74 = bitcast i8* %73 to i16*
  store i16 %69, i16* %74, align 2
  %75 = add nuw nsw i32 %27, 1
  %76 = add nuw nsw i32 %75, %32
  %77 = lshr i32 %76, 1
  %78 = trunc i32 %77 to i16
  %79 = getelementptr inbounds i8, i8* %0, i64 6
  %80 = bitcast i8* %79 to i16*
  store i16 %78, i16* %80, align 2
  %81 = shl nuw nsw i32 %12, 1
  %82 = add nuw nsw i32 %17, 2
  %83 = add nuw nsw i32 %82, %81
  %84 = add nuw nsw i32 %83, %36
  %85 = lshr i32 %84, 2
  %86 = trunc i32 %85 to i16
  %87 = add nsw i32 %49, 1
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds i16, i16* %4, i64 %88
  store i16 %86, i16* %89, align 2
  %90 = getelementptr inbounds i16, i16* %4, i64 %8
  store i16 %86, i16* %90, align 2
  %91 = shl nuw nsw i32 %17, 1
  %92 = add nuw nsw i32 %12, 2
  %93 = add nuw nsw i32 %92, %91
  %94 = add nuw nsw i32 %93, %22
  %95 = lshr i32 %94, 2
  %96 = trunc i32 %95 to i16
  %97 = add nsw i32 %49, 2
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds i16, i16* %4, i64 %98
  store i16 %96, i16* %99, align 2
  %100 = add i64 %7, 4294967296
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %4, i64 %101
  store i16 %96, i16* %102, align 2
  %103 = shl nuw nsw i32 %22, 1
  %104 = add nuw nsw i32 %82, %103
  %105 = add nuw nsw i32 %104, %27
  %106 = lshr i32 %105, 2
  %107 = trunc i32 %106 to i16
  %108 = add nsw i32 %49, 3
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds i16, i16* %4, i64 %109
  store i16 %107, i16* %110, align 2
  %111 = add i64 %7, 8589934592
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds i16, i16* %4, i64 %112
  store i16 %107, i16* %113, align 2
  %114 = shl nuw nsw i32 %27, 1
  %115 = add nuw nsw i32 %22, 2
  %116 = add nuw nsw i32 %115, %114
  %117 = add nuw nsw i32 %116, %32
  %118 = lshr i32 %117, 2
  %119 = trunc i32 %118 to i16
  %120 = add i64 %7, 12884901888
  %121 = ashr exact i64 %120, 32
  %122 = getelementptr inbounds i16, i16* %4, i64 %121
  store i16 %119, i16* %122, align 2
  %123 = shl nuw nsw i32 %36, 1
  %124 = add nuw nsw i32 %92, %123
  %125 = add nuw nsw i32 %124, %41
  %126 = lshr i32 %125, 2
  %127 = trunc i32 %126 to i16
  %128 = sext i32 %43 to i64
  %129 = getelementptr inbounds i16, i16* %4, i64 %128
  store i16 %127, i16* %129, align 2
  %130 = shl nuw nsw i32 %41, 1
  %131 = add nuw nsw i32 %36, 2
  %132 = add nuw nsw i32 %131, %130
  %133 = add nuw nsw i32 %132, %48
  %134 = lshr i32 %133, 2
  %135 = trunc i32 %134 to i16
  %136 = sext i32 %49 to i64
  %137 = getelementptr inbounds i16, i16* %4, i64 %136
  store i16 %135, i16* %137, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_down_10_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = xor i64 %8, -1
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 0, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 4294967296, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 8589934592, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = getelementptr inbounds i8, i8* %0, i64 -2
  %29 = bitcast i8* %28 to i16*
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i32
  %32 = add i64 %7, -4294967296
  %33 = ashr exact i64 %32, 32
  %34 = getelementptr inbounds i16, i16* %4, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = trunc i64 %2 to i32
  %38 = and i32 %37, -2
  %39 = add nsw i32 %38, -1
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds i16, i16* %4, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = mul nsw i32 %6, 3
  %45 = add nsw i32 %44, -1
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds i16, i16* %4, i64 %46
  %48 = load i16, i16* %47, align 2
  %49 = zext i16 %48 to i32
  %50 = add nuw nsw i32 %31, 1
  %51 = add nuw nsw i32 %50, %12
  %52 = lshr i32 %51, 1
  %53 = trunc i32 %52 to i16
  %54 = add i64 %7, 8589934592
  %55 = ashr exact i64 %54, 32
  %56 = getelementptr inbounds i16, i16* %4, i64 %55
  store i16 %53, i16* %56, align 2
  store i16 %53, i16* %4, align 2
  %57 = shl nuw nsw i32 %12, 1
  %58 = add nuw nsw i32 %17, 2
  %59 = add nuw nsw i32 %58, %57
  %60 = add nuw nsw i32 %59, %31
  %61 = lshr i32 %60, 2
  %62 = trunc i32 %61 to i16
  %63 = add i64 %7, 12884901888
  %64 = ashr exact i64 %63, 32
  %65 = getelementptr inbounds i16, i16* %4, i64 %64
  store i16 %62, i16* %65, align 2
  %66 = getelementptr inbounds i8, i8* %0, i64 2
  %67 = bitcast i8* %66 to i16*
  store i16 %62, i16* %67, align 2
  %68 = shl nuw nsw i32 %17, 1
  %69 = add nuw nsw i32 %12, 2
  %70 = add nuw nsw i32 %69, %68
  %71 = add nuw nsw i32 %70, %22
  %72 = lshr i32 %71, 2
  %73 = trunc i32 %72 to i16
  %74 = getelementptr inbounds i8, i8* %0, i64 4
  %75 = bitcast i8* %74 to i16*
  store i16 %73, i16* %75, align 2
  %76 = shl nuw nsw i32 %22, 1
  %77 = add nuw nsw i32 %58, %76
  %78 = add nuw nsw i32 %77, %27
  %79 = lshr i32 %78, 2
  %80 = trunc i32 %79 to i16
  %81 = getelementptr inbounds i8, i8* %0, i64 6
  %82 = bitcast i8* %81 to i16*
  store i16 %80, i16* %82, align 2
  %83 = add nuw nsw i32 %50, %36
  %84 = lshr i32 %83, 1
  %85 = trunc i32 %84 to i16
  %86 = add nsw i32 %38, 2
  %87 = sext i32 %86 to i64
  %88 = getelementptr inbounds i16, i16* %4, i64 %87
  store i16 %85, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %4, i64 %8
  store i16 %85, i16* %89, align 2
  %90 = shl nuw nsw i32 %31, 1
  %91 = add nuw nsw i32 %69, %90
  %92 = add nuw nsw i32 %91, %36
  %93 = lshr i32 %92, 2
  %94 = trunc i32 %93 to i16
  %95 = add nsw i32 %38, 3
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %4, i64 %96
  store i16 %94, i16* %97, align 2
  %98 = add i64 %7, 4294967296
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i16, i16* %4, i64 %99
  store i16 %94, i16* %100, align 2
  %101 = add nuw nsw i32 %36, 1
  %102 = add nuw nsw i32 %101, %43
  %103 = lshr i32 %102, 1
  %104 = trunc i32 %103 to i16
  %105 = add nsw i32 %44, 2
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i16, i16* %4, i64 %106
  store i16 %104, i16* %107, align 2
  %108 = sext i32 %38 to i64
  %109 = getelementptr inbounds i16, i16* %4, i64 %108
  store i16 %104, i16* %109, align 2
  %110 = shl nuw nsw i32 %36, 1
  %111 = add nuw nsw i32 %31, 2
  %112 = add nuw nsw i32 %111, %110
  %113 = add nuw nsw i32 %112, %43
  %114 = lshr i32 %113, 2
  %115 = trunc i32 %114 to i16
  %116 = add nsw i32 %44, 3
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds i16, i16* %4, i64 %117
  store i16 %115, i16* %118, align 2
  %119 = shl i64 %2, 32
  %120 = ashr exact i64 %119, 32
  %121 = or i64 %120, 1
  %122 = getelementptr inbounds i16, i16* %4, i64 %121
  store i16 %115, i16* %122, align 2
  %123 = add nuw nsw i32 %43, 1
  %124 = add nuw nsw i32 %123, %49
  %125 = lshr i32 %124, 1
  %126 = trunc i32 %125 to i16
  %127 = sext i32 %44 to i64
  %128 = getelementptr inbounds i16, i16* %4, i64 %127
  store i16 %126, i16* %128, align 2
  %129 = shl nuw nsw i32 %43, 1
  %130 = add nuw nsw i32 %36, 2
  %131 = add nuw nsw i32 %130, %129
  %132 = add nuw nsw i32 %131, %49
  %133 = lshr i32 %132, 2
  %134 = trunc i32 %133 to i16
  %135 = add nsw i32 %44, 1
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds i16, i16* %4, i64 %136
  store i16 %134, i16* %137, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_left_10_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i8* %1 to i16*
  %6 = lshr i64 %2, 1
  %7 = trunc i64 %6 to i32
  %8 = shl i64 %6, 32
  %9 = sub i64 0, %8
  %10 = ashr exact i64 %9, 32
  %11 = getelementptr inbounds i16, i16* %4, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i32
  %14 = sub i64 4294967296, %8
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i16, i16* %4, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i32
  %19 = sub i64 8589934592, %8
  %20 = ashr exact i64 %19, 32
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = sub i64 12884901888, %8
  %25 = ashr exact i64 %24, 32
  %26 = getelementptr inbounds i16, i16* %4, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %5, align 2
  %30 = zext i16 %29 to i32
  %31 = getelementptr inbounds i8, i8* %1, i64 2
  %32 = bitcast i8* %31 to i16*
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = getelementptr inbounds i8, i8* %1, i64 4
  %36 = bitcast i8* %35 to i16*
  %37 = load i16, i16* %36, align 2
  %38 = zext i16 %37 to i32
  %39 = add nuw nsw i32 %18, 1
  %40 = add nuw nsw i32 %39, %13
  %41 = lshr i32 %40, 1
  %42 = trunc i32 %41 to i16
  store i16 %42, i16* %4, align 2
  %43 = add nuw nsw i32 %39, %23
  %44 = lshr i32 %43, 1
  %45 = trunc i32 %44 to i16
  %46 = trunc i64 %2 to i32
  %47 = and i32 %46, -2
  %48 = sext i32 %47 to i64
  %49 = getelementptr inbounds i16, i16* %4, i64 %48
  store i16 %45, i16* %49, align 2
  %50 = getelementptr inbounds i8, i8* %0, i64 2
  %51 = bitcast i8* %50 to i16*
  store i16 %45, i16* %51, align 2
  %52 = add nuw nsw i32 %23, 1
  %53 = add nuw nsw i32 %52, %28
  %54 = lshr i32 %53, 1
  %55 = trunc i32 %54 to i16
  %56 = shl i64 %2, 32
  %57 = ashr exact i64 %56, 32
  %58 = or i64 %57, 1
  %59 = getelementptr inbounds i16, i16* %4, i64 %58
  store i16 %55, i16* %59, align 2
  %60 = getelementptr inbounds i8, i8* %0, i64 4
  %61 = bitcast i8* %60 to i16*
  store i16 %55, i16* %61, align 2
  %62 = add nuw nsw i32 %28, 1
  %63 = add nuw nsw i32 %62, %30
  %64 = lshr i32 %63, 1
  %65 = trunc i32 %64 to i16
  %66 = add nsw i32 %47, 2
  %67 = sext i32 %66 to i64
  %68 = getelementptr inbounds i16, i16* %4, i64 %67
  store i16 %65, i16* %68, align 2
  %69 = getelementptr inbounds i8, i8* %0, i64 6
  %70 = bitcast i8* %69 to i16*
  store i16 %65, i16* %70, align 2
  %71 = add nuw nsw i32 %30, 1
  %72 = add nuw nsw i32 %71, %34
  %73 = lshr i32 %72, 1
  %74 = trunc i32 %73 to i16
  %75 = add nsw i32 %47, 3
  %76 = sext i32 %75 to i64
  %77 = getelementptr inbounds i16, i16* %4, i64 %76
  store i16 %74, i16* %77, align 2
  %78 = shl nuw nsw i32 %18, 1
  %79 = add nuw nsw i32 %23, 2
  %80 = add nuw nsw i32 %79, %13
  %81 = add nuw nsw i32 %80, %78
  %82 = lshr i32 %81, 2
  %83 = trunc i32 %82 to i16
  %84 = ashr exact i64 %8, 32
  %85 = getelementptr inbounds i16, i16* %4, i64 %84
  store i16 %83, i16* %85, align 2
  %86 = shl nuw nsw i32 %23, 1
  %87 = add nuw nsw i32 %28, 2
  %88 = add nuw nsw i32 %87, %18
  %89 = add nuw nsw i32 %88, %86
  %90 = lshr i32 %89, 2
  %91 = trunc i32 %90 to i16
  %92 = mul nsw i32 %7, 3
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds i16, i16* %4, i64 %93
  store i16 %91, i16* %94, align 2
  %95 = add i64 %8, 4294967296
  %96 = ashr exact i64 %95, 32
  %97 = getelementptr inbounds i16, i16* %4, i64 %96
  store i16 %91, i16* %97, align 2
  %98 = shl nuw nsw i32 %28, 1
  %99 = add nuw nsw i32 %79, %98
  %100 = add nuw nsw i32 %99, %30
  %101 = lshr i32 %100, 2
  %102 = trunc i32 %101 to i16
  %103 = add nsw i32 %92, 1
  %104 = sext i32 %103 to i64
  %105 = getelementptr inbounds i16, i16* %4, i64 %104
  store i16 %102, i16* %105, align 2
  %106 = add i64 %8, 8589934592
  %107 = ashr exact i64 %106, 32
  %108 = getelementptr inbounds i16, i16* %4, i64 %107
  store i16 %102, i16* %108, align 2
  %109 = shl nuw nsw i32 %30, 1
  %110 = add nuw nsw i32 %87, %109
  %111 = add nuw nsw i32 %110, %34
  %112 = lshr i32 %111, 2
  %113 = trunc i32 %112 to i16
  %114 = add nsw i32 %92, 2
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds i16, i16* %4, i64 %115
  store i16 %113, i16* %116, align 2
  %117 = add i64 %8, 12884901888
  %118 = ashr exact i64 %117, 32
  %119 = getelementptr inbounds i16, i16* %4, i64 %118
  store i16 %113, i16* %119, align 2
  %120 = shl nuw nsw i32 %34, 1
  %121 = add nuw nsw i32 %30, 2
  %122 = add nuw nsw i32 %121, %120
  %123 = add nuw nsw i32 %122, %38
  %124 = lshr i32 %123, 2
  %125 = trunc i32 %124 to i16
  %126 = add nsw i32 %92, 3
  %127 = sext i32 %126 to i64
  %128 = getelementptr inbounds i16, i16* %4, i64 %127
  store i16 %125, i16* %128, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_up_10_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i32
  %11 = shl i64 %5, 32
  %12 = add i64 %11, -4294967296
  %13 = ashr exact i64 %12, 32
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i32
  %17 = trunc i64 %2 to i32
  %18 = and i32 %17, -2
  %19 = add nsw i32 %18, -1
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = mul nsw i32 %6, 3
  %25 = add nsw i32 %24, -1
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds i16, i16* %4, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i32
  %30 = add nuw nsw i32 %16, 1
  %31 = add nuw nsw i32 %30, %10
  %32 = lshr i32 %31, 1
  %33 = trunc i32 %32 to i16
  store i16 %33, i16* %4, align 2
  %34 = shl nuw nsw i32 %16, 1
  %35 = add nuw nsw i32 %23, 2
  %36 = add nuw nsw i32 %35, %10
  %37 = add nuw nsw i32 %36, %34
  %38 = lshr i32 %37, 2
  %39 = trunc i32 %38 to i16
  %40 = getelementptr inbounds i8, i8* %0, i64 2
  %41 = bitcast i8* %40 to i16*
  store i16 %39, i16* %41, align 2
  %42 = add nuw nsw i32 %30, %23
  %43 = lshr i32 %42, 1
  %44 = trunc i32 %43 to i16
  %45 = ashr exact i64 %11, 32
  %46 = getelementptr inbounds i16, i16* %4, i64 %45
  store i16 %44, i16* %46, align 2
  %47 = getelementptr inbounds i8, i8* %0, i64 4
  %48 = bitcast i8* %47 to i16*
  store i16 %44, i16* %48, align 2
  %49 = shl nuw nsw i32 %23, 1
  %50 = add nuw nsw i32 %29, 2
  %51 = add nuw nsw i32 %50, %16
  %52 = add nuw nsw i32 %51, %49
  %53 = lshr i32 %52, 2
  %54 = trunc i32 %53 to i16
  %55 = add i64 %11, 4294967296
  %56 = ashr exact i64 %55, 32
  %57 = getelementptr inbounds i16, i16* %4, i64 %56
  store i16 %54, i16* %57, align 2
  %58 = getelementptr inbounds i8, i8* %0, i64 6
  %59 = bitcast i8* %58 to i16*
  store i16 %54, i16* %59, align 2
  %60 = add nuw nsw i32 %23, 1
  %61 = add nuw nsw i32 %60, %29
  %62 = lshr i32 %61, 1
  %63 = trunc i32 %62 to i16
  %64 = sext i32 %18 to i64
  %65 = getelementptr inbounds i16, i16* %4, i64 %64
  store i16 %63, i16* %65, align 2
  %66 = add i64 %11, 8589934592
  %67 = ashr exact i64 %66, 32
  %68 = getelementptr inbounds i16, i16* %4, i64 %67
  store i16 %63, i16* %68, align 2
  %69 = shl nuw nsw i32 %29, 1
  %70 = add nuw nsw i32 %35, %29
  %71 = add nuw nsw i32 %70, %69
  %72 = lshr i32 %71, 2
  %73 = trunc i32 %72 to i16
  %74 = shl i64 %2, 32
  %75 = ashr exact i64 %74, 32
  %76 = or i64 %75, 1
  %77 = getelementptr inbounds i16, i16* %4, i64 %76
  store i16 %73, i16* %77, align 2
  %78 = add i64 %11, 12884901888
  %79 = ashr exact i64 %78, 32
  %80 = getelementptr inbounds i16, i16* %4, i64 %79
  store i16 %73, i16* %80, align 2
  %81 = add nsw i32 %24, 3
  %82 = sext i32 %81 to i64
  %83 = getelementptr inbounds i16, i16* %4, i64 %82
  store i16 %28, i16* %83, align 2
  %84 = add nsw i32 %24, 2
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i16, i16* %4, i64 %85
  store i16 %28, i16* %86, align 2
  %87 = add nsw i32 %18, 2
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds i16, i16* %4, i64 %88
  store i16 %28, i16* %89, align 2
  %90 = sext i32 %24 to i64
  %91 = getelementptr inbounds i16, i16* %4, i64 %90
  store i16 %28, i16* %91, align 2
  %92 = add nsw i32 %24, 1
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds i16, i16* %4, i64 %93
  store i16 %28, i16* %94, align 2
  %95 = add nsw i32 %18, 3
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %4, i64 %96
  store i16 %28, i16* %97, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_left_dc_10_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = shl i64 %5, 32
  %12 = add i64 %11, -4294967296
  %13 = ashr exact i64 %12, 32
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = trunc i64 %2 to i32
  %18 = and i32 %17, -2
  %19 = add nsw i32 %18, -1
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i64
  %24 = mul nsw i32 %6, 3
  %25 = add nsw i32 %24, -1
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds i16, i16* %4, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i64
  %30 = add nuw nsw i64 %10, 2
  %31 = add nuw nsw i64 %30, %16
  %32 = add nuw nsw i64 %31, %23
  %33 = add nuw nsw i64 %32, %29
  %34 = lshr i64 %33, 2
  %35 = mul i64 %34, 281479271743489
  %36 = bitcast i8* %0 to i64*
  store i64 %35, i64* %36, align 8
  %37 = ashr exact i64 %11, 32
  %38 = getelementptr inbounds i16, i16* %4, i64 %37
  %39 = bitcast i16* %38 to i64*
  store i64 %35, i64* %39, align 8
  %40 = sext i32 %18 to i64
  %41 = getelementptr inbounds i16, i16* %4, i64 %40
  %42 = bitcast i16* %41 to i64*
  store i64 %35, i64* %42, align 8
  %43 = sext i32 %24 to i64
  %44 = getelementptr inbounds i16, i16* %4, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %35, i64* %45, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_top_dc_10_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = shl i64 %5, 32
  %7 = sub i64 0, %6
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  %12 = sub i64 4294967296, %6
  %13 = ashr exact i64 %12, 32
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = sub i64 8589934592, %6
  %18 = ashr exact i64 %17, 32
  %19 = getelementptr inbounds i16, i16* %4, i64 %18
  %20 = load i16, i16* %19, align 2
  %21 = zext i16 %20 to i64
  %22 = sub i64 12884901888, %6
  %23 = ashr exact i64 %22, 32
  %24 = getelementptr inbounds i16, i16* %4, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = add nuw nsw i64 %11, 2
  %28 = add nuw nsw i64 %27, %16
  %29 = add nuw nsw i64 %28, %21
  %30 = add nuw nsw i64 %29, %26
  %31 = lshr i64 %30, 2
  %32 = mul i64 %31, 281479271743489
  %33 = bitcast i8* %0 to i64*
  store i64 %32, i64* %33, align 8
  %34 = ashr exact i64 %6, 32
  %35 = getelementptr inbounds i16, i16* %4, i64 %34
  %36 = bitcast i16* %35 to i64*
  store i64 %32, i64* %36, align 8
  %37 = shl i64 %2, 32
  %38 = ashr exact i64 %37, 32
  %39 = and i64 %38, -2
  %40 = getelementptr inbounds i16, i16* %4, i64 %39
  %41 = bitcast i16* %40 to i64*
  store i64 %32, i64* %41, align 8
  %42 = mul i64 %5, 12884901888
  %43 = ashr exact i64 %42, 32
  %44 = getelementptr inbounds i16, i16* %4, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %32, i64* %45, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_127_dc_10_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = bitcast i8* %0 to i64*
  store i64 143835907860922879, i64* %6, align 8
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  store i64 143835907860922879, i64* %10, align 8
  %11 = shl i64 %2, 32
  %12 = ashr exact i64 %11, 32
  %13 = and i64 %12, -2
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = bitcast i16* %14 to i64*
  store i64 143835907860922879, i64* %15, align 8
  %16 = mul i64 %5, 12884901888
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 143835907860922879, i64* %19, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_129_dc_10_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = bitcast i8* %0 to i64*
  store i64 144398866404409857, i64* %6, align 8
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  store i64 144398866404409857, i64* %10, align 8
  %11 = shl i64 %2, 32
  %12 = ashr exact i64 %11, 32
  %13 = and i64 %12, -2
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = bitcast i16* %14 to i64*
  store i64 144398866404409857, i64* %15, align 8
  %16 = mul i64 %5, 12884901888
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 144398866404409857, i64* %19, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_128_dc_10_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = bitcast i8* %0 to i64*
  store i64 144117387132666368, i64* %6, align 8
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  store i64 144117387132666368, i64* %10, align 8
  %11 = shl i64 %2, 32
  %12 = ashr exact i64 %11, 32
  %13 = and i64 %12, -2
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = bitcast i16* %14 to i64*
  store i64 144117387132666368, i64* %15, align 8
  %16 = mul i64 %5, 12884901888
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 144117387132666368, i64* %19, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_10_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %103, label %97

97:                                               ; preds = %18
  %98 = sub i64 34359738368, %19
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i16, i16* %5, i64 %99
  %101 = load i16, i16* %100, align 2
  %102 = zext i16 %101 to i32
  br label %103

103:                                              ; preds = %18, %97
  %104 = phi i32 [ %102, %97 ], [ %91, %18 ]
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %81, 2
  %107 = add nuw nsw i32 %106, %105
  %108 = add nuw nsw i32 %107, %104
  %109 = lshr i32 %108, 2
  %110 = trunc i32 %37 to i16
  store i16 %110, i16* %5, align 2
  %111 = trunc i32 %47 to i16
  %112 = getelementptr inbounds i8, i8* %0, i64 2
  %113 = bitcast i8* %112 to i16*
  store i16 %111, i16* %113, align 2
  %114 = trunc i32 %56 to i16
  %115 = getelementptr inbounds i8, i8* %0, i64 4
  %116 = bitcast i8* %115 to i16*
  store i16 %114, i16* %116, align 2
  %117 = trunc i32 %65 to i16
  %118 = getelementptr inbounds i8, i8* %0, i64 6
  %119 = bitcast i8* %118 to i16*
  store i16 %117, i16* %119, align 2
  %120 = trunc i32 %75 to i16
  %121 = getelementptr inbounds i8, i8* %0, i64 8
  %122 = bitcast i8* %121 to i16*
  store i16 %120, i16* %122, align 2
  %123 = trunc i32 %85 to i16
  %124 = getelementptr inbounds i8, i8* %0, i64 10
  %125 = bitcast i8* %124 to i16*
  store i16 %123, i16* %125, align 2
  %126 = trunc i32 %95 to i16
  %127 = getelementptr inbounds i8, i8* %0, i64 12
  %128 = bitcast i8* %127 to i16*
  store i16 %126, i16* %128, align 2
  %129 = trunc i32 %109 to i16
  %130 = getelementptr inbounds i8, i8* %0, i64 14
  %131 = bitcast i8* %130 to i16*
  store i16 %129, i16* %131, align 2
  %132 = bitcast i8* %0 to i64*
  %133 = load i64, i64* %132, align 8
  %134 = bitcast i8* %121 to i64*
  %135 = load i64, i64* %134, align 8
  %136 = shl i64 %6, 32
  %137 = ashr exact i64 %136, 32
  %138 = getelementptr inbounds i16, i16* %5, i64 %137
  %139 = bitcast i16* %138 to i64*
  store i64 %133, i64* %139, align 8
  %140 = getelementptr inbounds i16, i16* %138, i64 4
  %141 = bitcast i16* %140 to i64*
  store i64 %135, i64* %141, align 8
  %142 = ashr exact i64 %136, 31
  %143 = getelementptr inbounds i16, i16* %5, i64 %142
  %144 = bitcast i16* %143 to i64*
  store i64 %133, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %143, i64 4
  %146 = bitcast i16* %145 to i64*
  store i64 %135, i64* %146, align 8
  %147 = mul nsw i64 %137, 3
  %148 = getelementptr inbounds i16, i16* %5, i64 %147
  %149 = bitcast i16* %148 to i64*
  store i64 %133, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %148, i64 4
  %151 = bitcast i16* %150 to i64*
  store i64 %135, i64* %151, align 8
  %152 = ashr exact i64 %136, 30
  %153 = getelementptr inbounds i16, i16* %5, i64 %152
  %154 = bitcast i16* %153 to i64*
  store i64 %133, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %153, i64 4
  %156 = bitcast i16* %155 to i64*
  store i64 %135, i64* %156, align 8
  %157 = mul nsw i64 %137, 5
  %158 = getelementptr inbounds i16, i16* %5, i64 %157
  %159 = bitcast i16* %158 to i64*
  store i64 %133, i64* %159, align 8
  %160 = getelementptr inbounds i16, i16* %158, i64 4
  %161 = bitcast i16* %160 to i64*
  store i64 %135, i64* %161, align 8
  %162 = mul nsw i64 %137, 6
  %163 = getelementptr inbounds i16, i16* %5, i64 %162
  %164 = bitcast i16* %163 to i64*
  store i64 %133, i64* %164, align 8
  %165 = getelementptr inbounds i16, i16* %163, i64 4
  %166 = bitcast i16* %165 to i64*
  store i64 %135, i64* %166, align 8
  %167 = mul nsw i64 %137, 7
  %168 = getelementptr inbounds i16, i16* %5, i64 %167
  %169 = bitcast i16* %168 to i64*
  store i64 %133, i64* %169, align 8
  %170 = getelementptr inbounds i16, i16* %168, i64 4
  %171 = bitcast i16* %170 to i64*
  store i64 %135, i64* %171, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_10_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  br i1 %8, label %14, label %9

9:                                                ; preds = %4
  %10 = shl i64 %6, 32
  %11 = ashr exact i64 %10, 32
  %12 = xor i64 %11, -1
  %13 = getelementptr inbounds i16, i16* %5, i64 %12
  br label %19

14:                                               ; preds = %4
  %15 = getelementptr inbounds i8, i8* %0, i64 -2
  %16 = bitcast i8* %15 to i16*
  %17 = shl i64 %6, 32
  %18 = ashr exact i64 %17, 32
  br label %19

19:                                               ; preds = %14, %9
  %20 = phi i64 [ %18, %14 ], [ %11, %9 ]
  %21 = phi i64 [ %17, %14 ], [ %10, %9 ]
  %22 = phi i16* [ %16, %14 ], [ %13, %9 ]
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i8, i8* %0, i64 -2
  %26 = bitcast i8* %25 to i16*
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = shl nuw nsw i32 %28, 1
  %30 = add i64 %21, -4294967296
  %31 = ashr exact i64 %30, 32
  %32 = getelementptr inbounds i16, i16* %5, i64 %31
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = add nuw nsw i32 %34, 2
  %36 = add nuw nsw i32 %35, %24
  %37 = add nuw nsw i32 %36, %29
  %38 = lshr i32 %37, 2
  %39 = shl nuw nsw i32 %34, 1
  %40 = trunc i64 %3 to i32
  %41 = and i32 %40, -2
  %42 = add nsw i32 %41, -1
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i16, i16* %5, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %28
  %49 = add nuw nsw i32 %48, %39
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = mul nsw i32 %7, 3
  %53 = add nsw i32 %52, -1
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i16, i16* %5, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i32
  %58 = add nuw nsw i32 %35, %51
  %59 = add nuw nsw i32 %58, %57
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %57, 1
  %62 = shl i64 %6, 34
  %63 = add i64 %62, -4294967296
  %64 = ashr exact i64 %63, 32
  %65 = getelementptr inbounds i16, i16* %5, i64 %64
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = add nuw nsw i32 %47, %61
  %69 = add nuw nsw i32 %68, %67
  %70 = lshr i32 %69, 2
  %71 = shl nuw nsw i32 %67, 1
  %72 = mul nsw i32 %7, 5
  %73 = add nsw i32 %72, -1
  %74 = sext i32 %73 to i64
  %75 = getelementptr inbounds i16, i16* %5, i64 %74
  %76 = load i16, i16* %75, align 2
  %77 = zext i16 %76 to i32
  %78 = add nuw nsw i32 %57, 2
  %79 = add nuw nsw i32 %78, %71
  %80 = add nuw nsw i32 %79, %77
  %81 = lshr i32 %80, 2
  %82 = shl nuw nsw i32 %77, 1
  %83 = mul nsw i32 %7, 6
  %84 = add nsw i32 %83, -1
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i16, i16* %5, i64 %85
  %87 = load i16, i16* %86, align 2
  %88 = zext i16 %87 to i32
  %89 = add nuw nsw i32 %67, 2
  %90 = add nuw nsw i32 %89, %82
  %91 = add nuw nsw i32 %90, %88
  %92 = lshr i32 %91, 2
  %93 = shl nuw nsw i32 %88, 1
  %94 = mul nsw i32 %7, 7
  %95 = add nsw i32 %94, -1
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %5, i64 %96
  %98 = load i16, i16* %97, align 2
  %99 = zext i16 %98 to i32
  %100 = add nuw nsw i32 %77, 2
  %101 = add nuw nsw i32 %100, %93
  %102 = add nuw nsw i32 %101, %99
  %103 = lshr i32 %102, 2
  %104 = mul nuw nsw i32 %99, 3
  %105 = add nuw nsw i32 %88, 2
  %106 = add nuw nsw i32 %105, %104
  %107 = lshr i32 %106, 2
  %108 = zext i32 %38 to i64
  %109 = mul i64 %108, 281479271743489
  %110 = bitcast i8* %0 to i64*
  store i64 %109, i64* %110, align 8
  %111 = getelementptr inbounds i8, i8* %0, i64 8
  %112 = bitcast i8* %111 to i64*
  store i64 %109, i64* %112, align 8
  %113 = zext i32 %50 to i64
  %114 = mul i64 %113, 281479271743489
  %115 = getelementptr inbounds i16, i16* %5, i64 %20
  %116 = bitcast i16* %115 to i64*
  store i64 %114, i64* %116, align 8
  %117 = getelementptr inbounds i16, i16* %115, i64 4
  %118 = bitcast i16* %117 to i64*
  store i64 %114, i64* %118, align 8
  %119 = zext i32 %60 to i64
  %120 = mul i64 %119, 281479271743489
  %121 = sext i32 %41 to i64
  %122 = getelementptr inbounds i16, i16* %5, i64 %121
  %123 = bitcast i16* %122 to i64*
  store i64 %120, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %122, i64 4
  %125 = bitcast i16* %124 to i64*
  store i64 %120, i64* %125, align 8
  %126 = zext i32 %70 to i64
  %127 = mul i64 %126, 281479271743489
  %128 = sext i32 %52 to i64
  %129 = getelementptr inbounds i16, i16* %5, i64 %128
  %130 = bitcast i16* %129 to i64*
  store i64 %127, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %129, i64 4
  %132 = bitcast i16* %131 to i64*
  store i64 %127, i64* %132, align 8
  %133 = zext i32 %81 to i64
  %134 = mul i64 %133, 281479271743489
  %135 = ashr exact i64 %62, 32
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  %137 = bitcast i16* %136 to i64*
  store i64 %134, i64* %137, align 8
  %138 = getelementptr inbounds i16, i16* %136, i64 4
  %139 = bitcast i16* %138 to i64*
  store i64 %134, i64* %139, align 8
  %140 = zext i32 %92 to i64
  %141 = mul i64 %140, 281479271743489
  %142 = sext i32 %72 to i64
  %143 = getelementptr inbounds i16, i16* %5, i64 %142
  %144 = bitcast i16* %143 to i64*
  store i64 %141, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %143, i64 4
  %146 = bitcast i16* %145 to i64*
  store i64 %141, i64* %146, align 8
  %147 = zext i32 %103 to i64
  %148 = mul i64 %147, 281479271743489
  %149 = sext i32 %83 to i64
  %150 = getelementptr inbounds i16, i16* %5, i64 %149
  %151 = bitcast i16* %150 to i64*
  store i64 %148, i64* %151, align 8
  %152 = getelementptr inbounds i16, i16* %150, i64 4
  %153 = bitcast i16* %152 to i64*
  store i64 %148, i64* %153, align 8
  %154 = zext i32 %107 to i64
  %155 = mul i64 %154, 281479271743489
  %156 = sext i32 %94 to i64
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  %158 = bitcast i16* %157 to i64*
  store i64 %155, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %157, i64 4
  %160 = bitcast i16* %159 to i64*
  store i64 %155, i64* %160, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_dc_10_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = icmp ne i32 %1, 0
  br i1 %7, label %8, label %13

8:                                                ; preds = %4
  %9 = shl i64 %6, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = getelementptr inbounds i16, i16* %5, i64 %11
  br label %19

13:                                               ; preds = %4
  %14 = getelementptr inbounds i8, i8* %0, i64 -2
  %15 = bitcast i8* %14 to i16*
  %16 = shl i64 %6, 32
  %17 = ashr exact i64 %16, 32
  %18 = xor i64 %17, -1
  br label %19

19:                                               ; preds = %13, %8
  %20 = phi i64 [ %18, %13 ], [ %11, %8 ]
  %21 = phi i64 [ %17, %13 ], [ %10, %8 ]
  %22 = phi i64 [ %16, %13 ], [ %9, %8 ]
  %23 = phi i16* [ %15, %13 ], [ %12, %8 ]
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = getelementptr inbounds i8, i8* %0, i64 -2
  %27 = bitcast i8* %26 to i16*
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i32
  %30 = shl nuw nsw i32 %29, 1
  %31 = add i64 %22, -4294967296
  %32 = ashr exact i64 %31, 32
  %33 = getelementptr inbounds i16, i16* %5, i64 %32
  %34 = load i16, i16* %33, align 2
  %35 = zext i16 %34 to i32
  %36 = add nuw nsw i32 %35, 2
  %37 = add nuw nsw i32 %36, %25
  %38 = add nuw nsw i32 %37, %30
  %39 = lshr i32 %38, 2
  %40 = shl nuw nsw i32 %35, 1
  %41 = shl i64 %3, 32
  %42 = and i64 %41, -8589934592
  %43 = add i64 %42, -4294967296
  %44 = ashr exact i64 %43, 32
  %45 = getelementptr inbounds i16, i16* %5, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i32
  %48 = add nuw nsw i32 %47, 2
  %49 = add nuw nsw i32 %48, %29
  %50 = add nuw nsw i32 %49, %40
  %51 = lshr i32 %50, 2
  %52 = shl nuw nsw i32 %47, 1
  %53 = mul i64 %6, 12884901888
  %54 = add i64 %53, -4294967296
  %55 = ashr exact i64 %54, 32
  %56 = getelementptr inbounds i16, i16* %5, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %36, %52
  %60 = add nuw nsw i32 %59, %58
  %61 = lshr i32 %60, 2
  %62 = shl nuw nsw i32 %58, 1
  %63 = shl i64 %6, 34
  %64 = add i64 %63, -4294967296
  %65 = ashr exact i64 %64, 32
  %66 = getelementptr inbounds i16, i16* %5, i64 %65
  %67 = load i16, i16* %66, align 2
  %68 = zext i16 %67 to i32
  %69 = add nuw nsw i32 %48, %62
  %70 = add nuw nsw i32 %69, %68
  %71 = lshr i32 %70, 2
  %72 = shl nuw nsw i32 %68, 1
  %73 = mul i64 %6, 21474836480
  %74 = add i64 %73, -4294967296
  %75 = ashr exact i64 %74, 32
  %76 = getelementptr inbounds i16, i16* %5, i64 %75
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i32
  %79 = add nuw nsw i32 %58, 2
  %80 = add nuw nsw i32 %79, %72
  %81 = add nuw nsw i32 %80, %78
  %82 = lshr i32 %81, 2
  %83 = shl nuw nsw i32 %78, 1
  %84 = mul i64 %6, 25769803776
  %85 = add i64 %84, -4294967296
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i16, i16* %5, i64 %86
  %88 = load i16, i16* %87, align 2
  %89 = zext i16 %88 to i32
  %90 = add nuw nsw i32 %68, 2
  %91 = add nuw nsw i32 %90, %83
  %92 = add nuw nsw i32 %91, %89
  %93 = lshr i32 %92, 2
  %94 = shl nuw nsw i32 %89, 1
  %95 = mul i64 %6, 30064771072
  %96 = add i64 %95, -4294967296
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i16, i16* %5, i64 %97
  %99 = load i16, i16* %98, align 2
  %100 = zext i16 %99 to i32
  %101 = add nuw nsw i32 %78, 2
  %102 = add nuw nsw i32 %101, %94
  %103 = add nuw nsw i32 %102, %100
  %104 = lshr i32 %103, 2
  %105 = mul nuw nsw i32 %100, 3
  %106 = add nuw nsw i32 %89, 2
  %107 = add nuw nsw i32 %106, %105
  %108 = lshr i32 %107, 2
  %109 = shl i64 %6, 32
  %110 = sub i64 0, %109
  %111 = ashr exact i64 %110, 32
  %112 = select i1 %7, i64 %20, i64 %111
  %113 = getelementptr inbounds i16, i16* %5, i64 %112
  %114 = load i16, i16* %113, align 2
  %115 = zext i16 %114 to i32
  %116 = getelementptr inbounds i16, i16* %5, i64 %111
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = shl nuw nsw i32 %118, 1
  %120 = sub i64 4294967296, %22
  %121 = ashr exact i64 %120, 32
  %122 = getelementptr inbounds i16, i16* %5, i64 %121
  %123 = load i16, i16* %122, align 2
  %124 = zext i16 %123 to i32
  %125 = add nuw nsw i32 %124, 2
  %126 = add nuw nsw i32 %125, %115
  %127 = add nuw nsw i32 %126, %119
  %128 = lshr i32 %127, 2
  %129 = shl nuw nsw i32 %124, 1
  %130 = sub i64 8589934592, %22
  %131 = ashr exact i64 %130, 32
  %132 = getelementptr inbounds i16, i16* %5, i64 %131
  %133 = load i16, i16* %132, align 2
  %134 = zext i16 %133 to i32
  %135 = add nuw nsw i32 %134, 2
  %136 = add nuw nsw i32 %135, %118
  %137 = add nuw nsw i32 %136, %129
  %138 = lshr i32 %137, 2
  %139 = shl nuw nsw i32 %134, 1
  %140 = sub i64 12884901888, %22
  %141 = ashr exact i64 %140, 32
  %142 = getelementptr inbounds i16, i16* %5, i64 %141
  %143 = load i16, i16* %142, align 2
  %144 = zext i16 %143 to i32
  %145 = add nuw nsw i32 %125, %139
  %146 = add nuw nsw i32 %145, %144
  %147 = lshr i32 %146, 2
  %148 = shl nuw nsw i32 %144, 1
  %149 = sub i64 17179869184, %22
  %150 = ashr exact i64 %149, 32
  %151 = getelementptr inbounds i16, i16* %5, i64 %150
  %152 = load i16, i16* %151, align 2
  %153 = zext i16 %152 to i32
  %154 = add nuw nsw i32 %135, %148
  %155 = add nuw nsw i32 %154, %153
  %156 = lshr i32 %155, 2
  %157 = shl nuw nsw i32 %153, 1
  %158 = sub i64 21474836480, %22
  %159 = ashr exact i64 %158, 32
  %160 = getelementptr inbounds i16, i16* %5, i64 %159
  %161 = load i16, i16* %160, align 2
  %162 = zext i16 %161 to i32
  %163 = add nuw nsw i32 %144, 2
  %164 = add nuw nsw i32 %163, %157
  %165 = add nuw nsw i32 %164, %162
  %166 = lshr i32 %165, 2
  %167 = shl nuw nsw i32 %162, 1
  %168 = sub i64 25769803776, %22
  %169 = ashr exact i64 %168, 32
  %170 = getelementptr inbounds i16, i16* %5, i64 %169
  %171 = load i16, i16* %170, align 2
  %172 = zext i16 %171 to i32
  %173 = add nuw nsw i32 %153, 2
  %174 = add nuw nsw i32 %173, %167
  %175 = add nuw nsw i32 %174, %172
  %176 = lshr i32 %175, 2
  %177 = shl nuw nsw i32 %172, 1
  %178 = sub i64 30064771072, %22
  %179 = ashr exact i64 %178, 32
  %180 = getelementptr inbounds i16, i16* %5, i64 %179
  %181 = load i16, i16* %180, align 2
  %182 = zext i16 %181 to i32
  %183 = add nuw nsw i32 %162, 2
  %184 = add nuw nsw i32 %183, %177
  %185 = add nuw nsw i32 %184, %182
  %186 = lshr i32 %185, 2
  %187 = icmp eq i32 %2, 0
  br i1 %187, label %194, label %188

188:                                              ; preds = %19
  %189 = sub i64 34359738368, %22
  %190 = ashr exact i64 %189, 32
  %191 = getelementptr inbounds i16, i16* %5, i64 %190
  %192 = load i16, i16* %191, align 2
  %193 = zext i16 %192 to i32
  br label %194

194:                                              ; preds = %19, %188
  %195 = phi i32 [ %193, %188 ], [ %182, %19 ]
  %196 = shl nuw nsw i32 %182, 1
  %197 = add nuw nsw i32 %172, 2
  %198 = add nuw nsw i32 %197, %196
  %199 = add nuw nsw i32 %198, %195
  %200 = lshr i32 %199, 2
  %201 = add nuw nsw i32 %39, 8
  %202 = add nuw nsw i32 %201, %51
  %203 = add nuw nsw i32 %202, %61
  %204 = add nuw nsw i32 %203, %71
  %205 = add nuw nsw i32 %204, %82
  %206 = add nuw nsw i32 %205, %93
  %207 = add nuw nsw i32 %206, %108
  %208 = add nuw nsw i32 %207, %104
  %209 = add nuw nsw i32 %208, %128
  %210 = add nuw nsw i32 %209, %138
  %211 = add nuw nsw i32 %210, %147
  %212 = add nuw nsw i32 %211, %156
  %213 = add nuw nsw i32 %212, %166
  %214 = add nuw nsw i32 %213, %176
  %215 = add nuw nsw i32 %214, %186
  %216 = add nuw nsw i32 %215, %200
  %217 = ashr i32 %216, 4
  %218 = sext i32 %217 to i64
  %219 = mul i64 %218, 281479271743489
  %220 = bitcast i8* %0 to i64*
  store i64 %219, i64* %220, align 8
  %221 = getelementptr inbounds i8, i8* %0, i64 8
  %222 = bitcast i8* %221 to i64*
  store i64 %219, i64* %222, align 8
  %223 = getelementptr inbounds i16, i16* %5, i64 %21
  %224 = bitcast i16* %223 to i64*
  store i64 %219, i64* %224, align 8
  %225 = getelementptr inbounds i16, i16* %223, i64 4
  %226 = bitcast i16* %225 to i64*
  store i64 %219, i64* %226, align 8
  %227 = getelementptr inbounds i16, i16* %223, i64 %21
  %228 = bitcast i16* %227 to i64*
  store i64 %219, i64* %228, align 8
  %229 = getelementptr inbounds i16, i16* %227, i64 4
  %230 = bitcast i16* %229 to i64*
  store i64 %219, i64* %230, align 8
  %231 = getelementptr inbounds i16, i16* %227, i64 %21
  %232 = bitcast i16* %231 to i64*
  store i64 %219, i64* %232, align 8
  %233 = getelementptr inbounds i16, i16* %231, i64 4
  %234 = bitcast i16* %233 to i64*
  store i64 %219, i64* %234, align 8
  %235 = getelementptr inbounds i16, i16* %231, i64 %21
  %236 = bitcast i16* %235 to i64*
  store i64 %219, i64* %236, align 8
  %237 = getelementptr inbounds i16, i16* %235, i64 4
  %238 = bitcast i16* %237 to i64*
  store i64 %219, i64* %238, align 8
  %239 = getelementptr inbounds i16, i16* %235, i64 %21
  %240 = bitcast i16* %239 to i64*
  store i64 %219, i64* %240, align 8
  %241 = getelementptr inbounds i16, i16* %239, i64 4
  %242 = bitcast i16* %241 to i64*
  store i64 %219, i64* %242, align 8
  %243 = getelementptr inbounds i16, i16* %239, i64 %21
  %244 = bitcast i16* %243 to i64*
  store i64 %219, i64* %244, align 8
  %245 = getelementptr inbounds i16, i16* %243, i64 4
  %246 = bitcast i16* %245 to i64*
  store i64 %219, i64* %246, align 8
  %247 = getelementptr inbounds i16, i16* %243, i64 %21
  %248 = bitcast i16* %247 to i64*
  store i64 %219, i64* %248, align 8
  %249 = getelementptr inbounds i16, i16* %247, i64 4
  %250 = bitcast i16* %249 to i64*
  store i64 %219, i64* %250, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_down_left_10_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %97, label %99

97:                                               ; preds = %18
  %98 = mul nuw nsw i32 %91, 3
  br label %181

99:                                               ; preds = %18
  %100 = sub i64 34359738368, %19
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %5, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i32
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %105, %104
  %107 = shl nuw nsw i32 %104, 1
  %108 = sub i64 38654705664, %19
  %109 = ashr exact i64 %108, 32
  %110 = getelementptr inbounds i16, i16* %5, i64 %109
  %111 = load i16, i16* %110, align 2
  %112 = zext i16 %111 to i32
  %113 = add nuw nsw i32 %91, 2
  %114 = add nuw nsw i32 %113, %107
  %115 = add nuw nsw i32 %114, %112
  %116 = lshr i32 %115, 2
  %117 = shl nuw nsw i32 %112, 1
  %118 = sub i64 42949672960, %19
  %119 = ashr exact i64 %118, 32
  %120 = getelementptr inbounds i16, i16* %5, i64 %119
  %121 = load i16, i16* %120, align 2
  %122 = zext i16 %121 to i32
  %123 = add nuw nsw i32 %122, 2
  %124 = add nuw nsw i32 %123, %104
  %125 = add nuw nsw i32 %124, %117
  %126 = lshr i32 %125, 2
  %127 = shl nuw nsw i32 %122, 1
  %128 = sub i64 47244640256, %19
  %129 = ashr exact i64 %128, 32
  %130 = getelementptr inbounds i16, i16* %5, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i32
  %133 = add nuw nsw i32 %112, 2
  %134 = add nuw nsw i32 %133, %127
  %135 = add nuw nsw i32 %134, %132
  %136 = lshr i32 %135, 2
  %137 = shl nuw nsw i32 %132, 1
  %138 = sub i64 51539607552, %19
  %139 = ashr exact i64 %138, 32
  %140 = getelementptr inbounds i16, i16* %5, i64 %139
  %141 = load i16, i16* %140, align 2
  %142 = zext i16 %141 to i32
  %143 = add nuw nsw i32 %123, %137
  %144 = add nuw nsw i32 %143, %142
  %145 = lshr i32 %144, 2
  %146 = shl nuw nsw i32 %142, 1
  %147 = sub i64 55834574848, %19
  %148 = ashr exact i64 %147, 32
  %149 = getelementptr inbounds i16, i16* %5, i64 %148
  %150 = load i16, i16* %149, align 2
  %151 = zext i16 %150 to i32
  %152 = add nuw nsw i32 %132, 2
  %153 = add nuw nsw i32 %152, %146
  %154 = add nuw nsw i32 %153, %151
  %155 = lshr i32 %154, 2
  %156 = shl nuw nsw i32 %151, 1
  %157 = sub i64 60129542144, %19
  %158 = ashr exact i64 %157, 32
  %159 = getelementptr inbounds i16, i16* %5, i64 %158
  %160 = load i16, i16* %159, align 2
  %161 = zext i16 %160 to i32
  %162 = add nuw nsw i32 %142, 2
  %163 = add nuw nsw i32 %162, %156
  %164 = add nuw nsw i32 %163, %161
  %165 = lshr i32 %164, 2
  %166 = shl nuw nsw i32 %161, 1
  %167 = sub i64 64424509440, %19
  %168 = ashr exact i64 %167, 32
  %169 = getelementptr inbounds i16, i16* %5, i64 %168
  %170 = load i16, i16* %169, align 2
  %171 = zext i16 %170 to i32
  %172 = add nuw nsw i32 %151, 2
  %173 = add nuw nsw i32 %172, %166
  %174 = add nuw nsw i32 %173, %171
  %175 = lshr i32 %174, 2
  %176 = mul nuw nsw i32 %171, 3
  %177 = add nuw nsw i32 %161, 2
  %178 = add nuw nsw i32 %177, %176
  %179 = lshr i32 %178, 2
  %180 = mul nuw nsw i32 %179, 3
  br label %181

181:                                              ; preds = %97, %99
  %182 = phi i32 [ %98, %97 ], [ %180, %99 ]
  %183 = phi i32 [ %98, %97 ], [ %106, %99 ]
  %184 = phi i32 [ %91, %97 ], [ %116, %99 ]
  %185 = phi i32 [ %91, %97 ], [ %126, %99 ]
  %186 = phi i32 [ %91, %97 ], [ %136, %99 ]
  %187 = phi i32 [ %91, %97 ], [ %145, %99 ]
  %188 = phi i32 [ %91, %97 ], [ %155, %99 ]
  %189 = phi i32 [ %91, %97 ], [ %165, %99 ]
  %190 = phi i32 [ %91, %97 ], [ %175, %99 ]
  %191 = phi i32 [ %91, %97 ], [ %179, %99 ]
  %192 = add nuw nsw i32 %81, 2
  %193 = add nuw nsw i32 %192, %183
  %194 = lshr i32 %193, 2
  %195 = shl nuw nsw i32 %47, 1
  %196 = add nuw nsw i32 %56, 2
  %197 = add nuw nsw i32 %196, %37
  %198 = add nuw nsw i32 %197, %195
  %199 = lshr i32 %198, 2
  %200 = trunc i32 %199 to i16
  store i16 %200, i16* %5, align 2
  %201 = shl nuw nsw i32 %56, 1
  %202 = add nuw nsw i32 %65, 2
  %203 = add nuw nsw i32 %202, %47
  %204 = add nuw nsw i32 %203, %201
  %205 = lshr i32 %204, 2
  %206 = trunc i32 %205 to i16
  %207 = getelementptr inbounds i8, i8* %0, i64 2
  %208 = bitcast i8* %207 to i16*
  store i16 %206, i16* %208, align 2
  %209 = ashr exact i64 %19, 32
  %210 = getelementptr inbounds i16, i16* %5, i64 %209
  store i16 %206, i16* %210, align 2
  %211 = shl nuw nsw i32 %65, 1
  %212 = add nuw nsw i32 %196, %211
  %213 = add nuw nsw i32 %212, %75
  %214 = lshr i32 %213, 2
  %215 = trunc i32 %214 to i16
  %216 = getelementptr inbounds i8, i8* %0, i64 4
  %217 = bitcast i8* %216 to i16*
  store i16 %215, i16* %217, align 2
  %218 = add i64 %19, 4294967296
  %219 = ashr exact i64 %218, 32
  %220 = getelementptr inbounds i16, i16* %5, i64 %219
  store i16 %215, i16* %220, align 2
  %221 = trunc i64 %3 to i32
  %222 = and i32 %221, -2
  %223 = sext i32 %222 to i64
  %224 = getelementptr inbounds i16, i16* %5, i64 %223
  store i16 %215, i16* %224, align 2
  %225 = shl nuw nsw i32 %75, 1
  %226 = add nuw nsw i32 %202, %225
  %227 = add nuw nsw i32 %226, %85
  %228 = lshr i32 %227, 2
  %229 = trunc i32 %228 to i16
  %230 = getelementptr inbounds i8, i8* %0, i64 6
  %231 = bitcast i8* %230 to i16*
  store i16 %229, i16* %231, align 2
  %232 = add i64 %19, 8589934592
  %233 = ashr exact i64 %232, 32
  %234 = getelementptr inbounds i16, i16* %5, i64 %233
  store i16 %229, i16* %234, align 2
  %235 = shl i64 %3, 32
  %236 = ashr exact i64 %235, 32
  %237 = or i64 %236, 1
  %238 = getelementptr inbounds i16, i16* %5, i64 %237
  store i16 %229, i16* %238, align 2
  %239 = mul nsw i32 %7, 3
  %240 = sext i32 %239 to i64
  %241 = getelementptr inbounds i16, i16* %5, i64 %240
  store i16 %229, i16* %241, align 2
  %242 = shl nuw nsw i32 %85, 1
  %243 = add nuw nsw i32 %75, 2
  %244 = add nuw nsw i32 %243, %242
  %245 = add nuw nsw i32 %244, %95
  %246 = lshr i32 %245, 2
  %247 = trunc i32 %246 to i16
  %248 = getelementptr inbounds i8, i8* %0, i64 8
  %249 = bitcast i8* %248 to i16*
  store i16 %247, i16* %249, align 2
  %250 = add i64 %19, 12884901888
  %251 = ashr exact i64 %250, 32
  %252 = getelementptr inbounds i16, i16* %5, i64 %251
  store i16 %247, i16* %252, align 2
  %253 = add nsw i32 %222, 2
  %254 = sext i32 %253 to i64
  %255 = getelementptr inbounds i16, i16* %5, i64 %254
  store i16 %247, i16* %255, align 2
  %256 = add nsw i32 %239, 1
  %257 = sext i32 %256 to i64
  %258 = getelementptr inbounds i16, i16* %5, i64 %257
  store i16 %247, i16* %258, align 2
  %259 = shl i64 %6, 34
  %260 = ashr exact i64 %259, 32
  %261 = getelementptr inbounds i16, i16* %5, i64 %260
  store i16 %247, i16* %261, align 2
  %262 = shl nuw nsw i32 %95, 1
  %263 = add nuw nsw i32 %85, 2
  %264 = add nuw nsw i32 %263, %262
  %265 = add nuw nsw i32 %264, %194
  %266 = lshr i32 %265, 2
  %267 = trunc i32 %266 to i16
  %268 = getelementptr inbounds i8, i8* %0, i64 10
  %269 = bitcast i8* %268 to i16*
  store i16 %267, i16* %269, align 2
  %270 = add i64 %19, 17179869184
  %271 = ashr exact i64 %270, 32
  %272 = getelementptr inbounds i16, i16* %5, i64 %271
  store i16 %267, i16* %272, align 2
  %273 = add nsw i32 %222, 3
  %274 = sext i32 %273 to i64
  %275 = getelementptr inbounds i16, i16* %5, i64 %274
  store i16 %267, i16* %275, align 2
  %276 = add nsw i32 %239, 2
  %277 = sext i32 %276 to i64
  %278 = getelementptr inbounds i16, i16* %5, i64 %277
  store i16 %267, i16* %278, align 2
  %279 = or i64 %260, 1
  %280 = getelementptr inbounds i16, i16* %5, i64 %279
  store i16 %267, i16* %280, align 2
  %281 = mul nsw i32 %7, 5
  %282 = sext i32 %281 to i64
  %283 = getelementptr inbounds i16, i16* %5, i64 %282
  store i16 %267, i16* %283, align 2
  %284 = shl nuw nsw i32 %194, 1
  %285 = add nuw nsw i32 %95, 2
  %286 = add nuw nsw i32 %285, %184
  %287 = add nuw nsw i32 %286, %284
  %288 = lshr i32 %287, 2
  %289 = trunc i32 %288 to i16
  %290 = getelementptr inbounds i8, i8* %0, i64 12
  %291 = bitcast i8* %290 to i16*
  store i16 %289, i16* %291, align 2
  %292 = add i64 %19, 21474836480
  %293 = ashr exact i64 %292, 32
  %294 = getelementptr inbounds i16, i16* %5, i64 %293
  store i16 %289, i16* %294, align 2
  %295 = add nsw i32 %222, 4
  %296 = sext i32 %295 to i64
  %297 = getelementptr inbounds i16, i16* %5, i64 %296
  store i16 %289, i16* %297, align 2
  %298 = add nsw i32 %239, 3
  %299 = sext i32 %298 to i64
  %300 = getelementptr inbounds i16, i16* %5, i64 %299
  store i16 %289, i16* %300, align 2
  %301 = or i64 %260, 2
  %302 = getelementptr inbounds i16, i16* %5, i64 %301
  store i16 %289, i16* %302, align 2
  %303 = add nsw i32 %281, 1
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds i16, i16* %5, i64 %304
  store i16 %289, i16* %305, align 2
  %306 = mul nsw i32 %7, 6
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i16, i16* %5, i64 %307
  store i16 %289, i16* %308, align 2
  %309 = shl nuw nsw i32 %184, 1
  %310 = add nuw nsw i32 %194, 2
  %311 = add nuw nsw i32 %310, %185
  %312 = add nuw nsw i32 %311, %309
  %313 = lshr i32 %312, 2
  %314 = trunc i32 %313 to i16
  %315 = getelementptr inbounds i8, i8* %0, i64 14
  %316 = bitcast i8* %315 to i16*
  store i16 %314, i16* %316, align 2
  %317 = add i64 %19, 25769803776
  %318 = ashr exact i64 %317, 32
  %319 = getelementptr inbounds i16, i16* %5, i64 %318
  store i16 %314, i16* %319, align 2
  %320 = add nsw i32 %222, 5
  %321 = sext i32 %320 to i64
  %322 = getelementptr inbounds i16, i16* %5, i64 %321
  store i16 %314, i16* %322, align 2
  %323 = add nsw i32 %239, 4
  %324 = sext i32 %323 to i64
  %325 = getelementptr inbounds i16, i16* %5, i64 %324
  store i16 %314, i16* %325, align 2
  %326 = or i64 %260, 3
  %327 = getelementptr inbounds i16, i16* %5, i64 %326
  store i16 %314, i16* %327, align 2
  %328 = add nsw i32 %281, 2
  %329 = sext i32 %328 to i64
  %330 = getelementptr inbounds i16, i16* %5, i64 %329
  store i16 %314, i16* %330, align 2
  %331 = or i32 %306, 1
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds i16, i16* %5, i64 %332
  store i16 %314, i16* %333, align 2
  %334 = mul nsw i32 %7, 7
  %335 = sext i32 %334 to i64
  %336 = getelementptr inbounds i16, i16* %5, i64 %335
  store i16 %314, i16* %336, align 2
  %337 = shl nuw nsw i32 %185, 1
  %338 = add nuw nsw i32 %184, 2
  %339 = add nuw nsw i32 %338, %337
  %340 = add nuw nsw i32 %339, %186
  %341 = lshr i32 %340, 2
  %342 = trunc i32 %341 to i16
  %343 = add i64 %19, 30064771072
  %344 = ashr exact i64 %343, 32
  %345 = getelementptr inbounds i16, i16* %5, i64 %344
  store i16 %342, i16* %345, align 2
  %346 = add nsw i32 %222, 6
  %347 = sext i32 %346 to i64
  %348 = getelementptr inbounds i16, i16* %5, i64 %347
  store i16 %342, i16* %348, align 2
  %349 = add nsw i32 %239, 5
  %350 = sext i32 %349 to i64
  %351 = getelementptr inbounds i16, i16* %5, i64 %350
  store i16 %342, i16* %351, align 2
  %352 = add i64 %259, 17179869184
  %353 = ashr exact i64 %352, 32
  %354 = getelementptr inbounds i16, i16* %5, i64 %353
  store i16 %342, i16* %354, align 2
  %355 = add nsw i32 %281, 3
  %356 = sext i32 %355 to i64
  %357 = getelementptr inbounds i16, i16* %5, i64 %356
  store i16 %342, i16* %357, align 2
  %358 = add nsw i32 %306, 2
  %359 = sext i32 %358 to i64
  %360 = getelementptr inbounds i16, i16* %5, i64 %359
  store i16 %342, i16* %360, align 2
  %361 = add nsw i32 %334, 1
  %362 = sext i32 %361 to i64
  %363 = getelementptr inbounds i16, i16* %5, i64 %362
  store i16 %342, i16* %363, align 2
  %364 = shl nuw nsw i32 %186, 1
  %365 = add nuw nsw i32 %185, 2
  %366 = add nuw nsw i32 %365, %364
  %367 = add nuw nsw i32 %366, %187
  %368 = lshr i32 %367, 2
  %369 = trunc i32 %368 to i16
  %370 = add nsw i32 %222, 7
  %371 = sext i32 %370 to i64
  %372 = getelementptr inbounds i16, i16* %5, i64 %371
  store i16 %369, i16* %372, align 2
  %373 = add nsw i32 %239, 6
  %374 = sext i32 %373 to i64
  %375 = getelementptr inbounds i16, i16* %5, i64 %374
  store i16 %369, i16* %375, align 2
  %376 = add i64 %259, 21474836480
  %377 = ashr exact i64 %376, 32
  %378 = getelementptr inbounds i16, i16* %5, i64 %377
  store i16 %369, i16* %378, align 2
  %379 = add nsw i32 %281, 4
  %380 = sext i32 %379 to i64
  %381 = getelementptr inbounds i16, i16* %5, i64 %380
  store i16 %369, i16* %381, align 2
  %382 = add nsw i32 %306, 3
  %383 = sext i32 %382 to i64
  %384 = getelementptr inbounds i16, i16* %5, i64 %383
  store i16 %369, i16* %384, align 2
  %385 = add nsw i32 %334, 2
  %386 = sext i32 %385 to i64
  %387 = getelementptr inbounds i16, i16* %5, i64 %386
  store i16 %369, i16* %387, align 2
  %388 = shl nuw nsw i32 %187, 1
  %389 = add nuw nsw i32 %186, 2
  %390 = add nuw nsw i32 %389, %388
  %391 = add nuw nsw i32 %390, %188
  %392 = lshr i32 %391, 2
  %393 = trunc i32 %392 to i16
  %394 = add nsw i32 %239, 7
  %395 = sext i32 %394 to i64
  %396 = getelementptr inbounds i16, i16* %5, i64 %395
  store i16 %393, i16* %396, align 2
  %397 = add i64 %259, 25769803776
  %398 = ashr exact i64 %397, 32
  %399 = getelementptr inbounds i16, i16* %5, i64 %398
  store i16 %393, i16* %399, align 2
  %400 = add nsw i32 %281, 5
  %401 = sext i32 %400 to i64
  %402 = getelementptr inbounds i16, i16* %5, i64 %401
  store i16 %393, i16* %402, align 2
  %403 = add nsw i32 %306, 4
  %404 = sext i32 %403 to i64
  %405 = getelementptr inbounds i16, i16* %5, i64 %404
  store i16 %393, i16* %405, align 2
  %406 = add nsw i32 %334, 3
  %407 = sext i32 %406 to i64
  %408 = getelementptr inbounds i16, i16* %5, i64 %407
  store i16 %393, i16* %408, align 2
  %409 = shl nuw nsw i32 %188, 1
  %410 = add nuw nsw i32 %187, 2
  %411 = add nuw nsw i32 %410, %409
  %412 = add nuw nsw i32 %411, %189
  %413 = lshr i32 %412, 2
  %414 = trunc i32 %413 to i16
  %415 = add i64 %259, 30064771072
  %416 = ashr exact i64 %415, 32
  %417 = getelementptr inbounds i16, i16* %5, i64 %416
  store i16 %414, i16* %417, align 2
  %418 = add nsw i32 %281, 6
  %419 = sext i32 %418 to i64
  %420 = getelementptr inbounds i16, i16* %5, i64 %419
  store i16 %414, i16* %420, align 2
  %421 = add nsw i32 %306, 5
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds i16, i16* %5, i64 %422
  store i16 %414, i16* %423, align 2
  %424 = add nsw i32 %334, 4
  %425 = sext i32 %424 to i64
  %426 = getelementptr inbounds i16, i16* %5, i64 %425
  store i16 %414, i16* %426, align 2
  %427 = shl nuw nsw i32 %189, 1
  %428 = add nuw nsw i32 %188, 2
  %429 = add nuw nsw i32 %428, %427
  %430 = add nuw nsw i32 %429, %190
  %431 = lshr i32 %430, 2
  %432 = trunc i32 %431 to i16
  %433 = add nsw i32 %281, 7
  %434 = sext i32 %433 to i64
  %435 = getelementptr inbounds i16, i16* %5, i64 %434
  store i16 %432, i16* %435, align 2
  %436 = add nsw i32 %306, 6
  %437 = sext i32 %436 to i64
  %438 = getelementptr inbounds i16, i16* %5, i64 %437
  store i16 %432, i16* %438, align 2
  %439 = add nsw i32 %334, 5
  %440 = sext i32 %439 to i64
  %441 = getelementptr inbounds i16, i16* %5, i64 %440
  store i16 %432, i16* %441, align 2
  %442 = shl nuw nsw i32 %190, 1
  %443 = add nuw nsw i32 %189, 2
  %444 = add nuw nsw i32 %443, %442
  %445 = add nuw nsw i32 %444, %191
  %446 = lshr i32 %445, 2
  %447 = trunc i32 %446 to i16
  %448 = add nsw i32 %306, 7
  %449 = sext i32 %448 to i64
  %450 = getelementptr inbounds i16, i16* %5, i64 %449
  store i16 %447, i16* %450, align 2
  %451 = add nsw i32 %334, 6
  %452 = sext i32 %451 to i64
  %453 = getelementptr inbounds i16, i16* %5, i64 %452
  store i16 %447, i16* %453, align 2
  %454 = add nuw nsw i32 %190, 2
  %455 = add nuw nsw i32 %454, %182
  %456 = lshr i32 %455, 2
  %457 = trunc i32 %456 to i16
  %458 = add nsw i32 %334, 7
  %459 = sext i32 %458 to i64
  %460 = getelementptr inbounds i16, i16* %5, i64 %459
  store i16 %457, i16* %460, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_down_right_10_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp ne i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %10, label %15

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %27, 2
  %45 = add nuw nsw i32 %44, %38
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %43, 2
  %64 = add nuw nsw i32 %63, %57
  %65 = add nuw nsw i32 %64, %62
  %66 = lshr i32 %65, 2
  %67 = shl nuw nsw i32 %62, 1
  %68 = sub i64 21474836480, %19
  %69 = ashr exact i64 %68, 32
  %70 = getelementptr inbounds i16, i16* %5, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i32
  %73 = add nuw nsw i32 %53, 2
  %74 = add nuw nsw i32 %73, %67
  %75 = add nuw nsw i32 %74, %72
  %76 = lshr i32 %75, 2
  %77 = shl nuw nsw i32 %72, 1
  %78 = sub i64 25769803776, %19
  %79 = ashr exact i64 %78, 32
  %80 = getelementptr inbounds i16, i16* %5, i64 %79
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i32
  %83 = add nuw nsw i32 %62, 2
  %84 = add nuw nsw i32 %83, %77
  %85 = add nuw nsw i32 %84, %82
  %86 = lshr i32 %85, 2
  %87 = shl nuw nsw i32 %82, 1
  %88 = sub i64 30064771072, %19
  %89 = ashr exact i64 %88, 32
  %90 = getelementptr inbounds i16, i16* %5, i64 %89
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i32
  %93 = add nuw nsw i32 %72, 2
  %94 = add nuw nsw i32 %93, %87
  %95 = add nuw nsw i32 %94, %92
  %96 = lshr i32 %95, 2
  %97 = icmp eq i32 %2, 0
  br i1 %97, label %104, label %98

98:                                               ; preds = %18
  %99 = sub i64 34359738368, %19
  %100 = ashr exact i64 %99, 32
  %101 = getelementptr inbounds i16, i16* %5, i64 %100
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  br label %104

104:                                              ; preds = %18, %98
  %105 = phi i32 [ %103, %98 ], [ %92, %18 ]
  %106 = shl nuw nsw i32 %92, 1
  %107 = add nuw nsw i32 %82, 2
  %108 = add nuw nsw i32 %107, %106
  %109 = add nuw nsw i32 %108, %105
  %110 = lshr i32 %109, 2
  %111 = ashr exact i64 %19, 32
  %112 = xor i64 %111, -1
  %113 = getelementptr inbounds i16, i16* %5, i64 %112
  %114 = getelementptr inbounds i8, i8* %0, i64 -2
  %115 = bitcast i8* %114 to i16*
  %116 = select i1 %8, i16* %113, i16* %115
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = load i16, i16* %115, align 2
  %120 = zext i16 %119 to i32
  %121 = shl nuw nsw i32 %120, 1
  %122 = add i64 %19, -4294967296
  %123 = ashr exact i64 %122, 32
  %124 = getelementptr inbounds i16, i16* %5, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %126, 2
  %128 = add nuw nsw i32 %127, %118
  %129 = add nuw nsw i32 %128, %121
  %130 = lshr i32 %129, 2
  %131 = shl nuw nsw i32 %126, 1
  %132 = trunc i64 %3 to i32
  %133 = and i32 %132, -2
  %134 = add nsw i32 %133, -1
  %135 = sext i32 %134 to i64
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  %137 = load i16, i16* %136, align 2
  %138 = zext i16 %137 to i32
  %139 = add nuw nsw i32 %120, 2
  %140 = add nuw nsw i32 %139, %131
  %141 = add nuw nsw i32 %140, %138
  %142 = lshr i32 %141, 2
  %143 = shl nuw nsw i32 %138, 1
  %144 = mul nsw i32 %7, 3
  %145 = add nsw i32 %144, -1
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds i16, i16* %5, i64 %146
  %148 = load i16, i16* %147, align 2
  %149 = zext i16 %148 to i32
  %150 = add nuw nsw i32 %127, %143
  %151 = add nuw nsw i32 %150, %149
  %152 = lshr i32 %151, 2
  %153 = shl nuw nsw i32 %149, 1
  %154 = shl i64 %6, 34
  %155 = add i64 %154, -4294967296
  %156 = ashr exact i64 %155, 32
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  %158 = load i16, i16* %157, align 2
  %159 = zext i16 %158 to i32
  %160 = add nuw nsw i32 %138, 2
  %161 = add nuw nsw i32 %160, %153
  %162 = add nuw nsw i32 %161, %159
  %163 = lshr i32 %162, 2
  %164 = shl nuw nsw i32 %159, 1
  %165 = mul nsw i32 %7, 5
  %166 = add nsw i32 %165, -1
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds i16, i16* %5, i64 %167
  %169 = load i16, i16* %168, align 2
  %170 = zext i16 %169 to i32
  %171 = add nuw nsw i32 %149, 2
  %172 = add nuw nsw i32 %171, %164
  %173 = add nuw nsw i32 %172, %170
  %174 = lshr i32 %173, 2
  %175 = shl nuw nsw i32 %170, 1
  %176 = mul nsw i32 %7, 6
  %177 = add nsw i32 %176, -1
  %178 = sext i32 %177 to i64
  %179 = getelementptr inbounds i16, i16* %5, i64 %178
  %180 = load i16, i16* %179, align 2
  %181 = zext i16 %180 to i32
  %182 = add nuw nsw i32 %159, 2
  %183 = add nuw nsw i32 %182, %175
  %184 = add nuw nsw i32 %183, %181
  %185 = lshr i32 %184, 2
  %186 = shl nuw nsw i32 %181, 1
  %187 = mul nsw i32 %7, 7
  %188 = add nsw i32 %187, -1
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds i16, i16* %5, i64 %189
  %191 = load i16, i16* %190, align 2
  %192 = zext i16 %191 to i32
  %193 = add nuw nsw i32 %170, 2
  %194 = add nuw nsw i32 %193, %186
  %195 = add nuw nsw i32 %194, %192
  %196 = lshr i32 %195, 2
  %197 = mul nuw nsw i32 %192, 3
  %198 = add nuw nsw i32 %181, 2
  %199 = add nuw nsw i32 %198, %197
  %200 = lshr i32 %199, 2
  %201 = load i16, i16* %113, align 2
  %202 = zext i16 %201 to i32
  %203 = shl nuw nsw i32 %202, 1
  %204 = add nuw nsw i32 %44, %120
  %205 = add nuw nsw i32 %204, %203
  %206 = lshr i32 %205, 2
  %207 = shl nuw nsw i32 %196, 1
  %208 = add nuw nsw i32 %185, 2
  %209 = add nuw nsw i32 %208, %200
  %210 = add nuw nsw i32 %209, %207
  %211 = lshr i32 %210, 2
  %212 = trunc i32 %211 to i16
  %213 = sext i32 %187 to i64
  %214 = getelementptr inbounds i16, i16* %5, i64 %213
  store i16 %212, i16* %214, align 2
  %215 = shl nuw nsw i32 %185, 1
  %216 = add nuw nsw i32 %174, 2
  %217 = add nuw nsw i32 %216, %215
  %218 = add nuw nsw i32 %217, %196
  %219 = lshr i32 %218, 2
  %220 = trunc i32 %219 to i16
  %221 = add nsw i32 %187, 1
  %222 = sext i32 %221 to i64
  %223 = getelementptr inbounds i16, i16* %5, i64 %222
  store i16 %220, i16* %223, align 2
  %224 = sext i32 %176 to i64
  %225 = getelementptr inbounds i16, i16* %5, i64 %224
  store i16 %220, i16* %225, align 2
  %226 = shl nuw nsw i32 %174, 1
  %227 = add nuw nsw i32 %163, 2
  %228 = add nuw nsw i32 %227, %226
  %229 = add nuw nsw i32 %228, %185
  %230 = lshr i32 %229, 2
  %231 = trunc i32 %230 to i16
  %232 = add nsw i32 %187, 2
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds i16, i16* %5, i64 %233
  store i16 %231, i16* %234, align 2
  %235 = or i32 %176, 1
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds i16, i16* %5, i64 %236
  store i16 %231, i16* %237, align 2
  %238 = sext i32 %165 to i64
  %239 = getelementptr inbounds i16, i16* %5, i64 %238
  store i16 %231, i16* %239, align 2
  %240 = shl nuw nsw i32 %163, 1
  %241 = add nuw nsw i32 %152, 2
  %242 = add nuw nsw i32 %241, %240
  %243 = add nuw nsw i32 %242, %174
  %244 = lshr i32 %243, 2
  %245 = trunc i32 %244 to i16
  %246 = add nsw i32 %187, 3
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds i16, i16* %5, i64 %247
  store i16 %245, i16* %248, align 2
  %249 = add nsw i32 %176, 2
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds i16, i16* %5, i64 %250
  store i16 %245, i16* %251, align 2
  %252 = add nsw i32 %165, 1
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i16, i16* %5, i64 %253
  store i16 %245, i16* %254, align 2
  %255 = ashr exact i64 %154, 32
  %256 = getelementptr inbounds i16, i16* %5, i64 %255
  store i16 %245, i16* %256, align 2
  %257 = shl nuw nsw i32 %152, 1
  %258 = add nuw nsw i32 %142, 2
  %259 = add nuw nsw i32 %258, %257
  %260 = add nuw nsw i32 %259, %163
  %261 = lshr i32 %260, 2
  %262 = trunc i32 %261 to i16
  %263 = add nsw i32 %187, 4
  %264 = sext i32 %263 to i64
  %265 = getelementptr inbounds i16, i16* %5, i64 %264
  store i16 %262, i16* %265, align 2
  %266 = add nsw i32 %176, 3
  %267 = sext i32 %266 to i64
  %268 = getelementptr inbounds i16, i16* %5, i64 %267
  store i16 %262, i16* %268, align 2
  %269 = add nsw i32 %165, 2
  %270 = sext i32 %269 to i64
  %271 = getelementptr inbounds i16, i16* %5, i64 %270
  store i16 %262, i16* %271, align 2
  %272 = or i64 %255, 1
  %273 = getelementptr inbounds i16, i16* %5, i64 %272
  store i16 %262, i16* %273, align 2
  %274 = sext i32 %144 to i64
  %275 = getelementptr inbounds i16, i16* %5, i64 %274
  store i16 %262, i16* %275, align 2
  %276 = shl nuw nsw i32 %142, 1
  %277 = add nuw nsw i32 %130, 2
  %278 = add nuw nsw i32 %277, %276
  %279 = add nuw nsw i32 %278, %152
  %280 = lshr i32 %279, 2
  %281 = trunc i32 %280 to i16
  %282 = add nsw i32 %187, 5
  %283 = sext i32 %282 to i64
  %284 = getelementptr inbounds i16, i16* %5, i64 %283
  store i16 %281, i16* %284, align 2
  %285 = add nsw i32 %176, 4
  %286 = sext i32 %285 to i64
  %287 = getelementptr inbounds i16, i16* %5, i64 %286
  store i16 %281, i16* %287, align 2
  %288 = add nsw i32 %165, 3
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds i16, i16* %5, i64 %289
  store i16 %281, i16* %290, align 2
  %291 = or i64 %255, 2
  %292 = getelementptr inbounds i16, i16* %5, i64 %291
  store i16 %281, i16* %292, align 2
  %293 = add nsw i32 %144, 1
  %294 = sext i32 %293 to i64
  %295 = getelementptr inbounds i16, i16* %5, i64 %294
  store i16 %281, i16* %295, align 2
  %296 = sext i32 %133 to i64
  %297 = getelementptr inbounds i16, i16* %5, i64 %296
  store i16 %281, i16* %297, align 2
  %298 = shl nuw nsw i32 %130, 1
  %299 = add nuw nsw i32 %258, %298
  %300 = add nuw nsw i32 %299, %206
  %301 = lshr i32 %300, 2
  %302 = trunc i32 %301 to i16
  %303 = add nsw i32 %187, 6
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds i16, i16* %5, i64 %304
  store i16 %302, i16* %305, align 2
  %306 = add nsw i32 %176, 5
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i16, i16* %5, i64 %307
  store i16 %302, i16* %308, align 2
  %309 = add nsw i32 %165, 4
  %310 = sext i32 %309 to i64
  %311 = getelementptr inbounds i16, i16* %5, i64 %310
  store i16 %302, i16* %311, align 2
  %312 = or i64 %255, 3
  %313 = getelementptr inbounds i16, i16* %5, i64 %312
  store i16 %302, i16* %313, align 2
  %314 = add nsw i32 %144, 2
  %315 = sext i32 %314 to i64
  %316 = getelementptr inbounds i16, i16* %5, i64 %315
  store i16 %302, i16* %316, align 2
  %317 = shl i64 %3, 32
  %318 = ashr exact i64 %317, 32
  %319 = or i64 %318, 1
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %302, i16* %320, align 2
  %321 = getelementptr inbounds i16, i16* %5, i64 %111
  store i16 %302, i16* %321, align 2
  %322 = shl nuw nsw i32 %206, 1
  %323 = add nuw nsw i32 %37, 2
  %324 = add nuw nsw i32 %323, %130
  %325 = add nuw nsw i32 %324, %322
  %326 = lshr i32 %325, 2
  %327 = trunc i32 %326 to i16
  %328 = add nsw i32 %187, 7
  %329 = sext i32 %328 to i64
  %330 = getelementptr inbounds i16, i16* %5, i64 %329
  store i16 %327, i16* %330, align 2
  %331 = add nsw i32 %176, 6
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds i16, i16* %5, i64 %332
  store i16 %327, i16* %333, align 2
  %334 = add nsw i32 %165, 5
  %335 = sext i32 %334 to i64
  %336 = getelementptr inbounds i16, i16* %5, i64 %335
  store i16 %327, i16* %336, align 2
  %337 = add i64 %154, 17179869184
  %338 = ashr exact i64 %337, 32
  %339 = getelementptr inbounds i16, i16* %5, i64 %338
  store i16 %327, i16* %339, align 2
  %340 = add nsw i32 %144, 3
  %341 = sext i32 %340 to i64
  %342 = getelementptr inbounds i16, i16* %5, i64 %341
  store i16 %327, i16* %342, align 2
  %343 = add nsw i32 %133, 2
  %344 = sext i32 %343 to i64
  %345 = getelementptr inbounds i16, i16* %5, i64 %344
  store i16 %327, i16* %345, align 2
  %346 = add i64 %19, 4294967296
  %347 = ashr exact i64 %346, 32
  %348 = getelementptr inbounds i16, i16* %5, i64 %347
  store i16 %327, i16* %348, align 2
  store i16 %327, i16* %5, align 2
  %349 = shl nuw nsw i32 %37, 1
  %350 = add nuw nsw i32 %47, 2
  %351 = add nuw nsw i32 %350, %349
  %352 = add nuw nsw i32 %351, %206
  %353 = lshr i32 %352, 2
  %354 = trunc i32 %353 to i16
  %355 = add nsw i32 %176, 7
  %356 = sext i32 %355 to i64
  %357 = getelementptr inbounds i16, i16* %5, i64 %356
  store i16 %354, i16* %357, align 2
  %358 = add nsw i32 %165, 6
  %359 = sext i32 %358 to i64
  %360 = getelementptr inbounds i16, i16* %5, i64 %359
  store i16 %354, i16* %360, align 2
  %361 = add i64 %154, 21474836480
  %362 = ashr exact i64 %361, 32
  %363 = getelementptr inbounds i16, i16* %5, i64 %362
  store i16 %354, i16* %363, align 2
  %364 = add nsw i32 %144, 4
  %365 = sext i32 %364 to i64
  %366 = getelementptr inbounds i16, i16* %5, i64 %365
  store i16 %354, i16* %366, align 2
  %367 = add nsw i32 %133, 3
  %368 = sext i32 %367 to i64
  %369 = getelementptr inbounds i16, i16* %5, i64 %368
  store i16 %354, i16* %369, align 2
  %370 = add i64 %19, 8589934592
  %371 = ashr exact i64 %370, 32
  %372 = getelementptr inbounds i16, i16* %5, i64 %371
  store i16 %354, i16* %372, align 2
  %373 = getelementptr inbounds i8, i8* %0, i64 2
  %374 = bitcast i8* %373 to i16*
  store i16 %354, i16* %374, align 2
  %375 = shl nuw nsw i32 %47, 1
  %376 = add nuw nsw i32 %323, %375
  %377 = add nuw nsw i32 %376, %56
  %378 = lshr i32 %377, 2
  %379 = trunc i32 %378 to i16
  %380 = add nsw i32 %165, 7
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i16, i16* %5, i64 %381
  store i16 %379, i16* %382, align 2
  %383 = add i64 %154, 25769803776
  %384 = ashr exact i64 %383, 32
  %385 = getelementptr inbounds i16, i16* %5, i64 %384
  store i16 %379, i16* %385, align 2
  %386 = add nsw i32 %144, 5
  %387 = sext i32 %386 to i64
  %388 = getelementptr inbounds i16, i16* %5, i64 %387
  store i16 %379, i16* %388, align 2
  %389 = add nsw i32 %133, 4
  %390 = sext i32 %389 to i64
  %391 = getelementptr inbounds i16, i16* %5, i64 %390
  store i16 %379, i16* %391, align 2
  %392 = add i64 %19, 12884901888
  %393 = ashr exact i64 %392, 32
  %394 = getelementptr inbounds i16, i16* %5, i64 %393
  store i16 %379, i16* %394, align 2
  %395 = getelementptr inbounds i8, i8* %0, i64 4
  %396 = bitcast i8* %395 to i16*
  store i16 %379, i16* %396, align 2
  %397 = shl nuw nsw i32 %56, 1
  %398 = add nuw nsw i32 %350, %397
  %399 = add nuw nsw i32 %398, %66
  %400 = lshr i32 %399, 2
  %401 = trunc i32 %400 to i16
  %402 = add i64 %154, 30064771072
  %403 = ashr exact i64 %402, 32
  %404 = getelementptr inbounds i16, i16* %5, i64 %403
  store i16 %401, i16* %404, align 2
  %405 = add nsw i32 %144, 6
  %406 = sext i32 %405 to i64
  %407 = getelementptr inbounds i16, i16* %5, i64 %406
  store i16 %401, i16* %407, align 2
  %408 = add nsw i32 %133, 5
  %409 = sext i32 %408 to i64
  %410 = getelementptr inbounds i16, i16* %5, i64 %409
  store i16 %401, i16* %410, align 2
  %411 = add i64 %19, 17179869184
  %412 = ashr exact i64 %411, 32
  %413 = getelementptr inbounds i16, i16* %5, i64 %412
  store i16 %401, i16* %413, align 2
  %414 = getelementptr inbounds i8, i8* %0, i64 6
  %415 = bitcast i8* %414 to i16*
  store i16 %401, i16* %415, align 2
  %416 = shl nuw nsw i32 %66, 1
  %417 = add nuw nsw i32 %56, 2
  %418 = add nuw nsw i32 %417, %416
  %419 = add nuw nsw i32 %418, %76
  %420 = lshr i32 %419, 2
  %421 = trunc i32 %420 to i16
  %422 = add nsw i32 %144, 7
  %423 = sext i32 %422 to i64
  %424 = getelementptr inbounds i16, i16* %5, i64 %423
  store i16 %421, i16* %424, align 2
  %425 = add nsw i32 %133, 6
  %426 = sext i32 %425 to i64
  %427 = getelementptr inbounds i16, i16* %5, i64 %426
  store i16 %421, i16* %427, align 2
  %428 = add i64 %19, 21474836480
  %429 = ashr exact i64 %428, 32
  %430 = getelementptr inbounds i16, i16* %5, i64 %429
  store i16 %421, i16* %430, align 2
  %431 = getelementptr inbounds i8, i8* %0, i64 8
  %432 = bitcast i8* %431 to i16*
  store i16 %421, i16* %432, align 2
  %433 = shl nuw nsw i32 %76, 1
  %434 = add nuw nsw i32 %66, 2
  %435 = add nuw nsw i32 %434, %433
  %436 = add nuw nsw i32 %435, %86
  %437 = lshr i32 %436, 2
  %438 = trunc i32 %437 to i16
  %439 = add nsw i32 %133, 7
  %440 = sext i32 %439 to i64
  %441 = getelementptr inbounds i16, i16* %5, i64 %440
  store i16 %438, i16* %441, align 2
  %442 = add i64 %19, 25769803776
  %443 = ashr exact i64 %442, 32
  %444 = getelementptr inbounds i16, i16* %5, i64 %443
  store i16 %438, i16* %444, align 2
  %445 = getelementptr inbounds i8, i8* %0, i64 10
  %446 = bitcast i8* %445 to i16*
  store i16 %438, i16* %446, align 2
  %447 = shl nuw nsw i32 %86, 1
  %448 = add nuw nsw i32 %76, 2
  %449 = add nuw nsw i32 %448, %447
  %450 = add nuw nsw i32 %449, %96
  %451 = lshr i32 %450, 2
  %452 = trunc i32 %451 to i16
  %453 = add i64 %19, 30064771072
  %454 = ashr exact i64 %453, 32
  %455 = getelementptr inbounds i16, i16* %5, i64 %454
  store i16 %452, i16* %455, align 2
  %456 = getelementptr inbounds i8, i8* %0, i64 12
  %457 = bitcast i8* %456 to i16*
  store i16 %452, i16* %457, align 2
  %458 = shl nuw nsw i32 %96, 1
  %459 = add nuw nsw i32 %86, 2
  %460 = add nuw nsw i32 %459, %458
  %461 = add nuw nsw i32 %460, %110
  %462 = lshr i32 %461, 2
  %463 = trunc i32 %462 to i16
  %464 = getelementptr inbounds i8, i8* %0, i64 14
  %465 = bitcast i8* %464 to i16*
  store i16 %463, i16* %465, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_right_10_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp ne i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %10, label %15

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %27, 2
  %45 = add nuw nsw i32 %44, %38
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %43, 2
  %64 = add nuw nsw i32 %63, %57
  %65 = add nuw nsw i32 %64, %62
  %66 = lshr i32 %65, 2
  %67 = shl nuw nsw i32 %62, 1
  %68 = sub i64 21474836480, %19
  %69 = ashr exact i64 %68, 32
  %70 = getelementptr inbounds i16, i16* %5, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i32
  %73 = add nuw nsw i32 %53, 2
  %74 = add nuw nsw i32 %73, %67
  %75 = add nuw nsw i32 %74, %72
  %76 = lshr i32 %75, 2
  %77 = shl nuw nsw i32 %72, 1
  %78 = sub i64 25769803776, %19
  %79 = ashr exact i64 %78, 32
  %80 = getelementptr inbounds i16, i16* %5, i64 %79
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i32
  %83 = add nuw nsw i32 %62, 2
  %84 = add nuw nsw i32 %83, %77
  %85 = add nuw nsw i32 %84, %82
  %86 = lshr i32 %85, 2
  %87 = shl nuw nsw i32 %82, 1
  %88 = sub i64 30064771072, %19
  %89 = ashr exact i64 %88, 32
  %90 = getelementptr inbounds i16, i16* %5, i64 %89
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i32
  %93 = add nuw nsw i32 %72, 2
  %94 = add nuw nsw i32 %93, %87
  %95 = add nuw nsw i32 %94, %92
  %96 = lshr i32 %95, 2
  %97 = icmp eq i32 %2, 0
  br i1 %97, label %104, label %98

98:                                               ; preds = %18
  %99 = sub i64 34359738368, %19
  %100 = ashr exact i64 %99, 32
  %101 = getelementptr inbounds i16, i16* %5, i64 %100
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  br label %104

104:                                              ; preds = %18, %98
  %105 = phi i32 [ %103, %98 ], [ %92, %18 ]
  %106 = shl nuw nsw i32 %92, 1
  %107 = add nuw nsw i32 %82, 2
  %108 = add nuw nsw i32 %107, %106
  %109 = add nuw nsw i32 %108, %105
  %110 = lshr i32 %109, 2
  %111 = ashr exact i64 %19, 32
  %112 = xor i64 %111, -1
  %113 = getelementptr inbounds i16, i16* %5, i64 %112
  %114 = getelementptr inbounds i8, i8* %0, i64 -2
  %115 = bitcast i8* %114 to i16*
  %116 = select i1 %8, i16* %113, i16* %115
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = load i16, i16* %115, align 2
  %120 = zext i16 %119 to i32
  %121 = shl nuw nsw i32 %120, 1
  %122 = add i64 %19, -4294967296
  %123 = ashr exact i64 %122, 32
  %124 = getelementptr inbounds i16, i16* %5, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %126, 2
  %128 = add nuw nsw i32 %127, %118
  %129 = add nuw nsw i32 %128, %121
  %130 = lshr i32 %129, 2
  %131 = shl nuw nsw i32 %126, 1
  %132 = trunc i64 %3 to i32
  %133 = and i32 %132, -2
  %134 = add nsw i32 %133, -1
  %135 = sext i32 %134 to i64
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  %137 = load i16, i16* %136, align 2
  %138 = zext i16 %137 to i32
  %139 = add nuw nsw i32 %120, 2
  %140 = add nuw nsw i32 %139, %131
  %141 = add nuw nsw i32 %140, %138
  %142 = lshr i32 %141, 2
  %143 = shl nuw nsw i32 %138, 1
  %144 = mul nsw i32 %7, 3
  %145 = add nsw i32 %144, -1
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds i16, i16* %5, i64 %146
  %148 = load i16, i16* %147, align 2
  %149 = zext i16 %148 to i32
  %150 = add nuw nsw i32 %127, %143
  %151 = add nuw nsw i32 %150, %149
  %152 = lshr i32 %151, 2
  %153 = shl nuw nsw i32 %149, 1
  %154 = shl i64 %6, 34
  %155 = add i64 %154, -4294967296
  %156 = ashr exact i64 %155, 32
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  %158 = load i16, i16* %157, align 2
  %159 = zext i16 %158 to i32
  %160 = add nuw nsw i32 %138, 2
  %161 = add nuw nsw i32 %160, %153
  %162 = add nuw nsw i32 %161, %159
  %163 = lshr i32 %162, 2
  %164 = shl nuw nsw i32 %159, 1
  %165 = mul nsw i32 %7, 5
  %166 = add nsw i32 %165, -1
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds i16, i16* %5, i64 %167
  %169 = load i16, i16* %168, align 2
  %170 = zext i16 %169 to i32
  %171 = add nuw nsw i32 %149, 2
  %172 = add nuw nsw i32 %171, %164
  %173 = add nuw nsw i32 %172, %170
  %174 = lshr i32 %173, 2
  %175 = shl nuw nsw i32 %170, 1
  %176 = mul nsw i32 %7, 6
  %177 = add nsw i32 %176, -1
  %178 = sext i32 %177 to i64
  %179 = getelementptr inbounds i16, i16* %5, i64 %178
  %180 = load i16, i16* %179, align 2
  %181 = zext i16 %180 to i32
  %182 = add nuw nsw i32 %159, 2
  %183 = add nuw nsw i32 %182, %175
  %184 = add nuw nsw i32 %183, %181
  %185 = lshr i32 %184, 2
  %186 = shl nuw nsw i32 %181, 1
  %187 = mul nsw i32 %7, 7
  %188 = add nsw i32 %187, -1
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds i16, i16* %5, i64 %189
  %191 = load i16, i16* %190, align 2
  %192 = zext i16 %191 to i32
  %193 = add nuw nsw i32 %170, 2
  %194 = add nuw nsw i32 %193, %186
  %195 = add nuw nsw i32 %194, %192
  %196 = lshr i32 %195, 2
  %197 = load i16, i16* %113, align 2
  %198 = zext i16 %197 to i32
  %199 = shl nuw nsw i32 %198, 1
  %200 = add nuw nsw i32 %44, %120
  %201 = add nuw nsw i32 %200, %199
  %202 = lshr i32 %201, 2
  %203 = shl nuw nsw i32 %174, 1
  %204 = add nuw nsw i32 %163, 2
  %205 = add nuw nsw i32 %204, %203
  %206 = add nuw nsw i32 %205, %185
  %207 = lshr i32 %206, 2
  %208 = trunc i32 %207 to i16
  %209 = sext i32 %176 to i64
  %210 = getelementptr inbounds i16, i16* %5, i64 %209
  store i16 %208, i16* %210, align 2
  %211 = shl nuw nsw i32 %185, 1
  %212 = add nuw nsw i32 %174, 2
  %213 = add nuw nsw i32 %212, %211
  %214 = add nuw nsw i32 %213, %196
  %215 = lshr i32 %214, 2
  %216 = trunc i32 %215 to i16
  %217 = sext i32 %187 to i64
  %218 = getelementptr inbounds i16, i16* %5, i64 %217
  store i16 %216, i16* %218, align 2
  %219 = shl nuw nsw i32 %152, 1
  %220 = add nuw nsw i32 %142, 2
  %221 = add nuw nsw i32 %220, %219
  %222 = add nuw nsw i32 %221, %163
  %223 = lshr i32 %222, 2
  %224 = trunc i32 %223 to i16
  %225 = or i32 %176, 1
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds i16, i16* %5, i64 %226
  store i16 %224, i16* %227, align 2
  %228 = ashr exact i64 %154, 32
  %229 = getelementptr inbounds i16, i16* %5, i64 %228
  store i16 %224, i16* %229, align 2
  %230 = shl nuw nsw i32 %163, 1
  %231 = add nuw nsw i32 %152, 2
  %232 = add nuw nsw i32 %231, %230
  %233 = add nuw nsw i32 %232, %174
  %234 = lshr i32 %233, 2
  %235 = trunc i32 %234 to i16
  %236 = add nsw i32 %187, 1
  %237 = sext i32 %236 to i64
  %238 = getelementptr inbounds i16, i16* %5, i64 %237
  store i16 %235, i16* %238, align 2
  %239 = sext i32 %165 to i64
  %240 = getelementptr inbounds i16, i16* %5, i64 %239
  store i16 %235, i16* %240, align 2
  %241 = shl nuw nsw i32 %130, 1
  %242 = add nuw nsw i32 %220, %241
  %243 = add nuw nsw i32 %242, %202
  %244 = lshr i32 %243, 2
  %245 = trunc i32 %244 to i16
  %246 = add nsw i32 %176, 2
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds i16, i16* %5, i64 %247
  store i16 %245, i16* %248, align 2
  %249 = or i64 %228, 1
  %250 = getelementptr inbounds i16, i16* %5, i64 %249
  store i16 %245, i16* %250, align 2
  %251 = sext i32 %133 to i64
  %252 = getelementptr inbounds i16, i16* %5, i64 %251
  store i16 %245, i16* %252, align 2
  %253 = shl nuw nsw i32 %142, 1
  %254 = add nuw nsw i32 %130, 2
  %255 = add nuw nsw i32 %254, %253
  %256 = add nuw nsw i32 %255, %152
  %257 = lshr i32 %256, 2
  %258 = trunc i32 %257 to i16
  %259 = add nsw i32 %187, 2
  %260 = sext i32 %259 to i64
  %261 = getelementptr inbounds i16, i16* %5, i64 %260
  store i16 %258, i16* %261, align 2
  %262 = add nsw i32 %165, 1
  %263 = sext i32 %262 to i64
  %264 = getelementptr inbounds i16, i16* %5, i64 %263
  store i16 %258, i16* %264, align 2
  %265 = sext i32 %144 to i64
  %266 = getelementptr inbounds i16, i16* %5, i64 %265
  store i16 %258, i16* %266, align 2
  %267 = shl nuw nsw i32 %202, 1
  %268 = add nuw nsw i32 %37, 2
  %269 = add nuw nsw i32 %268, %130
  %270 = add nuw nsw i32 %269, %267
  %271 = lshr i32 %270, 2
  %272 = trunc i32 %271 to i16
  %273 = add nsw i32 %187, 3
  %274 = sext i32 %273 to i64
  %275 = getelementptr inbounds i16, i16* %5, i64 %274
  store i16 %272, i16* %275, align 2
  %276 = add nsw i32 %165, 2
  %277 = sext i32 %276 to i64
  %278 = getelementptr inbounds i16, i16* %5, i64 %277
  store i16 %272, i16* %278, align 2
  %279 = add nsw i32 %144, 1
  %280 = sext i32 %279 to i64
  %281 = getelementptr inbounds i16, i16* %5, i64 %280
  store i16 %272, i16* %281, align 2
  %282 = getelementptr inbounds i16, i16* %5, i64 %111
  store i16 %272, i16* %282, align 2
  %283 = add nuw nsw i32 %37, 1
  %284 = add nuw nsw i32 %283, %202
  %285 = lshr i32 %284, 1
  %286 = trunc i32 %285 to i16
  %287 = add nsw i32 %176, 3
  %288 = sext i32 %287 to i64
  %289 = getelementptr inbounds i16, i16* %5, i64 %288
  store i16 %286, i16* %289, align 2
  %290 = or i64 %228, 2
  %291 = getelementptr inbounds i16, i16* %5, i64 %290
  store i16 %286, i16* %291, align 2
  %292 = shl i64 %3, 32
  %293 = ashr exact i64 %292, 32
  %294 = or i64 %293, 1
  %295 = getelementptr inbounds i16, i16* %5, i64 %294
  store i16 %286, i16* %295, align 2
  store i16 %286, i16* %5, align 2
  %296 = shl nuw nsw i32 %37, 1
  %297 = add nuw nsw i32 %47, 2
  %298 = add nuw nsw i32 %297, %296
  %299 = add nuw nsw i32 %298, %202
  %300 = lshr i32 %299, 2
  %301 = trunc i32 %300 to i16
  %302 = add nsw i32 %187, 4
  %303 = sext i32 %302 to i64
  %304 = getelementptr inbounds i16, i16* %5, i64 %303
  store i16 %301, i16* %304, align 2
  %305 = add nsw i32 %165, 3
  %306 = sext i32 %305 to i64
  %307 = getelementptr inbounds i16, i16* %5, i64 %306
  store i16 %301, i16* %307, align 2
  %308 = add nsw i32 %144, 2
  %309 = sext i32 %308 to i64
  %310 = getelementptr inbounds i16, i16* %5, i64 %309
  store i16 %301, i16* %310, align 2
  %311 = add i64 %19, 4294967296
  %312 = ashr exact i64 %311, 32
  %313 = getelementptr inbounds i16, i16* %5, i64 %312
  store i16 %301, i16* %313, align 2
  %314 = add nuw nsw i32 %283, %47
  %315 = lshr i32 %314, 1
  %316 = trunc i32 %315 to i16
  %317 = add nsw i32 %176, 4
  %318 = sext i32 %317 to i64
  %319 = getelementptr inbounds i16, i16* %5, i64 %318
  store i16 %316, i16* %319, align 2
  %320 = or i64 %228, 3
  %321 = getelementptr inbounds i16, i16* %5, i64 %320
  store i16 %316, i16* %321, align 2
  %322 = add nsw i32 %133, 2
  %323 = sext i32 %322 to i64
  %324 = getelementptr inbounds i16, i16* %5, i64 %323
  store i16 %316, i16* %324, align 2
  %325 = getelementptr inbounds i8, i8* %0, i64 2
  %326 = bitcast i8* %325 to i16*
  store i16 %316, i16* %326, align 2
  %327 = shl nuw nsw i32 %47, 1
  %328 = add nuw nsw i32 %268, %327
  %329 = add nuw nsw i32 %328, %56
  %330 = lshr i32 %329, 2
  %331 = trunc i32 %330 to i16
  %332 = add nsw i32 %187, 5
  %333 = sext i32 %332 to i64
  %334 = getelementptr inbounds i16, i16* %5, i64 %333
  store i16 %331, i16* %334, align 2
  %335 = add nsw i32 %165, 4
  %336 = sext i32 %335 to i64
  %337 = getelementptr inbounds i16, i16* %5, i64 %336
  store i16 %331, i16* %337, align 2
  %338 = add nsw i32 %144, 3
  %339 = sext i32 %338 to i64
  %340 = getelementptr inbounds i16, i16* %5, i64 %339
  store i16 %331, i16* %340, align 2
  %341 = add i64 %19, 8589934592
  %342 = ashr exact i64 %341, 32
  %343 = getelementptr inbounds i16, i16* %5, i64 %342
  store i16 %331, i16* %343, align 2
  %344 = add nuw nsw i32 %47, 1
  %345 = add nuw nsw i32 %344, %56
  %346 = lshr i32 %345, 1
  %347 = trunc i32 %346 to i16
  %348 = add nsw i32 %176, 5
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i16, i16* %5, i64 %349
  store i16 %347, i16* %350, align 2
  %351 = add i64 %154, 17179869184
  %352 = ashr exact i64 %351, 32
  %353 = getelementptr inbounds i16, i16* %5, i64 %352
  store i16 %347, i16* %353, align 2
  %354 = add nsw i32 %133, 3
  %355 = sext i32 %354 to i64
  %356 = getelementptr inbounds i16, i16* %5, i64 %355
  store i16 %347, i16* %356, align 2
  %357 = getelementptr inbounds i8, i8* %0, i64 4
  %358 = bitcast i8* %357 to i16*
  store i16 %347, i16* %358, align 2
  %359 = shl nuw nsw i32 %56, 1
  %360 = add nuw nsw i32 %297, %359
  %361 = add nuw nsw i32 %360, %66
  %362 = lshr i32 %361, 2
  %363 = trunc i32 %362 to i16
  %364 = add nsw i32 %187, 6
  %365 = sext i32 %364 to i64
  %366 = getelementptr inbounds i16, i16* %5, i64 %365
  store i16 %363, i16* %366, align 2
  %367 = add nsw i32 %165, 5
  %368 = sext i32 %367 to i64
  %369 = getelementptr inbounds i16, i16* %5, i64 %368
  store i16 %363, i16* %369, align 2
  %370 = add nsw i32 %144, 4
  %371 = sext i32 %370 to i64
  %372 = getelementptr inbounds i16, i16* %5, i64 %371
  store i16 %363, i16* %372, align 2
  %373 = add i64 %19, 12884901888
  %374 = ashr exact i64 %373, 32
  %375 = getelementptr inbounds i16, i16* %5, i64 %374
  store i16 %363, i16* %375, align 2
  %376 = add nuw nsw i32 %56, 1
  %377 = add nuw nsw i32 %376, %66
  %378 = lshr i32 %377, 1
  %379 = trunc i32 %378 to i16
  %380 = add nsw i32 %176, 6
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i16, i16* %5, i64 %381
  store i16 %379, i16* %382, align 2
  %383 = add i64 %154, 21474836480
  %384 = ashr exact i64 %383, 32
  %385 = getelementptr inbounds i16, i16* %5, i64 %384
  store i16 %379, i16* %385, align 2
  %386 = add nsw i32 %133, 4
  %387 = sext i32 %386 to i64
  %388 = getelementptr inbounds i16, i16* %5, i64 %387
  store i16 %379, i16* %388, align 2
  %389 = getelementptr inbounds i8, i8* %0, i64 6
  %390 = bitcast i8* %389 to i16*
  store i16 %379, i16* %390, align 2
  %391 = shl nuw nsw i32 %66, 1
  %392 = add nuw nsw i32 %56, 2
  %393 = add nuw nsw i32 %392, %391
  %394 = add nuw nsw i32 %393, %76
  %395 = lshr i32 %394, 2
  %396 = trunc i32 %395 to i16
  %397 = add nsw i32 %187, 7
  %398 = sext i32 %397 to i64
  %399 = getelementptr inbounds i16, i16* %5, i64 %398
  store i16 %396, i16* %399, align 2
  %400 = add nsw i32 %165, 6
  %401 = sext i32 %400 to i64
  %402 = getelementptr inbounds i16, i16* %5, i64 %401
  store i16 %396, i16* %402, align 2
  %403 = add nsw i32 %144, 5
  %404 = sext i32 %403 to i64
  %405 = getelementptr inbounds i16, i16* %5, i64 %404
  store i16 %396, i16* %405, align 2
  %406 = add i64 %19, 17179869184
  %407 = ashr exact i64 %406, 32
  %408 = getelementptr inbounds i16, i16* %5, i64 %407
  store i16 %396, i16* %408, align 2
  %409 = add nuw nsw i32 %66, 1
  %410 = add nuw nsw i32 %409, %76
  %411 = lshr i32 %410, 1
  %412 = trunc i32 %411 to i16
  %413 = add nsw i32 %176, 7
  %414 = sext i32 %413 to i64
  %415 = getelementptr inbounds i16, i16* %5, i64 %414
  store i16 %412, i16* %415, align 2
  %416 = add i64 %154, 25769803776
  %417 = ashr exact i64 %416, 32
  %418 = getelementptr inbounds i16, i16* %5, i64 %417
  store i16 %412, i16* %418, align 2
  %419 = add nsw i32 %133, 5
  %420 = sext i32 %419 to i64
  %421 = getelementptr inbounds i16, i16* %5, i64 %420
  store i16 %412, i16* %421, align 2
  %422 = getelementptr inbounds i8, i8* %0, i64 8
  %423 = bitcast i8* %422 to i16*
  store i16 %412, i16* %423, align 2
  %424 = shl nuw nsw i32 %76, 1
  %425 = add nuw nsw i32 %66, 2
  %426 = add nuw nsw i32 %425, %424
  %427 = add nuw nsw i32 %426, %86
  %428 = lshr i32 %427, 2
  %429 = trunc i32 %428 to i16
  %430 = add nsw i32 %165, 7
  %431 = sext i32 %430 to i64
  %432 = getelementptr inbounds i16, i16* %5, i64 %431
  store i16 %429, i16* %432, align 2
  %433 = add nsw i32 %144, 6
  %434 = sext i32 %433 to i64
  %435 = getelementptr inbounds i16, i16* %5, i64 %434
  store i16 %429, i16* %435, align 2
  %436 = add i64 %19, 21474836480
  %437 = ashr exact i64 %436, 32
  %438 = getelementptr inbounds i16, i16* %5, i64 %437
  store i16 %429, i16* %438, align 2
  %439 = add nuw nsw i32 %76, 1
  %440 = add nuw nsw i32 %439, %86
  %441 = lshr i32 %440, 1
  %442 = trunc i32 %441 to i16
  %443 = add i64 %154, 30064771072
  %444 = ashr exact i64 %443, 32
  %445 = getelementptr inbounds i16, i16* %5, i64 %444
  store i16 %442, i16* %445, align 2
  %446 = add nsw i32 %133, 6
  %447 = sext i32 %446 to i64
  %448 = getelementptr inbounds i16, i16* %5, i64 %447
  store i16 %442, i16* %448, align 2
  %449 = getelementptr inbounds i8, i8* %0, i64 10
  %450 = bitcast i8* %449 to i16*
  store i16 %442, i16* %450, align 2
  %451 = shl nuw nsw i32 %86, 1
  %452 = add nuw nsw i32 %76, 2
  %453 = add nuw nsw i32 %452, %451
  %454 = add nuw nsw i32 %453, %96
  %455 = lshr i32 %454, 2
  %456 = trunc i32 %455 to i16
  %457 = add nsw i32 %144, 7
  %458 = sext i32 %457 to i64
  %459 = getelementptr inbounds i16, i16* %5, i64 %458
  store i16 %456, i16* %459, align 2
  %460 = add i64 %19, 25769803776
  %461 = ashr exact i64 %460, 32
  %462 = getelementptr inbounds i16, i16* %5, i64 %461
  store i16 %456, i16* %462, align 2
  %463 = add nuw nsw i32 %86, 1
  %464 = add nuw nsw i32 %463, %96
  %465 = lshr i32 %464, 1
  %466 = trunc i32 %465 to i16
  %467 = add nsw i32 %133, 7
  %468 = sext i32 %467 to i64
  %469 = getelementptr inbounds i16, i16* %5, i64 %468
  store i16 %466, i16* %469, align 2
  %470 = getelementptr inbounds i8, i8* %0, i64 12
  %471 = bitcast i8* %470 to i16*
  store i16 %466, i16* %471, align 2
  %472 = shl nuw nsw i32 %96, 1
  %473 = add nuw nsw i32 %86, 2
  %474 = add nuw nsw i32 %473, %472
  %475 = add nuw nsw i32 %474, %110
  %476 = lshr i32 %475, 2
  %477 = trunc i32 %476 to i16
  %478 = add i64 %19, 30064771072
  %479 = ashr exact i64 %478, 32
  %480 = getelementptr inbounds i16, i16* %5, i64 %479
  store i16 %477, i16* %480, align 2
  %481 = add nuw nsw i32 %96, 1
  %482 = add nuw nsw i32 %481, %110
  %483 = lshr i32 %482, 1
  %484 = trunc i32 %483 to i16
  %485 = getelementptr inbounds i8, i8* %0, i64 14
  %486 = bitcast i8* %485 to i16*
  store i16 %484, i16* %486, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_down_10_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp ne i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %10, label %15

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %20

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  %18 = ashr exact i64 %17, 32
  %19 = xor i64 %18, -1
  br label %20

20:                                               ; preds = %15, %10
  %21 = phi i64 [ %19, %15 ], [ %13, %10 ]
  %22 = phi i64 [ %18, %15 ], [ %12, %10 ]
  %23 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %24 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %25 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %26 = getelementptr inbounds i16, i16* %5, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = getelementptr inbounds i16, i16* %5, i64 %24
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i32
  %32 = shl nuw nsw i32 %31, 1
  %33 = sub i64 4294967296, %23
  %34 = ashr exact i64 %33, 32
  %35 = getelementptr inbounds i16, i16* %5, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i32
  %38 = add nuw nsw i32 %37, 2
  %39 = add nuw nsw i32 %38, %28
  %40 = add nuw nsw i32 %39, %32
  %41 = lshr i32 %40, 2
  %42 = shl nuw nsw i32 %37, 1
  %43 = sub i64 8589934592, %23
  %44 = ashr exact i64 %43, 32
  %45 = getelementptr inbounds i16, i16* %5, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i32
  %48 = add nuw nsw i32 %31, 2
  %49 = add nuw nsw i32 %48, %42
  %50 = add nuw nsw i32 %49, %47
  %51 = lshr i32 %50, 2
  %52 = shl nuw nsw i32 %47, 1
  %53 = sub i64 12884901888, %23
  %54 = ashr exact i64 %53, 32
  %55 = getelementptr inbounds i16, i16* %5, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i32
  %58 = add nuw nsw i32 %38, %52
  %59 = add nuw nsw i32 %58, %57
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %57, 1
  %62 = sub i64 17179869184, %23
  %63 = ashr exact i64 %62, 32
  %64 = getelementptr inbounds i16, i16* %5, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i32
  %67 = add nuw nsw i32 %47, 2
  %68 = add nuw nsw i32 %67, %61
  %69 = add nuw nsw i32 %68, %66
  %70 = lshr i32 %69, 2
  %71 = shl nuw nsw i32 %66, 1
  %72 = sub i64 21474836480, %23
  %73 = ashr exact i64 %72, 32
  %74 = getelementptr inbounds i16, i16* %5, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i32
  %77 = add nuw nsw i32 %57, 2
  %78 = add nuw nsw i32 %77, %71
  %79 = add nuw nsw i32 %78, %76
  %80 = lshr i32 %79, 2
  %81 = shl nuw nsw i32 %76, 1
  %82 = sub i64 25769803776, %23
  %83 = ashr exact i64 %82, 32
  %84 = getelementptr inbounds i16, i16* %5, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i32
  %87 = add nuw nsw i32 %66, 2
  %88 = add nuw nsw i32 %87, %81
  %89 = add nuw nsw i32 %88, %86
  %90 = lshr i32 %89, 2
  %91 = shl nuw nsw i32 %86, 1
  %92 = sub i64 30064771072, %23
  %93 = ashr exact i64 %92, 32
  %94 = getelementptr inbounds i16, i16* %5, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i32
  %97 = add nuw nsw i32 %76, 2
  %98 = add nuw nsw i32 %97, %91
  %99 = add nuw nsw i32 %98, %96
  %100 = lshr i32 %99, 2
  %101 = getelementptr inbounds i16, i16* %5, i64 %21
  %102 = getelementptr inbounds i8, i8* %0, i64 -2
  %103 = bitcast i8* %102 to i16*
  %104 = select i1 %8, i16* %101, i16* %103
  %105 = load i16, i16* %104, align 2
  %106 = zext i16 %105 to i32
  %107 = load i16, i16* %103, align 2
  %108 = zext i16 %107 to i32
  %109 = shl nuw nsw i32 %108, 1
  %110 = add i64 %23, -4294967296
  %111 = ashr exact i64 %110, 32
  %112 = getelementptr inbounds i16, i16* %5, i64 %111
  %113 = load i16, i16* %112, align 2
  %114 = zext i16 %113 to i32
  %115 = add nuw nsw i32 %114, 2
  %116 = add nuw nsw i32 %115, %106
  %117 = add nuw nsw i32 %116, %109
  %118 = lshr i32 %117, 2
  %119 = shl nuw nsw i32 %114, 1
  %120 = trunc i64 %3 to i32
  %121 = and i32 %120, -2
  %122 = add nsw i32 %121, -1
  %123 = sext i32 %122 to i64
  %124 = getelementptr inbounds i16, i16* %5, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %108, 2
  %128 = add nuw nsw i32 %127, %119
  %129 = add nuw nsw i32 %128, %126
  %130 = lshr i32 %129, 2
  %131 = shl nuw nsw i32 %126, 1
  %132 = mul nsw i32 %7, 3
  %133 = add nsw i32 %132, -1
  %134 = sext i32 %133 to i64
  %135 = getelementptr inbounds i16, i16* %5, i64 %134
  %136 = load i16, i16* %135, align 2
  %137 = zext i16 %136 to i32
  %138 = add nuw nsw i32 %115, %131
  %139 = add nuw nsw i32 %138, %137
  %140 = lshr i32 %139, 2
  %141 = shl nuw nsw i32 %137, 1
  %142 = shl i64 %6, 34
  %143 = add i64 %142, -4294967296
  %144 = ashr exact i64 %143, 32
  %145 = getelementptr inbounds i16, i16* %5, i64 %144
  %146 = load i16, i16* %145, align 2
  %147 = zext i16 %146 to i32
  %148 = add nuw nsw i32 %126, 2
  %149 = add nuw nsw i32 %148, %141
  %150 = add nuw nsw i32 %149, %147
  %151 = lshr i32 %150, 2
  %152 = shl nuw nsw i32 %147, 1
  %153 = mul nsw i32 %7, 5
  %154 = add nsw i32 %153, -1
  %155 = sext i32 %154 to i64
  %156 = getelementptr inbounds i16, i16* %5, i64 %155
  %157 = load i16, i16* %156, align 2
  %158 = zext i16 %157 to i32
  %159 = add nuw nsw i32 %137, 2
  %160 = add nuw nsw i32 %159, %152
  %161 = add nuw nsw i32 %160, %158
  %162 = lshr i32 %161, 2
  %163 = shl nuw nsw i32 %158, 1
  %164 = mul nsw i32 %7, 6
  %165 = add nsw i32 %164, -1
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds i16, i16* %5, i64 %166
  %168 = load i16, i16* %167, align 2
  %169 = zext i16 %168 to i32
  %170 = add nuw nsw i32 %147, 2
  %171 = add nuw nsw i32 %170, %163
  %172 = add nuw nsw i32 %171, %169
  %173 = lshr i32 %172, 2
  %174 = shl nuw nsw i32 %169, 1
  %175 = mul nsw i32 %7, 7
  %176 = add nsw i32 %175, -1
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds i16, i16* %5, i64 %177
  %179 = load i16, i16* %178, align 2
  %180 = zext i16 %179 to i32
  %181 = add nuw nsw i32 %158, 2
  %182 = add nuw nsw i32 %181, %174
  %183 = add nuw nsw i32 %182, %180
  %184 = lshr i32 %183, 2
  %185 = mul nuw nsw i32 %180, 3
  %186 = add nuw nsw i32 %169, 2
  %187 = add nuw nsw i32 %186, %185
  %188 = lshr i32 %187, 2
  %189 = load i16, i16* %101, align 2
  %190 = zext i16 %189 to i32
  %191 = shl nuw nsw i32 %190, 1
  %192 = add nuw nsw i32 %48, %108
  %193 = add nuw nsw i32 %192, %191
  %194 = lshr i32 %193, 2
  %195 = add nuw nsw i32 %184, 1
  %196 = add nuw nsw i32 %195, %188
  %197 = lshr i32 %196, 1
  %198 = trunc i32 %197 to i16
  %199 = sext i32 %175 to i64
  %200 = getelementptr inbounds i16, i16* %5, i64 %199
  store i16 %198, i16* %200, align 2
  %201 = shl nuw nsw i32 %184, 1
  %202 = add nuw nsw i32 %173, 2
  %203 = add nuw nsw i32 %202, %188
  %204 = add nuw nsw i32 %203, %201
  %205 = lshr i32 %204, 2
  %206 = trunc i32 %205 to i16
  %207 = add nsw i32 %175, 1
  %208 = sext i32 %207 to i64
  %209 = getelementptr inbounds i16, i16* %5, i64 %208
  store i16 %206, i16* %209, align 2
  %210 = add nuw nsw i32 %173, 1
  %211 = add nuw nsw i32 %210, %184
  %212 = lshr i32 %211, 1
  %213 = trunc i32 %212 to i16
  %214 = add nsw i32 %175, 2
  %215 = sext i32 %214 to i64
  %216 = getelementptr inbounds i16, i16* %5, i64 %215
  store i16 %213, i16* %216, align 2
  %217 = sext i32 %164 to i64
  %218 = getelementptr inbounds i16, i16* %5, i64 %217
  store i16 %213, i16* %218, align 2
  %219 = shl nuw nsw i32 %173, 1
  %220 = add nuw nsw i32 %162, 2
  %221 = add nuw nsw i32 %220, %219
  %222 = add nuw nsw i32 %221, %184
  %223 = lshr i32 %222, 2
  %224 = trunc i32 %223 to i16
  %225 = add nsw i32 %175, 3
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds i16, i16* %5, i64 %226
  store i16 %224, i16* %227, align 2
  %228 = or i32 %164, 1
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds i16, i16* %5, i64 %229
  store i16 %224, i16* %230, align 2
  %231 = add nuw nsw i32 %162, 1
  %232 = add nuw nsw i32 %231, %173
  %233 = lshr i32 %232, 1
  %234 = trunc i32 %233 to i16
  %235 = add nsw i32 %175, 4
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds i16, i16* %5, i64 %236
  store i16 %234, i16* %237, align 2
  %238 = add nsw i32 %164, 2
  %239 = sext i32 %238 to i64
  %240 = getelementptr inbounds i16, i16* %5, i64 %239
  store i16 %234, i16* %240, align 2
  %241 = sext i32 %153 to i64
  %242 = getelementptr inbounds i16, i16* %5, i64 %241
  store i16 %234, i16* %242, align 2
  %243 = shl nuw nsw i32 %162, 1
  %244 = add nuw nsw i32 %151, 2
  %245 = add nuw nsw i32 %244, %243
  %246 = add nuw nsw i32 %245, %173
  %247 = lshr i32 %246, 2
  %248 = trunc i32 %247 to i16
  %249 = add nsw i32 %175, 5
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds i16, i16* %5, i64 %250
  store i16 %248, i16* %251, align 2
  %252 = add nsw i32 %164, 3
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i16, i16* %5, i64 %253
  store i16 %248, i16* %254, align 2
  %255 = add nsw i32 %153, 1
  %256 = sext i32 %255 to i64
  %257 = getelementptr inbounds i16, i16* %5, i64 %256
  store i16 %248, i16* %257, align 2
  %258 = add nuw nsw i32 %151, 1
  %259 = add nuw nsw i32 %258, %162
  %260 = lshr i32 %259, 1
  %261 = trunc i32 %260 to i16
  %262 = add nsw i32 %175, 6
  %263 = sext i32 %262 to i64
  %264 = getelementptr inbounds i16, i16* %5, i64 %263
  store i16 %261, i16* %264, align 2
  %265 = add nsw i32 %164, 4
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds i16, i16* %5, i64 %266
  store i16 %261, i16* %267, align 2
  %268 = add nsw i32 %153, 2
  %269 = sext i32 %268 to i64
  %270 = getelementptr inbounds i16, i16* %5, i64 %269
  store i16 %261, i16* %270, align 2
  %271 = ashr exact i64 %142, 32
  %272 = getelementptr inbounds i16, i16* %5, i64 %271
  store i16 %261, i16* %272, align 2
  %273 = shl nuw nsw i32 %151, 1
  %274 = add nuw nsw i32 %140, 2
  %275 = add nuw nsw i32 %274, %273
  %276 = add nuw nsw i32 %275, %162
  %277 = lshr i32 %276, 2
  %278 = trunc i32 %277 to i16
  %279 = add nsw i32 %175, 7
  %280 = sext i32 %279 to i64
  %281 = getelementptr inbounds i16, i16* %5, i64 %280
  store i16 %278, i16* %281, align 2
  %282 = add nsw i32 %164, 5
  %283 = sext i32 %282 to i64
  %284 = getelementptr inbounds i16, i16* %5, i64 %283
  store i16 %278, i16* %284, align 2
  %285 = add nsw i32 %153, 3
  %286 = sext i32 %285 to i64
  %287 = getelementptr inbounds i16, i16* %5, i64 %286
  store i16 %278, i16* %287, align 2
  %288 = or i64 %271, 1
  %289 = getelementptr inbounds i16, i16* %5, i64 %288
  store i16 %278, i16* %289, align 2
  %290 = add nuw nsw i32 %140, 1
  %291 = add nuw nsw i32 %290, %151
  %292 = lshr i32 %291, 1
  %293 = trunc i32 %292 to i16
  %294 = add nsw i32 %164, 6
  %295 = sext i32 %294 to i64
  %296 = getelementptr inbounds i16, i16* %5, i64 %295
  store i16 %293, i16* %296, align 2
  %297 = add nsw i32 %153, 4
  %298 = sext i32 %297 to i64
  %299 = getelementptr inbounds i16, i16* %5, i64 %298
  store i16 %293, i16* %299, align 2
  %300 = or i64 %271, 2
  %301 = getelementptr inbounds i16, i16* %5, i64 %300
  store i16 %293, i16* %301, align 2
  %302 = sext i32 %132 to i64
  %303 = getelementptr inbounds i16, i16* %5, i64 %302
  store i16 %293, i16* %303, align 2
  %304 = shl nuw nsw i32 %140, 1
  %305 = add nuw nsw i32 %130, 2
  %306 = add nuw nsw i32 %305, %304
  %307 = add nuw nsw i32 %306, %151
  %308 = lshr i32 %307, 2
  %309 = trunc i32 %308 to i16
  %310 = add nsw i32 %164, 7
  %311 = sext i32 %310 to i64
  %312 = getelementptr inbounds i16, i16* %5, i64 %311
  store i16 %309, i16* %312, align 2
  %313 = add nsw i32 %153, 5
  %314 = sext i32 %313 to i64
  %315 = getelementptr inbounds i16, i16* %5, i64 %314
  store i16 %309, i16* %315, align 2
  %316 = or i64 %271, 3
  %317 = getelementptr inbounds i16, i16* %5, i64 %316
  store i16 %309, i16* %317, align 2
  %318 = add nsw i32 %132, 1
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %309, i16* %320, align 2
  %321 = add nuw nsw i32 %130, 1
  %322 = add nuw nsw i32 %321, %140
  %323 = lshr i32 %322, 1
  %324 = trunc i32 %323 to i16
  %325 = add nsw i32 %153, 6
  %326 = sext i32 %325 to i64
  %327 = getelementptr inbounds i16, i16* %5, i64 %326
  store i16 %324, i16* %327, align 2
  %328 = add i64 %142, 17179869184
  %329 = ashr exact i64 %328, 32
  %330 = getelementptr inbounds i16, i16* %5, i64 %329
  store i16 %324, i16* %330, align 2
  %331 = add nsw i32 %132, 2
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds i16, i16* %5, i64 %332
  store i16 %324, i16* %333, align 2
  %334 = sext i32 %121 to i64
  %335 = getelementptr inbounds i16, i16* %5, i64 %334
  store i16 %324, i16* %335, align 2
  %336 = shl nuw nsw i32 %130, 1
  %337 = add nuw nsw i32 %118, 2
  %338 = add nuw nsw i32 %337, %336
  %339 = add nuw nsw i32 %338, %140
  %340 = lshr i32 %339, 2
  %341 = trunc i32 %340 to i16
  %342 = add nsw i32 %153, 7
  %343 = sext i32 %342 to i64
  %344 = getelementptr inbounds i16, i16* %5, i64 %343
  store i16 %341, i16* %344, align 2
  %345 = add i64 %142, 21474836480
  %346 = ashr exact i64 %345, 32
  %347 = getelementptr inbounds i16, i16* %5, i64 %346
  store i16 %341, i16* %347, align 2
  %348 = add nsw i32 %132, 3
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i16, i16* %5, i64 %349
  store i16 %341, i16* %350, align 2
  %351 = shl i64 %3, 32
  %352 = ashr exact i64 %351, 32
  %353 = or i64 %352, 1
  %354 = getelementptr inbounds i16, i16* %5, i64 %353
  store i16 %341, i16* %354, align 2
  %355 = add nuw nsw i32 %118, 1
  %356 = add nuw nsw i32 %355, %130
  %357 = lshr i32 %356, 1
  %358 = trunc i32 %357 to i16
  %359 = add i64 %142, 25769803776
  %360 = ashr exact i64 %359, 32
  %361 = getelementptr inbounds i16, i16* %5, i64 %360
  store i16 %358, i16* %361, align 2
  %362 = add nsw i32 %132, 4
  %363 = sext i32 %362 to i64
  %364 = getelementptr inbounds i16, i16* %5, i64 %363
  store i16 %358, i16* %364, align 2
  %365 = add nsw i32 %121, 2
  %366 = sext i32 %365 to i64
  %367 = getelementptr inbounds i16, i16* %5, i64 %366
  store i16 %358, i16* %367, align 2
  %368 = getelementptr inbounds i16, i16* %5, i64 %22
  store i16 %358, i16* %368, align 2
  %369 = shl nuw nsw i32 %118, 1
  %370 = add nuw nsw i32 %305, %369
  %371 = add nuw nsw i32 %370, %194
  %372 = lshr i32 %371, 2
  %373 = trunc i32 %372 to i16
  %374 = add i64 %142, 30064771072
  %375 = ashr exact i64 %374, 32
  %376 = getelementptr inbounds i16, i16* %5, i64 %375
  store i16 %373, i16* %376, align 2
  %377 = add nsw i32 %132, 5
  %378 = sext i32 %377 to i64
  %379 = getelementptr inbounds i16, i16* %5, i64 %378
  store i16 %373, i16* %379, align 2
  %380 = add nsw i32 %121, 3
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i16, i16* %5, i64 %381
  store i16 %373, i16* %382, align 2
  %383 = add i64 %23, 4294967296
  %384 = ashr exact i64 %383, 32
  %385 = getelementptr inbounds i16, i16* %5, i64 %384
  store i16 %373, i16* %385, align 2
  %386 = add nuw nsw i32 %355, %194
  %387 = lshr i32 %386, 1
  %388 = trunc i32 %387 to i16
  %389 = add nsw i32 %132, 6
  %390 = sext i32 %389 to i64
  %391 = getelementptr inbounds i16, i16* %5, i64 %390
  store i16 %388, i16* %391, align 2
  %392 = add nsw i32 %121, 4
  %393 = sext i32 %392 to i64
  %394 = getelementptr inbounds i16, i16* %5, i64 %393
  store i16 %388, i16* %394, align 2
  %395 = add i64 %23, 8589934592
  %396 = ashr exact i64 %395, 32
  %397 = getelementptr inbounds i16, i16* %5, i64 %396
  store i16 %388, i16* %397, align 2
  store i16 %388, i16* %5, align 2
  %398 = shl nuw nsw i32 %194, 1
  %399 = add nuw nsw i32 %41, 2
  %400 = add nuw nsw i32 %399, %118
  %401 = add nuw nsw i32 %400, %398
  %402 = lshr i32 %401, 2
  %403 = trunc i32 %402 to i16
  %404 = add nsw i32 %132, 7
  %405 = sext i32 %404 to i64
  %406 = getelementptr inbounds i16, i16* %5, i64 %405
  store i16 %403, i16* %406, align 2
  %407 = add nsw i32 %121, 5
  %408 = sext i32 %407 to i64
  %409 = getelementptr inbounds i16, i16* %5, i64 %408
  store i16 %403, i16* %409, align 2
  %410 = add i64 %23, 12884901888
  %411 = ashr exact i64 %410, 32
  %412 = getelementptr inbounds i16, i16* %5, i64 %411
  store i16 %403, i16* %412, align 2
  %413 = getelementptr inbounds i8, i8* %0, i64 2
  %414 = bitcast i8* %413 to i16*
  store i16 %403, i16* %414, align 2
  %415 = shl nuw nsw i32 %41, 1
  %416 = add nuw nsw i32 %51, 2
  %417 = add nuw nsw i32 %416, %415
  %418 = add nuw nsw i32 %417, %194
  %419 = lshr i32 %418, 2
  %420 = trunc i32 %419 to i16
  %421 = add nsw i32 %121, 6
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds i16, i16* %5, i64 %422
  store i16 %420, i16* %423, align 2
  %424 = add i64 %23, 17179869184
  %425 = ashr exact i64 %424, 32
  %426 = getelementptr inbounds i16, i16* %5, i64 %425
  store i16 %420, i16* %426, align 2
  %427 = getelementptr inbounds i8, i8* %0, i64 4
  %428 = bitcast i8* %427 to i16*
  store i16 %420, i16* %428, align 2
  %429 = shl nuw nsw i32 %51, 1
  %430 = add nuw nsw i32 %399, %429
  %431 = add nuw nsw i32 %430, %60
  %432 = lshr i32 %431, 2
  %433 = trunc i32 %432 to i16
  %434 = add nsw i32 %121, 7
  %435 = sext i32 %434 to i64
  %436 = getelementptr inbounds i16, i16* %5, i64 %435
  store i16 %433, i16* %436, align 2
  %437 = add i64 %23, 21474836480
  %438 = ashr exact i64 %437, 32
  %439 = getelementptr inbounds i16, i16* %5, i64 %438
  store i16 %433, i16* %439, align 2
  %440 = getelementptr inbounds i8, i8* %0, i64 6
  %441 = bitcast i8* %440 to i16*
  store i16 %433, i16* %441, align 2
  %442 = shl nuw nsw i32 %60, 1
  %443 = add nuw nsw i32 %416, %442
  %444 = add nuw nsw i32 %443, %70
  %445 = lshr i32 %444, 2
  %446 = trunc i32 %445 to i16
  %447 = add i64 %23, 25769803776
  %448 = ashr exact i64 %447, 32
  %449 = getelementptr inbounds i16, i16* %5, i64 %448
  store i16 %446, i16* %449, align 2
  %450 = getelementptr inbounds i8, i8* %0, i64 8
  %451 = bitcast i8* %450 to i16*
  store i16 %446, i16* %451, align 2
  %452 = shl nuw nsw i32 %70, 1
  %453 = add nuw nsw i32 %60, 2
  %454 = add nuw nsw i32 %453, %452
  %455 = add nuw nsw i32 %454, %80
  %456 = lshr i32 %455, 2
  %457 = trunc i32 %456 to i16
  %458 = add i64 %23, 30064771072
  %459 = ashr exact i64 %458, 32
  %460 = getelementptr inbounds i16, i16* %5, i64 %459
  store i16 %457, i16* %460, align 2
  %461 = getelementptr inbounds i8, i8* %0, i64 10
  %462 = bitcast i8* %461 to i16*
  store i16 %457, i16* %462, align 2
  %463 = shl nuw nsw i32 %80, 1
  %464 = add nuw nsw i32 %70, 2
  %465 = add nuw nsw i32 %464, %463
  %466 = add nuw nsw i32 %465, %90
  %467 = lshr i32 %466, 2
  %468 = trunc i32 %467 to i16
  %469 = getelementptr inbounds i8, i8* %0, i64 12
  %470 = bitcast i8* %469 to i16*
  store i16 %468, i16* %470, align 2
  %471 = shl nuw nsw i32 %90, 1
  %472 = add nuw nsw i32 %80, 2
  %473 = add nuw nsw i32 %472, %471
  %474 = add nuw nsw i32 %473, %100
  %475 = lshr i32 %474, 2
  %476 = trunc i32 %475 to i16
  %477 = getelementptr inbounds i8, i8* %0, i64 14
  %478 = bitcast i8* %477 to i16*
  store i16 %476, i16* %478, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_left_10_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %97, label %99

97:                                               ; preds = %18
  %98 = mul nuw nsw i32 %91, 3
  br label %156

99:                                               ; preds = %18
  %100 = sub i64 34359738368, %19
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %5, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i32
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %105, %104
  %107 = shl nuw nsw i32 %104, 1
  %108 = sub i64 38654705664, %19
  %109 = ashr exact i64 %108, 32
  %110 = getelementptr inbounds i16, i16* %5, i64 %109
  %111 = load i16, i16* %110, align 2
  %112 = zext i16 %111 to i32
  %113 = add nuw nsw i32 %91, 2
  %114 = add nuw nsw i32 %113, %107
  %115 = add nuw nsw i32 %114, %112
  %116 = lshr i32 %115, 2
  %117 = shl nuw nsw i32 %112, 1
  %118 = sub i64 42949672960, %19
  %119 = ashr exact i64 %118, 32
  %120 = getelementptr inbounds i16, i16* %5, i64 %119
  %121 = load i16, i16* %120, align 2
  %122 = zext i16 %121 to i32
  %123 = add nuw nsw i32 %122, 2
  %124 = add nuw nsw i32 %123, %104
  %125 = add nuw nsw i32 %124, %117
  %126 = lshr i32 %125, 2
  %127 = shl nuw nsw i32 %122, 1
  %128 = sub i64 47244640256, %19
  %129 = ashr exact i64 %128, 32
  %130 = getelementptr inbounds i16, i16* %5, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i32
  %133 = add nuw nsw i32 %112, 2
  %134 = add nuw nsw i32 %133, %127
  %135 = add nuw nsw i32 %134, %132
  %136 = lshr i32 %135, 2
  %137 = shl nuw nsw i32 %132, 1
  %138 = sub i64 51539607552, %19
  %139 = ashr exact i64 %138, 32
  %140 = getelementptr inbounds i16, i16* %5, i64 %139
  %141 = load i16, i16* %140, align 2
  %142 = zext i16 %141 to i32
  %143 = add nuw nsw i32 %123, %137
  %144 = add nuw nsw i32 %143, %142
  %145 = lshr i32 %144, 2
  %146 = shl nuw nsw i32 %142, 1
  %147 = sub i64 55834574848, %19
  %148 = ashr exact i64 %147, 32
  %149 = getelementptr inbounds i16, i16* %5, i64 %148
  %150 = load i16, i16* %149, align 2
  %151 = zext i16 %150 to i32
  %152 = add nuw nsw i32 %132, 2
  %153 = add nuw nsw i32 %152, %146
  %154 = add nuw nsw i32 %153, %151
  %155 = lshr i32 %154, 2
  br label %156

156:                                              ; preds = %97, %99
  %157 = phi i32 [ %106, %99 ], [ %98, %97 ]
  %158 = phi i32 [ %116, %99 ], [ %91, %97 ]
  %159 = phi i32 [ %126, %99 ], [ %91, %97 ]
  %160 = phi i32 [ %136, %99 ], [ %91, %97 ]
  %161 = phi i32 [ %145, %99 ], [ %91, %97 ]
  %162 = phi i32 [ %155, %99 ], [ %91, %97 ]
  %163 = add nuw nsw i32 %81, 2
  %164 = add nuw nsw i32 %163, %157
  %165 = lshr i32 %164, 2
  %166 = add nuw nsw i32 %47, 1
  %167 = add nuw nsw i32 %166, %37
  %168 = lshr i32 %167, 1
  %169 = trunc i32 %168 to i16
  store i16 %169, i16* %5, align 2
  %170 = shl nuw nsw i32 %47, 1
  %171 = add nuw nsw i32 %56, 2
  %172 = add nuw nsw i32 %171, %37
  %173 = add nuw nsw i32 %172, %170
  %174 = lshr i32 %173, 2
  %175 = trunc i32 %174 to i16
  %176 = ashr exact i64 %19, 32
  %177 = getelementptr inbounds i16, i16* %5, i64 %176
  store i16 %175, i16* %177, align 2
  %178 = add nuw nsw i32 %166, %56
  %179 = lshr i32 %178, 1
  %180 = trunc i32 %179 to i16
  %181 = getelementptr inbounds i8, i8* %0, i64 2
  %182 = bitcast i8* %181 to i16*
  store i16 %180, i16* %182, align 2
  %183 = trunc i64 %3 to i32
  %184 = and i32 %183, -2
  %185 = sext i32 %184 to i64
  %186 = getelementptr inbounds i16, i16* %5, i64 %185
  store i16 %180, i16* %186, align 2
  %187 = shl nuw nsw i32 %56, 1
  %188 = add nuw nsw i32 %65, 2
  %189 = add nuw nsw i32 %188, %47
  %190 = add nuw nsw i32 %189, %187
  %191 = lshr i32 %190, 2
  %192 = trunc i32 %191 to i16
  %193 = add i64 %19, 4294967296
  %194 = ashr exact i64 %193, 32
  %195 = getelementptr inbounds i16, i16* %5, i64 %194
  store i16 %192, i16* %195, align 2
  %196 = mul nsw i32 %7, 3
  %197 = sext i32 %196 to i64
  %198 = getelementptr inbounds i16, i16* %5, i64 %197
  store i16 %192, i16* %198, align 2
  %199 = add nuw nsw i32 %56, 1
  %200 = add nuw nsw i32 %199, %65
  %201 = lshr i32 %200, 1
  %202 = trunc i32 %201 to i16
  %203 = getelementptr inbounds i8, i8* %0, i64 4
  %204 = bitcast i8* %203 to i16*
  store i16 %202, i16* %204, align 2
  %205 = shl i64 %3, 32
  %206 = ashr exact i64 %205, 32
  %207 = or i64 %206, 1
  %208 = getelementptr inbounds i16, i16* %5, i64 %207
  store i16 %202, i16* %208, align 2
  %209 = shl i64 %6, 34
  %210 = ashr exact i64 %209, 32
  %211 = getelementptr inbounds i16, i16* %5, i64 %210
  store i16 %202, i16* %211, align 2
  %212 = shl nuw nsw i32 %65, 1
  %213 = add nuw nsw i32 %171, %212
  %214 = add nuw nsw i32 %213, %75
  %215 = lshr i32 %214, 2
  %216 = trunc i32 %215 to i16
  %217 = add i64 %19, 8589934592
  %218 = ashr exact i64 %217, 32
  %219 = getelementptr inbounds i16, i16* %5, i64 %218
  store i16 %216, i16* %219, align 2
  %220 = add nsw i32 %196, 1
  %221 = sext i32 %220 to i64
  %222 = getelementptr inbounds i16, i16* %5, i64 %221
  store i16 %216, i16* %222, align 2
  %223 = mul nsw i32 %7, 5
  %224 = sext i32 %223 to i64
  %225 = getelementptr inbounds i16, i16* %5, i64 %224
  store i16 %216, i16* %225, align 2
  %226 = add nuw nsw i32 %65, 1
  %227 = add nuw nsw i32 %226, %75
  %228 = lshr i32 %227, 1
  %229 = trunc i32 %228 to i16
  %230 = getelementptr inbounds i8, i8* %0, i64 6
  %231 = bitcast i8* %230 to i16*
  store i16 %229, i16* %231, align 2
  %232 = add nsw i32 %184, 2
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds i16, i16* %5, i64 %233
  store i16 %229, i16* %234, align 2
  %235 = or i64 %210, 1
  %236 = getelementptr inbounds i16, i16* %5, i64 %235
  store i16 %229, i16* %236, align 2
  %237 = mul nsw i32 %7, 6
  %238 = sext i32 %237 to i64
  %239 = getelementptr inbounds i16, i16* %5, i64 %238
  store i16 %229, i16* %239, align 2
  %240 = shl nuw nsw i32 %75, 1
  %241 = add nuw nsw i32 %188, %240
  %242 = add nuw nsw i32 %241, %85
  %243 = lshr i32 %242, 2
  %244 = trunc i32 %243 to i16
  %245 = add i64 %19, 12884901888
  %246 = ashr exact i64 %245, 32
  %247 = getelementptr inbounds i16, i16* %5, i64 %246
  store i16 %244, i16* %247, align 2
  %248 = add nsw i32 %196, 2
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i16, i16* %5, i64 %249
  store i16 %244, i16* %250, align 2
  %251 = add nsw i32 %223, 1
  %252 = sext i32 %251 to i64
  %253 = getelementptr inbounds i16, i16* %5, i64 %252
  store i16 %244, i16* %253, align 2
  %254 = mul nsw i32 %7, 7
  %255 = sext i32 %254 to i64
  %256 = getelementptr inbounds i16, i16* %5, i64 %255
  store i16 %244, i16* %256, align 2
  %257 = add nuw nsw i32 %75, 1
  %258 = add nuw nsw i32 %257, %85
  %259 = lshr i32 %258, 1
  %260 = trunc i32 %259 to i16
  %261 = getelementptr inbounds i8, i8* %0, i64 8
  %262 = bitcast i8* %261 to i16*
  store i16 %260, i16* %262, align 2
  %263 = add nsw i32 %184, 3
  %264 = sext i32 %263 to i64
  %265 = getelementptr inbounds i16, i16* %5, i64 %264
  store i16 %260, i16* %265, align 2
  %266 = or i64 %210, 2
  %267 = getelementptr inbounds i16, i16* %5, i64 %266
  store i16 %260, i16* %267, align 2
  %268 = or i32 %237, 1
  %269 = sext i32 %268 to i64
  %270 = getelementptr inbounds i16, i16* %5, i64 %269
  store i16 %260, i16* %270, align 2
  %271 = shl nuw nsw i32 %85, 1
  %272 = add nuw nsw i32 %75, 2
  %273 = add nuw nsw i32 %272, %271
  %274 = add nuw nsw i32 %273, %95
  %275 = lshr i32 %274, 2
  %276 = trunc i32 %275 to i16
  %277 = add i64 %19, 17179869184
  %278 = ashr exact i64 %277, 32
  %279 = getelementptr inbounds i16, i16* %5, i64 %278
  store i16 %276, i16* %279, align 2
  %280 = add nsw i32 %196, 3
  %281 = sext i32 %280 to i64
  %282 = getelementptr inbounds i16, i16* %5, i64 %281
  store i16 %276, i16* %282, align 2
  %283 = add nsw i32 %223, 2
  %284 = sext i32 %283 to i64
  %285 = getelementptr inbounds i16, i16* %5, i64 %284
  store i16 %276, i16* %285, align 2
  %286 = add nsw i32 %254, 1
  %287 = sext i32 %286 to i64
  %288 = getelementptr inbounds i16, i16* %5, i64 %287
  store i16 %276, i16* %288, align 2
  %289 = add nuw nsw i32 %85, 1
  %290 = add nuw nsw i32 %289, %95
  %291 = lshr i32 %290, 1
  %292 = trunc i32 %291 to i16
  %293 = getelementptr inbounds i8, i8* %0, i64 10
  %294 = bitcast i8* %293 to i16*
  store i16 %292, i16* %294, align 2
  %295 = add nsw i32 %184, 4
  %296 = sext i32 %295 to i64
  %297 = getelementptr inbounds i16, i16* %5, i64 %296
  store i16 %292, i16* %297, align 2
  %298 = or i64 %210, 3
  %299 = getelementptr inbounds i16, i16* %5, i64 %298
  store i16 %292, i16* %299, align 2
  %300 = add nsw i32 %237, 2
  %301 = sext i32 %300 to i64
  %302 = getelementptr inbounds i16, i16* %5, i64 %301
  store i16 %292, i16* %302, align 2
  %303 = shl nuw nsw i32 %95, 1
  %304 = add nuw nsw i32 %85, 2
  %305 = add nuw nsw i32 %304, %303
  %306 = add nuw nsw i32 %305, %165
  %307 = lshr i32 %306, 2
  %308 = trunc i32 %307 to i16
  %309 = add i64 %19, 21474836480
  %310 = ashr exact i64 %309, 32
  %311 = getelementptr inbounds i16, i16* %5, i64 %310
  store i16 %308, i16* %311, align 2
  %312 = add nsw i32 %196, 4
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds i16, i16* %5, i64 %313
  store i16 %308, i16* %314, align 2
  %315 = add nsw i32 %223, 3
  %316 = sext i32 %315 to i64
  %317 = getelementptr inbounds i16, i16* %5, i64 %316
  store i16 %308, i16* %317, align 2
  %318 = add nsw i32 %254, 2
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %308, i16* %320, align 2
  %321 = add nuw nsw i32 %95, 1
  %322 = add nuw nsw i32 %321, %165
  %323 = lshr i32 %322, 1
  %324 = trunc i32 %323 to i16
  %325 = getelementptr inbounds i8, i8* %0, i64 12
  %326 = bitcast i8* %325 to i16*
  store i16 %324, i16* %326, align 2
  %327 = add nsw i32 %184, 5
  %328 = sext i32 %327 to i64
  %329 = getelementptr inbounds i16, i16* %5, i64 %328
  store i16 %324, i16* %329, align 2
  %330 = add i64 %209, 17179869184
  %331 = ashr exact i64 %330, 32
  %332 = getelementptr inbounds i16, i16* %5, i64 %331
  store i16 %324, i16* %332, align 2
  %333 = add nsw i32 %237, 3
  %334 = sext i32 %333 to i64
  %335 = getelementptr inbounds i16, i16* %5, i64 %334
  store i16 %324, i16* %335, align 2
  %336 = shl nuw nsw i32 %165, 1
  %337 = add nuw nsw i32 %95, 2
  %338 = add nuw nsw i32 %337, %158
  %339 = add nuw nsw i32 %338, %336
  %340 = lshr i32 %339, 2
  %341 = trunc i32 %340 to i16
  %342 = add i64 %19, 25769803776
  %343 = ashr exact i64 %342, 32
  %344 = getelementptr inbounds i16, i16* %5, i64 %343
  store i16 %341, i16* %344, align 2
  %345 = add nsw i32 %196, 5
  %346 = sext i32 %345 to i64
  %347 = getelementptr inbounds i16, i16* %5, i64 %346
  store i16 %341, i16* %347, align 2
  %348 = add nsw i32 %223, 4
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i16, i16* %5, i64 %349
  store i16 %341, i16* %350, align 2
  %351 = add nsw i32 %254, 3
  %352 = sext i32 %351 to i64
  %353 = getelementptr inbounds i16, i16* %5, i64 %352
  store i16 %341, i16* %353, align 2
  %354 = add nuw nsw i32 %158, 1
  %355 = add nuw nsw i32 %354, %165
  %356 = lshr i32 %355, 1
  %357 = trunc i32 %356 to i16
  %358 = getelementptr inbounds i8, i8* %0, i64 14
  %359 = bitcast i8* %358 to i16*
  store i16 %357, i16* %359, align 2
  %360 = add nsw i32 %184, 6
  %361 = sext i32 %360 to i64
  %362 = getelementptr inbounds i16, i16* %5, i64 %361
  store i16 %357, i16* %362, align 2
  %363 = add i64 %209, 21474836480
  %364 = ashr exact i64 %363, 32
  %365 = getelementptr inbounds i16, i16* %5, i64 %364
  store i16 %357, i16* %365, align 2
  %366 = add nsw i32 %237, 4
  %367 = sext i32 %366 to i64
  %368 = getelementptr inbounds i16, i16* %5, i64 %367
  store i16 %357, i16* %368, align 2
  %369 = shl nuw nsw i32 %158, 1
  %370 = add nuw nsw i32 %165, 2
  %371 = add nuw nsw i32 %370, %159
  %372 = add nuw nsw i32 %371, %369
  %373 = lshr i32 %372, 2
  %374 = trunc i32 %373 to i16
  %375 = add i64 %19, 30064771072
  %376 = ashr exact i64 %375, 32
  %377 = getelementptr inbounds i16, i16* %5, i64 %376
  store i16 %374, i16* %377, align 2
  %378 = add nsw i32 %196, 6
  %379 = sext i32 %378 to i64
  %380 = getelementptr inbounds i16, i16* %5, i64 %379
  store i16 %374, i16* %380, align 2
  %381 = add nsw i32 %223, 5
  %382 = sext i32 %381 to i64
  %383 = getelementptr inbounds i16, i16* %5, i64 %382
  store i16 %374, i16* %383, align 2
  %384 = add nsw i32 %254, 4
  %385 = sext i32 %384 to i64
  %386 = getelementptr inbounds i16, i16* %5, i64 %385
  store i16 %374, i16* %386, align 2
  %387 = add nuw nsw i32 %354, %159
  %388 = lshr i32 %387, 1
  %389 = trunc i32 %388 to i16
  %390 = add nsw i32 %184, 7
  %391 = sext i32 %390 to i64
  %392 = getelementptr inbounds i16, i16* %5, i64 %391
  store i16 %389, i16* %392, align 2
  %393 = add i64 %209, 25769803776
  %394 = ashr exact i64 %393, 32
  %395 = getelementptr inbounds i16, i16* %5, i64 %394
  store i16 %389, i16* %395, align 2
  %396 = add nsw i32 %237, 5
  %397 = sext i32 %396 to i64
  %398 = getelementptr inbounds i16, i16* %5, i64 %397
  store i16 %389, i16* %398, align 2
  %399 = shl nuw nsw i32 %159, 1
  %400 = add nuw nsw i32 %158, 2
  %401 = add nuw nsw i32 %400, %399
  %402 = add nuw nsw i32 %401, %160
  %403 = lshr i32 %402, 2
  %404 = trunc i32 %403 to i16
  %405 = add nsw i32 %196, 7
  %406 = sext i32 %405 to i64
  %407 = getelementptr inbounds i16, i16* %5, i64 %406
  store i16 %404, i16* %407, align 2
  %408 = add nsw i32 %223, 6
  %409 = sext i32 %408 to i64
  %410 = getelementptr inbounds i16, i16* %5, i64 %409
  store i16 %404, i16* %410, align 2
  %411 = add nsw i32 %254, 5
  %412 = sext i32 %411 to i64
  %413 = getelementptr inbounds i16, i16* %5, i64 %412
  store i16 %404, i16* %413, align 2
  %414 = add nuw nsw i32 %159, 1
  %415 = add nuw nsw i32 %414, %160
  %416 = lshr i32 %415, 1
  %417 = trunc i32 %416 to i16
  %418 = add i64 %209, 30064771072
  %419 = ashr exact i64 %418, 32
  %420 = getelementptr inbounds i16, i16* %5, i64 %419
  store i16 %417, i16* %420, align 2
  %421 = add nsw i32 %237, 6
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds i16, i16* %5, i64 %422
  store i16 %417, i16* %423, align 2
  %424 = shl nuw nsw i32 %160, 1
  %425 = add nuw nsw i32 %159, 2
  %426 = add nuw nsw i32 %425, %424
  %427 = add nuw nsw i32 %426, %161
  %428 = lshr i32 %427, 2
  %429 = trunc i32 %428 to i16
  %430 = add nsw i32 %223, 7
  %431 = sext i32 %430 to i64
  %432 = getelementptr inbounds i16, i16* %5, i64 %431
  store i16 %429, i16* %432, align 2
  %433 = add nsw i32 %254, 6
  %434 = sext i32 %433 to i64
  %435 = getelementptr inbounds i16, i16* %5, i64 %434
  store i16 %429, i16* %435, align 2
  %436 = add nuw nsw i32 %160, 1
  %437 = add nuw nsw i32 %436, %161
  %438 = lshr i32 %437, 1
  %439 = trunc i32 %438 to i16
  %440 = add nsw i32 %237, 7
  %441 = sext i32 %440 to i64
  %442 = getelementptr inbounds i16, i16* %5, i64 %441
  store i16 %439, i16* %442, align 2
  %443 = shl nuw nsw i32 %161, 1
  %444 = add nuw nsw i32 %160, 2
  %445 = add nuw nsw i32 %444, %443
  %446 = add nuw nsw i32 %445, %162
  %447 = lshr i32 %446, 2
  %448 = trunc i32 %447 to i16
  %449 = add nsw i32 %254, 7
  %450 = sext i32 %449 to i64
  %451 = getelementptr inbounds i16, i16* %5, i64 %450
  store i16 %448, i16* %451, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_up_10_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  br i1 %8, label %14, label %9

9:                                                ; preds = %4
  %10 = shl i64 %6, 32
  %11 = ashr exact i64 %10, 32
  %12 = xor i64 %11, -1
  %13 = getelementptr inbounds i16, i16* %5, i64 %12
  br label %19

14:                                               ; preds = %4
  %15 = getelementptr inbounds i8, i8* %0, i64 -2
  %16 = bitcast i8* %15 to i16*
  %17 = shl i64 %6, 32
  %18 = ashr exact i64 %17, 32
  br label %19

19:                                               ; preds = %14, %9
  %20 = phi i64 [ %18, %14 ], [ %11, %9 ]
  %21 = phi i64 [ %17, %14 ], [ %10, %9 ]
  %22 = phi i16* [ %16, %14 ], [ %13, %9 ]
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i8, i8* %0, i64 -2
  %26 = bitcast i8* %25 to i16*
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = shl nuw nsw i32 %28, 1
  %30 = add i64 %21, -4294967296
  %31 = ashr exact i64 %30, 32
  %32 = getelementptr inbounds i16, i16* %5, i64 %31
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = add nuw nsw i32 %34, 2
  %36 = add nuw nsw i32 %35, %24
  %37 = add nuw nsw i32 %36, %29
  %38 = lshr i32 %37, 2
  %39 = shl nuw nsw i32 %34, 1
  %40 = trunc i64 %3 to i32
  %41 = and i32 %40, -2
  %42 = add nsw i32 %41, -1
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i16, i16* %5, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %28
  %49 = add nuw nsw i32 %48, %39
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = mul nsw i32 %7, 3
  %53 = add nsw i32 %52, -1
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i16, i16* %5, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i32
  %58 = add nuw nsw i32 %35, %51
  %59 = add nuw nsw i32 %58, %57
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %57, 1
  %62 = shl i64 %6, 34
  %63 = add i64 %62, -4294967296
  %64 = ashr exact i64 %63, 32
  %65 = getelementptr inbounds i16, i16* %5, i64 %64
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = add nuw nsw i32 %47, %61
  %69 = add nuw nsw i32 %68, %67
  %70 = lshr i32 %69, 2
  %71 = shl nuw nsw i32 %67, 1
  %72 = mul nsw i32 %7, 5
  %73 = add nsw i32 %72, -1
  %74 = sext i32 %73 to i64
  %75 = getelementptr inbounds i16, i16* %5, i64 %74
  %76 = load i16, i16* %75, align 2
  %77 = zext i16 %76 to i32
  %78 = add nuw nsw i32 %57, 2
  %79 = add nuw nsw i32 %78, %71
  %80 = add nuw nsw i32 %79, %77
  %81 = lshr i32 %80, 2
  %82 = shl nuw nsw i32 %77, 1
  %83 = mul nsw i32 %7, 6
  %84 = add nsw i32 %83, -1
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i16, i16* %5, i64 %85
  %87 = load i16, i16* %86, align 2
  %88 = zext i16 %87 to i32
  %89 = add nuw nsw i32 %67, 2
  %90 = add nuw nsw i32 %89, %82
  %91 = add nuw nsw i32 %90, %88
  %92 = lshr i32 %91, 2
  %93 = shl nuw nsw i32 %88, 1
  %94 = mul nsw i32 %7, 7
  %95 = add nsw i32 %94, -1
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %5, i64 %96
  %98 = load i16, i16* %97, align 2
  %99 = zext i16 %98 to i32
  %100 = add nuw nsw i32 %77, 2
  %101 = add nuw nsw i32 %100, %93
  %102 = add nuw nsw i32 %101, %99
  %103 = lshr i32 %102, 2
  %104 = mul nuw nsw i32 %99, 3
  %105 = add nuw nsw i32 %88, 2
  %106 = add nuw nsw i32 %105, %104
  %107 = lshr i32 %106, 2
  %108 = add nuw nsw i32 %50, 1
  %109 = add nuw nsw i32 %108, %38
  %110 = lshr i32 %109, 1
  %111 = trunc i32 %110 to i16
  store i16 %111, i16* %5, align 2
  %112 = shl nuw nsw i32 %50, 1
  %113 = add nuw nsw i32 %60, 2
  %114 = add nuw nsw i32 %113, %38
  %115 = add nuw nsw i32 %114, %112
  %116 = lshr i32 %115, 2
  %117 = trunc i32 %116 to i16
  %118 = getelementptr inbounds i8, i8* %0, i64 2
  %119 = bitcast i8* %118 to i16*
  store i16 %117, i16* %119, align 2
  %120 = add nuw nsw i32 %108, %60
  %121 = lshr i32 %120, 1
  %122 = trunc i32 %121 to i16
  %123 = getelementptr inbounds i8, i8* %0, i64 4
  %124 = bitcast i8* %123 to i16*
  store i16 %122, i16* %124, align 2
  %125 = getelementptr inbounds i16, i16* %5, i64 %20
  store i16 %122, i16* %125, align 2
  %126 = shl nuw nsw i32 %60, 1
  %127 = add nuw nsw i32 %70, 2
  %128 = add nuw nsw i32 %127, %50
  %129 = add nuw nsw i32 %128, %126
  %130 = lshr i32 %129, 2
  %131 = trunc i32 %130 to i16
  %132 = getelementptr inbounds i8, i8* %0, i64 6
  %133 = bitcast i8* %132 to i16*
  store i16 %131, i16* %133, align 2
  %134 = add i64 %21, 4294967296
  %135 = ashr exact i64 %134, 32
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  store i16 %131, i16* %136, align 2
  %137 = add nuw nsw i32 %60, 1
  %138 = add nuw nsw i32 %137, %70
  %139 = lshr i32 %138, 1
  %140 = trunc i32 %139 to i16
  %141 = getelementptr inbounds i8, i8* %0, i64 8
  %142 = bitcast i8* %141 to i16*
  store i16 %140, i16* %142, align 2
  %143 = add i64 %21, 8589934592
  %144 = ashr exact i64 %143, 32
  %145 = getelementptr inbounds i16, i16* %5, i64 %144
  store i16 %140, i16* %145, align 2
  %146 = sext i32 %41 to i64
  %147 = getelementptr inbounds i16, i16* %5, i64 %146
  store i16 %140, i16* %147, align 2
  %148 = shl nuw nsw i32 %70, 1
  %149 = add nuw nsw i32 %113, %148
  %150 = add nuw nsw i32 %149, %81
  %151 = lshr i32 %150, 2
  %152 = trunc i32 %151 to i16
  %153 = getelementptr inbounds i8, i8* %0, i64 10
  %154 = bitcast i8* %153 to i16*
  store i16 %152, i16* %154, align 2
  %155 = add i64 %21, 12884901888
  %156 = ashr exact i64 %155, 32
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  store i16 %152, i16* %157, align 2
  %158 = shl i64 %3, 32
  %159 = ashr exact i64 %158, 32
  %160 = or i64 %159, 1
  %161 = getelementptr inbounds i16, i16* %5, i64 %160
  store i16 %152, i16* %161, align 2
  %162 = add nuw nsw i32 %70, 1
  %163 = add nuw nsw i32 %162, %81
  %164 = lshr i32 %163, 1
  %165 = trunc i32 %164 to i16
  %166 = getelementptr inbounds i8, i8* %0, i64 12
  %167 = bitcast i8* %166 to i16*
  store i16 %165, i16* %167, align 2
  %168 = add i64 %21, 17179869184
  %169 = ashr exact i64 %168, 32
  %170 = getelementptr inbounds i16, i16* %5, i64 %169
  store i16 %165, i16* %170, align 2
  %171 = add nsw i32 %41, 2
  %172 = sext i32 %171 to i64
  %173 = getelementptr inbounds i16, i16* %5, i64 %172
  store i16 %165, i16* %173, align 2
  %174 = sext i32 %52 to i64
  %175 = getelementptr inbounds i16, i16* %5, i64 %174
  store i16 %165, i16* %175, align 2
  %176 = shl nuw nsw i32 %81, 1
  %177 = add nuw nsw i32 %127, %176
  %178 = add nuw nsw i32 %177, %92
  %179 = lshr i32 %178, 2
  %180 = trunc i32 %179 to i16
  %181 = getelementptr inbounds i8, i8* %0, i64 14
  %182 = bitcast i8* %181 to i16*
  store i16 %180, i16* %182, align 2
  %183 = add i64 %21, 21474836480
  %184 = ashr exact i64 %183, 32
  %185 = getelementptr inbounds i16, i16* %5, i64 %184
  store i16 %180, i16* %185, align 2
  %186 = add nsw i32 %41, 3
  %187 = sext i32 %186 to i64
  %188 = getelementptr inbounds i16, i16* %5, i64 %187
  store i16 %180, i16* %188, align 2
  %189 = add nsw i32 %52, 1
  %190 = sext i32 %189 to i64
  %191 = getelementptr inbounds i16, i16* %5, i64 %190
  store i16 %180, i16* %191, align 2
  %192 = add nuw nsw i32 %81, 1
  %193 = add nuw nsw i32 %192, %92
  %194 = lshr i32 %193, 1
  %195 = trunc i32 %194 to i16
  %196 = add i64 %21, 25769803776
  %197 = ashr exact i64 %196, 32
  %198 = getelementptr inbounds i16, i16* %5, i64 %197
  store i16 %195, i16* %198, align 2
  %199 = add nsw i32 %41, 4
  %200 = sext i32 %199 to i64
  %201 = getelementptr inbounds i16, i16* %5, i64 %200
  store i16 %195, i16* %201, align 2
  %202 = add nsw i32 %52, 2
  %203 = sext i32 %202 to i64
  %204 = getelementptr inbounds i16, i16* %5, i64 %203
  store i16 %195, i16* %204, align 2
  %205 = ashr exact i64 %62, 32
  %206 = getelementptr inbounds i16, i16* %5, i64 %205
  store i16 %195, i16* %206, align 2
  %207 = shl nuw nsw i32 %92, 1
  %208 = add nuw nsw i32 %81, 2
  %209 = add nuw nsw i32 %208, %207
  %210 = add nuw nsw i32 %209, %103
  %211 = lshr i32 %210, 2
  %212 = trunc i32 %211 to i16
  %213 = add i64 %21, 30064771072
  %214 = ashr exact i64 %213, 32
  %215 = getelementptr inbounds i16, i16* %5, i64 %214
  store i16 %212, i16* %215, align 2
  %216 = add nsw i32 %41, 5
  %217 = sext i32 %216 to i64
  %218 = getelementptr inbounds i16, i16* %5, i64 %217
  store i16 %212, i16* %218, align 2
  %219 = add nsw i32 %52, 3
  %220 = sext i32 %219 to i64
  %221 = getelementptr inbounds i16, i16* %5, i64 %220
  store i16 %212, i16* %221, align 2
  %222 = or i64 %205, 1
  %223 = getelementptr inbounds i16, i16* %5, i64 %222
  store i16 %212, i16* %223, align 2
  %224 = add nuw nsw i32 %92, 1
  %225 = add nuw nsw i32 %224, %103
  %226 = lshr i32 %225, 1
  %227 = trunc i32 %226 to i16
  %228 = add nsw i32 %41, 6
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds i16, i16* %5, i64 %229
  store i16 %227, i16* %230, align 2
  %231 = add nsw i32 %52, 4
  %232 = sext i32 %231 to i64
  %233 = getelementptr inbounds i16, i16* %5, i64 %232
  store i16 %227, i16* %233, align 2
  %234 = or i64 %205, 2
  %235 = getelementptr inbounds i16, i16* %5, i64 %234
  store i16 %227, i16* %235, align 2
  %236 = sext i32 %72 to i64
  %237 = getelementptr inbounds i16, i16* %5, i64 %236
  store i16 %227, i16* %237, align 2
  %238 = shl nuw nsw i32 %103, 1
  %239 = add nuw nsw i32 %92, 2
  %240 = add nuw nsw i32 %239, %107
  %241 = add nuw nsw i32 %240, %238
  %242 = lshr i32 %241, 2
  %243 = trunc i32 %242 to i16
  %244 = add nsw i32 %41, 7
  %245 = sext i32 %244 to i64
  %246 = getelementptr inbounds i16, i16* %5, i64 %245
  store i16 %243, i16* %246, align 2
  %247 = add nsw i32 %52, 5
  %248 = sext i32 %247 to i64
  %249 = getelementptr inbounds i16, i16* %5, i64 %248
  store i16 %243, i16* %249, align 2
  %250 = or i64 %205, 3
  %251 = getelementptr inbounds i16, i16* %5, i64 %250
  store i16 %243, i16* %251, align 2
  %252 = add nsw i32 %72, 1
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i16, i16* %5, i64 %253
  store i16 %243, i16* %254, align 2
  %255 = add nuw nsw i32 %103, 1
  %256 = add nuw nsw i32 %255, %107
  %257 = lshr i32 %256, 1
  %258 = trunc i32 %257 to i16
  %259 = add nsw i32 %52, 6
  %260 = sext i32 %259 to i64
  %261 = getelementptr inbounds i16, i16* %5, i64 %260
  store i16 %258, i16* %261, align 2
  %262 = add i64 %62, 17179869184
  %263 = ashr exact i64 %262, 32
  %264 = getelementptr inbounds i16, i16* %5, i64 %263
  store i16 %258, i16* %264, align 2
  %265 = add nsw i32 %72, 2
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds i16, i16* %5, i64 %266
  store i16 %258, i16* %267, align 2
  %268 = sext i32 %83 to i64
  %269 = getelementptr inbounds i16, i16* %5, i64 %268
  store i16 %258, i16* %269, align 2
  %270 = mul nuw nsw i32 %107, 3
  %271 = add nuw nsw i32 %103, 2
  %272 = add nuw nsw i32 %271, %270
  %273 = lshr i32 %272, 2
  %274 = trunc i32 %273 to i16
  %275 = add nsw i32 %52, 7
  %276 = sext i32 %275 to i64
  %277 = getelementptr inbounds i16, i16* %5, i64 %276
  store i16 %274, i16* %277, align 2
  %278 = add i64 %62, 21474836480
  %279 = ashr exact i64 %278, 32
  %280 = getelementptr inbounds i16, i16* %5, i64 %279
  store i16 %274, i16* %280, align 2
  %281 = add nsw i32 %72, 3
  %282 = sext i32 %281 to i64
  %283 = getelementptr inbounds i16, i16* %5, i64 %282
  store i16 %274, i16* %283, align 2
  %284 = or i32 %83, 1
  %285 = sext i32 %284 to i64
  %286 = getelementptr inbounds i16, i16* %5, i64 %285
  store i16 %274, i16* %286, align 2
  %287 = trunc i32 %107 to i16
  %288 = add nsw i32 %94, 7
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds i16, i16* %5, i64 %289
  store i16 %287, i16* %290, align 2
  %291 = add nsw i32 %83, 7
  %292 = sext i32 %291 to i64
  %293 = getelementptr inbounds i16, i16* %5, i64 %292
  store i16 %287, i16* %293, align 2
  %294 = add nsw i32 %72, 7
  %295 = sext i32 %294 to i64
  %296 = getelementptr inbounds i16, i16* %5, i64 %295
  store i16 %287, i16* %296, align 2
  %297 = add i64 %62, 30064771072
  %298 = ashr exact i64 %297, 32
  %299 = getelementptr inbounds i16, i16* %5, i64 %298
  store i16 %287, i16* %299, align 2
  %300 = add nsw i32 %94, 6
  %301 = sext i32 %300 to i64
  %302 = getelementptr inbounds i16, i16* %5, i64 %301
  store i16 %287, i16* %302, align 2
  %303 = add nsw i32 %83, 6
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds i16, i16* %5, i64 %304
  store i16 %287, i16* %305, align 2
  %306 = add nsw i32 %72, 6
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i16, i16* %5, i64 %307
  store i16 %287, i16* %308, align 2
  %309 = add i64 %62, 25769803776
  %310 = ashr exact i64 %309, 32
  %311 = getelementptr inbounds i16, i16* %5, i64 %310
  store i16 %287, i16* %311, align 2
  %312 = add nsw i32 %94, 5
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds i16, i16* %5, i64 %313
  store i16 %287, i16* %314, align 2
  %315 = add nsw i32 %83, 5
  %316 = sext i32 %315 to i64
  %317 = getelementptr inbounds i16, i16* %5, i64 %316
  store i16 %287, i16* %317, align 2
  %318 = add nsw i32 %72, 5
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %287, i16* %320, align 2
  %321 = add nsw i32 %94, 4
  %322 = sext i32 %321 to i64
  %323 = getelementptr inbounds i16, i16* %5, i64 %322
  store i16 %287, i16* %323, align 2
  %324 = add nsw i32 %83, 4
  %325 = sext i32 %324 to i64
  %326 = getelementptr inbounds i16, i16* %5, i64 %325
  store i16 %287, i16* %326, align 2
  %327 = add nsw i32 %72, 4
  %328 = sext i32 %327 to i64
  %329 = getelementptr inbounds i16, i16* %5, i64 %328
  store i16 %287, i16* %329, align 2
  %330 = add nsw i32 %94, 3
  %331 = sext i32 %330 to i64
  %332 = getelementptr inbounds i16, i16* %5, i64 %331
  store i16 %287, i16* %332, align 2
  %333 = add nsw i32 %83, 3
  %334 = sext i32 %333 to i64
  %335 = getelementptr inbounds i16, i16* %5, i64 %334
  store i16 %287, i16* %335, align 2
  %336 = add nsw i32 %94, 2
  %337 = sext i32 %336 to i64
  %338 = getelementptr inbounds i16, i16* %5, i64 %337
  store i16 %287, i16* %338, align 2
  %339 = add nsw i32 %83, 2
  %340 = sext i32 %339 to i64
  %341 = getelementptr inbounds i16, i16* %5, i64 %340
  store i16 %287, i16* %341, align 2
  %342 = add nsw i32 %94, 1
  %343 = sext i32 %342 to i64
  %344 = getelementptr inbounds i16, i16* %5, i64 %343
  store i16 %287, i16* %344, align 2
  %345 = sext i32 %94 to i64
  %346 = getelementptr inbounds i16, i16* %5, i64 %345
  store i16 %287, i16* %346, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_left_dc_10_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = icmp eq i32 %1, 0
  br i1 %7, label %13, label %8

8:                                                ; preds = %4
  %9 = shl i64 %6, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = getelementptr inbounds i16, i16* %5, i64 %11
  br label %18

13:                                               ; preds = %4
  %14 = getelementptr inbounds i8, i8* %0, i64 -2
  %15 = bitcast i8* %14 to i16*
  %16 = shl i64 %6, 32
  %17 = ashr exact i64 %16, 32
  br label %18

18:                                               ; preds = %13, %8
  %19 = phi i64 [ %17, %13 ], [ %10, %8 ]
  %20 = phi i64 [ %16, %13 ], [ %9, %8 ]
  %21 = phi i16* [ %15, %13 ], [ %12, %8 ]
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = getelementptr inbounds i8, i8* %0, i64 -2
  %25 = bitcast i8* %24 to i16*
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = add i64 %20, -4294967296
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %23
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = shl i64 %3, 32
  %40 = and i64 %39, -8589934592
  %41 = add i64 %40, -4294967296
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds i16, i16* %5, i64 %42
  %44 = load i16, i16* %43, align 2
  %45 = zext i16 %44 to i32
  %46 = add nuw nsw i32 %45, 2
  %47 = add nuw nsw i32 %46, %27
  %48 = add nuw nsw i32 %47, %38
  %49 = lshr i32 %48, 2
  %50 = shl nuw nsw i32 %45, 1
  %51 = mul i64 %6, 12884901888
  %52 = add i64 %51, -4294967296
  %53 = ashr exact i64 %52, 32
  %54 = getelementptr inbounds i16, i16* %5, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i32
  %57 = add nuw nsw i32 %34, %50
  %58 = add nuw nsw i32 %57, %56
  %59 = lshr i32 %58, 2
  %60 = shl nuw nsw i32 %56, 1
  %61 = shl i64 %6, 34
  %62 = add i64 %61, -4294967296
  %63 = ashr exact i64 %62, 32
  %64 = getelementptr inbounds i16, i16* %5, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i32
  %67 = add nuw nsw i32 %46, %60
  %68 = add nuw nsw i32 %67, %66
  %69 = lshr i32 %68, 2
  %70 = shl nuw nsw i32 %66, 1
  %71 = mul i64 %6, 21474836480
  %72 = add i64 %71, -4294967296
  %73 = ashr exact i64 %72, 32
  %74 = getelementptr inbounds i16, i16* %5, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i32
  %77 = add nuw nsw i32 %56, 2
  %78 = add nuw nsw i32 %77, %70
  %79 = add nuw nsw i32 %78, %76
  %80 = lshr i32 %79, 2
  %81 = shl nuw nsw i32 %76, 1
  %82 = mul i64 %6, 25769803776
  %83 = add i64 %82, -4294967296
  %84 = ashr exact i64 %83, 32
  %85 = getelementptr inbounds i16, i16* %5, i64 %84
  %86 = load i16, i16* %85, align 2
  %87 = zext i16 %86 to i32
  %88 = add nuw nsw i32 %66, 2
  %89 = add nuw nsw i32 %88, %81
  %90 = add nuw nsw i32 %89, %87
  %91 = lshr i32 %90, 2
  %92 = shl nuw nsw i32 %87, 1
  %93 = mul i64 %6, 30064771072
  %94 = add i64 %93, -4294967296
  %95 = ashr exact i64 %94, 32
  %96 = getelementptr inbounds i16, i16* %5, i64 %95
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i32
  %99 = add nuw nsw i32 %76, 2
  %100 = add nuw nsw i32 %99, %92
  %101 = add nuw nsw i32 %100, %98
  %102 = lshr i32 %101, 2
  %103 = mul nuw nsw i32 %98, 3
  %104 = add nuw nsw i32 %87, 2
  %105 = add nuw nsw i32 %104, %103
  %106 = lshr i32 %105, 2
  %107 = add nuw nsw i32 %37, 4
  %108 = add nuw nsw i32 %107, %49
  %109 = add nuw nsw i32 %108, %59
  %110 = add nuw nsw i32 %109, %69
  %111 = add nuw nsw i32 %110, %80
  %112 = add nuw nsw i32 %111, %91
  %113 = add nuw nsw i32 %112, %106
  %114 = add nuw nsw i32 %113, %102
  %115 = ashr i32 %114, 3
  %116 = sext i32 %115 to i64
  %117 = mul i64 %116, 281479271743489
  %118 = bitcast i8* %0 to i64*
  store i64 %117, i64* %118, align 8
  %119 = getelementptr inbounds i8, i8* %0, i64 8
  %120 = bitcast i8* %119 to i64*
  store i64 %117, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %5, i64 %19
  %122 = bitcast i16* %121 to i64*
  store i64 %117, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %121, i64 4
  %124 = bitcast i16* %123 to i64*
  store i64 %117, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %121, i64 %19
  %126 = bitcast i16* %125 to i64*
  store i64 %117, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %125, i64 4
  %128 = bitcast i16* %127 to i64*
  store i64 %117, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %125, i64 %19
  %130 = bitcast i16* %129 to i64*
  store i64 %117, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %129, i64 4
  %132 = bitcast i16* %131 to i64*
  store i64 %117, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %129, i64 %19
  %134 = bitcast i16* %133 to i64*
  store i64 %117, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %133, i64 4
  %136 = bitcast i16* %135 to i64*
  store i64 %117, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %133, i64 %19
  %138 = bitcast i16* %137 to i64*
  store i64 %117, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %137, i64 4
  %140 = bitcast i16* %139 to i64*
  store i64 %117, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %137, i64 %19
  %142 = bitcast i16* %141 to i64*
  store i64 %117, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %117, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %141, i64 %19
  %146 = bitcast i16* %145 to i64*
  store i64 %117, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %145, i64 4
  %148 = bitcast i16* %147 to i64*
  store i64 %117, i64* %148, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_top_dc_10_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %103, label %97

97:                                               ; preds = %18
  %98 = sub i64 34359738368, %19
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i16, i16* %5, i64 %99
  %101 = load i16, i16* %100, align 2
  %102 = zext i16 %101 to i32
  br label %103

103:                                              ; preds = %18, %97
  %104 = phi i32 [ %102, %97 ], [ %91, %18 ]
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %81, 2
  %107 = add nuw nsw i32 %106, %105
  %108 = add nuw nsw i32 %107, %104
  %109 = lshr i32 %108, 2
  %110 = add nuw nsw i32 %37, 4
  %111 = add nuw nsw i32 %110, %47
  %112 = add nuw nsw i32 %111, %56
  %113 = add nuw nsw i32 %112, %65
  %114 = add nuw nsw i32 %113, %75
  %115 = add nuw nsw i32 %114, %85
  %116 = add nuw nsw i32 %115, %95
  %117 = add nuw nsw i32 %116, %109
  %118 = ashr i32 %117, 3
  %119 = sext i32 %118 to i64
  %120 = mul i64 %119, 281479271743489
  %121 = ashr exact i64 %19, 32
  %122 = bitcast i8* %0 to i64*
  store i64 %120, i64* %122, align 8
  %123 = getelementptr inbounds i8, i8* %0, i64 8
  %124 = bitcast i8* %123 to i64*
  store i64 %120, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %5, i64 %121
  %126 = bitcast i16* %125 to i64*
  store i64 %120, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %125, i64 4
  %128 = bitcast i16* %127 to i64*
  store i64 %120, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %125, i64 %121
  %130 = bitcast i16* %129 to i64*
  store i64 %120, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %129, i64 4
  %132 = bitcast i16* %131 to i64*
  store i64 %120, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %129, i64 %121
  %134 = bitcast i16* %133 to i64*
  store i64 %120, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %133, i64 4
  %136 = bitcast i16* %135 to i64*
  store i64 %120, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %133, i64 %121
  %138 = bitcast i16* %137 to i64*
  store i64 %120, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %137, i64 4
  %140 = bitcast i16* %139 to i64*
  store i64 %120, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %137, i64 %121
  %142 = bitcast i16* %141 to i64*
  store i64 %120, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %120, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %141, i64 %121
  %146 = bitcast i16* %145 to i64*
  store i64 %120, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %145, i64 4
  %148 = bitcast i16* %147 to i64*
  store i64 %120, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %145, i64 %121
  %150 = bitcast i16* %149 to i64*
  store i64 %120, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %149, i64 4
  %152 = bitcast i16* %151 to i64*
  store i64 %120, i64* %152, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8l_128_dc_10_c(i8* nocapture, i32, i32, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = shl i64 %3, 31
  %7 = ashr i64 %6, 32
  %8 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %8, align 8
  %9 = getelementptr inbounds i16, i16* %5, i64 %7
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %10, align 8
  %11 = getelementptr inbounds i16, i16* %9, i64 %7
  %12 = bitcast i16* %11 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %12, align 8
  %13 = getelementptr inbounds i16, i16* %11, i64 %7
  %14 = bitcast i16* %13 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %14, align 8
  %15 = getelementptr inbounds i16, i16* %13, i64 %7
  %16 = bitcast i16* %15 to i64*
  store i64 144117387132666368, i64* %16, align 8
  %17 = getelementptr inbounds i16, i16* %15, i64 4
  %18 = bitcast i16* %17 to i64*
  store i64 144117387132666368, i64* %18, align 8
  %19 = getelementptr inbounds i16, i16* %15, i64 %7
  %20 = bitcast i16* %19 to i64*
  store i64 144117387132666368, i64* %20, align 8
  %21 = getelementptr inbounds i16, i16* %19, i64 4
  %22 = bitcast i16* %21 to i64*
  store i64 144117387132666368, i64* %22, align 8
  %23 = getelementptr inbounds i16, i16* %19, i64 %7
  %24 = bitcast i16* %23 to i64*
  store i64 144117387132666368, i64* %24, align 8
  %25 = getelementptr inbounds i16, i16* %23, i64 4
  %26 = bitcast i16* %25 to i64*
  store i64 144117387132666368, i64* %26, align 8
  %27 = getelementptr inbounds i16, i16* %23, i64 %7
  %28 = bitcast i16* %27 to i64*
  store i64 144117387132666368, i64* %28, align 8
  %29 = getelementptr inbounds i16, i16* %27, i64 4
  %30 = bitcast i16* %29 to i64*
  store i64 144117387132666368, i64* %30, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_vertical_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds i16, i16* %8, i64 4
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = shl i64 %4, 32
  %15 = ashr exact i64 %14, 32
  %16 = bitcast i8* %0 to i64*
  store i64 %10, i64* %16, align 8
  %17 = getelementptr inbounds i8, i8* %0, i64 8
  %18 = bitcast i8* %17 to i64*
  store i64 %13, i64* %18, align 8
  %19 = getelementptr inbounds i16, i16* %3, i64 %15
  %20 = bitcast i16* %19 to i64*
  store i64 %10, i64* %20, align 8
  %21 = getelementptr inbounds i16, i16* %19, i64 4
  %22 = bitcast i16* %21 to i64*
  store i64 %13, i64* %22, align 8
  %23 = ashr exact i64 %14, 31
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to i64*
  store i64 %10, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %24, i64 4
  %27 = bitcast i16* %26 to i64*
  store i64 %13, i64* %27, align 8
  %28 = mul nsw i64 %15, 3
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = bitcast i16* %29 to i64*
  store i64 %10, i64* %30, align 8
  %31 = getelementptr inbounds i16, i16* %29, i64 4
  %32 = bitcast i16* %31 to i64*
  store i64 %13, i64* %32, align 8
  %33 = ashr exact i64 %14, 30
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %10, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %34, i64 4
  %37 = bitcast i16* %36 to i64*
  store i64 %13, i64* %37, align 8
  %38 = mul nsw i64 %15, 5
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %10, i64* %40, align 8
  %41 = getelementptr inbounds i16, i16* %39, i64 4
  %42 = bitcast i16* %41 to i64*
  store i64 %13, i64* %42, align 8
  %43 = mul nsw i64 %15, 6
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %10, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 %13, i64* %47, align 8
  %48 = mul nsw i64 %15, 7
  %49 = getelementptr inbounds i16, i16* %3, i64 %48
  %50 = bitcast i16* %49 to i64*
  store i64 %10, i64* %50, align 8
  %51 = getelementptr inbounds i16, i16* %49, i64 4
  %52 = bitcast i16* %51 to i64*
  store i64 %13, i64* %52, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_horizontal_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = mul nuw i64 %8, 281479271743489
  %10 = bitcast i8* %0 to i64*
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to i64*
  store i64 %9, i64* %12, align 8
  %13 = add nsw i64 %4, -1
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = mul nuw i64 %16, 281479271743489
  %18 = getelementptr inbounds i16, i16* %3, i64 %4
  %19 = bitcast i16* %18 to i64*
  store i64 %17, i64* %19, align 8
  %20 = getelementptr inbounds i16, i16* %18, i64 4
  %21 = bitcast i16* %20 to i64*
  store i64 %17, i64* %21, align 8
  %22 = and i64 %1, -2
  %23 = add nsw i64 %22, -1
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = mul nuw i64 %26, 281479271743489
  %28 = getelementptr inbounds i16, i16* %3, i64 %22
  %29 = bitcast i16* %28 to i64*
  store i64 %27, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 %27, i64* %31, align 8
  %32 = mul nsw i64 %4, 3
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = mul nuw i64 %36, 281479271743489
  %38 = getelementptr inbounds i16, i16* %3, i64 %32
  %39 = bitcast i16* %38 to i64*
  store i64 %37, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %38, i64 4
  %41 = bitcast i16* %40 to i64*
  store i64 %37, i64* %41, align 8
  %42 = shl nsw i64 %4, 2
  %43 = add nsw i64 %42, -1
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i64
  %47 = mul nuw i64 %46, 281479271743489
  %48 = getelementptr inbounds i16, i16* %3, i64 %42
  %49 = bitcast i16* %48 to i64*
  store i64 %47, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %48, i64 4
  %51 = bitcast i16* %50 to i64*
  store i64 %47, i64* %51, align 8
  %52 = mul nsw i64 %4, 5
  %53 = add nsw i64 %52, -1
  %54 = getelementptr inbounds i16, i16* %3, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i64
  %57 = mul nuw i64 %56, 281479271743489
  %58 = getelementptr inbounds i16, i16* %3, i64 %52
  %59 = bitcast i16* %58 to i64*
  store i64 %57, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %58, i64 4
  %61 = bitcast i16* %60 to i64*
  store i64 %57, i64* %61, align 8
  %62 = mul nsw i64 %4, 6
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = mul nuw i64 %66, 281479271743489
  %68 = getelementptr inbounds i16, i16* %3, i64 %62
  %69 = bitcast i16* %68 to i64*
  store i64 %67, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 %67, i64* %71, align 8
  %72 = mul nsw i64 %4, 7
  %73 = add nsw i64 %72, -1
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i64
  %77 = mul nuw i64 %76, 281479271743489
  %78 = getelementptr inbounds i16, i16* %3, i64 %72
  %79 = bitcast i16* %78 to i64*
  store i64 %77, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %77, i64* %81, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_vertical_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds i16, i16* %8, i64 4
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = shl i64 %4, 32
  %15 = ashr exact i64 %14, 32
  %16 = bitcast i8* %0 to i64*
  store i64 %10, i64* %16, align 8
  %17 = getelementptr inbounds i8, i8* %0, i64 8
  %18 = bitcast i8* %17 to i64*
  store i64 %13, i64* %18, align 8
  %19 = getelementptr inbounds i16, i16* %3, i64 %15
  %20 = bitcast i16* %19 to i64*
  store i64 %10, i64* %20, align 8
  %21 = getelementptr inbounds i16, i16* %19, i64 4
  %22 = bitcast i16* %21 to i64*
  store i64 %13, i64* %22, align 8
  %23 = ashr exact i64 %14, 31
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to i64*
  store i64 %10, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %24, i64 4
  %27 = bitcast i16* %26 to i64*
  store i64 %13, i64* %27, align 8
  %28 = mul nsw i64 %15, 3
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = bitcast i16* %29 to i64*
  store i64 %10, i64* %30, align 8
  %31 = getelementptr inbounds i16, i16* %29, i64 4
  %32 = bitcast i16* %31 to i64*
  store i64 %13, i64* %32, align 8
  %33 = ashr exact i64 %14, 30
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %10, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %34, i64 4
  %37 = bitcast i16* %36 to i64*
  store i64 %13, i64* %37, align 8
  %38 = mul nsw i64 %15, 5
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %10, i64* %40, align 8
  %41 = getelementptr inbounds i16, i16* %39, i64 4
  %42 = bitcast i16* %41 to i64*
  store i64 %13, i64* %42, align 8
  %43 = mul nsw i64 %15, 6
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %10, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 %13, i64* %47, align 8
  %48 = mul nsw i64 %15, 7
  %49 = getelementptr inbounds i16, i16* %3, i64 %48
  %50 = bitcast i16* %49 to i64*
  store i64 %10, i64* %50, align 8
  %51 = getelementptr inbounds i16, i16* %49, i64 4
  %52 = bitcast i16* %51 to i64*
  store i64 %13, i64* %52, align 8
  %53 = ashr exact i64 %14, 29
  %54 = getelementptr inbounds i16, i16* %3, i64 %53
  %55 = bitcast i16* %54 to i64*
  store i64 %10, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %54, i64 4
  %57 = bitcast i16* %56 to i64*
  store i64 %13, i64* %57, align 8
  %58 = mul nsw i64 %15, 9
  %59 = getelementptr inbounds i16, i16* %3, i64 %58
  %60 = bitcast i16* %59 to i64*
  store i64 %10, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %59, i64 4
  %62 = bitcast i16* %61 to i64*
  store i64 %13, i64* %62, align 8
  %63 = mul nsw i64 %15, 10
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = bitcast i16* %64 to i64*
  store i64 %10, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %64, i64 4
  %67 = bitcast i16* %66 to i64*
  store i64 %13, i64* %67, align 8
  %68 = mul nsw i64 %15, 11
  %69 = getelementptr inbounds i16, i16* %3, i64 %68
  %70 = bitcast i16* %69 to i64*
  store i64 %10, i64* %70, align 8
  %71 = getelementptr inbounds i16, i16* %69, i64 4
  %72 = bitcast i16* %71 to i64*
  store i64 %13, i64* %72, align 8
  %73 = mul nsw i64 %15, 12
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = bitcast i16* %74 to i64*
  store i64 %10, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %13, i64* %77, align 8
  %78 = mul nsw i64 %15, 13
  %79 = getelementptr inbounds i16, i16* %3, i64 %78
  %80 = bitcast i16* %79 to i64*
  store i64 %10, i64* %80, align 8
  %81 = getelementptr inbounds i16, i16* %79, i64 4
  %82 = bitcast i16* %81 to i64*
  store i64 %13, i64* %82, align 8
  %83 = mul nsw i64 %15, 14
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = bitcast i16* %84 to i64*
  store i64 %10, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 %13, i64* %87, align 8
  %88 = mul nsw i64 %15, 15
  %89 = getelementptr inbounds i16, i16* %3, i64 %88
  %90 = bitcast i16* %89 to i64*
  store i64 %10, i64* %90, align 8
  %91 = getelementptr inbounds i16, i16* %89, i64 4
  %92 = bitcast i16* %91 to i64*
  store i64 %13, i64* %92, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_horizontal_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = mul nuw i64 %8, 281479271743489
  %10 = bitcast i8* %0 to i64*
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to i64*
  store i64 %9, i64* %12, align 8
  %13 = add nsw i64 %4, -1
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = mul nuw i64 %16, 281479271743489
  %18 = getelementptr inbounds i16, i16* %3, i64 %4
  %19 = bitcast i16* %18 to i64*
  store i64 %17, i64* %19, align 8
  %20 = getelementptr inbounds i16, i16* %18, i64 4
  %21 = bitcast i16* %20 to i64*
  store i64 %17, i64* %21, align 8
  %22 = and i64 %1, -2
  %23 = add nsw i64 %22, -1
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = mul nuw i64 %26, 281479271743489
  %28 = getelementptr inbounds i16, i16* %3, i64 %22
  %29 = bitcast i16* %28 to i64*
  store i64 %27, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 %27, i64* %31, align 8
  %32 = mul nsw i64 %4, 3
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = mul nuw i64 %36, 281479271743489
  %38 = getelementptr inbounds i16, i16* %3, i64 %32
  %39 = bitcast i16* %38 to i64*
  store i64 %37, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %38, i64 4
  %41 = bitcast i16* %40 to i64*
  store i64 %37, i64* %41, align 8
  %42 = shl nsw i64 %4, 2
  %43 = add nsw i64 %42, -1
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i64
  %47 = mul nuw i64 %46, 281479271743489
  %48 = getelementptr inbounds i16, i16* %3, i64 %42
  %49 = bitcast i16* %48 to i64*
  store i64 %47, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %48, i64 4
  %51 = bitcast i16* %50 to i64*
  store i64 %47, i64* %51, align 8
  %52 = mul nsw i64 %4, 5
  %53 = add nsw i64 %52, -1
  %54 = getelementptr inbounds i16, i16* %3, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i64
  %57 = mul nuw i64 %56, 281479271743489
  %58 = getelementptr inbounds i16, i16* %3, i64 %52
  %59 = bitcast i16* %58 to i64*
  store i64 %57, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %58, i64 4
  %61 = bitcast i16* %60 to i64*
  store i64 %57, i64* %61, align 8
  %62 = mul nsw i64 %4, 6
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = mul nuw i64 %66, 281479271743489
  %68 = getelementptr inbounds i16, i16* %3, i64 %62
  %69 = bitcast i16* %68 to i64*
  store i64 %67, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 %67, i64* %71, align 8
  %72 = mul nsw i64 %4, 7
  %73 = add nsw i64 %72, -1
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i64
  %77 = mul nuw i64 %76, 281479271743489
  %78 = getelementptr inbounds i16, i16* %3, i64 %72
  %79 = bitcast i16* %78 to i64*
  store i64 %77, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %77, i64* %81, align 8
  %82 = shl nsw i64 %4, 3
  %83 = add nsw i64 %82, -1
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i64
  %87 = mul nuw i64 %86, 281479271743489
  %88 = getelementptr inbounds i16, i16* %3, i64 %82
  %89 = bitcast i16* %88 to i64*
  store i64 %87, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %88, i64 4
  %91 = bitcast i16* %90 to i64*
  store i64 %87, i64* %91, align 8
  %92 = mul nsw i64 %4, 9
  %93 = add nsw i64 %92, -1
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i64
  %97 = mul nuw i64 %96, 281479271743489
  %98 = getelementptr inbounds i16, i16* %3, i64 %92
  %99 = bitcast i16* %98 to i64*
  store i64 %97, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %98, i64 4
  %101 = bitcast i16* %100 to i64*
  store i64 %97, i64* %101, align 8
  %102 = mul nsw i64 %4, 10
  %103 = add nsw i64 %102, -1
  %104 = getelementptr inbounds i16, i16* %3, i64 %103
  %105 = load i16, i16* %104, align 2
  %106 = zext i16 %105 to i64
  %107 = mul nuw i64 %106, 281479271743489
  %108 = getelementptr inbounds i16, i16* %3, i64 %102
  %109 = bitcast i16* %108 to i64*
  store i64 %107, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 %107, i64* %111, align 8
  %112 = mul nsw i64 %4, 11
  %113 = add nsw i64 %112, -1
  %114 = getelementptr inbounds i16, i16* %3, i64 %113
  %115 = load i16, i16* %114, align 2
  %116 = zext i16 %115 to i64
  %117 = mul nuw i64 %116, 281479271743489
  %118 = getelementptr inbounds i16, i16* %3, i64 %112
  %119 = bitcast i16* %118 to i64*
  store i64 %117, i64* %119, align 8
  %120 = getelementptr inbounds i16, i16* %118, i64 4
  %121 = bitcast i16* %120 to i64*
  store i64 %117, i64* %121, align 8
  %122 = mul nsw i64 %4, 12
  %123 = add nsw i64 %122, -1
  %124 = getelementptr inbounds i16, i16* %3, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i64
  %127 = mul nuw i64 %126, 281479271743489
  %128 = getelementptr inbounds i16, i16* %3, i64 %122
  %129 = bitcast i16* %128 to i64*
  store i64 %127, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %127, i64* %131, align 8
  %132 = mul nsw i64 %4, 13
  %133 = add nsw i64 %132, -1
  %134 = getelementptr inbounds i16, i16* %3, i64 %133
  %135 = load i16, i16* %134, align 2
  %136 = zext i16 %135 to i64
  %137 = mul nuw i64 %136, 281479271743489
  %138 = getelementptr inbounds i16, i16* %3, i64 %132
  %139 = bitcast i16* %138 to i64*
  store i64 %137, i64* %139, align 8
  %140 = getelementptr inbounds i16, i16* %138, i64 4
  %141 = bitcast i16* %140 to i64*
  store i64 %137, i64* %141, align 8
  %142 = mul nsw i64 %4, 14
  %143 = add nsw i64 %142, -1
  %144 = getelementptr inbounds i16, i16* %3, i64 %143
  %145 = load i16, i16* %144, align 2
  %146 = zext i16 %145 to i64
  %147 = mul nuw i64 %146, 281479271743489
  %148 = getelementptr inbounds i16, i16* %3, i64 %142
  %149 = bitcast i16* %148 to i64*
  store i64 %147, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %148, i64 4
  %151 = bitcast i16* %150 to i64*
  store i64 %147, i64* %151, align 8
  %152 = mul nsw i64 %4, 15
  %153 = add nsw i64 %152, -1
  %154 = getelementptr inbounds i16, i16* %3, i64 %153
  %155 = load i16, i16* %154, align 2
  %156 = zext i16 %155 to i64
  %157 = mul nuw i64 %156, 281479271743489
  %158 = getelementptr inbounds i16, i16* %3, i64 %152
  %159 = bitcast i16* %158 to i64*
  store i64 %157, i64* %159, align 8
  %160 = getelementptr inbounds i16, i16* %158, i64 4
  %161 = bitcast i16* %160 to i64*
  store i64 %157, i64* %161, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_plane_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 6
  %6 = bitcast i8* %5 to i16*
  %7 = shl i64 %4, 32
  %8 = ashr exact i64 %7, 32
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i16, i16* %6, i64 %9
  %11 = shl i64 %4, 34
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = getelementptr inbounds i16, i16* %13, i64 -1
  %15 = shl i64 %1, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = sub nsw i64 0, %17
  %19 = getelementptr inbounds i16, i16* %14, i64 %18
  %20 = getelementptr inbounds i16, i16* %10, i64 1
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = getelementptr inbounds i16, i16* %10, i64 -1
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = sub nsw i32 %22, %25
  %27 = load i16, i16* %14, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %19, align 2
  %30 = zext i16 %29 to i32
  %31 = sub nsw i32 %28, %30
  %32 = shl i64 %4, 32
  %33 = ashr exact i64 %32, 32
  %34 = mul nsw i64 %33, 6
  %35 = shl i64 %4, 34
  %36 = ashr exact i64 %35, 31
  %37 = add nsw i64 %34, %36
  %38 = add nsw i64 %37, -2
  %39 = getelementptr i8, i8* %0, i64 %38
  %40 = add nsw i64 %36, -2
  %41 = shl i64 %1, 32
  %42 = ashr exact i64 %41, 32
  %43 = lshr i64 %42, 1
  %44 = shl i64 %43, 2
  %45 = sub i64 %40, %44
  %46 = sub i64 %45, %34
  %47 = getelementptr i8, i8* %0, i64 %46
  %48 = getelementptr inbounds i16, i16* %14, i64 %8
  %49 = getelementptr inbounds i16, i16* %19, i64 %9
  %50 = getelementptr inbounds i16, i16* %10, i64 2
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i32
  %53 = getelementptr inbounds i16, i16* %10, i64 -2
  %54 = load i16, i16* %53, align 2
  %55 = zext i16 %54 to i32
  %56 = sub nsw i32 %52, %55
  %57 = shl nsw i32 %56, 1
  %58 = add nsw i32 %57, %26
  %59 = load i16, i16* %48, align 2
  %60 = zext i16 %59 to i32
  %61 = load i16, i16* %49, align 2
  %62 = zext i16 %61 to i32
  %63 = sub nsw i32 %60, %62
  %64 = shl nsw i32 %63, 1
  %65 = add nsw i32 %64, %31
  %66 = getelementptr inbounds i16, i16* %48, i64 %8
  %67 = getelementptr inbounds i16, i16* %49, i64 %9
  %68 = getelementptr inbounds i16, i16* %10, i64 3
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i32
  %71 = getelementptr inbounds i16, i16* %10, i64 -3
  %72 = load i16, i16* %71, align 2
  %73 = zext i16 %72 to i32
  %74 = sub nsw i32 %70, %73
  %75 = mul nsw i32 %74, 3
  %76 = add nsw i32 %75, %58
  %77 = load i16, i16* %66, align 2
  %78 = zext i16 %77 to i32
  %79 = load i16, i16* %67, align 2
  %80 = zext i16 %79 to i32
  %81 = sub nsw i32 %78, %80
  %82 = mul nsw i32 %81, 3
  %83 = add nsw i32 %82, %65
  %84 = getelementptr inbounds i16, i16* %66, i64 %8
  %85 = getelementptr inbounds i16, i16* %67, i64 %9
  %86 = getelementptr inbounds i16, i16* %10, i64 4
  %87 = load i16, i16* %86, align 2
  %88 = zext i16 %87 to i32
  %89 = getelementptr inbounds i16, i16* %10, i64 -4
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = sub nsw i32 %88, %91
  %93 = shl nsw i32 %92, 2
  %94 = add nsw i32 %93, %76
  %95 = load i16, i16* %84, align 2
  %96 = zext i16 %95 to i32
  %97 = load i16, i16* %85, align 2
  %98 = zext i16 %97 to i32
  %99 = sub nsw i32 %96, %98
  %100 = shl nsw i32 %99, 2
  %101 = add nsw i32 %100, %83
  %102 = bitcast i8* %39 to i16*
  %103 = mul nsw i32 %94, 17
  %104 = add nsw i32 %103, 16
  %105 = ashr i32 %104, 5
  %106 = mul nsw i32 %101, 17
  %107 = add nsw i32 %106, 16
  %108 = ashr i32 %107, 5
  %109 = load i16, i16* %102, align 2
  %110 = zext i16 %109 to i32
  %111 = getelementptr inbounds i8, i8* %47, i64 16
  %112 = bitcast i8* %111 to i16*
  %113 = load i16, i16* %112, align 2
  %114 = zext i16 %113 to i32
  %115 = add nuw nsw i32 %114, %110
  %116 = shl nuw nsw i32 %115, 4
  %117 = add nsw i32 %108, %105
  %118 = mul nsw i32 %117, -3
  %119 = add nsw i32 %118, 16
  %120 = add nsw i32 %119, %116
  %121 = shl nsw i32 %105, 1
  %122 = mul nsw i32 %105, 3
  %123 = shl nsw i32 %105, 2
  %124 = mul nsw i32 %105, 5
  %125 = mul nsw i32 %105, 6
  %126 = mul nsw i32 %105, 7
  br label %127

127:                                              ; preds = %214, %2
  %128 = phi i32 [ 8, %2 ], [ %219, %214 ]
  %129 = phi i16* [ %3, %2 ], [ %218, %214 ]
  %130 = phi i32 [ %120, %2 ], [ %131, %214 ]
  %131 = add nsw i32 %130, %108
  %132 = ashr i32 %130, 5
  %133 = icmp ult i32 %132, 1024
  br i1 %133, label %138, label %134

134:                                              ; preds = %127
  %135 = ashr i32 %130, 31
  %136 = or i32 %135, -1024
  %137 = xor i32 %136, -1
  br label %138

138:                                              ; preds = %127, %134
  %139 = phi i32 [ %137, %134 ], [ %132, %127 ]
  %140 = trunc i32 %139 to i16
  store i16 %140, i16* %129, align 2
  %141 = add nsw i32 %130, %105
  %142 = ashr i32 %141, 5
  %143 = icmp ult i32 %142, 1024
  br i1 %143, label %148, label %144

144:                                              ; preds = %138
  %145 = ashr i32 %141, 31
  %146 = or i32 %145, -1024
  %147 = xor i32 %146, -1
  br label %148

148:                                              ; preds = %138, %144
  %149 = phi i32 [ %147, %144 ], [ %142, %138 ]
  %150 = trunc i32 %149 to i16
  %151 = getelementptr inbounds i16, i16* %129, i64 1
  store i16 %150, i16* %151, align 2
  %152 = add nsw i32 %130, %121
  %153 = ashr i32 %152, 5
  %154 = icmp ult i32 %153, 1024
  br i1 %154, label %159, label %155

155:                                              ; preds = %148
  %156 = ashr i32 %152, 31
  %157 = or i32 %156, -1024
  %158 = xor i32 %157, -1
  br label %159

159:                                              ; preds = %148, %155
  %160 = phi i32 [ %158, %155 ], [ %153, %148 ]
  %161 = trunc i32 %160 to i16
  %162 = getelementptr inbounds i16, i16* %129, i64 2
  store i16 %161, i16* %162, align 2
  %163 = add nsw i32 %130, %122
  %164 = ashr i32 %163, 5
  %165 = icmp ult i32 %164, 1024
  br i1 %165, label %170, label %166

166:                                              ; preds = %159
  %167 = ashr i32 %163, 31
  %168 = or i32 %167, -1024
  %169 = xor i32 %168, -1
  br label %170

170:                                              ; preds = %159, %166
  %171 = phi i32 [ %169, %166 ], [ %164, %159 ]
  %172 = trunc i32 %171 to i16
  %173 = getelementptr inbounds i16, i16* %129, i64 3
  store i16 %172, i16* %173, align 2
  %174 = add nsw i32 %130, %123
  %175 = ashr i32 %174, 5
  %176 = icmp ult i32 %175, 1024
  br i1 %176, label %181, label %177

177:                                              ; preds = %170
  %178 = ashr i32 %174, 31
  %179 = or i32 %178, -1024
  %180 = xor i32 %179, -1
  br label %181

181:                                              ; preds = %170, %177
  %182 = phi i32 [ %180, %177 ], [ %175, %170 ]
  %183 = trunc i32 %182 to i16
  %184 = getelementptr inbounds i16, i16* %129, i64 4
  store i16 %183, i16* %184, align 2
  %185 = add nsw i32 %130, %124
  %186 = ashr i32 %185, 5
  %187 = icmp ult i32 %186, 1024
  br i1 %187, label %192, label %188

188:                                              ; preds = %181
  %189 = ashr i32 %185, 31
  %190 = or i32 %189, -1024
  %191 = xor i32 %190, -1
  br label %192

192:                                              ; preds = %181, %188
  %193 = phi i32 [ %191, %188 ], [ %186, %181 ]
  %194 = trunc i32 %193 to i16
  %195 = getelementptr inbounds i16, i16* %129, i64 5
  store i16 %194, i16* %195, align 2
  %196 = add nsw i32 %130, %125
  %197 = ashr i32 %196, 5
  %198 = icmp ult i32 %197, 1024
  br i1 %198, label %203, label %199

199:                                              ; preds = %192
  %200 = ashr i32 %196, 31
  %201 = or i32 %200, -1024
  %202 = xor i32 %201, -1
  br label %203

203:                                              ; preds = %192, %199
  %204 = phi i32 [ %202, %199 ], [ %197, %192 ]
  %205 = trunc i32 %204 to i16
  %206 = getelementptr inbounds i16, i16* %129, i64 6
  store i16 %205, i16* %206, align 2
  %207 = add nsw i32 %130, %126
  %208 = ashr i32 %207, 5
  %209 = icmp ult i32 %208, 1024
  br i1 %209, label %214, label %210

210:                                              ; preds = %203
  %211 = ashr i32 %207, 31
  %212 = or i32 %211, -1024
  %213 = xor i32 %212, -1
  br label %214

214:                                              ; preds = %203, %210
  %215 = phi i32 [ %213, %210 ], [ %208, %203 ]
  %216 = trunc i32 %215 to i16
  %217 = getelementptr inbounds i16, i16* %129, i64 7
  store i16 %216, i16* %217, align 2
  %218 = getelementptr inbounds i16, i16* %129, i64 %8
  %219 = add nsw i32 %128, -1
  %220 = icmp eq i32 %219, 0
  br i1 %220, label %221, label %127

221:                                              ; preds = %214
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_plane_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 6
  %6 = bitcast i8* %5 to i16*
  %7 = shl i64 %4, 32
  %8 = ashr exact i64 %7, 32
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i16, i16* %6, i64 %9
  %11 = shl i64 %4, 35
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = getelementptr inbounds i16, i16* %13, i64 -1
  %15 = shl i64 %1, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = sub nsw i64 0, %17
  %19 = getelementptr inbounds i16, i16* %14, i64 %18
  %20 = getelementptr inbounds i16, i16* %10, i64 1
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = getelementptr inbounds i16, i16* %10, i64 -1
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = sub nsw i32 %22, %25
  %27 = shl i64 %4, 35
  %28 = ashr exact i64 %27, 31
  %29 = add nsw i64 %28, -2
  %30 = shl i64 %1, 32
  %31 = ashr exact i64 %30, 32
  %32 = lshr i64 %31, 1
  %33 = shl i64 %32, 2
  %34 = sub i64 %29, %33
  %35 = shl i64 %4, 32
  %36 = ashr exact i64 %35, 32
  %37 = mul nsw i64 %36, 6
  %38 = add nsw i64 %37, %28
  %39 = add nsw i64 %38, -2
  %40 = getelementptr i8, i8* %0, i64 %39
  %41 = sub i64 %34, %37
  %42 = getelementptr i8, i8* %0, i64 %41
  %43 = getelementptr inbounds i16, i16* %14, i64 %8
  %44 = getelementptr inbounds i16, i16* %19, i64 %9
  %45 = getelementptr inbounds i16, i16* %10, i64 2
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i32
  %48 = getelementptr inbounds i16, i16* %10, i64 -2
  %49 = load i16, i16* %48, align 2
  %50 = zext i16 %49 to i32
  %51 = sub nsw i32 %47, %50
  %52 = shl nsw i32 %51, 1
  %53 = add nsw i32 %52, %26
  %54 = getelementptr inbounds i16, i16* %43, i64 %8
  %55 = getelementptr inbounds i16, i16* %44, i64 %9
  %56 = getelementptr inbounds i16, i16* %10, i64 3
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = getelementptr inbounds i16, i16* %10, i64 -3
  %60 = load i16, i16* %59, align 2
  %61 = zext i16 %60 to i32
  %62 = sub nsw i32 %58, %61
  %63 = mul nsw i32 %62, 3
  %64 = add nsw i32 %63, %53
  %65 = getelementptr inbounds i16, i16* %10, i64 4
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = getelementptr inbounds i16, i16* %10, i64 -4
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i32
  %71 = sub nsw i32 %67, %70
  %72 = shl nsw i32 %71, 2
  %73 = add nsw i32 %72, %64
  %74 = bitcast i8* %40 to i16*
  %75 = bitcast i8* %42 to i16*
  %76 = getelementptr inbounds i16, i16* %54, i64 %8
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i32
  %79 = getelementptr inbounds i16, i16* %55, i64 %9
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = sub nsw i32 %78, %81
  %83 = shl nsw i32 %82, 2
  %84 = load i16, i16* %54, align 2
  %85 = zext i16 %84 to i32
  %86 = load i16, i16* %55, align 2
  %87 = zext i16 %86 to i32
  %88 = sub nsw i32 %85, %87
  %89 = mul nsw i32 %88, 3
  %90 = load i16, i16* %43, align 2
  %91 = zext i16 %90 to i32
  %92 = load i16, i16* %44, align 2
  %93 = zext i16 %92 to i32
  %94 = sub nsw i32 %91, %93
  %95 = shl nsw i32 %94, 1
  %96 = load i16, i16* %14, align 2
  %97 = zext i16 %96 to i32
  %98 = load i16, i16* %19, align 2
  %99 = zext i16 %98 to i32
  %100 = sub nsw i32 %97, %99
  %101 = add nsw i32 %95, %100
  %102 = add nsw i32 %89, %101
  %103 = add nsw i32 %83, %102
  %104 = ashr exact i64 %35, 30
  %105 = mul nsw i64 %36, -3
  %106 = getelementptr inbounds i16, i16* %74, i64 %8
  %107 = getelementptr inbounds i16, i16* %75, i64 %9
  %108 = load i16, i16* %106, align 2
  %109 = zext i16 %108 to i32
  %110 = load i16, i16* %107, align 2
  %111 = zext i16 %110 to i32
  %112 = sub nsw i32 %109, %111
  %113 = mul nsw i32 %112, 5
  %114 = add nsw i32 %113, %103
  %115 = getelementptr inbounds i16, i16* %106, i64 %8
  %116 = getelementptr inbounds i16, i16* %107, i64 %9
  %117 = load i16, i16* %115, align 2
  %118 = zext i16 %117 to i32
  %119 = load i16, i16* %116, align 2
  %120 = zext i16 %119 to i32
  %121 = sub nsw i32 %118, %120
  %122 = mul nsw i32 %121, 6
  %123 = add nsw i32 %122, %114
  %124 = getelementptr inbounds i16, i16* %115, i64 %8
  %125 = getelementptr inbounds i16, i16* %116, i64 %9
  %126 = load i16, i16* %124, align 2
  %127 = zext i16 %126 to i32
  %128 = load i16, i16* %125, align 2
  %129 = zext i16 %128 to i32
  %130 = sub nsw i32 %127, %129
  %131 = mul nsw i32 %130, 7
  %132 = add nsw i32 %131, %123
  %133 = getelementptr inbounds i16, i16* %124, i64 %8
  %134 = getelementptr inbounds i16, i16* %125, i64 %9
  %135 = load i16, i16* %133, align 2
  %136 = zext i16 %135 to i32
  %137 = load i16, i16* %134, align 2
  %138 = zext i16 %137 to i32
  %139 = sub nsw i32 %136, %138
  %140 = shl nsw i32 %139, 3
  %141 = add nsw i32 %140, %132
  %142 = getelementptr i16, i16* %75, i64 %105
  %143 = getelementptr i16, i16* %74, i64 %104
  %144 = mul i32 %141, 5
  %145 = add i32 %144, 32
  %146 = ashr i32 %145, 6
  %147 = getelementptr inbounds i16, i16* %142, i64 %9
  %148 = mul nsw i32 %73, 17
  %149 = add nsw i32 %148, 16
  %150 = ashr i32 %149, 5
  %151 = load i16, i16* %143, align 2
  %152 = zext i16 %151 to i32
  %153 = getelementptr inbounds i16, i16* %147, i64 8
  %154 = load i16, i16* %153, align 2
  %155 = zext i16 %154 to i32
  %156 = add nuw nsw i32 %155, %152
  %157 = shl nuw nsw i32 %156, 4
  %158 = mul nsw i32 %146, -7
  %159 = mul nsw i32 %150, 3
  %160 = sub nsw i32 16, %159
  %161 = add nsw i32 %160, %158
  %162 = add nsw i32 %161, %157
  %163 = shl nsw i32 %150, 1
  %164 = shl nsw i32 %150, 2
  %165 = mul nsw i32 %150, 5
  %166 = mul nsw i32 %150, 6
  %167 = mul nsw i32 %150, 7
  br label %168

168:                                              ; preds = %255, %2
  %169 = phi i32 [ 16, %2 ], [ %260, %255 ]
  %170 = phi i16* [ %3, %2 ], [ %259, %255 ]
  %171 = phi i32 [ %162, %2 ], [ %172, %255 ]
  %172 = add nsw i32 %171, %146
  %173 = ashr i32 %171, 5
  %174 = icmp ult i32 %173, 1024
  br i1 %174, label %179, label %175

175:                                              ; preds = %168
  %176 = ashr i32 %171, 31
  %177 = or i32 %176, -1024
  %178 = xor i32 %177, -1
  br label %179

179:                                              ; preds = %168, %175
  %180 = phi i32 [ %178, %175 ], [ %173, %168 ]
  %181 = trunc i32 %180 to i16
  store i16 %181, i16* %170, align 2
  %182 = add nsw i32 %171, %150
  %183 = ashr i32 %182, 5
  %184 = icmp ult i32 %183, 1024
  br i1 %184, label %189, label %185

185:                                              ; preds = %179
  %186 = ashr i32 %182, 31
  %187 = or i32 %186, -1024
  %188 = xor i32 %187, -1
  br label %189

189:                                              ; preds = %179, %185
  %190 = phi i32 [ %188, %185 ], [ %183, %179 ]
  %191 = trunc i32 %190 to i16
  %192 = getelementptr inbounds i16, i16* %170, i64 1
  store i16 %191, i16* %192, align 2
  %193 = add nsw i32 %171, %163
  %194 = ashr i32 %193, 5
  %195 = icmp ult i32 %194, 1024
  br i1 %195, label %200, label %196

196:                                              ; preds = %189
  %197 = ashr i32 %193, 31
  %198 = or i32 %197, -1024
  %199 = xor i32 %198, -1
  br label %200

200:                                              ; preds = %189, %196
  %201 = phi i32 [ %199, %196 ], [ %194, %189 ]
  %202 = trunc i32 %201 to i16
  %203 = getelementptr inbounds i16, i16* %170, i64 2
  store i16 %202, i16* %203, align 2
  %204 = add nsw i32 %171, %159
  %205 = ashr i32 %204, 5
  %206 = icmp ult i32 %205, 1024
  br i1 %206, label %211, label %207

207:                                              ; preds = %200
  %208 = ashr i32 %204, 31
  %209 = or i32 %208, -1024
  %210 = xor i32 %209, -1
  br label %211

211:                                              ; preds = %200, %207
  %212 = phi i32 [ %210, %207 ], [ %205, %200 ]
  %213 = trunc i32 %212 to i16
  %214 = getelementptr inbounds i16, i16* %170, i64 3
  store i16 %213, i16* %214, align 2
  %215 = add nsw i32 %171, %164
  %216 = ashr i32 %215, 5
  %217 = icmp ult i32 %216, 1024
  br i1 %217, label %222, label %218

218:                                              ; preds = %211
  %219 = ashr i32 %215, 31
  %220 = or i32 %219, -1024
  %221 = xor i32 %220, -1
  br label %222

222:                                              ; preds = %211, %218
  %223 = phi i32 [ %221, %218 ], [ %216, %211 ]
  %224 = trunc i32 %223 to i16
  %225 = getelementptr inbounds i16, i16* %170, i64 4
  store i16 %224, i16* %225, align 2
  %226 = add nsw i32 %171, %165
  %227 = ashr i32 %226, 5
  %228 = icmp ult i32 %227, 1024
  br i1 %228, label %233, label %229

229:                                              ; preds = %222
  %230 = ashr i32 %226, 31
  %231 = or i32 %230, -1024
  %232 = xor i32 %231, -1
  br label %233

233:                                              ; preds = %222, %229
  %234 = phi i32 [ %232, %229 ], [ %227, %222 ]
  %235 = trunc i32 %234 to i16
  %236 = getelementptr inbounds i16, i16* %170, i64 5
  store i16 %235, i16* %236, align 2
  %237 = add nsw i32 %171, %166
  %238 = ashr i32 %237, 5
  %239 = icmp ult i32 %238, 1024
  br i1 %239, label %244, label %240

240:                                              ; preds = %233
  %241 = ashr i32 %237, 31
  %242 = or i32 %241, -1024
  %243 = xor i32 %242, -1
  br label %244

244:                                              ; preds = %233, %240
  %245 = phi i32 [ %243, %240 ], [ %238, %233 ]
  %246 = trunc i32 %245 to i16
  %247 = getelementptr inbounds i16, i16* %170, i64 6
  store i16 %246, i16* %247, align 2
  %248 = add nsw i32 %171, %167
  %249 = ashr i32 %248, 5
  %250 = icmp ult i32 %249, 1024
  br i1 %250, label %255, label %251

251:                                              ; preds = %244
  %252 = ashr i32 %248, 31
  %253 = or i32 %252, -1024
  %254 = xor i32 %253, -1
  br label %255

255:                                              ; preds = %244, %251
  %256 = phi i32 [ %254, %251 ], [ %249, %244 ]
  %257 = trunc i32 %256 to i16
  %258 = getelementptr inbounds i16, i16* %170, i64 7
  store i16 %257, i16* %258, align 2
  %259 = getelementptr inbounds i16, i16* %170, i64 %8
  %260 = add nsw i32 %169, -1
  %261 = icmp eq i32 %260, 0
  br i1 %261, label %262, label %168

262:                                              ; preds = %255
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_dc_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 0, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = sub nsw i64 4, %4
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = shl nsw i64 %4, 2
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = add nsw i64 %4, -1
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = sub nsw i64 1, %4
  %28 = getelementptr inbounds i16, i16* %3, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = zext i16 %29 to i64
  %31 = add nuw nsw i64 %13, %26
  %32 = add nuw nsw i64 %31, %30
  %33 = sub nsw i64 5, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = add nuw nsw i32 %17, %36
  %38 = mul nsw i64 %4, 5
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i32
  %43 = add nuw nsw i32 %22, %42
  %44 = and i64 %1, -2
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = sub nsw i64 2, %4
  %50 = getelementptr inbounds i16, i16* %3, i64 %49
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i64
  %53 = add nuw nsw i64 %32, %48
  %54 = add nuw nsw i64 %53, %52
  %55 = sub nsw i64 6, %4
  %56 = getelementptr inbounds i16, i16* %3, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %37, %58
  %60 = mul nsw i64 %4, 6
  %61 = add nsw i64 %60, -1
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = load i16, i16* %62, align 2
  %64 = zext i16 %63 to i32
  %65 = add nuw nsw i32 %43, %64
  %66 = mul nsw i64 %4, 3
  %67 = add nsw i64 %66, -1
  %68 = getelementptr inbounds i16, i16* %3, i64 %67
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i64
  %71 = sub nsw i64 3, %4
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = load i16, i16* %72, align 2
  %74 = zext i16 %73 to i64
  %75 = add nuw nsw i64 %54, %70
  %76 = add nuw nsw i64 %75, %74
  %77 = sub nsw i64 7, %4
  %78 = getelementptr inbounds i16, i16* %3, i64 %77
  %79 = load i16, i16* %78, align 2
  %80 = zext i16 %79 to i32
  %81 = add nuw nsw i32 %59, %80
  %82 = mul nsw i64 %4, 7
  %83 = add nsw i64 %82, -1
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i32
  %87 = add nuw nsw i32 %65, %86
  %88 = add nuw nsw i64 %76, 4
  %89 = lshr i64 %88, 3
  %90 = and i64 %89, 536870911
  %91 = mul i64 %90, 281479271743489
  %92 = add nuw nsw i32 %81, 2
  %93 = lshr i32 %92, 2
  %94 = zext i32 %93 to i64
  %95 = mul i64 %94, 281479271743489
  %96 = add nuw nsw i32 %87, 2
  %97 = lshr i32 %96, 2
  %98 = zext i32 %97 to i64
  %99 = add nuw nsw i32 %81, 4
  %100 = add nuw nsw i32 %99, %87
  %101 = lshr i32 %100, 3
  %102 = zext i32 %101 to i64
  %103 = bitcast i8* %0 to i64*
  store i64 %91, i64* %103, align 8
  %104 = getelementptr inbounds i8, i8* %0, i64 8
  %105 = bitcast i8* %104 to i64*
  store i64 %95, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %3, i64 %4
  %107 = bitcast i16* %106 to i64*
  store i64 %91, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %106, i64 4
  %109 = bitcast i16* %108 to i64*
  store i64 %95, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %3, i64 %44
  %111 = bitcast i16* %110 to i64*
  store i64 %91, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %110, i64 4
  %113 = bitcast i16* %112 to i64*
  store i64 %95, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %3, i64 %66
  %115 = bitcast i16* %114 to i64*
  store i64 %91, i64* %115, align 8
  %116 = getelementptr inbounds i16, i16* %114, i64 4
  %117 = bitcast i16* %116 to i64*
  store i64 %95, i64* %117, align 8
  %118 = mul i64 %98, 281479271743489
  %119 = mul i64 %102, 281479271743489
  %120 = getelementptr inbounds i16, i16* %3, i64 %18
  %121 = bitcast i16* %120 to i64*
  store i64 %118, i64* %121, align 8
  %122 = getelementptr inbounds i16, i16* %120, i64 4
  %123 = bitcast i16* %122 to i64*
  store i64 %119, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %3, i64 %38
  %125 = bitcast i16* %124 to i64*
  store i64 %118, i64* %125, align 8
  %126 = getelementptr inbounds i16, i16* %124, i64 4
  %127 = bitcast i16* %126 to i64*
  store i64 %119, i64* %127, align 8
  %128 = getelementptr inbounds i16, i16* %3, i64 %60
  %129 = bitcast i16* %128 to i64*
  store i64 %118, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %119, i64* %131, align 8
  %132 = getelementptr inbounds i16, i16* %3, i64 %82
  %133 = bitcast i16* %132 to i64*
  store i64 %118, i64* %133, align 8
  %134 = getelementptr inbounds i16, i16* %132, i64 4
  %135 = bitcast i16* %134 to i64*
  store i64 %119, i64* %135, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_left_dc_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = add nuw nsw i64 %8, %17
  %19 = mul nsw i64 %4, 5
  %20 = add nsw i64 %19, -1
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i64
  %24 = add nuw nsw i64 %13, %23
  %25 = and i64 %1, -2
  %26 = add nsw i64 %25, -1
  %27 = getelementptr inbounds i16, i16* %3, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i64
  %30 = add nuw nsw i64 %18, %29
  %31 = mul nsw i64 %4, 6
  %32 = add nsw i64 %31, -1
  %33 = getelementptr inbounds i16, i16* %3, i64 %32
  %34 = load i16, i16* %33, align 2
  %35 = zext i16 %34 to i64
  %36 = add nuw nsw i64 %24, %35
  %37 = mul nsw i64 %4, 3
  %38 = add nsw i64 %37, -1
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i64
  %42 = add nuw nsw i64 %30, %41
  %43 = mul nsw i64 %4, 7
  %44 = add nsw i64 %43, -1
  %45 = getelementptr inbounds i16, i16* %3, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i64
  %48 = add nuw nsw i64 %36, %47
  %49 = add nuw nsw i64 %42, 2
  %50 = lshr i64 %49, 2
  %51 = mul i64 %50, 281479271743489
  %52 = add nuw nsw i64 %48, 2
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  store i64 %51, i64* %54, align 8
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  store i64 %51, i64* %56, align 8
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %51, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %51, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %25
  %62 = bitcast i16* %61 to i64*
  store i64 %51, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %51, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %37
  %66 = bitcast i16* %65 to i64*
  store i64 %51, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %51, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %19
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %31
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %43
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_top_dc_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = add nuw nsw i64 %8, %16
  %18 = sub nsw i64 5, %4
  %19 = getelementptr inbounds i16, i16* %3, i64 %18
  %20 = load i16, i16* %19, align 2
  %21 = zext i16 %20 to i64
  %22 = add nuw nsw i64 %12, %21
  %23 = sub nsw i64 2, %4
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = add nuw nsw i64 %17, %26
  %28 = sub nsw i64 6, %4
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i64
  %32 = add nuw nsw i64 %22, %31
  %33 = sub nsw i64 3, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %27, %36
  %38 = sub nsw i64 7, %4
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i64
  %42 = add nuw nsw i64 %32, %41
  %43 = add nuw nsw i64 %37, 2
  %44 = lshr i64 %43, 2
  %45 = mul i64 %44, 281479271743489
  %46 = add nuw nsw i64 %42, 2
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %45, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %45, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %45, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %45, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %45, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %45, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %45, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %45, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_l0t_10(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = sub nsw i64 5, %4
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub nsw i64 2, %4
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = sub nsw i64 6, %4
  %26 = getelementptr inbounds i16, i16* %3, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i64
  %29 = sub nsw i64 3, %4
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = sub nsw i64 7, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %8, 2
  %38 = add nuw nsw i64 %37, %16
  %39 = add nuw nsw i64 %38, %24
  %40 = add nuw nsw i64 %39, %32
  %41 = lshr i64 %40, 2
  %42 = mul i64 %41, 281479271743489
  %43 = add nuw nsw i64 %12, 2
  %44 = add nuw nsw i64 %43, %20
  %45 = add nuw nsw i64 %44, %28
  %46 = add nuw nsw i64 %45, %36
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %42, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %42, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %42, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %42, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %42, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %42, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %42, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %42, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  %86 = lshr i64 %1, 1
  %87 = trunc i64 %86 to i32
  %88 = shl i64 %86, 32
  %89 = sub i64 0, %88
  %90 = ashr exact i64 %89, 32
  %91 = getelementptr inbounds i16, i16* %3, i64 %90
  %92 = load i16, i16* %91, align 2
  %93 = zext i16 %92 to i32
  %94 = sub i64 4294967296, %88
  %95 = ashr exact i64 %94, 32
  %96 = getelementptr inbounds i16, i16* %3, i64 %95
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i32
  %99 = sub i64 8589934592, %88
  %100 = ashr exact i64 %99, 32
  %101 = getelementptr inbounds i16, i16* %3, i64 %100
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  %104 = sub i64 12884901888, %88
  %105 = ashr exact i64 %104, 32
  %106 = getelementptr inbounds i16, i16* %3, i64 %105
  %107 = load i16, i16* %106, align 2
  %108 = zext i16 %107 to i32
  %109 = getelementptr inbounds i8, i8* %0, i64 -2
  %110 = bitcast i8* %109 to i16*
  %111 = load i16, i16* %110, align 2
  %112 = zext i16 %111 to i32
  %113 = add i64 %88, -4294967296
  %114 = ashr exact i64 %113, 32
  %115 = getelementptr inbounds i16, i16* %3, i64 %114
  %116 = load i16, i16* %115, align 2
  %117 = zext i16 %116 to i32
  %118 = trunc i64 %1 to i32
  %119 = and i32 %118, -2
  %120 = add nsw i32 %119, -1
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds i16, i16* %3, i64 %121
  %123 = load i16, i16* %122, align 2
  %124 = zext i16 %123 to i32
  %125 = mul nsw i32 %87, 3
  %126 = add nsw i32 %125, -1
  %127 = sext i32 %126 to i64
  %128 = getelementptr inbounds i16, i16* %3, i64 %127
  %129 = load i16, i16* %128, align 2
  %130 = zext i16 %129 to i32
  %131 = add nuw nsw i32 %93, 4
  %132 = add nuw nsw i32 %131, %98
  %133 = add nuw nsw i32 %132, %103
  %134 = add nuw nsw i32 %133, %108
  %135 = add nuw nsw i32 %134, %112
  %136 = add nuw nsw i32 %135, %117
  %137 = add nuw nsw i32 %136, %124
  %138 = add nuw nsw i32 %137, %130
  %139 = ashr i32 %138, 3
  %140 = sext i32 %139 to i64
  %141 = mul i64 %140, 281479271743489
  store i64 %141, i64* %49, align 8
  %142 = ashr exact i64 %88, 32
  %143 = getelementptr inbounds i16, i16* %3, i64 %142
  %144 = bitcast i16* %143 to i64*
  store i64 %141, i64* %144, align 8
  %145 = sext i32 %119 to i64
  %146 = getelementptr inbounds i16, i16* %3, i64 %145
  %147 = bitcast i16* %146 to i64*
  store i64 %141, i64* %147, align 8
  %148 = sext i32 %125 to i64
  %149 = getelementptr inbounds i16, i16* %3, i64 %148
  %150 = bitcast i16* %149 to i64*
  store i64 %141, i64* %150, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_0lt_10(i8* nocapture, i64) #1 {
  tail call void @pred8x8_dc_10_c(i8* %0, i64 %1)
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = sub i64 0, %5
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = sub i64 4294967296, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = load i16, i16* %13, align 2
  %15 = zext i16 %14 to i64
  %16 = sub i64 8589934592, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub i64 12884901888, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i16, i16* %3, i64 %22
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i64
  %26 = add nuw nsw i64 %10, 2
  %27 = add nuw nsw i64 %26, %15
  %28 = add nuw nsw i64 %27, %20
  %29 = add nuw nsw i64 %28, %25
  %30 = lshr i64 %29, 2
  %31 = mul i64 %30, 281479271743489
  %32 = bitcast i8* %0 to i64*
  store i64 %31, i64* %32, align 8
  %33 = ashr exact i64 %5, 32
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %31, i64* %35, align 8
  %36 = shl i64 %1, 32
  %37 = ashr exact i64 %36, 32
  %38 = and i64 %37, -2
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %31, i64* %40, align 8
  %41 = mul i64 %4, 12884901888
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds i16, i16* %3, i64 %42
  %44 = bitcast i16* %43 to i64*
  store i64 %31, i64* %44, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_l00_10(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = mul nsw i64 %4, 5
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = and i64 %1, -2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = mul nsw i64 %4, 6
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = mul nsw i64 %4, 3
  %34 = add nsw i64 %33, -1
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = mul nsw i64 %4, 7
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %8, 2
  %44 = add nuw nsw i64 %43, %17
  %45 = add nuw nsw i64 %44, %27
  %46 = add nuw nsw i64 %45, %37
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = add nuw nsw i64 %13, 2
  %50 = add nuw nsw i64 %49, %22
  %51 = add nuw nsw i64 %50, %32
  %52 = add nuw nsw i64 %51, %42
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  store i64 %48, i64* %54, align 8
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  store i64 %48, i64* %56, align 8
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %48, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %23
  %62 = bitcast i16* %61 to i64*
  store i64 %48, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %48, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %33
  %66 = bitcast i16* %65 to i64*
  store i64 %48, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %48, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %18
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %28
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %38
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  %86 = shl nsw i64 %1, 2
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = bitcast i8* %87 to i16*
  %89 = lshr i64 %1, 1
  %90 = bitcast i8* %87 to i64*
  store i64 144117387132666368, i64* %90, align 8
  %91 = shl i64 %89, 32
  %92 = ashr exact i64 %91, 32
  %93 = getelementptr inbounds i16, i16* %88, i64 %92
  %94 = bitcast i16* %93 to i64*
  store i64 144117387132666368, i64* %94, align 8
  %95 = shl i64 %1, 32
  %96 = ashr exact i64 %95, 32
  %97 = and i64 %96, -2
  %98 = getelementptr inbounds i16, i16* %88, i64 %97
  %99 = bitcast i16* %98 to i64*
  store i64 144117387132666368, i64* %99, align 8
  %100 = mul i64 %89, 12884901888
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %88, i64 %101
  %103 = bitcast i16* %102 to i64*
  store i64 144117387132666368, i64* %103, align 8
  %104 = getelementptr inbounds i8, i8* %87, i64 8
  %105 = bitcast i8* %104 to i16*
  %106 = bitcast i8* %104 to i64*
  store i64 144117387132666368, i64* %106, align 8
  %107 = getelementptr inbounds i16, i16* %105, i64 %92
  %108 = bitcast i16* %107 to i64*
  store i64 144117387132666368, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %105, i64 %97
  %110 = bitcast i16* %109 to i64*
  store i64 144117387132666368, i64* %110, align 8
  %111 = getelementptr inbounds i16, i16* %105, i64 %101
  %112 = bitcast i16* %111 to i64*
  store i64 144117387132666368, i64* %112, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_0l0_10(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = mul nsw i64 %4, 5
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = and i64 %1, -2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = mul nsw i64 %4, 6
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = mul nsw i64 %4, 3
  %34 = add nsw i64 %33, -1
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = mul nsw i64 %4, 7
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %8, 2
  %44 = add nuw nsw i64 %43, %17
  %45 = add nuw nsw i64 %44, %27
  %46 = add nuw nsw i64 %45, %37
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = add nuw nsw i64 %13, 2
  %50 = add nuw nsw i64 %49, %22
  %51 = add nuw nsw i64 %50, %32
  %52 = add nuw nsw i64 %51, %42
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %48, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %23
  %62 = bitcast i16* %61 to i64*
  store i64 %48, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %48, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %33
  %66 = bitcast i16* %65 to i64*
  store i64 %48, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %48, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %18
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %28
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %38
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  %86 = lshr i64 %1, 1
  store i64 144117387132666368, i64* %54, align 8
  %87 = shl i64 %86, 32
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %3, i64 %88
  %90 = bitcast i16* %89 to i64*
  store i64 144117387132666368, i64* %90, align 8
  %91 = shl i64 %1, 32
  %92 = ashr exact i64 %91, 32
  %93 = and i64 %92, -2
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = bitcast i16* %94 to i64*
  store i64 144117387132666368, i64* %95, align 8
  %96 = mul i64 %86, 12884901888
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i16, i16* %3, i64 %97
  %99 = bitcast i16* %98 to i64*
  store i64 144117387132666368, i64* %99, align 8
  %100 = bitcast i8* %55 to i16*
  store i64 144117387132666368, i64* %56, align 8
  %101 = getelementptr inbounds i16, i16* %100, i64 %88
  %102 = bitcast i16* %101 to i64*
  store i64 144117387132666368, i64* %102, align 8
  %103 = getelementptr inbounds i16, i16* %100, i64 %93
  %104 = bitcast i16* %103 to i64*
  store i64 144117387132666368, i64* %104, align 8
  %105 = getelementptr inbounds i16, i16* %100, i64 %97
  %106 = bitcast i16* %105 to i64*
  store i64 144117387132666368, i64* %106, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_dc_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 0, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = sub nsw i64 4, %4
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = shl nsw i64 %4, 2
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = shl nsw i64 %4, 3
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = mul nsw i64 %4, 12
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i32
  %33 = add nsw i64 %4, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = sub nsw i64 1, %4
  %38 = getelementptr inbounds i16, i16* %3, i64 %37
  %39 = load i16, i16* %38, align 2
  %40 = zext i16 %39 to i64
  %41 = add nuw nsw i64 %13, %36
  %42 = add nuw nsw i64 %41, %40
  %43 = sub nsw i64 5, %4
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %17, %46
  %48 = mul nsw i64 %4, 5
  %49 = add nsw i64 %48, -1
  %50 = getelementptr inbounds i16, i16* %3, i64 %49
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i32
  %53 = add nuw nsw i32 %22, %52
  %54 = mul nsw i64 %4, 9
  %55 = add nsw i64 %54, -1
  %56 = getelementptr inbounds i16, i16* %3, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %27, %58
  %60 = mul nsw i64 %4, 13
  %61 = add nsw i64 %60, -1
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = load i16, i16* %62, align 2
  %64 = zext i16 %63 to i32
  %65 = add nuw nsw i32 %32, %64
  %66 = and i64 %1, -2
  %67 = add nsw i64 %66, -1
  %68 = getelementptr inbounds i16, i16* %3, i64 %67
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i64
  %71 = sub nsw i64 2, %4
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = load i16, i16* %72, align 2
  %74 = zext i16 %73 to i64
  %75 = add nuw nsw i64 %42, %70
  %76 = add nuw nsw i64 %75, %74
  %77 = sub nsw i64 6, %4
  %78 = getelementptr inbounds i16, i16* %3, i64 %77
  %79 = load i16, i16* %78, align 2
  %80 = zext i16 %79 to i32
  %81 = add nuw nsw i32 %47, %80
  %82 = mul nsw i64 %4, 6
  %83 = add nsw i64 %82, -1
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i32
  %87 = add nuw nsw i32 %53, %86
  %88 = mul nsw i64 %4, 10
  %89 = add nsw i64 %88, -1
  %90 = getelementptr inbounds i16, i16* %3, i64 %89
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i32
  %93 = add nuw nsw i32 %59, %92
  %94 = mul nsw i64 %4, 14
  %95 = add nsw i64 %94, -1
  %96 = getelementptr inbounds i16, i16* %3, i64 %95
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i32
  %99 = add nuw nsw i32 %65, %98
  %100 = mul nsw i64 %4, 3
  %101 = add nsw i64 %100, -1
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i64
  %105 = sub nsw i64 3, %4
  %106 = getelementptr inbounds i16, i16* %3, i64 %105
  %107 = load i16, i16* %106, align 2
  %108 = zext i16 %107 to i64
  %109 = add nuw nsw i64 %76, %104
  %110 = add nuw nsw i64 %109, %108
  %111 = sub nsw i64 7, %4
  %112 = getelementptr inbounds i16, i16* %3, i64 %111
  %113 = load i16, i16* %112, align 2
  %114 = zext i16 %113 to i32
  %115 = add nuw nsw i32 %81, %114
  %116 = mul nsw i64 %4, 7
  %117 = add nsw i64 %116, -1
  %118 = getelementptr inbounds i16, i16* %3, i64 %117
  %119 = load i16, i16* %118, align 2
  %120 = zext i16 %119 to i32
  %121 = add nuw nsw i32 %87, %120
  %122 = mul nsw i64 %4, 11
  %123 = add nsw i64 %122, -1
  %124 = getelementptr inbounds i16, i16* %3, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %93, %126
  %128 = mul nsw i64 %4, 15
  %129 = add nsw i64 %128, -1
  %130 = getelementptr inbounds i16, i16* %3, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i32
  %133 = add nuw nsw i32 %99, %132
  %134 = add nuw nsw i64 %110, 4
  %135 = lshr i64 %134, 3
  %136 = and i64 %135, 536870911
  %137 = mul i64 %136, 281479271743489
  %138 = add nuw nsw i32 %115, 2
  %139 = lshr i32 %138, 2
  %140 = zext i32 %139 to i64
  %141 = mul i64 %140, 281479271743489
  %142 = add nuw nsw i32 %121, 2
  %143 = lshr i32 %142, 2
  %144 = zext i32 %143 to i64
  %145 = add nuw nsw i32 %115, 4
  %146 = add nuw nsw i32 %145, %121
  %147 = lshr i32 %146, 3
  %148 = zext i32 %147 to i64
  %149 = add nuw nsw i32 %127, 2
  %150 = lshr i32 %149, 2
  %151 = zext i32 %150 to i64
  %152 = add nuw nsw i32 %145, %127
  %153 = lshr i32 %152, 3
  %154 = zext i32 %153 to i64
  %155 = add nuw nsw i32 %133, 2
  %156 = lshr i32 %155, 2
  %157 = zext i32 %156 to i64
  %158 = add nuw nsw i32 %145, %133
  %159 = lshr i32 %158, 3
  %160 = zext i32 %159 to i64
  %161 = bitcast i8* %0 to i64*
  store i64 %137, i64* %161, align 8
  %162 = getelementptr inbounds i8, i8* %0, i64 8
  %163 = bitcast i8* %162 to i64*
  store i64 %141, i64* %163, align 8
  %164 = getelementptr inbounds i16, i16* %3, i64 %4
  %165 = bitcast i16* %164 to i64*
  store i64 %137, i64* %165, align 8
  %166 = getelementptr inbounds i16, i16* %164, i64 4
  %167 = bitcast i16* %166 to i64*
  store i64 %141, i64* %167, align 8
  %168 = getelementptr inbounds i16, i16* %3, i64 %66
  %169 = bitcast i16* %168 to i64*
  store i64 %137, i64* %169, align 8
  %170 = getelementptr inbounds i16, i16* %168, i64 4
  %171 = bitcast i16* %170 to i64*
  store i64 %141, i64* %171, align 8
  %172 = getelementptr inbounds i16, i16* %3, i64 %100
  %173 = bitcast i16* %172 to i64*
  store i64 %137, i64* %173, align 8
  %174 = getelementptr inbounds i16, i16* %172, i64 4
  %175 = bitcast i16* %174 to i64*
  store i64 %141, i64* %175, align 8
  %176 = mul i64 %144, 281479271743489
  %177 = mul i64 %148, 281479271743489
  %178 = mul i64 %151, 281479271743489
  %179 = mul i64 %154, 281479271743489
  %180 = mul i64 %157, 281479271743489
  %181 = mul i64 %160, 281479271743489
  %182 = getelementptr inbounds i16, i16* %3, i64 %18
  %183 = bitcast i16* %182 to i64*
  store i64 %176, i64* %183, align 8
  %184 = getelementptr inbounds i16, i16* %182, i64 4
  %185 = bitcast i16* %184 to i64*
  store i64 %177, i64* %185, align 8
  %186 = getelementptr inbounds i16, i16* %3, i64 %48
  %187 = bitcast i16* %186 to i64*
  store i64 %176, i64* %187, align 8
  %188 = getelementptr inbounds i16, i16* %186, i64 4
  %189 = bitcast i16* %188 to i64*
  store i64 %177, i64* %189, align 8
  %190 = getelementptr inbounds i16, i16* %3, i64 %82
  %191 = bitcast i16* %190 to i64*
  store i64 %176, i64* %191, align 8
  %192 = getelementptr inbounds i16, i16* %190, i64 4
  %193 = bitcast i16* %192 to i64*
  store i64 %177, i64* %193, align 8
  %194 = getelementptr inbounds i16, i16* %3, i64 %116
  %195 = bitcast i16* %194 to i64*
  store i64 %176, i64* %195, align 8
  %196 = getelementptr inbounds i16, i16* %194, i64 4
  %197 = bitcast i16* %196 to i64*
  store i64 %177, i64* %197, align 8
  %198 = getelementptr inbounds i16, i16* %3, i64 %23
  %199 = bitcast i16* %198 to i64*
  store i64 %178, i64* %199, align 8
  %200 = getelementptr inbounds i16, i16* %198, i64 4
  %201 = bitcast i16* %200 to i64*
  store i64 %179, i64* %201, align 8
  %202 = getelementptr inbounds i16, i16* %3, i64 %54
  %203 = bitcast i16* %202 to i64*
  store i64 %178, i64* %203, align 8
  %204 = getelementptr inbounds i16, i16* %202, i64 4
  %205 = bitcast i16* %204 to i64*
  store i64 %179, i64* %205, align 8
  %206 = getelementptr inbounds i16, i16* %3, i64 %88
  %207 = bitcast i16* %206 to i64*
  store i64 %178, i64* %207, align 8
  %208 = getelementptr inbounds i16, i16* %206, i64 4
  %209 = bitcast i16* %208 to i64*
  store i64 %179, i64* %209, align 8
  %210 = getelementptr inbounds i16, i16* %3, i64 %122
  %211 = bitcast i16* %210 to i64*
  store i64 %178, i64* %211, align 8
  %212 = getelementptr inbounds i16, i16* %210, i64 4
  %213 = bitcast i16* %212 to i64*
  store i64 %179, i64* %213, align 8
  %214 = getelementptr inbounds i16, i16* %3, i64 %28
  %215 = bitcast i16* %214 to i64*
  store i64 %180, i64* %215, align 8
  %216 = getelementptr inbounds i16, i16* %214, i64 4
  %217 = bitcast i16* %216 to i64*
  store i64 %181, i64* %217, align 8
  %218 = getelementptr inbounds i16, i16* %3, i64 %60
  %219 = bitcast i16* %218 to i64*
  store i64 %180, i64* %219, align 8
  %220 = getelementptr inbounds i16, i16* %218, i64 4
  %221 = bitcast i16* %220 to i64*
  store i64 %181, i64* %221, align 8
  %222 = getelementptr inbounds i16, i16* %3, i64 %94
  %223 = bitcast i16* %222 to i64*
  store i64 %180, i64* %223, align 8
  %224 = getelementptr inbounds i16, i16* %222, i64 4
  %225 = bitcast i16* %224 to i64*
  store i64 %181, i64* %225, align 8
  %226 = getelementptr inbounds i16, i16* %3, i64 %128
  %227 = bitcast i16* %226 to i64*
  store i64 %180, i64* %227, align 8
  %228 = getelementptr inbounds i16, i16* %226, i64 4
  %229 = bitcast i16* %228 to i64*
  store i64 %181, i64* %229, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_left_dc_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = mul nsw i64 %4, 5
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = and i64 %1, -2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = mul nsw i64 %4, 6
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = mul nsw i64 %4, 3
  %34 = add nsw i64 %33, -1
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = mul nsw i64 %4, 7
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %8, 2
  %44 = add nuw nsw i64 %43, %17
  %45 = add nuw nsw i64 %44, %27
  %46 = add nuw nsw i64 %45, %37
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = add nuw nsw i64 %13, 2
  %50 = add nuw nsw i64 %49, %22
  %51 = add nuw nsw i64 %50, %32
  %52 = add nuw nsw i64 %51, %42
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  store i64 %48, i64* %54, align 8
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  store i64 %48, i64* %56, align 8
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %48, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %23
  %62 = bitcast i16* %61 to i64*
  store i64 %48, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %48, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %33
  %66 = bitcast i16* %65 to i64*
  store i64 %48, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %48, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %18
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %28
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %38
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  %86 = shl nsw i64 %1, 3
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = bitcast i8* %87 to i16*
  %89 = getelementptr inbounds i8, i8* %87, i64 -2
  %90 = bitcast i8* %89 to i16*
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i64
  %93 = getelementptr inbounds i16, i16* %88, i64 %10
  %94 = load i16, i16* %93, align 2
  %95 = zext i16 %94 to i64
  %96 = getelementptr inbounds i16, i16* %88, i64 %14
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i64
  %99 = getelementptr inbounds i16, i16* %88, i64 %19
  %100 = load i16, i16* %99, align 2
  %101 = zext i16 %100 to i64
  %102 = getelementptr inbounds i16, i16* %88, i64 %24
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i64
  %105 = getelementptr inbounds i16, i16* %88, i64 %29
  %106 = load i16, i16* %105, align 2
  %107 = zext i16 %106 to i64
  %108 = getelementptr inbounds i16, i16* %88, i64 %34
  %109 = load i16, i16* %108, align 2
  %110 = zext i16 %109 to i64
  %111 = getelementptr inbounds i16, i16* %88, i64 %39
  %112 = load i16, i16* %111, align 2
  %113 = zext i16 %112 to i64
  %114 = add nuw nsw i64 %92, 2
  %115 = add nuw nsw i64 %114, %98
  %116 = add nuw nsw i64 %115, %104
  %117 = add nuw nsw i64 %116, %110
  %118 = lshr i64 %117, 2
  %119 = mul i64 %118, 281479271743489
  %120 = add nuw nsw i64 %95, 2
  %121 = add nuw nsw i64 %120, %101
  %122 = add nuw nsw i64 %121, %107
  %123 = add nuw nsw i64 %122, %113
  %124 = lshr i64 %123, 2
  %125 = bitcast i8* %87 to i64*
  store i64 %119, i64* %125, align 8
  %126 = getelementptr inbounds i8, i8* %87, i64 8
  %127 = bitcast i8* %126 to i64*
  store i64 %119, i64* %127, align 8
  %128 = getelementptr inbounds i16, i16* %88, i64 %4
  %129 = bitcast i16* %128 to i64*
  store i64 %119, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %119, i64* %131, align 8
  %132 = getelementptr inbounds i16, i16* %88, i64 %23
  %133 = bitcast i16* %132 to i64*
  store i64 %119, i64* %133, align 8
  %134 = getelementptr inbounds i16, i16* %132, i64 4
  %135 = bitcast i16* %134 to i64*
  store i64 %119, i64* %135, align 8
  %136 = getelementptr inbounds i16, i16* %88, i64 %33
  %137 = bitcast i16* %136 to i64*
  store i64 %119, i64* %137, align 8
  %138 = getelementptr inbounds i16, i16* %136, i64 4
  %139 = bitcast i16* %138 to i64*
  store i64 %119, i64* %139, align 8
  %140 = mul i64 %124, 281479271743489
  %141 = getelementptr inbounds i16, i16* %88, i64 %9
  %142 = bitcast i16* %141 to i64*
  store i64 %140, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %140, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %88, i64 %18
  %146 = bitcast i16* %145 to i64*
  store i64 %140, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %145, i64 4
  %148 = bitcast i16* %147 to i64*
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %88, i64 %28
  %150 = bitcast i16* %149 to i64*
  store i64 %140, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %149, i64 4
  %152 = bitcast i16* %151 to i64*
  store i64 %140, i64* %152, align 8
  %153 = getelementptr inbounds i16, i16* %88, i64 %38
  %154 = bitcast i16* %153 to i64*
  store i64 %140, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %153, i64 4
  %156 = bitcast i16* %155 to i64*
  store i64 %140, i64* %156, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_top_dc_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = add nuw nsw i64 %8, %16
  %18 = sub nsw i64 5, %4
  %19 = getelementptr inbounds i16, i16* %3, i64 %18
  %20 = load i16, i16* %19, align 2
  %21 = zext i16 %20 to i64
  %22 = add nuw nsw i64 %12, %21
  %23 = sub nsw i64 2, %4
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = add nuw nsw i64 %17, %26
  %28 = sub nsw i64 6, %4
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i64
  %32 = add nuw nsw i64 %22, %31
  %33 = sub nsw i64 3, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %27, %36
  %38 = sub nsw i64 7, %4
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i64
  %42 = add nuw nsw i64 %32, %41
  %43 = add nuw nsw i64 %37, 2
  %44 = lshr i64 %43, 2
  %45 = mul i64 %44, 281479271743489
  %46 = add nuw nsw i64 %42, 2
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %45, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %45, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %45, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %45, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %45, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %45, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %45, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %45, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  %86 = shl nsw i64 %4, 3
  %87 = getelementptr inbounds i16, i16* %3, i64 %86
  %88 = bitcast i16* %87 to i64*
  store i64 %45, i64* %88, align 8
  %89 = getelementptr inbounds i16, i16* %87, i64 4
  %90 = bitcast i16* %89 to i64*
  store i64 %48, i64* %90, align 8
  %91 = mul nsw i64 %4, 9
  %92 = getelementptr inbounds i16, i16* %3, i64 %91
  %93 = bitcast i16* %92 to i64*
  store i64 %45, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %48, i64* %95, align 8
  %96 = mul nsw i64 %4, 10
  %97 = getelementptr inbounds i16, i16* %3, i64 %96
  %98 = bitcast i16* %97 to i64*
  store i64 %45, i64* %98, align 8
  %99 = getelementptr inbounds i16, i16* %97, i64 4
  %100 = bitcast i16* %99 to i64*
  store i64 %48, i64* %100, align 8
  %101 = mul nsw i64 %4, 11
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = bitcast i16* %102 to i64*
  store i64 %45, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %102, i64 4
  %105 = bitcast i16* %104 to i64*
  store i64 %48, i64* %105, align 8
  %106 = mul nsw i64 %4, 12
  %107 = getelementptr inbounds i16, i16* %3, i64 %106
  %108 = bitcast i16* %107 to i64*
  store i64 %45, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %107, i64 4
  %110 = bitcast i16* %109 to i64*
  store i64 %48, i64* %110, align 8
  %111 = mul nsw i64 %4, 13
  %112 = getelementptr inbounds i16, i16* %3, i64 %111
  %113 = bitcast i16* %112 to i64*
  store i64 %45, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %112, i64 4
  %115 = bitcast i16* %114 to i64*
  store i64 %48, i64* %115, align 8
  %116 = mul nsw i64 %4, 14
  %117 = getelementptr inbounds i16, i16* %3, i64 %116
  %118 = bitcast i16* %117 to i64*
  store i64 %45, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %117, i64 4
  %120 = bitcast i16* %119 to i64*
  store i64 %48, i64* %120, align 8
  %121 = mul nsw i64 %4, 15
  %122 = getelementptr inbounds i16, i16* %3, i64 %121
  %123 = bitcast i16* %122 to i64*
  store i64 %45, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %122, i64 4
  %125 = bitcast i16* %124 to i64*
  store i64 %48, i64* %125, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_l0t_10(i8*, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = sub nsw i64 5, %4
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub nsw i64 2, %4
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = sub nsw i64 6, %4
  %26 = getelementptr inbounds i16, i16* %3, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i64
  %29 = sub nsw i64 3, %4
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = sub nsw i64 7, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %8, 2
  %38 = add nuw nsw i64 %37, %16
  %39 = add nuw nsw i64 %38, %24
  %40 = add nuw nsw i64 %39, %32
  %41 = lshr i64 %40, 2
  %42 = mul i64 %41, 281479271743489
  %43 = add nuw nsw i64 %12, 2
  %44 = add nuw nsw i64 %43, %20
  %45 = add nuw nsw i64 %44, %28
  %46 = add nuw nsw i64 %45, %36
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %42, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %42, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %42, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %42, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %42, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %42, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %42, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %42, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  %86 = shl nsw i64 %4, 3
  %87 = getelementptr inbounds i16, i16* %3, i64 %86
  %88 = bitcast i16* %87 to i64*
  store i64 %42, i64* %88, align 8
  %89 = getelementptr inbounds i16, i16* %87, i64 4
  %90 = bitcast i16* %89 to i64*
  store i64 %48, i64* %90, align 8
  %91 = mul nsw i64 %4, 9
  %92 = getelementptr inbounds i16, i16* %3, i64 %91
  %93 = bitcast i16* %92 to i64*
  store i64 %42, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %48, i64* %95, align 8
  %96 = mul nsw i64 %4, 10
  %97 = getelementptr inbounds i16, i16* %3, i64 %96
  %98 = bitcast i16* %97 to i64*
  store i64 %42, i64* %98, align 8
  %99 = getelementptr inbounds i16, i16* %97, i64 4
  %100 = bitcast i16* %99 to i64*
  store i64 %48, i64* %100, align 8
  %101 = mul nsw i64 %4, 11
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = bitcast i16* %102 to i64*
  store i64 %42, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %102, i64 4
  %105 = bitcast i16* %104 to i64*
  store i64 %48, i64* %105, align 8
  %106 = mul nsw i64 %4, 12
  %107 = getelementptr inbounds i16, i16* %3, i64 %106
  %108 = bitcast i16* %107 to i64*
  store i64 %42, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %107, i64 4
  %110 = bitcast i16* %109 to i64*
  store i64 %48, i64* %110, align 8
  %111 = mul nsw i64 %4, 13
  %112 = getelementptr inbounds i16, i16* %3, i64 %111
  %113 = bitcast i16* %112 to i64*
  store i64 %42, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %112, i64 4
  %115 = bitcast i16* %114 to i64*
  store i64 %48, i64* %115, align 8
  %116 = mul nsw i64 %4, 14
  %117 = getelementptr inbounds i16, i16* %3, i64 %116
  %118 = bitcast i16* %117 to i64*
  store i64 %42, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %117, i64 4
  %120 = bitcast i16* %119 to i64*
  store i64 %48, i64* %120, align 8
  %121 = mul nsw i64 %4, 15
  %122 = getelementptr inbounds i16, i16* %3, i64 %121
  %123 = bitcast i16* %122 to i64*
  store i64 %42, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %122, i64 4
  %125 = bitcast i16* %124 to i64*
  store i64 %48, i64* %125, align 8
  %126 = lshr i64 %1, 1
  %127 = trunc i64 %126 to i32
  %128 = shl i64 %126, 32
  %129 = sub i64 0, %128
  %130 = ashr exact i64 %129, 32
  %131 = getelementptr inbounds i16, i16* %3, i64 %130
  %132 = load i16, i16* %131, align 2
  %133 = zext i16 %132 to i32
  %134 = sub i64 4294967296, %128
  %135 = ashr exact i64 %134, 32
  %136 = getelementptr inbounds i16, i16* %3, i64 %135
  %137 = load i16, i16* %136, align 2
  %138 = zext i16 %137 to i32
  %139 = sub i64 8589934592, %128
  %140 = ashr exact i64 %139, 32
  %141 = getelementptr inbounds i16, i16* %3, i64 %140
  %142 = load i16, i16* %141, align 2
  %143 = zext i16 %142 to i32
  %144 = sub i64 12884901888, %128
  %145 = ashr exact i64 %144, 32
  %146 = getelementptr inbounds i16, i16* %3, i64 %145
  %147 = load i16, i16* %146, align 2
  %148 = zext i16 %147 to i32
  %149 = getelementptr inbounds i8, i8* %0, i64 -2
  %150 = bitcast i8* %149 to i16*
  %151 = load i16, i16* %150, align 2
  %152 = zext i16 %151 to i32
  %153 = add i64 %128, -4294967296
  %154 = ashr exact i64 %153, 32
  %155 = getelementptr inbounds i16, i16* %3, i64 %154
  %156 = load i16, i16* %155, align 2
  %157 = zext i16 %156 to i32
  %158 = trunc i64 %1 to i32
  %159 = and i32 %158, -2
  %160 = add nsw i32 %159, -1
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds i16, i16* %3, i64 %161
  %163 = load i16, i16* %162, align 2
  %164 = zext i16 %163 to i32
  %165 = mul nsw i32 %127, 3
  %166 = add nsw i32 %165, -1
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds i16, i16* %3, i64 %167
  %169 = load i16, i16* %168, align 2
  %170 = zext i16 %169 to i32
  %171 = add nuw nsw i32 %133, 4
  %172 = add nuw nsw i32 %171, %138
  %173 = add nuw nsw i32 %172, %143
  %174 = add nuw nsw i32 %173, %148
  %175 = add nuw nsw i32 %174, %152
  %176 = add nuw nsw i32 %175, %157
  %177 = add nuw nsw i32 %176, %164
  %178 = add nuw nsw i32 %177, %170
  %179 = ashr i32 %178, 3
  %180 = sext i32 %179 to i64
  %181 = mul i64 %180, 281479271743489
  store i64 %181, i64* %49, align 8
  %182 = ashr exact i64 %128, 32
  %183 = getelementptr inbounds i16, i16* %3, i64 %182
  %184 = bitcast i16* %183 to i64*
  store i64 %181, i64* %184, align 8
  %185 = sext i32 %159 to i64
  %186 = getelementptr inbounds i16, i16* %3, i64 %185
  %187 = bitcast i16* %186 to i64*
  store i64 %181, i64* %187, align 8
  %188 = sext i32 %165 to i64
  %189 = getelementptr inbounds i16, i16* %3, i64 %188
  %190 = bitcast i16* %189 to i64*
  store i64 %181, i64* %190, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_0lt_10(i8* nocapture, i64) #1 {
  tail call void @pred8x16_dc_10_c(i8* %0, i64 %1)
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = sub i64 0, %5
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = sub i64 4294967296, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = load i16, i16* %13, align 2
  %15 = zext i16 %14 to i64
  %16 = sub i64 8589934592, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub i64 12884901888, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i16, i16* %3, i64 %22
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i64
  %26 = add nuw nsw i64 %10, 2
  %27 = add nuw nsw i64 %26, %15
  %28 = add nuw nsw i64 %27, %20
  %29 = add nuw nsw i64 %28, %25
  %30 = lshr i64 %29, 2
  %31 = mul i64 %30, 281479271743489
  %32 = bitcast i8* %0 to i64*
  store i64 %31, i64* %32, align 8
  %33 = ashr exact i64 %5, 32
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %31, i64* %35, align 8
  %36 = shl i64 %1, 32
  %37 = ashr exact i64 %36, 32
  %38 = and i64 %37, -2
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %31, i64* %40, align 8
  %41 = mul i64 %4, 12884901888
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds i16, i16* %3, i64 %42
  %44 = bitcast i16* %43 to i64*
  store i64 %31, i64* %44, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_l00_10(i8* nocapture, i64) #1 {
  tail call void @pred8x16_left_dc_10_c(i8* %0, i64 %1)
  %3 = shl nsw i64 %1, 2
  %4 = getelementptr inbounds i8, i8* %0, i64 %3
  %5 = bitcast i8* %4 to i16*
  %6 = lshr i64 %1, 1
  %7 = bitcast i8* %4 to i64*
  store i64 144117387132666368, i64* %7, align 8
  %8 = shl i64 %6, 32
  %9 = ashr exact i64 %8, 32
  %10 = getelementptr inbounds i16, i16* %5, i64 %9
  %11 = bitcast i16* %10 to i64*
  store i64 144117387132666368, i64* %11, align 8
  %12 = shl i64 %1, 32
  %13 = ashr exact i64 %12, 32
  %14 = and i64 %13, -2
  %15 = getelementptr inbounds i16, i16* %5, i64 %14
  %16 = bitcast i16* %15 to i64*
  store i64 144117387132666368, i64* %16, align 8
  %17 = mul i64 %6, 12884901888
  %18 = ashr exact i64 %17, 32
  %19 = getelementptr inbounds i16, i16* %5, i64 %18
  %20 = bitcast i16* %19 to i64*
  store i64 144117387132666368, i64* %20, align 8
  %21 = getelementptr inbounds i8, i8* %4, i64 8
  %22 = bitcast i8* %21 to i16*
  %23 = bitcast i8* %21 to i64*
  store i64 144117387132666368, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %22, i64 %9
  %25 = bitcast i16* %24 to i64*
  store i64 144117387132666368, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %22, i64 %14
  %27 = bitcast i16* %26 to i64*
  store i64 144117387132666368, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %22, i64 %18
  %29 = bitcast i16* %28 to i64*
  store i64 144117387132666368, i64* %29, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_0l0_10(i8* nocapture, i64) #1 {
  tail call void @pred8x16_left_dc_10_c(i8* %0, i64 %1)
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = bitcast i8* %0 to i64*
  store i64 144117387132666368, i64* %5, align 8
  %6 = shl i64 %4, 32
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  store i64 144117387132666368, i64* %9, align 8
  %10 = shl i64 %1, 32
  %11 = ashr exact i64 %10, 32
  %12 = and i64 %11, -2
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = bitcast i16* %13 to i64*
  store i64 144117387132666368, i64* %14, align 8
  %15 = mul i64 %4, 12884901888
  %16 = ashr exact i64 %15, 32
  %17 = getelementptr inbounds i16, i16* %3, i64 %16
  %18 = bitcast i16* %17 to i64*
  store i64 144117387132666368, i64* %18, align 8
  %19 = getelementptr inbounds i8, i8* %0, i64 8
  %20 = bitcast i8* %19 to i16*
  %21 = bitcast i8* %19 to i64*
  store i64 144117387132666368, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 %7
  %23 = bitcast i16* %22 to i64*
  store i64 144117387132666368, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 %12
  %25 = bitcast i16* %24 to i64*
  store i64 144117387132666368, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 %16
  %27 = bitcast i16* %26 to i64*
  store i64 144117387132666368, i64* %27, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_127_dc_10_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %25, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_129_dc_10_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %25, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_128_dc_10_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %25, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x16_128_dc_10_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %25, align 8
  %26 = shl nsw i64 %1, 3
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = bitcast i8* %27 to i16*
  %29 = bitcast i8* %27 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 %4
  %31 = bitcast i16* %30 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 %8
  %33 = bitcast i16* %32 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 %11
  %35 = bitcast i16* %34 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %14
  %37 = bitcast i16* %36 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %37, align 8
  %38 = getelementptr inbounds i16, i16* %28, i64 %17
  %39 = bitcast i16* %38 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %39, align 8
  %40 = getelementptr inbounds i16, i16* %28, i64 %20
  %41 = bitcast i16* %40 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %41, align 8
  %42 = getelementptr inbounds i16, i16* %28, i64 %23
  %43 = bitcast i16* %42 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %43, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_dc_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = add nsw i64 %4, -1
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = and i64 %1, -2
  %15 = add nsw i64 %14, -1
  %16 = getelementptr inbounds i16, i16* %3, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i64
  %19 = add nuw nsw i64 %13, %18
  %20 = mul nsw i64 %4, 3
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = add nuw nsw i64 %19, %24
  %26 = shl nsw i64 %4, 2
  %27 = add nsw i64 %26, -1
  %28 = getelementptr inbounds i16, i16* %3, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = zext i16 %29 to i64
  %31 = add nuw nsw i64 %25, %30
  %32 = mul nsw i64 %4, 5
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %31, %36
  %38 = mul nsw i64 %4, 6
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %37, %42
  %44 = mul nsw i64 %4, 7
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = add nuw nsw i64 %43, %48
  %50 = shl nsw i64 %4, 3
  %51 = add nsw i64 %50, -1
  %52 = getelementptr inbounds i16, i16* %3, i64 %51
  %53 = load i16, i16* %52, align 2
  %54 = zext i16 %53 to i64
  %55 = add nuw nsw i64 %49, %54
  %56 = mul nsw i64 %4, 9
  %57 = add nsw i64 %56, -1
  %58 = getelementptr inbounds i16, i16* %3, i64 %57
  %59 = load i16, i16* %58, align 2
  %60 = zext i16 %59 to i64
  %61 = add nuw nsw i64 %55, %60
  %62 = mul nsw i64 %4, 10
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = add nuw nsw i64 %61, %66
  %68 = mul nsw i64 %4, 11
  %69 = add nsw i64 %68, -1
  %70 = getelementptr inbounds i16, i16* %3, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i64
  %73 = add nuw nsw i64 %67, %72
  %74 = mul nsw i64 %4, 12
  %75 = add nsw i64 %74, -1
  %76 = getelementptr inbounds i16, i16* %3, i64 %75
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i64
  %79 = add nuw nsw i64 %73, %78
  %80 = mul nsw i64 %4, 13
  %81 = add nsw i64 %80, -1
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = zext i16 %83 to i64
  %85 = add nuw nsw i64 %79, %84
  %86 = mul nsw i64 %4, 14
  %87 = add nsw i64 %86, -1
  %88 = getelementptr inbounds i16, i16* %3, i64 %87
  %89 = load i16, i16* %88, align 2
  %90 = zext i16 %89 to i64
  %91 = add nuw nsw i64 %85, %90
  %92 = mul nsw i64 %4, 15
  %93 = add nsw i64 %92, -1
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i64
  %97 = add nuw nsw i64 %91, %96
  %98 = sub nsw i64 0, %4
  %99 = getelementptr inbounds i16, i16* %3, i64 %98
  %100 = load i16, i16* %99, align 2
  %101 = zext i16 %100 to i64
  %102 = add nuw nsw i64 %97, %101
  %103 = sub nsw i64 1, %4
  %104 = getelementptr inbounds i16, i16* %3, i64 %103
  %105 = load i16, i16* %104, align 2
  %106 = zext i16 %105 to i64
  %107 = add nuw nsw i64 %102, %106
  %108 = sub nsw i64 2, %4
  %109 = getelementptr inbounds i16, i16* %3, i64 %108
  %110 = load i16, i16* %109, align 2
  %111 = zext i16 %110 to i64
  %112 = add nuw nsw i64 %107, %111
  %113 = sub nsw i64 3, %4
  %114 = getelementptr inbounds i16, i16* %3, i64 %113
  %115 = load i16, i16* %114, align 2
  %116 = zext i16 %115 to i64
  %117 = add nuw nsw i64 %112, %116
  %118 = sub nsw i64 4, %4
  %119 = getelementptr inbounds i16, i16* %3, i64 %118
  %120 = load i16, i16* %119, align 2
  %121 = zext i16 %120 to i64
  %122 = add nuw nsw i64 %117, %121
  %123 = sub nsw i64 5, %4
  %124 = getelementptr inbounds i16, i16* %3, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i64
  %127 = add nuw nsw i64 %122, %126
  %128 = sub nsw i64 6, %4
  %129 = getelementptr inbounds i16, i16* %3, i64 %128
  %130 = load i16, i16* %129, align 2
  %131 = zext i16 %130 to i64
  %132 = add nuw nsw i64 %127, %131
  %133 = sub nsw i64 7, %4
  %134 = getelementptr inbounds i16, i16* %3, i64 %133
  %135 = load i16, i16* %134, align 2
  %136 = zext i16 %135 to i64
  %137 = add nuw nsw i64 %132, %136
  %138 = sub nsw i64 8, %4
  %139 = getelementptr inbounds i16, i16* %3, i64 %138
  %140 = load i16, i16* %139, align 2
  %141 = zext i16 %140 to i64
  %142 = add nuw nsw i64 %137, %141
  %143 = sub nsw i64 9, %4
  %144 = getelementptr inbounds i16, i16* %3, i64 %143
  %145 = load i16, i16* %144, align 2
  %146 = zext i16 %145 to i64
  %147 = add nuw nsw i64 %142, %146
  %148 = sub nsw i64 10, %4
  %149 = getelementptr inbounds i16, i16* %3, i64 %148
  %150 = load i16, i16* %149, align 2
  %151 = zext i16 %150 to i64
  %152 = add nuw nsw i64 %147, %151
  %153 = sub nsw i64 11, %4
  %154 = getelementptr inbounds i16, i16* %3, i64 %153
  %155 = load i16, i16* %154, align 2
  %156 = zext i16 %155 to i64
  %157 = add nuw nsw i64 %152, %156
  %158 = sub nsw i64 12, %4
  %159 = getelementptr inbounds i16, i16* %3, i64 %158
  %160 = load i16, i16* %159, align 2
  %161 = zext i16 %160 to i64
  %162 = add nuw nsw i64 %157, %161
  %163 = sub nsw i64 13, %4
  %164 = getelementptr inbounds i16, i16* %3, i64 %163
  %165 = load i16, i16* %164, align 2
  %166 = zext i16 %165 to i64
  %167 = add nuw nsw i64 %162, %166
  %168 = sub nsw i64 14, %4
  %169 = getelementptr inbounds i16, i16* %3, i64 %168
  %170 = load i16, i16* %169, align 2
  %171 = zext i16 %170 to i64
  %172 = add nuw nsw i64 %167, %171
  %173 = sub nsw i64 15, %4
  %174 = getelementptr inbounds i16, i16* %3, i64 %173
  %175 = load i16, i16* %174, align 2
  %176 = zext i16 %175 to i64
  %177 = add nuw nsw i64 %172, %176
  %178 = add nuw nsw i64 %177, 16
  %179 = lshr i64 %178, 5
  %180 = and i64 %179, 134217727
  %181 = mul i64 %180, 281479271743489
  %182 = bitcast i8* %0 to i64*
  store i64 %181, i64* %182, align 8
  %183 = getelementptr inbounds i8, i8* %0, i64 8
  %184 = bitcast i8* %183 to i64*
  store i64 %181, i64* %184, align 8
  %185 = getelementptr inbounds i8, i8* %0, i64 16
  %186 = bitcast i8* %185 to i64*
  store i64 %181, i64* %186, align 8
  %187 = getelementptr inbounds i8, i8* %0, i64 24
  %188 = bitcast i8* %187 to i64*
  store i64 %181, i64* %188, align 8
  %189 = getelementptr inbounds i16, i16* %3, i64 %4
  %190 = bitcast i16* %189 to i64*
  store i64 %181, i64* %190, align 8
  %191 = getelementptr inbounds i16, i16* %189, i64 4
  %192 = bitcast i16* %191 to i64*
  store i64 %181, i64* %192, align 8
  %193 = getelementptr inbounds i16, i16* %189, i64 8
  %194 = bitcast i16* %193 to i64*
  store i64 %181, i64* %194, align 8
  %195 = getelementptr inbounds i16, i16* %189, i64 12
  %196 = bitcast i16* %195 to i64*
  store i64 %181, i64* %196, align 8
  %197 = getelementptr inbounds i16, i16* %189, i64 %4
  %198 = bitcast i16* %197 to i64*
  store i64 %181, i64* %198, align 8
  %199 = getelementptr inbounds i16, i16* %197, i64 4
  %200 = bitcast i16* %199 to i64*
  store i64 %181, i64* %200, align 8
  %201 = getelementptr inbounds i16, i16* %197, i64 8
  %202 = bitcast i16* %201 to i64*
  store i64 %181, i64* %202, align 8
  %203 = getelementptr inbounds i16, i16* %197, i64 12
  %204 = bitcast i16* %203 to i64*
  store i64 %181, i64* %204, align 8
  %205 = getelementptr inbounds i16, i16* %197, i64 %4
  %206 = bitcast i16* %205 to i64*
  store i64 %181, i64* %206, align 8
  %207 = getelementptr inbounds i16, i16* %205, i64 4
  %208 = bitcast i16* %207 to i64*
  store i64 %181, i64* %208, align 8
  %209 = getelementptr inbounds i16, i16* %205, i64 8
  %210 = bitcast i16* %209 to i64*
  store i64 %181, i64* %210, align 8
  %211 = getelementptr inbounds i16, i16* %205, i64 12
  %212 = bitcast i16* %211 to i64*
  store i64 %181, i64* %212, align 8
  %213 = getelementptr inbounds i16, i16* %205, i64 %4
  %214 = bitcast i16* %213 to i64*
  store i64 %181, i64* %214, align 8
  %215 = getelementptr inbounds i16, i16* %213, i64 4
  %216 = bitcast i16* %215 to i64*
  store i64 %181, i64* %216, align 8
  %217 = getelementptr inbounds i16, i16* %213, i64 8
  %218 = bitcast i16* %217 to i64*
  store i64 %181, i64* %218, align 8
  %219 = getelementptr inbounds i16, i16* %213, i64 12
  %220 = bitcast i16* %219 to i64*
  store i64 %181, i64* %220, align 8
  %221 = getelementptr inbounds i16, i16* %213, i64 %4
  %222 = bitcast i16* %221 to i64*
  store i64 %181, i64* %222, align 8
  %223 = getelementptr inbounds i16, i16* %221, i64 4
  %224 = bitcast i16* %223 to i64*
  store i64 %181, i64* %224, align 8
  %225 = getelementptr inbounds i16, i16* %221, i64 8
  %226 = bitcast i16* %225 to i64*
  store i64 %181, i64* %226, align 8
  %227 = getelementptr inbounds i16, i16* %221, i64 12
  %228 = bitcast i16* %227 to i64*
  store i64 %181, i64* %228, align 8
  %229 = getelementptr inbounds i16, i16* %221, i64 %4
  %230 = bitcast i16* %229 to i64*
  store i64 %181, i64* %230, align 8
  %231 = getelementptr inbounds i16, i16* %229, i64 4
  %232 = bitcast i16* %231 to i64*
  store i64 %181, i64* %232, align 8
  %233 = getelementptr inbounds i16, i16* %229, i64 8
  %234 = bitcast i16* %233 to i64*
  store i64 %181, i64* %234, align 8
  %235 = getelementptr inbounds i16, i16* %229, i64 12
  %236 = bitcast i16* %235 to i64*
  store i64 %181, i64* %236, align 8
  %237 = getelementptr inbounds i16, i16* %229, i64 %4
  %238 = bitcast i16* %237 to i64*
  store i64 %181, i64* %238, align 8
  %239 = getelementptr inbounds i16, i16* %237, i64 4
  %240 = bitcast i16* %239 to i64*
  store i64 %181, i64* %240, align 8
  %241 = getelementptr inbounds i16, i16* %237, i64 8
  %242 = bitcast i16* %241 to i64*
  store i64 %181, i64* %242, align 8
  %243 = getelementptr inbounds i16, i16* %237, i64 12
  %244 = bitcast i16* %243 to i64*
  store i64 %181, i64* %244, align 8
  %245 = getelementptr inbounds i16, i16* %237, i64 %4
  %246 = bitcast i16* %245 to i64*
  store i64 %181, i64* %246, align 8
  %247 = getelementptr inbounds i16, i16* %245, i64 4
  %248 = bitcast i16* %247 to i64*
  store i64 %181, i64* %248, align 8
  %249 = getelementptr inbounds i16, i16* %245, i64 8
  %250 = bitcast i16* %249 to i64*
  store i64 %181, i64* %250, align 8
  %251 = getelementptr inbounds i16, i16* %245, i64 12
  %252 = bitcast i16* %251 to i64*
  store i64 %181, i64* %252, align 8
  %253 = getelementptr inbounds i16, i16* %245, i64 %4
  %254 = bitcast i16* %253 to i64*
  store i64 %181, i64* %254, align 8
  %255 = getelementptr inbounds i16, i16* %253, i64 4
  %256 = bitcast i16* %255 to i64*
  store i64 %181, i64* %256, align 8
  %257 = getelementptr inbounds i16, i16* %253, i64 8
  %258 = bitcast i16* %257 to i64*
  store i64 %181, i64* %258, align 8
  %259 = getelementptr inbounds i16, i16* %253, i64 12
  %260 = bitcast i16* %259 to i64*
  store i64 %181, i64* %260, align 8
  %261 = getelementptr inbounds i16, i16* %253, i64 %4
  %262 = bitcast i16* %261 to i64*
  store i64 %181, i64* %262, align 8
  %263 = getelementptr inbounds i16, i16* %261, i64 4
  %264 = bitcast i16* %263 to i64*
  store i64 %181, i64* %264, align 8
  %265 = getelementptr inbounds i16, i16* %261, i64 8
  %266 = bitcast i16* %265 to i64*
  store i64 %181, i64* %266, align 8
  %267 = getelementptr inbounds i16, i16* %261, i64 12
  %268 = bitcast i16* %267 to i64*
  store i64 %181, i64* %268, align 8
  %269 = getelementptr inbounds i16, i16* %261, i64 %4
  %270 = bitcast i16* %269 to i64*
  store i64 %181, i64* %270, align 8
  %271 = getelementptr inbounds i16, i16* %269, i64 4
  %272 = bitcast i16* %271 to i64*
  store i64 %181, i64* %272, align 8
  %273 = getelementptr inbounds i16, i16* %269, i64 8
  %274 = bitcast i16* %273 to i64*
  store i64 %181, i64* %274, align 8
  %275 = getelementptr inbounds i16, i16* %269, i64 12
  %276 = bitcast i16* %275 to i64*
  store i64 %181, i64* %276, align 8
  %277 = getelementptr inbounds i16, i16* %269, i64 %4
  %278 = bitcast i16* %277 to i64*
  store i64 %181, i64* %278, align 8
  %279 = getelementptr inbounds i16, i16* %277, i64 4
  %280 = bitcast i16* %279 to i64*
  store i64 %181, i64* %280, align 8
  %281 = getelementptr inbounds i16, i16* %277, i64 8
  %282 = bitcast i16* %281 to i64*
  store i64 %181, i64* %282, align 8
  %283 = getelementptr inbounds i16, i16* %277, i64 12
  %284 = bitcast i16* %283 to i64*
  store i64 %181, i64* %284, align 8
  %285 = getelementptr inbounds i16, i16* %277, i64 %4
  %286 = bitcast i16* %285 to i64*
  store i64 %181, i64* %286, align 8
  %287 = getelementptr inbounds i16, i16* %285, i64 4
  %288 = bitcast i16* %287 to i64*
  store i64 %181, i64* %288, align 8
  %289 = getelementptr inbounds i16, i16* %285, i64 8
  %290 = bitcast i16* %289 to i64*
  store i64 %181, i64* %290, align 8
  %291 = getelementptr inbounds i16, i16* %285, i64 12
  %292 = bitcast i16* %291 to i64*
  store i64 %181, i64* %292, align 8
  %293 = getelementptr inbounds i16, i16* %285, i64 %4
  %294 = bitcast i16* %293 to i64*
  store i64 %181, i64* %294, align 8
  %295 = getelementptr inbounds i16, i16* %293, i64 4
  %296 = bitcast i16* %295 to i64*
  store i64 %181, i64* %296, align 8
  %297 = getelementptr inbounds i16, i16* %293, i64 8
  %298 = bitcast i16* %297 to i64*
  store i64 %181, i64* %298, align 8
  %299 = getelementptr inbounds i16, i16* %293, i64 12
  %300 = bitcast i16* %299 to i64*
  store i64 %181, i64* %300, align 8
  %301 = getelementptr inbounds i16, i16* %293, i64 %4
  %302 = bitcast i16* %301 to i64*
  store i64 %181, i64* %302, align 8
  %303 = getelementptr inbounds i16, i16* %301, i64 4
  %304 = bitcast i16* %303 to i64*
  store i64 %181, i64* %304, align 8
  %305 = getelementptr inbounds i16, i16* %301, i64 8
  %306 = bitcast i16* %305 to i64*
  store i64 %181, i64* %306, align 8
  %307 = getelementptr inbounds i16, i16* %301, i64 12
  %308 = bitcast i16* %307 to i64*
  store i64 %181, i64* %308, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_vertical_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds i16, i16* %8, i64 4
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = getelementptr inbounds i16, i16* %8, i64 8
  %15 = bitcast i16* %14 to i64*
  %16 = load i64, i64* %15, align 8
  %17 = getelementptr inbounds i16, i16* %8, i64 12
  %18 = bitcast i16* %17 to i64*
  %19 = load i64, i64* %18, align 8
  %20 = shl i64 %4, 32
  %21 = ashr exact i64 %20, 32
  %22 = bitcast i8* %0 to i64*
  store i64 %10, i64* %22, align 8
  %23 = getelementptr inbounds i8, i8* %0, i64 8
  %24 = bitcast i8* %23 to i64*
  store i64 %13, i64* %24, align 8
  %25 = getelementptr inbounds i8, i8* %0, i64 16
  %26 = bitcast i8* %25 to i64*
  store i64 %16, i64* %26, align 8
  %27 = getelementptr inbounds i8, i8* %0, i64 24
  %28 = bitcast i8* %27 to i64*
  store i64 %19, i64* %28, align 8
  %29 = getelementptr inbounds i16, i16* %3, i64 %21
  %30 = bitcast i16* %29 to i64*
  store i64 %10, i64* %30, align 8
  %31 = getelementptr inbounds i16, i16* %29, i64 4
  %32 = bitcast i16* %31 to i64*
  store i64 %13, i64* %32, align 8
  %33 = getelementptr inbounds i16, i16* %29, i64 8
  %34 = bitcast i16* %33 to i64*
  store i64 %16, i64* %34, align 8
  %35 = getelementptr inbounds i16, i16* %29, i64 12
  %36 = bitcast i16* %35 to i64*
  store i64 %19, i64* %36, align 8
  %37 = ashr exact i64 %20, 31
  %38 = getelementptr inbounds i16, i16* %3, i64 %37
  %39 = bitcast i16* %38 to i64*
  store i64 %10, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %38, i64 4
  %41 = bitcast i16* %40 to i64*
  store i64 %13, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %38, i64 8
  %43 = bitcast i16* %42 to i64*
  store i64 %16, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %38, i64 12
  %45 = bitcast i16* %44 to i64*
  store i64 %19, i64* %45, align 8
  %46 = mul nsw i64 %21, 3
  %47 = getelementptr inbounds i16, i16* %3, i64 %46
  %48 = bitcast i16* %47 to i64*
  store i64 %10, i64* %48, align 8
  %49 = getelementptr inbounds i16, i16* %47, i64 4
  %50 = bitcast i16* %49 to i64*
  store i64 %13, i64* %50, align 8
  %51 = getelementptr inbounds i16, i16* %47, i64 8
  %52 = bitcast i16* %51 to i64*
  store i64 %16, i64* %52, align 8
  %53 = getelementptr inbounds i16, i16* %47, i64 12
  %54 = bitcast i16* %53 to i64*
  store i64 %19, i64* %54, align 8
  %55 = ashr exact i64 %20, 30
  %56 = getelementptr inbounds i16, i16* %3, i64 %55
  %57 = bitcast i16* %56 to i64*
  store i64 %10, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %56, i64 4
  %59 = bitcast i16* %58 to i64*
  store i64 %13, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %56, i64 8
  %61 = bitcast i16* %60 to i64*
  store i64 %16, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %56, i64 12
  %63 = bitcast i16* %62 to i64*
  store i64 %19, i64* %63, align 8
  %64 = mul nsw i64 %21, 5
  %65 = getelementptr inbounds i16, i16* %3, i64 %64
  %66 = bitcast i16* %65 to i64*
  store i64 %10, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %13, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %65, i64 8
  %70 = bitcast i16* %69 to i64*
  store i64 %16, i64* %70, align 8
  %71 = getelementptr inbounds i16, i16* %65, i64 12
  %72 = bitcast i16* %71 to i64*
  store i64 %19, i64* %72, align 8
  %73 = mul nsw i64 %21, 6
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = bitcast i16* %74 to i64*
  store i64 %10, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %13, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %74, i64 8
  %79 = bitcast i16* %78 to i64*
  store i64 %16, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %74, i64 12
  %81 = bitcast i16* %80 to i64*
  store i64 %19, i64* %81, align 8
  %82 = mul nsw i64 %21, 7
  %83 = getelementptr inbounds i16, i16* %3, i64 %82
  %84 = bitcast i16* %83 to i64*
  store i64 %10, i64* %84, align 8
  %85 = getelementptr inbounds i16, i16* %83, i64 4
  %86 = bitcast i16* %85 to i64*
  store i64 %13, i64* %86, align 8
  %87 = getelementptr inbounds i16, i16* %83, i64 8
  %88 = bitcast i16* %87 to i64*
  store i64 %16, i64* %88, align 8
  %89 = getelementptr inbounds i16, i16* %83, i64 12
  %90 = bitcast i16* %89 to i64*
  store i64 %19, i64* %90, align 8
  %91 = ashr exact i64 %20, 29
  %92 = getelementptr inbounds i16, i16* %3, i64 %91
  %93 = bitcast i16* %92 to i64*
  store i64 %10, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %13, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 %16, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 %19, i64* %99, align 8
  %100 = mul nsw i64 %21, 9
  %101 = getelementptr inbounds i16, i16* %3, i64 %100
  %102 = bitcast i16* %101 to i64*
  store i64 %10, i64* %102, align 8
  %103 = getelementptr inbounds i16, i16* %101, i64 4
  %104 = bitcast i16* %103 to i64*
  store i64 %13, i64* %104, align 8
  %105 = getelementptr inbounds i16, i16* %101, i64 8
  %106 = bitcast i16* %105 to i64*
  store i64 %16, i64* %106, align 8
  %107 = getelementptr inbounds i16, i16* %101, i64 12
  %108 = bitcast i16* %107 to i64*
  store i64 %19, i64* %108, align 8
  %109 = mul nsw i64 %21, 10
  %110 = getelementptr inbounds i16, i16* %3, i64 %109
  %111 = bitcast i16* %110 to i64*
  store i64 %10, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %110, i64 4
  %113 = bitcast i16* %112 to i64*
  store i64 %13, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %110, i64 8
  %115 = bitcast i16* %114 to i64*
  store i64 %16, i64* %115, align 8
  %116 = getelementptr inbounds i16, i16* %110, i64 12
  %117 = bitcast i16* %116 to i64*
  store i64 %19, i64* %117, align 8
  %118 = mul nsw i64 %21, 11
  %119 = getelementptr inbounds i16, i16* %3, i64 %118
  %120 = bitcast i16* %119 to i64*
  store i64 %10, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %119, i64 4
  %122 = bitcast i16* %121 to i64*
  store i64 %13, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %119, i64 8
  %124 = bitcast i16* %123 to i64*
  store i64 %16, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %119, i64 12
  %126 = bitcast i16* %125 to i64*
  store i64 %19, i64* %126, align 8
  %127 = mul nsw i64 %21, 12
  %128 = getelementptr inbounds i16, i16* %3, i64 %127
  %129 = bitcast i16* %128 to i64*
  store i64 %10, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %13, i64* %131, align 8
  %132 = getelementptr inbounds i16, i16* %128, i64 8
  %133 = bitcast i16* %132 to i64*
  store i64 %16, i64* %133, align 8
  %134 = getelementptr inbounds i16, i16* %128, i64 12
  %135 = bitcast i16* %134 to i64*
  store i64 %19, i64* %135, align 8
  %136 = mul nsw i64 %21, 13
  %137 = getelementptr inbounds i16, i16* %3, i64 %136
  %138 = bitcast i16* %137 to i64*
  store i64 %10, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %137, i64 4
  %140 = bitcast i16* %139 to i64*
  store i64 %13, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %137, i64 8
  %142 = bitcast i16* %141 to i64*
  store i64 %16, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %137, i64 12
  %144 = bitcast i16* %143 to i64*
  store i64 %19, i64* %144, align 8
  %145 = mul nsw i64 %21, 14
  %146 = getelementptr inbounds i16, i16* %3, i64 %145
  %147 = bitcast i16* %146 to i64*
  store i64 %10, i64* %147, align 8
  %148 = getelementptr inbounds i16, i16* %146, i64 4
  %149 = bitcast i16* %148 to i64*
  store i64 %13, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %146, i64 8
  %151 = bitcast i16* %150 to i64*
  store i64 %16, i64* %151, align 8
  %152 = getelementptr inbounds i16, i16* %146, i64 12
  %153 = bitcast i16* %152 to i64*
  store i64 %19, i64* %153, align 8
  %154 = mul nsw i64 %21, 15
  %155 = getelementptr inbounds i16, i16* %3, i64 %154
  %156 = bitcast i16* %155 to i64*
  store i64 %10, i64* %156, align 8
  %157 = getelementptr inbounds i16, i16* %155, i64 4
  %158 = bitcast i16* %157 to i64*
  store i64 %13, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %155, i64 8
  %160 = bitcast i16* %159 to i64*
  store i64 %16, i64* %160, align 8
  %161 = getelementptr inbounds i16, i16* %155, i64 12
  %162 = bitcast i16* %161 to i64*
  store i64 %19, i64* %162, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_horizontal_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = mul nuw i64 %8, 281479271743489
  %10 = bitcast i8* %0 to i64*
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to i64*
  store i64 %9, i64* %12, align 8
  %13 = getelementptr inbounds i8, i8* %0, i64 16
  %14 = bitcast i8* %13 to i64*
  store i64 %9, i64* %14, align 8
  %15 = getelementptr inbounds i8, i8* %0, i64 24
  %16 = bitcast i8* %15 to i64*
  store i64 %9, i64* %16, align 8
  %17 = add nsw i64 %4, -1
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = mul nuw i64 %20, 281479271743489
  %22 = getelementptr inbounds i16, i16* %3, i64 %4
  %23 = bitcast i16* %22 to i64*
  store i64 %21, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %22, i64 4
  %25 = bitcast i16* %24 to i64*
  store i64 %21, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %22, i64 8
  %27 = bitcast i16* %26 to i64*
  store i64 %21, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %22, i64 12
  %29 = bitcast i16* %28 to i64*
  store i64 %21, i64* %29, align 8
  %30 = and i64 %1, -2
  %31 = add nsw i64 %30, -1
  %32 = getelementptr inbounds i16, i16* %3, i64 %31
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i64
  %35 = mul nuw i64 %34, 281479271743489
  %36 = getelementptr inbounds i16, i16* %3, i64 %30
  %37 = bitcast i16* %36 to i64*
  store i64 %35, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 %35, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 %35, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 %35, i64* %43, align 8
  %44 = mul nsw i64 %4, 3
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = mul nuw i64 %48, 281479271743489
  %50 = getelementptr inbounds i16, i16* %3, i64 %44
  %51 = bitcast i16* %50 to i64*
  store i64 %49, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %50, i64 4
  %53 = bitcast i16* %52 to i64*
  store i64 %49, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %50, i64 8
  %55 = bitcast i16* %54 to i64*
  store i64 %49, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %50, i64 12
  %57 = bitcast i16* %56 to i64*
  store i64 %49, i64* %57, align 8
  %58 = shl nsw i64 %4, 2
  %59 = add nsw i64 %58, -1
  %60 = getelementptr inbounds i16, i16* %3, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i64
  %63 = mul nuw i64 %62, 281479271743489
  %64 = getelementptr inbounds i16, i16* %3, i64 %58
  %65 = bitcast i16* %64 to i64*
  store i64 %63, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %64, i64 4
  %67 = bitcast i16* %66 to i64*
  store i64 %63, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %64, i64 8
  %69 = bitcast i16* %68 to i64*
  store i64 %63, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %64, i64 12
  %71 = bitcast i16* %70 to i64*
  store i64 %63, i64* %71, align 8
  %72 = mul nsw i64 %4, 5
  %73 = add nsw i64 %72, -1
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i64
  %77 = mul nuw i64 %76, 281479271743489
  %78 = getelementptr inbounds i16, i16* %3, i64 %72
  %79 = bitcast i16* %78 to i64*
  store i64 %77, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %77, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %78, i64 8
  %83 = bitcast i16* %82 to i64*
  store i64 %77, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %78, i64 12
  %85 = bitcast i16* %84 to i64*
  store i64 %77, i64* %85, align 8
  %86 = mul nsw i64 %4, 6
  %87 = add nsw i64 %86, -1
  %88 = getelementptr inbounds i16, i16* %3, i64 %87
  %89 = load i16, i16* %88, align 2
  %90 = zext i16 %89 to i64
  %91 = mul nuw i64 %90, 281479271743489
  %92 = getelementptr inbounds i16, i16* %3, i64 %86
  %93 = bitcast i16* %92 to i64*
  store i64 %91, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %91, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 %91, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 %91, i64* %99, align 8
  %100 = mul nsw i64 %4, 7
  %101 = add nsw i64 %100, -1
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i64
  %105 = mul nuw i64 %104, 281479271743489
  %106 = getelementptr inbounds i16, i16* %3, i64 %100
  %107 = bitcast i16* %106 to i64*
  store i64 %105, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %106, i64 4
  %109 = bitcast i16* %108 to i64*
  store i64 %105, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %106, i64 8
  %111 = bitcast i16* %110 to i64*
  store i64 %105, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %106, i64 12
  %113 = bitcast i16* %112 to i64*
  store i64 %105, i64* %113, align 8
  %114 = shl nsw i64 %4, 3
  %115 = add nsw i64 %114, -1
  %116 = getelementptr inbounds i16, i16* %3, i64 %115
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i64
  %119 = mul nuw i64 %118, 281479271743489
  %120 = getelementptr inbounds i16, i16* %3, i64 %114
  %121 = bitcast i16* %120 to i64*
  store i64 %119, i64* %121, align 8
  %122 = getelementptr inbounds i16, i16* %120, i64 4
  %123 = bitcast i16* %122 to i64*
  store i64 %119, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %120, i64 8
  %125 = bitcast i16* %124 to i64*
  store i64 %119, i64* %125, align 8
  %126 = getelementptr inbounds i16, i16* %120, i64 12
  %127 = bitcast i16* %126 to i64*
  store i64 %119, i64* %127, align 8
  %128 = mul nsw i64 %4, 9
  %129 = add nsw i64 %128, -1
  %130 = getelementptr inbounds i16, i16* %3, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i64
  %133 = mul nuw i64 %132, 281479271743489
  %134 = getelementptr inbounds i16, i16* %3, i64 %128
  %135 = bitcast i16* %134 to i64*
  store i64 %133, i64* %135, align 8
  %136 = getelementptr inbounds i16, i16* %134, i64 4
  %137 = bitcast i16* %136 to i64*
  store i64 %133, i64* %137, align 8
  %138 = getelementptr inbounds i16, i16* %134, i64 8
  %139 = bitcast i16* %138 to i64*
  store i64 %133, i64* %139, align 8
  %140 = getelementptr inbounds i16, i16* %134, i64 12
  %141 = bitcast i16* %140 to i64*
  store i64 %133, i64* %141, align 8
  %142 = mul nsw i64 %4, 10
  %143 = add nsw i64 %142, -1
  %144 = getelementptr inbounds i16, i16* %3, i64 %143
  %145 = load i16, i16* %144, align 2
  %146 = zext i16 %145 to i64
  %147 = mul nuw i64 %146, 281479271743489
  %148 = getelementptr inbounds i16, i16* %3, i64 %142
  %149 = bitcast i16* %148 to i64*
  store i64 %147, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %148, i64 4
  %151 = bitcast i16* %150 to i64*
  store i64 %147, i64* %151, align 8
  %152 = getelementptr inbounds i16, i16* %148, i64 8
  %153 = bitcast i16* %152 to i64*
  store i64 %147, i64* %153, align 8
  %154 = getelementptr inbounds i16, i16* %148, i64 12
  %155 = bitcast i16* %154 to i64*
  store i64 %147, i64* %155, align 8
  %156 = mul nsw i64 %4, 11
  %157 = add nsw i64 %156, -1
  %158 = getelementptr inbounds i16, i16* %3, i64 %157
  %159 = load i16, i16* %158, align 2
  %160 = zext i16 %159 to i64
  %161 = mul nuw i64 %160, 281479271743489
  %162 = getelementptr inbounds i16, i16* %3, i64 %156
  %163 = bitcast i16* %162 to i64*
  store i64 %161, i64* %163, align 8
  %164 = getelementptr inbounds i16, i16* %162, i64 4
  %165 = bitcast i16* %164 to i64*
  store i64 %161, i64* %165, align 8
  %166 = getelementptr inbounds i16, i16* %162, i64 8
  %167 = bitcast i16* %166 to i64*
  store i64 %161, i64* %167, align 8
  %168 = getelementptr inbounds i16, i16* %162, i64 12
  %169 = bitcast i16* %168 to i64*
  store i64 %161, i64* %169, align 8
  %170 = mul nsw i64 %4, 12
  %171 = add nsw i64 %170, -1
  %172 = getelementptr inbounds i16, i16* %3, i64 %171
  %173 = load i16, i16* %172, align 2
  %174 = zext i16 %173 to i64
  %175 = mul nuw i64 %174, 281479271743489
  %176 = getelementptr inbounds i16, i16* %3, i64 %170
  %177 = bitcast i16* %176 to i64*
  store i64 %175, i64* %177, align 8
  %178 = getelementptr inbounds i16, i16* %176, i64 4
  %179 = bitcast i16* %178 to i64*
  store i64 %175, i64* %179, align 8
  %180 = getelementptr inbounds i16, i16* %176, i64 8
  %181 = bitcast i16* %180 to i64*
  store i64 %175, i64* %181, align 8
  %182 = getelementptr inbounds i16, i16* %176, i64 12
  %183 = bitcast i16* %182 to i64*
  store i64 %175, i64* %183, align 8
  %184 = mul nsw i64 %4, 13
  %185 = add nsw i64 %184, -1
  %186 = getelementptr inbounds i16, i16* %3, i64 %185
  %187 = load i16, i16* %186, align 2
  %188 = zext i16 %187 to i64
  %189 = mul nuw i64 %188, 281479271743489
  %190 = getelementptr inbounds i16, i16* %3, i64 %184
  %191 = bitcast i16* %190 to i64*
  store i64 %189, i64* %191, align 8
  %192 = getelementptr inbounds i16, i16* %190, i64 4
  %193 = bitcast i16* %192 to i64*
  store i64 %189, i64* %193, align 8
  %194 = getelementptr inbounds i16, i16* %190, i64 8
  %195 = bitcast i16* %194 to i64*
  store i64 %189, i64* %195, align 8
  %196 = getelementptr inbounds i16, i16* %190, i64 12
  %197 = bitcast i16* %196 to i64*
  store i64 %189, i64* %197, align 8
  %198 = mul nsw i64 %4, 14
  %199 = add nsw i64 %198, -1
  %200 = getelementptr inbounds i16, i16* %3, i64 %199
  %201 = load i16, i16* %200, align 2
  %202 = zext i16 %201 to i64
  %203 = mul nuw i64 %202, 281479271743489
  %204 = getelementptr inbounds i16, i16* %3, i64 %198
  %205 = bitcast i16* %204 to i64*
  store i64 %203, i64* %205, align 8
  %206 = getelementptr inbounds i16, i16* %204, i64 4
  %207 = bitcast i16* %206 to i64*
  store i64 %203, i64* %207, align 8
  %208 = getelementptr inbounds i16, i16* %204, i64 8
  %209 = bitcast i16* %208 to i64*
  store i64 %203, i64* %209, align 8
  %210 = getelementptr inbounds i16, i16* %204, i64 12
  %211 = bitcast i16* %210 to i64*
  store i64 %203, i64* %211, align 8
  %212 = mul nsw i64 %4, 15
  %213 = add nsw i64 %212, -1
  %214 = getelementptr inbounds i16, i16* %3, i64 %213
  %215 = load i16, i16* %214, align 2
  %216 = zext i16 %215 to i64
  %217 = mul nuw i64 %216, 281479271743489
  %218 = getelementptr inbounds i16, i16* %3, i64 %212
  %219 = bitcast i16* %218 to i64*
  store i64 %217, i64* %219, align 8
  %220 = getelementptr inbounds i16, i16* %218, i64 4
  %221 = bitcast i16* %220 to i64*
  store i64 %217, i64* %221, align 8
  %222 = getelementptr inbounds i16, i16* %218, i64 8
  %223 = bitcast i16* %222 to i64*
  store i64 %217, i64* %223, align 8
  %224 = getelementptr inbounds i16, i16* %218, i64 12
  %225 = bitcast i16* %224 to i64*
  store i64 %217, i64* %225, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_127_dc_10_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i8, i8* %0, i64 16
  %7 = bitcast i8* %6 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %7, align 8
  %8 = getelementptr inbounds i16, i16* %3, i64 %4
  %9 = bitcast i16* %8 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %9, align 8
  %10 = getelementptr inbounds i16, i16* %8, i64 8
  %11 = bitcast i16* %10 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %11, align 8
  %12 = getelementptr inbounds i16, i16* %8, i64 %4
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %13, align 8
  %14 = getelementptr inbounds i16, i16* %12, i64 8
  %15 = bitcast i16* %14 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %15, align 8
  %16 = getelementptr inbounds i16, i16* %12, i64 %4
  %17 = bitcast i16* %16 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %17, align 8
  %18 = getelementptr inbounds i16, i16* %16, i64 8
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 143835907860922879, i64 143835907860922879>, <2 x i64>* %19, align 8
  %20 = getelementptr inbounds i16, i16* %16, i64 %4
  %21 = bitcast i16* %20 to i64*
  store i64 143835907860922879, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 4
  %23 = bitcast i16* %22 to i64*
  store i64 143835907860922879, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 8
  %25 = bitcast i16* %24 to i64*
  store i64 143835907860922879, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 12
  %27 = bitcast i16* %26 to i64*
  store i64 143835907860922879, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %20, i64 %4
  %29 = bitcast i16* %28 to i64*
  store i64 143835907860922879, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 143835907860922879, i64* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 8
  %33 = bitcast i16* %32 to i64*
  store i64 143835907860922879, i64* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 12
  %35 = bitcast i16* %34 to i64*
  store i64 143835907860922879, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %4
  %37 = bitcast i16* %36 to i64*
  store i64 143835907860922879, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 143835907860922879, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 143835907860922879, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 143835907860922879, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %36, i64 %4
  %45 = bitcast i16* %44 to i64*
  store i64 143835907860922879, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 143835907860922879, i64* %47, align 8
  %48 = getelementptr inbounds i16, i16* %44, i64 8
  %49 = bitcast i16* %48 to i64*
  store i64 143835907860922879, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %44, i64 12
  %51 = bitcast i16* %50 to i64*
  store i64 143835907860922879, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %44, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 143835907860922879, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 143835907860922879, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %52, i64 8
  %57 = bitcast i16* %56 to i64*
  store i64 143835907860922879, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %52, i64 12
  %59 = bitcast i16* %58 to i64*
  store i64 143835907860922879, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %52, i64 %4
  %61 = bitcast i16* %60 to i64*
  store i64 143835907860922879, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %60, i64 4
  %63 = bitcast i16* %62 to i64*
  store i64 143835907860922879, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %60, i64 8
  %65 = bitcast i16* %64 to i64*
  store i64 143835907860922879, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %60, i64 12
  %67 = bitcast i16* %66 to i64*
  store i64 143835907860922879, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %60, i64 %4
  %69 = bitcast i16* %68 to i64*
  store i64 143835907860922879, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 143835907860922879, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %68, i64 8
  %73 = bitcast i16* %72 to i64*
  store i64 143835907860922879, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %68, i64 12
  %75 = bitcast i16* %74 to i64*
  store i64 143835907860922879, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %68, i64 %4
  %77 = bitcast i16* %76 to i64*
  store i64 143835907860922879, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %76, i64 4
  %79 = bitcast i16* %78 to i64*
  store i64 143835907860922879, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %76, i64 8
  %81 = bitcast i16* %80 to i64*
  store i64 143835907860922879, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %76, i64 12
  %83 = bitcast i16* %82 to i64*
  store i64 143835907860922879, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %76, i64 %4
  %85 = bitcast i16* %84 to i64*
  store i64 143835907860922879, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 143835907860922879, i64* %87, align 8
  %88 = getelementptr inbounds i16, i16* %84, i64 8
  %89 = bitcast i16* %88 to i64*
  store i64 143835907860922879, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %84, i64 12
  %91 = bitcast i16* %90 to i64*
  store i64 143835907860922879, i64* %91, align 8
  %92 = getelementptr inbounds i16, i16* %84, i64 %4
  %93 = bitcast i16* %92 to i64*
  store i64 143835907860922879, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 143835907860922879, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 143835907860922879, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 143835907860922879, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %92, i64 %4
  %101 = bitcast i16* %100 to i64*
  store i64 143835907860922879, i64* %101, align 8
  %102 = getelementptr inbounds i16, i16* %100, i64 4
  %103 = bitcast i16* %102 to i64*
  store i64 143835907860922879, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %100, i64 8
  %105 = bitcast i16* %104 to i64*
  store i64 143835907860922879, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %100, i64 12
  %107 = bitcast i16* %106 to i64*
  store i64 143835907860922879, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %100, i64 %4
  %109 = bitcast i16* %108 to i64*
  store i64 143835907860922879, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 143835907860922879, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %108, i64 8
  %113 = bitcast i16* %112 to i64*
  store i64 143835907860922879, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %108, i64 12
  %115 = bitcast i16* %114 to i64*
  store i64 143835907860922879, i64* %115, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_129_dc_10_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i8, i8* %0, i64 16
  %7 = bitcast i8* %6 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %7, align 8
  %8 = getelementptr inbounds i16, i16* %3, i64 %4
  %9 = bitcast i16* %8 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %9, align 8
  %10 = getelementptr inbounds i16, i16* %8, i64 8
  %11 = bitcast i16* %10 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %11, align 8
  %12 = getelementptr inbounds i16, i16* %8, i64 %4
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %13, align 8
  %14 = getelementptr inbounds i16, i16* %12, i64 8
  %15 = bitcast i16* %14 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %15, align 8
  %16 = getelementptr inbounds i16, i16* %12, i64 %4
  %17 = bitcast i16* %16 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %17, align 8
  %18 = getelementptr inbounds i16, i16* %16, i64 8
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 144398866404409857, i64 144398866404409857>, <2 x i64>* %19, align 8
  %20 = getelementptr inbounds i16, i16* %16, i64 %4
  %21 = bitcast i16* %20 to i64*
  store i64 144398866404409857, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 4
  %23 = bitcast i16* %22 to i64*
  store i64 144398866404409857, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 8
  %25 = bitcast i16* %24 to i64*
  store i64 144398866404409857, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 12
  %27 = bitcast i16* %26 to i64*
  store i64 144398866404409857, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %20, i64 %4
  %29 = bitcast i16* %28 to i64*
  store i64 144398866404409857, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 144398866404409857, i64* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 8
  %33 = bitcast i16* %32 to i64*
  store i64 144398866404409857, i64* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 12
  %35 = bitcast i16* %34 to i64*
  store i64 144398866404409857, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %4
  %37 = bitcast i16* %36 to i64*
  store i64 144398866404409857, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 144398866404409857, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 144398866404409857, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 144398866404409857, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %36, i64 %4
  %45 = bitcast i16* %44 to i64*
  store i64 144398866404409857, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 144398866404409857, i64* %47, align 8
  %48 = getelementptr inbounds i16, i16* %44, i64 8
  %49 = bitcast i16* %48 to i64*
  store i64 144398866404409857, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %44, i64 12
  %51 = bitcast i16* %50 to i64*
  store i64 144398866404409857, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %44, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 144398866404409857, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 144398866404409857, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %52, i64 8
  %57 = bitcast i16* %56 to i64*
  store i64 144398866404409857, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %52, i64 12
  %59 = bitcast i16* %58 to i64*
  store i64 144398866404409857, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %52, i64 %4
  %61 = bitcast i16* %60 to i64*
  store i64 144398866404409857, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %60, i64 4
  %63 = bitcast i16* %62 to i64*
  store i64 144398866404409857, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %60, i64 8
  %65 = bitcast i16* %64 to i64*
  store i64 144398866404409857, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %60, i64 12
  %67 = bitcast i16* %66 to i64*
  store i64 144398866404409857, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %60, i64 %4
  %69 = bitcast i16* %68 to i64*
  store i64 144398866404409857, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 144398866404409857, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %68, i64 8
  %73 = bitcast i16* %72 to i64*
  store i64 144398866404409857, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %68, i64 12
  %75 = bitcast i16* %74 to i64*
  store i64 144398866404409857, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %68, i64 %4
  %77 = bitcast i16* %76 to i64*
  store i64 144398866404409857, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %76, i64 4
  %79 = bitcast i16* %78 to i64*
  store i64 144398866404409857, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %76, i64 8
  %81 = bitcast i16* %80 to i64*
  store i64 144398866404409857, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %76, i64 12
  %83 = bitcast i16* %82 to i64*
  store i64 144398866404409857, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %76, i64 %4
  %85 = bitcast i16* %84 to i64*
  store i64 144398866404409857, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 144398866404409857, i64* %87, align 8
  %88 = getelementptr inbounds i16, i16* %84, i64 8
  %89 = bitcast i16* %88 to i64*
  store i64 144398866404409857, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %84, i64 12
  %91 = bitcast i16* %90 to i64*
  store i64 144398866404409857, i64* %91, align 8
  %92 = getelementptr inbounds i16, i16* %84, i64 %4
  %93 = bitcast i16* %92 to i64*
  store i64 144398866404409857, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 144398866404409857, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 144398866404409857, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 144398866404409857, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %92, i64 %4
  %101 = bitcast i16* %100 to i64*
  store i64 144398866404409857, i64* %101, align 8
  %102 = getelementptr inbounds i16, i16* %100, i64 4
  %103 = bitcast i16* %102 to i64*
  store i64 144398866404409857, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %100, i64 8
  %105 = bitcast i16* %104 to i64*
  store i64 144398866404409857, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %100, i64 12
  %107 = bitcast i16* %106 to i64*
  store i64 144398866404409857, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %100, i64 %4
  %109 = bitcast i16* %108 to i64*
  store i64 144398866404409857, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 144398866404409857, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %108, i64 8
  %113 = bitcast i16* %112 to i64*
  store i64 144398866404409857, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %108, i64 12
  %115 = bitcast i16* %114 to i64*
  store i64 144398866404409857, i64* %115, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_plane_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 14
  %6 = bitcast i8* %5 to i16*
  %7 = shl i64 %4, 32
  %8 = ashr exact i64 %7, 32
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i16, i16* %6, i64 %9
  %11 = shl i64 %4, 35
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = getelementptr inbounds i16, i16* %13, i64 -1
  %15 = shl i64 %1, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = sub nsw i64 0, %17
  %19 = getelementptr inbounds i16, i16* %14, i64 %18
  %20 = getelementptr inbounds i16, i16* %10, i64 1
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = getelementptr inbounds i16, i16* %10, i64 -1
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = sub nsw i32 %22, %25
  %27 = load i16, i16* %14, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %19, align 2
  %30 = zext i16 %29 to i32
  %31 = sub nsw i32 %28, %30
  %32 = mul nsw i64 %8, 14
  %33 = ashr exact i64 %11, 31
  %34 = add nsw i64 %33, -2
  %35 = add nsw i64 %34, %32
  %36 = getelementptr i8, i8* %0, i64 %35
  %37 = lshr i64 %16, 1
  %38 = shl i64 %37, 2
  %39 = sub i64 %34, %38
  %40 = sub i64 %39, %32
  %41 = getelementptr i8, i8* %0, i64 %40
  %42 = getelementptr inbounds i16, i16* %14, i64 %8
  %43 = getelementptr inbounds i16, i16* %19, i64 %9
  %44 = getelementptr inbounds i16, i16* %10, i64 2
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = getelementptr inbounds i16, i16* %10, i64 -2
  %48 = load i16, i16* %47, align 2
  %49 = zext i16 %48 to i32
  %50 = sub nsw i32 %46, %49
  %51 = shl nsw i32 %50, 1
  %52 = add nsw i32 %26, %51
  %53 = load i16, i16* %42, align 2
  %54 = zext i16 %53 to i32
  %55 = load i16, i16* %43, align 2
  %56 = zext i16 %55 to i32
  %57 = sub nsw i32 %54, %56
  %58 = shl nsw i32 %57, 1
  %59 = add nsw i32 %31, %58
  %60 = getelementptr inbounds i16, i16* %42, i64 %8
  %61 = getelementptr inbounds i16, i16* %43, i64 %9
  %62 = getelementptr inbounds i16, i16* %10, i64 3
  %63 = load i16, i16* %62, align 2
  %64 = zext i16 %63 to i32
  %65 = getelementptr inbounds i16, i16* %10, i64 -3
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = sub nsw i32 %64, %67
  %69 = mul nsw i32 %68, 3
  %70 = add nsw i32 %52, %69
  %71 = load i16, i16* %60, align 2
  %72 = zext i16 %71 to i32
  %73 = load i16, i16* %61, align 2
  %74 = zext i16 %73 to i32
  %75 = sub nsw i32 %72, %74
  %76 = mul nsw i32 %75, 3
  %77 = add nsw i32 %59, %76
  %78 = getelementptr inbounds i16, i16* %60, i64 %8
  %79 = getelementptr inbounds i16, i16* %61, i64 %9
  %80 = getelementptr inbounds i16, i16* %10, i64 4
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i32
  %83 = getelementptr inbounds i16, i16* %10, i64 -4
  %84 = load i16, i16* %83, align 2
  %85 = zext i16 %84 to i32
  %86 = sub nsw i32 %82, %85
  %87 = shl nsw i32 %86, 2
  %88 = add nsw i32 %70, %87
  %89 = load i16, i16* %78, align 2
  %90 = zext i16 %89 to i32
  %91 = load i16, i16* %79, align 2
  %92 = zext i16 %91 to i32
  %93 = sub nsw i32 %90, %92
  %94 = shl nsw i32 %93, 2
  %95 = add nsw i32 %77, %94
  %96 = getelementptr inbounds i16, i16* %78, i64 %8
  %97 = getelementptr inbounds i16, i16* %79, i64 %9
  %98 = getelementptr inbounds i16, i16* %10, i64 5
  %99 = load i16, i16* %98, align 2
  %100 = zext i16 %99 to i32
  %101 = getelementptr inbounds i16, i16* %10, i64 -5
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  %104 = sub nsw i32 %100, %103
  %105 = mul nsw i32 %104, 5
  %106 = add nsw i32 %88, %105
  %107 = load i16, i16* %96, align 2
  %108 = zext i16 %107 to i32
  %109 = load i16, i16* %97, align 2
  %110 = zext i16 %109 to i32
  %111 = sub nsw i32 %108, %110
  %112 = mul nsw i32 %111, 5
  %113 = add nsw i32 %95, %112
  %114 = getelementptr inbounds i16, i16* %96, i64 %8
  %115 = getelementptr inbounds i16, i16* %97, i64 %9
  %116 = getelementptr inbounds i16, i16* %10, i64 6
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = getelementptr inbounds i16, i16* %10, i64 -6
  %120 = load i16, i16* %119, align 2
  %121 = zext i16 %120 to i32
  %122 = sub nsw i32 %118, %121
  %123 = mul nsw i32 %122, 6
  %124 = add nsw i32 %106, %123
  %125 = load i16, i16* %114, align 2
  %126 = zext i16 %125 to i32
  %127 = load i16, i16* %115, align 2
  %128 = zext i16 %127 to i32
  %129 = sub nsw i32 %126, %128
  %130 = mul nsw i32 %129, 6
  %131 = add nsw i32 %113, %130
  %132 = getelementptr inbounds i16, i16* %114, i64 %8
  %133 = getelementptr inbounds i16, i16* %115, i64 %9
  %134 = getelementptr inbounds i16, i16* %10, i64 7
  %135 = load i16, i16* %134, align 2
  %136 = zext i16 %135 to i32
  %137 = getelementptr inbounds i16, i16* %10, i64 -7
  %138 = load i16, i16* %137, align 2
  %139 = zext i16 %138 to i32
  %140 = sub nsw i32 %136, %139
  %141 = mul nsw i32 %140, 7
  %142 = add nsw i32 %124, %141
  %143 = load i16, i16* %132, align 2
  %144 = zext i16 %143 to i32
  %145 = load i16, i16* %133, align 2
  %146 = zext i16 %145 to i32
  %147 = sub nsw i32 %144, %146
  %148 = mul nsw i32 %147, 7
  %149 = add nsw i32 %131, %148
  %150 = getelementptr inbounds i16, i16* %132, i64 %8
  %151 = getelementptr inbounds i16, i16* %133, i64 %9
  %152 = getelementptr inbounds i16, i16* %10, i64 8
  %153 = load i16, i16* %152, align 2
  %154 = zext i16 %153 to i32
  %155 = getelementptr inbounds i16, i16* %10, i64 -8
  %156 = load i16, i16* %155, align 2
  %157 = zext i16 %156 to i32
  %158 = sub nsw i32 %154, %157
  %159 = shl nsw i32 %158, 3
  %160 = add nsw i32 %142, %159
  %161 = load i16, i16* %150, align 2
  %162 = zext i16 %161 to i32
  %163 = load i16, i16* %151, align 2
  %164 = zext i16 %163 to i32
  %165 = sub nsw i32 %162, %164
  %166 = shl nsw i32 %165, 3
  %167 = add nsw i32 %149, %166
  %168 = bitcast i8* %36 to i16*
  %169 = mul nsw i32 %160, 5
  %170 = add nsw i32 %169, 32
  %171 = ashr i32 %170, 6
  %172 = mul nsw i32 %167, 5
  %173 = add nsw i32 %172, 32
  %174 = ashr i32 %173, 6
  %175 = load i16, i16* %168, align 2
  %176 = zext i16 %175 to i32
  %177 = getelementptr inbounds i8, i8* %41, i64 32
  %178 = bitcast i8* %177 to i16*
  %179 = load i16, i16* %178, align 2
  %180 = zext i16 %179 to i32
  %181 = add nuw nsw i32 %180, %176
  %182 = shl nuw nsw i32 %181, 4
  %183 = add nsw i32 %174, %171
  %184 = mul nsw i32 %183, -7
  %185 = add nuw nsw i32 %182, 16
  %186 = add nsw i32 %185, %184
  %187 = shl nsw i32 %171, 1
  %188 = mul nsw i32 %171, 3
  %189 = shl nsw i32 %171, 2
  br label %190

190:                                              ; preds = %364, %2
  %191 = phi i16* [ %3, %2 ], [ %369, %364 ]
  %192 = phi i32 [ %186, %2 ], [ %368, %364 ]
  %193 = phi i32 [ 16, %2 ], [ %370, %364 ]
  %194 = ashr i32 %192, 5
  %195 = icmp ult i32 %194, 1024
  br i1 %195, label %200, label %196

196:                                              ; preds = %190
  %197 = ashr i32 %192, 31
  %198 = or i32 %197, -1024
  %199 = xor i32 %198, -1
  br label %200

200:                                              ; preds = %196, %190
  %201 = phi i32 [ %199, %196 ], [ %194, %190 ]
  %202 = trunc i32 %201 to i16
  store i16 %202, i16* %191, align 2
  %203 = add nsw i32 %192, %171
  %204 = ashr i32 %203, 5
  %205 = icmp ult i32 %204, 1024
  br i1 %205, label %210, label %206

206:                                              ; preds = %200
  %207 = ashr i32 %203, 31
  %208 = or i32 %207, -1024
  %209 = xor i32 %208, -1
  br label %210

210:                                              ; preds = %206, %200
  %211 = phi i32 [ %209, %206 ], [ %204, %200 ]
  %212 = trunc i32 %211 to i16
  %213 = getelementptr inbounds i16, i16* %191, i64 1
  store i16 %212, i16* %213, align 2
  %214 = add nsw i32 %192, %187
  %215 = ashr i32 %214, 5
  %216 = icmp ult i32 %215, 1024
  br i1 %216, label %221, label %217

217:                                              ; preds = %210
  %218 = ashr i32 %214, 31
  %219 = or i32 %218, -1024
  %220 = xor i32 %219, -1
  br label %221

221:                                              ; preds = %217, %210
  %222 = phi i32 [ %220, %217 ], [ %215, %210 ]
  %223 = trunc i32 %222 to i16
  %224 = getelementptr inbounds i16, i16* %191, i64 2
  store i16 %223, i16* %224, align 2
  %225 = add nsw i32 %192, %188
  %226 = ashr i32 %225, 5
  %227 = icmp ult i32 %226, 1024
  br i1 %227, label %232, label %228

228:                                              ; preds = %221
  %229 = ashr i32 %225, 31
  %230 = or i32 %229, -1024
  %231 = xor i32 %230, -1
  br label %232

232:                                              ; preds = %228, %221
  %233 = phi i32 [ %231, %228 ], [ %226, %221 ]
  %234 = trunc i32 %233 to i16
  %235 = getelementptr inbounds i16, i16* %191, i64 3
  store i16 %234, i16* %235, align 2
  %236 = add nsw i32 %192, %189
  %237 = ashr i32 %236, 5
  %238 = icmp ult i32 %237, 1024
  br i1 %238, label %243, label %239

239:                                              ; preds = %232
  %240 = ashr i32 %236, 31
  %241 = or i32 %240, -1024
  %242 = xor i32 %241, -1
  br label %243

243:                                              ; preds = %239, %232
  %244 = phi i32 [ %242, %239 ], [ %237, %232 ]
  %245 = trunc i32 %244 to i16
  %246 = getelementptr inbounds i16, i16* %191, i64 4
  store i16 %245, i16* %246, align 2
  %247 = add nsw i32 %236, %171
  %248 = ashr i32 %247, 5
  %249 = icmp ult i32 %248, 1024
  br i1 %249, label %254, label %250

250:                                              ; preds = %243
  %251 = ashr i32 %247, 31
  %252 = or i32 %251, -1024
  %253 = xor i32 %252, -1
  br label %254

254:                                              ; preds = %250, %243
  %255 = phi i32 [ %253, %250 ], [ %248, %243 ]
  %256 = trunc i32 %255 to i16
  %257 = getelementptr inbounds i16, i16* %191, i64 5
  store i16 %256, i16* %257, align 2
  %258 = add nsw i32 %236, %187
  %259 = ashr i32 %258, 5
  %260 = icmp ult i32 %259, 1024
  br i1 %260, label %265, label %261

261:                                              ; preds = %254
  %262 = ashr i32 %258, 31
  %263 = or i32 %262, -1024
  %264 = xor i32 %263, -1
  br label %265

265:                                              ; preds = %261, %254
  %266 = phi i32 [ %264, %261 ], [ %259, %254 ]
  %267 = trunc i32 %266 to i16
  %268 = getelementptr inbounds i16, i16* %191, i64 6
  store i16 %267, i16* %268, align 2
  %269 = add nsw i32 %236, %188
  %270 = ashr i32 %269, 5
  %271 = icmp ult i32 %270, 1024
  br i1 %271, label %276, label %272

272:                                              ; preds = %265
  %273 = ashr i32 %269, 31
  %274 = or i32 %273, -1024
  %275 = xor i32 %274, -1
  br label %276

276:                                              ; preds = %272, %265
  %277 = phi i32 [ %275, %272 ], [ %270, %265 ]
  %278 = trunc i32 %277 to i16
  %279 = getelementptr inbounds i16, i16* %191, i64 7
  store i16 %278, i16* %279, align 2
  %280 = add nsw i32 %236, %189
  %281 = ashr i32 %280, 5
  %282 = icmp ult i32 %281, 1024
  br i1 %282, label %287, label %283

283:                                              ; preds = %276
  %284 = ashr i32 %280, 31
  %285 = or i32 %284, -1024
  %286 = xor i32 %285, -1
  br label %287

287:                                              ; preds = %283, %276
  %288 = phi i32 [ %286, %283 ], [ %281, %276 ]
  %289 = trunc i32 %288 to i16
  %290 = getelementptr inbounds i16, i16* %191, i64 8
  store i16 %289, i16* %290, align 2
  %291 = add nsw i32 %280, %171
  %292 = ashr i32 %291, 5
  %293 = icmp ult i32 %292, 1024
  br i1 %293, label %298, label %294

294:                                              ; preds = %287
  %295 = ashr i32 %291, 31
  %296 = or i32 %295, -1024
  %297 = xor i32 %296, -1
  br label %298

298:                                              ; preds = %294, %287
  %299 = phi i32 [ %297, %294 ], [ %292, %287 ]
  %300 = trunc i32 %299 to i16
  %301 = getelementptr inbounds i16, i16* %191, i64 9
  store i16 %300, i16* %301, align 2
  %302 = add nsw i32 %280, %187
  %303 = ashr i32 %302, 5
  %304 = icmp ult i32 %303, 1024
  br i1 %304, label %309, label %305

305:                                              ; preds = %298
  %306 = ashr i32 %302, 31
  %307 = or i32 %306, -1024
  %308 = xor i32 %307, -1
  br label %309

309:                                              ; preds = %305, %298
  %310 = phi i32 [ %308, %305 ], [ %303, %298 ]
  %311 = trunc i32 %310 to i16
  %312 = getelementptr inbounds i16, i16* %191, i64 10
  store i16 %311, i16* %312, align 2
  %313 = add nsw i32 %280, %188
  %314 = ashr i32 %313, 5
  %315 = icmp ult i32 %314, 1024
  br i1 %315, label %320, label %316

316:                                              ; preds = %309
  %317 = ashr i32 %313, 31
  %318 = or i32 %317, -1024
  %319 = xor i32 %318, -1
  br label %320

320:                                              ; preds = %316, %309
  %321 = phi i32 [ %319, %316 ], [ %314, %309 ]
  %322 = trunc i32 %321 to i16
  %323 = getelementptr inbounds i16, i16* %191, i64 11
  store i16 %322, i16* %323, align 2
  %324 = add nsw i32 %280, %189
  %325 = ashr i32 %324, 5
  %326 = icmp ult i32 %325, 1024
  br i1 %326, label %331, label %327

327:                                              ; preds = %320
  %328 = ashr i32 %324, 31
  %329 = or i32 %328, -1024
  %330 = xor i32 %329, -1
  br label %331

331:                                              ; preds = %327, %320
  %332 = phi i32 [ %330, %327 ], [ %325, %320 ]
  %333 = trunc i32 %332 to i16
  %334 = getelementptr inbounds i16, i16* %191, i64 12
  store i16 %333, i16* %334, align 2
  %335 = add nsw i32 %324, %171
  %336 = ashr i32 %335, 5
  %337 = icmp ult i32 %336, 1024
  br i1 %337, label %342, label %338

338:                                              ; preds = %331
  %339 = ashr i32 %335, 31
  %340 = or i32 %339, -1024
  %341 = xor i32 %340, -1
  br label %342

342:                                              ; preds = %338, %331
  %343 = phi i32 [ %341, %338 ], [ %336, %331 ]
  %344 = trunc i32 %343 to i16
  %345 = getelementptr inbounds i16, i16* %191, i64 13
  store i16 %344, i16* %345, align 2
  %346 = add nsw i32 %324, %187
  %347 = ashr i32 %346, 5
  %348 = icmp ult i32 %347, 1024
  br i1 %348, label %353, label %349

349:                                              ; preds = %342
  %350 = ashr i32 %346, 31
  %351 = or i32 %350, -1024
  %352 = xor i32 %351, -1
  br label %353

353:                                              ; preds = %349, %342
  %354 = phi i32 [ %352, %349 ], [ %347, %342 ]
  %355 = trunc i32 %354 to i16
  %356 = getelementptr inbounds i16, i16* %191, i64 14
  store i16 %355, i16* %356, align 2
  %357 = add nsw i32 %324, %188
  %358 = ashr i32 %357, 5
  %359 = icmp ult i32 %358, 1024
  br i1 %359, label %364, label %360

360:                                              ; preds = %353
  %361 = ashr i32 %357, 31
  %362 = or i32 %361, -1024
  %363 = xor i32 %362, -1
  br label %364

364:                                              ; preds = %360, %353
  %365 = phi i32 [ %363, %360 ], [ %358, %353 ]
  %366 = trunc i32 %365 to i16
  %367 = getelementptr inbounds i16, i16* %191, i64 15
  store i16 %366, i16* %367, align 2
  %368 = add nsw i32 %192, %174
  %369 = getelementptr inbounds i16, i16* %191, i64 %8
  %370 = add nsw i32 %193, -1
  %371 = icmp eq i32 %370, 0
  br i1 %371, label %372, label %190

372:                                              ; preds = %364
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_left_dc_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = add nsw i64 %4, -1
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = and i64 %1, -2
  %15 = add nsw i64 %14, -1
  %16 = getelementptr inbounds i16, i16* %3, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i64
  %19 = add nuw nsw i64 %13, %18
  %20 = mul nsw i64 %4, 3
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = add nuw nsw i64 %19, %24
  %26 = shl nsw i64 %4, 2
  %27 = add nsw i64 %26, -1
  %28 = getelementptr inbounds i16, i16* %3, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = zext i16 %29 to i64
  %31 = add nuw nsw i64 %25, %30
  %32 = mul nsw i64 %4, 5
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %31, %36
  %38 = mul nsw i64 %4, 6
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %37, %42
  %44 = mul nsw i64 %4, 7
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = add nuw nsw i64 %43, %48
  %50 = shl nsw i64 %4, 3
  %51 = add nsw i64 %50, -1
  %52 = getelementptr inbounds i16, i16* %3, i64 %51
  %53 = load i16, i16* %52, align 2
  %54 = zext i16 %53 to i64
  %55 = add nuw nsw i64 %49, %54
  %56 = mul nsw i64 %4, 9
  %57 = add nsw i64 %56, -1
  %58 = getelementptr inbounds i16, i16* %3, i64 %57
  %59 = load i16, i16* %58, align 2
  %60 = zext i16 %59 to i64
  %61 = add nuw nsw i64 %55, %60
  %62 = mul nsw i64 %4, 10
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = add nuw nsw i64 %61, %66
  %68 = mul nsw i64 %4, 11
  %69 = add nsw i64 %68, -1
  %70 = getelementptr inbounds i16, i16* %3, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i64
  %73 = add nuw nsw i64 %67, %72
  %74 = mul nsw i64 %4, 12
  %75 = add nsw i64 %74, -1
  %76 = getelementptr inbounds i16, i16* %3, i64 %75
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i64
  %79 = add nuw nsw i64 %73, %78
  %80 = mul nsw i64 %4, 13
  %81 = add nsw i64 %80, -1
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = zext i16 %83 to i64
  %85 = add nuw nsw i64 %79, %84
  %86 = mul nsw i64 %4, 14
  %87 = add nsw i64 %86, -1
  %88 = getelementptr inbounds i16, i16* %3, i64 %87
  %89 = load i16, i16* %88, align 2
  %90 = zext i16 %89 to i64
  %91 = add nuw nsw i64 %85, %90
  %92 = mul nsw i64 %4, 15
  %93 = add nsw i64 %92, -1
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i64
  %97 = add nuw nsw i64 %91, %96
  %98 = add nuw nsw i64 %97, 8
  %99 = lshr i64 %98, 4
  %100 = and i64 %99, 268435455
  %101 = mul i64 %100, 281479271743489
  %102 = bitcast i8* %0 to i64*
  store i64 %101, i64* %102, align 8
  %103 = getelementptr inbounds i8, i8* %0, i64 8
  %104 = bitcast i8* %103 to i64*
  store i64 %101, i64* %104, align 8
  %105 = getelementptr inbounds i8, i8* %0, i64 16
  %106 = bitcast i8* %105 to i64*
  store i64 %101, i64* %106, align 8
  %107 = getelementptr inbounds i8, i8* %0, i64 24
  %108 = bitcast i8* %107 to i64*
  store i64 %101, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %3, i64 %4
  %110 = bitcast i16* %109 to i64*
  store i64 %101, i64* %110, align 8
  %111 = getelementptr inbounds i16, i16* %109, i64 4
  %112 = bitcast i16* %111 to i64*
  store i64 %101, i64* %112, align 8
  %113 = getelementptr inbounds i16, i16* %109, i64 8
  %114 = bitcast i16* %113 to i64*
  store i64 %101, i64* %114, align 8
  %115 = getelementptr inbounds i16, i16* %109, i64 12
  %116 = bitcast i16* %115 to i64*
  store i64 %101, i64* %116, align 8
  %117 = getelementptr inbounds i16, i16* %109, i64 %4
  %118 = bitcast i16* %117 to i64*
  store i64 %101, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %117, i64 4
  %120 = bitcast i16* %119 to i64*
  store i64 %101, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %117, i64 8
  %122 = bitcast i16* %121 to i64*
  store i64 %101, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %117, i64 12
  %124 = bitcast i16* %123 to i64*
  store i64 %101, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %117, i64 %4
  %126 = bitcast i16* %125 to i64*
  store i64 %101, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %125, i64 4
  %128 = bitcast i16* %127 to i64*
  store i64 %101, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %125, i64 8
  %130 = bitcast i16* %129 to i64*
  store i64 %101, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %125, i64 12
  %132 = bitcast i16* %131 to i64*
  store i64 %101, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %125, i64 %4
  %134 = bitcast i16* %133 to i64*
  store i64 %101, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %133, i64 4
  %136 = bitcast i16* %135 to i64*
  store i64 %101, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %133, i64 8
  %138 = bitcast i16* %137 to i64*
  store i64 %101, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %133, i64 12
  %140 = bitcast i16* %139 to i64*
  store i64 %101, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %133, i64 %4
  %142 = bitcast i16* %141 to i64*
  store i64 %101, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %101, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %141, i64 8
  %146 = bitcast i16* %145 to i64*
  store i64 %101, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %141, i64 12
  %148 = bitcast i16* %147 to i64*
  store i64 %101, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %141, i64 %4
  %150 = bitcast i16* %149 to i64*
  store i64 %101, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %149, i64 4
  %152 = bitcast i16* %151 to i64*
  store i64 %101, i64* %152, align 8
  %153 = getelementptr inbounds i16, i16* %149, i64 8
  %154 = bitcast i16* %153 to i64*
  store i64 %101, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %149, i64 12
  %156 = bitcast i16* %155 to i64*
  store i64 %101, i64* %156, align 8
  %157 = getelementptr inbounds i16, i16* %149, i64 %4
  %158 = bitcast i16* %157 to i64*
  store i64 %101, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %157, i64 4
  %160 = bitcast i16* %159 to i64*
  store i64 %101, i64* %160, align 8
  %161 = getelementptr inbounds i16, i16* %157, i64 8
  %162 = bitcast i16* %161 to i64*
  store i64 %101, i64* %162, align 8
  %163 = getelementptr inbounds i16, i16* %157, i64 12
  %164 = bitcast i16* %163 to i64*
  store i64 %101, i64* %164, align 8
  %165 = getelementptr inbounds i16, i16* %157, i64 %4
  %166 = bitcast i16* %165 to i64*
  store i64 %101, i64* %166, align 8
  %167 = getelementptr inbounds i16, i16* %165, i64 4
  %168 = bitcast i16* %167 to i64*
  store i64 %101, i64* %168, align 8
  %169 = getelementptr inbounds i16, i16* %165, i64 8
  %170 = bitcast i16* %169 to i64*
  store i64 %101, i64* %170, align 8
  %171 = getelementptr inbounds i16, i16* %165, i64 12
  %172 = bitcast i16* %171 to i64*
  store i64 %101, i64* %172, align 8
  %173 = getelementptr inbounds i16, i16* %165, i64 %4
  %174 = bitcast i16* %173 to i64*
  store i64 %101, i64* %174, align 8
  %175 = getelementptr inbounds i16, i16* %173, i64 4
  %176 = bitcast i16* %175 to i64*
  store i64 %101, i64* %176, align 8
  %177 = getelementptr inbounds i16, i16* %173, i64 8
  %178 = bitcast i16* %177 to i64*
  store i64 %101, i64* %178, align 8
  %179 = getelementptr inbounds i16, i16* %173, i64 12
  %180 = bitcast i16* %179 to i64*
  store i64 %101, i64* %180, align 8
  %181 = getelementptr inbounds i16, i16* %173, i64 %4
  %182 = bitcast i16* %181 to i64*
  store i64 %101, i64* %182, align 8
  %183 = getelementptr inbounds i16, i16* %181, i64 4
  %184 = bitcast i16* %183 to i64*
  store i64 %101, i64* %184, align 8
  %185 = getelementptr inbounds i16, i16* %181, i64 8
  %186 = bitcast i16* %185 to i64*
  store i64 %101, i64* %186, align 8
  %187 = getelementptr inbounds i16, i16* %181, i64 12
  %188 = bitcast i16* %187 to i64*
  store i64 %101, i64* %188, align 8
  %189 = getelementptr inbounds i16, i16* %181, i64 %4
  %190 = bitcast i16* %189 to i64*
  store i64 %101, i64* %190, align 8
  %191 = getelementptr inbounds i16, i16* %189, i64 4
  %192 = bitcast i16* %191 to i64*
  store i64 %101, i64* %192, align 8
  %193 = getelementptr inbounds i16, i16* %189, i64 8
  %194 = bitcast i16* %193 to i64*
  store i64 %101, i64* %194, align 8
  %195 = getelementptr inbounds i16, i16* %189, i64 12
  %196 = bitcast i16* %195 to i64*
  store i64 %101, i64* %196, align 8
  %197 = getelementptr inbounds i16, i16* %189, i64 %4
  %198 = bitcast i16* %197 to i64*
  store i64 %101, i64* %198, align 8
  %199 = getelementptr inbounds i16, i16* %197, i64 4
  %200 = bitcast i16* %199 to i64*
  store i64 %101, i64* %200, align 8
  %201 = getelementptr inbounds i16, i16* %197, i64 8
  %202 = bitcast i16* %201 to i64*
  store i64 %101, i64* %202, align 8
  %203 = getelementptr inbounds i16, i16* %197, i64 12
  %204 = bitcast i16* %203 to i64*
  store i64 %101, i64* %204, align 8
  %205 = getelementptr inbounds i16, i16* %197, i64 %4
  %206 = bitcast i16* %205 to i64*
  store i64 %101, i64* %206, align 8
  %207 = getelementptr inbounds i16, i16* %205, i64 4
  %208 = bitcast i16* %207 to i64*
  store i64 %101, i64* %208, align 8
  %209 = getelementptr inbounds i16, i16* %205, i64 8
  %210 = bitcast i16* %209 to i64*
  store i64 %101, i64* %210, align 8
  %211 = getelementptr inbounds i16, i16* %205, i64 12
  %212 = bitcast i16* %211 to i64*
  store i64 %101, i64* %212, align 8
  %213 = getelementptr inbounds i16, i16* %205, i64 %4
  %214 = bitcast i16* %213 to i64*
  store i64 %101, i64* %214, align 8
  %215 = getelementptr inbounds i16, i16* %213, i64 4
  %216 = bitcast i16* %215 to i64*
  store i64 %101, i64* %216, align 8
  %217 = getelementptr inbounds i16, i16* %213, i64 8
  %218 = bitcast i16* %217 to i64*
  store i64 %101, i64* %218, align 8
  %219 = getelementptr inbounds i16, i16* %213, i64 12
  %220 = bitcast i16* %219 to i64*
  store i64 %101, i64* %220, align 8
  %221 = getelementptr inbounds i16, i16* %213, i64 %4
  %222 = bitcast i16* %221 to i64*
  store i64 %101, i64* %222, align 8
  %223 = getelementptr inbounds i16, i16* %221, i64 4
  %224 = bitcast i16* %223 to i64*
  store i64 %101, i64* %224, align 8
  %225 = getelementptr inbounds i16, i16* %221, i64 8
  %226 = bitcast i16* %225 to i64*
  store i64 %101, i64* %226, align 8
  %227 = getelementptr inbounds i16, i16* %221, i64 12
  %228 = bitcast i16* %227 to i64*
  store i64 %101, i64* %228, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_top_dc_10_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 1, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = sub nsw i64 2, %4
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = add nuw nsw i64 %13, %17
  %19 = sub nsw i64 3, %4
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = add nuw nsw i64 %18, %22
  %24 = sub nsw i64 4, %4
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = add nuw nsw i64 %23, %27
  %29 = sub nsw i64 5, %4
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = add nuw nsw i64 %28, %32
  %34 = sub nsw i64 6, %4
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = add nuw nsw i64 %33, %37
  %39 = sub nsw i64 7, %4
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %38, %42
  %44 = sub nsw i64 8, %4
  %45 = getelementptr inbounds i16, i16* %3, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i64
  %48 = add nuw nsw i64 %43, %47
  %49 = sub nsw i64 9, %4
  %50 = getelementptr inbounds i16, i16* %3, i64 %49
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i64
  %53 = add nuw nsw i64 %48, %52
  %54 = sub nsw i64 10, %4
  %55 = getelementptr inbounds i16, i16* %3, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i64
  %58 = add nuw nsw i64 %53, %57
  %59 = sub nsw i64 11, %4
  %60 = getelementptr inbounds i16, i16* %3, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i64
  %63 = add nuw nsw i64 %58, %62
  %64 = sub nsw i64 12, %4
  %65 = getelementptr inbounds i16, i16* %3, i64 %64
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i64
  %68 = add nuw nsw i64 %63, %67
  %69 = sub nsw i64 13, %4
  %70 = getelementptr inbounds i16, i16* %3, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i64
  %73 = add nuw nsw i64 %68, %72
  %74 = sub nsw i64 14, %4
  %75 = getelementptr inbounds i16, i16* %3, i64 %74
  %76 = load i16, i16* %75, align 2
  %77 = zext i16 %76 to i64
  %78 = add nuw nsw i64 %73, %77
  %79 = sub nsw i64 15, %4
  %80 = getelementptr inbounds i16, i16* %3, i64 %79
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i64
  %83 = add nuw nsw i64 %78, %82
  %84 = add nuw nsw i64 %83, 8
  %85 = lshr i64 %84, 4
  %86 = and i64 %85, 268435455
  %87 = mul i64 %86, 281479271743489
  %88 = bitcast i8* %0 to i64*
  store i64 %87, i64* %88, align 8
  %89 = getelementptr inbounds i8, i8* %0, i64 8
  %90 = bitcast i8* %89 to i64*
  store i64 %87, i64* %90, align 8
  %91 = getelementptr inbounds i8, i8* %0, i64 16
  %92 = bitcast i8* %91 to i64*
  store i64 %87, i64* %92, align 8
  %93 = getelementptr inbounds i8, i8* %0, i64 24
  %94 = bitcast i8* %93 to i64*
  store i64 %87, i64* %94, align 8
  %95 = getelementptr inbounds i16, i16* %3, i64 %4
  %96 = bitcast i16* %95 to i64*
  store i64 %87, i64* %96, align 8
  %97 = getelementptr inbounds i16, i16* %95, i64 4
  %98 = bitcast i16* %97 to i64*
  store i64 %87, i64* %98, align 8
  %99 = getelementptr inbounds i16, i16* %95, i64 8
  %100 = bitcast i16* %99 to i64*
  store i64 %87, i64* %100, align 8
  %101 = getelementptr inbounds i16, i16* %95, i64 12
  %102 = bitcast i16* %101 to i64*
  store i64 %87, i64* %102, align 8
  %103 = getelementptr inbounds i16, i16* %95, i64 %4
  %104 = bitcast i16* %103 to i64*
  store i64 %87, i64* %104, align 8
  %105 = getelementptr inbounds i16, i16* %103, i64 4
  %106 = bitcast i16* %105 to i64*
  store i64 %87, i64* %106, align 8
  %107 = getelementptr inbounds i16, i16* %103, i64 8
  %108 = bitcast i16* %107 to i64*
  store i64 %87, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %103, i64 12
  %110 = bitcast i16* %109 to i64*
  store i64 %87, i64* %110, align 8
  %111 = getelementptr inbounds i16, i16* %103, i64 %4
  %112 = bitcast i16* %111 to i64*
  store i64 %87, i64* %112, align 8
  %113 = getelementptr inbounds i16, i16* %111, i64 4
  %114 = bitcast i16* %113 to i64*
  store i64 %87, i64* %114, align 8
  %115 = getelementptr inbounds i16, i16* %111, i64 8
  %116 = bitcast i16* %115 to i64*
  store i64 %87, i64* %116, align 8
  %117 = getelementptr inbounds i16, i16* %111, i64 12
  %118 = bitcast i16* %117 to i64*
  store i64 %87, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %111, i64 %4
  %120 = bitcast i16* %119 to i64*
  store i64 %87, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %119, i64 4
  %122 = bitcast i16* %121 to i64*
  store i64 %87, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %119, i64 8
  %124 = bitcast i16* %123 to i64*
  store i64 %87, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %119, i64 12
  %126 = bitcast i16* %125 to i64*
  store i64 %87, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %119, i64 %4
  %128 = bitcast i16* %127 to i64*
  store i64 %87, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %127, i64 4
  %130 = bitcast i16* %129 to i64*
  store i64 %87, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %127, i64 8
  %132 = bitcast i16* %131 to i64*
  store i64 %87, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %127, i64 12
  %134 = bitcast i16* %133 to i64*
  store i64 %87, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %127, i64 %4
  %136 = bitcast i16* %135 to i64*
  store i64 %87, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %135, i64 4
  %138 = bitcast i16* %137 to i64*
  store i64 %87, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %135, i64 8
  %140 = bitcast i16* %139 to i64*
  store i64 %87, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %135, i64 12
  %142 = bitcast i16* %141 to i64*
  store i64 %87, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %135, i64 %4
  %144 = bitcast i16* %143 to i64*
  store i64 %87, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %143, i64 4
  %146 = bitcast i16* %145 to i64*
  store i64 %87, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %143, i64 8
  %148 = bitcast i16* %147 to i64*
  store i64 %87, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %143, i64 12
  %150 = bitcast i16* %149 to i64*
  store i64 %87, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %143, i64 %4
  %152 = bitcast i16* %151 to i64*
  store i64 %87, i64* %152, align 8
  %153 = getelementptr inbounds i16, i16* %151, i64 4
  %154 = bitcast i16* %153 to i64*
  store i64 %87, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %151, i64 8
  %156 = bitcast i16* %155 to i64*
  store i64 %87, i64* %156, align 8
  %157 = getelementptr inbounds i16, i16* %151, i64 12
  %158 = bitcast i16* %157 to i64*
  store i64 %87, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %151, i64 %4
  %160 = bitcast i16* %159 to i64*
  store i64 %87, i64* %160, align 8
  %161 = getelementptr inbounds i16, i16* %159, i64 4
  %162 = bitcast i16* %161 to i64*
  store i64 %87, i64* %162, align 8
  %163 = getelementptr inbounds i16, i16* %159, i64 8
  %164 = bitcast i16* %163 to i64*
  store i64 %87, i64* %164, align 8
  %165 = getelementptr inbounds i16, i16* %159, i64 12
  %166 = bitcast i16* %165 to i64*
  store i64 %87, i64* %166, align 8
  %167 = getelementptr inbounds i16, i16* %159, i64 %4
  %168 = bitcast i16* %167 to i64*
  store i64 %87, i64* %168, align 8
  %169 = getelementptr inbounds i16, i16* %167, i64 4
  %170 = bitcast i16* %169 to i64*
  store i64 %87, i64* %170, align 8
  %171 = getelementptr inbounds i16, i16* %167, i64 8
  %172 = bitcast i16* %171 to i64*
  store i64 %87, i64* %172, align 8
  %173 = getelementptr inbounds i16, i16* %167, i64 12
  %174 = bitcast i16* %173 to i64*
  store i64 %87, i64* %174, align 8
  %175 = getelementptr inbounds i16, i16* %167, i64 %4
  %176 = bitcast i16* %175 to i64*
  store i64 %87, i64* %176, align 8
  %177 = getelementptr inbounds i16, i16* %175, i64 4
  %178 = bitcast i16* %177 to i64*
  store i64 %87, i64* %178, align 8
  %179 = getelementptr inbounds i16, i16* %175, i64 8
  %180 = bitcast i16* %179 to i64*
  store i64 %87, i64* %180, align 8
  %181 = getelementptr inbounds i16, i16* %175, i64 12
  %182 = bitcast i16* %181 to i64*
  store i64 %87, i64* %182, align 8
  %183 = getelementptr inbounds i16, i16* %175, i64 %4
  %184 = bitcast i16* %183 to i64*
  store i64 %87, i64* %184, align 8
  %185 = getelementptr inbounds i16, i16* %183, i64 4
  %186 = bitcast i16* %185 to i64*
  store i64 %87, i64* %186, align 8
  %187 = getelementptr inbounds i16, i16* %183, i64 8
  %188 = bitcast i16* %187 to i64*
  store i64 %87, i64* %188, align 8
  %189 = getelementptr inbounds i16, i16* %183, i64 12
  %190 = bitcast i16* %189 to i64*
  store i64 %87, i64* %190, align 8
  %191 = getelementptr inbounds i16, i16* %183, i64 %4
  %192 = bitcast i16* %191 to i64*
  store i64 %87, i64* %192, align 8
  %193 = getelementptr inbounds i16, i16* %191, i64 4
  %194 = bitcast i16* %193 to i64*
  store i64 %87, i64* %194, align 8
  %195 = getelementptr inbounds i16, i16* %191, i64 8
  %196 = bitcast i16* %195 to i64*
  store i64 %87, i64* %196, align 8
  %197 = getelementptr inbounds i16, i16* %191, i64 12
  %198 = bitcast i16* %197 to i64*
  store i64 %87, i64* %198, align 8
  %199 = getelementptr inbounds i16, i16* %191, i64 %4
  %200 = bitcast i16* %199 to i64*
  store i64 %87, i64* %200, align 8
  %201 = getelementptr inbounds i16, i16* %199, i64 4
  %202 = bitcast i16* %201 to i64*
  store i64 %87, i64* %202, align 8
  %203 = getelementptr inbounds i16, i16* %199, i64 8
  %204 = bitcast i16* %203 to i64*
  store i64 %87, i64* %204, align 8
  %205 = getelementptr inbounds i16, i16* %199, i64 12
  %206 = bitcast i16* %205 to i64*
  store i64 %87, i64* %206, align 8
  %207 = getelementptr inbounds i16, i16* %199, i64 %4
  %208 = bitcast i16* %207 to i64*
  store i64 %87, i64* %208, align 8
  %209 = getelementptr inbounds i16, i16* %207, i64 4
  %210 = bitcast i16* %209 to i64*
  store i64 %87, i64* %210, align 8
  %211 = getelementptr inbounds i16, i16* %207, i64 8
  %212 = bitcast i16* %211 to i64*
  store i64 %87, i64* %212, align 8
  %213 = getelementptr inbounds i16, i16* %207, i64 12
  %214 = bitcast i16* %213 to i64*
  store i64 %87, i64* %214, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_128_dc_10_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i8, i8* %0, i64 16
  %7 = bitcast i8* %6 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %7, align 8
  %8 = getelementptr inbounds i16, i16* %3, i64 %4
  %9 = bitcast i16* %8 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %9, align 8
  %10 = getelementptr inbounds i16, i16* %8, i64 8
  %11 = bitcast i16* %10 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %11, align 8
  %12 = getelementptr inbounds i16, i16* %8, i64 %4
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %13, align 8
  %14 = getelementptr inbounds i16, i16* %12, i64 8
  %15 = bitcast i16* %14 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %15, align 8
  %16 = getelementptr inbounds i16, i16* %12, i64 %4
  %17 = bitcast i16* %16 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %17, align 8
  %18 = getelementptr inbounds i16, i16* %16, i64 8
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 144117387132666368, i64 144117387132666368>, <2 x i64>* %19, align 8
  %20 = getelementptr inbounds i16, i16* %16, i64 %4
  %21 = bitcast i16* %20 to i64*
  store i64 144117387132666368, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 4
  %23 = bitcast i16* %22 to i64*
  store i64 144117387132666368, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 8
  %25 = bitcast i16* %24 to i64*
  store i64 144117387132666368, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 12
  %27 = bitcast i16* %26 to i64*
  store i64 144117387132666368, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %20, i64 %4
  %29 = bitcast i16* %28 to i64*
  store i64 144117387132666368, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 144117387132666368, i64* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 8
  %33 = bitcast i16* %32 to i64*
  store i64 144117387132666368, i64* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 12
  %35 = bitcast i16* %34 to i64*
  store i64 144117387132666368, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %4
  %37 = bitcast i16* %36 to i64*
  store i64 144117387132666368, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 144117387132666368, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 144117387132666368, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 144117387132666368, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %36, i64 %4
  %45 = bitcast i16* %44 to i64*
  store i64 144117387132666368, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 144117387132666368, i64* %47, align 8
  %48 = getelementptr inbounds i16, i16* %44, i64 8
  %49 = bitcast i16* %48 to i64*
  store i64 144117387132666368, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %44, i64 12
  %51 = bitcast i16* %50 to i64*
  store i64 144117387132666368, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %44, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 144117387132666368, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 144117387132666368, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %52, i64 8
  %57 = bitcast i16* %56 to i64*
  store i64 144117387132666368, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %52, i64 12
  %59 = bitcast i16* %58 to i64*
  store i64 144117387132666368, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %52, i64 %4
  %61 = bitcast i16* %60 to i64*
  store i64 144117387132666368, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %60, i64 4
  %63 = bitcast i16* %62 to i64*
  store i64 144117387132666368, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %60, i64 8
  %65 = bitcast i16* %64 to i64*
  store i64 144117387132666368, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %60, i64 12
  %67 = bitcast i16* %66 to i64*
  store i64 144117387132666368, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %60, i64 %4
  %69 = bitcast i16* %68 to i64*
  store i64 144117387132666368, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 144117387132666368, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %68, i64 8
  %73 = bitcast i16* %72 to i64*
  store i64 144117387132666368, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %68, i64 12
  %75 = bitcast i16* %74 to i64*
  store i64 144117387132666368, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %68, i64 %4
  %77 = bitcast i16* %76 to i64*
  store i64 144117387132666368, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %76, i64 4
  %79 = bitcast i16* %78 to i64*
  store i64 144117387132666368, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %76, i64 8
  %81 = bitcast i16* %80 to i64*
  store i64 144117387132666368, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %76, i64 12
  %83 = bitcast i16* %82 to i64*
  store i64 144117387132666368, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %76, i64 %4
  %85 = bitcast i16* %84 to i64*
  store i64 144117387132666368, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 144117387132666368, i64* %87, align 8
  %88 = getelementptr inbounds i16, i16* %84, i64 8
  %89 = bitcast i16* %88 to i64*
  store i64 144117387132666368, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %84, i64 12
  %91 = bitcast i16* %90 to i64*
  store i64 144117387132666368, i64* %91, align 8
  %92 = getelementptr inbounds i16, i16* %84, i64 %4
  %93 = bitcast i16* %92 to i64*
  store i64 144117387132666368, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 144117387132666368, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 144117387132666368, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 144117387132666368, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %92, i64 %4
  %101 = bitcast i16* %100 to i64*
  store i64 144117387132666368, i64* %101, align 8
  %102 = getelementptr inbounds i16, i16* %100, i64 4
  %103 = bitcast i16* %102 to i64*
  store i64 144117387132666368, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %100, i64 8
  %105 = bitcast i16* %104 to i64*
  store i64 144117387132666368, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %100, i64 12
  %107 = bitcast i16* %106 to i64*
  store i64 144117387132666368, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %100, i64 %4
  %109 = bitcast i16* %108 to i64*
  store i64 144117387132666368, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 144117387132666368, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %108, i64 8
  %113 = bitcast i16* %112 to i64*
  store i64 144117387132666368, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %108, i64 12
  %115 = bitcast i16* %114 to i64*
  store i64 144117387132666368, i64* %115, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred4x4_vertical_add_10_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %4, i64 %7
  %9 = and i64 %2, -2
  %10 = mul nsw i64 %6, 3
  %11 = shl nsw i64 %6, 2
  %12 = load i16, i16* %8, align 2
  %13 = load i32, i32* %5, align 4
  %14 = trunc i32 %13 to i16
  %15 = add i16 %12, %14
  store i16 %15, i16* %4, align 2
  %16 = getelementptr inbounds i16, i16* %1, i64 8
  %17 = bitcast i16* %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = trunc i32 %18 to i16
  %20 = add i16 %15, %19
  %21 = getelementptr inbounds i16, i16* %8, i64 %9
  store i16 %20, i16* %21, align 2
  %22 = getelementptr inbounds i16, i16* %1, i64 16
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %20, %25
  %27 = getelementptr inbounds i16, i16* %8, i64 %10
  store i16 %26, i16* %27, align 2
  %28 = getelementptr inbounds i16, i16* %1, i64 24
  %29 = bitcast i16* %28 to i32*
  %30 = load i32, i32* %29, align 4
  %31 = trunc i32 %30 to i16
  %32 = add i16 %26, %31
  %33 = getelementptr inbounds i16, i16* %8, i64 %11
  store i16 %32, i16* %33, align 2
  %34 = getelementptr inbounds i16, i16* %8, i64 1
  %35 = getelementptr inbounds i16, i16* %1, i64 2
  %36 = bitcast i16* %35 to i32*
  %37 = load i16, i16* %34, align 2
  %38 = load i32, i32* %36, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %37, %39
  %41 = getelementptr inbounds i16, i16* %34, i64 %6
  store i16 %40, i16* %41, align 2
  %42 = getelementptr inbounds i16, i16* %1, i64 10
  %43 = bitcast i16* %42 to i32*
  %44 = load i32, i32* %43, align 4
  %45 = trunc i32 %44 to i16
  %46 = add i16 %40, %45
  %47 = getelementptr inbounds i16, i16* %34, i64 %9
  store i16 %46, i16* %47, align 2
  %48 = getelementptr inbounds i16, i16* %1, i64 18
  %49 = bitcast i16* %48 to i32*
  %50 = load i32, i32* %49, align 4
  %51 = trunc i32 %50 to i16
  %52 = add i16 %46, %51
  %53 = getelementptr inbounds i16, i16* %34, i64 %10
  store i16 %52, i16* %53, align 2
  %54 = getelementptr inbounds i16, i16* %1, i64 26
  %55 = bitcast i16* %54 to i32*
  %56 = load i32, i32* %55, align 4
  %57 = trunc i32 %56 to i16
  %58 = add i16 %52, %57
  %59 = getelementptr inbounds i16, i16* %34, i64 %11
  store i16 %58, i16* %59, align 2
  %60 = getelementptr inbounds i16, i16* %34, i64 1
  %61 = getelementptr inbounds i16, i16* %1, i64 4
  %62 = bitcast i16* %61 to i32*
  %63 = load i16, i16* %60, align 2
  %64 = load i32, i32* %62, align 4
  %65 = trunc i32 %64 to i16
  %66 = add i16 %63, %65
  %67 = getelementptr inbounds i16, i16* %60, i64 %6
  store i16 %66, i16* %67, align 2
  %68 = getelementptr inbounds i16, i16* %1, i64 12
  %69 = bitcast i16* %68 to i32*
  %70 = load i32, i32* %69, align 4
  %71 = trunc i32 %70 to i16
  %72 = add i16 %66, %71
  %73 = getelementptr inbounds i16, i16* %60, i64 %9
  store i16 %72, i16* %73, align 2
  %74 = getelementptr inbounds i16, i16* %1, i64 20
  %75 = bitcast i16* %74 to i32*
  %76 = load i32, i32* %75, align 4
  %77 = trunc i32 %76 to i16
  %78 = add i16 %72, %77
  %79 = getelementptr inbounds i16, i16* %60, i64 %10
  store i16 %78, i16* %79, align 2
  %80 = getelementptr inbounds i16, i16* %1, i64 28
  %81 = bitcast i16* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = trunc i32 %82 to i16
  %84 = add i16 %78, %83
  %85 = getelementptr inbounds i16, i16* %60, i64 %11
  store i16 %84, i16* %85, align 2
  %86 = getelementptr inbounds i16, i16* %60, i64 1
  %87 = getelementptr inbounds i16, i16* %1, i64 6
  %88 = bitcast i16* %87 to i32*
  %89 = load i16, i16* %86, align 2
  %90 = load i32, i32* %88, align 4
  %91 = trunc i32 %90 to i16
  %92 = add i16 %89, %91
  %93 = getelementptr inbounds i16, i16* %86, i64 %6
  store i16 %92, i16* %93, align 2
  %94 = getelementptr inbounds i16, i16* %1, i64 14
  %95 = bitcast i16* %94 to i32*
  %96 = load i32, i32* %95, align 4
  %97 = trunc i32 %96 to i16
  %98 = add i16 %92, %97
  %99 = getelementptr inbounds i16, i16* %86, i64 %9
  store i16 %98, i16* %99, align 2
  %100 = getelementptr inbounds i16, i16* %1, i64 22
  %101 = bitcast i16* %100 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = trunc i32 %102 to i16
  %104 = add i16 %98, %103
  %105 = getelementptr inbounds i16, i16* %86, i64 %10
  store i16 %104, i16* %105, align 2
  %106 = getelementptr inbounds i16, i16* %1, i64 30
  %107 = bitcast i16* %106 to i32*
  %108 = load i32, i32* %107, align 4
  %109 = trunc i32 %108 to i16
  %110 = add i16 %104, %109
  %111 = getelementptr inbounds i16, i16* %86, i64 %11
  store i16 %110, i16* %111, align 2
  %112 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %112, i8 0, i64 64, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred4x4_horizontal_add_10_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = load i32, i32* %5, align 4
  %11 = trunc i32 %10 to i16
  %12 = add i16 %9, %11
  store i16 %12, i16* %4, align 2
  %13 = getelementptr inbounds i16, i16* %1, i64 2
  %14 = bitcast i16* %13 to i32*
  %15 = load i32, i32* %14, align 4
  %16 = trunc i32 %15 to i16
  %17 = add i16 %12, %16
  %18 = getelementptr inbounds i8, i8* %0, i64 2
  %19 = bitcast i8* %18 to i16*
  store i16 %17, i16* %19, align 2
  %20 = getelementptr inbounds i16, i16* %1, i64 4
  %21 = bitcast i16* %20 to i32*
  %22 = load i32, i32* %21, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %17, %23
  %25 = getelementptr inbounds i8, i8* %0, i64 4
  %26 = bitcast i8* %25 to i16*
  store i16 %24, i16* %26, align 2
  %27 = getelementptr inbounds i16, i16* %1, i64 6
  %28 = bitcast i16* %27 to i32*
  %29 = load i32, i32* %28, align 4
  %30 = trunc i32 %29 to i16
  %31 = add i16 %24, %30
  %32 = getelementptr inbounds i8, i8* %0, i64 6
  %33 = bitcast i8* %32 to i16*
  store i16 %31, i16* %33, align 2
  %34 = getelementptr inbounds i16, i16* %4, i64 %6
  %35 = getelementptr inbounds i16, i16* %1, i64 8
  %36 = bitcast i16* %35 to i32*
  %37 = getelementptr inbounds i16, i16* %34, i64 -1
  %38 = load i16, i16* %37, align 2
  %39 = load i32, i32* %36, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %38, %40
  store i16 %41, i16* %34, align 2
  %42 = getelementptr inbounds i16, i16* %1, i64 10
  %43 = bitcast i16* %42 to i32*
  %44 = load i32, i32* %43, align 4
  %45 = trunc i32 %44 to i16
  %46 = add i16 %41, %45
  %47 = getelementptr inbounds i16, i16* %34, i64 1
  store i16 %46, i16* %47, align 2
  %48 = getelementptr inbounds i16, i16* %1, i64 12
  %49 = bitcast i16* %48 to i32*
  %50 = load i32, i32* %49, align 4
  %51 = trunc i32 %50 to i16
  %52 = add i16 %46, %51
  %53 = getelementptr inbounds i16, i16* %34, i64 2
  store i16 %52, i16* %53, align 2
  %54 = getelementptr inbounds i16, i16* %1, i64 14
  %55 = bitcast i16* %54 to i32*
  %56 = load i32, i32* %55, align 4
  %57 = trunc i32 %56 to i16
  %58 = add i16 %52, %57
  %59 = getelementptr inbounds i16, i16* %34, i64 3
  store i16 %58, i16* %59, align 2
  %60 = getelementptr inbounds i16, i16* %34, i64 %6
  %61 = getelementptr inbounds i16, i16* %1, i64 16
  %62 = bitcast i16* %61 to i32*
  %63 = getelementptr inbounds i16, i16* %60, i64 -1
  %64 = load i16, i16* %63, align 2
  %65 = load i32, i32* %62, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %64, %66
  store i16 %67, i16* %60, align 2
  %68 = getelementptr inbounds i16, i16* %1, i64 18
  %69 = bitcast i16* %68 to i32*
  %70 = load i32, i32* %69, align 4
  %71 = trunc i32 %70 to i16
  %72 = add i16 %67, %71
  %73 = getelementptr inbounds i16, i16* %60, i64 1
  store i16 %72, i16* %73, align 2
  %74 = getelementptr inbounds i16, i16* %1, i64 20
  %75 = bitcast i16* %74 to i32*
  %76 = load i32, i32* %75, align 4
  %77 = trunc i32 %76 to i16
  %78 = add i16 %72, %77
  %79 = getelementptr inbounds i16, i16* %60, i64 2
  store i16 %78, i16* %79, align 2
  %80 = getelementptr inbounds i16, i16* %1, i64 22
  %81 = bitcast i16* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = trunc i32 %82 to i16
  %84 = add i16 %78, %83
  %85 = getelementptr inbounds i16, i16* %60, i64 3
  store i16 %84, i16* %85, align 2
  %86 = getelementptr inbounds i16, i16* %60, i64 %6
  %87 = getelementptr inbounds i16, i16* %1, i64 24
  %88 = bitcast i16* %87 to i32*
  %89 = getelementptr inbounds i16, i16* %86, i64 -1
  %90 = load i16, i16* %89, align 2
  %91 = load i32, i32* %88, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %90, %92
  store i16 %93, i16* %86, align 2
  %94 = getelementptr inbounds i16, i16* %1, i64 26
  %95 = bitcast i16* %94 to i32*
  %96 = load i32, i32* %95, align 4
  %97 = trunc i32 %96 to i16
  %98 = add i16 %93, %97
  %99 = getelementptr inbounds i16, i16* %86, i64 1
  store i16 %98, i16* %99, align 2
  %100 = getelementptr inbounds i16, i16* %1, i64 28
  %101 = bitcast i16* %100 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = trunc i32 %102 to i16
  %104 = add i16 %98, %103
  %105 = getelementptr inbounds i16, i16* %86, i64 2
  store i16 %104, i16* %105, align 2
  %106 = getelementptr inbounds i16, i16* %1, i64 30
  %107 = bitcast i16* %106 to i32*
  %108 = load i32, i32* %107, align 4
  %109 = trunc i32 %108 to i16
  %110 = add i16 %104, %109
  %111 = getelementptr inbounds i16, i16* %86, i64 3
  store i16 %110, i16* %111, align 2
  %112 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %112, i8 0, i64 64, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_vertical_add_10_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %4, i64 %7
  %9 = and i64 %2, -2
  %10 = mul nsw i64 %6, 3
  %11 = shl nsw i64 %6, 2
  %12 = mul nsw i64 %6, 5
  %13 = mul nsw i64 %6, 6
  %14 = mul nsw i64 %6, 7
  %15 = shl nsw i64 %6, 3
  br label %16

16:                                               ; preds = %16, %3
  %17 = phi i32* [ %5, %3 ], [ %61, %16 ]
  %18 = phi i16* [ %8, %3 ], [ %60, %16 ]
  %19 = phi i32 [ 0, %3 ], [ %62, %16 ]
  %20 = load i16, i16* %18, align 2
  %21 = load i32, i32* %17, align 4
  %22 = trunc i32 %21 to i16
  %23 = add i16 %20, %22
  %24 = getelementptr inbounds i16, i16* %18, i64 %6
  store i16 %23, i16* %24, align 2
  %25 = getelementptr inbounds i32, i32* %17, i64 8
  %26 = load i32, i32* %25, align 4
  %27 = trunc i32 %26 to i16
  %28 = add i16 %23, %27
  %29 = getelementptr inbounds i16, i16* %18, i64 %9
  store i16 %28, i16* %29, align 2
  %30 = getelementptr inbounds i32, i32* %17, i64 16
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %28, %32
  %34 = getelementptr inbounds i16, i16* %18, i64 %10
  store i16 %33, i16* %34, align 2
  %35 = getelementptr inbounds i32, i32* %17, i64 24
  %36 = load i32, i32* %35, align 4
  %37 = trunc i32 %36 to i16
  %38 = add i16 %33, %37
  %39 = getelementptr inbounds i16, i16* %18, i64 %11
  store i16 %38, i16* %39, align 2
  %40 = getelementptr inbounds i32, i32* %17, i64 32
  %41 = load i32, i32* %40, align 4
  %42 = trunc i32 %41 to i16
  %43 = add i16 %38, %42
  %44 = getelementptr inbounds i16, i16* %18, i64 %12
  store i16 %43, i16* %44, align 2
  %45 = getelementptr inbounds i32, i32* %17, i64 40
  %46 = load i32, i32* %45, align 4
  %47 = trunc i32 %46 to i16
  %48 = add i16 %43, %47
  %49 = getelementptr inbounds i16, i16* %18, i64 %13
  store i16 %48, i16* %49, align 2
  %50 = getelementptr inbounds i32, i32* %17, i64 48
  %51 = load i32, i32* %50, align 4
  %52 = trunc i32 %51 to i16
  %53 = add i16 %48, %52
  %54 = getelementptr inbounds i16, i16* %18, i64 %14
  store i16 %53, i16* %54, align 2
  %55 = getelementptr inbounds i32, i32* %17, i64 56
  %56 = load i32, i32* %55, align 4
  %57 = trunc i32 %56 to i16
  %58 = add i16 %53, %57
  %59 = getelementptr inbounds i16, i16* %18, i64 %15
  store i16 %58, i16* %59, align 2
  %60 = getelementptr inbounds i16, i16* %18, i64 1
  %61 = getelementptr inbounds i32, i32* %17, i64 1
  %62 = add nuw nsw i32 %19, 1
  %63 = icmp eq i32 %62, 8
  br i1 %63, label %64, label %16

64:                                               ; preds = %16
  %65 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %65, i8 0, i64 256, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_horizontal_add_10_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  br label %7

7:                                                ; preds = %7, %3
  %8 = phi i32* [ %5, %3 ], [ %52, %7 ]
  %9 = phi i16* [ %4, %3 ], [ %51, %7 ]
  %10 = phi i32 [ 0, %3 ], [ %53, %7 ]
  %11 = getelementptr inbounds i16, i16* %9, i64 -1
  %12 = load i16, i16* %11, align 2
  %13 = load i32, i32* %8, align 4
  %14 = trunc i32 %13 to i16
  %15 = add i16 %12, %14
  store i16 %15, i16* %9, align 2
  %16 = getelementptr inbounds i32, i32* %8, i64 1
  %17 = load i32, i32* %16, align 4
  %18 = trunc i32 %17 to i16
  %19 = add i16 %15, %18
  %20 = getelementptr inbounds i16, i16* %9, i64 1
  store i16 %19, i16* %20, align 2
  %21 = getelementptr inbounds i32, i32* %8, i64 2
  %22 = load i32, i32* %21, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %19, %23
  %25 = getelementptr inbounds i16, i16* %9, i64 2
  store i16 %24, i16* %25, align 2
  %26 = getelementptr inbounds i32, i32* %8, i64 3
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %9, i64 3
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i32, i32* %8, i64 4
  %32 = load i32, i32* %31, align 4
  %33 = trunc i32 %32 to i16
  %34 = add i16 %29, %33
  %35 = getelementptr inbounds i16, i16* %9, i64 4
  store i16 %34, i16* %35, align 2
  %36 = getelementptr inbounds i32, i32* %8, i64 5
  %37 = load i32, i32* %36, align 4
  %38 = trunc i32 %37 to i16
  %39 = add i16 %34, %38
  %40 = getelementptr inbounds i16, i16* %9, i64 5
  store i16 %39, i16* %40, align 2
  %41 = getelementptr inbounds i32, i32* %8, i64 6
  %42 = load i32, i32* %41, align 4
  %43 = trunc i32 %42 to i16
  %44 = add i16 %39, %43
  %45 = getelementptr inbounds i16, i16* %9, i64 6
  store i16 %44, i16* %45, align 2
  %46 = getelementptr inbounds i32, i32* %8, i64 7
  %47 = load i32, i32* %46, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %44, %48
  %50 = getelementptr inbounds i16, i16* %9, i64 7
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %9, i64 %6
  %52 = getelementptr inbounds i32, i32* %8, i64 8
  %53 = add nuw nsw i32 %10, 1
  %54 = icmp eq i32 %53, 8
  br i1 %54, label %55, label %7

55:                                               ; preds = %7
  %56 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %56, i8 0, i64 256, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_vertical_filter_add_10_c(i8* nocapture, i16* nocapture, i32, i32, i64) #3 {
  %6 = alloca [8 x i16], align 16
  %7 = bitcast i8* %0 to i16*
  %8 = bitcast i16* %1 to i32*
  %9 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %9) #8
  %10 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 0
  %11 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 1
  %12 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 2
  %13 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 3
  %14 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 4
  %15 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 5
  %16 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 6
  %17 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 7
  %18 = lshr i64 %4, 1
  %19 = trunc i64 %18 to i32
  %20 = icmp eq i32 %2, 0
  %21 = sub nsw i32 0, %19
  %22 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 16, i1 false)
  br i1 %20, label %28, label %23

23:                                               ; preds = %5
  %24 = shl i64 %18, 32
  %25 = ashr exact i64 %24, 32
  %26 = xor i64 %25, -1
  %27 = sext i32 %21 to i64
  br label %31

28:                                               ; preds = %5
  %29 = sext i32 %21 to i64
  %30 = shl i64 %18, 32
  br label %31

31:                                               ; preds = %28, %23
  %32 = phi i64 [ %30, %28 ], [ %24, %23 ]
  %33 = phi i64 [ %29, %28 ], [ %27, %23 ]
  %34 = phi i64 [ %29, %28 ], [ %26, %23 ]
  %35 = getelementptr inbounds i16, i16* %7, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i32
  %38 = getelementptr inbounds i16, i16* %7, i64 %33
  %39 = load i16, i16* %38, align 2
  %40 = zext i16 %39 to i32
  %41 = shl nuw nsw i32 %40, 1
  %42 = sub i64 4294967296, %32
  %43 = ashr exact i64 %42, 32
  %44 = getelementptr inbounds i16, i16* %7, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %37
  %49 = add nuw nsw i32 %48, %41
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = sub i64 8589934592, %32
  %53 = ashr exact i64 %52, 32
  %54 = getelementptr inbounds i16, i16* %7, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i32
  %57 = add nuw nsw i32 %56, 2
  %58 = add nuw nsw i32 %57, %40
  %59 = add nuw nsw i32 %58, %51
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %56, 1
  %62 = sub i64 12884901888, %32
  %63 = ashr exact i64 %62, 32
  %64 = getelementptr inbounds i16, i16* %7, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i32
  %67 = add nuw nsw i32 %47, %61
  %68 = add nuw nsw i32 %67, %66
  %69 = lshr i32 %68, 2
  %70 = shl nuw nsw i32 %66, 1
  %71 = sub i64 17179869184, %32
  %72 = ashr exact i64 %71, 32
  %73 = getelementptr inbounds i16, i16* %7, i64 %72
  %74 = load i16, i16* %73, align 2
  %75 = zext i16 %74 to i32
  %76 = add nuw nsw i32 %57, %70
  %77 = add nuw nsw i32 %76, %75
  %78 = lshr i32 %77, 2
  %79 = shl nuw nsw i32 %75, 1
  %80 = sub i64 21474836480, %32
  %81 = ashr exact i64 %80, 32
  %82 = getelementptr inbounds i16, i16* %7, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = zext i16 %83 to i32
  %85 = add nuw nsw i32 %66, 2
  %86 = add nuw nsw i32 %85, %79
  %87 = add nuw nsw i32 %86, %84
  %88 = lshr i32 %87, 2
  %89 = shl nuw nsw i32 %84, 1
  %90 = sub i64 25769803776, %32
  %91 = ashr exact i64 %90, 32
  %92 = getelementptr inbounds i16, i16* %7, i64 %91
  %93 = load i16, i16* %92, align 2
  %94 = zext i16 %93 to i32
  %95 = add nuw nsw i32 %75, 2
  %96 = add nuw nsw i32 %95, %89
  %97 = add nuw nsw i32 %96, %94
  %98 = lshr i32 %97, 2
  %99 = shl nuw nsw i32 %94, 1
  %100 = sub i64 30064771072, %32
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %7, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i32
  %105 = add nuw nsw i32 %84, 2
  %106 = add nuw nsw i32 %105, %99
  %107 = add nuw nsw i32 %106, %104
  %108 = lshr i32 %107, 2
  %109 = icmp eq i32 %3, 0
  br i1 %109, label %116, label %110

110:                                              ; preds = %31
  %111 = sub i64 34359738368, %32
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds i16, i16* %7, i64 %112
  %114 = load i16, i16* %113, align 2
  %115 = zext i16 %114 to i32
  br label %116

116:                                              ; preds = %31, %110
  %117 = phi i32 [ %115, %110 ], [ %104, %31 ]
  %118 = shl nuw nsw i32 %104, 1
  %119 = add nuw nsw i32 %94, 2
  %120 = add nuw nsw i32 %119, %118
  %121 = add nuw nsw i32 %120, %117
  %122 = lshr i32 %121, 2
  %123 = trunc i32 %50 to i16
  store i16 %123, i16* %10, align 16
  %124 = trunc i32 %60 to i16
  store i16 %124, i16* %11, align 2
  %125 = trunc i32 %69 to i16
  store i16 %125, i16* %12, align 4
  %126 = trunc i32 %78 to i16
  store i16 %126, i16* %13, align 2
  %127 = trunc i32 %88 to i16
  store i16 %127, i16* %14, align 8
  %128 = trunc i32 %98 to i16
  store i16 %128, i16* %15, align 2
  %129 = trunc i32 %108 to i16
  store i16 %129, i16* %16, align 4
  %130 = trunc i32 %122 to i16
  store i16 %130, i16* %17, align 2
  %131 = ashr exact i64 %32, 32
  %132 = shl i64 %4, 32
  %133 = ashr exact i64 %132, 32
  %134 = and i64 %133, -2
  %135 = mul i64 %18, 12884901888
  %136 = ashr exact i64 %135, 32
  %137 = shl i64 %18, 34
  %138 = ashr exact i64 %137, 32
  %139 = mul i64 %18, 21474836480
  %140 = ashr exact i64 %139, 32
  %141 = mul i64 %18, 25769803776
  %142 = ashr exact i64 %141, 32
  %143 = mul i64 %18, 30064771072
  %144 = ashr exact i64 %143, 32
  br label %145

145:                                              ; preds = %190, %116
  %146 = phi i16 [ %123, %116 ], [ %194, %190 ]
  %147 = phi i64 [ 0, %116 ], [ %188, %190 ]
  %148 = phi i32* [ %8, %116 ], [ %191, %190 ]
  %149 = phi i16* [ %7, %116 ], [ %192, %190 ]
  %150 = load i32, i32* %148, align 4
  %151 = trunc i32 %150 to i16
  %152 = add i16 %146, %151
  store i16 %152, i16* %149, align 2
  %153 = getelementptr inbounds i32, i32* %148, i64 8
  %154 = load i32, i32* %153, align 4
  %155 = trunc i32 %154 to i16
  %156 = add i16 %152, %155
  %157 = getelementptr inbounds i16, i16* %149, i64 %131
  store i16 %156, i16* %157, align 2
  %158 = getelementptr inbounds i32, i32* %148, i64 16
  %159 = load i32, i32* %158, align 4
  %160 = trunc i32 %159 to i16
  %161 = add i16 %156, %160
  %162 = getelementptr inbounds i16, i16* %149, i64 %134
  store i16 %161, i16* %162, align 2
  %163 = getelementptr inbounds i32, i32* %148, i64 24
  %164 = load i32, i32* %163, align 4
  %165 = trunc i32 %164 to i16
  %166 = add i16 %161, %165
  %167 = getelementptr inbounds i16, i16* %149, i64 %136
  store i16 %166, i16* %167, align 2
  %168 = getelementptr inbounds i32, i32* %148, i64 32
  %169 = load i32, i32* %168, align 4
  %170 = trunc i32 %169 to i16
  %171 = add i16 %166, %170
  %172 = getelementptr inbounds i16, i16* %149, i64 %138
  store i16 %171, i16* %172, align 2
  %173 = getelementptr inbounds i32, i32* %148, i64 40
  %174 = load i32, i32* %173, align 4
  %175 = trunc i32 %174 to i16
  %176 = add i16 %171, %175
  %177 = getelementptr inbounds i16, i16* %149, i64 %140
  store i16 %176, i16* %177, align 2
  %178 = getelementptr inbounds i32, i32* %148, i64 48
  %179 = load i32, i32* %178, align 4
  %180 = trunc i32 %179 to i16
  %181 = add i16 %176, %180
  %182 = getelementptr inbounds i16, i16* %149, i64 %142
  store i16 %181, i16* %182, align 2
  %183 = getelementptr inbounds i32, i32* %148, i64 56
  %184 = load i32, i32* %183, align 4
  %185 = trunc i32 %184 to i16
  %186 = add i16 %181, %185
  %187 = getelementptr inbounds i16, i16* %149, i64 %144
  store i16 %186, i16* %187, align 2
  %188 = add nuw nsw i64 %147, 1
  %189 = icmp eq i64 %188, 8
  br i1 %189, label %195, label %190

190:                                              ; preds = %145
  %191 = getelementptr inbounds i32, i32* %148, i64 1
  %192 = getelementptr inbounds i16, i16* %149, i64 1
  %193 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 %188
  %194 = load i16, i16* %193, align 2
  br label %145

195:                                              ; preds = %145
  %196 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %196, i8 0, i64 256, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %9) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_horizontal_filter_add_10_c(i8* nocapture, i16* nocapture, i32, i32, i64) #3 {
  %6 = alloca [8 x i16], align 16
  %7 = bitcast i8* %0 to i16*
  %8 = bitcast i16* %1 to i32*
  %9 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %9) #8
  %10 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 0
  %11 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 1
  %12 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 2
  %13 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 3
  %14 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 4
  %15 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 5
  %16 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 6
  %17 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 7
  %18 = lshr i64 %4, 1
  %19 = icmp eq i32 %2, 0
  %20 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 16, i1 false)
  br i1 %19, label %26, label %21

21:                                               ; preds = %5
  %22 = shl i64 %18, 32
  %23 = ashr exact i64 %22, 32
  %24 = xor i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %7, i64 %24
  br label %31

26:                                               ; preds = %5
  %27 = getelementptr inbounds i8, i8* %0, i64 -2
  %28 = bitcast i8* %27 to i16*
  %29 = shl i64 %18, 32
  %30 = ashr exact i64 %29, 32
  br label %31

31:                                               ; preds = %26, %21
  %32 = phi i64 [ %30, %26 ], [ %23, %21 ]
  %33 = phi i64 [ %29, %26 ], [ %22, %21 ]
  %34 = phi i16* [ %28, %26 ], [ %25, %21 ]
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = getelementptr inbounds i8, i8* %0, i64 -2
  %38 = bitcast i8* %37 to i16*
  %39 = load i16, i16* %38, align 2
  %40 = zext i16 %39 to i32
  %41 = shl nuw nsw i32 %40, 1
  %42 = add i64 %33, -4294967296
  %43 = ashr exact i64 %42, 32
  %44 = getelementptr inbounds i16, i16* %7, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %36
  %49 = add nuw nsw i32 %48, %41
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = shl i64 %4, 32
  %53 = and i64 %52, -8589934592
  %54 = add i64 %53, -4294967296
  %55 = ashr exact i64 %54, 32
  %56 = getelementptr inbounds i16, i16* %7, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %58, 2
  %60 = add nuw nsw i32 %59, %40
  %61 = add nuw nsw i32 %60, %51
  %62 = lshr i32 %61, 2
  %63 = shl nuw nsw i32 %58, 1
  %64 = mul i64 %18, 12884901888
  %65 = add i64 %64, -4294967296
  %66 = ashr exact i64 %65, 32
  %67 = getelementptr inbounds i16, i16* %7, i64 %66
  %68 = load i16, i16* %67, align 2
  %69 = zext i16 %68 to i32
  %70 = add nuw nsw i32 %47, %63
  %71 = add nuw nsw i32 %70, %69
  %72 = lshr i32 %71, 2
  %73 = shl nuw nsw i32 %69, 1
  %74 = shl i64 %18, 34
  %75 = add i64 %74, -4294967296
  %76 = ashr exact i64 %75, 32
  %77 = getelementptr inbounds i16, i16* %7, i64 %76
  %78 = load i16, i16* %77, align 2
  %79 = zext i16 %78 to i32
  %80 = add nuw nsw i32 %59, %73
  %81 = add nuw nsw i32 %80, %79
  %82 = lshr i32 %81, 2
  %83 = shl nuw nsw i32 %79, 1
  %84 = mul i64 %18, 21474836480
  %85 = add i64 %84, -4294967296
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i16, i16* %7, i64 %86
  %88 = load i16, i16* %87, align 2
  %89 = zext i16 %88 to i32
  %90 = add nuw nsw i32 %69, 2
  %91 = add nuw nsw i32 %90, %83
  %92 = add nuw nsw i32 %91, %89
  %93 = lshr i32 %92, 2
  %94 = shl nuw nsw i32 %89, 1
  %95 = mul i64 %18, 25769803776
  %96 = add i64 %95, -4294967296
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i16, i16* %7, i64 %97
  %99 = load i16, i16* %98, align 2
  %100 = zext i16 %99 to i32
  %101 = add nuw nsw i32 %79, 2
  %102 = add nuw nsw i32 %101, %94
  %103 = add nuw nsw i32 %102, %100
  %104 = lshr i32 %103, 2
  %105 = shl nuw nsw i32 %100, 1
  %106 = mul i64 %18, 30064771072
  %107 = add i64 %106, -4294967296
  %108 = ashr exact i64 %107, 32
  %109 = getelementptr inbounds i16, i16* %7, i64 %108
  %110 = load i16, i16* %109, align 2
  %111 = zext i16 %110 to i32
  %112 = add nuw nsw i32 %89, 2
  %113 = add nuw nsw i32 %112, %105
  %114 = add nuw nsw i32 %113, %111
  %115 = lshr i32 %114, 2
  %116 = mul nuw nsw i32 %111, 3
  %117 = add nuw nsw i32 %100, 2
  %118 = add nuw nsw i32 %117, %116
  %119 = lshr i32 %118, 2
  %120 = trunc i32 %50 to i16
  store i16 %120, i16* %10, align 16
  %121 = trunc i32 %62 to i16
  store i16 %121, i16* %11, align 2
  %122 = trunc i32 %72 to i16
  store i16 %122, i16* %12, align 4
  %123 = trunc i32 %82 to i16
  store i16 %123, i16* %13, align 2
  %124 = trunc i32 %93 to i16
  store i16 %124, i16* %14, align 8
  %125 = trunc i32 %104 to i16
  store i16 %125, i16* %15, align 2
  %126 = trunc i32 %115 to i16
  store i16 %126, i16* %16, align 4
  %127 = trunc i32 %119 to i16
  store i16 %127, i16* %17, align 2
  br label %128

128:                                              ; preds = %173, %31
  %129 = phi i16 [ %120, %31 ], [ %177, %173 ]
  %130 = phi i64 [ 0, %31 ], [ %171, %173 ]
  %131 = phi i16* [ %7, %31 ], [ %175, %173 ]
  %132 = phi i32* [ %8, %31 ], [ %174, %173 ]
  %133 = load i32, i32* %132, align 4
  %134 = trunc i32 %133 to i16
  %135 = add i16 %129, %134
  store i16 %135, i16* %131, align 2
  %136 = getelementptr inbounds i32, i32* %132, i64 1
  %137 = load i32, i32* %136, align 4
  %138 = trunc i32 %137 to i16
  %139 = add i16 %135, %138
  %140 = getelementptr inbounds i16, i16* %131, i64 1
  store i16 %139, i16* %140, align 2
  %141 = getelementptr inbounds i32, i32* %132, i64 2
  %142 = load i32, i32* %141, align 4
  %143 = trunc i32 %142 to i16
  %144 = add i16 %139, %143
  %145 = getelementptr inbounds i16, i16* %131, i64 2
  store i16 %144, i16* %145, align 2
  %146 = getelementptr inbounds i32, i32* %132, i64 3
  %147 = load i32, i32* %146, align 4
  %148 = trunc i32 %147 to i16
  %149 = add i16 %144, %148
  %150 = getelementptr inbounds i16, i16* %131, i64 3
  store i16 %149, i16* %150, align 2
  %151 = getelementptr inbounds i32, i32* %132, i64 4
  %152 = load i32, i32* %151, align 4
  %153 = trunc i32 %152 to i16
  %154 = add i16 %149, %153
  %155 = getelementptr inbounds i16, i16* %131, i64 4
  store i16 %154, i16* %155, align 2
  %156 = getelementptr inbounds i32, i32* %132, i64 5
  %157 = load i32, i32* %156, align 4
  %158 = trunc i32 %157 to i16
  %159 = add i16 %154, %158
  %160 = getelementptr inbounds i16, i16* %131, i64 5
  store i16 %159, i16* %160, align 2
  %161 = getelementptr inbounds i32, i32* %132, i64 6
  %162 = load i32, i32* %161, align 4
  %163 = trunc i32 %162 to i16
  %164 = add i16 %159, %163
  %165 = getelementptr inbounds i16, i16* %131, i64 6
  store i16 %164, i16* %165, align 2
  %166 = getelementptr inbounds i32, i32* %132, i64 7
  %167 = load i32, i32* %166, align 4
  %168 = trunc i32 %167 to i16
  %169 = add i16 %164, %168
  %170 = getelementptr inbounds i16, i16* %131, i64 7
  store i16 %169, i16* %170, align 2
  %171 = add nuw nsw i64 %130, 1
  %172 = icmp eq i64 %171, 8
  br i1 %172, label %178, label %173

173:                                              ; preds = %128
  %174 = getelementptr inbounds i32, i32* %132, i64 8
  %175 = getelementptr inbounds i16, i16* %131, i64 %32
  %176 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 %171
  %177 = load i16, i16* %176, align 2
  br label %128

178:                                              ; preds = %128
  %179 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %179, i8 0, i64 256, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %9) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8_vertical_add_10_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  %6 = sub nsw i64 0, %5
  %7 = and i64 %3, -2
  %8 = mul nsw i64 %5, 3
  %9 = shl nsw i64 %5, 2
  br label %10

10:                                               ; preds = %10, %4
  %11 = phi i64 [ 0, %4 ], [ %122, %10 ]
  %12 = getelementptr inbounds i32, i32* %1, i64 %11
  %13 = load i32, i32* %12, align 4
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = shl i64 %11, 5
  %17 = getelementptr inbounds i16, i16* %2, i64 %16
  %18 = bitcast i8* %15 to i16*
  %19 = bitcast i16* %17 to i32*
  %20 = getelementptr inbounds i16, i16* %18, i64 %6
  %21 = load i16, i16* %20, align 2
  %22 = load i32, i32* %19, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %21, %23
  store i16 %24, i16* %18, align 2
  %25 = getelementptr inbounds i16, i16* %17, i64 8
  %26 = bitcast i16* %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %20, i64 %7
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i16, i16* %17, i64 16
  %32 = bitcast i16* %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = trunc i32 %33 to i16
  %35 = add i16 %29, %34
  %36 = getelementptr inbounds i16, i16* %20, i64 %8
  store i16 %35, i16* %36, align 2
  %37 = getelementptr inbounds i16, i16* %17, i64 24
  %38 = bitcast i16* %37 to i32*
  %39 = load i32, i32* %38, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %35, %40
  %42 = getelementptr inbounds i16, i16* %20, i64 %9
  store i16 %41, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %20, i64 1
  %44 = getelementptr inbounds i16, i16* %17, i64 2
  %45 = bitcast i16* %44 to i32*
  %46 = load i16, i16* %43, align 2
  %47 = load i32, i32* %45, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %46, %48
  %50 = getelementptr inbounds i16, i16* %43, i64 %5
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %17, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %49, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 %7
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %17, i64 18
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 %8
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %17, i64 26
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 %9
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 1
  %70 = getelementptr inbounds i16, i16* %17, i64 4
  %71 = bitcast i16* %70 to i32*
  %72 = load i16, i16* %69, align 2
  %73 = load i32, i32* %71, align 4
  %74 = trunc i32 %73 to i16
  %75 = add i16 %72, %74
  %76 = getelementptr inbounds i16, i16* %69, i64 %5
  store i16 %75, i16* %76, align 2
  %77 = getelementptr inbounds i16, i16* %17, i64 12
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %75, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 %7
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %17, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 %8
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %17, i64 28
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 %9
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 1
  %96 = getelementptr inbounds i16, i16* %17, i64 6
  %97 = bitcast i16* %96 to i32*
  %98 = load i16, i16* %95, align 2
  %99 = load i32, i32* %97, align 4
  %100 = trunc i32 %99 to i16
  %101 = add i16 %98, %100
  %102 = getelementptr inbounds i16, i16* %95, i64 %5
  store i16 %101, i16* %102, align 2
  %103 = getelementptr inbounds i16, i16* %17, i64 14
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %101, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 %7
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %17, i64 22
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 %8
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %17, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 %9
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %11, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %10

124:                                              ; preds = %10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8_horizontal_add_10_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %122, %6 ]
  %8 = getelementptr inbounds i32, i32* %1, i64 %7
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = shl i64 %7, 5
  %13 = getelementptr inbounds i16, i16* %2, i64 %12
  %14 = bitcast i8* %11 to i16*
  %15 = bitcast i16* %13 to i32*
  %16 = getelementptr inbounds i8, i8* %11, i64 -2
  %17 = bitcast i8* %16 to i16*
  %18 = load i16, i16* %17, align 2
  %19 = load i32, i32* %15, align 4
  %20 = trunc i32 %19 to i16
  %21 = add i16 %18, %20
  store i16 %21, i16* %14, align 2
  %22 = getelementptr inbounds i16, i16* %13, i64 2
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %21, %25
  %27 = getelementptr inbounds i8, i8* %11, i64 2
  %28 = bitcast i8* %27 to i16*
  store i16 %26, i16* %28, align 2
  %29 = getelementptr inbounds i16, i16* %13, i64 4
  %30 = bitcast i16* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %26, %32
  %34 = getelementptr inbounds i8, i8* %11, i64 4
  %35 = bitcast i8* %34 to i16*
  store i16 %33, i16* %35, align 2
  %36 = getelementptr inbounds i16, i16* %13, i64 6
  %37 = bitcast i16* %36 to i32*
  %38 = load i32, i32* %37, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %33, %39
  %41 = getelementptr inbounds i8, i8* %11, i64 6
  %42 = bitcast i8* %41 to i16*
  store i16 %40, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %14, i64 %5
  %44 = getelementptr inbounds i16, i16* %13, i64 8
  %45 = bitcast i16* %44 to i32*
  %46 = getelementptr inbounds i16, i16* %43, i64 -1
  %47 = load i16, i16* %46, align 2
  %48 = load i32, i32* %45, align 4
  %49 = trunc i32 %48 to i16
  %50 = add i16 %47, %49
  store i16 %50, i16* %43, align 2
  %51 = getelementptr inbounds i16, i16* %13, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %50, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 1
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %13, i64 12
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 2
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %13, i64 14
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 3
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 %5
  %70 = getelementptr inbounds i16, i16* %13, i64 16
  %71 = bitcast i16* %70 to i32*
  %72 = getelementptr inbounds i16, i16* %69, i64 -1
  %73 = load i16, i16* %72, align 2
  %74 = load i32, i32* %71, align 4
  %75 = trunc i32 %74 to i16
  %76 = add i16 %73, %75
  store i16 %76, i16* %69, align 2
  %77 = getelementptr inbounds i16, i16* %13, i64 18
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %76, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 1
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %13, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 2
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %13, i64 22
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 3
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 %5
  %96 = getelementptr inbounds i16, i16* %13, i64 24
  %97 = bitcast i16* %96 to i32*
  %98 = getelementptr inbounds i16, i16* %95, i64 -1
  %99 = load i16, i16* %98, align 2
  %100 = load i32, i32* %97, align 4
  %101 = trunc i32 %100 to i16
  %102 = add i16 %99, %101
  store i16 %102, i16* %95, align 2
  %103 = getelementptr inbounds i16, i16* %13, i64 26
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %102, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 1
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %13, i64 28
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 2
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %13, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 3
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %7, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %6

124:                                              ; preds = %6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x16_vertical_add_10_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  %6 = sub nsw i64 0, %5
  %7 = and i64 %3, -2
  %8 = mul nsw i64 %5, 3
  %9 = shl nsw i64 %5, 2
  br label %10

10:                                               ; preds = %10, %4
  %11 = phi i64 [ 0, %4 ], [ %122, %10 ]
  %12 = getelementptr inbounds i32, i32* %1, i64 %11
  %13 = load i32, i32* %12, align 4
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = shl i64 %11, 5
  %17 = getelementptr inbounds i16, i16* %2, i64 %16
  %18 = bitcast i8* %15 to i16*
  %19 = bitcast i16* %17 to i32*
  %20 = getelementptr inbounds i16, i16* %18, i64 %6
  %21 = load i16, i16* %20, align 2
  %22 = load i32, i32* %19, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %21, %23
  store i16 %24, i16* %18, align 2
  %25 = getelementptr inbounds i16, i16* %17, i64 8
  %26 = bitcast i16* %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %20, i64 %7
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i16, i16* %17, i64 16
  %32 = bitcast i16* %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = trunc i32 %33 to i16
  %35 = add i16 %29, %34
  %36 = getelementptr inbounds i16, i16* %20, i64 %8
  store i16 %35, i16* %36, align 2
  %37 = getelementptr inbounds i16, i16* %17, i64 24
  %38 = bitcast i16* %37 to i32*
  %39 = load i32, i32* %38, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %35, %40
  %42 = getelementptr inbounds i16, i16* %20, i64 %9
  store i16 %41, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %20, i64 1
  %44 = getelementptr inbounds i16, i16* %17, i64 2
  %45 = bitcast i16* %44 to i32*
  %46 = load i16, i16* %43, align 2
  %47 = load i32, i32* %45, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %46, %48
  %50 = getelementptr inbounds i16, i16* %43, i64 %5
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %17, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %49, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 %7
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %17, i64 18
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 %8
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %17, i64 26
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 %9
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 1
  %70 = getelementptr inbounds i16, i16* %17, i64 4
  %71 = bitcast i16* %70 to i32*
  %72 = load i16, i16* %69, align 2
  %73 = load i32, i32* %71, align 4
  %74 = trunc i32 %73 to i16
  %75 = add i16 %72, %74
  %76 = getelementptr inbounds i16, i16* %69, i64 %5
  store i16 %75, i16* %76, align 2
  %77 = getelementptr inbounds i16, i16* %17, i64 12
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %75, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 %7
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %17, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 %8
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %17, i64 28
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 %9
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 1
  %96 = getelementptr inbounds i16, i16* %17, i64 6
  %97 = bitcast i16* %96 to i32*
  %98 = load i16, i16* %95, align 2
  %99 = load i32, i32* %97, align 4
  %100 = trunc i32 %99 to i16
  %101 = add i16 %98, %100
  %102 = getelementptr inbounds i16, i16* %95, i64 %5
  store i16 %101, i16* %102, align 2
  %103 = getelementptr inbounds i16, i16* %17, i64 14
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %101, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 %7
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %17, i64 22
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 %8
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %17, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 %9
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %11, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %10

124:                                              ; preds = %10, %124
  %125 = phi i64 [ %237, %124 ], [ 4, %10 ]
  %126 = add nuw nsw i64 %125, 4
  %127 = getelementptr inbounds i32, i32* %1, i64 %126
  %128 = load i32, i32* %127, align 4
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds i8, i8* %0, i64 %129
  %131 = shl i64 %125, 5
  %132 = getelementptr inbounds i16, i16* %2, i64 %131
  %133 = bitcast i8* %130 to i16*
  %134 = bitcast i16* %132 to i32*
  %135 = getelementptr inbounds i16, i16* %133, i64 %6
  %136 = load i16, i16* %135, align 2
  %137 = load i32, i32* %134, align 4
  %138 = trunc i32 %137 to i16
  %139 = add i16 %136, %138
  store i16 %139, i16* %133, align 2
  %140 = getelementptr inbounds i16, i16* %132, i64 8
  %141 = bitcast i16* %140 to i32*
  %142 = load i32, i32* %141, align 4
  %143 = trunc i32 %142 to i16
  %144 = add i16 %139, %143
  %145 = getelementptr inbounds i16, i16* %135, i64 %7
  store i16 %144, i16* %145, align 2
  %146 = getelementptr inbounds i16, i16* %132, i64 16
  %147 = bitcast i16* %146 to i32*
  %148 = load i32, i32* %147, align 4
  %149 = trunc i32 %148 to i16
  %150 = add i16 %144, %149
  %151 = getelementptr inbounds i16, i16* %135, i64 %8
  store i16 %150, i16* %151, align 2
  %152 = getelementptr inbounds i16, i16* %132, i64 24
  %153 = bitcast i16* %152 to i32*
  %154 = load i32, i32* %153, align 4
  %155 = trunc i32 %154 to i16
  %156 = add i16 %150, %155
  %157 = getelementptr inbounds i16, i16* %135, i64 %9
  store i16 %156, i16* %157, align 2
  %158 = getelementptr inbounds i16, i16* %135, i64 1
  %159 = getelementptr inbounds i16, i16* %132, i64 2
  %160 = bitcast i16* %159 to i32*
  %161 = load i16, i16* %158, align 2
  %162 = load i32, i32* %160, align 4
  %163 = trunc i32 %162 to i16
  %164 = add i16 %161, %163
  %165 = getelementptr inbounds i16, i16* %158, i64 %5
  store i16 %164, i16* %165, align 2
  %166 = getelementptr inbounds i16, i16* %132, i64 10
  %167 = bitcast i16* %166 to i32*
  %168 = load i32, i32* %167, align 4
  %169 = trunc i32 %168 to i16
  %170 = add i16 %164, %169
  %171 = getelementptr inbounds i16, i16* %158, i64 %7
  store i16 %170, i16* %171, align 2
  %172 = getelementptr inbounds i16, i16* %132, i64 18
  %173 = bitcast i16* %172 to i32*
  %174 = load i32, i32* %173, align 4
  %175 = trunc i32 %174 to i16
  %176 = add i16 %170, %175
  %177 = getelementptr inbounds i16, i16* %158, i64 %8
  store i16 %176, i16* %177, align 2
  %178 = getelementptr inbounds i16, i16* %132, i64 26
  %179 = bitcast i16* %178 to i32*
  %180 = load i32, i32* %179, align 4
  %181 = trunc i32 %180 to i16
  %182 = add i16 %176, %181
  %183 = getelementptr inbounds i16, i16* %158, i64 %9
  store i16 %182, i16* %183, align 2
  %184 = getelementptr inbounds i16, i16* %158, i64 1
  %185 = getelementptr inbounds i16, i16* %132, i64 4
  %186 = bitcast i16* %185 to i32*
  %187 = load i16, i16* %184, align 2
  %188 = load i32, i32* %186, align 4
  %189 = trunc i32 %188 to i16
  %190 = add i16 %187, %189
  %191 = getelementptr inbounds i16, i16* %184, i64 %5
  store i16 %190, i16* %191, align 2
  %192 = getelementptr inbounds i16, i16* %132, i64 12
  %193 = bitcast i16* %192 to i32*
  %194 = load i32, i32* %193, align 4
  %195 = trunc i32 %194 to i16
  %196 = add i16 %190, %195
  %197 = getelementptr inbounds i16, i16* %184, i64 %7
  store i16 %196, i16* %197, align 2
  %198 = getelementptr inbounds i16, i16* %132, i64 20
  %199 = bitcast i16* %198 to i32*
  %200 = load i32, i32* %199, align 4
  %201 = trunc i32 %200 to i16
  %202 = add i16 %196, %201
  %203 = getelementptr inbounds i16, i16* %184, i64 %8
  store i16 %202, i16* %203, align 2
  %204 = getelementptr inbounds i16, i16* %132, i64 28
  %205 = bitcast i16* %204 to i32*
  %206 = load i32, i32* %205, align 4
  %207 = trunc i32 %206 to i16
  %208 = add i16 %202, %207
  %209 = getelementptr inbounds i16, i16* %184, i64 %9
  store i16 %208, i16* %209, align 2
  %210 = getelementptr inbounds i16, i16* %184, i64 1
  %211 = getelementptr inbounds i16, i16* %132, i64 6
  %212 = bitcast i16* %211 to i32*
  %213 = load i16, i16* %210, align 2
  %214 = load i32, i32* %212, align 4
  %215 = trunc i32 %214 to i16
  %216 = add i16 %213, %215
  %217 = getelementptr inbounds i16, i16* %210, i64 %5
  store i16 %216, i16* %217, align 2
  %218 = getelementptr inbounds i16, i16* %132, i64 14
  %219 = bitcast i16* %218 to i32*
  %220 = load i32, i32* %219, align 4
  %221 = trunc i32 %220 to i16
  %222 = add i16 %216, %221
  %223 = getelementptr inbounds i16, i16* %210, i64 %7
  store i16 %222, i16* %223, align 2
  %224 = getelementptr inbounds i16, i16* %132, i64 22
  %225 = bitcast i16* %224 to i32*
  %226 = load i32, i32* %225, align 4
  %227 = trunc i32 %226 to i16
  %228 = add i16 %222, %227
  %229 = getelementptr inbounds i16, i16* %210, i64 %8
  store i16 %228, i16* %229, align 2
  %230 = getelementptr inbounds i16, i16* %132, i64 30
  %231 = bitcast i16* %230 to i32*
  %232 = load i32, i32* %231, align 4
  %233 = trunc i32 %232 to i16
  %234 = add i16 %228, %233
  %235 = getelementptr inbounds i16, i16* %210, i64 %9
  store i16 %234, i16* %235, align 2
  %236 = bitcast i16* %132 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %236, i8 0, i64 64, i1 false) #8
  %237 = add nuw nsw i64 %125, 1
  %238 = icmp eq i64 %237, 8
  br i1 %238, label %239, label %124

239:                                              ; preds = %124
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x16_horizontal_add_10_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %122, %6 ]
  %8 = getelementptr inbounds i32, i32* %1, i64 %7
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = shl i64 %7, 5
  %13 = getelementptr inbounds i16, i16* %2, i64 %12
  %14 = bitcast i8* %11 to i16*
  %15 = bitcast i16* %13 to i32*
  %16 = getelementptr inbounds i8, i8* %11, i64 -2
  %17 = bitcast i8* %16 to i16*
  %18 = load i16, i16* %17, align 2
  %19 = load i32, i32* %15, align 4
  %20 = trunc i32 %19 to i16
  %21 = add i16 %18, %20
  store i16 %21, i16* %14, align 2
  %22 = getelementptr inbounds i16, i16* %13, i64 2
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %21, %25
  %27 = getelementptr inbounds i8, i8* %11, i64 2
  %28 = bitcast i8* %27 to i16*
  store i16 %26, i16* %28, align 2
  %29 = getelementptr inbounds i16, i16* %13, i64 4
  %30 = bitcast i16* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %26, %32
  %34 = getelementptr inbounds i8, i8* %11, i64 4
  %35 = bitcast i8* %34 to i16*
  store i16 %33, i16* %35, align 2
  %36 = getelementptr inbounds i16, i16* %13, i64 6
  %37 = bitcast i16* %36 to i32*
  %38 = load i32, i32* %37, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %33, %39
  %41 = getelementptr inbounds i8, i8* %11, i64 6
  %42 = bitcast i8* %41 to i16*
  store i16 %40, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %14, i64 %5
  %44 = getelementptr inbounds i16, i16* %13, i64 8
  %45 = bitcast i16* %44 to i32*
  %46 = getelementptr inbounds i16, i16* %43, i64 -1
  %47 = load i16, i16* %46, align 2
  %48 = load i32, i32* %45, align 4
  %49 = trunc i32 %48 to i16
  %50 = add i16 %47, %49
  store i16 %50, i16* %43, align 2
  %51 = getelementptr inbounds i16, i16* %13, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %50, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 1
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %13, i64 12
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 2
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %13, i64 14
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 3
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 %5
  %70 = getelementptr inbounds i16, i16* %13, i64 16
  %71 = bitcast i16* %70 to i32*
  %72 = getelementptr inbounds i16, i16* %69, i64 -1
  %73 = load i16, i16* %72, align 2
  %74 = load i32, i32* %71, align 4
  %75 = trunc i32 %74 to i16
  %76 = add i16 %73, %75
  store i16 %76, i16* %69, align 2
  %77 = getelementptr inbounds i16, i16* %13, i64 18
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %76, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 1
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %13, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 2
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %13, i64 22
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 3
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 %5
  %96 = getelementptr inbounds i16, i16* %13, i64 24
  %97 = bitcast i16* %96 to i32*
  %98 = getelementptr inbounds i16, i16* %95, i64 -1
  %99 = load i16, i16* %98, align 2
  %100 = load i32, i32* %97, align 4
  %101 = trunc i32 %100 to i16
  %102 = add i16 %99, %101
  store i16 %102, i16* %95, align 2
  %103 = getelementptr inbounds i16, i16* %13, i64 26
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %102, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 1
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %13, i64 28
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 2
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %13, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 3
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %7, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %6

124:                                              ; preds = %6, %124
  %125 = phi i64 [ %241, %124 ], [ 4, %6 ]
  %126 = add nuw nsw i64 %125, 4
  %127 = getelementptr inbounds i32, i32* %1, i64 %126
  %128 = load i32, i32* %127, align 4
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds i8, i8* %0, i64 %129
  %131 = shl i64 %125, 5
  %132 = getelementptr inbounds i16, i16* %2, i64 %131
  %133 = bitcast i8* %130 to i16*
  %134 = bitcast i16* %132 to i32*
  %135 = getelementptr inbounds i8, i8* %130, i64 -2
  %136 = bitcast i8* %135 to i16*
  %137 = load i16, i16* %136, align 2
  %138 = load i32, i32* %134, align 4
  %139 = trunc i32 %138 to i16
  %140 = add i16 %137, %139
  store i16 %140, i16* %133, align 2
  %141 = getelementptr inbounds i16, i16* %132, i64 2
  %142 = bitcast i16* %141 to i32*
  %143 = load i32, i32* %142, align 4
  %144 = trunc i32 %143 to i16
  %145 = add i16 %140, %144
  %146 = getelementptr inbounds i8, i8* %130, i64 2
  %147 = bitcast i8* %146 to i16*
  store i16 %145, i16* %147, align 2
  %148 = getelementptr inbounds i16, i16* %132, i64 4
  %149 = bitcast i16* %148 to i32*
  %150 = load i32, i32* %149, align 4
  %151 = trunc i32 %150 to i16
  %152 = add i16 %145, %151
  %153 = getelementptr inbounds i8, i8* %130, i64 4
  %154 = bitcast i8* %153 to i16*
  store i16 %152, i16* %154, align 2
  %155 = getelementptr inbounds i16, i16* %132, i64 6
  %156 = bitcast i16* %155 to i32*
  %157 = load i32, i32* %156, align 4
  %158 = trunc i32 %157 to i16
  %159 = add i16 %152, %158
  %160 = getelementptr inbounds i8, i8* %130, i64 6
  %161 = bitcast i8* %160 to i16*
  store i16 %159, i16* %161, align 2
  %162 = getelementptr inbounds i16, i16* %133, i64 %5
  %163 = getelementptr inbounds i16, i16* %132, i64 8
  %164 = bitcast i16* %163 to i32*
  %165 = getelementptr inbounds i16, i16* %162, i64 -1
  %166 = load i16, i16* %165, align 2
  %167 = load i32, i32* %164, align 4
  %168 = trunc i32 %167 to i16
  %169 = add i16 %166, %168
  store i16 %169, i16* %162, align 2
  %170 = getelementptr inbounds i16, i16* %132, i64 10
  %171 = bitcast i16* %170 to i32*
  %172 = load i32, i32* %171, align 4
  %173 = trunc i32 %172 to i16
  %174 = add i16 %169, %173
  %175 = getelementptr inbounds i16, i16* %162, i64 1
  store i16 %174, i16* %175, align 2
  %176 = getelementptr inbounds i16, i16* %132, i64 12
  %177 = bitcast i16* %176 to i32*
  %178 = load i32, i32* %177, align 4
  %179 = trunc i32 %178 to i16
  %180 = add i16 %174, %179
  %181 = getelementptr inbounds i16, i16* %162, i64 2
  store i16 %180, i16* %181, align 2
  %182 = getelementptr inbounds i16, i16* %132, i64 14
  %183 = bitcast i16* %182 to i32*
  %184 = load i32, i32* %183, align 4
  %185 = trunc i32 %184 to i16
  %186 = add i16 %180, %185
  %187 = getelementptr inbounds i16, i16* %162, i64 3
  store i16 %186, i16* %187, align 2
  %188 = getelementptr inbounds i16, i16* %162, i64 %5
  %189 = getelementptr inbounds i16, i16* %132, i64 16
  %190 = bitcast i16* %189 to i32*
  %191 = getelementptr inbounds i16, i16* %188, i64 -1
  %192 = load i16, i16* %191, align 2
  %193 = load i32, i32* %190, align 4
  %194 = trunc i32 %193 to i16
  %195 = add i16 %192, %194
  store i16 %195, i16* %188, align 2
  %196 = getelementptr inbounds i16, i16* %132, i64 18
  %197 = bitcast i16* %196 to i32*
  %198 = load i32, i32* %197, align 4
  %199 = trunc i32 %198 to i16
  %200 = add i16 %195, %199
  %201 = getelementptr inbounds i16, i16* %188, i64 1
  store i16 %200, i16* %201, align 2
  %202 = getelementptr inbounds i16, i16* %132, i64 20
  %203 = bitcast i16* %202 to i32*
  %204 = load i32, i32* %203, align 4
  %205 = trunc i32 %204 to i16
  %206 = add i16 %200, %205
  %207 = getelementptr inbounds i16, i16* %188, i64 2
  store i16 %206, i16* %207, align 2
  %208 = getelementptr inbounds i16, i16* %132, i64 22
  %209 = bitcast i16* %208 to i32*
  %210 = load i32, i32* %209, align 4
  %211 = trunc i32 %210 to i16
  %212 = add i16 %206, %211
  %213 = getelementptr inbounds i16, i16* %188, i64 3
  store i16 %212, i16* %213, align 2
  %214 = getelementptr inbounds i16, i16* %188, i64 %5
  %215 = getelementptr inbounds i16, i16* %132, i64 24
  %216 = bitcast i16* %215 to i32*
  %217 = getelementptr inbounds i16, i16* %214, i64 -1
  %218 = load i16, i16* %217, align 2
  %219 = load i32, i32* %216, align 4
  %220 = trunc i32 %219 to i16
  %221 = add i16 %218, %220
  store i16 %221, i16* %214, align 2
  %222 = getelementptr inbounds i16, i16* %132, i64 26
  %223 = bitcast i16* %222 to i32*
  %224 = load i32, i32* %223, align 4
  %225 = trunc i32 %224 to i16
  %226 = add i16 %221, %225
  %227 = getelementptr inbounds i16, i16* %214, i64 1
  store i16 %226, i16* %227, align 2
  %228 = getelementptr inbounds i16, i16* %132, i64 28
  %229 = bitcast i16* %228 to i32*
  %230 = load i32, i32* %229, align 4
  %231 = trunc i32 %230 to i16
  %232 = add i16 %226, %231
  %233 = getelementptr inbounds i16, i16* %214, i64 2
  store i16 %232, i16* %233, align 2
  %234 = getelementptr inbounds i16, i16* %132, i64 30
  %235 = bitcast i16* %234 to i32*
  %236 = load i32, i32* %235, align 4
  %237 = trunc i32 %236 to i16
  %238 = add i16 %232, %237
  %239 = getelementptr inbounds i16, i16* %214, i64 3
  store i16 %238, i16* %239, align 2
  %240 = bitcast i16* %132 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %240, i8 0, i64 64, i1 false) #8
  %241 = add nuw nsw i64 %125, 1
  %242 = icmp eq i64 %241, 8
  br i1 %242, label %243, label %124

243:                                              ; preds = %124
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred16x16_vertical_add_10_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  %6 = sub nsw i64 0, %5
  %7 = and i64 %3, -2
  %8 = mul nsw i64 %5, 3
  %9 = shl nsw i64 %5, 2
  br label %10

10:                                               ; preds = %10, %4
  %11 = phi i64 [ 0, %4 ], [ %122, %10 ]
  %12 = getelementptr inbounds i32, i32* %1, i64 %11
  %13 = load i32, i32* %12, align 4
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = shl i64 %11, 5
  %17 = getelementptr inbounds i16, i16* %2, i64 %16
  %18 = bitcast i8* %15 to i16*
  %19 = bitcast i16* %17 to i32*
  %20 = getelementptr inbounds i16, i16* %18, i64 %6
  %21 = load i16, i16* %20, align 2
  %22 = load i32, i32* %19, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %21, %23
  store i16 %24, i16* %18, align 2
  %25 = getelementptr inbounds i16, i16* %17, i64 8
  %26 = bitcast i16* %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %20, i64 %7
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i16, i16* %17, i64 16
  %32 = bitcast i16* %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = trunc i32 %33 to i16
  %35 = add i16 %29, %34
  %36 = getelementptr inbounds i16, i16* %20, i64 %8
  store i16 %35, i16* %36, align 2
  %37 = getelementptr inbounds i16, i16* %17, i64 24
  %38 = bitcast i16* %37 to i32*
  %39 = load i32, i32* %38, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %35, %40
  %42 = getelementptr inbounds i16, i16* %20, i64 %9
  store i16 %41, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %20, i64 1
  %44 = getelementptr inbounds i16, i16* %17, i64 2
  %45 = bitcast i16* %44 to i32*
  %46 = load i16, i16* %43, align 2
  %47 = load i32, i32* %45, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %46, %48
  %50 = getelementptr inbounds i16, i16* %43, i64 %5
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %17, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %49, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 %7
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %17, i64 18
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 %8
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %17, i64 26
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 %9
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 1
  %70 = getelementptr inbounds i16, i16* %17, i64 4
  %71 = bitcast i16* %70 to i32*
  %72 = load i16, i16* %69, align 2
  %73 = load i32, i32* %71, align 4
  %74 = trunc i32 %73 to i16
  %75 = add i16 %72, %74
  %76 = getelementptr inbounds i16, i16* %69, i64 %5
  store i16 %75, i16* %76, align 2
  %77 = getelementptr inbounds i16, i16* %17, i64 12
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %75, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 %7
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %17, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 %8
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %17, i64 28
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 %9
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 1
  %96 = getelementptr inbounds i16, i16* %17, i64 6
  %97 = bitcast i16* %96 to i32*
  %98 = load i16, i16* %95, align 2
  %99 = load i32, i32* %97, align 4
  %100 = trunc i32 %99 to i16
  %101 = add i16 %98, %100
  %102 = getelementptr inbounds i16, i16* %95, i64 %5
  store i16 %101, i16* %102, align 2
  %103 = getelementptr inbounds i16, i16* %17, i64 14
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %101, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 %7
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %17, i64 22
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 %8
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %17, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 %9
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %11, 1
  %123 = icmp eq i64 %122, 16
  br i1 %123, label %124, label %10

124:                                              ; preds = %10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred16x16_horizontal_add_10_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %122, %6 ]
  %8 = getelementptr inbounds i32, i32* %1, i64 %7
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = shl i64 %7, 5
  %13 = getelementptr inbounds i16, i16* %2, i64 %12
  %14 = bitcast i8* %11 to i16*
  %15 = bitcast i16* %13 to i32*
  %16 = getelementptr inbounds i8, i8* %11, i64 -2
  %17 = bitcast i8* %16 to i16*
  %18 = load i16, i16* %17, align 2
  %19 = load i32, i32* %15, align 4
  %20 = trunc i32 %19 to i16
  %21 = add i16 %18, %20
  store i16 %21, i16* %14, align 2
  %22 = getelementptr inbounds i16, i16* %13, i64 2
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %21, %25
  %27 = getelementptr inbounds i8, i8* %11, i64 2
  %28 = bitcast i8* %27 to i16*
  store i16 %26, i16* %28, align 2
  %29 = getelementptr inbounds i16, i16* %13, i64 4
  %30 = bitcast i16* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %26, %32
  %34 = getelementptr inbounds i8, i8* %11, i64 4
  %35 = bitcast i8* %34 to i16*
  store i16 %33, i16* %35, align 2
  %36 = getelementptr inbounds i16, i16* %13, i64 6
  %37 = bitcast i16* %36 to i32*
  %38 = load i32, i32* %37, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %33, %39
  %41 = getelementptr inbounds i8, i8* %11, i64 6
  %42 = bitcast i8* %41 to i16*
  store i16 %40, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %14, i64 %5
  %44 = getelementptr inbounds i16, i16* %13, i64 8
  %45 = bitcast i16* %44 to i32*
  %46 = getelementptr inbounds i16, i16* %43, i64 -1
  %47 = load i16, i16* %46, align 2
  %48 = load i32, i32* %45, align 4
  %49 = trunc i32 %48 to i16
  %50 = add i16 %47, %49
  store i16 %50, i16* %43, align 2
  %51 = getelementptr inbounds i16, i16* %13, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %50, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 1
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %13, i64 12
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 2
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %13, i64 14
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 3
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 %5
  %70 = getelementptr inbounds i16, i16* %13, i64 16
  %71 = bitcast i16* %70 to i32*
  %72 = getelementptr inbounds i16, i16* %69, i64 -1
  %73 = load i16, i16* %72, align 2
  %74 = load i32, i32* %71, align 4
  %75 = trunc i32 %74 to i16
  %76 = add i16 %73, %75
  store i16 %76, i16* %69, align 2
  %77 = getelementptr inbounds i16, i16* %13, i64 18
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %76, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 1
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %13, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 2
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %13, i64 22
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 3
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 %5
  %96 = getelementptr inbounds i16, i16* %13, i64 24
  %97 = bitcast i16* %96 to i32*
  %98 = getelementptr inbounds i16, i16* %95, i64 -1
  %99 = load i16, i16* %98, align 2
  %100 = load i32, i32* %97, align 4
  %101 = trunc i32 %100 to i16
  %102 = add i16 %99, %101
  store i16 %102, i16* %95, align 2
  %103 = getelementptr inbounds i16, i16* %13, i64 26
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %102, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 1
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %13, i64 28
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 2
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %13, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 3
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %7, 1
  %123 = icmp eq i64 %122, 16
  br i1 %123, label %124, label %6

124:                                              ; preds = %6
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_12_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = shl i64 %5, 32
  %7 = ashr exact i64 %6, 32
  %8 = sub nsw i64 0, %7
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  %11 = load i64, i64* %10, align 8
  %12 = bitcast i8* %0 to i64*
  store i64 %11, i64* %12, align 8
  %13 = getelementptr inbounds i16, i16* %4, i64 %7
  %14 = bitcast i16* %13 to i64*
  store i64 %11, i64* %14, align 8
  %15 = shl i64 %2, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 %11, i64* %19, align 8
  %20 = mul i64 %5, 12884901888
  %21 = ashr exact i64 %20, 32
  %22 = getelementptr inbounds i16, i16* %4, i64 %21
  %23 = bitcast i16* %22 to i64*
  store i64 %11, i64* %23, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_12_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = mul nuw i64 %10, 281479271743489
  %12 = bitcast i8* %0 to i64*
  store i64 %11, i64* %12, align 8
  %13 = shl i64 %5, 32
  %14 = add i64 %13, -4294967296
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i16, i16* %4, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i64
  %19 = mul nuw i64 %18, 281479271743489
  %20 = ashr exact i64 %13, 32
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = bitcast i16* %21 to i64*
  store i64 %19, i64* %22, align 8
  %23 = trunc i64 %2 to i32
  %24 = and i32 %23, -2
  %25 = add nsw i32 %24, -1
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds i16, i16* %4, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i64
  %30 = mul nuw i64 %29, 281479271743489
  %31 = sext i32 %24 to i64
  %32 = getelementptr inbounds i16, i16* %4, i64 %31
  %33 = bitcast i16* %32 to i64*
  store i64 %30, i64* %33, align 8
  %34 = mul nsw i32 %6, 3
  %35 = add nsw i32 %34, -1
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds i16, i16* %4, i64 %36
  %38 = load i16, i16* %37, align 2
  %39 = zext i16 %38 to i64
  %40 = mul nuw i64 %39, 281479271743489
  %41 = sext i32 %34 to i64
  %42 = getelementptr inbounds i16, i16* %4, i64 %41
  %43 = bitcast i16* %42 to i64*
  store i64 %40, i64* %43, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_dc_12_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = sub i64 0, %7
  %9 = ashr exact i64 %8, 32
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 4294967296, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 8589934592, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 12884901888, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = getelementptr inbounds i8, i8* %0, i64 -2
  %29 = bitcast i8* %28 to i16*
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i32
  %32 = add i64 %7, -4294967296
  %33 = ashr exact i64 %32, 32
  %34 = getelementptr inbounds i16, i16* %4, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = trunc i64 %2 to i32
  %38 = and i32 %37, -2
  %39 = add nsw i32 %38, -1
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds i16, i16* %4, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = mul nsw i32 %6, 3
  %45 = add nsw i32 %44, -1
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds i16, i16* %4, i64 %46
  %48 = load i16, i16* %47, align 2
  %49 = zext i16 %48 to i32
  %50 = add nuw nsw i32 %12, 4
  %51 = add nuw nsw i32 %50, %17
  %52 = add nuw nsw i32 %51, %22
  %53 = add nuw nsw i32 %52, %27
  %54 = add nuw nsw i32 %53, %31
  %55 = add nuw nsw i32 %54, %36
  %56 = add nuw nsw i32 %55, %43
  %57 = add nuw nsw i32 %56, %49
  %58 = ashr i32 %57, 3
  %59 = sext i32 %58 to i64
  %60 = mul i64 %59, 281479271743489
  %61 = bitcast i8* %0 to i64*
  store i64 %60, i64* %61, align 8
  %62 = ashr exact i64 %7, 32
  %63 = getelementptr inbounds i16, i16* %4, i64 %62
  %64 = bitcast i16* %63 to i64*
  store i64 %60, i64* %64, align 8
  %65 = sext i32 %38 to i64
  %66 = getelementptr inbounds i16, i16* %4, i64 %65
  %67 = bitcast i16* %66 to i64*
  store i64 %60, i64* %67, align 8
  %68 = sext i32 %44 to i64
  %69 = getelementptr inbounds i16, i16* %4, i64 %68
  %70 = bitcast i16* %69 to i64*
  store i64 %60, i64* %70, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_down_left_12_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i8* %1 to i16*
  %6 = lshr i64 %2, 1
  %7 = trunc i64 %6 to i32
  %8 = shl i64 %6, 32
  %9 = sub i64 0, %8
  %10 = ashr exact i64 %9, 32
  %11 = getelementptr inbounds i16, i16* %4, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i32
  %14 = sub i64 4294967296, %8
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i16, i16* %4, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i32
  %19 = sub i64 8589934592, %8
  %20 = ashr exact i64 %19, 32
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = sub i64 12884901888, %8
  %25 = ashr exact i64 %24, 32
  %26 = getelementptr inbounds i16, i16* %4, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %5, align 2
  %30 = zext i16 %29 to i32
  %31 = getelementptr inbounds i8, i8* %1, i64 2
  %32 = bitcast i8* %31 to i16*
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = getelementptr inbounds i8, i8* %1, i64 4
  %36 = bitcast i8* %35 to i16*
  %37 = load i16, i16* %36, align 2
  %38 = zext i16 %37 to i32
  %39 = getelementptr inbounds i8, i8* %1, i64 6
  %40 = bitcast i8* %39 to i16*
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i32
  %43 = shl nuw nsw i32 %18, 1
  %44 = add nuw nsw i32 %23, 2
  %45 = add nuw nsw i32 %44, %13
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = trunc i32 %47 to i16
  store i16 %48, i16* %4, align 2
  %49 = shl nuw nsw i32 %23, 1
  %50 = add nuw nsw i32 %28, 2
  %51 = add nuw nsw i32 %50, %18
  %52 = add nuw nsw i32 %51, %49
  %53 = lshr i32 %52, 2
  %54 = trunc i32 %53 to i16
  %55 = ashr exact i64 %8, 32
  %56 = getelementptr inbounds i16, i16* %4, i64 %55
  store i16 %54, i16* %56, align 2
  %57 = getelementptr inbounds i8, i8* %0, i64 2
  %58 = bitcast i8* %57 to i16*
  store i16 %54, i16* %58, align 2
  %59 = shl nuw nsw i32 %28, 1
  %60 = add nuw nsw i32 %44, %30
  %61 = add nuw nsw i32 %60, %59
  %62 = lshr i32 %61, 2
  %63 = trunc i32 %62 to i16
  %64 = trunc i64 %2 to i32
  %65 = and i32 %64, -2
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds i16, i16* %4, i64 %66
  store i16 %63, i16* %67, align 2
  %68 = add i64 %8, 4294967296
  %69 = ashr exact i64 %68, 32
  %70 = getelementptr inbounds i16, i16* %4, i64 %69
  store i16 %63, i16* %70, align 2
  %71 = getelementptr inbounds i8, i8* %0, i64 4
  %72 = bitcast i8* %71 to i16*
  store i16 %63, i16* %72, align 2
  %73 = shl nuw nsw i32 %30, 1
  %74 = add nuw nsw i32 %50, %34
  %75 = add nuw nsw i32 %74, %73
  %76 = lshr i32 %75, 2
  %77 = trunc i32 %76 to i16
  %78 = mul nsw i32 %7, 3
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i16, i16* %4, i64 %79
  store i16 %77, i16* %80, align 2
  %81 = shl i64 %2, 32
  %82 = ashr exact i64 %81, 32
  %83 = or i64 %82, 1
  %84 = getelementptr inbounds i16, i16* %4, i64 %83
  store i16 %77, i16* %84, align 2
  %85 = add i64 %8, 8589934592
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i16, i16* %4, i64 %86
  store i16 %77, i16* %87, align 2
  %88 = getelementptr inbounds i8, i8* %0, i64 6
  %89 = bitcast i8* %88 to i16*
  store i16 %77, i16* %89, align 2
  %90 = shl nuw nsw i32 %34, 1
  %91 = add nuw nsw i32 %30, 2
  %92 = add nuw nsw i32 %91, %38
  %93 = add nuw nsw i32 %92, %90
  %94 = lshr i32 %93, 2
  %95 = trunc i32 %94 to i16
  %96 = add nsw i32 %78, 1
  %97 = sext i32 %96 to i64
  %98 = getelementptr inbounds i16, i16* %4, i64 %97
  store i16 %95, i16* %98, align 2
  %99 = add nsw i32 %65, 2
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds i16, i16* %4, i64 %100
  store i16 %95, i16* %101, align 2
  %102 = add i64 %8, 12884901888
  %103 = ashr exact i64 %102, 32
  %104 = getelementptr inbounds i16, i16* %4, i64 %103
  store i16 %95, i16* %104, align 2
  %105 = shl nuw nsw i32 %38, 1
  %106 = add nuw nsw i32 %34, 2
  %107 = add nuw nsw i32 %106, %42
  %108 = add nuw nsw i32 %107, %105
  %109 = lshr i32 %108, 2
  %110 = trunc i32 %109 to i16
  %111 = add nsw i32 %78, 2
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds i16, i16* %4, i64 %112
  store i16 %110, i16* %113, align 2
  %114 = add nsw i32 %65, 3
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds i16, i16* %4, i64 %115
  store i16 %110, i16* %116, align 2
  %117 = mul nuw nsw i32 %42, 3
  %118 = add nuw nsw i32 %38, 2
  %119 = add nuw nsw i32 %118, %117
  %120 = lshr i32 %119, 2
  %121 = trunc i32 %120 to i16
  %122 = add nsw i32 %78, 3
  %123 = sext i32 %122 to i64
  %124 = getelementptr inbounds i16, i16* %4, i64 %123
  store i16 %121, i16* %124, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_down_right_12_c(i8*, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = xor i64 %8, -1
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 0, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 4294967296, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 8589934592, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = sub i64 12884901888, %7
  %29 = ashr exact i64 %28, 32
  %30 = getelementptr inbounds i16, i16* %4, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i32
  %33 = getelementptr inbounds i8, i8* %0, i64 -2
  %34 = bitcast i8* %33 to i16*
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = add i64 %7, -4294967296
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i16, i16* %4, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i32
  %42 = trunc i64 %2 to i32
  %43 = and i32 %42, -2
  %44 = add nsw i32 %43, -1
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i16, i16* %4, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i32
  %49 = mul nsw i32 %6, 3
  %50 = add nsw i32 %49, -1
  %51 = sext i32 %50 to i64
  %52 = getelementptr inbounds i16, i16* %4, i64 %51
  %53 = load i16, i16* %52, align 2
  %54 = zext i16 %53 to i32
  %55 = shl nuw nsw i32 %48, 1
  %56 = add nuw nsw i32 %41, 2
  %57 = add nuw nsw i32 %56, %54
  %58 = add nuw nsw i32 %57, %55
  %59 = lshr i32 %58, 2
  %60 = trunc i32 %59 to i16
  %61 = sext i32 %49 to i64
  %62 = getelementptr inbounds i16, i16* %4, i64 %61
  store i16 %60, i16* %62, align 2
  %63 = shl nuw nsw i32 %41, 1
  %64 = add nuw nsw i32 %36, 2
  %65 = add nuw nsw i32 %64, %48
  %66 = add nuw nsw i32 %65, %63
  %67 = lshr i32 %66, 2
  %68 = trunc i32 %67 to i16
  %69 = add nsw i32 %49, 1
  %70 = sext i32 %69 to i64
  %71 = getelementptr inbounds i16, i16* %4, i64 %70
  store i16 %68, i16* %71, align 2
  %72 = sext i32 %43 to i64
  %73 = getelementptr inbounds i16, i16* %4, i64 %72
  store i16 %68, i16* %73, align 2
  %74 = shl nuw nsw i32 %36, 1
  %75 = add nuw nsw i32 %12, 2
  %76 = add nuw nsw i32 %75, %41
  %77 = add nuw nsw i32 %76, %74
  %78 = lshr i32 %77, 2
  %79 = trunc i32 %78 to i16
  %80 = add nsw i32 %49, 2
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds i16, i16* %4, i64 %81
  store i16 %79, i16* %82, align 2
  %83 = shl i64 %2, 32
  %84 = ashr exact i64 %83, 32
  %85 = or i64 %84, 1
  %86 = getelementptr inbounds i16, i16* %4, i64 %85
  store i16 %79, i16* %86, align 2
  %87 = getelementptr inbounds i16, i16* %4, i64 %8
  store i16 %79, i16* %87, align 2
  %88 = shl nuw nsw i32 %12, 1
  %89 = add nuw nsw i32 %17, 2
  %90 = add nuw nsw i32 %89, %88
  %91 = add nuw nsw i32 %90, %36
  %92 = lshr i32 %91, 2
  %93 = trunc i32 %92 to i16
  %94 = add nsw i32 %49, 3
  %95 = sext i32 %94 to i64
  %96 = getelementptr inbounds i16, i16* %4, i64 %95
  store i16 %93, i16* %96, align 2
  %97 = add nsw i32 %43, 2
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds i16, i16* %4, i64 %98
  store i16 %93, i16* %99, align 2
  %100 = add i64 %7, 4294967296
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %4, i64 %101
  store i16 %93, i16* %102, align 2
  store i16 %93, i16* %4, align 2
  %103 = shl nuw nsw i32 %17, 1
  %104 = add nuw nsw i32 %75, %103
  %105 = add nuw nsw i32 %104, %22
  %106 = lshr i32 %105, 2
  %107 = trunc i32 %106 to i16
  %108 = add nsw i32 %43, 3
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds i16, i16* %4, i64 %109
  store i16 %107, i16* %110, align 2
  %111 = add i64 %7, 8589934592
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds i16, i16* %4, i64 %112
  store i16 %107, i16* %113, align 2
  %114 = getelementptr inbounds i8, i8* %0, i64 2
  %115 = bitcast i8* %114 to i16*
  store i16 %107, i16* %115, align 2
  %116 = shl nuw nsw i32 %22, 1
  %117 = add nuw nsw i32 %89, %116
  %118 = add nuw nsw i32 %117, %27
  %119 = lshr i32 %118, 2
  %120 = trunc i32 %119 to i16
  %121 = add i64 %7, 12884901888
  %122 = ashr exact i64 %121, 32
  %123 = getelementptr inbounds i16, i16* %4, i64 %122
  store i16 %120, i16* %123, align 2
  %124 = getelementptr inbounds i8, i8* %0, i64 4
  %125 = bitcast i8* %124 to i16*
  store i16 %120, i16* %125, align 2
  %126 = shl nuw nsw i32 %27, 1
  %127 = add nuw nsw i32 %22, 2
  %128 = add nuw nsw i32 %127, %126
  %129 = add nuw nsw i32 %128, %32
  %130 = lshr i32 %129, 2
  %131 = trunc i32 %130 to i16
  %132 = getelementptr inbounds i8, i8* %0, i64 6
  %133 = bitcast i8* %132 to i16*
  store i16 %131, i16* %133, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_right_12_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = xor i64 %8, -1
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 0, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 4294967296, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 8589934592, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = sub i64 12884901888, %7
  %29 = ashr exact i64 %28, 32
  %30 = getelementptr inbounds i16, i16* %4, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i32
  %33 = getelementptr inbounds i8, i8* %0, i64 -2
  %34 = bitcast i8* %33 to i16*
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = add i64 %7, -4294967296
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i16, i16* %4, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i32
  %42 = trunc i64 %2 to i32
  %43 = and i32 %42, -2
  %44 = add nsw i32 %43, -1
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i16, i16* %4, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i32
  %49 = mul nsw i32 %6, 3
  %50 = add nuw nsw i32 %17, 1
  %51 = add nuw nsw i32 %50, %12
  %52 = lshr i32 %51, 1
  %53 = trunc i32 %52 to i16
  %54 = shl i64 %2, 32
  %55 = ashr exact i64 %54, 32
  %56 = or i64 %55, 1
  %57 = getelementptr inbounds i16, i16* %4, i64 %56
  store i16 %53, i16* %57, align 2
  store i16 %53, i16* %4, align 2
  %58 = add nuw nsw i32 %50, %22
  %59 = lshr i32 %58, 1
  %60 = trunc i32 %59 to i16
  %61 = add nsw i32 %43, 2
  %62 = sext i32 %61 to i64
  %63 = getelementptr inbounds i16, i16* %4, i64 %62
  store i16 %60, i16* %63, align 2
  %64 = getelementptr inbounds i8, i8* %0, i64 2
  %65 = bitcast i8* %64 to i16*
  store i16 %60, i16* %65, align 2
  %66 = add nuw nsw i32 %22, 1
  %67 = add nuw nsw i32 %66, %27
  %68 = lshr i32 %67, 1
  %69 = trunc i32 %68 to i16
  %70 = add nsw i32 %43, 3
  %71 = sext i32 %70 to i64
  %72 = getelementptr inbounds i16, i16* %4, i64 %71
  store i16 %69, i16* %72, align 2
  %73 = getelementptr inbounds i8, i8* %0, i64 4
  %74 = bitcast i8* %73 to i16*
  store i16 %69, i16* %74, align 2
  %75 = add nuw nsw i32 %27, 1
  %76 = add nuw nsw i32 %75, %32
  %77 = lshr i32 %76, 1
  %78 = trunc i32 %77 to i16
  %79 = getelementptr inbounds i8, i8* %0, i64 6
  %80 = bitcast i8* %79 to i16*
  store i16 %78, i16* %80, align 2
  %81 = shl nuw nsw i32 %12, 1
  %82 = add nuw nsw i32 %17, 2
  %83 = add nuw nsw i32 %82, %81
  %84 = add nuw nsw i32 %83, %36
  %85 = lshr i32 %84, 2
  %86 = trunc i32 %85 to i16
  %87 = add nsw i32 %49, 1
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds i16, i16* %4, i64 %88
  store i16 %86, i16* %89, align 2
  %90 = getelementptr inbounds i16, i16* %4, i64 %8
  store i16 %86, i16* %90, align 2
  %91 = shl nuw nsw i32 %17, 1
  %92 = add nuw nsw i32 %12, 2
  %93 = add nuw nsw i32 %92, %91
  %94 = add nuw nsw i32 %93, %22
  %95 = lshr i32 %94, 2
  %96 = trunc i32 %95 to i16
  %97 = add nsw i32 %49, 2
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds i16, i16* %4, i64 %98
  store i16 %96, i16* %99, align 2
  %100 = add i64 %7, 4294967296
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %4, i64 %101
  store i16 %96, i16* %102, align 2
  %103 = shl nuw nsw i32 %22, 1
  %104 = add nuw nsw i32 %82, %103
  %105 = add nuw nsw i32 %104, %27
  %106 = lshr i32 %105, 2
  %107 = trunc i32 %106 to i16
  %108 = add nsw i32 %49, 3
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds i16, i16* %4, i64 %109
  store i16 %107, i16* %110, align 2
  %111 = add i64 %7, 8589934592
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds i16, i16* %4, i64 %112
  store i16 %107, i16* %113, align 2
  %114 = shl nuw nsw i32 %27, 1
  %115 = add nuw nsw i32 %22, 2
  %116 = add nuw nsw i32 %115, %114
  %117 = add nuw nsw i32 %116, %32
  %118 = lshr i32 %117, 2
  %119 = trunc i32 %118 to i16
  %120 = add i64 %7, 12884901888
  %121 = ashr exact i64 %120, 32
  %122 = getelementptr inbounds i16, i16* %4, i64 %121
  store i16 %119, i16* %122, align 2
  %123 = shl nuw nsw i32 %36, 1
  %124 = add nuw nsw i32 %92, %123
  %125 = add nuw nsw i32 %124, %41
  %126 = lshr i32 %125, 2
  %127 = trunc i32 %126 to i16
  %128 = sext i32 %43 to i64
  %129 = getelementptr inbounds i16, i16* %4, i64 %128
  store i16 %127, i16* %129, align 2
  %130 = shl nuw nsw i32 %41, 1
  %131 = add nuw nsw i32 %36, 2
  %132 = add nuw nsw i32 %131, %130
  %133 = add nuw nsw i32 %132, %48
  %134 = lshr i32 %133, 2
  %135 = trunc i32 %134 to i16
  %136 = sext i32 %49 to i64
  %137 = getelementptr inbounds i16, i16* %4, i64 %136
  store i16 %135, i16* %137, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_down_12_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = xor i64 %8, -1
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 0, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 4294967296, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 8589934592, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = getelementptr inbounds i8, i8* %0, i64 -2
  %29 = bitcast i8* %28 to i16*
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i32
  %32 = add i64 %7, -4294967296
  %33 = ashr exact i64 %32, 32
  %34 = getelementptr inbounds i16, i16* %4, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = trunc i64 %2 to i32
  %38 = and i32 %37, -2
  %39 = add nsw i32 %38, -1
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds i16, i16* %4, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = mul nsw i32 %6, 3
  %45 = add nsw i32 %44, -1
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds i16, i16* %4, i64 %46
  %48 = load i16, i16* %47, align 2
  %49 = zext i16 %48 to i32
  %50 = add nuw nsw i32 %31, 1
  %51 = add nuw nsw i32 %50, %12
  %52 = lshr i32 %51, 1
  %53 = trunc i32 %52 to i16
  %54 = add i64 %7, 8589934592
  %55 = ashr exact i64 %54, 32
  %56 = getelementptr inbounds i16, i16* %4, i64 %55
  store i16 %53, i16* %56, align 2
  store i16 %53, i16* %4, align 2
  %57 = shl nuw nsw i32 %12, 1
  %58 = add nuw nsw i32 %17, 2
  %59 = add nuw nsw i32 %58, %57
  %60 = add nuw nsw i32 %59, %31
  %61 = lshr i32 %60, 2
  %62 = trunc i32 %61 to i16
  %63 = add i64 %7, 12884901888
  %64 = ashr exact i64 %63, 32
  %65 = getelementptr inbounds i16, i16* %4, i64 %64
  store i16 %62, i16* %65, align 2
  %66 = getelementptr inbounds i8, i8* %0, i64 2
  %67 = bitcast i8* %66 to i16*
  store i16 %62, i16* %67, align 2
  %68 = shl nuw nsw i32 %17, 1
  %69 = add nuw nsw i32 %12, 2
  %70 = add nuw nsw i32 %69, %68
  %71 = add nuw nsw i32 %70, %22
  %72 = lshr i32 %71, 2
  %73 = trunc i32 %72 to i16
  %74 = getelementptr inbounds i8, i8* %0, i64 4
  %75 = bitcast i8* %74 to i16*
  store i16 %73, i16* %75, align 2
  %76 = shl nuw nsw i32 %22, 1
  %77 = add nuw nsw i32 %58, %76
  %78 = add nuw nsw i32 %77, %27
  %79 = lshr i32 %78, 2
  %80 = trunc i32 %79 to i16
  %81 = getelementptr inbounds i8, i8* %0, i64 6
  %82 = bitcast i8* %81 to i16*
  store i16 %80, i16* %82, align 2
  %83 = add nuw nsw i32 %50, %36
  %84 = lshr i32 %83, 1
  %85 = trunc i32 %84 to i16
  %86 = add nsw i32 %38, 2
  %87 = sext i32 %86 to i64
  %88 = getelementptr inbounds i16, i16* %4, i64 %87
  store i16 %85, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %4, i64 %8
  store i16 %85, i16* %89, align 2
  %90 = shl nuw nsw i32 %31, 1
  %91 = add nuw nsw i32 %69, %90
  %92 = add nuw nsw i32 %91, %36
  %93 = lshr i32 %92, 2
  %94 = trunc i32 %93 to i16
  %95 = add nsw i32 %38, 3
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %4, i64 %96
  store i16 %94, i16* %97, align 2
  %98 = add i64 %7, 4294967296
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i16, i16* %4, i64 %99
  store i16 %94, i16* %100, align 2
  %101 = add nuw nsw i32 %36, 1
  %102 = add nuw nsw i32 %101, %43
  %103 = lshr i32 %102, 1
  %104 = trunc i32 %103 to i16
  %105 = add nsw i32 %44, 2
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i16, i16* %4, i64 %106
  store i16 %104, i16* %107, align 2
  %108 = sext i32 %38 to i64
  %109 = getelementptr inbounds i16, i16* %4, i64 %108
  store i16 %104, i16* %109, align 2
  %110 = shl nuw nsw i32 %36, 1
  %111 = add nuw nsw i32 %31, 2
  %112 = add nuw nsw i32 %111, %110
  %113 = add nuw nsw i32 %112, %43
  %114 = lshr i32 %113, 2
  %115 = trunc i32 %114 to i16
  %116 = add nsw i32 %44, 3
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds i16, i16* %4, i64 %117
  store i16 %115, i16* %118, align 2
  %119 = shl i64 %2, 32
  %120 = ashr exact i64 %119, 32
  %121 = or i64 %120, 1
  %122 = getelementptr inbounds i16, i16* %4, i64 %121
  store i16 %115, i16* %122, align 2
  %123 = add nuw nsw i32 %43, 1
  %124 = add nuw nsw i32 %123, %49
  %125 = lshr i32 %124, 1
  %126 = trunc i32 %125 to i16
  %127 = sext i32 %44 to i64
  %128 = getelementptr inbounds i16, i16* %4, i64 %127
  store i16 %126, i16* %128, align 2
  %129 = shl nuw nsw i32 %43, 1
  %130 = add nuw nsw i32 %36, 2
  %131 = add nuw nsw i32 %130, %129
  %132 = add nuw nsw i32 %131, %49
  %133 = lshr i32 %132, 2
  %134 = trunc i32 %133 to i16
  %135 = add nsw i32 %44, 1
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds i16, i16* %4, i64 %136
  store i16 %134, i16* %137, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_left_12_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i8* %1 to i16*
  %6 = lshr i64 %2, 1
  %7 = trunc i64 %6 to i32
  %8 = shl i64 %6, 32
  %9 = sub i64 0, %8
  %10 = ashr exact i64 %9, 32
  %11 = getelementptr inbounds i16, i16* %4, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i32
  %14 = sub i64 4294967296, %8
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i16, i16* %4, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i32
  %19 = sub i64 8589934592, %8
  %20 = ashr exact i64 %19, 32
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = sub i64 12884901888, %8
  %25 = ashr exact i64 %24, 32
  %26 = getelementptr inbounds i16, i16* %4, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %5, align 2
  %30 = zext i16 %29 to i32
  %31 = getelementptr inbounds i8, i8* %1, i64 2
  %32 = bitcast i8* %31 to i16*
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = getelementptr inbounds i8, i8* %1, i64 4
  %36 = bitcast i8* %35 to i16*
  %37 = load i16, i16* %36, align 2
  %38 = zext i16 %37 to i32
  %39 = add nuw nsw i32 %18, 1
  %40 = add nuw nsw i32 %39, %13
  %41 = lshr i32 %40, 1
  %42 = trunc i32 %41 to i16
  store i16 %42, i16* %4, align 2
  %43 = add nuw nsw i32 %39, %23
  %44 = lshr i32 %43, 1
  %45 = trunc i32 %44 to i16
  %46 = trunc i64 %2 to i32
  %47 = and i32 %46, -2
  %48 = sext i32 %47 to i64
  %49 = getelementptr inbounds i16, i16* %4, i64 %48
  store i16 %45, i16* %49, align 2
  %50 = getelementptr inbounds i8, i8* %0, i64 2
  %51 = bitcast i8* %50 to i16*
  store i16 %45, i16* %51, align 2
  %52 = add nuw nsw i32 %23, 1
  %53 = add nuw nsw i32 %52, %28
  %54 = lshr i32 %53, 1
  %55 = trunc i32 %54 to i16
  %56 = shl i64 %2, 32
  %57 = ashr exact i64 %56, 32
  %58 = or i64 %57, 1
  %59 = getelementptr inbounds i16, i16* %4, i64 %58
  store i16 %55, i16* %59, align 2
  %60 = getelementptr inbounds i8, i8* %0, i64 4
  %61 = bitcast i8* %60 to i16*
  store i16 %55, i16* %61, align 2
  %62 = add nuw nsw i32 %28, 1
  %63 = add nuw nsw i32 %62, %30
  %64 = lshr i32 %63, 1
  %65 = trunc i32 %64 to i16
  %66 = add nsw i32 %47, 2
  %67 = sext i32 %66 to i64
  %68 = getelementptr inbounds i16, i16* %4, i64 %67
  store i16 %65, i16* %68, align 2
  %69 = getelementptr inbounds i8, i8* %0, i64 6
  %70 = bitcast i8* %69 to i16*
  store i16 %65, i16* %70, align 2
  %71 = add nuw nsw i32 %30, 1
  %72 = add nuw nsw i32 %71, %34
  %73 = lshr i32 %72, 1
  %74 = trunc i32 %73 to i16
  %75 = add nsw i32 %47, 3
  %76 = sext i32 %75 to i64
  %77 = getelementptr inbounds i16, i16* %4, i64 %76
  store i16 %74, i16* %77, align 2
  %78 = shl nuw nsw i32 %18, 1
  %79 = add nuw nsw i32 %23, 2
  %80 = add nuw nsw i32 %79, %13
  %81 = add nuw nsw i32 %80, %78
  %82 = lshr i32 %81, 2
  %83 = trunc i32 %82 to i16
  %84 = ashr exact i64 %8, 32
  %85 = getelementptr inbounds i16, i16* %4, i64 %84
  store i16 %83, i16* %85, align 2
  %86 = shl nuw nsw i32 %23, 1
  %87 = add nuw nsw i32 %28, 2
  %88 = add nuw nsw i32 %87, %18
  %89 = add nuw nsw i32 %88, %86
  %90 = lshr i32 %89, 2
  %91 = trunc i32 %90 to i16
  %92 = mul nsw i32 %7, 3
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds i16, i16* %4, i64 %93
  store i16 %91, i16* %94, align 2
  %95 = add i64 %8, 4294967296
  %96 = ashr exact i64 %95, 32
  %97 = getelementptr inbounds i16, i16* %4, i64 %96
  store i16 %91, i16* %97, align 2
  %98 = shl nuw nsw i32 %28, 1
  %99 = add nuw nsw i32 %79, %98
  %100 = add nuw nsw i32 %99, %30
  %101 = lshr i32 %100, 2
  %102 = trunc i32 %101 to i16
  %103 = add nsw i32 %92, 1
  %104 = sext i32 %103 to i64
  %105 = getelementptr inbounds i16, i16* %4, i64 %104
  store i16 %102, i16* %105, align 2
  %106 = add i64 %8, 8589934592
  %107 = ashr exact i64 %106, 32
  %108 = getelementptr inbounds i16, i16* %4, i64 %107
  store i16 %102, i16* %108, align 2
  %109 = shl nuw nsw i32 %30, 1
  %110 = add nuw nsw i32 %87, %109
  %111 = add nuw nsw i32 %110, %34
  %112 = lshr i32 %111, 2
  %113 = trunc i32 %112 to i16
  %114 = add nsw i32 %92, 2
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds i16, i16* %4, i64 %115
  store i16 %113, i16* %116, align 2
  %117 = add i64 %8, 12884901888
  %118 = ashr exact i64 %117, 32
  %119 = getelementptr inbounds i16, i16* %4, i64 %118
  store i16 %113, i16* %119, align 2
  %120 = shl nuw nsw i32 %34, 1
  %121 = add nuw nsw i32 %30, 2
  %122 = add nuw nsw i32 %121, %120
  %123 = add nuw nsw i32 %122, %38
  %124 = lshr i32 %123, 2
  %125 = trunc i32 %124 to i16
  %126 = add nsw i32 %92, 3
  %127 = sext i32 %126 to i64
  %128 = getelementptr inbounds i16, i16* %4, i64 %127
  store i16 %125, i16* %128, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_up_12_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i32
  %11 = shl i64 %5, 32
  %12 = add i64 %11, -4294967296
  %13 = ashr exact i64 %12, 32
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i32
  %17 = trunc i64 %2 to i32
  %18 = and i32 %17, -2
  %19 = add nsw i32 %18, -1
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = mul nsw i32 %6, 3
  %25 = add nsw i32 %24, -1
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds i16, i16* %4, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i32
  %30 = add nuw nsw i32 %16, 1
  %31 = add nuw nsw i32 %30, %10
  %32 = lshr i32 %31, 1
  %33 = trunc i32 %32 to i16
  store i16 %33, i16* %4, align 2
  %34 = shl nuw nsw i32 %16, 1
  %35 = add nuw nsw i32 %23, 2
  %36 = add nuw nsw i32 %35, %10
  %37 = add nuw nsw i32 %36, %34
  %38 = lshr i32 %37, 2
  %39 = trunc i32 %38 to i16
  %40 = getelementptr inbounds i8, i8* %0, i64 2
  %41 = bitcast i8* %40 to i16*
  store i16 %39, i16* %41, align 2
  %42 = add nuw nsw i32 %30, %23
  %43 = lshr i32 %42, 1
  %44 = trunc i32 %43 to i16
  %45 = ashr exact i64 %11, 32
  %46 = getelementptr inbounds i16, i16* %4, i64 %45
  store i16 %44, i16* %46, align 2
  %47 = getelementptr inbounds i8, i8* %0, i64 4
  %48 = bitcast i8* %47 to i16*
  store i16 %44, i16* %48, align 2
  %49 = shl nuw nsw i32 %23, 1
  %50 = add nuw nsw i32 %29, 2
  %51 = add nuw nsw i32 %50, %16
  %52 = add nuw nsw i32 %51, %49
  %53 = lshr i32 %52, 2
  %54 = trunc i32 %53 to i16
  %55 = add i64 %11, 4294967296
  %56 = ashr exact i64 %55, 32
  %57 = getelementptr inbounds i16, i16* %4, i64 %56
  store i16 %54, i16* %57, align 2
  %58 = getelementptr inbounds i8, i8* %0, i64 6
  %59 = bitcast i8* %58 to i16*
  store i16 %54, i16* %59, align 2
  %60 = add nuw nsw i32 %23, 1
  %61 = add nuw nsw i32 %60, %29
  %62 = lshr i32 %61, 1
  %63 = trunc i32 %62 to i16
  %64 = sext i32 %18 to i64
  %65 = getelementptr inbounds i16, i16* %4, i64 %64
  store i16 %63, i16* %65, align 2
  %66 = add i64 %11, 8589934592
  %67 = ashr exact i64 %66, 32
  %68 = getelementptr inbounds i16, i16* %4, i64 %67
  store i16 %63, i16* %68, align 2
  %69 = shl nuw nsw i32 %29, 1
  %70 = add nuw nsw i32 %35, %29
  %71 = add nuw nsw i32 %70, %69
  %72 = lshr i32 %71, 2
  %73 = trunc i32 %72 to i16
  %74 = shl i64 %2, 32
  %75 = ashr exact i64 %74, 32
  %76 = or i64 %75, 1
  %77 = getelementptr inbounds i16, i16* %4, i64 %76
  store i16 %73, i16* %77, align 2
  %78 = add i64 %11, 12884901888
  %79 = ashr exact i64 %78, 32
  %80 = getelementptr inbounds i16, i16* %4, i64 %79
  store i16 %73, i16* %80, align 2
  %81 = add nsw i32 %24, 3
  %82 = sext i32 %81 to i64
  %83 = getelementptr inbounds i16, i16* %4, i64 %82
  store i16 %28, i16* %83, align 2
  %84 = add nsw i32 %24, 2
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i16, i16* %4, i64 %85
  store i16 %28, i16* %86, align 2
  %87 = add nsw i32 %18, 2
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds i16, i16* %4, i64 %88
  store i16 %28, i16* %89, align 2
  %90 = sext i32 %24 to i64
  %91 = getelementptr inbounds i16, i16* %4, i64 %90
  store i16 %28, i16* %91, align 2
  %92 = add nsw i32 %24, 1
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds i16, i16* %4, i64 %93
  store i16 %28, i16* %94, align 2
  %95 = add nsw i32 %18, 3
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %4, i64 %96
  store i16 %28, i16* %97, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_left_dc_12_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = shl i64 %5, 32
  %12 = add i64 %11, -4294967296
  %13 = ashr exact i64 %12, 32
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = trunc i64 %2 to i32
  %18 = and i32 %17, -2
  %19 = add nsw i32 %18, -1
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i64
  %24 = mul nsw i32 %6, 3
  %25 = add nsw i32 %24, -1
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds i16, i16* %4, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i64
  %30 = add nuw nsw i64 %10, 2
  %31 = add nuw nsw i64 %30, %16
  %32 = add nuw nsw i64 %31, %23
  %33 = add nuw nsw i64 %32, %29
  %34 = lshr i64 %33, 2
  %35 = mul i64 %34, 281479271743489
  %36 = bitcast i8* %0 to i64*
  store i64 %35, i64* %36, align 8
  %37 = ashr exact i64 %11, 32
  %38 = getelementptr inbounds i16, i16* %4, i64 %37
  %39 = bitcast i16* %38 to i64*
  store i64 %35, i64* %39, align 8
  %40 = sext i32 %18 to i64
  %41 = getelementptr inbounds i16, i16* %4, i64 %40
  %42 = bitcast i16* %41 to i64*
  store i64 %35, i64* %42, align 8
  %43 = sext i32 %24 to i64
  %44 = getelementptr inbounds i16, i16* %4, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %35, i64* %45, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_top_dc_12_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = shl i64 %5, 32
  %7 = sub i64 0, %6
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  %12 = sub i64 4294967296, %6
  %13 = ashr exact i64 %12, 32
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = sub i64 8589934592, %6
  %18 = ashr exact i64 %17, 32
  %19 = getelementptr inbounds i16, i16* %4, i64 %18
  %20 = load i16, i16* %19, align 2
  %21 = zext i16 %20 to i64
  %22 = sub i64 12884901888, %6
  %23 = ashr exact i64 %22, 32
  %24 = getelementptr inbounds i16, i16* %4, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = add nuw nsw i64 %11, 2
  %28 = add nuw nsw i64 %27, %16
  %29 = add nuw nsw i64 %28, %21
  %30 = add nuw nsw i64 %29, %26
  %31 = lshr i64 %30, 2
  %32 = mul i64 %31, 281479271743489
  %33 = bitcast i8* %0 to i64*
  store i64 %32, i64* %33, align 8
  %34 = ashr exact i64 %6, 32
  %35 = getelementptr inbounds i16, i16* %4, i64 %34
  %36 = bitcast i16* %35 to i64*
  store i64 %32, i64* %36, align 8
  %37 = shl i64 %2, 32
  %38 = ashr exact i64 %37, 32
  %39 = and i64 %38, -2
  %40 = getelementptr inbounds i16, i16* %4, i64 %39
  %41 = bitcast i16* %40 to i64*
  store i64 %32, i64* %41, align 8
  %42 = mul i64 %5, 12884901888
  %43 = ashr exact i64 %42, 32
  %44 = getelementptr inbounds i16, i16* %4, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %32, i64* %45, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_127_dc_12_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = bitcast i8* %0 to i64*
  store i64 576188069258921983, i64* %6, align 8
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  store i64 576188069258921983, i64* %10, align 8
  %11 = shl i64 %2, 32
  %12 = ashr exact i64 %11, 32
  %13 = and i64 %12, -2
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = bitcast i16* %14 to i64*
  store i64 576188069258921983, i64* %15, align 8
  %16 = mul i64 %5, 12884901888
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 576188069258921983, i64* %19, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_129_dc_12_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = bitcast i8* %0 to i64*
  store i64 576751027802408961, i64* %6, align 8
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  store i64 576751027802408961, i64* %10, align 8
  %11 = shl i64 %2, 32
  %12 = ashr exact i64 %11, 32
  %13 = and i64 %12, -2
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = bitcast i16* %14 to i64*
  store i64 576751027802408961, i64* %15, align 8
  %16 = mul i64 %5, 12884901888
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 576751027802408961, i64* %19, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_128_dc_12_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = bitcast i8* %0 to i64*
  store i64 576469548530665472, i64* %6, align 8
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  store i64 576469548530665472, i64* %10, align 8
  %11 = shl i64 %2, 32
  %12 = ashr exact i64 %11, 32
  %13 = and i64 %12, -2
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = bitcast i16* %14 to i64*
  store i64 576469548530665472, i64* %15, align 8
  %16 = mul i64 %5, 12884901888
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 576469548530665472, i64* %19, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_12_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %103, label %97

97:                                               ; preds = %18
  %98 = sub i64 34359738368, %19
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i16, i16* %5, i64 %99
  %101 = load i16, i16* %100, align 2
  %102 = zext i16 %101 to i32
  br label %103

103:                                              ; preds = %18, %97
  %104 = phi i32 [ %102, %97 ], [ %91, %18 ]
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %81, 2
  %107 = add nuw nsw i32 %106, %105
  %108 = add nuw nsw i32 %107, %104
  %109 = lshr i32 %108, 2
  %110 = trunc i32 %37 to i16
  store i16 %110, i16* %5, align 2
  %111 = trunc i32 %47 to i16
  %112 = getelementptr inbounds i8, i8* %0, i64 2
  %113 = bitcast i8* %112 to i16*
  store i16 %111, i16* %113, align 2
  %114 = trunc i32 %56 to i16
  %115 = getelementptr inbounds i8, i8* %0, i64 4
  %116 = bitcast i8* %115 to i16*
  store i16 %114, i16* %116, align 2
  %117 = trunc i32 %65 to i16
  %118 = getelementptr inbounds i8, i8* %0, i64 6
  %119 = bitcast i8* %118 to i16*
  store i16 %117, i16* %119, align 2
  %120 = trunc i32 %75 to i16
  %121 = getelementptr inbounds i8, i8* %0, i64 8
  %122 = bitcast i8* %121 to i16*
  store i16 %120, i16* %122, align 2
  %123 = trunc i32 %85 to i16
  %124 = getelementptr inbounds i8, i8* %0, i64 10
  %125 = bitcast i8* %124 to i16*
  store i16 %123, i16* %125, align 2
  %126 = trunc i32 %95 to i16
  %127 = getelementptr inbounds i8, i8* %0, i64 12
  %128 = bitcast i8* %127 to i16*
  store i16 %126, i16* %128, align 2
  %129 = trunc i32 %109 to i16
  %130 = getelementptr inbounds i8, i8* %0, i64 14
  %131 = bitcast i8* %130 to i16*
  store i16 %129, i16* %131, align 2
  %132 = bitcast i8* %0 to i64*
  %133 = load i64, i64* %132, align 8
  %134 = bitcast i8* %121 to i64*
  %135 = load i64, i64* %134, align 8
  %136 = shl i64 %6, 32
  %137 = ashr exact i64 %136, 32
  %138 = getelementptr inbounds i16, i16* %5, i64 %137
  %139 = bitcast i16* %138 to i64*
  store i64 %133, i64* %139, align 8
  %140 = getelementptr inbounds i16, i16* %138, i64 4
  %141 = bitcast i16* %140 to i64*
  store i64 %135, i64* %141, align 8
  %142 = ashr exact i64 %136, 31
  %143 = getelementptr inbounds i16, i16* %5, i64 %142
  %144 = bitcast i16* %143 to i64*
  store i64 %133, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %143, i64 4
  %146 = bitcast i16* %145 to i64*
  store i64 %135, i64* %146, align 8
  %147 = mul nsw i64 %137, 3
  %148 = getelementptr inbounds i16, i16* %5, i64 %147
  %149 = bitcast i16* %148 to i64*
  store i64 %133, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %148, i64 4
  %151 = bitcast i16* %150 to i64*
  store i64 %135, i64* %151, align 8
  %152 = ashr exact i64 %136, 30
  %153 = getelementptr inbounds i16, i16* %5, i64 %152
  %154 = bitcast i16* %153 to i64*
  store i64 %133, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %153, i64 4
  %156 = bitcast i16* %155 to i64*
  store i64 %135, i64* %156, align 8
  %157 = mul nsw i64 %137, 5
  %158 = getelementptr inbounds i16, i16* %5, i64 %157
  %159 = bitcast i16* %158 to i64*
  store i64 %133, i64* %159, align 8
  %160 = getelementptr inbounds i16, i16* %158, i64 4
  %161 = bitcast i16* %160 to i64*
  store i64 %135, i64* %161, align 8
  %162 = mul nsw i64 %137, 6
  %163 = getelementptr inbounds i16, i16* %5, i64 %162
  %164 = bitcast i16* %163 to i64*
  store i64 %133, i64* %164, align 8
  %165 = getelementptr inbounds i16, i16* %163, i64 4
  %166 = bitcast i16* %165 to i64*
  store i64 %135, i64* %166, align 8
  %167 = mul nsw i64 %137, 7
  %168 = getelementptr inbounds i16, i16* %5, i64 %167
  %169 = bitcast i16* %168 to i64*
  store i64 %133, i64* %169, align 8
  %170 = getelementptr inbounds i16, i16* %168, i64 4
  %171 = bitcast i16* %170 to i64*
  store i64 %135, i64* %171, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_12_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  br i1 %8, label %14, label %9

9:                                                ; preds = %4
  %10 = shl i64 %6, 32
  %11 = ashr exact i64 %10, 32
  %12 = xor i64 %11, -1
  %13 = getelementptr inbounds i16, i16* %5, i64 %12
  br label %19

14:                                               ; preds = %4
  %15 = getelementptr inbounds i8, i8* %0, i64 -2
  %16 = bitcast i8* %15 to i16*
  %17 = shl i64 %6, 32
  %18 = ashr exact i64 %17, 32
  br label %19

19:                                               ; preds = %14, %9
  %20 = phi i64 [ %18, %14 ], [ %11, %9 ]
  %21 = phi i64 [ %17, %14 ], [ %10, %9 ]
  %22 = phi i16* [ %16, %14 ], [ %13, %9 ]
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i8, i8* %0, i64 -2
  %26 = bitcast i8* %25 to i16*
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = shl nuw nsw i32 %28, 1
  %30 = add i64 %21, -4294967296
  %31 = ashr exact i64 %30, 32
  %32 = getelementptr inbounds i16, i16* %5, i64 %31
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = add nuw nsw i32 %34, 2
  %36 = add nuw nsw i32 %35, %24
  %37 = add nuw nsw i32 %36, %29
  %38 = lshr i32 %37, 2
  %39 = shl nuw nsw i32 %34, 1
  %40 = trunc i64 %3 to i32
  %41 = and i32 %40, -2
  %42 = add nsw i32 %41, -1
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i16, i16* %5, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %28
  %49 = add nuw nsw i32 %48, %39
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = mul nsw i32 %7, 3
  %53 = add nsw i32 %52, -1
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i16, i16* %5, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i32
  %58 = add nuw nsw i32 %35, %51
  %59 = add nuw nsw i32 %58, %57
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %57, 1
  %62 = shl i64 %6, 34
  %63 = add i64 %62, -4294967296
  %64 = ashr exact i64 %63, 32
  %65 = getelementptr inbounds i16, i16* %5, i64 %64
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = add nuw nsw i32 %47, %61
  %69 = add nuw nsw i32 %68, %67
  %70 = lshr i32 %69, 2
  %71 = shl nuw nsw i32 %67, 1
  %72 = mul nsw i32 %7, 5
  %73 = add nsw i32 %72, -1
  %74 = sext i32 %73 to i64
  %75 = getelementptr inbounds i16, i16* %5, i64 %74
  %76 = load i16, i16* %75, align 2
  %77 = zext i16 %76 to i32
  %78 = add nuw nsw i32 %57, 2
  %79 = add nuw nsw i32 %78, %71
  %80 = add nuw nsw i32 %79, %77
  %81 = lshr i32 %80, 2
  %82 = shl nuw nsw i32 %77, 1
  %83 = mul nsw i32 %7, 6
  %84 = add nsw i32 %83, -1
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i16, i16* %5, i64 %85
  %87 = load i16, i16* %86, align 2
  %88 = zext i16 %87 to i32
  %89 = add nuw nsw i32 %67, 2
  %90 = add nuw nsw i32 %89, %82
  %91 = add nuw nsw i32 %90, %88
  %92 = lshr i32 %91, 2
  %93 = shl nuw nsw i32 %88, 1
  %94 = mul nsw i32 %7, 7
  %95 = add nsw i32 %94, -1
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %5, i64 %96
  %98 = load i16, i16* %97, align 2
  %99 = zext i16 %98 to i32
  %100 = add nuw nsw i32 %77, 2
  %101 = add nuw nsw i32 %100, %93
  %102 = add nuw nsw i32 %101, %99
  %103 = lshr i32 %102, 2
  %104 = mul nuw nsw i32 %99, 3
  %105 = add nuw nsw i32 %88, 2
  %106 = add nuw nsw i32 %105, %104
  %107 = lshr i32 %106, 2
  %108 = zext i32 %38 to i64
  %109 = mul i64 %108, 281479271743489
  %110 = bitcast i8* %0 to i64*
  store i64 %109, i64* %110, align 8
  %111 = getelementptr inbounds i8, i8* %0, i64 8
  %112 = bitcast i8* %111 to i64*
  store i64 %109, i64* %112, align 8
  %113 = zext i32 %50 to i64
  %114 = mul i64 %113, 281479271743489
  %115 = getelementptr inbounds i16, i16* %5, i64 %20
  %116 = bitcast i16* %115 to i64*
  store i64 %114, i64* %116, align 8
  %117 = getelementptr inbounds i16, i16* %115, i64 4
  %118 = bitcast i16* %117 to i64*
  store i64 %114, i64* %118, align 8
  %119 = zext i32 %60 to i64
  %120 = mul i64 %119, 281479271743489
  %121 = sext i32 %41 to i64
  %122 = getelementptr inbounds i16, i16* %5, i64 %121
  %123 = bitcast i16* %122 to i64*
  store i64 %120, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %122, i64 4
  %125 = bitcast i16* %124 to i64*
  store i64 %120, i64* %125, align 8
  %126 = zext i32 %70 to i64
  %127 = mul i64 %126, 281479271743489
  %128 = sext i32 %52 to i64
  %129 = getelementptr inbounds i16, i16* %5, i64 %128
  %130 = bitcast i16* %129 to i64*
  store i64 %127, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %129, i64 4
  %132 = bitcast i16* %131 to i64*
  store i64 %127, i64* %132, align 8
  %133 = zext i32 %81 to i64
  %134 = mul i64 %133, 281479271743489
  %135 = ashr exact i64 %62, 32
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  %137 = bitcast i16* %136 to i64*
  store i64 %134, i64* %137, align 8
  %138 = getelementptr inbounds i16, i16* %136, i64 4
  %139 = bitcast i16* %138 to i64*
  store i64 %134, i64* %139, align 8
  %140 = zext i32 %92 to i64
  %141 = mul i64 %140, 281479271743489
  %142 = sext i32 %72 to i64
  %143 = getelementptr inbounds i16, i16* %5, i64 %142
  %144 = bitcast i16* %143 to i64*
  store i64 %141, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %143, i64 4
  %146 = bitcast i16* %145 to i64*
  store i64 %141, i64* %146, align 8
  %147 = zext i32 %103 to i64
  %148 = mul i64 %147, 281479271743489
  %149 = sext i32 %83 to i64
  %150 = getelementptr inbounds i16, i16* %5, i64 %149
  %151 = bitcast i16* %150 to i64*
  store i64 %148, i64* %151, align 8
  %152 = getelementptr inbounds i16, i16* %150, i64 4
  %153 = bitcast i16* %152 to i64*
  store i64 %148, i64* %153, align 8
  %154 = zext i32 %107 to i64
  %155 = mul i64 %154, 281479271743489
  %156 = sext i32 %94 to i64
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  %158 = bitcast i16* %157 to i64*
  store i64 %155, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %157, i64 4
  %160 = bitcast i16* %159 to i64*
  store i64 %155, i64* %160, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_dc_12_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = icmp ne i32 %1, 0
  br i1 %7, label %8, label %13

8:                                                ; preds = %4
  %9 = shl i64 %6, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = getelementptr inbounds i16, i16* %5, i64 %11
  br label %19

13:                                               ; preds = %4
  %14 = getelementptr inbounds i8, i8* %0, i64 -2
  %15 = bitcast i8* %14 to i16*
  %16 = shl i64 %6, 32
  %17 = ashr exact i64 %16, 32
  %18 = xor i64 %17, -1
  br label %19

19:                                               ; preds = %13, %8
  %20 = phi i64 [ %18, %13 ], [ %11, %8 ]
  %21 = phi i64 [ %17, %13 ], [ %10, %8 ]
  %22 = phi i64 [ %16, %13 ], [ %9, %8 ]
  %23 = phi i16* [ %15, %13 ], [ %12, %8 ]
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = getelementptr inbounds i8, i8* %0, i64 -2
  %27 = bitcast i8* %26 to i16*
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i32
  %30 = shl nuw nsw i32 %29, 1
  %31 = add i64 %22, -4294967296
  %32 = ashr exact i64 %31, 32
  %33 = getelementptr inbounds i16, i16* %5, i64 %32
  %34 = load i16, i16* %33, align 2
  %35 = zext i16 %34 to i32
  %36 = add nuw nsw i32 %35, 2
  %37 = add nuw nsw i32 %36, %25
  %38 = add nuw nsw i32 %37, %30
  %39 = lshr i32 %38, 2
  %40 = shl nuw nsw i32 %35, 1
  %41 = shl i64 %3, 32
  %42 = and i64 %41, -8589934592
  %43 = add i64 %42, -4294967296
  %44 = ashr exact i64 %43, 32
  %45 = getelementptr inbounds i16, i16* %5, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i32
  %48 = add nuw nsw i32 %47, 2
  %49 = add nuw nsw i32 %48, %29
  %50 = add nuw nsw i32 %49, %40
  %51 = lshr i32 %50, 2
  %52 = shl nuw nsw i32 %47, 1
  %53 = mul i64 %6, 12884901888
  %54 = add i64 %53, -4294967296
  %55 = ashr exact i64 %54, 32
  %56 = getelementptr inbounds i16, i16* %5, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %36, %52
  %60 = add nuw nsw i32 %59, %58
  %61 = lshr i32 %60, 2
  %62 = shl nuw nsw i32 %58, 1
  %63 = shl i64 %6, 34
  %64 = add i64 %63, -4294967296
  %65 = ashr exact i64 %64, 32
  %66 = getelementptr inbounds i16, i16* %5, i64 %65
  %67 = load i16, i16* %66, align 2
  %68 = zext i16 %67 to i32
  %69 = add nuw nsw i32 %48, %62
  %70 = add nuw nsw i32 %69, %68
  %71 = lshr i32 %70, 2
  %72 = shl nuw nsw i32 %68, 1
  %73 = mul i64 %6, 21474836480
  %74 = add i64 %73, -4294967296
  %75 = ashr exact i64 %74, 32
  %76 = getelementptr inbounds i16, i16* %5, i64 %75
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i32
  %79 = add nuw nsw i32 %58, 2
  %80 = add nuw nsw i32 %79, %72
  %81 = add nuw nsw i32 %80, %78
  %82 = lshr i32 %81, 2
  %83 = shl nuw nsw i32 %78, 1
  %84 = mul i64 %6, 25769803776
  %85 = add i64 %84, -4294967296
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i16, i16* %5, i64 %86
  %88 = load i16, i16* %87, align 2
  %89 = zext i16 %88 to i32
  %90 = add nuw nsw i32 %68, 2
  %91 = add nuw nsw i32 %90, %83
  %92 = add nuw nsw i32 %91, %89
  %93 = lshr i32 %92, 2
  %94 = shl nuw nsw i32 %89, 1
  %95 = mul i64 %6, 30064771072
  %96 = add i64 %95, -4294967296
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i16, i16* %5, i64 %97
  %99 = load i16, i16* %98, align 2
  %100 = zext i16 %99 to i32
  %101 = add nuw nsw i32 %78, 2
  %102 = add nuw nsw i32 %101, %94
  %103 = add nuw nsw i32 %102, %100
  %104 = lshr i32 %103, 2
  %105 = mul nuw nsw i32 %100, 3
  %106 = add nuw nsw i32 %89, 2
  %107 = add nuw nsw i32 %106, %105
  %108 = lshr i32 %107, 2
  %109 = shl i64 %6, 32
  %110 = sub i64 0, %109
  %111 = ashr exact i64 %110, 32
  %112 = select i1 %7, i64 %20, i64 %111
  %113 = getelementptr inbounds i16, i16* %5, i64 %112
  %114 = load i16, i16* %113, align 2
  %115 = zext i16 %114 to i32
  %116 = getelementptr inbounds i16, i16* %5, i64 %111
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = shl nuw nsw i32 %118, 1
  %120 = sub i64 4294967296, %22
  %121 = ashr exact i64 %120, 32
  %122 = getelementptr inbounds i16, i16* %5, i64 %121
  %123 = load i16, i16* %122, align 2
  %124 = zext i16 %123 to i32
  %125 = add nuw nsw i32 %124, 2
  %126 = add nuw nsw i32 %125, %115
  %127 = add nuw nsw i32 %126, %119
  %128 = lshr i32 %127, 2
  %129 = shl nuw nsw i32 %124, 1
  %130 = sub i64 8589934592, %22
  %131 = ashr exact i64 %130, 32
  %132 = getelementptr inbounds i16, i16* %5, i64 %131
  %133 = load i16, i16* %132, align 2
  %134 = zext i16 %133 to i32
  %135 = add nuw nsw i32 %134, 2
  %136 = add nuw nsw i32 %135, %118
  %137 = add nuw nsw i32 %136, %129
  %138 = lshr i32 %137, 2
  %139 = shl nuw nsw i32 %134, 1
  %140 = sub i64 12884901888, %22
  %141 = ashr exact i64 %140, 32
  %142 = getelementptr inbounds i16, i16* %5, i64 %141
  %143 = load i16, i16* %142, align 2
  %144 = zext i16 %143 to i32
  %145 = add nuw nsw i32 %125, %139
  %146 = add nuw nsw i32 %145, %144
  %147 = lshr i32 %146, 2
  %148 = shl nuw nsw i32 %144, 1
  %149 = sub i64 17179869184, %22
  %150 = ashr exact i64 %149, 32
  %151 = getelementptr inbounds i16, i16* %5, i64 %150
  %152 = load i16, i16* %151, align 2
  %153 = zext i16 %152 to i32
  %154 = add nuw nsw i32 %135, %148
  %155 = add nuw nsw i32 %154, %153
  %156 = lshr i32 %155, 2
  %157 = shl nuw nsw i32 %153, 1
  %158 = sub i64 21474836480, %22
  %159 = ashr exact i64 %158, 32
  %160 = getelementptr inbounds i16, i16* %5, i64 %159
  %161 = load i16, i16* %160, align 2
  %162 = zext i16 %161 to i32
  %163 = add nuw nsw i32 %144, 2
  %164 = add nuw nsw i32 %163, %157
  %165 = add nuw nsw i32 %164, %162
  %166 = lshr i32 %165, 2
  %167 = shl nuw nsw i32 %162, 1
  %168 = sub i64 25769803776, %22
  %169 = ashr exact i64 %168, 32
  %170 = getelementptr inbounds i16, i16* %5, i64 %169
  %171 = load i16, i16* %170, align 2
  %172 = zext i16 %171 to i32
  %173 = add nuw nsw i32 %153, 2
  %174 = add nuw nsw i32 %173, %167
  %175 = add nuw nsw i32 %174, %172
  %176 = lshr i32 %175, 2
  %177 = shl nuw nsw i32 %172, 1
  %178 = sub i64 30064771072, %22
  %179 = ashr exact i64 %178, 32
  %180 = getelementptr inbounds i16, i16* %5, i64 %179
  %181 = load i16, i16* %180, align 2
  %182 = zext i16 %181 to i32
  %183 = add nuw nsw i32 %162, 2
  %184 = add nuw nsw i32 %183, %177
  %185 = add nuw nsw i32 %184, %182
  %186 = lshr i32 %185, 2
  %187 = icmp eq i32 %2, 0
  br i1 %187, label %194, label %188

188:                                              ; preds = %19
  %189 = sub i64 34359738368, %22
  %190 = ashr exact i64 %189, 32
  %191 = getelementptr inbounds i16, i16* %5, i64 %190
  %192 = load i16, i16* %191, align 2
  %193 = zext i16 %192 to i32
  br label %194

194:                                              ; preds = %19, %188
  %195 = phi i32 [ %193, %188 ], [ %182, %19 ]
  %196 = shl nuw nsw i32 %182, 1
  %197 = add nuw nsw i32 %172, 2
  %198 = add nuw nsw i32 %197, %196
  %199 = add nuw nsw i32 %198, %195
  %200 = lshr i32 %199, 2
  %201 = add nuw nsw i32 %39, 8
  %202 = add nuw nsw i32 %201, %51
  %203 = add nuw nsw i32 %202, %61
  %204 = add nuw nsw i32 %203, %71
  %205 = add nuw nsw i32 %204, %82
  %206 = add nuw nsw i32 %205, %93
  %207 = add nuw nsw i32 %206, %108
  %208 = add nuw nsw i32 %207, %104
  %209 = add nuw nsw i32 %208, %128
  %210 = add nuw nsw i32 %209, %138
  %211 = add nuw nsw i32 %210, %147
  %212 = add nuw nsw i32 %211, %156
  %213 = add nuw nsw i32 %212, %166
  %214 = add nuw nsw i32 %213, %176
  %215 = add nuw nsw i32 %214, %186
  %216 = add nuw nsw i32 %215, %200
  %217 = ashr i32 %216, 4
  %218 = sext i32 %217 to i64
  %219 = mul i64 %218, 281479271743489
  %220 = bitcast i8* %0 to i64*
  store i64 %219, i64* %220, align 8
  %221 = getelementptr inbounds i8, i8* %0, i64 8
  %222 = bitcast i8* %221 to i64*
  store i64 %219, i64* %222, align 8
  %223 = getelementptr inbounds i16, i16* %5, i64 %21
  %224 = bitcast i16* %223 to i64*
  store i64 %219, i64* %224, align 8
  %225 = getelementptr inbounds i16, i16* %223, i64 4
  %226 = bitcast i16* %225 to i64*
  store i64 %219, i64* %226, align 8
  %227 = getelementptr inbounds i16, i16* %223, i64 %21
  %228 = bitcast i16* %227 to i64*
  store i64 %219, i64* %228, align 8
  %229 = getelementptr inbounds i16, i16* %227, i64 4
  %230 = bitcast i16* %229 to i64*
  store i64 %219, i64* %230, align 8
  %231 = getelementptr inbounds i16, i16* %227, i64 %21
  %232 = bitcast i16* %231 to i64*
  store i64 %219, i64* %232, align 8
  %233 = getelementptr inbounds i16, i16* %231, i64 4
  %234 = bitcast i16* %233 to i64*
  store i64 %219, i64* %234, align 8
  %235 = getelementptr inbounds i16, i16* %231, i64 %21
  %236 = bitcast i16* %235 to i64*
  store i64 %219, i64* %236, align 8
  %237 = getelementptr inbounds i16, i16* %235, i64 4
  %238 = bitcast i16* %237 to i64*
  store i64 %219, i64* %238, align 8
  %239 = getelementptr inbounds i16, i16* %235, i64 %21
  %240 = bitcast i16* %239 to i64*
  store i64 %219, i64* %240, align 8
  %241 = getelementptr inbounds i16, i16* %239, i64 4
  %242 = bitcast i16* %241 to i64*
  store i64 %219, i64* %242, align 8
  %243 = getelementptr inbounds i16, i16* %239, i64 %21
  %244 = bitcast i16* %243 to i64*
  store i64 %219, i64* %244, align 8
  %245 = getelementptr inbounds i16, i16* %243, i64 4
  %246 = bitcast i16* %245 to i64*
  store i64 %219, i64* %246, align 8
  %247 = getelementptr inbounds i16, i16* %243, i64 %21
  %248 = bitcast i16* %247 to i64*
  store i64 %219, i64* %248, align 8
  %249 = getelementptr inbounds i16, i16* %247, i64 4
  %250 = bitcast i16* %249 to i64*
  store i64 %219, i64* %250, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_down_left_12_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %97, label %99

97:                                               ; preds = %18
  %98 = mul nuw nsw i32 %91, 3
  br label %181

99:                                               ; preds = %18
  %100 = sub i64 34359738368, %19
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %5, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i32
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %105, %104
  %107 = shl nuw nsw i32 %104, 1
  %108 = sub i64 38654705664, %19
  %109 = ashr exact i64 %108, 32
  %110 = getelementptr inbounds i16, i16* %5, i64 %109
  %111 = load i16, i16* %110, align 2
  %112 = zext i16 %111 to i32
  %113 = add nuw nsw i32 %91, 2
  %114 = add nuw nsw i32 %113, %107
  %115 = add nuw nsw i32 %114, %112
  %116 = lshr i32 %115, 2
  %117 = shl nuw nsw i32 %112, 1
  %118 = sub i64 42949672960, %19
  %119 = ashr exact i64 %118, 32
  %120 = getelementptr inbounds i16, i16* %5, i64 %119
  %121 = load i16, i16* %120, align 2
  %122 = zext i16 %121 to i32
  %123 = add nuw nsw i32 %122, 2
  %124 = add nuw nsw i32 %123, %104
  %125 = add nuw nsw i32 %124, %117
  %126 = lshr i32 %125, 2
  %127 = shl nuw nsw i32 %122, 1
  %128 = sub i64 47244640256, %19
  %129 = ashr exact i64 %128, 32
  %130 = getelementptr inbounds i16, i16* %5, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i32
  %133 = add nuw nsw i32 %112, 2
  %134 = add nuw nsw i32 %133, %127
  %135 = add nuw nsw i32 %134, %132
  %136 = lshr i32 %135, 2
  %137 = shl nuw nsw i32 %132, 1
  %138 = sub i64 51539607552, %19
  %139 = ashr exact i64 %138, 32
  %140 = getelementptr inbounds i16, i16* %5, i64 %139
  %141 = load i16, i16* %140, align 2
  %142 = zext i16 %141 to i32
  %143 = add nuw nsw i32 %123, %137
  %144 = add nuw nsw i32 %143, %142
  %145 = lshr i32 %144, 2
  %146 = shl nuw nsw i32 %142, 1
  %147 = sub i64 55834574848, %19
  %148 = ashr exact i64 %147, 32
  %149 = getelementptr inbounds i16, i16* %5, i64 %148
  %150 = load i16, i16* %149, align 2
  %151 = zext i16 %150 to i32
  %152 = add nuw nsw i32 %132, 2
  %153 = add nuw nsw i32 %152, %146
  %154 = add nuw nsw i32 %153, %151
  %155 = lshr i32 %154, 2
  %156 = shl nuw nsw i32 %151, 1
  %157 = sub i64 60129542144, %19
  %158 = ashr exact i64 %157, 32
  %159 = getelementptr inbounds i16, i16* %5, i64 %158
  %160 = load i16, i16* %159, align 2
  %161 = zext i16 %160 to i32
  %162 = add nuw nsw i32 %142, 2
  %163 = add nuw nsw i32 %162, %156
  %164 = add nuw nsw i32 %163, %161
  %165 = lshr i32 %164, 2
  %166 = shl nuw nsw i32 %161, 1
  %167 = sub i64 64424509440, %19
  %168 = ashr exact i64 %167, 32
  %169 = getelementptr inbounds i16, i16* %5, i64 %168
  %170 = load i16, i16* %169, align 2
  %171 = zext i16 %170 to i32
  %172 = add nuw nsw i32 %151, 2
  %173 = add nuw nsw i32 %172, %166
  %174 = add nuw nsw i32 %173, %171
  %175 = lshr i32 %174, 2
  %176 = mul nuw nsw i32 %171, 3
  %177 = add nuw nsw i32 %161, 2
  %178 = add nuw nsw i32 %177, %176
  %179 = lshr i32 %178, 2
  %180 = mul nuw nsw i32 %179, 3
  br label %181

181:                                              ; preds = %97, %99
  %182 = phi i32 [ %98, %97 ], [ %180, %99 ]
  %183 = phi i32 [ %98, %97 ], [ %106, %99 ]
  %184 = phi i32 [ %91, %97 ], [ %116, %99 ]
  %185 = phi i32 [ %91, %97 ], [ %126, %99 ]
  %186 = phi i32 [ %91, %97 ], [ %136, %99 ]
  %187 = phi i32 [ %91, %97 ], [ %145, %99 ]
  %188 = phi i32 [ %91, %97 ], [ %155, %99 ]
  %189 = phi i32 [ %91, %97 ], [ %165, %99 ]
  %190 = phi i32 [ %91, %97 ], [ %175, %99 ]
  %191 = phi i32 [ %91, %97 ], [ %179, %99 ]
  %192 = add nuw nsw i32 %81, 2
  %193 = add nuw nsw i32 %192, %183
  %194 = lshr i32 %193, 2
  %195 = shl nuw nsw i32 %47, 1
  %196 = add nuw nsw i32 %56, 2
  %197 = add nuw nsw i32 %196, %37
  %198 = add nuw nsw i32 %197, %195
  %199 = lshr i32 %198, 2
  %200 = trunc i32 %199 to i16
  store i16 %200, i16* %5, align 2
  %201 = shl nuw nsw i32 %56, 1
  %202 = add nuw nsw i32 %65, 2
  %203 = add nuw nsw i32 %202, %47
  %204 = add nuw nsw i32 %203, %201
  %205 = lshr i32 %204, 2
  %206 = trunc i32 %205 to i16
  %207 = getelementptr inbounds i8, i8* %0, i64 2
  %208 = bitcast i8* %207 to i16*
  store i16 %206, i16* %208, align 2
  %209 = ashr exact i64 %19, 32
  %210 = getelementptr inbounds i16, i16* %5, i64 %209
  store i16 %206, i16* %210, align 2
  %211 = shl nuw nsw i32 %65, 1
  %212 = add nuw nsw i32 %196, %211
  %213 = add nuw nsw i32 %212, %75
  %214 = lshr i32 %213, 2
  %215 = trunc i32 %214 to i16
  %216 = getelementptr inbounds i8, i8* %0, i64 4
  %217 = bitcast i8* %216 to i16*
  store i16 %215, i16* %217, align 2
  %218 = add i64 %19, 4294967296
  %219 = ashr exact i64 %218, 32
  %220 = getelementptr inbounds i16, i16* %5, i64 %219
  store i16 %215, i16* %220, align 2
  %221 = trunc i64 %3 to i32
  %222 = and i32 %221, -2
  %223 = sext i32 %222 to i64
  %224 = getelementptr inbounds i16, i16* %5, i64 %223
  store i16 %215, i16* %224, align 2
  %225 = shl nuw nsw i32 %75, 1
  %226 = add nuw nsw i32 %202, %225
  %227 = add nuw nsw i32 %226, %85
  %228 = lshr i32 %227, 2
  %229 = trunc i32 %228 to i16
  %230 = getelementptr inbounds i8, i8* %0, i64 6
  %231 = bitcast i8* %230 to i16*
  store i16 %229, i16* %231, align 2
  %232 = add i64 %19, 8589934592
  %233 = ashr exact i64 %232, 32
  %234 = getelementptr inbounds i16, i16* %5, i64 %233
  store i16 %229, i16* %234, align 2
  %235 = shl i64 %3, 32
  %236 = ashr exact i64 %235, 32
  %237 = or i64 %236, 1
  %238 = getelementptr inbounds i16, i16* %5, i64 %237
  store i16 %229, i16* %238, align 2
  %239 = mul nsw i32 %7, 3
  %240 = sext i32 %239 to i64
  %241 = getelementptr inbounds i16, i16* %5, i64 %240
  store i16 %229, i16* %241, align 2
  %242 = shl nuw nsw i32 %85, 1
  %243 = add nuw nsw i32 %75, 2
  %244 = add nuw nsw i32 %243, %242
  %245 = add nuw nsw i32 %244, %95
  %246 = lshr i32 %245, 2
  %247 = trunc i32 %246 to i16
  %248 = getelementptr inbounds i8, i8* %0, i64 8
  %249 = bitcast i8* %248 to i16*
  store i16 %247, i16* %249, align 2
  %250 = add i64 %19, 12884901888
  %251 = ashr exact i64 %250, 32
  %252 = getelementptr inbounds i16, i16* %5, i64 %251
  store i16 %247, i16* %252, align 2
  %253 = add nsw i32 %222, 2
  %254 = sext i32 %253 to i64
  %255 = getelementptr inbounds i16, i16* %5, i64 %254
  store i16 %247, i16* %255, align 2
  %256 = add nsw i32 %239, 1
  %257 = sext i32 %256 to i64
  %258 = getelementptr inbounds i16, i16* %5, i64 %257
  store i16 %247, i16* %258, align 2
  %259 = shl i64 %6, 34
  %260 = ashr exact i64 %259, 32
  %261 = getelementptr inbounds i16, i16* %5, i64 %260
  store i16 %247, i16* %261, align 2
  %262 = shl nuw nsw i32 %95, 1
  %263 = add nuw nsw i32 %85, 2
  %264 = add nuw nsw i32 %263, %262
  %265 = add nuw nsw i32 %264, %194
  %266 = lshr i32 %265, 2
  %267 = trunc i32 %266 to i16
  %268 = getelementptr inbounds i8, i8* %0, i64 10
  %269 = bitcast i8* %268 to i16*
  store i16 %267, i16* %269, align 2
  %270 = add i64 %19, 17179869184
  %271 = ashr exact i64 %270, 32
  %272 = getelementptr inbounds i16, i16* %5, i64 %271
  store i16 %267, i16* %272, align 2
  %273 = add nsw i32 %222, 3
  %274 = sext i32 %273 to i64
  %275 = getelementptr inbounds i16, i16* %5, i64 %274
  store i16 %267, i16* %275, align 2
  %276 = add nsw i32 %239, 2
  %277 = sext i32 %276 to i64
  %278 = getelementptr inbounds i16, i16* %5, i64 %277
  store i16 %267, i16* %278, align 2
  %279 = or i64 %260, 1
  %280 = getelementptr inbounds i16, i16* %5, i64 %279
  store i16 %267, i16* %280, align 2
  %281 = mul nsw i32 %7, 5
  %282 = sext i32 %281 to i64
  %283 = getelementptr inbounds i16, i16* %5, i64 %282
  store i16 %267, i16* %283, align 2
  %284 = shl nuw nsw i32 %194, 1
  %285 = add nuw nsw i32 %95, 2
  %286 = add nuw nsw i32 %285, %184
  %287 = add nuw nsw i32 %286, %284
  %288 = lshr i32 %287, 2
  %289 = trunc i32 %288 to i16
  %290 = getelementptr inbounds i8, i8* %0, i64 12
  %291 = bitcast i8* %290 to i16*
  store i16 %289, i16* %291, align 2
  %292 = add i64 %19, 21474836480
  %293 = ashr exact i64 %292, 32
  %294 = getelementptr inbounds i16, i16* %5, i64 %293
  store i16 %289, i16* %294, align 2
  %295 = add nsw i32 %222, 4
  %296 = sext i32 %295 to i64
  %297 = getelementptr inbounds i16, i16* %5, i64 %296
  store i16 %289, i16* %297, align 2
  %298 = add nsw i32 %239, 3
  %299 = sext i32 %298 to i64
  %300 = getelementptr inbounds i16, i16* %5, i64 %299
  store i16 %289, i16* %300, align 2
  %301 = or i64 %260, 2
  %302 = getelementptr inbounds i16, i16* %5, i64 %301
  store i16 %289, i16* %302, align 2
  %303 = add nsw i32 %281, 1
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds i16, i16* %5, i64 %304
  store i16 %289, i16* %305, align 2
  %306 = mul nsw i32 %7, 6
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i16, i16* %5, i64 %307
  store i16 %289, i16* %308, align 2
  %309 = shl nuw nsw i32 %184, 1
  %310 = add nuw nsw i32 %194, 2
  %311 = add nuw nsw i32 %310, %185
  %312 = add nuw nsw i32 %311, %309
  %313 = lshr i32 %312, 2
  %314 = trunc i32 %313 to i16
  %315 = getelementptr inbounds i8, i8* %0, i64 14
  %316 = bitcast i8* %315 to i16*
  store i16 %314, i16* %316, align 2
  %317 = add i64 %19, 25769803776
  %318 = ashr exact i64 %317, 32
  %319 = getelementptr inbounds i16, i16* %5, i64 %318
  store i16 %314, i16* %319, align 2
  %320 = add nsw i32 %222, 5
  %321 = sext i32 %320 to i64
  %322 = getelementptr inbounds i16, i16* %5, i64 %321
  store i16 %314, i16* %322, align 2
  %323 = add nsw i32 %239, 4
  %324 = sext i32 %323 to i64
  %325 = getelementptr inbounds i16, i16* %5, i64 %324
  store i16 %314, i16* %325, align 2
  %326 = or i64 %260, 3
  %327 = getelementptr inbounds i16, i16* %5, i64 %326
  store i16 %314, i16* %327, align 2
  %328 = add nsw i32 %281, 2
  %329 = sext i32 %328 to i64
  %330 = getelementptr inbounds i16, i16* %5, i64 %329
  store i16 %314, i16* %330, align 2
  %331 = or i32 %306, 1
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds i16, i16* %5, i64 %332
  store i16 %314, i16* %333, align 2
  %334 = mul nsw i32 %7, 7
  %335 = sext i32 %334 to i64
  %336 = getelementptr inbounds i16, i16* %5, i64 %335
  store i16 %314, i16* %336, align 2
  %337 = shl nuw nsw i32 %185, 1
  %338 = add nuw nsw i32 %184, 2
  %339 = add nuw nsw i32 %338, %337
  %340 = add nuw nsw i32 %339, %186
  %341 = lshr i32 %340, 2
  %342 = trunc i32 %341 to i16
  %343 = add i64 %19, 30064771072
  %344 = ashr exact i64 %343, 32
  %345 = getelementptr inbounds i16, i16* %5, i64 %344
  store i16 %342, i16* %345, align 2
  %346 = add nsw i32 %222, 6
  %347 = sext i32 %346 to i64
  %348 = getelementptr inbounds i16, i16* %5, i64 %347
  store i16 %342, i16* %348, align 2
  %349 = add nsw i32 %239, 5
  %350 = sext i32 %349 to i64
  %351 = getelementptr inbounds i16, i16* %5, i64 %350
  store i16 %342, i16* %351, align 2
  %352 = add i64 %259, 17179869184
  %353 = ashr exact i64 %352, 32
  %354 = getelementptr inbounds i16, i16* %5, i64 %353
  store i16 %342, i16* %354, align 2
  %355 = add nsw i32 %281, 3
  %356 = sext i32 %355 to i64
  %357 = getelementptr inbounds i16, i16* %5, i64 %356
  store i16 %342, i16* %357, align 2
  %358 = add nsw i32 %306, 2
  %359 = sext i32 %358 to i64
  %360 = getelementptr inbounds i16, i16* %5, i64 %359
  store i16 %342, i16* %360, align 2
  %361 = add nsw i32 %334, 1
  %362 = sext i32 %361 to i64
  %363 = getelementptr inbounds i16, i16* %5, i64 %362
  store i16 %342, i16* %363, align 2
  %364 = shl nuw nsw i32 %186, 1
  %365 = add nuw nsw i32 %185, 2
  %366 = add nuw nsw i32 %365, %364
  %367 = add nuw nsw i32 %366, %187
  %368 = lshr i32 %367, 2
  %369 = trunc i32 %368 to i16
  %370 = add nsw i32 %222, 7
  %371 = sext i32 %370 to i64
  %372 = getelementptr inbounds i16, i16* %5, i64 %371
  store i16 %369, i16* %372, align 2
  %373 = add nsw i32 %239, 6
  %374 = sext i32 %373 to i64
  %375 = getelementptr inbounds i16, i16* %5, i64 %374
  store i16 %369, i16* %375, align 2
  %376 = add i64 %259, 21474836480
  %377 = ashr exact i64 %376, 32
  %378 = getelementptr inbounds i16, i16* %5, i64 %377
  store i16 %369, i16* %378, align 2
  %379 = add nsw i32 %281, 4
  %380 = sext i32 %379 to i64
  %381 = getelementptr inbounds i16, i16* %5, i64 %380
  store i16 %369, i16* %381, align 2
  %382 = add nsw i32 %306, 3
  %383 = sext i32 %382 to i64
  %384 = getelementptr inbounds i16, i16* %5, i64 %383
  store i16 %369, i16* %384, align 2
  %385 = add nsw i32 %334, 2
  %386 = sext i32 %385 to i64
  %387 = getelementptr inbounds i16, i16* %5, i64 %386
  store i16 %369, i16* %387, align 2
  %388 = shl nuw nsw i32 %187, 1
  %389 = add nuw nsw i32 %186, 2
  %390 = add nuw nsw i32 %389, %388
  %391 = add nuw nsw i32 %390, %188
  %392 = lshr i32 %391, 2
  %393 = trunc i32 %392 to i16
  %394 = add nsw i32 %239, 7
  %395 = sext i32 %394 to i64
  %396 = getelementptr inbounds i16, i16* %5, i64 %395
  store i16 %393, i16* %396, align 2
  %397 = add i64 %259, 25769803776
  %398 = ashr exact i64 %397, 32
  %399 = getelementptr inbounds i16, i16* %5, i64 %398
  store i16 %393, i16* %399, align 2
  %400 = add nsw i32 %281, 5
  %401 = sext i32 %400 to i64
  %402 = getelementptr inbounds i16, i16* %5, i64 %401
  store i16 %393, i16* %402, align 2
  %403 = add nsw i32 %306, 4
  %404 = sext i32 %403 to i64
  %405 = getelementptr inbounds i16, i16* %5, i64 %404
  store i16 %393, i16* %405, align 2
  %406 = add nsw i32 %334, 3
  %407 = sext i32 %406 to i64
  %408 = getelementptr inbounds i16, i16* %5, i64 %407
  store i16 %393, i16* %408, align 2
  %409 = shl nuw nsw i32 %188, 1
  %410 = add nuw nsw i32 %187, 2
  %411 = add nuw nsw i32 %410, %409
  %412 = add nuw nsw i32 %411, %189
  %413 = lshr i32 %412, 2
  %414 = trunc i32 %413 to i16
  %415 = add i64 %259, 30064771072
  %416 = ashr exact i64 %415, 32
  %417 = getelementptr inbounds i16, i16* %5, i64 %416
  store i16 %414, i16* %417, align 2
  %418 = add nsw i32 %281, 6
  %419 = sext i32 %418 to i64
  %420 = getelementptr inbounds i16, i16* %5, i64 %419
  store i16 %414, i16* %420, align 2
  %421 = add nsw i32 %306, 5
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds i16, i16* %5, i64 %422
  store i16 %414, i16* %423, align 2
  %424 = add nsw i32 %334, 4
  %425 = sext i32 %424 to i64
  %426 = getelementptr inbounds i16, i16* %5, i64 %425
  store i16 %414, i16* %426, align 2
  %427 = shl nuw nsw i32 %189, 1
  %428 = add nuw nsw i32 %188, 2
  %429 = add nuw nsw i32 %428, %427
  %430 = add nuw nsw i32 %429, %190
  %431 = lshr i32 %430, 2
  %432 = trunc i32 %431 to i16
  %433 = add nsw i32 %281, 7
  %434 = sext i32 %433 to i64
  %435 = getelementptr inbounds i16, i16* %5, i64 %434
  store i16 %432, i16* %435, align 2
  %436 = add nsw i32 %306, 6
  %437 = sext i32 %436 to i64
  %438 = getelementptr inbounds i16, i16* %5, i64 %437
  store i16 %432, i16* %438, align 2
  %439 = add nsw i32 %334, 5
  %440 = sext i32 %439 to i64
  %441 = getelementptr inbounds i16, i16* %5, i64 %440
  store i16 %432, i16* %441, align 2
  %442 = shl nuw nsw i32 %190, 1
  %443 = add nuw nsw i32 %189, 2
  %444 = add nuw nsw i32 %443, %442
  %445 = add nuw nsw i32 %444, %191
  %446 = lshr i32 %445, 2
  %447 = trunc i32 %446 to i16
  %448 = add nsw i32 %306, 7
  %449 = sext i32 %448 to i64
  %450 = getelementptr inbounds i16, i16* %5, i64 %449
  store i16 %447, i16* %450, align 2
  %451 = add nsw i32 %334, 6
  %452 = sext i32 %451 to i64
  %453 = getelementptr inbounds i16, i16* %5, i64 %452
  store i16 %447, i16* %453, align 2
  %454 = add nuw nsw i32 %190, 2
  %455 = add nuw nsw i32 %454, %182
  %456 = lshr i32 %455, 2
  %457 = trunc i32 %456 to i16
  %458 = add nsw i32 %334, 7
  %459 = sext i32 %458 to i64
  %460 = getelementptr inbounds i16, i16* %5, i64 %459
  store i16 %457, i16* %460, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_down_right_12_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp ne i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %10, label %15

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %27, 2
  %45 = add nuw nsw i32 %44, %38
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %43, 2
  %64 = add nuw nsw i32 %63, %57
  %65 = add nuw nsw i32 %64, %62
  %66 = lshr i32 %65, 2
  %67 = shl nuw nsw i32 %62, 1
  %68 = sub i64 21474836480, %19
  %69 = ashr exact i64 %68, 32
  %70 = getelementptr inbounds i16, i16* %5, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i32
  %73 = add nuw nsw i32 %53, 2
  %74 = add nuw nsw i32 %73, %67
  %75 = add nuw nsw i32 %74, %72
  %76 = lshr i32 %75, 2
  %77 = shl nuw nsw i32 %72, 1
  %78 = sub i64 25769803776, %19
  %79 = ashr exact i64 %78, 32
  %80 = getelementptr inbounds i16, i16* %5, i64 %79
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i32
  %83 = add nuw nsw i32 %62, 2
  %84 = add nuw nsw i32 %83, %77
  %85 = add nuw nsw i32 %84, %82
  %86 = lshr i32 %85, 2
  %87 = shl nuw nsw i32 %82, 1
  %88 = sub i64 30064771072, %19
  %89 = ashr exact i64 %88, 32
  %90 = getelementptr inbounds i16, i16* %5, i64 %89
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i32
  %93 = add nuw nsw i32 %72, 2
  %94 = add nuw nsw i32 %93, %87
  %95 = add nuw nsw i32 %94, %92
  %96 = lshr i32 %95, 2
  %97 = icmp eq i32 %2, 0
  br i1 %97, label %104, label %98

98:                                               ; preds = %18
  %99 = sub i64 34359738368, %19
  %100 = ashr exact i64 %99, 32
  %101 = getelementptr inbounds i16, i16* %5, i64 %100
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  br label %104

104:                                              ; preds = %18, %98
  %105 = phi i32 [ %103, %98 ], [ %92, %18 ]
  %106 = shl nuw nsw i32 %92, 1
  %107 = add nuw nsw i32 %82, 2
  %108 = add nuw nsw i32 %107, %106
  %109 = add nuw nsw i32 %108, %105
  %110 = lshr i32 %109, 2
  %111 = ashr exact i64 %19, 32
  %112 = xor i64 %111, -1
  %113 = getelementptr inbounds i16, i16* %5, i64 %112
  %114 = getelementptr inbounds i8, i8* %0, i64 -2
  %115 = bitcast i8* %114 to i16*
  %116 = select i1 %8, i16* %113, i16* %115
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = load i16, i16* %115, align 2
  %120 = zext i16 %119 to i32
  %121 = shl nuw nsw i32 %120, 1
  %122 = add i64 %19, -4294967296
  %123 = ashr exact i64 %122, 32
  %124 = getelementptr inbounds i16, i16* %5, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %126, 2
  %128 = add nuw nsw i32 %127, %118
  %129 = add nuw nsw i32 %128, %121
  %130 = lshr i32 %129, 2
  %131 = shl nuw nsw i32 %126, 1
  %132 = trunc i64 %3 to i32
  %133 = and i32 %132, -2
  %134 = add nsw i32 %133, -1
  %135 = sext i32 %134 to i64
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  %137 = load i16, i16* %136, align 2
  %138 = zext i16 %137 to i32
  %139 = add nuw nsw i32 %120, 2
  %140 = add nuw nsw i32 %139, %131
  %141 = add nuw nsw i32 %140, %138
  %142 = lshr i32 %141, 2
  %143 = shl nuw nsw i32 %138, 1
  %144 = mul nsw i32 %7, 3
  %145 = add nsw i32 %144, -1
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds i16, i16* %5, i64 %146
  %148 = load i16, i16* %147, align 2
  %149 = zext i16 %148 to i32
  %150 = add nuw nsw i32 %127, %143
  %151 = add nuw nsw i32 %150, %149
  %152 = lshr i32 %151, 2
  %153 = shl nuw nsw i32 %149, 1
  %154 = shl i64 %6, 34
  %155 = add i64 %154, -4294967296
  %156 = ashr exact i64 %155, 32
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  %158 = load i16, i16* %157, align 2
  %159 = zext i16 %158 to i32
  %160 = add nuw nsw i32 %138, 2
  %161 = add nuw nsw i32 %160, %153
  %162 = add nuw nsw i32 %161, %159
  %163 = lshr i32 %162, 2
  %164 = shl nuw nsw i32 %159, 1
  %165 = mul nsw i32 %7, 5
  %166 = add nsw i32 %165, -1
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds i16, i16* %5, i64 %167
  %169 = load i16, i16* %168, align 2
  %170 = zext i16 %169 to i32
  %171 = add nuw nsw i32 %149, 2
  %172 = add nuw nsw i32 %171, %164
  %173 = add nuw nsw i32 %172, %170
  %174 = lshr i32 %173, 2
  %175 = shl nuw nsw i32 %170, 1
  %176 = mul nsw i32 %7, 6
  %177 = add nsw i32 %176, -1
  %178 = sext i32 %177 to i64
  %179 = getelementptr inbounds i16, i16* %5, i64 %178
  %180 = load i16, i16* %179, align 2
  %181 = zext i16 %180 to i32
  %182 = add nuw nsw i32 %159, 2
  %183 = add nuw nsw i32 %182, %175
  %184 = add nuw nsw i32 %183, %181
  %185 = lshr i32 %184, 2
  %186 = shl nuw nsw i32 %181, 1
  %187 = mul nsw i32 %7, 7
  %188 = add nsw i32 %187, -1
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds i16, i16* %5, i64 %189
  %191 = load i16, i16* %190, align 2
  %192 = zext i16 %191 to i32
  %193 = add nuw nsw i32 %170, 2
  %194 = add nuw nsw i32 %193, %186
  %195 = add nuw nsw i32 %194, %192
  %196 = lshr i32 %195, 2
  %197 = mul nuw nsw i32 %192, 3
  %198 = add nuw nsw i32 %181, 2
  %199 = add nuw nsw i32 %198, %197
  %200 = lshr i32 %199, 2
  %201 = load i16, i16* %113, align 2
  %202 = zext i16 %201 to i32
  %203 = shl nuw nsw i32 %202, 1
  %204 = add nuw nsw i32 %44, %120
  %205 = add nuw nsw i32 %204, %203
  %206 = lshr i32 %205, 2
  %207 = shl nuw nsw i32 %196, 1
  %208 = add nuw nsw i32 %185, 2
  %209 = add nuw nsw i32 %208, %200
  %210 = add nuw nsw i32 %209, %207
  %211 = lshr i32 %210, 2
  %212 = trunc i32 %211 to i16
  %213 = sext i32 %187 to i64
  %214 = getelementptr inbounds i16, i16* %5, i64 %213
  store i16 %212, i16* %214, align 2
  %215 = shl nuw nsw i32 %185, 1
  %216 = add nuw nsw i32 %174, 2
  %217 = add nuw nsw i32 %216, %215
  %218 = add nuw nsw i32 %217, %196
  %219 = lshr i32 %218, 2
  %220 = trunc i32 %219 to i16
  %221 = add nsw i32 %187, 1
  %222 = sext i32 %221 to i64
  %223 = getelementptr inbounds i16, i16* %5, i64 %222
  store i16 %220, i16* %223, align 2
  %224 = sext i32 %176 to i64
  %225 = getelementptr inbounds i16, i16* %5, i64 %224
  store i16 %220, i16* %225, align 2
  %226 = shl nuw nsw i32 %174, 1
  %227 = add nuw nsw i32 %163, 2
  %228 = add nuw nsw i32 %227, %226
  %229 = add nuw nsw i32 %228, %185
  %230 = lshr i32 %229, 2
  %231 = trunc i32 %230 to i16
  %232 = add nsw i32 %187, 2
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds i16, i16* %5, i64 %233
  store i16 %231, i16* %234, align 2
  %235 = or i32 %176, 1
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds i16, i16* %5, i64 %236
  store i16 %231, i16* %237, align 2
  %238 = sext i32 %165 to i64
  %239 = getelementptr inbounds i16, i16* %5, i64 %238
  store i16 %231, i16* %239, align 2
  %240 = shl nuw nsw i32 %163, 1
  %241 = add nuw nsw i32 %152, 2
  %242 = add nuw nsw i32 %241, %240
  %243 = add nuw nsw i32 %242, %174
  %244 = lshr i32 %243, 2
  %245 = trunc i32 %244 to i16
  %246 = add nsw i32 %187, 3
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds i16, i16* %5, i64 %247
  store i16 %245, i16* %248, align 2
  %249 = add nsw i32 %176, 2
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds i16, i16* %5, i64 %250
  store i16 %245, i16* %251, align 2
  %252 = add nsw i32 %165, 1
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i16, i16* %5, i64 %253
  store i16 %245, i16* %254, align 2
  %255 = ashr exact i64 %154, 32
  %256 = getelementptr inbounds i16, i16* %5, i64 %255
  store i16 %245, i16* %256, align 2
  %257 = shl nuw nsw i32 %152, 1
  %258 = add nuw nsw i32 %142, 2
  %259 = add nuw nsw i32 %258, %257
  %260 = add nuw nsw i32 %259, %163
  %261 = lshr i32 %260, 2
  %262 = trunc i32 %261 to i16
  %263 = add nsw i32 %187, 4
  %264 = sext i32 %263 to i64
  %265 = getelementptr inbounds i16, i16* %5, i64 %264
  store i16 %262, i16* %265, align 2
  %266 = add nsw i32 %176, 3
  %267 = sext i32 %266 to i64
  %268 = getelementptr inbounds i16, i16* %5, i64 %267
  store i16 %262, i16* %268, align 2
  %269 = add nsw i32 %165, 2
  %270 = sext i32 %269 to i64
  %271 = getelementptr inbounds i16, i16* %5, i64 %270
  store i16 %262, i16* %271, align 2
  %272 = or i64 %255, 1
  %273 = getelementptr inbounds i16, i16* %5, i64 %272
  store i16 %262, i16* %273, align 2
  %274 = sext i32 %144 to i64
  %275 = getelementptr inbounds i16, i16* %5, i64 %274
  store i16 %262, i16* %275, align 2
  %276 = shl nuw nsw i32 %142, 1
  %277 = add nuw nsw i32 %130, 2
  %278 = add nuw nsw i32 %277, %276
  %279 = add nuw nsw i32 %278, %152
  %280 = lshr i32 %279, 2
  %281 = trunc i32 %280 to i16
  %282 = add nsw i32 %187, 5
  %283 = sext i32 %282 to i64
  %284 = getelementptr inbounds i16, i16* %5, i64 %283
  store i16 %281, i16* %284, align 2
  %285 = add nsw i32 %176, 4
  %286 = sext i32 %285 to i64
  %287 = getelementptr inbounds i16, i16* %5, i64 %286
  store i16 %281, i16* %287, align 2
  %288 = add nsw i32 %165, 3
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds i16, i16* %5, i64 %289
  store i16 %281, i16* %290, align 2
  %291 = or i64 %255, 2
  %292 = getelementptr inbounds i16, i16* %5, i64 %291
  store i16 %281, i16* %292, align 2
  %293 = add nsw i32 %144, 1
  %294 = sext i32 %293 to i64
  %295 = getelementptr inbounds i16, i16* %5, i64 %294
  store i16 %281, i16* %295, align 2
  %296 = sext i32 %133 to i64
  %297 = getelementptr inbounds i16, i16* %5, i64 %296
  store i16 %281, i16* %297, align 2
  %298 = shl nuw nsw i32 %130, 1
  %299 = add nuw nsw i32 %258, %298
  %300 = add nuw nsw i32 %299, %206
  %301 = lshr i32 %300, 2
  %302 = trunc i32 %301 to i16
  %303 = add nsw i32 %187, 6
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds i16, i16* %5, i64 %304
  store i16 %302, i16* %305, align 2
  %306 = add nsw i32 %176, 5
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i16, i16* %5, i64 %307
  store i16 %302, i16* %308, align 2
  %309 = add nsw i32 %165, 4
  %310 = sext i32 %309 to i64
  %311 = getelementptr inbounds i16, i16* %5, i64 %310
  store i16 %302, i16* %311, align 2
  %312 = or i64 %255, 3
  %313 = getelementptr inbounds i16, i16* %5, i64 %312
  store i16 %302, i16* %313, align 2
  %314 = add nsw i32 %144, 2
  %315 = sext i32 %314 to i64
  %316 = getelementptr inbounds i16, i16* %5, i64 %315
  store i16 %302, i16* %316, align 2
  %317 = shl i64 %3, 32
  %318 = ashr exact i64 %317, 32
  %319 = or i64 %318, 1
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %302, i16* %320, align 2
  %321 = getelementptr inbounds i16, i16* %5, i64 %111
  store i16 %302, i16* %321, align 2
  %322 = shl nuw nsw i32 %206, 1
  %323 = add nuw nsw i32 %37, 2
  %324 = add nuw nsw i32 %323, %130
  %325 = add nuw nsw i32 %324, %322
  %326 = lshr i32 %325, 2
  %327 = trunc i32 %326 to i16
  %328 = add nsw i32 %187, 7
  %329 = sext i32 %328 to i64
  %330 = getelementptr inbounds i16, i16* %5, i64 %329
  store i16 %327, i16* %330, align 2
  %331 = add nsw i32 %176, 6
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds i16, i16* %5, i64 %332
  store i16 %327, i16* %333, align 2
  %334 = add nsw i32 %165, 5
  %335 = sext i32 %334 to i64
  %336 = getelementptr inbounds i16, i16* %5, i64 %335
  store i16 %327, i16* %336, align 2
  %337 = add i64 %154, 17179869184
  %338 = ashr exact i64 %337, 32
  %339 = getelementptr inbounds i16, i16* %5, i64 %338
  store i16 %327, i16* %339, align 2
  %340 = add nsw i32 %144, 3
  %341 = sext i32 %340 to i64
  %342 = getelementptr inbounds i16, i16* %5, i64 %341
  store i16 %327, i16* %342, align 2
  %343 = add nsw i32 %133, 2
  %344 = sext i32 %343 to i64
  %345 = getelementptr inbounds i16, i16* %5, i64 %344
  store i16 %327, i16* %345, align 2
  %346 = add i64 %19, 4294967296
  %347 = ashr exact i64 %346, 32
  %348 = getelementptr inbounds i16, i16* %5, i64 %347
  store i16 %327, i16* %348, align 2
  store i16 %327, i16* %5, align 2
  %349 = shl nuw nsw i32 %37, 1
  %350 = add nuw nsw i32 %47, 2
  %351 = add nuw nsw i32 %350, %349
  %352 = add nuw nsw i32 %351, %206
  %353 = lshr i32 %352, 2
  %354 = trunc i32 %353 to i16
  %355 = add nsw i32 %176, 7
  %356 = sext i32 %355 to i64
  %357 = getelementptr inbounds i16, i16* %5, i64 %356
  store i16 %354, i16* %357, align 2
  %358 = add nsw i32 %165, 6
  %359 = sext i32 %358 to i64
  %360 = getelementptr inbounds i16, i16* %5, i64 %359
  store i16 %354, i16* %360, align 2
  %361 = add i64 %154, 21474836480
  %362 = ashr exact i64 %361, 32
  %363 = getelementptr inbounds i16, i16* %5, i64 %362
  store i16 %354, i16* %363, align 2
  %364 = add nsw i32 %144, 4
  %365 = sext i32 %364 to i64
  %366 = getelementptr inbounds i16, i16* %5, i64 %365
  store i16 %354, i16* %366, align 2
  %367 = add nsw i32 %133, 3
  %368 = sext i32 %367 to i64
  %369 = getelementptr inbounds i16, i16* %5, i64 %368
  store i16 %354, i16* %369, align 2
  %370 = add i64 %19, 8589934592
  %371 = ashr exact i64 %370, 32
  %372 = getelementptr inbounds i16, i16* %5, i64 %371
  store i16 %354, i16* %372, align 2
  %373 = getelementptr inbounds i8, i8* %0, i64 2
  %374 = bitcast i8* %373 to i16*
  store i16 %354, i16* %374, align 2
  %375 = shl nuw nsw i32 %47, 1
  %376 = add nuw nsw i32 %323, %375
  %377 = add nuw nsw i32 %376, %56
  %378 = lshr i32 %377, 2
  %379 = trunc i32 %378 to i16
  %380 = add nsw i32 %165, 7
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i16, i16* %5, i64 %381
  store i16 %379, i16* %382, align 2
  %383 = add i64 %154, 25769803776
  %384 = ashr exact i64 %383, 32
  %385 = getelementptr inbounds i16, i16* %5, i64 %384
  store i16 %379, i16* %385, align 2
  %386 = add nsw i32 %144, 5
  %387 = sext i32 %386 to i64
  %388 = getelementptr inbounds i16, i16* %5, i64 %387
  store i16 %379, i16* %388, align 2
  %389 = add nsw i32 %133, 4
  %390 = sext i32 %389 to i64
  %391 = getelementptr inbounds i16, i16* %5, i64 %390
  store i16 %379, i16* %391, align 2
  %392 = add i64 %19, 12884901888
  %393 = ashr exact i64 %392, 32
  %394 = getelementptr inbounds i16, i16* %5, i64 %393
  store i16 %379, i16* %394, align 2
  %395 = getelementptr inbounds i8, i8* %0, i64 4
  %396 = bitcast i8* %395 to i16*
  store i16 %379, i16* %396, align 2
  %397 = shl nuw nsw i32 %56, 1
  %398 = add nuw nsw i32 %350, %397
  %399 = add nuw nsw i32 %398, %66
  %400 = lshr i32 %399, 2
  %401 = trunc i32 %400 to i16
  %402 = add i64 %154, 30064771072
  %403 = ashr exact i64 %402, 32
  %404 = getelementptr inbounds i16, i16* %5, i64 %403
  store i16 %401, i16* %404, align 2
  %405 = add nsw i32 %144, 6
  %406 = sext i32 %405 to i64
  %407 = getelementptr inbounds i16, i16* %5, i64 %406
  store i16 %401, i16* %407, align 2
  %408 = add nsw i32 %133, 5
  %409 = sext i32 %408 to i64
  %410 = getelementptr inbounds i16, i16* %5, i64 %409
  store i16 %401, i16* %410, align 2
  %411 = add i64 %19, 17179869184
  %412 = ashr exact i64 %411, 32
  %413 = getelementptr inbounds i16, i16* %5, i64 %412
  store i16 %401, i16* %413, align 2
  %414 = getelementptr inbounds i8, i8* %0, i64 6
  %415 = bitcast i8* %414 to i16*
  store i16 %401, i16* %415, align 2
  %416 = shl nuw nsw i32 %66, 1
  %417 = add nuw nsw i32 %56, 2
  %418 = add nuw nsw i32 %417, %416
  %419 = add nuw nsw i32 %418, %76
  %420 = lshr i32 %419, 2
  %421 = trunc i32 %420 to i16
  %422 = add nsw i32 %144, 7
  %423 = sext i32 %422 to i64
  %424 = getelementptr inbounds i16, i16* %5, i64 %423
  store i16 %421, i16* %424, align 2
  %425 = add nsw i32 %133, 6
  %426 = sext i32 %425 to i64
  %427 = getelementptr inbounds i16, i16* %5, i64 %426
  store i16 %421, i16* %427, align 2
  %428 = add i64 %19, 21474836480
  %429 = ashr exact i64 %428, 32
  %430 = getelementptr inbounds i16, i16* %5, i64 %429
  store i16 %421, i16* %430, align 2
  %431 = getelementptr inbounds i8, i8* %0, i64 8
  %432 = bitcast i8* %431 to i16*
  store i16 %421, i16* %432, align 2
  %433 = shl nuw nsw i32 %76, 1
  %434 = add nuw nsw i32 %66, 2
  %435 = add nuw nsw i32 %434, %433
  %436 = add nuw nsw i32 %435, %86
  %437 = lshr i32 %436, 2
  %438 = trunc i32 %437 to i16
  %439 = add nsw i32 %133, 7
  %440 = sext i32 %439 to i64
  %441 = getelementptr inbounds i16, i16* %5, i64 %440
  store i16 %438, i16* %441, align 2
  %442 = add i64 %19, 25769803776
  %443 = ashr exact i64 %442, 32
  %444 = getelementptr inbounds i16, i16* %5, i64 %443
  store i16 %438, i16* %444, align 2
  %445 = getelementptr inbounds i8, i8* %0, i64 10
  %446 = bitcast i8* %445 to i16*
  store i16 %438, i16* %446, align 2
  %447 = shl nuw nsw i32 %86, 1
  %448 = add nuw nsw i32 %76, 2
  %449 = add nuw nsw i32 %448, %447
  %450 = add nuw nsw i32 %449, %96
  %451 = lshr i32 %450, 2
  %452 = trunc i32 %451 to i16
  %453 = add i64 %19, 30064771072
  %454 = ashr exact i64 %453, 32
  %455 = getelementptr inbounds i16, i16* %5, i64 %454
  store i16 %452, i16* %455, align 2
  %456 = getelementptr inbounds i8, i8* %0, i64 12
  %457 = bitcast i8* %456 to i16*
  store i16 %452, i16* %457, align 2
  %458 = shl nuw nsw i32 %96, 1
  %459 = add nuw nsw i32 %86, 2
  %460 = add nuw nsw i32 %459, %458
  %461 = add nuw nsw i32 %460, %110
  %462 = lshr i32 %461, 2
  %463 = trunc i32 %462 to i16
  %464 = getelementptr inbounds i8, i8* %0, i64 14
  %465 = bitcast i8* %464 to i16*
  store i16 %463, i16* %465, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_right_12_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp ne i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %10, label %15

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %27, 2
  %45 = add nuw nsw i32 %44, %38
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %43, 2
  %64 = add nuw nsw i32 %63, %57
  %65 = add nuw nsw i32 %64, %62
  %66 = lshr i32 %65, 2
  %67 = shl nuw nsw i32 %62, 1
  %68 = sub i64 21474836480, %19
  %69 = ashr exact i64 %68, 32
  %70 = getelementptr inbounds i16, i16* %5, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i32
  %73 = add nuw nsw i32 %53, 2
  %74 = add nuw nsw i32 %73, %67
  %75 = add nuw nsw i32 %74, %72
  %76 = lshr i32 %75, 2
  %77 = shl nuw nsw i32 %72, 1
  %78 = sub i64 25769803776, %19
  %79 = ashr exact i64 %78, 32
  %80 = getelementptr inbounds i16, i16* %5, i64 %79
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i32
  %83 = add nuw nsw i32 %62, 2
  %84 = add nuw nsw i32 %83, %77
  %85 = add nuw nsw i32 %84, %82
  %86 = lshr i32 %85, 2
  %87 = shl nuw nsw i32 %82, 1
  %88 = sub i64 30064771072, %19
  %89 = ashr exact i64 %88, 32
  %90 = getelementptr inbounds i16, i16* %5, i64 %89
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i32
  %93 = add nuw nsw i32 %72, 2
  %94 = add nuw nsw i32 %93, %87
  %95 = add nuw nsw i32 %94, %92
  %96 = lshr i32 %95, 2
  %97 = icmp eq i32 %2, 0
  br i1 %97, label %104, label %98

98:                                               ; preds = %18
  %99 = sub i64 34359738368, %19
  %100 = ashr exact i64 %99, 32
  %101 = getelementptr inbounds i16, i16* %5, i64 %100
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  br label %104

104:                                              ; preds = %18, %98
  %105 = phi i32 [ %103, %98 ], [ %92, %18 ]
  %106 = shl nuw nsw i32 %92, 1
  %107 = add nuw nsw i32 %82, 2
  %108 = add nuw nsw i32 %107, %106
  %109 = add nuw nsw i32 %108, %105
  %110 = lshr i32 %109, 2
  %111 = ashr exact i64 %19, 32
  %112 = xor i64 %111, -1
  %113 = getelementptr inbounds i16, i16* %5, i64 %112
  %114 = getelementptr inbounds i8, i8* %0, i64 -2
  %115 = bitcast i8* %114 to i16*
  %116 = select i1 %8, i16* %113, i16* %115
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = load i16, i16* %115, align 2
  %120 = zext i16 %119 to i32
  %121 = shl nuw nsw i32 %120, 1
  %122 = add i64 %19, -4294967296
  %123 = ashr exact i64 %122, 32
  %124 = getelementptr inbounds i16, i16* %5, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %126, 2
  %128 = add nuw nsw i32 %127, %118
  %129 = add nuw nsw i32 %128, %121
  %130 = lshr i32 %129, 2
  %131 = shl nuw nsw i32 %126, 1
  %132 = trunc i64 %3 to i32
  %133 = and i32 %132, -2
  %134 = add nsw i32 %133, -1
  %135 = sext i32 %134 to i64
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  %137 = load i16, i16* %136, align 2
  %138 = zext i16 %137 to i32
  %139 = add nuw nsw i32 %120, 2
  %140 = add nuw nsw i32 %139, %131
  %141 = add nuw nsw i32 %140, %138
  %142 = lshr i32 %141, 2
  %143 = shl nuw nsw i32 %138, 1
  %144 = mul nsw i32 %7, 3
  %145 = add nsw i32 %144, -1
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds i16, i16* %5, i64 %146
  %148 = load i16, i16* %147, align 2
  %149 = zext i16 %148 to i32
  %150 = add nuw nsw i32 %127, %143
  %151 = add nuw nsw i32 %150, %149
  %152 = lshr i32 %151, 2
  %153 = shl nuw nsw i32 %149, 1
  %154 = shl i64 %6, 34
  %155 = add i64 %154, -4294967296
  %156 = ashr exact i64 %155, 32
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  %158 = load i16, i16* %157, align 2
  %159 = zext i16 %158 to i32
  %160 = add nuw nsw i32 %138, 2
  %161 = add nuw nsw i32 %160, %153
  %162 = add nuw nsw i32 %161, %159
  %163 = lshr i32 %162, 2
  %164 = shl nuw nsw i32 %159, 1
  %165 = mul nsw i32 %7, 5
  %166 = add nsw i32 %165, -1
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds i16, i16* %5, i64 %167
  %169 = load i16, i16* %168, align 2
  %170 = zext i16 %169 to i32
  %171 = add nuw nsw i32 %149, 2
  %172 = add nuw nsw i32 %171, %164
  %173 = add nuw nsw i32 %172, %170
  %174 = lshr i32 %173, 2
  %175 = shl nuw nsw i32 %170, 1
  %176 = mul nsw i32 %7, 6
  %177 = add nsw i32 %176, -1
  %178 = sext i32 %177 to i64
  %179 = getelementptr inbounds i16, i16* %5, i64 %178
  %180 = load i16, i16* %179, align 2
  %181 = zext i16 %180 to i32
  %182 = add nuw nsw i32 %159, 2
  %183 = add nuw nsw i32 %182, %175
  %184 = add nuw nsw i32 %183, %181
  %185 = lshr i32 %184, 2
  %186 = shl nuw nsw i32 %181, 1
  %187 = mul nsw i32 %7, 7
  %188 = add nsw i32 %187, -1
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds i16, i16* %5, i64 %189
  %191 = load i16, i16* %190, align 2
  %192 = zext i16 %191 to i32
  %193 = add nuw nsw i32 %170, 2
  %194 = add nuw nsw i32 %193, %186
  %195 = add nuw nsw i32 %194, %192
  %196 = lshr i32 %195, 2
  %197 = load i16, i16* %113, align 2
  %198 = zext i16 %197 to i32
  %199 = shl nuw nsw i32 %198, 1
  %200 = add nuw nsw i32 %44, %120
  %201 = add nuw nsw i32 %200, %199
  %202 = lshr i32 %201, 2
  %203 = shl nuw nsw i32 %174, 1
  %204 = add nuw nsw i32 %163, 2
  %205 = add nuw nsw i32 %204, %203
  %206 = add nuw nsw i32 %205, %185
  %207 = lshr i32 %206, 2
  %208 = trunc i32 %207 to i16
  %209 = sext i32 %176 to i64
  %210 = getelementptr inbounds i16, i16* %5, i64 %209
  store i16 %208, i16* %210, align 2
  %211 = shl nuw nsw i32 %185, 1
  %212 = add nuw nsw i32 %174, 2
  %213 = add nuw nsw i32 %212, %211
  %214 = add nuw nsw i32 %213, %196
  %215 = lshr i32 %214, 2
  %216 = trunc i32 %215 to i16
  %217 = sext i32 %187 to i64
  %218 = getelementptr inbounds i16, i16* %5, i64 %217
  store i16 %216, i16* %218, align 2
  %219 = shl nuw nsw i32 %152, 1
  %220 = add nuw nsw i32 %142, 2
  %221 = add nuw nsw i32 %220, %219
  %222 = add nuw nsw i32 %221, %163
  %223 = lshr i32 %222, 2
  %224 = trunc i32 %223 to i16
  %225 = or i32 %176, 1
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds i16, i16* %5, i64 %226
  store i16 %224, i16* %227, align 2
  %228 = ashr exact i64 %154, 32
  %229 = getelementptr inbounds i16, i16* %5, i64 %228
  store i16 %224, i16* %229, align 2
  %230 = shl nuw nsw i32 %163, 1
  %231 = add nuw nsw i32 %152, 2
  %232 = add nuw nsw i32 %231, %230
  %233 = add nuw nsw i32 %232, %174
  %234 = lshr i32 %233, 2
  %235 = trunc i32 %234 to i16
  %236 = add nsw i32 %187, 1
  %237 = sext i32 %236 to i64
  %238 = getelementptr inbounds i16, i16* %5, i64 %237
  store i16 %235, i16* %238, align 2
  %239 = sext i32 %165 to i64
  %240 = getelementptr inbounds i16, i16* %5, i64 %239
  store i16 %235, i16* %240, align 2
  %241 = shl nuw nsw i32 %130, 1
  %242 = add nuw nsw i32 %220, %241
  %243 = add nuw nsw i32 %242, %202
  %244 = lshr i32 %243, 2
  %245 = trunc i32 %244 to i16
  %246 = add nsw i32 %176, 2
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds i16, i16* %5, i64 %247
  store i16 %245, i16* %248, align 2
  %249 = or i64 %228, 1
  %250 = getelementptr inbounds i16, i16* %5, i64 %249
  store i16 %245, i16* %250, align 2
  %251 = sext i32 %133 to i64
  %252 = getelementptr inbounds i16, i16* %5, i64 %251
  store i16 %245, i16* %252, align 2
  %253 = shl nuw nsw i32 %142, 1
  %254 = add nuw nsw i32 %130, 2
  %255 = add nuw nsw i32 %254, %253
  %256 = add nuw nsw i32 %255, %152
  %257 = lshr i32 %256, 2
  %258 = trunc i32 %257 to i16
  %259 = add nsw i32 %187, 2
  %260 = sext i32 %259 to i64
  %261 = getelementptr inbounds i16, i16* %5, i64 %260
  store i16 %258, i16* %261, align 2
  %262 = add nsw i32 %165, 1
  %263 = sext i32 %262 to i64
  %264 = getelementptr inbounds i16, i16* %5, i64 %263
  store i16 %258, i16* %264, align 2
  %265 = sext i32 %144 to i64
  %266 = getelementptr inbounds i16, i16* %5, i64 %265
  store i16 %258, i16* %266, align 2
  %267 = shl nuw nsw i32 %202, 1
  %268 = add nuw nsw i32 %37, 2
  %269 = add nuw nsw i32 %268, %130
  %270 = add nuw nsw i32 %269, %267
  %271 = lshr i32 %270, 2
  %272 = trunc i32 %271 to i16
  %273 = add nsw i32 %187, 3
  %274 = sext i32 %273 to i64
  %275 = getelementptr inbounds i16, i16* %5, i64 %274
  store i16 %272, i16* %275, align 2
  %276 = add nsw i32 %165, 2
  %277 = sext i32 %276 to i64
  %278 = getelementptr inbounds i16, i16* %5, i64 %277
  store i16 %272, i16* %278, align 2
  %279 = add nsw i32 %144, 1
  %280 = sext i32 %279 to i64
  %281 = getelementptr inbounds i16, i16* %5, i64 %280
  store i16 %272, i16* %281, align 2
  %282 = getelementptr inbounds i16, i16* %5, i64 %111
  store i16 %272, i16* %282, align 2
  %283 = add nuw nsw i32 %37, 1
  %284 = add nuw nsw i32 %283, %202
  %285 = lshr i32 %284, 1
  %286 = trunc i32 %285 to i16
  %287 = add nsw i32 %176, 3
  %288 = sext i32 %287 to i64
  %289 = getelementptr inbounds i16, i16* %5, i64 %288
  store i16 %286, i16* %289, align 2
  %290 = or i64 %228, 2
  %291 = getelementptr inbounds i16, i16* %5, i64 %290
  store i16 %286, i16* %291, align 2
  %292 = shl i64 %3, 32
  %293 = ashr exact i64 %292, 32
  %294 = or i64 %293, 1
  %295 = getelementptr inbounds i16, i16* %5, i64 %294
  store i16 %286, i16* %295, align 2
  store i16 %286, i16* %5, align 2
  %296 = shl nuw nsw i32 %37, 1
  %297 = add nuw nsw i32 %47, 2
  %298 = add nuw nsw i32 %297, %296
  %299 = add nuw nsw i32 %298, %202
  %300 = lshr i32 %299, 2
  %301 = trunc i32 %300 to i16
  %302 = add nsw i32 %187, 4
  %303 = sext i32 %302 to i64
  %304 = getelementptr inbounds i16, i16* %5, i64 %303
  store i16 %301, i16* %304, align 2
  %305 = add nsw i32 %165, 3
  %306 = sext i32 %305 to i64
  %307 = getelementptr inbounds i16, i16* %5, i64 %306
  store i16 %301, i16* %307, align 2
  %308 = add nsw i32 %144, 2
  %309 = sext i32 %308 to i64
  %310 = getelementptr inbounds i16, i16* %5, i64 %309
  store i16 %301, i16* %310, align 2
  %311 = add i64 %19, 4294967296
  %312 = ashr exact i64 %311, 32
  %313 = getelementptr inbounds i16, i16* %5, i64 %312
  store i16 %301, i16* %313, align 2
  %314 = add nuw nsw i32 %283, %47
  %315 = lshr i32 %314, 1
  %316 = trunc i32 %315 to i16
  %317 = add nsw i32 %176, 4
  %318 = sext i32 %317 to i64
  %319 = getelementptr inbounds i16, i16* %5, i64 %318
  store i16 %316, i16* %319, align 2
  %320 = or i64 %228, 3
  %321 = getelementptr inbounds i16, i16* %5, i64 %320
  store i16 %316, i16* %321, align 2
  %322 = add nsw i32 %133, 2
  %323 = sext i32 %322 to i64
  %324 = getelementptr inbounds i16, i16* %5, i64 %323
  store i16 %316, i16* %324, align 2
  %325 = getelementptr inbounds i8, i8* %0, i64 2
  %326 = bitcast i8* %325 to i16*
  store i16 %316, i16* %326, align 2
  %327 = shl nuw nsw i32 %47, 1
  %328 = add nuw nsw i32 %268, %327
  %329 = add nuw nsw i32 %328, %56
  %330 = lshr i32 %329, 2
  %331 = trunc i32 %330 to i16
  %332 = add nsw i32 %187, 5
  %333 = sext i32 %332 to i64
  %334 = getelementptr inbounds i16, i16* %5, i64 %333
  store i16 %331, i16* %334, align 2
  %335 = add nsw i32 %165, 4
  %336 = sext i32 %335 to i64
  %337 = getelementptr inbounds i16, i16* %5, i64 %336
  store i16 %331, i16* %337, align 2
  %338 = add nsw i32 %144, 3
  %339 = sext i32 %338 to i64
  %340 = getelementptr inbounds i16, i16* %5, i64 %339
  store i16 %331, i16* %340, align 2
  %341 = add i64 %19, 8589934592
  %342 = ashr exact i64 %341, 32
  %343 = getelementptr inbounds i16, i16* %5, i64 %342
  store i16 %331, i16* %343, align 2
  %344 = add nuw nsw i32 %47, 1
  %345 = add nuw nsw i32 %344, %56
  %346 = lshr i32 %345, 1
  %347 = trunc i32 %346 to i16
  %348 = add nsw i32 %176, 5
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i16, i16* %5, i64 %349
  store i16 %347, i16* %350, align 2
  %351 = add i64 %154, 17179869184
  %352 = ashr exact i64 %351, 32
  %353 = getelementptr inbounds i16, i16* %5, i64 %352
  store i16 %347, i16* %353, align 2
  %354 = add nsw i32 %133, 3
  %355 = sext i32 %354 to i64
  %356 = getelementptr inbounds i16, i16* %5, i64 %355
  store i16 %347, i16* %356, align 2
  %357 = getelementptr inbounds i8, i8* %0, i64 4
  %358 = bitcast i8* %357 to i16*
  store i16 %347, i16* %358, align 2
  %359 = shl nuw nsw i32 %56, 1
  %360 = add nuw nsw i32 %297, %359
  %361 = add nuw nsw i32 %360, %66
  %362 = lshr i32 %361, 2
  %363 = trunc i32 %362 to i16
  %364 = add nsw i32 %187, 6
  %365 = sext i32 %364 to i64
  %366 = getelementptr inbounds i16, i16* %5, i64 %365
  store i16 %363, i16* %366, align 2
  %367 = add nsw i32 %165, 5
  %368 = sext i32 %367 to i64
  %369 = getelementptr inbounds i16, i16* %5, i64 %368
  store i16 %363, i16* %369, align 2
  %370 = add nsw i32 %144, 4
  %371 = sext i32 %370 to i64
  %372 = getelementptr inbounds i16, i16* %5, i64 %371
  store i16 %363, i16* %372, align 2
  %373 = add i64 %19, 12884901888
  %374 = ashr exact i64 %373, 32
  %375 = getelementptr inbounds i16, i16* %5, i64 %374
  store i16 %363, i16* %375, align 2
  %376 = add nuw nsw i32 %56, 1
  %377 = add nuw nsw i32 %376, %66
  %378 = lshr i32 %377, 1
  %379 = trunc i32 %378 to i16
  %380 = add nsw i32 %176, 6
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i16, i16* %5, i64 %381
  store i16 %379, i16* %382, align 2
  %383 = add i64 %154, 21474836480
  %384 = ashr exact i64 %383, 32
  %385 = getelementptr inbounds i16, i16* %5, i64 %384
  store i16 %379, i16* %385, align 2
  %386 = add nsw i32 %133, 4
  %387 = sext i32 %386 to i64
  %388 = getelementptr inbounds i16, i16* %5, i64 %387
  store i16 %379, i16* %388, align 2
  %389 = getelementptr inbounds i8, i8* %0, i64 6
  %390 = bitcast i8* %389 to i16*
  store i16 %379, i16* %390, align 2
  %391 = shl nuw nsw i32 %66, 1
  %392 = add nuw nsw i32 %56, 2
  %393 = add nuw nsw i32 %392, %391
  %394 = add nuw nsw i32 %393, %76
  %395 = lshr i32 %394, 2
  %396 = trunc i32 %395 to i16
  %397 = add nsw i32 %187, 7
  %398 = sext i32 %397 to i64
  %399 = getelementptr inbounds i16, i16* %5, i64 %398
  store i16 %396, i16* %399, align 2
  %400 = add nsw i32 %165, 6
  %401 = sext i32 %400 to i64
  %402 = getelementptr inbounds i16, i16* %5, i64 %401
  store i16 %396, i16* %402, align 2
  %403 = add nsw i32 %144, 5
  %404 = sext i32 %403 to i64
  %405 = getelementptr inbounds i16, i16* %5, i64 %404
  store i16 %396, i16* %405, align 2
  %406 = add i64 %19, 17179869184
  %407 = ashr exact i64 %406, 32
  %408 = getelementptr inbounds i16, i16* %5, i64 %407
  store i16 %396, i16* %408, align 2
  %409 = add nuw nsw i32 %66, 1
  %410 = add nuw nsw i32 %409, %76
  %411 = lshr i32 %410, 1
  %412 = trunc i32 %411 to i16
  %413 = add nsw i32 %176, 7
  %414 = sext i32 %413 to i64
  %415 = getelementptr inbounds i16, i16* %5, i64 %414
  store i16 %412, i16* %415, align 2
  %416 = add i64 %154, 25769803776
  %417 = ashr exact i64 %416, 32
  %418 = getelementptr inbounds i16, i16* %5, i64 %417
  store i16 %412, i16* %418, align 2
  %419 = add nsw i32 %133, 5
  %420 = sext i32 %419 to i64
  %421 = getelementptr inbounds i16, i16* %5, i64 %420
  store i16 %412, i16* %421, align 2
  %422 = getelementptr inbounds i8, i8* %0, i64 8
  %423 = bitcast i8* %422 to i16*
  store i16 %412, i16* %423, align 2
  %424 = shl nuw nsw i32 %76, 1
  %425 = add nuw nsw i32 %66, 2
  %426 = add nuw nsw i32 %425, %424
  %427 = add nuw nsw i32 %426, %86
  %428 = lshr i32 %427, 2
  %429 = trunc i32 %428 to i16
  %430 = add nsw i32 %165, 7
  %431 = sext i32 %430 to i64
  %432 = getelementptr inbounds i16, i16* %5, i64 %431
  store i16 %429, i16* %432, align 2
  %433 = add nsw i32 %144, 6
  %434 = sext i32 %433 to i64
  %435 = getelementptr inbounds i16, i16* %5, i64 %434
  store i16 %429, i16* %435, align 2
  %436 = add i64 %19, 21474836480
  %437 = ashr exact i64 %436, 32
  %438 = getelementptr inbounds i16, i16* %5, i64 %437
  store i16 %429, i16* %438, align 2
  %439 = add nuw nsw i32 %76, 1
  %440 = add nuw nsw i32 %439, %86
  %441 = lshr i32 %440, 1
  %442 = trunc i32 %441 to i16
  %443 = add i64 %154, 30064771072
  %444 = ashr exact i64 %443, 32
  %445 = getelementptr inbounds i16, i16* %5, i64 %444
  store i16 %442, i16* %445, align 2
  %446 = add nsw i32 %133, 6
  %447 = sext i32 %446 to i64
  %448 = getelementptr inbounds i16, i16* %5, i64 %447
  store i16 %442, i16* %448, align 2
  %449 = getelementptr inbounds i8, i8* %0, i64 10
  %450 = bitcast i8* %449 to i16*
  store i16 %442, i16* %450, align 2
  %451 = shl nuw nsw i32 %86, 1
  %452 = add nuw nsw i32 %76, 2
  %453 = add nuw nsw i32 %452, %451
  %454 = add nuw nsw i32 %453, %96
  %455 = lshr i32 %454, 2
  %456 = trunc i32 %455 to i16
  %457 = add nsw i32 %144, 7
  %458 = sext i32 %457 to i64
  %459 = getelementptr inbounds i16, i16* %5, i64 %458
  store i16 %456, i16* %459, align 2
  %460 = add i64 %19, 25769803776
  %461 = ashr exact i64 %460, 32
  %462 = getelementptr inbounds i16, i16* %5, i64 %461
  store i16 %456, i16* %462, align 2
  %463 = add nuw nsw i32 %86, 1
  %464 = add nuw nsw i32 %463, %96
  %465 = lshr i32 %464, 1
  %466 = trunc i32 %465 to i16
  %467 = add nsw i32 %133, 7
  %468 = sext i32 %467 to i64
  %469 = getelementptr inbounds i16, i16* %5, i64 %468
  store i16 %466, i16* %469, align 2
  %470 = getelementptr inbounds i8, i8* %0, i64 12
  %471 = bitcast i8* %470 to i16*
  store i16 %466, i16* %471, align 2
  %472 = shl nuw nsw i32 %96, 1
  %473 = add nuw nsw i32 %86, 2
  %474 = add nuw nsw i32 %473, %472
  %475 = add nuw nsw i32 %474, %110
  %476 = lshr i32 %475, 2
  %477 = trunc i32 %476 to i16
  %478 = add i64 %19, 30064771072
  %479 = ashr exact i64 %478, 32
  %480 = getelementptr inbounds i16, i16* %5, i64 %479
  store i16 %477, i16* %480, align 2
  %481 = add nuw nsw i32 %96, 1
  %482 = add nuw nsw i32 %481, %110
  %483 = lshr i32 %482, 1
  %484 = trunc i32 %483 to i16
  %485 = getelementptr inbounds i8, i8* %0, i64 14
  %486 = bitcast i8* %485 to i16*
  store i16 %484, i16* %486, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_down_12_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp ne i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %10, label %15

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %20

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  %18 = ashr exact i64 %17, 32
  %19 = xor i64 %18, -1
  br label %20

20:                                               ; preds = %15, %10
  %21 = phi i64 [ %19, %15 ], [ %13, %10 ]
  %22 = phi i64 [ %18, %15 ], [ %12, %10 ]
  %23 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %24 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %25 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %26 = getelementptr inbounds i16, i16* %5, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = getelementptr inbounds i16, i16* %5, i64 %24
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i32
  %32 = shl nuw nsw i32 %31, 1
  %33 = sub i64 4294967296, %23
  %34 = ashr exact i64 %33, 32
  %35 = getelementptr inbounds i16, i16* %5, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i32
  %38 = add nuw nsw i32 %37, 2
  %39 = add nuw nsw i32 %38, %28
  %40 = add nuw nsw i32 %39, %32
  %41 = lshr i32 %40, 2
  %42 = shl nuw nsw i32 %37, 1
  %43 = sub i64 8589934592, %23
  %44 = ashr exact i64 %43, 32
  %45 = getelementptr inbounds i16, i16* %5, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i32
  %48 = add nuw nsw i32 %31, 2
  %49 = add nuw nsw i32 %48, %42
  %50 = add nuw nsw i32 %49, %47
  %51 = lshr i32 %50, 2
  %52 = shl nuw nsw i32 %47, 1
  %53 = sub i64 12884901888, %23
  %54 = ashr exact i64 %53, 32
  %55 = getelementptr inbounds i16, i16* %5, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i32
  %58 = add nuw nsw i32 %38, %52
  %59 = add nuw nsw i32 %58, %57
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %57, 1
  %62 = sub i64 17179869184, %23
  %63 = ashr exact i64 %62, 32
  %64 = getelementptr inbounds i16, i16* %5, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i32
  %67 = add nuw nsw i32 %47, 2
  %68 = add nuw nsw i32 %67, %61
  %69 = add nuw nsw i32 %68, %66
  %70 = lshr i32 %69, 2
  %71 = shl nuw nsw i32 %66, 1
  %72 = sub i64 21474836480, %23
  %73 = ashr exact i64 %72, 32
  %74 = getelementptr inbounds i16, i16* %5, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i32
  %77 = add nuw nsw i32 %57, 2
  %78 = add nuw nsw i32 %77, %71
  %79 = add nuw nsw i32 %78, %76
  %80 = lshr i32 %79, 2
  %81 = shl nuw nsw i32 %76, 1
  %82 = sub i64 25769803776, %23
  %83 = ashr exact i64 %82, 32
  %84 = getelementptr inbounds i16, i16* %5, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i32
  %87 = add nuw nsw i32 %66, 2
  %88 = add nuw nsw i32 %87, %81
  %89 = add nuw nsw i32 %88, %86
  %90 = lshr i32 %89, 2
  %91 = shl nuw nsw i32 %86, 1
  %92 = sub i64 30064771072, %23
  %93 = ashr exact i64 %92, 32
  %94 = getelementptr inbounds i16, i16* %5, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i32
  %97 = add nuw nsw i32 %76, 2
  %98 = add nuw nsw i32 %97, %91
  %99 = add nuw nsw i32 %98, %96
  %100 = lshr i32 %99, 2
  %101 = getelementptr inbounds i16, i16* %5, i64 %21
  %102 = getelementptr inbounds i8, i8* %0, i64 -2
  %103 = bitcast i8* %102 to i16*
  %104 = select i1 %8, i16* %101, i16* %103
  %105 = load i16, i16* %104, align 2
  %106 = zext i16 %105 to i32
  %107 = load i16, i16* %103, align 2
  %108 = zext i16 %107 to i32
  %109 = shl nuw nsw i32 %108, 1
  %110 = add i64 %23, -4294967296
  %111 = ashr exact i64 %110, 32
  %112 = getelementptr inbounds i16, i16* %5, i64 %111
  %113 = load i16, i16* %112, align 2
  %114 = zext i16 %113 to i32
  %115 = add nuw nsw i32 %114, 2
  %116 = add nuw nsw i32 %115, %106
  %117 = add nuw nsw i32 %116, %109
  %118 = lshr i32 %117, 2
  %119 = shl nuw nsw i32 %114, 1
  %120 = trunc i64 %3 to i32
  %121 = and i32 %120, -2
  %122 = add nsw i32 %121, -1
  %123 = sext i32 %122 to i64
  %124 = getelementptr inbounds i16, i16* %5, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %108, 2
  %128 = add nuw nsw i32 %127, %119
  %129 = add nuw nsw i32 %128, %126
  %130 = lshr i32 %129, 2
  %131 = shl nuw nsw i32 %126, 1
  %132 = mul nsw i32 %7, 3
  %133 = add nsw i32 %132, -1
  %134 = sext i32 %133 to i64
  %135 = getelementptr inbounds i16, i16* %5, i64 %134
  %136 = load i16, i16* %135, align 2
  %137 = zext i16 %136 to i32
  %138 = add nuw nsw i32 %115, %131
  %139 = add nuw nsw i32 %138, %137
  %140 = lshr i32 %139, 2
  %141 = shl nuw nsw i32 %137, 1
  %142 = shl i64 %6, 34
  %143 = add i64 %142, -4294967296
  %144 = ashr exact i64 %143, 32
  %145 = getelementptr inbounds i16, i16* %5, i64 %144
  %146 = load i16, i16* %145, align 2
  %147 = zext i16 %146 to i32
  %148 = add nuw nsw i32 %126, 2
  %149 = add nuw nsw i32 %148, %141
  %150 = add nuw nsw i32 %149, %147
  %151 = lshr i32 %150, 2
  %152 = shl nuw nsw i32 %147, 1
  %153 = mul nsw i32 %7, 5
  %154 = add nsw i32 %153, -1
  %155 = sext i32 %154 to i64
  %156 = getelementptr inbounds i16, i16* %5, i64 %155
  %157 = load i16, i16* %156, align 2
  %158 = zext i16 %157 to i32
  %159 = add nuw nsw i32 %137, 2
  %160 = add nuw nsw i32 %159, %152
  %161 = add nuw nsw i32 %160, %158
  %162 = lshr i32 %161, 2
  %163 = shl nuw nsw i32 %158, 1
  %164 = mul nsw i32 %7, 6
  %165 = add nsw i32 %164, -1
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds i16, i16* %5, i64 %166
  %168 = load i16, i16* %167, align 2
  %169 = zext i16 %168 to i32
  %170 = add nuw nsw i32 %147, 2
  %171 = add nuw nsw i32 %170, %163
  %172 = add nuw nsw i32 %171, %169
  %173 = lshr i32 %172, 2
  %174 = shl nuw nsw i32 %169, 1
  %175 = mul nsw i32 %7, 7
  %176 = add nsw i32 %175, -1
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds i16, i16* %5, i64 %177
  %179 = load i16, i16* %178, align 2
  %180 = zext i16 %179 to i32
  %181 = add nuw nsw i32 %158, 2
  %182 = add nuw nsw i32 %181, %174
  %183 = add nuw nsw i32 %182, %180
  %184 = lshr i32 %183, 2
  %185 = mul nuw nsw i32 %180, 3
  %186 = add nuw nsw i32 %169, 2
  %187 = add nuw nsw i32 %186, %185
  %188 = lshr i32 %187, 2
  %189 = load i16, i16* %101, align 2
  %190 = zext i16 %189 to i32
  %191 = shl nuw nsw i32 %190, 1
  %192 = add nuw nsw i32 %48, %108
  %193 = add nuw nsw i32 %192, %191
  %194 = lshr i32 %193, 2
  %195 = add nuw nsw i32 %184, 1
  %196 = add nuw nsw i32 %195, %188
  %197 = lshr i32 %196, 1
  %198 = trunc i32 %197 to i16
  %199 = sext i32 %175 to i64
  %200 = getelementptr inbounds i16, i16* %5, i64 %199
  store i16 %198, i16* %200, align 2
  %201 = shl nuw nsw i32 %184, 1
  %202 = add nuw nsw i32 %173, 2
  %203 = add nuw nsw i32 %202, %188
  %204 = add nuw nsw i32 %203, %201
  %205 = lshr i32 %204, 2
  %206 = trunc i32 %205 to i16
  %207 = add nsw i32 %175, 1
  %208 = sext i32 %207 to i64
  %209 = getelementptr inbounds i16, i16* %5, i64 %208
  store i16 %206, i16* %209, align 2
  %210 = add nuw nsw i32 %173, 1
  %211 = add nuw nsw i32 %210, %184
  %212 = lshr i32 %211, 1
  %213 = trunc i32 %212 to i16
  %214 = add nsw i32 %175, 2
  %215 = sext i32 %214 to i64
  %216 = getelementptr inbounds i16, i16* %5, i64 %215
  store i16 %213, i16* %216, align 2
  %217 = sext i32 %164 to i64
  %218 = getelementptr inbounds i16, i16* %5, i64 %217
  store i16 %213, i16* %218, align 2
  %219 = shl nuw nsw i32 %173, 1
  %220 = add nuw nsw i32 %162, 2
  %221 = add nuw nsw i32 %220, %219
  %222 = add nuw nsw i32 %221, %184
  %223 = lshr i32 %222, 2
  %224 = trunc i32 %223 to i16
  %225 = add nsw i32 %175, 3
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds i16, i16* %5, i64 %226
  store i16 %224, i16* %227, align 2
  %228 = or i32 %164, 1
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds i16, i16* %5, i64 %229
  store i16 %224, i16* %230, align 2
  %231 = add nuw nsw i32 %162, 1
  %232 = add nuw nsw i32 %231, %173
  %233 = lshr i32 %232, 1
  %234 = trunc i32 %233 to i16
  %235 = add nsw i32 %175, 4
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds i16, i16* %5, i64 %236
  store i16 %234, i16* %237, align 2
  %238 = add nsw i32 %164, 2
  %239 = sext i32 %238 to i64
  %240 = getelementptr inbounds i16, i16* %5, i64 %239
  store i16 %234, i16* %240, align 2
  %241 = sext i32 %153 to i64
  %242 = getelementptr inbounds i16, i16* %5, i64 %241
  store i16 %234, i16* %242, align 2
  %243 = shl nuw nsw i32 %162, 1
  %244 = add nuw nsw i32 %151, 2
  %245 = add nuw nsw i32 %244, %243
  %246 = add nuw nsw i32 %245, %173
  %247 = lshr i32 %246, 2
  %248 = trunc i32 %247 to i16
  %249 = add nsw i32 %175, 5
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds i16, i16* %5, i64 %250
  store i16 %248, i16* %251, align 2
  %252 = add nsw i32 %164, 3
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i16, i16* %5, i64 %253
  store i16 %248, i16* %254, align 2
  %255 = add nsw i32 %153, 1
  %256 = sext i32 %255 to i64
  %257 = getelementptr inbounds i16, i16* %5, i64 %256
  store i16 %248, i16* %257, align 2
  %258 = add nuw nsw i32 %151, 1
  %259 = add nuw nsw i32 %258, %162
  %260 = lshr i32 %259, 1
  %261 = trunc i32 %260 to i16
  %262 = add nsw i32 %175, 6
  %263 = sext i32 %262 to i64
  %264 = getelementptr inbounds i16, i16* %5, i64 %263
  store i16 %261, i16* %264, align 2
  %265 = add nsw i32 %164, 4
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds i16, i16* %5, i64 %266
  store i16 %261, i16* %267, align 2
  %268 = add nsw i32 %153, 2
  %269 = sext i32 %268 to i64
  %270 = getelementptr inbounds i16, i16* %5, i64 %269
  store i16 %261, i16* %270, align 2
  %271 = ashr exact i64 %142, 32
  %272 = getelementptr inbounds i16, i16* %5, i64 %271
  store i16 %261, i16* %272, align 2
  %273 = shl nuw nsw i32 %151, 1
  %274 = add nuw nsw i32 %140, 2
  %275 = add nuw nsw i32 %274, %273
  %276 = add nuw nsw i32 %275, %162
  %277 = lshr i32 %276, 2
  %278 = trunc i32 %277 to i16
  %279 = add nsw i32 %175, 7
  %280 = sext i32 %279 to i64
  %281 = getelementptr inbounds i16, i16* %5, i64 %280
  store i16 %278, i16* %281, align 2
  %282 = add nsw i32 %164, 5
  %283 = sext i32 %282 to i64
  %284 = getelementptr inbounds i16, i16* %5, i64 %283
  store i16 %278, i16* %284, align 2
  %285 = add nsw i32 %153, 3
  %286 = sext i32 %285 to i64
  %287 = getelementptr inbounds i16, i16* %5, i64 %286
  store i16 %278, i16* %287, align 2
  %288 = or i64 %271, 1
  %289 = getelementptr inbounds i16, i16* %5, i64 %288
  store i16 %278, i16* %289, align 2
  %290 = add nuw nsw i32 %140, 1
  %291 = add nuw nsw i32 %290, %151
  %292 = lshr i32 %291, 1
  %293 = trunc i32 %292 to i16
  %294 = add nsw i32 %164, 6
  %295 = sext i32 %294 to i64
  %296 = getelementptr inbounds i16, i16* %5, i64 %295
  store i16 %293, i16* %296, align 2
  %297 = add nsw i32 %153, 4
  %298 = sext i32 %297 to i64
  %299 = getelementptr inbounds i16, i16* %5, i64 %298
  store i16 %293, i16* %299, align 2
  %300 = or i64 %271, 2
  %301 = getelementptr inbounds i16, i16* %5, i64 %300
  store i16 %293, i16* %301, align 2
  %302 = sext i32 %132 to i64
  %303 = getelementptr inbounds i16, i16* %5, i64 %302
  store i16 %293, i16* %303, align 2
  %304 = shl nuw nsw i32 %140, 1
  %305 = add nuw nsw i32 %130, 2
  %306 = add nuw nsw i32 %305, %304
  %307 = add nuw nsw i32 %306, %151
  %308 = lshr i32 %307, 2
  %309 = trunc i32 %308 to i16
  %310 = add nsw i32 %164, 7
  %311 = sext i32 %310 to i64
  %312 = getelementptr inbounds i16, i16* %5, i64 %311
  store i16 %309, i16* %312, align 2
  %313 = add nsw i32 %153, 5
  %314 = sext i32 %313 to i64
  %315 = getelementptr inbounds i16, i16* %5, i64 %314
  store i16 %309, i16* %315, align 2
  %316 = or i64 %271, 3
  %317 = getelementptr inbounds i16, i16* %5, i64 %316
  store i16 %309, i16* %317, align 2
  %318 = add nsw i32 %132, 1
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %309, i16* %320, align 2
  %321 = add nuw nsw i32 %130, 1
  %322 = add nuw nsw i32 %321, %140
  %323 = lshr i32 %322, 1
  %324 = trunc i32 %323 to i16
  %325 = add nsw i32 %153, 6
  %326 = sext i32 %325 to i64
  %327 = getelementptr inbounds i16, i16* %5, i64 %326
  store i16 %324, i16* %327, align 2
  %328 = add i64 %142, 17179869184
  %329 = ashr exact i64 %328, 32
  %330 = getelementptr inbounds i16, i16* %5, i64 %329
  store i16 %324, i16* %330, align 2
  %331 = add nsw i32 %132, 2
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds i16, i16* %5, i64 %332
  store i16 %324, i16* %333, align 2
  %334 = sext i32 %121 to i64
  %335 = getelementptr inbounds i16, i16* %5, i64 %334
  store i16 %324, i16* %335, align 2
  %336 = shl nuw nsw i32 %130, 1
  %337 = add nuw nsw i32 %118, 2
  %338 = add nuw nsw i32 %337, %336
  %339 = add nuw nsw i32 %338, %140
  %340 = lshr i32 %339, 2
  %341 = trunc i32 %340 to i16
  %342 = add nsw i32 %153, 7
  %343 = sext i32 %342 to i64
  %344 = getelementptr inbounds i16, i16* %5, i64 %343
  store i16 %341, i16* %344, align 2
  %345 = add i64 %142, 21474836480
  %346 = ashr exact i64 %345, 32
  %347 = getelementptr inbounds i16, i16* %5, i64 %346
  store i16 %341, i16* %347, align 2
  %348 = add nsw i32 %132, 3
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i16, i16* %5, i64 %349
  store i16 %341, i16* %350, align 2
  %351 = shl i64 %3, 32
  %352 = ashr exact i64 %351, 32
  %353 = or i64 %352, 1
  %354 = getelementptr inbounds i16, i16* %5, i64 %353
  store i16 %341, i16* %354, align 2
  %355 = add nuw nsw i32 %118, 1
  %356 = add nuw nsw i32 %355, %130
  %357 = lshr i32 %356, 1
  %358 = trunc i32 %357 to i16
  %359 = add i64 %142, 25769803776
  %360 = ashr exact i64 %359, 32
  %361 = getelementptr inbounds i16, i16* %5, i64 %360
  store i16 %358, i16* %361, align 2
  %362 = add nsw i32 %132, 4
  %363 = sext i32 %362 to i64
  %364 = getelementptr inbounds i16, i16* %5, i64 %363
  store i16 %358, i16* %364, align 2
  %365 = add nsw i32 %121, 2
  %366 = sext i32 %365 to i64
  %367 = getelementptr inbounds i16, i16* %5, i64 %366
  store i16 %358, i16* %367, align 2
  %368 = getelementptr inbounds i16, i16* %5, i64 %22
  store i16 %358, i16* %368, align 2
  %369 = shl nuw nsw i32 %118, 1
  %370 = add nuw nsw i32 %305, %369
  %371 = add nuw nsw i32 %370, %194
  %372 = lshr i32 %371, 2
  %373 = trunc i32 %372 to i16
  %374 = add i64 %142, 30064771072
  %375 = ashr exact i64 %374, 32
  %376 = getelementptr inbounds i16, i16* %5, i64 %375
  store i16 %373, i16* %376, align 2
  %377 = add nsw i32 %132, 5
  %378 = sext i32 %377 to i64
  %379 = getelementptr inbounds i16, i16* %5, i64 %378
  store i16 %373, i16* %379, align 2
  %380 = add nsw i32 %121, 3
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i16, i16* %5, i64 %381
  store i16 %373, i16* %382, align 2
  %383 = add i64 %23, 4294967296
  %384 = ashr exact i64 %383, 32
  %385 = getelementptr inbounds i16, i16* %5, i64 %384
  store i16 %373, i16* %385, align 2
  %386 = add nuw nsw i32 %355, %194
  %387 = lshr i32 %386, 1
  %388 = trunc i32 %387 to i16
  %389 = add nsw i32 %132, 6
  %390 = sext i32 %389 to i64
  %391 = getelementptr inbounds i16, i16* %5, i64 %390
  store i16 %388, i16* %391, align 2
  %392 = add nsw i32 %121, 4
  %393 = sext i32 %392 to i64
  %394 = getelementptr inbounds i16, i16* %5, i64 %393
  store i16 %388, i16* %394, align 2
  %395 = add i64 %23, 8589934592
  %396 = ashr exact i64 %395, 32
  %397 = getelementptr inbounds i16, i16* %5, i64 %396
  store i16 %388, i16* %397, align 2
  store i16 %388, i16* %5, align 2
  %398 = shl nuw nsw i32 %194, 1
  %399 = add nuw nsw i32 %41, 2
  %400 = add nuw nsw i32 %399, %118
  %401 = add nuw nsw i32 %400, %398
  %402 = lshr i32 %401, 2
  %403 = trunc i32 %402 to i16
  %404 = add nsw i32 %132, 7
  %405 = sext i32 %404 to i64
  %406 = getelementptr inbounds i16, i16* %5, i64 %405
  store i16 %403, i16* %406, align 2
  %407 = add nsw i32 %121, 5
  %408 = sext i32 %407 to i64
  %409 = getelementptr inbounds i16, i16* %5, i64 %408
  store i16 %403, i16* %409, align 2
  %410 = add i64 %23, 12884901888
  %411 = ashr exact i64 %410, 32
  %412 = getelementptr inbounds i16, i16* %5, i64 %411
  store i16 %403, i16* %412, align 2
  %413 = getelementptr inbounds i8, i8* %0, i64 2
  %414 = bitcast i8* %413 to i16*
  store i16 %403, i16* %414, align 2
  %415 = shl nuw nsw i32 %41, 1
  %416 = add nuw nsw i32 %51, 2
  %417 = add nuw nsw i32 %416, %415
  %418 = add nuw nsw i32 %417, %194
  %419 = lshr i32 %418, 2
  %420 = trunc i32 %419 to i16
  %421 = add nsw i32 %121, 6
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds i16, i16* %5, i64 %422
  store i16 %420, i16* %423, align 2
  %424 = add i64 %23, 17179869184
  %425 = ashr exact i64 %424, 32
  %426 = getelementptr inbounds i16, i16* %5, i64 %425
  store i16 %420, i16* %426, align 2
  %427 = getelementptr inbounds i8, i8* %0, i64 4
  %428 = bitcast i8* %427 to i16*
  store i16 %420, i16* %428, align 2
  %429 = shl nuw nsw i32 %51, 1
  %430 = add nuw nsw i32 %399, %429
  %431 = add nuw nsw i32 %430, %60
  %432 = lshr i32 %431, 2
  %433 = trunc i32 %432 to i16
  %434 = add nsw i32 %121, 7
  %435 = sext i32 %434 to i64
  %436 = getelementptr inbounds i16, i16* %5, i64 %435
  store i16 %433, i16* %436, align 2
  %437 = add i64 %23, 21474836480
  %438 = ashr exact i64 %437, 32
  %439 = getelementptr inbounds i16, i16* %5, i64 %438
  store i16 %433, i16* %439, align 2
  %440 = getelementptr inbounds i8, i8* %0, i64 6
  %441 = bitcast i8* %440 to i16*
  store i16 %433, i16* %441, align 2
  %442 = shl nuw nsw i32 %60, 1
  %443 = add nuw nsw i32 %416, %442
  %444 = add nuw nsw i32 %443, %70
  %445 = lshr i32 %444, 2
  %446 = trunc i32 %445 to i16
  %447 = add i64 %23, 25769803776
  %448 = ashr exact i64 %447, 32
  %449 = getelementptr inbounds i16, i16* %5, i64 %448
  store i16 %446, i16* %449, align 2
  %450 = getelementptr inbounds i8, i8* %0, i64 8
  %451 = bitcast i8* %450 to i16*
  store i16 %446, i16* %451, align 2
  %452 = shl nuw nsw i32 %70, 1
  %453 = add nuw nsw i32 %60, 2
  %454 = add nuw nsw i32 %453, %452
  %455 = add nuw nsw i32 %454, %80
  %456 = lshr i32 %455, 2
  %457 = trunc i32 %456 to i16
  %458 = add i64 %23, 30064771072
  %459 = ashr exact i64 %458, 32
  %460 = getelementptr inbounds i16, i16* %5, i64 %459
  store i16 %457, i16* %460, align 2
  %461 = getelementptr inbounds i8, i8* %0, i64 10
  %462 = bitcast i8* %461 to i16*
  store i16 %457, i16* %462, align 2
  %463 = shl nuw nsw i32 %80, 1
  %464 = add nuw nsw i32 %70, 2
  %465 = add nuw nsw i32 %464, %463
  %466 = add nuw nsw i32 %465, %90
  %467 = lshr i32 %466, 2
  %468 = trunc i32 %467 to i16
  %469 = getelementptr inbounds i8, i8* %0, i64 12
  %470 = bitcast i8* %469 to i16*
  store i16 %468, i16* %470, align 2
  %471 = shl nuw nsw i32 %90, 1
  %472 = add nuw nsw i32 %80, 2
  %473 = add nuw nsw i32 %472, %471
  %474 = add nuw nsw i32 %473, %100
  %475 = lshr i32 %474, 2
  %476 = trunc i32 %475 to i16
  %477 = getelementptr inbounds i8, i8* %0, i64 14
  %478 = bitcast i8* %477 to i16*
  store i16 %476, i16* %478, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_left_12_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %97, label %99

97:                                               ; preds = %18
  %98 = mul nuw nsw i32 %91, 3
  br label %156

99:                                               ; preds = %18
  %100 = sub i64 34359738368, %19
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %5, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i32
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %105, %104
  %107 = shl nuw nsw i32 %104, 1
  %108 = sub i64 38654705664, %19
  %109 = ashr exact i64 %108, 32
  %110 = getelementptr inbounds i16, i16* %5, i64 %109
  %111 = load i16, i16* %110, align 2
  %112 = zext i16 %111 to i32
  %113 = add nuw nsw i32 %91, 2
  %114 = add nuw nsw i32 %113, %107
  %115 = add nuw nsw i32 %114, %112
  %116 = lshr i32 %115, 2
  %117 = shl nuw nsw i32 %112, 1
  %118 = sub i64 42949672960, %19
  %119 = ashr exact i64 %118, 32
  %120 = getelementptr inbounds i16, i16* %5, i64 %119
  %121 = load i16, i16* %120, align 2
  %122 = zext i16 %121 to i32
  %123 = add nuw nsw i32 %122, 2
  %124 = add nuw nsw i32 %123, %104
  %125 = add nuw nsw i32 %124, %117
  %126 = lshr i32 %125, 2
  %127 = shl nuw nsw i32 %122, 1
  %128 = sub i64 47244640256, %19
  %129 = ashr exact i64 %128, 32
  %130 = getelementptr inbounds i16, i16* %5, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i32
  %133 = add nuw nsw i32 %112, 2
  %134 = add nuw nsw i32 %133, %127
  %135 = add nuw nsw i32 %134, %132
  %136 = lshr i32 %135, 2
  %137 = shl nuw nsw i32 %132, 1
  %138 = sub i64 51539607552, %19
  %139 = ashr exact i64 %138, 32
  %140 = getelementptr inbounds i16, i16* %5, i64 %139
  %141 = load i16, i16* %140, align 2
  %142 = zext i16 %141 to i32
  %143 = add nuw nsw i32 %123, %137
  %144 = add nuw nsw i32 %143, %142
  %145 = lshr i32 %144, 2
  %146 = shl nuw nsw i32 %142, 1
  %147 = sub i64 55834574848, %19
  %148 = ashr exact i64 %147, 32
  %149 = getelementptr inbounds i16, i16* %5, i64 %148
  %150 = load i16, i16* %149, align 2
  %151 = zext i16 %150 to i32
  %152 = add nuw nsw i32 %132, 2
  %153 = add nuw nsw i32 %152, %146
  %154 = add nuw nsw i32 %153, %151
  %155 = lshr i32 %154, 2
  br label %156

156:                                              ; preds = %97, %99
  %157 = phi i32 [ %106, %99 ], [ %98, %97 ]
  %158 = phi i32 [ %116, %99 ], [ %91, %97 ]
  %159 = phi i32 [ %126, %99 ], [ %91, %97 ]
  %160 = phi i32 [ %136, %99 ], [ %91, %97 ]
  %161 = phi i32 [ %145, %99 ], [ %91, %97 ]
  %162 = phi i32 [ %155, %99 ], [ %91, %97 ]
  %163 = add nuw nsw i32 %81, 2
  %164 = add nuw nsw i32 %163, %157
  %165 = lshr i32 %164, 2
  %166 = add nuw nsw i32 %47, 1
  %167 = add nuw nsw i32 %166, %37
  %168 = lshr i32 %167, 1
  %169 = trunc i32 %168 to i16
  store i16 %169, i16* %5, align 2
  %170 = shl nuw nsw i32 %47, 1
  %171 = add nuw nsw i32 %56, 2
  %172 = add nuw nsw i32 %171, %37
  %173 = add nuw nsw i32 %172, %170
  %174 = lshr i32 %173, 2
  %175 = trunc i32 %174 to i16
  %176 = ashr exact i64 %19, 32
  %177 = getelementptr inbounds i16, i16* %5, i64 %176
  store i16 %175, i16* %177, align 2
  %178 = add nuw nsw i32 %166, %56
  %179 = lshr i32 %178, 1
  %180 = trunc i32 %179 to i16
  %181 = getelementptr inbounds i8, i8* %0, i64 2
  %182 = bitcast i8* %181 to i16*
  store i16 %180, i16* %182, align 2
  %183 = trunc i64 %3 to i32
  %184 = and i32 %183, -2
  %185 = sext i32 %184 to i64
  %186 = getelementptr inbounds i16, i16* %5, i64 %185
  store i16 %180, i16* %186, align 2
  %187 = shl nuw nsw i32 %56, 1
  %188 = add nuw nsw i32 %65, 2
  %189 = add nuw nsw i32 %188, %47
  %190 = add nuw nsw i32 %189, %187
  %191 = lshr i32 %190, 2
  %192 = trunc i32 %191 to i16
  %193 = add i64 %19, 4294967296
  %194 = ashr exact i64 %193, 32
  %195 = getelementptr inbounds i16, i16* %5, i64 %194
  store i16 %192, i16* %195, align 2
  %196 = mul nsw i32 %7, 3
  %197 = sext i32 %196 to i64
  %198 = getelementptr inbounds i16, i16* %5, i64 %197
  store i16 %192, i16* %198, align 2
  %199 = add nuw nsw i32 %56, 1
  %200 = add nuw nsw i32 %199, %65
  %201 = lshr i32 %200, 1
  %202 = trunc i32 %201 to i16
  %203 = getelementptr inbounds i8, i8* %0, i64 4
  %204 = bitcast i8* %203 to i16*
  store i16 %202, i16* %204, align 2
  %205 = shl i64 %3, 32
  %206 = ashr exact i64 %205, 32
  %207 = or i64 %206, 1
  %208 = getelementptr inbounds i16, i16* %5, i64 %207
  store i16 %202, i16* %208, align 2
  %209 = shl i64 %6, 34
  %210 = ashr exact i64 %209, 32
  %211 = getelementptr inbounds i16, i16* %5, i64 %210
  store i16 %202, i16* %211, align 2
  %212 = shl nuw nsw i32 %65, 1
  %213 = add nuw nsw i32 %171, %212
  %214 = add nuw nsw i32 %213, %75
  %215 = lshr i32 %214, 2
  %216 = trunc i32 %215 to i16
  %217 = add i64 %19, 8589934592
  %218 = ashr exact i64 %217, 32
  %219 = getelementptr inbounds i16, i16* %5, i64 %218
  store i16 %216, i16* %219, align 2
  %220 = add nsw i32 %196, 1
  %221 = sext i32 %220 to i64
  %222 = getelementptr inbounds i16, i16* %5, i64 %221
  store i16 %216, i16* %222, align 2
  %223 = mul nsw i32 %7, 5
  %224 = sext i32 %223 to i64
  %225 = getelementptr inbounds i16, i16* %5, i64 %224
  store i16 %216, i16* %225, align 2
  %226 = add nuw nsw i32 %65, 1
  %227 = add nuw nsw i32 %226, %75
  %228 = lshr i32 %227, 1
  %229 = trunc i32 %228 to i16
  %230 = getelementptr inbounds i8, i8* %0, i64 6
  %231 = bitcast i8* %230 to i16*
  store i16 %229, i16* %231, align 2
  %232 = add nsw i32 %184, 2
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds i16, i16* %5, i64 %233
  store i16 %229, i16* %234, align 2
  %235 = or i64 %210, 1
  %236 = getelementptr inbounds i16, i16* %5, i64 %235
  store i16 %229, i16* %236, align 2
  %237 = mul nsw i32 %7, 6
  %238 = sext i32 %237 to i64
  %239 = getelementptr inbounds i16, i16* %5, i64 %238
  store i16 %229, i16* %239, align 2
  %240 = shl nuw nsw i32 %75, 1
  %241 = add nuw nsw i32 %188, %240
  %242 = add nuw nsw i32 %241, %85
  %243 = lshr i32 %242, 2
  %244 = trunc i32 %243 to i16
  %245 = add i64 %19, 12884901888
  %246 = ashr exact i64 %245, 32
  %247 = getelementptr inbounds i16, i16* %5, i64 %246
  store i16 %244, i16* %247, align 2
  %248 = add nsw i32 %196, 2
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i16, i16* %5, i64 %249
  store i16 %244, i16* %250, align 2
  %251 = add nsw i32 %223, 1
  %252 = sext i32 %251 to i64
  %253 = getelementptr inbounds i16, i16* %5, i64 %252
  store i16 %244, i16* %253, align 2
  %254 = mul nsw i32 %7, 7
  %255 = sext i32 %254 to i64
  %256 = getelementptr inbounds i16, i16* %5, i64 %255
  store i16 %244, i16* %256, align 2
  %257 = add nuw nsw i32 %75, 1
  %258 = add nuw nsw i32 %257, %85
  %259 = lshr i32 %258, 1
  %260 = trunc i32 %259 to i16
  %261 = getelementptr inbounds i8, i8* %0, i64 8
  %262 = bitcast i8* %261 to i16*
  store i16 %260, i16* %262, align 2
  %263 = add nsw i32 %184, 3
  %264 = sext i32 %263 to i64
  %265 = getelementptr inbounds i16, i16* %5, i64 %264
  store i16 %260, i16* %265, align 2
  %266 = or i64 %210, 2
  %267 = getelementptr inbounds i16, i16* %5, i64 %266
  store i16 %260, i16* %267, align 2
  %268 = or i32 %237, 1
  %269 = sext i32 %268 to i64
  %270 = getelementptr inbounds i16, i16* %5, i64 %269
  store i16 %260, i16* %270, align 2
  %271 = shl nuw nsw i32 %85, 1
  %272 = add nuw nsw i32 %75, 2
  %273 = add nuw nsw i32 %272, %271
  %274 = add nuw nsw i32 %273, %95
  %275 = lshr i32 %274, 2
  %276 = trunc i32 %275 to i16
  %277 = add i64 %19, 17179869184
  %278 = ashr exact i64 %277, 32
  %279 = getelementptr inbounds i16, i16* %5, i64 %278
  store i16 %276, i16* %279, align 2
  %280 = add nsw i32 %196, 3
  %281 = sext i32 %280 to i64
  %282 = getelementptr inbounds i16, i16* %5, i64 %281
  store i16 %276, i16* %282, align 2
  %283 = add nsw i32 %223, 2
  %284 = sext i32 %283 to i64
  %285 = getelementptr inbounds i16, i16* %5, i64 %284
  store i16 %276, i16* %285, align 2
  %286 = add nsw i32 %254, 1
  %287 = sext i32 %286 to i64
  %288 = getelementptr inbounds i16, i16* %5, i64 %287
  store i16 %276, i16* %288, align 2
  %289 = add nuw nsw i32 %85, 1
  %290 = add nuw nsw i32 %289, %95
  %291 = lshr i32 %290, 1
  %292 = trunc i32 %291 to i16
  %293 = getelementptr inbounds i8, i8* %0, i64 10
  %294 = bitcast i8* %293 to i16*
  store i16 %292, i16* %294, align 2
  %295 = add nsw i32 %184, 4
  %296 = sext i32 %295 to i64
  %297 = getelementptr inbounds i16, i16* %5, i64 %296
  store i16 %292, i16* %297, align 2
  %298 = or i64 %210, 3
  %299 = getelementptr inbounds i16, i16* %5, i64 %298
  store i16 %292, i16* %299, align 2
  %300 = add nsw i32 %237, 2
  %301 = sext i32 %300 to i64
  %302 = getelementptr inbounds i16, i16* %5, i64 %301
  store i16 %292, i16* %302, align 2
  %303 = shl nuw nsw i32 %95, 1
  %304 = add nuw nsw i32 %85, 2
  %305 = add nuw nsw i32 %304, %303
  %306 = add nuw nsw i32 %305, %165
  %307 = lshr i32 %306, 2
  %308 = trunc i32 %307 to i16
  %309 = add i64 %19, 21474836480
  %310 = ashr exact i64 %309, 32
  %311 = getelementptr inbounds i16, i16* %5, i64 %310
  store i16 %308, i16* %311, align 2
  %312 = add nsw i32 %196, 4
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds i16, i16* %5, i64 %313
  store i16 %308, i16* %314, align 2
  %315 = add nsw i32 %223, 3
  %316 = sext i32 %315 to i64
  %317 = getelementptr inbounds i16, i16* %5, i64 %316
  store i16 %308, i16* %317, align 2
  %318 = add nsw i32 %254, 2
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %308, i16* %320, align 2
  %321 = add nuw nsw i32 %95, 1
  %322 = add nuw nsw i32 %321, %165
  %323 = lshr i32 %322, 1
  %324 = trunc i32 %323 to i16
  %325 = getelementptr inbounds i8, i8* %0, i64 12
  %326 = bitcast i8* %325 to i16*
  store i16 %324, i16* %326, align 2
  %327 = add nsw i32 %184, 5
  %328 = sext i32 %327 to i64
  %329 = getelementptr inbounds i16, i16* %5, i64 %328
  store i16 %324, i16* %329, align 2
  %330 = add i64 %209, 17179869184
  %331 = ashr exact i64 %330, 32
  %332 = getelementptr inbounds i16, i16* %5, i64 %331
  store i16 %324, i16* %332, align 2
  %333 = add nsw i32 %237, 3
  %334 = sext i32 %333 to i64
  %335 = getelementptr inbounds i16, i16* %5, i64 %334
  store i16 %324, i16* %335, align 2
  %336 = shl nuw nsw i32 %165, 1
  %337 = add nuw nsw i32 %95, 2
  %338 = add nuw nsw i32 %337, %158
  %339 = add nuw nsw i32 %338, %336
  %340 = lshr i32 %339, 2
  %341 = trunc i32 %340 to i16
  %342 = add i64 %19, 25769803776
  %343 = ashr exact i64 %342, 32
  %344 = getelementptr inbounds i16, i16* %5, i64 %343
  store i16 %341, i16* %344, align 2
  %345 = add nsw i32 %196, 5
  %346 = sext i32 %345 to i64
  %347 = getelementptr inbounds i16, i16* %5, i64 %346
  store i16 %341, i16* %347, align 2
  %348 = add nsw i32 %223, 4
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i16, i16* %5, i64 %349
  store i16 %341, i16* %350, align 2
  %351 = add nsw i32 %254, 3
  %352 = sext i32 %351 to i64
  %353 = getelementptr inbounds i16, i16* %5, i64 %352
  store i16 %341, i16* %353, align 2
  %354 = add nuw nsw i32 %158, 1
  %355 = add nuw nsw i32 %354, %165
  %356 = lshr i32 %355, 1
  %357 = trunc i32 %356 to i16
  %358 = getelementptr inbounds i8, i8* %0, i64 14
  %359 = bitcast i8* %358 to i16*
  store i16 %357, i16* %359, align 2
  %360 = add nsw i32 %184, 6
  %361 = sext i32 %360 to i64
  %362 = getelementptr inbounds i16, i16* %5, i64 %361
  store i16 %357, i16* %362, align 2
  %363 = add i64 %209, 21474836480
  %364 = ashr exact i64 %363, 32
  %365 = getelementptr inbounds i16, i16* %5, i64 %364
  store i16 %357, i16* %365, align 2
  %366 = add nsw i32 %237, 4
  %367 = sext i32 %366 to i64
  %368 = getelementptr inbounds i16, i16* %5, i64 %367
  store i16 %357, i16* %368, align 2
  %369 = shl nuw nsw i32 %158, 1
  %370 = add nuw nsw i32 %165, 2
  %371 = add nuw nsw i32 %370, %159
  %372 = add nuw nsw i32 %371, %369
  %373 = lshr i32 %372, 2
  %374 = trunc i32 %373 to i16
  %375 = add i64 %19, 30064771072
  %376 = ashr exact i64 %375, 32
  %377 = getelementptr inbounds i16, i16* %5, i64 %376
  store i16 %374, i16* %377, align 2
  %378 = add nsw i32 %196, 6
  %379 = sext i32 %378 to i64
  %380 = getelementptr inbounds i16, i16* %5, i64 %379
  store i16 %374, i16* %380, align 2
  %381 = add nsw i32 %223, 5
  %382 = sext i32 %381 to i64
  %383 = getelementptr inbounds i16, i16* %5, i64 %382
  store i16 %374, i16* %383, align 2
  %384 = add nsw i32 %254, 4
  %385 = sext i32 %384 to i64
  %386 = getelementptr inbounds i16, i16* %5, i64 %385
  store i16 %374, i16* %386, align 2
  %387 = add nuw nsw i32 %354, %159
  %388 = lshr i32 %387, 1
  %389 = trunc i32 %388 to i16
  %390 = add nsw i32 %184, 7
  %391 = sext i32 %390 to i64
  %392 = getelementptr inbounds i16, i16* %5, i64 %391
  store i16 %389, i16* %392, align 2
  %393 = add i64 %209, 25769803776
  %394 = ashr exact i64 %393, 32
  %395 = getelementptr inbounds i16, i16* %5, i64 %394
  store i16 %389, i16* %395, align 2
  %396 = add nsw i32 %237, 5
  %397 = sext i32 %396 to i64
  %398 = getelementptr inbounds i16, i16* %5, i64 %397
  store i16 %389, i16* %398, align 2
  %399 = shl nuw nsw i32 %159, 1
  %400 = add nuw nsw i32 %158, 2
  %401 = add nuw nsw i32 %400, %399
  %402 = add nuw nsw i32 %401, %160
  %403 = lshr i32 %402, 2
  %404 = trunc i32 %403 to i16
  %405 = add nsw i32 %196, 7
  %406 = sext i32 %405 to i64
  %407 = getelementptr inbounds i16, i16* %5, i64 %406
  store i16 %404, i16* %407, align 2
  %408 = add nsw i32 %223, 6
  %409 = sext i32 %408 to i64
  %410 = getelementptr inbounds i16, i16* %5, i64 %409
  store i16 %404, i16* %410, align 2
  %411 = add nsw i32 %254, 5
  %412 = sext i32 %411 to i64
  %413 = getelementptr inbounds i16, i16* %5, i64 %412
  store i16 %404, i16* %413, align 2
  %414 = add nuw nsw i32 %159, 1
  %415 = add nuw nsw i32 %414, %160
  %416 = lshr i32 %415, 1
  %417 = trunc i32 %416 to i16
  %418 = add i64 %209, 30064771072
  %419 = ashr exact i64 %418, 32
  %420 = getelementptr inbounds i16, i16* %5, i64 %419
  store i16 %417, i16* %420, align 2
  %421 = add nsw i32 %237, 6
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds i16, i16* %5, i64 %422
  store i16 %417, i16* %423, align 2
  %424 = shl nuw nsw i32 %160, 1
  %425 = add nuw nsw i32 %159, 2
  %426 = add nuw nsw i32 %425, %424
  %427 = add nuw nsw i32 %426, %161
  %428 = lshr i32 %427, 2
  %429 = trunc i32 %428 to i16
  %430 = add nsw i32 %223, 7
  %431 = sext i32 %430 to i64
  %432 = getelementptr inbounds i16, i16* %5, i64 %431
  store i16 %429, i16* %432, align 2
  %433 = add nsw i32 %254, 6
  %434 = sext i32 %433 to i64
  %435 = getelementptr inbounds i16, i16* %5, i64 %434
  store i16 %429, i16* %435, align 2
  %436 = add nuw nsw i32 %160, 1
  %437 = add nuw nsw i32 %436, %161
  %438 = lshr i32 %437, 1
  %439 = trunc i32 %438 to i16
  %440 = add nsw i32 %237, 7
  %441 = sext i32 %440 to i64
  %442 = getelementptr inbounds i16, i16* %5, i64 %441
  store i16 %439, i16* %442, align 2
  %443 = shl nuw nsw i32 %161, 1
  %444 = add nuw nsw i32 %160, 2
  %445 = add nuw nsw i32 %444, %443
  %446 = add nuw nsw i32 %445, %162
  %447 = lshr i32 %446, 2
  %448 = trunc i32 %447 to i16
  %449 = add nsw i32 %254, 7
  %450 = sext i32 %449 to i64
  %451 = getelementptr inbounds i16, i16* %5, i64 %450
  store i16 %448, i16* %451, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_up_12_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  br i1 %8, label %14, label %9

9:                                                ; preds = %4
  %10 = shl i64 %6, 32
  %11 = ashr exact i64 %10, 32
  %12 = xor i64 %11, -1
  %13 = getelementptr inbounds i16, i16* %5, i64 %12
  br label %19

14:                                               ; preds = %4
  %15 = getelementptr inbounds i8, i8* %0, i64 -2
  %16 = bitcast i8* %15 to i16*
  %17 = shl i64 %6, 32
  %18 = ashr exact i64 %17, 32
  br label %19

19:                                               ; preds = %14, %9
  %20 = phi i64 [ %18, %14 ], [ %11, %9 ]
  %21 = phi i64 [ %17, %14 ], [ %10, %9 ]
  %22 = phi i16* [ %16, %14 ], [ %13, %9 ]
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i8, i8* %0, i64 -2
  %26 = bitcast i8* %25 to i16*
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = shl nuw nsw i32 %28, 1
  %30 = add i64 %21, -4294967296
  %31 = ashr exact i64 %30, 32
  %32 = getelementptr inbounds i16, i16* %5, i64 %31
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = add nuw nsw i32 %34, 2
  %36 = add nuw nsw i32 %35, %24
  %37 = add nuw nsw i32 %36, %29
  %38 = lshr i32 %37, 2
  %39 = shl nuw nsw i32 %34, 1
  %40 = trunc i64 %3 to i32
  %41 = and i32 %40, -2
  %42 = add nsw i32 %41, -1
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i16, i16* %5, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %28
  %49 = add nuw nsw i32 %48, %39
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = mul nsw i32 %7, 3
  %53 = add nsw i32 %52, -1
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i16, i16* %5, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i32
  %58 = add nuw nsw i32 %35, %51
  %59 = add nuw nsw i32 %58, %57
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %57, 1
  %62 = shl i64 %6, 34
  %63 = add i64 %62, -4294967296
  %64 = ashr exact i64 %63, 32
  %65 = getelementptr inbounds i16, i16* %5, i64 %64
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = add nuw nsw i32 %47, %61
  %69 = add nuw nsw i32 %68, %67
  %70 = lshr i32 %69, 2
  %71 = shl nuw nsw i32 %67, 1
  %72 = mul nsw i32 %7, 5
  %73 = add nsw i32 %72, -1
  %74 = sext i32 %73 to i64
  %75 = getelementptr inbounds i16, i16* %5, i64 %74
  %76 = load i16, i16* %75, align 2
  %77 = zext i16 %76 to i32
  %78 = add nuw nsw i32 %57, 2
  %79 = add nuw nsw i32 %78, %71
  %80 = add nuw nsw i32 %79, %77
  %81 = lshr i32 %80, 2
  %82 = shl nuw nsw i32 %77, 1
  %83 = mul nsw i32 %7, 6
  %84 = add nsw i32 %83, -1
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i16, i16* %5, i64 %85
  %87 = load i16, i16* %86, align 2
  %88 = zext i16 %87 to i32
  %89 = add nuw nsw i32 %67, 2
  %90 = add nuw nsw i32 %89, %82
  %91 = add nuw nsw i32 %90, %88
  %92 = lshr i32 %91, 2
  %93 = shl nuw nsw i32 %88, 1
  %94 = mul nsw i32 %7, 7
  %95 = add nsw i32 %94, -1
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %5, i64 %96
  %98 = load i16, i16* %97, align 2
  %99 = zext i16 %98 to i32
  %100 = add nuw nsw i32 %77, 2
  %101 = add nuw nsw i32 %100, %93
  %102 = add nuw nsw i32 %101, %99
  %103 = lshr i32 %102, 2
  %104 = mul nuw nsw i32 %99, 3
  %105 = add nuw nsw i32 %88, 2
  %106 = add nuw nsw i32 %105, %104
  %107 = lshr i32 %106, 2
  %108 = add nuw nsw i32 %50, 1
  %109 = add nuw nsw i32 %108, %38
  %110 = lshr i32 %109, 1
  %111 = trunc i32 %110 to i16
  store i16 %111, i16* %5, align 2
  %112 = shl nuw nsw i32 %50, 1
  %113 = add nuw nsw i32 %60, 2
  %114 = add nuw nsw i32 %113, %38
  %115 = add nuw nsw i32 %114, %112
  %116 = lshr i32 %115, 2
  %117 = trunc i32 %116 to i16
  %118 = getelementptr inbounds i8, i8* %0, i64 2
  %119 = bitcast i8* %118 to i16*
  store i16 %117, i16* %119, align 2
  %120 = add nuw nsw i32 %108, %60
  %121 = lshr i32 %120, 1
  %122 = trunc i32 %121 to i16
  %123 = getelementptr inbounds i8, i8* %0, i64 4
  %124 = bitcast i8* %123 to i16*
  store i16 %122, i16* %124, align 2
  %125 = getelementptr inbounds i16, i16* %5, i64 %20
  store i16 %122, i16* %125, align 2
  %126 = shl nuw nsw i32 %60, 1
  %127 = add nuw nsw i32 %70, 2
  %128 = add nuw nsw i32 %127, %50
  %129 = add nuw nsw i32 %128, %126
  %130 = lshr i32 %129, 2
  %131 = trunc i32 %130 to i16
  %132 = getelementptr inbounds i8, i8* %0, i64 6
  %133 = bitcast i8* %132 to i16*
  store i16 %131, i16* %133, align 2
  %134 = add i64 %21, 4294967296
  %135 = ashr exact i64 %134, 32
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  store i16 %131, i16* %136, align 2
  %137 = add nuw nsw i32 %60, 1
  %138 = add nuw nsw i32 %137, %70
  %139 = lshr i32 %138, 1
  %140 = trunc i32 %139 to i16
  %141 = getelementptr inbounds i8, i8* %0, i64 8
  %142 = bitcast i8* %141 to i16*
  store i16 %140, i16* %142, align 2
  %143 = add i64 %21, 8589934592
  %144 = ashr exact i64 %143, 32
  %145 = getelementptr inbounds i16, i16* %5, i64 %144
  store i16 %140, i16* %145, align 2
  %146 = sext i32 %41 to i64
  %147 = getelementptr inbounds i16, i16* %5, i64 %146
  store i16 %140, i16* %147, align 2
  %148 = shl nuw nsw i32 %70, 1
  %149 = add nuw nsw i32 %113, %148
  %150 = add nuw nsw i32 %149, %81
  %151 = lshr i32 %150, 2
  %152 = trunc i32 %151 to i16
  %153 = getelementptr inbounds i8, i8* %0, i64 10
  %154 = bitcast i8* %153 to i16*
  store i16 %152, i16* %154, align 2
  %155 = add i64 %21, 12884901888
  %156 = ashr exact i64 %155, 32
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  store i16 %152, i16* %157, align 2
  %158 = shl i64 %3, 32
  %159 = ashr exact i64 %158, 32
  %160 = or i64 %159, 1
  %161 = getelementptr inbounds i16, i16* %5, i64 %160
  store i16 %152, i16* %161, align 2
  %162 = add nuw nsw i32 %70, 1
  %163 = add nuw nsw i32 %162, %81
  %164 = lshr i32 %163, 1
  %165 = trunc i32 %164 to i16
  %166 = getelementptr inbounds i8, i8* %0, i64 12
  %167 = bitcast i8* %166 to i16*
  store i16 %165, i16* %167, align 2
  %168 = add i64 %21, 17179869184
  %169 = ashr exact i64 %168, 32
  %170 = getelementptr inbounds i16, i16* %5, i64 %169
  store i16 %165, i16* %170, align 2
  %171 = add nsw i32 %41, 2
  %172 = sext i32 %171 to i64
  %173 = getelementptr inbounds i16, i16* %5, i64 %172
  store i16 %165, i16* %173, align 2
  %174 = sext i32 %52 to i64
  %175 = getelementptr inbounds i16, i16* %5, i64 %174
  store i16 %165, i16* %175, align 2
  %176 = shl nuw nsw i32 %81, 1
  %177 = add nuw nsw i32 %127, %176
  %178 = add nuw nsw i32 %177, %92
  %179 = lshr i32 %178, 2
  %180 = trunc i32 %179 to i16
  %181 = getelementptr inbounds i8, i8* %0, i64 14
  %182 = bitcast i8* %181 to i16*
  store i16 %180, i16* %182, align 2
  %183 = add i64 %21, 21474836480
  %184 = ashr exact i64 %183, 32
  %185 = getelementptr inbounds i16, i16* %5, i64 %184
  store i16 %180, i16* %185, align 2
  %186 = add nsw i32 %41, 3
  %187 = sext i32 %186 to i64
  %188 = getelementptr inbounds i16, i16* %5, i64 %187
  store i16 %180, i16* %188, align 2
  %189 = add nsw i32 %52, 1
  %190 = sext i32 %189 to i64
  %191 = getelementptr inbounds i16, i16* %5, i64 %190
  store i16 %180, i16* %191, align 2
  %192 = add nuw nsw i32 %81, 1
  %193 = add nuw nsw i32 %192, %92
  %194 = lshr i32 %193, 1
  %195 = trunc i32 %194 to i16
  %196 = add i64 %21, 25769803776
  %197 = ashr exact i64 %196, 32
  %198 = getelementptr inbounds i16, i16* %5, i64 %197
  store i16 %195, i16* %198, align 2
  %199 = add nsw i32 %41, 4
  %200 = sext i32 %199 to i64
  %201 = getelementptr inbounds i16, i16* %5, i64 %200
  store i16 %195, i16* %201, align 2
  %202 = add nsw i32 %52, 2
  %203 = sext i32 %202 to i64
  %204 = getelementptr inbounds i16, i16* %5, i64 %203
  store i16 %195, i16* %204, align 2
  %205 = ashr exact i64 %62, 32
  %206 = getelementptr inbounds i16, i16* %5, i64 %205
  store i16 %195, i16* %206, align 2
  %207 = shl nuw nsw i32 %92, 1
  %208 = add nuw nsw i32 %81, 2
  %209 = add nuw nsw i32 %208, %207
  %210 = add nuw nsw i32 %209, %103
  %211 = lshr i32 %210, 2
  %212 = trunc i32 %211 to i16
  %213 = add i64 %21, 30064771072
  %214 = ashr exact i64 %213, 32
  %215 = getelementptr inbounds i16, i16* %5, i64 %214
  store i16 %212, i16* %215, align 2
  %216 = add nsw i32 %41, 5
  %217 = sext i32 %216 to i64
  %218 = getelementptr inbounds i16, i16* %5, i64 %217
  store i16 %212, i16* %218, align 2
  %219 = add nsw i32 %52, 3
  %220 = sext i32 %219 to i64
  %221 = getelementptr inbounds i16, i16* %5, i64 %220
  store i16 %212, i16* %221, align 2
  %222 = or i64 %205, 1
  %223 = getelementptr inbounds i16, i16* %5, i64 %222
  store i16 %212, i16* %223, align 2
  %224 = add nuw nsw i32 %92, 1
  %225 = add nuw nsw i32 %224, %103
  %226 = lshr i32 %225, 1
  %227 = trunc i32 %226 to i16
  %228 = add nsw i32 %41, 6
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds i16, i16* %5, i64 %229
  store i16 %227, i16* %230, align 2
  %231 = add nsw i32 %52, 4
  %232 = sext i32 %231 to i64
  %233 = getelementptr inbounds i16, i16* %5, i64 %232
  store i16 %227, i16* %233, align 2
  %234 = or i64 %205, 2
  %235 = getelementptr inbounds i16, i16* %5, i64 %234
  store i16 %227, i16* %235, align 2
  %236 = sext i32 %72 to i64
  %237 = getelementptr inbounds i16, i16* %5, i64 %236
  store i16 %227, i16* %237, align 2
  %238 = shl nuw nsw i32 %103, 1
  %239 = add nuw nsw i32 %92, 2
  %240 = add nuw nsw i32 %239, %107
  %241 = add nuw nsw i32 %240, %238
  %242 = lshr i32 %241, 2
  %243 = trunc i32 %242 to i16
  %244 = add nsw i32 %41, 7
  %245 = sext i32 %244 to i64
  %246 = getelementptr inbounds i16, i16* %5, i64 %245
  store i16 %243, i16* %246, align 2
  %247 = add nsw i32 %52, 5
  %248 = sext i32 %247 to i64
  %249 = getelementptr inbounds i16, i16* %5, i64 %248
  store i16 %243, i16* %249, align 2
  %250 = or i64 %205, 3
  %251 = getelementptr inbounds i16, i16* %5, i64 %250
  store i16 %243, i16* %251, align 2
  %252 = add nsw i32 %72, 1
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i16, i16* %5, i64 %253
  store i16 %243, i16* %254, align 2
  %255 = add nuw nsw i32 %103, 1
  %256 = add nuw nsw i32 %255, %107
  %257 = lshr i32 %256, 1
  %258 = trunc i32 %257 to i16
  %259 = add nsw i32 %52, 6
  %260 = sext i32 %259 to i64
  %261 = getelementptr inbounds i16, i16* %5, i64 %260
  store i16 %258, i16* %261, align 2
  %262 = add i64 %62, 17179869184
  %263 = ashr exact i64 %262, 32
  %264 = getelementptr inbounds i16, i16* %5, i64 %263
  store i16 %258, i16* %264, align 2
  %265 = add nsw i32 %72, 2
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds i16, i16* %5, i64 %266
  store i16 %258, i16* %267, align 2
  %268 = sext i32 %83 to i64
  %269 = getelementptr inbounds i16, i16* %5, i64 %268
  store i16 %258, i16* %269, align 2
  %270 = mul nuw nsw i32 %107, 3
  %271 = add nuw nsw i32 %103, 2
  %272 = add nuw nsw i32 %271, %270
  %273 = lshr i32 %272, 2
  %274 = trunc i32 %273 to i16
  %275 = add nsw i32 %52, 7
  %276 = sext i32 %275 to i64
  %277 = getelementptr inbounds i16, i16* %5, i64 %276
  store i16 %274, i16* %277, align 2
  %278 = add i64 %62, 21474836480
  %279 = ashr exact i64 %278, 32
  %280 = getelementptr inbounds i16, i16* %5, i64 %279
  store i16 %274, i16* %280, align 2
  %281 = add nsw i32 %72, 3
  %282 = sext i32 %281 to i64
  %283 = getelementptr inbounds i16, i16* %5, i64 %282
  store i16 %274, i16* %283, align 2
  %284 = or i32 %83, 1
  %285 = sext i32 %284 to i64
  %286 = getelementptr inbounds i16, i16* %5, i64 %285
  store i16 %274, i16* %286, align 2
  %287 = trunc i32 %107 to i16
  %288 = add nsw i32 %94, 7
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds i16, i16* %5, i64 %289
  store i16 %287, i16* %290, align 2
  %291 = add nsw i32 %83, 7
  %292 = sext i32 %291 to i64
  %293 = getelementptr inbounds i16, i16* %5, i64 %292
  store i16 %287, i16* %293, align 2
  %294 = add nsw i32 %72, 7
  %295 = sext i32 %294 to i64
  %296 = getelementptr inbounds i16, i16* %5, i64 %295
  store i16 %287, i16* %296, align 2
  %297 = add i64 %62, 30064771072
  %298 = ashr exact i64 %297, 32
  %299 = getelementptr inbounds i16, i16* %5, i64 %298
  store i16 %287, i16* %299, align 2
  %300 = add nsw i32 %94, 6
  %301 = sext i32 %300 to i64
  %302 = getelementptr inbounds i16, i16* %5, i64 %301
  store i16 %287, i16* %302, align 2
  %303 = add nsw i32 %83, 6
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds i16, i16* %5, i64 %304
  store i16 %287, i16* %305, align 2
  %306 = add nsw i32 %72, 6
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i16, i16* %5, i64 %307
  store i16 %287, i16* %308, align 2
  %309 = add i64 %62, 25769803776
  %310 = ashr exact i64 %309, 32
  %311 = getelementptr inbounds i16, i16* %5, i64 %310
  store i16 %287, i16* %311, align 2
  %312 = add nsw i32 %94, 5
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds i16, i16* %5, i64 %313
  store i16 %287, i16* %314, align 2
  %315 = add nsw i32 %83, 5
  %316 = sext i32 %315 to i64
  %317 = getelementptr inbounds i16, i16* %5, i64 %316
  store i16 %287, i16* %317, align 2
  %318 = add nsw i32 %72, 5
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %287, i16* %320, align 2
  %321 = add nsw i32 %94, 4
  %322 = sext i32 %321 to i64
  %323 = getelementptr inbounds i16, i16* %5, i64 %322
  store i16 %287, i16* %323, align 2
  %324 = add nsw i32 %83, 4
  %325 = sext i32 %324 to i64
  %326 = getelementptr inbounds i16, i16* %5, i64 %325
  store i16 %287, i16* %326, align 2
  %327 = add nsw i32 %72, 4
  %328 = sext i32 %327 to i64
  %329 = getelementptr inbounds i16, i16* %5, i64 %328
  store i16 %287, i16* %329, align 2
  %330 = add nsw i32 %94, 3
  %331 = sext i32 %330 to i64
  %332 = getelementptr inbounds i16, i16* %5, i64 %331
  store i16 %287, i16* %332, align 2
  %333 = add nsw i32 %83, 3
  %334 = sext i32 %333 to i64
  %335 = getelementptr inbounds i16, i16* %5, i64 %334
  store i16 %287, i16* %335, align 2
  %336 = add nsw i32 %94, 2
  %337 = sext i32 %336 to i64
  %338 = getelementptr inbounds i16, i16* %5, i64 %337
  store i16 %287, i16* %338, align 2
  %339 = add nsw i32 %83, 2
  %340 = sext i32 %339 to i64
  %341 = getelementptr inbounds i16, i16* %5, i64 %340
  store i16 %287, i16* %341, align 2
  %342 = add nsw i32 %94, 1
  %343 = sext i32 %342 to i64
  %344 = getelementptr inbounds i16, i16* %5, i64 %343
  store i16 %287, i16* %344, align 2
  %345 = sext i32 %94 to i64
  %346 = getelementptr inbounds i16, i16* %5, i64 %345
  store i16 %287, i16* %346, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_left_dc_12_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = icmp eq i32 %1, 0
  br i1 %7, label %13, label %8

8:                                                ; preds = %4
  %9 = shl i64 %6, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = getelementptr inbounds i16, i16* %5, i64 %11
  br label %18

13:                                               ; preds = %4
  %14 = getelementptr inbounds i8, i8* %0, i64 -2
  %15 = bitcast i8* %14 to i16*
  %16 = shl i64 %6, 32
  %17 = ashr exact i64 %16, 32
  br label %18

18:                                               ; preds = %13, %8
  %19 = phi i64 [ %17, %13 ], [ %10, %8 ]
  %20 = phi i64 [ %16, %13 ], [ %9, %8 ]
  %21 = phi i16* [ %15, %13 ], [ %12, %8 ]
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = getelementptr inbounds i8, i8* %0, i64 -2
  %25 = bitcast i8* %24 to i16*
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = add i64 %20, -4294967296
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %23
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = shl i64 %3, 32
  %40 = and i64 %39, -8589934592
  %41 = add i64 %40, -4294967296
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds i16, i16* %5, i64 %42
  %44 = load i16, i16* %43, align 2
  %45 = zext i16 %44 to i32
  %46 = add nuw nsw i32 %45, 2
  %47 = add nuw nsw i32 %46, %27
  %48 = add nuw nsw i32 %47, %38
  %49 = lshr i32 %48, 2
  %50 = shl nuw nsw i32 %45, 1
  %51 = mul i64 %6, 12884901888
  %52 = add i64 %51, -4294967296
  %53 = ashr exact i64 %52, 32
  %54 = getelementptr inbounds i16, i16* %5, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i32
  %57 = add nuw nsw i32 %34, %50
  %58 = add nuw nsw i32 %57, %56
  %59 = lshr i32 %58, 2
  %60 = shl nuw nsw i32 %56, 1
  %61 = shl i64 %6, 34
  %62 = add i64 %61, -4294967296
  %63 = ashr exact i64 %62, 32
  %64 = getelementptr inbounds i16, i16* %5, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i32
  %67 = add nuw nsw i32 %46, %60
  %68 = add nuw nsw i32 %67, %66
  %69 = lshr i32 %68, 2
  %70 = shl nuw nsw i32 %66, 1
  %71 = mul i64 %6, 21474836480
  %72 = add i64 %71, -4294967296
  %73 = ashr exact i64 %72, 32
  %74 = getelementptr inbounds i16, i16* %5, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i32
  %77 = add nuw nsw i32 %56, 2
  %78 = add nuw nsw i32 %77, %70
  %79 = add nuw nsw i32 %78, %76
  %80 = lshr i32 %79, 2
  %81 = shl nuw nsw i32 %76, 1
  %82 = mul i64 %6, 25769803776
  %83 = add i64 %82, -4294967296
  %84 = ashr exact i64 %83, 32
  %85 = getelementptr inbounds i16, i16* %5, i64 %84
  %86 = load i16, i16* %85, align 2
  %87 = zext i16 %86 to i32
  %88 = add nuw nsw i32 %66, 2
  %89 = add nuw nsw i32 %88, %81
  %90 = add nuw nsw i32 %89, %87
  %91 = lshr i32 %90, 2
  %92 = shl nuw nsw i32 %87, 1
  %93 = mul i64 %6, 30064771072
  %94 = add i64 %93, -4294967296
  %95 = ashr exact i64 %94, 32
  %96 = getelementptr inbounds i16, i16* %5, i64 %95
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i32
  %99 = add nuw nsw i32 %76, 2
  %100 = add nuw nsw i32 %99, %92
  %101 = add nuw nsw i32 %100, %98
  %102 = lshr i32 %101, 2
  %103 = mul nuw nsw i32 %98, 3
  %104 = add nuw nsw i32 %87, 2
  %105 = add nuw nsw i32 %104, %103
  %106 = lshr i32 %105, 2
  %107 = add nuw nsw i32 %37, 4
  %108 = add nuw nsw i32 %107, %49
  %109 = add nuw nsw i32 %108, %59
  %110 = add nuw nsw i32 %109, %69
  %111 = add nuw nsw i32 %110, %80
  %112 = add nuw nsw i32 %111, %91
  %113 = add nuw nsw i32 %112, %106
  %114 = add nuw nsw i32 %113, %102
  %115 = ashr i32 %114, 3
  %116 = sext i32 %115 to i64
  %117 = mul i64 %116, 281479271743489
  %118 = bitcast i8* %0 to i64*
  store i64 %117, i64* %118, align 8
  %119 = getelementptr inbounds i8, i8* %0, i64 8
  %120 = bitcast i8* %119 to i64*
  store i64 %117, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %5, i64 %19
  %122 = bitcast i16* %121 to i64*
  store i64 %117, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %121, i64 4
  %124 = bitcast i16* %123 to i64*
  store i64 %117, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %121, i64 %19
  %126 = bitcast i16* %125 to i64*
  store i64 %117, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %125, i64 4
  %128 = bitcast i16* %127 to i64*
  store i64 %117, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %125, i64 %19
  %130 = bitcast i16* %129 to i64*
  store i64 %117, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %129, i64 4
  %132 = bitcast i16* %131 to i64*
  store i64 %117, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %129, i64 %19
  %134 = bitcast i16* %133 to i64*
  store i64 %117, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %133, i64 4
  %136 = bitcast i16* %135 to i64*
  store i64 %117, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %133, i64 %19
  %138 = bitcast i16* %137 to i64*
  store i64 %117, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %137, i64 4
  %140 = bitcast i16* %139 to i64*
  store i64 %117, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %137, i64 %19
  %142 = bitcast i16* %141 to i64*
  store i64 %117, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %117, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %141, i64 %19
  %146 = bitcast i16* %145 to i64*
  store i64 %117, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %145, i64 4
  %148 = bitcast i16* %147 to i64*
  store i64 %117, i64* %148, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_top_dc_12_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %103, label %97

97:                                               ; preds = %18
  %98 = sub i64 34359738368, %19
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i16, i16* %5, i64 %99
  %101 = load i16, i16* %100, align 2
  %102 = zext i16 %101 to i32
  br label %103

103:                                              ; preds = %18, %97
  %104 = phi i32 [ %102, %97 ], [ %91, %18 ]
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %81, 2
  %107 = add nuw nsw i32 %106, %105
  %108 = add nuw nsw i32 %107, %104
  %109 = lshr i32 %108, 2
  %110 = add nuw nsw i32 %37, 4
  %111 = add nuw nsw i32 %110, %47
  %112 = add nuw nsw i32 %111, %56
  %113 = add nuw nsw i32 %112, %65
  %114 = add nuw nsw i32 %113, %75
  %115 = add nuw nsw i32 %114, %85
  %116 = add nuw nsw i32 %115, %95
  %117 = add nuw nsw i32 %116, %109
  %118 = ashr i32 %117, 3
  %119 = sext i32 %118 to i64
  %120 = mul i64 %119, 281479271743489
  %121 = ashr exact i64 %19, 32
  %122 = bitcast i8* %0 to i64*
  store i64 %120, i64* %122, align 8
  %123 = getelementptr inbounds i8, i8* %0, i64 8
  %124 = bitcast i8* %123 to i64*
  store i64 %120, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %5, i64 %121
  %126 = bitcast i16* %125 to i64*
  store i64 %120, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %125, i64 4
  %128 = bitcast i16* %127 to i64*
  store i64 %120, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %125, i64 %121
  %130 = bitcast i16* %129 to i64*
  store i64 %120, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %129, i64 4
  %132 = bitcast i16* %131 to i64*
  store i64 %120, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %129, i64 %121
  %134 = bitcast i16* %133 to i64*
  store i64 %120, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %133, i64 4
  %136 = bitcast i16* %135 to i64*
  store i64 %120, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %133, i64 %121
  %138 = bitcast i16* %137 to i64*
  store i64 %120, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %137, i64 4
  %140 = bitcast i16* %139 to i64*
  store i64 %120, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %137, i64 %121
  %142 = bitcast i16* %141 to i64*
  store i64 %120, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %120, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %141, i64 %121
  %146 = bitcast i16* %145 to i64*
  store i64 %120, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %145, i64 4
  %148 = bitcast i16* %147 to i64*
  store i64 %120, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %145, i64 %121
  %150 = bitcast i16* %149 to i64*
  store i64 %120, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %149, i64 4
  %152 = bitcast i16* %151 to i64*
  store i64 %120, i64* %152, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8l_128_dc_12_c(i8* nocapture, i32, i32, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = shl i64 %3, 31
  %7 = ashr i64 %6, 32
  %8 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %8, align 8
  %9 = getelementptr inbounds i16, i16* %5, i64 %7
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %10, align 8
  %11 = getelementptr inbounds i16, i16* %9, i64 %7
  %12 = bitcast i16* %11 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %12, align 8
  %13 = getelementptr inbounds i16, i16* %11, i64 %7
  %14 = bitcast i16* %13 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %14, align 8
  %15 = getelementptr inbounds i16, i16* %13, i64 %7
  %16 = bitcast i16* %15 to i64*
  store i64 576469548530665472, i64* %16, align 8
  %17 = getelementptr inbounds i16, i16* %15, i64 4
  %18 = bitcast i16* %17 to i64*
  store i64 576469548530665472, i64* %18, align 8
  %19 = getelementptr inbounds i16, i16* %15, i64 %7
  %20 = bitcast i16* %19 to i64*
  store i64 576469548530665472, i64* %20, align 8
  %21 = getelementptr inbounds i16, i16* %19, i64 4
  %22 = bitcast i16* %21 to i64*
  store i64 576469548530665472, i64* %22, align 8
  %23 = getelementptr inbounds i16, i16* %19, i64 %7
  %24 = bitcast i16* %23 to i64*
  store i64 576469548530665472, i64* %24, align 8
  %25 = getelementptr inbounds i16, i16* %23, i64 4
  %26 = bitcast i16* %25 to i64*
  store i64 576469548530665472, i64* %26, align 8
  %27 = getelementptr inbounds i16, i16* %23, i64 %7
  %28 = bitcast i16* %27 to i64*
  store i64 576469548530665472, i64* %28, align 8
  %29 = getelementptr inbounds i16, i16* %27, i64 4
  %30 = bitcast i16* %29 to i64*
  store i64 576469548530665472, i64* %30, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_vertical_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds i16, i16* %8, i64 4
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = shl i64 %4, 32
  %15 = ashr exact i64 %14, 32
  %16 = bitcast i8* %0 to i64*
  store i64 %10, i64* %16, align 8
  %17 = getelementptr inbounds i8, i8* %0, i64 8
  %18 = bitcast i8* %17 to i64*
  store i64 %13, i64* %18, align 8
  %19 = getelementptr inbounds i16, i16* %3, i64 %15
  %20 = bitcast i16* %19 to i64*
  store i64 %10, i64* %20, align 8
  %21 = getelementptr inbounds i16, i16* %19, i64 4
  %22 = bitcast i16* %21 to i64*
  store i64 %13, i64* %22, align 8
  %23 = ashr exact i64 %14, 31
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to i64*
  store i64 %10, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %24, i64 4
  %27 = bitcast i16* %26 to i64*
  store i64 %13, i64* %27, align 8
  %28 = mul nsw i64 %15, 3
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = bitcast i16* %29 to i64*
  store i64 %10, i64* %30, align 8
  %31 = getelementptr inbounds i16, i16* %29, i64 4
  %32 = bitcast i16* %31 to i64*
  store i64 %13, i64* %32, align 8
  %33 = ashr exact i64 %14, 30
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %10, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %34, i64 4
  %37 = bitcast i16* %36 to i64*
  store i64 %13, i64* %37, align 8
  %38 = mul nsw i64 %15, 5
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %10, i64* %40, align 8
  %41 = getelementptr inbounds i16, i16* %39, i64 4
  %42 = bitcast i16* %41 to i64*
  store i64 %13, i64* %42, align 8
  %43 = mul nsw i64 %15, 6
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %10, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 %13, i64* %47, align 8
  %48 = mul nsw i64 %15, 7
  %49 = getelementptr inbounds i16, i16* %3, i64 %48
  %50 = bitcast i16* %49 to i64*
  store i64 %10, i64* %50, align 8
  %51 = getelementptr inbounds i16, i16* %49, i64 4
  %52 = bitcast i16* %51 to i64*
  store i64 %13, i64* %52, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_horizontal_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = mul nuw i64 %8, 281479271743489
  %10 = bitcast i8* %0 to i64*
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to i64*
  store i64 %9, i64* %12, align 8
  %13 = add nsw i64 %4, -1
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = mul nuw i64 %16, 281479271743489
  %18 = getelementptr inbounds i16, i16* %3, i64 %4
  %19 = bitcast i16* %18 to i64*
  store i64 %17, i64* %19, align 8
  %20 = getelementptr inbounds i16, i16* %18, i64 4
  %21 = bitcast i16* %20 to i64*
  store i64 %17, i64* %21, align 8
  %22 = and i64 %1, -2
  %23 = add nsw i64 %22, -1
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = mul nuw i64 %26, 281479271743489
  %28 = getelementptr inbounds i16, i16* %3, i64 %22
  %29 = bitcast i16* %28 to i64*
  store i64 %27, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 %27, i64* %31, align 8
  %32 = mul nsw i64 %4, 3
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = mul nuw i64 %36, 281479271743489
  %38 = getelementptr inbounds i16, i16* %3, i64 %32
  %39 = bitcast i16* %38 to i64*
  store i64 %37, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %38, i64 4
  %41 = bitcast i16* %40 to i64*
  store i64 %37, i64* %41, align 8
  %42 = shl nsw i64 %4, 2
  %43 = add nsw i64 %42, -1
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i64
  %47 = mul nuw i64 %46, 281479271743489
  %48 = getelementptr inbounds i16, i16* %3, i64 %42
  %49 = bitcast i16* %48 to i64*
  store i64 %47, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %48, i64 4
  %51 = bitcast i16* %50 to i64*
  store i64 %47, i64* %51, align 8
  %52 = mul nsw i64 %4, 5
  %53 = add nsw i64 %52, -1
  %54 = getelementptr inbounds i16, i16* %3, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i64
  %57 = mul nuw i64 %56, 281479271743489
  %58 = getelementptr inbounds i16, i16* %3, i64 %52
  %59 = bitcast i16* %58 to i64*
  store i64 %57, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %58, i64 4
  %61 = bitcast i16* %60 to i64*
  store i64 %57, i64* %61, align 8
  %62 = mul nsw i64 %4, 6
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = mul nuw i64 %66, 281479271743489
  %68 = getelementptr inbounds i16, i16* %3, i64 %62
  %69 = bitcast i16* %68 to i64*
  store i64 %67, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 %67, i64* %71, align 8
  %72 = mul nsw i64 %4, 7
  %73 = add nsw i64 %72, -1
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i64
  %77 = mul nuw i64 %76, 281479271743489
  %78 = getelementptr inbounds i16, i16* %3, i64 %72
  %79 = bitcast i16* %78 to i64*
  store i64 %77, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %77, i64* %81, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_vertical_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds i16, i16* %8, i64 4
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = shl i64 %4, 32
  %15 = ashr exact i64 %14, 32
  %16 = bitcast i8* %0 to i64*
  store i64 %10, i64* %16, align 8
  %17 = getelementptr inbounds i8, i8* %0, i64 8
  %18 = bitcast i8* %17 to i64*
  store i64 %13, i64* %18, align 8
  %19 = getelementptr inbounds i16, i16* %3, i64 %15
  %20 = bitcast i16* %19 to i64*
  store i64 %10, i64* %20, align 8
  %21 = getelementptr inbounds i16, i16* %19, i64 4
  %22 = bitcast i16* %21 to i64*
  store i64 %13, i64* %22, align 8
  %23 = ashr exact i64 %14, 31
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to i64*
  store i64 %10, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %24, i64 4
  %27 = bitcast i16* %26 to i64*
  store i64 %13, i64* %27, align 8
  %28 = mul nsw i64 %15, 3
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = bitcast i16* %29 to i64*
  store i64 %10, i64* %30, align 8
  %31 = getelementptr inbounds i16, i16* %29, i64 4
  %32 = bitcast i16* %31 to i64*
  store i64 %13, i64* %32, align 8
  %33 = ashr exact i64 %14, 30
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %10, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %34, i64 4
  %37 = bitcast i16* %36 to i64*
  store i64 %13, i64* %37, align 8
  %38 = mul nsw i64 %15, 5
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %10, i64* %40, align 8
  %41 = getelementptr inbounds i16, i16* %39, i64 4
  %42 = bitcast i16* %41 to i64*
  store i64 %13, i64* %42, align 8
  %43 = mul nsw i64 %15, 6
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %10, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 %13, i64* %47, align 8
  %48 = mul nsw i64 %15, 7
  %49 = getelementptr inbounds i16, i16* %3, i64 %48
  %50 = bitcast i16* %49 to i64*
  store i64 %10, i64* %50, align 8
  %51 = getelementptr inbounds i16, i16* %49, i64 4
  %52 = bitcast i16* %51 to i64*
  store i64 %13, i64* %52, align 8
  %53 = ashr exact i64 %14, 29
  %54 = getelementptr inbounds i16, i16* %3, i64 %53
  %55 = bitcast i16* %54 to i64*
  store i64 %10, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %54, i64 4
  %57 = bitcast i16* %56 to i64*
  store i64 %13, i64* %57, align 8
  %58 = mul nsw i64 %15, 9
  %59 = getelementptr inbounds i16, i16* %3, i64 %58
  %60 = bitcast i16* %59 to i64*
  store i64 %10, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %59, i64 4
  %62 = bitcast i16* %61 to i64*
  store i64 %13, i64* %62, align 8
  %63 = mul nsw i64 %15, 10
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = bitcast i16* %64 to i64*
  store i64 %10, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %64, i64 4
  %67 = bitcast i16* %66 to i64*
  store i64 %13, i64* %67, align 8
  %68 = mul nsw i64 %15, 11
  %69 = getelementptr inbounds i16, i16* %3, i64 %68
  %70 = bitcast i16* %69 to i64*
  store i64 %10, i64* %70, align 8
  %71 = getelementptr inbounds i16, i16* %69, i64 4
  %72 = bitcast i16* %71 to i64*
  store i64 %13, i64* %72, align 8
  %73 = mul nsw i64 %15, 12
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = bitcast i16* %74 to i64*
  store i64 %10, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %13, i64* %77, align 8
  %78 = mul nsw i64 %15, 13
  %79 = getelementptr inbounds i16, i16* %3, i64 %78
  %80 = bitcast i16* %79 to i64*
  store i64 %10, i64* %80, align 8
  %81 = getelementptr inbounds i16, i16* %79, i64 4
  %82 = bitcast i16* %81 to i64*
  store i64 %13, i64* %82, align 8
  %83 = mul nsw i64 %15, 14
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = bitcast i16* %84 to i64*
  store i64 %10, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 %13, i64* %87, align 8
  %88 = mul nsw i64 %15, 15
  %89 = getelementptr inbounds i16, i16* %3, i64 %88
  %90 = bitcast i16* %89 to i64*
  store i64 %10, i64* %90, align 8
  %91 = getelementptr inbounds i16, i16* %89, i64 4
  %92 = bitcast i16* %91 to i64*
  store i64 %13, i64* %92, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_horizontal_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = mul nuw i64 %8, 281479271743489
  %10 = bitcast i8* %0 to i64*
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to i64*
  store i64 %9, i64* %12, align 8
  %13 = add nsw i64 %4, -1
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = mul nuw i64 %16, 281479271743489
  %18 = getelementptr inbounds i16, i16* %3, i64 %4
  %19 = bitcast i16* %18 to i64*
  store i64 %17, i64* %19, align 8
  %20 = getelementptr inbounds i16, i16* %18, i64 4
  %21 = bitcast i16* %20 to i64*
  store i64 %17, i64* %21, align 8
  %22 = and i64 %1, -2
  %23 = add nsw i64 %22, -1
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = mul nuw i64 %26, 281479271743489
  %28 = getelementptr inbounds i16, i16* %3, i64 %22
  %29 = bitcast i16* %28 to i64*
  store i64 %27, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 %27, i64* %31, align 8
  %32 = mul nsw i64 %4, 3
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = mul nuw i64 %36, 281479271743489
  %38 = getelementptr inbounds i16, i16* %3, i64 %32
  %39 = bitcast i16* %38 to i64*
  store i64 %37, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %38, i64 4
  %41 = bitcast i16* %40 to i64*
  store i64 %37, i64* %41, align 8
  %42 = shl nsw i64 %4, 2
  %43 = add nsw i64 %42, -1
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i64
  %47 = mul nuw i64 %46, 281479271743489
  %48 = getelementptr inbounds i16, i16* %3, i64 %42
  %49 = bitcast i16* %48 to i64*
  store i64 %47, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %48, i64 4
  %51 = bitcast i16* %50 to i64*
  store i64 %47, i64* %51, align 8
  %52 = mul nsw i64 %4, 5
  %53 = add nsw i64 %52, -1
  %54 = getelementptr inbounds i16, i16* %3, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i64
  %57 = mul nuw i64 %56, 281479271743489
  %58 = getelementptr inbounds i16, i16* %3, i64 %52
  %59 = bitcast i16* %58 to i64*
  store i64 %57, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %58, i64 4
  %61 = bitcast i16* %60 to i64*
  store i64 %57, i64* %61, align 8
  %62 = mul nsw i64 %4, 6
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = mul nuw i64 %66, 281479271743489
  %68 = getelementptr inbounds i16, i16* %3, i64 %62
  %69 = bitcast i16* %68 to i64*
  store i64 %67, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 %67, i64* %71, align 8
  %72 = mul nsw i64 %4, 7
  %73 = add nsw i64 %72, -1
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i64
  %77 = mul nuw i64 %76, 281479271743489
  %78 = getelementptr inbounds i16, i16* %3, i64 %72
  %79 = bitcast i16* %78 to i64*
  store i64 %77, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %77, i64* %81, align 8
  %82 = shl nsw i64 %4, 3
  %83 = add nsw i64 %82, -1
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i64
  %87 = mul nuw i64 %86, 281479271743489
  %88 = getelementptr inbounds i16, i16* %3, i64 %82
  %89 = bitcast i16* %88 to i64*
  store i64 %87, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %88, i64 4
  %91 = bitcast i16* %90 to i64*
  store i64 %87, i64* %91, align 8
  %92 = mul nsw i64 %4, 9
  %93 = add nsw i64 %92, -1
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i64
  %97 = mul nuw i64 %96, 281479271743489
  %98 = getelementptr inbounds i16, i16* %3, i64 %92
  %99 = bitcast i16* %98 to i64*
  store i64 %97, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %98, i64 4
  %101 = bitcast i16* %100 to i64*
  store i64 %97, i64* %101, align 8
  %102 = mul nsw i64 %4, 10
  %103 = add nsw i64 %102, -1
  %104 = getelementptr inbounds i16, i16* %3, i64 %103
  %105 = load i16, i16* %104, align 2
  %106 = zext i16 %105 to i64
  %107 = mul nuw i64 %106, 281479271743489
  %108 = getelementptr inbounds i16, i16* %3, i64 %102
  %109 = bitcast i16* %108 to i64*
  store i64 %107, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 %107, i64* %111, align 8
  %112 = mul nsw i64 %4, 11
  %113 = add nsw i64 %112, -1
  %114 = getelementptr inbounds i16, i16* %3, i64 %113
  %115 = load i16, i16* %114, align 2
  %116 = zext i16 %115 to i64
  %117 = mul nuw i64 %116, 281479271743489
  %118 = getelementptr inbounds i16, i16* %3, i64 %112
  %119 = bitcast i16* %118 to i64*
  store i64 %117, i64* %119, align 8
  %120 = getelementptr inbounds i16, i16* %118, i64 4
  %121 = bitcast i16* %120 to i64*
  store i64 %117, i64* %121, align 8
  %122 = mul nsw i64 %4, 12
  %123 = add nsw i64 %122, -1
  %124 = getelementptr inbounds i16, i16* %3, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i64
  %127 = mul nuw i64 %126, 281479271743489
  %128 = getelementptr inbounds i16, i16* %3, i64 %122
  %129 = bitcast i16* %128 to i64*
  store i64 %127, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %127, i64* %131, align 8
  %132 = mul nsw i64 %4, 13
  %133 = add nsw i64 %132, -1
  %134 = getelementptr inbounds i16, i16* %3, i64 %133
  %135 = load i16, i16* %134, align 2
  %136 = zext i16 %135 to i64
  %137 = mul nuw i64 %136, 281479271743489
  %138 = getelementptr inbounds i16, i16* %3, i64 %132
  %139 = bitcast i16* %138 to i64*
  store i64 %137, i64* %139, align 8
  %140 = getelementptr inbounds i16, i16* %138, i64 4
  %141 = bitcast i16* %140 to i64*
  store i64 %137, i64* %141, align 8
  %142 = mul nsw i64 %4, 14
  %143 = add nsw i64 %142, -1
  %144 = getelementptr inbounds i16, i16* %3, i64 %143
  %145 = load i16, i16* %144, align 2
  %146 = zext i16 %145 to i64
  %147 = mul nuw i64 %146, 281479271743489
  %148 = getelementptr inbounds i16, i16* %3, i64 %142
  %149 = bitcast i16* %148 to i64*
  store i64 %147, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %148, i64 4
  %151 = bitcast i16* %150 to i64*
  store i64 %147, i64* %151, align 8
  %152 = mul nsw i64 %4, 15
  %153 = add nsw i64 %152, -1
  %154 = getelementptr inbounds i16, i16* %3, i64 %153
  %155 = load i16, i16* %154, align 2
  %156 = zext i16 %155 to i64
  %157 = mul nuw i64 %156, 281479271743489
  %158 = getelementptr inbounds i16, i16* %3, i64 %152
  %159 = bitcast i16* %158 to i64*
  store i64 %157, i64* %159, align 8
  %160 = getelementptr inbounds i16, i16* %158, i64 4
  %161 = bitcast i16* %160 to i64*
  store i64 %157, i64* %161, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_plane_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 6
  %6 = bitcast i8* %5 to i16*
  %7 = shl i64 %4, 32
  %8 = ashr exact i64 %7, 32
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i16, i16* %6, i64 %9
  %11 = shl i64 %4, 34
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = getelementptr inbounds i16, i16* %13, i64 -1
  %15 = shl i64 %1, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = sub nsw i64 0, %17
  %19 = getelementptr inbounds i16, i16* %14, i64 %18
  %20 = getelementptr inbounds i16, i16* %10, i64 1
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = getelementptr inbounds i16, i16* %10, i64 -1
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = sub nsw i32 %22, %25
  %27 = load i16, i16* %14, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %19, align 2
  %30 = zext i16 %29 to i32
  %31 = sub nsw i32 %28, %30
  %32 = shl i64 %4, 32
  %33 = ashr exact i64 %32, 32
  %34 = mul nsw i64 %33, 6
  %35 = shl i64 %4, 34
  %36 = ashr exact i64 %35, 31
  %37 = add nsw i64 %34, %36
  %38 = add nsw i64 %37, -2
  %39 = getelementptr i8, i8* %0, i64 %38
  %40 = add nsw i64 %36, -2
  %41 = shl i64 %1, 32
  %42 = ashr exact i64 %41, 32
  %43 = lshr i64 %42, 1
  %44 = shl i64 %43, 2
  %45 = sub i64 %40, %44
  %46 = sub i64 %45, %34
  %47 = getelementptr i8, i8* %0, i64 %46
  %48 = getelementptr inbounds i16, i16* %14, i64 %8
  %49 = getelementptr inbounds i16, i16* %19, i64 %9
  %50 = getelementptr inbounds i16, i16* %10, i64 2
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i32
  %53 = getelementptr inbounds i16, i16* %10, i64 -2
  %54 = load i16, i16* %53, align 2
  %55 = zext i16 %54 to i32
  %56 = sub nsw i32 %52, %55
  %57 = shl nsw i32 %56, 1
  %58 = add nsw i32 %57, %26
  %59 = load i16, i16* %48, align 2
  %60 = zext i16 %59 to i32
  %61 = load i16, i16* %49, align 2
  %62 = zext i16 %61 to i32
  %63 = sub nsw i32 %60, %62
  %64 = shl nsw i32 %63, 1
  %65 = add nsw i32 %64, %31
  %66 = getelementptr inbounds i16, i16* %48, i64 %8
  %67 = getelementptr inbounds i16, i16* %49, i64 %9
  %68 = getelementptr inbounds i16, i16* %10, i64 3
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i32
  %71 = getelementptr inbounds i16, i16* %10, i64 -3
  %72 = load i16, i16* %71, align 2
  %73 = zext i16 %72 to i32
  %74 = sub nsw i32 %70, %73
  %75 = mul nsw i32 %74, 3
  %76 = add nsw i32 %75, %58
  %77 = load i16, i16* %66, align 2
  %78 = zext i16 %77 to i32
  %79 = load i16, i16* %67, align 2
  %80 = zext i16 %79 to i32
  %81 = sub nsw i32 %78, %80
  %82 = mul nsw i32 %81, 3
  %83 = add nsw i32 %82, %65
  %84 = getelementptr inbounds i16, i16* %66, i64 %8
  %85 = getelementptr inbounds i16, i16* %67, i64 %9
  %86 = getelementptr inbounds i16, i16* %10, i64 4
  %87 = load i16, i16* %86, align 2
  %88 = zext i16 %87 to i32
  %89 = getelementptr inbounds i16, i16* %10, i64 -4
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = sub nsw i32 %88, %91
  %93 = shl nsw i32 %92, 2
  %94 = add nsw i32 %93, %76
  %95 = load i16, i16* %84, align 2
  %96 = zext i16 %95 to i32
  %97 = load i16, i16* %85, align 2
  %98 = zext i16 %97 to i32
  %99 = sub nsw i32 %96, %98
  %100 = shl nsw i32 %99, 2
  %101 = add nsw i32 %100, %83
  %102 = bitcast i8* %39 to i16*
  %103 = mul nsw i32 %94, 17
  %104 = add nsw i32 %103, 16
  %105 = ashr i32 %104, 5
  %106 = mul nsw i32 %101, 17
  %107 = add nsw i32 %106, 16
  %108 = ashr i32 %107, 5
  %109 = load i16, i16* %102, align 2
  %110 = zext i16 %109 to i32
  %111 = getelementptr inbounds i8, i8* %47, i64 16
  %112 = bitcast i8* %111 to i16*
  %113 = load i16, i16* %112, align 2
  %114 = zext i16 %113 to i32
  %115 = add nuw nsw i32 %114, %110
  %116 = shl nuw nsw i32 %115, 4
  %117 = add nsw i32 %108, %105
  %118 = mul nsw i32 %117, -3
  %119 = add nsw i32 %118, 16
  %120 = add nsw i32 %119, %116
  %121 = shl nsw i32 %105, 1
  %122 = mul nsw i32 %105, 3
  %123 = shl nsw i32 %105, 2
  %124 = mul nsw i32 %105, 5
  %125 = mul nsw i32 %105, 6
  %126 = mul nsw i32 %105, 7
  br label %127

127:                                              ; preds = %214, %2
  %128 = phi i32 [ 8, %2 ], [ %219, %214 ]
  %129 = phi i16* [ %3, %2 ], [ %218, %214 ]
  %130 = phi i32 [ %120, %2 ], [ %131, %214 ]
  %131 = add nsw i32 %130, %108
  %132 = ashr i32 %130, 5
  %133 = icmp ult i32 %132, 4096
  br i1 %133, label %138, label %134

134:                                              ; preds = %127
  %135 = ashr i32 %130, 31
  %136 = or i32 %135, -4096
  %137 = xor i32 %136, -1
  br label %138

138:                                              ; preds = %127, %134
  %139 = phi i32 [ %137, %134 ], [ %132, %127 ]
  %140 = trunc i32 %139 to i16
  store i16 %140, i16* %129, align 2
  %141 = add nsw i32 %130, %105
  %142 = ashr i32 %141, 5
  %143 = icmp ult i32 %142, 4096
  br i1 %143, label %148, label %144

144:                                              ; preds = %138
  %145 = ashr i32 %141, 31
  %146 = or i32 %145, -4096
  %147 = xor i32 %146, -1
  br label %148

148:                                              ; preds = %138, %144
  %149 = phi i32 [ %147, %144 ], [ %142, %138 ]
  %150 = trunc i32 %149 to i16
  %151 = getelementptr inbounds i16, i16* %129, i64 1
  store i16 %150, i16* %151, align 2
  %152 = add nsw i32 %130, %121
  %153 = ashr i32 %152, 5
  %154 = icmp ult i32 %153, 4096
  br i1 %154, label %159, label %155

155:                                              ; preds = %148
  %156 = ashr i32 %152, 31
  %157 = or i32 %156, -4096
  %158 = xor i32 %157, -1
  br label %159

159:                                              ; preds = %148, %155
  %160 = phi i32 [ %158, %155 ], [ %153, %148 ]
  %161 = trunc i32 %160 to i16
  %162 = getelementptr inbounds i16, i16* %129, i64 2
  store i16 %161, i16* %162, align 2
  %163 = add nsw i32 %130, %122
  %164 = ashr i32 %163, 5
  %165 = icmp ult i32 %164, 4096
  br i1 %165, label %170, label %166

166:                                              ; preds = %159
  %167 = ashr i32 %163, 31
  %168 = or i32 %167, -4096
  %169 = xor i32 %168, -1
  br label %170

170:                                              ; preds = %159, %166
  %171 = phi i32 [ %169, %166 ], [ %164, %159 ]
  %172 = trunc i32 %171 to i16
  %173 = getelementptr inbounds i16, i16* %129, i64 3
  store i16 %172, i16* %173, align 2
  %174 = add nsw i32 %130, %123
  %175 = ashr i32 %174, 5
  %176 = icmp ult i32 %175, 4096
  br i1 %176, label %181, label %177

177:                                              ; preds = %170
  %178 = ashr i32 %174, 31
  %179 = or i32 %178, -4096
  %180 = xor i32 %179, -1
  br label %181

181:                                              ; preds = %170, %177
  %182 = phi i32 [ %180, %177 ], [ %175, %170 ]
  %183 = trunc i32 %182 to i16
  %184 = getelementptr inbounds i16, i16* %129, i64 4
  store i16 %183, i16* %184, align 2
  %185 = add nsw i32 %130, %124
  %186 = ashr i32 %185, 5
  %187 = icmp ult i32 %186, 4096
  br i1 %187, label %192, label %188

188:                                              ; preds = %181
  %189 = ashr i32 %185, 31
  %190 = or i32 %189, -4096
  %191 = xor i32 %190, -1
  br label %192

192:                                              ; preds = %181, %188
  %193 = phi i32 [ %191, %188 ], [ %186, %181 ]
  %194 = trunc i32 %193 to i16
  %195 = getelementptr inbounds i16, i16* %129, i64 5
  store i16 %194, i16* %195, align 2
  %196 = add nsw i32 %130, %125
  %197 = ashr i32 %196, 5
  %198 = icmp ult i32 %197, 4096
  br i1 %198, label %203, label %199

199:                                              ; preds = %192
  %200 = ashr i32 %196, 31
  %201 = or i32 %200, -4096
  %202 = xor i32 %201, -1
  br label %203

203:                                              ; preds = %192, %199
  %204 = phi i32 [ %202, %199 ], [ %197, %192 ]
  %205 = trunc i32 %204 to i16
  %206 = getelementptr inbounds i16, i16* %129, i64 6
  store i16 %205, i16* %206, align 2
  %207 = add nsw i32 %130, %126
  %208 = ashr i32 %207, 5
  %209 = icmp ult i32 %208, 4096
  br i1 %209, label %214, label %210

210:                                              ; preds = %203
  %211 = ashr i32 %207, 31
  %212 = or i32 %211, -4096
  %213 = xor i32 %212, -1
  br label %214

214:                                              ; preds = %203, %210
  %215 = phi i32 [ %213, %210 ], [ %208, %203 ]
  %216 = trunc i32 %215 to i16
  %217 = getelementptr inbounds i16, i16* %129, i64 7
  store i16 %216, i16* %217, align 2
  %218 = getelementptr inbounds i16, i16* %129, i64 %8
  %219 = add nsw i32 %128, -1
  %220 = icmp eq i32 %219, 0
  br i1 %220, label %221, label %127

221:                                              ; preds = %214
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_plane_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 6
  %6 = bitcast i8* %5 to i16*
  %7 = shl i64 %4, 32
  %8 = ashr exact i64 %7, 32
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i16, i16* %6, i64 %9
  %11 = shl i64 %4, 35
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = getelementptr inbounds i16, i16* %13, i64 -1
  %15 = shl i64 %1, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = sub nsw i64 0, %17
  %19 = getelementptr inbounds i16, i16* %14, i64 %18
  %20 = getelementptr inbounds i16, i16* %10, i64 1
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = getelementptr inbounds i16, i16* %10, i64 -1
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = sub nsw i32 %22, %25
  %27 = shl i64 %4, 35
  %28 = ashr exact i64 %27, 31
  %29 = add nsw i64 %28, -2
  %30 = shl i64 %1, 32
  %31 = ashr exact i64 %30, 32
  %32 = lshr i64 %31, 1
  %33 = shl i64 %32, 2
  %34 = sub i64 %29, %33
  %35 = shl i64 %4, 32
  %36 = ashr exact i64 %35, 32
  %37 = mul nsw i64 %36, 6
  %38 = add nsw i64 %37, %28
  %39 = add nsw i64 %38, -2
  %40 = getelementptr i8, i8* %0, i64 %39
  %41 = sub i64 %34, %37
  %42 = getelementptr i8, i8* %0, i64 %41
  %43 = getelementptr inbounds i16, i16* %14, i64 %8
  %44 = getelementptr inbounds i16, i16* %19, i64 %9
  %45 = getelementptr inbounds i16, i16* %10, i64 2
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i32
  %48 = getelementptr inbounds i16, i16* %10, i64 -2
  %49 = load i16, i16* %48, align 2
  %50 = zext i16 %49 to i32
  %51 = sub nsw i32 %47, %50
  %52 = shl nsw i32 %51, 1
  %53 = add nsw i32 %52, %26
  %54 = getelementptr inbounds i16, i16* %43, i64 %8
  %55 = getelementptr inbounds i16, i16* %44, i64 %9
  %56 = getelementptr inbounds i16, i16* %10, i64 3
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = getelementptr inbounds i16, i16* %10, i64 -3
  %60 = load i16, i16* %59, align 2
  %61 = zext i16 %60 to i32
  %62 = sub nsw i32 %58, %61
  %63 = mul nsw i32 %62, 3
  %64 = add nsw i32 %63, %53
  %65 = getelementptr inbounds i16, i16* %10, i64 4
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = getelementptr inbounds i16, i16* %10, i64 -4
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i32
  %71 = sub nsw i32 %67, %70
  %72 = shl nsw i32 %71, 2
  %73 = add nsw i32 %72, %64
  %74 = bitcast i8* %40 to i16*
  %75 = bitcast i8* %42 to i16*
  %76 = getelementptr inbounds i16, i16* %54, i64 %8
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i32
  %79 = getelementptr inbounds i16, i16* %55, i64 %9
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = sub nsw i32 %78, %81
  %83 = shl nsw i32 %82, 2
  %84 = load i16, i16* %54, align 2
  %85 = zext i16 %84 to i32
  %86 = load i16, i16* %55, align 2
  %87 = zext i16 %86 to i32
  %88 = sub nsw i32 %85, %87
  %89 = mul nsw i32 %88, 3
  %90 = load i16, i16* %43, align 2
  %91 = zext i16 %90 to i32
  %92 = load i16, i16* %44, align 2
  %93 = zext i16 %92 to i32
  %94 = sub nsw i32 %91, %93
  %95 = shl nsw i32 %94, 1
  %96 = load i16, i16* %14, align 2
  %97 = zext i16 %96 to i32
  %98 = load i16, i16* %19, align 2
  %99 = zext i16 %98 to i32
  %100 = sub nsw i32 %97, %99
  %101 = add nsw i32 %95, %100
  %102 = add nsw i32 %89, %101
  %103 = add nsw i32 %83, %102
  %104 = ashr exact i64 %35, 30
  %105 = mul nsw i64 %36, -3
  %106 = getelementptr inbounds i16, i16* %74, i64 %8
  %107 = getelementptr inbounds i16, i16* %75, i64 %9
  %108 = load i16, i16* %106, align 2
  %109 = zext i16 %108 to i32
  %110 = load i16, i16* %107, align 2
  %111 = zext i16 %110 to i32
  %112 = sub nsw i32 %109, %111
  %113 = mul nsw i32 %112, 5
  %114 = add nsw i32 %113, %103
  %115 = getelementptr inbounds i16, i16* %106, i64 %8
  %116 = getelementptr inbounds i16, i16* %107, i64 %9
  %117 = load i16, i16* %115, align 2
  %118 = zext i16 %117 to i32
  %119 = load i16, i16* %116, align 2
  %120 = zext i16 %119 to i32
  %121 = sub nsw i32 %118, %120
  %122 = mul nsw i32 %121, 6
  %123 = add nsw i32 %122, %114
  %124 = getelementptr inbounds i16, i16* %115, i64 %8
  %125 = getelementptr inbounds i16, i16* %116, i64 %9
  %126 = load i16, i16* %124, align 2
  %127 = zext i16 %126 to i32
  %128 = load i16, i16* %125, align 2
  %129 = zext i16 %128 to i32
  %130 = sub nsw i32 %127, %129
  %131 = mul nsw i32 %130, 7
  %132 = add nsw i32 %131, %123
  %133 = getelementptr inbounds i16, i16* %124, i64 %8
  %134 = getelementptr inbounds i16, i16* %125, i64 %9
  %135 = load i16, i16* %133, align 2
  %136 = zext i16 %135 to i32
  %137 = load i16, i16* %134, align 2
  %138 = zext i16 %137 to i32
  %139 = sub nsw i32 %136, %138
  %140 = shl nsw i32 %139, 3
  %141 = add nsw i32 %140, %132
  %142 = getelementptr i16, i16* %75, i64 %105
  %143 = getelementptr i16, i16* %74, i64 %104
  %144 = mul i32 %141, 5
  %145 = add i32 %144, 32
  %146 = ashr i32 %145, 6
  %147 = getelementptr inbounds i16, i16* %142, i64 %9
  %148 = mul nsw i32 %73, 17
  %149 = add nsw i32 %148, 16
  %150 = ashr i32 %149, 5
  %151 = load i16, i16* %143, align 2
  %152 = zext i16 %151 to i32
  %153 = getelementptr inbounds i16, i16* %147, i64 8
  %154 = load i16, i16* %153, align 2
  %155 = zext i16 %154 to i32
  %156 = add nuw nsw i32 %155, %152
  %157 = shl nuw nsw i32 %156, 4
  %158 = mul nsw i32 %146, -7
  %159 = mul nsw i32 %150, 3
  %160 = sub nsw i32 16, %159
  %161 = add nsw i32 %160, %158
  %162 = add nsw i32 %161, %157
  %163 = shl nsw i32 %150, 1
  %164 = shl nsw i32 %150, 2
  %165 = mul nsw i32 %150, 5
  %166 = mul nsw i32 %150, 6
  %167 = mul nsw i32 %150, 7
  br label %168

168:                                              ; preds = %255, %2
  %169 = phi i32 [ 16, %2 ], [ %260, %255 ]
  %170 = phi i16* [ %3, %2 ], [ %259, %255 ]
  %171 = phi i32 [ %162, %2 ], [ %172, %255 ]
  %172 = add nsw i32 %171, %146
  %173 = ashr i32 %171, 5
  %174 = icmp ult i32 %173, 4096
  br i1 %174, label %179, label %175

175:                                              ; preds = %168
  %176 = ashr i32 %171, 31
  %177 = or i32 %176, -4096
  %178 = xor i32 %177, -1
  br label %179

179:                                              ; preds = %168, %175
  %180 = phi i32 [ %178, %175 ], [ %173, %168 ]
  %181 = trunc i32 %180 to i16
  store i16 %181, i16* %170, align 2
  %182 = add nsw i32 %171, %150
  %183 = ashr i32 %182, 5
  %184 = icmp ult i32 %183, 4096
  br i1 %184, label %189, label %185

185:                                              ; preds = %179
  %186 = ashr i32 %182, 31
  %187 = or i32 %186, -4096
  %188 = xor i32 %187, -1
  br label %189

189:                                              ; preds = %179, %185
  %190 = phi i32 [ %188, %185 ], [ %183, %179 ]
  %191 = trunc i32 %190 to i16
  %192 = getelementptr inbounds i16, i16* %170, i64 1
  store i16 %191, i16* %192, align 2
  %193 = add nsw i32 %171, %163
  %194 = ashr i32 %193, 5
  %195 = icmp ult i32 %194, 4096
  br i1 %195, label %200, label %196

196:                                              ; preds = %189
  %197 = ashr i32 %193, 31
  %198 = or i32 %197, -4096
  %199 = xor i32 %198, -1
  br label %200

200:                                              ; preds = %189, %196
  %201 = phi i32 [ %199, %196 ], [ %194, %189 ]
  %202 = trunc i32 %201 to i16
  %203 = getelementptr inbounds i16, i16* %170, i64 2
  store i16 %202, i16* %203, align 2
  %204 = add nsw i32 %171, %159
  %205 = ashr i32 %204, 5
  %206 = icmp ult i32 %205, 4096
  br i1 %206, label %211, label %207

207:                                              ; preds = %200
  %208 = ashr i32 %204, 31
  %209 = or i32 %208, -4096
  %210 = xor i32 %209, -1
  br label %211

211:                                              ; preds = %200, %207
  %212 = phi i32 [ %210, %207 ], [ %205, %200 ]
  %213 = trunc i32 %212 to i16
  %214 = getelementptr inbounds i16, i16* %170, i64 3
  store i16 %213, i16* %214, align 2
  %215 = add nsw i32 %171, %164
  %216 = ashr i32 %215, 5
  %217 = icmp ult i32 %216, 4096
  br i1 %217, label %222, label %218

218:                                              ; preds = %211
  %219 = ashr i32 %215, 31
  %220 = or i32 %219, -4096
  %221 = xor i32 %220, -1
  br label %222

222:                                              ; preds = %211, %218
  %223 = phi i32 [ %221, %218 ], [ %216, %211 ]
  %224 = trunc i32 %223 to i16
  %225 = getelementptr inbounds i16, i16* %170, i64 4
  store i16 %224, i16* %225, align 2
  %226 = add nsw i32 %171, %165
  %227 = ashr i32 %226, 5
  %228 = icmp ult i32 %227, 4096
  br i1 %228, label %233, label %229

229:                                              ; preds = %222
  %230 = ashr i32 %226, 31
  %231 = or i32 %230, -4096
  %232 = xor i32 %231, -1
  br label %233

233:                                              ; preds = %222, %229
  %234 = phi i32 [ %232, %229 ], [ %227, %222 ]
  %235 = trunc i32 %234 to i16
  %236 = getelementptr inbounds i16, i16* %170, i64 5
  store i16 %235, i16* %236, align 2
  %237 = add nsw i32 %171, %166
  %238 = ashr i32 %237, 5
  %239 = icmp ult i32 %238, 4096
  br i1 %239, label %244, label %240

240:                                              ; preds = %233
  %241 = ashr i32 %237, 31
  %242 = or i32 %241, -4096
  %243 = xor i32 %242, -1
  br label %244

244:                                              ; preds = %233, %240
  %245 = phi i32 [ %243, %240 ], [ %238, %233 ]
  %246 = trunc i32 %245 to i16
  %247 = getelementptr inbounds i16, i16* %170, i64 6
  store i16 %246, i16* %247, align 2
  %248 = add nsw i32 %171, %167
  %249 = ashr i32 %248, 5
  %250 = icmp ult i32 %249, 4096
  br i1 %250, label %255, label %251

251:                                              ; preds = %244
  %252 = ashr i32 %248, 31
  %253 = or i32 %252, -4096
  %254 = xor i32 %253, -1
  br label %255

255:                                              ; preds = %244, %251
  %256 = phi i32 [ %254, %251 ], [ %249, %244 ]
  %257 = trunc i32 %256 to i16
  %258 = getelementptr inbounds i16, i16* %170, i64 7
  store i16 %257, i16* %258, align 2
  %259 = getelementptr inbounds i16, i16* %170, i64 %8
  %260 = add nsw i32 %169, -1
  %261 = icmp eq i32 %260, 0
  br i1 %261, label %262, label %168

262:                                              ; preds = %255
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_dc_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 0, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = sub nsw i64 4, %4
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = shl nsw i64 %4, 2
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = add nsw i64 %4, -1
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = sub nsw i64 1, %4
  %28 = getelementptr inbounds i16, i16* %3, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = zext i16 %29 to i64
  %31 = add nuw nsw i64 %13, %26
  %32 = add nuw nsw i64 %31, %30
  %33 = sub nsw i64 5, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = add nuw nsw i32 %17, %36
  %38 = mul nsw i64 %4, 5
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i32
  %43 = add nuw nsw i32 %22, %42
  %44 = and i64 %1, -2
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = sub nsw i64 2, %4
  %50 = getelementptr inbounds i16, i16* %3, i64 %49
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i64
  %53 = add nuw nsw i64 %32, %48
  %54 = add nuw nsw i64 %53, %52
  %55 = sub nsw i64 6, %4
  %56 = getelementptr inbounds i16, i16* %3, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %37, %58
  %60 = mul nsw i64 %4, 6
  %61 = add nsw i64 %60, -1
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = load i16, i16* %62, align 2
  %64 = zext i16 %63 to i32
  %65 = add nuw nsw i32 %43, %64
  %66 = mul nsw i64 %4, 3
  %67 = add nsw i64 %66, -1
  %68 = getelementptr inbounds i16, i16* %3, i64 %67
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i64
  %71 = sub nsw i64 3, %4
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = load i16, i16* %72, align 2
  %74 = zext i16 %73 to i64
  %75 = add nuw nsw i64 %54, %70
  %76 = add nuw nsw i64 %75, %74
  %77 = sub nsw i64 7, %4
  %78 = getelementptr inbounds i16, i16* %3, i64 %77
  %79 = load i16, i16* %78, align 2
  %80 = zext i16 %79 to i32
  %81 = add nuw nsw i32 %59, %80
  %82 = mul nsw i64 %4, 7
  %83 = add nsw i64 %82, -1
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i32
  %87 = add nuw nsw i32 %65, %86
  %88 = add nuw nsw i64 %76, 4
  %89 = lshr i64 %88, 3
  %90 = and i64 %89, 536870911
  %91 = mul i64 %90, 281479271743489
  %92 = add nuw nsw i32 %81, 2
  %93 = lshr i32 %92, 2
  %94 = zext i32 %93 to i64
  %95 = mul i64 %94, 281479271743489
  %96 = add nuw nsw i32 %87, 2
  %97 = lshr i32 %96, 2
  %98 = zext i32 %97 to i64
  %99 = add nuw nsw i32 %81, 4
  %100 = add nuw nsw i32 %99, %87
  %101 = lshr i32 %100, 3
  %102 = zext i32 %101 to i64
  %103 = bitcast i8* %0 to i64*
  store i64 %91, i64* %103, align 8
  %104 = getelementptr inbounds i8, i8* %0, i64 8
  %105 = bitcast i8* %104 to i64*
  store i64 %95, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %3, i64 %4
  %107 = bitcast i16* %106 to i64*
  store i64 %91, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %106, i64 4
  %109 = bitcast i16* %108 to i64*
  store i64 %95, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %3, i64 %44
  %111 = bitcast i16* %110 to i64*
  store i64 %91, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %110, i64 4
  %113 = bitcast i16* %112 to i64*
  store i64 %95, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %3, i64 %66
  %115 = bitcast i16* %114 to i64*
  store i64 %91, i64* %115, align 8
  %116 = getelementptr inbounds i16, i16* %114, i64 4
  %117 = bitcast i16* %116 to i64*
  store i64 %95, i64* %117, align 8
  %118 = mul i64 %98, 281479271743489
  %119 = mul i64 %102, 281479271743489
  %120 = getelementptr inbounds i16, i16* %3, i64 %18
  %121 = bitcast i16* %120 to i64*
  store i64 %118, i64* %121, align 8
  %122 = getelementptr inbounds i16, i16* %120, i64 4
  %123 = bitcast i16* %122 to i64*
  store i64 %119, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %3, i64 %38
  %125 = bitcast i16* %124 to i64*
  store i64 %118, i64* %125, align 8
  %126 = getelementptr inbounds i16, i16* %124, i64 4
  %127 = bitcast i16* %126 to i64*
  store i64 %119, i64* %127, align 8
  %128 = getelementptr inbounds i16, i16* %3, i64 %60
  %129 = bitcast i16* %128 to i64*
  store i64 %118, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %119, i64* %131, align 8
  %132 = getelementptr inbounds i16, i16* %3, i64 %82
  %133 = bitcast i16* %132 to i64*
  store i64 %118, i64* %133, align 8
  %134 = getelementptr inbounds i16, i16* %132, i64 4
  %135 = bitcast i16* %134 to i64*
  store i64 %119, i64* %135, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_left_dc_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = add nuw nsw i64 %8, %17
  %19 = mul nsw i64 %4, 5
  %20 = add nsw i64 %19, -1
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i64
  %24 = add nuw nsw i64 %13, %23
  %25 = and i64 %1, -2
  %26 = add nsw i64 %25, -1
  %27 = getelementptr inbounds i16, i16* %3, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i64
  %30 = add nuw nsw i64 %18, %29
  %31 = mul nsw i64 %4, 6
  %32 = add nsw i64 %31, -1
  %33 = getelementptr inbounds i16, i16* %3, i64 %32
  %34 = load i16, i16* %33, align 2
  %35 = zext i16 %34 to i64
  %36 = add nuw nsw i64 %24, %35
  %37 = mul nsw i64 %4, 3
  %38 = add nsw i64 %37, -1
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i64
  %42 = add nuw nsw i64 %30, %41
  %43 = mul nsw i64 %4, 7
  %44 = add nsw i64 %43, -1
  %45 = getelementptr inbounds i16, i16* %3, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i64
  %48 = add nuw nsw i64 %36, %47
  %49 = add nuw nsw i64 %42, 2
  %50 = lshr i64 %49, 2
  %51 = mul i64 %50, 281479271743489
  %52 = add nuw nsw i64 %48, 2
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  store i64 %51, i64* %54, align 8
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  store i64 %51, i64* %56, align 8
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %51, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %51, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %25
  %62 = bitcast i16* %61 to i64*
  store i64 %51, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %51, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %37
  %66 = bitcast i16* %65 to i64*
  store i64 %51, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %51, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %19
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %31
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %43
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_top_dc_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = add nuw nsw i64 %8, %16
  %18 = sub nsw i64 5, %4
  %19 = getelementptr inbounds i16, i16* %3, i64 %18
  %20 = load i16, i16* %19, align 2
  %21 = zext i16 %20 to i64
  %22 = add nuw nsw i64 %12, %21
  %23 = sub nsw i64 2, %4
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = add nuw nsw i64 %17, %26
  %28 = sub nsw i64 6, %4
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i64
  %32 = add nuw nsw i64 %22, %31
  %33 = sub nsw i64 3, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %27, %36
  %38 = sub nsw i64 7, %4
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i64
  %42 = add nuw nsw i64 %32, %41
  %43 = add nuw nsw i64 %37, 2
  %44 = lshr i64 %43, 2
  %45 = mul i64 %44, 281479271743489
  %46 = add nuw nsw i64 %42, 2
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %45, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %45, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %45, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %45, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %45, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %45, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %45, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %45, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_l0t_12(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = sub nsw i64 5, %4
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub nsw i64 2, %4
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = sub nsw i64 6, %4
  %26 = getelementptr inbounds i16, i16* %3, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i64
  %29 = sub nsw i64 3, %4
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = sub nsw i64 7, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %8, 2
  %38 = add nuw nsw i64 %37, %16
  %39 = add nuw nsw i64 %38, %24
  %40 = add nuw nsw i64 %39, %32
  %41 = lshr i64 %40, 2
  %42 = mul i64 %41, 281479271743489
  %43 = add nuw nsw i64 %12, 2
  %44 = add nuw nsw i64 %43, %20
  %45 = add nuw nsw i64 %44, %28
  %46 = add nuw nsw i64 %45, %36
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %42, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %42, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %42, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %42, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %42, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %42, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %42, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %42, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  %86 = lshr i64 %1, 1
  %87 = trunc i64 %86 to i32
  %88 = shl i64 %86, 32
  %89 = sub i64 0, %88
  %90 = ashr exact i64 %89, 32
  %91 = getelementptr inbounds i16, i16* %3, i64 %90
  %92 = load i16, i16* %91, align 2
  %93 = zext i16 %92 to i32
  %94 = sub i64 4294967296, %88
  %95 = ashr exact i64 %94, 32
  %96 = getelementptr inbounds i16, i16* %3, i64 %95
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i32
  %99 = sub i64 8589934592, %88
  %100 = ashr exact i64 %99, 32
  %101 = getelementptr inbounds i16, i16* %3, i64 %100
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  %104 = sub i64 12884901888, %88
  %105 = ashr exact i64 %104, 32
  %106 = getelementptr inbounds i16, i16* %3, i64 %105
  %107 = load i16, i16* %106, align 2
  %108 = zext i16 %107 to i32
  %109 = getelementptr inbounds i8, i8* %0, i64 -2
  %110 = bitcast i8* %109 to i16*
  %111 = load i16, i16* %110, align 2
  %112 = zext i16 %111 to i32
  %113 = add i64 %88, -4294967296
  %114 = ashr exact i64 %113, 32
  %115 = getelementptr inbounds i16, i16* %3, i64 %114
  %116 = load i16, i16* %115, align 2
  %117 = zext i16 %116 to i32
  %118 = trunc i64 %1 to i32
  %119 = and i32 %118, -2
  %120 = add nsw i32 %119, -1
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds i16, i16* %3, i64 %121
  %123 = load i16, i16* %122, align 2
  %124 = zext i16 %123 to i32
  %125 = mul nsw i32 %87, 3
  %126 = add nsw i32 %125, -1
  %127 = sext i32 %126 to i64
  %128 = getelementptr inbounds i16, i16* %3, i64 %127
  %129 = load i16, i16* %128, align 2
  %130 = zext i16 %129 to i32
  %131 = add nuw nsw i32 %93, 4
  %132 = add nuw nsw i32 %131, %98
  %133 = add nuw nsw i32 %132, %103
  %134 = add nuw nsw i32 %133, %108
  %135 = add nuw nsw i32 %134, %112
  %136 = add nuw nsw i32 %135, %117
  %137 = add nuw nsw i32 %136, %124
  %138 = add nuw nsw i32 %137, %130
  %139 = ashr i32 %138, 3
  %140 = sext i32 %139 to i64
  %141 = mul i64 %140, 281479271743489
  store i64 %141, i64* %49, align 8
  %142 = ashr exact i64 %88, 32
  %143 = getelementptr inbounds i16, i16* %3, i64 %142
  %144 = bitcast i16* %143 to i64*
  store i64 %141, i64* %144, align 8
  %145 = sext i32 %119 to i64
  %146 = getelementptr inbounds i16, i16* %3, i64 %145
  %147 = bitcast i16* %146 to i64*
  store i64 %141, i64* %147, align 8
  %148 = sext i32 %125 to i64
  %149 = getelementptr inbounds i16, i16* %3, i64 %148
  %150 = bitcast i16* %149 to i64*
  store i64 %141, i64* %150, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_0lt_12(i8* nocapture, i64) #1 {
  tail call void @pred8x8_dc_12_c(i8* %0, i64 %1)
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = sub i64 0, %5
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = sub i64 4294967296, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = load i16, i16* %13, align 2
  %15 = zext i16 %14 to i64
  %16 = sub i64 8589934592, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub i64 12884901888, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i16, i16* %3, i64 %22
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i64
  %26 = add nuw nsw i64 %10, 2
  %27 = add nuw nsw i64 %26, %15
  %28 = add nuw nsw i64 %27, %20
  %29 = add nuw nsw i64 %28, %25
  %30 = lshr i64 %29, 2
  %31 = mul i64 %30, 281479271743489
  %32 = bitcast i8* %0 to i64*
  store i64 %31, i64* %32, align 8
  %33 = ashr exact i64 %5, 32
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %31, i64* %35, align 8
  %36 = shl i64 %1, 32
  %37 = ashr exact i64 %36, 32
  %38 = and i64 %37, -2
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %31, i64* %40, align 8
  %41 = mul i64 %4, 12884901888
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds i16, i16* %3, i64 %42
  %44 = bitcast i16* %43 to i64*
  store i64 %31, i64* %44, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_l00_12(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = mul nsw i64 %4, 5
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = and i64 %1, -2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = mul nsw i64 %4, 6
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = mul nsw i64 %4, 3
  %34 = add nsw i64 %33, -1
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = mul nsw i64 %4, 7
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %8, 2
  %44 = add nuw nsw i64 %43, %17
  %45 = add nuw nsw i64 %44, %27
  %46 = add nuw nsw i64 %45, %37
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = add nuw nsw i64 %13, 2
  %50 = add nuw nsw i64 %49, %22
  %51 = add nuw nsw i64 %50, %32
  %52 = add nuw nsw i64 %51, %42
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  store i64 %48, i64* %54, align 8
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  store i64 %48, i64* %56, align 8
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %48, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %23
  %62 = bitcast i16* %61 to i64*
  store i64 %48, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %48, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %33
  %66 = bitcast i16* %65 to i64*
  store i64 %48, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %48, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %18
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %28
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %38
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  %86 = shl nsw i64 %1, 2
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = bitcast i8* %87 to i16*
  %89 = lshr i64 %1, 1
  %90 = bitcast i8* %87 to i64*
  store i64 576469548530665472, i64* %90, align 8
  %91 = shl i64 %89, 32
  %92 = ashr exact i64 %91, 32
  %93 = getelementptr inbounds i16, i16* %88, i64 %92
  %94 = bitcast i16* %93 to i64*
  store i64 576469548530665472, i64* %94, align 8
  %95 = shl i64 %1, 32
  %96 = ashr exact i64 %95, 32
  %97 = and i64 %96, -2
  %98 = getelementptr inbounds i16, i16* %88, i64 %97
  %99 = bitcast i16* %98 to i64*
  store i64 576469548530665472, i64* %99, align 8
  %100 = mul i64 %89, 12884901888
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %88, i64 %101
  %103 = bitcast i16* %102 to i64*
  store i64 576469548530665472, i64* %103, align 8
  %104 = getelementptr inbounds i8, i8* %87, i64 8
  %105 = bitcast i8* %104 to i16*
  %106 = bitcast i8* %104 to i64*
  store i64 576469548530665472, i64* %106, align 8
  %107 = getelementptr inbounds i16, i16* %105, i64 %92
  %108 = bitcast i16* %107 to i64*
  store i64 576469548530665472, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %105, i64 %97
  %110 = bitcast i16* %109 to i64*
  store i64 576469548530665472, i64* %110, align 8
  %111 = getelementptr inbounds i16, i16* %105, i64 %101
  %112 = bitcast i16* %111 to i64*
  store i64 576469548530665472, i64* %112, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_0l0_12(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = mul nsw i64 %4, 5
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = and i64 %1, -2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = mul nsw i64 %4, 6
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = mul nsw i64 %4, 3
  %34 = add nsw i64 %33, -1
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = mul nsw i64 %4, 7
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %8, 2
  %44 = add nuw nsw i64 %43, %17
  %45 = add nuw nsw i64 %44, %27
  %46 = add nuw nsw i64 %45, %37
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = add nuw nsw i64 %13, 2
  %50 = add nuw nsw i64 %49, %22
  %51 = add nuw nsw i64 %50, %32
  %52 = add nuw nsw i64 %51, %42
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %48, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %23
  %62 = bitcast i16* %61 to i64*
  store i64 %48, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %48, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %33
  %66 = bitcast i16* %65 to i64*
  store i64 %48, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %48, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %18
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %28
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %38
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  %86 = lshr i64 %1, 1
  store i64 576469548530665472, i64* %54, align 8
  %87 = shl i64 %86, 32
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %3, i64 %88
  %90 = bitcast i16* %89 to i64*
  store i64 576469548530665472, i64* %90, align 8
  %91 = shl i64 %1, 32
  %92 = ashr exact i64 %91, 32
  %93 = and i64 %92, -2
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = bitcast i16* %94 to i64*
  store i64 576469548530665472, i64* %95, align 8
  %96 = mul i64 %86, 12884901888
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i16, i16* %3, i64 %97
  %99 = bitcast i16* %98 to i64*
  store i64 576469548530665472, i64* %99, align 8
  %100 = bitcast i8* %55 to i16*
  store i64 576469548530665472, i64* %56, align 8
  %101 = getelementptr inbounds i16, i16* %100, i64 %88
  %102 = bitcast i16* %101 to i64*
  store i64 576469548530665472, i64* %102, align 8
  %103 = getelementptr inbounds i16, i16* %100, i64 %93
  %104 = bitcast i16* %103 to i64*
  store i64 576469548530665472, i64* %104, align 8
  %105 = getelementptr inbounds i16, i16* %100, i64 %97
  %106 = bitcast i16* %105 to i64*
  store i64 576469548530665472, i64* %106, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_dc_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 0, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = sub nsw i64 4, %4
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = shl nsw i64 %4, 2
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = shl nsw i64 %4, 3
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = mul nsw i64 %4, 12
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i32
  %33 = add nsw i64 %4, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = sub nsw i64 1, %4
  %38 = getelementptr inbounds i16, i16* %3, i64 %37
  %39 = load i16, i16* %38, align 2
  %40 = zext i16 %39 to i64
  %41 = add nuw nsw i64 %13, %36
  %42 = add nuw nsw i64 %41, %40
  %43 = sub nsw i64 5, %4
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %17, %46
  %48 = mul nsw i64 %4, 5
  %49 = add nsw i64 %48, -1
  %50 = getelementptr inbounds i16, i16* %3, i64 %49
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i32
  %53 = add nuw nsw i32 %22, %52
  %54 = mul nsw i64 %4, 9
  %55 = add nsw i64 %54, -1
  %56 = getelementptr inbounds i16, i16* %3, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %27, %58
  %60 = mul nsw i64 %4, 13
  %61 = add nsw i64 %60, -1
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = load i16, i16* %62, align 2
  %64 = zext i16 %63 to i32
  %65 = add nuw nsw i32 %32, %64
  %66 = and i64 %1, -2
  %67 = add nsw i64 %66, -1
  %68 = getelementptr inbounds i16, i16* %3, i64 %67
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i64
  %71 = sub nsw i64 2, %4
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = load i16, i16* %72, align 2
  %74 = zext i16 %73 to i64
  %75 = add nuw nsw i64 %42, %70
  %76 = add nuw nsw i64 %75, %74
  %77 = sub nsw i64 6, %4
  %78 = getelementptr inbounds i16, i16* %3, i64 %77
  %79 = load i16, i16* %78, align 2
  %80 = zext i16 %79 to i32
  %81 = add nuw nsw i32 %47, %80
  %82 = mul nsw i64 %4, 6
  %83 = add nsw i64 %82, -1
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i32
  %87 = add nuw nsw i32 %53, %86
  %88 = mul nsw i64 %4, 10
  %89 = add nsw i64 %88, -1
  %90 = getelementptr inbounds i16, i16* %3, i64 %89
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i32
  %93 = add nuw nsw i32 %59, %92
  %94 = mul nsw i64 %4, 14
  %95 = add nsw i64 %94, -1
  %96 = getelementptr inbounds i16, i16* %3, i64 %95
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i32
  %99 = add nuw nsw i32 %65, %98
  %100 = mul nsw i64 %4, 3
  %101 = add nsw i64 %100, -1
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i64
  %105 = sub nsw i64 3, %4
  %106 = getelementptr inbounds i16, i16* %3, i64 %105
  %107 = load i16, i16* %106, align 2
  %108 = zext i16 %107 to i64
  %109 = add nuw nsw i64 %76, %104
  %110 = add nuw nsw i64 %109, %108
  %111 = sub nsw i64 7, %4
  %112 = getelementptr inbounds i16, i16* %3, i64 %111
  %113 = load i16, i16* %112, align 2
  %114 = zext i16 %113 to i32
  %115 = add nuw nsw i32 %81, %114
  %116 = mul nsw i64 %4, 7
  %117 = add nsw i64 %116, -1
  %118 = getelementptr inbounds i16, i16* %3, i64 %117
  %119 = load i16, i16* %118, align 2
  %120 = zext i16 %119 to i32
  %121 = add nuw nsw i32 %87, %120
  %122 = mul nsw i64 %4, 11
  %123 = add nsw i64 %122, -1
  %124 = getelementptr inbounds i16, i16* %3, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %93, %126
  %128 = mul nsw i64 %4, 15
  %129 = add nsw i64 %128, -1
  %130 = getelementptr inbounds i16, i16* %3, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i32
  %133 = add nuw nsw i32 %99, %132
  %134 = add nuw nsw i64 %110, 4
  %135 = lshr i64 %134, 3
  %136 = and i64 %135, 536870911
  %137 = mul i64 %136, 281479271743489
  %138 = add nuw nsw i32 %115, 2
  %139 = lshr i32 %138, 2
  %140 = zext i32 %139 to i64
  %141 = mul i64 %140, 281479271743489
  %142 = add nuw nsw i32 %121, 2
  %143 = lshr i32 %142, 2
  %144 = zext i32 %143 to i64
  %145 = add nuw nsw i32 %115, 4
  %146 = add nuw nsw i32 %145, %121
  %147 = lshr i32 %146, 3
  %148 = zext i32 %147 to i64
  %149 = add nuw nsw i32 %127, 2
  %150 = lshr i32 %149, 2
  %151 = zext i32 %150 to i64
  %152 = add nuw nsw i32 %145, %127
  %153 = lshr i32 %152, 3
  %154 = zext i32 %153 to i64
  %155 = add nuw nsw i32 %133, 2
  %156 = lshr i32 %155, 2
  %157 = zext i32 %156 to i64
  %158 = add nuw nsw i32 %145, %133
  %159 = lshr i32 %158, 3
  %160 = zext i32 %159 to i64
  %161 = bitcast i8* %0 to i64*
  store i64 %137, i64* %161, align 8
  %162 = getelementptr inbounds i8, i8* %0, i64 8
  %163 = bitcast i8* %162 to i64*
  store i64 %141, i64* %163, align 8
  %164 = getelementptr inbounds i16, i16* %3, i64 %4
  %165 = bitcast i16* %164 to i64*
  store i64 %137, i64* %165, align 8
  %166 = getelementptr inbounds i16, i16* %164, i64 4
  %167 = bitcast i16* %166 to i64*
  store i64 %141, i64* %167, align 8
  %168 = getelementptr inbounds i16, i16* %3, i64 %66
  %169 = bitcast i16* %168 to i64*
  store i64 %137, i64* %169, align 8
  %170 = getelementptr inbounds i16, i16* %168, i64 4
  %171 = bitcast i16* %170 to i64*
  store i64 %141, i64* %171, align 8
  %172 = getelementptr inbounds i16, i16* %3, i64 %100
  %173 = bitcast i16* %172 to i64*
  store i64 %137, i64* %173, align 8
  %174 = getelementptr inbounds i16, i16* %172, i64 4
  %175 = bitcast i16* %174 to i64*
  store i64 %141, i64* %175, align 8
  %176 = mul i64 %144, 281479271743489
  %177 = mul i64 %148, 281479271743489
  %178 = mul i64 %151, 281479271743489
  %179 = mul i64 %154, 281479271743489
  %180 = mul i64 %157, 281479271743489
  %181 = mul i64 %160, 281479271743489
  %182 = getelementptr inbounds i16, i16* %3, i64 %18
  %183 = bitcast i16* %182 to i64*
  store i64 %176, i64* %183, align 8
  %184 = getelementptr inbounds i16, i16* %182, i64 4
  %185 = bitcast i16* %184 to i64*
  store i64 %177, i64* %185, align 8
  %186 = getelementptr inbounds i16, i16* %3, i64 %48
  %187 = bitcast i16* %186 to i64*
  store i64 %176, i64* %187, align 8
  %188 = getelementptr inbounds i16, i16* %186, i64 4
  %189 = bitcast i16* %188 to i64*
  store i64 %177, i64* %189, align 8
  %190 = getelementptr inbounds i16, i16* %3, i64 %82
  %191 = bitcast i16* %190 to i64*
  store i64 %176, i64* %191, align 8
  %192 = getelementptr inbounds i16, i16* %190, i64 4
  %193 = bitcast i16* %192 to i64*
  store i64 %177, i64* %193, align 8
  %194 = getelementptr inbounds i16, i16* %3, i64 %116
  %195 = bitcast i16* %194 to i64*
  store i64 %176, i64* %195, align 8
  %196 = getelementptr inbounds i16, i16* %194, i64 4
  %197 = bitcast i16* %196 to i64*
  store i64 %177, i64* %197, align 8
  %198 = getelementptr inbounds i16, i16* %3, i64 %23
  %199 = bitcast i16* %198 to i64*
  store i64 %178, i64* %199, align 8
  %200 = getelementptr inbounds i16, i16* %198, i64 4
  %201 = bitcast i16* %200 to i64*
  store i64 %179, i64* %201, align 8
  %202 = getelementptr inbounds i16, i16* %3, i64 %54
  %203 = bitcast i16* %202 to i64*
  store i64 %178, i64* %203, align 8
  %204 = getelementptr inbounds i16, i16* %202, i64 4
  %205 = bitcast i16* %204 to i64*
  store i64 %179, i64* %205, align 8
  %206 = getelementptr inbounds i16, i16* %3, i64 %88
  %207 = bitcast i16* %206 to i64*
  store i64 %178, i64* %207, align 8
  %208 = getelementptr inbounds i16, i16* %206, i64 4
  %209 = bitcast i16* %208 to i64*
  store i64 %179, i64* %209, align 8
  %210 = getelementptr inbounds i16, i16* %3, i64 %122
  %211 = bitcast i16* %210 to i64*
  store i64 %178, i64* %211, align 8
  %212 = getelementptr inbounds i16, i16* %210, i64 4
  %213 = bitcast i16* %212 to i64*
  store i64 %179, i64* %213, align 8
  %214 = getelementptr inbounds i16, i16* %3, i64 %28
  %215 = bitcast i16* %214 to i64*
  store i64 %180, i64* %215, align 8
  %216 = getelementptr inbounds i16, i16* %214, i64 4
  %217 = bitcast i16* %216 to i64*
  store i64 %181, i64* %217, align 8
  %218 = getelementptr inbounds i16, i16* %3, i64 %60
  %219 = bitcast i16* %218 to i64*
  store i64 %180, i64* %219, align 8
  %220 = getelementptr inbounds i16, i16* %218, i64 4
  %221 = bitcast i16* %220 to i64*
  store i64 %181, i64* %221, align 8
  %222 = getelementptr inbounds i16, i16* %3, i64 %94
  %223 = bitcast i16* %222 to i64*
  store i64 %180, i64* %223, align 8
  %224 = getelementptr inbounds i16, i16* %222, i64 4
  %225 = bitcast i16* %224 to i64*
  store i64 %181, i64* %225, align 8
  %226 = getelementptr inbounds i16, i16* %3, i64 %128
  %227 = bitcast i16* %226 to i64*
  store i64 %180, i64* %227, align 8
  %228 = getelementptr inbounds i16, i16* %226, i64 4
  %229 = bitcast i16* %228 to i64*
  store i64 %181, i64* %229, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_left_dc_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = mul nsw i64 %4, 5
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = and i64 %1, -2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = mul nsw i64 %4, 6
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = mul nsw i64 %4, 3
  %34 = add nsw i64 %33, -1
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = mul nsw i64 %4, 7
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %8, 2
  %44 = add nuw nsw i64 %43, %17
  %45 = add nuw nsw i64 %44, %27
  %46 = add nuw nsw i64 %45, %37
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = add nuw nsw i64 %13, 2
  %50 = add nuw nsw i64 %49, %22
  %51 = add nuw nsw i64 %50, %32
  %52 = add nuw nsw i64 %51, %42
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  store i64 %48, i64* %54, align 8
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  store i64 %48, i64* %56, align 8
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %48, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %23
  %62 = bitcast i16* %61 to i64*
  store i64 %48, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %48, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %33
  %66 = bitcast i16* %65 to i64*
  store i64 %48, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %48, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %18
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %28
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %38
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  %86 = shl nsw i64 %1, 3
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = bitcast i8* %87 to i16*
  %89 = getelementptr inbounds i8, i8* %87, i64 -2
  %90 = bitcast i8* %89 to i16*
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i64
  %93 = getelementptr inbounds i16, i16* %88, i64 %10
  %94 = load i16, i16* %93, align 2
  %95 = zext i16 %94 to i64
  %96 = getelementptr inbounds i16, i16* %88, i64 %14
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i64
  %99 = getelementptr inbounds i16, i16* %88, i64 %19
  %100 = load i16, i16* %99, align 2
  %101 = zext i16 %100 to i64
  %102 = getelementptr inbounds i16, i16* %88, i64 %24
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i64
  %105 = getelementptr inbounds i16, i16* %88, i64 %29
  %106 = load i16, i16* %105, align 2
  %107 = zext i16 %106 to i64
  %108 = getelementptr inbounds i16, i16* %88, i64 %34
  %109 = load i16, i16* %108, align 2
  %110 = zext i16 %109 to i64
  %111 = getelementptr inbounds i16, i16* %88, i64 %39
  %112 = load i16, i16* %111, align 2
  %113 = zext i16 %112 to i64
  %114 = add nuw nsw i64 %92, 2
  %115 = add nuw nsw i64 %114, %98
  %116 = add nuw nsw i64 %115, %104
  %117 = add nuw nsw i64 %116, %110
  %118 = lshr i64 %117, 2
  %119 = mul i64 %118, 281479271743489
  %120 = add nuw nsw i64 %95, 2
  %121 = add nuw nsw i64 %120, %101
  %122 = add nuw nsw i64 %121, %107
  %123 = add nuw nsw i64 %122, %113
  %124 = lshr i64 %123, 2
  %125 = bitcast i8* %87 to i64*
  store i64 %119, i64* %125, align 8
  %126 = getelementptr inbounds i8, i8* %87, i64 8
  %127 = bitcast i8* %126 to i64*
  store i64 %119, i64* %127, align 8
  %128 = getelementptr inbounds i16, i16* %88, i64 %4
  %129 = bitcast i16* %128 to i64*
  store i64 %119, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %119, i64* %131, align 8
  %132 = getelementptr inbounds i16, i16* %88, i64 %23
  %133 = bitcast i16* %132 to i64*
  store i64 %119, i64* %133, align 8
  %134 = getelementptr inbounds i16, i16* %132, i64 4
  %135 = bitcast i16* %134 to i64*
  store i64 %119, i64* %135, align 8
  %136 = getelementptr inbounds i16, i16* %88, i64 %33
  %137 = bitcast i16* %136 to i64*
  store i64 %119, i64* %137, align 8
  %138 = getelementptr inbounds i16, i16* %136, i64 4
  %139 = bitcast i16* %138 to i64*
  store i64 %119, i64* %139, align 8
  %140 = mul i64 %124, 281479271743489
  %141 = getelementptr inbounds i16, i16* %88, i64 %9
  %142 = bitcast i16* %141 to i64*
  store i64 %140, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %140, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %88, i64 %18
  %146 = bitcast i16* %145 to i64*
  store i64 %140, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %145, i64 4
  %148 = bitcast i16* %147 to i64*
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %88, i64 %28
  %150 = bitcast i16* %149 to i64*
  store i64 %140, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %149, i64 4
  %152 = bitcast i16* %151 to i64*
  store i64 %140, i64* %152, align 8
  %153 = getelementptr inbounds i16, i16* %88, i64 %38
  %154 = bitcast i16* %153 to i64*
  store i64 %140, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %153, i64 4
  %156 = bitcast i16* %155 to i64*
  store i64 %140, i64* %156, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_top_dc_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = add nuw nsw i64 %8, %16
  %18 = sub nsw i64 5, %4
  %19 = getelementptr inbounds i16, i16* %3, i64 %18
  %20 = load i16, i16* %19, align 2
  %21 = zext i16 %20 to i64
  %22 = add nuw nsw i64 %12, %21
  %23 = sub nsw i64 2, %4
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = add nuw nsw i64 %17, %26
  %28 = sub nsw i64 6, %4
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i64
  %32 = add nuw nsw i64 %22, %31
  %33 = sub nsw i64 3, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %27, %36
  %38 = sub nsw i64 7, %4
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i64
  %42 = add nuw nsw i64 %32, %41
  %43 = add nuw nsw i64 %37, 2
  %44 = lshr i64 %43, 2
  %45 = mul i64 %44, 281479271743489
  %46 = add nuw nsw i64 %42, 2
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %45, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %45, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %45, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %45, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %45, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %45, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %45, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %45, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  %86 = shl nsw i64 %4, 3
  %87 = getelementptr inbounds i16, i16* %3, i64 %86
  %88 = bitcast i16* %87 to i64*
  store i64 %45, i64* %88, align 8
  %89 = getelementptr inbounds i16, i16* %87, i64 4
  %90 = bitcast i16* %89 to i64*
  store i64 %48, i64* %90, align 8
  %91 = mul nsw i64 %4, 9
  %92 = getelementptr inbounds i16, i16* %3, i64 %91
  %93 = bitcast i16* %92 to i64*
  store i64 %45, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %48, i64* %95, align 8
  %96 = mul nsw i64 %4, 10
  %97 = getelementptr inbounds i16, i16* %3, i64 %96
  %98 = bitcast i16* %97 to i64*
  store i64 %45, i64* %98, align 8
  %99 = getelementptr inbounds i16, i16* %97, i64 4
  %100 = bitcast i16* %99 to i64*
  store i64 %48, i64* %100, align 8
  %101 = mul nsw i64 %4, 11
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = bitcast i16* %102 to i64*
  store i64 %45, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %102, i64 4
  %105 = bitcast i16* %104 to i64*
  store i64 %48, i64* %105, align 8
  %106 = mul nsw i64 %4, 12
  %107 = getelementptr inbounds i16, i16* %3, i64 %106
  %108 = bitcast i16* %107 to i64*
  store i64 %45, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %107, i64 4
  %110 = bitcast i16* %109 to i64*
  store i64 %48, i64* %110, align 8
  %111 = mul nsw i64 %4, 13
  %112 = getelementptr inbounds i16, i16* %3, i64 %111
  %113 = bitcast i16* %112 to i64*
  store i64 %45, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %112, i64 4
  %115 = bitcast i16* %114 to i64*
  store i64 %48, i64* %115, align 8
  %116 = mul nsw i64 %4, 14
  %117 = getelementptr inbounds i16, i16* %3, i64 %116
  %118 = bitcast i16* %117 to i64*
  store i64 %45, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %117, i64 4
  %120 = bitcast i16* %119 to i64*
  store i64 %48, i64* %120, align 8
  %121 = mul nsw i64 %4, 15
  %122 = getelementptr inbounds i16, i16* %3, i64 %121
  %123 = bitcast i16* %122 to i64*
  store i64 %45, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %122, i64 4
  %125 = bitcast i16* %124 to i64*
  store i64 %48, i64* %125, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_l0t_12(i8*, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = sub nsw i64 5, %4
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub nsw i64 2, %4
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = sub nsw i64 6, %4
  %26 = getelementptr inbounds i16, i16* %3, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i64
  %29 = sub nsw i64 3, %4
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = sub nsw i64 7, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %8, 2
  %38 = add nuw nsw i64 %37, %16
  %39 = add nuw nsw i64 %38, %24
  %40 = add nuw nsw i64 %39, %32
  %41 = lshr i64 %40, 2
  %42 = mul i64 %41, 281479271743489
  %43 = add nuw nsw i64 %12, 2
  %44 = add nuw nsw i64 %43, %20
  %45 = add nuw nsw i64 %44, %28
  %46 = add nuw nsw i64 %45, %36
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %42, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %42, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %42, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %42, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %42, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %42, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %42, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %42, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  %86 = shl nsw i64 %4, 3
  %87 = getelementptr inbounds i16, i16* %3, i64 %86
  %88 = bitcast i16* %87 to i64*
  store i64 %42, i64* %88, align 8
  %89 = getelementptr inbounds i16, i16* %87, i64 4
  %90 = bitcast i16* %89 to i64*
  store i64 %48, i64* %90, align 8
  %91 = mul nsw i64 %4, 9
  %92 = getelementptr inbounds i16, i16* %3, i64 %91
  %93 = bitcast i16* %92 to i64*
  store i64 %42, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %48, i64* %95, align 8
  %96 = mul nsw i64 %4, 10
  %97 = getelementptr inbounds i16, i16* %3, i64 %96
  %98 = bitcast i16* %97 to i64*
  store i64 %42, i64* %98, align 8
  %99 = getelementptr inbounds i16, i16* %97, i64 4
  %100 = bitcast i16* %99 to i64*
  store i64 %48, i64* %100, align 8
  %101 = mul nsw i64 %4, 11
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = bitcast i16* %102 to i64*
  store i64 %42, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %102, i64 4
  %105 = bitcast i16* %104 to i64*
  store i64 %48, i64* %105, align 8
  %106 = mul nsw i64 %4, 12
  %107 = getelementptr inbounds i16, i16* %3, i64 %106
  %108 = bitcast i16* %107 to i64*
  store i64 %42, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %107, i64 4
  %110 = bitcast i16* %109 to i64*
  store i64 %48, i64* %110, align 8
  %111 = mul nsw i64 %4, 13
  %112 = getelementptr inbounds i16, i16* %3, i64 %111
  %113 = bitcast i16* %112 to i64*
  store i64 %42, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %112, i64 4
  %115 = bitcast i16* %114 to i64*
  store i64 %48, i64* %115, align 8
  %116 = mul nsw i64 %4, 14
  %117 = getelementptr inbounds i16, i16* %3, i64 %116
  %118 = bitcast i16* %117 to i64*
  store i64 %42, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %117, i64 4
  %120 = bitcast i16* %119 to i64*
  store i64 %48, i64* %120, align 8
  %121 = mul nsw i64 %4, 15
  %122 = getelementptr inbounds i16, i16* %3, i64 %121
  %123 = bitcast i16* %122 to i64*
  store i64 %42, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %122, i64 4
  %125 = bitcast i16* %124 to i64*
  store i64 %48, i64* %125, align 8
  %126 = lshr i64 %1, 1
  %127 = trunc i64 %126 to i32
  %128 = shl i64 %126, 32
  %129 = sub i64 0, %128
  %130 = ashr exact i64 %129, 32
  %131 = getelementptr inbounds i16, i16* %3, i64 %130
  %132 = load i16, i16* %131, align 2
  %133 = zext i16 %132 to i32
  %134 = sub i64 4294967296, %128
  %135 = ashr exact i64 %134, 32
  %136 = getelementptr inbounds i16, i16* %3, i64 %135
  %137 = load i16, i16* %136, align 2
  %138 = zext i16 %137 to i32
  %139 = sub i64 8589934592, %128
  %140 = ashr exact i64 %139, 32
  %141 = getelementptr inbounds i16, i16* %3, i64 %140
  %142 = load i16, i16* %141, align 2
  %143 = zext i16 %142 to i32
  %144 = sub i64 12884901888, %128
  %145 = ashr exact i64 %144, 32
  %146 = getelementptr inbounds i16, i16* %3, i64 %145
  %147 = load i16, i16* %146, align 2
  %148 = zext i16 %147 to i32
  %149 = getelementptr inbounds i8, i8* %0, i64 -2
  %150 = bitcast i8* %149 to i16*
  %151 = load i16, i16* %150, align 2
  %152 = zext i16 %151 to i32
  %153 = add i64 %128, -4294967296
  %154 = ashr exact i64 %153, 32
  %155 = getelementptr inbounds i16, i16* %3, i64 %154
  %156 = load i16, i16* %155, align 2
  %157 = zext i16 %156 to i32
  %158 = trunc i64 %1 to i32
  %159 = and i32 %158, -2
  %160 = add nsw i32 %159, -1
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds i16, i16* %3, i64 %161
  %163 = load i16, i16* %162, align 2
  %164 = zext i16 %163 to i32
  %165 = mul nsw i32 %127, 3
  %166 = add nsw i32 %165, -1
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds i16, i16* %3, i64 %167
  %169 = load i16, i16* %168, align 2
  %170 = zext i16 %169 to i32
  %171 = add nuw nsw i32 %133, 4
  %172 = add nuw nsw i32 %171, %138
  %173 = add nuw nsw i32 %172, %143
  %174 = add nuw nsw i32 %173, %148
  %175 = add nuw nsw i32 %174, %152
  %176 = add nuw nsw i32 %175, %157
  %177 = add nuw nsw i32 %176, %164
  %178 = add nuw nsw i32 %177, %170
  %179 = ashr i32 %178, 3
  %180 = sext i32 %179 to i64
  %181 = mul i64 %180, 281479271743489
  store i64 %181, i64* %49, align 8
  %182 = ashr exact i64 %128, 32
  %183 = getelementptr inbounds i16, i16* %3, i64 %182
  %184 = bitcast i16* %183 to i64*
  store i64 %181, i64* %184, align 8
  %185 = sext i32 %159 to i64
  %186 = getelementptr inbounds i16, i16* %3, i64 %185
  %187 = bitcast i16* %186 to i64*
  store i64 %181, i64* %187, align 8
  %188 = sext i32 %165 to i64
  %189 = getelementptr inbounds i16, i16* %3, i64 %188
  %190 = bitcast i16* %189 to i64*
  store i64 %181, i64* %190, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_0lt_12(i8* nocapture, i64) #1 {
  tail call void @pred8x16_dc_12_c(i8* %0, i64 %1)
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = sub i64 0, %5
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = sub i64 4294967296, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = load i16, i16* %13, align 2
  %15 = zext i16 %14 to i64
  %16 = sub i64 8589934592, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub i64 12884901888, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i16, i16* %3, i64 %22
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i64
  %26 = add nuw nsw i64 %10, 2
  %27 = add nuw nsw i64 %26, %15
  %28 = add nuw nsw i64 %27, %20
  %29 = add nuw nsw i64 %28, %25
  %30 = lshr i64 %29, 2
  %31 = mul i64 %30, 281479271743489
  %32 = bitcast i8* %0 to i64*
  store i64 %31, i64* %32, align 8
  %33 = ashr exact i64 %5, 32
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %31, i64* %35, align 8
  %36 = shl i64 %1, 32
  %37 = ashr exact i64 %36, 32
  %38 = and i64 %37, -2
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %31, i64* %40, align 8
  %41 = mul i64 %4, 12884901888
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds i16, i16* %3, i64 %42
  %44 = bitcast i16* %43 to i64*
  store i64 %31, i64* %44, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_l00_12(i8* nocapture, i64) #1 {
  tail call void @pred8x16_left_dc_12_c(i8* %0, i64 %1)
  %3 = shl nsw i64 %1, 2
  %4 = getelementptr inbounds i8, i8* %0, i64 %3
  %5 = bitcast i8* %4 to i16*
  %6 = lshr i64 %1, 1
  %7 = bitcast i8* %4 to i64*
  store i64 576469548530665472, i64* %7, align 8
  %8 = shl i64 %6, 32
  %9 = ashr exact i64 %8, 32
  %10 = getelementptr inbounds i16, i16* %5, i64 %9
  %11 = bitcast i16* %10 to i64*
  store i64 576469548530665472, i64* %11, align 8
  %12 = shl i64 %1, 32
  %13 = ashr exact i64 %12, 32
  %14 = and i64 %13, -2
  %15 = getelementptr inbounds i16, i16* %5, i64 %14
  %16 = bitcast i16* %15 to i64*
  store i64 576469548530665472, i64* %16, align 8
  %17 = mul i64 %6, 12884901888
  %18 = ashr exact i64 %17, 32
  %19 = getelementptr inbounds i16, i16* %5, i64 %18
  %20 = bitcast i16* %19 to i64*
  store i64 576469548530665472, i64* %20, align 8
  %21 = getelementptr inbounds i8, i8* %4, i64 8
  %22 = bitcast i8* %21 to i16*
  %23 = bitcast i8* %21 to i64*
  store i64 576469548530665472, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %22, i64 %9
  %25 = bitcast i16* %24 to i64*
  store i64 576469548530665472, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %22, i64 %14
  %27 = bitcast i16* %26 to i64*
  store i64 576469548530665472, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %22, i64 %18
  %29 = bitcast i16* %28 to i64*
  store i64 576469548530665472, i64* %29, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_0l0_12(i8* nocapture, i64) #1 {
  tail call void @pred8x16_left_dc_12_c(i8* %0, i64 %1)
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = bitcast i8* %0 to i64*
  store i64 576469548530665472, i64* %5, align 8
  %6 = shl i64 %4, 32
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  store i64 576469548530665472, i64* %9, align 8
  %10 = shl i64 %1, 32
  %11 = ashr exact i64 %10, 32
  %12 = and i64 %11, -2
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = bitcast i16* %13 to i64*
  store i64 576469548530665472, i64* %14, align 8
  %15 = mul i64 %4, 12884901888
  %16 = ashr exact i64 %15, 32
  %17 = getelementptr inbounds i16, i16* %3, i64 %16
  %18 = bitcast i16* %17 to i64*
  store i64 576469548530665472, i64* %18, align 8
  %19 = getelementptr inbounds i8, i8* %0, i64 8
  %20 = bitcast i8* %19 to i16*
  %21 = bitcast i8* %19 to i64*
  store i64 576469548530665472, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 %7
  %23 = bitcast i16* %22 to i64*
  store i64 576469548530665472, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 %12
  %25 = bitcast i16* %24 to i64*
  store i64 576469548530665472, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 %16
  %27 = bitcast i16* %26 to i64*
  store i64 576469548530665472, i64* %27, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_127_dc_12_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %25, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_129_dc_12_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %25, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_128_dc_12_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %25, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x16_128_dc_12_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %25, align 8
  %26 = shl nsw i64 %1, 3
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = bitcast i8* %27 to i16*
  %29 = bitcast i8* %27 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 %4
  %31 = bitcast i16* %30 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 %8
  %33 = bitcast i16* %32 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 %11
  %35 = bitcast i16* %34 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %14
  %37 = bitcast i16* %36 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %37, align 8
  %38 = getelementptr inbounds i16, i16* %28, i64 %17
  %39 = bitcast i16* %38 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %39, align 8
  %40 = getelementptr inbounds i16, i16* %28, i64 %20
  %41 = bitcast i16* %40 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %41, align 8
  %42 = getelementptr inbounds i16, i16* %28, i64 %23
  %43 = bitcast i16* %42 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %43, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_dc_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = add nsw i64 %4, -1
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = and i64 %1, -2
  %15 = add nsw i64 %14, -1
  %16 = getelementptr inbounds i16, i16* %3, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i64
  %19 = add nuw nsw i64 %13, %18
  %20 = mul nsw i64 %4, 3
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = add nuw nsw i64 %19, %24
  %26 = shl nsw i64 %4, 2
  %27 = add nsw i64 %26, -1
  %28 = getelementptr inbounds i16, i16* %3, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = zext i16 %29 to i64
  %31 = add nuw nsw i64 %25, %30
  %32 = mul nsw i64 %4, 5
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %31, %36
  %38 = mul nsw i64 %4, 6
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %37, %42
  %44 = mul nsw i64 %4, 7
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = add nuw nsw i64 %43, %48
  %50 = shl nsw i64 %4, 3
  %51 = add nsw i64 %50, -1
  %52 = getelementptr inbounds i16, i16* %3, i64 %51
  %53 = load i16, i16* %52, align 2
  %54 = zext i16 %53 to i64
  %55 = add nuw nsw i64 %49, %54
  %56 = mul nsw i64 %4, 9
  %57 = add nsw i64 %56, -1
  %58 = getelementptr inbounds i16, i16* %3, i64 %57
  %59 = load i16, i16* %58, align 2
  %60 = zext i16 %59 to i64
  %61 = add nuw nsw i64 %55, %60
  %62 = mul nsw i64 %4, 10
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = add nuw nsw i64 %61, %66
  %68 = mul nsw i64 %4, 11
  %69 = add nsw i64 %68, -1
  %70 = getelementptr inbounds i16, i16* %3, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i64
  %73 = add nuw nsw i64 %67, %72
  %74 = mul nsw i64 %4, 12
  %75 = add nsw i64 %74, -1
  %76 = getelementptr inbounds i16, i16* %3, i64 %75
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i64
  %79 = add nuw nsw i64 %73, %78
  %80 = mul nsw i64 %4, 13
  %81 = add nsw i64 %80, -1
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = zext i16 %83 to i64
  %85 = add nuw nsw i64 %79, %84
  %86 = mul nsw i64 %4, 14
  %87 = add nsw i64 %86, -1
  %88 = getelementptr inbounds i16, i16* %3, i64 %87
  %89 = load i16, i16* %88, align 2
  %90 = zext i16 %89 to i64
  %91 = add nuw nsw i64 %85, %90
  %92 = mul nsw i64 %4, 15
  %93 = add nsw i64 %92, -1
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i64
  %97 = add nuw nsw i64 %91, %96
  %98 = sub nsw i64 0, %4
  %99 = getelementptr inbounds i16, i16* %3, i64 %98
  %100 = load i16, i16* %99, align 2
  %101 = zext i16 %100 to i64
  %102 = add nuw nsw i64 %97, %101
  %103 = sub nsw i64 1, %4
  %104 = getelementptr inbounds i16, i16* %3, i64 %103
  %105 = load i16, i16* %104, align 2
  %106 = zext i16 %105 to i64
  %107 = add nuw nsw i64 %102, %106
  %108 = sub nsw i64 2, %4
  %109 = getelementptr inbounds i16, i16* %3, i64 %108
  %110 = load i16, i16* %109, align 2
  %111 = zext i16 %110 to i64
  %112 = add nuw nsw i64 %107, %111
  %113 = sub nsw i64 3, %4
  %114 = getelementptr inbounds i16, i16* %3, i64 %113
  %115 = load i16, i16* %114, align 2
  %116 = zext i16 %115 to i64
  %117 = add nuw nsw i64 %112, %116
  %118 = sub nsw i64 4, %4
  %119 = getelementptr inbounds i16, i16* %3, i64 %118
  %120 = load i16, i16* %119, align 2
  %121 = zext i16 %120 to i64
  %122 = add nuw nsw i64 %117, %121
  %123 = sub nsw i64 5, %4
  %124 = getelementptr inbounds i16, i16* %3, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i64
  %127 = add nuw nsw i64 %122, %126
  %128 = sub nsw i64 6, %4
  %129 = getelementptr inbounds i16, i16* %3, i64 %128
  %130 = load i16, i16* %129, align 2
  %131 = zext i16 %130 to i64
  %132 = add nuw nsw i64 %127, %131
  %133 = sub nsw i64 7, %4
  %134 = getelementptr inbounds i16, i16* %3, i64 %133
  %135 = load i16, i16* %134, align 2
  %136 = zext i16 %135 to i64
  %137 = add nuw nsw i64 %132, %136
  %138 = sub nsw i64 8, %4
  %139 = getelementptr inbounds i16, i16* %3, i64 %138
  %140 = load i16, i16* %139, align 2
  %141 = zext i16 %140 to i64
  %142 = add nuw nsw i64 %137, %141
  %143 = sub nsw i64 9, %4
  %144 = getelementptr inbounds i16, i16* %3, i64 %143
  %145 = load i16, i16* %144, align 2
  %146 = zext i16 %145 to i64
  %147 = add nuw nsw i64 %142, %146
  %148 = sub nsw i64 10, %4
  %149 = getelementptr inbounds i16, i16* %3, i64 %148
  %150 = load i16, i16* %149, align 2
  %151 = zext i16 %150 to i64
  %152 = add nuw nsw i64 %147, %151
  %153 = sub nsw i64 11, %4
  %154 = getelementptr inbounds i16, i16* %3, i64 %153
  %155 = load i16, i16* %154, align 2
  %156 = zext i16 %155 to i64
  %157 = add nuw nsw i64 %152, %156
  %158 = sub nsw i64 12, %4
  %159 = getelementptr inbounds i16, i16* %3, i64 %158
  %160 = load i16, i16* %159, align 2
  %161 = zext i16 %160 to i64
  %162 = add nuw nsw i64 %157, %161
  %163 = sub nsw i64 13, %4
  %164 = getelementptr inbounds i16, i16* %3, i64 %163
  %165 = load i16, i16* %164, align 2
  %166 = zext i16 %165 to i64
  %167 = add nuw nsw i64 %162, %166
  %168 = sub nsw i64 14, %4
  %169 = getelementptr inbounds i16, i16* %3, i64 %168
  %170 = load i16, i16* %169, align 2
  %171 = zext i16 %170 to i64
  %172 = add nuw nsw i64 %167, %171
  %173 = sub nsw i64 15, %4
  %174 = getelementptr inbounds i16, i16* %3, i64 %173
  %175 = load i16, i16* %174, align 2
  %176 = zext i16 %175 to i64
  %177 = add nuw nsw i64 %172, %176
  %178 = add nuw nsw i64 %177, 16
  %179 = lshr i64 %178, 5
  %180 = and i64 %179, 134217727
  %181 = mul i64 %180, 281479271743489
  %182 = bitcast i8* %0 to i64*
  store i64 %181, i64* %182, align 8
  %183 = getelementptr inbounds i8, i8* %0, i64 8
  %184 = bitcast i8* %183 to i64*
  store i64 %181, i64* %184, align 8
  %185 = getelementptr inbounds i8, i8* %0, i64 16
  %186 = bitcast i8* %185 to i64*
  store i64 %181, i64* %186, align 8
  %187 = getelementptr inbounds i8, i8* %0, i64 24
  %188 = bitcast i8* %187 to i64*
  store i64 %181, i64* %188, align 8
  %189 = getelementptr inbounds i16, i16* %3, i64 %4
  %190 = bitcast i16* %189 to i64*
  store i64 %181, i64* %190, align 8
  %191 = getelementptr inbounds i16, i16* %189, i64 4
  %192 = bitcast i16* %191 to i64*
  store i64 %181, i64* %192, align 8
  %193 = getelementptr inbounds i16, i16* %189, i64 8
  %194 = bitcast i16* %193 to i64*
  store i64 %181, i64* %194, align 8
  %195 = getelementptr inbounds i16, i16* %189, i64 12
  %196 = bitcast i16* %195 to i64*
  store i64 %181, i64* %196, align 8
  %197 = getelementptr inbounds i16, i16* %189, i64 %4
  %198 = bitcast i16* %197 to i64*
  store i64 %181, i64* %198, align 8
  %199 = getelementptr inbounds i16, i16* %197, i64 4
  %200 = bitcast i16* %199 to i64*
  store i64 %181, i64* %200, align 8
  %201 = getelementptr inbounds i16, i16* %197, i64 8
  %202 = bitcast i16* %201 to i64*
  store i64 %181, i64* %202, align 8
  %203 = getelementptr inbounds i16, i16* %197, i64 12
  %204 = bitcast i16* %203 to i64*
  store i64 %181, i64* %204, align 8
  %205 = getelementptr inbounds i16, i16* %197, i64 %4
  %206 = bitcast i16* %205 to i64*
  store i64 %181, i64* %206, align 8
  %207 = getelementptr inbounds i16, i16* %205, i64 4
  %208 = bitcast i16* %207 to i64*
  store i64 %181, i64* %208, align 8
  %209 = getelementptr inbounds i16, i16* %205, i64 8
  %210 = bitcast i16* %209 to i64*
  store i64 %181, i64* %210, align 8
  %211 = getelementptr inbounds i16, i16* %205, i64 12
  %212 = bitcast i16* %211 to i64*
  store i64 %181, i64* %212, align 8
  %213 = getelementptr inbounds i16, i16* %205, i64 %4
  %214 = bitcast i16* %213 to i64*
  store i64 %181, i64* %214, align 8
  %215 = getelementptr inbounds i16, i16* %213, i64 4
  %216 = bitcast i16* %215 to i64*
  store i64 %181, i64* %216, align 8
  %217 = getelementptr inbounds i16, i16* %213, i64 8
  %218 = bitcast i16* %217 to i64*
  store i64 %181, i64* %218, align 8
  %219 = getelementptr inbounds i16, i16* %213, i64 12
  %220 = bitcast i16* %219 to i64*
  store i64 %181, i64* %220, align 8
  %221 = getelementptr inbounds i16, i16* %213, i64 %4
  %222 = bitcast i16* %221 to i64*
  store i64 %181, i64* %222, align 8
  %223 = getelementptr inbounds i16, i16* %221, i64 4
  %224 = bitcast i16* %223 to i64*
  store i64 %181, i64* %224, align 8
  %225 = getelementptr inbounds i16, i16* %221, i64 8
  %226 = bitcast i16* %225 to i64*
  store i64 %181, i64* %226, align 8
  %227 = getelementptr inbounds i16, i16* %221, i64 12
  %228 = bitcast i16* %227 to i64*
  store i64 %181, i64* %228, align 8
  %229 = getelementptr inbounds i16, i16* %221, i64 %4
  %230 = bitcast i16* %229 to i64*
  store i64 %181, i64* %230, align 8
  %231 = getelementptr inbounds i16, i16* %229, i64 4
  %232 = bitcast i16* %231 to i64*
  store i64 %181, i64* %232, align 8
  %233 = getelementptr inbounds i16, i16* %229, i64 8
  %234 = bitcast i16* %233 to i64*
  store i64 %181, i64* %234, align 8
  %235 = getelementptr inbounds i16, i16* %229, i64 12
  %236 = bitcast i16* %235 to i64*
  store i64 %181, i64* %236, align 8
  %237 = getelementptr inbounds i16, i16* %229, i64 %4
  %238 = bitcast i16* %237 to i64*
  store i64 %181, i64* %238, align 8
  %239 = getelementptr inbounds i16, i16* %237, i64 4
  %240 = bitcast i16* %239 to i64*
  store i64 %181, i64* %240, align 8
  %241 = getelementptr inbounds i16, i16* %237, i64 8
  %242 = bitcast i16* %241 to i64*
  store i64 %181, i64* %242, align 8
  %243 = getelementptr inbounds i16, i16* %237, i64 12
  %244 = bitcast i16* %243 to i64*
  store i64 %181, i64* %244, align 8
  %245 = getelementptr inbounds i16, i16* %237, i64 %4
  %246 = bitcast i16* %245 to i64*
  store i64 %181, i64* %246, align 8
  %247 = getelementptr inbounds i16, i16* %245, i64 4
  %248 = bitcast i16* %247 to i64*
  store i64 %181, i64* %248, align 8
  %249 = getelementptr inbounds i16, i16* %245, i64 8
  %250 = bitcast i16* %249 to i64*
  store i64 %181, i64* %250, align 8
  %251 = getelementptr inbounds i16, i16* %245, i64 12
  %252 = bitcast i16* %251 to i64*
  store i64 %181, i64* %252, align 8
  %253 = getelementptr inbounds i16, i16* %245, i64 %4
  %254 = bitcast i16* %253 to i64*
  store i64 %181, i64* %254, align 8
  %255 = getelementptr inbounds i16, i16* %253, i64 4
  %256 = bitcast i16* %255 to i64*
  store i64 %181, i64* %256, align 8
  %257 = getelementptr inbounds i16, i16* %253, i64 8
  %258 = bitcast i16* %257 to i64*
  store i64 %181, i64* %258, align 8
  %259 = getelementptr inbounds i16, i16* %253, i64 12
  %260 = bitcast i16* %259 to i64*
  store i64 %181, i64* %260, align 8
  %261 = getelementptr inbounds i16, i16* %253, i64 %4
  %262 = bitcast i16* %261 to i64*
  store i64 %181, i64* %262, align 8
  %263 = getelementptr inbounds i16, i16* %261, i64 4
  %264 = bitcast i16* %263 to i64*
  store i64 %181, i64* %264, align 8
  %265 = getelementptr inbounds i16, i16* %261, i64 8
  %266 = bitcast i16* %265 to i64*
  store i64 %181, i64* %266, align 8
  %267 = getelementptr inbounds i16, i16* %261, i64 12
  %268 = bitcast i16* %267 to i64*
  store i64 %181, i64* %268, align 8
  %269 = getelementptr inbounds i16, i16* %261, i64 %4
  %270 = bitcast i16* %269 to i64*
  store i64 %181, i64* %270, align 8
  %271 = getelementptr inbounds i16, i16* %269, i64 4
  %272 = bitcast i16* %271 to i64*
  store i64 %181, i64* %272, align 8
  %273 = getelementptr inbounds i16, i16* %269, i64 8
  %274 = bitcast i16* %273 to i64*
  store i64 %181, i64* %274, align 8
  %275 = getelementptr inbounds i16, i16* %269, i64 12
  %276 = bitcast i16* %275 to i64*
  store i64 %181, i64* %276, align 8
  %277 = getelementptr inbounds i16, i16* %269, i64 %4
  %278 = bitcast i16* %277 to i64*
  store i64 %181, i64* %278, align 8
  %279 = getelementptr inbounds i16, i16* %277, i64 4
  %280 = bitcast i16* %279 to i64*
  store i64 %181, i64* %280, align 8
  %281 = getelementptr inbounds i16, i16* %277, i64 8
  %282 = bitcast i16* %281 to i64*
  store i64 %181, i64* %282, align 8
  %283 = getelementptr inbounds i16, i16* %277, i64 12
  %284 = bitcast i16* %283 to i64*
  store i64 %181, i64* %284, align 8
  %285 = getelementptr inbounds i16, i16* %277, i64 %4
  %286 = bitcast i16* %285 to i64*
  store i64 %181, i64* %286, align 8
  %287 = getelementptr inbounds i16, i16* %285, i64 4
  %288 = bitcast i16* %287 to i64*
  store i64 %181, i64* %288, align 8
  %289 = getelementptr inbounds i16, i16* %285, i64 8
  %290 = bitcast i16* %289 to i64*
  store i64 %181, i64* %290, align 8
  %291 = getelementptr inbounds i16, i16* %285, i64 12
  %292 = bitcast i16* %291 to i64*
  store i64 %181, i64* %292, align 8
  %293 = getelementptr inbounds i16, i16* %285, i64 %4
  %294 = bitcast i16* %293 to i64*
  store i64 %181, i64* %294, align 8
  %295 = getelementptr inbounds i16, i16* %293, i64 4
  %296 = bitcast i16* %295 to i64*
  store i64 %181, i64* %296, align 8
  %297 = getelementptr inbounds i16, i16* %293, i64 8
  %298 = bitcast i16* %297 to i64*
  store i64 %181, i64* %298, align 8
  %299 = getelementptr inbounds i16, i16* %293, i64 12
  %300 = bitcast i16* %299 to i64*
  store i64 %181, i64* %300, align 8
  %301 = getelementptr inbounds i16, i16* %293, i64 %4
  %302 = bitcast i16* %301 to i64*
  store i64 %181, i64* %302, align 8
  %303 = getelementptr inbounds i16, i16* %301, i64 4
  %304 = bitcast i16* %303 to i64*
  store i64 %181, i64* %304, align 8
  %305 = getelementptr inbounds i16, i16* %301, i64 8
  %306 = bitcast i16* %305 to i64*
  store i64 %181, i64* %306, align 8
  %307 = getelementptr inbounds i16, i16* %301, i64 12
  %308 = bitcast i16* %307 to i64*
  store i64 %181, i64* %308, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_vertical_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds i16, i16* %8, i64 4
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = getelementptr inbounds i16, i16* %8, i64 8
  %15 = bitcast i16* %14 to i64*
  %16 = load i64, i64* %15, align 8
  %17 = getelementptr inbounds i16, i16* %8, i64 12
  %18 = bitcast i16* %17 to i64*
  %19 = load i64, i64* %18, align 8
  %20 = shl i64 %4, 32
  %21 = ashr exact i64 %20, 32
  %22 = bitcast i8* %0 to i64*
  store i64 %10, i64* %22, align 8
  %23 = getelementptr inbounds i8, i8* %0, i64 8
  %24 = bitcast i8* %23 to i64*
  store i64 %13, i64* %24, align 8
  %25 = getelementptr inbounds i8, i8* %0, i64 16
  %26 = bitcast i8* %25 to i64*
  store i64 %16, i64* %26, align 8
  %27 = getelementptr inbounds i8, i8* %0, i64 24
  %28 = bitcast i8* %27 to i64*
  store i64 %19, i64* %28, align 8
  %29 = getelementptr inbounds i16, i16* %3, i64 %21
  %30 = bitcast i16* %29 to i64*
  store i64 %10, i64* %30, align 8
  %31 = getelementptr inbounds i16, i16* %29, i64 4
  %32 = bitcast i16* %31 to i64*
  store i64 %13, i64* %32, align 8
  %33 = getelementptr inbounds i16, i16* %29, i64 8
  %34 = bitcast i16* %33 to i64*
  store i64 %16, i64* %34, align 8
  %35 = getelementptr inbounds i16, i16* %29, i64 12
  %36 = bitcast i16* %35 to i64*
  store i64 %19, i64* %36, align 8
  %37 = ashr exact i64 %20, 31
  %38 = getelementptr inbounds i16, i16* %3, i64 %37
  %39 = bitcast i16* %38 to i64*
  store i64 %10, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %38, i64 4
  %41 = bitcast i16* %40 to i64*
  store i64 %13, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %38, i64 8
  %43 = bitcast i16* %42 to i64*
  store i64 %16, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %38, i64 12
  %45 = bitcast i16* %44 to i64*
  store i64 %19, i64* %45, align 8
  %46 = mul nsw i64 %21, 3
  %47 = getelementptr inbounds i16, i16* %3, i64 %46
  %48 = bitcast i16* %47 to i64*
  store i64 %10, i64* %48, align 8
  %49 = getelementptr inbounds i16, i16* %47, i64 4
  %50 = bitcast i16* %49 to i64*
  store i64 %13, i64* %50, align 8
  %51 = getelementptr inbounds i16, i16* %47, i64 8
  %52 = bitcast i16* %51 to i64*
  store i64 %16, i64* %52, align 8
  %53 = getelementptr inbounds i16, i16* %47, i64 12
  %54 = bitcast i16* %53 to i64*
  store i64 %19, i64* %54, align 8
  %55 = ashr exact i64 %20, 30
  %56 = getelementptr inbounds i16, i16* %3, i64 %55
  %57 = bitcast i16* %56 to i64*
  store i64 %10, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %56, i64 4
  %59 = bitcast i16* %58 to i64*
  store i64 %13, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %56, i64 8
  %61 = bitcast i16* %60 to i64*
  store i64 %16, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %56, i64 12
  %63 = bitcast i16* %62 to i64*
  store i64 %19, i64* %63, align 8
  %64 = mul nsw i64 %21, 5
  %65 = getelementptr inbounds i16, i16* %3, i64 %64
  %66 = bitcast i16* %65 to i64*
  store i64 %10, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %13, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %65, i64 8
  %70 = bitcast i16* %69 to i64*
  store i64 %16, i64* %70, align 8
  %71 = getelementptr inbounds i16, i16* %65, i64 12
  %72 = bitcast i16* %71 to i64*
  store i64 %19, i64* %72, align 8
  %73 = mul nsw i64 %21, 6
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = bitcast i16* %74 to i64*
  store i64 %10, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %13, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %74, i64 8
  %79 = bitcast i16* %78 to i64*
  store i64 %16, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %74, i64 12
  %81 = bitcast i16* %80 to i64*
  store i64 %19, i64* %81, align 8
  %82 = mul nsw i64 %21, 7
  %83 = getelementptr inbounds i16, i16* %3, i64 %82
  %84 = bitcast i16* %83 to i64*
  store i64 %10, i64* %84, align 8
  %85 = getelementptr inbounds i16, i16* %83, i64 4
  %86 = bitcast i16* %85 to i64*
  store i64 %13, i64* %86, align 8
  %87 = getelementptr inbounds i16, i16* %83, i64 8
  %88 = bitcast i16* %87 to i64*
  store i64 %16, i64* %88, align 8
  %89 = getelementptr inbounds i16, i16* %83, i64 12
  %90 = bitcast i16* %89 to i64*
  store i64 %19, i64* %90, align 8
  %91 = ashr exact i64 %20, 29
  %92 = getelementptr inbounds i16, i16* %3, i64 %91
  %93 = bitcast i16* %92 to i64*
  store i64 %10, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %13, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 %16, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 %19, i64* %99, align 8
  %100 = mul nsw i64 %21, 9
  %101 = getelementptr inbounds i16, i16* %3, i64 %100
  %102 = bitcast i16* %101 to i64*
  store i64 %10, i64* %102, align 8
  %103 = getelementptr inbounds i16, i16* %101, i64 4
  %104 = bitcast i16* %103 to i64*
  store i64 %13, i64* %104, align 8
  %105 = getelementptr inbounds i16, i16* %101, i64 8
  %106 = bitcast i16* %105 to i64*
  store i64 %16, i64* %106, align 8
  %107 = getelementptr inbounds i16, i16* %101, i64 12
  %108 = bitcast i16* %107 to i64*
  store i64 %19, i64* %108, align 8
  %109 = mul nsw i64 %21, 10
  %110 = getelementptr inbounds i16, i16* %3, i64 %109
  %111 = bitcast i16* %110 to i64*
  store i64 %10, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %110, i64 4
  %113 = bitcast i16* %112 to i64*
  store i64 %13, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %110, i64 8
  %115 = bitcast i16* %114 to i64*
  store i64 %16, i64* %115, align 8
  %116 = getelementptr inbounds i16, i16* %110, i64 12
  %117 = bitcast i16* %116 to i64*
  store i64 %19, i64* %117, align 8
  %118 = mul nsw i64 %21, 11
  %119 = getelementptr inbounds i16, i16* %3, i64 %118
  %120 = bitcast i16* %119 to i64*
  store i64 %10, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %119, i64 4
  %122 = bitcast i16* %121 to i64*
  store i64 %13, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %119, i64 8
  %124 = bitcast i16* %123 to i64*
  store i64 %16, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %119, i64 12
  %126 = bitcast i16* %125 to i64*
  store i64 %19, i64* %126, align 8
  %127 = mul nsw i64 %21, 12
  %128 = getelementptr inbounds i16, i16* %3, i64 %127
  %129 = bitcast i16* %128 to i64*
  store i64 %10, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %13, i64* %131, align 8
  %132 = getelementptr inbounds i16, i16* %128, i64 8
  %133 = bitcast i16* %132 to i64*
  store i64 %16, i64* %133, align 8
  %134 = getelementptr inbounds i16, i16* %128, i64 12
  %135 = bitcast i16* %134 to i64*
  store i64 %19, i64* %135, align 8
  %136 = mul nsw i64 %21, 13
  %137 = getelementptr inbounds i16, i16* %3, i64 %136
  %138 = bitcast i16* %137 to i64*
  store i64 %10, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %137, i64 4
  %140 = bitcast i16* %139 to i64*
  store i64 %13, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %137, i64 8
  %142 = bitcast i16* %141 to i64*
  store i64 %16, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %137, i64 12
  %144 = bitcast i16* %143 to i64*
  store i64 %19, i64* %144, align 8
  %145 = mul nsw i64 %21, 14
  %146 = getelementptr inbounds i16, i16* %3, i64 %145
  %147 = bitcast i16* %146 to i64*
  store i64 %10, i64* %147, align 8
  %148 = getelementptr inbounds i16, i16* %146, i64 4
  %149 = bitcast i16* %148 to i64*
  store i64 %13, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %146, i64 8
  %151 = bitcast i16* %150 to i64*
  store i64 %16, i64* %151, align 8
  %152 = getelementptr inbounds i16, i16* %146, i64 12
  %153 = bitcast i16* %152 to i64*
  store i64 %19, i64* %153, align 8
  %154 = mul nsw i64 %21, 15
  %155 = getelementptr inbounds i16, i16* %3, i64 %154
  %156 = bitcast i16* %155 to i64*
  store i64 %10, i64* %156, align 8
  %157 = getelementptr inbounds i16, i16* %155, i64 4
  %158 = bitcast i16* %157 to i64*
  store i64 %13, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %155, i64 8
  %160 = bitcast i16* %159 to i64*
  store i64 %16, i64* %160, align 8
  %161 = getelementptr inbounds i16, i16* %155, i64 12
  %162 = bitcast i16* %161 to i64*
  store i64 %19, i64* %162, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_horizontal_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = mul nuw i64 %8, 281479271743489
  %10 = bitcast i8* %0 to i64*
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to i64*
  store i64 %9, i64* %12, align 8
  %13 = getelementptr inbounds i8, i8* %0, i64 16
  %14 = bitcast i8* %13 to i64*
  store i64 %9, i64* %14, align 8
  %15 = getelementptr inbounds i8, i8* %0, i64 24
  %16 = bitcast i8* %15 to i64*
  store i64 %9, i64* %16, align 8
  %17 = add nsw i64 %4, -1
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = mul nuw i64 %20, 281479271743489
  %22 = getelementptr inbounds i16, i16* %3, i64 %4
  %23 = bitcast i16* %22 to i64*
  store i64 %21, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %22, i64 4
  %25 = bitcast i16* %24 to i64*
  store i64 %21, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %22, i64 8
  %27 = bitcast i16* %26 to i64*
  store i64 %21, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %22, i64 12
  %29 = bitcast i16* %28 to i64*
  store i64 %21, i64* %29, align 8
  %30 = and i64 %1, -2
  %31 = add nsw i64 %30, -1
  %32 = getelementptr inbounds i16, i16* %3, i64 %31
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i64
  %35 = mul nuw i64 %34, 281479271743489
  %36 = getelementptr inbounds i16, i16* %3, i64 %30
  %37 = bitcast i16* %36 to i64*
  store i64 %35, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 %35, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 %35, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 %35, i64* %43, align 8
  %44 = mul nsw i64 %4, 3
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = mul nuw i64 %48, 281479271743489
  %50 = getelementptr inbounds i16, i16* %3, i64 %44
  %51 = bitcast i16* %50 to i64*
  store i64 %49, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %50, i64 4
  %53 = bitcast i16* %52 to i64*
  store i64 %49, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %50, i64 8
  %55 = bitcast i16* %54 to i64*
  store i64 %49, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %50, i64 12
  %57 = bitcast i16* %56 to i64*
  store i64 %49, i64* %57, align 8
  %58 = shl nsw i64 %4, 2
  %59 = add nsw i64 %58, -1
  %60 = getelementptr inbounds i16, i16* %3, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i64
  %63 = mul nuw i64 %62, 281479271743489
  %64 = getelementptr inbounds i16, i16* %3, i64 %58
  %65 = bitcast i16* %64 to i64*
  store i64 %63, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %64, i64 4
  %67 = bitcast i16* %66 to i64*
  store i64 %63, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %64, i64 8
  %69 = bitcast i16* %68 to i64*
  store i64 %63, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %64, i64 12
  %71 = bitcast i16* %70 to i64*
  store i64 %63, i64* %71, align 8
  %72 = mul nsw i64 %4, 5
  %73 = add nsw i64 %72, -1
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i64
  %77 = mul nuw i64 %76, 281479271743489
  %78 = getelementptr inbounds i16, i16* %3, i64 %72
  %79 = bitcast i16* %78 to i64*
  store i64 %77, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %77, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %78, i64 8
  %83 = bitcast i16* %82 to i64*
  store i64 %77, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %78, i64 12
  %85 = bitcast i16* %84 to i64*
  store i64 %77, i64* %85, align 8
  %86 = mul nsw i64 %4, 6
  %87 = add nsw i64 %86, -1
  %88 = getelementptr inbounds i16, i16* %3, i64 %87
  %89 = load i16, i16* %88, align 2
  %90 = zext i16 %89 to i64
  %91 = mul nuw i64 %90, 281479271743489
  %92 = getelementptr inbounds i16, i16* %3, i64 %86
  %93 = bitcast i16* %92 to i64*
  store i64 %91, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %91, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 %91, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 %91, i64* %99, align 8
  %100 = mul nsw i64 %4, 7
  %101 = add nsw i64 %100, -1
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i64
  %105 = mul nuw i64 %104, 281479271743489
  %106 = getelementptr inbounds i16, i16* %3, i64 %100
  %107 = bitcast i16* %106 to i64*
  store i64 %105, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %106, i64 4
  %109 = bitcast i16* %108 to i64*
  store i64 %105, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %106, i64 8
  %111 = bitcast i16* %110 to i64*
  store i64 %105, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %106, i64 12
  %113 = bitcast i16* %112 to i64*
  store i64 %105, i64* %113, align 8
  %114 = shl nsw i64 %4, 3
  %115 = add nsw i64 %114, -1
  %116 = getelementptr inbounds i16, i16* %3, i64 %115
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i64
  %119 = mul nuw i64 %118, 281479271743489
  %120 = getelementptr inbounds i16, i16* %3, i64 %114
  %121 = bitcast i16* %120 to i64*
  store i64 %119, i64* %121, align 8
  %122 = getelementptr inbounds i16, i16* %120, i64 4
  %123 = bitcast i16* %122 to i64*
  store i64 %119, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %120, i64 8
  %125 = bitcast i16* %124 to i64*
  store i64 %119, i64* %125, align 8
  %126 = getelementptr inbounds i16, i16* %120, i64 12
  %127 = bitcast i16* %126 to i64*
  store i64 %119, i64* %127, align 8
  %128 = mul nsw i64 %4, 9
  %129 = add nsw i64 %128, -1
  %130 = getelementptr inbounds i16, i16* %3, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i64
  %133 = mul nuw i64 %132, 281479271743489
  %134 = getelementptr inbounds i16, i16* %3, i64 %128
  %135 = bitcast i16* %134 to i64*
  store i64 %133, i64* %135, align 8
  %136 = getelementptr inbounds i16, i16* %134, i64 4
  %137 = bitcast i16* %136 to i64*
  store i64 %133, i64* %137, align 8
  %138 = getelementptr inbounds i16, i16* %134, i64 8
  %139 = bitcast i16* %138 to i64*
  store i64 %133, i64* %139, align 8
  %140 = getelementptr inbounds i16, i16* %134, i64 12
  %141 = bitcast i16* %140 to i64*
  store i64 %133, i64* %141, align 8
  %142 = mul nsw i64 %4, 10
  %143 = add nsw i64 %142, -1
  %144 = getelementptr inbounds i16, i16* %3, i64 %143
  %145 = load i16, i16* %144, align 2
  %146 = zext i16 %145 to i64
  %147 = mul nuw i64 %146, 281479271743489
  %148 = getelementptr inbounds i16, i16* %3, i64 %142
  %149 = bitcast i16* %148 to i64*
  store i64 %147, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %148, i64 4
  %151 = bitcast i16* %150 to i64*
  store i64 %147, i64* %151, align 8
  %152 = getelementptr inbounds i16, i16* %148, i64 8
  %153 = bitcast i16* %152 to i64*
  store i64 %147, i64* %153, align 8
  %154 = getelementptr inbounds i16, i16* %148, i64 12
  %155 = bitcast i16* %154 to i64*
  store i64 %147, i64* %155, align 8
  %156 = mul nsw i64 %4, 11
  %157 = add nsw i64 %156, -1
  %158 = getelementptr inbounds i16, i16* %3, i64 %157
  %159 = load i16, i16* %158, align 2
  %160 = zext i16 %159 to i64
  %161 = mul nuw i64 %160, 281479271743489
  %162 = getelementptr inbounds i16, i16* %3, i64 %156
  %163 = bitcast i16* %162 to i64*
  store i64 %161, i64* %163, align 8
  %164 = getelementptr inbounds i16, i16* %162, i64 4
  %165 = bitcast i16* %164 to i64*
  store i64 %161, i64* %165, align 8
  %166 = getelementptr inbounds i16, i16* %162, i64 8
  %167 = bitcast i16* %166 to i64*
  store i64 %161, i64* %167, align 8
  %168 = getelementptr inbounds i16, i16* %162, i64 12
  %169 = bitcast i16* %168 to i64*
  store i64 %161, i64* %169, align 8
  %170 = mul nsw i64 %4, 12
  %171 = add nsw i64 %170, -1
  %172 = getelementptr inbounds i16, i16* %3, i64 %171
  %173 = load i16, i16* %172, align 2
  %174 = zext i16 %173 to i64
  %175 = mul nuw i64 %174, 281479271743489
  %176 = getelementptr inbounds i16, i16* %3, i64 %170
  %177 = bitcast i16* %176 to i64*
  store i64 %175, i64* %177, align 8
  %178 = getelementptr inbounds i16, i16* %176, i64 4
  %179 = bitcast i16* %178 to i64*
  store i64 %175, i64* %179, align 8
  %180 = getelementptr inbounds i16, i16* %176, i64 8
  %181 = bitcast i16* %180 to i64*
  store i64 %175, i64* %181, align 8
  %182 = getelementptr inbounds i16, i16* %176, i64 12
  %183 = bitcast i16* %182 to i64*
  store i64 %175, i64* %183, align 8
  %184 = mul nsw i64 %4, 13
  %185 = add nsw i64 %184, -1
  %186 = getelementptr inbounds i16, i16* %3, i64 %185
  %187 = load i16, i16* %186, align 2
  %188 = zext i16 %187 to i64
  %189 = mul nuw i64 %188, 281479271743489
  %190 = getelementptr inbounds i16, i16* %3, i64 %184
  %191 = bitcast i16* %190 to i64*
  store i64 %189, i64* %191, align 8
  %192 = getelementptr inbounds i16, i16* %190, i64 4
  %193 = bitcast i16* %192 to i64*
  store i64 %189, i64* %193, align 8
  %194 = getelementptr inbounds i16, i16* %190, i64 8
  %195 = bitcast i16* %194 to i64*
  store i64 %189, i64* %195, align 8
  %196 = getelementptr inbounds i16, i16* %190, i64 12
  %197 = bitcast i16* %196 to i64*
  store i64 %189, i64* %197, align 8
  %198 = mul nsw i64 %4, 14
  %199 = add nsw i64 %198, -1
  %200 = getelementptr inbounds i16, i16* %3, i64 %199
  %201 = load i16, i16* %200, align 2
  %202 = zext i16 %201 to i64
  %203 = mul nuw i64 %202, 281479271743489
  %204 = getelementptr inbounds i16, i16* %3, i64 %198
  %205 = bitcast i16* %204 to i64*
  store i64 %203, i64* %205, align 8
  %206 = getelementptr inbounds i16, i16* %204, i64 4
  %207 = bitcast i16* %206 to i64*
  store i64 %203, i64* %207, align 8
  %208 = getelementptr inbounds i16, i16* %204, i64 8
  %209 = bitcast i16* %208 to i64*
  store i64 %203, i64* %209, align 8
  %210 = getelementptr inbounds i16, i16* %204, i64 12
  %211 = bitcast i16* %210 to i64*
  store i64 %203, i64* %211, align 8
  %212 = mul nsw i64 %4, 15
  %213 = add nsw i64 %212, -1
  %214 = getelementptr inbounds i16, i16* %3, i64 %213
  %215 = load i16, i16* %214, align 2
  %216 = zext i16 %215 to i64
  %217 = mul nuw i64 %216, 281479271743489
  %218 = getelementptr inbounds i16, i16* %3, i64 %212
  %219 = bitcast i16* %218 to i64*
  store i64 %217, i64* %219, align 8
  %220 = getelementptr inbounds i16, i16* %218, i64 4
  %221 = bitcast i16* %220 to i64*
  store i64 %217, i64* %221, align 8
  %222 = getelementptr inbounds i16, i16* %218, i64 8
  %223 = bitcast i16* %222 to i64*
  store i64 %217, i64* %223, align 8
  %224 = getelementptr inbounds i16, i16* %218, i64 12
  %225 = bitcast i16* %224 to i64*
  store i64 %217, i64* %225, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_127_dc_12_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i8, i8* %0, i64 16
  %7 = bitcast i8* %6 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %7, align 8
  %8 = getelementptr inbounds i16, i16* %3, i64 %4
  %9 = bitcast i16* %8 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %9, align 8
  %10 = getelementptr inbounds i16, i16* %8, i64 8
  %11 = bitcast i16* %10 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %11, align 8
  %12 = getelementptr inbounds i16, i16* %8, i64 %4
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %13, align 8
  %14 = getelementptr inbounds i16, i16* %12, i64 8
  %15 = bitcast i16* %14 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %15, align 8
  %16 = getelementptr inbounds i16, i16* %12, i64 %4
  %17 = bitcast i16* %16 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %17, align 8
  %18 = getelementptr inbounds i16, i16* %16, i64 8
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 576188069258921983, i64 576188069258921983>, <2 x i64>* %19, align 8
  %20 = getelementptr inbounds i16, i16* %16, i64 %4
  %21 = bitcast i16* %20 to i64*
  store i64 576188069258921983, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 4
  %23 = bitcast i16* %22 to i64*
  store i64 576188069258921983, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 8
  %25 = bitcast i16* %24 to i64*
  store i64 576188069258921983, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 12
  %27 = bitcast i16* %26 to i64*
  store i64 576188069258921983, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %20, i64 %4
  %29 = bitcast i16* %28 to i64*
  store i64 576188069258921983, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 576188069258921983, i64* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 8
  %33 = bitcast i16* %32 to i64*
  store i64 576188069258921983, i64* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 12
  %35 = bitcast i16* %34 to i64*
  store i64 576188069258921983, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %4
  %37 = bitcast i16* %36 to i64*
  store i64 576188069258921983, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 576188069258921983, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 576188069258921983, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 576188069258921983, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %36, i64 %4
  %45 = bitcast i16* %44 to i64*
  store i64 576188069258921983, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 576188069258921983, i64* %47, align 8
  %48 = getelementptr inbounds i16, i16* %44, i64 8
  %49 = bitcast i16* %48 to i64*
  store i64 576188069258921983, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %44, i64 12
  %51 = bitcast i16* %50 to i64*
  store i64 576188069258921983, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %44, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 576188069258921983, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 576188069258921983, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %52, i64 8
  %57 = bitcast i16* %56 to i64*
  store i64 576188069258921983, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %52, i64 12
  %59 = bitcast i16* %58 to i64*
  store i64 576188069258921983, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %52, i64 %4
  %61 = bitcast i16* %60 to i64*
  store i64 576188069258921983, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %60, i64 4
  %63 = bitcast i16* %62 to i64*
  store i64 576188069258921983, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %60, i64 8
  %65 = bitcast i16* %64 to i64*
  store i64 576188069258921983, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %60, i64 12
  %67 = bitcast i16* %66 to i64*
  store i64 576188069258921983, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %60, i64 %4
  %69 = bitcast i16* %68 to i64*
  store i64 576188069258921983, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 576188069258921983, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %68, i64 8
  %73 = bitcast i16* %72 to i64*
  store i64 576188069258921983, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %68, i64 12
  %75 = bitcast i16* %74 to i64*
  store i64 576188069258921983, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %68, i64 %4
  %77 = bitcast i16* %76 to i64*
  store i64 576188069258921983, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %76, i64 4
  %79 = bitcast i16* %78 to i64*
  store i64 576188069258921983, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %76, i64 8
  %81 = bitcast i16* %80 to i64*
  store i64 576188069258921983, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %76, i64 12
  %83 = bitcast i16* %82 to i64*
  store i64 576188069258921983, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %76, i64 %4
  %85 = bitcast i16* %84 to i64*
  store i64 576188069258921983, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 576188069258921983, i64* %87, align 8
  %88 = getelementptr inbounds i16, i16* %84, i64 8
  %89 = bitcast i16* %88 to i64*
  store i64 576188069258921983, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %84, i64 12
  %91 = bitcast i16* %90 to i64*
  store i64 576188069258921983, i64* %91, align 8
  %92 = getelementptr inbounds i16, i16* %84, i64 %4
  %93 = bitcast i16* %92 to i64*
  store i64 576188069258921983, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 576188069258921983, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 576188069258921983, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 576188069258921983, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %92, i64 %4
  %101 = bitcast i16* %100 to i64*
  store i64 576188069258921983, i64* %101, align 8
  %102 = getelementptr inbounds i16, i16* %100, i64 4
  %103 = bitcast i16* %102 to i64*
  store i64 576188069258921983, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %100, i64 8
  %105 = bitcast i16* %104 to i64*
  store i64 576188069258921983, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %100, i64 12
  %107 = bitcast i16* %106 to i64*
  store i64 576188069258921983, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %100, i64 %4
  %109 = bitcast i16* %108 to i64*
  store i64 576188069258921983, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 576188069258921983, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %108, i64 8
  %113 = bitcast i16* %112 to i64*
  store i64 576188069258921983, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %108, i64 12
  %115 = bitcast i16* %114 to i64*
  store i64 576188069258921983, i64* %115, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_129_dc_12_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i8, i8* %0, i64 16
  %7 = bitcast i8* %6 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %7, align 8
  %8 = getelementptr inbounds i16, i16* %3, i64 %4
  %9 = bitcast i16* %8 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %9, align 8
  %10 = getelementptr inbounds i16, i16* %8, i64 8
  %11 = bitcast i16* %10 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %11, align 8
  %12 = getelementptr inbounds i16, i16* %8, i64 %4
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %13, align 8
  %14 = getelementptr inbounds i16, i16* %12, i64 8
  %15 = bitcast i16* %14 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %15, align 8
  %16 = getelementptr inbounds i16, i16* %12, i64 %4
  %17 = bitcast i16* %16 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %17, align 8
  %18 = getelementptr inbounds i16, i16* %16, i64 8
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 576751027802408961, i64 576751027802408961>, <2 x i64>* %19, align 8
  %20 = getelementptr inbounds i16, i16* %16, i64 %4
  %21 = bitcast i16* %20 to i64*
  store i64 576751027802408961, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 4
  %23 = bitcast i16* %22 to i64*
  store i64 576751027802408961, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 8
  %25 = bitcast i16* %24 to i64*
  store i64 576751027802408961, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 12
  %27 = bitcast i16* %26 to i64*
  store i64 576751027802408961, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %20, i64 %4
  %29 = bitcast i16* %28 to i64*
  store i64 576751027802408961, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 576751027802408961, i64* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 8
  %33 = bitcast i16* %32 to i64*
  store i64 576751027802408961, i64* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 12
  %35 = bitcast i16* %34 to i64*
  store i64 576751027802408961, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %4
  %37 = bitcast i16* %36 to i64*
  store i64 576751027802408961, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 576751027802408961, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 576751027802408961, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 576751027802408961, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %36, i64 %4
  %45 = bitcast i16* %44 to i64*
  store i64 576751027802408961, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 576751027802408961, i64* %47, align 8
  %48 = getelementptr inbounds i16, i16* %44, i64 8
  %49 = bitcast i16* %48 to i64*
  store i64 576751027802408961, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %44, i64 12
  %51 = bitcast i16* %50 to i64*
  store i64 576751027802408961, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %44, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 576751027802408961, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 576751027802408961, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %52, i64 8
  %57 = bitcast i16* %56 to i64*
  store i64 576751027802408961, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %52, i64 12
  %59 = bitcast i16* %58 to i64*
  store i64 576751027802408961, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %52, i64 %4
  %61 = bitcast i16* %60 to i64*
  store i64 576751027802408961, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %60, i64 4
  %63 = bitcast i16* %62 to i64*
  store i64 576751027802408961, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %60, i64 8
  %65 = bitcast i16* %64 to i64*
  store i64 576751027802408961, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %60, i64 12
  %67 = bitcast i16* %66 to i64*
  store i64 576751027802408961, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %60, i64 %4
  %69 = bitcast i16* %68 to i64*
  store i64 576751027802408961, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 576751027802408961, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %68, i64 8
  %73 = bitcast i16* %72 to i64*
  store i64 576751027802408961, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %68, i64 12
  %75 = bitcast i16* %74 to i64*
  store i64 576751027802408961, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %68, i64 %4
  %77 = bitcast i16* %76 to i64*
  store i64 576751027802408961, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %76, i64 4
  %79 = bitcast i16* %78 to i64*
  store i64 576751027802408961, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %76, i64 8
  %81 = bitcast i16* %80 to i64*
  store i64 576751027802408961, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %76, i64 12
  %83 = bitcast i16* %82 to i64*
  store i64 576751027802408961, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %76, i64 %4
  %85 = bitcast i16* %84 to i64*
  store i64 576751027802408961, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 576751027802408961, i64* %87, align 8
  %88 = getelementptr inbounds i16, i16* %84, i64 8
  %89 = bitcast i16* %88 to i64*
  store i64 576751027802408961, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %84, i64 12
  %91 = bitcast i16* %90 to i64*
  store i64 576751027802408961, i64* %91, align 8
  %92 = getelementptr inbounds i16, i16* %84, i64 %4
  %93 = bitcast i16* %92 to i64*
  store i64 576751027802408961, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 576751027802408961, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 576751027802408961, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 576751027802408961, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %92, i64 %4
  %101 = bitcast i16* %100 to i64*
  store i64 576751027802408961, i64* %101, align 8
  %102 = getelementptr inbounds i16, i16* %100, i64 4
  %103 = bitcast i16* %102 to i64*
  store i64 576751027802408961, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %100, i64 8
  %105 = bitcast i16* %104 to i64*
  store i64 576751027802408961, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %100, i64 12
  %107 = bitcast i16* %106 to i64*
  store i64 576751027802408961, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %100, i64 %4
  %109 = bitcast i16* %108 to i64*
  store i64 576751027802408961, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 576751027802408961, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %108, i64 8
  %113 = bitcast i16* %112 to i64*
  store i64 576751027802408961, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %108, i64 12
  %115 = bitcast i16* %114 to i64*
  store i64 576751027802408961, i64* %115, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_plane_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 14
  %6 = bitcast i8* %5 to i16*
  %7 = shl i64 %4, 32
  %8 = ashr exact i64 %7, 32
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i16, i16* %6, i64 %9
  %11 = shl i64 %4, 35
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = getelementptr inbounds i16, i16* %13, i64 -1
  %15 = shl i64 %1, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = sub nsw i64 0, %17
  %19 = getelementptr inbounds i16, i16* %14, i64 %18
  %20 = getelementptr inbounds i16, i16* %10, i64 1
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = getelementptr inbounds i16, i16* %10, i64 -1
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = sub nsw i32 %22, %25
  %27 = load i16, i16* %14, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %19, align 2
  %30 = zext i16 %29 to i32
  %31 = sub nsw i32 %28, %30
  %32 = mul nsw i64 %8, 14
  %33 = ashr exact i64 %11, 31
  %34 = add nsw i64 %33, -2
  %35 = add nsw i64 %34, %32
  %36 = getelementptr i8, i8* %0, i64 %35
  %37 = lshr i64 %16, 1
  %38 = shl i64 %37, 2
  %39 = sub i64 %34, %38
  %40 = sub i64 %39, %32
  %41 = getelementptr i8, i8* %0, i64 %40
  %42 = getelementptr inbounds i16, i16* %14, i64 %8
  %43 = getelementptr inbounds i16, i16* %19, i64 %9
  %44 = getelementptr inbounds i16, i16* %10, i64 2
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = getelementptr inbounds i16, i16* %10, i64 -2
  %48 = load i16, i16* %47, align 2
  %49 = zext i16 %48 to i32
  %50 = sub nsw i32 %46, %49
  %51 = shl nsw i32 %50, 1
  %52 = add nsw i32 %26, %51
  %53 = load i16, i16* %42, align 2
  %54 = zext i16 %53 to i32
  %55 = load i16, i16* %43, align 2
  %56 = zext i16 %55 to i32
  %57 = sub nsw i32 %54, %56
  %58 = shl nsw i32 %57, 1
  %59 = add nsw i32 %31, %58
  %60 = getelementptr inbounds i16, i16* %42, i64 %8
  %61 = getelementptr inbounds i16, i16* %43, i64 %9
  %62 = getelementptr inbounds i16, i16* %10, i64 3
  %63 = load i16, i16* %62, align 2
  %64 = zext i16 %63 to i32
  %65 = getelementptr inbounds i16, i16* %10, i64 -3
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = sub nsw i32 %64, %67
  %69 = mul nsw i32 %68, 3
  %70 = add nsw i32 %52, %69
  %71 = load i16, i16* %60, align 2
  %72 = zext i16 %71 to i32
  %73 = load i16, i16* %61, align 2
  %74 = zext i16 %73 to i32
  %75 = sub nsw i32 %72, %74
  %76 = mul nsw i32 %75, 3
  %77 = add nsw i32 %59, %76
  %78 = getelementptr inbounds i16, i16* %60, i64 %8
  %79 = getelementptr inbounds i16, i16* %61, i64 %9
  %80 = getelementptr inbounds i16, i16* %10, i64 4
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i32
  %83 = getelementptr inbounds i16, i16* %10, i64 -4
  %84 = load i16, i16* %83, align 2
  %85 = zext i16 %84 to i32
  %86 = sub nsw i32 %82, %85
  %87 = shl nsw i32 %86, 2
  %88 = add nsw i32 %70, %87
  %89 = load i16, i16* %78, align 2
  %90 = zext i16 %89 to i32
  %91 = load i16, i16* %79, align 2
  %92 = zext i16 %91 to i32
  %93 = sub nsw i32 %90, %92
  %94 = shl nsw i32 %93, 2
  %95 = add nsw i32 %77, %94
  %96 = getelementptr inbounds i16, i16* %78, i64 %8
  %97 = getelementptr inbounds i16, i16* %79, i64 %9
  %98 = getelementptr inbounds i16, i16* %10, i64 5
  %99 = load i16, i16* %98, align 2
  %100 = zext i16 %99 to i32
  %101 = getelementptr inbounds i16, i16* %10, i64 -5
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  %104 = sub nsw i32 %100, %103
  %105 = mul nsw i32 %104, 5
  %106 = add nsw i32 %88, %105
  %107 = load i16, i16* %96, align 2
  %108 = zext i16 %107 to i32
  %109 = load i16, i16* %97, align 2
  %110 = zext i16 %109 to i32
  %111 = sub nsw i32 %108, %110
  %112 = mul nsw i32 %111, 5
  %113 = add nsw i32 %95, %112
  %114 = getelementptr inbounds i16, i16* %96, i64 %8
  %115 = getelementptr inbounds i16, i16* %97, i64 %9
  %116 = getelementptr inbounds i16, i16* %10, i64 6
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = getelementptr inbounds i16, i16* %10, i64 -6
  %120 = load i16, i16* %119, align 2
  %121 = zext i16 %120 to i32
  %122 = sub nsw i32 %118, %121
  %123 = mul nsw i32 %122, 6
  %124 = add nsw i32 %106, %123
  %125 = load i16, i16* %114, align 2
  %126 = zext i16 %125 to i32
  %127 = load i16, i16* %115, align 2
  %128 = zext i16 %127 to i32
  %129 = sub nsw i32 %126, %128
  %130 = mul nsw i32 %129, 6
  %131 = add nsw i32 %113, %130
  %132 = getelementptr inbounds i16, i16* %114, i64 %8
  %133 = getelementptr inbounds i16, i16* %115, i64 %9
  %134 = getelementptr inbounds i16, i16* %10, i64 7
  %135 = load i16, i16* %134, align 2
  %136 = zext i16 %135 to i32
  %137 = getelementptr inbounds i16, i16* %10, i64 -7
  %138 = load i16, i16* %137, align 2
  %139 = zext i16 %138 to i32
  %140 = sub nsw i32 %136, %139
  %141 = mul nsw i32 %140, 7
  %142 = add nsw i32 %124, %141
  %143 = load i16, i16* %132, align 2
  %144 = zext i16 %143 to i32
  %145 = load i16, i16* %133, align 2
  %146 = zext i16 %145 to i32
  %147 = sub nsw i32 %144, %146
  %148 = mul nsw i32 %147, 7
  %149 = add nsw i32 %131, %148
  %150 = getelementptr inbounds i16, i16* %132, i64 %8
  %151 = getelementptr inbounds i16, i16* %133, i64 %9
  %152 = getelementptr inbounds i16, i16* %10, i64 8
  %153 = load i16, i16* %152, align 2
  %154 = zext i16 %153 to i32
  %155 = getelementptr inbounds i16, i16* %10, i64 -8
  %156 = load i16, i16* %155, align 2
  %157 = zext i16 %156 to i32
  %158 = sub nsw i32 %154, %157
  %159 = shl nsw i32 %158, 3
  %160 = add nsw i32 %142, %159
  %161 = load i16, i16* %150, align 2
  %162 = zext i16 %161 to i32
  %163 = load i16, i16* %151, align 2
  %164 = zext i16 %163 to i32
  %165 = sub nsw i32 %162, %164
  %166 = shl nsw i32 %165, 3
  %167 = add nsw i32 %149, %166
  %168 = bitcast i8* %36 to i16*
  %169 = mul nsw i32 %160, 5
  %170 = add nsw i32 %169, 32
  %171 = ashr i32 %170, 6
  %172 = mul nsw i32 %167, 5
  %173 = add nsw i32 %172, 32
  %174 = ashr i32 %173, 6
  %175 = load i16, i16* %168, align 2
  %176 = zext i16 %175 to i32
  %177 = getelementptr inbounds i8, i8* %41, i64 32
  %178 = bitcast i8* %177 to i16*
  %179 = load i16, i16* %178, align 2
  %180 = zext i16 %179 to i32
  %181 = add nuw nsw i32 %180, %176
  %182 = shl nuw nsw i32 %181, 4
  %183 = add nsw i32 %174, %171
  %184 = mul nsw i32 %183, -7
  %185 = add nuw nsw i32 %182, 16
  %186 = add nsw i32 %185, %184
  %187 = shl nsw i32 %171, 1
  %188 = mul nsw i32 %171, 3
  %189 = shl nsw i32 %171, 2
  br label %190

190:                                              ; preds = %364, %2
  %191 = phi i16* [ %3, %2 ], [ %369, %364 ]
  %192 = phi i32 [ %186, %2 ], [ %368, %364 ]
  %193 = phi i32 [ 16, %2 ], [ %370, %364 ]
  %194 = ashr i32 %192, 5
  %195 = icmp ult i32 %194, 4096
  br i1 %195, label %200, label %196

196:                                              ; preds = %190
  %197 = ashr i32 %192, 31
  %198 = or i32 %197, -4096
  %199 = xor i32 %198, -1
  br label %200

200:                                              ; preds = %196, %190
  %201 = phi i32 [ %199, %196 ], [ %194, %190 ]
  %202 = trunc i32 %201 to i16
  store i16 %202, i16* %191, align 2
  %203 = add nsw i32 %192, %171
  %204 = ashr i32 %203, 5
  %205 = icmp ult i32 %204, 4096
  br i1 %205, label %210, label %206

206:                                              ; preds = %200
  %207 = ashr i32 %203, 31
  %208 = or i32 %207, -4096
  %209 = xor i32 %208, -1
  br label %210

210:                                              ; preds = %206, %200
  %211 = phi i32 [ %209, %206 ], [ %204, %200 ]
  %212 = trunc i32 %211 to i16
  %213 = getelementptr inbounds i16, i16* %191, i64 1
  store i16 %212, i16* %213, align 2
  %214 = add nsw i32 %192, %187
  %215 = ashr i32 %214, 5
  %216 = icmp ult i32 %215, 4096
  br i1 %216, label %221, label %217

217:                                              ; preds = %210
  %218 = ashr i32 %214, 31
  %219 = or i32 %218, -4096
  %220 = xor i32 %219, -1
  br label %221

221:                                              ; preds = %217, %210
  %222 = phi i32 [ %220, %217 ], [ %215, %210 ]
  %223 = trunc i32 %222 to i16
  %224 = getelementptr inbounds i16, i16* %191, i64 2
  store i16 %223, i16* %224, align 2
  %225 = add nsw i32 %192, %188
  %226 = ashr i32 %225, 5
  %227 = icmp ult i32 %226, 4096
  br i1 %227, label %232, label %228

228:                                              ; preds = %221
  %229 = ashr i32 %225, 31
  %230 = or i32 %229, -4096
  %231 = xor i32 %230, -1
  br label %232

232:                                              ; preds = %228, %221
  %233 = phi i32 [ %231, %228 ], [ %226, %221 ]
  %234 = trunc i32 %233 to i16
  %235 = getelementptr inbounds i16, i16* %191, i64 3
  store i16 %234, i16* %235, align 2
  %236 = add nsw i32 %192, %189
  %237 = ashr i32 %236, 5
  %238 = icmp ult i32 %237, 4096
  br i1 %238, label %243, label %239

239:                                              ; preds = %232
  %240 = ashr i32 %236, 31
  %241 = or i32 %240, -4096
  %242 = xor i32 %241, -1
  br label %243

243:                                              ; preds = %239, %232
  %244 = phi i32 [ %242, %239 ], [ %237, %232 ]
  %245 = trunc i32 %244 to i16
  %246 = getelementptr inbounds i16, i16* %191, i64 4
  store i16 %245, i16* %246, align 2
  %247 = add nsw i32 %236, %171
  %248 = ashr i32 %247, 5
  %249 = icmp ult i32 %248, 4096
  br i1 %249, label %254, label %250

250:                                              ; preds = %243
  %251 = ashr i32 %247, 31
  %252 = or i32 %251, -4096
  %253 = xor i32 %252, -1
  br label %254

254:                                              ; preds = %250, %243
  %255 = phi i32 [ %253, %250 ], [ %248, %243 ]
  %256 = trunc i32 %255 to i16
  %257 = getelementptr inbounds i16, i16* %191, i64 5
  store i16 %256, i16* %257, align 2
  %258 = add nsw i32 %236, %187
  %259 = ashr i32 %258, 5
  %260 = icmp ult i32 %259, 4096
  br i1 %260, label %265, label %261

261:                                              ; preds = %254
  %262 = ashr i32 %258, 31
  %263 = or i32 %262, -4096
  %264 = xor i32 %263, -1
  br label %265

265:                                              ; preds = %261, %254
  %266 = phi i32 [ %264, %261 ], [ %259, %254 ]
  %267 = trunc i32 %266 to i16
  %268 = getelementptr inbounds i16, i16* %191, i64 6
  store i16 %267, i16* %268, align 2
  %269 = add nsw i32 %236, %188
  %270 = ashr i32 %269, 5
  %271 = icmp ult i32 %270, 4096
  br i1 %271, label %276, label %272

272:                                              ; preds = %265
  %273 = ashr i32 %269, 31
  %274 = or i32 %273, -4096
  %275 = xor i32 %274, -1
  br label %276

276:                                              ; preds = %272, %265
  %277 = phi i32 [ %275, %272 ], [ %270, %265 ]
  %278 = trunc i32 %277 to i16
  %279 = getelementptr inbounds i16, i16* %191, i64 7
  store i16 %278, i16* %279, align 2
  %280 = add nsw i32 %236, %189
  %281 = ashr i32 %280, 5
  %282 = icmp ult i32 %281, 4096
  br i1 %282, label %287, label %283

283:                                              ; preds = %276
  %284 = ashr i32 %280, 31
  %285 = or i32 %284, -4096
  %286 = xor i32 %285, -1
  br label %287

287:                                              ; preds = %283, %276
  %288 = phi i32 [ %286, %283 ], [ %281, %276 ]
  %289 = trunc i32 %288 to i16
  %290 = getelementptr inbounds i16, i16* %191, i64 8
  store i16 %289, i16* %290, align 2
  %291 = add nsw i32 %280, %171
  %292 = ashr i32 %291, 5
  %293 = icmp ult i32 %292, 4096
  br i1 %293, label %298, label %294

294:                                              ; preds = %287
  %295 = ashr i32 %291, 31
  %296 = or i32 %295, -4096
  %297 = xor i32 %296, -1
  br label %298

298:                                              ; preds = %294, %287
  %299 = phi i32 [ %297, %294 ], [ %292, %287 ]
  %300 = trunc i32 %299 to i16
  %301 = getelementptr inbounds i16, i16* %191, i64 9
  store i16 %300, i16* %301, align 2
  %302 = add nsw i32 %280, %187
  %303 = ashr i32 %302, 5
  %304 = icmp ult i32 %303, 4096
  br i1 %304, label %309, label %305

305:                                              ; preds = %298
  %306 = ashr i32 %302, 31
  %307 = or i32 %306, -4096
  %308 = xor i32 %307, -1
  br label %309

309:                                              ; preds = %305, %298
  %310 = phi i32 [ %308, %305 ], [ %303, %298 ]
  %311 = trunc i32 %310 to i16
  %312 = getelementptr inbounds i16, i16* %191, i64 10
  store i16 %311, i16* %312, align 2
  %313 = add nsw i32 %280, %188
  %314 = ashr i32 %313, 5
  %315 = icmp ult i32 %314, 4096
  br i1 %315, label %320, label %316

316:                                              ; preds = %309
  %317 = ashr i32 %313, 31
  %318 = or i32 %317, -4096
  %319 = xor i32 %318, -1
  br label %320

320:                                              ; preds = %316, %309
  %321 = phi i32 [ %319, %316 ], [ %314, %309 ]
  %322 = trunc i32 %321 to i16
  %323 = getelementptr inbounds i16, i16* %191, i64 11
  store i16 %322, i16* %323, align 2
  %324 = add nsw i32 %280, %189
  %325 = ashr i32 %324, 5
  %326 = icmp ult i32 %325, 4096
  br i1 %326, label %331, label %327

327:                                              ; preds = %320
  %328 = ashr i32 %324, 31
  %329 = or i32 %328, -4096
  %330 = xor i32 %329, -1
  br label %331

331:                                              ; preds = %327, %320
  %332 = phi i32 [ %330, %327 ], [ %325, %320 ]
  %333 = trunc i32 %332 to i16
  %334 = getelementptr inbounds i16, i16* %191, i64 12
  store i16 %333, i16* %334, align 2
  %335 = add nsw i32 %324, %171
  %336 = ashr i32 %335, 5
  %337 = icmp ult i32 %336, 4096
  br i1 %337, label %342, label %338

338:                                              ; preds = %331
  %339 = ashr i32 %335, 31
  %340 = or i32 %339, -4096
  %341 = xor i32 %340, -1
  br label %342

342:                                              ; preds = %338, %331
  %343 = phi i32 [ %341, %338 ], [ %336, %331 ]
  %344 = trunc i32 %343 to i16
  %345 = getelementptr inbounds i16, i16* %191, i64 13
  store i16 %344, i16* %345, align 2
  %346 = add nsw i32 %324, %187
  %347 = ashr i32 %346, 5
  %348 = icmp ult i32 %347, 4096
  br i1 %348, label %353, label %349

349:                                              ; preds = %342
  %350 = ashr i32 %346, 31
  %351 = or i32 %350, -4096
  %352 = xor i32 %351, -1
  br label %353

353:                                              ; preds = %349, %342
  %354 = phi i32 [ %352, %349 ], [ %347, %342 ]
  %355 = trunc i32 %354 to i16
  %356 = getelementptr inbounds i16, i16* %191, i64 14
  store i16 %355, i16* %356, align 2
  %357 = add nsw i32 %324, %188
  %358 = ashr i32 %357, 5
  %359 = icmp ult i32 %358, 4096
  br i1 %359, label %364, label %360

360:                                              ; preds = %353
  %361 = ashr i32 %357, 31
  %362 = or i32 %361, -4096
  %363 = xor i32 %362, -1
  br label %364

364:                                              ; preds = %360, %353
  %365 = phi i32 [ %363, %360 ], [ %358, %353 ]
  %366 = trunc i32 %365 to i16
  %367 = getelementptr inbounds i16, i16* %191, i64 15
  store i16 %366, i16* %367, align 2
  %368 = add nsw i32 %192, %174
  %369 = getelementptr inbounds i16, i16* %191, i64 %8
  %370 = add nsw i32 %193, -1
  %371 = icmp eq i32 %370, 0
  br i1 %371, label %372, label %190

372:                                              ; preds = %364
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_left_dc_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = add nsw i64 %4, -1
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = and i64 %1, -2
  %15 = add nsw i64 %14, -1
  %16 = getelementptr inbounds i16, i16* %3, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i64
  %19 = add nuw nsw i64 %13, %18
  %20 = mul nsw i64 %4, 3
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = add nuw nsw i64 %19, %24
  %26 = shl nsw i64 %4, 2
  %27 = add nsw i64 %26, -1
  %28 = getelementptr inbounds i16, i16* %3, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = zext i16 %29 to i64
  %31 = add nuw nsw i64 %25, %30
  %32 = mul nsw i64 %4, 5
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %31, %36
  %38 = mul nsw i64 %4, 6
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %37, %42
  %44 = mul nsw i64 %4, 7
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = add nuw nsw i64 %43, %48
  %50 = shl nsw i64 %4, 3
  %51 = add nsw i64 %50, -1
  %52 = getelementptr inbounds i16, i16* %3, i64 %51
  %53 = load i16, i16* %52, align 2
  %54 = zext i16 %53 to i64
  %55 = add nuw nsw i64 %49, %54
  %56 = mul nsw i64 %4, 9
  %57 = add nsw i64 %56, -1
  %58 = getelementptr inbounds i16, i16* %3, i64 %57
  %59 = load i16, i16* %58, align 2
  %60 = zext i16 %59 to i64
  %61 = add nuw nsw i64 %55, %60
  %62 = mul nsw i64 %4, 10
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = add nuw nsw i64 %61, %66
  %68 = mul nsw i64 %4, 11
  %69 = add nsw i64 %68, -1
  %70 = getelementptr inbounds i16, i16* %3, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i64
  %73 = add nuw nsw i64 %67, %72
  %74 = mul nsw i64 %4, 12
  %75 = add nsw i64 %74, -1
  %76 = getelementptr inbounds i16, i16* %3, i64 %75
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i64
  %79 = add nuw nsw i64 %73, %78
  %80 = mul nsw i64 %4, 13
  %81 = add nsw i64 %80, -1
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = zext i16 %83 to i64
  %85 = add nuw nsw i64 %79, %84
  %86 = mul nsw i64 %4, 14
  %87 = add nsw i64 %86, -1
  %88 = getelementptr inbounds i16, i16* %3, i64 %87
  %89 = load i16, i16* %88, align 2
  %90 = zext i16 %89 to i64
  %91 = add nuw nsw i64 %85, %90
  %92 = mul nsw i64 %4, 15
  %93 = add nsw i64 %92, -1
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i64
  %97 = add nuw nsw i64 %91, %96
  %98 = add nuw nsw i64 %97, 8
  %99 = lshr i64 %98, 4
  %100 = and i64 %99, 268435455
  %101 = mul i64 %100, 281479271743489
  %102 = bitcast i8* %0 to i64*
  store i64 %101, i64* %102, align 8
  %103 = getelementptr inbounds i8, i8* %0, i64 8
  %104 = bitcast i8* %103 to i64*
  store i64 %101, i64* %104, align 8
  %105 = getelementptr inbounds i8, i8* %0, i64 16
  %106 = bitcast i8* %105 to i64*
  store i64 %101, i64* %106, align 8
  %107 = getelementptr inbounds i8, i8* %0, i64 24
  %108 = bitcast i8* %107 to i64*
  store i64 %101, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %3, i64 %4
  %110 = bitcast i16* %109 to i64*
  store i64 %101, i64* %110, align 8
  %111 = getelementptr inbounds i16, i16* %109, i64 4
  %112 = bitcast i16* %111 to i64*
  store i64 %101, i64* %112, align 8
  %113 = getelementptr inbounds i16, i16* %109, i64 8
  %114 = bitcast i16* %113 to i64*
  store i64 %101, i64* %114, align 8
  %115 = getelementptr inbounds i16, i16* %109, i64 12
  %116 = bitcast i16* %115 to i64*
  store i64 %101, i64* %116, align 8
  %117 = getelementptr inbounds i16, i16* %109, i64 %4
  %118 = bitcast i16* %117 to i64*
  store i64 %101, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %117, i64 4
  %120 = bitcast i16* %119 to i64*
  store i64 %101, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %117, i64 8
  %122 = bitcast i16* %121 to i64*
  store i64 %101, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %117, i64 12
  %124 = bitcast i16* %123 to i64*
  store i64 %101, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %117, i64 %4
  %126 = bitcast i16* %125 to i64*
  store i64 %101, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %125, i64 4
  %128 = bitcast i16* %127 to i64*
  store i64 %101, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %125, i64 8
  %130 = bitcast i16* %129 to i64*
  store i64 %101, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %125, i64 12
  %132 = bitcast i16* %131 to i64*
  store i64 %101, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %125, i64 %4
  %134 = bitcast i16* %133 to i64*
  store i64 %101, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %133, i64 4
  %136 = bitcast i16* %135 to i64*
  store i64 %101, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %133, i64 8
  %138 = bitcast i16* %137 to i64*
  store i64 %101, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %133, i64 12
  %140 = bitcast i16* %139 to i64*
  store i64 %101, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %133, i64 %4
  %142 = bitcast i16* %141 to i64*
  store i64 %101, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %101, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %141, i64 8
  %146 = bitcast i16* %145 to i64*
  store i64 %101, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %141, i64 12
  %148 = bitcast i16* %147 to i64*
  store i64 %101, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %141, i64 %4
  %150 = bitcast i16* %149 to i64*
  store i64 %101, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %149, i64 4
  %152 = bitcast i16* %151 to i64*
  store i64 %101, i64* %152, align 8
  %153 = getelementptr inbounds i16, i16* %149, i64 8
  %154 = bitcast i16* %153 to i64*
  store i64 %101, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %149, i64 12
  %156 = bitcast i16* %155 to i64*
  store i64 %101, i64* %156, align 8
  %157 = getelementptr inbounds i16, i16* %149, i64 %4
  %158 = bitcast i16* %157 to i64*
  store i64 %101, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %157, i64 4
  %160 = bitcast i16* %159 to i64*
  store i64 %101, i64* %160, align 8
  %161 = getelementptr inbounds i16, i16* %157, i64 8
  %162 = bitcast i16* %161 to i64*
  store i64 %101, i64* %162, align 8
  %163 = getelementptr inbounds i16, i16* %157, i64 12
  %164 = bitcast i16* %163 to i64*
  store i64 %101, i64* %164, align 8
  %165 = getelementptr inbounds i16, i16* %157, i64 %4
  %166 = bitcast i16* %165 to i64*
  store i64 %101, i64* %166, align 8
  %167 = getelementptr inbounds i16, i16* %165, i64 4
  %168 = bitcast i16* %167 to i64*
  store i64 %101, i64* %168, align 8
  %169 = getelementptr inbounds i16, i16* %165, i64 8
  %170 = bitcast i16* %169 to i64*
  store i64 %101, i64* %170, align 8
  %171 = getelementptr inbounds i16, i16* %165, i64 12
  %172 = bitcast i16* %171 to i64*
  store i64 %101, i64* %172, align 8
  %173 = getelementptr inbounds i16, i16* %165, i64 %4
  %174 = bitcast i16* %173 to i64*
  store i64 %101, i64* %174, align 8
  %175 = getelementptr inbounds i16, i16* %173, i64 4
  %176 = bitcast i16* %175 to i64*
  store i64 %101, i64* %176, align 8
  %177 = getelementptr inbounds i16, i16* %173, i64 8
  %178 = bitcast i16* %177 to i64*
  store i64 %101, i64* %178, align 8
  %179 = getelementptr inbounds i16, i16* %173, i64 12
  %180 = bitcast i16* %179 to i64*
  store i64 %101, i64* %180, align 8
  %181 = getelementptr inbounds i16, i16* %173, i64 %4
  %182 = bitcast i16* %181 to i64*
  store i64 %101, i64* %182, align 8
  %183 = getelementptr inbounds i16, i16* %181, i64 4
  %184 = bitcast i16* %183 to i64*
  store i64 %101, i64* %184, align 8
  %185 = getelementptr inbounds i16, i16* %181, i64 8
  %186 = bitcast i16* %185 to i64*
  store i64 %101, i64* %186, align 8
  %187 = getelementptr inbounds i16, i16* %181, i64 12
  %188 = bitcast i16* %187 to i64*
  store i64 %101, i64* %188, align 8
  %189 = getelementptr inbounds i16, i16* %181, i64 %4
  %190 = bitcast i16* %189 to i64*
  store i64 %101, i64* %190, align 8
  %191 = getelementptr inbounds i16, i16* %189, i64 4
  %192 = bitcast i16* %191 to i64*
  store i64 %101, i64* %192, align 8
  %193 = getelementptr inbounds i16, i16* %189, i64 8
  %194 = bitcast i16* %193 to i64*
  store i64 %101, i64* %194, align 8
  %195 = getelementptr inbounds i16, i16* %189, i64 12
  %196 = bitcast i16* %195 to i64*
  store i64 %101, i64* %196, align 8
  %197 = getelementptr inbounds i16, i16* %189, i64 %4
  %198 = bitcast i16* %197 to i64*
  store i64 %101, i64* %198, align 8
  %199 = getelementptr inbounds i16, i16* %197, i64 4
  %200 = bitcast i16* %199 to i64*
  store i64 %101, i64* %200, align 8
  %201 = getelementptr inbounds i16, i16* %197, i64 8
  %202 = bitcast i16* %201 to i64*
  store i64 %101, i64* %202, align 8
  %203 = getelementptr inbounds i16, i16* %197, i64 12
  %204 = bitcast i16* %203 to i64*
  store i64 %101, i64* %204, align 8
  %205 = getelementptr inbounds i16, i16* %197, i64 %4
  %206 = bitcast i16* %205 to i64*
  store i64 %101, i64* %206, align 8
  %207 = getelementptr inbounds i16, i16* %205, i64 4
  %208 = bitcast i16* %207 to i64*
  store i64 %101, i64* %208, align 8
  %209 = getelementptr inbounds i16, i16* %205, i64 8
  %210 = bitcast i16* %209 to i64*
  store i64 %101, i64* %210, align 8
  %211 = getelementptr inbounds i16, i16* %205, i64 12
  %212 = bitcast i16* %211 to i64*
  store i64 %101, i64* %212, align 8
  %213 = getelementptr inbounds i16, i16* %205, i64 %4
  %214 = bitcast i16* %213 to i64*
  store i64 %101, i64* %214, align 8
  %215 = getelementptr inbounds i16, i16* %213, i64 4
  %216 = bitcast i16* %215 to i64*
  store i64 %101, i64* %216, align 8
  %217 = getelementptr inbounds i16, i16* %213, i64 8
  %218 = bitcast i16* %217 to i64*
  store i64 %101, i64* %218, align 8
  %219 = getelementptr inbounds i16, i16* %213, i64 12
  %220 = bitcast i16* %219 to i64*
  store i64 %101, i64* %220, align 8
  %221 = getelementptr inbounds i16, i16* %213, i64 %4
  %222 = bitcast i16* %221 to i64*
  store i64 %101, i64* %222, align 8
  %223 = getelementptr inbounds i16, i16* %221, i64 4
  %224 = bitcast i16* %223 to i64*
  store i64 %101, i64* %224, align 8
  %225 = getelementptr inbounds i16, i16* %221, i64 8
  %226 = bitcast i16* %225 to i64*
  store i64 %101, i64* %226, align 8
  %227 = getelementptr inbounds i16, i16* %221, i64 12
  %228 = bitcast i16* %227 to i64*
  store i64 %101, i64* %228, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_top_dc_12_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 1, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = sub nsw i64 2, %4
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = add nuw nsw i64 %13, %17
  %19 = sub nsw i64 3, %4
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = add nuw nsw i64 %18, %22
  %24 = sub nsw i64 4, %4
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = add nuw nsw i64 %23, %27
  %29 = sub nsw i64 5, %4
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = add nuw nsw i64 %28, %32
  %34 = sub nsw i64 6, %4
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = add nuw nsw i64 %33, %37
  %39 = sub nsw i64 7, %4
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %38, %42
  %44 = sub nsw i64 8, %4
  %45 = getelementptr inbounds i16, i16* %3, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i64
  %48 = add nuw nsw i64 %43, %47
  %49 = sub nsw i64 9, %4
  %50 = getelementptr inbounds i16, i16* %3, i64 %49
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i64
  %53 = add nuw nsw i64 %48, %52
  %54 = sub nsw i64 10, %4
  %55 = getelementptr inbounds i16, i16* %3, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i64
  %58 = add nuw nsw i64 %53, %57
  %59 = sub nsw i64 11, %4
  %60 = getelementptr inbounds i16, i16* %3, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i64
  %63 = add nuw nsw i64 %58, %62
  %64 = sub nsw i64 12, %4
  %65 = getelementptr inbounds i16, i16* %3, i64 %64
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i64
  %68 = add nuw nsw i64 %63, %67
  %69 = sub nsw i64 13, %4
  %70 = getelementptr inbounds i16, i16* %3, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i64
  %73 = add nuw nsw i64 %68, %72
  %74 = sub nsw i64 14, %4
  %75 = getelementptr inbounds i16, i16* %3, i64 %74
  %76 = load i16, i16* %75, align 2
  %77 = zext i16 %76 to i64
  %78 = add nuw nsw i64 %73, %77
  %79 = sub nsw i64 15, %4
  %80 = getelementptr inbounds i16, i16* %3, i64 %79
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i64
  %83 = add nuw nsw i64 %78, %82
  %84 = add nuw nsw i64 %83, 8
  %85 = lshr i64 %84, 4
  %86 = and i64 %85, 268435455
  %87 = mul i64 %86, 281479271743489
  %88 = bitcast i8* %0 to i64*
  store i64 %87, i64* %88, align 8
  %89 = getelementptr inbounds i8, i8* %0, i64 8
  %90 = bitcast i8* %89 to i64*
  store i64 %87, i64* %90, align 8
  %91 = getelementptr inbounds i8, i8* %0, i64 16
  %92 = bitcast i8* %91 to i64*
  store i64 %87, i64* %92, align 8
  %93 = getelementptr inbounds i8, i8* %0, i64 24
  %94 = bitcast i8* %93 to i64*
  store i64 %87, i64* %94, align 8
  %95 = getelementptr inbounds i16, i16* %3, i64 %4
  %96 = bitcast i16* %95 to i64*
  store i64 %87, i64* %96, align 8
  %97 = getelementptr inbounds i16, i16* %95, i64 4
  %98 = bitcast i16* %97 to i64*
  store i64 %87, i64* %98, align 8
  %99 = getelementptr inbounds i16, i16* %95, i64 8
  %100 = bitcast i16* %99 to i64*
  store i64 %87, i64* %100, align 8
  %101 = getelementptr inbounds i16, i16* %95, i64 12
  %102 = bitcast i16* %101 to i64*
  store i64 %87, i64* %102, align 8
  %103 = getelementptr inbounds i16, i16* %95, i64 %4
  %104 = bitcast i16* %103 to i64*
  store i64 %87, i64* %104, align 8
  %105 = getelementptr inbounds i16, i16* %103, i64 4
  %106 = bitcast i16* %105 to i64*
  store i64 %87, i64* %106, align 8
  %107 = getelementptr inbounds i16, i16* %103, i64 8
  %108 = bitcast i16* %107 to i64*
  store i64 %87, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %103, i64 12
  %110 = bitcast i16* %109 to i64*
  store i64 %87, i64* %110, align 8
  %111 = getelementptr inbounds i16, i16* %103, i64 %4
  %112 = bitcast i16* %111 to i64*
  store i64 %87, i64* %112, align 8
  %113 = getelementptr inbounds i16, i16* %111, i64 4
  %114 = bitcast i16* %113 to i64*
  store i64 %87, i64* %114, align 8
  %115 = getelementptr inbounds i16, i16* %111, i64 8
  %116 = bitcast i16* %115 to i64*
  store i64 %87, i64* %116, align 8
  %117 = getelementptr inbounds i16, i16* %111, i64 12
  %118 = bitcast i16* %117 to i64*
  store i64 %87, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %111, i64 %4
  %120 = bitcast i16* %119 to i64*
  store i64 %87, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %119, i64 4
  %122 = bitcast i16* %121 to i64*
  store i64 %87, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %119, i64 8
  %124 = bitcast i16* %123 to i64*
  store i64 %87, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %119, i64 12
  %126 = bitcast i16* %125 to i64*
  store i64 %87, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %119, i64 %4
  %128 = bitcast i16* %127 to i64*
  store i64 %87, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %127, i64 4
  %130 = bitcast i16* %129 to i64*
  store i64 %87, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %127, i64 8
  %132 = bitcast i16* %131 to i64*
  store i64 %87, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %127, i64 12
  %134 = bitcast i16* %133 to i64*
  store i64 %87, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %127, i64 %4
  %136 = bitcast i16* %135 to i64*
  store i64 %87, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %135, i64 4
  %138 = bitcast i16* %137 to i64*
  store i64 %87, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %135, i64 8
  %140 = bitcast i16* %139 to i64*
  store i64 %87, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %135, i64 12
  %142 = bitcast i16* %141 to i64*
  store i64 %87, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %135, i64 %4
  %144 = bitcast i16* %143 to i64*
  store i64 %87, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %143, i64 4
  %146 = bitcast i16* %145 to i64*
  store i64 %87, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %143, i64 8
  %148 = bitcast i16* %147 to i64*
  store i64 %87, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %143, i64 12
  %150 = bitcast i16* %149 to i64*
  store i64 %87, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %143, i64 %4
  %152 = bitcast i16* %151 to i64*
  store i64 %87, i64* %152, align 8
  %153 = getelementptr inbounds i16, i16* %151, i64 4
  %154 = bitcast i16* %153 to i64*
  store i64 %87, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %151, i64 8
  %156 = bitcast i16* %155 to i64*
  store i64 %87, i64* %156, align 8
  %157 = getelementptr inbounds i16, i16* %151, i64 12
  %158 = bitcast i16* %157 to i64*
  store i64 %87, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %151, i64 %4
  %160 = bitcast i16* %159 to i64*
  store i64 %87, i64* %160, align 8
  %161 = getelementptr inbounds i16, i16* %159, i64 4
  %162 = bitcast i16* %161 to i64*
  store i64 %87, i64* %162, align 8
  %163 = getelementptr inbounds i16, i16* %159, i64 8
  %164 = bitcast i16* %163 to i64*
  store i64 %87, i64* %164, align 8
  %165 = getelementptr inbounds i16, i16* %159, i64 12
  %166 = bitcast i16* %165 to i64*
  store i64 %87, i64* %166, align 8
  %167 = getelementptr inbounds i16, i16* %159, i64 %4
  %168 = bitcast i16* %167 to i64*
  store i64 %87, i64* %168, align 8
  %169 = getelementptr inbounds i16, i16* %167, i64 4
  %170 = bitcast i16* %169 to i64*
  store i64 %87, i64* %170, align 8
  %171 = getelementptr inbounds i16, i16* %167, i64 8
  %172 = bitcast i16* %171 to i64*
  store i64 %87, i64* %172, align 8
  %173 = getelementptr inbounds i16, i16* %167, i64 12
  %174 = bitcast i16* %173 to i64*
  store i64 %87, i64* %174, align 8
  %175 = getelementptr inbounds i16, i16* %167, i64 %4
  %176 = bitcast i16* %175 to i64*
  store i64 %87, i64* %176, align 8
  %177 = getelementptr inbounds i16, i16* %175, i64 4
  %178 = bitcast i16* %177 to i64*
  store i64 %87, i64* %178, align 8
  %179 = getelementptr inbounds i16, i16* %175, i64 8
  %180 = bitcast i16* %179 to i64*
  store i64 %87, i64* %180, align 8
  %181 = getelementptr inbounds i16, i16* %175, i64 12
  %182 = bitcast i16* %181 to i64*
  store i64 %87, i64* %182, align 8
  %183 = getelementptr inbounds i16, i16* %175, i64 %4
  %184 = bitcast i16* %183 to i64*
  store i64 %87, i64* %184, align 8
  %185 = getelementptr inbounds i16, i16* %183, i64 4
  %186 = bitcast i16* %185 to i64*
  store i64 %87, i64* %186, align 8
  %187 = getelementptr inbounds i16, i16* %183, i64 8
  %188 = bitcast i16* %187 to i64*
  store i64 %87, i64* %188, align 8
  %189 = getelementptr inbounds i16, i16* %183, i64 12
  %190 = bitcast i16* %189 to i64*
  store i64 %87, i64* %190, align 8
  %191 = getelementptr inbounds i16, i16* %183, i64 %4
  %192 = bitcast i16* %191 to i64*
  store i64 %87, i64* %192, align 8
  %193 = getelementptr inbounds i16, i16* %191, i64 4
  %194 = bitcast i16* %193 to i64*
  store i64 %87, i64* %194, align 8
  %195 = getelementptr inbounds i16, i16* %191, i64 8
  %196 = bitcast i16* %195 to i64*
  store i64 %87, i64* %196, align 8
  %197 = getelementptr inbounds i16, i16* %191, i64 12
  %198 = bitcast i16* %197 to i64*
  store i64 %87, i64* %198, align 8
  %199 = getelementptr inbounds i16, i16* %191, i64 %4
  %200 = bitcast i16* %199 to i64*
  store i64 %87, i64* %200, align 8
  %201 = getelementptr inbounds i16, i16* %199, i64 4
  %202 = bitcast i16* %201 to i64*
  store i64 %87, i64* %202, align 8
  %203 = getelementptr inbounds i16, i16* %199, i64 8
  %204 = bitcast i16* %203 to i64*
  store i64 %87, i64* %204, align 8
  %205 = getelementptr inbounds i16, i16* %199, i64 12
  %206 = bitcast i16* %205 to i64*
  store i64 %87, i64* %206, align 8
  %207 = getelementptr inbounds i16, i16* %199, i64 %4
  %208 = bitcast i16* %207 to i64*
  store i64 %87, i64* %208, align 8
  %209 = getelementptr inbounds i16, i16* %207, i64 4
  %210 = bitcast i16* %209 to i64*
  store i64 %87, i64* %210, align 8
  %211 = getelementptr inbounds i16, i16* %207, i64 8
  %212 = bitcast i16* %211 to i64*
  store i64 %87, i64* %212, align 8
  %213 = getelementptr inbounds i16, i16* %207, i64 12
  %214 = bitcast i16* %213 to i64*
  store i64 %87, i64* %214, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_128_dc_12_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i8, i8* %0, i64 16
  %7 = bitcast i8* %6 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %7, align 8
  %8 = getelementptr inbounds i16, i16* %3, i64 %4
  %9 = bitcast i16* %8 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %9, align 8
  %10 = getelementptr inbounds i16, i16* %8, i64 8
  %11 = bitcast i16* %10 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %11, align 8
  %12 = getelementptr inbounds i16, i16* %8, i64 %4
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %13, align 8
  %14 = getelementptr inbounds i16, i16* %12, i64 8
  %15 = bitcast i16* %14 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %15, align 8
  %16 = getelementptr inbounds i16, i16* %12, i64 %4
  %17 = bitcast i16* %16 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %17, align 8
  %18 = getelementptr inbounds i16, i16* %16, i64 8
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 576469548530665472, i64 576469548530665472>, <2 x i64>* %19, align 8
  %20 = getelementptr inbounds i16, i16* %16, i64 %4
  %21 = bitcast i16* %20 to i64*
  store i64 576469548530665472, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 4
  %23 = bitcast i16* %22 to i64*
  store i64 576469548530665472, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 8
  %25 = bitcast i16* %24 to i64*
  store i64 576469548530665472, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 12
  %27 = bitcast i16* %26 to i64*
  store i64 576469548530665472, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %20, i64 %4
  %29 = bitcast i16* %28 to i64*
  store i64 576469548530665472, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 576469548530665472, i64* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 8
  %33 = bitcast i16* %32 to i64*
  store i64 576469548530665472, i64* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 12
  %35 = bitcast i16* %34 to i64*
  store i64 576469548530665472, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %4
  %37 = bitcast i16* %36 to i64*
  store i64 576469548530665472, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 576469548530665472, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 576469548530665472, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 576469548530665472, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %36, i64 %4
  %45 = bitcast i16* %44 to i64*
  store i64 576469548530665472, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 576469548530665472, i64* %47, align 8
  %48 = getelementptr inbounds i16, i16* %44, i64 8
  %49 = bitcast i16* %48 to i64*
  store i64 576469548530665472, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %44, i64 12
  %51 = bitcast i16* %50 to i64*
  store i64 576469548530665472, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %44, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 576469548530665472, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 576469548530665472, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %52, i64 8
  %57 = bitcast i16* %56 to i64*
  store i64 576469548530665472, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %52, i64 12
  %59 = bitcast i16* %58 to i64*
  store i64 576469548530665472, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %52, i64 %4
  %61 = bitcast i16* %60 to i64*
  store i64 576469548530665472, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %60, i64 4
  %63 = bitcast i16* %62 to i64*
  store i64 576469548530665472, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %60, i64 8
  %65 = bitcast i16* %64 to i64*
  store i64 576469548530665472, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %60, i64 12
  %67 = bitcast i16* %66 to i64*
  store i64 576469548530665472, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %60, i64 %4
  %69 = bitcast i16* %68 to i64*
  store i64 576469548530665472, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 576469548530665472, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %68, i64 8
  %73 = bitcast i16* %72 to i64*
  store i64 576469548530665472, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %68, i64 12
  %75 = bitcast i16* %74 to i64*
  store i64 576469548530665472, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %68, i64 %4
  %77 = bitcast i16* %76 to i64*
  store i64 576469548530665472, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %76, i64 4
  %79 = bitcast i16* %78 to i64*
  store i64 576469548530665472, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %76, i64 8
  %81 = bitcast i16* %80 to i64*
  store i64 576469548530665472, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %76, i64 12
  %83 = bitcast i16* %82 to i64*
  store i64 576469548530665472, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %76, i64 %4
  %85 = bitcast i16* %84 to i64*
  store i64 576469548530665472, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 576469548530665472, i64* %87, align 8
  %88 = getelementptr inbounds i16, i16* %84, i64 8
  %89 = bitcast i16* %88 to i64*
  store i64 576469548530665472, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %84, i64 12
  %91 = bitcast i16* %90 to i64*
  store i64 576469548530665472, i64* %91, align 8
  %92 = getelementptr inbounds i16, i16* %84, i64 %4
  %93 = bitcast i16* %92 to i64*
  store i64 576469548530665472, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 576469548530665472, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 576469548530665472, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 576469548530665472, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %92, i64 %4
  %101 = bitcast i16* %100 to i64*
  store i64 576469548530665472, i64* %101, align 8
  %102 = getelementptr inbounds i16, i16* %100, i64 4
  %103 = bitcast i16* %102 to i64*
  store i64 576469548530665472, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %100, i64 8
  %105 = bitcast i16* %104 to i64*
  store i64 576469548530665472, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %100, i64 12
  %107 = bitcast i16* %106 to i64*
  store i64 576469548530665472, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %100, i64 %4
  %109 = bitcast i16* %108 to i64*
  store i64 576469548530665472, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 576469548530665472, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %108, i64 8
  %113 = bitcast i16* %112 to i64*
  store i64 576469548530665472, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %108, i64 12
  %115 = bitcast i16* %114 to i64*
  store i64 576469548530665472, i64* %115, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred4x4_vertical_add_12_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %4, i64 %7
  %9 = and i64 %2, -2
  %10 = mul nsw i64 %6, 3
  %11 = shl nsw i64 %6, 2
  %12 = load i16, i16* %8, align 2
  %13 = load i32, i32* %5, align 4
  %14 = trunc i32 %13 to i16
  %15 = add i16 %12, %14
  store i16 %15, i16* %4, align 2
  %16 = getelementptr inbounds i16, i16* %1, i64 8
  %17 = bitcast i16* %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = trunc i32 %18 to i16
  %20 = add i16 %15, %19
  %21 = getelementptr inbounds i16, i16* %8, i64 %9
  store i16 %20, i16* %21, align 2
  %22 = getelementptr inbounds i16, i16* %1, i64 16
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %20, %25
  %27 = getelementptr inbounds i16, i16* %8, i64 %10
  store i16 %26, i16* %27, align 2
  %28 = getelementptr inbounds i16, i16* %1, i64 24
  %29 = bitcast i16* %28 to i32*
  %30 = load i32, i32* %29, align 4
  %31 = trunc i32 %30 to i16
  %32 = add i16 %26, %31
  %33 = getelementptr inbounds i16, i16* %8, i64 %11
  store i16 %32, i16* %33, align 2
  %34 = getelementptr inbounds i16, i16* %8, i64 1
  %35 = getelementptr inbounds i16, i16* %1, i64 2
  %36 = bitcast i16* %35 to i32*
  %37 = load i16, i16* %34, align 2
  %38 = load i32, i32* %36, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %37, %39
  %41 = getelementptr inbounds i16, i16* %34, i64 %6
  store i16 %40, i16* %41, align 2
  %42 = getelementptr inbounds i16, i16* %1, i64 10
  %43 = bitcast i16* %42 to i32*
  %44 = load i32, i32* %43, align 4
  %45 = trunc i32 %44 to i16
  %46 = add i16 %40, %45
  %47 = getelementptr inbounds i16, i16* %34, i64 %9
  store i16 %46, i16* %47, align 2
  %48 = getelementptr inbounds i16, i16* %1, i64 18
  %49 = bitcast i16* %48 to i32*
  %50 = load i32, i32* %49, align 4
  %51 = trunc i32 %50 to i16
  %52 = add i16 %46, %51
  %53 = getelementptr inbounds i16, i16* %34, i64 %10
  store i16 %52, i16* %53, align 2
  %54 = getelementptr inbounds i16, i16* %1, i64 26
  %55 = bitcast i16* %54 to i32*
  %56 = load i32, i32* %55, align 4
  %57 = trunc i32 %56 to i16
  %58 = add i16 %52, %57
  %59 = getelementptr inbounds i16, i16* %34, i64 %11
  store i16 %58, i16* %59, align 2
  %60 = getelementptr inbounds i16, i16* %34, i64 1
  %61 = getelementptr inbounds i16, i16* %1, i64 4
  %62 = bitcast i16* %61 to i32*
  %63 = load i16, i16* %60, align 2
  %64 = load i32, i32* %62, align 4
  %65 = trunc i32 %64 to i16
  %66 = add i16 %63, %65
  %67 = getelementptr inbounds i16, i16* %60, i64 %6
  store i16 %66, i16* %67, align 2
  %68 = getelementptr inbounds i16, i16* %1, i64 12
  %69 = bitcast i16* %68 to i32*
  %70 = load i32, i32* %69, align 4
  %71 = trunc i32 %70 to i16
  %72 = add i16 %66, %71
  %73 = getelementptr inbounds i16, i16* %60, i64 %9
  store i16 %72, i16* %73, align 2
  %74 = getelementptr inbounds i16, i16* %1, i64 20
  %75 = bitcast i16* %74 to i32*
  %76 = load i32, i32* %75, align 4
  %77 = trunc i32 %76 to i16
  %78 = add i16 %72, %77
  %79 = getelementptr inbounds i16, i16* %60, i64 %10
  store i16 %78, i16* %79, align 2
  %80 = getelementptr inbounds i16, i16* %1, i64 28
  %81 = bitcast i16* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = trunc i32 %82 to i16
  %84 = add i16 %78, %83
  %85 = getelementptr inbounds i16, i16* %60, i64 %11
  store i16 %84, i16* %85, align 2
  %86 = getelementptr inbounds i16, i16* %60, i64 1
  %87 = getelementptr inbounds i16, i16* %1, i64 6
  %88 = bitcast i16* %87 to i32*
  %89 = load i16, i16* %86, align 2
  %90 = load i32, i32* %88, align 4
  %91 = trunc i32 %90 to i16
  %92 = add i16 %89, %91
  %93 = getelementptr inbounds i16, i16* %86, i64 %6
  store i16 %92, i16* %93, align 2
  %94 = getelementptr inbounds i16, i16* %1, i64 14
  %95 = bitcast i16* %94 to i32*
  %96 = load i32, i32* %95, align 4
  %97 = trunc i32 %96 to i16
  %98 = add i16 %92, %97
  %99 = getelementptr inbounds i16, i16* %86, i64 %9
  store i16 %98, i16* %99, align 2
  %100 = getelementptr inbounds i16, i16* %1, i64 22
  %101 = bitcast i16* %100 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = trunc i32 %102 to i16
  %104 = add i16 %98, %103
  %105 = getelementptr inbounds i16, i16* %86, i64 %10
  store i16 %104, i16* %105, align 2
  %106 = getelementptr inbounds i16, i16* %1, i64 30
  %107 = bitcast i16* %106 to i32*
  %108 = load i32, i32* %107, align 4
  %109 = trunc i32 %108 to i16
  %110 = add i16 %104, %109
  %111 = getelementptr inbounds i16, i16* %86, i64 %11
  store i16 %110, i16* %111, align 2
  %112 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %112, i8 0, i64 64, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred4x4_horizontal_add_12_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = load i32, i32* %5, align 4
  %11 = trunc i32 %10 to i16
  %12 = add i16 %9, %11
  store i16 %12, i16* %4, align 2
  %13 = getelementptr inbounds i16, i16* %1, i64 2
  %14 = bitcast i16* %13 to i32*
  %15 = load i32, i32* %14, align 4
  %16 = trunc i32 %15 to i16
  %17 = add i16 %12, %16
  %18 = getelementptr inbounds i8, i8* %0, i64 2
  %19 = bitcast i8* %18 to i16*
  store i16 %17, i16* %19, align 2
  %20 = getelementptr inbounds i16, i16* %1, i64 4
  %21 = bitcast i16* %20 to i32*
  %22 = load i32, i32* %21, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %17, %23
  %25 = getelementptr inbounds i8, i8* %0, i64 4
  %26 = bitcast i8* %25 to i16*
  store i16 %24, i16* %26, align 2
  %27 = getelementptr inbounds i16, i16* %1, i64 6
  %28 = bitcast i16* %27 to i32*
  %29 = load i32, i32* %28, align 4
  %30 = trunc i32 %29 to i16
  %31 = add i16 %24, %30
  %32 = getelementptr inbounds i8, i8* %0, i64 6
  %33 = bitcast i8* %32 to i16*
  store i16 %31, i16* %33, align 2
  %34 = getelementptr inbounds i16, i16* %4, i64 %6
  %35 = getelementptr inbounds i16, i16* %1, i64 8
  %36 = bitcast i16* %35 to i32*
  %37 = getelementptr inbounds i16, i16* %34, i64 -1
  %38 = load i16, i16* %37, align 2
  %39 = load i32, i32* %36, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %38, %40
  store i16 %41, i16* %34, align 2
  %42 = getelementptr inbounds i16, i16* %1, i64 10
  %43 = bitcast i16* %42 to i32*
  %44 = load i32, i32* %43, align 4
  %45 = trunc i32 %44 to i16
  %46 = add i16 %41, %45
  %47 = getelementptr inbounds i16, i16* %34, i64 1
  store i16 %46, i16* %47, align 2
  %48 = getelementptr inbounds i16, i16* %1, i64 12
  %49 = bitcast i16* %48 to i32*
  %50 = load i32, i32* %49, align 4
  %51 = trunc i32 %50 to i16
  %52 = add i16 %46, %51
  %53 = getelementptr inbounds i16, i16* %34, i64 2
  store i16 %52, i16* %53, align 2
  %54 = getelementptr inbounds i16, i16* %1, i64 14
  %55 = bitcast i16* %54 to i32*
  %56 = load i32, i32* %55, align 4
  %57 = trunc i32 %56 to i16
  %58 = add i16 %52, %57
  %59 = getelementptr inbounds i16, i16* %34, i64 3
  store i16 %58, i16* %59, align 2
  %60 = getelementptr inbounds i16, i16* %34, i64 %6
  %61 = getelementptr inbounds i16, i16* %1, i64 16
  %62 = bitcast i16* %61 to i32*
  %63 = getelementptr inbounds i16, i16* %60, i64 -1
  %64 = load i16, i16* %63, align 2
  %65 = load i32, i32* %62, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %64, %66
  store i16 %67, i16* %60, align 2
  %68 = getelementptr inbounds i16, i16* %1, i64 18
  %69 = bitcast i16* %68 to i32*
  %70 = load i32, i32* %69, align 4
  %71 = trunc i32 %70 to i16
  %72 = add i16 %67, %71
  %73 = getelementptr inbounds i16, i16* %60, i64 1
  store i16 %72, i16* %73, align 2
  %74 = getelementptr inbounds i16, i16* %1, i64 20
  %75 = bitcast i16* %74 to i32*
  %76 = load i32, i32* %75, align 4
  %77 = trunc i32 %76 to i16
  %78 = add i16 %72, %77
  %79 = getelementptr inbounds i16, i16* %60, i64 2
  store i16 %78, i16* %79, align 2
  %80 = getelementptr inbounds i16, i16* %1, i64 22
  %81 = bitcast i16* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = trunc i32 %82 to i16
  %84 = add i16 %78, %83
  %85 = getelementptr inbounds i16, i16* %60, i64 3
  store i16 %84, i16* %85, align 2
  %86 = getelementptr inbounds i16, i16* %60, i64 %6
  %87 = getelementptr inbounds i16, i16* %1, i64 24
  %88 = bitcast i16* %87 to i32*
  %89 = getelementptr inbounds i16, i16* %86, i64 -1
  %90 = load i16, i16* %89, align 2
  %91 = load i32, i32* %88, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %90, %92
  store i16 %93, i16* %86, align 2
  %94 = getelementptr inbounds i16, i16* %1, i64 26
  %95 = bitcast i16* %94 to i32*
  %96 = load i32, i32* %95, align 4
  %97 = trunc i32 %96 to i16
  %98 = add i16 %93, %97
  %99 = getelementptr inbounds i16, i16* %86, i64 1
  store i16 %98, i16* %99, align 2
  %100 = getelementptr inbounds i16, i16* %1, i64 28
  %101 = bitcast i16* %100 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = trunc i32 %102 to i16
  %104 = add i16 %98, %103
  %105 = getelementptr inbounds i16, i16* %86, i64 2
  store i16 %104, i16* %105, align 2
  %106 = getelementptr inbounds i16, i16* %1, i64 30
  %107 = bitcast i16* %106 to i32*
  %108 = load i32, i32* %107, align 4
  %109 = trunc i32 %108 to i16
  %110 = add i16 %104, %109
  %111 = getelementptr inbounds i16, i16* %86, i64 3
  store i16 %110, i16* %111, align 2
  %112 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %112, i8 0, i64 64, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_vertical_add_12_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %4, i64 %7
  %9 = and i64 %2, -2
  %10 = mul nsw i64 %6, 3
  %11 = shl nsw i64 %6, 2
  %12 = mul nsw i64 %6, 5
  %13 = mul nsw i64 %6, 6
  %14 = mul nsw i64 %6, 7
  %15 = shl nsw i64 %6, 3
  br label %16

16:                                               ; preds = %16, %3
  %17 = phi i32* [ %5, %3 ], [ %61, %16 ]
  %18 = phi i16* [ %8, %3 ], [ %60, %16 ]
  %19 = phi i32 [ 0, %3 ], [ %62, %16 ]
  %20 = load i16, i16* %18, align 2
  %21 = load i32, i32* %17, align 4
  %22 = trunc i32 %21 to i16
  %23 = add i16 %20, %22
  %24 = getelementptr inbounds i16, i16* %18, i64 %6
  store i16 %23, i16* %24, align 2
  %25 = getelementptr inbounds i32, i32* %17, i64 8
  %26 = load i32, i32* %25, align 4
  %27 = trunc i32 %26 to i16
  %28 = add i16 %23, %27
  %29 = getelementptr inbounds i16, i16* %18, i64 %9
  store i16 %28, i16* %29, align 2
  %30 = getelementptr inbounds i32, i32* %17, i64 16
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %28, %32
  %34 = getelementptr inbounds i16, i16* %18, i64 %10
  store i16 %33, i16* %34, align 2
  %35 = getelementptr inbounds i32, i32* %17, i64 24
  %36 = load i32, i32* %35, align 4
  %37 = trunc i32 %36 to i16
  %38 = add i16 %33, %37
  %39 = getelementptr inbounds i16, i16* %18, i64 %11
  store i16 %38, i16* %39, align 2
  %40 = getelementptr inbounds i32, i32* %17, i64 32
  %41 = load i32, i32* %40, align 4
  %42 = trunc i32 %41 to i16
  %43 = add i16 %38, %42
  %44 = getelementptr inbounds i16, i16* %18, i64 %12
  store i16 %43, i16* %44, align 2
  %45 = getelementptr inbounds i32, i32* %17, i64 40
  %46 = load i32, i32* %45, align 4
  %47 = trunc i32 %46 to i16
  %48 = add i16 %43, %47
  %49 = getelementptr inbounds i16, i16* %18, i64 %13
  store i16 %48, i16* %49, align 2
  %50 = getelementptr inbounds i32, i32* %17, i64 48
  %51 = load i32, i32* %50, align 4
  %52 = trunc i32 %51 to i16
  %53 = add i16 %48, %52
  %54 = getelementptr inbounds i16, i16* %18, i64 %14
  store i16 %53, i16* %54, align 2
  %55 = getelementptr inbounds i32, i32* %17, i64 56
  %56 = load i32, i32* %55, align 4
  %57 = trunc i32 %56 to i16
  %58 = add i16 %53, %57
  %59 = getelementptr inbounds i16, i16* %18, i64 %15
  store i16 %58, i16* %59, align 2
  %60 = getelementptr inbounds i16, i16* %18, i64 1
  %61 = getelementptr inbounds i32, i32* %17, i64 1
  %62 = add nuw nsw i32 %19, 1
  %63 = icmp eq i32 %62, 8
  br i1 %63, label %64, label %16

64:                                               ; preds = %16
  %65 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %65, i8 0, i64 256, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_horizontal_add_12_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  br label %7

7:                                                ; preds = %7, %3
  %8 = phi i32* [ %5, %3 ], [ %52, %7 ]
  %9 = phi i16* [ %4, %3 ], [ %51, %7 ]
  %10 = phi i32 [ 0, %3 ], [ %53, %7 ]
  %11 = getelementptr inbounds i16, i16* %9, i64 -1
  %12 = load i16, i16* %11, align 2
  %13 = load i32, i32* %8, align 4
  %14 = trunc i32 %13 to i16
  %15 = add i16 %12, %14
  store i16 %15, i16* %9, align 2
  %16 = getelementptr inbounds i32, i32* %8, i64 1
  %17 = load i32, i32* %16, align 4
  %18 = trunc i32 %17 to i16
  %19 = add i16 %15, %18
  %20 = getelementptr inbounds i16, i16* %9, i64 1
  store i16 %19, i16* %20, align 2
  %21 = getelementptr inbounds i32, i32* %8, i64 2
  %22 = load i32, i32* %21, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %19, %23
  %25 = getelementptr inbounds i16, i16* %9, i64 2
  store i16 %24, i16* %25, align 2
  %26 = getelementptr inbounds i32, i32* %8, i64 3
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %9, i64 3
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i32, i32* %8, i64 4
  %32 = load i32, i32* %31, align 4
  %33 = trunc i32 %32 to i16
  %34 = add i16 %29, %33
  %35 = getelementptr inbounds i16, i16* %9, i64 4
  store i16 %34, i16* %35, align 2
  %36 = getelementptr inbounds i32, i32* %8, i64 5
  %37 = load i32, i32* %36, align 4
  %38 = trunc i32 %37 to i16
  %39 = add i16 %34, %38
  %40 = getelementptr inbounds i16, i16* %9, i64 5
  store i16 %39, i16* %40, align 2
  %41 = getelementptr inbounds i32, i32* %8, i64 6
  %42 = load i32, i32* %41, align 4
  %43 = trunc i32 %42 to i16
  %44 = add i16 %39, %43
  %45 = getelementptr inbounds i16, i16* %9, i64 6
  store i16 %44, i16* %45, align 2
  %46 = getelementptr inbounds i32, i32* %8, i64 7
  %47 = load i32, i32* %46, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %44, %48
  %50 = getelementptr inbounds i16, i16* %9, i64 7
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %9, i64 %6
  %52 = getelementptr inbounds i32, i32* %8, i64 8
  %53 = add nuw nsw i32 %10, 1
  %54 = icmp eq i32 %53, 8
  br i1 %54, label %55, label %7

55:                                               ; preds = %7
  %56 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %56, i8 0, i64 256, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_vertical_filter_add_12_c(i8* nocapture, i16* nocapture, i32, i32, i64) #3 {
  %6 = alloca [8 x i16], align 16
  %7 = bitcast i8* %0 to i16*
  %8 = bitcast i16* %1 to i32*
  %9 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %9) #8
  %10 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 0
  %11 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 1
  %12 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 2
  %13 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 3
  %14 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 4
  %15 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 5
  %16 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 6
  %17 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 7
  %18 = lshr i64 %4, 1
  %19 = trunc i64 %18 to i32
  %20 = icmp eq i32 %2, 0
  %21 = sub nsw i32 0, %19
  %22 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 16, i1 false)
  br i1 %20, label %28, label %23

23:                                               ; preds = %5
  %24 = shl i64 %18, 32
  %25 = ashr exact i64 %24, 32
  %26 = xor i64 %25, -1
  %27 = sext i32 %21 to i64
  br label %31

28:                                               ; preds = %5
  %29 = sext i32 %21 to i64
  %30 = shl i64 %18, 32
  br label %31

31:                                               ; preds = %28, %23
  %32 = phi i64 [ %30, %28 ], [ %24, %23 ]
  %33 = phi i64 [ %29, %28 ], [ %27, %23 ]
  %34 = phi i64 [ %29, %28 ], [ %26, %23 ]
  %35 = getelementptr inbounds i16, i16* %7, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i32
  %38 = getelementptr inbounds i16, i16* %7, i64 %33
  %39 = load i16, i16* %38, align 2
  %40 = zext i16 %39 to i32
  %41 = shl nuw nsw i32 %40, 1
  %42 = sub i64 4294967296, %32
  %43 = ashr exact i64 %42, 32
  %44 = getelementptr inbounds i16, i16* %7, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %37
  %49 = add nuw nsw i32 %48, %41
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = sub i64 8589934592, %32
  %53 = ashr exact i64 %52, 32
  %54 = getelementptr inbounds i16, i16* %7, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i32
  %57 = add nuw nsw i32 %56, 2
  %58 = add nuw nsw i32 %57, %40
  %59 = add nuw nsw i32 %58, %51
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %56, 1
  %62 = sub i64 12884901888, %32
  %63 = ashr exact i64 %62, 32
  %64 = getelementptr inbounds i16, i16* %7, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i32
  %67 = add nuw nsw i32 %47, %61
  %68 = add nuw nsw i32 %67, %66
  %69 = lshr i32 %68, 2
  %70 = shl nuw nsw i32 %66, 1
  %71 = sub i64 17179869184, %32
  %72 = ashr exact i64 %71, 32
  %73 = getelementptr inbounds i16, i16* %7, i64 %72
  %74 = load i16, i16* %73, align 2
  %75 = zext i16 %74 to i32
  %76 = add nuw nsw i32 %57, %70
  %77 = add nuw nsw i32 %76, %75
  %78 = lshr i32 %77, 2
  %79 = shl nuw nsw i32 %75, 1
  %80 = sub i64 21474836480, %32
  %81 = ashr exact i64 %80, 32
  %82 = getelementptr inbounds i16, i16* %7, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = zext i16 %83 to i32
  %85 = add nuw nsw i32 %66, 2
  %86 = add nuw nsw i32 %85, %79
  %87 = add nuw nsw i32 %86, %84
  %88 = lshr i32 %87, 2
  %89 = shl nuw nsw i32 %84, 1
  %90 = sub i64 25769803776, %32
  %91 = ashr exact i64 %90, 32
  %92 = getelementptr inbounds i16, i16* %7, i64 %91
  %93 = load i16, i16* %92, align 2
  %94 = zext i16 %93 to i32
  %95 = add nuw nsw i32 %75, 2
  %96 = add nuw nsw i32 %95, %89
  %97 = add nuw nsw i32 %96, %94
  %98 = lshr i32 %97, 2
  %99 = shl nuw nsw i32 %94, 1
  %100 = sub i64 30064771072, %32
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %7, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i32
  %105 = add nuw nsw i32 %84, 2
  %106 = add nuw nsw i32 %105, %99
  %107 = add nuw nsw i32 %106, %104
  %108 = lshr i32 %107, 2
  %109 = icmp eq i32 %3, 0
  br i1 %109, label %116, label %110

110:                                              ; preds = %31
  %111 = sub i64 34359738368, %32
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds i16, i16* %7, i64 %112
  %114 = load i16, i16* %113, align 2
  %115 = zext i16 %114 to i32
  br label %116

116:                                              ; preds = %31, %110
  %117 = phi i32 [ %115, %110 ], [ %104, %31 ]
  %118 = shl nuw nsw i32 %104, 1
  %119 = add nuw nsw i32 %94, 2
  %120 = add nuw nsw i32 %119, %118
  %121 = add nuw nsw i32 %120, %117
  %122 = lshr i32 %121, 2
  %123 = trunc i32 %50 to i16
  store i16 %123, i16* %10, align 16
  %124 = trunc i32 %60 to i16
  store i16 %124, i16* %11, align 2
  %125 = trunc i32 %69 to i16
  store i16 %125, i16* %12, align 4
  %126 = trunc i32 %78 to i16
  store i16 %126, i16* %13, align 2
  %127 = trunc i32 %88 to i16
  store i16 %127, i16* %14, align 8
  %128 = trunc i32 %98 to i16
  store i16 %128, i16* %15, align 2
  %129 = trunc i32 %108 to i16
  store i16 %129, i16* %16, align 4
  %130 = trunc i32 %122 to i16
  store i16 %130, i16* %17, align 2
  %131 = ashr exact i64 %32, 32
  %132 = shl i64 %4, 32
  %133 = ashr exact i64 %132, 32
  %134 = and i64 %133, -2
  %135 = mul i64 %18, 12884901888
  %136 = ashr exact i64 %135, 32
  %137 = shl i64 %18, 34
  %138 = ashr exact i64 %137, 32
  %139 = mul i64 %18, 21474836480
  %140 = ashr exact i64 %139, 32
  %141 = mul i64 %18, 25769803776
  %142 = ashr exact i64 %141, 32
  %143 = mul i64 %18, 30064771072
  %144 = ashr exact i64 %143, 32
  br label %145

145:                                              ; preds = %190, %116
  %146 = phi i16 [ %123, %116 ], [ %194, %190 ]
  %147 = phi i64 [ 0, %116 ], [ %188, %190 ]
  %148 = phi i32* [ %8, %116 ], [ %191, %190 ]
  %149 = phi i16* [ %7, %116 ], [ %192, %190 ]
  %150 = load i32, i32* %148, align 4
  %151 = trunc i32 %150 to i16
  %152 = add i16 %146, %151
  store i16 %152, i16* %149, align 2
  %153 = getelementptr inbounds i32, i32* %148, i64 8
  %154 = load i32, i32* %153, align 4
  %155 = trunc i32 %154 to i16
  %156 = add i16 %152, %155
  %157 = getelementptr inbounds i16, i16* %149, i64 %131
  store i16 %156, i16* %157, align 2
  %158 = getelementptr inbounds i32, i32* %148, i64 16
  %159 = load i32, i32* %158, align 4
  %160 = trunc i32 %159 to i16
  %161 = add i16 %156, %160
  %162 = getelementptr inbounds i16, i16* %149, i64 %134
  store i16 %161, i16* %162, align 2
  %163 = getelementptr inbounds i32, i32* %148, i64 24
  %164 = load i32, i32* %163, align 4
  %165 = trunc i32 %164 to i16
  %166 = add i16 %161, %165
  %167 = getelementptr inbounds i16, i16* %149, i64 %136
  store i16 %166, i16* %167, align 2
  %168 = getelementptr inbounds i32, i32* %148, i64 32
  %169 = load i32, i32* %168, align 4
  %170 = trunc i32 %169 to i16
  %171 = add i16 %166, %170
  %172 = getelementptr inbounds i16, i16* %149, i64 %138
  store i16 %171, i16* %172, align 2
  %173 = getelementptr inbounds i32, i32* %148, i64 40
  %174 = load i32, i32* %173, align 4
  %175 = trunc i32 %174 to i16
  %176 = add i16 %171, %175
  %177 = getelementptr inbounds i16, i16* %149, i64 %140
  store i16 %176, i16* %177, align 2
  %178 = getelementptr inbounds i32, i32* %148, i64 48
  %179 = load i32, i32* %178, align 4
  %180 = trunc i32 %179 to i16
  %181 = add i16 %176, %180
  %182 = getelementptr inbounds i16, i16* %149, i64 %142
  store i16 %181, i16* %182, align 2
  %183 = getelementptr inbounds i32, i32* %148, i64 56
  %184 = load i32, i32* %183, align 4
  %185 = trunc i32 %184 to i16
  %186 = add i16 %181, %185
  %187 = getelementptr inbounds i16, i16* %149, i64 %144
  store i16 %186, i16* %187, align 2
  %188 = add nuw nsw i64 %147, 1
  %189 = icmp eq i64 %188, 8
  br i1 %189, label %195, label %190

190:                                              ; preds = %145
  %191 = getelementptr inbounds i32, i32* %148, i64 1
  %192 = getelementptr inbounds i16, i16* %149, i64 1
  %193 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 %188
  %194 = load i16, i16* %193, align 2
  br label %145

195:                                              ; preds = %145
  %196 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %196, i8 0, i64 256, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %9) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_horizontal_filter_add_12_c(i8* nocapture, i16* nocapture, i32, i32, i64) #3 {
  %6 = alloca [8 x i16], align 16
  %7 = bitcast i8* %0 to i16*
  %8 = bitcast i16* %1 to i32*
  %9 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %9) #8
  %10 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 0
  %11 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 1
  %12 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 2
  %13 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 3
  %14 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 4
  %15 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 5
  %16 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 6
  %17 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 7
  %18 = lshr i64 %4, 1
  %19 = icmp eq i32 %2, 0
  %20 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 16, i1 false)
  br i1 %19, label %26, label %21

21:                                               ; preds = %5
  %22 = shl i64 %18, 32
  %23 = ashr exact i64 %22, 32
  %24 = xor i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %7, i64 %24
  br label %31

26:                                               ; preds = %5
  %27 = getelementptr inbounds i8, i8* %0, i64 -2
  %28 = bitcast i8* %27 to i16*
  %29 = shl i64 %18, 32
  %30 = ashr exact i64 %29, 32
  br label %31

31:                                               ; preds = %26, %21
  %32 = phi i64 [ %30, %26 ], [ %23, %21 ]
  %33 = phi i64 [ %29, %26 ], [ %22, %21 ]
  %34 = phi i16* [ %28, %26 ], [ %25, %21 ]
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = getelementptr inbounds i8, i8* %0, i64 -2
  %38 = bitcast i8* %37 to i16*
  %39 = load i16, i16* %38, align 2
  %40 = zext i16 %39 to i32
  %41 = shl nuw nsw i32 %40, 1
  %42 = add i64 %33, -4294967296
  %43 = ashr exact i64 %42, 32
  %44 = getelementptr inbounds i16, i16* %7, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %36
  %49 = add nuw nsw i32 %48, %41
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = shl i64 %4, 32
  %53 = and i64 %52, -8589934592
  %54 = add i64 %53, -4294967296
  %55 = ashr exact i64 %54, 32
  %56 = getelementptr inbounds i16, i16* %7, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %58, 2
  %60 = add nuw nsw i32 %59, %40
  %61 = add nuw nsw i32 %60, %51
  %62 = lshr i32 %61, 2
  %63 = shl nuw nsw i32 %58, 1
  %64 = mul i64 %18, 12884901888
  %65 = add i64 %64, -4294967296
  %66 = ashr exact i64 %65, 32
  %67 = getelementptr inbounds i16, i16* %7, i64 %66
  %68 = load i16, i16* %67, align 2
  %69 = zext i16 %68 to i32
  %70 = add nuw nsw i32 %47, %63
  %71 = add nuw nsw i32 %70, %69
  %72 = lshr i32 %71, 2
  %73 = shl nuw nsw i32 %69, 1
  %74 = shl i64 %18, 34
  %75 = add i64 %74, -4294967296
  %76 = ashr exact i64 %75, 32
  %77 = getelementptr inbounds i16, i16* %7, i64 %76
  %78 = load i16, i16* %77, align 2
  %79 = zext i16 %78 to i32
  %80 = add nuw nsw i32 %59, %73
  %81 = add nuw nsw i32 %80, %79
  %82 = lshr i32 %81, 2
  %83 = shl nuw nsw i32 %79, 1
  %84 = mul i64 %18, 21474836480
  %85 = add i64 %84, -4294967296
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i16, i16* %7, i64 %86
  %88 = load i16, i16* %87, align 2
  %89 = zext i16 %88 to i32
  %90 = add nuw nsw i32 %69, 2
  %91 = add nuw nsw i32 %90, %83
  %92 = add nuw nsw i32 %91, %89
  %93 = lshr i32 %92, 2
  %94 = shl nuw nsw i32 %89, 1
  %95 = mul i64 %18, 25769803776
  %96 = add i64 %95, -4294967296
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i16, i16* %7, i64 %97
  %99 = load i16, i16* %98, align 2
  %100 = zext i16 %99 to i32
  %101 = add nuw nsw i32 %79, 2
  %102 = add nuw nsw i32 %101, %94
  %103 = add nuw nsw i32 %102, %100
  %104 = lshr i32 %103, 2
  %105 = shl nuw nsw i32 %100, 1
  %106 = mul i64 %18, 30064771072
  %107 = add i64 %106, -4294967296
  %108 = ashr exact i64 %107, 32
  %109 = getelementptr inbounds i16, i16* %7, i64 %108
  %110 = load i16, i16* %109, align 2
  %111 = zext i16 %110 to i32
  %112 = add nuw nsw i32 %89, 2
  %113 = add nuw nsw i32 %112, %105
  %114 = add nuw nsw i32 %113, %111
  %115 = lshr i32 %114, 2
  %116 = mul nuw nsw i32 %111, 3
  %117 = add nuw nsw i32 %100, 2
  %118 = add nuw nsw i32 %117, %116
  %119 = lshr i32 %118, 2
  %120 = trunc i32 %50 to i16
  store i16 %120, i16* %10, align 16
  %121 = trunc i32 %62 to i16
  store i16 %121, i16* %11, align 2
  %122 = trunc i32 %72 to i16
  store i16 %122, i16* %12, align 4
  %123 = trunc i32 %82 to i16
  store i16 %123, i16* %13, align 2
  %124 = trunc i32 %93 to i16
  store i16 %124, i16* %14, align 8
  %125 = trunc i32 %104 to i16
  store i16 %125, i16* %15, align 2
  %126 = trunc i32 %115 to i16
  store i16 %126, i16* %16, align 4
  %127 = trunc i32 %119 to i16
  store i16 %127, i16* %17, align 2
  br label %128

128:                                              ; preds = %173, %31
  %129 = phi i16 [ %120, %31 ], [ %177, %173 ]
  %130 = phi i64 [ 0, %31 ], [ %171, %173 ]
  %131 = phi i16* [ %7, %31 ], [ %175, %173 ]
  %132 = phi i32* [ %8, %31 ], [ %174, %173 ]
  %133 = load i32, i32* %132, align 4
  %134 = trunc i32 %133 to i16
  %135 = add i16 %129, %134
  store i16 %135, i16* %131, align 2
  %136 = getelementptr inbounds i32, i32* %132, i64 1
  %137 = load i32, i32* %136, align 4
  %138 = trunc i32 %137 to i16
  %139 = add i16 %135, %138
  %140 = getelementptr inbounds i16, i16* %131, i64 1
  store i16 %139, i16* %140, align 2
  %141 = getelementptr inbounds i32, i32* %132, i64 2
  %142 = load i32, i32* %141, align 4
  %143 = trunc i32 %142 to i16
  %144 = add i16 %139, %143
  %145 = getelementptr inbounds i16, i16* %131, i64 2
  store i16 %144, i16* %145, align 2
  %146 = getelementptr inbounds i32, i32* %132, i64 3
  %147 = load i32, i32* %146, align 4
  %148 = trunc i32 %147 to i16
  %149 = add i16 %144, %148
  %150 = getelementptr inbounds i16, i16* %131, i64 3
  store i16 %149, i16* %150, align 2
  %151 = getelementptr inbounds i32, i32* %132, i64 4
  %152 = load i32, i32* %151, align 4
  %153 = trunc i32 %152 to i16
  %154 = add i16 %149, %153
  %155 = getelementptr inbounds i16, i16* %131, i64 4
  store i16 %154, i16* %155, align 2
  %156 = getelementptr inbounds i32, i32* %132, i64 5
  %157 = load i32, i32* %156, align 4
  %158 = trunc i32 %157 to i16
  %159 = add i16 %154, %158
  %160 = getelementptr inbounds i16, i16* %131, i64 5
  store i16 %159, i16* %160, align 2
  %161 = getelementptr inbounds i32, i32* %132, i64 6
  %162 = load i32, i32* %161, align 4
  %163 = trunc i32 %162 to i16
  %164 = add i16 %159, %163
  %165 = getelementptr inbounds i16, i16* %131, i64 6
  store i16 %164, i16* %165, align 2
  %166 = getelementptr inbounds i32, i32* %132, i64 7
  %167 = load i32, i32* %166, align 4
  %168 = trunc i32 %167 to i16
  %169 = add i16 %164, %168
  %170 = getelementptr inbounds i16, i16* %131, i64 7
  store i16 %169, i16* %170, align 2
  %171 = add nuw nsw i64 %130, 1
  %172 = icmp eq i64 %171, 8
  br i1 %172, label %178, label %173

173:                                              ; preds = %128
  %174 = getelementptr inbounds i32, i32* %132, i64 8
  %175 = getelementptr inbounds i16, i16* %131, i64 %32
  %176 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 %171
  %177 = load i16, i16* %176, align 2
  br label %128

178:                                              ; preds = %128
  %179 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %179, i8 0, i64 256, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %9) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8_vertical_add_12_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  %6 = sub nsw i64 0, %5
  %7 = and i64 %3, -2
  %8 = mul nsw i64 %5, 3
  %9 = shl nsw i64 %5, 2
  br label %10

10:                                               ; preds = %10, %4
  %11 = phi i64 [ 0, %4 ], [ %122, %10 ]
  %12 = getelementptr inbounds i32, i32* %1, i64 %11
  %13 = load i32, i32* %12, align 4
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = shl i64 %11, 5
  %17 = getelementptr inbounds i16, i16* %2, i64 %16
  %18 = bitcast i8* %15 to i16*
  %19 = bitcast i16* %17 to i32*
  %20 = getelementptr inbounds i16, i16* %18, i64 %6
  %21 = load i16, i16* %20, align 2
  %22 = load i32, i32* %19, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %21, %23
  store i16 %24, i16* %18, align 2
  %25 = getelementptr inbounds i16, i16* %17, i64 8
  %26 = bitcast i16* %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %20, i64 %7
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i16, i16* %17, i64 16
  %32 = bitcast i16* %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = trunc i32 %33 to i16
  %35 = add i16 %29, %34
  %36 = getelementptr inbounds i16, i16* %20, i64 %8
  store i16 %35, i16* %36, align 2
  %37 = getelementptr inbounds i16, i16* %17, i64 24
  %38 = bitcast i16* %37 to i32*
  %39 = load i32, i32* %38, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %35, %40
  %42 = getelementptr inbounds i16, i16* %20, i64 %9
  store i16 %41, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %20, i64 1
  %44 = getelementptr inbounds i16, i16* %17, i64 2
  %45 = bitcast i16* %44 to i32*
  %46 = load i16, i16* %43, align 2
  %47 = load i32, i32* %45, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %46, %48
  %50 = getelementptr inbounds i16, i16* %43, i64 %5
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %17, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %49, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 %7
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %17, i64 18
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 %8
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %17, i64 26
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 %9
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 1
  %70 = getelementptr inbounds i16, i16* %17, i64 4
  %71 = bitcast i16* %70 to i32*
  %72 = load i16, i16* %69, align 2
  %73 = load i32, i32* %71, align 4
  %74 = trunc i32 %73 to i16
  %75 = add i16 %72, %74
  %76 = getelementptr inbounds i16, i16* %69, i64 %5
  store i16 %75, i16* %76, align 2
  %77 = getelementptr inbounds i16, i16* %17, i64 12
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %75, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 %7
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %17, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 %8
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %17, i64 28
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 %9
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 1
  %96 = getelementptr inbounds i16, i16* %17, i64 6
  %97 = bitcast i16* %96 to i32*
  %98 = load i16, i16* %95, align 2
  %99 = load i32, i32* %97, align 4
  %100 = trunc i32 %99 to i16
  %101 = add i16 %98, %100
  %102 = getelementptr inbounds i16, i16* %95, i64 %5
  store i16 %101, i16* %102, align 2
  %103 = getelementptr inbounds i16, i16* %17, i64 14
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %101, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 %7
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %17, i64 22
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 %8
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %17, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 %9
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %11, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %10

124:                                              ; preds = %10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8_horizontal_add_12_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %122, %6 ]
  %8 = getelementptr inbounds i32, i32* %1, i64 %7
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = shl i64 %7, 5
  %13 = getelementptr inbounds i16, i16* %2, i64 %12
  %14 = bitcast i8* %11 to i16*
  %15 = bitcast i16* %13 to i32*
  %16 = getelementptr inbounds i8, i8* %11, i64 -2
  %17 = bitcast i8* %16 to i16*
  %18 = load i16, i16* %17, align 2
  %19 = load i32, i32* %15, align 4
  %20 = trunc i32 %19 to i16
  %21 = add i16 %18, %20
  store i16 %21, i16* %14, align 2
  %22 = getelementptr inbounds i16, i16* %13, i64 2
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %21, %25
  %27 = getelementptr inbounds i8, i8* %11, i64 2
  %28 = bitcast i8* %27 to i16*
  store i16 %26, i16* %28, align 2
  %29 = getelementptr inbounds i16, i16* %13, i64 4
  %30 = bitcast i16* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %26, %32
  %34 = getelementptr inbounds i8, i8* %11, i64 4
  %35 = bitcast i8* %34 to i16*
  store i16 %33, i16* %35, align 2
  %36 = getelementptr inbounds i16, i16* %13, i64 6
  %37 = bitcast i16* %36 to i32*
  %38 = load i32, i32* %37, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %33, %39
  %41 = getelementptr inbounds i8, i8* %11, i64 6
  %42 = bitcast i8* %41 to i16*
  store i16 %40, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %14, i64 %5
  %44 = getelementptr inbounds i16, i16* %13, i64 8
  %45 = bitcast i16* %44 to i32*
  %46 = getelementptr inbounds i16, i16* %43, i64 -1
  %47 = load i16, i16* %46, align 2
  %48 = load i32, i32* %45, align 4
  %49 = trunc i32 %48 to i16
  %50 = add i16 %47, %49
  store i16 %50, i16* %43, align 2
  %51 = getelementptr inbounds i16, i16* %13, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %50, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 1
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %13, i64 12
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 2
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %13, i64 14
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 3
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 %5
  %70 = getelementptr inbounds i16, i16* %13, i64 16
  %71 = bitcast i16* %70 to i32*
  %72 = getelementptr inbounds i16, i16* %69, i64 -1
  %73 = load i16, i16* %72, align 2
  %74 = load i32, i32* %71, align 4
  %75 = trunc i32 %74 to i16
  %76 = add i16 %73, %75
  store i16 %76, i16* %69, align 2
  %77 = getelementptr inbounds i16, i16* %13, i64 18
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %76, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 1
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %13, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 2
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %13, i64 22
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 3
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 %5
  %96 = getelementptr inbounds i16, i16* %13, i64 24
  %97 = bitcast i16* %96 to i32*
  %98 = getelementptr inbounds i16, i16* %95, i64 -1
  %99 = load i16, i16* %98, align 2
  %100 = load i32, i32* %97, align 4
  %101 = trunc i32 %100 to i16
  %102 = add i16 %99, %101
  store i16 %102, i16* %95, align 2
  %103 = getelementptr inbounds i16, i16* %13, i64 26
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %102, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 1
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %13, i64 28
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 2
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %13, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 3
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %7, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %6

124:                                              ; preds = %6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x16_vertical_add_12_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  %6 = sub nsw i64 0, %5
  %7 = and i64 %3, -2
  %8 = mul nsw i64 %5, 3
  %9 = shl nsw i64 %5, 2
  br label %10

10:                                               ; preds = %10, %4
  %11 = phi i64 [ 0, %4 ], [ %122, %10 ]
  %12 = getelementptr inbounds i32, i32* %1, i64 %11
  %13 = load i32, i32* %12, align 4
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = shl i64 %11, 5
  %17 = getelementptr inbounds i16, i16* %2, i64 %16
  %18 = bitcast i8* %15 to i16*
  %19 = bitcast i16* %17 to i32*
  %20 = getelementptr inbounds i16, i16* %18, i64 %6
  %21 = load i16, i16* %20, align 2
  %22 = load i32, i32* %19, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %21, %23
  store i16 %24, i16* %18, align 2
  %25 = getelementptr inbounds i16, i16* %17, i64 8
  %26 = bitcast i16* %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %20, i64 %7
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i16, i16* %17, i64 16
  %32 = bitcast i16* %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = trunc i32 %33 to i16
  %35 = add i16 %29, %34
  %36 = getelementptr inbounds i16, i16* %20, i64 %8
  store i16 %35, i16* %36, align 2
  %37 = getelementptr inbounds i16, i16* %17, i64 24
  %38 = bitcast i16* %37 to i32*
  %39 = load i32, i32* %38, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %35, %40
  %42 = getelementptr inbounds i16, i16* %20, i64 %9
  store i16 %41, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %20, i64 1
  %44 = getelementptr inbounds i16, i16* %17, i64 2
  %45 = bitcast i16* %44 to i32*
  %46 = load i16, i16* %43, align 2
  %47 = load i32, i32* %45, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %46, %48
  %50 = getelementptr inbounds i16, i16* %43, i64 %5
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %17, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %49, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 %7
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %17, i64 18
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 %8
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %17, i64 26
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 %9
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 1
  %70 = getelementptr inbounds i16, i16* %17, i64 4
  %71 = bitcast i16* %70 to i32*
  %72 = load i16, i16* %69, align 2
  %73 = load i32, i32* %71, align 4
  %74 = trunc i32 %73 to i16
  %75 = add i16 %72, %74
  %76 = getelementptr inbounds i16, i16* %69, i64 %5
  store i16 %75, i16* %76, align 2
  %77 = getelementptr inbounds i16, i16* %17, i64 12
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %75, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 %7
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %17, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 %8
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %17, i64 28
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 %9
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 1
  %96 = getelementptr inbounds i16, i16* %17, i64 6
  %97 = bitcast i16* %96 to i32*
  %98 = load i16, i16* %95, align 2
  %99 = load i32, i32* %97, align 4
  %100 = trunc i32 %99 to i16
  %101 = add i16 %98, %100
  %102 = getelementptr inbounds i16, i16* %95, i64 %5
  store i16 %101, i16* %102, align 2
  %103 = getelementptr inbounds i16, i16* %17, i64 14
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %101, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 %7
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %17, i64 22
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 %8
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %17, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 %9
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %11, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %10

124:                                              ; preds = %10, %124
  %125 = phi i64 [ %237, %124 ], [ 4, %10 ]
  %126 = add nuw nsw i64 %125, 4
  %127 = getelementptr inbounds i32, i32* %1, i64 %126
  %128 = load i32, i32* %127, align 4
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds i8, i8* %0, i64 %129
  %131 = shl i64 %125, 5
  %132 = getelementptr inbounds i16, i16* %2, i64 %131
  %133 = bitcast i8* %130 to i16*
  %134 = bitcast i16* %132 to i32*
  %135 = getelementptr inbounds i16, i16* %133, i64 %6
  %136 = load i16, i16* %135, align 2
  %137 = load i32, i32* %134, align 4
  %138 = trunc i32 %137 to i16
  %139 = add i16 %136, %138
  store i16 %139, i16* %133, align 2
  %140 = getelementptr inbounds i16, i16* %132, i64 8
  %141 = bitcast i16* %140 to i32*
  %142 = load i32, i32* %141, align 4
  %143 = trunc i32 %142 to i16
  %144 = add i16 %139, %143
  %145 = getelementptr inbounds i16, i16* %135, i64 %7
  store i16 %144, i16* %145, align 2
  %146 = getelementptr inbounds i16, i16* %132, i64 16
  %147 = bitcast i16* %146 to i32*
  %148 = load i32, i32* %147, align 4
  %149 = trunc i32 %148 to i16
  %150 = add i16 %144, %149
  %151 = getelementptr inbounds i16, i16* %135, i64 %8
  store i16 %150, i16* %151, align 2
  %152 = getelementptr inbounds i16, i16* %132, i64 24
  %153 = bitcast i16* %152 to i32*
  %154 = load i32, i32* %153, align 4
  %155 = trunc i32 %154 to i16
  %156 = add i16 %150, %155
  %157 = getelementptr inbounds i16, i16* %135, i64 %9
  store i16 %156, i16* %157, align 2
  %158 = getelementptr inbounds i16, i16* %135, i64 1
  %159 = getelementptr inbounds i16, i16* %132, i64 2
  %160 = bitcast i16* %159 to i32*
  %161 = load i16, i16* %158, align 2
  %162 = load i32, i32* %160, align 4
  %163 = trunc i32 %162 to i16
  %164 = add i16 %161, %163
  %165 = getelementptr inbounds i16, i16* %158, i64 %5
  store i16 %164, i16* %165, align 2
  %166 = getelementptr inbounds i16, i16* %132, i64 10
  %167 = bitcast i16* %166 to i32*
  %168 = load i32, i32* %167, align 4
  %169 = trunc i32 %168 to i16
  %170 = add i16 %164, %169
  %171 = getelementptr inbounds i16, i16* %158, i64 %7
  store i16 %170, i16* %171, align 2
  %172 = getelementptr inbounds i16, i16* %132, i64 18
  %173 = bitcast i16* %172 to i32*
  %174 = load i32, i32* %173, align 4
  %175 = trunc i32 %174 to i16
  %176 = add i16 %170, %175
  %177 = getelementptr inbounds i16, i16* %158, i64 %8
  store i16 %176, i16* %177, align 2
  %178 = getelementptr inbounds i16, i16* %132, i64 26
  %179 = bitcast i16* %178 to i32*
  %180 = load i32, i32* %179, align 4
  %181 = trunc i32 %180 to i16
  %182 = add i16 %176, %181
  %183 = getelementptr inbounds i16, i16* %158, i64 %9
  store i16 %182, i16* %183, align 2
  %184 = getelementptr inbounds i16, i16* %158, i64 1
  %185 = getelementptr inbounds i16, i16* %132, i64 4
  %186 = bitcast i16* %185 to i32*
  %187 = load i16, i16* %184, align 2
  %188 = load i32, i32* %186, align 4
  %189 = trunc i32 %188 to i16
  %190 = add i16 %187, %189
  %191 = getelementptr inbounds i16, i16* %184, i64 %5
  store i16 %190, i16* %191, align 2
  %192 = getelementptr inbounds i16, i16* %132, i64 12
  %193 = bitcast i16* %192 to i32*
  %194 = load i32, i32* %193, align 4
  %195 = trunc i32 %194 to i16
  %196 = add i16 %190, %195
  %197 = getelementptr inbounds i16, i16* %184, i64 %7
  store i16 %196, i16* %197, align 2
  %198 = getelementptr inbounds i16, i16* %132, i64 20
  %199 = bitcast i16* %198 to i32*
  %200 = load i32, i32* %199, align 4
  %201 = trunc i32 %200 to i16
  %202 = add i16 %196, %201
  %203 = getelementptr inbounds i16, i16* %184, i64 %8
  store i16 %202, i16* %203, align 2
  %204 = getelementptr inbounds i16, i16* %132, i64 28
  %205 = bitcast i16* %204 to i32*
  %206 = load i32, i32* %205, align 4
  %207 = trunc i32 %206 to i16
  %208 = add i16 %202, %207
  %209 = getelementptr inbounds i16, i16* %184, i64 %9
  store i16 %208, i16* %209, align 2
  %210 = getelementptr inbounds i16, i16* %184, i64 1
  %211 = getelementptr inbounds i16, i16* %132, i64 6
  %212 = bitcast i16* %211 to i32*
  %213 = load i16, i16* %210, align 2
  %214 = load i32, i32* %212, align 4
  %215 = trunc i32 %214 to i16
  %216 = add i16 %213, %215
  %217 = getelementptr inbounds i16, i16* %210, i64 %5
  store i16 %216, i16* %217, align 2
  %218 = getelementptr inbounds i16, i16* %132, i64 14
  %219 = bitcast i16* %218 to i32*
  %220 = load i32, i32* %219, align 4
  %221 = trunc i32 %220 to i16
  %222 = add i16 %216, %221
  %223 = getelementptr inbounds i16, i16* %210, i64 %7
  store i16 %222, i16* %223, align 2
  %224 = getelementptr inbounds i16, i16* %132, i64 22
  %225 = bitcast i16* %224 to i32*
  %226 = load i32, i32* %225, align 4
  %227 = trunc i32 %226 to i16
  %228 = add i16 %222, %227
  %229 = getelementptr inbounds i16, i16* %210, i64 %8
  store i16 %228, i16* %229, align 2
  %230 = getelementptr inbounds i16, i16* %132, i64 30
  %231 = bitcast i16* %230 to i32*
  %232 = load i32, i32* %231, align 4
  %233 = trunc i32 %232 to i16
  %234 = add i16 %228, %233
  %235 = getelementptr inbounds i16, i16* %210, i64 %9
  store i16 %234, i16* %235, align 2
  %236 = bitcast i16* %132 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %236, i8 0, i64 64, i1 false) #8
  %237 = add nuw nsw i64 %125, 1
  %238 = icmp eq i64 %237, 8
  br i1 %238, label %239, label %124

239:                                              ; preds = %124
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x16_horizontal_add_12_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %122, %6 ]
  %8 = getelementptr inbounds i32, i32* %1, i64 %7
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = shl i64 %7, 5
  %13 = getelementptr inbounds i16, i16* %2, i64 %12
  %14 = bitcast i8* %11 to i16*
  %15 = bitcast i16* %13 to i32*
  %16 = getelementptr inbounds i8, i8* %11, i64 -2
  %17 = bitcast i8* %16 to i16*
  %18 = load i16, i16* %17, align 2
  %19 = load i32, i32* %15, align 4
  %20 = trunc i32 %19 to i16
  %21 = add i16 %18, %20
  store i16 %21, i16* %14, align 2
  %22 = getelementptr inbounds i16, i16* %13, i64 2
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %21, %25
  %27 = getelementptr inbounds i8, i8* %11, i64 2
  %28 = bitcast i8* %27 to i16*
  store i16 %26, i16* %28, align 2
  %29 = getelementptr inbounds i16, i16* %13, i64 4
  %30 = bitcast i16* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %26, %32
  %34 = getelementptr inbounds i8, i8* %11, i64 4
  %35 = bitcast i8* %34 to i16*
  store i16 %33, i16* %35, align 2
  %36 = getelementptr inbounds i16, i16* %13, i64 6
  %37 = bitcast i16* %36 to i32*
  %38 = load i32, i32* %37, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %33, %39
  %41 = getelementptr inbounds i8, i8* %11, i64 6
  %42 = bitcast i8* %41 to i16*
  store i16 %40, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %14, i64 %5
  %44 = getelementptr inbounds i16, i16* %13, i64 8
  %45 = bitcast i16* %44 to i32*
  %46 = getelementptr inbounds i16, i16* %43, i64 -1
  %47 = load i16, i16* %46, align 2
  %48 = load i32, i32* %45, align 4
  %49 = trunc i32 %48 to i16
  %50 = add i16 %47, %49
  store i16 %50, i16* %43, align 2
  %51 = getelementptr inbounds i16, i16* %13, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %50, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 1
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %13, i64 12
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 2
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %13, i64 14
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 3
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 %5
  %70 = getelementptr inbounds i16, i16* %13, i64 16
  %71 = bitcast i16* %70 to i32*
  %72 = getelementptr inbounds i16, i16* %69, i64 -1
  %73 = load i16, i16* %72, align 2
  %74 = load i32, i32* %71, align 4
  %75 = trunc i32 %74 to i16
  %76 = add i16 %73, %75
  store i16 %76, i16* %69, align 2
  %77 = getelementptr inbounds i16, i16* %13, i64 18
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %76, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 1
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %13, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 2
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %13, i64 22
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 3
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 %5
  %96 = getelementptr inbounds i16, i16* %13, i64 24
  %97 = bitcast i16* %96 to i32*
  %98 = getelementptr inbounds i16, i16* %95, i64 -1
  %99 = load i16, i16* %98, align 2
  %100 = load i32, i32* %97, align 4
  %101 = trunc i32 %100 to i16
  %102 = add i16 %99, %101
  store i16 %102, i16* %95, align 2
  %103 = getelementptr inbounds i16, i16* %13, i64 26
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %102, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 1
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %13, i64 28
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 2
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %13, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 3
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %7, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %6

124:                                              ; preds = %6, %124
  %125 = phi i64 [ %241, %124 ], [ 4, %6 ]
  %126 = add nuw nsw i64 %125, 4
  %127 = getelementptr inbounds i32, i32* %1, i64 %126
  %128 = load i32, i32* %127, align 4
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds i8, i8* %0, i64 %129
  %131 = shl i64 %125, 5
  %132 = getelementptr inbounds i16, i16* %2, i64 %131
  %133 = bitcast i8* %130 to i16*
  %134 = bitcast i16* %132 to i32*
  %135 = getelementptr inbounds i8, i8* %130, i64 -2
  %136 = bitcast i8* %135 to i16*
  %137 = load i16, i16* %136, align 2
  %138 = load i32, i32* %134, align 4
  %139 = trunc i32 %138 to i16
  %140 = add i16 %137, %139
  store i16 %140, i16* %133, align 2
  %141 = getelementptr inbounds i16, i16* %132, i64 2
  %142 = bitcast i16* %141 to i32*
  %143 = load i32, i32* %142, align 4
  %144 = trunc i32 %143 to i16
  %145 = add i16 %140, %144
  %146 = getelementptr inbounds i8, i8* %130, i64 2
  %147 = bitcast i8* %146 to i16*
  store i16 %145, i16* %147, align 2
  %148 = getelementptr inbounds i16, i16* %132, i64 4
  %149 = bitcast i16* %148 to i32*
  %150 = load i32, i32* %149, align 4
  %151 = trunc i32 %150 to i16
  %152 = add i16 %145, %151
  %153 = getelementptr inbounds i8, i8* %130, i64 4
  %154 = bitcast i8* %153 to i16*
  store i16 %152, i16* %154, align 2
  %155 = getelementptr inbounds i16, i16* %132, i64 6
  %156 = bitcast i16* %155 to i32*
  %157 = load i32, i32* %156, align 4
  %158 = trunc i32 %157 to i16
  %159 = add i16 %152, %158
  %160 = getelementptr inbounds i8, i8* %130, i64 6
  %161 = bitcast i8* %160 to i16*
  store i16 %159, i16* %161, align 2
  %162 = getelementptr inbounds i16, i16* %133, i64 %5
  %163 = getelementptr inbounds i16, i16* %132, i64 8
  %164 = bitcast i16* %163 to i32*
  %165 = getelementptr inbounds i16, i16* %162, i64 -1
  %166 = load i16, i16* %165, align 2
  %167 = load i32, i32* %164, align 4
  %168 = trunc i32 %167 to i16
  %169 = add i16 %166, %168
  store i16 %169, i16* %162, align 2
  %170 = getelementptr inbounds i16, i16* %132, i64 10
  %171 = bitcast i16* %170 to i32*
  %172 = load i32, i32* %171, align 4
  %173 = trunc i32 %172 to i16
  %174 = add i16 %169, %173
  %175 = getelementptr inbounds i16, i16* %162, i64 1
  store i16 %174, i16* %175, align 2
  %176 = getelementptr inbounds i16, i16* %132, i64 12
  %177 = bitcast i16* %176 to i32*
  %178 = load i32, i32* %177, align 4
  %179 = trunc i32 %178 to i16
  %180 = add i16 %174, %179
  %181 = getelementptr inbounds i16, i16* %162, i64 2
  store i16 %180, i16* %181, align 2
  %182 = getelementptr inbounds i16, i16* %132, i64 14
  %183 = bitcast i16* %182 to i32*
  %184 = load i32, i32* %183, align 4
  %185 = trunc i32 %184 to i16
  %186 = add i16 %180, %185
  %187 = getelementptr inbounds i16, i16* %162, i64 3
  store i16 %186, i16* %187, align 2
  %188 = getelementptr inbounds i16, i16* %162, i64 %5
  %189 = getelementptr inbounds i16, i16* %132, i64 16
  %190 = bitcast i16* %189 to i32*
  %191 = getelementptr inbounds i16, i16* %188, i64 -1
  %192 = load i16, i16* %191, align 2
  %193 = load i32, i32* %190, align 4
  %194 = trunc i32 %193 to i16
  %195 = add i16 %192, %194
  store i16 %195, i16* %188, align 2
  %196 = getelementptr inbounds i16, i16* %132, i64 18
  %197 = bitcast i16* %196 to i32*
  %198 = load i32, i32* %197, align 4
  %199 = trunc i32 %198 to i16
  %200 = add i16 %195, %199
  %201 = getelementptr inbounds i16, i16* %188, i64 1
  store i16 %200, i16* %201, align 2
  %202 = getelementptr inbounds i16, i16* %132, i64 20
  %203 = bitcast i16* %202 to i32*
  %204 = load i32, i32* %203, align 4
  %205 = trunc i32 %204 to i16
  %206 = add i16 %200, %205
  %207 = getelementptr inbounds i16, i16* %188, i64 2
  store i16 %206, i16* %207, align 2
  %208 = getelementptr inbounds i16, i16* %132, i64 22
  %209 = bitcast i16* %208 to i32*
  %210 = load i32, i32* %209, align 4
  %211 = trunc i32 %210 to i16
  %212 = add i16 %206, %211
  %213 = getelementptr inbounds i16, i16* %188, i64 3
  store i16 %212, i16* %213, align 2
  %214 = getelementptr inbounds i16, i16* %188, i64 %5
  %215 = getelementptr inbounds i16, i16* %132, i64 24
  %216 = bitcast i16* %215 to i32*
  %217 = getelementptr inbounds i16, i16* %214, i64 -1
  %218 = load i16, i16* %217, align 2
  %219 = load i32, i32* %216, align 4
  %220 = trunc i32 %219 to i16
  %221 = add i16 %218, %220
  store i16 %221, i16* %214, align 2
  %222 = getelementptr inbounds i16, i16* %132, i64 26
  %223 = bitcast i16* %222 to i32*
  %224 = load i32, i32* %223, align 4
  %225 = trunc i32 %224 to i16
  %226 = add i16 %221, %225
  %227 = getelementptr inbounds i16, i16* %214, i64 1
  store i16 %226, i16* %227, align 2
  %228 = getelementptr inbounds i16, i16* %132, i64 28
  %229 = bitcast i16* %228 to i32*
  %230 = load i32, i32* %229, align 4
  %231 = trunc i32 %230 to i16
  %232 = add i16 %226, %231
  %233 = getelementptr inbounds i16, i16* %214, i64 2
  store i16 %232, i16* %233, align 2
  %234 = getelementptr inbounds i16, i16* %132, i64 30
  %235 = bitcast i16* %234 to i32*
  %236 = load i32, i32* %235, align 4
  %237 = trunc i32 %236 to i16
  %238 = add i16 %232, %237
  %239 = getelementptr inbounds i16, i16* %214, i64 3
  store i16 %238, i16* %239, align 2
  %240 = bitcast i16* %132 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %240, i8 0, i64 64, i1 false) #8
  %241 = add nuw nsw i64 %125, 1
  %242 = icmp eq i64 %241, 8
  br i1 %242, label %243, label %124

243:                                              ; preds = %124
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred16x16_vertical_add_12_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  %6 = sub nsw i64 0, %5
  %7 = and i64 %3, -2
  %8 = mul nsw i64 %5, 3
  %9 = shl nsw i64 %5, 2
  br label %10

10:                                               ; preds = %10, %4
  %11 = phi i64 [ 0, %4 ], [ %122, %10 ]
  %12 = getelementptr inbounds i32, i32* %1, i64 %11
  %13 = load i32, i32* %12, align 4
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = shl i64 %11, 5
  %17 = getelementptr inbounds i16, i16* %2, i64 %16
  %18 = bitcast i8* %15 to i16*
  %19 = bitcast i16* %17 to i32*
  %20 = getelementptr inbounds i16, i16* %18, i64 %6
  %21 = load i16, i16* %20, align 2
  %22 = load i32, i32* %19, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %21, %23
  store i16 %24, i16* %18, align 2
  %25 = getelementptr inbounds i16, i16* %17, i64 8
  %26 = bitcast i16* %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %20, i64 %7
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i16, i16* %17, i64 16
  %32 = bitcast i16* %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = trunc i32 %33 to i16
  %35 = add i16 %29, %34
  %36 = getelementptr inbounds i16, i16* %20, i64 %8
  store i16 %35, i16* %36, align 2
  %37 = getelementptr inbounds i16, i16* %17, i64 24
  %38 = bitcast i16* %37 to i32*
  %39 = load i32, i32* %38, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %35, %40
  %42 = getelementptr inbounds i16, i16* %20, i64 %9
  store i16 %41, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %20, i64 1
  %44 = getelementptr inbounds i16, i16* %17, i64 2
  %45 = bitcast i16* %44 to i32*
  %46 = load i16, i16* %43, align 2
  %47 = load i32, i32* %45, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %46, %48
  %50 = getelementptr inbounds i16, i16* %43, i64 %5
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %17, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %49, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 %7
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %17, i64 18
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 %8
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %17, i64 26
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 %9
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 1
  %70 = getelementptr inbounds i16, i16* %17, i64 4
  %71 = bitcast i16* %70 to i32*
  %72 = load i16, i16* %69, align 2
  %73 = load i32, i32* %71, align 4
  %74 = trunc i32 %73 to i16
  %75 = add i16 %72, %74
  %76 = getelementptr inbounds i16, i16* %69, i64 %5
  store i16 %75, i16* %76, align 2
  %77 = getelementptr inbounds i16, i16* %17, i64 12
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %75, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 %7
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %17, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 %8
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %17, i64 28
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 %9
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 1
  %96 = getelementptr inbounds i16, i16* %17, i64 6
  %97 = bitcast i16* %96 to i32*
  %98 = load i16, i16* %95, align 2
  %99 = load i32, i32* %97, align 4
  %100 = trunc i32 %99 to i16
  %101 = add i16 %98, %100
  %102 = getelementptr inbounds i16, i16* %95, i64 %5
  store i16 %101, i16* %102, align 2
  %103 = getelementptr inbounds i16, i16* %17, i64 14
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %101, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 %7
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %17, i64 22
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 %8
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %17, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 %9
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %11, 1
  %123 = icmp eq i64 %122, 16
  br i1 %123, label %124, label %10

124:                                              ; preds = %10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred16x16_horizontal_add_12_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %122, %6 ]
  %8 = getelementptr inbounds i32, i32* %1, i64 %7
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = shl i64 %7, 5
  %13 = getelementptr inbounds i16, i16* %2, i64 %12
  %14 = bitcast i8* %11 to i16*
  %15 = bitcast i16* %13 to i32*
  %16 = getelementptr inbounds i8, i8* %11, i64 -2
  %17 = bitcast i8* %16 to i16*
  %18 = load i16, i16* %17, align 2
  %19 = load i32, i32* %15, align 4
  %20 = trunc i32 %19 to i16
  %21 = add i16 %18, %20
  store i16 %21, i16* %14, align 2
  %22 = getelementptr inbounds i16, i16* %13, i64 2
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %21, %25
  %27 = getelementptr inbounds i8, i8* %11, i64 2
  %28 = bitcast i8* %27 to i16*
  store i16 %26, i16* %28, align 2
  %29 = getelementptr inbounds i16, i16* %13, i64 4
  %30 = bitcast i16* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %26, %32
  %34 = getelementptr inbounds i8, i8* %11, i64 4
  %35 = bitcast i8* %34 to i16*
  store i16 %33, i16* %35, align 2
  %36 = getelementptr inbounds i16, i16* %13, i64 6
  %37 = bitcast i16* %36 to i32*
  %38 = load i32, i32* %37, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %33, %39
  %41 = getelementptr inbounds i8, i8* %11, i64 6
  %42 = bitcast i8* %41 to i16*
  store i16 %40, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %14, i64 %5
  %44 = getelementptr inbounds i16, i16* %13, i64 8
  %45 = bitcast i16* %44 to i32*
  %46 = getelementptr inbounds i16, i16* %43, i64 -1
  %47 = load i16, i16* %46, align 2
  %48 = load i32, i32* %45, align 4
  %49 = trunc i32 %48 to i16
  %50 = add i16 %47, %49
  store i16 %50, i16* %43, align 2
  %51 = getelementptr inbounds i16, i16* %13, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %50, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 1
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %13, i64 12
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 2
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %13, i64 14
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 3
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 %5
  %70 = getelementptr inbounds i16, i16* %13, i64 16
  %71 = bitcast i16* %70 to i32*
  %72 = getelementptr inbounds i16, i16* %69, i64 -1
  %73 = load i16, i16* %72, align 2
  %74 = load i32, i32* %71, align 4
  %75 = trunc i32 %74 to i16
  %76 = add i16 %73, %75
  store i16 %76, i16* %69, align 2
  %77 = getelementptr inbounds i16, i16* %13, i64 18
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %76, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 1
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %13, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 2
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %13, i64 22
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 3
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 %5
  %96 = getelementptr inbounds i16, i16* %13, i64 24
  %97 = bitcast i16* %96 to i32*
  %98 = getelementptr inbounds i16, i16* %95, i64 -1
  %99 = load i16, i16* %98, align 2
  %100 = load i32, i32* %97, align 4
  %101 = trunc i32 %100 to i16
  %102 = add i16 %99, %101
  store i16 %102, i16* %95, align 2
  %103 = getelementptr inbounds i16, i16* %13, i64 26
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %102, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 1
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %13, i64 28
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 2
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %13, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 3
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %7, 1
  %123 = icmp eq i64 %122, 16
  br i1 %123, label %124, label %6

124:                                              ; preds = %6
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_14_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = shl i64 %5, 32
  %7 = ashr exact i64 %6, 32
  %8 = sub nsw i64 0, %7
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  %11 = load i64, i64* %10, align 8
  %12 = bitcast i8* %0 to i64*
  store i64 %11, i64* %12, align 8
  %13 = getelementptr inbounds i16, i16* %4, i64 %7
  %14 = bitcast i16* %13 to i64*
  store i64 %11, i64* %14, align 8
  %15 = shl i64 %2, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 %11, i64* %19, align 8
  %20 = mul i64 %5, 12884901888
  %21 = ashr exact i64 %20, 32
  %22 = getelementptr inbounds i16, i16* %4, i64 %21
  %23 = bitcast i16* %22 to i64*
  store i64 %11, i64* %23, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_14_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = mul nuw i64 %10, 281479271743489
  %12 = bitcast i8* %0 to i64*
  store i64 %11, i64* %12, align 8
  %13 = shl i64 %5, 32
  %14 = add i64 %13, -4294967296
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i16, i16* %4, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i64
  %19 = mul nuw i64 %18, 281479271743489
  %20 = ashr exact i64 %13, 32
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = bitcast i16* %21 to i64*
  store i64 %19, i64* %22, align 8
  %23 = trunc i64 %2 to i32
  %24 = and i32 %23, -2
  %25 = add nsw i32 %24, -1
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds i16, i16* %4, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i64
  %30 = mul nuw i64 %29, 281479271743489
  %31 = sext i32 %24 to i64
  %32 = getelementptr inbounds i16, i16* %4, i64 %31
  %33 = bitcast i16* %32 to i64*
  store i64 %30, i64* %33, align 8
  %34 = mul nsw i32 %6, 3
  %35 = add nsw i32 %34, -1
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds i16, i16* %4, i64 %36
  %38 = load i16, i16* %37, align 2
  %39 = zext i16 %38 to i64
  %40 = mul nuw i64 %39, 281479271743489
  %41 = sext i32 %34 to i64
  %42 = getelementptr inbounds i16, i16* %4, i64 %41
  %43 = bitcast i16* %42 to i64*
  store i64 %40, i64* %43, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_dc_14_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = sub i64 0, %7
  %9 = ashr exact i64 %8, 32
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 4294967296, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 8589934592, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 12884901888, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = getelementptr inbounds i8, i8* %0, i64 -2
  %29 = bitcast i8* %28 to i16*
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i32
  %32 = add i64 %7, -4294967296
  %33 = ashr exact i64 %32, 32
  %34 = getelementptr inbounds i16, i16* %4, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = trunc i64 %2 to i32
  %38 = and i32 %37, -2
  %39 = add nsw i32 %38, -1
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds i16, i16* %4, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = mul nsw i32 %6, 3
  %45 = add nsw i32 %44, -1
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds i16, i16* %4, i64 %46
  %48 = load i16, i16* %47, align 2
  %49 = zext i16 %48 to i32
  %50 = add nuw nsw i32 %12, 4
  %51 = add nuw nsw i32 %50, %17
  %52 = add nuw nsw i32 %51, %22
  %53 = add nuw nsw i32 %52, %27
  %54 = add nuw nsw i32 %53, %31
  %55 = add nuw nsw i32 %54, %36
  %56 = add nuw nsw i32 %55, %43
  %57 = add nuw nsw i32 %56, %49
  %58 = ashr i32 %57, 3
  %59 = sext i32 %58 to i64
  %60 = mul i64 %59, 281479271743489
  %61 = bitcast i8* %0 to i64*
  store i64 %60, i64* %61, align 8
  %62 = ashr exact i64 %7, 32
  %63 = getelementptr inbounds i16, i16* %4, i64 %62
  %64 = bitcast i16* %63 to i64*
  store i64 %60, i64* %64, align 8
  %65 = sext i32 %38 to i64
  %66 = getelementptr inbounds i16, i16* %4, i64 %65
  %67 = bitcast i16* %66 to i64*
  store i64 %60, i64* %67, align 8
  %68 = sext i32 %44 to i64
  %69 = getelementptr inbounds i16, i16* %4, i64 %68
  %70 = bitcast i16* %69 to i64*
  store i64 %60, i64* %70, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_down_left_14_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i8* %1 to i16*
  %6 = lshr i64 %2, 1
  %7 = trunc i64 %6 to i32
  %8 = shl i64 %6, 32
  %9 = sub i64 0, %8
  %10 = ashr exact i64 %9, 32
  %11 = getelementptr inbounds i16, i16* %4, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i32
  %14 = sub i64 4294967296, %8
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i16, i16* %4, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i32
  %19 = sub i64 8589934592, %8
  %20 = ashr exact i64 %19, 32
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = sub i64 12884901888, %8
  %25 = ashr exact i64 %24, 32
  %26 = getelementptr inbounds i16, i16* %4, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %5, align 2
  %30 = zext i16 %29 to i32
  %31 = getelementptr inbounds i8, i8* %1, i64 2
  %32 = bitcast i8* %31 to i16*
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = getelementptr inbounds i8, i8* %1, i64 4
  %36 = bitcast i8* %35 to i16*
  %37 = load i16, i16* %36, align 2
  %38 = zext i16 %37 to i32
  %39 = getelementptr inbounds i8, i8* %1, i64 6
  %40 = bitcast i8* %39 to i16*
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i32
  %43 = shl nuw nsw i32 %18, 1
  %44 = add nuw nsw i32 %23, 2
  %45 = add nuw nsw i32 %44, %13
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = trunc i32 %47 to i16
  store i16 %48, i16* %4, align 2
  %49 = shl nuw nsw i32 %23, 1
  %50 = add nuw nsw i32 %28, 2
  %51 = add nuw nsw i32 %50, %18
  %52 = add nuw nsw i32 %51, %49
  %53 = lshr i32 %52, 2
  %54 = trunc i32 %53 to i16
  %55 = ashr exact i64 %8, 32
  %56 = getelementptr inbounds i16, i16* %4, i64 %55
  store i16 %54, i16* %56, align 2
  %57 = getelementptr inbounds i8, i8* %0, i64 2
  %58 = bitcast i8* %57 to i16*
  store i16 %54, i16* %58, align 2
  %59 = shl nuw nsw i32 %28, 1
  %60 = add nuw nsw i32 %44, %30
  %61 = add nuw nsw i32 %60, %59
  %62 = lshr i32 %61, 2
  %63 = trunc i32 %62 to i16
  %64 = trunc i64 %2 to i32
  %65 = and i32 %64, -2
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds i16, i16* %4, i64 %66
  store i16 %63, i16* %67, align 2
  %68 = add i64 %8, 4294967296
  %69 = ashr exact i64 %68, 32
  %70 = getelementptr inbounds i16, i16* %4, i64 %69
  store i16 %63, i16* %70, align 2
  %71 = getelementptr inbounds i8, i8* %0, i64 4
  %72 = bitcast i8* %71 to i16*
  store i16 %63, i16* %72, align 2
  %73 = shl nuw nsw i32 %30, 1
  %74 = add nuw nsw i32 %50, %34
  %75 = add nuw nsw i32 %74, %73
  %76 = lshr i32 %75, 2
  %77 = trunc i32 %76 to i16
  %78 = mul nsw i32 %7, 3
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i16, i16* %4, i64 %79
  store i16 %77, i16* %80, align 2
  %81 = shl i64 %2, 32
  %82 = ashr exact i64 %81, 32
  %83 = or i64 %82, 1
  %84 = getelementptr inbounds i16, i16* %4, i64 %83
  store i16 %77, i16* %84, align 2
  %85 = add i64 %8, 8589934592
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i16, i16* %4, i64 %86
  store i16 %77, i16* %87, align 2
  %88 = getelementptr inbounds i8, i8* %0, i64 6
  %89 = bitcast i8* %88 to i16*
  store i16 %77, i16* %89, align 2
  %90 = shl nuw nsw i32 %34, 1
  %91 = add nuw nsw i32 %30, 2
  %92 = add nuw nsw i32 %91, %38
  %93 = add nuw nsw i32 %92, %90
  %94 = lshr i32 %93, 2
  %95 = trunc i32 %94 to i16
  %96 = add nsw i32 %78, 1
  %97 = sext i32 %96 to i64
  %98 = getelementptr inbounds i16, i16* %4, i64 %97
  store i16 %95, i16* %98, align 2
  %99 = add nsw i32 %65, 2
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds i16, i16* %4, i64 %100
  store i16 %95, i16* %101, align 2
  %102 = add i64 %8, 12884901888
  %103 = ashr exact i64 %102, 32
  %104 = getelementptr inbounds i16, i16* %4, i64 %103
  store i16 %95, i16* %104, align 2
  %105 = shl nuw nsw i32 %38, 1
  %106 = add nuw nsw i32 %34, 2
  %107 = add nuw nsw i32 %106, %42
  %108 = add nuw nsw i32 %107, %105
  %109 = lshr i32 %108, 2
  %110 = trunc i32 %109 to i16
  %111 = add nsw i32 %78, 2
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds i16, i16* %4, i64 %112
  store i16 %110, i16* %113, align 2
  %114 = add nsw i32 %65, 3
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds i16, i16* %4, i64 %115
  store i16 %110, i16* %116, align 2
  %117 = mul nuw nsw i32 %42, 3
  %118 = add nuw nsw i32 %38, 2
  %119 = add nuw nsw i32 %118, %117
  %120 = lshr i32 %119, 2
  %121 = trunc i32 %120 to i16
  %122 = add nsw i32 %78, 3
  %123 = sext i32 %122 to i64
  %124 = getelementptr inbounds i16, i16* %4, i64 %123
  store i16 %121, i16* %124, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_down_right_14_c(i8*, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = xor i64 %8, -1
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 0, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 4294967296, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 8589934592, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = sub i64 12884901888, %7
  %29 = ashr exact i64 %28, 32
  %30 = getelementptr inbounds i16, i16* %4, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i32
  %33 = getelementptr inbounds i8, i8* %0, i64 -2
  %34 = bitcast i8* %33 to i16*
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = add i64 %7, -4294967296
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i16, i16* %4, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i32
  %42 = trunc i64 %2 to i32
  %43 = and i32 %42, -2
  %44 = add nsw i32 %43, -1
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i16, i16* %4, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i32
  %49 = mul nsw i32 %6, 3
  %50 = add nsw i32 %49, -1
  %51 = sext i32 %50 to i64
  %52 = getelementptr inbounds i16, i16* %4, i64 %51
  %53 = load i16, i16* %52, align 2
  %54 = zext i16 %53 to i32
  %55 = shl nuw nsw i32 %48, 1
  %56 = add nuw nsw i32 %41, 2
  %57 = add nuw nsw i32 %56, %54
  %58 = add nuw nsw i32 %57, %55
  %59 = lshr i32 %58, 2
  %60 = trunc i32 %59 to i16
  %61 = sext i32 %49 to i64
  %62 = getelementptr inbounds i16, i16* %4, i64 %61
  store i16 %60, i16* %62, align 2
  %63 = shl nuw nsw i32 %41, 1
  %64 = add nuw nsw i32 %36, 2
  %65 = add nuw nsw i32 %64, %48
  %66 = add nuw nsw i32 %65, %63
  %67 = lshr i32 %66, 2
  %68 = trunc i32 %67 to i16
  %69 = add nsw i32 %49, 1
  %70 = sext i32 %69 to i64
  %71 = getelementptr inbounds i16, i16* %4, i64 %70
  store i16 %68, i16* %71, align 2
  %72 = sext i32 %43 to i64
  %73 = getelementptr inbounds i16, i16* %4, i64 %72
  store i16 %68, i16* %73, align 2
  %74 = shl nuw nsw i32 %36, 1
  %75 = add nuw nsw i32 %12, 2
  %76 = add nuw nsw i32 %75, %41
  %77 = add nuw nsw i32 %76, %74
  %78 = lshr i32 %77, 2
  %79 = trunc i32 %78 to i16
  %80 = add nsw i32 %49, 2
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds i16, i16* %4, i64 %81
  store i16 %79, i16* %82, align 2
  %83 = shl i64 %2, 32
  %84 = ashr exact i64 %83, 32
  %85 = or i64 %84, 1
  %86 = getelementptr inbounds i16, i16* %4, i64 %85
  store i16 %79, i16* %86, align 2
  %87 = getelementptr inbounds i16, i16* %4, i64 %8
  store i16 %79, i16* %87, align 2
  %88 = shl nuw nsw i32 %12, 1
  %89 = add nuw nsw i32 %17, 2
  %90 = add nuw nsw i32 %89, %88
  %91 = add nuw nsw i32 %90, %36
  %92 = lshr i32 %91, 2
  %93 = trunc i32 %92 to i16
  %94 = add nsw i32 %49, 3
  %95 = sext i32 %94 to i64
  %96 = getelementptr inbounds i16, i16* %4, i64 %95
  store i16 %93, i16* %96, align 2
  %97 = add nsw i32 %43, 2
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds i16, i16* %4, i64 %98
  store i16 %93, i16* %99, align 2
  %100 = add i64 %7, 4294967296
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %4, i64 %101
  store i16 %93, i16* %102, align 2
  store i16 %93, i16* %4, align 2
  %103 = shl nuw nsw i32 %17, 1
  %104 = add nuw nsw i32 %75, %103
  %105 = add nuw nsw i32 %104, %22
  %106 = lshr i32 %105, 2
  %107 = trunc i32 %106 to i16
  %108 = add nsw i32 %43, 3
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds i16, i16* %4, i64 %109
  store i16 %107, i16* %110, align 2
  %111 = add i64 %7, 8589934592
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds i16, i16* %4, i64 %112
  store i16 %107, i16* %113, align 2
  %114 = getelementptr inbounds i8, i8* %0, i64 2
  %115 = bitcast i8* %114 to i16*
  store i16 %107, i16* %115, align 2
  %116 = shl nuw nsw i32 %22, 1
  %117 = add nuw nsw i32 %89, %116
  %118 = add nuw nsw i32 %117, %27
  %119 = lshr i32 %118, 2
  %120 = trunc i32 %119 to i16
  %121 = add i64 %7, 12884901888
  %122 = ashr exact i64 %121, 32
  %123 = getelementptr inbounds i16, i16* %4, i64 %122
  store i16 %120, i16* %123, align 2
  %124 = getelementptr inbounds i8, i8* %0, i64 4
  %125 = bitcast i8* %124 to i16*
  store i16 %120, i16* %125, align 2
  %126 = shl nuw nsw i32 %27, 1
  %127 = add nuw nsw i32 %22, 2
  %128 = add nuw nsw i32 %127, %126
  %129 = add nuw nsw i32 %128, %32
  %130 = lshr i32 %129, 2
  %131 = trunc i32 %130 to i16
  %132 = getelementptr inbounds i8, i8* %0, i64 6
  %133 = bitcast i8* %132 to i16*
  store i16 %131, i16* %133, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_right_14_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = xor i64 %8, -1
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 0, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 4294967296, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 8589934592, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = sub i64 12884901888, %7
  %29 = ashr exact i64 %28, 32
  %30 = getelementptr inbounds i16, i16* %4, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i32
  %33 = getelementptr inbounds i8, i8* %0, i64 -2
  %34 = bitcast i8* %33 to i16*
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = add i64 %7, -4294967296
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i16, i16* %4, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i32
  %42 = trunc i64 %2 to i32
  %43 = and i32 %42, -2
  %44 = add nsw i32 %43, -1
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i16, i16* %4, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i32
  %49 = mul nsw i32 %6, 3
  %50 = add nuw nsw i32 %17, 1
  %51 = add nuw nsw i32 %50, %12
  %52 = lshr i32 %51, 1
  %53 = trunc i32 %52 to i16
  %54 = shl i64 %2, 32
  %55 = ashr exact i64 %54, 32
  %56 = or i64 %55, 1
  %57 = getelementptr inbounds i16, i16* %4, i64 %56
  store i16 %53, i16* %57, align 2
  store i16 %53, i16* %4, align 2
  %58 = add nuw nsw i32 %50, %22
  %59 = lshr i32 %58, 1
  %60 = trunc i32 %59 to i16
  %61 = add nsw i32 %43, 2
  %62 = sext i32 %61 to i64
  %63 = getelementptr inbounds i16, i16* %4, i64 %62
  store i16 %60, i16* %63, align 2
  %64 = getelementptr inbounds i8, i8* %0, i64 2
  %65 = bitcast i8* %64 to i16*
  store i16 %60, i16* %65, align 2
  %66 = add nuw nsw i32 %22, 1
  %67 = add nuw nsw i32 %66, %27
  %68 = lshr i32 %67, 1
  %69 = trunc i32 %68 to i16
  %70 = add nsw i32 %43, 3
  %71 = sext i32 %70 to i64
  %72 = getelementptr inbounds i16, i16* %4, i64 %71
  store i16 %69, i16* %72, align 2
  %73 = getelementptr inbounds i8, i8* %0, i64 4
  %74 = bitcast i8* %73 to i16*
  store i16 %69, i16* %74, align 2
  %75 = add nuw nsw i32 %27, 1
  %76 = add nuw nsw i32 %75, %32
  %77 = lshr i32 %76, 1
  %78 = trunc i32 %77 to i16
  %79 = getelementptr inbounds i8, i8* %0, i64 6
  %80 = bitcast i8* %79 to i16*
  store i16 %78, i16* %80, align 2
  %81 = shl nuw nsw i32 %12, 1
  %82 = add nuw nsw i32 %17, 2
  %83 = add nuw nsw i32 %82, %81
  %84 = add nuw nsw i32 %83, %36
  %85 = lshr i32 %84, 2
  %86 = trunc i32 %85 to i16
  %87 = add nsw i32 %49, 1
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds i16, i16* %4, i64 %88
  store i16 %86, i16* %89, align 2
  %90 = getelementptr inbounds i16, i16* %4, i64 %8
  store i16 %86, i16* %90, align 2
  %91 = shl nuw nsw i32 %17, 1
  %92 = add nuw nsw i32 %12, 2
  %93 = add nuw nsw i32 %92, %91
  %94 = add nuw nsw i32 %93, %22
  %95 = lshr i32 %94, 2
  %96 = trunc i32 %95 to i16
  %97 = add nsw i32 %49, 2
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds i16, i16* %4, i64 %98
  store i16 %96, i16* %99, align 2
  %100 = add i64 %7, 4294967296
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %4, i64 %101
  store i16 %96, i16* %102, align 2
  %103 = shl nuw nsw i32 %22, 1
  %104 = add nuw nsw i32 %82, %103
  %105 = add nuw nsw i32 %104, %27
  %106 = lshr i32 %105, 2
  %107 = trunc i32 %106 to i16
  %108 = add nsw i32 %49, 3
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds i16, i16* %4, i64 %109
  store i16 %107, i16* %110, align 2
  %111 = add i64 %7, 8589934592
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds i16, i16* %4, i64 %112
  store i16 %107, i16* %113, align 2
  %114 = shl nuw nsw i32 %27, 1
  %115 = add nuw nsw i32 %22, 2
  %116 = add nuw nsw i32 %115, %114
  %117 = add nuw nsw i32 %116, %32
  %118 = lshr i32 %117, 2
  %119 = trunc i32 %118 to i16
  %120 = add i64 %7, 12884901888
  %121 = ashr exact i64 %120, 32
  %122 = getelementptr inbounds i16, i16* %4, i64 %121
  store i16 %119, i16* %122, align 2
  %123 = shl nuw nsw i32 %36, 1
  %124 = add nuw nsw i32 %92, %123
  %125 = add nuw nsw i32 %124, %41
  %126 = lshr i32 %125, 2
  %127 = trunc i32 %126 to i16
  %128 = sext i32 %43 to i64
  %129 = getelementptr inbounds i16, i16* %4, i64 %128
  store i16 %127, i16* %129, align 2
  %130 = shl nuw nsw i32 %41, 1
  %131 = add nuw nsw i32 %36, 2
  %132 = add nuw nsw i32 %131, %130
  %133 = add nuw nsw i32 %132, %48
  %134 = lshr i32 %133, 2
  %135 = trunc i32 %134 to i16
  %136 = sext i32 %49 to i64
  %137 = getelementptr inbounds i16, i16* %4, i64 %136
  store i16 %135, i16* %137, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_down_14_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = xor i64 %8, -1
  %10 = getelementptr inbounds i16, i16* %4, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i32
  %13 = sub i64 0, %7
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i16, i16* %4, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = sub i64 4294967296, %7
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i16, i16* %4, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = sub i64 8589934592, %7
  %24 = ashr exact i64 %23, 32
  %25 = getelementptr inbounds i16, i16* %4, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = getelementptr inbounds i8, i8* %0, i64 -2
  %29 = bitcast i8* %28 to i16*
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i32
  %32 = add i64 %7, -4294967296
  %33 = ashr exact i64 %32, 32
  %34 = getelementptr inbounds i16, i16* %4, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = trunc i64 %2 to i32
  %38 = and i32 %37, -2
  %39 = add nsw i32 %38, -1
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds i16, i16* %4, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = mul nsw i32 %6, 3
  %45 = add nsw i32 %44, -1
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds i16, i16* %4, i64 %46
  %48 = load i16, i16* %47, align 2
  %49 = zext i16 %48 to i32
  %50 = add nuw nsw i32 %31, 1
  %51 = add nuw nsw i32 %50, %12
  %52 = lshr i32 %51, 1
  %53 = trunc i32 %52 to i16
  %54 = add i64 %7, 8589934592
  %55 = ashr exact i64 %54, 32
  %56 = getelementptr inbounds i16, i16* %4, i64 %55
  store i16 %53, i16* %56, align 2
  store i16 %53, i16* %4, align 2
  %57 = shl nuw nsw i32 %12, 1
  %58 = add nuw nsw i32 %17, 2
  %59 = add nuw nsw i32 %58, %57
  %60 = add nuw nsw i32 %59, %31
  %61 = lshr i32 %60, 2
  %62 = trunc i32 %61 to i16
  %63 = add i64 %7, 12884901888
  %64 = ashr exact i64 %63, 32
  %65 = getelementptr inbounds i16, i16* %4, i64 %64
  store i16 %62, i16* %65, align 2
  %66 = getelementptr inbounds i8, i8* %0, i64 2
  %67 = bitcast i8* %66 to i16*
  store i16 %62, i16* %67, align 2
  %68 = shl nuw nsw i32 %17, 1
  %69 = add nuw nsw i32 %12, 2
  %70 = add nuw nsw i32 %69, %68
  %71 = add nuw nsw i32 %70, %22
  %72 = lshr i32 %71, 2
  %73 = trunc i32 %72 to i16
  %74 = getelementptr inbounds i8, i8* %0, i64 4
  %75 = bitcast i8* %74 to i16*
  store i16 %73, i16* %75, align 2
  %76 = shl nuw nsw i32 %22, 1
  %77 = add nuw nsw i32 %58, %76
  %78 = add nuw nsw i32 %77, %27
  %79 = lshr i32 %78, 2
  %80 = trunc i32 %79 to i16
  %81 = getelementptr inbounds i8, i8* %0, i64 6
  %82 = bitcast i8* %81 to i16*
  store i16 %80, i16* %82, align 2
  %83 = add nuw nsw i32 %50, %36
  %84 = lshr i32 %83, 1
  %85 = trunc i32 %84 to i16
  %86 = add nsw i32 %38, 2
  %87 = sext i32 %86 to i64
  %88 = getelementptr inbounds i16, i16* %4, i64 %87
  store i16 %85, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %4, i64 %8
  store i16 %85, i16* %89, align 2
  %90 = shl nuw nsw i32 %31, 1
  %91 = add nuw nsw i32 %69, %90
  %92 = add nuw nsw i32 %91, %36
  %93 = lshr i32 %92, 2
  %94 = trunc i32 %93 to i16
  %95 = add nsw i32 %38, 3
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %4, i64 %96
  store i16 %94, i16* %97, align 2
  %98 = add i64 %7, 4294967296
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i16, i16* %4, i64 %99
  store i16 %94, i16* %100, align 2
  %101 = add nuw nsw i32 %36, 1
  %102 = add nuw nsw i32 %101, %43
  %103 = lshr i32 %102, 1
  %104 = trunc i32 %103 to i16
  %105 = add nsw i32 %44, 2
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i16, i16* %4, i64 %106
  store i16 %104, i16* %107, align 2
  %108 = sext i32 %38 to i64
  %109 = getelementptr inbounds i16, i16* %4, i64 %108
  store i16 %104, i16* %109, align 2
  %110 = shl nuw nsw i32 %36, 1
  %111 = add nuw nsw i32 %31, 2
  %112 = add nuw nsw i32 %111, %110
  %113 = add nuw nsw i32 %112, %43
  %114 = lshr i32 %113, 2
  %115 = trunc i32 %114 to i16
  %116 = add nsw i32 %44, 3
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds i16, i16* %4, i64 %117
  store i16 %115, i16* %118, align 2
  %119 = shl i64 %2, 32
  %120 = ashr exact i64 %119, 32
  %121 = or i64 %120, 1
  %122 = getelementptr inbounds i16, i16* %4, i64 %121
  store i16 %115, i16* %122, align 2
  %123 = add nuw nsw i32 %43, 1
  %124 = add nuw nsw i32 %123, %49
  %125 = lshr i32 %124, 1
  %126 = trunc i32 %125 to i16
  %127 = sext i32 %44 to i64
  %128 = getelementptr inbounds i16, i16* %4, i64 %127
  store i16 %126, i16* %128, align 2
  %129 = shl nuw nsw i32 %43, 1
  %130 = add nuw nsw i32 %36, 2
  %131 = add nuw nsw i32 %130, %129
  %132 = add nuw nsw i32 %131, %49
  %133 = lshr i32 %132, 2
  %134 = trunc i32 %133 to i16
  %135 = add nsw i32 %44, 1
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds i16, i16* %4, i64 %136
  store i16 %134, i16* %137, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_left_14_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i8* %1 to i16*
  %6 = lshr i64 %2, 1
  %7 = trunc i64 %6 to i32
  %8 = shl i64 %6, 32
  %9 = sub i64 0, %8
  %10 = ashr exact i64 %9, 32
  %11 = getelementptr inbounds i16, i16* %4, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i32
  %14 = sub i64 4294967296, %8
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i16, i16* %4, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i32
  %19 = sub i64 8589934592, %8
  %20 = ashr exact i64 %19, 32
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = sub i64 12884901888, %8
  %25 = ashr exact i64 %24, 32
  %26 = getelementptr inbounds i16, i16* %4, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %5, align 2
  %30 = zext i16 %29 to i32
  %31 = getelementptr inbounds i8, i8* %1, i64 2
  %32 = bitcast i8* %31 to i16*
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = getelementptr inbounds i8, i8* %1, i64 4
  %36 = bitcast i8* %35 to i16*
  %37 = load i16, i16* %36, align 2
  %38 = zext i16 %37 to i32
  %39 = add nuw nsw i32 %18, 1
  %40 = add nuw nsw i32 %39, %13
  %41 = lshr i32 %40, 1
  %42 = trunc i32 %41 to i16
  store i16 %42, i16* %4, align 2
  %43 = add nuw nsw i32 %39, %23
  %44 = lshr i32 %43, 1
  %45 = trunc i32 %44 to i16
  %46 = trunc i64 %2 to i32
  %47 = and i32 %46, -2
  %48 = sext i32 %47 to i64
  %49 = getelementptr inbounds i16, i16* %4, i64 %48
  store i16 %45, i16* %49, align 2
  %50 = getelementptr inbounds i8, i8* %0, i64 2
  %51 = bitcast i8* %50 to i16*
  store i16 %45, i16* %51, align 2
  %52 = add nuw nsw i32 %23, 1
  %53 = add nuw nsw i32 %52, %28
  %54 = lshr i32 %53, 1
  %55 = trunc i32 %54 to i16
  %56 = shl i64 %2, 32
  %57 = ashr exact i64 %56, 32
  %58 = or i64 %57, 1
  %59 = getelementptr inbounds i16, i16* %4, i64 %58
  store i16 %55, i16* %59, align 2
  %60 = getelementptr inbounds i8, i8* %0, i64 4
  %61 = bitcast i8* %60 to i16*
  store i16 %55, i16* %61, align 2
  %62 = add nuw nsw i32 %28, 1
  %63 = add nuw nsw i32 %62, %30
  %64 = lshr i32 %63, 1
  %65 = trunc i32 %64 to i16
  %66 = add nsw i32 %47, 2
  %67 = sext i32 %66 to i64
  %68 = getelementptr inbounds i16, i16* %4, i64 %67
  store i16 %65, i16* %68, align 2
  %69 = getelementptr inbounds i8, i8* %0, i64 6
  %70 = bitcast i8* %69 to i16*
  store i16 %65, i16* %70, align 2
  %71 = add nuw nsw i32 %30, 1
  %72 = add nuw nsw i32 %71, %34
  %73 = lshr i32 %72, 1
  %74 = trunc i32 %73 to i16
  %75 = add nsw i32 %47, 3
  %76 = sext i32 %75 to i64
  %77 = getelementptr inbounds i16, i16* %4, i64 %76
  store i16 %74, i16* %77, align 2
  %78 = shl nuw nsw i32 %18, 1
  %79 = add nuw nsw i32 %23, 2
  %80 = add nuw nsw i32 %79, %13
  %81 = add nuw nsw i32 %80, %78
  %82 = lshr i32 %81, 2
  %83 = trunc i32 %82 to i16
  %84 = ashr exact i64 %8, 32
  %85 = getelementptr inbounds i16, i16* %4, i64 %84
  store i16 %83, i16* %85, align 2
  %86 = shl nuw nsw i32 %23, 1
  %87 = add nuw nsw i32 %28, 2
  %88 = add nuw nsw i32 %87, %18
  %89 = add nuw nsw i32 %88, %86
  %90 = lshr i32 %89, 2
  %91 = trunc i32 %90 to i16
  %92 = mul nsw i32 %7, 3
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds i16, i16* %4, i64 %93
  store i16 %91, i16* %94, align 2
  %95 = add i64 %8, 4294967296
  %96 = ashr exact i64 %95, 32
  %97 = getelementptr inbounds i16, i16* %4, i64 %96
  store i16 %91, i16* %97, align 2
  %98 = shl nuw nsw i32 %28, 1
  %99 = add nuw nsw i32 %79, %98
  %100 = add nuw nsw i32 %99, %30
  %101 = lshr i32 %100, 2
  %102 = trunc i32 %101 to i16
  %103 = add nsw i32 %92, 1
  %104 = sext i32 %103 to i64
  %105 = getelementptr inbounds i16, i16* %4, i64 %104
  store i16 %102, i16* %105, align 2
  %106 = add i64 %8, 8589934592
  %107 = ashr exact i64 %106, 32
  %108 = getelementptr inbounds i16, i16* %4, i64 %107
  store i16 %102, i16* %108, align 2
  %109 = shl nuw nsw i32 %30, 1
  %110 = add nuw nsw i32 %87, %109
  %111 = add nuw nsw i32 %110, %34
  %112 = lshr i32 %111, 2
  %113 = trunc i32 %112 to i16
  %114 = add nsw i32 %92, 2
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds i16, i16* %4, i64 %115
  store i16 %113, i16* %116, align 2
  %117 = add i64 %8, 12884901888
  %118 = ashr exact i64 %117, 32
  %119 = getelementptr inbounds i16, i16* %4, i64 %118
  store i16 %113, i16* %119, align 2
  %120 = shl nuw nsw i32 %34, 1
  %121 = add nuw nsw i32 %30, 2
  %122 = add nuw nsw i32 %121, %120
  %123 = add nuw nsw i32 %122, %38
  %124 = lshr i32 %123, 2
  %125 = trunc i32 %124 to i16
  %126 = add nsw i32 %92, 3
  %127 = sext i32 %126 to i64
  %128 = getelementptr inbounds i16, i16* %4, i64 %127
  store i16 %125, i16* %128, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_up_14_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i32
  %11 = shl i64 %5, 32
  %12 = add i64 %11, -4294967296
  %13 = ashr exact i64 %12, 32
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i32
  %17 = trunc i64 %2 to i32
  %18 = and i32 %17, -2
  %19 = add nsw i32 %18, -1
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = mul nsw i32 %6, 3
  %25 = add nsw i32 %24, -1
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds i16, i16* %4, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i32
  %30 = add nuw nsw i32 %16, 1
  %31 = add nuw nsw i32 %30, %10
  %32 = lshr i32 %31, 1
  %33 = trunc i32 %32 to i16
  store i16 %33, i16* %4, align 2
  %34 = shl nuw nsw i32 %16, 1
  %35 = add nuw nsw i32 %23, 2
  %36 = add nuw nsw i32 %35, %10
  %37 = add nuw nsw i32 %36, %34
  %38 = lshr i32 %37, 2
  %39 = trunc i32 %38 to i16
  %40 = getelementptr inbounds i8, i8* %0, i64 2
  %41 = bitcast i8* %40 to i16*
  store i16 %39, i16* %41, align 2
  %42 = add nuw nsw i32 %30, %23
  %43 = lshr i32 %42, 1
  %44 = trunc i32 %43 to i16
  %45 = ashr exact i64 %11, 32
  %46 = getelementptr inbounds i16, i16* %4, i64 %45
  store i16 %44, i16* %46, align 2
  %47 = getelementptr inbounds i8, i8* %0, i64 4
  %48 = bitcast i8* %47 to i16*
  store i16 %44, i16* %48, align 2
  %49 = shl nuw nsw i32 %23, 1
  %50 = add nuw nsw i32 %29, 2
  %51 = add nuw nsw i32 %50, %16
  %52 = add nuw nsw i32 %51, %49
  %53 = lshr i32 %52, 2
  %54 = trunc i32 %53 to i16
  %55 = add i64 %11, 4294967296
  %56 = ashr exact i64 %55, 32
  %57 = getelementptr inbounds i16, i16* %4, i64 %56
  store i16 %54, i16* %57, align 2
  %58 = getelementptr inbounds i8, i8* %0, i64 6
  %59 = bitcast i8* %58 to i16*
  store i16 %54, i16* %59, align 2
  %60 = add nuw nsw i32 %23, 1
  %61 = add nuw nsw i32 %60, %29
  %62 = lshr i32 %61, 1
  %63 = trunc i32 %62 to i16
  %64 = sext i32 %18 to i64
  %65 = getelementptr inbounds i16, i16* %4, i64 %64
  store i16 %63, i16* %65, align 2
  %66 = add i64 %11, 8589934592
  %67 = ashr exact i64 %66, 32
  %68 = getelementptr inbounds i16, i16* %4, i64 %67
  store i16 %63, i16* %68, align 2
  %69 = shl nuw nsw i32 %29, 1
  %70 = add nuw nsw i32 %35, %29
  %71 = add nuw nsw i32 %70, %69
  %72 = lshr i32 %71, 2
  %73 = trunc i32 %72 to i16
  %74 = shl i64 %2, 32
  %75 = ashr exact i64 %74, 32
  %76 = or i64 %75, 1
  %77 = getelementptr inbounds i16, i16* %4, i64 %76
  store i16 %73, i16* %77, align 2
  %78 = add i64 %11, 12884901888
  %79 = ashr exact i64 %78, 32
  %80 = getelementptr inbounds i16, i16* %4, i64 %79
  store i16 %73, i16* %80, align 2
  %81 = add nsw i32 %24, 3
  %82 = sext i32 %81 to i64
  %83 = getelementptr inbounds i16, i16* %4, i64 %82
  store i16 %28, i16* %83, align 2
  %84 = add nsw i32 %24, 2
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i16, i16* %4, i64 %85
  store i16 %28, i16* %86, align 2
  %87 = add nsw i32 %18, 2
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds i16, i16* %4, i64 %88
  store i16 %28, i16* %89, align 2
  %90 = sext i32 %24 to i64
  %91 = getelementptr inbounds i16, i16* %4, i64 %90
  store i16 %28, i16* %91, align 2
  %92 = add nsw i32 %24, 1
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds i16, i16* %4, i64 %93
  store i16 %28, i16* %94, align 2
  %95 = add nsw i32 %18, 3
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %4, i64 %96
  store i16 %28, i16* %97, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_left_dc_14_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = trunc i64 %5 to i32
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = shl i64 %5, 32
  %12 = add i64 %11, -4294967296
  %13 = ashr exact i64 %12, 32
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = trunc i64 %2 to i32
  %18 = and i32 %17, -2
  %19 = add nsw i32 %18, -1
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds i16, i16* %4, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i64
  %24 = mul nsw i32 %6, 3
  %25 = add nsw i32 %24, -1
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds i16, i16* %4, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i64
  %30 = add nuw nsw i64 %10, 2
  %31 = add nuw nsw i64 %30, %16
  %32 = add nuw nsw i64 %31, %23
  %33 = add nuw nsw i64 %32, %29
  %34 = lshr i64 %33, 2
  %35 = mul i64 %34, 281479271743489
  %36 = bitcast i8* %0 to i64*
  store i64 %35, i64* %36, align 8
  %37 = ashr exact i64 %11, 32
  %38 = getelementptr inbounds i16, i16* %4, i64 %37
  %39 = bitcast i16* %38 to i64*
  store i64 %35, i64* %39, align 8
  %40 = sext i32 %18 to i64
  %41 = getelementptr inbounds i16, i16* %4, i64 %40
  %42 = bitcast i16* %41 to i64*
  store i64 %35, i64* %42, align 8
  %43 = sext i32 %24 to i64
  %44 = getelementptr inbounds i16, i16* %4, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %35, i64* %45, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_top_dc_14_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = shl i64 %5, 32
  %7 = sub i64 0, %6
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = load i16, i16* %9, align 2
  %11 = zext i16 %10 to i64
  %12 = sub i64 4294967296, %6
  %13 = ashr exact i64 %12, 32
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = sub i64 8589934592, %6
  %18 = ashr exact i64 %17, 32
  %19 = getelementptr inbounds i16, i16* %4, i64 %18
  %20 = load i16, i16* %19, align 2
  %21 = zext i16 %20 to i64
  %22 = sub i64 12884901888, %6
  %23 = ashr exact i64 %22, 32
  %24 = getelementptr inbounds i16, i16* %4, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = add nuw nsw i64 %11, 2
  %28 = add nuw nsw i64 %27, %16
  %29 = add nuw nsw i64 %28, %21
  %30 = add nuw nsw i64 %29, %26
  %31 = lshr i64 %30, 2
  %32 = mul i64 %31, 281479271743489
  %33 = bitcast i8* %0 to i64*
  store i64 %32, i64* %33, align 8
  %34 = ashr exact i64 %6, 32
  %35 = getelementptr inbounds i16, i16* %4, i64 %34
  %36 = bitcast i16* %35 to i64*
  store i64 %32, i64* %36, align 8
  %37 = shl i64 %2, 32
  %38 = ashr exact i64 %37, 32
  %39 = and i64 %38, -2
  %40 = getelementptr inbounds i16, i16* %4, i64 %39
  %41 = bitcast i16* %40 to i64*
  store i64 %32, i64* %41, align 8
  %42 = mul i64 %5, 12884901888
  %43 = ashr exact i64 %42, 32
  %44 = getelementptr inbounds i16, i16* %4, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %32, i64* %45, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_127_dc_14_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = bitcast i8* %0 to i64*
  store i64 2305596714850918399, i64* %6, align 8
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  store i64 2305596714850918399, i64* %10, align 8
  %11 = shl i64 %2, 32
  %12 = ashr exact i64 %11, 32
  %13 = and i64 %12, -2
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = bitcast i16* %14 to i64*
  store i64 2305596714850918399, i64* %15, align 8
  %16 = mul i64 %5, 12884901888
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 2305596714850918399, i64* %19, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_129_dc_14_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = bitcast i8* %0 to i64*
  store i64 2306159673394405377, i64* %6, align 8
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  store i64 2306159673394405377, i64* %10, align 8
  %11 = shl i64 %2, 32
  %12 = ashr exact i64 %11, 32
  %13 = and i64 %12, -2
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = bitcast i16* %14 to i64*
  store i64 2306159673394405377, i64* %15, align 8
  %16 = mul i64 %5, 12884901888
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 2306159673394405377, i64* %19, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_128_dc_14_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = bitcast i8* %0 to i16*
  %5 = lshr i64 %2, 1
  %6 = bitcast i8* %0 to i64*
  store i64 2305878194122661888, i64* %6, align 8
  %7 = shl i64 %5, 32
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i16, i16* %4, i64 %8
  %10 = bitcast i16* %9 to i64*
  store i64 2305878194122661888, i64* %10, align 8
  %11 = shl i64 %2, 32
  %12 = ashr exact i64 %11, 32
  %13 = and i64 %12, -2
  %14 = getelementptr inbounds i16, i16* %4, i64 %13
  %15 = bitcast i16* %14 to i64*
  store i64 2305878194122661888, i64* %15, align 8
  %16 = mul i64 %5, 12884901888
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %4, i64 %17
  %19 = bitcast i16* %18 to i64*
  store i64 2305878194122661888, i64* %19, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_14_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %103, label %97

97:                                               ; preds = %18
  %98 = sub i64 34359738368, %19
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i16, i16* %5, i64 %99
  %101 = load i16, i16* %100, align 2
  %102 = zext i16 %101 to i32
  br label %103

103:                                              ; preds = %18, %97
  %104 = phi i32 [ %102, %97 ], [ %91, %18 ]
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %81, 2
  %107 = add nuw nsw i32 %106, %105
  %108 = add nuw nsw i32 %107, %104
  %109 = lshr i32 %108, 2
  %110 = trunc i32 %37 to i16
  store i16 %110, i16* %5, align 2
  %111 = trunc i32 %47 to i16
  %112 = getelementptr inbounds i8, i8* %0, i64 2
  %113 = bitcast i8* %112 to i16*
  store i16 %111, i16* %113, align 2
  %114 = trunc i32 %56 to i16
  %115 = getelementptr inbounds i8, i8* %0, i64 4
  %116 = bitcast i8* %115 to i16*
  store i16 %114, i16* %116, align 2
  %117 = trunc i32 %65 to i16
  %118 = getelementptr inbounds i8, i8* %0, i64 6
  %119 = bitcast i8* %118 to i16*
  store i16 %117, i16* %119, align 2
  %120 = trunc i32 %75 to i16
  %121 = getelementptr inbounds i8, i8* %0, i64 8
  %122 = bitcast i8* %121 to i16*
  store i16 %120, i16* %122, align 2
  %123 = trunc i32 %85 to i16
  %124 = getelementptr inbounds i8, i8* %0, i64 10
  %125 = bitcast i8* %124 to i16*
  store i16 %123, i16* %125, align 2
  %126 = trunc i32 %95 to i16
  %127 = getelementptr inbounds i8, i8* %0, i64 12
  %128 = bitcast i8* %127 to i16*
  store i16 %126, i16* %128, align 2
  %129 = trunc i32 %109 to i16
  %130 = getelementptr inbounds i8, i8* %0, i64 14
  %131 = bitcast i8* %130 to i16*
  store i16 %129, i16* %131, align 2
  %132 = bitcast i8* %0 to i64*
  %133 = load i64, i64* %132, align 8
  %134 = bitcast i8* %121 to i64*
  %135 = load i64, i64* %134, align 8
  %136 = shl i64 %6, 32
  %137 = ashr exact i64 %136, 32
  %138 = getelementptr inbounds i16, i16* %5, i64 %137
  %139 = bitcast i16* %138 to i64*
  store i64 %133, i64* %139, align 8
  %140 = getelementptr inbounds i16, i16* %138, i64 4
  %141 = bitcast i16* %140 to i64*
  store i64 %135, i64* %141, align 8
  %142 = ashr exact i64 %136, 31
  %143 = getelementptr inbounds i16, i16* %5, i64 %142
  %144 = bitcast i16* %143 to i64*
  store i64 %133, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %143, i64 4
  %146 = bitcast i16* %145 to i64*
  store i64 %135, i64* %146, align 8
  %147 = mul nsw i64 %137, 3
  %148 = getelementptr inbounds i16, i16* %5, i64 %147
  %149 = bitcast i16* %148 to i64*
  store i64 %133, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %148, i64 4
  %151 = bitcast i16* %150 to i64*
  store i64 %135, i64* %151, align 8
  %152 = ashr exact i64 %136, 30
  %153 = getelementptr inbounds i16, i16* %5, i64 %152
  %154 = bitcast i16* %153 to i64*
  store i64 %133, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %153, i64 4
  %156 = bitcast i16* %155 to i64*
  store i64 %135, i64* %156, align 8
  %157 = mul nsw i64 %137, 5
  %158 = getelementptr inbounds i16, i16* %5, i64 %157
  %159 = bitcast i16* %158 to i64*
  store i64 %133, i64* %159, align 8
  %160 = getelementptr inbounds i16, i16* %158, i64 4
  %161 = bitcast i16* %160 to i64*
  store i64 %135, i64* %161, align 8
  %162 = mul nsw i64 %137, 6
  %163 = getelementptr inbounds i16, i16* %5, i64 %162
  %164 = bitcast i16* %163 to i64*
  store i64 %133, i64* %164, align 8
  %165 = getelementptr inbounds i16, i16* %163, i64 4
  %166 = bitcast i16* %165 to i64*
  store i64 %135, i64* %166, align 8
  %167 = mul nsw i64 %137, 7
  %168 = getelementptr inbounds i16, i16* %5, i64 %167
  %169 = bitcast i16* %168 to i64*
  store i64 %133, i64* %169, align 8
  %170 = getelementptr inbounds i16, i16* %168, i64 4
  %171 = bitcast i16* %170 to i64*
  store i64 %135, i64* %171, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_14_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  br i1 %8, label %14, label %9

9:                                                ; preds = %4
  %10 = shl i64 %6, 32
  %11 = ashr exact i64 %10, 32
  %12 = xor i64 %11, -1
  %13 = getelementptr inbounds i16, i16* %5, i64 %12
  br label %19

14:                                               ; preds = %4
  %15 = getelementptr inbounds i8, i8* %0, i64 -2
  %16 = bitcast i8* %15 to i16*
  %17 = shl i64 %6, 32
  %18 = ashr exact i64 %17, 32
  br label %19

19:                                               ; preds = %14, %9
  %20 = phi i64 [ %18, %14 ], [ %11, %9 ]
  %21 = phi i64 [ %17, %14 ], [ %10, %9 ]
  %22 = phi i16* [ %16, %14 ], [ %13, %9 ]
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i8, i8* %0, i64 -2
  %26 = bitcast i8* %25 to i16*
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = shl nuw nsw i32 %28, 1
  %30 = add i64 %21, -4294967296
  %31 = ashr exact i64 %30, 32
  %32 = getelementptr inbounds i16, i16* %5, i64 %31
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = add nuw nsw i32 %34, 2
  %36 = add nuw nsw i32 %35, %24
  %37 = add nuw nsw i32 %36, %29
  %38 = lshr i32 %37, 2
  %39 = shl nuw nsw i32 %34, 1
  %40 = trunc i64 %3 to i32
  %41 = and i32 %40, -2
  %42 = add nsw i32 %41, -1
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i16, i16* %5, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %28
  %49 = add nuw nsw i32 %48, %39
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = mul nsw i32 %7, 3
  %53 = add nsw i32 %52, -1
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i16, i16* %5, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i32
  %58 = add nuw nsw i32 %35, %51
  %59 = add nuw nsw i32 %58, %57
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %57, 1
  %62 = shl i64 %6, 34
  %63 = add i64 %62, -4294967296
  %64 = ashr exact i64 %63, 32
  %65 = getelementptr inbounds i16, i16* %5, i64 %64
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = add nuw nsw i32 %47, %61
  %69 = add nuw nsw i32 %68, %67
  %70 = lshr i32 %69, 2
  %71 = shl nuw nsw i32 %67, 1
  %72 = mul nsw i32 %7, 5
  %73 = add nsw i32 %72, -1
  %74 = sext i32 %73 to i64
  %75 = getelementptr inbounds i16, i16* %5, i64 %74
  %76 = load i16, i16* %75, align 2
  %77 = zext i16 %76 to i32
  %78 = add nuw nsw i32 %57, 2
  %79 = add nuw nsw i32 %78, %71
  %80 = add nuw nsw i32 %79, %77
  %81 = lshr i32 %80, 2
  %82 = shl nuw nsw i32 %77, 1
  %83 = mul nsw i32 %7, 6
  %84 = add nsw i32 %83, -1
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i16, i16* %5, i64 %85
  %87 = load i16, i16* %86, align 2
  %88 = zext i16 %87 to i32
  %89 = add nuw nsw i32 %67, 2
  %90 = add nuw nsw i32 %89, %82
  %91 = add nuw nsw i32 %90, %88
  %92 = lshr i32 %91, 2
  %93 = shl nuw nsw i32 %88, 1
  %94 = mul nsw i32 %7, 7
  %95 = add nsw i32 %94, -1
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %5, i64 %96
  %98 = load i16, i16* %97, align 2
  %99 = zext i16 %98 to i32
  %100 = add nuw nsw i32 %77, 2
  %101 = add nuw nsw i32 %100, %93
  %102 = add nuw nsw i32 %101, %99
  %103 = lshr i32 %102, 2
  %104 = mul nuw nsw i32 %99, 3
  %105 = add nuw nsw i32 %88, 2
  %106 = add nuw nsw i32 %105, %104
  %107 = lshr i32 %106, 2
  %108 = zext i32 %38 to i64
  %109 = mul i64 %108, 281479271743489
  %110 = bitcast i8* %0 to i64*
  store i64 %109, i64* %110, align 8
  %111 = getelementptr inbounds i8, i8* %0, i64 8
  %112 = bitcast i8* %111 to i64*
  store i64 %109, i64* %112, align 8
  %113 = zext i32 %50 to i64
  %114 = mul i64 %113, 281479271743489
  %115 = getelementptr inbounds i16, i16* %5, i64 %20
  %116 = bitcast i16* %115 to i64*
  store i64 %114, i64* %116, align 8
  %117 = getelementptr inbounds i16, i16* %115, i64 4
  %118 = bitcast i16* %117 to i64*
  store i64 %114, i64* %118, align 8
  %119 = zext i32 %60 to i64
  %120 = mul i64 %119, 281479271743489
  %121 = sext i32 %41 to i64
  %122 = getelementptr inbounds i16, i16* %5, i64 %121
  %123 = bitcast i16* %122 to i64*
  store i64 %120, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %122, i64 4
  %125 = bitcast i16* %124 to i64*
  store i64 %120, i64* %125, align 8
  %126 = zext i32 %70 to i64
  %127 = mul i64 %126, 281479271743489
  %128 = sext i32 %52 to i64
  %129 = getelementptr inbounds i16, i16* %5, i64 %128
  %130 = bitcast i16* %129 to i64*
  store i64 %127, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %129, i64 4
  %132 = bitcast i16* %131 to i64*
  store i64 %127, i64* %132, align 8
  %133 = zext i32 %81 to i64
  %134 = mul i64 %133, 281479271743489
  %135 = ashr exact i64 %62, 32
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  %137 = bitcast i16* %136 to i64*
  store i64 %134, i64* %137, align 8
  %138 = getelementptr inbounds i16, i16* %136, i64 4
  %139 = bitcast i16* %138 to i64*
  store i64 %134, i64* %139, align 8
  %140 = zext i32 %92 to i64
  %141 = mul i64 %140, 281479271743489
  %142 = sext i32 %72 to i64
  %143 = getelementptr inbounds i16, i16* %5, i64 %142
  %144 = bitcast i16* %143 to i64*
  store i64 %141, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %143, i64 4
  %146 = bitcast i16* %145 to i64*
  store i64 %141, i64* %146, align 8
  %147 = zext i32 %103 to i64
  %148 = mul i64 %147, 281479271743489
  %149 = sext i32 %83 to i64
  %150 = getelementptr inbounds i16, i16* %5, i64 %149
  %151 = bitcast i16* %150 to i64*
  store i64 %148, i64* %151, align 8
  %152 = getelementptr inbounds i16, i16* %150, i64 4
  %153 = bitcast i16* %152 to i64*
  store i64 %148, i64* %153, align 8
  %154 = zext i32 %107 to i64
  %155 = mul i64 %154, 281479271743489
  %156 = sext i32 %94 to i64
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  %158 = bitcast i16* %157 to i64*
  store i64 %155, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %157, i64 4
  %160 = bitcast i16* %159 to i64*
  store i64 %155, i64* %160, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_dc_14_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = icmp ne i32 %1, 0
  br i1 %7, label %8, label %13

8:                                                ; preds = %4
  %9 = shl i64 %6, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = getelementptr inbounds i16, i16* %5, i64 %11
  br label %19

13:                                               ; preds = %4
  %14 = getelementptr inbounds i8, i8* %0, i64 -2
  %15 = bitcast i8* %14 to i16*
  %16 = shl i64 %6, 32
  %17 = ashr exact i64 %16, 32
  %18 = xor i64 %17, -1
  br label %19

19:                                               ; preds = %13, %8
  %20 = phi i64 [ %18, %13 ], [ %11, %8 ]
  %21 = phi i64 [ %17, %13 ], [ %10, %8 ]
  %22 = phi i64 [ %16, %13 ], [ %9, %8 ]
  %23 = phi i16* [ %15, %13 ], [ %12, %8 ]
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = getelementptr inbounds i8, i8* %0, i64 -2
  %27 = bitcast i8* %26 to i16*
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i32
  %30 = shl nuw nsw i32 %29, 1
  %31 = add i64 %22, -4294967296
  %32 = ashr exact i64 %31, 32
  %33 = getelementptr inbounds i16, i16* %5, i64 %32
  %34 = load i16, i16* %33, align 2
  %35 = zext i16 %34 to i32
  %36 = add nuw nsw i32 %35, 2
  %37 = add nuw nsw i32 %36, %25
  %38 = add nuw nsw i32 %37, %30
  %39 = lshr i32 %38, 2
  %40 = shl nuw nsw i32 %35, 1
  %41 = shl i64 %3, 32
  %42 = and i64 %41, -8589934592
  %43 = add i64 %42, -4294967296
  %44 = ashr exact i64 %43, 32
  %45 = getelementptr inbounds i16, i16* %5, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i32
  %48 = add nuw nsw i32 %47, 2
  %49 = add nuw nsw i32 %48, %29
  %50 = add nuw nsw i32 %49, %40
  %51 = lshr i32 %50, 2
  %52 = shl nuw nsw i32 %47, 1
  %53 = mul i64 %6, 12884901888
  %54 = add i64 %53, -4294967296
  %55 = ashr exact i64 %54, 32
  %56 = getelementptr inbounds i16, i16* %5, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %36, %52
  %60 = add nuw nsw i32 %59, %58
  %61 = lshr i32 %60, 2
  %62 = shl nuw nsw i32 %58, 1
  %63 = shl i64 %6, 34
  %64 = add i64 %63, -4294967296
  %65 = ashr exact i64 %64, 32
  %66 = getelementptr inbounds i16, i16* %5, i64 %65
  %67 = load i16, i16* %66, align 2
  %68 = zext i16 %67 to i32
  %69 = add nuw nsw i32 %48, %62
  %70 = add nuw nsw i32 %69, %68
  %71 = lshr i32 %70, 2
  %72 = shl nuw nsw i32 %68, 1
  %73 = mul i64 %6, 21474836480
  %74 = add i64 %73, -4294967296
  %75 = ashr exact i64 %74, 32
  %76 = getelementptr inbounds i16, i16* %5, i64 %75
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i32
  %79 = add nuw nsw i32 %58, 2
  %80 = add nuw nsw i32 %79, %72
  %81 = add nuw nsw i32 %80, %78
  %82 = lshr i32 %81, 2
  %83 = shl nuw nsw i32 %78, 1
  %84 = mul i64 %6, 25769803776
  %85 = add i64 %84, -4294967296
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i16, i16* %5, i64 %86
  %88 = load i16, i16* %87, align 2
  %89 = zext i16 %88 to i32
  %90 = add nuw nsw i32 %68, 2
  %91 = add nuw nsw i32 %90, %83
  %92 = add nuw nsw i32 %91, %89
  %93 = lshr i32 %92, 2
  %94 = shl nuw nsw i32 %89, 1
  %95 = mul i64 %6, 30064771072
  %96 = add i64 %95, -4294967296
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i16, i16* %5, i64 %97
  %99 = load i16, i16* %98, align 2
  %100 = zext i16 %99 to i32
  %101 = add nuw nsw i32 %78, 2
  %102 = add nuw nsw i32 %101, %94
  %103 = add nuw nsw i32 %102, %100
  %104 = lshr i32 %103, 2
  %105 = mul nuw nsw i32 %100, 3
  %106 = add nuw nsw i32 %89, 2
  %107 = add nuw nsw i32 %106, %105
  %108 = lshr i32 %107, 2
  %109 = shl i64 %6, 32
  %110 = sub i64 0, %109
  %111 = ashr exact i64 %110, 32
  %112 = select i1 %7, i64 %20, i64 %111
  %113 = getelementptr inbounds i16, i16* %5, i64 %112
  %114 = load i16, i16* %113, align 2
  %115 = zext i16 %114 to i32
  %116 = getelementptr inbounds i16, i16* %5, i64 %111
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = shl nuw nsw i32 %118, 1
  %120 = sub i64 4294967296, %22
  %121 = ashr exact i64 %120, 32
  %122 = getelementptr inbounds i16, i16* %5, i64 %121
  %123 = load i16, i16* %122, align 2
  %124 = zext i16 %123 to i32
  %125 = add nuw nsw i32 %124, 2
  %126 = add nuw nsw i32 %125, %115
  %127 = add nuw nsw i32 %126, %119
  %128 = lshr i32 %127, 2
  %129 = shl nuw nsw i32 %124, 1
  %130 = sub i64 8589934592, %22
  %131 = ashr exact i64 %130, 32
  %132 = getelementptr inbounds i16, i16* %5, i64 %131
  %133 = load i16, i16* %132, align 2
  %134 = zext i16 %133 to i32
  %135 = add nuw nsw i32 %134, 2
  %136 = add nuw nsw i32 %135, %118
  %137 = add nuw nsw i32 %136, %129
  %138 = lshr i32 %137, 2
  %139 = shl nuw nsw i32 %134, 1
  %140 = sub i64 12884901888, %22
  %141 = ashr exact i64 %140, 32
  %142 = getelementptr inbounds i16, i16* %5, i64 %141
  %143 = load i16, i16* %142, align 2
  %144 = zext i16 %143 to i32
  %145 = add nuw nsw i32 %125, %139
  %146 = add nuw nsw i32 %145, %144
  %147 = lshr i32 %146, 2
  %148 = shl nuw nsw i32 %144, 1
  %149 = sub i64 17179869184, %22
  %150 = ashr exact i64 %149, 32
  %151 = getelementptr inbounds i16, i16* %5, i64 %150
  %152 = load i16, i16* %151, align 2
  %153 = zext i16 %152 to i32
  %154 = add nuw nsw i32 %135, %148
  %155 = add nuw nsw i32 %154, %153
  %156 = lshr i32 %155, 2
  %157 = shl nuw nsw i32 %153, 1
  %158 = sub i64 21474836480, %22
  %159 = ashr exact i64 %158, 32
  %160 = getelementptr inbounds i16, i16* %5, i64 %159
  %161 = load i16, i16* %160, align 2
  %162 = zext i16 %161 to i32
  %163 = add nuw nsw i32 %144, 2
  %164 = add nuw nsw i32 %163, %157
  %165 = add nuw nsw i32 %164, %162
  %166 = lshr i32 %165, 2
  %167 = shl nuw nsw i32 %162, 1
  %168 = sub i64 25769803776, %22
  %169 = ashr exact i64 %168, 32
  %170 = getelementptr inbounds i16, i16* %5, i64 %169
  %171 = load i16, i16* %170, align 2
  %172 = zext i16 %171 to i32
  %173 = add nuw nsw i32 %153, 2
  %174 = add nuw nsw i32 %173, %167
  %175 = add nuw nsw i32 %174, %172
  %176 = lshr i32 %175, 2
  %177 = shl nuw nsw i32 %172, 1
  %178 = sub i64 30064771072, %22
  %179 = ashr exact i64 %178, 32
  %180 = getelementptr inbounds i16, i16* %5, i64 %179
  %181 = load i16, i16* %180, align 2
  %182 = zext i16 %181 to i32
  %183 = add nuw nsw i32 %162, 2
  %184 = add nuw nsw i32 %183, %177
  %185 = add nuw nsw i32 %184, %182
  %186 = lshr i32 %185, 2
  %187 = icmp eq i32 %2, 0
  br i1 %187, label %194, label %188

188:                                              ; preds = %19
  %189 = sub i64 34359738368, %22
  %190 = ashr exact i64 %189, 32
  %191 = getelementptr inbounds i16, i16* %5, i64 %190
  %192 = load i16, i16* %191, align 2
  %193 = zext i16 %192 to i32
  br label %194

194:                                              ; preds = %19, %188
  %195 = phi i32 [ %193, %188 ], [ %182, %19 ]
  %196 = shl nuw nsw i32 %182, 1
  %197 = add nuw nsw i32 %172, 2
  %198 = add nuw nsw i32 %197, %196
  %199 = add nuw nsw i32 %198, %195
  %200 = lshr i32 %199, 2
  %201 = add nuw nsw i32 %39, 8
  %202 = add nuw nsw i32 %201, %51
  %203 = add nuw nsw i32 %202, %61
  %204 = add nuw nsw i32 %203, %71
  %205 = add nuw nsw i32 %204, %82
  %206 = add nuw nsw i32 %205, %93
  %207 = add nuw nsw i32 %206, %108
  %208 = add nuw nsw i32 %207, %104
  %209 = add nuw nsw i32 %208, %128
  %210 = add nuw nsw i32 %209, %138
  %211 = add nuw nsw i32 %210, %147
  %212 = add nuw nsw i32 %211, %156
  %213 = add nuw nsw i32 %212, %166
  %214 = add nuw nsw i32 %213, %176
  %215 = add nuw nsw i32 %214, %186
  %216 = add nuw nsw i32 %215, %200
  %217 = ashr i32 %216, 4
  %218 = sext i32 %217 to i64
  %219 = mul i64 %218, 281479271743489
  %220 = bitcast i8* %0 to i64*
  store i64 %219, i64* %220, align 8
  %221 = getelementptr inbounds i8, i8* %0, i64 8
  %222 = bitcast i8* %221 to i64*
  store i64 %219, i64* %222, align 8
  %223 = getelementptr inbounds i16, i16* %5, i64 %21
  %224 = bitcast i16* %223 to i64*
  store i64 %219, i64* %224, align 8
  %225 = getelementptr inbounds i16, i16* %223, i64 4
  %226 = bitcast i16* %225 to i64*
  store i64 %219, i64* %226, align 8
  %227 = getelementptr inbounds i16, i16* %223, i64 %21
  %228 = bitcast i16* %227 to i64*
  store i64 %219, i64* %228, align 8
  %229 = getelementptr inbounds i16, i16* %227, i64 4
  %230 = bitcast i16* %229 to i64*
  store i64 %219, i64* %230, align 8
  %231 = getelementptr inbounds i16, i16* %227, i64 %21
  %232 = bitcast i16* %231 to i64*
  store i64 %219, i64* %232, align 8
  %233 = getelementptr inbounds i16, i16* %231, i64 4
  %234 = bitcast i16* %233 to i64*
  store i64 %219, i64* %234, align 8
  %235 = getelementptr inbounds i16, i16* %231, i64 %21
  %236 = bitcast i16* %235 to i64*
  store i64 %219, i64* %236, align 8
  %237 = getelementptr inbounds i16, i16* %235, i64 4
  %238 = bitcast i16* %237 to i64*
  store i64 %219, i64* %238, align 8
  %239 = getelementptr inbounds i16, i16* %235, i64 %21
  %240 = bitcast i16* %239 to i64*
  store i64 %219, i64* %240, align 8
  %241 = getelementptr inbounds i16, i16* %239, i64 4
  %242 = bitcast i16* %241 to i64*
  store i64 %219, i64* %242, align 8
  %243 = getelementptr inbounds i16, i16* %239, i64 %21
  %244 = bitcast i16* %243 to i64*
  store i64 %219, i64* %244, align 8
  %245 = getelementptr inbounds i16, i16* %243, i64 4
  %246 = bitcast i16* %245 to i64*
  store i64 %219, i64* %246, align 8
  %247 = getelementptr inbounds i16, i16* %243, i64 %21
  %248 = bitcast i16* %247 to i64*
  store i64 %219, i64* %248, align 8
  %249 = getelementptr inbounds i16, i16* %247, i64 4
  %250 = bitcast i16* %249 to i64*
  store i64 %219, i64* %250, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_down_left_14_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %97, label %99

97:                                               ; preds = %18
  %98 = mul nuw nsw i32 %91, 3
  br label %181

99:                                               ; preds = %18
  %100 = sub i64 34359738368, %19
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %5, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i32
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %105, %104
  %107 = shl nuw nsw i32 %104, 1
  %108 = sub i64 38654705664, %19
  %109 = ashr exact i64 %108, 32
  %110 = getelementptr inbounds i16, i16* %5, i64 %109
  %111 = load i16, i16* %110, align 2
  %112 = zext i16 %111 to i32
  %113 = add nuw nsw i32 %91, 2
  %114 = add nuw nsw i32 %113, %107
  %115 = add nuw nsw i32 %114, %112
  %116 = lshr i32 %115, 2
  %117 = shl nuw nsw i32 %112, 1
  %118 = sub i64 42949672960, %19
  %119 = ashr exact i64 %118, 32
  %120 = getelementptr inbounds i16, i16* %5, i64 %119
  %121 = load i16, i16* %120, align 2
  %122 = zext i16 %121 to i32
  %123 = add nuw nsw i32 %122, 2
  %124 = add nuw nsw i32 %123, %104
  %125 = add nuw nsw i32 %124, %117
  %126 = lshr i32 %125, 2
  %127 = shl nuw nsw i32 %122, 1
  %128 = sub i64 47244640256, %19
  %129 = ashr exact i64 %128, 32
  %130 = getelementptr inbounds i16, i16* %5, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i32
  %133 = add nuw nsw i32 %112, 2
  %134 = add nuw nsw i32 %133, %127
  %135 = add nuw nsw i32 %134, %132
  %136 = lshr i32 %135, 2
  %137 = shl nuw nsw i32 %132, 1
  %138 = sub i64 51539607552, %19
  %139 = ashr exact i64 %138, 32
  %140 = getelementptr inbounds i16, i16* %5, i64 %139
  %141 = load i16, i16* %140, align 2
  %142 = zext i16 %141 to i32
  %143 = add nuw nsw i32 %123, %137
  %144 = add nuw nsw i32 %143, %142
  %145 = lshr i32 %144, 2
  %146 = shl nuw nsw i32 %142, 1
  %147 = sub i64 55834574848, %19
  %148 = ashr exact i64 %147, 32
  %149 = getelementptr inbounds i16, i16* %5, i64 %148
  %150 = load i16, i16* %149, align 2
  %151 = zext i16 %150 to i32
  %152 = add nuw nsw i32 %132, 2
  %153 = add nuw nsw i32 %152, %146
  %154 = add nuw nsw i32 %153, %151
  %155 = lshr i32 %154, 2
  %156 = shl nuw nsw i32 %151, 1
  %157 = sub i64 60129542144, %19
  %158 = ashr exact i64 %157, 32
  %159 = getelementptr inbounds i16, i16* %5, i64 %158
  %160 = load i16, i16* %159, align 2
  %161 = zext i16 %160 to i32
  %162 = add nuw nsw i32 %142, 2
  %163 = add nuw nsw i32 %162, %156
  %164 = add nuw nsw i32 %163, %161
  %165 = lshr i32 %164, 2
  %166 = shl nuw nsw i32 %161, 1
  %167 = sub i64 64424509440, %19
  %168 = ashr exact i64 %167, 32
  %169 = getelementptr inbounds i16, i16* %5, i64 %168
  %170 = load i16, i16* %169, align 2
  %171 = zext i16 %170 to i32
  %172 = add nuw nsw i32 %151, 2
  %173 = add nuw nsw i32 %172, %166
  %174 = add nuw nsw i32 %173, %171
  %175 = lshr i32 %174, 2
  %176 = mul nuw nsw i32 %171, 3
  %177 = add nuw nsw i32 %161, 2
  %178 = add nuw nsw i32 %177, %176
  %179 = lshr i32 %178, 2
  %180 = mul nuw nsw i32 %179, 3
  br label %181

181:                                              ; preds = %97, %99
  %182 = phi i32 [ %98, %97 ], [ %180, %99 ]
  %183 = phi i32 [ %98, %97 ], [ %106, %99 ]
  %184 = phi i32 [ %91, %97 ], [ %116, %99 ]
  %185 = phi i32 [ %91, %97 ], [ %126, %99 ]
  %186 = phi i32 [ %91, %97 ], [ %136, %99 ]
  %187 = phi i32 [ %91, %97 ], [ %145, %99 ]
  %188 = phi i32 [ %91, %97 ], [ %155, %99 ]
  %189 = phi i32 [ %91, %97 ], [ %165, %99 ]
  %190 = phi i32 [ %91, %97 ], [ %175, %99 ]
  %191 = phi i32 [ %91, %97 ], [ %179, %99 ]
  %192 = add nuw nsw i32 %81, 2
  %193 = add nuw nsw i32 %192, %183
  %194 = lshr i32 %193, 2
  %195 = shl nuw nsw i32 %47, 1
  %196 = add nuw nsw i32 %56, 2
  %197 = add nuw nsw i32 %196, %37
  %198 = add nuw nsw i32 %197, %195
  %199 = lshr i32 %198, 2
  %200 = trunc i32 %199 to i16
  store i16 %200, i16* %5, align 2
  %201 = shl nuw nsw i32 %56, 1
  %202 = add nuw nsw i32 %65, 2
  %203 = add nuw nsw i32 %202, %47
  %204 = add nuw nsw i32 %203, %201
  %205 = lshr i32 %204, 2
  %206 = trunc i32 %205 to i16
  %207 = getelementptr inbounds i8, i8* %0, i64 2
  %208 = bitcast i8* %207 to i16*
  store i16 %206, i16* %208, align 2
  %209 = ashr exact i64 %19, 32
  %210 = getelementptr inbounds i16, i16* %5, i64 %209
  store i16 %206, i16* %210, align 2
  %211 = shl nuw nsw i32 %65, 1
  %212 = add nuw nsw i32 %196, %211
  %213 = add nuw nsw i32 %212, %75
  %214 = lshr i32 %213, 2
  %215 = trunc i32 %214 to i16
  %216 = getelementptr inbounds i8, i8* %0, i64 4
  %217 = bitcast i8* %216 to i16*
  store i16 %215, i16* %217, align 2
  %218 = add i64 %19, 4294967296
  %219 = ashr exact i64 %218, 32
  %220 = getelementptr inbounds i16, i16* %5, i64 %219
  store i16 %215, i16* %220, align 2
  %221 = trunc i64 %3 to i32
  %222 = and i32 %221, -2
  %223 = sext i32 %222 to i64
  %224 = getelementptr inbounds i16, i16* %5, i64 %223
  store i16 %215, i16* %224, align 2
  %225 = shl nuw nsw i32 %75, 1
  %226 = add nuw nsw i32 %202, %225
  %227 = add nuw nsw i32 %226, %85
  %228 = lshr i32 %227, 2
  %229 = trunc i32 %228 to i16
  %230 = getelementptr inbounds i8, i8* %0, i64 6
  %231 = bitcast i8* %230 to i16*
  store i16 %229, i16* %231, align 2
  %232 = add i64 %19, 8589934592
  %233 = ashr exact i64 %232, 32
  %234 = getelementptr inbounds i16, i16* %5, i64 %233
  store i16 %229, i16* %234, align 2
  %235 = shl i64 %3, 32
  %236 = ashr exact i64 %235, 32
  %237 = or i64 %236, 1
  %238 = getelementptr inbounds i16, i16* %5, i64 %237
  store i16 %229, i16* %238, align 2
  %239 = mul nsw i32 %7, 3
  %240 = sext i32 %239 to i64
  %241 = getelementptr inbounds i16, i16* %5, i64 %240
  store i16 %229, i16* %241, align 2
  %242 = shl nuw nsw i32 %85, 1
  %243 = add nuw nsw i32 %75, 2
  %244 = add nuw nsw i32 %243, %242
  %245 = add nuw nsw i32 %244, %95
  %246 = lshr i32 %245, 2
  %247 = trunc i32 %246 to i16
  %248 = getelementptr inbounds i8, i8* %0, i64 8
  %249 = bitcast i8* %248 to i16*
  store i16 %247, i16* %249, align 2
  %250 = add i64 %19, 12884901888
  %251 = ashr exact i64 %250, 32
  %252 = getelementptr inbounds i16, i16* %5, i64 %251
  store i16 %247, i16* %252, align 2
  %253 = add nsw i32 %222, 2
  %254 = sext i32 %253 to i64
  %255 = getelementptr inbounds i16, i16* %5, i64 %254
  store i16 %247, i16* %255, align 2
  %256 = add nsw i32 %239, 1
  %257 = sext i32 %256 to i64
  %258 = getelementptr inbounds i16, i16* %5, i64 %257
  store i16 %247, i16* %258, align 2
  %259 = shl i64 %6, 34
  %260 = ashr exact i64 %259, 32
  %261 = getelementptr inbounds i16, i16* %5, i64 %260
  store i16 %247, i16* %261, align 2
  %262 = shl nuw nsw i32 %95, 1
  %263 = add nuw nsw i32 %85, 2
  %264 = add nuw nsw i32 %263, %262
  %265 = add nuw nsw i32 %264, %194
  %266 = lshr i32 %265, 2
  %267 = trunc i32 %266 to i16
  %268 = getelementptr inbounds i8, i8* %0, i64 10
  %269 = bitcast i8* %268 to i16*
  store i16 %267, i16* %269, align 2
  %270 = add i64 %19, 17179869184
  %271 = ashr exact i64 %270, 32
  %272 = getelementptr inbounds i16, i16* %5, i64 %271
  store i16 %267, i16* %272, align 2
  %273 = add nsw i32 %222, 3
  %274 = sext i32 %273 to i64
  %275 = getelementptr inbounds i16, i16* %5, i64 %274
  store i16 %267, i16* %275, align 2
  %276 = add nsw i32 %239, 2
  %277 = sext i32 %276 to i64
  %278 = getelementptr inbounds i16, i16* %5, i64 %277
  store i16 %267, i16* %278, align 2
  %279 = or i64 %260, 1
  %280 = getelementptr inbounds i16, i16* %5, i64 %279
  store i16 %267, i16* %280, align 2
  %281 = mul nsw i32 %7, 5
  %282 = sext i32 %281 to i64
  %283 = getelementptr inbounds i16, i16* %5, i64 %282
  store i16 %267, i16* %283, align 2
  %284 = shl nuw nsw i32 %194, 1
  %285 = add nuw nsw i32 %95, 2
  %286 = add nuw nsw i32 %285, %184
  %287 = add nuw nsw i32 %286, %284
  %288 = lshr i32 %287, 2
  %289 = trunc i32 %288 to i16
  %290 = getelementptr inbounds i8, i8* %0, i64 12
  %291 = bitcast i8* %290 to i16*
  store i16 %289, i16* %291, align 2
  %292 = add i64 %19, 21474836480
  %293 = ashr exact i64 %292, 32
  %294 = getelementptr inbounds i16, i16* %5, i64 %293
  store i16 %289, i16* %294, align 2
  %295 = add nsw i32 %222, 4
  %296 = sext i32 %295 to i64
  %297 = getelementptr inbounds i16, i16* %5, i64 %296
  store i16 %289, i16* %297, align 2
  %298 = add nsw i32 %239, 3
  %299 = sext i32 %298 to i64
  %300 = getelementptr inbounds i16, i16* %5, i64 %299
  store i16 %289, i16* %300, align 2
  %301 = or i64 %260, 2
  %302 = getelementptr inbounds i16, i16* %5, i64 %301
  store i16 %289, i16* %302, align 2
  %303 = add nsw i32 %281, 1
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds i16, i16* %5, i64 %304
  store i16 %289, i16* %305, align 2
  %306 = mul nsw i32 %7, 6
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i16, i16* %5, i64 %307
  store i16 %289, i16* %308, align 2
  %309 = shl nuw nsw i32 %184, 1
  %310 = add nuw nsw i32 %194, 2
  %311 = add nuw nsw i32 %310, %185
  %312 = add nuw nsw i32 %311, %309
  %313 = lshr i32 %312, 2
  %314 = trunc i32 %313 to i16
  %315 = getelementptr inbounds i8, i8* %0, i64 14
  %316 = bitcast i8* %315 to i16*
  store i16 %314, i16* %316, align 2
  %317 = add i64 %19, 25769803776
  %318 = ashr exact i64 %317, 32
  %319 = getelementptr inbounds i16, i16* %5, i64 %318
  store i16 %314, i16* %319, align 2
  %320 = add nsw i32 %222, 5
  %321 = sext i32 %320 to i64
  %322 = getelementptr inbounds i16, i16* %5, i64 %321
  store i16 %314, i16* %322, align 2
  %323 = add nsw i32 %239, 4
  %324 = sext i32 %323 to i64
  %325 = getelementptr inbounds i16, i16* %5, i64 %324
  store i16 %314, i16* %325, align 2
  %326 = or i64 %260, 3
  %327 = getelementptr inbounds i16, i16* %5, i64 %326
  store i16 %314, i16* %327, align 2
  %328 = add nsw i32 %281, 2
  %329 = sext i32 %328 to i64
  %330 = getelementptr inbounds i16, i16* %5, i64 %329
  store i16 %314, i16* %330, align 2
  %331 = or i32 %306, 1
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds i16, i16* %5, i64 %332
  store i16 %314, i16* %333, align 2
  %334 = mul nsw i32 %7, 7
  %335 = sext i32 %334 to i64
  %336 = getelementptr inbounds i16, i16* %5, i64 %335
  store i16 %314, i16* %336, align 2
  %337 = shl nuw nsw i32 %185, 1
  %338 = add nuw nsw i32 %184, 2
  %339 = add nuw nsw i32 %338, %337
  %340 = add nuw nsw i32 %339, %186
  %341 = lshr i32 %340, 2
  %342 = trunc i32 %341 to i16
  %343 = add i64 %19, 30064771072
  %344 = ashr exact i64 %343, 32
  %345 = getelementptr inbounds i16, i16* %5, i64 %344
  store i16 %342, i16* %345, align 2
  %346 = add nsw i32 %222, 6
  %347 = sext i32 %346 to i64
  %348 = getelementptr inbounds i16, i16* %5, i64 %347
  store i16 %342, i16* %348, align 2
  %349 = add nsw i32 %239, 5
  %350 = sext i32 %349 to i64
  %351 = getelementptr inbounds i16, i16* %5, i64 %350
  store i16 %342, i16* %351, align 2
  %352 = add i64 %259, 17179869184
  %353 = ashr exact i64 %352, 32
  %354 = getelementptr inbounds i16, i16* %5, i64 %353
  store i16 %342, i16* %354, align 2
  %355 = add nsw i32 %281, 3
  %356 = sext i32 %355 to i64
  %357 = getelementptr inbounds i16, i16* %5, i64 %356
  store i16 %342, i16* %357, align 2
  %358 = add nsw i32 %306, 2
  %359 = sext i32 %358 to i64
  %360 = getelementptr inbounds i16, i16* %5, i64 %359
  store i16 %342, i16* %360, align 2
  %361 = add nsw i32 %334, 1
  %362 = sext i32 %361 to i64
  %363 = getelementptr inbounds i16, i16* %5, i64 %362
  store i16 %342, i16* %363, align 2
  %364 = shl nuw nsw i32 %186, 1
  %365 = add nuw nsw i32 %185, 2
  %366 = add nuw nsw i32 %365, %364
  %367 = add nuw nsw i32 %366, %187
  %368 = lshr i32 %367, 2
  %369 = trunc i32 %368 to i16
  %370 = add nsw i32 %222, 7
  %371 = sext i32 %370 to i64
  %372 = getelementptr inbounds i16, i16* %5, i64 %371
  store i16 %369, i16* %372, align 2
  %373 = add nsw i32 %239, 6
  %374 = sext i32 %373 to i64
  %375 = getelementptr inbounds i16, i16* %5, i64 %374
  store i16 %369, i16* %375, align 2
  %376 = add i64 %259, 21474836480
  %377 = ashr exact i64 %376, 32
  %378 = getelementptr inbounds i16, i16* %5, i64 %377
  store i16 %369, i16* %378, align 2
  %379 = add nsw i32 %281, 4
  %380 = sext i32 %379 to i64
  %381 = getelementptr inbounds i16, i16* %5, i64 %380
  store i16 %369, i16* %381, align 2
  %382 = add nsw i32 %306, 3
  %383 = sext i32 %382 to i64
  %384 = getelementptr inbounds i16, i16* %5, i64 %383
  store i16 %369, i16* %384, align 2
  %385 = add nsw i32 %334, 2
  %386 = sext i32 %385 to i64
  %387 = getelementptr inbounds i16, i16* %5, i64 %386
  store i16 %369, i16* %387, align 2
  %388 = shl nuw nsw i32 %187, 1
  %389 = add nuw nsw i32 %186, 2
  %390 = add nuw nsw i32 %389, %388
  %391 = add nuw nsw i32 %390, %188
  %392 = lshr i32 %391, 2
  %393 = trunc i32 %392 to i16
  %394 = add nsw i32 %239, 7
  %395 = sext i32 %394 to i64
  %396 = getelementptr inbounds i16, i16* %5, i64 %395
  store i16 %393, i16* %396, align 2
  %397 = add i64 %259, 25769803776
  %398 = ashr exact i64 %397, 32
  %399 = getelementptr inbounds i16, i16* %5, i64 %398
  store i16 %393, i16* %399, align 2
  %400 = add nsw i32 %281, 5
  %401 = sext i32 %400 to i64
  %402 = getelementptr inbounds i16, i16* %5, i64 %401
  store i16 %393, i16* %402, align 2
  %403 = add nsw i32 %306, 4
  %404 = sext i32 %403 to i64
  %405 = getelementptr inbounds i16, i16* %5, i64 %404
  store i16 %393, i16* %405, align 2
  %406 = add nsw i32 %334, 3
  %407 = sext i32 %406 to i64
  %408 = getelementptr inbounds i16, i16* %5, i64 %407
  store i16 %393, i16* %408, align 2
  %409 = shl nuw nsw i32 %188, 1
  %410 = add nuw nsw i32 %187, 2
  %411 = add nuw nsw i32 %410, %409
  %412 = add nuw nsw i32 %411, %189
  %413 = lshr i32 %412, 2
  %414 = trunc i32 %413 to i16
  %415 = add i64 %259, 30064771072
  %416 = ashr exact i64 %415, 32
  %417 = getelementptr inbounds i16, i16* %5, i64 %416
  store i16 %414, i16* %417, align 2
  %418 = add nsw i32 %281, 6
  %419 = sext i32 %418 to i64
  %420 = getelementptr inbounds i16, i16* %5, i64 %419
  store i16 %414, i16* %420, align 2
  %421 = add nsw i32 %306, 5
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds i16, i16* %5, i64 %422
  store i16 %414, i16* %423, align 2
  %424 = add nsw i32 %334, 4
  %425 = sext i32 %424 to i64
  %426 = getelementptr inbounds i16, i16* %5, i64 %425
  store i16 %414, i16* %426, align 2
  %427 = shl nuw nsw i32 %189, 1
  %428 = add nuw nsw i32 %188, 2
  %429 = add nuw nsw i32 %428, %427
  %430 = add nuw nsw i32 %429, %190
  %431 = lshr i32 %430, 2
  %432 = trunc i32 %431 to i16
  %433 = add nsw i32 %281, 7
  %434 = sext i32 %433 to i64
  %435 = getelementptr inbounds i16, i16* %5, i64 %434
  store i16 %432, i16* %435, align 2
  %436 = add nsw i32 %306, 6
  %437 = sext i32 %436 to i64
  %438 = getelementptr inbounds i16, i16* %5, i64 %437
  store i16 %432, i16* %438, align 2
  %439 = add nsw i32 %334, 5
  %440 = sext i32 %439 to i64
  %441 = getelementptr inbounds i16, i16* %5, i64 %440
  store i16 %432, i16* %441, align 2
  %442 = shl nuw nsw i32 %190, 1
  %443 = add nuw nsw i32 %189, 2
  %444 = add nuw nsw i32 %443, %442
  %445 = add nuw nsw i32 %444, %191
  %446 = lshr i32 %445, 2
  %447 = trunc i32 %446 to i16
  %448 = add nsw i32 %306, 7
  %449 = sext i32 %448 to i64
  %450 = getelementptr inbounds i16, i16* %5, i64 %449
  store i16 %447, i16* %450, align 2
  %451 = add nsw i32 %334, 6
  %452 = sext i32 %451 to i64
  %453 = getelementptr inbounds i16, i16* %5, i64 %452
  store i16 %447, i16* %453, align 2
  %454 = add nuw nsw i32 %190, 2
  %455 = add nuw nsw i32 %454, %182
  %456 = lshr i32 %455, 2
  %457 = trunc i32 %456 to i16
  %458 = add nsw i32 %334, 7
  %459 = sext i32 %458 to i64
  %460 = getelementptr inbounds i16, i16* %5, i64 %459
  store i16 %457, i16* %460, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_down_right_14_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp ne i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %10, label %15

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %27, 2
  %45 = add nuw nsw i32 %44, %38
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %43, 2
  %64 = add nuw nsw i32 %63, %57
  %65 = add nuw nsw i32 %64, %62
  %66 = lshr i32 %65, 2
  %67 = shl nuw nsw i32 %62, 1
  %68 = sub i64 21474836480, %19
  %69 = ashr exact i64 %68, 32
  %70 = getelementptr inbounds i16, i16* %5, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i32
  %73 = add nuw nsw i32 %53, 2
  %74 = add nuw nsw i32 %73, %67
  %75 = add nuw nsw i32 %74, %72
  %76 = lshr i32 %75, 2
  %77 = shl nuw nsw i32 %72, 1
  %78 = sub i64 25769803776, %19
  %79 = ashr exact i64 %78, 32
  %80 = getelementptr inbounds i16, i16* %5, i64 %79
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i32
  %83 = add nuw nsw i32 %62, 2
  %84 = add nuw nsw i32 %83, %77
  %85 = add nuw nsw i32 %84, %82
  %86 = lshr i32 %85, 2
  %87 = shl nuw nsw i32 %82, 1
  %88 = sub i64 30064771072, %19
  %89 = ashr exact i64 %88, 32
  %90 = getelementptr inbounds i16, i16* %5, i64 %89
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i32
  %93 = add nuw nsw i32 %72, 2
  %94 = add nuw nsw i32 %93, %87
  %95 = add nuw nsw i32 %94, %92
  %96 = lshr i32 %95, 2
  %97 = icmp eq i32 %2, 0
  br i1 %97, label %104, label %98

98:                                               ; preds = %18
  %99 = sub i64 34359738368, %19
  %100 = ashr exact i64 %99, 32
  %101 = getelementptr inbounds i16, i16* %5, i64 %100
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  br label %104

104:                                              ; preds = %18, %98
  %105 = phi i32 [ %103, %98 ], [ %92, %18 ]
  %106 = shl nuw nsw i32 %92, 1
  %107 = add nuw nsw i32 %82, 2
  %108 = add nuw nsw i32 %107, %106
  %109 = add nuw nsw i32 %108, %105
  %110 = lshr i32 %109, 2
  %111 = ashr exact i64 %19, 32
  %112 = xor i64 %111, -1
  %113 = getelementptr inbounds i16, i16* %5, i64 %112
  %114 = getelementptr inbounds i8, i8* %0, i64 -2
  %115 = bitcast i8* %114 to i16*
  %116 = select i1 %8, i16* %113, i16* %115
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = load i16, i16* %115, align 2
  %120 = zext i16 %119 to i32
  %121 = shl nuw nsw i32 %120, 1
  %122 = add i64 %19, -4294967296
  %123 = ashr exact i64 %122, 32
  %124 = getelementptr inbounds i16, i16* %5, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %126, 2
  %128 = add nuw nsw i32 %127, %118
  %129 = add nuw nsw i32 %128, %121
  %130 = lshr i32 %129, 2
  %131 = shl nuw nsw i32 %126, 1
  %132 = trunc i64 %3 to i32
  %133 = and i32 %132, -2
  %134 = add nsw i32 %133, -1
  %135 = sext i32 %134 to i64
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  %137 = load i16, i16* %136, align 2
  %138 = zext i16 %137 to i32
  %139 = add nuw nsw i32 %120, 2
  %140 = add nuw nsw i32 %139, %131
  %141 = add nuw nsw i32 %140, %138
  %142 = lshr i32 %141, 2
  %143 = shl nuw nsw i32 %138, 1
  %144 = mul nsw i32 %7, 3
  %145 = add nsw i32 %144, -1
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds i16, i16* %5, i64 %146
  %148 = load i16, i16* %147, align 2
  %149 = zext i16 %148 to i32
  %150 = add nuw nsw i32 %127, %143
  %151 = add nuw nsw i32 %150, %149
  %152 = lshr i32 %151, 2
  %153 = shl nuw nsw i32 %149, 1
  %154 = shl i64 %6, 34
  %155 = add i64 %154, -4294967296
  %156 = ashr exact i64 %155, 32
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  %158 = load i16, i16* %157, align 2
  %159 = zext i16 %158 to i32
  %160 = add nuw nsw i32 %138, 2
  %161 = add nuw nsw i32 %160, %153
  %162 = add nuw nsw i32 %161, %159
  %163 = lshr i32 %162, 2
  %164 = shl nuw nsw i32 %159, 1
  %165 = mul nsw i32 %7, 5
  %166 = add nsw i32 %165, -1
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds i16, i16* %5, i64 %167
  %169 = load i16, i16* %168, align 2
  %170 = zext i16 %169 to i32
  %171 = add nuw nsw i32 %149, 2
  %172 = add nuw nsw i32 %171, %164
  %173 = add nuw nsw i32 %172, %170
  %174 = lshr i32 %173, 2
  %175 = shl nuw nsw i32 %170, 1
  %176 = mul nsw i32 %7, 6
  %177 = add nsw i32 %176, -1
  %178 = sext i32 %177 to i64
  %179 = getelementptr inbounds i16, i16* %5, i64 %178
  %180 = load i16, i16* %179, align 2
  %181 = zext i16 %180 to i32
  %182 = add nuw nsw i32 %159, 2
  %183 = add nuw nsw i32 %182, %175
  %184 = add nuw nsw i32 %183, %181
  %185 = lshr i32 %184, 2
  %186 = shl nuw nsw i32 %181, 1
  %187 = mul nsw i32 %7, 7
  %188 = add nsw i32 %187, -1
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds i16, i16* %5, i64 %189
  %191 = load i16, i16* %190, align 2
  %192 = zext i16 %191 to i32
  %193 = add nuw nsw i32 %170, 2
  %194 = add nuw nsw i32 %193, %186
  %195 = add nuw nsw i32 %194, %192
  %196 = lshr i32 %195, 2
  %197 = mul nuw nsw i32 %192, 3
  %198 = add nuw nsw i32 %181, 2
  %199 = add nuw nsw i32 %198, %197
  %200 = lshr i32 %199, 2
  %201 = load i16, i16* %113, align 2
  %202 = zext i16 %201 to i32
  %203 = shl nuw nsw i32 %202, 1
  %204 = add nuw nsw i32 %44, %120
  %205 = add nuw nsw i32 %204, %203
  %206 = lshr i32 %205, 2
  %207 = shl nuw nsw i32 %196, 1
  %208 = add nuw nsw i32 %185, 2
  %209 = add nuw nsw i32 %208, %200
  %210 = add nuw nsw i32 %209, %207
  %211 = lshr i32 %210, 2
  %212 = trunc i32 %211 to i16
  %213 = sext i32 %187 to i64
  %214 = getelementptr inbounds i16, i16* %5, i64 %213
  store i16 %212, i16* %214, align 2
  %215 = shl nuw nsw i32 %185, 1
  %216 = add nuw nsw i32 %174, 2
  %217 = add nuw nsw i32 %216, %215
  %218 = add nuw nsw i32 %217, %196
  %219 = lshr i32 %218, 2
  %220 = trunc i32 %219 to i16
  %221 = add nsw i32 %187, 1
  %222 = sext i32 %221 to i64
  %223 = getelementptr inbounds i16, i16* %5, i64 %222
  store i16 %220, i16* %223, align 2
  %224 = sext i32 %176 to i64
  %225 = getelementptr inbounds i16, i16* %5, i64 %224
  store i16 %220, i16* %225, align 2
  %226 = shl nuw nsw i32 %174, 1
  %227 = add nuw nsw i32 %163, 2
  %228 = add nuw nsw i32 %227, %226
  %229 = add nuw nsw i32 %228, %185
  %230 = lshr i32 %229, 2
  %231 = trunc i32 %230 to i16
  %232 = add nsw i32 %187, 2
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds i16, i16* %5, i64 %233
  store i16 %231, i16* %234, align 2
  %235 = or i32 %176, 1
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds i16, i16* %5, i64 %236
  store i16 %231, i16* %237, align 2
  %238 = sext i32 %165 to i64
  %239 = getelementptr inbounds i16, i16* %5, i64 %238
  store i16 %231, i16* %239, align 2
  %240 = shl nuw nsw i32 %163, 1
  %241 = add nuw nsw i32 %152, 2
  %242 = add nuw nsw i32 %241, %240
  %243 = add nuw nsw i32 %242, %174
  %244 = lshr i32 %243, 2
  %245 = trunc i32 %244 to i16
  %246 = add nsw i32 %187, 3
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds i16, i16* %5, i64 %247
  store i16 %245, i16* %248, align 2
  %249 = add nsw i32 %176, 2
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds i16, i16* %5, i64 %250
  store i16 %245, i16* %251, align 2
  %252 = add nsw i32 %165, 1
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i16, i16* %5, i64 %253
  store i16 %245, i16* %254, align 2
  %255 = ashr exact i64 %154, 32
  %256 = getelementptr inbounds i16, i16* %5, i64 %255
  store i16 %245, i16* %256, align 2
  %257 = shl nuw nsw i32 %152, 1
  %258 = add nuw nsw i32 %142, 2
  %259 = add nuw nsw i32 %258, %257
  %260 = add nuw nsw i32 %259, %163
  %261 = lshr i32 %260, 2
  %262 = trunc i32 %261 to i16
  %263 = add nsw i32 %187, 4
  %264 = sext i32 %263 to i64
  %265 = getelementptr inbounds i16, i16* %5, i64 %264
  store i16 %262, i16* %265, align 2
  %266 = add nsw i32 %176, 3
  %267 = sext i32 %266 to i64
  %268 = getelementptr inbounds i16, i16* %5, i64 %267
  store i16 %262, i16* %268, align 2
  %269 = add nsw i32 %165, 2
  %270 = sext i32 %269 to i64
  %271 = getelementptr inbounds i16, i16* %5, i64 %270
  store i16 %262, i16* %271, align 2
  %272 = or i64 %255, 1
  %273 = getelementptr inbounds i16, i16* %5, i64 %272
  store i16 %262, i16* %273, align 2
  %274 = sext i32 %144 to i64
  %275 = getelementptr inbounds i16, i16* %5, i64 %274
  store i16 %262, i16* %275, align 2
  %276 = shl nuw nsw i32 %142, 1
  %277 = add nuw nsw i32 %130, 2
  %278 = add nuw nsw i32 %277, %276
  %279 = add nuw nsw i32 %278, %152
  %280 = lshr i32 %279, 2
  %281 = trunc i32 %280 to i16
  %282 = add nsw i32 %187, 5
  %283 = sext i32 %282 to i64
  %284 = getelementptr inbounds i16, i16* %5, i64 %283
  store i16 %281, i16* %284, align 2
  %285 = add nsw i32 %176, 4
  %286 = sext i32 %285 to i64
  %287 = getelementptr inbounds i16, i16* %5, i64 %286
  store i16 %281, i16* %287, align 2
  %288 = add nsw i32 %165, 3
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds i16, i16* %5, i64 %289
  store i16 %281, i16* %290, align 2
  %291 = or i64 %255, 2
  %292 = getelementptr inbounds i16, i16* %5, i64 %291
  store i16 %281, i16* %292, align 2
  %293 = add nsw i32 %144, 1
  %294 = sext i32 %293 to i64
  %295 = getelementptr inbounds i16, i16* %5, i64 %294
  store i16 %281, i16* %295, align 2
  %296 = sext i32 %133 to i64
  %297 = getelementptr inbounds i16, i16* %5, i64 %296
  store i16 %281, i16* %297, align 2
  %298 = shl nuw nsw i32 %130, 1
  %299 = add nuw nsw i32 %258, %298
  %300 = add nuw nsw i32 %299, %206
  %301 = lshr i32 %300, 2
  %302 = trunc i32 %301 to i16
  %303 = add nsw i32 %187, 6
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds i16, i16* %5, i64 %304
  store i16 %302, i16* %305, align 2
  %306 = add nsw i32 %176, 5
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i16, i16* %5, i64 %307
  store i16 %302, i16* %308, align 2
  %309 = add nsw i32 %165, 4
  %310 = sext i32 %309 to i64
  %311 = getelementptr inbounds i16, i16* %5, i64 %310
  store i16 %302, i16* %311, align 2
  %312 = or i64 %255, 3
  %313 = getelementptr inbounds i16, i16* %5, i64 %312
  store i16 %302, i16* %313, align 2
  %314 = add nsw i32 %144, 2
  %315 = sext i32 %314 to i64
  %316 = getelementptr inbounds i16, i16* %5, i64 %315
  store i16 %302, i16* %316, align 2
  %317 = shl i64 %3, 32
  %318 = ashr exact i64 %317, 32
  %319 = or i64 %318, 1
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %302, i16* %320, align 2
  %321 = getelementptr inbounds i16, i16* %5, i64 %111
  store i16 %302, i16* %321, align 2
  %322 = shl nuw nsw i32 %206, 1
  %323 = add nuw nsw i32 %37, 2
  %324 = add nuw nsw i32 %323, %130
  %325 = add nuw nsw i32 %324, %322
  %326 = lshr i32 %325, 2
  %327 = trunc i32 %326 to i16
  %328 = add nsw i32 %187, 7
  %329 = sext i32 %328 to i64
  %330 = getelementptr inbounds i16, i16* %5, i64 %329
  store i16 %327, i16* %330, align 2
  %331 = add nsw i32 %176, 6
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds i16, i16* %5, i64 %332
  store i16 %327, i16* %333, align 2
  %334 = add nsw i32 %165, 5
  %335 = sext i32 %334 to i64
  %336 = getelementptr inbounds i16, i16* %5, i64 %335
  store i16 %327, i16* %336, align 2
  %337 = add i64 %154, 17179869184
  %338 = ashr exact i64 %337, 32
  %339 = getelementptr inbounds i16, i16* %5, i64 %338
  store i16 %327, i16* %339, align 2
  %340 = add nsw i32 %144, 3
  %341 = sext i32 %340 to i64
  %342 = getelementptr inbounds i16, i16* %5, i64 %341
  store i16 %327, i16* %342, align 2
  %343 = add nsw i32 %133, 2
  %344 = sext i32 %343 to i64
  %345 = getelementptr inbounds i16, i16* %5, i64 %344
  store i16 %327, i16* %345, align 2
  %346 = add i64 %19, 4294967296
  %347 = ashr exact i64 %346, 32
  %348 = getelementptr inbounds i16, i16* %5, i64 %347
  store i16 %327, i16* %348, align 2
  store i16 %327, i16* %5, align 2
  %349 = shl nuw nsw i32 %37, 1
  %350 = add nuw nsw i32 %47, 2
  %351 = add nuw nsw i32 %350, %349
  %352 = add nuw nsw i32 %351, %206
  %353 = lshr i32 %352, 2
  %354 = trunc i32 %353 to i16
  %355 = add nsw i32 %176, 7
  %356 = sext i32 %355 to i64
  %357 = getelementptr inbounds i16, i16* %5, i64 %356
  store i16 %354, i16* %357, align 2
  %358 = add nsw i32 %165, 6
  %359 = sext i32 %358 to i64
  %360 = getelementptr inbounds i16, i16* %5, i64 %359
  store i16 %354, i16* %360, align 2
  %361 = add i64 %154, 21474836480
  %362 = ashr exact i64 %361, 32
  %363 = getelementptr inbounds i16, i16* %5, i64 %362
  store i16 %354, i16* %363, align 2
  %364 = add nsw i32 %144, 4
  %365 = sext i32 %364 to i64
  %366 = getelementptr inbounds i16, i16* %5, i64 %365
  store i16 %354, i16* %366, align 2
  %367 = add nsw i32 %133, 3
  %368 = sext i32 %367 to i64
  %369 = getelementptr inbounds i16, i16* %5, i64 %368
  store i16 %354, i16* %369, align 2
  %370 = add i64 %19, 8589934592
  %371 = ashr exact i64 %370, 32
  %372 = getelementptr inbounds i16, i16* %5, i64 %371
  store i16 %354, i16* %372, align 2
  %373 = getelementptr inbounds i8, i8* %0, i64 2
  %374 = bitcast i8* %373 to i16*
  store i16 %354, i16* %374, align 2
  %375 = shl nuw nsw i32 %47, 1
  %376 = add nuw nsw i32 %323, %375
  %377 = add nuw nsw i32 %376, %56
  %378 = lshr i32 %377, 2
  %379 = trunc i32 %378 to i16
  %380 = add nsw i32 %165, 7
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i16, i16* %5, i64 %381
  store i16 %379, i16* %382, align 2
  %383 = add i64 %154, 25769803776
  %384 = ashr exact i64 %383, 32
  %385 = getelementptr inbounds i16, i16* %5, i64 %384
  store i16 %379, i16* %385, align 2
  %386 = add nsw i32 %144, 5
  %387 = sext i32 %386 to i64
  %388 = getelementptr inbounds i16, i16* %5, i64 %387
  store i16 %379, i16* %388, align 2
  %389 = add nsw i32 %133, 4
  %390 = sext i32 %389 to i64
  %391 = getelementptr inbounds i16, i16* %5, i64 %390
  store i16 %379, i16* %391, align 2
  %392 = add i64 %19, 12884901888
  %393 = ashr exact i64 %392, 32
  %394 = getelementptr inbounds i16, i16* %5, i64 %393
  store i16 %379, i16* %394, align 2
  %395 = getelementptr inbounds i8, i8* %0, i64 4
  %396 = bitcast i8* %395 to i16*
  store i16 %379, i16* %396, align 2
  %397 = shl nuw nsw i32 %56, 1
  %398 = add nuw nsw i32 %350, %397
  %399 = add nuw nsw i32 %398, %66
  %400 = lshr i32 %399, 2
  %401 = trunc i32 %400 to i16
  %402 = add i64 %154, 30064771072
  %403 = ashr exact i64 %402, 32
  %404 = getelementptr inbounds i16, i16* %5, i64 %403
  store i16 %401, i16* %404, align 2
  %405 = add nsw i32 %144, 6
  %406 = sext i32 %405 to i64
  %407 = getelementptr inbounds i16, i16* %5, i64 %406
  store i16 %401, i16* %407, align 2
  %408 = add nsw i32 %133, 5
  %409 = sext i32 %408 to i64
  %410 = getelementptr inbounds i16, i16* %5, i64 %409
  store i16 %401, i16* %410, align 2
  %411 = add i64 %19, 17179869184
  %412 = ashr exact i64 %411, 32
  %413 = getelementptr inbounds i16, i16* %5, i64 %412
  store i16 %401, i16* %413, align 2
  %414 = getelementptr inbounds i8, i8* %0, i64 6
  %415 = bitcast i8* %414 to i16*
  store i16 %401, i16* %415, align 2
  %416 = shl nuw nsw i32 %66, 1
  %417 = add nuw nsw i32 %56, 2
  %418 = add nuw nsw i32 %417, %416
  %419 = add nuw nsw i32 %418, %76
  %420 = lshr i32 %419, 2
  %421 = trunc i32 %420 to i16
  %422 = add nsw i32 %144, 7
  %423 = sext i32 %422 to i64
  %424 = getelementptr inbounds i16, i16* %5, i64 %423
  store i16 %421, i16* %424, align 2
  %425 = add nsw i32 %133, 6
  %426 = sext i32 %425 to i64
  %427 = getelementptr inbounds i16, i16* %5, i64 %426
  store i16 %421, i16* %427, align 2
  %428 = add i64 %19, 21474836480
  %429 = ashr exact i64 %428, 32
  %430 = getelementptr inbounds i16, i16* %5, i64 %429
  store i16 %421, i16* %430, align 2
  %431 = getelementptr inbounds i8, i8* %0, i64 8
  %432 = bitcast i8* %431 to i16*
  store i16 %421, i16* %432, align 2
  %433 = shl nuw nsw i32 %76, 1
  %434 = add nuw nsw i32 %66, 2
  %435 = add nuw nsw i32 %434, %433
  %436 = add nuw nsw i32 %435, %86
  %437 = lshr i32 %436, 2
  %438 = trunc i32 %437 to i16
  %439 = add nsw i32 %133, 7
  %440 = sext i32 %439 to i64
  %441 = getelementptr inbounds i16, i16* %5, i64 %440
  store i16 %438, i16* %441, align 2
  %442 = add i64 %19, 25769803776
  %443 = ashr exact i64 %442, 32
  %444 = getelementptr inbounds i16, i16* %5, i64 %443
  store i16 %438, i16* %444, align 2
  %445 = getelementptr inbounds i8, i8* %0, i64 10
  %446 = bitcast i8* %445 to i16*
  store i16 %438, i16* %446, align 2
  %447 = shl nuw nsw i32 %86, 1
  %448 = add nuw nsw i32 %76, 2
  %449 = add nuw nsw i32 %448, %447
  %450 = add nuw nsw i32 %449, %96
  %451 = lshr i32 %450, 2
  %452 = trunc i32 %451 to i16
  %453 = add i64 %19, 30064771072
  %454 = ashr exact i64 %453, 32
  %455 = getelementptr inbounds i16, i16* %5, i64 %454
  store i16 %452, i16* %455, align 2
  %456 = getelementptr inbounds i8, i8* %0, i64 12
  %457 = bitcast i8* %456 to i16*
  store i16 %452, i16* %457, align 2
  %458 = shl nuw nsw i32 %96, 1
  %459 = add nuw nsw i32 %86, 2
  %460 = add nuw nsw i32 %459, %458
  %461 = add nuw nsw i32 %460, %110
  %462 = lshr i32 %461, 2
  %463 = trunc i32 %462 to i16
  %464 = getelementptr inbounds i8, i8* %0, i64 14
  %465 = bitcast i8* %464 to i16*
  store i16 %463, i16* %465, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_right_14_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp ne i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %10, label %15

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %27, 2
  %45 = add nuw nsw i32 %44, %38
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %43, 2
  %64 = add nuw nsw i32 %63, %57
  %65 = add nuw nsw i32 %64, %62
  %66 = lshr i32 %65, 2
  %67 = shl nuw nsw i32 %62, 1
  %68 = sub i64 21474836480, %19
  %69 = ashr exact i64 %68, 32
  %70 = getelementptr inbounds i16, i16* %5, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i32
  %73 = add nuw nsw i32 %53, 2
  %74 = add nuw nsw i32 %73, %67
  %75 = add nuw nsw i32 %74, %72
  %76 = lshr i32 %75, 2
  %77 = shl nuw nsw i32 %72, 1
  %78 = sub i64 25769803776, %19
  %79 = ashr exact i64 %78, 32
  %80 = getelementptr inbounds i16, i16* %5, i64 %79
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i32
  %83 = add nuw nsw i32 %62, 2
  %84 = add nuw nsw i32 %83, %77
  %85 = add nuw nsw i32 %84, %82
  %86 = lshr i32 %85, 2
  %87 = shl nuw nsw i32 %82, 1
  %88 = sub i64 30064771072, %19
  %89 = ashr exact i64 %88, 32
  %90 = getelementptr inbounds i16, i16* %5, i64 %89
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i32
  %93 = add nuw nsw i32 %72, 2
  %94 = add nuw nsw i32 %93, %87
  %95 = add nuw nsw i32 %94, %92
  %96 = lshr i32 %95, 2
  %97 = icmp eq i32 %2, 0
  br i1 %97, label %104, label %98

98:                                               ; preds = %18
  %99 = sub i64 34359738368, %19
  %100 = ashr exact i64 %99, 32
  %101 = getelementptr inbounds i16, i16* %5, i64 %100
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  br label %104

104:                                              ; preds = %18, %98
  %105 = phi i32 [ %103, %98 ], [ %92, %18 ]
  %106 = shl nuw nsw i32 %92, 1
  %107 = add nuw nsw i32 %82, 2
  %108 = add nuw nsw i32 %107, %106
  %109 = add nuw nsw i32 %108, %105
  %110 = lshr i32 %109, 2
  %111 = ashr exact i64 %19, 32
  %112 = xor i64 %111, -1
  %113 = getelementptr inbounds i16, i16* %5, i64 %112
  %114 = getelementptr inbounds i8, i8* %0, i64 -2
  %115 = bitcast i8* %114 to i16*
  %116 = select i1 %8, i16* %113, i16* %115
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = load i16, i16* %115, align 2
  %120 = zext i16 %119 to i32
  %121 = shl nuw nsw i32 %120, 1
  %122 = add i64 %19, -4294967296
  %123 = ashr exact i64 %122, 32
  %124 = getelementptr inbounds i16, i16* %5, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %126, 2
  %128 = add nuw nsw i32 %127, %118
  %129 = add nuw nsw i32 %128, %121
  %130 = lshr i32 %129, 2
  %131 = shl nuw nsw i32 %126, 1
  %132 = trunc i64 %3 to i32
  %133 = and i32 %132, -2
  %134 = add nsw i32 %133, -1
  %135 = sext i32 %134 to i64
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  %137 = load i16, i16* %136, align 2
  %138 = zext i16 %137 to i32
  %139 = add nuw nsw i32 %120, 2
  %140 = add nuw nsw i32 %139, %131
  %141 = add nuw nsw i32 %140, %138
  %142 = lshr i32 %141, 2
  %143 = shl nuw nsw i32 %138, 1
  %144 = mul nsw i32 %7, 3
  %145 = add nsw i32 %144, -1
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds i16, i16* %5, i64 %146
  %148 = load i16, i16* %147, align 2
  %149 = zext i16 %148 to i32
  %150 = add nuw nsw i32 %127, %143
  %151 = add nuw nsw i32 %150, %149
  %152 = lshr i32 %151, 2
  %153 = shl nuw nsw i32 %149, 1
  %154 = shl i64 %6, 34
  %155 = add i64 %154, -4294967296
  %156 = ashr exact i64 %155, 32
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  %158 = load i16, i16* %157, align 2
  %159 = zext i16 %158 to i32
  %160 = add nuw nsw i32 %138, 2
  %161 = add nuw nsw i32 %160, %153
  %162 = add nuw nsw i32 %161, %159
  %163 = lshr i32 %162, 2
  %164 = shl nuw nsw i32 %159, 1
  %165 = mul nsw i32 %7, 5
  %166 = add nsw i32 %165, -1
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds i16, i16* %5, i64 %167
  %169 = load i16, i16* %168, align 2
  %170 = zext i16 %169 to i32
  %171 = add nuw nsw i32 %149, 2
  %172 = add nuw nsw i32 %171, %164
  %173 = add nuw nsw i32 %172, %170
  %174 = lshr i32 %173, 2
  %175 = shl nuw nsw i32 %170, 1
  %176 = mul nsw i32 %7, 6
  %177 = add nsw i32 %176, -1
  %178 = sext i32 %177 to i64
  %179 = getelementptr inbounds i16, i16* %5, i64 %178
  %180 = load i16, i16* %179, align 2
  %181 = zext i16 %180 to i32
  %182 = add nuw nsw i32 %159, 2
  %183 = add nuw nsw i32 %182, %175
  %184 = add nuw nsw i32 %183, %181
  %185 = lshr i32 %184, 2
  %186 = shl nuw nsw i32 %181, 1
  %187 = mul nsw i32 %7, 7
  %188 = add nsw i32 %187, -1
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds i16, i16* %5, i64 %189
  %191 = load i16, i16* %190, align 2
  %192 = zext i16 %191 to i32
  %193 = add nuw nsw i32 %170, 2
  %194 = add nuw nsw i32 %193, %186
  %195 = add nuw nsw i32 %194, %192
  %196 = lshr i32 %195, 2
  %197 = load i16, i16* %113, align 2
  %198 = zext i16 %197 to i32
  %199 = shl nuw nsw i32 %198, 1
  %200 = add nuw nsw i32 %44, %120
  %201 = add nuw nsw i32 %200, %199
  %202 = lshr i32 %201, 2
  %203 = shl nuw nsw i32 %174, 1
  %204 = add nuw nsw i32 %163, 2
  %205 = add nuw nsw i32 %204, %203
  %206 = add nuw nsw i32 %205, %185
  %207 = lshr i32 %206, 2
  %208 = trunc i32 %207 to i16
  %209 = sext i32 %176 to i64
  %210 = getelementptr inbounds i16, i16* %5, i64 %209
  store i16 %208, i16* %210, align 2
  %211 = shl nuw nsw i32 %185, 1
  %212 = add nuw nsw i32 %174, 2
  %213 = add nuw nsw i32 %212, %211
  %214 = add nuw nsw i32 %213, %196
  %215 = lshr i32 %214, 2
  %216 = trunc i32 %215 to i16
  %217 = sext i32 %187 to i64
  %218 = getelementptr inbounds i16, i16* %5, i64 %217
  store i16 %216, i16* %218, align 2
  %219 = shl nuw nsw i32 %152, 1
  %220 = add nuw nsw i32 %142, 2
  %221 = add nuw nsw i32 %220, %219
  %222 = add nuw nsw i32 %221, %163
  %223 = lshr i32 %222, 2
  %224 = trunc i32 %223 to i16
  %225 = or i32 %176, 1
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds i16, i16* %5, i64 %226
  store i16 %224, i16* %227, align 2
  %228 = ashr exact i64 %154, 32
  %229 = getelementptr inbounds i16, i16* %5, i64 %228
  store i16 %224, i16* %229, align 2
  %230 = shl nuw nsw i32 %163, 1
  %231 = add nuw nsw i32 %152, 2
  %232 = add nuw nsw i32 %231, %230
  %233 = add nuw nsw i32 %232, %174
  %234 = lshr i32 %233, 2
  %235 = trunc i32 %234 to i16
  %236 = add nsw i32 %187, 1
  %237 = sext i32 %236 to i64
  %238 = getelementptr inbounds i16, i16* %5, i64 %237
  store i16 %235, i16* %238, align 2
  %239 = sext i32 %165 to i64
  %240 = getelementptr inbounds i16, i16* %5, i64 %239
  store i16 %235, i16* %240, align 2
  %241 = shl nuw nsw i32 %130, 1
  %242 = add nuw nsw i32 %220, %241
  %243 = add nuw nsw i32 %242, %202
  %244 = lshr i32 %243, 2
  %245 = trunc i32 %244 to i16
  %246 = add nsw i32 %176, 2
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds i16, i16* %5, i64 %247
  store i16 %245, i16* %248, align 2
  %249 = or i64 %228, 1
  %250 = getelementptr inbounds i16, i16* %5, i64 %249
  store i16 %245, i16* %250, align 2
  %251 = sext i32 %133 to i64
  %252 = getelementptr inbounds i16, i16* %5, i64 %251
  store i16 %245, i16* %252, align 2
  %253 = shl nuw nsw i32 %142, 1
  %254 = add nuw nsw i32 %130, 2
  %255 = add nuw nsw i32 %254, %253
  %256 = add nuw nsw i32 %255, %152
  %257 = lshr i32 %256, 2
  %258 = trunc i32 %257 to i16
  %259 = add nsw i32 %187, 2
  %260 = sext i32 %259 to i64
  %261 = getelementptr inbounds i16, i16* %5, i64 %260
  store i16 %258, i16* %261, align 2
  %262 = add nsw i32 %165, 1
  %263 = sext i32 %262 to i64
  %264 = getelementptr inbounds i16, i16* %5, i64 %263
  store i16 %258, i16* %264, align 2
  %265 = sext i32 %144 to i64
  %266 = getelementptr inbounds i16, i16* %5, i64 %265
  store i16 %258, i16* %266, align 2
  %267 = shl nuw nsw i32 %202, 1
  %268 = add nuw nsw i32 %37, 2
  %269 = add nuw nsw i32 %268, %130
  %270 = add nuw nsw i32 %269, %267
  %271 = lshr i32 %270, 2
  %272 = trunc i32 %271 to i16
  %273 = add nsw i32 %187, 3
  %274 = sext i32 %273 to i64
  %275 = getelementptr inbounds i16, i16* %5, i64 %274
  store i16 %272, i16* %275, align 2
  %276 = add nsw i32 %165, 2
  %277 = sext i32 %276 to i64
  %278 = getelementptr inbounds i16, i16* %5, i64 %277
  store i16 %272, i16* %278, align 2
  %279 = add nsw i32 %144, 1
  %280 = sext i32 %279 to i64
  %281 = getelementptr inbounds i16, i16* %5, i64 %280
  store i16 %272, i16* %281, align 2
  %282 = getelementptr inbounds i16, i16* %5, i64 %111
  store i16 %272, i16* %282, align 2
  %283 = add nuw nsw i32 %37, 1
  %284 = add nuw nsw i32 %283, %202
  %285 = lshr i32 %284, 1
  %286 = trunc i32 %285 to i16
  %287 = add nsw i32 %176, 3
  %288 = sext i32 %287 to i64
  %289 = getelementptr inbounds i16, i16* %5, i64 %288
  store i16 %286, i16* %289, align 2
  %290 = or i64 %228, 2
  %291 = getelementptr inbounds i16, i16* %5, i64 %290
  store i16 %286, i16* %291, align 2
  %292 = shl i64 %3, 32
  %293 = ashr exact i64 %292, 32
  %294 = or i64 %293, 1
  %295 = getelementptr inbounds i16, i16* %5, i64 %294
  store i16 %286, i16* %295, align 2
  store i16 %286, i16* %5, align 2
  %296 = shl nuw nsw i32 %37, 1
  %297 = add nuw nsw i32 %47, 2
  %298 = add nuw nsw i32 %297, %296
  %299 = add nuw nsw i32 %298, %202
  %300 = lshr i32 %299, 2
  %301 = trunc i32 %300 to i16
  %302 = add nsw i32 %187, 4
  %303 = sext i32 %302 to i64
  %304 = getelementptr inbounds i16, i16* %5, i64 %303
  store i16 %301, i16* %304, align 2
  %305 = add nsw i32 %165, 3
  %306 = sext i32 %305 to i64
  %307 = getelementptr inbounds i16, i16* %5, i64 %306
  store i16 %301, i16* %307, align 2
  %308 = add nsw i32 %144, 2
  %309 = sext i32 %308 to i64
  %310 = getelementptr inbounds i16, i16* %5, i64 %309
  store i16 %301, i16* %310, align 2
  %311 = add i64 %19, 4294967296
  %312 = ashr exact i64 %311, 32
  %313 = getelementptr inbounds i16, i16* %5, i64 %312
  store i16 %301, i16* %313, align 2
  %314 = add nuw nsw i32 %283, %47
  %315 = lshr i32 %314, 1
  %316 = trunc i32 %315 to i16
  %317 = add nsw i32 %176, 4
  %318 = sext i32 %317 to i64
  %319 = getelementptr inbounds i16, i16* %5, i64 %318
  store i16 %316, i16* %319, align 2
  %320 = or i64 %228, 3
  %321 = getelementptr inbounds i16, i16* %5, i64 %320
  store i16 %316, i16* %321, align 2
  %322 = add nsw i32 %133, 2
  %323 = sext i32 %322 to i64
  %324 = getelementptr inbounds i16, i16* %5, i64 %323
  store i16 %316, i16* %324, align 2
  %325 = getelementptr inbounds i8, i8* %0, i64 2
  %326 = bitcast i8* %325 to i16*
  store i16 %316, i16* %326, align 2
  %327 = shl nuw nsw i32 %47, 1
  %328 = add nuw nsw i32 %268, %327
  %329 = add nuw nsw i32 %328, %56
  %330 = lshr i32 %329, 2
  %331 = trunc i32 %330 to i16
  %332 = add nsw i32 %187, 5
  %333 = sext i32 %332 to i64
  %334 = getelementptr inbounds i16, i16* %5, i64 %333
  store i16 %331, i16* %334, align 2
  %335 = add nsw i32 %165, 4
  %336 = sext i32 %335 to i64
  %337 = getelementptr inbounds i16, i16* %5, i64 %336
  store i16 %331, i16* %337, align 2
  %338 = add nsw i32 %144, 3
  %339 = sext i32 %338 to i64
  %340 = getelementptr inbounds i16, i16* %5, i64 %339
  store i16 %331, i16* %340, align 2
  %341 = add i64 %19, 8589934592
  %342 = ashr exact i64 %341, 32
  %343 = getelementptr inbounds i16, i16* %5, i64 %342
  store i16 %331, i16* %343, align 2
  %344 = add nuw nsw i32 %47, 1
  %345 = add nuw nsw i32 %344, %56
  %346 = lshr i32 %345, 1
  %347 = trunc i32 %346 to i16
  %348 = add nsw i32 %176, 5
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i16, i16* %5, i64 %349
  store i16 %347, i16* %350, align 2
  %351 = add i64 %154, 17179869184
  %352 = ashr exact i64 %351, 32
  %353 = getelementptr inbounds i16, i16* %5, i64 %352
  store i16 %347, i16* %353, align 2
  %354 = add nsw i32 %133, 3
  %355 = sext i32 %354 to i64
  %356 = getelementptr inbounds i16, i16* %5, i64 %355
  store i16 %347, i16* %356, align 2
  %357 = getelementptr inbounds i8, i8* %0, i64 4
  %358 = bitcast i8* %357 to i16*
  store i16 %347, i16* %358, align 2
  %359 = shl nuw nsw i32 %56, 1
  %360 = add nuw nsw i32 %297, %359
  %361 = add nuw nsw i32 %360, %66
  %362 = lshr i32 %361, 2
  %363 = trunc i32 %362 to i16
  %364 = add nsw i32 %187, 6
  %365 = sext i32 %364 to i64
  %366 = getelementptr inbounds i16, i16* %5, i64 %365
  store i16 %363, i16* %366, align 2
  %367 = add nsw i32 %165, 5
  %368 = sext i32 %367 to i64
  %369 = getelementptr inbounds i16, i16* %5, i64 %368
  store i16 %363, i16* %369, align 2
  %370 = add nsw i32 %144, 4
  %371 = sext i32 %370 to i64
  %372 = getelementptr inbounds i16, i16* %5, i64 %371
  store i16 %363, i16* %372, align 2
  %373 = add i64 %19, 12884901888
  %374 = ashr exact i64 %373, 32
  %375 = getelementptr inbounds i16, i16* %5, i64 %374
  store i16 %363, i16* %375, align 2
  %376 = add nuw nsw i32 %56, 1
  %377 = add nuw nsw i32 %376, %66
  %378 = lshr i32 %377, 1
  %379 = trunc i32 %378 to i16
  %380 = add nsw i32 %176, 6
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i16, i16* %5, i64 %381
  store i16 %379, i16* %382, align 2
  %383 = add i64 %154, 21474836480
  %384 = ashr exact i64 %383, 32
  %385 = getelementptr inbounds i16, i16* %5, i64 %384
  store i16 %379, i16* %385, align 2
  %386 = add nsw i32 %133, 4
  %387 = sext i32 %386 to i64
  %388 = getelementptr inbounds i16, i16* %5, i64 %387
  store i16 %379, i16* %388, align 2
  %389 = getelementptr inbounds i8, i8* %0, i64 6
  %390 = bitcast i8* %389 to i16*
  store i16 %379, i16* %390, align 2
  %391 = shl nuw nsw i32 %66, 1
  %392 = add nuw nsw i32 %56, 2
  %393 = add nuw nsw i32 %392, %391
  %394 = add nuw nsw i32 %393, %76
  %395 = lshr i32 %394, 2
  %396 = trunc i32 %395 to i16
  %397 = add nsw i32 %187, 7
  %398 = sext i32 %397 to i64
  %399 = getelementptr inbounds i16, i16* %5, i64 %398
  store i16 %396, i16* %399, align 2
  %400 = add nsw i32 %165, 6
  %401 = sext i32 %400 to i64
  %402 = getelementptr inbounds i16, i16* %5, i64 %401
  store i16 %396, i16* %402, align 2
  %403 = add nsw i32 %144, 5
  %404 = sext i32 %403 to i64
  %405 = getelementptr inbounds i16, i16* %5, i64 %404
  store i16 %396, i16* %405, align 2
  %406 = add i64 %19, 17179869184
  %407 = ashr exact i64 %406, 32
  %408 = getelementptr inbounds i16, i16* %5, i64 %407
  store i16 %396, i16* %408, align 2
  %409 = add nuw nsw i32 %66, 1
  %410 = add nuw nsw i32 %409, %76
  %411 = lshr i32 %410, 1
  %412 = trunc i32 %411 to i16
  %413 = add nsw i32 %176, 7
  %414 = sext i32 %413 to i64
  %415 = getelementptr inbounds i16, i16* %5, i64 %414
  store i16 %412, i16* %415, align 2
  %416 = add i64 %154, 25769803776
  %417 = ashr exact i64 %416, 32
  %418 = getelementptr inbounds i16, i16* %5, i64 %417
  store i16 %412, i16* %418, align 2
  %419 = add nsw i32 %133, 5
  %420 = sext i32 %419 to i64
  %421 = getelementptr inbounds i16, i16* %5, i64 %420
  store i16 %412, i16* %421, align 2
  %422 = getelementptr inbounds i8, i8* %0, i64 8
  %423 = bitcast i8* %422 to i16*
  store i16 %412, i16* %423, align 2
  %424 = shl nuw nsw i32 %76, 1
  %425 = add nuw nsw i32 %66, 2
  %426 = add nuw nsw i32 %425, %424
  %427 = add nuw nsw i32 %426, %86
  %428 = lshr i32 %427, 2
  %429 = trunc i32 %428 to i16
  %430 = add nsw i32 %165, 7
  %431 = sext i32 %430 to i64
  %432 = getelementptr inbounds i16, i16* %5, i64 %431
  store i16 %429, i16* %432, align 2
  %433 = add nsw i32 %144, 6
  %434 = sext i32 %433 to i64
  %435 = getelementptr inbounds i16, i16* %5, i64 %434
  store i16 %429, i16* %435, align 2
  %436 = add i64 %19, 21474836480
  %437 = ashr exact i64 %436, 32
  %438 = getelementptr inbounds i16, i16* %5, i64 %437
  store i16 %429, i16* %438, align 2
  %439 = add nuw nsw i32 %76, 1
  %440 = add nuw nsw i32 %439, %86
  %441 = lshr i32 %440, 1
  %442 = trunc i32 %441 to i16
  %443 = add i64 %154, 30064771072
  %444 = ashr exact i64 %443, 32
  %445 = getelementptr inbounds i16, i16* %5, i64 %444
  store i16 %442, i16* %445, align 2
  %446 = add nsw i32 %133, 6
  %447 = sext i32 %446 to i64
  %448 = getelementptr inbounds i16, i16* %5, i64 %447
  store i16 %442, i16* %448, align 2
  %449 = getelementptr inbounds i8, i8* %0, i64 10
  %450 = bitcast i8* %449 to i16*
  store i16 %442, i16* %450, align 2
  %451 = shl nuw nsw i32 %86, 1
  %452 = add nuw nsw i32 %76, 2
  %453 = add nuw nsw i32 %452, %451
  %454 = add nuw nsw i32 %453, %96
  %455 = lshr i32 %454, 2
  %456 = trunc i32 %455 to i16
  %457 = add nsw i32 %144, 7
  %458 = sext i32 %457 to i64
  %459 = getelementptr inbounds i16, i16* %5, i64 %458
  store i16 %456, i16* %459, align 2
  %460 = add i64 %19, 25769803776
  %461 = ashr exact i64 %460, 32
  %462 = getelementptr inbounds i16, i16* %5, i64 %461
  store i16 %456, i16* %462, align 2
  %463 = add nuw nsw i32 %86, 1
  %464 = add nuw nsw i32 %463, %96
  %465 = lshr i32 %464, 1
  %466 = trunc i32 %465 to i16
  %467 = add nsw i32 %133, 7
  %468 = sext i32 %467 to i64
  %469 = getelementptr inbounds i16, i16* %5, i64 %468
  store i16 %466, i16* %469, align 2
  %470 = getelementptr inbounds i8, i8* %0, i64 12
  %471 = bitcast i8* %470 to i16*
  store i16 %466, i16* %471, align 2
  %472 = shl nuw nsw i32 %96, 1
  %473 = add nuw nsw i32 %86, 2
  %474 = add nuw nsw i32 %473, %472
  %475 = add nuw nsw i32 %474, %110
  %476 = lshr i32 %475, 2
  %477 = trunc i32 %476 to i16
  %478 = add i64 %19, 30064771072
  %479 = ashr exact i64 %478, 32
  %480 = getelementptr inbounds i16, i16* %5, i64 %479
  store i16 %477, i16* %480, align 2
  %481 = add nuw nsw i32 %96, 1
  %482 = add nuw nsw i32 %481, %110
  %483 = lshr i32 %482, 1
  %484 = trunc i32 %483 to i16
  %485 = getelementptr inbounds i8, i8* %0, i64 14
  %486 = bitcast i8* %485 to i16*
  store i16 %484, i16* %486, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_down_14_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp ne i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %10, label %15

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %20

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  %18 = ashr exact i64 %17, 32
  %19 = xor i64 %18, -1
  br label %20

20:                                               ; preds = %15, %10
  %21 = phi i64 [ %19, %15 ], [ %13, %10 ]
  %22 = phi i64 [ %18, %15 ], [ %12, %10 ]
  %23 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %24 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %25 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %26 = getelementptr inbounds i16, i16* %5, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = getelementptr inbounds i16, i16* %5, i64 %24
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i32
  %32 = shl nuw nsw i32 %31, 1
  %33 = sub i64 4294967296, %23
  %34 = ashr exact i64 %33, 32
  %35 = getelementptr inbounds i16, i16* %5, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i32
  %38 = add nuw nsw i32 %37, 2
  %39 = add nuw nsw i32 %38, %28
  %40 = add nuw nsw i32 %39, %32
  %41 = lshr i32 %40, 2
  %42 = shl nuw nsw i32 %37, 1
  %43 = sub i64 8589934592, %23
  %44 = ashr exact i64 %43, 32
  %45 = getelementptr inbounds i16, i16* %5, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i32
  %48 = add nuw nsw i32 %31, 2
  %49 = add nuw nsw i32 %48, %42
  %50 = add nuw nsw i32 %49, %47
  %51 = lshr i32 %50, 2
  %52 = shl nuw nsw i32 %47, 1
  %53 = sub i64 12884901888, %23
  %54 = ashr exact i64 %53, 32
  %55 = getelementptr inbounds i16, i16* %5, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i32
  %58 = add nuw nsw i32 %38, %52
  %59 = add nuw nsw i32 %58, %57
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %57, 1
  %62 = sub i64 17179869184, %23
  %63 = ashr exact i64 %62, 32
  %64 = getelementptr inbounds i16, i16* %5, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i32
  %67 = add nuw nsw i32 %47, 2
  %68 = add nuw nsw i32 %67, %61
  %69 = add nuw nsw i32 %68, %66
  %70 = lshr i32 %69, 2
  %71 = shl nuw nsw i32 %66, 1
  %72 = sub i64 21474836480, %23
  %73 = ashr exact i64 %72, 32
  %74 = getelementptr inbounds i16, i16* %5, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i32
  %77 = add nuw nsw i32 %57, 2
  %78 = add nuw nsw i32 %77, %71
  %79 = add nuw nsw i32 %78, %76
  %80 = lshr i32 %79, 2
  %81 = shl nuw nsw i32 %76, 1
  %82 = sub i64 25769803776, %23
  %83 = ashr exact i64 %82, 32
  %84 = getelementptr inbounds i16, i16* %5, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i32
  %87 = add nuw nsw i32 %66, 2
  %88 = add nuw nsw i32 %87, %81
  %89 = add nuw nsw i32 %88, %86
  %90 = lshr i32 %89, 2
  %91 = shl nuw nsw i32 %86, 1
  %92 = sub i64 30064771072, %23
  %93 = ashr exact i64 %92, 32
  %94 = getelementptr inbounds i16, i16* %5, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i32
  %97 = add nuw nsw i32 %76, 2
  %98 = add nuw nsw i32 %97, %91
  %99 = add nuw nsw i32 %98, %96
  %100 = lshr i32 %99, 2
  %101 = getelementptr inbounds i16, i16* %5, i64 %21
  %102 = getelementptr inbounds i8, i8* %0, i64 -2
  %103 = bitcast i8* %102 to i16*
  %104 = select i1 %8, i16* %101, i16* %103
  %105 = load i16, i16* %104, align 2
  %106 = zext i16 %105 to i32
  %107 = load i16, i16* %103, align 2
  %108 = zext i16 %107 to i32
  %109 = shl nuw nsw i32 %108, 1
  %110 = add i64 %23, -4294967296
  %111 = ashr exact i64 %110, 32
  %112 = getelementptr inbounds i16, i16* %5, i64 %111
  %113 = load i16, i16* %112, align 2
  %114 = zext i16 %113 to i32
  %115 = add nuw nsw i32 %114, 2
  %116 = add nuw nsw i32 %115, %106
  %117 = add nuw nsw i32 %116, %109
  %118 = lshr i32 %117, 2
  %119 = shl nuw nsw i32 %114, 1
  %120 = trunc i64 %3 to i32
  %121 = and i32 %120, -2
  %122 = add nsw i32 %121, -1
  %123 = sext i32 %122 to i64
  %124 = getelementptr inbounds i16, i16* %5, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %108, 2
  %128 = add nuw nsw i32 %127, %119
  %129 = add nuw nsw i32 %128, %126
  %130 = lshr i32 %129, 2
  %131 = shl nuw nsw i32 %126, 1
  %132 = mul nsw i32 %7, 3
  %133 = add nsw i32 %132, -1
  %134 = sext i32 %133 to i64
  %135 = getelementptr inbounds i16, i16* %5, i64 %134
  %136 = load i16, i16* %135, align 2
  %137 = zext i16 %136 to i32
  %138 = add nuw nsw i32 %115, %131
  %139 = add nuw nsw i32 %138, %137
  %140 = lshr i32 %139, 2
  %141 = shl nuw nsw i32 %137, 1
  %142 = shl i64 %6, 34
  %143 = add i64 %142, -4294967296
  %144 = ashr exact i64 %143, 32
  %145 = getelementptr inbounds i16, i16* %5, i64 %144
  %146 = load i16, i16* %145, align 2
  %147 = zext i16 %146 to i32
  %148 = add nuw nsw i32 %126, 2
  %149 = add nuw nsw i32 %148, %141
  %150 = add nuw nsw i32 %149, %147
  %151 = lshr i32 %150, 2
  %152 = shl nuw nsw i32 %147, 1
  %153 = mul nsw i32 %7, 5
  %154 = add nsw i32 %153, -1
  %155 = sext i32 %154 to i64
  %156 = getelementptr inbounds i16, i16* %5, i64 %155
  %157 = load i16, i16* %156, align 2
  %158 = zext i16 %157 to i32
  %159 = add nuw nsw i32 %137, 2
  %160 = add nuw nsw i32 %159, %152
  %161 = add nuw nsw i32 %160, %158
  %162 = lshr i32 %161, 2
  %163 = shl nuw nsw i32 %158, 1
  %164 = mul nsw i32 %7, 6
  %165 = add nsw i32 %164, -1
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds i16, i16* %5, i64 %166
  %168 = load i16, i16* %167, align 2
  %169 = zext i16 %168 to i32
  %170 = add nuw nsw i32 %147, 2
  %171 = add nuw nsw i32 %170, %163
  %172 = add nuw nsw i32 %171, %169
  %173 = lshr i32 %172, 2
  %174 = shl nuw nsw i32 %169, 1
  %175 = mul nsw i32 %7, 7
  %176 = add nsw i32 %175, -1
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds i16, i16* %5, i64 %177
  %179 = load i16, i16* %178, align 2
  %180 = zext i16 %179 to i32
  %181 = add nuw nsw i32 %158, 2
  %182 = add nuw nsw i32 %181, %174
  %183 = add nuw nsw i32 %182, %180
  %184 = lshr i32 %183, 2
  %185 = mul nuw nsw i32 %180, 3
  %186 = add nuw nsw i32 %169, 2
  %187 = add nuw nsw i32 %186, %185
  %188 = lshr i32 %187, 2
  %189 = load i16, i16* %101, align 2
  %190 = zext i16 %189 to i32
  %191 = shl nuw nsw i32 %190, 1
  %192 = add nuw nsw i32 %48, %108
  %193 = add nuw nsw i32 %192, %191
  %194 = lshr i32 %193, 2
  %195 = add nuw nsw i32 %184, 1
  %196 = add nuw nsw i32 %195, %188
  %197 = lshr i32 %196, 1
  %198 = trunc i32 %197 to i16
  %199 = sext i32 %175 to i64
  %200 = getelementptr inbounds i16, i16* %5, i64 %199
  store i16 %198, i16* %200, align 2
  %201 = shl nuw nsw i32 %184, 1
  %202 = add nuw nsw i32 %173, 2
  %203 = add nuw nsw i32 %202, %188
  %204 = add nuw nsw i32 %203, %201
  %205 = lshr i32 %204, 2
  %206 = trunc i32 %205 to i16
  %207 = add nsw i32 %175, 1
  %208 = sext i32 %207 to i64
  %209 = getelementptr inbounds i16, i16* %5, i64 %208
  store i16 %206, i16* %209, align 2
  %210 = add nuw nsw i32 %173, 1
  %211 = add nuw nsw i32 %210, %184
  %212 = lshr i32 %211, 1
  %213 = trunc i32 %212 to i16
  %214 = add nsw i32 %175, 2
  %215 = sext i32 %214 to i64
  %216 = getelementptr inbounds i16, i16* %5, i64 %215
  store i16 %213, i16* %216, align 2
  %217 = sext i32 %164 to i64
  %218 = getelementptr inbounds i16, i16* %5, i64 %217
  store i16 %213, i16* %218, align 2
  %219 = shl nuw nsw i32 %173, 1
  %220 = add nuw nsw i32 %162, 2
  %221 = add nuw nsw i32 %220, %219
  %222 = add nuw nsw i32 %221, %184
  %223 = lshr i32 %222, 2
  %224 = trunc i32 %223 to i16
  %225 = add nsw i32 %175, 3
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds i16, i16* %5, i64 %226
  store i16 %224, i16* %227, align 2
  %228 = or i32 %164, 1
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds i16, i16* %5, i64 %229
  store i16 %224, i16* %230, align 2
  %231 = add nuw nsw i32 %162, 1
  %232 = add nuw nsw i32 %231, %173
  %233 = lshr i32 %232, 1
  %234 = trunc i32 %233 to i16
  %235 = add nsw i32 %175, 4
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds i16, i16* %5, i64 %236
  store i16 %234, i16* %237, align 2
  %238 = add nsw i32 %164, 2
  %239 = sext i32 %238 to i64
  %240 = getelementptr inbounds i16, i16* %5, i64 %239
  store i16 %234, i16* %240, align 2
  %241 = sext i32 %153 to i64
  %242 = getelementptr inbounds i16, i16* %5, i64 %241
  store i16 %234, i16* %242, align 2
  %243 = shl nuw nsw i32 %162, 1
  %244 = add nuw nsw i32 %151, 2
  %245 = add nuw nsw i32 %244, %243
  %246 = add nuw nsw i32 %245, %173
  %247 = lshr i32 %246, 2
  %248 = trunc i32 %247 to i16
  %249 = add nsw i32 %175, 5
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds i16, i16* %5, i64 %250
  store i16 %248, i16* %251, align 2
  %252 = add nsw i32 %164, 3
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i16, i16* %5, i64 %253
  store i16 %248, i16* %254, align 2
  %255 = add nsw i32 %153, 1
  %256 = sext i32 %255 to i64
  %257 = getelementptr inbounds i16, i16* %5, i64 %256
  store i16 %248, i16* %257, align 2
  %258 = add nuw nsw i32 %151, 1
  %259 = add nuw nsw i32 %258, %162
  %260 = lshr i32 %259, 1
  %261 = trunc i32 %260 to i16
  %262 = add nsw i32 %175, 6
  %263 = sext i32 %262 to i64
  %264 = getelementptr inbounds i16, i16* %5, i64 %263
  store i16 %261, i16* %264, align 2
  %265 = add nsw i32 %164, 4
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds i16, i16* %5, i64 %266
  store i16 %261, i16* %267, align 2
  %268 = add nsw i32 %153, 2
  %269 = sext i32 %268 to i64
  %270 = getelementptr inbounds i16, i16* %5, i64 %269
  store i16 %261, i16* %270, align 2
  %271 = ashr exact i64 %142, 32
  %272 = getelementptr inbounds i16, i16* %5, i64 %271
  store i16 %261, i16* %272, align 2
  %273 = shl nuw nsw i32 %151, 1
  %274 = add nuw nsw i32 %140, 2
  %275 = add nuw nsw i32 %274, %273
  %276 = add nuw nsw i32 %275, %162
  %277 = lshr i32 %276, 2
  %278 = trunc i32 %277 to i16
  %279 = add nsw i32 %175, 7
  %280 = sext i32 %279 to i64
  %281 = getelementptr inbounds i16, i16* %5, i64 %280
  store i16 %278, i16* %281, align 2
  %282 = add nsw i32 %164, 5
  %283 = sext i32 %282 to i64
  %284 = getelementptr inbounds i16, i16* %5, i64 %283
  store i16 %278, i16* %284, align 2
  %285 = add nsw i32 %153, 3
  %286 = sext i32 %285 to i64
  %287 = getelementptr inbounds i16, i16* %5, i64 %286
  store i16 %278, i16* %287, align 2
  %288 = or i64 %271, 1
  %289 = getelementptr inbounds i16, i16* %5, i64 %288
  store i16 %278, i16* %289, align 2
  %290 = add nuw nsw i32 %140, 1
  %291 = add nuw nsw i32 %290, %151
  %292 = lshr i32 %291, 1
  %293 = trunc i32 %292 to i16
  %294 = add nsw i32 %164, 6
  %295 = sext i32 %294 to i64
  %296 = getelementptr inbounds i16, i16* %5, i64 %295
  store i16 %293, i16* %296, align 2
  %297 = add nsw i32 %153, 4
  %298 = sext i32 %297 to i64
  %299 = getelementptr inbounds i16, i16* %5, i64 %298
  store i16 %293, i16* %299, align 2
  %300 = or i64 %271, 2
  %301 = getelementptr inbounds i16, i16* %5, i64 %300
  store i16 %293, i16* %301, align 2
  %302 = sext i32 %132 to i64
  %303 = getelementptr inbounds i16, i16* %5, i64 %302
  store i16 %293, i16* %303, align 2
  %304 = shl nuw nsw i32 %140, 1
  %305 = add nuw nsw i32 %130, 2
  %306 = add nuw nsw i32 %305, %304
  %307 = add nuw nsw i32 %306, %151
  %308 = lshr i32 %307, 2
  %309 = trunc i32 %308 to i16
  %310 = add nsw i32 %164, 7
  %311 = sext i32 %310 to i64
  %312 = getelementptr inbounds i16, i16* %5, i64 %311
  store i16 %309, i16* %312, align 2
  %313 = add nsw i32 %153, 5
  %314 = sext i32 %313 to i64
  %315 = getelementptr inbounds i16, i16* %5, i64 %314
  store i16 %309, i16* %315, align 2
  %316 = or i64 %271, 3
  %317 = getelementptr inbounds i16, i16* %5, i64 %316
  store i16 %309, i16* %317, align 2
  %318 = add nsw i32 %132, 1
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %309, i16* %320, align 2
  %321 = add nuw nsw i32 %130, 1
  %322 = add nuw nsw i32 %321, %140
  %323 = lshr i32 %322, 1
  %324 = trunc i32 %323 to i16
  %325 = add nsw i32 %153, 6
  %326 = sext i32 %325 to i64
  %327 = getelementptr inbounds i16, i16* %5, i64 %326
  store i16 %324, i16* %327, align 2
  %328 = add i64 %142, 17179869184
  %329 = ashr exact i64 %328, 32
  %330 = getelementptr inbounds i16, i16* %5, i64 %329
  store i16 %324, i16* %330, align 2
  %331 = add nsw i32 %132, 2
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds i16, i16* %5, i64 %332
  store i16 %324, i16* %333, align 2
  %334 = sext i32 %121 to i64
  %335 = getelementptr inbounds i16, i16* %5, i64 %334
  store i16 %324, i16* %335, align 2
  %336 = shl nuw nsw i32 %130, 1
  %337 = add nuw nsw i32 %118, 2
  %338 = add nuw nsw i32 %337, %336
  %339 = add nuw nsw i32 %338, %140
  %340 = lshr i32 %339, 2
  %341 = trunc i32 %340 to i16
  %342 = add nsw i32 %153, 7
  %343 = sext i32 %342 to i64
  %344 = getelementptr inbounds i16, i16* %5, i64 %343
  store i16 %341, i16* %344, align 2
  %345 = add i64 %142, 21474836480
  %346 = ashr exact i64 %345, 32
  %347 = getelementptr inbounds i16, i16* %5, i64 %346
  store i16 %341, i16* %347, align 2
  %348 = add nsw i32 %132, 3
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i16, i16* %5, i64 %349
  store i16 %341, i16* %350, align 2
  %351 = shl i64 %3, 32
  %352 = ashr exact i64 %351, 32
  %353 = or i64 %352, 1
  %354 = getelementptr inbounds i16, i16* %5, i64 %353
  store i16 %341, i16* %354, align 2
  %355 = add nuw nsw i32 %118, 1
  %356 = add nuw nsw i32 %355, %130
  %357 = lshr i32 %356, 1
  %358 = trunc i32 %357 to i16
  %359 = add i64 %142, 25769803776
  %360 = ashr exact i64 %359, 32
  %361 = getelementptr inbounds i16, i16* %5, i64 %360
  store i16 %358, i16* %361, align 2
  %362 = add nsw i32 %132, 4
  %363 = sext i32 %362 to i64
  %364 = getelementptr inbounds i16, i16* %5, i64 %363
  store i16 %358, i16* %364, align 2
  %365 = add nsw i32 %121, 2
  %366 = sext i32 %365 to i64
  %367 = getelementptr inbounds i16, i16* %5, i64 %366
  store i16 %358, i16* %367, align 2
  %368 = getelementptr inbounds i16, i16* %5, i64 %22
  store i16 %358, i16* %368, align 2
  %369 = shl nuw nsw i32 %118, 1
  %370 = add nuw nsw i32 %305, %369
  %371 = add nuw nsw i32 %370, %194
  %372 = lshr i32 %371, 2
  %373 = trunc i32 %372 to i16
  %374 = add i64 %142, 30064771072
  %375 = ashr exact i64 %374, 32
  %376 = getelementptr inbounds i16, i16* %5, i64 %375
  store i16 %373, i16* %376, align 2
  %377 = add nsw i32 %132, 5
  %378 = sext i32 %377 to i64
  %379 = getelementptr inbounds i16, i16* %5, i64 %378
  store i16 %373, i16* %379, align 2
  %380 = add nsw i32 %121, 3
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i16, i16* %5, i64 %381
  store i16 %373, i16* %382, align 2
  %383 = add i64 %23, 4294967296
  %384 = ashr exact i64 %383, 32
  %385 = getelementptr inbounds i16, i16* %5, i64 %384
  store i16 %373, i16* %385, align 2
  %386 = add nuw nsw i32 %355, %194
  %387 = lshr i32 %386, 1
  %388 = trunc i32 %387 to i16
  %389 = add nsw i32 %132, 6
  %390 = sext i32 %389 to i64
  %391 = getelementptr inbounds i16, i16* %5, i64 %390
  store i16 %388, i16* %391, align 2
  %392 = add nsw i32 %121, 4
  %393 = sext i32 %392 to i64
  %394 = getelementptr inbounds i16, i16* %5, i64 %393
  store i16 %388, i16* %394, align 2
  %395 = add i64 %23, 8589934592
  %396 = ashr exact i64 %395, 32
  %397 = getelementptr inbounds i16, i16* %5, i64 %396
  store i16 %388, i16* %397, align 2
  store i16 %388, i16* %5, align 2
  %398 = shl nuw nsw i32 %194, 1
  %399 = add nuw nsw i32 %41, 2
  %400 = add nuw nsw i32 %399, %118
  %401 = add nuw nsw i32 %400, %398
  %402 = lshr i32 %401, 2
  %403 = trunc i32 %402 to i16
  %404 = add nsw i32 %132, 7
  %405 = sext i32 %404 to i64
  %406 = getelementptr inbounds i16, i16* %5, i64 %405
  store i16 %403, i16* %406, align 2
  %407 = add nsw i32 %121, 5
  %408 = sext i32 %407 to i64
  %409 = getelementptr inbounds i16, i16* %5, i64 %408
  store i16 %403, i16* %409, align 2
  %410 = add i64 %23, 12884901888
  %411 = ashr exact i64 %410, 32
  %412 = getelementptr inbounds i16, i16* %5, i64 %411
  store i16 %403, i16* %412, align 2
  %413 = getelementptr inbounds i8, i8* %0, i64 2
  %414 = bitcast i8* %413 to i16*
  store i16 %403, i16* %414, align 2
  %415 = shl nuw nsw i32 %41, 1
  %416 = add nuw nsw i32 %51, 2
  %417 = add nuw nsw i32 %416, %415
  %418 = add nuw nsw i32 %417, %194
  %419 = lshr i32 %418, 2
  %420 = trunc i32 %419 to i16
  %421 = add nsw i32 %121, 6
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds i16, i16* %5, i64 %422
  store i16 %420, i16* %423, align 2
  %424 = add i64 %23, 17179869184
  %425 = ashr exact i64 %424, 32
  %426 = getelementptr inbounds i16, i16* %5, i64 %425
  store i16 %420, i16* %426, align 2
  %427 = getelementptr inbounds i8, i8* %0, i64 4
  %428 = bitcast i8* %427 to i16*
  store i16 %420, i16* %428, align 2
  %429 = shl nuw nsw i32 %51, 1
  %430 = add nuw nsw i32 %399, %429
  %431 = add nuw nsw i32 %430, %60
  %432 = lshr i32 %431, 2
  %433 = trunc i32 %432 to i16
  %434 = add nsw i32 %121, 7
  %435 = sext i32 %434 to i64
  %436 = getelementptr inbounds i16, i16* %5, i64 %435
  store i16 %433, i16* %436, align 2
  %437 = add i64 %23, 21474836480
  %438 = ashr exact i64 %437, 32
  %439 = getelementptr inbounds i16, i16* %5, i64 %438
  store i16 %433, i16* %439, align 2
  %440 = getelementptr inbounds i8, i8* %0, i64 6
  %441 = bitcast i8* %440 to i16*
  store i16 %433, i16* %441, align 2
  %442 = shl nuw nsw i32 %60, 1
  %443 = add nuw nsw i32 %416, %442
  %444 = add nuw nsw i32 %443, %70
  %445 = lshr i32 %444, 2
  %446 = trunc i32 %445 to i16
  %447 = add i64 %23, 25769803776
  %448 = ashr exact i64 %447, 32
  %449 = getelementptr inbounds i16, i16* %5, i64 %448
  store i16 %446, i16* %449, align 2
  %450 = getelementptr inbounds i8, i8* %0, i64 8
  %451 = bitcast i8* %450 to i16*
  store i16 %446, i16* %451, align 2
  %452 = shl nuw nsw i32 %70, 1
  %453 = add nuw nsw i32 %60, 2
  %454 = add nuw nsw i32 %453, %452
  %455 = add nuw nsw i32 %454, %80
  %456 = lshr i32 %455, 2
  %457 = trunc i32 %456 to i16
  %458 = add i64 %23, 30064771072
  %459 = ashr exact i64 %458, 32
  %460 = getelementptr inbounds i16, i16* %5, i64 %459
  store i16 %457, i16* %460, align 2
  %461 = getelementptr inbounds i8, i8* %0, i64 10
  %462 = bitcast i8* %461 to i16*
  store i16 %457, i16* %462, align 2
  %463 = shl nuw nsw i32 %80, 1
  %464 = add nuw nsw i32 %70, 2
  %465 = add nuw nsw i32 %464, %463
  %466 = add nuw nsw i32 %465, %90
  %467 = lshr i32 %466, 2
  %468 = trunc i32 %467 to i16
  %469 = getelementptr inbounds i8, i8* %0, i64 12
  %470 = bitcast i8* %469 to i16*
  store i16 %468, i16* %470, align 2
  %471 = shl nuw nsw i32 %90, 1
  %472 = add nuw nsw i32 %80, 2
  %473 = add nuw nsw i32 %472, %471
  %474 = add nuw nsw i32 %473, %100
  %475 = lshr i32 %474, 2
  %476 = trunc i32 %475 to i16
  %477 = getelementptr inbounds i8, i8* %0, i64 14
  %478 = bitcast i8* %477 to i16*
  store i16 %476, i16* %478, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_left_14_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %97, label %99

97:                                               ; preds = %18
  %98 = mul nuw nsw i32 %91, 3
  br label %156

99:                                               ; preds = %18
  %100 = sub i64 34359738368, %19
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %5, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i32
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %105, %104
  %107 = shl nuw nsw i32 %104, 1
  %108 = sub i64 38654705664, %19
  %109 = ashr exact i64 %108, 32
  %110 = getelementptr inbounds i16, i16* %5, i64 %109
  %111 = load i16, i16* %110, align 2
  %112 = zext i16 %111 to i32
  %113 = add nuw nsw i32 %91, 2
  %114 = add nuw nsw i32 %113, %107
  %115 = add nuw nsw i32 %114, %112
  %116 = lshr i32 %115, 2
  %117 = shl nuw nsw i32 %112, 1
  %118 = sub i64 42949672960, %19
  %119 = ashr exact i64 %118, 32
  %120 = getelementptr inbounds i16, i16* %5, i64 %119
  %121 = load i16, i16* %120, align 2
  %122 = zext i16 %121 to i32
  %123 = add nuw nsw i32 %122, 2
  %124 = add nuw nsw i32 %123, %104
  %125 = add nuw nsw i32 %124, %117
  %126 = lshr i32 %125, 2
  %127 = shl nuw nsw i32 %122, 1
  %128 = sub i64 47244640256, %19
  %129 = ashr exact i64 %128, 32
  %130 = getelementptr inbounds i16, i16* %5, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i32
  %133 = add nuw nsw i32 %112, 2
  %134 = add nuw nsw i32 %133, %127
  %135 = add nuw nsw i32 %134, %132
  %136 = lshr i32 %135, 2
  %137 = shl nuw nsw i32 %132, 1
  %138 = sub i64 51539607552, %19
  %139 = ashr exact i64 %138, 32
  %140 = getelementptr inbounds i16, i16* %5, i64 %139
  %141 = load i16, i16* %140, align 2
  %142 = zext i16 %141 to i32
  %143 = add nuw nsw i32 %123, %137
  %144 = add nuw nsw i32 %143, %142
  %145 = lshr i32 %144, 2
  %146 = shl nuw nsw i32 %142, 1
  %147 = sub i64 55834574848, %19
  %148 = ashr exact i64 %147, 32
  %149 = getelementptr inbounds i16, i16* %5, i64 %148
  %150 = load i16, i16* %149, align 2
  %151 = zext i16 %150 to i32
  %152 = add nuw nsw i32 %132, 2
  %153 = add nuw nsw i32 %152, %146
  %154 = add nuw nsw i32 %153, %151
  %155 = lshr i32 %154, 2
  br label %156

156:                                              ; preds = %97, %99
  %157 = phi i32 [ %106, %99 ], [ %98, %97 ]
  %158 = phi i32 [ %116, %99 ], [ %91, %97 ]
  %159 = phi i32 [ %126, %99 ], [ %91, %97 ]
  %160 = phi i32 [ %136, %99 ], [ %91, %97 ]
  %161 = phi i32 [ %145, %99 ], [ %91, %97 ]
  %162 = phi i32 [ %155, %99 ], [ %91, %97 ]
  %163 = add nuw nsw i32 %81, 2
  %164 = add nuw nsw i32 %163, %157
  %165 = lshr i32 %164, 2
  %166 = add nuw nsw i32 %47, 1
  %167 = add nuw nsw i32 %166, %37
  %168 = lshr i32 %167, 1
  %169 = trunc i32 %168 to i16
  store i16 %169, i16* %5, align 2
  %170 = shl nuw nsw i32 %47, 1
  %171 = add nuw nsw i32 %56, 2
  %172 = add nuw nsw i32 %171, %37
  %173 = add nuw nsw i32 %172, %170
  %174 = lshr i32 %173, 2
  %175 = trunc i32 %174 to i16
  %176 = ashr exact i64 %19, 32
  %177 = getelementptr inbounds i16, i16* %5, i64 %176
  store i16 %175, i16* %177, align 2
  %178 = add nuw nsw i32 %166, %56
  %179 = lshr i32 %178, 1
  %180 = trunc i32 %179 to i16
  %181 = getelementptr inbounds i8, i8* %0, i64 2
  %182 = bitcast i8* %181 to i16*
  store i16 %180, i16* %182, align 2
  %183 = trunc i64 %3 to i32
  %184 = and i32 %183, -2
  %185 = sext i32 %184 to i64
  %186 = getelementptr inbounds i16, i16* %5, i64 %185
  store i16 %180, i16* %186, align 2
  %187 = shl nuw nsw i32 %56, 1
  %188 = add nuw nsw i32 %65, 2
  %189 = add nuw nsw i32 %188, %47
  %190 = add nuw nsw i32 %189, %187
  %191 = lshr i32 %190, 2
  %192 = trunc i32 %191 to i16
  %193 = add i64 %19, 4294967296
  %194 = ashr exact i64 %193, 32
  %195 = getelementptr inbounds i16, i16* %5, i64 %194
  store i16 %192, i16* %195, align 2
  %196 = mul nsw i32 %7, 3
  %197 = sext i32 %196 to i64
  %198 = getelementptr inbounds i16, i16* %5, i64 %197
  store i16 %192, i16* %198, align 2
  %199 = add nuw nsw i32 %56, 1
  %200 = add nuw nsw i32 %199, %65
  %201 = lshr i32 %200, 1
  %202 = trunc i32 %201 to i16
  %203 = getelementptr inbounds i8, i8* %0, i64 4
  %204 = bitcast i8* %203 to i16*
  store i16 %202, i16* %204, align 2
  %205 = shl i64 %3, 32
  %206 = ashr exact i64 %205, 32
  %207 = or i64 %206, 1
  %208 = getelementptr inbounds i16, i16* %5, i64 %207
  store i16 %202, i16* %208, align 2
  %209 = shl i64 %6, 34
  %210 = ashr exact i64 %209, 32
  %211 = getelementptr inbounds i16, i16* %5, i64 %210
  store i16 %202, i16* %211, align 2
  %212 = shl nuw nsw i32 %65, 1
  %213 = add nuw nsw i32 %171, %212
  %214 = add nuw nsw i32 %213, %75
  %215 = lshr i32 %214, 2
  %216 = trunc i32 %215 to i16
  %217 = add i64 %19, 8589934592
  %218 = ashr exact i64 %217, 32
  %219 = getelementptr inbounds i16, i16* %5, i64 %218
  store i16 %216, i16* %219, align 2
  %220 = add nsw i32 %196, 1
  %221 = sext i32 %220 to i64
  %222 = getelementptr inbounds i16, i16* %5, i64 %221
  store i16 %216, i16* %222, align 2
  %223 = mul nsw i32 %7, 5
  %224 = sext i32 %223 to i64
  %225 = getelementptr inbounds i16, i16* %5, i64 %224
  store i16 %216, i16* %225, align 2
  %226 = add nuw nsw i32 %65, 1
  %227 = add nuw nsw i32 %226, %75
  %228 = lshr i32 %227, 1
  %229 = trunc i32 %228 to i16
  %230 = getelementptr inbounds i8, i8* %0, i64 6
  %231 = bitcast i8* %230 to i16*
  store i16 %229, i16* %231, align 2
  %232 = add nsw i32 %184, 2
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds i16, i16* %5, i64 %233
  store i16 %229, i16* %234, align 2
  %235 = or i64 %210, 1
  %236 = getelementptr inbounds i16, i16* %5, i64 %235
  store i16 %229, i16* %236, align 2
  %237 = mul nsw i32 %7, 6
  %238 = sext i32 %237 to i64
  %239 = getelementptr inbounds i16, i16* %5, i64 %238
  store i16 %229, i16* %239, align 2
  %240 = shl nuw nsw i32 %75, 1
  %241 = add nuw nsw i32 %188, %240
  %242 = add nuw nsw i32 %241, %85
  %243 = lshr i32 %242, 2
  %244 = trunc i32 %243 to i16
  %245 = add i64 %19, 12884901888
  %246 = ashr exact i64 %245, 32
  %247 = getelementptr inbounds i16, i16* %5, i64 %246
  store i16 %244, i16* %247, align 2
  %248 = add nsw i32 %196, 2
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i16, i16* %5, i64 %249
  store i16 %244, i16* %250, align 2
  %251 = add nsw i32 %223, 1
  %252 = sext i32 %251 to i64
  %253 = getelementptr inbounds i16, i16* %5, i64 %252
  store i16 %244, i16* %253, align 2
  %254 = mul nsw i32 %7, 7
  %255 = sext i32 %254 to i64
  %256 = getelementptr inbounds i16, i16* %5, i64 %255
  store i16 %244, i16* %256, align 2
  %257 = add nuw nsw i32 %75, 1
  %258 = add nuw nsw i32 %257, %85
  %259 = lshr i32 %258, 1
  %260 = trunc i32 %259 to i16
  %261 = getelementptr inbounds i8, i8* %0, i64 8
  %262 = bitcast i8* %261 to i16*
  store i16 %260, i16* %262, align 2
  %263 = add nsw i32 %184, 3
  %264 = sext i32 %263 to i64
  %265 = getelementptr inbounds i16, i16* %5, i64 %264
  store i16 %260, i16* %265, align 2
  %266 = or i64 %210, 2
  %267 = getelementptr inbounds i16, i16* %5, i64 %266
  store i16 %260, i16* %267, align 2
  %268 = or i32 %237, 1
  %269 = sext i32 %268 to i64
  %270 = getelementptr inbounds i16, i16* %5, i64 %269
  store i16 %260, i16* %270, align 2
  %271 = shl nuw nsw i32 %85, 1
  %272 = add nuw nsw i32 %75, 2
  %273 = add nuw nsw i32 %272, %271
  %274 = add nuw nsw i32 %273, %95
  %275 = lshr i32 %274, 2
  %276 = trunc i32 %275 to i16
  %277 = add i64 %19, 17179869184
  %278 = ashr exact i64 %277, 32
  %279 = getelementptr inbounds i16, i16* %5, i64 %278
  store i16 %276, i16* %279, align 2
  %280 = add nsw i32 %196, 3
  %281 = sext i32 %280 to i64
  %282 = getelementptr inbounds i16, i16* %5, i64 %281
  store i16 %276, i16* %282, align 2
  %283 = add nsw i32 %223, 2
  %284 = sext i32 %283 to i64
  %285 = getelementptr inbounds i16, i16* %5, i64 %284
  store i16 %276, i16* %285, align 2
  %286 = add nsw i32 %254, 1
  %287 = sext i32 %286 to i64
  %288 = getelementptr inbounds i16, i16* %5, i64 %287
  store i16 %276, i16* %288, align 2
  %289 = add nuw nsw i32 %85, 1
  %290 = add nuw nsw i32 %289, %95
  %291 = lshr i32 %290, 1
  %292 = trunc i32 %291 to i16
  %293 = getelementptr inbounds i8, i8* %0, i64 10
  %294 = bitcast i8* %293 to i16*
  store i16 %292, i16* %294, align 2
  %295 = add nsw i32 %184, 4
  %296 = sext i32 %295 to i64
  %297 = getelementptr inbounds i16, i16* %5, i64 %296
  store i16 %292, i16* %297, align 2
  %298 = or i64 %210, 3
  %299 = getelementptr inbounds i16, i16* %5, i64 %298
  store i16 %292, i16* %299, align 2
  %300 = add nsw i32 %237, 2
  %301 = sext i32 %300 to i64
  %302 = getelementptr inbounds i16, i16* %5, i64 %301
  store i16 %292, i16* %302, align 2
  %303 = shl nuw nsw i32 %95, 1
  %304 = add nuw nsw i32 %85, 2
  %305 = add nuw nsw i32 %304, %303
  %306 = add nuw nsw i32 %305, %165
  %307 = lshr i32 %306, 2
  %308 = trunc i32 %307 to i16
  %309 = add i64 %19, 21474836480
  %310 = ashr exact i64 %309, 32
  %311 = getelementptr inbounds i16, i16* %5, i64 %310
  store i16 %308, i16* %311, align 2
  %312 = add nsw i32 %196, 4
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds i16, i16* %5, i64 %313
  store i16 %308, i16* %314, align 2
  %315 = add nsw i32 %223, 3
  %316 = sext i32 %315 to i64
  %317 = getelementptr inbounds i16, i16* %5, i64 %316
  store i16 %308, i16* %317, align 2
  %318 = add nsw i32 %254, 2
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %308, i16* %320, align 2
  %321 = add nuw nsw i32 %95, 1
  %322 = add nuw nsw i32 %321, %165
  %323 = lshr i32 %322, 1
  %324 = trunc i32 %323 to i16
  %325 = getelementptr inbounds i8, i8* %0, i64 12
  %326 = bitcast i8* %325 to i16*
  store i16 %324, i16* %326, align 2
  %327 = add nsw i32 %184, 5
  %328 = sext i32 %327 to i64
  %329 = getelementptr inbounds i16, i16* %5, i64 %328
  store i16 %324, i16* %329, align 2
  %330 = add i64 %209, 17179869184
  %331 = ashr exact i64 %330, 32
  %332 = getelementptr inbounds i16, i16* %5, i64 %331
  store i16 %324, i16* %332, align 2
  %333 = add nsw i32 %237, 3
  %334 = sext i32 %333 to i64
  %335 = getelementptr inbounds i16, i16* %5, i64 %334
  store i16 %324, i16* %335, align 2
  %336 = shl nuw nsw i32 %165, 1
  %337 = add nuw nsw i32 %95, 2
  %338 = add nuw nsw i32 %337, %158
  %339 = add nuw nsw i32 %338, %336
  %340 = lshr i32 %339, 2
  %341 = trunc i32 %340 to i16
  %342 = add i64 %19, 25769803776
  %343 = ashr exact i64 %342, 32
  %344 = getelementptr inbounds i16, i16* %5, i64 %343
  store i16 %341, i16* %344, align 2
  %345 = add nsw i32 %196, 5
  %346 = sext i32 %345 to i64
  %347 = getelementptr inbounds i16, i16* %5, i64 %346
  store i16 %341, i16* %347, align 2
  %348 = add nsw i32 %223, 4
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i16, i16* %5, i64 %349
  store i16 %341, i16* %350, align 2
  %351 = add nsw i32 %254, 3
  %352 = sext i32 %351 to i64
  %353 = getelementptr inbounds i16, i16* %5, i64 %352
  store i16 %341, i16* %353, align 2
  %354 = add nuw nsw i32 %158, 1
  %355 = add nuw nsw i32 %354, %165
  %356 = lshr i32 %355, 1
  %357 = trunc i32 %356 to i16
  %358 = getelementptr inbounds i8, i8* %0, i64 14
  %359 = bitcast i8* %358 to i16*
  store i16 %357, i16* %359, align 2
  %360 = add nsw i32 %184, 6
  %361 = sext i32 %360 to i64
  %362 = getelementptr inbounds i16, i16* %5, i64 %361
  store i16 %357, i16* %362, align 2
  %363 = add i64 %209, 21474836480
  %364 = ashr exact i64 %363, 32
  %365 = getelementptr inbounds i16, i16* %5, i64 %364
  store i16 %357, i16* %365, align 2
  %366 = add nsw i32 %237, 4
  %367 = sext i32 %366 to i64
  %368 = getelementptr inbounds i16, i16* %5, i64 %367
  store i16 %357, i16* %368, align 2
  %369 = shl nuw nsw i32 %158, 1
  %370 = add nuw nsw i32 %165, 2
  %371 = add nuw nsw i32 %370, %159
  %372 = add nuw nsw i32 %371, %369
  %373 = lshr i32 %372, 2
  %374 = trunc i32 %373 to i16
  %375 = add i64 %19, 30064771072
  %376 = ashr exact i64 %375, 32
  %377 = getelementptr inbounds i16, i16* %5, i64 %376
  store i16 %374, i16* %377, align 2
  %378 = add nsw i32 %196, 6
  %379 = sext i32 %378 to i64
  %380 = getelementptr inbounds i16, i16* %5, i64 %379
  store i16 %374, i16* %380, align 2
  %381 = add nsw i32 %223, 5
  %382 = sext i32 %381 to i64
  %383 = getelementptr inbounds i16, i16* %5, i64 %382
  store i16 %374, i16* %383, align 2
  %384 = add nsw i32 %254, 4
  %385 = sext i32 %384 to i64
  %386 = getelementptr inbounds i16, i16* %5, i64 %385
  store i16 %374, i16* %386, align 2
  %387 = add nuw nsw i32 %354, %159
  %388 = lshr i32 %387, 1
  %389 = trunc i32 %388 to i16
  %390 = add nsw i32 %184, 7
  %391 = sext i32 %390 to i64
  %392 = getelementptr inbounds i16, i16* %5, i64 %391
  store i16 %389, i16* %392, align 2
  %393 = add i64 %209, 25769803776
  %394 = ashr exact i64 %393, 32
  %395 = getelementptr inbounds i16, i16* %5, i64 %394
  store i16 %389, i16* %395, align 2
  %396 = add nsw i32 %237, 5
  %397 = sext i32 %396 to i64
  %398 = getelementptr inbounds i16, i16* %5, i64 %397
  store i16 %389, i16* %398, align 2
  %399 = shl nuw nsw i32 %159, 1
  %400 = add nuw nsw i32 %158, 2
  %401 = add nuw nsw i32 %400, %399
  %402 = add nuw nsw i32 %401, %160
  %403 = lshr i32 %402, 2
  %404 = trunc i32 %403 to i16
  %405 = add nsw i32 %196, 7
  %406 = sext i32 %405 to i64
  %407 = getelementptr inbounds i16, i16* %5, i64 %406
  store i16 %404, i16* %407, align 2
  %408 = add nsw i32 %223, 6
  %409 = sext i32 %408 to i64
  %410 = getelementptr inbounds i16, i16* %5, i64 %409
  store i16 %404, i16* %410, align 2
  %411 = add nsw i32 %254, 5
  %412 = sext i32 %411 to i64
  %413 = getelementptr inbounds i16, i16* %5, i64 %412
  store i16 %404, i16* %413, align 2
  %414 = add nuw nsw i32 %159, 1
  %415 = add nuw nsw i32 %414, %160
  %416 = lshr i32 %415, 1
  %417 = trunc i32 %416 to i16
  %418 = add i64 %209, 30064771072
  %419 = ashr exact i64 %418, 32
  %420 = getelementptr inbounds i16, i16* %5, i64 %419
  store i16 %417, i16* %420, align 2
  %421 = add nsw i32 %237, 6
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds i16, i16* %5, i64 %422
  store i16 %417, i16* %423, align 2
  %424 = shl nuw nsw i32 %160, 1
  %425 = add nuw nsw i32 %159, 2
  %426 = add nuw nsw i32 %425, %424
  %427 = add nuw nsw i32 %426, %161
  %428 = lshr i32 %427, 2
  %429 = trunc i32 %428 to i16
  %430 = add nsw i32 %223, 7
  %431 = sext i32 %430 to i64
  %432 = getelementptr inbounds i16, i16* %5, i64 %431
  store i16 %429, i16* %432, align 2
  %433 = add nsw i32 %254, 6
  %434 = sext i32 %433 to i64
  %435 = getelementptr inbounds i16, i16* %5, i64 %434
  store i16 %429, i16* %435, align 2
  %436 = add nuw nsw i32 %160, 1
  %437 = add nuw nsw i32 %436, %161
  %438 = lshr i32 %437, 1
  %439 = trunc i32 %438 to i16
  %440 = add nsw i32 %237, 7
  %441 = sext i32 %440 to i64
  %442 = getelementptr inbounds i16, i16* %5, i64 %441
  store i16 %439, i16* %442, align 2
  %443 = shl nuw nsw i32 %161, 1
  %444 = add nuw nsw i32 %160, 2
  %445 = add nuw nsw i32 %444, %443
  %446 = add nuw nsw i32 %445, %162
  %447 = lshr i32 %446, 2
  %448 = trunc i32 %447 to i16
  %449 = add nsw i32 %254, 7
  %450 = sext i32 %449 to i64
  %451 = getelementptr inbounds i16, i16* %5, i64 %450
  store i16 %448, i16* %451, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_up_14_c(i8*, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  br i1 %8, label %14, label %9

9:                                                ; preds = %4
  %10 = shl i64 %6, 32
  %11 = ashr exact i64 %10, 32
  %12 = xor i64 %11, -1
  %13 = getelementptr inbounds i16, i16* %5, i64 %12
  br label %19

14:                                               ; preds = %4
  %15 = getelementptr inbounds i8, i8* %0, i64 -2
  %16 = bitcast i8* %15 to i16*
  %17 = shl i64 %6, 32
  %18 = ashr exact i64 %17, 32
  br label %19

19:                                               ; preds = %14, %9
  %20 = phi i64 [ %18, %14 ], [ %11, %9 ]
  %21 = phi i64 [ %17, %14 ], [ %10, %9 ]
  %22 = phi i16* [ %16, %14 ], [ %13, %9 ]
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i8, i8* %0, i64 -2
  %26 = bitcast i8* %25 to i16*
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i32
  %29 = shl nuw nsw i32 %28, 1
  %30 = add i64 %21, -4294967296
  %31 = ashr exact i64 %30, 32
  %32 = getelementptr inbounds i16, i16* %5, i64 %31
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i32
  %35 = add nuw nsw i32 %34, 2
  %36 = add nuw nsw i32 %35, %24
  %37 = add nuw nsw i32 %36, %29
  %38 = lshr i32 %37, 2
  %39 = shl nuw nsw i32 %34, 1
  %40 = trunc i64 %3 to i32
  %41 = and i32 %40, -2
  %42 = add nsw i32 %41, -1
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i16, i16* %5, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %28
  %49 = add nuw nsw i32 %48, %39
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = mul nsw i32 %7, 3
  %53 = add nsw i32 %52, -1
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i16, i16* %5, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i32
  %58 = add nuw nsw i32 %35, %51
  %59 = add nuw nsw i32 %58, %57
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %57, 1
  %62 = shl i64 %6, 34
  %63 = add i64 %62, -4294967296
  %64 = ashr exact i64 %63, 32
  %65 = getelementptr inbounds i16, i16* %5, i64 %64
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = add nuw nsw i32 %47, %61
  %69 = add nuw nsw i32 %68, %67
  %70 = lshr i32 %69, 2
  %71 = shl nuw nsw i32 %67, 1
  %72 = mul nsw i32 %7, 5
  %73 = add nsw i32 %72, -1
  %74 = sext i32 %73 to i64
  %75 = getelementptr inbounds i16, i16* %5, i64 %74
  %76 = load i16, i16* %75, align 2
  %77 = zext i16 %76 to i32
  %78 = add nuw nsw i32 %57, 2
  %79 = add nuw nsw i32 %78, %71
  %80 = add nuw nsw i32 %79, %77
  %81 = lshr i32 %80, 2
  %82 = shl nuw nsw i32 %77, 1
  %83 = mul nsw i32 %7, 6
  %84 = add nsw i32 %83, -1
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i16, i16* %5, i64 %85
  %87 = load i16, i16* %86, align 2
  %88 = zext i16 %87 to i32
  %89 = add nuw nsw i32 %67, 2
  %90 = add nuw nsw i32 %89, %82
  %91 = add nuw nsw i32 %90, %88
  %92 = lshr i32 %91, 2
  %93 = shl nuw nsw i32 %88, 1
  %94 = mul nsw i32 %7, 7
  %95 = add nsw i32 %94, -1
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i16, i16* %5, i64 %96
  %98 = load i16, i16* %97, align 2
  %99 = zext i16 %98 to i32
  %100 = add nuw nsw i32 %77, 2
  %101 = add nuw nsw i32 %100, %93
  %102 = add nuw nsw i32 %101, %99
  %103 = lshr i32 %102, 2
  %104 = mul nuw nsw i32 %99, 3
  %105 = add nuw nsw i32 %88, 2
  %106 = add nuw nsw i32 %105, %104
  %107 = lshr i32 %106, 2
  %108 = add nuw nsw i32 %50, 1
  %109 = add nuw nsw i32 %108, %38
  %110 = lshr i32 %109, 1
  %111 = trunc i32 %110 to i16
  store i16 %111, i16* %5, align 2
  %112 = shl nuw nsw i32 %50, 1
  %113 = add nuw nsw i32 %60, 2
  %114 = add nuw nsw i32 %113, %38
  %115 = add nuw nsw i32 %114, %112
  %116 = lshr i32 %115, 2
  %117 = trunc i32 %116 to i16
  %118 = getelementptr inbounds i8, i8* %0, i64 2
  %119 = bitcast i8* %118 to i16*
  store i16 %117, i16* %119, align 2
  %120 = add nuw nsw i32 %108, %60
  %121 = lshr i32 %120, 1
  %122 = trunc i32 %121 to i16
  %123 = getelementptr inbounds i8, i8* %0, i64 4
  %124 = bitcast i8* %123 to i16*
  store i16 %122, i16* %124, align 2
  %125 = getelementptr inbounds i16, i16* %5, i64 %20
  store i16 %122, i16* %125, align 2
  %126 = shl nuw nsw i32 %60, 1
  %127 = add nuw nsw i32 %70, 2
  %128 = add nuw nsw i32 %127, %50
  %129 = add nuw nsw i32 %128, %126
  %130 = lshr i32 %129, 2
  %131 = trunc i32 %130 to i16
  %132 = getelementptr inbounds i8, i8* %0, i64 6
  %133 = bitcast i8* %132 to i16*
  store i16 %131, i16* %133, align 2
  %134 = add i64 %21, 4294967296
  %135 = ashr exact i64 %134, 32
  %136 = getelementptr inbounds i16, i16* %5, i64 %135
  store i16 %131, i16* %136, align 2
  %137 = add nuw nsw i32 %60, 1
  %138 = add nuw nsw i32 %137, %70
  %139 = lshr i32 %138, 1
  %140 = trunc i32 %139 to i16
  %141 = getelementptr inbounds i8, i8* %0, i64 8
  %142 = bitcast i8* %141 to i16*
  store i16 %140, i16* %142, align 2
  %143 = add i64 %21, 8589934592
  %144 = ashr exact i64 %143, 32
  %145 = getelementptr inbounds i16, i16* %5, i64 %144
  store i16 %140, i16* %145, align 2
  %146 = sext i32 %41 to i64
  %147 = getelementptr inbounds i16, i16* %5, i64 %146
  store i16 %140, i16* %147, align 2
  %148 = shl nuw nsw i32 %70, 1
  %149 = add nuw nsw i32 %113, %148
  %150 = add nuw nsw i32 %149, %81
  %151 = lshr i32 %150, 2
  %152 = trunc i32 %151 to i16
  %153 = getelementptr inbounds i8, i8* %0, i64 10
  %154 = bitcast i8* %153 to i16*
  store i16 %152, i16* %154, align 2
  %155 = add i64 %21, 12884901888
  %156 = ashr exact i64 %155, 32
  %157 = getelementptr inbounds i16, i16* %5, i64 %156
  store i16 %152, i16* %157, align 2
  %158 = shl i64 %3, 32
  %159 = ashr exact i64 %158, 32
  %160 = or i64 %159, 1
  %161 = getelementptr inbounds i16, i16* %5, i64 %160
  store i16 %152, i16* %161, align 2
  %162 = add nuw nsw i32 %70, 1
  %163 = add nuw nsw i32 %162, %81
  %164 = lshr i32 %163, 1
  %165 = trunc i32 %164 to i16
  %166 = getelementptr inbounds i8, i8* %0, i64 12
  %167 = bitcast i8* %166 to i16*
  store i16 %165, i16* %167, align 2
  %168 = add i64 %21, 17179869184
  %169 = ashr exact i64 %168, 32
  %170 = getelementptr inbounds i16, i16* %5, i64 %169
  store i16 %165, i16* %170, align 2
  %171 = add nsw i32 %41, 2
  %172 = sext i32 %171 to i64
  %173 = getelementptr inbounds i16, i16* %5, i64 %172
  store i16 %165, i16* %173, align 2
  %174 = sext i32 %52 to i64
  %175 = getelementptr inbounds i16, i16* %5, i64 %174
  store i16 %165, i16* %175, align 2
  %176 = shl nuw nsw i32 %81, 1
  %177 = add nuw nsw i32 %127, %176
  %178 = add nuw nsw i32 %177, %92
  %179 = lshr i32 %178, 2
  %180 = trunc i32 %179 to i16
  %181 = getelementptr inbounds i8, i8* %0, i64 14
  %182 = bitcast i8* %181 to i16*
  store i16 %180, i16* %182, align 2
  %183 = add i64 %21, 21474836480
  %184 = ashr exact i64 %183, 32
  %185 = getelementptr inbounds i16, i16* %5, i64 %184
  store i16 %180, i16* %185, align 2
  %186 = add nsw i32 %41, 3
  %187 = sext i32 %186 to i64
  %188 = getelementptr inbounds i16, i16* %5, i64 %187
  store i16 %180, i16* %188, align 2
  %189 = add nsw i32 %52, 1
  %190 = sext i32 %189 to i64
  %191 = getelementptr inbounds i16, i16* %5, i64 %190
  store i16 %180, i16* %191, align 2
  %192 = add nuw nsw i32 %81, 1
  %193 = add nuw nsw i32 %192, %92
  %194 = lshr i32 %193, 1
  %195 = trunc i32 %194 to i16
  %196 = add i64 %21, 25769803776
  %197 = ashr exact i64 %196, 32
  %198 = getelementptr inbounds i16, i16* %5, i64 %197
  store i16 %195, i16* %198, align 2
  %199 = add nsw i32 %41, 4
  %200 = sext i32 %199 to i64
  %201 = getelementptr inbounds i16, i16* %5, i64 %200
  store i16 %195, i16* %201, align 2
  %202 = add nsw i32 %52, 2
  %203 = sext i32 %202 to i64
  %204 = getelementptr inbounds i16, i16* %5, i64 %203
  store i16 %195, i16* %204, align 2
  %205 = ashr exact i64 %62, 32
  %206 = getelementptr inbounds i16, i16* %5, i64 %205
  store i16 %195, i16* %206, align 2
  %207 = shl nuw nsw i32 %92, 1
  %208 = add nuw nsw i32 %81, 2
  %209 = add nuw nsw i32 %208, %207
  %210 = add nuw nsw i32 %209, %103
  %211 = lshr i32 %210, 2
  %212 = trunc i32 %211 to i16
  %213 = add i64 %21, 30064771072
  %214 = ashr exact i64 %213, 32
  %215 = getelementptr inbounds i16, i16* %5, i64 %214
  store i16 %212, i16* %215, align 2
  %216 = add nsw i32 %41, 5
  %217 = sext i32 %216 to i64
  %218 = getelementptr inbounds i16, i16* %5, i64 %217
  store i16 %212, i16* %218, align 2
  %219 = add nsw i32 %52, 3
  %220 = sext i32 %219 to i64
  %221 = getelementptr inbounds i16, i16* %5, i64 %220
  store i16 %212, i16* %221, align 2
  %222 = or i64 %205, 1
  %223 = getelementptr inbounds i16, i16* %5, i64 %222
  store i16 %212, i16* %223, align 2
  %224 = add nuw nsw i32 %92, 1
  %225 = add nuw nsw i32 %224, %103
  %226 = lshr i32 %225, 1
  %227 = trunc i32 %226 to i16
  %228 = add nsw i32 %41, 6
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds i16, i16* %5, i64 %229
  store i16 %227, i16* %230, align 2
  %231 = add nsw i32 %52, 4
  %232 = sext i32 %231 to i64
  %233 = getelementptr inbounds i16, i16* %5, i64 %232
  store i16 %227, i16* %233, align 2
  %234 = or i64 %205, 2
  %235 = getelementptr inbounds i16, i16* %5, i64 %234
  store i16 %227, i16* %235, align 2
  %236 = sext i32 %72 to i64
  %237 = getelementptr inbounds i16, i16* %5, i64 %236
  store i16 %227, i16* %237, align 2
  %238 = shl nuw nsw i32 %103, 1
  %239 = add nuw nsw i32 %92, 2
  %240 = add nuw nsw i32 %239, %107
  %241 = add nuw nsw i32 %240, %238
  %242 = lshr i32 %241, 2
  %243 = trunc i32 %242 to i16
  %244 = add nsw i32 %41, 7
  %245 = sext i32 %244 to i64
  %246 = getelementptr inbounds i16, i16* %5, i64 %245
  store i16 %243, i16* %246, align 2
  %247 = add nsw i32 %52, 5
  %248 = sext i32 %247 to i64
  %249 = getelementptr inbounds i16, i16* %5, i64 %248
  store i16 %243, i16* %249, align 2
  %250 = or i64 %205, 3
  %251 = getelementptr inbounds i16, i16* %5, i64 %250
  store i16 %243, i16* %251, align 2
  %252 = add nsw i32 %72, 1
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i16, i16* %5, i64 %253
  store i16 %243, i16* %254, align 2
  %255 = add nuw nsw i32 %103, 1
  %256 = add nuw nsw i32 %255, %107
  %257 = lshr i32 %256, 1
  %258 = trunc i32 %257 to i16
  %259 = add nsw i32 %52, 6
  %260 = sext i32 %259 to i64
  %261 = getelementptr inbounds i16, i16* %5, i64 %260
  store i16 %258, i16* %261, align 2
  %262 = add i64 %62, 17179869184
  %263 = ashr exact i64 %262, 32
  %264 = getelementptr inbounds i16, i16* %5, i64 %263
  store i16 %258, i16* %264, align 2
  %265 = add nsw i32 %72, 2
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds i16, i16* %5, i64 %266
  store i16 %258, i16* %267, align 2
  %268 = sext i32 %83 to i64
  %269 = getelementptr inbounds i16, i16* %5, i64 %268
  store i16 %258, i16* %269, align 2
  %270 = mul nuw nsw i32 %107, 3
  %271 = add nuw nsw i32 %103, 2
  %272 = add nuw nsw i32 %271, %270
  %273 = lshr i32 %272, 2
  %274 = trunc i32 %273 to i16
  %275 = add nsw i32 %52, 7
  %276 = sext i32 %275 to i64
  %277 = getelementptr inbounds i16, i16* %5, i64 %276
  store i16 %274, i16* %277, align 2
  %278 = add i64 %62, 21474836480
  %279 = ashr exact i64 %278, 32
  %280 = getelementptr inbounds i16, i16* %5, i64 %279
  store i16 %274, i16* %280, align 2
  %281 = add nsw i32 %72, 3
  %282 = sext i32 %281 to i64
  %283 = getelementptr inbounds i16, i16* %5, i64 %282
  store i16 %274, i16* %283, align 2
  %284 = or i32 %83, 1
  %285 = sext i32 %284 to i64
  %286 = getelementptr inbounds i16, i16* %5, i64 %285
  store i16 %274, i16* %286, align 2
  %287 = trunc i32 %107 to i16
  %288 = add nsw i32 %94, 7
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds i16, i16* %5, i64 %289
  store i16 %287, i16* %290, align 2
  %291 = add nsw i32 %83, 7
  %292 = sext i32 %291 to i64
  %293 = getelementptr inbounds i16, i16* %5, i64 %292
  store i16 %287, i16* %293, align 2
  %294 = add nsw i32 %72, 7
  %295 = sext i32 %294 to i64
  %296 = getelementptr inbounds i16, i16* %5, i64 %295
  store i16 %287, i16* %296, align 2
  %297 = add i64 %62, 30064771072
  %298 = ashr exact i64 %297, 32
  %299 = getelementptr inbounds i16, i16* %5, i64 %298
  store i16 %287, i16* %299, align 2
  %300 = add nsw i32 %94, 6
  %301 = sext i32 %300 to i64
  %302 = getelementptr inbounds i16, i16* %5, i64 %301
  store i16 %287, i16* %302, align 2
  %303 = add nsw i32 %83, 6
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds i16, i16* %5, i64 %304
  store i16 %287, i16* %305, align 2
  %306 = add nsw i32 %72, 6
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i16, i16* %5, i64 %307
  store i16 %287, i16* %308, align 2
  %309 = add i64 %62, 25769803776
  %310 = ashr exact i64 %309, 32
  %311 = getelementptr inbounds i16, i16* %5, i64 %310
  store i16 %287, i16* %311, align 2
  %312 = add nsw i32 %94, 5
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds i16, i16* %5, i64 %313
  store i16 %287, i16* %314, align 2
  %315 = add nsw i32 %83, 5
  %316 = sext i32 %315 to i64
  %317 = getelementptr inbounds i16, i16* %5, i64 %316
  store i16 %287, i16* %317, align 2
  %318 = add nsw i32 %72, 5
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i16, i16* %5, i64 %319
  store i16 %287, i16* %320, align 2
  %321 = add nsw i32 %94, 4
  %322 = sext i32 %321 to i64
  %323 = getelementptr inbounds i16, i16* %5, i64 %322
  store i16 %287, i16* %323, align 2
  %324 = add nsw i32 %83, 4
  %325 = sext i32 %324 to i64
  %326 = getelementptr inbounds i16, i16* %5, i64 %325
  store i16 %287, i16* %326, align 2
  %327 = add nsw i32 %72, 4
  %328 = sext i32 %327 to i64
  %329 = getelementptr inbounds i16, i16* %5, i64 %328
  store i16 %287, i16* %329, align 2
  %330 = add nsw i32 %94, 3
  %331 = sext i32 %330 to i64
  %332 = getelementptr inbounds i16, i16* %5, i64 %331
  store i16 %287, i16* %332, align 2
  %333 = add nsw i32 %83, 3
  %334 = sext i32 %333 to i64
  %335 = getelementptr inbounds i16, i16* %5, i64 %334
  store i16 %287, i16* %335, align 2
  %336 = add nsw i32 %94, 2
  %337 = sext i32 %336 to i64
  %338 = getelementptr inbounds i16, i16* %5, i64 %337
  store i16 %287, i16* %338, align 2
  %339 = add nsw i32 %83, 2
  %340 = sext i32 %339 to i64
  %341 = getelementptr inbounds i16, i16* %5, i64 %340
  store i16 %287, i16* %341, align 2
  %342 = add nsw i32 %94, 1
  %343 = sext i32 %342 to i64
  %344 = getelementptr inbounds i16, i16* %5, i64 %343
  store i16 %287, i16* %344, align 2
  %345 = sext i32 %94 to i64
  %346 = getelementptr inbounds i16, i16* %5, i64 %345
  store i16 %287, i16* %346, align 2
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_left_dc_14_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = icmp eq i32 %1, 0
  br i1 %7, label %13, label %8

8:                                                ; preds = %4
  %9 = shl i64 %6, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = getelementptr inbounds i16, i16* %5, i64 %11
  br label %18

13:                                               ; preds = %4
  %14 = getelementptr inbounds i8, i8* %0, i64 -2
  %15 = bitcast i8* %14 to i16*
  %16 = shl i64 %6, 32
  %17 = ashr exact i64 %16, 32
  br label %18

18:                                               ; preds = %13, %8
  %19 = phi i64 [ %17, %13 ], [ %10, %8 ]
  %20 = phi i64 [ %16, %13 ], [ %9, %8 ]
  %21 = phi i16* [ %15, %13 ], [ %12, %8 ]
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i32
  %24 = getelementptr inbounds i8, i8* %0, i64 -2
  %25 = bitcast i8* %24 to i16*
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = add i64 %20, -4294967296
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %23
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = shl i64 %3, 32
  %40 = and i64 %39, -8589934592
  %41 = add i64 %40, -4294967296
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds i16, i16* %5, i64 %42
  %44 = load i16, i16* %43, align 2
  %45 = zext i16 %44 to i32
  %46 = add nuw nsw i32 %45, 2
  %47 = add nuw nsw i32 %46, %27
  %48 = add nuw nsw i32 %47, %38
  %49 = lshr i32 %48, 2
  %50 = shl nuw nsw i32 %45, 1
  %51 = mul i64 %6, 12884901888
  %52 = add i64 %51, -4294967296
  %53 = ashr exact i64 %52, 32
  %54 = getelementptr inbounds i16, i16* %5, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i32
  %57 = add nuw nsw i32 %34, %50
  %58 = add nuw nsw i32 %57, %56
  %59 = lshr i32 %58, 2
  %60 = shl nuw nsw i32 %56, 1
  %61 = shl i64 %6, 34
  %62 = add i64 %61, -4294967296
  %63 = ashr exact i64 %62, 32
  %64 = getelementptr inbounds i16, i16* %5, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i32
  %67 = add nuw nsw i32 %46, %60
  %68 = add nuw nsw i32 %67, %66
  %69 = lshr i32 %68, 2
  %70 = shl nuw nsw i32 %66, 1
  %71 = mul i64 %6, 21474836480
  %72 = add i64 %71, -4294967296
  %73 = ashr exact i64 %72, 32
  %74 = getelementptr inbounds i16, i16* %5, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i32
  %77 = add nuw nsw i32 %56, 2
  %78 = add nuw nsw i32 %77, %70
  %79 = add nuw nsw i32 %78, %76
  %80 = lshr i32 %79, 2
  %81 = shl nuw nsw i32 %76, 1
  %82 = mul i64 %6, 25769803776
  %83 = add i64 %82, -4294967296
  %84 = ashr exact i64 %83, 32
  %85 = getelementptr inbounds i16, i16* %5, i64 %84
  %86 = load i16, i16* %85, align 2
  %87 = zext i16 %86 to i32
  %88 = add nuw nsw i32 %66, 2
  %89 = add nuw nsw i32 %88, %81
  %90 = add nuw nsw i32 %89, %87
  %91 = lshr i32 %90, 2
  %92 = shl nuw nsw i32 %87, 1
  %93 = mul i64 %6, 30064771072
  %94 = add i64 %93, -4294967296
  %95 = ashr exact i64 %94, 32
  %96 = getelementptr inbounds i16, i16* %5, i64 %95
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i32
  %99 = add nuw nsw i32 %76, 2
  %100 = add nuw nsw i32 %99, %92
  %101 = add nuw nsw i32 %100, %98
  %102 = lshr i32 %101, 2
  %103 = mul nuw nsw i32 %98, 3
  %104 = add nuw nsw i32 %87, 2
  %105 = add nuw nsw i32 %104, %103
  %106 = lshr i32 %105, 2
  %107 = add nuw nsw i32 %37, 4
  %108 = add nuw nsw i32 %107, %49
  %109 = add nuw nsw i32 %108, %59
  %110 = add nuw nsw i32 %109, %69
  %111 = add nuw nsw i32 %110, %80
  %112 = add nuw nsw i32 %111, %91
  %113 = add nuw nsw i32 %112, %106
  %114 = add nuw nsw i32 %113, %102
  %115 = ashr i32 %114, 3
  %116 = sext i32 %115 to i64
  %117 = mul i64 %116, 281479271743489
  %118 = bitcast i8* %0 to i64*
  store i64 %117, i64* %118, align 8
  %119 = getelementptr inbounds i8, i8* %0, i64 8
  %120 = bitcast i8* %119 to i64*
  store i64 %117, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %5, i64 %19
  %122 = bitcast i16* %121 to i64*
  store i64 %117, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %121, i64 4
  %124 = bitcast i16* %123 to i64*
  store i64 %117, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %121, i64 %19
  %126 = bitcast i16* %125 to i64*
  store i64 %117, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %125, i64 4
  %128 = bitcast i16* %127 to i64*
  store i64 %117, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %125, i64 %19
  %130 = bitcast i16* %129 to i64*
  store i64 %117, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %129, i64 4
  %132 = bitcast i16* %131 to i64*
  store i64 %117, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %129, i64 %19
  %134 = bitcast i16* %133 to i64*
  store i64 %117, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %133, i64 4
  %136 = bitcast i16* %135 to i64*
  store i64 %117, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %133, i64 %19
  %138 = bitcast i16* %137 to i64*
  store i64 %117, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %137, i64 4
  %140 = bitcast i16* %139 to i64*
  store i64 %117, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %137, i64 %19
  %142 = bitcast i16* %141 to i64*
  store i64 %117, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %117, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %141, i64 %19
  %146 = bitcast i16* %145 to i64*
  store i64 %117, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %145, i64 4
  %148 = bitcast i16* %147 to i64*
  store i64 %117, i64* %148, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_top_dc_14_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = bitcast i8* %0 to i16*
  %6 = lshr i64 %3, 1
  %7 = trunc i64 %6 to i32
  %8 = icmp eq i32 %1, 0
  %9 = sub nsw i32 0, %7
  br i1 %8, label %15, label %10

10:                                               ; preds = %4
  %11 = shl i64 %6, 32
  %12 = ashr exact i64 %11, 32
  %13 = xor i64 %12, -1
  %14 = sext i32 %9 to i64
  br label %18

15:                                               ; preds = %4
  %16 = sext i32 %9 to i64
  %17 = shl i64 %6, 32
  br label %18

18:                                               ; preds = %15, %10
  %19 = phi i64 [ %17, %15 ], [ %11, %10 ]
  %20 = phi i64 [ %16, %15 ], [ %14, %10 ]
  %21 = phi i64 [ %16, %15 ], [ %13, %10 ]
  %22 = getelementptr inbounds i16, i16* %5, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i32
  %25 = getelementptr inbounds i16, i16* %5, i64 %20
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = shl nuw nsw i32 %27, 1
  %29 = sub i64 4294967296, %19
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i16, i16* %5, i64 %30
  %32 = load i16, i16* %31, align 2
  %33 = zext i16 %32 to i32
  %34 = add nuw nsw i32 %33, 2
  %35 = add nuw nsw i32 %34, %24
  %36 = add nuw nsw i32 %35, %28
  %37 = lshr i32 %36, 2
  %38 = shl nuw nsw i32 %33, 1
  %39 = sub i64 8589934592, %19
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i16, i16* %5, i64 %40
  %42 = load i16, i16* %41, align 2
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %27
  %46 = add nuw nsw i32 %45, %38
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = sub i64 12884901888, %19
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i16, i16* %5, i64 %50
  %52 = load i16, i16* %51, align 2
  %53 = zext i16 %52 to i32
  %54 = add nuw nsw i32 %34, %48
  %55 = add nuw nsw i32 %54, %53
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %53, 1
  %58 = sub i64 17179869184, %19
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i16, i16* %5, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i32
  %63 = add nuw nsw i32 %44, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 21474836480, %19
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i16, i16* %5, i64 %68
  %70 = load i16, i16* %69, align 2
  %71 = zext i16 %70 to i32
  %72 = add nuw nsw i32 %53, 2
  %73 = add nuw nsw i32 %72, %66
  %74 = add nuw nsw i32 %73, %71
  %75 = lshr i32 %74, 2
  %76 = shl nuw nsw i32 %71, 1
  %77 = sub i64 25769803776, %19
  %78 = ashr exact i64 %77, 32
  %79 = getelementptr inbounds i16, i16* %5, i64 %78
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = add nuw nsw i32 %62, 2
  %83 = add nuw nsw i32 %82, %76
  %84 = add nuw nsw i32 %83, %81
  %85 = lshr i32 %84, 2
  %86 = shl nuw nsw i32 %81, 1
  %87 = sub i64 30064771072, %19
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %5, i64 %88
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %71, 2
  %93 = add nuw nsw i32 %92, %86
  %94 = add nuw nsw i32 %93, %91
  %95 = lshr i32 %94, 2
  %96 = icmp eq i32 %2, 0
  br i1 %96, label %103, label %97

97:                                               ; preds = %18
  %98 = sub i64 34359738368, %19
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i16, i16* %5, i64 %99
  %101 = load i16, i16* %100, align 2
  %102 = zext i16 %101 to i32
  br label %103

103:                                              ; preds = %18, %97
  %104 = phi i32 [ %102, %97 ], [ %91, %18 ]
  %105 = shl nuw nsw i32 %91, 1
  %106 = add nuw nsw i32 %81, 2
  %107 = add nuw nsw i32 %106, %105
  %108 = add nuw nsw i32 %107, %104
  %109 = lshr i32 %108, 2
  %110 = add nuw nsw i32 %37, 4
  %111 = add nuw nsw i32 %110, %47
  %112 = add nuw nsw i32 %111, %56
  %113 = add nuw nsw i32 %112, %65
  %114 = add nuw nsw i32 %113, %75
  %115 = add nuw nsw i32 %114, %85
  %116 = add nuw nsw i32 %115, %95
  %117 = add nuw nsw i32 %116, %109
  %118 = ashr i32 %117, 3
  %119 = sext i32 %118 to i64
  %120 = mul i64 %119, 281479271743489
  %121 = ashr exact i64 %19, 32
  %122 = bitcast i8* %0 to i64*
  store i64 %120, i64* %122, align 8
  %123 = getelementptr inbounds i8, i8* %0, i64 8
  %124 = bitcast i8* %123 to i64*
  store i64 %120, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %5, i64 %121
  %126 = bitcast i16* %125 to i64*
  store i64 %120, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %125, i64 4
  %128 = bitcast i16* %127 to i64*
  store i64 %120, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %125, i64 %121
  %130 = bitcast i16* %129 to i64*
  store i64 %120, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %129, i64 4
  %132 = bitcast i16* %131 to i64*
  store i64 %120, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %129, i64 %121
  %134 = bitcast i16* %133 to i64*
  store i64 %120, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %133, i64 4
  %136 = bitcast i16* %135 to i64*
  store i64 %120, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %133, i64 %121
  %138 = bitcast i16* %137 to i64*
  store i64 %120, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %137, i64 4
  %140 = bitcast i16* %139 to i64*
  store i64 %120, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %137, i64 %121
  %142 = bitcast i16* %141 to i64*
  store i64 %120, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %120, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %141, i64 %121
  %146 = bitcast i16* %145 to i64*
  store i64 %120, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %145, i64 4
  %148 = bitcast i16* %147 to i64*
  store i64 %120, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %145, i64 %121
  %150 = bitcast i16* %149 to i64*
  store i64 %120, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %149, i64 4
  %152 = bitcast i16* %151 to i64*
  store i64 %120, i64* %152, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8l_128_dc_14_c(i8* nocapture, i32, i32, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = shl i64 %3, 31
  %7 = ashr i64 %6, 32
  %8 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %8, align 8
  %9 = getelementptr inbounds i16, i16* %5, i64 %7
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %10, align 8
  %11 = getelementptr inbounds i16, i16* %9, i64 %7
  %12 = bitcast i16* %11 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %12, align 8
  %13 = getelementptr inbounds i16, i16* %11, i64 %7
  %14 = bitcast i16* %13 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %14, align 8
  %15 = getelementptr inbounds i16, i16* %13, i64 %7
  %16 = bitcast i16* %15 to i64*
  store i64 2305878194122661888, i64* %16, align 8
  %17 = getelementptr inbounds i16, i16* %15, i64 4
  %18 = bitcast i16* %17 to i64*
  store i64 2305878194122661888, i64* %18, align 8
  %19 = getelementptr inbounds i16, i16* %15, i64 %7
  %20 = bitcast i16* %19 to i64*
  store i64 2305878194122661888, i64* %20, align 8
  %21 = getelementptr inbounds i16, i16* %19, i64 4
  %22 = bitcast i16* %21 to i64*
  store i64 2305878194122661888, i64* %22, align 8
  %23 = getelementptr inbounds i16, i16* %19, i64 %7
  %24 = bitcast i16* %23 to i64*
  store i64 2305878194122661888, i64* %24, align 8
  %25 = getelementptr inbounds i16, i16* %23, i64 4
  %26 = bitcast i16* %25 to i64*
  store i64 2305878194122661888, i64* %26, align 8
  %27 = getelementptr inbounds i16, i16* %23, i64 %7
  %28 = bitcast i16* %27 to i64*
  store i64 2305878194122661888, i64* %28, align 8
  %29 = getelementptr inbounds i16, i16* %27, i64 4
  %30 = bitcast i16* %29 to i64*
  store i64 2305878194122661888, i64* %30, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_vertical_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds i16, i16* %8, i64 4
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = shl i64 %4, 32
  %15 = ashr exact i64 %14, 32
  %16 = bitcast i8* %0 to i64*
  store i64 %10, i64* %16, align 8
  %17 = getelementptr inbounds i8, i8* %0, i64 8
  %18 = bitcast i8* %17 to i64*
  store i64 %13, i64* %18, align 8
  %19 = getelementptr inbounds i16, i16* %3, i64 %15
  %20 = bitcast i16* %19 to i64*
  store i64 %10, i64* %20, align 8
  %21 = getelementptr inbounds i16, i16* %19, i64 4
  %22 = bitcast i16* %21 to i64*
  store i64 %13, i64* %22, align 8
  %23 = ashr exact i64 %14, 31
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to i64*
  store i64 %10, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %24, i64 4
  %27 = bitcast i16* %26 to i64*
  store i64 %13, i64* %27, align 8
  %28 = mul nsw i64 %15, 3
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = bitcast i16* %29 to i64*
  store i64 %10, i64* %30, align 8
  %31 = getelementptr inbounds i16, i16* %29, i64 4
  %32 = bitcast i16* %31 to i64*
  store i64 %13, i64* %32, align 8
  %33 = ashr exact i64 %14, 30
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %10, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %34, i64 4
  %37 = bitcast i16* %36 to i64*
  store i64 %13, i64* %37, align 8
  %38 = mul nsw i64 %15, 5
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %10, i64* %40, align 8
  %41 = getelementptr inbounds i16, i16* %39, i64 4
  %42 = bitcast i16* %41 to i64*
  store i64 %13, i64* %42, align 8
  %43 = mul nsw i64 %15, 6
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %10, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 %13, i64* %47, align 8
  %48 = mul nsw i64 %15, 7
  %49 = getelementptr inbounds i16, i16* %3, i64 %48
  %50 = bitcast i16* %49 to i64*
  store i64 %10, i64* %50, align 8
  %51 = getelementptr inbounds i16, i16* %49, i64 4
  %52 = bitcast i16* %51 to i64*
  store i64 %13, i64* %52, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_horizontal_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = mul nuw i64 %8, 281479271743489
  %10 = bitcast i8* %0 to i64*
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to i64*
  store i64 %9, i64* %12, align 8
  %13 = add nsw i64 %4, -1
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = mul nuw i64 %16, 281479271743489
  %18 = getelementptr inbounds i16, i16* %3, i64 %4
  %19 = bitcast i16* %18 to i64*
  store i64 %17, i64* %19, align 8
  %20 = getelementptr inbounds i16, i16* %18, i64 4
  %21 = bitcast i16* %20 to i64*
  store i64 %17, i64* %21, align 8
  %22 = and i64 %1, -2
  %23 = add nsw i64 %22, -1
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = mul nuw i64 %26, 281479271743489
  %28 = getelementptr inbounds i16, i16* %3, i64 %22
  %29 = bitcast i16* %28 to i64*
  store i64 %27, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 %27, i64* %31, align 8
  %32 = mul nsw i64 %4, 3
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = mul nuw i64 %36, 281479271743489
  %38 = getelementptr inbounds i16, i16* %3, i64 %32
  %39 = bitcast i16* %38 to i64*
  store i64 %37, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %38, i64 4
  %41 = bitcast i16* %40 to i64*
  store i64 %37, i64* %41, align 8
  %42 = shl nsw i64 %4, 2
  %43 = add nsw i64 %42, -1
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i64
  %47 = mul nuw i64 %46, 281479271743489
  %48 = getelementptr inbounds i16, i16* %3, i64 %42
  %49 = bitcast i16* %48 to i64*
  store i64 %47, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %48, i64 4
  %51 = bitcast i16* %50 to i64*
  store i64 %47, i64* %51, align 8
  %52 = mul nsw i64 %4, 5
  %53 = add nsw i64 %52, -1
  %54 = getelementptr inbounds i16, i16* %3, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i64
  %57 = mul nuw i64 %56, 281479271743489
  %58 = getelementptr inbounds i16, i16* %3, i64 %52
  %59 = bitcast i16* %58 to i64*
  store i64 %57, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %58, i64 4
  %61 = bitcast i16* %60 to i64*
  store i64 %57, i64* %61, align 8
  %62 = mul nsw i64 %4, 6
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = mul nuw i64 %66, 281479271743489
  %68 = getelementptr inbounds i16, i16* %3, i64 %62
  %69 = bitcast i16* %68 to i64*
  store i64 %67, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 %67, i64* %71, align 8
  %72 = mul nsw i64 %4, 7
  %73 = add nsw i64 %72, -1
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i64
  %77 = mul nuw i64 %76, 281479271743489
  %78 = getelementptr inbounds i16, i16* %3, i64 %72
  %79 = bitcast i16* %78 to i64*
  store i64 %77, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %77, i64* %81, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_vertical_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds i16, i16* %8, i64 4
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = shl i64 %4, 32
  %15 = ashr exact i64 %14, 32
  %16 = bitcast i8* %0 to i64*
  store i64 %10, i64* %16, align 8
  %17 = getelementptr inbounds i8, i8* %0, i64 8
  %18 = bitcast i8* %17 to i64*
  store i64 %13, i64* %18, align 8
  %19 = getelementptr inbounds i16, i16* %3, i64 %15
  %20 = bitcast i16* %19 to i64*
  store i64 %10, i64* %20, align 8
  %21 = getelementptr inbounds i16, i16* %19, i64 4
  %22 = bitcast i16* %21 to i64*
  store i64 %13, i64* %22, align 8
  %23 = ashr exact i64 %14, 31
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to i64*
  store i64 %10, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %24, i64 4
  %27 = bitcast i16* %26 to i64*
  store i64 %13, i64* %27, align 8
  %28 = mul nsw i64 %15, 3
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = bitcast i16* %29 to i64*
  store i64 %10, i64* %30, align 8
  %31 = getelementptr inbounds i16, i16* %29, i64 4
  %32 = bitcast i16* %31 to i64*
  store i64 %13, i64* %32, align 8
  %33 = ashr exact i64 %14, 30
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %10, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %34, i64 4
  %37 = bitcast i16* %36 to i64*
  store i64 %13, i64* %37, align 8
  %38 = mul nsw i64 %15, 5
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %10, i64* %40, align 8
  %41 = getelementptr inbounds i16, i16* %39, i64 4
  %42 = bitcast i16* %41 to i64*
  store i64 %13, i64* %42, align 8
  %43 = mul nsw i64 %15, 6
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = bitcast i16* %44 to i64*
  store i64 %10, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 %13, i64* %47, align 8
  %48 = mul nsw i64 %15, 7
  %49 = getelementptr inbounds i16, i16* %3, i64 %48
  %50 = bitcast i16* %49 to i64*
  store i64 %10, i64* %50, align 8
  %51 = getelementptr inbounds i16, i16* %49, i64 4
  %52 = bitcast i16* %51 to i64*
  store i64 %13, i64* %52, align 8
  %53 = ashr exact i64 %14, 29
  %54 = getelementptr inbounds i16, i16* %3, i64 %53
  %55 = bitcast i16* %54 to i64*
  store i64 %10, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %54, i64 4
  %57 = bitcast i16* %56 to i64*
  store i64 %13, i64* %57, align 8
  %58 = mul nsw i64 %15, 9
  %59 = getelementptr inbounds i16, i16* %3, i64 %58
  %60 = bitcast i16* %59 to i64*
  store i64 %10, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %59, i64 4
  %62 = bitcast i16* %61 to i64*
  store i64 %13, i64* %62, align 8
  %63 = mul nsw i64 %15, 10
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = bitcast i16* %64 to i64*
  store i64 %10, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %64, i64 4
  %67 = bitcast i16* %66 to i64*
  store i64 %13, i64* %67, align 8
  %68 = mul nsw i64 %15, 11
  %69 = getelementptr inbounds i16, i16* %3, i64 %68
  %70 = bitcast i16* %69 to i64*
  store i64 %10, i64* %70, align 8
  %71 = getelementptr inbounds i16, i16* %69, i64 4
  %72 = bitcast i16* %71 to i64*
  store i64 %13, i64* %72, align 8
  %73 = mul nsw i64 %15, 12
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = bitcast i16* %74 to i64*
  store i64 %10, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %13, i64* %77, align 8
  %78 = mul nsw i64 %15, 13
  %79 = getelementptr inbounds i16, i16* %3, i64 %78
  %80 = bitcast i16* %79 to i64*
  store i64 %10, i64* %80, align 8
  %81 = getelementptr inbounds i16, i16* %79, i64 4
  %82 = bitcast i16* %81 to i64*
  store i64 %13, i64* %82, align 8
  %83 = mul nsw i64 %15, 14
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = bitcast i16* %84 to i64*
  store i64 %10, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 %13, i64* %87, align 8
  %88 = mul nsw i64 %15, 15
  %89 = getelementptr inbounds i16, i16* %3, i64 %88
  %90 = bitcast i16* %89 to i64*
  store i64 %10, i64* %90, align 8
  %91 = getelementptr inbounds i16, i16* %89, i64 4
  %92 = bitcast i16* %91 to i64*
  store i64 %13, i64* %92, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_horizontal_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = mul nuw i64 %8, 281479271743489
  %10 = bitcast i8* %0 to i64*
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to i64*
  store i64 %9, i64* %12, align 8
  %13 = add nsw i64 %4, -1
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = mul nuw i64 %16, 281479271743489
  %18 = getelementptr inbounds i16, i16* %3, i64 %4
  %19 = bitcast i16* %18 to i64*
  store i64 %17, i64* %19, align 8
  %20 = getelementptr inbounds i16, i16* %18, i64 4
  %21 = bitcast i16* %20 to i64*
  store i64 %17, i64* %21, align 8
  %22 = and i64 %1, -2
  %23 = add nsw i64 %22, -1
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = mul nuw i64 %26, 281479271743489
  %28 = getelementptr inbounds i16, i16* %3, i64 %22
  %29 = bitcast i16* %28 to i64*
  store i64 %27, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 %27, i64* %31, align 8
  %32 = mul nsw i64 %4, 3
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = mul nuw i64 %36, 281479271743489
  %38 = getelementptr inbounds i16, i16* %3, i64 %32
  %39 = bitcast i16* %38 to i64*
  store i64 %37, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %38, i64 4
  %41 = bitcast i16* %40 to i64*
  store i64 %37, i64* %41, align 8
  %42 = shl nsw i64 %4, 2
  %43 = add nsw i64 %42, -1
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i64
  %47 = mul nuw i64 %46, 281479271743489
  %48 = getelementptr inbounds i16, i16* %3, i64 %42
  %49 = bitcast i16* %48 to i64*
  store i64 %47, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %48, i64 4
  %51 = bitcast i16* %50 to i64*
  store i64 %47, i64* %51, align 8
  %52 = mul nsw i64 %4, 5
  %53 = add nsw i64 %52, -1
  %54 = getelementptr inbounds i16, i16* %3, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i64
  %57 = mul nuw i64 %56, 281479271743489
  %58 = getelementptr inbounds i16, i16* %3, i64 %52
  %59 = bitcast i16* %58 to i64*
  store i64 %57, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %58, i64 4
  %61 = bitcast i16* %60 to i64*
  store i64 %57, i64* %61, align 8
  %62 = mul nsw i64 %4, 6
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = mul nuw i64 %66, 281479271743489
  %68 = getelementptr inbounds i16, i16* %3, i64 %62
  %69 = bitcast i16* %68 to i64*
  store i64 %67, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 %67, i64* %71, align 8
  %72 = mul nsw i64 %4, 7
  %73 = add nsw i64 %72, -1
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i64
  %77 = mul nuw i64 %76, 281479271743489
  %78 = getelementptr inbounds i16, i16* %3, i64 %72
  %79 = bitcast i16* %78 to i64*
  store i64 %77, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %77, i64* %81, align 8
  %82 = shl nsw i64 %4, 3
  %83 = add nsw i64 %82, -1
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i64
  %87 = mul nuw i64 %86, 281479271743489
  %88 = getelementptr inbounds i16, i16* %3, i64 %82
  %89 = bitcast i16* %88 to i64*
  store i64 %87, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %88, i64 4
  %91 = bitcast i16* %90 to i64*
  store i64 %87, i64* %91, align 8
  %92 = mul nsw i64 %4, 9
  %93 = add nsw i64 %92, -1
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i64
  %97 = mul nuw i64 %96, 281479271743489
  %98 = getelementptr inbounds i16, i16* %3, i64 %92
  %99 = bitcast i16* %98 to i64*
  store i64 %97, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %98, i64 4
  %101 = bitcast i16* %100 to i64*
  store i64 %97, i64* %101, align 8
  %102 = mul nsw i64 %4, 10
  %103 = add nsw i64 %102, -1
  %104 = getelementptr inbounds i16, i16* %3, i64 %103
  %105 = load i16, i16* %104, align 2
  %106 = zext i16 %105 to i64
  %107 = mul nuw i64 %106, 281479271743489
  %108 = getelementptr inbounds i16, i16* %3, i64 %102
  %109 = bitcast i16* %108 to i64*
  store i64 %107, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 %107, i64* %111, align 8
  %112 = mul nsw i64 %4, 11
  %113 = add nsw i64 %112, -1
  %114 = getelementptr inbounds i16, i16* %3, i64 %113
  %115 = load i16, i16* %114, align 2
  %116 = zext i16 %115 to i64
  %117 = mul nuw i64 %116, 281479271743489
  %118 = getelementptr inbounds i16, i16* %3, i64 %112
  %119 = bitcast i16* %118 to i64*
  store i64 %117, i64* %119, align 8
  %120 = getelementptr inbounds i16, i16* %118, i64 4
  %121 = bitcast i16* %120 to i64*
  store i64 %117, i64* %121, align 8
  %122 = mul nsw i64 %4, 12
  %123 = add nsw i64 %122, -1
  %124 = getelementptr inbounds i16, i16* %3, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i64
  %127 = mul nuw i64 %126, 281479271743489
  %128 = getelementptr inbounds i16, i16* %3, i64 %122
  %129 = bitcast i16* %128 to i64*
  store i64 %127, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %127, i64* %131, align 8
  %132 = mul nsw i64 %4, 13
  %133 = add nsw i64 %132, -1
  %134 = getelementptr inbounds i16, i16* %3, i64 %133
  %135 = load i16, i16* %134, align 2
  %136 = zext i16 %135 to i64
  %137 = mul nuw i64 %136, 281479271743489
  %138 = getelementptr inbounds i16, i16* %3, i64 %132
  %139 = bitcast i16* %138 to i64*
  store i64 %137, i64* %139, align 8
  %140 = getelementptr inbounds i16, i16* %138, i64 4
  %141 = bitcast i16* %140 to i64*
  store i64 %137, i64* %141, align 8
  %142 = mul nsw i64 %4, 14
  %143 = add nsw i64 %142, -1
  %144 = getelementptr inbounds i16, i16* %3, i64 %143
  %145 = load i16, i16* %144, align 2
  %146 = zext i16 %145 to i64
  %147 = mul nuw i64 %146, 281479271743489
  %148 = getelementptr inbounds i16, i16* %3, i64 %142
  %149 = bitcast i16* %148 to i64*
  store i64 %147, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %148, i64 4
  %151 = bitcast i16* %150 to i64*
  store i64 %147, i64* %151, align 8
  %152 = mul nsw i64 %4, 15
  %153 = add nsw i64 %152, -1
  %154 = getelementptr inbounds i16, i16* %3, i64 %153
  %155 = load i16, i16* %154, align 2
  %156 = zext i16 %155 to i64
  %157 = mul nuw i64 %156, 281479271743489
  %158 = getelementptr inbounds i16, i16* %3, i64 %152
  %159 = bitcast i16* %158 to i64*
  store i64 %157, i64* %159, align 8
  %160 = getelementptr inbounds i16, i16* %158, i64 4
  %161 = bitcast i16* %160 to i64*
  store i64 %157, i64* %161, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_plane_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 6
  %6 = bitcast i8* %5 to i16*
  %7 = shl i64 %4, 32
  %8 = ashr exact i64 %7, 32
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i16, i16* %6, i64 %9
  %11 = shl i64 %4, 34
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = getelementptr inbounds i16, i16* %13, i64 -1
  %15 = shl i64 %1, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = sub nsw i64 0, %17
  %19 = getelementptr inbounds i16, i16* %14, i64 %18
  %20 = getelementptr inbounds i16, i16* %10, i64 1
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = getelementptr inbounds i16, i16* %10, i64 -1
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = sub nsw i32 %22, %25
  %27 = load i16, i16* %14, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %19, align 2
  %30 = zext i16 %29 to i32
  %31 = sub nsw i32 %28, %30
  %32 = shl i64 %4, 32
  %33 = ashr exact i64 %32, 32
  %34 = mul nsw i64 %33, 6
  %35 = shl i64 %4, 34
  %36 = ashr exact i64 %35, 31
  %37 = add nsw i64 %34, %36
  %38 = add nsw i64 %37, -2
  %39 = getelementptr i8, i8* %0, i64 %38
  %40 = add nsw i64 %36, -2
  %41 = shl i64 %1, 32
  %42 = ashr exact i64 %41, 32
  %43 = lshr i64 %42, 1
  %44 = shl i64 %43, 2
  %45 = sub i64 %40, %44
  %46 = sub i64 %45, %34
  %47 = getelementptr i8, i8* %0, i64 %46
  %48 = getelementptr inbounds i16, i16* %14, i64 %8
  %49 = getelementptr inbounds i16, i16* %19, i64 %9
  %50 = getelementptr inbounds i16, i16* %10, i64 2
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i32
  %53 = getelementptr inbounds i16, i16* %10, i64 -2
  %54 = load i16, i16* %53, align 2
  %55 = zext i16 %54 to i32
  %56 = sub nsw i32 %52, %55
  %57 = shl nsw i32 %56, 1
  %58 = add nsw i32 %57, %26
  %59 = load i16, i16* %48, align 2
  %60 = zext i16 %59 to i32
  %61 = load i16, i16* %49, align 2
  %62 = zext i16 %61 to i32
  %63 = sub nsw i32 %60, %62
  %64 = shl nsw i32 %63, 1
  %65 = add nsw i32 %64, %31
  %66 = getelementptr inbounds i16, i16* %48, i64 %8
  %67 = getelementptr inbounds i16, i16* %49, i64 %9
  %68 = getelementptr inbounds i16, i16* %10, i64 3
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i32
  %71 = getelementptr inbounds i16, i16* %10, i64 -3
  %72 = load i16, i16* %71, align 2
  %73 = zext i16 %72 to i32
  %74 = sub nsw i32 %70, %73
  %75 = mul nsw i32 %74, 3
  %76 = add nsw i32 %75, %58
  %77 = load i16, i16* %66, align 2
  %78 = zext i16 %77 to i32
  %79 = load i16, i16* %67, align 2
  %80 = zext i16 %79 to i32
  %81 = sub nsw i32 %78, %80
  %82 = mul nsw i32 %81, 3
  %83 = add nsw i32 %82, %65
  %84 = getelementptr inbounds i16, i16* %66, i64 %8
  %85 = getelementptr inbounds i16, i16* %67, i64 %9
  %86 = getelementptr inbounds i16, i16* %10, i64 4
  %87 = load i16, i16* %86, align 2
  %88 = zext i16 %87 to i32
  %89 = getelementptr inbounds i16, i16* %10, i64 -4
  %90 = load i16, i16* %89, align 2
  %91 = zext i16 %90 to i32
  %92 = sub nsw i32 %88, %91
  %93 = shl nsw i32 %92, 2
  %94 = add nsw i32 %93, %76
  %95 = load i16, i16* %84, align 2
  %96 = zext i16 %95 to i32
  %97 = load i16, i16* %85, align 2
  %98 = zext i16 %97 to i32
  %99 = sub nsw i32 %96, %98
  %100 = shl nsw i32 %99, 2
  %101 = add nsw i32 %100, %83
  %102 = bitcast i8* %39 to i16*
  %103 = mul nsw i32 %94, 17
  %104 = add nsw i32 %103, 16
  %105 = ashr i32 %104, 5
  %106 = mul nsw i32 %101, 17
  %107 = add nsw i32 %106, 16
  %108 = ashr i32 %107, 5
  %109 = load i16, i16* %102, align 2
  %110 = zext i16 %109 to i32
  %111 = getelementptr inbounds i8, i8* %47, i64 16
  %112 = bitcast i8* %111 to i16*
  %113 = load i16, i16* %112, align 2
  %114 = zext i16 %113 to i32
  %115 = add nuw nsw i32 %114, %110
  %116 = shl nuw nsw i32 %115, 4
  %117 = add nsw i32 %108, %105
  %118 = mul nsw i32 %117, -3
  %119 = add nsw i32 %118, 16
  %120 = add nsw i32 %119, %116
  %121 = shl nsw i32 %105, 1
  %122 = mul nsw i32 %105, 3
  %123 = shl nsw i32 %105, 2
  %124 = mul nsw i32 %105, 5
  %125 = mul nsw i32 %105, 6
  %126 = mul nsw i32 %105, 7
  br label %127

127:                                              ; preds = %214, %2
  %128 = phi i32 [ 8, %2 ], [ %219, %214 ]
  %129 = phi i16* [ %3, %2 ], [ %218, %214 ]
  %130 = phi i32 [ %120, %2 ], [ %131, %214 ]
  %131 = add nsw i32 %130, %108
  %132 = ashr i32 %130, 5
  %133 = icmp ult i32 %132, 16384
  br i1 %133, label %138, label %134

134:                                              ; preds = %127
  %135 = ashr i32 %130, 31
  %136 = or i32 %135, -16384
  %137 = xor i32 %136, -1
  br label %138

138:                                              ; preds = %127, %134
  %139 = phi i32 [ %137, %134 ], [ %132, %127 ]
  %140 = trunc i32 %139 to i16
  store i16 %140, i16* %129, align 2
  %141 = add nsw i32 %130, %105
  %142 = ashr i32 %141, 5
  %143 = icmp ult i32 %142, 16384
  br i1 %143, label %148, label %144

144:                                              ; preds = %138
  %145 = ashr i32 %141, 31
  %146 = or i32 %145, -16384
  %147 = xor i32 %146, -1
  br label %148

148:                                              ; preds = %138, %144
  %149 = phi i32 [ %147, %144 ], [ %142, %138 ]
  %150 = trunc i32 %149 to i16
  %151 = getelementptr inbounds i16, i16* %129, i64 1
  store i16 %150, i16* %151, align 2
  %152 = add nsw i32 %130, %121
  %153 = ashr i32 %152, 5
  %154 = icmp ult i32 %153, 16384
  br i1 %154, label %159, label %155

155:                                              ; preds = %148
  %156 = ashr i32 %152, 31
  %157 = or i32 %156, -16384
  %158 = xor i32 %157, -1
  br label %159

159:                                              ; preds = %148, %155
  %160 = phi i32 [ %158, %155 ], [ %153, %148 ]
  %161 = trunc i32 %160 to i16
  %162 = getelementptr inbounds i16, i16* %129, i64 2
  store i16 %161, i16* %162, align 2
  %163 = add nsw i32 %130, %122
  %164 = ashr i32 %163, 5
  %165 = icmp ult i32 %164, 16384
  br i1 %165, label %170, label %166

166:                                              ; preds = %159
  %167 = ashr i32 %163, 31
  %168 = or i32 %167, -16384
  %169 = xor i32 %168, -1
  br label %170

170:                                              ; preds = %159, %166
  %171 = phi i32 [ %169, %166 ], [ %164, %159 ]
  %172 = trunc i32 %171 to i16
  %173 = getelementptr inbounds i16, i16* %129, i64 3
  store i16 %172, i16* %173, align 2
  %174 = add nsw i32 %130, %123
  %175 = ashr i32 %174, 5
  %176 = icmp ult i32 %175, 16384
  br i1 %176, label %181, label %177

177:                                              ; preds = %170
  %178 = ashr i32 %174, 31
  %179 = or i32 %178, -16384
  %180 = xor i32 %179, -1
  br label %181

181:                                              ; preds = %170, %177
  %182 = phi i32 [ %180, %177 ], [ %175, %170 ]
  %183 = trunc i32 %182 to i16
  %184 = getelementptr inbounds i16, i16* %129, i64 4
  store i16 %183, i16* %184, align 2
  %185 = add nsw i32 %130, %124
  %186 = ashr i32 %185, 5
  %187 = icmp ult i32 %186, 16384
  br i1 %187, label %192, label %188

188:                                              ; preds = %181
  %189 = ashr i32 %185, 31
  %190 = or i32 %189, -16384
  %191 = xor i32 %190, -1
  br label %192

192:                                              ; preds = %181, %188
  %193 = phi i32 [ %191, %188 ], [ %186, %181 ]
  %194 = trunc i32 %193 to i16
  %195 = getelementptr inbounds i16, i16* %129, i64 5
  store i16 %194, i16* %195, align 2
  %196 = add nsw i32 %130, %125
  %197 = ashr i32 %196, 5
  %198 = icmp ult i32 %197, 16384
  br i1 %198, label %203, label %199

199:                                              ; preds = %192
  %200 = ashr i32 %196, 31
  %201 = or i32 %200, -16384
  %202 = xor i32 %201, -1
  br label %203

203:                                              ; preds = %192, %199
  %204 = phi i32 [ %202, %199 ], [ %197, %192 ]
  %205 = trunc i32 %204 to i16
  %206 = getelementptr inbounds i16, i16* %129, i64 6
  store i16 %205, i16* %206, align 2
  %207 = add nsw i32 %130, %126
  %208 = ashr i32 %207, 5
  %209 = icmp ult i32 %208, 16384
  br i1 %209, label %214, label %210

210:                                              ; preds = %203
  %211 = ashr i32 %207, 31
  %212 = or i32 %211, -16384
  %213 = xor i32 %212, -1
  br label %214

214:                                              ; preds = %203, %210
  %215 = phi i32 [ %213, %210 ], [ %208, %203 ]
  %216 = trunc i32 %215 to i16
  %217 = getelementptr inbounds i16, i16* %129, i64 7
  store i16 %216, i16* %217, align 2
  %218 = getelementptr inbounds i16, i16* %129, i64 %8
  %219 = add nsw i32 %128, -1
  %220 = icmp eq i32 %219, 0
  br i1 %220, label %221, label %127

221:                                              ; preds = %214
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_plane_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 6
  %6 = bitcast i8* %5 to i16*
  %7 = shl i64 %4, 32
  %8 = ashr exact i64 %7, 32
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i16, i16* %6, i64 %9
  %11 = shl i64 %4, 35
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = getelementptr inbounds i16, i16* %13, i64 -1
  %15 = shl i64 %1, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = sub nsw i64 0, %17
  %19 = getelementptr inbounds i16, i16* %14, i64 %18
  %20 = getelementptr inbounds i16, i16* %10, i64 1
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = getelementptr inbounds i16, i16* %10, i64 -1
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = sub nsw i32 %22, %25
  %27 = shl i64 %4, 35
  %28 = ashr exact i64 %27, 31
  %29 = add nsw i64 %28, -2
  %30 = shl i64 %1, 32
  %31 = ashr exact i64 %30, 32
  %32 = lshr i64 %31, 1
  %33 = shl i64 %32, 2
  %34 = sub i64 %29, %33
  %35 = shl i64 %4, 32
  %36 = ashr exact i64 %35, 32
  %37 = mul nsw i64 %36, 6
  %38 = add nsw i64 %37, %28
  %39 = add nsw i64 %38, -2
  %40 = getelementptr i8, i8* %0, i64 %39
  %41 = sub i64 %34, %37
  %42 = getelementptr i8, i8* %0, i64 %41
  %43 = getelementptr inbounds i16, i16* %14, i64 %8
  %44 = getelementptr inbounds i16, i16* %19, i64 %9
  %45 = getelementptr inbounds i16, i16* %10, i64 2
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i32
  %48 = getelementptr inbounds i16, i16* %10, i64 -2
  %49 = load i16, i16* %48, align 2
  %50 = zext i16 %49 to i32
  %51 = sub nsw i32 %47, %50
  %52 = shl nsw i32 %51, 1
  %53 = add nsw i32 %52, %26
  %54 = getelementptr inbounds i16, i16* %43, i64 %8
  %55 = getelementptr inbounds i16, i16* %44, i64 %9
  %56 = getelementptr inbounds i16, i16* %10, i64 3
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = getelementptr inbounds i16, i16* %10, i64 -3
  %60 = load i16, i16* %59, align 2
  %61 = zext i16 %60 to i32
  %62 = sub nsw i32 %58, %61
  %63 = mul nsw i32 %62, 3
  %64 = add nsw i32 %63, %53
  %65 = getelementptr inbounds i16, i16* %10, i64 4
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = getelementptr inbounds i16, i16* %10, i64 -4
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i32
  %71 = sub nsw i32 %67, %70
  %72 = shl nsw i32 %71, 2
  %73 = add nsw i32 %72, %64
  %74 = bitcast i8* %40 to i16*
  %75 = bitcast i8* %42 to i16*
  %76 = getelementptr inbounds i16, i16* %54, i64 %8
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i32
  %79 = getelementptr inbounds i16, i16* %55, i64 %9
  %80 = load i16, i16* %79, align 2
  %81 = zext i16 %80 to i32
  %82 = sub nsw i32 %78, %81
  %83 = shl nsw i32 %82, 2
  %84 = load i16, i16* %54, align 2
  %85 = zext i16 %84 to i32
  %86 = load i16, i16* %55, align 2
  %87 = zext i16 %86 to i32
  %88 = sub nsw i32 %85, %87
  %89 = mul nsw i32 %88, 3
  %90 = load i16, i16* %43, align 2
  %91 = zext i16 %90 to i32
  %92 = load i16, i16* %44, align 2
  %93 = zext i16 %92 to i32
  %94 = sub nsw i32 %91, %93
  %95 = shl nsw i32 %94, 1
  %96 = load i16, i16* %14, align 2
  %97 = zext i16 %96 to i32
  %98 = load i16, i16* %19, align 2
  %99 = zext i16 %98 to i32
  %100 = sub nsw i32 %97, %99
  %101 = add nsw i32 %95, %100
  %102 = add nsw i32 %89, %101
  %103 = add nsw i32 %83, %102
  %104 = ashr exact i64 %35, 30
  %105 = mul nsw i64 %36, -3
  %106 = getelementptr inbounds i16, i16* %74, i64 %8
  %107 = getelementptr inbounds i16, i16* %75, i64 %9
  %108 = load i16, i16* %106, align 2
  %109 = zext i16 %108 to i32
  %110 = load i16, i16* %107, align 2
  %111 = zext i16 %110 to i32
  %112 = sub nsw i32 %109, %111
  %113 = mul nsw i32 %112, 5
  %114 = add nsw i32 %113, %103
  %115 = getelementptr inbounds i16, i16* %106, i64 %8
  %116 = getelementptr inbounds i16, i16* %107, i64 %9
  %117 = load i16, i16* %115, align 2
  %118 = zext i16 %117 to i32
  %119 = load i16, i16* %116, align 2
  %120 = zext i16 %119 to i32
  %121 = sub nsw i32 %118, %120
  %122 = mul nsw i32 %121, 6
  %123 = add nsw i32 %122, %114
  %124 = getelementptr inbounds i16, i16* %115, i64 %8
  %125 = getelementptr inbounds i16, i16* %116, i64 %9
  %126 = load i16, i16* %124, align 2
  %127 = zext i16 %126 to i32
  %128 = load i16, i16* %125, align 2
  %129 = zext i16 %128 to i32
  %130 = sub nsw i32 %127, %129
  %131 = mul nsw i32 %130, 7
  %132 = add nsw i32 %131, %123
  %133 = getelementptr inbounds i16, i16* %124, i64 %8
  %134 = getelementptr inbounds i16, i16* %125, i64 %9
  %135 = load i16, i16* %133, align 2
  %136 = zext i16 %135 to i32
  %137 = load i16, i16* %134, align 2
  %138 = zext i16 %137 to i32
  %139 = sub nsw i32 %136, %138
  %140 = shl nsw i32 %139, 3
  %141 = add nsw i32 %140, %132
  %142 = getelementptr i16, i16* %75, i64 %105
  %143 = getelementptr i16, i16* %74, i64 %104
  %144 = mul i32 %141, 5
  %145 = add i32 %144, 32
  %146 = ashr i32 %145, 6
  %147 = getelementptr inbounds i16, i16* %142, i64 %9
  %148 = mul nsw i32 %73, 17
  %149 = add nsw i32 %148, 16
  %150 = ashr i32 %149, 5
  %151 = load i16, i16* %143, align 2
  %152 = zext i16 %151 to i32
  %153 = getelementptr inbounds i16, i16* %147, i64 8
  %154 = load i16, i16* %153, align 2
  %155 = zext i16 %154 to i32
  %156 = add nuw nsw i32 %155, %152
  %157 = shl nuw nsw i32 %156, 4
  %158 = mul nsw i32 %146, -7
  %159 = mul nsw i32 %150, 3
  %160 = sub nsw i32 16, %159
  %161 = add nsw i32 %160, %158
  %162 = add nsw i32 %161, %157
  %163 = shl nsw i32 %150, 1
  %164 = shl nsw i32 %150, 2
  %165 = mul nsw i32 %150, 5
  %166 = mul nsw i32 %150, 6
  %167 = mul nsw i32 %150, 7
  br label %168

168:                                              ; preds = %255, %2
  %169 = phi i32 [ 16, %2 ], [ %260, %255 ]
  %170 = phi i16* [ %3, %2 ], [ %259, %255 ]
  %171 = phi i32 [ %162, %2 ], [ %172, %255 ]
  %172 = add nsw i32 %171, %146
  %173 = ashr i32 %171, 5
  %174 = icmp ult i32 %173, 16384
  br i1 %174, label %179, label %175

175:                                              ; preds = %168
  %176 = ashr i32 %171, 31
  %177 = or i32 %176, -16384
  %178 = xor i32 %177, -1
  br label %179

179:                                              ; preds = %168, %175
  %180 = phi i32 [ %178, %175 ], [ %173, %168 ]
  %181 = trunc i32 %180 to i16
  store i16 %181, i16* %170, align 2
  %182 = add nsw i32 %171, %150
  %183 = ashr i32 %182, 5
  %184 = icmp ult i32 %183, 16384
  br i1 %184, label %189, label %185

185:                                              ; preds = %179
  %186 = ashr i32 %182, 31
  %187 = or i32 %186, -16384
  %188 = xor i32 %187, -1
  br label %189

189:                                              ; preds = %179, %185
  %190 = phi i32 [ %188, %185 ], [ %183, %179 ]
  %191 = trunc i32 %190 to i16
  %192 = getelementptr inbounds i16, i16* %170, i64 1
  store i16 %191, i16* %192, align 2
  %193 = add nsw i32 %171, %163
  %194 = ashr i32 %193, 5
  %195 = icmp ult i32 %194, 16384
  br i1 %195, label %200, label %196

196:                                              ; preds = %189
  %197 = ashr i32 %193, 31
  %198 = or i32 %197, -16384
  %199 = xor i32 %198, -1
  br label %200

200:                                              ; preds = %189, %196
  %201 = phi i32 [ %199, %196 ], [ %194, %189 ]
  %202 = trunc i32 %201 to i16
  %203 = getelementptr inbounds i16, i16* %170, i64 2
  store i16 %202, i16* %203, align 2
  %204 = add nsw i32 %171, %159
  %205 = ashr i32 %204, 5
  %206 = icmp ult i32 %205, 16384
  br i1 %206, label %211, label %207

207:                                              ; preds = %200
  %208 = ashr i32 %204, 31
  %209 = or i32 %208, -16384
  %210 = xor i32 %209, -1
  br label %211

211:                                              ; preds = %200, %207
  %212 = phi i32 [ %210, %207 ], [ %205, %200 ]
  %213 = trunc i32 %212 to i16
  %214 = getelementptr inbounds i16, i16* %170, i64 3
  store i16 %213, i16* %214, align 2
  %215 = add nsw i32 %171, %164
  %216 = ashr i32 %215, 5
  %217 = icmp ult i32 %216, 16384
  br i1 %217, label %222, label %218

218:                                              ; preds = %211
  %219 = ashr i32 %215, 31
  %220 = or i32 %219, -16384
  %221 = xor i32 %220, -1
  br label %222

222:                                              ; preds = %211, %218
  %223 = phi i32 [ %221, %218 ], [ %216, %211 ]
  %224 = trunc i32 %223 to i16
  %225 = getelementptr inbounds i16, i16* %170, i64 4
  store i16 %224, i16* %225, align 2
  %226 = add nsw i32 %171, %165
  %227 = ashr i32 %226, 5
  %228 = icmp ult i32 %227, 16384
  br i1 %228, label %233, label %229

229:                                              ; preds = %222
  %230 = ashr i32 %226, 31
  %231 = or i32 %230, -16384
  %232 = xor i32 %231, -1
  br label %233

233:                                              ; preds = %222, %229
  %234 = phi i32 [ %232, %229 ], [ %227, %222 ]
  %235 = trunc i32 %234 to i16
  %236 = getelementptr inbounds i16, i16* %170, i64 5
  store i16 %235, i16* %236, align 2
  %237 = add nsw i32 %171, %166
  %238 = ashr i32 %237, 5
  %239 = icmp ult i32 %238, 16384
  br i1 %239, label %244, label %240

240:                                              ; preds = %233
  %241 = ashr i32 %237, 31
  %242 = or i32 %241, -16384
  %243 = xor i32 %242, -1
  br label %244

244:                                              ; preds = %233, %240
  %245 = phi i32 [ %243, %240 ], [ %238, %233 ]
  %246 = trunc i32 %245 to i16
  %247 = getelementptr inbounds i16, i16* %170, i64 6
  store i16 %246, i16* %247, align 2
  %248 = add nsw i32 %171, %167
  %249 = ashr i32 %248, 5
  %250 = icmp ult i32 %249, 16384
  br i1 %250, label %255, label %251

251:                                              ; preds = %244
  %252 = ashr i32 %248, 31
  %253 = or i32 %252, -16384
  %254 = xor i32 %253, -1
  br label %255

255:                                              ; preds = %244, %251
  %256 = phi i32 [ %254, %251 ], [ %249, %244 ]
  %257 = trunc i32 %256 to i16
  %258 = getelementptr inbounds i16, i16* %170, i64 7
  store i16 %257, i16* %258, align 2
  %259 = getelementptr inbounds i16, i16* %170, i64 %8
  %260 = add nsw i32 %169, -1
  %261 = icmp eq i32 %260, 0
  br i1 %261, label %262, label %168

262:                                              ; preds = %255
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_dc_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 0, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = sub nsw i64 4, %4
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = shl nsw i64 %4, 2
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = add nsw i64 %4, -1
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = sub nsw i64 1, %4
  %28 = getelementptr inbounds i16, i16* %3, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = zext i16 %29 to i64
  %31 = add nuw nsw i64 %13, %26
  %32 = add nuw nsw i64 %31, %30
  %33 = sub nsw i64 5, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = add nuw nsw i32 %17, %36
  %38 = mul nsw i64 %4, 5
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i32
  %43 = add nuw nsw i32 %22, %42
  %44 = and i64 %1, -2
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = sub nsw i64 2, %4
  %50 = getelementptr inbounds i16, i16* %3, i64 %49
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i64
  %53 = add nuw nsw i64 %32, %48
  %54 = add nuw nsw i64 %53, %52
  %55 = sub nsw i64 6, %4
  %56 = getelementptr inbounds i16, i16* %3, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %37, %58
  %60 = mul nsw i64 %4, 6
  %61 = add nsw i64 %60, -1
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = load i16, i16* %62, align 2
  %64 = zext i16 %63 to i32
  %65 = add nuw nsw i32 %43, %64
  %66 = mul nsw i64 %4, 3
  %67 = add nsw i64 %66, -1
  %68 = getelementptr inbounds i16, i16* %3, i64 %67
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i64
  %71 = sub nsw i64 3, %4
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = load i16, i16* %72, align 2
  %74 = zext i16 %73 to i64
  %75 = add nuw nsw i64 %54, %70
  %76 = add nuw nsw i64 %75, %74
  %77 = sub nsw i64 7, %4
  %78 = getelementptr inbounds i16, i16* %3, i64 %77
  %79 = load i16, i16* %78, align 2
  %80 = zext i16 %79 to i32
  %81 = add nuw nsw i32 %59, %80
  %82 = mul nsw i64 %4, 7
  %83 = add nsw i64 %82, -1
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i32
  %87 = add nuw nsw i32 %65, %86
  %88 = add nuw nsw i64 %76, 4
  %89 = lshr i64 %88, 3
  %90 = and i64 %89, 536870911
  %91 = mul i64 %90, 281479271743489
  %92 = add nuw nsw i32 %81, 2
  %93 = lshr i32 %92, 2
  %94 = zext i32 %93 to i64
  %95 = mul i64 %94, 281479271743489
  %96 = add nuw nsw i32 %87, 2
  %97 = lshr i32 %96, 2
  %98 = zext i32 %97 to i64
  %99 = add nuw nsw i32 %81, 4
  %100 = add nuw nsw i32 %99, %87
  %101 = lshr i32 %100, 3
  %102 = zext i32 %101 to i64
  %103 = bitcast i8* %0 to i64*
  store i64 %91, i64* %103, align 8
  %104 = getelementptr inbounds i8, i8* %0, i64 8
  %105 = bitcast i8* %104 to i64*
  store i64 %95, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %3, i64 %4
  %107 = bitcast i16* %106 to i64*
  store i64 %91, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %106, i64 4
  %109 = bitcast i16* %108 to i64*
  store i64 %95, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %3, i64 %44
  %111 = bitcast i16* %110 to i64*
  store i64 %91, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %110, i64 4
  %113 = bitcast i16* %112 to i64*
  store i64 %95, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %3, i64 %66
  %115 = bitcast i16* %114 to i64*
  store i64 %91, i64* %115, align 8
  %116 = getelementptr inbounds i16, i16* %114, i64 4
  %117 = bitcast i16* %116 to i64*
  store i64 %95, i64* %117, align 8
  %118 = mul i64 %98, 281479271743489
  %119 = mul i64 %102, 281479271743489
  %120 = getelementptr inbounds i16, i16* %3, i64 %18
  %121 = bitcast i16* %120 to i64*
  store i64 %118, i64* %121, align 8
  %122 = getelementptr inbounds i16, i16* %120, i64 4
  %123 = bitcast i16* %122 to i64*
  store i64 %119, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %3, i64 %38
  %125 = bitcast i16* %124 to i64*
  store i64 %118, i64* %125, align 8
  %126 = getelementptr inbounds i16, i16* %124, i64 4
  %127 = bitcast i16* %126 to i64*
  store i64 %119, i64* %127, align 8
  %128 = getelementptr inbounds i16, i16* %3, i64 %60
  %129 = bitcast i16* %128 to i64*
  store i64 %118, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %119, i64* %131, align 8
  %132 = getelementptr inbounds i16, i16* %3, i64 %82
  %133 = bitcast i16* %132 to i64*
  store i64 %118, i64* %133, align 8
  %134 = getelementptr inbounds i16, i16* %132, i64 4
  %135 = bitcast i16* %134 to i64*
  store i64 %119, i64* %135, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_left_dc_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = add nuw nsw i64 %8, %17
  %19 = mul nsw i64 %4, 5
  %20 = add nsw i64 %19, -1
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = load i16, i16* %21, align 2
  %23 = zext i16 %22 to i64
  %24 = add nuw nsw i64 %13, %23
  %25 = and i64 %1, -2
  %26 = add nsw i64 %25, -1
  %27 = getelementptr inbounds i16, i16* %3, i64 %26
  %28 = load i16, i16* %27, align 2
  %29 = zext i16 %28 to i64
  %30 = add nuw nsw i64 %18, %29
  %31 = mul nsw i64 %4, 6
  %32 = add nsw i64 %31, -1
  %33 = getelementptr inbounds i16, i16* %3, i64 %32
  %34 = load i16, i16* %33, align 2
  %35 = zext i16 %34 to i64
  %36 = add nuw nsw i64 %24, %35
  %37 = mul nsw i64 %4, 3
  %38 = add nsw i64 %37, -1
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i64
  %42 = add nuw nsw i64 %30, %41
  %43 = mul nsw i64 %4, 7
  %44 = add nsw i64 %43, -1
  %45 = getelementptr inbounds i16, i16* %3, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i64
  %48 = add nuw nsw i64 %36, %47
  %49 = add nuw nsw i64 %42, 2
  %50 = lshr i64 %49, 2
  %51 = mul i64 %50, 281479271743489
  %52 = add nuw nsw i64 %48, 2
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  store i64 %51, i64* %54, align 8
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  store i64 %51, i64* %56, align 8
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %51, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %51, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %25
  %62 = bitcast i16* %61 to i64*
  store i64 %51, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %51, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %37
  %66 = bitcast i16* %65 to i64*
  store i64 %51, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %51, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %19
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %31
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %43
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_top_dc_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = add nuw nsw i64 %8, %16
  %18 = sub nsw i64 5, %4
  %19 = getelementptr inbounds i16, i16* %3, i64 %18
  %20 = load i16, i16* %19, align 2
  %21 = zext i16 %20 to i64
  %22 = add nuw nsw i64 %12, %21
  %23 = sub nsw i64 2, %4
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = add nuw nsw i64 %17, %26
  %28 = sub nsw i64 6, %4
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i64
  %32 = add nuw nsw i64 %22, %31
  %33 = sub nsw i64 3, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %27, %36
  %38 = sub nsw i64 7, %4
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i64
  %42 = add nuw nsw i64 %32, %41
  %43 = add nuw nsw i64 %37, 2
  %44 = lshr i64 %43, 2
  %45 = mul i64 %44, 281479271743489
  %46 = add nuw nsw i64 %42, 2
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %45, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %45, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %45, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %45, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %45, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %45, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %45, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %45, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_l0t_14(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = sub nsw i64 5, %4
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub nsw i64 2, %4
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = sub nsw i64 6, %4
  %26 = getelementptr inbounds i16, i16* %3, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i64
  %29 = sub nsw i64 3, %4
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = sub nsw i64 7, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %8, 2
  %38 = add nuw nsw i64 %37, %16
  %39 = add nuw nsw i64 %38, %24
  %40 = add nuw nsw i64 %39, %32
  %41 = lshr i64 %40, 2
  %42 = mul i64 %41, 281479271743489
  %43 = add nuw nsw i64 %12, 2
  %44 = add nuw nsw i64 %43, %20
  %45 = add nuw nsw i64 %44, %28
  %46 = add nuw nsw i64 %45, %36
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %42, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %42, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %42, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %42, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %42, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %42, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %42, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %42, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  %86 = lshr i64 %1, 1
  %87 = trunc i64 %86 to i32
  %88 = shl i64 %86, 32
  %89 = sub i64 0, %88
  %90 = ashr exact i64 %89, 32
  %91 = getelementptr inbounds i16, i16* %3, i64 %90
  %92 = load i16, i16* %91, align 2
  %93 = zext i16 %92 to i32
  %94 = sub i64 4294967296, %88
  %95 = ashr exact i64 %94, 32
  %96 = getelementptr inbounds i16, i16* %3, i64 %95
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i32
  %99 = sub i64 8589934592, %88
  %100 = ashr exact i64 %99, 32
  %101 = getelementptr inbounds i16, i16* %3, i64 %100
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  %104 = sub i64 12884901888, %88
  %105 = ashr exact i64 %104, 32
  %106 = getelementptr inbounds i16, i16* %3, i64 %105
  %107 = load i16, i16* %106, align 2
  %108 = zext i16 %107 to i32
  %109 = getelementptr inbounds i8, i8* %0, i64 -2
  %110 = bitcast i8* %109 to i16*
  %111 = load i16, i16* %110, align 2
  %112 = zext i16 %111 to i32
  %113 = add i64 %88, -4294967296
  %114 = ashr exact i64 %113, 32
  %115 = getelementptr inbounds i16, i16* %3, i64 %114
  %116 = load i16, i16* %115, align 2
  %117 = zext i16 %116 to i32
  %118 = trunc i64 %1 to i32
  %119 = and i32 %118, -2
  %120 = add nsw i32 %119, -1
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds i16, i16* %3, i64 %121
  %123 = load i16, i16* %122, align 2
  %124 = zext i16 %123 to i32
  %125 = mul nsw i32 %87, 3
  %126 = add nsw i32 %125, -1
  %127 = sext i32 %126 to i64
  %128 = getelementptr inbounds i16, i16* %3, i64 %127
  %129 = load i16, i16* %128, align 2
  %130 = zext i16 %129 to i32
  %131 = add nuw nsw i32 %93, 4
  %132 = add nuw nsw i32 %131, %98
  %133 = add nuw nsw i32 %132, %103
  %134 = add nuw nsw i32 %133, %108
  %135 = add nuw nsw i32 %134, %112
  %136 = add nuw nsw i32 %135, %117
  %137 = add nuw nsw i32 %136, %124
  %138 = add nuw nsw i32 %137, %130
  %139 = ashr i32 %138, 3
  %140 = sext i32 %139 to i64
  %141 = mul i64 %140, 281479271743489
  store i64 %141, i64* %49, align 8
  %142 = ashr exact i64 %88, 32
  %143 = getelementptr inbounds i16, i16* %3, i64 %142
  %144 = bitcast i16* %143 to i64*
  store i64 %141, i64* %144, align 8
  %145 = sext i32 %119 to i64
  %146 = getelementptr inbounds i16, i16* %3, i64 %145
  %147 = bitcast i16* %146 to i64*
  store i64 %141, i64* %147, align 8
  %148 = sext i32 %125 to i64
  %149 = getelementptr inbounds i16, i16* %3, i64 %148
  %150 = bitcast i16* %149 to i64*
  store i64 %141, i64* %150, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_0lt_14(i8* nocapture, i64) #1 {
  tail call void @pred8x8_dc_14_c(i8* %0, i64 %1)
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = sub i64 0, %5
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = sub i64 4294967296, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = load i16, i16* %13, align 2
  %15 = zext i16 %14 to i64
  %16 = sub i64 8589934592, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub i64 12884901888, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i16, i16* %3, i64 %22
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i64
  %26 = add nuw nsw i64 %10, 2
  %27 = add nuw nsw i64 %26, %15
  %28 = add nuw nsw i64 %27, %20
  %29 = add nuw nsw i64 %28, %25
  %30 = lshr i64 %29, 2
  %31 = mul i64 %30, 281479271743489
  %32 = bitcast i8* %0 to i64*
  store i64 %31, i64* %32, align 8
  %33 = ashr exact i64 %5, 32
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %31, i64* %35, align 8
  %36 = shl i64 %1, 32
  %37 = ashr exact i64 %36, 32
  %38 = and i64 %37, -2
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %31, i64* %40, align 8
  %41 = mul i64 %4, 12884901888
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds i16, i16* %3, i64 %42
  %44 = bitcast i16* %43 to i64*
  store i64 %31, i64* %44, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_l00_14(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = mul nsw i64 %4, 5
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = and i64 %1, -2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = mul nsw i64 %4, 6
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = mul nsw i64 %4, 3
  %34 = add nsw i64 %33, -1
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = mul nsw i64 %4, 7
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %8, 2
  %44 = add nuw nsw i64 %43, %17
  %45 = add nuw nsw i64 %44, %27
  %46 = add nuw nsw i64 %45, %37
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = add nuw nsw i64 %13, 2
  %50 = add nuw nsw i64 %49, %22
  %51 = add nuw nsw i64 %50, %32
  %52 = add nuw nsw i64 %51, %42
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  store i64 %48, i64* %54, align 8
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  store i64 %48, i64* %56, align 8
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %48, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %23
  %62 = bitcast i16* %61 to i64*
  store i64 %48, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %48, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %33
  %66 = bitcast i16* %65 to i64*
  store i64 %48, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %48, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %18
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %28
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %38
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  %86 = shl nsw i64 %1, 2
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = bitcast i8* %87 to i16*
  %89 = lshr i64 %1, 1
  %90 = bitcast i8* %87 to i64*
  store i64 2305878194122661888, i64* %90, align 8
  %91 = shl i64 %89, 32
  %92 = ashr exact i64 %91, 32
  %93 = getelementptr inbounds i16, i16* %88, i64 %92
  %94 = bitcast i16* %93 to i64*
  store i64 2305878194122661888, i64* %94, align 8
  %95 = shl i64 %1, 32
  %96 = ashr exact i64 %95, 32
  %97 = and i64 %96, -2
  %98 = getelementptr inbounds i16, i16* %88, i64 %97
  %99 = bitcast i16* %98 to i64*
  store i64 2305878194122661888, i64* %99, align 8
  %100 = mul i64 %89, 12884901888
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %88, i64 %101
  %103 = bitcast i16* %102 to i64*
  store i64 2305878194122661888, i64* %103, align 8
  %104 = getelementptr inbounds i8, i8* %87, i64 8
  %105 = bitcast i8* %104 to i16*
  %106 = bitcast i8* %104 to i64*
  store i64 2305878194122661888, i64* %106, align 8
  %107 = getelementptr inbounds i16, i16* %105, i64 %92
  %108 = bitcast i16* %107 to i64*
  store i64 2305878194122661888, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %105, i64 %97
  %110 = bitcast i16* %109 to i64*
  store i64 2305878194122661888, i64* %110, align 8
  %111 = getelementptr inbounds i16, i16* %105, i64 %101
  %112 = bitcast i16* %111 to i64*
  store i64 2305878194122661888, i64* %112, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_0l0_14(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = mul nsw i64 %4, 5
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = and i64 %1, -2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = mul nsw i64 %4, 6
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = mul nsw i64 %4, 3
  %34 = add nsw i64 %33, -1
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = mul nsw i64 %4, 7
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %8, 2
  %44 = add nuw nsw i64 %43, %17
  %45 = add nuw nsw i64 %44, %27
  %46 = add nuw nsw i64 %45, %37
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = add nuw nsw i64 %13, 2
  %50 = add nuw nsw i64 %49, %22
  %51 = add nuw nsw i64 %50, %32
  %52 = add nuw nsw i64 %51, %42
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %48, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %23
  %62 = bitcast i16* %61 to i64*
  store i64 %48, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %48, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %33
  %66 = bitcast i16* %65 to i64*
  store i64 %48, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %48, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %18
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %28
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %38
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  %86 = lshr i64 %1, 1
  store i64 2305878194122661888, i64* %54, align 8
  %87 = shl i64 %86, 32
  %88 = ashr exact i64 %87, 32
  %89 = getelementptr inbounds i16, i16* %3, i64 %88
  %90 = bitcast i16* %89 to i64*
  store i64 2305878194122661888, i64* %90, align 8
  %91 = shl i64 %1, 32
  %92 = ashr exact i64 %91, 32
  %93 = and i64 %92, -2
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = bitcast i16* %94 to i64*
  store i64 2305878194122661888, i64* %95, align 8
  %96 = mul i64 %86, 12884901888
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i16, i16* %3, i64 %97
  %99 = bitcast i16* %98 to i64*
  store i64 2305878194122661888, i64* %99, align 8
  %100 = bitcast i8* %55 to i16*
  store i64 2305878194122661888, i64* %56, align 8
  %101 = getelementptr inbounds i16, i16* %100, i64 %88
  %102 = bitcast i16* %101 to i64*
  store i64 2305878194122661888, i64* %102, align 8
  %103 = getelementptr inbounds i16, i16* %100, i64 %93
  %104 = bitcast i16* %103 to i64*
  store i64 2305878194122661888, i64* %104, align 8
  %105 = getelementptr inbounds i16, i16* %100, i64 %97
  %106 = bitcast i16* %105 to i64*
  store i64 2305878194122661888, i64* %106, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_dc_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 0, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = sub nsw i64 4, %4
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i32
  %18 = shl nsw i64 %4, 2
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = shl nsw i64 %4, 3
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i32
  %28 = mul nsw i64 %4, 12
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i32
  %33 = add nsw i64 %4, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = sub nsw i64 1, %4
  %38 = getelementptr inbounds i16, i16* %3, i64 %37
  %39 = load i16, i16* %38, align 2
  %40 = zext i16 %39 to i64
  %41 = add nuw nsw i64 %13, %36
  %42 = add nuw nsw i64 %41, %40
  %43 = sub nsw i64 5, %4
  %44 = getelementptr inbounds i16, i16* %3, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %17, %46
  %48 = mul nsw i64 %4, 5
  %49 = add nsw i64 %48, -1
  %50 = getelementptr inbounds i16, i16* %3, i64 %49
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i32
  %53 = add nuw nsw i32 %22, %52
  %54 = mul nsw i64 %4, 9
  %55 = add nsw i64 %54, -1
  %56 = getelementptr inbounds i16, i16* %3, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %27, %58
  %60 = mul nsw i64 %4, 13
  %61 = add nsw i64 %60, -1
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = load i16, i16* %62, align 2
  %64 = zext i16 %63 to i32
  %65 = add nuw nsw i32 %32, %64
  %66 = and i64 %1, -2
  %67 = add nsw i64 %66, -1
  %68 = getelementptr inbounds i16, i16* %3, i64 %67
  %69 = load i16, i16* %68, align 2
  %70 = zext i16 %69 to i64
  %71 = sub nsw i64 2, %4
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = load i16, i16* %72, align 2
  %74 = zext i16 %73 to i64
  %75 = add nuw nsw i64 %42, %70
  %76 = add nuw nsw i64 %75, %74
  %77 = sub nsw i64 6, %4
  %78 = getelementptr inbounds i16, i16* %3, i64 %77
  %79 = load i16, i16* %78, align 2
  %80 = zext i16 %79 to i32
  %81 = add nuw nsw i32 %47, %80
  %82 = mul nsw i64 %4, 6
  %83 = add nsw i64 %82, -1
  %84 = getelementptr inbounds i16, i16* %3, i64 %83
  %85 = load i16, i16* %84, align 2
  %86 = zext i16 %85 to i32
  %87 = add nuw nsw i32 %53, %86
  %88 = mul nsw i64 %4, 10
  %89 = add nsw i64 %88, -1
  %90 = getelementptr inbounds i16, i16* %3, i64 %89
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i32
  %93 = add nuw nsw i32 %59, %92
  %94 = mul nsw i64 %4, 14
  %95 = add nsw i64 %94, -1
  %96 = getelementptr inbounds i16, i16* %3, i64 %95
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i32
  %99 = add nuw nsw i32 %65, %98
  %100 = mul nsw i64 %4, 3
  %101 = add nsw i64 %100, -1
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i64
  %105 = sub nsw i64 3, %4
  %106 = getelementptr inbounds i16, i16* %3, i64 %105
  %107 = load i16, i16* %106, align 2
  %108 = zext i16 %107 to i64
  %109 = add nuw nsw i64 %76, %104
  %110 = add nuw nsw i64 %109, %108
  %111 = sub nsw i64 7, %4
  %112 = getelementptr inbounds i16, i16* %3, i64 %111
  %113 = load i16, i16* %112, align 2
  %114 = zext i16 %113 to i32
  %115 = add nuw nsw i32 %81, %114
  %116 = mul nsw i64 %4, 7
  %117 = add nsw i64 %116, -1
  %118 = getelementptr inbounds i16, i16* %3, i64 %117
  %119 = load i16, i16* %118, align 2
  %120 = zext i16 %119 to i32
  %121 = add nuw nsw i32 %87, %120
  %122 = mul nsw i64 %4, 11
  %123 = add nsw i64 %122, -1
  %124 = getelementptr inbounds i16, i16* %3, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i32
  %127 = add nuw nsw i32 %93, %126
  %128 = mul nsw i64 %4, 15
  %129 = add nsw i64 %128, -1
  %130 = getelementptr inbounds i16, i16* %3, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i32
  %133 = add nuw nsw i32 %99, %132
  %134 = add nuw nsw i64 %110, 4
  %135 = lshr i64 %134, 3
  %136 = and i64 %135, 536870911
  %137 = mul i64 %136, 281479271743489
  %138 = add nuw nsw i32 %115, 2
  %139 = lshr i32 %138, 2
  %140 = zext i32 %139 to i64
  %141 = mul i64 %140, 281479271743489
  %142 = add nuw nsw i32 %121, 2
  %143 = lshr i32 %142, 2
  %144 = zext i32 %143 to i64
  %145 = add nuw nsw i32 %115, 4
  %146 = add nuw nsw i32 %145, %121
  %147 = lshr i32 %146, 3
  %148 = zext i32 %147 to i64
  %149 = add nuw nsw i32 %127, 2
  %150 = lshr i32 %149, 2
  %151 = zext i32 %150 to i64
  %152 = add nuw nsw i32 %145, %127
  %153 = lshr i32 %152, 3
  %154 = zext i32 %153 to i64
  %155 = add nuw nsw i32 %133, 2
  %156 = lshr i32 %155, 2
  %157 = zext i32 %156 to i64
  %158 = add nuw nsw i32 %145, %133
  %159 = lshr i32 %158, 3
  %160 = zext i32 %159 to i64
  %161 = bitcast i8* %0 to i64*
  store i64 %137, i64* %161, align 8
  %162 = getelementptr inbounds i8, i8* %0, i64 8
  %163 = bitcast i8* %162 to i64*
  store i64 %141, i64* %163, align 8
  %164 = getelementptr inbounds i16, i16* %3, i64 %4
  %165 = bitcast i16* %164 to i64*
  store i64 %137, i64* %165, align 8
  %166 = getelementptr inbounds i16, i16* %164, i64 4
  %167 = bitcast i16* %166 to i64*
  store i64 %141, i64* %167, align 8
  %168 = getelementptr inbounds i16, i16* %3, i64 %66
  %169 = bitcast i16* %168 to i64*
  store i64 %137, i64* %169, align 8
  %170 = getelementptr inbounds i16, i16* %168, i64 4
  %171 = bitcast i16* %170 to i64*
  store i64 %141, i64* %171, align 8
  %172 = getelementptr inbounds i16, i16* %3, i64 %100
  %173 = bitcast i16* %172 to i64*
  store i64 %137, i64* %173, align 8
  %174 = getelementptr inbounds i16, i16* %172, i64 4
  %175 = bitcast i16* %174 to i64*
  store i64 %141, i64* %175, align 8
  %176 = mul i64 %144, 281479271743489
  %177 = mul i64 %148, 281479271743489
  %178 = mul i64 %151, 281479271743489
  %179 = mul i64 %154, 281479271743489
  %180 = mul i64 %157, 281479271743489
  %181 = mul i64 %160, 281479271743489
  %182 = getelementptr inbounds i16, i16* %3, i64 %18
  %183 = bitcast i16* %182 to i64*
  store i64 %176, i64* %183, align 8
  %184 = getelementptr inbounds i16, i16* %182, i64 4
  %185 = bitcast i16* %184 to i64*
  store i64 %177, i64* %185, align 8
  %186 = getelementptr inbounds i16, i16* %3, i64 %48
  %187 = bitcast i16* %186 to i64*
  store i64 %176, i64* %187, align 8
  %188 = getelementptr inbounds i16, i16* %186, i64 4
  %189 = bitcast i16* %188 to i64*
  store i64 %177, i64* %189, align 8
  %190 = getelementptr inbounds i16, i16* %3, i64 %82
  %191 = bitcast i16* %190 to i64*
  store i64 %176, i64* %191, align 8
  %192 = getelementptr inbounds i16, i16* %190, i64 4
  %193 = bitcast i16* %192 to i64*
  store i64 %177, i64* %193, align 8
  %194 = getelementptr inbounds i16, i16* %3, i64 %116
  %195 = bitcast i16* %194 to i64*
  store i64 %176, i64* %195, align 8
  %196 = getelementptr inbounds i16, i16* %194, i64 4
  %197 = bitcast i16* %196 to i64*
  store i64 %177, i64* %197, align 8
  %198 = getelementptr inbounds i16, i16* %3, i64 %23
  %199 = bitcast i16* %198 to i64*
  store i64 %178, i64* %199, align 8
  %200 = getelementptr inbounds i16, i16* %198, i64 4
  %201 = bitcast i16* %200 to i64*
  store i64 %179, i64* %201, align 8
  %202 = getelementptr inbounds i16, i16* %3, i64 %54
  %203 = bitcast i16* %202 to i64*
  store i64 %178, i64* %203, align 8
  %204 = getelementptr inbounds i16, i16* %202, i64 4
  %205 = bitcast i16* %204 to i64*
  store i64 %179, i64* %205, align 8
  %206 = getelementptr inbounds i16, i16* %3, i64 %88
  %207 = bitcast i16* %206 to i64*
  store i64 %178, i64* %207, align 8
  %208 = getelementptr inbounds i16, i16* %206, i64 4
  %209 = bitcast i16* %208 to i64*
  store i64 %179, i64* %209, align 8
  %210 = getelementptr inbounds i16, i16* %3, i64 %122
  %211 = bitcast i16* %210 to i64*
  store i64 %178, i64* %211, align 8
  %212 = getelementptr inbounds i16, i16* %210, i64 4
  %213 = bitcast i16* %212 to i64*
  store i64 %179, i64* %213, align 8
  %214 = getelementptr inbounds i16, i16* %3, i64 %28
  %215 = bitcast i16* %214 to i64*
  store i64 %180, i64* %215, align 8
  %216 = getelementptr inbounds i16, i16* %214, i64 4
  %217 = bitcast i16* %216 to i64*
  store i64 %181, i64* %217, align 8
  %218 = getelementptr inbounds i16, i16* %3, i64 %60
  %219 = bitcast i16* %218 to i64*
  store i64 %180, i64* %219, align 8
  %220 = getelementptr inbounds i16, i16* %218, i64 4
  %221 = bitcast i16* %220 to i64*
  store i64 %181, i64* %221, align 8
  %222 = getelementptr inbounds i16, i16* %3, i64 %94
  %223 = bitcast i16* %222 to i64*
  store i64 %180, i64* %223, align 8
  %224 = getelementptr inbounds i16, i16* %222, i64 4
  %225 = bitcast i16* %224 to i64*
  store i64 %181, i64* %225, align 8
  %226 = getelementptr inbounds i16, i16* %3, i64 %128
  %227 = bitcast i16* %226 to i64*
  store i64 %180, i64* %227, align 8
  %228 = getelementptr inbounds i16, i16* %226, i64 4
  %229 = bitcast i16* %228 to i64*
  store i64 %181, i64* %229, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_left_dc_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = shl nsw i64 %4, 2
  %10 = add nsw i64 %9, -1
  %11 = getelementptr inbounds i16, i16* %3, i64 %10
  %12 = load i16, i16* %11, align 2
  %13 = zext i16 %12 to i64
  %14 = add nsw i64 %4, -1
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = mul nsw i64 %4, 5
  %19 = add nsw i64 %18, -1
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = and i64 %1, -2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = mul nsw i64 %4, 6
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = mul nsw i64 %4, 3
  %34 = add nsw i64 %33, -1
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = mul nsw i64 %4, 7
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %8, 2
  %44 = add nuw nsw i64 %43, %17
  %45 = add nuw nsw i64 %44, %27
  %46 = add nuw nsw i64 %45, %37
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = add nuw nsw i64 %13, 2
  %50 = add nuw nsw i64 %49, %22
  %51 = add nuw nsw i64 %50, %32
  %52 = add nuw nsw i64 %51, %42
  %53 = lshr i64 %52, 2
  %54 = bitcast i8* %0 to i64*
  store i64 %48, i64* %54, align 8
  %55 = getelementptr inbounds i8, i8* %0, i64 8
  %56 = bitcast i8* %55 to i64*
  store i64 %48, i64* %56, align 8
  %57 = getelementptr inbounds i16, i16* %3, i64 %4
  %58 = bitcast i16* %57 to i64*
  store i64 %48, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = getelementptr inbounds i16, i16* %3, i64 %23
  %62 = bitcast i16* %61 to i64*
  store i64 %48, i64* %62, align 8
  %63 = getelementptr inbounds i16, i16* %61, i64 4
  %64 = bitcast i16* %63 to i64*
  store i64 %48, i64* %64, align 8
  %65 = getelementptr inbounds i16, i16* %3, i64 %33
  %66 = bitcast i16* %65 to i64*
  store i64 %48, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %48, i64* %68, align 8
  %69 = mul i64 %53, 281479271743489
  %70 = getelementptr inbounds i16, i16* %3, i64 %9
  %71 = bitcast i16* %70 to i64*
  store i64 %69, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %70, i64 4
  %73 = bitcast i16* %72 to i64*
  store i64 %69, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %3, i64 %18
  %75 = bitcast i16* %74 to i64*
  store i64 %69, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %3, i64 %28
  %79 = bitcast i16* %78 to i64*
  store i64 %69, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %69, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %3, i64 %38
  %83 = bitcast i16* %82 to i64*
  store i64 %69, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %69, i64* %85, align 8
  %86 = shl nsw i64 %1, 3
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = bitcast i8* %87 to i16*
  %89 = getelementptr inbounds i8, i8* %87, i64 -2
  %90 = bitcast i8* %89 to i16*
  %91 = load i16, i16* %90, align 2
  %92 = zext i16 %91 to i64
  %93 = getelementptr inbounds i16, i16* %88, i64 %10
  %94 = load i16, i16* %93, align 2
  %95 = zext i16 %94 to i64
  %96 = getelementptr inbounds i16, i16* %88, i64 %14
  %97 = load i16, i16* %96, align 2
  %98 = zext i16 %97 to i64
  %99 = getelementptr inbounds i16, i16* %88, i64 %19
  %100 = load i16, i16* %99, align 2
  %101 = zext i16 %100 to i64
  %102 = getelementptr inbounds i16, i16* %88, i64 %24
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i64
  %105 = getelementptr inbounds i16, i16* %88, i64 %29
  %106 = load i16, i16* %105, align 2
  %107 = zext i16 %106 to i64
  %108 = getelementptr inbounds i16, i16* %88, i64 %34
  %109 = load i16, i16* %108, align 2
  %110 = zext i16 %109 to i64
  %111 = getelementptr inbounds i16, i16* %88, i64 %39
  %112 = load i16, i16* %111, align 2
  %113 = zext i16 %112 to i64
  %114 = add nuw nsw i64 %92, 2
  %115 = add nuw nsw i64 %114, %98
  %116 = add nuw nsw i64 %115, %104
  %117 = add nuw nsw i64 %116, %110
  %118 = lshr i64 %117, 2
  %119 = mul i64 %118, 281479271743489
  %120 = add nuw nsw i64 %95, 2
  %121 = add nuw nsw i64 %120, %101
  %122 = add nuw nsw i64 %121, %107
  %123 = add nuw nsw i64 %122, %113
  %124 = lshr i64 %123, 2
  %125 = bitcast i8* %87 to i64*
  store i64 %119, i64* %125, align 8
  %126 = getelementptr inbounds i8, i8* %87, i64 8
  %127 = bitcast i8* %126 to i64*
  store i64 %119, i64* %127, align 8
  %128 = getelementptr inbounds i16, i16* %88, i64 %4
  %129 = bitcast i16* %128 to i64*
  store i64 %119, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %119, i64* %131, align 8
  %132 = getelementptr inbounds i16, i16* %88, i64 %23
  %133 = bitcast i16* %132 to i64*
  store i64 %119, i64* %133, align 8
  %134 = getelementptr inbounds i16, i16* %132, i64 4
  %135 = bitcast i16* %134 to i64*
  store i64 %119, i64* %135, align 8
  %136 = getelementptr inbounds i16, i16* %88, i64 %33
  %137 = bitcast i16* %136 to i64*
  store i64 %119, i64* %137, align 8
  %138 = getelementptr inbounds i16, i16* %136, i64 4
  %139 = bitcast i16* %138 to i64*
  store i64 %119, i64* %139, align 8
  %140 = mul i64 %124, 281479271743489
  %141 = getelementptr inbounds i16, i16* %88, i64 %9
  %142 = bitcast i16* %141 to i64*
  store i64 %140, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %140, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %88, i64 %18
  %146 = bitcast i16* %145 to i64*
  store i64 %140, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %145, i64 4
  %148 = bitcast i16* %147 to i64*
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %88, i64 %28
  %150 = bitcast i16* %149 to i64*
  store i64 %140, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %149, i64 4
  %152 = bitcast i16* %151 to i64*
  store i64 %140, i64* %152, align 8
  %153 = getelementptr inbounds i16, i16* %88, i64 %38
  %154 = bitcast i16* %153 to i64*
  store i64 %140, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %153, i64 4
  %156 = bitcast i16* %155 to i64*
  store i64 %140, i64* %156, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_top_dc_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = add nuw nsw i64 %8, %16
  %18 = sub nsw i64 5, %4
  %19 = getelementptr inbounds i16, i16* %3, i64 %18
  %20 = load i16, i16* %19, align 2
  %21 = zext i16 %20 to i64
  %22 = add nuw nsw i64 %12, %21
  %23 = sub nsw i64 2, %4
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = load i16, i16* %24, align 2
  %26 = zext i16 %25 to i64
  %27 = add nuw nsw i64 %17, %26
  %28 = sub nsw i64 6, %4
  %29 = getelementptr inbounds i16, i16* %3, i64 %28
  %30 = load i16, i16* %29, align 2
  %31 = zext i16 %30 to i64
  %32 = add nuw nsw i64 %22, %31
  %33 = sub nsw i64 3, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %27, %36
  %38 = sub nsw i64 7, %4
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = load i16, i16* %39, align 2
  %41 = zext i16 %40 to i64
  %42 = add nuw nsw i64 %32, %41
  %43 = add nuw nsw i64 %37, 2
  %44 = lshr i64 %43, 2
  %45 = mul i64 %44, 281479271743489
  %46 = add nuw nsw i64 %42, 2
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %45, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %45, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %45, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %45, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %45, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %45, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %45, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %45, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  %86 = shl nsw i64 %4, 3
  %87 = getelementptr inbounds i16, i16* %3, i64 %86
  %88 = bitcast i16* %87 to i64*
  store i64 %45, i64* %88, align 8
  %89 = getelementptr inbounds i16, i16* %87, i64 4
  %90 = bitcast i16* %89 to i64*
  store i64 %48, i64* %90, align 8
  %91 = mul nsw i64 %4, 9
  %92 = getelementptr inbounds i16, i16* %3, i64 %91
  %93 = bitcast i16* %92 to i64*
  store i64 %45, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %48, i64* %95, align 8
  %96 = mul nsw i64 %4, 10
  %97 = getelementptr inbounds i16, i16* %3, i64 %96
  %98 = bitcast i16* %97 to i64*
  store i64 %45, i64* %98, align 8
  %99 = getelementptr inbounds i16, i16* %97, i64 4
  %100 = bitcast i16* %99 to i64*
  store i64 %48, i64* %100, align 8
  %101 = mul nsw i64 %4, 11
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = bitcast i16* %102 to i64*
  store i64 %45, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %102, i64 4
  %105 = bitcast i16* %104 to i64*
  store i64 %48, i64* %105, align 8
  %106 = mul nsw i64 %4, 12
  %107 = getelementptr inbounds i16, i16* %3, i64 %106
  %108 = bitcast i16* %107 to i64*
  store i64 %45, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %107, i64 4
  %110 = bitcast i16* %109 to i64*
  store i64 %48, i64* %110, align 8
  %111 = mul nsw i64 %4, 13
  %112 = getelementptr inbounds i16, i16* %3, i64 %111
  %113 = bitcast i16* %112 to i64*
  store i64 %45, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %112, i64 4
  %115 = bitcast i16* %114 to i64*
  store i64 %48, i64* %115, align 8
  %116 = mul nsw i64 %4, 14
  %117 = getelementptr inbounds i16, i16* %3, i64 %116
  %118 = bitcast i16* %117 to i64*
  store i64 %45, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %117, i64 4
  %120 = bitcast i16* %119 to i64*
  store i64 %48, i64* %120, align 8
  %121 = mul nsw i64 %4, 15
  %122 = getelementptr inbounds i16, i16* %3, i64 %121
  %123 = bitcast i16* %122 to i64*
  store i64 %45, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %122, i64 4
  %125 = bitcast i16* %124 to i64*
  store i64 %48, i64* %125, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_l0t_14(i8*, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 4, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = sub nsw i64 1, %4
  %14 = getelementptr inbounds i16, i16* %3, i64 %13
  %15 = load i16, i16* %14, align 2
  %16 = zext i16 %15 to i64
  %17 = sub nsw i64 5, %4
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub nsw i64 2, %4
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = sub nsw i64 6, %4
  %26 = getelementptr inbounds i16, i16* %3, i64 %25
  %27 = load i16, i16* %26, align 2
  %28 = zext i16 %27 to i64
  %29 = sub nsw i64 3, %4
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = sub nsw i64 7, %4
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %8, 2
  %38 = add nuw nsw i64 %37, %16
  %39 = add nuw nsw i64 %38, %24
  %40 = add nuw nsw i64 %39, %32
  %41 = lshr i64 %40, 2
  %42 = mul i64 %41, 281479271743489
  %43 = add nuw nsw i64 %12, 2
  %44 = add nuw nsw i64 %43, %20
  %45 = add nuw nsw i64 %44, %28
  %46 = add nuw nsw i64 %45, %36
  %47 = lshr i64 %46, 2
  %48 = mul i64 %47, 281479271743489
  %49 = bitcast i8* %0 to i64*
  store i64 %42, i64* %49, align 8
  %50 = getelementptr inbounds i8, i8* %0, i64 8
  %51 = bitcast i8* %50 to i64*
  store i64 %48, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %3, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 %42, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 %48, i64* %55, align 8
  %56 = and i64 %1, -2
  %57 = getelementptr inbounds i16, i16* %3, i64 %56
  %58 = bitcast i16* %57 to i64*
  store i64 %42, i64* %58, align 8
  %59 = getelementptr inbounds i16, i16* %57, i64 4
  %60 = bitcast i16* %59 to i64*
  store i64 %48, i64* %60, align 8
  %61 = mul nsw i64 %4, 3
  %62 = getelementptr inbounds i16, i16* %3, i64 %61
  %63 = bitcast i16* %62 to i64*
  store i64 %42, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %62, i64 4
  %65 = bitcast i16* %64 to i64*
  store i64 %48, i64* %65, align 8
  %66 = shl nsw i64 %4, 2
  %67 = getelementptr inbounds i16, i16* %3, i64 %66
  %68 = bitcast i16* %67 to i64*
  store i64 %42, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %67, i64 4
  %70 = bitcast i16* %69 to i64*
  store i64 %48, i64* %70, align 8
  %71 = mul nsw i64 %4, 5
  %72 = getelementptr inbounds i16, i16* %3, i64 %71
  %73 = bitcast i16* %72 to i64*
  store i64 %42, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %72, i64 4
  %75 = bitcast i16* %74 to i64*
  store i64 %48, i64* %75, align 8
  %76 = mul nsw i64 %4, 6
  %77 = getelementptr inbounds i16, i16* %3, i64 %76
  %78 = bitcast i16* %77 to i64*
  store i64 %42, i64* %78, align 8
  %79 = getelementptr inbounds i16, i16* %77, i64 4
  %80 = bitcast i16* %79 to i64*
  store i64 %48, i64* %80, align 8
  %81 = mul nsw i64 %4, 7
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = bitcast i16* %82 to i64*
  store i64 %42, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %82, i64 4
  %85 = bitcast i16* %84 to i64*
  store i64 %48, i64* %85, align 8
  %86 = shl nsw i64 %4, 3
  %87 = getelementptr inbounds i16, i16* %3, i64 %86
  %88 = bitcast i16* %87 to i64*
  store i64 %42, i64* %88, align 8
  %89 = getelementptr inbounds i16, i16* %87, i64 4
  %90 = bitcast i16* %89 to i64*
  store i64 %48, i64* %90, align 8
  %91 = mul nsw i64 %4, 9
  %92 = getelementptr inbounds i16, i16* %3, i64 %91
  %93 = bitcast i16* %92 to i64*
  store i64 %42, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %48, i64* %95, align 8
  %96 = mul nsw i64 %4, 10
  %97 = getelementptr inbounds i16, i16* %3, i64 %96
  %98 = bitcast i16* %97 to i64*
  store i64 %42, i64* %98, align 8
  %99 = getelementptr inbounds i16, i16* %97, i64 4
  %100 = bitcast i16* %99 to i64*
  store i64 %48, i64* %100, align 8
  %101 = mul nsw i64 %4, 11
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = bitcast i16* %102 to i64*
  store i64 %42, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %102, i64 4
  %105 = bitcast i16* %104 to i64*
  store i64 %48, i64* %105, align 8
  %106 = mul nsw i64 %4, 12
  %107 = getelementptr inbounds i16, i16* %3, i64 %106
  %108 = bitcast i16* %107 to i64*
  store i64 %42, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %107, i64 4
  %110 = bitcast i16* %109 to i64*
  store i64 %48, i64* %110, align 8
  %111 = mul nsw i64 %4, 13
  %112 = getelementptr inbounds i16, i16* %3, i64 %111
  %113 = bitcast i16* %112 to i64*
  store i64 %42, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %112, i64 4
  %115 = bitcast i16* %114 to i64*
  store i64 %48, i64* %115, align 8
  %116 = mul nsw i64 %4, 14
  %117 = getelementptr inbounds i16, i16* %3, i64 %116
  %118 = bitcast i16* %117 to i64*
  store i64 %42, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %117, i64 4
  %120 = bitcast i16* %119 to i64*
  store i64 %48, i64* %120, align 8
  %121 = mul nsw i64 %4, 15
  %122 = getelementptr inbounds i16, i16* %3, i64 %121
  %123 = bitcast i16* %122 to i64*
  store i64 %42, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %122, i64 4
  %125 = bitcast i16* %124 to i64*
  store i64 %48, i64* %125, align 8
  %126 = lshr i64 %1, 1
  %127 = trunc i64 %126 to i32
  %128 = shl i64 %126, 32
  %129 = sub i64 0, %128
  %130 = ashr exact i64 %129, 32
  %131 = getelementptr inbounds i16, i16* %3, i64 %130
  %132 = load i16, i16* %131, align 2
  %133 = zext i16 %132 to i32
  %134 = sub i64 4294967296, %128
  %135 = ashr exact i64 %134, 32
  %136 = getelementptr inbounds i16, i16* %3, i64 %135
  %137 = load i16, i16* %136, align 2
  %138 = zext i16 %137 to i32
  %139 = sub i64 8589934592, %128
  %140 = ashr exact i64 %139, 32
  %141 = getelementptr inbounds i16, i16* %3, i64 %140
  %142 = load i16, i16* %141, align 2
  %143 = zext i16 %142 to i32
  %144 = sub i64 12884901888, %128
  %145 = ashr exact i64 %144, 32
  %146 = getelementptr inbounds i16, i16* %3, i64 %145
  %147 = load i16, i16* %146, align 2
  %148 = zext i16 %147 to i32
  %149 = getelementptr inbounds i8, i8* %0, i64 -2
  %150 = bitcast i8* %149 to i16*
  %151 = load i16, i16* %150, align 2
  %152 = zext i16 %151 to i32
  %153 = add i64 %128, -4294967296
  %154 = ashr exact i64 %153, 32
  %155 = getelementptr inbounds i16, i16* %3, i64 %154
  %156 = load i16, i16* %155, align 2
  %157 = zext i16 %156 to i32
  %158 = trunc i64 %1 to i32
  %159 = and i32 %158, -2
  %160 = add nsw i32 %159, -1
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds i16, i16* %3, i64 %161
  %163 = load i16, i16* %162, align 2
  %164 = zext i16 %163 to i32
  %165 = mul nsw i32 %127, 3
  %166 = add nsw i32 %165, -1
  %167 = sext i32 %166 to i64
  %168 = getelementptr inbounds i16, i16* %3, i64 %167
  %169 = load i16, i16* %168, align 2
  %170 = zext i16 %169 to i32
  %171 = add nuw nsw i32 %133, 4
  %172 = add nuw nsw i32 %171, %138
  %173 = add nuw nsw i32 %172, %143
  %174 = add nuw nsw i32 %173, %148
  %175 = add nuw nsw i32 %174, %152
  %176 = add nuw nsw i32 %175, %157
  %177 = add nuw nsw i32 %176, %164
  %178 = add nuw nsw i32 %177, %170
  %179 = ashr i32 %178, 3
  %180 = sext i32 %179 to i64
  %181 = mul i64 %180, 281479271743489
  store i64 %181, i64* %49, align 8
  %182 = ashr exact i64 %128, 32
  %183 = getelementptr inbounds i16, i16* %3, i64 %182
  %184 = bitcast i16* %183 to i64*
  store i64 %181, i64* %184, align 8
  %185 = sext i32 %159 to i64
  %186 = getelementptr inbounds i16, i16* %3, i64 %185
  %187 = bitcast i16* %186 to i64*
  store i64 %181, i64* %187, align 8
  %188 = sext i32 %165 to i64
  %189 = getelementptr inbounds i16, i16* %3, i64 %188
  %190 = bitcast i16* %189 to i64*
  store i64 %181, i64* %190, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_0lt_14(i8* nocapture, i64) #1 {
  tail call void @pred8x16_dc_14_c(i8* %0, i64 %1)
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = sub i64 0, %5
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = load i16, i16* %8, align 2
  %10 = zext i16 %9 to i64
  %11 = sub i64 4294967296, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = load i16, i16* %13, align 2
  %15 = zext i16 %14 to i64
  %16 = sub i64 8589934592, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = sub i64 12884901888, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i16, i16* %3, i64 %22
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i64
  %26 = add nuw nsw i64 %10, 2
  %27 = add nuw nsw i64 %26, %15
  %28 = add nuw nsw i64 %27, %20
  %29 = add nuw nsw i64 %28, %25
  %30 = lshr i64 %29, 2
  %31 = mul i64 %30, 281479271743489
  %32 = bitcast i8* %0 to i64*
  store i64 %31, i64* %32, align 8
  %33 = ashr exact i64 %5, 32
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = bitcast i16* %34 to i64*
  store i64 %31, i64* %35, align 8
  %36 = shl i64 %1, 32
  %37 = ashr exact i64 %36, 32
  %38 = and i64 %37, -2
  %39 = getelementptr inbounds i16, i16* %3, i64 %38
  %40 = bitcast i16* %39 to i64*
  store i64 %31, i64* %40, align 8
  %41 = mul i64 %4, 12884901888
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds i16, i16* %3, i64 %42
  %44 = bitcast i16* %43 to i64*
  store i64 %31, i64* %44, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_l00_14(i8* nocapture, i64) #1 {
  tail call void @pred8x16_left_dc_14_c(i8* %0, i64 %1)
  %3 = shl nsw i64 %1, 2
  %4 = getelementptr inbounds i8, i8* %0, i64 %3
  %5 = bitcast i8* %4 to i16*
  %6 = lshr i64 %1, 1
  %7 = bitcast i8* %4 to i64*
  store i64 2305878194122661888, i64* %7, align 8
  %8 = shl i64 %6, 32
  %9 = ashr exact i64 %8, 32
  %10 = getelementptr inbounds i16, i16* %5, i64 %9
  %11 = bitcast i16* %10 to i64*
  store i64 2305878194122661888, i64* %11, align 8
  %12 = shl i64 %1, 32
  %13 = ashr exact i64 %12, 32
  %14 = and i64 %13, -2
  %15 = getelementptr inbounds i16, i16* %5, i64 %14
  %16 = bitcast i16* %15 to i64*
  store i64 2305878194122661888, i64* %16, align 8
  %17 = mul i64 %6, 12884901888
  %18 = ashr exact i64 %17, 32
  %19 = getelementptr inbounds i16, i16* %5, i64 %18
  %20 = bitcast i16* %19 to i64*
  store i64 2305878194122661888, i64* %20, align 8
  %21 = getelementptr inbounds i8, i8* %4, i64 8
  %22 = bitcast i8* %21 to i16*
  %23 = bitcast i8* %21 to i64*
  store i64 2305878194122661888, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %22, i64 %9
  %25 = bitcast i16* %24 to i64*
  store i64 2305878194122661888, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %22, i64 %14
  %27 = bitcast i16* %26 to i64*
  store i64 2305878194122661888, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %22, i64 %18
  %29 = bitcast i16* %28 to i64*
  store i64 2305878194122661888, i64* %29, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_0l0_14(i8* nocapture, i64) #1 {
  tail call void @pred8x16_left_dc_14_c(i8* %0, i64 %1)
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = bitcast i8* %0 to i64*
  store i64 2305878194122661888, i64* %5, align 8
  %6 = shl i64 %4, 32
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  store i64 2305878194122661888, i64* %9, align 8
  %10 = shl i64 %1, 32
  %11 = ashr exact i64 %10, 32
  %12 = and i64 %11, -2
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = bitcast i16* %13 to i64*
  store i64 2305878194122661888, i64* %14, align 8
  %15 = mul i64 %4, 12884901888
  %16 = ashr exact i64 %15, 32
  %17 = getelementptr inbounds i16, i16* %3, i64 %16
  %18 = bitcast i16* %17 to i64*
  store i64 2305878194122661888, i64* %18, align 8
  %19 = getelementptr inbounds i8, i8* %0, i64 8
  %20 = bitcast i8* %19 to i16*
  %21 = bitcast i8* %19 to i64*
  store i64 2305878194122661888, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 %7
  %23 = bitcast i16* %22 to i64*
  store i64 2305878194122661888, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 %12
  %25 = bitcast i16* %24 to i64*
  store i64 2305878194122661888, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 %16
  %27 = bitcast i16* %26 to i64*
  store i64 2305878194122661888, i64* %27, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_127_dc_14_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %25, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_129_dc_14_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %25, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_128_dc_14_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %25, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x16_128_dc_14_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i16, i16* %3, i64 %4
  %7 = bitcast i16* %6 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %7, align 8
  %8 = and i64 %1, -2
  %9 = getelementptr inbounds i16, i16* %3, i64 %8
  %10 = bitcast i16* %9 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %10, align 8
  %11 = mul nsw i64 %4, 3
  %12 = getelementptr inbounds i16, i16* %3, i64 %11
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %13, align 8
  %14 = shl nsw i64 %4, 2
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = bitcast i16* %15 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %16, align 8
  %17 = mul nsw i64 %4, 5
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %19, align 8
  %20 = mul nsw i64 %4, 6
  %21 = getelementptr inbounds i16, i16* %3, i64 %20
  %22 = bitcast i16* %21 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %22, align 8
  %23 = mul nsw i64 %4, 7
  %24 = getelementptr inbounds i16, i16* %3, i64 %23
  %25 = bitcast i16* %24 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %25, align 8
  %26 = shl nsw i64 %1, 3
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = bitcast i8* %27 to i16*
  %29 = bitcast i8* %27 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 %4
  %31 = bitcast i16* %30 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 %8
  %33 = bitcast i16* %32 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 %11
  %35 = bitcast i16* %34 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %14
  %37 = bitcast i16* %36 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %37, align 8
  %38 = getelementptr inbounds i16, i16* %28, i64 %17
  %39 = bitcast i16* %38 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %39, align 8
  %40 = getelementptr inbounds i16, i16* %28, i64 %20
  %41 = bitcast i16* %40 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %41, align 8
  %42 = getelementptr inbounds i16, i16* %28, i64 %23
  %43 = bitcast i16* %42 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %43, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_dc_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = add nsw i64 %4, -1
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = and i64 %1, -2
  %15 = add nsw i64 %14, -1
  %16 = getelementptr inbounds i16, i16* %3, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i64
  %19 = add nuw nsw i64 %13, %18
  %20 = mul nsw i64 %4, 3
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = add nuw nsw i64 %19, %24
  %26 = shl nsw i64 %4, 2
  %27 = add nsw i64 %26, -1
  %28 = getelementptr inbounds i16, i16* %3, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = zext i16 %29 to i64
  %31 = add nuw nsw i64 %25, %30
  %32 = mul nsw i64 %4, 5
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %31, %36
  %38 = mul nsw i64 %4, 6
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %37, %42
  %44 = mul nsw i64 %4, 7
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = add nuw nsw i64 %43, %48
  %50 = shl nsw i64 %4, 3
  %51 = add nsw i64 %50, -1
  %52 = getelementptr inbounds i16, i16* %3, i64 %51
  %53 = load i16, i16* %52, align 2
  %54 = zext i16 %53 to i64
  %55 = add nuw nsw i64 %49, %54
  %56 = mul nsw i64 %4, 9
  %57 = add nsw i64 %56, -1
  %58 = getelementptr inbounds i16, i16* %3, i64 %57
  %59 = load i16, i16* %58, align 2
  %60 = zext i16 %59 to i64
  %61 = add nuw nsw i64 %55, %60
  %62 = mul nsw i64 %4, 10
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = add nuw nsw i64 %61, %66
  %68 = mul nsw i64 %4, 11
  %69 = add nsw i64 %68, -1
  %70 = getelementptr inbounds i16, i16* %3, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i64
  %73 = add nuw nsw i64 %67, %72
  %74 = mul nsw i64 %4, 12
  %75 = add nsw i64 %74, -1
  %76 = getelementptr inbounds i16, i16* %3, i64 %75
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i64
  %79 = add nuw nsw i64 %73, %78
  %80 = mul nsw i64 %4, 13
  %81 = add nsw i64 %80, -1
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = zext i16 %83 to i64
  %85 = add nuw nsw i64 %79, %84
  %86 = mul nsw i64 %4, 14
  %87 = add nsw i64 %86, -1
  %88 = getelementptr inbounds i16, i16* %3, i64 %87
  %89 = load i16, i16* %88, align 2
  %90 = zext i16 %89 to i64
  %91 = add nuw nsw i64 %85, %90
  %92 = mul nsw i64 %4, 15
  %93 = add nsw i64 %92, -1
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i64
  %97 = add nuw nsw i64 %91, %96
  %98 = sub nsw i64 0, %4
  %99 = getelementptr inbounds i16, i16* %3, i64 %98
  %100 = load i16, i16* %99, align 2
  %101 = zext i16 %100 to i64
  %102 = add nuw nsw i64 %97, %101
  %103 = sub nsw i64 1, %4
  %104 = getelementptr inbounds i16, i16* %3, i64 %103
  %105 = load i16, i16* %104, align 2
  %106 = zext i16 %105 to i64
  %107 = add nuw nsw i64 %102, %106
  %108 = sub nsw i64 2, %4
  %109 = getelementptr inbounds i16, i16* %3, i64 %108
  %110 = load i16, i16* %109, align 2
  %111 = zext i16 %110 to i64
  %112 = add nuw nsw i64 %107, %111
  %113 = sub nsw i64 3, %4
  %114 = getelementptr inbounds i16, i16* %3, i64 %113
  %115 = load i16, i16* %114, align 2
  %116 = zext i16 %115 to i64
  %117 = add nuw nsw i64 %112, %116
  %118 = sub nsw i64 4, %4
  %119 = getelementptr inbounds i16, i16* %3, i64 %118
  %120 = load i16, i16* %119, align 2
  %121 = zext i16 %120 to i64
  %122 = add nuw nsw i64 %117, %121
  %123 = sub nsw i64 5, %4
  %124 = getelementptr inbounds i16, i16* %3, i64 %123
  %125 = load i16, i16* %124, align 2
  %126 = zext i16 %125 to i64
  %127 = add nuw nsw i64 %122, %126
  %128 = sub nsw i64 6, %4
  %129 = getelementptr inbounds i16, i16* %3, i64 %128
  %130 = load i16, i16* %129, align 2
  %131 = zext i16 %130 to i64
  %132 = add nuw nsw i64 %127, %131
  %133 = sub nsw i64 7, %4
  %134 = getelementptr inbounds i16, i16* %3, i64 %133
  %135 = load i16, i16* %134, align 2
  %136 = zext i16 %135 to i64
  %137 = add nuw nsw i64 %132, %136
  %138 = sub nsw i64 8, %4
  %139 = getelementptr inbounds i16, i16* %3, i64 %138
  %140 = load i16, i16* %139, align 2
  %141 = zext i16 %140 to i64
  %142 = add nuw nsw i64 %137, %141
  %143 = sub nsw i64 9, %4
  %144 = getelementptr inbounds i16, i16* %3, i64 %143
  %145 = load i16, i16* %144, align 2
  %146 = zext i16 %145 to i64
  %147 = add nuw nsw i64 %142, %146
  %148 = sub nsw i64 10, %4
  %149 = getelementptr inbounds i16, i16* %3, i64 %148
  %150 = load i16, i16* %149, align 2
  %151 = zext i16 %150 to i64
  %152 = add nuw nsw i64 %147, %151
  %153 = sub nsw i64 11, %4
  %154 = getelementptr inbounds i16, i16* %3, i64 %153
  %155 = load i16, i16* %154, align 2
  %156 = zext i16 %155 to i64
  %157 = add nuw nsw i64 %152, %156
  %158 = sub nsw i64 12, %4
  %159 = getelementptr inbounds i16, i16* %3, i64 %158
  %160 = load i16, i16* %159, align 2
  %161 = zext i16 %160 to i64
  %162 = add nuw nsw i64 %157, %161
  %163 = sub nsw i64 13, %4
  %164 = getelementptr inbounds i16, i16* %3, i64 %163
  %165 = load i16, i16* %164, align 2
  %166 = zext i16 %165 to i64
  %167 = add nuw nsw i64 %162, %166
  %168 = sub nsw i64 14, %4
  %169 = getelementptr inbounds i16, i16* %3, i64 %168
  %170 = load i16, i16* %169, align 2
  %171 = zext i16 %170 to i64
  %172 = add nuw nsw i64 %167, %171
  %173 = sub nsw i64 15, %4
  %174 = getelementptr inbounds i16, i16* %3, i64 %173
  %175 = load i16, i16* %174, align 2
  %176 = zext i16 %175 to i64
  %177 = add nuw nsw i64 %172, %176
  %178 = add nuw nsw i64 %177, 16
  %179 = lshr i64 %178, 5
  %180 = and i64 %179, 134217727
  %181 = mul i64 %180, 281479271743489
  %182 = bitcast i8* %0 to i64*
  store i64 %181, i64* %182, align 8
  %183 = getelementptr inbounds i8, i8* %0, i64 8
  %184 = bitcast i8* %183 to i64*
  store i64 %181, i64* %184, align 8
  %185 = getelementptr inbounds i8, i8* %0, i64 16
  %186 = bitcast i8* %185 to i64*
  store i64 %181, i64* %186, align 8
  %187 = getelementptr inbounds i8, i8* %0, i64 24
  %188 = bitcast i8* %187 to i64*
  store i64 %181, i64* %188, align 8
  %189 = getelementptr inbounds i16, i16* %3, i64 %4
  %190 = bitcast i16* %189 to i64*
  store i64 %181, i64* %190, align 8
  %191 = getelementptr inbounds i16, i16* %189, i64 4
  %192 = bitcast i16* %191 to i64*
  store i64 %181, i64* %192, align 8
  %193 = getelementptr inbounds i16, i16* %189, i64 8
  %194 = bitcast i16* %193 to i64*
  store i64 %181, i64* %194, align 8
  %195 = getelementptr inbounds i16, i16* %189, i64 12
  %196 = bitcast i16* %195 to i64*
  store i64 %181, i64* %196, align 8
  %197 = getelementptr inbounds i16, i16* %189, i64 %4
  %198 = bitcast i16* %197 to i64*
  store i64 %181, i64* %198, align 8
  %199 = getelementptr inbounds i16, i16* %197, i64 4
  %200 = bitcast i16* %199 to i64*
  store i64 %181, i64* %200, align 8
  %201 = getelementptr inbounds i16, i16* %197, i64 8
  %202 = bitcast i16* %201 to i64*
  store i64 %181, i64* %202, align 8
  %203 = getelementptr inbounds i16, i16* %197, i64 12
  %204 = bitcast i16* %203 to i64*
  store i64 %181, i64* %204, align 8
  %205 = getelementptr inbounds i16, i16* %197, i64 %4
  %206 = bitcast i16* %205 to i64*
  store i64 %181, i64* %206, align 8
  %207 = getelementptr inbounds i16, i16* %205, i64 4
  %208 = bitcast i16* %207 to i64*
  store i64 %181, i64* %208, align 8
  %209 = getelementptr inbounds i16, i16* %205, i64 8
  %210 = bitcast i16* %209 to i64*
  store i64 %181, i64* %210, align 8
  %211 = getelementptr inbounds i16, i16* %205, i64 12
  %212 = bitcast i16* %211 to i64*
  store i64 %181, i64* %212, align 8
  %213 = getelementptr inbounds i16, i16* %205, i64 %4
  %214 = bitcast i16* %213 to i64*
  store i64 %181, i64* %214, align 8
  %215 = getelementptr inbounds i16, i16* %213, i64 4
  %216 = bitcast i16* %215 to i64*
  store i64 %181, i64* %216, align 8
  %217 = getelementptr inbounds i16, i16* %213, i64 8
  %218 = bitcast i16* %217 to i64*
  store i64 %181, i64* %218, align 8
  %219 = getelementptr inbounds i16, i16* %213, i64 12
  %220 = bitcast i16* %219 to i64*
  store i64 %181, i64* %220, align 8
  %221 = getelementptr inbounds i16, i16* %213, i64 %4
  %222 = bitcast i16* %221 to i64*
  store i64 %181, i64* %222, align 8
  %223 = getelementptr inbounds i16, i16* %221, i64 4
  %224 = bitcast i16* %223 to i64*
  store i64 %181, i64* %224, align 8
  %225 = getelementptr inbounds i16, i16* %221, i64 8
  %226 = bitcast i16* %225 to i64*
  store i64 %181, i64* %226, align 8
  %227 = getelementptr inbounds i16, i16* %221, i64 12
  %228 = bitcast i16* %227 to i64*
  store i64 %181, i64* %228, align 8
  %229 = getelementptr inbounds i16, i16* %221, i64 %4
  %230 = bitcast i16* %229 to i64*
  store i64 %181, i64* %230, align 8
  %231 = getelementptr inbounds i16, i16* %229, i64 4
  %232 = bitcast i16* %231 to i64*
  store i64 %181, i64* %232, align 8
  %233 = getelementptr inbounds i16, i16* %229, i64 8
  %234 = bitcast i16* %233 to i64*
  store i64 %181, i64* %234, align 8
  %235 = getelementptr inbounds i16, i16* %229, i64 12
  %236 = bitcast i16* %235 to i64*
  store i64 %181, i64* %236, align 8
  %237 = getelementptr inbounds i16, i16* %229, i64 %4
  %238 = bitcast i16* %237 to i64*
  store i64 %181, i64* %238, align 8
  %239 = getelementptr inbounds i16, i16* %237, i64 4
  %240 = bitcast i16* %239 to i64*
  store i64 %181, i64* %240, align 8
  %241 = getelementptr inbounds i16, i16* %237, i64 8
  %242 = bitcast i16* %241 to i64*
  store i64 %181, i64* %242, align 8
  %243 = getelementptr inbounds i16, i16* %237, i64 12
  %244 = bitcast i16* %243 to i64*
  store i64 %181, i64* %244, align 8
  %245 = getelementptr inbounds i16, i16* %237, i64 %4
  %246 = bitcast i16* %245 to i64*
  store i64 %181, i64* %246, align 8
  %247 = getelementptr inbounds i16, i16* %245, i64 4
  %248 = bitcast i16* %247 to i64*
  store i64 %181, i64* %248, align 8
  %249 = getelementptr inbounds i16, i16* %245, i64 8
  %250 = bitcast i16* %249 to i64*
  store i64 %181, i64* %250, align 8
  %251 = getelementptr inbounds i16, i16* %245, i64 12
  %252 = bitcast i16* %251 to i64*
  store i64 %181, i64* %252, align 8
  %253 = getelementptr inbounds i16, i16* %245, i64 %4
  %254 = bitcast i16* %253 to i64*
  store i64 %181, i64* %254, align 8
  %255 = getelementptr inbounds i16, i16* %253, i64 4
  %256 = bitcast i16* %255 to i64*
  store i64 %181, i64* %256, align 8
  %257 = getelementptr inbounds i16, i16* %253, i64 8
  %258 = bitcast i16* %257 to i64*
  store i64 %181, i64* %258, align 8
  %259 = getelementptr inbounds i16, i16* %253, i64 12
  %260 = bitcast i16* %259 to i64*
  store i64 %181, i64* %260, align 8
  %261 = getelementptr inbounds i16, i16* %253, i64 %4
  %262 = bitcast i16* %261 to i64*
  store i64 %181, i64* %262, align 8
  %263 = getelementptr inbounds i16, i16* %261, i64 4
  %264 = bitcast i16* %263 to i64*
  store i64 %181, i64* %264, align 8
  %265 = getelementptr inbounds i16, i16* %261, i64 8
  %266 = bitcast i16* %265 to i64*
  store i64 %181, i64* %266, align 8
  %267 = getelementptr inbounds i16, i16* %261, i64 12
  %268 = bitcast i16* %267 to i64*
  store i64 %181, i64* %268, align 8
  %269 = getelementptr inbounds i16, i16* %261, i64 %4
  %270 = bitcast i16* %269 to i64*
  store i64 %181, i64* %270, align 8
  %271 = getelementptr inbounds i16, i16* %269, i64 4
  %272 = bitcast i16* %271 to i64*
  store i64 %181, i64* %272, align 8
  %273 = getelementptr inbounds i16, i16* %269, i64 8
  %274 = bitcast i16* %273 to i64*
  store i64 %181, i64* %274, align 8
  %275 = getelementptr inbounds i16, i16* %269, i64 12
  %276 = bitcast i16* %275 to i64*
  store i64 %181, i64* %276, align 8
  %277 = getelementptr inbounds i16, i16* %269, i64 %4
  %278 = bitcast i16* %277 to i64*
  store i64 %181, i64* %278, align 8
  %279 = getelementptr inbounds i16, i16* %277, i64 4
  %280 = bitcast i16* %279 to i64*
  store i64 %181, i64* %280, align 8
  %281 = getelementptr inbounds i16, i16* %277, i64 8
  %282 = bitcast i16* %281 to i64*
  store i64 %181, i64* %282, align 8
  %283 = getelementptr inbounds i16, i16* %277, i64 12
  %284 = bitcast i16* %283 to i64*
  store i64 %181, i64* %284, align 8
  %285 = getelementptr inbounds i16, i16* %277, i64 %4
  %286 = bitcast i16* %285 to i64*
  store i64 %181, i64* %286, align 8
  %287 = getelementptr inbounds i16, i16* %285, i64 4
  %288 = bitcast i16* %287 to i64*
  store i64 %181, i64* %288, align 8
  %289 = getelementptr inbounds i16, i16* %285, i64 8
  %290 = bitcast i16* %289 to i64*
  store i64 %181, i64* %290, align 8
  %291 = getelementptr inbounds i16, i16* %285, i64 12
  %292 = bitcast i16* %291 to i64*
  store i64 %181, i64* %292, align 8
  %293 = getelementptr inbounds i16, i16* %285, i64 %4
  %294 = bitcast i16* %293 to i64*
  store i64 %181, i64* %294, align 8
  %295 = getelementptr inbounds i16, i16* %293, i64 4
  %296 = bitcast i16* %295 to i64*
  store i64 %181, i64* %296, align 8
  %297 = getelementptr inbounds i16, i16* %293, i64 8
  %298 = bitcast i16* %297 to i64*
  store i64 %181, i64* %298, align 8
  %299 = getelementptr inbounds i16, i16* %293, i64 12
  %300 = bitcast i16* %299 to i64*
  store i64 %181, i64* %300, align 8
  %301 = getelementptr inbounds i16, i16* %293, i64 %4
  %302 = bitcast i16* %301 to i64*
  store i64 %181, i64* %302, align 8
  %303 = getelementptr inbounds i16, i16* %301, i64 4
  %304 = bitcast i16* %303 to i64*
  store i64 %181, i64* %304, align 8
  %305 = getelementptr inbounds i16, i16* %301, i64 8
  %306 = bitcast i16* %305 to i64*
  store i64 %181, i64* %306, align 8
  %307 = getelementptr inbounds i16, i16* %301, i64 12
  %308 = bitcast i16* %307 to i64*
  store i64 %181, i64* %308, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_vertical_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = shl i64 %4, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %3, i64 %7
  %9 = bitcast i16* %8 to i64*
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds i16, i16* %8, i64 4
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = getelementptr inbounds i16, i16* %8, i64 8
  %15 = bitcast i16* %14 to i64*
  %16 = load i64, i64* %15, align 8
  %17 = getelementptr inbounds i16, i16* %8, i64 12
  %18 = bitcast i16* %17 to i64*
  %19 = load i64, i64* %18, align 8
  %20 = shl i64 %4, 32
  %21 = ashr exact i64 %20, 32
  %22 = bitcast i8* %0 to i64*
  store i64 %10, i64* %22, align 8
  %23 = getelementptr inbounds i8, i8* %0, i64 8
  %24 = bitcast i8* %23 to i64*
  store i64 %13, i64* %24, align 8
  %25 = getelementptr inbounds i8, i8* %0, i64 16
  %26 = bitcast i8* %25 to i64*
  store i64 %16, i64* %26, align 8
  %27 = getelementptr inbounds i8, i8* %0, i64 24
  %28 = bitcast i8* %27 to i64*
  store i64 %19, i64* %28, align 8
  %29 = getelementptr inbounds i16, i16* %3, i64 %21
  %30 = bitcast i16* %29 to i64*
  store i64 %10, i64* %30, align 8
  %31 = getelementptr inbounds i16, i16* %29, i64 4
  %32 = bitcast i16* %31 to i64*
  store i64 %13, i64* %32, align 8
  %33 = getelementptr inbounds i16, i16* %29, i64 8
  %34 = bitcast i16* %33 to i64*
  store i64 %16, i64* %34, align 8
  %35 = getelementptr inbounds i16, i16* %29, i64 12
  %36 = bitcast i16* %35 to i64*
  store i64 %19, i64* %36, align 8
  %37 = ashr exact i64 %20, 31
  %38 = getelementptr inbounds i16, i16* %3, i64 %37
  %39 = bitcast i16* %38 to i64*
  store i64 %10, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %38, i64 4
  %41 = bitcast i16* %40 to i64*
  store i64 %13, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %38, i64 8
  %43 = bitcast i16* %42 to i64*
  store i64 %16, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %38, i64 12
  %45 = bitcast i16* %44 to i64*
  store i64 %19, i64* %45, align 8
  %46 = mul nsw i64 %21, 3
  %47 = getelementptr inbounds i16, i16* %3, i64 %46
  %48 = bitcast i16* %47 to i64*
  store i64 %10, i64* %48, align 8
  %49 = getelementptr inbounds i16, i16* %47, i64 4
  %50 = bitcast i16* %49 to i64*
  store i64 %13, i64* %50, align 8
  %51 = getelementptr inbounds i16, i16* %47, i64 8
  %52 = bitcast i16* %51 to i64*
  store i64 %16, i64* %52, align 8
  %53 = getelementptr inbounds i16, i16* %47, i64 12
  %54 = bitcast i16* %53 to i64*
  store i64 %19, i64* %54, align 8
  %55 = ashr exact i64 %20, 30
  %56 = getelementptr inbounds i16, i16* %3, i64 %55
  %57 = bitcast i16* %56 to i64*
  store i64 %10, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %56, i64 4
  %59 = bitcast i16* %58 to i64*
  store i64 %13, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %56, i64 8
  %61 = bitcast i16* %60 to i64*
  store i64 %16, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %56, i64 12
  %63 = bitcast i16* %62 to i64*
  store i64 %19, i64* %63, align 8
  %64 = mul nsw i64 %21, 5
  %65 = getelementptr inbounds i16, i16* %3, i64 %64
  %66 = bitcast i16* %65 to i64*
  store i64 %10, i64* %66, align 8
  %67 = getelementptr inbounds i16, i16* %65, i64 4
  %68 = bitcast i16* %67 to i64*
  store i64 %13, i64* %68, align 8
  %69 = getelementptr inbounds i16, i16* %65, i64 8
  %70 = bitcast i16* %69 to i64*
  store i64 %16, i64* %70, align 8
  %71 = getelementptr inbounds i16, i16* %65, i64 12
  %72 = bitcast i16* %71 to i64*
  store i64 %19, i64* %72, align 8
  %73 = mul nsw i64 %21, 6
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = bitcast i16* %74 to i64*
  store i64 %10, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %74, i64 4
  %77 = bitcast i16* %76 to i64*
  store i64 %13, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %74, i64 8
  %79 = bitcast i16* %78 to i64*
  store i64 %16, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %74, i64 12
  %81 = bitcast i16* %80 to i64*
  store i64 %19, i64* %81, align 8
  %82 = mul nsw i64 %21, 7
  %83 = getelementptr inbounds i16, i16* %3, i64 %82
  %84 = bitcast i16* %83 to i64*
  store i64 %10, i64* %84, align 8
  %85 = getelementptr inbounds i16, i16* %83, i64 4
  %86 = bitcast i16* %85 to i64*
  store i64 %13, i64* %86, align 8
  %87 = getelementptr inbounds i16, i16* %83, i64 8
  %88 = bitcast i16* %87 to i64*
  store i64 %16, i64* %88, align 8
  %89 = getelementptr inbounds i16, i16* %83, i64 12
  %90 = bitcast i16* %89 to i64*
  store i64 %19, i64* %90, align 8
  %91 = ashr exact i64 %20, 29
  %92 = getelementptr inbounds i16, i16* %3, i64 %91
  %93 = bitcast i16* %92 to i64*
  store i64 %10, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %13, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 %16, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 %19, i64* %99, align 8
  %100 = mul nsw i64 %21, 9
  %101 = getelementptr inbounds i16, i16* %3, i64 %100
  %102 = bitcast i16* %101 to i64*
  store i64 %10, i64* %102, align 8
  %103 = getelementptr inbounds i16, i16* %101, i64 4
  %104 = bitcast i16* %103 to i64*
  store i64 %13, i64* %104, align 8
  %105 = getelementptr inbounds i16, i16* %101, i64 8
  %106 = bitcast i16* %105 to i64*
  store i64 %16, i64* %106, align 8
  %107 = getelementptr inbounds i16, i16* %101, i64 12
  %108 = bitcast i16* %107 to i64*
  store i64 %19, i64* %108, align 8
  %109 = mul nsw i64 %21, 10
  %110 = getelementptr inbounds i16, i16* %3, i64 %109
  %111 = bitcast i16* %110 to i64*
  store i64 %10, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %110, i64 4
  %113 = bitcast i16* %112 to i64*
  store i64 %13, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %110, i64 8
  %115 = bitcast i16* %114 to i64*
  store i64 %16, i64* %115, align 8
  %116 = getelementptr inbounds i16, i16* %110, i64 12
  %117 = bitcast i16* %116 to i64*
  store i64 %19, i64* %117, align 8
  %118 = mul nsw i64 %21, 11
  %119 = getelementptr inbounds i16, i16* %3, i64 %118
  %120 = bitcast i16* %119 to i64*
  store i64 %10, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %119, i64 4
  %122 = bitcast i16* %121 to i64*
  store i64 %13, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %119, i64 8
  %124 = bitcast i16* %123 to i64*
  store i64 %16, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %119, i64 12
  %126 = bitcast i16* %125 to i64*
  store i64 %19, i64* %126, align 8
  %127 = mul nsw i64 %21, 12
  %128 = getelementptr inbounds i16, i16* %3, i64 %127
  %129 = bitcast i16* %128 to i64*
  store i64 %10, i64* %129, align 8
  %130 = getelementptr inbounds i16, i16* %128, i64 4
  %131 = bitcast i16* %130 to i64*
  store i64 %13, i64* %131, align 8
  %132 = getelementptr inbounds i16, i16* %128, i64 8
  %133 = bitcast i16* %132 to i64*
  store i64 %16, i64* %133, align 8
  %134 = getelementptr inbounds i16, i16* %128, i64 12
  %135 = bitcast i16* %134 to i64*
  store i64 %19, i64* %135, align 8
  %136 = mul nsw i64 %21, 13
  %137 = getelementptr inbounds i16, i16* %3, i64 %136
  %138 = bitcast i16* %137 to i64*
  store i64 %10, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %137, i64 4
  %140 = bitcast i16* %139 to i64*
  store i64 %13, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %137, i64 8
  %142 = bitcast i16* %141 to i64*
  store i64 %16, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %137, i64 12
  %144 = bitcast i16* %143 to i64*
  store i64 %19, i64* %144, align 8
  %145 = mul nsw i64 %21, 14
  %146 = getelementptr inbounds i16, i16* %3, i64 %145
  %147 = bitcast i16* %146 to i64*
  store i64 %10, i64* %147, align 8
  %148 = getelementptr inbounds i16, i16* %146, i64 4
  %149 = bitcast i16* %148 to i64*
  store i64 %13, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %146, i64 8
  %151 = bitcast i16* %150 to i64*
  store i64 %16, i64* %151, align 8
  %152 = getelementptr inbounds i16, i16* %146, i64 12
  %153 = bitcast i16* %152 to i64*
  store i64 %19, i64* %153, align 8
  %154 = mul nsw i64 %21, 15
  %155 = getelementptr inbounds i16, i16* %3, i64 %154
  %156 = bitcast i16* %155 to i64*
  store i64 %10, i64* %156, align 8
  %157 = getelementptr inbounds i16, i16* %155, i64 4
  %158 = bitcast i16* %157 to i64*
  store i64 %13, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %155, i64 8
  %160 = bitcast i16* %159 to i64*
  store i64 %16, i64* %160, align 8
  %161 = getelementptr inbounds i16, i16* %155, i64 12
  %162 = bitcast i16* %161 to i64*
  store i64 %19, i64* %162, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_horizontal_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = mul nuw i64 %8, 281479271743489
  %10 = bitcast i8* %0 to i64*
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds i8, i8* %0, i64 8
  %12 = bitcast i8* %11 to i64*
  store i64 %9, i64* %12, align 8
  %13 = getelementptr inbounds i8, i8* %0, i64 16
  %14 = bitcast i8* %13 to i64*
  store i64 %9, i64* %14, align 8
  %15 = getelementptr inbounds i8, i8* %0, i64 24
  %16 = bitcast i8* %15 to i64*
  store i64 %9, i64* %16, align 8
  %17 = add nsw i64 %4, -1
  %18 = getelementptr inbounds i16, i16* %3, i64 %17
  %19 = load i16, i16* %18, align 2
  %20 = zext i16 %19 to i64
  %21 = mul nuw i64 %20, 281479271743489
  %22 = getelementptr inbounds i16, i16* %3, i64 %4
  %23 = bitcast i16* %22 to i64*
  store i64 %21, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %22, i64 4
  %25 = bitcast i16* %24 to i64*
  store i64 %21, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %22, i64 8
  %27 = bitcast i16* %26 to i64*
  store i64 %21, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %22, i64 12
  %29 = bitcast i16* %28 to i64*
  store i64 %21, i64* %29, align 8
  %30 = and i64 %1, -2
  %31 = add nsw i64 %30, -1
  %32 = getelementptr inbounds i16, i16* %3, i64 %31
  %33 = load i16, i16* %32, align 2
  %34 = zext i16 %33 to i64
  %35 = mul nuw i64 %34, 281479271743489
  %36 = getelementptr inbounds i16, i16* %3, i64 %30
  %37 = bitcast i16* %36 to i64*
  store i64 %35, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 %35, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 %35, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 %35, i64* %43, align 8
  %44 = mul nsw i64 %4, 3
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = mul nuw i64 %48, 281479271743489
  %50 = getelementptr inbounds i16, i16* %3, i64 %44
  %51 = bitcast i16* %50 to i64*
  store i64 %49, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %50, i64 4
  %53 = bitcast i16* %52 to i64*
  store i64 %49, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %50, i64 8
  %55 = bitcast i16* %54 to i64*
  store i64 %49, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %50, i64 12
  %57 = bitcast i16* %56 to i64*
  store i64 %49, i64* %57, align 8
  %58 = shl nsw i64 %4, 2
  %59 = add nsw i64 %58, -1
  %60 = getelementptr inbounds i16, i16* %3, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i64
  %63 = mul nuw i64 %62, 281479271743489
  %64 = getelementptr inbounds i16, i16* %3, i64 %58
  %65 = bitcast i16* %64 to i64*
  store i64 %63, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %64, i64 4
  %67 = bitcast i16* %66 to i64*
  store i64 %63, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %64, i64 8
  %69 = bitcast i16* %68 to i64*
  store i64 %63, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %64, i64 12
  %71 = bitcast i16* %70 to i64*
  store i64 %63, i64* %71, align 8
  %72 = mul nsw i64 %4, 5
  %73 = add nsw i64 %72, -1
  %74 = getelementptr inbounds i16, i16* %3, i64 %73
  %75 = load i16, i16* %74, align 2
  %76 = zext i16 %75 to i64
  %77 = mul nuw i64 %76, 281479271743489
  %78 = getelementptr inbounds i16, i16* %3, i64 %72
  %79 = bitcast i16* %78 to i64*
  store i64 %77, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %78, i64 4
  %81 = bitcast i16* %80 to i64*
  store i64 %77, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %78, i64 8
  %83 = bitcast i16* %82 to i64*
  store i64 %77, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %78, i64 12
  %85 = bitcast i16* %84 to i64*
  store i64 %77, i64* %85, align 8
  %86 = mul nsw i64 %4, 6
  %87 = add nsw i64 %86, -1
  %88 = getelementptr inbounds i16, i16* %3, i64 %87
  %89 = load i16, i16* %88, align 2
  %90 = zext i16 %89 to i64
  %91 = mul nuw i64 %90, 281479271743489
  %92 = getelementptr inbounds i16, i16* %3, i64 %86
  %93 = bitcast i16* %92 to i64*
  store i64 %91, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 %91, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 %91, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 %91, i64* %99, align 8
  %100 = mul nsw i64 %4, 7
  %101 = add nsw i64 %100, -1
  %102 = getelementptr inbounds i16, i16* %3, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i64
  %105 = mul nuw i64 %104, 281479271743489
  %106 = getelementptr inbounds i16, i16* %3, i64 %100
  %107 = bitcast i16* %106 to i64*
  store i64 %105, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %106, i64 4
  %109 = bitcast i16* %108 to i64*
  store i64 %105, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %106, i64 8
  %111 = bitcast i16* %110 to i64*
  store i64 %105, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %106, i64 12
  %113 = bitcast i16* %112 to i64*
  store i64 %105, i64* %113, align 8
  %114 = shl nsw i64 %4, 3
  %115 = add nsw i64 %114, -1
  %116 = getelementptr inbounds i16, i16* %3, i64 %115
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i64
  %119 = mul nuw i64 %118, 281479271743489
  %120 = getelementptr inbounds i16, i16* %3, i64 %114
  %121 = bitcast i16* %120 to i64*
  store i64 %119, i64* %121, align 8
  %122 = getelementptr inbounds i16, i16* %120, i64 4
  %123 = bitcast i16* %122 to i64*
  store i64 %119, i64* %123, align 8
  %124 = getelementptr inbounds i16, i16* %120, i64 8
  %125 = bitcast i16* %124 to i64*
  store i64 %119, i64* %125, align 8
  %126 = getelementptr inbounds i16, i16* %120, i64 12
  %127 = bitcast i16* %126 to i64*
  store i64 %119, i64* %127, align 8
  %128 = mul nsw i64 %4, 9
  %129 = add nsw i64 %128, -1
  %130 = getelementptr inbounds i16, i16* %3, i64 %129
  %131 = load i16, i16* %130, align 2
  %132 = zext i16 %131 to i64
  %133 = mul nuw i64 %132, 281479271743489
  %134 = getelementptr inbounds i16, i16* %3, i64 %128
  %135 = bitcast i16* %134 to i64*
  store i64 %133, i64* %135, align 8
  %136 = getelementptr inbounds i16, i16* %134, i64 4
  %137 = bitcast i16* %136 to i64*
  store i64 %133, i64* %137, align 8
  %138 = getelementptr inbounds i16, i16* %134, i64 8
  %139 = bitcast i16* %138 to i64*
  store i64 %133, i64* %139, align 8
  %140 = getelementptr inbounds i16, i16* %134, i64 12
  %141 = bitcast i16* %140 to i64*
  store i64 %133, i64* %141, align 8
  %142 = mul nsw i64 %4, 10
  %143 = add nsw i64 %142, -1
  %144 = getelementptr inbounds i16, i16* %3, i64 %143
  %145 = load i16, i16* %144, align 2
  %146 = zext i16 %145 to i64
  %147 = mul nuw i64 %146, 281479271743489
  %148 = getelementptr inbounds i16, i16* %3, i64 %142
  %149 = bitcast i16* %148 to i64*
  store i64 %147, i64* %149, align 8
  %150 = getelementptr inbounds i16, i16* %148, i64 4
  %151 = bitcast i16* %150 to i64*
  store i64 %147, i64* %151, align 8
  %152 = getelementptr inbounds i16, i16* %148, i64 8
  %153 = bitcast i16* %152 to i64*
  store i64 %147, i64* %153, align 8
  %154 = getelementptr inbounds i16, i16* %148, i64 12
  %155 = bitcast i16* %154 to i64*
  store i64 %147, i64* %155, align 8
  %156 = mul nsw i64 %4, 11
  %157 = add nsw i64 %156, -1
  %158 = getelementptr inbounds i16, i16* %3, i64 %157
  %159 = load i16, i16* %158, align 2
  %160 = zext i16 %159 to i64
  %161 = mul nuw i64 %160, 281479271743489
  %162 = getelementptr inbounds i16, i16* %3, i64 %156
  %163 = bitcast i16* %162 to i64*
  store i64 %161, i64* %163, align 8
  %164 = getelementptr inbounds i16, i16* %162, i64 4
  %165 = bitcast i16* %164 to i64*
  store i64 %161, i64* %165, align 8
  %166 = getelementptr inbounds i16, i16* %162, i64 8
  %167 = bitcast i16* %166 to i64*
  store i64 %161, i64* %167, align 8
  %168 = getelementptr inbounds i16, i16* %162, i64 12
  %169 = bitcast i16* %168 to i64*
  store i64 %161, i64* %169, align 8
  %170 = mul nsw i64 %4, 12
  %171 = add nsw i64 %170, -1
  %172 = getelementptr inbounds i16, i16* %3, i64 %171
  %173 = load i16, i16* %172, align 2
  %174 = zext i16 %173 to i64
  %175 = mul nuw i64 %174, 281479271743489
  %176 = getelementptr inbounds i16, i16* %3, i64 %170
  %177 = bitcast i16* %176 to i64*
  store i64 %175, i64* %177, align 8
  %178 = getelementptr inbounds i16, i16* %176, i64 4
  %179 = bitcast i16* %178 to i64*
  store i64 %175, i64* %179, align 8
  %180 = getelementptr inbounds i16, i16* %176, i64 8
  %181 = bitcast i16* %180 to i64*
  store i64 %175, i64* %181, align 8
  %182 = getelementptr inbounds i16, i16* %176, i64 12
  %183 = bitcast i16* %182 to i64*
  store i64 %175, i64* %183, align 8
  %184 = mul nsw i64 %4, 13
  %185 = add nsw i64 %184, -1
  %186 = getelementptr inbounds i16, i16* %3, i64 %185
  %187 = load i16, i16* %186, align 2
  %188 = zext i16 %187 to i64
  %189 = mul nuw i64 %188, 281479271743489
  %190 = getelementptr inbounds i16, i16* %3, i64 %184
  %191 = bitcast i16* %190 to i64*
  store i64 %189, i64* %191, align 8
  %192 = getelementptr inbounds i16, i16* %190, i64 4
  %193 = bitcast i16* %192 to i64*
  store i64 %189, i64* %193, align 8
  %194 = getelementptr inbounds i16, i16* %190, i64 8
  %195 = bitcast i16* %194 to i64*
  store i64 %189, i64* %195, align 8
  %196 = getelementptr inbounds i16, i16* %190, i64 12
  %197 = bitcast i16* %196 to i64*
  store i64 %189, i64* %197, align 8
  %198 = mul nsw i64 %4, 14
  %199 = add nsw i64 %198, -1
  %200 = getelementptr inbounds i16, i16* %3, i64 %199
  %201 = load i16, i16* %200, align 2
  %202 = zext i16 %201 to i64
  %203 = mul nuw i64 %202, 281479271743489
  %204 = getelementptr inbounds i16, i16* %3, i64 %198
  %205 = bitcast i16* %204 to i64*
  store i64 %203, i64* %205, align 8
  %206 = getelementptr inbounds i16, i16* %204, i64 4
  %207 = bitcast i16* %206 to i64*
  store i64 %203, i64* %207, align 8
  %208 = getelementptr inbounds i16, i16* %204, i64 8
  %209 = bitcast i16* %208 to i64*
  store i64 %203, i64* %209, align 8
  %210 = getelementptr inbounds i16, i16* %204, i64 12
  %211 = bitcast i16* %210 to i64*
  store i64 %203, i64* %211, align 8
  %212 = mul nsw i64 %4, 15
  %213 = add nsw i64 %212, -1
  %214 = getelementptr inbounds i16, i16* %3, i64 %213
  %215 = load i16, i16* %214, align 2
  %216 = zext i16 %215 to i64
  %217 = mul nuw i64 %216, 281479271743489
  %218 = getelementptr inbounds i16, i16* %3, i64 %212
  %219 = bitcast i16* %218 to i64*
  store i64 %217, i64* %219, align 8
  %220 = getelementptr inbounds i16, i16* %218, i64 4
  %221 = bitcast i16* %220 to i64*
  store i64 %217, i64* %221, align 8
  %222 = getelementptr inbounds i16, i16* %218, i64 8
  %223 = bitcast i16* %222 to i64*
  store i64 %217, i64* %223, align 8
  %224 = getelementptr inbounds i16, i16* %218, i64 12
  %225 = bitcast i16* %224 to i64*
  store i64 %217, i64* %225, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_127_dc_14_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i8, i8* %0, i64 16
  %7 = bitcast i8* %6 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %7, align 8
  %8 = getelementptr inbounds i16, i16* %3, i64 %4
  %9 = bitcast i16* %8 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %9, align 8
  %10 = getelementptr inbounds i16, i16* %8, i64 8
  %11 = bitcast i16* %10 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %11, align 8
  %12 = getelementptr inbounds i16, i16* %8, i64 %4
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %13, align 8
  %14 = getelementptr inbounds i16, i16* %12, i64 8
  %15 = bitcast i16* %14 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %15, align 8
  %16 = getelementptr inbounds i16, i16* %12, i64 %4
  %17 = bitcast i16* %16 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %17, align 8
  %18 = getelementptr inbounds i16, i16* %16, i64 8
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 2305596714850918399, i64 2305596714850918399>, <2 x i64>* %19, align 8
  %20 = getelementptr inbounds i16, i16* %16, i64 %4
  %21 = bitcast i16* %20 to i64*
  store i64 2305596714850918399, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 4
  %23 = bitcast i16* %22 to i64*
  store i64 2305596714850918399, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 8
  %25 = bitcast i16* %24 to i64*
  store i64 2305596714850918399, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 12
  %27 = bitcast i16* %26 to i64*
  store i64 2305596714850918399, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %20, i64 %4
  %29 = bitcast i16* %28 to i64*
  store i64 2305596714850918399, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 2305596714850918399, i64* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 8
  %33 = bitcast i16* %32 to i64*
  store i64 2305596714850918399, i64* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 12
  %35 = bitcast i16* %34 to i64*
  store i64 2305596714850918399, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %4
  %37 = bitcast i16* %36 to i64*
  store i64 2305596714850918399, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 2305596714850918399, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 2305596714850918399, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 2305596714850918399, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %36, i64 %4
  %45 = bitcast i16* %44 to i64*
  store i64 2305596714850918399, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 2305596714850918399, i64* %47, align 8
  %48 = getelementptr inbounds i16, i16* %44, i64 8
  %49 = bitcast i16* %48 to i64*
  store i64 2305596714850918399, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %44, i64 12
  %51 = bitcast i16* %50 to i64*
  store i64 2305596714850918399, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %44, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 2305596714850918399, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 2305596714850918399, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %52, i64 8
  %57 = bitcast i16* %56 to i64*
  store i64 2305596714850918399, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %52, i64 12
  %59 = bitcast i16* %58 to i64*
  store i64 2305596714850918399, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %52, i64 %4
  %61 = bitcast i16* %60 to i64*
  store i64 2305596714850918399, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %60, i64 4
  %63 = bitcast i16* %62 to i64*
  store i64 2305596714850918399, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %60, i64 8
  %65 = bitcast i16* %64 to i64*
  store i64 2305596714850918399, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %60, i64 12
  %67 = bitcast i16* %66 to i64*
  store i64 2305596714850918399, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %60, i64 %4
  %69 = bitcast i16* %68 to i64*
  store i64 2305596714850918399, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 2305596714850918399, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %68, i64 8
  %73 = bitcast i16* %72 to i64*
  store i64 2305596714850918399, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %68, i64 12
  %75 = bitcast i16* %74 to i64*
  store i64 2305596714850918399, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %68, i64 %4
  %77 = bitcast i16* %76 to i64*
  store i64 2305596714850918399, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %76, i64 4
  %79 = bitcast i16* %78 to i64*
  store i64 2305596714850918399, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %76, i64 8
  %81 = bitcast i16* %80 to i64*
  store i64 2305596714850918399, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %76, i64 12
  %83 = bitcast i16* %82 to i64*
  store i64 2305596714850918399, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %76, i64 %4
  %85 = bitcast i16* %84 to i64*
  store i64 2305596714850918399, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 2305596714850918399, i64* %87, align 8
  %88 = getelementptr inbounds i16, i16* %84, i64 8
  %89 = bitcast i16* %88 to i64*
  store i64 2305596714850918399, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %84, i64 12
  %91 = bitcast i16* %90 to i64*
  store i64 2305596714850918399, i64* %91, align 8
  %92 = getelementptr inbounds i16, i16* %84, i64 %4
  %93 = bitcast i16* %92 to i64*
  store i64 2305596714850918399, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 2305596714850918399, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 2305596714850918399, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 2305596714850918399, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %92, i64 %4
  %101 = bitcast i16* %100 to i64*
  store i64 2305596714850918399, i64* %101, align 8
  %102 = getelementptr inbounds i16, i16* %100, i64 4
  %103 = bitcast i16* %102 to i64*
  store i64 2305596714850918399, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %100, i64 8
  %105 = bitcast i16* %104 to i64*
  store i64 2305596714850918399, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %100, i64 12
  %107 = bitcast i16* %106 to i64*
  store i64 2305596714850918399, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %100, i64 %4
  %109 = bitcast i16* %108 to i64*
  store i64 2305596714850918399, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 2305596714850918399, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %108, i64 8
  %113 = bitcast i16* %112 to i64*
  store i64 2305596714850918399, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %108, i64 12
  %115 = bitcast i16* %114 to i64*
  store i64 2305596714850918399, i64* %115, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_129_dc_14_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i8, i8* %0, i64 16
  %7 = bitcast i8* %6 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %7, align 8
  %8 = getelementptr inbounds i16, i16* %3, i64 %4
  %9 = bitcast i16* %8 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %9, align 8
  %10 = getelementptr inbounds i16, i16* %8, i64 8
  %11 = bitcast i16* %10 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %11, align 8
  %12 = getelementptr inbounds i16, i16* %8, i64 %4
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %13, align 8
  %14 = getelementptr inbounds i16, i16* %12, i64 8
  %15 = bitcast i16* %14 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %15, align 8
  %16 = getelementptr inbounds i16, i16* %12, i64 %4
  %17 = bitcast i16* %16 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %17, align 8
  %18 = getelementptr inbounds i16, i16* %16, i64 8
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 2306159673394405377, i64 2306159673394405377>, <2 x i64>* %19, align 8
  %20 = getelementptr inbounds i16, i16* %16, i64 %4
  %21 = bitcast i16* %20 to i64*
  store i64 2306159673394405377, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 4
  %23 = bitcast i16* %22 to i64*
  store i64 2306159673394405377, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 8
  %25 = bitcast i16* %24 to i64*
  store i64 2306159673394405377, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 12
  %27 = bitcast i16* %26 to i64*
  store i64 2306159673394405377, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %20, i64 %4
  %29 = bitcast i16* %28 to i64*
  store i64 2306159673394405377, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 2306159673394405377, i64* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 8
  %33 = bitcast i16* %32 to i64*
  store i64 2306159673394405377, i64* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 12
  %35 = bitcast i16* %34 to i64*
  store i64 2306159673394405377, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %4
  %37 = bitcast i16* %36 to i64*
  store i64 2306159673394405377, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 2306159673394405377, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 2306159673394405377, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 2306159673394405377, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %36, i64 %4
  %45 = bitcast i16* %44 to i64*
  store i64 2306159673394405377, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 2306159673394405377, i64* %47, align 8
  %48 = getelementptr inbounds i16, i16* %44, i64 8
  %49 = bitcast i16* %48 to i64*
  store i64 2306159673394405377, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %44, i64 12
  %51 = bitcast i16* %50 to i64*
  store i64 2306159673394405377, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %44, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 2306159673394405377, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 2306159673394405377, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %52, i64 8
  %57 = bitcast i16* %56 to i64*
  store i64 2306159673394405377, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %52, i64 12
  %59 = bitcast i16* %58 to i64*
  store i64 2306159673394405377, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %52, i64 %4
  %61 = bitcast i16* %60 to i64*
  store i64 2306159673394405377, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %60, i64 4
  %63 = bitcast i16* %62 to i64*
  store i64 2306159673394405377, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %60, i64 8
  %65 = bitcast i16* %64 to i64*
  store i64 2306159673394405377, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %60, i64 12
  %67 = bitcast i16* %66 to i64*
  store i64 2306159673394405377, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %60, i64 %4
  %69 = bitcast i16* %68 to i64*
  store i64 2306159673394405377, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 2306159673394405377, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %68, i64 8
  %73 = bitcast i16* %72 to i64*
  store i64 2306159673394405377, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %68, i64 12
  %75 = bitcast i16* %74 to i64*
  store i64 2306159673394405377, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %68, i64 %4
  %77 = bitcast i16* %76 to i64*
  store i64 2306159673394405377, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %76, i64 4
  %79 = bitcast i16* %78 to i64*
  store i64 2306159673394405377, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %76, i64 8
  %81 = bitcast i16* %80 to i64*
  store i64 2306159673394405377, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %76, i64 12
  %83 = bitcast i16* %82 to i64*
  store i64 2306159673394405377, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %76, i64 %4
  %85 = bitcast i16* %84 to i64*
  store i64 2306159673394405377, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 2306159673394405377, i64* %87, align 8
  %88 = getelementptr inbounds i16, i16* %84, i64 8
  %89 = bitcast i16* %88 to i64*
  store i64 2306159673394405377, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %84, i64 12
  %91 = bitcast i16* %90 to i64*
  store i64 2306159673394405377, i64* %91, align 8
  %92 = getelementptr inbounds i16, i16* %84, i64 %4
  %93 = bitcast i16* %92 to i64*
  store i64 2306159673394405377, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 2306159673394405377, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 2306159673394405377, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 2306159673394405377, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %92, i64 %4
  %101 = bitcast i16* %100 to i64*
  store i64 2306159673394405377, i64* %101, align 8
  %102 = getelementptr inbounds i16, i16* %100, i64 4
  %103 = bitcast i16* %102 to i64*
  store i64 2306159673394405377, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %100, i64 8
  %105 = bitcast i16* %104 to i64*
  store i64 2306159673394405377, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %100, i64 12
  %107 = bitcast i16* %106 to i64*
  store i64 2306159673394405377, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %100, i64 %4
  %109 = bitcast i16* %108 to i64*
  store i64 2306159673394405377, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 2306159673394405377, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %108, i64 8
  %113 = bitcast i16* %112 to i64*
  store i64 2306159673394405377, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %108, i64 12
  %115 = bitcast i16* %114 to i64*
  store i64 2306159673394405377, i64* %115, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_plane_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = lshr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 14
  %6 = bitcast i8* %5 to i16*
  %7 = shl i64 %4, 32
  %8 = ashr exact i64 %7, 32
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i16, i16* %6, i64 %9
  %11 = shl i64 %4, 35
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i16, i16* %3, i64 %12
  %14 = getelementptr inbounds i16, i16* %13, i64 -1
  %15 = shl i64 %1, 32
  %16 = ashr exact i64 %15, 32
  %17 = and i64 %16, -2
  %18 = sub nsw i64 0, %17
  %19 = getelementptr inbounds i16, i16* %14, i64 %18
  %20 = getelementptr inbounds i16, i16* %10, i64 1
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i32
  %23 = getelementptr inbounds i16, i16* %10, i64 -1
  %24 = load i16, i16* %23, align 2
  %25 = zext i16 %24 to i32
  %26 = sub nsw i32 %22, %25
  %27 = load i16, i16* %14, align 2
  %28 = zext i16 %27 to i32
  %29 = load i16, i16* %19, align 2
  %30 = zext i16 %29 to i32
  %31 = sub nsw i32 %28, %30
  %32 = mul nsw i64 %8, 14
  %33 = ashr exact i64 %11, 31
  %34 = add nsw i64 %33, -2
  %35 = add nsw i64 %34, %32
  %36 = getelementptr i8, i8* %0, i64 %35
  %37 = lshr i64 %16, 1
  %38 = shl i64 %37, 2
  %39 = sub i64 %34, %38
  %40 = sub i64 %39, %32
  %41 = getelementptr i8, i8* %0, i64 %40
  %42 = getelementptr inbounds i16, i16* %14, i64 %8
  %43 = getelementptr inbounds i16, i16* %19, i64 %9
  %44 = getelementptr inbounds i16, i16* %10, i64 2
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = getelementptr inbounds i16, i16* %10, i64 -2
  %48 = load i16, i16* %47, align 2
  %49 = zext i16 %48 to i32
  %50 = sub nsw i32 %46, %49
  %51 = shl nsw i32 %50, 1
  %52 = add nsw i32 %26, %51
  %53 = load i16, i16* %42, align 2
  %54 = zext i16 %53 to i32
  %55 = load i16, i16* %43, align 2
  %56 = zext i16 %55 to i32
  %57 = sub nsw i32 %54, %56
  %58 = shl nsw i32 %57, 1
  %59 = add nsw i32 %31, %58
  %60 = getelementptr inbounds i16, i16* %42, i64 %8
  %61 = getelementptr inbounds i16, i16* %43, i64 %9
  %62 = getelementptr inbounds i16, i16* %10, i64 3
  %63 = load i16, i16* %62, align 2
  %64 = zext i16 %63 to i32
  %65 = getelementptr inbounds i16, i16* %10, i64 -3
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i32
  %68 = sub nsw i32 %64, %67
  %69 = mul nsw i32 %68, 3
  %70 = add nsw i32 %52, %69
  %71 = load i16, i16* %60, align 2
  %72 = zext i16 %71 to i32
  %73 = load i16, i16* %61, align 2
  %74 = zext i16 %73 to i32
  %75 = sub nsw i32 %72, %74
  %76 = mul nsw i32 %75, 3
  %77 = add nsw i32 %59, %76
  %78 = getelementptr inbounds i16, i16* %60, i64 %8
  %79 = getelementptr inbounds i16, i16* %61, i64 %9
  %80 = getelementptr inbounds i16, i16* %10, i64 4
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i32
  %83 = getelementptr inbounds i16, i16* %10, i64 -4
  %84 = load i16, i16* %83, align 2
  %85 = zext i16 %84 to i32
  %86 = sub nsw i32 %82, %85
  %87 = shl nsw i32 %86, 2
  %88 = add nsw i32 %70, %87
  %89 = load i16, i16* %78, align 2
  %90 = zext i16 %89 to i32
  %91 = load i16, i16* %79, align 2
  %92 = zext i16 %91 to i32
  %93 = sub nsw i32 %90, %92
  %94 = shl nsw i32 %93, 2
  %95 = add nsw i32 %77, %94
  %96 = getelementptr inbounds i16, i16* %78, i64 %8
  %97 = getelementptr inbounds i16, i16* %79, i64 %9
  %98 = getelementptr inbounds i16, i16* %10, i64 5
  %99 = load i16, i16* %98, align 2
  %100 = zext i16 %99 to i32
  %101 = getelementptr inbounds i16, i16* %10, i64 -5
  %102 = load i16, i16* %101, align 2
  %103 = zext i16 %102 to i32
  %104 = sub nsw i32 %100, %103
  %105 = mul nsw i32 %104, 5
  %106 = add nsw i32 %88, %105
  %107 = load i16, i16* %96, align 2
  %108 = zext i16 %107 to i32
  %109 = load i16, i16* %97, align 2
  %110 = zext i16 %109 to i32
  %111 = sub nsw i32 %108, %110
  %112 = mul nsw i32 %111, 5
  %113 = add nsw i32 %95, %112
  %114 = getelementptr inbounds i16, i16* %96, i64 %8
  %115 = getelementptr inbounds i16, i16* %97, i64 %9
  %116 = getelementptr inbounds i16, i16* %10, i64 6
  %117 = load i16, i16* %116, align 2
  %118 = zext i16 %117 to i32
  %119 = getelementptr inbounds i16, i16* %10, i64 -6
  %120 = load i16, i16* %119, align 2
  %121 = zext i16 %120 to i32
  %122 = sub nsw i32 %118, %121
  %123 = mul nsw i32 %122, 6
  %124 = add nsw i32 %106, %123
  %125 = load i16, i16* %114, align 2
  %126 = zext i16 %125 to i32
  %127 = load i16, i16* %115, align 2
  %128 = zext i16 %127 to i32
  %129 = sub nsw i32 %126, %128
  %130 = mul nsw i32 %129, 6
  %131 = add nsw i32 %113, %130
  %132 = getelementptr inbounds i16, i16* %114, i64 %8
  %133 = getelementptr inbounds i16, i16* %115, i64 %9
  %134 = getelementptr inbounds i16, i16* %10, i64 7
  %135 = load i16, i16* %134, align 2
  %136 = zext i16 %135 to i32
  %137 = getelementptr inbounds i16, i16* %10, i64 -7
  %138 = load i16, i16* %137, align 2
  %139 = zext i16 %138 to i32
  %140 = sub nsw i32 %136, %139
  %141 = mul nsw i32 %140, 7
  %142 = add nsw i32 %124, %141
  %143 = load i16, i16* %132, align 2
  %144 = zext i16 %143 to i32
  %145 = load i16, i16* %133, align 2
  %146 = zext i16 %145 to i32
  %147 = sub nsw i32 %144, %146
  %148 = mul nsw i32 %147, 7
  %149 = add nsw i32 %131, %148
  %150 = getelementptr inbounds i16, i16* %132, i64 %8
  %151 = getelementptr inbounds i16, i16* %133, i64 %9
  %152 = getelementptr inbounds i16, i16* %10, i64 8
  %153 = load i16, i16* %152, align 2
  %154 = zext i16 %153 to i32
  %155 = getelementptr inbounds i16, i16* %10, i64 -8
  %156 = load i16, i16* %155, align 2
  %157 = zext i16 %156 to i32
  %158 = sub nsw i32 %154, %157
  %159 = shl nsw i32 %158, 3
  %160 = add nsw i32 %142, %159
  %161 = load i16, i16* %150, align 2
  %162 = zext i16 %161 to i32
  %163 = load i16, i16* %151, align 2
  %164 = zext i16 %163 to i32
  %165 = sub nsw i32 %162, %164
  %166 = shl nsw i32 %165, 3
  %167 = add nsw i32 %149, %166
  %168 = bitcast i8* %36 to i16*
  %169 = mul nsw i32 %160, 5
  %170 = add nsw i32 %169, 32
  %171 = ashr i32 %170, 6
  %172 = mul nsw i32 %167, 5
  %173 = add nsw i32 %172, 32
  %174 = ashr i32 %173, 6
  %175 = load i16, i16* %168, align 2
  %176 = zext i16 %175 to i32
  %177 = getelementptr inbounds i8, i8* %41, i64 32
  %178 = bitcast i8* %177 to i16*
  %179 = load i16, i16* %178, align 2
  %180 = zext i16 %179 to i32
  %181 = add nuw nsw i32 %180, %176
  %182 = shl nuw nsw i32 %181, 4
  %183 = add nsw i32 %174, %171
  %184 = mul nsw i32 %183, -7
  %185 = add nuw nsw i32 %182, 16
  %186 = add nsw i32 %185, %184
  %187 = shl nsw i32 %171, 1
  %188 = mul nsw i32 %171, 3
  %189 = shl nsw i32 %171, 2
  br label %190

190:                                              ; preds = %364, %2
  %191 = phi i16* [ %3, %2 ], [ %369, %364 ]
  %192 = phi i32 [ %186, %2 ], [ %368, %364 ]
  %193 = phi i32 [ 16, %2 ], [ %370, %364 ]
  %194 = ashr i32 %192, 5
  %195 = icmp ult i32 %194, 16384
  br i1 %195, label %200, label %196

196:                                              ; preds = %190
  %197 = ashr i32 %192, 31
  %198 = or i32 %197, -16384
  %199 = xor i32 %198, -1
  br label %200

200:                                              ; preds = %196, %190
  %201 = phi i32 [ %199, %196 ], [ %194, %190 ]
  %202 = trunc i32 %201 to i16
  store i16 %202, i16* %191, align 2
  %203 = add nsw i32 %192, %171
  %204 = ashr i32 %203, 5
  %205 = icmp ult i32 %204, 16384
  br i1 %205, label %210, label %206

206:                                              ; preds = %200
  %207 = ashr i32 %203, 31
  %208 = or i32 %207, -16384
  %209 = xor i32 %208, -1
  br label %210

210:                                              ; preds = %206, %200
  %211 = phi i32 [ %209, %206 ], [ %204, %200 ]
  %212 = trunc i32 %211 to i16
  %213 = getelementptr inbounds i16, i16* %191, i64 1
  store i16 %212, i16* %213, align 2
  %214 = add nsw i32 %192, %187
  %215 = ashr i32 %214, 5
  %216 = icmp ult i32 %215, 16384
  br i1 %216, label %221, label %217

217:                                              ; preds = %210
  %218 = ashr i32 %214, 31
  %219 = or i32 %218, -16384
  %220 = xor i32 %219, -1
  br label %221

221:                                              ; preds = %217, %210
  %222 = phi i32 [ %220, %217 ], [ %215, %210 ]
  %223 = trunc i32 %222 to i16
  %224 = getelementptr inbounds i16, i16* %191, i64 2
  store i16 %223, i16* %224, align 2
  %225 = add nsw i32 %192, %188
  %226 = ashr i32 %225, 5
  %227 = icmp ult i32 %226, 16384
  br i1 %227, label %232, label %228

228:                                              ; preds = %221
  %229 = ashr i32 %225, 31
  %230 = or i32 %229, -16384
  %231 = xor i32 %230, -1
  br label %232

232:                                              ; preds = %228, %221
  %233 = phi i32 [ %231, %228 ], [ %226, %221 ]
  %234 = trunc i32 %233 to i16
  %235 = getelementptr inbounds i16, i16* %191, i64 3
  store i16 %234, i16* %235, align 2
  %236 = add nsw i32 %192, %189
  %237 = ashr i32 %236, 5
  %238 = icmp ult i32 %237, 16384
  br i1 %238, label %243, label %239

239:                                              ; preds = %232
  %240 = ashr i32 %236, 31
  %241 = or i32 %240, -16384
  %242 = xor i32 %241, -1
  br label %243

243:                                              ; preds = %239, %232
  %244 = phi i32 [ %242, %239 ], [ %237, %232 ]
  %245 = trunc i32 %244 to i16
  %246 = getelementptr inbounds i16, i16* %191, i64 4
  store i16 %245, i16* %246, align 2
  %247 = add nsw i32 %236, %171
  %248 = ashr i32 %247, 5
  %249 = icmp ult i32 %248, 16384
  br i1 %249, label %254, label %250

250:                                              ; preds = %243
  %251 = ashr i32 %247, 31
  %252 = or i32 %251, -16384
  %253 = xor i32 %252, -1
  br label %254

254:                                              ; preds = %250, %243
  %255 = phi i32 [ %253, %250 ], [ %248, %243 ]
  %256 = trunc i32 %255 to i16
  %257 = getelementptr inbounds i16, i16* %191, i64 5
  store i16 %256, i16* %257, align 2
  %258 = add nsw i32 %236, %187
  %259 = ashr i32 %258, 5
  %260 = icmp ult i32 %259, 16384
  br i1 %260, label %265, label %261

261:                                              ; preds = %254
  %262 = ashr i32 %258, 31
  %263 = or i32 %262, -16384
  %264 = xor i32 %263, -1
  br label %265

265:                                              ; preds = %261, %254
  %266 = phi i32 [ %264, %261 ], [ %259, %254 ]
  %267 = trunc i32 %266 to i16
  %268 = getelementptr inbounds i16, i16* %191, i64 6
  store i16 %267, i16* %268, align 2
  %269 = add nsw i32 %236, %188
  %270 = ashr i32 %269, 5
  %271 = icmp ult i32 %270, 16384
  br i1 %271, label %276, label %272

272:                                              ; preds = %265
  %273 = ashr i32 %269, 31
  %274 = or i32 %273, -16384
  %275 = xor i32 %274, -1
  br label %276

276:                                              ; preds = %272, %265
  %277 = phi i32 [ %275, %272 ], [ %270, %265 ]
  %278 = trunc i32 %277 to i16
  %279 = getelementptr inbounds i16, i16* %191, i64 7
  store i16 %278, i16* %279, align 2
  %280 = add nsw i32 %236, %189
  %281 = ashr i32 %280, 5
  %282 = icmp ult i32 %281, 16384
  br i1 %282, label %287, label %283

283:                                              ; preds = %276
  %284 = ashr i32 %280, 31
  %285 = or i32 %284, -16384
  %286 = xor i32 %285, -1
  br label %287

287:                                              ; preds = %283, %276
  %288 = phi i32 [ %286, %283 ], [ %281, %276 ]
  %289 = trunc i32 %288 to i16
  %290 = getelementptr inbounds i16, i16* %191, i64 8
  store i16 %289, i16* %290, align 2
  %291 = add nsw i32 %280, %171
  %292 = ashr i32 %291, 5
  %293 = icmp ult i32 %292, 16384
  br i1 %293, label %298, label %294

294:                                              ; preds = %287
  %295 = ashr i32 %291, 31
  %296 = or i32 %295, -16384
  %297 = xor i32 %296, -1
  br label %298

298:                                              ; preds = %294, %287
  %299 = phi i32 [ %297, %294 ], [ %292, %287 ]
  %300 = trunc i32 %299 to i16
  %301 = getelementptr inbounds i16, i16* %191, i64 9
  store i16 %300, i16* %301, align 2
  %302 = add nsw i32 %280, %187
  %303 = ashr i32 %302, 5
  %304 = icmp ult i32 %303, 16384
  br i1 %304, label %309, label %305

305:                                              ; preds = %298
  %306 = ashr i32 %302, 31
  %307 = or i32 %306, -16384
  %308 = xor i32 %307, -1
  br label %309

309:                                              ; preds = %305, %298
  %310 = phi i32 [ %308, %305 ], [ %303, %298 ]
  %311 = trunc i32 %310 to i16
  %312 = getelementptr inbounds i16, i16* %191, i64 10
  store i16 %311, i16* %312, align 2
  %313 = add nsw i32 %280, %188
  %314 = ashr i32 %313, 5
  %315 = icmp ult i32 %314, 16384
  br i1 %315, label %320, label %316

316:                                              ; preds = %309
  %317 = ashr i32 %313, 31
  %318 = or i32 %317, -16384
  %319 = xor i32 %318, -1
  br label %320

320:                                              ; preds = %316, %309
  %321 = phi i32 [ %319, %316 ], [ %314, %309 ]
  %322 = trunc i32 %321 to i16
  %323 = getelementptr inbounds i16, i16* %191, i64 11
  store i16 %322, i16* %323, align 2
  %324 = add nsw i32 %280, %189
  %325 = ashr i32 %324, 5
  %326 = icmp ult i32 %325, 16384
  br i1 %326, label %331, label %327

327:                                              ; preds = %320
  %328 = ashr i32 %324, 31
  %329 = or i32 %328, -16384
  %330 = xor i32 %329, -1
  br label %331

331:                                              ; preds = %327, %320
  %332 = phi i32 [ %330, %327 ], [ %325, %320 ]
  %333 = trunc i32 %332 to i16
  %334 = getelementptr inbounds i16, i16* %191, i64 12
  store i16 %333, i16* %334, align 2
  %335 = add nsw i32 %324, %171
  %336 = ashr i32 %335, 5
  %337 = icmp ult i32 %336, 16384
  br i1 %337, label %342, label %338

338:                                              ; preds = %331
  %339 = ashr i32 %335, 31
  %340 = or i32 %339, -16384
  %341 = xor i32 %340, -1
  br label %342

342:                                              ; preds = %338, %331
  %343 = phi i32 [ %341, %338 ], [ %336, %331 ]
  %344 = trunc i32 %343 to i16
  %345 = getelementptr inbounds i16, i16* %191, i64 13
  store i16 %344, i16* %345, align 2
  %346 = add nsw i32 %324, %187
  %347 = ashr i32 %346, 5
  %348 = icmp ult i32 %347, 16384
  br i1 %348, label %353, label %349

349:                                              ; preds = %342
  %350 = ashr i32 %346, 31
  %351 = or i32 %350, -16384
  %352 = xor i32 %351, -1
  br label %353

353:                                              ; preds = %349, %342
  %354 = phi i32 [ %352, %349 ], [ %347, %342 ]
  %355 = trunc i32 %354 to i16
  %356 = getelementptr inbounds i16, i16* %191, i64 14
  store i16 %355, i16* %356, align 2
  %357 = add nsw i32 %324, %188
  %358 = ashr i32 %357, 5
  %359 = icmp ult i32 %358, 16384
  br i1 %359, label %364, label %360

360:                                              ; preds = %353
  %361 = ashr i32 %357, 31
  %362 = or i32 %361, -16384
  %363 = xor i32 %362, -1
  br label %364

364:                                              ; preds = %360, %353
  %365 = phi i32 [ %363, %360 ], [ %358, %353 ]
  %366 = trunc i32 %365 to i16
  %367 = getelementptr inbounds i16, i16* %191, i64 15
  store i16 %366, i16* %367, align 2
  %368 = add nsw i32 %192, %174
  %369 = getelementptr inbounds i16, i16* %191, i64 %8
  %370 = add nsw i32 %193, -1
  %371 = icmp eq i32 %370, 0
  br i1 %371, label %372, label %190

372:                                              ; preds = %364
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_left_dc_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = getelementptr inbounds i8, i8* %0, i64 -2
  %6 = bitcast i8* %5 to i16*
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = add nsw i64 %4, -1
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = and i64 %1, -2
  %15 = add nsw i64 %14, -1
  %16 = getelementptr inbounds i16, i16* %3, i64 %15
  %17 = load i16, i16* %16, align 2
  %18 = zext i16 %17 to i64
  %19 = add nuw nsw i64 %13, %18
  %20 = mul nsw i64 %4, 3
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i16, i16* %3, i64 %21
  %23 = load i16, i16* %22, align 2
  %24 = zext i16 %23 to i64
  %25 = add nuw nsw i64 %19, %24
  %26 = shl nsw i64 %4, 2
  %27 = add nsw i64 %26, -1
  %28 = getelementptr inbounds i16, i16* %3, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = zext i16 %29 to i64
  %31 = add nuw nsw i64 %25, %30
  %32 = mul nsw i64 %4, 5
  %33 = add nsw i64 %32, -1
  %34 = getelementptr inbounds i16, i16* %3, i64 %33
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i64
  %37 = add nuw nsw i64 %31, %36
  %38 = mul nsw i64 %4, 6
  %39 = add nsw i64 %38, -1
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %37, %42
  %44 = mul nsw i64 %4, 7
  %45 = add nsw i64 %44, -1
  %46 = getelementptr inbounds i16, i16* %3, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = zext i16 %47 to i64
  %49 = add nuw nsw i64 %43, %48
  %50 = shl nsw i64 %4, 3
  %51 = add nsw i64 %50, -1
  %52 = getelementptr inbounds i16, i16* %3, i64 %51
  %53 = load i16, i16* %52, align 2
  %54 = zext i16 %53 to i64
  %55 = add nuw nsw i64 %49, %54
  %56 = mul nsw i64 %4, 9
  %57 = add nsw i64 %56, -1
  %58 = getelementptr inbounds i16, i16* %3, i64 %57
  %59 = load i16, i16* %58, align 2
  %60 = zext i16 %59 to i64
  %61 = add nuw nsw i64 %55, %60
  %62 = mul nsw i64 %4, 10
  %63 = add nsw i64 %62, -1
  %64 = getelementptr inbounds i16, i16* %3, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i64
  %67 = add nuw nsw i64 %61, %66
  %68 = mul nsw i64 %4, 11
  %69 = add nsw i64 %68, -1
  %70 = getelementptr inbounds i16, i16* %3, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i64
  %73 = add nuw nsw i64 %67, %72
  %74 = mul nsw i64 %4, 12
  %75 = add nsw i64 %74, -1
  %76 = getelementptr inbounds i16, i16* %3, i64 %75
  %77 = load i16, i16* %76, align 2
  %78 = zext i16 %77 to i64
  %79 = add nuw nsw i64 %73, %78
  %80 = mul nsw i64 %4, 13
  %81 = add nsw i64 %80, -1
  %82 = getelementptr inbounds i16, i16* %3, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = zext i16 %83 to i64
  %85 = add nuw nsw i64 %79, %84
  %86 = mul nsw i64 %4, 14
  %87 = add nsw i64 %86, -1
  %88 = getelementptr inbounds i16, i16* %3, i64 %87
  %89 = load i16, i16* %88, align 2
  %90 = zext i16 %89 to i64
  %91 = add nuw nsw i64 %85, %90
  %92 = mul nsw i64 %4, 15
  %93 = add nsw i64 %92, -1
  %94 = getelementptr inbounds i16, i16* %3, i64 %93
  %95 = load i16, i16* %94, align 2
  %96 = zext i16 %95 to i64
  %97 = add nuw nsw i64 %91, %96
  %98 = add nuw nsw i64 %97, 8
  %99 = lshr i64 %98, 4
  %100 = and i64 %99, 268435455
  %101 = mul i64 %100, 281479271743489
  %102 = bitcast i8* %0 to i64*
  store i64 %101, i64* %102, align 8
  %103 = getelementptr inbounds i8, i8* %0, i64 8
  %104 = bitcast i8* %103 to i64*
  store i64 %101, i64* %104, align 8
  %105 = getelementptr inbounds i8, i8* %0, i64 16
  %106 = bitcast i8* %105 to i64*
  store i64 %101, i64* %106, align 8
  %107 = getelementptr inbounds i8, i8* %0, i64 24
  %108 = bitcast i8* %107 to i64*
  store i64 %101, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %3, i64 %4
  %110 = bitcast i16* %109 to i64*
  store i64 %101, i64* %110, align 8
  %111 = getelementptr inbounds i16, i16* %109, i64 4
  %112 = bitcast i16* %111 to i64*
  store i64 %101, i64* %112, align 8
  %113 = getelementptr inbounds i16, i16* %109, i64 8
  %114 = bitcast i16* %113 to i64*
  store i64 %101, i64* %114, align 8
  %115 = getelementptr inbounds i16, i16* %109, i64 12
  %116 = bitcast i16* %115 to i64*
  store i64 %101, i64* %116, align 8
  %117 = getelementptr inbounds i16, i16* %109, i64 %4
  %118 = bitcast i16* %117 to i64*
  store i64 %101, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %117, i64 4
  %120 = bitcast i16* %119 to i64*
  store i64 %101, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %117, i64 8
  %122 = bitcast i16* %121 to i64*
  store i64 %101, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %117, i64 12
  %124 = bitcast i16* %123 to i64*
  store i64 %101, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %117, i64 %4
  %126 = bitcast i16* %125 to i64*
  store i64 %101, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %125, i64 4
  %128 = bitcast i16* %127 to i64*
  store i64 %101, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %125, i64 8
  %130 = bitcast i16* %129 to i64*
  store i64 %101, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %125, i64 12
  %132 = bitcast i16* %131 to i64*
  store i64 %101, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %125, i64 %4
  %134 = bitcast i16* %133 to i64*
  store i64 %101, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %133, i64 4
  %136 = bitcast i16* %135 to i64*
  store i64 %101, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %133, i64 8
  %138 = bitcast i16* %137 to i64*
  store i64 %101, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %133, i64 12
  %140 = bitcast i16* %139 to i64*
  store i64 %101, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %133, i64 %4
  %142 = bitcast i16* %141 to i64*
  store i64 %101, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %141, i64 4
  %144 = bitcast i16* %143 to i64*
  store i64 %101, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %141, i64 8
  %146 = bitcast i16* %145 to i64*
  store i64 %101, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %141, i64 12
  %148 = bitcast i16* %147 to i64*
  store i64 %101, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %141, i64 %4
  %150 = bitcast i16* %149 to i64*
  store i64 %101, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %149, i64 4
  %152 = bitcast i16* %151 to i64*
  store i64 %101, i64* %152, align 8
  %153 = getelementptr inbounds i16, i16* %149, i64 8
  %154 = bitcast i16* %153 to i64*
  store i64 %101, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %149, i64 12
  %156 = bitcast i16* %155 to i64*
  store i64 %101, i64* %156, align 8
  %157 = getelementptr inbounds i16, i16* %149, i64 %4
  %158 = bitcast i16* %157 to i64*
  store i64 %101, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %157, i64 4
  %160 = bitcast i16* %159 to i64*
  store i64 %101, i64* %160, align 8
  %161 = getelementptr inbounds i16, i16* %157, i64 8
  %162 = bitcast i16* %161 to i64*
  store i64 %101, i64* %162, align 8
  %163 = getelementptr inbounds i16, i16* %157, i64 12
  %164 = bitcast i16* %163 to i64*
  store i64 %101, i64* %164, align 8
  %165 = getelementptr inbounds i16, i16* %157, i64 %4
  %166 = bitcast i16* %165 to i64*
  store i64 %101, i64* %166, align 8
  %167 = getelementptr inbounds i16, i16* %165, i64 4
  %168 = bitcast i16* %167 to i64*
  store i64 %101, i64* %168, align 8
  %169 = getelementptr inbounds i16, i16* %165, i64 8
  %170 = bitcast i16* %169 to i64*
  store i64 %101, i64* %170, align 8
  %171 = getelementptr inbounds i16, i16* %165, i64 12
  %172 = bitcast i16* %171 to i64*
  store i64 %101, i64* %172, align 8
  %173 = getelementptr inbounds i16, i16* %165, i64 %4
  %174 = bitcast i16* %173 to i64*
  store i64 %101, i64* %174, align 8
  %175 = getelementptr inbounds i16, i16* %173, i64 4
  %176 = bitcast i16* %175 to i64*
  store i64 %101, i64* %176, align 8
  %177 = getelementptr inbounds i16, i16* %173, i64 8
  %178 = bitcast i16* %177 to i64*
  store i64 %101, i64* %178, align 8
  %179 = getelementptr inbounds i16, i16* %173, i64 12
  %180 = bitcast i16* %179 to i64*
  store i64 %101, i64* %180, align 8
  %181 = getelementptr inbounds i16, i16* %173, i64 %4
  %182 = bitcast i16* %181 to i64*
  store i64 %101, i64* %182, align 8
  %183 = getelementptr inbounds i16, i16* %181, i64 4
  %184 = bitcast i16* %183 to i64*
  store i64 %101, i64* %184, align 8
  %185 = getelementptr inbounds i16, i16* %181, i64 8
  %186 = bitcast i16* %185 to i64*
  store i64 %101, i64* %186, align 8
  %187 = getelementptr inbounds i16, i16* %181, i64 12
  %188 = bitcast i16* %187 to i64*
  store i64 %101, i64* %188, align 8
  %189 = getelementptr inbounds i16, i16* %181, i64 %4
  %190 = bitcast i16* %189 to i64*
  store i64 %101, i64* %190, align 8
  %191 = getelementptr inbounds i16, i16* %189, i64 4
  %192 = bitcast i16* %191 to i64*
  store i64 %101, i64* %192, align 8
  %193 = getelementptr inbounds i16, i16* %189, i64 8
  %194 = bitcast i16* %193 to i64*
  store i64 %101, i64* %194, align 8
  %195 = getelementptr inbounds i16, i16* %189, i64 12
  %196 = bitcast i16* %195 to i64*
  store i64 %101, i64* %196, align 8
  %197 = getelementptr inbounds i16, i16* %189, i64 %4
  %198 = bitcast i16* %197 to i64*
  store i64 %101, i64* %198, align 8
  %199 = getelementptr inbounds i16, i16* %197, i64 4
  %200 = bitcast i16* %199 to i64*
  store i64 %101, i64* %200, align 8
  %201 = getelementptr inbounds i16, i16* %197, i64 8
  %202 = bitcast i16* %201 to i64*
  store i64 %101, i64* %202, align 8
  %203 = getelementptr inbounds i16, i16* %197, i64 12
  %204 = bitcast i16* %203 to i64*
  store i64 %101, i64* %204, align 8
  %205 = getelementptr inbounds i16, i16* %197, i64 %4
  %206 = bitcast i16* %205 to i64*
  store i64 %101, i64* %206, align 8
  %207 = getelementptr inbounds i16, i16* %205, i64 4
  %208 = bitcast i16* %207 to i64*
  store i64 %101, i64* %208, align 8
  %209 = getelementptr inbounds i16, i16* %205, i64 8
  %210 = bitcast i16* %209 to i64*
  store i64 %101, i64* %210, align 8
  %211 = getelementptr inbounds i16, i16* %205, i64 12
  %212 = bitcast i16* %211 to i64*
  store i64 %101, i64* %212, align 8
  %213 = getelementptr inbounds i16, i16* %205, i64 %4
  %214 = bitcast i16* %213 to i64*
  store i64 %101, i64* %214, align 8
  %215 = getelementptr inbounds i16, i16* %213, i64 4
  %216 = bitcast i16* %215 to i64*
  store i64 %101, i64* %216, align 8
  %217 = getelementptr inbounds i16, i16* %213, i64 8
  %218 = bitcast i16* %217 to i64*
  store i64 %101, i64* %218, align 8
  %219 = getelementptr inbounds i16, i16* %213, i64 12
  %220 = bitcast i16* %219 to i64*
  store i64 %101, i64* %220, align 8
  %221 = getelementptr inbounds i16, i16* %213, i64 %4
  %222 = bitcast i16* %221 to i64*
  store i64 %101, i64* %222, align 8
  %223 = getelementptr inbounds i16, i16* %221, i64 4
  %224 = bitcast i16* %223 to i64*
  store i64 %101, i64* %224, align 8
  %225 = getelementptr inbounds i16, i16* %221, i64 8
  %226 = bitcast i16* %225 to i64*
  store i64 %101, i64* %226, align 8
  %227 = getelementptr inbounds i16, i16* %221, i64 12
  %228 = bitcast i16* %227 to i64*
  store i64 %101, i64* %228, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_top_dc_14_c(i8* nocapture, i64) #1 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i16, i16* %3, i64 %5
  %7 = load i16, i16* %6, align 2
  %8 = zext i16 %7 to i64
  %9 = sub nsw i64 1, %4
  %10 = getelementptr inbounds i16, i16* %3, i64 %9
  %11 = load i16, i16* %10, align 2
  %12 = zext i16 %11 to i64
  %13 = add nuw nsw i64 %8, %12
  %14 = sub nsw i64 2, %4
  %15 = getelementptr inbounds i16, i16* %3, i64 %14
  %16 = load i16, i16* %15, align 2
  %17 = zext i16 %16 to i64
  %18 = add nuw nsw i64 %13, %17
  %19 = sub nsw i64 3, %4
  %20 = getelementptr inbounds i16, i16* %3, i64 %19
  %21 = load i16, i16* %20, align 2
  %22 = zext i16 %21 to i64
  %23 = add nuw nsw i64 %18, %22
  %24 = sub nsw i64 4, %4
  %25 = getelementptr inbounds i16, i16* %3, i64 %24
  %26 = load i16, i16* %25, align 2
  %27 = zext i16 %26 to i64
  %28 = add nuw nsw i64 %23, %27
  %29 = sub nsw i64 5, %4
  %30 = getelementptr inbounds i16, i16* %3, i64 %29
  %31 = load i16, i16* %30, align 2
  %32 = zext i16 %31 to i64
  %33 = add nuw nsw i64 %28, %32
  %34 = sub nsw i64 6, %4
  %35 = getelementptr inbounds i16, i16* %3, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i64
  %38 = add nuw nsw i64 %33, %37
  %39 = sub nsw i64 7, %4
  %40 = getelementptr inbounds i16, i16* %3, i64 %39
  %41 = load i16, i16* %40, align 2
  %42 = zext i16 %41 to i64
  %43 = add nuw nsw i64 %38, %42
  %44 = sub nsw i64 8, %4
  %45 = getelementptr inbounds i16, i16* %3, i64 %44
  %46 = load i16, i16* %45, align 2
  %47 = zext i16 %46 to i64
  %48 = add nuw nsw i64 %43, %47
  %49 = sub nsw i64 9, %4
  %50 = getelementptr inbounds i16, i16* %3, i64 %49
  %51 = load i16, i16* %50, align 2
  %52 = zext i16 %51 to i64
  %53 = add nuw nsw i64 %48, %52
  %54 = sub nsw i64 10, %4
  %55 = getelementptr inbounds i16, i16* %3, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = zext i16 %56 to i64
  %58 = add nuw nsw i64 %53, %57
  %59 = sub nsw i64 11, %4
  %60 = getelementptr inbounds i16, i16* %3, i64 %59
  %61 = load i16, i16* %60, align 2
  %62 = zext i16 %61 to i64
  %63 = add nuw nsw i64 %58, %62
  %64 = sub nsw i64 12, %4
  %65 = getelementptr inbounds i16, i16* %3, i64 %64
  %66 = load i16, i16* %65, align 2
  %67 = zext i16 %66 to i64
  %68 = add nuw nsw i64 %63, %67
  %69 = sub nsw i64 13, %4
  %70 = getelementptr inbounds i16, i16* %3, i64 %69
  %71 = load i16, i16* %70, align 2
  %72 = zext i16 %71 to i64
  %73 = add nuw nsw i64 %68, %72
  %74 = sub nsw i64 14, %4
  %75 = getelementptr inbounds i16, i16* %3, i64 %74
  %76 = load i16, i16* %75, align 2
  %77 = zext i16 %76 to i64
  %78 = add nuw nsw i64 %73, %77
  %79 = sub nsw i64 15, %4
  %80 = getelementptr inbounds i16, i16* %3, i64 %79
  %81 = load i16, i16* %80, align 2
  %82 = zext i16 %81 to i64
  %83 = add nuw nsw i64 %78, %82
  %84 = add nuw nsw i64 %83, 8
  %85 = lshr i64 %84, 4
  %86 = and i64 %85, 268435455
  %87 = mul i64 %86, 281479271743489
  %88 = bitcast i8* %0 to i64*
  store i64 %87, i64* %88, align 8
  %89 = getelementptr inbounds i8, i8* %0, i64 8
  %90 = bitcast i8* %89 to i64*
  store i64 %87, i64* %90, align 8
  %91 = getelementptr inbounds i8, i8* %0, i64 16
  %92 = bitcast i8* %91 to i64*
  store i64 %87, i64* %92, align 8
  %93 = getelementptr inbounds i8, i8* %0, i64 24
  %94 = bitcast i8* %93 to i64*
  store i64 %87, i64* %94, align 8
  %95 = getelementptr inbounds i16, i16* %3, i64 %4
  %96 = bitcast i16* %95 to i64*
  store i64 %87, i64* %96, align 8
  %97 = getelementptr inbounds i16, i16* %95, i64 4
  %98 = bitcast i16* %97 to i64*
  store i64 %87, i64* %98, align 8
  %99 = getelementptr inbounds i16, i16* %95, i64 8
  %100 = bitcast i16* %99 to i64*
  store i64 %87, i64* %100, align 8
  %101 = getelementptr inbounds i16, i16* %95, i64 12
  %102 = bitcast i16* %101 to i64*
  store i64 %87, i64* %102, align 8
  %103 = getelementptr inbounds i16, i16* %95, i64 %4
  %104 = bitcast i16* %103 to i64*
  store i64 %87, i64* %104, align 8
  %105 = getelementptr inbounds i16, i16* %103, i64 4
  %106 = bitcast i16* %105 to i64*
  store i64 %87, i64* %106, align 8
  %107 = getelementptr inbounds i16, i16* %103, i64 8
  %108 = bitcast i16* %107 to i64*
  store i64 %87, i64* %108, align 8
  %109 = getelementptr inbounds i16, i16* %103, i64 12
  %110 = bitcast i16* %109 to i64*
  store i64 %87, i64* %110, align 8
  %111 = getelementptr inbounds i16, i16* %103, i64 %4
  %112 = bitcast i16* %111 to i64*
  store i64 %87, i64* %112, align 8
  %113 = getelementptr inbounds i16, i16* %111, i64 4
  %114 = bitcast i16* %113 to i64*
  store i64 %87, i64* %114, align 8
  %115 = getelementptr inbounds i16, i16* %111, i64 8
  %116 = bitcast i16* %115 to i64*
  store i64 %87, i64* %116, align 8
  %117 = getelementptr inbounds i16, i16* %111, i64 12
  %118 = bitcast i16* %117 to i64*
  store i64 %87, i64* %118, align 8
  %119 = getelementptr inbounds i16, i16* %111, i64 %4
  %120 = bitcast i16* %119 to i64*
  store i64 %87, i64* %120, align 8
  %121 = getelementptr inbounds i16, i16* %119, i64 4
  %122 = bitcast i16* %121 to i64*
  store i64 %87, i64* %122, align 8
  %123 = getelementptr inbounds i16, i16* %119, i64 8
  %124 = bitcast i16* %123 to i64*
  store i64 %87, i64* %124, align 8
  %125 = getelementptr inbounds i16, i16* %119, i64 12
  %126 = bitcast i16* %125 to i64*
  store i64 %87, i64* %126, align 8
  %127 = getelementptr inbounds i16, i16* %119, i64 %4
  %128 = bitcast i16* %127 to i64*
  store i64 %87, i64* %128, align 8
  %129 = getelementptr inbounds i16, i16* %127, i64 4
  %130 = bitcast i16* %129 to i64*
  store i64 %87, i64* %130, align 8
  %131 = getelementptr inbounds i16, i16* %127, i64 8
  %132 = bitcast i16* %131 to i64*
  store i64 %87, i64* %132, align 8
  %133 = getelementptr inbounds i16, i16* %127, i64 12
  %134 = bitcast i16* %133 to i64*
  store i64 %87, i64* %134, align 8
  %135 = getelementptr inbounds i16, i16* %127, i64 %4
  %136 = bitcast i16* %135 to i64*
  store i64 %87, i64* %136, align 8
  %137 = getelementptr inbounds i16, i16* %135, i64 4
  %138 = bitcast i16* %137 to i64*
  store i64 %87, i64* %138, align 8
  %139 = getelementptr inbounds i16, i16* %135, i64 8
  %140 = bitcast i16* %139 to i64*
  store i64 %87, i64* %140, align 8
  %141 = getelementptr inbounds i16, i16* %135, i64 12
  %142 = bitcast i16* %141 to i64*
  store i64 %87, i64* %142, align 8
  %143 = getelementptr inbounds i16, i16* %135, i64 %4
  %144 = bitcast i16* %143 to i64*
  store i64 %87, i64* %144, align 8
  %145 = getelementptr inbounds i16, i16* %143, i64 4
  %146 = bitcast i16* %145 to i64*
  store i64 %87, i64* %146, align 8
  %147 = getelementptr inbounds i16, i16* %143, i64 8
  %148 = bitcast i16* %147 to i64*
  store i64 %87, i64* %148, align 8
  %149 = getelementptr inbounds i16, i16* %143, i64 12
  %150 = bitcast i16* %149 to i64*
  store i64 %87, i64* %150, align 8
  %151 = getelementptr inbounds i16, i16* %143, i64 %4
  %152 = bitcast i16* %151 to i64*
  store i64 %87, i64* %152, align 8
  %153 = getelementptr inbounds i16, i16* %151, i64 4
  %154 = bitcast i16* %153 to i64*
  store i64 %87, i64* %154, align 8
  %155 = getelementptr inbounds i16, i16* %151, i64 8
  %156 = bitcast i16* %155 to i64*
  store i64 %87, i64* %156, align 8
  %157 = getelementptr inbounds i16, i16* %151, i64 12
  %158 = bitcast i16* %157 to i64*
  store i64 %87, i64* %158, align 8
  %159 = getelementptr inbounds i16, i16* %151, i64 %4
  %160 = bitcast i16* %159 to i64*
  store i64 %87, i64* %160, align 8
  %161 = getelementptr inbounds i16, i16* %159, i64 4
  %162 = bitcast i16* %161 to i64*
  store i64 %87, i64* %162, align 8
  %163 = getelementptr inbounds i16, i16* %159, i64 8
  %164 = bitcast i16* %163 to i64*
  store i64 %87, i64* %164, align 8
  %165 = getelementptr inbounds i16, i16* %159, i64 12
  %166 = bitcast i16* %165 to i64*
  store i64 %87, i64* %166, align 8
  %167 = getelementptr inbounds i16, i16* %159, i64 %4
  %168 = bitcast i16* %167 to i64*
  store i64 %87, i64* %168, align 8
  %169 = getelementptr inbounds i16, i16* %167, i64 4
  %170 = bitcast i16* %169 to i64*
  store i64 %87, i64* %170, align 8
  %171 = getelementptr inbounds i16, i16* %167, i64 8
  %172 = bitcast i16* %171 to i64*
  store i64 %87, i64* %172, align 8
  %173 = getelementptr inbounds i16, i16* %167, i64 12
  %174 = bitcast i16* %173 to i64*
  store i64 %87, i64* %174, align 8
  %175 = getelementptr inbounds i16, i16* %167, i64 %4
  %176 = bitcast i16* %175 to i64*
  store i64 %87, i64* %176, align 8
  %177 = getelementptr inbounds i16, i16* %175, i64 4
  %178 = bitcast i16* %177 to i64*
  store i64 %87, i64* %178, align 8
  %179 = getelementptr inbounds i16, i16* %175, i64 8
  %180 = bitcast i16* %179 to i64*
  store i64 %87, i64* %180, align 8
  %181 = getelementptr inbounds i16, i16* %175, i64 12
  %182 = bitcast i16* %181 to i64*
  store i64 %87, i64* %182, align 8
  %183 = getelementptr inbounds i16, i16* %175, i64 %4
  %184 = bitcast i16* %183 to i64*
  store i64 %87, i64* %184, align 8
  %185 = getelementptr inbounds i16, i16* %183, i64 4
  %186 = bitcast i16* %185 to i64*
  store i64 %87, i64* %186, align 8
  %187 = getelementptr inbounds i16, i16* %183, i64 8
  %188 = bitcast i16* %187 to i64*
  store i64 %87, i64* %188, align 8
  %189 = getelementptr inbounds i16, i16* %183, i64 12
  %190 = bitcast i16* %189 to i64*
  store i64 %87, i64* %190, align 8
  %191 = getelementptr inbounds i16, i16* %183, i64 %4
  %192 = bitcast i16* %191 to i64*
  store i64 %87, i64* %192, align 8
  %193 = getelementptr inbounds i16, i16* %191, i64 4
  %194 = bitcast i16* %193 to i64*
  store i64 %87, i64* %194, align 8
  %195 = getelementptr inbounds i16, i16* %191, i64 8
  %196 = bitcast i16* %195 to i64*
  store i64 %87, i64* %196, align 8
  %197 = getelementptr inbounds i16, i16* %191, i64 12
  %198 = bitcast i16* %197 to i64*
  store i64 %87, i64* %198, align 8
  %199 = getelementptr inbounds i16, i16* %191, i64 %4
  %200 = bitcast i16* %199 to i64*
  store i64 %87, i64* %200, align 8
  %201 = getelementptr inbounds i16, i16* %199, i64 4
  %202 = bitcast i16* %201 to i64*
  store i64 %87, i64* %202, align 8
  %203 = getelementptr inbounds i16, i16* %199, i64 8
  %204 = bitcast i16* %203 to i64*
  store i64 %87, i64* %204, align 8
  %205 = getelementptr inbounds i16, i16* %199, i64 12
  %206 = bitcast i16* %205 to i64*
  store i64 %87, i64* %206, align 8
  %207 = getelementptr inbounds i16, i16* %199, i64 %4
  %208 = bitcast i16* %207 to i64*
  store i64 %87, i64* %208, align 8
  %209 = getelementptr inbounds i16, i16* %207, i64 4
  %210 = bitcast i16* %209 to i64*
  store i64 %87, i64* %210, align 8
  %211 = getelementptr inbounds i16, i16* %207, i64 8
  %212 = bitcast i16* %211 to i64*
  store i64 %87, i64* %212, align 8
  %213 = getelementptr inbounds i16, i16* %207, i64 12
  %214 = bitcast i16* %213 to i64*
  store i64 %87, i64* %214, align 8
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_128_dc_14_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i16*
  %4 = ashr i64 %1, 1
  %5 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %5, align 8
  %6 = getelementptr inbounds i8, i8* %0, i64 16
  %7 = bitcast i8* %6 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %7, align 8
  %8 = getelementptr inbounds i16, i16* %3, i64 %4
  %9 = bitcast i16* %8 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %9, align 8
  %10 = getelementptr inbounds i16, i16* %8, i64 8
  %11 = bitcast i16* %10 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %11, align 8
  %12 = getelementptr inbounds i16, i16* %8, i64 %4
  %13 = bitcast i16* %12 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %13, align 8
  %14 = getelementptr inbounds i16, i16* %12, i64 8
  %15 = bitcast i16* %14 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %15, align 8
  %16 = getelementptr inbounds i16, i16* %12, i64 %4
  %17 = bitcast i16* %16 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %17, align 8
  %18 = getelementptr inbounds i16, i16* %16, i64 8
  %19 = bitcast i16* %18 to <2 x i64>*
  store <2 x i64> <i64 2305878194122661888, i64 2305878194122661888>, <2 x i64>* %19, align 8
  %20 = getelementptr inbounds i16, i16* %16, i64 %4
  %21 = bitcast i16* %20 to i64*
  store i64 2305878194122661888, i64* %21, align 8
  %22 = getelementptr inbounds i16, i16* %20, i64 4
  %23 = bitcast i16* %22 to i64*
  store i64 2305878194122661888, i64* %23, align 8
  %24 = getelementptr inbounds i16, i16* %20, i64 8
  %25 = bitcast i16* %24 to i64*
  store i64 2305878194122661888, i64* %25, align 8
  %26 = getelementptr inbounds i16, i16* %20, i64 12
  %27 = bitcast i16* %26 to i64*
  store i64 2305878194122661888, i64* %27, align 8
  %28 = getelementptr inbounds i16, i16* %20, i64 %4
  %29 = bitcast i16* %28 to i64*
  store i64 2305878194122661888, i64* %29, align 8
  %30 = getelementptr inbounds i16, i16* %28, i64 4
  %31 = bitcast i16* %30 to i64*
  store i64 2305878194122661888, i64* %31, align 8
  %32 = getelementptr inbounds i16, i16* %28, i64 8
  %33 = bitcast i16* %32 to i64*
  store i64 2305878194122661888, i64* %33, align 8
  %34 = getelementptr inbounds i16, i16* %28, i64 12
  %35 = bitcast i16* %34 to i64*
  store i64 2305878194122661888, i64* %35, align 8
  %36 = getelementptr inbounds i16, i16* %28, i64 %4
  %37 = bitcast i16* %36 to i64*
  store i64 2305878194122661888, i64* %37, align 8
  %38 = getelementptr inbounds i16, i16* %36, i64 4
  %39 = bitcast i16* %38 to i64*
  store i64 2305878194122661888, i64* %39, align 8
  %40 = getelementptr inbounds i16, i16* %36, i64 8
  %41 = bitcast i16* %40 to i64*
  store i64 2305878194122661888, i64* %41, align 8
  %42 = getelementptr inbounds i16, i16* %36, i64 12
  %43 = bitcast i16* %42 to i64*
  store i64 2305878194122661888, i64* %43, align 8
  %44 = getelementptr inbounds i16, i16* %36, i64 %4
  %45 = bitcast i16* %44 to i64*
  store i64 2305878194122661888, i64* %45, align 8
  %46 = getelementptr inbounds i16, i16* %44, i64 4
  %47 = bitcast i16* %46 to i64*
  store i64 2305878194122661888, i64* %47, align 8
  %48 = getelementptr inbounds i16, i16* %44, i64 8
  %49 = bitcast i16* %48 to i64*
  store i64 2305878194122661888, i64* %49, align 8
  %50 = getelementptr inbounds i16, i16* %44, i64 12
  %51 = bitcast i16* %50 to i64*
  store i64 2305878194122661888, i64* %51, align 8
  %52 = getelementptr inbounds i16, i16* %44, i64 %4
  %53 = bitcast i16* %52 to i64*
  store i64 2305878194122661888, i64* %53, align 8
  %54 = getelementptr inbounds i16, i16* %52, i64 4
  %55 = bitcast i16* %54 to i64*
  store i64 2305878194122661888, i64* %55, align 8
  %56 = getelementptr inbounds i16, i16* %52, i64 8
  %57 = bitcast i16* %56 to i64*
  store i64 2305878194122661888, i64* %57, align 8
  %58 = getelementptr inbounds i16, i16* %52, i64 12
  %59 = bitcast i16* %58 to i64*
  store i64 2305878194122661888, i64* %59, align 8
  %60 = getelementptr inbounds i16, i16* %52, i64 %4
  %61 = bitcast i16* %60 to i64*
  store i64 2305878194122661888, i64* %61, align 8
  %62 = getelementptr inbounds i16, i16* %60, i64 4
  %63 = bitcast i16* %62 to i64*
  store i64 2305878194122661888, i64* %63, align 8
  %64 = getelementptr inbounds i16, i16* %60, i64 8
  %65 = bitcast i16* %64 to i64*
  store i64 2305878194122661888, i64* %65, align 8
  %66 = getelementptr inbounds i16, i16* %60, i64 12
  %67 = bitcast i16* %66 to i64*
  store i64 2305878194122661888, i64* %67, align 8
  %68 = getelementptr inbounds i16, i16* %60, i64 %4
  %69 = bitcast i16* %68 to i64*
  store i64 2305878194122661888, i64* %69, align 8
  %70 = getelementptr inbounds i16, i16* %68, i64 4
  %71 = bitcast i16* %70 to i64*
  store i64 2305878194122661888, i64* %71, align 8
  %72 = getelementptr inbounds i16, i16* %68, i64 8
  %73 = bitcast i16* %72 to i64*
  store i64 2305878194122661888, i64* %73, align 8
  %74 = getelementptr inbounds i16, i16* %68, i64 12
  %75 = bitcast i16* %74 to i64*
  store i64 2305878194122661888, i64* %75, align 8
  %76 = getelementptr inbounds i16, i16* %68, i64 %4
  %77 = bitcast i16* %76 to i64*
  store i64 2305878194122661888, i64* %77, align 8
  %78 = getelementptr inbounds i16, i16* %76, i64 4
  %79 = bitcast i16* %78 to i64*
  store i64 2305878194122661888, i64* %79, align 8
  %80 = getelementptr inbounds i16, i16* %76, i64 8
  %81 = bitcast i16* %80 to i64*
  store i64 2305878194122661888, i64* %81, align 8
  %82 = getelementptr inbounds i16, i16* %76, i64 12
  %83 = bitcast i16* %82 to i64*
  store i64 2305878194122661888, i64* %83, align 8
  %84 = getelementptr inbounds i16, i16* %76, i64 %4
  %85 = bitcast i16* %84 to i64*
  store i64 2305878194122661888, i64* %85, align 8
  %86 = getelementptr inbounds i16, i16* %84, i64 4
  %87 = bitcast i16* %86 to i64*
  store i64 2305878194122661888, i64* %87, align 8
  %88 = getelementptr inbounds i16, i16* %84, i64 8
  %89 = bitcast i16* %88 to i64*
  store i64 2305878194122661888, i64* %89, align 8
  %90 = getelementptr inbounds i16, i16* %84, i64 12
  %91 = bitcast i16* %90 to i64*
  store i64 2305878194122661888, i64* %91, align 8
  %92 = getelementptr inbounds i16, i16* %84, i64 %4
  %93 = bitcast i16* %92 to i64*
  store i64 2305878194122661888, i64* %93, align 8
  %94 = getelementptr inbounds i16, i16* %92, i64 4
  %95 = bitcast i16* %94 to i64*
  store i64 2305878194122661888, i64* %95, align 8
  %96 = getelementptr inbounds i16, i16* %92, i64 8
  %97 = bitcast i16* %96 to i64*
  store i64 2305878194122661888, i64* %97, align 8
  %98 = getelementptr inbounds i16, i16* %92, i64 12
  %99 = bitcast i16* %98 to i64*
  store i64 2305878194122661888, i64* %99, align 8
  %100 = getelementptr inbounds i16, i16* %92, i64 %4
  %101 = bitcast i16* %100 to i64*
  store i64 2305878194122661888, i64* %101, align 8
  %102 = getelementptr inbounds i16, i16* %100, i64 4
  %103 = bitcast i16* %102 to i64*
  store i64 2305878194122661888, i64* %103, align 8
  %104 = getelementptr inbounds i16, i16* %100, i64 8
  %105 = bitcast i16* %104 to i64*
  store i64 2305878194122661888, i64* %105, align 8
  %106 = getelementptr inbounds i16, i16* %100, i64 12
  %107 = bitcast i16* %106 to i64*
  store i64 2305878194122661888, i64* %107, align 8
  %108 = getelementptr inbounds i16, i16* %100, i64 %4
  %109 = bitcast i16* %108 to i64*
  store i64 2305878194122661888, i64* %109, align 8
  %110 = getelementptr inbounds i16, i16* %108, i64 4
  %111 = bitcast i16* %110 to i64*
  store i64 2305878194122661888, i64* %111, align 8
  %112 = getelementptr inbounds i16, i16* %108, i64 8
  %113 = bitcast i16* %112 to i64*
  store i64 2305878194122661888, i64* %113, align 8
  %114 = getelementptr inbounds i16, i16* %108, i64 12
  %115 = bitcast i16* %114 to i64*
  store i64 2305878194122661888, i64* %115, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred4x4_vertical_add_14_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %4, i64 %7
  %9 = and i64 %2, -2
  %10 = mul nsw i64 %6, 3
  %11 = shl nsw i64 %6, 2
  %12 = load i16, i16* %8, align 2
  %13 = load i32, i32* %5, align 4
  %14 = trunc i32 %13 to i16
  %15 = add i16 %12, %14
  store i16 %15, i16* %4, align 2
  %16 = getelementptr inbounds i16, i16* %1, i64 8
  %17 = bitcast i16* %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = trunc i32 %18 to i16
  %20 = add i16 %15, %19
  %21 = getelementptr inbounds i16, i16* %8, i64 %9
  store i16 %20, i16* %21, align 2
  %22 = getelementptr inbounds i16, i16* %1, i64 16
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %20, %25
  %27 = getelementptr inbounds i16, i16* %8, i64 %10
  store i16 %26, i16* %27, align 2
  %28 = getelementptr inbounds i16, i16* %1, i64 24
  %29 = bitcast i16* %28 to i32*
  %30 = load i32, i32* %29, align 4
  %31 = trunc i32 %30 to i16
  %32 = add i16 %26, %31
  %33 = getelementptr inbounds i16, i16* %8, i64 %11
  store i16 %32, i16* %33, align 2
  %34 = getelementptr inbounds i16, i16* %8, i64 1
  %35 = getelementptr inbounds i16, i16* %1, i64 2
  %36 = bitcast i16* %35 to i32*
  %37 = load i16, i16* %34, align 2
  %38 = load i32, i32* %36, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %37, %39
  %41 = getelementptr inbounds i16, i16* %34, i64 %6
  store i16 %40, i16* %41, align 2
  %42 = getelementptr inbounds i16, i16* %1, i64 10
  %43 = bitcast i16* %42 to i32*
  %44 = load i32, i32* %43, align 4
  %45 = trunc i32 %44 to i16
  %46 = add i16 %40, %45
  %47 = getelementptr inbounds i16, i16* %34, i64 %9
  store i16 %46, i16* %47, align 2
  %48 = getelementptr inbounds i16, i16* %1, i64 18
  %49 = bitcast i16* %48 to i32*
  %50 = load i32, i32* %49, align 4
  %51 = trunc i32 %50 to i16
  %52 = add i16 %46, %51
  %53 = getelementptr inbounds i16, i16* %34, i64 %10
  store i16 %52, i16* %53, align 2
  %54 = getelementptr inbounds i16, i16* %1, i64 26
  %55 = bitcast i16* %54 to i32*
  %56 = load i32, i32* %55, align 4
  %57 = trunc i32 %56 to i16
  %58 = add i16 %52, %57
  %59 = getelementptr inbounds i16, i16* %34, i64 %11
  store i16 %58, i16* %59, align 2
  %60 = getelementptr inbounds i16, i16* %34, i64 1
  %61 = getelementptr inbounds i16, i16* %1, i64 4
  %62 = bitcast i16* %61 to i32*
  %63 = load i16, i16* %60, align 2
  %64 = load i32, i32* %62, align 4
  %65 = trunc i32 %64 to i16
  %66 = add i16 %63, %65
  %67 = getelementptr inbounds i16, i16* %60, i64 %6
  store i16 %66, i16* %67, align 2
  %68 = getelementptr inbounds i16, i16* %1, i64 12
  %69 = bitcast i16* %68 to i32*
  %70 = load i32, i32* %69, align 4
  %71 = trunc i32 %70 to i16
  %72 = add i16 %66, %71
  %73 = getelementptr inbounds i16, i16* %60, i64 %9
  store i16 %72, i16* %73, align 2
  %74 = getelementptr inbounds i16, i16* %1, i64 20
  %75 = bitcast i16* %74 to i32*
  %76 = load i32, i32* %75, align 4
  %77 = trunc i32 %76 to i16
  %78 = add i16 %72, %77
  %79 = getelementptr inbounds i16, i16* %60, i64 %10
  store i16 %78, i16* %79, align 2
  %80 = getelementptr inbounds i16, i16* %1, i64 28
  %81 = bitcast i16* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = trunc i32 %82 to i16
  %84 = add i16 %78, %83
  %85 = getelementptr inbounds i16, i16* %60, i64 %11
  store i16 %84, i16* %85, align 2
  %86 = getelementptr inbounds i16, i16* %60, i64 1
  %87 = getelementptr inbounds i16, i16* %1, i64 6
  %88 = bitcast i16* %87 to i32*
  %89 = load i16, i16* %86, align 2
  %90 = load i32, i32* %88, align 4
  %91 = trunc i32 %90 to i16
  %92 = add i16 %89, %91
  %93 = getelementptr inbounds i16, i16* %86, i64 %6
  store i16 %92, i16* %93, align 2
  %94 = getelementptr inbounds i16, i16* %1, i64 14
  %95 = bitcast i16* %94 to i32*
  %96 = load i32, i32* %95, align 4
  %97 = trunc i32 %96 to i16
  %98 = add i16 %92, %97
  %99 = getelementptr inbounds i16, i16* %86, i64 %9
  store i16 %98, i16* %99, align 2
  %100 = getelementptr inbounds i16, i16* %1, i64 22
  %101 = bitcast i16* %100 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = trunc i32 %102 to i16
  %104 = add i16 %98, %103
  %105 = getelementptr inbounds i16, i16* %86, i64 %10
  store i16 %104, i16* %105, align 2
  %106 = getelementptr inbounds i16, i16* %1, i64 30
  %107 = bitcast i16* %106 to i32*
  %108 = load i32, i32* %107, align 4
  %109 = trunc i32 %108 to i16
  %110 = add i16 %104, %109
  %111 = getelementptr inbounds i16, i16* %86, i64 %11
  store i16 %110, i16* %111, align 2
  %112 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %112, i8 0, i64 64, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred4x4_horizontal_add_14_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  %7 = getelementptr inbounds i8, i8* %0, i64 -2
  %8 = bitcast i8* %7 to i16*
  %9 = load i16, i16* %8, align 2
  %10 = load i32, i32* %5, align 4
  %11 = trunc i32 %10 to i16
  %12 = add i16 %9, %11
  store i16 %12, i16* %4, align 2
  %13 = getelementptr inbounds i16, i16* %1, i64 2
  %14 = bitcast i16* %13 to i32*
  %15 = load i32, i32* %14, align 4
  %16 = trunc i32 %15 to i16
  %17 = add i16 %12, %16
  %18 = getelementptr inbounds i8, i8* %0, i64 2
  %19 = bitcast i8* %18 to i16*
  store i16 %17, i16* %19, align 2
  %20 = getelementptr inbounds i16, i16* %1, i64 4
  %21 = bitcast i16* %20 to i32*
  %22 = load i32, i32* %21, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %17, %23
  %25 = getelementptr inbounds i8, i8* %0, i64 4
  %26 = bitcast i8* %25 to i16*
  store i16 %24, i16* %26, align 2
  %27 = getelementptr inbounds i16, i16* %1, i64 6
  %28 = bitcast i16* %27 to i32*
  %29 = load i32, i32* %28, align 4
  %30 = trunc i32 %29 to i16
  %31 = add i16 %24, %30
  %32 = getelementptr inbounds i8, i8* %0, i64 6
  %33 = bitcast i8* %32 to i16*
  store i16 %31, i16* %33, align 2
  %34 = getelementptr inbounds i16, i16* %4, i64 %6
  %35 = getelementptr inbounds i16, i16* %1, i64 8
  %36 = bitcast i16* %35 to i32*
  %37 = getelementptr inbounds i16, i16* %34, i64 -1
  %38 = load i16, i16* %37, align 2
  %39 = load i32, i32* %36, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %38, %40
  store i16 %41, i16* %34, align 2
  %42 = getelementptr inbounds i16, i16* %1, i64 10
  %43 = bitcast i16* %42 to i32*
  %44 = load i32, i32* %43, align 4
  %45 = trunc i32 %44 to i16
  %46 = add i16 %41, %45
  %47 = getelementptr inbounds i16, i16* %34, i64 1
  store i16 %46, i16* %47, align 2
  %48 = getelementptr inbounds i16, i16* %1, i64 12
  %49 = bitcast i16* %48 to i32*
  %50 = load i32, i32* %49, align 4
  %51 = trunc i32 %50 to i16
  %52 = add i16 %46, %51
  %53 = getelementptr inbounds i16, i16* %34, i64 2
  store i16 %52, i16* %53, align 2
  %54 = getelementptr inbounds i16, i16* %1, i64 14
  %55 = bitcast i16* %54 to i32*
  %56 = load i32, i32* %55, align 4
  %57 = trunc i32 %56 to i16
  %58 = add i16 %52, %57
  %59 = getelementptr inbounds i16, i16* %34, i64 3
  store i16 %58, i16* %59, align 2
  %60 = getelementptr inbounds i16, i16* %34, i64 %6
  %61 = getelementptr inbounds i16, i16* %1, i64 16
  %62 = bitcast i16* %61 to i32*
  %63 = getelementptr inbounds i16, i16* %60, i64 -1
  %64 = load i16, i16* %63, align 2
  %65 = load i32, i32* %62, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %64, %66
  store i16 %67, i16* %60, align 2
  %68 = getelementptr inbounds i16, i16* %1, i64 18
  %69 = bitcast i16* %68 to i32*
  %70 = load i32, i32* %69, align 4
  %71 = trunc i32 %70 to i16
  %72 = add i16 %67, %71
  %73 = getelementptr inbounds i16, i16* %60, i64 1
  store i16 %72, i16* %73, align 2
  %74 = getelementptr inbounds i16, i16* %1, i64 20
  %75 = bitcast i16* %74 to i32*
  %76 = load i32, i32* %75, align 4
  %77 = trunc i32 %76 to i16
  %78 = add i16 %72, %77
  %79 = getelementptr inbounds i16, i16* %60, i64 2
  store i16 %78, i16* %79, align 2
  %80 = getelementptr inbounds i16, i16* %1, i64 22
  %81 = bitcast i16* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = trunc i32 %82 to i16
  %84 = add i16 %78, %83
  %85 = getelementptr inbounds i16, i16* %60, i64 3
  store i16 %84, i16* %85, align 2
  %86 = getelementptr inbounds i16, i16* %60, i64 %6
  %87 = getelementptr inbounds i16, i16* %1, i64 24
  %88 = bitcast i16* %87 to i32*
  %89 = getelementptr inbounds i16, i16* %86, i64 -1
  %90 = load i16, i16* %89, align 2
  %91 = load i32, i32* %88, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %90, %92
  store i16 %93, i16* %86, align 2
  %94 = getelementptr inbounds i16, i16* %1, i64 26
  %95 = bitcast i16* %94 to i32*
  %96 = load i32, i32* %95, align 4
  %97 = trunc i32 %96 to i16
  %98 = add i16 %93, %97
  %99 = getelementptr inbounds i16, i16* %86, i64 1
  store i16 %98, i16* %99, align 2
  %100 = getelementptr inbounds i16, i16* %1, i64 28
  %101 = bitcast i16* %100 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = trunc i32 %102 to i16
  %104 = add i16 %98, %103
  %105 = getelementptr inbounds i16, i16* %86, i64 2
  store i16 %104, i16* %105, align 2
  %106 = getelementptr inbounds i16, i16* %1, i64 30
  %107 = bitcast i16* %106 to i32*
  %108 = load i32, i32* %107, align 4
  %109 = trunc i32 %108 to i16
  %110 = add i16 %104, %109
  %111 = getelementptr inbounds i16, i16* %86, i64 3
  store i16 %110, i16* %111, align 2
  %112 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %112, i8 0, i64 64, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_vertical_add_14_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i16, i16* %4, i64 %7
  %9 = and i64 %2, -2
  %10 = mul nsw i64 %6, 3
  %11 = shl nsw i64 %6, 2
  %12 = mul nsw i64 %6, 5
  %13 = mul nsw i64 %6, 6
  %14 = mul nsw i64 %6, 7
  %15 = shl nsw i64 %6, 3
  br label %16

16:                                               ; preds = %16, %3
  %17 = phi i32* [ %5, %3 ], [ %61, %16 ]
  %18 = phi i16* [ %8, %3 ], [ %60, %16 ]
  %19 = phi i32 [ 0, %3 ], [ %62, %16 ]
  %20 = load i16, i16* %18, align 2
  %21 = load i32, i32* %17, align 4
  %22 = trunc i32 %21 to i16
  %23 = add i16 %20, %22
  %24 = getelementptr inbounds i16, i16* %18, i64 %6
  store i16 %23, i16* %24, align 2
  %25 = getelementptr inbounds i32, i32* %17, i64 8
  %26 = load i32, i32* %25, align 4
  %27 = trunc i32 %26 to i16
  %28 = add i16 %23, %27
  %29 = getelementptr inbounds i16, i16* %18, i64 %9
  store i16 %28, i16* %29, align 2
  %30 = getelementptr inbounds i32, i32* %17, i64 16
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %28, %32
  %34 = getelementptr inbounds i16, i16* %18, i64 %10
  store i16 %33, i16* %34, align 2
  %35 = getelementptr inbounds i32, i32* %17, i64 24
  %36 = load i32, i32* %35, align 4
  %37 = trunc i32 %36 to i16
  %38 = add i16 %33, %37
  %39 = getelementptr inbounds i16, i16* %18, i64 %11
  store i16 %38, i16* %39, align 2
  %40 = getelementptr inbounds i32, i32* %17, i64 32
  %41 = load i32, i32* %40, align 4
  %42 = trunc i32 %41 to i16
  %43 = add i16 %38, %42
  %44 = getelementptr inbounds i16, i16* %18, i64 %12
  store i16 %43, i16* %44, align 2
  %45 = getelementptr inbounds i32, i32* %17, i64 40
  %46 = load i32, i32* %45, align 4
  %47 = trunc i32 %46 to i16
  %48 = add i16 %43, %47
  %49 = getelementptr inbounds i16, i16* %18, i64 %13
  store i16 %48, i16* %49, align 2
  %50 = getelementptr inbounds i32, i32* %17, i64 48
  %51 = load i32, i32* %50, align 4
  %52 = trunc i32 %51 to i16
  %53 = add i16 %48, %52
  %54 = getelementptr inbounds i16, i16* %18, i64 %14
  store i16 %53, i16* %54, align 2
  %55 = getelementptr inbounds i32, i32* %17, i64 56
  %56 = load i32, i32* %55, align 4
  %57 = trunc i32 %56 to i16
  %58 = add i16 %53, %57
  %59 = getelementptr inbounds i16, i16* %18, i64 %15
  store i16 %58, i16* %59, align 2
  %60 = getelementptr inbounds i16, i16* %18, i64 1
  %61 = getelementptr inbounds i32, i32* %17, i64 1
  %62 = add nuw nsw i32 %19, 1
  %63 = icmp eq i32 %62, 8
  br i1 %63, label %64, label %16

64:                                               ; preds = %16
  %65 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %65, i8 0, i64 256, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_horizontal_add_14_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = bitcast i8* %0 to i16*
  %5 = bitcast i16* %1 to i32*
  %6 = ashr i64 %2, 1
  br label %7

7:                                                ; preds = %7, %3
  %8 = phi i32* [ %5, %3 ], [ %52, %7 ]
  %9 = phi i16* [ %4, %3 ], [ %51, %7 ]
  %10 = phi i32 [ 0, %3 ], [ %53, %7 ]
  %11 = getelementptr inbounds i16, i16* %9, i64 -1
  %12 = load i16, i16* %11, align 2
  %13 = load i32, i32* %8, align 4
  %14 = trunc i32 %13 to i16
  %15 = add i16 %12, %14
  store i16 %15, i16* %9, align 2
  %16 = getelementptr inbounds i32, i32* %8, i64 1
  %17 = load i32, i32* %16, align 4
  %18 = trunc i32 %17 to i16
  %19 = add i16 %15, %18
  %20 = getelementptr inbounds i16, i16* %9, i64 1
  store i16 %19, i16* %20, align 2
  %21 = getelementptr inbounds i32, i32* %8, i64 2
  %22 = load i32, i32* %21, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %19, %23
  %25 = getelementptr inbounds i16, i16* %9, i64 2
  store i16 %24, i16* %25, align 2
  %26 = getelementptr inbounds i32, i32* %8, i64 3
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %9, i64 3
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i32, i32* %8, i64 4
  %32 = load i32, i32* %31, align 4
  %33 = trunc i32 %32 to i16
  %34 = add i16 %29, %33
  %35 = getelementptr inbounds i16, i16* %9, i64 4
  store i16 %34, i16* %35, align 2
  %36 = getelementptr inbounds i32, i32* %8, i64 5
  %37 = load i32, i32* %36, align 4
  %38 = trunc i32 %37 to i16
  %39 = add i16 %34, %38
  %40 = getelementptr inbounds i16, i16* %9, i64 5
  store i16 %39, i16* %40, align 2
  %41 = getelementptr inbounds i32, i32* %8, i64 6
  %42 = load i32, i32* %41, align 4
  %43 = trunc i32 %42 to i16
  %44 = add i16 %39, %43
  %45 = getelementptr inbounds i16, i16* %9, i64 6
  store i16 %44, i16* %45, align 2
  %46 = getelementptr inbounds i32, i32* %8, i64 7
  %47 = load i32, i32* %46, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %44, %48
  %50 = getelementptr inbounds i16, i16* %9, i64 7
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %9, i64 %6
  %52 = getelementptr inbounds i32, i32* %8, i64 8
  %53 = add nuw nsw i32 %10, 1
  %54 = icmp eq i32 %53, 8
  br i1 %54, label %55, label %7

55:                                               ; preds = %7
  %56 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %56, i8 0, i64 256, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_vertical_filter_add_14_c(i8* nocapture, i16* nocapture, i32, i32, i64) #3 {
  %6 = alloca [8 x i16], align 16
  %7 = bitcast i8* %0 to i16*
  %8 = bitcast i16* %1 to i32*
  %9 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %9) #8
  %10 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 0
  %11 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 1
  %12 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 2
  %13 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 3
  %14 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 4
  %15 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 5
  %16 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 6
  %17 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 7
  %18 = lshr i64 %4, 1
  %19 = trunc i64 %18 to i32
  %20 = icmp eq i32 %2, 0
  %21 = sub nsw i32 0, %19
  %22 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 16, i1 false)
  br i1 %20, label %28, label %23

23:                                               ; preds = %5
  %24 = shl i64 %18, 32
  %25 = ashr exact i64 %24, 32
  %26 = xor i64 %25, -1
  %27 = sext i32 %21 to i64
  br label %31

28:                                               ; preds = %5
  %29 = sext i32 %21 to i64
  %30 = shl i64 %18, 32
  br label %31

31:                                               ; preds = %28, %23
  %32 = phi i64 [ %30, %28 ], [ %24, %23 ]
  %33 = phi i64 [ %29, %28 ], [ %27, %23 ]
  %34 = phi i64 [ %29, %28 ], [ %26, %23 ]
  %35 = getelementptr inbounds i16, i16* %7, i64 %34
  %36 = load i16, i16* %35, align 2
  %37 = zext i16 %36 to i32
  %38 = getelementptr inbounds i16, i16* %7, i64 %33
  %39 = load i16, i16* %38, align 2
  %40 = zext i16 %39 to i32
  %41 = shl nuw nsw i32 %40, 1
  %42 = sub i64 4294967296, %32
  %43 = ashr exact i64 %42, 32
  %44 = getelementptr inbounds i16, i16* %7, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %37
  %49 = add nuw nsw i32 %48, %41
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = sub i64 8589934592, %32
  %53 = ashr exact i64 %52, 32
  %54 = getelementptr inbounds i16, i16* %7, i64 %53
  %55 = load i16, i16* %54, align 2
  %56 = zext i16 %55 to i32
  %57 = add nuw nsw i32 %56, 2
  %58 = add nuw nsw i32 %57, %40
  %59 = add nuw nsw i32 %58, %51
  %60 = lshr i32 %59, 2
  %61 = shl nuw nsw i32 %56, 1
  %62 = sub i64 12884901888, %32
  %63 = ashr exact i64 %62, 32
  %64 = getelementptr inbounds i16, i16* %7, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = zext i16 %65 to i32
  %67 = add nuw nsw i32 %47, %61
  %68 = add nuw nsw i32 %67, %66
  %69 = lshr i32 %68, 2
  %70 = shl nuw nsw i32 %66, 1
  %71 = sub i64 17179869184, %32
  %72 = ashr exact i64 %71, 32
  %73 = getelementptr inbounds i16, i16* %7, i64 %72
  %74 = load i16, i16* %73, align 2
  %75 = zext i16 %74 to i32
  %76 = add nuw nsw i32 %57, %70
  %77 = add nuw nsw i32 %76, %75
  %78 = lshr i32 %77, 2
  %79 = shl nuw nsw i32 %75, 1
  %80 = sub i64 21474836480, %32
  %81 = ashr exact i64 %80, 32
  %82 = getelementptr inbounds i16, i16* %7, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = zext i16 %83 to i32
  %85 = add nuw nsw i32 %66, 2
  %86 = add nuw nsw i32 %85, %79
  %87 = add nuw nsw i32 %86, %84
  %88 = lshr i32 %87, 2
  %89 = shl nuw nsw i32 %84, 1
  %90 = sub i64 25769803776, %32
  %91 = ashr exact i64 %90, 32
  %92 = getelementptr inbounds i16, i16* %7, i64 %91
  %93 = load i16, i16* %92, align 2
  %94 = zext i16 %93 to i32
  %95 = add nuw nsw i32 %75, 2
  %96 = add nuw nsw i32 %95, %89
  %97 = add nuw nsw i32 %96, %94
  %98 = lshr i32 %97, 2
  %99 = shl nuw nsw i32 %94, 1
  %100 = sub i64 30064771072, %32
  %101 = ashr exact i64 %100, 32
  %102 = getelementptr inbounds i16, i16* %7, i64 %101
  %103 = load i16, i16* %102, align 2
  %104 = zext i16 %103 to i32
  %105 = add nuw nsw i32 %84, 2
  %106 = add nuw nsw i32 %105, %99
  %107 = add nuw nsw i32 %106, %104
  %108 = lshr i32 %107, 2
  %109 = icmp eq i32 %3, 0
  br i1 %109, label %116, label %110

110:                                              ; preds = %31
  %111 = sub i64 34359738368, %32
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds i16, i16* %7, i64 %112
  %114 = load i16, i16* %113, align 2
  %115 = zext i16 %114 to i32
  br label %116

116:                                              ; preds = %31, %110
  %117 = phi i32 [ %115, %110 ], [ %104, %31 ]
  %118 = shl nuw nsw i32 %104, 1
  %119 = add nuw nsw i32 %94, 2
  %120 = add nuw nsw i32 %119, %118
  %121 = add nuw nsw i32 %120, %117
  %122 = lshr i32 %121, 2
  %123 = trunc i32 %50 to i16
  store i16 %123, i16* %10, align 16
  %124 = trunc i32 %60 to i16
  store i16 %124, i16* %11, align 2
  %125 = trunc i32 %69 to i16
  store i16 %125, i16* %12, align 4
  %126 = trunc i32 %78 to i16
  store i16 %126, i16* %13, align 2
  %127 = trunc i32 %88 to i16
  store i16 %127, i16* %14, align 8
  %128 = trunc i32 %98 to i16
  store i16 %128, i16* %15, align 2
  %129 = trunc i32 %108 to i16
  store i16 %129, i16* %16, align 4
  %130 = trunc i32 %122 to i16
  store i16 %130, i16* %17, align 2
  %131 = ashr exact i64 %32, 32
  %132 = shl i64 %4, 32
  %133 = ashr exact i64 %132, 32
  %134 = and i64 %133, -2
  %135 = mul i64 %18, 12884901888
  %136 = ashr exact i64 %135, 32
  %137 = shl i64 %18, 34
  %138 = ashr exact i64 %137, 32
  %139 = mul i64 %18, 21474836480
  %140 = ashr exact i64 %139, 32
  %141 = mul i64 %18, 25769803776
  %142 = ashr exact i64 %141, 32
  %143 = mul i64 %18, 30064771072
  %144 = ashr exact i64 %143, 32
  br label %145

145:                                              ; preds = %190, %116
  %146 = phi i16 [ %123, %116 ], [ %194, %190 ]
  %147 = phi i64 [ 0, %116 ], [ %188, %190 ]
  %148 = phi i32* [ %8, %116 ], [ %191, %190 ]
  %149 = phi i16* [ %7, %116 ], [ %192, %190 ]
  %150 = load i32, i32* %148, align 4
  %151 = trunc i32 %150 to i16
  %152 = add i16 %146, %151
  store i16 %152, i16* %149, align 2
  %153 = getelementptr inbounds i32, i32* %148, i64 8
  %154 = load i32, i32* %153, align 4
  %155 = trunc i32 %154 to i16
  %156 = add i16 %152, %155
  %157 = getelementptr inbounds i16, i16* %149, i64 %131
  store i16 %156, i16* %157, align 2
  %158 = getelementptr inbounds i32, i32* %148, i64 16
  %159 = load i32, i32* %158, align 4
  %160 = trunc i32 %159 to i16
  %161 = add i16 %156, %160
  %162 = getelementptr inbounds i16, i16* %149, i64 %134
  store i16 %161, i16* %162, align 2
  %163 = getelementptr inbounds i32, i32* %148, i64 24
  %164 = load i32, i32* %163, align 4
  %165 = trunc i32 %164 to i16
  %166 = add i16 %161, %165
  %167 = getelementptr inbounds i16, i16* %149, i64 %136
  store i16 %166, i16* %167, align 2
  %168 = getelementptr inbounds i32, i32* %148, i64 32
  %169 = load i32, i32* %168, align 4
  %170 = trunc i32 %169 to i16
  %171 = add i16 %166, %170
  %172 = getelementptr inbounds i16, i16* %149, i64 %138
  store i16 %171, i16* %172, align 2
  %173 = getelementptr inbounds i32, i32* %148, i64 40
  %174 = load i32, i32* %173, align 4
  %175 = trunc i32 %174 to i16
  %176 = add i16 %171, %175
  %177 = getelementptr inbounds i16, i16* %149, i64 %140
  store i16 %176, i16* %177, align 2
  %178 = getelementptr inbounds i32, i32* %148, i64 48
  %179 = load i32, i32* %178, align 4
  %180 = trunc i32 %179 to i16
  %181 = add i16 %176, %180
  %182 = getelementptr inbounds i16, i16* %149, i64 %142
  store i16 %181, i16* %182, align 2
  %183 = getelementptr inbounds i32, i32* %148, i64 56
  %184 = load i32, i32* %183, align 4
  %185 = trunc i32 %184 to i16
  %186 = add i16 %181, %185
  %187 = getelementptr inbounds i16, i16* %149, i64 %144
  store i16 %186, i16* %187, align 2
  %188 = add nuw nsw i64 %147, 1
  %189 = icmp eq i64 %188, 8
  br i1 %189, label %195, label %190

190:                                              ; preds = %145
  %191 = getelementptr inbounds i32, i32* %148, i64 1
  %192 = getelementptr inbounds i16, i16* %149, i64 1
  %193 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 %188
  %194 = load i16, i16* %193, align 2
  br label %145

195:                                              ; preds = %145
  %196 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %196, i8 0, i64 256, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %9) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_horizontal_filter_add_14_c(i8* nocapture, i16* nocapture, i32, i32, i64) #3 {
  %6 = alloca [8 x i16], align 16
  %7 = bitcast i8* %0 to i16*
  %8 = bitcast i16* %1 to i32*
  %9 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %9) #8
  %10 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 0
  %11 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 1
  %12 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 2
  %13 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 3
  %14 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 4
  %15 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 5
  %16 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 6
  %17 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 7
  %18 = lshr i64 %4, 1
  %19 = icmp eq i32 %2, 0
  %20 = bitcast [8 x i16]* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 16, i1 false)
  br i1 %19, label %26, label %21

21:                                               ; preds = %5
  %22 = shl i64 %18, 32
  %23 = ashr exact i64 %22, 32
  %24 = xor i64 %23, -1
  %25 = getelementptr inbounds i16, i16* %7, i64 %24
  br label %31

26:                                               ; preds = %5
  %27 = getelementptr inbounds i8, i8* %0, i64 -2
  %28 = bitcast i8* %27 to i16*
  %29 = shl i64 %18, 32
  %30 = ashr exact i64 %29, 32
  br label %31

31:                                               ; preds = %26, %21
  %32 = phi i64 [ %30, %26 ], [ %23, %21 ]
  %33 = phi i64 [ %29, %26 ], [ %22, %21 ]
  %34 = phi i16* [ %28, %26 ], [ %25, %21 ]
  %35 = load i16, i16* %34, align 2
  %36 = zext i16 %35 to i32
  %37 = getelementptr inbounds i8, i8* %0, i64 -2
  %38 = bitcast i8* %37 to i16*
  %39 = load i16, i16* %38, align 2
  %40 = zext i16 %39 to i32
  %41 = shl nuw nsw i32 %40, 1
  %42 = add i64 %33, -4294967296
  %43 = ashr exact i64 %42, 32
  %44 = getelementptr inbounds i16, i16* %7, i64 %43
  %45 = load i16, i16* %44, align 2
  %46 = zext i16 %45 to i32
  %47 = add nuw nsw i32 %46, 2
  %48 = add nuw nsw i32 %47, %36
  %49 = add nuw nsw i32 %48, %41
  %50 = lshr i32 %49, 2
  %51 = shl nuw nsw i32 %46, 1
  %52 = shl i64 %4, 32
  %53 = and i64 %52, -8589934592
  %54 = add i64 %53, -4294967296
  %55 = ashr exact i64 %54, 32
  %56 = getelementptr inbounds i16, i16* %7, i64 %55
  %57 = load i16, i16* %56, align 2
  %58 = zext i16 %57 to i32
  %59 = add nuw nsw i32 %58, 2
  %60 = add nuw nsw i32 %59, %40
  %61 = add nuw nsw i32 %60, %51
  %62 = lshr i32 %61, 2
  %63 = shl nuw nsw i32 %58, 1
  %64 = mul i64 %18, 12884901888
  %65 = add i64 %64, -4294967296
  %66 = ashr exact i64 %65, 32
  %67 = getelementptr inbounds i16, i16* %7, i64 %66
  %68 = load i16, i16* %67, align 2
  %69 = zext i16 %68 to i32
  %70 = add nuw nsw i32 %47, %63
  %71 = add nuw nsw i32 %70, %69
  %72 = lshr i32 %71, 2
  %73 = shl nuw nsw i32 %69, 1
  %74 = shl i64 %18, 34
  %75 = add i64 %74, -4294967296
  %76 = ashr exact i64 %75, 32
  %77 = getelementptr inbounds i16, i16* %7, i64 %76
  %78 = load i16, i16* %77, align 2
  %79 = zext i16 %78 to i32
  %80 = add nuw nsw i32 %59, %73
  %81 = add nuw nsw i32 %80, %79
  %82 = lshr i32 %81, 2
  %83 = shl nuw nsw i32 %79, 1
  %84 = mul i64 %18, 21474836480
  %85 = add i64 %84, -4294967296
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i16, i16* %7, i64 %86
  %88 = load i16, i16* %87, align 2
  %89 = zext i16 %88 to i32
  %90 = add nuw nsw i32 %69, 2
  %91 = add nuw nsw i32 %90, %83
  %92 = add nuw nsw i32 %91, %89
  %93 = lshr i32 %92, 2
  %94 = shl nuw nsw i32 %89, 1
  %95 = mul i64 %18, 25769803776
  %96 = add i64 %95, -4294967296
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i16, i16* %7, i64 %97
  %99 = load i16, i16* %98, align 2
  %100 = zext i16 %99 to i32
  %101 = add nuw nsw i32 %79, 2
  %102 = add nuw nsw i32 %101, %94
  %103 = add nuw nsw i32 %102, %100
  %104 = lshr i32 %103, 2
  %105 = shl nuw nsw i32 %100, 1
  %106 = mul i64 %18, 30064771072
  %107 = add i64 %106, -4294967296
  %108 = ashr exact i64 %107, 32
  %109 = getelementptr inbounds i16, i16* %7, i64 %108
  %110 = load i16, i16* %109, align 2
  %111 = zext i16 %110 to i32
  %112 = add nuw nsw i32 %89, 2
  %113 = add nuw nsw i32 %112, %105
  %114 = add nuw nsw i32 %113, %111
  %115 = lshr i32 %114, 2
  %116 = mul nuw nsw i32 %111, 3
  %117 = add nuw nsw i32 %100, 2
  %118 = add nuw nsw i32 %117, %116
  %119 = lshr i32 %118, 2
  %120 = trunc i32 %50 to i16
  store i16 %120, i16* %10, align 16
  %121 = trunc i32 %62 to i16
  store i16 %121, i16* %11, align 2
  %122 = trunc i32 %72 to i16
  store i16 %122, i16* %12, align 4
  %123 = trunc i32 %82 to i16
  store i16 %123, i16* %13, align 2
  %124 = trunc i32 %93 to i16
  store i16 %124, i16* %14, align 8
  %125 = trunc i32 %104 to i16
  store i16 %125, i16* %15, align 2
  %126 = trunc i32 %115 to i16
  store i16 %126, i16* %16, align 4
  %127 = trunc i32 %119 to i16
  store i16 %127, i16* %17, align 2
  br label %128

128:                                              ; preds = %173, %31
  %129 = phi i16 [ %120, %31 ], [ %177, %173 ]
  %130 = phi i64 [ 0, %31 ], [ %171, %173 ]
  %131 = phi i16* [ %7, %31 ], [ %175, %173 ]
  %132 = phi i32* [ %8, %31 ], [ %174, %173 ]
  %133 = load i32, i32* %132, align 4
  %134 = trunc i32 %133 to i16
  %135 = add i16 %129, %134
  store i16 %135, i16* %131, align 2
  %136 = getelementptr inbounds i32, i32* %132, i64 1
  %137 = load i32, i32* %136, align 4
  %138 = trunc i32 %137 to i16
  %139 = add i16 %135, %138
  %140 = getelementptr inbounds i16, i16* %131, i64 1
  store i16 %139, i16* %140, align 2
  %141 = getelementptr inbounds i32, i32* %132, i64 2
  %142 = load i32, i32* %141, align 4
  %143 = trunc i32 %142 to i16
  %144 = add i16 %139, %143
  %145 = getelementptr inbounds i16, i16* %131, i64 2
  store i16 %144, i16* %145, align 2
  %146 = getelementptr inbounds i32, i32* %132, i64 3
  %147 = load i32, i32* %146, align 4
  %148 = trunc i32 %147 to i16
  %149 = add i16 %144, %148
  %150 = getelementptr inbounds i16, i16* %131, i64 3
  store i16 %149, i16* %150, align 2
  %151 = getelementptr inbounds i32, i32* %132, i64 4
  %152 = load i32, i32* %151, align 4
  %153 = trunc i32 %152 to i16
  %154 = add i16 %149, %153
  %155 = getelementptr inbounds i16, i16* %131, i64 4
  store i16 %154, i16* %155, align 2
  %156 = getelementptr inbounds i32, i32* %132, i64 5
  %157 = load i32, i32* %156, align 4
  %158 = trunc i32 %157 to i16
  %159 = add i16 %154, %158
  %160 = getelementptr inbounds i16, i16* %131, i64 5
  store i16 %159, i16* %160, align 2
  %161 = getelementptr inbounds i32, i32* %132, i64 6
  %162 = load i32, i32* %161, align 4
  %163 = trunc i32 %162 to i16
  %164 = add i16 %159, %163
  %165 = getelementptr inbounds i16, i16* %131, i64 6
  store i16 %164, i16* %165, align 2
  %166 = getelementptr inbounds i32, i32* %132, i64 7
  %167 = load i32, i32* %166, align 4
  %168 = trunc i32 %167 to i16
  %169 = add i16 %164, %168
  %170 = getelementptr inbounds i16, i16* %131, i64 7
  store i16 %169, i16* %170, align 2
  %171 = add nuw nsw i64 %130, 1
  %172 = icmp eq i64 %171, 8
  br i1 %172, label %178, label %173

173:                                              ; preds = %128
  %174 = getelementptr inbounds i32, i32* %132, i64 8
  %175 = getelementptr inbounds i16, i16* %131, i64 %32
  %176 = getelementptr inbounds [8 x i16], [8 x i16]* %6, i64 0, i64 %171
  %177 = load i16, i16* %176, align 2
  br label %128

178:                                              ; preds = %128
  %179 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %179, i8 0, i64 256, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %9) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8_vertical_add_14_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  %6 = sub nsw i64 0, %5
  %7 = and i64 %3, -2
  %8 = mul nsw i64 %5, 3
  %9 = shl nsw i64 %5, 2
  br label %10

10:                                               ; preds = %10, %4
  %11 = phi i64 [ 0, %4 ], [ %122, %10 ]
  %12 = getelementptr inbounds i32, i32* %1, i64 %11
  %13 = load i32, i32* %12, align 4
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = shl i64 %11, 5
  %17 = getelementptr inbounds i16, i16* %2, i64 %16
  %18 = bitcast i8* %15 to i16*
  %19 = bitcast i16* %17 to i32*
  %20 = getelementptr inbounds i16, i16* %18, i64 %6
  %21 = load i16, i16* %20, align 2
  %22 = load i32, i32* %19, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %21, %23
  store i16 %24, i16* %18, align 2
  %25 = getelementptr inbounds i16, i16* %17, i64 8
  %26 = bitcast i16* %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %20, i64 %7
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i16, i16* %17, i64 16
  %32 = bitcast i16* %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = trunc i32 %33 to i16
  %35 = add i16 %29, %34
  %36 = getelementptr inbounds i16, i16* %20, i64 %8
  store i16 %35, i16* %36, align 2
  %37 = getelementptr inbounds i16, i16* %17, i64 24
  %38 = bitcast i16* %37 to i32*
  %39 = load i32, i32* %38, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %35, %40
  %42 = getelementptr inbounds i16, i16* %20, i64 %9
  store i16 %41, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %20, i64 1
  %44 = getelementptr inbounds i16, i16* %17, i64 2
  %45 = bitcast i16* %44 to i32*
  %46 = load i16, i16* %43, align 2
  %47 = load i32, i32* %45, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %46, %48
  %50 = getelementptr inbounds i16, i16* %43, i64 %5
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %17, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %49, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 %7
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %17, i64 18
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 %8
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %17, i64 26
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 %9
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 1
  %70 = getelementptr inbounds i16, i16* %17, i64 4
  %71 = bitcast i16* %70 to i32*
  %72 = load i16, i16* %69, align 2
  %73 = load i32, i32* %71, align 4
  %74 = trunc i32 %73 to i16
  %75 = add i16 %72, %74
  %76 = getelementptr inbounds i16, i16* %69, i64 %5
  store i16 %75, i16* %76, align 2
  %77 = getelementptr inbounds i16, i16* %17, i64 12
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %75, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 %7
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %17, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 %8
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %17, i64 28
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 %9
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 1
  %96 = getelementptr inbounds i16, i16* %17, i64 6
  %97 = bitcast i16* %96 to i32*
  %98 = load i16, i16* %95, align 2
  %99 = load i32, i32* %97, align 4
  %100 = trunc i32 %99 to i16
  %101 = add i16 %98, %100
  %102 = getelementptr inbounds i16, i16* %95, i64 %5
  store i16 %101, i16* %102, align 2
  %103 = getelementptr inbounds i16, i16* %17, i64 14
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %101, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 %7
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %17, i64 22
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 %8
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %17, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 %9
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %11, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %10

124:                                              ; preds = %10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8_horizontal_add_14_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %122, %6 ]
  %8 = getelementptr inbounds i32, i32* %1, i64 %7
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = shl i64 %7, 5
  %13 = getelementptr inbounds i16, i16* %2, i64 %12
  %14 = bitcast i8* %11 to i16*
  %15 = bitcast i16* %13 to i32*
  %16 = getelementptr inbounds i8, i8* %11, i64 -2
  %17 = bitcast i8* %16 to i16*
  %18 = load i16, i16* %17, align 2
  %19 = load i32, i32* %15, align 4
  %20 = trunc i32 %19 to i16
  %21 = add i16 %18, %20
  store i16 %21, i16* %14, align 2
  %22 = getelementptr inbounds i16, i16* %13, i64 2
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %21, %25
  %27 = getelementptr inbounds i8, i8* %11, i64 2
  %28 = bitcast i8* %27 to i16*
  store i16 %26, i16* %28, align 2
  %29 = getelementptr inbounds i16, i16* %13, i64 4
  %30 = bitcast i16* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %26, %32
  %34 = getelementptr inbounds i8, i8* %11, i64 4
  %35 = bitcast i8* %34 to i16*
  store i16 %33, i16* %35, align 2
  %36 = getelementptr inbounds i16, i16* %13, i64 6
  %37 = bitcast i16* %36 to i32*
  %38 = load i32, i32* %37, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %33, %39
  %41 = getelementptr inbounds i8, i8* %11, i64 6
  %42 = bitcast i8* %41 to i16*
  store i16 %40, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %14, i64 %5
  %44 = getelementptr inbounds i16, i16* %13, i64 8
  %45 = bitcast i16* %44 to i32*
  %46 = getelementptr inbounds i16, i16* %43, i64 -1
  %47 = load i16, i16* %46, align 2
  %48 = load i32, i32* %45, align 4
  %49 = trunc i32 %48 to i16
  %50 = add i16 %47, %49
  store i16 %50, i16* %43, align 2
  %51 = getelementptr inbounds i16, i16* %13, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %50, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 1
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %13, i64 12
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 2
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %13, i64 14
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 3
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 %5
  %70 = getelementptr inbounds i16, i16* %13, i64 16
  %71 = bitcast i16* %70 to i32*
  %72 = getelementptr inbounds i16, i16* %69, i64 -1
  %73 = load i16, i16* %72, align 2
  %74 = load i32, i32* %71, align 4
  %75 = trunc i32 %74 to i16
  %76 = add i16 %73, %75
  store i16 %76, i16* %69, align 2
  %77 = getelementptr inbounds i16, i16* %13, i64 18
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %76, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 1
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %13, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 2
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %13, i64 22
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 3
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 %5
  %96 = getelementptr inbounds i16, i16* %13, i64 24
  %97 = bitcast i16* %96 to i32*
  %98 = getelementptr inbounds i16, i16* %95, i64 -1
  %99 = load i16, i16* %98, align 2
  %100 = load i32, i32* %97, align 4
  %101 = trunc i32 %100 to i16
  %102 = add i16 %99, %101
  store i16 %102, i16* %95, align 2
  %103 = getelementptr inbounds i16, i16* %13, i64 26
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %102, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 1
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %13, i64 28
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 2
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %13, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 3
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %7, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %6

124:                                              ; preds = %6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x16_vertical_add_14_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  %6 = sub nsw i64 0, %5
  %7 = and i64 %3, -2
  %8 = mul nsw i64 %5, 3
  %9 = shl nsw i64 %5, 2
  br label %10

10:                                               ; preds = %10, %4
  %11 = phi i64 [ 0, %4 ], [ %122, %10 ]
  %12 = getelementptr inbounds i32, i32* %1, i64 %11
  %13 = load i32, i32* %12, align 4
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = shl i64 %11, 5
  %17 = getelementptr inbounds i16, i16* %2, i64 %16
  %18 = bitcast i8* %15 to i16*
  %19 = bitcast i16* %17 to i32*
  %20 = getelementptr inbounds i16, i16* %18, i64 %6
  %21 = load i16, i16* %20, align 2
  %22 = load i32, i32* %19, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %21, %23
  store i16 %24, i16* %18, align 2
  %25 = getelementptr inbounds i16, i16* %17, i64 8
  %26 = bitcast i16* %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %20, i64 %7
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i16, i16* %17, i64 16
  %32 = bitcast i16* %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = trunc i32 %33 to i16
  %35 = add i16 %29, %34
  %36 = getelementptr inbounds i16, i16* %20, i64 %8
  store i16 %35, i16* %36, align 2
  %37 = getelementptr inbounds i16, i16* %17, i64 24
  %38 = bitcast i16* %37 to i32*
  %39 = load i32, i32* %38, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %35, %40
  %42 = getelementptr inbounds i16, i16* %20, i64 %9
  store i16 %41, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %20, i64 1
  %44 = getelementptr inbounds i16, i16* %17, i64 2
  %45 = bitcast i16* %44 to i32*
  %46 = load i16, i16* %43, align 2
  %47 = load i32, i32* %45, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %46, %48
  %50 = getelementptr inbounds i16, i16* %43, i64 %5
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %17, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %49, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 %7
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %17, i64 18
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 %8
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %17, i64 26
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 %9
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 1
  %70 = getelementptr inbounds i16, i16* %17, i64 4
  %71 = bitcast i16* %70 to i32*
  %72 = load i16, i16* %69, align 2
  %73 = load i32, i32* %71, align 4
  %74 = trunc i32 %73 to i16
  %75 = add i16 %72, %74
  %76 = getelementptr inbounds i16, i16* %69, i64 %5
  store i16 %75, i16* %76, align 2
  %77 = getelementptr inbounds i16, i16* %17, i64 12
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %75, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 %7
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %17, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 %8
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %17, i64 28
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 %9
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 1
  %96 = getelementptr inbounds i16, i16* %17, i64 6
  %97 = bitcast i16* %96 to i32*
  %98 = load i16, i16* %95, align 2
  %99 = load i32, i32* %97, align 4
  %100 = trunc i32 %99 to i16
  %101 = add i16 %98, %100
  %102 = getelementptr inbounds i16, i16* %95, i64 %5
  store i16 %101, i16* %102, align 2
  %103 = getelementptr inbounds i16, i16* %17, i64 14
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %101, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 %7
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %17, i64 22
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 %8
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %17, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 %9
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %11, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %10

124:                                              ; preds = %10, %124
  %125 = phi i64 [ %237, %124 ], [ 4, %10 ]
  %126 = add nuw nsw i64 %125, 4
  %127 = getelementptr inbounds i32, i32* %1, i64 %126
  %128 = load i32, i32* %127, align 4
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds i8, i8* %0, i64 %129
  %131 = shl i64 %125, 5
  %132 = getelementptr inbounds i16, i16* %2, i64 %131
  %133 = bitcast i8* %130 to i16*
  %134 = bitcast i16* %132 to i32*
  %135 = getelementptr inbounds i16, i16* %133, i64 %6
  %136 = load i16, i16* %135, align 2
  %137 = load i32, i32* %134, align 4
  %138 = trunc i32 %137 to i16
  %139 = add i16 %136, %138
  store i16 %139, i16* %133, align 2
  %140 = getelementptr inbounds i16, i16* %132, i64 8
  %141 = bitcast i16* %140 to i32*
  %142 = load i32, i32* %141, align 4
  %143 = trunc i32 %142 to i16
  %144 = add i16 %139, %143
  %145 = getelementptr inbounds i16, i16* %135, i64 %7
  store i16 %144, i16* %145, align 2
  %146 = getelementptr inbounds i16, i16* %132, i64 16
  %147 = bitcast i16* %146 to i32*
  %148 = load i32, i32* %147, align 4
  %149 = trunc i32 %148 to i16
  %150 = add i16 %144, %149
  %151 = getelementptr inbounds i16, i16* %135, i64 %8
  store i16 %150, i16* %151, align 2
  %152 = getelementptr inbounds i16, i16* %132, i64 24
  %153 = bitcast i16* %152 to i32*
  %154 = load i32, i32* %153, align 4
  %155 = trunc i32 %154 to i16
  %156 = add i16 %150, %155
  %157 = getelementptr inbounds i16, i16* %135, i64 %9
  store i16 %156, i16* %157, align 2
  %158 = getelementptr inbounds i16, i16* %135, i64 1
  %159 = getelementptr inbounds i16, i16* %132, i64 2
  %160 = bitcast i16* %159 to i32*
  %161 = load i16, i16* %158, align 2
  %162 = load i32, i32* %160, align 4
  %163 = trunc i32 %162 to i16
  %164 = add i16 %161, %163
  %165 = getelementptr inbounds i16, i16* %158, i64 %5
  store i16 %164, i16* %165, align 2
  %166 = getelementptr inbounds i16, i16* %132, i64 10
  %167 = bitcast i16* %166 to i32*
  %168 = load i32, i32* %167, align 4
  %169 = trunc i32 %168 to i16
  %170 = add i16 %164, %169
  %171 = getelementptr inbounds i16, i16* %158, i64 %7
  store i16 %170, i16* %171, align 2
  %172 = getelementptr inbounds i16, i16* %132, i64 18
  %173 = bitcast i16* %172 to i32*
  %174 = load i32, i32* %173, align 4
  %175 = trunc i32 %174 to i16
  %176 = add i16 %170, %175
  %177 = getelementptr inbounds i16, i16* %158, i64 %8
  store i16 %176, i16* %177, align 2
  %178 = getelementptr inbounds i16, i16* %132, i64 26
  %179 = bitcast i16* %178 to i32*
  %180 = load i32, i32* %179, align 4
  %181 = trunc i32 %180 to i16
  %182 = add i16 %176, %181
  %183 = getelementptr inbounds i16, i16* %158, i64 %9
  store i16 %182, i16* %183, align 2
  %184 = getelementptr inbounds i16, i16* %158, i64 1
  %185 = getelementptr inbounds i16, i16* %132, i64 4
  %186 = bitcast i16* %185 to i32*
  %187 = load i16, i16* %184, align 2
  %188 = load i32, i32* %186, align 4
  %189 = trunc i32 %188 to i16
  %190 = add i16 %187, %189
  %191 = getelementptr inbounds i16, i16* %184, i64 %5
  store i16 %190, i16* %191, align 2
  %192 = getelementptr inbounds i16, i16* %132, i64 12
  %193 = bitcast i16* %192 to i32*
  %194 = load i32, i32* %193, align 4
  %195 = trunc i32 %194 to i16
  %196 = add i16 %190, %195
  %197 = getelementptr inbounds i16, i16* %184, i64 %7
  store i16 %196, i16* %197, align 2
  %198 = getelementptr inbounds i16, i16* %132, i64 20
  %199 = bitcast i16* %198 to i32*
  %200 = load i32, i32* %199, align 4
  %201 = trunc i32 %200 to i16
  %202 = add i16 %196, %201
  %203 = getelementptr inbounds i16, i16* %184, i64 %8
  store i16 %202, i16* %203, align 2
  %204 = getelementptr inbounds i16, i16* %132, i64 28
  %205 = bitcast i16* %204 to i32*
  %206 = load i32, i32* %205, align 4
  %207 = trunc i32 %206 to i16
  %208 = add i16 %202, %207
  %209 = getelementptr inbounds i16, i16* %184, i64 %9
  store i16 %208, i16* %209, align 2
  %210 = getelementptr inbounds i16, i16* %184, i64 1
  %211 = getelementptr inbounds i16, i16* %132, i64 6
  %212 = bitcast i16* %211 to i32*
  %213 = load i16, i16* %210, align 2
  %214 = load i32, i32* %212, align 4
  %215 = trunc i32 %214 to i16
  %216 = add i16 %213, %215
  %217 = getelementptr inbounds i16, i16* %210, i64 %5
  store i16 %216, i16* %217, align 2
  %218 = getelementptr inbounds i16, i16* %132, i64 14
  %219 = bitcast i16* %218 to i32*
  %220 = load i32, i32* %219, align 4
  %221 = trunc i32 %220 to i16
  %222 = add i16 %216, %221
  %223 = getelementptr inbounds i16, i16* %210, i64 %7
  store i16 %222, i16* %223, align 2
  %224 = getelementptr inbounds i16, i16* %132, i64 22
  %225 = bitcast i16* %224 to i32*
  %226 = load i32, i32* %225, align 4
  %227 = trunc i32 %226 to i16
  %228 = add i16 %222, %227
  %229 = getelementptr inbounds i16, i16* %210, i64 %8
  store i16 %228, i16* %229, align 2
  %230 = getelementptr inbounds i16, i16* %132, i64 30
  %231 = bitcast i16* %230 to i32*
  %232 = load i32, i32* %231, align 4
  %233 = trunc i32 %232 to i16
  %234 = add i16 %228, %233
  %235 = getelementptr inbounds i16, i16* %210, i64 %9
  store i16 %234, i16* %235, align 2
  %236 = bitcast i16* %132 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %236, i8 0, i64 64, i1 false) #8
  %237 = add nuw nsw i64 %125, 1
  %238 = icmp eq i64 %237, 8
  br i1 %238, label %239, label %124

239:                                              ; preds = %124
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x16_horizontal_add_14_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %122, %6 ]
  %8 = getelementptr inbounds i32, i32* %1, i64 %7
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = shl i64 %7, 5
  %13 = getelementptr inbounds i16, i16* %2, i64 %12
  %14 = bitcast i8* %11 to i16*
  %15 = bitcast i16* %13 to i32*
  %16 = getelementptr inbounds i8, i8* %11, i64 -2
  %17 = bitcast i8* %16 to i16*
  %18 = load i16, i16* %17, align 2
  %19 = load i32, i32* %15, align 4
  %20 = trunc i32 %19 to i16
  %21 = add i16 %18, %20
  store i16 %21, i16* %14, align 2
  %22 = getelementptr inbounds i16, i16* %13, i64 2
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %21, %25
  %27 = getelementptr inbounds i8, i8* %11, i64 2
  %28 = bitcast i8* %27 to i16*
  store i16 %26, i16* %28, align 2
  %29 = getelementptr inbounds i16, i16* %13, i64 4
  %30 = bitcast i16* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %26, %32
  %34 = getelementptr inbounds i8, i8* %11, i64 4
  %35 = bitcast i8* %34 to i16*
  store i16 %33, i16* %35, align 2
  %36 = getelementptr inbounds i16, i16* %13, i64 6
  %37 = bitcast i16* %36 to i32*
  %38 = load i32, i32* %37, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %33, %39
  %41 = getelementptr inbounds i8, i8* %11, i64 6
  %42 = bitcast i8* %41 to i16*
  store i16 %40, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %14, i64 %5
  %44 = getelementptr inbounds i16, i16* %13, i64 8
  %45 = bitcast i16* %44 to i32*
  %46 = getelementptr inbounds i16, i16* %43, i64 -1
  %47 = load i16, i16* %46, align 2
  %48 = load i32, i32* %45, align 4
  %49 = trunc i32 %48 to i16
  %50 = add i16 %47, %49
  store i16 %50, i16* %43, align 2
  %51 = getelementptr inbounds i16, i16* %13, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %50, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 1
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %13, i64 12
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 2
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %13, i64 14
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 3
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 %5
  %70 = getelementptr inbounds i16, i16* %13, i64 16
  %71 = bitcast i16* %70 to i32*
  %72 = getelementptr inbounds i16, i16* %69, i64 -1
  %73 = load i16, i16* %72, align 2
  %74 = load i32, i32* %71, align 4
  %75 = trunc i32 %74 to i16
  %76 = add i16 %73, %75
  store i16 %76, i16* %69, align 2
  %77 = getelementptr inbounds i16, i16* %13, i64 18
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %76, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 1
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %13, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 2
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %13, i64 22
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 3
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 %5
  %96 = getelementptr inbounds i16, i16* %13, i64 24
  %97 = bitcast i16* %96 to i32*
  %98 = getelementptr inbounds i16, i16* %95, i64 -1
  %99 = load i16, i16* %98, align 2
  %100 = load i32, i32* %97, align 4
  %101 = trunc i32 %100 to i16
  %102 = add i16 %99, %101
  store i16 %102, i16* %95, align 2
  %103 = getelementptr inbounds i16, i16* %13, i64 26
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %102, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 1
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %13, i64 28
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 2
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %13, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 3
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %7, 1
  %123 = icmp eq i64 %122, 4
  br i1 %123, label %124, label %6

124:                                              ; preds = %6, %124
  %125 = phi i64 [ %241, %124 ], [ 4, %6 ]
  %126 = add nuw nsw i64 %125, 4
  %127 = getelementptr inbounds i32, i32* %1, i64 %126
  %128 = load i32, i32* %127, align 4
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds i8, i8* %0, i64 %129
  %131 = shl i64 %125, 5
  %132 = getelementptr inbounds i16, i16* %2, i64 %131
  %133 = bitcast i8* %130 to i16*
  %134 = bitcast i16* %132 to i32*
  %135 = getelementptr inbounds i8, i8* %130, i64 -2
  %136 = bitcast i8* %135 to i16*
  %137 = load i16, i16* %136, align 2
  %138 = load i32, i32* %134, align 4
  %139 = trunc i32 %138 to i16
  %140 = add i16 %137, %139
  store i16 %140, i16* %133, align 2
  %141 = getelementptr inbounds i16, i16* %132, i64 2
  %142 = bitcast i16* %141 to i32*
  %143 = load i32, i32* %142, align 4
  %144 = trunc i32 %143 to i16
  %145 = add i16 %140, %144
  %146 = getelementptr inbounds i8, i8* %130, i64 2
  %147 = bitcast i8* %146 to i16*
  store i16 %145, i16* %147, align 2
  %148 = getelementptr inbounds i16, i16* %132, i64 4
  %149 = bitcast i16* %148 to i32*
  %150 = load i32, i32* %149, align 4
  %151 = trunc i32 %150 to i16
  %152 = add i16 %145, %151
  %153 = getelementptr inbounds i8, i8* %130, i64 4
  %154 = bitcast i8* %153 to i16*
  store i16 %152, i16* %154, align 2
  %155 = getelementptr inbounds i16, i16* %132, i64 6
  %156 = bitcast i16* %155 to i32*
  %157 = load i32, i32* %156, align 4
  %158 = trunc i32 %157 to i16
  %159 = add i16 %152, %158
  %160 = getelementptr inbounds i8, i8* %130, i64 6
  %161 = bitcast i8* %160 to i16*
  store i16 %159, i16* %161, align 2
  %162 = getelementptr inbounds i16, i16* %133, i64 %5
  %163 = getelementptr inbounds i16, i16* %132, i64 8
  %164 = bitcast i16* %163 to i32*
  %165 = getelementptr inbounds i16, i16* %162, i64 -1
  %166 = load i16, i16* %165, align 2
  %167 = load i32, i32* %164, align 4
  %168 = trunc i32 %167 to i16
  %169 = add i16 %166, %168
  store i16 %169, i16* %162, align 2
  %170 = getelementptr inbounds i16, i16* %132, i64 10
  %171 = bitcast i16* %170 to i32*
  %172 = load i32, i32* %171, align 4
  %173 = trunc i32 %172 to i16
  %174 = add i16 %169, %173
  %175 = getelementptr inbounds i16, i16* %162, i64 1
  store i16 %174, i16* %175, align 2
  %176 = getelementptr inbounds i16, i16* %132, i64 12
  %177 = bitcast i16* %176 to i32*
  %178 = load i32, i32* %177, align 4
  %179 = trunc i32 %178 to i16
  %180 = add i16 %174, %179
  %181 = getelementptr inbounds i16, i16* %162, i64 2
  store i16 %180, i16* %181, align 2
  %182 = getelementptr inbounds i16, i16* %132, i64 14
  %183 = bitcast i16* %182 to i32*
  %184 = load i32, i32* %183, align 4
  %185 = trunc i32 %184 to i16
  %186 = add i16 %180, %185
  %187 = getelementptr inbounds i16, i16* %162, i64 3
  store i16 %186, i16* %187, align 2
  %188 = getelementptr inbounds i16, i16* %162, i64 %5
  %189 = getelementptr inbounds i16, i16* %132, i64 16
  %190 = bitcast i16* %189 to i32*
  %191 = getelementptr inbounds i16, i16* %188, i64 -1
  %192 = load i16, i16* %191, align 2
  %193 = load i32, i32* %190, align 4
  %194 = trunc i32 %193 to i16
  %195 = add i16 %192, %194
  store i16 %195, i16* %188, align 2
  %196 = getelementptr inbounds i16, i16* %132, i64 18
  %197 = bitcast i16* %196 to i32*
  %198 = load i32, i32* %197, align 4
  %199 = trunc i32 %198 to i16
  %200 = add i16 %195, %199
  %201 = getelementptr inbounds i16, i16* %188, i64 1
  store i16 %200, i16* %201, align 2
  %202 = getelementptr inbounds i16, i16* %132, i64 20
  %203 = bitcast i16* %202 to i32*
  %204 = load i32, i32* %203, align 4
  %205 = trunc i32 %204 to i16
  %206 = add i16 %200, %205
  %207 = getelementptr inbounds i16, i16* %188, i64 2
  store i16 %206, i16* %207, align 2
  %208 = getelementptr inbounds i16, i16* %132, i64 22
  %209 = bitcast i16* %208 to i32*
  %210 = load i32, i32* %209, align 4
  %211 = trunc i32 %210 to i16
  %212 = add i16 %206, %211
  %213 = getelementptr inbounds i16, i16* %188, i64 3
  store i16 %212, i16* %213, align 2
  %214 = getelementptr inbounds i16, i16* %188, i64 %5
  %215 = getelementptr inbounds i16, i16* %132, i64 24
  %216 = bitcast i16* %215 to i32*
  %217 = getelementptr inbounds i16, i16* %214, i64 -1
  %218 = load i16, i16* %217, align 2
  %219 = load i32, i32* %216, align 4
  %220 = trunc i32 %219 to i16
  %221 = add i16 %218, %220
  store i16 %221, i16* %214, align 2
  %222 = getelementptr inbounds i16, i16* %132, i64 26
  %223 = bitcast i16* %222 to i32*
  %224 = load i32, i32* %223, align 4
  %225 = trunc i32 %224 to i16
  %226 = add i16 %221, %225
  %227 = getelementptr inbounds i16, i16* %214, i64 1
  store i16 %226, i16* %227, align 2
  %228 = getelementptr inbounds i16, i16* %132, i64 28
  %229 = bitcast i16* %228 to i32*
  %230 = load i32, i32* %229, align 4
  %231 = trunc i32 %230 to i16
  %232 = add i16 %226, %231
  %233 = getelementptr inbounds i16, i16* %214, i64 2
  store i16 %232, i16* %233, align 2
  %234 = getelementptr inbounds i16, i16* %132, i64 30
  %235 = bitcast i16* %234 to i32*
  %236 = load i32, i32* %235, align 4
  %237 = trunc i32 %236 to i16
  %238 = add i16 %232, %237
  %239 = getelementptr inbounds i16, i16* %214, i64 3
  store i16 %238, i16* %239, align 2
  %240 = bitcast i16* %132 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %240, i8 0, i64 64, i1 false) #8
  %241 = add nuw nsw i64 %125, 1
  %242 = icmp eq i64 %241, 8
  br i1 %242, label %243, label %124

243:                                              ; preds = %124
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred16x16_vertical_add_14_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  %6 = sub nsw i64 0, %5
  %7 = and i64 %3, -2
  %8 = mul nsw i64 %5, 3
  %9 = shl nsw i64 %5, 2
  br label %10

10:                                               ; preds = %10, %4
  %11 = phi i64 [ 0, %4 ], [ %122, %10 ]
  %12 = getelementptr inbounds i32, i32* %1, i64 %11
  %13 = load i32, i32* %12, align 4
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = shl i64 %11, 5
  %17 = getelementptr inbounds i16, i16* %2, i64 %16
  %18 = bitcast i8* %15 to i16*
  %19 = bitcast i16* %17 to i32*
  %20 = getelementptr inbounds i16, i16* %18, i64 %6
  %21 = load i16, i16* %20, align 2
  %22 = load i32, i32* %19, align 4
  %23 = trunc i32 %22 to i16
  %24 = add i16 %21, %23
  store i16 %24, i16* %18, align 2
  %25 = getelementptr inbounds i16, i16* %17, i64 8
  %26 = bitcast i16* %25 to i32*
  %27 = load i32, i32* %26, align 4
  %28 = trunc i32 %27 to i16
  %29 = add i16 %24, %28
  %30 = getelementptr inbounds i16, i16* %20, i64 %7
  store i16 %29, i16* %30, align 2
  %31 = getelementptr inbounds i16, i16* %17, i64 16
  %32 = bitcast i16* %31 to i32*
  %33 = load i32, i32* %32, align 4
  %34 = trunc i32 %33 to i16
  %35 = add i16 %29, %34
  %36 = getelementptr inbounds i16, i16* %20, i64 %8
  store i16 %35, i16* %36, align 2
  %37 = getelementptr inbounds i16, i16* %17, i64 24
  %38 = bitcast i16* %37 to i32*
  %39 = load i32, i32* %38, align 4
  %40 = trunc i32 %39 to i16
  %41 = add i16 %35, %40
  %42 = getelementptr inbounds i16, i16* %20, i64 %9
  store i16 %41, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %20, i64 1
  %44 = getelementptr inbounds i16, i16* %17, i64 2
  %45 = bitcast i16* %44 to i32*
  %46 = load i16, i16* %43, align 2
  %47 = load i32, i32* %45, align 4
  %48 = trunc i32 %47 to i16
  %49 = add i16 %46, %48
  %50 = getelementptr inbounds i16, i16* %43, i64 %5
  store i16 %49, i16* %50, align 2
  %51 = getelementptr inbounds i16, i16* %17, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %49, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 %7
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %17, i64 18
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 %8
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %17, i64 26
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 %9
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 1
  %70 = getelementptr inbounds i16, i16* %17, i64 4
  %71 = bitcast i16* %70 to i32*
  %72 = load i16, i16* %69, align 2
  %73 = load i32, i32* %71, align 4
  %74 = trunc i32 %73 to i16
  %75 = add i16 %72, %74
  %76 = getelementptr inbounds i16, i16* %69, i64 %5
  store i16 %75, i16* %76, align 2
  %77 = getelementptr inbounds i16, i16* %17, i64 12
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %75, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 %7
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %17, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 %8
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %17, i64 28
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 %9
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 1
  %96 = getelementptr inbounds i16, i16* %17, i64 6
  %97 = bitcast i16* %96 to i32*
  %98 = load i16, i16* %95, align 2
  %99 = load i32, i32* %97, align 4
  %100 = trunc i32 %99 to i16
  %101 = add i16 %98, %100
  %102 = getelementptr inbounds i16, i16* %95, i64 %5
  store i16 %101, i16* %102, align 2
  %103 = getelementptr inbounds i16, i16* %17, i64 14
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %101, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 %7
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %17, i64 22
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 %8
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %17, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 %9
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %17 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %11, 1
  %123 = icmp eq i64 %122, 16
  br i1 %123, label %124, label %10

124:                                              ; preds = %10
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred16x16_horizontal_add_14_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = ashr i64 %3, 1
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %122, %6 ]
  %8 = getelementptr inbounds i32, i32* %1, i64 %7
  %9 = load i32, i32* %8, align 4
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = shl i64 %7, 5
  %13 = getelementptr inbounds i16, i16* %2, i64 %12
  %14 = bitcast i8* %11 to i16*
  %15 = bitcast i16* %13 to i32*
  %16 = getelementptr inbounds i8, i8* %11, i64 -2
  %17 = bitcast i8* %16 to i16*
  %18 = load i16, i16* %17, align 2
  %19 = load i32, i32* %15, align 4
  %20 = trunc i32 %19 to i16
  %21 = add i16 %18, %20
  store i16 %21, i16* %14, align 2
  %22 = getelementptr inbounds i16, i16* %13, i64 2
  %23 = bitcast i16* %22 to i32*
  %24 = load i32, i32* %23, align 4
  %25 = trunc i32 %24 to i16
  %26 = add i16 %21, %25
  %27 = getelementptr inbounds i8, i8* %11, i64 2
  %28 = bitcast i8* %27 to i16*
  store i16 %26, i16* %28, align 2
  %29 = getelementptr inbounds i16, i16* %13, i64 4
  %30 = bitcast i16* %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = trunc i32 %31 to i16
  %33 = add i16 %26, %32
  %34 = getelementptr inbounds i8, i8* %11, i64 4
  %35 = bitcast i8* %34 to i16*
  store i16 %33, i16* %35, align 2
  %36 = getelementptr inbounds i16, i16* %13, i64 6
  %37 = bitcast i16* %36 to i32*
  %38 = load i32, i32* %37, align 4
  %39 = trunc i32 %38 to i16
  %40 = add i16 %33, %39
  %41 = getelementptr inbounds i8, i8* %11, i64 6
  %42 = bitcast i8* %41 to i16*
  store i16 %40, i16* %42, align 2
  %43 = getelementptr inbounds i16, i16* %14, i64 %5
  %44 = getelementptr inbounds i16, i16* %13, i64 8
  %45 = bitcast i16* %44 to i32*
  %46 = getelementptr inbounds i16, i16* %43, i64 -1
  %47 = load i16, i16* %46, align 2
  %48 = load i32, i32* %45, align 4
  %49 = trunc i32 %48 to i16
  %50 = add i16 %47, %49
  store i16 %50, i16* %43, align 2
  %51 = getelementptr inbounds i16, i16* %13, i64 10
  %52 = bitcast i16* %51 to i32*
  %53 = load i32, i32* %52, align 4
  %54 = trunc i32 %53 to i16
  %55 = add i16 %50, %54
  %56 = getelementptr inbounds i16, i16* %43, i64 1
  store i16 %55, i16* %56, align 2
  %57 = getelementptr inbounds i16, i16* %13, i64 12
  %58 = bitcast i16* %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = trunc i32 %59 to i16
  %61 = add i16 %55, %60
  %62 = getelementptr inbounds i16, i16* %43, i64 2
  store i16 %61, i16* %62, align 2
  %63 = getelementptr inbounds i16, i16* %13, i64 14
  %64 = bitcast i16* %63 to i32*
  %65 = load i32, i32* %64, align 4
  %66 = trunc i32 %65 to i16
  %67 = add i16 %61, %66
  %68 = getelementptr inbounds i16, i16* %43, i64 3
  store i16 %67, i16* %68, align 2
  %69 = getelementptr inbounds i16, i16* %43, i64 %5
  %70 = getelementptr inbounds i16, i16* %13, i64 16
  %71 = bitcast i16* %70 to i32*
  %72 = getelementptr inbounds i16, i16* %69, i64 -1
  %73 = load i16, i16* %72, align 2
  %74 = load i32, i32* %71, align 4
  %75 = trunc i32 %74 to i16
  %76 = add i16 %73, %75
  store i16 %76, i16* %69, align 2
  %77 = getelementptr inbounds i16, i16* %13, i64 18
  %78 = bitcast i16* %77 to i32*
  %79 = load i32, i32* %78, align 4
  %80 = trunc i32 %79 to i16
  %81 = add i16 %76, %80
  %82 = getelementptr inbounds i16, i16* %69, i64 1
  store i16 %81, i16* %82, align 2
  %83 = getelementptr inbounds i16, i16* %13, i64 20
  %84 = bitcast i16* %83 to i32*
  %85 = load i32, i32* %84, align 4
  %86 = trunc i32 %85 to i16
  %87 = add i16 %81, %86
  %88 = getelementptr inbounds i16, i16* %69, i64 2
  store i16 %87, i16* %88, align 2
  %89 = getelementptr inbounds i16, i16* %13, i64 22
  %90 = bitcast i16* %89 to i32*
  %91 = load i32, i32* %90, align 4
  %92 = trunc i32 %91 to i16
  %93 = add i16 %87, %92
  %94 = getelementptr inbounds i16, i16* %69, i64 3
  store i16 %93, i16* %94, align 2
  %95 = getelementptr inbounds i16, i16* %69, i64 %5
  %96 = getelementptr inbounds i16, i16* %13, i64 24
  %97 = bitcast i16* %96 to i32*
  %98 = getelementptr inbounds i16, i16* %95, i64 -1
  %99 = load i16, i16* %98, align 2
  %100 = load i32, i32* %97, align 4
  %101 = trunc i32 %100 to i16
  %102 = add i16 %99, %101
  store i16 %102, i16* %95, align 2
  %103 = getelementptr inbounds i16, i16* %13, i64 26
  %104 = bitcast i16* %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = trunc i32 %105 to i16
  %107 = add i16 %102, %106
  %108 = getelementptr inbounds i16, i16* %95, i64 1
  store i16 %107, i16* %108, align 2
  %109 = getelementptr inbounds i16, i16* %13, i64 28
  %110 = bitcast i16* %109 to i32*
  %111 = load i32, i32* %110, align 4
  %112 = trunc i32 %111 to i16
  %113 = add i16 %107, %112
  %114 = getelementptr inbounds i16, i16* %95, i64 2
  store i16 %113, i16* %114, align 2
  %115 = getelementptr inbounds i16, i16* %13, i64 30
  %116 = bitcast i16* %115 to i32*
  %117 = load i32, i32* %116, align 4
  %118 = trunc i32 %117 to i16
  %119 = add i16 %113, %118
  %120 = getelementptr inbounds i16, i16* %95, i64 3
  store i16 %119, i16* %120, align 2
  %121 = bitcast i16* %13 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %121, i8 0, i64 64, i1 false) #8
  %122 = add nuw nsw i64 %7, 1
  %123 = icmp eq i64 %122, 16
  br i1 %123, label %124, label %6

124:                                              ; preds = %6
  ret void
}

declare void @av_log(i8*, i32, i8*, ...) local_unnamed_addr #4

; Function Attrs: noreturn nounwind
declare void @abort() local_unnamed_addr #5

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_8_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = trunc i64 %2 to i32
  %5 = shl i64 %2, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = bitcast i8* %8 to i32*
  %10 = load i32, i32* %9, align 4
  %11 = bitcast i8* %0 to i32*
  store i32 %10, i32* %11, align 4
  %12 = getelementptr inbounds i8, i8* %0, i64 %6
  %13 = bitcast i8* %12 to i32*
  store i32 %10, i32* %13, align 4
  %14 = shl nsw i32 %4, 1
  %15 = sext i32 %14 to i64
  %16 = getelementptr inbounds i8, i8* %0, i64 %15
  %17 = bitcast i8* %16 to i32*
  store i32 %10, i32* %17, align 4
  %18 = mul i64 %2, 12884901888
  %19 = ashr exact i64 %18, 32
  %20 = getelementptr inbounds i8, i8* %0, i64 %19
  %21 = bitcast i8* %20 to i32*
  store i32 %10, i32* %21, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_8_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = trunc i64 %2 to i32
  %5 = getelementptr inbounds i8, i8* %0, i64 -1
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = mul nuw i32 %7, 16843009
  %9 = bitcast i8* %0 to i32*
  store i32 %8, i32* %9, align 4
  %10 = shl i64 %2, 32
  %11 = add i64 %10, -4294967296
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = mul nuw i32 %15, 16843009
  %17 = ashr exact i64 %10, 32
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = bitcast i8* %18 to i32*
  store i32 %16, i32* %19, align 4
  %20 = shl nsw i32 %4, 1
  %21 = add nsw i32 %20, -1
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = mul nuw i32 %25, 16843009
  %27 = sext i32 %20 to i64
  %28 = getelementptr inbounds i8, i8* %0, i64 %27
  %29 = bitcast i8* %28 to i32*
  store i32 %26, i32* %29, align 4
  %30 = mul nsw i32 %4, 3
  %31 = add nsw i32 %30, -1
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds i8, i8* %0, i64 %32
  %34 = load i8, i8* %33, align 1
  %35 = zext i8 %34 to i32
  %36 = mul nuw i32 %35, 16843009
  %37 = sext i32 %30 to i64
  %38 = getelementptr inbounds i8, i8* %0, i64 %37
  %39 = bitcast i8* %38 to i32*
  store i32 %36, i32* %39, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_dc_8_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = trunc i64 %2 to i32
  %5 = shl i64 %2, 32
  %6 = sub i64 0, %5
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = sub i64 4294967296, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = sub i64 8589934592, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = sub i64 12884901888, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = getelementptr inbounds i8, i8* %0, i64 -1
  %27 = load i8, i8* %26, align 1
  %28 = zext i8 %27 to i32
  %29 = add i64 %5, -4294967296
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = shl nsw i32 %4, 1
  %35 = add nsw i32 %34, -1
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = load i8, i8* %37, align 1
  %39 = zext i8 %38 to i32
  %40 = mul nsw i32 %4, 3
  %41 = add nsw i32 %40, -1
  %42 = sext i32 %41 to i64
  %43 = getelementptr inbounds i8, i8* %0, i64 %42
  %44 = load i8, i8* %43, align 1
  %45 = zext i8 %44 to i32
  %46 = add nuw nsw i32 %10, 4
  %47 = add nuw nsw i32 %46, %15
  %48 = add nuw nsw i32 %47, %20
  %49 = add nuw nsw i32 %48, %25
  %50 = add nuw nsw i32 %49, %28
  %51 = add nuw nsw i32 %50, %33
  %52 = add nuw nsw i32 %51, %39
  %53 = add nuw nsw i32 %52, %45
  %54 = ashr i32 %53, 3
  %55 = mul i32 %54, 16843009
  %56 = bitcast i8* %0 to i32*
  store i32 %55, i32* %56, align 4
  %57 = ashr exact i64 %5, 32
  %58 = getelementptr inbounds i8, i8* %0, i64 %57
  %59 = bitcast i8* %58 to i32*
  store i32 %55, i32* %59, align 4
  %60 = sext i32 %34 to i64
  %61 = getelementptr inbounds i8, i8* %0, i64 %60
  %62 = bitcast i8* %61 to i32*
  store i32 %55, i32* %62, align 4
  %63 = sext i32 %40 to i64
  %64 = getelementptr inbounds i8, i8* %0, i64 %63
  %65 = bitcast i8* %64 to i32*
  store i32 %55, i32* %65, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_down_left_8_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = trunc i64 %2 to i32
  %5 = shl i64 %2, 32
  %6 = sub i64 0, %5
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = sub i64 4294967296, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = sub i64 8589934592, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = sub i64 12884901888, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = load i8, i8* %1, align 1
  %27 = zext i8 %26 to i32
  %28 = getelementptr inbounds i8, i8* %1, i64 1
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = getelementptr inbounds i8, i8* %1, i64 2
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = getelementptr inbounds i8, i8* %1, i64 3
  %35 = load i8, i8* %34, align 1
  %36 = zext i8 %35 to i32
  %37 = shl nuw nsw i32 %15, 1
  %38 = add nuw nsw i32 %20, 2
  %39 = add nuw nsw i32 %38, %10
  %40 = add nuw nsw i32 %39, %37
  %41 = lshr i32 %40, 2
  %42 = trunc i32 %41 to i8
  store i8 %42, i8* %0, align 1
  %43 = shl nuw nsw i32 %20, 1
  %44 = add nuw nsw i32 %25, 2
  %45 = add nuw nsw i32 %44, %15
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = trunc i32 %47 to i8
  %49 = ashr exact i64 %5, 32
  %50 = getelementptr inbounds i8, i8* %0, i64 %49
  store i8 %48, i8* %50, align 1
  %51 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %48, i8* %51, align 1
  %52 = shl nuw nsw i32 %25, 1
  %53 = add nuw nsw i32 %38, %27
  %54 = add nuw nsw i32 %53, %52
  %55 = lshr i32 %54, 2
  %56 = trunc i32 %55 to i8
  %57 = shl nsw i32 %4, 1
  %58 = sext i32 %57 to i64
  %59 = getelementptr inbounds i8, i8* %0, i64 %58
  store i8 %56, i8* %59, align 1
  %60 = add i64 %5, 4294967296
  %61 = ashr exact i64 %60, 32
  %62 = getelementptr inbounds i8, i8* %0, i64 %61
  store i8 %56, i8* %62, align 1
  %63 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %56, i8* %63, align 1
  %64 = shl nuw nsw i32 %27, 1
  %65 = add nuw nsw i32 %44, %30
  %66 = add nuw nsw i32 %65, %64
  %67 = lshr i32 %66, 2
  %68 = trunc i32 %67 to i8
  %69 = mul nsw i32 %4, 3
  %70 = sext i32 %69 to i64
  %71 = getelementptr inbounds i8, i8* %0, i64 %70
  store i8 %68, i8* %71, align 1
  %72 = or i32 %57, 1
  %73 = sext i32 %72 to i64
  %74 = getelementptr inbounds i8, i8* %0, i64 %73
  store i8 %68, i8* %74, align 1
  %75 = add i64 %5, 8589934592
  %76 = ashr exact i64 %75, 32
  %77 = getelementptr inbounds i8, i8* %0, i64 %76
  store i8 %68, i8* %77, align 1
  %78 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %68, i8* %78, align 1
  %79 = shl nuw nsw i32 %30, 1
  %80 = add nuw nsw i32 %27, 2
  %81 = add nuw nsw i32 %80, %33
  %82 = add nuw nsw i32 %81, %79
  %83 = lshr i32 %82, 2
  %84 = trunc i32 %83 to i8
  %85 = add nsw i32 %69, 1
  %86 = sext i32 %85 to i64
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  store i8 %84, i8* %87, align 1
  %88 = add nsw i32 %57, 2
  %89 = sext i32 %88 to i64
  %90 = getelementptr inbounds i8, i8* %0, i64 %89
  store i8 %84, i8* %90, align 1
  %91 = add i64 %5, 12884901888
  %92 = ashr exact i64 %91, 32
  %93 = getelementptr inbounds i8, i8* %0, i64 %92
  store i8 %84, i8* %93, align 1
  %94 = shl nuw nsw i32 %33, 1
  %95 = add nuw nsw i32 %30, 2
  %96 = add nuw nsw i32 %95, %36
  %97 = add nuw nsw i32 %96, %94
  %98 = lshr i32 %97, 2
  %99 = trunc i32 %98 to i8
  %100 = add nsw i32 %69, 2
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds i8, i8* %0, i64 %101
  store i8 %99, i8* %102, align 1
  %103 = add nsw i32 %57, 3
  %104 = sext i32 %103 to i64
  %105 = getelementptr inbounds i8, i8* %0, i64 %104
  store i8 %99, i8* %105, align 1
  %106 = mul nuw nsw i32 %36, 3
  %107 = add nuw nsw i32 %33, 2
  %108 = add nuw nsw i32 %107, %106
  %109 = lshr i32 %108, 2
  %110 = trunc i32 %109 to i8
  %111 = add nsw i32 %69, 3
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds i8, i8* %0, i64 %112
  store i8 %110, i8* %113, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_down_right_8_c(i8*, i8* nocapture readnone, i64) #1 {
  %4 = trunc i64 %2 to i32
  %5 = shl i64 %2, 32
  %6 = ashr exact i64 %5, 32
  %7 = xor i64 %6, -1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = sub i64 0, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = sub i64 4294967296, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = sub i64 8589934592, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = sub i64 12884901888, %5
  %27 = ashr exact i64 %26, 32
  %28 = getelementptr inbounds i8, i8* %0, i64 %27
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = getelementptr inbounds i8, i8* %0, i64 -1
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = add i64 %5, -4294967296
  %35 = ashr exact i64 %34, 32
  %36 = getelementptr inbounds i8, i8* %0, i64 %35
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i32
  %39 = shl nsw i32 %4, 1
  %40 = add nsw i32 %39, -1
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds i8, i8* %0, i64 %41
  %43 = load i8, i8* %42, align 1
  %44 = zext i8 %43 to i32
  %45 = mul nsw i32 %4, 3
  %46 = add nsw i32 %45, -1
  %47 = sext i32 %46 to i64
  %48 = getelementptr inbounds i8, i8* %0, i64 %47
  %49 = load i8, i8* %48, align 1
  %50 = zext i8 %49 to i32
  %51 = shl nuw nsw i32 %44, 1
  %52 = add nuw nsw i32 %38, 2
  %53 = add nuw nsw i32 %52, %50
  %54 = add nuw nsw i32 %53, %51
  %55 = lshr i32 %54, 2
  %56 = trunc i32 %55 to i8
  %57 = sext i32 %45 to i64
  %58 = getelementptr inbounds i8, i8* %0, i64 %57
  store i8 %56, i8* %58, align 1
  %59 = shl nuw nsw i32 %38, 1
  %60 = add nuw nsw i32 %33, 2
  %61 = add nuw nsw i32 %60, %44
  %62 = add nuw nsw i32 %61, %59
  %63 = lshr i32 %62, 2
  %64 = trunc i32 %63 to i8
  %65 = add nsw i32 %45, 1
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds i8, i8* %0, i64 %66
  store i8 %64, i8* %67, align 1
  %68 = sext i32 %39 to i64
  %69 = getelementptr inbounds i8, i8* %0, i64 %68
  store i8 %64, i8* %69, align 1
  %70 = shl nuw nsw i32 %33, 1
  %71 = add nuw nsw i32 %10, 2
  %72 = add nuw nsw i32 %71, %38
  %73 = add nuw nsw i32 %72, %70
  %74 = lshr i32 %73, 2
  %75 = trunc i32 %74 to i8
  %76 = add nsw i32 %45, 2
  %77 = sext i32 %76 to i64
  %78 = getelementptr inbounds i8, i8* %0, i64 %77
  store i8 %75, i8* %78, align 1
  %79 = or i32 %39, 1
  %80 = sext i32 %79 to i64
  %81 = getelementptr inbounds i8, i8* %0, i64 %80
  store i8 %75, i8* %81, align 1
  %82 = getelementptr inbounds i8, i8* %0, i64 %6
  store i8 %75, i8* %82, align 1
  %83 = shl nuw nsw i32 %10, 1
  %84 = add nuw nsw i32 %15, 2
  %85 = add nuw nsw i32 %84, %83
  %86 = add nuw nsw i32 %85, %33
  %87 = lshr i32 %86, 2
  %88 = trunc i32 %87 to i8
  %89 = add nsw i32 %45, 3
  %90 = sext i32 %89 to i64
  %91 = getelementptr inbounds i8, i8* %0, i64 %90
  store i8 %88, i8* %91, align 1
  %92 = add nsw i32 %39, 2
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds i8, i8* %0, i64 %93
  store i8 %88, i8* %94, align 1
  %95 = add i64 %5, 4294967296
  %96 = ashr exact i64 %95, 32
  %97 = getelementptr inbounds i8, i8* %0, i64 %96
  store i8 %88, i8* %97, align 1
  store i8 %88, i8* %0, align 1
  %98 = shl nuw nsw i32 %15, 1
  %99 = add nuw nsw i32 %71, %98
  %100 = add nuw nsw i32 %99, %20
  %101 = lshr i32 %100, 2
  %102 = trunc i32 %101 to i8
  %103 = add nsw i32 %39, 3
  %104 = sext i32 %103 to i64
  %105 = getelementptr inbounds i8, i8* %0, i64 %104
  store i8 %102, i8* %105, align 1
  %106 = add i64 %5, 8589934592
  %107 = ashr exact i64 %106, 32
  %108 = getelementptr inbounds i8, i8* %0, i64 %107
  store i8 %102, i8* %108, align 1
  %109 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %102, i8* %109, align 1
  %110 = shl nuw nsw i32 %20, 1
  %111 = add nuw nsw i32 %84, %110
  %112 = add nuw nsw i32 %111, %25
  %113 = lshr i32 %112, 2
  %114 = trunc i32 %113 to i8
  %115 = add i64 %5, 12884901888
  %116 = ashr exact i64 %115, 32
  %117 = getelementptr inbounds i8, i8* %0, i64 %116
  store i8 %114, i8* %117, align 1
  %118 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %114, i8* %118, align 1
  %119 = shl nuw nsw i32 %25, 1
  %120 = add nuw nsw i32 %20, 2
  %121 = add nuw nsw i32 %120, %119
  %122 = add nuw nsw i32 %121, %30
  %123 = lshr i32 %122, 2
  %124 = trunc i32 %123 to i8
  %125 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %124, i8* %125, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_right_8_c(i8*, i8* nocapture readnone, i64) #1 {
  %4 = trunc i64 %2 to i32
  %5 = shl i64 %2, 32
  %6 = ashr exact i64 %5, 32
  %7 = xor i64 %6, -1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = sub i64 0, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = sub i64 4294967296, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = sub i64 8589934592, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = sub i64 12884901888, %5
  %27 = ashr exact i64 %26, 32
  %28 = getelementptr inbounds i8, i8* %0, i64 %27
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = getelementptr inbounds i8, i8* %0, i64 -1
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = add i64 %5, -4294967296
  %35 = ashr exact i64 %34, 32
  %36 = getelementptr inbounds i8, i8* %0, i64 %35
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i32
  %39 = shl nsw i32 %4, 1
  %40 = add nsw i32 %39, -1
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds i8, i8* %0, i64 %41
  %43 = load i8, i8* %42, align 1
  %44 = zext i8 %43 to i32
  %45 = mul nsw i32 %4, 3
  %46 = add nuw nsw i32 %15, 1
  %47 = add nuw nsw i32 %46, %10
  %48 = lshr i32 %47, 1
  %49 = trunc i32 %48 to i8
  %50 = or i32 %39, 1
  %51 = sext i32 %50 to i64
  %52 = getelementptr inbounds i8, i8* %0, i64 %51
  store i8 %49, i8* %52, align 1
  store i8 %49, i8* %0, align 1
  %53 = add nuw nsw i32 %46, %20
  %54 = lshr i32 %53, 1
  %55 = trunc i32 %54 to i8
  %56 = add nsw i32 %39, 2
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i8, i8* %0, i64 %57
  store i8 %55, i8* %58, align 1
  %59 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %55, i8* %59, align 1
  %60 = add nuw nsw i32 %20, 1
  %61 = add nuw nsw i32 %60, %25
  %62 = lshr i32 %61, 1
  %63 = trunc i32 %62 to i8
  %64 = add nsw i32 %39, 3
  %65 = sext i32 %64 to i64
  %66 = getelementptr inbounds i8, i8* %0, i64 %65
  store i8 %63, i8* %66, align 1
  %67 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %63, i8* %67, align 1
  %68 = add nuw nsw i32 %25, 1
  %69 = add nuw nsw i32 %68, %30
  %70 = lshr i32 %69, 1
  %71 = trunc i32 %70 to i8
  %72 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %71, i8* %72, align 1
  %73 = shl nuw nsw i32 %10, 1
  %74 = add nuw nsw i32 %15, 2
  %75 = add nuw nsw i32 %74, %73
  %76 = add nuw nsw i32 %75, %33
  %77 = lshr i32 %76, 2
  %78 = trunc i32 %77 to i8
  %79 = add nsw i32 %45, 1
  %80 = sext i32 %79 to i64
  %81 = getelementptr inbounds i8, i8* %0, i64 %80
  store i8 %78, i8* %81, align 1
  %82 = getelementptr inbounds i8, i8* %0, i64 %6
  store i8 %78, i8* %82, align 1
  %83 = shl nuw nsw i32 %15, 1
  %84 = add nuw nsw i32 %10, 2
  %85 = add nuw nsw i32 %84, %83
  %86 = add nuw nsw i32 %85, %20
  %87 = lshr i32 %86, 2
  %88 = trunc i32 %87 to i8
  %89 = add nsw i32 %45, 2
  %90 = sext i32 %89 to i64
  %91 = getelementptr inbounds i8, i8* %0, i64 %90
  store i8 %88, i8* %91, align 1
  %92 = add i64 %5, 4294967296
  %93 = ashr exact i64 %92, 32
  %94 = getelementptr inbounds i8, i8* %0, i64 %93
  store i8 %88, i8* %94, align 1
  %95 = shl nuw nsw i32 %20, 1
  %96 = add nuw nsw i32 %74, %95
  %97 = add nuw nsw i32 %96, %25
  %98 = lshr i32 %97, 2
  %99 = trunc i32 %98 to i8
  %100 = add nsw i32 %45, 3
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds i8, i8* %0, i64 %101
  store i8 %99, i8* %102, align 1
  %103 = add i64 %5, 8589934592
  %104 = ashr exact i64 %103, 32
  %105 = getelementptr inbounds i8, i8* %0, i64 %104
  store i8 %99, i8* %105, align 1
  %106 = shl nuw nsw i32 %25, 1
  %107 = add nuw nsw i32 %20, 2
  %108 = add nuw nsw i32 %107, %106
  %109 = add nuw nsw i32 %108, %30
  %110 = lshr i32 %109, 2
  %111 = trunc i32 %110 to i8
  %112 = add i64 %5, 12884901888
  %113 = ashr exact i64 %112, 32
  %114 = getelementptr inbounds i8, i8* %0, i64 %113
  store i8 %111, i8* %114, align 1
  %115 = shl nuw nsw i32 %33, 1
  %116 = add nuw nsw i32 %84, %115
  %117 = add nuw nsw i32 %116, %38
  %118 = lshr i32 %117, 2
  %119 = trunc i32 %118 to i8
  %120 = sext i32 %39 to i64
  %121 = getelementptr inbounds i8, i8* %0, i64 %120
  store i8 %119, i8* %121, align 1
  %122 = shl nuw nsw i32 %38, 1
  %123 = add nuw nsw i32 %33, 2
  %124 = add nuw nsw i32 %123, %122
  %125 = add nuw nsw i32 %124, %44
  %126 = lshr i32 %125, 2
  %127 = trunc i32 %126 to i8
  %128 = sext i32 %45 to i64
  %129 = getelementptr inbounds i8, i8* %0, i64 %128
  store i8 %127, i8* %129, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_down_8_c(i8*, i8* nocapture readnone, i64) #1 {
  %4 = trunc i64 %2 to i32
  %5 = shl i64 %2, 32
  %6 = ashr exact i64 %5, 32
  %7 = xor i64 %6, -1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = sub i64 0, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = sub i64 4294967296, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = sub i64 8589934592, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = getelementptr inbounds i8, i8* %0, i64 -1
  %27 = load i8, i8* %26, align 1
  %28 = zext i8 %27 to i32
  %29 = add i64 %5, -4294967296
  %30 = ashr exact i64 %29, 32
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = shl nsw i32 %4, 1
  %35 = add nsw i32 %34, -1
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = load i8, i8* %37, align 1
  %39 = zext i8 %38 to i32
  %40 = mul nsw i32 %4, 3
  %41 = add nsw i32 %40, -1
  %42 = sext i32 %41 to i64
  %43 = getelementptr inbounds i8, i8* %0, i64 %42
  %44 = load i8, i8* %43, align 1
  %45 = zext i8 %44 to i32
  %46 = add nuw nsw i32 %28, 1
  %47 = add nuw nsw i32 %46, %10
  %48 = lshr i32 %47, 1
  %49 = trunc i32 %48 to i8
  %50 = add i64 %5, 8589934592
  %51 = ashr exact i64 %50, 32
  %52 = getelementptr inbounds i8, i8* %0, i64 %51
  store i8 %49, i8* %52, align 1
  store i8 %49, i8* %0, align 1
  %53 = shl nuw nsw i32 %10, 1
  %54 = add nuw nsw i32 %15, 2
  %55 = add nuw nsw i32 %54, %53
  %56 = add nuw nsw i32 %55, %28
  %57 = lshr i32 %56, 2
  %58 = trunc i32 %57 to i8
  %59 = add i64 %5, 12884901888
  %60 = ashr exact i64 %59, 32
  %61 = getelementptr inbounds i8, i8* %0, i64 %60
  store i8 %58, i8* %61, align 1
  %62 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %58, i8* %62, align 1
  %63 = shl nuw nsw i32 %15, 1
  %64 = add nuw nsw i32 %10, 2
  %65 = add nuw nsw i32 %64, %63
  %66 = add nuw nsw i32 %65, %20
  %67 = lshr i32 %66, 2
  %68 = trunc i32 %67 to i8
  %69 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %68, i8* %69, align 1
  %70 = shl nuw nsw i32 %20, 1
  %71 = add nuw nsw i32 %54, %70
  %72 = add nuw nsw i32 %71, %25
  %73 = lshr i32 %72, 2
  %74 = trunc i32 %73 to i8
  %75 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %74, i8* %75, align 1
  %76 = add nuw nsw i32 %46, %33
  %77 = lshr i32 %76, 1
  %78 = trunc i32 %77 to i8
  %79 = add nsw i32 %34, 2
  %80 = sext i32 %79 to i64
  %81 = getelementptr inbounds i8, i8* %0, i64 %80
  store i8 %78, i8* %81, align 1
  %82 = getelementptr inbounds i8, i8* %0, i64 %6
  store i8 %78, i8* %82, align 1
  %83 = shl nuw nsw i32 %28, 1
  %84 = add nuw nsw i32 %64, %83
  %85 = add nuw nsw i32 %84, %33
  %86 = lshr i32 %85, 2
  %87 = trunc i32 %86 to i8
  %88 = add nsw i32 %34, 3
  %89 = sext i32 %88 to i64
  %90 = getelementptr inbounds i8, i8* %0, i64 %89
  store i8 %87, i8* %90, align 1
  %91 = add i64 %5, 4294967296
  %92 = ashr exact i64 %91, 32
  %93 = getelementptr inbounds i8, i8* %0, i64 %92
  store i8 %87, i8* %93, align 1
  %94 = add nuw nsw i32 %33, 1
  %95 = add nuw nsw i32 %94, %39
  %96 = lshr i32 %95, 1
  %97 = trunc i32 %96 to i8
  %98 = add nsw i32 %40, 2
  %99 = sext i32 %98 to i64
  %100 = getelementptr inbounds i8, i8* %0, i64 %99
  store i8 %97, i8* %100, align 1
  %101 = sext i32 %34 to i64
  %102 = getelementptr inbounds i8, i8* %0, i64 %101
  store i8 %97, i8* %102, align 1
  %103 = shl nuw nsw i32 %33, 1
  %104 = add nuw nsw i32 %28, 2
  %105 = add nuw nsw i32 %104, %103
  %106 = add nuw nsw i32 %105, %39
  %107 = lshr i32 %106, 2
  %108 = trunc i32 %107 to i8
  %109 = add nsw i32 %40, 3
  %110 = sext i32 %109 to i64
  %111 = getelementptr inbounds i8, i8* %0, i64 %110
  store i8 %108, i8* %111, align 1
  %112 = or i32 %34, 1
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds i8, i8* %0, i64 %113
  store i8 %108, i8* %114, align 1
  %115 = add nuw nsw i32 %39, 1
  %116 = add nuw nsw i32 %115, %45
  %117 = lshr i32 %116, 1
  %118 = trunc i32 %117 to i8
  %119 = sext i32 %40 to i64
  %120 = getelementptr inbounds i8, i8* %0, i64 %119
  store i8 %118, i8* %120, align 1
  %121 = shl nuw nsw i32 %39, 1
  %122 = add nuw nsw i32 %33, 2
  %123 = add nuw nsw i32 %122, %121
  %124 = add nuw nsw i32 %123, %45
  %125 = lshr i32 %124, 2
  %126 = trunc i32 %125 to i8
  %127 = add nsw i32 %40, 1
  %128 = sext i32 %127 to i64
  %129 = getelementptr inbounds i8, i8* %0, i64 %128
  store i8 %126, i8* %129, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_vertical_left_8_c(i8* nocapture, i8* nocapture readonly, i64) #1 {
  %4 = trunc i64 %2 to i32
  %5 = shl i64 %2, 32
  %6 = sub i64 0, %5
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = sub i64 4294967296, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = sub i64 8589934592, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = sub i64 12884901888, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = load i8, i8* %1, align 1
  %27 = zext i8 %26 to i32
  %28 = getelementptr inbounds i8, i8* %1, i64 1
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = getelementptr inbounds i8, i8* %1, i64 2
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = add nuw nsw i32 %15, 1
  %35 = add nuw nsw i32 %34, %10
  %36 = lshr i32 %35, 1
  %37 = trunc i32 %36 to i8
  store i8 %37, i8* %0, align 1
  %38 = add nuw nsw i32 %34, %20
  %39 = lshr i32 %38, 1
  %40 = trunc i32 %39 to i8
  %41 = shl nsw i32 %4, 1
  %42 = sext i32 %41 to i64
  %43 = getelementptr inbounds i8, i8* %0, i64 %42
  store i8 %40, i8* %43, align 1
  %44 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %40, i8* %44, align 1
  %45 = add nuw nsw i32 %20, 1
  %46 = add nuw nsw i32 %45, %25
  %47 = lshr i32 %46, 1
  %48 = trunc i32 %47 to i8
  %49 = or i32 %41, 1
  %50 = sext i32 %49 to i64
  %51 = getelementptr inbounds i8, i8* %0, i64 %50
  store i8 %48, i8* %51, align 1
  %52 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %48, i8* %52, align 1
  %53 = add nuw nsw i32 %25, 1
  %54 = add nuw nsw i32 %53, %27
  %55 = lshr i32 %54, 1
  %56 = trunc i32 %55 to i8
  %57 = add nsw i32 %41, 2
  %58 = sext i32 %57 to i64
  %59 = getelementptr inbounds i8, i8* %0, i64 %58
  store i8 %56, i8* %59, align 1
  %60 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %56, i8* %60, align 1
  %61 = add nuw nsw i32 %27, 1
  %62 = add nuw nsw i32 %61, %30
  %63 = lshr i32 %62, 1
  %64 = trunc i32 %63 to i8
  %65 = add nsw i32 %41, 3
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds i8, i8* %0, i64 %66
  store i8 %64, i8* %67, align 1
  %68 = shl nuw nsw i32 %15, 1
  %69 = add nuw nsw i32 %20, 2
  %70 = add nuw nsw i32 %69, %10
  %71 = add nuw nsw i32 %70, %68
  %72 = lshr i32 %71, 2
  %73 = trunc i32 %72 to i8
  %74 = ashr exact i64 %5, 32
  %75 = getelementptr inbounds i8, i8* %0, i64 %74
  store i8 %73, i8* %75, align 1
  %76 = shl nuw nsw i32 %20, 1
  %77 = add nuw nsw i32 %25, 2
  %78 = add nuw nsw i32 %77, %15
  %79 = add nuw nsw i32 %78, %76
  %80 = lshr i32 %79, 2
  %81 = trunc i32 %80 to i8
  %82 = mul nsw i32 %4, 3
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds i8, i8* %0, i64 %83
  store i8 %81, i8* %84, align 1
  %85 = add i64 %5, 4294967296
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  store i8 %81, i8* %87, align 1
  %88 = shl nuw nsw i32 %25, 1
  %89 = add nuw nsw i32 %69, %88
  %90 = add nuw nsw i32 %89, %27
  %91 = lshr i32 %90, 2
  %92 = trunc i32 %91 to i8
  %93 = add nsw i32 %82, 1
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds i8, i8* %0, i64 %94
  store i8 %92, i8* %95, align 1
  %96 = add i64 %5, 8589934592
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i8, i8* %0, i64 %97
  store i8 %92, i8* %98, align 1
  %99 = shl nuw nsw i32 %27, 1
  %100 = add nuw nsw i32 %77, %99
  %101 = add nuw nsw i32 %100, %30
  %102 = lshr i32 %101, 2
  %103 = trunc i32 %102 to i8
  %104 = add nsw i32 %82, 2
  %105 = sext i32 %104 to i64
  %106 = getelementptr inbounds i8, i8* %0, i64 %105
  store i8 %103, i8* %106, align 1
  %107 = add i64 %5, 12884901888
  %108 = ashr exact i64 %107, 32
  %109 = getelementptr inbounds i8, i8* %0, i64 %108
  store i8 %103, i8* %109, align 1
  %110 = shl nuw nsw i32 %30, 1
  %111 = add nuw nsw i32 %27, 2
  %112 = add nuw nsw i32 %111, %110
  %113 = add nuw nsw i32 %112, %33
  %114 = lshr i32 %113, 2
  %115 = trunc i32 %114 to i8
  %116 = add nsw i32 %82, 3
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds i8, i8* %0, i64 %117
  store i8 %115, i8* %118, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_horizontal_up_8_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = trunc i64 %2 to i32
  %5 = getelementptr inbounds i8, i8* %0, i64 -1
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = shl i64 %2, 32
  %9 = add i64 %8, -4294967296
  %10 = ashr exact i64 %9, 32
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = load i8, i8* %11, align 1
  %13 = zext i8 %12 to i32
  %14 = shl nsw i32 %4, 1
  %15 = add nsw i32 %14, -1
  %16 = sext i32 %15 to i64
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = mul nsw i32 %4, 3
  %21 = add nsw i32 %20, -1
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = add nuw nsw i32 %13, 1
  %27 = add nuw nsw i32 %26, %7
  %28 = lshr i32 %27, 1
  %29 = trunc i32 %28 to i8
  store i8 %29, i8* %0, align 1
  %30 = shl nuw nsw i32 %13, 1
  %31 = add nuw nsw i32 %19, 2
  %32 = add nuw nsw i32 %31, %7
  %33 = add nuw nsw i32 %32, %30
  %34 = lshr i32 %33, 2
  %35 = trunc i32 %34 to i8
  %36 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %35, i8* %36, align 1
  %37 = add nuw nsw i32 %26, %19
  %38 = lshr i32 %37, 1
  %39 = trunc i32 %38 to i8
  %40 = ashr exact i64 %8, 32
  %41 = getelementptr inbounds i8, i8* %0, i64 %40
  store i8 %39, i8* %41, align 1
  %42 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %39, i8* %42, align 1
  %43 = shl nuw nsw i32 %19, 1
  %44 = add nuw nsw i32 %25, 2
  %45 = add nuw nsw i32 %44, %13
  %46 = add nuw nsw i32 %45, %43
  %47 = lshr i32 %46, 2
  %48 = trunc i32 %47 to i8
  %49 = add i64 %8, 4294967296
  %50 = ashr exact i64 %49, 32
  %51 = getelementptr inbounds i8, i8* %0, i64 %50
  store i8 %48, i8* %51, align 1
  %52 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %48, i8* %52, align 1
  %53 = add nuw nsw i32 %19, 1
  %54 = add nuw nsw i32 %53, %25
  %55 = lshr i32 %54, 1
  %56 = trunc i32 %55 to i8
  %57 = sext i32 %14 to i64
  %58 = getelementptr inbounds i8, i8* %0, i64 %57
  store i8 %56, i8* %58, align 1
  %59 = add i64 %8, 8589934592
  %60 = ashr exact i64 %59, 32
  %61 = getelementptr inbounds i8, i8* %0, i64 %60
  store i8 %56, i8* %61, align 1
  %62 = shl nuw nsw i32 %25, 1
  %63 = add nuw nsw i32 %31, %25
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = trunc i32 %65 to i8
  %67 = or i32 %14, 1
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds i8, i8* %0, i64 %68
  store i8 %66, i8* %69, align 1
  %70 = add i64 %8, 12884901888
  %71 = ashr exact i64 %70, 32
  %72 = getelementptr inbounds i8, i8* %0, i64 %71
  store i8 %66, i8* %72, align 1
  %73 = add nsw i32 %20, 3
  %74 = sext i32 %73 to i64
  %75 = getelementptr inbounds i8, i8* %0, i64 %74
  store i8 %24, i8* %75, align 1
  %76 = add nsw i32 %20, 2
  %77 = sext i32 %76 to i64
  %78 = getelementptr inbounds i8, i8* %0, i64 %77
  store i8 %24, i8* %78, align 1
  %79 = add nsw i32 %14, 2
  %80 = sext i32 %79 to i64
  %81 = getelementptr inbounds i8, i8* %0, i64 %80
  store i8 %24, i8* %81, align 1
  %82 = sext i32 %20 to i64
  %83 = getelementptr inbounds i8, i8* %0, i64 %82
  store i8 %24, i8* %83, align 1
  %84 = add nsw i32 %20, 1
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i8, i8* %0, i64 %85
  store i8 %24, i8* %86, align 1
  %87 = add nsw i32 %14, 3
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds i8, i8* %0, i64 %88
  store i8 %24, i8* %89, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_left_dc_8_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = trunc i64 %2 to i32
  %5 = getelementptr inbounds i8, i8* %0, i64 -1
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = shl i64 %2, 32
  %9 = add i64 %8, -4294967296
  %10 = ashr exact i64 %9, 32
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = load i8, i8* %11, align 1
  %13 = zext i8 %12 to i32
  %14 = shl nsw i32 %4, 1
  %15 = add nsw i32 %14, -1
  %16 = sext i32 %15 to i64
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = mul nsw i32 %4, 3
  %21 = add nsw i32 %20, -1
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = add nuw nsw i32 %7, 2
  %27 = add nuw nsw i32 %26, %13
  %28 = add nuw nsw i32 %27, %19
  %29 = add nuw nsw i32 %28, %25
  %30 = lshr i32 %29, 2
  %31 = mul i32 %30, 16843009
  %32 = bitcast i8* %0 to i32*
  store i32 %31, i32* %32, align 4
  %33 = ashr exact i64 %8, 32
  %34 = getelementptr inbounds i8, i8* %0, i64 %33
  %35 = bitcast i8* %34 to i32*
  store i32 %31, i32* %35, align 4
  %36 = sext i32 %14 to i64
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = bitcast i8* %37 to i32*
  store i32 %31, i32* %38, align 4
  %39 = sext i32 %20 to i64
  %40 = getelementptr inbounds i8, i8* %0, i64 %39
  %41 = bitcast i8* %40 to i32*
  store i32 %31, i32* %41, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred4x4_top_dc_8_c(i8* nocapture, i8* nocapture readnone, i64) #1 {
  %4 = trunc i64 %2 to i32
  %5 = shl i64 %2, 32
  %6 = sub i64 0, %5
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = sub i64 4294967296, %5
  %12 = ashr exact i64 %11, 32
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = sub i64 8589934592, %5
  %17 = ashr exact i64 %16, 32
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = sub i64 12884901888, %5
  %22 = ashr exact i64 %21, 32
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = add nuw nsw i32 %10, 2
  %27 = add nuw nsw i32 %26, %15
  %28 = add nuw nsw i32 %27, %20
  %29 = add nuw nsw i32 %28, %25
  %30 = lshr i32 %29, 2
  %31 = mul i32 %30, 16843009
  %32 = bitcast i8* %0 to i32*
  store i32 %31, i32* %32, align 4
  %33 = ashr exact i64 %5, 32
  %34 = getelementptr inbounds i8, i8* %0, i64 %33
  %35 = bitcast i8* %34 to i32*
  store i32 %31, i32* %35, align 4
  %36 = shl nsw i32 %4, 1
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds i8, i8* %0, i64 %37
  %39 = bitcast i8* %38 to i32*
  store i32 %31, i32* %39, align 4
  %40 = mul i64 %2, 12884901888
  %41 = ashr exact i64 %40, 32
  %42 = getelementptr inbounds i8, i8* %0, i64 %41
  %43 = bitcast i8* %42 to i32*
  store i32 %31, i32* %43, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_127_dc_8_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = trunc i64 %2 to i32
  %5 = bitcast i8* %0 to i32*
  store i32 2139062143, i32* %5, align 4
  %6 = shl i64 %2, 32
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = bitcast i8* %8 to i32*
  store i32 2139062143, i32* %9, align 4
  %10 = shl nsw i32 %4, 1
  %11 = sext i32 %10 to i64
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = bitcast i8* %12 to i32*
  store i32 2139062143, i32* %13, align 4
  %14 = mul i64 %2, 12884901888
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i8, i8* %0, i64 %15
  %17 = bitcast i8* %16 to i32*
  store i32 2139062143, i32* %17, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_129_dc_8_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = trunc i64 %2 to i32
  %5 = bitcast i8* %0 to i32*
  store i32 -2122219135, i32* %5, align 4
  %6 = shl i64 %2, 32
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = bitcast i8* %8 to i32*
  store i32 -2122219135, i32* %9, align 4
  %10 = shl nsw i32 %4, 1
  %11 = sext i32 %10 to i64
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = bitcast i8* %12 to i32*
  store i32 -2122219135, i32* %13, align 4
  %14 = mul i64 %2, 12884901888
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i8, i8* %0, i64 %15
  %17 = bitcast i8* %16 to i32*
  store i32 -2122219135, i32* %17, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred4x4_128_dc_8_c(i8* nocapture, i8* nocapture readnone, i64) #2 {
  %4 = trunc i64 %2 to i32
  %5 = bitcast i8* %0 to i32*
  store i32 -2139062144, i32* %5, align 4
  %6 = shl i64 %2, 32
  %7 = ashr exact i64 %6, 32
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = bitcast i8* %8 to i32*
  store i32 -2139062144, i32* %9, align 4
  %10 = shl nsw i32 %4, 1
  %11 = sext i32 %10 to i64
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = bitcast i8* %12 to i32*
  store i32 -2139062144, i32* %13, align 4
  %14 = mul i64 %2, 12884901888
  %15 = ashr exact i64 %14, 32
  %16 = getelementptr inbounds i8, i8* %0, i64 %15
  %17 = bitcast i8* %16 to i32*
  store i32 -2139062144, i32* %17, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_8_c(i8*, i32, i32, i64) #1 {
  %5 = trunc i64 %3 to i32
  %6 = icmp eq i32 %1, 0
  %7 = sub nsw i32 0, %5
  br i1 %6, label %13, label %8

8:                                                ; preds = %4
  %9 = shl i64 %3, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = sext i32 %7 to i64
  br label %16

13:                                               ; preds = %4
  %14 = sext i32 %7 to i64
  %15 = shl i64 %3, 32
  br label %16

16:                                               ; preds = %13, %8
  %17 = phi i64 [ %15, %13 ], [ %9, %8 ]
  %18 = phi i64 [ %14, %13 ], [ %12, %8 ]
  %19 = phi i64 [ %14, %13 ], [ %11, %8 ]
  %20 = getelementptr inbounds i8, i8* %0, i64 %19
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  %23 = getelementptr inbounds i8, i8* %0, i64 %18
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = shl nuw nsw i32 %25, 1
  %27 = sub i64 4294967296, %17
  %28 = ashr exact i64 %27, 32
  %29 = getelementptr inbounds i8, i8* %0, i64 %28
  %30 = load i8, i8* %29, align 1
  %31 = zext i8 %30 to i32
  %32 = add nuw nsw i32 %31, 2
  %33 = add nuw nsw i32 %32, %22
  %34 = add nuw nsw i32 %33, %26
  %35 = lshr i32 %34, 2
  %36 = shl nuw nsw i32 %31, 1
  %37 = sub i64 8589934592, %17
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i32
  %42 = add nuw nsw i32 %41, 2
  %43 = add nuw nsw i32 %42, %25
  %44 = add nuw nsw i32 %43, %36
  %45 = lshr i32 %44, 2
  %46 = shl nuw nsw i32 %41, 1
  %47 = sub i64 12884901888, %17
  %48 = ashr exact i64 %47, 32
  %49 = getelementptr inbounds i8, i8* %0, i64 %48
  %50 = load i8, i8* %49, align 1
  %51 = zext i8 %50 to i32
  %52 = add nuw nsw i32 %32, %46
  %53 = add nuw nsw i32 %52, %51
  %54 = lshr i32 %53, 2
  %55 = shl nuw nsw i32 %51, 1
  %56 = sub i64 17179869184, %17
  %57 = ashr exact i64 %56, 32
  %58 = getelementptr inbounds i8, i8* %0, i64 %57
  %59 = load i8, i8* %58, align 1
  %60 = zext i8 %59 to i32
  %61 = add nuw nsw i32 %42, %55
  %62 = add nuw nsw i32 %61, %60
  %63 = lshr i32 %62, 2
  %64 = shl nuw nsw i32 %60, 1
  %65 = sub i64 21474836480, %17
  %66 = ashr exact i64 %65, 32
  %67 = getelementptr inbounds i8, i8* %0, i64 %66
  %68 = load i8, i8* %67, align 1
  %69 = zext i8 %68 to i32
  %70 = add nuw nsw i32 %51, 2
  %71 = add nuw nsw i32 %70, %64
  %72 = add nuw nsw i32 %71, %69
  %73 = lshr i32 %72, 2
  %74 = shl nuw nsw i32 %69, 1
  %75 = sub i64 25769803776, %17
  %76 = ashr exact i64 %75, 32
  %77 = getelementptr inbounds i8, i8* %0, i64 %76
  %78 = load i8, i8* %77, align 1
  %79 = zext i8 %78 to i32
  %80 = add nuw nsw i32 %60, 2
  %81 = add nuw nsw i32 %80, %74
  %82 = add nuw nsw i32 %81, %79
  %83 = lshr i32 %82, 2
  %84 = shl nuw nsw i32 %79, 1
  %85 = sub i64 30064771072, %17
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = load i8, i8* %87, align 1
  %89 = zext i8 %88 to i32
  %90 = add nuw nsw i32 %69, 2
  %91 = add nuw nsw i32 %90, %84
  %92 = add nuw nsw i32 %91, %89
  %93 = lshr i32 %92, 2
  %94 = icmp eq i32 %2, 0
  br i1 %94, label %101, label %95

95:                                               ; preds = %16
  %96 = sub i64 34359738368, %17
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i8, i8* %0, i64 %97
  %99 = load i8, i8* %98, align 1
  %100 = zext i8 %99 to i32
  br label %101

101:                                              ; preds = %16, %95
  %102 = phi i32 [ %100, %95 ], [ %89, %16 ]
  %103 = shl nuw nsw i32 %89, 1
  %104 = add nuw nsw i32 %79, 2
  %105 = add nuw nsw i32 %104, %103
  %106 = add nuw nsw i32 %105, %102
  %107 = lshr i32 %106, 2
  %108 = trunc i32 %35 to i8
  store i8 %108, i8* %0, align 1
  %109 = trunc i32 %45 to i8
  %110 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %109, i8* %110, align 1
  %111 = trunc i32 %54 to i8
  %112 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %111, i8* %112, align 1
  %113 = trunc i32 %63 to i8
  %114 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %113, i8* %114, align 1
  %115 = trunc i32 %73 to i8
  %116 = getelementptr inbounds i8, i8* %0, i64 4
  store i8 %115, i8* %116, align 1
  %117 = trunc i32 %83 to i8
  %118 = getelementptr inbounds i8, i8* %0, i64 5
  store i8 %117, i8* %118, align 1
  %119 = trunc i32 %93 to i8
  %120 = getelementptr inbounds i8, i8* %0, i64 6
  store i8 %119, i8* %120, align 1
  %121 = trunc i32 %107 to i8
  %122 = getelementptr inbounds i8, i8* %0, i64 7
  store i8 %121, i8* %122, align 1
  %123 = bitcast i8* %0 to i32*
  %124 = load i32, i32* %123, align 4
  %125 = bitcast i8* %116 to i32*
  %126 = load i32, i32* %125, align 4
  %127 = shl i64 %3, 32
  %128 = ashr exact i64 %127, 32
  %129 = getelementptr inbounds i8, i8* %0, i64 %128
  %130 = bitcast i8* %129 to i32*
  store i32 %124, i32* %130, align 4
  %131 = getelementptr inbounds i8, i8* %129, i64 4
  %132 = bitcast i8* %131 to i32*
  store i32 %126, i32* %132, align 4
  %133 = ashr exact i64 %127, 31
  %134 = getelementptr inbounds i8, i8* %0, i64 %133
  %135 = bitcast i8* %134 to i32*
  store i32 %124, i32* %135, align 4
  %136 = getelementptr inbounds i8, i8* %134, i64 4
  %137 = bitcast i8* %136 to i32*
  store i32 %126, i32* %137, align 4
  %138 = mul nsw i64 %128, 3
  %139 = getelementptr inbounds i8, i8* %0, i64 %138
  %140 = bitcast i8* %139 to i32*
  store i32 %124, i32* %140, align 4
  %141 = getelementptr inbounds i8, i8* %139, i64 4
  %142 = bitcast i8* %141 to i32*
  store i32 %126, i32* %142, align 4
  %143 = ashr exact i64 %127, 30
  %144 = getelementptr inbounds i8, i8* %0, i64 %143
  %145 = bitcast i8* %144 to i32*
  store i32 %124, i32* %145, align 4
  %146 = getelementptr inbounds i8, i8* %144, i64 4
  %147 = bitcast i8* %146 to i32*
  store i32 %126, i32* %147, align 4
  %148 = mul nsw i64 %128, 5
  %149 = getelementptr inbounds i8, i8* %0, i64 %148
  %150 = bitcast i8* %149 to i32*
  store i32 %124, i32* %150, align 4
  %151 = getelementptr inbounds i8, i8* %149, i64 4
  %152 = bitcast i8* %151 to i32*
  store i32 %126, i32* %152, align 4
  %153 = mul nsw i64 %128, 6
  %154 = getelementptr inbounds i8, i8* %0, i64 %153
  %155 = bitcast i8* %154 to i32*
  store i32 %124, i32* %155, align 4
  %156 = getelementptr inbounds i8, i8* %154, i64 4
  %157 = bitcast i8* %156 to i32*
  store i32 %126, i32* %157, align 4
  %158 = mul nsw i64 %128, 7
  %159 = getelementptr inbounds i8, i8* %0, i64 %158
  %160 = bitcast i8* %159 to i32*
  store i32 %124, i32* %160, align 4
  %161 = getelementptr inbounds i8, i8* %159, i64 4
  %162 = bitcast i8* %161 to i32*
  store i32 %126, i32* %162, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_8_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = trunc i64 %3 to i32
  %6 = icmp eq i32 %1, 0
  br i1 %6, label %12, label %7

7:                                                ; preds = %4
  %8 = shl i64 %3, 32
  %9 = ashr exact i64 %8, 32
  %10 = xor i64 %9, -1
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  br label %16

12:                                               ; preds = %4
  %13 = getelementptr inbounds i8, i8* %0, i64 -1
  %14 = shl i64 %3, 32
  %15 = ashr exact i64 %14, 32
  br label %16

16:                                               ; preds = %12, %7
  %17 = phi i64 [ %15, %12 ], [ %9, %7 ]
  %18 = phi i64 [ %14, %12 ], [ %8, %7 ]
  %19 = phi i8* [ %13, %12 ], [ %11, %7 ]
  %20 = load i8, i8* %19, align 1
  %21 = zext i8 %20 to i32
  %22 = getelementptr inbounds i8, i8* %0, i64 -1
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = shl nuw nsw i32 %24, 1
  %26 = add i64 %18, -4294967296
  %27 = ashr exact i64 %26, 32
  %28 = getelementptr inbounds i8, i8* %0, i64 %27
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = add nuw nsw i32 %30, 2
  %32 = add nuw nsw i32 %31, %21
  %33 = add nuw nsw i32 %32, %25
  %34 = lshr i32 %33, 2
  %35 = shl nuw nsw i32 %30, 1
  %36 = shl nsw i32 %5, 1
  %37 = add nsw i32 %36, -1
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i32
  %42 = add nuw nsw i32 %41, 2
  %43 = add nuw nsw i32 %42, %24
  %44 = add nuw nsw i32 %43, %35
  %45 = lshr i32 %44, 2
  %46 = shl nuw nsw i32 %41, 1
  %47 = mul nsw i32 %5, 3
  %48 = add nsw i32 %47, -1
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds i8, i8* %0, i64 %49
  %51 = load i8, i8* %50, align 1
  %52 = zext i8 %51 to i32
  %53 = add nuw nsw i32 %31, %46
  %54 = add nuw nsw i32 %53, %52
  %55 = lshr i32 %54, 2
  %56 = shl nuw nsw i32 %52, 1
  %57 = shl nsw i32 %5, 2
  %58 = add nsw i32 %57, -1
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds i8, i8* %0, i64 %59
  %61 = load i8, i8* %60, align 1
  %62 = zext i8 %61 to i32
  %63 = add nuw nsw i32 %42, %56
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = mul nsw i32 %5, 5
  %68 = add nsw i32 %67, -1
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds i8, i8* %0, i64 %69
  %71 = load i8, i8* %70, align 1
  %72 = zext i8 %71 to i32
  %73 = add nuw nsw i32 %52, 2
  %74 = add nuw nsw i32 %73, %66
  %75 = add nuw nsw i32 %74, %72
  %76 = lshr i32 %75, 2
  %77 = shl nuw nsw i32 %72, 1
  %78 = mul nsw i32 %5, 6
  %79 = add nsw i32 %78, -1
  %80 = sext i32 %79 to i64
  %81 = getelementptr inbounds i8, i8* %0, i64 %80
  %82 = load i8, i8* %81, align 1
  %83 = zext i8 %82 to i32
  %84 = add nuw nsw i32 %62, 2
  %85 = add nuw nsw i32 %84, %77
  %86 = add nuw nsw i32 %85, %83
  %87 = lshr i32 %86, 2
  %88 = shl nuw nsw i32 %83, 1
  %89 = mul nsw i32 %5, 7
  %90 = add nsw i32 %89, -1
  %91 = sext i32 %90 to i64
  %92 = getelementptr inbounds i8, i8* %0, i64 %91
  %93 = load i8, i8* %92, align 1
  %94 = zext i8 %93 to i32
  %95 = add nuw nsw i32 %72, 2
  %96 = add nuw nsw i32 %95, %88
  %97 = add nuw nsw i32 %96, %94
  %98 = lshr i32 %97, 2
  %99 = mul nuw nsw i32 %94, 3
  %100 = add nuw nsw i32 %83, 2
  %101 = add nuw nsw i32 %100, %99
  %102 = lshr i32 %101, 2
  %103 = mul i32 %34, 16843009
  %104 = bitcast i8* %0 to i32*
  store i32 %103, i32* %104, align 4
  %105 = getelementptr inbounds i8, i8* %0, i64 4
  %106 = bitcast i8* %105 to i32*
  store i32 %103, i32* %106, align 4
  %107 = mul i32 %45, 16843009
  %108 = getelementptr inbounds i8, i8* %0, i64 %17
  %109 = bitcast i8* %108 to i32*
  store i32 %107, i32* %109, align 4
  %110 = getelementptr inbounds i8, i8* %108, i64 4
  %111 = bitcast i8* %110 to i32*
  store i32 %107, i32* %111, align 4
  %112 = mul i32 %55, 16843009
  %113 = sext i32 %36 to i64
  %114 = getelementptr inbounds i8, i8* %0, i64 %113
  %115 = bitcast i8* %114 to i32*
  store i32 %112, i32* %115, align 4
  %116 = getelementptr inbounds i8, i8* %114, i64 4
  %117 = bitcast i8* %116 to i32*
  store i32 %112, i32* %117, align 4
  %118 = mul i32 %65, 16843009
  %119 = sext i32 %47 to i64
  %120 = getelementptr inbounds i8, i8* %0, i64 %119
  %121 = bitcast i8* %120 to i32*
  store i32 %118, i32* %121, align 4
  %122 = getelementptr inbounds i8, i8* %120, i64 4
  %123 = bitcast i8* %122 to i32*
  store i32 %118, i32* %123, align 4
  %124 = mul i32 %76, 16843009
  %125 = sext i32 %57 to i64
  %126 = getelementptr inbounds i8, i8* %0, i64 %125
  %127 = bitcast i8* %126 to i32*
  store i32 %124, i32* %127, align 4
  %128 = getelementptr inbounds i8, i8* %126, i64 4
  %129 = bitcast i8* %128 to i32*
  store i32 %124, i32* %129, align 4
  %130 = mul i32 %87, 16843009
  %131 = sext i32 %67 to i64
  %132 = getelementptr inbounds i8, i8* %0, i64 %131
  %133 = bitcast i8* %132 to i32*
  store i32 %130, i32* %133, align 4
  %134 = getelementptr inbounds i8, i8* %132, i64 4
  %135 = bitcast i8* %134 to i32*
  store i32 %130, i32* %135, align 4
  %136 = mul i32 %98, 16843009
  %137 = sext i32 %78 to i64
  %138 = getelementptr inbounds i8, i8* %0, i64 %137
  %139 = bitcast i8* %138 to i32*
  store i32 %136, i32* %139, align 4
  %140 = getelementptr inbounds i8, i8* %138, i64 4
  %141 = bitcast i8* %140 to i32*
  store i32 %136, i32* %141, align 4
  %142 = mul i32 %102, 16843009
  %143 = sext i32 %89 to i64
  %144 = getelementptr inbounds i8, i8* %0, i64 %143
  %145 = bitcast i8* %144 to i32*
  store i32 %142, i32* %145, align 4
  %146 = getelementptr inbounds i8, i8* %144, i64 4
  %147 = bitcast i8* %146 to i32*
  store i32 %142, i32* %147, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_dc_8_c(i8*, i32, i32, i64) #1 {
  %5 = trunc i64 %3 to i32
  %6 = icmp ne i32 %1, 0
  br i1 %6, label %7, label %12

7:                                                ; preds = %4
  %8 = shl i64 %3, 32
  %9 = ashr exact i64 %8, 32
  %10 = xor i64 %9, -1
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  br label %17

12:                                               ; preds = %4
  %13 = getelementptr inbounds i8, i8* %0, i64 -1
  %14 = shl i64 %3, 32
  %15 = ashr exact i64 %14, 32
  %16 = xor i64 %15, -1
  br label %17

17:                                               ; preds = %12, %7
  %18 = phi i64 [ %16, %12 ], [ %10, %7 ]
  %19 = phi i64 [ %15, %12 ], [ %9, %7 ]
  %20 = phi i64 [ %14, %12 ], [ %8, %7 ]
  %21 = phi i8* [ %13, %12 ], [ %11, %7 ]
  %22 = load i8, i8* %21, align 1
  %23 = zext i8 %22 to i32
  %24 = getelementptr inbounds i8, i8* %0, i64 -1
  %25 = load i8, i8* %24, align 1
  %26 = zext i8 %25 to i32
  %27 = shl nuw nsw i32 %26, 1
  %28 = add i64 %20, -4294967296
  %29 = ashr exact i64 %28, 32
  %30 = getelementptr inbounds i8, i8* %0, i64 %29
  %31 = load i8, i8* %30, align 1
  %32 = zext i8 %31 to i32
  %33 = add nuw nsw i32 %32, 2
  %34 = add nuw nsw i32 %33, %23
  %35 = add nuw nsw i32 %34, %27
  %36 = lshr i32 %35, 2
  %37 = shl nuw nsw i32 %32, 1
  %38 = shl i32 %5, 1
  %39 = add nsw i32 %38, -1
  %40 = sext i32 %39 to i64
  %41 = getelementptr inbounds i8, i8* %0, i64 %40
  %42 = load i8, i8* %41, align 1
  %43 = zext i8 %42 to i32
  %44 = add nuw nsw i32 %43, 2
  %45 = add nuw nsw i32 %44, %26
  %46 = add nuw nsw i32 %45, %37
  %47 = lshr i32 %46, 2
  %48 = shl nuw nsw i32 %43, 1
  %49 = mul i64 %3, 12884901888
  %50 = add i64 %49, -4294967296
  %51 = ashr exact i64 %50, 32
  %52 = getelementptr inbounds i8, i8* %0, i64 %51
  %53 = load i8, i8* %52, align 1
  %54 = zext i8 %53 to i32
  %55 = add nuw nsw i32 %33, %48
  %56 = add nuw nsw i32 %55, %54
  %57 = lshr i32 %56, 2
  %58 = shl nuw nsw i32 %54, 1
  %59 = shl i32 %5, 2
  %60 = add nsw i32 %59, -1
  %61 = sext i32 %60 to i64
  %62 = getelementptr inbounds i8, i8* %0, i64 %61
  %63 = load i8, i8* %62, align 1
  %64 = zext i8 %63 to i32
  %65 = add nuw nsw i32 %44, %58
  %66 = add nuw nsw i32 %65, %64
  %67 = lshr i32 %66, 2
  %68 = shl nuw nsw i32 %64, 1
  %69 = mul i64 %3, 21474836480
  %70 = add i64 %69, -4294967296
  %71 = ashr exact i64 %70, 32
  %72 = getelementptr inbounds i8, i8* %0, i64 %71
  %73 = load i8, i8* %72, align 1
  %74 = zext i8 %73 to i32
  %75 = add nuw nsw i32 %54, 2
  %76 = add nuw nsw i32 %75, %68
  %77 = add nuw nsw i32 %76, %74
  %78 = lshr i32 %77, 2
  %79 = shl nuw nsw i32 %74, 1
  %80 = mul i64 %3, 25769803776
  %81 = add i64 %80, -4294967296
  %82 = ashr exact i64 %81, 32
  %83 = getelementptr inbounds i8, i8* %0, i64 %82
  %84 = load i8, i8* %83, align 1
  %85 = zext i8 %84 to i32
  %86 = add nuw nsw i32 %64, 2
  %87 = add nuw nsw i32 %86, %79
  %88 = add nuw nsw i32 %87, %85
  %89 = lshr i32 %88, 2
  %90 = shl nuw nsw i32 %85, 1
  %91 = mul i64 %3, 30064771072
  %92 = add i64 %91, -4294967296
  %93 = ashr exact i64 %92, 32
  %94 = getelementptr inbounds i8, i8* %0, i64 %93
  %95 = load i8, i8* %94, align 1
  %96 = zext i8 %95 to i32
  %97 = add nuw nsw i32 %74, 2
  %98 = add nuw nsw i32 %97, %90
  %99 = add nuw nsw i32 %98, %96
  %100 = lshr i32 %99, 2
  %101 = mul nuw nsw i32 %96, 3
  %102 = add nuw nsw i32 %85, 2
  %103 = add nuw nsw i32 %102, %101
  %104 = lshr i32 %103, 2
  %105 = shl i64 %3, 32
  %106 = sub i64 0, %105
  %107 = ashr exact i64 %106, 32
  %108 = select i1 %6, i64 %18, i64 %107
  %109 = getelementptr inbounds i8, i8* %0, i64 %108
  %110 = load i8, i8* %109, align 1
  %111 = zext i8 %110 to i32
  %112 = getelementptr inbounds i8, i8* %0, i64 %107
  %113 = load i8, i8* %112, align 1
  %114 = zext i8 %113 to i32
  %115 = shl nuw nsw i32 %114, 1
  %116 = sub i64 4294967296, %20
  %117 = ashr exact i64 %116, 32
  %118 = getelementptr inbounds i8, i8* %0, i64 %117
  %119 = load i8, i8* %118, align 1
  %120 = zext i8 %119 to i32
  %121 = add nuw nsw i32 %120, 2
  %122 = add nuw nsw i32 %121, %111
  %123 = add nuw nsw i32 %122, %115
  %124 = lshr i32 %123, 2
  %125 = shl nuw nsw i32 %120, 1
  %126 = sub i64 8589934592, %20
  %127 = ashr exact i64 %126, 32
  %128 = getelementptr inbounds i8, i8* %0, i64 %127
  %129 = load i8, i8* %128, align 1
  %130 = zext i8 %129 to i32
  %131 = add nuw nsw i32 %130, 2
  %132 = add nuw nsw i32 %131, %114
  %133 = add nuw nsw i32 %132, %125
  %134 = lshr i32 %133, 2
  %135 = shl nuw nsw i32 %130, 1
  %136 = sub i64 12884901888, %20
  %137 = ashr exact i64 %136, 32
  %138 = getelementptr inbounds i8, i8* %0, i64 %137
  %139 = load i8, i8* %138, align 1
  %140 = zext i8 %139 to i32
  %141 = add nuw nsw i32 %121, %135
  %142 = add nuw nsw i32 %141, %140
  %143 = lshr i32 %142, 2
  %144 = shl nuw nsw i32 %140, 1
  %145 = sub i64 17179869184, %20
  %146 = ashr exact i64 %145, 32
  %147 = getelementptr inbounds i8, i8* %0, i64 %146
  %148 = load i8, i8* %147, align 1
  %149 = zext i8 %148 to i32
  %150 = add nuw nsw i32 %131, %144
  %151 = add nuw nsw i32 %150, %149
  %152 = lshr i32 %151, 2
  %153 = shl nuw nsw i32 %149, 1
  %154 = sub i64 21474836480, %20
  %155 = ashr exact i64 %154, 32
  %156 = getelementptr inbounds i8, i8* %0, i64 %155
  %157 = load i8, i8* %156, align 1
  %158 = zext i8 %157 to i32
  %159 = add nuw nsw i32 %140, 2
  %160 = add nuw nsw i32 %159, %153
  %161 = add nuw nsw i32 %160, %158
  %162 = lshr i32 %161, 2
  %163 = shl nuw nsw i32 %158, 1
  %164 = sub i64 25769803776, %20
  %165 = ashr exact i64 %164, 32
  %166 = getelementptr inbounds i8, i8* %0, i64 %165
  %167 = load i8, i8* %166, align 1
  %168 = zext i8 %167 to i32
  %169 = add nuw nsw i32 %149, 2
  %170 = add nuw nsw i32 %169, %163
  %171 = add nuw nsw i32 %170, %168
  %172 = lshr i32 %171, 2
  %173 = shl nuw nsw i32 %168, 1
  %174 = sub i64 30064771072, %20
  %175 = ashr exact i64 %174, 32
  %176 = getelementptr inbounds i8, i8* %0, i64 %175
  %177 = load i8, i8* %176, align 1
  %178 = zext i8 %177 to i32
  %179 = add nuw nsw i32 %158, 2
  %180 = add nuw nsw i32 %179, %173
  %181 = add nuw nsw i32 %180, %178
  %182 = lshr i32 %181, 2
  %183 = icmp eq i32 %2, 0
  br i1 %183, label %190, label %184

184:                                              ; preds = %17
  %185 = sub i64 34359738368, %20
  %186 = ashr exact i64 %185, 32
  %187 = getelementptr inbounds i8, i8* %0, i64 %186
  %188 = load i8, i8* %187, align 1
  %189 = zext i8 %188 to i32
  br label %190

190:                                              ; preds = %17, %184
  %191 = phi i32 [ %189, %184 ], [ %178, %17 ]
  %192 = shl nuw nsw i32 %178, 1
  %193 = add nuw nsw i32 %168, 2
  %194 = add nuw nsw i32 %193, %192
  %195 = add nuw nsw i32 %194, %191
  %196 = lshr i32 %195, 2
  %197 = add nuw nsw i32 %36, 8
  %198 = add nuw nsw i32 %197, %47
  %199 = add nuw nsw i32 %198, %57
  %200 = add nuw nsw i32 %199, %67
  %201 = add nuw nsw i32 %200, %78
  %202 = add nuw nsw i32 %201, %89
  %203 = add nuw nsw i32 %202, %104
  %204 = add nuw nsw i32 %203, %100
  %205 = add nuw nsw i32 %204, %124
  %206 = add nuw nsw i32 %205, %134
  %207 = add nuw nsw i32 %206, %143
  %208 = add nuw nsw i32 %207, %152
  %209 = add nuw nsw i32 %208, %162
  %210 = add nuw nsw i32 %209, %172
  %211 = add nuw nsw i32 %210, %182
  %212 = add nuw nsw i32 %211, %196
  %213 = ashr i32 %212, 4
  %214 = mul i32 %213, 16843009
  %215 = bitcast i8* %0 to i32*
  store i32 %214, i32* %215, align 4
  %216 = getelementptr inbounds i8, i8* %0, i64 4
  %217 = bitcast i8* %216 to i32*
  store i32 %214, i32* %217, align 4
  %218 = getelementptr inbounds i8, i8* %0, i64 %19
  %219 = bitcast i8* %218 to i32*
  store i32 %214, i32* %219, align 4
  %220 = getelementptr inbounds i8, i8* %218, i64 4
  %221 = bitcast i8* %220 to i32*
  store i32 %214, i32* %221, align 4
  %222 = getelementptr inbounds i8, i8* %218, i64 %19
  %223 = bitcast i8* %222 to i32*
  store i32 %214, i32* %223, align 4
  %224 = getelementptr inbounds i8, i8* %222, i64 4
  %225 = bitcast i8* %224 to i32*
  store i32 %214, i32* %225, align 4
  %226 = getelementptr inbounds i8, i8* %222, i64 %19
  %227 = bitcast i8* %226 to i32*
  store i32 %214, i32* %227, align 4
  %228 = getelementptr inbounds i8, i8* %226, i64 4
  %229 = bitcast i8* %228 to i32*
  store i32 %214, i32* %229, align 4
  %230 = getelementptr inbounds i8, i8* %226, i64 %19
  %231 = bitcast i8* %230 to i32*
  store i32 %214, i32* %231, align 4
  %232 = getelementptr inbounds i8, i8* %230, i64 4
  %233 = bitcast i8* %232 to i32*
  store i32 %214, i32* %233, align 4
  %234 = getelementptr inbounds i8, i8* %230, i64 %19
  %235 = bitcast i8* %234 to i32*
  store i32 %214, i32* %235, align 4
  %236 = getelementptr inbounds i8, i8* %234, i64 4
  %237 = bitcast i8* %236 to i32*
  store i32 %214, i32* %237, align 4
  %238 = getelementptr inbounds i8, i8* %234, i64 %19
  %239 = bitcast i8* %238 to i32*
  store i32 %214, i32* %239, align 4
  %240 = getelementptr inbounds i8, i8* %238, i64 4
  %241 = bitcast i8* %240 to i32*
  store i32 %214, i32* %241, align 4
  %242 = getelementptr inbounds i8, i8* %238, i64 %19
  %243 = bitcast i8* %242 to i32*
  store i32 %214, i32* %243, align 4
  %244 = getelementptr inbounds i8, i8* %242, i64 4
  %245 = bitcast i8* %244 to i32*
  store i32 %214, i32* %245, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_down_left_8_c(i8*, i32, i32, i64) #1 {
  %5 = trunc i64 %3 to i32
  %6 = icmp eq i32 %1, 0
  %7 = sub nsw i32 0, %5
  br i1 %6, label %13, label %8

8:                                                ; preds = %4
  %9 = shl i64 %3, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = sext i32 %7 to i64
  br label %16

13:                                               ; preds = %4
  %14 = sext i32 %7 to i64
  %15 = shl i64 %3, 32
  br label %16

16:                                               ; preds = %13, %8
  %17 = phi i64 [ %15, %13 ], [ %9, %8 ]
  %18 = phi i64 [ %14, %13 ], [ %12, %8 ]
  %19 = phi i64 [ %14, %13 ], [ %11, %8 ]
  %20 = getelementptr inbounds i8, i8* %0, i64 %19
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  %23 = getelementptr inbounds i8, i8* %0, i64 %18
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = shl nuw nsw i32 %25, 1
  %27 = sub i64 4294967296, %17
  %28 = ashr exact i64 %27, 32
  %29 = getelementptr inbounds i8, i8* %0, i64 %28
  %30 = load i8, i8* %29, align 1
  %31 = zext i8 %30 to i32
  %32 = add nuw nsw i32 %31, 2
  %33 = add nuw nsw i32 %32, %22
  %34 = add nuw nsw i32 %33, %26
  %35 = lshr i32 %34, 2
  %36 = shl nuw nsw i32 %31, 1
  %37 = sub i64 8589934592, %17
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i32
  %42 = add nuw nsw i32 %41, 2
  %43 = add nuw nsw i32 %42, %25
  %44 = add nuw nsw i32 %43, %36
  %45 = lshr i32 %44, 2
  %46 = shl nuw nsw i32 %41, 1
  %47 = sub i64 12884901888, %17
  %48 = ashr exact i64 %47, 32
  %49 = getelementptr inbounds i8, i8* %0, i64 %48
  %50 = load i8, i8* %49, align 1
  %51 = zext i8 %50 to i32
  %52 = add nuw nsw i32 %32, %46
  %53 = add nuw nsw i32 %52, %51
  %54 = lshr i32 %53, 2
  %55 = shl nuw nsw i32 %51, 1
  %56 = sub i64 17179869184, %17
  %57 = ashr exact i64 %56, 32
  %58 = getelementptr inbounds i8, i8* %0, i64 %57
  %59 = load i8, i8* %58, align 1
  %60 = zext i8 %59 to i32
  %61 = add nuw nsw i32 %42, %55
  %62 = add nuw nsw i32 %61, %60
  %63 = lshr i32 %62, 2
  %64 = shl nuw nsw i32 %60, 1
  %65 = sub i64 21474836480, %17
  %66 = ashr exact i64 %65, 32
  %67 = getelementptr inbounds i8, i8* %0, i64 %66
  %68 = load i8, i8* %67, align 1
  %69 = zext i8 %68 to i32
  %70 = add nuw nsw i32 %51, 2
  %71 = add nuw nsw i32 %70, %64
  %72 = add nuw nsw i32 %71, %69
  %73 = lshr i32 %72, 2
  %74 = shl nuw nsw i32 %69, 1
  %75 = sub i64 25769803776, %17
  %76 = ashr exact i64 %75, 32
  %77 = getelementptr inbounds i8, i8* %0, i64 %76
  %78 = load i8, i8* %77, align 1
  %79 = zext i8 %78 to i32
  %80 = add nuw nsw i32 %60, 2
  %81 = add nuw nsw i32 %80, %74
  %82 = add nuw nsw i32 %81, %79
  %83 = lshr i32 %82, 2
  %84 = shl nuw nsw i32 %79, 1
  %85 = sub i64 30064771072, %17
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = load i8, i8* %87, align 1
  %89 = zext i8 %88 to i32
  %90 = add nuw nsw i32 %69, 2
  %91 = add nuw nsw i32 %90, %84
  %92 = add nuw nsw i32 %91, %89
  %93 = lshr i32 %92, 2
  %94 = icmp eq i32 %2, 0
  br i1 %94, label %95, label %97

95:                                               ; preds = %16
  %96 = mul nuw nsw i32 %89, 3
  br label %179

97:                                               ; preds = %16
  %98 = sub i64 34359738368, %17
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i8, i8* %0, i64 %99
  %101 = load i8, i8* %100, align 1
  %102 = zext i8 %101 to i32
  %103 = shl nuw nsw i32 %89, 1
  %104 = add nuw nsw i32 %103, %102
  %105 = shl nuw nsw i32 %102, 1
  %106 = sub i64 38654705664, %17
  %107 = ashr exact i64 %106, 32
  %108 = getelementptr inbounds i8, i8* %0, i64 %107
  %109 = load i8, i8* %108, align 1
  %110 = zext i8 %109 to i32
  %111 = add nuw nsw i32 %89, 2
  %112 = add nuw nsw i32 %111, %105
  %113 = add nuw nsw i32 %112, %110
  %114 = lshr i32 %113, 2
  %115 = shl nuw nsw i32 %110, 1
  %116 = sub i64 42949672960, %17
  %117 = ashr exact i64 %116, 32
  %118 = getelementptr inbounds i8, i8* %0, i64 %117
  %119 = load i8, i8* %118, align 1
  %120 = zext i8 %119 to i32
  %121 = add nuw nsw i32 %120, 2
  %122 = add nuw nsw i32 %121, %102
  %123 = add nuw nsw i32 %122, %115
  %124 = lshr i32 %123, 2
  %125 = shl nuw nsw i32 %120, 1
  %126 = sub i64 47244640256, %17
  %127 = ashr exact i64 %126, 32
  %128 = getelementptr inbounds i8, i8* %0, i64 %127
  %129 = load i8, i8* %128, align 1
  %130 = zext i8 %129 to i32
  %131 = add nuw nsw i32 %110, 2
  %132 = add nuw nsw i32 %131, %125
  %133 = add nuw nsw i32 %132, %130
  %134 = lshr i32 %133, 2
  %135 = shl nuw nsw i32 %130, 1
  %136 = sub i64 51539607552, %17
  %137 = ashr exact i64 %136, 32
  %138 = getelementptr inbounds i8, i8* %0, i64 %137
  %139 = load i8, i8* %138, align 1
  %140 = zext i8 %139 to i32
  %141 = add nuw nsw i32 %121, %135
  %142 = add nuw nsw i32 %141, %140
  %143 = lshr i32 %142, 2
  %144 = shl nuw nsw i32 %140, 1
  %145 = sub i64 55834574848, %17
  %146 = ashr exact i64 %145, 32
  %147 = getelementptr inbounds i8, i8* %0, i64 %146
  %148 = load i8, i8* %147, align 1
  %149 = zext i8 %148 to i32
  %150 = add nuw nsw i32 %130, 2
  %151 = add nuw nsw i32 %150, %144
  %152 = add nuw nsw i32 %151, %149
  %153 = lshr i32 %152, 2
  %154 = shl nuw nsw i32 %149, 1
  %155 = sub i64 60129542144, %17
  %156 = ashr exact i64 %155, 32
  %157 = getelementptr inbounds i8, i8* %0, i64 %156
  %158 = load i8, i8* %157, align 1
  %159 = zext i8 %158 to i32
  %160 = add nuw nsw i32 %140, 2
  %161 = add nuw nsw i32 %160, %154
  %162 = add nuw nsw i32 %161, %159
  %163 = lshr i32 %162, 2
  %164 = shl nuw nsw i32 %159, 1
  %165 = sub i64 64424509440, %17
  %166 = ashr exact i64 %165, 32
  %167 = getelementptr inbounds i8, i8* %0, i64 %166
  %168 = load i8, i8* %167, align 1
  %169 = zext i8 %168 to i32
  %170 = add nuw nsw i32 %149, 2
  %171 = add nuw nsw i32 %170, %164
  %172 = add nuw nsw i32 %171, %169
  %173 = lshr i32 %172, 2
  %174 = mul nuw nsw i32 %169, 3
  %175 = add nuw nsw i32 %159, 2
  %176 = add nuw nsw i32 %175, %174
  %177 = lshr i32 %176, 2
  %178 = mul nuw nsw i32 %177, 3
  br label %179

179:                                              ; preds = %95, %97
  %180 = phi i32 [ %96, %95 ], [ %178, %97 ]
  %181 = phi i32 [ %96, %95 ], [ %104, %97 ]
  %182 = phi i32 [ %89, %95 ], [ %114, %97 ]
  %183 = phi i32 [ %89, %95 ], [ %124, %97 ]
  %184 = phi i32 [ %89, %95 ], [ %134, %97 ]
  %185 = phi i32 [ %89, %95 ], [ %143, %97 ]
  %186 = phi i32 [ %89, %95 ], [ %153, %97 ]
  %187 = phi i32 [ %89, %95 ], [ %163, %97 ]
  %188 = phi i32 [ %89, %95 ], [ %173, %97 ]
  %189 = phi i32 [ %89, %95 ], [ %177, %97 ]
  %190 = add nuw nsw i32 %79, 2
  %191 = add nuw nsw i32 %190, %181
  %192 = lshr i32 %191, 2
  %193 = shl nuw nsw i32 %45, 1
  %194 = add nuw nsw i32 %54, 2
  %195 = add nuw nsw i32 %194, %35
  %196 = add nuw nsw i32 %195, %193
  %197 = lshr i32 %196, 2
  %198 = trunc i32 %197 to i8
  store i8 %198, i8* %0, align 1
  %199 = shl nuw nsw i32 %54, 1
  %200 = add nuw nsw i32 %63, 2
  %201 = add nuw nsw i32 %200, %45
  %202 = add nuw nsw i32 %201, %199
  %203 = lshr i32 %202, 2
  %204 = trunc i32 %203 to i8
  %205 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %204, i8* %205, align 1
  %206 = ashr exact i64 %17, 32
  %207 = getelementptr inbounds i8, i8* %0, i64 %206
  store i8 %204, i8* %207, align 1
  %208 = shl nuw nsw i32 %63, 1
  %209 = add nuw nsw i32 %194, %208
  %210 = add nuw nsw i32 %209, %73
  %211 = lshr i32 %210, 2
  %212 = trunc i32 %211 to i8
  %213 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %212, i8* %213, align 1
  %214 = add i64 %17, 4294967296
  %215 = ashr exact i64 %214, 32
  %216 = getelementptr inbounds i8, i8* %0, i64 %215
  store i8 %212, i8* %216, align 1
  %217 = shl nsw i32 %5, 1
  %218 = sext i32 %217 to i64
  %219 = getelementptr inbounds i8, i8* %0, i64 %218
  store i8 %212, i8* %219, align 1
  %220 = shl nuw nsw i32 %73, 1
  %221 = add nuw nsw i32 %200, %220
  %222 = add nuw nsw i32 %221, %83
  %223 = lshr i32 %222, 2
  %224 = trunc i32 %223 to i8
  %225 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %224, i8* %225, align 1
  %226 = add i64 %17, 8589934592
  %227 = ashr exact i64 %226, 32
  %228 = getelementptr inbounds i8, i8* %0, i64 %227
  store i8 %224, i8* %228, align 1
  %229 = or i32 %217, 1
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %0, i64 %230
  store i8 %224, i8* %231, align 1
  %232 = mul nsw i32 %5, 3
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds i8, i8* %0, i64 %233
  store i8 %224, i8* %234, align 1
  %235 = shl nuw nsw i32 %83, 1
  %236 = add nuw nsw i32 %73, 2
  %237 = add nuw nsw i32 %236, %235
  %238 = add nuw nsw i32 %237, %93
  %239 = lshr i32 %238, 2
  %240 = trunc i32 %239 to i8
  %241 = getelementptr inbounds i8, i8* %0, i64 4
  store i8 %240, i8* %241, align 1
  %242 = add i64 %17, 12884901888
  %243 = ashr exact i64 %242, 32
  %244 = getelementptr inbounds i8, i8* %0, i64 %243
  store i8 %240, i8* %244, align 1
  %245 = add nsw i32 %217, 2
  %246 = sext i32 %245 to i64
  %247 = getelementptr inbounds i8, i8* %0, i64 %246
  store i8 %240, i8* %247, align 1
  %248 = add nsw i32 %232, 1
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %0, i64 %249
  store i8 %240, i8* %250, align 1
  %251 = shl nsw i32 %5, 2
  %252 = sext i32 %251 to i64
  %253 = getelementptr inbounds i8, i8* %0, i64 %252
  store i8 %240, i8* %253, align 1
  %254 = shl nuw nsw i32 %93, 1
  %255 = add nuw nsw i32 %83, 2
  %256 = add nuw nsw i32 %255, %254
  %257 = add nuw nsw i32 %256, %192
  %258 = lshr i32 %257, 2
  %259 = trunc i32 %258 to i8
  %260 = getelementptr inbounds i8, i8* %0, i64 5
  store i8 %259, i8* %260, align 1
  %261 = add i64 %17, 17179869184
  %262 = ashr exact i64 %261, 32
  %263 = getelementptr inbounds i8, i8* %0, i64 %262
  store i8 %259, i8* %263, align 1
  %264 = add nsw i32 %217, 3
  %265 = sext i32 %264 to i64
  %266 = getelementptr inbounds i8, i8* %0, i64 %265
  store i8 %259, i8* %266, align 1
  %267 = add nsw i32 %232, 2
  %268 = sext i32 %267 to i64
  %269 = getelementptr inbounds i8, i8* %0, i64 %268
  store i8 %259, i8* %269, align 1
  %270 = or i32 %251, 1
  %271 = sext i32 %270 to i64
  %272 = getelementptr inbounds i8, i8* %0, i64 %271
  store i8 %259, i8* %272, align 1
  %273 = mul nsw i32 %5, 5
  %274 = sext i32 %273 to i64
  %275 = getelementptr inbounds i8, i8* %0, i64 %274
  store i8 %259, i8* %275, align 1
  %276 = shl nuw nsw i32 %192, 1
  %277 = add nuw nsw i32 %93, 2
  %278 = add nuw nsw i32 %277, %182
  %279 = add nuw nsw i32 %278, %276
  %280 = lshr i32 %279, 2
  %281 = trunc i32 %280 to i8
  %282 = getelementptr inbounds i8, i8* %0, i64 6
  store i8 %281, i8* %282, align 1
  %283 = add i64 %17, 21474836480
  %284 = ashr exact i64 %283, 32
  %285 = getelementptr inbounds i8, i8* %0, i64 %284
  store i8 %281, i8* %285, align 1
  %286 = add nsw i32 %217, 4
  %287 = sext i32 %286 to i64
  %288 = getelementptr inbounds i8, i8* %0, i64 %287
  store i8 %281, i8* %288, align 1
  %289 = add nsw i32 %232, 3
  %290 = sext i32 %289 to i64
  %291 = getelementptr inbounds i8, i8* %0, i64 %290
  store i8 %281, i8* %291, align 1
  %292 = or i32 %251, 2
  %293 = sext i32 %292 to i64
  %294 = getelementptr inbounds i8, i8* %0, i64 %293
  store i8 %281, i8* %294, align 1
  %295 = add nsw i32 %273, 1
  %296 = sext i32 %295 to i64
  %297 = getelementptr inbounds i8, i8* %0, i64 %296
  store i8 %281, i8* %297, align 1
  %298 = mul nsw i32 %5, 6
  %299 = sext i32 %298 to i64
  %300 = getelementptr inbounds i8, i8* %0, i64 %299
  store i8 %281, i8* %300, align 1
  %301 = shl nuw nsw i32 %182, 1
  %302 = add nuw nsw i32 %192, 2
  %303 = add nuw nsw i32 %302, %183
  %304 = add nuw nsw i32 %303, %301
  %305 = lshr i32 %304, 2
  %306 = trunc i32 %305 to i8
  %307 = getelementptr inbounds i8, i8* %0, i64 7
  store i8 %306, i8* %307, align 1
  %308 = add i64 %17, 25769803776
  %309 = ashr exact i64 %308, 32
  %310 = getelementptr inbounds i8, i8* %0, i64 %309
  store i8 %306, i8* %310, align 1
  %311 = add nsw i32 %217, 5
  %312 = sext i32 %311 to i64
  %313 = getelementptr inbounds i8, i8* %0, i64 %312
  store i8 %306, i8* %313, align 1
  %314 = add nsw i32 %232, 4
  %315 = sext i32 %314 to i64
  %316 = getelementptr inbounds i8, i8* %0, i64 %315
  store i8 %306, i8* %316, align 1
  %317 = or i32 %251, 3
  %318 = sext i32 %317 to i64
  %319 = getelementptr inbounds i8, i8* %0, i64 %318
  store i8 %306, i8* %319, align 1
  %320 = add nsw i32 %273, 2
  %321 = sext i32 %320 to i64
  %322 = getelementptr inbounds i8, i8* %0, i64 %321
  store i8 %306, i8* %322, align 1
  %323 = or i32 %298, 1
  %324 = sext i32 %323 to i64
  %325 = getelementptr inbounds i8, i8* %0, i64 %324
  store i8 %306, i8* %325, align 1
  %326 = mul nsw i32 %5, 7
  %327 = sext i32 %326 to i64
  %328 = getelementptr inbounds i8, i8* %0, i64 %327
  store i8 %306, i8* %328, align 1
  %329 = shl nuw nsw i32 %183, 1
  %330 = add nuw nsw i32 %182, 2
  %331 = add nuw nsw i32 %330, %329
  %332 = add nuw nsw i32 %331, %184
  %333 = lshr i32 %332, 2
  %334 = trunc i32 %333 to i8
  %335 = add i64 %17, 30064771072
  %336 = ashr exact i64 %335, 32
  %337 = getelementptr inbounds i8, i8* %0, i64 %336
  store i8 %334, i8* %337, align 1
  %338 = add nsw i32 %217, 6
  %339 = sext i32 %338 to i64
  %340 = getelementptr inbounds i8, i8* %0, i64 %339
  store i8 %334, i8* %340, align 1
  %341 = add nsw i32 %232, 5
  %342 = sext i32 %341 to i64
  %343 = getelementptr inbounds i8, i8* %0, i64 %342
  store i8 %334, i8* %343, align 1
  %344 = add nsw i32 %251, 4
  %345 = sext i32 %344 to i64
  %346 = getelementptr inbounds i8, i8* %0, i64 %345
  store i8 %334, i8* %346, align 1
  %347 = add nsw i32 %273, 3
  %348 = sext i32 %347 to i64
  %349 = getelementptr inbounds i8, i8* %0, i64 %348
  store i8 %334, i8* %349, align 1
  %350 = add nsw i32 %298, 2
  %351 = sext i32 %350 to i64
  %352 = getelementptr inbounds i8, i8* %0, i64 %351
  store i8 %334, i8* %352, align 1
  %353 = add nsw i32 %326, 1
  %354 = sext i32 %353 to i64
  %355 = getelementptr inbounds i8, i8* %0, i64 %354
  store i8 %334, i8* %355, align 1
  %356 = shl nuw nsw i32 %184, 1
  %357 = add nuw nsw i32 %183, 2
  %358 = add nuw nsw i32 %357, %356
  %359 = add nuw nsw i32 %358, %185
  %360 = lshr i32 %359, 2
  %361 = trunc i32 %360 to i8
  %362 = add nsw i32 %217, 7
  %363 = sext i32 %362 to i64
  %364 = getelementptr inbounds i8, i8* %0, i64 %363
  store i8 %361, i8* %364, align 1
  %365 = add nsw i32 %232, 6
  %366 = sext i32 %365 to i64
  %367 = getelementptr inbounds i8, i8* %0, i64 %366
  store i8 %361, i8* %367, align 1
  %368 = add nsw i32 %251, 5
  %369 = sext i32 %368 to i64
  %370 = getelementptr inbounds i8, i8* %0, i64 %369
  store i8 %361, i8* %370, align 1
  %371 = add nsw i32 %273, 4
  %372 = sext i32 %371 to i64
  %373 = getelementptr inbounds i8, i8* %0, i64 %372
  store i8 %361, i8* %373, align 1
  %374 = add nsw i32 %298, 3
  %375 = sext i32 %374 to i64
  %376 = getelementptr inbounds i8, i8* %0, i64 %375
  store i8 %361, i8* %376, align 1
  %377 = add nsw i32 %326, 2
  %378 = sext i32 %377 to i64
  %379 = getelementptr inbounds i8, i8* %0, i64 %378
  store i8 %361, i8* %379, align 1
  %380 = shl nuw nsw i32 %185, 1
  %381 = add nuw nsw i32 %184, 2
  %382 = add nuw nsw i32 %381, %380
  %383 = add nuw nsw i32 %382, %186
  %384 = lshr i32 %383, 2
  %385 = trunc i32 %384 to i8
  %386 = add nsw i32 %232, 7
  %387 = sext i32 %386 to i64
  %388 = getelementptr inbounds i8, i8* %0, i64 %387
  store i8 %385, i8* %388, align 1
  %389 = add nsw i32 %251, 6
  %390 = sext i32 %389 to i64
  %391 = getelementptr inbounds i8, i8* %0, i64 %390
  store i8 %385, i8* %391, align 1
  %392 = add nsw i32 %273, 5
  %393 = sext i32 %392 to i64
  %394 = getelementptr inbounds i8, i8* %0, i64 %393
  store i8 %385, i8* %394, align 1
  %395 = add nsw i32 %298, 4
  %396 = sext i32 %395 to i64
  %397 = getelementptr inbounds i8, i8* %0, i64 %396
  store i8 %385, i8* %397, align 1
  %398 = add nsw i32 %326, 3
  %399 = sext i32 %398 to i64
  %400 = getelementptr inbounds i8, i8* %0, i64 %399
  store i8 %385, i8* %400, align 1
  %401 = shl nuw nsw i32 %186, 1
  %402 = add nuw nsw i32 %185, 2
  %403 = add nuw nsw i32 %402, %401
  %404 = add nuw nsw i32 %403, %187
  %405 = lshr i32 %404, 2
  %406 = trunc i32 %405 to i8
  %407 = add nsw i32 %251, 7
  %408 = sext i32 %407 to i64
  %409 = getelementptr inbounds i8, i8* %0, i64 %408
  store i8 %406, i8* %409, align 1
  %410 = add nsw i32 %273, 6
  %411 = sext i32 %410 to i64
  %412 = getelementptr inbounds i8, i8* %0, i64 %411
  store i8 %406, i8* %412, align 1
  %413 = add nsw i32 %298, 5
  %414 = sext i32 %413 to i64
  %415 = getelementptr inbounds i8, i8* %0, i64 %414
  store i8 %406, i8* %415, align 1
  %416 = add nsw i32 %326, 4
  %417 = sext i32 %416 to i64
  %418 = getelementptr inbounds i8, i8* %0, i64 %417
  store i8 %406, i8* %418, align 1
  %419 = shl nuw nsw i32 %187, 1
  %420 = add nuw nsw i32 %186, 2
  %421 = add nuw nsw i32 %420, %419
  %422 = add nuw nsw i32 %421, %188
  %423 = lshr i32 %422, 2
  %424 = trunc i32 %423 to i8
  %425 = add nsw i32 %273, 7
  %426 = sext i32 %425 to i64
  %427 = getelementptr inbounds i8, i8* %0, i64 %426
  store i8 %424, i8* %427, align 1
  %428 = add nsw i32 %298, 6
  %429 = sext i32 %428 to i64
  %430 = getelementptr inbounds i8, i8* %0, i64 %429
  store i8 %424, i8* %430, align 1
  %431 = add nsw i32 %326, 5
  %432 = sext i32 %431 to i64
  %433 = getelementptr inbounds i8, i8* %0, i64 %432
  store i8 %424, i8* %433, align 1
  %434 = shl nuw nsw i32 %188, 1
  %435 = add nuw nsw i32 %187, 2
  %436 = add nuw nsw i32 %435, %434
  %437 = add nuw nsw i32 %436, %189
  %438 = lshr i32 %437, 2
  %439 = trunc i32 %438 to i8
  %440 = add nsw i32 %298, 7
  %441 = sext i32 %440 to i64
  %442 = getelementptr inbounds i8, i8* %0, i64 %441
  store i8 %439, i8* %442, align 1
  %443 = add nsw i32 %326, 6
  %444 = sext i32 %443 to i64
  %445 = getelementptr inbounds i8, i8* %0, i64 %444
  store i8 %439, i8* %445, align 1
  %446 = add nuw nsw i32 %188, 2
  %447 = add nuw nsw i32 %446, %180
  %448 = lshr i32 %447, 2
  %449 = trunc i32 %448 to i8
  %450 = add nsw i32 %326, 7
  %451 = sext i32 %450 to i64
  %452 = getelementptr inbounds i8, i8* %0, i64 %451
  store i8 %449, i8* %452, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_down_right_8_c(i8*, i32, i32, i64) #1 {
  %5 = trunc i64 %3 to i32
  %6 = icmp ne i32 %1, 0
  %7 = sub nsw i32 0, %5
  br i1 %6, label %8, label %13

8:                                                ; preds = %4
  %9 = shl i64 %3, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = sext i32 %7 to i64
  br label %16

13:                                               ; preds = %4
  %14 = sext i32 %7 to i64
  %15 = shl i64 %3, 32
  br label %16

16:                                               ; preds = %13, %8
  %17 = phi i64 [ %15, %13 ], [ %9, %8 ]
  %18 = phi i64 [ %14, %13 ], [ %12, %8 ]
  %19 = phi i64 [ %14, %13 ], [ %11, %8 ]
  %20 = getelementptr inbounds i8, i8* %0, i64 %19
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  %23 = getelementptr inbounds i8, i8* %0, i64 %18
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = shl nuw nsw i32 %25, 1
  %27 = sub i64 4294967296, %17
  %28 = ashr exact i64 %27, 32
  %29 = getelementptr inbounds i8, i8* %0, i64 %28
  %30 = load i8, i8* %29, align 1
  %31 = zext i8 %30 to i32
  %32 = add nuw nsw i32 %31, 2
  %33 = add nuw nsw i32 %32, %22
  %34 = add nuw nsw i32 %33, %26
  %35 = lshr i32 %34, 2
  %36 = shl nuw nsw i32 %31, 1
  %37 = sub i64 8589934592, %17
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i32
  %42 = add nuw nsw i32 %25, 2
  %43 = add nuw nsw i32 %42, %36
  %44 = add nuw nsw i32 %43, %41
  %45 = lshr i32 %44, 2
  %46 = shl nuw nsw i32 %41, 1
  %47 = sub i64 12884901888, %17
  %48 = ashr exact i64 %47, 32
  %49 = getelementptr inbounds i8, i8* %0, i64 %48
  %50 = load i8, i8* %49, align 1
  %51 = zext i8 %50 to i32
  %52 = add nuw nsw i32 %32, %46
  %53 = add nuw nsw i32 %52, %51
  %54 = lshr i32 %53, 2
  %55 = shl nuw nsw i32 %51, 1
  %56 = sub i64 17179869184, %17
  %57 = ashr exact i64 %56, 32
  %58 = getelementptr inbounds i8, i8* %0, i64 %57
  %59 = load i8, i8* %58, align 1
  %60 = zext i8 %59 to i32
  %61 = add nuw nsw i32 %41, 2
  %62 = add nuw nsw i32 %61, %55
  %63 = add nuw nsw i32 %62, %60
  %64 = lshr i32 %63, 2
  %65 = shl nuw nsw i32 %60, 1
  %66 = sub i64 21474836480, %17
  %67 = ashr exact i64 %66, 32
  %68 = getelementptr inbounds i8, i8* %0, i64 %67
  %69 = load i8, i8* %68, align 1
  %70 = zext i8 %69 to i32
  %71 = add nuw nsw i32 %51, 2
  %72 = add nuw nsw i32 %71, %65
  %73 = add nuw nsw i32 %72, %70
  %74 = lshr i32 %73, 2
  %75 = shl nuw nsw i32 %70, 1
  %76 = sub i64 25769803776, %17
  %77 = ashr exact i64 %76, 32
  %78 = getelementptr inbounds i8, i8* %0, i64 %77
  %79 = load i8, i8* %78, align 1
  %80 = zext i8 %79 to i32
  %81 = add nuw nsw i32 %60, 2
  %82 = add nuw nsw i32 %81, %75
  %83 = add nuw nsw i32 %82, %80
  %84 = lshr i32 %83, 2
  %85 = shl nuw nsw i32 %80, 1
  %86 = sub i64 30064771072, %17
  %87 = ashr exact i64 %86, 32
  %88 = getelementptr inbounds i8, i8* %0, i64 %87
  %89 = load i8, i8* %88, align 1
  %90 = zext i8 %89 to i32
  %91 = add nuw nsw i32 %70, 2
  %92 = add nuw nsw i32 %91, %85
  %93 = add nuw nsw i32 %92, %90
  %94 = lshr i32 %93, 2
  %95 = icmp eq i32 %2, 0
  br i1 %95, label %102, label %96

96:                                               ; preds = %16
  %97 = sub i64 34359738368, %17
  %98 = ashr exact i64 %97, 32
  %99 = getelementptr inbounds i8, i8* %0, i64 %98
  %100 = load i8, i8* %99, align 1
  %101 = zext i8 %100 to i32
  br label %102

102:                                              ; preds = %16, %96
  %103 = phi i32 [ %101, %96 ], [ %90, %16 ]
  %104 = shl nuw nsw i32 %90, 1
  %105 = add nuw nsw i32 %80, 2
  %106 = add nuw nsw i32 %105, %104
  %107 = add nuw nsw i32 %106, %103
  %108 = lshr i32 %107, 2
  %109 = ashr exact i64 %17, 32
  %110 = xor i64 %109, -1
  %111 = select i1 %6, i64 %110, i64 -1
  %112 = getelementptr inbounds i8, i8* %0, i64 %111
  %113 = load i8, i8* %112, align 1
  %114 = zext i8 %113 to i32
  %115 = getelementptr inbounds i8, i8* %0, i64 -1
  %116 = load i8, i8* %115, align 1
  %117 = zext i8 %116 to i32
  %118 = shl nuw nsw i32 %117, 1
  %119 = add i64 %17, -4294967296
  %120 = ashr exact i64 %119, 32
  %121 = getelementptr inbounds i8, i8* %0, i64 %120
  %122 = load i8, i8* %121, align 1
  %123 = zext i8 %122 to i32
  %124 = add nuw nsw i32 %123, 2
  %125 = add nuw nsw i32 %124, %114
  %126 = add nuw nsw i32 %125, %118
  %127 = lshr i32 %126, 2
  %128 = shl nuw nsw i32 %123, 1
  %129 = shl nsw i32 %5, 1
  %130 = add nsw i32 %129, -1
  %131 = sext i32 %130 to i64
  %132 = getelementptr inbounds i8, i8* %0, i64 %131
  %133 = load i8, i8* %132, align 1
  %134 = zext i8 %133 to i32
  %135 = add nuw nsw i32 %117, 2
  %136 = add nuw nsw i32 %135, %128
  %137 = add nuw nsw i32 %136, %134
  %138 = lshr i32 %137, 2
  %139 = shl nuw nsw i32 %134, 1
  %140 = mul nsw i32 %5, 3
  %141 = add nsw i32 %140, -1
  %142 = sext i32 %141 to i64
  %143 = getelementptr inbounds i8, i8* %0, i64 %142
  %144 = load i8, i8* %143, align 1
  %145 = zext i8 %144 to i32
  %146 = add nuw nsw i32 %124, %139
  %147 = add nuw nsw i32 %146, %145
  %148 = lshr i32 %147, 2
  %149 = shl nuw nsw i32 %145, 1
  %150 = shl nsw i32 %5, 2
  %151 = add nsw i32 %150, -1
  %152 = sext i32 %151 to i64
  %153 = getelementptr inbounds i8, i8* %0, i64 %152
  %154 = load i8, i8* %153, align 1
  %155 = zext i8 %154 to i32
  %156 = add nuw nsw i32 %134, 2
  %157 = add nuw nsw i32 %156, %149
  %158 = add nuw nsw i32 %157, %155
  %159 = lshr i32 %158, 2
  %160 = shl nuw nsw i32 %155, 1
  %161 = mul nsw i32 %5, 5
  %162 = add nsw i32 %161, -1
  %163 = sext i32 %162 to i64
  %164 = getelementptr inbounds i8, i8* %0, i64 %163
  %165 = load i8, i8* %164, align 1
  %166 = zext i8 %165 to i32
  %167 = add nuw nsw i32 %145, 2
  %168 = add nuw nsw i32 %167, %160
  %169 = add nuw nsw i32 %168, %166
  %170 = lshr i32 %169, 2
  %171 = shl nuw nsw i32 %166, 1
  %172 = mul nsw i32 %5, 6
  %173 = add nsw i32 %172, -1
  %174 = sext i32 %173 to i64
  %175 = getelementptr inbounds i8, i8* %0, i64 %174
  %176 = load i8, i8* %175, align 1
  %177 = zext i8 %176 to i32
  %178 = add nuw nsw i32 %155, 2
  %179 = add nuw nsw i32 %178, %171
  %180 = add nuw nsw i32 %179, %177
  %181 = lshr i32 %180, 2
  %182 = shl nuw nsw i32 %177, 1
  %183 = mul nsw i32 %5, 7
  %184 = add nsw i32 %183, -1
  %185 = sext i32 %184 to i64
  %186 = getelementptr inbounds i8, i8* %0, i64 %185
  %187 = load i8, i8* %186, align 1
  %188 = zext i8 %187 to i32
  %189 = add nuw nsw i32 %166, 2
  %190 = add nuw nsw i32 %189, %182
  %191 = add nuw nsw i32 %190, %188
  %192 = lshr i32 %191, 2
  %193 = mul nuw nsw i32 %188, 3
  %194 = add nuw nsw i32 %177, 2
  %195 = add nuw nsw i32 %194, %193
  %196 = lshr i32 %195, 2
  %197 = getelementptr inbounds i8, i8* %0, i64 %110
  %198 = load i8, i8* %197, align 1
  %199 = zext i8 %198 to i32
  %200 = shl nuw nsw i32 %199, 1
  %201 = add nuw nsw i32 %42, %117
  %202 = add nuw nsw i32 %201, %200
  %203 = lshr i32 %202, 2
  %204 = shl nuw nsw i32 %192, 1
  %205 = add nuw nsw i32 %181, 2
  %206 = add nuw nsw i32 %205, %196
  %207 = add nuw nsw i32 %206, %204
  %208 = lshr i32 %207, 2
  %209 = trunc i32 %208 to i8
  %210 = sext i32 %183 to i64
  %211 = getelementptr inbounds i8, i8* %0, i64 %210
  store i8 %209, i8* %211, align 1
  %212 = shl nuw nsw i32 %181, 1
  %213 = add nuw nsw i32 %170, 2
  %214 = add nuw nsw i32 %213, %212
  %215 = add nuw nsw i32 %214, %192
  %216 = lshr i32 %215, 2
  %217 = trunc i32 %216 to i8
  %218 = add nsw i32 %183, 1
  %219 = sext i32 %218 to i64
  %220 = getelementptr inbounds i8, i8* %0, i64 %219
  store i8 %217, i8* %220, align 1
  %221 = sext i32 %172 to i64
  %222 = getelementptr inbounds i8, i8* %0, i64 %221
  store i8 %217, i8* %222, align 1
  %223 = shl nuw nsw i32 %170, 1
  %224 = add nuw nsw i32 %159, 2
  %225 = add nuw nsw i32 %224, %223
  %226 = add nuw nsw i32 %225, %181
  %227 = lshr i32 %226, 2
  %228 = trunc i32 %227 to i8
  %229 = add nsw i32 %183, 2
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %0, i64 %230
  store i8 %228, i8* %231, align 1
  %232 = or i32 %172, 1
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds i8, i8* %0, i64 %233
  store i8 %228, i8* %234, align 1
  %235 = sext i32 %161 to i64
  %236 = getelementptr inbounds i8, i8* %0, i64 %235
  store i8 %228, i8* %236, align 1
  %237 = shl nuw nsw i32 %159, 1
  %238 = add nuw nsw i32 %148, 2
  %239 = add nuw nsw i32 %238, %237
  %240 = add nuw nsw i32 %239, %170
  %241 = lshr i32 %240, 2
  %242 = trunc i32 %241 to i8
  %243 = add nsw i32 %183, 3
  %244 = sext i32 %243 to i64
  %245 = getelementptr inbounds i8, i8* %0, i64 %244
  store i8 %242, i8* %245, align 1
  %246 = add nsw i32 %172, 2
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds i8, i8* %0, i64 %247
  store i8 %242, i8* %248, align 1
  %249 = add nsw i32 %161, 1
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds i8, i8* %0, i64 %250
  store i8 %242, i8* %251, align 1
  %252 = sext i32 %150 to i64
  %253 = getelementptr inbounds i8, i8* %0, i64 %252
  store i8 %242, i8* %253, align 1
  %254 = shl nuw nsw i32 %148, 1
  %255 = add nuw nsw i32 %138, 2
  %256 = add nuw nsw i32 %255, %254
  %257 = add nuw nsw i32 %256, %159
  %258 = lshr i32 %257, 2
  %259 = trunc i32 %258 to i8
  %260 = add nsw i32 %183, 4
  %261 = sext i32 %260 to i64
  %262 = getelementptr inbounds i8, i8* %0, i64 %261
  store i8 %259, i8* %262, align 1
  %263 = add nsw i32 %172, 3
  %264 = sext i32 %263 to i64
  %265 = getelementptr inbounds i8, i8* %0, i64 %264
  store i8 %259, i8* %265, align 1
  %266 = add nsw i32 %161, 2
  %267 = sext i32 %266 to i64
  %268 = getelementptr inbounds i8, i8* %0, i64 %267
  store i8 %259, i8* %268, align 1
  %269 = or i32 %150, 1
  %270 = sext i32 %269 to i64
  %271 = getelementptr inbounds i8, i8* %0, i64 %270
  store i8 %259, i8* %271, align 1
  %272 = sext i32 %140 to i64
  %273 = getelementptr inbounds i8, i8* %0, i64 %272
  store i8 %259, i8* %273, align 1
  %274 = shl nuw nsw i32 %138, 1
  %275 = add nuw nsw i32 %127, 2
  %276 = add nuw nsw i32 %275, %274
  %277 = add nuw nsw i32 %276, %148
  %278 = lshr i32 %277, 2
  %279 = trunc i32 %278 to i8
  %280 = add nsw i32 %183, 5
  %281 = sext i32 %280 to i64
  %282 = getelementptr inbounds i8, i8* %0, i64 %281
  store i8 %279, i8* %282, align 1
  %283 = add nsw i32 %172, 4
  %284 = sext i32 %283 to i64
  %285 = getelementptr inbounds i8, i8* %0, i64 %284
  store i8 %279, i8* %285, align 1
  %286 = add nsw i32 %161, 3
  %287 = sext i32 %286 to i64
  %288 = getelementptr inbounds i8, i8* %0, i64 %287
  store i8 %279, i8* %288, align 1
  %289 = or i32 %150, 2
  %290 = sext i32 %289 to i64
  %291 = getelementptr inbounds i8, i8* %0, i64 %290
  store i8 %279, i8* %291, align 1
  %292 = add nsw i32 %140, 1
  %293 = sext i32 %292 to i64
  %294 = getelementptr inbounds i8, i8* %0, i64 %293
  store i8 %279, i8* %294, align 1
  %295 = sext i32 %129 to i64
  %296 = getelementptr inbounds i8, i8* %0, i64 %295
  store i8 %279, i8* %296, align 1
  %297 = shl nuw nsw i32 %127, 1
  %298 = add nuw nsw i32 %255, %297
  %299 = add nuw nsw i32 %298, %203
  %300 = lshr i32 %299, 2
  %301 = trunc i32 %300 to i8
  %302 = add nsw i32 %183, 6
  %303 = sext i32 %302 to i64
  %304 = getelementptr inbounds i8, i8* %0, i64 %303
  store i8 %301, i8* %304, align 1
  %305 = add nsw i32 %172, 5
  %306 = sext i32 %305 to i64
  %307 = getelementptr inbounds i8, i8* %0, i64 %306
  store i8 %301, i8* %307, align 1
  %308 = add nsw i32 %161, 4
  %309 = sext i32 %308 to i64
  %310 = getelementptr inbounds i8, i8* %0, i64 %309
  store i8 %301, i8* %310, align 1
  %311 = or i32 %150, 3
  %312 = sext i32 %311 to i64
  %313 = getelementptr inbounds i8, i8* %0, i64 %312
  store i8 %301, i8* %313, align 1
  %314 = add nsw i32 %140, 2
  %315 = sext i32 %314 to i64
  %316 = getelementptr inbounds i8, i8* %0, i64 %315
  store i8 %301, i8* %316, align 1
  %317 = or i32 %129, 1
  %318 = sext i32 %317 to i64
  %319 = getelementptr inbounds i8, i8* %0, i64 %318
  store i8 %301, i8* %319, align 1
  %320 = getelementptr inbounds i8, i8* %0, i64 %109
  store i8 %301, i8* %320, align 1
  %321 = shl nuw nsw i32 %203, 1
  %322 = add nuw nsw i32 %35, 2
  %323 = add nuw nsw i32 %322, %127
  %324 = add nuw nsw i32 %323, %321
  %325 = lshr i32 %324, 2
  %326 = trunc i32 %325 to i8
  %327 = add nsw i32 %183, 7
  %328 = sext i32 %327 to i64
  %329 = getelementptr inbounds i8, i8* %0, i64 %328
  store i8 %326, i8* %329, align 1
  %330 = add nsw i32 %172, 6
  %331 = sext i32 %330 to i64
  %332 = getelementptr inbounds i8, i8* %0, i64 %331
  store i8 %326, i8* %332, align 1
  %333 = add nsw i32 %161, 5
  %334 = sext i32 %333 to i64
  %335 = getelementptr inbounds i8, i8* %0, i64 %334
  store i8 %326, i8* %335, align 1
  %336 = add nsw i32 %150, 4
  %337 = sext i32 %336 to i64
  %338 = getelementptr inbounds i8, i8* %0, i64 %337
  store i8 %326, i8* %338, align 1
  %339 = add nsw i32 %140, 3
  %340 = sext i32 %339 to i64
  %341 = getelementptr inbounds i8, i8* %0, i64 %340
  store i8 %326, i8* %341, align 1
  %342 = add nsw i32 %129, 2
  %343 = sext i32 %342 to i64
  %344 = getelementptr inbounds i8, i8* %0, i64 %343
  store i8 %326, i8* %344, align 1
  %345 = add i64 %17, 4294967296
  %346 = ashr exact i64 %345, 32
  %347 = getelementptr inbounds i8, i8* %0, i64 %346
  store i8 %326, i8* %347, align 1
  store i8 %326, i8* %0, align 1
  %348 = shl nuw nsw i32 %35, 1
  %349 = add nuw nsw i32 %45, 2
  %350 = add nuw nsw i32 %349, %348
  %351 = add nuw nsw i32 %350, %203
  %352 = lshr i32 %351, 2
  %353 = trunc i32 %352 to i8
  %354 = add nsw i32 %172, 7
  %355 = sext i32 %354 to i64
  %356 = getelementptr inbounds i8, i8* %0, i64 %355
  store i8 %353, i8* %356, align 1
  %357 = add nsw i32 %161, 6
  %358 = sext i32 %357 to i64
  %359 = getelementptr inbounds i8, i8* %0, i64 %358
  store i8 %353, i8* %359, align 1
  %360 = add nsw i32 %150, 5
  %361 = sext i32 %360 to i64
  %362 = getelementptr inbounds i8, i8* %0, i64 %361
  store i8 %353, i8* %362, align 1
  %363 = add nsw i32 %140, 4
  %364 = sext i32 %363 to i64
  %365 = getelementptr inbounds i8, i8* %0, i64 %364
  store i8 %353, i8* %365, align 1
  %366 = add nsw i32 %129, 3
  %367 = sext i32 %366 to i64
  %368 = getelementptr inbounds i8, i8* %0, i64 %367
  store i8 %353, i8* %368, align 1
  %369 = add i64 %17, 8589934592
  %370 = ashr exact i64 %369, 32
  %371 = getelementptr inbounds i8, i8* %0, i64 %370
  store i8 %353, i8* %371, align 1
  %372 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %353, i8* %372, align 1
  %373 = shl nuw nsw i32 %45, 1
  %374 = add nuw nsw i32 %322, %373
  %375 = add nuw nsw i32 %374, %54
  %376 = lshr i32 %375, 2
  %377 = trunc i32 %376 to i8
  %378 = add nsw i32 %161, 7
  %379 = sext i32 %378 to i64
  %380 = getelementptr inbounds i8, i8* %0, i64 %379
  store i8 %377, i8* %380, align 1
  %381 = add nsw i32 %150, 6
  %382 = sext i32 %381 to i64
  %383 = getelementptr inbounds i8, i8* %0, i64 %382
  store i8 %377, i8* %383, align 1
  %384 = add nsw i32 %140, 5
  %385 = sext i32 %384 to i64
  %386 = getelementptr inbounds i8, i8* %0, i64 %385
  store i8 %377, i8* %386, align 1
  %387 = add nsw i32 %129, 4
  %388 = sext i32 %387 to i64
  %389 = getelementptr inbounds i8, i8* %0, i64 %388
  store i8 %377, i8* %389, align 1
  %390 = add i64 %17, 12884901888
  %391 = ashr exact i64 %390, 32
  %392 = getelementptr inbounds i8, i8* %0, i64 %391
  store i8 %377, i8* %392, align 1
  %393 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %377, i8* %393, align 1
  %394 = shl nuw nsw i32 %54, 1
  %395 = add nuw nsw i32 %349, %394
  %396 = add nuw nsw i32 %395, %64
  %397 = lshr i32 %396, 2
  %398 = trunc i32 %397 to i8
  %399 = add nsw i32 %150, 7
  %400 = sext i32 %399 to i64
  %401 = getelementptr inbounds i8, i8* %0, i64 %400
  store i8 %398, i8* %401, align 1
  %402 = add nsw i32 %140, 6
  %403 = sext i32 %402 to i64
  %404 = getelementptr inbounds i8, i8* %0, i64 %403
  store i8 %398, i8* %404, align 1
  %405 = add nsw i32 %129, 5
  %406 = sext i32 %405 to i64
  %407 = getelementptr inbounds i8, i8* %0, i64 %406
  store i8 %398, i8* %407, align 1
  %408 = add i64 %17, 17179869184
  %409 = ashr exact i64 %408, 32
  %410 = getelementptr inbounds i8, i8* %0, i64 %409
  store i8 %398, i8* %410, align 1
  %411 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %398, i8* %411, align 1
  %412 = shl nuw nsw i32 %64, 1
  %413 = add nuw nsw i32 %54, 2
  %414 = add nuw nsw i32 %413, %412
  %415 = add nuw nsw i32 %414, %74
  %416 = lshr i32 %415, 2
  %417 = trunc i32 %416 to i8
  %418 = add nsw i32 %140, 7
  %419 = sext i32 %418 to i64
  %420 = getelementptr inbounds i8, i8* %0, i64 %419
  store i8 %417, i8* %420, align 1
  %421 = add nsw i32 %129, 6
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds i8, i8* %0, i64 %422
  store i8 %417, i8* %423, align 1
  %424 = add i64 %17, 21474836480
  %425 = ashr exact i64 %424, 32
  %426 = getelementptr inbounds i8, i8* %0, i64 %425
  store i8 %417, i8* %426, align 1
  %427 = getelementptr inbounds i8, i8* %0, i64 4
  store i8 %417, i8* %427, align 1
  %428 = shl nuw nsw i32 %74, 1
  %429 = add nuw nsw i32 %64, 2
  %430 = add nuw nsw i32 %429, %428
  %431 = add nuw nsw i32 %430, %84
  %432 = lshr i32 %431, 2
  %433 = trunc i32 %432 to i8
  %434 = add nsw i32 %129, 7
  %435 = sext i32 %434 to i64
  %436 = getelementptr inbounds i8, i8* %0, i64 %435
  store i8 %433, i8* %436, align 1
  %437 = add i64 %17, 25769803776
  %438 = ashr exact i64 %437, 32
  %439 = getelementptr inbounds i8, i8* %0, i64 %438
  store i8 %433, i8* %439, align 1
  %440 = getelementptr inbounds i8, i8* %0, i64 5
  store i8 %433, i8* %440, align 1
  %441 = shl nuw nsw i32 %84, 1
  %442 = add nuw nsw i32 %74, 2
  %443 = add nuw nsw i32 %442, %441
  %444 = add nuw nsw i32 %443, %94
  %445 = lshr i32 %444, 2
  %446 = trunc i32 %445 to i8
  %447 = add i64 %17, 30064771072
  %448 = ashr exact i64 %447, 32
  %449 = getelementptr inbounds i8, i8* %0, i64 %448
  store i8 %446, i8* %449, align 1
  %450 = getelementptr inbounds i8, i8* %0, i64 6
  store i8 %446, i8* %450, align 1
  %451 = shl nuw nsw i32 %94, 1
  %452 = add nuw nsw i32 %84, 2
  %453 = add nuw nsw i32 %452, %451
  %454 = add nuw nsw i32 %453, %108
  %455 = lshr i32 %454, 2
  %456 = trunc i32 %455 to i8
  %457 = getelementptr inbounds i8, i8* %0, i64 7
  store i8 %456, i8* %457, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_right_8_c(i8*, i32, i32, i64) #1 {
  %5 = trunc i64 %3 to i32
  %6 = icmp ne i32 %1, 0
  %7 = sub nsw i32 0, %5
  br i1 %6, label %8, label %13

8:                                                ; preds = %4
  %9 = shl i64 %3, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = sext i32 %7 to i64
  br label %16

13:                                               ; preds = %4
  %14 = sext i32 %7 to i64
  %15 = shl i64 %3, 32
  br label %16

16:                                               ; preds = %13, %8
  %17 = phi i64 [ %15, %13 ], [ %9, %8 ]
  %18 = phi i64 [ %14, %13 ], [ %12, %8 ]
  %19 = phi i64 [ %14, %13 ], [ %11, %8 ]
  %20 = getelementptr inbounds i8, i8* %0, i64 %19
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  %23 = getelementptr inbounds i8, i8* %0, i64 %18
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = shl nuw nsw i32 %25, 1
  %27 = sub i64 4294967296, %17
  %28 = ashr exact i64 %27, 32
  %29 = getelementptr inbounds i8, i8* %0, i64 %28
  %30 = load i8, i8* %29, align 1
  %31 = zext i8 %30 to i32
  %32 = add nuw nsw i32 %31, 2
  %33 = add nuw nsw i32 %32, %22
  %34 = add nuw nsw i32 %33, %26
  %35 = lshr i32 %34, 2
  %36 = shl nuw nsw i32 %31, 1
  %37 = sub i64 8589934592, %17
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i32
  %42 = add nuw nsw i32 %25, 2
  %43 = add nuw nsw i32 %42, %36
  %44 = add nuw nsw i32 %43, %41
  %45 = lshr i32 %44, 2
  %46 = shl nuw nsw i32 %41, 1
  %47 = sub i64 12884901888, %17
  %48 = ashr exact i64 %47, 32
  %49 = getelementptr inbounds i8, i8* %0, i64 %48
  %50 = load i8, i8* %49, align 1
  %51 = zext i8 %50 to i32
  %52 = add nuw nsw i32 %32, %46
  %53 = add nuw nsw i32 %52, %51
  %54 = lshr i32 %53, 2
  %55 = shl nuw nsw i32 %51, 1
  %56 = sub i64 17179869184, %17
  %57 = ashr exact i64 %56, 32
  %58 = getelementptr inbounds i8, i8* %0, i64 %57
  %59 = load i8, i8* %58, align 1
  %60 = zext i8 %59 to i32
  %61 = add nuw nsw i32 %41, 2
  %62 = add nuw nsw i32 %61, %55
  %63 = add nuw nsw i32 %62, %60
  %64 = lshr i32 %63, 2
  %65 = shl nuw nsw i32 %60, 1
  %66 = sub i64 21474836480, %17
  %67 = ashr exact i64 %66, 32
  %68 = getelementptr inbounds i8, i8* %0, i64 %67
  %69 = load i8, i8* %68, align 1
  %70 = zext i8 %69 to i32
  %71 = add nuw nsw i32 %51, 2
  %72 = add nuw nsw i32 %71, %65
  %73 = add nuw nsw i32 %72, %70
  %74 = lshr i32 %73, 2
  %75 = shl nuw nsw i32 %70, 1
  %76 = sub i64 25769803776, %17
  %77 = ashr exact i64 %76, 32
  %78 = getelementptr inbounds i8, i8* %0, i64 %77
  %79 = load i8, i8* %78, align 1
  %80 = zext i8 %79 to i32
  %81 = add nuw nsw i32 %60, 2
  %82 = add nuw nsw i32 %81, %75
  %83 = add nuw nsw i32 %82, %80
  %84 = lshr i32 %83, 2
  %85 = shl nuw nsw i32 %80, 1
  %86 = sub i64 30064771072, %17
  %87 = ashr exact i64 %86, 32
  %88 = getelementptr inbounds i8, i8* %0, i64 %87
  %89 = load i8, i8* %88, align 1
  %90 = zext i8 %89 to i32
  %91 = add nuw nsw i32 %70, 2
  %92 = add nuw nsw i32 %91, %85
  %93 = add nuw nsw i32 %92, %90
  %94 = lshr i32 %93, 2
  %95 = icmp eq i32 %2, 0
  br i1 %95, label %102, label %96

96:                                               ; preds = %16
  %97 = sub i64 34359738368, %17
  %98 = ashr exact i64 %97, 32
  %99 = getelementptr inbounds i8, i8* %0, i64 %98
  %100 = load i8, i8* %99, align 1
  %101 = zext i8 %100 to i32
  br label %102

102:                                              ; preds = %16, %96
  %103 = phi i32 [ %101, %96 ], [ %90, %16 ]
  %104 = shl nuw nsw i32 %90, 1
  %105 = add nuw nsw i32 %80, 2
  %106 = add nuw nsw i32 %105, %104
  %107 = add nuw nsw i32 %106, %103
  %108 = lshr i32 %107, 2
  %109 = ashr exact i64 %17, 32
  %110 = xor i64 %109, -1
  %111 = select i1 %6, i64 %110, i64 -1
  %112 = getelementptr inbounds i8, i8* %0, i64 %111
  %113 = load i8, i8* %112, align 1
  %114 = zext i8 %113 to i32
  %115 = getelementptr inbounds i8, i8* %0, i64 -1
  %116 = load i8, i8* %115, align 1
  %117 = zext i8 %116 to i32
  %118 = shl nuw nsw i32 %117, 1
  %119 = add i64 %17, -4294967296
  %120 = ashr exact i64 %119, 32
  %121 = getelementptr inbounds i8, i8* %0, i64 %120
  %122 = load i8, i8* %121, align 1
  %123 = zext i8 %122 to i32
  %124 = add nuw nsw i32 %123, 2
  %125 = add nuw nsw i32 %124, %114
  %126 = add nuw nsw i32 %125, %118
  %127 = lshr i32 %126, 2
  %128 = shl nuw nsw i32 %123, 1
  %129 = shl nsw i32 %5, 1
  %130 = add nsw i32 %129, -1
  %131 = sext i32 %130 to i64
  %132 = getelementptr inbounds i8, i8* %0, i64 %131
  %133 = load i8, i8* %132, align 1
  %134 = zext i8 %133 to i32
  %135 = add nuw nsw i32 %117, 2
  %136 = add nuw nsw i32 %135, %128
  %137 = add nuw nsw i32 %136, %134
  %138 = lshr i32 %137, 2
  %139 = shl nuw nsw i32 %134, 1
  %140 = mul nsw i32 %5, 3
  %141 = add nsw i32 %140, -1
  %142 = sext i32 %141 to i64
  %143 = getelementptr inbounds i8, i8* %0, i64 %142
  %144 = load i8, i8* %143, align 1
  %145 = zext i8 %144 to i32
  %146 = add nuw nsw i32 %124, %139
  %147 = add nuw nsw i32 %146, %145
  %148 = lshr i32 %147, 2
  %149 = shl nuw nsw i32 %145, 1
  %150 = shl nsw i32 %5, 2
  %151 = add nsw i32 %150, -1
  %152 = sext i32 %151 to i64
  %153 = getelementptr inbounds i8, i8* %0, i64 %152
  %154 = load i8, i8* %153, align 1
  %155 = zext i8 %154 to i32
  %156 = add nuw nsw i32 %134, 2
  %157 = add nuw nsw i32 %156, %149
  %158 = add nuw nsw i32 %157, %155
  %159 = lshr i32 %158, 2
  %160 = shl nuw nsw i32 %155, 1
  %161 = mul nsw i32 %5, 5
  %162 = add nsw i32 %161, -1
  %163 = sext i32 %162 to i64
  %164 = getelementptr inbounds i8, i8* %0, i64 %163
  %165 = load i8, i8* %164, align 1
  %166 = zext i8 %165 to i32
  %167 = add nuw nsw i32 %145, 2
  %168 = add nuw nsw i32 %167, %160
  %169 = add nuw nsw i32 %168, %166
  %170 = lshr i32 %169, 2
  %171 = shl nuw nsw i32 %166, 1
  %172 = mul nsw i32 %5, 6
  %173 = add nsw i32 %172, -1
  %174 = sext i32 %173 to i64
  %175 = getelementptr inbounds i8, i8* %0, i64 %174
  %176 = load i8, i8* %175, align 1
  %177 = zext i8 %176 to i32
  %178 = add nuw nsw i32 %155, 2
  %179 = add nuw nsw i32 %178, %171
  %180 = add nuw nsw i32 %179, %177
  %181 = lshr i32 %180, 2
  %182 = shl nuw nsw i32 %177, 1
  %183 = mul nsw i32 %5, 7
  %184 = add nsw i32 %183, -1
  %185 = sext i32 %184 to i64
  %186 = getelementptr inbounds i8, i8* %0, i64 %185
  %187 = load i8, i8* %186, align 1
  %188 = zext i8 %187 to i32
  %189 = add nuw nsw i32 %166, 2
  %190 = add nuw nsw i32 %189, %182
  %191 = add nuw nsw i32 %190, %188
  %192 = lshr i32 %191, 2
  %193 = getelementptr inbounds i8, i8* %0, i64 %110
  %194 = load i8, i8* %193, align 1
  %195 = zext i8 %194 to i32
  %196 = shl nuw nsw i32 %195, 1
  %197 = add nuw nsw i32 %42, %117
  %198 = add nuw nsw i32 %197, %196
  %199 = lshr i32 %198, 2
  %200 = shl nuw nsw i32 %170, 1
  %201 = add nuw nsw i32 %159, 2
  %202 = add nuw nsw i32 %201, %200
  %203 = add nuw nsw i32 %202, %181
  %204 = lshr i32 %203, 2
  %205 = trunc i32 %204 to i8
  %206 = sext i32 %172 to i64
  %207 = getelementptr inbounds i8, i8* %0, i64 %206
  store i8 %205, i8* %207, align 1
  %208 = shl nuw nsw i32 %181, 1
  %209 = add nuw nsw i32 %170, 2
  %210 = add nuw nsw i32 %209, %208
  %211 = add nuw nsw i32 %210, %192
  %212 = lshr i32 %211, 2
  %213 = trunc i32 %212 to i8
  %214 = sext i32 %183 to i64
  %215 = getelementptr inbounds i8, i8* %0, i64 %214
  store i8 %213, i8* %215, align 1
  %216 = shl nuw nsw i32 %148, 1
  %217 = add nuw nsw i32 %138, 2
  %218 = add nuw nsw i32 %217, %216
  %219 = add nuw nsw i32 %218, %159
  %220 = lshr i32 %219, 2
  %221 = trunc i32 %220 to i8
  %222 = or i32 %172, 1
  %223 = sext i32 %222 to i64
  %224 = getelementptr inbounds i8, i8* %0, i64 %223
  store i8 %221, i8* %224, align 1
  %225 = sext i32 %150 to i64
  %226 = getelementptr inbounds i8, i8* %0, i64 %225
  store i8 %221, i8* %226, align 1
  %227 = shl nuw nsw i32 %159, 1
  %228 = add nuw nsw i32 %148, 2
  %229 = add nuw nsw i32 %228, %227
  %230 = add nuw nsw i32 %229, %170
  %231 = lshr i32 %230, 2
  %232 = trunc i32 %231 to i8
  %233 = add nsw i32 %183, 1
  %234 = sext i32 %233 to i64
  %235 = getelementptr inbounds i8, i8* %0, i64 %234
  store i8 %232, i8* %235, align 1
  %236 = sext i32 %161 to i64
  %237 = getelementptr inbounds i8, i8* %0, i64 %236
  store i8 %232, i8* %237, align 1
  %238 = shl nuw nsw i32 %127, 1
  %239 = add nuw nsw i32 %217, %238
  %240 = add nuw nsw i32 %239, %199
  %241 = lshr i32 %240, 2
  %242 = trunc i32 %241 to i8
  %243 = add nsw i32 %172, 2
  %244 = sext i32 %243 to i64
  %245 = getelementptr inbounds i8, i8* %0, i64 %244
  store i8 %242, i8* %245, align 1
  %246 = or i32 %150, 1
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds i8, i8* %0, i64 %247
  store i8 %242, i8* %248, align 1
  %249 = sext i32 %129 to i64
  %250 = getelementptr inbounds i8, i8* %0, i64 %249
  store i8 %242, i8* %250, align 1
  %251 = shl nuw nsw i32 %138, 1
  %252 = add nuw nsw i32 %127, 2
  %253 = add nuw nsw i32 %252, %251
  %254 = add nuw nsw i32 %253, %148
  %255 = lshr i32 %254, 2
  %256 = trunc i32 %255 to i8
  %257 = add nsw i32 %183, 2
  %258 = sext i32 %257 to i64
  %259 = getelementptr inbounds i8, i8* %0, i64 %258
  store i8 %256, i8* %259, align 1
  %260 = add nsw i32 %161, 1
  %261 = sext i32 %260 to i64
  %262 = getelementptr inbounds i8, i8* %0, i64 %261
  store i8 %256, i8* %262, align 1
  %263 = sext i32 %140 to i64
  %264 = getelementptr inbounds i8, i8* %0, i64 %263
  store i8 %256, i8* %264, align 1
  %265 = shl nuw nsw i32 %199, 1
  %266 = add nuw nsw i32 %35, 2
  %267 = add nuw nsw i32 %266, %127
  %268 = add nuw nsw i32 %267, %265
  %269 = lshr i32 %268, 2
  %270 = trunc i32 %269 to i8
  %271 = add nsw i32 %183, 3
  %272 = sext i32 %271 to i64
  %273 = getelementptr inbounds i8, i8* %0, i64 %272
  store i8 %270, i8* %273, align 1
  %274 = add nsw i32 %161, 2
  %275 = sext i32 %274 to i64
  %276 = getelementptr inbounds i8, i8* %0, i64 %275
  store i8 %270, i8* %276, align 1
  %277 = add nsw i32 %140, 1
  %278 = sext i32 %277 to i64
  %279 = getelementptr inbounds i8, i8* %0, i64 %278
  store i8 %270, i8* %279, align 1
  %280 = getelementptr inbounds i8, i8* %0, i64 %109
  store i8 %270, i8* %280, align 1
  %281 = add nuw nsw i32 %35, 1
  %282 = add nuw nsw i32 %281, %199
  %283 = lshr i32 %282, 1
  %284 = trunc i32 %283 to i8
  %285 = add nsw i32 %172, 3
  %286 = sext i32 %285 to i64
  %287 = getelementptr inbounds i8, i8* %0, i64 %286
  store i8 %284, i8* %287, align 1
  %288 = or i32 %150, 2
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds i8, i8* %0, i64 %289
  store i8 %284, i8* %290, align 1
  %291 = or i32 %129, 1
  %292 = sext i32 %291 to i64
  %293 = getelementptr inbounds i8, i8* %0, i64 %292
  store i8 %284, i8* %293, align 1
  store i8 %284, i8* %0, align 1
  %294 = shl nuw nsw i32 %35, 1
  %295 = add nuw nsw i32 %45, 2
  %296 = add nuw nsw i32 %295, %294
  %297 = add nuw nsw i32 %296, %199
  %298 = lshr i32 %297, 2
  %299 = trunc i32 %298 to i8
  %300 = add nsw i32 %183, 4
  %301 = sext i32 %300 to i64
  %302 = getelementptr inbounds i8, i8* %0, i64 %301
  store i8 %299, i8* %302, align 1
  %303 = add nsw i32 %161, 3
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds i8, i8* %0, i64 %304
  store i8 %299, i8* %305, align 1
  %306 = add nsw i32 %140, 2
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i8, i8* %0, i64 %307
  store i8 %299, i8* %308, align 1
  %309 = add i64 %17, 4294967296
  %310 = ashr exact i64 %309, 32
  %311 = getelementptr inbounds i8, i8* %0, i64 %310
  store i8 %299, i8* %311, align 1
  %312 = add nuw nsw i32 %281, %45
  %313 = lshr i32 %312, 1
  %314 = trunc i32 %313 to i8
  %315 = add nsw i32 %172, 4
  %316 = sext i32 %315 to i64
  %317 = getelementptr inbounds i8, i8* %0, i64 %316
  store i8 %314, i8* %317, align 1
  %318 = or i32 %150, 3
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i8, i8* %0, i64 %319
  store i8 %314, i8* %320, align 1
  %321 = add nsw i32 %129, 2
  %322 = sext i32 %321 to i64
  %323 = getelementptr inbounds i8, i8* %0, i64 %322
  store i8 %314, i8* %323, align 1
  %324 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %314, i8* %324, align 1
  %325 = shl nuw nsw i32 %45, 1
  %326 = add nuw nsw i32 %266, %325
  %327 = add nuw nsw i32 %326, %54
  %328 = lshr i32 %327, 2
  %329 = trunc i32 %328 to i8
  %330 = add nsw i32 %183, 5
  %331 = sext i32 %330 to i64
  %332 = getelementptr inbounds i8, i8* %0, i64 %331
  store i8 %329, i8* %332, align 1
  %333 = add nsw i32 %161, 4
  %334 = sext i32 %333 to i64
  %335 = getelementptr inbounds i8, i8* %0, i64 %334
  store i8 %329, i8* %335, align 1
  %336 = add nsw i32 %140, 3
  %337 = sext i32 %336 to i64
  %338 = getelementptr inbounds i8, i8* %0, i64 %337
  store i8 %329, i8* %338, align 1
  %339 = add i64 %17, 8589934592
  %340 = ashr exact i64 %339, 32
  %341 = getelementptr inbounds i8, i8* %0, i64 %340
  store i8 %329, i8* %341, align 1
  %342 = add nuw nsw i32 %45, 1
  %343 = add nuw nsw i32 %342, %54
  %344 = lshr i32 %343, 1
  %345 = trunc i32 %344 to i8
  %346 = add nsw i32 %172, 5
  %347 = sext i32 %346 to i64
  %348 = getelementptr inbounds i8, i8* %0, i64 %347
  store i8 %345, i8* %348, align 1
  %349 = add nsw i32 %150, 4
  %350 = sext i32 %349 to i64
  %351 = getelementptr inbounds i8, i8* %0, i64 %350
  store i8 %345, i8* %351, align 1
  %352 = add nsw i32 %129, 3
  %353 = sext i32 %352 to i64
  %354 = getelementptr inbounds i8, i8* %0, i64 %353
  store i8 %345, i8* %354, align 1
  %355 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %345, i8* %355, align 1
  %356 = shl nuw nsw i32 %54, 1
  %357 = add nuw nsw i32 %295, %356
  %358 = add nuw nsw i32 %357, %64
  %359 = lshr i32 %358, 2
  %360 = trunc i32 %359 to i8
  %361 = add nsw i32 %183, 6
  %362 = sext i32 %361 to i64
  %363 = getelementptr inbounds i8, i8* %0, i64 %362
  store i8 %360, i8* %363, align 1
  %364 = add nsw i32 %161, 5
  %365 = sext i32 %364 to i64
  %366 = getelementptr inbounds i8, i8* %0, i64 %365
  store i8 %360, i8* %366, align 1
  %367 = add nsw i32 %140, 4
  %368 = sext i32 %367 to i64
  %369 = getelementptr inbounds i8, i8* %0, i64 %368
  store i8 %360, i8* %369, align 1
  %370 = add i64 %17, 12884901888
  %371 = ashr exact i64 %370, 32
  %372 = getelementptr inbounds i8, i8* %0, i64 %371
  store i8 %360, i8* %372, align 1
  %373 = add nuw nsw i32 %54, 1
  %374 = add nuw nsw i32 %373, %64
  %375 = lshr i32 %374, 1
  %376 = trunc i32 %375 to i8
  %377 = add nsw i32 %172, 6
  %378 = sext i32 %377 to i64
  %379 = getelementptr inbounds i8, i8* %0, i64 %378
  store i8 %376, i8* %379, align 1
  %380 = add nsw i32 %150, 5
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i8, i8* %0, i64 %381
  store i8 %376, i8* %382, align 1
  %383 = add nsw i32 %129, 4
  %384 = sext i32 %383 to i64
  %385 = getelementptr inbounds i8, i8* %0, i64 %384
  store i8 %376, i8* %385, align 1
  %386 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %376, i8* %386, align 1
  %387 = shl nuw nsw i32 %64, 1
  %388 = add nuw nsw i32 %54, 2
  %389 = add nuw nsw i32 %388, %387
  %390 = add nuw nsw i32 %389, %74
  %391 = lshr i32 %390, 2
  %392 = trunc i32 %391 to i8
  %393 = add nsw i32 %183, 7
  %394 = sext i32 %393 to i64
  %395 = getelementptr inbounds i8, i8* %0, i64 %394
  store i8 %392, i8* %395, align 1
  %396 = add nsw i32 %161, 6
  %397 = sext i32 %396 to i64
  %398 = getelementptr inbounds i8, i8* %0, i64 %397
  store i8 %392, i8* %398, align 1
  %399 = add nsw i32 %140, 5
  %400 = sext i32 %399 to i64
  %401 = getelementptr inbounds i8, i8* %0, i64 %400
  store i8 %392, i8* %401, align 1
  %402 = add i64 %17, 17179869184
  %403 = ashr exact i64 %402, 32
  %404 = getelementptr inbounds i8, i8* %0, i64 %403
  store i8 %392, i8* %404, align 1
  %405 = add nuw nsw i32 %64, 1
  %406 = add nuw nsw i32 %405, %74
  %407 = lshr i32 %406, 1
  %408 = trunc i32 %407 to i8
  %409 = add nsw i32 %172, 7
  %410 = sext i32 %409 to i64
  %411 = getelementptr inbounds i8, i8* %0, i64 %410
  store i8 %408, i8* %411, align 1
  %412 = add nsw i32 %150, 6
  %413 = sext i32 %412 to i64
  %414 = getelementptr inbounds i8, i8* %0, i64 %413
  store i8 %408, i8* %414, align 1
  %415 = add nsw i32 %129, 5
  %416 = sext i32 %415 to i64
  %417 = getelementptr inbounds i8, i8* %0, i64 %416
  store i8 %408, i8* %417, align 1
  %418 = getelementptr inbounds i8, i8* %0, i64 4
  store i8 %408, i8* %418, align 1
  %419 = shl nuw nsw i32 %74, 1
  %420 = add nuw nsw i32 %64, 2
  %421 = add nuw nsw i32 %420, %419
  %422 = add nuw nsw i32 %421, %84
  %423 = lshr i32 %422, 2
  %424 = trunc i32 %423 to i8
  %425 = add nsw i32 %161, 7
  %426 = sext i32 %425 to i64
  %427 = getelementptr inbounds i8, i8* %0, i64 %426
  store i8 %424, i8* %427, align 1
  %428 = add nsw i32 %140, 6
  %429 = sext i32 %428 to i64
  %430 = getelementptr inbounds i8, i8* %0, i64 %429
  store i8 %424, i8* %430, align 1
  %431 = add i64 %17, 21474836480
  %432 = ashr exact i64 %431, 32
  %433 = getelementptr inbounds i8, i8* %0, i64 %432
  store i8 %424, i8* %433, align 1
  %434 = add nuw nsw i32 %74, 1
  %435 = add nuw nsw i32 %434, %84
  %436 = lshr i32 %435, 1
  %437 = trunc i32 %436 to i8
  %438 = add nsw i32 %150, 7
  %439 = sext i32 %438 to i64
  %440 = getelementptr inbounds i8, i8* %0, i64 %439
  store i8 %437, i8* %440, align 1
  %441 = add nsw i32 %129, 6
  %442 = sext i32 %441 to i64
  %443 = getelementptr inbounds i8, i8* %0, i64 %442
  store i8 %437, i8* %443, align 1
  %444 = getelementptr inbounds i8, i8* %0, i64 5
  store i8 %437, i8* %444, align 1
  %445 = shl nuw nsw i32 %84, 1
  %446 = add nuw nsw i32 %74, 2
  %447 = add nuw nsw i32 %446, %445
  %448 = add nuw nsw i32 %447, %94
  %449 = lshr i32 %448, 2
  %450 = trunc i32 %449 to i8
  %451 = add nsw i32 %140, 7
  %452 = sext i32 %451 to i64
  %453 = getelementptr inbounds i8, i8* %0, i64 %452
  store i8 %450, i8* %453, align 1
  %454 = add i64 %17, 25769803776
  %455 = ashr exact i64 %454, 32
  %456 = getelementptr inbounds i8, i8* %0, i64 %455
  store i8 %450, i8* %456, align 1
  %457 = add nuw nsw i32 %84, 1
  %458 = add nuw nsw i32 %457, %94
  %459 = lshr i32 %458, 1
  %460 = trunc i32 %459 to i8
  %461 = add nsw i32 %129, 7
  %462 = sext i32 %461 to i64
  %463 = getelementptr inbounds i8, i8* %0, i64 %462
  store i8 %460, i8* %463, align 1
  %464 = getelementptr inbounds i8, i8* %0, i64 6
  store i8 %460, i8* %464, align 1
  %465 = shl nuw nsw i32 %94, 1
  %466 = add nuw nsw i32 %84, 2
  %467 = add nuw nsw i32 %466, %465
  %468 = add nuw nsw i32 %467, %108
  %469 = lshr i32 %468, 2
  %470 = trunc i32 %469 to i8
  %471 = add i64 %17, 30064771072
  %472 = ashr exact i64 %471, 32
  %473 = getelementptr inbounds i8, i8* %0, i64 %472
  store i8 %470, i8* %473, align 1
  %474 = add nuw nsw i32 %94, 1
  %475 = add nuw nsw i32 %474, %108
  %476 = lshr i32 %475, 1
  %477 = trunc i32 %476 to i8
  %478 = getelementptr inbounds i8, i8* %0, i64 7
  store i8 %477, i8* %478, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_down_8_c(i8*, i32, i32, i64) #1 {
  %5 = trunc i64 %3 to i32
  %6 = icmp ne i32 %1, 0
  %7 = sub nsw i32 0, %5
  br i1 %6, label %8, label %13

8:                                                ; preds = %4
  %9 = shl i64 %3, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = sext i32 %7 to i64
  br label %18

13:                                               ; preds = %4
  %14 = sext i32 %7 to i64
  %15 = shl i64 %3, 32
  %16 = ashr exact i64 %15, 32
  %17 = xor i64 %16, -1
  br label %18

18:                                               ; preds = %13, %8
  %19 = phi i64 [ %17, %13 ], [ %11, %8 ]
  %20 = phi i64 [ %16, %13 ], [ %10, %8 ]
  %21 = phi i64 [ %15, %13 ], [ %9, %8 ]
  %22 = phi i64 [ %14, %13 ], [ %12, %8 ]
  %23 = phi i64 [ %14, %13 ], [ %11, %8 ]
  %24 = getelementptr inbounds i8, i8* %0, i64 %23
  %25 = load i8, i8* %24, align 1
  %26 = zext i8 %25 to i32
  %27 = getelementptr inbounds i8, i8* %0, i64 %22
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i32
  %30 = shl nuw nsw i32 %29, 1
  %31 = sub i64 4294967296, %21
  %32 = ashr exact i64 %31, 32
  %33 = getelementptr inbounds i8, i8* %0, i64 %32
  %34 = load i8, i8* %33, align 1
  %35 = zext i8 %34 to i32
  %36 = add nuw nsw i32 %35, 2
  %37 = add nuw nsw i32 %36, %26
  %38 = add nuw nsw i32 %37, %30
  %39 = lshr i32 %38, 2
  %40 = shl nuw nsw i32 %35, 1
  %41 = sub i64 8589934592, %21
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds i8, i8* %0, i64 %42
  %44 = load i8, i8* %43, align 1
  %45 = zext i8 %44 to i32
  %46 = add nuw nsw i32 %29, 2
  %47 = add nuw nsw i32 %46, %40
  %48 = add nuw nsw i32 %47, %45
  %49 = lshr i32 %48, 2
  %50 = shl nuw nsw i32 %45, 1
  %51 = sub i64 12884901888, %21
  %52 = ashr exact i64 %51, 32
  %53 = getelementptr inbounds i8, i8* %0, i64 %52
  %54 = load i8, i8* %53, align 1
  %55 = zext i8 %54 to i32
  %56 = add nuw nsw i32 %36, %50
  %57 = add nuw nsw i32 %56, %55
  %58 = lshr i32 %57, 2
  %59 = shl nuw nsw i32 %55, 1
  %60 = sub i64 17179869184, %21
  %61 = ashr exact i64 %60, 32
  %62 = getelementptr inbounds i8, i8* %0, i64 %61
  %63 = load i8, i8* %62, align 1
  %64 = zext i8 %63 to i32
  %65 = add nuw nsw i32 %45, 2
  %66 = add nuw nsw i32 %65, %59
  %67 = add nuw nsw i32 %66, %64
  %68 = lshr i32 %67, 2
  %69 = shl nuw nsw i32 %64, 1
  %70 = sub i64 21474836480, %21
  %71 = ashr exact i64 %70, 32
  %72 = getelementptr inbounds i8, i8* %0, i64 %71
  %73 = load i8, i8* %72, align 1
  %74 = zext i8 %73 to i32
  %75 = add nuw nsw i32 %55, 2
  %76 = add nuw nsw i32 %75, %69
  %77 = add nuw nsw i32 %76, %74
  %78 = lshr i32 %77, 2
  %79 = shl nuw nsw i32 %74, 1
  %80 = sub i64 25769803776, %21
  %81 = ashr exact i64 %80, 32
  %82 = getelementptr inbounds i8, i8* %0, i64 %81
  %83 = load i8, i8* %82, align 1
  %84 = zext i8 %83 to i32
  %85 = add nuw nsw i32 %64, 2
  %86 = add nuw nsw i32 %85, %79
  %87 = add nuw nsw i32 %86, %84
  %88 = lshr i32 %87, 2
  %89 = shl nuw nsw i32 %84, 1
  %90 = sub i64 30064771072, %21
  %91 = ashr exact i64 %90, 32
  %92 = getelementptr inbounds i8, i8* %0, i64 %91
  %93 = load i8, i8* %92, align 1
  %94 = zext i8 %93 to i32
  %95 = add nuw nsw i32 %74, 2
  %96 = add nuw nsw i32 %95, %89
  %97 = add nuw nsw i32 %96, %94
  %98 = lshr i32 %97, 2
  %99 = select i1 %6, i64 %19, i64 -1
  %100 = getelementptr inbounds i8, i8* %0, i64 %99
  %101 = load i8, i8* %100, align 1
  %102 = zext i8 %101 to i32
  %103 = getelementptr inbounds i8, i8* %0, i64 -1
  %104 = load i8, i8* %103, align 1
  %105 = zext i8 %104 to i32
  %106 = shl nuw nsw i32 %105, 1
  %107 = add i64 %21, -4294967296
  %108 = ashr exact i64 %107, 32
  %109 = getelementptr inbounds i8, i8* %0, i64 %108
  %110 = load i8, i8* %109, align 1
  %111 = zext i8 %110 to i32
  %112 = add nuw nsw i32 %111, 2
  %113 = add nuw nsw i32 %112, %102
  %114 = add nuw nsw i32 %113, %106
  %115 = lshr i32 %114, 2
  %116 = shl nuw nsw i32 %111, 1
  %117 = shl nsw i32 %5, 1
  %118 = add nsw i32 %117, -1
  %119 = sext i32 %118 to i64
  %120 = getelementptr inbounds i8, i8* %0, i64 %119
  %121 = load i8, i8* %120, align 1
  %122 = zext i8 %121 to i32
  %123 = add nuw nsw i32 %105, 2
  %124 = add nuw nsw i32 %123, %116
  %125 = add nuw nsw i32 %124, %122
  %126 = lshr i32 %125, 2
  %127 = shl nuw nsw i32 %122, 1
  %128 = mul nsw i32 %5, 3
  %129 = add nsw i32 %128, -1
  %130 = sext i32 %129 to i64
  %131 = getelementptr inbounds i8, i8* %0, i64 %130
  %132 = load i8, i8* %131, align 1
  %133 = zext i8 %132 to i32
  %134 = add nuw nsw i32 %112, %127
  %135 = add nuw nsw i32 %134, %133
  %136 = lshr i32 %135, 2
  %137 = shl nuw nsw i32 %133, 1
  %138 = shl nsw i32 %5, 2
  %139 = add nsw i32 %138, -1
  %140 = sext i32 %139 to i64
  %141 = getelementptr inbounds i8, i8* %0, i64 %140
  %142 = load i8, i8* %141, align 1
  %143 = zext i8 %142 to i32
  %144 = add nuw nsw i32 %122, 2
  %145 = add nuw nsw i32 %144, %137
  %146 = add nuw nsw i32 %145, %143
  %147 = lshr i32 %146, 2
  %148 = shl nuw nsw i32 %143, 1
  %149 = mul nsw i32 %5, 5
  %150 = add nsw i32 %149, -1
  %151 = sext i32 %150 to i64
  %152 = getelementptr inbounds i8, i8* %0, i64 %151
  %153 = load i8, i8* %152, align 1
  %154 = zext i8 %153 to i32
  %155 = add nuw nsw i32 %133, 2
  %156 = add nuw nsw i32 %155, %148
  %157 = add nuw nsw i32 %156, %154
  %158 = lshr i32 %157, 2
  %159 = shl nuw nsw i32 %154, 1
  %160 = mul nsw i32 %5, 6
  %161 = add nsw i32 %160, -1
  %162 = sext i32 %161 to i64
  %163 = getelementptr inbounds i8, i8* %0, i64 %162
  %164 = load i8, i8* %163, align 1
  %165 = zext i8 %164 to i32
  %166 = add nuw nsw i32 %143, 2
  %167 = add nuw nsw i32 %166, %159
  %168 = add nuw nsw i32 %167, %165
  %169 = lshr i32 %168, 2
  %170 = shl nuw nsw i32 %165, 1
  %171 = mul nsw i32 %5, 7
  %172 = add nsw i32 %171, -1
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds i8, i8* %0, i64 %173
  %175 = load i8, i8* %174, align 1
  %176 = zext i8 %175 to i32
  %177 = add nuw nsw i32 %154, 2
  %178 = add nuw nsw i32 %177, %170
  %179 = add nuw nsw i32 %178, %176
  %180 = lshr i32 %179, 2
  %181 = mul nuw nsw i32 %176, 3
  %182 = add nuw nsw i32 %165, 2
  %183 = add nuw nsw i32 %182, %181
  %184 = lshr i32 %183, 2
  %185 = getelementptr inbounds i8, i8* %0, i64 %19
  %186 = load i8, i8* %185, align 1
  %187 = zext i8 %186 to i32
  %188 = shl nuw nsw i32 %187, 1
  %189 = add nuw nsw i32 %46, %105
  %190 = add nuw nsw i32 %189, %188
  %191 = lshr i32 %190, 2
  %192 = add nuw nsw i32 %180, 1
  %193 = add nuw nsw i32 %192, %184
  %194 = lshr i32 %193, 1
  %195 = trunc i32 %194 to i8
  %196 = sext i32 %171 to i64
  %197 = getelementptr inbounds i8, i8* %0, i64 %196
  store i8 %195, i8* %197, align 1
  %198 = shl nuw nsw i32 %180, 1
  %199 = add nuw nsw i32 %169, 2
  %200 = add nuw nsw i32 %199, %184
  %201 = add nuw nsw i32 %200, %198
  %202 = lshr i32 %201, 2
  %203 = trunc i32 %202 to i8
  %204 = add nsw i32 %171, 1
  %205 = sext i32 %204 to i64
  %206 = getelementptr inbounds i8, i8* %0, i64 %205
  store i8 %203, i8* %206, align 1
  %207 = add nuw nsw i32 %169, 1
  %208 = add nuw nsw i32 %207, %180
  %209 = lshr i32 %208, 1
  %210 = trunc i32 %209 to i8
  %211 = add nsw i32 %171, 2
  %212 = sext i32 %211 to i64
  %213 = getelementptr inbounds i8, i8* %0, i64 %212
  store i8 %210, i8* %213, align 1
  %214 = sext i32 %160 to i64
  %215 = getelementptr inbounds i8, i8* %0, i64 %214
  store i8 %210, i8* %215, align 1
  %216 = shl nuw nsw i32 %169, 1
  %217 = add nuw nsw i32 %158, 2
  %218 = add nuw nsw i32 %217, %216
  %219 = add nuw nsw i32 %218, %180
  %220 = lshr i32 %219, 2
  %221 = trunc i32 %220 to i8
  %222 = add nsw i32 %171, 3
  %223 = sext i32 %222 to i64
  %224 = getelementptr inbounds i8, i8* %0, i64 %223
  store i8 %221, i8* %224, align 1
  %225 = or i32 %160, 1
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds i8, i8* %0, i64 %226
  store i8 %221, i8* %227, align 1
  %228 = add nuw nsw i32 %158, 1
  %229 = add nuw nsw i32 %228, %169
  %230 = lshr i32 %229, 1
  %231 = trunc i32 %230 to i8
  %232 = add nsw i32 %171, 4
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds i8, i8* %0, i64 %233
  store i8 %231, i8* %234, align 1
  %235 = add nsw i32 %160, 2
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds i8, i8* %0, i64 %236
  store i8 %231, i8* %237, align 1
  %238 = sext i32 %149 to i64
  %239 = getelementptr inbounds i8, i8* %0, i64 %238
  store i8 %231, i8* %239, align 1
  %240 = shl nuw nsw i32 %158, 1
  %241 = add nuw nsw i32 %147, 2
  %242 = add nuw nsw i32 %241, %240
  %243 = add nuw nsw i32 %242, %169
  %244 = lshr i32 %243, 2
  %245 = trunc i32 %244 to i8
  %246 = add nsw i32 %171, 5
  %247 = sext i32 %246 to i64
  %248 = getelementptr inbounds i8, i8* %0, i64 %247
  store i8 %245, i8* %248, align 1
  %249 = add nsw i32 %160, 3
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds i8, i8* %0, i64 %250
  store i8 %245, i8* %251, align 1
  %252 = add nsw i32 %149, 1
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i8, i8* %0, i64 %253
  store i8 %245, i8* %254, align 1
  %255 = add nuw nsw i32 %147, 1
  %256 = add nuw nsw i32 %255, %158
  %257 = lshr i32 %256, 1
  %258 = trunc i32 %257 to i8
  %259 = add nsw i32 %171, 6
  %260 = sext i32 %259 to i64
  %261 = getelementptr inbounds i8, i8* %0, i64 %260
  store i8 %258, i8* %261, align 1
  %262 = add nsw i32 %160, 4
  %263 = sext i32 %262 to i64
  %264 = getelementptr inbounds i8, i8* %0, i64 %263
  store i8 %258, i8* %264, align 1
  %265 = add nsw i32 %149, 2
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds i8, i8* %0, i64 %266
  store i8 %258, i8* %267, align 1
  %268 = sext i32 %138 to i64
  %269 = getelementptr inbounds i8, i8* %0, i64 %268
  store i8 %258, i8* %269, align 1
  %270 = shl nuw nsw i32 %147, 1
  %271 = add nuw nsw i32 %136, 2
  %272 = add nuw nsw i32 %271, %270
  %273 = add nuw nsw i32 %272, %158
  %274 = lshr i32 %273, 2
  %275 = trunc i32 %274 to i8
  %276 = add nsw i32 %171, 7
  %277 = sext i32 %276 to i64
  %278 = getelementptr inbounds i8, i8* %0, i64 %277
  store i8 %275, i8* %278, align 1
  %279 = add nsw i32 %160, 5
  %280 = sext i32 %279 to i64
  %281 = getelementptr inbounds i8, i8* %0, i64 %280
  store i8 %275, i8* %281, align 1
  %282 = add nsw i32 %149, 3
  %283 = sext i32 %282 to i64
  %284 = getelementptr inbounds i8, i8* %0, i64 %283
  store i8 %275, i8* %284, align 1
  %285 = or i32 %138, 1
  %286 = sext i32 %285 to i64
  %287 = getelementptr inbounds i8, i8* %0, i64 %286
  store i8 %275, i8* %287, align 1
  %288 = add nuw nsw i32 %136, 1
  %289 = add nuw nsw i32 %288, %147
  %290 = lshr i32 %289, 1
  %291 = trunc i32 %290 to i8
  %292 = add nsw i32 %160, 6
  %293 = sext i32 %292 to i64
  %294 = getelementptr inbounds i8, i8* %0, i64 %293
  store i8 %291, i8* %294, align 1
  %295 = add nsw i32 %149, 4
  %296 = sext i32 %295 to i64
  %297 = getelementptr inbounds i8, i8* %0, i64 %296
  store i8 %291, i8* %297, align 1
  %298 = or i32 %138, 2
  %299 = sext i32 %298 to i64
  %300 = getelementptr inbounds i8, i8* %0, i64 %299
  store i8 %291, i8* %300, align 1
  %301 = sext i32 %128 to i64
  %302 = getelementptr inbounds i8, i8* %0, i64 %301
  store i8 %291, i8* %302, align 1
  %303 = shl nuw nsw i32 %136, 1
  %304 = add nuw nsw i32 %126, 2
  %305 = add nuw nsw i32 %304, %303
  %306 = add nuw nsw i32 %305, %147
  %307 = lshr i32 %306, 2
  %308 = trunc i32 %307 to i8
  %309 = add nsw i32 %160, 7
  %310 = sext i32 %309 to i64
  %311 = getelementptr inbounds i8, i8* %0, i64 %310
  store i8 %308, i8* %311, align 1
  %312 = add nsw i32 %149, 5
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds i8, i8* %0, i64 %313
  store i8 %308, i8* %314, align 1
  %315 = or i32 %138, 3
  %316 = sext i32 %315 to i64
  %317 = getelementptr inbounds i8, i8* %0, i64 %316
  store i8 %308, i8* %317, align 1
  %318 = add nsw i32 %128, 1
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i8, i8* %0, i64 %319
  store i8 %308, i8* %320, align 1
  %321 = add nuw nsw i32 %126, 1
  %322 = add nuw nsw i32 %321, %136
  %323 = lshr i32 %322, 1
  %324 = trunc i32 %323 to i8
  %325 = add nsw i32 %149, 6
  %326 = sext i32 %325 to i64
  %327 = getelementptr inbounds i8, i8* %0, i64 %326
  store i8 %324, i8* %327, align 1
  %328 = add nsw i32 %138, 4
  %329 = sext i32 %328 to i64
  %330 = getelementptr inbounds i8, i8* %0, i64 %329
  store i8 %324, i8* %330, align 1
  %331 = add nsw i32 %128, 2
  %332 = sext i32 %331 to i64
  %333 = getelementptr inbounds i8, i8* %0, i64 %332
  store i8 %324, i8* %333, align 1
  %334 = sext i32 %117 to i64
  %335 = getelementptr inbounds i8, i8* %0, i64 %334
  store i8 %324, i8* %335, align 1
  %336 = shl nuw nsw i32 %126, 1
  %337 = add nuw nsw i32 %115, 2
  %338 = add nuw nsw i32 %337, %336
  %339 = add nuw nsw i32 %338, %136
  %340 = lshr i32 %339, 2
  %341 = trunc i32 %340 to i8
  %342 = add nsw i32 %149, 7
  %343 = sext i32 %342 to i64
  %344 = getelementptr inbounds i8, i8* %0, i64 %343
  store i8 %341, i8* %344, align 1
  %345 = add nsw i32 %138, 5
  %346 = sext i32 %345 to i64
  %347 = getelementptr inbounds i8, i8* %0, i64 %346
  store i8 %341, i8* %347, align 1
  %348 = add nsw i32 %128, 3
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i8, i8* %0, i64 %349
  store i8 %341, i8* %350, align 1
  %351 = or i32 %117, 1
  %352 = sext i32 %351 to i64
  %353 = getelementptr inbounds i8, i8* %0, i64 %352
  store i8 %341, i8* %353, align 1
  %354 = add nuw nsw i32 %115, 1
  %355 = add nuw nsw i32 %354, %126
  %356 = lshr i32 %355, 1
  %357 = trunc i32 %356 to i8
  %358 = add nsw i32 %138, 6
  %359 = sext i32 %358 to i64
  %360 = getelementptr inbounds i8, i8* %0, i64 %359
  store i8 %357, i8* %360, align 1
  %361 = add nsw i32 %128, 4
  %362 = sext i32 %361 to i64
  %363 = getelementptr inbounds i8, i8* %0, i64 %362
  store i8 %357, i8* %363, align 1
  %364 = add nsw i32 %117, 2
  %365 = sext i32 %364 to i64
  %366 = getelementptr inbounds i8, i8* %0, i64 %365
  store i8 %357, i8* %366, align 1
  %367 = getelementptr inbounds i8, i8* %0, i64 %20
  store i8 %357, i8* %367, align 1
  %368 = shl nuw nsw i32 %115, 1
  %369 = add nuw nsw i32 %304, %368
  %370 = add nuw nsw i32 %369, %191
  %371 = lshr i32 %370, 2
  %372 = trunc i32 %371 to i8
  %373 = add nsw i32 %138, 7
  %374 = sext i32 %373 to i64
  %375 = getelementptr inbounds i8, i8* %0, i64 %374
  store i8 %372, i8* %375, align 1
  %376 = add nsw i32 %128, 5
  %377 = sext i32 %376 to i64
  %378 = getelementptr inbounds i8, i8* %0, i64 %377
  store i8 %372, i8* %378, align 1
  %379 = add nsw i32 %117, 3
  %380 = sext i32 %379 to i64
  %381 = getelementptr inbounds i8, i8* %0, i64 %380
  store i8 %372, i8* %381, align 1
  %382 = add i64 %21, 4294967296
  %383 = ashr exact i64 %382, 32
  %384 = getelementptr inbounds i8, i8* %0, i64 %383
  store i8 %372, i8* %384, align 1
  %385 = add nuw nsw i32 %354, %191
  %386 = lshr i32 %385, 1
  %387 = trunc i32 %386 to i8
  %388 = add nsw i32 %128, 6
  %389 = sext i32 %388 to i64
  %390 = getelementptr inbounds i8, i8* %0, i64 %389
  store i8 %387, i8* %390, align 1
  %391 = add nsw i32 %117, 4
  %392 = sext i32 %391 to i64
  %393 = getelementptr inbounds i8, i8* %0, i64 %392
  store i8 %387, i8* %393, align 1
  %394 = add i64 %21, 8589934592
  %395 = ashr exact i64 %394, 32
  %396 = getelementptr inbounds i8, i8* %0, i64 %395
  store i8 %387, i8* %396, align 1
  store i8 %387, i8* %0, align 1
  %397 = shl nuw nsw i32 %191, 1
  %398 = add nuw nsw i32 %39, 2
  %399 = add nuw nsw i32 %398, %115
  %400 = add nuw nsw i32 %399, %397
  %401 = lshr i32 %400, 2
  %402 = trunc i32 %401 to i8
  %403 = add nsw i32 %128, 7
  %404 = sext i32 %403 to i64
  %405 = getelementptr inbounds i8, i8* %0, i64 %404
  store i8 %402, i8* %405, align 1
  %406 = add nsw i32 %117, 5
  %407 = sext i32 %406 to i64
  %408 = getelementptr inbounds i8, i8* %0, i64 %407
  store i8 %402, i8* %408, align 1
  %409 = add i64 %21, 12884901888
  %410 = ashr exact i64 %409, 32
  %411 = getelementptr inbounds i8, i8* %0, i64 %410
  store i8 %402, i8* %411, align 1
  %412 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %402, i8* %412, align 1
  %413 = shl nuw nsw i32 %39, 1
  %414 = add nuw nsw i32 %49, 2
  %415 = add nuw nsw i32 %414, %413
  %416 = add nuw nsw i32 %415, %191
  %417 = lshr i32 %416, 2
  %418 = trunc i32 %417 to i8
  %419 = add nsw i32 %117, 6
  %420 = sext i32 %419 to i64
  %421 = getelementptr inbounds i8, i8* %0, i64 %420
  store i8 %418, i8* %421, align 1
  %422 = add i64 %21, 17179869184
  %423 = ashr exact i64 %422, 32
  %424 = getelementptr inbounds i8, i8* %0, i64 %423
  store i8 %418, i8* %424, align 1
  %425 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %418, i8* %425, align 1
  %426 = shl nuw nsw i32 %49, 1
  %427 = add nuw nsw i32 %398, %426
  %428 = add nuw nsw i32 %427, %58
  %429 = lshr i32 %428, 2
  %430 = trunc i32 %429 to i8
  %431 = add nsw i32 %117, 7
  %432 = sext i32 %431 to i64
  %433 = getelementptr inbounds i8, i8* %0, i64 %432
  store i8 %430, i8* %433, align 1
  %434 = add i64 %21, 21474836480
  %435 = ashr exact i64 %434, 32
  %436 = getelementptr inbounds i8, i8* %0, i64 %435
  store i8 %430, i8* %436, align 1
  %437 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %430, i8* %437, align 1
  %438 = shl nuw nsw i32 %58, 1
  %439 = add nuw nsw i32 %414, %438
  %440 = add nuw nsw i32 %439, %68
  %441 = lshr i32 %440, 2
  %442 = trunc i32 %441 to i8
  %443 = add i64 %21, 25769803776
  %444 = ashr exact i64 %443, 32
  %445 = getelementptr inbounds i8, i8* %0, i64 %444
  store i8 %442, i8* %445, align 1
  %446 = getelementptr inbounds i8, i8* %0, i64 4
  store i8 %442, i8* %446, align 1
  %447 = shl nuw nsw i32 %68, 1
  %448 = add nuw nsw i32 %58, 2
  %449 = add nuw nsw i32 %448, %447
  %450 = add nuw nsw i32 %449, %78
  %451 = lshr i32 %450, 2
  %452 = trunc i32 %451 to i8
  %453 = add i64 %21, 30064771072
  %454 = ashr exact i64 %453, 32
  %455 = getelementptr inbounds i8, i8* %0, i64 %454
  store i8 %452, i8* %455, align 1
  %456 = getelementptr inbounds i8, i8* %0, i64 5
  store i8 %452, i8* %456, align 1
  %457 = shl nuw nsw i32 %78, 1
  %458 = add nuw nsw i32 %68, 2
  %459 = add nuw nsw i32 %458, %457
  %460 = add nuw nsw i32 %459, %88
  %461 = lshr i32 %460, 2
  %462 = trunc i32 %461 to i8
  %463 = getelementptr inbounds i8, i8* %0, i64 6
  store i8 %462, i8* %463, align 1
  %464 = shl nuw nsw i32 %88, 1
  %465 = add nuw nsw i32 %78, 2
  %466 = add nuw nsw i32 %465, %464
  %467 = add nuw nsw i32 %466, %98
  %468 = lshr i32 %467, 2
  %469 = trunc i32 %468 to i8
  %470 = getelementptr inbounds i8, i8* %0, i64 7
  store i8 %469, i8* %470, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_vertical_left_8_c(i8*, i32, i32, i64) #1 {
  %5 = trunc i64 %3 to i32
  %6 = icmp eq i32 %1, 0
  %7 = sub nsw i32 0, %5
  br i1 %6, label %13, label %8

8:                                                ; preds = %4
  %9 = shl i64 %3, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = sext i32 %7 to i64
  br label %16

13:                                               ; preds = %4
  %14 = sext i32 %7 to i64
  %15 = shl i64 %3, 32
  br label %16

16:                                               ; preds = %13, %8
  %17 = phi i64 [ %15, %13 ], [ %9, %8 ]
  %18 = phi i64 [ %14, %13 ], [ %12, %8 ]
  %19 = phi i64 [ %14, %13 ], [ %11, %8 ]
  %20 = getelementptr inbounds i8, i8* %0, i64 %19
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  %23 = getelementptr inbounds i8, i8* %0, i64 %18
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = shl nuw nsw i32 %25, 1
  %27 = sub i64 4294967296, %17
  %28 = ashr exact i64 %27, 32
  %29 = getelementptr inbounds i8, i8* %0, i64 %28
  %30 = load i8, i8* %29, align 1
  %31 = zext i8 %30 to i32
  %32 = add nuw nsw i32 %31, 2
  %33 = add nuw nsw i32 %32, %22
  %34 = add nuw nsw i32 %33, %26
  %35 = lshr i32 %34, 2
  %36 = shl nuw nsw i32 %31, 1
  %37 = sub i64 8589934592, %17
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i32
  %42 = add nuw nsw i32 %41, 2
  %43 = add nuw nsw i32 %42, %25
  %44 = add nuw nsw i32 %43, %36
  %45 = lshr i32 %44, 2
  %46 = shl nuw nsw i32 %41, 1
  %47 = sub i64 12884901888, %17
  %48 = ashr exact i64 %47, 32
  %49 = getelementptr inbounds i8, i8* %0, i64 %48
  %50 = load i8, i8* %49, align 1
  %51 = zext i8 %50 to i32
  %52 = add nuw nsw i32 %32, %46
  %53 = add nuw nsw i32 %52, %51
  %54 = lshr i32 %53, 2
  %55 = shl nuw nsw i32 %51, 1
  %56 = sub i64 17179869184, %17
  %57 = ashr exact i64 %56, 32
  %58 = getelementptr inbounds i8, i8* %0, i64 %57
  %59 = load i8, i8* %58, align 1
  %60 = zext i8 %59 to i32
  %61 = add nuw nsw i32 %42, %55
  %62 = add nuw nsw i32 %61, %60
  %63 = lshr i32 %62, 2
  %64 = shl nuw nsw i32 %60, 1
  %65 = sub i64 21474836480, %17
  %66 = ashr exact i64 %65, 32
  %67 = getelementptr inbounds i8, i8* %0, i64 %66
  %68 = load i8, i8* %67, align 1
  %69 = zext i8 %68 to i32
  %70 = add nuw nsw i32 %51, 2
  %71 = add nuw nsw i32 %70, %64
  %72 = add nuw nsw i32 %71, %69
  %73 = lshr i32 %72, 2
  %74 = shl nuw nsw i32 %69, 1
  %75 = sub i64 25769803776, %17
  %76 = ashr exact i64 %75, 32
  %77 = getelementptr inbounds i8, i8* %0, i64 %76
  %78 = load i8, i8* %77, align 1
  %79 = zext i8 %78 to i32
  %80 = add nuw nsw i32 %60, 2
  %81 = add nuw nsw i32 %80, %74
  %82 = add nuw nsw i32 %81, %79
  %83 = lshr i32 %82, 2
  %84 = shl nuw nsw i32 %79, 1
  %85 = sub i64 30064771072, %17
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = load i8, i8* %87, align 1
  %89 = zext i8 %88 to i32
  %90 = add nuw nsw i32 %69, 2
  %91 = add nuw nsw i32 %90, %84
  %92 = add nuw nsw i32 %91, %89
  %93 = lshr i32 %92, 2
  %94 = icmp eq i32 %2, 0
  br i1 %94, label %95, label %97

95:                                               ; preds = %16
  %96 = mul nuw nsw i32 %89, 3
  br label %154

97:                                               ; preds = %16
  %98 = sub i64 34359738368, %17
  %99 = ashr exact i64 %98, 32
  %100 = getelementptr inbounds i8, i8* %0, i64 %99
  %101 = load i8, i8* %100, align 1
  %102 = zext i8 %101 to i32
  %103 = shl nuw nsw i32 %89, 1
  %104 = add nuw nsw i32 %103, %102
  %105 = shl nuw nsw i32 %102, 1
  %106 = sub i64 38654705664, %17
  %107 = ashr exact i64 %106, 32
  %108 = getelementptr inbounds i8, i8* %0, i64 %107
  %109 = load i8, i8* %108, align 1
  %110 = zext i8 %109 to i32
  %111 = add nuw nsw i32 %89, 2
  %112 = add nuw nsw i32 %111, %105
  %113 = add nuw nsw i32 %112, %110
  %114 = lshr i32 %113, 2
  %115 = shl nuw nsw i32 %110, 1
  %116 = sub i64 42949672960, %17
  %117 = ashr exact i64 %116, 32
  %118 = getelementptr inbounds i8, i8* %0, i64 %117
  %119 = load i8, i8* %118, align 1
  %120 = zext i8 %119 to i32
  %121 = add nuw nsw i32 %120, 2
  %122 = add nuw nsw i32 %121, %102
  %123 = add nuw nsw i32 %122, %115
  %124 = lshr i32 %123, 2
  %125 = shl nuw nsw i32 %120, 1
  %126 = sub i64 47244640256, %17
  %127 = ashr exact i64 %126, 32
  %128 = getelementptr inbounds i8, i8* %0, i64 %127
  %129 = load i8, i8* %128, align 1
  %130 = zext i8 %129 to i32
  %131 = add nuw nsw i32 %110, 2
  %132 = add nuw nsw i32 %131, %125
  %133 = add nuw nsw i32 %132, %130
  %134 = lshr i32 %133, 2
  %135 = shl nuw nsw i32 %130, 1
  %136 = sub i64 51539607552, %17
  %137 = ashr exact i64 %136, 32
  %138 = getelementptr inbounds i8, i8* %0, i64 %137
  %139 = load i8, i8* %138, align 1
  %140 = zext i8 %139 to i32
  %141 = add nuw nsw i32 %121, %135
  %142 = add nuw nsw i32 %141, %140
  %143 = lshr i32 %142, 2
  %144 = shl nuw nsw i32 %140, 1
  %145 = sub i64 55834574848, %17
  %146 = ashr exact i64 %145, 32
  %147 = getelementptr inbounds i8, i8* %0, i64 %146
  %148 = load i8, i8* %147, align 1
  %149 = zext i8 %148 to i32
  %150 = add nuw nsw i32 %130, 2
  %151 = add nuw nsw i32 %150, %144
  %152 = add nuw nsw i32 %151, %149
  %153 = lshr i32 %152, 2
  br label %154

154:                                              ; preds = %95, %97
  %155 = phi i32 [ %104, %97 ], [ %96, %95 ]
  %156 = phi i32 [ %114, %97 ], [ %89, %95 ]
  %157 = phi i32 [ %124, %97 ], [ %89, %95 ]
  %158 = phi i32 [ %134, %97 ], [ %89, %95 ]
  %159 = phi i32 [ %143, %97 ], [ %89, %95 ]
  %160 = phi i32 [ %153, %97 ], [ %89, %95 ]
  %161 = add nuw nsw i32 %79, 2
  %162 = add nuw nsw i32 %161, %155
  %163 = lshr i32 %162, 2
  %164 = add nuw nsw i32 %45, 1
  %165 = add nuw nsw i32 %164, %35
  %166 = lshr i32 %165, 1
  %167 = trunc i32 %166 to i8
  store i8 %167, i8* %0, align 1
  %168 = shl nuw nsw i32 %45, 1
  %169 = add nuw nsw i32 %54, 2
  %170 = add nuw nsw i32 %169, %35
  %171 = add nuw nsw i32 %170, %168
  %172 = lshr i32 %171, 2
  %173 = trunc i32 %172 to i8
  %174 = ashr exact i64 %17, 32
  %175 = getelementptr inbounds i8, i8* %0, i64 %174
  store i8 %173, i8* %175, align 1
  %176 = add nuw nsw i32 %164, %54
  %177 = lshr i32 %176, 1
  %178 = trunc i32 %177 to i8
  %179 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %178, i8* %179, align 1
  %180 = shl nsw i32 %5, 1
  %181 = sext i32 %180 to i64
  %182 = getelementptr inbounds i8, i8* %0, i64 %181
  store i8 %178, i8* %182, align 1
  %183 = shl nuw nsw i32 %54, 1
  %184 = add nuw nsw i32 %63, 2
  %185 = add nuw nsw i32 %184, %45
  %186 = add nuw nsw i32 %185, %183
  %187 = lshr i32 %186, 2
  %188 = trunc i32 %187 to i8
  %189 = add i64 %17, 4294967296
  %190 = ashr exact i64 %189, 32
  %191 = getelementptr inbounds i8, i8* %0, i64 %190
  store i8 %188, i8* %191, align 1
  %192 = mul nsw i32 %5, 3
  %193 = sext i32 %192 to i64
  %194 = getelementptr inbounds i8, i8* %0, i64 %193
  store i8 %188, i8* %194, align 1
  %195 = add nuw nsw i32 %54, 1
  %196 = add nuw nsw i32 %195, %63
  %197 = lshr i32 %196, 1
  %198 = trunc i32 %197 to i8
  %199 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %198, i8* %199, align 1
  %200 = or i32 %180, 1
  %201 = sext i32 %200 to i64
  %202 = getelementptr inbounds i8, i8* %0, i64 %201
  store i8 %198, i8* %202, align 1
  %203 = shl nsw i32 %5, 2
  %204 = sext i32 %203 to i64
  %205 = getelementptr inbounds i8, i8* %0, i64 %204
  store i8 %198, i8* %205, align 1
  %206 = shl nuw nsw i32 %63, 1
  %207 = add nuw nsw i32 %169, %206
  %208 = add nuw nsw i32 %207, %73
  %209 = lshr i32 %208, 2
  %210 = trunc i32 %209 to i8
  %211 = add i64 %17, 8589934592
  %212 = ashr exact i64 %211, 32
  %213 = getelementptr inbounds i8, i8* %0, i64 %212
  store i8 %210, i8* %213, align 1
  %214 = add nsw i32 %192, 1
  %215 = sext i32 %214 to i64
  %216 = getelementptr inbounds i8, i8* %0, i64 %215
  store i8 %210, i8* %216, align 1
  %217 = mul nsw i32 %5, 5
  %218 = sext i32 %217 to i64
  %219 = getelementptr inbounds i8, i8* %0, i64 %218
  store i8 %210, i8* %219, align 1
  %220 = add nuw nsw i32 %63, 1
  %221 = add nuw nsw i32 %220, %73
  %222 = lshr i32 %221, 1
  %223 = trunc i32 %222 to i8
  %224 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %223, i8* %224, align 1
  %225 = add nsw i32 %180, 2
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds i8, i8* %0, i64 %226
  store i8 %223, i8* %227, align 1
  %228 = or i32 %203, 1
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds i8, i8* %0, i64 %229
  store i8 %223, i8* %230, align 1
  %231 = mul nsw i32 %5, 6
  %232 = sext i32 %231 to i64
  %233 = getelementptr inbounds i8, i8* %0, i64 %232
  store i8 %223, i8* %233, align 1
  %234 = shl nuw nsw i32 %73, 1
  %235 = add nuw nsw i32 %184, %234
  %236 = add nuw nsw i32 %235, %83
  %237 = lshr i32 %236, 2
  %238 = trunc i32 %237 to i8
  %239 = add i64 %17, 12884901888
  %240 = ashr exact i64 %239, 32
  %241 = getelementptr inbounds i8, i8* %0, i64 %240
  store i8 %238, i8* %241, align 1
  %242 = add nsw i32 %192, 2
  %243 = sext i32 %242 to i64
  %244 = getelementptr inbounds i8, i8* %0, i64 %243
  store i8 %238, i8* %244, align 1
  %245 = add nsw i32 %217, 1
  %246 = sext i32 %245 to i64
  %247 = getelementptr inbounds i8, i8* %0, i64 %246
  store i8 %238, i8* %247, align 1
  %248 = mul nsw i32 %5, 7
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %0, i64 %249
  store i8 %238, i8* %250, align 1
  %251 = add nuw nsw i32 %73, 1
  %252 = add nuw nsw i32 %251, %83
  %253 = lshr i32 %252, 1
  %254 = trunc i32 %253 to i8
  %255 = getelementptr inbounds i8, i8* %0, i64 4
  store i8 %254, i8* %255, align 1
  %256 = add nsw i32 %180, 3
  %257 = sext i32 %256 to i64
  %258 = getelementptr inbounds i8, i8* %0, i64 %257
  store i8 %254, i8* %258, align 1
  %259 = or i32 %203, 2
  %260 = sext i32 %259 to i64
  %261 = getelementptr inbounds i8, i8* %0, i64 %260
  store i8 %254, i8* %261, align 1
  %262 = or i32 %231, 1
  %263 = sext i32 %262 to i64
  %264 = getelementptr inbounds i8, i8* %0, i64 %263
  store i8 %254, i8* %264, align 1
  %265 = shl nuw nsw i32 %83, 1
  %266 = add nuw nsw i32 %73, 2
  %267 = add nuw nsw i32 %266, %265
  %268 = add nuw nsw i32 %267, %93
  %269 = lshr i32 %268, 2
  %270 = trunc i32 %269 to i8
  %271 = add i64 %17, 17179869184
  %272 = ashr exact i64 %271, 32
  %273 = getelementptr inbounds i8, i8* %0, i64 %272
  store i8 %270, i8* %273, align 1
  %274 = add nsw i32 %192, 3
  %275 = sext i32 %274 to i64
  %276 = getelementptr inbounds i8, i8* %0, i64 %275
  store i8 %270, i8* %276, align 1
  %277 = add nsw i32 %217, 2
  %278 = sext i32 %277 to i64
  %279 = getelementptr inbounds i8, i8* %0, i64 %278
  store i8 %270, i8* %279, align 1
  %280 = add nsw i32 %248, 1
  %281 = sext i32 %280 to i64
  %282 = getelementptr inbounds i8, i8* %0, i64 %281
  store i8 %270, i8* %282, align 1
  %283 = add nuw nsw i32 %83, 1
  %284 = add nuw nsw i32 %283, %93
  %285 = lshr i32 %284, 1
  %286 = trunc i32 %285 to i8
  %287 = getelementptr inbounds i8, i8* %0, i64 5
  store i8 %286, i8* %287, align 1
  %288 = add nsw i32 %180, 4
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds i8, i8* %0, i64 %289
  store i8 %286, i8* %290, align 1
  %291 = or i32 %203, 3
  %292 = sext i32 %291 to i64
  %293 = getelementptr inbounds i8, i8* %0, i64 %292
  store i8 %286, i8* %293, align 1
  %294 = add nsw i32 %231, 2
  %295 = sext i32 %294 to i64
  %296 = getelementptr inbounds i8, i8* %0, i64 %295
  store i8 %286, i8* %296, align 1
  %297 = shl nuw nsw i32 %93, 1
  %298 = add nuw nsw i32 %83, 2
  %299 = add nuw nsw i32 %298, %297
  %300 = add nuw nsw i32 %299, %163
  %301 = lshr i32 %300, 2
  %302 = trunc i32 %301 to i8
  %303 = add i64 %17, 21474836480
  %304 = ashr exact i64 %303, 32
  %305 = getelementptr inbounds i8, i8* %0, i64 %304
  store i8 %302, i8* %305, align 1
  %306 = add nsw i32 %192, 4
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i8, i8* %0, i64 %307
  store i8 %302, i8* %308, align 1
  %309 = add nsw i32 %217, 3
  %310 = sext i32 %309 to i64
  %311 = getelementptr inbounds i8, i8* %0, i64 %310
  store i8 %302, i8* %311, align 1
  %312 = add nsw i32 %248, 2
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds i8, i8* %0, i64 %313
  store i8 %302, i8* %314, align 1
  %315 = add nuw nsw i32 %93, 1
  %316 = add nuw nsw i32 %315, %163
  %317 = lshr i32 %316, 1
  %318 = trunc i32 %317 to i8
  %319 = getelementptr inbounds i8, i8* %0, i64 6
  store i8 %318, i8* %319, align 1
  %320 = add nsw i32 %180, 5
  %321 = sext i32 %320 to i64
  %322 = getelementptr inbounds i8, i8* %0, i64 %321
  store i8 %318, i8* %322, align 1
  %323 = add nsw i32 %203, 4
  %324 = sext i32 %323 to i64
  %325 = getelementptr inbounds i8, i8* %0, i64 %324
  store i8 %318, i8* %325, align 1
  %326 = add nsw i32 %231, 3
  %327 = sext i32 %326 to i64
  %328 = getelementptr inbounds i8, i8* %0, i64 %327
  store i8 %318, i8* %328, align 1
  %329 = shl nuw nsw i32 %163, 1
  %330 = add nuw nsw i32 %93, 2
  %331 = add nuw nsw i32 %330, %156
  %332 = add nuw nsw i32 %331, %329
  %333 = lshr i32 %332, 2
  %334 = trunc i32 %333 to i8
  %335 = add i64 %17, 25769803776
  %336 = ashr exact i64 %335, 32
  %337 = getelementptr inbounds i8, i8* %0, i64 %336
  store i8 %334, i8* %337, align 1
  %338 = add nsw i32 %192, 5
  %339 = sext i32 %338 to i64
  %340 = getelementptr inbounds i8, i8* %0, i64 %339
  store i8 %334, i8* %340, align 1
  %341 = add nsw i32 %217, 4
  %342 = sext i32 %341 to i64
  %343 = getelementptr inbounds i8, i8* %0, i64 %342
  store i8 %334, i8* %343, align 1
  %344 = add nsw i32 %248, 3
  %345 = sext i32 %344 to i64
  %346 = getelementptr inbounds i8, i8* %0, i64 %345
  store i8 %334, i8* %346, align 1
  %347 = add nuw nsw i32 %156, 1
  %348 = add nuw nsw i32 %347, %163
  %349 = lshr i32 %348, 1
  %350 = trunc i32 %349 to i8
  %351 = getelementptr inbounds i8, i8* %0, i64 7
  store i8 %350, i8* %351, align 1
  %352 = add nsw i32 %180, 6
  %353 = sext i32 %352 to i64
  %354 = getelementptr inbounds i8, i8* %0, i64 %353
  store i8 %350, i8* %354, align 1
  %355 = add nsw i32 %203, 5
  %356 = sext i32 %355 to i64
  %357 = getelementptr inbounds i8, i8* %0, i64 %356
  store i8 %350, i8* %357, align 1
  %358 = add nsw i32 %231, 4
  %359 = sext i32 %358 to i64
  %360 = getelementptr inbounds i8, i8* %0, i64 %359
  store i8 %350, i8* %360, align 1
  %361 = shl nuw nsw i32 %156, 1
  %362 = add nuw nsw i32 %163, 2
  %363 = add nuw nsw i32 %362, %157
  %364 = add nuw nsw i32 %363, %361
  %365 = lshr i32 %364, 2
  %366 = trunc i32 %365 to i8
  %367 = add i64 %17, 30064771072
  %368 = ashr exact i64 %367, 32
  %369 = getelementptr inbounds i8, i8* %0, i64 %368
  store i8 %366, i8* %369, align 1
  %370 = add nsw i32 %192, 6
  %371 = sext i32 %370 to i64
  %372 = getelementptr inbounds i8, i8* %0, i64 %371
  store i8 %366, i8* %372, align 1
  %373 = add nsw i32 %217, 5
  %374 = sext i32 %373 to i64
  %375 = getelementptr inbounds i8, i8* %0, i64 %374
  store i8 %366, i8* %375, align 1
  %376 = add nsw i32 %248, 4
  %377 = sext i32 %376 to i64
  %378 = getelementptr inbounds i8, i8* %0, i64 %377
  store i8 %366, i8* %378, align 1
  %379 = add nuw nsw i32 %347, %157
  %380 = lshr i32 %379, 1
  %381 = trunc i32 %380 to i8
  %382 = add nsw i32 %180, 7
  %383 = sext i32 %382 to i64
  %384 = getelementptr inbounds i8, i8* %0, i64 %383
  store i8 %381, i8* %384, align 1
  %385 = add nsw i32 %203, 6
  %386 = sext i32 %385 to i64
  %387 = getelementptr inbounds i8, i8* %0, i64 %386
  store i8 %381, i8* %387, align 1
  %388 = add nsw i32 %231, 5
  %389 = sext i32 %388 to i64
  %390 = getelementptr inbounds i8, i8* %0, i64 %389
  store i8 %381, i8* %390, align 1
  %391 = shl nuw nsw i32 %157, 1
  %392 = add nuw nsw i32 %156, 2
  %393 = add nuw nsw i32 %392, %391
  %394 = add nuw nsw i32 %393, %158
  %395 = lshr i32 %394, 2
  %396 = trunc i32 %395 to i8
  %397 = add nsw i32 %192, 7
  %398 = sext i32 %397 to i64
  %399 = getelementptr inbounds i8, i8* %0, i64 %398
  store i8 %396, i8* %399, align 1
  %400 = add nsw i32 %217, 6
  %401 = sext i32 %400 to i64
  %402 = getelementptr inbounds i8, i8* %0, i64 %401
  store i8 %396, i8* %402, align 1
  %403 = add nsw i32 %248, 5
  %404 = sext i32 %403 to i64
  %405 = getelementptr inbounds i8, i8* %0, i64 %404
  store i8 %396, i8* %405, align 1
  %406 = add nuw nsw i32 %157, 1
  %407 = add nuw nsw i32 %406, %158
  %408 = lshr i32 %407, 1
  %409 = trunc i32 %408 to i8
  %410 = add nsw i32 %203, 7
  %411 = sext i32 %410 to i64
  %412 = getelementptr inbounds i8, i8* %0, i64 %411
  store i8 %409, i8* %412, align 1
  %413 = add nsw i32 %231, 6
  %414 = sext i32 %413 to i64
  %415 = getelementptr inbounds i8, i8* %0, i64 %414
  store i8 %409, i8* %415, align 1
  %416 = shl nuw nsw i32 %158, 1
  %417 = add nuw nsw i32 %157, 2
  %418 = add nuw nsw i32 %417, %416
  %419 = add nuw nsw i32 %418, %159
  %420 = lshr i32 %419, 2
  %421 = trunc i32 %420 to i8
  %422 = add nsw i32 %217, 7
  %423 = sext i32 %422 to i64
  %424 = getelementptr inbounds i8, i8* %0, i64 %423
  store i8 %421, i8* %424, align 1
  %425 = add nsw i32 %248, 6
  %426 = sext i32 %425 to i64
  %427 = getelementptr inbounds i8, i8* %0, i64 %426
  store i8 %421, i8* %427, align 1
  %428 = add nuw nsw i32 %158, 1
  %429 = add nuw nsw i32 %428, %159
  %430 = lshr i32 %429, 1
  %431 = trunc i32 %430 to i8
  %432 = add nsw i32 %231, 7
  %433 = sext i32 %432 to i64
  %434 = getelementptr inbounds i8, i8* %0, i64 %433
  store i8 %431, i8* %434, align 1
  %435 = shl nuw nsw i32 %159, 1
  %436 = add nuw nsw i32 %158, 2
  %437 = add nuw nsw i32 %436, %435
  %438 = add nuw nsw i32 %437, %160
  %439 = lshr i32 %438, 2
  %440 = trunc i32 %439 to i8
  %441 = add nsw i32 %248, 7
  %442 = sext i32 %441 to i64
  %443 = getelementptr inbounds i8, i8* %0, i64 %442
  store i8 %440, i8* %443, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_horizontal_up_8_c(i8*, i32, i32, i64) #1 {
  %5 = trunc i64 %3 to i32
  %6 = icmp eq i32 %1, 0
  br i1 %6, label %12, label %7

7:                                                ; preds = %4
  %8 = shl i64 %3, 32
  %9 = ashr exact i64 %8, 32
  %10 = xor i64 %9, -1
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  br label %16

12:                                               ; preds = %4
  %13 = getelementptr inbounds i8, i8* %0, i64 -1
  %14 = shl i64 %3, 32
  %15 = ashr exact i64 %14, 32
  br label %16

16:                                               ; preds = %12, %7
  %17 = phi i64 [ %15, %12 ], [ %9, %7 ]
  %18 = phi i64 [ %14, %12 ], [ %8, %7 ]
  %19 = phi i8* [ %13, %12 ], [ %11, %7 ]
  %20 = load i8, i8* %19, align 1
  %21 = zext i8 %20 to i32
  %22 = getelementptr inbounds i8, i8* %0, i64 -1
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = shl nuw nsw i32 %24, 1
  %26 = add i64 %18, -4294967296
  %27 = ashr exact i64 %26, 32
  %28 = getelementptr inbounds i8, i8* %0, i64 %27
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = add nuw nsw i32 %30, 2
  %32 = add nuw nsw i32 %31, %21
  %33 = add nuw nsw i32 %32, %25
  %34 = lshr i32 %33, 2
  %35 = shl nuw nsw i32 %30, 1
  %36 = shl nsw i32 %5, 1
  %37 = add nsw i32 %36, -1
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i32
  %42 = add nuw nsw i32 %41, 2
  %43 = add nuw nsw i32 %42, %24
  %44 = add nuw nsw i32 %43, %35
  %45 = lshr i32 %44, 2
  %46 = shl nuw nsw i32 %41, 1
  %47 = mul nsw i32 %5, 3
  %48 = add nsw i32 %47, -1
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds i8, i8* %0, i64 %49
  %51 = load i8, i8* %50, align 1
  %52 = zext i8 %51 to i32
  %53 = add nuw nsw i32 %31, %46
  %54 = add nuw nsw i32 %53, %52
  %55 = lshr i32 %54, 2
  %56 = shl nuw nsw i32 %52, 1
  %57 = shl nsw i32 %5, 2
  %58 = add nsw i32 %57, -1
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds i8, i8* %0, i64 %59
  %61 = load i8, i8* %60, align 1
  %62 = zext i8 %61 to i32
  %63 = add nuw nsw i32 %42, %56
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = mul nsw i32 %5, 5
  %68 = add nsw i32 %67, -1
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds i8, i8* %0, i64 %69
  %71 = load i8, i8* %70, align 1
  %72 = zext i8 %71 to i32
  %73 = add nuw nsw i32 %52, 2
  %74 = add nuw nsw i32 %73, %66
  %75 = add nuw nsw i32 %74, %72
  %76 = lshr i32 %75, 2
  %77 = shl nuw nsw i32 %72, 1
  %78 = mul nsw i32 %5, 6
  %79 = add nsw i32 %78, -1
  %80 = sext i32 %79 to i64
  %81 = getelementptr inbounds i8, i8* %0, i64 %80
  %82 = load i8, i8* %81, align 1
  %83 = zext i8 %82 to i32
  %84 = add nuw nsw i32 %62, 2
  %85 = add nuw nsw i32 %84, %77
  %86 = add nuw nsw i32 %85, %83
  %87 = lshr i32 %86, 2
  %88 = shl nuw nsw i32 %83, 1
  %89 = mul nsw i32 %5, 7
  %90 = add nsw i32 %89, -1
  %91 = sext i32 %90 to i64
  %92 = getelementptr inbounds i8, i8* %0, i64 %91
  %93 = load i8, i8* %92, align 1
  %94 = zext i8 %93 to i32
  %95 = add nuw nsw i32 %72, 2
  %96 = add nuw nsw i32 %95, %88
  %97 = add nuw nsw i32 %96, %94
  %98 = lshr i32 %97, 2
  %99 = mul nuw nsw i32 %94, 3
  %100 = add nuw nsw i32 %83, 2
  %101 = add nuw nsw i32 %100, %99
  %102 = lshr i32 %101, 2
  %103 = add nuw nsw i32 %45, 1
  %104 = add nuw nsw i32 %103, %34
  %105 = lshr i32 %104, 1
  %106 = trunc i32 %105 to i8
  store i8 %106, i8* %0, align 1
  %107 = shl nuw nsw i32 %45, 1
  %108 = add nuw nsw i32 %55, 2
  %109 = add nuw nsw i32 %108, %34
  %110 = add nuw nsw i32 %109, %107
  %111 = lshr i32 %110, 2
  %112 = trunc i32 %111 to i8
  %113 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %112, i8* %113, align 1
  %114 = add nuw nsw i32 %103, %55
  %115 = lshr i32 %114, 1
  %116 = trunc i32 %115 to i8
  %117 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %116, i8* %117, align 1
  %118 = getelementptr inbounds i8, i8* %0, i64 %17
  store i8 %116, i8* %118, align 1
  %119 = shl nuw nsw i32 %55, 1
  %120 = add nuw nsw i32 %65, 2
  %121 = add nuw nsw i32 %120, %45
  %122 = add nuw nsw i32 %121, %119
  %123 = lshr i32 %122, 2
  %124 = trunc i32 %123 to i8
  %125 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %124, i8* %125, align 1
  %126 = add i64 %18, 4294967296
  %127 = ashr exact i64 %126, 32
  %128 = getelementptr inbounds i8, i8* %0, i64 %127
  store i8 %124, i8* %128, align 1
  %129 = add nuw nsw i32 %55, 1
  %130 = add nuw nsw i32 %129, %65
  %131 = lshr i32 %130, 1
  %132 = trunc i32 %131 to i8
  %133 = getelementptr inbounds i8, i8* %0, i64 4
  store i8 %132, i8* %133, align 1
  %134 = add i64 %18, 8589934592
  %135 = ashr exact i64 %134, 32
  %136 = getelementptr inbounds i8, i8* %0, i64 %135
  store i8 %132, i8* %136, align 1
  %137 = sext i32 %36 to i64
  %138 = getelementptr inbounds i8, i8* %0, i64 %137
  store i8 %132, i8* %138, align 1
  %139 = shl nuw nsw i32 %65, 1
  %140 = add nuw nsw i32 %108, %139
  %141 = add nuw nsw i32 %140, %76
  %142 = lshr i32 %141, 2
  %143 = trunc i32 %142 to i8
  %144 = getelementptr inbounds i8, i8* %0, i64 5
  store i8 %143, i8* %144, align 1
  %145 = add i64 %18, 12884901888
  %146 = ashr exact i64 %145, 32
  %147 = getelementptr inbounds i8, i8* %0, i64 %146
  store i8 %143, i8* %147, align 1
  %148 = or i32 %36, 1
  %149 = sext i32 %148 to i64
  %150 = getelementptr inbounds i8, i8* %0, i64 %149
  store i8 %143, i8* %150, align 1
  %151 = add nuw nsw i32 %65, 1
  %152 = add nuw nsw i32 %151, %76
  %153 = lshr i32 %152, 1
  %154 = trunc i32 %153 to i8
  %155 = getelementptr inbounds i8, i8* %0, i64 6
  store i8 %154, i8* %155, align 1
  %156 = add i64 %18, 17179869184
  %157 = ashr exact i64 %156, 32
  %158 = getelementptr inbounds i8, i8* %0, i64 %157
  store i8 %154, i8* %158, align 1
  %159 = add nsw i32 %36, 2
  %160 = sext i32 %159 to i64
  %161 = getelementptr inbounds i8, i8* %0, i64 %160
  store i8 %154, i8* %161, align 1
  %162 = sext i32 %47 to i64
  %163 = getelementptr inbounds i8, i8* %0, i64 %162
  store i8 %154, i8* %163, align 1
  %164 = shl nuw nsw i32 %76, 1
  %165 = add nuw nsw i32 %120, %164
  %166 = add nuw nsw i32 %165, %87
  %167 = lshr i32 %166, 2
  %168 = trunc i32 %167 to i8
  %169 = getelementptr inbounds i8, i8* %0, i64 7
  store i8 %168, i8* %169, align 1
  %170 = add i64 %18, 21474836480
  %171 = ashr exact i64 %170, 32
  %172 = getelementptr inbounds i8, i8* %0, i64 %171
  store i8 %168, i8* %172, align 1
  %173 = add nsw i32 %36, 3
  %174 = sext i32 %173 to i64
  %175 = getelementptr inbounds i8, i8* %0, i64 %174
  store i8 %168, i8* %175, align 1
  %176 = add nsw i32 %47, 1
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds i8, i8* %0, i64 %177
  store i8 %168, i8* %178, align 1
  %179 = add nuw nsw i32 %76, 1
  %180 = add nuw nsw i32 %179, %87
  %181 = lshr i32 %180, 1
  %182 = trunc i32 %181 to i8
  %183 = add i64 %18, 25769803776
  %184 = ashr exact i64 %183, 32
  %185 = getelementptr inbounds i8, i8* %0, i64 %184
  store i8 %182, i8* %185, align 1
  %186 = add nsw i32 %36, 4
  %187 = sext i32 %186 to i64
  %188 = getelementptr inbounds i8, i8* %0, i64 %187
  store i8 %182, i8* %188, align 1
  %189 = add nsw i32 %47, 2
  %190 = sext i32 %189 to i64
  %191 = getelementptr inbounds i8, i8* %0, i64 %190
  store i8 %182, i8* %191, align 1
  %192 = sext i32 %57 to i64
  %193 = getelementptr inbounds i8, i8* %0, i64 %192
  store i8 %182, i8* %193, align 1
  %194 = shl nuw nsw i32 %87, 1
  %195 = add nuw nsw i32 %76, 2
  %196 = add nuw nsw i32 %195, %194
  %197 = add nuw nsw i32 %196, %98
  %198 = lshr i32 %197, 2
  %199 = trunc i32 %198 to i8
  %200 = add i64 %18, 30064771072
  %201 = ashr exact i64 %200, 32
  %202 = getelementptr inbounds i8, i8* %0, i64 %201
  store i8 %199, i8* %202, align 1
  %203 = add nsw i32 %36, 5
  %204 = sext i32 %203 to i64
  %205 = getelementptr inbounds i8, i8* %0, i64 %204
  store i8 %199, i8* %205, align 1
  %206 = add nsw i32 %47, 3
  %207 = sext i32 %206 to i64
  %208 = getelementptr inbounds i8, i8* %0, i64 %207
  store i8 %199, i8* %208, align 1
  %209 = or i32 %57, 1
  %210 = sext i32 %209 to i64
  %211 = getelementptr inbounds i8, i8* %0, i64 %210
  store i8 %199, i8* %211, align 1
  %212 = add nuw nsw i32 %87, 1
  %213 = add nuw nsw i32 %212, %98
  %214 = lshr i32 %213, 1
  %215 = trunc i32 %214 to i8
  %216 = add nsw i32 %36, 6
  %217 = sext i32 %216 to i64
  %218 = getelementptr inbounds i8, i8* %0, i64 %217
  store i8 %215, i8* %218, align 1
  %219 = add nsw i32 %47, 4
  %220 = sext i32 %219 to i64
  %221 = getelementptr inbounds i8, i8* %0, i64 %220
  store i8 %215, i8* %221, align 1
  %222 = or i32 %57, 2
  %223 = sext i32 %222 to i64
  %224 = getelementptr inbounds i8, i8* %0, i64 %223
  store i8 %215, i8* %224, align 1
  %225 = sext i32 %67 to i64
  %226 = getelementptr inbounds i8, i8* %0, i64 %225
  store i8 %215, i8* %226, align 1
  %227 = shl nuw nsw i32 %98, 1
  %228 = add nuw nsw i32 %87, 2
  %229 = add nuw nsw i32 %228, %102
  %230 = add nuw nsw i32 %229, %227
  %231 = lshr i32 %230, 2
  %232 = trunc i32 %231 to i8
  %233 = add nsw i32 %36, 7
  %234 = sext i32 %233 to i64
  %235 = getelementptr inbounds i8, i8* %0, i64 %234
  store i8 %232, i8* %235, align 1
  %236 = add nsw i32 %47, 5
  %237 = sext i32 %236 to i64
  %238 = getelementptr inbounds i8, i8* %0, i64 %237
  store i8 %232, i8* %238, align 1
  %239 = or i32 %57, 3
  %240 = sext i32 %239 to i64
  %241 = getelementptr inbounds i8, i8* %0, i64 %240
  store i8 %232, i8* %241, align 1
  %242 = add nsw i32 %67, 1
  %243 = sext i32 %242 to i64
  %244 = getelementptr inbounds i8, i8* %0, i64 %243
  store i8 %232, i8* %244, align 1
  %245 = add nuw nsw i32 %98, 1
  %246 = add nuw nsw i32 %245, %102
  %247 = lshr i32 %246, 1
  %248 = trunc i32 %247 to i8
  %249 = add nsw i32 %47, 6
  %250 = sext i32 %249 to i64
  %251 = getelementptr inbounds i8, i8* %0, i64 %250
  store i8 %248, i8* %251, align 1
  %252 = add nsw i32 %57, 4
  %253 = sext i32 %252 to i64
  %254 = getelementptr inbounds i8, i8* %0, i64 %253
  store i8 %248, i8* %254, align 1
  %255 = add nsw i32 %67, 2
  %256 = sext i32 %255 to i64
  %257 = getelementptr inbounds i8, i8* %0, i64 %256
  store i8 %248, i8* %257, align 1
  %258 = sext i32 %78 to i64
  %259 = getelementptr inbounds i8, i8* %0, i64 %258
  store i8 %248, i8* %259, align 1
  %260 = mul nuw nsw i32 %102, 3
  %261 = add nuw nsw i32 %98, 2
  %262 = add nuw nsw i32 %261, %260
  %263 = lshr i32 %262, 2
  %264 = trunc i32 %263 to i8
  %265 = add nsw i32 %47, 7
  %266 = sext i32 %265 to i64
  %267 = getelementptr inbounds i8, i8* %0, i64 %266
  store i8 %264, i8* %267, align 1
  %268 = add nsw i32 %57, 5
  %269 = sext i32 %268 to i64
  %270 = getelementptr inbounds i8, i8* %0, i64 %269
  store i8 %264, i8* %270, align 1
  %271 = add nsw i32 %67, 3
  %272 = sext i32 %271 to i64
  %273 = getelementptr inbounds i8, i8* %0, i64 %272
  store i8 %264, i8* %273, align 1
  %274 = or i32 %78, 1
  %275 = sext i32 %274 to i64
  %276 = getelementptr inbounds i8, i8* %0, i64 %275
  store i8 %264, i8* %276, align 1
  %277 = trunc i32 %102 to i8
  %278 = add nsw i32 %89, 7
  %279 = sext i32 %278 to i64
  %280 = getelementptr inbounds i8, i8* %0, i64 %279
  store i8 %277, i8* %280, align 1
  %281 = add nsw i32 %78, 7
  %282 = sext i32 %281 to i64
  %283 = getelementptr inbounds i8, i8* %0, i64 %282
  store i8 %277, i8* %283, align 1
  %284 = add nsw i32 %67, 7
  %285 = sext i32 %284 to i64
  %286 = getelementptr inbounds i8, i8* %0, i64 %285
  store i8 %277, i8* %286, align 1
  %287 = add nsw i32 %57, 7
  %288 = sext i32 %287 to i64
  %289 = getelementptr inbounds i8, i8* %0, i64 %288
  store i8 %277, i8* %289, align 1
  %290 = add nsw i32 %89, 6
  %291 = sext i32 %290 to i64
  %292 = getelementptr inbounds i8, i8* %0, i64 %291
  store i8 %277, i8* %292, align 1
  %293 = add nsw i32 %78, 6
  %294 = sext i32 %293 to i64
  %295 = getelementptr inbounds i8, i8* %0, i64 %294
  store i8 %277, i8* %295, align 1
  %296 = add nsw i32 %67, 6
  %297 = sext i32 %296 to i64
  %298 = getelementptr inbounds i8, i8* %0, i64 %297
  store i8 %277, i8* %298, align 1
  %299 = add nsw i32 %57, 6
  %300 = sext i32 %299 to i64
  %301 = getelementptr inbounds i8, i8* %0, i64 %300
  store i8 %277, i8* %301, align 1
  %302 = add nsw i32 %89, 5
  %303 = sext i32 %302 to i64
  %304 = getelementptr inbounds i8, i8* %0, i64 %303
  store i8 %277, i8* %304, align 1
  %305 = add nsw i32 %78, 5
  %306 = sext i32 %305 to i64
  %307 = getelementptr inbounds i8, i8* %0, i64 %306
  store i8 %277, i8* %307, align 1
  %308 = add nsw i32 %67, 5
  %309 = sext i32 %308 to i64
  %310 = getelementptr inbounds i8, i8* %0, i64 %309
  store i8 %277, i8* %310, align 1
  %311 = add nsw i32 %89, 4
  %312 = sext i32 %311 to i64
  %313 = getelementptr inbounds i8, i8* %0, i64 %312
  store i8 %277, i8* %313, align 1
  %314 = add nsw i32 %78, 4
  %315 = sext i32 %314 to i64
  %316 = getelementptr inbounds i8, i8* %0, i64 %315
  store i8 %277, i8* %316, align 1
  %317 = add nsw i32 %67, 4
  %318 = sext i32 %317 to i64
  %319 = getelementptr inbounds i8, i8* %0, i64 %318
  store i8 %277, i8* %319, align 1
  %320 = add nsw i32 %89, 3
  %321 = sext i32 %320 to i64
  %322 = getelementptr inbounds i8, i8* %0, i64 %321
  store i8 %277, i8* %322, align 1
  %323 = add nsw i32 %78, 3
  %324 = sext i32 %323 to i64
  %325 = getelementptr inbounds i8, i8* %0, i64 %324
  store i8 %277, i8* %325, align 1
  %326 = add nsw i32 %89, 2
  %327 = sext i32 %326 to i64
  %328 = getelementptr inbounds i8, i8* %0, i64 %327
  store i8 %277, i8* %328, align 1
  %329 = add nsw i32 %78, 2
  %330 = sext i32 %329 to i64
  %331 = getelementptr inbounds i8, i8* %0, i64 %330
  store i8 %277, i8* %331, align 1
  %332 = add nsw i32 %89, 1
  %333 = sext i32 %332 to i64
  %334 = getelementptr inbounds i8, i8* %0, i64 %333
  store i8 %277, i8* %334, align 1
  %335 = sext i32 %89 to i64
  %336 = getelementptr inbounds i8, i8* %0, i64 %335
  store i8 %277, i8* %336, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_left_dc_8_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = trunc i64 %3 to i32
  %6 = icmp eq i32 %1, 0
  br i1 %6, label %12, label %7

7:                                                ; preds = %4
  %8 = shl i64 %3, 32
  %9 = ashr exact i64 %8, 32
  %10 = xor i64 %9, -1
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  br label %16

12:                                               ; preds = %4
  %13 = getelementptr inbounds i8, i8* %0, i64 -1
  %14 = shl i64 %3, 32
  %15 = ashr exact i64 %14, 32
  br label %16

16:                                               ; preds = %12, %7
  %17 = phi i64 [ %15, %12 ], [ %9, %7 ]
  %18 = phi i64 [ %14, %12 ], [ %8, %7 ]
  %19 = phi i8* [ %13, %12 ], [ %11, %7 ]
  %20 = load i8, i8* %19, align 1
  %21 = zext i8 %20 to i32
  %22 = getelementptr inbounds i8, i8* %0, i64 -1
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = shl nuw nsw i32 %24, 1
  %26 = add i64 %18, -4294967296
  %27 = ashr exact i64 %26, 32
  %28 = getelementptr inbounds i8, i8* %0, i64 %27
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = add nuw nsw i32 %30, 2
  %32 = add nuw nsw i32 %31, %21
  %33 = add nuw nsw i32 %32, %25
  %34 = lshr i32 %33, 2
  %35 = shl nuw nsw i32 %30, 1
  %36 = shl i32 %5, 1
  %37 = add nsw i32 %36, -1
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i32
  %42 = add nuw nsw i32 %41, 2
  %43 = add nuw nsw i32 %42, %24
  %44 = add nuw nsw i32 %43, %35
  %45 = lshr i32 %44, 2
  %46 = shl nuw nsw i32 %41, 1
  %47 = mul i64 %3, 12884901888
  %48 = add i64 %47, -4294967296
  %49 = ashr exact i64 %48, 32
  %50 = getelementptr inbounds i8, i8* %0, i64 %49
  %51 = load i8, i8* %50, align 1
  %52 = zext i8 %51 to i32
  %53 = add nuw nsw i32 %31, %46
  %54 = add nuw nsw i32 %53, %52
  %55 = lshr i32 %54, 2
  %56 = shl nuw nsw i32 %52, 1
  %57 = shl i32 %5, 2
  %58 = add nsw i32 %57, -1
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds i8, i8* %0, i64 %59
  %61 = load i8, i8* %60, align 1
  %62 = zext i8 %61 to i32
  %63 = add nuw nsw i32 %42, %56
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = mul i64 %3, 21474836480
  %68 = add i64 %67, -4294967296
  %69 = ashr exact i64 %68, 32
  %70 = getelementptr inbounds i8, i8* %0, i64 %69
  %71 = load i8, i8* %70, align 1
  %72 = zext i8 %71 to i32
  %73 = add nuw nsw i32 %52, 2
  %74 = add nuw nsw i32 %73, %66
  %75 = add nuw nsw i32 %74, %72
  %76 = lshr i32 %75, 2
  %77 = shl nuw nsw i32 %72, 1
  %78 = mul i64 %3, 25769803776
  %79 = add i64 %78, -4294967296
  %80 = ashr exact i64 %79, 32
  %81 = getelementptr inbounds i8, i8* %0, i64 %80
  %82 = load i8, i8* %81, align 1
  %83 = zext i8 %82 to i32
  %84 = add nuw nsw i32 %62, 2
  %85 = add nuw nsw i32 %84, %77
  %86 = add nuw nsw i32 %85, %83
  %87 = lshr i32 %86, 2
  %88 = shl nuw nsw i32 %83, 1
  %89 = mul i64 %3, 30064771072
  %90 = add i64 %89, -4294967296
  %91 = ashr exact i64 %90, 32
  %92 = getelementptr inbounds i8, i8* %0, i64 %91
  %93 = load i8, i8* %92, align 1
  %94 = zext i8 %93 to i32
  %95 = add nuw nsw i32 %72, 2
  %96 = add nuw nsw i32 %95, %88
  %97 = add nuw nsw i32 %96, %94
  %98 = lshr i32 %97, 2
  %99 = mul nuw nsw i32 %94, 3
  %100 = add nuw nsw i32 %83, 2
  %101 = add nuw nsw i32 %100, %99
  %102 = lshr i32 %101, 2
  %103 = add nuw nsw i32 %34, 4
  %104 = add nuw nsw i32 %103, %45
  %105 = add nuw nsw i32 %104, %55
  %106 = add nuw nsw i32 %105, %65
  %107 = add nuw nsw i32 %106, %76
  %108 = add nuw nsw i32 %107, %87
  %109 = add nuw nsw i32 %108, %102
  %110 = add nuw nsw i32 %109, %98
  %111 = ashr i32 %110, 3
  %112 = mul i32 %111, 16843009
  %113 = bitcast i8* %0 to i32*
  store i32 %112, i32* %113, align 4
  %114 = getelementptr inbounds i8, i8* %0, i64 4
  %115 = bitcast i8* %114 to i32*
  store i32 %112, i32* %115, align 4
  %116 = getelementptr inbounds i8, i8* %0, i64 %17
  %117 = bitcast i8* %116 to i32*
  store i32 %112, i32* %117, align 4
  %118 = getelementptr inbounds i8, i8* %116, i64 4
  %119 = bitcast i8* %118 to i32*
  store i32 %112, i32* %119, align 4
  %120 = getelementptr inbounds i8, i8* %116, i64 %17
  %121 = bitcast i8* %120 to i32*
  store i32 %112, i32* %121, align 4
  %122 = getelementptr inbounds i8, i8* %120, i64 4
  %123 = bitcast i8* %122 to i32*
  store i32 %112, i32* %123, align 4
  %124 = getelementptr inbounds i8, i8* %120, i64 %17
  %125 = bitcast i8* %124 to i32*
  store i32 %112, i32* %125, align 4
  %126 = getelementptr inbounds i8, i8* %124, i64 4
  %127 = bitcast i8* %126 to i32*
  store i32 %112, i32* %127, align 4
  %128 = getelementptr inbounds i8, i8* %124, i64 %17
  %129 = bitcast i8* %128 to i32*
  store i32 %112, i32* %129, align 4
  %130 = getelementptr inbounds i8, i8* %128, i64 4
  %131 = bitcast i8* %130 to i32*
  store i32 %112, i32* %131, align 4
  %132 = getelementptr inbounds i8, i8* %128, i64 %17
  %133 = bitcast i8* %132 to i32*
  store i32 %112, i32* %133, align 4
  %134 = getelementptr inbounds i8, i8* %132, i64 4
  %135 = bitcast i8* %134 to i32*
  store i32 %112, i32* %135, align 4
  %136 = getelementptr inbounds i8, i8* %132, i64 %17
  %137 = bitcast i8* %136 to i32*
  store i32 %112, i32* %137, align 4
  %138 = getelementptr inbounds i8, i8* %136, i64 4
  %139 = bitcast i8* %138 to i32*
  store i32 %112, i32* %139, align 4
  %140 = getelementptr inbounds i8, i8* %136, i64 %17
  %141 = bitcast i8* %140 to i32*
  store i32 %112, i32* %141, align 4
  %142 = getelementptr inbounds i8, i8* %140, i64 4
  %143 = bitcast i8* %142 to i32*
  store i32 %112, i32* %143, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8l_top_dc_8_c(i8* nocapture, i32, i32, i64) #1 {
  %5 = trunc i64 %3 to i32
  %6 = icmp eq i32 %1, 0
  %7 = sub nsw i32 0, %5
  br i1 %6, label %13, label %8

8:                                                ; preds = %4
  %9 = shl i64 %3, 32
  %10 = ashr exact i64 %9, 32
  %11 = xor i64 %10, -1
  %12 = sext i32 %7 to i64
  br label %16

13:                                               ; preds = %4
  %14 = sext i32 %7 to i64
  %15 = shl i64 %3, 32
  br label %16

16:                                               ; preds = %13, %8
  %17 = phi i64 [ %15, %13 ], [ %9, %8 ]
  %18 = phi i64 [ %14, %13 ], [ %12, %8 ]
  %19 = phi i64 [ %14, %13 ], [ %11, %8 ]
  %20 = getelementptr inbounds i8, i8* %0, i64 %19
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  %23 = getelementptr inbounds i8, i8* %0, i64 %18
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = shl nuw nsw i32 %25, 1
  %27 = sub i64 4294967296, %17
  %28 = ashr exact i64 %27, 32
  %29 = getelementptr inbounds i8, i8* %0, i64 %28
  %30 = load i8, i8* %29, align 1
  %31 = zext i8 %30 to i32
  %32 = add nuw nsw i32 %31, 2
  %33 = add nuw nsw i32 %32, %22
  %34 = add nuw nsw i32 %33, %26
  %35 = lshr i32 %34, 2
  %36 = shl nuw nsw i32 %31, 1
  %37 = sub i64 8589934592, %17
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i32
  %42 = add nuw nsw i32 %41, 2
  %43 = add nuw nsw i32 %42, %25
  %44 = add nuw nsw i32 %43, %36
  %45 = lshr i32 %44, 2
  %46 = shl nuw nsw i32 %41, 1
  %47 = sub i64 12884901888, %17
  %48 = ashr exact i64 %47, 32
  %49 = getelementptr inbounds i8, i8* %0, i64 %48
  %50 = load i8, i8* %49, align 1
  %51 = zext i8 %50 to i32
  %52 = add nuw nsw i32 %32, %46
  %53 = add nuw nsw i32 %52, %51
  %54 = lshr i32 %53, 2
  %55 = shl nuw nsw i32 %51, 1
  %56 = sub i64 17179869184, %17
  %57 = ashr exact i64 %56, 32
  %58 = getelementptr inbounds i8, i8* %0, i64 %57
  %59 = load i8, i8* %58, align 1
  %60 = zext i8 %59 to i32
  %61 = add nuw nsw i32 %42, %55
  %62 = add nuw nsw i32 %61, %60
  %63 = lshr i32 %62, 2
  %64 = shl nuw nsw i32 %60, 1
  %65 = sub i64 21474836480, %17
  %66 = ashr exact i64 %65, 32
  %67 = getelementptr inbounds i8, i8* %0, i64 %66
  %68 = load i8, i8* %67, align 1
  %69 = zext i8 %68 to i32
  %70 = add nuw nsw i32 %51, 2
  %71 = add nuw nsw i32 %70, %64
  %72 = add nuw nsw i32 %71, %69
  %73 = lshr i32 %72, 2
  %74 = shl nuw nsw i32 %69, 1
  %75 = sub i64 25769803776, %17
  %76 = ashr exact i64 %75, 32
  %77 = getelementptr inbounds i8, i8* %0, i64 %76
  %78 = load i8, i8* %77, align 1
  %79 = zext i8 %78 to i32
  %80 = add nuw nsw i32 %60, 2
  %81 = add nuw nsw i32 %80, %74
  %82 = add nuw nsw i32 %81, %79
  %83 = lshr i32 %82, 2
  %84 = shl nuw nsw i32 %79, 1
  %85 = sub i64 30064771072, %17
  %86 = ashr exact i64 %85, 32
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = load i8, i8* %87, align 1
  %89 = zext i8 %88 to i32
  %90 = add nuw nsw i32 %69, 2
  %91 = add nuw nsw i32 %90, %84
  %92 = add nuw nsw i32 %91, %89
  %93 = lshr i32 %92, 2
  %94 = icmp eq i32 %2, 0
  br i1 %94, label %101, label %95

95:                                               ; preds = %16
  %96 = sub i64 34359738368, %17
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i8, i8* %0, i64 %97
  %99 = load i8, i8* %98, align 1
  %100 = zext i8 %99 to i32
  br label %101

101:                                              ; preds = %16, %95
  %102 = phi i32 [ %100, %95 ], [ %89, %16 ]
  %103 = shl nuw nsw i32 %89, 1
  %104 = add nuw nsw i32 %79, 2
  %105 = add nuw nsw i32 %104, %103
  %106 = add nuw nsw i32 %105, %102
  %107 = lshr i32 %106, 2
  %108 = add nuw nsw i32 %35, 4
  %109 = add nuw nsw i32 %108, %45
  %110 = add nuw nsw i32 %109, %54
  %111 = add nuw nsw i32 %110, %63
  %112 = add nuw nsw i32 %111, %73
  %113 = add nuw nsw i32 %112, %83
  %114 = add nuw nsw i32 %113, %93
  %115 = add nuw nsw i32 %114, %107
  %116 = ashr i32 %115, 3
  %117 = mul i32 %116, 16843009
  %118 = ashr exact i64 %17, 32
  %119 = bitcast i8* %0 to i32*
  store i32 %117, i32* %119, align 4
  %120 = getelementptr inbounds i8, i8* %0, i64 4
  %121 = bitcast i8* %120 to i32*
  store i32 %117, i32* %121, align 4
  %122 = getelementptr inbounds i8, i8* %0, i64 %118
  %123 = bitcast i8* %122 to i32*
  store i32 %117, i32* %123, align 4
  %124 = getelementptr inbounds i8, i8* %122, i64 4
  %125 = bitcast i8* %124 to i32*
  store i32 %117, i32* %125, align 4
  %126 = getelementptr inbounds i8, i8* %122, i64 %118
  %127 = bitcast i8* %126 to i32*
  store i32 %117, i32* %127, align 4
  %128 = getelementptr inbounds i8, i8* %126, i64 4
  %129 = bitcast i8* %128 to i32*
  store i32 %117, i32* %129, align 4
  %130 = getelementptr inbounds i8, i8* %126, i64 %118
  %131 = bitcast i8* %130 to i32*
  store i32 %117, i32* %131, align 4
  %132 = getelementptr inbounds i8, i8* %130, i64 4
  %133 = bitcast i8* %132 to i32*
  store i32 %117, i32* %133, align 4
  %134 = getelementptr inbounds i8, i8* %130, i64 %118
  %135 = bitcast i8* %134 to i32*
  store i32 %117, i32* %135, align 4
  %136 = getelementptr inbounds i8, i8* %134, i64 4
  %137 = bitcast i8* %136 to i32*
  store i32 %117, i32* %137, align 4
  %138 = getelementptr inbounds i8, i8* %134, i64 %118
  %139 = bitcast i8* %138 to i32*
  store i32 %117, i32* %139, align 4
  %140 = getelementptr inbounds i8, i8* %138, i64 4
  %141 = bitcast i8* %140 to i32*
  store i32 %117, i32* %141, align 4
  %142 = getelementptr inbounds i8, i8* %138, i64 %118
  %143 = bitcast i8* %142 to i32*
  store i32 %117, i32* %143, align 4
  %144 = getelementptr inbounds i8, i8* %142, i64 4
  %145 = bitcast i8* %144 to i32*
  store i32 %117, i32* %145, align 4
  %146 = getelementptr inbounds i8, i8* %142, i64 %118
  %147 = bitcast i8* %146 to i32*
  store i32 %117, i32* %147, align 4
  %148 = getelementptr inbounds i8, i8* %146, i64 4
  %149 = bitcast i8* %148 to i32*
  store i32 %117, i32* %149, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8l_128_dc_8_c(i8* nocapture, i32, i32, i64) #2 {
  %5 = shl i64 %3, 32
  %6 = ashr exact i64 %5, 32
  %7 = bitcast i8* %0 to i32*
  store i32 -2139062144, i32* %7, align 4
  %8 = getelementptr inbounds i8, i8* %0, i64 4
  %9 = bitcast i8* %8 to i32*
  store i32 -2139062144, i32* %9, align 4
  %10 = getelementptr inbounds i8, i8* %0, i64 %6
  %11 = bitcast i8* %10 to i32*
  store i32 -2139062144, i32* %11, align 4
  %12 = getelementptr inbounds i8, i8* %10, i64 4
  %13 = bitcast i8* %12 to i32*
  store i32 -2139062144, i32* %13, align 4
  %14 = getelementptr inbounds i8, i8* %10, i64 %6
  %15 = bitcast i8* %14 to i32*
  store i32 -2139062144, i32* %15, align 4
  %16 = getelementptr inbounds i8, i8* %14, i64 4
  %17 = bitcast i8* %16 to i32*
  store i32 -2139062144, i32* %17, align 4
  %18 = getelementptr inbounds i8, i8* %14, i64 %6
  %19 = bitcast i8* %18 to i32*
  store i32 -2139062144, i32* %19, align 4
  %20 = getelementptr inbounds i8, i8* %18, i64 4
  %21 = bitcast i8* %20 to i32*
  store i32 -2139062144, i32* %21, align 4
  %22 = getelementptr inbounds i8, i8* %18, i64 %6
  %23 = bitcast i8* %22 to i32*
  store i32 -2139062144, i32* %23, align 4
  %24 = getelementptr inbounds i8, i8* %22, i64 4
  %25 = bitcast i8* %24 to i32*
  store i32 -2139062144, i32* %25, align 4
  %26 = getelementptr inbounds i8, i8* %22, i64 %6
  %27 = bitcast i8* %26 to i32*
  store i32 -2139062144, i32* %27, align 4
  %28 = getelementptr inbounds i8, i8* %26, i64 4
  %29 = bitcast i8* %28 to i32*
  store i32 -2139062144, i32* %29, align 4
  %30 = getelementptr inbounds i8, i8* %26, i64 %6
  %31 = bitcast i8* %30 to i32*
  store i32 -2139062144, i32* %31, align 4
  %32 = getelementptr inbounds i8, i8* %30, i64 4
  %33 = bitcast i8* %32 to i32*
  store i32 -2139062144, i32* %33, align 4
  %34 = getelementptr inbounds i8, i8* %30, i64 %6
  %35 = bitcast i8* %34 to i32*
  store i32 -2139062144, i32* %35, align 4
  %36 = getelementptr inbounds i8, i8* %34, i64 4
  %37 = bitcast i8* %36 to i32*
  store i32 -2139062144, i32* %37, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_vertical_8_c(i8* nocapture, i64) #1 {
  %3 = shl i64 %1, 32
  %4 = ashr exact i64 %3, 32
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i8, i8* %0, i64 %5
  %7 = bitcast i8* %6 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds i8, i8* %6, i64 4
  %10 = bitcast i8* %9 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = shl i64 %1, 32
  %13 = ashr exact i64 %12, 32
  %14 = bitcast i8* %0 to i32*
  store i32 %8, i32* %14, align 4
  %15 = getelementptr inbounds i8, i8* %0, i64 4
  %16 = bitcast i8* %15 to i32*
  store i32 %11, i32* %16, align 4
  %17 = getelementptr inbounds i8, i8* %0, i64 %13
  %18 = bitcast i8* %17 to i32*
  store i32 %8, i32* %18, align 4
  %19 = getelementptr inbounds i8, i8* %17, i64 4
  %20 = bitcast i8* %19 to i32*
  store i32 %11, i32* %20, align 4
  %21 = ashr exact i64 %12, 31
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = bitcast i8* %22 to i32*
  store i32 %8, i32* %23, align 4
  %24 = getelementptr inbounds i8, i8* %22, i64 4
  %25 = bitcast i8* %24 to i32*
  store i32 %11, i32* %25, align 4
  %26 = mul nsw i64 %13, 3
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = bitcast i8* %27 to i32*
  store i32 %8, i32* %28, align 4
  %29 = getelementptr inbounds i8, i8* %27, i64 4
  %30 = bitcast i8* %29 to i32*
  store i32 %11, i32* %30, align 4
  %31 = ashr exact i64 %12, 30
  %32 = getelementptr inbounds i8, i8* %0, i64 %31
  %33 = bitcast i8* %32 to i32*
  store i32 %8, i32* %33, align 4
  %34 = getelementptr inbounds i8, i8* %32, i64 4
  %35 = bitcast i8* %34 to i32*
  store i32 %11, i32* %35, align 4
  %36 = mul nsw i64 %13, 5
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = bitcast i8* %37 to i32*
  store i32 %8, i32* %38, align 4
  %39 = getelementptr inbounds i8, i8* %37, i64 4
  %40 = bitcast i8* %39 to i32*
  store i32 %11, i32* %40, align 4
  %41 = mul nsw i64 %13, 6
  %42 = getelementptr inbounds i8, i8* %0, i64 %41
  %43 = bitcast i8* %42 to i32*
  store i32 %8, i32* %43, align 4
  %44 = getelementptr inbounds i8, i8* %42, i64 4
  %45 = bitcast i8* %44 to i32*
  store i32 %11, i32* %45, align 4
  %46 = mul nsw i64 %13, 7
  %47 = getelementptr inbounds i8, i8* %0, i64 %46
  %48 = bitcast i8* %47 to i32*
  store i32 %8, i32* %48, align 4
  %49 = getelementptr inbounds i8, i8* %47, i64 4
  %50 = bitcast i8* %49 to i32*
  store i32 %11, i32* %50, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_horizontal_8_c(i8* nocapture, i64) #1 {
  %3 = getelementptr inbounds i8, i8* %0, i64 -1
  %4 = load i8, i8* %3, align 1
  %5 = zext i8 %4 to i32
  %6 = mul nuw i32 %5, 16843009
  %7 = bitcast i8* %0 to i32*
  store i32 %6, i32* %7, align 4
  %8 = getelementptr inbounds i8, i8* %0, i64 4
  %9 = bitcast i8* %8 to i32*
  store i32 %6, i32* %9, align 4
  %10 = add nsw i64 %1, -1
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = load i8, i8* %11, align 1
  %13 = zext i8 %12 to i32
  %14 = mul nuw i32 %13, 16843009
  %15 = getelementptr inbounds i8, i8* %0, i64 %1
  %16 = bitcast i8* %15 to i32*
  store i32 %14, i32* %16, align 4
  %17 = getelementptr inbounds i8, i8* %15, i64 4
  %18 = bitcast i8* %17 to i32*
  store i32 %14, i32* %18, align 4
  %19 = shl nsw i64 %1, 1
  %20 = add nsw i64 %19, -1
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = load i8, i8* %21, align 1
  %23 = zext i8 %22 to i32
  %24 = mul nuw i32 %23, 16843009
  %25 = getelementptr inbounds i8, i8* %0, i64 %19
  %26 = bitcast i8* %25 to i32*
  store i32 %24, i32* %26, align 4
  %27 = getelementptr inbounds i8, i8* %25, i64 4
  %28 = bitcast i8* %27 to i32*
  store i32 %24, i32* %28, align 4
  %29 = mul nsw i64 %1, 3
  %30 = add nsw i64 %29, -1
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = mul nuw i32 %33, 16843009
  %35 = getelementptr inbounds i8, i8* %0, i64 %29
  %36 = bitcast i8* %35 to i32*
  store i32 %34, i32* %36, align 4
  %37 = getelementptr inbounds i8, i8* %35, i64 4
  %38 = bitcast i8* %37 to i32*
  store i32 %34, i32* %38, align 4
  %39 = shl nsw i64 %1, 2
  %40 = add nsw i64 %39, -1
  %41 = getelementptr inbounds i8, i8* %0, i64 %40
  %42 = load i8, i8* %41, align 1
  %43 = zext i8 %42 to i32
  %44 = mul nuw i32 %43, 16843009
  %45 = getelementptr inbounds i8, i8* %0, i64 %39
  %46 = bitcast i8* %45 to i32*
  store i32 %44, i32* %46, align 4
  %47 = getelementptr inbounds i8, i8* %45, i64 4
  %48 = bitcast i8* %47 to i32*
  store i32 %44, i32* %48, align 4
  %49 = mul nsw i64 %1, 5
  %50 = add nsw i64 %49, -1
  %51 = getelementptr inbounds i8, i8* %0, i64 %50
  %52 = load i8, i8* %51, align 1
  %53 = zext i8 %52 to i32
  %54 = mul nuw i32 %53, 16843009
  %55 = getelementptr inbounds i8, i8* %0, i64 %49
  %56 = bitcast i8* %55 to i32*
  store i32 %54, i32* %56, align 4
  %57 = getelementptr inbounds i8, i8* %55, i64 4
  %58 = bitcast i8* %57 to i32*
  store i32 %54, i32* %58, align 4
  %59 = mul nsw i64 %1, 6
  %60 = add nsw i64 %59, -1
  %61 = getelementptr inbounds i8, i8* %0, i64 %60
  %62 = load i8, i8* %61, align 1
  %63 = zext i8 %62 to i32
  %64 = mul nuw i32 %63, 16843009
  %65 = getelementptr inbounds i8, i8* %0, i64 %59
  %66 = bitcast i8* %65 to i32*
  store i32 %64, i32* %66, align 4
  %67 = getelementptr inbounds i8, i8* %65, i64 4
  %68 = bitcast i8* %67 to i32*
  store i32 %64, i32* %68, align 4
  %69 = mul nsw i64 %1, 7
  %70 = add nsw i64 %69, -1
  %71 = getelementptr inbounds i8, i8* %0, i64 %70
  %72 = load i8, i8* %71, align 1
  %73 = zext i8 %72 to i32
  %74 = mul nuw i32 %73, 16843009
  %75 = getelementptr inbounds i8, i8* %0, i64 %69
  %76 = bitcast i8* %75 to i32*
  store i32 %74, i32* %76, align 4
  %77 = getelementptr inbounds i8, i8* %75, i64 4
  %78 = bitcast i8* %77 to i32*
  store i32 %74, i32* %78, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_vertical_8_c(i8* nocapture, i64) #1 {
  %3 = shl i64 %1, 32
  %4 = ashr exact i64 %3, 32
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i8, i8* %0, i64 %5
  %7 = bitcast i8* %6 to i32*
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds i8, i8* %6, i64 4
  %10 = bitcast i8* %9 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = shl i64 %1, 32
  %13 = ashr exact i64 %12, 32
  %14 = bitcast i8* %0 to i32*
  store i32 %8, i32* %14, align 4
  %15 = getelementptr inbounds i8, i8* %0, i64 4
  %16 = bitcast i8* %15 to i32*
  store i32 %11, i32* %16, align 4
  %17 = getelementptr inbounds i8, i8* %0, i64 %13
  %18 = bitcast i8* %17 to i32*
  store i32 %8, i32* %18, align 4
  %19 = getelementptr inbounds i8, i8* %17, i64 4
  %20 = bitcast i8* %19 to i32*
  store i32 %11, i32* %20, align 4
  %21 = ashr exact i64 %12, 31
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = bitcast i8* %22 to i32*
  store i32 %8, i32* %23, align 4
  %24 = getelementptr inbounds i8, i8* %22, i64 4
  %25 = bitcast i8* %24 to i32*
  store i32 %11, i32* %25, align 4
  %26 = mul nsw i64 %13, 3
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = bitcast i8* %27 to i32*
  store i32 %8, i32* %28, align 4
  %29 = getelementptr inbounds i8, i8* %27, i64 4
  %30 = bitcast i8* %29 to i32*
  store i32 %11, i32* %30, align 4
  %31 = ashr exact i64 %12, 30
  %32 = getelementptr inbounds i8, i8* %0, i64 %31
  %33 = bitcast i8* %32 to i32*
  store i32 %8, i32* %33, align 4
  %34 = getelementptr inbounds i8, i8* %32, i64 4
  %35 = bitcast i8* %34 to i32*
  store i32 %11, i32* %35, align 4
  %36 = mul nsw i64 %13, 5
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = bitcast i8* %37 to i32*
  store i32 %8, i32* %38, align 4
  %39 = getelementptr inbounds i8, i8* %37, i64 4
  %40 = bitcast i8* %39 to i32*
  store i32 %11, i32* %40, align 4
  %41 = mul nsw i64 %13, 6
  %42 = getelementptr inbounds i8, i8* %0, i64 %41
  %43 = bitcast i8* %42 to i32*
  store i32 %8, i32* %43, align 4
  %44 = getelementptr inbounds i8, i8* %42, i64 4
  %45 = bitcast i8* %44 to i32*
  store i32 %11, i32* %45, align 4
  %46 = mul nsw i64 %13, 7
  %47 = getelementptr inbounds i8, i8* %0, i64 %46
  %48 = bitcast i8* %47 to i32*
  store i32 %8, i32* %48, align 4
  %49 = getelementptr inbounds i8, i8* %47, i64 4
  %50 = bitcast i8* %49 to i32*
  store i32 %11, i32* %50, align 4
  %51 = ashr exact i64 %12, 29
  %52 = getelementptr inbounds i8, i8* %0, i64 %51
  %53 = bitcast i8* %52 to i32*
  store i32 %8, i32* %53, align 4
  %54 = getelementptr inbounds i8, i8* %52, i64 4
  %55 = bitcast i8* %54 to i32*
  store i32 %11, i32* %55, align 4
  %56 = mul nsw i64 %13, 9
  %57 = getelementptr inbounds i8, i8* %0, i64 %56
  %58 = bitcast i8* %57 to i32*
  store i32 %8, i32* %58, align 4
  %59 = getelementptr inbounds i8, i8* %57, i64 4
  %60 = bitcast i8* %59 to i32*
  store i32 %11, i32* %60, align 4
  %61 = mul nsw i64 %13, 10
  %62 = getelementptr inbounds i8, i8* %0, i64 %61
  %63 = bitcast i8* %62 to i32*
  store i32 %8, i32* %63, align 4
  %64 = getelementptr inbounds i8, i8* %62, i64 4
  %65 = bitcast i8* %64 to i32*
  store i32 %11, i32* %65, align 4
  %66 = mul nsw i64 %13, 11
  %67 = getelementptr inbounds i8, i8* %0, i64 %66
  %68 = bitcast i8* %67 to i32*
  store i32 %8, i32* %68, align 4
  %69 = getelementptr inbounds i8, i8* %67, i64 4
  %70 = bitcast i8* %69 to i32*
  store i32 %11, i32* %70, align 4
  %71 = mul nsw i64 %13, 12
  %72 = getelementptr inbounds i8, i8* %0, i64 %71
  %73 = bitcast i8* %72 to i32*
  store i32 %8, i32* %73, align 4
  %74 = getelementptr inbounds i8, i8* %72, i64 4
  %75 = bitcast i8* %74 to i32*
  store i32 %11, i32* %75, align 4
  %76 = mul nsw i64 %13, 13
  %77 = getelementptr inbounds i8, i8* %0, i64 %76
  %78 = bitcast i8* %77 to i32*
  store i32 %8, i32* %78, align 4
  %79 = getelementptr inbounds i8, i8* %77, i64 4
  %80 = bitcast i8* %79 to i32*
  store i32 %11, i32* %80, align 4
  %81 = mul nsw i64 %13, 14
  %82 = getelementptr inbounds i8, i8* %0, i64 %81
  %83 = bitcast i8* %82 to i32*
  store i32 %8, i32* %83, align 4
  %84 = getelementptr inbounds i8, i8* %82, i64 4
  %85 = bitcast i8* %84 to i32*
  store i32 %11, i32* %85, align 4
  %86 = mul nsw i64 %13, 15
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = bitcast i8* %87 to i32*
  store i32 %8, i32* %88, align 4
  %89 = getelementptr inbounds i8, i8* %87, i64 4
  %90 = bitcast i8* %89 to i32*
  store i32 %11, i32* %90, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_horizontal_8_c(i8* nocapture, i64) #1 {
  %3 = getelementptr inbounds i8, i8* %0, i64 -1
  %4 = load i8, i8* %3, align 1
  %5 = zext i8 %4 to i32
  %6 = mul nuw i32 %5, 16843009
  %7 = bitcast i8* %0 to i32*
  store i32 %6, i32* %7, align 4
  %8 = getelementptr inbounds i8, i8* %0, i64 4
  %9 = bitcast i8* %8 to i32*
  store i32 %6, i32* %9, align 4
  %10 = add nsw i64 %1, -1
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = load i8, i8* %11, align 1
  %13 = zext i8 %12 to i32
  %14 = mul nuw i32 %13, 16843009
  %15 = getelementptr inbounds i8, i8* %0, i64 %1
  %16 = bitcast i8* %15 to i32*
  store i32 %14, i32* %16, align 4
  %17 = getelementptr inbounds i8, i8* %15, i64 4
  %18 = bitcast i8* %17 to i32*
  store i32 %14, i32* %18, align 4
  %19 = shl nsw i64 %1, 1
  %20 = add nsw i64 %19, -1
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = load i8, i8* %21, align 1
  %23 = zext i8 %22 to i32
  %24 = mul nuw i32 %23, 16843009
  %25 = getelementptr inbounds i8, i8* %0, i64 %19
  %26 = bitcast i8* %25 to i32*
  store i32 %24, i32* %26, align 4
  %27 = getelementptr inbounds i8, i8* %25, i64 4
  %28 = bitcast i8* %27 to i32*
  store i32 %24, i32* %28, align 4
  %29 = mul nsw i64 %1, 3
  %30 = add nsw i64 %29, -1
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = mul nuw i32 %33, 16843009
  %35 = getelementptr inbounds i8, i8* %0, i64 %29
  %36 = bitcast i8* %35 to i32*
  store i32 %34, i32* %36, align 4
  %37 = getelementptr inbounds i8, i8* %35, i64 4
  %38 = bitcast i8* %37 to i32*
  store i32 %34, i32* %38, align 4
  %39 = shl nsw i64 %1, 2
  %40 = add nsw i64 %39, -1
  %41 = getelementptr inbounds i8, i8* %0, i64 %40
  %42 = load i8, i8* %41, align 1
  %43 = zext i8 %42 to i32
  %44 = mul nuw i32 %43, 16843009
  %45 = getelementptr inbounds i8, i8* %0, i64 %39
  %46 = bitcast i8* %45 to i32*
  store i32 %44, i32* %46, align 4
  %47 = getelementptr inbounds i8, i8* %45, i64 4
  %48 = bitcast i8* %47 to i32*
  store i32 %44, i32* %48, align 4
  %49 = mul nsw i64 %1, 5
  %50 = add nsw i64 %49, -1
  %51 = getelementptr inbounds i8, i8* %0, i64 %50
  %52 = load i8, i8* %51, align 1
  %53 = zext i8 %52 to i32
  %54 = mul nuw i32 %53, 16843009
  %55 = getelementptr inbounds i8, i8* %0, i64 %49
  %56 = bitcast i8* %55 to i32*
  store i32 %54, i32* %56, align 4
  %57 = getelementptr inbounds i8, i8* %55, i64 4
  %58 = bitcast i8* %57 to i32*
  store i32 %54, i32* %58, align 4
  %59 = mul nsw i64 %1, 6
  %60 = add nsw i64 %59, -1
  %61 = getelementptr inbounds i8, i8* %0, i64 %60
  %62 = load i8, i8* %61, align 1
  %63 = zext i8 %62 to i32
  %64 = mul nuw i32 %63, 16843009
  %65 = getelementptr inbounds i8, i8* %0, i64 %59
  %66 = bitcast i8* %65 to i32*
  store i32 %64, i32* %66, align 4
  %67 = getelementptr inbounds i8, i8* %65, i64 4
  %68 = bitcast i8* %67 to i32*
  store i32 %64, i32* %68, align 4
  %69 = mul nsw i64 %1, 7
  %70 = add nsw i64 %69, -1
  %71 = getelementptr inbounds i8, i8* %0, i64 %70
  %72 = load i8, i8* %71, align 1
  %73 = zext i8 %72 to i32
  %74 = mul nuw i32 %73, 16843009
  %75 = getelementptr inbounds i8, i8* %0, i64 %69
  %76 = bitcast i8* %75 to i32*
  store i32 %74, i32* %76, align 4
  %77 = getelementptr inbounds i8, i8* %75, i64 4
  %78 = bitcast i8* %77 to i32*
  store i32 %74, i32* %78, align 4
  %79 = shl nsw i64 %1, 3
  %80 = add nsw i64 %79, -1
  %81 = getelementptr inbounds i8, i8* %0, i64 %80
  %82 = load i8, i8* %81, align 1
  %83 = zext i8 %82 to i32
  %84 = mul nuw i32 %83, 16843009
  %85 = getelementptr inbounds i8, i8* %0, i64 %79
  %86 = bitcast i8* %85 to i32*
  store i32 %84, i32* %86, align 4
  %87 = getelementptr inbounds i8, i8* %85, i64 4
  %88 = bitcast i8* %87 to i32*
  store i32 %84, i32* %88, align 4
  %89 = mul nsw i64 %1, 9
  %90 = add nsw i64 %89, -1
  %91 = getelementptr inbounds i8, i8* %0, i64 %90
  %92 = load i8, i8* %91, align 1
  %93 = zext i8 %92 to i32
  %94 = mul nuw i32 %93, 16843009
  %95 = getelementptr inbounds i8, i8* %0, i64 %89
  %96 = bitcast i8* %95 to i32*
  store i32 %94, i32* %96, align 4
  %97 = getelementptr inbounds i8, i8* %95, i64 4
  %98 = bitcast i8* %97 to i32*
  store i32 %94, i32* %98, align 4
  %99 = mul nsw i64 %1, 10
  %100 = add nsw i64 %99, -1
  %101 = getelementptr inbounds i8, i8* %0, i64 %100
  %102 = load i8, i8* %101, align 1
  %103 = zext i8 %102 to i32
  %104 = mul nuw i32 %103, 16843009
  %105 = getelementptr inbounds i8, i8* %0, i64 %99
  %106 = bitcast i8* %105 to i32*
  store i32 %104, i32* %106, align 4
  %107 = getelementptr inbounds i8, i8* %105, i64 4
  %108 = bitcast i8* %107 to i32*
  store i32 %104, i32* %108, align 4
  %109 = mul nsw i64 %1, 11
  %110 = add nsw i64 %109, -1
  %111 = getelementptr inbounds i8, i8* %0, i64 %110
  %112 = load i8, i8* %111, align 1
  %113 = zext i8 %112 to i32
  %114 = mul nuw i32 %113, 16843009
  %115 = getelementptr inbounds i8, i8* %0, i64 %109
  %116 = bitcast i8* %115 to i32*
  store i32 %114, i32* %116, align 4
  %117 = getelementptr inbounds i8, i8* %115, i64 4
  %118 = bitcast i8* %117 to i32*
  store i32 %114, i32* %118, align 4
  %119 = mul nsw i64 %1, 12
  %120 = add nsw i64 %119, -1
  %121 = getelementptr inbounds i8, i8* %0, i64 %120
  %122 = load i8, i8* %121, align 1
  %123 = zext i8 %122 to i32
  %124 = mul nuw i32 %123, 16843009
  %125 = getelementptr inbounds i8, i8* %0, i64 %119
  %126 = bitcast i8* %125 to i32*
  store i32 %124, i32* %126, align 4
  %127 = getelementptr inbounds i8, i8* %125, i64 4
  %128 = bitcast i8* %127 to i32*
  store i32 %124, i32* %128, align 4
  %129 = mul nsw i64 %1, 13
  %130 = add nsw i64 %129, -1
  %131 = getelementptr inbounds i8, i8* %0, i64 %130
  %132 = load i8, i8* %131, align 1
  %133 = zext i8 %132 to i32
  %134 = mul nuw i32 %133, 16843009
  %135 = getelementptr inbounds i8, i8* %0, i64 %129
  %136 = bitcast i8* %135 to i32*
  store i32 %134, i32* %136, align 4
  %137 = getelementptr inbounds i8, i8* %135, i64 4
  %138 = bitcast i8* %137 to i32*
  store i32 %134, i32* %138, align 4
  %139 = mul nsw i64 %1, 14
  %140 = add nsw i64 %139, -1
  %141 = getelementptr inbounds i8, i8* %0, i64 %140
  %142 = load i8, i8* %141, align 1
  %143 = zext i8 %142 to i32
  %144 = mul nuw i32 %143, 16843009
  %145 = getelementptr inbounds i8, i8* %0, i64 %139
  %146 = bitcast i8* %145 to i32*
  store i32 %144, i32* %146, align 4
  %147 = getelementptr inbounds i8, i8* %145, i64 4
  %148 = bitcast i8* %147 to i32*
  store i32 %144, i32* %148, align 4
  %149 = mul nsw i64 %1, 15
  %150 = add nsw i64 %149, -1
  %151 = getelementptr inbounds i8, i8* %0, i64 %150
  %152 = load i8, i8* %151, align 1
  %153 = zext i8 %152 to i32
  %154 = mul nuw i32 %153, 16843009
  %155 = getelementptr inbounds i8, i8* %0, i64 %149
  %156 = bitcast i8* %155 to i32*
  store i32 %154, i32* %156, align 4
  %157 = getelementptr inbounds i8, i8* %155, i64 4
  %158 = bitcast i8* %157 to i32*
  store i32 %154, i32* %158, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_plane_8_c(i8* nocapture, i64) #1 {
  %3 = trunc i64 %1 to i32
  %4 = getelementptr inbounds i8, i8* %0, i64 3
  %5 = shl i64 %1, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i8, i8* %4, i64 %7
  %9 = shl nsw i32 %3, 2
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = getelementptr inbounds i8, i8* %11, i64 -1
  %13 = shl nsw i32 %3, 1
  %14 = sext i32 %13 to i64
  %15 = sub nsw i64 0, %14
  %16 = getelementptr inbounds i8, i8* %12, i64 %15
  %17 = getelementptr inbounds i8, i8* %8, i64 1
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = getelementptr inbounds i8, i8* %8, i64 -1
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  %23 = sub nsw i32 %19, %22
  %24 = load i8, i8* %12, align 1
  %25 = zext i8 %24 to i32
  %26 = load i8, i8* %16, align 1
  %27 = zext i8 %26 to i32
  %28 = sub nsw i32 %25, %27
  %29 = shl i64 %1, 32
  %30 = ashr exact i64 %29, 32
  %31 = mul nsw i64 %30, 3
  %32 = add nsw i64 %31, %10
  %33 = add nsw i64 %32, -1
  %34 = xor i64 %14, -1
  %35 = add nsw i64 %34, %10
  %36 = sub nsw i64 %35, %31
  %37 = getelementptr inbounds i8, i8* %12, i64 %6
  %38 = getelementptr inbounds i8, i8* %16, i64 %7
  %39 = getelementptr inbounds i8, i8* %8, i64 2
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i32
  %42 = getelementptr inbounds i8, i8* %8, i64 -2
  %43 = load i8, i8* %42, align 1
  %44 = zext i8 %43 to i32
  %45 = sub nsw i32 %41, %44
  %46 = shl nsw i32 %45, 1
  %47 = add nsw i32 %46, %23
  %48 = load i8, i8* %37, align 1
  %49 = zext i8 %48 to i32
  %50 = load i8, i8* %38, align 1
  %51 = zext i8 %50 to i32
  %52 = sub nsw i32 %49, %51
  %53 = shl nsw i32 %52, 1
  %54 = add nsw i32 %53, %28
  %55 = getelementptr inbounds i8, i8* %37, i64 %6
  %56 = getelementptr inbounds i8, i8* %38, i64 %7
  %57 = getelementptr inbounds i8, i8* %8, i64 3
  %58 = load i8, i8* %57, align 1
  %59 = zext i8 %58 to i32
  %60 = getelementptr inbounds i8, i8* %8, i64 -3
  %61 = load i8, i8* %60, align 1
  %62 = zext i8 %61 to i32
  %63 = sub nsw i32 %59, %62
  %64 = mul nsw i32 %63, 3
  %65 = add nsw i32 %64, %47
  %66 = load i8, i8* %55, align 1
  %67 = zext i8 %66 to i32
  %68 = load i8, i8* %56, align 1
  %69 = zext i8 %68 to i32
  %70 = sub nsw i32 %67, %69
  %71 = mul nsw i32 %70, 3
  %72 = add nsw i32 %71, %54
  %73 = getelementptr inbounds i8, i8* %55, i64 %6
  %74 = getelementptr inbounds i8, i8* %56, i64 %7
  %75 = getelementptr inbounds i8, i8* %8, i64 4
  %76 = load i8, i8* %75, align 1
  %77 = zext i8 %76 to i32
  %78 = getelementptr inbounds i8, i8* %8, i64 -4
  %79 = load i8, i8* %78, align 1
  %80 = zext i8 %79 to i32
  %81 = sub nsw i32 %77, %80
  %82 = shl nsw i32 %81, 2
  %83 = add nsw i32 %82, %65
  %84 = load i8, i8* %73, align 1
  %85 = zext i8 %84 to i32
  %86 = load i8, i8* %74, align 1
  %87 = zext i8 %86 to i32
  %88 = sub nsw i32 %85, %87
  %89 = shl nsw i32 %88, 2
  %90 = add nsw i32 %89, %72
  %91 = getelementptr i8, i8* %0, i64 %33
  %92 = getelementptr i8, i8* %0, i64 %36
  %93 = mul nsw i32 %83, 17
  %94 = add nsw i32 %93, 16
  %95 = ashr i32 %94, 5
  %96 = mul nsw i32 %90, 17
  %97 = add nsw i32 %96, 16
  %98 = ashr i32 %97, 5
  %99 = load i8, i8* %91, align 1
  %100 = zext i8 %99 to i32
  %101 = getelementptr inbounds i8, i8* %92, i64 8
  %102 = load i8, i8* %101, align 1
  %103 = zext i8 %102 to i32
  %104 = add nuw nsw i32 %103, %100
  %105 = shl nuw nsw i32 %104, 4
  %106 = add nsw i32 %98, %95
  %107 = mul nsw i32 %106, -3
  %108 = add nsw i32 %107, 16
  %109 = add nsw i32 %108, %105
  %110 = shl nsw i32 %95, 1
  %111 = mul nsw i32 %95, 3
  %112 = shl nsw i32 %95, 2
  %113 = mul nsw i32 %95, 5
  %114 = mul nsw i32 %95, 6
  %115 = mul nsw i32 %95, 7
  br label %116

116:                                              ; preds = %116, %2
  %117 = phi i32 [ 8, %2 ], [ %184, %116 ]
  %118 = phi i8* [ %0, %2 ], [ %183, %116 ]
  %119 = phi i32 [ %109, %2 ], [ %120, %116 ]
  %120 = add nsw i32 %119, %98
  %121 = ashr i32 %119, 5
  %122 = icmp ugt i32 %121, 255
  %123 = ashr i32 %119, 31
  %124 = xor i32 %123, 255
  %125 = select i1 %122, i32 %124, i32 %121
  %126 = trunc i32 %125 to i8
  store i8 %126, i8* %118, align 1
  %127 = add nsw i32 %119, %95
  %128 = ashr i32 %127, 5
  %129 = icmp ugt i32 %128, 255
  %130 = ashr i32 %127, 31
  %131 = xor i32 %130, 255
  %132 = select i1 %129, i32 %131, i32 %128
  %133 = trunc i32 %132 to i8
  %134 = getelementptr inbounds i8, i8* %118, i64 1
  store i8 %133, i8* %134, align 1
  %135 = add nsw i32 %119, %110
  %136 = ashr i32 %135, 5
  %137 = icmp ugt i32 %136, 255
  %138 = ashr i32 %135, 31
  %139 = xor i32 %138, 255
  %140 = select i1 %137, i32 %139, i32 %136
  %141 = trunc i32 %140 to i8
  %142 = getelementptr inbounds i8, i8* %118, i64 2
  store i8 %141, i8* %142, align 1
  %143 = add nsw i32 %119, %111
  %144 = ashr i32 %143, 5
  %145 = icmp ugt i32 %144, 255
  %146 = ashr i32 %143, 31
  %147 = xor i32 %146, 255
  %148 = select i1 %145, i32 %147, i32 %144
  %149 = trunc i32 %148 to i8
  %150 = getelementptr inbounds i8, i8* %118, i64 3
  store i8 %149, i8* %150, align 1
  %151 = add nsw i32 %119, %112
  %152 = ashr i32 %151, 5
  %153 = icmp ugt i32 %152, 255
  %154 = ashr i32 %151, 31
  %155 = xor i32 %154, 255
  %156 = select i1 %153, i32 %155, i32 %152
  %157 = trunc i32 %156 to i8
  %158 = getelementptr inbounds i8, i8* %118, i64 4
  store i8 %157, i8* %158, align 1
  %159 = add nsw i32 %119, %113
  %160 = ashr i32 %159, 5
  %161 = icmp ugt i32 %160, 255
  %162 = ashr i32 %159, 31
  %163 = xor i32 %162, 255
  %164 = select i1 %161, i32 %163, i32 %160
  %165 = trunc i32 %164 to i8
  %166 = getelementptr inbounds i8, i8* %118, i64 5
  store i8 %165, i8* %166, align 1
  %167 = add nsw i32 %119, %114
  %168 = ashr i32 %167, 5
  %169 = icmp ugt i32 %168, 255
  %170 = ashr i32 %167, 31
  %171 = xor i32 %170, 255
  %172 = select i1 %169, i32 %171, i32 %168
  %173 = trunc i32 %172 to i8
  %174 = getelementptr inbounds i8, i8* %118, i64 6
  store i8 %173, i8* %174, align 1
  %175 = add nsw i32 %119, %115
  %176 = ashr i32 %175, 5
  %177 = icmp ugt i32 %176, 255
  %178 = ashr i32 %175, 31
  %179 = xor i32 %178, 255
  %180 = select i1 %177, i32 %179, i32 %176
  %181 = trunc i32 %180 to i8
  %182 = getelementptr inbounds i8, i8* %118, i64 7
  store i8 %181, i8* %182, align 1
  %183 = getelementptr inbounds i8, i8* %118, i64 %6
  %184 = add nsw i32 %117, -1
  %185 = icmp eq i32 %184, 0
  br i1 %185, label %186, label %116

186:                                              ; preds = %116
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_plane_8_c(i8* nocapture, i64) #1 {
  %3 = trunc i64 %1 to i32
  %4 = getelementptr inbounds i8, i8* %0, i64 3
  %5 = shl i64 %1, 32
  %6 = ashr exact i64 %5, 32
  %7 = sub nsw i64 0, %6
  %8 = getelementptr inbounds i8, i8* %4, i64 %7
  %9 = shl nsw i32 %3, 3
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = getelementptr inbounds i8, i8* %11, i64 -1
  %13 = shl nsw i32 %3, 1
  %14 = sext i32 %13 to i64
  %15 = sub nsw i64 0, %14
  %16 = getelementptr inbounds i8, i8* %12, i64 %15
  %17 = getelementptr inbounds i8, i8* %8, i64 1
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = getelementptr inbounds i8, i8* %8, i64 -1
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  %23 = sub nsw i32 %19, %22
  %24 = xor i64 %14, -1
  %25 = add nsw i64 %24, %10
  %26 = shl i64 %1, 32
  %27 = ashr exact i64 %26, 32
  %28 = mul nsw i64 %27, 3
  %29 = add nsw i64 %28, %10
  %30 = add nsw i64 %29, -1
  %31 = sub nsw i64 %25, %28
  %32 = getelementptr inbounds i8, i8* %12, i64 %6
  %33 = getelementptr inbounds i8, i8* %16, i64 %7
  %34 = getelementptr inbounds i8, i8* %8, i64 2
  %35 = load i8, i8* %34, align 1
  %36 = zext i8 %35 to i32
  %37 = getelementptr inbounds i8, i8* %8, i64 -2
  %38 = load i8, i8* %37, align 1
  %39 = zext i8 %38 to i32
  %40 = sub nsw i32 %36, %39
  %41 = shl nsw i32 %40, 1
  %42 = add nsw i32 %41, %23
  %43 = getelementptr inbounds i8, i8* %32, i64 %6
  %44 = getelementptr inbounds i8, i8* %33, i64 %7
  %45 = getelementptr inbounds i8, i8* %8, i64 3
  %46 = load i8, i8* %45, align 1
  %47 = zext i8 %46 to i32
  %48 = getelementptr inbounds i8, i8* %8, i64 -3
  %49 = load i8, i8* %48, align 1
  %50 = zext i8 %49 to i32
  %51 = sub nsw i32 %47, %50
  %52 = mul nsw i32 %51, 3
  %53 = add nsw i32 %52, %42
  %54 = getelementptr inbounds i8, i8* %8, i64 4
  %55 = load i8, i8* %54, align 1
  %56 = zext i8 %55 to i32
  %57 = getelementptr inbounds i8, i8* %8, i64 -4
  %58 = load i8, i8* %57, align 1
  %59 = zext i8 %58 to i32
  %60 = sub nsw i32 %56, %59
  %61 = shl nsw i32 %60, 2
  %62 = add nsw i32 %61, %53
  %63 = getelementptr i8, i8* %0, i64 %30
  %64 = getelementptr i8, i8* %0, i64 %31
  %65 = getelementptr inbounds i8, i8* %43, i64 %6
  %66 = load i8, i8* %65, align 1
  %67 = zext i8 %66 to i32
  %68 = getelementptr inbounds i8, i8* %44, i64 %7
  %69 = load i8, i8* %68, align 1
  %70 = zext i8 %69 to i32
  %71 = sub nsw i32 %67, %70
  %72 = shl nsw i32 %71, 2
  %73 = load i8, i8* %43, align 1
  %74 = zext i8 %73 to i32
  %75 = load i8, i8* %44, align 1
  %76 = zext i8 %75 to i32
  %77 = sub nsw i32 %74, %76
  %78 = mul nsw i32 %77, 3
  %79 = load i8, i8* %32, align 1
  %80 = zext i8 %79 to i32
  %81 = load i8, i8* %33, align 1
  %82 = zext i8 %81 to i32
  %83 = sub nsw i32 %80, %82
  %84 = shl nsw i32 %83, 1
  %85 = load i8, i8* %12, align 1
  %86 = zext i8 %85 to i32
  %87 = load i8, i8* %16, align 1
  %88 = zext i8 %87 to i32
  %89 = sub nsw i32 %86, %88
  %90 = add nsw i32 %84, %89
  %91 = add nsw i32 %78, %90
  %92 = add nsw i32 %72, %91
  %93 = mul nsw i64 %27, -3
  %94 = ashr exact i64 %26, 30
  %95 = getelementptr inbounds i8, i8* %63, i64 %6
  %96 = getelementptr inbounds i8, i8* %64, i64 %7
  %97 = load i8, i8* %95, align 1
  %98 = zext i8 %97 to i32
  %99 = load i8, i8* %96, align 1
  %100 = zext i8 %99 to i32
  %101 = sub nsw i32 %98, %100
  %102 = mul nsw i32 %101, 5
  %103 = add nsw i32 %102, %92
  %104 = getelementptr inbounds i8, i8* %95, i64 %6
  %105 = getelementptr inbounds i8, i8* %96, i64 %7
  %106 = load i8, i8* %104, align 1
  %107 = zext i8 %106 to i32
  %108 = load i8, i8* %105, align 1
  %109 = zext i8 %108 to i32
  %110 = sub nsw i32 %107, %109
  %111 = mul nsw i32 %110, 6
  %112 = add nsw i32 %111, %103
  %113 = getelementptr inbounds i8, i8* %104, i64 %6
  %114 = getelementptr inbounds i8, i8* %105, i64 %7
  %115 = load i8, i8* %113, align 1
  %116 = zext i8 %115 to i32
  %117 = load i8, i8* %114, align 1
  %118 = zext i8 %117 to i32
  %119 = sub nsw i32 %116, %118
  %120 = mul nsw i32 %119, 7
  %121 = add nsw i32 %120, %112
  %122 = getelementptr inbounds i8, i8* %113, i64 %6
  %123 = getelementptr inbounds i8, i8* %114, i64 %7
  %124 = load i8, i8* %122, align 1
  %125 = zext i8 %124 to i32
  %126 = load i8, i8* %123, align 1
  %127 = zext i8 %126 to i32
  %128 = sub nsw i32 %125, %127
  %129 = shl nsw i32 %128, 3
  %130 = add nsw i32 %129, %121
  %131 = getelementptr i8, i8* %64, i64 %93
  %132 = getelementptr i8, i8* %63, i64 %94
  %133 = mul i32 %130, 5
  %134 = add i32 %133, 32
  %135 = ashr i32 %134, 6
  %136 = getelementptr inbounds i8, i8* %131, i64 %7
  %137 = mul nsw i32 %62, 17
  %138 = add nsw i32 %137, 16
  %139 = ashr i32 %138, 5
  %140 = load i8, i8* %132, align 1
  %141 = zext i8 %140 to i32
  %142 = getelementptr inbounds i8, i8* %136, i64 8
  %143 = load i8, i8* %142, align 1
  %144 = zext i8 %143 to i32
  %145 = add nuw nsw i32 %144, %141
  %146 = shl nuw nsw i32 %145, 4
  %147 = mul nsw i32 %135, -7
  %148 = mul nsw i32 %139, 3
  %149 = sub nsw i32 16, %148
  %150 = add nsw i32 %149, %147
  %151 = add nsw i32 %150, %146
  %152 = shl nsw i32 %139, 1
  %153 = shl nsw i32 %139, 2
  %154 = mul nsw i32 %139, 5
  %155 = mul nsw i32 %139, 6
  %156 = mul nsw i32 %139, 7
  br label %157

157:                                              ; preds = %157, %2
  %158 = phi i32 [ 16, %2 ], [ %225, %157 ]
  %159 = phi i8* [ %0, %2 ], [ %224, %157 ]
  %160 = phi i32 [ %151, %2 ], [ %161, %157 ]
  %161 = add nsw i32 %160, %135
  %162 = ashr i32 %160, 5
  %163 = icmp ugt i32 %162, 255
  %164 = ashr i32 %160, 31
  %165 = xor i32 %164, 255
  %166 = select i1 %163, i32 %165, i32 %162
  %167 = trunc i32 %166 to i8
  store i8 %167, i8* %159, align 1
  %168 = add nsw i32 %160, %139
  %169 = ashr i32 %168, 5
  %170 = icmp ugt i32 %169, 255
  %171 = ashr i32 %168, 31
  %172 = xor i32 %171, 255
  %173 = select i1 %170, i32 %172, i32 %169
  %174 = trunc i32 %173 to i8
  %175 = getelementptr inbounds i8, i8* %159, i64 1
  store i8 %174, i8* %175, align 1
  %176 = add nsw i32 %160, %152
  %177 = ashr i32 %176, 5
  %178 = icmp ugt i32 %177, 255
  %179 = ashr i32 %176, 31
  %180 = xor i32 %179, 255
  %181 = select i1 %178, i32 %180, i32 %177
  %182 = trunc i32 %181 to i8
  %183 = getelementptr inbounds i8, i8* %159, i64 2
  store i8 %182, i8* %183, align 1
  %184 = add nsw i32 %160, %148
  %185 = ashr i32 %184, 5
  %186 = icmp ugt i32 %185, 255
  %187 = ashr i32 %184, 31
  %188 = xor i32 %187, 255
  %189 = select i1 %186, i32 %188, i32 %185
  %190 = trunc i32 %189 to i8
  %191 = getelementptr inbounds i8, i8* %159, i64 3
  store i8 %190, i8* %191, align 1
  %192 = add nsw i32 %160, %153
  %193 = ashr i32 %192, 5
  %194 = icmp ugt i32 %193, 255
  %195 = ashr i32 %192, 31
  %196 = xor i32 %195, 255
  %197 = select i1 %194, i32 %196, i32 %193
  %198 = trunc i32 %197 to i8
  %199 = getelementptr inbounds i8, i8* %159, i64 4
  store i8 %198, i8* %199, align 1
  %200 = add nsw i32 %160, %154
  %201 = ashr i32 %200, 5
  %202 = icmp ugt i32 %201, 255
  %203 = ashr i32 %200, 31
  %204 = xor i32 %203, 255
  %205 = select i1 %202, i32 %204, i32 %201
  %206 = trunc i32 %205 to i8
  %207 = getelementptr inbounds i8, i8* %159, i64 5
  store i8 %206, i8* %207, align 1
  %208 = add nsw i32 %160, %155
  %209 = ashr i32 %208, 5
  %210 = icmp ugt i32 %209, 255
  %211 = ashr i32 %208, 31
  %212 = xor i32 %211, 255
  %213 = select i1 %210, i32 %212, i32 %209
  %214 = trunc i32 %213 to i8
  %215 = getelementptr inbounds i8, i8* %159, i64 6
  store i8 %214, i8* %215, align 1
  %216 = add nsw i32 %160, %156
  %217 = ashr i32 %216, 5
  %218 = icmp ugt i32 %217, 255
  %219 = ashr i32 %216, 31
  %220 = xor i32 %219, 255
  %221 = select i1 %218, i32 %220, i32 %217
  %222 = trunc i32 %221 to i8
  %223 = getelementptr inbounds i8, i8* %159, i64 7
  store i8 %222, i8* %223, align 1
  %224 = getelementptr inbounds i8, i8* %159, i64 %6
  %225 = add nsw i32 %158, -1
  %226 = icmp eq i32 %225, 0
  br i1 %226, label %227, label %157

227:                                              ; preds = %157
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_dc_8_c(i8* nocapture, i64) #1 {
  %3 = getelementptr inbounds i8, i8* %0, i64 -1
  %4 = load i8, i8* %3, align 1
  %5 = zext i8 %4 to i32
  %6 = sub nsw i64 0, %1
  %7 = getelementptr inbounds i8, i8* %0, i64 %6
  %8 = load i8, i8* %7, align 1
  %9 = zext i8 %8 to i32
  %10 = add nuw nsw i32 %5, %9
  %11 = sub nsw i64 4, %1
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = shl nsw i64 %1, 2
  %16 = add nsw i64 %15, -1
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = add nsw i64 %1, -1
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = load i8, i8* %21, align 1
  %23 = zext i8 %22 to i32
  %24 = sub nsw i64 1, %1
  %25 = getelementptr inbounds i8, i8* %0, i64 %24
  %26 = load i8, i8* %25, align 1
  %27 = zext i8 %26 to i32
  %28 = add nuw nsw i32 %10, %23
  %29 = add nuw nsw i32 %28, %27
  %30 = sub nsw i64 5, %1
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = add nuw nsw i32 %14, %33
  %35 = mul nsw i64 %1, 5
  %36 = add nsw i64 %35, -1
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = load i8, i8* %37, align 1
  %39 = zext i8 %38 to i32
  %40 = add nuw nsw i32 %19, %39
  %41 = shl nsw i64 %1, 1
  %42 = add nsw i64 %41, -1
  %43 = getelementptr inbounds i8, i8* %0, i64 %42
  %44 = load i8, i8* %43, align 1
  %45 = zext i8 %44 to i32
  %46 = sub nsw i64 2, %1
  %47 = getelementptr inbounds i8, i8* %0, i64 %46
  %48 = load i8, i8* %47, align 1
  %49 = zext i8 %48 to i32
  %50 = add nuw nsw i32 %29, %45
  %51 = add nuw nsw i32 %50, %49
  %52 = sub nsw i64 6, %1
  %53 = getelementptr inbounds i8, i8* %0, i64 %52
  %54 = load i8, i8* %53, align 1
  %55 = zext i8 %54 to i32
  %56 = add nuw nsw i32 %34, %55
  %57 = mul nsw i64 %1, 6
  %58 = add nsw i64 %57, -1
  %59 = getelementptr inbounds i8, i8* %0, i64 %58
  %60 = load i8, i8* %59, align 1
  %61 = zext i8 %60 to i32
  %62 = add nuw nsw i32 %40, %61
  %63 = mul nsw i64 %1, 3
  %64 = add nsw i64 %63, -1
  %65 = getelementptr inbounds i8, i8* %0, i64 %64
  %66 = load i8, i8* %65, align 1
  %67 = zext i8 %66 to i32
  %68 = sub nsw i64 3, %1
  %69 = getelementptr inbounds i8, i8* %0, i64 %68
  %70 = load i8, i8* %69, align 1
  %71 = zext i8 %70 to i32
  %72 = add nuw nsw i32 %51, %67
  %73 = add nuw nsw i32 %72, %71
  %74 = sub nsw i64 7, %1
  %75 = getelementptr inbounds i8, i8* %0, i64 %74
  %76 = load i8, i8* %75, align 1
  %77 = zext i8 %76 to i32
  %78 = add nuw nsw i32 %56, %77
  %79 = mul nsw i64 %1, 7
  %80 = add nsw i64 %79, -1
  %81 = getelementptr inbounds i8, i8* %0, i64 %80
  %82 = load i8, i8* %81, align 1
  %83 = zext i8 %82 to i32
  %84 = add nuw nsw i32 %62, %83
  %85 = add nuw nsw i32 %73, 4
  %86 = lshr i32 %85, 3
  %87 = mul i32 %86, 16843009
  %88 = add nuw nsw i32 %78, 2
  %89 = lshr i32 %88, 2
  %90 = mul i32 %89, 16843009
  %91 = add nuw nsw i32 %84, 2
  %92 = lshr i32 %91, 2
  %93 = add nuw nsw i32 %78, 4
  %94 = add nuw nsw i32 %93, %84
  %95 = lshr i32 %94, 3
  %96 = bitcast i8* %0 to i32*
  store i32 %87, i32* %96, align 4
  %97 = getelementptr inbounds i8, i8* %0, i64 4
  %98 = bitcast i8* %97 to i32*
  store i32 %90, i32* %98, align 4
  %99 = getelementptr inbounds i8, i8* %0, i64 %1
  %100 = bitcast i8* %99 to i32*
  store i32 %87, i32* %100, align 4
  %101 = getelementptr inbounds i8, i8* %99, i64 4
  %102 = bitcast i8* %101 to i32*
  store i32 %90, i32* %102, align 4
  %103 = getelementptr inbounds i8, i8* %0, i64 %41
  %104 = bitcast i8* %103 to i32*
  store i32 %87, i32* %104, align 4
  %105 = getelementptr inbounds i8, i8* %103, i64 4
  %106 = bitcast i8* %105 to i32*
  store i32 %90, i32* %106, align 4
  %107 = getelementptr inbounds i8, i8* %0, i64 %63
  %108 = bitcast i8* %107 to i32*
  store i32 %87, i32* %108, align 4
  %109 = getelementptr inbounds i8, i8* %107, i64 4
  %110 = bitcast i8* %109 to i32*
  store i32 %90, i32* %110, align 4
  %111 = mul i32 %92, 16843009
  %112 = mul i32 %95, 16843009
  %113 = getelementptr inbounds i8, i8* %0, i64 %15
  %114 = bitcast i8* %113 to i32*
  store i32 %111, i32* %114, align 4
  %115 = getelementptr inbounds i8, i8* %113, i64 4
  %116 = bitcast i8* %115 to i32*
  store i32 %112, i32* %116, align 4
  %117 = getelementptr inbounds i8, i8* %0, i64 %35
  %118 = bitcast i8* %117 to i32*
  store i32 %111, i32* %118, align 4
  %119 = getelementptr inbounds i8, i8* %117, i64 4
  %120 = bitcast i8* %119 to i32*
  store i32 %112, i32* %120, align 4
  %121 = getelementptr inbounds i8, i8* %0, i64 %57
  %122 = bitcast i8* %121 to i32*
  store i32 %111, i32* %122, align 4
  %123 = getelementptr inbounds i8, i8* %121, i64 4
  %124 = bitcast i8* %123 to i32*
  store i32 %112, i32* %124, align 4
  %125 = getelementptr inbounds i8, i8* %0, i64 %79
  %126 = bitcast i8* %125 to i32*
  store i32 %111, i32* %126, align 4
  %127 = getelementptr inbounds i8, i8* %125, i64 4
  %128 = bitcast i8* %127 to i32*
  store i32 %112, i32* %128, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_left_dc_8_c(i8* nocapture, i64) #1 {
  %3 = getelementptr inbounds i8, i8* %0, i64 -1
  %4 = load i8, i8* %3, align 1
  %5 = zext i8 %4 to i32
  %6 = shl nsw i64 %1, 2
  %7 = add nsw i64 %6, -1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = add nsw i64 %1, -1
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = add nuw nsw i32 %5, %14
  %16 = mul nsw i64 %1, 5
  %17 = add nsw i64 %16, -1
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = add nuw nsw i32 %10, %20
  %22 = shl nsw i64 %1, 1
  %23 = add nsw i64 %22, -1
  %24 = getelementptr inbounds i8, i8* %0, i64 %23
  %25 = load i8, i8* %24, align 1
  %26 = zext i8 %25 to i32
  %27 = add nuw nsw i32 %15, %26
  %28 = mul nsw i64 %1, 6
  %29 = add nsw i64 %28, -1
  %30 = getelementptr inbounds i8, i8* %0, i64 %29
  %31 = load i8, i8* %30, align 1
  %32 = zext i8 %31 to i32
  %33 = add nuw nsw i32 %21, %32
  %34 = mul nsw i64 %1, 3
  %35 = add nsw i64 %34, -1
  %36 = getelementptr inbounds i8, i8* %0, i64 %35
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i32
  %39 = add nuw nsw i32 %27, %38
  %40 = mul nsw i64 %1, 7
  %41 = add nsw i64 %40, -1
  %42 = getelementptr inbounds i8, i8* %0, i64 %41
  %43 = load i8, i8* %42, align 1
  %44 = zext i8 %43 to i32
  %45 = add nuw nsw i32 %33, %44
  %46 = add nuw nsw i32 %39, 2
  %47 = lshr i32 %46, 2
  %48 = mul i32 %47, 16843009
  %49 = add nuw nsw i32 %45, 2
  %50 = lshr i32 %49, 2
  %51 = bitcast i8* %0 to i32*
  store i32 %48, i32* %51, align 4
  %52 = getelementptr inbounds i8, i8* %0, i64 4
  %53 = bitcast i8* %52 to i32*
  store i32 %48, i32* %53, align 4
  %54 = getelementptr inbounds i8, i8* %0, i64 %1
  %55 = bitcast i8* %54 to i32*
  store i32 %48, i32* %55, align 4
  %56 = getelementptr inbounds i8, i8* %54, i64 4
  %57 = bitcast i8* %56 to i32*
  store i32 %48, i32* %57, align 4
  %58 = getelementptr inbounds i8, i8* %0, i64 %22
  %59 = bitcast i8* %58 to i32*
  store i32 %48, i32* %59, align 4
  %60 = getelementptr inbounds i8, i8* %58, i64 4
  %61 = bitcast i8* %60 to i32*
  store i32 %48, i32* %61, align 4
  %62 = getelementptr inbounds i8, i8* %0, i64 %34
  %63 = bitcast i8* %62 to i32*
  store i32 %48, i32* %63, align 4
  %64 = getelementptr inbounds i8, i8* %62, i64 4
  %65 = bitcast i8* %64 to i32*
  store i32 %48, i32* %65, align 4
  %66 = mul i32 %50, 16843009
  %67 = getelementptr inbounds i8, i8* %0, i64 %6
  %68 = bitcast i8* %67 to i32*
  store i32 %66, i32* %68, align 4
  %69 = getelementptr inbounds i8, i8* %67, i64 4
  %70 = bitcast i8* %69 to i32*
  store i32 %66, i32* %70, align 4
  %71 = getelementptr inbounds i8, i8* %0, i64 %16
  %72 = bitcast i8* %71 to i32*
  store i32 %66, i32* %72, align 4
  %73 = getelementptr inbounds i8, i8* %71, i64 4
  %74 = bitcast i8* %73 to i32*
  store i32 %66, i32* %74, align 4
  %75 = getelementptr inbounds i8, i8* %0, i64 %28
  %76 = bitcast i8* %75 to i32*
  store i32 %66, i32* %76, align 4
  %77 = getelementptr inbounds i8, i8* %75, i64 4
  %78 = bitcast i8* %77 to i32*
  store i32 %66, i32* %78, align 4
  %79 = getelementptr inbounds i8, i8* %0, i64 %40
  %80 = bitcast i8* %79 to i32*
  store i32 %66, i32* %80, align 4
  %81 = getelementptr inbounds i8, i8* %79, i64 4
  %82 = bitcast i8* %81 to i32*
  store i32 %66, i32* %82, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_top_dc_8_c(i8* nocapture, i64) #1 {
  %3 = sub nsw i64 0, %1
  %4 = getelementptr inbounds i8, i8* %0, i64 %3
  %5 = load i8, i8* %4, align 1
  %6 = zext i8 %5 to i32
  %7 = sub nsw i64 4, %1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = sub nsw i64 1, %1
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = add nuw nsw i32 %6, %14
  %16 = sub nsw i64 5, %1
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = add nuw nsw i32 %10, %19
  %21 = sub nsw i64 2, %1
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = add nuw nsw i32 %15, %24
  %26 = sub nsw i64 6, %1
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i32
  %30 = add nuw nsw i32 %20, %29
  %31 = sub nsw i64 3, %1
  %32 = getelementptr inbounds i8, i8* %0, i64 %31
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i32
  %35 = add nuw nsw i32 %25, %34
  %36 = sub nsw i64 7, %1
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = load i8, i8* %37, align 1
  %39 = zext i8 %38 to i32
  %40 = add nuw nsw i32 %30, %39
  %41 = add nuw nsw i32 %35, 2
  %42 = lshr i32 %41, 2
  %43 = mul i32 %42, 16843009
  %44 = add nuw nsw i32 %40, 2
  %45 = lshr i32 %44, 2
  %46 = mul i32 %45, 16843009
  %47 = bitcast i8* %0 to i32*
  store i32 %43, i32* %47, align 4
  %48 = getelementptr inbounds i8, i8* %0, i64 4
  %49 = bitcast i8* %48 to i32*
  store i32 %46, i32* %49, align 4
  %50 = getelementptr inbounds i8, i8* %0, i64 %1
  %51 = bitcast i8* %50 to i32*
  store i32 %43, i32* %51, align 4
  %52 = getelementptr inbounds i8, i8* %50, i64 4
  %53 = bitcast i8* %52 to i32*
  store i32 %46, i32* %53, align 4
  %54 = shl nsw i64 %1, 1
  %55 = getelementptr inbounds i8, i8* %0, i64 %54
  %56 = bitcast i8* %55 to i32*
  store i32 %43, i32* %56, align 4
  %57 = getelementptr inbounds i8, i8* %55, i64 4
  %58 = bitcast i8* %57 to i32*
  store i32 %46, i32* %58, align 4
  %59 = mul nsw i64 %1, 3
  %60 = getelementptr inbounds i8, i8* %0, i64 %59
  %61 = bitcast i8* %60 to i32*
  store i32 %43, i32* %61, align 4
  %62 = getelementptr inbounds i8, i8* %60, i64 4
  %63 = bitcast i8* %62 to i32*
  store i32 %46, i32* %63, align 4
  %64 = shl nsw i64 %1, 2
  %65 = getelementptr inbounds i8, i8* %0, i64 %64
  %66 = bitcast i8* %65 to i32*
  store i32 %43, i32* %66, align 4
  %67 = getelementptr inbounds i8, i8* %65, i64 4
  %68 = bitcast i8* %67 to i32*
  store i32 %46, i32* %68, align 4
  %69 = mul nsw i64 %1, 5
  %70 = getelementptr inbounds i8, i8* %0, i64 %69
  %71 = bitcast i8* %70 to i32*
  store i32 %43, i32* %71, align 4
  %72 = getelementptr inbounds i8, i8* %70, i64 4
  %73 = bitcast i8* %72 to i32*
  store i32 %46, i32* %73, align 4
  %74 = mul nsw i64 %1, 6
  %75 = getelementptr inbounds i8, i8* %0, i64 %74
  %76 = bitcast i8* %75 to i32*
  store i32 %43, i32* %76, align 4
  %77 = getelementptr inbounds i8, i8* %75, i64 4
  %78 = bitcast i8* %77 to i32*
  store i32 %46, i32* %78, align 4
  %79 = mul nsw i64 %1, 7
  %80 = getelementptr inbounds i8, i8* %0, i64 %79
  %81 = bitcast i8* %80 to i32*
  store i32 %43, i32* %81, align 4
  %82 = getelementptr inbounds i8, i8* %80, i64 4
  %83 = bitcast i8* %82 to i32*
  store i32 %46, i32* %83, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_l0t_8(i8*, i64) #1 {
  %3 = sub nsw i64 0, %1
  %4 = getelementptr inbounds i8, i8* %0, i64 %3
  %5 = load i8, i8* %4, align 1
  %6 = zext i8 %5 to i32
  %7 = sub nsw i64 4, %1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = sub nsw i64 1, %1
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = sub nsw i64 5, %1
  %16 = getelementptr inbounds i8, i8* %0, i64 %15
  %17 = load i8, i8* %16, align 1
  %18 = zext i8 %17 to i32
  %19 = sub nsw i64 2, %1
  %20 = getelementptr inbounds i8, i8* %0, i64 %19
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  %23 = sub nsw i64 6, %1
  %24 = getelementptr inbounds i8, i8* %0, i64 %23
  %25 = load i8, i8* %24, align 1
  %26 = zext i8 %25 to i32
  %27 = sub nsw i64 3, %1
  %28 = getelementptr inbounds i8, i8* %0, i64 %27
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = sub nsw i64 7, %1
  %32 = getelementptr inbounds i8, i8* %0, i64 %31
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i32
  %35 = add nuw nsw i32 %6, 2
  %36 = add nuw nsw i32 %35, %14
  %37 = add nuw nsw i32 %36, %22
  %38 = add nuw nsw i32 %37, %30
  %39 = lshr i32 %38, 2
  %40 = mul i32 %39, 16843009
  %41 = add nuw nsw i32 %10, 2
  %42 = add nuw nsw i32 %41, %18
  %43 = add nuw nsw i32 %42, %26
  %44 = add nuw nsw i32 %43, %34
  %45 = lshr i32 %44, 2
  %46 = mul i32 %45, 16843009
  %47 = bitcast i8* %0 to i32*
  store i32 %40, i32* %47, align 4
  %48 = getelementptr inbounds i8, i8* %0, i64 4
  %49 = bitcast i8* %48 to i32*
  store i32 %46, i32* %49, align 4
  %50 = getelementptr inbounds i8, i8* %0, i64 %1
  %51 = bitcast i8* %50 to i32*
  store i32 %40, i32* %51, align 4
  %52 = getelementptr inbounds i8, i8* %50, i64 4
  %53 = bitcast i8* %52 to i32*
  store i32 %46, i32* %53, align 4
  %54 = shl nsw i64 %1, 1
  %55 = getelementptr inbounds i8, i8* %0, i64 %54
  %56 = bitcast i8* %55 to i32*
  store i32 %40, i32* %56, align 4
  %57 = getelementptr inbounds i8, i8* %55, i64 4
  %58 = bitcast i8* %57 to i32*
  store i32 %46, i32* %58, align 4
  %59 = mul nsw i64 %1, 3
  %60 = getelementptr inbounds i8, i8* %0, i64 %59
  %61 = bitcast i8* %60 to i32*
  store i32 %40, i32* %61, align 4
  %62 = getelementptr inbounds i8, i8* %60, i64 4
  %63 = bitcast i8* %62 to i32*
  store i32 %46, i32* %63, align 4
  %64 = shl nsw i64 %1, 2
  %65 = getelementptr inbounds i8, i8* %0, i64 %64
  %66 = bitcast i8* %65 to i32*
  store i32 %40, i32* %66, align 4
  %67 = getelementptr inbounds i8, i8* %65, i64 4
  %68 = bitcast i8* %67 to i32*
  store i32 %46, i32* %68, align 4
  %69 = mul nsw i64 %1, 5
  %70 = getelementptr inbounds i8, i8* %0, i64 %69
  %71 = bitcast i8* %70 to i32*
  store i32 %40, i32* %71, align 4
  %72 = getelementptr inbounds i8, i8* %70, i64 4
  %73 = bitcast i8* %72 to i32*
  store i32 %46, i32* %73, align 4
  %74 = mul nsw i64 %1, 6
  %75 = getelementptr inbounds i8, i8* %0, i64 %74
  %76 = bitcast i8* %75 to i32*
  store i32 %40, i32* %76, align 4
  %77 = getelementptr inbounds i8, i8* %75, i64 4
  %78 = bitcast i8* %77 to i32*
  store i32 %46, i32* %78, align 4
  %79 = mul nsw i64 %1, 7
  %80 = getelementptr inbounds i8, i8* %0, i64 %79
  %81 = bitcast i8* %80 to i32*
  store i32 %40, i32* %81, align 4
  %82 = getelementptr inbounds i8, i8* %80, i64 4
  %83 = bitcast i8* %82 to i32*
  store i32 %46, i32* %83, align 4
  %84 = trunc i64 %1 to i32
  %85 = shl i64 %1, 32
  %86 = sub i64 0, %85
  %87 = ashr exact i64 %86, 32
  %88 = getelementptr inbounds i8, i8* %0, i64 %87
  %89 = load i8, i8* %88, align 1
  %90 = zext i8 %89 to i32
  %91 = sub i64 4294967296, %85
  %92 = ashr exact i64 %91, 32
  %93 = getelementptr inbounds i8, i8* %0, i64 %92
  %94 = load i8, i8* %93, align 1
  %95 = zext i8 %94 to i32
  %96 = sub i64 8589934592, %85
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i8, i8* %0, i64 %97
  %99 = load i8, i8* %98, align 1
  %100 = zext i8 %99 to i32
  %101 = sub i64 12884901888, %85
  %102 = ashr exact i64 %101, 32
  %103 = getelementptr inbounds i8, i8* %0, i64 %102
  %104 = load i8, i8* %103, align 1
  %105 = zext i8 %104 to i32
  %106 = getelementptr inbounds i8, i8* %0, i64 -1
  %107 = load i8, i8* %106, align 1
  %108 = zext i8 %107 to i32
  %109 = add i64 %85, -4294967296
  %110 = ashr exact i64 %109, 32
  %111 = getelementptr inbounds i8, i8* %0, i64 %110
  %112 = load i8, i8* %111, align 1
  %113 = zext i8 %112 to i32
  %114 = shl nsw i32 %84, 1
  %115 = add nsw i32 %114, -1
  %116 = sext i32 %115 to i64
  %117 = getelementptr inbounds i8, i8* %0, i64 %116
  %118 = load i8, i8* %117, align 1
  %119 = zext i8 %118 to i32
  %120 = mul nsw i32 %84, 3
  %121 = add nsw i32 %120, -1
  %122 = sext i32 %121 to i64
  %123 = getelementptr inbounds i8, i8* %0, i64 %122
  %124 = load i8, i8* %123, align 1
  %125 = zext i8 %124 to i32
  %126 = add nuw nsw i32 %90, 4
  %127 = add nuw nsw i32 %126, %95
  %128 = add nuw nsw i32 %127, %100
  %129 = add nuw nsw i32 %128, %105
  %130 = add nuw nsw i32 %129, %108
  %131 = add nuw nsw i32 %130, %113
  %132 = add nuw nsw i32 %131, %119
  %133 = add nuw nsw i32 %132, %125
  %134 = ashr i32 %133, 3
  %135 = mul i32 %134, 16843009
  store i32 %135, i32* %47, align 4
  %136 = ashr exact i64 %85, 32
  %137 = getelementptr inbounds i8, i8* %0, i64 %136
  %138 = bitcast i8* %137 to i32*
  store i32 %135, i32* %138, align 4
  %139 = sext i32 %114 to i64
  %140 = getelementptr inbounds i8, i8* %0, i64 %139
  %141 = bitcast i8* %140 to i32*
  store i32 %135, i32* %141, align 4
  %142 = sext i32 %120 to i64
  %143 = getelementptr inbounds i8, i8* %0, i64 %142
  %144 = bitcast i8* %143 to i32*
  store i32 %135, i32* %144, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_0lt_8(i8* nocapture, i64) #1 {
  tail call void @pred8x8_dc_8_c(i8* %0, i64 %1)
  %3 = trunc i64 %1 to i32
  %4 = shl i64 %1, 32
  %5 = sub i64 0, %4
  %6 = ashr exact i64 %5, 32
  %7 = getelementptr inbounds i8, i8* %0, i64 %6
  %8 = load i8, i8* %7, align 1
  %9 = zext i8 %8 to i32
  %10 = sub i64 4294967296, %4
  %11 = ashr exact i64 %10, 32
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = sub i64 8589934592, %4
  %16 = ashr exact i64 %15, 32
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = sub i64 12884901888, %4
  %21 = ashr exact i64 %20, 32
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = add nuw nsw i32 %9, 2
  %26 = add nuw nsw i32 %25, %14
  %27 = add nuw nsw i32 %26, %19
  %28 = add nuw nsw i32 %27, %24
  %29 = lshr i32 %28, 2
  %30 = mul i32 %29, 16843009
  %31 = bitcast i8* %0 to i32*
  store i32 %30, i32* %31, align 4
  %32 = ashr exact i64 %4, 32
  %33 = getelementptr inbounds i8, i8* %0, i64 %32
  %34 = bitcast i8* %33 to i32*
  store i32 %30, i32* %34, align 4
  %35 = shl nsw i32 %3, 1
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = bitcast i8* %37 to i32*
  store i32 %30, i32* %38, align 4
  %39 = mul i64 %1, 12884901888
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i8, i8* %0, i64 %40
  %42 = bitcast i8* %41 to i32*
  store i32 %30, i32* %42, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_l00_8(i8* nocapture, i64) #1 {
  %3 = getelementptr inbounds i8, i8* %0, i64 -1
  %4 = load i8, i8* %3, align 1
  %5 = zext i8 %4 to i32
  %6 = shl nsw i64 %1, 2
  %7 = add nsw i64 %6, -1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = add nsw i64 %1, -1
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = mul nsw i64 %1, 5
  %16 = add nsw i64 %15, -1
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = shl nsw i64 %1, 1
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = mul nsw i64 %1, 6
  %26 = add nsw i64 %25, -1
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i32
  %30 = mul nsw i64 %1, 3
  %31 = add nsw i64 %30, -1
  %32 = getelementptr inbounds i8, i8* %0, i64 %31
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i32
  %35 = mul nsw i64 %1, 7
  %36 = add nsw i64 %35, -1
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = load i8, i8* %37, align 1
  %39 = zext i8 %38 to i32
  %40 = add nuw nsw i32 %5, 2
  %41 = add nuw nsw i32 %40, %14
  %42 = add nuw nsw i32 %41, %24
  %43 = add nuw nsw i32 %42, %34
  %44 = lshr i32 %43, 2
  %45 = mul i32 %44, 16843009
  %46 = add nuw nsw i32 %10, 2
  %47 = add nuw nsw i32 %46, %19
  %48 = add nuw nsw i32 %47, %29
  %49 = add nuw nsw i32 %48, %39
  %50 = lshr i32 %49, 2
  %51 = bitcast i8* %0 to i32*
  store i32 %45, i32* %51, align 4
  %52 = getelementptr inbounds i8, i8* %0, i64 4
  %53 = bitcast i8* %52 to i32*
  store i32 %45, i32* %53, align 4
  %54 = getelementptr inbounds i8, i8* %0, i64 %1
  %55 = bitcast i8* %54 to i32*
  store i32 %45, i32* %55, align 4
  %56 = getelementptr inbounds i8, i8* %54, i64 4
  %57 = bitcast i8* %56 to i32*
  store i32 %45, i32* %57, align 4
  %58 = getelementptr inbounds i8, i8* %0, i64 %20
  %59 = bitcast i8* %58 to i32*
  store i32 %45, i32* %59, align 4
  %60 = getelementptr inbounds i8, i8* %58, i64 4
  %61 = bitcast i8* %60 to i32*
  store i32 %45, i32* %61, align 4
  %62 = getelementptr inbounds i8, i8* %0, i64 %30
  %63 = bitcast i8* %62 to i32*
  store i32 %45, i32* %63, align 4
  %64 = getelementptr inbounds i8, i8* %62, i64 4
  %65 = bitcast i8* %64 to i32*
  store i32 %45, i32* %65, align 4
  %66 = mul i32 %50, 16843009
  %67 = getelementptr inbounds i8, i8* %0, i64 %6
  %68 = bitcast i8* %67 to i32*
  %69 = getelementptr inbounds i8, i8* %67, i64 4
  %70 = bitcast i8* %69 to i32*
  %71 = getelementptr inbounds i8, i8* %0, i64 %15
  %72 = bitcast i8* %71 to i32*
  store i32 %66, i32* %72, align 4
  %73 = getelementptr inbounds i8, i8* %71, i64 4
  %74 = bitcast i8* %73 to i32*
  store i32 %66, i32* %74, align 4
  %75 = getelementptr inbounds i8, i8* %0, i64 %25
  %76 = bitcast i8* %75 to i32*
  store i32 %66, i32* %76, align 4
  %77 = getelementptr inbounds i8, i8* %75, i64 4
  %78 = bitcast i8* %77 to i32*
  store i32 %66, i32* %78, align 4
  %79 = getelementptr inbounds i8, i8* %0, i64 %35
  %80 = bitcast i8* %79 to i32*
  store i32 %66, i32* %80, align 4
  %81 = getelementptr inbounds i8, i8* %79, i64 4
  %82 = bitcast i8* %81 to i32*
  store i32 %66, i32* %82, align 4
  %83 = trunc i64 %1 to i32
  store i32 -2139062144, i32* %68, align 4
  %84 = shl i64 %1, 32
  %85 = ashr exact i64 %84, 32
  %86 = getelementptr inbounds i8, i8* %67, i64 %85
  %87 = bitcast i8* %86 to i32*
  store i32 -2139062144, i32* %87, align 4
  %88 = shl nsw i32 %83, 1
  %89 = sext i32 %88 to i64
  %90 = getelementptr inbounds i8, i8* %67, i64 %89
  %91 = bitcast i8* %90 to i32*
  store i32 -2139062144, i32* %91, align 4
  %92 = mul i64 %1, 12884901888
  %93 = ashr exact i64 %92, 32
  %94 = getelementptr inbounds i8, i8* %67, i64 %93
  %95 = bitcast i8* %94 to i32*
  store i32 -2139062144, i32* %95, align 4
  store i32 -2139062144, i32* %70, align 4
  %96 = getelementptr inbounds i8, i8* %69, i64 %85
  %97 = bitcast i8* %96 to i32*
  store i32 -2139062144, i32* %97, align 4
  %98 = getelementptr inbounds i8, i8* %69, i64 %89
  %99 = bitcast i8* %98 to i32*
  store i32 -2139062144, i32* %99, align 4
  %100 = getelementptr inbounds i8, i8* %69, i64 %93
  %101 = bitcast i8* %100 to i32*
  store i32 -2139062144, i32* %101, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x8_mad_cow_dc_0l0_8(i8*, i64) #1 {
  %3 = getelementptr inbounds i8, i8* %0, i64 -1
  %4 = load i8, i8* %3, align 1
  %5 = zext i8 %4 to i32
  %6 = shl nsw i64 %1, 2
  %7 = add nsw i64 %6, -1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = add nsw i64 %1, -1
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = mul nsw i64 %1, 5
  %16 = add nsw i64 %15, -1
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = shl nsw i64 %1, 1
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = mul nsw i64 %1, 6
  %26 = add nsw i64 %25, -1
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i32
  %30 = mul nsw i64 %1, 3
  %31 = add nsw i64 %30, -1
  %32 = getelementptr inbounds i8, i8* %0, i64 %31
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i32
  %35 = mul nsw i64 %1, 7
  %36 = add nsw i64 %35, -1
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = load i8, i8* %37, align 1
  %39 = zext i8 %38 to i32
  %40 = add nuw nsw i32 %5, 2
  %41 = add nuw nsw i32 %40, %14
  %42 = add nuw nsw i32 %41, %24
  %43 = add nuw nsw i32 %42, %34
  %44 = lshr i32 %43, 2
  %45 = mul i32 %44, 16843009
  %46 = add nuw nsw i32 %10, 2
  %47 = add nuw nsw i32 %46, %19
  %48 = add nuw nsw i32 %47, %29
  %49 = add nuw nsw i32 %48, %39
  %50 = lshr i32 %49, 2
  %51 = bitcast i8* %0 to i32*
  %52 = getelementptr inbounds i8, i8* %0, i64 4
  %53 = bitcast i8* %52 to i32*
  %54 = getelementptr inbounds i8, i8* %0, i64 %1
  %55 = bitcast i8* %54 to i32*
  store i32 %45, i32* %55, align 4
  %56 = getelementptr inbounds i8, i8* %54, i64 4
  %57 = bitcast i8* %56 to i32*
  store i32 %45, i32* %57, align 4
  %58 = getelementptr inbounds i8, i8* %0, i64 %20
  %59 = bitcast i8* %58 to i32*
  store i32 %45, i32* %59, align 4
  %60 = getelementptr inbounds i8, i8* %58, i64 4
  %61 = bitcast i8* %60 to i32*
  store i32 %45, i32* %61, align 4
  %62 = getelementptr inbounds i8, i8* %0, i64 %30
  %63 = bitcast i8* %62 to i32*
  store i32 %45, i32* %63, align 4
  %64 = getelementptr inbounds i8, i8* %62, i64 4
  %65 = bitcast i8* %64 to i32*
  store i32 %45, i32* %65, align 4
  %66 = mul i32 %50, 16843009
  %67 = getelementptr inbounds i8, i8* %0, i64 %6
  %68 = bitcast i8* %67 to i32*
  store i32 %66, i32* %68, align 4
  %69 = getelementptr inbounds i8, i8* %67, i64 4
  %70 = bitcast i8* %69 to i32*
  store i32 %66, i32* %70, align 4
  %71 = getelementptr inbounds i8, i8* %0, i64 %15
  %72 = bitcast i8* %71 to i32*
  store i32 %66, i32* %72, align 4
  %73 = getelementptr inbounds i8, i8* %71, i64 4
  %74 = bitcast i8* %73 to i32*
  store i32 %66, i32* %74, align 4
  %75 = getelementptr inbounds i8, i8* %0, i64 %25
  %76 = bitcast i8* %75 to i32*
  store i32 %66, i32* %76, align 4
  %77 = getelementptr inbounds i8, i8* %75, i64 4
  %78 = bitcast i8* %77 to i32*
  store i32 %66, i32* %78, align 4
  %79 = getelementptr inbounds i8, i8* %0, i64 %35
  %80 = bitcast i8* %79 to i32*
  store i32 %66, i32* %80, align 4
  %81 = getelementptr inbounds i8, i8* %79, i64 4
  %82 = bitcast i8* %81 to i32*
  store i32 %66, i32* %82, align 4
  %83 = trunc i64 %1 to i32
  store i32 -2139062144, i32* %51, align 4
  %84 = shl i64 %1, 32
  %85 = ashr exact i64 %84, 32
  %86 = getelementptr inbounds i8, i8* %0, i64 %85
  %87 = bitcast i8* %86 to i32*
  store i32 -2139062144, i32* %87, align 4
  %88 = shl nsw i32 %83, 1
  %89 = sext i32 %88 to i64
  %90 = getelementptr inbounds i8, i8* %0, i64 %89
  %91 = bitcast i8* %90 to i32*
  store i32 -2139062144, i32* %91, align 4
  %92 = mul i64 %1, 12884901888
  %93 = ashr exact i64 %92, 32
  %94 = getelementptr inbounds i8, i8* %0, i64 %93
  %95 = bitcast i8* %94 to i32*
  store i32 -2139062144, i32* %95, align 4
  store i32 -2139062144, i32* %53, align 4
  %96 = getelementptr inbounds i8, i8* %52, i64 %85
  %97 = bitcast i8* %96 to i32*
  store i32 -2139062144, i32* %97, align 4
  %98 = getelementptr inbounds i8, i8* %52, i64 %89
  %99 = bitcast i8* %98 to i32*
  store i32 -2139062144, i32* %99, align 4
  %100 = getelementptr inbounds i8, i8* %52, i64 %93
  %101 = bitcast i8* %100 to i32*
  store i32 -2139062144, i32* %101, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_dc_8_c(i8* nocapture, i64) #1 {
  %3 = getelementptr inbounds i8, i8* %0, i64 -1
  %4 = load i8, i8* %3, align 1
  %5 = zext i8 %4 to i32
  %6 = sub nsw i64 0, %1
  %7 = getelementptr inbounds i8, i8* %0, i64 %6
  %8 = load i8, i8* %7, align 1
  %9 = zext i8 %8 to i32
  %10 = add nuw nsw i32 %5, %9
  %11 = sub nsw i64 4, %1
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = shl nsw i64 %1, 2
  %16 = add nsw i64 %15, -1
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = shl nsw i64 %1, 3
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = mul nsw i64 %1, 12
  %26 = add nsw i64 %25, -1
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i32
  %30 = add nsw i64 %1, -1
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = sub nsw i64 1, %1
  %35 = getelementptr inbounds i8, i8* %0, i64 %34
  %36 = load i8, i8* %35, align 1
  %37 = zext i8 %36 to i32
  %38 = add nuw nsw i32 %10, %33
  %39 = add nuw nsw i32 %38, %37
  %40 = sub nsw i64 5, %1
  %41 = getelementptr inbounds i8, i8* %0, i64 %40
  %42 = load i8, i8* %41, align 1
  %43 = zext i8 %42 to i32
  %44 = add nuw nsw i32 %14, %43
  %45 = mul nsw i64 %1, 5
  %46 = add nsw i64 %45, -1
  %47 = getelementptr inbounds i8, i8* %0, i64 %46
  %48 = load i8, i8* %47, align 1
  %49 = zext i8 %48 to i32
  %50 = add nuw nsw i32 %19, %49
  %51 = mul nsw i64 %1, 9
  %52 = add nsw i64 %51, -1
  %53 = getelementptr inbounds i8, i8* %0, i64 %52
  %54 = load i8, i8* %53, align 1
  %55 = zext i8 %54 to i32
  %56 = add nuw nsw i32 %24, %55
  %57 = mul nsw i64 %1, 13
  %58 = add nsw i64 %57, -1
  %59 = getelementptr inbounds i8, i8* %0, i64 %58
  %60 = load i8, i8* %59, align 1
  %61 = zext i8 %60 to i32
  %62 = add nuw nsw i32 %29, %61
  %63 = shl nsw i64 %1, 1
  %64 = add nsw i64 %63, -1
  %65 = getelementptr inbounds i8, i8* %0, i64 %64
  %66 = load i8, i8* %65, align 1
  %67 = zext i8 %66 to i32
  %68 = sub nsw i64 2, %1
  %69 = getelementptr inbounds i8, i8* %0, i64 %68
  %70 = load i8, i8* %69, align 1
  %71 = zext i8 %70 to i32
  %72 = add nuw nsw i32 %39, %67
  %73 = add nuw nsw i32 %72, %71
  %74 = sub nsw i64 6, %1
  %75 = getelementptr inbounds i8, i8* %0, i64 %74
  %76 = load i8, i8* %75, align 1
  %77 = zext i8 %76 to i32
  %78 = add nuw nsw i32 %44, %77
  %79 = mul nsw i64 %1, 6
  %80 = add nsw i64 %79, -1
  %81 = getelementptr inbounds i8, i8* %0, i64 %80
  %82 = load i8, i8* %81, align 1
  %83 = zext i8 %82 to i32
  %84 = add nuw nsw i32 %50, %83
  %85 = mul nsw i64 %1, 10
  %86 = add nsw i64 %85, -1
  %87 = getelementptr inbounds i8, i8* %0, i64 %86
  %88 = load i8, i8* %87, align 1
  %89 = zext i8 %88 to i32
  %90 = add nuw nsw i32 %56, %89
  %91 = mul nsw i64 %1, 14
  %92 = add nsw i64 %91, -1
  %93 = getelementptr inbounds i8, i8* %0, i64 %92
  %94 = load i8, i8* %93, align 1
  %95 = zext i8 %94 to i32
  %96 = add nuw nsw i32 %62, %95
  %97 = mul nsw i64 %1, 3
  %98 = add nsw i64 %97, -1
  %99 = getelementptr inbounds i8, i8* %0, i64 %98
  %100 = load i8, i8* %99, align 1
  %101 = zext i8 %100 to i32
  %102 = sub nsw i64 3, %1
  %103 = getelementptr inbounds i8, i8* %0, i64 %102
  %104 = load i8, i8* %103, align 1
  %105 = zext i8 %104 to i32
  %106 = add nuw nsw i32 %73, %101
  %107 = add nuw nsw i32 %106, %105
  %108 = sub nsw i64 7, %1
  %109 = getelementptr inbounds i8, i8* %0, i64 %108
  %110 = load i8, i8* %109, align 1
  %111 = zext i8 %110 to i32
  %112 = add nuw nsw i32 %78, %111
  %113 = mul nsw i64 %1, 7
  %114 = add nsw i64 %113, -1
  %115 = getelementptr inbounds i8, i8* %0, i64 %114
  %116 = load i8, i8* %115, align 1
  %117 = zext i8 %116 to i32
  %118 = add nuw nsw i32 %84, %117
  %119 = mul nsw i64 %1, 11
  %120 = add nsw i64 %119, -1
  %121 = getelementptr inbounds i8, i8* %0, i64 %120
  %122 = load i8, i8* %121, align 1
  %123 = zext i8 %122 to i32
  %124 = add nuw nsw i32 %90, %123
  %125 = mul nsw i64 %1, 15
  %126 = add nsw i64 %125, -1
  %127 = getelementptr inbounds i8, i8* %0, i64 %126
  %128 = load i8, i8* %127, align 1
  %129 = zext i8 %128 to i32
  %130 = add nuw nsw i32 %96, %129
  %131 = add nuw nsw i32 %107, 4
  %132 = lshr i32 %131, 3
  %133 = mul i32 %132, 16843009
  %134 = add nuw nsw i32 %112, 2
  %135 = lshr i32 %134, 2
  %136 = mul i32 %135, 16843009
  %137 = add nuw nsw i32 %118, 2
  %138 = lshr i32 %137, 2
  %139 = add nuw nsw i32 %112, 4
  %140 = add nuw nsw i32 %139, %118
  %141 = lshr i32 %140, 3
  %142 = add nuw nsw i32 %124, 2
  %143 = lshr i32 %142, 2
  %144 = add nuw nsw i32 %139, %124
  %145 = lshr i32 %144, 3
  %146 = add nuw nsw i32 %130, 2
  %147 = lshr i32 %146, 2
  %148 = add nuw nsw i32 %139, %130
  %149 = lshr i32 %148, 3
  %150 = bitcast i8* %0 to i32*
  store i32 %133, i32* %150, align 4
  %151 = getelementptr inbounds i8, i8* %0, i64 4
  %152 = bitcast i8* %151 to i32*
  store i32 %136, i32* %152, align 4
  %153 = getelementptr inbounds i8, i8* %0, i64 %1
  %154 = bitcast i8* %153 to i32*
  store i32 %133, i32* %154, align 4
  %155 = getelementptr inbounds i8, i8* %153, i64 4
  %156 = bitcast i8* %155 to i32*
  store i32 %136, i32* %156, align 4
  %157 = getelementptr inbounds i8, i8* %0, i64 %63
  %158 = bitcast i8* %157 to i32*
  store i32 %133, i32* %158, align 4
  %159 = getelementptr inbounds i8, i8* %157, i64 4
  %160 = bitcast i8* %159 to i32*
  store i32 %136, i32* %160, align 4
  %161 = getelementptr inbounds i8, i8* %0, i64 %97
  %162 = bitcast i8* %161 to i32*
  store i32 %133, i32* %162, align 4
  %163 = getelementptr inbounds i8, i8* %161, i64 4
  %164 = bitcast i8* %163 to i32*
  store i32 %136, i32* %164, align 4
  %165 = mul i32 %138, 16843009
  %166 = mul i32 %141, 16843009
  %167 = mul i32 %143, 16843009
  %168 = mul i32 %145, 16843009
  %169 = mul i32 %147, 16843009
  %170 = mul i32 %149, 16843009
  %171 = getelementptr inbounds i8, i8* %0, i64 %15
  %172 = bitcast i8* %171 to i32*
  store i32 %165, i32* %172, align 4
  %173 = getelementptr inbounds i8, i8* %171, i64 4
  %174 = bitcast i8* %173 to i32*
  store i32 %166, i32* %174, align 4
  %175 = getelementptr inbounds i8, i8* %0, i64 %45
  %176 = bitcast i8* %175 to i32*
  store i32 %165, i32* %176, align 4
  %177 = getelementptr inbounds i8, i8* %175, i64 4
  %178 = bitcast i8* %177 to i32*
  store i32 %166, i32* %178, align 4
  %179 = getelementptr inbounds i8, i8* %0, i64 %79
  %180 = bitcast i8* %179 to i32*
  store i32 %165, i32* %180, align 4
  %181 = getelementptr inbounds i8, i8* %179, i64 4
  %182 = bitcast i8* %181 to i32*
  store i32 %166, i32* %182, align 4
  %183 = getelementptr inbounds i8, i8* %0, i64 %113
  %184 = bitcast i8* %183 to i32*
  store i32 %165, i32* %184, align 4
  %185 = getelementptr inbounds i8, i8* %183, i64 4
  %186 = bitcast i8* %185 to i32*
  store i32 %166, i32* %186, align 4
  %187 = getelementptr inbounds i8, i8* %0, i64 %20
  %188 = bitcast i8* %187 to i32*
  store i32 %167, i32* %188, align 4
  %189 = getelementptr inbounds i8, i8* %187, i64 4
  %190 = bitcast i8* %189 to i32*
  store i32 %168, i32* %190, align 4
  %191 = getelementptr inbounds i8, i8* %0, i64 %51
  %192 = bitcast i8* %191 to i32*
  store i32 %167, i32* %192, align 4
  %193 = getelementptr inbounds i8, i8* %191, i64 4
  %194 = bitcast i8* %193 to i32*
  store i32 %168, i32* %194, align 4
  %195 = getelementptr inbounds i8, i8* %0, i64 %85
  %196 = bitcast i8* %195 to i32*
  store i32 %167, i32* %196, align 4
  %197 = getelementptr inbounds i8, i8* %195, i64 4
  %198 = bitcast i8* %197 to i32*
  store i32 %168, i32* %198, align 4
  %199 = getelementptr inbounds i8, i8* %0, i64 %119
  %200 = bitcast i8* %199 to i32*
  store i32 %167, i32* %200, align 4
  %201 = getelementptr inbounds i8, i8* %199, i64 4
  %202 = bitcast i8* %201 to i32*
  store i32 %168, i32* %202, align 4
  %203 = getelementptr inbounds i8, i8* %0, i64 %25
  %204 = bitcast i8* %203 to i32*
  store i32 %169, i32* %204, align 4
  %205 = getelementptr inbounds i8, i8* %203, i64 4
  %206 = bitcast i8* %205 to i32*
  store i32 %170, i32* %206, align 4
  %207 = getelementptr inbounds i8, i8* %0, i64 %57
  %208 = bitcast i8* %207 to i32*
  store i32 %169, i32* %208, align 4
  %209 = getelementptr inbounds i8, i8* %207, i64 4
  %210 = bitcast i8* %209 to i32*
  store i32 %170, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %0, i64 %91
  %212 = bitcast i8* %211 to i32*
  store i32 %169, i32* %212, align 4
  %213 = getelementptr inbounds i8, i8* %211, i64 4
  %214 = bitcast i8* %213 to i32*
  store i32 %170, i32* %214, align 4
  %215 = getelementptr inbounds i8, i8* %0, i64 %125
  %216 = bitcast i8* %215 to i32*
  store i32 %169, i32* %216, align 4
  %217 = getelementptr inbounds i8, i8* %215, i64 4
  %218 = bitcast i8* %217 to i32*
  store i32 %170, i32* %218, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_left_dc_8_c(i8* nocapture, i64) #1 {
  %3 = getelementptr inbounds i8, i8* %0, i64 -1
  %4 = load i8, i8* %3, align 1
  %5 = zext i8 %4 to i32
  %6 = shl nsw i64 %1, 2
  %7 = add nsw i64 %6, -1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = add nsw i64 %1, -1
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = mul nsw i64 %1, 5
  %16 = add nsw i64 %15, -1
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = shl nsw i64 %1, 1
  %21 = add nsw i64 %20, -1
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = mul nsw i64 %1, 6
  %26 = add nsw i64 %25, -1
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i32
  %30 = mul nsw i64 %1, 3
  %31 = add nsw i64 %30, -1
  %32 = getelementptr inbounds i8, i8* %0, i64 %31
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i32
  %35 = mul nsw i64 %1, 7
  %36 = add nsw i64 %35, -1
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = load i8, i8* %37, align 1
  %39 = zext i8 %38 to i32
  %40 = add nuw nsw i32 %5, 2
  %41 = add nuw nsw i32 %40, %14
  %42 = add nuw nsw i32 %41, %24
  %43 = add nuw nsw i32 %42, %34
  %44 = lshr i32 %43, 2
  %45 = mul i32 %44, 16843009
  %46 = add nuw nsw i32 %10, 2
  %47 = add nuw nsw i32 %46, %19
  %48 = add nuw nsw i32 %47, %29
  %49 = add nuw nsw i32 %48, %39
  %50 = lshr i32 %49, 2
  %51 = bitcast i8* %0 to i32*
  store i32 %45, i32* %51, align 4
  %52 = getelementptr inbounds i8, i8* %0, i64 4
  %53 = bitcast i8* %52 to i32*
  store i32 %45, i32* %53, align 4
  %54 = getelementptr inbounds i8, i8* %0, i64 %1
  %55 = bitcast i8* %54 to i32*
  store i32 %45, i32* %55, align 4
  %56 = getelementptr inbounds i8, i8* %54, i64 4
  %57 = bitcast i8* %56 to i32*
  store i32 %45, i32* %57, align 4
  %58 = getelementptr inbounds i8, i8* %0, i64 %20
  %59 = bitcast i8* %58 to i32*
  store i32 %45, i32* %59, align 4
  %60 = getelementptr inbounds i8, i8* %58, i64 4
  %61 = bitcast i8* %60 to i32*
  store i32 %45, i32* %61, align 4
  %62 = getelementptr inbounds i8, i8* %0, i64 %30
  %63 = bitcast i8* %62 to i32*
  store i32 %45, i32* %63, align 4
  %64 = getelementptr inbounds i8, i8* %62, i64 4
  %65 = bitcast i8* %64 to i32*
  store i32 %45, i32* %65, align 4
  %66 = mul i32 %50, 16843009
  %67 = getelementptr inbounds i8, i8* %0, i64 %6
  %68 = bitcast i8* %67 to i32*
  store i32 %66, i32* %68, align 4
  %69 = getelementptr inbounds i8, i8* %67, i64 4
  %70 = bitcast i8* %69 to i32*
  store i32 %66, i32* %70, align 4
  %71 = getelementptr inbounds i8, i8* %0, i64 %15
  %72 = bitcast i8* %71 to i32*
  store i32 %66, i32* %72, align 4
  %73 = getelementptr inbounds i8, i8* %71, i64 4
  %74 = bitcast i8* %73 to i32*
  store i32 %66, i32* %74, align 4
  %75 = getelementptr inbounds i8, i8* %0, i64 %25
  %76 = bitcast i8* %75 to i32*
  store i32 %66, i32* %76, align 4
  %77 = getelementptr inbounds i8, i8* %75, i64 4
  %78 = bitcast i8* %77 to i32*
  store i32 %66, i32* %78, align 4
  %79 = getelementptr inbounds i8, i8* %0, i64 %35
  %80 = bitcast i8* %79 to i32*
  store i32 %66, i32* %80, align 4
  %81 = getelementptr inbounds i8, i8* %79, i64 4
  %82 = bitcast i8* %81 to i32*
  store i32 %66, i32* %82, align 4
  %83 = shl nsw i64 %1, 3
  %84 = getelementptr inbounds i8, i8* %0, i64 %83
  %85 = getelementptr inbounds i8, i8* %84, i64 -1
  %86 = load i8, i8* %85, align 1
  %87 = zext i8 %86 to i32
  %88 = getelementptr inbounds i8, i8* %84, i64 %7
  %89 = load i8, i8* %88, align 1
  %90 = zext i8 %89 to i32
  %91 = getelementptr inbounds i8, i8* %84, i64 %11
  %92 = load i8, i8* %91, align 1
  %93 = zext i8 %92 to i32
  %94 = getelementptr inbounds i8, i8* %84, i64 %16
  %95 = load i8, i8* %94, align 1
  %96 = zext i8 %95 to i32
  %97 = getelementptr inbounds i8, i8* %84, i64 %21
  %98 = load i8, i8* %97, align 1
  %99 = zext i8 %98 to i32
  %100 = getelementptr inbounds i8, i8* %84, i64 %26
  %101 = load i8, i8* %100, align 1
  %102 = zext i8 %101 to i32
  %103 = getelementptr inbounds i8, i8* %84, i64 %31
  %104 = load i8, i8* %103, align 1
  %105 = zext i8 %104 to i32
  %106 = getelementptr inbounds i8, i8* %84, i64 %36
  %107 = load i8, i8* %106, align 1
  %108 = zext i8 %107 to i32
  %109 = add nuw nsw i32 %87, 2
  %110 = add nuw nsw i32 %109, %93
  %111 = add nuw nsw i32 %110, %99
  %112 = add nuw nsw i32 %111, %105
  %113 = lshr i32 %112, 2
  %114 = mul i32 %113, 16843009
  %115 = add nuw nsw i32 %90, 2
  %116 = add nuw nsw i32 %115, %96
  %117 = add nuw nsw i32 %116, %102
  %118 = add nuw nsw i32 %117, %108
  %119 = lshr i32 %118, 2
  %120 = bitcast i8* %84 to i32*
  store i32 %114, i32* %120, align 4
  %121 = getelementptr inbounds i8, i8* %84, i64 4
  %122 = bitcast i8* %121 to i32*
  store i32 %114, i32* %122, align 4
  %123 = getelementptr inbounds i8, i8* %84, i64 %1
  %124 = bitcast i8* %123 to i32*
  store i32 %114, i32* %124, align 4
  %125 = getelementptr inbounds i8, i8* %123, i64 4
  %126 = bitcast i8* %125 to i32*
  store i32 %114, i32* %126, align 4
  %127 = getelementptr inbounds i8, i8* %84, i64 %20
  %128 = bitcast i8* %127 to i32*
  store i32 %114, i32* %128, align 4
  %129 = getelementptr inbounds i8, i8* %127, i64 4
  %130 = bitcast i8* %129 to i32*
  store i32 %114, i32* %130, align 4
  %131 = getelementptr inbounds i8, i8* %84, i64 %30
  %132 = bitcast i8* %131 to i32*
  store i32 %114, i32* %132, align 4
  %133 = getelementptr inbounds i8, i8* %131, i64 4
  %134 = bitcast i8* %133 to i32*
  store i32 %114, i32* %134, align 4
  %135 = mul i32 %119, 16843009
  %136 = getelementptr inbounds i8, i8* %84, i64 %6
  %137 = bitcast i8* %136 to i32*
  store i32 %135, i32* %137, align 4
  %138 = getelementptr inbounds i8, i8* %136, i64 4
  %139 = bitcast i8* %138 to i32*
  store i32 %135, i32* %139, align 4
  %140 = getelementptr inbounds i8, i8* %84, i64 %15
  %141 = bitcast i8* %140 to i32*
  store i32 %135, i32* %141, align 4
  %142 = getelementptr inbounds i8, i8* %140, i64 4
  %143 = bitcast i8* %142 to i32*
  store i32 %135, i32* %143, align 4
  %144 = getelementptr inbounds i8, i8* %84, i64 %25
  %145 = bitcast i8* %144 to i32*
  store i32 %135, i32* %145, align 4
  %146 = getelementptr inbounds i8, i8* %144, i64 4
  %147 = bitcast i8* %146 to i32*
  store i32 %135, i32* %147, align 4
  %148 = getelementptr inbounds i8, i8* %84, i64 %35
  %149 = bitcast i8* %148 to i32*
  store i32 %135, i32* %149, align 4
  %150 = getelementptr inbounds i8, i8* %148, i64 4
  %151 = bitcast i8* %150 to i32*
  store i32 %135, i32* %151, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_top_dc_8_c(i8* nocapture, i64) #1 {
  %3 = sub nsw i64 0, %1
  %4 = getelementptr inbounds i8, i8* %0, i64 %3
  %5 = load i8, i8* %4, align 1
  %6 = zext i8 %5 to i32
  %7 = sub nsw i64 4, %1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = sub nsw i64 1, %1
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = add nuw nsw i32 %6, %14
  %16 = sub nsw i64 5, %1
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = add nuw nsw i32 %10, %19
  %21 = sub nsw i64 2, %1
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = add nuw nsw i32 %15, %24
  %26 = sub nsw i64 6, %1
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i32
  %30 = add nuw nsw i32 %20, %29
  %31 = sub nsw i64 3, %1
  %32 = getelementptr inbounds i8, i8* %0, i64 %31
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i32
  %35 = add nuw nsw i32 %25, %34
  %36 = sub nsw i64 7, %1
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = load i8, i8* %37, align 1
  %39 = zext i8 %38 to i32
  %40 = add nuw nsw i32 %30, %39
  %41 = add nuw nsw i32 %35, 2
  %42 = lshr i32 %41, 2
  %43 = mul i32 %42, 16843009
  %44 = add nuw nsw i32 %40, 2
  %45 = lshr i32 %44, 2
  %46 = mul i32 %45, 16843009
  %47 = bitcast i8* %0 to i32*
  store i32 %43, i32* %47, align 4
  %48 = getelementptr inbounds i8, i8* %0, i64 4
  %49 = bitcast i8* %48 to i32*
  store i32 %46, i32* %49, align 4
  %50 = getelementptr inbounds i8, i8* %0, i64 %1
  %51 = bitcast i8* %50 to i32*
  store i32 %43, i32* %51, align 4
  %52 = getelementptr inbounds i8, i8* %50, i64 4
  %53 = bitcast i8* %52 to i32*
  store i32 %46, i32* %53, align 4
  %54 = shl nsw i64 %1, 1
  %55 = getelementptr inbounds i8, i8* %0, i64 %54
  %56 = bitcast i8* %55 to i32*
  store i32 %43, i32* %56, align 4
  %57 = getelementptr inbounds i8, i8* %55, i64 4
  %58 = bitcast i8* %57 to i32*
  store i32 %46, i32* %58, align 4
  %59 = mul nsw i64 %1, 3
  %60 = getelementptr inbounds i8, i8* %0, i64 %59
  %61 = bitcast i8* %60 to i32*
  store i32 %43, i32* %61, align 4
  %62 = getelementptr inbounds i8, i8* %60, i64 4
  %63 = bitcast i8* %62 to i32*
  store i32 %46, i32* %63, align 4
  %64 = shl nsw i64 %1, 2
  %65 = getelementptr inbounds i8, i8* %0, i64 %64
  %66 = bitcast i8* %65 to i32*
  store i32 %43, i32* %66, align 4
  %67 = getelementptr inbounds i8, i8* %65, i64 4
  %68 = bitcast i8* %67 to i32*
  store i32 %46, i32* %68, align 4
  %69 = mul nsw i64 %1, 5
  %70 = getelementptr inbounds i8, i8* %0, i64 %69
  %71 = bitcast i8* %70 to i32*
  store i32 %43, i32* %71, align 4
  %72 = getelementptr inbounds i8, i8* %70, i64 4
  %73 = bitcast i8* %72 to i32*
  store i32 %46, i32* %73, align 4
  %74 = mul nsw i64 %1, 6
  %75 = getelementptr inbounds i8, i8* %0, i64 %74
  %76 = bitcast i8* %75 to i32*
  store i32 %43, i32* %76, align 4
  %77 = getelementptr inbounds i8, i8* %75, i64 4
  %78 = bitcast i8* %77 to i32*
  store i32 %46, i32* %78, align 4
  %79 = mul nsw i64 %1, 7
  %80 = getelementptr inbounds i8, i8* %0, i64 %79
  %81 = bitcast i8* %80 to i32*
  store i32 %43, i32* %81, align 4
  %82 = getelementptr inbounds i8, i8* %80, i64 4
  %83 = bitcast i8* %82 to i32*
  store i32 %46, i32* %83, align 4
  %84 = shl nsw i64 %1, 3
  %85 = getelementptr inbounds i8, i8* %0, i64 %84
  %86 = bitcast i8* %85 to i32*
  store i32 %43, i32* %86, align 4
  %87 = getelementptr inbounds i8, i8* %85, i64 4
  %88 = bitcast i8* %87 to i32*
  store i32 %46, i32* %88, align 4
  %89 = mul nsw i64 %1, 9
  %90 = getelementptr inbounds i8, i8* %0, i64 %89
  %91 = bitcast i8* %90 to i32*
  store i32 %43, i32* %91, align 4
  %92 = getelementptr inbounds i8, i8* %90, i64 4
  %93 = bitcast i8* %92 to i32*
  store i32 %46, i32* %93, align 4
  %94 = mul nsw i64 %1, 10
  %95 = getelementptr inbounds i8, i8* %0, i64 %94
  %96 = bitcast i8* %95 to i32*
  store i32 %43, i32* %96, align 4
  %97 = getelementptr inbounds i8, i8* %95, i64 4
  %98 = bitcast i8* %97 to i32*
  store i32 %46, i32* %98, align 4
  %99 = mul nsw i64 %1, 11
  %100 = getelementptr inbounds i8, i8* %0, i64 %99
  %101 = bitcast i8* %100 to i32*
  store i32 %43, i32* %101, align 4
  %102 = getelementptr inbounds i8, i8* %100, i64 4
  %103 = bitcast i8* %102 to i32*
  store i32 %46, i32* %103, align 4
  %104 = mul nsw i64 %1, 12
  %105 = getelementptr inbounds i8, i8* %0, i64 %104
  %106 = bitcast i8* %105 to i32*
  store i32 %43, i32* %106, align 4
  %107 = getelementptr inbounds i8, i8* %105, i64 4
  %108 = bitcast i8* %107 to i32*
  store i32 %46, i32* %108, align 4
  %109 = mul nsw i64 %1, 13
  %110 = getelementptr inbounds i8, i8* %0, i64 %109
  %111 = bitcast i8* %110 to i32*
  store i32 %43, i32* %111, align 4
  %112 = getelementptr inbounds i8, i8* %110, i64 4
  %113 = bitcast i8* %112 to i32*
  store i32 %46, i32* %113, align 4
  %114 = mul nsw i64 %1, 14
  %115 = getelementptr inbounds i8, i8* %0, i64 %114
  %116 = bitcast i8* %115 to i32*
  store i32 %43, i32* %116, align 4
  %117 = getelementptr inbounds i8, i8* %115, i64 4
  %118 = bitcast i8* %117 to i32*
  store i32 %46, i32* %118, align 4
  %119 = mul nsw i64 %1, 15
  %120 = getelementptr inbounds i8, i8* %0, i64 %119
  %121 = bitcast i8* %120 to i32*
  store i32 %43, i32* %121, align 4
  %122 = getelementptr inbounds i8, i8* %120, i64 4
  %123 = bitcast i8* %122 to i32*
  store i32 %46, i32* %123, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_l0t_8(i8*, i64) #1 {
  %3 = sub nsw i64 0, %1
  %4 = getelementptr inbounds i8, i8* %0, i64 %3
  %5 = load i8, i8* %4, align 1
  %6 = zext i8 %5 to i32
  %7 = sub nsw i64 4, %1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = sub nsw i64 1, %1
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = sub nsw i64 5, %1
  %16 = getelementptr inbounds i8, i8* %0, i64 %15
  %17 = load i8, i8* %16, align 1
  %18 = zext i8 %17 to i32
  %19 = sub nsw i64 2, %1
  %20 = getelementptr inbounds i8, i8* %0, i64 %19
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  %23 = sub nsw i64 6, %1
  %24 = getelementptr inbounds i8, i8* %0, i64 %23
  %25 = load i8, i8* %24, align 1
  %26 = zext i8 %25 to i32
  %27 = sub nsw i64 3, %1
  %28 = getelementptr inbounds i8, i8* %0, i64 %27
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = sub nsw i64 7, %1
  %32 = getelementptr inbounds i8, i8* %0, i64 %31
  %33 = load i8, i8* %32, align 1
  %34 = zext i8 %33 to i32
  %35 = add nuw nsw i32 %6, 2
  %36 = add nuw nsw i32 %35, %14
  %37 = add nuw nsw i32 %36, %22
  %38 = add nuw nsw i32 %37, %30
  %39 = lshr i32 %38, 2
  %40 = mul i32 %39, 16843009
  %41 = add nuw nsw i32 %10, 2
  %42 = add nuw nsw i32 %41, %18
  %43 = add nuw nsw i32 %42, %26
  %44 = add nuw nsw i32 %43, %34
  %45 = lshr i32 %44, 2
  %46 = mul i32 %45, 16843009
  %47 = bitcast i8* %0 to i32*
  store i32 %40, i32* %47, align 4
  %48 = getelementptr inbounds i8, i8* %0, i64 4
  %49 = bitcast i8* %48 to i32*
  store i32 %46, i32* %49, align 4
  %50 = getelementptr inbounds i8, i8* %0, i64 %1
  %51 = bitcast i8* %50 to i32*
  store i32 %40, i32* %51, align 4
  %52 = getelementptr inbounds i8, i8* %50, i64 4
  %53 = bitcast i8* %52 to i32*
  store i32 %46, i32* %53, align 4
  %54 = shl nsw i64 %1, 1
  %55 = getelementptr inbounds i8, i8* %0, i64 %54
  %56 = bitcast i8* %55 to i32*
  store i32 %40, i32* %56, align 4
  %57 = getelementptr inbounds i8, i8* %55, i64 4
  %58 = bitcast i8* %57 to i32*
  store i32 %46, i32* %58, align 4
  %59 = mul nsw i64 %1, 3
  %60 = getelementptr inbounds i8, i8* %0, i64 %59
  %61 = bitcast i8* %60 to i32*
  store i32 %40, i32* %61, align 4
  %62 = getelementptr inbounds i8, i8* %60, i64 4
  %63 = bitcast i8* %62 to i32*
  store i32 %46, i32* %63, align 4
  %64 = shl nsw i64 %1, 2
  %65 = getelementptr inbounds i8, i8* %0, i64 %64
  %66 = bitcast i8* %65 to i32*
  store i32 %40, i32* %66, align 4
  %67 = getelementptr inbounds i8, i8* %65, i64 4
  %68 = bitcast i8* %67 to i32*
  store i32 %46, i32* %68, align 4
  %69 = mul nsw i64 %1, 5
  %70 = getelementptr inbounds i8, i8* %0, i64 %69
  %71 = bitcast i8* %70 to i32*
  store i32 %40, i32* %71, align 4
  %72 = getelementptr inbounds i8, i8* %70, i64 4
  %73 = bitcast i8* %72 to i32*
  store i32 %46, i32* %73, align 4
  %74 = mul nsw i64 %1, 6
  %75 = getelementptr inbounds i8, i8* %0, i64 %74
  %76 = bitcast i8* %75 to i32*
  store i32 %40, i32* %76, align 4
  %77 = getelementptr inbounds i8, i8* %75, i64 4
  %78 = bitcast i8* %77 to i32*
  store i32 %46, i32* %78, align 4
  %79 = mul nsw i64 %1, 7
  %80 = getelementptr inbounds i8, i8* %0, i64 %79
  %81 = bitcast i8* %80 to i32*
  store i32 %40, i32* %81, align 4
  %82 = getelementptr inbounds i8, i8* %80, i64 4
  %83 = bitcast i8* %82 to i32*
  store i32 %46, i32* %83, align 4
  %84 = shl nsw i64 %1, 3
  %85 = getelementptr inbounds i8, i8* %0, i64 %84
  %86 = bitcast i8* %85 to i32*
  store i32 %40, i32* %86, align 4
  %87 = getelementptr inbounds i8, i8* %85, i64 4
  %88 = bitcast i8* %87 to i32*
  store i32 %46, i32* %88, align 4
  %89 = mul nsw i64 %1, 9
  %90 = getelementptr inbounds i8, i8* %0, i64 %89
  %91 = bitcast i8* %90 to i32*
  store i32 %40, i32* %91, align 4
  %92 = getelementptr inbounds i8, i8* %90, i64 4
  %93 = bitcast i8* %92 to i32*
  store i32 %46, i32* %93, align 4
  %94 = mul nsw i64 %1, 10
  %95 = getelementptr inbounds i8, i8* %0, i64 %94
  %96 = bitcast i8* %95 to i32*
  store i32 %40, i32* %96, align 4
  %97 = getelementptr inbounds i8, i8* %95, i64 4
  %98 = bitcast i8* %97 to i32*
  store i32 %46, i32* %98, align 4
  %99 = mul nsw i64 %1, 11
  %100 = getelementptr inbounds i8, i8* %0, i64 %99
  %101 = bitcast i8* %100 to i32*
  store i32 %40, i32* %101, align 4
  %102 = getelementptr inbounds i8, i8* %100, i64 4
  %103 = bitcast i8* %102 to i32*
  store i32 %46, i32* %103, align 4
  %104 = mul nsw i64 %1, 12
  %105 = getelementptr inbounds i8, i8* %0, i64 %104
  %106 = bitcast i8* %105 to i32*
  store i32 %40, i32* %106, align 4
  %107 = getelementptr inbounds i8, i8* %105, i64 4
  %108 = bitcast i8* %107 to i32*
  store i32 %46, i32* %108, align 4
  %109 = mul nsw i64 %1, 13
  %110 = getelementptr inbounds i8, i8* %0, i64 %109
  %111 = bitcast i8* %110 to i32*
  store i32 %40, i32* %111, align 4
  %112 = getelementptr inbounds i8, i8* %110, i64 4
  %113 = bitcast i8* %112 to i32*
  store i32 %46, i32* %113, align 4
  %114 = mul nsw i64 %1, 14
  %115 = getelementptr inbounds i8, i8* %0, i64 %114
  %116 = bitcast i8* %115 to i32*
  store i32 %40, i32* %116, align 4
  %117 = getelementptr inbounds i8, i8* %115, i64 4
  %118 = bitcast i8* %117 to i32*
  store i32 %46, i32* %118, align 4
  %119 = mul nsw i64 %1, 15
  %120 = getelementptr inbounds i8, i8* %0, i64 %119
  %121 = bitcast i8* %120 to i32*
  store i32 %40, i32* %121, align 4
  %122 = getelementptr inbounds i8, i8* %120, i64 4
  %123 = bitcast i8* %122 to i32*
  store i32 %46, i32* %123, align 4
  %124 = trunc i64 %1 to i32
  %125 = shl i64 %1, 32
  %126 = sub i64 0, %125
  %127 = ashr exact i64 %126, 32
  %128 = getelementptr inbounds i8, i8* %0, i64 %127
  %129 = load i8, i8* %128, align 1
  %130 = zext i8 %129 to i32
  %131 = sub i64 4294967296, %125
  %132 = ashr exact i64 %131, 32
  %133 = getelementptr inbounds i8, i8* %0, i64 %132
  %134 = load i8, i8* %133, align 1
  %135 = zext i8 %134 to i32
  %136 = sub i64 8589934592, %125
  %137 = ashr exact i64 %136, 32
  %138 = getelementptr inbounds i8, i8* %0, i64 %137
  %139 = load i8, i8* %138, align 1
  %140 = zext i8 %139 to i32
  %141 = sub i64 12884901888, %125
  %142 = ashr exact i64 %141, 32
  %143 = getelementptr inbounds i8, i8* %0, i64 %142
  %144 = load i8, i8* %143, align 1
  %145 = zext i8 %144 to i32
  %146 = getelementptr inbounds i8, i8* %0, i64 -1
  %147 = load i8, i8* %146, align 1
  %148 = zext i8 %147 to i32
  %149 = add i64 %125, -4294967296
  %150 = ashr exact i64 %149, 32
  %151 = getelementptr inbounds i8, i8* %0, i64 %150
  %152 = load i8, i8* %151, align 1
  %153 = zext i8 %152 to i32
  %154 = shl nsw i32 %124, 1
  %155 = add nsw i32 %154, -1
  %156 = sext i32 %155 to i64
  %157 = getelementptr inbounds i8, i8* %0, i64 %156
  %158 = load i8, i8* %157, align 1
  %159 = zext i8 %158 to i32
  %160 = mul nsw i32 %124, 3
  %161 = add nsw i32 %160, -1
  %162 = sext i32 %161 to i64
  %163 = getelementptr inbounds i8, i8* %0, i64 %162
  %164 = load i8, i8* %163, align 1
  %165 = zext i8 %164 to i32
  %166 = add nuw nsw i32 %130, 4
  %167 = add nuw nsw i32 %166, %135
  %168 = add nuw nsw i32 %167, %140
  %169 = add nuw nsw i32 %168, %145
  %170 = add nuw nsw i32 %169, %148
  %171 = add nuw nsw i32 %170, %153
  %172 = add nuw nsw i32 %171, %159
  %173 = add nuw nsw i32 %172, %165
  %174 = ashr i32 %173, 3
  %175 = mul i32 %174, 16843009
  store i32 %175, i32* %47, align 4
  %176 = ashr exact i64 %125, 32
  %177 = getelementptr inbounds i8, i8* %0, i64 %176
  %178 = bitcast i8* %177 to i32*
  store i32 %175, i32* %178, align 4
  %179 = sext i32 %154 to i64
  %180 = getelementptr inbounds i8, i8* %0, i64 %179
  %181 = bitcast i8* %180 to i32*
  store i32 %175, i32* %181, align 4
  %182 = sext i32 %160 to i64
  %183 = getelementptr inbounds i8, i8* %0, i64 %182
  %184 = bitcast i8* %183 to i32*
  store i32 %175, i32* %184, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_0lt_8(i8* nocapture, i64) #1 {
  tail call void @pred8x16_dc_8_c(i8* %0, i64 %1)
  %3 = trunc i64 %1 to i32
  %4 = shl i64 %1, 32
  %5 = sub i64 0, %4
  %6 = ashr exact i64 %5, 32
  %7 = getelementptr inbounds i8, i8* %0, i64 %6
  %8 = load i8, i8* %7, align 1
  %9 = zext i8 %8 to i32
  %10 = sub i64 4294967296, %4
  %11 = ashr exact i64 %10, 32
  %12 = getelementptr inbounds i8, i8* %0, i64 %11
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = sub i64 8589934592, %4
  %16 = ashr exact i64 %15, 32
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = sub i64 12884901888, %4
  %21 = ashr exact i64 %20, 32
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = add nuw nsw i32 %9, 2
  %26 = add nuw nsw i32 %25, %14
  %27 = add nuw nsw i32 %26, %19
  %28 = add nuw nsw i32 %27, %24
  %29 = lshr i32 %28, 2
  %30 = mul i32 %29, 16843009
  %31 = bitcast i8* %0 to i32*
  store i32 %30, i32* %31, align 4
  %32 = ashr exact i64 %4, 32
  %33 = getelementptr inbounds i8, i8* %0, i64 %32
  %34 = bitcast i8* %33 to i32*
  store i32 %30, i32* %34, align 4
  %35 = shl nsw i32 %3, 1
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = bitcast i8* %37 to i32*
  store i32 %30, i32* %38, align 4
  %39 = mul i64 %1, 12884901888
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds i8, i8* %0, i64 %40
  %42 = bitcast i8* %41 to i32*
  store i32 %30, i32* %42, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_l00_8(i8* nocapture, i64) #1 {
  tail call void @pred8x16_left_dc_8_c(i8* %0, i64 %1)
  %3 = shl nsw i64 %1, 2
  %4 = getelementptr inbounds i8, i8* %0, i64 %3
  %5 = trunc i64 %1 to i32
  %6 = bitcast i8* %4 to i32*
  store i32 -2139062144, i32* %6, align 4
  %7 = shl i64 %1, 32
  %8 = ashr exact i64 %7, 32
  %9 = getelementptr inbounds i8, i8* %4, i64 %8
  %10 = bitcast i8* %9 to i32*
  store i32 -2139062144, i32* %10, align 4
  %11 = shl nsw i32 %5, 1
  %12 = sext i32 %11 to i64
  %13 = getelementptr inbounds i8, i8* %4, i64 %12
  %14 = bitcast i8* %13 to i32*
  store i32 -2139062144, i32* %14, align 4
  %15 = mul i64 %1, 12884901888
  %16 = ashr exact i64 %15, 32
  %17 = getelementptr inbounds i8, i8* %4, i64 %16
  %18 = bitcast i8* %17 to i32*
  store i32 -2139062144, i32* %18, align 4
  %19 = getelementptr inbounds i8, i8* %4, i64 4
  %20 = bitcast i8* %19 to i32*
  store i32 -2139062144, i32* %20, align 4
  %21 = getelementptr inbounds i8, i8* %19, i64 %8
  %22 = bitcast i8* %21 to i32*
  store i32 -2139062144, i32* %22, align 4
  %23 = getelementptr inbounds i8, i8* %19, i64 %12
  %24 = bitcast i8* %23 to i32*
  store i32 -2139062144, i32* %24, align 4
  %25 = getelementptr inbounds i8, i8* %19, i64 %16
  %26 = bitcast i8* %25 to i32*
  store i32 -2139062144, i32* %26, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred8x16_mad_cow_dc_0l0_8(i8* nocapture, i64) #1 {
  tail call void @pred8x16_left_dc_8_c(i8* %0, i64 %1)
  %3 = trunc i64 %1 to i32
  %4 = bitcast i8* %0 to i32*
  store i32 -2139062144, i32* %4, align 4
  %5 = shl i64 %1, 32
  %6 = ashr exact i64 %5, 32
  %7 = getelementptr inbounds i8, i8* %0, i64 %6
  %8 = bitcast i8* %7 to i32*
  store i32 -2139062144, i32* %8, align 4
  %9 = shl nsw i32 %3, 1
  %10 = sext i32 %9 to i64
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = bitcast i8* %11 to i32*
  store i32 -2139062144, i32* %12, align 4
  %13 = mul i64 %1, 12884901888
  %14 = ashr exact i64 %13, 32
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = bitcast i8* %15 to i32*
  store i32 -2139062144, i32* %16, align 4
  %17 = getelementptr inbounds i8, i8* %0, i64 4
  %18 = bitcast i8* %17 to i32*
  store i32 -2139062144, i32* %18, align 4
  %19 = getelementptr inbounds i8, i8* %17, i64 %6
  %20 = bitcast i8* %19 to i32*
  store i32 -2139062144, i32* %20, align 4
  %21 = getelementptr inbounds i8, i8* %17, i64 %10
  %22 = bitcast i8* %21 to i32*
  store i32 -2139062144, i32* %22, align 4
  %23 = getelementptr inbounds i8, i8* %17, i64 %14
  %24 = bitcast i8* %23 to i32*
  store i32 -2139062144, i32* %24, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_127_dc_8_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i32*
  store i32 2139062143, i32* %3, align 4
  %4 = getelementptr inbounds i8, i8* %0, i64 4
  %5 = bitcast i8* %4 to i32*
  store i32 2139062143, i32* %5, align 4
  %6 = getelementptr inbounds i8, i8* %0, i64 %1
  %7 = bitcast i8* %6 to i32*
  store i32 2139062143, i32* %7, align 4
  %8 = getelementptr inbounds i8, i8* %6, i64 4
  %9 = bitcast i8* %8 to i32*
  store i32 2139062143, i32* %9, align 4
  %10 = shl nsw i64 %1, 1
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = bitcast i8* %11 to i32*
  store i32 2139062143, i32* %12, align 4
  %13 = getelementptr inbounds i8, i8* %11, i64 4
  %14 = bitcast i8* %13 to i32*
  store i32 2139062143, i32* %14, align 4
  %15 = mul nsw i64 %1, 3
  %16 = getelementptr inbounds i8, i8* %0, i64 %15
  %17 = bitcast i8* %16 to i32*
  store i32 2139062143, i32* %17, align 4
  %18 = getelementptr inbounds i8, i8* %16, i64 4
  %19 = bitcast i8* %18 to i32*
  store i32 2139062143, i32* %19, align 4
  %20 = shl nsw i64 %1, 2
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = bitcast i8* %21 to i32*
  store i32 2139062143, i32* %22, align 4
  %23 = getelementptr inbounds i8, i8* %21, i64 4
  %24 = bitcast i8* %23 to i32*
  store i32 2139062143, i32* %24, align 4
  %25 = mul nsw i64 %1, 5
  %26 = getelementptr inbounds i8, i8* %0, i64 %25
  %27 = bitcast i8* %26 to i32*
  store i32 2139062143, i32* %27, align 4
  %28 = getelementptr inbounds i8, i8* %26, i64 4
  %29 = bitcast i8* %28 to i32*
  store i32 2139062143, i32* %29, align 4
  %30 = mul nsw i64 %1, 6
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = bitcast i8* %31 to i32*
  store i32 2139062143, i32* %32, align 4
  %33 = getelementptr inbounds i8, i8* %31, i64 4
  %34 = bitcast i8* %33 to i32*
  store i32 2139062143, i32* %34, align 4
  %35 = mul nsw i64 %1, 7
  %36 = getelementptr inbounds i8, i8* %0, i64 %35
  %37 = bitcast i8* %36 to i32*
  store i32 2139062143, i32* %37, align 4
  %38 = getelementptr inbounds i8, i8* %36, i64 4
  %39 = bitcast i8* %38 to i32*
  store i32 2139062143, i32* %39, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_129_dc_8_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i32*
  store i32 -2122219135, i32* %3, align 4
  %4 = getelementptr inbounds i8, i8* %0, i64 4
  %5 = bitcast i8* %4 to i32*
  store i32 -2122219135, i32* %5, align 4
  %6 = getelementptr inbounds i8, i8* %0, i64 %1
  %7 = bitcast i8* %6 to i32*
  store i32 -2122219135, i32* %7, align 4
  %8 = getelementptr inbounds i8, i8* %6, i64 4
  %9 = bitcast i8* %8 to i32*
  store i32 -2122219135, i32* %9, align 4
  %10 = shl nsw i64 %1, 1
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = bitcast i8* %11 to i32*
  store i32 -2122219135, i32* %12, align 4
  %13 = getelementptr inbounds i8, i8* %11, i64 4
  %14 = bitcast i8* %13 to i32*
  store i32 -2122219135, i32* %14, align 4
  %15 = mul nsw i64 %1, 3
  %16 = getelementptr inbounds i8, i8* %0, i64 %15
  %17 = bitcast i8* %16 to i32*
  store i32 -2122219135, i32* %17, align 4
  %18 = getelementptr inbounds i8, i8* %16, i64 4
  %19 = bitcast i8* %18 to i32*
  store i32 -2122219135, i32* %19, align 4
  %20 = shl nsw i64 %1, 2
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = bitcast i8* %21 to i32*
  store i32 -2122219135, i32* %22, align 4
  %23 = getelementptr inbounds i8, i8* %21, i64 4
  %24 = bitcast i8* %23 to i32*
  store i32 -2122219135, i32* %24, align 4
  %25 = mul nsw i64 %1, 5
  %26 = getelementptr inbounds i8, i8* %0, i64 %25
  %27 = bitcast i8* %26 to i32*
  store i32 -2122219135, i32* %27, align 4
  %28 = getelementptr inbounds i8, i8* %26, i64 4
  %29 = bitcast i8* %28 to i32*
  store i32 -2122219135, i32* %29, align 4
  %30 = mul nsw i64 %1, 6
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = bitcast i8* %31 to i32*
  store i32 -2122219135, i32* %32, align 4
  %33 = getelementptr inbounds i8, i8* %31, i64 4
  %34 = bitcast i8* %33 to i32*
  store i32 -2122219135, i32* %34, align 4
  %35 = mul nsw i64 %1, 7
  %36 = getelementptr inbounds i8, i8* %0, i64 %35
  %37 = bitcast i8* %36 to i32*
  store i32 -2122219135, i32* %37, align 4
  %38 = getelementptr inbounds i8, i8* %36, i64 4
  %39 = bitcast i8* %38 to i32*
  store i32 -2122219135, i32* %39, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x8_128_dc_8_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i32*
  store i32 -2139062144, i32* %3, align 4
  %4 = getelementptr inbounds i8, i8* %0, i64 4
  %5 = bitcast i8* %4 to i32*
  store i32 -2139062144, i32* %5, align 4
  %6 = getelementptr inbounds i8, i8* %0, i64 %1
  %7 = bitcast i8* %6 to i32*
  store i32 -2139062144, i32* %7, align 4
  %8 = getelementptr inbounds i8, i8* %6, i64 4
  %9 = bitcast i8* %8 to i32*
  store i32 -2139062144, i32* %9, align 4
  %10 = shl nsw i64 %1, 1
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = bitcast i8* %11 to i32*
  store i32 -2139062144, i32* %12, align 4
  %13 = getelementptr inbounds i8, i8* %11, i64 4
  %14 = bitcast i8* %13 to i32*
  store i32 -2139062144, i32* %14, align 4
  %15 = mul nsw i64 %1, 3
  %16 = getelementptr inbounds i8, i8* %0, i64 %15
  %17 = bitcast i8* %16 to i32*
  store i32 -2139062144, i32* %17, align 4
  %18 = getelementptr inbounds i8, i8* %16, i64 4
  %19 = bitcast i8* %18 to i32*
  store i32 -2139062144, i32* %19, align 4
  %20 = shl nsw i64 %1, 2
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = bitcast i8* %21 to i32*
  store i32 -2139062144, i32* %22, align 4
  %23 = getelementptr inbounds i8, i8* %21, i64 4
  %24 = bitcast i8* %23 to i32*
  store i32 -2139062144, i32* %24, align 4
  %25 = mul nsw i64 %1, 5
  %26 = getelementptr inbounds i8, i8* %0, i64 %25
  %27 = bitcast i8* %26 to i32*
  store i32 -2139062144, i32* %27, align 4
  %28 = getelementptr inbounds i8, i8* %26, i64 4
  %29 = bitcast i8* %28 to i32*
  store i32 -2139062144, i32* %29, align 4
  %30 = mul nsw i64 %1, 6
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = bitcast i8* %31 to i32*
  store i32 -2139062144, i32* %32, align 4
  %33 = getelementptr inbounds i8, i8* %31, i64 4
  %34 = bitcast i8* %33 to i32*
  store i32 -2139062144, i32* %34, align 4
  %35 = mul nsw i64 %1, 7
  %36 = getelementptr inbounds i8, i8* %0, i64 %35
  %37 = bitcast i8* %36 to i32*
  store i32 -2139062144, i32* %37, align 4
  %38 = getelementptr inbounds i8, i8* %36, i64 4
  %39 = bitcast i8* %38 to i32*
  store i32 -2139062144, i32* %39, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred8x16_128_dc_8_c(i8* nocapture, i64) #2 {
  %3 = bitcast i8* %0 to i32*
  store i32 -2139062144, i32* %3, align 4
  %4 = getelementptr inbounds i8, i8* %0, i64 4
  %5 = bitcast i8* %4 to i32*
  store i32 -2139062144, i32* %5, align 4
  %6 = getelementptr inbounds i8, i8* %0, i64 %1
  %7 = bitcast i8* %6 to i32*
  store i32 -2139062144, i32* %7, align 4
  %8 = getelementptr inbounds i8, i8* %6, i64 4
  %9 = bitcast i8* %8 to i32*
  store i32 -2139062144, i32* %9, align 4
  %10 = shl nsw i64 %1, 1
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = bitcast i8* %11 to i32*
  store i32 -2139062144, i32* %12, align 4
  %13 = getelementptr inbounds i8, i8* %11, i64 4
  %14 = bitcast i8* %13 to i32*
  store i32 -2139062144, i32* %14, align 4
  %15 = mul nsw i64 %1, 3
  %16 = getelementptr inbounds i8, i8* %0, i64 %15
  %17 = bitcast i8* %16 to i32*
  store i32 -2139062144, i32* %17, align 4
  %18 = getelementptr inbounds i8, i8* %16, i64 4
  %19 = bitcast i8* %18 to i32*
  store i32 -2139062144, i32* %19, align 4
  %20 = shl nsw i64 %1, 2
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = bitcast i8* %21 to i32*
  store i32 -2139062144, i32* %22, align 4
  %23 = getelementptr inbounds i8, i8* %21, i64 4
  %24 = bitcast i8* %23 to i32*
  store i32 -2139062144, i32* %24, align 4
  %25 = mul nsw i64 %1, 5
  %26 = getelementptr inbounds i8, i8* %0, i64 %25
  %27 = bitcast i8* %26 to i32*
  store i32 -2139062144, i32* %27, align 4
  %28 = getelementptr inbounds i8, i8* %26, i64 4
  %29 = bitcast i8* %28 to i32*
  store i32 -2139062144, i32* %29, align 4
  %30 = mul nsw i64 %1, 6
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = bitcast i8* %31 to i32*
  store i32 -2139062144, i32* %32, align 4
  %33 = getelementptr inbounds i8, i8* %31, i64 4
  %34 = bitcast i8* %33 to i32*
  store i32 -2139062144, i32* %34, align 4
  %35 = mul nsw i64 %1, 7
  %36 = getelementptr inbounds i8, i8* %0, i64 %35
  %37 = bitcast i8* %36 to i32*
  store i32 -2139062144, i32* %37, align 4
  %38 = getelementptr inbounds i8, i8* %36, i64 4
  %39 = bitcast i8* %38 to i32*
  store i32 -2139062144, i32* %39, align 4
  %40 = shl nsw i64 %1, 3
  %41 = getelementptr inbounds i8, i8* %0, i64 %40
  %42 = bitcast i8* %41 to i32*
  store i32 -2139062144, i32* %42, align 4
  %43 = getelementptr inbounds i8, i8* %41, i64 4
  %44 = bitcast i8* %43 to i32*
  store i32 -2139062144, i32* %44, align 4
  %45 = getelementptr inbounds i8, i8* %41, i64 %1
  %46 = bitcast i8* %45 to i32*
  store i32 -2139062144, i32* %46, align 4
  %47 = getelementptr inbounds i8, i8* %45, i64 4
  %48 = bitcast i8* %47 to i32*
  store i32 -2139062144, i32* %48, align 4
  %49 = getelementptr inbounds i8, i8* %41, i64 %10
  %50 = bitcast i8* %49 to i32*
  store i32 -2139062144, i32* %50, align 4
  %51 = getelementptr inbounds i8, i8* %49, i64 4
  %52 = bitcast i8* %51 to i32*
  store i32 -2139062144, i32* %52, align 4
  %53 = getelementptr inbounds i8, i8* %41, i64 %15
  %54 = bitcast i8* %53 to i32*
  store i32 -2139062144, i32* %54, align 4
  %55 = getelementptr inbounds i8, i8* %53, i64 4
  %56 = bitcast i8* %55 to i32*
  store i32 -2139062144, i32* %56, align 4
  %57 = getelementptr inbounds i8, i8* %41, i64 %20
  %58 = bitcast i8* %57 to i32*
  store i32 -2139062144, i32* %58, align 4
  %59 = getelementptr inbounds i8, i8* %57, i64 4
  %60 = bitcast i8* %59 to i32*
  store i32 -2139062144, i32* %60, align 4
  %61 = getelementptr inbounds i8, i8* %41, i64 %25
  %62 = bitcast i8* %61 to i32*
  store i32 -2139062144, i32* %62, align 4
  %63 = getelementptr inbounds i8, i8* %61, i64 4
  %64 = bitcast i8* %63 to i32*
  store i32 -2139062144, i32* %64, align 4
  %65 = getelementptr inbounds i8, i8* %41, i64 %30
  %66 = bitcast i8* %65 to i32*
  store i32 -2139062144, i32* %66, align 4
  %67 = getelementptr inbounds i8, i8* %65, i64 4
  %68 = bitcast i8* %67 to i32*
  store i32 -2139062144, i32* %68, align 4
  %69 = getelementptr inbounds i8, i8* %41, i64 %35
  %70 = bitcast i8* %69 to i32*
  store i32 -2139062144, i32* %70, align 4
  %71 = getelementptr inbounds i8, i8* %69, i64 4
  %72 = bitcast i8* %71 to i32*
  store i32 -2139062144, i32* %72, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_dc_8_c(i8* nocapture, i64) #1 {
  %3 = getelementptr inbounds i8, i8* %0, i64 -1
  %4 = load i8, i8* %3, align 1
  %5 = zext i8 %4 to i32
  %6 = add nsw i64 %1, -1
  %7 = getelementptr inbounds i8, i8* %0, i64 %6
  %8 = load i8, i8* %7, align 1
  %9 = zext i8 %8 to i32
  %10 = add nuw nsw i32 %5, %9
  %11 = shl nsw i64 %1, 1
  %12 = add nsw i64 %11, -1
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = add nuw nsw i32 %10, %15
  %17 = mul nsw i64 %1, 3
  %18 = add nsw i64 %17, -1
  %19 = getelementptr inbounds i8, i8* %0, i64 %18
  %20 = load i8, i8* %19, align 1
  %21 = zext i8 %20 to i32
  %22 = add nuw nsw i32 %16, %21
  %23 = shl nsw i64 %1, 2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i8, i8* %0, i64 %24
  %26 = load i8, i8* %25, align 1
  %27 = zext i8 %26 to i32
  %28 = add nuw nsw i32 %22, %27
  %29 = mul nsw i64 %1, 5
  %30 = add nsw i64 %29, -1
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = add nuw nsw i32 %28, %33
  %35 = mul nsw i64 %1, 6
  %36 = add nsw i64 %35, -1
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = load i8, i8* %37, align 1
  %39 = zext i8 %38 to i32
  %40 = add nuw nsw i32 %34, %39
  %41 = mul nsw i64 %1, 7
  %42 = add nsw i64 %41, -1
  %43 = getelementptr inbounds i8, i8* %0, i64 %42
  %44 = load i8, i8* %43, align 1
  %45 = zext i8 %44 to i32
  %46 = add nuw nsw i32 %40, %45
  %47 = shl nsw i64 %1, 3
  %48 = add nsw i64 %47, -1
  %49 = getelementptr inbounds i8, i8* %0, i64 %48
  %50 = load i8, i8* %49, align 1
  %51 = zext i8 %50 to i32
  %52 = add nuw nsw i32 %46, %51
  %53 = mul nsw i64 %1, 9
  %54 = add nsw i64 %53, -1
  %55 = getelementptr inbounds i8, i8* %0, i64 %54
  %56 = load i8, i8* %55, align 1
  %57 = zext i8 %56 to i32
  %58 = add nuw nsw i32 %52, %57
  %59 = mul nsw i64 %1, 10
  %60 = add nsw i64 %59, -1
  %61 = getelementptr inbounds i8, i8* %0, i64 %60
  %62 = load i8, i8* %61, align 1
  %63 = zext i8 %62 to i32
  %64 = add nuw nsw i32 %58, %63
  %65 = mul nsw i64 %1, 11
  %66 = add nsw i64 %65, -1
  %67 = getelementptr inbounds i8, i8* %0, i64 %66
  %68 = load i8, i8* %67, align 1
  %69 = zext i8 %68 to i32
  %70 = add nuw nsw i32 %64, %69
  %71 = mul nsw i64 %1, 12
  %72 = add nsw i64 %71, -1
  %73 = getelementptr inbounds i8, i8* %0, i64 %72
  %74 = load i8, i8* %73, align 1
  %75 = zext i8 %74 to i32
  %76 = add nuw nsw i32 %70, %75
  %77 = mul nsw i64 %1, 13
  %78 = add nsw i64 %77, -1
  %79 = getelementptr inbounds i8, i8* %0, i64 %78
  %80 = load i8, i8* %79, align 1
  %81 = zext i8 %80 to i32
  %82 = add nuw nsw i32 %76, %81
  %83 = mul nsw i64 %1, 14
  %84 = add nsw i64 %83, -1
  %85 = getelementptr inbounds i8, i8* %0, i64 %84
  %86 = load i8, i8* %85, align 1
  %87 = zext i8 %86 to i32
  %88 = add nuw nsw i32 %82, %87
  %89 = mul nsw i64 %1, 15
  %90 = add nsw i64 %89, -1
  %91 = getelementptr inbounds i8, i8* %0, i64 %90
  %92 = load i8, i8* %91, align 1
  %93 = zext i8 %92 to i32
  %94 = add nuw nsw i32 %88, %93
  %95 = sub nsw i64 0, %1
  %96 = getelementptr inbounds i8, i8* %0, i64 %95
  %97 = load i8, i8* %96, align 1
  %98 = zext i8 %97 to i32
  %99 = add nuw nsw i32 %94, %98
  %100 = sub nsw i64 1, %1
  %101 = getelementptr inbounds i8, i8* %0, i64 %100
  %102 = load i8, i8* %101, align 1
  %103 = zext i8 %102 to i32
  %104 = add nuw nsw i32 %99, %103
  %105 = sub nsw i64 2, %1
  %106 = getelementptr inbounds i8, i8* %0, i64 %105
  %107 = load i8, i8* %106, align 1
  %108 = zext i8 %107 to i32
  %109 = add nuw nsw i32 %104, %108
  %110 = sub nsw i64 3, %1
  %111 = getelementptr inbounds i8, i8* %0, i64 %110
  %112 = load i8, i8* %111, align 1
  %113 = zext i8 %112 to i32
  %114 = add nuw nsw i32 %109, %113
  %115 = sub nsw i64 4, %1
  %116 = getelementptr inbounds i8, i8* %0, i64 %115
  %117 = load i8, i8* %116, align 1
  %118 = zext i8 %117 to i32
  %119 = add nuw nsw i32 %114, %118
  %120 = sub nsw i64 5, %1
  %121 = getelementptr inbounds i8, i8* %0, i64 %120
  %122 = load i8, i8* %121, align 1
  %123 = zext i8 %122 to i32
  %124 = add nuw nsw i32 %119, %123
  %125 = sub nsw i64 6, %1
  %126 = getelementptr inbounds i8, i8* %0, i64 %125
  %127 = load i8, i8* %126, align 1
  %128 = zext i8 %127 to i32
  %129 = add nuw nsw i32 %124, %128
  %130 = sub nsw i64 7, %1
  %131 = getelementptr inbounds i8, i8* %0, i64 %130
  %132 = load i8, i8* %131, align 1
  %133 = zext i8 %132 to i32
  %134 = add nuw nsw i32 %129, %133
  %135 = sub nsw i64 8, %1
  %136 = getelementptr inbounds i8, i8* %0, i64 %135
  %137 = load i8, i8* %136, align 1
  %138 = zext i8 %137 to i32
  %139 = add nuw nsw i32 %134, %138
  %140 = sub nsw i64 9, %1
  %141 = getelementptr inbounds i8, i8* %0, i64 %140
  %142 = load i8, i8* %141, align 1
  %143 = zext i8 %142 to i32
  %144 = add nuw nsw i32 %139, %143
  %145 = sub nsw i64 10, %1
  %146 = getelementptr inbounds i8, i8* %0, i64 %145
  %147 = load i8, i8* %146, align 1
  %148 = zext i8 %147 to i32
  %149 = add nuw nsw i32 %144, %148
  %150 = sub nsw i64 11, %1
  %151 = getelementptr inbounds i8, i8* %0, i64 %150
  %152 = load i8, i8* %151, align 1
  %153 = zext i8 %152 to i32
  %154 = add nuw nsw i32 %149, %153
  %155 = sub nsw i64 12, %1
  %156 = getelementptr inbounds i8, i8* %0, i64 %155
  %157 = load i8, i8* %156, align 1
  %158 = zext i8 %157 to i32
  %159 = add nuw nsw i32 %154, %158
  %160 = sub nsw i64 13, %1
  %161 = getelementptr inbounds i8, i8* %0, i64 %160
  %162 = load i8, i8* %161, align 1
  %163 = zext i8 %162 to i32
  %164 = add nuw nsw i32 %159, %163
  %165 = sub nsw i64 14, %1
  %166 = getelementptr inbounds i8, i8* %0, i64 %165
  %167 = load i8, i8* %166, align 1
  %168 = zext i8 %167 to i32
  %169 = add nuw nsw i32 %164, %168
  %170 = sub nsw i64 15, %1
  %171 = getelementptr inbounds i8, i8* %0, i64 %170
  %172 = load i8, i8* %171, align 1
  %173 = zext i8 %172 to i32
  %174 = add nuw nsw i32 %169, %173
  %175 = add nuw nsw i32 %174, 16
  %176 = lshr i32 %175, 5
  %177 = mul i32 %176, 16843009
  %178 = insertelement <4 x i32> undef, i32 %177, i32 0
  %179 = shufflevector <4 x i32> %178, <4 x i32> undef, <4 x i32> zeroinitializer
  %180 = bitcast i8* %0 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %180, align 4
  %181 = getelementptr inbounds i8, i8* %0, i64 %1
  %182 = bitcast i8* %181 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %182, align 4
  %183 = getelementptr inbounds i8, i8* %181, i64 %1
  %184 = bitcast i8* %183 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %184, align 4
  %185 = getelementptr inbounds i8, i8* %183, i64 %1
  %186 = bitcast i8* %185 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %186, align 4
  %187 = getelementptr inbounds i8, i8* %185, i64 %1
  %188 = bitcast i8* %187 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %188, align 4
  %189 = getelementptr inbounds i8, i8* %187, i64 %1
  %190 = bitcast i8* %189 to i32*
  store i32 %177, i32* %190, align 4
  %191 = getelementptr inbounds i8, i8* %189, i64 4
  %192 = bitcast i8* %191 to i32*
  store i32 %177, i32* %192, align 4
  %193 = getelementptr inbounds i8, i8* %189, i64 8
  %194 = bitcast i8* %193 to i32*
  store i32 %177, i32* %194, align 4
  %195 = getelementptr inbounds i8, i8* %189, i64 12
  %196 = bitcast i8* %195 to i32*
  store i32 %177, i32* %196, align 4
  %197 = getelementptr inbounds i8, i8* %189, i64 %1
  %198 = bitcast i8* %197 to i32*
  store i32 %177, i32* %198, align 4
  %199 = getelementptr inbounds i8, i8* %197, i64 4
  %200 = bitcast i8* %199 to i32*
  store i32 %177, i32* %200, align 4
  %201 = getelementptr inbounds i8, i8* %197, i64 8
  %202 = bitcast i8* %201 to i32*
  store i32 %177, i32* %202, align 4
  %203 = getelementptr inbounds i8, i8* %197, i64 12
  %204 = bitcast i8* %203 to i32*
  store i32 %177, i32* %204, align 4
  %205 = getelementptr inbounds i8, i8* %197, i64 %1
  %206 = bitcast i8* %205 to i32*
  store i32 %177, i32* %206, align 4
  %207 = getelementptr inbounds i8, i8* %205, i64 4
  %208 = bitcast i8* %207 to i32*
  store i32 %177, i32* %208, align 4
  %209 = getelementptr inbounds i8, i8* %205, i64 8
  %210 = bitcast i8* %209 to i32*
  store i32 %177, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %205, i64 12
  %212 = bitcast i8* %211 to i32*
  store i32 %177, i32* %212, align 4
  %213 = getelementptr inbounds i8, i8* %205, i64 %1
  %214 = bitcast i8* %213 to i32*
  store i32 %177, i32* %214, align 4
  %215 = getelementptr inbounds i8, i8* %213, i64 4
  %216 = bitcast i8* %215 to i32*
  store i32 %177, i32* %216, align 4
  %217 = getelementptr inbounds i8, i8* %213, i64 8
  %218 = bitcast i8* %217 to i32*
  store i32 %177, i32* %218, align 4
  %219 = getelementptr inbounds i8, i8* %213, i64 12
  %220 = bitcast i8* %219 to i32*
  store i32 %177, i32* %220, align 4
  %221 = getelementptr inbounds i8, i8* %213, i64 %1
  %222 = bitcast i8* %221 to i32*
  store i32 %177, i32* %222, align 4
  %223 = getelementptr inbounds i8, i8* %221, i64 4
  %224 = bitcast i8* %223 to i32*
  store i32 %177, i32* %224, align 4
  %225 = getelementptr inbounds i8, i8* %221, i64 8
  %226 = bitcast i8* %225 to i32*
  store i32 %177, i32* %226, align 4
  %227 = getelementptr inbounds i8, i8* %221, i64 12
  %228 = bitcast i8* %227 to i32*
  store i32 %177, i32* %228, align 4
  %229 = getelementptr inbounds i8, i8* %221, i64 %1
  %230 = bitcast i8* %229 to i32*
  store i32 %177, i32* %230, align 4
  %231 = getelementptr inbounds i8, i8* %229, i64 4
  %232 = bitcast i8* %231 to i32*
  store i32 %177, i32* %232, align 4
  %233 = getelementptr inbounds i8, i8* %229, i64 8
  %234 = bitcast i8* %233 to i32*
  store i32 %177, i32* %234, align 4
  %235 = getelementptr inbounds i8, i8* %229, i64 12
  %236 = bitcast i8* %235 to i32*
  store i32 %177, i32* %236, align 4
  %237 = getelementptr inbounds i8, i8* %229, i64 %1
  %238 = bitcast i8* %237 to i32*
  store i32 %177, i32* %238, align 4
  %239 = getelementptr inbounds i8, i8* %237, i64 4
  %240 = bitcast i8* %239 to i32*
  store i32 %177, i32* %240, align 4
  %241 = getelementptr inbounds i8, i8* %237, i64 8
  %242 = bitcast i8* %241 to i32*
  store i32 %177, i32* %242, align 4
  %243 = getelementptr inbounds i8, i8* %237, i64 12
  %244 = bitcast i8* %243 to i32*
  store i32 %177, i32* %244, align 4
  %245 = getelementptr inbounds i8, i8* %237, i64 %1
  %246 = bitcast i8* %245 to i32*
  store i32 %177, i32* %246, align 4
  %247 = getelementptr inbounds i8, i8* %245, i64 4
  %248 = bitcast i8* %247 to i32*
  store i32 %177, i32* %248, align 4
  %249 = getelementptr inbounds i8, i8* %245, i64 8
  %250 = bitcast i8* %249 to i32*
  store i32 %177, i32* %250, align 4
  %251 = getelementptr inbounds i8, i8* %245, i64 12
  %252 = bitcast i8* %251 to i32*
  store i32 %177, i32* %252, align 4
  %253 = getelementptr inbounds i8, i8* %245, i64 %1
  %254 = bitcast i8* %253 to i32*
  store i32 %177, i32* %254, align 4
  %255 = getelementptr inbounds i8, i8* %253, i64 4
  %256 = bitcast i8* %255 to i32*
  store i32 %177, i32* %256, align 4
  %257 = getelementptr inbounds i8, i8* %253, i64 8
  %258 = bitcast i8* %257 to i32*
  store i32 %177, i32* %258, align 4
  %259 = getelementptr inbounds i8, i8* %253, i64 12
  %260 = bitcast i8* %259 to i32*
  store i32 %177, i32* %260, align 4
  %261 = getelementptr inbounds i8, i8* %253, i64 %1
  %262 = bitcast i8* %261 to i32*
  store i32 %177, i32* %262, align 4
  %263 = getelementptr inbounds i8, i8* %261, i64 4
  %264 = bitcast i8* %263 to i32*
  store i32 %177, i32* %264, align 4
  %265 = getelementptr inbounds i8, i8* %261, i64 8
  %266 = bitcast i8* %265 to i32*
  store i32 %177, i32* %266, align 4
  %267 = getelementptr inbounds i8, i8* %261, i64 12
  %268 = bitcast i8* %267 to i32*
  store i32 %177, i32* %268, align 4
  %269 = getelementptr inbounds i8, i8* %261, i64 %1
  %270 = bitcast i8* %269 to i32*
  store i32 %177, i32* %270, align 4
  %271 = getelementptr inbounds i8, i8* %269, i64 4
  %272 = bitcast i8* %271 to i32*
  store i32 %177, i32* %272, align 4
  %273 = getelementptr inbounds i8, i8* %269, i64 8
  %274 = bitcast i8* %273 to i32*
  store i32 %177, i32* %274, align 4
  %275 = getelementptr inbounds i8, i8* %269, i64 12
  %276 = bitcast i8* %275 to i32*
  store i32 %177, i32* %276, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_vertical_8_c(i8* nocapture, i64) #1 {
  %3 = shl i64 %1, 32
  %4 = ashr exact i64 %3, 32
  %5 = sub nsw i64 0, %4
  %6 = getelementptr inbounds i8, i8* %0, i64 %5
  %7 = bitcast i8* %6 to <4 x i32>*
  %8 = load <4 x i32>, <4 x i32>* %7, align 4
  %9 = shl i64 %1, 32
  %10 = ashr exact i64 %9, 32
  %11 = bitcast i8* %0 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %11, align 4
  %12 = getelementptr inbounds i8, i8* %0, i64 %10
  %13 = bitcast i8* %12 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %13, align 4
  %14 = ashr exact i64 %9, 31
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  %16 = bitcast i8* %15 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %16, align 4
  %17 = mul nsw i64 %10, 3
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = bitcast i8* %18 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %19, align 4
  %20 = ashr exact i64 %9, 30
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = bitcast i8* %21 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %22, align 4
  %23 = mul nsw i64 %10, 5
  %24 = getelementptr inbounds i8, i8* %0, i64 %23
  %25 = bitcast i8* %24 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %25, align 4
  %26 = mul nsw i64 %10, 6
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  %28 = bitcast i8* %27 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %28, align 4
  %29 = mul nsw i64 %10, 7
  %30 = getelementptr inbounds i8, i8* %0, i64 %29
  %31 = bitcast i8* %30 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %31, align 4
  %32 = ashr exact i64 %9, 29
  %33 = getelementptr inbounds i8, i8* %0, i64 %32
  %34 = bitcast i8* %33 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %34, align 4
  %35 = mul nsw i64 %10, 9
  %36 = getelementptr inbounds i8, i8* %0, i64 %35
  %37 = bitcast i8* %36 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %37, align 4
  %38 = mul nsw i64 %10, 10
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = bitcast i8* %39 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %40, align 4
  %41 = mul nsw i64 %10, 11
  %42 = getelementptr inbounds i8, i8* %0, i64 %41
  %43 = bitcast i8* %42 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %43, align 4
  %44 = mul nsw i64 %10, 12
  %45 = getelementptr inbounds i8, i8* %0, i64 %44
  %46 = bitcast i8* %45 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %46, align 4
  %47 = mul nsw i64 %10, 13
  %48 = getelementptr inbounds i8, i8* %0, i64 %47
  %49 = bitcast i8* %48 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %49, align 4
  %50 = mul nsw i64 %10, 14
  %51 = getelementptr inbounds i8, i8* %0, i64 %50
  %52 = bitcast i8* %51 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %52, align 4
  %53 = mul nsw i64 %10, 15
  %54 = getelementptr inbounds i8, i8* %0, i64 %53
  %55 = bitcast i8* %54 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %55, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_horizontal_8_c(i8* nocapture, i64) #1 {
  %3 = getelementptr inbounds i8, i8* %0, i64 -1
  %4 = load i8, i8* %3, align 1
  %5 = zext i8 %4 to i32
  %6 = mul nuw i32 %5, 16843009
  %7 = insertelement <4 x i32> undef, i32 %6, i32 0
  %8 = shufflevector <4 x i32> %7, <4 x i32> undef, <4 x i32> zeroinitializer
  %9 = bitcast i8* %0 to <4 x i32>*
  store <4 x i32> %8, <4 x i32>* %9, align 4
  %10 = add nsw i64 %1, -1
  %11 = getelementptr inbounds i8, i8* %0, i64 %10
  %12 = load i8, i8* %11, align 1
  %13 = zext i8 %12 to i32
  %14 = mul nuw i32 %13, 16843009
  %15 = getelementptr inbounds i8, i8* %0, i64 %1
  %16 = insertelement <4 x i32> undef, i32 %14, i32 0
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> zeroinitializer
  %18 = bitcast i8* %15 to <4 x i32>*
  store <4 x i32> %17, <4 x i32>* %18, align 4
  %19 = shl nsw i64 %1, 1
  %20 = add nsw i64 %19, -1
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = load i8, i8* %21, align 1
  %23 = zext i8 %22 to i32
  %24 = mul nuw i32 %23, 16843009
  %25 = getelementptr inbounds i8, i8* %0, i64 %19
  %26 = insertelement <4 x i32> undef, i32 %24, i32 0
  %27 = shufflevector <4 x i32> %26, <4 x i32> undef, <4 x i32> zeroinitializer
  %28 = bitcast i8* %25 to <4 x i32>*
  store <4 x i32> %27, <4 x i32>* %28, align 4
  %29 = mul nsw i64 %1, 3
  %30 = add nsw i64 %29, -1
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = mul nuw i32 %33, 16843009
  %35 = getelementptr inbounds i8, i8* %0, i64 %29
  %36 = insertelement <4 x i32> undef, i32 %34, i32 0
  %37 = shufflevector <4 x i32> %36, <4 x i32> undef, <4 x i32> zeroinitializer
  %38 = bitcast i8* %35 to <4 x i32>*
  store <4 x i32> %37, <4 x i32>* %38, align 4
  %39 = shl nsw i64 %1, 2
  %40 = add nsw i64 %39, -1
  %41 = getelementptr inbounds i8, i8* %0, i64 %40
  %42 = load i8, i8* %41, align 1
  %43 = zext i8 %42 to i32
  %44 = mul nuw i32 %43, 16843009
  %45 = getelementptr inbounds i8, i8* %0, i64 %39
  %46 = insertelement <4 x i32> undef, i32 %44, i32 0
  %47 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> zeroinitializer
  %48 = bitcast i8* %45 to <4 x i32>*
  store <4 x i32> %47, <4 x i32>* %48, align 4
  %49 = mul nsw i64 %1, 5
  %50 = add nsw i64 %49, -1
  %51 = getelementptr inbounds i8, i8* %0, i64 %50
  %52 = load i8, i8* %51, align 1
  %53 = zext i8 %52 to i32
  %54 = mul nuw i32 %53, 16843009
  %55 = getelementptr inbounds i8, i8* %0, i64 %49
  %56 = insertelement <4 x i32> undef, i32 %54, i32 0
  %57 = shufflevector <4 x i32> %56, <4 x i32> undef, <4 x i32> zeroinitializer
  %58 = bitcast i8* %55 to <4 x i32>*
  store <4 x i32> %57, <4 x i32>* %58, align 4
  %59 = mul nsw i64 %1, 6
  %60 = add nsw i64 %59, -1
  %61 = getelementptr inbounds i8, i8* %0, i64 %60
  %62 = load i8, i8* %61, align 1
  %63 = zext i8 %62 to i32
  %64 = mul nuw i32 %63, 16843009
  %65 = getelementptr inbounds i8, i8* %0, i64 %59
  %66 = insertelement <4 x i32> undef, i32 %64, i32 0
  %67 = shufflevector <4 x i32> %66, <4 x i32> undef, <4 x i32> zeroinitializer
  %68 = bitcast i8* %65 to <4 x i32>*
  store <4 x i32> %67, <4 x i32>* %68, align 4
  %69 = mul nsw i64 %1, 7
  %70 = add nsw i64 %69, -1
  %71 = getelementptr inbounds i8, i8* %0, i64 %70
  %72 = load i8, i8* %71, align 1
  %73 = zext i8 %72 to i32
  %74 = mul nuw i32 %73, 16843009
  %75 = getelementptr inbounds i8, i8* %0, i64 %69
  %76 = insertelement <4 x i32> undef, i32 %74, i32 0
  %77 = shufflevector <4 x i32> %76, <4 x i32> undef, <4 x i32> zeroinitializer
  %78 = bitcast i8* %75 to <4 x i32>*
  store <4 x i32> %77, <4 x i32>* %78, align 4
  %79 = shl nsw i64 %1, 3
  %80 = add nsw i64 %79, -1
  %81 = getelementptr inbounds i8, i8* %0, i64 %80
  %82 = load i8, i8* %81, align 1
  %83 = zext i8 %82 to i32
  %84 = mul nuw i32 %83, 16843009
  %85 = getelementptr inbounds i8, i8* %0, i64 %79
  %86 = insertelement <4 x i32> undef, i32 %84, i32 0
  %87 = shufflevector <4 x i32> %86, <4 x i32> undef, <4 x i32> zeroinitializer
  %88 = bitcast i8* %85 to <4 x i32>*
  store <4 x i32> %87, <4 x i32>* %88, align 4
  %89 = mul nsw i64 %1, 9
  %90 = add nsw i64 %89, -1
  %91 = getelementptr inbounds i8, i8* %0, i64 %90
  %92 = load i8, i8* %91, align 1
  %93 = zext i8 %92 to i32
  %94 = mul nuw i32 %93, 16843009
  %95 = getelementptr inbounds i8, i8* %0, i64 %89
  %96 = insertelement <4 x i32> undef, i32 %94, i32 0
  %97 = shufflevector <4 x i32> %96, <4 x i32> undef, <4 x i32> zeroinitializer
  %98 = bitcast i8* %95 to <4 x i32>*
  store <4 x i32> %97, <4 x i32>* %98, align 4
  %99 = mul nsw i64 %1, 10
  %100 = add nsw i64 %99, -1
  %101 = getelementptr inbounds i8, i8* %0, i64 %100
  %102 = load i8, i8* %101, align 1
  %103 = zext i8 %102 to i32
  %104 = mul nuw i32 %103, 16843009
  %105 = getelementptr inbounds i8, i8* %0, i64 %99
  %106 = insertelement <4 x i32> undef, i32 %104, i32 0
  %107 = shufflevector <4 x i32> %106, <4 x i32> undef, <4 x i32> zeroinitializer
  %108 = bitcast i8* %105 to <4 x i32>*
  store <4 x i32> %107, <4 x i32>* %108, align 4
  %109 = mul nsw i64 %1, 11
  %110 = add nsw i64 %109, -1
  %111 = getelementptr inbounds i8, i8* %0, i64 %110
  %112 = load i8, i8* %111, align 1
  %113 = zext i8 %112 to i32
  %114 = mul nuw i32 %113, 16843009
  %115 = getelementptr inbounds i8, i8* %0, i64 %109
  %116 = insertelement <4 x i32> undef, i32 %114, i32 0
  %117 = shufflevector <4 x i32> %116, <4 x i32> undef, <4 x i32> zeroinitializer
  %118 = bitcast i8* %115 to <4 x i32>*
  store <4 x i32> %117, <4 x i32>* %118, align 4
  %119 = mul nsw i64 %1, 12
  %120 = add nsw i64 %119, -1
  %121 = getelementptr inbounds i8, i8* %0, i64 %120
  %122 = load i8, i8* %121, align 1
  %123 = zext i8 %122 to i32
  %124 = mul nuw i32 %123, 16843009
  %125 = getelementptr inbounds i8, i8* %0, i64 %119
  %126 = insertelement <4 x i32> undef, i32 %124, i32 0
  %127 = shufflevector <4 x i32> %126, <4 x i32> undef, <4 x i32> zeroinitializer
  %128 = bitcast i8* %125 to <4 x i32>*
  store <4 x i32> %127, <4 x i32>* %128, align 4
  %129 = mul nsw i64 %1, 13
  %130 = add nsw i64 %129, -1
  %131 = getelementptr inbounds i8, i8* %0, i64 %130
  %132 = load i8, i8* %131, align 1
  %133 = zext i8 %132 to i32
  %134 = mul nuw i32 %133, 16843009
  %135 = getelementptr inbounds i8, i8* %0, i64 %129
  %136 = insertelement <4 x i32> undef, i32 %134, i32 0
  %137 = shufflevector <4 x i32> %136, <4 x i32> undef, <4 x i32> zeroinitializer
  %138 = bitcast i8* %135 to <4 x i32>*
  store <4 x i32> %137, <4 x i32>* %138, align 4
  %139 = mul nsw i64 %1, 14
  %140 = add nsw i64 %139, -1
  %141 = getelementptr inbounds i8, i8* %0, i64 %140
  %142 = load i8, i8* %141, align 1
  %143 = zext i8 %142 to i32
  %144 = mul nuw i32 %143, 16843009
  %145 = getelementptr inbounds i8, i8* %0, i64 %139
  %146 = insertelement <4 x i32> undef, i32 %144, i32 0
  %147 = shufflevector <4 x i32> %146, <4 x i32> undef, <4 x i32> zeroinitializer
  %148 = bitcast i8* %145 to <4 x i32>*
  store <4 x i32> %147, <4 x i32>* %148, align 4
  %149 = mul nsw i64 %1, 15
  %150 = add nsw i64 %149, -1
  %151 = getelementptr inbounds i8, i8* %0, i64 %150
  %152 = load i8, i8* %151, align 1
  %153 = zext i8 %152 to i32
  %154 = mul nuw i32 %153, 16843009
  %155 = getelementptr inbounds i8, i8* %0, i64 %149
  %156 = insertelement <4 x i32> undef, i32 %154, i32 0
  %157 = shufflevector <4 x i32> %156, <4 x i32> undef, <4 x i32> zeroinitializer
  %158 = bitcast i8* %155 to <4 x i32>*
  store <4 x i32> %157, <4 x i32>* %158, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_127_dc_8_c(i8* nocapture, i64) #2 {
  %3 = getelementptr inbounds i8, i8* %0, i64 %1
  call void @llvm.memset.p0i8.i64(i8* align 4 %0, i8 127, i64 16, i1 false)
  %4 = bitcast i8* %3 to <4 x i32>*
  store <4 x i32> <i32 2139062143, i32 2139062143, i32 2139062143, i32 2139062143>, <4 x i32>* %4, align 4
  %5 = getelementptr inbounds i8, i8* %3, i64 %1
  %6 = bitcast i8* %5 to <4 x i32>*
  store <4 x i32> <i32 2139062143, i32 2139062143, i32 2139062143, i32 2139062143>, <4 x i32>* %6, align 4
  %7 = getelementptr inbounds i8, i8* %5, i64 %1
  %8 = bitcast i8* %7 to <4 x i32>*
  store <4 x i32> <i32 2139062143, i32 2139062143, i32 2139062143, i32 2139062143>, <4 x i32>* %8, align 4
  %9 = getelementptr inbounds i8, i8* %7, i64 %1
  %10 = bitcast i8* %9 to <4 x i32>*
  store <4 x i32> <i32 2139062143, i32 2139062143, i32 2139062143, i32 2139062143>, <4 x i32>* %10, align 4
  %11 = getelementptr inbounds i8, i8* %9, i64 %1
  %12 = bitcast i8* %11 to i32*
  store i32 2139062143, i32* %12, align 4
  %13 = getelementptr inbounds i8, i8* %11, i64 4
  %14 = bitcast i8* %13 to i32*
  store i32 2139062143, i32* %14, align 4
  %15 = getelementptr inbounds i8, i8* %11, i64 8
  %16 = bitcast i8* %15 to i32*
  store i32 2139062143, i32* %16, align 4
  %17 = getelementptr inbounds i8, i8* %11, i64 12
  %18 = bitcast i8* %17 to i32*
  store i32 2139062143, i32* %18, align 4
  %19 = getelementptr inbounds i8, i8* %11, i64 %1
  %20 = bitcast i8* %19 to i32*
  store i32 2139062143, i32* %20, align 4
  %21 = getelementptr inbounds i8, i8* %19, i64 4
  %22 = bitcast i8* %21 to i32*
  store i32 2139062143, i32* %22, align 4
  %23 = getelementptr inbounds i8, i8* %19, i64 8
  %24 = bitcast i8* %23 to i32*
  store i32 2139062143, i32* %24, align 4
  %25 = getelementptr inbounds i8, i8* %19, i64 12
  %26 = bitcast i8* %25 to i32*
  store i32 2139062143, i32* %26, align 4
  %27 = getelementptr inbounds i8, i8* %19, i64 %1
  %28 = bitcast i8* %27 to i32*
  store i32 2139062143, i32* %28, align 4
  %29 = getelementptr inbounds i8, i8* %27, i64 4
  %30 = bitcast i8* %29 to i32*
  store i32 2139062143, i32* %30, align 4
  %31 = getelementptr inbounds i8, i8* %27, i64 8
  %32 = bitcast i8* %31 to i32*
  store i32 2139062143, i32* %32, align 4
  %33 = getelementptr inbounds i8, i8* %27, i64 12
  %34 = bitcast i8* %33 to i32*
  store i32 2139062143, i32* %34, align 4
  %35 = getelementptr inbounds i8, i8* %27, i64 %1
  %36 = bitcast i8* %35 to i32*
  store i32 2139062143, i32* %36, align 4
  %37 = getelementptr inbounds i8, i8* %35, i64 4
  %38 = bitcast i8* %37 to i32*
  store i32 2139062143, i32* %38, align 4
  %39 = getelementptr inbounds i8, i8* %35, i64 8
  %40 = bitcast i8* %39 to i32*
  store i32 2139062143, i32* %40, align 4
  %41 = getelementptr inbounds i8, i8* %35, i64 12
  %42 = bitcast i8* %41 to i32*
  store i32 2139062143, i32* %42, align 4
  %43 = getelementptr inbounds i8, i8* %35, i64 %1
  %44 = bitcast i8* %43 to i32*
  store i32 2139062143, i32* %44, align 4
  %45 = getelementptr inbounds i8, i8* %43, i64 4
  %46 = bitcast i8* %45 to i32*
  store i32 2139062143, i32* %46, align 4
  %47 = getelementptr inbounds i8, i8* %43, i64 8
  %48 = bitcast i8* %47 to i32*
  store i32 2139062143, i32* %48, align 4
  %49 = getelementptr inbounds i8, i8* %43, i64 12
  %50 = bitcast i8* %49 to i32*
  store i32 2139062143, i32* %50, align 4
  %51 = getelementptr inbounds i8, i8* %43, i64 %1
  %52 = bitcast i8* %51 to i32*
  store i32 2139062143, i32* %52, align 4
  %53 = getelementptr inbounds i8, i8* %51, i64 4
  %54 = bitcast i8* %53 to i32*
  store i32 2139062143, i32* %54, align 4
  %55 = getelementptr inbounds i8, i8* %51, i64 8
  %56 = bitcast i8* %55 to i32*
  store i32 2139062143, i32* %56, align 4
  %57 = getelementptr inbounds i8, i8* %51, i64 12
  %58 = bitcast i8* %57 to i32*
  store i32 2139062143, i32* %58, align 4
  %59 = getelementptr inbounds i8, i8* %51, i64 %1
  %60 = bitcast i8* %59 to i32*
  store i32 2139062143, i32* %60, align 4
  %61 = getelementptr inbounds i8, i8* %59, i64 4
  %62 = bitcast i8* %61 to i32*
  store i32 2139062143, i32* %62, align 4
  %63 = getelementptr inbounds i8, i8* %59, i64 8
  %64 = bitcast i8* %63 to i32*
  store i32 2139062143, i32* %64, align 4
  %65 = getelementptr inbounds i8, i8* %59, i64 12
  %66 = bitcast i8* %65 to i32*
  store i32 2139062143, i32* %66, align 4
  %67 = getelementptr inbounds i8, i8* %59, i64 %1
  %68 = bitcast i8* %67 to i32*
  store i32 2139062143, i32* %68, align 4
  %69 = getelementptr inbounds i8, i8* %67, i64 4
  %70 = bitcast i8* %69 to i32*
  store i32 2139062143, i32* %70, align 4
  %71 = getelementptr inbounds i8, i8* %67, i64 8
  %72 = bitcast i8* %71 to i32*
  store i32 2139062143, i32* %72, align 4
  %73 = getelementptr inbounds i8, i8* %67, i64 12
  %74 = bitcast i8* %73 to i32*
  store i32 2139062143, i32* %74, align 4
  %75 = getelementptr inbounds i8, i8* %67, i64 %1
  %76 = bitcast i8* %75 to i32*
  store i32 2139062143, i32* %76, align 4
  %77 = getelementptr inbounds i8, i8* %75, i64 4
  %78 = bitcast i8* %77 to i32*
  store i32 2139062143, i32* %78, align 4
  %79 = getelementptr inbounds i8, i8* %75, i64 8
  %80 = bitcast i8* %79 to i32*
  store i32 2139062143, i32* %80, align 4
  %81 = getelementptr inbounds i8, i8* %75, i64 12
  %82 = bitcast i8* %81 to i32*
  store i32 2139062143, i32* %82, align 4
  %83 = getelementptr inbounds i8, i8* %75, i64 %1
  %84 = bitcast i8* %83 to i32*
  store i32 2139062143, i32* %84, align 4
  %85 = getelementptr inbounds i8, i8* %83, i64 4
  %86 = bitcast i8* %85 to i32*
  store i32 2139062143, i32* %86, align 4
  %87 = getelementptr inbounds i8, i8* %83, i64 8
  %88 = bitcast i8* %87 to i32*
  store i32 2139062143, i32* %88, align 4
  %89 = getelementptr inbounds i8, i8* %83, i64 12
  %90 = bitcast i8* %89 to i32*
  store i32 2139062143, i32* %90, align 4
  %91 = getelementptr inbounds i8, i8* %83, i64 %1
  %92 = bitcast i8* %91 to i32*
  store i32 2139062143, i32* %92, align 4
  %93 = getelementptr inbounds i8, i8* %91, i64 4
  %94 = bitcast i8* %93 to i32*
  store i32 2139062143, i32* %94, align 4
  %95 = getelementptr inbounds i8, i8* %91, i64 8
  %96 = bitcast i8* %95 to i32*
  store i32 2139062143, i32* %96, align 4
  %97 = getelementptr inbounds i8, i8* %91, i64 12
  %98 = bitcast i8* %97 to i32*
  store i32 2139062143, i32* %98, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_129_dc_8_c(i8* nocapture, i64) #2 {
  %3 = getelementptr inbounds i8, i8* %0, i64 %1
  call void @llvm.memset.p0i8.i64(i8* align 4 %0, i8 -127, i64 16, i1 false)
  %4 = bitcast i8* %3 to <4 x i32>*
  store <4 x i32> <i32 -2122219135, i32 -2122219135, i32 -2122219135, i32 -2122219135>, <4 x i32>* %4, align 4
  %5 = getelementptr inbounds i8, i8* %3, i64 %1
  %6 = bitcast i8* %5 to <4 x i32>*
  store <4 x i32> <i32 -2122219135, i32 -2122219135, i32 -2122219135, i32 -2122219135>, <4 x i32>* %6, align 4
  %7 = getelementptr inbounds i8, i8* %5, i64 %1
  %8 = bitcast i8* %7 to <4 x i32>*
  store <4 x i32> <i32 -2122219135, i32 -2122219135, i32 -2122219135, i32 -2122219135>, <4 x i32>* %8, align 4
  %9 = getelementptr inbounds i8, i8* %7, i64 %1
  %10 = bitcast i8* %9 to <4 x i32>*
  store <4 x i32> <i32 -2122219135, i32 -2122219135, i32 -2122219135, i32 -2122219135>, <4 x i32>* %10, align 4
  %11 = getelementptr inbounds i8, i8* %9, i64 %1
  %12 = bitcast i8* %11 to i32*
  store i32 -2122219135, i32* %12, align 4
  %13 = getelementptr inbounds i8, i8* %11, i64 4
  %14 = bitcast i8* %13 to i32*
  store i32 -2122219135, i32* %14, align 4
  %15 = getelementptr inbounds i8, i8* %11, i64 8
  %16 = bitcast i8* %15 to i32*
  store i32 -2122219135, i32* %16, align 4
  %17 = getelementptr inbounds i8, i8* %11, i64 12
  %18 = bitcast i8* %17 to i32*
  store i32 -2122219135, i32* %18, align 4
  %19 = getelementptr inbounds i8, i8* %11, i64 %1
  %20 = bitcast i8* %19 to i32*
  store i32 -2122219135, i32* %20, align 4
  %21 = getelementptr inbounds i8, i8* %19, i64 4
  %22 = bitcast i8* %21 to i32*
  store i32 -2122219135, i32* %22, align 4
  %23 = getelementptr inbounds i8, i8* %19, i64 8
  %24 = bitcast i8* %23 to i32*
  store i32 -2122219135, i32* %24, align 4
  %25 = getelementptr inbounds i8, i8* %19, i64 12
  %26 = bitcast i8* %25 to i32*
  store i32 -2122219135, i32* %26, align 4
  %27 = getelementptr inbounds i8, i8* %19, i64 %1
  %28 = bitcast i8* %27 to i32*
  store i32 -2122219135, i32* %28, align 4
  %29 = getelementptr inbounds i8, i8* %27, i64 4
  %30 = bitcast i8* %29 to i32*
  store i32 -2122219135, i32* %30, align 4
  %31 = getelementptr inbounds i8, i8* %27, i64 8
  %32 = bitcast i8* %31 to i32*
  store i32 -2122219135, i32* %32, align 4
  %33 = getelementptr inbounds i8, i8* %27, i64 12
  %34 = bitcast i8* %33 to i32*
  store i32 -2122219135, i32* %34, align 4
  %35 = getelementptr inbounds i8, i8* %27, i64 %1
  %36 = bitcast i8* %35 to i32*
  store i32 -2122219135, i32* %36, align 4
  %37 = getelementptr inbounds i8, i8* %35, i64 4
  %38 = bitcast i8* %37 to i32*
  store i32 -2122219135, i32* %38, align 4
  %39 = getelementptr inbounds i8, i8* %35, i64 8
  %40 = bitcast i8* %39 to i32*
  store i32 -2122219135, i32* %40, align 4
  %41 = getelementptr inbounds i8, i8* %35, i64 12
  %42 = bitcast i8* %41 to i32*
  store i32 -2122219135, i32* %42, align 4
  %43 = getelementptr inbounds i8, i8* %35, i64 %1
  %44 = bitcast i8* %43 to i32*
  store i32 -2122219135, i32* %44, align 4
  %45 = getelementptr inbounds i8, i8* %43, i64 4
  %46 = bitcast i8* %45 to i32*
  store i32 -2122219135, i32* %46, align 4
  %47 = getelementptr inbounds i8, i8* %43, i64 8
  %48 = bitcast i8* %47 to i32*
  store i32 -2122219135, i32* %48, align 4
  %49 = getelementptr inbounds i8, i8* %43, i64 12
  %50 = bitcast i8* %49 to i32*
  store i32 -2122219135, i32* %50, align 4
  %51 = getelementptr inbounds i8, i8* %43, i64 %1
  %52 = bitcast i8* %51 to i32*
  store i32 -2122219135, i32* %52, align 4
  %53 = getelementptr inbounds i8, i8* %51, i64 4
  %54 = bitcast i8* %53 to i32*
  store i32 -2122219135, i32* %54, align 4
  %55 = getelementptr inbounds i8, i8* %51, i64 8
  %56 = bitcast i8* %55 to i32*
  store i32 -2122219135, i32* %56, align 4
  %57 = getelementptr inbounds i8, i8* %51, i64 12
  %58 = bitcast i8* %57 to i32*
  store i32 -2122219135, i32* %58, align 4
  %59 = getelementptr inbounds i8, i8* %51, i64 %1
  %60 = bitcast i8* %59 to i32*
  store i32 -2122219135, i32* %60, align 4
  %61 = getelementptr inbounds i8, i8* %59, i64 4
  %62 = bitcast i8* %61 to i32*
  store i32 -2122219135, i32* %62, align 4
  %63 = getelementptr inbounds i8, i8* %59, i64 8
  %64 = bitcast i8* %63 to i32*
  store i32 -2122219135, i32* %64, align 4
  %65 = getelementptr inbounds i8, i8* %59, i64 12
  %66 = bitcast i8* %65 to i32*
  store i32 -2122219135, i32* %66, align 4
  %67 = getelementptr inbounds i8, i8* %59, i64 %1
  %68 = bitcast i8* %67 to i32*
  store i32 -2122219135, i32* %68, align 4
  %69 = getelementptr inbounds i8, i8* %67, i64 4
  %70 = bitcast i8* %69 to i32*
  store i32 -2122219135, i32* %70, align 4
  %71 = getelementptr inbounds i8, i8* %67, i64 8
  %72 = bitcast i8* %71 to i32*
  store i32 -2122219135, i32* %72, align 4
  %73 = getelementptr inbounds i8, i8* %67, i64 12
  %74 = bitcast i8* %73 to i32*
  store i32 -2122219135, i32* %74, align 4
  %75 = getelementptr inbounds i8, i8* %67, i64 %1
  %76 = bitcast i8* %75 to i32*
  store i32 -2122219135, i32* %76, align 4
  %77 = getelementptr inbounds i8, i8* %75, i64 4
  %78 = bitcast i8* %77 to i32*
  store i32 -2122219135, i32* %78, align 4
  %79 = getelementptr inbounds i8, i8* %75, i64 8
  %80 = bitcast i8* %79 to i32*
  store i32 -2122219135, i32* %80, align 4
  %81 = getelementptr inbounds i8, i8* %75, i64 12
  %82 = bitcast i8* %81 to i32*
  store i32 -2122219135, i32* %82, align 4
  %83 = getelementptr inbounds i8, i8* %75, i64 %1
  %84 = bitcast i8* %83 to i32*
  store i32 -2122219135, i32* %84, align 4
  %85 = getelementptr inbounds i8, i8* %83, i64 4
  %86 = bitcast i8* %85 to i32*
  store i32 -2122219135, i32* %86, align 4
  %87 = getelementptr inbounds i8, i8* %83, i64 8
  %88 = bitcast i8* %87 to i32*
  store i32 -2122219135, i32* %88, align 4
  %89 = getelementptr inbounds i8, i8* %83, i64 12
  %90 = bitcast i8* %89 to i32*
  store i32 -2122219135, i32* %90, align 4
  %91 = getelementptr inbounds i8, i8* %83, i64 %1
  %92 = bitcast i8* %91 to i32*
  store i32 -2122219135, i32* %92, align 4
  %93 = getelementptr inbounds i8, i8* %91, i64 4
  %94 = bitcast i8* %93 to i32*
  store i32 -2122219135, i32* %94, align 4
  %95 = getelementptr inbounds i8, i8* %91, i64 8
  %96 = bitcast i8* %95 to i32*
  store i32 -2122219135, i32* %96, align 4
  %97 = getelementptr inbounds i8, i8* %91, i64 12
  %98 = bitcast i8* %97 to i32*
  store i32 -2122219135, i32* %98, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_plane_8_c(i8* nocapture, i64) #1 {
  tail call fastcc void @pred16x16_plane_compat_8_c(i8* %0, i64 %1, i32 0, i32 0)
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_left_dc_8_c(i8* nocapture, i64) #1 {
  %3 = getelementptr inbounds i8, i8* %0, i64 -1
  %4 = load i8, i8* %3, align 1
  %5 = zext i8 %4 to i32
  %6 = add nsw i64 %1, -1
  %7 = getelementptr inbounds i8, i8* %0, i64 %6
  %8 = load i8, i8* %7, align 1
  %9 = zext i8 %8 to i32
  %10 = add nuw nsw i32 %5, %9
  %11 = shl nsw i64 %1, 1
  %12 = add nsw i64 %11, -1
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = add nuw nsw i32 %10, %15
  %17 = mul nsw i64 %1, 3
  %18 = add nsw i64 %17, -1
  %19 = getelementptr inbounds i8, i8* %0, i64 %18
  %20 = load i8, i8* %19, align 1
  %21 = zext i8 %20 to i32
  %22 = add nuw nsw i32 %16, %21
  %23 = shl nsw i64 %1, 2
  %24 = add nsw i64 %23, -1
  %25 = getelementptr inbounds i8, i8* %0, i64 %24
  %26 = load i8, i8* %25, align 1
  %27 = zext i8 %26 to i32
  %28 = add nuw nsw i32 %22, %27
  %29 = mul nsw i64 %1, 5
  %30 = add nsw i64 %29, -1
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = add nuw nsw i32 %28, %33
  %35 = mul nsw i64 %1, 6
  %36 = add nsw i64 %35, -1
  %37 = getelementptr inbounds i8, i8* %0, i64 %36
  %38 = load i8, i8* %37, align 1
  %39 = zext i8 %38 to i32
  %40 = add nuw nsw i32 %34, %39
  %41 = mul nsw i64 %1, 7
  %42 = add nsw i64 %41, -1
  %43 = getelementptr inbounds i8, i8* %0, i64 %42
  %44 = load i8, i8* %43, align 1
  %45 = zext i8 %44 to i32
  %46 = add nuw nsw i32 %40, %45
  %47 = shl nsw i64 %1, 3
  %48 = add nsw i64 %47, -1
  %49 = getelementptr inbounds i8, i8* %0, i64 %48
  %50 = load i8, i8* %49, align 1
  %51 = zext i8 %50 to i32
  %52 = add nuw nsw i32 %46, %51
  %53 = mul nsw i64 %1, 9
  %54 = add nsw i64 %53, -1
  %55 = getelementptr inbounds i8, i8* %0, i64 %54
  %56 = load i8, i8* %55, align 1
  %57 = zext i8 %56 to i32
  %58 = add nuw nsw i32 %52, %57
  %59 = mul nsw i64 %1, 10
  %60 = add nsw i64 %59, -1
  %61 = getelementptr inbounds i8, i8* %0, i64 %60
  %62 = load i8, i8* %61, align 1
  %63 = zext i8 %62 to i32
  %64 = add nuw nsw i32 %58, %63
  %65 = mul nsw i64 %1, 11
  %66 = add nsw i64 %65, -1
  %67 = getelementptr inbounds i8, i8* %0, i64 %66
  %68 = load i8, i8* %67, align 1
  %69 = zext i8 %68 to i32
  %70 = add nuw nsw i32 %64, %69
  %71 = mul nsw i64 %1, 12
  %72 = add nsw i64 %71, -1
  %73 = getelementptr inbounds i8, i8* %0, i64 %72
  %74 = load i8, i8* %73, align 1
  %75 = zext i8 %74 to i32
  %76 = add nuw nsw i32 %70, %75
  %77 = mul nsw i64 %1, 13
  %78 = add nsw i64 %77, -1
  %79 = getelementptr inbounds i8, i8* %0, i64 %78
  %80 = load i8, i8* %79, align 1
  %81 = zext i8 %80 to i32
  %82 = add nuw nsw i32 %76, %81
  %83 = mul nsw i64 %1, 14
  %84 = add nsw i64 %83, -1
  %85 = getelementptr inbounds i8, i8* %0, i64 %84
  %86 = load i8, i8* %85, align 1
  %87 = zext i8 %86 to i32
  %88 = add nuw nsw i32 %82, %87
  %89 = mul nsw i64 %1, 15
  %90 = add nsw i64 %89, -1
  %91 = getelementptr inbounds i8, i8* %0, i64 %90
  %92 = load i8, i8* %91, align 1
  %93 = zext i8 %92 to i32
  %94 = add nuw nsw i32 %88, %93
  %95 = add nuw nsw i32 %94, 8
  %96 = lshr i32 %95, 4
  %97 = mul i32 %96, 16843009
  %98 = insertelement <4 x i32> undef, i32 %97, i32 0
  %99 = shufflevector <4 x i32> %98, <4 x i32> undef, <4 x i32> zeroinitializer
  %100 = bitcast i8* %0 to <4 x i32>*
  store <4 x i32> %99, <4 x i32>* %100, align 4
  %101 = getelementptr inbounds i8, i8* %0, i64 %1
  %102 = bitcast i8* %101 to <4 x i32>*
  store <4 x i32> %99, <4 x i32>* %102, align 4
  %103 = getelementptr inbounds i8, i8* %101, i64 %1
  %104 = bitcast i8* %103 to <4 x i32>*
  store <4 x i32> %99, <4 x i32>* %104, align 4
  %105 = getelementptr inbounds i8, i8* %103, i64 %1
  %106 = bitcast i8* %105 to <4 x i32>*
  store <4 x i32> %99, <4 x i32>* %106, align 4
  %107 = getelementptr inbounds i8, i8* %105, i64 %1
  %108 = bitcast i8* %107 to <4 x i32>*
  store <4 x i32> %99, <4 x i32>* %108, align 4
  %109 = getelementptr inbounds i8, i8* %107, i64 %1
  %110 = bitcast i8* %109 to i32*
  store i32 %97, i32* %110, align 4
  %111 = getelementptr inbounds i8, i8* %109, i64 4
  %112 = bitcast i8* %111 to i32*
  store i32 %97, i32* %112, align 4
  %113 = getelementptr inbounds i8, i8* %109, i64 8
  %114 = bitcast i8* %113 to i32*
  store i32 %97, i32* %114, align 4
  %115 = getelementptr inbounds i8, i8* %109, i64 12
  %116 = bitcast i8* %115 to i32*
  store i32 %97, i32* %116, align 4
  %117 = getelementptr inbounds i8, i8* %109, i64 %1
  %118 = bitcast i8* %117 to i32*
  store i32 %97, i32* %118, align 4
  %119 = getelementptr inbounds i8, i8* %117, i64 4
  %120 = bitcast i8* %119 to i32*
  store i32 %97, i32* %120, align 4
  %121 = getelementptr inbounds i8, i8* %117, i64 8
  %122 = bitcast i8* %121 to i32*
  store i32 %97, i32* %122, align 4
  %123 = getelementptr inbounds i8, i8* %117, i64 12
  %124 = bitcast i8* %123 to i32*
  store i32 %97, i32* %124, align 4
  %125 = getelementptr inbounds i8, i8* %117, i64 %1
  %126 = bitcast i8* %125 to i32*
  store i32 %97, i32* %126, align 4
  %127 = getelementptr inbounds i8, i8* %125, i64 4
  %128 = bitcast i8* %127 to i32*
  store i32 %97, i32* %128, align 4
  %129 = getelementptr inbounds i8, i8* %125, i64 8
  %130 = bitcast i8* %129 to i32*
  store i32 %97, i32* %130, align 4
  %131 = getelementptr inbounds i8, i8* %125, i64 12
  %132 = bitcast i8* %131 to i32*
  store i32 %97, i32* %132, align 4
  %133 = getelementptr inbounds i8, i8* %125, i64 %1
  %134 = bitcast i8* %133 to i32*
  store i32 %97, i32* %134, align 4
  %135 = getelementptr inbounds i8, i8* %133, i64 4
  %136 = bitcast i8* %135 to i32*
  store i32 %97, i32* %136, align 4
  %137 = getelementptr inbounds i8, i8* %133, i64 8
  %138 = bitcast i8* %137 to i32*
  store i32 %97, i32* %138, align 4
  %139 = getelementptr inbounds i8, i8* %133, i64 12
  %140 = bitcast i8* %139 to i32*
  store i32 %97, i32* %140, align 4
  %141 = getelementptr inbounds i8, i8* %133, i64 %1
  %142 = bitcast i8* %141 to i32*
  store i32 %97, i32* %142, align 4
  %143 = getelementptr inbounds i8, i8* %141, i64 4
  %144 = bitcast i8* %143 to i32*
  store i32 %97, i32* %144, align 4
  %145 = getelementptr inbounds i8, i8* %141, i64 8
  %146 = bitcast i8* %145 to i32*
  store i32 %97, i32* %146, align 4
  %147 = getelementptr inbounds i8, i8* %141, i64 12
  %148 = bitcast i8* %147 to i32*
  store i32 %97, i32* %148, align 4
  %149 = getelementptr inbounds i8, i8* %141, i64 %1
  %150 = bitcast i8* %149 to i32*
  store i32 %97, i32* %150, align 4
  %151 = getelementptr inbounds i8, i8* %149, i64 4
  %152 = bitcast i8* %151 to i32*
  store i32 %97, i32* %152, align 4
  %153 = getelementptr inbounds i8, i8* %149, i64 8
  %154 = bitcast i8* %153 to i32*
  store i32 %97, i32* %154, align 4
  %155 = getelementptr inbounds i8, i8* %149, i64 12
  %156 = bitcast i8* %155 to i32*
  store i32 %97, i32* %156, align 4
  %157 = getelementptr inbounds i8, i8* %149, i64 %1
  %158 = bitcast i8* %157 to i32*
  store i32 %97, i32* %158, align 4
  %159 = getelementptr inbounds i8, i8* %157, i64 4
  %160 = bitcast i8* %159 to i32*
  store i32 %97, i32* %160, align 4
  %161 = getelementptr inbounds i8, i8* %157, i64 8
  %162 = bitcast i8* %161 to i32*
  store i32 %97, i32* %162, align 4
  %163 = getelementptr inbounds i8, i8* %157, i64 12
  %164 = bitcast i8* %163 to i32*
  store i32 %97, i32* %164, align 4
  %165 = getelementptr inbounds i8, i8* %157, i64 %1
  %166 = bitcast i8* %165 to i32*
  store i32 %97, i32* %166, align 4
  %167 = getelementptr inbounds i8, i8* %165, i64 4
  %168 = bitcast i8* %167 to i32*
  store i32 %97, i32* %168, align 4
  %169 = getelementptr inbounds i8, i8* %165, i64 8
  %170 = bitcast i8* %169 to i32*
  store i32 %97, i32* %170, align 4
  %171 = getelementptr inbounds i8, i8* %165, i64 12
  %172 = bitcast i8* %171 to i32*
  store i32 %97, i32* %172, align 4
  %173 = getelementptr inbounds i8, i8* %165, i64 %1
  %174 = bitcast i8* %173 to i32*
  store i32 %97, i32* %174, align 4
  %175 = getelementptr inbounds i8, i8* %173, i64 4
  %176 = bitcast i8* %175 to i32*
  store i32 %97, i32* %176, align 4
  %177 = getelementptr inbounds i8, i8* %173, i64 8
  %178 = bitcast i8* %177 to i32*
  store i32 %97, i32* %178, align 4
  %179 = getelementptr inbounds i8, i8* %173, i64 12
  %180 = bitcast i8* %179 to i32*
  store i32 %97, i32* %180, align 4
  %181 = getelementptr inbounds i8, i8* %173, i64 %1
  %182 = bitcast i8* %181 to i32*
  store i32 %97, i32* %182, align 4
  %183 = getelementptr inbounds i8, i8* %181, i64 4
  %184 = bitcast i8* %183 to i32*
  store i32 %97, i32* %184, align 4
  %185 = getelementptr inbounds i8, i8* %181, i64 8
  %186 = bitcast i8* %185 to i32*
  store i32 %97, i32* %186, align 4
  %187 = getelementptr inbounds i8, i8* %181, i64 12
  %188 = bitcast i8* %187 to i32*
  store i32 %97, i32* %188, align 4
  %189 = getelementptr inbounds i8, i8* %181, i64 %1
  %190 = bitcast i8* %189 to i32*
  store i32 %97, i32* %190, align 4
  %191 = getelementptr inbounds i8, i8* %189, i64 4
  %192 = bitcast i8* %191 to i32*
  store i32 %97, i32* %192, align 4
  %193 = getelementptr inbounds i8, i8* %189, i64 8
  %194 = bitcast i8* %193 to i32*
  store i32 %97, i32* %194, align 4
  %195 = getelementptr inbounds i8, i8* %189, i64 12
  %196 = bitcast i8* %195 to i32*
  store i32 %97, i32* %196, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @pred16x16_top_dc_8_c(i8* nocapture, i64) #1 {
  %3 = sub nsw i64 0, %1
  %4 = getelementptr inbounds i8, i8* %0, i64 %3
  %5 = load i8, i8* %4, align 1
  %6 = zext i8 %5 to i32
  %7 = sub nsw i64 1, %1
  %8 = getelementptr inbounds i8, i8* %0, i64 %7
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = add nuw nsw i32 %6, %10
  %12 = sub nsw i64 2, %1
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = add nuw nsw i32 %11, %15
  %17 = sub nsw i64 3, %1
  %18 = getelementptr inbounds i8, i8* %0, i64 %17
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = add nuw nsw i32 %16, %20
  %22 = sub nsw i64 4, %1
  %23 = getelementptr inbounds i8, i8* %0, i64 %22
  %24 = load i8, i8* %23, align 1
  %25 = zext i8 %24 to i32
  %26 = add nuw nsw i32 %21, %25
  %27 = sub nsw i64 5, %1
  %28 = getelementptr inbounds i8, i8* %0, i64 %27
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i32
  %31 = add nuw nsw i32 %26, %30
  %32 = sub nsw i64 6, %1
  %33 = getelementptr inbounds i8, i8* %0, i64 %32
  %34 = load i8, i8* %33, align 1
  %35 = zext i8 %34 to i32
  %36 = add nuw nsw i32 %31, %35
  %37 = sub nsw i64 7, %1
  %38 = getelementptr inbounds i8, i8* %0, i64 %37
  %39 = load i8, i8* %38, align 1
  %40 = zext i8 %39 to i32
  %41 = add nuw nsw i32 %36, %40
  %42 = sub nsw i64 8, %1
  %43 = getelementptr inbounds i8, i8* %0, i64 %42
  %44 = load i8, i8* %43, align 1
  %45 = zext i8 %44 to i32
  %46 = add nuw nsw i32 %41, %45
  %47 = sub nsw i64 9, %1
  %48 = getelementptr inbounds i8, i8* %0, i64 %47
  %49 = load i8, i8* %48, align 1
  %50 = zext i8 %49 to i32
  %51 = add nuw nsw i32 %46, %50
  %52 = sub nsw i64 10, %1
  %53 = getelementptr inbounds i8, i8* %0, i64 %52
  %54 = load i8, i8* %53, align 1
  %55 = zext i8 %54 to i32
  %56 = add nuw nsw i32 %51, %55
  %57 = sub nsw i64 11, %1
  %58 = getelementptr inbounds i8, i8* %0, i64 %57
  %59 = load i8, i8* %58, align 1
  %60 = zext i8 %59 to i32
  %61 = add nuw nsw i32 %56, %60
  %62 = sub nsw i64 12, %1
  %63 = getelementptr inbounds i8, i8* %0, i64 %62
  %64 = load i8, i8* %63, align 1
  %65 = zext i8 %64 to i32
  %66 = add nuw nsw i32 %61, %65
  %67 = sub nsw i64 13, %1
  %68 = getelementptr inbounds i8, i8* %0, i64 %67
  %69 = load i8, i8* %68, align 1
  %70 = zext i8 %69 to i32
  %71 = add nuw nsw i32 %66, %70
  %72 = sub nsw i64 14, %1
  %73 = getelementptr inbounds i8, i8* %0, i64 %72
  %74 = load i8, i8* %73, align 1
  %75 = zext i8 %74 to i32
  %76 = add nuw nsw i32 %71, %75
  %77 = sub nsw i64 15, %1
  %78 = getelementptr inbounds i8, i8* %0, i64 %77
  %79 = load i8, i8* %78, align 1
  %80 = zext i8 %79 to i32
  %81 = add nuw nsw i32 %76, %80
  %82 = add nuw nsw i32 %81, 8
  %83 = lshr i32 %82, 4
  %84 = mul i32 %83, 16843009
  %85 = insertelement <4 x i32> undef, i32 %84, i32 0
  %86 = shufflevector <4 x i32> %85, <4 x i32> undef, <4 x i32> zeroinitializer
  %87 = bitcast i8* %0 to <4 x i32>*
  store <4 x i32> %86, <4 x i32>* %87, align 4
  %88 = getelementptr inbounds i8, i8* %0, i64 %1
  %89 = bitcast i8* %88 to <4 x i32>*
  store <4 x i32> %86, <4 x i32>* %89, align 4
  %90 = getelementptr inbounds i8, i8* %88, i64 %1
  %91 = bitcast i8* %90 to <4 x i32>*
  store <4 x i32> %86, <4 x i32>* %91, align 4
  %92 = getelementptr inbounds i8, i8* %90, i64 %1
  %93 = bitcast i8* %92 to <4 x i32>*
  store <4 x i32> %86, <4 x i32>* %93, align 4
  %94 = getelementptr inbounds i8, i8* %92, i64 %1
  %95 = bitcast i8* %94 to <4 x i32>*
  store <4 x i32> %86, <4 x i32>* %95, align 4
  %96 = getelementptr inbounds i8, i8* %94, i64 %1
  %97 = bitcast i8* %96 to i32*
  store i32 %84, i32* %97, align 4
  %98 = getelementptr inbounds i8, i8* %96, i64 4
  %99 = bitcast i8* %98 to i32*
  store i32 %84, i32* %99, align 4
  %100 = getelementptr inbounds i8, i8* %96, i64 8
  %101 = bitcast i8* %100 to i32*
  store i32 %84, i32* %101, align 4
  %102 = getelementptr inbounds i8, i8* %96, i64 12
  %103 = bitcast i8* %102 to i32*
  store i32 %84, i32* %103, align 4
  %104 = getelementptr inbounds i8, i8* %96, i64 %1
  %105 = bitcast i8* %104 to i32*
  store i32 %84, i32* %105, align 4
  %106 = getelementptr inbounds i8, i8* %104, i64 4
  %107 = bitcast i8* %106 to i32*
  store i32 %84, i32* %107, align 4
  %108 = getelementptr inbounds i8, i8* %104, i64 8
  %109 = bitcast i8* %108 to i32*
  store i32 %84, i32* %109, align 4
  %110 = getelementptr inbounds i8, i8* %104, i64 12
  %111 = bitcast i8* %110 to i32*
  store i32 %84, i32* %111, align 4
  %112 = getelementptr inbounds i8, i8* %104, i64 %1
  %113 = bitcast i8* %112 to i32*
  store i32 %84, i32* %113, align 4
  %114 = getelementptr inbounds i8, i8* %112, i64 4
  %115 = bitcast i8* %114 to i32*
  store i32 %84, i32* %115, align 4
  %116 = getelementptr inbounds i8, i8* %112, i64 8
  %117 = bitcast i8* %116 to i32*
  store i32 %84, i32* %117, align 4
  %118 = getelementptr inbounds i8, i8* %112, i64 12
  %119 = bitcast i8* %118 to i32*
  store i32 %84, i32* %119, align 4
  %120 = getelementptr inbounds i8, i8* %112, i64 %1
  %121 = bitcast i8* %120 to i32*
  store i32 %84, i32* %121, align 4
  %122 = getelementptr inbounds i8, i8* %120, i64 4
  %123 = bitcast i8* %122 to i32*
  store i32 %84, i32* %123, align 4
  %124 = getelementptr inbounds i8, i8* %120, i64 8
  %125 = bitcast i8* %124 to i32*
  store i32 %84, i32* %125, align 4
  %126 = getelementptr inbounds i8, i8* %120, i64 12
  %127 = bitcast i8* %126 to i32*
  store i32 %84, i32* %127, align 4
  %128 = getelementptr inbounds i8, i8* %120, i64 %1
  %129 = bitcast i8* %128 to i32*
  store i32 %84, i32* %129, align 4
  %130 = getelementptr inbounds i8, i8* %128, i64 4
  %131 = bitcast i8* %130 to i32*
  store i32 %84, i32* %131, align 4
  %132 = getelementptr inbounds i8, i8* %128, i64 8
  %133 = bitcast i8* %132 to i32*
  store i32 %84, i32* %133, align 4
  %134 = getelementptr inbounds i8, i8* %128, i64 12
  %135 = bitcast i8* %134 to i32*
  store i32 %84, i32* %135, align 4
  %136 = getelementptr inbounds i8, i8* %128, i64 %1
  %137 = bitcast i8* %136 to i32*
  store i32 %84, i32* %137, align 4
  %138 = getelementptr inbounds i8, i8* %136, i64 4
  %139 = bitcast i8* %138 to i32*
  store i32 %84, i32* %139, align 4
  %140 = getelementptr inbounds i8, i8* %136, i64 8
  %141 = bitcast i8* %140 to i32*
  store i32 %84, i32* %141, align 4
  %142 = getelementptr inbounds i8, i8* %136, i64 12
  %143 = bitcast i8* %142 to i32*
  store i32 %84, i32* %143, align 4
  %144 = getelementptr inbounds i8, i8* %136, i64 %1
  %145 = bitcast i8* %144 to i32*
  store i32 %84, i32* %145, align 4
  %146 = getelementptr inbounds i8, i8* %144, i64 4
  %147 = bitcast i8* %146 to i32*
  store i32 %84, i32* %147, align 4
  %148 = getelementptr inbounds i8, i8* %144, i64 8
  %149 = bitcast i8* %148 to i32*
  store i32 %84, i32* %149, align 4
  %150 = getelementptr inbounds i8, i8* %144, i64 12
  %151 = bitcast i8* %150 to i32*
  store i32 %84, i32* %151, align 4
  %152 = getelementptr inbounds i8, i8* %144, i64 %1
  %153 = bitcast i8* %152 to i32*
  store i32 %84, i32* %153, align 4
  %154 = getelementptr inbounds i8, i8* %152, i64 4
  %155 = bitcast i8* %154 to i32*
  store i32 %84, i32* %155, align 4
  %156 = getelementptr inbounds i8, i8* %152, i64 8
  %157 = bitcast i8* %156 to i32*
  store i32 %84, i32* %157, align 4
  %158 = getelementptr inbounds i8, i8* %152, i64 12
  %159 = bitcast i8* %158 to i32*
  store i32 %84, i32* %159, align 4
  %160 = getelementptr inbounds i8, i8* %152, i64 %1
  %161 = bitcast i8* %160 to i32*
  store i32 %84, i32* %161, align 4
  %162 = getelementptr inbounds i8, i8* %160, i64 4
  %163 = bitcast i8* %162 to i32*
  store i32 %84, i32* %163, align 4
  %164 = getelementptr inbounds i8, i8* %160, i64 8
  %165 = bitcast i8* %164 to i32*
  store i32 %84, i32* %165, align 4
  %166 = getelementptr inbounds i8, i8* %160, i64 12
  %167 = bitcast i8* %166 to i32*
  store i32 %84, i32* %167, align 4
  %168 = getelementptr inbounds i8, i8* %160, i64 %1
  %169 = bitcast i8* %168 to i32*
  store i32 %84, i32* %169, align 4
  %170 = getelementptr inbounds i8, i8* %168, i64 4
  %171 = bitcast i8* %170 to i32*
  store i32 %84, i32* %171, align 4
  %172 = getelementptr inbounds i8, i8* %168, i64 8
  %173 = bitcast i8* %172 to i32*
  store i32 %84, i32* %173, align 4
  %174 = getelementptr inbounds i8, i8* %168, i64 12
  %175 = bitcast i8* %174 to i32*
  store i32 %84, i32* %175, align 4
  %176 = getelementptr inbounds i8, i8* %168, i64 %1
  %177 = bitcast i8* %176 to i32*
  store i32 %84, i32* %177, align 4
  %178 = getelementptr inbounds i8, i8* %176, i64 4
  %179 = bitcast i8* %178 to i32*
  store i32 %84, i32* %179, align 4
  %180 = getelementptr inbounds i8, i8* %176, i64 8
  %181 = bitcast i8* %180 to i32*
  store i32 %84, i32* %181, align 4
  %182 = getelementptr inbounds i8, i8* %176, i64 12
  %183 = bitcast i8* %182 to i32*
  store i32 %84, i32* %183, align 4
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable writeonly
define internal void @pred16x16_128_dc_8_c(i8* nocapture, i64) #2 {
  %3 = getelementptr inbounds i8, i8* %0, i64 %1
  call void @llvm.memset.p0i8.i64(i8* align 4 %0, i8 -128, i64 16, i1 false)
  %4 = bitcast i8* %3 to <4 x i32>*
  store <4 x i32> <i32 -2139062144, i32 -2139062144, i32 -2139062144, i32 -2139062144>, <4 x i32>* %4, align 4
  %5 = getelementptr inbounds i8, i8* %3, i64 %1
  %6 = bitcast i8* %5 to <4 x i32>*
  store <4 x i32> <i32 -2139062144, i32 -2139062144, i32 -2139062144, i32 -2139062144>, <4 x i32>* %6, align 4
  %7 = getelementptr inbounds i8, i8* %5, i64 %1
  %8 = bitcast i8* %7 to <4 x i32>*
  store <4 x i32> <i32 -2139062144, i32 -2139062144, i32 -2139062144, i32 -2139062144>, <4 x i32>* %8, align 4
  %9 = getelementptr inbounds i8, i8* %7, i64 %1
  %10 = bitcast i8* %9 to <4 x i32>*
  store <4 x i32> <i32 -2139062144, i32 -2139062144, i32 -2139062144, i32 -2139062144>, <4 x i32>* %10, align 4
  %11 = getelementptr inbounds i8, i8* %9, i64 %1
  %12 = bitcast i8* %11 to i32*
  store i32 -2139062144, i32* %12, align 4
  %13 = getelementptr inbounds i8, i8* %11, i64 4
  %14 = bitcast i8* %13 to i32*
  store i32 -2139062144, i32* %14, align 4
  %15 = getelementptr inbounds i8, i8* %11, i64 8
  %16 = bitcast i8* %15 to i32*
  store i32 -2139062144, i32* %16, align 4
  %17 = getelementptr inbounds i8, i8* %11, i64 12
  %18 = bitcast i8* %17 to i32*
  store i32 -2139062144, i32* %18, align 4
  %19 = getelementptr inbounds i8, i8* %11, i64 %1
  %20 = bitcast i8* %19 to i32*
  store i32 -2139062144, i32* %20, align 4
  %21 = getelementptr inbounds i8, i8* %19, i64 4
  %22 = bitcast i8* %21 to i32*
  store i32 -2139062144, i32* %22, align 4
  %23 = getelementptr inbounds i8, i8* %19, i64 8
  %24 = bitcast i8* %23 to i32*
  store i32 -2139062144, i32* %24, align 4
  %25 = getelementptr inbounds i8, i8* %19, i64 12
  %26 = bitcast i8* %25 to i32*
  store i32 -2139062144, i32* %26, align 4
  %27 = getelementptr inbounds i8, i8* %19, i64 %1
  %28 = bitcast i8* %27 to i32*
  store i32 -2139062144, i32* %28, align 4
  %29 = getelementptr inbounds i8, i8* %27, i64 4
  %30 = bitcast i8* %29 to i32*
  store i32 -2139062144, i32* %30, align 4
  %31 = getelementptr inbounds i8, i8* %27, i64 8
  %32 = bitcast i8* %31 to i32*
  store i32 -2139062144, i32* %32, align 4
  %33 = getelementptr inbounds i8, i8* %27, i64 12
  %34 = bitcast i8* %33 to i32*
  store i32 -2139062144, i32* %34, align 4
  %35 = getelementptr inbounds i8, i8* %27, i64 %1
  %36 = bitcast i8* %35 to i32*
  store i32 -2139062144, i32* %36, align 4
  %37 = getelementptr inbounds i8, i8* %35, i64 4
  %38 = bitcast i8* %37 to i32*
  store i32 -2139062144, i32* %38, align 4
  %39 = getelementptr inbounds i8, i8* %35, i64 8
  %40 = bitcast i8* %39 to i32*
  store i32 -2139062144, i32* %40, align 4
  %41 = getelementptr inbounds i8, i8* %35, i64 12
  %42 = bitcast i8* %41 to i32*
  store i32 -2139062144, i32* %42, align 4
  %43 = getelementptr inbounds i8, i8* %35, i64 %1
  %44 = bitcast i8* %43 to i32*
  store i32 -2139062144, i32* %44, align 4
  %45 = getelementptr inbounds i8, i8* %43, i64 4
  %46 = bitcast i8* %45 to i32*
  store i32 -2139062144, i32* %46, align 4
  %47 = getelementptr inbounds i8, i8* %43, i64 8
  %48 = bitcast i8* %47 to i32*
  store i32 -2139062144, i32* %48, align 4
  %49 = getelementptr inbounds i8, i8* %43, i64 12
  %50 = bitcast i8* %49 to i32*
  store i32 -2139062144, i32* %50, align 4
  %51 = getelementptr inbounds i8, i8* %43, i64 %1
  %52 = bitcast i8* %51 to i32*
  store i32 -2139062144, i32* %52, align 4
  %53 = getelementptr inbounds i8, i8* %51, i64 4
  %54 = bitcast i8* %53 to i32*
  store i32 -2139062144, i32* %54, align 4
  %55 = getelementptr inbounds i8, i8* %51, i64 8
  %56 = bitcast i8* %55 to i32*
  store i32 -2139062144, i32* %56, align 4
  %57 = getelementptr inbounds i8, i8* %51, i64 12
  %58 = bitcast i8* %57 to i32*
  store i32 -2139062144, i32* %58, align 4
  %59 = getelementptr inbounds i8, i8* %51, i64 %1
  %60 = bitcast i8* %59 to i32*
  store i32 -2139062144, i32* %60, align 4
  %61 = getelementptr inbounds i8, i8* %59, i64 4
  %62 = bitcast i8* %61 to i32*
  store i32 -2139062144, i32* %62, align 4
  %63 = getelementptr inbounds i8, i8* %59, i64 8
  %64 = bitcast i8* %63 to i32*
  store i32 -2139062144, i32* %64, align 4
  %65 = getelementptr inbounds i8, i8* %59, i64 12
  %66 = bitcast i8* %65 to i32*
  store i32 -2139062144, i32* %66, align 4
  %67 = getelementptr inbounds i8, i8* %59, i64 %1
  %68 = bitcast i8* %67 to i32*
  store i32 -2139062144, i32* %68, align 4
  %69 = getelementptr inbounds i8, i8* %67, i64 4
  %70 = bitcast i8* %69 to i32*
  store i32 -2139062144, i32* %70, align 4
  %71 = getelementptr inbounds i8, i8* %67, i64 8
  %72 = bitcast i8* %71 to i32*
  store i32 -2139062144, i32* %72, align 4
  %73 = getelementptr inbounds i8, i8* %67, i64 12
  %74 = bitcast i8* %73 to i32*
  store i32 -2139062144, i32* %74, align 4
  %75 = getelementptr inbounds i8, i8* %67, i64 %1
  %76 = bitcast i8* %75 to i32*
  store i32 -2139062144, i32* %76, align 4
  %77 = getelementptr inbounds i8, i8* %75, i64 4
  %78 = bitcast i8* %77 to i32*
  store i32 -2139062144, i32* %78, align 4
  %79 = getelementptr inbounds i8, i8* %75, i64 8
  %80 = bitcast i8* %79 to i32*
  store i32 -2139062144, i32* %80, align 4
  %81 = getelementptr inbounds i8, i8* %75, i64 12
  %82 = bitcast i8* %81 to i32*
  store i32 -2139062144, i32* %82, align 4
  %83 = getelementptr inbounds i8, i8* %75, i64 %1
  %84 = bitcast i8* %83 to i32*
  store i32 -2139062144, i32* %84, align 4
  %85 = getelementptr inbounds i8, i8* %83, i64 4
  %86 = bitcast i8* %85 to i32*
  store i32 -2139062144, i32* %86, align 4
  %87 = getelementptr inbounds i8, i8* %83, i64 8
  %88 = bitcast i8* %87 to i32*
  store i32 -2139062144, i32* %88, align 4
  %89 = getelementptr inbounds i8, i8* %83, i64 12
  %90 = bitcast i8* %89 to i32*
  store i32 -2139062144, i32* %90, align 4
  %91 = getelementptr inbounds i8, i8* %83, i64 %1
  %92 = bitcast i8* %91 to i32*
  store i32 -2139062144, i32* %92, align 4
  %93 = getelementptr inbounds i8, i8* %91, i64 4
  %94 = bitcast i8* %93 to i32*
  store i32 -2139062144, i32* %94, align 4
  %95 = getelementptr inbounds i8, i8* %91, i64 8
  %96 = bitcast i8* %95 to i32*
  store i32 -2139062144, i32* %96, align 4
  %97 = getelementptr inbounds i8, i8* %91, i64 12
  %98 = bitcast i8* %97 to i32*
  store i32 -2139062144, i32* %98, align 4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred4x4_vertical_add_8_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = sub i64 0, %2
  %5 = getelementptr inbounds i8, i8* %0, i64 %4
  %6 = shl nsw i64 %2, 1
  %7 = mul nsw i64 %2, 3
  %8 = shl nsw i64 %2, 2
  %9 = load i8, i8* %5, align 1
  %10 = load i16, i16* %1, align 2
  %11 = trunc i16 %10 to i8
  %12 = add i8 %9, %11
  store i8 %12, i8* %0, align 1
  %13 = getelementptr inbounds i16, i16* %1, i64 4
  %14 = load i16, i16* %13, align 2
  %15 = trunc i16 %14 to i8
  %16 = add i8 %12, %15
  %17 = getelementptr inbounds i8, i8* %5, i64 %6
  store i8 %16, i8* %17, align 1
  %18 = getelementptr inbounds i16, i16* %1, i64 8
  %19 = load i16, i16* %18, align 2
  %20 = trunc i16 %19 to i8
  %21 = add i8 %16, %20
  %22 = getelementptr inbounds i8, i8* %5, i64 %7
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds i16, i16* %1, i64 12
  %24 = load i16, i16* %23, align 2
  %25 = trunc i16 %24 to i8
  %26 = add i8 %21, %25
  %27 = getelementptr inbounds i8, i8* %5, i64 %8
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds i8, i8* %5, i64 1
  %29 = getelementptr inbounds i16, i16* %1, i64 1
  %30 = load i8, i8* %28, align 1
  %31 = load i16, i16* %29, align 2
  %32 = trunc i16 %31 to i8
  %33 = add i8 %30, %32
  %34 = getelementptr inbounds i8, i8* %28, i64 %2
  store i8 %33, i8* %34, align 1
  %35 = getelementptr inbounds i16, i16* %1, i64 5
  %36 = load i16, i16* %35, align 2
  %37 = trunc i16 %36 to i8
  %38 = add i8 %33, %37
  %39 = getelementptr inbounds i8, i8* %28, i64 %6
  store i8 %38, i8* %39, align 1
  %40 = getelementptr inbounds i16, i16* %1, i64 9
  %41 = load i16, i16* %40, align 2
  %42 = trunc i16 %41 to i8
  %43 = add i8 %38, %42
  %44 = getelementptr inbounds i8, i8* %28, i64 %7
  store i8 %43, i8* %44, align 1
  %45 = getelementptr inbounds i16, i16* %1, i64 13
  %46 = load i16, i16* %45, align 2
  %47 = trunc i16 %46 to i8
  %48 = add i8 %43, %47
  %49 = getelementptr inbounds i8, i8* %28, i64 %8
  store i8 %48, i8* %49, align 1
  %50 = getelementptr inbounds i8, i8* %28, i64 1
  %51 = getelementptr inbounds i16, i16* %1, i64 2
  %52 = load i8, i8* %50, align 1
  %53 = load i16, i16* %51, align 2
  %54 = trunc i16 %53 to i8
  %55 = add i8 %52, %54
  %56 = getelementptr inbounds i8, i8* %50, i64 %2
  store i8 %55, i8* %56, align 1
  %57 = getelementptr inbounds i16, i16* %1, i64 6
  %58 = load i16, i16* %57, align 2
  %59 = trunc i16 %58 to i8
  %60 = add i8 %55, %59
  %61 = getelementptr inbounds i8, i8* %50, i64 %6
  store i8 %60, i8* %61, align 1
  %62 = getelementptr inbounds i16, i16* %1, i64 10
  %63 = load i16, i16* %62, align 2
  %64 = trunc i16 %63 to i8
  %65 = add i8 %60, %64
  %66 = getelementptr inbounds i8, i8* %50, i64 %7
  store i8 %65, i8* %66, align 1
  %67 = getelementptr inbounds i16, i16* %1, i64 14
  %68 = load i16, i16* %67, align 2
  %69 = trunc i16 %68 to i8
  %70 = add i8 %65, %69
  %71 = getelementptr inbounds i8, i8* %50, i64 %8
  store i8 %70, i8* %71, align 1
  %72 = getelementptr inbounds i8, i8* %50, i64 1
  %73 = getelementptr inbounds i16, i16* %1, i64 3
  %74 = load i8, i8* %72, align 1
  %75 = load i16, i16* %73, align 2
  %76 = trunc i16 %75 to i8
  %77 = add i8 %74, %76
  %78 = getelementptr inbounds i8, i8* %72, i64 %2
  store i8 %77, i8* %78, align 1
  %79 = getelementptr inbounds i16, i16* %1, i64 7
  %80 = load i16, i16* %79, align 2
  %81 = trunc i16 %80 to i8
  %82 = add i8 %77, %81
  %83 = getelementptr inbounds i8, i8* %72, i64 %6
  store i8 %82, i8* %83, align 1
  %84 = getelementptr inbounds i16, i16* %1, i64 11
  %85 = load i16, i16* %84, align 2
  %86 = trunc i16 %85 to i8
  %87 = add i8 %82, %86
  %88 = getelementptr inbounds i8, i8* %72, i64 %7
  store i8 %87, i8* %88, align 1
  %89 = getelementptr inbounds i16, i16* %1, i64 15
  %90 = load i16, i16* %89, align 2
  %91 = trunc i16 %90 to i8
  %92 = add i8 %87, %91
  %93 = getelementptr inbounds i8, i8* %72, i64 %8
  store i8 %92, i8* %93, align 1
  %94 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %94, i8 0, i64 32, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred4x4_horizontal_add_8_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = getelementptr inbounds i8, i8* %0, i64 -1
  %5 = load i8, i8* %4, align 1
  %6 = load i16, i16* %1, align 2
  %7 = trunc i16 %6 to i8
  %8 = add i8 %5, %7
  store i8 %8, i8* %0, align 1
  %9 = getelementptr inbounds i16, i16* %1, i64 1
  %10 = load i16, i16* %9, align 2
  %11 = trunc i16 %10 to i8
  %12 = add i8 %8, %11
  %13 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %12, i8* %13, align 1
  %14 = getelementptr inbounds i16, i16* %1, i64 2
  %15 = load i16, i16* %14, align 2
  %16 = trunc i16 %15 to i8
  %17 = add i8 %12, %16
  %18 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %17, i8* %18, align 1
  %19 = getelementptr inbounds i16, i16* %1, i64 3
  %20 = load i16, i16* %19, align 2
  %21 = trunc i16 %20 to i8
  %22 = add i8 %17, %21
  %23 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %22, i8* %23, align 1
  %24 = getelementptr inbounds i8, i8* %0, i64 %2
  %25 = getelementptr inbounds i16, i16* %1, i64 4
  %26 = getelementptr inbounds i8, i8* %24, i64 -1
  %27 = load i8, i8* %26, align 1
  %28 = load i16, i16* %25, align 2
  %29 = trunc i16 %28 to i8
  %30 = add i8 %27, %29
  store i8 %30, i8* %24, align 1
  %31 = getelementptr inbounds i16, i16* %1, i64 5
  %32 = load i16, i16* %31, align 2
  %33 = trunc i16 %32 to i8
  %34 = add i8 %30, %33
  %35 = getelementptr inbounds i8, i8* %24, i64 1
  store i8 %34, i8* %35, align 1
  %36 = getelementptr inbounds i16, i16* %1, i64 6
  %37 = load i16, i16* %36, align 2
  %38 = trunc i16 %37 to i8
  %39 = add i8 %34, %38
  %40 = getelementptr inbounds i8, i8* %24, i64 2
  store i8 %39, i8* %40, align 1
  %41 = getelementptr inbounds i16, i16* %1, i64 7
  %42 = load i16, i16* %41, align 2
  %43 = trunc i16 %42 to i8
  %44 = add i8 %39, %43
  %45 = getelementptr inbounds i8, i8* %24, i64 3
  store i8 %44, i8* %45, align 1
  %46 = getelementptr inbounds i8, i8* %24, i64 %2
  %47 = getelementptr inbounds i16, i16* %1, i64 8
  %48 = getelementptr inbounds i8, i8* %46, i64 -1
  %49 = load i8, i8* %48, align 1
  %50 = load i16, i16* %47, align 2
  %51 = trunc i16 %50 to i8
  %52 = add i8 %49, %51
  store i8 %52, i8* %46, align 1
  %53 = getelementptr inbounds i16, i16* %1, i64 9
  %54 = load i16, i16* %53, align 2
  %55 = trunc i16 %54 to i8
  %56 = add i8 %52, %55
  %57 = getelementptr inbounds i8, i8* %46, i64 1
  store i8 %56, i8* %57, align 1
  %58 = getelementptr inbounds i16, i16* %1, i64 10
  %59 = load i16, i16* %58, align 2
  %60 = trunc i16 %59 to i8
  %61 = add i8 %56, %60
  %62 = getelementptr inbounds i8, i8* %46, i64 2
  store i8 %61, i8* %62, align 1
  %63 = getelementptr inbounds i16, i16* %1, i64 11
  %64 = load i16, i16* %63, align 2
  %65 = trunc i16 %64 to i8
  %66 = add i8 %61, %65
  %67 = getelementptr inbounds i8, i8* %46, i64 3
  store i8 %66, i8* %67, align 1
  %68 = getelementptr inbounds i8, i8* %46, i64 %2
  %69 = getelementptr inbounds i16, i16* %1, i64 12
  %70 = getelementptr inbounds i8, i8* %68, i64 -1
  %71 = load i8, i8* %70, align 1
  %72 = load i16, i16* %69, align 2
  %73 = trunc i16 %72 to i8
  %74 = add i8 %71, %73
  store i8 %74, i8* %68, align 1
  %75 = getelementptr inbounds i16, i16* %1, i64 13
  %76 = load i16, i16* %75, align 2
  %77 = trunc i16 %76 to i8
  %78 = add i8 %74, %77
  %79 = getelementptr inbounds i8, i8* %68, i64 1
  store i8 %78, i8* %79, align 1
  %80 = getelementptr inbounds i16, i16* %1, i64 14
  %81 = load i16, i16* %80, align 2
  %82 = trunc i16 %81 to i8
  %83 = add i8 %78, %82
  %84 = getelementptr inbounds i8, i8* %68, i64 2
  store i8 %83, i8* %84, align 1
  %85 = getelementptr inbounds i16, i16* %1, i64 15
  %86 = load i16, i16* %85, align 2
  %87 = trunc i16 %86 to i8
  %88 = add i8 %83, %87
  %89 = getelementptr inbounds i8, i8* %68, i64 3
  store i8 %88, i8* %89, align 1
  %90 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %90, i8 0, i64 32, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_vertical_add_8_c(i8* nocapture, i16* nocapture, i64) #3 {
  %4 = sub i64 0, %2
  %5 = getelementptr inbounds i8, i8* %0, i64 %4
  %6 = shl nsw i64 %2, 1
  %7 = mul nsw i64 %2, 3
  %8 = shl nsw i64 %2, 2
  %9 = mul nsw i64 %2, 5
  %10 = mul nsw i64 %2, 6
  %11 = mul nsw i64 %2, 7
  %12 = shl nsw i64 %2, 3
  br label %13

13:                                               ; preds = %13, %3
  %14 = phi i16* [ %1, %3 ], [ %58, %13 ]
  %15 = phi i8* [ %5, %3 ], [ %57, %13 ]
  %16 = phi i32 [ 0, %3 ], [ %59, %13 ]
  %17 = load i8, i8* %15, align 1
  %18 = load i16, i16* %14, align 2
  %19 = trunc i16 %18 to i8
  %20 = add i8 %17, %19
  %21 = getelementptr inbounds i8, i8* %15, i64 %2
  store i8 %20, i8* %21, align 1
  %22 = getelementptr inbounds i16, i16* %14, i64 8
  %23 = load i16, i16* %22, align 2
  %24 = trunc i16 %23 to i8
  %25 = add i8 %20, %24
  %26 = getelementptr inbounds i8, i8* %15, i64 %6
  store i8 %25, i8* %26, align 1
  %27 = getelementptr inbounds i16, i16* %14, i64 16
  %28 = load i16, i16* %27, align 2
  %29 = trunc i16 %28 to i8
  %30 = add i8 %25, %29
  %31 = getelementptr inbounds i8, i8* %15, i64 %7
  store i8 %30, i8* %31, align 1
  %32 = getelementptr inbounds i16, i16* %14, i64 24
  %33 = load i16, i16* %32, align 2
  %34 = trunc i16 %33 to i8
  %35 = add i8 %30, %34
  %36 = getelementptr inbounds i8, i8* %15, i64 %8
  store i8 %35, i8* %36, align 1
  %37 = getelementptr inbounds i16, i16* %14, i64 32
  %38 = load i16, i16* %37, align 2
  %39 = trunc i16 %38 to i8
  %40 = add i8 %35, %39
  %41 = getelementptr inbounds i8, i8* %15, i64 %9
  store i8 %40, i8* %41, align 1
  %42 = getelementptr inbounds i16, i16* %14, i64 40
  %43 = load i16, i16* %42, align 2
  %44 = trunc i16 %43 to i8
  %45 = add i8 %40, %44
  %46 = getelementptr inbounds i8, i8* %15, i64 %10
  store i8 %45, i8* %46, align 1
  %47 = getelementptr inbounds i16, i16* %14, i64 48
  %48 = load i16, i16* %47, align 2
  %49 = trunc i16 %48 to i8
  %50 = add i8 %45, %49
  %51 = getelementptr inbounds i8, i8* %15, i64 %11
  store i8 %50, i8* %51, align 1
  %52 = getelementptr inbounds i16, i16* %14, i64 56
  %53 = load i16, i16* %52, align 2
  %54 = trunc i16 %53 to i8
  %55 = add i8 %50, %54
  %56 = getelementptr inbounds i8, i8* %15, i64 %12
  store i8 %55, i8* %56, align 1
  %57 = getelementptr inbounds i8, i8* %15, i64 1
  %58 = getelementptr inbounds i16, i16* %14, i64 1
  %59 = add nuw nsw i32 %16, 1
  %60 = icmp eq i32 %59, 8
  br i1 %60, label %61, label %13

61:                                               ; preds = %13
  %62 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %62, i8 0, i64 128, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_horizontal_add_8_c(i8* nocapture, i16* nocapture, i64) #3 {
  br label %4

4:                                                ; preds = %4, %3
  %5 = phi i16* [ %1, %3 ], [ %49, %4 ]
  %6 = phi i8* [ %0, %3 ], [ %48, %4 ]
  %7 = phi i32 [ 0, %3 ], [ %50, %4 ]
  %8 = getelementptr inbounds i8, i8* %6, i64 -1
  %9 = load i8, i8* %8, align 1
  %10 = load i16, i16* %5, align 2
  %11 = trunc i16 %10 to i8
  %12 = add i8 %9, %11
  store i8 %12, i8* %6, align 1
  %13 = getelementptr inbounds i16, i16* %5, i64 1
  %14 = load i16, i16* %13, align 2
  %15 = trunc i16 %14 to i8
  %16 = add i8 %12, %15
  %17 = getelementptr inbounds i8, i8* %6, i64 1
  store i8 %16, i8* %17, align 1
  %18 = getelementptr inbounds i16, i16* %5, i64 2
  %19 = load i16, i16* %18, align 2
  %20 = trunc i16 %19 to i8
  %21 = add i8 %16, %20
  %22 = getelementptr inbounds i8, i8* %6, i64 2
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds i16, i16* %5, i64 3
  %24 = load i16, i16* %23, align 2
  %25 = trunc i16 %24 to i8
  %26 = add i8 %21, %25
  %27 = getelementptr inbounds i8, i8* %6, i64 3
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds i16, i16* %5, i64 4
  %29 = load i16, i16* %28, align 2
  %30 = trunc i16 %29 to i8
  %31 = add i8 %26, %30
  %32 = getelementptr inbounds i8, i8* %6, i64 4
  store i8 %31, i8* %32, align 1
  %33 = getelementptr inbounds i16, i16* %5, i64 5
  %34 = load i16, i16* %33, align 2
  %35 = trunc i16 %34 to i8
  %36 = add i8 %31, %35
  %37 = getelementptr inbounds i8, i8* %6, i64 5
  store i8 %36, i8* %37, align 1
  %38 = getelementptr inbounds i16, i16* %5, i64 6
  %39 = load i16, i16* %38, align 2
  %40 = trunc i16 %39 to i8
  %41 = add i8 %36, %40
  %42 = getelementptr inbounds i8, i8* %6, i64 6
  store i8 %41, i8* %42, align 1
  %43 = getelementptr inbounds i16, i16* %5, i64 7
  %44 = load i16, i16* %43, align 2
  %45 = trunc i16 %44 to i8
  %46 = add i8 %41, %45
  %47 = getelementptr inbounds i8, i8* %6, i64 7
  store i8 %46, i8* %47, align 1
  %48 = getelementptr inbounds i8, i8* %6, i64 %2
  %49 = getelementptr inbounds i16, i16* %5, i64 8
  %50 = add nuw nsw i32 %7, 1
  %51 = icmp eq i32 %50, 8
  br i1 %51, label %52, label %4

52:                                               ; preds = %4
  %53 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %53, i8 0, i64 128, i1 false)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_vertical_filter_add_8_c(i8* nocapture, i16* nocapture, i32, i32, i64) #3 {
  %6 = alloca i64, align 8
  %7 = bitcast i64* %6 to [8 x i8]*
  %8 = bitcast i64* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %8) #8
  %9 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 1
  %10 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 2
  %11 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 3
  %12 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 4
  %13 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 5
  %14 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 6
  %15 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 7
  %16 = trunc i64 %4 to i32
  %17 = icmp eq i32 %2, 0
  %18 = sub nsw i32 0, %16
  store i64 -6148914691236517206, i64* %6, align 8
  br i1 %17, label %24, label %19

19:                                               ; preds = %5
  %20 = shl i64 %4, 32
  %21 = ashr exact i64 %20, 32
  %22 = xor i64 %21, -1
  %23 = sext i32 %18 to i64
  br label %27

24:                                               ; preds = %5
  %25 = sext i32 %18 to i64
  %26 = shl i64 %4, 32
  br label %27

27:                                               ; preds = %24, %19
  %28 = phi i64 [ %26, %24 ], [ %20, %19 ]
  %29 = phi i64 [ %25, %24 ], [ %23, %19 ]
  %30 = phi i64 [ %25, %24 ], [ %22, %19 ]
  %31 = getelementptr inbounds i8, i8* %0, i64 %30
  %32 = load i8, i8* %31, align 1
  %33 = zext i8 %32 to i32
  %34 = getelementptr inbounds i8, i8* %0, i64 %29
  %35 = load i8, i8* %34, align 1
  %36 = zext i8 %35 to i32
  %37 = shl nuw nsw i32 %36, 1
  %38 = sub i64 4294967296, %28
  %39 = ashr exact i64 %38, 32
  %40 = getelementptr inbounds i8, i8* %0, i64 %39
  %41 = load i8, i8* %40, align 1
  %42 = zext i8 %41 to i32
  %43 = add nuw nsw i32 %42, 2
  %44 = add nuw nsw i32 %43, %33
  %45 = add nuw nsw i32 %44, %37
  %46 = lshr i32 %45, 2
  %47 = shl nuw nsw i32 %42, 1
  %48 = sub i64 8589934592, %28
  %49 = ashr exact i64 %48, 32
  %50 = getelementptr inbounds i8, i8* %0, i64 %49
  %51 = load i8, i8* %50, align 1
  %52 = zext i8 %51 to i32
  %53 = add nuw nsw i32 %52, 2
  %54 = add nuw nsw i32 %53, %36
  %55 = add nuw nsw i32 %54, %47
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %52, 1
  %58 = sub i64 12884901888, %28
  %59 = ashr exact i64 %58, 32
  %60 = getelementptr inbounds i8, i8* %0, i64 %59
  %61 = load i8, i8* %60, align 1
  %62 = zext i8 %61 to i32
  %63 = add nuw nsw i32 %43, %57
  %64 = add nuw nsw i32 %63, %62
  %65 = lshr i32 %64, 2
  %66 = shl nuw nsw i32 %62, 1
  %67 = sub i64 17179869184, %28
  %68 = ashr exact i64 %67, 32
  %69 = getelementptr inbounds i8, i8* %0, i64 %68
  %70 = load i8, i8* %69, align 1
  %71 = zext i8 %70 to i32
  %72 = add nuw nsw i32 %53, %66
  %73 = add nuw nsw i32 %72, %71
  %74 = lshr i32 %73, 2
  %75 = shl nuw nsw i32 %71, 1
  %76 = sub i64 21474836480, %28
  %77 = ashr exact i64 %76, 32
  %78 = getelementptr inbounds i8, i8* %0, i64 %77
  %79 = load i8, i8* %78, align 1
  %80 = zext i8 %79 to i32
  %81 = add nuw nsw i32 %62, 2
  %82 = add nuw nsw i32 %81, %75
  %83 = add nuw nsw i32 %82, %80
  %84 = lshr i32 %83, 2
  %85 = shl nuw nsw i32 %80, 1
  %86 = sub i64 25769803776, %28
  %87 = ashr exact i64 %86, 32
  %88 = getelementptr inbounds i8, i8* %0, i64 %87
  %89 = load i8, i8* %88, align 1
  %90 = zext i8 %89 to i32
  %91 = add nuw nsw i32 %71, 2
  %92 = add nuw nsw i32 %91, %85
  %93 = add nuw nsw i32 %92, %90
  %94 = lshr i32 %93, 2
  %95 = shl nuw nsw i32 %90, 1
  %96 = sub i64 30064771072, %28
  %97 = ashr exact i64 %96, 32
  %98 = getelementptr inbounds i8, i8* %0, i64 %97
  %99 = load i8, i8* %98, align 1
  %100 = zext i8 %99 to i32
  %101 = add nuw nsw i32 %80, 2
  %102 = add nuw nsw i32 %101, %95
  %103 = add nuw nsw i32 %102, %100
  %104 = lshr i32 %103, 2
  %105 = icmp eq i32 %3, 0
  br i1 %105, label %112, label %106

106:                                              ; preds = %27
  %107 = sub i64 34359738368, %28
  %108 = ashr exact i64 %107, 32
  %109 = getelementptr inbounds i8, i8* %0, i64 %108
  %110 = load i8, i8* %109, align 1
  %111 = zext i8 %110 to i32
  br label %112

112:                                              ; preds = %27, %106
  %113 = phi i32 [ %111, %106 ], [ %100, %27 ]
  %114 = shl nuw nsw i32 %100, 1
  %115 = add nuw nsw i32 %90, 2
  %116 = add nuw nsw i32 %115, %114
  %117 = add nuw nsw i32 %116, %113
  %118 = lshr i32 %117, 2
  %119 = trunc i32 %46 to i8
  store i8 %119, i8* %8, align 8
  %120 = trunc i32 %56 to i8
  store i8 %120, i8* %9, align 1
  %121 = trunc i32 %65 to i8
  store i8 %121, i8* %10, align 2
  %122 = trunc i32 %74 to i8
  store i8 %122, i8* %11, align 1
  %123 = trunc i32 %84 to i8
  store i8 %123, i8* %12, align 4
  %124 = trunc i32 %94 to i8
  store i8 %124, i8* %13, align 1
  %125 = trunc i32 %104 to i8
  store i8 %125, i8* %14, align 2
  %126 = trunc i32 %118 to i8
  store i8 %126, i8* %15, align 1
  %127 = ashr exact i64 %28, 32
  %128 = shl nsw i32 %16, 1
  %129 = sext i32 %128 to i64
  %130 = mul i64 %4, 12884901888
  %131 = ashr exact i64 %130, 32
  %132 = shl nsw i32 %16, 2
  %133 = sext i32 %132 to i64
  %134 = mul i64 %4, 21474836480
  %135 = ashr exact i64 %134, 32
  %136 = mul i64 %4, 25769803776
  %137 = ashr exact i64 %136, 32
  %138 = mul i64 %4, 30064771072
  %139 = ashr exact i64 %138, 32
  br label %140

140:                                              ; preds = %185, %112
  %141 = phi i8 [ %119, %112 ], [ %189, %185 ]
  %142 = phi i64 [ 0, %112 ], [ %183, %185 ]
  %143 = phi i16* [ %1, %112 ], [ %186, %185 ]
  %144 = phi i8* [ %0, %112 ], [ %187, %185 ]
  %145 = load i16, i16* %143, align 2
  %146 = trunc i16 %145 to i8
  %147 = add i8 %141, %146
  store i8 %147, i8* %144, align 1
  %148 = getelementptr inbounds i16, i16* %143, i64 8
  %149 = load i16, i16* %148, align 2
  %150 = trunc i16 %149 to i8
  %151 = add i8 %147, %150
  %152 = getelementptr inbounds i8, i8* %144, i64 %127
  store i8 %151, i8* %152, align 1
  %153 = getelementptr inbounds i16, i16* %143, i64 16
  %154 = load i16, i16* %153, align 2
  %155 = trunc i16 %154 to i8
  %156 = add i8 %151, %155
  %157 = getelementptr inbounds i8, i8* %144, i64 %129
  store i8 %156, i8* %157, align 1
  %158 = getelementptr inbounds i16, i16* %143, i64 24
  %159 = load i16, i16* %158, align 2
  %160 = trunc i16 %159 to i8
  %161 = add i8 %156, %160
  %162 = getelementptr inbounds i8, i8* %144, i64 %131
  store i8 %161, i8* %162, align 1
  %163 = getelementptr inbounds i16, i16* %143, i64 32
  %164 = load i16, i16* %163, align 2
  %165 = trunc i16 %164 to i8
  %166 = add i8 %161, %165
  %167 = getelementptr inbounds i8, i8* %144, i64 %133
  store i8 %166, i8* %167, align 1
  %168 = getelementptr inbounds i16, i16* %143, i64 40
  %169 = load i16, i16* %168, align 2
  %170 = trunc i16 %169 to i8
  %171 = add i8 %166, %170
  %172 = getelementptr inbounds i8, i8* %144, i64 %135
  store i8 %171, i8* %172, align 1
  %173 = getelementptr inbounds i16, i16* %143, i64 48
  %174 = load i16, i16* %173, align 2
  %175 = trunc i16 %174 to i8
  %176 = add i8 %171, %175
  %177 = getelementptr inbounds i8, i8* %144, i64 %137
  store i8 %176, i8* %177, align 1
  %178 = getelementptr inbounds i16, i16* %143, i64 56
  %179 = load i16, i16* %178, align 2
  %180 = trunc i16 %179 to i8
  %181 = add i8 %176, %180
  %182 = getelementptr inbounds i8, i8* %144, i64 %139
  store i8 %181, i8* %182, align 1
  %183 = add nuw nsw i64 %142, 1
  %184 = icmp eq i64 %183, 8
  br i1 %184, label %190, label %185

185:                                              ; preds = %140
  %186 = getelementptr inbounds i16, i16* %143, i64 1
  %187 = getelementptr inbounds i8, i8* %144, i64 1
  %188 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 %183
  %189 = load i8, i8* %188, align 1
  br label %140

190:                                              ; preds = %140
  %191 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %191, i8 0, i64 128, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %8) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8l_horizontal_filter_add_8_c(i8* nocapture, i16* nocapture, i32, i32, i64) #3 {
  %6 = alloca i64, align 8
  %7 = bitcast i64* %6 to [8 x i8]*
  %8 = bitcast i64* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %8) #8
  %9 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 1
  %10 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 2
  %11 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 3
  %12 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 4
  %13 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 5
  %14 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 6
  %15 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 7
  %16 = trunc i64 %4 to i32
  %17 = icmp eq i32 %2, 0
  store i64 -6148914691236517206, i64* %6, align 8
  br i1 %17, label %23, label %18

18:                                               ; preds = %5
  %19 = shl i64 %4, 32
  %20 = ashr exact i64 %19, 32
  %21 = xor i64 %20, -1
  %22 = getelementptr inbounds i8, i8* %0, i64 %21
  br label %27

23:                                               ; preds = %5
  %24 = getelementptr inbounds i8, i8* %0, i64 -1
  %25 = shl i64 %4, 32
  %26 = ashr exact i64 %25, 32
  br label %27

27:                                               ; preds = %23, %18
  %28 = phi i64 [ %26, %23 ], [ %20, %18 ]
  %29 = phi i64 [ %25, %23 ], [ %19, %18 ]
  %30 = phi i8* [ %24, %23 ], [ %22, %18 ]
  %31 = load i8, i8* %30, align 1
  %32 = zext i8 %31 to i32
  %33 = getelementptr inbounds i8, i8* %0, i64 -1
  %34 = load i8, i8* %33, align 1
  %35 = zext i8 %34 to i32
  %36 = shl nuw nsw i32 %35, 1
  %37 = add i64 %29, -4294967296
  %38 = ashr exact i64 %37, 32
  %39 = getelementptr inbounds i8, i8* %0, i64 %38
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i32
  %42 = add nuw nsw i32 %41, 2
  %43 = add nuw nsw i32 %42, %32
  %44 = add nuw nsw i32 %43, %36
  %45 = lshr i32 %44, 2
  %46 = shl nuw nsw i32 %41, 1
  %47 = shl i32 %16, 1
  %48 = add nsw i32 %47, -1
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds i8, i8* %0, i64 %49
  %51 = load i8, i8* %50, align 1
  %52 = zext i8 %51 to i32
  %53 = add nuw nsw i32 %52, 2
  %54 = add nuw nsw i32 %53, %35
  %55 = add nuw nsw i32 %54, %46
  %56 = lshr i32 %55, 2
  %57 = shl nuw nsw i32 %52, 1
  %58 = mul i64 %4, 12884901888
  %59 = add i64 %58, -4294967296
  %60 = ashr exact i64 %59, 32
  %61 = getelementptr inbounds i8, i8* %0, i64 %60
  %62 = load i8, i8* %61, align 1
  %63 = zext i8 %62 to i32
  %64 = add nuw nsw i32 %42, %57
  %65 = add nuw nsw i32 %64, %63
  %66 = lshr i32 %65, 2
  %67 = shl nuw nsw i32 %63, 1
  %68 = shl i32 %16, 2
  %69 = add nsw i32 %68, -1
  %70 = sext i32 %69 to i64
  %71 = getelementptr inbounds i8, i8* %0, i64 %70
  %72 = load i8, i8* %71, align 1
  %73 = zext i8 %72 to i32
  %74 = add nuw nsw i32 %53, %67
  %75 = add nuw nsw i32 %74, %73
  %76 = lshr i32 %75, 2
  %77 = shl nuw nsw i32 %73, 1
  %78 = mul i64 %4, 21474836480
  %79 = add i64 %78, -4294967296
  %80 = ashr exact i64 %79, 32
  %81 = getelementptr inbounds i8, i8* %0, i64 %80
  %82 = load i8, i8* %81, align 1
  %83 = zext i8 %82 to i32
  %84 = add nuw nsw i32 %63, 2
  %85 = add nuw nsw i32 %84, %77
  %86 = add nuw nsw i32 %85, %83
  %87 = lshr i32 %86, 2
  %88 = shl nuw nsw i32 %83, 1
  %89 = mul i64 %4, 25769803776
  %90 = add i64 %89, -4294967296
  %91 = ashr exact i64 %90, 32
  %92 = getelementptr inbounds i8, i8* %0, i64 %91
  %93 = load i8, i8* %92, align 1
  %94 = zext i8 %93 to i32
  %95 = add nuw nsw i32 %73, 2
  %96 = add nuw nsw i32 %95, %88
  %97 = add nuw nsw i32 %96, %94
  %98 = lshr i32 %97, 2
  %99 = shl nuw nsw i32 %94, 1
  %100 = mul i64 %4, 30064771072
  %101 = add i64 %100, -4294967296
  %102 = ashr exact i64 %101, 32
  %103 = getelementptr inbounds i8, i8* %0, i64 %102
  %104 = load i8, i8* %103, align 1
  %105 = zext i8 %104 to i32
  %106 = add nuw nsw i32 %83, 2
  %107 = add nuw nsw i32 %106, %99
  %108 = add nuw nsw i32 %107, %105
  %109 = lshr i32 %108, 2
  %110 = mul nuw nsw i32 %105, 3
  %111 = add nuw nsw i32 %94, 2
  %112 = add nuw nsw i32 %111, %110
  %113 = lshr i32 %112, 2
  %114 = trunc i32 %45 to i8
  store i8 %114, i8* %8, align 8
  %115 = trunc i32 %56 to i8
  store i8 %115, i8* %9, align 1
  %116 = trunc i32 %66 to i8
  store i8 %116, i8* %10, align 2
  %117 = trunc i32 %76 to i8
  store i8 %117, i8* %11, align 1
  %118 = trunc i32 %87 to i8
  store i8 %118, i8* %12, align 4
  %119 = trunc i32 %98 to i8
  store i8 %119, i8* %13, align 1
  %120 = trunc i32 %109 to i8
  store i8 %120, i8* %14, align 2
  %121 = trunc i32 %113 to i8
  store i8 %121, i8* %15, align 1
  br label %122

122:                                              ; preds = %167, %27
  %123 = phi i8 [ %114, %27 ], [ %171, %167 ]
  %124 = phi i64 [ 0, %27 ], [ %165, %167 ]
  %125 = phi i8* [ %0, %27 ], [ %169, %167 ]
  %126 = phi i16* [ %1, %27 ], [ %168, %167 ]
  %127 = load i16, i16* %126, align 2
  %128 = trunc i16 %127 to i8
  %129 = add i8 %123, %128
  store i8 %129, i8* %125, align 1
  %130 = getelementptr inbounds i16, i16* %126, i64 1
  %131 = load i16, i16* %130, align 2
  %132 = trunc i16 %131 to i8
  %133 = add i8 %129, %132
  %134 = getelementptr inbounds i8, i8* %125, i64 1
  store i8 %133, i8* %134, align 1
  %135 = getelementptr inbounds i16, i16* %126, i64 2
  %136 = load i16, i16* %135, align 2
  %137 = trunc i16 %136 to i8
  %138 = add i8 %133, %137
  %139 = getelementptr inbounds i8, i8* %125, i64 2
  store i8 %138, i8* %139, align 1
  %140 = getelementptr inbounds i16, i16* %126, i64 3
  %141 = load i16, i16* %140, align 2
  %142 = trunc i16 %141 to i8
  %143 = add i8 %138, %142
  %144 = getelementptr inbounds i8, i8* %125, i64 3
  store i8 %143, i8* %144, align 1
  %145 = getelementptr inbounds i16, i16* %126, i64 4
  %146 = load i16, i16* %145, align 2
  %147 = trunc i16 %146 to i8
  %148 = add i8 %143, %147
  %149 = getelementptr inbounds i8, i8* %125, i64 4
  store i8 %148, i8* %149, align 1
  %150 = getelementptr inbounds i16, i16* %126, i64 5
  %151 = load i16, i16* %150, align 2
  %152 = trunc i16 %151 to i8
  %153 = add i8 %148, %152
  %154 = getelementptr inbounds i8, i8* %125, i64 5
  store i8 %153, i8* %154, align 1
  %155 = getelementptr inbounds i16, i16* %126, i64 6
  %156 = load i16, i16* %155, align 2
  %157 = trunc i16 %156 to i8
  %158 = add i8 %153, %157
  %159 = getelementptr inbounds i8, i8* %125, i64 6
  store i8 %158, i8* %159, align 1
  %160 = getelementptr inbounds i16, i16* %126, i64 7
  %161 = load i16, i16* %160, align 2
  %162 = trunc i16 %161 to i8
  %163 = add i8 %158, %162
  %164 = getelementptr inbounds i8, i8* %125, i64 7
  store i8 %163, i8* %164, align 1
  %165 = add nuw nsw i64 %124, 1
  %166 = icmp eq i64 %165, 8
  br i1 %166, label %172, label %167

167:                                              ; preds = %122
  %168 = getelementptr inbounds i16, i16* %126, i64 8
  %169 = getelementptr inbounds i8, i8* %125, i64 %28
  %170 = getelementptr inbounds [8 x i8], [8 x i8]* %7, i64 0, i64 %165
  %171 = load i8, i8* %170, align 1
  br label %122

172:                                              ; preds = %122
  %173 = bitcast i16* %1 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %173, i8 0, i64 128, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %8) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8_vertical_add_8_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = sub i64 0, %3
  %6 = shl nsw i64 %3, 1
  %7 = mul nsw i64 %3, 3
  %8 = shl nsw i64 %3, 2
  br label %9

9:                                                ; preds = %9, %4
  %10 = phi i64 [ 0, %4 ], [ %104, %9 ]
  %11 = getelementptr inbounds i32, i32* %1, i64 %10
  %12 = load i32, i32* %11, align 4
  %13 = sext i32 %12 to i64
  %14 = getelementptr inbounds i8, i8* %0, i64 %13
  %15 = shl nsw i64 %10, 4
  %16 = getelementptr inbounds i16, i16* %2, i64 %15
  %17 = getelementptr inbounds i8, i8* %14, i64 %5
  %18 = load i8, i8* %17, align 1
  %19 = load i16, i16* %16, align 2
  %20 = trunc i16 %19 to i8
  %21 = add i8 %18, %20
  store i8 %21, i8* %14, align 1
  %22 = getelementptr inbounds i16, i16* %16, i64 4
  %23 = load i16, i16* %22, align 2
  %24 = trunc i16 %23 to i8
  %25 = add i8 %21, %24
  %26 = getelementptr inbounds i8, i8* %17, i64 %6
  store i8 %25, i8* %26, align 1
  %27 = getelementptr inbounds i16, i16* %16, i64 8
  %28 = load i16, i16* %27, align 2
  %29 = trunc i16 %28 to i8
  %30 = add i8 %25, %29
  %31 = getelementptr inbounds i8, i8* %17, i64 %7
  store i8 %30, i8* %31, align 1
  %32 = getelementptr inbounds i16, i16* %16, i64 12
  %33 = load i16, i16* %32, align 2
  %34 = trunc i16 %33 to i8
  %35 = add i8 %30, %34
  %36 = getelementptr inbounds i8, i8* %17, i64 %8
  store i8 %35, i8* %36, align 1
  %37 = getelementptr inbounds i8, i8* %17, i64 1
  %38 = getelementptr inbounds i16, i16* %16, i64 1
  %39 = load i8, i8* %37, align 1
  %40 = load i16, i16* %38, align 2
  %41 = trunc i16 %40 to i8
  %42 = add i8 %39, %41
  %43 = getelementptr inbounds i8, i8* %37, i64 %3
  store i8 %42, i8* %43, align 1
  %44 = getelementptr inbounds i16, i16* %16, i64 5
  %45 = load i16, i16* %44, align 2
  %46 = trunc i16 %45 to i8
  %47 = add i8 %42, %46
  %48 = getelementptr inbounds i8, i8* %37, i64 %6
  store i8 %47, i8* %48, align 1
  %49 = getelementptr inbounds i16, i16* %16, i64 9
  %50 = load i16, i16* %49, align 2
  %51 = trunc i16 %50 to i8
  %52 = add i8 %47, %51
  %53 = getelementptr inbounds i8, i8* %37, i64 %7
  store i8 %52, i8* %53, align 1
  %54 = getelementptr inbounds i16, i16* %16, i64 13
  %55 = load i16, i16* %54, align 2
  %56 = trunc i16 %55 to i8
  %57 = add i8 %52, %56
  %58 = getelementptr inbounds i8, i8* %37, i64 %8
  store i8 %57, i8* %58, align 1
  %59 = getelementptr inbounds i8, i8* %37, i64 1
  %60 = getelementptr inbounds i16, i16* %16, i64 2
  %61 = load i8, i8* %59, align 1
  %62 = load i16, i16* %60, align 2
  %63 = trunc i16 %62 to i8
  %64 = add i8 %61, %63
  %65 = getelementptr inbounds i8, i8* %59, i64 %3
  store i8 %64, i8* %65, align 1
  %66 = getelementptr inbounds i16, i16* %16, i64 6
  %67 = load i16, i16* %66, align 2
  %68 = trunc i16 %67 to i8
  %69 = add i8 %64, %68
  %70 = getelementptr inbounds i8, i8* %59, i64 %6
  store i8 %69, i8* %70, align 1
  %71 = getelementptr inbounds i16, i16* %16, i64 10
  %72 = load i16, i16* %71, align 2
  %73 = trunc i16 %72 to i8
  %74 = add i8 %69, %73
  %75 = getelementptr inbounds i8, i8* %59, i64 %7
  store i8 %74, i8* %75, align 1
  %76 = getelementptr inbounds i16, i16* %16, i64 14
  %77 = load i16, i16* %76, align 2
  %78 = trunc i16 %77 to i8
  %79 = add i8 %74, %78
  %80 = getelementptr inbounds i8, i8* %59, i64 %8
  store i8 %79, i8* %80, align 1
  %81 = getelementptr inbounds i8, i8* %59, i64 1
  %82 = getelementptr inbounds i16, i16* %16, i64 3
  %83 = load i8, i8* %81, align 1
  %84 = load i16, i16* %82, align 2
  %85 = trunc i16 %84 to i8
  %86 = add i8 %83, %85
  %87 = getelementptr inbounds i8, i8* %81, i64 %3
  store i8 %86, i8* %87, align 1
  %88 = getelementptr inbounds i16, i16* %16, i64 7
  %89 = load i16, i16* %88, align 2
  %90 = trunc i16 %89 to i8
  %91 = add i8 %86, %90
  %92 = getelementptr inbounds i8, i8* %81, i64 %6
  store i8 %91, i8* %92, align 1
  %93 = getelementptr inbounds i16, i16* %16, i64 11
  %94 = load i16, i16* %93, align 2
  %95 = trunc i16 %94 to i8
  %96 = add i8 %91, %95
  %97 = getelementptr inbounds i8, i8* %81, i64 %7
  store i8 %96, i8* %97, align 1
  %98 = getelementptr inbounds i16, i16* %16, i64 15
  %99 = load i16, i16* %98, align 2
  %100 = trunc i16 %99 to i8
  %101 = add i8 %96, %100
  %102 = getelementptr inbounds i8, i8* %81, i64 %8
  store i8 %101, i8* %102, align 1
  %103 = bitcast i16* %16 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %103, i8 0, i64 32, i1 false) #8
  %104 = add nuw nsw i64 %10, 1
  %105 = icmp eq i64 %104, 4
  br i1 %105, label %106, label %9

106:                                              ; preds = %9
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x8_horizontal_add_8_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  br label %5

5:                                                ; preds = %5, %4
  %6 = phi i64 [ 0, %4 ], [ %100, %5 ]
  %7 = getelementptr inbounds i32, i32* %1, i64 %6
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  %10 = getelementptr inbounds i8, i8* %0, i64 %9
  %11 = shl nsw i64 %6, 4
  %12 = getelementptr inbounds i16, i16* %2, i64 %11
  %13 = getelementptr inbounds i8, i8* %10, i64 -1
  %14 = load i8, i8* %13, align 1
  %15 = load i16, i16* %12, align 2
  %16 = trunc i16 %15 to i8
  %17 = add i8 %14, %16
  store i8 %17, i8* %10, align 1
  %18 = getelementptr inbounds i16, i16* %12, i64 1
  %19 = load i16, i16* %18, align 2
  %20 = trunc i16 %19 to i8
  %21 = add i8 %17, %20
  %22 = getelementptr inbounds i8, i8* %10, i64 1
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds i16, i16* %12, i64 2
  %24 = load i16, i16* %23, align 2
  %25 = trunc i16 %24 to i8
  %26 = add i8 %21, %25
  %27 = getelementptr inbounds i8, i8* %10, i64 2
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds i16, i16* %12, i64 3
  %29 = load i16, i16* %28, align 2
  %30 = trunc i16 %29 to i8
  %31 = add i8 %26, %30
  %32 = getelementptr inbounds i8, i8* %10, i64 3
  store i8 %31, i8* %32, align 1
  %33 = getelementptr inbounds i8, i8* %10, i64 %3
  %34 = getelementptr inbounds i16, i16* %12, i64 4
  %35 = getelementptr inbounds i8, i8* %33, i64 -1
  %36 = load i8, i8* %35, align 1
  %37 = load i16, i16* %34, align 2
  %38 = trunc i16 %37 to i8
  %39 = add i8 %36, %38
  store i8 %39, i8* %33, align 1
  %40 = getelementptr inbounds i16, i16* %12, i64 5
  %41 = load i16, i16* %40, align 2
  %42 = trunc i16 %41 to i8
  %43 = add i8 %39, %42
  %44 = getelementptr inbounds i8, i8* %33, i64 1
  store i8 %43, i8* %44, align 1
  %45 = getelementptr inbounds i16, i16* %12, i64 6
  %46 = load i16, i16* %45, align 2
  %47 = trunc i16 %46 to i8
  %48 = add i8 %43, %47
  %49 = getelementptr inbounds i8, i8* %33, i64 2
  store i8 %48, i8* %49, align 1
  %50 = getelementptr inbounds i16, i16* %12, i64 7
  %51 = load i16, i16* %50, align 2
  %52 = trunc i16 %51 to i8
  %53 = add i8 %48, %52
  %54 = getelementptr inbounds i8, i8* %33, i64 3
  store i8 %53, i8* %54, align 1
  %55 = getelementptr inbounds i8, i8* %33, i64 %3
  %56 = getelementptr inbounds i16, i16* %12, i64 8
  %57 = getelementptr inbounds i8, i8* %55, i64 -1
  %58 = load i8, i8* %57, align 1
  %59 = load i16, i16* %56, align 2
  %60 = trunc i16 %59 to i8
  %61 = add i8 %58, %60
  store i8 %61, i8* %55, align 1
  %62 = getelementptr inbounds i16, i16* %12, i64 9
  %63 = load i16, i16* %62, align 2
  %64 = trunc i16 %63 to i8
  %65 = add i8 %61, %64
  %66 = getelementptr inbounds i8, i8* %55, i64 1
  store i8 %65, i8* %66, align 1
  %67 = getelementptr inbounds i16, i16* %12, i64 10
  %68 = load i16, i16* %67, align 2
  %69 = trunc i16 %68 to i8
  %70 = add i8 %65, %69
  %71 = getelementptr inbounds i8, i8* %55, i64 2
  store i8 %70, i8* %71, align 1
  %72 = getelementptr inbounds i16, i16* %12, i64 11
  %73 = load i16, i16* %72, align 2
  %74 = trunc i16 %73 to i8
  %75 = add i8 %70, %74
  %76 = getelementptr inbounds i8, i8* %55, i64 3
  store i8 %75, i8* %76, align 1
  %77 = getelementptr inbounds i8, i8* %55, i64 %3
  %78 = getelementptr inbounds i16, i16* %12, i64 12
  %79 = getelementptr inbounds i8, i8* %77, i64 -1
  %80 = load i8, i8* %79, align 1
  %81 = load i16, i16* %78, align 2
  %82 = trunc i16 %81 to i8
  %83 = add i8 %80, %82
  store i8 %83, i8* %77, align 1
  %84 = getelementptr inbounds i16, i16* %12, i64 13
  %85 = load i16, i16* %84, align 2
  %86 = trunc i16 %85 to i8
  %87 = add i8 %83, %86
  %88 = getelementptr inbounds i8, i8* %77, i64 1
  store i8 %87, i8* %88, align 1
  %89 = getelementptr inbounds i16, i16* %12, i64 14
  %90 = load i16, i16* %89, align 2
  %91 = trunc i16 %90 to i8
  %92 = add i8 %87, %91
  %93 = getelementptr inbounds i8, i8* %77, i64 2
  store i8 %92, i8* %93, align 1
  %94 = getelementptr inbounds i16, i16* %12, i64 15
  %95 = load i16, i16* %94, align 2
  %96 = trunc i16 %95 to i8
  %97 = add i8 %92, %96
  %98 = getelementptr inbounds i8, i8* %77, i64 3
  store i8 %97, i8* %98, align 1
  %99 = bitcast i16* %12 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %99, i8 0, i64 32, i1 false) #8
  %100 = add nuw nsw i64 %6, 1
  %101 = icmp eq i64 %100, 4
  br i1 %101, label %102, label %5

102:                                              ; preds = %5
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x16_vertical_add_8_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = sub i64 0, %3
  %6 = shl nsw i64 %3, 1
  %7 = mul nsw i64 %3, 3
  %8 = shl nsw i64 %3, 2
  br label %9

9:                                                ; preds = %9, %4
  %10 = phi i64 [ 0, %4 ], [ %104, %9 ]
  %11 = getelementptr inbounds i32, i32* %1, i64 %10
  %12 = load i32, i32* %11, align 4
  %13 = sext i32 %12 to i64
  %14 = getelementptr inbounds i8, i8* %0, i64 %13
  %15 = shl nsw i64 %10, 4
  %16 = getelementptr inbounds i16, i16* %2, i64 %15
  %17 = getelementptr inbounds i8, i8* %14, i64 %5
  %18 = load i8, i8* %17, align 1
  %19 = load i16, i16* %16, align 2
  %20 = trunc i16 %19 to i8
  %21 = add i8 %18, %20
  store i8 %21, i8* %14, align 1
  %22 = getelementptr inbounds i16, i16* %16, i64 4
  %23 = load i16, i16* %22, align 2
  %24 = trunc i16 %23 to i8
  %25 = add i8 %21, %24
  %26 = getelementptr inbounds i8, i8* %17, i64 %6
  store i8 %25, i8* %26, align 1
  %27 = getelementptr inbounds i16, i16* %16, i64 8
  %28 = load i16, i16* %27, align 2
  %29 = trunc i16 %28 to i8
  %30 = add i8 %25, %29
  %31 = getelementptr inbounds i8, i8* %17, i64 %7
  store i8 %30, i8* %31, align 1
  %32 = getelementptr inbounds i16, i16* %16, i64 12
  %33 = load i16, i16* %32, align 2
  %34 = trunc i16 %33 to i8
  %35 = add i8 %30, %34
  %36 = getelementptr inbounds i8, i8* %17, i64 %8
  store i8 %35, i8* %36, align 1
  %37 = getelementptr inbounds i8, i8* %17, i64 1
  %38 = getelementptr inbounds i16, i16* %16, i64 1
  %39 = load i8, i8* %37, align 1
  %40 = load i16, i16* %38, align 2
  %41 = trunc i16 %40 to i8
  %42 = add i8 %39, %41
  %43 = getelementptr inbounds i8, i8* %37, i64 %3
  store i8 %42, i8* %43, align 1
  %44 = getelementptr inbounds i16, i16* %16, i64 5
  %45 = load i16, i16* %44, align 2
  %46 = trunc i16 %45 to i8
  %47 = add i8 %42, %46
  %48 = getelementptr inbounds i8, i8* %37, i64 %6
  store i8 %47, i8* %48, align 1
  %49 = getelementptr inbounds i16, i16* %16, i64 9
  %50 = load i16, i16* %49, align 2
  %51 = trunc i16 %50 to i8
  %52 = add i8 %47, %51
  %53 = getelementptr inbounds i8, i8* %37, i64 %7
  store i8 %52, i8* %53, align 1
  %54 = getelementptr inbounds i16, i16* %16, i64 13
  %55 = load i16, i16* %54, align 2
  %56 = trunc i16 %55 to i8
  %57 = add i8 %52, %56
  %58 = getelementptr inbounds i8, i8* %37, i64 %8
  store i8 %57, i8* %58, align 1
  %59 = getelementptr inbounds i8, i8* %37, i64 1
  %60 = getelementptr inbounds i16, i16* %16, i64 2
  %61 = load i8, i8* %59, align 1
  %62 = load i16, i16* %60, align 2
  %63 = trunc i16 %62 to i8
  %64 = add i8 %61, %63
  %65 = getelementptr inbounds i8, i8* %59, i64 %3
  store i8 %64, i8* %65, align 1
  %66 = getelementptr inbounds i16, i16* %16, i64 6
  %67 = load i16, i16* %66, align 2
  %68 = trunc i16 %67 to i8
  %69 = add i8 %64, %68
  %70 = getelementptr inbounds i8, i8* %59, i64 %6
  store i8 %69, i8* %70, align 1
  %71 = getelementptr inbounds i16, i16* %16, i64 10
  %72 = load i16, i16* %71, align 2
  %73 = trunc i16 %72 to i8
  %74 = add i8 %69, %73
  %75 = getelementptr inbounds i8, i8* %59, i64 %7
  store i8 %74, i8* %75, align 1
  %76 = getelementptr inbounds i16, i16* %16, i64 14
  %77 = load i16, i16* %76, align 2
  %78 = trunc i16 %77 to i8
  %79 = add i8 %74, %78
  %80 = getelementptr inbounds i8, i8* %59, i64 %8
  store i8 %79, i8* %80, align 1
  %81 = getelementptr inbounds i8, i8* %59, i64 1
  %82 = getelementptr inbounds i16, i16* %16, i64 3
  %83 = load i8, i8* %81, align 1
  %84 = load i16, i16* %82, align 2
  %85 = trunc i16 %84 to i8
  %86 = add i8 %83, %85
  %87 = getelementptr inbounds i8, i8* %81, i64 %3
  store i8 %86, i8* %87, align 1
  %88 = getelementptr inbounds i16, i16* %16, i64 7
  %89 = load i16, i16* %88, align 2
  %90 = trunc i16 %89 to i8
  %91 = add i8 %86, %90
  %92 = getelementptr inbounds i8, i8* %81, i64 %6
  store i8 %91, i8* %92, align 1
  %93 = getelementptr inbounds i16, i16* %16, i64 11
  %94 = load i16, i16* %93, align 2
  %95 = trunc i16 %94 to i8
  %96 = add i8 %91, %95
  %97 = getelementptr inbounds i8, i8* %81, i64 %7
  store i8 %96, i8* %97, align 1
  %98 = getelementptr inbounds i16, i16* %16, i64 15
  %99 = load i16, i16* %98, align 2
  %100 = trunc i16 %99 to i8
  %101 = add i8 %96, %100
  %102 = getelementptr inbounds i8, i8* %81, i64 %8
  store i8 %101, i8* %102, align 1
  %103 = bitcast i16* %16 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %103, i8 0, i64 32, i1 false) #8
  %104 = add nuw nsw i64 %10, 1
  %105 = icmp eq i64 %104, 4
  br i1 %105, label %106, label %9

106:                                              ; preds = %9, %106
  %107 = phi i64 [ %202, %106 ], [ 4, %9 ]
  %108 = add nuw nsw i64 %107, 4
  %109 = getelementptr inbounds i32, i32* %1, i64 %108
  %110 = load i32, i32* %109, align 4
  %111 = sext i32 %110 to i64
  %112 = getelementptr inbounds i8, i8* %0, i64 %111
  %113 = shl nsw i64 %107, 4
  %114 = getelementptr inbounds i16, i16* %2, i64 %113
  %115 = getelementptr inbounds i8, i8* %112, i64 %5
  %116 = load i8, i8* %115, align 1
  %117 = load i16, i16* %114, align 2
  %118 = trunc i16 %117 to i8
  %119 = add i8 %116, %118
  store i8 %119, i8* %112, align 1
  %120 = getelementptr inbounds i16, i16* %114, i64 4
  %121 = load i16, i16* %120, align 2
  %122 = trunc i16 %121 to i8
  %123 = add i8 %119, %122
  %124 = getelementptr inbounds i8, i8* %115, i64 %6
  store i8 %123, i8* %124, align 1
  %125 = getelementptr inbounds i16, i16* %114, i64 8
  %126 = load i16, i16* %125, align 2
  %127 = trunc i16 %126 to i8
  %128 = add i8 %123, %127
  %129 = getelementptr inbounds i8, i8* %115, i64 %7
  store i8 %128, i8* %129, align 1
  %130 = getelementptr inbounds i16, i16* %114, i64 12
  %131 = load i16, i16* %130, align 2
  %132 = trunc i16 %131 to i8
  %133 = add i8 %128, %132
  %134 = getelementptr inbounds i8, i8* %115, i64 %8
  store i8 %133, i8* %134, align 1
  %135 = getelementptr inbounds i8, i8* %115, i64 1
  %136 = getelementptr inbounds i16, i16* %114, i64 1
  %137 = load i8, i8* %135, align 1
  %138 = load i16, i16* %136, align 2
  %139 = trunc i16 %138 to i8
  %140 = add i8 %137, %139
  %141 = getelementptr inbounds i8, i8* %135, i64 %3
  store i8 %140, i8* %141, align 1
  %142 = getelementptr inbounds i16, i16* %114, i64 5
  %143 = load i16, i16* %142, align 2
  %144 = trunc i16 %143 to i8
  %145 = add i8 %140, %144
  %146 = getelementptr inbounds i8, i8* %135, i64 %6
  store i8 %145, i8* %146, align 1
  %147 = getelementptr inbounds i16, i16* %114, i64 9
  %148 = load i16, i16* %147, align 2
  %149 = trunc i16 %148 to i8
  %150 = add i8 %145, %149
  %151 = getelementptr inbounds i8, i8* %135, i64 %7
  store i8 %150, i8* %151, align 1
  %152 = getelementptr inbounds i16, i16* %114, i64 13
  %153 = load i16, i16* %152, align 2
  %154 = trunc i16 %153 to i8
  %155 = add i8 %150, %154
  %156 = getelementptr inbounds i8, i8* %135, i64 %8
  store i8 %155, i8* %156, align 1
  %157 = getelementptr inbounds i8, i8* %135, i64 1
  %158 = getelementptr inbounds i16, i16* %114, i64 2
  %159 = load i8, i8* %157, align 1
  %160 = load i16, i16* %158, align 2
  %161 = trunc i16 %160 to i8
  %162 = add i8 %159, %161
  %163 = getelementptr inbounds i8, i8* %157, i64 %3
  store i8 %162, i8* %163, align 1
  %164 = getelementptr inbounds i16, i16* %114, i64 6
  %165 = load i16, i16* %164, align 2
  %166 = trunc i16 %165 to i8
  %167 = add i8 %162, %166
  %168 = getelementptr inbounds i8, i8* %157, i64 %6
  store i8 %167, i8* %168, align 1
  %169 = getelementptr inbounds i16, i16* %114, i64 10
  %170 = load i16, i16* %169, align 2
  %171 = trunc i16 %170 to i8
  %172 = add i8 %167, %171
  %173 = getelementptr inbounds i8, i8* %157, i64 %7
  store i8 %172, i8* %173, align 1
  %174 = getelementptr inbounds i16, i16* %114, i64 14
  %175 = load i16, i16* %174, align 2
  %176 = trunc i16 %175 to i8
  %177 = add i8 %172, %176
  %178 = getelementptr inbounds i8, i8* %157, i64 %8
  store i8 %177, i8* %178, align 1
  %179 = getelementptr inbounds i8, i8* %157, i64 1
  %180 = getelementptr inbounds i16, i16* %114, i64 3
  %181 = load i8, i8* %179, align 1
  %182 = load i16, i16* %180, align 2
  %183 = trunc i16 %182 to i8
  %184 = add i8 %181, %183
  %185 = getelementptr inbounds i8, i8* %179, i64 %3
  store i8 %184, i8* %185, align 1
  %186 = getelementptr inbounds i16, i16* %114, i64 7
  %187 = load i16, i16* %186, align 2
  %188 = trunc i16 %187 to i8
  %189 = add i8 %184, %188
  %190 = getelementptr inbounds i8, i8* %179, i64 %6
  store i8 %189, i8* %190, align 1
  %191 = getelementptr inbounds i16, i16* %114, i64 11
  %192 = load i16, i16* %191, align 2
  %193 = trunc i16 %192 to i8
  %194 = add i8 %189, %193
  %195 = getelementptr inbounds i8, i8* %179, i64 %7
  store i8 %194, i8* %195, align 1
  %196 = getelementptr inbounds i16, i16* %114, i64 15
  %197 = load i16, i16* %196, align 2
  %198 = trunc i16 %197 to i8
  %199 = add i8 %194, %198
  %200 = getelementptr inbounds i8, i8* %179, i64 %8
  store i8 %199, i8* %200, align 1
  %201 = bitcast i16* %114 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %201, i8 0, i64 32, i1 false) #8
  %202 = add nuw nsw i64 %107, 1
  %203 = icmp eq i64 %202, 8
  br i1 %203, label %204, label %106

204:                                              ; preds = %106
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred8x16_horizontal_add_8_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  br label %5

5:                                                ; preds = %5, %4
  %6 = phi i64 [ 0, %4 ], [ %100, %5 ]
  %7 = getelementptr inbounds i32, i32* %1, i64 %6
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  %10 = getelementptr inbounds i8, i8* %0, i64 %9
  %11 = shl nsw i64 %6, 4
  %12 = getelementptr inbounds i16, i16* %2, i64 %11
  %13 = getelementptr inbounds i8, i8* %10, i64 -1
  %14 = load i8, i8* %13, align 1
  %15 = load i16, i16* %12, align 2
  %16 = trunc i16 %15 to i8
  %17 = add i8 %14, %16
  store i8 %17, i8* %10, align 1
  %18 = getelementptr inbounds i16, i16* %12, i64 1
  %19 = load i16, i16* %18, align 2
  %20 = trunc i16 %19 to i8
  %21 = add i8 %17, %20
  %22 = getelementptr inbounds i8, i8* %10, i64 1
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds i16, i16* %12, i64 2
  %24 = load i16, i16* %23, align 2
  %25 = trunc i16 %24 to i8
  %26 = add i8 %21, %25
  %27 = getelementptr inbounds i8, i8* %10, i64 2
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds i16, i16* %12, i64 3
  %29 = load i16, i16* %28, align 2
  %30 = trunc i16 %29 to i8
  %31 = add i8 %26, %30
  %32 = getelementptr inbounds i8, i8* %10, i64 3
  store i8 %31, i8* %32, align 1
  %33 = getelementptr inbounds i8, i8* %10, i64 %3
  %34 = getelementptr inbounds i16, i16* %12, i64 4
  %35 = getelementptr inbounds i8, i8* %33, i64 -1
  %36 = load i8, i8* %35, align 1
  %37 = load i16, i16* %34, align 2
  %38 = trunc i16 %37 to i8
  %39 = add i8 %36, %38
  store i8 %39, i8* %33, align 1
  %40 = getelementptr inbounds i16, i16* %12, i64 5
  %41 = load i16, i16* %40, align 2
  %42 = trunc i16 %41 to i8
  %43 = add i8 %39, %42
  %44 = getelementptr inbounds i8, i8* %33, i64 1
  store i8 %43, i8* %44, align 1
  %45 = getelementptr inbounds i16, i16* %12, i64 6
  %46 = load i16, i16* %45, align 2
  %47 = trunc i16 %46 to i8
  %48 = add i8 %43, %47
  %49 = getelementptr inbounds i8, i8* %33, i64 2
  store i8 %48, i8* %49, align 1
  %50 = getelementptr inbounds i16, i16* %12, i64 7
  %51 = load i16, i16* %50, align 2
  %52 = trunc i16 %51 to i8
  %53 = add i8 %48, %52
  %54 = getelementptr inbounds i8, i8* %33, i64 3
  store i8 %53, i8* %54, align 1
  %55 = getelementptr inbounds i8, i8* %33, i64 %3
  %56 = getelementptr inbounds i16, i16* %12, i64 8
  %57 = getelementptr inbounds i8, i8* %55, i64 -1
  %58 = load i8, i8* %57, align 1
  %59 = load i16, i16* %56, align 2
  %60 = trunc i16 %59 to i8
  %61 = add i8 %58, %60
  store i8 %61, i8* %55, align 1
  %62 = getelementptr inbounds i16, i16* %12, i64 9
  %63 = load i16, i16* %62, align 2
  %64 = trunc i16 %63 to i8
  %65 = add i8 %61, %64
  %66 = getelementptr inbounds i8, i8* %55, i64 1
  store i8 %65, i8* %66, align 1
  %67 = getelementptr inbounds i16, i16* %12, i64 10
  %68 = load i16, i16* %67, align 2
  %69 = trunc i16 %68 to i8
  %70 = add i8 %65, %69
  %71 = getelementptr inbounds i8, i8* %55, i64 2
  store i8 %70, i8* %71, align 1
  %72 = getelementptr inbounds i16, i16* %12, i64 11
  %73 = load i16, i16* %72, align 2
  %74 = trunc i16 %73 to i8
  %75 = add i8 %70, %74
  %76 = getelementptr inbounds i8, i8* %55, i64 3
  store i8 %75, i8* %76, align 1
  %77 = getelementptr inbounds i8, i8* %55, i64 %3
  %78 = getelementptr inbounds i16, i16* %12, i64 12
  %79 = getelementptr inbounds i8, i8* %77, i64 -1
  %80 = load i8, i8* %79, align 1
  %81 = load i16, i16* %78, align 2
  %82 = trunc i16 %81 to i8
  %83 = add i8 %80, %82
  store i8 %83, i8* %77, align 1
  %84 = getelementptr inbounds i16, i16* %12, i64 13
  %85 = load i16, i16* %84, align 2
  %86 = trunc i16 %85 to i8
  %87 = add i8 %83, %86
  %88 = getelementptr inbounds i8, i8* %77, i64 1
  store i8 %87, i8* %88, align 1
  %89 = getelementptr inbounds i16, i16* %12, i64 14
  %90 = load i16, i16* %89, align 2
  %91 = trunc i16 %90 to i8
  %92 = add i8 %87, %91
  %93 = getelementptr inbounds i8, i8* %77, i64 2
  store i8 %92, i8* %93, align 1
  %94 = getelementptr inbounds i16, i16* %12, i64 15
  %95 = load i16, i16* %94, align 2
  %96 = trunc i16 %95 to i8
  %97 = add i8 %92, %96
  %98 = getelementptr inbounds i8, i8* %77, i64 3
  store i8 %97, i8* %98, align 1
  %99 = bitcast i16* %12 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %99, i8 0, i64 32, i1 false) #8
  %100 = add nuw nsw i64 %6, 1
  %101 = icmp eq i64 %100, 4
  br i1 %101, label %102, label %5

102:                                              ; preds = %5, %102
  %103 = phi i64 [ %198, %102 ], [ 4, %5 ]
  %104 = add nuw nsw i64 %103, 4
  %105 = getelementptr inbounds i32, i32* %1, i64 %104
  %106 = load i32, i32* %105, align 4
  %107 = sext i32 %106 to i64
  %108 = getelementptr inbounds i8, i8* %0, i64 %107
  %109 = shl nsw i64 %103, 4
  %110 = getelementptr inbounds i16, i16* %2, i64 %109
  %111 = getelementptr inbounds i8, i8* %108, i64 -1
  %112 = load i8, i8* %111, align 1
  %113 = load i16, i16* %110, align 2
  %114 = trunc i16 %113 to i8
  %115 = add i8 %112, %114
  store i8 %115, i8* %108, align 1
  %116 = getelementptr inbounds i16, i16* %110, i64 1
  %117 = load i16, i16* %116, align 2
  %118 = trunc i16 %117 to i8
  %119 = add i8 %115, %118
  %120 = getelementptr inbounds i8, i8* %108, i64 1
  store i8 %119, i8* %120, align 1
  %121 = getelementptr inbounds i16, i16* %110, i64 2
  %122 = load i16, i16* %121, align 2
  %123 = trunc i16 %122 to i8
  %124 = add i8 %119, %123
  %125 = getelementptr inbounds i8, i8* %108, i64 2
  store i8 %124, i8* %125, align 1
  %126 = getelementptr inbounds i16, i16* %110, i64 3
  %127 = load i16, i16* %126, align 2
  %128 = trunc i16 %127 to i8
  %129 = add i8 %124, %128
  %130 = getelementptr inbounds i8, i8* %108, i64 3
  store i8 %129, i8* %130, align 1
  %131 = getelementptr inbounds i8, i8* %108, i64 %3
  %132 = getelementptr inbounds i16, i16* %110, i64 4
  %133 = getelementptr inbounds i8, i8* %131, i64 -1
  %134 = load i8, i8* %133, align 1
  %135 = load i16, i16* %132, align 2
  %136 = trunc i16 %135 to i8
  %137 = add i8 %134, %136
  store i8 %137, i8* %131, align 1
  %138 = getelementptr inbounds i16, i16* %110, i64 5
  %139 = load i16, i16* %138, align 2
  %140 = trunc i16 %139 to i8
  %141 = add i8 %137, %140
  %142 = getelementptr inbounds i8, i8* %131, i64 1
  store i8 %141, i8* %142, align 1
  %143 = getelementptr inbounds i16, i16* %110, i64 6
  %144 = load i16, i16* %143, align 2
  %145 = trunc i16 %144 to i8
  %146 = add i8 %141, %145
  %147 = getelementptr inbounds i8, i8* %131, i64 2
  store i8 %146, i8* %147, align 1
  %148 = getelementptr inbounds i16, i16* %110, i64 7
  %149 = load i16, i16* %148, align 2
  %150 = trunc i16 %149 to i8
  %151 = add i8 %146, %150
  %152 = getelementptr inbounds i8, i8* %131, i64 3
  store i8 %151, i8* %152, align 1
  %153 = getelementptr inbounds i8, i8* %131, i64 %3
  %154 = getelementptr inbounds i16, i16* %110, i64 8
  %155 = getelementptr inbounds i8, i8* %153, i64 -1
  %156 = load i8, i8* %155, align 1
  %157 = load i16, i16* %154, align 2
  %158 = trunc i16 %157 to i8
  %159 = add i8 %156, %158
  store i8 %159, i8* %153, align 1
  %160 = getelementptr inbounds i16, i16* %110, i64 9
  %161 = load i16, i16* %160, align 2
  %162 = trunc i16 %161 to i8
  %163 = add i8 %159, %162
  %164 = getelementptr inbounds i8, i8* %153, i64 1
  store i8 %163, i8* %164, align 1
  %165 = getelementptr inbounds i16, i16* %110, i64 10
  %166 = load i16, i16* %165, align 2
  %167 = trunc i16 %166 to i8
  %168 = add i8 %163, %167
  %169 = getelementptr inbounds i8, i8* %153, i64 2
  store i8 %168, i8* %169, align 1
  %170 = getelementptr inbounds i16, i16* %110, i64 11
  %171 = load i16, i16* %170, align 2
  %172 = trunc i16 %171 to i8
  %173 = add i8 %168, %172
  %174 = getelementptr inbounds i8, i8* %153, i64 3
  store i8 %173, i8* %174, align 1
  %175 = getelementptr inbounds i8, i8* %153, i64 %3
  %176 = getelementptr inbounds i16, i16* %110, i64 12
  %177 = getelementptr inbounds i8, i8* %175, i64 -1
  %178 = load i8, i8* %177, align 1
  %179 = load i16, i16* %176, align 2
  %180 = trunc i16 %179 to i8
  %181 = add i8 %178, %180
  store i8 %181, i8* %175, align 1
  %182 = getelementptr inbounds i16, i16* %110, i64 13
  %183 = load i16, i16* %182, align 2
  %184 = trunc i16 %183 to i8
  %185 = add i8 %181, %184
  %186 = getelementptr inbounds i8, i8* %175, i64 1
  store i8 %185, i8* %186, align 1
  %187 = getelementptr inbounds i16, i16* %110, i64 14
  %188 = load i16, i16* %187, align 2
  %189 = trunc i16 %188 to i8
  %190 = add i8 %185, %189
  %191 = getelementptr inbounds i8, i8* %175, i64 2
  store i8 %190, i8* %191, align 1
  %192 = getelementptr inbounds i16, i16* %110, i64 15
  %193 = load i16, i16* %192, align 2
  %194 = trunc i16 %193 to i8
  %195 = add i8 %190, %194
  %196 = getelementptr inbounds i8, i8* %175, i64 3
  store i8 %195, i8* %196, align 1
  %197 = bitcast i16* %110 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %197, i8 0, i64 32, i1 false) #8
  %198 = add nuw nsw i64 %103, 1
  %199 = icmp eq i64 %198, 8
  br i1 %199, label %200, label %102

200:                                              ; preds = %102
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred16x16_vertical_add_8_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  %5 = sub i64 0, %3
  %6 = shl nsw i64 %3, 1
  %7 = mul nsw i64 %3, 3
  %8 = shl nsw i64 %3, 2
  br label %9

9:                                                ; preds = %9, %4
  %10 = phi i64 [ 0, %4 ], [ %104, %9 ]
  %11 = getelementptr inbounds i32, i32* %1, i64 %10
  %12 = load i32, i32* %11, align 4
  %13 = sext i32 %12 to i64
  %14 = getelementptr inbounds i8, i8* %0, i64 %13
  %15 = shl nsw i64 %10, 4
  %16 = getelementptr inbounds i16, i16* %2, i64 %15
  %17 = getelementptr inbounds i8, i8* %14, i64 %5
  %18 = load i8, i8* %17, align 1
  %19 = load i16, i16* %16, align 2
  %20 = trunc i16 %19 to i8
  %21 = add i8 %18, %20
  store i8 %21, i8* %14, align 1
  %22 = getelementptr inbounds i16, i16* %16, i64 4
  %23 = load i16, i16* %22, align 2
  %24 = trunc i16 %23 to i8
  %25 = add i8 %21, %24
  %26 = getelementptr inbounds i8, i8* %17, i64 %6
  store i8 %25, i8* %26, align 1
  %27 = getelementptr inbounds i16, i16* %16, i64 8
  %28 = load i16, i16* %27, align 2
  %29 = trunc i16 %28 to i8
  %30 = add i8 %25, %29
  %31 = getelementptr inbounds i8, i8* %17, i64 %7
  store i8 %30, i8* %31, align 1
  %32 = getelementptr inbounds i16, i16* %16, i64 12
  %33 = load i16, i16* %32, align 2
  %34 = trunc i16 %33 to i8
  %35 = add i8 %30, %34
  %36 = getelementptr inbounds i8, i8* %17, i64 %8
  store i8 %35, i8* %36, align 1
  %37 = getelementptr inbounds i8, i8* %17, i64 1
  %38 = getelementptr inbounds i16, i16* %16, i64 1
  %39 = load i8, i8* %37, align 1
  %40 = load i16, i16* %38, align 2
  %41 = trunc i16 %40 to i8
  %42 = add i8 %39, %41
  %43 = getelementptr inbounds i8, i8* %37, i64 %3
  store i8 %42, i8* %43, align 1
  %44 = getelementptr inbounds i16, i16* %16, i64 5
  %45 = load i16, i16* %44, align 2
  %46 = trunc i16 %45 to i8
  %47 = add i8 %42, %46
  %48 = getelementptr inbounds i8, i8* %37, i64 %6
  store i8 %47, i8* %48, align 1
  %49 = getelementptr inbounds i16, i16* %16, i64 9
  %50 = load i16, i16* %49, align 2
  %51 = trunc i16 %50 to i8
  %52 = add i8 %47, %51
  %53 = getelementptr inbounds i8, i8* %37, i64 %7
  store i8 %52, i8* %53, align 1
  %54 = getelementptr inbounds i16, i16* %16, i64 13
  %55 = load i16, i16* %54, align 2
  %56 = trunc i16 %55 to i8
  %57 = add i8 %52, %56
  %58 = getelementptr inbounds i8, i8* %37, i64 %8
  store i8 %57, i8* %58, align 1
  %59 = getelementptr inbounds i8, i8* %37, i64 1
  %60 = getelementptr inbounds i16, i16* %16, i64 2
  %61 = load i8, i8* %59, align 1
  %62 = load i16, i16* %60, align 2
  %63 = trunc i16 %62 to i8
  %64 = add i8 %61, %63
  %65 = getelementptr inbounds i8, i8* %59, i64 %3
  store i8 %64, i8* %65, align 1
  %66 = getelementptr inbounds i16, i16* %16, i64 6
  %67 = load i16, i16* %66, align 2
  %68 = trunc i16 %67 to i8
  %69 = add i8 %64, %68
  %70 = getelementptr inbounds i8, i8* %59, i64 %6
  store i8 %69, i8* %70, align 1
  %71 = getelementptr inbounds i16, i16* %16, i64 10
  %72 = load i16, i16* %71, align 2
  %73 = trunc i16 %72 to i8
  %74 = add i8 %69, %73
  %75 = getelementptr inbounds i8, i8* %59, i64 %7
  store i8 %74, i8* %75, align 1
  %76 = getelementptr inbounds i16, i16* %16, i64 14
  %77 = load i16, i16* %76, align 2
  %78 = trunc i16 %77 to i8
  %79 = add i8 %74, %78
  %80 = getelementptr inbounds i8, i8* %59, i64 %8
  store i8 %79, i8* %80, align 1
  %81 = getelementptr inbounds i8, i8* %59, i64 1
  %82 = getelementptr inbounds i16, i16* %16, i64 3
  %83 = load i8, i8* %81, align 1
  %84 = load i16, i16* %82, align 2
  %85 = trunc i16 %84 to i8
  %86 = add i8 %83, %85
  %87 = getelementptr inbounds i8, i8* %81, i64 %3
  store i8 %86, i8* %87, align 1
  %88 = getelementptr inbounds i16, i16* %16, i64 7
  %89 = load i16, i16* %88, align 2
  %90 = trunc i16 %89 to i8
  %91 = add i8 %86, %90
  %92 = getelementptr inbounds i8, i8* %81, i64 %6
  store i8 %91, i8* %92, align 1
  %93 = getelementptr inbounds i16, i16* %16, i64 11
  %94 = load i16, i16* %93, align 2
  %95 = trunc i16 %94 to i8
  %96 = add i8 %91, %95
  %97 = getelementptr inbounds i8, i8* %81, i64 %7
  store i8 %96, i8* %97, align 1
  %98 = getelementptr inbounds i16, i16* %16, i64 15
  %99 = load i16, i16* %98, align 2
  %100 = trunc i16 %99 to i8
  %101 = add i8 %96, %100
  %102 = getelementptr inbounds i8, i8* %81, i64 %8
  store i8 %101, i8* %102, align 1
  %103 = bitcast i16* %16 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %103, i8 0, i64 32, i1 false) #8
  %104 = add nuw nsw i64 %10, 1
  %105 = icmp eq i64 %104, 16
  br i1 %105, label %106, label %9

106:                                              ; preds = %9
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @pred16x16_horizontal_add_8_c(i8* nocapture, i32* nocapture readonly, i16* nocapture, i64) #3 {
  br label %5

5:                                                ; preds = %5, %4
  %6 = phi i64 [ 0, %4 ], [ %100, %5 ]
  %7 = getelementptr inbounds i32, i32* %1, i64 %6
  %8 = load i32, i32* %7, align 4
  %9 = sext i32 %8 to i64
  %10 = getelementptr inbounds i8, i8* %0, i64 %9
  %11 = shl nsw i64 %6, 4
  %12 = getelementptr inbounds i16, i16* %2, i64 %11
  %13 = getelementptr inbounds i8, i8* %10, i64 -1
  %14 = load i8, i8* %13, align 1
  %15 = load i16, i16* %12, align 2
  %16 = trunc i16 %15 to i8
  %17 = add i8 %14, %16
  store i8 %17, i8* %10, align 1
  %18 = getelementptr inbounds i16, i16* %12, i64 1
  %19 = load i16, i16* %18, align 2
  %20 = trunc i16 %19 to i8
  %21 = add i8 %17, %20
  %22 = getelementptr inbounds i8, i8* %10, i64 1
  store i8 %21, i8* %22, align 1
  %23 = getelementptr inbounds i16, i16* %12, i64 2
  %24 = load i16, i16* %23, align 2
  %25 = trunc i16 %24 to i8
  %26 = add i8 %21, %25
  %27 = getelementptr inbounds i8, i8* %10, i64 2
  store i8 %26, i8* %27, align 1
  %28 = getelementptr inbounds i16, i16* %12, i64 3
  %29 = load i16, i16* %28, align 2
  %30 = trunc i16 %29 to i8
  %31 = add i8 %26, %30
  %32 = getelementptr inbounds i8, i8* %10, i64 3
  store i8 %31, i8* %32, align 1
  %33 = getelementptr inbounds i8, i8* %10, i64 %3
  %34 = getelementptr inbounds i16, i16* %12, i64 4
  %35 = getelementptr inbounds i8, i8* %33, i64 -1
  %36 = load i8, i8* %35, align 1
  %37 = load i16, i16* %34, align 2
  %38 = trunc i16 %37 to i8
  %39 = add i8 %36, %38
  store i8 %39, i8* %33, align 1
  %40 = getelementptr inbounds i16, i16* %12, i64 5
  %41 = load i16, i16* %40, align 2
  %42 = trunc i16 %41 to i8
  %43 = add i8 %39, %42
  %44 = getelementptr inbounds i8, i8* %33, i64 1
  store i8 %43, i8* %44, align 1
  %45 = getelementptr inbounds i16, i16* %12, i64 6
  %46 = load i16, i16* %45, align 2
  %47 = trunc i16 %46 to i8
  %48 = add i8 %43, %47
  %49 = getelementptr inbounds i8, i8* %33, i64 2
  store i8 %48, i8* %49, align 1
  %50 = getelementptr inbounds i16, i16* %12, i64 7
  %51 = load i16, i16* %50, align 2
  %52 = trunc i16 %51 to i8
  %53 = add i8 %48, %52
  %54 = getelementptr inbounds i8, i8* %33, i64 3
  store i8 %53, i8* %54, align 1
  %55 = getelementptr inbounds i8, i8* %33, i64 %3
  %56 = getelementptr inbounds i16, i16* %12, i64 8
  %57 = getelementptr inbounds i8, i8* %55, i64 -1
  %58 = load i8, i8* %57, align 1
  %59 = load i16, i16* %56, align 2
  %60 = trunc i16 %59 to i8
  %61 = add i8 %58, %60
  store i8 %61, i8* %55, align 1
  %62 = getelementptr inbounds i16, i16* %12, i64 9
  %63 = load i16, i16* %62, align 2
  %64 = trunc i16 %63 to i8
  %65 = add i8 %61, %64
  %66 = getelementptr inbounds i8, i8* %55, i64 1
  store i8 %65, i8* %66, align 1
  %67 = getelementptr inbounds i16, i16* %12, i64 10
  %68 = load i16, i16* %67, align 2
  %69 = trunc i16 %68 to i8
  %70 = add i8 %65, %69
  %71 = getelementptr inbounds i8, i8* %55, i64 2
  store i8 %70, i8* %71, align 1
  %72 = getelementptr inbounds i16, i16* %12, i64 11
  %73 = load i16, i16* %72, align 2
  %74 = trunc i16 %73 to i8
  %75 = add i8 %70, %74
  %76 = getelementptr inbounds i8, i8* %55, i64 3
  store i8 %75, i8* %76, align 1
  %77 = getelementptr inbounds i8, i8* %55, i64 %3
  %78 = getelementptr inbounds i16, i16* %12, i64 12
  %79 = getelementptr inbounds i8, i8* %77, i64 -1
  %80 = load i8, i8* %79, align 1
  %81 = load i16, i16* %78, align 2
  %82 = trunc i16 %81 to i8
  %83 = add i8 %80, %82
  store i8 %83, i8* %77, align 1
  %84 = getelementptr inbounds i16, i16* %12, i64 13
  %85 = load i16, i16* %84, align 2
  %86 = trunc i16 %85 to i8
  %87 = add i8 %83, %86
  %88 = getelementptr inbounds i8, i8* %77, i64 1
  store i8 %87, i8* %88, align 1
  %89 = getelementptr inbounds i16, i16* %12, i64 14
  %90 = load i16, i16* %89, align 2
  %91 = trunc i16 %90 to i8
  %92 = add i8 %87, %91
  %93 = getelementptr inbounds i8, i8* %77, i64 2
  store i8 %92, i8* %93, align 1
  %94 = getelementptr inbounds i16, i16* %12, i64 15
  %95 = load i16, i16* %94, align 2
  %96 = trunc i16 %95 to i8
  %97 = add i8 %92, %96
  %98 = getelementptr inbounds i8, i8* %77, i64 3
  store i8 %97, i8* %98, align 1
  %99 = bitcast i16* %12 to i8*
  tail call void @llvm.memset.p0i8.i64(i8* align 2 %99, i8 0, i64 32, i1 false) #8
  %100 = add nuw nsw i64 %6, 1
  %101 = icmp eq i64 %100, 16
  br i1 %101, label %102, label %5

102:                                              ; preds = %5
  ret void
}

declare void @ff_h264_pred_init_x86(%struct.H264PredContext*, i32, i32, i32) local_unnamed_addr #4

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #6

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #6

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal fastcc void @pred4x4_vertical_left_rv40(i8* nocapture, i8* nocapture readonly, i64, i32, i32, i32, i32) unnamed_addr #1 {
  %8 = sub nsw i64 0, %2
  %9 = getelementptr inbounds i8, i8* %0, i64 %8
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i32
  %12 = sub nsw i64 1, %2
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = load i8, i8* %13, align 1
  %15 = zext i8 %14 to i32
  %16 = sub nsw i64 2, %2
  %17 = getelementptr inbounds i8, i8* %0, i64 %16
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = sub nsw i64 3, %2
  %21 = getelementptr inbounds i8, i8* %0, i64 %20
  %22 = load i8, i8* %21, align 1
  %23 = zext i8 %22 to i32
  %24 = load i8, i8* %1, align 1
  %25 = zext i8 %24 to i32
  %26 = getelementptr inbounds i8, i8* %1, i64 1
  %27 = load i8, i8* %26, align 1
  %28 = zext i8 %27 to i32
  %29 = getelementptr inbounds i8, i8* %1, i64 2
  %30 = load i8, i8* %29, align 1
  %31 = zext i8 %30 to i32
  %32 = shl nuw nsw i32 %15, 1
  %33 = add i32 %11, %4
  %34 = shl i32 %33, 1
  %35 = add nuw nsw i32 %32, 4
  %36 = add i32 %35, %3
  %37 = add i32 %36, %5
  %38 = add i32 %37, %34
  %39 = lshr i32 %38, 3
  %40 = trunc i32 %39 to i8
  store i8 %40, i8* %0, align 1
  %41 = add nuw nsw i32 %19, 1
  %42 = add nuw nsw i32 %41, %15
  %43 = lshr i32 %42, 1
  %44 = trunc i32 %43 to i8
  %45 = shl nsw i64 %2, 1
  %46 = getelementptr inbounds i8, i8* %0, i64 %45
  store i8 %44, i8* %46, align 1
  %47 = getelementptr inbounds i8, i8* %0, i64 1
  store i8 %44, i8* %47, align 1
  %48 = add nuw nsw i32 %41, %23
  %49 = lshr i32 %48, 1
  %50 = trunc i32 %49 to i8
  %51 = or i64 %45, 1
  %52 = getelementptr inbounds i8, i8* %0, i64 %51
  store i8 %50, i8* %52, align 1
  %53 = getelementptr inbounds i8, i8* %0, i64 2
  store i8 %50, i8* %53, align 1
  %54 = add nuw nsw i32 %23, 1
  %55 = add nuw nsw i32 %54, %25
  %56 = lshr i32 %55, 1
  %57 = trunc i32 %56 to i8
  %58 = add nsw i64 %45, 2
  %59 = getelementptr inbounds i8, i8* %0, i64 %58
  store i8 %57, i8* %59, align 1
  %60 = getelementptr inbounds i8, i8* %0, i64 3
  store i8 %57, i8* %60, align 1
  %61 = add nuw nsw i32 %25, 1
  %62 = add nuw nsw i32 %61, %28
  %63 = lshr i32 %62, 1
  %64 = trunc i32 %63 to i8
  %65 = add nsw i64 %45, 3
  %66 = getelementptr inbounds i8, i8* %0, i64 %65
  store i8 %64, i8* %66, align 1
  %67 = shl i32 %5, 1
  %68 = add i32 %35, %4
  %69 = add i32 %68, %67
  %70 = add i32 %69, %6
  %71 = add i32 %70, %11
  %72 = add i32 %71, %19
  %73 = lshr i32 %72, 3
  %74 = trunc i32 %73 to i8
  %75 = getelementptr inbounds i8, i8* %0, i64 %2
  store i8 %74, i8* %75, align 1
  %76 = shl nuw nsw i32 %19, 1
  %77 = add nuw nsw i32 %23, 2
  %78 = add nuw nsw i32 %77, %15
  %79 = add nuw nsw i32 %78, %76
  %80 = lshr i32 %79, 2
  %81 = trunc i32 %80 to i8
  %82 = mul nsw i64 %2, 3
  %83 = getelementptr inbounds i8, i8* %0, i64 %82
  store i8 %81, i8* %83, align 1
  %84 = add nsw i64 %2, 1
  %85 = getelementptr inbounds i8, i8* %0, i64 %84
  store i8 %81, i8* %85, align 1
  %86 = shl nuw nsw i32 %23, 1
  %87 = add nuw nsw i32 %25, 2
  %88 = add nuw nsw i32 %87, %19
  %89 = add nuw nsw i32 %88, %86
  %90 = lshr i32 %89, 2
  %91 = trunc i32 %90 to i8
  %92 = add nsw i64 %82, 1
  %93 = getelementptr inbounds i8, i8* %0, i64 %92
  store i8 %91, i8* %93, align 1
  %94 = add nsw i64 %2, 2
  %95 = getelementptr inbounds i8, i8* %0, i64 %94
  store i8 %91, i8* %95, align 1
  %96 = shl nuw nsw i32 %25, 1
  %97 = add nuw nsw i32 %77, %96
  %98 = add nuw nsw i32 %97, %28
  %99 = lshr i32 %98, 2
  %100 = trunc i32 %99 to i8
  %101 = add nsw i64 %82, 2
  %102 = getelementptr inbounds i8, i8* %0, i64 %101
  store i8 %100, i8* %102, align 1
  %103 = add nsw i64 %2, 3
  %104 = getelementptr inbounds i8, i8* %0, i64 %103
  store i8 %100, i8* %104, align 1
  %105 = shl nuw nsw i32 %28, 1
  %106 = add nuw nsw i32 %87, %105
  %107 = add nuw nsw i32 %106, %31
  %108 = lshr i32 %107, 2
  %109 = trunc i32 %108 to i8
  %110 = add nsw i64 %82, 3
  %111 = getelementptr inbounds i8, i8* %0, i64 %110
  store i8 %109, i8* %111, align 1
  ret void
}

; Function Attrs: inlinehint nofree norecurse nounwind ssp uwtable
define internal fastcc void @pred16x16_plane_compat_8_c(i8* nocapture, i64, i32, i32) unnamed_addr #7 {
  %5 = trunc i64 %1 to i32
  %6 = getelementptr inbounds i8, i8* %0, i64 7
  %7 = shl i64 %1, 32
  %8 = ashr exact i64 %7, 32
  %9 = sub nsw i64 0, %8
  %10 = getelementptr inbounds i8, i8* %6, i64 %9
  %11 = shl nsw i32 %5, 3
  %12 = sext i32 %11 to i64
  %13 = getelementptr inbounds i8, i8* %0, i64 %12
  %14 = getelementptr inbounds i8, i8* %13, i64 -1
  %15 = shl nsw i32 %5, 1
  %16 = sext i32 %15 to i64
  %17 = sub nsw i64 0, %16
  %18 = getelementptr inbounds i8, i8* %14, i64 %17
  %19 = getelementptr inbounds i8, i8* %10, i64 1
  %20 = load i8, i8* %19, align 1
  %21 = zext i8 %20 to i32
  %22 = getelementptr inbounds i8, i8* %10, i64 -1
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = sub nsw i32 %21, %24
  %26 = load i8, i8* %14, align 1
  %27 = zext i8 %26 to i32
  %28 = load i8, i8* %18, align 1
  %29 = zext i8 %28 to i32
  %30 = sub nsw i32 %27, %29
  %31 = shl i64 %1, 32
  %32 = ashr exact i64 %31, 32
  %33 = mul nsw i64 %32, 7
  %34 = add nsw i64 %33, %12
  %35 = add nsw i64 %34, -1
  %36 = xor i64 %16, -1
  %37 = add nsw i64 %36, %12
  %38 = sub nsw i64 %37, %33
  %39 = getelementptr inbounds i8, i8* %14, i64 %8
  %40 = getelementptr inbounds i8, i8* %18, i64 %9
  %41 = getelementptr inbounds i8, i8* %10, i64 2
  %42 = load i8, i8* %41, align 1
  %43 = zext i8 %42 to i32
  %44 = getelementptr inbounds i8, i8* %10, i64 -2
  %45 = load i8, i8* %44, align 1
  %46 = zext i8 %45 to i32
  %47 = sub nsw i32 %43, %46
  %48 = shl nsw i32 %47, 1
  %49 = add nsw i32 %48, %25
  %50 = load i8, i8* %39, align 1
  %51 = zext i8 %50 to i32
  %52 = load i8, i8* %40, align 1
  %53 = zext i8 %52 to i32
  %54 = sub nsw i32 %51, %53
  %55 = shl nsw i32 %54, 1
  %56 = add nsw i32 %55, %30
  %57 = getelementptr inbounds i8, i8* %39, i64 %8
  %58 = getelementptr inbounds i8, i8* %40, i64 %9
  %59 = getelementptr inbounds i8, i8* %10, i64 3
  %60 = load i8, i8* %59, align 1
  %61 = zext i8 %60 to i32
  %62 = getelementptr inbounds i8, i8* %10, i64 -3
  %63 = load i8, i8* %62, align 1
  %64 = zext i8 %63 to i32
  %65 = sub nsw i32 %61, %64
  %66 = mul nsw i32 %65, 3
  %67 = add nsw i32 %66, %49
  %68 = load i8, i8* %57, align 1
  %69 = zext i8 %68 to i32
  %70 = load i8, i8* %58, align 1
  %71 = zext i8 %70 to i32
  %72 = sub nsw i32 %69, %71
  %73 = mul nsw i32 %72, 3
  %74 = add nsw i32 %73, %56
  %75 = getelementptr inbounds i8, i8* %57, i64 %8
  %76 = getelementptr inbounds i8, i8* %58, i64 %9
  %77 = getelementptr inbounds i8, i8* %10, i64 4
  %78 = load i8, i8* %77, align 1
  %79 = zext i8 %78 to i32
  %80 = getelementptr inbounds i8, i8* %10, i64 -4
  %81 = load i8, i8* %80, align 1
  %82 = zext i8 %81 to i32
  %83 = sub nsw i32 %79, %82
  %84 = shl nsw i32 %83, 2
  %85 = add nsw i32 %84, %67
  %86 = load i8, i8* %75, align 1
  %87 = zext i8 %86 to i32
  %88 = load i8, i8* %76, align 1
  %89 = zext i8 %88 to i32
  %90 = sub nsw i32 %87, %89
  %91 = shl nsw i32 %90, 2
  %92 = add nsw i32 %91, %74
  %93 = getelementptr inbounds i8, i8* %75, i64 %8
  %94 = getelementptr inbounds i8, i8* %76, i64 %9
  %95 = getelementptr inbounds i8, i8* %10, i64 5
  %96 = load i8, i8* %95, align 1
  %97 = zext i8 %96 to i32
  %98 = getelementptr inbounds i8, i8* %10, i64 -5
  %99 = load i8, i8* %98, align 1
  %100 = zext i8 %99 to i32
  %101 = sub nsw i32 %97, %100
  %102 = mul nsw i32 %101, 5
  %103 = add nsw i32 %102, %85
  %104 = load i8, i8* %93, align 1
  %105 = zext i8 %104 to i32
  %106 = load i8, i8* %94, align 1
  %107 = zext i8 %106 to i32
  %108 = sub nsw i32 %105, %107
  %109 = mul nsw i32 %108, 5
  %110 = add nsw i32 %109, %92
  %111 = getelementptr inbounds i8, i8* %93, i64 %8
  %112 = getelementptr inbounds i8, i8* %94, i64 %9
  %113 = getelementptr inbounds i8, i8* %10, i64 6
  %114 = load i8, i8* %113, align 1
  %115 = zext i8 %114 to i32
  %116 = getelementptr inbounds i8, i8* %10, i64 -6
  %117 = load i8, i8* %116, align 1
  %118 = zext i8 %117 to i32
  %119 = sub nsw i32 %115, %118
  %120 = mul nsw i32 %119, 6
  %121 = add nsw i32 %120, %103
  %122 = load i8, i8* %111, align 1
  %123 = zext i8 %122 to i32
  %124 = load i8, i8* %112, align 1
  %125 = zext i8 %124 to i32
  %126 = sub nsw i32 %123, %125
  %127 = mul nsw i32 %126, 6
  %128 = add nsw i32 %127, %110
  %129 = getelementptr inbounds i8, i8* %111, i64 %8
  %130 = getelementptr inbounds i8, i8* %112, i64 %9
  %131 = getelementptr inbounds i8, i8* %10, i64 7
  %132 = load i8, i8* %131, align 1
  %133 = zext i8 %132 to i32
  %134 = getelementptr inbounds i8, i8* %10, i64 -7
  %135 = load i8, i8* %134, align 1
  %136 = zext i8 %135 to i32
  %137 = sub nsw i32 %133, %136
  %138 = mul nsw i32 %137, 7
  %139 = add nsw i32 %138, %121
  %140 = load i8, i8* %129, align 1
  %141 = zext i8 %140 to i32
  %142 = load i8, i8* %130, align 1
  %143 = zext i8 %142 to i32
  %144 = sub nsw i32 %141, %143
  %145 = mul nsw i32 %144, 7
  %146 = add nsw i32 %145, %128
  %147 = getelementptr inbounds i8, i8* %129, i64 %8
  %148 = getelementptr inbounds i8, i8* %130, i64 %9
  %149 = getelementptr inbounds i8, i8* %10, i64 8
  %150 = load i8, i8* %149, align 1
  %151 = zext i8 %150 to i32
  %152 = getelementptr inbounds i8, i8* %10, i64 -8
  %153 = load i8, i8* %152, align 1
  %154 = zext i8 %153 to i32
  %155 = sub nsw i32 %151, %154
  %156 = shl nsw i32 %155, 3
  %157 = add nsw i32 %156, %139
  %158 = load i8, i8* %147, align 1
  %159 = zext i8 %158 to i32
  %160 = load i8, i8* %148, align 1
  %161 = zext i8 %160 to i32
  %162 = sub nsw i32 %159, %161
  %163 = shl nsw i32 %162, 3
  %164 = add nsw i32 %163, %146
  %165 = getelementptr i8, i8* %0, i64 %35
  %166 = getelementptr i8, i8* %0, i64 %38
  %167 = icmp eq i32 %2, 0
  br i1 %167, label %175, label %168

168:                                              ; preds = %4
  %169 = sdiv i32 %157, 4
  %170 = mul nsw i32 %169, 5
  %171 = sdiv i32 %170, 16
  %172 = sdiv i32 %164, 4
  %173 = mul nsw i32 %172, 5
  %174 = sdiv i32 %173, 16
  br label %191

175:                                              ; preds = %4
  %176 = icmp eq i32 %3, 0
  br i1 %176, label %184, label %177

177:                                              ; preds = %175
  %178 = ashr i32 %157, 2
  %179 = add nsw i32 %178, %157
  %180 = ashr i32 %179, 4
  %181 = ashr i32 %164, 2
  %182 = add nsw i32 %181, %164
  %183 = ashr i32 %182, 4
  br label %191

184:                                              ; preds = %175
  %185 = mul nsw i32 %157, 5
  %186 = add nsw i32 %185, 32
  %187 = ashr i32 %186, 6
  %188 = mul nsw i32 %164, 5
  %189 = add nsw i32 %188, 32
  %190 = ashr i32 %189, 6
  br label %191

191:                                              ; preds = %177, %184, %168
  %192 = phi i32 [ %174, %168 ], [ %180, %177 ], [ %187, %184 ]
  %193 = phi i32 [ %171, %168 ], [ %183, %177 ], [ %190, %184 ]
  %194 = load i8, i8* %165, align 1
  %195 = zext i8 %194 to i32
  %196 = getelementptr inbounds i8, i8* %166, i64 16
  %197 = load i8, i8* %196, align 1
  %198 = zext i8 %197 to i32
  %199 = add nuw nsw i32 %198, %195
  %200 = shl nuw nsw i32 %199, 4
  %201 = add nsw i32 %193, %192
  %202 = mul i32 %201, -7
  %203 = add nsw i32 %202, 16
  %204 = add nsw i32 %203, %200
  %205 = shl nsw i32 %192, 1
  %206 = mul nsw i32 %192, 3
  %207 = shl nsw i32 %192, 2
  br label %208

208:                                              ; preds = %208, %191
  %209 = phi i8* [ %0, %191 ], [ %251, %208 ]
  %210 = phi i32 [ %204, %191 ], [ %250, %208 ]
  %211 = phi i32 [ 16, %191 ], [ %252, %208 ]
  %212 = add nsw i32 %210, %192
  %213 = add nsw i32 %210, %205
  %214 = add nsw i32 %210, %206
  %215 = add nsw i32 %210, %207
  %216 = add nsw i32 %215, %192
  %217 = add nsw i32 %215, %205
  %218 = add nsw i32 %215, %206
  %219 = add nsw i32 %215, %207
  %220 = add nsw i32 %219, %192
  %221 = add nsw i32 %219, %205
  %222 = add nsw i32 %219, %206
  %223 = add nsw i32 %219, %207
  %224 = add nsw i32 %223, %192
  %225 = add nsw i32 %223, %205
  %226 = add nsw i32 %223, %206
  %227 = insertelement <16 x i32> undef, i32 %210, i32 0
  %228 = insertelement <16 x i32> %227, i32 %212, i32 1
  %229 = insertelement <16 x i32> %228, i32 %213, i32 2
  %230 = insertelement <16 x i32> %229, i32 %214, i32 3
  %231 = insertelement <16 x i32> %230, i32 %215, i32 4
  %232 = insertelement <16 x i32> %231, i32 %216, i32 5
  %233 = insertelement <16 x i32> %232, i32 %217, i32 6
  %234 = insertelement <16 x i32> %233, i32 %218, i32 7
  %235 = insertelement <16 x i32> %234, i32 %219, i32 8
  %236 = insertelement <16 x i32> %235, i32 %220, i32 9
  %237 = insertelement <16 x i32> %236, i32 %221, i32 10
  %238 = insertelement <16 x i32> %237, i32 %222, i32 11
  %239 = insertelement <16 x i32> %238, i32 %223, i32 12
  %240 = insertelement <16 x i32> %239, i32 %224, i32 13
  %241 = insertelement <16 x i32> %240, i32 %225, i32 14
  %242 = insertelement <16 x i32> %241, i32 %226, i32 15
  %243 = ashr <16 x i32> %242, <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %244 = icmp ugt <16 x i32> %243, <i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255>
  %245 = ashr <16 x i32> %242, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %246 = xor <16 x i32> %245, <i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255, i32 255>
  %247 = select <16 x i1> %244, <16 x i32> %246, <16 x i32> %243
  %248 = trunc <16 x i32> %247 to <16 x i8>
  %249 = bitcast i8* %209 to <16 x i8>*
  store <16 x i8> %248, <16 x i8>* %249, align 1
  %250 = add nsw i32 %210, %193
  %251 = getelementptr inbounds i8, i8* %209, i64 %8
  %252 = add nsw i32 %211, -1
  %253 = icmp eq i32 %252, 0
  br i1 %253, label %254, label %208

254:                                              ; preds = %208
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #6

attributes #0 = { cold nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="true" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="true" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nofree norecurse nounwind ssp uwtable writeonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="true" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="true" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="true" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { noreturn nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="true" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { argmemonly nounwind }
attributes #7 = { inlinehint nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="true" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { nounwind }
attributes #9 = { noreturn nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
