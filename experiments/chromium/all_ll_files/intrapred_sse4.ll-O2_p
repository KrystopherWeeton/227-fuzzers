; ModuleID = '../../third_party/libgav1/src/src/dsp/x86/intrapred_sse4.cc'
source_filename = "../../third_party/libgav1/src/src/dsp/x86/intrapred_sse4.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%"struct.libgav1::dsp::Dsp" = type { void (i8*, i8*, i32, i32, i8*, i64)*, void (i8*, i64, i8*, i32*)*, [2 x [3 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*]], [19 x void (i8*, i64, [32 x i16]*, i32)*], [19 x [3 x void ([32 x i16]*, i32, i32, i8*, i64)*]], [2 x [2 x [2 x [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i8*, i64)*]]]], [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i32, i32, i8*, i64)*], void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i64, i8*, i8*, i32, i32, i32, i32, i1, i1)*, void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i8*, i8, i8, i32, i32, i8*, i64)*, %"struct.libgav1::dsp::FilmGrainFuncs", void (i8*, i64, i8*, i8*, i8, i32, i32)*, [3 x void (i8*, i8*, i64, i8*, i64, i32, i32)*], void (i8*, i32, i32)*, void (i8*, i32)*, [19 x [10 x void (i8*, i64, i8*, i8*)*]], [4 x [5 x [2 x void (i8, i8, i32, i8*, i32, i32, i8*)*]]], [4 x [2 x void (i8*, i64, i32, i32, i32)*]], [2 x void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)*], [3 x [2 x void (i8*, i8*, i64, i8*, i64, i32, i32, i8*, i64)*]], void (%"struct.libgav1::ReferenceInfo"*, i32, i32, i32, i32, i32, i32, %"struct.libgav1::TemporalMotionField"*)*, [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32*, i32, %"union.libgav1::CompoundMotionVector"*)*], [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32, i32, %"struct.libgav1::MotionVector"*)*], [2 x void (i8*, i64, i32, i32, i8*, i64)*], void (i32, i32, i32, i8*)*, void (i8*, i8*, i64, i32, i32, i32, i32, i32, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, [6 x [6 x [2 x void (i8*, i8*, i8*, i64)*]]] }
%"struct.libgav1::dsp::FilmGrainFuncs" = type { [3 x void (%"struct.libgav1::FilmGrainParams"*, i8*)*], [2 x [4 x void (%"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i8*, i8*)*]], [2 x void (i8*, i32, i32, i32, i32, i32, i8*)*], void (i8*, i32, i32, i32, i32, i8*)*, void (i32, i8*, i8*, i8*)*, void (i8*, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64)*, [2 x void (i8, %"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64, i8*, i64)*] }
%"struct.libgav1::FilmGrainParams" = type { i8, i8, i8, i8, i8, i8, i8, i8, [14 x i8], [14 x i8], [10 x i8], [10 x i8], [10 x i8], [10 x i8], i8, i8, [24 x i8], [25 x i8], [25 x i8], i8, i16, i32, i32, i8, i8, i16, i8, i8, i16 }
%"struct.libgav1::RestorationUnitInfo" = type { i8, %"struct.libgav1::SgrProjInfo", [16 x i8], %"struct.libgav1::WienerInfo" }
%"struct.libgav1::SgrProjInfo" = type { i32, [2 x i32] }
%"struct.libgav1::WienerInfo" = type { [2 x i16], [28 x i8], [2 x [4 x i16]], [16 x i8] }
%"union.libgav1::RestorationBuffer" = type { %"struct.libgav1::SgrBuffer", [5024 x i8] }
%"struct.libgav1::SgrBuffer" = type { [1152 x i16], [1440 x i16], [1152 x i32], [1440 x i32], [1024 x i16], [768 x i16], [512 x i16], [1024 x i32], [768 x i32], [512 x i32], [288 x i8], [288 x i32] }
%"struct.libgav1::ReferenceInfo" = type { %"struct.std::__1::array", %"struct.std::__1::array.0", %"struct.std::__1::array.0", %"struct.std::__1::array.1", %"struct.std::__1::array.2", %"class.libgav1::Array2D", %"class.libgav1::Array2D.4" }
%"struct.std::__1::array" = type { [8 x i8] }
%"struct.std::__1::array.0" = type { [8 x i8] }
%"struct.std::__1::array.1" = type { [8 x i8] }
%"struct.std::__1::array.2" = type { [8 x i16] }
%"class.libgav1::Array2D" = type { %"class.std::__1::unique_ptr", i64, i64, %"class.libgav1::Array2DView" }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { i8* }
%"class.libgav1::Array2DView" = type { i32, i32, i8* }
%"class.libgav1::Array2D.4" = type { %"class.std::__1::unique_ptr.5", i64, i64, %"class.libgav1::Array2DView.11" }
%"class.std::__1::unique_ptr.5" = type { %"class.std::__1::__compressed_pair.6" }
%"class.std::__1::__compressed_pair.6" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::__compressed_pair_elem.7" = type { %"struct.libgav1::MotionVector"* }
%"struct.libgav1::MotionVector" = type { %union.anon }
%union.anon = type { i32 }
%"class.libgav1::Array2DView.11" = type { i32, i32, %"struct.libgav1::MotionVector"* }
%"struct.libgav1::TemporalMotionField" = type { %"class.libgav1::Array2D.4", %"class.libgav1::Array2D.12" }
%"class.libgav1::Array2D.12" = type { %"class.std::__1::unique_ptr.13", i64, i64, %"class.libgav1::Array2DView.19" }
%"class.std::__1::unique_ptr.13" = type { %"class.std::__1::__compressed_pair.14" }
%"class.std::__1::__compressed_pair.14" = type { %"struct.std::__1::__compressed_pair_elem.15" }
%"struct.std::__1::__compressed_pair_elem.15" = type { i8* }
%"class.libgav1::Array2DView.19" = type { i32, i32, i8* }
%"union.libgav1::CompoundMotionVector" = type { i64 }

@_ZN7libgav116kFilterIntraTapsE = external local_unnamed_addr constant [5 x [8 x [8 x i8]]], align 16
@_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_137kDirectionalZone2ShuffleInvalidHeightE = internal unnamed_addr constant [16 x i32] [i32 1024, i32 1024, i32 16, i32 16, i32 16, i32 16, i32 0, i32 0, i32 18, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 40], align 16

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN7libgav13dsp20IntraPredInit_SSE4_1Ev() local_unnamed_addr #0 {
  %1 = tail call %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32 8) #11
  %2 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 12
  store void (i8*, i64, i8*, i8*, i8, i32, i32)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127FilterIntraPredictor_SSE4_1EPvlPKvS5_NS_20FilterIntraPredictorEii, void (i8*, i64, i8*, i8*, i8, i32, i32)** %2, align 8
  %3 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 7
  store void (i8*, i64, i8*, i32, i32, i32, i1)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_137DirectionalIntraPredictorZone1_SSE4_1EPvlPKviiib, void (i8*, i64, i8*, i32, i32, i32, i1)** %3, align 8
  %4 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 8
  store void (i8*, i64, i8*, i8*, i32, i32, i32, i32, i1, i1)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_137DirectionalIntraPredictorZone2_SSE4_1EPvlPKvS5_iiiibb, void (i8*, i64, i8*, i8*, i32, i32, i32, i32, i1, i1)** %4, align 8
  %5 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 9
  store void (i8*, i64, i8*, i32, i32, i32, i1)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_137DirectionalIntraPredictorZone3_SSE4_1EPvlPKviiib, void (i8*, i64, i8*, i32, i32, i32, i1)** %5, align 8
  %6 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 0, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi4EEEvPvlDv2_xEELi0ELi0EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %6, align 8
  %7 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 1, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi8EEEvPvlDv2_xEELi2ELi21846EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %7, align 8
  %8 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 2, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi16EEEvPvlDv2_xEELi2ELi13108EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %8, align 8
  %9 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 3, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi4EEEvPvlDv2_xEELi2ELi21846EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %9, align 8
  %10 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 4, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi8EEEvPvlDv2_xEELi0ELi0EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %10, align 8
  %11 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 5, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi16EEEvPvlDv2_xEELi3ELi21846EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %11, align 8
  %12 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 6, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi32EEEvPvlDv2_xEELi3ELi13108EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %12, align 8
  %13 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 7, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi4EEEvPvlDv2_xEELi2ELi13108EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %13, align 8
  %14 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 8, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi8EEEvPvlDv2_xEELi3ELi21846EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %14, align 8
  %15 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 9, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi16EEEvPvlDv2_xEELi0ELi0EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %15, align 8
  %16 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 10, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi32EEEvPvlDv2_xEELi4ELi21846EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %16, align 8
  %17 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 11, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi64EEEvPvlDv2_xEELi4ELi13108EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %17, align 8
  %18 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 12, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi8EEEvPvlDv2_xEELi3ELi13108EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %18, align 8
  %19 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 13, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi16EEEvPvlDv2_xEELi4ELi21846EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %19, align 8
  %20 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 14, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi32EEEvPvlDv2_xEELi0ELi0EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %20, align 8
  %21 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 15, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi64EEEvPvlDv2_xEELi5ELi21846EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %21, align 8
  %22 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 16, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi16EEEvPvlDv2_xEELi4ELi13108EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %22, align 8
  %23 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 17, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi32EEEvPvlDv2_xEELi5ELi21846EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %23, align 8
  %24 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 18, i64 1
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi64EEEvPvlDv2_xEELi0ELi0EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %24, align 8
  %25 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 0, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi4EEEvPvlDv2_xEELi0ELi0EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %25, align 8
  %26 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 1, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi8EEEvPvlDv2_xEELi2ELi21846EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %26, align 8
  %27 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 2, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi16EEEvPvlDv2_xEELi2ELi13108EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %27, align 8
  %28 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 3, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi4EEEvPvlDv2_xEELi2ELi21846EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %28, align 8
  %29 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 4, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi8EEEvPvlDv2_xEELi0ELi0EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %29, align 8
  %30 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 5, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi16EEEvPvlDv2_xEELi3ELi21846EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %30, align 8
  %31 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 6, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi32EEEvPvlDv2_xEELi3ELi13108EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %31, align 8
  %32 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 7, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi4EEEvPvlDv2_xEELi2ELi13108EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %32, align 8
  %33 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 8, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi8EEEvPvlDv2_xEELi3ELi21846EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %33, align 8
  %34 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 9, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi16EEEvPvlDv2_xEELi0ELi0EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %34, align 8
  %35 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 10, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi32EEEvPvlDv2_xEELi4ELi21846EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %35, align 8
  %36 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 11, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi64EEEvPvlDv2_xEELi4ELi13108EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %36, align 8
  %37 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 12, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi8EEEvPvlDv2_xEELi3ELi13108EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %37, align 8
  %38 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 13, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi16EEEvPvlDv2_xEELi4ELi21846EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %38, align 8
  %39 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 14, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi32EEEvPvlDv2_xEELi0ELi0EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %39, align 8
  %40 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 15, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi64EEEvPvlDv2_xEELi5ELi21846EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %40, align 8
  %41 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 16, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi16EEEvPvlDv2_xEELi4ELi13108EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %41, align 8
  %42 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 17, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi32EEEvPvlDv2_xEELi5ELi21846EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %42, align 8
  %43 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 18, i64 2
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi64EEEvPvlDv2_xEELi0ELi0EE6DcLeftES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %43, align 8
  %44 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 0, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi4EEEvPvlDv2_xEELi0ELi0EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %44, align 8
  %45 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 1, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi8EEEvPvlDv2_xEELi2ELi21846EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %45, align 8
  %46 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 2, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi16EEEvPvlDv2_xEELi2ELi13108EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %46, align 8
  %47 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 3, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi4EEEvPvlDv2_xEELi2ELi21846EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %47, align 8
  %48 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 4, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi8EEEvPvlDv2_xEELi0ELi0EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %48, align 8
  %49 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 5, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi16EEEvPvlDv2_xEELi3ELi21846EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %49, align 8
  %50 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 6, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi32EEEvPvlDv2_xEELi3ELi13108EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %50, align 8
  %51 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 7, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi4EEEvPvlDv2_xEELi2ELi13108EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %51, align 8
  %52 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 8, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi8EEEvPvlDv2_xEELi3ELi21846EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %52, align 8
  %53 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 9, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi16EEEvPvlDv2_xEELi0ELi0EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %53, align 8
  %54 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 10, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi32EEEvPvlDv2_xEELi4ELi21846EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %54, align 8
  %55 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 11, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi64EEEvPvlDv2_xEELi4ELi13108EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %55, align 8
  %56 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 12, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi8EEEvPvlDv2_xEELi3ELi13108EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %56, align 8
  %57 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 13, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi16EEEvPvlDv2_xEELi4ELi21846EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %57, align 8
  %58 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 14, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi32EEEvPvlDv2_xEELi0ELi0EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %58, align 8
  %59 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 15, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi64EEEvPvlDv2_xEELi5ELi21846EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %59, align 8
  %60 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 16, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi16EEEvPvlDv2_xEELi4ELi13108EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %60, align 8
  %61 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 17, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi32EEEvPvlDv2_xEELi5ELi21846EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %61, align 8
  %62 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 18, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi64EEEvPvlDv2_xEELi0ELi0EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %62, align 8
  %63 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 0, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115Paeth4x4_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %63, align 8
  %64 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 1, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115Paeth4x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %64, align 8
  %65 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 2, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth4x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %65, align 8
  %66 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 3, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115Paeth8x4_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %66, align 8
  %67 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 4, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115Paeth8x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %67, align 8
  %68 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 5, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth8x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %68, align 8
  %69 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 6, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth8x32_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %69, align 8
  %70 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 7, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth16x4_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %70, align 8
  %71 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 8, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth16x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %71, align 8
  %72 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 9, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth16x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %72, align 8
  %73 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 10, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth16x32_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %73, align 8
  %74 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 11, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth16x64_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %74, align 8
  %75 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 12, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth32x8_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %75, align 8
  %76 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 13, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth32x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %76, align 8
  %77 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 14, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth32x32_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %77, align 8
  %78 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 15, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth32x64_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %78, align 8
  %79 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 16, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth64x16_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %79, align 8
  %80 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 17, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth64x32_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %80, align 8
  %81 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 18, i64 6
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth64x64_SSE4_1EPvlPKvS5_, void (i8*, i64, i8*, i8*)** %81, align 8
  %82 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 0, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore4_SSE4_1IXadL_ZNS4_17WriteDuplicate4x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %82, align 8
  %83 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 1, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_17WriteDuplicate4x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %83, align 8
  %84 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 2, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_17WriteDuplicate4x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %84, align 8
  %85 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 3, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore4_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %85, align 8
  %86 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 4, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %86, align 8
  %87 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 5, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %87, align 8
  %88 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 6, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %88, align 8
  %89 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 7, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore4_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %89, align 8
  %90 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 8, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %90, align 8
  %91 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 9, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %91, align 8
  %92 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 10, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %92, align 8
  %93 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 11, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore64_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %93, align 8
  %94 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 12, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %94, align 8
  %95 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 13, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %95, align 8
  %96 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 14, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %96, align 8
  %97 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 15, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore64_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %97, align 8
  %98 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 16, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_18WriteDuplicate64x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %98, align 8
  %99 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 17, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_18WriteDuplicate64x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %99, align 8
  %100 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 16, i64 18, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore64_SSE4_1IXadL_ZNS4_18WriteDuplicate64x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %100, align 8
  %101 = tail call %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32 10) #11
  %102 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 7
  store void (i8*, i64, i8*, i32, i32, i32, i1)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_137DirectionalIntraPredictorZone1_SSE4_1EPvlPKviiib, void (i8*, i64, i8*, i32, i32, i32, i1)** %102, align 8
  %103 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 0, i64 1
  %104 = bitcast void (i8*, i64, i8*, i8*)** %103 to <2 x void (i8*, i64, i8*, i8*)*>*
  store <2 x void (i8*, i64, i8*, i8*)*> <void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi2EXadL_ZNS0_13high_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi4EEEvPvlDv2_xEELi0ELi0EE5DcTopES8_lS6_S6_, void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi2EXadL_ZNS0_13high_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi4EEEvPvlDv2_xEELi0ELi0EE6DcLeftES8_lS6_S6_>, <2 x void (i8*, i64, i8*, i8*)*>* %104, align 8
  %105 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 0, i64 3
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi2EXadL_ZNS0_13high_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi4EEEvPvlDv2_xEELi0ELi0EE2DcES8_lS6_S6_, void (i8*, i64, i8*, i8*)** %105, align 8
  %106 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 0, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore4_SSE4_1IXadL_ZNS4_17WriteDuplicate4x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %106, align 8
  %107 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 1, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_17WriteDuplicate4x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %107, align 8
  %108 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 2, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_17WriteDuplicate4x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %108, align 8
  %109 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 3, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore4_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %109, align 8
  %110 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 4, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %110, align 8
  %111 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 5, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %111, align 8
  %112 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 6, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %112, align 8
  %113 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 7, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore4_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %113, align 8
  %114 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 8, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %114, align 8
  %115 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 9, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %115, align 8
  %116 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 10, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %116, align 8
  %117 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 11, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore64_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %117, align 8
  %118 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 12, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %118, align 8
  %119 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 13, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %119, align 8
  %120 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 14, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %120, align 8
  %121 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 15, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore64_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %121, align 8
  %122 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 16, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_18WriteDuplicate64x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %122, align 8
  %123 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 17, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_18WriteDuplicate64x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %123, align 8
  %124 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %101, i64 0, i32 16, i64 18, i64 5
  store void (i8*, i64, i8*, i8*)* @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore64_SSE4_1IXadL_ZNS4_18WriteDuplicate64x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_, void (i8*, i64, i8*, i8*)** %124, align 8
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

declare %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_127FilterIntraPredictor_SSE4_1EPvlPKvS5_NS_20FilterIntraPredictorEii(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly, i8 zeroext, i32, i32) #3 {
  %8 = icmp eq i32 %5, 4
  %9 = zext i8 %4 to i64
  %10 = getelementptr inbounds [5 x [8 x [8 x i8]]], [5 x [8 x [8 x i8]]]* @_ZN7libgav116kFilterIntraTapsE, i64 0, i64 %9, i64 0, i64 0
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 16
  %13 = getelementptr inbounds [5 x [8 x [8 x i8]]], [5 x [8 x [8 x i8]]]* @_ZN7libgav116kFilterIntraTapsE, i64 0, i64 %9, i64 2, i64 0
  %14 = bitcast i8* %13 to <16 x i8>*
  %15 = load <16 x i8>, <16 x i8>* %14, align 16
  %16 = getelementptr inbounds [5 x [8 x [8 x i8]]], [5 x [8 x [8 x i8]]]* @_ZN7libgav116kFilterIntraTapsE, i64 0, i64 %9, i64 4, i64 0
  %17 = bitcast i8* %16 to <16 x i8>*
  %18 = load <16 x i8>, <16 x i8>* %17, align 16
  %19 = getelementptr inbounds [5 x [8 x [8 x i8]]], [5 x [8 x [8 x i8]]]* @_ZN7libgav116kFilterIntraTapsE, i64 0, i64 %9, i64 6, i64 0
  %20 = bitcast i8* %19 to <16 x i8>*
  %21 = load <16 x i8>, <16 x i8>* %20, align 16
  %22 = getelementptr inbounds i8, i8* %2, i64 -1
  br i1 %8, label %23, label %278

23:                                               ; preds = %7
  %24 = bitcast i8* %22 to i32*
  %25 = load i32, i32* %24, align 1
  %26 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %25, i32 0
  %27 = bitcast <4 x i32> %26 to <16 x i8>
  %28 = getelementptr inbounds i8, i8* %2, i64 3
  %29 = load i8, i8* %28, align 1
  %30 = insertelement <16 x i8> %27, i8 %29, i64 4
  %31 = icmp eq i32 %6, 4
  br i1 %31, label %32, label %37

32:                                               ; preds = %23
  %33 = bitcast i8* %3 to i32*
  %34 = load i32, i32* %33, align 1
  %35 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %34, i32 0
  %36 = bitcast <4 x i32> %35 to <2 x i64>
  br label %41

37:                                               ; preds = %23
  %38 = bitcast i8* %3 to i64*
  %39 = load i64, i64* %38, align 1
  %40 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %39, i32 0
  br label %41

41:                                               ; preds = %37, %32
  %42 = phi <2 x i64> [ %36, %32 ], [ %40, %37 ]
  %43 = bitcast <2 x i64> %42 to <16 x i8>
  %44 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %43, <16 x i32> <i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26>
  %45 = or <16 x i8> %44, %30
  %46 = bitcast <16 x i8> %45 to <4 x i32>
  %47 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> <i32 0, i32 1, i32 0, i32 1>
  %48 = bitcast <4 x i32> %47 to <16 x i8>
  %49 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %48, <16 x i8> %12) #11
  %50 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %48, <16 x i8> %15) #11
  %51 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %49, <8 x i16> %50) #11
  %52 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %51, <8 x i16> %51) #11
  %53 = add <8 x i16> %52, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %54 = ashr <8 x i16> %53, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %55 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> undef) #11
  %56 = bitcast <16 x i8> %55 to <4 x i32>
  %57 = extractelement <4 x i32> %56, i32 0
  %58 = bitcast i8* %0 to i32*
  store i32 %57, i32* %58, align 1
  %59 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %48, <16 x i8> %18) #11
  %60 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %48, <16 x i8> %21) #11
  %61 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %59, <8 x i16> %60) #11
  %62 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %61, <8 x i16> %61) #11
  %63 = add <8 x i16> %62, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %64 = ashr <8 x i16> %63, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %65 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %64, <8 x i16> undef) #11
  %66 = getelementptr inbounds i8, i8* %0, i64 %1
  %67 = bitcast <16 x i8> %65 to <4 x i32>
  %68 = extractelement <4 x i32> %67, i32 0
  %69 = bitcast i8* %66 to i32*
  store i32 %68, i32* %69, align 1
  %70 = shufflevector <4 x i32> %67, <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, <4 x i32> <i32 0, i32 5, i32 6, i32 7>
  %71 = bitcast <4 x i32> %70 to <16 x i8>
  %72 = or <16 x i8> %44, %71
  %73 = shufflevector <16 x i8> %72, <16 x i8> undef, <16 x i32> <i32 6, i32 0, i32 1, i32 2, i32 3, i32 7, i32 8, i32 15, i32 6, i32 0, i32 1, i32 2, i32 3, i32 7, i32 8, i32 15>
  %74 = getelementptr inbounds i8, i8* %66, i64 %1
  %75 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %73, <16 x i8> %12) #11
  %76 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %73, <16 x i8> %15) #11
  %77 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %75, <8 x i16> %76) #11
  %78 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %77, <8 x i16> %77) #11
  %79 = add <8 x i16> %78, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %80 = ashr <8 x i16> %79, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %81 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %80, <8 x i16> undef) #11
  %82 = bitcast <16 x i8> %81 to <4 x i32>
  %83 = extractelement <4 x i32> %82, i32 0
  %84 = bitcast i8* %74 to i32*
  store i32 %83, i32* %84, align 1
  %85 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %73, <16 x i8> %18) #11
  %86 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %73, <16 x i8> %21) #11
  %87 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %85, <8 x i16> %86) #11
  %88 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %87, <8 x i16> %87) #11
  %89 = add <8 x i16> %88, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %90 = ashr <8 x i16> %89, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %91 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %90, <8 x i16> undef) #11
  %92 = getelementptr inbounds i8, i8* %74, i64 %1
  %93 = bitcast <16 x i8> %91 to <4 x i32>
  %94 = extractelement <4 x i32> %93, i32 0
  %95 = bitcast i8* %92 to i32*
  store i32 %94, i32* %95, align 1
  %96 = icmp eq i32 %6, 16
  br i1 %96, label %97, label %214

97:                                               ; preds = %41
  %98 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0>, <16 x i8> %44, <16 x i32> <i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25, i32 26, i32 27, i32 28, i32 29, i32 30>
  %99 = shufflevector <4 x i32> %93, <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, <4 x i32> <i32 0, i32 undef, i32 6, i32 7>
  %100 = bitcast <4 x i32> %99 to <16 x i8>
  %101 = or <16 x i8> %98, %100
  %102 = shufflevector <16 x i8> %101, <16 x i8> undef, <16 x i32> <i32 9, i32 0, i32 1, i32 2, i32 3, i32 10, i32 11, i32 15, i32 9, i32 0, i32 1, i32 2, i32 3, i32 10, i32 11, i32 15>
  %103 = getelementptr inbounds i8, i8* %92, i64 %1
  %104 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %102, <16 x i8> %12) #11
  %105 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %102, <16 x i8> %15) #11
  %106 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %104, <8 x i16> %105) #11
  %107 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %106, <8 x i16> %106) #11
  %108 = add <8 x i16> %107, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %109 = ashr <8 x i16> %108, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %110 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %109, <8 x i16> undef) #11
  %111 = bitcast <16 x i8> %110 to <4 x i32>
  %112 = extractelement <4 x i32> %111, i32 0
  %113 = bitcast i8* %103 to i32*
  store i32 %112, i32* %113, align 1
  %114 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %102, <16 x i8> %18) #11
  %115 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %102, <16 x i8> %21) #11
  %116 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %114, <8 x i16> %115) #11
  %117 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %116, <8 x i16> %116) #11
  %118 = add <8 x i16> %117, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %119 = ashr <8 x i16> %118, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %120 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %119, <8 x i16> undef) #11
  %121 = getelementptr inbounds i8, i8* %103, i64 %1
  %122 = bitcast <16 x i8> %120 to <4 x i32>
  %123 = extractelement <4 x i32> %122, i32 0
  %124 = bitcast i8* %121 to i32*
  store i32 %123, i32* %124, align 1
  %125 = shufflevector <16 x i8> %98, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %126 = shufflevector <4 x i32> %122, <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, <4 x i32> <i32 0, i32 undef, i32 6, i32 7>
  %127 = shufflevector <16 x i8> %98, <16 x i8> <i8 undef, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 11, i32 12, i32 13, i32 undef, i32 undef, i32 undef, i32 17>
  %128 = getelementptr inbounds i8, i8* %3, i64 8
  %129 = bitcast i8* %128 to i64*
  %130 = load i64, i64* %129, align 1
  %131 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %130, i32 0
  %132 = bitcast <4 x i32> %126 to <16 x i8>
  %133 = or <16 x i8> %127, %132
  %134 = shufflevector <16 x i8> %133, <16 x i8> undef, <16 x i32> <i32 9, i32 0, i32 1, i32 2, i32 3, i32 10, i32 11, i32 15, i32 9, i32 0, i32 1, i32 2, i32 3, i32 10, i32 11, i32 15>
  %135 = getelementptr inbounds i8, i8* %121, i64 %1
  %136 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %134, <16 x i8> %12) #11
  %137 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %134, <16 x i8> %15) #11
  %138 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %136, <8 x i16> %137) #11
  %139 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %138, <8 x i16> %138) #11
  %140 = add <8 x i16> %139, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %141 = ashr <8 x i16> %140, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %142 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %141, <8 x i16> undef) #11
  %143 = bitcast <16 x i8> %142 to <4 x i32>
  %144 = extractelement <4 x i32> %143, i32 0
  %145 = bitcast i8* %135 to i32*
  store i32 %144, i32* %145, align 1
  %146 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %134, <16 x i8> %18) #11
  %147 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %134, <16 x i8> %21) #11
  %148 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %146, <8 x i16> %147) #11
  %149 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %148, <8 x i16> %148) #11
  %150 = add <8 x i16> %149, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %151 = ashr <8 x i16> %150, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %152 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %151, <8 x i16> undef) #11
  %153 = getelementptr inbounds i8, i8* %135, i64 %1
  %154 = bitcast <16 x i8> %152 to <4 x i32>
  %155 = extractelement <4 x i32> %154, i32 0
  %156 = bitcast i8* %153 to i32*
  store i32 %155, i32* %156, align 1
  %157 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %125, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %158 = shufflevector <4 x i32> %154, <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, <4 x i32> <i32 0, i32 5, i32 6, i32 7>
  %159 = bitcast <2 x i64> %131 to <16 x i8>
  %160 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %159, <16 x i32> <i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24>
  %161 = or <16 x i8> %160, %157
  %162 = bitcast <4 x i32> %158 to <16 x i8>
  %163 = or <16 x i8> %161, %162
  %164 = shufflevector <16 x i8> %163, <16 x i8> undef, <16 x i32> <i32 6, i32 0, i32 1, i32 2, i32 3, i32 7, i32 8, i32 15, i32 6, i32 0, i32 1, i32 2, i32 3, i32 7, i32 8, i32 15>
  %165 = getelementptr inbounds i8, i8* %153, i64 %1
  %166 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %164, <16 x i8> %12) #11
  %167 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %164, <16 x i8> %15) #11
  %168 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %166, <8 x i16> %167) #11
  %169 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %168, <8 x i16> %168) #11
  %170 = add <8 x i16> %169, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %171 = ashr <8 x i16> %170, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %172 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %171, <8 x i16> undef) #11
  %173 = bitcast <16 x i8> %172 to <4 x i32>
  %174 = extractelement <4 x i32> %173, i32 0
  %175 = bitcast i8* %165 to i32*
  store i32 %174, i32* %175, align 1
  %176 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %164, <16 x i8> %18) #11
  %177 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %164, <16 x i8> %21) #11
  %178 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %176, <8 x i16> %177) #11
  %179 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %178, <8 x i16> %178) #11
  %180 = add <8 x i16> %179, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %181 = ashr <8 x i16> %180, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %182 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %181, <8 x i16> undef) #11
  %183 = getelementptr inbounds i8, i8* %165, i64 %1
  %184 = bitcast <16 x i8> %182 to <4 x i32>
  %185 = extractelement <4 x i32> %184, i32 0
  %186 = bitcast i8* %183 to i32*
  store i32 %185, i32* %186, align 1
  %187 = shufflevector <4 x i32> %184, <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, <4 x i32> <i32 0, i32 5, i32 6, i32 7>
  %188 = shufflevector <16 x i8> %161, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %189 = bitcast <4 x i32> %187 to <16 x i8>
  %190 = or <16 x i8> %188, %189
  %191 = shufflevector <16 x i8> %190, <16 x i8> undef, <16 x i32> <i32 6, i32 0, i32 1, i32 2, i32 3, i32 7, i32 8, i32 15, i32 6, i32 0, i32 1, i32 2, i32 3, i32 7, i32 8, i32 15>
  %192 = getelementptr inbounds i8, i8* %183, i64 %1
  %193 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %191, <16 x i8> %12) #11
  %194 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %191, <16 x i8> %15) #11
  %195 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %193, <8 x i16> %194) #11
  %196 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %195, <8 x i16> %195) #11
  %197 = add <8 x i16> %196, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %198 = ashr <8 x i16> %197, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %199 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %198, <8 x i16> undef) #11
  %200 = bitcast <16 x i8> %199 to <4 x i32>
  %201 = extractelement <4 x i32> %200, i32 0
  %202 = bitcast i8* %192 to i32*
  store i32 %201, i32* %202, align 1
  %203 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %191, <16 x i8> %18) #11
  %204 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %191, <16 x i8> %21) #11
  %205 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %203, <8 x i16> %204) #11
  %206 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %205, <8 x i16> %205) #11
  %207 = add <8 x i16> %206, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %208 = ashr <8 x i16> %207, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %209 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %208, <8 x i16> undef) #11
  %210 = getelementptr inbounds i8, i8* %192, i64 %1
  %211 = bitcast <16 x i8> %209 to <4 x i32>
  %212 = extractelement <4 x i32> %211, i32 0
  %213 = bitcast i8* %210 to i32*
  store i32 %212, i32* %213, align 1
  br label %216

214:                                              ; preds = %41
  %215 = icmp sgt i32 %6, 4
  br i1 %215, label %216, label %607

216:                                              ; preds = %214, %97
  %217 = phi i32 [ %212, %97 ], [ %94, %214 ]
  %218 = phi i8* [ %165, %97 ], [ %0, %214 ]
  %219 = phi <16 x i8> [ %188, %97 ], [ %44, %214 ]
  %220 = getelementptr inbounds i8, i8* %218, i64 %1
  %221 = getelementptr inbounds i8, i8* %220, i64 %1
  %222 = getelementptr inbounds i8, i8* %221, i64 %1
  %223 = shufflevector <16 x i8> %219, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %224 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %223, <16 x i32> <i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23, i32 24, i32 25>
  %225 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %217, i32 0
  %226 = bitcast <4 x i32> %225 to <16 x i8>
  %227 = or <16 x i8> %224, %226
  %228 = shufflevector <16 x i8> %227, <16 x i8> undef, <16 x i32> <i32 6, i32 0, i32 1, i32 2, i32 3, i32 7, i32 8, i32 15, i32 6, i32 0, i32 1, i32 2, i32 3, i32 7, i32 8, i32 15>
  %229 = getelementptr inbounds i8, i8* %222, i64 %1
  %230 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %228, <16 x i8> %12) #11
  %231 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %228, <16 x i8> %15) #11
  %232 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %230, <8 x i16> %231) #11
  %233 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %232, <8 x i16> %232) #11
  %234 = add <8 x i16> %233, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %235 = ashr <8 x i16> %234, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %236 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %235, <8 x i16> undef) #11
  %237 = bitcast <16 x i8> %236 to <4 x i32>
  %238 = extractelement <4 x i32> %237, i32 0
  %239 = bitcast i8* %229 to i32*
  store i32 %238, i32* %239, align 1
  %240 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %228, <16 x i8> %18) #11
  %241 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %228, <16 x i8> %21) #11
  %242 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %240, <8 x i16> %241) #11
  %243 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %242, <8 x i16> %242) #11
  %244 = add <8 x i16> %243, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %245 = ashr <8 x i16> %244, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %246 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %245, <8 x i16> undef) #11
  %247 = getelementptr inbounds i8, i8* %229, i64 %1
  %248 = bitcast <16 x i8> %246 to <4 x i32>
  %249 = extractelement <4 x i32> %248, i32 0
  %250 = bitcast i8* %247 to i32*
  store i32 %249, i32* %250, align 1
  %251 = shufflevector <4 x i32> %248, <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, <4 x i32> <i32 0, i32 5, i32 6, i32 7>
  %252 = shufflevector <16 x i8> %224, <16 x i8> <i8 undef, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 undef, i32 undef, i32 8, i32 9, i32 10, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 17>
  %253 = bitcast <4 x i32> %251 to <16 x i8>
  %254 = or <16 x i8> %252, %253
  %255 = shufflevector <16 x i8> %254, <16 x i8> undef, <16 x i32> <i32 6, i32 0, i32 1, i32 2, i32 3, i32 7, i32 8, i32 15, i32 6, i32 0, i32 1, i32 2, i32 3, i32 7, i32 8, i32 15>
  %256 = getelementptr inbounds i8, i8* %247, i64 %1
  %257 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %255, <16 x i8> %12) #11
  %258 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %255, <16 x i8> %15) #11
  %259 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %257, <8 x i16> %258) #11
  %260 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %259, <8 x i16> %259) #11
  %261 = add <8 x i16> %260, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %262 = ashr <8 x i16> %261, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %263 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %262, <8 x i16> undef) #11
  %264 = bitcast <16 x i8> %263 to <4 x i32>
  %265 = extractelement <4 x i32> %264, i32 0
  %266 = bitcast i8* %256 to i32*
  store i32 %265, i32* %266, align 1
  %267 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %255, <16 x i8> %18) #11
  %268 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %255, <16 x i8> %21) #11
  %269 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %267, <8 x i16> %268) #11
  %270 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %269, <8 x i16> %269) #11
  %271 = add <8 x i16> %270, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %272 = ashr <8 x i16> %271, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %273 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %272, <8 x i16> undef) #11
  %274 = getelementptr inbounds i8, i8* %256, i64 %1
  %275 = bitcast <16 x i8> %273 to <4 x i32>
  %276 = extractelement <4 x i32> %275, i32 0
  %277 = bitcast i8* %274 to i32*
  store i32 %276, i32* %277, align 1
  br label %607

278:                                              ; preds = %7
  %279 = bitcast i8* %22 to i64*
  %280 = load i64, i64* %279, align 1
  %281 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %280, i32 0
  %282 = bitcast i8* %3 to i32*
  %283 = load i32, i32* %282, align 1
  %284 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %283, i32 0
  %285 = bitcast <4 x i32> %284 to <16 x i8>
  %286 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %285, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %287 = bitcast <2 x i64> %281 to <16 x i8>
  %288 = or <16 x i8> %286, %287
  %289 = shufflevector <16 x i8> %288, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 8, i32 9, i32 15, i32 0, i32 1, i32 2, i32 3, i32 4, i32 8, i32 9, i32 15>
  %290 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %289, <16 x i8> %12) #11
  %291 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %289, <16 x i8> %15) #11
  %292 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %290, <8 x i16> %291) #11
  %293 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %292, <8 x i16> %292) #11
  %294 = add <8 x i16> %293, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %295 = ashr <8 x i16> %294, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %296 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %295, <8 x i16> undef) #11
  %297 = bitcast <16 x i8> %296 to <4 x i32>
  %298 = extractelement <4 x i32> %297, i32 0
  %299 = bitcast i8* %0 to i32*
  store i32 %298, i32* %299, align 1
  %300 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %289, <16 x i8> %18) #11
  %301 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %289, <16 x i8> %21) #11
  %302 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %300, <8 x i16> %301) #11
  %303 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %302, <8 x i16> %302) #11
  %304 = add <8 x i16> %303, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %305 = ashr <8 x i16> %304, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %306 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %305, <8 x i16> undef) #11
  %307 = getelementptr inbounds i8, i8* %0, i64 %1
  %308 = bitcast <16 x i8> %306 to <4 x i32>
  %309 = extractelement <4 x i32> %308, i32 0
  %310 = bitcast i8* %307 to i32*
  store i32 %309, i32* %310, align 1
  %311 = shufflevector <16 x i8> %286, <16 x i8> <i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 1, i32 2, i32 3, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 9, i32 10, i32 11, i32 undef, i32 undef, i32 undef, i32 undef, i32 16>
  %312 = shufflevector <4 x i32> %308, <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, <4 x i32> <i32 0, i32 undef, i32 6, i32 7>
  %313 = bitcast <4 x i32> %312 to <16 x i8>
  %314 = or <16 x i8> %311, %313
  %315 = shufflevector <16 x i8> %314, <16 x i8> undef, <16 x i32> <i32 8, i32 0, i32 1, i32 2, i32 3, i32 9, i32 10, i32 15, i32 8, i32 0, i32 1, i32 2, i32 3, i32 9, i32 10, i32 15>
  %316 = shl i64 %1, 1
  %317 = shl i64 %1, 2
  %318 = getelementptr inbounds i8, i8* %0, i64 %316
  %319 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %315, <16 x i8> %12) #11
  %320 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %315, <16 x i8> %15) #11
  %321 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %319, <8 x i16> %320) #11
  %322 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %321, <8 x i16> %321) #11
  %323 = add <8 x i16> %322, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %324 = ashr <8 x i16> %323, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %325 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %324, <8 x i16> undef) #11
  %326 = bitcast <16 x i8> %325 to <4 x i32>
  %327 = extractelement <4 x i32> %326, i32 0
  %328 = bitcast i8* %318 to i32*
  store i32 %327, i32* %328, align 1
  %329 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %315, <16 x i8> %18) #11
  %330 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %315, <16 x i8> %21) #11
  %331 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %329, <8 x i16> %330) #11
  %332 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %331, <8 x i16> %331) #11
  %333 = add <8 x i16> %332, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %334 = ashr <8 x i16> %333, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %335 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %334, <8 x i16> undef) #11
  %336 = getelementptr inbounds i8, i8* %318, i64 %1
  %337 = bitcast <16 x i8> %335 to <4 x i32>
  %338 = extractelement <4 x i32> %337, i32 0
  %339 = bitcast i8* %336 to i32*
  store i32 %338, i32* %339, align 1
  %340 = add nsw i32 %5, -4
  %341 = icmp sgt i32 %340, 3
  br i1 %341, label %342, label %349

342:                                              ; preds = %278
  %343 = add nsw i64 %1, -1
  %344 = add nsw i64 %1, 3
  %345 = add nsw i64 %316, -1
  %346 = mul i64 %1, 3
  %347 = add nsw i64 %346, -1
  %348 = sext i32 %340 to i64
  br label %365

349:                                              ; preds = %365, %278
  %350 = phi i8* [ %0, %278 ], [ %368, %365 ]
  %351 = icmp sgt i32 %6, 4
  br i1 %351, label %352, label %607

352:                                              ; preds = %349
  %353 = sext i32 %5 to i64
  %354 = sub nsw i64 0, %353
  %355 = sub i64 0, %1
  %356 = getelementptr inbounds i8, i8* %3, i64 -1
  %357 = icmp sgt i32 %5, 4
  %358 = sub i64 3, %1
  %359 = add nsw i64 %1, -1
  %360 = add nsw i64 %1, 3
  %361 = add nsw i64 %316, -1
  %362 = mul i64 %1, 3
  %363 = add nsw i64 %362, -1
  %364 = sext i32 %6 to i64
  br label %448

365:                                              ; preds = %342, %365
  %366 = phi i64 [ 3, %342 ], [ %374, %365 ]
  %367 = phi i8* [ %0, %342 ], [ %368, %365 ]
  %368 = getelementptr inbounds i8, i8* %367, i64 4
  %369 = getelementptr inbounds i8, i8* %2, i64 %366
  %370 = bitcast i8* %369 to i32*
  %371 = load i32, i32* %370, align 1
  %372 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %371, i32 0
  %373 = bitcast <4 x i32> %372 to <16 x i8>
  %374 = add nuw nsw i64 %366, 4
  %375 = getelementptr inbounds i8, i8* %2, i64 %374
  %376 = load i8, i8* %375, align 1
  %377 = insertelement <16 x i8> %373, i8 %376, i64 4
  %378 = getelementptr inbounds i8, i8* %367, i64 3
  %379 = load i8, i8* %378, align 1
  %380 = insertelement <16 x i8> %377, i8 %379, i64 5
  %381 = getelementptr inbounds i8, i8* %368, i64 %343
  %382 = load i8, i8* %381, align 1
  %383 = insertelement <16 x i8> %380, i8 %382, i64 6
  %384 = bitcast <16 x i8> %383 to <4 x i32>
  %385 = shufflevector <4 x i32> %384, <4 x i32> undef, <4 x i32> <i32 0, i32 1, i32 0, i32 1>
  %386 = bitcast <4 x i32> %385 to <16 x i8>
  %387 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %386, <16 x i8> %12) #11
  %388 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %386, <16 x i8> %15) #11
  %389 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %387, <8 x i16> %388) #11
  %390 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %389, <8 x i16> %389) #11
  %391 = add <8 x i16> %390, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %392 = ashr <8 x i16> %391, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %393 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %392, <8 x i16> undef) #11
  %394 = bitcast <16 x i8> %393 to <4 x i32>
  %395 = extractelement <4 x i32> %394, i32 0
  %396 = bitcast i8* %368 to i32*
  store i32 %395, i32* %396, align 1
  %397 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %386, <16 x i8> %18) #11
  %398 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %386, <16 x i8> %21) #11
  %399 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %397, <8 x i16> %398) #11
  %400 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %399, <8 x i16> %399) #11
  %401 = add <8 x i16> %400, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %402 = ashr <8 x i16> %401, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %403 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %402, <8 x i16> undef) #11
  %404 = getelementptr inbounds i8, i8* %368, i64 %1
  %405 = bitcast <16 x i8> %403 to <4 x i32>
  %406 = extractelement <4 x i32> %405, i32 0
  %407 = bitcast i8* %404 to i32*
  store i32 %406, i32* %407, align 1
  %408 = getelementptr inbounds i8, i8* %404, i64 -1
  %409 = bitcast i8* %408 to i32*
  %410 = load i32, i32* %409, align 1
  %411 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %410, i32 0
  %412 = bitcast <4 x i32> %411 to <16 x i8>
  %413 = getelementptr inbounds i8, i8* %368, i64 %344
  %414 = load i8, i8* %413, align 1
  %415 = insertelement <16 x i8> %412, i8 %414, i64 4
  %416 = getelementptr inbounds i8, i8* %368, i64 %345
  %417 = load i8, i8* %416, align 1
  %418 = insertelement <16 x i8> %415, i8 %417, i64 5
  %419 = getelementptr inbounds i8, i8* %368, i64 %347
  %420 = load i8, i8* %419, align 1
  %421 = insertelement <16 x i8> %418, i8 %420, i64 6
  %422 = bitcast <16 x i8> %421 to <4 x i32>
  %423 = shufflevector <4 x i32> %422, <4 x i32> undef, <4 x i32> <i32 0, i32 1, i32 0, i32 1>
  %424 = getelementptr inbounds i8, i8* %368, i64 %316
  %425 = bitcast <4 x i32> %423 to <16 x i8>
  %426 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %425, <16 x i8> %12) #11
  %427 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %425, <16 x i8> %15) #11
  %428 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %426, <8 x i16> %427) #11
  %429 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %428, <8 x i16> %428) #11
  %430 = add <8 x i16> %429, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %431 = ashr <8 x i16> %430, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %432 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %431, <8 x i16> undef) #11
  %433 = bitcast <16 x i8> %432 to <4 x i32>
  %434 = extractelement <4 x i32> %433, i32 0
  %435 = bitcast i8* %424 to i32*
  store i32 %434, i32* %435, align 1
  %436 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %425, <16 x i8> %18) #11
  %437 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %425, <16 x i8> %21) #11
  %438 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %436, <8 x i16> %437) #11
  %439 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %438, <8 x i16> %438) #11
  %440 = add <8 x i16> %439, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %441 = ashr <8 x i16> %440, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %442 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %441, <8 x i16> undef) #11
  %443 = getelementptr inbounds i8, i8* %424, i64 %1
  %444 = bitcast <16 x i8> %442 to <4 x i32>
  %445 = extractelement <4 x i32> %444, i32 0
  %446 = bitcast i8* %443 to i32*
  store i32 %445, i32* %446, align 1
  %447 = icmp slt i64 %374, %348
  br i1 %447, label %365, label %349

448:                                              ; preds = %352, %519
  %449 = phi i64 [ 4, %352 ], [ %521, %519 ]
  %450 = phi i8* [ %350, %352 ], [ %520, %519 ]
  %451 = getelementptr inbounds i8, i8* %450, i64 4
  %452 = getelementptr inbounds i8, i8* %451, i64 %317
  %453 = getelementptr inbounds i8, i8* %452, i64 %354
  %454 = getelementptr inbounds i8, i8* %453, i64 %355
  %455 = bitcast i8* %454 to i32*
  %456 = load i32, i32* %455, align 1
  %457 = insertelement <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, i32 %456, i32 0
  %458 = getelementptr inbounds i8, i8* %356, i64 %449
  %459 = bitcast i8* %458 to i32*
  %460 = load i32, i32* %459, align 1
  %461 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %460, i32 0
  %462 = bitcast <4 x i32> %461 to <16 x i8>
  %463 = shufflevector <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i8> %462, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 undef, i32 21, i32 22, i32 23>
  %464 = or i64 %449, 3
  %465 = getelementptr inbounds i8, i8* %3, i64 %464
  %466 = load i8, i8* %465, align 1
  %467 = insertelement <16 x i8> %463, i8 %466, i64 12
  %468 = bitcast <4 x i32> %457 to <16 x i8>
  %469 = or <16 x i8> %467, %468
  %470 = shufflevector <16 x i8> %469, <16 x i8> undef, <16 x i32> <i32 8, i32 0, i32 1, i32 2, i32 3, i32 9, i32 10, i32 15, i32 8, i32 0, i32 1, i32 2, i32 3, i32 9, i32 10, i32 15>
  %471 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %470, <16 x i8> %12) #11
  %472 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %470, <16 x i8> %15) #11
  %473 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %471, <8 x i16> %472) #11
  %474 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %473, <8 x i16> %473) #11
  %475 = add <8 x i16> %474, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %476 = ashr <8 x i16> %475, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %477 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %476, <8 x i16> undef) #11
  %478 = bitcast <16 x i8> %477 to <4 x i32>
  %479 = extractelement <4 x i32> %478, i32 0
  %480 = bitcast i8* %453 to i32*
  store i32 %479, i32* %480, align 1
  %481 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %470, <16 x i8> %18) #11
  %482 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %470, <16 x i8> %21) #11
  %483 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %481, <8 x i16> %482) #11
  %484 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %483, <8 x i16> %483) #11
  %485 = add <8 x i16> %484, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %486 = ashr <8 x i16> %485, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %487 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %486, <8 x i16> undef) #11
  %488 = getelementptr inbounds i8, i8* %453, i64 %1
  %489 = bitcast <16 x i8> %487 to <4 x i32>
  %490 = extractelement <4 x i32> %489, i32 0
  %491 = bitcast i8* %488 to i32*
  store i32 %490, i32* %491, align 1
  %492 = shufflevector <16 x i8> %467, <16 x i8> <i8 undef, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 undef, i32 undef, i32 undef, i32 undef, i32 10, i32 11, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 17>
  %493 = shufflevector <4 x i32> %489, <4 x i32> <i32 undef, i32 undef, i32 0, i32 0>, <4 x i32> <i32 0, i32 undef, i32 6, i32 7>
  %494 = bitcast <4 x i32> %493 to <16 x i8>
  %495 = or <16 x i8> %492, %494
  %496 = shufflevector <16 x i8> %495, <16 x i8> undef, <16 x i32> <i32 8, i32 0, i32 1, i32 2, i32 3, i32 9, i32 10, i32 15, i32 8, i32 0, i32 1, i32 2, i32 3, i32 9, i32 10, i32 15>
  %497 = getelementptr inbounds i8, i8* %453, i64 %316
  %498 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %496, <16 x i8> %12) #11
  %499 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %496, <16 x i8> %15) #11
  %500 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %498, <8 x i16> %499) #11
  %501 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %500, <8 x i16> %500) #11
  %502 = add <8 x i16> %501, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %503 = ashr <8 x i16> %502, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %504 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %503, <8 x i16> undef) #11
  %505 = bitcast <16 x i8> %504 to <4 x i32>
  %506 = extractelement <4 x i32> %505, i32 0
  %507 = bitcast i8* %497 to i32*
  store i32 %506, i32* %507, align 1
  %508 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %496, <16 x i8> %18) #11
  %509 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %496, <16 x i8> %21) #11
  %510 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %508, <8 x i16> %509) #11
  %511 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %510, <8 x i16> %510) #11
  %512 = add <8 x i16> %511, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %513 = ashr <8 x i16> %512, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %514 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %513, <8 x i16> undef) #11
  %515 = getelementptr inbounds i8, i8* %497, i64 %1
  %516 = bitcast <16 x i8> %514 to <4 x i32>
  %517 = extractelement <4 x i32> %516, i32 0
  %518 = bitcast i8* %515 to i32*
  store i32 %517, i32* %518, align 1
  br i1 %357, label %523, label %519

519:                                              ; preds = %523, %448
  %520 = phi i8* [ %453, %448 ], [ %526, %523 ]
  %521 = add nuw nsw i64 %449, 4
  %522 = icmp slt i64 %521, %364
  br i1 %522, label %448, label %607

523:                                              ; preds = %448, %523
  %524 = phi i8* [ %526, %523 ], [ %453, %448 ]
  %525 = phi i32 [ %605, %523 ], [ 4, %448 ]
  %526 = getelementptr inbounds i8, i8* %524, i64 4
  %527 = getelementptr inbounds i8, i8* %526, i64 %355
  %528 = getelementptr inbounds i8, i8* %527, i64 -1
  %529 = bitcast i8* %528 to i32*
  %530 = load i32, i32* %529, align 1
  %531 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %530, i32 0
  %532 = bitcast <4 x i32> %531 to <16 x i8>
  %533 = getelementptr inbounds i8, i8* %526, i64 %358
  %534 = load i8, i8* %533, align 1
  %535 = insertelement <16 x i8> %532, i8 %534, i64 4
  %536 = getelementptr inbounds i8, i8* %524, i64 3
  %537 = load i8, i8* %536, align 1
  %538 = insertelement <16 x i8> %535, i8 %537, i64 5
  %539 = getelementptr inbounds i8, i8* %526, i64 %359
  %540 = load i8, i8* %539, align 1
  %541 = insertelement <16 x i8> %538, i8 %540, i64 6
  %542 = bitcast <16 x i8> %541 to <4 x i32>
  %543 = shufflevector <4 x i32> %542, <4 x i32> undef, <4 x i32> <i32 0, i32 1, i32 0, i32 1>
  %544 = bitcast <4 x i32> %543 to <16 x i8>
  %545 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %544, <16 x i8> %12) #11
  %546 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %544, <16 x i8> %15) #11
  %547 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %545, <8 x i16> %546) #11
  %548 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %547, <8 x i16> %547) #11
  %549 = add <8 x i16> %548, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %550 = ashr <8 x i16> %549, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %551 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %550, <8 x i16> undef) #11
  %552 = bitcast <16 x i8> %551 to <4 x i32>
  %553 = extractelement <4 x i32> %552, i32 0
  %554 = bitcast i8* %526 to i32*
  store i32 %553, i32* %554, align 1
  %555 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %544, <16 x i8> %18) #11
  %556 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %544, <16 x i8> %21) #11
  %557 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %555, <8 x i16> %556) #11
  %558 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %557, <8 x i16> %557) #11
  %559 = add <8 x i16> %558, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %560 = ashr <8 x i16> %559, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %561 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %560, <8 x i16> undef) #11
  %562 = getelementptr inbounds i8, i8* %526, i64 %1
  %563 = bitcast <16 x i8> %561 to <4 x i32>
  %564 = extractelement <4 x i32> %563, i32 0
  %565 = bitcast i8* %562 to i32*
  store i32 %564, i32* %565, align 1
  %566 = getelementptr inbounds i8, i8* %562, i64 -1
  %567 = bitcast i8* %566 to i32*
  %568 = load i32, i32* %567, align 1
  %569 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %568, i32 0
  %570 = bitcast <4 x i32> %569 to <16 x i8>
  %571 = getelementptr inbounds i8, i8* %526, i64 %360
  %572 = load i8, i8* %571, align 1
  %573 = insertelement <16 x i8> %570, i8 %572, i64 4
  %574 = getelementptr inbounds i8, i8* %526, i64 %361
  %575 = load i8, i8* %574, align 1
  %576 = insertelement <16 x i8> %573, i8 %575, i64 5
  %577 = getelementptr inbounds i8, i8* %526, i64 %363
  %578 = load i8, i8* %577, align 1
  %579 = insertelement <16 x i8> %576, i8 %578, i64 6
  %580 = bitcast <16 x i8> %579 to <4 x i32>
  %581 = shufflevector <4 x i32> %580, <4 x i32> undef, <4 x i32> <i32 0, i32 1, i32 0, i32 1>
  %582 = getelementptr inbounds i8, i8* %526, i64 %316
  %583 = bitcast <4 x i32> %581 to <16 x i8>
  %584 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %583, <16 x i8> %12) #11
  %585 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %583, <16 x i8> %15) #11
  %586 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %584, <8 x i16> %585) #11
  %587 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %586, <8 x i16> %586) #11
  %588 = add <8 x i16> %587, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %589 = ashr <8 x i16> %588, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %590 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %589, <8 x i16> undef) #11
  %591 = bitcast <16 x i8> %590 to <4 x i32>
  %592 = extractelement <4 x i32> %591, i32 0
  %593 = bitcast i8* %582 to i32*
  store i32 %592, i32* %593, align 1
  %594 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %583, <16 x i8> %18) #11
  %595 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %583, <16 x i8> %21) #11
  %596 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %594, <8 x i16> %595) #11
  %597 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %596, <8 x i16> %596) #11
  %598 = add <8 x i16> %597, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %599 = ashr <8 x i16> %598, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %600 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %599, <8 x i16> undef) #11
  %601 = getelementptr inbounds i8, i8* %582, i64 %1
  %602 = bitcast <16 x i8> %600 to <4 x i32>
  %603 = extractelement <4 x i32> %602, i32 0
  %604 = bitcast i8* %601 to i32*
  store i32 %603, i32* %604, align 1
  %605 = add nuw nsw i32 %525, 4
  %606 = icmp slt i32 %605, %5
  br i1 %606, label %523, label %519

607:                                              ; preds = %519, %349, %216, %214
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_137DirectionalIntraPredictorZone1_SSE4_1EPvlPKviiib(i8* nocapture, i64, i8* nocapture readonly, i32, i32, i32, i1 zeroext) #3 {
  %8 = zext i1 %6 to i32
  %9 = icmp eq i32 %5, 64
  br i1 %9, label %10, label %46

10:                                               ; preds = %7
  %11 = icmp eq i32 %4, 4
  br i1 %11, label %14, label %12

12:                                               ; preds = %10
  %13 = sext i32 %3 to i64
  br label %23

14:                                               ; preds = %10
  %15 = getelementptr inbounds i8, i8* %2, i64 1
  %16 = sext i32 %3 to i64
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %0, i8* align 1 %15, i64 %16, i1 false) #11
  %17 = getelementptr inbounds i8, i8* %0, i64 %1
  %18 = getelementptr inbounds i8, i8* %2, i64 2
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %17, i8* align 1 %18, i64 %16, i1 false) #11
  %19 = getelementptr inbounds i8, i8* %17, i64 %1
  %20 = getelementptr inbounds i8, i8* %2, i64 3
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %19, i8* align 1 %20, i64 %16, i1 false) #11
  %21 = getelementptr inbounds i8, i8* %19, i64 %1
  %22 = getelementptr inbounds i8, i8* %2, i64 4
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %21, i8* align 1 %22, i64 %16, i1 false) #11
  br label %577

23:                                               ; preds = %23, %12
  %24 = phi i8* [ %42, %23 ], [ %0, %12 ]
  %25 = phi i64 [ %43, %23 ], [ 1, %12 ]
  %26 = phi i32 [ %44, %23 ], [ 0, %12 ]
  %27 = getelementptr inbounds i8, i8* %2, i64 %25
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %24, i8* align 1 %27, i64 %13, i1 false) #11
  %28 = getelementptr inbounds i8, i8* %24, i64 %1
  %29 = getelementptr inbounds i8, i8* %27, i64 1
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %28, i8* align 1 %29, i64 %13, i1 false) #11
  %30 = getelementptr inbounds i8, i8* %28, i64 %1
  %31 = getelementptr inbounds i8, i8* %27, i64 2
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %30, i8* align 1 %31, i64 %13, i1 false) #11
  %32 = getelementptr inbounds i8, i8* %30, i64 %1
  %33 = getelementptr inbounds i8, i8* %27, i64 3
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %32, i8* align 1 %33, i64 %13, i1 false) #11
  %34 = getelementptr inbounds i8, i8* %32, i64 %1
  %35 = getelementptr inbounds i8, i8* %27, i64 4
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %34, i8* align 1 %35, i64 %13, i1 false) #11
  %36 = getelementptr inbounds i8, i8* %34, i64 %1
  %37 = getelementptr inbounds i8, i8* %27, i64 5
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %36, i8* align 1 %37, i64 %13, i1 false) #11
  %38 = getelementptr inbounds i8, i8* %36, i64 %1
  %39 = getelementptr inbounds i8, i8* %27, i64 6
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %38, i8* align 1 %39, i64 %13, i1 false) #11
  %40 = getelementptr inbounds i8, i8* %38, i64 %1
  %41 = getelementptr inbounds i8, i8* %27, i64 7
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %40, i8* align 1 %41, i64 %13, i1 false) #11
  %42 = getelementptr inbounds i8, i8* %40, i64 %1
  %43 = add nuw nsw i64 %25, 8
  %44 = add nuw nsw i32 %26, 8
  %45 = icmp slt i32 %44, %4
  br i1 %45, label %23, label %577

46:                                               ; preds = %7
  %47 = icmp eq i32 %3, 4
  br i1 %47, label %48, label %152

48:                                               ; preds = %46
  %49 = select i1 %6, i32 5, i32 6
  %50 = add nsw i32 %4, 3
  %51 = shl i32 %50, %8
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i8, i8* %2, i64 %52
  %54 = load i8, i8* %53, align 1
  %55 = zext i8 %54 to i16
  %56 = insertelement <8 x i16> undef, i16 %55, i32 0
  %57 = shufflevector <8 x i16> %56, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %58 = ashr i32 %5, %49
  %59 = icmp sgt i32 %58, 1
  %60 = select i1 %59, i32 %58, i32 1
  %61 = sdiv i32 %51, %60
  %62 = icmp sgt i32 %61, %4
  %63 = select i1 %62, i32 %4, i32 %61
  %64 = icmp sgt i32 %63, 0
  br i1 %64, label %65, label %71

65:                                               ; preds = %48
  %66 = select i1 %6, <2 x i64> <i64 506097522914230528, i64 0>, <2 x i64> <i64 289078108240281856, i64 0>
  %67 = trunc i32 %51 to i16
  %68 = insertelement <8 x i16> undef, i16 %67, i32 0
  %69 = shufflevector <8 x i16> %68, <8 x i16> undef, <8 x i32> zeroinitializer
  %70 = bitcast <2 x i64> %66 to <16 x i8>
  br label %94

71:                                               ; preds = %94, %48
  %72 = phi i32 [ 0, %48 ], [ %63, %94 ]
  %73 = phi i8* [ %0, %48 ], [ %128, %94 ]
  %74 = icmp slt i32 %72, %4
  br i1 %74, label %75, label %577

75:                                               ; preds = %71
  %76 = sub i32 %4, %72
  %77 = xor i32 %72, -1
  %78 = add i32 %77, %4
  %79 = and i32 %76, 7
  %80 = icmp eq i32 %79, 0
  br i1 %80, label %90, label %81

81:                                               ; preds = %75, %81
  %82 = phi i8* [ %86, %81 ], [ %73, %75 ]
  %83 = phi i32 [ %87, %81 ], [ %72, %75 ]
  %84 = phi i32 [ %88, %81 ], [ %79, %75 ]
  %85 = load i8, i8* %53, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %82, i8 %85, i64 4, i1 false) #11
  %86 = getelementptr inbounds i8, i8* %82, i64 %1
  %87 = add nuw nsw i32 %83, 1
  %88 = add i32 %84, -1
  %89 = icmp eq i32 %88, 0
  br i1 %89, label %90, label %81, !llvm.loop !2

90:                                               ; preds = %81, %75
  %91 = phi i8* [ %73, %75 ], [ %86, %81 ]
  %92 = phi i32 [ %72, %75 ], [ %87, %81 ]
  %93 = icmp ult i32 %78, 7
  br i1 %93, label %577, label %131

94:                                               ; preds = %94, %65
  %95 = phi i8* [ %0, %65 ], [ %128, %94 ]
  %96 = phi i32 [ 0, %65 ], [ %127, %94 ]
  %97 = phi i32 [ %5, %65 ], [ %129, %94 ]
  %98 = ashr i32 %97, %49
  %99 = shl i32 %97, %8
  %100 = lshr i32 %99, 1
  %101 = trunc i32 %100 to i8
  %102 = and i8 %101, 31
  %103 = insertelement <16 x i8> undef, i8 %102, i32 0
  %104 = shufflevector <16 x i8> %103, <16 x i8> undef, <16 x i32> zeroinitializer
  %105 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %104
  %106 = shufflevector <16 x i8> %105, <16 x i8> %104, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %107 = trunc i32 %98 to i16
  %108 = insertelement <8 x i16> undef, i16 %107, i32 0
  %109 = shufflevector <8 x i16> %108, <8 x i16> undef, <8 x i32> zeroinitializer
  %110 = add <8 x i16> %109, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %111 = sext i32 %98 to i64
  %112 = getelementptr inbounds i8, i8* %2, i64 %111
  %113 = bitcast i8* %112 to i64*
  %114 = load i64, i64* %113, align 1
  %115 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %114, i32 0
  %116 = bitcast <2 x i64> %115 to <16 x i8>
  %117 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %116, <16 x i8> %70) #11
  %118 = icmp sgt <8 x i16> %110, %69
  %119 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %117, <16 x i8> %106) #11
  %120 = lshr <8 x i16> %119, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %121 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %120, <8 x i16> zeroinitializer) #11
  %122 = select <8 x i1> %118, <8 x i16> %57, <8 x i16> %121
  %123 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %122, <8 x i16> undef) #11
  %124 = bitcast <16 x i8> %123 to <4 x i32>
  %125 = extractelement <4 x i32> %124, i32 0
  %126 = bitcast i8* %95 to i32*
  store i32 %125, i32* %126, align 1
  %127 = add nuw nsw i32 %96, 1
  %128 = getelementptr inbounds i8, i8* %95, i64 %1
  %129 = add nsw i32 %97, %5
  %130 = icmp slt i32 %127, %63
  br i1 %130, label %94, label %71

131:                                              ; preds = %90, %131
  %132 = phi i8* [ %149, %131 ], [ %91, %90 ]
  %133 = phi i32 [ %150, %131 ], [ %92, %90 ]
  %134 = load i8, i8* %53, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %132, i8 %134, i64 4, i1 false) #11
  %135 = getelementptr inbounds i8, i8* %132, i64 %1
  %136 = load i8, i8* %53, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %135, i8 %136, i64 4, i1 false) #11
  %137 = getelementptr inbounds i8, i8* %135, i64 %1
  %138 = load i8, i8* %53, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %137, i8 %138, i64 4, i1 false) #11
  %139 = getelementptr inbounds i8, i8* %137, i64 %1
  %140 = load i8, i8* %53, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %139, i8 %140, i64 4, i1 false) #11
  %141 = getelementptr inbounds i8, i8* %139, i64 %1
  %142 = load i8, i8* %53, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %141, i8 %142, i64 4, i1 false) #11
  %143 = getelementptr inbounds i8, i8* %141, i64 %1
  %144 = load i8, i8* %53, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %143, i8 %144, i64 4, i1 false) #11
  %145 = getelementptr inbounds i8, i8* %143, i64 %1
  %146 = load i8, i8* %53, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %145, i8 %146, i64 4, i1 false) #11
  %147 = getelementptr inbounds i8, i8* %145, i64 %1
  %148 = load i8, i8* %53, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %147, i8 %148, i64 4, i1 false) #11
  %149 = getelementptr inbounds i8, i8* %147, i64 %1
  %150 = add nuw nsw i32 %133, 8
  %151 = icmp eq i32 %150, %4
  br i1 %151, label %577, label %131

152:                                              ; preds = %46
  %153 = icmp sgt i32 %3, 31
  %154 = select i1 %6, <2 x i64> <i64 506097522914230528, i64 1084818905618843912>, <2 x i64> <i64 289078108240281856, i64 578438799592588548>
  %155 = select i1 %6, i32 5, i32 6
  %156 = add i32 %3, -1
  %157 = add i32 %156, %4
  %158 = shl i32 %157, %8
  %159 = shl i32 8, %8
  br i1 %153, label %160, label %385

160:                                              ; preds = %152
  %161 = ashr i32 %5, %155
  %162 = icmp sgt i32 %161, 1
  %163 = select i1 %162, i32 %161, i32 1
  %164 = sdiv i32 %158, %163
  %165 = icmp sgt i32 %164, %4
  %166 = select i1 %165, i32 %4, i32 %164
  %167 = shl i32 %3, %8
  %168 = sub nsw i32 %158, %167
  %169 = shl i32 %168, %155
  %170 = sdiv i32 %169, %5
  %171 = icmp sgt i32 %170, %4
  %172 = select i1 %171, i32 %4, i32 %170
  %173 = icmp sgt i32 %172, 0
  br i1 %173, label %174, label %254

174:                                              ; preds = %160
  %175 = bitcast <2 x i64> %154 to <16 x i8>
  %176 = zext i32 %159 to i64
  %177 = sext i32 %3 to i64
  %178 = add nsw i64 %177, -1
  %179 = lshr i64 %178, 3
  %180 = add nuw nsw i64 %179, 1
  %181 = and i64 %180, 1
  %182 = icmp eq i64 %179, 0
  %183 = sub nuw nsw i64 %180, %181
  %184 = icmp eq i64 %181, 0
  br label %185

185:                                              ; preds = %249, %174
  %186 = phi i8* [ %0, %174 ], [ %251, %249 ]
  %187 = phi i32 [ 0, %174 ], [ %250, %249 ]
  %188 = phi i32 [ %5, %174 ], [ %252, %249 ]
  %189 = ashr i32 %188, %155
  %190 = shl i32 %188, %8
  %191 = lshr i32 %190, 1
  %192 = trunc i32 %191 to i8
  %193 = and i8 %192, 31
  %194 = insertelement <16 x i8> undef, i8 %193, i32 0
  %195 = shufflevector <16 x i8> %194, <16 x i8> undef, <16 x i32> zeroinitializer
  %196 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %195
  %197 = shufflevector <16 x i8> %196, <16 x i8> %195, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %198 = sext i32 %189 to i64
  br i1 %182, label %233, label %199

199:                                              ; preds = %185, %199
  %200 = phi i64 [ %230, %199 ], [ 0, %185 ]
  %201 = phi i64 [ %229, %199 ], [ %198, %185 ]
  %202 = phi i64 [ %231, %199 ], [ %183, %185 ]
  %203 = getelementptr inbounds i8, i8* %2, i64 %201
  %204 = bitcast i8* %203 to <16 x i8>*
  %205 = load <16 x i8>, <16 x i8>* %204, align 1
  %206 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %205, <16 x i8> %175) #11
  %207 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %206, <16 x i8> %197) #11
  %208 = lshr <8 x i16> %207, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %209 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %208, <8 x i16> zeroinitializer) #11
  %210 = getelementptr inbounds i8, i8* %186, i64 %200
  %211 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %209, <8 x i16> undef) #11
  %212 = bitcast <16 x i8> %211 to <2 x i64>
  %213 = extractelement <2 x i64> %212, i32 0
  %214 = bitcast i8* %210 to i64*
  store i64 %213, i64* %214, align 1
  %215 = add i64 %201, %176
  %216 = or i64 %200, 8
  %217 = getelementptr inbounds i8, i8* %2, i64 %215
  %218 = bitcast i8* %217 to <16 x i8>*
  %219 = load <16 x i8>, <16 x i8>* %218, align 1
  %220 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %219, <16 x i8> %175) #11
  %221 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %220, <16 x i8> %197) #11
  %222 = lshr <8 x i16> %221, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %223 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %222, <8 x i16> zeroinitializer) #11
  %224 = getelementptr inbounds i8, i8* %186, i64 %216
  %225 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %223, <8 x i16> undef) #11
  %226 = bitcast <16 x i8> %225 to <2 x i64>
  %227 = extractelement <2 x i64> %226, i32 0
  %228 = bitcast i8* %224 to i64*
  store i64 %227, i64* %228, align 1
  %229 = add i64 %215, %176
  %230 = add nuw nsw i64 %200, 16
  %231 = add i64 %202, -2
  %232 = icmp eq i64 %231, 0
  br i1 %232, label %233, label %199

233:                                              ; preds = %199, %185
  %234 = phi i64 [ 0, %185 ], [ %230, %199 ]
  %235 = phi i64 [ %198, %185 ], [ %229, %199 ]
  br i1 %184, label %249, label %236

236:                                              ; preds = %233
  %237 = getelementptr inbounds i8, i8* %2, i64 %235
  %238 = bitcast i8* %237 to <16 x i8>*
  %239 = load <16 x i8>, <16 x i8>* %238, align 1
  %240 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %239, <16 x i8> %175) #11
  %241 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %240, <16 x i8> %197) #11
  %242 = lshr <8 x i16> %241, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %243 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %242, <8 x i16> zeroinitializer) #11
  %244 = getelementptr inbounds i8, i8* %186, i64 %234
  %245 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %243, <8 x i16> undef) #11
  %246 = bitcast <16 x i8> %245 to <2 x i64>
  %247 = extractelement <2 x i64> %246, i32 0
  %248 = bitcast i8* %244 to i64*
  store i64 %247, i64* %248, align 1
  br label %249

249:                                              ; preds = %233, %236
  %250 = add nuw nsw i32 %187, 1
  %251 = getelementptr inbounds i8, i8* %186, i64 %1
  %252 = add nsw i32 %188, %5
  %253 = icmp slt i32 %250, %172
  br i1 %253, label %185, label %254

254:                                              ; preds = %249, %160
  %255 = phi i32 [ %5, %160 ], [ %252, %249 ]
  %256 = phi i32 [ 0, %160 ], [ %172, %249 ]
  %257 = phi i8* [ %0, %160 ], [ %251, %249 ]
  %258 = trunc i32 %158 to i16
  %259 = insertelement <8 x i16> undef, i16 %258, i32 0
  %260 = shufflevector <8 x i16> %259, <8 x i16> undef, <8 x i32> zeroinitializer
  %261 = sext i32 %158 to i64
  %262 = getelementptr inbounds i8, i8* %2, i64 %261
  %263 = load i8, i8* %262, align 1
  %264 = zext i8 %263 to i16
  %265 = insertelement <8 x i16> undef, i16 %264, i32 0
  %266 = shufflevector <8 x i16> %265, <8 x i16> undef, <8 x i32> zeroinitializer
  %267 = trunc i32 %159 to i16
  %268 = insertelement <8 x i16> undef, i16 %267, i32 0
  %269 = shufflevector <8 x i16> %268, <8 x i16> undef, <8 x i32> zeroinitializer
  %270 = icmp slt i32 %256, %166
  br i1 %270, label %271, label %273

271:                                              ; preds = %254
  %272 = bitcast <2 x i64> %154 to <16 x i8>
  br label %297

273:                                              ; preds = %353, %254
  %274 = phi i32 [ %256, %254 ], [ %166, %353 ]
  %275 = phi i8* [ %257, %254 ], [ %361, %353 ]
  %276 = icmp slt i32 %274, %4
  br i1 %276, label %277, label %577

277:                                              ; preds = %273
  %278 = sext i32 %3 to i64
  %279 = sub i32 %4, %274
  %280 = xor i32 %274, -1
  %281 = add i32 %280, %4
  %282 = and i32 %279, 7
  %283 = icmp eq i32 %282, 0
  br i1 %283, label %293, label %284

284:                                              ; preds = %277, %284
  %285 = phi i8* [ %289, %284 ], [ %275, %277 ]
  %286 = phi i32 [ %290, %284 ], [ %274, %277 ]
  %287 = phi i32 [ %291, %284 ], [ %282, %277 ]
  %288 = load i8, i8* %262, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %285, i8 %288, i64 %278, i1 false) #11
  %289 = getelementptr inbounds i8, i8* %285, i64 %1
  %290 = add nuw nsw i32 %286, 1
  %291 = add i32 %287, -1
  %292 = icmp eq i32 %291, 0
  br i1 %292, label %293, label %284, !llvm.loop !4

293:                                              ; preds = %284, %277
  %294 = phi i8* [ %275, %277 ], [ %289, %284 ]
  %295 = phi i32 [ %274, %277 ], [ %290, %284 ]
  %296 = icmp ult i32 %281, 7
  br i1 %296, label %577, label %364

297:                                              ; preds = %353, %271
  %298 = phi i8* [ %257, %271 ], [ %361, %353 ]
  %299 = phi i32 [ %256, %271 ], [ %360, %353 ]
  %300 = phi i32 [ %255, %271 ], [ %362, %353 ]
  %301 = ashr i32 %300, %155
  %302 = shl i32 %300, %8
  %303 = lshr i32 %302, 1
  %304 = trunc i32 %303 to i8
  %305 = and i8 %304, 31
  %306 = insertelement <16 x i8> undef, i8 %305, i32 0
  %307 = shufflevector <16 x i8> %306, <16 x i8> undef, <16 x i32> zeroinitializer
  %308 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %307
  %309 = shufflevector <16 x i8> %308, <16 x i8> %307, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %310 = sub nsw i32 %158, %301
  %311 = ashr i32 %310, %8
  %312 = add nsw i32 %311, 7
  %313 = icmp slt i32 %312, %3
  %314 = select i1 %313, i32 %312, i32 %3
  %315 = and i32 %314, -8
  %316 = icmp sgt i32 %315, 0
  br i1 %316, label %317, label %353

317:                                              ; preds = %297
  %318 = trunc i32 %301 to i16
  %319 = insertelement <8 x i16> undef, i16 %318, i32 0
  %320 = shufflevector <8 x i16> %319, <8 x i16> undef, <8 x i32> zeroinitializer
  %321 = add <8 x i16> %320, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %322 = sext i32 %315 to i64
  br label %323

323:                                              ; preds = %323, %317
  %324 = phi i64 [ 0, %317 ], [ %347, %323 ]
  %325 = phi <8 x i16> [ %321, %317 ], [ %349, %323 ]
  %326 = phi i32 [ %301, %317 ], [ %348, %323 ]
  %327 = icmp sgt <8 x i16> %325, %260
  %328 = sext <8 x i1> %327 to <8 x i16>
  %329 = bitcast <8 x i16> %328 to <4 x i32>
  %330 = extractelement <4 x i32> %329, i32 0
  %331 = xor i32 %330, -1
  %332 = and i32 %326, %331
  %333 = sext i32 %332 to i64
  %334 = getelementptr inbounds i8, i8* %2, i64 %333
  %335 = bitcast i8* %334 to <16 x i8>*
  %336 = load <16 x i8>, <16 x i8>* %335, align 1
  %337 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %336, <16 x i8> %272) #11
  %338 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %337, <16 x i8> %309) #11
  %339 = lshr <8 x i16> %338, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %340 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %339, <8 x i16> zeroinitializer) #11
  %341 = select <8 x i1> %327, <8 x i16> %266, <8 x i16> %340
  %342 = getelementptr inbounds i8, i8* %298, i64 %324
  %343 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %341, <8 x i16> undef) #11
  %344 = bitcast <16 x i8> %343 to <2 x i64>
  %345 = extractelement <2 x i64> %344, i32 0
  %346 = bitcast i8* %342 to i64*
  store i64 %345, i64* %346, align 1
  %347 = add nuw nsw i64 %324, 8
  %348 = add nsw i32 %332, %159
  %349 = add <8 x i16> %325, %269
  %350 = icmp slt i64 %347, %322
  br i1 %350, label %323, label %351

351:                                              ; preds = %323
  %352 = trunc i64 %347 to i32
  br label %353

353:                                              ; preds = %351, %297
  %354 = phi i32 [ 0, %297 ], [ %352, %351 ]
  %355 = zext i32 %354 to i64
  %356 = getelementptr inbounds i8, i8* %298, i64 %355
  %357 = load i8, i8* %262, align 1
  %358 = sub nsw i32 %3, %354
  %359 = sext i32 %358 to i64
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %356, i8 %357, i64 %359, i1 false) #11
  %360 = add nuw nsw i32 %299, 1
  %361 = getelementptr inbounds i8, i8* %298, i64 %1
  %362 = add nsw i32 %300, %5
  %363 = icmp slt i32 %360, %166
  br i1 %363, label %297, label %273

364:                                              ; preds = %293, %364
  %365 = phi i8* [ %382, %364 ], [ %294, %293 ]
  %366 = phi i32 [ %383, %364 ], [ %295, %293 ]
  %367 = load i8, i8* %262, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %365, i8 %367, i64 %278, i1 false) #11
  %368 = getelementptr inbounds i8, i8* %365, i64 %1
  %369 = load i8, i8* %262, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %368, i8 %369, i64 %278, i1 false) #11
  %370 = getelementptr inbounds i8, i8* %368, i64 %1
  %371 = load i8, i8* %262, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %370, i8 %371, i64 %278, i1 false) #11
  %372 = getelementptr inbounds i8, i8* %370, i64 %1
  %373 = load i8, i8* %262, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %372, i8 %373, i64 %278, i1 false) #11
  %374 = getelementptr inbounds i8, i8* %372, i64 %1
  %375 = load i8, i8* %262, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %374, i8 %375, i64 %278, i1 false) #11
  %376 = getelementptr inbounds i8, i8* %374, i64 %1
  %377 = load i8, i8* %262, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %376, i8 %377, i64 %278, i1 false) #11
  %378 = getelementptr inbounds i8, i8* %376, i64 %1
  %379 = load i8, i8* %262, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %378, i8 %379, i64 %278, i1 false) #11
  %380 = getelementptr inbounds i8, i8* %378, i64 %1
  %381 = load i8, i8* %262, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %380, i8 %381, i64 %278, i1 false) #11
  %382 = getelementptr inbounds i8, i8* %380, i64 %1
  %383 = add nuw nsw i32 %366, 8
  %384 = icmp eq i32 %383, %4
  br i1 %384, label %577, label %364

385:                                              ; preds = %152
  %386 = mul nsw i32 %5, %4
  %387 = ashr i32 %386, %155
  %388 = shl i32 %3, %8
  %389 = add nsw i32 %387, %388
  %390 = icmp slt i32 %389, %158
  br i1 %390, label %391, label %432

391:                                              ; preds = %385
  %392 = bitcast <2 x i64> %154 to <16 x i8>
  %393 = zext i32 %159 to i64
  %394 = sext i32 %3 to i64
  br label %395

395:                                              ; preds = %427, %391
  %396 = phi i32 [ %430, %427 ], [ 0, %391 ]
  %397 = phi i32 [ %429, %427 ], [ %5, %391 ]
  %398 = phi i8* [ %428, %427 ], [ %0, %391 ]
  %399 = ashr i32 %397, %155
  %400 = shl i32 %397, %8
  %401 = lshr i32 %400, 1
  %402 = trunc i32 %401 to i8
  %403 = and i8 %402, 31
  %404 = insertelement <16 x i8> undef, i8 %403, i32 0
  %405 = shufflevector <16 x i8> %404, <16 x i8> undef, <16 x i32> zeroinitializer
  %406 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %405
  %407 = shufflevector <16 x i8> %406, <16 x i8> %405, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %408 = sext i32 %399 to i64
  br label %409

409:                                              ; preds = %409, %395
  %410 = phi i64 [ %425, %409 ], [ 0, %395 ]
  %411 = phi i64 [ %424, %409 ], [ %408, %395 ]
  %412 = getelementptr inbounds i8, i8* %2, i64 %411
  %413 = bitcast i8* %412 to <16 x i8>*
  %414 = load <16 x i8>, <16 x i8>* %413, align 1
  %415 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %414, <16 x i8> %392) #11
  %416 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %415, <16 x i8> %407) #11
  %417 = lshr <8 x i16> %416, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %418 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %417, <8 x i16> zeroinitializer) #11
  %419 = getelementptr inbounds i8, i8* %398, i64 %410
  %420 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %418, <8 x i16> undef) #11
  %421 = bitcast <16 x i8> %420 to <2 x i64>
  %422 = extractelement <2 x i64> %421, i32 0
  %423 = bitcast i8* %419 to i64*
  store i64 %422, i64* %423, align 1
  %424 = add i64 %411, %393
  %425 = add nuw nsw i64 %410, 8
  %426 = icmp slt i64 %425, %394
  br i1 %426, label %409, label %427

427:                                              ; preds = %409
  %428 = getelementptr inbounds i8, i8* %398, i64 %1
  %429 = add nsw i32 %397, %5
  %430 = add nuw nsw i32 %396, 1
  %431 = icmp slt i32 %430, %4
  br i1 %431, label %395, label %577

432:                                              ; preds = %385
  %433 = trunc i32 %158 to i16
  %434 = insertelement <8 x i16> undef, i16 %433, i32 0
  %435 = shufflevector <8 x i16> %434, <8 x i16> undef, <8 x i32> zeroinitializer
  %436 = sext i32 %158 to i64
  %437 = getelementptr inbounds i8, i8* %2, i64 %436
  %438 = load i8, i8* %437, align 1
  %439 = zext i8 %438 to i16
  %440 = insertelement <8 x i16> undef, i16 %439, i32 0
  %441 = shufflevector <8 x i16> %440, <8 x i16> undef, <8 x i32> zeroinitializer
  %442 = trunc i32 %159 to i16
  %443 = insertelement <8 x i16> undef, i16 %442, i32 0
  %444 = shufflevector <8 x i16> %443, <8 x i16> undef, <8 x i32> zeroinitializer
  %445 = add nsw i32 %3, -8
  %446 = icmp sgt i32 %445, 0
  %447 = bitcast <2 x i64> %154 to <16 x i8>
  %448 = sext i32 %445 to i64
  br label %449

449:                                              ; preds = %561, %432
  %450 = phi i32 [ %5, %432 ], [ %574, %561 ]
  %451 = phi i32 [ 0, %432 ], [ %575, %561 ]
  %452 = phi i8* [ %0, %432 ], [ %573, %561 ]
  %453 = ashr i32 %450, %155
  %454 = icmp slt i32 %453, %158
  br i1 %454, label %498, label %455

455:                                              ; preds = %449
  %456 = icmp slt i32 %451, %4
  br i1 %456, label %457, label %577

457:                                              ; preds = %455
  %458 = sext i32 %3 to i64
  %459 = sub i32 %4, %451
  %460 = xor i32 %451, -1
  %461 = add i32 %460, %4
  %462 = and i32 %459, 7
  %463 = icmp eq i32 %462, 0
  br i1 %463, label %473, label %464

464:                                              ; preds = %457, %464
  %465 = phi i8* [ %469, %464 ], [ %452, %457 ]
  %466 = phi i32 [ %470, %464 ], [ %451, %457 ]
  %467 = phi i32 [ %471, %464 ], [ %462, %457 ]
  %468 = load i8, i8* %437, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %465, i8 %468, i64 %458, i1 false) #11
  %469 = getelementptr inbounds i8, i8* %465, i64 %1
  %470 = add nuw nsw i32 %466, 1
  %471 = add i32 %467, -1
  %472 = icmp eq i32 %471, 0
  br i1 %472, label %473, label %464, !llvm.loop !5

473:                                              ; preds = %464, %457
  %474 = phi i8* [ %452, %457 ], [ %469, %464 ]
  %475 = phi i32 [ %451, %457 ], [ %470, %464 ]
  %476 = icmp ult i32 %461, 7
  br i1 %476, label %577, label %477

477:                                              ; preds = %473, %477
  %478 = phi i8* [ %495, %477 ], [ %474, %473 ]
  %479 = phi i32 [ %496, %477 ], [ %475, %473 ]
  %480 = load i8, i8* %437, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %478, i8 %480, i64 %458, i1 false) #11
  %481 = getelementptr inbounds i8, i8* %478, i64 %1
  %482 = load i8, i8* %437, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %481, i8 %482, i64 %458, i1 false) #11
  %483 = getelementptr inbounds i8, i8* %481, i64 %1
  %484 = load i8, i8* %437, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %483, i8 %484, i64 %458, i1 false) #11
  %485 = getelementptr inbounds i8, i8* %483, i64 %1
  %486 = load i8, i8* %437, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %485, i8 %486, i64 %458, i1 false) #11
  %487 = getelementptr inbounds i8, i8* %485, i64 %1
  %488 = load i8, i8* %437, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %487, i8 %488, i64 %458, i1 false) #11
  %489 = getelementptr inbounds i8, i8* %487, i64 %1
  %490 = load i8, i8* %437, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %489, i8 %490, i64 %458, i1 false) #11
  %491 = getelementptr inbounds i8, i8* %489, i64 %1
  %492 = load i8, i8* %437, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %491, i8 %492, i64 %458, i1 false) #11
  %493 = getelementptr inbounds i8, i8* %491, i64 %1
  %494 = load i8, i8* %437, align 1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %493, i8 %494, i64 %458, i1 false) #11
  %495 = getelementptr inbounds i8, i8* %493, i64 %1
  %496 = add nuw nsw i32 %479, 8
  %497 = icmp eq i32 %496, %4
  br i1 %497, label %577, label %477

498:                                              ; preds = %449
  %499 = shl i32 %450, %8
  %500 = lshr i32 %499, 1
  %501 = trunc i32 %500 to i8
  %502 = and i8 %501, 31
  %503 = insertelement <16 x i8> undef, i8 %502, i32 0
  %504 = shufflevector <16 x i8> %503, <16 x i8> undef, <16 x i32> zeroinitializer
  %505 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %504
  %506 = shufflevector <16 x i8> %505, <16 x i8> %504, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %507 = trunc i32 %453 to i16
  %508 = insertelement <8 x i16> undef, i16 %507, i32 0
  %509 = shufflevector <8 x i16> %508, <8 x i16> undef, <8 x i32> zeroinitializer
  %510 = add <8 x i16> %509, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %511 = icmp sgt <8 x i16> %510, %435
  br i1 %446, label %512, label %541

512:                                              ; preds = %498, %512
  %513 = phi i64 [ %536, %512 ], [ 0, %498 ]
  %514 = phi <8 x i1> [ %540, %512 ], [ %511, %498 ]
  %515 = phi <8 x i16> [ %538, %512 ], [ %510, %498 ]
  %516 = phi i32 [ %537, %512 ], [ %453, %498 ]
  %517 = sext <8 x i1> %514 to <8 x i16>
  %518 = bitcast <8 x i16> %517 to <4 x i32>
  %519 = extractelement <4 x i32> %518, i32 0
  %520 = xor i32 %519, -1
  %521 = and i32 %516, %520
  %522 = sext i32 %521 to i64
  %523 = getelementptr inbounds i8, i8* %2, i64 %522
  %524 = bitcast i8* %523 to <16 x i8>*
  %525 = load <16 x i8>, <16 x i8>* %524, align 1
  %526 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %525, <16 x i8> %447) #11
  %527 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %526, <16 x i8> %506) #11
  %528 = lshr <8 x i16> %527, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %529 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %528, <8 x i16> zeroinitializer) #11
  %530 = select <8 x i1> %514, <8 x i16> %441, <8 x i16> %529
  %531 = getelementptr inbounds i8, i8* %452, i64 %513
  %532 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %530, <8 x i16> undef) #11
  %533 = bitcast <16 x i8> %532 to <2 x i64>
  %534 = extractelement <2 x i64> %533, i32 0
  %535 = bitcast i8* %531 to i64*
  store i64 %534, i64* %535, align 1
  %536 = add nuw nsw i64 %513, 8
  %537 = add nsw i32 %521, %159
  %538 = add <8 x i16> %515, %444
  %539 = icmp slt i64 %536, %448
  %540 = icmp sgt <8 x i16> %538, %435
  br i1 %539, label %512, label %541

541:                                              ; preds = %512, %498
  %542 = phi i32 [ %453, %498 ], [ %537, %512 ]
  %543 = phi i64 [ 0, %498 ], [ %536, %512 ]
  %544 = phi <8 x i1> [ %511, %498 ], [ %540, %512 ]
  %545 = sext i32 %542 to i64
  %546 = getelementptr inbounds i8, i8* %2, i64 %545
  br i1 %6, label %547, label %550

547:                                              ; preds = %541
  %548 = bitcast i8* %546 to <16 x i8>*
  %549 = load <16 x i8>, <16 x i8>* %548, align 1
  br label %561

550:                                              ; preds = %541
  %551 = bitcast i8* %546 to i64*
  %552 = load i64, i64* %551, align 1
  %553 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %552, i32 0
  %554 = bitcast <2 x i64> %553 to <16 x i8>
  %555 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %554, <16 x i8> %447) #11
  %556 = add nsw i32 %542, 8
  %557 = sext i32 %556 to i64
  %558 = getelementptr inbounds i8, i8* %2, i64 %557
  %559 = load i8, i8* %558, align 1
  %560 = insertelement <16 x i8> %555, i8 %559, i64 15
  br label %561

561:                                              ; preds = %550, %547
  %562 = phi <16 x i8> [ %549, %547 ], [ %560, %550 ]
  %563 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %562, <16 x i8> %506) #11
  %564 = lshr <8 x i16> %563, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %565 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %564, <8 x i16> zeroinitializer) #11
  %566 = select <8 x i1> %544, <8 x i16> %441, <8 x i16> %565
  %567 = and i64 %543, 4294967295
  %568 = getelementptr inbounds i8, i8* %452, i64 %567
  %569 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %566, <8 x i16> undef) #11
  %570 = bitcast <16 x i8> %569 to <2 x i64>
  %571 = extractelement <2 x i64> %570, i32 0
  %572 = bitcast i8* %568 to i64*
  store i64 %571, i64* %572, align 1
  %573 = getelementptr inbounds i8, i8* %452, i64 %1
  %574 = add nsw i32 %450, %5
  %575 = add nuw nsw i32 %451, 1
  %576 = icmp slt i32 %575, %4
  br i1 %576, label %449, label %577

577:                                              ; preds = %561, %473, %477, %427, %293, %364, %90, %131, %23, %14, %71, %273, %455
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_137DirectionalIntraPredictorZone2_SSE4_1EPvlPKvS5_iiiibb(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly, i32, i32, i32, i32, i1 zeroext, i1 zeroext) #3 {
  %11 = alloca [288 x i8], align 16
  %12 = alloca [288 x i8], align 16
  %13 = getelementptr inbounds [288 x i8], [288 x i8]* %11, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 288, i8* nonnull %13) #11
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 128, i1 false)
  %14 = getelementptr inbounds [288 x i8], [288 x i8]* %12, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 288, i8* nonnull %14) #11
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 128, i1 false)
  %15 = getelementptr inbounds [288 x i8], [288 x i8]* %11, i64 0, i64 128
  %16 = getelementptr inbounds i8, i8* %2, i64 -16
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %15, i8* align 1 %16, i64 160, i1 false)
  %17 = getelementptr inbounds [288 x i8], [288 x i8]* %12, i64 0, i64 128
  %18 = getelementptr inbounds i8, i8* %3, i64 -16
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 16 %17, i8* align 1 %18, i64 160, i1 false)
  %19 = getelementptr inbounds [288 x i8], [288 x i8]* %11, i64 0, i64 144
  %20 = getelementptr inbounds [288 x i8], [288 x i8]* %12, i64 0, i64 144
  %21 = icmp eq i32 %4, 4
  %22 = icmp eq i32 %5, 4
  %23 = or i1 %21, %22
  br i1 %23, label %24, label %2070

24:                                               ; preds = %10
  %25 = shl i64 %1, 2
  %26 = mul nsw i32 %6, %5
  %27 = ashr i32 %26, 6
  %28 = icmp sgt i32 %27, %4
  %29 = select i1 %28, i32 %4, i32 %27
  %30 = shl i32 %6, 2
  %31 = trunc i32 %30 to i16
  %32 = insertelement <8 x i16> undef, i16 %31, i32 0
  %33 = shufflevector <8 x i16> %32, <8 x i16> undef, <8 x i32> zeroinitializer
  %34 = sub nsw i32 0, %6
  %35 = trunc i32 %34 to i16
  %36 = insertelement <8 x i16> undef, i16 %35, i32 0
  %37 = shufflevector <8 x i16> %36, <8 x i16> undef, <8 x i32> zeroinitializer
  %38 = mul <8 x i16> %37, <i16 1, i16 2, i16 3, i16 4, i16 0, i16 0, i16 0, i16 0>
  %39 = shl i32 %7, 2
  %40 = ashr i32 %39, 6
  %41 = trunc i32 %39 to i16
  %42 = and i16 %41, 60
  %43 = sub nsw i16 0, %42
  %44 = insertelement <8 x i16> undef, i16 %43, i32 0
  %45 = shufflevector <8 x i16> %44, <8 x i16> undef, <8 x i32> zeroinitializer
  %46 = trunc i32 %7 to i16
  %47 = icmp sgt i32 %29, 0
  br i1 %9, label %48, label %1065

48:                                               ; preds = %24
  br i1 %8, label %49, label %557

49:                                               ; preds = %48
  br i1 %47, label %50, label %75

50:                                               ; preds = %49
  %51 = ashr i32 %7, 6
  %52 = sub nsw i32 0, %51
  %53 = sub i16 0, %46
  %54 = insertelement <8 x i16> undef, i16 %53, i32 0
  %55 = shufflevector <8 x i16> %54, <8 x i16> undef, <8 x i32> zeroinitializer
  %56 = mul <8 x i16> %55, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %57 = and i16 %46, 63
  %58 = sub nsw i16 0, %57
  %59 = insertelement <8 x i16> undef, i16 %58, i32 0
  %60 = shufflevector <8 x i16> %59, <8 x i16> undef, <8 x i32> zeroinitializer
  %61 = add <8 x i16> %56, %60
  %62 = icmp eq i32 %6, 64
  %63 = sub <8 x i16> <i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64>, %38
  %64 = bitcast <8 x i16> %63 to <2 x i64>
  %65 = bitcast <8 x i16> %38 to <2 x i64>
  %66 = xor <2 x i64> %65, <i64 -1, i64 -1>
  %67 = select i1 %62, <2 x i64> %64, <2 x i64> %66
  %68 = ashr i32 %34, 5
  %69 = icmp sgt i32 %68, 1
  %70 = select i1 %69, i32 %68, i32 1
  %71 = sext i32 %5 to i64
  %72 = sext i32 %29 to i64
  br label %102

73:                                               ; preds = %471
  %74 = trunc i64 %212 to i32
  br label %75

75:                                               ; preds = %73, %49
  %76 = phi i32 [ 0, %49 ], [ %74, %73 ]
  %77 = icmp slt i32 %76, %4
  br i1 %77, label %78, label %7373

78:                                               ; preds = %75
  %79 = shl i32 %5, 1
  %80 = add i32 %79, 6
  %81 = sext i32 %80 to i64
  %82 = ashr i32 %34, 5
  %83 = icmp sgt i32 %82, 1
  %84 = select i1 %83, i32 %82, i32 1
  %85 = sdiv i32 %80, %84
  %86 = icmp sgt i32 %85, %5
  %87 = select i1 %86, i32 %5, i32 %85
  %88 = icmp sgt i32 %87, 0
  %89 = trunc i32 %80 to i16
  %90 = insertelement <8 x i16> undef, i16 %89, i32 0
  %91 = shufflevector <8 x i16> %90, <8 x i16> undef, <8 x i32> zeroinitializer
  %92 = zext i32 %76 to i64
  %93 = sext i32 %4 to i64
  %94 = icmp sgt i32 %87, 0
  %95 = select i1 %94, i32 %87, i32 0
  %96 = sub i32 %5, %95
  %97 = xor i32 %95, -1
  %98 = add i32 %97, %5
  %99 = and i32 %96, 7
  %100 = icmp eq i32 %99, 0
  %101 = icmp ult i32 %98, 7
  br label %477

102:                                              ; preds = %471, %50
  %103 = phi i64 [ 0, %50 ], [ %212, %471 ]
  %104 = phi i32 [ %52, %50 ], [ %475, %471 ]
  %105 = phi <8 x i16> [ %61, %50 ], [ %474, %471 ]
  %106 = phi <2 x i64> [ %67, %50 ], [ %473, %471 ]
  %107 = getelementptr inbounds i8, i8* %0, i64 %103
  %108 = trunc i64 %103 to i32
  %109 = shl i32 %108, 6
  %110 = sdiv i32 %109, %6
  %111 = icmp sgt i32 %110, %5
  %112 = select i1 %111, i32 %5, i32 %110
  %113 = and i32 %112, -12
  %114 = shl i32 %108, 1
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds i8, i8* %19, i64 %115
  %117 = shl i32 %113, 1
  %118 = or i32 %117, 6
  %119 = sext i32 %118 to i64
  %120 = getelementptr inbounds i8, i8* %116, i64 %119
  %121 = load i8, i8* %120, align 2
  %122 = zext i8 %121 to i16
  %123 = insertelement <8 x i16> undef, i16 %122, i32 0
  %124 = shufflevector <8 x i16> %123, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %125 = sdiv i32 %118, %70
  %126 = icmp sgt i32 %125, %113
  %127 = select i1 %126, i32 %113, i32 %125
  %128 = icmp sgt i32 %127, 0
  br i1 %128, label %129, label %133

129:                                              ; preds = %102
  %130 = trunc i32 %118 to i16
  %131 = insertelement <8 x i16> undef, i16 %130, i32 0
  %132 = shufflevector <8 x i16> %131, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %156

133:                                              ; preds = %156, %102
  %134 = phi i32 [ 0, %102 ], [ %127, %156 ]
  %135 = phi i8* [ %107, %102 ], [ %188, %156 ]
  %136 = icmp sgt i32 %113, %134
  br i1 %136, label %137, label %204

137:                                              ; preds = %133
  %138 = load i8, i8* %120, align 2
  %139 = sub i32 %113, %134
  %140 = xor i32 %134, -1
  %141 = add i32 %113, %140
  %142 = and i32 %139, 7
  %143 = icmp eq i32 %142, 0
  br i1 %143, label %152, label %144

144:                                              ; preds = %137, %144
  %145 = phi i8* [ %148, %144 ], [ %135, %137 ]
  %146 = phi i32 [ %149, %144 ], [ %134, %137 ]
  %147 = phi i32 [ %150, %144 ], [ %142, %137 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %145, i8 %138, i64 4, i1 false) #11
  %148 = getelementptr inbounds i8, i8* %145, i64 %1
  %149 = add nuw nsw i32 %146, 1
  %150 = add i32 %147, -1
  %151 = icmp eq i32 %150, 0
  br i1 %151, label %152, label %144, !llvm.loop !6

152:                                              ; preds = %144, %137
  %153 = phi i8* [ %135, %137 ], [ %148, %144 ]
  %154 = phi i32 [ %134, %137 ], [ %149, %144 ]
  %155 = icmp ult i32 %141, 7
  br i1 %155, label %204, label %191

156:                                              ; preds = %156, %129
  %157 = phi i8* [ %107, %129 ], [ %188, %156 ]
  %158 = phi i32 [ 0, %129 ], [ %187, %156 ]
  %159 = phi i32 [ %34, %129 ], [ %189, %156 ]
  %160 = ashr i32 %159, 5
  %161 = trunc i32 %159 to i8
  %162 = and i8 %161, 31
  %163 = insertelement <16 x i8> undef, i8 %162, i32 0
  %164 = shufflevector <16 x i8> %163, <16 x i8> undef, <16 x i32> zeroinitializer
  %165 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %164
  %166 = shufflevector <16 x i8> %165, <16 x i8> %164, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %167 = trunc i32 %160 to i16
  %168 = insertelement <8 x i16> undef, i16 %167, i32 0
  %169 = shufflevector <8 x i16> %168, <8 x i16> undef, <8 x i32> zeroinitializer
  %170 = add <8 x i16> %169, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %171 = sext i32 %160 to i64
  %172 = getelementptr inbounds i8, i8* %116, i64 %171
  %173 = bitcast i8* %172 to i64*
  %174 = load i64, i64* %173, align 1
  %175 = insertelement <2 x i64> undef, i64 %174, i32 0
  %176 = bitcast <2 x i64> %175 to <16 x i8>
  %177 = shufflevector <16 x i8> %176, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %178 = icmp sgt <8 x i16> %170, %132
  %179 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %177, <16 x i8> %166) #11
  %180 = lshr <8 x i16> %179, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %181 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %180, <8 x i16> zeroinitializer) #11
  %182 = select <8 x i1> %178, <8 x i16> %124, <8 x i16> %181
  %183 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %182, <8 x i16> undef) #11
  %184 = bitcast <16 x i8> %183 to <4 x i32>
  %185 = extractelement <4 x i32> %184, i32 0
  %186 = bitcast i8* %157 to i32*
  store i32 %185, i32* %186, align 1
  %187 = add nuw nsw i32 %158, 1
  %188 = getelementptr inbounds i8, i8* %157, i64 %1
  %189 = sub i32 %159, %6
  %190 = icmp slt i32 %187, %127
  br i1 %190, label %156, label %133

191:                                              ; preds = %152, %191
  %192 = phi i8* [ %201, %191 ], [ %153, %152 ]
  %193 = phi i32 [ %202, %191 ], [ %154, %152 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %192, i8 %138, i64 4, i1 false) #11
  %194 = getelementptr inbounds i8, i8* %192, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %194, i8 %138, i64 4, i1 false) #11
  %195 = getelementptr inbounds i8, i8* %194, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %195, i8 %138, i64 4, i1 false) #11
  %196 = getelementptr inbounds i8, i8* %195, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %196, i8 %138, i64 4, i1 false) #11
  %197 = getelementptr inbounds i8, i8* %196, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %197, i8 %138, i64 4, i1 false) #11
  %198 = getelementptr inbounds i8, i8* %197, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %198, i8 %138, i64 4, i1 false) #11
  %199 = getelementptr inbounds i8, i8* %198, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %199, i8 %138, i64 4, i1 false) #11
  %200 = getelementptr inbounds i8, i8* %199, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %200, i8 %138, i64 4, i1 false) #11
  %201 = getelementptr inbounds i8, i8* %200, i64 %1
  %202 = add nuw nsw i32 %193, 8
  %203 = icmp eq i32 %202, %113
  br i1 %203, label %204, label %191

204:                                              ; preds = %152, %191, %133
  %205 = sext i32 %113 to i64
  %206 = mul nsw i64 %205, %1
  %207 = getelementptr inbounds i8, i8* %107, i64 %206
  %208 = mul nsw i32 %113, %6
  %209 = trunc i32 %208 to i16
  %210 = insertelement <8 x i16> undef, i16 %209, i32 0
  %211 = shufflevector <8 x i16> %210, <8 x i16> undef, <8 x i32> zeroinitializer
  %212 = add nuw nsw i64 %103, 4
  %213 = trunc i64 %212 to i32
  %214 = shl i32 %213, 6
  %215 = sdiv i32 %214, %6
  %216 = icmp sgt i32 %215, %5
  %217 = select i1 %216, i32 %5, i32 %215
  %218 = bitcast <2 x i64> %106 to <8 x i16>
  %219 = icmp slt i32 %113, %217
  br i1 %219, label %220, label %239

220:                                              ; preds = %204
  %221 = sub nsw i32 0, %208
  %222 = sub <8 x i16> %38, %211
  %223 = add <8 x i16> %211, %218
  %224 = ashr <8 x i16> %105, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %225 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %224, <8 x i16> %224) #11
  %226 = add <16 x i8> %225, <i8 1, i8 1, i8 1, i8 1, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %227 = shufflevector <16 x i8> %225, <16 x i8> %226, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %228 = add <16 x i8> %227, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %229 = and <8 x i16> %105, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %230 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %229, <8 x i16> %229) #11
  %231 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %230
  %232 = shufflevector <16 x i8> %231, <16 x i8> %230, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %233 = sext i32 %217 to i64
  %234 = sub i32 3, %113
  %235 = add i32 %234, %217
  br label %254

236:                                              ; preds = %254
  %237 = and i32 %235, -4
  %238 = add i32 %237, %113
  br label %239

239:                                              ; preds = %236, %204
  %240 = phi i8* [ %207, %204 ], [ %408, %236 ]
  %241 = phi i32 [ %113, %204 ], [ %238, %236 ]
  %242 = icmp slt i32 %241, %5
  br i1 %242, label %243, label %471

243:                                              ; preds = %239
  %244 = ashr <8 x i16> %105, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %245 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %244, <8 x i16> %244) #11
  %246 = add <16 x i8> %245, <i8 1, i8 1, i8 1, i8 1, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %247 = shufflevector <16 x i8> %245, <16 x i8> %246, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %248 = add <16 x i8> %247, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %249 = and <8 x i16> %105, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %250 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %249, <8 x i16> %249) #11
  %251 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %250
  %252 = shufflevector <16 x i8> %251, <16 x i8> %250, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %253 = sext i32 %241 to i64
  br label %413

254:                                              ; preds = %254, %220
  %255 = phi i64 [ %205, %220 ], [ %406, %254 ]
  %256 = phi i32 [ %221, %220 ], [ %411, %254 ]
  %257 = phi <8 x i16> [ %222, %220 ], [ %410, %254 ]
  %258 = phi <8 x i16> [ %223, %220 ], [ %409, %254 ]
  %259 = phi i32 [ %113, %220 ], [ %407, %254 ]
  %260 = phi i8* [ %207, %220 ], [ %408, %254 ]
  %261 = add nsw i32 %259, %104
  %262 = shl nsw i32 %261, 1
  %263 = sext i32 %262 to i64
  %264 = getelementptr inbounds i8, i8* %20, i64 %263
  %265 = getelementptr inbounds i8, i8* %264, i64 -15
  %266 = bitcast i8* %265 to <16 x i8>*
  %267 = load <16 x i8>, <16 x i8>* %266, align 1
  %268 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %267, <16 x i8> %228) #11
  %269 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %268, <16 x i8> %232) #11
  %270 = lshr <8 x i16> %269, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %271 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %270, <8 x i16> zeroinitializer) #11
  %272 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %271, <8 x i16> undef) #11
  %273 = bitcast <16 x i8> %272 to <4 x i32>
  %274 = extractelement <4 x i32> %273, i32 0
  %275 = bitcast i8* %260 to i32*
  store i32 %274, i32* %275, align 1
  %276 = getelementptr inbounds i8, i8* %260, i64 %1
  %277 = getelementptr inbounds i8, i8* %264, i64 -13
  %278 = bitcast i8* %277 to <16 x i8>*
  %279 = load <16 x i8>, <16 x i8>* %278, align 1
  %280 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %279, <16 x i8> %228) #11
  %281 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %280, <16 x i8> %232) #11
  %282 = lshr <8 x i16> %281, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %283 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %282, <8 x i16> zeroinitializer) #11
  %284 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %283, <8 x i16> undef) #11
  %285 = bitcast <16 x i8> %284 to <4 x i32>
  %286 = extractelement <4 x i32> %285, i32 0
  %287 = bitcast i8* %276 to i32*
  store i32 %286, i32* %287, align 1
  %288 = getelementptr inbounds i8, i8* %276, i64 %1
  %289 = getelementptr inbounds i8, i8* %264, i64 -11
  %290 = bitcast i8* %289 to <16 x i8>*
  %291 = load <16 x i8>, <16 x i8>* %290, align 1
  %292 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %291, <16 x i8> %228) #11
  %293 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %292, <16 x i8> %232) #11
  %294 = lshr <8 x i16> %293, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %295 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %294, <8 x i16> zeroinitializer) #11
  %296 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %295, <8 x i16> undef) #11
  %297 = bitcast <16 x i8> %296 to <4 x i32>
  %298 = extractelement <4 x i32> %297, i32 0
  %299 = bitcast i8* %288 to i32*
  store i32 %298, i32* %299, align 1
  %300 = getelementptr inbounds i8, i8* %288, i64 %1
  %301 = getelementptr inbounds i8, i8* %264, i64 -9
  %302 = bitcast i8* %301 to <16 x i8>*
  %303 = load <16 x i8>, <16 x i8>* %302, align 1
  %304 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %303, <16 x i8> %228) #11
  %305 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %304, <16 x i8> %232) #11
  %306 = lshr <8 x i16> %305, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %307 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %306, <8 x i16> zeroinitializer) #11
  %308 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %307, <8 x i16> undef) #11
  %309 = bitcast <16 x i8> %308 to <4 x i32>
  %310 = extractelement <4 x i32> %309, i32 0
  %311 = bitcast i8* %300 to i32*
  store i32 %310, i32* %311, align 1
  %312 = and <8 x i16> %257, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %313 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %312, <8 x i16> %312) #11
  %314 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %313
  %315 = shufflevector <16 x i8> %314, <16 x i8> %313, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %316 = ashr <8 x i16> %258, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %317 = sub nsw i32 %256, %6
  %318 = ashr i32 %317, 5
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i8, i8* %116, i64 %319
  %321 = bitcast <16 x i8> %315 to <8 x i16>
  %322 = shufflevector <8 x i16> %321, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %323 = bitcast i8* %320 to <16 x i8>*
  %324 = load <16 x i8>, <16 x i8>* %323, align 1
  %325 = bitcast <8 x i16> %322 to <16 x i8>
  %326 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %324, <16 x i8> %325) #11
  %327 = lshr <8 x i16> %326, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %328 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %327, <8 x i16> zeroinitializer) #11
  %329 = shufflevector <8 x i16> %316, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %330 = icmp sgt <8 x i16> %329, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %331 = load i32, i32* %275, align 1
  %332 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %331, i32 0
  %333 = bitcast <4 x i32> %332 to <16 x i8>
  %334 = shufflevector <16 x i8> %333, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %335 = zext <8 x i8> %334 to <8 x i16>
  %336 = select <8 x i1> %330, <8 x i16> %335, <8 x i16> %328
  %337 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %336, <8 x i16> undef) #11
  %338 = bitcast <16 x i8> %337 to <4 x i32>
  %339 = extractelement <4 x i32> %338, i32 0
  store i32 %339, i32* %275, align 1
  %340 = sub nsw i32 %317, %6
  %341 = ashr i32 %340, 5
  %342 = sext i32 %341 to i64
  %343 = getelementptr inbounds i8, i8* %116, i64 %342
  %344 = shufflevector <8 x i16> %321, <8 x i16> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 4, i32 5, i32 6, i32 7>
  %345 = bitcast i8* %343 to <16 x i8>*
  %346 = load <16 x i8>, <16 x i8>* %345, align 1
  %347 = bitcast <8 x i16> %344 to <16 x i8>
  %348 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %346, <16 x i8> %347) #11
  %349 = lshr <8 x i16> %348, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %350 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %349, <8 x i16> zeroinitializer) #11
  %351 = shufflevector <8 x i16> %316, <8 x i16> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 4, i32 5, i32 6, i32 7>
  %352 = icmp sgt <8 x i16> %351, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %353 = load i32, i32* %287, align 1
  %354 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %353, i32 0
  %355 = bitcast <4 x i32> %354 to <16 x i8>
  %356 = shufflevector <16 x i8> %355, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %357 = zext <8 x i8> %356 to <8 x i16>
  %358 = select <8 x i1> %352, <8 x i16> %357, <8 x i16> %350
  %359 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %358, <8 x i16> undef) #11
  %360 = bitcast <16 x i8> %359 to <4 x i32>
  %361 = extractelement <4 x i32> %360, i32 0
  store i32 %361, i32* %287, align 1
  %362 = sub nsw i32 %340, %6
  %363 = ashr i32 %362, 5
  %364 = sext i32 %363 to i64
  %365 = getelementptr inbounds i8, i8* %116, i64 %364
  %366 = shufflevector <8 x i16> %321, <8 x i16> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 4, i32 5, i32 6, i32 7>
  %367 = bitcast i8* %365 to <16 x i8>*
  %368 = load <16 x i8>, <16 x i8>* %367, align 1
  %369 = bitcast <8 x i16> %366 to <16 x i8>
  %370 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %368, <16 x i8> %369) #11
  %371 = lshr <8 x i16> %370, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %372 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %371, <8 x i16> zeroinitializer) #11
  %373 = shufflevector <8 x i16> %316, <8 x i16> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 4, i32 5, i32 6, i32 7>
  %374 = icmp sgt <8 x i16> %373, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %375 = load i32, i32* %299, align 1
  %376 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %375, i32 0
  %377 = bitcast <4 x i32> %376 to <16 x i8>
  %378 = shufflevector <16 x i8> %377, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %379 = zext <8 x i8> %378 to <8 x i16>
  %380 = select <8 x i1> %374, <8 x i16> %379, <8 x i16> %372
  %381 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %380, <8 x i16> undef) #11
  %382 = bitcast <16 x i8> %381 to <4 x i32>
  %383 = extractelement <4 x i32> %382, i32 0
  store i32 %383, i32* %299, align 1
  %384 = sub nsw i32 %362, %6
  %385 = ashr i32 %384, 5
  %386 = sext i32 %385 to i64
  %387 = getelementptr inbounds i8, i8* %116, i64 %386
  %388 = shufflevector <8 x i16> %321, <8 x i16> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 4, i32 5, i32 6, i32 7>
  %389 = bitcast i8* %387 to <16 x i8>*
  %390 = load <16 x i8>, <16 x i8>* %389, align 1
  %391 = bitcast <8 x i16> %388 to <16 x i8>
  %392 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %390, <16 x i8> %391) #11
  %393 = lshr <8 x i16> %392, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %394 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %393, <8 x i16> zeroinitializer) #11
  %395 = shufflevector <8 x i16> %316, <8 x i16> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 4, i32 5, i32 6, i32 7>
  %396 = icmp sgt <8 x i16> %395, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %397 = load i32, i32* %311, align 1
  %398 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %397, i32 0
  %399 = bitcast <4 x i32> %398 to <16 x i8>
  %400 = shufflevector <16 x i8> %399, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %401 = zext <8 x i8> %400 to <8 x i16>
  %402 = select <8 x i1> %396, <8 x i16> %401, <8 x i16> %394
  %403 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %402, <8 x i16> undef) #11
  %404 = bitcast <16 x i8> %403 to <4 x i32>
  %405 = extractelement <4 x i32> %404, i32 0
  store i32 %405, i32* %311, align 1
  %406 = add nsw i64 %255, 4
  %407 = add nsw i32 %259, 4
  %408 = getelementptr inbounds i8, i8* %260, i64 %25
  %409 = add <8 x i16> %258, %33
  %410 = sub <8 x i16> %257, %33
  %411 = sub nsw i32 %256, %30
  %412 = icmp slt i64 %406, %233
  br i1 %412, label %254, label %236

413:                                              ; preds = %413, %243
  %414 = phi i64 [ %253, %243 ], [ %468, %413 ]
  %415 = phi i8* [ %240, %243 ], [ %469, %413 ]
  %416 = trunc i64 %414 to i32
  %417 = add i32 %104, %416
  %418 = shl i32 %417, 1
  %419 = sext i32 %418 to i64
  %420 = getelementptr inbounds i8, i8* %20, i64 %419
  %421 = getelementptr inbounds i8, i8* %420, i64 -15
  %422 = bitcast i8* %421 to <16 x i8>*
  %423 = load <16 x i8>, <16 x i8>* %422, align 1
  %424 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %423, <16 x i8> %248) #11
  %425 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %424, <16 x i8> %252) #11
  %426 = lshr <8 x i16> %425, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %427 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %426, <8 x i16> zeroinitializer) #11
  %428 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %427, <8 x i16> undef) #11
  %429 = bitcast <16 x i8> %428 to <4 x i32>
  %430 = extractelement <4 x i32> %429, i32 0
  %431 = bitcast i8* %415 to i32*
  store i32 %430, i32* %431, align 1
  %432 = getelementptr inbounds i8, i8* %415, i64 %1
  %433 = getelementptr inbounds i8, i8* %420, i64 -13
  %434 = bitcast i8* %433 to <16 x i8>*
  %435 = load <16 x i8>, <16 x i8>* %434, align 1
  %436 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %435, <16 x i8> %248) #11
  %437 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %436, <16 x i8> %252) #11
  %438 = lshr <8 x i16> %437, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %439 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %438, <8 x i16> zeroinitializer) #11
  %440 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %439, <8 x i16> undef) #11
  %441 = bitcast <16 x i8> %440 to <4 x i32>
  %442 = extractelement <4 x i32> %441, i32 0
  %443 = bitcast i8* %432 to i32*
  store i32 %442, i32* %443, align 1
  %444 = getelementptr inbounds i8, i8* %432, i64 %1
  %445 = getelementptr inbounds i8, i8* %420, i64 -11
  %446 = bitcast i8* %445 to <16 x i8>*
  %447 = load <16 x i8>, <16 x i8>* %446, align 1
  %448 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %447, <16 x i8> %248) #11
  %449 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %448, <16 x i8> %252) #11
  %450 = lshr <8 x i16> %449, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %451 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %450, <8 x i16> zeroinitializer) #11
  %452 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %451, <8 x i16> undef) #11
  %453 = bitcast <16 x i8> %452 to <4 x i32>
  %454 = extractelement <4 x i32> %453, i32 0
  %455 = bitcast i8* %444 to i32*
  store i32 %454, i32* %455, align 1
  %456 = getelementptr inbounds i8, i8* %444, i64 %1
  %457 = getelementptr inbounds i8, i8* %420, i64 -9
  %458 = bitcast i8* %457 to <16 x i8>*
  %459 = load <16 x i8>, <16 x i8>* %458, align 1
  %460 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %459, <16 x i8> %248) #11
  %461 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %460, <16 x i8> %252) #11
  %462 = lshr <8 x i16> %461, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %463 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %462, <8 x i16> zeroinitializer) #11
  %464 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %463, <8 x i16> undef) #11
  %465 = bitcast <16 x i8> %464 to <4 x i32>
  %466 = extractelement <4 x i32> %465, i32 0
  %467 = bitcast i8* %456 to i32*
  store i32 %466, i32* %467, align 1
  %468 = add nsw i64 %414, 4
  %469 = getelementptr inbounds i8, i8* %415, i64 %25
  %470 = icmp slt i64 %468, %71
  br i1 %470, label %413, label %471

471:                                              ; preds = %413, %239
  %472 = add <8 x i16> %218, <i16 -256, i16 -256, i16 -256, i16 -256, i16 -256, i16 -256, i16 -256, i16 -256>
  %473 = bitcast <8 x i16> %472 to <2 x i64>
  %474 = add <8 x i16> %105, %45
  %475 = sub nsw i32 %104, %40
  %476 = icmp slt i64 %212, %72
  br i1 %476, label %102, label %73

477:                                              ; preds = %554, %78
  %478 = phi i64 [ %92, %78 ], [ %555, %554 ]
  %479 = getelementptr inbounds i8, i8* %0, i64 %478
  %480 = trunc i64 %478 to i32
  %481 = shl i32 %480, 1
  %482 = sext i32 %481 to i64
  %483 = getelementptr inbounds i8, i8* %19, i64 %482
  %484 = getelementptr inbounds i8, i8* %483, i64 %81
  %485 = load i8, i8* %484, align 2
  %486 = zext i8 %485 to i16
  %487 = insertelement <8 x i16> undef, i16 %486, i32 0
  %488 = shufflevector <8 x i16> %487, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  br i1 %88, label %506, label %489

489:                                              ; preds = %506, %477
  %490 = phi i32 [ 0, %477 ], [ %87, %506 ]
  %491 = phi i8* [ %479, %477 ], [ %538, %506 ]
  %492 = icmp slt i32 %490, %5
  br i1 %492, label %493, label %554

493:                                              ; preds = %489
  %494 = load i8, i8* %484, align 2
  br i1 %100, label %503, label %495

495:                                              ; preds = %493, %495
  %496 = phi i8* [ %499, %495 ], [ %491, %493 ]
  %497 = phi i32 [ %500, %495 ], [ %490, %493 ]
  %498 = phi i32 [ %501, %495 ], [ %99, %493 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %496, i8 %494, i64 4, i1 false) #11
  %499 = getelementptr inbounds i8, i8* %496, i64 %1
  %500 = add nuw nsw i32 %497, 1
  %501 = add i32 %498, -1
  %502 = icmp eq i32 %501, 0
  br i1 %502, label %503, label %495, !llvm.loop !7

503:                                              ; preds = %495, %493
  %504 = phi i8* [ %491, %493 ], [ %499, %495 ]
  %505 = phi i32 [ %490, %493 ], [ %500, %495 ]
  br i1 %101, label %554, label %541

506:                                              ; preds = %477, %506
  %507 = phi i8* [ %538, %506 ], [ %479, %477 ]
  %508 = phi i32 [ %537, %506 ], [ 0, %477 ]
  %509 = phi i32 [ %539, %506 ], [ %34, %477 ]
  %510 = ashr i32 %509, 5
  %511 = trunc i32 %509 to i8
  %512 = and i8 %511, 31
  %513 = insertelement <16 x i8> undef, i8 %512, i32 0
  %514 = shufflevector <16 x i8> %513, <16 x i8> undef, <16 x i32> zeroinitializer
  %515 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %514
  %516 = shufflevector <16 x i8> %515, <16 x i8> %514, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %517 = trunc i32 %510 to i16
  %518 = insertelement <8 x i16> undef, i16 %517, i32 0
  %519 = shufflevector <8 x i16> %518, <8 x i16> undef, <8 x i32> zeroinitializer
  %520 = add <8 x i16> %519, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %521 = sext i32 %510 to i64
  %522 = getelementptr inbounds i8, i8* %483, i64 %521
  %523 = bitcast i8* %522 to i64*
  %524 = load i64, i64* %523, align 1
  %525 = insertelement <2 x i64> undef, i64 %524, i32 0
  %526 = bitcast <2 x i64> %525 to <16 x i8>
  %527 = shufflevector <16 x i8> %526, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %528 = icmp sgt <8 x i16> %520, %91
  %529 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %527, <16 x i8> %516) #11
  %530 = lshr <8 x i16> %529, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %531 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %530, <8 x i16> zeroinitializer) #11
  %532 = select <8 x i1> %528, <8 x i16> %488, <8 x i16> %531
  %533 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %532, <8 x i16> undef) #11
  %534 = bitcast <16 x i8> %533 to <4 x i32>
  %535 = extractelement <4 x i32> %534, i32 0
  %536 = bitcast i8* %507 to i32*
  store i32 %535, i32* %536, align 1
  %537 = add nuw nsw i32 %508, 1
  %538 = getelementptr inbounds i8, i8* %507, i64 %1
  %539 = sub i32 %509, %6
  %540 = icmp slt i32 %537, %87
  br i1 %540, label %506, label %489

541:                                              ; preds = %503, %541
  %542 = phi i8* [ %551, %541 ], [ %504, %503 ]
  %543 = phi i32 [ %552, %541 ], [ %505, %503 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %542, i8 %494, i64 4, i1 false) #11
  %544 = getelementptr inbounds i8, i8* %542, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %544, i8 %494, i64 4, i1 false) #11
  %545 = getelementptr inbounds i8, i8* %544, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %545, i8 %494, i64 4, i1 false) #11
  %546 = getelementptr inbounds i8, i8* %545, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %546, i8 %494, i64 4, i1 false) #11
  %547 = getelementptr inbounds i8, i8* %546, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %547, i8 %494, i64 4, i1 false) #11
  %548 = getelementptr inbounds i8, i8* %547, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %548, i8 %494, i64 4, i1 false) #11
  %549 = getelementptr inbounds i8, i8* %548, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %549, i8 %494, i64 4, i1 false) #11
  %550 = getelementptr inbounds i8, i8* %549, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %550, i8 %494, i64 4, i1 false) #11
  %551 = getelementptr inbounds i8, i8* %550, i64 %1
  %552 = add nuw nsw i32 %543, 8
  %553 = icmp eq i32 %552, %5
  br i1 %553, label %554, label %541

554:                                              ; preds = %503, %541, %489
  %555 = add nuw nsw i64 %478, 4
  %556 = icmp slt i64 %555, %93
  br i1 %556, label %477, label %7373

557:                                              ; preds = %48
  br i1 %47, label %558, label %583

558:                                              ; preds = %557
  %559 = ashr i32 %7, 6
  %560 = sub nsw i32 0, %559
  %561 = sub i16 0, %46
  %562 = insertelement <8 x i16> undef, i16 %561, i32 0
  %563 = shufflevector <8 x i16> %562, <8 x i16> undef, <8 x i32> zeroinitializer
  %564 = mul <8 x i16> %563, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %565 = and i16 %46, 63
  %566 = sub nsw i16 0, %565
  %567 = insertelement <8 x i16> undef, i16 %566, i32 0
  %568 = shufflevector <8 x i16> %567, <8 x i16> undef, <8 x i32> zeroinitializer
  %569 = add <8 x i16> %564, %568
  %570 = icmp eq i32 %6, 64
  %571 = sub <8 x i16> <i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64>, %38
  %572 = bitcast <8 x i16> %571 to <2 x i64>
  %573 = bitcast <8 x i16> %38 to <2 x i64>
  %574 = xor <2 x i64> %573, <i64 -1, i64 -1>
  %575 = select i1 %570, <2 x i64> %572, <2 x i64> %574
  %576 = ashr i32 %34, 6
  %577 = icmp sgt i32 %576, 1
  %578 = select i1 %577, i32 %576, i32 1
  %579 = sext i32 %5 to i64
  %580 = sext i32 %29 to i64
  br label %609

581:                                              ; preds = %981
  %582 = trunc i64 %717 to i32
  br label %583

583:                                              ; preds = %581, %557
  %584 = phi i32 [ 0, %557 ], [ %582, %581 ]
  %585 = icmp slt i32 %584, %4
  br i1 %585, label %586, label %7373

586:                                              ; preds = %583
  %587 = add nsw i32 %5, 3
  %588 = sext i32 %587 to i64
  %589 = ashr i32 %34, 6
  %590 = icmp sgt i32 %589, 1
  %591 = select i1 %590, i32 %589, i32 1
  %592 = sdiv i32 %587, %591
  %593 = icmp sgt i32 %592, %5
  %594 = select i1 %593, i32 %5, i32 %592
  %595 = icmp sgt i32 %594, 0
  %596 = trunc i32 %587 to i16
  %597 = insertelement <8 x i16> undef, i16 %596, i32 0
  %598 = shufflevector <8 x i16> %597, <8 x i16> undef, <8 x i32> zeroinitializer
  %599 = zext i32 %584 to i64
  %600 = sext i32 %4 to i64
  %601 = icmp sgt i32 %594, 0
  %602 = select i1 %601, i32 %594, i32 0
  %603 = sub i32 %5, %602
  %604 = xor i32 %602, -1
  %605 = add i32 %604, %5
  %606 = and i32 %603, 7
  %607 = icmp eq i32 %606, 0
  %608 = icmp ult i32 %605, 7
  br label %987

609:                                              ; preds = %981, %558
  %610 = phi i64 [ 0, %558 ], [ %717, %981 ]
  %611 = phi i32 [ %560, %558 ], [ %985, %981 ]
  %612 = phi <8 x i16> [ %569, %558 ], [ %984, %981 ]
  %613 = phi <2 x i64> [ %575, %558 ], [ %983, %981 ]
  %614 = getelementptr inbounds i8, i8* %0, i64 %610
  %615 = trunc i64 %610 to i32
  %616 = shl i32 %615, 6
  %617 = sdiv i32 %616, %6
  %618 = icmp sgt i32 %617, %5
  %619 = select i1 %618, i32 %5, i32 %617
  %620 = and i32 %619, -12
  %621 = getelementptr inbounds i8, i8* %19, i64 %610
  %622 = or i32 %620, 3
  %623 = sext i32 %622 to i64
  %624 = getelementptr inbounds i8, i8* %621, i64 %623
  %625 = load i8, i8* %624, align 1
  %626 = zext i8 %625 to i16
  %627 = insertelement <8 x i16> undef, i16 %626, i32 0
  %628 = shufflevector <8 x i16> %627, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %629 = sdiv i32 %622, %578
  %630 = icmp sgt i32 %629, %620
  %631 = select i1 %630, i32 %620, i32 %629
  %632 = icmp sgt i32 %631, 0
  br i1 %632, label %633, label %637

633:                                              ; preds = %609
  %634 = trunc i32 %622 to i16
  %635 = insertelement <8 x i16> undef, i16 %634, i32 0
  %636 = shufflevector <8 x i16> %635, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %660

637:                                              ; preds = %660, %609
  %638 = phi i32 [ 0, %609 ], [ %631, %660 ]
  %639 = phi i8* [ %614, %609 ], [ %693, %660 ]
  %640 = icmp sgt i32 %620, %638
  br i1 %640, label %641, label %709

641:                                              ; preds = %637
  %642 = load i8, i8* %624, align 1
  %643 = sub i32 %620, %638
  %644 = xor i32 %638, -1
  %645 = add i32 %620, %644
  %646 = and i32 %643, 7
  %647 = icmp eq i32 %646, 0
  br i1 %647, label %656, label %648

648:                                              ; preds = %641, %648
  %649 = phi i8* [ %652, %648 ], [ %639, %641 ]
  %650 = phi i32 [ %653, %648 ], [ %638, %641 ]
  %651 = phi i32 [ %654, %648 ], [ %646, %641 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %649, i8 %642, i64 4, i1 false) #11
  %652 = getelementptr inbounds i8, i8* %649, i64 %1
  %653 = add nuw nsw i32 %650, 1
  %654 = add i32 %651, -1
  %655 = icmp eq i32 %654, 0
  br i1 %655, label %656, label %648, !llvm.loop !8

656:                                              ; preds = %648, %641
  %657 = phi i8* [ %639, %641 ], [ %652, %648 ]
  %658 = phi i32 [ %638, %641 ], [ %653, %648 ]
  %659 = icmp ult i32 %645, 7
  br i1 %659, label %709, label %696

660:                                              ; preds = %660, %633
  %661 = phi i8* [ %614, %633 ], [ %693, %660 ]
  %662 = phi i32 [ 0, %633 ], [ %692, %660 ]
  %663 = phi i32 [ %34, %633 ], [ %694, %660 ]
  %664 = ashr i32 %663, 6
  %665 = lshr i32 %663, 1
  %666 = trunc i32 %665 to i8
  %667 = and i8 %666, 31
  %668 = insertelement <16 x i8> undef, i8 %667, i32 0
  %669 = shufflevector <16 x i8> %668, <16 x i8> undef, <16 x i32> zeroinitializer
  %670 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %669
  %671 = shufflevector <16 x i8> %670, <16 x i8> %669, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %672 = trunc i32 %664 to i16
  %673 = insertelement <8 x i16> undef, i16 %672, i32 0
  %674 = shufflevector <8 x i16> %673, <8 x i16> undef, <8 x i32> zeroinitializer
  %675 = add <8 x i16> %674, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %676 = sext i32 %664 to i64
  %677 = getelementptr inbounds i8, i8* %621, i64 %676
  %678 = bitcast i8* %677 to i64*
  %679 = load i64, i64* %678, align 1
  %680 = insertelement <2 x i64> undef, i64 %679, i32 0
  %681 = bitcast <2 x i64> %680 to <16 x i8>
  %682 = shufflevector <16 x i8> %681, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %683 = icmp sgt <8 x i16> %675, %636
  %684 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %682, <16 x i8> %671) #11
  %685 = lshr <8 x i16> %684, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %686 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %685, <8 x i16> zeroinitializer) #11
  %687 = select <8 x i1> %683, <8 x i16> %628, <8 x i16> %686
  %688 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %687, <8 x i16> undef) #11
  %689 = bitcast <16 x i8> %688 to <4 x i32>
  %690 = extractelement <4 x i32> %689, i32 0
  %691 = bitcast i8* %661 to i32*
  store i32 %690, i32* %691, align 1
  %692 = add nuw nsw i32 %662, 1
  %693 = getelementptr inbounds i8, i8* %661, i64 %1
  %694 = sub i32 %663, %6
  %695 = icmp slt i32 %692, %631
  br i1 %695, label %660, label %637

696:                                              ; preds = %656, %696
  %697 = phi i8* [ %706, %696 ], [ %657, %656 ]
  %698 = phi i32 [ %707, %696 ], [ %658, %656 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %697, i8 %642, i64 4, i1 false) #11
  %699 = getelementptr inbounds i8, i8* %697, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %699, i8 %642, i64 4, i1 false) #11
  %700 = getelementptr inbounds i8, i8* %699, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %700, i8 %642, i64 4, i1 false) #11
  %701 = getelementptr inbounds i8, i8* %700, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %701, i8 %642, i64 4, i1 false) #11
  %702 = getelementptr inbounds i8, i8* %701, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %702, i8 %642, i64 4, i1 false) #11
  %703 = getelementptr inbounds i8, i8* %702, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %703, i8 %642, i64 4, i1 false) #11
  %704 = getelementptr inbounds i8, i8* %703, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %704, i8 %642, i64 4, i1 false) #11
  %705 = getelementptr inbounds i8, i8* %704, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %705, i8 %642, i64 4, i1 false) #11
  %706 = getelementptr inbounds i8, i8* %705, i64 %1
  %707 = add nuw nsw i32 %698, 8
  %708 = icmp eq i32 %707, %620
  br i1 %708, label %709, label %696

709:                                              ; preds = %656, %696, %637
  %710 = sext i32 %620 to i64
  %711 = mul nsw i64 %710, %1
  %712 = getelementptr inbounds i8, i8* %614, i64 %711
  %713 = mul nsw i32 %620, %6
  %714 = trunc i32 %713 to i16
  %715 = insertelement <8 x i16> undef, i16 %714, i32 0
  %716 = shufflevector <8 x i16> %715, <8 x i16> undef, <8 x i32> zeroinitializer
  %717 = add nuw nsw i64 %610, 4
  %718 = trunc i64 %717 to i32
  %719 = shl i32 %718, 6
  %720 = sdiv i32 %719, %6
  %721 = icmp sgt i32 %720, %5
  %722 = select i1 %721, i32 %5, i32 %720
  %723 = bitcast <2 x i64> %613 to <8 x i16>
  %724 = icmp slt i32 %620, %722
  br i1 %724, label %725, label %744

725:                                              ; preds = %709
  %726 = sub nsw i32 0, %713
  %727 = sub <8 x i16> %38, %716
  %728 = add <8 x i16> %716, %723
  %729 = ashr <8 x i16> %612, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %730 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %729, <8 x i16> %729) #11
  %731 = add <16 x i8> %730, <i8 1, i8 1, i8 1, i8 1, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %732 = shufflevector <16 x i8> %730, <16 x i8> %731, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %733 = add <16 x i8> %732, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %734 = and <8 x i16> %612, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %735 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %734, <8 x i16> %734) #11
  %736 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %735
  %737 = shufflevector <16 x i8> %736, <16 x i8> %735, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %738 = sext i32 %722 to i64
  %739 = sub i32 3, %620
  %740 = add i32 %739, %722
  br label %759

741:                                              ; preds = %759
  %742 = and i32 %740, -4
  %743 = add i32 %742, %620
  br label %744

744:                                              ; preds = %741, %709
  %745 = phi i8* [ %712, %709 ], [ %918, %741 ]
  %746 = phi i32 [ %620, %709 ], [ %743, %741 ]
  %747 = icmp slt i32 %746, %5
  br i1 %747, label %748, label %981

748:                                              ; preds = %744
  %749 = ashr <8 x i16> %612, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %750 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %749, <8 x i16> %749) #11
  %751 = add <16 x i8> %750, <i8 1, i8 1, i8 1, i8 1, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %752 = shufflevector <16 x i8> %750, <16 x i8> %751, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %753 = add <16 x i8> %752, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %754 = and <8 x i16> %612, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %755 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %754, <8 x i16> %754) #11
  %756 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %755
  %757 = shufflevector <16 x i8> %756, <16 x i8> %755, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %758 = sext i32 %746 to i64
  br label %923

759:                                              ; preds = %759, %725
  %760 = phi i64 [ %710, %725 ], [ %916, %759 ]
  %761 = phi i32 [ %726, %725 ], [ %921, %759 ]
  %762 = phi <8 x i16> [ %727, %725 ], [ %920, %759 ]
  %763 = phi <8 x i16> [ %728, %725 ], [ %919, %759 ]
  %764 = phi i32 [ %620, %725 ], [ %917, %759 ]
  %765 = phi i8* [ %712, %725 ], [ %918, %759 ]
  %766 = add nsw i32 %764, %611
  %767 = shl nsw i32 %766, 1
  %768 = sext i32 %767 to i64
  %769 = getelementptr inbounds i8, i8* %20, i64 %768
  %770 = getelementptr inbounds i8, i8* %769, i64 -15
  %771 = bitcast i8* %770 to <16 x i8>*
  %772 = load <16 x i8>, <16 x i8>* %771, align 1
  %773 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %772, <16 x i8> %733) #11
  %774 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %773, <16 x i8> %737) #11
  %775 = lshr <8 x i16> %774, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %776 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %775, <8 x i16> zeroinitializer) #11
  %777 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %776, <8 x i16> undef) #11
  %778 = bitcast <16 x i8> %777 to <4 x i32>
  %779 = extractelement <4 x i32> %778, i32 0
  %780 = bitcast i8* %765 to i32*
  store i32 %779, i32* %780, align 1
  %781 = getelementptr inbounds i8, i8* %765, i64 %1
  %782 = getelementptr inbounds i8, i8* %769, i64 -13
  %783 = bitcast i8* %782 to <16 x i8>*
  %784 = load <16 x i8>, <16 x i8>* %783, align 1
  %785 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %784, <16 x i8> %733) #11
  %786 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %785, <16 x i8> %737) #11
  %787 = lshr <8 x i16> %786, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %788 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %787, <8 x i16> zeroinitializer) #11
  %789 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %788, <8 x i16> undef) #11
  %790 = bitcast <16 x i8> %789 to <4 x i32>
  %791 = extractelement <4 x i32> %790, i32 0
  %792 = bitcast i8* %781 to i32*
  store i32 %791, i32* %792, align 1
  %793 = getelementptr inbounds i8, i8* %781, i64 %1
  %794 = getelementptr inbounds i8, i8* %769, i64 -11
  %795 = bitcast i8* %794 to <16 x i8>*
  %796 = load <16 x i8>, <16 x i8>* %795, align 1
  %797 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %796, <16 x i8> %733) #11
  %798 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %797, <16 x i8> %737) #11
  %799 = lshr <8 x i16> %798, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %800 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %799, <8 x i16> zeroinitializer) #11
  %801 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %800, <8 x i16> undef) #11
  %802 = bitcast <16 x i8> %801 to <4 x i32>
  %803 = extractelement <4 x i32> %802, i32 0
  %804 = bitcast i8* %793 to i32*
  store i32 %803, i32* %804, align 1
  %805 = getelementptr inbounds i8, i8* %793, i64 %1
  %806 = getelementptr inbounds i8, i8* %769, i64 -9
  %807 = bitcast i8* %806 to <16 x i8>*
  %808 = load <16 x i8>, <16 x i8>* %807, align 1
  %809 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %808, <16 x i8> %733) #11
  %810 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %809, <16 x i8> %737) #11
  %811 = lshr <8 x i16> %810, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %812 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %811, <8 x i16> zeroinitializer) #11
  %813 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %812, <8 x i16> undef) #11
  %814 = bitcast <16 x i8> %813 to <4 x i32>
  %815 = extractelement <4 x i32> %814, i32 0
  %816 = bitcast i8* %805 to i32*
  store i32 %815, i32* %816, align 1
  %817 = lshr <8 x i16> %762, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %818 = and <8 x i16> %817, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %819 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %818, <8 x i16> %818) #11
  %820 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %819
  %821 = shufflevector <16 x i8> %820, <16 x i8> %819, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %822 = ashr <8 x i16> %763, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %823 = sub nsw i32 %761, %6
  %824 = ashr i32 %823, 6
  %825 = sext i32 %824 to i64
  %826 = getelementptr inbounds i8, i8* %621, i64 %825
  %827 = bitcast <16 x i8> %821 to <8 x i16>
  %828 = shufflevector <8 x i16> %827, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %829 = bitcast i8* %826 to <16 x i8>*
  %830 = load <16 x i8>, <16 x i8>* %829, align 1
  %831 = shufflevector <16 x i8> %830, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %832 = bitcast <8 x i16> %828 to <16 x i8>
  %833 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %831, <16 x i8> %832) #11
  %834 = lshr <8 x i16> %833, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %835 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %834, <8 x i16> zeroinitializer) #11
  %836 = shufflevector <8 x i16> %822, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %837 = icmp sgt <8 x i16> %836, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %838 = load i32, i32* %780, align 1
  %839 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %838, i32 0
  %840 = bitcast <4 x i32> %839 to <16 x i8>
  %841 = shufflevector <16 x i8> %840, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %842 = zext <8 x i8> %841 to <8 x i16>
  %843 = select <8 x i1> %837, <8 x i16> %842, <8 x i16> %835
  %844 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %843, <8 x i16> undef) #11
  %845 = bitcast <16 x i8> %844 to <4 x i32>
  %846 = extractelement <4 x i32> %845, i32 0
  store i32 %846, i32* %780, align 1
  %847 = sub nsw i32 %823, %6
  %848 = ashr i32 %847, 6
  %849 = sext i32 %848 to i64
  %850 = getelementptr inbounds i8, i8* %621, i64 %849
  %851 = shufflevector <8 x i16> %827, <8 x i16> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 4, i32 5, i32 6, i32 7>
  %852 = bitcast i8* %850 to <16 x i8>*
  %853 = load <16 x i8>, <16 x i8>* %852, align 1
  %854 = shufflevector <16 x i8> %853, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %855 = bitcast <8 x i16> %851 to <16 x i8>
  %856 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %854, <16 x i8> %855) #11
  %857 = lshr <8 x i16> %856, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %858 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %857, <8 x i16> zeroinitializer) #11
  %859 = shufflevector <8 x i16> %822, <8 x i16> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 4, i32 5, i32 6, i32 7>
  %860 = icmp sgt <8 x i16> %859, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %861 = load i32, i32* %792, align 1
  %862 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %861, i32 0
  %863 = bitcast <4 x i32> %862 to <16 x i8>
  %864 = shufflevector <16 x i8> %863, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %865 = zext <8 x i8> %864 to <8 x i16>
  %866 = select <8 x i1> %860, <8 x i16> %865, <8 x i16> %858
  %867 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %866, <8 x i16> undef) #11
  %868 = bitcast <16 x i8> %867 to <4 x i32>
  %869 = extractelement <4 x i32> %868, i32 0
  store i32 %869, i32* %792, align 1
  %870 = sub nsw i32 %847, %6
  %871 = ashr i32 %870, 6
  %872 = sext i32 %871 to i64
  %873 = getelementptr inbounds i8, i8* %621, i64 %872
  %874 = shufflevector <8 x i16> %827, <8 x i16> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 4, i32 5, i32 6, i32 7>
  %875 = bitcast i8* %873 to <16 x i8>*
  %876 = load <16 x i8>, <16 x i8>* %875, align 1
  %877 = shufflevector <16 x i8> %876, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %878 = bitcast <8 x i16> %874 to <16 x i8>
  %879 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %877, <16 x i8> %878) #11
  %880 = lshr <8 x i16> %879, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %881 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %880, <8 x i16> zeroinitializer) #11
  %882 = shufflevector <8 x i16> %822, <8 x i16> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 4, i32 5, i32 6, i32 7>
  %883 = icmp sgt <8 x i16> %882, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %884 = load i32, i32* %804, align 1
  %885 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %884, i32 0
  %886 = bitcast <4 x i32> %885 to <16 x i8>
  %887 = shufflevector <16 x i8> %886, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %888 = zext <8 x i8> %887 to <8 x i16>
  %889 = select <8 x i1> %883, <8 x i16> %888, <8 x i16> %881
  %890 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %889, <8 x i16> undef) #11
  %891 = bitcast <16 x i8> %890 to <4 x i32>
  %892 = extractelement <4 x i32> %891, i32 0
  store i32 %892, i32* %804, align 1
  %893 = sub nsw i32 %870, %6
  %894 = ashr i32 %893, 6
  %895 = sext i32 %894 to i64
  %896 = getelementptr inbounds i8, i8* %621, i64 %895
  %897 = shufflevector <8 x i16> %827, <8 x i16> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 4, i32 5, i32 6, i32 7>
  %898 = bitcast i8* %896 to <16 x i8>*
  %899 = load <16 x i8>, <16 x i8>* %898, align 1
  %900 = shufflevector <16 x i8> %899, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %901 = bitcast <8 x i16> %897 to <16 x i8>
  %902 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %900, <16 x i8> %901) #11
  %903 = lshr <8 x i16> %902, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %904 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %903, <8 x i16> zeroinitializer) #11
  %905 = shufflevector <8 x i16> %822, <8 x i16> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 4, i32 5, i32 6, i32 7>
  %906 = icmp sgt <8 x i16> %905, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %907 = load i32, i32* %816, align 1
  %908 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %907, i32 0
  %909 = bitcast <4 x i32> %908 to <16 x i8>
  %910 = shufflevector <16 x i8> %909, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %911 = zext <8 x i8> %910 to <8 x i16>
  %912 = select <8 x i1> %906, <8 x i16> %911, <8 x i16> %904
  %913 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %912, <8 x i16> undef) #11
  %914 = bitcast <16 x i8> %913 to <4 x i32>
  %915 = extractelement <4 x i32> %914, i32 0
  store i32 %915, i32* %816, align 1
  %916 = add nsw i64 %760, 4
  %917 = add nsw i32 %764, 4
  %918 = getelementptr inbounds i8, i8* %765, i64 %25
  %919 = add <8 x i16> %763, %33
  %920 = sub <8 x i16> %762, %33
  %921 = sub nsw i32 %761, %30
  %922 = icmp slt i64 %916, %738
  br i1 %922, label %759, label %741

923:                                              ; preds = %923, %748
  %924 = phi i64 [ %758, %748 ], [ %978, %923 ]
  %925 = phi i8* [ %745, %748 ], [ %979, %923 ]
  %926 = trunc i64 %924 to i32
  %927 = add i32 %611, %926
  %928 = shl i32 %927, 1
  %929 = sext i32 %928 to i64
  %930 = getelementptr inbounds i8, i8* %20, i64 %929
  %931 = getelementptr inbounds i8, i8* %930, i64 -15
  %932 = bitcast i8* %931 to <16 x i8>*
  %933 = load <16 x i8>, <16 x i8>* %932, align 1
  %934 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %933, <16 x i8> %753) #11
  %935 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %934, <16 x i8> %757) #11
  %936 = lshr <8 x i16> %935, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %937 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %936, <8 x i16> zeroinitializer) #11
  %938 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %937, <8 x i16> undef) #11
  %939 = bitcast <16 x i8> %938 to <4 x i32>
  %940 = extractelement <4 x i32> %939, i32 0
  %941 = bitcast i8* %925 to i32*
  store i32 %940, i32* %941, align 1
  %942 = getelementptr inbounds i8, i8* %925, i64 %1
  %943 = getelementptr inbounds i8, i8* %930, i64 -13
  %944 = bitcast i8* %943 to <16 x i8>*
  %945 = load <16 x i8>, <16 x i8>* %944, align 1
  %946 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %945, <16 x i8> %753) #11
  %947 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %946, <16 x i8> %757) #11
  %948 = lshr <8 x i16> %947, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %949 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %948, <8 x i16> zeroinitializer) #11
  %950 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %949, <8 x i16> undef) #11
  %951 = bitcast <16 x i8> %950 to <4 x i32>
  %952 = extractelement <4 x i32> %951, i32 0
  %953 = bitcast i8* %942 to i32*
  store i32 %952, i32* %953, align 1
  %954 = getelementptr inbounds i8, i8* %942, i64 %1
  %955 = getelementptr inbounds i8, i8* %930, i64 -11
  %956 = bitcast i8* %955 to <16 x i8>*
  %957 = load <16 x i8>, <16 x i8>* %956, align 1
  %958 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %957, <16 x i8> %753) #11
  %959 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %958, <16 x i8> %757) #11
  %960 = lshr <8 x i16> %959, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %961 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %960, <8 x i16> zeroinitializer) #11
  %962 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %961, <8 x i16> undef) #11
  %963 = bitcast <16 x i8> %962 to <4 x i32>
  %964 = extractelement <4 x i32> %963, i32 0
  %965 = bitcast i8* %954 to i32*
  store i32 %964, i32* %965, align 1
  %966 = getelementptr inbounds i8, i8* %954, i64 %1
  %967 = getelementptr inbounds i8, i8* %930, i64 -9
  %968 = bitcast i8* %967 to <16 x i8>*
  %969 = load <16 x i8>, <16 x i8>* %968, align 1
  %970 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %969, <16 x i8> %753) #11
  %971 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %970, <16 x i8> %757) #11
  %972 = lshr <8 x i16> %971, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %973 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %972, <8 x i16> zeroinitializer) #11
  %974 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %973, <8 x i16> undef) #11
  %975 = bitcast <16 x i8> %974 to <4 x i32>
  %976 = extractelement <4 x i32> %975, i32 0
  %977 = bitcast i8* %966 to i32*
  store i32 %976, i32* %977, align 1
  %978 = add nsw i64 %924, 4
  %979 = getelementptr inbounds i8, i8* %925, i64 %25
  %980 = icmp slt i64 %978, %579
  br i1 %980, label %923, label %981

981:                                              ; preds = %923, %744
  %982 = add <8 x i16> %723, <i16 -256, i16 -256, i16 -256, i16 -256, i16 -256, i16 -256, i16 -256, i16 -256>
  %983 = bitcast <8 x i16> %982 to <2 x i64>
  %984 = add <8 x i16> %612, %45
  %985 = sub nsw i32 %611, %40
  %986 = icmp slt i64 %717, %580
  br i1 %986, label %609, label %581

987:                                              ; preds = %1062, %586
  %988 = phi i64 [ %599, %586 ], [ %1063, %1062 ]
  %989 = getelementptr inbounds i8, i8* %0, i64 %988
  %990 = getelementptr inbounds i8, i8* %19, i64 %988
  %991 = getelementptr inbounds i8, i8* %990, i64 %588
  %992 = load i8, i8* %991, align 1
  %993 = zext i8 %992 to i16
  %994 = insertelement <8 x i16> undef, i16 %993, i32 0
  %995 = shufflevector <8 x i16> %994, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  br i1 %595, label %1013, label %996

996:                                              ; preds = %1013, %987
  %997 = phi i32 [ 0, %987 ], [ %594, %1013 ]
  %998 = phi i8* [ %989, %987 ], [ %1046, %1013 ]
  %999 = icmp slt i32 %997, %5
  br i1 %999, label %1000, label %1062

1000:                                             ; preds = %996
  %1001 = load i8, i8* %991, align 1
  br i1 %607, label %1010, label %1002

1002:                                             ; preds = %1000, %1002
  %1003 = phi i8* [ %1006, %1002 ], [ %998, %1000 ]
  %1004 = phi i32 [ %1007, %1002 ], [ %997, %1000 ]
  %1005 = phi i32 [ %1008, %1002 ], [ %606, %1000 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1003, i8 %1001, i64 4, i1 false) #11
  %1006 = getelementptr inbounds i8, i8* %1003, i64 %1
  %1007 = add nuw nsw i32 %1004, 1
  %1008 = add i32 %1005, -1
  %1009 = icmp eq i32 %1008, 0
  br i1 %1009, label %1010, label %1002, !llvm.loop !9

1010:                                             ; preds = %1002, %1000
  %1011 = phi i8* [ %998, %1000 ], [ %1006, %1002 ]
  %1012 = phi i32 [ %997, %1000 ], [ %1007, %1002 ]
  br i1 %608, label %1062, label %1049

1013:                                             ; preds = %987, %1013
  %1014 = phi i8* [ %1046, %1013 ], [ %989, %987 ]
  %1015 = phi i32 [ %1045, %1013 ], [ 0, %987 ]
  %1016 = phi i32 [ %1047, %1013 ], [ %34, %987 ]
  %1017 = ashr i32 %1016, 6
  %1018 = lshr i32 %1016, 1
  %1019 = trunc i32 %1018 to i8
  %1020 = and i8 %1019, 31
  %1021 = insertelement <16 x i8> undef, i8 %1020, i32 0
  %1022 = shufflevector <16 x i8> %1021, <16 x i8> undef, <16 x i32> zeroinitializer
  %1023 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %1022
  %1024 = shufflevector <16 x i8> %1023, <16 x i8> %1022, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1025 = trunc i32 %1017 to i16
  %1026 = insertelement <8 x i16> undef, i16 %1025, i32 0
  %1027 = shufflevector <8 x i16> %1026, <8 x i16> undef, <8 x i32> zeroinitializer
  %1028 = add <8 x i16> %1027, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %1029 = sext i32 %1017 to i64
  %1030 = getelementptr inbounds i8, i8* %990, i64 %1029
  %1031 = bitcast i8* %1030 to i64*
  %1032 = load i64, i64* %1031, align 1
  %1033 = insertelement <2 x i64> undef, i64 %1032, i32 0
  %1034 = bitcast <2 x i64> %1033 to <16 x i8>
  %1035 = shufflevector <16 x i8> %1034, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %1036 = icmp sgt <8 x i16> %1028, %598
  %1037 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1035, <16 x i8> %1024) #11
  %1038 = lshr <8 x i16> %1037, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1039 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1038, <8 x i16> zeroinitializer) #11
  %1040 = select <8 x i1> %1036, <8 x i16> %995, <8 x i16> %1039
  %1041 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1040, <8 x i16> undef) #11
  %1042 = bitcast <16 x i8> %1041 to <4 x i32>
  %1043 = extractelement <4 x i32> %1042, i32 0
  %1044 = bitcast i8* %1014 to i32*
  store i32 %1043, i32* %1044, align 1
  %1045 = add nuw nsw i32 %1015, 1
  %1046 = getelementptr inbounds i8, i8* %1014, i64 %1
  %1047 = sub i32 %1016, %6
  %1048 = icmp slt i32 %1045, %594
  br i1 %1048, label %1013, label %996

1049:                                             ; preds = %1010, %1049
  %1050 = phi i8* [ %1059, %1049 ], [ %1011, %1010 ]
  %1051 = phi i32 [ %1060, %1049 ], [ %1012, %1010 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1050, i8 %1001, i64 4, i1 false) #11
  %1052 = getelementptr inbounds i8, i8* %1050, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1052, i8 %1001, i64 4, i1 false) #11
  %1053 = getelementptr inbounds i8, i8* %1052, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1053, i8 %1001, i64 4, i1 false) #11
  %1054 = getelementptr inbounds i8, i8* %1053, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1054, i8 %1001, i64 4, i1 false) #11
  %1055 = getelementptr inbounds i8, i8* %1054, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1055, i8 %1001, i64 4, i1 false) #11
  %1056 = getelementptr inbounds i8, i8* %1055, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1056, i8 %1001, i64 4, i1 false) #11
  %1057 = getelementptr inbounds i8, i8* %1056, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1057, i8 %1001, i64 4, i1 false) #11
  %1058 = getelementptr inbounds i8, i8* %1057, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1058, i8 %1001, i64 4, i1 false) #11
  %1059 = getelementptr inbounds i8, i8* %1058, i64 %1
  %1060 = add nuw nsw i32 %1051, 8
  %1061 = icmp eq i32 %1060, %5
  br i1 %1061, label %1062, label %1049

1062:                                             ; preds = %1010, %1049, %996
  %1063 = add nuw nsw i64 %988, 4
  %1064 = icmp slt i64 %1063, %600
  br i1 %1064, label %987, label %7373

1065:                                             ; preds = %24
  br i1 %8, label %1066, label %1568

1066:                                             ; preds = %1065
  br i1 %47, label %1067, label %1092

1067:                                             ; preds = %1066
  %1068 = ashr i32 %7, 6
  %1069 = sub nsw i32 0, %1068
  %1070 = sub i16 0, %46
  %1071 = insertelement <8 x i16> undef, i16 %1070, i32 0
  %1072 = shufflevector <8 x i16> %1071, <8 x i16> undef, <8 x i32> zeroinitializer
  %1073 = mul <8 x i16> %1072, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %1074 = and i16 %46, 63
  %1075 = sub nsw i16 0, %1074
  %1076 = insertelement <8 x i16> undef, i16 %1075, i32 0
  %1077 = shufflevector <8 x i16> %1076, <8 x i16> undef, <8 x i32> zeroinitializer
  %1078 = add <8 x i16> %1073, %1077
  %1079 = icmp eq i32 %6, 64
  %1080 = sub <8 x i16> <i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64>, %38
  %1081 = bitcast <8 x i16> %1080 to <2 x i64>
  %1082 = bitcast <8 x i16> %38 to <2 x i64>
  %1083 = xor <2 x i64> %1082, <i64 -1, i64 -1>
  %1084 = select i1 %1079, <2 x i64> %1081, <2 x i64> %1083
  %1085 = ashr i32 %34, 5
  %1086 = icmp sgt i32 %1085, 1
  %1087 = select i1 %1086, i32 %1085, i32 1
  %1088 = sext i32 %5 to i64
  %1089 = sext i32 %29 to i64
  br label %1119

1090:                                             ; preds = %1482
  %1091 = trunc i64 %1229 to i32
  br label %1092

1092:                                             ; preds = %1090, %1066
  %1093 = phi i32 [ 0, %1066 ], [ %1091, %1090 ]
  %1094 = icmp slt i32 %1093, %4
  br i1 %1094, label %1095, label %7373

1095:                                             ; preds = %1092
  %1096 = shl i32 %5, 1
  %1097 = add i32 %1096, 6
  %1098 = sext i32 %1097 to i64
  %1099 = ashr i32 %34, 5
  %1100 = icmp sgt i32 %1099, 1
  %1101 = select i1 %1100, i32 %1099, i32 1
  %1102 = sdiv i32 %1097, %1101
  %1103 = icmp sgt i32 %1102, %5
  %1104 = select i1 %1103, i32 %5, i32 %1102
  %1105 = icmp sgt i32 %1104, 0
  %1106 = trunc i32 %1097 to i16
  %1107 = insertelement <8 x i16> undef, i16 %1106, i32 0
  %1108 = shufflevector <8 x i16> %1107, <8 x i16> undef, <8 x i32> zeroinitializer
  %1109 = zext i32 %1093 to i64
  %1110 = sext i32 %4 to i64
  %1111 = icmp sgt i32 %1104, 0
  %1112 = select i1 %1111, i32 %1104, i32 0
  %1113 = sub i32 %5, %1112
  %1114 = xor i32 %1112, -1
  %1115 = add i32 %1114, %5
  %1116 = and i32 %1113, 7
  %1117 = icmp eq i32 %1116, 0
  %1118 = icmp ult i32 %1115, 7
  br label %1488

1119:                                             ; preds = %1482, %1067
  %1120 = phi i64 [ 0, %1067 ], [ %1229, %1482 ]
  %1121 = phi i32 [ %1069, %1067 ], [ %1486, %1482 ]
  %1122 = phi <8 x i16> [ %1078, %1067 ], [ %1485, %1482 ]
  %1123 = phi <2 x i64> [ %1084, %1067 ], [ %1484, %1482 ]
  %1124 = getelementptr inbounds i8, i8* %0, i64 %1120
  %1125 = trunc i64 %1120 to i32
  %1126 = shl i32 %1125, 6
  %1127 = sdiv i32 %1126, %6
  %1128 = icmp sgt i32 %1127, %5
  %1129 = select i1 %1128, i32 %5, i32 %1127
  %1130 = and i32 %1129, -12
  %1131 = shl i32 %1125, 1
  %1132 = sext i32 %1131 to i64
  %1133 = getelementptr inbounds i8, i8* %19, i64 %1132
  %1134 = shl i32 %1130, 1
  %1135 = or i32 %1134, 6
  %1136 = sext i32 %1135 to i64
  %1137 = getelementptr inbounds i8, i8* %1133, i64 %1136
  %1138 = load i8, i8* %1137, align 2
  %1139 = zext i8 %1138 to i16
  %1140 = insertelement <8 x i16> undef, i16 %1139, i32 0
  %1141 = shufflevector <8 x i16> %1140, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %1142 = sdiv i32 %1135, %1087
  %1143 = icmp sgt i32 %1142, %1130
  %1144 = select i1 %1143, i32 %1130, i32 %1142
  %1145 = icmp sgt i32 %1144, 0
  br i1 %1145, label %1146, label %1150

1146:                                             ; preds = %1119
  %1147 = trunc i32 %1135 to i16
  %1148 = insertelement <8 x i16> undef, i16 %1147, i32 0
  %1149 = shufflevector <8 x i16> %1148, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %1173

1150:                                             ; preds = %1173, %1119
  %1151 = phi i32 [ 0, %1119 ], [ %1144, %1173 ]
  %1152 = phi i8* [ %1124, %1119 ], [ %1205, %1173 ]
  %1153 = icmp sgt i32 %1130, %1151
  br i1 %1153, label %1154, label %1221

1154:                                             ; preds = %1150
  %1155 = load i8, i8* %1137, align 2
  %1156 = sub i32 %1130, %1151
  %1157 = xor i32 %1151, -1
  %1158 = add i32 %1130, %1157
  %1159 = and i32 %1156, 7
  %1160 = icmp eq i32 %1159, 0
  br i1 %1160, label %1169, label %1161

1161:                                             ; preds = %1154, %1161
  %1162 = phi i8* [ %1165, %1161 ], [ %1152, %1154 ]
  %1163 = phi i32 [ %1166, %1161 ], [ %1151, %1154 ]
  %1164 = phi i32 [ %1167, %1161 ], [ %1159, %1154 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1162, i8 %1155, i64 4, i1 false) #11
  %1165 = getelementptr inbounds i8, i8* %1162, i64 %1
  %1166 = add nuw nsw i32 %1163, 1
  %1167 = add i32 %1164, -1
  %1168 = icmp eq i32 %1167, 0
  br i1 %1168, label %1169, label %1161, !llvm.loop !10

1169:                                             ; preds = %1161, %1154
  %1170 = phi i8* [ %1152, %1154 ], [ %1165, %1161 ]
  %1171 = phi i32 [ %1151, %1154 ], [ %1166, %1161 ]
  %1172 = icmp ult i32 %1158, 7
  br i1 %1172, label %1221, label %1208

1173:                                             ; preds = %1173, %1146
  %1174 = phi i8* [ %1124, %1146 ], [ %1205, %1173 ]
  %1175 = phi i32 [ 0, %1146 ], [ %1204, %1173 ]
  %1176 = phi i32 [ %34, %1146 ], [ %1206, %1173 ]
  %1177 = ashr i32 %1176, 5
  %1178 = trunc i32 %1176 to i8
  %1179 = and i8 %1178, 31
  %1180 = insertelement <16 x i8> undef, i8 %1179, i32 0
  %1181 = shufflevector <16 x i8> %1180, <16 x i8> undef, <16 x i32> zeroinitializer
  %1182 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %1181
  %1183 = shufflevector <16 x i8> %1182, <16 x i8> %1181, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1184 = trunc i32 %1177 to i16
  %1185 = insertelement <8 x i16> undef, i16 %1184, i32 0
  %1186 = shufflevector <8 x i16> %1185, <8 x i16> undef, <8 x i32> zeroinitializer
  %1187 = add <8 x i16> %1186, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %1188 = sext i32 %1177 to i64
  %1189 = getelementptr inbounds i8, i8* %1133, i64 %1188
  %1190 = bitcast i8* %1189 to i64*
  %1191 = load i64, i64* %1190, align 1
  %1192 = insertelement <2 x i64> undef, i64 %1191, i32 0
  %1193 = bitcast <2 x i64> %1192 to <16 x i8>
  %1194 = shufflevector <16 x i8> %1193, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %1195 = icmp sgt <8 x i16> %1187, %1149
  %1196 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1194, <16 x i8> %1183) #11
  %1197 = lshr <8 x i16> %1196, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1198 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1197, <8 x i16> zeroinitializer) #11
  %1199 = select <8 x i1> %1195, <8 x i16> %1141, <8 x i16> %1198
  %1200 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1199, <8 x i16> undef) #11
  %1201 = bitcast <16 x i8> %1200 to <4 x i32>
  %1202 = extractelement <4 x i32> %1201, i32 0
  %1203 = bitcast i8* %1174 to i32*
  store i32 %1202, i32* %1203, align 1
  %1204 = add nuw nsw i32 %1175, 1
  %1205 = getelementptr inbounds i8, i8* %1174, i64 %1
  %1206 = sub i32 %1176, %6
  %1207 = icmp slt i32 %1204, %1144
  br i1 %1207, label %1173, label %1150

1208:                                             ; preds = %1169, %1208
  %1209 = phi i8* [ %1218, %1208 ], [ %1170, %1169 ]
  %1210 = phi i32 [ %1219, %1208 ], [ %1171, %1169 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1209, i8 %1155, i64 4, i1 false) #11
  %1211 = getelementptr inbounds i8, i8* %1209, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1211, i8 %1155, i64 4, i1 false) #11
  %1212 = getelementptr inbounds i8, i8* %1211, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1212, i8 %1155, i64 4, i1 false) #11
  %1213 = getelementptr inbounds i8, i8* %1212, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1213, i8 %1155, i64 4, i1 false) #11
  %1214 = getelementptr inbounds i8, i8* %1213, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1214, i8 %1155, i64 4, i1 false) #11
  %1215 = getelementptr inbounds i8, i8* %1214, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1215, i8 %1155, i64 4, i1 false) #11
  %1216 = getelementptr inbounds i8, i8* %1215, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1216, i8 %1155, i64 4, i1 false) #11
  %1217 = getelementptr inbounds i8, i8* %1216, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1217, i8 %1155, i64 4, i1 false) #11
  %1218 = getelementptr inbounds i8, i8* %1217, i64 %1
  %1219 = add nuw nsw i32 %1210, 8
  %1220 = icmp eq i32 %1219, %1130
  br i1 %1220, label %1221, label %1208

1221:                                             ; preds = %1169, %1208, %1150
  %1222 = sext i32 %1130 to i64
  %1223 = mul nsw i64 %1222, %1
  %1224 = getelementptr inbounds i8, i8* %1124, i64 %1223
  %1225 = mul nsw i32 %1130, %6
  %1226 = trunc i32 %1225 to i16
  %1227 = insertelement <8 x i16> undef, i16 %1226, i32 0
  %1228 = shufflevector <8 x i16> %1227, <8 x i16> undef, <8 x i32> zeroinitializer
  %1229 = add nuw nsw i64 %1120, 4
  %1230 = trunc i64 %1229 to i32
  %1231 = shl i32 %1230, 6
  %1232 = sdiv i32 %1231, %6
  %1233 = icmp sgt i32 %1232, %5
  %1234 = select i1 %1233, i32 %5, i32 %1232
  %1235 = bitcast <2 x i64> %1123 to <8 x i16>
  %1236 = icmp slt i32 %1130, %1234
  br i1 %1236, label %1237, label %1255

1237:                                             ; preds = %1221
  %1238 = sub nsw i32 0, %1225
  %1239 = sub <8 x i16> %38, %1228
  %1240 = add <8 x i16> %1228, %1235
  %1241 = ashr <8 x i16> %1122, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %1242 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %1241, <8 x i16> %1241) #11
  %1243 = add <16 x i8> %1242, <i8 1, i8 1, i8 1, i8 1, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %1244 = shufflevector <16 x i8> %1242, <16 x i8> %1243, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1245 = add <16 x i8> %1244, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %1246 = lshr <8 x i16> %1122, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %1247 = and <8 x i16> %1246, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %1248 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1247, <8 x i16> %1247) #11
  %1249 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %1248
  %1250 = shufflevector <16 x i8> %1249, <16 x i8> %1248, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1251 = sext i32 %1121 to i64
  %1252 = sext i32 %1234 to i64
  br label %1272

1253:                                             ; preds = %1272
  %1254 = trunc i64 %1421 to i32
  br label %1255

1255:                                             ; preds = %1253, %1221
  %1256 = phi i8* [ %1224, %1221 ], [ %1422, %1253 ]
  %1257 = phi i32 [ %1130, %1221 ], [ %1254, %1253 ]
  %1258 = icmp slt i32 %1257, %5
  br i1 %1258, label %1259, label %1482

1259:                                             ; preds = %1255
  %1260 = ashr <8 x i16> %1122, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %1261 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %1260, <8 x i16> %1260) #11
  %1262 = add <16 x i8> %1261, <i8 1, i8 1, i8 1, i8 1, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %1263 = shufflevector <16 x i8> %1261, <16 x i8> %1262, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1264 = add <16 x i8> %1263, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %1265 = lshr <8 x i16> %1122, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %1266 = and <8 x i16> %1265, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %1267 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1266, <8 x i16> %1266) #11
  %1268 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %1267
  %1269 = shufflevector <16 x i8> %1268, <16 x i8> %1267, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1270 = sext i32 %1257 to i64
  %1271 = sext i32 %1121 to i64
  br label %1427

1272:                                             ; preds = %1272, %1237
  %1273 = phi i64 [ %1222, %1237 ], [ %1421, %1272 ]
  %1274 = phi i32 [ %1238, %1237 ], [ %1425, %1272 ]
  %1275 = phi <8 x i16> [ %1239, %1237 ], [ %1424, %1272 ]
  %1276 = phi <8 x i16> [ %1240, %1237 ], [ %1423, %1272 ]
  %1277 = phi i8* [ %1224, %1237 ], [ %1422, %1272 ]
  %1278 = add nsw i64 %1273, %1251
  %1279 = getelementptr inbounds i8, i8* %20, i64 %1278
  %1280 = getelementptr inbounds i8, i8* %1279, i64 -15
  %1281 = bitcast i8* %1280 to <16 x i8>*
  %1282 = load <16 x i8>, <16 x i8>* %1281, align 1
  %1283 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1282, <16 x i8> %1245) #11
  %1284 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1283, <16 x i8> %1250) #11
  %1285 = lshr <8 x i16> %1284, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1286 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1285, <8 x i16> zeroinitializer) #11
  %1287 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1286, <8 x i16> undef) #11
  %1288 = bitcast <16 x i8> %1287 to <4 x i32>
  %1289 = extractelement <4 x i32> %1288, i32 0
  %1290 = bitcast i8* %1277 to i32*
  store i32 %1289, i32* %1290, align 1
  %1291 = getelementptr inbounds i8, i8* %1277, i64 %1
  %1292 = getelementptr inbounds i8, i8* %1279, i64 -14
  %1293 = bitcast i8* %1292 to <16 x i8>*
  %1294 = load <16 x i8>, <16 x i8>* %1293, align 1
  %1295 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1294, <16 x i8> %1245) #11
  %1296 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1295, <16 x i8> %1250) #11
  %1297 = lshr <8 x i16> %1296, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1298 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1297, <8 x i16> zeroinitializer) #11
  %1299 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1298, <8 x i16> undef) #11
  %1300 = bitcast <16 x i8> %1299 to <4 x i32>
  %1301 = extractelement <4 x i32> %1300, i32 0
  %1302 = bitcast i8* %1291 to i32*
  store i32 %1301, i32* %1302, align 1
  %1303 = getelementptr inbounds i8, i8* %1291, i64 %1
  %1304 = getelementptr inbounds i8, i8* %1279, i64 -13
  %1305 = bitcast i8* %1304 to <16 x i8>*
  %1306 = load <16 x i8>, <16 x i8>* %1305, align 1
  %1307 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1306, <16 x i8> %1245) #11
  %1308 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1307, <16 x i8> %1250) #11
  %1309 = lshr <8 x i16> %1308, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1310 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1309, <8 x i16> zeroinitializer) #11
  %1311 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1310, <8 x i16> undef) #11
  %1312 = bitcast <16 x i8> %1311 to <4 x i32>
  %1313 = extractelement <4 x i32> %1312, i32 0
  %1314 = bitcast i8* %1303 to i32*
  store i32 %1313, i32* %1314, align 1
  %1315 = getelementptr inbounds i8, i8* %1303, i64 %1
  %1316 = getelementptr inbounds i8, i8* %1279, i64 -12
  %1317 = bitcast i8* %1316 to <16 x i8>*
  %1318 = load <16 x i8>, <16 x i8>* %1317, align 1
  %1319 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1318, <16 x i8> %1245) #11
  %1320 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1319, <16 x i8> %1250) #11
  %1321 = lshr <8 x i16> %1320, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1322 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1321, <8 x i16> zeroinitializer) #11
  %1323 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1322, <8 x i16> undef) #11
  %1324 = bitcast <16 x i8> %1323 to <4 x i32>
  %1325 = extractelement <4 x i32> %1324, i32 0
  %1326 = bitcast i8* %1315 to i32*
  store i32 %1325, i32* %1326, align 1
  %1327 = and <8 x i16> %1275, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %1328 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1327, <8 x i16> %1327) #11
  %1329 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %1328
  %1330 = shufflevector <16 x i8> %1329, <16 x i8> %1328, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1331 = ashr <8 x i16> %1276, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %1332 = sub nsw i32 %1274, %6
  %1333 = ashr i32 %1332, 5
  %1334 = sext i32 %1333 to i64
  %1335 = getelementptr inbounds i8, i8* %1133, i64 %1334
  %1336 = bitcast <16 x i8> %1330 to <8 x i16>
  %1337 = shufflevector <8 x i16> %1336, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %1338 = bitcast i8* %1335 to <16 x i8>*
  %1339 = load <16 x i8>, <16 x i8>* %1338, align 1
  %1340 = bitcast <8 x i16> %1337 to <16 x i8>
  %1341 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1339, <16 x i8> %1340) #11
  %1342 = lshr <8 x i16> %1341, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1343 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1342, <8 x i16> zeroinitializer) #11
  %1344 = shufflevector <8 x i16> %1331, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %1345 = icmp sgt <8 x i16> %1344, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %1346 = load i32, i32* %1290, align 1
  %1347 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %1346, i32 0
  %1348 = bitcast <4 x i32> %1347 to <16 x i8>
  %1349 = shufflevector <16 x i8> %1348, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1350 = zext <8 x i8> %1349 to <8 x i16>
  %1351 = select <8 x i1> %1345, <8 x i16> %1350, <8 x i16> %1343
  %1352 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1351, <8 x i16> undef) #11
  %1353 = bitcast <16 x i8> %1352 to <4 x i32>
  %1354 = extractelement <4 x i32> %1353, i32 0
  store i32 %1354, i32* %1290, align 1
  %1355 = sub nsw i32 %1332, %6
  %1356 = ashr i32 %1355, 5
  %1357 = sext i32 %1356 to i64
  %1358 = getelementptr inbounds i8, i8* %1133, i64 %1357
  %1359 = shufflevector <8 x i16> %1336, <8 x i16> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 4, i32 5, i32 6, i32 7>
  %1360 = bitcast i8* %1358 to <16 x i8>*
  %1361 = load <16 x i8>, <16 x i8>* %1360, align 1
  %1362 = bitcast <8 x i16> %1359 to <16 x i8>
  %1363 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1361, <16 x i8> %1362) #11
  %1364 = lshr <8 x i16> %1363, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1365 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1364, <8 x i16> zeroinitializer) #11
  %1366 = shufflevector <8 x i16> %1331, <8 x i16> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 4, i32 5, i32 6, i32 7>
  %1367 = icmp sgt <8 x i16> %1366, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %1368 = load i32, i32* %1302, align 1
  %1369 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %1368, i32 0
  %1370 = bitcast <4 x i32> %1369 to <16 x i8>
  %1371 = shufflevector <16 x i8> %1370, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1372 = zext <8 x i8> %1371 to <8 x i16>
  %1373 = select <8 x i1> %1367, <8 x i16> %1372, <8 x i16> %1365
  %1374 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1373, <8 x i16> undef) #11
  %1375 = bitcast <16 x i8> %1374 to <4 x i32>
  %1376 = extractelement <4 x i32> %1375, i32 0
  store i32 %1376, i32* %1302, align 1
  %1377 = sub nsw i32 %1355, %6
  %1378 = ashr i32 %1377, 5
  %1379 = sext i32 %1378 to i64
  %1380 = getelementptr inbounds i8, i8* %1133, i64 %1379
  %1381 = shufflevector <8 x i16> %1336, <8 x i16> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 4, i32 5, i32 6, i32 7>
  %1382 = bitcast i8* %1380 to <16 x i8>*
  %1383 = load <16 x i8>, <16 x i8>* %1382, align 1
  %1384 = bitcast <8 x i16> %1381 to <16 x i8>
  %1385 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1383, <16 x i8> %1384) #11
  %1386 = lshr <8 x i16> %1385, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1387 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1386, <8 x i16> zeroinitializer) #11
  %1388 = shufflevector <8 x i16> %1331, <8 x i16> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 4, i32 5, i32 6, i32 7>
  %1389 = icmp sgt <8 x i16> %1388, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %1390 = load i32, i32* %1314, align 1
  %1391 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %1390, i32 0
  %1392 = bitcast <4 x i32> %1391 to <16 x i8>
  %1393 = shufflevector <16 x i8> %1392, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1394 = zext <8 x i8> %1393 to <8 x i16>
  %1395 = select <8 x i1> %1389, <8 x i16> %1394, <8 x i16> %1387
  %1396 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1395, <8 x i16> undef) #11
  %1397 = bitcast <16 x i8> %1396 to <4 x i32>
  %1398 = extractelement <4 x i32> %1397, i32 0
  store i32 %1398, i32* %1314, align 1
  %1399 = sub nsw i32 %1377, %6
  %1400 = ashr i32 %1399, 5
  %1401 = sext i32 %1400 to i64
  %1402 = getelementptr inbounds i8, i8* %1133, i64 %1401
  %1403 = shufflevector <8 x i16> %1336, <8 x i16> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1404 = bitcast i8* %1402 to <16 x i8>*
  %1405 = load <16 x i8>, <16 x i8>* %1404, align 1
  %1406 = bitcast <8 x i16> %1403 to <16 x i8>
  %1407 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1405, <16 x i8> %1406) #11
  %1408 = lshr <8 x i16> %1407, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1409 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1408, <8 x i16> zeroinitializer) #11
  %1410 = shufflevector <8 x i16> %1331, <8 x i16> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1411 = icmp sgt <8 x i16> %1410, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %1412 = load i32, i32* %1326, align 1
  %1413 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %1412, i32 0
  %1414 = bitcast <4 x i32> %1413 to <16 x i8>
  %1415 = shufflevector <16 x i8> %1414, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1416 = zext <8 x i8> %1415 to <8 x i16>
  %1417 = select <8 x i1> %1411, <8 x i16> %1416, <8 x i16> %1409
  %1418 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1417, <8 x i16> undef) #11
  %1419 = bitcast <16 x i8> %1418 to <4 x i32>
  %1420 = extractelement <4 x i32> %1419, i32 0
  store i32 %1420, i32* %1326, align 1
  %1421 = add nsw i64 %1273, 4
  %1422 = getelementptr inbounds i8, i8* %1277, i64 %25
  %1423 = add <8 x i16> %1276, %33
  %1424 = sub <8 x i16> %1275, %33
  %1425 = sub nsw i32 %1274, %30
  %1426 = icmp slt i64 %1421, %1252
  br i1 %1426, label %1272, label %1253

1427:                                             ; preds = %1427, %1259
  %1428 = phi i64 [ %1270, %1259 ], [ %1479, %1427 ]
  %1429 = phi i8* [ %1256, %1259 ], [ %1480, %1427 ]
  %1430 = add nsw i64 %1428, %1271
  %1431 = getelementptr inbounds i8, i8* %20, i64 %1430
  %1432 = getelementptr inbounds i8, i8* %1431, i64 -15
  %1433 = bitcast i8* %1432 to <16 x i8>*
  %1434 = load <16 x i8>, <16 x i8>* %1433, align 1
  %1435 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1434, <16 x i8> %1264) #11
  %1436 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1435, <16 x i8> %1269) #11
  %1437 = lshr <8 x i16> %1436, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1438 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1437, <8 x i16> zeroinitializer) #11
  %1439 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1438, <8 x i16> undef) #11
  %1440 = bitcast <16 x i8> %1439 to <4 x i32>
  %1441 = extractelement <4 x i32> %1440, i32 0
  %1442 = bitcast i8* %1429 to i32*
  store i32 %1441, i32* %1442, align 1
  %1443 = getelementptr inbounds i8, i8* %1429, i64 %1
  %1444 = getelementptr inbounds i8, i8* %1431, i64 -14
  %1445 = bitcast i8* %1444 to <16 x i8>*
  %1446 = load <16 x i8>, <16 x i8>* %1445, align 1
  %1447 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1446, <16 x i8> %1264) #11
  %1448 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1447, <16 x i8> %1269) #11
  %1449 = lshr <8 x i16> %1448, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1450 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1449, <8 x i16> zeroinitializer) #11
  %1451 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1450, <8 x i16> undef) #11
  %1452 = bitcast <16 x i8> %1451 to <4 x i32>
  %1453 = extractelement <4 x i32> %1452, i32 0
  %1454 = bitcast i8* %1443 to i32*
  store i32 %1453, i32* %1454, align 1
  %1455 = getelementptr inbounds i8, i8* %1443, i64 %1
  %1456 = getelementptr inbounds i8, i8* %1431, i64 -13
  %1457 = bitcast i8* %1456 to <16 x i8>*
  %1458 = load <16 x i8>, <16 x i8>* %1457, align 1
  %1459 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1458, <16 x i8> %1264) #11
  %1460 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1459, <16 x i8> %1269) #11
  %1461 = lshr <8 x i16> %1460, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1462 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1461, <8 x i16> zeroinitializer) #11
  %1463 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1462, <8 x i16> undef) #11
  %1464 = bitcast <16 x i8> %1463 to <4 x i32>
  %1465 = extractelement <4 x i32> %1464, i32 0
  %1466 = bitcast i8* %1455 to i32*
  store i32 %1465, i32* %1466, align 1
  %1467 = getelementptr inbounds i8, i8* %1455, i64 %1
  %1468 = getelementptr inbounds i8, i8* %1431, i64 -12
  %1469 = bitcast i8* %1468 to <16 x i8>*
  %1470 = load <16 x i8>, <16 x i8>* %1469, align 1
  %1471 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1470, <16 x i8> %1264) #11
  %1472 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1471, <16 x i8> %1269) #11
  %1473 = lshr <8 x i16> %1472, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1474 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1473, <8 x i16> zeroinitializer) #11
  %1475 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1474, <8 x i16> undef) #11
  %1476 = bitcast <16 x i8> %1475 to <4 x i32>
  %1477 = extractelement <4 x i32> %1476, i32 0
  %1478 = bitcast i8* %1467 to i32*
  store i32 %1477, i32* %1478, align 1
  %1479 = add nsw i64 %1428, 4
  %1480 = getelementptr inbounds i8, i8* %1429, i64 %25
  %1481 = icmp slt i64 %1479, %1088
  br i1 %1481, label %1427, label %1482

1482:                                             ; preds = %1427, %1255
  %1483 = add <8 x i16> %1235, <i16 -256, i16 -256, i16 -256, i16 -256, i16 -256, i16 -256, i16 -256, i16 -256>
  %1484 = bitcast <8 x i16> %1483 to <2 x i64>
  %1485 = add <8 x i16> %1122, %45
  %1486 = sub nsw i32 %1121, %40
  %1487 = icmp slt i64 %1229, %1089
  br i1 %1487, label %1119, label %1090

1488:                                             ; preds = %1565, %1095
  %1489 = phi i64 [ %1109, %1095 ], [ %1566, %1565 ]
  %1490 = getelementptr inbounds i8, i8* %0, i64 %1489
  %1491 = trunc i64 %1489 to i32
  %1492 = shl i32 %1491, 1
  %1493 = sext i32 %1492 to i64
  %1494 = getelementptr inbounds i8, i8* %19, i64 %1493
  %1495 = getelementptr inbounds i8, i8* %1494, i64 %1098
  %1496 = load i8, i8* %1495, align 2
  %1497 = zext i8 %1496 to i16
  %1498 = insertelement <8 x i16> undef, i16 %1497, i32 0
  %1499 = shufflevector <8 x i16> %1498, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  br i1 %1105, label %1517, label %1500

1500:                                             ; preds = %1517, %1488
  %1501 = phi i32 [ 0, %1488 ], [ %1104, %1517 ]
  %1502 = phi i8* [ %1490, %1488 ], [ %1549, %1517 ]
  %1503 = icmp slt i32 %1501, %5
  br i1 %1503, label %1504, label %1565

1504:                                             ; preds = %1500
  %1505 = load i8, i8* %1495, align 2
  br i1 %1117, label %1514, label %1506

1506:                                             ; preds = %1504, %1506
  %1507 = phi i8* [ %1510, %1506 ], [ %1502, %1504 ]
  %1508 = phi i32 [ %1511, %1506 ], [ %1501, %1504 ]
  %1509 = phi i32 [ %1512, %1506 ], [ %1116, %1504 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1507, i8 %1505, i64 4, i1 false) #11
  %1510 = getelementptr inbounds i8, i8* %1507, i64 %1
  %1511 = add nuw nsw i32 %1508, 1
  %1512 = add i32 %1509, -1
  %1513 = icmp eq i32 %1512, 0
  br i1 %1513, label %1514, label %1506, !llvm.loop !11

1514:                                             ; preds = %1506, %1504
  %1515 = phi i8* [ %1502, %1504 ], [ %1510, %1506 ]
  %1516 = phi i32 [ %1501, %1504 ], [ %1511, %1506 ]
  br i1 %1118, label %1565, label %1552

1517:                                             ; preds = %1488, %1517
  %1518 = phi i8* [ %1549, %1517 ], [ %1490, %1488 ]
  %1519 = phi i32 [ %1548, %1517 ], [ 0, %1488 ]
  %1520 = phi i32 [ %1550, %1517 ], [ %34, %1488 ]
  %1521 = ashr i32 %1520, 5
  %1522 = trunc i32 %1520 to i8
  %1523 = and i8 %1522, 31
  %1524 = insertelement <16 x i8> undef, i8 %1523, i32 0
  %1525 = shufflevector <16 x i8> %1524, <16 x i8> undef, <16 x i32> zeroinitializer
  %1526 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %1525
  %1527 = shufflevector <16 x i8> %1526, <16 x i8> %1525, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1528 = trunc i32 %1521 to i16
  %1529 = insertelement <8 x i16> undef, i16 %1528, i32 0
  %1530 = shufflevector <8 x i16> %1529, <8 x i16> undef, <8 x i32> zeroinitializer
  %1531 = add <8 x i16> %1530, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %1532 = sext i32 %1521 to i64
  %1533 = getelementptr inbounds i8, i8* %1494, i64 %1532
  %1534 = bitcast i8* %1533 to i64*
  %1535 = load i64, i64* %1534, align 1
  %1536 = insertelement <2 x i64> undef, i64 %1535, i32 0
  %1537 = bitcast <2 x i64> %1536 to <16 x i8>
  %1538 = shufflevector <16 x i8> %1537, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %1539 = icmp sgt <8 x i16> %1531, %1108
  %1540 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1538, <16 x i8> %1527) #11
  %1541 = lshr <8 x i16> %1540, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1542 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1541, <8 x i16> zeroinitializer) #11
  %1543 = select <8 x i1> %1539, <8 x i16> %1499, <8 x i16> %1542
  %1544 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1543, <8 x i16> undef) #11
  %1545 = bitcast <16 x i8> %1544 to <4 x i32>
  %1546 = extractelement <4 x i32> %1545, i32 0
  %1547 = bitcast i8* %1518 to i32*
  store i32 %1546, i32* %1547, align 1
  %1548 = add nuw nsw i32 %1519, 1
  %1549 = getelementptr inbounds i8, i8* %1518, i64 %1
  %1550 = sub i32 %1520, %6
  %1551 = icmp slt i32 %1548, %1104
  br i1 %1551, label %1517, label %1500

1552:                                             ; preds = %1514, %1552
  %1553 = phi i8* [ %1562, %1552 ], [ %1515, %1514 ]
  %1554 = phi i32 [ %1563, %1552 ], [ %1516, %1514 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1553, i8 %1505, i64 4, i1 false) #11
  %1555 = getelementptr inbounds i8, i8* %1553, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1555, i8 %1505, i64 4, i1 false) #11
  %1556 = getelementptr inbounds i8, i8* %1555, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1556, i8 %1505, i64 4, i1 false) #11
  %1557 = getelementptr inbounds i8, i8* %1556, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1557, i8 %1505, i64 4, i1 false) #11
  %1558 = getelementptr inbounds i8, i8* %1557, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1558, i8 %1505, i64 4, i1 false) #11
  %1559 = getelementptr inbounds i8, i8* %1558, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1559, i8 %1505, i64 4, i1 false) #11
  %1560 = getelementptr inbounds i8, i8* %1559, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1560, i8 %1505, i64 4, i1 false) #11
  %1561 = getelementptr inbounds i8, i8* %1560, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1561, i8 %1505, i64 4, i1 false) #11
  %1562 = getelementptr inbounds i8, i8* %1561, i64 %1
  %1563 = add nuw nsw i32 %1554, 8
  %1564 = icmp eq i32 %1563, %5
  br i1 %1564, label %1565, label %1552

1565:                                             ; preds = %1514, %1552, %1500
  %1566 = add nuw nsw i64 %1489, 4
  %1567 = icmp slt i64 %1566, %1110
  br i1 %1567, label %1488, label %7373

1568:                                             ; preds = %1065
  br i1 %47, label %1569, label %1594

1569:                                             ; preds = %1568
  %1570 = ashr i32 %7, 6
  %1571 = sub nsw i32 0, %1570
  %1572 = sub i16 0, %46
  %1573 = insertelement <8 x i16> undef, i16 %1572, i32 0
  %1574 = shufflevector <8 x i16> %1573, <8 x i16> undef, <8 x i32> zeroinitializer
  %1575 = mul <8 x i16> %1574, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %1576 = and i16 %46, 63
  %1577 = sub nsw i16 0, %1576
  %1578 = insertelement <8 x i16> undef, i16 %1577, i32 0
  %1579 = shufflevector <8 x i16> %1578, <8 x i16> undef, <8 x i32> zeroinitializer
  %1580 = add <8 x i16> %1575, %1579
  %1581 = icmp eq i32 %6, 64
  %1582 = sub <8 x i16> <i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64>, %38
  %1583 = bitcast <8 x i16> %1582 to <2 x i64>
  %1584 = bitcast <8 x i16> %38 to <2 x i64>
  %1585 = xor <2 x i64> %1584, <i64 -1, i64 -1>
  %1586 = select i1 %1581, <2 x i64> %1583, <2 x i64> %1585
  %1587 = ashr i32 %34, 6
  %1588 = icmp sgt i32 %1587, 1
  %1589 = select i1 %1588, i32 %1587, i32 1
  %1590 = sext i32 %5 to i64
  %1591 = sext i32 %29 to i64
  br label %1620

1592:                                             ; preds = %1986
  %1593 = trunc i64 %1728 to i32
  br label %1594

1594:                                             ; preds = %1592, %1568
  %1595 = phi i32 [ 0, %1568 ], [ %1593, %1592 ]
  %1596 = icmp slt i32 %1595, %4
  br i1 %1596, label %1597, label %7373

1597:                                             ; preds = %1594
  %1598 = add nsw i32 %5, 3
  %1599 = sext i32 %1598 to i64
  %1600 = ashr i32 %34, 6
  %1601 = icmp sgt i32 %1600, 1
  %1602 = select i1 %1601, i32 %1600, i32 1
  %1603 = sdiv i32 %1598, %1602
  %1604 = icmp sgt i32 %1603, %5
  %1605 = select i1 %1604, i32 %5, i32 %1603
  %1606 = icmp sgt i32 %1605, 0
  %1607 = trunc i32 %1598 to i16
  %1608 = insertelement <8 x i16> undef, i16 %1607, i32 0
  %1609 = shufflevector <8 x i16> %1608, <8 x i16> undef, <8 x i32> zeroinitializer
  %1610 = zext i32 %1595 to i64
  %1611 = sext i32 %4 to i64
  %1612 = icmp sgt i32 %1605, 0
  %1613 = select i1 %1612, i32 %1605, i32 0
  %1614 = sub i32 %5, %1613
  %1615 = xor i32 %1613, -1
  %1616 = add i32 %1615, %5
  %1617 = and i32 %1614, 7
  %1618 = icmp eq i32 %1617, 0
  %1619 = icmp ult i32 %1616, 7
  br label %1992

1620:                                             ; preds = %1986, %1569
  %1621 = phi i64 [ 0, %1569 ], [ %1728, %1986 ]
  %1622 = phi i32 [ %1571, %1569 ], [ %1990, %1986 ]
  %1623 = phi <8 x i16> [ %1580, %1569 ], [ %1989, %1986 ]
  %1624 = phi <2 x i64> [ %1586, %1569 ], [ %1988, %1986 ]
  %1625 = getelementptr inbounds i8, i8* %0, i64 %1621
  %1626 = trunc i64 %1621 to i32
  %1627 = shl i32 %1626, 6
  %1628 = sdiv i32 %1627, %6
  %1629 = icmp sgt i32 %1628, %5
  %1630 = select i1 %1629, i32 %5, i32 %1628
  %1631 = and i32 %1630, -12
  %1632 = getelementptr inbounds i8, i8* %19, i64 %1621
  %1633 = or i32 %1631, 3
  %1634 = sext i32 %1633 to i64
  %1635 = getelementptr inbounds i8, i8* %1632, i64 %1634
  %1636 = load i8, i8* %1635, align 1
  %1637 = zext i8 %1636 to i16
  %1638 = insertelement <8 x i16> undef, i16 %1637, i32 0
  %1639 = shufflevector <8 x i16> %1638, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %1640 = sdiv i32 %1633, %1589
  %1641 = icmp sgt i32 %1640, %1631
  %1642 = select i1 %1641, i32 %1631, i32 %1640
  %1643 = icmp sgt i32 %1642, 0
  br i1 %1643, label %1644, label %1648

1644:                                             ; preds = %1620
  %1645 = trunc i32 %1633 to i16
  %1646 = insertelement <8 x i16> undef, i16 %1645, i32 0
  %1647 = shufflevector <8 x i16> %1646, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %1671

1648:                                             ; preds = %1671, %1620
  %1649 = phi i32 [ 0, %1620 ], [ %1642, %1671 ]
  %1650 = phi i8* [ %1625, %1620 ], [ %1704, %1671 ]
  %1651 = icmp sgt i32 %1631, %1649
  br i1 %1651, label %1652, label %1720

1652:                                             ; preds = %1648
  %1653 = load i8, i8* %1635, align 1
  %1654 = sub i32 %1631, %1649
  %1655 = xor i32 %1649, -1
  %1656 = add i32 %1631, %1655
  %1657 = and i32 %1654, 7
  %1658 = icmp eq i32 %1657, 0
  br i1 %1658, label %1667, label %1659

1659:                                             ; preds = %1652, %1659
  %1660 = phi i8* [ %1663, %1659 ], [ %1650, %1652 ]
  %1661 = phi i32 [ %1664, %1659 ], [ %1649, %1652 ]
  %1662 = phi i32 [ %1665, %1659 ], [ %1657, %1652 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1660, i8 %1653, i64 4, i1 false) #11
  %1663 = getelementptr inbounds i8, i8* %1660, i64 %1
  %1664 = add nuw nsw i32 %1661, 1
  %1665 = add i32 %1662, -1
  %1666 = icmp eq i32 %1665, 0
  br i1 %1666, label %1667, label %1659, !llvm.loop !12

1667:                                             ; preds = %1659, %1652
  %1668 = phi i8* [ %1650, %1652 ], [ %1663, %1659 ]
  %1669 = phi i32 [ %1649, %1652 ], [ %1664, %1659 ]
  %1670 = icmp ult i32 %1656, 7
  br i1 %1670, label %1720, label %1707

1671:                                             ; preds = %1671, %1644
  %1672 = phi i8* [ %1625, %1644 ], [ %1704, %1671 ]
  %1673 = phi i32 [ 0, %1644 ], [ %1703, %1671 ]
  %1674 = phi i32 [ %34, %1644 ], [ %1705, %1671 ]
  %1675 = ashr i32 %1674, 6
  %1676 = lshr i32 %1674, 1
  %1677 = trunc i32 %1676 to i8
  %1678 = and i8 %1677, 31
  %1679 = insertelement <16 x i8> undef, i8 %1678, i32 0
  %1680 = shufflevector <16 x i8> %1679, <16 x i8> undef, <16 x i32> zeroinitializer
  %1681 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %1680
  %1682 = shufflevector <16 x i8> %1681, <16 x i8> %1680, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1683 = trunc i32 %1675 to i16
  %1684 = insertelement <8 x i16> undef, i16 %1683, i32 0
  %1685 = shufflevector <8 x i16> %1684, <8 x i16> undef, <8 x i32> zeroinitializer
  %1686 = add <8 x i16> %1685, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %1687 = sext i32 %1675 to i64
  %1688 = getelementptr inbounds i8, i8* %1632, i64 %1687
  %1689 = bitcast i8* %1688 to i64*
  %1690 = load i64, i64* %1689, align 1
  %1691 = insertelement <2 x i64> undef, i64 %1690, i32 0
  %1692 = bitcast <2 x i64> %1691 to <16 x i8>
  %1693 = shufflevector <16 x i8> %1692, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %1694 = icmp sgt <8 x i16> %1686, %1647
  %1695 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1693, <16 x i8> %1682) #11
  %1696 = lshr <8 x i16> %1695, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1697 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1696, <8 x i16> zeroinitializer) #11
  %1698 = select <8 x i1> %1694, <8 x i16> %1639, <8 x i16> %1697
  %1699 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1698, <8 x i16> undef) #11
  %1700 = bitcast <16 x i8> %1699 to <4 x i32>
  %1701 = extractelement <4 x i32> %1700, i32 0
  %1702 = bitcast i8* %1672 to i32*
  store i32 %1701, i32* %1702, align 1
  %1703 = add nuw nsw i32 %1673, 1
  %1704 = getelementptr inbounds i8, i8* %1672, i64 %1
  %1705 = sub i32 %1674, %6
  %1706 = icmp slt i32 %1703, %1642
  br i1 %1706, label %1671, label %1648

1707:                                             ; preds = %1667, %1707
  %1708 = phi i8* [ %1717, %1707 ], [ %1668, %1667 ]
  %1709 = phi i32 [ %1718, %1707 ], [ %1669, %1667 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1708, i8 %1653, i64 4, i1 false) #11
  %1710 = getelementptr inbounds i8, i8* %1708, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1710, i8 %1653, i64 4, i1 false) #11
  %1711 = getelementptr inbounds i8, i8* %1710, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1711, i8 %1653, i64 4, i1 false) #11
  %1712 = getelementptr inbounds i8, i8* %1711, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1712, i8 %1653, i64 4, i1 false) #11
  %1713 = getelementptr inbounds i8, i8* %1712, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1713, i8 %1653, i64 4, i1 false) #11
  %1714 = getelementptr inbounds i8, i8* %1713, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1714, i8 %1653, i64 4, i1 false) #11
  %1715 = getelementptr inbounds i8, i8* %1714, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1715, i8 %1653, i64 4, i1 false) #11
  %1716 = getelementptr inbounds i8, i8* %1715, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %1716, i8 %1653, i64 4, i1 false) #11
  %1717 = getelementptr inbounds i8, i8* %1716, i64 %1
  %1718 = add nuw nsw i32 %1709, 8
  %1719 = icmp eq i32 %1718, %1631
  br i1 %1719, label %1720, label %1707

1720:                                             ; preds = %1667, %1707, %1648
  %1721 = sext i32 %1631 to i64
  %1722 = mul nsw i64 %1721, %1
  %1723 = getelementptr inbounds i8, i8* %1625, i64 %1722
  %1724 = mul nsw i32 %1631, %6
  %1725 = trunc i32 %1724 to i16
  %1726 = insertelement <8 x i16> undef, i16 %1725, i32 0
  %1727 = shufflevector <8 x i16> %1726, <8 x i16> undef, <8 x i32> zeroinitializer
  %1728 = add nuw nsw i64 %1621, 4
  %1729 = trunc i64 %1728 to i32
  %1730 = shl i32 %1729, 6
  %1731 = sdiv i32 %1730, %6
  %1732 = icmp sgt i32 %1731, %5
  %1733 = select i1 %1732, i32 %5, i32 %1731
  %1734 = bitcast <2 x i64> %1624 to <8 x i16>
  %1735 = icmp slt i32 %1631, %1733
  br i1 %1735, label %1736, label %1754

1736:                                             ; preds = %1720
  %1737 = sub nsw i32 0, %1724
  %1738 = sub <8 x i16> %38, %1727
  %1739 = add <8 x i16> %1727, %1734
  %1740 = ashr <8 x i16> %1623, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %1741 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %1740, <8 x i16> %1740) #11
  %1742 = add <16 x i8> %1741, <i8 1, i8 1, i8 1, i8 1, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %1743 = shufflevector <16 x i8> %1741, <16 x i8> %1742, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1744 = add <16 x i8> %1743, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %1745 = lshr <8 x i16> %1623, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %1746 = and <8 x i16> %1745, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %1747 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1746, <8 x i16> %1746) #11
  %1748 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %1747
  %1749 = shufflevector <16 x i8> %1748, <16 x i8> %1747, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1750 = sext i32 %1622 to i64
  %1751 = sext i32 %1733 to i64
  br label %1771

1752:                                             ; preds = %1771
  %1753 = trunc i64 %1925 to i32
  br label %1754

1754:                                             ; preds = %1752, %1720
  %1755 = phi i8* [ %1723, %1720 ], [ %1926, %1752 ]
  %1756 = phi i32 [ %1631, %1720 ], [ %1753, %1752 ]
  %1757 = icmp slt i32 %1756, %5
  br i1 %1757, label %1758, label %1986

1758:                                             ; preds = %1754
  %1759 = ashr <8 x i16> %1623, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %1760 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %1759, <8 x i16> %1759) #11
  %1761 = add <16 x i8> %1760, <i8 1, i8 1, i8 1, i8 1, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %1762 = shufflevector <16 x i8> %1760, <16 x i8> %1761, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1763 = add <16 x i8> %1762, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %1764 = lshr <8 x i16> %1623, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %1765 = and <8 x i16> %1764, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %1766 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1765, <8 x i16> %1765) #11
  %1767 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %1766
  %1768 = shufflevector <16 x i8> %1767, <16 x i8> %1766, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1769 = sext i32 %1756 to i64
  %1770 = sext i32 %1622 to i64
  br label %1931

1771:                                             ; preds = %1771, %1736
  %1772 = phi i64 [ %1721, %1736 ], [ %1925, %1771 ]
  %1773 = phi i32 [ %1737, %1736 ], [ %1929, %1771 ]
  %1774 = phi <8 x i16> [ %1738, %1736 ], [ %1928, %1771 ]
  %1775 = phi <8 x i16> [ %1739, %1736 ], [ %1927, %1771 ]
  %1776 = phi i8* [ %1723, %1736 ], [ %1926, %1771 ]
  %1777 = add nsw i64 %1772, %1750
  %1778 = getelementptr inbounds i8, i8* %20, i64 %1777
  %1779 = getelementptr inbounds i8, i8* %1778, i64 -15
  %1780 = bitcast i8* %1779 to <16 x i8>*
  %1781 = load <16 x i8>, <16 x i8>* %1780, align 1
  %1782 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1781, <16 x i8> %1744) #11
  %1783 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1782, <16 x i8> %1749) #11
  %1784 = lshr <8 x i16> %1783, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1785 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1784, <8 x i16> zeroinitializer) #11
  %1786 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1785, <8 x i16> undef) #11
  %1787 = bitcast <16 x i8> %1786 to <4 x i32>
  %1788 = extractelement <4 x i32> %1787, i32 0
  %1789 = bitcast i8* %1776 to i32*
  store i32 %1788, i32* %1789, align 1
  %1790 = getelementptr inbounds i8, i8* %1776, i64 %1
  %1791 = getelementptr inbounds i8, i8* %1778, i64 -14
  %1792 = bitcast i8* %1791 to <16 x i8>*
  %1793 = load <16 x i8>, <16 x i8>* %1792, align 1
  %1794 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1793, <16 x i8> %1744) #11
  %1795 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1794, <16 x i8> %1749) #11
  %1796 = lshr <8 x i16> %1795, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1797 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1796, <8 x i16> zeroinitializer) #11
  %1798 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1797, <8 x i16> undef) #11
  %1799 = bitcast <16 x i8> %1798 to <4 x i32>
  %1800 = extractelement <4 x i32> %1799, i32 0
  %1801 = bitcast i8* %1790 to i32*
  store i32 %1800, i32* %1801, align 1
  %1802 = getelementptr inbounds i8, i8* %1790, i64 %1
  %1803 = getelementptr inbounds i8, i8* %1778, i64 -13
  %1804 = bitcast i8* %1803 to <16 x i8>*
  %1805 = load <16 x i8>, <16 x i8>* %1804, align 1
  %1806 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1805, <16 x i8> %1744) #11
  %1807 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1806, <16 x i8> %1749) #11
  %1808 = lshr <8 x i16> %1807, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1809 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1808, <8 x i16> zeroinitializer) #11
  %1810 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1809, <8 x i16> undef) #11
  %1811 = bitcast <16 x i8> %1810 to <4 x i32>
  %1812 = extractelement <4 x i32> %1811, i32 0
  %1813 = bitcast i8* %1802 to i32*
  store i32 %1812, i32* %1813, align 1
  %1814 = getelementptr inbounds i8, i8* %1802, i64 %1
  %1815 = getelementptr inbounds i8, i8* %1778, i64 -12
  %1816 = bitcast i8* %1815 to <16 x i8>*
  %1817 = load <16 x i8>, <16 x i8>* %1816, align 1
  %1818 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1817, <16 x i8> %1744) #11
  %1819 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1818, <16 x i8> %1749) #11
  %1820 = lshr <8 x i16> %1819, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1821 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1820, <8 x i16> zeroinitializer) #11
  %1822 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1821, <8 x i16> undef) #11
  %1823 = bitcast <16 x i8> %1822 to <4 x i32>
  %1824 = extractelement <4 x i32> %1823, i32 0
  %1825 = bitcast i8* %1814 to i32*
  store i32 %1824, i32* %1825, align 1
  %1826 = lshr <8 x i16> %1774, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %1827 = and <8 x i16> %1826, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %1828 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1827, <8 x i16> %1827) #11
  %1829 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %1828
  %1830 = shufflevector <16 x i8> %1829, <16 x i8> %1828, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %1831 = ashr <8 x i16> %1775, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %1832 = sub nsw i32 %1773, %6
  %1833 = ashr i32 %1832, 6
  %1834 = sext i32 %1833 to i64
  %1835 = getelementptr inbounds i8, i8* %1632, i64 %1834
  %1836 = bitcast <16 x i8> %1830 to <8 x i16>
  %1837 = shufflevector <8 x i16> %1836, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %1838 = bitcast i8* %1835 to <16 x i8>*
  %1839 = load <16 x i8>, <16 x i8>* %1838, align 1
  %1840 = shufflevector <16 x i8> %1839, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %1841 = bitcast <8 x i16> %1837 to <16 x i8>
  %1842 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1840, <16 x i8> %1841) #11
  %1843 = lshr <8 x i16> %1842, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1844 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1843, <8 x i16> zeroinitializer) #11
  %1845 = shufflevector <8 x i16> %1831, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 4, i32 5, i32 6, i32 7>
  %1846 = icmp sgt <8 x i16> %1845, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %1847 = load i32, i32* %1789, align 1
  %1848 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %1847, i32 0
  %1849 = bitcast <4 x i32> %1848 to <16 x i8>
  %1850 = shufflevector <16 x i8> %1849, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1851 = zext <8 x i8> %1850 to <8 x i16>
  %1852 = select <8 x i1> %1846, <8 x i16> %1851, <8 x i16> %1844
  %1853 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1852, <8 x i16> undef) #11
  %1854 = bitcast <16 x i8> %1853 to <4 x i32>
  %1855 = extractelement <4 x i32> %1854, i32 0
  store i32 %1855, i32* %1789, align 1
  %1856 = sub nsw i32 %1832, %6
  %1857 = ashr i32 %1856, 6
  %1858 = sext i32 %1857 to i64
  %1859 = getelementptr inbounds i8, i8* %1632, i64 %1858
  %1860 = shufflevector <8 x i16> %1836, <8 x i16> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 4, i32 5, i32 6, i32 7>
  %1861 = bitcast i8* %1859 to <16 x i8>*
  %1862 = load <16 x i8>, <16 x i8>* %1861, align 1
  %1863 = shufflevector <16 x i8> %1862, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %1864 = bitcast <8 x i16> %1860 to <16 x i8>
  %1865 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1863, <16 x i8> %1864) #11
  %1866 = lshr <8 x i16> %1865, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1867 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1866, <8 x i16> zeroinitializer) #11
  %1868 = shufflevector <8 x i16> %1831, <8 x i16> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 4, i32 5, i32 6, i32 7>
  %1869 = icmp sgt <8 x i16> %1868, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %1870 = load i32, i32* %1801, align 1
  %1871 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %1870, i32 0
  %1872 = bitcast <4 x i32> %1871 to <16 x i8>
  %1873 = shufflevector <16 x i8> %1872, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1874 = zext <8 x i8> %1873 to <8 x i16>
  %1875 = select <8 x i1> %1869, <8 x i16> %1874, <8 x i16> %1867
  %1876 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1875, <8 x i16> undef) #11
  %1877 = bitcast <16 x i8> %1876 to <4 x i32>
  %1878 = extractelement <4 x i32> %1877, i32 0
  store i32 %1878, i32* %1801, align 1
  %1879 = sub nsw i32 %1856, %6
  %1880 = ashr i32 %1879, 6
  %1881 = sext i32 %1880 to i64
  %1882 = getelementptr inbounds i8, i8* %1632, i64 %1881
  %1883 = shufflevector <8 x i16> %1836, <8 x i16> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 4, i32 5, i32 6, i32 7>
  %1884 = bitcast i8* %1882 to <16 x i8>*
  %1885 = load <16 x i8>, <16 x i8>* %1884, align 1
  %1886 = shufflevector <16 x i8> %1885, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %1887 = bitcast <8 x i16> %1883 to <16 x i8>
  %1888 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1886, <16 x i8> %1887) #11
  %1889 = lshr <8 x i16> %1888, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1890 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1889, <8 x i16> zeroinitializer) #11
  %1891 = shufflevector <8 x i16> %1831, <8 x i16> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 4, i32 5, i32 6, i32 7>
  %1892 = icmp sgt <8 x i16> %1891, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %1893 = load i32, i32* %1813, align 1
  %1894 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %1893, i32 0
  %1895 = bitcast <4 x i32> %1894 to <16 x i8>
  %1896 = shufflevector <16 x i8> %1895, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1897 = zext <8 x i8> %1896 to <8 x i16>
  %1898 = select <8 x i1> %1892, <8 x i16> %1897, <8 x i16> %1890
  %1899 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1898, <8 x i16> undef) #11
  %1900 = bitcast <16 x i8> %1899 to <4 x i32>
  %1901 = extractelement <4 x i32> %1900, i32 0
  store i32 %1901, i32* %1813, align 1
  %1902 = sub nsw i32 %1879, %6
  %1903 = ashr i32 %1902, 6
  %1904 = sext i32 %1903 to i64
  %1905 = getelementptr inbounds i8, i8* %1632, i64 %1904
  %1906 = shufflevector <8 x i16> %1836, <8 x i16> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1907 = bitcast i8* %1905 to <16 x i8>*
  %1908 = load <16 x i8>, <16 x i8>* %1907, align 1
  %1909 = shufflevector <16 x i8> %1908, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %1910 = bitcast <8 x i16> %1906 to <16 x i8>
  %1911 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1909, <16 x i8> %1910) #11
  %1912 = lshr <8 x i16> %1911, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1913 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1912, <8 x i16> zeroinitializer) #11
  %1914 = shufflevector <8 x i16> %1831, <8 x i16> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1915 = icmp sgt <8 x i16> %1914, <i16 0, i16 1, i16 2, i16 3, i16 0, i16 0, i16 0, i16 0>
  %1916 = load i32, i32* %1825, align 1
  %1917 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %1916, i32 0
  %1918 = bitcast <4 x i32> %1917 to <16 x i8>
  %1919 = shufflevector <16 x i8> %1918, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %1920 = zext <8 x i8> %1919 to <8 x i16>
  %1921 = select <8 x i1> %1915, <8 x i16> %1920, <8 x i16> %1913
  %1922 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1921, <8 x i16> undef) #11
  %1923 = bitcast <16 x i8> %1922 to <4 x i32>
  %1924 = extractelement <4 x i32> %1923, i32 0
  store i32 %1924, i32* %1825, align 1
  %1925 = add nsw i64 %1772, 4
  %1926 = getelementptr inbounds i8, i8* %1776, i64 %25
  %1927 = add <8 x i16> %1775, %33
  %1928 = sub <8 x i16> %1774, %33
  %1929 = sub nsw i32 %1773, %30
  %1930 = icmp slt i64 %1925, %1751
  br i1 %1930, label %1771, label %1752

1931:                                             ; preds = %1931, %1758
  %1932 = phi i64 [ %1769, %1758 ], [ %1983, %1931 ]
  %1933 = phi i8* [ %1755, %1758 ], [ %1984, %1931 ]
  %1934 = add nsw i64 %1932, %1770
  %1935 = getelementptr inbounds i8, i8* %20, i64 %1934
  %1936 = getelementptr inbounds i8, i8* %1935, i64 -15
  %1937 = bitcast i8* %1936 to <16 x i8>*
  %1938 = load <16 x i8>, <16 x i8>* %1937, align 1
  %1939 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1938, <16 x i8> %1763) #11
  %1940 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1939, <16 x i8> %1768) #11
  %1941 = lshr <8 x i16> %1940, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1942 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1941, <8 x i16> zeroinitializer) #11
  %1943 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1942, <8 x i16> undef) #11
  %1944 = bitcast <16 x i8> %1943 to <4 x i32>
  %1945 = extractelement <4 x i32> %1944, i32 0
  %1946 = bitcast i8* %1933 to i32*
  store i32 %1945, i32* %1946, align 1
  %1947 = getelementptr inbounds i8, i8* %1933, i64 %1
  %1948 = getelementptr inbounds i8, i8* %1935, i64 -14
  %1949 = bitcast i8* %1948 to <16 x i8>*
  %1950 = load <16 x i8>, <16 x i8>* %1949, align 1
  %1951 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1950, <16 x i8> %1763) #11
  %1952 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1951, <16 x i8> %1768) #11
  %1953 = lshr <8 x i16> %1952, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1954 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1953, <8 x i16> zeroinitializer) #11
  %1955 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1954, <8 x i16> undef) #11
  %1956 = bitcast <16 x i8> %1955 to <4 x i32>
  %1957 = extractelement <4 x i32> %1956, i32 0
  %1958 = bitcast i8* %1947 to i32*
  store i32 %1957, i32* %1958, align 1
  %1959 = getelementptr inbounds i8, i8* %1947, i64 %1
  %1960 = getelementptr inbounds i8, i8* %1935, i64 -13
  %1961 = bitcast i8* %1960 to <16 x i8>*
  %1962 = load <16 x i8>, <16 x i8>* %1961, align 1
  %1963 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1962, <16 x i8> %1763) #11
  %1964 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1963, <16 x i8> %1768) #11
  %1965 = lshr <8 x i16> %1964, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1966 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1965, <8 x i16> zeroinitializer) #11
  %1967 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1966, <8 x i16> undef) #11
  %1968 = bitcast <16 x i8> %1967 to <4 x i32>
  %1969 = extractelement <4 x i32> %1968, i32 0
  %1970 = bitcast i8* %1959 to i32*
  store i32 %1969, i32* %1970, align 1
  %1971 = getelementptr inbounds i8, i8* %1959, i64 %1
  %1972 = getelementptr inbounds i8, i8* %1935, i64 -12
  %1973 = bitcast i8* %1972 to <16 x i8>*
  %1974 = load <16 x i8>, <16 x i8>* %1973, align 1
  %1975 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %1974, <16 x i8> %1763) #11
  %1976 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %1975, <16 x i8> %1768) #11
  %1977 = lshr <8 x i16> %1976, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1978 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1977, <8 x i16> zeroinitializer) #11
  %1979 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1978, <8 x i16> undef) #11
  %1980 = bitcast <16 x i8> %1979 to <4 x i32>
  %1981 = extractelement <4 x i32> %1980, i32 0
  %1982 = bitcast i8* %1971 to i32*
  store i32 %1981, i32* %1982, align 1
  %1983 = add nsw i64 %1932, 4
  %1984 = getelementptr inbounds i8, i8* %1933, i64 %25
  %1985 = icmp slt i64 %1983, %1590
  br i1 %1985, label %1931, label %1986

1986:                                             ; preds = %1931, %1754
  %1987 = add <8 x i16> %1734, <i16 -256, i16 -256, i16 -256, i16 -256, i16 -256, i16 -256, i16 -256, i16 -256>
  %1988 = bitcast <8 x i16> %1987 to <2 x i64>
  %1989 = add <8 x i16> %1623, %45
  %1990 = sub nsw i32 %1622, %40
  %1991 = icmp slt i64 %1728, %1591
  br i1 %1991, label %1620, label %1592

1992:                                             ; preds = %2067, %1597
  %1993 = phi i64 [ %1610, %1597 ], [ %2068, %2067 ]
  %1994 = getelementptr inbounds i8, i8* %0, i64 %1993
  %1995 = getelementptr inbounds i8, i8* %19, i64 %1993
  %1996 = getelementptr inbounds i8, i8* %1995, i64 %1599
  %1997 = load i8, i8* %1996, align 1
  %1998 = zext i8 %1997 to i16
  %1999 = insertelement <8 x i16> undef, i16 %1998, i32 0
  %2000 = shufflevector <8 x i16> %1999, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  br i1 %1606, label %2018, label %2001

2001:                                             ; preds = %2018, %1992
  %2002 = phi i32 [ 0, %1992 ], [ %1605, %2018 ]
  %2003 = phi i8* [ %1994, %1992 ], [ %2051, %2018 ]
  %2004 = icmp slt i32 %2002, %5
  br i1 %2004, label %2005, label %2067

2005:                                             ; preds = %2001
  %2006 = load i8, i8* %1996, align 1
  br i1 %1618, label %2015, label %2007

2007:                                             ; preds = %2005, %2007
  %2008 = phi i8* [ %2011, %2007 ], [ %2003, %2005 ]
  %2009 = phi i32 [ %2012, %2007 ], [ %2002, %2005 ]
  %2010 = phi i32 [ %2013, %2007 ], [ %1617, %2005 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2008, i8 %2006, i64 4, i1 false) #11
  %2011 = getelementptr inbounds i8, i8* %2008, i64 %1
  %2012 = add nuw nsw i32 %2009, 1
  %2013 = add i32 %2010, -1
  %2014 = icmp eq i32 %2013, 0
  br i1 %2014, label %2015, label %2007, !llvm.loop !13

2015:                                             ; preds = %2007, %2005
  %2016 = phi i8* [ %2003, %2005 ], [ %2011, %2007 ]
  %2017 = phi i32 [ %2002, %2005 ], [ %2012, %2007 ]
  br i1 %1619, label %2067, label %2054

2018:                                             ; preds = %1992, %2018
  %2019 = phi i8* [ %2051, %2018 ], [ %1994, %1992 ]
  %2020 = phi i32 [ %2050, %2018 ], [ 0, %1992 ]
  %2021 = phi i32 [ %2052, %2018 ], [ %34, %1992 ]
  %2022 = ashr i32 %2021, 6
  %2023 = lshr i32 %2021, 1
  %2024 = trunc i32 %2023 to i8
  %2025 = and i8 %2024, 31
  %2026 = insertelement <16 x i8> undef, i8 %2025, i32 0
  %2027 = shufflevector <16 x i8> %2026, <16 x i8> undef, <16 x i32> zeroinitializer
  %2028 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2027
  %2029 = shufflevector <16 x i8> %2028, <16 x i8> %2027, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2030 = trunc i32 %2022 to i16
  %2031 = insertelement <8 x i16> undef, i16 %2030, i32 0
  %2032 = shufflevector <8 x i16> %2031, <8 x i16> undef, <8 x i32> zeroinitializer
  %2033 = add <8 x i16> %2032, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %2034 = sext i32 %2022 to i64
  %2035 = getelementptr inbounds i8, i8* %1995, i64 %2034
  %2036 = bitcast i8* %2035 to i64*
  %2037 = load i64, i64* %2036, align 1
  %2038 = insertelement <2 x i64> undef, i64 %2037, i32 0
  %2039 = bitcast <2 x i64> %2038 to <16 x i8>
  %2040 = shufflevector <16 x i8> %2039, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %2041 = icmp sgt <8 x i16> %2033, %1609
  %2042 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2040, <16 x i8> %2029) #11
  %2043 = lshr <8 x i16> %2042, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2044 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2043, <8 x i16> zeroinitializer) #11
  %2045 = select <8 x i1> %2041, <8 x i16> %2000, <8 x i16> %2044
  %2046 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2045, <8 x i16> undef) #11
  %2047 = bitcast <16 x i8> %2046 to <4 x i32>
  %2048 = extractelement <4 x i32> %2047, i32 0
  %2049 = bitcast i8* %2019 to i32*
  store i32 %2048, i32* %2049, align 1
  %2050 = add nuw nsw i32 %2020, 1
  %2051 = getelementptr inbounds i8, i8* %2019, i64 %1
  %2052 = sub i32 %2021, %6
  %2053 = icmp slt i32 %2050, %1605
  br i1 %2053, label %2018, label %2001

2054:                                             ; preds = %2015, %2054
  %2055 = phi i8* [ %2064, %2054 ], [ %2016, %2015 ]
  %2056 = phi i32 [ %2065, %2054 ], [ %2017, %2015 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2055, i8 %2006, i64 4, i1 false) #11
  %2057 = getelementptr inbounds i8, i8* %2055, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2057, i8 %2006, i64 4, i1 false) #11
  %2058 = getelementptr inbounds i8, i8* %2057, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2058, i8 %2006, i64 4, i1 false) #11
  %2059 = getelementptr inbounds i8, i8* %2058, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2059, i8 %2006, i64 4, i1 false) #11
  %2060 = getelementptr inbounds i8, i8* %2059, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2060, i8 %2006, i64 4, i1 false) #11
  %2061 = getelementptr inbounds i8, i8* %2060, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2061, i8 %2006, i64 4, i1 false) #11
  %2062 = getelementptr inbounds i8, i8* %2061, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2062, i8 %2006, i64 4, i1 false) #11
  %2063 = getelementptr inbounds i8, i8* %2062, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2063, i8 %2006, i64 4, i1 false) #11
  %2064 = getelementptr inbounds i8, i8* %2063, i64 %1
  %2065 = add nuw nsw i32 %2056, 8
  %2066 = icmp eq i32 %2065, %5
  br i1 %2066, label %2067, label %2054

2067:                                             ; preds = %2015, %2054, %2001
  %2068 = add nuw nsw i64 %1993, 4
  %2069 = icmp slt i64 %2068, %1611
  br i1 %2069, label %1992, label %7373

2070:                                             ; preds = %10
  %2071 = shl i64 %1, 3
  %2072 = mul nsw i32 %6, %5
  %2073 = ashr i32 %2072, 6
  %2074 = icmp sgt i32 %2073, %4
  %2075 = select i1 %2074, i32 %4, i32 %2073
  %2076 = ashr i32 %7, 6
  %2077 = sext i32 %2076 to i64
  %2078 = getelementptr inbounds [16 x i32], [16 x i32]* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_137kDirectionalZone2ShuffleInvalidHeightE, i64 0, i64 %2077
  %2079 = load i32, i32* %2078, align 4
  %2080 = shl i32 %6, 3
  %2081 = trunc i32 %2080 to i16
  %2082 = insertelement <8 x i16> undef, i16 %2081, i32 0
  %2083 = shufflevector <8 x i16> %2082, <8 x i16> undef, <8 x i32> zeroinitializer
  %2084 = sub nsw i32 0, %6
  %2085 = trunc i32 %2084 to i16
  %2086 = insertelement <8 x i16> undef, i16 %2085, i32 0
  %2087 = shufflevector <8 x i16> %2086, <8 x i16> undef, <8 x i32> zeroinitializer
  %2088 = mul <8 x i16> %2087, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %2089 = shl i32 %7, 3
  %2090 = ashr i32 %2089, 6
  %2091 = trunc i32 %2089 to i16
  %2092 = and i16 %2091, 56
  %2093 = sub nsw i16 0, %2092
  %2094 = insertelement <8 x i16> undef, i16 %2093, i32 0
  %2095 = shufflevector <8 x i16> %2094, <8 x i16> undef, <8 x i32> zeroinitializer
  %2096 = icmp sgt i32 %2075, 0
  br i1 %9, label %2097, label %4708

2097:                                             ; preds = %2070
  br i1 %8, label %2098, label %3397

2098:                                             ; preds = %2097
  br i1 %2096, label %2099, label %2124

2099:                                             ; preds = %2098
  %2100 = sub nsw i32 0, %2076
  %2101 = trunc i32 %7 to i16
  %2102 = sub i16 0, %2101
  %2103 = insertelement <8 x i16> undef, i16 %2102, i32 0
  %2104 = shufflevector <8 x i16> %2103, <8 x i16> undef, <8 x i32> zeroinitializer
  %2105 = mul <8 x i16> %2104, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %2106 = and i16 %2101, 63
  %2107 = sub nsw i16 0, %2106
  %2108 = insertelement <8 x i16> undef, i16 %2107, i32 0
  %2109 = shufflevector <8 x i16> %2108, <8 x i16> undef, <8 x i32> zeroinitializer
  %2110 = add <8 x i16> %2105, %2109
  %2111 = icmp eq i32 %6, 64
  %2112 = sub <8 x i16> <i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64>, %2088
  %2113 = bitcast <8 x i16> %2112 to <2 x i64>
  %2114 = bitcast <8 x i16> %2088 to <2 x i64>
  %2115 = xor <2 x i64> %2114, <i64 -1, i64 -1>
  %2116 = select i1 %2111, <2 x i64> %2113, <2 x i64> %2115
  %2117 = ashr i32 %2084, 5
  %2118 = icmp sgt i32 %2117, 1
  %2119 = select i1 %2118, i32 %2117, i32 1
  %2120 = sext i32 %5 to i64
  %2121 = sext i32 %2075 to i64
  br label %2151

2122:                                             ; preds = %3311
  %2123 = trunc i64 %2348 to i32
  br label %2124

2124:                                             ; preds = %2122, %2098
  %2125 = phi i32 [ 0, %2098 ], [ %2123, %2122 ]
  %2126 = icmp slt i32 %2125, %4
  br i1 %2126, label %2127, label %7373

2127:                                             ; preds = %2124
  %2128 = shl i32 %5, 1
  %2129 = add i32 %2128, 6
  %2130 = sext i32 %2129 to i64
  %2131 = ashr i32 %2084, 5
  %2132 = icmp sgt i32 %2131, 1
  %2133 = select i1 %2132, i32 %2131, i32 1
  %2134 = sdiv i32 %2129, %2133
  %2135 = icmp sgt i32 %2134, %5
  %2136 = select i1 %2135, i32 %5, i32 %2134
  %2137 = icmp sgt i32 %2136, 0
  %2138 = trunc i32 %2129 to i16
  %2139 = insertelement <8 x i16> undef, i16 %2138, i32 0
  %2140 = shufflevector <8 x i16> %2139, <8 x i16> undef, <8 x i32> zeroinitializer
  %2141 = zext i32 %2125 to i64
  %2142 = sext i32 %4 to i64
  %2143 = icmp sgt i32 %2136, 0
  %2144 = select i1 %2143, i32 %2136, i32 0
  %2145 = sub i32 %5, %2144
  %2146 = xor i32 %2144, -1
  %2147 = add i32 %2146, %5
  %2148 = and i32 %2145, 7
  %2149 = icmp eq i32 %2148, 0
  %2150 = icmp ult i32 %2147, 7
  br label %3317

2151:                                             ; preds = %3311, %2099
  %2152 = phi i64 [ 0, %2099 ], [ %2348, %3311 ]
  %2153 = phi i32 [ %2100, %2099 ], [ %3315, %3311 ]
  %2154 = phi <8 x i16> [ %2110, %2099 ], [ %3314, %3311 ]
  %2155 = phi <2 x i64> [ %2116, %2099 ], [ %3313, %3311 ]
  %2156 = getelementptr inbounds i8, i8* %0, i64 %2152
  %2157 = trunc i64 %2152 to i32
  %2158 = shl i32 %2157, 6
  %2159 = or i32 %2158, 64
  %2160 = sdiv i32 %2159, %6
  %2161 = icmp sgt i32 %2160, %5
  %2162 = select i1 %2161, i32 %5, i32 %2160
  %2163 = and i32 %2162, -8
  %2164 = shl i64 %2152, 33
  %2165 = ashr exact i64 %2164, 32
  %2166 = getelementptr inbounds i8, i8* %19, i64 %2165
  %2167 = shl i32 %2163, 1
  %2168 = or i32 %2167, 6
  %2169 = sext i32 %2168 to i64
  %2170 = getelementptr inbounds i8, i8* %2166, i64 %2169
  %2171 = load i8, i8* %2170, align 2
  %2172 = zext i8 %2171 to i16
  %2173 = insertelement <8 x i16> undef, i16 %2172, i32 0
  %2174 = shufflevector <8 x i16> %2173, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %2175 = sdiv i32 %2168, %2119
  %2176 = icmp sgt i32 %2175, %2163
  %2177 = select i1 %2176, i32 %2163, i32 %2175
  %2178 = icmp sgt i32 %2177, 0
  br i1 %2178, label %2179, label %2183

2179:                                             ; preds = %2151
  %2180 = trunc i32 %2168 to i16
  %2181 = insertelement <8 x i16> undef, i16 %2180, i32 0
  %2182 = shufflevector <8 x i16> %2181, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %2206

2183:                                             ; preds = %2206, %2151
  %2184 = phi i32 [ 0, %2151 ], [ %2177, %2206 ]
  %2185 = phi i8* [ %2156, %2151 ], [ %2238, %2206 ]
  %2186 = icmp sgt i32 %2163, %2184
  br i1 %2186, label %2187, label %2254

2187:                                             ; preds = %2183
  %2188 = load i8, i8* %2170, align 2
  %2189 = sub i32 0, %2184
  %2190 = xor i32 %2184, -1
  %2191 = add i32 %2163, %2190
  %2192 = and i32 %2189, 7
  %2193 = icmp eq i32 %2192, 0
  br i1 %2193, label %2202, label %2194

2194:                                             ; preds = %2187, %2194
  %2195 = phi i8* [ %2198, %2194 ], [ %2185, %2187 ]
  %2196 = phi i32 [ %2199, %2194 ], [ %2184, %2187 ]
  %2197 = phi i32 [ %2200, %2194 ], [ %2192, %2187 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2195, i8 %2188, i64 4, i1 false) #11
  %2198 = getelementptr inbounds i8, i8* %2195, i64 %1
  %2199 = add nuw nsw i32 %2196, 1
  %2200 = add i32 %2197, -1
  %2201 = icmp eq i32 %2200, 0
  br i1 %2201, label %2202, label %2194, !llvm.loop !14

2202:                                             ; preds = %2194, %2187
  %2203 = phi i8* [ %2185, %2187 ], [ %2198, %2194 ]
  %2204 = phi i32 [ %2184, %2187 ], [ %2199, %2194 ]
  %2205 = icmp ult i32 %2191, 7
  br i1 %2205, label %2254, label %2241

2206:                                             ; preds = %2206, %2179
  %2207 = phi i8* [ %2156, %2179 ], [ %2238, %2206 ]
  %2208 = phi i32 [ 0, %2179 ], [ %2237, %2206 ]
  %2209 = phi i32 [ %2084, %2179 ], [ %2239, %2206 ]
  %2210 = ashr i32 %2209, 5
  %2211 = trunc i32 %2209 to i8
  %2212 = and i8 %2211, 31
  %2213 = insertelement <16 x i8> undef, i8 %2212, i32 0
  %2214 = shufflevector <16 x i8> %2213, <16 x i8> undef, <16 x i32> zeroinitializer
  %2215 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2214
  %2216 = shufflevector <16 x i8> %2215, <16 x i8> %2214, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2217 = trunc i32 %2210 to i16
  %2218 = insertelement <8 x i16> undef, i16 %2217, i32 0
  %2219 = shufflevector <8 x i16> %2218, <8 x i16> undef, <8 x i32> zeroinitializer
  %2220 = add <8 x i16> %2219, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %2221 = sext i32 %2210 to i64
  %2222 = getelementptr inbounds i8, i8* %2166, i64 %2221
  %2223 = bitcast i8* %2222 to i64*
  %2224 = load i64, i64* %2223, align 1
  %2225 = insertelement <2 x i64> undef, i64 %2224, i32 0
  %2226 = bitcast <2 x i64> %2225 to <16 x i8>
  %2227 = shufflevector <16 x i8> %2226, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %2228 = icmp sgt <8 x i16> %2220, %2182
  %2229 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2227, <16 x i8> %2216) #11
  %2230 = lshr <8 x i16> %2229, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2231 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2230, <8 x i16> zeroinitializer) #11
  %2232 = select <8 x i1> %2228, <8 x i16> %2174, <8 x i16> %2231
  %2233 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2232, <8 x i16> undef) #11
  %2234 = bitcast <16 x i8> %2233 to <4 x i32>
  %2235 = extractelement <4 x i32> %2234, i32 0
  %2236 = bitcast i8* %2207 to i32*
  store i32 %2235, i32* %2236, align 1
  %2237 = add nuw nsw i32 %2208, 1
  %2238 = getelementptr inbounds i8, i8* %2207, i64 %1
  %2239 = sub i32 %2209, %6
  %2240 = icmp slt i32 %2237, %2177
  br i1 %2240, label %2206, label %2183

2241:                                             ; preds = %2202, %2241
  %2242 = phi i8* [ %2251, %2241 ], [ %2203, %2202 ]
  %2243 = phi i32 [ %2252, %2241 ], [ %2204, %2202 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2242, i8 %2188, i64 4, i1 false) #11
  %2244 = getelementptr inbounds i8, i8* %2242, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2244, i8 %2188, i64 4, i1 false) #11
  %2245 = getelementptr inbounds i8, i8* %2244, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2245, i8 %2188, i64 4, i1 false) #11
  %2246 = getelementptr inbounds i8, i8* %2245, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2246, i8 %2188, i64 4, i1 false) #11
  %2247 = getelementptr inbounds i8, i8* %2246, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2247, i8 %2188, i64 4, i1 false) #11
  %2248 = getelementptr inbounds i8, i8* %2247, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2248, i8 %2188, i64 4, i1 false) #11
  %2249 = getelementptr inbounds i8, i8* %2248, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2249, i8 %2188, i64 4, i1 false) #11
  %2250 = getelementptr inbounds i8, i8* %2249, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2250, i8 %2188, i64 4, i1 false) #11
  %2251 = getelementptr inbounds i8, i8* %2250, i64 %1
  %2252 = add nuw nsw i32 %2243, 8
  %2253 = icmp eq i32 %2252, %2163
  br i1 %2253, label %2254, label %2241

2254:                                             ; preds = %2202, %2241, %2183
  %2255 = getelementptr inbounds i8, i8* %2156, i64 4
  %2256 = shl i32 %2157, 1
  %2257 = or i32 %2256, 8
  %2258 = sext i32 %2257 to i64
  %2259 = getelementptr inbounds i8, i8* %19, i64 %2258
  %2260 = getelementptr inbounds i8, i8* %2259, i64 %2169
  %2261 = load i8, i8* %2260, align 2
  %2262 = zext i8 %2261 to i16
  %2263 = insertelement <8 x i16> undef, i16 %2262, i32 0
  %2264 = shufflevector <8 x i16> %2263, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  br i1 %2178, label %2265, label %2269

2265:                                             ; preds = %2254
  %2266 = trunc i32 %2168 to i16
  %2267 = insertelement <8 x i16> undef, i16 %2266, i32 0
  %2268 = shufflevector <8 x i16> %2267, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %2292

2269:                                             ; preds = %2292, %2254
  %2270 = phi i32 [ 0, %2254 ], [ %2177, %2292 ]
  %2271 = phi i8* [ %2255, %2254 ], [ %2324, %2292 ]
  %2272 = icmp sgt i32 %2163, %2270
  br i1 %2272, label %2273, label %2340

2273:                                             ; preds = %2269
  %2274 = load i8, i8* %2260, align 2
  %2275 = sub i32 0, %2270
  %2276 = xor i32 %2270, -1
  %2277 = add i32 %2163, %2276
  %2278 = and i32 %2275, 7
  %2279 = icmp eq i32 %2278, 0
  br i1 %2279, label %2288, label %2280

2280:                                             ; preds = %2273, %2280
  %2281 = phi i8* [ %2284, %2280 ], [ %2271, %2273 ]
  %2282 = phi i32 [ %2285, %2280 ], [ %2270, %2273 ]
  %2283 = phi i32 [ %2286, %2280 ], [ %2278, %2273 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2281, i8 %2274, i64 4, i1 false) #11
  %2284 = getelementptr inbounds i8, i8* %2281, i64 %1
  %2285 = add nuw nsw i32 %2282, 1
  %2286 = add i32 %2283, -1
  %2287 = icmp eq i32 %2286, 0
  br i1 %2287, label %2288, label %2280, !llvm.loop !15

2288:                                             ; preds = %2280, %2273
  %2289 = phi i8* [ %2271, %2273 ], [ %2284, %2280 ]
  %2290 = phi i32 [ %2270, %2273 ], [ %2285, %2280 ]
  %2291 = icmp ult i32 %2277, 7
  br i1 %2291, label %2340, label %2327

2292:                                             ; preds = %2292, %2265
  %2293 = phi i8* [ %2255, %2265 ], [ %2324, %2292 ]
  %2294 = phi i32 [ 0, %2265 ], [ %2323, %2292 ]
  %2295 = phi i32 [ %2084, %2265 ], [ %2325, %2292 ]
  %2296 = ashr i32 %2295, 5
  %2297 = trunc i32 %2295 to i8
  %2298 = and i8 %2297, 31
  %2299 = insertelement <16 x i8> undef, i8 %2298, i32 0
  %2300 = shufflevector <16 x i8> %2299, <16 x i8> undef, <16 x i32> zeroinitializer
  %2301 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2300
  %2302 = shufflevector <16 x i8> %2301, <16 x i8> %2300, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2303 = trunc i32 %2296 to i16
  %2304 = insertelement <8 x i16> undef, i16 %2303, i32 0
  %2305 = shufflevector <8 x i16> %2304, <8 x i16> undef, <8 x i32> zeroinitializer
  %2306 = add <8 x i16> %2305, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %2307 = sext i32 %2296 to i64
  %2308 = getelementptr inbounds i8, i8* %2259, i64 %2307
  %2309 = bitcast i8* %2308 to i64*
  %2310 = load i64, i64* %2309, align 1
  %2311 = insertelement <2 x i64> undef, i64 %2310, i32 0
  %2312 = bitcast <2 x i64> %2311 to <16 x i8>
  %2313 = shufflevector <16 x i8> %2312, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %2314 = icmp sgt <8 x i16> %2306, %2268
  %2315 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2313, <16 x i8> %2302) #11
  %2316 = lshr <8 x i16> %2315, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2317 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2316, <8 x i16> zeroinitializer) #11
  %2318 = select <8 x i1> %2314, <8 x i16> %2264, <8 x i16> %2317
  %2319 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2318, <8 x i16> undef) #11
  %2320 = bitcast <16 x i8> %2319 to <4 x i32>
  %2321 = extractelement <4 x i32> %2320, i32 0
  %2322 = bitcast i8* %2293 to i32*
  store i32 %2321, i32* %2322, align 1
  %2323 = add nuw nsw i32 %2294, 1
  %2324 = getelementptr inbounds i8, i8* %2293, i64 %1
  %2325 = sub i32 %2295, %6
  %2326 = icmp slt i32 %2323, %2177
  br i1 %2326, label %2292, label %2269

2327:                                             ; preds = %2288, %2327
  %2328 = phi i8* [ %2337, %2327 ], [ %2289, %2288 ]
  %2329 = phi i32 [ %2338, %2327 ], [ %2290, %2288 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2328, i8 %2274, i64 4, i1 false) #11
  %2330 = getelementptr inbounds i8, i8* %2328, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2330, i8 %2274, i64 4, i1 false) #11
  %2331 = getelementptr inbounds i8, i8* %2330, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2331, i8 %2274, i64 4, i1 false) #11
  %2332 = getelementptr inbounds i8, i8* %2331, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2332, i8 %2274, i64 4, i1 false) #11
  %2333 = getelementptr inbounds i8, i8* %2332, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2333, i8 %2274, i64 4, i1 false) #11
  %2334 = getelementptr inbounds i8, i8* %2333, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2334, i8 %2274, i64 4, i1 false) #11
  %2335 = getelementptr inbounds i8, i8* %2334, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2335, i8 %2274, i64 4, i1 false) #11
  %2336 = getelementptr inbounds i8, i8* %2335, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %2336, i8 %2274, i64 4, i1 false) #11
  %2337 = getelementptr inbounds i8, i8* %2336, i64 %1
  %2338 = add nuw nsw i32 %2329, 8
  %2339 = icmp eq i32 %2338, %2163
  br i1 %2339, label %2340, label %2327

2340:                                             ; preds = %2288, %2327, %2269
  %2341 = sext i32 %2163 to i64
  %2342 = mul nsw i64 %2341, %1
  %2343 = getelementptr inbounds i8, i8* %2156, i64 %2342
  %2344 = mul nsw i32 %2163, %6
  %2345 = trunc i32 %2344 to i16
  %2346 = insertelement <8 x i16> undef, i16 %2345, i32 0
  %2347 = shufflevector <8 x i16> %2346, <8 x i16> undef, <8 x i32> zeroinitializer
  %2348 = add nuw nsw i64 %2152, 8
  %2349 = trunc i64 %2348 to i32
  %2350 = shl i32 %2349, 6
  %2351 = sdiv i32 %2350, %6
  %2352 = icmp sgt i32 %2351, %5
  %2353 = select i1 %2352, i32 %5, i32 %2351
  %2354 = icmp slt i32 %2353, %2079
  %2355 = select i1 %2354, i32 %2353, i32 %2079
  %2356 = bitcast <2 x i64> %2155 to <8 x i16>
  %2357 = add <8 x i16> %2347, %2356
  %2358 = sub <8 x i16> %2088, %2347
  %2359 = sub nsw i32 0, %2344
  %2360 = icmp slt i32 %2163, %2355
  br i1 %2360, label %2361, label %2668

2361:                                             ; preds = %2340
  %2362 = ashr <8 x i16> %2154, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %2363 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %2362, <8 x i16> %2362) #11
  %2364 = add <16 x i8> %2363, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %2365 = shufflevector <16 x i8> %2363, <16 x i8> %2364, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2366 = add <16 x i8> %2365, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %2367 = and <8 x i16> %2154, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %2368 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2367, <8 x i16> %2367) #11
  %2369 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2368
  %2370 = shufflevector <16 x i8> %2369, <16 x i8> %2368, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2371 = sext i32 %2355 to i64
  br label %2372

2372:                                             ; preds = %2372, %2361
  %2373 = phi i64 [ %2341, %2361 ], [ %2660, %2372 ]
  %2374 = phi i32 [ %2359, %2361 ], [ %2664, %2372 ]
  %2375 = phi <8 x i16> [ %2358, %2361 ], [ %2663, %2372 ]
  %2376 = phi <8 x i16> [ %2357, %2361 ], [ %2662, %2372 ]
  %2377 = phi i8* [ %2343, %2361 ], [ %2661, %2372 ]
  %2378 = trunc i64 %2373 to i32
  %2379 = add i32 %2153, %2378
  %2380 = shl i32 %2379, 1
  %2381 = sext i32 %2380 to i64
  %2382 = getelementptr inbounds i8, i8* %20, i64 %2381
  %2383 = getelementptr inbounds i8, i8* %2382, i64 -15
  %2384 = bitcast i8* %2383 to <16 x i8>*
  %2385 = load <16 x i8>, <16 x i8>* %2384, align 1
  %2386 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %2385, <16 x i8> %2366) #11
  %2387 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2386, <16 x i8> %2370) #11
  %2388 = lshr <8 x i16> %2387, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2389 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2388, <8 x i16> zeroinitializer) #11
  %2390 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2389, <8 x i16> undef) #11
  %2391 = bitcast <16 x i8> %2390 to <2 x i64>
  %2392 = extractelement <2 x i64> %2391, i32 0
  %2393 = bitcast i8* %2377 to i64*
  store i64 %2392, i64* %2393, align 1
  %2394 = getelementptr inbounds i8, i8* %2377, i64 %1
  %2395 = getelementptr inbounds i8, i8* %2382, i64 -13
  %2396 = bitcast i8* %2395 to <16 x i8>*
  %2397 = load <16 x i8>, <16 x i8>* %2396, align 1
  %2398 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %2397, <16 x i8> %2366) #11
  %2399 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2398, <16 x i8> %2370) #11
  %2400 = lshr <8 x i16> %2399, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2401 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2400, <8 x i16> zeroinitializer) #11
  %2402 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2401, <8 x i16> undef) #11
  %2403 = bitcast <16 x i8> %2402 to <2 x i64>
  %2404 = extractelement <2 x i64> %2403, i32 0
  %2405 = bitcast i8* %2394 to i64*
  store i64 %2404, i64* %2405, align 1
  %2406 = getelementptr inbounds i8, i8* %2394, i64 %1
  %2407 = getelementptr inbounds i8, i8* %2382, i64 -11
  %2408 = bitcast i8* %2407 to <16 x i8>*
  %2409 = load <16 x i8>, <16 x i8>* %2408, align 1
  %2410 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %2409, <16 x i8> %2366) #11
  %2411 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2410, <16 x i8> %2370) #11
  %2412 = lshr <8 x i16> %2411, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2413 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2412, <8 x i16> zeroinitializer) #11
  %2414 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2413, <8 x i16> undef) #11
  %2415 = bitcast <16 x i8> %2414 to <2 x i64>
  %2416 = extractelement <2 x i64> %2415, i32 0
  %2417 = bitcast i8* %2406 to i64*
  store i64 %2416, i64* %2417, align 1
  %2418 = getelementptr inbounds i8, i8* %2406, i64 %1
  %2419 = getelementptr inbounds i8, i8* %2382, i64 -9
  %2420 = bitcast i8* %2419 to <16 x i8>*
  %2421 = load <16 x i8>, <16 x i8>* %2420, align 1
  %2422 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %2421, <16 x i8> %2366) #11
  %2423 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2422, <16 x i8> %2370) #11
  %2424 = lshr <8 x i16> %2423, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2425 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2424, <8 x i16> zeroinitializer) #11
  %2426 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2425, <8 x i16> undef) #11
  %2427 = bitcast <16 x i8> %2426 to <2 x i64>
  %2428 = extractelement <2 x i64> %2427, i32 0
  %2429 = bitcast i8* %2418 to i64*
  store i64 %2428, i64* %2429, align 1
  %2430 = getelementptr inbounds i8, i8* %2418, i64 %1
  %2431 = getelementptr inbounds i8, i8* %2382, i64 -7
  %2432 = bitcast i8* %2431 to <16 x i8>*
  %2433 = load <16 x i8>, <16 x i8>* %2432, align 1
  %2434 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %2433, <16 x i8> %2366) #11
  %2435 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2434, <16 x i8> %2370) #11
  %2436 = lshr <8 x i16> %2435, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2437 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2436, <8 x i16> zeroinitializer) #11
  %2438 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2437, <8 x i16> undef) #11
  %2439 = bitcast <16 x i8> %2438 to <2 x i64>
  %2440 = extractelement <2 x i64> %2439, i32 0
  %2441 = bitcast i8* %2430 to i64*
  store i64 %2440, i64* %2441, align 1
  %2442 = getelementptr inbounds i8, i8* %2430, i64 %1
  %2443 = getelementptr inbounds i8, i8* %2382, i64 -5
  %2444 = bitcast i8* %2443 to <16 x i8>*
  %2445 = load <16 x i8>, <16 x i8>* %2444, align 1
  %2446 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %2445, <16 x i8> %2366) #11
  %2447 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2446, <16 x i8> %2370) #11
  %2448 = lshr <8 x i16> %2447, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2449 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2448, <8 x i16> zeroinitializer) #11
  %2450 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2449, <8 x i16> undef) #11
  %2451 = bitcast <16 x i8> %2450 to <2 x i64>
  %2452 = extractelement <2 x i64> %2451, i32 0
  %2453 = bitcast i8* %2442 to i64*
  store i64 %2452, i64* %2453, align 1
  %2454 = getelementptr inbounds i8, i8* %2442, i64 %1
  %2455 = getelementptr inbounds i8, i8* %2382, i64 -3
  %2456 = bitcast i8* %2455 to <16 x i8>*
  %2457 = load <16 x i8>, <16 x i8>* %2456, align 1
  %2458 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %2457, <16 x i8> %2366) #11
  %2459 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2458, <16 x i8> %2370) #11
  %2460 = lshr <8 x i16> %2459, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2461 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2460, <8 x i16> zeroinitializer) #11
  %2462 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2461, <8 x i16> undef) #11
  %2463 = bitcast <16 x i8> %2462 to <2 x i64>
  %2464 = extractelement <2 x i64> %2463, i32 0
  %2465 = bitcast i8* %2454 to i64*
  store i64 %2464, i64* %2465, align 1
  %2466 = getelementptr inbounds i8, i8* %2454, i64 %1
  %2467 = getelementptr inbounds i8, i8* %2382, i64 -1
  %2468 = bitcast i8* %2467 to <16 x i8>*
  %2469 = load <16 x i8>, <16 x i8>* %2468, align 1
  %2470 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %2469, <16 x i8> %2366) #11
  %2471 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2470, <16 x i8> %2370) #11
  %2472 = lshr <8 x i16> %2471, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2473 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2472, <8 x i16> zeroinitializer) #11
  %2474 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2473, <8 x i16> undef) #11
  %2475 = bitcast <16 x i8> %2474 to <2 x i64>
  %2476 = extractelement <2 x i64> %2475, i32 0
  %2477 = bitcast i8* %2466 to i64*
  store i64 %2476, i64* %2477, align 1
  %2478 = and <8 x i16> %2375, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %2479 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2478, <8 x i16> %2478) #11
  %2480 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2479
  %2481 = shufflevector <16 x i8> %2480, <16 x i8> %2479, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2482 = ashr <8 x i16> %2376, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %2483 = bitcast <8 x i16> %2482 to <16 x i8>
  %2484 = sub nsw i32 %2374, %6
  %2485 = ashr i32 %2484, 5
  %2486 = sext i32 %2485 to i64
  %2487 = getelementptr inbounds i8, i8* %2166, i64 %2486
  %2488 = shufflevector <16 x i8> %2481, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %2489 = bitcast i8* %2487 to <16 x i8>*
  %2490 = load <16 x i8>, <16 x i8>* %2489, align 1
  %2491 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2490, <16 x i8> %2488) #11
  %2492 = lshr <8 x i16> %2491, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2493 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2492, <8 x i16> zeroinitializer) #11
  %2494 = shufflevector <16 x i8> %2483, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %2495 = bitcast <16 x i8> %2494 to <8 x i16>
  %2496 = icmp sgt <8 x i16> %2495, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %2497 = load i64, i64* %2393, align 1
  %2498 = insertelement <2 x i64> undef, i64 %2497, i32 0
  %2499 = bitcast <2 x i64> %2498 to <16 x i8>
  %2500 = shufflevector <16 x i8> %2499, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2501 = zext <8 x i8> %2500 to <8 x i16>
  %2502 = select <8 x i1> %2496, <8 x i16> %2501, <8 x i16> %2493
  %2503 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2502, <8 x i16> undef) #11
  %2504 = bitcast <16 x i8> %2503 to <2 x i64>
  %2505 = extractelement <2 x i64> %2504, i32 0
  store i64 %2505, i64* %2393, align 1
  %2506 = sub nsw i32 %2484, %6
  %2507 = ashr i32 %2506, 5
  %2508 = sext i32 %2507 to i64
  %2509 = getelementptr inbounds i8, i8* %2166, i64 %2508
  %2510 = shufflevector <16 x i8> %2481, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %2511 = bitcast i8* %2509 to <16 x i8>*
  %2512 = load <16 x i8>, <16 x i8>* %2511, align 1
  %2513 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2512, <16 x i8> %2510) #11
  %2514 = lshr <8 x i16> %2513, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2515 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2514, <8 x i16> zeroinitializer) #11
  %2516 = shufflevector <16 x i8> %2483, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %2517 = bitcast <16 x i8> %2516 to <8 x i16>
  %2518 = icmp sgt <8 x i16> %2517, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %2519 = load i64, i64* %2405, align 1
  %2520 = insertelement <2 x i64> undef, i64 %2519, i32 0
  %2521 = bitcast <2 x i64> %2520 to <16 x i8>
  %2522 = shufflevector <16 x i8> %2521, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2523 = zext <8 x i8> %2522 to <8 x i16>
  %2524 = select <8 x i1> %2518, <8 x i16> %2523, <8 x i16> %2515
  %2525 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2524, <8 x i16> undef) #11
  %2526 = bitcast <16 x i8> %2525 to <2 x i64>
  %2527 = extractelement <2 x i64> %2526, i32 0
  store i64 %2527, i64* %2405, align 1
  %2528 = sub nsw i32 %2506, %6
  %2529 = ashr i32 %2528, 5
  %2530 = sext i32 %2529 to i64
  %2531 = getelementptr inbounds i8, i8* %2166, i64 %2530
  %2532 = shufflevector <16 x i8> %2481, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %2533 = bitcast i8* %2531 to <16 x i8>*
  %2534 = load <16 x i8>, <16 x i8>* %2533, align 1
  %2535 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2534, <16 x i8> %2532) #11
  %2536 = lshr <8 x i16> %2535, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2537 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2536, <8 x i16> zeroinitializer) #11
  %2538 = shufflevector <16 x i8> %2483, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %2539 = bitcast <16 x i8> %2538 to <8 x i16>
  %2540 = icmp sgt <8 x i16> %2539, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %2541 = load i64, i64* %2417, align 1
  %2542 = insertelement <2 x i64> undef, i64 %2541, i32 0
  %2543 = bitcast <2 x i64> %2542 to <16 x i8>
  %2544 = shufflevector <16 x i8> %2543, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2545 = zext <8 x i8> %2544 to <8 x i16>
  %2546 = select <8 x i1> %2540, <8 x i16> %2545, <8 x i16> %2537
  %2547 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2546, <8 x i16> undef) #11
  %2548 = bitcast <16 x i8> %2547 to <2 x i64>
  %2549 = extractelement <2 x i64> %2548, i32 0
  store i64 %2549, i64* %2417, align 1
  %2550 = sub nsw i32 %2528, %6
  %2551 = ashr i32 %2550, 5
  %2552 = sext i32 %2551 to i64
  %2553 = getelementptr inbounds i8, i8* %2166, i64 %2552
  %2554 = shufflevector <16 x i8> %2481, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %2555 = bitcast i8* %2553 to <16 x i8>*
  %2556 = load <16 x i8>, <16 x i8>* %2555, align 1
  %2557 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2556, <16 x i8> %2554) #11
  %2558 = lshr <8 x i16> %2557, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2559 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2558, <8 x i16> zeroinitializer) #11
  %2560 = shufflevector <16 x i8> %2483, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %2561 = bitcast <16 x i8> %2560 to <8 x i16>
  %2562 = icmp sgt <8 x i16> %2561, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %2563 = load i64, i64* %2429, align 1
  %2564 = insertelement <2 x i64> undef, i64 %2563, i32 0
  %2565 = bitcast <2 x i64> %2564 to <16 x i8>
  %2566 = shufflevector <16 x i8> %2565, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2567 = zext <8 x i8> %2566 to <8 x i16>
  %2568 = select <8 x i1> %2562, <8 x i16> %2567, <8 x i16> %2559
  %2569 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2568, <8 x i16> undef) #11
  %2570 = bitcast <16 x i8> %2569 to <2 x i64>
  %2571 = extractelement <2 x i64> %2570, i32 0
  store i64 %2571, i64* %2429, align 1
  %2572 = sub nsw i32 %2550, %6
  %2573 = ashr i32 %2572, 5
  %2574 = sext i32 %2573 to i64
  %2575 = getelementptr inbounds i8, i8* %2166, i64 %2574
  %2576 = shufflevector <16 x i8> %2481, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %2577 = bitcast i8* %2575 to <16 x i8>*
  %2578 = load <16 x i8>, <16 x i8>* %2577, align 1
  %2579 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2578, <16 x i8> %2576) #11
  %2580 = lshr <8 x i16> %2579, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2581 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2580, <8 x i16> zeroinitializer) #11
  %2582 = shufflevector <16 x i8> %2483, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %2583 = bitcast <16 x i8> %2582 to <8 x i16>
  %2584 = icmp sgt <8 x i16> %2583, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %2585 = load i64, i64* %2441, align 1
  %2586 = insertelement <2 x i64> undef, i64 %2585, i32 0
  %2587 = bitcast <2 x i64> %2586 to <16 x i8>
  %2588 = shufflevector <16 x i8> %2587, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2589 = zext <8 x i8> %2588 to <8 x i16>
  %2590 = select <8 x i1> %2584, <8 x i16> %2589, <8 x i16> %2581
  %2591 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2590, <8 x i16> undef) #11
  %2592 = bitcast <16 x i8> %2591 to <2 x i64>
  %2593 = extractelement <2 x i64> %2592, i32 0
  store i64 %2593, i64* %2441, align 1
  %2594 = sub nsw i32 %2572, %6
  %2595 = ashr i32 %2594, 5
  %2596 = sext i32 %2595 to i64
  %2597 = getelementptr inbounds i8, i8* %2166, i64 %2596
  %2598 = shufflevector <16 x i8> %2481, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %2599 = bitcast i8* %2597 to <16 x i8>*
  %2600 = load <16 x i8>, <16 x i8>* %2599, align 1
  %2601 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2600, <16 x i8> %2598) #11
  %2602 = lshr <8 x i16> %2601, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2603 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2602, <8 x i16> zeroinitializer) #11
  %2604 = shufflevector <16 x i8> %2483, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %2605 = bitcast <16 x i8> %2604 to <8 x i16>
  %2606 = icmp sgt <8 x i16> %2605, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %2607 = load i64, i64* %2453, align 1
  %2608 = insertelement <2 x i64> undef, i64 %2607, i32 0
  %2609 = bitcast <2 x i64> %2608 to <16 x i8>
  %2610 = shufflevector <16 x i8> %2609, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2611 = zext <8 x i8> %2610 to <8 x i16>
  %2612 = select <8 x i1> %2606, <8 x i16> %2611, <8 x i16> %2603
  %2613 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2612, <8 x i16> undef) #11
  %2614 = bitcast <16 x i8> %2613 to <2 x i64>
  %2615 = extractelement <2 x i64> %2614, i32 0
  store i64 %2615, i64* %2453, align 1
  %2616 = sub nsw i32 %2594, %6
  %2617 = ashr i32 %2616, 5
  %2618 = sext i32 %2617 to i64
  %2619 = getelementptr inbounds i8, i8* %2166, i64 %2618
  %2620 = shufflevector <16 x i8> %2481, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %2621 = bitcast i8* %2619 to <16 x i8>*
  %2622 = load <16 x i8>, <16 x i8>* %2621, align 1
  %2623 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2622, <16 x i8> %2620) #11
  %2624 = lshr <8 x i16> %2623, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2625 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2624, <8 x i16> zeroinitializer) #11
  %2626 = shufflevector <16 x i8> %2483, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %2627 = bitcast <16 x i8> %2626 to <8 x i16>
  %2628 = icmp sgt <8 x i16> %2627, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %2629 = load i64, i64* %2465, align 1
  %2630 = insertelement <2 x i64> undef, i64 %2629, i32 0
  %2631 = bitcast <2 x i64> %2630 to <16 x i8>
  %2632 = shufflevector <16 x i8> %2631, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2633 = zext <8 x i8> %2632 to <8 x i16>
  %2634 = select <8 x i1> %2628, <8 x i16> %2633, <8 x i16> %2625
  %2635 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2634, <8 x i16> undef) #11
  %2636 = bitcast <16 x i8> %2635 to <2 x i64>
  %2637 = extractelement <2 x i64> %2636, i32 0
  store i64 %2637, i64* %2465, align 1
  %2638 = sub nsw i32 %2616, %6
  %2639 = ashr i32 %2638, 5
  %2640 = sext i32 %2639 to i64
  %2641 = getelementptr inbounds i8, i8* %2166, i64 %2640
  %2642 = shufflevector <16 x i8> %2481, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %2643 = bitcast i8* %2641 to <16 x i8>*
  %2644 = load <16 x i8>, <16 x i8>* %2643, align 1
  %2645 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2644, <16 x i8> %2642) #11
  %2646 = lshr <8 x i16> %2645, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2647 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2646, <8 x i16> zeroinitializer) #11
  %2648 = shufflevector <16 x i8> %2483, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %2649 = bitcast <16 x i8> %2648 to <8 x i16>
  %2650 = icmp sgt <8 x i16> %2649, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %2651 = load i64, i64* %2477, align 1
  %2652 = insertelement <2 x i64> undef, i64 %2651, i32 0
  %2653 = bitcast <2 x i64> %2652 to <16 x i8>
  %2654 = shufflevector <16 x i8> %2653, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %2655 = zext <8 x i8> %2654 to <8 x i16>
  %2656 = select <8 x i1> %2650, <8 x i16> %2655, <8 x i16> %2647
  %2657 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2656, <8 x i16> undef) #11
  %2658 = bitcast <16 x i8> %2657 to <2 x i64>
  %2659 = extractelement <2 x i64> %2658, i32 0
  store i64 %2659, i64* %2477, align 1
  %2660 = add nsw i64 %2373, 8
  %2661 = getelementptr inbounds i8, i8* %2377, i64 %2071
  %2662 = add <8 x i16> %2376, %2083
  %2663 = sub <8 x i16> %2375, %2083
  %2664 = sub nsw i32 %2374, %2080
  %2665 = icmp slt i64 %2660, %2371
  br i1 %2665, label %2372, label %2666

2666:                                             ; preds = %2372
  %2667 = trunc i64 %2660 to i32
  br label %2668

2668:                                             ; preds = %2666, %2340
  %2669 = phi i8* [ %2343, %2340 ], [ %2661, %2666 ]
  %2670 = phi i32 [ %2163, %2340 ], [ %2667, %2666 ]
  %2671 = phi <8 x i16> [ %2357, %2340 ], [ %2662, %2666 ]
  %2672 = phi <8 x i16> [ %2358, %2340 ], [ %2663, %2666 ]
  %2673 = phi i32 [ %2359, %2340 ], [ %2664, %2666 ]
  %2674 = extractelement <8 x i16> %2154, i64 0
  %2675 = icmp slt i32 %2670, %2353
  br i1 %2675, label %2676, label %2753

2676:                                             ; preds = %2668
  %2677 = sext i16 %2674 to i32
  %2678 = ashr i32 %2677, 5
  %2679 = trunc i16 %2674 to i8
  %2680 = and i8 %2679, 31
  %2681 = insertelement <16 x i8> undef, i8 %2680, i32 0
  %2682 = shufflevector <16 x i8> %2681, <16 x i8> undef, <16 x i32> zeroinitializer
  %2683 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2682
  %2684 = shufflevector <16 x i8> %2683, <16 x i8> %2682, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2685 = sext i32 %2678 to i64
  %2686 = sub i32 %2677, %7
  %2687 = ashr i32 %2686, 5
  %2688 = trunc i32 %2686 to i8
  %2689 = and i8 %2688, 31
  %2690 = insertelement <16 x i8> undef, i8 %2689, i32 0
  %2691 = shufflevector <16 x i8> %2690, <16 x i8> undef, <16 x i32> zeroinitializer
  %2692 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2691
  %2693 = shufflevector <16 x i8> %2692, <16 x i8> %2691, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2694 = sext i32 %2687 to i64
  %2695 = sub i32 %2686, %7
  %2696 = ashr i32 %2695, 5
  %2697 = trunc i32 %2695 to i8
  %2698 = and i8 %2697, 31
  %2699 = insertelement <16 x i8> undef, i8 %2698, i32 0
  %2700 = shufflevector <16 x i8> %2699, <16 x i8> undef, <16 x i32> zeroinitializer
  %2701 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2700
  %2702 = shufflevector <16 x i8> %2701, <16 x i8> %2700, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2703 = sext i32 %2696 to i64
  %2704 = sub i32 %2695, %7
  %2705 = ashr i32 %2704, 5
  %2706 = trunc i32 %2704 to i8
  %2707 = and i8 %2706, 31
  %2708 = insertelement <16 x i8> undef, i8 %2707, i32 0
  %2709 = shufflevector <16 x i8> %2708, <16 x i8> undef, <16 x i32> zeroinitializer
  %2710 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2709
  %2711 = shufflevector <16 x i8> %2710, <16 x i8> %2709, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2712 = sext i32 %2705 to i64
  %2713 = sub i32 %2704, %7
  %2714 = ashr i32 %2713, 5
  %2715 = trunc i32 %2713 to i8
  %2716 = and i8 %2715, 31
  %2717 = insertelement <16 x i8> undef, i8 %2716, i32 0
  %2718 = shufflevector <16 x i8> %2717, <16 x i8> undef, <16 x i32> zeroinitializer
  %2719 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2718
  %2720 = shufflevector <16 x i8> %2719, <16 x i8> %2718, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2721 = sext i32 %2714 to i64
  %2722 = sub i32 %2713, %7
  %2723 = ashr i32 %2722, 5
  %2724 = trunc i32 %2722 to i8
  %2725 = and i8 %2724, 31
  %2726 = insertelement <16 x i8> undef, i8 %2725, i32 0
  %2727 = shufflevector <16 x i8> %2726, <16 x i8> undef, <16 x i32> zeroinitializer
  %2728 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2727
  %2729 = shufflevector <16 x i8> %2728, <16 x i8> %2727, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2730 = sext i32 %2723 to i64
  %2731 = sub i32 %2722, %7
  %2732 = ashr i32 %2731, 5
  %2733 = trunc i32 %2731 to i8
  %2734 = and i8 %2733, 31
  %2735 = insertelement <16 x i8> undef, i8 %2734, i32 0
  %2736 = shufflevector <16 x i8> %2735, <16 x i8> undef, <16 x i32> zeroinitializer
  %2737 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2736
  %2738 = shufflevector <16 x i8> %2737, <16 x i8> %2736, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2739 = sext i32 %2732 to i64
  %2740 = sub i32 %2731, %7
  %2741 = ashr i32 %2740, 5
  %2742 = trunc i32 %2740 to i8
  %2743 = and i8 %2742, 31
  %2744 = insertelement <16 x i8> undef, i8 %2743, i32 0
  %2745 = shufflevector <16 x i8> %2744, <16 x i8> undef, <16 x i32> zeroinitializer
  %2746 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2745
  %2747 = shufflevector <16 x i8> %2746, <16 x i8> %2745, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2748 = sext i32 %2741 to i64
  %2749 = sext i32 %2670 to i64
  %2750 = sext i32 %2353 to i64
  br label %2831

2751:                                             ; preds = %2831
  %2752 = trunc i64 %3159 to i32
  br label %2753

2753:                                             ; preds = %2751, %2668
  %2754 = phi i8* [ %2669, %2668 ], [ %3160, %2751 ]
  %2755 = phi i32 [ %2670, %2668 ], [ %2752, %2751 ]
  %2756 = icmp slt i32 %2755, %5
  br i1 %2756, label %2757, label %3311

2757:                                             ; preds = %2753
  %2758 = sext i16 %2674 to i32
  %2759 = ashr i32 %2758, 5
  %2760 = trunc i16 %2674 to i8
  %2761 = and i8 %2760, 31
  %2762 = insertelement <16 x i8> undef, i8 %2761, i32 0
  %2763 = shufflevector <16 x i8> %2762, <16 x i8> undef, <16 x i32> zeroinitializer
  %2764 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2763
  %2765 = shufflevector <16 x i8> %2764, <16 x i8> %2763, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2766 = sext i32 %2759 to i64
  %2767 = sub i32 %2758, %7
  %2768 = ashr i32 %2767, 5
  %2769 = trunc i32 %2767 to i8
  %2770 = and i8 %2769, 31
  %2771 = insertelement <16 x i8> undef, i8 %2770, i32 0
  %2772 = shufflevector <16 x i8> %2771, <16 x i8> undef, <16 x i32> zeroinitializer
  %2773 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2772
  %2774 = shufflevector <16 x i8> %2773, <16 x i8> %2772, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2775 = sext i32 %2768 to i64
  %2776 = sub i32 %2767, %7
  %2777 = ashr i32 %2776, 5
  %2778 = trunc i32 %2776 to i8
  %2779 = and i8 %2778, 31
  %2780 = insertelement <16 x i8> undef, i8 %2779, i32 0
  %2781 = shufflevector <16 x i8> %2780, <16 x i8> undef, <16 x i32> zeroinitializer
  %2782 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2781
  %2783 = shufflevector <16 x i8> %2782, <16 x i8> %2781, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2784 = sext i32 %2777 to i64
  %2785 = sub i32 %2776, %7
  %2786 = ashr i32 %2785, 5
  %2787 = trunc i32 %2785 to i8
  %2788 = and i8 %2787, 31
  %2789 = insertelement <16 x i8> undef, i8 %2788, i32 0
  %2790 = shufflevector <16 x i8> %2789, <16 x i8> undef, <16 x i32> zeroinitializer
  %2791 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2790
  %2792 = shufflevector <16 x i8> %2791, <16 x i8> %2790, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2793 = sext i32 %2786 to i64
  %2794 = sub i32 %2785, %7
  %2795 = ashr i32 %2794, 5
  %2796 = trunc i32 %2794 to i8
  %2797 = and i8 %2796, 31
  %2798 = insertelement <16 x i8> undef, i8 %2797, i32 0
  %2799 = shufflevector <16 x i8> %2798, <16 x i8> undef, <16 x i32> zeroinitializer
  %2800 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2799
  %2801 = shufflevector <16 x i8> %2800, <16 x i8> %2799, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2802 = sext i32 %2795 to i64
  %2803 = sub i32 %2794, %7
  %2804 = ashr i32 %2803, 5
  %2805 = trunc i32 %2803 to i8
  %2806 = and i8 %2805, 31
  %2807 = insertelement <16 x i8> undef, i8 %2806, i32 0
  %2808 = shufflevector <16 x i8> %2807, <16 x i8> undef, <16 x i32> zeroinitializer
  %2809 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2808
  %2810 = shufflevector <16 x i8> %2809, <16 x i8> %2808, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2811 = sext i32 %2804 to i64
  %2812 = sub i32 %2803, %7
  %2813 = ashr i32 %2812, 5
  %2814 = trunc i32 %2812 to i8
  %2815 = and i8 %2814, 31
  %2816 = insertelement <16 x i8> undef, i8 %2815, i32 0
  %2817 = shufflevector <16 x i8> %2816, <16 x i8> undef, <16 x i32> zeroinitializer
  %2818 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2817
  %2819 = shufflevector <16 x i8> %2818, <16 x i8> %2817, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2820 = sext i32 %2813 to i64
  %2821 = sub i32 %2812, %7
  %2822 = ashr i32 %2821, 5
  %2823 = trunc i32 %2821 to i8
  %2824 = and i8 %2823, 31
  %2825 = insertelement <16 x i8> undef, i8 %2824, i32 0
  %2826 = shufflevector <16 x i8> %2825, <16 x i8> undef, <16 x i32> zeroinitializer
  %2827 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2826
  %2828 = shufflevector <16 x i8> %2827, <16 x i8> %2826, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2829 = sext i32 %2822 to i64
  %2830 = sext i32 %2755 to i64
  br label %3165

2831:                                             ; preds = %2831, %2676
  %2832 = phi i64 [ %2749, %2676 ], [ %3159, %2831 ]
  %2833 = phi i32 [ %2673, %2676 ], [ %3163, %2831 ]
  %2834 = phi <8 x i16> [ %2672, %2676 ], [ %3162, %2831 ]
  %2835 = phi <8 x i16> [ %2671, %2676 ], [ %3161, %2831 ]
  %2836 = phi i8* [ %2669, %2676 ], [ %3160, %2831 ]
  %2837 = ashr <8 x i16> %2835, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %2838 = trunc i64 %2832 to i32
  %2839 = add i32 %2153, %2838
  %2840 = shl i32 %2839, 1
  %2841 = sext i32 %2840 to i64
  %2842 = getelementptr inbounds i8, i8* %20, i64 %2841
  %2843 = getelementptr inbounds i8, i8* %2842, i64 %2685
  %2844 = bitcast i8* %2843 to <16 x i8>*
  %2845 = load <16 x i8>, <16 x i8>* %2844, align 1
  %2846 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2845, <16 x i8> %2684) #11
  %2847 = lshr <8 x i16> %2846, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2848 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2847, <8 x i16> zeroinitializer) #11
  %2849 = getelementptr inbounds i8, i8* %2842, i64 %2694
  %2850 = bitcast i8* %2849 to <16 x i8>*
  %2851 = load <16 x i8>, <16 x i8>* %2850, align 1
  %2852 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2851, <16 x i8> %2693) #11
  %2853 = lshr <8 x i16> %2852, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2854 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2853, <8 x i16> zeroinitializer) #11
  %2855 = getelementptr inbounds i8, i8* %2842, i64 %2703
  %2856 = bitcast i8* %2855 to <16 x i8>*
  %2857 = load <16 x i8>, <16 x i8>* %2856, align 1
  %2858 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2857, <16 x i8> %2702) #11
  %2859 = lshr <8 x i16> %2858, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2860 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2859, <8 x i16> zeroinitializer) #11
  %2861 = getelementptr inbounds i8, i8* %2842, i64 %2712
  %2862 = bitcast i8* %2861 to <16 x i8>*
  %2863 = load <16 x i8>, <16 x i8>* %2862, align 1
  %2864 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2863, <16 x i8> %2711) #11
  %2865 = lshr <8 x i16> %2864, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2866 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2865, <8 x i16> zeroinitializer) #11
  %2867 = getelementptr inbounds i8, i8* %2842, i64 %2721
  %2868 = bitcast i8* %2867 to <16 x i8>*
  %2869 = load <16 x i8>, <16 x i8>* %2868, align 1
  %2870 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2869, <16 x i8> %2720) #11
  %2871 = lshr <8 x i16> %2870, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2872 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2871, <8 x i16> zeroinitializer) #11
  %2873 = getelementptr inbounds i8, i8* %2842, i64 %2730
  %2874 = bitcast i8* %2873 to <16 x i8>*
  %2875 = load <16 x i8>, <16 x i8>* %2874, align 1
  %2876 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2875, <16 x i8> %2729) #11
  %2877 = lshr <8 x i16> %2876, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2878 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2877, <8 x i16> zeroinitializer) #11
  %2879 = getelementptr inbounds i8, i8* %2842, i64 %2739
  %2880 = bitcast i8* %2879 to <16 x i8>*
  %2881 = load <16 x i8>, <16 x i8>* %2880, align 1
  %2882 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2881, <16 x i8> %2738) #11
  %2883 = lshr <8 x i16> %2882, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2884 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2883, <8 x i16> zeroinitializer) #11
  %2885 = getelementptr inbounds i8, i8* %2842, i64 %2748
  %2886 = bitcast i8* %2885 to <16 x i8>*
  %2887 = load <16 x i8>, <16 x i8>* %2886, align 1
  %2888 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2887, <16 x i8> %2747) #11
  %2889 = lshr <8 x i16> %2888, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2890 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2889, <8 x i16> zeroinitializer) #11
  %2891 = shufflevector <8 x i16> %2848, <8 x i16> %2854, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2892 = shufflevector <8 x i16> %2860, <8 x i16> %2866, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2893 = shufflevector <8 x i16> %2872, <8 x i16> %2878, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2894 = shufflevector <8 x i16> %2884, <8 x i16> %2890, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2895 = shufflevector <8 x i16> %2848, <8 x i16> %2854, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2896 = shufflevector <8 x i16> %2860, <8 x i16> %2866, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2897 = shufflevector <8 x i16> %2872, <8 x i16> %2878, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2898 = shufflevector <8 x i16> %2884, <8 x i16> %2890, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2899 = bitcast <8 x i16> %2891 to <4 x i32>
  %2900 = bitcast <8 x i16> %2892 to <4 x i32>
  %2901 = shufflevector <4 x i32> %2899, <4 x i32> %2900, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2902 = bitcast <4 x i32> %2901 to <2 x i64>
  %2903 = bitcast <8 x i16> %2893 to <4 x i32>
  %2904 = bitcast <8 x i16> %2894 to <4 x i32>
  %2905 = shufflevector <4 x i32> %2903, <4 x i32> %2904, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2906 = bitcast <4 x i32> %2905 to <2 x i64>
  %2907 = bitcast <8 x i16> %2895 to <4 x i32>
  %2908 = bitcast <8 x i16> %2896 to <4 x i32>
  %2909 = shufflevector <4 x i32> %2907, <4 x i32> %2908, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2910 = bitcast <4 x i32> %2909 to <2 x i64>
  %2911 = bitcast <8 x i16> %2897 to <4 x i32>
  %2912 = bitcast <8 x i16> %2898 to <4 x i32>
  %2913 = shufflevector <4 x i32> %2911, <4 x i32> %2912, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %2914 = bitcast <4 x i32> %2913 to <2 x i64>
  %2915 = shufflevector <4 x i32> %2899, <4 x i32> %2900, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2916 = bitcast <4 x i32> %2915 to <2 x i64>
  %2917 = shufflevector <4 x i32> %2903, <4 x i32> %2904, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2918 = bitcast <4 x i32> %2917 to <2 x i64>
  %2919 = shufflevector <4 x i32> %2907, <4 x i32> %2908, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2920 = bitcast <4 x i32> %2919 to <2 x i64>
  %2921 = shufflevector <4 x i32> %2911, <4 x i32> %2912, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %2922 = bitcast <4 x i32> %2921 to <2 x i64>
  %2923 = shufflevector <2 x i64> %2902, <2 x i64> %2906, <2 x i32> <i32 0, i32 2>
  %2924 = shufflevector <2 x i64> %2902, <2 x i64> %2906, <2 x i32> <i32 1, i32 3>
  %2925 = shufflevector <2 x i64> %2916, <2 x i64> %2918, <2 x i32> <i32 0, i32 2>
  %2926 = shufflevector <2 x i64> %2916, <2 x i64> %2918, <2 x i32> <i32 1, i32 3>
  %2927 = shufflevector <2 x i64> %2910, <2 x i64> %2914, <2 x i32> <i32 0, i32 2>
  %2928 = shufflevector <2 x i64> %2910, <2 x i64> %2914, <2 x i32> <i32 1, i32 3>
  %2929 = shufflevector <2 x i64> %2920, <2 x i64> %2922, <2 x i32> <i32 0, i32 2>
  %2930 = shufflevector <2 x i64> %2920, <2 x i64> %2922, <2 x i32> <i32 1, i32 3>
  %2931 = bitcast <2 x i64> %2923 to <8 x i16>
  %2932 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2931, <8 x i16> undef) #11
  %2933 = bitcast <16 x i8> %2932 to <2 x i64>
  %2934 = extractelement <2 x i64> %2933, i32 0
  %2935 = bitcast i8* %2836 to i64*
  store i64 %2934, i64* %2935, align 1
  %2936 = getelementptr inbounds i8, i8* %2836, i64 %1
  %2937 = bitcast <2 x i64> %2924 to <8 x i16>
  %2938 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2937, <8 x i16> undef) #11
  %2939 = bitcast <16 x i8> %2938 to <2 x i64>
  %2940 = extractelement <2 x i64> %2939, i32 0
  %2941 = bitcast i8* %2936 to i64*
  store i64 %2940, i64* %2941, align 1
  %2942 = getelementptr inbounds i8, i8* %2936, i64 %1
  %2943 = bitcast <2 x i64> %2925 to <8 x i16>
  %2944 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2943, <8 x i16> undef) #11
  %2945 = bitcast <16 x i8> %2944 to <2 x i64>
  %2946 = extractelement <2 x i64> %2945, i32 0
  %2947 = bitcast i8* %2942 to i64*
  store i64 %2946, i64* %2947, align 1
  %2948 = getelementptr inbounds i8, i8* %2942, i64 %1
  %2949 = bitcast <2 x i64> %2926 to <8 x i16>
  %2950 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2949, <8 x i16> undef) #11
  %2951 = bitcast <16 x i8> %2950 to <2 x i64>
  %2952 = extractelement <2 x i64> %2951, i32 0
  %2953 = bitcast i8* %2948 to i64*
  store i64 %2952, i64* %2953, align 1
  %2954 = getelementptr inbounds i8, i8* %2948, i64 %1
  %2955 = bitcast <2 x i64> %2927 to <8 x i16>
  %2956 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2955, <8 x i16> undef) #11
  %2957 = bitcast <16 x i8> %2956 to <2 x i64>
  %2958 = extractelement <2 x i64> %2957, i32 0
  %2959 = bitcast i8* %2954 to i64*
  store i64 %2958, i64* %2959, align 1
  %2960 = getelementptr inbounds i8, i8* %2954, i64 %1
  %2961 = bitcast <2 x i64> %2928 to <8 x i16>
  %2962 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2961, <8 x i16> undef) #11
  %2963 = bitcast <16 x i8> %2962 to <2 x i64>
  %2964 = extractelement <2 x i64> %2963, i32 0
  %2965 = bitcast i8* %2960 to i64*
  store i64 %2964, i64* %2965, align 1
  %2966 = getelementptr inbounds i8, i8* %2960, i64 %1
  %2967 = bitcast <2 x i64> %2929 to <8 x i16>
  %2968 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2967, <8 x i16> undef) #11
  %2969 = bitcast <16 x i8> %2968 to <2 x i64>
  %2970 = extractelement <2 x i64> %2969, i32 0
  %2971 = bitcast i8* %2966 to i64*
  store i64 %2970, i64* %2971, align 1
  %2972 = getelementptr inbounds i8, i8* %2966, i64 %1
  %2973 = bitcast <2 x i64> %2930 to <8 x i16>
  %2974 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2973, <8 x i16> undef) #11
  %2975 = bitcast <16 x i8> %2974 to <2 x i64>
  %2976 = extractelement <2 x i64> %2975, i32 0
  %2977 = bitcast i8* %2972 to i64*
  store i64 %2976, i64* %2977, align 1
  %2978 = and <8 x i16> %2834, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %2979 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2978, <8 x i16> %2978) #11
  %2980 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %2979
  %2981 = shufflevector <16 x i8> %2980, <16 x i8> %2979, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %2982 = bitcast <8 x i16> %2837 to <16 x i8>
  %2983 = sub nsw i32 %2833, %6
  %2984 = ashr i32 %2983, 5
  %2985 = sext i32 %2984 to i64
  %2986 = getelementptr inbounds i8, i8* %2166, i64 %2985
  %2987 = shufflevector <16 x i8> %2981, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %2988 = bitcast i8* %2986 to <16 x i8>*
  %2989 = load <16 x i8>, <16 x i8>* %2988, align 1
  %2990 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %2989, <16 x i8> %2987) #11
  %2991 = lshr <8 x i16> %2990, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2992 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %2991, <8 x i16> zeroinitializer) #11
  %2993 = shufflevector <16 x i8> %2982, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %2994 = bitcast <16 x i8> %2993 to <8 x i16>
  %2995 = icmp sgt <8 x i16> %2994, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %2996 = load i64, i64* %2935, align 1
  %2997 = insertelement <2 x i64> undef, i64 %2996, i32 0
  %2998 = bitcast <2 x i64> %2997 to <16 x i8>
  %2999 = shufflevector <16 x i8> %2998, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3000 = zext <8 x i8> %2999 to <8 x i16>
  %3001 = select <8 x i1> %2995, <8 x i16> %3000, <8 x i16> %2992
  %3002 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3001, <8 x i16> undef) #11
  %3003 = bitcast <16 x i8> %3002 to <2 x i64>
  %3004 = extractelement <2 x i64> %3003, i32 0
  store i64 %3004, i64* %2935, align 1
  %3005 = sub nsw i32 %2983, %6
  %3006 = ashr i32 %3005, 5
  %3007 = sext i32 %3006 to i64
  %3008 = getelementptr inbounds i8, i8* %2166, i64 %3007
  %3009 = shufflevector <16 x i8> %2981, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %3010 = bitcast i8* %3008 to <16 x i8>*
  %3011 = load <16 x i8>, <16 x i8>* %3010, align 1
  %3012 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3011, <16 x i8> %3009) #11
  %3013 = lshr <8 x i16> %3012, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3014 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3013, <8 x i16> zeroinitializer) #11
  %3015 = shufflevector <16 x i8> %2982, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %3016 = bitcast <16 x i8> %3015 to <8 x i16>
  %3017 = icmp sgt <8 x i16> %3016, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3018 = load i64, i64* %2941, align 1
  %3019 = insertelement <2 x i64> undef, i64 %3018, i32 0
  %3020 = bitcast <2 x i64> %3019 to <16 x i8>
  %3021 = shufflevector <16 x i8> %3020, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3022 = zext <8 x i8> %3021 to <8 x i16>
  %3023 = select <8 x i1> %3017, <8 x i16> %3022, <8 x i16> %3014
  %3024 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3023, <8 x i16> undef) #11
  %3025 = bitcast <16 x i8> %3024 to <2 x i64>
  %3026 = extractelement <2 x i64> %3025, i32 0
  store i64 %3026, i64* %2941, align 1
  %3027 = sub nsw i32 %3005, %6
  %3028 = ashr i32 %3027, 5
  %3029 = sext i32 %3028 to i64
  %3030 = getelementptr inbounds i8, i8* %2166, i64 %3029
  %3031 = shufflevector <16 x i8> %2981, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %3032 = bitcast i8* %3030 to <16 x i8>*
  %3033 = load <16 x i8>, <16 x i8>* %3032, align 1
  %3034 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3033, <16 x i8> %3031) #11
  %3035 = lshr <8 x i16> %3034, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3036 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3035, <8 x i16> zeroinitializer) #11
  %3037 = shufflevector <16 x i8> %2982, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %3038 = bitcast <16 x i8> %3037 to <8 x i16>
  %3039 = icmp sgt <8 x i16> %3038, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3040 = load i64, i64* %2947, align 1
  %3041 = insertelement <2 x i64> undef, i64 %3040, i32 0
  %3042 = bitcast <2 x i64> %3041 to <16 x i8>
  %3043 = shufflevector <16 x i8> %3042, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3044 = zext <8 x i8> %3043 to <8 x i16>
  %3045 = select <8 x i1> %3039, <8 x i16> %3044, <8 x i16> %3036
  %3046 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3045, <8 x i16> undef) #11
  %3047 = bitcast <16 x i8> %3046 to <2 x i64>
  %3048 = extractelement <2 x i64> %3047, i32 0
  store i64 %3048, i64* %2947, align 1
  %3049 = sub nsw i32 %3027, %6
  %3050 = ashr i32 %3049, 5
  %3051 = sext i32 %3050 to i64
  %3052 = getelementptr inbounds i8, i8* %2166, i64 %3051
  %3053 = shufflevector <16 x i8> %2981, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %3054 = bitcast i8* %3052 to <16 x i8>*
  %3055 = load <16 x i8>, <16 x i8>* %3054, align 1
  %3056 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3055, <16 x i8> %3053) #11
  %3057 = lshr <8 x i16> %3056, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3058 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3057, <8 x i16> zeroinitializer) #11
  %3059 = shufflevector <16 x i8> %2982, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %3060 = bitcast <16 x i8> %3059 to <8 x i16>
  %3061 = icmp sgt <8 x i16> %3060, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3062 = load i64, i64* %2953, align 1
  %3063 = insertelement <2 x i64> undef, i64 %3062, i32 0
  %3064 = bitcast <2 x i64> %3063 to <16 x i8>
  %3065 = shufflevector <16 x i8> %3064, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3066 = zext <8 x i8> %3065 to <8 x i16>
  %3067 = select <8 x i1> %3061, <8 x i16> %3066, <8 x i16> %3058
  %3068 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3067, <8 x i16> undef) #11
  %3069 = bitcast <16 x i8> %3068 to <2 x i64>
  %3070 = extractelement <2 x i64> %3069, i32 0
  store i64 %3070, i64* %2953, align 1
  %3071 = sub nsw i32 %3049, %6
  %3072 = ashr i32 %3071, 5
  %3073 = sext i32 %3072 to i64
  %3074 = getelementptr inbounds i8, i8* %2166, i64 %3073
  %3075 = shufflevector <16 x i8> %2981, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %3076 = bitcast i8* %3074 to <16 x i8>*
  %3077 = load <16 x i8>, <16 x i8>* %3076, align 1
  %3078 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3077, <16 x i8> %3075) #11
  %3079 = lshr <8 x i16> %3078, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3080 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3079, <8 x i16> zeroinitializer) #11
  %3081 = shufflevector <16 x i8> %2982, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %3082 = bitcast <16 x i8> %3081 to <8 x i16>
  %3083 = icmp sgt <8 x i16> %3082, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3084 = load i64, i64* %2959, align 1
  %3085 = insertelement <2 x i64> undef, i64 %3084, i32 0
  %3086 = bitcast <2 x i64> %3085 to <16 x i8>
  %3087 = shufflevector <16 x i8> %3086, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3088 = zext <8 x i8> %3087 to <8 x i16>
  %3089 = select <8 x i1> %3083, <8 x i16> %3088, <8 x i16> %3080
  %3090 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3089, <8 x i16> undef) #11
  %3091 = bitcast <16 x i8> %3090 to <2 x i64>
  %3092 = extractelement <2 x i64> %3091, i32 0
  store i64 %3092, i64* %2959, align 1
  %3093 = sub nsw i32 %3071, %6
  %3094 = ashr i32 %3093, 5
  %3095 = sext i32 %3094 to i64
  %3096 = getelementptr inbounds i8, i8* %2166, i64 %3095
  %3097 = shufflevector <16 x i8> %2981, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %3098 = bitcast i8* %3096 to <16 x i8>*
  %3099 = load <16 x i8>, <16 x i8>* %3098, align 1
  %3100 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3099, <16 x i8> %3097) #11
  %3101 = lshr <8 x i16> %3100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3102 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3101, <8 x i16> zeroinitializer) #11
  %3103 = shufflevector <16 x i8> %2982, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %3104 = bitcast <16 x i8> %3103 to <8 x i16>
  %3105 = icmp sgt <8 x i16> %3104, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3106 = load i64, i64* %2965, align 1
  %3107 = insertelement <2 x i64> undef, i64 %3106, i32 0
  %3108 = bitcast <2 x i64> %3107 to <16 x i8>
  %3109 = shufflevector <16 x i8> %3108, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3110 = zext <8 x i8> %3109 to <8 x i16>
  %3111 = select <8 x i1> %3105, <8 x i16> %3110, <8 x i16> %3102
  %3112 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3111, <8 x i16> undef) #11
  %3113 = bitcast <16 x i8> %3112 to <2 x i64>
  %3114 = extractelement <2 x i64> %3113, i32 0
  store i64 %3114, i64* %2965, align 1
  %3115 = sub nsw i32 %3093, %6
  %3116 = ashr i32 %3115, 5
  %3117 = sext i32 %3116 to i64
  %3118 = getelementptr inbounds i8, i8* %2166, i64 %3117
  %3119 = shufflevector <16 x i8> %2981, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %3120 = bitcast i8* %3118 to <16 x i8>*
  %3121 = load <16 x i8>, <16 x i8>* %3120, align 1
  %3122 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3121, <16 x i8> %3119) #11
  %3123 = lshr <8 x i16> %3122, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3124 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3123, <8 x i16> zeroinitializer) #11
  %3125 = shufflevector <16 x i8> %2982, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %3126 = bitcast <16 x i8> %3125 to <8 x i16>
  %3127 = icmp sgt <8 x i16> %3126, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3128 = load i64, i64* %2971, align 1
  %3129 = insertelement <2 x i64> undef, i64 %3128, i32 0
  %3130 = bitcast <2 x i64> %3129 to <16 x i8>
  %3131 = shufflevector <16 x i8> %3130, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3132 = zext <8 x i8> %3131 to <8 x i16>
  %3133 = select <8 x i1> %3127, <8 x i16> %3132, <8 x i16> %3124
  %3134 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3133, <8 x i16> undef) #11
  %3135 = bitcast <16 x i8> %3134 to <2 x i64>
  %3136 = extractelement <2 x i64> %3135, i32 0
  store i64 %3136, i64* %2971, align 1
  %3137 = sub nsw i32 %3115, %6
  %3138 = ashr i32 %3137, 5
  %3139 = sext i32 %3138 to i64
  %3140 = getelementptr inbounds i8, i8* %2166, i64 %3139
  %3141 = shufflevector <16 x i8> %2981, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %3142 = bitcast i8* %3140 to <16 x i8>*
  %3143 = load <16 x i8>, <16 x i8>* %3142, align 1
  %3144 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3143, <16 x i8> %3141) #11
  %3145 = lshr <8 x i16> %3144, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3146 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3145, <8 x i16> zeroinitializer) #11
  %3147 = shufflevector <16 x i8> %2982, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %3148 = bitcast <16 x i8> %3147 to <8 x i16>
  %3149 = icmp sgt <8 x i16> %3148, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3150 = load i64, i64* %2977, align 1
  %3151 = insertelement <2 x i64> undef, i64 %3150, i32 0
  %3152 = bitcast <2 x i64> %3151 to <16 x i8>
  %3153 = shufflevector <16 x i8> %3152, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3154 = zext <8 x i8> %3153 to <8 x i16>
  %3155 = select <8 x i1> %3149, <8 x i16> %3154, <8 x i16> %3146
  %3156 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3155, <8 x i16> undef) #11
  %3157 = bitcast <16 x i8> %3156 to <2 x i64>
  %3158 = extractelement <2 x i64> %3157, i32 0
  store i64 %3158, i64* %2977, align 1
  %3159 = add nsw i64 %2832, 8
  %3160 = getelementptr inbounds i8, i8* %2836, i64 %2071
  %3161 = add <8 x i16> %2835, %2083
  %3162 = sub <8 x i16> %2834, %2083
  %3163 = sub nsw i32 %2833, %2080
  %3164 = icmp slt i64 %3159, %2750
  br i1 %3164, label %2831, label %2751

3165:                                             ; preds = %3165, %2757
  %3166 = phi i64 [ %2830, %2757 ], [ %3308, %3165 ]
  %3167 = phi i8* [ %2754, %2757 ], [ %3309, %3165 ]
  %3168 = trunc i64 %3166 to i32
  %3169 = add i32 %2153, %3168
  %3170 = shl i32 %3169, 1
  %3171 = sext i32 %3170 to i64
  %3172 = getelementptr inbounds i8, i8* %20, i64 %3171
  %3173 = getelementptr inbounds i8, i8* %3172, i64 %2766
  %3174 = bitcast i8* %3173 to <16 x i8>*
  %3175 = load <16 x i8>, <16 x i8>* %3174, align 1
  %3176 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3175, <16 x i8> %2765) #11
  %3177 = lshr <8 x i16> %3176, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3178 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3177, <8 x i16> zeroinitializer) #11
  %3179 = getelementptr inbounds i8, i8* %3172, i64 %2775
  %3180 = bitcast i8* %3179 to <16 x i8>*
  %3181 = load <16 x i8>, <16 x i8>* %3180, align 1
  %3182 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3181, <16 x i8> %2774) #11
  %3183 = lshr <8 x i16> %3182, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3184 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3183, <8 x i16> zeroinitializer) #11
  %3185 = getelementptr inbounds i8, i8* %3172, i64 %2784
  %3186 = bitcast i8* %3185 to <16 x i8>*
  %3187 = load <16 x i8>, <16 x i8>* %3186, align 1
  %3188 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3187, <16 x i8> %2783) #11
  %3189 = lshr <8 x i16> %3188, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3190 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3189, <8 x i16> zeroinitializer) #11
  %3191 = getelementptr inbounds i8, i8* %3172, i64 %2793
  %3192 = bitcast i8* %3191 to <16 x i8>*
  %3193 = load <16 x i8>, <16 x i8>* %3192, align 1
  %3194 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3193, <16 x i8> %2792) #11
  %3195 = lshr <8 x i16> %3194, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3196 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3195, <8 x i16> zeroinitializer) #11
  %3197 = getelementptr inbounds i8, i8* %3172, i64 %2802
  %3198 = bitcast i8* %3197 to <16 x i8>*
  %3199 = load <16 x i8>, <16 x i8>* %3198, align 1
  %3200 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3199, <16 x i8> %2801) #11
  %3201 = lshr <8 x i16> %3200, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3202 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3201, <8 x i16> zeroinitializer) #11
  %3203 = getelementptr inbounds i8, i8* %3172, i64 %2811
  %3204 = bitcast i8* %3203 to <16 x i8>*
  %3205 = load <16 x i8>, <16 x i8>* %3204, align 1
  %3206 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3205, <16 x i8> %2810) #11
  %3207 = lshr <8 x i16> %3206, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3208 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3207, <8 x i16> zeroinitializer) #11
  %3209 = getelementptr inbounds i8, i8* %3172, i64 %2820
  %3210 = bitcast i8* %3209 to <16 x i8>*
  %3211 = load <16 x i8>, <16 x i8>* %3210, align 1
  %3212 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3211, <16 x i8> %2819) #11
  %3213 = lshr <8 x i16> %3212, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3214 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3213, <8 x i16> zeroinitializer) #11
  %3215 = getelementptr inbounds i8, i8* %3172, i64 %2829
  %3216 = bitcast i8* %3215 to <16 x i8>*
  %3217 = load <16 x i8>, <16 x i8>* %3216, align 1
  %3218 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3217, <16 x i8> %2828) #11
  %3219 = lshr <8 x i16> %3218, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3220 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3219, <8 x i16> zeroinitializer) #11
  %3221 = shufflevector <8 x i16> %3178, <8 x i16> %3184, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3222 = shufflevector <8 x i16> %3190, <8 x i16> %3196, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3223 = shufflevector <8 x i16> %3202, <8 x i16> %3208, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3224 = shufflevector <8 x i16> %3214, <8 x i16> %3220, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %3225 = shufflevector <8 x i16> %3178, <8 x i16> %3184, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3226 = shufflevector <8 x i16> %3190, <8 x i16> %3196, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3227 = shufflevector <8 x i16> %3202, <8 x i16> %3208, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3228 = shufflevector <8 x i16> %3214, <8 x i16> %3220, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %3229 = bitcast <8 x i16> %3221 to <4 x i32>
  %3230 = bitcast <8 x i16> %3222 to <4 x i32>
  %3231 = shufflevector <4 x i32> %3229, <4 x i32> %3230, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3232 = bitcast <4 x i32> %3231 to <2 x i64>
  %3233 = bitcast <8 x i16> %3223 to <4 x i32>
  %3234 = bitcast <8 x i16> %3224 to <4 x i32>
  %3235 = shufflevector <4 x i32> %3233, <4 x i32> %3234, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3236 = bitcast <4 x i32> %3235 to <2 x i64>
  %3237 = bitcast <8 x i16> %3225 to <4 x i32>
  %3238 = bitcast <8 x i16> %3226 to <4 x i32>
  %3239 = shufflevector <4 x i32> %3237, <4 x i32> %3238, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3240 = bitcast <4 x i32> %3239 to <2 x i64>
  %3241 = bitcast <8 x i16> %3227 to <4 x i32>
  %3242 = bitcast <8 x i16> %3228 to <4 x i32>
  %3243 = shufflevector <4 x i32> %3241, <4 x i32> %3242, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %3244 = bitcast <4 x i32> %3243 to <2 x i64>
  %3245 = shufflevector <4 x i32> %3229, <4 x i32> %3230, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3246 = bitcast <4 x i32> %3245 to <2 x i64>
  %3247 = shufflevector <4 x i32> %3233, <4 x i32> %3234, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3248 = bitcast <4 x i32> %3247 to <2 x i64>
  %3249 = shufflevector <4 x i32> %3237, <4 x i32> %3238, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3250 = bitcast <4 x i32> %3249 to <2 x i64>
  %3251 = shufflevector <4 x i32> %3241, <4 x i32> %3242, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %3252 = bitcast <4 x i32> %3251 to <2 x i64>
  %3253 = shufflevector <2 x i64> %3232, <2 x i64> %3236, <2 x i32> <i32 0, i32 2>
  %3254 = shufflevector <2 x i64> %3232, <2 x i64> %3236, <2 x i32> <i32 1, i32 3>
  %3255 = shufflevector <2 x i64> %3246, <2 x i64> %3248, <2 x i32> <i32 0, i32 2>
  %3256 = shufflevector <2 x i64> %3246, <2 x i64> %3248, <2 x i32> <i32 1, i32 3>
  %3257 = shufflevector <2 x i64> %3240, <2 x i64> %3244, <2 x i32> <i32 0, i32 2>
  %3258 = shufflevector <2 x i64> %3240, <2 x i64> %3244, <2 x i32> <i32 1, i32 3>
  %3259 = shufflevector <2 x i64> %3250, <2 x i64> %3252, <2 x i32> <i32 0, i32 2>
  %3260 = shufflevector <2 x i64> %3250, <2 x i64> %3252, <2 x i32> <i32 1, i32 3>
  %3261 = bitcast <2 x i64> %3253 to <8 x i16>
  %3262 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3261, <8 x i16> undef) #11
  %3263 = bitcast <16 x i8> %3262 to <2 x i64>
  %3264 = extractelement <2 x i64> %3263, i32 0
  %3265 = bitcast i8* %3167 to i64*
  store i64 %3264, i64* %3265, align 1
  %3266 = getelementptr inbounds i8, i8* %3167, i64 %1
  %3267 = bitcast <2 x i64> %3254 to <8 x i16>
  %3268 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3267, <8 x i16> undef) #11
  %3269 = bitcast <16 x i8> %3268 to <2 x i64>
  %3270 = extractelement <2 x i64> %3269, i32 0
  %3271 = bitcast i8* %3266 to i64*
  store i64 %3270, i64* %3271, align 1
  %3272 = getelementptr inbounds i8, i8* %3266, i64 %1
  %3273 = bitcast <2 x i64> %3255 to <8 x i16>
  %3274 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3273, <8 x i16> undef) #11
  %3275 = bitcast <16 x i8> %3274 to <2 x i64>
  %3276 = extractelement <2 x i64> %3275, i32 0
  %3277 = bitcast i8* %3272 to i64*
  store i64 %3276, i64* %3277, align 1
  %3278 = getelementptr inbounds i8, i8* %3272, i64 %1
  %3279 = bitcast <2 x i64> %3256 to <8 x i16>
  %3280 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3279, <8 x i16> undef) #11
  %3281 = bitcast <16 x i8> %3280 to <2 x i64>
  %3282 = extractelement <2 x i64> %3281, i32 0
  %3283 = bitcast i8* %3278 to i64*
  store i64 %3282, i64* %3283, align 1
  %3284 = getelementptr inbounds i8, i8* %3278, i64 %1
  %3285 = bitcast <2 x i64> %3257 to <8 x i16>
  %3286 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3285, <8 x i16> undef) #11
  %3287 = bitcast <16 x i8> %3286 to <2 x i64>
  %3288 = extractelement <2 x i64> %3287, i32 0
  %3289 = bitcast i8* %3284 to i64*
  store i64 %3288, i64* %3289, align 1
  %3290 = getelementptr inbounds i8, i8* %3284, i64 %1
  %3291 = bitcast <2 x i64> %3258 to <8 x i16>
  %3292 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3291, <8 x i16> undef) #11
  %3293 = bitcast <16 x i8> %3292 to <2 x i64>
  %3294 = extractelement <2 x i64> %3293, i32 0
  %3295 = bitcast i8* %3290 to i64*
  store i64 %3294, i64* %3295, align 1
  %3296 = getelementptr inbounds i8, i8* %3290, i64 %1
  %3297 = bitcast <2 x i64> %3259 to <8 x i16>
  %3298 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3297, <8 x i16> undef) #11
  %3299 = bitcast <16 x i8> %3298 to <2 x i64>
  %3300 = extractelement <2 x i64> %3299, i32 0
  %3301 = bitcast i8* %3296 to i64*
  store i64 %3300, i64* %3301, align 1
  %3302 = getelementptr inbounds i8, i8* %3296, i64 %1
  %3303 = bitcast <2 x i64> %3260 to <8 x i16>
  %3304 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3303, <8 x i16> undef) #11
  %3305 = bitcast <16 x i8> %3304 to <2 x i64>
  %3306 = extractelement <2 x i64> %3305, i32 0
  %3307 = bitcast i8* %3302 to i64*
  store i64 %3306, i64* %3307, align 1
  %3308 = add nsw i64 %3166, 8
  %3309 = getelementptr inbounds i8, i8* %3167, i64 %2071
  %3310 = icmp slt i64 %3308, %2120
  br i1 %3310, label %3165, label %3311

3311:                                             ; preds = %3165, %2753
  %3312 = add <8 x i16> %2356, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %3313 = bitcast <8 x i16> %3312 to <2 x i64>
  %3314 = add <8 x i16> %2154, %2095
  %3315 = sub nsw i32 %2153, %2090
  %3316 = icmp slt i64 %2348, %2121
  br i1 %3316, label %2151, label %2122

3317:                                             ; preds = %3394, %2127
  %3318 = phi i64 [ %2141, %2127 ], [ %3395, %3394 ]
  %3319 = getelementptr inbounds i8, i8* %0, i64 %3318
  %3320 = trunc i64 %3318 to i32
  %3321 = shl i32 %3320, 1
  %3322 = sext i32 %3321 to i64
  %3323 = getelementptr inbounds i8, i8* %19, i64 %3322
  %3324 = getelementptr inbounds i8, i8* %3323, i64 %2130
  %3325 = load i8, i8* %3324, align 2
  %3326 = zext i8 %3325 to i16
  %3327 = insertelement <8 x i16> undef, i16 %3326, i32 0
  %3328 = shufflevector <8 x i16> %3327, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  br i1 %2137, label %3346, label %3329

3329:                                             ; preds = %3346, %3317
  %3330 = phi i32 [ 0, %3317 ], [ %2136, %3346 ]
  %3331 = phi i8* [ %3319, %3317 ], [ %3378, %3346 ]
  %3332 = icmp slt i32 %3330, %5
  br i1 %3332, label %3333, label %3394

3333:                                             ; preds = %3329
  %3334 = load i8, i8* %3324, align 2
  br i1 %2149, label %3343, label %3335

3335:                                             ; preds = %3333, %3335
  %3336 = phi i8* [ %3339, %3335 ], [ %3331, %3333 ]
  %3337 = phi i32 [ %3340, %3335 ], [ %3330, %3333 ]
  %3338 = phi i32 [ %3341, %3335 ], [ %2148, %3333 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3336, i8 %3334, i64 4, i1 false) #11
  %3339 = getelementptr inbounds i8, i8* %3336, i64 %1
  %3340 = add nuw nsw i32 %3337, 1
  %3341 = add i32 %3338, -1
  %3342 = icmp eq i32 %3341, 0
  br i1 %3342, label %3343, label %3335, !llvm.loop !16

3343:                                             ; preds = %3335, %3333
  %3344 = phi i8* [ %3331, %3333 ], [ %3339, %3335 ]
  %3345 = phi i32 [ %3330, %3333 ], [ %3340, %3335 ]
  br i1 %2150, label %3394, label %3381

3346:                                             ; preds = %3317, %3346
  %3347 = phi i8* [ %3378, %3346 ], [ %3319, %3317 ]
  %3348 = phi i32 [ %3377, %3346 ], [ 0, %3317 ]
  %3349 = phi i32 [ %3379, %3346 ], [ %2084, %3317 ]
  %3350 = ashr i32 %3349, 5
  %3351 = trunc i32 %3349 to i8
  %3352 = and i8 %3351, 31
  %3353 = insertelement <16 x i8> undef, i8 %3352, i32 0
  %3354 = shufflevector <16 x i8> %3353, <16 x i8> undef, <16 x i32> zeroinitializer
  %3355 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %3354
  %3356 = shufflevector <16 x i8> %3355, <16 x i8> %3354, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3357 = trunc i32 %3350 to i16
  %3358 = insertelement <8 x i16> undef, i16 %3357, i32 0
  %3359 = shufflevector <8 x i16> %3358, <8 x i16> undef, <8 x i32> zeroinitializer
  %3360 = add <8 x i16> %3359, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %3361 = sext i32 %3350 to i64
  %3362 = getelementptr inbounds i8, i8* %3323, i64 %3361
  %3363 = bitcast i8* %3362 to i64*
  %3364 = load i64, i64* %3363, align 1
  %3365 = insertelement <2 x i64> undef, i64 %3364, i32 0
  %3366 = bitcast <2 x i64> %3365 to <16 x i8>
  %3367 = shufflevector <16 x i8> %3366, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %3368 = icmp sgt <8 x i16> %3360, %2140
  %3369 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3367, <16 x i8> %3356) #11
  %3370 = lshr <8 x i16> %3369, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3371 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3370, <8 x i16> zeroinitializer) #11
  %3372 = select <8 x i1> %3368, <8 x i16> %3328, <8 x i16> %3371
  %3373 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3372, <8 x i16> undef) #11
  %3374 = bitcast <16 x i8> %3373 to <4 x i32>
  %3375 = extractelement <4 x i32> %3374, i32 0
  %3376 = bitcast i8* %3347 to i32*
  store i32 %3375, i32* %3376, align 1
  %3377 = add nuw nsw i32 %3348, 1
  %3378 = getelementptr inbounds i8, i8* %3347, i64 %1
  %3379 = sub i32 %3349, %6
  %3380 = icmp slt i32 %3377, %2136
  br i1 %3380, label %3346, label %3329

3381:                                             ; preds = %3343, %3381
  %3382 = phi i8* [ %3391, %3381 ], [ %3344, %3343 ]
  %3383 = phi i32 [ %3392, %3381 ], [ %3345, %3343 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3382, i8 %3334, i64 4, i1 false) #11
  %3384 = getelementptr inbounds i8, i8* %3382, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3384, i8 %3334, i64 4, i1 false) #11
  %3385 = getelementptr inbounds i8, i8* %3384, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3385, i8 %3334, i64 4, i1 false) #11
  %3386 = getelementptr inbounds i8, i8* %3385, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3386, i8 %3334, i64 4, i1 false) #11
  %3387 = getelementptr inbounds i8, i8* %3386, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3387, i8 %3334, i64 4, i1 false) #11
  %3388 = getelementptr inbounds i8, i8* %3387, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3388, i8 %3334, i64 4, i1 false) #11
  %3389 = getelementptr inbounds i8, i8* %3388, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3389, i8 %3334, i64 4, i1 false) #11
  %3390 = getelementptr inbounds i8, i8* %3389, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3390, i8 %3334, i64 4, i1 false) #11
  %3391 = getelementptr inbounds i8, i8* %3390, i64 %1
  %3392 = add nuw nsw i32 %3383, 8
  %3393 = icmp eq i32 %3392, %5
  br i1 %3393, label %3394, label %3381

3394:                                             ; preds = %3343, %3381, %3329
  %3395 = add nuw nsw i64 %3318, 4
  %3396 = icmp slt i64 %3395, %2142
  br i1 %3396, label %3317, label %7373

3397:                                             ; preds = %2097
  br i1 %2096, label %3398, label %3423

3398:                                             ; preds = %3397
  %3399 = sub nsw i32 0, %2076
  %3400 = trunc i32 %7 to i16
  %3401 = sub i16 0, %3400
  %3402 = insertelement <8 x i16> undef, i16 %3401, i32 0
  %3403 = shufflevector <8 x i16> %3402, <8 x i16> undef, <8 x i32> zeroinitializer
  %3404 = mul <8 x i16> %3403, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3405 = and i16 %3400, 63
  %3406 = sub nsw i16 0, %3405
  %3407 = insertelement <8 x i16> undef, i16 %3406, i32 0
  %3408 = shufflevector <8 x i16> %3407, <8 x i16> undef, <8 x i32> zeroinitializer
  %3409 = add <8 x i16> %3404, %3408
  %3410 = icmp eq i32 %6, 64
  %3411 = sub <8 x i16> <i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64>, %2088
  %3412 = bitcast <8 x i16> %3411 to <2 x i64>
  %3413 = bitcast <8 x i16> %2088 to <2 x i64>
  %3414 = xor <2 x i64> %3413, <i64 -1, i64 -1>
  %3415 = select i1 %3410, <2 x i64> %3412, <2 x i64> %3414
  %3416 = ashr i32 %2084, 6
  %3417 = icmp sgt i32 %3416, 1
  %3418 = select i1 %3417, i32 %3416, i32 1
  %3419 = sext i32 %5 to i64
  %3420 = sext i32 %2075 to i64
  br label %3449

3421:                                             ; preds = %4624
  %3422 = trunc i64 %3643 to i32
  br label %3423

3423:                                             ; preds = %3421, %3397
  %3424 = phi i32 [ 0, %3397 ], [ %3422, %3421 ]
  %3425 = icmp slt i32 %3424, %4
  br i1 %3425, label %3426, label %7373

3426:                                             ; preds = %3423
  %3427 = add nsw i32 %5, 3
  %3428 = sext i32 %3427 to i64
  %3429 = ashr i32 %2084, 6
  %3430 = icmp sgt i32 %3429, 1
  %3431 = select i1 %3430, i32 %3429, i32 1
  %3432 = sdiv i32 %3427, %3431
  %3433 = icmp sgt i32 %3432, %5
  %3434 = select i1 %3433, i32 %5, i32 %3432
  %3435 = icmp sgt i32 %3434, 0
  %3436 = trunc i32 %3427 to i16
  %3437 = insertelement <8 x i16> undef, i16 %3436, i32 0
  %3438 = shufflevector <8 x i16> %3437, <8 x i16> undef, <8 x i32> zeroinitializer
  %3439 = zext i32 %3424 to i64
  %3440 = sext i32 %4 to i64
  %3441 = icmp sgt i32 %3434, 0
  %3442 = select i1 %3441, i32 %3434, i32 0
  %3443 = sub i32 %5, %3442
  %3444 = xor i32 %3442, -1
  %3445 = add i32 %3444, %5
  %3446 = and i32 %3443, 7
  %3447 = icmp eq i32 %3446, 0
  %3448 = icmp ult i32 %3445, 7
  br label %4630

3449:                                             ; preds = %4624, %3398
  %3450 = phi i64 [ 0, %3398 ], [ %3643, %4624 ]
  %3451 = phi i32 [ %3399, %3398 ], [ %4628, %4624 ]
  %3452 = phi <8 x i16> [ %3409, %3398 ], [ %4627, %4624 ]
  %3453 = phi <2 x i64> [ %3415, %3398 ], [ %4626, %4624 ]
  %3454 = getelementptr inbounds i8, i8* %0, i64 %3450
  %3455 = trunc i64 %3450 to i32
  %3456 = shl i32 %3455, 6
  %3457 = or i32 %3456, 64
  %3458 = sdiv i32 %3457, %6
  %3459 = icmp sgt i32 %3458, %5
  %3460 = select i1 %3459, i32 %5, i32 %3458
  %3461 = and i32 %3460, -8
  %3462 = getelementptr inbounds i8, i8* %19, i64 %3450
  %3463 = or i32 %3461, 3
  %3464 = sext i32 %3463 to i64
  %3465 = getelementptr inbounds i8, i8* %3462, i64 %3464
  %3466 = load i8, i8* %3465, align 1
  %3467 = zext i8 %3466 to i16
  %3468 = insertelement <8 x i16> undef, i16 %3467, i32 0
  %3469 = shufflevector <8 x i16> %3468, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %3470 = sdiv i32 %3463, %3418
  %3471 = icmp sgt i32 %3470, %3461
  %3472 = select i1 %3471, i32 %3461, i32 %3470
  %3473 = icmp sgt i32 %3472, 0
  br i1 %3473, label %3474, label %3478

3474:                                             ; preds = %3449
  %3475 = trunc i32 %3463 to i16
  %3476 = insertelement <8 x i16> undef, i16 %3475, i32 0
  %3477 = shufflevector <8 x i16> %3476, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %3501

3478:                                             ; preds = %3501, %3449
  %3479 = phi i32 [ 0, %3449 ], [ %3472, %3501 ]
  %3480 = phi i8* [ %3454, %3449 ], [ %3534, %3501 ]
  %3481 = icmp sgt i32 %3461, %3479
  br i1 %3481, label %3482, label %3550

3482:                                             ; preds = %3478
  %3483 = load i8, i8* %3465, align 1
  %3484 = sub i32 0, %3479
  %3485 = xor i32 %3479, -1
  %3486 = add i32 %3461, %3485
  %3487 = and i32 %3484, 7
  %3488 = icmp eq i32 %3487, 0
  br i1 %3488, label %3497, label %3489

3489:                                             ; preds = %3482, %3489
  %3490 = phi i8* [ %3493, %3489 ], [ %3480, %3482 ]
  %3491 = phi i32 [ %3494, %3489 ], [ %3479, %3482 ]
  %3492 = phi i32 [ %3495, %3489 ], [ %3487, %3482 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3490, i8 %3483, i64 4, i1 false) #11
  %3493 = getelementptr inbounds i8, i8* %3490, i64 %1
  %3494 = add nuw nsw i32 %3491, 1
  %3495 = add i32 %3492, -1
  %3496 = icmp eq i32 %3495, 0
  br i1 %3496, label %3497, label %3489, !llvm.loop !17

3497:                                             ; preds = %3489, %3482
  %3498 = phi i8* [ %3480, %3482 ], [ %3493, %3489 ]
  %3499 = phi i32 [ %3479, %3482 ], [ %3494, %3489 ]
  %3500 = icmp ult i32 %3486, 7
  br i1 %3500, label %3550, label %3537

3501:                                             ; preds = %3501, %3474
  %3502 = phi i8* [ %3454, %3474 ], [ %3534, %3501 ]
  %3503 = phi i32 [ 0, %3474 ], [ %3533, %3501 ]
  %3504 = phi i32 [ %2084, %3474 ], [ %3535, %3501 ]
  %3505 = ashr i32 %3504, 6
  %3506 = lshr i32 %3504, 1
  %3507 = trunc i32 %3506 to i8
  %3508 = and i8 %3507, 31
  %3509 = insertelement <16 x i8> undef, i8 %3508, i32 0
  %3510 = shufflevector <16 x i8> %3509, <16 x i8> undef, <16 x i32> zeroinitializer
  %3511 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %3510
  %3512 = shufflevector <16 x i8> %3511, <16 x i8> %3510, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3513 = trunc i32 %3505 to i16
  %3514 = insertelement <8 x i16> undef, i16 %3513, i32 0
  %3515 = shufflevector <8 x i16> %3514, <8 x i16> undef, <8 x i32> zeroinitializer
  %3516 = add <8 x i16> %3515, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %3517 = sext i32 %3505 to i64
  %3518 = getelementptr inbounds i8, i8* %3462, i64 %3517
  %3519 = bitcast i8* %3518 to i64*
  %3520 = load i64, i64* %3519, align 1
  %3521 = insertelement <2 x i64> undef, i64 %3520, i32 0
  %3522 = bitcast <2 x i64> %3521 to <16 x i8>
  %3523 = shufflevector <16 x i8> %3522, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %3524 = icmp sgt <8 x i16> %3516, %3477
  %3525 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3523, <16 x i8> %3512) #11
  %3526 = lshr <8 x i16> %3525, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3527 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3526, <8 x i16> zeroinitializer) #11
  %3528 = select <8 x i1> %3524, <8 x i16> %3469, <8 x i16> %3527
  %3529 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3528, <8 x i16> undef) #11
  %3530 = bitcast <16 x i8> %3529 to <4 x i32>
  %3531 = extractelement <4 x i32> %3530, i32 0
  %3532 = bitcast i8* %3502 to i32*
  store i32 %3531, i32* %3532, align 1
  %3533 = add nuw nsw i32 %3503, 1
  %3534 = getelementptr inbounds i8, i8* %3502, i64 %1
  %3535 = sub i32 %3504, %6
  %3536 = icmp slt i32 %3533, %3472
  br i1 %3536, label %3501, label %3478

3537:                                             ; preds = %3497, %3537
  %3538 = phi i8* [ %3547, %3537 ], [ %3498, %3497 ]
  %3539 = phi i32 [ %3548, %3537 ], [ %3499, %3497 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3538, i8 %3483, i64 4, i1 false) #11
  %3540 = getelementptr inbounds i8, i8* %3538, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3540, i8 %3483, i64 4, i1 false) #11
  %3541 = getelementptr inbounds i8, i8* %3540, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3541, i8 %3483, i64 4, i1 false) #11
  %3542 = getelementptr inbounds i8, i8* %3541, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3542, i8 %3483, i64 4, i1 false) #11
  %3543 = getelementptr inbounds i8, i8* %3542, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3543, i8 %3483, i64 4, i1 false) #11
  %3544 = getelementptr inbounds i8, i8* %3543, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3544, i8 %3483, i64 4, i1 false) #11
  %3545 = getelementptr inbounds i8, i8* %3544, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3545, i8 %3483, i64 4, i1 false) #11
  %3546 = getelementptr inbounds i8, i8* %3545, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3546, i8 %3483, i64 4, i1 false) #11
  %3547 = getelementptr inbounds i8, i8* %3546, i64 %1
  %3548 = add nuw nsw i32 %3539, 8
  %3549 = icmp eq i32 %3548, %3461
  br i1 %3549, label %3550, label %3537

3550:                                             ; preds = %3497, %3537, %3478
  %3551 = getelementptr inbounds i8, i8* %3454, i64 4
  %3552 = or i64 %3450, 4
  %3553 = getelementptr inbounds i8, i8* %19, i64 %3552
  %3554 = getelementptr inbounds i8, i8* %3553, i64 %3464
  %3555 = load i8, i8* %3554, align 1
  %3556 = zext i8 %3555 to i16
  %3557 = insertelement <8 x i16> undef, i16 %3556, i32 0
  %3558 = shufflevector <8 x i16> %3557, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  br i1 %3473, label %3559, label %3563

3559:                                             ; preds = %3550
  %3560 = trunc i32 %3463 to i16
  %3561 = insertelement <8 x i16> undef, i16 %3560, i32 0
  %3562 = shufflevector <8 x i16> %3561, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %3586

3563:                                             ; preds = %3586, %3550
  %3564 = phi i32 [ 0, %3550 ], [ %3472, %3586 ]
  %3565 = phi i8* [ %3551, %3550 ], [ %3619, %3586 ]
  %3566 = icmp sgt i32 %3461, %3564
  br i1 %3566, label %3567, label %3635

3567:                                             ; preds = %3563
  %3568 = load i8, i8* %3554, align 1
  %3569 = sub i32 0, %3564
  %3570 = xor i32 %3564, -1
  %3571 = add i32 %3461, %3570
  %3572 = and i32 %3569, 7
  %3573 = icmp eq i32 %3572, 0
  br i1 %3573, label %3582, label %3574

3574:                                             ; preds = %3567, %3574
  %3575 = phi i8* [ %3578, %3574 ], [ %3565, %3567 ]
  %3576 = phi i32 [ %3579, %3574 ], [ %3564, %3567 ]
  %3577 = phi i32 [ %3580, %3574 ], [ %3572, %3567 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3575, i8 %3568, i64 4, i1 false) #11
  %3578 = getelementptr inbounds i8, i8* %3575, i64 %1
  %3579 = add nuw nsw i32 %3576, 1
  %3580 = add i32 %3577, -1
  %3581 = icmp eq i32 %3580, 0
  br i1 %3581, label %3582, label %3574, !llvm.loop !18

3582:                                             ; preds = %3574, %3567
  %3583 = phi i8* [ %3565, %3567 ], [ %3578, %3574 ]
  %3584 = phi i32 [ %3564, %3567 ], [ %3579, %3574 ]
  %3585 = icmp ult i32 %3571, 7
  br i1 %3585, label %3635, label %3622

3586:                                             ; preds = %3586, %3559
  %3587 = phi i8* [ %3551, %3559 ], [ %3619, %3586 ]
  %3588 = phi i32 [ 0, %3559 ], [ %3618, %3586 ]
  %3589 = phi i32 [ %2084, %3559 ], [ %3620, %3586 ]
  %3590 = ashr i32 %3589, 6
  %3591 = lshr i32 %3589, 1
  %3592 = trunc i32 %3591 to i8
  %3593 = and i8 %3592, 31
  %3594 = insertelement <16 x i8> undef, i8 %3593, i32 0
  %3595 = shufflevector <16 x i8> %3594, <16 x i8> undef, <16 x i32> zeroinitializer
  %3596 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %3595
  %3597 = shufflevector <16 x i8> %3596, <16 x i8> %3595, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3598 = trunc i32 %3590 to i16
  %3599 = insertelement <8 x i16> undef, i16 %3598, i32 0
  %3600 = shufflevector <8 x i16> %3599, <8 x i16> undef, <8 x i32> zeroinitializer
  %3601 = add <8 x i16> %3600, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %3602 = sext i32 %3590 to i64
  %3603 = getelementptr inbounds i8, i8* %3553, i64 %3602
  %3604 = bitcast i8* %3603 to i64*
  %3605 = load i64, i64* %3604, align 1
  %3606 = insertelement <2 x i64> undef, i64 %3605, i32 0
  %3607 = bitcast <2 x i64> %3606 to <16 x i8>
  %3608 = shufflevector <16 x i8> %3607, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %3609 = icmp sgt <8 x i16> %3601, %3562
  %3610 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3608, <16 x i8> %3597) #11
  %3611 = lshr <8 x i16> %3610, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3612 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3611, <8 x i16> zeroinitializer) #11
  %3613 = select <8 x i1> %3609, <8 x i16> %3558, <8 x i16> %3612
  %3614 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3613, <8 x i16> undef) #11
  %3615 = bitcast <16 x i8> %3614 to <4 x i32>
  %3616 = extractelement <4 x i32> %3615, i32 0
  %3617 = bitcast i8* %3587 to i32*
  store i32 %3616, i32* %3617, align 1
  %3618 = add nuw nsw i32 %3588, 1
  %3619 = getelementptr inbounds i8, i8* %3587, i64 %1
  %3620 = sub i32 %3589, %6
  %3621 = icmp slt i32 %3618, %3472
  br i1 %3621, label %3586, label %3563

3622:                                             ; preds = %3582, %3622
  %3623 = phi i8* [ %3632, %3622 ], [ %3583, %3582 ]
  %3624 = phi i32 [ %3633, %3622 ], [ %3584, %3582 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3623, i8 %3568, i64 4, i1 false) #11
  %3625 = getelementptr inbounds i8, i8* %3623, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3625, i8 %3568, i64 4, i1 false) #11
  %3626 = getelementptr inbounds i8, i8* %3625, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3626, i8 %3568, i64 4, i1 false) #11
  %3627 = getelementptr inbounds i8, i8* %3626, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3627, i8 %3568, i64 4, i1 false) #11
  %3628 = getelementptr inbounds i8, i8* %3627, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3628, i8 %3568, i64 4, i1 false) #11
  %3629 = getelementptr inbounds i8, i8* %3628, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3629, i8 %3568, i64 4, i1 false) #11
  %3630 = getelementptr inbounds i8, i8* %3629, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3630, i8 %3568, i64 4, i1 false) #11
  %3631 = getelementptr inbounds i8, i8* %3630, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %3631, i8 %3568, i64 4, i1 false) #11
  %3632 = getelementptr inbounds i8, i8* %3631, i64 %1
  %3633 = add nuw nsw i32 %3624, 8
  %3634 = icmp eq i32 %3633, %3461
  br i1 %3634, label %3635, label %3622

3635:                                             ; preds = %3582, %3622, %3563
  %3636 = sext i32 %3461 to i64
  %3637 = mul nsw i64 %3636, %1
  %3638 = getelementptr inbounds i8, i8* %3454, i64 %3637
  %3639 = mul nsw i32 %3461, %6
  %3640 = trunc i32 %3639 to i16
  %3641 = insertelement <8 x i16> undef, i16 %3640, i32 0
  %3642 = shufflevector <8 x i16> %3641, <8 x i16> undef, <8 x i32> zeroinitializer
  %3643 = add nuw nsw i64 %3450, 8
  %3644 = trunc i64 %3643 to i32
  %3645 = shl i32 %3644, 6
  %3646 = sdiv i32 %3645, %6
  %3647 = icmp sgt i32 %3646, %5
  %3648 = select i1 %3647, i32 %5, i32 %3646
  %3649 = icmp slt i32 %3648, %2079
  %3650 = select i1 %3649, i32 %3648, i32 %2079
  %3651 = bitcast <2 x i64> %3453 to <8 x i16>
  %3652 = add <8 x i16> %3642, %3651
  %3653 = sub <8 x i16> %2088, %3642
  %3654 = sub nsw i32 0, %3639
  %3655 = icmp slt i32 %3461, %3650
  br i1 %3655, label %3656, label %3972

3656:                                             ; preds = %3635
  %3657 = ashr <8 x i16> %3452, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %3658 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %3657, <8 x i16> %3657) #11
  %3659 = add <16 x i8> %3658, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %3660 = shufflevector <16 x i8> %3658, <16 x i8> %3659, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3661 = add <16 x i8> %3660, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %3662 = and <8 x i16> %3452, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %3663 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3662, <8 x i16> %3662) #11
  %3664 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %3663
  %3665 = shufflevector <16 x i8> %3664, <16 x i8> %3663, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3666 = sext i32 %3650 to i64
  br label %3667

3667:                                             ; preds = %3667, %3656
  %3668 = phi i64 [ %3636, %3656 ], [ %3964, %3667 ]
  %3669 = phi i32 [ %3654, %3656 ], [ %3968, %3667 ]
  %3670 = phi <8 x i16> [ %3653, %3656 ], [ %3967, %3667 ]
  %3671 = phi <8 x i16> [ %3652, %3656 ], [ %3966, %3667 ]
  %3672 = phi i8* [ %3638, %3656 ], [ %3965, %3667 ]
  %3673 = trunc i64 %3668 to i32
  %3674 = add i32 %3451, %3673
  %3675 = shl i32 %3674, 1
  %3676 = sext i32 %3675 to i64
  %3677 = getelementptr inbounds i8, i8* %20, i64 %3676
  %3678 = getelementptr inbounds i8, i8* %3677, i64 -15
  %3679 = bitcast i8* %3678 to <16 x i8>*
  %3680 = load <16 x i8>, <16 x i8>* %3679, align 1
  %3681 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3680, <16 x i8> %3661) #11
  %3682 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3681, <16 x i8> %3665) #11
  %3683 = lshr <8 x i16> %3682, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3684 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3683, <8 x i16> zeroinitializer) #11
  %3685 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3684, <8 x i16> undef) #11
  %3686 = bitcast <16 x i8> %3685 to <2 x i64>
  %3687 = extractelement <2 x i64> %3686, i32 0
  %3688 = bitcast i8* %3672 to i64*
  store i64 %3687, i64* %3688, align 1
  %3689 = getelementptr inbounds i8, i8* %3672, i64 %1
  %3690 = getelementptr inbounds i8, i8* %3677, i64 -13
  %3691 = bitcast i8* %3690 to <16 x i8>*
  %3692 = load <16 x i8>, <16 x i8>* %3691, align 1
  %3693 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3692, <16 x i8> %3661) #11
  %3694 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3693, <16 x i8> %3665) #11
  %3695 = lshr <8 x i16> %3694, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3696 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3695, <8 x i16> zeroinitializer) #11
  %3697 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3696, <8 x i16> undef) #11
  %3698 = bitcast <16 x i8> %3697 to <2 x i64>
  %3699 = extractelement <2 x i64> %3698, i32 0
  %3700 = bitcast i8* %3689 to i64*
  store i64 %3699, i64* %3700, align 1
  %3701 = getelementptr inbounds i8, i8* %3689, i64 %1
  %3702 = getelementptr inbounds i8, i8* %3677, i64 -11
  %3703 = bitcast i8* %3702 to <16 x i8>*
  %3704 = load <16 x i8>, <16 x i8>* %3703, align 1
  %3705 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3704, <16 x i8> %3661) #11
  %3706 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3705, <16 x i8> %3665) #11
  %3707 = lshr <8 x i16> %3706, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3708 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3707, <8 x i16> zeroinitializer) #11
  %3709 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3708, <8 x i16> undef) #11
  %3710 = bitcast <16 x i8> %3709 to <2 x i64>
  %3711 = extractelement <2 x i64> %3710, i32 0
  %3712 = bitcast i8* %3701 to i64*
  store i64 %3711, i64* %3712, align 1
  %3713 = getelementptr inbounds i8, i8* %3701, i64 %1
  %3714 = getelementptr inbounds i8, i8* %3677, i64 -9
  %3715 = bitcast i8* %3714 to <16 x i8>*
  %3716 = load <16 x i8>, <16 x i8>* %3715, align 1
  %3717 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3716, <16 x i8> %3661) #11
  %3718 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3717, <16 x i8> %3665) #11
  %3719 = lshr <8 x i16> %3718, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3720 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3719, <8 x i16> zeroinitializer) #11
  %3721 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3720, <8 x i16> undef) #11
  %3722 = bitcast <16 x i8> %3721 to <2 x i64>
  %3723 = extractelement <2 x i64> %3722, i32 0
  %3724 = bitcast i8* %3713 to i64*
  store i64 %3723, i64* %3724, align 1
  %3725 = getelementptr inbounds i8, i8* %3713, i64 %1
  %3726 = getelementptr inbounds i8, i8* %3677, i64 -7
  %3727 = bitcast i8* %3726 to <16 x i8>*
  %3728 = load <16 x i8>, <16 x i8>* %3727, align 1
  %3729 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3728, <16 x i8> %3661) #11
  %3730 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3729, <16 x i8> %3665) #11
  %3731 = lshr <8 x i16> %3730, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3732 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3731, <8 x i16> zeroinitializer) #11
  %3733 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3732, <8 x i16> undef) #11
  %3734 = bitcast <16 x i8> %3733 to <2 x i64>
  %3735 = extractelement <2 x i64> %3734, i32 0
  %3736 = bitcast i8* %3725 to i64*
  store i64 %3735, i64* %3736, align 1
  %3737 = getelementptr inbounds i8, i8* %3725, i64 %1
  %3738 = getelementptr inbounds i8, i8* %3677, i64 -5
  %3739 = bitcast i8* %3738 to <16 x i8>*
  %3740 = load <16 x i8>, <16 x i8>* %3739, align 1
  %3741 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3740, <16 x i8> %3661) #11
  %3742 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3741, <16 x i8> %3665) #11
  %3743 = lshr <8 x i16> %3742, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3744 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3743, <8 x i16> zeroinitializer) #11
  %3745 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3744, <8 x i16> undef) #11
  %3746 = bitcast <16 x i8> %3745 to <2 x i64>
  %3747 = extractelement <2 x i64> %3746, i32 0
  %3748 = bitcast i8* %3737 to i64*
  store i64 %3747, i64* %3748, align 1
  %3749 = getelementptr inbounds i8, i8* %3737, i64 %1
  %3750 = getelementptr inbounds i8, i8* %3677, i64 -3
  %3751 = bitcast i8* %3750 to <16 x i8>*
  %3752 = load <16 x i8>, <16 x i8>* %3751, align 1
  %3753 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3752, <16 x i8> %3661) #11
  %3754 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3753, <16 x i8> %3665) #11
  %3755 = lshr <8 x i16> %3754, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3756 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3755, <8 x i16> zeroinitializer) #11
  %3757 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3756, <8 x i16> undef) #11
  %3758 = bitcast <16 x i8> %3757 to <2 x i64>
  %3759 = extractelement <2 x i64> %3758, i32 0
  %3760 = bitcast i8* %3749 to i64*
  store i64 %3759, i64* %3760, align 1
  %3761 = getelementptr inbounds i8, i8* %3749, i64 %1
  %3762 = getelementptr inbounds i8, i8* %3677, i64 -1
  %3763 = bitcast i8* %3762 to <16 x i8>*
  %3764 = load <16 x i8>, <16 x i8>* %3763, align 1
  %3765 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %3764, <16 x i8> %3661) #11
  %3766 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3765, <16 x i8> %3665) #11
  %3767 = lshr <8 x i16> %3766, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3768 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3767, <8 x i16> zeroinitializer) #11
  %3769 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3768, <8 x i16> undef) #11
  %3770 = bitcast <16 x i8> %3769 to <2 x i64>
  %3771 = extractelement <2 x i64> %3770, i32 0
  %3772 = bitcast i8* %3761 to i64*
  store i64 %3771, i64* %3772, align 1
  %3773 = lshr <8 x i16> %3670, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %3774 = and <8 x i16> %3773, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %3775 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3774, <8 x i16> %3774) #11
  %3776 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %3775
  %3777 = shufflevector <16 x i8> %3776, <16 x i8> %3775, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3778 = ashr <8 x i16> %3671, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %3779 = bitcast <8 x i16> %3778 to <16 x i8>
  %3780 = sub nsw i32 %3669, %6
  %3781 = ashr i32 %3780, 6
  %3782 = sext i32 %3781 to i64
  %3783 = getelementptr inbounds i8, i8* %3462, i64 %3782
  %3784 = shufflevector <16 x i8> %3777, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %3785 = bitcast i8* %3783 to <16 x i8>*
  %3786 = load <16 x i8>, <16 x i8>* %3785, align 1
  %3787 = shufflevector <16 x i8> %3786, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %3788 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3787, <16 x i8> %3784) #11
  %3789 = lshr <8 x i16> %3788, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3790 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3789, <8 x i16> zeroinitializer) #11
  %3791 = shufflevector <16 x i8> %3779, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %3792 = bitcast <16 x i8> %3791 to <8 x i16>
  %3793 = icmp sgt <8 x i16> %3792, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3794 = load i64, i64* %3688, align 1
  %3795 = insertelement <2 x i64> undef, i64 %3794, i32 0
  %3796 = bitcast <2 x i64> %3795 to <16 x i8>
  %3797 = shufflevector <16 x i8> %3796, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3798 = zext <8 x i8> %3797 to <8 x i16>
  %3799 = select <8 x i1> %3793, <8 x i16> %3798, <8 x i16> %3790
  %3800 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3799, <8 x i16> undef) #11
  %3801 = bitcast <16 x i8> %3800 to <2 x i64>
  %3802 = extractelement <2 x i64> %3801, i32 0
  store i64 %3802, i64* %3688, align 1
  %3803 = sub nsw i32 %3780, %6
  %3804 = ashr i32 %3803, 6
  %3805 = sext i32 %3804 to i64
  %3806 = getelementptr inbounds i8, i8* %3462, i64 %3805
  %3807 = shufflevector <16 x i8> %3777, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %3808 = bitcast i8* %3806 to <16 x i8>*
  %3809 = load <16 x i8>, <16 x i8>* %3808, align 1
  %3810 = shufflevector <16 x i8> %3809, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %3811 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3810, <16 x i8> %3807) #11
  %3812 = lshr <8 x i16> %3811, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3813 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3812, <8 x i16> zeroinitializer) #11
  %3814 = shufflevector <16 x i8> %3779, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %3815 = bitcast <16 x i8> %3814 to <8 x i16>
  %3816 = icmp sgt <8 x i16> %3815, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3817 = load i64, i64* %3700, align 1
  %3818 = insertelement <2 x i64> undef, i64 %3817, i32 0
  %3819 = bitcast <2 x i64> %3818 to <16 x i8>
  %3820 = shufflevector <16 x i8> %3819, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3821 = zext <8 x i8> %3820 to <8 x i16>
  %3822 = select <8 x i1> %3816, <8 x i16> %3821, <8 x i16> %3813
  %3823 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3822, <8 x i16> undef) #11
  %3824 = bitcast <16 x i8> %3823 to <2 x i64>
  %3825 = extractelement <2 x i64> %3824, i32 0
  store i64 %3825, i64* %3700, align 1
  %3826 = sub nsw i32 %3803, %6
  %3827 = ashr i32 %3826, 6
  %3828 = sext i32 %3827 to i64
  %3829 = getelementptr inbounds i8, i8* %3462, i64 %3828
  %3830 = shufflevector <16 x i8> %3777, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %3831 = bitcast i8* %3829 to <16 x i8>*
  %3832 = load <16 x i8>, <16 x i8>* %3831, align 1
  %3833 = shufflevector <16 x i8> %3832, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %3834 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3833, <16 x i8> %3830) #11
  %3835 = lshr <8 x i16> %3834, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3836 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3835, <8 x i16> zeroinitializer) #11
  %3837 = shufflevector <16 x i8> %3779, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %3838 = bitcast <16 x i8> %3837 to <8 x i16>
  %3839 = icmp sgt <8 x i16> %3838, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3840 = load i64, i64* %3712, align 1
  %3841 = insertelement <2 x i64> undef, i64 %3840, i32 0
  %3842 = bitcast <2 x i64> %3841 to <16 x i8>
  %3843 = shufflevector <16 x i8> %3842, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3844 = zext <8 x i8> %3843 to <8 x i16>
  %3845 = select <8 x i1> %3839, <8 x i16> %3844, <8 x i16> %3836
  %3846 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3845, <8 x i16> undef) #11
  %3847 = bitcast <16 x i8> %3846 to <2 x i64>
  %3848 = extractelement <2 x i64> %3847, i32 0
  store i64 %3848, i64* %3712, align 1
  %3849 = sub nsw i32 %3826, %6
  %3850 = ashr i32 %3849, 6
  %3851 = sext i32 %3850 to i64
  %3852 = getelementptr inbounds i8, i8* %3462, i64 %3851
  %3853 = shufflevector <16 x i8> %3777, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %3854 = bitcast i8* %3852 to <16 x i8>*
  %3855 = load <16 x i8>, <16 x i8>* %3854, align 1
  %3856 = shufflevector <16 x i8> %3855, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %3857 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3856, <16 x i8> %3853) #11
  %3858 = lshr <8 x i16> %3857, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3859 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3858, <8 x i16> zeroinitializer) #11
  %3860 = shufflevector <16 x i8> %3779, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %3861 = bitcast <16 x i8> %3860 to <8 x i16>
  %3862 = icmp sgt <8 x i16> %3861, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3863 = load i64, i64* %3724, align 1
  %3864 = insertelement <2 x i64> undef, i64 %3863, i32 0
  %3865 = bitcast <2 x i64> %3864 to <16 x i8>
  %3866 = shufflevector <16 x i8> %3865, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3867 = zext <8 x i8> %3866 to <8 x i16>
  %3868 = select <8 x i1> %3862, <8 x i16> %3867, <8 x i16> %3859
  %3869 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3868, <8 x i16> undef) #11
  %3870 = bitcast <16 x i8> %3869 to <2 x i64>
  %3871 = extractelement <2 x i64> %3870, i32 0
  store i64 %3871, i64* %3724, align 1
  %3872 = sub nsw i32 %3849, %6
  %3873 = ashr i32 %3872, 6
  %3874 = sext i32 %3873 to i64
  %3875 = getelementptr inbounds i8, i8* %3462, i64 %3874
  %3876 = shufflevector <16 x i8> %3777, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %3877 = bitcast i8* %3875 to <16 x i8>*
  %3878 = load <16 x i8>, <16 x i8>* %3877, align 1
  %3879 = shufflevector <16 x i8> %3878, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %3880 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3879, <16 x i8> %3876) #11
  %3881 = lshr <8 x i16> %3880, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3882 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3881, <8 x i16> zeroinitializer) #11
  %3883 = shufflevector <16 x i8> %3779, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %3884 = bitcast <16 x i8> %3883 to <8 x i16>
  %3885 = icmp sgt <8 x i16> %3884, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3886 = load i64, i64* %3736, align 1
  %3887 = insertelement <2 x i64> undef, i64 %3886, i32 0
  %3888 = bitcast <2 x i64> %3887 to <16 x i8>
  %3889 = shufflevector <16 x i8> %3888, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3890 = zext <8 x i8> %3889 to <8 x i16>
  %3891 = select <8 x i1> %3885, <8 x i16> %3890, <8 x i16> %3882
  %3892 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3891, <8 x i16> undef) #11
  %3893 = bitcast <16 x i8> %3892 to <2 x i64>
  %3894 = extractelement <2 x i64> %3893, i32 0
  store i64 %3894, i64* %3736, align 1
  %3895 = sub nsw i32 %3872, %6
  %3896 = ashr i32 %3895, 6
  %3897 = sext i32 %3896 to i64
  %3898 = getelementptr inbounds i8, i8* %3462, i64 %3897
  %3899 = shufflevector <16 x i8> %3777, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %3900 = bitcast i8* %3898 to <16 x i8>*
  %3901 = load <16 x i8>, <16 x i8>* %3900, align 1
  %3902 = shufflevector <16 x i8> %3901, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %3903 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3902, <16 x i8> %3899) #11
  %3904 = lshr <8 x i16> %3903, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3905 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3904, <8 x i16> zeroinitializer) #11
  %3906 = shufflevector <16 x i8> %3779, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %3907 = bitcast <16 x i8> %3906 to <8 x i16>
  %3908 = icmp sgt <8 x i16> %3907, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3909 = load i64, i64* %3748, align 1
  %3910 = insertelement <2 x i64> undef, i64 %3909, i32 0
  %3911 = bitcast <2 x i64> %3910 to <16 x i8>
  %3912 = shufflevector <16 x i8> %3911, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3913 = zext <8 x i8> %3912 to <8 x i16>
  %3914 = select <8 x i1> %3908, <8 x i16> %3913, <8 x i16> %3905
  %3915 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3914, <8 x i16> undef) #11
  %3916 = bitcast <16 x i8> %3915 to <2 x i64>
  %3917 = extractelement <2 x i64> %3916, i32 0
  store i64 %3917, i64* %3748, align 1
  %3918 = sub nsw i32 %3895, %6
  %3919 = ashr i32 %3918, 6
  %3920 = sext i32 %3919 to i64
  %3921 = getelementptr inbounds i8, i8* %3462, i64 %3920
  %3922 = shufflevector <16 x i8> %3777, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %3923 = bitcast i8* %3921 to <16 x i8>*
  %3924 = load <16 x i8>, <16 x i8>* %3923, align 1
  %3925 = shufflevector <16 x i8> %3924, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %3926 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3925, <16 x i8> %3922) #11
  %3927 = lshr <8 x i16> %3926, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3928 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3927, <8 x i16> zeroinitializer) #11
  %3929 = shufflevector <16 x i8> %3779, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %3930 = bitcast <16 x i8> %3929 to <8 x i16>
  %3931 = icmp sgt <8 x i16> %3930, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3932 = load i64, i64* %3760, align 1
  %3933 = insertelement <2 x i64> undef, i64 %3932, i32 0
  %3934 = bitcast <2 x i64> %3933 to <16 x i8>
  %3935 = shufflevector <16 x i8> %3934, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3936 = zext <8 x i8> %3935 to <8 x i16>
  %3937 = select <8 x i1> %3931, <8 x i16> %3936, <8 x i16> %3928
  %3938 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3937, <8 x i16> undef) #11
  %3939 = bitcast <16 x i8> %3938 to <2 x i64>
  %3940 = extractelement <2 x i64> %3939, i32 0
  store i64 %3940, i64* %3760, align 1
  %3941 = sub nsw i32 %3918, %6
  %3942 = ashr i32 %3941, 6
  %3943 = sext i32 %3942 to i64
  %3944 = getelementptr inbounds i8, i8* %3462, i64 %3943
  %3945 = shufflevector <16 x i8> %3777, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %3946 = bitcast i8* %3944 to <16 x i8>*
  %3947 = load <16 x i8>, <16 x i8>* %3946, align 1
  %3948 = shufflevector <16 x i8> %3947, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %3949 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %3948, <16 x i8> %3945) #11
  %3950 = lshr <8 x i16> %3949, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %3951 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %3950, <8 x i16> zeroinitializer) #11
  %3952 = shufflevector <16 x i8> %3779, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %3953 = bitcast <16 x i8> %3952 to <8 x i16>
  %3954 = icmp sgt <8 x i16> %3953, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %3955 = load i64, i64* %3772, align 1
  %3956 = insertelement <2 x i64> undef, i64 %3955, i32 0
  %3957 = bitcast <2 x i64> %3956 to <16 x i8>
  %3958 = shufflevector <16 x i8> %3957, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %3959 = zext <8 x i8> %3958 to <8 x i16>
  %3960 = select <8 x i1> %3954, <8 x i16> %3959, <8 x i16> %3951
  %3961 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %3960, <8 x i16> undef) #11
  %3962 = bitcast <16 x i8> %3961 to <2 x i64>
  %3963 = extractelement <2 x i64> %3962, i32 0
  store i64 %3963, i64* %3772, align 1
  %3964 = add nsw i64 %3668, 8
  %3965 = getelementptr inbounds i8, i8* %3672, i64 %2071
  %3966 = add <8 x i16> %3671, %2083
  %3967 = sub <8 x i16> %3670, %2083
  %3968 = sub nsw i32 %3669, %2080
  %3969 = icmp slt i64 %3964, %3666
  br i1 %3969, label %3667, label %3970

3970:                                             ; preds = %3667
  %3971 = trunc i64 %3964 to i32
  br label %3972

3972:                                             ; preds = %3970, %3635
  %3973 = phi i8* [ %3638, %3635 ], [ %3965, %3970 ]
  %3974 = phi i32 [ %3461, %3635 ], [ %3971, %3970 ]
  %3975 = phi <8 x i16> [ %3652, %3635 ], [ %3966, %3970 ]
  %3976 = phi <8 x i16> [ %3653, %3635 ], [ %3967, %3970 ]
  %3977 = phi i32 [ %3654, %3635 ], [ %3968, %3970 ]
  %3978 = extractelement <8 x i16> %3452, i64 0
  %3979 = icmp slt i32 %3974, %3648
  br i1 %3979, label %3980, label %4057

3980:                                             ; preds = %3972
  %3981 = sext i16 %3978 to i32
  %3982 = ashr i32 %3981, 5
  %3983 = trunc i16 %3978 to i8
  %3984 = and i8 %3983, 31
  %3985 = insertelement <16 x i8> undef, i8 %3984, i32 0
  %3986 = shufflevector <16 x i8> %3985, <16 x i8> undef, <16 x i32> zeroinitializer
  %3987 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %3986
  %3988 = shufflevector <16 x i8> %3987, <16 x i8> %3986, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3989 = sext i32 %3982 to i64
  %3990 = sub i32 %3981, %7
  %3991 = ashr i32 %3990, 5
  %3992 = trunc i32 %3990 to i8
  %3993 = and i8 %3992, 31
  %3994 = insertelement <16 x i8> undef, i8 %3993, i32 0
  %3995 = shufflevector <16 x i8> %3994, <16 x i8> undef, <16 x i32> zeroinitializer
  %3996 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %3995
  %3997 = shufflevector <16 x i8> %3996, <16 x i8> %3995, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %3998 = sext i32 %3991 to i64
  %3999 = sub i32 %3990, %7
  %4000 = ashr i32 %3999, 5
  %4001 = trunc i32 %3999 to i8
  %4002 = and i8 %4001, 31
  %4003 = insertelement <16 x i8> undef, i8 %4002, i32 0
  %4004 = shufflevector <16 x i8> %4003, <16 x i8> undef, <16 x i32> zeroinitializer
  %4005 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4004
  %4006 = shufflevector <16 x i8> %4005, <16 x i8> %4004, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4007 = sext i32 %4000 to i64
  %4008 = sub i32 %3999, %7
  %4009 = ashr i32 %4008, 5
  %4010 = trunc i32 %4008 to i8
  %4011 = and i8 %4010, 31
  %4012 = insertelement <16 x i8> undef, i8 %4011, i32 0
  %4013 = shufflevector <16 x i8> %4012, <16 x i8> undef, <16 x i32> zeroinitializer
  %4014 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4013
  %4015 = shufflevector <16 x i8> %4014, <16 x i8> %4013, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4016 = sext i32 %4009 to i64
  %4017 = sub i32 %4008, %7
  %4018 = ashr i32 %4017, 5
  %4019 = trunc i32 %4017 to i8
  %4020 = and i8 %4019, 31
  %4021 = insertelement <16 x i8> undef, i8 %4020, i32 0
  %4022 = shufflevector <16 x i8> %4021, <16 x i8> undef, <16 x i32> zeroinitializer
  %4023 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4022
  %4024 = shufflevector <16 x i8> %4023, <16 x i8> %4022, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4025 = sext i32 %4018 to i64
  %4026 = sub i32 %4017, %7
  %4027 = ashr i32 %4026, 5
  %4028 = trunc i32 %4026 to i8
  %4029 = and i8 %4028, 31
  %4030 = insertelement <16 x i8> undef, i8 %4029, i32 0
  %4031 = shufflevector <16 x i8> %4030, <16 x i8> undef, <16 x i32> zeroinitializer
  %4032 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4031
  %4033 = shufflevector <16 x i8> %4032, <16 x i8> %4031, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4034 = sext i32 %4027 to i64
  %4035 = sub i32 %4026, %7
  %4036 = ashr i32 %4035, 5
  %4037 = trunc i32 %4035 to i8
  %4038 = and i8 %4037, 31
  %4039 = insertelement <16 x i8> undef, i8 %4038, i32 0
  %4040 = shufflevector <16 x i8> %4039, <16 x i8> undef, <16 x i32> zeroinitializer
  %4041 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4040
  %4042 = shufflevector <16 x i8> %4041, <16 x i8> %4040, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4043 = sext i32 %4036 to i64
  %4044 = sub i32 %4035, %7
  %4045 = ashr i32 %4044, 5
  %4046 = trunc i32 %4044 to i8
  %4047 = and i8 %4046, 31
  %4048 = insertelement <16 x i8> undef, i8 %4047, i32 0
  %4049 = shufflevector <16 x i8> %4048, <16 x i8> undef, <16 x i32> zeroinitializer
  %4050 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4049
  %4051 = shufflevector <16 x i8> %4050, <16 x i8> %4049, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4052 = sext i32 %4045 to i64
  %4053 = sext i32 %3974 to i64
  %4054 = sext i32 %3648 to i64
  br label %4135

4055:                                             ; preds = %4135
  %4056 = trunc i64 %4472 to i32
  br label %4057

4057:                                             ; preds = %4055, %3972
  %4058 = phi i8* [ %3973, %3972 ], [ %4473, %4055 ]
  %4059 = phi i32 [ %3974, %3972 ], [ %4056, %4055 ]
  %4060 = icmp slt i32 %4059, %5
  br i1 %4060, label %4061, label %4624

4061:                                             ; preds = %4057
  %4062 = sext i16 %3978 to i32
  %4063 = ashr i32 %4062, 5
  %4064 = trunc i16 %3978 to i8
  %4065 = and i8 %4064, 31
  %4066 = insertelement <16 x i8> undef, i8 %4065, i32 0
  %4067 = shufflevector <16 x i8> %4066, <16 x i8> undef, <16 x i32> zeroinitializer
  %4068 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4067
  %4069 = shufflevector <16 x i8> %4068, <16 x i8> %4067, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4070 = sext i32 %4063 to i64
  %4071 = sub i32 %4062, %7
  %4072 = ashr i32 %4071, 5
  %4073 = trunc i32 %4071 to i8
  %4074 = and i8 %4073, 31
  %4075 = insertelement <16 x i8> undef, i8 %4074, i32 0
  %4076 = shufflevector <16 x i8> %4075, <16 x i8> undef, <16 x i32> zeroinitializer
  %4077 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4076
  %4078 = shufflevector <16 x i8> %4077, <16 x i8> %4076, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4079 = sext i32 %4072 to i64
  %4080 = sub i32 %4071, %7
  %4081 = ashr i32 %4080, 5
  %4082 = trunc i32 %4080 to i8
  %4083 = and i8 %4082, 31
  %4084 = insertelement <16 x i8> undef, i8 %4083, i32 0
  %4085 = shufflevector <16 x i8> %4084, <16 x i8> undef, <16 x i32> zeroinitializer
  %4086 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4085
  %4087 = shufflevector <16 x i8> %4086, <16 x i8> %4085, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4088 = sext i32 %4081 to i64
  %4089 = sub i32 %4080, %7
  %4090 = ashr i32 %4089, 5
  %4091 = trunc i32 %4089 to i8
  %4092 = and i8 %4091, 31
  %4093 = insertelement <16 x i8> undef, i8 %4092, i32 0
  %4094 = shufflevector <16 x i8> %4093, <16 x i8> undef, <16 x i32> zeroinitializer
  %4095 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4094
  %4096 = shufflevector <16 x i8> %4095, <16 x i8> %4094, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4097 = sext i32 %4090 to i64
  %4098 = sub i32 %4089, %7
  %4099 = ashr i32 %4098, 5
  %4100 = trunc i32 %4098 to i8
  %4101 = and i8 %4100, 31
  %4102 = insertelement <16 x i8> undef, i8 %4101, i32 0
  %4103 = shufflevector <16 x i8> %4102, <16 x i8> undef, <16 x i32> zeroinitializer
  %4104 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4103
  %4105 = shufflevector <16 x i8> %4104, <16 x i8> %4103, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4106 = sext i32 %4099 to i64
  %4107 = sub i32 %4098, %7
  %4108 = ashr i32 %4107, 5
  %4109 = trunc i32 %4107 to i8
  %4110 = and i8 %4109, 31
  %4111 = insertelement <16 x i8> undef, i8 %4110, i32 0
  %4112 = shufflevector <16 x i8> %4111, <16 x i8> undef, <16 x i32> zeroinitializer
  %4113 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4112
  %4114 = shufflevector <16 x i8> %4113, <16 x i8> %4112, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4115 = sext i32 %4108 to i64
  %4116 = sub i32 %4107, %7
  %4117 = ashr i32 %4116, 5
  %4118 = trunc i32 %4116 to i8
  %4119 = and i8 %4118, 31
  %4120 = insertelement <16 x i8> undef, i8 %4119, i32 0
  %4121 = shufflevector <16 x i8> %4120, <16 x i8> undef, <16 x i32> zeroinitializer
  %4122 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4121
  %4123 = shufflevector <16 x i8> %4122, <16 x i8> %4121, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4124 = sext i32 %4117 to i64
  %4125 = sub i32 %4116, %7
  %4126 = ashr i32 %4125, 5
  %4127 = trunc i32 %4125 to i8
  %4128 = and i8 %4127, 31
  %4129 = insertelement <16 x i8> undef, i8 %4128, i32 0
  %4130 = shufflevector <16 x i8> %4129, <16 x i8> undef, <16 x i32> zeroinitializer
  %4131 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4130
  %4132 = shufflevector <16 x i8> %4131, <16 x i8> %4130, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4133 = sext i32 %4126 to i64
  %4134 = sext i32 %4059 to i64
  br label %4478

4135:                                             ; preds = %4135, %3980
  %4136 = phi i64 [ %4053, %3980 ], [ %4472, %4135 ]
  %4137 = phi i32 [ %3977, %3980 ], [ %4476, %4135 ]
  %4138 = phi <8 x i16> [ %3976, %3980 ], [ %4475, %4135 ]
  %4139 = phi <8 x i16> [ %3975, %3980 ], [ %4474, %4135 ]
  %4140 = phi i8* [ %3973, %3980 ], [ %4473, %4135 ]
  %4141 = ashr <8 x i16> %4139, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %4142 = trunc i64 %4136 to i32
  %4143 = add i32 %3451, %4142
  %4144 = shl i32 %4143, 1
  %4145 = sext i32 %4144 to i64
  %4146 = getelementptr inbounds i8, i8* %20, i64 %4145
  %4147 = getelementptr inbounds i8, i8* %4146, i64 %3989
  %4148 = bitcast i8* %4147 to <16 x i8>*
  %4149 = load <16 x i8>, <16 x i8>* %4148, align 1
  %4150 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4149, <16 x i8> %3988) #11
  %4151 = lshr <8 x i16> %4150, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4152 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4151, <8 x i16> zeroinitializer) #11
  %4153 = getelementptr inbounds i8, i8* %4146, i64 %3998
  %4154 = bitcast i8* %4153 to <16 x i8>*
  %4155 = load <16 x i8>, <16 x i8>* %4154, align 1
  %4156 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4155, <16 x i8> %3997) #11
  %4157 = lshr <8 x i16> %4156, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4158 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4157, <8 x i16> zeroinitializer) #11
  %4159 = getelementptr inbounds i8, i8* %4146, i64 %4007
  %4160 = bitcast i8* %4159 to <16 x i8>*
  %4161 = load <16 x i8>, <16 x i8>* %4160, align 1
  %4162 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4161, <16 x i8> %4006) #11
  %4163 = lshr <8 x i16> %4162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4164 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4163, <8 x i16> zeroinitializer) #11
  %4165 = getelementptr inbounds i8, i8* %4146, i64 %4016
  %4166 = bitcast i8* %4165 to <16 x i8>*
  %4167 = load <16 x i8>, <16 x i8>* %4166, align 1
  %4168 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4167, <16 x i8> %4015) #11
  %4169 = lshr <8 x i16> %4168, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4170 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4169, <8 x i16> zeroinitializer) #11
  %4171 = getelementptr inbounds i8, i8* %4146, i64 %4025
  %4172 = bitcast i8* %4171 to <16 x i8>*
  %4173 = load <16 x i8>, <16 x i8>* %4172, align 1
  %4174 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4173, <16 x i8> %4024) #11
  %4175 = lshr <8 x i16> %4174, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4176 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4175, <8 x i16> zeroinitializer) #11
  %4177 = getelementptr inbounds i8, i8* %4146, i64 %4034
  %4178 = bitcast i8* %4177 to <16 x i8>*
  %4179 = load <16 x i8>, <16 x i8>* %4178, align 1
  %4180 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4179, <16 x i8> %4033) #11
  %4181 = lshr <8 x i16> %4180, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4182 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4181, <8 x i16> zeroinitializer) #11
  %4183 = getelementptr inbounds i8, i8* %4146, i64 %4043
  %4184 = bitcast i8* %4183 to <16 x i8>*
  %4185 = load <16 x i8>, <16 x i8>* %4184, align 1
  %4186 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4185, <16 x i8> %4042) #11
  %4187 = lshr <8 x i16> %4186, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4188 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4187, <8 x i16> zeroinitializer) #11
  %4189 = getelementptr inbounds i8, i8* %4146, i64 %4052
  %4190 = bitcast i8* %4189 to <16 x i8>*
  %4191 = load <16 x i8>, <16 x i8>* %4190, align 1
  %4192 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4191, <16 x i8> %4051) #11
  %4193 = lshr <8 x i16> %4192, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4194 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4193, <8 x i16> zeroinitializer) #11
  %4195 = shufflevector <8 x i16> %4152, <8 x i16> %4158, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4196 = shufflevector <8 x i16> %4164, <8 x i16> %4170, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4197 = shufflevector <8 x i16> %4176, <8 x i16> %4182, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4198 = shufflevector <8 x i16> %4188, <8 x i16> %4194, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4199 = shufflevector <8 x i16> %4152, <8 x i16> %4158, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4200 = shufflevector <8 x i16> %4164, <8 x i16> %4170, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4201 = shufflevector <8 x i16> %4176, <8 x i16> %4182, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4202 = shufflevector <8 x i16> %4188, <8 x i16> %4194, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4203 = bitcast <8 x i16> %4195 to <4 x i32>
  %4204 = bitcast <8 x i16> %4196 to <4 x i32>
  %4205 = shufflevector <4 x i32> %4203, <4 x i32> %4204, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4206 = bitcast <4 x i32> %4205 to <2 x i64>
  %4207 = bitcast <8 x i16> %4197 to <4 x i32>
  %4208 = bitcast <8 x i16> %4198 to <4 x i32>
  %4209 = shufflevector <4 x i32> %4207, <4 x i32> %4208, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4210 = bitcast <4 x i32> %4209 to <2 x i64>
  %4211 = bitcast <8 x i16> %4199 to <4 x i32>
  %4212 = bitcast <8 x i16> %4200 to <4 x i32>
  %4213 = shufflevector <4 x i32> %4211, <4 x i32> %4212, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4214 = bitcast <4 x i32> %4213 to <2 x i64>
  %4215 = bitcast <8 x i16> %4201 to <4 x i32>
  %4216 = bitcast <8 x i16> %4202 to <4 x i32>
  %4217 = shufflevector <4 x i32> %4215, <4 x i32> %4216, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4218 = bitcast <4 x i32> %4217 to <2 x i64>
  %4219 = shufflevector <4 x i32> %4203, <4 x i32> %4204, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4220 = bitcast <4 x i32> %4219 to <2 x i64>
  %4221 = shufflevector <4 x i32> %4207, <4 x i32> %4208, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4222 = bitcast <4 x i32> %4221 to <2 x i64>
  %4223 = shufflevector <4 x i32> %4211, <4 x i32> %4212, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4224 = bitcast <4 x i32> %4223 to <2 x i64>
  %4225 = shufflevector <4 x i32> %4215, <4 x i32> %4216, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4226 = bitcast <4 x i32> %4225 to <2 x i64>
  %4227 = shufflevector <2 x i64> %4206, <2 x i64> %4210, <2 x i32> <i32 0, i32 2>
  %4228 = shufflevector <2 x i64> %4206, <2 x i64> %4210, <2 x i32> <i32 1, i32 3>
  %4229 = shufflevector <2 x i64> %4220, <2 x i64> %4222, <2 x i32> <i32 0, i32 2>
  %4230 = shufflevector <2 x i64> %4220, <2 x i64> %4222, <2 x i32> <i32 1, i32 3>
  %4231 = shufflevector <2 x i64> %4214, <2 x i64> %4218, <2 x i32> <i32 0, i32 2>
  %4232 = shufflevector <2 x i64> %4214, <2 x i64> %4218, <2 x i32> <i32 1, i32 3>
  %4233 = shufflevector <2 x i64> %4224, <2 x i64> %4226, <2 x i32> <i32 0, i32 2>
  %4234 = shufflevector <2 x i64> %4224, <2 x i64> %4226, <2 x i32> <i32 1, i32 3>
  %4235 = bitcast <2 x i64> %4227 to <8 x i16>
  %4236 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4235, <8 x i16> undef) #11
  %4237 = bitcast <16 x i8> %4236 to <2 x i64>
  %4238 = extractelement <2 x i64> %4237, i32 0
  %4239 = bitcast i8* %4140 to i64*
  store i64 %4238, i64* %4239, align 1
  %4240 = getelementptr inbounds i8, i8* %4140, i64 %1
  %4241 = bitcast <2 x i64> %4228 to <8 x i16>
  %4242 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4241, <8 x i16> undef) #11
  %4243 = bitcast <16 x i8> %4242 to <2 x i64>
  %4244 = extractelement <2 x i64> %4243, i32 0
  %4245 = bitcast i8* %4240 to i64*
  store i64 %4244, i64* %4245, align 1
  %4246 = getelementptr inbounds i8, i8* %4240, i64 %1
  %4247 = bitcast <2 x i64> %4229 to <8 x i16>
  %4248 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4247, <8 x i16> undef) #11
  %4249 = bitcast <16 x i8> %4248 to <2 x i64>
  %4250 = extractelement <2 x i64> %4249, i32 0
  %4251 = bitcast i8* %4246 to i64*
  store i64 %4250, i64* %4251, align 1
  %4252 = getelementptr inbounds i8, i8* %4246, i64 %1
  %4253 = bitcast <2 x i64> %4230 to <8 x i16>
  %4254 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4253, <8 x i16> undef) #11
  %4255 = bitcast <16 x i8> %4254 to <2 x i64>
  %4256 = extractelement <2 x i64> %4255, i32 0
  %4257 = bitcast i8* %4252 to i64*
  store i64 %4256, i64* %4257, align 1
  %4258 = getelementptr inbounds i8, i8* %4252, i64 %1
  %4259 = bitcast <2 x i64> %4231 to <8 x i16>
  %4260 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4259, <8 x i16> undef) #11
  %4261 = bitcast <16 x i8> %4260 to <2 x i64>
  %4262 = extractelement <2 x i64> %4261, i32 0
  %4263 = bitcast i8* %4258 to i64*
  store i64 %4262, i64* %4263, align 1
  %4264 = getelementptr inbounds i8, i8* %4258, i64 %1
  %4265 = bitcast <2 x i64> %4232 to <8 x i16>
  %4266 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4265, <8 x i16> undef) #11
  %4267 = bitcast <16 x i8> %4266 to <2 x i64>
  %4268 = extractelement <2 x i64> %4267, i32 0
  %4269 = bitcast i8* %4264 to i64*
  store i64 %4268, i64* %4269, align 1
  %4270 = getelementptr inbounds i8, i8* %4264, i64 %1
  %4271 = bitcast <2 x i64> %4233 to <8 x i16>
  %4272 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4271, <8 x i16> undef) #11
  %4273 = bitcast <16 x i8> %4272 to <2 x i64>
  %4274 = extractelement <2 x i64> %4273, i32 0
  %4275 = bitcast i8* %4270 to i64*
  store i64 %4274, i64* %4275, align 1
  %4276 = getelementptr inbounds i8, i8* %4270, i64 %1
  %4277 = bitcast <2 x i64> %4234 to <8 x i16>
  %4278 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4277, <8 x i16> undef) #11
  %4279 = bitcast <16 x i8> %4278 to <2 x i64>
  %4280 = extractelement <2 x i64> %4279, i32 0
  %4281 = bitcast i8* %4276 to i64*
  store i64 %4280, i64* %4281, align 1
  %4282 = lshr <8 x i16> %4138, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %4283 = and <8 x i16> %4282, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %4284 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4283, <8 x i16> %4283) #11
  %4285 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4284
  %4286 = shufflevector <16 x i8> %4285, <16 x i8> %4284, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4287 = bitcast <8 x i16> %4141 to <16 x i8>
  %4288 = sub nsw i32 %4137, %6
  %4289 = ashr i32 %4288, 6
  %4290 = sext i32 %4289 to i64
  %4291 = getelementptr inbounds i8, i8* %3462, i64 %4290
  %4292 = shufflevector <16 x i8> %4286, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %4293 = bitcast i8* %4291 to <16 x i8>*
  %4294 = load <16 x i8>, <16 x i8>* %4293, align 1
  %4295 = shufflevector <16 x i8> %4294, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %4296 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4295, <16 x i8> %4292) #11
  %4297 = lshr <8 x i16> %4296, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4298 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4297, <8 x i16> zeroinitializer) #11
  %4299 = shufflevector <16 x i8> %4287, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %4300 = bitcast <16 x i8> %4299 to <8 x i16>
  %4301 = icmp sgt <8 x i16> %4300, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %4302 = load i64, i64* %4239, align 1
  %4303 = insertelement <2 x i64> undef, i64 %4302, i32 0
  %4304 = bitcast <2 x i64> %4303 to <16 x i8>
  %4305 = shufflevector <16 x i8> %4304, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %4306 = zext <8 x i8> %4305 to <8 x i16>
  %4307 = select <8 x i1> %4301, <8 x i16> %4306, <8 x i16> %4298
  %4308 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4307, <8 x i16> undef) #11
  %4309 = bitcast <16 x i8> %4308 to <2 x i64>
  %4310 = extractelement <2 x i64> %4309, i32 0
  store i64 %4310, i64* %4239, align 1
  %4311 = sub nsw i32 %4288, %6
  %4312 = ashr i32 %4311, 6
  %4313 = sext i32 %4312 to i64
  %4314 = getelementptr inbounds i8, i8* %3462, i64 %4313
  %4315 = shufflevector <16 x i8> %4286, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %4316 = bitcast i8* %4314 to <16 x i8>*
  %4317 = load <16 x i8>, <16 x i8>* %4316, align 1
  %4318 = shufflevector <16 x i8> %4317, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %4319 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4318, <16 x i8> %4315) #11
  %4320 = lshr <8 x i16> %4319, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4321 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4320, <8 x i16> zeroinitializer) #11
  %4322 = shufflevector <16 x i8> %4287, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %4323 = bitcast <16 x i8> %4322 to <8 x i16>
  %4324 = icmp sgt <8 x i16> %4323, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %4325 = load i64, i64* %4245, align 1
  %4326 = insertelement <2 x i64> undef, i64 %4325, i32 0
  %4327 = bitcast <2 x i64> %4326 to <16 x i8>
  %4328 = shufflevector <16 x i8> %4327, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %4329 = zext <8 x i8> %4328 to <8 x i16>
  %4330 = select <8 x i1> %4324, <8 x i16> %4329, <8 x i16> %4321
  %4331 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4330, <8 x i16> undef) #11
  %4332 = bitcast <16 x i8> %4331 to <2 x i64>
  %4333 = extractelement <2 x i64> %4332, i32 0
  store i64 %4333, i64* %4245, align 1
  %4334 = sub nsw i32 %4311, %6
  %4335 = ashr i32 %4334, 6
  %4336 = sext i32 %4335 to i64
  %4337 = getelementptr inbounds i8, i8* %3462, i64 %4336
  %4338 = shufflevector <16 x i8> %4286, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %4339 = bitcast i8* %4337 to <16 x i8>*
  %4340 = load <16 x i8>, <16 x i8>* %4339, align 1
  %4341 = shufflevector <16 x i8> %4340, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %4342 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4341, <16 x i8> %4338) #11
  %4343 = lshr <8 x i16> %4342, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4344 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4343, <8 x i16> zeroinitializer) #11
  %4345 = shufflevector <16 x i8> %4287, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %4346 = bitcast <16 x i8> %4345 to <8 x i16>
  %4347 = icmp sgt <8 x i16> %4346, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %4348 = load i64, i64* %4251, align 1
  %4349 = insertelement <2 x i64> undef, i64 %4348, i32 0
  %4350 = bitcast <2 x i64> %4349 to <16 x i8>
  %4351 = shufflevector <16 x i8> %4350, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %4352 = zext <8 x i8> %4351 to <8 x i16>
  %4353 = select <8 x i1> %4347, <8 x i16> %4352, <8 x i16> %4344
  %4354 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4353, <8 x i16> undef) #11
  %4355 = bitcast <16 x i8> %4354 to <2 x i64>
  %4356 = extractelement <2 x i64> %4355, i32 0
  store i64 %4356, i64* %4251, align 1
  %4357 = sub nsw i32 %4334, %6
  %4358 = ashr i32 %4357, 6
  %4359 = sext i32 %4358 to i64
  %4360 = getelementptr inbounds i8, i8* %3462, i64 %4359
  %4361 = shufflevector <16 x i8> %4286, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %4362 = bitcast i8* %4360 to <16 x i8>*
  %4363 = load <16 x i8>, <16 x i8>* %4362, align 1
  %4364 = shufflevector <16 x i8> %4363, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %4365 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4364, <16 x i8> %4361) #11
  %4366 = lshr <8 x i16> %4365, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4367 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4366, <8 x i16> zeroinitializer) #11
  %4368 = shufflevector <16 x i8> %4287, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %4369 = bitcast <16 x i8> %4368 to <8 x i16>
  %4370 = icmp sgt <8 x i16> %4369, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %4371 = load i64, i64* %4257, align 1
  %4372 = insertelement <2 x i64> undef, i64 %4371, i32 0
  %4373 = bitcast <2 x i64> %4372 to <16 x i8>
  %4374 = shufflevector <16 x i8> %4373, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %4375 = zext <8 x i8> %4374 to <8 x i16>
  %4376 = select <8 x i1> %4370, <8 x i16> %4375, <8 x i16> %4367
  %4377 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4376, <8 x i16> undef) #11
  %4378 = bitcast <16 x i8> %4377 to <2 x i64>
  %4379 = extractelement <2 x i64> %4378, i32 0
  store i64 %4379, i64* %4257, align 1
  %4380 = sub nsw i32 %4357, %6
  %4381 = ashr i32 %4380, 6
  %4382 = sext i32 %4381 to i64
  %4383 = getelementptr inbounds i8, i8* %3462, i64 %4382
  %4384 = shufflevector <16 x i8> %4286, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %4385 = bitcast i8* %4383 to <16 x i8>*
  %4386 = load <16 x i8>, <16 x i8>* %4385, align 1
  %4387 = shufflevector <16 x i8> %4386, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %4388 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4387, <16 x i8> %4384) #11
  %4389 = lshr <8 x i16> %4388, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4390 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4389, <8 x i16> zeroinitializer) #11
  %4391 = shufflevector <16 x i8> %4287, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %4392 = bitcast <16 x i8> %4391 to <8 x i16>
  %4393 = icmp sgt <8 x i16> %4392, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %4394 = load i64, i64* %4263, align 1
  %4395 = insertelement <2 x i64> undef, i64 %4394, i32 0
  %4396 = bitcast <2 x i64> %4395 to <16 x i8>
  %4397 = shufflevector <16 x i8> %4396, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %4398 = zext <8 x i8> %4397 to <8 x i16>
  %4399 = select <8 x i1> %4393, <8 x i16> %4398, <8 x i16> %4390
  %4400 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4399, <8 x i16> undef) #11
  %4401 = bitcast <16 x i8> %4400 to <2 x i64>
  %4402 = extractelement <2 x i64> %4401, i32 0
  store i64 %4402, i64* %4263, align 1
  %4403 = sub nsw i32 %4380, %6
  %4404 = ashr i32 %4403, 6
  %4405 = sext i32 %4404 to i64
  %4406 = getelementptr inbounds i8, i8* %3462, i64 %4405
  %4407 = shufflevector <16 x i8> %4286, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %4408 = bitcast i8* %4406 to <16 x i8>*
  %4409 = load <16 x i8>, <16 x i8>* %4408, align 1
  %4410 = shufflevector <16 x i8> %4409, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %4411 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4410, <16 x i8> %4407) #11
  %4412 = lshr <8 x i16> %4411, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4413 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4412, <8 x i16> zeroinitializer) #11
  %4414 = shufflevector <16 x i8> %4287, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %4415 = bitcast <16 x i8> %4414 to <8 x i16>
  %4416 = icmp sgt <8 x i16> %4415, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %4417 = load i64, i64* %4269, align 1
  %4418 = insertelement <2 x i64> undef, i64 %4417, i32 0
  %4419 = bitcast <2 x i64> %4418 to <16 x i8>
  %4420 = shufflevector <16 x i8> %4419, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %4421 = zext <8 x i8> %4420 to <8 x i16>
  %4422 = select <8 x i1> %4416, <8 x i16> %4421, <8 x i16> %4413
  %4423 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4422, <8 x i16> undef) #11
  %4424 = bitcast <16 x i8> %4423 to <2 x i64>
  %4425 = extractelement <2 x i64> %4424, i32 0
  store i64 %4425, i64* %4269, align 1
  %4426 = sub nsw i32 %4403, %6
  %4427 = ashr i32 %4426, 6
  %4428 = sext i32 %4427 to i64
  %4429 = getelementptr inbounds i8, i8* %3462, i64 %4428
  %4430 = shufflevector <16 x i8> %4286, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %4431 = bitcast i8* %4429 to <16 x i8>*
  %4432 = load <16 x i8>, <16 x i8>* %4431, align 1
  %4433 = shufflevector <16 x i8> %4432, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %4434 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4433, <16 x i8> %4430) #11
  %4435 = lshr <8 x i16> %4434, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4436 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4435, <8 x i16> zeroinitializer) #11
  %4437 = shufflevector <16 x i8> %4287, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %4438 = bitcast <16 x i8> %4437 to <8 x i16>
  %4439 = icmp sgt <8 x i16> %4438, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %4440 = load i64, i64* %4275, align 1
  %4441 = insertelement <2 x i64> undef, i64 %4440, i32 0
  %4442 = bitcast <2 x i64> %4441 to <16 x i8>
  %4443 = shufflevector <16 x i8> %4442, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %4444 = zext <8 x i8> %4443 to <8 x i16>
  %4445 = select <8 x i1> %4439, <8 x i16> %4444, <8 x i16> %4436
  %4446 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4445, <8 x i16> undef) #11
  %4447 = bitcast <16 x i8> %4446 to <2 x i64>
  %4448 = extractelement <2 x i64> %4447, i32 0
  store i64 %4448, i64* %4275, align 1
  %4449 = sub nsw i32 %4426, %6
  %4450 = ashr i32 %4449, 6
  %4451 = sext i32 %4450 to i64
  %4452 = getelementptr inbounds i8, i8* %3462, i64 %4451
  %4453 = shufflevector <16 x i8> %4286, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %4454 = bitcast i8* %4452 to <16 x i8>*
  %4455 = load <16 x i8>, <16 x i8>* %4454, align 1
  %4456 = shufflevector <16 x i8> %4455, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %4457 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4456, <16 x i8> %4453) #11
  %4458 = lshr <8 x i16> %4457, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4459 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4458, <8 x i16> zeroinitializer) #11
  %4460 = shufflevector <16 x i8> %4287, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %4461 = bitcast <16 x i8> %4460 to <8 x i16>
  %4462 = icmp sgt <8 x i16> %4461, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %4463 = load i64, i64* %4281, align 1
  %4464 = insertelement <2 x i64> undef, i64 %4463, i32 0
  %4465 = bitcast <2 x i64> %4464 to <16 x i8>
  %4466 = shufflevector <16 x i8> %4465, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %4467 = zext <8 x i8> %4466 to <8 x i16>
  %4468 = select <8 x i1> %4462, <8 x i16> %4467, <8 x i16> %4459
  %4469 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4468, <8 x i16> undef) #11
  %4470 = bitcast <16 x i8> %4469 to <2 x i64>
  %4471 = extractelement <2 x i64> %4470, i32 0
  store i64 %4471, i64* %4281, align 1
  %4472 = add nsw i64 %4136, 8
  %4473 = getelementptr inbounds i8, i8* %4140, i64 %2071
  %4474 = add <8 x i16> %4139, %2083
  %4475 = sub <8 x i16> %4138, %2083
  %4476 = sub nsw i32 %4137, %2080
  %4477 = icmp slt i64 %4472, %4054
  br i1 %4477, label %4135, label %4055

4478:                                             ; preds = %4478, %4061
  %4479 = phi i64 [ %4134, %4061 ], [ %4621, %4478 ]
  %4480 = phi i8* [ %4058, %4061 ], [ %4622, %4478 ]
  %4481 = trunc i64 %4479 to i32
  %4482 = add i32 %3451, %4481
  %4483 = shl i32 %4482, 1
  %4484 = sext i32 %4483 to i64
  %4485 = getelementptr inbounds i8, i8* %20, i64 %4484
  %4486 = getelementptr inbounds i8, i8* %4485, i64 %4070
  %4487 = bitcast i8* %4486 to <16 x i8>*
  %4488 = load <16 x i8>, <16 x i8>* %4487, align 1
  %4489 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4488, <16 x i8> %4069) #11
  %4490 = lshr <8 x i16> %4489, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4491 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4490, <8 x i16> zeroinitializer) #11
  %4492 = getelementptr inbounds i8, i8* %4485, i64 %4079
  %4493 = bitcast i8* %4492 to <16 x i8>*
  %4494 = load <16 x i8>, <16 x i8>* %4493, align 1
  %4495 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4494, <16 x i8> %4078) #11
  %4496 = lshr <8 x i16> %4495, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4497 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4496, <8 x i16> zeroinitializer) #11
  %4498 = getelementptr inbounds i8, i8* %4485, i64 %4088
  %4499 = bitcast i8* %4498 to <16 x i8>*
  %4500 = load <16 x i8>, <16 x i8>* %4499, align 1
  %4501 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4500, <16 x i8> %4087) #11
  %4502 = lshr <8 x i16> %4501, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4503 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4502, <8 x i16> zeroinitializer) #11
  %4504 = getelementptr inbounds i8, i8* %4485, i64 %4097
  %4505 = bitcast i8* %4504 to <16 x i8>*
  %4506 = load <16 x i8>, <16 x i8>* %4505, align 1
  %4507 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4506, <16 x i8> %4096) #11
  %4508 = lshr <8 x i16> %4507, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4509 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4508, <8 x i16> zeroinitializer) #11
  %4510 = getelementptr inbounds i8, i8* %4485, i64 %4106
  %4511 = bitcast i8* %4510 to <16 x i8>*
  %4512 = load <16 x i8>, <16 x i8>* %4511, align 1
  %4513 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4512, <16 x i8> %4105) #11
  %4514 = lshr <8 x i16> %4513, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4515 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4514, <8 x i16> zeroinitializer) #11
  %4516 = getelementptr inbounds i8, i8* %4485, i64 %4115
  %4517 = bitcast i8* %4516 to <16 x i8>*
  %4518 = load <16 x i8>, <16 x i8>* %4517, align 1
  %4519 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4518, <16 x i8> %4114) #11
  %4520 = lshr <8 x i16> %4519, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4521 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4520, <8 x i16> zeroinitializer) #11
  %4522 = getelementptr inbounds i8, i8* %4485, i64 %4124
  %4523 = bitcast i8* %4522 to <16 x i8>*
  %4524 = load <16 x i8>, <16 x i8>* %4523, align 1
  %4525 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4524, <16 x i8> %4123) #11
  %4526 = lshr <8 x i16> %4525, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4527 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4526, <8 x i16> zeroinitializer) #11
  %4528 = getelementptr inbounds i8, i8* %4485, i64 %4133
  %4529 = bitcast i8* %4528 to <16 x i8>*
  %4530 = load <16 x i8>, <16 x i8>* %4529, align 1
  %4531 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4530, <16 x i8> %4132) #11
  %4532 = lshr <8 x i16> %4531, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4533 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4532, <8 x i16> zeroinitializer) #11
  %4534 = shufflevector <8 x i16> %4491, <8 x i16> %4497, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4535 = shufflevector <8 x i16> %4503, <8 x i16> %4509, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4536 = shufflevector <8 x i16> %4515, <8 x i16> %4521, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4537 = shufflevector <8 x i16> %4527, <8 x i16> %4533, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %4538 = shufflevector <8 x i16> %4491, <8 x i16> %4497, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4539 = shufflevector <8 x i16> %4503, <8 x i16> %4509, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4540 = shufflevector <8 x i16> %4515, <8 x i16> %4521, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4541 = shufflevector <8 x i16> %4527, <8 x i16> %4533, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %4542 = bitcast <8 x i16> %4534 to <4 x i32>
  %4543 = bitcast <8 x i16> %4535 to <4 x i32>
  %4544 = shufflevector <4 x i32> %4542, <4 x i32> %4543, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4545 = bitcast <4 x i32> %4544 to <2 x i64>
  %4546 = bitcast <8 x i16> %4536 to <4 x i32>
  %4547 = bitcast <8 x i16> %4537 to <4 x i32>
  %4548 = shufflevector <4 x i32> %4546, <4 x i32> %4547, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4549 = bitcast <4 x i32> %4548 to <2 x i64>
  %4550 = bitcast <8 x i16> %4538 to <4 x i32>
  %4551 = bitcast <8 x i16> %4539 to <4 x i32>
  %4552 = shufflevector <4 x i32> %4550, <4 x i32> %4551, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4553 = bitcast <4 x i32> %4552 to <2 x i64>
  %4554 = bitcast <8 x i16> %4540 to <4 x i32>
  %4555 = bitcast <8 x i16> %4541 to <4 x i32>
  %4556 = shufflevector <4 x i32> %4554, <4 x i32> %4555, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %4557 = bitcast <4 x i32> %4556 to <2 x i64>
  %4558 = shufflevector <4 x i32> %4542, <4 x i32> %4543, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4559 = bitcast <4 x i32> %4558 to <2 x i64>
  %4560 = shufflevector <4 x i32> %4546, <4 x i32> %4547, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4561 = bitcast <4 x i32> %4560 to <2 x i64>
  %4562 = shufflevector <4 x i32> %4550, <4 x i32> %4551, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4563 = bitcast <4 x i32> %4562 to <2 x i64>
  %4564 = shufflevector <4 x i32> %4554, <4 x i32> %4555, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %4565 = bitcast <4 x i32> %4564 to <2 x i64>
  %4566 = shufflevector <2 x i64> %4545, <2 x i64> %4549, <2 x i32> <i32 0, i32 2>
  %4567 = shufflevector <2 x i64> %4545, <2 x i64> %4549, <2 x i32> <i32 1, i32 3>
  %4568 = shufflevector <2 x i64> %4559, <2 x i64> %4561, <2 x i32> <i32 0, i32 2>
  %4569 = shufflevector <2 x i64> %4559, <2 x i64> %4561, <2 x i32> <i32 1, i32 3>
  %4570 = shufflevector <2 x i64> %4553, <2 x i64> %4557, <2 x i32> <i32 0, i32 2>
  %4571 = shufflevector <2 x i64> %4553, <2 x i64> %4557, <2 x i32> <i32 1, i32 3>
  %4572 = shufflevector <2 x i64> %4563, <2 x i64> %4565, <2 x i32> <i32 0, i32 2>
  %4573 = shufflevector <2 x i64> %4563, <2 x i64> %4565, <2 x i32> <i32 1, i32 3>
  %4574 = bitcast <2 x i64> %4566 to <8 x i16>
  %4575 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4574, <8 x i16> undef) #11
  %4576 = bitcast <16 x i8> %4575 to <2 x i64>
  %4577 = extractelement <2 x i64> %4576, i32 0
  %4578 = bitcast i8* %4480 to i64*
  store i64 %4577, i64* %4578, align 1
  %4579 = getelementptr inbounds i8, i8* %4480, i64 %1
  %4580 = bitcast <2 x i64> %4567 to <8 x i16>
  %4581 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4580, <8 x i16> undef) #11
  %4582 = bitcast <16 x i8> %4581 to <2 x i64>
  %4583 = extractelement <2 x i64> %4582, i32 0
  %4584 = bitcast i8* %4579 to i64*
  store i64 %4583, i64* %4584, align 1
  %4585 = getelementptr inbounds i8, i8* %4579, i64 %1
  %4586 = bitcast <2 x i64> %4568 to <8 x i16>
  %4587 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4586, <8 x i16> undef) #11
  %4588 = bitcast <16 x i8> %4587 to <2 x i64>
  %4589 = extractelement <2 x i64> %4588, i32 0
  %4590 = bitcast i8* %4585 to i64*
  store i64 %4589, i64* %4590, align 1
  %4591 = getelementptr inbounds i8, i8* %4585, i64 %1
  %4592 = bitcast <2 x i64> %4569 to <8 x i16>
  %4593 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4592, <8 x i16> undef) #11
  %4594 = bitcast <16 x i8> %4593 to <2 x i64>
  %4595 = extractelement <2 x i64> %4594, i32 0
  %4596 = bitcast i8* %4591 to i64*
  store i64 %4595, i64* %4596, align 1
  %4597 = getelementptr inbounds i8, i8* %4591, i64 %1
  %4598 = bitcast <2 x i64> %4570 to <8 x i16>
  %4599 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4598, <8 x i16> undef) #11
  %4600 = bitcast <16 x i8> %4599 to <2 x i64>
  %4601 = extractelement <2 x i64> %4600, i32 0
  %4602 = bitcast i8* %4597 to i64*
  store i64 %4601, i64* %4602, align 1
  %4603 = getelementptr inbounds i8, i8* %4597, i64 %1
  %4604 = bitcast <2 x i64> %4571 to <8 x i16>
  %4605 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4604, <8 x i16> undef) #11
  %4606 = bitcast <16 x i8> %4605 to <2 x i64>
  %4607 = extractelement <2 x i64> %4606, i32 0
  %4608 = bitcast i8* %4603 to i64*
  store i64 %4607, i64* %4608, align 1
  %4609 = getelementptr inbounds i8, i8* %4603, i64 %1
  %4610 = bitcast <2 x i64> %4572 to <8 x i16>
  %4611 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4610, <8 x i16> undef) #11
  %4612 = bitcast <16 x i8> %4611 to <2 x i64>
  %4613 = extractelement <2 x i64> %4612, i32 0
  %4614 = bitcast i8* %4609 to i64*
  store i64 %4613, i64* %4614, align 1
  %4615 = getelementptr inbounds i8, i8* %4609, i64 %1
  %4616 = bitcast <2 x i64> %4573 to <8 x i16>
  %4617 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4616, <8 x i16> undef) #11
  %4618 = bitcast <16 x i8> %4617 to <2 x i64>
  %4619 = extractelement <2 x i64> %4618, i32 0
  %4620 = bitcast i8* %4615 to i64*
  store i64 %4619, i64* %4620, align 1
  %4621 = add nsw i64 %4479, 8
  %4622 = getelementptr inbounds i8, i8* %4480, i64 %2071
  %4623 = icmp slt i64 %4621, %3419
  br i1 %4623, label %4478, label %4624

4624:                                             ; preds = %4478, %4057
  %4625 = add <8 x i16> %3651, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %4626 = bitcast <8 x i16> %4625 to <2 x i64>
  %4627 = add <8 x i16> %3452, %2095
  %4628 = sub nsw i32 %3451, %2090
  %4629 = icmp slt i64 %3643, %3420
  br i1 %4629, label %3449, label %3421

4630:                                             ; preds = %4705, %3426
  %4631 = phi i64 [ %3439, %3426 ], [ %4706, %4705 ]
  %4632 = getelementptr inbounds i8, i8* %0, i64 %4631
  %4633 = getelementptr inbounds i8, i8* %19, i64 %4631
  %4634 = getelementptr inbounds i8, i8* %4633, i64 %3428
  %4635 = load i8, i8* %4634, align 1
  %4636 = zext i8 %4635 to i16
  %4637 = insertelement <8 x i16> undef, i16 %4636, i32 0
  %4638 = shufflevector <8 x i16> %4637, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  br i1 %3435, label %4656, label %4639

4639:                                             ; preds = %4656, %4630
  %4640 = phi i32 [ 0, %4630 ], [ %3434, %4656 ]
  %4641 = phi i8* [ %4632, %4630 ], [ %4689, %4656 ]
  %4642 = icmp slt i32 %4640, %5
  br i1 %4642, label %4643, label %4705

4643:                                             ; preds = %4639
  %4644 = load i8, i8* %4634, align 1
  br i1 %3447, label %4653, label %4645

4645:                                             ; preds = %4643, %4645
  %4646 = phi i8* [ %4649, %4645 ], [ %4641, %4643 ]
  %4647 = phi i32 [ %4650, %4645 ], [ %4640, %4643 ]
  %4648 = phi i32 [ %4651, %4645 ], [ %3446, %4643 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4646, i8 %4644, i64 4, i1 false) #11
  %4649 = getelementptr inbounds i8, i8* %4646, i64 %1
  %4650 = add nuw nsw i32 %4647, 1
  %4651 = add i32 %4648, -1
  %4652 = icmp eq i32 %4651, 0
  br i1 %4652, label %4653, label %4645, !llvm.loop !19

4653:                                             ; preds = %4645, %4643
  %4654 = phi i8* [ %4641, %4643 ], [ %4649, %4645 ]
  %4655 = phi i32 [ %4640, %4643 ], [ %4650, %4645 ]
  br i1 %3448, label %4705, label %4692

4656:                                             ; preds = %4630, %4656
  %4657 = phi i8* [ %4689, %4656 ], [ %4632, %4630 ]
  %4658 = phi i32 [ %4688, %4656 ], [ 0, %4630 ]
  %4659 = phi i32 [ %4690, %4656 ], [ %2084, %4630 ]
  %4660 = ashr i32 %4659, 6
  %4661 = lshr i32 %4659, 1
  %4662 = trunc i32 %4661 to i8
  %4663 = and i8 %4662, 31
  %4664 = insertelement <16 x i8> undef, i8 %4663, i32 0
  %4665 = shufflevector <16 x i8> %4664, <16 x i8> undef, <16 x i32> zeroinitializer
  %4666 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4665
  %4667 = shufflevector <16 x i8> %4666, <16 x i8> %4665, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4668 = trunc i32 %4660 to i16
  %4669 = insertelement <8 x i16> undef, i16 %4668, i32 0
  %4670 = shufflevector <8 x i16> %4669, <8 x i16> undef, <8 x i32> zeroinitializer
  %4671 = add <8 x i16> %4670, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %4672 = sext i32 %4660 to i64
  %4673 = getelementptr inbounds i8, i8* %4633, i64 %4672
  %4674 = bitcast i8* %4673 to i64*
  %4675 = load i64, i64* %4674, align 1
  %4676 = insertelement <2 x i64> undef, i64 %4675, i32 0
  %4677 = bitcast <2 x i64> %4676 to <16 x i8>
  %4678 = shufflevector <16 x i8> %4677, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %4679 = icmp sgt <8 x i16> %4671, %3438
  %4680 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4678, <16 x i8> %4667) #11
  %4681 = lshr <8 x i16> %4680, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4682 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4681, <8 x i16> zeroinitializer) #11
  %4683 = select <8 x i1> %4679, <8 x i16> %4638, <8 x i16> %4682
  %4684 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4683, <8 x i16> undef) #11
  %4685 = bitcast <16 x i8> %4684 to <4 x i32>
  %4686 = extractelement <4 x i32> %4685, i32 0
  %4687 = bitcast i8* %4657 to i32*
  store i32 %4686, i32* %4687, align 1
  %4688 = add nuw nsw i32 %4658, 1
  %4689 = getelementptr inbounds i8, i8* %4657, i64 %1
  %4690 = sub i32 %4659, %6
  %4691 = icmp slt i32 %4688, %3434
  br i1 %4691, label %4656, label %4639

4692:                                             ; preds = %4653, %4692
  %4693 = phi i8* [ %4702, %4692 ], [ %4654, %4653 ]
  %4694 = phi i32 [ %4703, %4692 ], [ %4655, %4653 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4693, i8 %4644, i64 4, i1 false) #11
  %4695 = getelementptr inbounds i8, i8* %4693, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4695, i8 %4644, i64 4, i1 false) #11
  %4696 = getelementptr inbounds i8, i8* %4695, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4696, i8 %4644, i64 4, i1 false) #11
  %4697 = getelementptr inbounds i8, i8* %4696, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4697, i8 %4644, i64 4, i1 false) #11
  %4698 = getelementptr inbounds i8, i8* %4697, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4698, i8 %4644, i64 4, i1 false) #11
  %4699 = getelementptr inbounds i8, i8* %4698, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4699, i8 %4644, i64 4, i1 false) #11
  %4700 = getelementptr inbounds i8, i8* %4699, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4700, i8 %4644, i64 4, i1 false) #11
  %4701 = getelementptr inbounds i8, i8* %4700, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4701, i8 %4644, i64 4, i1 false) #11
  %4702 = getelementptr inbounds i8, i8* %4701, i64 %1
  %4703 = add nuw nsw i32 %4694, 8
  %4704 = icmp eq i32 %4703, %5
  br i1 %4704, label %4705, label %4692

4705:                                             ; preds = %4653, %4692, %4639
  %4706 = add nuw nsw i64 %4631, 4
  %4707 = icmp slt i64 %4706, %3440
  br i1 %4707, label %4630, label %7373

4708:                                             ; preds = %2070
  br i1 %8, label %4709, label %6035

4709:                                             ; preds = %4708
  br i1 %2096, label %4710, label %4735

4710:                                             ; preds = %4709
  %4711 = sub nsw i32 0, %2076
  %4712 = trunc i32 %7 to i16
  %4713 = sub i16 0, %4712
  %4714 = insertelement <8 x i16> undef, i16 %4713, i32 0
  %4715 = shufflevector <8 x i16> %4714, <8 x i16> undef, <8 x i32> zeroinitializer
  %4716 = mul <8 x i16> %4715, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %4717 = and i16 %4712, 63
  %4718 = sub nsw i16 0, %4717
  %4719 = insertelement <8 x i16> undef, i16 %4718, i32 0
  %4720 = shufflevector <8 x i16> %4719, <8 x i16> undef, <8 x i32> zeroinitializer
  %4721 = add <8 x i16> %4716, %4720
  %4722 = icmp eq i32 %6, 64
  %4723 = sub <8 x i16> <i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64>, %2088
  %4724 = bitcast <8 x i16> %4723 to <2 x i64>
  %4725 = bitcast <8 x i16> %2088 to <2 x i64>
  %4726 = xor <2 x i64> %4725, <i64 -1, i64 -1>
  %4727 = select i1 %4722, <2 x i64> %4724, <2 x i64> %4726
  %4728 = ashr i32 %2084, 5
  %4729 = icmp sgt i32 %4728, 1
  %4730 = select i1 %4729, i32 %4728, i32 1
  %4731 = sext i32 %5 to i64
  %4732 = sext i32 %2075 to i64
  br label %4762

4733:                                             ; preds = %5949
  %4734 = trunc i64 %4959 to i32
  br label %4735

4735:                                             ; preds = %4733, %4709
  %4736 = phi i32 [ 0, %4709 ], [ %4734, %4733 ]
  %4737 = icmp slt i32 %4736, %4
  br i1 %4737, label %4738, label %7373

4738:                                             ; preds = %4735
  %4739 = shl i32 %5, 1
  %4740 = add i32 %4739, 6
  %4741 = sext i32 %4740 to i64
  %4742 = ashr i32 %2084, 5
  %4743 = icmp sgt i32 %4742, 1
  %4744 = select i1 %4743, i32 %4742, i32 1
  %4745 = sdiv i32 %4740, %4744
  %4746 = icmp sgt i32 %4745, %5
  %4747 = select i1 %4746, i32 %5, i32 %4745
  %4748 = icmp sgt i32 %4747, 0
  %4749 = trunc i32 %4740 to i16
  %4750 = insertelement <8 x i16> undef, i16 %4749, i32 0
  %4751 = shufflevector <8 x i16> %4750, <8 x i16> undef, <8 x i32> zeroinitializer
  %4752 = zext i32 %4736 to i64
  %4753 = sext i32 %4 to i64
  %4754 = icmp sgt i32 %4747, 0
  %4755 = select i1 %4754, i32 %4747, i32 0
  %4756 = sub i32 %5, %4755
  %4757 = xor i32 %4755, -1
  %4758 = add i32 %4757, %5
  %4759 = and i32 %4756, 7
  %4760 = icmp eq i32 %4759, 0
  %4761 = icmp ult i32 %4758, 7
  br label %5955

4762:                                             ; preds = %5949, %4710
  %4763 = phi i64 [ 0, %4710 ], [ %4959, %5949 ]
  %4764 = phi i32 [ %4711, %4710 ], [ %5953, %5949 ]
  %4765 = phi <8 x i16> [ %4721, %4710 ], [ %5952, %5949 ]
  %4766 = phi <2 x i64> [ %4727, %4710 ], [ %5951, %5949 ]
  %4767 = getelementptr inbounds i8, i8* %0, i64 %4763
  %4768 = trunc i64 %4763 to i32
  %4769 = shl i32 %4768, 6
  %4770 = or i32 %4769, 64
  %4771 = sdiv i32 %4770, %6
  %4772 = icmp sgt i32 %4771, %5
  %4773 = select i1 %4772, i32 %5, i32 %4771
  %4774 = and i32 %4773, -8
  %4775 = shl i64 %4763, 33
  %4776 = ashr exact i64 %4775, 32
  %4777 = getelementptr inbounds i8, i8* %19, i64 %4776
  %4778 = shl i32 %4774, 1
  %4779 = or i32 %4778, 6
  %4780 = sext i32 %4779 to i64
  %4781 = getelementptr inbounds i8, i8* %4777, i64 %4780
  %4782 = load i8, i8* %4781, align 2
  %4783 = zext i8 %4782 to i16
  %4784 = insertelement <8 x i16> undef, i16 %4783, i32 0
  %4785 = shufflevector <8 x i16> %4784, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %4786 = sdiv i32 %4779, %4730
  %4787 = icmp sgt i32 %4786, %4774
  %4788 = select i1 %4787, i32 %4774, i32 %4786
  %4789 = icmp sgt i32 %4788, 0
  br i1 %4789, label %4790, label %4794

4790:                                             ; preds = %4762
  %4791 = trunc i32 %4779 to i16
  %4792 = insertelement <8 x i16> undef, i16 %4791, i32 0
  %4793 = shufflevector <8 x i16> %4792, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %4817

4794:                                             ; preds = %4817, %4762
  %4795 = phi i32 [ 0, %4762 ], [ %4788, %4817 ]
  %4796 = phi i8* [ %4767, %4762 ], [ %4849, %4817 ]
  %4797 = icmp sgt i32 %4774, %4795
  br i1 %4797, label %4798, label %4865

4798:                                             ; preds = %4794
  %4799 = load i8, i8* %4781, align 2
  %4800 = sub i32 0, %4795
  %4801 = xor i32 %4795, -1
  %4802 = add i32 %4774, %4801
  %4803 = and i32 %4800, 7
  %4804 = icmp eq i32 %4803, 0
  br i1 %4804, label %4813, label %4805

4805:                                             ; preds = %4798, %4805
  %4806 = phi i8* [ %4809, %4805 ], [ %4796, %4798 ]
  %4807 = phi i32 [ %4810, %4805 ], [ %4795, %4798 ]
  %4808 = phi i32 [ %4811, %4805 ], [ %4803, %4798 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4806, i8 %4799, i64 4, i1 false) #11
  %4809 = getelementptr inbounds i8, i8* %4806, i64 %1
  %4810 = add nuw nsw i32 %4807, 1
  %4811 = add i32 %4808, -1
  %4812 = icmp eq i32 %4811, 0
  br i1 %4812, label %4813, label %4805, !llvm.loop !20

4813:                                             ; preds = %4805, %4798
  %4814 = phi i8* [ %4796, %4798 ], [ %4809, %4805 ]
  %4815 = phi i32 [ %4795, %4798 ], [ %4810, %4805 ]
  %4816 = icmp ult i32 %4802, 7
  br i1 %4816, label %4865, label %4852

4817:                                             ; preds = %4817, %4790
  %4818 = phi i8* [ %4767, %4790 ], [ %4849, %4817 ]
  %4819 = phi i32 [ 0, %4790 ], [ %4848, %4817 ]
  %4820 = phi i32 [ %2084, %4790 ], [ %4850, %4817 ]
  %4821 = ashr i32 %4820, 5
  %4822 = trunc i32 %4820 to i8
  %4823 = and i8 %4822, 31
  %4824 = insertelement <16 x i8> undef, i8 %4823, i32 0
  %4825 = shufflevector <16 x i8> %4824, <16 x i8> undef, <16 x i32> zeroinitializer
  %4826 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4825
  %4827 = shufflevector <16 x i8> %4826, <16 x i8> %4825, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4828 = trunc i32 %4821 to i16
  %4829 = insertelement <8 x i16> undef, i16 %4828, i32 0
  %4830 = shufflevector <8 x i16> %4829, <8 x i16> undef, <8 x i32> zeroinitializer
  %4831 = add <8 x i16> %4830, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %4832 = sext i32 %4821 to i64
  %4833 = getelementptr inbounds i8, i8* %4777, i64 %4832
  %4834 = bitcast i8* %4833 to i64*
  %4835 = load i64, i64* %4834, align 1
  %4836 = insertelement <2 x i64> undef, i64 %4835, i32 0
  %4837 = bitcast <2 x i64> %4836 to <16 x i8>
  %4838 = shufflevector <16 x i8> %4837, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %4839 = icmp sgt <8 x i16> %4831, %4793
  %4840 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4838, <16 x i8> %4827) #11
  %4841 = lshr <8 x i16> %4840, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4842 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4841, <8 x i16> zeroinitializer) #11
  %4843 = select <8 x i1> %4839, <8 x i16> %4785, <8 x i16> %4842
  %4844 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4843, <8 x i16> undef) #11
  %4845 = bitcast <16 x i8> %4844 to <4 x i32>
  %4846 = extractelement <4 x i32> %4845, i32 0
  %4847 = bitcast i8* %4818 to i32*
  store i32 %4846, i32* %4847, align 1
  %4848 = add nuw nsw i32 %4819, 1
  %4849 = getelementptr inbounds i8, i8* %4818, i64 %1
  %4850 = sub i32 %4820, %6
  %4851 = icmp slt i32 %4848, %4788
  br i1 %4851, label %4817, label %4794

4852:                                             ; preds = %4813, %4852
  %4853 = phi i8* [ %4862, %4852 ], [ %4814, %4813 ]
  %4854 = phi i32 [ %4863, %4852 ], [ %4815, %4813 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4853, i8 %4799, i64 4, i1 false) #11
  %4855 = getelementptr inbounds i8, i8* %4853, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4855, i8 %4799, i64 4, i1 false) #11
  %4856 = getelementptr inbounds i8, i8* %4855, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4856, i8 %4799, i64 4, i1 false) #11
  %4857 = getelementptr inbounds i8, i8* %4856, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4857, i8 %4799, i64 4, i1 false) #11
  %4858 = getelementptr inbounds i8, i8* %4857, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4858, i8 %4799, i64 4, i1 false) #11
  %4859 = getelementptr inbounds i8, i8* %4858, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4859, i8 %4799, i64 4, i1 false) #11
  %4860 = getelementptr inbounds i8, i8* %4859, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4860, i8 %4799, i64 4, i1 false) #11
  %4861 = getelementptr inbounds i8, i8* %4860, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4861, i8 %4799, i64 4, i1 false) #11
  %4862 = getelementptr inbounds i8, i8* %4861, i64 %1
  %4863 = add nuw nsw i32 %4854, 8
  %4864 = icmp eq i32 %4863, %4774
  br i1 %4864, label %4865, label %4852

4865:                                             ; preds = %4813, %4852, %4794
  %4866 = getelementptr inbounds i8, i8* %4767, i64 4
  %4867 = shl i32 %4768, 1
  %4868 = or i32 %4867, 8
  %4869 = sext i32 %4868 to i64
  %4870 = getelementptr inbounds i8, i8* %19, i64 %4869
  %4871 = getelementptr inbounds i8, i8* %4870, i64 %4780
  %4872 = load i8, i8* %4871, align 2
  %4873 = zext i8 %4872 to i16
  %4874 = insertelement <8 x i16> undef, i16 %4873, i32 0
  %4875 = shufflevector <8 x i16> %4874, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  br i1 %4789, label %4876, label %4880

4876:                                             ; preds = %4865
  %4877 = trunc i32 %4779 to i16
  %4878 = insertelement <8 x i16> undef, i16 %4877, i32 0
  %4879 = shufflevector <8 x i16> %4878, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %4903

4880:                                             ; preds = %4903, %4865
  %4881 = phi i32 [ 0, %4865 ], [ %4788, %4903 ]
  %4882 = phi i8* [ %4866, %4865 ], [ %4935, %4903 ]
  %4883 = icmp sgt i32 %4774, %4881
  br i1 %4883, label %4884, label %4951

4884:                                             ; preds = %4880
  %4885 = load i8, i8* %4871, align 2
  %4886 = sub i32 0, %4881
  %4887 = xor i32 %4881, -1
  %4888 = add i32 %4774, %4887
  %4889 = and i32 %4886, 7
  %4890 = icmp eq i32 %4889, 0
  br i1 %4890, label %4899, label %4891

4891:                                             ; preds = %4884, %4891
  %4892 = phi i8* [ %4895, %4891 ], [ %4882, %4884 ]
  %4893 = phi i32 [ %4896, %4891 ], [ %4881, %4884 ]
  %4894 = phi i32 [ %4897, %4891 ], [ %4889, %4884 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4892, i8 %4885, i64 4, i1 false) #11
  %4895 = getelementptr inbounds i8, i8* %4892, i64 %1
  %4896 = add nuw nsw i32 %4893, 1
  %4897 = add i32 %4894, -1
  %4898 = icmp eq i32 %4897, 0
  br i1 %4898, label %4899, label %4891, !llvm.loop !21

4899:                                             ; preds = %4891, %4884
  %4900 = phi i8* [ %4882, %4884 ], [ %4895, %4891 ]
  %4901 = phi i32 [ %4881, %4884 ], [ %4896, %4891 ]
  %4902 = icmp ult i32 %4888, 7
  br i1 %4902, label %4951, label %4938

4903:                                             ; preds = %4903, %4876
  %4904 = phi i8* [ %4866, %4876 ], [ %4935, %4903 ]
  %4905 = phi i32 [ 0, %4876 ], [ %4934, %4903 ]
  %4906 = phi i32 [ %2084, %4876 ], [ %4936, %4903 ]
  %4907 = ashr i32 %4906, 5
  %4908 = trunc i32 %4906 to i8
  %4909 = and i8 %4908, 31
  %4910 = insertelement <16 x i8> undef, i8 %4909, i32 0
  %4911 = shufflevector <16 x i8> %4910, <16 x i8> undef, <16 x i32> zeroinitializer
  %4912 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4911
  %4913 = shufflevector <16 x i8> %4912, <16 x i8> %4911, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4914 = trunc i32 %4907 to i16
  %4915 = insertelement <8 x i16> undef, i16 %4914, i32 0
  %4916 = shufflevector <8 x i16> %4915, <8 x i16> undef, <8 x i32> zeroinitializer
  %4917 = add <8 x i16> %4916, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %4918 = sext i32 %4907 to i64
  %4919 = getelementptr inbounds i8, i8* %4870, i64 %4918
  %4920 = bitcast i8* %4919 to i64*
  %4921 = load i64, i64* %4920, align 1
  %4922 = insertelement <2 x i64> undef, i64 %4921, i32 0
  %4923 = bitcast <2 x i64> %4922 to <16 x i8>
  %4924 = shufflevector <16 x i8> %4923, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %4925 = icmp sgt <8 x i16> %4917, %4879
  %4926 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4924, <16 x i8> %4913) #11
  %4927 = lshr <8 x i16> %4926, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4928 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4927, <8 x i16> zeroinitializer) #11
  %4929 = select <8 x i1> %4925, <8 x i16> %4875, <8 x i16> %4928
  %4930 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4929, <8 x i16> undef) #11
  %4931 = bitcast <16 x i8> %4930 to <4 x i32>
  %4932 = extractelement <4 x i32> %4931, i32 0
  %4933 = bitcast i8* %4904 to i32*
  store i32 %4932, i32* %4933, align 1
  %4934 = add nuw nsw i32 %4905, 1
  %4935 = getelementptr inbounds i8, i8* %4904, i64 %1
  %4936 = sub i32 %4906, %6
  %4937 = icmp slt i32 %4934, %4788
  br i1 %4937, label %4903, label %4880

4938:                                             ; preds = %4899, %4938
  %4939 = phi i8* [ %4948, %4938 ], [ %4900, %4899 ]
  %4940 = phi i32 [ %4949, %4938 ], [ %4901, %4899 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4939, i8 %4885, i64 4, i1 false) #11
  %4941 = getelementptr inbounds i8, i8* %4939, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4941, i8 %4885, i64 4, i1 false) #11
  %4942 = getelementptr inbounds i8, i8* %4941, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4942, i8 %4885, i64 4, i1 false) #11
  %4943 = getelementptr inbounds i8, i8* %4942, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4943, i8 %4885, i64 4, i1 false) #11
  %4944 = getelementptr inbounds i8, i8* %4943, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4944, i8 %4885, i64 4, i1 false) #11
  %4945 = getelementptr inbounds i8, i8* %4944, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4945, i8 %4885, i64 4, i1 false) #11
  %4946 = getelementptr inbounds i8, i8* %4945, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4946, i8 %4885, i64 4, i1 false) #11
  %4947 = getelementptr inbounds i8, i8* %4946, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %4947, i8 %4885, i64 4, i1 false) #11
  %4948 = getelementptr inbounds i8, i8* %4947, i64 %1
  %4949 = add nuw nsw i32 %4940, 8
  %4950 = icmp eq i32 %4949, %4774
  br i1 %4950, label %4951, label %4938

4951:                                             ; preds = %4899, %4938, %4880
  %4952 = sext i32 %4774 to i64
  %4953 = mul nsw i64 %4952, %1
  %4954 = getelementptr inbounds i8, i8* %4767, i64 %4953
  %4955 = mul nsw i32 %4774, %6
  %4956 = trunc i32 %4955 to i16
  %4957 = insertelement <8 x i16> undef, i16 %4956, i32 0
  %4958 = shufflevector <8 x i16> %4957, <8 x i16> undef, <8 x i32> zeroinitializer
  %4959 = add nuw nsw i64 %4763, 8
  %4960 = trunc i64 %4959 to i32
  %4961 = shl i32 %4960, 6
  %4962 = sdiv i32 %4961, %6
  %4963 = icmp sgt i32 %4962, %5
  %4964 = select i1 %4963, i32 %5, i32 %4962
  %4965 = icmp slt i32 %4964, %2079
  %4966 = select i1 %4965, i32 %4964, i32 %2079
  %4967 = bitcast <2 x i64> %4766 to <8 x i16>
  %4968 = add <8 x i16> %4958, %4967
  %4969 = sub <8 x i16> %2088, %4958
  %4970 = sub nsw i32 0, %4955
  %4971 = icmp slt i32 %4774, %4966
  br i1 %4971, label %4972, label %5278

4972:                                             ; preds = %4951
  %4973 = ashr <8 x i16> %4765, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %4974 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %4973, <8 x i16> %4973) #11
  %4975 = add <16 x i8> %4974, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %4976 = shufflevector <16 x i8> %4974, <16 x i8> %4975, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4977 = add <16 x i8> %4976, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %4978 = lshr <8 x i16> %4765, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %4979 = and <8 x i16> %4978, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %4980 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4979, <8 x i16> %4979) #11
  %4981 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %4980
  %4982 = shufflevector <16 x i8> %4981, <16 x i8> %4980, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %4983 = sext i32 %4764 to i64
  %4984 = sext i32 %4966 to i64
  br label %4985

4985:                                             ; preds = %4985, %4972
  %4986 = phi i64 [ %4952, %4972 ], [ %5270, %4985 ]
  %4987 = phi i32 [ %4970, %4972 ], [ %5274, %4985 ]
  %4988 = phi <8 x i16> [ %4969, %4972 ], [ %5273, %4985 ]
  %4989 = phi <8 x i16> [ %4968, %4972 ], [ %5272, %4985 ]
  %4990 = phi i8* [ %4954, %4972 ], [ %5271, %4985 ]
  %4991 = add nsw i64 %4986, %4983
  %4992 = getelementptr inbounds i8, i8* %20, i64 %4991
  %4993 = getelementptr inbounds i8, i8* %4992, i64 -15
  %4994 = bitcast i8* %4993 to <16 x i8>*
  %4995 = load <16 x i8>, <16 x i8>* %4994, align 1
  %4996 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %4995, <16 x i8> %4977) #11
  %4997 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %4996, <16 x i8> %4982) #11
  %4998 = lshr <8 x i16> %4997, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %4999 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %4998, <8 x i16> zeroinitializer) #11
  %5000 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %4999, <8 x i16> undef) #11
  %5001 = bitcast <16 x i8> %5000 to <2 x i64>
  %5002 = extractelement <2 x i64> %5001, i32 0
  %5003 = bitcast i8* %4990 to i64*
  store i64 %5002, i64* %5003, align 1
  %5004 = getelementptr inbounds i8, i8* %4990, i64 %1
  %5005 = getelementptr inbounds i8, i8* %4992, i64 -14
  %5006 = bitcast i8* %5005 to <16 x i8>*
  %5007 = load <16 x i8>, <16 x i8>* %5006, align 1
  %5008 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %5007, <16 x i8> %4977) #11
  %5009 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5008, <16 x i8> %4982) #11
  %5010 = lshr <8 x i16> %5009, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5011 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5010, <8 x i16> zeroinitializer) #11
  %5012 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5011, <8 x i16> undef) #11
  %5013 = bitcast <16 x i8> %5012 to <2 x i64>
  %5014 = extractelement <2 x i64> %5013, i32 0
  %5015 = bitcast i8* %5004 to i64*
  store i64 %5014, i64* %5015, align 1
  %5016 = getelementptr inbounds i8, i8* %5004, i64 %1
  %5017 = getelementptr inbounds i8, i8* %4992, i64 -13
  %5018 = bitcast i8* %5017 to <16 x i8>*
  %5019 = load <16 x i8>, <16 x i8>* %5018, align 1
  %5020 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %5019, <16 x i8> %4977) #11
  %5021 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5020, <16 x i8> %4982) #11
  %5022 = lshr <8 x i16> %5021, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5023 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5022, <8 x i16> zeroinitializer) #11
  %5024 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5023, <8 x i16> undef) #11
  %5025 = bitcast <16 x i8> %5024 to <2 x i64>
  %5026 = extractelement <2 x i64> %5025, i32 0
  %5027 = bitcast i8* %5016 to i64*
  store i64 %5026, i64* %5027, align 1
  %5028 = getelementptr inbounds i8, i8* %5016, i64 %1
  %5029 = getelementptr inbounds i8, i8* %4992, i64 -12
  %5030 = bitcast i8* %5029 to <16 x i8>*
  %5031 = load <16 x i8>, <16 x i8>* %5030, align 1
  %5032 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %5031, <16 x i8> %4977) #11
  %5033 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5032, <16 x i8> %4982) #11
  %5034 = lshr <8 x i16> %5033, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5035 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5034, <8 x i16> zeroinitializer) #11
  %5036 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5035, <8 x i16> undef) #11
  %5037 = bitcast <16 x i8> %5036 to <2 x i64>
  %5038 = extractelement <2 x i64> %5037, i32 0
  %5039 = bitcast i8* %5028 to i64*
  store i64 %5038, i64* %5039, align 1
  %5040 = getelementptr inbounds i8, i8* %5028, i64 %1
  %5041 = getelementptr inbounds i8, i8* %4992, i64 -11
  %5042 = bitcast i8* %5041 to <16 x i8>*
  %5043 = load <16 x i8>, <16 x i8>* %5042, align 1
  %5044 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %5043, <16 x i8> %4977) #11
  %5045 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5044, <16 x i8> %4982) #11
  %5046 = lshr <8 x i16> %5045, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5047 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5046, <8 x i16> zeroinitializer) #11
  %5048 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5047, <8 x i16> undef) #11
  %5049 = bitcast <16 x i8> %5048 to <2 x i64>
  %5050 = extractelement <2 x i64> %5049, i32 0
  %5051 = bitcast i8* %5040 to i64*
  store i64 %5050, i64* %5051, align 1
  %5052 = getelementptr inbounds i8, i8* %5040, i64 %1
  %5053 = getelementptr inbounds i8, i8* %4992, i64 -10
  %5054 = bitcast i8* %5053 to <16 x i8>*
  %5055 = load <16 x i8>, <16 x i8>* %5054, align 1
  %5056 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %5055, <16 x i8> %4977) #11
  %5057 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5056, <16 x i8> %4982) #11
  %5058 = lshr <8 x i16> %5057, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5059 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5058, <8 x i16> zeroinitializer) #11
  %5060 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5059, <8 x i16> undef) #11
  %5061 = bitcast <16 x i8> %5060 to <2 x i64>
  %5062 = extractelement <2 x i64> %5061, i32 0
  %5063 = bitcast i8* %5052 to i64*
  store i64 %5062, i64* %5063, align 1
  %5064 = getelementptr inbounds i8, i8* %5052, i64 %1
  %5065 = getelementptr inbounds i8, i8* %4992, i64 -9
  %5066 = bitcast i8* %5065 to <16 x i8>*
  %5067 = load <16 x i8>, <16 x i8>* %5066, align 1
  %5068 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %5067, <16 x i8> %4977) #11
  %5069 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5068, <16 x i8> %4982) #11
  %5070 = lshr <8 x i16> %5069, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5071 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5070, <8 x i16> zeroinitializer) #11
  %5072 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5071, <8 x i16> undef) #11
  %5073 = bitcast <16 x i8> %5072 to <2 x i64>
  %5074 = extractelement <2 x i64> %5073, i32 0
  %5075 = bitcast i8* %5064 to i64*
  store i64 %5074, i64* %5075, align 1
  %5076 = getelementptr inbounds i8, i8* %5064, i64 %1
  %5077 = getelementptr inbounds i8, i8* %4992, i64 -8
  %5078 = bitcast i8* %5077 to <16 x i8>*
  %5079 = load <16 x i8>, <16 x i8>* %5078, align 1
  %5080 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %5079, <16 x i8> %4977) #11
  %5081 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5080, <16 x i8> %4982) #11
  %5082 = lshr <8 x i16> %5081, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5083 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5082, <8 x i16> zeroinitializer) #11
  %5084 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5083, <8 x i16> undef) #11
  %5085 = bitcast <16 x i8> %5084 to <2 x i64>
  %5086 = extractelement <2 x i64> %5085, i32 0
  %5087 = bitcast i8* %5076 to i64*
  store i64 %5086, i64* %5087, align 1
  %5088 = and <8 x i16> %4988, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %5089 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5088, <8 x i16> %5088) #11
  %5090 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5089
  %5091 = shufflevector <16 x i8> %5090, <16 x i8> %5089, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5092 = ashr <8 x i16> %4989, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %5093 = bitcast <8 x i16> %5092 to <16 x i8>
  %5094 = sub nsw i32 %4987, %6
  %5095 = ashr i32 %5094, 5
  %5096 = sext i32 %5095 to i64
  %5097 = getelementptr inbounds i8, i8* %4777, i64 %5096
  %5098 = shufflevector <16 x i8> %5091, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %5099 = bitcast i8* %5097 to <16 x i8>*
  %5100 = load <16 x i8>, <16 x i8>* %5099, align 1
  %5101 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5100, <16 x i8> %5098) #11
  %5102 = lshr <8 x i16> %5101, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5103 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5102, <8 x i16> zeroinitializer) #11
  %5104 = shufflevector <16 x i8> %5093, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %5105 = bitcast <16 x i8> %5104 to <8 x i16>
  %5106 = icmp sgt <8 x i16> %5105, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5107 = load i64, i64* %5003, align 1
  %5108 = insertelement <2 x i64> undef, i64 %5107, i32 0
  %5109 = bitcast <2 x i64> %5108 to <16 x i8>
  %5110 = shufflevector <16 x i8> %5109, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5111 = zext <8 x i8> %5110 to <8 x i16>
  %5112 = select <8 x i1> %5106, <8 x i16> %5111, <8 x i16> %5103
  %5113 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5112, <8 x i16> undef) #11
  %5114 = bitcast <16 x i8> %5113 to <2 x i64>
  %5115 = extractelement <2 x i64> %5114, i32 0
  store i64 %5115, i64* %5003, align 1
  %5116 = sub nsw i32 %5094, %6
  %5117 = ashr i32 %5116, 5
  %5118 = sext i32 %5117 to i64
  %5119 = getelementptr inbounds i8, i8* %4777, i64 %5118
  %5120 = shufflevector <16 x i8> %5091, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %5121 = bitcast i8* %5119 to <16 x i8>*
  %5122 = load <16 x i8>, <16 x i8>* %5121, align 1
  %5123 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5122, <16 x i8> %5120) #11
  %5124 = lshr <8 x i16> %5123, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5125 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5124, <8 x i16> zeroinitializer) #11
  %5126 = shufflevector <16 x i8> %5093, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %5127 = bitcast <16 x i8> %5126 to <8 x i16>
  %5128 = icmp sgt <8 x i16> %5127, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5129 = load i64, i64* %5015, align 1
  %5130 = insertelement <2 x i64> undef, i64 %5129, i32 0
  %5131 = bitcast <2 x i64> %5130 to <16 x i8>
  %5132 = shufflevector <16 x i8> %5131, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5133 = zext <8 x i8> %5132 to <8 x i16>
  %5134 = select <8 x i1> %5128, <8 x i16> %5133, <8 x i16> %5125
  %5135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5134, <8 x i16> undef) #11
  %5136 = bitcast <16 x i8> %5135 to <2 x i64>
  %5137 = extractelement <2 x i64> %5136, i32 0
  store i64 %5137, i64* %5015, align 1
  %5138 = sub nsw i32 %5116, %6
  %5139 = ashr i32 %5138, 5
  %5140 = sext i32 %5139 to i64
  %5141 = getelementptr inbounds i8, i8* %4777, i64 %5140
  %5142 = shufflevector <16 x i8> %5091, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %5143 = bitcast i8* %5141 to <16 x i8>*
  %5144 = load <16 x i8>, <16 x i8>* %5143, align 1
  %5145 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5144, <16 x i8> %5142) #11
  %5146 = lshr <8 x i16> %5145, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5147 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5146, <8 x i16> zeroinitializer) #11
  %5148 = shufflevector <16 x i8> %5093, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %5149 = bitcast <16 x i8> %5148 to <8 x i16>
  %5150 = icmp sgt <8 x i16> %5149, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5151 = load i64, i64* %5027, align 1
  %5152 = insertelement <2 x i64> undef, i64 %5151, i32 0
  %5153 = bitcast <2 x i64> %5152 to <16 x i8>
  %5154 = shufflevector <16 x i8> %5153, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5155 = zext <8 x i8> %5154 to <8 x i16>
  %5156 = select <8 x i1> %5150, <8 x i16> %5155, <8 x i16> %5147
  %5157 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5156, <8 x i16> undef) #11
  %5158 = bitcast <16 x i8> %5157 to <2 x i64>
  %5159 = extractelement <2 x i64> %5158, i32 0
  store i64 %5159, i64* %5027, align 1
  %5160 = sub nsw i32 %5138, %6
  %5161 = ashr i32 %5160, 5
  %5162 = sext i32 %5161 to i64
  %5163 = getelementptr inbounds i8, i8* %4777, i64 %5162
  %5164 = shufflevector <16 x i8> %5091, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %5165 = bitcast i8* %5163 to <16 x i8>*
  %5166 = load <16 x i8>, <16 x i8>* %5165, align 1
  %5167 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5166, <16 x i8> %5164) #11
  %5168 = lshr <8 x i16> %5167, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5169 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5168, <8 x i16> zeroinitializer) #11
  %5170 = shufflevector <16 x i8> %5093, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %5171 = bitcast <16 x i8> %5170 to <8 x i16>
  %5172 = icmp sgt <8 x i16> %5171, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5173 = load i64, i64* %5039, align 1
  %5174 = insertelement <2 x i64> undef, i64 %5173, i32 0
  %5175 = bitcast <2 x i64> %5174 to <16 x i8>
  %5176 = shufflevector <16 x i8> %5175, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5177 = zext <8 x i8> %5176 to <8 x i16>
  %5178 = select <8 x i1> %5172, <8 x i16> %5177, <8 x i16> %5169
  %5179 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5178, <8 x i16> undef) #11
  %5180 = bitcast <16 x i8> %5179 to <2 x i64>
  %5181 = extractelement <2 x i64> %5180, i32 0
  store i64 %5181, i64* %5039, align 1
  %5182 = sub nsw i32 %5160, %6
  %5183 = ashr i32 %5182, 5
  %5184 = sext i32 %5183 to i64
  %5185 = getelementptr inbounds i8, i8* %4777, i64 %5184
  %5186 = shufflevector <16 x i8> %5091, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %5187 = bitcast i8* %5185 to <16 x i8>*
  %5188 = load <16 x i8>, <16 x i8>* %5187, align 1
  %5189 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5188, <16 x i8> %5186) #11
  %5190 = lshr <8 x i16> %5189, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5191 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5190, <8 x i16> zeroinitializer) #11
  %5192 = shufflevector <16 x i8> %5093, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %5193 = bitcast <16 x i8> %5192 to <8 x i16>
  %5194 = icmp sgt <8 x i16> %5193, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5195 = load i64, i64* %5051, align 1
  %5196 = insertelement <2 x i64> undef, i64 %5195, i32 0
  %5197 = bitcast <2 x i64> %5196 to <16 x i8>
  %5198 = shufflevector <16 x i8> %5197, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5199 = zext <8 x i8> %5198 to <8 x i16>
  %5200 = select <8 x i1> %5194, <8 x i16> %5199, <8 x i16> %5191
  %5201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5200, <8 x i16> undef) #11
  %5202 = bitcast <16 x i8> %5201 to <2 x i64>
  %5203 = extractelement <2 x i64> %5202, i32 0
  store i64 %5203, i64* %5051, align 1
  %5204 = sub nsw i32 %5182, %6
  %5205 = ashr i32 %5204, 5
  %5206 = sext i32 %5205 to i64
  %5207 = getelementptr inbounds i8, i8* %4777, i64 %5206
  %5208 = shufflevector <16 x i8> %5091, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %5209 = bitcast i8* %5207 to <16 x i8>*
  %5210 = load <16 x i8>, <16 x i8>* %5209, align 1
  %5211 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5210, <16 x i8> %5208) #11
  %5212 = lshr <8 x i16> %5211, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5213 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5212, <8 x i16> zeroinitializer) #11
  %5214 = shufflevector <16 x i8> %5093, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %5215 = bitcast <16 x i8> %5214 to <8 x i16>
  %5216 = icmp sgt <8 x i16> %5215, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5217 = load i64, i64* %5063, align 1
  %5218 = insertelement <2 x i64> undef, i64 %5217, i32 0
  %5219 = bitcast <2 x i64> %5218 to <16 x i8>
  %5220 = shufflevector <16 x i8> %5219, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5221 = zext <8 x i8> %5220 to <8 x i16>
  %5222 = select <8 x i1> %5216, <8 x i16> %5221, <8 x i16> %5213
  %5223 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5222, <8 x i16> undef) #11
  %5224 = bitcast <16 x i8> %5223 to <2 x i64>
  %5225 = extractelement <2 x i64> %5224, i32 0
  store i64 %5225, i64* %5063, align 1
  %5226 = sub nsw i32 %5204, %6
  %5227 = ashr i32 %5226, 5
  %5228 = sext i32 %5227 to i64
  %5229 = getelementptr inbounds i8, i8* %4777, i64 %5228
  %5230 = shufflevector <16 x i8> %5091, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %5231 = bitcast i8* %5229 to <16 x i8>*
  %5232 = load <16 x i8>, <16 x i8>* %5231, align 1
  %5233 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5232, <16 x i8> %5230) #11
  %5234 = lshr <8 x i16> %5233, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5235 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5234, <8 x i16> zeroinitializer) #11
  %5236 = shufflevector <16 x i8> %5093, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %5237 = bitcast <16 x i8> %5236 to <8 x i16>
  %5238 = icmp sgt <8 x i16> %5237, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5239 = load i64, i64* %5075, align 1
  %5240 = insertelement <2 x i64> undef, i64 %5239, i32 0
  %5241 = bitcast <2 x i64> %5240 to <16 x i8>
  %5242 = shufflevector <16 x i8> %5241, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5243 = zext <8 x i8> %5242 to <8 x i16>
  %5244 = select <8 x i1> %5238, <8 x i16> %5243, <8 x i16> %5235
  %5245 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5244, <8 x i16> undef) #11
  %5246 = bitcast <16 x i8> %5245 to <2 x i64>
  %5247 = extractelement <2 x i64> %5246, i32 0
  store i64 %5247, i64* %5075, align 1
  %5248 = sub nsw i32 %5226, %6
  %5249 = ashr i32 %5248, 5
  %5250 = sext i32 %5249 to i64
  %5251 = getelementptr inbounds i8, i8* %4777, i64 %5250
  %5252 = shufflevector <16 x i8> %5091, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %5253 = bitcast i8* %5251 to <16 x i8>*
  %5254 = load <16 x i8>, <16 x i8>* %5253, align 1
  %5255 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5254, <16 x i8> %5252) #11
  %5256 = lshr <8 x i16> %5255, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5257 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5256, <8 x i16> zeroinitializer) #11
  %5258 = shufflevector <16 x i8> %5093, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %5259 = bitcast <16 x i8> %5258 to <8 x i16>
  %5260 = icmp sgt <8 x i16> %5259, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5261 = load i64, i64* %5087, align 1
  %5262 = insertelement <2 x i64> undef, i64 %5261, i32 0
  %5263 = bitcast <2 x i64> %5262 to <16 x i8>
  %5264 = shufflevector <16 x i8> %5263, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5265 = zext <8 x i8> %5264 to <8 x i16>
  %5266 = select <8 x i1> %5260, <8 x i16> %5265, <8 x i16> %5257
  %5267 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5266, <8 x i16> undef) #11
  %5268 = bitcast <16 x i8> %5267 to <2 x i64>
  %5269 = extractelement <2 x i64> %5268, i32 0
  store i64 %5269, i64* %5087, align 1
  %5270 = add nsw i64 %4986, 8
  %5271 = getelementptr inbounds i8, i8* %4990, i64 %2071
  %5272 = add <8 x i16> %4989, %2083
  %5273 = sub <8 x i16> %4988, %2083
  %5274 = sub nsw i32 %4987, %2080
  %5275 = icmp slt i64 %5270, %4984
  br i1 %5275, label %4985, label %5276

5276:                                             ; preds = %4985
  %5277 = trunc i64 %5270 to i32
  br label %5278

5278:                                             ; preds = %5276, %4951
  %5279 = phi i8* [ %4954, %4951 ], [ %5271, %5276 ]
  %5280 = phi i32 [ %4774, %4951 ], [ %5277, %5276 ]
  %5281 = phi <8 x i16> [ %4968, %4951 ], [ %5272, %5276 ]
  %5282 = phi <8 x i16> [ %4969, %4951 ], [ %5273, %5276 ]
  %5283 = phi i32 [ %4970, %4951 ], [ %5274, %5276 ]
  %5284 = extractelement <8 x i16> %4765, i64 0
  %5285 = icmp slt i32 %5280, %4964
  br i1 %5285, label %5286, label %5372

5286:                                             ; preds = %5278
  %5287 = sext i16 %5284 to i32
  %5288 = ashr i32 %5287, 6
  %5289 = lshr i32 %5287, 1
  %5290 = trunc i32 %5289 to i8
  %5291 = and i8 %5290, 31
  %5292 = insertelement <16 x i8> undef, i8 %5291, i32 0
  %5293 = shufflevector <16 x i8> %5292, <16 x i8> undef, <16 x i32> zeroinitializer
  %5294 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5293
  %5295 = shufflevector <16 x i8> %5294, <16 x i8> %5293, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5296 = sext i32 %5288 to i64
  %5297 = sub i32 %5287, %7
  %5298 = ashr i32 %5297, 6
  %5299 = lshr i32 %5297, 1
  %5300 = trunc i32 %5299 to i8
  %5301 = and i8 %5300, 31
  %5302 = insertelement <16 x i8> undef, i8 %5301, i32 0
  %5303 = shufflevector <16 x i8> %5302, <16 x i8> undef, <16 x i32> zeroinitializer
  %5304 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5303
  %5305 = shufflevector <16 x i8> %5304, <16 x i8> %5303, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5306 = sext i32 %5298 to i64
  %5307 = sub i32 %5297, %7
  %5308 = ashr i32 %5307, 6
  %5309 = lshr i32 %5307, 1
  %5310 = trunc i32 %5309 to i8
  %5311 = and i8 %5310, 31
  %5312 = insertelement <16 x i8> undef, i8 %5311, i32 0
  %5313 = shufflevector <16 x i8> %5312, <16 x i8> undef, <16 x i32> zeroinitializer
  %5314 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5313
  %5315 = shufflevector <16 x i8> %5314, <16 x i8> %5313, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5316 = sext i32 %5308 to i64
  %5317 = sub i32 %5307, %7
  %5318 = ashr i32 %5317, 6
  %5319 = lshr i32 %5317, 1
  %5320 = trunc i32 %5319 to i8
  %5321 = and i8 %5320, 31
  %5322 = insertelement <16 x i8> undef, i8 %5321, i32 0
  %5323 = shufflevector <16 x i8> %5322, <16 x i8> undef, <16 x i32> zeroinitializer
  %5324 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5323
  %5325 = shufflevector <16 x i8> %5324, <16 x i8> %5323, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5326 = sext i32 %5318 to i64
  %5327 = sub i32 %5317, %7
  %5328 = ashr i32 %5327, 6
  %5329 = lshr i32 %5327, 1
  %5330 = trunc i32 %5329 to i8
  %5331 = and i8 %5330, 31
  %5332 = insertelement <16 x i8> undef, i8 %5331, i32 0
  %5333 = shufflevector <16 x i8> %5332, <16 x i8> undef, <16 x i32> zeroinitializer
  %5334 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5333
  %5335 = shufflevector <16 x i8> %5334, <16 x i8> %5333, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5336 = sext i32 %5328 to i64
  %5337 = sub i32 %5327, %7
  %5338 = ashr i32 %5337, 6
  %5339 = lshr i32 %5337, 1
  %5340 = trunc i32 %5339 to i8
  %5341 = and i8 %5340, 31
  %5342 = insertelement <16 x i8> undef, i8 %5341, i32 0
  %5343 = shufflevector <16 x i8> %5342, <16 x i8> undef, <16 x i32> zeroinitializer
  %5344 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5343
  %5345 = shufflevector <16 x i8> %5344, <16 x i8> %5343, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5346 = sext i32 %5338 to i64
  %5347 = sub i32 %5337, %7
  %5348 = ashr i32 %5347, 6
  %5349 = lshr i32 %5347, 1
  %5350 = trunc i32 %5349 to i8
  %5351 = and i8 %5350, 31
  %5352 = insertelement <16 x i8> undef, i8 %5351, i32 0
  %5353 = shufflevector <16 x i8> %5352, <16 x i8> undef, <16 x i32> zeroinitializer
  %5354 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5353
  %5355 = shufflevector <16 x i8> %5354, <16 x i8> %5353, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5356 = sext i32 %5348 to i64
  %5357 = sub i32 %5347, %7
  %5358 = ashr i32 %5357, 6
  %5359 = lshr i32 %5357, 1
  %5360 = trunc i32 %5359 to i8
  %5361 = and i8 %5360, 31
  %5362 = insertelement <16 x i8> undef, i8 %5361, i32 0
  %5363 = shufflevector <16 x i8> %5362, <16 x i8> undef, <16 x i32> zeroinitializer
  %5364 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5363
  %5365 = shufflevector <16 x i8> %5364, <16 x i8> %5363, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5366 = sext i32 %5358 to i64
  %5367 = sext i32 %5280 to i64
  %5368 = sext i32 %4764 to i64
  %5369 = sext i32 %4964 to i64
  br label %5459

5370:                                             ; preds = %5459
  %5371 = trunc i64 %5792 to i32
  br label %5372

5372:                                             ; preds = %5370, %5278
  %5373 = phi i8* [ %5279, %5278 ], [ %5793, %5370 ]
  %5374 = phi i32 [ %5280, %5278 ], [ %5371, %5370 ]
  %5375 = icmp slt i32 %5374, %5
  br i1 %5375, label %5376, label %5949

5376:                                             ; preds = %5372
  %5377 = sext i16 %5284 to i32
  %5378 = ashr i32 %5377, 6
  %5379 = lshr i32 %5377, 1
  %5380 = trunc i32 %5379 to i8
  %5381 = and i8 %5380, 31
  %5382 = insertelement <16 x i8> undef, i8 %5381, i32 0
  %5383 = shufflevector <16 x i8> %5382, <16 x i8> undef, <16 x i32> zeroinitializer
  %5384 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5383
  %5385 = shufflevector <16 x i8> %5384, <16 x i8> %5383, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5386 = sext i32 %5378 to i64
  %5387 = sub i32 %5377, %7
  %5388 = ashr i32 %5387, 6
  %5389 = lshr i32 %5387, 1
  %5390 = trunc i32 %5389 to i8
  %5391 = and i8 %5390, 31
  %5392 = insertelement <16 x i8> undef, i8 %5391, i32 0
  %5393 = shufflevector <16 x i8> %5392, <16 x i8> undef, <16 x i32> zeroinitializer
  %5394 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5393
  %5395 = shufflevector <16 x i8> %5394, <16 x i8> %5393, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5396 = sext i32 %5388 to i64
  %5397 = sub i32 %5387, %7
  %5398 = ashr i32 %5397, 6
  %5399 = lshr i32 %5397, 1
  %5400 = trunc i32 %5399 to i8
  %5401 = and i8 %5400, 31
  %5402 = insertelement <16 x i8> undef, i8 %5401, i32 0
  %5403 = shufflevector <16 x i8> %5402, <16 x i8> undef, <16 x i32> zeroinitializer
  %5404 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5403
  %5405 = shufflevector <16 x i8> %5404, <16 x i8> %5403, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5406 = sext i32 %5398 to i64
  %5407 = sub i32 %5397, %7
  %5408 = ashr i32 %5407, 6
  %5409 = lshr i32 %5407, 1
  %5410 = trunc i32 %5409 to i8
  %5411 = and i8 %5410, 31
  %5412 = insertelement <16 x i8> undef, i8 %5411, i32 0
  %5413 = shufflevector <16 x i8> %5412, <16 x i8> undef, <16 x i32> zeroinitializer
  %5414 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5413
  %5415 = shufflevector <16 x i8> %5414, <16 x i8> %5413, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5416 = sext i32 %5408 to i64
  %5417 = sub i32 %5407, %7
  %5418 = ashr i32 %5417, 6
  %5419 = lshr i32 %5417, 1
  %5420 = trunc i32 %5419 to i8
  %5421 = and i8 %5420, 31
  %5422 = insertelement <16 x i8> undef, i8 %5421, i32 0
  %5423 = shufflevector <16 x i8> %5422, <16 x i8> undef, <16 x i32> zeroinitializer
  %5424 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5423
  %5425 = shufflevector <16 x i8> %5424, <16 x i8> %5423, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5426 = sext i32 %5418 to i64
  %5427 = sub i32 %5417, %7
  %5428 = ashr i32 %5427, 6
  %5429 = lshr i32 %5427, 1
  %5430 = trunc i32 %5429 to i8
  %5431 = and i8 %5430, 31
  %5432 = insertelement <16 x i8> undef, i8 %5431, i32 0
  %5433 = shufflevector <16 x i8> %5432, <16 x i8> undef, <16 x i32> zeroinitializer
  %5434 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5433
  %5435 = shufflevector <16 x i8> %5434, <16 x i8> %5433, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5436 = sext i32 %5428 to i64
  %5437 = sub i32 %5427, %7
  %5438 = ashr i32 %5437, 6
  %5439 = lshr i32 %5437, 1
  %5440 = trunc i32 %5439 to i8
  %5441 = and i8 %5440, 31
  %5442 = insertelement <16 x i8> undef, i8 %5441, i32 0
  %5443 = shufflevector <16 x i8> %5442, <16 x i8> undef, <16 x i32> zeroinitializer
  %5444 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5443
  %5445 = shufflevector <16 x i8> %5444, <16 x i8> %5443, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5446 = sext i32 %5438 to i64
  %5447 = sub i32 %5437, %7
  %5448 = ashr i32 %5447, 6
  %5449 = lshr i32 %5447, 1
  %5450 = trunc i32 %5449 to i8
  %5451 = and i8 %5450, 31
  %5452 = insertelement <16 x i8> undef, i8 %5451, i32 0
  %5453 = shufflevector <16 x i8> %5452, <16 x i8> undef, <16 x i32> zeroinitializer
  %5454 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5453
  %5455 = shufflevector <16 x i8> %5454, <16 x i8> %5453, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5456 = sext i32 %5448 to i64
  %5457 = sext i32 %5374 to i64
  %5458 = sext i32 %4764 to i64
  br label %5798

5459:                                             ; preds = %5459, %5286
  %5460 = phi i64 [ %5367, %5286 ], [ %5792, %5459 ]
  %5461 = phi i32 [ %5283, %5286 ], [ %5796, %5459 ]
  %5462 = phi <8 x i16> [ %5282, %5286 ], [ %5795, %5459 ]
  %5463 = phi <8 x i16> [ %5281, %5286 ], [ %5794, %5459 ]
  %5464 = phi i8* [ %5279, %5286 ], [ %5793, %5459 ]
  %5465 = ashr <8 x i16> %5463, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %5466 = add nsw i64 %5460, %5368
  %5467 = getelementptr inbounds i8, i8* %20, i64 %5466
  %5468 = getelementptr inbounds i8, i8* %5467, i64 %5296
  %5469 = bitcast i8* %5468 to <16 x i8>*
  %5470 = load <16 x i8>, <16 x i8>* %5469, align 1
  %5471 = shufflevector <16 x i8> %5470, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5472 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5471, <16 x i8> %5295) #11
  %5473 = lshr <8 x i16> %5472, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5474 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5473, <8 x i16> zeroinitializer) #11
  %5475 = getelementptr inbounds i8, i8* %5467, i64 %5306
  %5476 = bitcast i8* %5475 to <16 x i8>*
  %5477 = load <16 x i8>, <16 x i8>* %5476, align 1
  %5478 = shufflevector <16 x i8> %5477, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5479 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5478, <16 x i8> %5305) #11
  %5480 = lshr <8 x i16> %5479, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5481 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5480, <8 x i16> zeroinitializer) #11
  %5482 = getelementptr inbounds i8, i8* %5467, i64 %5316
  %5483 = bitcast i8* %5482 to <16 x i8>*
  %5484 = load <16 x i8>, <16 x i8>* %5483, align 1
  %5485 = shufflevector <16 x i8> %5484, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5486 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5485, <16 x i8> %5315) #11
  %5487 = lshr <8 x i16> %5486, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5488 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5487, <8 x i16> zeroinitializer) #11
  %5489 = getelementptr inbounds i8, i8* %5467, i64 %5326
  %5490 = bitcast i8* %5489 to <16 x i8>*
  %5491 = load <16 x i8>, <16 x i8>* %5490, align 1
  %5492 = shufflevector <16 x i8> %5491, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5493 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5492, <16 x i8> %5325) #11
  %5494 = lshr <8 x i16> %5493, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5495 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5494, <8 x i16> zeroinitializer) #11
  %5496 = getelementptr inbounds i8, i8* %5467, i64 %5336
  %5497 = bitcast i8* %5496 to <16 x i8>*
  %5498 = load <16 x i8>, <16 x i8>* %5497, align 1
  %5499 = shufflevector <16 x i8> %5498, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5500 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5499, <16 x i8> %5335) #11
  %5501 = lshr <8 x i16> %5500, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5502 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5501, <8 x i16> zeroinitializer) #11
  %5503 = getelementptr inbounds i8, i8* %5467, i64 %5346
  %5504 = bitcast i8* %5503 to <16 x i8>*
  %5505 = load <16 x i8>, <16 x i8>* %5504, align 1
  %5506 = shufflevector <16 x i8> %5505, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5507 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5506, <16 x i8> %5345) #11
  %5508 = lshr <8 x i16> %5507, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5509 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5508, <8 x i16> zeroinitializer) #11
  %5510 = getelementptr inbounds i8, i8* %5467, i64 %5356
  %5511 = bitcast i8* %5510 to <16 x i8>*
  %5512 = load <16 x i8>, <16 x i8>* %5511, align 1
  %5513 = shufflevector <16 x i8> %5512, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5514 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5513, <16 x i8> %5355) #11
  %5515 = lshr <8 x i16> %5514, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5516 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5515, <8 x i16> zeroinitializer) #11
  %5517 = getelementptr inbounds i8, i8* %5467, i64 %5366
  %5518 = bitcast i8* %5517 to <16 x i8>*
  %5519 = load <16 x i8>, <16 x i8>* %5518, align 1
  %5520 = shufflevector <16 x i8> %5519, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5521 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5520, <16 x i8> %5365) #11
  %5522 = lshr <8 x i16> %5521, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5523 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5522, <8 x i16> zeroinitializer) #11
  %5524 = shufflevector <8 x i16> %5474, <8 x i16> %5481, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5525 = shufflevector <8 x i16> %5488, <8 x i16> %5495, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5526 = shufflevector <8 x i16> %5502, <8 x i16> %5509, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5527 = shufflevector <8 x i16> %5516, <8 x i16> %5523, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5528 = shufflevector <8 x i16> %5474, <8 x i16> %5481, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5529 = shufflevector <8 x i16> %5488, <8 x i16> %5495, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5530 = shufflevector <8 x i16> %5502, <8 x i16> %5509, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5531 = shufflevector <8 x i16> %5516, <8 x i16> %5523, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5532 = bitcast <8 x i16> %5524 to <4 x i32>
  %5533 = bitcast <8 x i16> %5525 to <4 x i32>
  %5534 = shufflevector <4 x i32> %5532, <4 x i32> %5533, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5535 = bitcast <4 x i32> %5534 to <2 x i64>
  %5536 = bitcast <8 x i16> %5526 to <4 x i32>
  %5537 = bitcast <8 x i16> %5527 to <4 x i32>
  %5538 = shufflevector <4 x i32> %5536, <4 x i32> %5537, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5539 = bitcast <4 x i32> %5538 to <2 x i64>
  %5540 = bitcast <8 x i16> %5528 to <4 x i32>
  %5541 = bitcast <8 x i16> %5529 to <4 x i32>
  %5542 = shufflevector <4 x i32> %5540, <4 x i32> %5541, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5543 = bitcast <4 x i32> %5542 to <2 x i64>
  %5544 = bitcast <8 x i16> %5530 to <4 x i32>
  %5545 = bitcast <8 x i16> %5531 to <4 x i32>
  %5546 = shufflevector <4 x i32> %5544, <4 x i32> %5545, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5547 = bitcast <4 x i32> %5546 to <2 x i64>
  %5548 = shufflevector <4 x i32> %5532, <4 x i32> %5533, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5549 = bitcast <4 x i32> %5548 to <2 x i64>
  %5550 = shufflevector <4 x i32> %5536, <4 x i32> %5537, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5551 = bitcast <4 x i32> %5550 to <2 x i64>
  %5552 = shufflevector <4 x i32> %5540, <4 x i32> %5541, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5553 = bitcast <4 x i32> %5552 to <2 x i64>
  %5554 = shufflevector <4 x i32> %5544, <4 x i32> %5545, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5555 = bitcast <4 x i32> %5554 to <2 x i64>
  %5556 = shufflevector <2 x i64> %5535, <2 x i64> %5539, <2 x i32> <i32 0, i32 2>
  %5557 = shufflevector <2 x i64> %5535, <2 x i64> %5539, <2 x i32> <i32 1, i32 3>
  %5558 = shufflevector <2 x i64> %5549, <2 x i64> %5551, <2 x i32> <i32 0, i32 2>
  %5559 = shufflevector <2 x i64> %5549, <2 x i64> %5551, <2 x i32> <i32 1, i32 3>
  %5560 = shufflevector <2 x i64> %5543, <2 x i64> %5547, <2 x i32> <i32 0, i32 2>
  %5561 = shufflevector <2 x i64> %5543, <2 x i64> %5547, <2 x i32> <i32 1, i32 3>
  %5562 = shufflevector <2 x i64> %5553, <2 x i64> %5555, <2 x i32> <i32 0, i32 2>
  %5563 = shufflevector <2 x i64> %5553, <2 x i64> %5555, <2 x i32> <i32 1, i32 3>
  %5564 = bitcast <2 x i64> %5556 to <8 x i16>
  %5565 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5564, <8 x i16> undef) #11
  %5566 = bitcast <16 x i8> %5565 to <2 x i64>
  %5567 = extractelement <2 x i64> %5566, i32 0
  %5568 = bitcast i8* %5464 to i64*
  store i64 %5567, i64* %5568, align 1
  %5569 = getelementptr inbounds i8, i8* %5464, i64 %1
  %5570 = bitcast <2 x i64> %5557 to <8 x i16>
  %5571 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5570, <8 x i16> undef) #11
  %5572 = bitcast <16 x i8> %5571 to <2 x i64>
  %5573 = extractelement <2 x i64> %5572, i32 0
  %5574 = bitcast i8* %5569 to i64*
  store i64 %5573, i64* %5574, align 1
  %5575 = getelementptr inbounds i8, i8* %5569, i64 %1
  %5576 = bitcast <2 x i64> %5558 to <8 x i16>
  %5577 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5576, <8 x i16> undef) #11
  %5578 = bitcast <16 x i8> %5577 to <2 x i64>
  %5579 = extractelement <2 x i64> %5578, i32 0
  %5580 = bitcast i8* %5575 to i64*
  store i64 %5579, i64* %5580, align 1
  %5581 = getelementptr inbounds i8, i8* %5575, i64 %1
  %5582 = bitcast <2 x i64> %5559 to <8 x i16>
  %5583 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5582, <8 x i16> undef) #11
  %5584 = bitcast <16 x i8> %5583 to <2 x i64>
  %5585 = extractelement <2 x i64> %5584, i32 0
  %5586 = bitcast i8* %5581 to i64*
  store i64 %5585, i64* %5586, align 1
  %5587 = getelementptr inbounds i8, i8* %5581, i64 %1
  %5588 = bitcast <2 x i64> %5560 to <8 x i16>
  %5589 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5588, <8 x i16> undef) #11
  %5590 = bitcast <16 x i8> %5589 to <2 x i64>
  %5591 = extractelement <2 x i64> %5590, i32 0
  %5592 = bitcast i8* %5587 to i64*
  store i64 %5591, i64* %5592, align 1
  %5593 = getelementptr inbounds i8, i8* %5587, i64 %1
  %5594 = bitcast <2 x i64> %5561 to <8 x i16>
  %5595 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5594, <8 x i16> undef) #11
  %5596 = bitcast <16 x i8> %5595 to <2 x i64>
  %5597 = extractelement <2 x i64> %5596, i32 0
  %5598 = bitcast i8* %5593 to i64*
  store i64 %5597, i64* %5598, align 1
  %5599 = getelementptr inbounds i8, i8* %5593, i64 %1
  %5600 = bitcast <2 x i64> %5562 to <8 x i16>
  %5601 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5600, <8 x i16> undef) #11
  %5602 = bitcast <16 x i8> %5601 to <2 x i64>
  %5603 = extractelement <2 x i64> %5602, i32 0
  %5604 = bitcast i8* %5599 to i64*
  store i64 %5603, i64* %5604, align 1
  %5605 = getelementptr inbounds i8, i8* %5599, i64 %1
  %5606 = bitcast <2 x i64> %5563 to <8 x i16>
  %5607 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5606, <8 x i16> undef) #11
  %5608 = bitcast <16 x i8> %5607 to <2 x i64>
  %5609 = extractelement <2 x i64> %5608, i32 0
  %5610 = bitcast i8* %5605 to i64*
  store i64 %5609, i64* %5610, align 1
  %5611 = and <8 x i16> %5462, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %5612 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5611, <8 x i16> %5611) #11
  %5613 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5612
  %5614 = shufflevector <16 x i8> %5613, <16 x i8> %5612, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5615 = bitcast <8 x i16> %5465 to <16 x i8>
  %5616 = sub nsw i32 %5461, %6
  %5617 = ashr i32 %5616, 5
  %5618 = sext i32 %5617 to i64
  %5619 = getelementptr inbounds i8, i8* %4777, i64 %5618
  %5620 = shufflevector <16 x i8> %5614, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %5621 = bitcast i8* %5619 to <16 x i8>*
  %5622 = load <16 x i8>, <16 x i8>* %5621, align 1
  %5623 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5622, <16 x i8> %5620) #11
  %5624 = lshr <8 x i16> %5623, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5625 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5624, <8 x i16> zeroinitializer) #11
  %5626 = shufflevector <16 x i8> %5615, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %5627 = bitcast <16 x i8> %5626 to <8 x i16>
  %5628 = icmp sgt <8 x i16> %5627, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5629 = load i64, i64* %5568, align 1
  %5630 = insertelement <2 x i64> undef, i64 %5629, i32 0
  %5631 = bitcast <2 x i64> %5630 to <16 x i8>
  %5632 = shufflevector <16 x i8> %5631, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5633 = zext <8 x i8> %5632 to <8 x i16>
  %5634 = select <8 x i1> %5628, <8 x i16> %5633, <8 x i16> %5625
  %5635 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5634, <8 x i16> undef) #11
  %5636 = bitcast <16 x i8> %5635 to <2 x i64>
  %5637 = extractelement <2 x i64> %5636, i32 0
  store i64 %5637, i64* %5568, align 1
  %5638 = sub nsw i32 %5616, %6
  %5639 = ashr i32 %5638, 5
  %5640 = sext i32 %5639 to i64
  %5641 = getelementptr inbounds i8, i8* %4777, i64 %5640
  %5642 = shufflevector <16 x i8> %5614, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %5643 = bitcast i8* %5641 to <16 x i8>*
  %5644 = load <16 x i8>, <16 x i8>* %5643, align 1
  %5645 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5644, <16 x i8> %5642) #11
  %5646 = lshr <8 x i16> %5645, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5647 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5646, <8 x i16> zeroinitializer) #11
  %5648 = shufflevector <16 x i8> %5615, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %5649 = bitcast <16 x i8> %5648 to <8 x i16>
  %5650 = icmp sgt <8 x i16> %5649, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5651 = load i64, i64* %5574, align 1
  %5652 = insertelement <2 x i64> undef, i64 %5651, i32 0
  %5653 = bitcast <2 x i64> %5652 to <16 x i8>
  %5654 = shufflevector <16 x i8> %5653, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5655 = zext <8 x i8> %5654 to <8 x i16>
  %5656 = select <8 x i1> %5650, <8 x i16> %5655, <8 x i16> %5647
  %5657 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5656, <8 x i16> undef) #11
  %5658 = bitcast <16 x i8> %5657 to <2 x i64>
  %5659 = extractelement <2 x i64> %5658, i32 0
  store i64 %5659, i64* %5574, align 1
  %5660 = sub nsw i32 %5638, %6
  %5661 = ashr i32 %5660, 5
  %5662 = sext i32 %5661 to i64
  %5663 = getelementptr inbounds i8, i8* %4777, i64 %5662
  %5664 = shufflevector <16 x i8> %5614, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %5665 = bitcast i8* %5663 to <16 x i8>*
  %5666 = load <16 x i8>, <16 x i8>* %5665, align 1
  %5667 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5666, <16 x i8> %5664) #11
  %5668 = lshr <8 x i16> %5667, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5669 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5668, <8 x i16> zeroinitializer) #11
  %5670 = shufflevector <16 x i8> %5615, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %5671 = bitcast <16 x i8> %5670 to <8 x i16>
  %5672 = icmp sgt <8 x i16> %5671, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5673 = load i64, i64* %5580, align 1
  %5674 = insertelement <2 x i64> undef, i64 %5673, i32 0
  %5675 = bitcast <2 x i64> %5674 to <16 x i8>
  %5676 = shufflevector <16 x i8> %5675, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5677 = zext <8 x i8> %5676 to <8 x i16>
  %5678 = select <8 x i1> %5672, <8 x i16> %5677, <8 x i16> %5669
  %5679 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5678, <8 x i16> undef) #11
  %5680 = bitcast <16 x i8> %5679 to <2 x i64>
  %5681 = extractelement <2 x i64> %5680, i32 0
  store i64 %5681, i64* %5580, align 1
  %5682 = sub nsw i32 %5660, %6
  %5683 = ashr i32 %5682, 5
  %5684 = sext i32 %5683 to i64
  %5685 = getelementptr inbounds i8, i8* %4777, i64 %5684
  %5686 = shufflevector <16 x i8> %5614, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %5687 = bitcast i8* %5685 to <16 x i8>*
  %5688 = load <16 x i8>, <16 x i8>* %5687, align 1
  %5689 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5688, <16 x i8> %5686) #11
  %5690 = lshr <8 x i16> %5689, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5691 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5690, <8 x i16> zeroinitializer) #11
  %5692 = shufflevector <16 x i8> %5615, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %5693 = bitcast <16 x i8> %5692 to <8 x i16>
  %5694 = icmp sgt <8 x i16> %5693, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5695 = load i64, i64* %5586, align 1
  %5696 = insertelement <2 x i64> undef, i64 %5695, i32 0
  %5697 = bitcast <2 x i64> %5696 to <16 x i8>
  %5698 = shufflevector <16 x i8> %5697, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5699 = zext <8 x i8> %5698 to <8 x i16>
  %5700 = select <8 x i1> %5694, <8 x i16> %5699, <8 x i16> %5691
  %5701 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5700, <8 x i16> undef) #11
  %5702 = bitcast <16 x i8> %5701 to <2 x i64>
  %5703 = extractelement <2 x i64> %5702, i32 0
  store i64 %5703, i64* %5586, align 1
  %5704 = sub nsw i32 %5682, %6
  %5705 = ashr i32 %5704, 5
  %5706 = sext i32 %5705 to i64
  %5707 = getelementptr inbounds i8, i8* %4777, i64 %5706
  %5708 = shufflevector <16 x i8> %5614, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %5709 = bitcast i8* %5707 to <16 x i8>*
  %5710 = load <16 x i8>, <16 x i8>* %5709, align 1
  %5711 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5710, <16 x i8> %5708) #11
  %5712 = lshr <8 x i16> %5711, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5713 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5712, <8 x i16> zeroinitializer) #11
  %5714 = shufflevector <16 x i8> %5615, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %5715 = bitcast <16 x i8> %5714 to <8 x i16>
  %5716 = icmp sgt <8 x i16> %5715, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5717 = load i64, i64* %5592, align 1
  %5718 = insertelement <2 x i64> undef, i64 %5717, i32 0
  %5719 = bitcast <2 x i64> %5718 to <16 x i8>
  %5720 = shufflevector <16 x i8> %5719, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5721 = zext <8 x i8> %5720 to <8 x i16>
  %5722 = select <8 x i1> %5716, <8 x i16> %5721, <8 x i16> %5713
  %5723 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5722, <8 x i16> undef) #11
  %5724 = bitcast <16 x i8> %5723 to <2 x i64>
  %5725 = extractelement <2 x i64> %5724, i32 0
  store i64 %5725, i64* %5592, align 1
  %5726 = sub nsw i32 %5704, %6
  %5727 = ashr i32 %5726, 5
  %5728 = sext i32 %5727 to i64
  %5729 = getelementptr inbounds i8, i8* %4777, i64 %5728
  %5730 = shufflevector <16 x i8> %5614, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %5731 = bitcast i8* %5729 to <16 x i8>*
  %5732 = load <16 x i8>, <16 x i8>* %5731, align 1
  %5733 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5732, <16 x i8> %5730) #11
  %5734 = lshr <8 x i16> %5733, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5735 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5734, <8 x i16> zeroinitializer) #11
  %5736 = shufflevector <16 x i8> %5615, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %5737 = bitcast <16 x i8> %5736 to <8 x i16>
  %5738 = icmp sgt <8 x i16> %5737, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5739 = load i64, i64* %5598, align 1
  %5740 = insertelement <2 x i64> undef, i64 %5739, i32 0
  %5741 = bitcast <2 x i64> %5740 to <16 x i8>
  %5742 = shufflevector <16 x i8> %5741, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5743 = zext <8 x i8> %5742 to <8 x i16>
  %5744 = select <8 x i1> %5738, <8 x i16> %5743, <8 x i16> %5735
  %5745 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5744, <8 x i16> undef) #11
  %5746 = bitcast <16 x i8> %5745 to <2 x i64>
  %5747 = extractelement <2 x i64> %5746, i32 0
  store i64 %5747, i64* %5598, align 1
  %5748 = sub nsw i32 %5726, %6
  %5749 = ashr i32 %5748, 5
  %5750 = sext i32 %5749 to i64
  %5751 = getelementptr inbounds i8, i8* %4777, i64 %5750
  %5752 = shufflevector <16 x i8> %5614, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %5753 = bitcast i8* %5751 to <16 x i8>*
  %5754 = load <16 x i8>, <16 x i8>* %5753, align 1
  %5755 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5754, <16 x i8> %5752) #11
  %5756 = lshr <8 x i16> %5755, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5757 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5756, <8 x i16> zeroinitializer) #11
  %5758 = shufflevector <16 x i8> %5615, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %5759 = bitcast <16 x i8> %5758 to <8 x i16>
  %5760 = icmp sgt <8 x i16> %5759, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5761 = load i64, i64* %5604, align 1
  %5762 = insertelement <2 x i64> undef, i64 %5761, i32 0
  %5763 = bitcast <2 x i64> %5762 to <16 x i8>
  %5764 = shufflevector <16 x i8> %5763, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5765 = zext <8 x i8> %5764 to <8 x i16>
  %5766 = select <8 x i1> %5760, <8 x i16> %5765, <8 x i16> %5757
  %5767 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5766, <8 x i16> undef) #11
  %5768 = bitcast <16 x i8> %5767 to <2 x i64>
  %5769 = extractelement <2 x i64> %5768, i32 0
  store i64 %5769, i64* %5604, align 1
  %5770 = sub nsw i32 %5748, %6
  %5771 = ashr i32 %5770, 5
  %5772 = sext i32 %5771 to i64
  %5773 = getelementptr inbounds i8, i8* %4777, i64 %5772
  %5774 = shufflevector <16 x i8> %5614, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %5775 = bitcast i8* %5773 to <16 x i8>*
  %5776 = load <16 x i8>, <16 x i8>* %5775, align 1
  %5777 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5776, <16 x i8> %5774) #11
  %5778 = lshr <8 x i16> %5777, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5779 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5778, <8 x i16> zeroinitializer) #11
  %5780 = shufflevector <16 x i8> %5615, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %5781 = bitcast <16 x i8> %5780 to <8 x i16>
  %5782 = icmp sgt <8 x i16> %5781, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %5783 = load i64, i64* %5610, align 1
  %5784 = insertelement <2 x i64> undef, i64 %5783, i32 0
  %5785 = bitcast <2 x i64> %5784 to <16 x i8>
  %5786 = shufflevector <16 x i8> %5785, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %5787 = zext <8 x i8> %5786 to <8 x i16>
  %5788 = select <8 x i1> %5782, <8 x i16> %5787, <8 x i16> %5779
  %5789 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5788, <8 x i16> undef) #11
  %5790 = bitcast <16 x i8> %5789 to <2 x i64>
  %5791 = extractelement <2 x i64> %5790, i32 0
  store i64 %5791, i64* %5610, align 1
  %5792 = add nsw i64 %5460, 8
  %5793 = getelementptr inbounds i8, i8* %5464, i64 %2071
  %5794 = add <8 x i16> %5463, %2083
  %5795 = sub <8 x i16> %5462, %2083
  %5796 = sub nsw i32 %5461, %2080
  %5797 = icmp slt i64 %5792, %5369
  br i1 %5797, label %5459, label %5370

5798:                                             ; preds = %5798, %5376
  %5799 = phi i64 [ %5457, %5376 ], [ %5946, %5798 ]
  %5800 = phi i8* [ %5373, %5376 ], [ %5947, %5798 ]
  %5801 = add nsw i64 %5799, %5458
  %5802 = getelementptr inbounds i8, i8* %20, i64 %5801
  %5803 = getelementptr inbounds i8, i8* %5802, i64 %5386
  %5804 = bitcast i8* %5803 to <16 x i8>*
  %5805 = load <16 x i8>, <16 x i8>* %5804, align 1
  %5806 = shufflevector <16 x i8> %5805, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5807 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5806, <16 x i8> %5385) #11
  %5808 = lshr <8 x i16> %5807, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5809 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5808, <8 x i16> zeroinitializer) #11
  %5810 = getelementptr inbounds i8, i8* %5802, i64 %5396
  %5811 = bitcast i8* %5810 to <16 x i8>*
  %5812 = load <16 x i8>, <16 x i8>* %5811, align 1
  %5813 = shufflevector <16 x i8> %5812, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5814 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5813, <16 x i8> %5395) #11
  %5815 = lshr <8 x i16> %5814, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5816 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5815, <8 x i16> zeroinitializer) #11
  %5817 = getelementptr inbounds i8, i8* %5802, i64 %5406
  %5818 = bitcast i8* %5817 to <16 x i8>*
  %5819 = load <16 x i8>, <16 x i8>* %5818, align 1
  %5820 = shufflevector <16 x i8> %5819, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5821 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5820, <16 x i8> %5405) #11
  %5822 = lshr <8 x i16> %5821, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5823 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5822, <8 x i16> zeroinitializer) #11
  %5824 = getelementptr inbounds i8, i8* %5802, i64 %5416
  %5825 = bitcast i8* %5824 to <16 x i8>*
  %5826 = load <16 x i8>, <16 x i8>* %5825, align 1
  %5827 = shufflevector <16 x i8> %5826, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5828 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5827, <16 x i8> %5415) #11
  %5829 = lshr <8 x i16> %5828, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5830 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5829, <8 x i16> zeroinitializer) #11
  %5831 = getelementptr inbounds i8, i8* %5802, i64 %5426
  %5832 = bitcast i8* %5831 to <16 x i8>*
  %5833 = load <16 x i8>, <16 x i8>* %5832, align 1
  %5834 = shufflevector <16 x i8> %5833, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5835 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5834, <16 x i8> %5425) #11
  %5836 = lshr <8 x i16> %5835, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5837 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5836, <8 x i16> zeroinitializer) #11
  %5838 = getelementptr inbounds i8, i8* %5802, i64 %5436
  %5839 = bitcast i8* %5838 to <16 x i8>*
  %5840 = load <16 x i8>, <16 x i8>* %5839, align 1
  %5841 = shufflevector <16 x i8> %5840, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5842 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5841, <16 x i8> %5435) #11
  %5843 = lshr <8 x i16> %5842, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5844 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5843, <8 x i16> zeroinitializer) #11
  %5845 = getelementptr inbounds i8, i8* %5802, i64 %5446
  %5846 = bitcast i8* %5845 to <16 x i8>*
  %5847 = load <16 x i8>, <16 x i8>* %5846, align 1
  %5848 = shufflevector <16 x i8> %5847, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5849 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5848, <16 x i8> %5445) #11
  %5850 = lshr <8 x i16> %5849, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5851 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5850, <8 x i16> zeroinitializer) #11
  %5852 = getelementptr inbounds i8, i8* %5802, i64 %5456
  %5853 = bitcast i8* %5852 to <16 x i8>*
  %5854 = load <16 x i8>, <16 x i8>* %5853, align 1
  %5855 = shufflevector <16 x i8> %5854, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %5856 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %5855, <16 x i8> %5455) #11
  %5857 = lshr <8 x i16> %5856, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %5858 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %5857, <8 x i16> zeroinitializer) #11
  %5859 = shufflevector <8 x i16> %5809, <8 x i16> %5816, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5860 = shufflevector <8 x i16> %5823, <8 x i16> %5830, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5861 = shufflevector <8 x i16> %5837, <8 x i16> %5844, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5862 = shufflevector <8 x i16> %5851, <8 x i16> %5858, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %5863 = shufflevector <8 x i16> %5809, <8 x i16> %5816, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5864 = shufflevector <8 x i16> %5823, <8 x i16> %5830, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5865 = shufflevector <8 x i16> %5837, <8 x i16> %5844, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5866 = shufflevector <8 x i16> %5851, <8 x i16> %5858, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %5867 = bitcast <8 x i16> %5859 to <4 x i32>
  %5868 = bitcast <8 x i16> %5860 to <4 x i32>
  %5869 = shufflevector <4 x i32> %5867, <4 x i32> %5868, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5870 = bitcast <4 x i32> %5869 to <2 x i64>
  %5871 = bitcast <8 x i16> %5861 to <4 x i32>
  %5872 = bitcast <8 x i16> %5862 to <4 x i32>
  %5873 = shufflevector <4 x i32> %5871, <4 x i32> %5872, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5874 = bitcast <4 x i32> %5873 to <2 x i64>
  %5875 = bitcast <8 x i16> %5863 to <4 x i32>
  %5876 = bitcast <8 x i16> %5864 to <4 x i32>
  %5877 = shufflevector <4 x i32> %5875, <4 x i32> %5876, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5878 = bitcast <4 x i32> %5877 to <2 x i64>
  %5879 = bitcast <8 x i16> %5865 to <4 x i32>
  %5880 = bitcast <8 x i16> %5866 to <4 x i32>
  %5881 = shufflevector <4 x i32> %5879, <4 x i32> %5880, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %5882 = bitcast <4 x i32> %5881 to <2 x i64>
  %5883 = shufflevector <4 x i32> %5867, <4 x i32> %5868, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5884 = bitcast <4 x i32> %5883 to <2 x i64>
  %5885 = shufflevector <4 x i32> %5871, <4 x i32> %5872, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5886 = bitcast <4 x i32> %5885 to <2 x i64>
  %5887 = shufflevector <4 x i32> %5875, <4 x i32> %5876, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5888 = bitcast <4 x i32> %5887 to <2 x i64>
  %5889 = shufflevector <4 x i32> %5879, <4 x i32> %5880, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %5890 = bitcast <4 x i32> %5889 to <2 x i64>
  %5891 = shufflevector <2 x i64> %5870, <2 x i64> %5874, <2 x i32> <i32 0, i32 2>
  %5892 = shufflevector <2 x i64> %5870, <2 x i64> %5874, <2 x i32> <i32 1, i32 3>
  %5893 = shufflevector <2 x i64> %5884, <2 x i64> %5886, <2 x i32> <i32 0, i32 2>
  %5894 = shufflevector <2 x i64> %5884, <2 x i64> %5886, <2 x i32> <i32 1, i32 3>
  %5895 = shufflevector <2 x i64> %5878, <2 x i64> %5882, <2 x i32> <i32 0, i32 2>
  %5896 = shufflevector <2 x i64> %5878, <2 x i64> %5882, <2 x i32> <i32 1, i32 3>
  %5897 = shufflevector <2 x i64> %5888, <2 x i64> %5890, <2 x i32> <i32 0, i32 2>
  %5898 = shufflevector <2 x i64> %5888, <2 x i64> %5890, <2 x i32> <i32 1, i32 3>
  %5899 = bitcast <2 x i64> %5891 to <8 x i16>
  %5900 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5899, <8 x i16> undef) #11
  %5901 = bitcast <16 x i8> %5900 to <2 x i64>
  %5902 = extractelement <2 x i64> %5901, i32 0
  %5903 = bitcast i8* %5800 to i64*
  store i64 %5902, i64* %5903, align 1
  %5904 = getelementptr inbounds i8, i8* %5800, i64 %1
  %5905 = bitcast <2 x i64> %5892 to <8 x i16>
  %5906 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5905, <8 x i16> undef) #11
  %5907 = bitcast <16 x i8> %5906 to <2 x i64>
  %5908 = extractelement <2 x i64> %5907, i32 0
  %5909 = bitcast i8* %5904 to i64*
  store i64 %5908, i64* %5909, align 1
  %5910 = getelementptr inbounds i8, i8* %5904, i64 %1
  %5911 = bitcast <2 x i64> %5893 to <8 x i16>
  %5912 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5911, <8 x i16> undef) #11
  %5913 = bitcast <16 x i8> %5912 to <2 x i64>
  %5914 = extractelement <2 x i64> %5913, i32 0
  %5915 = bitcast i8* %5910 to i64*
  store i64 %5914, i64* %5915, align 1
  %5916 = getelementptr inbounds i8, i8* %5910, i64 %1
  %5917 = bitcast <2 x i64> %5894 to <8 x i16>
  %5918 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5917, <8 x i16> undef) #11
  %5919 = bitcast <16 x i8> %5918 to <2 x i64>
  %5920 = extractelement <2 x i64> %5919, i32 0
  %5921 = bitcast i8* %5916 to i64*
  store i64 %5920, i64* %5921, align 1
  %5922 = getelementptr inbounds i8, i8* %5916, i64 %1
  %5923 = bitcast <2 x i64> %5895 to <8 x i16>
  %5924 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5923, <8 x i16> undef) #11
  %5925 = bitcast <16 x i8> %5924 to <2 x i64>
  %5926 = extractelement <2 x i64> %5925, i32 0
  %5927 = bitcast i8* %5922 to i64*
  store i64 %5926, i64* %5927, align 1
  %5928 = getelementptr inbounds i8, i8* %5922, i64 %1
  %5929 = bitcast <2 x i64> %5896 to <8 x i16>
  %5930 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5929, <8 x i16> undef) #11
  %5931 = bitcast <16 x i8> %5930 to <2 x i64>
  %5932 = extractelement <2 x i64> %5931, i32 0
  %5933 = bitcast i8* %5928 to i64*
  store i64 %5932, i64* %5933, align 1
  %5934 = getelementptr inbounds i8, i8* %5928, i64 %1
  %5935 = bitcast <2 x i64> %5897 to <8 x i16>
  %5936 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5935, <8 x i16> undef) #11
  %5937 = bitcast <16 x i8> %5936 to <2 x i64>
  %5938 = extractelement <2 x i64> %5937, i32 0
  %5939 = bitcast i8* %5934 to i64*
  store i64 %5938, i64* %5939, align 1
  %5940 = getelementptr inbounds i8, i8* %5934, i64 %1
  %5941 = bitcast <2 x i64> %5898 to <8 x i16>
  %5942 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %5941, <8 x i16> undef) #11
  %5943 = bitcast <16 x i8> %5942 to <2 x i64>
  %5944 = extractelement <2 x i64> %5943, i32 0
  %5945 = bitcast i8* %5940 to i64*
  store i64 %5944, i64* %5945, align 1
  %5946 = add nsw i64 %5799, 8
  %5947 = getelementptr inbounds i8, i8* %5800, i64 %2071
  %5948 = icmp slt i64 %5946, %4731
  br i1 %5948, label %5798, label %5949

5949:                                             ; preds = %5798, %5372
  %5950 = add <8 x i16> %4967, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %5951 = bitcast <8 x i16> %5950 to <2 x i64>
  %5952 = add <8 x i16> %4765, %2095
  %5953 = sub nsw i32 %4764, %2090
  %5954 = icmp slt i64 %4959, %4732
  br i1 %5954, label %4762, label %4733

5955:                                             ; preds = %6032, %4738
  %5956 = phi i64 [ %4752, %4738 ], [ %6033, %6032 ]
  %5957 = getelementptr inbounds i8, i8* %0, i64 %5956
  %5958 = trunc i64 %5956 to i32
  %5959 = shl i32 %5958, 1
  %5960 = sext i32 %5959 to i64
  %5961 = getelementptr inbounds i8, i8* %19, i64 %5960
  %5962 = getelementptr inbounds i8, i8* %5961, i64 %4741
  %5963 = load i8, i8* %5962, align 2
  %5964 = zext i8 %5963 to i16
  %5965 = insertelement <8 x i16> undef, i16 %5964, i32 0
  %5966 = shufflevector <8 x i16> %5965, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  br i1 %4748, label %5984, label %5967

5967:                                             ; preds = %5984, %5955
  %5968 = phi i32 [ 0, %5955 ], [ %4747, %5984 ]
  %5969 = phi i8* [ %5957, %5955 ], [ %6016, %5984 ]
  %5970 = icmp slt i32 %5968, %5
  br i1 %5970, label %5971, label %6032

5971:                                             ; preds = %5967
  %5972 = load i8, i8* %5962, align 2
  br i1 %4760, label %5981, label %5973

5973:                                             ; preds = %5971, %5973
  %5974 = phi i8* [ %5977, %5973 ], [ %5969, %5971 ]
  %5975 = phi i32 [ %5978, %5973 ], [ %5968, %5971 ]
  %5976 = phi i32 [ %5979, %5973 ], [ %4759, %5971 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %5974, i8 %5972, i64 4, i1 false) #11
  %5977 = getelementptr inbounds i8, i8* %5974, i64 %1
  %5978 = add nuw nsw i32 %5975, 1
  %5979 = add i32 %5976, -1
  %5980 = icmp eq i32 %5979, 0
  br i1 %5980, label %5981, label %5973, !llvm.loop !22

5981:                                             ; preds = %5973, %5971
  %5982 = phi i8* [ %5969, %5971 ], [ %5977, %5973 ]
  %5983 = phi i32 [ %5968, %5971 ], [ %5978, %5973 ]
  br i1 %4761, label %6032, label %6019

5984:                                             ; preds = %5955, %5984
  %5985 = phi i8* [ %6016, %5984 ], [ %5957, %5955 ]
  %5986 = phi i32 [ %6015, %5984 ], [ 0, %5955 ]
  %5987 = phi i32 [ %6017, %5984 ], [ %2084, %5955 ]
  %5988 = ashr i32 %5987, 5
  %5989 = trunc i32 %5987 to i8
  %5990 = and i8 %5989, 31
  %5991 = insertelement <16 x i8> undef, i8 %5990, i32 0
  %5992 = shufflevector <16 x i8> %5991, <16 x i8> undef, <16 x i32> zeroinitializer
  %5993 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %5992
  %5994 = shufflevector <16 x i8> %5993, <16 x i8> %5992, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %5995 = trunc i32 %5988 to i16
  %5996 = insertelement <8 x i16> undef, i16 %5995, i32 0
  %5997 = shufflevector <8 x i16> %5996, <8 x i16> undef, <8 x i32> zeroinitializer
  %5998 = add <8 x i16> %5997, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %5999 = sext i32 %5988 to i64
  %6000 = getelementptr inbounds i8, i8* %5961, i64 %5999
  %6001 = bitcast i8* %6000 to i64*
  %6002 = load i64, i64* %6001, align 1
  %6003 = insertelement <2 x i64> undef, i64 %6002, i32 0
  %6004 = bitcast <2 x i64> %6003 to <16 x i8>
  %6005 = shufflevector <16 x i8> %6004, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %6006 = icmp sgt <8 x i16> %5998, %4751
  %6007 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6005, <16 x i8> %5994) #11
  %6008 = lshr <8 x i16> %6007, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6009 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6008, <8 x i16> zeroinitializer) #11
  %6010 = select <8 x i1> %6006, <8 x i16> %5966, <8 x i16> %6009
  %6011 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6010, <8 x i16> undef) #11
  %6012 = bitcast <16 x i8> %6011 to <4 x i32>
  %6013 = extractelement <4 x i32> %6012, i32 0
  %6014 = bitcast i8* %5985 to i32*
  store i32 %6013, i32* %6014, align 1
  %6015 = add nuw nsw i32 %5986, 1
  %6016 = getelementptr inbounds i8, i8* %5985, i64 %1
  %6017 = sub i32 %5987, %6
  %6018 = icmp slt i32 %6015, %4747
  br i1 %6018, label %5984, label %5967

6019:                                             ; preds = %5981, %6019
  %6020 = phi i8* [ %6029, %6019 ], [ %5982, %5981 ]
  %6021 = phi i32 [ %6030, %6019 ], [ %5983, %5981 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6020, i8 %5972, i64 4, i1 false) #11
  %6022 = getelementptr inbounds i8, i8* %6020, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6022, i8 %5972, i64 4, i1 false) #11
  %6023 = getelementptr inbounds i8, i8* %6022, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6023, i8 %5972, i64 4, i1 false) #11
  %6024 = getelementptr inbounds i8, i8* %6023, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6024, i8 %5972, i64 4, i1 false) #11
  %6025 = getelementptr inbounds i8, i8* %6024, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6025, i8 %5972, i64 4, i1 false) #11
  %6026 = getelementptr inbounds i8, i8* %6025, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6026, i8 %5972, i64 4, i1 false) #11
  %6027 = getelementptr inbounds i8, i8* %6026, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6027, i8 %5972, i64 4, i1 false) #11
  %6028 = getelementptr inbounds i8, i8* %6027, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6028, i8 %5972, i64 4, i1 false) #11
  %6029 = getelementptr inbounds i8, i8* %6028, i64 %1
  %6030 = add nuw nsw i32 %6021, 8
  %6031 = icmp eq i32 %6030, %5
  br i1 %6031, label %6032, label %6019

6032:                                             ; preds = %5981, %6019, %5967
  %6033 = add nuw nsw i64 %5956, 4
  %6034 = icmp slt i64 %6033, %4753
  br i1 %6034, label %5955, label %7373

6035:                                             ; preds = %4708
  br i1 %2096, label %6036, label %6061

6036:                                             ; preds = %6035
  %6037 = sub nsw i32 0, %2076
  %6038 = trunc i32 %7 to i16
  %6039 = sub i16 0, %6038
  %6040 = insertelement <8 x i16> undef, i16 %6039, i32 0
  %6041 = shufflevector <8 x i16> %6040, <8 x i16> undef, <8 x i32> zeroinitializer
  %6042 = mul <8 x i16> %6041, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %6043 = and i16 %6038, 63
  %6044 = sub nsw i16 0, %6043
  %6045 = insertelement <8 x i16> undef, i16 %6044, i32 0
  %6046 = shufflevector <8 x i16> %6045, <8 x i16> undef, <8 x i32> zeroinitializer
  %6047 = add <8 x i16> %6042, %6046
  %6048 = icmp eq i32 %6, 64
  %6049 = sub <8 x i16> <i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64, i16 -64>, %2088
  %6050 = bitcast <8 x i16> %6049 to <2 x i64>
  %6051 = bitcast <8 x i16> %2088 to <2 x i64>
  %6052 = xor <2 x i64> %6051, <i64 -1, i64 -1>
  %6053 = select i1 %6048, <2 x i64> %6050, <2 x i64> %6052
  %6054 = ashr i32 %2084, 6
  %6055 = icmp sgt i32 %6054, 1
  %6056 = select i1 %6055, i32 %6054, i32 1
  %6057 = sext i32 %5 to i64
  %6058 = sext i32 %2075 to i64
  br label %6087

6059:                                             ; preds = %7289
  %6060 = trunc i64 %6281 to i32
  br label %6061

6061:                                             ; preds = %6059, %6035
  %6062 = phi i32 [ 0, %6035 ], [ %6060, %6059 ]
  %6063 = icmp slt i32 %6062, %4
  br i1 %6063, label %6064, label %7373

6064:                                             ; preds = %6061
  %6065 = add nsw i32 %5, 3
  %6066 = sext i32 %6065 to i64
  %6067 = ashr i32 %2084, 6
  %6068 = icmp sgt i32 %6067, 1
  %6069 = select i1 %6068, i32 %6067, i32 1
  %6070 = sdiv i32 %6065, %6069
  %6071 = icmp sgt i32 %6070, %5
  %6072 = select i1 %6071, i32 %5, i32 %6070
  %6073 = icmp sgt i32 %6072, 0
  %6074 = trunc i32 %6065 to i16
  %6075 = insertelement <8 x i16> undef, i16 %6074, i32 0
  %6076 = shufflevector <8 x i16> %6075, <8 x i16> undef, <8 x i32> zeroinitializer
  %6077 = zext i32 %6062 to i64
  %6078 = sext i32 %4 to i64
  %6079 = icmp sgt i32 %6072, 0
  %6080 = select i1 %6079, i32 %6072, i32 0
  %6081 = sub i32 %5, %6080
  %6082 = xor i32 %6080, -1
  %6083 = add i32 %6082, %5
  %6084 = and i32 %6081, 7
  %6085 = icmp eq i32 %6084, 0
  %6086 = icmp ult i32 %6083, 7
  br label %7295

6087:                                             ; preds = %7289, %6036
  %6088 = phi i64 [ 0, %6036 ], [ %6281, %7289 ]
  %6089 = phi i32 [ %6037, %6036 ], [ %7293, %7289 ]
  %6090 = phi <8 x i16> [ %6047, %6036 ], [ %7292, %7289 ]
  %6091 = phi <2 x i64> [ %6053, %6036 ], [ %7291, %7289 ]
  %6092 = getelementptr inbounds i8, i8* %0, i64 %6088
  %6093 = trunc i64 %6088 to i32
  %6094 = shl i32 %6093, 6
  %6095 = or i32 %6094, 64
  %6096 = sdiv i32 %6095, %6
  %6097 = icmp sgt i32 %6096, %5
  %6098 = select i1 %6097, i32 %5, i32 %6096
  %6099 = and i32 %6098, -8
  %6100 = getelementptr inbounds i8, i8* %19, i64 %6088
  %6101 = or i32 %6099, 3
  %6102 = sext i32 %6101 to i64
  %6103 = getelementptr inbounds i8, i8* %6100, i64 %6102
  %6104 = load i8, i8* %6103, align 1
  %6105 = zext i8 %6104 to i16
  %6106 = insertelement <8 x i16> undef, i16 %6105, i32 0
  %6107 = shufflevector <8 x i16> %6106, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %6108 = sdiv i32 %6101, %6056
  %6109 = icmp sgt i32 %6108, %6099
  %6110 = select i1 %6109, i32 %6099, i32 %6108
  %6111 = icmp sgt i32 %6110, 0
  br i1 %6111, label %6112, label %6116

6112:                                             ; preds = %6087
  %6113 = trunc i32 %6101 to i16
  %6114 = insertelement <8 x i16> undef, i16 %6113, i32 0
  %6115 = shufflevector <8 x i16> %6114, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %6139

6116:                                             ; preds = %6139, %6087
  %6117 = phi i32 [ 0, %6087 ], [ %6110, %6139 ]
  %6118 = phi i8* [ %6092, %6087 ], [ %6172, %6139 ]
  %6119 = icmp sgt i32 %6099, %6117
  br i1 %6119, label %6120, label %6188

6120:                                             ; preds = %6116
  %6121 = load i8, i8* %6103, align 1
  %6122 = sub i32 0, %6117
  %6123 = xor i32 %6117, -1
  %6124 = add i32 %6099, %6123
  %6125 = and i32 %6122, 7
  %6126 = icmp eq i32 %6125, 0
  br i1 %6126, label %6135, label %6127

6127:                                             ; preds = %6120, %6127
  %6128 = phi i8* [ %6131, %6127 ], [ %6118, %6120 ]
  %6129 = phi i32 [ %6132, %6127 ], [ %6117, %6120 ]
  %6130 = phi i32 [ %6133, %6127 ], [ %6125, %6120 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6128, i8 %6121, i64 4, i1 false) #11
  %6131 = getelementptr inbounds i8, i8* %6128, i64 %1
  %6132 = add nuw nsw i32 %6129, 1
  %6133 = add i32 %6130, -1
  %6134 = icmp eq i32 %6133, 0
  br i1 %6134, label %6135, label %6127, !llvm.loop !23

6135:                                             ; preds = %6127, %6120
  %6136 = phi i8* [ %6118, %6120 ], [ %6131, %6127 ]
  %6137 = phi i32 [ %6117, %6120 ], [ %6132, %6127 ]
  %6138 = icmp ult i32 %6124, 7
  br i1 %6138, label %6188, label %6175

6139:                                             ; preds = %6139, %6112
  %6140 = phi i8* [ %6092, %6112 ], [ %6172, %6139 ]
  %6141 = phi i32 [ 0, %6112 ], [ %6171, %6139 ]
  %6142 = phi i32 [ %2084, %6112 ], [ %6173, %6139 ]
  %6143 = ashr i32 %6142, 6
  %6144 = lshr i32 %6142, 1
  %6145 = trunc i32 %6144 to i8
  %6146 = and i8 %6145, 31
  %6147 = insertelement <16 x i8> undef, i8 %6146, i32 0
  %6148 = shufflevector <16 x i8> %6147, <16 x i8> undef, <16 x i32> zeroinitializer
  %6149 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6148
  %6150 = shufflevector <16 x i8> %6149, <16 x i8> %6148, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6151 = trunc i32 %6143 to i16
  %6152 = insertelement <8 x i16> undef, i16 %6151, i32 0
  %6153 = shufflevector <8 x i16> %6152, <8 x i16> undef, <8 x i32> zeroinitializer
  %6154 = add <8 x i16> %6153, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %6155 = sext i32 %6143 to i64
  %6156 = getelementptr inbounds i8, i8* %6100, i64 %6155
  %6157 = bitcast i8* %6156 to i64*
  %6158 = load i64, i64* %6157, align 1
  %6159 = insertelement <2 x i64> undef, i64 %6158, i32 0
  %6160 = bitcast <2 x i64> %6159 to <16 x i8>
  %6161 = shufflevector <16 x i8> %6160, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %6162 = icmp sgt <8 x i16> %6154, %6115
  %6163 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6161, <16 x i8> %6150) #11
  %6164 = lshr <8 x i16> %6163, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6165 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6164, <8 x i16> zeroinitializer) #11
  %6166 = select <8 x i1> %6162, <8 x i16> %6107, <8 x i16> %6165
  %6167 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6166, <8 x i16> undef) #11
  %6168 = bitcast <16 x i8> %6167 to <4 x i32>
  %6169 = extractelement <4 x i32> %6168, i32 0
  %6170 = bitcast i8* %6140 to i32*
  store i32 %6169, i32* %6170, align 1
  %6171 = add nuw nsw i32 %6141, 1
  %6172 = getelementptr inbounds i8, i8* %6140, i64 %1
  %6173 = sub i32 %6142, %6
  %6174 = icmp slt i32 %6171, %6110
  br i1 %6174, label %6139, label %6116

6175:                                             ; preds = %6135, %6175
  %6176 = phi i8* [ %6185, %6175 ], [ %6136, %6135 ]
  %6177 = phi i32 [ %6186, %6175 ], [ %6137, %6135 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6176, i8 %6121, i64 4, i1 false) #11
  %6178 = getelementptr inbounds i8, i8* %6176, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6178, i8 %6121, i64 4, i1 false) #11
  %6179 = getelementptr inbounds i8, i8* %6178, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6179, i8 %6121, i64 4, i1 false) #11
  %6180 = getelementptr inbounds i8, i8* %6179, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6180, i8 %6121, i64 4, i1 false) #11
  %6181 = getelementptr inbounds i8, i8* %6180, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6181, i8 %6121, i64 4, i1 false) #11
  %6182 = getelementptr inbounds i8, i8* %6181, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6182, i8 %6121, i64 4, i1 false) #11
  %6183 = getelementptr inbounds i8, i8* %6182, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6183, i8 %6121, i64 4, i1 false) #11
  %6184 = getelementptr inbounds i8, i8* %6183, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6184, i8 %6121, i64 4, i1 false) #11
  %6185 = getelementptr inbounds i8, i8* %6184, i64 %1
  %6186 = add nuw nsw i32 %6177, 8
  %6187 = icmp eq i32 %6186, %6099
  br i1 %6187, label %6188, label %6175

6188:                                             ; preds = %6135, %6175, %6116
  %6189 = getelementptr inbounds i8, i8* %6092, i64 4
  %6190 = or i64 %6088, 4
  %6191 = getelementptr inbounds i8, i8* %19, i64 %6190
  %6192 = getelementptr inbounds i8, i8* %6191, i64 %6102
  %6193 = load i8, i8* %6192, align 1
  %6194 = zext i8 %6193 to i16
  %6195 = insertelement <8 x i16> undef, i16 %6194, i32 0
  %6196 = shufflevector <8 x i16> %6195, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  br i1 %6111, label %6197, label %6201

6197:                                             ; preds = %6188
  %6198 = trunc i32 %6101 to i16
  %6199 = insertelement <8 x i16> undef, i16 %6198, i32 0
  %6200 = shufflevector <8 x i16> %6199, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %6224

6201:                                             ; preds = %6224, %6188
  %6202 = phi i32 [ 0, %6188 ], [ %6110, %6224 ]
  %6203 = phi i8* [ %6189, %6188 ], [ %6257, %6224 ]
  %6204 = icmp sgt i32 %6099, %6202
  br i1 %6204, label %6205, label %6273

6205:                                             ; preds = %6201
  %6206 = load i8, i8* %6192, align 1
  %6207 = sub i32 0, %6202
  %6208 = xor i32 %6202, -1
  %6209 = add i32 %6099, %6208
  %6210 = and i32 %6207, 7
  %6211 = icmp eq i32 %6210, 0
  br i1 %6211, label %6220, label %6212

6212:                                             ; preds = %6205, %6212
  %6213 = phi i8* [ %6216, %6212 ], [ %6203, %6205 ]
  %6214 = phi i32 [ %6217, %6212 ], [ %6202, %6205 ]
  %6215 = phi i32 [ %6218, %6212 ], [ %6210, %6205 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6213, i8 %6206, i64 4, i1 false) #11
  %6216 = getelementptr inbounds i8, i8* %6213, i64 %1
  %6217 = add nuw nsw i32 %6214, 1
  %6218 = add i32 %6215, -1
  %6219 = icmp eq i32 %6218, 0
  br i1 %6219, label %6220, label %6212, !llvm.loop !24

6220:                                             ; preds = %6212, %6205
  %6221 = phi i8* [ %6203, %6205 ], [ %6216, %6212 ]
  %6222 = phi i32 [ %6202, %6205 ], [ %6217, %6212 ]
  %6223 = icmp ult i32 %6209, 7
  br i1 %6223, label %6273, label %6260

6224:                                             ; preds = %6224, %6197
  %6225 = phi i8* [ %6189, %6197 ], [ %6257, %6224 ]
  %6226 = phi i32 [ 0, %6197 ], [ %6256, %6224 ]
  %6227 = phi i32 [ %2084, %6197 ], [ %6258, %6224 ]
  %6228 = ashr i32 %6227, 6
  %6229 = lshr i32 %6227, 1
  %6230 = trunc i32 %6229 to i8
  %6231 = and i8 %6230, 31
  %6232 = insertelement <16 x i8> undef, i8 %6231, i32 0
  %6233 = shufflevector <16 x i8> %6232, <16 x i8> undef, <16 x i32> zeroinitializer
  %6234 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6233
  %6235 = shufflevector <16 x i8> %6234, <16 x i8> %6233, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6236 = trunc i32 %6228 to i16
  %6237 = insertelement <8 x i16> undef, i16 %6236, i32 0
  %6238 = shufflevector <8 x i16> %6237, <8 x i16> undef, <8 x i32> zeroinitializer
  %6239 = add <8 x i16> %6238, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %6240 = sext i32 %6228 to i64
  %6241 = getelementptr inbounds i8, i8* %6191, i64 %6240
  %6242 = bitcast i8* %6241 to i64*
  %6243 = load i64, i64* %6242, align 1
  %6244 = insertelement <2 x i64> undef, i64 %6243, i32 0
  %6245 = bitcast <2 x i64> %6244 to <16 x i8>
  %6246 = shufflevector <16 x i8> %6245, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %6247 = icmp sgt <8 x i16> %6239, %6200
  %6248 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6246, <16 x i8> %6235) #11
  %6249 = lshr <8 x i16> %6248, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6250 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6249, <8 x i16> zeroinitializer) #11
  %6251 = select <8 x i1> %6247, <8 x i16> %6196, <8 x i16> %6250
  %6252 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6251, <8 x i16> undef) #11
  %6253 = bitcast <16 x i8> %6252 to <4 x i32>
  %6254 = extractelement <4 x i32> %6253, i32 0
  %6255 = bitcast i8* %6225 to i32*
  store i32 %6254, i32* %6255, align 1
  %6256 = add nuw nsw i32 %6226, 1
  %6257 = getelementptr inbounds i8, i8* %6225, i64 %1
  %6258 = sub i32 %6227, %6
  %6259 = icmp slt i32 %6256, %6110
  br i1 %6259, label %6224, label %6201

6260:                                             ; preds = %6220, %6260
  %6261 = phi i8* [ %6270, %6260 ], [ %6221, %6220 ]
  %6262 = phi i32 [ %6271, %6260 ], [ %6222, %6220 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6261, i8 %6206, i64 4, i1 false) #11
  %6263 = getelementptr inbounds i8, i8* %6261, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6263, i8 %6206, i64 4, i1 false) #11
  %6264 = getelementptr inbounds i8, i8* %6263, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6264, i8 %6206, i64 4, i1 false) #11
  %6265 = getelementptr inbounds i8, i8* %6264, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6265, i8 %6206, i64 4, i1 false) #11
  %6266 = getelementptr inbounds i8, i8* %6265, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6266, i8 %6206, i64 4, i1 false) #11
  %6267 = getelementptr inbounds i8, i8* %6266, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6267, i8 %6206, i64 4, i1 false) #11
  %6268 = getelementptr inbounds i8, i8* %6267, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6268, i8 %6206, i64 4, i1 false) #11
  %6269 = getelementptr inbounds i8, i8* %6268, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %6269, i8 %6206, i64 4, i1 false) #11
  %6270 = getelementptr inbounds i8, i8* %6269, i64 %1
  %6271 = add nuw nsw i32 %6262, 8
  %6272 = icmp eq i32 %6271, %6099
  br i1 %6272, label %6273, label %6260

6273:                                             ; preds = %6220, %6260, %6201
  %6274 = sext i32 %6099 to i64
  %6275 = mul nsw i64 %6274, %1
  %6276 = getelementptr inbounds i8, i8* %6092, i64 %6275
  %6277 = mul nsw i32 %6099, %6
  %6278 = trunc i32 %6277 to i16
  %6279 = insertelement <8 x i16> undef, i16 %6278, i32 0
  %6280 = shufflevector <8 x i16> %6279, <8 x i16> undef, <8 x i32> zeroinitializer
  %6281 = add nuw nsw i64 %6088, 8
  %6282 = trunc i64 %6281 to i32
  %6283 = shl i32 %6282, 6
  %6284 = sdiv i32 %6283, %6
  %6285 = icmp sgt i32 %6284, %5
  %6286 = select i1 %6285, i32 %5, i32 %6284
  %6287 = icmp slt i32 %6286, %2079
  %6288 = select i1 %6287, i32 %6286, i32 %2079
  %6289 = bitcast <2 x i64> %6091 to <8 x i16>
  %6290 = add <8 x i16> %6280, %6289
  %6291 = sub <8 x i16> %2088, %6280
  %6292 = sub nsw i32 0, %6277
  %6293 = icmp slt i32 %6099, %6288
  br i1 %6293, label %6294, label %6609

6294:                                             ; preds = %6273
  %6295 = ashr <8 x i16> %6090, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %6296 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %6295, <8 x i16> %6295) #11
  %6297 = add <16 x i8> %6296, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>
  %6298 = shufflevector <16 x i8> %6296, <16 x i8> %6297, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6299 = add <16 x i8> %6298, <i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15, i8 15>
  %6300 = lshr <8 x i16> %6090, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %6301 = and <8 x i16> %6300, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %6302 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6301, <8 x i16> %6301) #11
  %6303 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6302
  %6304 = shufflevector <16 x i8> %6303, <16 x i8> %6302, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6305 = sext i32 %6089 to i64
  %6306 = sext i32 %6288 to i64
  br label %6307

6307:                                             ; preds = %6307, %6294
  %6308 = phi i64 [ %6274, %6294 ], [ %6601, %6307 ]
  %6309 = phi i32 [ %6292, %6294 ], [ %6605, %6307 ]
  %6310 = phi <8 x i16> [ %6291, %6294 ], [ %6604, %6307 ]
  %6311 = phi <8 x i16> [ %6290, %6294 ], [ %6603, %6307 ]
  %6312 = phi i8* [ %6276, %6294 ], [ %6602, %6307 ]
  %6313 = add nsw i64 %6308, %6305
  %6314 = getelementptr inbounds i8, i8* %20, i64 %6313
  %6315 = getelementptr inbounds i8, i8* %6314, i64 -15
  %6316 = bitcast i8* %6315 to <16 x i8>*
  %6317 = load <16 x i8>, <16 x i8>* %6316, align 1
  %6318 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6317, <16 x i8> %6299) #11
  %6319 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6318, <16 x i8> %6304) #11
  %6320 = lshr <8 x i16> %6319, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6321 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6320, <8 x i16> zeroinitializer) #11
  %6322 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6321, <8 x i16> undef) #11
  %6323 = bitcast <16 x i8> %6322 to <2 x i64>
  %6324 = extractelement <2 x i64> %6323, i32 0
  %6325 = bitcast i8* %6312 to i64*
  store i64 %6324, i64* %6325, align 1
  %6326 = getelementptr inbounds i8, i8* %6312, i64 %1
  %6327 = getelementptr inbounds i8, i8* %6314, i64 -14
  %6328 = bitcast i8* %6327 to <16 x i8>*
  %6329 = load <16 x i8>, <16 x i8>* %6328, align 1
  %6330 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6329, <16 x i8> %6299) #11
  %6331 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6330, <16 x i8> %6304) #11
  %6332 = lshr <8 x i16> %6331, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6333 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6332, <8 x i16> zeroinitializer) #11
  %6334 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6333, <8 x i16> undef) #11
  %6335 = bitcast <16 x i8> %6334 to <2 x i64>
  %6336 = extractelement <2 x i64> %6335, i32 0
  %6337 = bitcast i8* %6326 to i64*
  store i64 %6336, i64* %6337, align 1
  %6338 = getelementptr inbounds i8, i8* %6326, i64 %1
  %6339 = getelementptr inbounds i8, i8* %6314, i64 -13
  %6340 = bitcast i8* %6339 to <16 x i8>*
  %6341 = load <16 x i8>, <16 x i8>* %6340, align 1
  %6342 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6341, <16 x i8> %6299) #11
  %6343 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6342, <16 x i8> %6304) #11
  %6344 = lshr <8 x i16> %6343, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6345 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6344, <8 x i16> zeroinitializer) #11
  %6346 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6345, <8 x i16> undef) #11
  %6347 = bitcast <16 x i8> %6346 to <2 x i64>
  %6348 = extractelement <2 x i64> %6347, i32 0
  %6349 = bitcast i8* %6338 to i64*
  store i64 %6348, i64* %6349, align 1
  %6350 = getelementptr inbounds i8, i8* %6338, i64 %1
  %6351 = getelementptr inbounds i8, i8* %6314, i64 -12
  %6352 = bitcast i8* %6351 to <16 x i8>*
  %6353 = load <16 x i8>, <16 x i8>* %6352, align 1
  %6354 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6353, <16 x i8> %6299) #11
  %6355 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6354, <16 x i8> %6304) #11
  %6356 = lshr <8 x i16> %6355, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6357 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6356, <8 x i16> zeroinitializer) #11
  %6358 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6357, <8 x i16> undef) #11
  %6359 = bitcast <16 x i8> %6358 to <2 x i64>
  %6360 = extractelement <2 x i64> %6359, i32 0
  %6361 = bitcast i8* %6350 to i64*
  store i64 %6360, i64* %6361, align 1
  %6362 = getelementptr inbounds i8, i8* %6350, i64 %1
  %6363 = getelementptr inbounds i8, i8* %6314, i64 -11
  %6364 = bitcast i8* %6363 to <16 x i8>*
  %6365 = load <16 x i8>, <16 x i8>* %6364, align 1
  %6366 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6365, <16 x i8> %6299) #11
  %6367 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6366, <16 x i8> %6304) #11
  %6368 = lshr <8 x i16> %6367, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6369 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6368, <8 x i16> zeroinitializer) #11
  %6370 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6369, <8 x i16> undef) #11
  %6371 = bitcast <16 x i8> %6370 to <2 x i64>
  %6372 = extractelement <2 x i64> %6371, i32 0
  %6373 = bitcast i8* %6362 to i64*
  store i64 %6372, i64* %6373, align 1
  %6374 = getelementptr inbounds i8, i8* %6362, i64 %1
  %6375 = getelementptr inbounds i8, i8* %6314, i64 -10
  %6376 = bitcast i8* %6375 to <16 x i8>*
  %6377 = load <16 x i8>, <16 x i8>* %6376, align 1
  %6378 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6377, <16 x i8> %6299) #11
  %6379 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6378, <16 x i8> %6304) #11
  %6380 = lshr <8 x i16> %6379, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6381 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6380, <8 x i16> zeroinitializer) #11
  %6382 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6381, <8 x i16> undef) #11
  %6383 = bitcast <16 x i8> %6382 to <2 x i64>
  %6384 = extractelement <2 x i64> %6383, i32 0
  %6385 = bitcast i8* %6374 to i64*
  store i64 %6384, i64* %6385, align 1
  %6386 = getelementptr inbounds i8, i8* %6374, i64 %1
  %6387 = getelementptr inbounds i8, i8* %6314, i64 -9
  %6388 = bitcast i8* %6387 to <16 x i8>*
  %6389 = load <16 x i8>, <16 x i8>* %6388, align 1
  %6390 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6389, <16 x i8> %6299) #11
  %6391 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6390, <16 x i8> %6304) #11
  %6392 = lshr <8 x i16> %6391, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6393 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6392, <8 x i16> zeroinitializer) #11
  %6394 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6393, <8 x i16> undef) #11
  %6395 = bitcast <16 x i8> %6394 to <2 x i64>
  %6396 = extractelement <2 x i64> %6395, i32 0
  %6397 = bitcast i8* %6386 to i64*
  store i64 %6396, i64* %6397, align 1
  %6398 = getelementptr inbounds i8, i8* %6386, i64 %1
  %6399 = getelementptr inbounds i8, i8* %6314, i64 -8
  %6400 = bitcast i8* %6399 to <16 x i8>*
  %6401 = load <16 x i8>, <16 x i8>* %6400, align 1
  %6402 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %6401, <16 x i8> %6299) #11
  %6403 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6402, <16 x i8> %6304) #11
  %6404 = lshr <8 x i16> %6403, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6405 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6404, <8 x i16> zeroinitializer) #11
  %6406 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6405, <8 x i16> undef) #11
  %6407 = bitcast <16 x i8> %6406 to <2 x i64>
  %6408 = extractelement <2 x i64> %6407, i32 0
  %6409 = bitcast i8* %6398 to i64*
  store i64 %6408, i64* %6409, align 1
  %6410 = lshr <8 x i16> %6310, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %6411 = and <8 x i16> %6410, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %6412 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6411, <8 x i16> %6411) #11
  %6413 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6412
  %6414 = shufflevector <16 x i8> %6413, <16 x i8> %6412, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6415 = ashr <8 x i16> %6311, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %6416 = bitcast <8 x i16> %6415 to <16 x i8>
  %6417 = sub nsw i32 %6309, %6
  %6418 = ashr i32 %6417, 6
  %6419 = sext i32 %6418 to i64
  %6420 = getelementptr inbounds i8, i8* %6100, i64 %6419
  %6421 = shufflevector <16 x i8> %6414, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %6422 = bitcast i8* %6420 to <16 x i8>*
  %6423 = load <16 x i8>, <16 x i8>* %6422, align 1
  %6424 = shufflevector <16 x i8> %6423, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6425 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6424, <16 x i8> %6421) #11
  %6426 = lshr <8 x i16> %6425, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6427 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6426, <8 x i16> zeroinitializer) #11
  %6428 = shufflevector <16 x i8> %6416, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %6429 = bitcast <16 x i8> %6428 to <8 x i16>
  %6430 = icmp sgt <8 x i16> %6429, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %6431 = load i64, i64* %6325, align 1
  %6432 = insertelement <2 x i64> undef, i64 %6431, i32 0
  %6433 = bitcast <2 x i64> %6432 to <16 x i8>
  %6434 = shufflevector <16 x i8> %6433, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %6435 = zext <8 x i8> %6434 to <8 x i16>
  %6436 = select <8 x i1> %6430, <8 x i16> %6435, <8 x i16> %6427
  %6437 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6436, <8 x i16> undef) #11
  %6438 = bitcast <16 x i8> %6437 to <2 x i64>
  %6439 = extractelement <2 x i64> %6438, i32 0
  store i64 %6439, i64* %6325, align 1
  %6440 = sub nsw i32 %6417, %6
  %6441 = ashr i32 %6440, 6
  %6442 = sext i32 %6441 to i64
  %6443 = getelementptr inbounds i8, i8* %6100, i64 %6442
  %6444 = shufflevector <16 x i8> %6414, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %6445 = bitcast i8* %6443 to <16 x i8>*
  %6446 = load <16 x i8>, <16 x i8>* %6445, align 1
  %6447 = shufflevector <16 x i8> %6446, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6448 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6447, <16 x i8> %6444) #11
  %6449 = lshr <8 x i16> %6448, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6450 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6449, <8 x i16> zeroinitializer) #11
  %6451 = shufflevector <16 x i8> %6416, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %6452 = bitcast <16 x i8> %6451 to <8 x i16>
  %6453 = icmp sgt <8 x i16> %6452, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %6454 = load i64, i64* %6337, align 1
  %6455 = insertelement <2 x i64> undef, i64 %6454, i32 0
  %6456 = bitcast <2 x i64> %6455 to <16 x i8>
  %6457 = shufflevector <16 x i8> %6456, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %6458 = zext <8 x i8> %6457 to <8 x i16>
  %6459 = select <8 x i1> %6453, <8 x i16> %6458, <8 x i16> %6450
  %6460 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6459, <8 x i16> undef) #11
  %6461 = bitcast <16 x i8> %6460 to <2 x i64>
  %6462 = extractelement <2 x i64> %6461, i32 0
  store i64 %6462, i64* %6337, align 1
  %6463 = sub nsw i32 %6440, %6
  %6464 = ashr i32 %6463, 6
  %6465 = sext i32 %6464 to i64
  %6466 = getelementptr inbounds i8, i8* %6100, i64 %6465
  %6467 = shufflevector <16 x i8> %6414, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %6468 = bitcast i8* %6466 to <16 x i8>*
  %6469 = load <16 x i8>, <16 x i8>* %6468, align 1
  %6470 = shufflevector <16 x i8> %6469, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6471 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6470, <16 x i8> %6467) #11
  %6472 = lshr <8 x i16> %6471, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6473 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6472, <8 x i16> zeroinitializer) #11
  %6474 = shufflevector <16 x i8> %6416, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %6475 = bitcast <16 x i8> %6474 to <8 x i16>
  %6476 = icmp sgt <8 x i16> %6475, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %6477 = load i64, i64* %6349, align 1
  %6478 = insertelement <2 x i64> undef, i64 %6477, i32 0
  %6479 = bitcast <2 x i64> %6478 to <16 x i8>
  %6480 = shufflevector <16 x i8> %6479, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %6481 = zext <8 x i8> %6480 to <8 x i16>
  %6482 = select <8 x i1> %6476, <8 x i16> %6481, <8 x i16> %6473
  %6483 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6482, <8 x i16> undef) #11
  %6484 = bitcast <16 x i8> %6483 to <2 x i64>
  %6485 = extractelement <2 x i64> %6484, i32 0
  store i64 %6485, i64* %6349, align 1
  %6486 = sub nsw i32 %6463, %6
  %6487 = ashr i32 %6486, 6
  %6488 = sext i32 %6487 to i64
  %6489 = getelementptr inbounds i8, i8* %6100, i64 %6488
  %6490 = shufflevector <16 x i8> %6414, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %6491 = bitcast i8* %6489 to <16 x i8>*
  %6492 = load <16 x i8>, <16 x i8>* %6491, align 1
  %6493 = shufflevector <16 x i8> %6492, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6494 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6493, <16 x i8> %6490) #11
  %6495 = lshr <8 x i16> %6494, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6496 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6495, <8 x i16> zeroinitializer) #11
  %6497 = shufflevector <16 x i8> %6416, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %6498 = bitcast <16 x i8> %6497 to <8 x i16>
  %6499 = icmp sgt <8 x i16> %6498, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %6500 = load i64, i64* %6361, align 1
  %6501 = insertelement <2 x i64> undef, i64 %6500, i32 0
  %6502 = bitcast <2 x i64> %6501 to <16 x i8>
  %6503 = shufflevector <16 x i8> %6502, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %6504 = zext <8 x i8> %6503 to <8 x i16>
  %6505 = select <8 x i1> %6499, <8 x i16> %6504, <8 x i16> %6496
  %6506 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6505, <8 x i16> undef) #11
  %6507 = bitcast <16 x i8> %6506 to <2 x i64>
  %6508 = extractelement <2 x i64> %6507, i32 0
  store i64 %6508, i64* %6361, align 1
  %6509 = sub nsw i32 %6486, %6
  %6510 = ashr i32 %6509, 6
  %6511 = sext i32 %6510 to i64
  %6512 = getelementptr inbounds i8, i8* %6100, i64 %6511
  %6513 = shufflevector <16 x i8> %6414, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %6514 = bitcast i8* %6512 to <16 x i8>*
  %6515 = load <16 x i8>, <16 x i8>* %6514, align 1
  %6516 = shufflevector <16 x i8> %6515, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6517 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6516, <16 x i8> %6513) #11
  %6518 = lshr <8 x i16> %6517, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6519 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6518, <8 x i16> zeroinitializer) #11
  %6520 = shufflevector <16 x i8> %6416, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %6521 = bitcast <16 x i8> %6520 to <8 x i16>
  %6522 = icmp sgt <8 x i16> %6521, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %6523 = load i64, i64* %6373, align 1
  %6524 = insertelement <2 x i64> undef, i64 %6523, i32 0
  %6525 = bitcast <2 x i64> %6524 to <16 x i8>
  %6526 = shufflevector <16 x i8> %6525, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %6527 = zext <8 x i8> %6526 to <8 x i16>
  %6528 = select <8 x i1> %6522, <8 x i16> %6527, <8 x i16> %6519
  %6529 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6528, <8 x i16> undef) #11
  %6530 = bitcast <16 x i8> %6529 to <2 x i64>
  %6531 = extractelement <2 x i64> %6530, i32 0
  store i64 %6531, i64* %6373, align 1
  %6532 = sub nsw i32 %6509, %6
  %6533 = ashr i32 %6532, 6
  %6534 = sext i32 %6533 to i64
  %6535 = getelementptr inbounds i8, i8* %6100, i64 %6534
  %6536 = shufflevector <16 x i8> %6414, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %6537 = bitcast i8* %6535 to <16 x i8>*
  %6538 = load <16 x i8>, <16 x i8>* %6537, align 1
  %6539 = shufflevector <16 x i8> %6538, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6540 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6539, <16 x i8> %6536) #11
  %6541 = lshr <8 x i16> %6540, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6542 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6541, <8 x i16> zeroinitializer) #11
  %6543 = shufflevector <16 x i8> %6416, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %6544 = bitcast <16 x i8> %6543 to <8 x i16>
  %6545 = icmp sgt <8 x i16> %6544, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %6546 = load i64, i64* %6385, align 1
  %6547 = insertelement <2 x i64> undef, i64 %6546, i32 0
  %6548 = bitcast <2 x i64> %6547 to <16 x i8>
  %6549 = shufflevector <16 x i8> %6548, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %6550 = zext <8 x i8> %6549 to <8 x i16>
  %6551 = select <8 x i1> %6545, <8 x i16> %6550, <8 x i16> %6542
  %6552 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6551, <8 x i16> undef) #11
  %6553 = bitcast <16 x i8> %6552 to <2 x i64>
  %6554 = extractelement <2 x i64> %6553, i32 0
  store i64 %6554, i64* %6385, align 1
  %6555 = sub nsw i32 %6532, %6
  %6556 = ashr i32 %6555, 6
  %6557 = sext i32 %6556 to i64
  %6558 = getelementptr inbounds i8, i8* %6100, i64 %6557
  %6559 = shufflevector <16 x i8> %6414, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %6560 = bitcast i8* %6558 to <16 x i8>*
  %6561 = load <16 x i8>, <16 x i8>* %6560, align 1
  %6562 = shufflevector <16 x i8> %6561, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6563 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6562, <16 x i8> %6559) #11
  %6564 = lshr <8 x i16> %6563, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6565 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6564, <8 x i16> zeroinitializer) #11
  %6566 = shufflevector <16 x i8> %6416, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %6567 = bitcast <16 x i8> %6566 to <8 x i16>
  %6568 = icmp sgt <8 x i16> %6567, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %6569 = load i64, i64* %6397, align 1
  %6570 = insertelement <2 x i64> undef, i64 %6569, i32 0
  %6571 = bitcast <2 x i64> %6570 to <16 x i8>
  %6572 = shufflevector <16 x i8> %6571, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %6573 = zext <8 x i8> %6572 to <8 x i16>
  %6574 = select <8 x i1> %6568, <8 x i16> %6573, <8 x i16> %6565
  %6575 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6574, <8 x i16> undef) #11
  %6576 = bitcast <16 x i8> %6575 to <2 x i64>
  %6577 = extractelement <2 x i64> %6576, i32 0
  store i64 %6577, i64* %6397, align 1
  %6578 = sub nsw i32 %6555, %6
  %6579 = ashr i32 %6578, 6
  %6580 = sext i32 %6579 to i64
  %6581 = getelementptr inbounds i8, i8* %6100, i64 %6580
  %6582 = shufflevector <16 x i8> %6414, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %6583 = bitcast i8* %6581 to <16 x i8>*
  %6584 = load <16 x i8>, <16 x i8>* %6583, align 1
  %6585 = shufflevector <16 x i8> %6584, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6586 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6585, <16 x i8> %6582) #11
  %6587 = lshr <8 x i16> %6586, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6588 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6587, <8 x i16> zeroinitializer) #11
  %6589 = shufflevector <16 x i8> %6416, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %6590 = bitcast <16 x i8> %6589 to <8 x i16>
  %6591 = icmp sgt <8 x i16> %6590, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %6592 = load i64, i64* %6409, align 1
  %6593 = insertelement <2 x i64> undef, i64 %6592, i32 0
  %6594 = bitcast <2 x i64> %6593 to <16 x i8>
  %6595 = shufflevector <16 x i8> %6594, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %6596 = zext <8 x i8> %6595 to <8 x i16>
  %6597 = select <8 x i1> %6591, <8 x i16> %6596, <8 x i16> %6588
  %6598 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6597, <8 x i16> undef) #11
  %6599 = bitcast <16 x i8> %6598 to <2 x i64>
  %6600 = extractelement <2 x i64> %6599, i32 0
  store i64 %6600, i64* %6409, align 1
  %6601 = add nsw i64 %6308, 8
  %6602 = getelementptr inbounds i8, i8* %6312, i64 %2071
  %6603 = add <8 x i16> %6311, %2083
  %6604 = sub <8 x i16> %6310, %2083
  %6605 = sub nsw i32 %6309, %2080
  %6606 = icmp slt i64 %6601, %6306
  br i1 %6606, label %6307, label %6607

6607:                                             ; preds = %6307
  %6608 = trunc i64 %6601 to i32
  br label %6609

6609:                                             ; preds = %6607, %6273
  %6610 = phi i8* [ %6276, %6273 ], [ %6602, %6607 ]
  %6611 = phi i32 [ %6099, %6273 ], [ %6608, %6607 ]
  %6612 = phi <8 x i16> [ %6290, %6273 ], [ %6603, %6607 ]
  %6613 = phi <8 x i16> [ %6291, %6273 ], [ %6604, %6607 ]
  %6614 = phi i32 [ %6292, %6273 ], [ %6605, %6607 ]
  %6615 = extractelement <8 x i16> %6090, i64 0
  %6616 = icmp slt i32 %6611, %6286
  br i1 %6616, label %6617, label %6703

6617:                                             ; preds = %6609
  %6618 = sext i16 %6615 to i32
  %6619 = ashr i32 %6618, 6
  %6620 = lshr i32 %6618, 1
  %6621 = trunc i32 %6620 to i8
  %6622 = and i8 %6621, 31
  %6623 = insertelement <16 x i8> undef, i8 %6622, i32 0
  %6624 = shufflevector <16 x i8> %6623, <16 x i8> undef, <16 x i32> zeroinitializer
  %6625 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6624
  %6626 = shufflevector <16 x i8> %6625, <16 x i8> %6624, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6627 = sext i32 %6619 to i64
  %6628 = sub i32 %6618, %7
  %6629 = ashr i32 %6628, 6
  %6630 = lshr i32 %6628, 1
  %6631 = trunc i32 %6630 to i8
  %6632 = and i8 %6631, 31
  %6633 = insertelement <16 x i8> undef, i8 %6632, i32 0
  %6634 = shufflevector <16 x i8> %6633, <16 x i8> undef, <16 x i32> zeroinitializer
  %6635 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6634
  %6636 = shufflevector <16 x i8> %6635, <16 x i8> %6634, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6637 = sext i32 %6629 to i64
  %6638 = sub i32 %6628, %7
  %6639 = ashr i32 %6638, 6
  %6640 = lshr i32 %6638, 1
  %6641 = trunc i32 %6640 to i8
  %6642 = and i8 %6641, 31
  %6643 = insertelement <16 x i8> undef, i8 %6642, i32 0
  %6644 = shufflevector <16 x i8> %6643, <16 x i8> undef, <16 x i32> zeroinitializer
  %6645 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6644
  %6646 = shufflevector <16 x i8> %6645, <16 x i8> %6644, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6647 = sext i32 %6639 to i64
  %6648 = sub i32 %6638, %7
  %6649 = ashr i32 %6648, 6
  %6650 = lshr i32 %6648, 1
  %6651 = trunc i32 %6650 to i8
  %6652 = and i8 %6651, 31
  %6653 = insertelement <16 x i8> undef, i8 %6652, i32 0
  %6654 = shufflevector <16 x i8> %6653, <16 x i8> undef, <16 x i32> zeroinitializer
  %6655 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6654
  %6656 = shufflevector <16 x i8> %6655, <16 x i8> %6654, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6657 = sext i32 %6649 to i64
  %6658 = sub i32 %6648, %7
  %6659 = ashr i32 %6658, 6
  %6660 = lshr i32 %6658, 1
  %6661 = trunc i32 %6660 to i8
  %6662 = and i8 %6661, 31
  %6663 = insertelement <16 x i8> undef, i8 %6662, i32 0
  %6664 = shufflevector <16 x i8> %6663, <16 x i8> undef, <16 x i32> zeroinitializer
  %6665 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6664
  %6666 = shufflevector <16 x i8> %6665, <16 x i8> %6664, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6667 = sext i32 %6659 to i64
  %6668 = sub i32 %6658, %7
  %6669 = ashr i32 %6668, 6
  %6670 = lshr i32 %6668, 1
  %6671 = trunc i32 %6670 to i8
  %6672 = and i8 %6671, 31
  %6673 = insertelement <16 x i8> undef, i8 %6672, i32 0
  %6674 = shufflevector <16 x i8> %6673, <16 x i8> undef, <16 x i32> zeroinitializer
  %6675 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6674
  %6676 = shufflevector <16 x i8> %6675, <16 x i8> %6674, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6677 = sext i32 %6669 to i64
  %6678 = sub i32 %6668, %7
  %6679 = ashr i32 %6678, 6
  %6680 = lshr i32 %6678, 1
  %6681 = trunc i32 %6680 to i8
  %6682 = and i8 %6681, 31
  %6683 = insertelement <16 x i8> undef, i8 %6682, i32 0
  %6684 = shufflevector <16 x i8> %6683, <16 x i8> undef, <16 x i32> zeroinitializer
  %6685 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6684
  %6686 = shufflevector <16 x i8> %6685, <16 x i8> %6684, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6687 = sext i32 %6679 to i64
  %6688 = sub i32 %6678, %7
  %6689 = ashr i32 %6688, 6
  %6690 = lshr i32 %6688, 1
  %6691 = trunc i32 %6690 to i8
  %6692 = and i8 %6691, 31
  %6693 = insertelement <16 x i8> undef, i8 %6692, i32 0
  %6694 = shufflevector <16 x i8> %6693, <16 x i8> undef, <16 x i32> zeroinitializer
  %6695 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6694
  %6696 = shufflevector <16 x i8> %6695, <16 x i8> %6694, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6697 = sext i32 %6689 to i64
  %6698 = sext i32 %6611 to i64
  %6699 = sext i32 %6089 to i64
  %6700 = sext i32 %6286 to i64
  br label %6790

6701:                                             ; preds = %6790
  %6702 = trunc i64 %7132 to i32
  br label %6703

6703:                                             ; preds = %6701, %6609
  %6704 = phi i8* [ %6610, %6609 ], [ %7133, %6701 ]
  %6705 = phi i32 [ %6611, %6609 ], [ %6702, %6701 ]
  %6706 = icmp slt i32 %6705, %5
  br i1 %6706, label %6707, label %7289

6707:                                             ; preds = %6703
  %6708 = sext i16 %6615 to i32
  %6709 = ashr i32 %6708, 6
  %6710 = lshr i32 %6708, 1
  %6711 = trunc i32 %6710 to i8
  %6712 = and i8 %6711, 31
  %6713 = insertelement <16 x i8> undef, i8 %6712, i32 0
  %6714 = shufflevector <16 x i8> %6713, <16 x i8> undef, <16 x i32> zeroinitializer
  %6715 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6714
  %6716 = shufflevector <16 x i8> %6715, <16 x i8> %6714, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6717 = sext i32 %6709 to i64
  %6718 = sub i32 %6708, %7
  %6719 = ashr i32 %6718, 6
  %6720 = lshr i32 %6718, 1
  %6721 = trunc i32 %6720 to i8
  %6722 = and i8 %6721, 31
  %6723 = insertelement <16 x i8> undef, i8 %6722, i32 0
  %6724 = shufflevector <16 x i8> %6723, <16 x i8> undef, <16 x i32> zeroinitializer
  %6725 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6724
  %6726 = shufflevector <16 x i8> %6725, <16 x i8> %6724, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6727 = sext i32 %6719 to i64
  %6728 = sub i32 %6718, %7
  %6729 = ashr i32 %6728, 6
  %6730 = lshr i32 %6728, 1
  %6731 = trunc i32 %6730 to i8
  %6732 = and i8 %6731, 31
  %6733 = insertelement <16 x i8> undef, i8 %6732, i32 0
  %6734 = shufflevector <16 x i8> %6733, <16 x i8> undef, <16 x i32> zeroinitializer
  %6735 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6734
  %6736 = shufflevector <16 x i8> %6735, <16 x i8> %6734, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6737 = sext i32 %6729 to i64
  %6738 = sub i32 %6728, %7
  %6739 = ashr i32 %6738, 6
  %6740 = lshr i32 %6738, 1
  %6741 = trunc i32 %6740 to i8
  %6742 = and i8 %6741, 31
  %6743 = insertelement <16 x i8> undef, i8 %6742, i32 0
  %6744 = shufflevector <16 x i8> %6743, <16 x i8> undef, <16 x i32> zeroinitializer
  %6745 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6744
  %6746 = shufflevector <16 x i8> %6745, <16 x i8> %6744, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6747 = sext i32 %6739 to i64
  %6748 = sub i32 %6738, %7
  %6749 = ashr i32 %6748, 6
  %6750 = lshr i32 %6748, 1
  %6751 = trunc i32 %6750 to i8
  %6752 = and i8 %6751, 31
  %6753 = insertelement <16 x i8> undef, i8 %6752, i32 0
  %6754 = shufflevector <16 x i8> %6753, <16 x i8> undef, <16 x i32> zeroinitializer
  %6755 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6754
  %6756 = shufflevector <16 x i8> %6755, <16 x i8> %6754, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6757 = sext i32 %6749 to i64
  %6758 = sub i32 %6748, %7
  %6759 = ashr i32 %6758, 6
  %6760 = lshr i32 %6758, 1
  %6761 = trunc i32 %6760 to i8
  %6762 = and i8 %6761, 31
  %6763 = insertelement <16 x i8> undef, i8 %6762, i32 0
  %6764 = shufflevector <16 x i8> %6763, <16 x i8> undef, <16 x i32> zeroinitializer
  %6765 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6764
  %6766 = shufflevector <16 x i8> %6765, <16 x i8> %6764, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6767 = sext i32 %6759 to i64
  %6768 = sub i32 %6758, %7
  %6769 = ashr i32 %6768, 6
  %6770 = lshr i32 %6768, 1
  %6771 = trunc i32 %6770 to i8
  %6772 = and i8 %6771, 31
  %6773 = insertelement <16 x i8> undef, i8 %6772, i32 0
  %6774 = shufflevector <16 x i8> %6773, <16 x i8> undef, <16 x i32> zeroinitializer
  %6775 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6774
  %6776 = shufflevector <16 x i8> %6775, <16 x i8> %6774, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6777 = sext i32 %6769 to i64
  %6778 = sub i32 %6768, %7
  %6779 = ashr i32 %6778, 6
  %6780 = lshr i32 %6778, 1
  %6781 = trunc i32 %6780 to i8
  %6782 = and i8 %6781, 31
  %6783 = insertelement <16 x i8> undef, i8 %6782, i32 0
  %6784 = shufflevector <16 x i8> %6783, <16 x i8> undef, <16 x i32> zeroinitializer
  %6785 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6784
  %6786 = shufflevector <16 x i8> %6785, <16 x i8> %6784, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6787 = sext i32 %6779 to i64
  %6788 = sext i32 %6705 to i64
  %6789 = sext i32 %6089 to i64
  br label %7138

6790:                                             ; preds = %6790, %6617
  %6791 = phi i64 [ %6698, %6617 ], [ %7132, %6790 ]
  %6792 = phi i32 [ %6614, %6617 ], [ %7136, %6790 ]
  %6793 = phi <8 x i16> [ %6613, %6617 ], [ %7135, %6790 ]
  %6794 = phi <8 x i16> [ %6612, %6617 ], [ %7134, %6790 ]
  %6795 = phi i8* [ %6610, %6617 ], [ %7133, %6790 ]
  %6796 = ashr <8 x i16> %6794, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %6797 = add nsw i64 %6791, %6699
  %6798 = getelementptr inbounds i8, i8* %20, i64 %6797
  %6799 = getelementptr inbounds i8, i8* %6798, i64 %6627
  %6800 = bitcast i8* %6799 to <16 x i8>*
  %6801 = load <16 x i8>, <16 x i8>* %6800, align 1
  %6802 = shufflevector <16 x i8> %6801, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6803 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6802, <16 x i8> %6626) #11
  %6804 = lshr <8 x i16> %6803, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6805 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6804, <8 x i16> zeroinitializer) #11
  %6806 = getelementptr inbounds i8, i8* %6798, i64 %6637
  %6807 = bitcast i8* %6806 to <16 x i8>*
  %6808 = load <16 x i8>, <16 x i8>* %6807, align 1
  %6809 = shufflevector <16 x i8> %6808, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6810 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6809, <16 x i8> %6636) #11
  %6811 = lshr <8 x i16> %6810, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6812 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6811, <8 x i16> zeroinitializer) #11
  %6813 = getelementptr inbounds i8, i8* %6798, i64 %6647
  %6814 = bitcast i8* %6813 to <16 x i8>*
  %6815 = load <16 x i8>, <16 x i8>* %6814, align 1
  %6816 = shufflevector <16 x i8> %6815, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6817 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6816, <16 x i8> %6646) #11
  %6818 = lshr <8 x i16> %6817, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6819 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6818, <8 x i16> zeroinitializer) #11
  %6820 = getelementptr inbounds i8, i8* %6798, i64 %6657
  %6821 = bitcast i8* %6820 to <16 x i8>*
  %6822 = load <16 x i8>, <16 x i8>* %6821, align 1
  %6823 = shufflevector <16 x i8> %6822, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6824 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6823, <16 x i8> %6656) #11
  %6825 = lshr <8 x i16> %6824, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6826 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6825, <8 x i16> zeroinitializer) #11
  %6827 = getelementptr inbounds i8, i8* %6798, i64 %6667
  %6828 = bitcast i8* %6827 to <16 x i8>*
  %6829 = load <16 x i8>, <16 x i8>* %6828, align 1
  %6830 = shufflevector <16 x i8> %6829, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6831 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6830, <16 x i8> %6666) #11
  %6832 = lshr <8 x i16> %6831, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6833 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6832, <8 x i16> zeroinitializer) #11
  %6834 = getelementptr inbounds i8, i8* %6798, i64 %6677
  %6835 = bitcast i8* %6834 to <16 x i8>*
  %6836 = load <16 x i8>, <16 x i8>* %6835, align 1
  %6837 = shufflevector <16 x i8> %6836, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6838 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6837, <16 x i8> %6676) #11
  %6839 = lshr <8 x i16> %6838, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6840 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6839, <8 x i16> zeroinitializer) #11
  %6841 = getelementptr inbounds i8, i8* %6798, i64 %6687
  %6842 = bitcast i8* %6841 to <16 x i8>*
  %6843 = load <16 x i8>, <16 x i8>* %6842, align 1
  %6844 = shufflevector <16 x i8> %6843, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6845 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6844, <16 x i8> %6686) #11
  %6846 = lshr <8 x i16> %6845, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6847 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6846, <8 x i16> zeroinitializer) #11
  %6848 = getelementptr inbounds i8, i8* %6798, i64 %6697
  %6849 = bitcast i8* %6848 to <16 x i8>*
  %6850 = load <16 x i8>, <16 x i8>* %6849, align 1
  %6851 = shufflevector <16 x i8> %6850, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6852 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6851, <16 x i8> %6696) #11
  %6853 = lshr <8 x i16> %6852, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6854 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6853, <8 x i16> zeroinitializer) #11
  %6855 = shufflevector <8 x i16> %6805, <8 x i16> %6812, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6856 = shufflevector <8 x i16> %6819, <8 x i16> %6826, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6857 = shufflevector <8 x i16> %6833, <8 x i16> %6840, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6858 = shufflevector <8 x i16> %6847, <8 x i16> %6854, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %6859 = shufflevector <8 x i16> %6805, <8 x i16> %6812, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6860 = shufflevector <8 x i16> %6819, <8 x i16> %6826, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6861 = shufflevector <8 x i16> %6833, <8 x i16> %6840, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6862 = shufflevector <8 x i16> %6847, <8 x i16> %6854, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %6863 = bitcast <8 x i16> %6855 to <4 x i32>
  %6864 = bitcast <8 x i16> %6856 to <4 x i32>
  %6865 = shufflevector <4 x i32> %6863, <4 x i32> %6864, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %6866 = bitcast <4 x i32> %6865 to <2 x i64>
  %6867 = bitcast <8 x i16> %6857 to <4 x i32>
  %6868 = bitcast <8 x i16> %6858 to <4 x i32>
  %6869 = shufflevector <4 x i32> %6867, <4 x i32> %6868, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %6870 = bitcast <4 x i32> %6869 to <2 x i64>
  %6871 = bitcast <8 x i16> %6859 to <4 x i32>
  %6872 = bitcast <8 x i16> %6860 to <4 x i32>
  %6873 = shufflevector <4 x i32> %6871, <4 x i32> %6872, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %6874 = bitcast <4 x i32> %6873 to <2 x i64>
  %6875 = bitcast <8 x i16> %6861 to <4 x i32>
  %6876 = bitcast <8 x i16> %6862 to <4 x i32>
  %6877 = shufflevector <4 x i32> %6875, <4 x i32> %6876, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %6878 = bitcast <4 x i32> %6877 to <2 x i64>
  %6879 = shufflevector <4 x i32> %6863, <4 x i32> %6864, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %6880 = bitcast <4 x i32> %6879 to <2 x i64>
  %6881 = shufflevector <4 x i32> %6867, <4 x i32> %6868, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %6882 = bitcast <4 x i32> %6881 to <2 x i64>
  %6883 = shufflevector <4 x i32> %6871, <4 x i32> %6872, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %6884 = bitcast <4 x i32> %6883 to <2 x i64>
  %6885 = shufflevector <4 x i32> %6875, <4 x i32> %6876, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %6886 = bitcast <4 x i32> %6885 to <2 x i64>
  %6887 = shufflevector <2 x i64> %6866, <2 x i64> %6870, <2 x i32> <i32 0, i32 2>
  %6888 = shufflevector <2 x i64> %6866, <2 x i64> %6870, <2 x i32> <i32 1, i32 3>
  %6889 = shufflevector <2 x i64> %6880, <2 x i64> %6882, <2 x i32> <i32 0, i32 2>
  %6890 = shufflevector <2 x i64> %6880, <2 x i64> %6882, <2 x i32> <i32 1, i32 3>
  %6891 = shufflevector <2 x i64> %6874, <2 x i64> %6878, <2 x i32> <i32 0, i32 2>
  %6892 = shufflevector <2 x i64> %6874, <2 x i64> %6878, <2 x i32> <i32 1, i32 3>
  %6893 = shufflevector <2 x i64> %6884, <2 x i64> %6886, <2 x i32> <i32 0, i32 2>
  %6894 = shufflevector <2 x i64> %6884, <2 x i64> %6886, <2 x i32> <i32 1, i32 3>
  %6895 = bitcast <2 x i64> %6887 to <8 x i16>
  %6896 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6895, <8 x i16> undef) #11
  %6897 = bitcast <16 x i8> %6896 to <2 x i64>
  %6898 = extractelement <2 x i64> %6897, i32 0
  %6899 = bitcast i8* %6795 to i64*
  store i64 %6898, i64* %6899, align 1
  %6900 = getelementptr inbounds i8, i8* %6795, i64 %1
  %6901 = bitcast <2 x i64> %6888 to <8 x i16>
  %6902 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6901, <8 x i16> undef) #11
  %6903 = bitcast <16 x i8> %6902 to <2 x i64>
  %6904 = extractelement <2 x i64> %6903, i32 0
  %6905 = bitcast i8* %6900 to i64*
  store i64 %6904, i64* %6905, align 1
  %6906 = getelementptr inbounds i8, i8* %6900, i64 %1
  %6907 = bitcast <2 x i64> %6889 to <8 x i16>
  %6908 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6907, <8 x i16> undef) #11
  %6909 = bitcast <16 x i8> %6908 to <2 x i64>
  %6910 = extractelement <2 x i64> %6909, i32 0
  %6911 = bitcast i8* %6906 to i64*
  store i64 %6910, i64* %6911, align 1
  %6912 = getelementptr inbounds i8, i8* %6906, i64 %1
  %6913 = bitcast <2 x i64> %6890 to <8 x i16>
  %6914 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6913, <8 x i16> undef) #11
  %6915 = bitcast <16 x i8> %6914 to <2 x i64>
  %6916 = extractelement <2 x i64> %6915, i32 0
  %6917 = bitcast i8* %6912 to i64*
  store i64 %6916, i64* %6917, align 1
  %6918 = getelementptr inbounds i8, i8* %6912, i64 %1
  %6919 = bitcast <2 x i64> %6891 to <8 x i16>
  %6920 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6919, <8 x i16> undef) #11
  %6921 = bitcast <16 x i8> %6920 to <2 x i64>
  %6922 = extractelement <2 x i64> %6921, i32 0
  %6923 = bitcast i8* %6918 to i64*
  store i64 %6922, i64* %6923, align 1
  %6924 = getelementptr inbounds i8, i8* %6918, i64 %1
  %6925 = bitcast <2 x i64> %6892 to <8 x i16>
  %6926 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6925, <8 x i16> undef) #11
  %6927 = bitcast <16 x i8> %6926 to <2 x i64>
  %6928 = extractelement <2 x i64> %6927, i32 0
  %6929 = bitcast i8* %6924 to i64*
  store i64 %6928, i64* %6929, align 1
  %6930 = getelementptr inbounds i8, i8* %6924, i64 %1
  %6931 = bitcast <2 x i64> %6893 to <8 x i16>
  %6932 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6931, <8 x i16> undef) #11
  %6933 = bitcast <16 x i8> %6932 to <2 x i64>
  %6934 = extractelement <2 x i64> %6933, i32 0
  %6935 = bitcast i8* %6930 to i64*
  store i64 %6934, i64* %6935, align 1
  %6936 = getelementptr inbounds i8, i8* %6930, i64 %1
  %6937 = bitcast <2 x i64> %6894 to <8 x i16>
  %6938 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6937, <8 x i16> undef) #11
  %6939 = bitcast <16 x i8> %6938 to <2 x i64>
  %6940 = extractelement <2 x i64> %6939, i32 0
  %6941 = bitcast i8* %6936 to i64*
  store i64 %6940, i64* %6941, align 1
  %6942 = lshr <8 x i16> %6793, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %6943 = and <8 x i16> %6942, <i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31, i16 31>
  %6944 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6943, <8 x i16> %6943) #11
  %6945 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %6944
  %6946 = shufflevector <16 x i8> %6945, <16 x i8> %6944, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %6947 = bitcast <8 x i16> %6796 to <16 x i8>
  %6948 = sub nsw i32 %6792, %6
  %6949 = ashr i32 %6948, 6
  %6950 = sext i32 %6949 to i64
  %6951 = getelementptr inbounds i8, i8* %6100, i64 %6950
  %6952 = shufflevector <16 x i8> %6946, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %6953 = bitcast i8* %6951 to <16 x i8>*
  %6954 = load <16 x i8>, <16 x i8>* %6953, align 1
  %6955 = shufflevector <16 x i8> %6954, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6956 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6955, <16 x i8> %6952) #11
  %6957 = lshr <8 x i16> %6956, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6958 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6957, <8 x i16> zeroinitializer) #11
  %6959 = shufflevector <16 x i8> %6947, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %6960 = bitcast <16 x i8> %6959 to <8 x i16>
  %6961 = icmp sgt <8 x i16> %6960, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %6962 = load i64, i64* %6899, align 1
  %6963 = insertelement <2 x i64> undef, i64 %6962, i32 0
  %6964 = bitcast <2 x i64> %6963 to <16 x i8>
  %6965 = shufflevector <16 x i8> %6964, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %6966 = zext <8 x i8> %6965 to <8 x i16>
  %6967 = select <8 x i1> %6961, <8 x i16> %6966, <8 x i16> %6958
  %6968 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6967, <8 x i16> undef) #11
  %6969 = bitcast <16 x i8> %6968 to <2 x i64>
  %6970 = extractelement <2 x i64> %6969, i32 0
  store i64 %6970, i64* %6899, align 1
  %6971 = sub nsw i32 %6948, %6
  %6972 = ashr i32 %6971, 6
  %6973 = sext i32 %6972 to i64
  %6974 = getelementptr inbounds i8, i8* %6100, i64 %6973
  %6975 = shufflevector <16 x i8> %6946, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %6976 = bitcast i8* %6974 to <16 x i8>*
  %6977 = load <16 x i8>, <16 x i8>* %6976, align 1
  %6978 = shufflevector <16 x i8> %6977, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %6979 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %6978, <16 x i8> %6975) #11
  %6980 = lshr <8 x i16> %6979, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %6981 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %6980, <8 x i16> zeroinitializer) #11
  %6982 = shufflevector <16 x i8> %6947, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %6983 = bitcast <16 x i8> %6982 to <8 x i16>
  %6984 = icmp sgt <8 x i16> %6983, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %6985 = load i64, i64* %6905, align 1
  %6986 = insertelement <2 x i64> undef, i64 %6985, i32 0
  %6987 = bitcast <2 x i64> %6986 to <16 x i8>
  %6988 = shufflevector <16 x i8> %6987, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %6989 = zext <8 x i8> %6988 to <8 x i16>
  %6990 = select <8 x i1> %6984, <8 x i16> %6989, <8 x i16> %6981
  %6991 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %6990, <8 x i16> undef) #11
  %6992 = bitcast <16 x i8> %6991 to <2 x i64>
  %6993 = extractelement <2 x i64> %6992, i32 0
  store i64 %6993, i64* %6905, align 1
  %6994 = sub nsw i32 %6971, %6
  %6995 = ashr i32 %6994, 6
  %6996 = sext i32 %6995 to i64
  %6997 = getelementptr inbounds i8, i8* %6100, i64 %6996
  %6998 = shufflevector <16 x i8> %6946, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %6999 = bitcast i8* %6997 to <16 x i8>*
  %7000 = load <16 x i8>, <16 x i8>* %6999, align 1
  %7001 = shufflevector <16 x i8> %7000, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7002 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7001, <16 x i8> %6998) #11
  %7003 = lshr <8 x i16> %7002, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7004 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7003, <8 x i16> zeroinitializer) #11
  %7005 = shufflevector <16 x i8> %6947, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %7006 = bitcast <16 x i8> %7005 to <8 x i16>
  %7007 = icmp sgt <8 x i16> %7006, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %7008 = load i64, i64* %6911, align 1
  %7009 = insertelement <2 x i64> undef, i64 %7008, i32 0
  %7010 = bitcast <2 x i64> %7009 to <16 x i8>
  %7011 = shufflevector <16 x i8> %7010, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %7012 = zext <8 x i8> %7011 to <8 x i16>
  %7013 = select <8 x i1> %7007, <8 x i16> %7012, <8 x i16> %7004
  %7014 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7013, <8 x i16> undef) #11
  %7015 = bitcast <16 x i8> %7014 to <2 x i64>
  %7016 = extractelement <2 x i64> %7015, i32 0
  store i64 %7016, i64* %6911, align 1
  %7017 = sub nsw i32 %6994, %6
  %7018 = ashr i32 %7017, 6
  %7019 = sext i32 %7018 to i64
  %7020 = getelementptr inbounds i8, i8* %6100, i64 %7019
  %7021 = shufflevector <16 x i8> %6946, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %7022 = bitcast i8* %7020 to <16 x i8>*
  %7023 = load <16 x i8>, <16 x i8>* %7022, align 1
  %7024 = shufflevector <16 x i8> %7023, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7025 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7024, <16 x i8> %7021) #11
  %7026 = lshr <8 x i16> %7025, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7027 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7026, <8 x i16> zeroinitializer) #11
  %7028 = shufflevector <16 x i8> %6947, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %7029 = bitcast <16 x i8> %7028 to <8 x i16>
  %7030 = icmp sgt <8 x i16> %7029, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %7031 = load i64, i64* %6917, align 1
  %7032 = insertelement <2 x i64> undef, i64 %7031, i32 0
  %7033 = bitcast <2 x i64> %7032 to <16 x i8>
  %7034 = shufflevector <16 x i8> %7033, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %7035 = zext <8 x i8> %7034 to <8 x i16>
  %7036 = select <8 x i1> %7030, <8 x i16> %7035, <8 x i16> %7027
  %7037 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7036, <8 x i16> undef) #11
  %7038 = bitcast <16 x i8> %7037 to <2 x i64>
  %7039 = extractelement <2 x i64> %7038, i32 0
  store i64 %7039, i64* %6917, align 1
  %7040 = sub nsw i32 %7017, %6
  %7041 = ashr i32 %7040, 6
  %7042 = sext i32 %7041 to i64
  %7043 = getelementptr inbounds i8, i8* %6100, i64 %7042
  %7044 = shufflevector <16 x i8> %6946, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %7045 = bitcast i8* %7043 to <16 x i8>*
  %7046 = load <16 x i8>, <16 x i8>* %7045, align 1
  %7047 = shufflevector <16 x i8> %7046, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7048 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7047, <16 x i8> %7044) #11
  %7049 = lshr <8 x i16> %7048, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7050 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7049, <8 x i16> zeroinitializer) #11
  %7051 = shufflevector <16 x i8> %6947, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %7052 = bitcast <16 x i8> %7051 to <8 x i16>
  %7053 = icmp sgt <8 x i16> %7052, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %7054 = load i64, i64* %6923, align 1
  %7055 = insertelement <2 x i64> undef, i64 %7054, i32 0
  %7056 = bitcast <2 x i64> %7055 to <16 x i8>
  %7057 = shufflevector <16 x i8> %7056, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %7058 = zext <8 x i8> %7057 to <8 x i16>
  %7059 = select <8 x i1> %7053, <8 x i16> %7058, <8 x i16> %7050
  %7060 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7059, <8 x i16> undef) #11
  %7061 = bitcast <16 x i8> %7060 to <2 x i64>
  %7062 = extractelement <2 x i64> %7061, i32 0
  store i64 %7062, i64* %6923, align 1
  %7063 = sub nsw i32 %7040, %6
  %7064 = ashr i32 %7063, 6
  %7065 = sext i32 %7064 to i64
  %7066 = getelementptr inbounds i8, i8* %6100, i64 %7065
  %7067 = shufflevector <16 x i8> %6946, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %7068 = bitcast i8* %7066 to <16 x i8>*
  %7069 = load <16 x i8>, <16 x i8>* %7068, align 1
  %7070 = shufflevector <16 x i8> %7069, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7071 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7070, <16 x i8> %7067) #11
  %7072 = lshr <8 x i16> %7071, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7073 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7072, <8 x i16> zeroinitializer) #11
  %7074 = shufflevector <16 x i8> %6947, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %7075 = bitcast <16 x i8> %7074 to <8 x i16>
  %7076 = icmp sgt <8 x i16> %7075, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %7077 = load i64, i64* %6929, align 1
  %7078 = insertelement <2 x i64> undef, i64 %7077, i32 0
  %7079 = bitcast <2 x i64> %7078 to <16 x i8>
  %7080 = shufflevector <16 x i8> %7079, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %7081 = zext <8 x i8> %7080 to <8 x i16>
  %7082 = select <8 x i1> %7076, <8 x i16> %7081, <8 x i16> %7073
  %7083 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7082, <8 x i16> undef) #11
  %7084 = bitcast <16 x i8> %7083 to <2 x i64>
  %7085 = extractelement <2 x i64> %7084, i32 0
  store i64 %7085, i64* %6929, align 1
  %7086 = sub nsw i32 %7063, %6
  %7087 = ashr i32 %7086, 6
  %7088 = sext i32 %7087 to i64
  %7089 = getelementptr inbounds i8, i8* %6100, i64 %7088
  %7090 = shufflevector <16 x i8> %6946, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %7091 = bitcast i8* %7089 to <16 x i8>*
  %7092 = load <16 x i8>, <16 x i8>* %7091, align 1
  %7093 = shufflevector <16 x i8> %7092, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7094 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7093, <16 x i8> %7090) #11
  %7095 = lshr <8 x i16> %7094, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7096 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7095, <8 x i16> zeroinitializer) #11
  %7097 = shufflevector <16 x i8> %6947, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %7098 = bitcast <16 x i8> %7097 to <8 x i16>
  %7099 = icmp sgt <8 x i16> %7098, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %7100 = load i64, i64* %6935, align 1
  %7101 = insertelement <2 x i64> undef, i64 %7100, i32 0
  %7102 = bitcast <2 x i64> %7101 to <16 x i8>
  %7103 = shufflevector <16 x i8> %7102, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %7104 = zext <8 x i8> %7103 to <8 x i16>
  %7105 = select <8 x i1> %7099, <8 x i16> %7104, <8 x i16> %7096
  %7106 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7105, <8 x i16> undef) #11
  %7107 = bitcast <16 x i8> %7106 to <2 x i64>
  %7108 = extractelement <2 x i64> %7107, i32 0
  store i64 %7108, i64* %6935, align 1
  %7109 = sub nsw i32 %7086, %6
  %7110 = ashr i32 %7109, 6
  %7111 = sext i32 %7110 to i64
  %7112 = getelementptr inbounds i8, i8* %6100, i64 %7111
  %7113 = shufflevector <16 x i8> %6946, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %7114 = bitcast i8* %7112 to <16 x i8>*
  %7115 = load <16 x i8>, <16 x i8>* %7114, align 1
  %7116 = shufflevector <16 x i8> %7115, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7117 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7116, <16 x i8> %7113) #11
  %7118 = lshr <8 x i16> %7117, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7119 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7118, <8 x i16> zeroinitializer) #11
  %7120 = shufflevector <16 x i8> %6947, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %7121 = bitcast <16 x i8> %7120 to <8 x i16>
  %7122 = icmp sgt <8 x i16> %7121, <i16 0, i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7>
  %7123 = load i64, i64* %6941, align 1
  %7124 = insertelement <2 x i64> undef, i64 %7123, i32 0
  %7125 = bitcast <2 x i64> %7124 to <16 x i8>
  %7126 = shufflevector <16 x i8> %7125, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %7127 = zext <8 x i8> %7126 to <8 x i16>
  %7128 = select <8 x i1> %7122, <8 x i16> %7127, <8 x i16> %7119
  %7129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7128, <8 x i16> undef) #11
  %7130 = bitcast <16 x i8> %7129 to <2 x i64>
  %7131 = extractelement <2 x i64> %7130, i32 0
  store i64 %7131, i64* %6941, align 1
  %7132 = add nsw i64 %6791, 8
  %7133 = getelementptr inbounds i8, i8* %6795, i64 %2071
  %7134 = add <8 x i16> %6794, %2083
  %7135 = sub <8 x i16> %6793, %2083
  %7136 = sub nsw i32 %6792, %2080
  %7137 = icmp slt i64 %7132, %6700
  br i1 %7137, label %6790, label %6701

7138:                                             ; preds = %7138, %6707
  %7139 = phi i64 [ %6788, %6707 ], [ %7286, %7138 ]
  %7140 = phi i8* [ %6704, %6707 ], [ %7287, %7138 ]
  %7141 = add nsw i64 %7139, %6789
  %7142 = getelementptr inbounds i8, i8* %20, i64 %7141
  %7143 = getelementptr inbounds i8, i8* %7142, i64 %6717
  %7144 = bitcast i8* %7143 to <16 x i8>*
  %7145 = load <16 x i8>, <16 x i8>* %7144, align 1
  %7146 = shufflevector <16 x i8> %7145, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7147 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7146, <16 x i8> %6716) #11
  %7148 = lshr <8 x i16> %7147, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7149 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7148, <8 x i16> zeroinitializer) #11
  %7150 = getelementptr inbounds i8, i8* %7142, i64 %6727
  %7151 = bitcast i8* %7150 to <16 x i8>*
  %7152 = load <16 x i8>, <16 x i8>* %7151, align 1
  %7153 = shufflevector <16 x i8> %7152, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7154 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7153, <16 x i8> %6726) #11
  %7155 = lshr <8 x i16> %7154, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7156 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7155, <8 x i16> zeroinitializer) #11
  %7157 = getelementptr inbounds i8, i8* %7142, i64 %6737
  %7158 = bitcast i8* %7157 to <16 x i8>*
  %7159 = load <16 x i8>, <16 x i8>* %7158, align 1
  %7160 = shufflevector <16 x i8> %7159, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7161 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7160, <16 x i8> %6736) #11
  %7162 = lshr <8 x i16> %7161, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7163 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7162, <8 x i16> zeroinitializer) #11
  %7164 = getelementptr inbounds i8, i8* %7142, i64 %6747
  %7165 = bitcast i8* %7164 to <16 x i8>*
  %7166 = load <16 x i8>, <16 x i8>* %7165, align 1
  %7167 = shufflevector <16 x i8> %7166, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7168 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7167, <16 x i8> %6746) #11
  %7169 = lshr <8 x i16> %7168, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7170 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7169, <8 x i16> zeroinitializer) #11
  %7171 = getelementptr inbounds i8, i8* %7142, i64 %6757
  %7172 = bitcast i8* %7171 to <16 x i8>*
  %7173 = load <16 x i8>, <16 x i8>* %7172, align 1
  %7174 = shufflevector <16 x i8> %7173, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7175 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7174, <16 x i8> %6756) #11
  %7176 = lshr <8 x i16> %7175, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7177 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7176, <8 x i16> zeroinitializer) #11
  %7178 = getelementptr inbounds i8, i8* %7142, i64 %6767
  %7179 = bitcast i8* %7178 to <16 x i8>*
  %7180 = load <16 x i8>, <16 x i8>* %7179, align 1
  %7181 = shufflevector <16 x i8> %7180, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7182 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7181, <16 x i8> %6766) #11
  %7183 = lshr <8 x i16> %7182, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7184 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7183, <8 x i16> zeroinitializer) #11
  %7185 = getelementptr inbounds i8, i8* %7142, i64 %6777
  %7186 = bitcast i8* %7185 to <16 x i8>*
  %7187 = load <16 x i8>, <16 x i8>* %7186, align 1
  %7188 = shufflevector <16 x i8> %7187, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7189 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7188, <16 x i8> %6776) #11
  %7190 = lshr <8 x i16> %7189, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7191 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7190, <8 x i16> zeroinitializer) #11
  %7192 = getelementptr inbounds i8, i8* %7142, i64 %6787
  %7193 = bitcast i8* %7192 to <16 x i8>*
  %7194 = load <16 x i8>, <16 x i8>* %7193, align 1
  %7195 = shufflevector <16 x i8> %7194, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %7196 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7195, <16 x i8> %6786) #11
  %7197 = lshr <8 x i16> %7196, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7198 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7197, <8 x i16> zeroinitializer) #11
  %7199 = shufflevector <8 x i16> %7149, <8 x i16> %7156, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7200 = shufflevector <8 x i16> %7163, <8 x i16> %7170, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7201 = shufflevector <8 x i16> %7177, <8 x i16> %7184, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7202 = shufflevector <8 x i16> %7191, <8 x i16> %7198, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7203 = shufflevector <8 x i16> %7149, <8 x i16> %7156, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7204 = shufflevector <8 x i16> %7163, <8 x i16> %7170, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7205 = shufflevector <8 x i16> %7177, <8 x i16> %7184, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7206 = shufflevector <8 x i16> %7191, <8 x i16> %7198, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %7207 = bitcast <8 x i16> %7199 to <4 x i32>
  %7208 = bitcast <8 x i16> %7200 to <4 x i32>
  %7209 = shufflevector <4 x i32> %7207, <4 x i32> %7208, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %7210 = bitcast <4 x i32> %7209 to <2 x i64>
  %7211 = bitcast <8 x i16> %7201 to <4 x i32>
  %7212 = bitcast <8 x i16> %7202 to <4 x i32>
  %7213 = shufflevector <4 x i32> %7211, <4 x i32> %7212, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %7214 = bitcast <4 x i32> %7213 to <2 x i64>
  %7215 = bitcast <8 x i16> %7203 to <4 x i32>
  %7216 = bitcast <8 x i16> %7204 to <4 x i32>
  %7217 = shufflevector <4 x i32> %7215, <4 x i32> %7216, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %7218 = bitcast <4 x i32> %7217 to <2 x i64>
  %7219 = bitcast <8 x i16> %7205 to <4 x i32>
  %7220 = bitcast <8 x i16> %7206 to <4 x i32>
  %7221 = shufflevector <4 x i32> %7219, <4 x i32> %7220, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %7222 = bitcast <4 x i32> %7221 to <2 x i64>
  %7223 = shufflevector <4 x i32> %7207, <4 x i32> %7208, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %7224 = bitcast <4 x i32> %7223 to <2 x i64>
  %7225 = shufflevector <4 x i32> %7211, <4 x i32> %7212, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %7226 = bitcast <4 x i32> %7225 to <2 x i64>
  %7227 = shufflevector <4 x i32> %7215, <4 x i32> %7216, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %7228 = bitcast <4 x i32> %7227 to <2 x i64>
  %7229 = shufflevector <4 x i32> %7219, <4 x i32> %7220, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %7230 = bitcast <4 x i32> %7229 to <2 x i64>
  %7231 = shufflevector <2 x i64> %7210, <2 x i64> %7214, <2 x i32> <i32 0, i32 2>
  %7232 = shufflevector <2 x i64> %7210, <2 x i64> %7214, <2 x i32> <i32 1, i32 3>
  %7233 = shufflevector <2 x i64> %7224, <2 x i64> %7226, <2 x i32> <i32 0, i32 2>
  %7234 = shufflevector <2 x i64> %7224, <2 x i64> %7226, <2 x i32> <i32 1, i32 3>
  %7235 = shufflevector <2 x i64> %7218, <2 x i64> %7222, <2 x i32> <i32 0, i32 2>
  %7236 = shufflevector <2 x i64> %7218, <2 x i64> %7222, <2 x i32> <i32 1, i32 3>
  %7237 = shufflevector <2 x i64> %7228, <2 x i64> %7230, <2 x i32> <i32 0, i32 2>
  %7238 = shufflevector <2 x i64> %7228, <2 x i64> %7230, <2 x i32> <i32 1, i32 3>
  %7239 = bitcast <2 x i64> %7231 to <8 x i16>
  %7240 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7239, <8 x i16> undef) #11
  %7241 = bitcast <16 x i8> %7240 to <2 x i64>
  %7242 = extractelement <2 x i64> %7241, i32 0
  %7243 = bitcast i8* %7140 to i64*
  store i64 %7242, i64* %7243, align 1
  %7244 = getelementptr inbounds i8, i8* %7140, i64 %1
  %7245 = bitcast <2 x i64> %7232 to <8 x i16>
  %7246 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7245, <8 x i16> undef) #11
  %7247 = bitcast <16 x i8> %7246 to <2 x i64>
  %7248 = extractelement <2 x i64> %7247, i32 0
  %7249 = bitcast i8* %7244 to i64*
  store i64 %7248, i64* %7249, align 1
  %7250 = getelementptr inbounds i8, i8* %7244, i64 %1
  %7251 = bitcast <2 x i64> %7233 to <8 x i16>
  %7252 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7251, <8 x i16> undef) #11
  %7253 = bitcast <16 x i8> %7252 to <2 x i64>
  %7254 = extractelement <2 x i64> %7253, i32 0
  %7255 = bitcast i8* %7250 to i64*
  store i64 %7254, i64* %7255, align 1
  %7256 = getelementptr inbounds i8, i8* %7250, i64 %1
  %7257 = bitcast <2 x i64> %7234 to <8 x i16>
  %7258 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7257, <8 x i16> undef) #11
  %7259 = bitcast <16 x i8> %7258 to <2 x i64>
  %7260 = extractelement <2 x i64> %7259, i32 0
  %7261 = bitcast i8* %7256 to i64*
  store i64 %7260, i64* %7261, align 1
  %7262 = getelementptr inbounds i8, i8* %7256, i64 %1
  %7263 = bitcast <2 x i64> %7235 to <8 x i16>
  %7264 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7263, <8 x i16> undef) #11
  %7265 = bitcast <16 x i8> %7264 to <2 x i64>
  %7266 = extractelement <2 x i64> %7265, i32 0
  %7267 = bitcast i8* %7262 to i64*
  store i64 %7266, i64* %7267, align 1
  %7268 = getelementptr inbounds i8, i8* %7262, i64 %1
  %7269 = bitcast <2 x i64> %7236 to <8 x i16>
  %7270 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7269, <8 x i16> undef) #11
  %7271 = bitcast <16 x i8> %7270 to <2 x i64>
  %7272 = extractelement <2 x i64> %7271, i32 0
  %7273 = bitcast i8* %7268 to i64*
  store i64 %7272, i64* %7273, align 1
  %7274 = getelementptr inbounds i8, i8* %7268, i64 %1
  %7275 = bitcast <2 x i64> %7237 to <8 x i16>
  %7276 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7275, <8 x i16> undef) #11
  %7277 = bitcast <16 x i8> %7276 to <2 x i64>
  %7278 = extractelement <2 x i64> %7277, i32 0
  %7279 = bitcast i8* %7274 to i64*
  store i64 %7278, i64* %7279, align 1
  %7280 = getelementptr inbounds i8, i8* %7274, i64 %1
  %7281 = bitcast <2 x i64> %7238 to <8 x i16>
  %7282 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7281, <8 x i16> undef) #11
  %7283 = bitcast <16 x i8> %7282 to <2 x i64>
  %7284 = extractelement <2 x i64> %7283, i32 0
  %7285 = bitcast i8* %7280 to i64*
  store i64 %7284, i64* %7285, align 1
  %7286 = add nsw i64 %7139, 8
  %7287 = getelementptr inbounds i8, i8* %7140, i64 %2071
  %7288 = icmp slt i64 %7286, %6057
  br i1 %7288, label %7138, label %7289

7289:                                             ; preds = %7138, %6703
  %7290 = add <8 x i16> %6289, <i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512, i16 -512>
  %7291 = bitcast <8 x i16> %7290 to <2 x i64>
  %7292 = add <8 x i16> %6090, %2095
  %7293 = sub nsw i32 %6089, %2090
  %7294 = icmp slt i64 %6281, %6058
  br i1 %7294, label %6087, label %6059

7295:                                             ; preds = %7370, %6064
  %7296 = phi i64 [ %6077, %6064 ], [ %7371, %7370 ]
  %7297 = getelementptr inbounds i8, i8* %0, i64 %7296
  %7298 = getelementptr inbounds i8, i8* %19, i64 %7296
  %7299 = getelementptr inbounds i8, i8* %7298, i64 %6066
  %7300 = load i8, i8* %7299, align 1
  %7301 = zext i8 %7300 to i16
  %7302 = insertelement <8 x i16> undef, i16 %7301, i32 0
  %7303 = shufflevector <8 x i16> %7302, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  br i1 %6073, label %7321, label %7304

7304:                                             ; preds = %7321, %7295
  %7305 = phi i32 [ 0, %7295 ], [ %6072, %7321 ]
  %7306 = phi i8* [ %7297, %7295 ], [ %7354, %7321 ]
  %7307 = icmp slt i32 %7305, %5
  br i1 %7307, label %7308, label %7370

7308:                                             ; preds = %7304
  %7309 = load i8, i8* %7299, align 1
  br i1 %6085, label %7318, label %7310

7310:                                             ; preds = %7308, %7310
  %7311 = phi i8* [ %7314, %7310 ], [ %7306, %7308 ]
  %7312 = phi i32 [ %7315, %7310 ], [ %7305, %7308 ]
  %7313 = phi i32 [ %7316, %7310 ], [ %6084, %7308 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %7311, i8 %7309, i64 4, i1 false) #11
  %7314 = getelementptr inbounds i8, i8* %7311, i64 %1
  %7315 = add nuw nsw i32 %7312, 1
  %7316 = add i32 %7313, -1
  %7317 = icmp eq i32 %7316, 0
  br i1 %7317, label %7318, label %7310, !llvm.loop !25

7318:                                             ; preds = %7310, %7308
  %7319 = phi i8* [ %7306, %7308 ], [ %7314, %7310 ]
  %7320 = phi i32 [ %7305, %7308 ], [ %7315, %7310 ]
  br i1 %6086, label %7370, label %7357

7321:                                             ; preds = %7295, %7321
  %7322 = phi i8* [ %7354, %7321 ], [ %7297, %7295 ]
  %7323 = phi i32 [ %7353, %7321 ], [ 0, %7295 ]
  %7324 = phi i32 [ %7355, %7321 ], [ %2084, %7295 ]
  %7325 = ashr i32 %7324, 6
  %7326 = lshr i32 %7324, 1
  %7327 = trunc i32 %7326 to i8
  %7328 = and i8 %7327, 31
  %7329 = insertelement <16 x i8> undef, i8 %7328, i32 0
  %7330 = shufflevector <16 x i8> %7329, <16 x i8> undef, <16 x i32> zeroinitializer
  %7331 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %7330
  %7332 = shufflevector <16 x i8> %7331, <16 x i8> %7330, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %7333 = trunc i32 %7325 to i16
  %7334 = insertelement <8 x i16> undef, i16 %7333, i32 0
  %7335 = shufflevector <8 x i16> %7334, <8 x i16> undef, <8 x i32> zeroinitializer
  %7336 = add <8 x i16> %7335, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %7337 = sext i32 %7325 to i64
  %7338 = getelementptr inbounds i8, i8* %7298, i64 %7337
  %7339 = bitcast i8* %7338 to i64*
  %7340 = load i64, i64* %7339, align 1
  %7341 = insertelement <2 x i64> undef, i64 %7340, i32 0
  %7342 = bitcast <2 x i64> %7341 to <16 x i8>
  %7343 = shufflevector <16 x i8> %7342, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %7344 = icmp sgt <8 x i16> %7336, %6076
  %7345 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %7343, <16 x i8> %7332) #11
  %7346 = lshr <8 x i16> %7345, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %7347 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %7346, <8 x i16> zeroinitializer) #11
  %7348 = select <8 x i1> %7344, <8 x i16> %7303, <8 x i16> %7347
  %7349 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %7348, <8 x i16> undef) #11
  %7350 = bitcast <16 x i8> %7349 to <4 x i32>
  %7351 = extractelement <4 x i32> %7350, i32 0
  %7352 = bitcast i8* %7322 to i32*
  store i32 %7351, i32* %7352, align 1
  %7353 = add nuw nsw i32 %7323, 1
  %7354 = getelementptr inbounds i8, i8* %7322, i64 %1
  %7355 = sub i32 %7324, %6
  %7356 = icmp slt i32 %7353, %6072
  br i1 %7356, label %7321, label %7304

7357:                                             ; preds = %7318, %7357
  %7358 = phi i8* [ %7367, %7357 ], [ %7319, %7318 ]
  %7359 = phi i32 [ %7368, %7357 ], [ %7320, %7318 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %7358, i8 %7309, i64 4, i1 false) #11
  %7360 = getelementptr inbounds i8, i8* %7358, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %7360, i8 %7309, i64 4, i1 false) #11
  %7361 = getelementptr inbounds i8, i8* %7360, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %7361, i8 %7309, i64 4, i1 false) #11
  %7362 = getelementptr inbounds i8, i8* %7361, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %7362, i8 %7309, i64 4, i1 false) #11
  %7363 = getelementptr inbounds i8, i8* %7362, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %7363, i8 %7309, i64 4, i1 false) #11
  %7364 = getelementptr inbounds i8, i8* %7363, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %7364, i8 %7309, i64 4, i1 false) #11
  %7365 = getelementptr inbounds i8, i8* %7364, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %7365, i8 %7309, i64 4, i1 false) #11
  %7366 = getelementptr inbounds i8, i8* %7365, i64 %1
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %7366, i8 %7309, i64 4, i1 false) #11
  %7367 = getelementptr inbounds i8, i8* %7366, i64 %1
  %7368 = add nuw nsw i32 %7359, 8
  %7369 = icmp eq i32 %7368, %5
  br i1 %7369, label %7370, label %7357

7370:                                             ; preds = %7318, %7357, %7304
  %7371 = add nuw nsw i64 %7296, 4
  %7372 = icmp slt i64 %7371, %6078
  br i1 %7372, label %7295, label %7373

7373:                                             ; preds = %7370, %6032, %4705, %3394, %2067, %1565, %1062, %554, %6061, %4735, %3423, %2124, %1594, %1092, %583, %75
  call void @llvm.lifetime.end.p0i8(i64 288, i8* nonnull %14) #11
  call void @llvm.lifetime.end.p0i8(i64 288, i8* nonnull %13) #11
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_137DirectionalIntraPredictorZone3_SSE4_1EPvlPKviiib(i8* nocapture, i64, i8* nocapture readonly, i32, i32, i32, i1 zeroext) #3 {
  %8 = zext i1 %6 to i32
  %9 = icmp eq i32 %3, 4
  %10 = icmp eq i32 %4, 4
  %11 = or i1 %9, %10
  br i1 %11, label %12, label %236

12:                                               ; preds = %7
  %13 = shl i64 %1, 2
  %14 = shl i32 %5, 2
  br i1 %6, label %18, label %15

15:                                               ; preds = %12
  %16 = sext i32 %4 to i64
  %17 = sext i32 %3 to i64
  br label %125

18:                                               ; preds = %12
  %19 = sext i32 %3 to i64
  br label %20

20:                                               ; preds = %18, %121
  %21 = phi i64 [ 0, %18 ], [ %123, %121 ]
  %22 = phi i32 [ %5, %18 ], [ %122, %121 ]
  %23 = getelementptr inbounds i8, i8* %0, i64 %21
  %24 = ashr i32 %22, 5
  %25 = trunc i32 %22 to i8
  %26 = and i8 %25, 31
  %27 = insertelement <16 x i8> undef, i8 %26, i32 0
  %28 = shufflevector <16 x i8> %27, <16 x i8> undef, <16 x i32> zeroinitializer
  %29 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %28
  %30 = shufflevector <16 x i8> %29, <16 x i8> %28, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %31 = sext i32 %24 to i64
  %32 = add nsw i32 %22, %5
  %33 = ashr i32 %32, 5
  %34 = trunc i32 %32 to i8
  %35 = and i8 %34, 31
  %36 = insertelement <16 x i8> undef, i8 %35, i32 0
  %37 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> zeroinitializer
  %38 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %37
  %39 = shufflevector <16 x i8> %38, <16 x i8> %37, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %40 = sext i32 %33 to i64
  %41 = add nsw i32 %32, %5
  %42 = ashr i32 %41, 5
  %43 = trunc i32 %41 to i8
  %44 = and i8 %43, 31
  %45 = insertelement <16 x i8> undef, i8 %44, i32 0
  %46 = shufflevector <16 x i8> %45, <16 x i8> undef, <16 x i32> zeroinitializer
  %47 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %46
  %48 = shufflevector <16 x i8> %47, <16 x i8> %46, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %49 = sext i32 %42 to i64
  %50 = add nsw i32 %41, %5
  %51 = ashr i32 %50, 5
  %52 = trunc i32 %50 to i8
  %53 = and i8 %52, 31
  %54 = insertelement <16 x i8> undef, i8 %53, i32 0
  %55 = shufflevector <16 x i8> %54, <16 x i8> undef, <16 x i32> zeroinitializer
  %56 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %55
  %57 = shufflevector <16 x i8> %56, <16 x i8> %55, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %58 = sext i32 %51 to i64
  br label %59

59:                                               ; preds = %59, %20
  %60 = phi i8* [ %23, %20 ], [ %118, %59 ]
  %61 = phi i32 [ 0, %20 ], [ %119, %59 ]
  %62 = shl i32 %61, %8
  %63 = sext i32 %62 to i64
  %64 = getelementptr inbounds i8, i8* %2, i64 %63
  %65 = getelementptr inbounds i8, i8* %64, i64 %31
  %66 = bitcast i8* %65 to i64*
  %67 = load i64, i64* %66, align 1
  %68 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %67, i32 0
  %69 = bitcast <2 x i64> %68 to <16 x i8>
  %70 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %69, <16 x i8> %30) #11
  %71 = lshr <8 x i16> %70, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %72 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %71, <8 x i16> zeroinitializer) #11
  %73 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %72, <8 x i16> undef) #11
  %74 = getelementptr inbounds i8, i8* %64, i64 %40
  %75 = bitcast i8* %74 to i64*
  %76 = load i64, i64* %75, align 1
  %77 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %76, i32 0
  %78 = bitcast <2 x i64> %77 to <16 x i8>
  %79 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %78, <16 x i8> %39) #11
  %80 = lshr <8 x i16> %79, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %81 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %80, <8 x i16> zeroinitializer) #11
  %82 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> undef) #11
  %83 = getelementptr inbounds i8, i8* %64, i64 %49
  %84 = bitcast i8* %83 to i64*
  %85 = load i64, i64* %84, align 1
  %86 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %85, i32 0
  %87 = bitcast <2 x i64> %86 to <16 x i8>
  %88 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %87, <16 x i8> %48) #11
  %89 = lshr <8 x i16> %88, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %90 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %89, <8 x i16> zeroinitializer) #11
  %91 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %90, <8 x i16> undef) #11
  %92 = getelementptr inbounds i8, i8* %64, i64 %58
  %93 = bitcast i8* %92 to i64*
  %94 = load i64, i64* %93, align 1
  %95 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %94, i32 0
  %96 = bitcast <2 x i64> %95 to <16 x i8>
  %97 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %96, <16 x i8> %57) #11
  %98 = lshr <8 x i16> %97, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %99 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %98, <8 x i16> zeroinitializer) #11
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> undef) #11
  %101 = shufflevector <16 x i8> %73, <16 x i8> %82, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %102 = shufflevector <16 x i8> %91, <16 x i8> %100, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %103 = bitcast <16 x i8> %101 to <8 x i16>
  %104 = bitcast <16 x i8> %102 to <8 x i16>
  %105 = shufflevector <8 x i16> %103, <8 x i16> %104, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %106 = bitcast <8 x i16> %105 to <4 x i32>
  %107 = extractelement <4 x i32> %106, i32 0
  %108 = bitcast i8* %60 to i32*
  store i32 %107, i32* %108, align 1
  %109 = getelementptr inbounds i8, i8* %60, i64 %1
  %110 = extractelement <4 x i32> %106, i64 1
  %111 = bitcast i8* %109 to i32*
  store i32 %110, i32* %111, align 1
  %112 = getelementptr inbounds i8, i8* %109, i64 %1
  %113 = extractelement <4 x i32> %106, i64 2
  %114 = bitcast i8* %112 to i32*
  store i32 %113, i32* %114, align 1
  %115 = getelementptr inbounds i8, i8* %112, i64 %1
  %116 = extractelement <4 x i32> %106, i64 3
  %117 = bitcast i8* %115 to i32*
  store i32 %116, i32* %117, align 1
  %118 = getelementptr inbounds i8, i8* %60, i64 %13
  %119 = add nuw nsw i32 %61, 4
  %120 = icmp slt i32 %119, %4
  br i1 %120, label %59, label %121

121:                                              ; preds = %59
  %122 = add nsw i32 %22, %14
  %123 = add nuw nsw i64 %21, 4
  %124 = icmp slt i64 %123, %19
  br i1 %124, label %20, label %702

125:                                              ; preds = %15, %232
  %126 = phi i64 [ 0, %15 ], [ %234, %232 ]
  %127 = phi i32 [ %5, %15 ], [ %233, %232 ]
  %128 = getelementptr inbounds i8, i8* %0, i64 %126
  %129 = ashr i32 %127, 6
  %130 = lshr i32 %127, 1
  %131 = trunc i32 %130 to i8
  %132 = and i8 %131, 31
  %133 = insertelement <16 x i8> undef, i8 %132, i32 0
  %134 = shufflevector <16 x i8> %133, <16 x i8> undef, <16 x i32> zeroinitializer
  %135 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %134
  %136 = shufflevector <16 x i8> %135, <16 x i8> %134, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %137 = sext i32 %129 to i64
  %138 = add nsw i32 %127, %5
  %139 = ashr i32 %138, 6
  %140 = lshr i32 %138, 1
  %141 = trunc i32 %140 to i8
  %142 = and i8 %141, 31
  %143 = insertelement <16 x i8> undef, i8 %142, i32 0
  %144 = shufflevector <16 x i8> %143, <16 x i8> undef, <16 x i32> zeroinitializer
  %145 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %144
  %146 = shufflevector <16 x i8> %145, <16 x i8> %144, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %147 = sext i32 %139 to i64
  %148 = add nsw i32 %138, %5
  %149 = ashr i32 %148, 6
  %150 = lshr i32 %148, 1
  %151 = trunc i32 %150 to i8
  %152 = and i8 %151, 31
  %153 = insertelement <16 x i8> undef, i8 %152, i32 0
  %154 = shufflevector <16 x i8> %153, <16 x i8> undef, <16 x i32> zeroinitializer
  %155 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %154
  %156 = shufflevector <16 x i8> %155, <16 x i8> %154, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %157 = sext i32 %149 to i64
  %158 = add nsw i32 %148, %5
  %159 = ashr i32 %158, 6
  %160 = lshr i32 %158, 1
  %161 = trunc i32 %160 to i8
  %162 = and i8 %161, 31
  %163 = insertelement <16 x i8> undef, i8 %162, i32 0
  %164 = shufflevector <16 x i8> %163, <16 x i8> undef, <16 x i32> zeroinitializer
  %165 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %164
  %166 = shufflevector <16 x i8> %165, <16 x i8> %164, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %167 = sext i32 %159 to i64
  br label %168

168:                                              ; preds = %168, %125
  %169 = phi i64 [ %230, %168 ], [ 0, %125 ]
  %170 = phi i8* [ %229, %168 ], [ %128, %125 ]
  %171 = getelementptr inbounds i8, i8* %2, i64 %169
  %172 = getelementptr inbounds i8, i8* %171, i64 %137
  %173 = bitcast i8* %172 to i64*
  %174 = load i64, i64* %173, align 1
  %175 = insertelement <2 x i64> undef, i64 %174, i32 0
  %176 = bitcast <2 x i64> %175 to <16 x i8>
  %177 = shufflevector <16 x i8> %176, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %178 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %177, <16 x i8> %136) #11
  %179 = lshr <8 x i16> %178, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %180 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %179, <8 x i16> zeroinitializer) #11
  %181 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %180, <8 x i16> undef) #11
  %182 = getelementptr inbounds i8, i8* %171, i64 %147
  %183 = bitcast i8* %182 to i64*
  %184 = load i64, i64* %183, align 1
  %185 = insertelement <2 x i64> undef, i64 %184, i32 0
  %186 = bitcast <2 x i64> %185 to <16 x i8>
  %187 = shufflevector <16 x i8> %186, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %188 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %187, <16 x i8> %146) #11
  %189 = lshr <8 x i16> %188, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %190 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %189, <8 x i16> zeroinitializer) #11
  %191 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %190, <8 x i16> undef) #11
  %192 = getelementptr inbounds i8, i8* %171, i64 %157
  %193 = bitcast i8* %192 to i64*
  %194 = load i64, i64* %193, align 1
  %195 = insertelement <2 x i64> undef, i64 %194, i32 0
  %196 = bitcast <2 x i64> %195 to <16 x i8>
  %197 = shufflevector <16 x i8> %196, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %198 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %197, <16 x i8> %156) #11
  %199 = lshr <8 x i16> %198, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %200 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %199, <8 x i16> zeroinitializer) #11
  %201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %200, <8 x i16> undef) #11
  %202 = getelementptr inbounds i8, i8* %171, i64 %167
  %203 = bitcast i8* %202 to i64*
  %204 = load i64, i64* %203, align 1
  %205 = insertelement <2 x i64> undef, i64 %204, i32 0
  %206 = bitcast <2 x i64> %205 to <16 x i8>
  %207 = shufflevector <16 x i8> %206, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0>
  %208 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %207, <16 x i8> %166) #11
  %209 = lshr <8 x i16> %208, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %210 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %209, <8 x i16> zeroinitializer) #11
  %211 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %210, <8 x i16> undef) #11
  %212 = shufflevector <16 x i8> %181, <16 x i8> %191, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %213 = shufflevector <16 x i8> %201, <16 x i8> %211, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %214 = bitcast <16 x i8> %212 to <8 x i16>
  %215 = bitcast <16 x i8> %213 to <8 x i16>
  %216 = shufflevector <8 x i16> %214, <8 x i16> %215, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %217 = bitcast <8 x i16> %216 to <4 x i32>
  %218 = extractelement <4 x i32> %217, i32 0
  %219 = bitcast i8* %170 to i32*
  store i32 %218, i32* %219, align 1
  %220 = getelementptr inbounds i8, i8* %170, i64 %1
  %221 = extractelement <4 x i32> %217, i64 1
  %222 = bitcast i8* %220 to i32*
  store i32 %221, i32* %222, align 1
  %223 = getelementptr inbounds i8, i8* %220, i64 %1
  %224 = extractelement <4 x i32> %217, i64 2
  %225 = bitcast i8* %223 to i32*
  store i32 %224, i32* %225, align 1
  %226 = getelementptr inbounds i8, i8* %223, i64 %1
  %227 = extractelement <4 x i32> %217, i64 3
  %228 = bitcast i8* %226 to i32*
  store i32 %227, i32* %228, align 1
  %229 = getelementptr inbounds i8, i8* %170, i64 %13
  %230 = add nuw nsw i64 %169, 4
  %231 = icmp slt i64 %230, %16
  br i1 %231, label %168, label %232

232:                                              ; preds = %168
  %233 = add nsw i32 %127, %14
  %234 = add nuw nsw i64 %126, 4
  %235 = icmp slt i64 %234, %17
  br i1 %235, label %125, label %702

236:                                              ; preds = %7
  %237 = shl i64 %1, 3
  %238 = shl i32 %5, 3
  %239 = sext i32 %3 to i64
  br i1 %6, label %240, label %463

240:                                              ; preds = %236, %459
  %241 = phi i64 [ %461, %459 ], [ 0, %236 ]
  %242 = phi i32 [ %460, %459 ], [ %5, %236 ]
  %243 = getelementptr inbounds i8, i8* %0, i64 %241
  %244 = ashr i32 %242, 5
  %245 = trunc i32 %242 to i8
  %246 = and i8 %245, 31
  %247 = insertelement <16 x i8> undef, i8 %246, i32 0
  %248 = shufflevector <16 x i8> %247, <16 x i8> undef, <16 x i32> zeroinitializer
  %249 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %248
  %250 = shufflevector <16 x i8> %249, <16 x i8> %248, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %251 = sext i32 %244 to i64
  %252 = add nsw i32 %242, %5
  %253 = ashr i32 %252, 5
  %254 = trunc i32 %252 to i8
  %255 = and i8 %254, 31
  %256 = insertelement <16 x i8> undef, i8 %255, i32 0
  %257 = shufflevector <16 x i8> %256, <16 x i8> undef, <16 x i32> zeroinitializer
  %258 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %257
  %259 = shufflevector <16 x i8> %258, <16 x i8> %257, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %260 = sext i32 %253 to i64
  %261 = add nsw i32 %252, %5
  %262 = ashr i32 %261, 5
  %263 = trunc i32 %261 to i8
  %264 = and i8 %263, 31
  %265 = insertelement <16 x i8> undef, i8 %264, i32 0
  %266 = shufflevector <16 x i8> %265, <16 x i8> undef, <16 x i32> zeroinitializer
  %267 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %266
  %268 = shufflevector <16 x i8> %267, <16 x i8> %266, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %269 = sext i32 %262 to i64
  %270 = add nsw i32 %261, %5
  %271 = ashr i32 %270, 5
  %272 = trunc i32 %270 to i8
  %273 = and i8 %272, 31
  %274 = insertelement <16 x i8> undef, i8 %273, i32 0
  %275 = shufflevector <16 x i8> %274, <16 x i8> undef, <16 x i32> zeroinitializer
  %276 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %275
  %277 = shufflevector <16 x i8> %276, <16 x i8> %275, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %278 = sext i32 %271 to i64
  %279 = add nsw i32 %270, %5
  %280 = ashr i32 %279, 5
  %281 = trunc i32 %279 to i8
  %282 = and i8 %281, 31
  %283 = insertelement <16 x i8> undef, i8 %282, i32 0
  %284 = shufflevector <16 x i8> %283, <16 x i8> undef, <16 x i32> zeroinitializer
  %285 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %284
  %286 = shufflevector <16 x i8> %285, <16 x i8> %284, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %287 = sext i32 %280 to i64
  %288 = add nsw i32 %279, %5
  %289 = ashr i32 %288, 5
  %290 = trunc i32 %288 to i8
  %291 = and i8 %290, 31
  %292 = insertelement <16 x i8> undef, i8 %291, i32 0
  %293 = shufflevector <16 x i8> %292, <16 x i8> undef, <16 x i32> zeroinitializer
  %294 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %293
  %295 = shufflevector <16 x i8> %294, <16 x i8> %293, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %296 = sext i32 %289 to i64
  %297 = add nsw i32 %288, %5
  %298 = ashr i32 %297, 5
  %299 = trunc i32 %297 to i8
  %300 = and i8 %299, 31
  %301 = insertelement <16 x i8> undef, i8 %300, i32 0
  %302 = shufflevector <16 x i8> %301, <16 x i8> undef, <16 x i32> zeroinitializer
  %303 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %302
  %304 = shufflevector <16 x i8> %303, <16 x i8> %302, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %305 = sext i32 %298 to i64
  %306 = add nsw i32 %297, %5
  %307 = ashr i32 %306, 5
  %308 = trunc i32 %306 to i8
  %309 = and i8 %308, 31
  %310 = insertelement <16 x i8> undef, i8 %309, i32 0
  %311 = shufflevector <16 x i8> %310, <16 x i8> undef, <16 x i32> zeroinitializer
  %312 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %311
  %313 = shufflevector <16 x i8> %312, <16 x i8> %311, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %314 = sext i32 %307 to i64
  br label %315

315:                                              ; preds = %315, %240
  %316 = phi i8* [ %243, %240 ], [ %456, %315 ]
  %317 = phi i32 [ 0, %240 ], [ %457, %315 ]
  %318 = shl i32 %317, %8
  %319 = sext i32 %318 to i64
  %320 = getelementptr inbounds i8, i8* %2, i64 %319
  %321 = getelementptr inbounds i8, i8* %320, i64 %251
  %322 = bitcast i8* %321 to <16 x i8>*
  %323 = load <16 x i8>, <16 x i8>* %322, align 1
  %324 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %323, <16 x i8> %250) #11
  %325 = lshr <8 x i16> %324, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %326 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %325, <8 x i16> zeroinitializer) #11
  %327 = getelementptr inbounds i8, i8* %320, i64 %260
  %328 = bitcast i8* %327 to <16 x i8>*
  %329 = load <16 x i8>, <16 x i8>* %328, align 1
  %330 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %329, <16 x i8> %259) #11
  %331 = lshr <8 x i16> %330, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %332 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %331, <8 x i16> zeroinitializer) #11
  %333 = getelementptr inbounds i8, i8* %320, i64 %269
  %334 = bitcast i8* %333 to <16 x i8>*
  %335 = load <16 x i8>, <16 x i8>* %334, align 1
  %336 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %335, <16 x i8> %268) #11
  %337 = lshr <8 x i16> %336, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %338 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %337, <8 x i16> zeroinitializer) #11
  %339 = getelementptr inbounds i8, i8* %320, i64 %278
  %340 = bitcast i8* %339 to <16 x i8>*
  %341 = load <16 x i8>, <16 x i8>* %340, align 1
  %342 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %341, <16 x i8> %277) #11
  %343 = lshr <8 x i16> %342, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %344 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %343, <8 x i16> zeroinitializer) #11
  %345 = getelementptr inbounds i8, i8* %320, i64 %287
  %346 = bitcast i8* %345 to <16 x i8>*
  %347 = load <16 x i8>, <16 x i8>* %346, align 1
  %348 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %347, <16 x i8> %286) #11
  %349 = lshr <8 x i16> %348, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %350 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %349, <8 x i16> zeroinitializer) #11
  %351 = getelementptr inbounds i8, i8* %320, i64 %296
  %352 = bitcast i8* %351 to <16 x i8>*
  %353 = load <16 x i8>, <16 x i8>* %352, align 1
  %354 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %353, <16 x i8> %295) #11
  %355 = lshr <8 x i16> %354, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %356 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %355, <8 x i16> zeroinitializer) #11
  %357 = getelementptr inbounds i8, i8* %320, i64 %305
  %358 = bitcast i8* %357 to <16 x i8>*
  %359 = load <16 x i8>, <16 x i8>* %358, align 1
  %360 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %359, <16 x i8> %304) #11
  %361 = lshr <8 x i16> %360, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %362 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %361, <8 x i16> zeroinitializer) #11
  %363 = getelementptr inbounds i8, i8* %320, i64 %314
  %364 = bitcast i8* %363 to <16 x i8>*
  %365 = load <16 x i8>, <16 x i8>* %364, align 1
  %366 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %365, <16 x i8> %313) #11
  %367 = lshr <8 x i16> %366, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %368 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %367, <8 x i16> zeroinitializer) #11
  %369 = shufflevector <8 x i16> %326, <8 x i16> %332, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %370 = shufflevector <8 x i16> %338, <8 x i16> %344, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %371 = shufflevector <8 x i16> %350, <8 x i16> %356, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %372 = shufflevector <8 x i16> %362, <8 x i16> %368, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %373 = shufflevector <8 x i16> %326, <8 x i16> %332, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %374 = shufflevector <8 x i16> %338, <8 x i16> %344, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %375 = shufflevector <8 x i16> %350, <8 x i16> %356, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %376 = shufflevector <8 x i16> %362, <8 x i16> %368, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %377 = bitcast <8 x i16> %369 to <4 x i32>
  %378 = bitcast <8 x i16> %370 to <4 x i32>
  %379 = shufflevector <4 x i32> %377, <4 x i32> %378, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %380 = bitcast <4 x i32> %379 to <2 x i64>
  %381 = bitcast <8 x i16> %371 to <4 x i32>
  %382 = bitcast <8 x i16> %372 to <4 x i32>
  %383 = shufflevector <4 x i32> %381, <4 x i32> %382, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %384 = bitcast <4 x i32> %383 to <2 x i64>
  %385 = bitcast <8 x i16> %373 to <4 x i32>
  %386 = bitcast <8 x i16> %374 to <4 x i32>
  %387 = shufflevector <4 x i32> %385, <4 x i32> %386, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %388 = bitcast <4 x i32> %387 to <2 x i64>
  %389 = bitcast <8 x i16> %375 to <4 x i32>
  %390 = bitcast <8 x i16> %376 to <4 x i32>
  %391 = shufflevector <4 x i32> %389, <4 x i32> %390, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %392 = bitcast <4 x i32> %391 to <2 x i64>
  %393 = shufflevector <4 x i32> %377, <4 x i32> %378, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %394 = bitcast <4 x i32> %393 to <2 x i64>
  %395 = shufflevector <4 x i32> %381, <4 x i32> %382, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %396 = bitcast <4 x i32> %395 to <2 x i64>
  %397 = shufflevector <4 x i32> %385, <4 x i32> %386, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %398 = bitcast <4 x i32> %397 to <2 x i64>
  %399 = shufflevector <4 x i32> %389, <4 x i32> %390, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %400 = bitcast <4 x i32> %399 to <2 x i64>
  %401 = shufflevector <2 x i64> %380, <2 x i64> %384, <2 x i32> <i32 0, i32 2>
  %402 = shufflevector <2 x i64> %380, <2 x i64> %384, <2 x i32> <i32 1, i32 3>
  %403 = shufflevector <2 x i64> %394, <2 x i64> %396, <2 x i32> <i32 0, i32 2>
  %404 = shufflevector <2 x i64> %394, <2 x i64> %396, <2 x i32> <i32 1, i32 3>
  %405 = shufflevector <2 x i64> %388, <2 x i64> %392, <2 x i32> <i32 0, i32 2>
  %406 = shufflevector <2 x i64> %388, <2 x i64> %392, <2 x i32> <i32 1, i32 3>
  %407 = shufflevector <2 x i64> %398, <2 x i64> %400, <2 x i32> <i32 0, i32 2>
  %408 = shufflevector <2 x i64> %398, <2 x i64> %400, <2 x i32> <i32 1, i32 3>
  %409 = bitcast <2 x i64> %401 to <8 x i16>
  %410 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %409, <8 x i16> undef) #11
  %411 = bitcast <16 x i8> %410 to <2 x i64>
  %412 = extractelement <2 x i64> %411, i32 0
  %413 = bitcast i8* %316 to i64*
  store i64 %412, i64* %413, align 1
  %414 = getelementptr inbounds i8, i8* %316, i64 %1
  %415 = bitcast <2 x i64> %402 to <8 x i16>
  %416 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %415, <8 x i16> undef) #11
  %417 = bitcast <16 x i8> %416 to <2 x i64>
  %418 = extractelement <2 x i64> %417, i32 0
  %419 = bitcast i8* %414 to i64*
  store i64 %418, i64* %419, align 1
  %420 = getelementptr inbounds i8, i8* %414, i64 %1
  %421 = bitcast <2 x i64> %403 to <8 x i16>
  %422 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %421, <8 x i16> undef) #11
  %423 = bitcast <16 x i8> %422 to <2 x i64>
  %424 = extractelement <2 x i64> %423, i32 0
  %425 = bitcast i8* %420 to i64*
  store i64 %424, i64* %425, align 1
  %426 = getelementptr inbounds i8, i8* %420, i64 %1
  %427 = bitcast <2 x i64> %404 to <8 x i16>
  %428 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %427, <8 x i16> undef) #11
  %429 = bitcast <16 x i8> %428 to <2 x i64>
  %430 = extractelement <2 x i64> %429, i32 0
  %431 = bitcast i8* %426 to i64*
  store i64 %430, i64* %431, align 1
  %432 = getelementptr inbounds i8, i8* %426, i64 %1
  %433 = bitcast <2 x i64> %405 to <8 x i16>
  %434 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %433, <8 x i16> undef) #11
  %435 = bitcast <16 x i8> %434 to <2 x i64>
  %436 = extractelement <2 x i64> %435, i32 0
  %437 = bitcast i8* %432 to i64*
  store i64 %436, i64* %437, align 1
  %438 = getelementptr inbounds i8, i8* %432, i64 %1
  %439 = bitcast <2 x i64> %406 to <8 x i16>
  %440 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %439, <8 x i16> undef) #11
  %441 = bitcast <16 x i8> %440 to <2 x i64>
  %442 = extractelement <2 x i64> %441, i32 0
  %443 = bitcast i8* %438 to i64*
  store i64 %442, i64* %443, align 1
  %444 = getelementptr inbounds i8, i8* %438, i64 %1
  %445 = bitcast <2 x i64> %407 to <8 x i16>
  %446 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %445, <8 x i16> undef) #11
  %447 = bitcast <16 x i8> %446 to <2 x i64>
  %448 = extractelement <2 x i64> %447, i32 0
  %449 = bitcast i8* %444 to i64*
  store i64 %448, i64* %449, align 1
  %450 = getelementptr inbounds i8, i8* %444, i64 %1
  %451 = bitcast <2 x i64> %408 to <8 x i16>
  %452 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %451, <8 x i16> undef) #11
  %453 = bitcast <16 x i8> %452 to <2 x i64>
  %454 = extractelement <2 x i64> %453, i32 0
  %455 = bitcast i8* %450 to i64*
  store i64 %454, i64* %455, align 1
  %456 = getelementptr inbounds i8, i8* %316, i64 %237
  %457 = add nuw nsw i32 %317, 8
  %458 = icmp slt i32 %457, %4
  br i1 %458, label %315, label %459

459:                                              ; preds = %315
  %460 = add nsw i32 %242, %238
  %461 = add nuw nsw i64 %241, 8
  %462 = icmp slt i64 %461, %239
  br i1 %462, label %240, label %702

463:                                              ; preds = %236, %698
  %464 = phi i64 [ %700, %698 ], [ 0, %236 ]
  %465 = phi i32 [ %699, %698 ], [ %5, %236 ]
  %466 = getelementptr inbounds i8, i8* %0, i64 %464
  %467 = ashr i32 %465, 6
  %468 = lshr i32 %465, 1
  %469 = trunc i32 %468 to i8
  %470 = and i8 %469, 31
  %471 = insertelement <16 x i8> undef, i8 %470, i32 0
  %472 = shufflevector <16 x i8> %471, <16 x i8> undef, <16 x i32> zeroinitializer
  %473 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %472
  %474 = shufflevector <16 x i8> %473, <16 x i8> %472, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %475 = sext i32 %467 to i64
  %476 = add nsw i32 %465, %5
  %477 = ashr i32 %476, 6
  %478 = lshr i32 %476, 1
  %479 = trunc i32 %478 to i8
  %480 = and i8 %479, 31
  %481 = insertelement <16 x i8> undef, i8 %480, i32 0
  %482 = shufflevector <16 x i8> %481, <16 x i8> undef, <16 x i32> zeroinitializer
  %483 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %482
  %484 = shufflevector <16 x i8> %483, <16 x i8> %482, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %485 = sext i32 %477 to i64
  %486 = add nsw i32 %476, %5
  %487 = ashr i32 %486, 6
  %488 = lshr i32 %486, 1
  %489 = trunc i32 %488 to i8
  %490 = and i8 %489, 31
  %491 = insertelement <16 x i8> undef, i8 %490, i32 0
  %492 = shufflevector <16 x i8> %491, <16 x i8> undef, <16 x i32> zeroinitializer
  %493 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %492
  %494 = shufflevector <16 x i8> %493, <16 x i8> %492, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %495 = sext i32 %487 to i64
  %496 = add nsw i32 %486, %5
  %497 = ashr i32 %496, 6
  %498 = lshr i32 %496, 1
  %499 = trunc i32 %498 to i8
  %500 = and i8 %499, 31
  %501 = insertelement <16 x i8> undef, i8 %500, i32 0
  %502 = shufflevector <16 x i8> %501, <16 x i8> undef, <16 x i32> zeroinitializer
  %503 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %502
  %504 = shufflevector <16 x i8> %503, <16 x i8> %502, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %505 = sext i32 %497 to i64
  %506 = add nsw i32 %496, %5
  %507 = ashr i32 %506, 6
  %508 = lshr i32 %506, 1
  %509 = trunc i32 %508 to i8
  %510 = and i8 %509, 31
  %511 = insertelement <16 x i8> undef, i8 %510, i32 0
  %512 = shufflevector <16 x i8> %511, <16 x i8> undef, <16 x i32> zeroinitializer
  %513 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %512
  %514 = shufflevector <16 x i8> %513, <16 x i8> %512, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %515 = sext i32 %507 to i64
  %516 = add nsw i32 %506, %5
  %517 = ashr i32 %516, 6
  %518 = lshr i32 %516, 1
  %519 = trunc i32 %518 to i8
  %520 = and i8 %519, 31
  %521 = insertelement <16 x i8> undef, i8 %520, i32 0
  %522 = shufflevector <16 x i8> %521, <16 x i8> undef, <16 x i32> zeroinitializer
  %523 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %522
  %524 = shufflevector <16 x i8> %523, <16 x i8> %522, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %525 = sext i32 %517 to i64
  %526 = add nsw i32 %516, %5
  %527 = ashr i32 %526, 6
  %528 = lshr i32 %526, 1
  %529 = trunc i32 %528 to i8
  %530 = and i8 %529, 31
  %531 = insertelement <16 x i8> undef, i8 %530, i32 0
  %532 = shufflevector <16 x i8> %531, <16 x i8> undef, <16 x i32> zeroinitializer
  %533 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %532
  %534 = shufflevector <16 x i8> %533, <16 x i8> %532, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %535 = sext i32 %527 to i64
  %536 = add nsw i32 %526, %5
  %537 = ashr i32 %536, 6
  %538 = lshr i32 %536, 1
  %539 = trunc i32 %538 to i8
  %540 = and i8 %539, 31
  %541 = insertelement <16 x i8> undef, i8 %540, i32 0
  %542 = shufflevector <16 x i8> %541, <16 x i8> undef, <16 x i32> zeroinitializer
  %543 = sub <16 x i8> <i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 32, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, %542
  %544 = shufflevector <16 x i8> %543, <16 x i8> %542, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %545 = sext i32 %537 to i64
  br label %546

546:                                              ; preds = %546, %463
  %547 = phi i8* [ %466, %463 ], [ %695, %546 ]
  %548 = phi i32 [ 0, %463 ], [ %696, %546 ]
  %549 = shl i32 %548, %8
  %550 = sext i32 %549 to i64
  %551 = getelementptr inbounds i8, i8* %2, i64 %550
  %552 = getelementptr inbounds i8, i8* %551, i64 %475
  %553 = bitcast i8* %552 to <16 x i8>*
  %554 = load <16 x i8>, <16 x i8>* %553, align 1
  %555 = shufflevector <16 x i8> %554, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %556 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %555, <16 x i8> %474) #11
  %557 = lshr <8 x i16> %556, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %558 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %557, <8 x i16> zeroinitializer) #11
  %559 = getelementptr inbounds i8, i8* %551, i64 %485
  %560 = bitcast i8* %559 to <16 x i8>*
  %561 = load <16 x i8>, <16 x i8>* %560, align 1
  %562 = shufflevector <16 x i8> %561, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %563 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %562, <16 x i8> %484) #11
  %564 = lshr <8 x i16> %563, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %565 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %564, <8 x i16> zeroinitializer) #11
  %566 = getelementptr inbounds i8, i8* %551, i64 %495
  %567 = bitcast i8* %566 to <16 x i8>*
  %568 = load <16 x i8>, <16 x i8>* %567, align 1
  %569 = shufflevector <16 x i8> %568, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %570 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %569, <16 x i8> %494) #11
  %571 = lshr <8 x i16> %570, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %572 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %571, <8 x i16> zeroinitializer) #11
  %573 = getelementptr inbounds i8, i8* %551, i64 %505
  %574 = bitcast i8* %573 to <16 x i8>*
  %575 = load <16 x i8>, <16 x i8>* %574, align 1
  %576 = shufflevector <16 x i8> %575, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %577 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %576, <16 x i8> %504) #11
  %578 = lshr <8 x i16> %577, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %579 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %578, <8 x i16> zeroinitializer) #11
  %580 = getelementptr inbounds i8, i8* %551, i64 %515
  %581 = bitcast i8* %580 to <16 x i8>*
  %582 = load <16 x i8>, <16 x i8>* %581, align 1
  %583 = shufflevector <16 x i8> %582, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %584 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %583, <16 x i8> %514) #11
  %585 = lshr <8 x i16> %584, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %586 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %585, <8 x i16> zeroinitializer) #11
  %587 = getelementptr inbounds i8, i8* %551, i64 %525
  %588 = bitcast i8* %587 to <16 x i8>*
  %589 = load <16 x i8>, <16 x i8>* %588, align 1
  %590 = shufflevector <16 x i8> %589, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %591 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %590, <16 x i8> %524) #11
  %592 = lshr <8 x i16> %591, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %593 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %592, <8 x i16> zeroinitializer) #11
  %594 = getelementptr inbounds i8, i8* %551, i64 %535
  %595 = bitcast i8* %594 to <16 x i8>*
  %596 = load <16 x i8>, <16 x i8>* %595, align 1
  %597 = shufflevector <16 x i8> %596, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %598 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %597, <16 x i8> %534) #11
  %599 = lshr <8 x i16> %598, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %600 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %599, <8 x i16> zeroinitializer) #11
  %601 = getelementptr inbounds i8, i8* %551, i64 %545
  %602 = bitcast i8* %601 to <16 x i8>*
  %603 = load <16 x i8>, <16 x i8>* %602, align 1
  %604 = shufflevector <16 x i8> %603, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7, i32 8>
  %605 = tail call <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8> %604, <16 x i8> %544) #11
  %606 = lshr <8 x i16> %605, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %607 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %606, <8 x i16> zeroinitializer) #11
  %608 = shufflevector <8 x i16> %558, <8 x i16> %565, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %609 = shufflevector <8 x i16> %572, <8 x i16> %579, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %610 = shufflevector <8 x i16> %586, <8 x i16> %593, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %611 = shufflevector <8 x i16> %600, <8 x i16> %607, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %612 = shufflevector <8 x i16> %558, <8 x i16> %565, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %613 = shufflevector <8 x i16> %572, <8 x i16> %579, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %614 = shufflevector <8 x i16> %586, <8 x i16> %593, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %615 = shufflevector <8 x i16> %600, <8 x i16> %607, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %616 = bitcast <8 x i16> %608 to <4 x i32>
  %617 = bitcast <8 x i16> %609 to <4 x i32>
  %618 = shufflevector <4 x i32> %616, <4 x i32> %617, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %619 = bitcast <4 x i32> %618 to <2 x i64>
  %620 = bitcast <8 x i16> %610 to <4 x i32>
  %621 = bitcast <8 x i16> %611 to <4 x i32>
  %622 = shufflevector <4 x i32> %620, <4 x i32> %621, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %623 = bitcast <4 x i32> %622 to <2 x i64>
  %624 = bitcast <8 x i16> %612 to <4 x i32>
  %625 = bitcast <8 x i16> %613 to <4 x i32>
  %626 = shufflevector <4 x i32> %624, <4 x i32> %625, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %627 = bitcast <4 x i32> %626 to <2 x i64>
  %628 = bitcast <8 x i16> %614 to <4 x i32>
  %629 = bitcast <8 x i16> %615 to <4 x i32>
  %630 = shufflevector <4 x i32> %628, <4 x i32> %629, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %631 = bitcast <4 x i32> %630 to <2 x i64>
  %632 = shufflevector <4 x i32> %616, <4 x i32> %617, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %633 = bitcast <4 x i32> %632 to <2 x i64>
  %634 = shufflevector <4 x i32> %620, <4 x i32> %621, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %635 = bitcast <4 x i32> %634 to <2 x i64>
  %636 = shufflevector <4 x i32> %624, <4 x i32> %625, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %637 = bitcast <4 x i32> %636 to <2 x i64>
  %638 = shufflevector <4 x i32> %628, <4 x i32> %629, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %639 = bitcast <4 x i32> %638 to <2 x i64>
  %640 = shufflevector <2 x i64> %619, <2 x i64> %623, <2 x i32> <i32 0, i32 2>
  %641 = shufflevector <2 x i64> %619, <2 x i64> %623, <2 x i32> <i32 1, i32 3>
  %642 = shufflevector <2 x i64> %633, <2 x i64> %635, <2 x i32> <i32 0, i32 2>
  %643 = shufflevector <2 x i64> %633, <2 x i64> %635, <2 x i32> <i32 1, i32 3>
  %644 = shufflevector <2 x i64> %627, <2 x i64> %631, <2 x i32> <i32 0, i32 2>
  %645 = shufflevector <2 x i64> %627, <2 x i64> %631, <2 x i32> <i32 1, i32 3>
  %646 = shufflevector <2 x i64> %637, <2 x i64> %639, <2 x i32> <i32 0, i32 2>
  %647 = shufflevector <2 x i64> %637, <2 x i64> %639, <2 x i32> <i32 1, i32 3>
  %648 = bitcast <2 x i64> %640 to <8 x i16>
  %649 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %648, <8 x i16> undef) #11
  %650 = bitcast <16 x i8> %649 to <2 x i64>
  %651 = extractelement <2 x i64> %650, i32 0
  %652 = bitcast i8* %547 to i64*
  store i64 %651, i64* %652, align 1
  %653 = getelementptr inbounds i8, i8* %547, i64 %1
  %654 = bitcast <2 x i64> %641 to <8 x i16>
  %655 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %654, <8 x i16> undef) #11
  %656 = bitcast <16 x i8> %655 to <2 x i64>
  %657 = extractelement <2 x i64> %656, i32 0
  %658 = bitcast i8* %653 to i64*
  store i64 %657, i64* %658, align 1
  %659 = getelementptr inbounds i8, i8* %653, i64 %1
  %660 = bitcast <2 x i64> %642 to <8 x i16>
  %661 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %660, <8 x i16> undef) #11
  %662 = bitcast <16 x i8> %661 to <2 x i64>
  %663 = extractelement <2 x i64> %662, i32 0
  %664 = bitcast i8* %659 to i64*
  store i64 %663, i64* %664, align 1
  %665 = getelementptr inbounds i8, i8* %659, i64 %1
  %666 = bitcast <2 x i64> %643 to <8 x i16>
  %667 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %666, <8 x i16> undef) #11
  %668 = bitcast <16 x i8> %667 to <2 x i64>
  %669 = extractelement <2 x i64> %668, i32 0
  %670 = bitcast i8* %665 to i64*
  store i64 %669, i64* %670, align 1
  %671 = getelementptr inbounds i8, i8* %665, i64 %1
  %672 = bitcast <2 x i64> %644 to <8 x i16>
  %673 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %672, <8 x i16> undef) #11
  %674 = bitcast <16 x i8> %673 to <2 x i64>
  %675 = extractelement <2 x i64> %674, i32 0
  %676 = bitcast i8* %671 to i64*
  store i64 %675, i64* %676, align 1
  %677 = getelementptr inbounds i8, i8* %671, i64 %1
  %678 = bitcast <2 x i64> %645 to <8 x i16>
  %679 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %678, <8 x i16> undef) #11
  %680 = bitcast <16 x i8> %679 to <2 x i64>
  %681 = extractelement <2 x i64> %680, i32 0
  %682 = bitcast i8* %677 to i64*
  store i64 %681, i64* %682, align 1
  %683 = getelementptr inbounds i8, i8* %677, i64 %1
  %684 = bitcast <2 x i64> %646 to <8 x i16>
  %685 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %684, <8 x i16> undef) #11
  %686 = bitcast <16 x i8> %685 to <2 x i64>
  %687 = extractelement <2 x i64> %686, i32 0
  %688 = bitcast i8* %683 to i64*
  store i64 %687, i64* %688, align 1
  %689 = getelementptr inbounds i8, i8* %683, i64 %1
  %690 = bitcast <2 x i64> %647 to <8 x i16>
  %691 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %690, <8 x i16> undef) #11
  %692 = bitcast <16 x i8> %691 to <2 x i64>
  %693 = extractelement <2 x i64> %692, i32 0
  %694 = bitcast i8* %689 to i64*
  store i64 %693, i64* %694, align 1
  %695 = getelementptr inbounds i8, i8* %547, i64 %237
  %696 = add nuw nsw i32 %548, 8
  %697 = icmp slt i32 %696, %4
  br i1 %697, label %546, label %698

698:                                              ; preds = %546
  %699 = add nsw i32 %465, %238
  %700 = add nuw nsw i64 %464, 8
  %701 = icmp slt i64 %700, %239
  br i1 %701, label %463, label %702

702:                                              ; preds = %698, %459, %232, %121
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi4EEEvPvlDv2_xEELi0ELi0EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 2, i32 2, i32 2, i32 2>
  %12 = lshr <4 x i32> %11, <i32 2, i32 2, i32 2, i32 2>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = bitcast <16 x i8> %14 to <4 x i32>
  %16 = extractelement <4 x i32> %15, i32 0
  %17 = bitcast i8* %0 to i32*
  store i32 %16, i32* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %1
  %19 = bitcast i8* %18 to i32*
  store i32 %16, i32* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 %1
  %21 = bitcast i8* %20 to i32*
  store i32 %16, i32* %21, align 1
  %22 = getelementptr inbounds i8, i8* %20, i64 %1
  %23 = bitcast i8* %22 to i32*
  store i32 %16, i32* %23, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi8EEEvPvlDv2_xEELi2ELi21846EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 2, i32 2, i32 2, i32 2>
  %12 = lshr <4 x i32> %11, <i32 2, i32 2, i32 2, i32 2>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = bitcast <16 x i8> %14 to <4 x i32>
  %16 = extractelement <4 x i32> %15, i32 0
  %17 = bitcast i8* %0 to i32*
  store i32 %16, i32* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %1
  %19 = bitcast i8* %18 to i32*
  store i32 %16, i32* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 %1
  %21 = bitcast i8* %20 to i32*
  store i32 %16, i32* %21, align 1
  %22 = getelementptr inbounds i8, i8* %20, i64 %1
  %23 = bitcast i8* %22 to i32*
  store i32 %16, i32* %23, align 1
  %24 = getelementptr inbounds i8, i8* %22, i64 %1
  %25 = bitcast i8* %24 to i32*
  store i32 %16, i32* %25, align 1
  %26 = getelementptr inbounds i8, i8* %24, i64 %1
  %27 = bitcast i8* %26 to i32*
  store i32 %16, i32* %27, align 1
  %28 = getelementptr inbounds i8, i8* %26, i64 %1
  %29 = bitcast i8* %28 to i32*
  store i32 %16, i32* %29, align 1
  %30 = getelementptr inbounds i8, i8* %28, i64 %1
  %31 = bitcast i8* %30 to i32*
  store i32 %16, i32* %31, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi16EEEvPvlDv2_xEELi2ELi13108EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 2, i32 2, i32 2, i32 2>
  %12 = lshr <4 x i32> %11, <i32 2, i32 2, i32 2, i32 2>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = bitcast <16 x i8> %14 to <4 x i32>
  %16 = extractelement <4 x i32> %15, i32 0
  %17 = bitcast i8* %0 to i32*
  store i32 %16, i32* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %1
  %19 = bitcast i8* %18 to i32*
  store i32 %16, i32* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 %1
  %21 = bitcast i8* %20 to i32*
  store i32 %16, i32* %21, align 1
  %22 = getelementptr inbounds i8, i8* %20, i64 %1
  %23 = bitcast i8* %22 to i32*
  store i32 %16, i32* %23, align 1
  %24 = getelementptr inbounds i8, i8* %22, i64 %1
  %25 = bitcast i8* %24 to i32*
  store i32 %16, i32* %25, align 1
  %26 = getelementptr inbounds i8, i8* %24, i64 %1
  %27 = bitcast i8* %26 to i32*
  store i32 %16, i32* %27, align 1
  %28 = getelementptr inbounds i8, i8* %26, i64 %1
  %29 = bitcast i8* %28 to i32*
  store i32 %16, i32* %29, align 1
  %30 = getelementptr inbounds i8, i8* %28, i64 %1
  %31 = bitcast i8* %30 to i32*
  store i32 %16, i32* %31, align 1
  %32 = getelementptr inbounds i8, i8* %30, i64 %1
  %33 = bitcast i8* %32 to i32*
  store i32 %16, i32* %33, align 1
  %34 = getelementptr inbounds i8, i8* %32, i64 %1
  %35 = bitcast i8* %34 to i32*
  store i32 %16, i32* %35, align 1
  %36 = getelementptr inbounds i8, i8* %34, i64 %1
  %37 = bitcast i8* %36 to i32*
  store i32 %16, i32* %37, align 1
  %38 = getelementptr inbounds i8, i8* %36, i64 %1
  %39 = bitcast i8* %38 to i32*
  store i32 %16, i32* %39, align 1
  %40 = getelementptr inbounds i8, i8* %38, i64 %1
  %41 = bitcast i8* %40 to i32*
  store i32 %16, i32* %41, align 1
  %42 = getelementptr inbounds i8, i8* %40, i64 %1
  %43 = bitcast i8* %42 to i32*
  store i32 %16, i32* %43, align 1
  %44 = getelementptr inbounds i8, i8* %42, i64 %1
  %45 = bitcast i8* %44 to i32*
  store i32 %16, i32* %45, align 1
  %46 = getelementptr inbounds i8, i8* %44, i64 %1
  %47 = bitcast i8* %46 to i32*
  store i32 %16, i32* %47, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi4EEEvPvlDv2_xEELi2ELi21846EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 4, i32 4, i32 4, i32 4>
  %12 = lshr <4 x i32> %11, <i32 3, i32 3, i32 3, i32 3>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = bitcast <16 x i8> %14 to <2 x i64>
  %16 = extractelement <2 x i64> %15, i32 0
  %17 = bitcast i8* %0 to i64*
  store i64 %16, i64* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %1
  %19 = bitcast i8* %18 to i64*
  store i64 %16, i64* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 %1
  %21 = bitcast i8* %20 to i64*
  store i64 %16, i64* %21, align 1
  %22 = getelementptr inbounds i8, i8* %20, i64 %1
  %23 = bitcast i8* %22 to i64*
  store i64 %16, i64* %23, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi8EEEvPvlDv2_xEELi0ELi0EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 4, i32 4, i32 4, i32 4>
  %12 = lshr <4 x i32> %11, <i32 3, i32 3, i32 3, i32 3>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = bitcast <16 x i8> %14 to <2 x i64>
  %16 = extractelement <2 x i64> %15, i32 0
  %17 = bitcast i8* %0 to i64*
  store i64 %16, i64* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %1
  %19 = bitcast i8* %18 to i64*
  store i64 %16, i64* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 %1
  %21 = bitcast i8* %20 to i64*
  store i64 %16, i64* %21, align 1
  %22 = getelementptr inbounds i8, i8* %20, i64 %1
  %23 = bitcast i8* %22 to i64*
  store i64 %16, i64* %23, align 1
  %24 = getelementptr inbounds i8, i8* %22, i64 %1
  %25 = bitcast i8* %24 to i64*
  store i64 %16, i64* %25, align 1
  %26 = getelementptr inbounds i8, i8* %24, i64 %1
  %27 = bitcast i8* %26 to i64*
  store i64 %16, i64* %27, align 1
  %28 = getelementptr inbounds i8, i8* %26, i64 %1
  %29 = bitcast i8* %28 to i64*
  store i64 %16, i64* %29, align 1
  %30 = getelementptr inbounds i8, i8* %28, i64 %1
  %31 = bitcast i8* %30 to i64*
  store i64 %16, i64* %31, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi16EEEvPvlDv2_xEELi3ELi21846EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 4, i32 4, i32 4, i32 4>
  %12 = lshr <4 x i32> %11, <i32 3, i32 3, i32 3, i32 3>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = bitcast <16 x i8> %14 to <2 x i64>
  %16 = extractelement <2 x i64> %15, i32 0
  %17 = bitcast i8* %0 to i64*
  store i64 %16, i64* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %1
  %19 = bitcast i8* %18 to i64*
  store i64 %16, i64* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 %1
  %21 = bitcast i8* %20 to i64*
  store i64 %16, i64* %21, align 1
  %22 = getelementptr inbounds i8, i8* %20, i64 %1
  %23 = bitcast i8* %22 to i64*
  store i64 %16, i64* %23, align 1
  %24 = getelementptr inbounds i8, i8* %22, i64 %1
  %25 = bitcast i8* %24 to i64*
  store i64 %16, i64* %25, align 1
  %26 = getelementptr inbounds i8, i8* %24, i64 %1
  %27 = bitcast i8* %26 to i64*
  store i64 %16, i64* %27, align 1
  %28 = getelementptr inbounds i8, i8* %26, i64 %1
  %29 = bitcast i8* %28 to i64*
  store i64 %16, i64* %29, align 1
  %30 = getelementptr inbounds i8, i8* %28, i64 %1
  %31 = bitcast i8* %30 to i64*
  store i64 %16, i64* %31, align 1
  %32 = getelementptr inbounds i8, i8* %30, i64 %1
  %33 = bitcast i8* %32 to i64*
  store i64 %16, i64* %33, align 1
  %34 = getelementptr inbounds i8, i8* %32, i64 %1
  %35 = bitcast i8* %34 to i64*
  store i64 %16, i64* %35, align 1
  %36 = getelementptr inbounds i8, i8* %34, i64 %1
  %37 = bitcast i8* %36 to i64*
  store i64 %16, i64* %37, align 1
  %38 = getelementptr inbounds i8, i8* %36, i64 %1
  %39 = bitcast i8* %38 to i64*
  store i64 %16, i64* %39, align 1
  %40 = getelementptr inbounds i8, i8* %38, i64 %1
  %41 = bitcast i8* %40 to i64*
  store i64 %16, i64* %41, align 1
  %42 = getelementptr inbounds i8, i8* %40, i64 %1
  %43 = bitcast i8* %42 to i64*
  store i64 %16, i64* %43, align 1
  %44 = getelementptr inbounds i8, i8* %42, i64 %1
  %45 = bitcast i8* %44 to i64*
  store i64 %16, i64* %45, align 1
  %46 = getelementptr inbounds i8, i8* %44, i64 %1
  %47 = bitcast i8* %46 to i64*
  store i64 %16, i64* %47, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi32EEEvPvlDv2_xEELi3ELi13108EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 4, i32 4, i32 4, i32 4>
  %12 = lshr <4 x i32> %11, <i32 3, i32 3, i32 3, i32 3>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = bitcast <16 x i8> %14 to <2 x i64>
  %16 = extractelement <2 x i64> %15, i32 0
  %17 = bitcast i8* %0 to i64*
  store i64 %16, i64* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %1
  %19 = bitcast i8* %18 to i64*
  store i64 %16, i64* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 %1
  %21 = bitcast i8* %20 to i64*
  store i64 %16, i64* %21, align 1
  %22 = getelementptr inbounds i8, i8* %20, i64 %1
  %23 = bitcast i8* %22 to i64*
  store i64 %16, i64* %23, align 1
  %24 = getelementptr inbounds i8, i8* %22, i64 %1
  %25 = bitcast i8* %24 to i64*
  store i64 %16, i64* %25, align 1
  %26 = getelementptr inbounds i8, i8* %24, i64 %1
  %27 = bitcast i8* %26 to i64*
  store i64 %16, i64* %27, align 1
  %28 = getelementptr inbounds i8, i8* %26, i64 %1
  %29 = bitcast i8* %28 to i64*
  store i64 %16, i64* %29, align 1
  %30 = getelementptr inbounds i8, i8* %28, i64 %1
  %31 = bitcast i8* %30 to i64*
  store i64 %16, i64* %31, align 1
  %32 = getelementptr inbounds i8, i8* %30, i64 %1
  %33 = bitcast i8* %32 to i64*
  store i64 %16, i64* %33, align 1
  %34 = getelementptr inbounds i8, i8* %32, i64 %1
  %35 = bitcast i8* %34 to i64*
  store i64 %16, i64* %35, align 1
  %36 = getelementptr inbounds i8, i8* %34, i64 %1
  %37 = bitcast i8* %36 to i64*
  store i64 %16, i64* %37, align 1
  %38 = getelementptr inbounds i8, i8* %36, i64 %1
  %39 = bitcast i8* %38 to i64*
  store i64 %16, i64* %39, align 1
  %40 = getelementptr inbounds i8, i8* %38, i64 %1
  %41 = bitcast i8* %40 to i64*
  store i64 %16, i64* %41, align 1
  %42 = getelementptr inbounds i8, i8* %40, i64 %1
  %43 = bitcast i8* %42 to i64*
  store i64 %16, i64* %43, align 1
  %44 = getelementptr inbounds i8, i8* %42, i64 %1
  %45 = bitcast i8* %44 to i64*
  store i64 %16, i64* %45, align 1
  %46 = getelementptr inbounds i8, i8* %44, i64 %1
  %47 = bitcast i8* %46 to i64*
  store i64 %16, i64* %47, align 1
  %48 = getelementptr inbounds i8, i8* %46, i64 %1
  %49 = bitcast i8* %48 to i64*
  store i64 %16, i64* %49, align 1
  %50 = getelementptr inbounds i8, i8* %48, i64 %1
  %51 = bitcast i8* %50 to i64*
  store i64 %16, i64* %51, align 1
  %52 = getelementptr inbounds i8, i8* %50, i64 %1
  %53 = bitcast i8* %52 to i64*
  store i64 %16, i64* %53, align 1
  %54 = getelementptr inbounds i8, i8* %52, i64 %1
  %55 = bitcast i8* %54 to i64*
  store i64 %16, i64* %55, align 1
  %56 = getelementptr inbounds i8, i8* %54, i64 %1
  %57 = bitcast i8* %56 to i64*
  store i64 %16, i64* %57, align 1
  %58 = getelementptr inbounds i8, i8* %56, i64 %1
  %59 = bitcast i8* %58 to i64*
  store i64 %16, i64* %59, align 1
  %60 = getelementptr inbounds i8, i8* %58, i64 %1
  %61 = bitcast i8* %60 to i64*
  store i64 %16, i64* %61, align 1
  %62 = getelementptr inbounds i8, i8* %60, i64 %1
  %63 = bitcast i8* %62 to i64*
  store i64 %16, i64* %63, align 1
  %64 = getelementptr inbounds i8, i8* %62, i64 %1
  %65 = bitcast i8* %64 to i64*
  store i64 %16, i64* %65, align 1
  %66 = getelementptr inbounds i8, i8* %64, i64 %1
  %67 = bitcast i8* %66 to i64*
  store i64 %16, i64* %67, align 1
  %68 = getelementptr inbounds i8, i8* %66, i64 %1
  %69 = bitcast i8* %68 to i64*
  store i64 %16, i64* %69, align 1
  %70 = getelementptr inbounds i8, i8* %68, i64 %1
  %71 = bitcast i8* %70 to i64*
  store i64 %16, i64* %71, align 1
  %72 = getelementptr inbounds i8, i8* %70, i64 %1
  %73 = bitcast i8* %72 to i64*
  store i64 %16, i64* %73, align 1
  %74 = getelementptr inbounds i8, i8* %72, i64 %1
  %75 = bitcast i8* %74 to i64*
  store i64 %16, i64* %75, align 1
  %76 = getelementptr inbounds i8, i8* %74, i64 %1
  %77 = bitcast i8* %76 to i64*
  store i64 %16, i64* %77, align 1
  %78 = getelementptr inbounds i8, i8* %76, i64 %1
  %79 = bitcast i8* %78 to i64*
  store i64 %16, i64* %79, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi4EEEvPvlDv2_xEELi2ELi13108EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = add <4 x i32> %13, <i32 8, i32 8, i32 8, i32 8>
  %15 = lshr <4 x i32> %14, <i32 4, i32 4, i32 4, i32 4>
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = bitcast i8* %19 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %19, i64 %1
  %22 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %21, i64 %1
  %24 = bitcast i8* %23 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %24, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi8EEEvPvlDv2_xEELi3ELi21846EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = add <4 x i32> %13, <i32 8, i32 8, i32 8, i32 8>
  %15 = lshr <4 x i32> %14, <i32 4, i32 4, i32 4, i32 4>
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = bitcast i8* %19 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %19, i64 %1
  %22 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %21, i64 %1
  %24 = bitcast i8* %23 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %23, i64 %1
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %25, i64 %1
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 %1
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 %1
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %32, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi16EEEvPvlDv2_xEELi0ELi0EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = add <4 x i32> %13, <i32 8, i32 8, i32 8, i32 8>
  %15 = lshr <4 x i32> %14, <i32 4, i32 4, i32 4, i32 4>
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = bitcast i8* %19 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %19, i64 %1
  %22 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %21, i64 %1
  %24 = bitcast i8* %23 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %23, i64 %1
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %25, i64 %1
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 %1
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 %1
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 %1
  %34 = bitcast i8* %33 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 %1
  %36 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 %1
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %37, i64 %1
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 %1
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %41, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 %1
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %45, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %48, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi32EEEvPvlDv2_xEELi4ELi21846EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = add <4 x i32> %13, <i32 8, i32 8, i32 8, i32 8>
  %15 = lshr <4 x i32> %14, <i32 4, i32 4, i32 4, i32 4>
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = bitcast i8* %19 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %19, i64 %1
  %22 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %21, i64 %1
  %24 = bitcast i8* %23 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %23, i64 %1
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %25, i64 %1
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 %1
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 %1
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 %1
  %34 = bitcast i8* %33 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 %1
  %36 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 %1
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %37, i64 %1
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 %1
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %41, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 %1
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %45, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 %1
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %49, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 %1
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %53, i64 %1
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 %1
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %57, i64 %1
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %59, i64 %1
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %61, i64 %1
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %63, i64 %1
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %65, i64 %1
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %67, i64 %1
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %69, i64 %1
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %71, i64 %1
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %73, i64 %1
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %75, i64 %1
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %77, i64 %1
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %80, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi64EEEvPvlDv2_xEELi4ELi13108EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = add <4 x i32> %13, <i32 8, i32 8, i32 8, i32 8>
  %15 = lshr <4 x i32> %14, <i32 4, i32 4, i32 4, i32 4>
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = bitcast i8* %19 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %19, i64 %1
  %22 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %21, i64 %1
  %24 = bitcast i8* %23 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %23, i64 %1
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %25, i64 %1
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 %1
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 %1
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 %1
  %34 = bitcast i8* %33 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 %1
  %36 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 %1
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %37, i64 %1
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 %1
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %41, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 %1
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %45, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 %1
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %49, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 %1
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %53, i64 %1
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 %1
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %57, i64 %1
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %59, i64 %1
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %61, i64 %1
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %63, i64 %1
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %65, i64 %1
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %67, i64 %1
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %69, i64 %1
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %71, i64 %1
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %73, i64 %1
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %75, i64 %1
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %77, i64 %1
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %79, i64 %1
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %81, i64 %1
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %83, i64 %1
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %85, i64 %1
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %87, i64 %1
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %89, i64 %1
  %92 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %91, i64 %1
  %94 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %93, i64 %1
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %95, i64 %1
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %97, i64 %1
  %100 = bitcast i8* %99 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %99, i64 %1
  %102 = bitcast i8* %101 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %101, i64 %1
  %104 = bitcast i8* %103 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %103, i64 %1
  %106 = bitcast i8* %105 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %105, i64 %1
  %108 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %107, i64 %1
  %110 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %109, i64 %1
  %112 = bitcast i8* %111 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %111, i64 %1
  %114 = bitcast i8* %113 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %113, i64 %1
  %116 = bitcast i8* %115 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %115, i64 %1
  %118 = bitcast i8* %117 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %117, i64 %1
  %120 = bitcast i8* %119 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %119, i64 %1
  %122 = bitcast i8* %121 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %121, i64 %1
  %124 = bitcast i8* %123 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %124, align 1
  %125 = getelementptr inbounds i8, i8* %123, i64 %1
  %126 = bitcast i8* %125 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %125, i64 %1
  %128 = bitcast i8* %127 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %128, align 1
  %129 = getelementptr inbounds i8, i8* %127, i64 %1
  %130 = bitcast i8* %129 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %130, align 1
  %131 = getelementptr inbounds i8, i8* %129, i64 %1
  %132 = bitcast i8* %131 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %132, align 1
  %133 = getelementptr inbounds i8, i8* %131, i64 %1
  %134 = bitcast i8* %133 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %133, i64 %1
  %136 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %135, i64 %1
  %138 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %137, i64 %1
  %140 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %139, i64 %1
  %142 = bitcast i8* %141 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %142, align 1
  %143 = getelementptr inbounds i8, i8* %141, i64 %1
  %144 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %144, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi8EEEvPvlDv2_xEELi3ELi13108EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %11 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %12 = bitcast <2 x i64> %10 to <8 x i16>
  %13 = bitcast <2 x i64> %11 to <8 x i16>
  %14 = add <8 x i16> %13, %12
  %15 = bitcast <8 x i16> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %17 = bitcast <16 x i8> %16 to <8 x i16>
  %18 = add <8 x i16> %14, %17
  %19 = bitcast <8 x i16> %18 to <4 x i32>
  %20 = add <4 x i32> %19, <i32 16, i32 16, i32 16, i32 16>
  %21 = lshr <4 x i32> %20, <i32 5, i32 5, i32 5, i32 5>
  %22 = bitcast <4 x i32> %21 to <16 x i8>
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> zeroinitializer
  %24 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 16
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %0, i64 %1
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 16
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %27, i64 %1
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 16
  %34 = bitcast i8* %33 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %31, i64 %1
  %36 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 16
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %35, i64 %1
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 16
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %39, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 16
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %43, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 16
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %47, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 16
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %54, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi16EEEvPvlDv2_xEELi4ELi21846EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %11 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %12 = bitcast <2 x i64> %10 to <8 x i16>
  %13 = bitcast <2 x i64> %11 to <8 x i16>
  %14 = add <8 x i16> %13, %12
  %15 = bitcast <8 x i16> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %17 = bitcast <16 x i8> %16 to <8 x i16>
  %18 = add <8 x i16> %14, %17
  %19 = bitcast <8 x i16> %18 to <4 x i32>
  %20 = add <4 x i32> %19, <i32 16, i32 16, i32 16, i32 16>
  %21 = lshr <4 x i32> %20, <i32 5, i32 5, i32 5, i32 5>
  %22 = bitcast <4 x i32> %21 to <16 x i8>
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> zeroinitializer
  %24 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 16
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %0, i64 %1
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 16
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %27, i64 %1
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 16
  %34 = bitcast i8* %33 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %31, i64 %1
  %36 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 16
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %35, i64 %1
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 16
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %39, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 16
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %43, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 16
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %47, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 16
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %51, i64 %1
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 16
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %55, i64 %1
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %59, i64 16
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %59, i64 %1
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %63, i64 16
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %63, i64 %1
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %67, i64 16
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %67, i64 %1
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %71, i64 16
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %71, i64 %1
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %75, i64 16
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %75, i64 %1
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %79, i64 16
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %79, i64 %1
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %83, i64 16
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %86, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi32EEEvPvlDv2_xEELi0ELi0EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %11 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %12 = bitcast <2 x i64> %10 to <8 x i16>
  %13 = bitcast <2 x i64> %11 to <8 x i16>
  %14 = add <8 x i16> %13, %12
  %15 = bitcast <8 x i16> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %17 = bitcast <16 x i8> %16 to <8 x i16>
  %18 = add <8 x i16> %14, %17
  %19 = bitcast <8 x i16> %18 to <4 x i32>
  %20 = add <4 x i32> %19, <i32 16, i32 16, i32 16, i32 16>
  %21 = lshr <4 x i32> %20, <i32 5, i32 5, i32 5, i32 5>
  %22 = bitcast <4 x i32> %21 to <16 x i8>
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> zeroinitializer
  %24 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 16
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %0, i64 %1
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 16
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %27, i64 %1
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 16
  %34 = bitcast i8* %33 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %31, i64 %1
  %36 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 16
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %35, i64 %1
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 16
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %39, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 16
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %43, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 16
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %47, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 16
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %51, i64 %1
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 16
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %55, i64 %1
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %59, i64 16
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %59, i64 %1
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %63, i64 16
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %63, i64 %1
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %67, i64 16
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %67, i64 %1
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %71, i64 16
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %71, i64 %1
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %75, i64 16
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %75, i64 %1
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %79, i64 16
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %79, i64 %1
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %83, i64 16
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %83, i64 %1
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %87, i64 16
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %87, i64 %1
  %92 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %91, i64 16
  %94 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %91, i64 %1
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %95, i64 16
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %95, i64 %1
  %100 = bitcast i8* %99 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %99, i64 16
  %102 = bitcast i8* %101 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %99, i64 %1
  %104 = bitcast i8* %103 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %103, i64 16
  %106 = bitcast i8* %105 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %103, i64 %1
  %108 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %107, i64 16
  %110 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %107, i64 %1
  %112 = bitcast i8* %111 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %111, i64 16
  %114 = bitcast i8* %113 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %111, i64 %1
  %116 = bitcast i8* %115 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %115, i64 16
  %118 = bitcast i8* %117 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %115, i64 %1
  %120 = bitcast i8* %119 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %119, i64 16
  %122 = bitcast i8* %121 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %119, i64 %1
  %124 = bitcast i8* %123 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %124, align 1
  %125 = getelementptr inbounds i8, i8* %123, i64 16
  %126 = bitcast i8* %125 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %123, i64 %1
  %128 = bitcast i8* %127 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %128, align 1
  %129 = getelementptr inbounds i8, i8* %127, i64 16
  %130 = bitcast i8* %129 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %130, align 1
  %131 = getelementptr inbounds i8, i8* %127, i64 %1
  %132 = bitcast i8* %131 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %132, align 1
  %133 = getelementptr inbounds i8, i8* %131, i64 16
  %134 = bitcast i8* %133 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %131, i64 %1
  %136 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %135, i64 16
  %138 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %135, i64 %1
  %140 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %139, i64 16
  %142 = bitcast i8* %141 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %142, align 1
  %143 = getelementptr inbounds i8, i8* %139, i64 %1
  %144 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %144, align 1
  %145 = getelementptr inbounds i8, i8* %143, i64 16
  %146 = bitcast i8* %145 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %143, i64 %1
  %148 = bitcast i8* %147 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %147, i64 16
  %150 = bitcast i8* %149 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %150, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi64EEEvPvlDv2_xEELi5ELi21846EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %11 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %12 = bitcast <2 x i64> %10 to <8 x i16>
  %13 = bitcast <2 x i64> %11 to <8 x i16>
  %14 = add <8 x i16> %13, %12
  %15 = bitcast <8 x i16> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %17 = bitcast <16 x i8> %16 to <8 x i16>
  %18 = add <8 x i16> %14, %17
  %19 = bitcast <8 x i16> %18 to <4 x i32>
  %20 = add <4 x i32> %19, <i32 16, i32 16, i32 16, i32 16>
  %21 = lshr <4 x i32> %20, <i32 5, i32 5, i32 5, i32 5>
  %22 = bitcast <4 x i32> %21 to <16 x i8>
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> zeroinitializer
  br label %24

24:                                               ; preds = %24, %4
  %25 = phi i32 [ 63, %4 ], [ %55, %24 ]
  %26 = phi i8* [ %0, %4 ], [ %54, %24 ]
  %27 = bitcast i8* %26 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %26, i64 16
  %29 = bitcast i8* %28 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %26, i64 %1
  %31 = bitcast i8* %30 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %30, i64 16
  %33 = bitcast i8* %32 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %30, i64 %1
  %35 = bitcast i8* %34 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %35, align 1
  %36 = getelementptr inbounds i8, i8* %34, i64 16
  %37 = bitcast i8* %36 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %34, i64 %1
  %39 = bitcast i8* %38 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %38, i64 16
  %41 = bitcast i8* %40 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %38, i64 %1
  %43 = bitcast i8* %42 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %42, i64 16
  %45 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %42, i64 %1
  %47 = bitcast i8* %46 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %46, i64 16
  %49 = bitcast i8* %48 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %46, i64 %1
  %51 = bitcast i8* %50 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %50, i64 16
  %53 = bitcast i8* %52 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %50, i64 %1
  %55 = add nsw i32 %25, -7
  %56 = icmp eq i32 %55, 0
  br i1 %56, label %57, label %24

57:                                               ; preds = %24
  %58 = bitcast i8* %54 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %54, i64 16
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %60, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi16EEEvPvlDv2_xEELi4ELi13108EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = getelementptr inbounds i8, i8* %2, i64 32
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = getelementptr inbounds i8, i8* %2, i64 48
  %14 = bitcast i8* %13 to <16 x i8>*
  %15 = load <16 x i8>, <16 x i8>* %14, align 1
  %16 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %17 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %18 = bitcast <2 x i64> %16 to <8 x i16>
  %19 = bitcast <2 x i64> %17 to <8 x i16>
  %20 = add <8 x i16> %19, %18
  %21 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %12, <16 x i8> zeroinitializer) #11
  %22 = bitcast <2 x i64> %21 to <8 x i16>
  %23 = add <8 x i16> %20, %22
  %24 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %15, <16 x i8> zeroinitializer) #11
  %25 = bitcast <2 x i64> %24 to <8 x i16>
  %26 = add <8 x i16> %23, %25
  %27 = bitcast <8 x i16> %26 to <16 x i8>
  %28 = shufflevector <16 x i8> %27, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %29 = bitcast <16 x i8> %28 to <8 x i16>
  %30 = add <8 x i16> %26, %29
  %31 = bitcast <8 x i16> %30 to <4 x i32>
  %32 = add <4 x i32> %31, <i32 32, i32 32, i32 32, i32 32>
  %33 = lshr <4 x i32> %32, <i32 6, i32 6, i32 6, i32 6>
  %34 = bitcast <4 x i32> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> zeroinitializer
  %36 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %0, i64 16
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %0, i64 32
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %0, i64 48
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %0, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 16
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %43, i64 32
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %43, i64 48
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %43, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 16
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %51, i64 32
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %51, i64 48
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %51, i64 %1
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %59, i64 16
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %59, i64 32
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %59, i64 48
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %59, i64 %1
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %67, i64 16
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %67, i64 32
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %67, i64 48
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %67, i64 %1
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %75, i64 16
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %75, i64 32
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %75, i64 48
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %75, i64 %1
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %83, i64 16
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %83, i64 32
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %83, i64 48
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %83, i64 %1
  %92 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %91, i64 16
  %94 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %91, i64 32
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %91, i64 48
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %91, i64 %1
  %100 = bitcast i8* %99 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %99, i64 16
  %102 = bitcast i8* %101 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %99, i64 32
  %104 = bitcast i8* %103 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %99, i64 48
  %106 = bitcast i8* %105 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %99, i64 %1
  %108 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %107, i64 16
  %110 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %107, i64 32
  %112 = bitcast i8* %111 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %107, i64 48
  %114 = bitcast i8* %113 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %107, i64 %1
  %116 = bitcast i8* %115 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %115, i64 16
  %118 = bitcast i8* %117 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %115, i64 32
  %120 = bitcast i8* %119 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %115, i64 48
  %122 = bitcast i8* %121 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %115, i64 %1
  %124 = bitcast i8* %123 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %124, align 1
  %125 = getelementptr inbounds i8, i8* %123, i64 16
  %126 = bitcast i8* %125 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %123, i64 32
  %128 = bitcast i8* %127 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %128, align 1
  %129 = getelementptr inbounds i8, i8* %123, i64 48
  %130 = bitcast i8* %129 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %130, align 1
  %131 = getelementptr inbounds i8, i8* %123, i64 %1
  %132 = bitcast i8* %131 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %132, align 1
  %133 = getelementptr inbounds i8, i8* %131, i64 16
  %134 = bitcast i8* %133 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %131, i64 32
  %136 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %131, i64 48
  %138 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %131, i64 %1
  %140 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %139, i64 16
  %142 = bitcast i8* %141 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %142, align 1
  %143 = getelementptr inbounds i8, i8* %139, i64 32
  %144 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %144, align 1
  %145 = getelementptr inbounds i8, i8* %139, i64 48
  %146 = bitcast i8* %145 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %139, i64 %1
  %148 = bitcast i8* %147 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %147, i64 16
  %150 = bitcast i8* %149 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %150, align 1
  %151 = getelementptr inbounds i8, i8* %147, i64 32
  %152 = bitcast i8* %151 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %152, align 1
  %153 = getelementptr inbounds i8, i8* %147, i64 48
  %154 = bitcast i8* %153 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %154, align 1
  %155 = getelementptr inbounds i8, i8* %147, i64 %1
  %156 = bitcast i8* %155 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %156, align 1
  %157 = getelementptr inbounds i8, i8* %155, i64 16
  %158 = bitcast i8* %157 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %155, i64 32
  %160 = bitcast i8* %159 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %160, align 1
  %161 = getelementptr inbounds i8, i8* %155, i64 48
  %162 = bitcast i8* %161 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %162, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi32EEEvPvlDv2_xEELi5ELi21846EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = getelementptr inbounds i8, i8* %2, i64 32
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = getelementptr inbounds i8, i8* %2, i64 48
  %14 = bitcast i8* %13 to <16 x i8>*
  %15 = load <16 x i8>, <16 x i8>* %14, align 1
  %16 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %17 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %18 = bitcast <2 x i64> %16 to <8 x i16>
  %19 = bitcast <2 x i64> %17 to <8 x i16>
  %20 = add <8 x i16> %19, %18
  %21 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %12, <16 x i8> zeroinitializer) #11
  %22 = bitcast <2 x i64> %21 to <8 x i16>
  %23 = add <8 x i16> %20, %22
  %24 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %15, <16 x i8> zeroinitializer) #11
  %25 = bitcast <2 x i64> %24 to <8 x i16>
  %26 = add <8 x i16> %23, %25
  %27 = bitcast <8 x i16> %26 to <16 x i8>
  %28 = shufflevector <16 x i8> %27, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %29 = bitcast <16 x i8> %28 to <8 x i16>
  %30 = add <8 x i16> %26, %29
  %31 = bitcast <8 x i16> %30 to <4 x i32>
  %32 = add <4 x i32> %31, <i32 32, i32 32, i32 32, i32 32>
  %33 = lshr <4 x i32> %32, <i32 6, i32 6, i32 6, i32 6>
  %34 = bitcast <4 x i32> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> zeroinitializer
  br label %36

36:                                               ; preds = %72, %4
  %37 = phi i32 [ 31, %4 ], [ %74, %72 ]
  %38 = phi i8* [ %0, %4 ], [ %73, %72 ]
  %39 = bitcast i8* %38 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %38, i64 16
  %41 = bitcast i8* %40 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %38, i64 32
  %43 = bitcast i8* %42 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %38, i64 48
  %45 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %38, i64 %1
  %47 = bitcast i8* %46 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %46, i64 16
  %49 = bitcast i8* %48 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %46, i64 32
  %51 = bitcast i8* %50 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %46, i64 48
  %53 = bitcast i8* %52 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %46, i64 %1
  %55 = bitcast i8* %54 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %54, i64 16
  %57 = bitcast i8* %56 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %54, i64 32
  %59 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %54, i64 48
  %61 = bitcast i8* %60 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %54, i64 %1
  %63 = icmp eq i32 %37, 3
  %64 = bitcast i8* %62 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %62, i64 16
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %62, i64 32
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %62, i64 48
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %70, align 1
  br i1 %63, label %71, label %72

71:                                               ; preds = %36
  ret void

72:                                               ; preds = %36
  %73 = getelementptr inbounds i8, i8* %62, i64 %1
  %74 = add nsw i32 %37, -4
  br label %36
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi64EEEvPvlDv2_xEELi0ELi0EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = getelementptr inbounds i8, i8* %2, i64 32
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = getelementptr inbounds i8, i8* %2, i64 48
  %14 = bitcast i8* %13 to <16 x i8>*
  %15 = load <16 x i8>, <16 x i8>* %14, align 1
  %16 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %17 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %18 = bitcast <2 x i64> %16 to <8 x i16>
  %19 = bitcast <2 x i64> %17 to <8 x i16>
  %20 = add <8 x i16> %19, %18
  %21 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %12, <16 x i8> zeroinitializer) #11
  %22 = bitcast <2 x i64> %21 to <8 x i16>
  %23 = add <8 x i16> %20, %22
  %24 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %15, <16 x i8> zeroinitializer) #11
  %25 = bitcast <2 x i64> %24 to <8 x i16>
  %26 = add <8 x i16> %23, %25
  %27 = bitcast <8 x i16> %26 to <16 x i8>
  %28 = shufflevector <16 x i8> %27, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %29 = bitcast <16 x i8> %28 to <8 x i16>
  %30 = add <8 x i16> %26, %29
  %31 = bitcast <8 x i16> %30 to <4 x i32>
  %32 = add <4 x i32> %31, <i32 32, i32 32, i32 32, i32 32>
  %33 = lshr <4 x i32> %32, <i32 6, i32 6, i32 6, i32 6>
  %34 = bitcast <4 x i32> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> zeroinitializer
  br label %36

36:                                               ; preds = %36, %4
  %37 = phi i32 [ 63, %4 ], [ %63, %36 ]
  %38 = phi i8* [ %0, %4 ], [ %62, %36 ]
  %39 = bitcast i8* %38 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %38, i64 16
  %41 = bitcast i8* %40 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %38, i64 32
  %43 = bitcast i8* %42 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %38, i64 48
  %45 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %38, i64 %1
  %47 = bitcast i8* %46 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %46, i64 16
  %49 = bitcast i8* %48 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %46, i64 32
  %51 = bitcast i8* %50 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %46, i64 48
  %53 = bitcast i8* %52 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %46, i64 %1
  %55 = bitcast i8* %54 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %54, i64 16
  %57 = bitcast i8* %56 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %54, i64 32
  %59 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %54, i64 48
  %61 = bitcast i8* %60 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %54, i64 %1
  %63 = add nsw i32 %37, -3
  %64 = icmp eq i32 %63, 0
  br i1 %64, label %65, label %36

65:                                               ; preds = %36
  %66 = bitcast i8* %62 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %62, i64 16
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %62, i64 32
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %62, i64 48
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %72, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi4EEEvPvlDv2_xEELi0ELi0EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 2, i32 2, i32 2, i32 2>
  %12 = lshr <4 x i32> %11, <i32 2, i32 2, i32 2, i32 2>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = bitcast <16 x i8> %14 to <4 x i32>
  %16 = extractelement <4 x i32> %15, i32 0
  %17 = bitcast i8* %0 to i32*
  store i32 %16, i32* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %1
  %19 = bitcast i8* %18 to i32*
  store i32 %16, i32* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 %1
  %21 = bitcast i8* %20 to i32*
  store i32 %16, i32* %21, align 1
  %22 = getelementptr inbounds i8, i8* %20, i64 %1
  %23 = bitcast i8* %22 to i32*
  store i32 %16, i32* %23, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi8EEEvPvlDv2_xEELi2ELi21846EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 4, i32 4, i32 4, i32 4>
  %12 = lshr <4 x i32> %11, <i32 3, i32 3, i32 3, i32 3>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = bitcast <16 x i8> %14 to <4 x i32>
  %16 = extractelement <4 x i32> %15, i32 0
  %17 = bitcast i8* %0 to i32*
  store i32 %16, i32* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %1
  %19 = bitcast i8* %18 to i32*
  store i32 %16, i32* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 %1
  %21 = bitcast i8* %20 to i32*
  store i32 %16, i32* %21, align 1
  %22 = getelementptr inbounds i8, i8* %20, i64 %1
  %23 = bitcast i8* %22 to i32*
  store i32 %16, i32* %23, align 1
  %24 = getelementptr inbounds i8, i8* %22, i64 %1
  %25 = bitcast i8* %24 to i32*
  store i32 %16, i32* %25, align 1
  %26 = getelementptr inbounds i8, i8* %24, i64 %1
  %27 = bitcast i8* %26 to i32*
  store i32 %16, i32* %27, align 1
  %28 = getelementptr inbounds i8, i8* %26, i64 %1
  %29 = bitcast i8* %28 to i32*
  store i32 %16, i32* %29, align 1
  %30 = getelementptr inbounds i8, i8* %28, i64 %1
  %31 = bitcast i8* %30 to i32*
  store i32 %16, i32* %31, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi16EEEvPvlDv2_xEELi2ELi13108EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = add <4 x i32> %13, <i32 8, i32 8, i32 8, i32 8>
  %15 = lshr <4 x i32> %14, <i32 4, i32 4, i32 4, i32 4>
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %18 = bitcast <16 x i8> %17 to <4 x i32>
  %19 = extractelement <4 x i32> %18, i32 0
  %20 = bitcast i8* %0 to i32*
  store i32 %19, i32* %20, align 1
  %21 = getelementptr inbounds i8, i8* %0, i64 %1
  %22 = bitcast i8* %21 to i32*
  store i32 %19, i32* %22, align 1
  %23 = getelementptr inbounds i8, i8* %21, i64 %1
  %24 = bitcast i8* %23 to i32*
  store i32 %19, i32* %24, align 1
  %25 = getelementptr inbounds i8, i8* %23, i64 %1
  %26 = bitcast i8* %25 to i32*
  store i32 %19, i32* %26, align 1
  %27 = getelementptr inbounds i8, i8* %25, i64 %1
  %28 = bitcast i8* %27 to i32*
  store i32 %19, i32* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 %1
  %30 = bitcast i8* %29 to i32*
  store i32 %19, i32* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 %1
  %32 = bitcast i8* %31 to i32*
  store i32 %19, i32* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 %1
  %34 = bitcast i8* %33 to i32*
  store i32 %19, i32* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 %1
  %36 = bitcast i8* %35 to i32*
  store i32 %19, i32* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 %1
  %38 = bitcast i8* %37 to i32*
  store i32 %19, i32* %38, align 1
  %39 = getelementptr inbounds i8, i8* %37, i64 %1
  %40 = bitcast i8* %39 to i32*
  store i32 %19, i32* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 %1
  %42 = bitcast i8* %41 to i32*
  store i32 %19, i32* %42, align 1
  %43 = getelementptr inbounds i8, i8* %41, i64 %1
  %44 = bitcast i8* %43 to i32*
  store i32 %19, i32* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 %1
  %46 = bitcast i8* %45 to i32*
  store i32 %19, i32* %46, align 1
  %47 = getelementptr inbounds i8, i8* %45, i64 %1
  %48 = bitcast i8* %47 to i32*
  store i32 %19, i32* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 %1
  %50 = bitcast i8* %49 to i32*
  store i32 %19, i32* %50, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi4EEEvPvlDv2_xEELi2ELi21846EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 2, i32 2, i32 2, i32 2>
  %12 = lshr <4 x i32> %11, <i32 2, i32 2, i32 2, i32 2>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = bitcast <16 x i8> %14 to <2 x i64>
  %16 = extractelement <2 x i64> %15, i32 0
  %17 = bitcast i8* %0 to i64*
  store i64 %16, i64* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %1
  %19 = bitcast i8* %18 to i64*
  store i64 %16, i64* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 %1
  %21 = bitcast i8* %20 to i64*
  store i64 %16, i64* %21, align 1
  %22 = getelementptr inbounds i8, i8* %20, i64 %1
  %23 = bitcast i8* %22 to i64*
  store i64 %16, i64* %23, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi8EEEvPvlDv2_xEELi0ELi0EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 4, i32 4, i32 4, i32 4>
  %12 = lshr <4 x i32> %11, <i32 3, i32 3, i32 3, i32 3>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = bitcast <16 x i8> %14 to <2 x i64>
  %16 = extractelement <2 x i64> %15, i32 0
  %17 = bitcast i8* %0 to i64*
  store i64 %16, i64* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %1
  %19 = bitcast i8* %18 to i64*
  store i64 %16, i64* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 %1
  %21 = bitcast i8* %20 to i64*
  store i64 %16, i64* %21, align 1
  %22 = getelementptr inbounds i8, i8* %20, i64 %1
  %23 = bitcast i8* %22 to i64*
  store i64 %16, i64* %23, align 1
  %24 = getelementptr inbounds i8, i8* %22, i64 %1
  %25 = bitcast i8* %24 to i64*
  store i64 %16, i64* %25, align 1
  %26 = getelementptr inbounds i8, i8* %24, i64 %1
  %27 = bitcast i8* %26 to i64*
  store i64 %16, i64* %27, align 1
  %28 = getelementptr inbounds i8, i8* %26, i64 %1
  %29 = bitcast i8* %28 to i64*
  store i64 %16, i64* %29, align 1
  %30 = getelementptr inbounds i8, i8* %28, i64 %1
  %31 = bitcast i8* %30 to i64*
  store i64 %16, i64* %31, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi16EEEvPvlDv2_xEELi3ELi21846EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = add <4 x i32> %13, <i32 8, i32 8, i32 8, i32 8>
  %15 = lshr <4 x i32> %14, <i32 4, i32 4, i32 4, i32 4>
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %18 = bitcast <16 x i8> %17 to <2 x i64>
  %19 = extractelement <2 x i64> %18, i32 0
  %20 = bitcast i8* %0 to i64*
  store i64 %19, i64* %20, align 1
  %21 = getelementptr inbounds i8, i8* %0, i64 %1
  %22 = bitcast i8* %21 to i64*
  store i64 %19, i64* %22, align 1
  %23 = getelementptr inbounds i8, i8* %21, i64 %1
  %24 = bitcast i8* %23 to i64*
  store i64 %19, i64* %24, align 1
  %25 = getelementptr inbounds i8, i8* %23, i64 %1
  %26 = bitcast i8* %25 to i64*
  store i64 %19, i64* %26, align 1
  %27 = getelementptr inbounds i8, i8* %25, i64 %1
  %28 = bitcast i8* %27 to i64*
  store i64 %19, i64* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 %1
  %30 = bitcast i8* %29 to i64*
  store i64 %19, i64* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 %1
  %32 = bitcast i8* %31 to i64*
  store i64 %19, i64* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 %1
  %34 = bitcast i8* %33 to i64*
  store i64 %19, i64* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 %1
  %36 = bitcast i8* %35 to i64*
  store i64 %19, i64* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 %1
  %38 = bitcast i8* %37 to i64*
  store i64 %19, i64* %38, align 1
  %39 = getelementptr inbounds i8, i8* %37, i64 %1
  %40 = bitcast i8* %39 to i64*
  store i64 %19, i64* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 %1
  %42 = bitcast i8* %41 to i64*
  store i64 %19, i64* %42, align 1
  %43 = getelementptr inbounds i8, i8* %41, i64 %1
  %44 = bitcast i8* %43 to i64*
  store i64 %19, i64* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 %1
  %46 = bitcast i8* %45 to i64*
  store i64 %19, i64* %46, align 1
  %47 = getelementptr inbounds i8, i8* %45, i64 %1
  %48 = bitcast i8* %47 to i64*
  store i64 %19, i64* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 %1
  %50 = bitcast i8* %49 to i64*
  store i64 %19, i64* %50, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi32EEEvPvlDv2_xEELi3ELi13108EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %3, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %11 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %12 = bitcast <2 x i64> %10 to <8 x i16>
  %13 = bitcast <2 x i64> %11 to <8 x i16>
  %14 = add <8 x i16> %13, %12
  %15 = bitcast <8 x i16> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %17 = bitcast <16 x i8> %16 to <8 x i16>
  %18 = add <8 x i16> %14, %17
  %19 = bitcast <8 x i16> %18 to <4 x i32>
  %20 = add <4 x i32> %19, <i32 16, i32 16, i32 16, i32 16>
  %21 = lshr <4 x i32> %20, <i32 5, i32 5, i32 5, i32 5>
  %22 = bitcast <4 x i32> %21 to <16 x i8>
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %24 = bitcast <16 x i8> %23 to <2 x i64>
  %25 = extractelement <2 x i64> %24, i32 0
  %26 = bitcast i8* %0 to i64*
  store i64 %25, i64* %26, align 1
  %27 = getelementptr inbounds i8, i8* %0, i64 %1
  %28 = bitcast i8* %27 to i64*
  store i64 %25, i64* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 %1
  %30 = bitcast i8* %29 to i64*
  store i64 %25, i64* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 %1
  %32 = bitcast i8* %31 to i64*
  store i64 %25, i64* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 %1
  %34 = bitcast i8* %33 to i64*
  store i64 %25, i64* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 %1
  %36 = bitcast i8* %35 to i64*
  store i64 %25, i64* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 %1
  %38 = bitcast i8* %37 to i64*
  store i64 %25, i64* %38, align 1
  %39 = getelementptr inbounds i8, i8* %37, i64 %1
  %40 = bitcast i8* %39 to i64*
  store i64 %25, i64* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 %1
  %42 = bitcast i8* %41 to i64*
  store i64 %25, i64* %42, align 1
  %43 = getelementptr inbounds i8, i8* %41, i64 %1
  %44 = bitcast i8* %43 to i64*
  store i64 %25, i64* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 %1
  %46 = bitcast i8* %45 to i64*
  store i64 %25, i64* %46, align 1
  %47 = getelementptr inbounds i8, i8* %45, i64 %1
  %48 = bitcast i8* %47 to i64*
  store i64 %25, i64* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 %1
  %50 = bitcast i8* %49 to i64*
  store i64 %25, i64* %50, align 1
  %51 = getelementptr inbounds i8, i8* %49, i64 %1
  %52 = bitcast i8* %51 to i64*
  store i64 %25, i64* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 %1
  %54 = bitcast i8* %53 to i64*
  store i64 %25, i64* %54, align 1
  %55 = getelementptr inbounds i8, i8* %53, i64 %1
  %56 = bitcast i8* %55 to i64*
  store i64 %25, i64* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 %1
  %58 = bitcast i8* %57 to i64*
  store i64 %25, i64* %58, align 1
  %59 = getelementptr inbounds i8, i8* %57, i64 %1
  %60 = bitcast i8* %59 to i64*
  store i64 %25, i64* %60, align 1
  %61 = getelementptr inbounds i8, i8* %59, i64 %1
  %62 = bitcast i8* %61 to i64*
  store i64 %25, i64* %62, align 1
  %63 = getelementptr inbounds i8, i8* %61, i64 %1
  %64 = bitcast i8* %63 to i64*
  store i64 %25, i64* %64, align 1
  %65 = getelementptr inbounds i8, i8* %63, i64 %1
  %66 = bitcast i8* %65 to i64*
  store i64 %25, i64* %66, align 1
  %67 = getelementptr inbounds i8, i8* %65, i64 %1
  %68 = bitcast i8* %67 to i64*
  store i64 %25, i64* %68, align 1
  %69 = getelementptr inbounds i8, i8* %67, i64 %1
  %70 = bitcast i8* %69 to i64*
  store i64 %25, i64* %70, align 1
  %71 = getelementptr inbounds i8, i8* %69, i64 %1
  %72 = bitcast i8* %71 to i64*
  store i64 %25, i64* %72, align 1
  %73 = getelementptr inbounds i8, i8* %71, i64 %1
  %74 = bitcast i8* %73 to i64*
  store i64 %25, i64* %74, align 1
  %75 = getelementptr inbounds i8, i8* %73, i64 %1
  %76 = bitcast i8* %75 to i64*
  store i64 %25, i64* %76, align 1
  %77 = getelementptr inbounds i8, i8* %75, i64 %1
  %78 = bitcast i8* %77 to i64*
  store i64 %25, i64* %78, align 1
  %79 = getelementptr inbounds i8, i8* %77, i64 %1
  %80 = bitcast i8* %79 to i64*
  store i64 %25, i64* %80, align 1
  %81 = getelementptr inbounds i8, i8* %79, i64 %1
  %82 = bitcast i8* %81 to i64*
  store i64 %25, i64* %82, align 1
  %83 = getelementptr inbounds i8, i8* %81, i64 %1
  %84 = bitcast i8* %83 to i64*
  store i64 %25, i64* %84, align 1
  %85 = getelementptr inbounds i8, i8* %83, i64 %1
  %86 = bitcast i8* %85 to i64*
  store i64 %25, i64* %86, align 1
  %87 = getelementptr inbounds i8, i8* %85, i64 %1
  %88 = bitcast i8* %87 to i64*
  store i64 %25, i64* %88, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi4EEEvPvlDv2_xEELi2ELi13108EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 2, i32 2, i32 2, i32 2>
  %12 = lshr <4 x i32> %11, <i32 2, i32 2, i32 2, i32 2>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> zeroinitializer
  %15 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 %1
  %17 = bitcast i8* %16 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %17, align 1
  %18 = getelementptr inbounds i8, i8* %16, i64 %1
  %19 = bitcast i8* %18 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 %1
  %21 = bitcast i8* %20 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %21, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi8EEEvPvlDv2_xEELi3ELi21846EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 4, i32 4, i32 4, i32 4>
  %12 = lshr <4 x i32> %11, <i32 3, i32 3, i32 3, i32 3>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> zeroinitializer
  %15 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 %1
  %17 = bitcast i8* %16 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %17, align 1
  %18 = getelementptr inbounds i8, i8* %16, i64 %1
  %19 = bitcast i8* %18 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 %1
  %21 = bitcast i8* %20 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %20, i64 %1
  %23 = bitcast i8* %22 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %23, align 1
  %24 = getelementptr inbounds i8, i8* %22, i64 %1
  %25 = bitcast i8* %24 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %24, i64 %1
  %27 = bitcast i8* %26 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %26, i64 %1
  %29 = bitcast i8* %28 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %29, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi16EEEvPvlDv2_xEELi0ELi0EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = add <4 x i32> %13, <i32 8, i32 8, i32 8, i32 8>
  %15 = lshr <4 x i32> %14, <i32 4, i32 4, i32 4, i32 4>
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = bitcast i8* %19 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %19, i64 %1
  %22 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %21, i64 %1
  %24 = bitcast i8* %23 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %23, i64 %1
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %25, i64 %1
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 %1
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 %1
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 %1
  %34 = bitcast i8* %33 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 %1
  %36 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 %1
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %37, i64 %1
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 %1
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %41, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 %1
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %45, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %48, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi32EEEvPvlDv2_xEELi4ELi21846EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %3, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %11 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %12 = bitcast <2 x i64> %10 to <8 x i16>
  %13 = bitcast <2 x i64> %11 to <8 x i16>
  %14 = add <8 x i16> %13, %12
  %15 = bitcast <8 x i16> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %17 = bitcast <16 x i8> %16 to <8 x i16>
  %18 = add <8 x i16> %14, %17
  %19 = bitcast <8 x i16> %18 to <4 x i32>
  %20 = add <4 x i32> %19, <i32 16, i32 16, i32 16, i32 16>
  %21 = lshr <4 x i32> %20, <i32 5, i32 5, i32 5, i32 5>
  %22 = bitcast <4 x i32> %21 to <16 x i8>
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> zeroinitializer
  %24 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 %1
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %25, i64 %1
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 %1
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 %1
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 %1
  %34 = bitcast i8* %33 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 %1
  %36 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 %1
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %37, i64 %1
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 %1
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %41, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 %1
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %45, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 %1
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %49, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 %1
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %53, i64 %1
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 %1
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %57, i64 %1
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %59, i64 %1
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %61, i64 %1
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %63, i64 %1
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %65, i64 %1
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %67, i64 %1
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %69, i64 %1
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %71, i64 %1
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %73, i64 %1
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %75, i64 %1
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %77, i64 %1
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %79, i64 %1
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %81, i64 %1
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %83, i64 %1
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %86, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi64EEEvPvlDv2_xEELi4ELi13108EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %3, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = getelementptr inbounds i8, i8* %3, i64 32
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = getelementptr inbounds i8, i8* %3, i64 48
  %14 = bitcast i8* %13 to <16 x i8>*
  %15 = load <16 x i8>, <16 x i8>* %14, align 1
  %16 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %17 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %18 = bitcast <2 x i64> %16 to <8 x i16>
  %19 = bitcast <2 x i64> %17 to <8 x i16>
  %20 = add <8 x i16> %19, %18
  %21 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %12, <16 x i8> zeroinitializer) #11
  %22 = bitcast <2 x i64> %21 to <8 x i16>
  %23 = add <8 x i16> %20, %22
  %24 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %15, <16 x i8> zeroinitializer) #11
  %25 = bitcast <2 x i64> %24 to <8 x i16>
  %26 = add <8 x i16> %23, %25
  %27 = bitcast <8 x i16> %26 to <16 x i8>
  %28 = shufflevector <16 x i8> %27, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %29 = bitcast <16 x i8> %28 to <8 x i16>
  %30 = add <8 x i16> %26, %29
  %31 = bitcast <8 x i16> %30 to <4 x i32>
  %32 = add <4 x i32> %31, <i32 32, i32 32, i32 32, i32 32>
  %33 = lshr <4 x i32> %32, <i32 6, i32 6, i32 6, i32 6>
  %34 = bitcast <4 x i32> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> zeroinitializer
  %36 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %0, i64 %1
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %37, i64 %1
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 %1
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %41, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 %1
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %45, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 %1
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %49, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 %1
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %53, i64 %1
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 %1
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %57, i64 %1
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %59, i64 %1
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %61, i64 %1
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %63, i64 %1
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %65, i64 %1
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %67, i64 %1
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %69, i64 %1
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %71, i64 %1
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %73, i64 %1
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %75, i64 %1
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %77, i64 %1
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %79, i64 %1
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %81, i64 %1
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %83, i64 %1
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %85, i64 %1
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %87, i64 %1
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %89, i64 %1
  %92 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %91, i64 %1
  %94 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %93, i64 %1
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %95, i64 %1
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %97, i64 %1
  %100 = bitcast i8* %99 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %99, i64 %1
  %102 = bitcast i8* %101 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %101, i64 %1
  %104 = bitcast i8* %103 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %103, i64 %1
  %106 = bitcast i8* %105 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %105, i64 %1
  %108 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %107, i64 %1
  %110 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %109, i64 %1
  %112 = bitcast i8* %111 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %111, i64 %1
  %114 = bitcast i8* %113 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %113, i64 %1
  %116 = bitcast i8* %115 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %115, i64 %1
  %118 = bitcast i8* %117 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %117, i64 %1
  %120 = bitcast i8* %119 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %119, i64 %1
  %122 = bitcast i8* %121 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %121, i64 %1
  %124 = bitcast i8* %123 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %124, align 1
  %125 = getelementptr inbounds i8, i8* %123, i64 %1
  %126 = bitcast i8* %125 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %125, i64 %1
  %128 = bitcast i8* %127 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %128, align 1
  %129 = getelementptr inbounds i8, i8* %127, i64 %1
  %130 = bitcast i8* %129 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %130, align 1
  %131 = getelementptr inbounds i8, i8* %129, i64 %1
  %132 = bitcast i8* %131 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %132, align 1
  %133 = getelementptr inbounds i8, i8* %131, i64 %1
  %134 = bitcast i8* %133 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %133, i64 %1
  %136 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %135, i64 %1
  %138 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %137, i64 %1
  %140 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %139, i64 %1
  %142 = bitcast i8* %141 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %142, align 1
  %143 = getelementptr inbounds i8, i8* %141, i64 %1
  %144 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %144, align 1
  %145 = getelementptr inbounds i8, i8* %143, i64 %1
  %146 = bitcast i8* %145 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %145, i64 %1
  %148 = bitcast i8* %147 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %147, i64 %1
  %150 = bitcast i8* %149 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %150, align 1
  %151 = getelementptr inbounds i8, i8* %149, i64 %1
  %152 = bitcast i8* %151 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %152, align 1
  %153 = getelementptr inbounds i8, i8* %151, i64 %1
  %154 = bitcast i8* %153 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %154, align 1
  %155 = getelementptr inbounds i8, i8* %153, i64 %1
  %156 = bitcast i8* %155 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %156, align 1
  %157 = getelementptr inbounds i8, i8* %155, i64 %1
  %158 = bitcast i8* %157 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %157, i64 %1
  %160 = bitcast i8* %159 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %160, align 1
  %161 = getelementptr inbounds i8, i8* %159, i64 %1
  %162 = bitcast i8* %161 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %162, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi8EEEvPvlDv2_xEELi3ELi13108EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast <2 x i64> %9 to <4 x i32>
  %11 = add <4 x i32> %10, <i32 4, i32 4, i32 4, i32 4>
  %12 = lshr <4 x i32> %11, <i32 3, i32 3, i32 3, i32 3>
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> zeroinitializer
  %15 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 16
  %17 = bitcast i8* %16 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %1
  %19 = bitcast i8* %18 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %19, align 1
  %20 = getelementptr inbounds i8, i8* %18, i64 16
  %21 = bitcast i8* %20 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %18, i64 %1
  %23 = bitcast i8* %22 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %23, align 1
  %24 = getelementptr inbounds i8, i8* %22, i64 16
  %25 = bitcast i8* %24 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %22, i64 %1
  %27 = bitcast i8* %26 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %26, i64 16
  %29 = bitcast i8* %28 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %26, i64 %1
  %31 = bitcast i8* %30 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %30, i64 16
  %33 = bitcast i8* %32 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %30, i64 %1
  %35 = bitcast i8* %34 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %35, align 1
  %36 = getelementptr inbounds i8, i8* %34, i64 16
  %37 = bitcast i8* %36 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %34, i64 %1
  %39 = bitcast i8* %38 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %38, i64 16
  %41 = bitcast i8* %40 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %38, i64 %1
  %43 = bitcast i8* %42 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %42, i64 16
  %45 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %14, <16 x i8>* %45, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi16EEEvPvlDv2_xEELi4ELi21846EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = add <4 x i32> %13, <i32 8, i32 8, i32 8, i32 8>
  %15 = lshr <4 x i32> %14, <i32 4, i32 4, i32 4, i32 4>
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 16
  %20 = bitcast i8* %19 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %0, i64 %1
  %22 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %21, i64 16
  %24 = bitcast i8* %23 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %21, i64 %1
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %25, i64 16
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %25, i64 %1
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 16
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %29, i64 %1
  %34 = bitcast i8* %33 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 16
  %36 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %33, i64 %1
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %37, i64 16
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %37, i64 %1
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %41, i64 16
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %41, i64 %1
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %45, i64 16
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %45, i64 %1
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %49, i64 16
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %49, i64 %1
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %53, i64 16
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %53, i64 %1
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %57, i64 16
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %57, i64 %1
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %61, i64 16
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %61, i64 %1
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %65, i64 16
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %65, i64 %1
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %69, i64 16
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %69, i64 %1
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %73, i64 16
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %73, i64 %1
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %77, i64 16
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %80, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi32EEEvPvlDv2_xEELi0ELi0EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %3, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %11 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %12 = bitcast <2 x i64> %10 to <8 x i16>
  %13 = bitcast <2 x i64> %11 to <8 x i16>
  %14 = add <8 x i16> %13, %12
  %15 = bitcast <8 x i16> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %17 = bitcast <16 x i8> %16 to <8 x i16>
  %18 = add <8 x i16> %14, %17
  %19 = bitcast <8 x i16> %18 to <4 x i32>
  %20 = add <4 x i32> %19, <i32 16, i32 16, i32 16, i32 16>
  %21 = lshr <4 x i32> %20, <i32 5, i32 5, i32 5, i32 5>
  %22 = bitcast <4 x i32> %21 to <16 x i8>
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> zeroinitializer
  %24 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 16
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %0, i64 %1
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 16
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %27, i64 %1
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 16
  %34 = bitcast i8* %33 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %31, i64 %1
  %36 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 16
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %35, i64 %1
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 16
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %39, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 16
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %43, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 16
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %47, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 16
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %51, i64 %1
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 16
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %55, i64 %1
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %59, i64 16
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %59, i64 %1
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %63, i64 16
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %63, i64 %1
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %67, i64 16
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %67, i64 %1
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %71, i64 16
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %71, i64 %1
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %75, i64 16
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %75, i64 %1
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %79, i64 16
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %79, i64 %1
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %83, i64 16
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %83, i64 %1
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %87, i64 16
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %87, i64 %1
  %92 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %91, i64 16
  %94 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %91, i64 %1
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %95, i64 16
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %95, i64 %1
  %100 = bitcast i8* %99 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %99, i64 16
  %102 = bitcast i8* %101 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %99, i64 %1
  %104 = bitcast i8* %103 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %103, i64 16
  %106 = bitcast i8* %105 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %103, i64 %1
  %108 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %107, i64 16
  %110 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %107, i64 %1
  %112 = bitcast i8* %111 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %111, i64 16
  %114 = bitcast i8* %113 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %111, i64 %1
  %116 = bitcast i8* %115 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %115, i64 16
  %118 = bitcast i8* %117 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %115, i64 %1
  %120 = bitcast i8* %119 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %119, i64 16
  %122 = bitcast i8* %121 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %119, i64 %1
  %124 = bitcast i8* %123 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %124, align 1
  %125 = getelementptr inbounds i8, i8* %123, i64 16
  %126 = bitcast i8* %125 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %123, i64 %1
  %128 = bitcast i8* %127 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %128, align 1
  %129 = getelementptr inbounds i8, i8* %127, i64 16
  %130 = bitcast i8* %129 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %130, align 1
  %131 = getelementptr inbounds i8, i8* %127, i64 %1
  %132 = bitcast i8* %131 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %132, align 1
  %133 = getelementptr inbounds i8, i8* %131, i64 16
  %134 = bitcast i8* %133 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %131, i64 %1
  %136 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %135, i64 16
  %138 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %135, i64 %1
  %140 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %139, i64 16
  %142 = bitcast i8* %141 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %142, align 1
  %143 = getelementptr inbounds i8, i8* %139, i64 %1
  %144 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %144, align 1
  %145 = getelementptr inbounds i8, i8* %143, i64 16
  %146 = bitcast i8* %145 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %143, i64 %1
  %148 = bitcast i8* %147 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %147, i64 16
  %150 = bitcast i8* %149 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %150, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi64EEEvPvlDv2_xEELi5ELi21846EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %3, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = getelementptr inbounds i8, i8* %3, i64 32
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = getelementptr inbounds i8, i8* %3, i64 48
  %14 = bitcast i8* %13 to <16 x i8>*
  %15 = load <16 x i8>, <16 x i8>* %14, align 1
  %16 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %17 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %18 = bitcast <2 x i64> %16 to <8 x i16>
  %19 = bitcast <2 x i64> %17 to <8 x i16>
  %20 = add <8 x i16> %19, %18
  %21 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %12, <16 x i8> zeroinitializer) #11
  %22 = bitcast <2 x i64> %21 to <8 x i16>
  %23 = add <8 x i16> %20, %22
  %24 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %15, <16 x i8> zeroinitializer) #11
  %25 = bitcast <2 x i64> %24 to <8 x i16>
  %26 = add <8 x i16> %23, %25
  %27 = bitcast <8 x i16> %26 to <16 x i8>
  %28 = shufflevector <16 x i8> %27, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %29 = bitcast <16 x i8> %28 to <8 x i16>
  %30 = add <8 x i16> %26, %29
  %31 = bitcast <8 x i16> %30 to <4 x i32>
  %32 = add <4 x i32> %31, <i32 32, i32 32, i32 32, i32 32>
  %33 = lshr <4 x i32> %32, <i32 6, i32 6, i32 6, i32 6>
  %34 = bitcast <4 x i32> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> zeroinitializer
  br label %36

36:                                               ; preds = %36, %4
  %37 = phi i32 [ 63, %4 ], [ %67, %36 ]
  %38 = phi i8* [ %0, %4 ], [ %66, %36 ]
  %39 = bitcast i8* %38 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %38, i64 16
  %41 = bitcast i8* %40 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %38, i64 %1
  %43 = bitcast i8* %42 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %42, i64 16
  %45 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %42, i64 %1
  %47 = bitcast i8* %46 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %46, i64 16
  %49 = bitcast i8* %48 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %46, i64 %1
  %51 = bitcast i8* %50 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %50, i64 16
  %53 = bitcast i8* %52 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %50, i64 %1
  %55 = bitcast i8* %54 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %54, i64 16
  %57 = bitcast i8* %56 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %54, i64 %1
  %59 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %58, i64 16
  %61 = bitcast i8* %60 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %58, i64 %1
  %63 = bitcast i8* %62 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %62, i64 16
  %65 = bitcast i8* %64 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %65, align 1
  %66 = getelementptr inbounds i8, i8* %62, i64 %1
  %67 = add nsw i32 %37, -7
  %68 = icmp eq i32 %67, 0
  br i1 %68, label %69, label %36

69:                                               ; preds = %36
  %70 = bitcast i8* %66 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %66, i64 16
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %72, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi16EEEvPvlDv2_xEELi4ELi13108EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = add <4 x i32> %13, <i32 8, i32 8, i32 8, i32 8>
  %15 = lshr <4 x i32> %14, <i32 4, i32 4, i32 4, i32 4>
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <16 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 16
  %20 = bitcast i8* %19 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %0, i64 32
  %22 = bitcast i8* %21 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %0, i64 48
  %24 = bitcast i8* %23 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 %1
  %26 = bitcast i8* %25 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %25, i64 16
  %28 = bitcast i8* %27 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %25, i64 32
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %25, i64 48
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %25, i64 %1
  %34 = bitcast i8* %33 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 16
  %36 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %33, i64 32
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %33, i64 48
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %33, i64 %1
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %41, i64 16
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %41, i64 32
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %41, i64 48
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %41, i64 %1
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %49, i64 16
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %49, i64 32
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %49, i64 48
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %49, i64 %1
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %57, i64 16
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %57, i64 32
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %57, i64 48
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %57, i64 %1
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %65, i64 16
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %65, i64 32
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %65, i64 48
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %65, i64 %1
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %73, i64 16
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %73, i64 32
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %73, i64 48
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %73, i64 %1
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %81, i64 16
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %81, i64 32
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %81, i64 48
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %81, i64 %1
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %89, i64 16
  %92 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %89, i64 32
  %94 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %89, i64 48
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %89, i64 %1
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %97, i64 16
  %100 = bitcast i8* %99 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %97, i64 32
  %102 = bitcast i8* %101 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %97, i64 48
  %104 = bitcast i8* %103 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %97, i64 %1
  %106 = bitcast i8* %105 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %105, i64 16
  %108 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %105, i64 32
  %110 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %105, i64 48
  %112 = bitcast i8* %111 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %105, i64 %1
  %114 = bitcast i8* %113 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %113, i64 16
  %116 = bitcast i8* %115 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %113, i64 32
  %118 = bitcast i8* %117 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %113, i64 48
  %120 = bitcast i8* %119 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %113, i64 %1
  %122 = bitcast i8* %121 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %121, i64 16
  %124 = bitcast i8* %123 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %124, align 1
  %125 = getelementptr inbounds i8, i8* %121, i64 32
  %126 = bitcast i8* %125 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %121, i64 48
  %128 = bitcast i8* %127 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %128, align 1
  %129 = getelementptr inbounds i8, i8* %121, i64 %1
  %130 = bitcast i8* %129 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %130, align 1
  %131 = getelementptr inbounds i8, i8* %129, i64 16
  %132 = bitcast i8* %131 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %132, align 1
  %133 = getelementptr inbounds i8, i8* %129, i64 32
  %134 = bitcast i8* %133 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %129, i64 48
  %136 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %129, i64 %1
  %138 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %137, i64 16
  %140 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %137, i64 32
  %142 = bitcast i8* %141 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %142, align 1
  %143 = getelementptr inbounds i8, i8* %137, i64 48
  %144 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %17, <16 x i8>* %144, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi32EEEvPvlDv2_xEELi5ELi21846EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %3, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %11 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %12 = bitcast <2 x i64> %10 to <8 x i16>
  %13 = bitcast <2 x i64> %11 to <8 x i16>
  %14 = add <8 x i16> %13, %12
  %15 = bitcast <8 x i16> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %17 = bitcast <16 x i8> %16 to <8 x i16>
  %18 = add <8 x i16> %14, %17
  %19 = bitcast <8 x i16> %18 to <4 x i32>
  %20 = add <4 x i32> %19, <i32 16, i32 16, i32 16, i32 16>
  %21 = lshr <4 x i32> %20, <i32 5, i32 5, i32 5, i32 5>
  %22 = bitcast <4 x i32> %21 to <16 x i8>
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> zeroinitializer
  br label %24

24:                                               ; preds = %60, %4
  %25 = phi i32 [ 31, %4 ], [ %62, %60 ]
  %26 = phi i8* [ %0, %4 ], [ %61, %60 ]
  %27 = bitcast i8* %26 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %26, i64 16
  %29 = bitcast i8* %28 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %26, i64 32
  %31 = bitcast i8* %30 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %26, i64 48
  %33 = bitcast i8* %32 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %26, i64 %1
  %35 = bitcast i8* %34 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %35, align 1
  %36 = getelementptr inbounds i8, i8* %34, i64 16
  %37 = bitcast i8* %36 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %34, i64 32
  %39 = bitcast i8* %38 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %34, i64 48
  %41 = bitcast i8* %40 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %34, i64 %1
  %43 = bitcast i8* %42 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %42, i64 16
  %45 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %42, i64 32
  %47 = bitcast i8* %46 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %42, i64 48
  %49 = bitcast i8* %48 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %42, i64 %1
  %51 = icmp eq i32 %25, 3
  %52 = bitcast i8* %50 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %50, i64 16
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %50, i64 32
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %50, i64 48
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %23, <16 x i8>* %58, align 1
  br i1 %51, label %59, label %60

59:                                               ; preds = %24
  ret void

60:                                               ; preds = %24
  %61 = getelementptr inbounds i8, i8* %50, i64 %1
  %62 = add nsw i32 %25, -4
  br label %24
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi64EEEvPvlDv2_xEELi0ELi0EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %3, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = getelementptr inbounds i8, i8* %3, i64 32
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = getelementptr inbounds i8, i8* %3, i64 48
  %14 = bitcast i8* %13 to <16 x i8>*
  %15 = load <16 x i8>, <16 x i8>* %14, align 1
  %16 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %17 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %18 = bitcast <2 x i64> %16 to <8 x i16>
  %19 = bitcast <2 x i64> %17 to <8 x i16>
  %20 = add <8 x i16> %19, %18
  %21 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %12, <16 x i8> zeroinitializer) #11
  %22 = bitcast <2 x i64> %21 to <8 x i16>
  %23 = add <8 x i16> %20, %22
  %24 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %15, <16 x i8> zeroinitializer) #11
  %25 = bitcast <2 x i64> %24 to <8 x i16>
  %26 = add <8 x i16> %23, %25
  %27 = bitcast <8 x i16> %26 to <16 x i8>
  %28 = shufflevector <16 x i8> %27, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %29 = bitcast <16 x i8> %28 to <8 x i16>
  %30 = add <8 x i16> %26, %29
  %31 = bitcast <8 x i16> %30 to <4 x i32>
  %32 = add <4 x i32> %31, <i32 32, i32 32, i32 32, i32 32>
  %33 = lshr <4 x i32> %32, <i32 6, i32 6, i32 6, i32 6>
  %34 = bitcast <4 x i32> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> zeroinitializer
  br label %36

36:                                               ; preds = %36, %4
  %37 = phi i32 [ 63, %4 ], [ %63, %36 ]
  %38 = phi i8* [ %0, %4 ], [ %62, %36 ]
  %39 = bitcast i8* %38 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %38, i64 16
  %41 = bitcast i8* %40 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %38, i64 32
  %43 = bitcast i8* %42 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %38, i64 48
  %45 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %38, i64 %1
  %47 = bitcast i8* %46 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %46, i64 16
  %49 = bitcast i8* %48 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %46, i64 32
  %51 = bitcast i8* %50 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %46, i64 48
  %53 = bitcast i8* %52 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %46, i64 %1
  %55 = bitcast i8* %54 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %54, i64 16
  %57 = bitcast i8* %56 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %54, i64 32
  %59 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %54, i64 48
  %61 = bitcast i8* %60 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %54, i64 %1
  %63 = add nsw i32 %37, -3
  %64 = icmp eq i32 %63, 0
  br i1 %64, label %65, label %36

65:                                               ; preds = %36
  %66 = bitcast i8* %62 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %62, i64 16
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %62, i64 32
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %62, i64 48
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %72, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi4EEEvPvlDv2_xEELi0ELi0EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast i8* %3 to i32*
  %11 = load i32, i32* %10, align 1
  %12 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %11, i32 0
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %13, <16 x i8> zeroinitializer) #11
  %15 = bitcast <2 x i64> %9 to <4 x i32>
  %16 = bitcast <2 x i64> %14 to <4 x i32>
  %17 = add <4 x i32> %15, <i32 4, i32 4, i32 4, i32 4>
  %18 = add <4 x i32> %17, %16
  %19 = lshr <4 x i32> %18, <i32 3, i32 3, i32 3, i32 3>
  %20 = bitcast <4 x i32> %19 to <16 x i8>
  %21 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %22 = bitcast <16 x i8> %21 to <4 x i32>
  %23 = extractelement <4 x i32> %22, i32 0
  %24 = bitcast i8* %0 to i32*
  store i32 %23, i32* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 %1
  %26 = bitcast i8* %25 to i32*
  store i32 %23, i32* %26, align 1
  %27 = getelementptr inbounds i8, i8* %25, i64 %1
  %28 = bitcast i8* %27 to i32*
  store i32 %23, i32* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 %1
  %30 = bitcast i8* %29 to i32*
  store i32 %23, i32* %30, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi8EEEvPvlDv2_xEELi2ELi21846EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast i8* %3 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %13, <16 x i8> zeroinitializer) #11
  %15 = bitcast <2 x i64> %9 to <4 x i32>
  %16 = bitcast <2 x i64> %14 to <4 x i32>
  %17 = add <4 x i32> %15, <i32 6, i32 6, i32 6, i32 6>
  %18 = add <4 x i32> %17, %16
  %19 = lshr <4 x i32> %18, <i32 2, i32 2, i32 2, i32 2>
  %20 = bitcast <4 x i32> %19 to <8 x i16>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %20, <8 x i16> <i16 21846, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %22 = bitcast <8 x i16> %21 to <16 x i8>
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %24 = bitcast <16 x i8> %23 to <4 x i32>
  %25 = extractelement <4 x i32> %24, i32 0
  %26 = bitcast i8* %0 to i32*
  store i32 %25, i32* %26, align 1
  %27 = getelementptr inbounds i8, i8* %0, i64 %1
  %28 = bitcast i8* %27 to i32*
  store i32 %25, i32* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 %1
  %30 = bitcast i8* %29 to i32*
  store i32 %25, i32* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 %1
  %32 = bitcast i8* %31 to i32*
  store i32 %25, i32* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 %1
  %34 = bitcast i8* %33 to i32*
  store i32 %25, i32* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 %1
  %36 = bitcast i8* %35 to i32*
  store i32 %25, i32* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 %1
  %38 = bitcast i8* %37 to i32*
  store i32 %25, i32* %38, align 1
  %39 = getelementptr inbounds i8, i8* %37, i64 %1
  %40 = bitcast i8* %39 to i32*
  store i32 %25, i32* %40, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi16EEEvPvlDv2_xEELi2ELi13108EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast i8* %3 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %11, <16 x i8> zeroinitializer) #11
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %15 = bitcast <2 x i64> %12 to <8 x i16>
  %16 = bitcast <16 x i8> %14 to <8 x i16>
  %17 = add <8 x i16> %16, %15
  %18 = bitcast <2 x i64> %9 to <4 x i32>
  %19 = bitcast <8 x i16> %17 to <4 x i32>
  %20 = add <4 x i32> %18, <i32 10, i32 10, i32 10, i32 10>
  %21 = add <4 x i32> %20, %19
  %22 = lshr <4 x i32> %21, <i32 2, i32 2, i32 2, i32 2>
  %23 = bitcast <4 x i32> %22 to <8 x i16>
  %24 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %23, <8 x i16> <i16 13108, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %25 = bitcast <8 x i16> %24 to <16 x i8>
  %26 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %27 = bitcast <16 x i8> %26 to <4 x i32>
  %28 = extractelement <4 x i32> %27, i32 0
  %29 = bitcast i8* %0 to i32*
  store i32 %28, i32* %29, align 1
  %30 = getelementptr inbounds i8, i8* %0, i64 %1
  %31 = bitcast i8* %30 to i32*
  store i32 %28, i32* %31, align 1
  %32 = getelementptr inbounds i8, i8* %30, i64 %1
  %33 = bitcast i8* %32 to i32*
  store i32 %28, i32* %33, align 1
  %34 = getelementptr inbounds i8, i8* %32, i64 %1
  %35 = bitcast i8* %34 to i32*
  store i32 %28, i32* %35, align 1
  %36 = getelementptr inbounds i8, i8* %34, i64 %1
  %37 = bitcast i8* %36 to i32*
  store i32 %28, i32* %37, align 1
  %38 = getelementptr inbounds i8, i8* %36, i64 %1
  %39 = bitcast i8* %38 to i32*
  store i32 %28, i32* %39, align 1
  %40 = getelementptr inbounds i8, i8* %38, i64 %1
  %41 = bitcast i8* %40 to i32*
  store i32 %28, i32* %41, align 1
  %42 = getelementptr inbounds i8, i8* %40, i64 %1
  %43 = bitcast i8* %42 to i32*
  store i32 %28, i32* %43, align 1
  %44 = getelementptr inbounds i8, i8* %42, i64 %1
  %45 = bitcast i8* %44 to i32*
  store i32 %28, i32* %45, align 1
  %46 = getelementptr inbounds i8, i8* %44, i64 %1
  %47 = bitcast i8* %46 to i32*
  store i32 %28, i32* %47, align 1
  %48 = getelementptr inbounds i8, i8* %46, i64 %1
  %49 = bitcast i8* %48 to i32*
  store i32 %28, i32* %49, align 1
  %50 = getelementptr inbounds i8, i8* %48, i64 %1
  %51 = bitcast i8* %50 to i32*
  store i32 %28, i32* %51, align 1
  %52 = getelementptr inbounds i8, i8* %50, i64 %1
  %53 = bitcast i8* %52 to i32*
  store i32 %28, i32* %53, align 1
  %54 = getelementptr inbounds i8, i8* %52, i64 %1
  %55 = bitcast i8* %54 to i32*
  store i32 %28, i32* %55, align 1
  %56 = getelementptr inbounds i8, i8* %54, i64 %1
  %57 = bitcast i8* %56 to i32*
  store i32 %28, i32* %57, align 1
  %58 = getelementptr inbounds i8, i8* %56, i64 %1
  %59 = bitcast i8* %58 to i32*
  store i32 %28, i32* %59, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi4EEEvPvlDv2_xEELi2ELi21846EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast i8* %3 to i32*
  %11 = load i32, i32* %10, align 1
  %12 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %11, i32 0
  %13 = bitcast <4 x i32> %12 to <16 x i8>
  %14 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %13, <16 x i8> zeroinitializer) #11
  %15 = bitcast <2 x i64> %9 to <4 x i32>
  %16 = bitcast <2 x i64> %14 to <4 x i32>
  %17 = add <4 x i32> %15, <i32 6, i32 6, i32 6, i32 6>
  %18 = add <4 x i32> %17, %16
  %19 = lshr <4 x i32> %18, <i32 2, i32 2, i32 2, i32 2>
  %20 = bitcast <4 x i32> %19 to <8 x i16>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %20, <8 x i16> <i16 21846, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %22 = bitcast <8 x i16> %21 to <16 x i8>
  %23 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %24 = bitcast <16 x i8> %23 to <2 x i64>
  %25 = extractelement <2 x i64> %24, i32 0
  %26 = bitcast i8* %0 to i64*
  store i64 %25, i64* %26, align 1
  %27 = getelementptr inbounds i8, i8* %0, i64 %1
  %28 = bitcast i8* %27 to i64*
  store i64 %25, i64* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 %1
  %30 = bitcast i8* %29 to i64*
  store i64 %25, i64* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 %1
  %32 = bitcast i8* %31 to i64*
  store i64 %25, i64* %32, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi8EEEvPvlDv2_xEELi0ELi0EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast i8* %3 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %13, <16 x i8> zeroinitializer) #11
  %15 = bitcast <2 x i64> %9 to <4 x i32>
  %16 = bitcast <2 x i64> %14 to <4 x i32>
  %17 = add <4 x i32> %15, <i32 8, i32 8, i32 8, i32 8>
  %18 = add <4 x i32> %17, %16
  %19 = lshr <4 x i32> %18, <i32 4, i32 4, i32 4, i32 4>
  %20 = bitcast <4 x i32> %19 to <16 x i8>
  %21 = shufflevector <16 x i8> %20, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %22 = bitcast <16 x i8> %21 to <2 x i64>
  %23 = extractelement <2 x i64> %22, i32 0
  %24 = bitcast i8* %0 to i64*
  store i64 %23, i64* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 %1
  %26 = bitcast i8* %25 to i64*
  store i64 %23, i64* %26, align 1
  %27 = getelementptr inbounds i8, i8* %25, i64 %1
  %28 = bitcast i8* %27 to i64*
  store i64 %23, i64* %28, align 1
  %29 = getelementptr inbounds i8, i8* %27, i64 %1
  %30 = bitcast i8* %29 to i64*
  store i64 %23, i64* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 %1
  %32 = bitcast i8* %31 to i64*
  store i64 %23, i64* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 %1
  %34 = bitcast i8* %33 to i64*
  store i64 %23, i64* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 %1
  %36 = bitcast i8* %35 to i64*
  store i64 %23, i64* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 %1
  %38 = bitcast i8* %37 to i64*
  store i64 %23, i64* %38, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi16EEEvPvlDv2_xEELi3ELi21846EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast i8* %3 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %11, <16 x i8> zeroinitializer) #11
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %15 = bitcast <2 x i64> %12 to <8 x i16>
  %16 = bitcast <16 x i8> %14 to <8 x i16>
  %17 = add <8 x i16> %16, %15
  %18 = bitcast <2 x i64> %9 to <4 x i32>
  %19 = bitcast <8 x i16> %17 to <4 x i32>
  %20 = add <4 x i32> %18, <i32 12, i32 12, i32 12, i32 12>
  %21 = add <4 x i32> %20, %19
  %22 = lshr <4 x i32> %21, <i32 3, i32 3, i32 3, i32 3>
  %23 = bitcast <4 x i32> %22 to <8 x i16>
  %24 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %23, <8 x i16> <i16 21846, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %25 = bitcast <8 x i16> %24 to <16 x i8>
  %26 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %27 = bitcast <16 x i8> %26 to <2 x i64>
  %28 = extractelement <2 x i64> %27, i32 0
  %29 = bitcast i8* %0 to i64*
  store i64 %28, i64* %29, align 1
  %30 = getelementptr inbounds i8, i8* %0, i64 %1
  %31 = bitcast i8* %30 to i64*
  store i64 %28, i64* %31, align 1
  %32 = getelementptr inbounds i8, i8* %30, i64 %1
  %33 = bitcast i8* %32 to i64*
  store i64 %28, i64* %33, align 1
  %34 = getelementptr inbounds i8, i8* %32, i64 %1
  %35 = bitcast i8* %34 to i64*
  store i64 %28, i64* %35, align 1
  %36 = getelementptr inbounds i8, i8* %34, i64 %1
  %37 = bitcast i8* %36 to i64*
  store i64 %28, i64* %37, align 1
  %38 = getelementptr inbounds i8, i8* %36, i64 %1
  %39 = bitcast i8* %38 to i64*
  store i64 %28, i64* %39, align 1
  %40 = getelementptr inbounds i8, i8* %38, i64 %1
  %41 = bitcast i8* %40 to i64*
  store i64 %28, i64* %41, align 1
  %42 = getelementptr inbounds i8, i8* %40, i64 %1
  %43 = bitcast i8* %42 to i64*
  store i64 %28, i64* %43, align 1
  %44 = getelementptr inbounds i8, i8* %42, i64 %1
  %45 = bitcast i8* %44 to i64*
  store i64 %28, i64* %45, align 1
  %46 = getelementptr inbounds i8, i8* %44, i64 %1
  %47 = bitcast i8* %46 to i64*
  store i64 %28, i64* %47, align 1
  %48 = getelementptr inbounds i8, i8* %46, i64 %1
  %49 = bitcast i8* %48 to i64*
  store i64 %28, i64* %49, align 1
  %50 = getelementptr inbounds i8, i8* %48, i64 %1
  %51 = bitcast i8* %50 to i64*
  store i64 %28, i64* %51, align 1
  %52 = getelementptr inbounds i8, i8* %50, i64 %1
  %53 = bitcast i8* %52 to i64*
  store i64 %28, i64* %53, align 1
  %54 = getelementptr inbounds i8, i8* %52, i64 %1
  %55 = bitcast i8* %54 to i64*
  store i64 %28, i64* %55, align 1
  %56 = getelementptr inbounds i8, i8* %54, i64 %1
  %57 = bitcast i8* %56 to i64*
  store i64 %28, i64* %57, align 1
  %58 = getelementptr inbounds i8, i8* %56, i64 %1
  %59 = bitcast i8* %58 to i64*
  store i64 %28, i64* %59, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi3ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_113DcSum8_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_17DcStore8xH_SSE4_1ILi32EEEvPvlDv2_xEELi3ELi13108EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %8, <16 x i8> zeroinitializer) #11
  %10 = bitcast i8* %3 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = getelementptr inbounds i8, i8* %3, i64 16
  %13 = bitcast i8* %12 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %11, <16 x i8> zeroinitializer) #11
  %16 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %14, <16 x i8> zeroinitializer) #11
  %17 = bitcast <2 x i64> %15 to <8 x i16>
  %18 = bitcast <2 x i64> %16 to <8 x i16>
  %19 = add <8 x i16> %18, %17
  %20 = bitcast <8 x i16> %19 to <16 x i8>
  %21 = shufflevector <16 x i8> %20, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %22 = bitcast <16 x i8> %21 to <8 x i16>
  %23 = add <8 x i16> %19, %22
  %24 = bitcast <2 x i64> %9 to <4 x i32>
  %25 = bitcast <8 x i16> %23 to <4 x i32>
  %26 = add <4 x i32> %24, <i32 20, i32 20, i32 20, i32 20>
  %27 = add <4 x i32> %26, %25
  %28 = lshr <4 x i32> %27, <i32 3, i32 3, i32 3, i32 3>
  %29 = bitcast <4 x i32> %28 to <8 x i16>
  %30 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %29, <8 x i16> <i16 13108, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %31 = bitcast <8 x i16> %30 to <16 x i8>
  %32 = shufflevector <16 x i8> %31, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %33 = bitcast <16 x i8> %32 to <2 x i64>
  %34 = extractelement <2 x i64> %33, i32 0
  %35 = bitcast i8* %0 to i64*
  store i64 %34, i64* %35, align 1
  %36 = getelementptr inbounds i8, i8* %0, i64 %1
  %37 = bitcast i8* %36 to i64*
  store i64 %34, i64* %37, align 1
  %38 = getelementptr inbounds i8, i8* %36, i64 %1
  %39 = bitcast i8* %38 to i64*
  store i64 %34, i64* %39, align 1
  %40 = getelementptr inbounds i8, i8* %38, i64 %1
  %41 = bitcast i8* %40 to i64*
  store i64 %34, i64* %41, align 1
  %42 = getelementptr inbounds i8, i8* %40, i64 %1
  %43 = bitcast i8* %42 to i64*
  store i64 %34, i64* %43, align 1
  %44 = getelementptr inbounds i8, i8* %42, i64 %1
  %45 = bitcast i8* %44 to i64*
  store i64 %34, i64* %45, align 1
  %46 = getelementptr inbounds i8, i8* %44, i64 %1
  %47 = bitcast i8* %46 to i64*
  store i64 %34, i64* %47, align 1
  %48 = getelementptr inbounds i8, i8* %46, i64 %1
  %49 = bitcast i8* %48 to i64*
  store i64 %34, i64* %49, align 1
  %50 = getelementptr inbounds i8, i8* %48, i64 %1
  %51 = bitcast i8* %50 to i64*
  store i64 %34, i64* %51, align 1
  %52 = getelementptr inbounds i8, i8* %50, i64 %1
  %53 = bitcast i8* %52 to i64*
  store i64 %34, i64* %53, align 1
  %54 = getelementptr inbounds i8, i8* %52, i64 %1
  %55 = bitcast i8* %54 to i64*
  store i64 %34, i64* %55, align 1
  %56 = getelementptr inbounds i8, i8* %54, i64 %1
  %57 = bitcast i8* %56 to i64*
  store i64 %34, i64* %57, align 1
  %58 = getelementptr inbounds i8, i8* %56, i64 %1
  %59 = bitcast i8* %58 to i64*
  store i64 %34, i64* %59, align 1
  %60 = getelementptr inbounds i8, i8* %58, i64 %1
  %61 = bitcast i8* %60 to i64*
  store i64 %34, i64* %61, align 1
  %62 = getelementptr inbounds i8, i8* %60, i64 %1
  %63 = bitcast i8* %62 to i64*
  store i64 %34, i64* %63, align 1
  %64 = getelementptr inbounds i8, i8* %62, i64 %1
  %65 = bitcast i8* %64 to i64*
  store i64 %34, i64* %65, align 1
  %66 = getelementptr inbounds i8, i8* %64, i64 %1
  %67 = bitcast i8* %66 to i64*
  store i64 %34, i64* %67, align 1
  %68 = getelementptr inbounds i8, i8* %66, i64 %1
  %69 = bitcast i8* %68 to i64*
  store i64 %34, i64* %69, align 1
  %70 = getelementptr inbounds i8, i8* %68, i64 %1
  %71 = bitcast i8* %70 to i64*
  store i64 %34, i64* %71, align 1
  %72 = getelementptr inbounds i8, i8* %70, i64 %1
  %73 = bitcast i8* %72 to i64*
  store i64 %34, i64* %73, align 1
  %74 = getelementptr inbounds i8, i8* %72, i64 %1
  %75 = bitcast i8* %74 to i64*
  store i64 %34, i64* %75, align 1
  %76 = getelementptr inbounds i8, i8* %74, i64 %1
  %77 = bitcast i8* %76 to i64*
  store i64 %34, i64* %77, align 1
  %78 = getelementptr inbounds i8, i8* %76, i64 %1
  %79 = bitcast i8* %78 to i64*
  store i64 %34, i64* %79, align 1
  %80 = getelementptr inbounds i8, i8* %78, i64 %1
  %81 = bitcast i8* %80 to i64*
  store i64 %34, i64* %81, align 1
  %82 = getelementptr inbounds i8, i8* %80, i64 %1
  %83 = bitcast i8* %82 to i64*
  store i64 %34, i64* %83, align 1
  %84 = getelementptr inbounds i8, i8* %82, i64 %1
  %85 = bitcast i8* %84 to i64*
  store i64 %34, i64* %85, align 1
  %86 = getelementptr inbounds i8, i8* %84, i64 %1
  %87 = bitcast i8* %86 to i64*
  store i64 %34, i64* %87, align 1
  %88 = getelementptr inbounds i8, i8* %86, i64 %1
  %89 = bitcast i8* %88 to i64*
  store i64 %34, i64* %89, align 1
  %90 = getelementptr inbounds i8, i8* %88, i64 %1
  %91 = bitcast i8* %90 to i64*
  store i64 %34, i64* %91, align 1
  %92 = getelementptr inbounds i8, i8* %90, i64 %1
  %93 = bitcast i8* %92 to i64*
  store i64 %34, i64* %93, align 1
  %94 = getelementptr inbounds i8, i8* %92, i64 %1
  %95 = bitcast i8* %94 to i64*
  store i64 %34, i64* %95, align 1
  %96 = getelementptr inbounds i8, i8* %94, i64 %1
  %97 = bitcast i8* %96 to i64*
  store i64 %34, i64* %97, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi2EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi4EEEvPvlDv2_xEELi2ELi13108EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast i8* %3 to i32*
  %14 = load i32, i32* %13, align 1
  %15 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %14, i32 0
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %16, <16 x i8> zeroinitializer) #11
  %18 = bitcast <8 x i16> %12 to <4 x i32>
  %19 = bitcast <2 x i64> %17 to <4 x i32>
  %20 = add <4 x i32> %19, <i32 10, i32 10, i32 10, i32 10>
  %21 = add <4 x i32> %20, %18
  %22 = lshr <4 x i32> %21, <i32 2, i32 2, i32 2, i32 2>
  %23 = bitcast <4 x i32> %22 to <8 x i16>
  %24 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %23, <8 x i16> <i16 13108, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %25 = bitcast <8 x i16> %24 to <16 x i8>
  %26 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> zeroinitializer
  %27 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %26, <16 x i8>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 %1
  %29 = bitcast i8* %28 to <16 x i8>*
  store <16 x i8> %26, <16 x i8>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %28, i64 %1
  %31 = bitcast i8* %30 to <16 x i8>*
  store <16 x i8> %26, <16 x i8>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %30, i64 %1
  %33 = bitcast i8* %32 to <16 x i8>*
  store <16 x i8> %26, <16 x i8>* %33, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi8EEEvPvlDv2_xEELi3ELi21846EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast i8* %3 to i64*
  %14 = load i64, i64* %13, align 1
  %15 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %14, i32 0
  %16 = bitcast <2 x i64> %15 to <16 x i8>
  %17 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %16, <16 x i8> zeroinitializer) #11
  %18 = bitcast <8 x i16> %12 to <4 x i32>
  %19 = bitcast <2 x i64> %17 to <4 x i32>
  %20 = add <4 x i32> %19, <i32 12, i32 12, i32 12, i32 12>
  %21 = add <4 x i32> %20, %18
  %22 = lshr <4 x i32> %21, <i32 3, i32 3, i32 3, i32 3>
  %23 = bitcast <4 x i32> %22 to <8 x i16>
  %24 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %23, <8 x i16> <i16 21846, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %25 = bitcast <8 x i16> %24 to <16 x i8>
  %26 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> zeroinitializer
  %27 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %26, <16 x i8>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 %1
  %29 = bitcast i8* %28 to <16 x i8>*
  store <16 x i8> %26, <16 x i8>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %28, i64 %1
  %31 = bitcast i8* %30 to <16 x i8>*
  store <16 x i8> %26, <16 x i8>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %30, i64 %1
  %33 = bitcast i8* %32 to <16 x i8>*
  store <16 x i8> %26, <16 x i8>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %32, i64 %1
  %35 = bitcast i8* %34 to <16 x i8>*
  store <16 x i8> %26, <16 x i8>* %35, align 1
  %36 = getelementptr inbounds i8, i8* %34, i64 %1
  %37 = bitcast i8* %36 to <16 x i8>*
  store <16 x i8> %26, <16 x i8>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %36, i64 %1
  %39 = bitcast i8* %38 to <16 x i8>*
  store <16 x i8> %26, <16 x i8>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %38, i64 %1
  %41 = bitcast i8* %40 to <16 x i8>*
  store <16 x i8> %26, <16 x i8>* %41, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi16EEEvPvlDv2_xEELi0ELi0EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast i8* %3 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %14, <16 x i8> zeroinitializer) #11
  %16 = bitcast <2 x i64> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %18 = bitcast <2 x i64> %15 to <8 x i16>
  %19 = bitcast <16 x i8> %17 to <8 x i16>
  %20 = add <8 x i16> %19, %18
  %21 = bitcast <8 x i16> %12 to <4 x i32>
  %22 = bitcast <8 x i16> %20 to <4 x i32>
  %23 = add <4 x i32> %21, <i32 16, i32 16, i32 16, i32 16>
  %24 = add <4 x i32> %23, %22
  %25 = lshr <4 x i32> %24, <i32 5, i32 5, i32 5, i32 5>
  %26 = bitcast <4 x i32> %25 to <16 x i8>
  %27 = shufflevector <16 x i8> %26, <16 x i8> undef, <16 x i32> zeroinitializer
  %28 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %0, i64 %1
  %30 = bitcast i8* %29 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %29, i64 %1
  %32 = bitcast i8* %31 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 %1
  %34 = bitcast i8* %33 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 %1
  %36 = bitcast i8* %35 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %35, i64 %1
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %37, i64 %1
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 %1
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %41, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 %1
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %45, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 %1
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %49, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 %1
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %53, i64 %1
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 %1
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %27, <16 x i8>* %58, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi32EEEvPvlDv2_xEELi4ELi21846EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast i8* %3 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = getelementptr inbounds i8, i8* %3, i64 16
  %16 = bitcast i8* %15 to <16 x i8>*
  %17 = load <16 x i8>, <16 x i8>* %16, align 1
  %18 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %14, <16 x i8> zeroinitializer) #11
  %19 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %17, <16 x i8> zeroinitializer) #11
  %20 = bitcast <2 x i64> %18 to <8 x i16>
  %21 = bitcast <2 x i64> %19 to <8 x i16>
  %22 = add <8 x i16> %21, %20
  %23 = bitcast <8 x i16> %22 to <16 x i8>
  %24 = shufflevector <16 x i8> %23, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %25 = bitcast <16 x i8> %24 to <8 x i16>
  %26 = add <8 x i16> %22, %25
  %27 = bitcast <8 x i16> %12 to <4 x i32>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = add <4 x i32> %27, <i32 24, i32 24, i32 24, i32 24>
  %30 = add <4 x i32> %29, %28
  %31 = lshr <4 x i32> %30, <i32 4, i32 4, i32 4, i32 4>
  %32 = bitcast <4 x i32> %31 to <8 x i16>
  %33 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %32, <8 x i16> <i16 21846, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %34 = bitcast <8 x i16> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> zeroinitializer
  %36 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %0, i64 %1
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %37, i64 %1
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 %1
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %41, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 %1
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %45, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 %1
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %49, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 %1
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %53, i64 %1
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 %1
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %57, i64 %1
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %59, i64 %1
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %61, i64 %1
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %63, i64 %1
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %65, i64 %1
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %67, i64 %1
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %69, i64 %1
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %71, i64 %1
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %73, i64 %1
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %75, i64 %1
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %77, i64 %1
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %79, i64 %1
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %81, i64 %1
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %83, i64 %1
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %85, i64 %1
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %87, i64 %1
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %89, i64 %1
  %92 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %91, i64 %1
  %94 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %93, i64 %1
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %95, i64 %1
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %98, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi4ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum16_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore16xH_SSE4_1ILi64EEEvPvlDv2_xEELi4ELi13108EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %10 = bitcast <2 x i64> %7 to <8 x i16>
  %11 = bitcast <16 x i8> %9 to <8 x i16>
  %12 = add <8 x i16> %11, %10
  %13 = bitcast i8* %3 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = getelementptr inbounds i8, i8* %3, i64 16
  %16 = bitcast i8* %15 to <16 x i8>*
  %17 = load <16 x i8>, <16 x i8>* %16, align 1
  %18 = getelementptr inbounds i8, i8* %3, i64 32
  %19 = bitcast i8* %18 to <16 x i8>*
  %20 = load <16 x i8>, <16 x i8>* %19, align 1
  %21 = getelementptr inbounds i8, i8* %3, i64 48
  %22 = bitcast i8* %21 to <16 x i8>*
  %23 = load <16 x i8>, <16 x i8>* %22, align 1
  %24 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %14, <16 x i8> zeroinitializer) #11
  %25 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %17, <16 x i8> zeroinitializer) #11
  %26 = bitcast <2 x i64> %24 to <8 x i16>
  %27 = bitcast <2 x i64> %25 to <8 x i16>
  %28 = add <8 x i16> %27, %26
  %29 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %20, <16 x i8> zeroinitializer) #11
  %30 = bitcast <2 x i64> %29 to <8 x i16>
  %31 = add <8 x i16> %28, %30
  %32 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %23, <16 x i8> zeroinitializer) #11
  %33 = bitcast <2 x i64> %32 to <8 x i16>
  %34 = add <8 x i16> %31, %33
  %35 = bitcast <8 x i16> %34 to <16 x i8>
  %36 = shufflevector <16 x i8> %35, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %37 = bitcast <16 x i8> %36 to <8 x i16>
  %38 = add <8 x i16> %34, %37
  %39 = bitcast <8 x i16> %12 to <4 x i32>
  %40 = bitcast <8 x i16> %38 to <4 x i32>
  %41 = add <4 x i32> %39, <i32 40, i32 40, i32 40, i32 40>
  %42 = add <4 x i32> %41, %40
  %43 = lshr <4 x i32> %42, <i32 4, i32 4, i32 4, i32 4>
  %44 = bitcast <4 x i32> %43 to <8 x i16>
  %45 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %44, <8 x i16> <i16 13108, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %46 = bitcast <8 x i16> %45 to <16 x i8>
  %47 = shufflevector <16 x i8> %46, <16 x i8> undef, <16 x i32> zeroinitializer
  %48 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %0, i64 %1
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %49, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 %1
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %53, i64 %1
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 %1
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %57, i64 %1
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %59, i64 %1
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %61, i64 %1
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %63, i64 %1
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %65, i64 %1
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %67, i64 %1
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %69, i64 %1
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %71, i64 %1
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %73, i64 %1
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %75, i64 %1
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %77, i64 %1
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %79, i64 %1
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %81, i64 %1
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %83, i64 %1
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %85, i64 %1
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %87, i64 %1
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %89, i64 %1
  %92 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %91, i64 %1
  %94 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %93, i64 %1
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %95, i64 %1
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %97, i64 %1
  %100 = bitcast i8* %99 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %99, i64 %1
  %102 = bitcast i8* %101 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %101, i64 %1
  %104 = bitcast i8* %103 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %103, i64 %1
  %106 = bitcast i8* %105 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %105, i64 %1
  %108 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %107, i64 %1
  %110 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %109, i64 %1
  %112 = bitcast i8* %111 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %111, i64 %1
  %114 = bitcast i8* %113 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %113, i64 %1
  %116 = bitcast i8* %115 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %115, i64 %1
  %118 = bitcast i8* %117 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %117, i64 %1
  %120 = bitcast i8* %119 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %119, i64 %1
  %122 = bitcast i8* %121 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %121, i64 %1
  %124 = bitcast i8* %123 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %124, align 1
  %125 = getelementptr inbounds i8, i8* %123, i64 %1
  %126 = bitcast i8* %125 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %125, i64 %1
  %128 = bitcast i8* %127 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %128, align 1
  %129 = getelementptr inbounds i8, i8* %127, i64 %1
  %130 = bitcast i8* %129 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %130, align 1
  %131 = getelementptr inbounds i8, i8* %129, i64 %1
  %132 = bitcast i8* %131 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %132, align 1
  %133 = getelementptr inbounds i8, i8* %131, i64 %1
  %134 = bitcast i8* %133 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %133, i64 %1
  %136 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %135, i64 %1
  %138 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %137, i64 %1
  %140 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %139, i64 %1
  %142 = bitcast i8* %141 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %142, align 1
  %143 = getelementptr inbounds i8, i8* %141, i64 %1
  %144 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %144, align 1
  %145 = getelementptr inbounds i8, i8* %143, i64 %1
  %146 = bitcast i8* %145 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %145, i64 %1
  %148 = bitcast i8* %147 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %147, i64 %1
  %150 = bitcast i8* %149 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %150, align 1
  %151 = getelementptr inbounds i8, i8* %149, i64 %1
  %152 = bitcast i8* %151 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %152, align 1
  %153 = getelementptr inbounds i8, i8* %151, i64 %1
  %154 = bitcast i8* %153 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %154, align 1
  %155 = getelementptr inbounds i8, i8* %153, i64 %1
  %156 = bitcast i8* %155 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %156, align 1
  %157 = getelementptr inbounds i8, i8* %155, i64 %1
  %158 = bitcast i8* %157 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %157, i64 %1
  %160 = bitcast i8* %159 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %160, align 1
  %161 = getelementptr inbounds i8, i8* %159, i64 %1
  %162 = bitcast i8* %161 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %162, align 1
  %163 = getelementptr inbounds i8, i8* %161, i64 %1
  %164 = bitcast i8* %163 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %164, align 1
  %165 = getelementptr inbounds i8, i8* %163, i64 %1
  %166 = bitcast i8* %165 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %166, align 1
  %167 = getelementptr inbounds i8, i8* %165, i64 %1
  %168 = bitcast i8* %167 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %168, align 1
  %169 = getelementptr inbounds i8, i8* %167, i64 %1
  %170 = bitcast i8* %169 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %170, align 1
  %171 = getelementptr inbounds i8, i8* %169, i64 %1
  %172 = bitcast i8* %171 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %172, align 1
  %173 = getelementptr inbounds i8, i8* %171, i64 %1
  %174 = bitcast i8* %173 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %174, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi3EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_13DcSum8_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi8EEEvPvlDv2_xEELi3ELi13108EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %11 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %12 = bitcast <2 x i64> %10 to <8 x i16>
  %13 = bitcast <2 x i64> %11 to <8 x i16>
  %14 = add <8 x i16> %13, %12
  %15 = bitcast <8 x i16> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %17 = bitcast <16 x i8> %16 to <8 x i16>
  %18 = add <8 x i16> %14, %17
  %19 = bitcast i8* %3 to i64*
  %20 = load i64, i64* %19, align 1
  %21 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %20, i32 0
  %22 = bitcast <2 x i64> %21 to <16 x i8>
  %23 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %22, <16 x i8> zeroinitializer) #11
  %24 = bitcast <8 x i16> %18 to <4 x i32>
  %25 = bitcast <2 x i64> %23 to <4 x i32>
  %26 = add <4 x i32> %25, <i32 20, i32 20, i32 20, i32 20>
  %27 = add <4 x i32> %26, %24
  %28 = lshr <4 x i32> %27, <i32 3, i32 3, i32 3, i32 3>
  %29 = bitcast <4 x i32> %28 to <8 x i16>
  %30 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %29, <8 x i16> <i16 13108, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %31 = bitcast <8 x i16> %30 to <16 x i8>
  %32 = shufflevector <16 x i8> %31, <16 x i8> undef, <16 x i32> zeroinitializer
  %33 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %0, i64 16
  %35 = bitcast i8* %34 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %35, align 1
  %36 = getelementptr inbounds i8, i8* %0, i64 %1
  %37 = bitcast i8* %36 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %36, i64 16
  %39 = bitcast i8* %38 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %36, i64 %1
  %41 = bitcast i8* %40 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %40, i64 16
  %43 = bitcast i8* %42 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %40, i64 %1
  %45 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %44, i64 16
  %47 = bitcast i8* %46 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %44, i64 %1
  %49 = bitcast i8* %48 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %48, i64 16
  %51 = bitcast i8* %50 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %48, i64 %1
  %53 = bitcast i8* %52 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %52, i64 16
  %55 = bitcast i8* %54 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %52, i64 %1
  %57 = bitcast i8* %56 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %56, i64 16
  %59 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %56, i64 %1
  %61 = bitcast i8* %60 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %60, i64 16
  %63 = bitcast i8* %62 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %63, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi16EEEvPvlDv2_xEELi4ELi21846EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %11 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %12 = bitcast <2 x i64> %10 to <8 x i16>
  %13 = bitcast <2 x i64> %11 to <8 x i16>
  %14 = add <8 x i16> %13, %12
  %15 = bitcast <8 x i16> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %17 = bitcast <16 x i8> %16 to <8 x i16>
  %18 = add <8 x i16> %14, %17
  %19 = bitcast i8* %3 to <16 x i8>*
  %20 = load <16 x i8>, <16 x i8>* %19, align 1
  %21 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %20, <16 x i8> zeroinitializer) #11
  %22 = bitcast <2 x i64> %21 to <16 x i8>
  %23 = shufflevector <16 x i8> %22, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %24 = bitcast <2 x i64> %21 to <8 x i16>
  %25 = bitcast <16 x i8> %23 to <8 x i16>
  %26 = add <8 x i16> %25, %24
  %27 = bitcast <8 x i16> %18 to <4 x i32>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = add <4 x i32> %27, <i32 24, i32 24, i32 24, i32 24>
  %30 = add <4 x i32> %29, %28
  %31 = lshr <4 x i32> %30, <i32 4, i32 4, i32 4, i32 4>
  %32 = bitcast <4 x i32> %31 to <8 x i16>
  %33 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %32, <8 x i16> <i16 21846, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %34 = bitcast <8 x i16> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> zeroinitializer
  %36 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %0, i64 16
  %38 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %0, i64 %1
  %40 = bitcast i8* %39 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %39, i64 16
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %39, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 16
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %43, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 16
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %47, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 16
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %51, i64 %1
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 16
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %55, i64 %1
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %59, i64 16
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %59, i64 %1
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %63, i64 16
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %63, i64 %1
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %67, i64 16
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %67, i64 %1
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %71, i64 16
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %71, i64 %1
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %75, i64 16
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %75, i64 %1
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %79, i64 16
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %79, i64 %1
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %83, i64 16
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %83, i64 %1
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %87, i64 16
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %87, i64 %1
  %92 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %91, i64 16
  %94 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %91, i64 %1
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %95, i64 16
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %35, <16 x i8>* %98, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi32EEEvPvlDv2_xEELi0ELi0EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %11 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %12 = bitcast <2 x i64> %10 to <8 x i16>
  %13 = bitcast <2 x i64> %11 to <8 x i16>
  %14 = add <8 x i16> %13, %12
  %15 = bitcast <8 x i16> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %17 = bitcast <16 x i8> %16 to <8 x i16>
  %18 = add <8 x i16> %14, %17
  %19 = bitcast i8* %3 to <16 x i8>*
  %20 = load <16 x i8>, <16 x i8>* %19, align 1
  %21 = getelementptr inbounds i8, i8* %3, i64 16
  %22 = bitcast i8* %21 to <16 x i8>*
  %23 = load <16 x i8>, <16 x i8>* %22, align 1
  %24 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %20, <16 x i8> zeroinitializer) #11
  %25 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %23, <16 x i8> zeroinitializer) #11
  %26 = bitcast <2 x i64> %24 to <8 x i16>
  %27 = bitcast <2 x i64> %25 to <8 x i16>
  %28 = add <8 x i16> %27, %26
  %29 = bitcast <8 x i16> %28 to <16 x i8>
  %30 = shufflevector <16 x i8> %29, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %31 = bitcast <16 x i8> %30 to <8 x i16>
  %32 = add <8 x i16> %28, %31
  %33 = bitcast <8 x i16> %18 to <4 x i32>
  %34 = bitcast <8 x i16> %32 to <4 x i32>
  %35 = add <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %36 = add <4 x i32> %35, %34
  %37 = lshr <4 x i32> %36, <i32 6, i32 6, i32 6, i32 6>
  %38 = bitcast <4 x i32> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> zeroinitializer
  %40 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %0, i64 16
  %42 = bitcast i8* %41 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %0, i64 %1
  %44 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %43, i64 16
  %46 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %43, i64 %1
  %48 = bitcast i8* %47 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %47, i64 16
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %47, i64 %1
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %51, i64 16
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %51, i64 %1
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 16
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %55, i64 %1
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %59, i64 16
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %59, i64 %1
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %63, i64 16
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %63, i64 %1
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %67, i64 16
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %67, i64 %1
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %71, i64 16
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %71, i64 %1
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %75, i64 16
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %75, i64 %1
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %79, i64 16
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %79, i64 %1
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %83, i64 16
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %83, i64 %1
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %87, i64 16
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %87, i64 %1
  %92 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %91, i64 16
  %94 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %91, i64 %1
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %95, i64 16
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %95, i64 %1
  %100 = bitcast i8* %99 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %99, i64 16
  %102 = bitcast i8* %101 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %99, i64 %1
  %104 = bitcast i8* %103 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %103, i64 16
  %106 = bitcast i8* %105 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %103, i64 %1
  %108 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %107, i64 16
  %110 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %107, i64 %1
  %112 = bitcast i8* %111 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %111, i64 16
  %114 = bitcast i8* %113 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %111, i64 %1
  %116 = bitcast i8* %115 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %115, i64 16
  %118 = bitcast i8* %117 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %115, i64 %1
  %120 = bitcast i8* %119 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %119, i64 16
  %122 = bitcast i8* %121 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %119, i64 %1
  %124 = bitcast i8* %123 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %124, align 1
  %125 = getelementptr inbounds i8, i8* %123, i64 16
  %126 = bitcast i8* %125 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %123, i64 %1
  %128 = bitcast i8* %127 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %128, align 1
  %129 = getelementptr inbounds i8, i8* %127, i64 16
  %130 = bitcast i8* %129 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %130, align 1
  %131 = getelementptr inbounds i8, i8* %127, i64 %1
  %132 = bitcast i8* %131 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %132, align 1
  %133 = getelementptr inbounds i8, i8* %131, i64 16
  %134 = bitcast i8* %133 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %131, i64 %1
  %136 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %135, i64 16
  %138 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %135, i64 %1
  %140 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %139, i64 16
  %142 = bitcast i8* %141 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %142, align 1
  %143 = getelementptr inbounds i8, i8* %139, i64 %1
  %144 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %144, align 1
  %145 = getelementptr inbounds i8, i8* %143, i64 16
  %146 = bitcast i8* %145 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %143, i64 %1
  %148 = bitcast i8* %147 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %147, i64 16
  %150 = bitcast i8* %149 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %150, align 1
  %151 = getelementptr inbounds i8, i8* %147, i64 %1
  %152 = bitcast i8* %151 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %152, align 1
  %153 = getelementptr inbounds i8, i8* %151, i64 16
  %154 = bitcast i8* %153 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %154, align 1
  %155 = getelementptr inbounds i8, i8* %151, i64 %1
  %156 = bitcast i8* %155 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %156, align 1
  %157 = getelementptr inbounds i8, i8* %155, i64 16
  %158 = bitcast i8* %157 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %155, i64 %1
  %160 = bitcast i8* %159 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %160, align 1
  %161 = getelementptr inbounds i8, i8* %159, i64 16
  %162 = bitcast i8* %161 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %162, align 1
  %163 = getelementptr inbounds i8, i8* %159, i64 %1
  %164 = bitcast i8* %163 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %164, align 1
  %165 = getelementptr inbounds i8, i8* %163, i64 16
  %166 = bitcast i8* %165 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %166, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi5ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum32_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore32xH_SSE4_1ILi64EEEvPvlDv2_xEELi5ELi21846EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %11 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %12 = bitcast <2 x i64> %10 to <8 x i16>
  %13 = bitcast <2 x i64> %11 to <8 x i16>
  %14 = add <8 x i16> %13, %12
  %15 = bitcast <8 x i16> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %17 = bitcast <16 x i8> %16 to <8 x i16>
  %18 = add <8 x i16> %14, %17
  %19 = bitcast i8* %3 to <16 x i8>*
  %20 = load <16 x i8>, <16 x i8>* %19, align 1
  %21 = getelementptr inbounds i8, i8* %3, i64 16
  %22 = bitcast i8* %21 to <16 x i8>*
  %23 = load <16 x i8>, <16 x i8>* %22, align 1
  %24 = getelementptr inbounds i8, i8* %3, i64 32
  %25 = bitcast i8* %24 to <16 x i8>*
  %26 = load <16 x i8>, <16 x i8>* %25, align 1
  %27 = getelementptr inbounds i8, i8* %3, i64 48
  %28 = bitcast i8* %27 to <16 x i8>*
  %29 = load <16 x i8>, <16 x i8>* %28, align 1
  %30 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %20, <16 x i8> zeroinitializer) #11
  %31 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %23, <16 x i8> zeroinitializer) #11
  %32 = bitcast <2 x i64> %30 to <8 x i16>
  %33 = bitcast <2 x i64> %31 to <8 x i16>
  %34 = add <8 x i16> %33, %32
  %35 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %26, <16 x i8> zeroinitializer) #11
  %36 = bitcast <2 x i64> %35 to <8 x i16>
  %37 = add <8 x i16> %34, %36
  %38 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %29, <16 x i8> zeroinitializer) #11
  %39 = bitcast <2 x i64> %38 to <8 x i16>
  %40 = add <8 x i16> %37, %39
  %41 = bitcast <8 x i16> %40 to <16 x i8>
  %42 = shufflevector <16 x i8> %41, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %43 = bitcast <16 x i8> %42 to <8 x i16>
  %44 = add <8 x i16> %40, %43
  %45 = bitcast <8 x i16> %18 to <4 x i32>
  %46 = bitcast <8 x i16> %44 to <4 x i32>
  %47 = add <4 x i32> %45, <i32 48, i32 48, i32 48, i32 48>
  %48 = add <4 x i32> %47, %46
  %49 = lshr <4 x i32> %48, <i32 5, i32 5, i32 5, i32 5>
  %50 = bitcast <4 x i32> %49 to <8 x i16>
  %51 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %50, <8 x i16> <i16 21846, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %52 = bitcast <8 x i16> %51 to <16 x i8>
  %53 = shufflevector <16 x i8> %52, <16 x i8> undef, <16 x i32> zeroinitializer
  br label %54

54:                                               ; preds = %54, %4
  %55 = phi i32 [ 63, %4 ], [ %85, %54 ]
  %56 = phi i8* [ %0, %4 ], [ %84, %54 ]
  %57 = bitcast i8* %56 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %56, i64 16
  %59 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %56, i64 %1
  %61 = bitcast i8* %60 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %60, i64 16
  %63 = bitcast i8* %62 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %60, i64 %1
  %65 = bitcast i8* %64 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %65, align 1
  %66 = getelementptr inbounds i8, i8* %64, i64 16
  %67 = bitcast i8* %66 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %67, align 1
  %68 = getelementptr inbounds i8, i8* %64, i64 %1
  %69 = bitcast i8* %68 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %69, align 1
  %70 = getelementptr inbounds i8, i8* %68, i64 16
  %71 = bitcast i8* %70 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %71, align 1
  %72 = getelementptr inbounds i8, i8* %68, i64 %1
  %73 = bitcast i8* %72 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %72, i64 16
  %75 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %72, i64 %1
  %77 = bitcast i8* %76 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %76, i64 16
  %79 = bitcast i8* %78 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %76, i64 %1
  %81 = bitcast i8* %80 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %80, i64 16
  %83 = bitcast i8* %82 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %80, i64 %1
  %85 = add nsw i32 %55, -7
  %86 = icmp eq i32 %85, 0
  br i1 %86, label %87, label %54

87:                                               ; preds = %54
  %88 = bitcast i8* %84 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %84, i64 16
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %90, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi4EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum16_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi16EEEvPvlDv2_xEELi4ELi13108EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = getelementptr inbounds i8, i8* %2, i64 32
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = getelementptr inbounds i8, i8* %2, i64 48
  %14 = bitcast i8* %13 to <16 x i8>*
  %15 = load <16 x i8>, <16 x i8>* %14, align 1
  %16 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %17 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %18 = bitcast <2 x i64> %16 to <8 x i16>
  %19 = bitcast <2 x i64> %17 to <8 x i16>
  %20 = add <8 x i16> %19, %18
  %21 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %12, <16 x i8> zeroinitializer) #11
  %22 = bitcast <2 x i64> %21 to <8 x i16>
  %23 = add <8 x i16> %20, %22
  %24 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %15, <16 x i8> zeroinitializer) #11
  %25 = bitcast <2 x i64> %24 to <8 x i16>
  %26 = add <8 x i16> %23, %25
  %27 = bitcast <8 x i16> %26 to <16 x i8>
  %28 = shufflevector <16 x i8> %27, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %29 = bitcast <16 x i8> %28 to <8 x i16>
  %30 = add <8 x i16> %26, %29
  %31 = bitcast i8* %3 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %32, <16 x i8> zeroinitializer) #11
  %34 = bitcast <2 x i64> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %36 = bitcast <2 x i64> %33 to <8 x i16>
  %37 = bitcast <16 x i8> %35 to <8 x i16>
  %38 = add <8 x i16> %37, %36
  %39 = bitcast <8 x i16> %30 to <4 x i32>
  %40 = bitcast <8 x i16> %38 to <4 x i32>
  %41 = add <4 x i32> %39, <i32 40, i32 40, i32 40, i32 40>
  %42 = add <4 x i32> %41, %40
  %43 = lshr <4 x i32> %42, <i32 4, i32 4, i32 4, i32 4>
  %44 = bitcast <4 x i32> %43 to <8 x i16>
  %45 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %44, <8 x i16> <i16 13108, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %46 = bitcast <8 x i16> %45 to <16 x i8>
  %47 = shufflevector <16 x i8> %46, <16 x i8> undef, <16 x i32> zeroinitializer
  %48 = bitcast i8* %0 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %0, i64 16
  %50 = bitcast i8* %49 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %0, i64 32
  %52 = bitcast i8* %51 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %0, i64 48
  %54 = bitcast i8* %53 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %0, i64 %1
  %56 = bitcast i8* %55 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %55, i64 16
  %58 = bitcast i8* %57 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %55, i64 32
  %60 = bitcast i8* %59 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %55, i64 48
  %62 = bitcast i8* %61 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %55, i64 %1
  %64 = bitcast i8* %63 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %63, i64 16
  %66 = bitcast i8* %65 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %63, i64 32
  %68 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %63, i64 48
  %70 = bitcast i8* %69 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %63, i64 %1
  %72 = bitcast i8* %71 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %71, i64 16
  %74 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %71, i64 32
  %76 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %71, i64 48
  %78 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %71, i64 %1
  %80 = bitcast i8* %79 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %79, i64 16
  %82 = bitcast i8* %81 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %79, i64 32
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %79, i64 48
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %79, i64 %1
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %87, i64 16
  %90 = bitcast i8* %89 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %87, i64 32
  %92 = bitcast i8* %91 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %87, i64 48
  %94 = bitcast i8* %93 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %87, i64 %1
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %95, i64 16
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %95, i64 32
  %100 = bitcast i8* %99 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %95, i64 48
  %102 = bitcast i8* %101 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %95, i64 %1
  %104 = bitcast i8* %103 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %103, i64 16
  %106 = bitcast i8* %105 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %103, i64 32
  %108 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %103, i64 48
  %110 = bitcast i8* %109 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %103, i64 %1
  %112 = bitcast i8* %111 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %111, i64 16
  %114 = bitcast i8* %113 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %111, i64 32
  %116 = bitcast i8* %115 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %111, i64 48
  %118 = bitcast i8* %117 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %111, i64 %1
  %120 = bitcast i8* %119 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %119, i64 16
  %122 = bitcast i8* %121 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %119, i64 32
  %124 = bitcast i8* %123 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %124, align 1
  %125 = getelementptr inbounds i8, i8* %119, i64 48
  %126 = bitcast i8* %125 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %119, i64 %1
  %128 = bitcast i8* %127 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %128, align 1
  %129 = getelementptr inbounds i8, i8* %127, i64 16
  %130 = bitcast i8* %129 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %130, align 1
  %131 = getelementptr inbounds i8, i8* %127, i64 32
  %132 = bitcast i8* %131 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %132, align 1
  %133 = getelementptr inbounds i8, i8* %127, i64 48
  %134 = bitcast i8* %133 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %127, i64 %1
  %136 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %135, i64 16
  %138 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %135, i64 32
  %140 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %135, i64 48
  %142 = bitcast i8* %141 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %142, align 1
  %143 = getelementptr inbounds i8, i8* %135, i64 %1
  %144 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %144, align 1
  %145 = getelementptr inbounds i8, i8* %143, i64 16
  %146 = bitcast i8* %145 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %143, i64 32
  %148 = bitcast i8* %147 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %143, i64 48
  %150 = bitcast i8* %149 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %150, align 1
  %151 = getelementptr inbounds i8, i8* %143, i64 %1
  %152 = bitcast i8* %151 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %152, align 1
  %153 = getelementptr inbounds i8, i8* %151, i64 16
  %154 = bitcast i8* %153 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %154, align 1
  %155 = getelementptr inbounds i8, i8* %151, i64 32
  %156 = bitcast i8* %155 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %156, align 1
  %157 = getelementptr inbounds i8, i8* %151, i64 48
  %158 = bitcast i8* %157 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %151, i64 %1
  %160 = bitcast i8* %159 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %160, align 1
  %161 = getelementptr inbounds i8, i8* %159, i64 16
  %162 = bitcast i8* %161 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %162, align 1
  %163 = getelementptr inbounds i8, i8* %159, i64 32
  %164 = bitcast i8* %163 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %164, align 1
  %165 = getelementptr inbounds i8, i8* %159, i64 48
  %166 = bitcast i8* %165 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %166, align 1
  %167 = getelementptr inbounds i8, i8* %159, i64 %1
  %168 = bitcast i8* %167 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %168, align 1
  %169 = getelementptr inbounds i8, i8* %167, i64 16
  %170 = bitcast i8* %169 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %170, align 1
  %171 = getelementptr inbounds i8, i8* %167, i64 32
  %172 = bitcast i8* %171 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %172, align 1
  %173 = getelementptr inbounds i8, i8* %167, i64 48
  %174 = bitcast i8* %173 to <16 x i8>*
  store <16 x i8> %47, <16 x i8>* %174, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi5EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum32_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi32EEEvPvlDv2_xEELi5ELi21846EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = getelementptr inbounds i8, i8* %2, i64 32
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = getelementptr inbounds i8, i8* %2, i64 48
  %14 = bitcast i8* %13 to <16 x i8>*
  %15 = load <16 x i8>, <16 x i8>* %14, align 1
  %16 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %17 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %18 = bitcast <2 x i64> %16 to <8 x i16>
  %19 = bitcast <2 x i64> %17 to <8 x i16>
  %20 = add <8 x i16> %19, %18
  %21 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %12, <16 x i8> zeroinitializer) #11
  %22 = bitcast <2 x i64> %21 to <8 x i16>
  %23 = add <8 x i16> %20, %22
  %24 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %15, <16 x i8> zeroinitializer) #11
  %25 = bitcast <2 x i64> %24 to <8 x i16>
  %26 = add <8 x i16> %23, %25
  %27 = bitcast <8 x i16> %26 to <16 x i8>
  %28 = shufflevector <16 x i8> %27, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %29 = bitcast <16 x i8> %28 to <8 x i16>
  %30 = add <8 x i16> %26, %29
  %31 = bitcast i8* %3 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = getelementptr inbounds i8, i8* %3, i64 16
  %34 = bitcast i8* %33 to <16 x i8>*
  %35 = load <16 x i8>, <16 x i8>* %34, align 1
  %36 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %32, <16 x i8> zeroinitializer) #11
  %37 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %35, <16 x i8> zeroinitializer) #11
  %38 = bitcast <2 x i64> %36 to <8 x i16>
  %39 = bitcast <2 x i64> %37 to <8 x i16>
  %40 = add <8 x i16> %39, %38
  %41 = bitcast <8 x i16> %40 to <16 x i8>
  %42 = shufflevector <16 x i8> %41, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %43 = bitcast <16 x i8> %42 to <8 x i16>
  %44 = add <8 x i16> %40, %43
  %45 = bitcast <8 x i16> %30 to <4 x i32>
  %46 = bitcast <8 x i16> %44 to <4 x i32>
  %47 = add <4 x i32> %45, <i32 48, i32 48, i32 48, i32 48>
  %48 = add <4 x i32> %47, %46
  %49 = lshr <4 x i32> %48, <i32 5, i32 5, i32 5, i32 5>
  %50 = bitcast <4 x i32> %49 to <8 x i16>
  %51 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %50, <8 x i16> <i16 21846, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0, i16 0>) #11
  %52 = bitcast <8 x i16> %51 to <16 x i8>
  %53 = shufflevector <16 x i8> %52, <16 x i8> undef, <16 x i32> zeroinitializer
  br label %54

54:                                               ; preds = %90, %4
  %55 = phi i32 [ 31, %4 ], [ %92, %90 ]
  %56 = phi i8* [ %0, %4 ], [ %91, %90 ]
  %57 = bitcast i8* %56 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %56, i64 16
  %59 = bitcast i8* %58 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %56, i64 32
  %61 = bitcast i8* %60 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %56, i64 48
  %63 = bitcast i8* %62 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %56, i64 %1
  %65 = bitcast i8* %64 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %65, align 1
  %66 = getelementptr inbounds i8, i8* %64, i64 16
  %67 = bitcast i8* %66 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %67, align 1
  %68 = getelementptr inbounds i8, i8* %64, i64 32
  %69 = bitcast i8* %68 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %69, align 1
  %70 = getelementptr inbounds i8, i8* %64, i64 48
  %71 = bitcast i8* %70 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %71, align 1
  %72 = getelementptr inbounds i8, i8* %64, i64 %1
  %73 = bitcast i8* %72 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %72, i64 16
  %75 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %72, i64 32
  %77 = bitcast i8* %76 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %72, i64 48
  %79 = bitcast i8* %78 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %72, i64 %1
  %81 = icmp eq i32 %55, 3
  %82 = bitcast i8* %80 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %80, i64 16
  %84 = bitcast i8* %83 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %80, i64 32
  %86 = bitcast i8* %85 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %80, i64 48
  %88 = bitcast i8* %87 to <16 x i8>*
  store <16 x i8> %53, <16 x i8>* %88, align 1
  br i1 %81, label %89, label %90

89:                                               ; preds = %54
  ret void

90:                                               ; preds = %54
  %91 = getelementptr inbounds i8, i8* %80, i64 %1
  %92 = add nsw i32 %55, -4
  br label %54
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi6ELi6EXadL_ZNS0_12low_bitdepth12_GLOBAL__N_114DcSum64_SSE4_1EPKvEEXadL_ZNS4_14DcSum64_SSE4_1ES6_EEXadL_ZNS4_18DcStore64xH_SSE4_1ILi64EEEvPvlDv2_xEELi0ELi0EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %2, i64 16
  %8 = bitcast i8* %7 to <16 x i8>*
  %9 = load <16 x i8>, <16 x i8>* %8, align 1
  %10 = getelementptr inbounds i8, i8* %2, i64 32
  %11 = bitcast i8* %10 to <16 x i8>*
  %12 = load <16 x i8>, <16 x i8>* %11, align 1
  %13 = getelementptr inbounds i8, i8* %2, i64 48
  %14 = bitcast i8* %13 to <16 x i8>*
  %15 = load <16 x i8>, <16 x i8>* %14, align 1
  %16 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %6, <16 x i8> zeroinitializer) #11
  %17 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %9, <16 x i8> zeroinitializer) #11
  %18 = bitcast <2 x i64> %16 to <8 x i16>
  %19 = bitcast <2 x i64> %17 to <8 x i16>
  %20 = add <8 x i16> %19, %18
  %21 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %12, <16 x i8> zeroinitializer) #11
  %22 = bitcast <2 x i64> %21 to <8 x i16>
  %23 = add <8 x i16> %20, %22
  %24 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %15, <16 x i8> zeroinitializer) #11
  %25 = bitcast <2 x i64> %24 to <8 x i16>
  %26 = add <8 x i16> %23, %25
  %27 = bitcast <8 x i16> %26 to <16 x i8>
  %28 = shufflevector <16 x i8> %27, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %29 = bitcast <16 x i8> %28 to <8 x i16>
  %30 = add <8 x i16> %26, %29
  %31 = bitcast i8* %3 to <16 x i8>*
  %32 = load <16 x i8>, <16 x i8>* %31, align 1
  %33 = getelementptr inbounds i8, i8* %3, i64 16
  %34 = bitcast i8* %33 to <16 x i8>*
  %35 = load <16 x i8>, <16 x i8>* %34, align 1
  %36 = getelementptr inbounds i8, i8* %3, i64 32
  %37 = bitcast i8* %36 to <16 x i8>*
  %38 = load <16 x i8>, <16 x i8>* %37, align 1
  %39 = getelementptr inbounds i8, i8* %3, i64 48
  %40 = bitcast i8* %39 to <16 x i8>*
  %41 = load <16 x i8>, <16 x i8>* %40, align 1
  %42 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %32, <16 x i8> zeroinitializer) #11
  %43 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %35, <16 x i8> zeroinitializer) #11
  %44 = bitcast <2 x i64> %42 to <8 x i16>
  %45 = bitcast <2 x i64> %43 to <8 x i16>
  %46 = add <8 x i16> %45, %44
  %47 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %38, <16 x i8> zeroinitializer) #11
  %48 = bitcast <2 x i64> %47 to <8 x i16>
  %49 = add <8 x i16> %46, %48
  %50 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %41, <16 x i8> zeroinitializer) #11
  %51 = bitcast <2 x i64> %50 to <8 x i16>
  %52 = add <8 x i16> %49, %51
  %53 = bitcast <8 x i16> %52 to <16 x i8>
  %54 = shufflevector <16 x i8> %53, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %55 = bitcast <16 x i8> %54 to <8 x i16>
  %56 = add <8 x i16> %52, %55
  %57 = bitcast <8 x i16> %30 to <4 x i32>
  %58 = bitcast <8 x i16> %56 to <4 x i32>
  %59 = add <4 x i32> %57, <i32 64, i32 64, i32 64, i32 64>
  %60 = add <4 x i32> %59, %58
  %61 = lshr <4 x i32> %60, <i32 7, i32 7, i32 7, i32 7>
  %62 = bitcast <4 x i32> %61 to <16 x i8>
  %63 = shufflevector <16 x i8> %62, <16 x i8> undef, <16 x i32> zeroinitializer
  br label %64

64:                                               ; preds = %64, %4
  %65 = phi i32 [ 63, %4 ], [ %91, %64 ]
  %66 = phi i8* [ %0, %4 ], [ %90, %64 ]
  %67 = bitcast i8* %66 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %67, align 1
  %68 = getelementptr inbounds i8, i8* %66, i64 16
  %69 = bitcast i8* %68 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %69, align 1
  %70 = getelementptr inbounds i8, i8* %66, i64 32
  %71 = bitcast i8* %70 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %71, align 1
  %72 = getelementptr inbounds i8, i8* %66, i64 48
  %73 = bitcast i8* %72 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %66, i64 %1
  %75 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %74, i64 16
  %77 = bitcast i8* %76 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %74, i64 32
  %79 = bitcast i8* %78 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %74, i64 48
  %81 = bitcast i8* %80 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %74, i64 %1
  %83 = bitcast i8* %82 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %82, i64 16
  %85 = bitcast i8* %84 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %85, align 1
  %86 = getelementptr inbounds i8, i8* %82, i64 32
  %87 = bitcast i8* %86 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %87, align 1
  %88 = getelementptr inbounds i8, i8* %82, i64 48
  %89 = bitcast i8* %88 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %89, align 1
  %90 = getelementptr inbounds i8, i8* %82, i64 %1
  %91 = add nsw i32 %65, -3
  %92 = icmp eq i32 %91, 0
  br i1 %92, label %93, label %64

93:                                               ; preds = %64
  %94 = bitcast i8* %90 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %90, i64 16
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %90, i64 32
  %98 = bitcast i8* %97 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %90, i64 48
  %100 = bitcast i8* %99 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %100, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115Paeth4x4_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> undef, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %10 = zext <4 x i8> %9 to <4 x i32>
  %11 = bitcast i8* %2 to i32*
  %12 = load i32, i32* %11, align 1
  %13 = insertelement <4 x i32> undef, i32 %12, i32 0
  %14 = bitcast <4 x i32> %13 to <16 x i8>
  %15 = shufflevector <16 x i8> %14, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %16 = zext <4 x i8> %15 to <4 x i32>
  %17 = bitcast <4 x i32> %16 to <2 x i64>
  %18 = getelementptr inbounds i8, i8* %2, i64 -1
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = insertelement <4 x i32> undef, i32 %20, i32 0
  %22 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> zeroinitializer
  %23 = sub <4 x i32> %16, %22
  %24 = sub <4 x i32> zeroinitializer, %23
  %25 = icmp slt <4 x i32> %23, zeroinitializer
  %26 = select <4 x i1> %25, <4 x i32> %24, <4 x i32> %23
  %27 = sub <4 x i32> %10, %22
  %28 = sub <4 x i32> zeroinitializer, %27
  %29 = icmp slt <4 x i32> %27, zeroinitializer
  %30 = select <4 x i1> %29, <4 x i32> %28, <4 x i32> %27
  %31 = shl <4 x i32> %21, <i32 1, i32 1, i32 1, i32 1>
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> zeroinitializer
  %33 = sub <4 x i32> %16, %32
  %34 = shufflevector <4 x i32> %30, <4 x i32> undef, <4 x i32> zeroinitializer
  %35 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> zeroinitializer
  %36 = bitcast <4 x i32> %35 to <2 x i64>
  %37 = add <4 x i32> %33, %35
  %38 = sub <4 x i32> zeroinitializer, %37
  %39 = icmp slt <4 x i32> %37, zeroinitializer
  %40 = select <4 x i1> %39, <4 x i32> %38, <4 x i32> %37
  %41 = icmp sgt <4 x i32> %26, %40
  %42 = icmp sgt <4 x i32> %26, %34
  %43 = or <4 x i1> %41, %42
  %44 = sext <4 x i1> %43 to <4 x i32>
  %45 = bitcast <4 x i32> %44 to <2 x i64>
  %46 = icmp sgt <4 x i32> %34, %40
  %47 = sext <4 x i1> %46 to <4 x i32>
  %48 = bitcast <4 x i32> %47 to <2 x i64>
  %49 = xor <2 x i64> %45, <i64 -1, i64 -1>
  %50 = and <2 x i64> %49, %36
  %51 = and <4 x i32> %22, %47
  %52 = bitcast <4 x i32> %51 to <2 x i64>
  %53 = xor <2 x i64> %48, <i64 -1, i64 -1>
  %54 = and <2 x i64> %53, %17
  %55 = or <2 x i64> %54, %52
  %56 = and <2 x i64> %55, %45
  %57 = or <2 x i64> %56, %50
  %58 = bitcast <2 x i64> %57 to <16 x i8>
  %59 = shufflevector <16 x i8> %58, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %60 = bitcast <16 x i8> %59 to <4 x i32>
  %61 = extractelement <4 x i32> %60, i32 0
  %62 = bitcast i8* %0 to i32*
  store i32 %61, i32* %62, align 1
  %63 = getelementptr inbounds i8, i8* %0, i64 %1
  %64 = shufflevector <4 x i32> %30, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %65 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %66 = bitcast <4 x i32> %65 to <2 x i64>
  %67 = add <4 x i32> %33, %65
  %68 = sub <4 x i32> zeroinitializer, %67
  %69 = icmp slt <4 x i32> %67, zeroinitializer
  %70 = select <4 x i1> %69, <4 x i32> %68, <4 x i32> %67
  %71 = icmp sgt <4 x i32> %26, %70
  %72 = icmp sgt <4 x i32> %26, %64
  %73 = or <4 x i1> %71, %72
  %74 = sext <4 x i1> %73 to <4 x i32>
  %75 = bitcast <4 x i32> %74 to <2 x i64>
  %76 = icmp sgt <4 x i32> %64, %70
  %77 = sext <4 x i1> %76 to <4 x i32>
  %78 = bitcast <4 x i32> %77 to <2 x i64>
  %79 = xor <2 x i64> %75, <i64 -1, i64 -1>
  %80 = and <2 x i64> %79, %66
  %81 = and <4 x i32> %22, %77
  %82 = bitcast <4 x i32> %81 to <2 x i64>
  %83 = xor <2 x i64> %78, <i64 -1, i64 -1>
  %84 = and <2 x i64> %83, %17
  %85 = or <2 x i64> %84, %82
  %86 = and <2 x i64> %85, %75
  %87 = or <2 x i64> %86, %80
  %88 = bitcast <2 x i64> %87 to <16 x i8>
  %89 = shufflevector <16 x i8> %88, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %90 = bitcast <16 x i8> %89 to <4 x i32>
  %91 = extractelement <4 x i32> %90, i32 0
  %92 = bitcast i8* %63 to i32*
  store i32 %91, i32* %92, align 1
  %93 = getelementptr inbounds i8, i8* %63, i64 %1
  %94 = shufflevector <4 x i32> %30, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %95 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %96 = bitcast <4 x i32> %95 to <2 x i64>
  %97 = add <4 x i32> %33, %95
  %98 = sub <4 x i32> zeroinitializer, %97
  %99 = icmp slt <4 x i32> %97, zeroinitializer
  %100 = select <4 x i1> %99, <4 x i32> %98, <4 x i32> %97
  %101 = icmp sgt <4 x i32> %26, %100
  %102 = icmp sgt <4 x i32> %26, %94
  %103 = or <4 x i1> %101, %102
  %104 = sext <4 x i1> %103 to <4 x i32>
  %105 = bitcast <4 x i32> %104 to <2 x i64>
  %106 = icmp sgt <4 x i32> %94, %100
  %107 = sext <4 x i1> %106 to <4 x i32>
  %108 = bitcast <4 x i32> %107 to <2 x i64>
  %109 = xor <2 x i64> %105, <i64 -1, i64 -1>
  %110 = and <2 x i64> %109, %96
  %111 = and <4 x i32> %22, %107
  %112 = bitcast <4 x i32> %111 to <2 x i64>
  %113 = xor <2 x i64> %108, <i64 -1, i64 -1>
  %114 = and <2 x i64> %113, %17
  %115 = or <2 x i64> %114, %112
  %116 = and <2 x i64> %115, %105
  %117 = or <2 x i64> %116, %110
  %118 = bitcast <2 x i64> %117 to <16 x i8>
  %119 = shufflevector <16 x i8> %118, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %120 = bitcast <16 x i8> %119 to <4 x i32>
  %121 = extractelement <4 x i32> %120, i32 0
  %122 = bitcast i8* %93 to i32*
  store i32 %121, i32* %122, align 1
  %123 = getelementptr inbounds i8, i8* %93, i64 %1
  %124 = shufflevector <4 x i32> %30, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %125 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %126 = bitcast <4 x i32> %125 to <2 x i64>
  %127 = add <4 x i32> %33, %125
  %128 = sub <4 x i32> zeroinitializer, %127
  %129 = icmp slt <4 x i32> %127, zeroinitializer
  %130 = select <4 x i1> %129, <4 x i32> %128, <4 x i32> %127
  %131 = icmp sgt <4 x i32> %26, %130
  %132 = icmp sgt <4 x i32> %26, %124
  %133 = or <4 x i1> %131, %132
  %134 = sext <4 x i1> %133 to <4 x i32>
  %135 = bitcast <4 x i32> %134 to <2 x i64>
  %136 = icmp sgt <4 x i32> %124, %130
  %137 = sext <4 x i1> %136 to <4 x i32>
  %138 = bitcast <4 x i32> %137 to <2 x i64>
  %139 = xor <2 x i64> %135, <i64 -1, i64 -1>
  %140 = and <2 x i64> %139, %126
  %141 = and <4 x i32> %22, %137
  %142 = bitcast <4 x i32> %141 to <2 x i64>
  %143 = xor <2 x i64> %138, <i64 -1, i64 -1>
  %144 = and <2 x i64> %143, %17
  %145 = or <2 x i64> %144, %142
  %146 = and <2 x i64> %145, %135
  %147 = or <2 x i64> %146, %140
  %148 = bitcast <2 x i64> %147 to <16 x i8>
  %149 = shufflevector <16 x i8> %148, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %150 = bitcast <16 x i8> %149 to <4 x i32>
  %151 = extractelement <4 x i32> %150, i32 0
  %152 = bitcast i8* %123 to i32*
  store i32 %151, i32* %152, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115Paeth4x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %10 = zext <4 x i8> %9 to <4 x i32>
  %11 = shufflevector <16 x i8> %8, <16 x i8> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %12 = zext <4 x i8> %11 to <4 x i32>
  %13 = bitcast i8* %2 to i32*
  %14 = load i32, i32* %13, align 1
  %15 = insertelement <4 x i32> undef, i32 %14, i32 0
  %16 = bitcast <4 x i32> %15 to <16 x i8>
  %17 = shufflevector <16 x i8> %16, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i8> %17 to <4 x i32>
  %19 = bitcast <4 x i32> %18 to <2 x i64>
  %20 = getelementptr inbounds i8, i8* %2, i64 -1
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  %23 = insertelement <4 x i32> undef, i32 %22, i32 0
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> zeroinitializer
  %25 = sub <4 x i32> %18, %24
  %26 = sub <4 x i32> zeroinitializer, %25
  %27 = icmp slt <4 x i32> %25, zeroinitializer
  %28 = select <4 x i1> %27, <4 x i32> %26, <4 x i32> %25
  %29 = sub <4 x i32> %10, %24
  %30 = sub <4 x i32> zeroinitializer, %29
  %31 = icmp slt <4 x i32> %29, zeroinitializer
  %32 = select <4 x i1> %31, <4 x i32> %30, <4 x i32> %29
  %33 = sub <4 x i32> %12, %24
  %34 = sub <4 x i32> zeroinitializer, %33
  %35 = icmp slt <4 x i32> %33, zeroinitializer
  %36 = select <4 x i1> %35, <4 x i32> %34, <4 x i32> %33
  %37 = shl <4 x i32> %23, <i32 1, i32 1, i32 1, i32 1>
  %38 = shufflevector <4 x i32> %37, <4 x i32> undef, <4 x i32> zeroinitializer
  %39 = sub <4 x i32> %18, %38
  %40 = shufflevector <4 x i32> %32, <4 x i32> undef, <4 x i32> zeroinitializer
  %41 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = bitcast <4 x i32> %41 to <2 x i64>
  %43 = add <4 x i32> %39, %41
  %44 = sub <4 x i32> zeroinitializer, %43
  %45 = icmp slt <4 x i32> %43, zeroinitializer
  %46 = select <4 x i1> %45, <4 x i32> %44, <4 x i32> %43
  %47 = icmp sgt <4 x i32> %28, %46
  %48 = icmp sgt <4 x i32> %28, %40
  %49 = or <4 x i1> %47, %48
  %50 = sext <4 x i1> %49 to <4 x i32>
  %51 = bitcast <4 x i32> %50 to <2 x i64>
  %52 = icmp sgt <4 x i32> %40, %46
  %53 = sext <4 x i1> %52 to <4 x i32>
  %54 = bitcast <4 x i32> %53 to <2 x i64>
  %55 = xor <2 x i64> %51, <i64 -1, i64 -1>
  %56 = and <2 x i64> %55, %42
  %57 = and <4 x i32> %24, %53
  %58 = bitcast <4 x i32> %57 to <2 x i64>
  %59 = xor <2 x i64> %54, <i64 -1, i64 -1>
  %60 = and <2 x i64> %59, %19
  %61 = or <2 x i64> %60, %58
  %62 = and <2 x i64> %61, %51
  %63 = or <2 x i64> %62, %56
  %64 = bitcast <2 x i64> %63 to <16 x i8>
  %65 = shufflevector <16 x i8> %64, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %66 = bitcast <16 x i8> %65 to <4 x i32>
  %67 = extractelement <4 x i32> %66, i32 0
  %68 = bitcast i8* %0 to i32*
  store i32 %67, i32* %68, align 1
  %69 = getelementptr inbounds i8, i8* %0, i64 %1
  %70 = shufflevector <4 x i32> %32, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %71 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %72 = bitcast <4 x i32> %71 to <2 x i64>
  %73 = add <4 x i32> %39, %71
  %74 = sub <4 x i32> zeroinitializer, %73
  %75 = icmp slt <4 x i32> %73, zeroinitializer
  %76 = select <4 x i1> %75, <4 x i32> %74, <4 x i32> %73
  %77 = icmp sgt <4 x i32> %28, %76
  %78 = icmp sgt <4 x i32> %28, %70
  %79 = or <4 x i1> %77, %78
  %80 = sext <4 x i1> %79 to <4 x i32>
  %81 = bitcast <4 x i32> %80 to <2 x i64>
  %82 = icmp sgt <4 x i32> %70, %76
  %83 = sext <4 x i1> %82 to <4 x i32>
  %84 = bitcast <4 x i32> %83 to <2 x i64>
  %85 = xor <2 x i64> %81, <i64 -1, i64 -1>
  %86 = and <2 x i64> %85, %72
  %87 = and <4 x i32> %24, %83
  %88 = bitcast <4 x i32> %87 to <2 x i64>
  %89 = xor <2 x i64> %84, <i64 -1, i64 -1>
  %90 = and <2 x i64> %89, %19
  %91 = or <2 x i64> %90, %88
  %92 = and <2 x i64> %91, %81
  %93 = or <2 x i64> %92, %86
  %94 = bitcast <2 x i64> %93 to <16 x i8>
  %95 = shufflevector <16 x i8> %94, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %96 = bitcast <16 x i8> %95 to <4 x i32>
  %97 = extractelement <4 x i32> %96, i32 0
  %98 = bitcast i8* %69 to i32*
  store i32 %97, i32* %98, align 1
  %99 = getelementptr inbounds i8, i8* %69, i64 %1
  %100 = shufflevector <4 x i32> %32, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %101 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %102 = bitcast <4 x i32> %101 to <2 x i64>
  %103 = add <4 x i32> %39, %101
  %104 = sub <4 x i32> zeroinitializer, %103
  %105 = icmp slt <4 x i32> %103, zeroinitializer
  %106 = select <4 x i1> %105, <4 x i32> %104, <4 x i32> %103
  %107 = icmp sgt <4 x i32> %28, %106
  %108 = icmp sgt <4 x i32> %28, %100
  %109 = or <4 x i1> %107, %108
  %110 = sext <4 x i1> %109 to <4 x i32>
  %111 = bitcast <4 x i32> %110 to <2 x i64>
  %112 = icmp sgt <4 x i32> %100, %106
  %113 = sext <4 x i1> %112 to <4 x i32>
  %114 = bitcast <4 x i32> %113 to <2 x i64>
  %115 = xor <2 x i64> %111, <i64 -1, i64 -1>
  %116 = and <2 x i64> %115, %102
  %117 = and <4 x i32> %24, %113
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = xor <2 x i64> %114, <i64 -1, i64 -1>
  %120 = and <2 x i64> %119, %19
  %121 = or <2 x i64> %120, %118
  %122 = and <2 x i64> %121, %111
  %123 = or <2 x i64> %122, %116
  %124 = bitcast <2 x i64> %123 to <16 x i8>
  %125 = shufflevector <16 x i8> %124, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %126 = bitcast <16 x i8> %125 to <4 x i32>
  %127 = extractelement <4 x i32> %126, i32 0
  %128 = bitcast i8* %99 to i32*
  store i32 %127, i32* %128, align 1
  %129 = getelementptr inbounds i8, i8* %99, i64 %1
  %130 = shufflevector <4 x i32> %32, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %131 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %132 = bitcast <4 x i32> %131 to <2 x i64>
  %133 = add <4 x i32> %39, %131
  %134 = sub <4 x i32> zeroinitializer, %133
  %135 = icmp slt <4 x i32> %133, zeroinitializer
  %136 = select <4 x i1> %135, <4 x i32> %134, <4 x i32> %133
  %137 = icmp sgt <4 x i32> %28, %136
  %138 = icmp sgt <4 x i32> %28, %130
  %139 = or <4 x i1> %137, %138
  %140 = sext <4 x i1> %139 to <4 x i32>
  %141 = bitcast <4 x i32> %140 to <2 x i64>
  %142 = icmp sgt <4 x i32> %130, %136
  %143 = sext <4 x i1> %142 to <4 x i32>
  %144 = bitcast <4 x i32> %143 to <2 x i64>
  %145 = xor <2 x i64> %141, <i64 -1, i64 -1>
  %146 = and <2 x i64> %145, %132
  %147 = and <4 x i32> %24, %143
  %148 = bitcast <4 x i32> %147 to <2 x i64>
  %149 = xor <2 x i64> %144, <i64 -1, i64 -1>
  %150 = and <2 x i64> %149, %19
  %151 = or <2 x i64> %150, %148
  %152 = and <2 x i64> %151, %141
  %153 = or <2 x i64> %152, %146
  %154 = bitcast <2 x i64> %153 to <16 x i8>
  %155 = shufflevector <16 x i8> %154, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %156 = bitcast <16 x i8> %155 to <4 x i32>
  %157 = extractelement <4 x i32> %156, i32 0
  %158 = bitcast i8* %129 to i32*
  store i32 %157, i32* %158, align 1
  %159 = getelementptr inbounds i8, i8* %129, i64 %1
  %160 = shufflevector <4 x i32> %36, <4 x i32> undef, <4 x i32> zeroinitializer
  %161 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> zeroinitializer
  %162 = bitcast <4 x i32> %161 to <2 x i64>
  %163 = add <4 x i32> %39, %161
  %164 = sub <4 x i32> zeroinitializer, %163
  %165 = icmp slt <4 x i32> %163, zeroinitializer
  %166 = select <4 x i1> %165, <4 x i32> %164, <4 x i32> %163
  %167 = icmp sgt <4 x i32> %28, %166
  %168 = icmp sgt <4 x i32> %28, %160
  %169 = or <4 x i1> %167, %168
  %170 = sext <4 x i1> %169 to <4 x i32>
  %171 = bitcast <4 x i32> %170 to <2 x i64>
  %172 = icmp sgt <4 x i32> %160, %166
  %173 = sext <4 x i1> %172 to <4 x i32>
  %174 = bitcast <4 x i32> %173 to <2 x i64>
  %175 = xor <2 x i64> %171, <i64 -1, i64 -1>
  %176 = and <2 x i64> %175, %162
  %177 = and <4 x i32> %24, %173
  %178 = bitcast <4 x i32> %177 to <2 x i64>
  %179 = xor <2 x i64> %174, <i64 -1, i64 -1>
  %180 = and <2 x i64> %179, %19
  %181 = or <2 x i64> %180, %178
  %182 = and <2 x i64> %181, %171
  %183 = or <2 x i64> %182, %176
  %184 = bitcast <2 x i64> %183 to <16 x i8>
  %185 = shufflevector <16 x i8> %184, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %186 = bitcast <16 x i8> %185 to <4 x i32>
  %187 = extractelement <4 x i32> %186, i32 0
  %188 = bitcast i8* %159 to i32*
  store i32 %187, i32* %188, align 1
  %189 = getelementptr inbounds i8, i8* %159, i64 %1
  %190 = shufflevector <4 x i32> %36, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %191 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %192 = bitcast <4 x i32> %191 to <2 x i64>
  %193 = add <4 x i32> %39, %191
  %194 = sub <4 x i32> zeroinitializer, %193
  %195 = icmp slt <4 x i32> %193, zeroinitializer
  %196 = select <4 x i1> %195, <4 x i32> %194, <4 x i32> %193
  %197 = icmp sgt <4 x i32> %28, %196
  %198 = icmp sgt <4 x i32> %28, %190
  %199 = or <4 x i1> %197, %198
  %200 = sext <4 x i1> %199 to <4 x i32>
  %201 = bitcast <4 x i32> %200 to <2 x i64>
  %202 = icmp sgt <4 x i32> %190, %196
  %203 = sext <4 x i1> %202 to <4 x i32>
  %204 = bitcast <4 x i32> %203 to <2 x i64>
  %205 = xor <2 x i64> %201, <i64 -1, i64 -1>
  %206 = and <2 x i64> %205, %192
  %207 = and <4 x i32> %24, %203
  %208 = bitcast <4 x i32> %207 to <2 x i64>
  %209 = xor <2 x i64> %204, <i64 -1, i64 -1>
  %210 = and <2 x i64> %209, %19
  %211 = or <2 x i64> %210, %208
  %212 = and <2 x i64> %211, %201
  %213 = or <2 x i64> %212, %206
  %214 = bitcast <2 x i64> %213 to <16 x i8>
  %215 = shufflevector <16 x i8> %214, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %216 = bitcast <16 x i8> %215 to <4 x i32>
  %217 = extractelement <4 x i32> %216, i32 0
  %218 = bitcast i8* %189 to i32*
  store i32 %217, i32* %218, align 1
  %219 = getelementptr inbounds i8, i8* %189, i64 %1
  %220 = shufflevector <4 x i32> %36, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %221 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %222 = bitcast <4 x i32> %221 to <2 x i64>
  %223 = add <4 x i32> %39, %221
  %224 = sub <4 x i32> zeroinitializer, %223
  %225 = icmp slt <4 x i32> %223, zeroinitializer
  %226 = select <4 x i1> %225, <4 x i32> %224, <4 x i32> %223
  %227 = icmp sgt <4 x i32> %28, %226
  %228 = icmp sgt <4 x i32> %28, %220
  %229 = or <4 x i1> %227, %228
  %230 = sext <4 x i1> %229 to <4 x i32>
  %231 = bitcast <4 x i32> %230 to <2 x i64>
  %232 = icmp sgt <4 x i32> %220, %226
  %233 = sext <4 x i1> %232 to <4 x i32>
  %234 = bitcast <4 x i32> %233 to <2 x i64>
  %235 = xor <2 x i64> %231, <i64 -1, i64 -1>
  %236 = and <2 x i64> %235, %222
  %237 = and <4 x i32> %24, %233
  %238 = bitcast <4 x i32> %237 to <2 x i64>
  %239 = xor <2 x i64> %234, <i64 -1, i64 -1>
  %240 = and <2 x i64> %239, %19
  %241 = or <2 x i64> %240, %238
  %242 = and <2 x i64> %241, %231
  %243 = or <2 x i64> %242, %236
  %244 = bitcast <2 x i64> %243 to <16 x i8>
  %245 = shufflevector <16 x i8> %244, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %246 = bitcast <16 x i8> %245 to <4 x i32>
  %247 = extractelement <4 x i32> %246, i32 0
  %248 = bitcast i8* %219 to i32*
  store i32 %247, i32* %248, align 1
  %249 = getelementptr inbounds i8, i8* %219, i64 %1
  %250 = shufflevector <4 x i32> %36, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %251 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %252 = bitcast <4 x i32> %251 to <2 x i64>
  %253 = add <4 x i32> %39, %251
  %254 = sub <4 x i32> zeroinitializer, %253
  %255 = icmp slt <4 x i32> %253, zeroinitializer
  %256 = select <4 x i1> %255, <4 x i32> %254, <4 x i32> %253
  %257 = icmp sgt <4 x i32> %28, %256
  %258 = icmp sgt <4 x i32> %28, %250
  %259 = or <4 x i1> %257, %258
  %260 = sext <4 x i1> %259 to <4 x i32>
  %261 = bitcast <4 x i32> %260 to <2 x i64>
  %262 = icmp sgt <4 x i32> %250, %256
  %263 = sext <4 x i1> %262 to <4 x i32>
  %264 = bitcast <4 x i32> %263 to <2 x i64>
  %265 = xor <2 x i64> %261, <i64 -1, i64 -1>
  %266 = and <2 x i64> %265, %252
  %267 = and <4 x i32> %24, %263
  %268 = bitcast <4 x i32> %267 to <2 x i64>
  %269 = xor <2 x i64> %264, <i64 -1, i64 -1>
  %270 = and <2 x i64> %269, %19
  %271 = or <2 x i64> %270, %268
  %272 = and <2 x i64> %271, %261
  %273 = or <2 x i64> %272, %266
  %274 = bitcast <2 x i64> %273 to <16 x i8>
  %275 = shufflevector <16 x i8> %274, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %276 = bitcast <16 x i8> %275 to <4 x i32>
  %277 = extractelement <4 x i32> %276, i32 0
  %278 = bitcast i8* %249 to i32*
  store i32 %277, i32* %278, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth4x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = shufflevector <16 x i8> %6, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %8 = zext <4 x i8> %7 to <4 x i32>
  %9 = shufflevector <16 x i8> %6, <16 x i8> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %10 = zext <4 x i8> %9 to <4 x i32>
  %11 = shufflevector <16 x i8> %6, <16 x i8> undef, <4 x i32> <i32 8, i32 9, i32 10, i32 11>
  %12 = zext <4 x i8> %11 to <4 x i32>
  %13 = shufflevector <16 x i8> %6, <16 x i8> undef, <4 x i32> <i32 12, i32 13, i32 14, i32 15>
  %14 = zext <4 x i8> %13 to <4 x i32>
  %15 = bitcast i8* %2 to i32*
  %16 = load i32, i32* %15, align 1
  %17 = insertelement <4 x i32> undef, i32 %16, i32 0
  %18 = bitcast <4 x i32> %17 to <16 x i8>
  %19 = shufflevector <16 x i8> %18, <16 x i8> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %20 = zext <4 x i8> %19 to <4 x i32>
  %21 = bitcast <4 x i32> %20 to <2 x i64>
  %22 = getelementptr inbounds i8, i8* %2, i64 -1
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> zeroinitializer
  %27 = sub <4 x i32> %20, %26
  %28 = sub <4 x i32> zeroinitializer, %27
  %29 = icmp slt <4 x i32> %27, zeroinitializer
  %30 = select <4 x i1> %29, <4 x i32> %28, <4 x i32> %27
  %31 = sub <4 x i32> %8, %26
  %32 = sub <4 x i32> zeroinitializer, %31
  %33 = icmp slt <4 x i32> %31, zeroinitializer
  %34 = select <4 x i1> %33, <4 x i32> %32, <4 x i32> %31
  %35 = sub <4 x i32> %10, %26
  %36 = sub <4 x i32> zeroinitializer, %35
  %37 = icmp slt <4 x i32> %35, zeroinitializer
  %38 = select <4 x i1> %37, <4 x i32> %36, <4 x i32> %35
  %39 = sub <4 x i32> %12, %26
  %40 = sub <4 x i32> zeroinitializer, %39
  %41 = icmp slt <4 x i32> %39, zeroinitializer
  %42 = select <4 x i1> %41, <4 x i32> %40, <4 x i32> %39
  %43 = sub <4 x i32> %14, %26
  %44 = sub <4 x i32> zeroinitializer, %43
  %45 = icmp slt <4 x i32> %43, zeroinitializer
  %46 = select <4 x i1> %45, <4 x i32> %44, <4 x i32> %43
  %47 = shl <4 x i32> %25, <i32 1, i32 1, i32 1, i32 1>
  %48 = shufflevector <4 x i32> %47, <4 x i32> undef, <4 x i32> zeroinitializer
  %49 = sub <4 x i32> %20, %48
  %50 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> zeroinitializer
  %51 = shufflevector <4 x i32> %8, <4 x i32> undef, <4 x i32> zeroinitializer
  %52 = bitcast <4 x i32> %51 to <2 x i64>
  %53 = add <4 x i32> %49, %51
  %54 = sub <4 x i32> zeroinitializer, %53
  %55 = icmp slt <4 x i32> %53, zeroinitializer
  %56 = select <4 x i1> %55, <4 x i32> %54, <4 x i32> %53
  %57 = icmp sgt <4 x i32> %30, %56
  %58 = icmp sgt <4 x i32> %30, %50
  %59 = or <4 x i1> %57, %58
  %60 = sext <4 x i1> %59 to <4 x i32>
  %61 = bitcast <4 x i32> %60 to <2 x i64>
  %62 = icmp sgt <4 x i32> %50, %56
  %63 = sext <4 x i1> %62 to <4 x i32>
  %64 = bitcast <4 x i32> %63 to <2 x i64>
  %65 = xor <2 x i64> %61, <i64 -1, i64 -1>
  %66 = and <2 x i64> %65, %52
  %67 = and <4 x i32> %26, %63
  %68 = bitcast <4 x i32> %67 to <2 x i64>
  %69 = xor <2 x i64> %64, <i64 -1, i64 -1>
  %70 = and <2 x i64> %69, %21
  %71 = or <2 x i64> %70, %68
  %72 = and <2 x i64> %71, %61
  %73 = or <2 x i64> %72, %66
  %74 = bitcast <2 x i64> %73 to <16 x i8>
  %75 = shufflevector <16 x i8> %74, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %76 = bitcast <16 x i8> %75 to <4 x i32>
  %77 = extractelement <4 x i32> %76, i32 0
  %78 = bitcast i8* %0 to i32*
  store i32 %77, i32* %78, align 1
  %79 = getelementptr inbounds i8, i8* %0, i64 %1
  %80 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %81 = shufflevector <4 x i32> %8, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %82 = bitcast <4 x i32> %81 to <2 x i64>
  %83 = add <4 x i32> %49, %81
  %84 = sub <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = icmp sgt <4 x i32> %30, %86
  %88 = icmp sgt <4 x i32> %30, %80
  %89 = or <4 x i1> %87, %88
  %90 = sext <4 x i1> %89 to <4 x i32>
  %91 = bitcast <4 x i32> %90 to <2 x i64>
  %92 = icmp sgt <4 x i32> %80, %86
  %93 = sext <4 x i1> %92 to <4 x i32>
  %94 = bitcast <4 x i32> %93 to <2 x i64>
  %95 = xor <2 x i64> %91, <i64 -1, i64 -1>
  %96 = and <2 x i64> %95, %82
  %97 = and <4 x i32> %26, %93
  %98 = bitcast <4 x i32> %97 to <2 x i64>
  %99 = xor <2 x i64> %94, <i64 -1, i64 -1>
  %100 = and <2 x i64> %99, %21
  %101 = or <2 x i64> %100, %98
  %102 = and <2 x i64> %101, %91
  %103 = or <2 x i64> %102, %96
  %104 = bitcast <2 x i64> %103 to <16 x i8>
  %105 = shufflevector <16 x i8> %104, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %106 = bitcast <16 x i8> %105 to <4 x i32>
  %107 = extractelement <4 x i32> %106, i32 0
  %108 = bitcast i8* %79 to i32*
  store i32 %107, i32* %108, align 1
  %109 = getelementptr inbounds i8, i8* %79, i64 %1
  %110 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %111 = shufflevector <4 x i32> %8, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %112 = bitcast <4 x i32> %111 to <2 x i64>
  %113 = add <4 x i32> %49, %111
  %114 = sub <4 x i32> zeroinitializer, %113
  %115 = icmp slt <4 x i32> %113, zeroinitializer
  %116 = select <4 x i1> %115, <4 x i32> %114, <4 x i32> %113
  %117 = icmp sgt <4 x i32> %30, %116
  %118 = icmp sgt <4 x i32> %30, %110
  %119 = or <4 x i1> %117, %118
  %120 = sext <4 x i1> %119 to <4 x i32>
  %121 = bitcast <4 x i32> %120 to <2 x i64>
  %122 = icmp sgt <4 x i32> %110, %116
  %123 = sext <4 x i1> %122 to <4 x i32>
  %124 = bitcast <4 x i32> %123 to <2 x i64>
  %125 = xor <2 x i64> %121, <i64 -1, i64 -1>
  %126 = and <2 x i64> %125, %112
  %127 = and <4 x i32> %26, %123
  %128 = bitcast <4 x i32> %127 to <2 x i64>
  %129 = xor <2 x i64> %124, <i64 -1, i64 -1>
  %130 = and <2 x i64> %129, %21
  %131 = or <2 x i64> %130, %128
  %132 = and <2 x i64> %131, %121
  %133 = or <2 x i64> %132, %126
  %134 = bitcast <2 x i64> %133 to <16 x i8>
  %135 = shufflevector <16 x i8> %134, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %136 = bitcast <16 x i8> %135 to <4 x i32>
  %137 = extractelement <4 x i32> %136, i32 0
  %138 = bitcast i8* %109 to i32*
  store i32 %137, i32* %138, align 1
  %139 = getelementptr inbounds i8, i8* %109, i64 %1
  %140 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %141 = shufflevector <4 x i32> %8, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %142 = bitcast <4 x i32> %141 to <2 x i64>
  %143 = add <4 x i32> %49, %141
  %144 = sub <4 x i32> zeroinitializer, %143
  %145 = icmp slt <4 x i32> %143, zeroinitializer
  %146 = select <4 x i1> %145, <4 x i32> %144, <4 x i32> %143
  %147 = icmp sgt <4 x i32> %30, %146
  %148 = icmp sgt <4 x i32> %30, %140
  %149 = or <4 x i1> %147, %148
  %150 = sext <4 x i1> %149 to <4 x i32>
  %151 = bitcast <4 x i32> %150 to <2 x i64>
  %152 = icmp sgt <4 x i32> %140, %146
  %153 = sext <4 x i1> %152 to <4 x i32>
  %154 = bitcast <4 x i32> %153 to <2 x i64>
  %155 = xor <2 x i64> %151, <i64 -1, i64 -1>
  %156 = and <2 x i64> %155, %142
  %157 = and <4 x i32> %26, %153
  %158 = bitcast <4 x i32> %157 to <2 x i64>
  %159 = xor <2 x i64> %154, <i64 -1, i64 -1>
  %160 = and <2 x i64> %159, %21
  %161 = or <2 x i64> %160, %158
  %162 = and <2 x i64> %161, %151
  %163 = or <2 x i64> %162, %156
  %164 = bitcast <2 x i64> %163 to <16 x i8>
  %165 = shufflevector <16 x i8> %164, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %166 = bitcast <16 x i8> %165 to <4 x i32>
  %167 = extractelement <4 x i32> %166, i32 0
  %168 = bitcast i8* %139 to i32*
  store i32 %167, i32* %168, align 1
  %169 = getelementptr inbounds i8, i8* %139, i64 %1
  %170 = shufflevector <4 x i32> %38, <4 x i32> undef, <4 x i32> zeroinitializer
  %171 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> zeroinitializer
  %172 = bitcast <4 x i32> %171 to <2 x i64>
  %173 = add <4 x i32> %49, %171
  %174 = sub <4 x i32> zeroinitializer, %173
  %175 = icmp slt <4 x i32> %173, zeroinitializer
  %176 = select <4 x i1> %175, <4 x i32> %174, <4 x i32> %173
  %177 = icmp sgt <4 x i32> %30, %176
  %178 = icmp sgt <4 x i32> %30, %170
  %179 = or <4 x i1> %177, %178
  %180 = sext <4 x i1> %179 to <4 x i32>
  %181 = bitcast <4 x i32> %180 to <2 x i64>
  %182 = icmp sgt <4 x i32> %170, %176
  %183 = sext <4 x i1> %182 to <4 x i32>
  %184 = bitcast <4 x i32> %183 to <2 x i64>
  %185 = xor <2 x i64> %181, <i64 -1, i64 -1>
  %186 = and <2 x i64> %185, %172
  %187 = and <4 x i32> %26, %183
  %188 = bitcast <4 x i32> %187 to <2 x i64>
  %189 = xor <2 x i64> %184, <i64 -1, i64 -1>
  %190 = and <2 x i64> %189, %21
  %191 = or <2 x i64> %190, %188
  %192 = and <2 x i64> %191, %181
  %193 = or <2 x i64> %192, %186
  %194 = bitcast <2 x i64> %193 to <16 x i8>
  %195 = shufflevector <16 x i8> %194, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %196 = bitcast <16 x i8> %195 to <4 x i32>
  %197 = extractelement <4 x i32> %196, i32 0
  %198 = bitcast i8* %169 to i32*
  store i32 %197, i32* %198, align 1
  %199 = getelementptr inbounds i8, i8* %169, i64 %1
  %200 = shufflevector <4 x i32> %38, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %201 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %202 = bitcast <4 x i32> %201 to <2 x i64>
  %203 = add <4 x i32> %49, %201
  %204 = sub <4 x i32> zeroinitializer, %203
  %205 = icmp slt <4 x i32> %203, zeroinitializer
  %206 = select <4 x i1> %205, <4 x i32> %204, <4 x i32> %203
  %207 = icmp sgt <4 x i32> %30, %206
  %208 = icmp sgt <4 x i32> %30, %200
  %209 = or <4 x i1> %207, %208
  %210 = sext <4 x i1> %209 to <4 x i32>
  %211 = bitcast <4 x i32> %210 to <2 x i64>
  %212 = icmp sgt <4 x i32> %200, %206
  %213 = sext <4 x i1> %212 to <4 x i32>
  %214 = bitcast <4 x i32> %213 to <2 x i64>
  %215 = xor <2 x i64> %211, <i64 -1, i64 -1>
  %216 = and <2 x i64> %215, %202
  %217 = and <4 x i32> %26, %213
  %218 = bitcast <4 x i32> %217 to <2 x i64>
  %219 = xor <2 x i64> %214, <i64 -1, i64 -1>
  %220 = and <2 x i64> %219, %21
  %221 = or <2 x i64> %220, %218
  %222 = and <2 x i64> %221, %211
  %223 = or <2 x i64> %222, %216
  %224 = bitcast <2 x i64> %223 to <16 x i8>
  %225 = shufflevector <16 x i8> %224, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %226 = bitcast <16 x i8> %225 to <4 x i32>
  %227 = extractelement <4 x i32> %226, i32 0
  %228 = bitcast i8* %199 to i32*
  store i32 %227, i32* %228, align 1
  %229 = getelementptr inbounds i8, i8* %199, i64 %1
  %230 = shufflevector <4 x i32> %38, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %231 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %232 = bitcast <4 x i32> %231 to <2 x i64>
  %233 = add <4 x i32> %49, %231
  %234 = sub <4 x i32> zeroinitializer, %233
  %235 = icmp slt <4 x i32> %233, zeroinitializer
  %236 = select <4 x i1> %235, <4 x i32> %234, <4 x i32> %233
  %237 = icmp sgt <4 x i32> %30, %236
  %238 = icmp sgt <4 x i32> %30, %230
  %239 = or <4 x i1> %237, %238
  %240 = sext <4 x i1> %239 to <4 x i32>
  %241 = bitcast <4 x i32> %240 to <2 x i64>
  %242 = icmp sgt <4 x i32> %230, %236
  %243 = sext <4 x i1> %242 to <4 x i32>
  %244 = bitcast <4 x i32> %243 to <2 x i64>
  %245 = xor <2 x i64> %241, <i64 -1, i64 -1>
  %246 = and <2 x i64> %245, %232
  %247 = and <4 x i32> %26, %243
  %248 = bitcast <4 x i32> %247 to <2 x i64>
  %249 = xor <2 x i64> %244, <i64 -1, i64 -1>
  %250 = and <2 x i64> %249, %21
  %251 = or <2 x i64> %250, %248
  %252 = and <2 x i64> %251, %241
  %253 = or <2 x i64> %252, %246
  %254 = bitcast <2 x i64> %253 to <16 x i8>
  %255 = shufflevector <16 x i8> %254, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %256 = bitcast <16 x i8> %255 to <4 x i32>
  %257 = extractelement <4 x i32> %256, i32 0
  %258 = bitcast i8* %229 to i32*
  store i32 %257, i32* %258, align 1
  %259 = getelementptr inbounds i8, i8* %229, i64 %1
  %260 = shufflevector <4 x i32> %38, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %261 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %262 = bitcast <4 x i32> %261 to <2 x i64>
  %263 = add <4 x i32> %49, %261
  %264 = sub <4 x i32> zeroinitializer, %263
  %265 = icmp slt <4 x i32> %263, zeroinitializer
  %266 = select <4 x i1> %265, <4 x i32> %264, <4 x i32> %263
  %267 = icmp sgt <4 x i32> %30, %266
  %268 = icmp sgt <4 x i32> %30, %260
  %269 = or <4 x i1> %267, %268
  %270 = sext <4 x i1> %269 to <4 x i32>
  %271 = bitcast <4 x i32> %270 to <2 x i64>
  %272 = icmp sgt <4 x i32> %260, %266
  %273 = sext <4 x i1> %272 to <4 x i32>
  %274 = bitcast <4 x i32> %273 to <2 x i64>
  %275 = xor <2 x i64> %271, <i64 -1, i64 -1>
  %276 = and <2 x i64> %275, %262
  %277 = and <4 x i32> %26, %273
  %278 = bitcast <4 x i32> %277 to <2 x i64>
  %279 = xor <2 x i64> %274, <i64 -1, i64 -1>
  %280 = and <2 x i64> %279, %21
  %281 = or <2 x i64> %280, %278
  %282 = and <2 x i64> %281, %271
  %283 = or <2 x i64> %282, %276
  %284 = bitcast <2 x i64> %283 to <16 x i8>
  %285 = shufflevector <16 x i8> %284, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %286 = bitcast <16 x i8> %285 to <4 x i32>
  %287 = extractelement <4 x i32> %286, i32 0
  %288 = bitcast i8* %259 to i32*
  store i32 %287, i32* %288, align 1
  %289 = getelementptr inbounds i8, i8* %259, i64 %1
  %290 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> zeroinitializer
  %291 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> zeroinitializer
  %292 = bitcast <4 x i32> %291 to <2 x i64>
  %293 = add <4 x i32> %49, %291
  %294 = sub <4 x i32> zeroinitializer, %293
  %295 = icmp slt <4 x i32> %293, zeroinitializer
  %296 = select <4 x i1> %295, <4 x i32> %294, <4 x i32> %293
  %297 = icmp sgt <4 x i32> %30, %296
  %298 = icmp sgt <4 x i32> %30, %290
  %299 = or <4 x i1> %297, %298
  %300 = sext <4 x i1> %299 to <4 x i32>
  %301 = bitcast <4 x i32> %300 to <2 x i64>
  %302 = icmp sgt <4 x i32> %290, %296
  %303 = sext <4 x i1> %302 to <4 x i32>
  %304 = bitcast <4 x i32> %303 to <2 x i64>
  %305 = xor <2 x i64> %301, <i64 -1, i64 -1>
  %306 = and <2 x i64> %305, %292
  %307 = and <4 x i32> %26, %303
  %308 = bitcast <4 x i32> %307 to <2 x i64>
  %309 = xor <2 x i64> %304, <i64 -1, i64 -1>
  %310 = and <2 x i64> %309, %21
  %311 = or <2 x i64> %310, %308
  %312 = and <2 x i64> %311, %301
  %313 = or <2 x i64> %312, %306
  %314 = bitcast <2 x i64> %313 to <16 x i8>
  %315 = shufflevector <16 x i8> %314, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %316 = bitcast <16 x i8> %315 to <4 x i32>
  %317 = extractelement <4 x i32> %316, i32 0
  %318 = bitcast i8* %289 to i32*
  store i32 %317, i32* %318, align 1
  %319 = getelementptr inbounds i8, i8* %289, i64 %1
  %320 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %321 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %322 = bitcast <4 x i32> %321 to <2 x i64>
  %323 = add <4 x i32> %49, %321
  %324 = sub <4 x i32> zeroinitializer, %323
  %325 = icmp slt <4 x i32> %323, zeroinitializer
  %326 = select <4 x i1> %325, <4 x i32> %324, <4 x i32> %323
  %327 = icmp sgt <4 x i32> %30, %326
  %328 = icmp sgt <4 x i32> %30, %320
  %329 = or <4 x i1> %327, %328
  %330 = sext <4 x i1> %329 to <4 x i32>
  %331 = bitcast <4 x i32> %330 to <2 x i64>
  %332 = icmp sgt <4 x i32> %320, %326
  %333 = sext <4 x i1> %332 to <4 x i32>
  %334 = bitcast <4 x i32> %333 to <2 x i64>
  %335 = xor <2 x i64> %331, <i64 -1, i64 -1>
  %336 = and <2 x i64> %335, %322
  %337 = and <4 x i32> %26, %333
  %338 = bitcast <4 x i32> %337 to <2 x i64>
  %339 = xor <2 x i64> %334, <i64 -1, i64 -1>
  %340 = and <2 x i64> %339, %21
  %341 = or <2 x i64> %340, %338
  %342 = and <2 x i64> %341, %331
  %343 = or <2 x i64> %342, %336
  %344 = bitcast <2 x i64> %343 to <16 x i8>
  %345 = shufflevector <16 x i8> %344, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %346 = bitcast <16 x i8> %345 to <4 x i32>
  %347 = extractelement <4 x i32> %346, i32 0
  %348 = bitcast i8* %319 to i32*
  store i32 %347, i32* %348, align 1
  %349 = getelementptr inbounds i8, i8* %319, i64 %1
  %350 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %351 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %352 = bitcast <4 x i32> %351 to <2 x i64>
  %353 = add <4 x i32> %49, %351
  %354 = sub <4 x i32> zeroinitializer, %353
  %355 = icmp slt <4 x i32> %353, zeroinitializer
  %356 = select <4 x i1> %355, <4 x i32> %354, <4 x i32> %353
  %357 = icmp sgt <4 x i32> %30, %356
  %358 = icmp sgt <4 x i32> %30, %350
  %359 = or <4 x i1> %357, %358
  %360 = sext <4 x i1> %359 to <4 x i32>
  %361 = bitcast <4 x i32> %360 to <2 x i64>
  %362 = icmp sgt <4 x i32> %350, %356
  %363 = sext <4 x i1> %362 to <4 x i32>
  %364 = bitcast <4 x i32> %363 to <2 x i64>
  %365 = xor <2 x i64> %361, <i64 -1, i64 -1>
  %366 = and <2 x i64> %365, %352
  %367 = and <4 x i32> %26, %363
  %368 = bitcast <4 x i32> %367 to <2 x i64>
  %369 = xor <2 x i64> %364, <i64 -1, i64 -1>
  %370 = and <2 x i64> %369, %21
  %371 = or <2 x i64> %370, %368
  %372 = and <2 x i64> %371, %361
  %373 = or <2 x i64> %372, %366
  %374 = bitcast <2 x i64> %373 to <16 x i8>
  %375 = shufflevector <16 x i8> %374, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %376 = bitcast <16 x i8> %375 to <4 x i32>
  %377 = extractelement <4 x i32> %376, i32 0
  %378 = bitcast i8* %349 to i32*
  store i32 %377, i32* %378, align 1
  %379 = getelementptr inbounds i8, i8* %349, i64 %1
  %380 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %381 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %382 = bitcast <4 x i32> %381 to <2 x i64>
  %383 = add <4 x i32> %49, %381
  %384 = sub <4 x i32> zeroinitializer, %383
  %385 = icmp slt <4 x i32> %383, zeroinitializer
  %386 = select <4 x i1> %385, <4 x i32> %384, <4 x i32> %383
  %387 = icmp sgt <4 x i32> %30, %386
  %388 = icmp sgt <4 x i32> %30, %380
  %389 = or <4 x i1> %387, %388
  %390 = sext <4 x i1> %389 to <4 x i32>
  %391 = bitcast <4 x i32> %390 to <2 x i64>
  %392 = icmp sgt <4 x i32> %380, %386
  %393 = sext <4 x i1> %392 to <4 x i32>
  %394 = bitcast <4 x i32> %393 to <2 x i64>
  %395 = xor <2 x i64> %391, <i64 -1, i64 -1>
  %396 = and <2 x i64> %395, %382
  %397 = and <4 x i32> %26, %393
  %398 = bitcast <4 x i32> %397 to <2 x i64>
  %399 = xor <2 x i64> %394, <i64 -1, i64 -1>
  %400 = and <2 x i64> %399, %21
  %401 = or <2 x i64> %400, %398
  %402 = and <2 x i64> %401, %391
  %403 = or <2 x i64> %402, %396
  %404 = bitcast <2 x i64> %403 to <16 x i8>
  %405 = shufflevector <16 x i8> %404, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %406 = bitcast <16 x i8> %405 to <4 x i32>
  %407 = extractelement <4 x i32> %406, i32 0
  %408 = bitcast i8* %379 to i32*
  store i32 %407, i32* %408, align 1
  %409 = getelementptr inbounds i8, i8* %379, i64 %1
  %410 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> zeroinitializer
  %411 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> zeroinitializer
  %412 = bitcast <4 x i32> %411 to <2 x i64>
  %413 = add <4 x i32> %49, %411
  %414 = sub <4 x i32> zeroinitializer, %413
  %415 = icmp slt <4 x i32> %413, zeroinitializer
  %416 = select <4 x i1> %415, <4 x i32> %414, <4 x i32> %413
  %417 = icmp sgt <4 x i32> %30, %416
  %418 = icmp sgt <4 x i32> %30, %410
  %419 = or <4 x i1> %417, %418
  %420 = sext <4 x i1> %419 to <4 x i32>
  %421 = bitcast <4 x i32> %420 to <2 x i64>
  %422 = icmp sgt <4 x i32> %410, %416
  %423 = sext <4 x i1> %422 to <4 x i32>
  %424 = bitcast <4 x i32> %423 to <2 x i64>
  %425 = xor <2 x i64> %421, <i64 -1, i64 -1>
  %426 = and <2 x i64> %425, %412
  %427 = and <4 x i32> %26, %423
  %428 = bitcast <4 x i32> %427 to <2 x i64>
  %429 = xor <2 x i64> %424, <i64 -1, i64 -1>
  %430 = and <2 x i64> %429, %21
  %431 = or <2 x i64> %430, %428
  %432 = and <2 x i64> %431, %421
  %433 = or <2 x i64> %432, %426
  %434 = bitcast <2 x i64> %433 to <16 x i8>
  %435 = shufflevector <16 x i8> %434, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %436 = bitcast <16 x i8> %435 to <4 x i32>
  %437 = extractelement <4 x i32> %436, i32 0
  %438 = bitcast i8* %409 to i32*
  store i32 %437, i32* %438, align 1
  %439 = getelementptr inbounds i8, i8* %409, i64 %1
  %440 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %441 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 1, i32 1, i32 1, i32 1>
  %442 = bitcast <4 x i32> %441 to <2 x i64>
  %443 = add <4 x i32> %49, %441
  %444 = sub <4 x i32> zeroinitializer, %443
  %445 = icmp slt <4 x i32> %443, zeroinitializer
  %446 = select <4 x i1> %445, <4 x i32> %444, <4 x i32> %443
  %447 = icmp sgt <4 x i32> %30, %446
  %448 = icmp sgt <4 x i32> %30, %440
  %449 = or <4 x i1> %447, %448
  %450 = sext <4 x i1> %449 to <4 x i32>
  %451 = bitcast <4 x i32> %450 to <2 x i64>
  %452 = icmp sgt <4 x i32> %440, %446
  %453 = sext <4 x i1> %452 to <4 x i32>
  %454 = bitcast <4 x i32> %453 to <2 x i64>
  %455 = xor <2 x i64> %451, <i64 -1, i64 -1>
  %456 = and <2 x i64> %455, %442
  %457 = and <4 x i32> %26, %453
  %458 = bitcast <4 x i32> %457 to <2 x i64>
  %459 = xor <2 x i64> %454, <i64 -1, i64 -1>
  %460 = and <2 x i64> %459, %21
  %461 = or <2 x i64> %460, %458
  %462 = and <2 x i64> %461, %451
  %463 = or <2 x i64> %462, %456
  %464 = bitcast <2 x i64> %463 to <16 x i8>
  %465 = shufflevector <16 x i8> %464, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %466 = bitcast <16 x i8> %465 to <4 x i32>
  %467 = extractelement <4 x i32> %466, i32 0
  %468 = bitcast i8* %439 to i32*
  store i32 %467, i32* %468, align 1
  %469 = getelementptr inbounds i8, i8* %439, i64 %1
  %470 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %471 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 2, i32 2>
  %472 = bitcast <4 x i32> %471 to <2 x i64>
  %473 = add <4 x i32> %49, %471
  %474 = sub <4 x i32> zeroinitializer, %473
  %475 = icmp slt <4 x i32> %473, zeroinitializer
  %476 = select <4 x i1> %475, <4 x i32> %474, <4 x i32> %473
  %477 = icmp sgt <4 x i32> %30, %476
  %478 = icmp sgt <4 x i32> %30, %470
  %479 = or <4 x i1> %477, %478
  %480 = sext <4 x i1> %479 to <4 x i32>
  %481 = bitcast <4 x i32> %480 to <2 x i64>
  %482 = icmp sgt <4 x i32> %470, %476
  %483 = sext <4 x i1> %482 to <4 x i32>
  %484 = bitcast <4 x i32> %483 to <2 x i64>
  %485 = xor <2 x i64> %481, <i64 -1, i64 -1>
  %486 = and <2 x i64> %485, %472
  %487 = and <4 x i32> %26, %483
  %488 = bitcast <4 x i32> %487 to <2 x i64>
  %489 = xor <2 x i64> %484, <i64 -1, i64 -1>
  %490 = and <2 x i64> %489, %21
  %491 = or <2 x i64> %490, %488
  %492 = and <2 x i64> %491, %481
  %493 = or <2 x i64> %492, %486
  %494 = bitcast <2 x i64> %493 to <16 x i8>
  %495 = shufflevector <16 x i8> %494, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %496 = bitcast <16 x i8> %495 to <4 x i32>
  %497 = extractelement <4 x i32> %496, i32 0
  %498 = bitcast i8* %469 to i32*
  store i32 %497, i32* %498, align 1
  %499 = getelementptr inbounds i8, i8* %469, i64 %1
  %500 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %501 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 3, i32 3, i32 3, i32 3>
  %502 = bitcast <4 x i32> %501 to <2 x i64>
  %503 = add <4 x i32> %49, %501
  %504 = sub <4 x i32> zeroinitializer, %503
  %505 = icmp slt <4 x i32> %503, zeroinitializer
  %506 = select <4 x i1> %505, <4 x i32> %504, <4 x i32> %503
  %507 = icmp sgt <4 x i32> %30, %506
  %508 = icmp sgt <4 x i32> %30, %500
  %509 = or <4 x i1> %507, %508
  %510 = sext <4 x i1> %509 to <4 x i32>
  %511 = bitcast <4 x i32> %510 to <2 x i64>
  %512 = icmp sgt <4 x i32> %500, %506
  %513 = sext <4 x i1> %512 to <4 x i32>
  %514 = bitcast <4 x i32> %513 to <2 x i64>
  %515 = xor <2 x i64> %511, <i64 -1, i64 -1>
  %516 = and <2 x i64> %515, %502
  %517 = and <4 x i32> %26, %513
  %518 = bitcast <4 x i32> %517 to <2 x i64>
  %519 = xor <2 x i64> %514, <i64 -1, i64 -1>
  %520 = and <2 x i64> %519, %21
  %521 = or <2 x i64> %520, %518
  %522 = and <2 x i64> %521, %511
  %523 = or <2 x i64> %522, %516
  %524 = bitcast <2 x i64> %523 to <16 x i8>
  %525 = shufflevector <16 x i8> %524, <16 x i8> undef, <16 x i32> <i32 0, i32 4, i32 8, i32 12, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %526 = bitcast <16 x i8> %525 to <4 x i32>
  %527 = extractelement <4 x i32> %526, i32 0
  %528 = bitcast i8* %499 to i32*
  store i32 %527, i32* %528, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115Paeth8x4_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 undef, i32 undef>, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %10 = zext <8 x i8> %9 to <8 x i16>
  %11 = bitcast i8* %2 to i64*
  %12 = load i64, i64* %11, align 1
  %13 = insertelement <2 x i64> undef, i64 %12, i32 0
  %14 = bitcast <2 x i64> %13 to <16 x i8>
  %15 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = bitcast <8 x i16> %16 to <2 x i64>
  %18 = getelementptr inbounds i8, i8* %2, i64 -1
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i16
  %21 = insertelement <8 x i16> undef, i16 %20, i32 0
  %22 = shufflevector <8 x i16> %21, <8 x i16> undef, <8 x i32> zeroinitializer
  %23 = sub <8 x i16> %16, %22
  %24 = sub <8 x i16> zeroinitializer, %23
  %25 = icmp slt <8 x i16> %23, zeroinitializer
  %26 = select <8 x i1> %25, <8 x i16> %24, <8 x i16> %23
  %27 = sub <8 x i16> %10, %22
  %28 = sub <8 x i16> zeroinitializer, %27
  %29 = icmp slt <8 x i16> %27, zeroinitializer
  %30 = select <8 x i1> %29, <8 x i16> %28, <8 x i16> %27
  %31 = shl <8 x i16> %21, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %32 = shufflevector <8 x i16> %31, <8 x i16> undef, <8 x i32> zeroinitializer
  %33 = sub <8 x i16> %16, %32
  %34 = bitcast <8 x i16> %30 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %36 = bitcast <8 x i16> %10 to <16 x i8>
  %37 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %38 = bitcast <16 x i8> %37 to <2 x i64>
  %39 = bitcast <16 x i8> %37 to <8 x i16>
  %40 = add <8 x i16> %33, %39
  %41 = sub <8 x i16> zeroinitializer, %40
  %42 = icmp slt <8 x i16> %40, zeroinitializer
  %43 = select <8 x i1> %42, <8 x i16> %41, <8 x i16> %40
  %44 = icmp sgt <8 x i16> %26, %43
  %45 = bitcast <16 x i8> %35 to <8 x i16>
  %46 = icmp sgt <8 x i16> %26, %45
  %47 = or <8 x i1> %46, %44
  %48 = sext <8 x i1> %47 to <8 x i16>
  %49 = bitcast <8 x i16> %48 to <2 x i64>
  %50 = icmp slt <8 x i16> %43, %45
  %51 = sext <8 x i1> %50 to <8 x i16>
  %52 = bitcast <8 x i16> %51 to <2 x i64>
  %53 = xor <2 x i64> %49, <i64 -1, i64 -1>
  %54 = and <2 x i64> %53, %38
  %55 = and <8 x i16> %22, %51
  %56 = bitcast <8 x i16> %55 to <2 x i64>
  %57 = xor <2 x i64> %52, <i64 -1, i64 -1>
  %58 = and <2 x i64> %57, %17
  %59 = or <2 x i64> %58, %56
  %60 = and <2 x i64> %59, %49
  %61 = or <2 x i64> %60, %54
  %62 = bitcast <2 x i64> %61 to <8 x i16>
  %63 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %62, <8 x i16> undef) #11
  %64 = bitcast <16 x i8> %63 to <2 x i64>
  %65 = extractelement <2 x i64> %64, i32 0
  %66 = bitcast i8* %0 to i64*
  store i64 %65, i64* %66, align 1
  %67 = getelementptr inbounds i8, i8* %0, i64 %1
  %68 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %69 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %70 = bitcast <16 x i8> %69 to <2 x i64>
  %71 = bitcast <16 x i8> %69 to <8 x i16>
  %72 = add <8 x i16> %33, %71
  %73 = sub <8 x i16> zeroinitializer, %72
  %74 = icmp slt <8 x i16> %72, zeroinitializer
  %75 = select <8 x i1> %74, <8 x i16> %73, <8 x i16> %72
  %76 = icmp sgt <8 x i16> %26, %75
  %77 = bitcast <16 x i8> %68 to <8 x i16>
  %78 = icmp sgt <8 x i16> %26, %77
  %79 = or <8 x i1> %78, %76
  %80 = sext <8 x i1> %79 to <8 x i16>
  %81 = bitcast <8 x i16> %80 to <2 x i64>
  %82 = icmp slt <8 x i16> %75, %77
  %83 = sext <8 x i1> %82 to <8 x i16>
  %84 = bitcast <8 x i16> %83 to <2 x i64>
  %85 = xor <2 x i64> %81, <i64 -1, i64 -1>
  %86 = and <2 x i64> %85, %70
  %87 = and <8 x i16> %22, %83
  %88 = bitcast <8 x i16> %87 to <2 x i64>
  %89 = xor <2 x i64> %84, <i64 -1, i64 -1>
  %90 = and <2 x i64> %89, %17
  %91 = or <2 x i64> %90, %88
  %92 = and <2 x i64> %91, %81
  %93 = or <2 x i64> %92, %86
  %94 = bitcast <2 x i64> %93 to <8 x i16>
  %95 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %94, <8 x i16> undef) #11
  %96 = bitcast <16 x i8> %95 to <2 x i64>
  %97 = extractelement <2 x i64> %96, i32 0
  %98 = bitcast i8* %67 to i64*
  store i64 %97, i64* %98, align 1
  %99 = getelementptr inbounds i8, i8* %67, i64 %1
  %100 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %101 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %102 = bitcast <16 x i8> %101 to <2 x i64>
  %103 = bitcast <16 x i8> %101 to <8 x i16>
  %104 = add <8 x i16> %33, %103
  %105 = sub <8 x i16> zeroinitializer, %104
  %106 = icmp slt <8 x i16> %104, zeroinitializer
  %107 = select <8 x i1> %106, <8 x i16> %105, <8 x i16> %104
  %108 = icmp sgt <8 x i16> %26, %107
  %109 = bitcast <16 x i8> %100 to <8 x i16>
  %110 = icmp sgt <8 x i16> %26, %109
  %111 = or <8 x i1> %110, %108
  %112 = sext <8 x i1> %111 to <8 x i16>
  %113 = bitcast <8 x i16> %112 to <2 x i64>
  %114 = icmp slt <8 x i16> %107, %109
  %115 = sext <8 x i1> %114 to <8 x i16>
  %116 = bitcast <8 x i16> %115 to <2 x i64>
  %117 = xor <2 x i64> %113, <i64 -1, i64 -1>
  %118 = and <2 x i64> %117, %102
  %119 = and <8 x i16> %22, %115
  %120 = bitcast <8 x i16> %119 to <2 x i64>
  %121 = xor <2 x i64> %116, <i64 -1, i64 -1>
  %122 = and <2 x i64> %121, %17
  %123 = or <2 x i64> %122, %120
  %124 = and <2 x i64> %123, %113
  %125 = or <2 x i64> %124, %118
  %126 = bitcast <2 x i64> %125 to <8 x i16>
  %127 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %126, <8 x i16> undef) #11
  %128 = bitcast <16 x i8> %127 to <2 x i64>
  %129 = extractelement <2 x i64> %128, i32 0
  %130 = bitcast i8* %99 to i64*
  store i64 %129, i64* %130, align 1
  %131 = getelementptr inbounds i8, i8* %99, i64 %1
  %132 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %133 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %134 = bitcast <16 x i8> %133 to <2 x i64>
  %135 = bitcast <16 x i8> %133 to <8 x i16>
  %136 = add <8 x i16> %33, %135
  %137 = sub <8 x i16> zeroinitializer, %136
  %138 = icmp slt <8 x i16> %136, zeroinitializer
  %139 = select <8 x i1> %138, <8 x i16> %137, <8 x i16> %136
  %140 = icmp sgt <8 x i16> %26, %139
  %141 = bitcast <16 x i8> %132 to <8 x i16>
  %142 = icmp sgt <8 x i16> %26, %141
  %143 = or <8 x i1> %142, %140
  %144 = sext <8 x i1> %143 to <8 x i16>
  %145 = bitcast <8 x i16> %144 to <2 x i64>
  %146 = icmp slt <8 x i16> %139, %141
  %147 = sext <8 x i1> %146 to <8 x i16>
  %148 = bitcast <8 x i16> %147 to <2 x i64>
  %149 = xor <2 x i64> %145, <i64 -1, i64 -1>
  %150 = and <2 x i64> %149, %134
  %151 = and <8 x i16> %22, %147
  %152 = bitcast <8 x i16> %151 to <2 x i64>
  %153 = xor <2 x i64> %148, <i64 -1, i64 -1>
  %154 = and <2 x i64> %153, %17
  %155 = or <2 x i64> %154, %152
  %156 = and <2 x i64> %155, %145
  %157 = or <2 x i64> %156, %150
  %158 = bitcast <2 x i64> %157 to <8 x i16>
  %159 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %158, <8 x i16> undef) #11
  %160 = bitcast <16 x i8> %159 to <2 x i64>
  %161 = extractelement <2 x i64> %160, i32 0
  %162 = bitcast i8* %131 to i64*
  store i64 %161, i64* %162, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115Paeth8x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> undef, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %10 = zext <8 x i8> %9 to <8 x i16>
  %11 = bitcast i8* %2 to i64*
  %12 = load i64, i64* %11, align 1
  %13 = insertelement <2 x i64> undef, i64 %12, i32 0
  %14 = bitcast <2 x i64> %13 to <16 x i8>
  %15 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = bitcast <8 x i16> %16 to <2 x i64>
  %18 = getelementptr inbounds i8, i8* %2, i64 -1
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i16
  %21 = insertelement <8 x i16> undef, i16 %20, i32 0
  %22 = shufflevector <8 x i16> %21, <8 x i16> undef, <8 x i32> zeroinitializer
  %23 = sub <8 x i16> %16, %22
  %24 = sub <8 x i16> zeroinitializer, %23
  %25 = icmp slt <8 x i16> %23, zeroinitializer
  %26 = select <8 x i1> %25, <8 x i16> %24, <8 x i16> %23
  %27 = sub <8 x i16> %10, %22
  %28 = sub <8 x i16> zeroinitializer, %27
  %29 = icmp slt <8 x i16> %27, zeroinitializer
  %30 = select <8 x i1> %29, <8 x i16> %28, <8 x i16> %27
  %31 = shl <8 x i16> %21, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %32 = shufflevector <8 x i16> %31, <8 x i16> undef, <8 x i32> zeroinitializer
  %33 = sub <8 x i16> %16, %32
  %34 = bitcast <8 x i16> %30 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %36 = bitcast <8 x i16> %10 to <16 x i8>
  %37 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %38 = bitcast <16 x i8> %37 to <2 x i64>
  %39 = bitcast <16 x i8> %37 to <8 x i16>
  %40 = add <8 x i16> %33, %39
  %41 = sub <8 x i16> zeroinitializer, %40
  %42 = icmp slt <8 x i16> %40, zeroinitializer
  %43 = select <8 x i1> %42, <8 x i16> %41, <8 x i16> %40
  %44 = icmp sgt <8 x i16> %26, %43
  %45 = bitcast <16 x i8> %35 to <8 x i16>
  %46 = icmp sgt <8 x i16> %26, %45
  %47 = or <8 x i1> %46, %44
  %48 = sext <8 x i1> %47 to <8 x i16>
  %49 = bitcast <8 x i16> %48 to <2 x i64>
  %50 = icmp slt <8 x i16> %43, %45
  %51 = sext <8 x i1> %50 to <8 x i16>
  %52 = bitcast <8 x i16> %51 to <2 x i64>
  %53 = xor <2 x i64> %49, <i64 -1, i64 -1>
  %54 = and <2 x i64> %53, %38
  %55 = and <8 x i16> %22, %51
  %56 = bitcast <8 x i16> %55 to <2 x i64>
  %57 = xor <2 x i64> %52, <i64 -1, i64 -1>
  %58 = and <2 x i64> %57, %17
  %59 = or <2 x i64> %58, %56
  %60 = and <2 x i64> %59, %49
  %61 = or <2 x i64> %60, %54
  %62 = bitcast <2 x i64> %61 to <8 x i16>
  %63 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %62, <8 x i16> undef) #11
  %64 = bitcast <16 x i8> %63 to <2 x i64>
  %65 = extractelement <2 x i64> %64, i32 0
  %66 = bitcast i8* %0 to i64*
  store i64 %65, i64* %66, align 1
  %67 = getelementptr inbounds i8, i8* %0, i64 %1
  %68 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %69 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %70 = bitcast <16 x i8> %69 to <2 x i64>
  %71 = bitcast <16 x i8> %69 to <8 x i16>
  %72 = add <8 x i16> %33, %71
  %73 = sub <8 x i16> zeroinitializer, %72
  %74 = icmp slt <8 x i16> %72, zeroinitializer
  %75 = select <8 x i1> %74, <8 x i16> %73, <8 x i16> %72
  %76 = icmp sgt <8 x i16> %26, %75
  %77 = bitcast <16 x i8> %68 to <8 x i16>
  %78 = icmp sgt <8 x i16> %26, %77
  %79 = or <8 x i1> %78, %76
  %80 = sext <8 x i1> %79 to <8 x i16>
  %81 = bitcast <8 x i16> %80 to <2 x i64>
  %82 = icmp slt <8 x i16> %75, %77
  %83 = sext <8 x i1> %82 to <8 x i16>
  %84 = bitcast <8 x i16> %83 to <2 x i64>
  %85 = xor <2 x i64> %81, <i64 -1, i64 -1>
  %86 = and <2 x i64> %85, %70
  %87 = and <8 x i16> %22, %83
  %88 = bitcast <8 x i16> %87 to <2 x i64>
  %89 = xor <2 x i64> %84, <i64 -1, i64 -1>
  %90 = and <2 x i64> %89, %17
  %91 = or <2 x i64> %90, %88
  %92 = and <2 x i64> %91, %81
  %93 = or <2 x i64> %92, %86
  %94 = bitcast <2 x i64> %93 to <8 x i16>
  %95 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %94, <8 x i16> undef) #11
  %96 = bitcast <16 x i8> %95 to <2 x i64>
  %97 = extractelement <2 x i64> %96, i32 0
  %98 = bitcast i8* %67 to i64*
  store i64 %97, i64* %98, align 1
  %99 = getelementptr inbounds i8, i8* %67, i64 %1
  %100 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %101 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %102 = bitcast <16 x i8> %101 to <2 x i64>
  %103 = bitcast <16 x i8> %101 to <8 x i16>
  %104 = add <8 x i16> %33, %103
  %105 = sub <8 x i16> zeroinitializer, %104
  %106 = icmp slt <8 x i16> %104, zeroinitializer
  %107 = select <8 x i1> %106, <8 x i16> %105, <8 x i16> %104
  %108 = icmp sgt <8 x i16> %26, %107
  %109 = bitcast <16 x i8> %100 to <8 x i16>
  %110 = icmp sgt <8 x i16> %26, %109
  %111 = or <8 x i1> %110, %108
  %112 = sext <8 x i1> %111 to <8 x i16>
  %113 = bitcast <8 x i16> %112 to <2 x i64>
  %114 = icmp slt <8 x i16> %107, %109
  %115 = sext <8 x i1> %114 to <8 x i16>
  %116 = bitcast <8 x i16> %115 to <2 x i64>
  %117 = xor <2 x i64> %113, <i64 -1, i64 -1>
  %118 = and <2 x i64> %117, %102
  %119 = and <8 x i16> %22, %115
  %120 = bitcast <8 x i16> %119 to <2 x i64>
  %121 = xor <2 x i64> %116, <i64 -1, i64 -1>
  %122 = and <2 x i64> %121, %17
  %123 = or <2 x i64> %122, %120
  %124 = and <2 x i64> %123, %113
  %125 = or <2 x i64> %124, %118
  %126 = bitcast <2 x i64> %125 to <8 x i16>
  %127 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %126, <8 x i16> undef) #11
  %128 = bitcast <16 x i8> %127 to <2 x i64>
  %129 = extractelement <2 x i64> %128, i32 0
  %130 = bitcast i8* %99 to i64*
  store i64 %129, i64* %130, align 1
  %131 = getelementptr inbounds i8, i8* %99, i64 %1
  %132 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %133 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %134 = bitcast <16 x i8> %133 to <2 x i64>
  %135 = bitcast <16 x i8> %133 to <8 x i16>
  %136 = add <8 x i16> %33, %135
  %137 = sub <8 x i16> zeroinitializer, %136
  %138 = icmp slt <8 x i16> %136, zeroinitializer
  %139 = select <8 x i1> %138, <8 x i16> %137, <8 x i16> %136
  %140 = icmp sgt <8 x i16> %26, %139
  %141 = bitcast <16 x i8> %132 to <8 x i16>
  %142 = icmp sgt <8 x i16> %26, %141
  %143 = or <8 x i1> %142, %140
  %144 = sext <8 x i1> %143 to <8 x i16>
  %145 = bitcast <8 x i16> %144 to <2 x i64>
  %146 = icmp slt <8 x i16> %139, %141
  %147 = sext <8 x i1> %146 to <8 x i16>
  %148 = bitcast <8 x i16> %147 to <2 x i64>
  %149 = xor <2 x i64> %145, <i64 -1, i64 -1>
  %150 = and <2 x i64> %149, %134
  %151 = and <8 x i16> %22, %147
  %152 = bitcast <8 x i16> %151 to <2 x i64>
  %153 = xor <2 x i64> %148, <i64 -1, i64 -1>
  %154 = and <2 x i64> %153, %17
  %155 = or <2 x i64> %154, %152
  %156 = and <2 x i64> %155, %145
  %157 = or <2 x i64> %156, %150
  %158 = bitcast <2 x i64> %157 to <8 x i16>
  %159 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %158, <8 x i16> undef) #11
  %160 = bitcast <16 x i8> %159 to <2 x i64>
  %161 = extractelement <2 x i64> %160, i32 0
  %162 = bitcast i8* %131 to i64*
  store i64 %161, i64* %162, align 1
  %163 = getelementptr inbounds i8, i8* %131, i64 %1
  %164 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %165 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %166 = bitcast <16 x i8> %165 to <2 x i64>
  %167 = bitcast <16 x i8> %165 to <8 x i16>
  %168 = add <8 x i16> %33, %167
  %169 = sub <8 x i16> zeroinitializer, %168
  %170 = icmp slt <8 x i16> %168, zeroinitializer
  %171 = select <8 x i1> %170, <8 x i16> %169, <8 x i16> %168
  %172 = icmp sgt <8 x i16> %26, %171
  %173 = bitcast <16 x i8> %164 to <8 x i16>
  %174 = icmp sgt <8 x i16> %26, %173
  %175 = or <8 x i1> %174, %172
  %176 = sext <8 x i1> %175 to <8 x i16>
  %177 = bitcast <8 x i16> %176 to <2 x i64>
  %178 = icmp slt <8 x i16> %171, %173
  %179 = sext <8 x i1> %178 to <8 x i16>
  %180 = bitcast <8 x i16> %179 to <2 x i64>
  %181 = xor <2 x i64> %177, <i64 -1, i64 -1>
  %182 = and <2 x i64> %181, %166
  %183 = and <8 x i16> %22, %179
  %184 = bitcast <8 x i16> %183 to <2 x i64>
  %185 = xor <2 x i64> %180, <i64 -1, i64 -1>
  %186 = and <2 x i64> %185, %17
  %187 = or <2 x i64> %186, %184
  %188 = and <2 x i64> %187, %177
  %189 = or <2 x i64> %188, %182
  %190 = bitcast <2 x i64> %189 to <8 x i16>
  %191 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %190, <8 x i16> undef) #11
  %192 = bitcast <16 x i8> %191 to <2 x i64>
  %193 = extractelement <2 x i64> %192, i32 0
  %194 = bitcast i8* %163 to i64*
  store i64 %193, i64* %194, align 1
  %195 = getelementptr inbounds i8, i8* %163, i64 %1
  %196 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %197 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %198 = bitcast <16 x i8> %197 to <2 x i64>
  %199 = bitcast <16 x i8> %197 to <8 x i16>
  %200 = add <8 x i16> %33, %199
  %201 = sub <8 x i16> zeroinitializer, %200
  %202 = icmp slt <8 x i16> %200, zeroinitializer
  %203 = select <8 x i1> %202, <8 x i16> %201, <8 x i16> %200
  %204 = icmp sgt <8 x i16> %26, %203
  %205 = bitcast <16 x i8> %196 to <8 x i16>
  %206 = icmp sgt <8 x i16> %26, %205
  %207 = or <8 x i1> %206, %204
  %208 = sext <8 x i1> %207 to <8 x i16>
  %209 = bitcast <8 x i16> %208 to <2 x i64>
  %210 = icmp slt <8 x i16> %203, %205
  %211 = sext <8 x i1> %210 to <8 x i16>
  %212 = bitcast <8 x i16> %211 to <2 x i64>
  %213 = xor <2 x i64> %209, <i64 -1, i64 -1>
  %214 = and <2 x i64> %213, %198
  %215 = and <8 x i16> %22, %211
  %216 = bitcast <8 x i16> %215 to <2 x i64>
  %217 = xor <2 x i64> %212, <i64 -1, i64 -1>
  %218 = and <2 x i64> %217, %17
  %219 = or <2 x i64> %218, %216
  %220 = and <2 x i64> %219, %209
  %221 = or <2 x i64> %220, %214
  %222 = bitcast <2 x i64> %221 to <8 x i16>
  %223 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %222, <8 x i16> undef) #11
  %224 = bitcast <16 x i8> %223 to <2 x i64>
  %225 = extractelement <2 x i64> %224, i32 0
  %226 = bitcast i8* %195 to i64*
  store i64 %225, i64* %226, align 1
  %227 = getelementptr inbounds i8, i8* %195, i64 %1
  %228 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %229 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %230 = bitcast <16 x i8> %229 to <2 x i64>
  %231 = bitcast <16 x i8> %229 to <8 x i16>
  %232 = add <8 x i16> %33, %231
  %233 = sub <8 x i16> zeroinitializer, %232
  %234 = icmp slt <8 x i16> %232, zeroinitializer
  %235 = select <8 x i1> %234, <8 x i16> %233, <8 x i16> %232
  %236 = icmp sgt <8 x i16> %26, %235
  %237 = bitcast <16 x i8> %228 to <8 x i16>
  %238 = icmp sgt <8 x i16> %26, %237
  %239 = or <8 x i1> %238, %236
  %240 = sext <8 x i1> %239 to <8 x i16>
  %241 = bitcast <8 x i16> %240 to <2 x i64>
  %242 = icmp slt <8 x i16> %235, %237
  %243 = sext <8 x i1> %242 to <8 x i16>
  %244 = bitcast <8 x i16> %243 to <2 x i64>
  %245 = xor <2 x i64> %241, <i64 -1, i64 -1>
  %246 = and <2 x i64> %245, %230
  %247 = and <8 x i16> %22, %243
  %248 = bitcast <8 x i16> %247 to <2 x i64>
  %249 = xor <2 x i64> %244, <i64 -1, i64 -1>
  %250 = and <2 x i64> %249, %17
  %251 = or <2 x i64> %250, %248
  %252 = and <2 x i64> %251, %241
  %253 = or <2 x i64> %252, %246
  %254 = bitcast <2 x i64> %253 to <8 x i16>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %254, <8 x i16> undef) #11
  %256 = bitcast <16 x i8> %255 to <2 x i64>
  %257 = extractelement <2 x i64> %256, i32 0
  %258 = bitcast i8* %227 to i64*
  store i64 %257, i64* %258, align 1
  %259 = getelementptr inbounds i8, i8* %227, i64 %1
  %260 = shufflevector <16 x i8> %34, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %261 = shufflevector <16 x i8> %36, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %262 = bitcast <16 x i8> %261 to <2 x i64>
  %263 = bitcast <16 x i8> %261 to <8 x i16>
  %264 = add <8 x i16> %33, %263
  %265 = sub <8 x i16> zeroinitializer, %264
  %266 = icmp slt <8 x i16> %264, zeroinitializer
  %267 = select <8 x i1> %266, <8 x i16> %265, <8 x i16> %264
  %268 = icmp sgt <8 x i16> %26, %267
  %269 = bitcast <16 x i8> %260 to <8 x i16>
  %270 = icmp sgt <8 x i16> %26, %269
  %271 = or <8 x i1> %270, %268
  %272 = sext <8 x i1> %271 to <8 x i16>
  %273 = bitcast <8 x i16> %272 to <2 x i64>
  %274 = icmp slt <8 x i16> %267, %269
  %275 = sext <8 x i1> %274 to <8 x i16>
  %276 = bitcast <8 x i16> %275 to <2 x i64>
  %277 = xor <2 x i64> %273, <i64 -1, i64 -1>
  %278 = and <2 x i64> %277, %262
  %279 = and <8 x i16> %22, %275
  %280 = bitcast <8 x i16> %279 to <2 x i64>
  %281 = xor <2 x i64> %276, <i64 -1, i64 -1>
  %282 = and <2 x i64> %281, %17
  %283 = or <2 x i64> %282, %280
  %284 = and <2 x i64> %283, %273
  %285 = or <2 x i64> %284, %278
  %286 = bitcast <2 x i64> %285 to <8 x i16>
  %287 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %286, <8 x i16> undef) #11
  %288 = bitcast <16 x i8> %287 to <2 x i64>
  %289 = extractelement <2 x i64> %288, i32 0
  %290 = bitcast i8* %259 to i64*
  store i64 %289, i64* %290, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth8x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = shufflevector <16 x i8> %6, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %8 = zext <8 x i8> %7 to <8 x i16>
  %9 = shufflevector <16 x i8> %6, <16 x i8> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %10 = zext <8 x i8> %9 to <8 x i16>
  %11 = bitcast i8* %2 to i64*
  %12 = load i64, i64* %11, align 1
  %13 = insertelement <2 x i64> undef, i64 %12, i32 0
  %14 = bitcast <2 x i64> %13 to <16 x i8>
  %15 = shufflevector <16 x i8> %14, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %16 = zext <8 x i8> %15 to <8 x i16>
  %17 = bitcast <8 x i16> %16 to <2 x i64>
  %18 = getelementptr inbounds i8, i8* %2, i64 -1
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i16
  %21 = insertelement <8 x i16> undef, i16 %20, i32 0
  %22 = shufflevector <8 x i16> %21, <8 x i16> undef, <8 x i32> zeroinitializer
  %23 = sub <8 x i16> %16, %22
  %24 = sub <8 x i16> zeroinitializer, %23
  %25 = icmp slt <8 x i16> %23, zeroinitializer
  %26 = select <8 x i1> %25, <8 x i16> %24, <8 x i16> %23
  %27 = sub <8 x i16> %8, %22
  %28 = sub <8 x i16> zeroinitializer, %27
  %29 = icmp slt <8 x i16> %27, zeroinitializer
  %30 = select <8 x i1> %29, <8 x i16> %28, <8 x i16> %27
  %31 = sub <8 x i16> %10, %22
  %32 = sub <8 x i16> zeroinitializer, %31
  %33 = icmp slt <8 x i16> %31, zeroinitializer
  %34 = select <8 x i1> %33, <8 x i16> %32, <8 x i16> %31
  %35 = shl <8 x i16> %21, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %36 = shufflevector <8 x i16> %35, <8 x i16> undef, <8 x i32> zeroinitializer
  %37 = sub <8 x i16> %16, %36
  %38 = bitcast <8 x i16> %30 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %40 = bitcast <8 x i16> %8 to <16 x i8>
  %41 = shufflevector <16 x i8> %40, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = bitcast <16 x i8> %41 to <8 x i16>
  %44 = add <8 x i16> %37, %43
  %45 = sub <8 x i16> zeroinitializer, %44
  %46 = icmp slt <8 x i16> %44, zeroinitializer
  %47 = select <8 x i1> %46, <8 x i16> %45, <8 x i16> %44
  %48 = icmp sgt <8 x i16> %26, %47
  %49 = bitcast <16 x i8> %39 to <8 x i16>
  %50 = icmp sgt <8 x i16> %26, %49
  %51 = or <8 x i1> %50, %48
  %52 = sext <8 x i1> %51 to <8 x i16>
  %53 = bitcast <8 x i16> %52 to <2 x i64>
  %54 = icmp slt <8 x i16> %47, %49
  %55 = sext <8 x i1> %54 to <8 x i16>
  %56 = bitcast <8 x i16> %55 to <2 x i64>
  %57 = xor <2 x i64> %53, <i64 -1, i64 -1>
  %58 = and <2 x i64> %57, %42
  %59 = and <8 x i16> %22, %55
  %60 = bitcast <8 x i16> %59 to <2 x i64>
  %61 = xor <2 x i64> %56, <i64 -1, i64 -1>
  %62 = and <2 x i64> %61, %17
  %63 = or <2 x i64> %62, %60
  %64 = and <2 x i64> %63, %53
  %65 = or <2 x i64> %64, %58
  %66 = bitcast <2 x i64> %65 to <8 x i16>
  %67 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %66, <8 x i16> undef) #11
  %68 = bitcast <16 x i8> %67 to <2 x i64>
  %69 = extractelement <2 x i64> %68, i32 0
  %70 = bitcast i8* %0 to i64*
  store i64 %69, i64* %70, align 1
  %71 = getelementptr inbounds i8, i8* %0, i64 %1
  %72 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %73 = shufflevector <16 x i8> %40, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %74 = bitcast <16 x i8> %73 to <2 x i64>
  %75 = bitcast <16 x i8> %73 to <8 x i16>
  %76 = add <8 x i16> %37, %75
  %77 = sub <8 x i16> zeroinitializer, %76
  %78 = icmp slt <8 x i16> %76, zeroinitializer
  %79 = select <8 x i1> %78, <8 x i16> %77, <8 x i16> %76
  %80 = icmp sgt <8 x i16> %26, %79
  %81 = bitcast <16 x i8> %72 to <8 x i16>
  %82 = icmp sgt <8 x i16> %26, %81
  %83 = or <8 x i1> %82, %80
  %84 = sext <8 x i1> %83 to <8 x i16>
  %85 = bitcast <8 x i16> %84 to <2 x i64>
  %86 = icmp slt <8 x i16> %79, %81
  %87 = sext <8 x i1> %86 to <8 x i16>
  %88 = bitcast <8 x i16> %87 to <2 x i64>
  %89 = xor <2 x i64> %85, <i64 -1, i64 -1>
  %90 = and <2 x i64> %89, %74
  %91 = and <8 x i16> %22, %87
  %92 = bitcast <8 x i16> %91 to <2 x i64>
  %93 = xor <2 x i64> %88, <i64 -1, i64 -1>
  %94 = and <2 x i64> %93, %17
  %95 = or <2 x i64> %94, %92
  %96 = and <2 x i64> %95, %85
  %97 = or <2 x i64> %96, %90
  %98 = bitcast <2 x i64> %97 to <8 x i16>
  %99 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %98, <8 x i16> undef) #11
  %100 = bitcast <16 x i8> %99 to <2 x i64>
  %101 = extractelement <2 x i64> %100, i32 0
  %102 = bitcast i8* %71 to i64*
  store i64 %101, i64* %102, align 1
  %103 = getelementptr inbounds i8, i8* %71, i64 %1
  %104 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %105 = shufflevector <16 x i8> %40, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %106 = bitcast <16 x i8> %105 to <2 x i64>
  %107 = bitcast <16 x i8> %105 to <8 x i16>
  %108 = add <8 x i16> %37, %107
  %109 = sub <8 x i16> zeroinitializer, %108
  %110 = icmp slt <8 x i16> %108, zeroinitializer
  %111 = select <8 x i1> %110, <8 x i16> %109, <8 x i16> %108
  %112 = icmp sgt <8 x i16> %26, %111
  %113 = bitcast <16 x i8> %104 to <8 x i16>
  %114 = icmp sgt <8 x i16> %26, %113
  %115 = or <8 x i1> %114, %112
  %116 = sext <8 x i1> %115 to <8 x i16>
  %117 = bitcast <8 x i16> %116 to <2 x i64>
  %118 = icmp slt <8 x i16> %111, %113
  %119 = sext <8 x i1> %118 to <8 x i16>
  %120 = bitcast <8 x i16> %119 to <2 x i64>
  %121 = xor <2 x i64> %117, <i64 -1, i64 -1>
  %122 = and <2 x i64> %121, %106
  %123 = and <8 x i16> %22, %119
  %124 = bitcast <8 x i16> %123 to <2 x i64>
  %125 = xor <2 x i64> %120, <i64 -1, i64 -1>
  %126 = and <2 x i64> %125, %17
  %127 = or <2 x i64> %126, %124
  %128 = and <2 x i64> %127, %117
  %129 = or <2 x i64> %128, %122
  %130 = bitcast <2 x i64> %129 to <8 x i16>
  %131 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %130, <8 x i16> undef) #11
  %132 = bitcast <16 x i8> %131 to <2 x i64>
  %133 = extractelement <2 x i64> %132, i32 0
  %134 = bitcast i8* %103 to i64*
  store i64 %133, i64* %134, align 1
  %135 = getelementptr inbounds i8, i8* %103, i64 %1
  %136 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %137 = shufflevector <16 x i8> %40, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %138 = bitcast <16 x i8> %137 to <2 x i64>
  %139 = bitcast <16 x i8> %137 to <8 x i16>
  %140 = add <8 x i16> %37, %139
  %141 = sub <8 x i16> zeroinitializer, %140
  %142 = icmp slt <8 x i16> %140, zeroinitializer
  %143 = select <8 x i1> %142, <8 x i16> %141, <8 x i16> %140
  %144 = icmp sgt <8 x i16> %26, %143
  %145 = bitcast <16 x i8> %136 to <8 x i16>
  %146 = icmp sgt <8 x i16> %26, %145
  %147 = or <8 x i1> %146, %144
  %148 = sext <8 x i1> %147 to <8 x i16>
  %149 = bitcast <8 x i16> %148 to <2 x i64>
  %150 = icmp slt <8 x i16> %143, %145
  %151 = sext <8 x i1> %150 to <8 x i16>
  %152 = bitcast <8 x i16> %151 to <2 x i64>
  %153 = xor <2 x i64> %149, <i64 -1, i64 -1>
  %154 = and <2 x i64> %153, %138
  %155 = and <8 x i16> %22, %151
  %156 = bitcast <8 x i16> %155 to <2 x i64>
  %157 = xor <2 x i64> %152, <i64 -1, i64 -1>
  %158 = and <2 x i64> %157, %17
  %159 = or <2 x i64> %158, %156
  %160 = and <2 x i64> %159, %149
  %161 = or <2 x i64> %160, %154
  %162 = bitcast <2 x i64> %161 to <8 x i16>
  %163 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %162, <8 x i16> undef) #11
  %164 = bitcast <16 x i8> %163 to <2 x i64>
  %165 = extractelement <2 x i64> %164, i32 0
  %166 = bitcast i8* %135 to i64*
  store i64 %165, i64* %166, align 1
  %167 = getelementptr inbounds i8, i8* %135, i64 %1
  %168 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %169 = shufflevector <16 x i8> %40, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %170 = bitcast <16 x i8> %169 to <2 x i64>
  %171 = bitcast <16 x i8> %169 to <8 x i16>
  %172 = add <8 x i16> %37, %171
  %173 = sub <8 x i16> zeroinitializer, %172
  %174 = icmp slt <8 x i16> %172, zeroinitializer
  %175 = select <8 x i1> %174, <8 x i16> %173, <8 x i16> %172
  %176 = icmp sgt <8 x i16> %26, %175
  %177 = bitcast <16 x i8> %168 to <8 x i16>
  %178 = icmp sgt <8 x i16> %26, %177
  %179 = or <8 x i1> %178, %176
  %180 = sext <8 x i1> %179 to <8 x i16>
  %181 = bitcast <8 x i16> %180 to <2 x i64>
  %182 = icmp slt <8 x i16> %175, %177
  %183 = sext <8 x i1> %182 to <8 x i16>
  %184 = bitcast <8 x i16> %183 to <2 x i64>
  %185 = xor <2 x i64> %181, <i64 -1, i64 -1>
  %186 = and <2 x i64> %185, %170
  %187 = and <8 x i16> %22, %183
  %188 = bitcast <8 x i16> %187 to <2 x i64>
  %189 = xor <2 x i64> %184, <i64 -1, i64 -1>
  %190 = and <2 x i64> %189, %17
  %191 = or <2 x i64> %190, %188
  %192 = and <2 x i64> %191, %181
  %193 = or <2 x i64> %192, %186
  %194 = bitcast <2 x i64> %193 to <8 x i16>
  %195 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %194, <8 x i16> undef) #11
  %196 = bitcast <16 x i8> %195 to <2 x i64>
  %197 = extractelement <2 x i64> %196, i32 0
  %198 = bitcast i8* %167 to i64*
  store i64 %197, i64* %198, align 1
  %199 = getelementptr inbounds i8, i8* %167, i64 %1
  %200 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %201 = shufflevector <16 x i8> %40, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %202 = bitcast <16 x i8> %201 to <2 x i64>
  %203 = bitcast <16 x i8> %201 to <8 x i16>
  %204 = add <8 x i16> %37, %203
  %205 = sub <8 x i16> zeroinitializer, %204
  %206 = icmp slt <8 x i16> %204, zeroinitializer
  %207 = select <8 x i1> %206, <8 x i16> %205, <8 x i16> %204
  %208 = icmp sgt <8 x i16> %26, %207
  %209 = bitcast <16 x i8> %200 to <8 x i16>
  %210 = icmp sgt <8 x i16> %26, %209
  %211 = or <8 x i1> %210, %208
  %212 = sext <8 x i1> %211 to <8 x i16>
  %213 = bitcast <8 x i16> %212 to <2 x i64>
  %214 = icmp slt <8 x i16> %207, %209
  %215 = sext <8 x i1> %214 to <8 x i16>
  %216 = bitcast <8 x i16> %215 to <2 x i64>
  %217 = xor <2 x i64> %213, <i64 -1, i64 -1>
  %218 = and <2 x i64> %217, %202
  %219 = and <8 x i16> %22, %215
  %220 = bitcast <8 x i16> %219 to <2 x i64>
  %221 = xor <2 x i64> %216, <i64 -1, i64 -1>
  %222 = and <2 x i64> %221, %17
  %223 = or <2 x i64> %222, %220
  %224 = and <2 x i64> %223, %213
  %225 = or <2 x i64> %224, %218
  %226 = bitcast <2 x i64> %225 to <8 x i16>
  %227 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %226, <8 x i16> undef) #11
  %228 = bitcast <16 x i8> %227 to <2 x i64>
  %229 = extractelement <2 x i64> %228, i32 0
  %230 = bitcast i8* %199 to i64*
  store i64 %229, i64* %230, align 1
  %231 = getelementptr inbounds i8, i8* %199, i64 %1
  %232 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %233 = shufflevector <16 x i8> %40, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %234 = bitcast <16 x i8> %233 to <2 x i64>
  %235 = bitcast <16 x i8> %233 to <8 x i16>
  %236 = add <8 x i16> %37, %235
  %237 = sub <8 x i16> zeroinitializer, %236
  %238 = icmp slt <8 x i16> %236, zeroinitializer
  %239 = select <8 x i1> %238, <8 x i16> %237, <8 x i16> %236
  %240 = icmp sgt <8 x i16> %26, %239
  %241 = bitcast <16 x i8> %232 to <8 x i16>
  %242 = icmp sgt <8 x i16> %26, %241
  %243 = or <8 x i1> %242, %240
  %244 = sext <8 x i1> %243 to <8 x i16>
  %245 = bitcast <8 x i16> %244 to <2 x i64>
  %246 = icmp slt <8 x i16> %239, %241
  %247 = sext <8 x i1> %246 to <8 x i16>
  %248 = bitcast <8 x i16> %247 to <2 x i64>
  %249 = xor <2 x i64> %245, <i64 -1, i64 -1>
  %250 = and <2 x i64> %249, %234
  %251 = and <8 x i16> %22, %247
  %252 = bitcast <8 x i16> %251 to <2 x i64>
  %253 = xor <2 x i64> %248, <i64 -1, i64 -1>
  %254 = and <2 x i64> %253, %17
  %255 = or <2 x i64> %254, %252
  %256 = and <2 x i64> %255, %245
  %257 = or <2 x i64> %256, %250
  %258 = bitcast <2 x i64> %257 to <8 x i16>
  %259 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %258, <8 x i16> undef) #11
  %260 = bitcast <16 x i8> %259 to <2 x i64>
  %261 = extractelement <2 x i64> %260, i32 0
  %262 = bitcast i8* %231 to i64*
  store i64 %261, i64* %262, align 1
  %263 = getelementptr inbounds i8, i8* %231, i64 %1
  %264 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %265 = shufflevector <16 x i8> %40, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %266 = bitcast <16 x i8> %265 to <2 x i64>
  %267 = bitcast <16 x i8> %265 to <8 x i16>
  %268 = add <8 x i16> %37, %267
  %269 = sub <8 x i16> zeroinitializer, %268
  %270 = icmp slt <8 x i16> %268, zeroinitializer
  %271 = select <8 x i1> %270, <8 x i16> %269, <8 x i16> %268
  %272 = icmp sgt <8 x i16> %26, %271
  %273 = bitcast <16 x i8> %264 to <8 x i16>
  %274 = icmp sgt <8 x i16> %26, %273
  %275 = or <8 x i1> %274, %272
  %276 = sext <8 x i1> %275 to <8 x i16>
  %277 = bitcast <8 x i16> %276 to <2 x i64>
  %278 = icmp slt <8 x i16> %271, %273
  %279 = sext <8 x i1> %278 to <8 x i16>
  %280 = bitcast <8 x i16> %279 to <2 x i64>
  %281 = xor <2 x i64> %277, <i64 -1, i64 -1>
  %282 = and <2 x i64> %281, %266
  %283 = and <8 x i16> %22, %279
  %284 = bitcast <8 x i16> %283 to <2 x i64>
  %285 = xor <2 x i64> %280, <i64 -1, i64 -1>
  %286 = and <2 x i64> %285, %17
  %287 = or <2 x i64> %286, %284
  %288 = and <2 x i64> %287, %277
  %289 = or <2 x i64> %288, %282
  %290 = bitcast <2 x i64> %289 to <8 x i16>
  %291 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %290, <8 x i16> undef) #11
  %292 = bitcast <16 x i8> %291 to <2 x i64>
  %293 = extractelement <2 x i64> %292, i32 0
  %294 = bitcast i8* %263 to i64*
  store i64 %293, i64* %294, align 1
  %295 = getelementptr inbounds i8, i8* %263, i64 %1
  %296 = bitcast <8 x i16> %34 to <16 x i8>
  %297 = shufflevector <16 x i8> %296, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %298 = bitcast <8 x i16> %10 to <16 x i8>
  %299 = shufflevector <16 x i8> %298, <16 x i8> undef, <16 x i32> <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
  %300 = bitcast <16 x i8> %299 to <2 x i64>
  %301 = bitcast <16 x i8> %299 to <8 x i16>
  %302 = add <8 x i16> %37, %301
  %303 = sub <8 x i16> zeroinitializer, %302
  %304 = icmp slt <8 x i16> %302, zeroinitializer
  %305 = select <8 x i1> %304, <8 x i16> %303, <8 x i16> %302
  %306 = icmp sgt <8 x i16> %26, %305
  %307 = bitcast <16 x i8> %297 to <8 x i16>
  %308 = icmp sgt <8 x i16> %26, %307
  %309 = or <8 x i1> %308, %306
  %310 = sext <8 x i1> %309 to <8 x i16>
  %311 = bitcast <8 x i16> %310 to <2 x i64>
  %312 = icmp slt <8 x i16> %305, %307
  %313 = sext <8 x i1> %312 to <8 x i16>
  %314 = bitcast <8 x i16> %313 to <2 x i64>
  %315 = xor <2 x i64> %311, <i64 -1, i64 -1>
  %316 = and <2 x i64> %315, %300
  %317 = and <8 x i16> %22, %313
  %318 = bitcast <8 x i16> %317 to <2 x i64>
  %319 = xor <2 x i64> %314, <i64 -1, i64 -1>
  %320 = and <2 x i64> %319, %17
  %321 = or <2 x i64> %320, %318
  %322 = and <2 x i64> %321, %311
  %323 = or <2 x i64> %322, %316
  %324 = bitcast <2 x i64> %323 to <8 x i16>
  %325 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %324, <8 x i16> undef) #11
  %326 = bitcast <16 x i8> %325 to <2 x i64>
  %327 = extractelement <2 x i64> %326, i32 0
  %328 = bitcast i8* %295 to i64*
  store i64 %327, i64* %328, align 1
  %329 = getelementptr inbounds i8, i8* %295, i64 %1
  %330 = shufflevector <16 x i8> %296, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %331 = shufflevector <16 x i8> %298, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3, i32 2, i32 3>
  %332 = bitcast <16 x i8> %331 to <2 x i64>
  %333 = bitcast <16 x i8> %331 to <8 x i16>
  %334 = add <8 x i16> %37, %333
  %335 = sub <8 x i16> zeroinitializer, %334
  %336 = icmp slt <8 x i16> %334, zeroinitializer
  %337 = select <8 x i1> %336, <8 x i16> %335, <8 x i16> %334
  %338 = icmp sgt <8 x i16> %26, %337
  %339 = bitcast <16 x i8> %330 to <8 x i16>
  %340 = icmp sgt <8 x i16> %26, %339
  %341 = or <8 x i1> %340, %338
  %342 = sext <8 x i1> %341 to <8 x i16>
  %343 = bitcast <8 x i16> %342 to <2 x i64>
  %344 = icmp slt <8 x i16> %337, %339
  %345 = sext <8 x i1> %344 to <8 x i16>
  %346 = bitcast <8 x i16> %345 to <2 x i64>
  %347 = xor <2 x i64> %343, <i64 -1, i64 -1>
  %348 = and <2 x i64> %347, %332
  %349 = and <8 x i16> %22, %345
  %350 = bitcast <8 x i16> %349 to <2 x i64>
  %351 = xor <2 x i64> %346, <i64 -1, i64 -1>
  %352 = and <2 x i64> %351, %17
  %353 = or <2 x i64> %352, %350
  %354 = and <2 x i64> %353, %343
  %355 = or <2 x i64> %354, %348
  %356 = bitcast <2 x i64> %355 to <8 x i16>
  %357 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %356, <8 x i16> undef) #11
  %358 = bitcast <16 x i8> %357 to <2 x i64>
  %359 = extractelement <2 x i64> %358, i32 0
  %360 = bitcast i8* %329 to i64*
  store i64 %359, i64* %360, align 1
  %361 = getelementptr inbounds i8, i8* %329, i64 %1
  %362 = shufflevector <16 x i8> %296, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %363 = shufflevector <16 x i8> %298, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5, i32 4, i32 5>
  %364 = bitcast <16 x i8> %363 to <2 x i64>
  %365 = bitcast <16 x i8> %363 to <8 x i16>
  %366 = add <8 x i16> %37, %365
  %367 = sub <8 x i16> zeroinitializer, %366
  %368 = icmp slt <8 x i16> %366, zeroinitializer
  %369 = select <8 x i1> %368, <8 x i16> %367, <8 x i16> %366
  %370 = icmp sgt <8 x i16> %26, %369
  %371 = bitcast <16 x i8> %362 to <8 x i16>
  %372 = icmp sgt <8 x i16> %26, %371
  %373 = or <8 x i1> %372, %370
  %374 = sext <8 x i1> %373 to <8 x i16>
  %375 = bitcast <8 x i16> %374 to <2 x i64>
  %376 = icmp slt <8 x i16> %369, %371
  %377 = sext <8 x i1> %376 to <8 x i16>
  %378 = bitcast <8 x i16> %377 to <2 x i64>
  %379 = xor <2 x i64> %375, <i64 -1, i64 -1>
  %380 = and <2 x i64> %379, %364
  %381 = and <8 x i16> %22, %377
  %382 = bitcast <8 x i16> %381 to <2 x i64>
  %383 = xor <2 x i64> %378, <i64 -1, i64 -1>
  %384 = and <2 x i64> %383, %17
  %385 = or <2 x i64> %384, %382
  %386 = and <2 x i64> %385, %375
  %387 = or <2 x i64> %386, %380
  %388 = bitcast <2 x i64> %387 to <8 x i16>
  %389 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %388, <8 x i16> undef) #11
  %390 = bitcast <16 x i8> %389 to <2 x i64>
  %391 = extractelement <2 x i64> %390, i32 0
  %392 = bitcast i8* %361 to i64*
  store i64 %391, i64* %392, align 1
  %393 = getelementptr inbounds i8, i8* %361, i64 %1
  %394 = shufflevector <16 x i8> %296, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %395 = shufflevector <16 x i8> %298, <16 x i8> undef, <16 x i32> <i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7, i32 6, i32 7>
  %396 = bitcast <16 x i8> %395 to <2 x i64>
  %397 = bitcast <16 x i8> %395 to <8 x i16>
  %398 = add <8 x i16> %37, %397
  %399 = sub <8 x i16> zeroinitializer, %398
  %400 = icmp slt <8 x i16> %398, zeroinitializer
  %401 = select <8 x i1> %400, <8 x i16> %399, <8 x i16> %398
  %402 = icmp sgt <8 x i16> %26, %401
  %403 = bitcast <16 x i8> %394 to <8 x i16>
  %404 = icmp sgt <8 x i16> %26, %403
  %405 = or <8 x i1> %404, %402
  %406 = sext <8 x i1> %405 to <8 x i16>
  %407 = bitcast <8 x i16> %406 to <2 x i64>
  %408 = icmp slt <8 x i16> %401, %403
  %409 = sext <8 x i1> %408 to <8 x i16>
  %410 = bitcast <8 x i16> %409 to <2 x i64>
  %411 = xor <2 x i64> %407, <i64 -1, i64 -1>
  %412 = and <2 x i64> %411, %396
  %413 = and <8 x i16> %22, %409
  %414 = bitcast <8 x i16> %413 to <2 x i64>
  %415 = xor <2 x i64> %410, <i64 -1, i64 -1>
  %416 = and <2 x i64> %415, %17
  %417 = or <2 x i64> %416, %414
  %418 = and <2 x i64> %417, %407
  %419 = or <2 x i64> %418, %412
  %420 = bitcast <2 x i64> %419 to <8 x i16>
  %421 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %420, <8 x i16> undef) #11
  %422 = bitcast <16 x i8> %421 to <2 x i64>
  %423 = extractelement <2 x i64> %422, i32 0
  %424 = bitcast i8* %393 to i64*
  store i64 %423, i64* %424, align 1
  %425 = getelementptr inbounds i8, i8* %393, i64 %1
  %426 = shufflevector <16 x i8> %296, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %427 = shufflevector <16 x i8> %298, <16 x i8> undef, <16 x i32> <i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9, i32 8, i32 9>
  %428 = bitcast <16 x i8> %427 to <2 x i64>
  %429 = bitcast <16 x i8> %427 to <8 x i16>
  %430 = add <8 x i16> %37, %429
  %431 = sub <8 x i16> zeroinitializer, %430
  %432 = icmp slt <8 x i16> %430, zeroinitializer
  %433 = select <8 x i1> %432, <8 x i16> %431, <8 x i16> %430
  %434 = icmp sgt <8 x i16> %26, %433
  %435 = bitcast <16 x i8> %426 to <8 x i16>
  %436 = icmp sgt <8 x i16> %26, %435
  %437 = or <8 x i1> %436, %434
  %438 = sext <8 x i1> %437 to <8 x i16>
  %439 = bitcast <8 x i16> %438 to <2 x i64>
  %440 = icmp slt <8 x i16> %433, %435
  %441 = sext <8 x i1> %440 to <8 x i16>
  %442 = bitcast <8 x i16> %441 to <2 x i64>
  %443 = xor <2 x i64> %439, <i64 -1, i64 -1>
  %444 = and <2 x i64> %443, %428
  %445 = and <8 x i16> %22, %441
  %446 = bitcast <8 x i16> %445 to <2 x i64>
  %447 = xor <2 x i64> %442, <i64 -1, i64 -1>
  %448 = and <2 x i64> %447, %17
  %449 = or <2 x i64> %448, %446
  %450 = and <2 x i64> %449, %439
  %451 = or <2 x i64> %450, %444
  %452 = bitcast <2 x i64> %451 to <8 x i16>
  %453 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %452, <8 x i16> undef) #11
  %454 = bitcast <16 x i8> %453 to <2 x i64>
  %455 = extractelement <2 x i64> %454, i32 0
  %456 = bitcast i8* %425 to i64*
  store i64 %455, i64* %456, align 1
  %457 = getelementptr inbounds i8, i8* %425, i64 %1
  %458 = shufflevector <16 x i8> %296, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %459 = shufflevector <16 x i8> %298, <16 x i8> undef, <16 x i32> <i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11, i32 10, i32 11>
  %460 = bitcast <16 x i8> %459 to <2 x i64>
  %461 = bitcast <16 x i8> %459 to <8 x i16>
  %462 = add <8 x i16> %37, %461
  %463 = sub <8 x i16> zeroinitializer, %462
  %464 = icmp slt <8 x i16> %462, zeroinitializer
  %465 = select <8 x i1> %464, <8 x i16> %463, <8 x i16> %462
  %466 = icmp sgt <8 x i16> %26, %465
  %467 = bitcast <16 x i8> %458 to <8 x i16>
  %468 = icmp sgt <8 x i16> %26, %467
  %469 = or <8 x i1> %468, %466
  %470 = sext <8 x i1> %469 to <8 x i16>
  %471 = bitcast <8 x i16> %470 to <2 x i64>
  %472 = icmp slt <8 x i16> %465, %467
  %473 = sext <8 x i1> %472 to <8 x i16>
  %474 = bitcast <8 x i16> %473 to <2 x i64>
  %475 = xor <2 x i64> %471, <i64 -1, i64 -1>
  %476 = and <2 x i64> %475, %460
  %477 = and <8 x i16> %22, %473
  %478 = bitcast <8 x i16> %477 to <2 x i64>
  %479 = xor <2 x i64> %474, <i64 -1, i64 -1>
  %480 = and <2 x i64> %479, %17
  %481 = or <2 x i64> %480, %478
  %482 = and <2 x i64> %481, %471
  %483 = or <2 x i64> %482, %476
  %484 = bitcast <2 x i64> %483 to <8 x i16>
  %485 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %484, <8 x i16> undef) #11
  %486 = bitcast <16 x i8> %485 to <2 x i64>
  %487 = extractelement <2 x i64> %486, i32 0
  %488 = bitcast i8* %457 to i64*
  store i64 %487, i64* %488, align 1
  %489 = getelementptr inbounds i8, i8* %457, i64 %1
  %490 = shufflevector <16 x i8> %296, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %491 = shufflevector <16 x i8> %298, <16 x i8> undef, <16 x i32> <i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13, i32 12, i32 13>
  %492 = bitcast <16 x i8> %491 to <2 x i64>
  %493 = bitcast <16 x i8> %491 to <8 x i16>
  %494 = add <8 x i16> %37, %493
  %495 = sub <8 x i16> zeroinitializer, %494
  %496 = icmp slt <8 x i16> %494, zeroinitializer
  %497 = select <8 x i1> %496, <8 x i16> %495, <8 x i16> %494
  %498 = icmp sgt <8 x i16> %26, %497
  %499 = bitcast <16 x i8> %490 to <8 x i16>
  %500 = icmp sgt <8 x i16> %26, %499
  %501 = or <8 x i1> %500, %498
  %502 = sext <8 x i1> %501 to <8 x i16>
  %503 = bitcast <8 x i16> %502 to <2 x i64>
  %504 = icmp slt <8 x i16> %497, %499
  %505 = sext <8 x i1> %504 to <8 x i16>
  %506 = bitcast <8 x i16> %505 to <2 x i64>
  %507 = xor <2 x i64> %503, <i64 -1, i64 -1>
  %508 = and <2 x i64> %507, %492
  %509 = and <8 x i16> %22, %505
  %510 = bitcast <8 x i16> %509 to <2 x i64>
  %511 = xor <2 x i64> %506, <i64 -1, i64 -1>
  %512 = and <2 x i64> %511, %17
  %513 = or <2 x i64> %512, %510
  %514 = and <2 x i64> %513, %503
  %515 = or <2 x i64> %514, %508
  %516 = bitcast <2 x i64> %515 to <8 x i16>
  %517 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %516, <8 x i16> undef) #11
  %518 = bitcast <16 x i8> %517 to <2 x i64>
  %519 = extractelement <2 x i64> %518, i32 0
  %520 = bitcast i8* %489 to i64*
  store i64 %519, i64* %520, align 1
  %521 = getelementptr inbounds i8, i8* %489, i64 %1
  %522 = shufflevector <16 x i8> %296, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %523 = shufflevector <16 x i8> %298, <16 x i8> undef, <16 x i32> <i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15, i32 14, i32 15>
  %524 = bitcast <16 x i8> %523 to <2 x i64>
  %525 = bitcast <16 x i8> %523 to <8 x i16>
  %526 = add <8 x i16> %37, %525
  %527 = sub <8 x i16> zeroinitializer, %526
  %528 = icmp slt <8 x i16> %526, zeroinitializer
  %529 = select <8 x i1> %528, <8 x i16> %527, <8 x i16> %526
  %530 = icmp sgt <8 x i16> %26, %529
  %531 = bitcast <16 x i8> %522 to <8 x i16>
  %532 = icmp sgt <8 x i16> %26, %531
  %533 = or <8 x i1> %532, %530
  %534 = sext <8 x i1> %533 to <8 x i16>
  %535 = bitcast <8 x i16> %534 to <2 x i64>
  %536 = icmp slt <8 x i16> %529, %531
  %537 = sext <8 x i1> %536 to <8 x i16>
  %538 = bitcast <8 x i16> %537 to <2 x i64>
  %539 = xor <2 x i64> %535, <i64 -1, i64 -1>
  %540 = and <2 x i64> %539, %524
  %541 = and <8 x i16> %22, %537
  %542 = bitcast <8 x i16> %541 to <2 x i64>
  %543 = xor <2 x i64> %538, <i64 -1, i64 -1>
  %544 = and <2 x i64> %543, %17
  %545 = or <2 x i64> %544, %542
  %546 = and <2 x i64> %545, %535
  %547 = or <2 x i64> %546, %540
  %548 = bitcast <2 x i64> %547 to <8 x i16>
  %549 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %548, <8 x i16> undef) #11
  %550 = bitcast <16 x i8> %549 to <2 x i64>
  %551 = extractelement <2 x i64> %550, i32 0
  %552 = bitcast i8* %521 to i64*
  store i64 %551, i64* %552, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth8x32_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #0 {
  tail call void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth8x16_SSE4_1EPvlPKvS5_(i8* %0, i64 %1, i8* %2, i8* %3)
  %5 = shl i64 %1, 4
  %6 = getelementptr inbounds i8, i8* %0, i64 %5
  %7 = getelementptr inbounds i8, i8* %3, i64 16
  tail call void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth8x16_SSE4_1EPvlPKvS5_(i8* %6, i64 %1, i8* %2, i8* %7)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth16x4_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %6, i32 0
  %8 = bitcast i8* %2 to <2 x i64>*
  %9 = load <2 x i64>, <2 x i64>* %8, align 1
  %10 = bitcast <2 x i64> %9 to <16 x i8>
  %11 = shufflevector <16 x i8> %10, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %12 = zext <8 x i8> %11 to <8 x i16>
  %13 = shufflevector <16 x i8> %10, <16 x i8> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %14 = zext <8 x i8> %13 to <8 x i16>
  %15 = getelementptr inbounds i8, i8* %2, i64 -1
  %16 = load i8, i8* %15, align 1
  %17 = zext i8 %16 to i16
  %18 = insertelement <8 x i16> undef, i16 %17, i32 0
  %19 = insertelement <16 x i8> undef, i8 %16, i32 0
  %20 = shufflevector <16 x i8> %19, <16 x i8> undef, <16 x i32> zeroinitializer
  %21 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %10, <16 x i8> %20) #11
  %22 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %20, <16 x i8> %10) #11
  %23 = or <16 x i8> %22, %21
  %24 = shufflevector <16 x i8> %23, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %25 = zext <8 x i8> %24 to <8 x i16>
  %26 = shufflevector <16 x i8> %23, <16 x i8> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %27 = zext <8 x i8> %26 to <8 x i16>
  %28 = bitcast <4 x i32> %7 to <16 x i8>
  %29 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %28, <16 x i8> %20) #11
  %30 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %20, <16 x i8> %28) #11
  %31 = or <16 x i8> %30, %29
  %32 = shl <8 x i16> %18, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %33 = shufflevector <8 x i16> %32, <8 x i16> undef, <8 x i32> zeroinitializer
  %34 = sub <8 x i16> %12, %33
  %35 = sub <8 x i16> %14, %33
  %36 = shufflevector <16 x i8> %31, <16 x i8> undef, <16 x i32> zeroinitializer
  %37 = shufflevector <16 x i8> %31, <16 x i8> undef, <8 x i32> zeroinitializer
  %38 = zext <8 x i8> %37 to <8 x i16>
  %39 = shufflevector <16 x i8> %28, <16 x i8> undef, <16 x i32> zeroinitializer
  %40 = bitcast <16 x i8> %39 to <2 x i64>
  %41 = shufflevector <16 x i8> %28, <16 x i8> undef, <8 x i32> zeroinitializer
  %42 = zext <8 x i8> %41 to <8 x i16>
  %43 = add <8 x i16> %34, %42
  %44 = sub <8 x i16> zeroinitializer, %43
  %45 = icmp slt <8 x i16> %43, zeroinitializer
  %46 = select <8 x i1> %45, <8 x i16> %44, <8 x i16> %43
  %47 = add <8 x i16> %35, %42
  %48 = sub <8 x i16> zeroinitializer, %47
  %49 = icmp slt <8 x i16> %47, zeroinitializer
  %50 = select <8 x i1> %49, <8 x i16> %48, <8 x i16> %47
  %51 = icmp slt <8 x i16> %46, %25
  %52 = sext <8 x i1> %51 to <8 x i16>
  %53 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %52, <8 x i16> undef) #11
  %54 = icmp slt <8 x i16> %50, %27
  %55 = sext <8 x i1> %54 to <8 x i16>
  %56 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %55, <8 x i16> undef) #11
  %57 = shufflevector <16 x i8> %53, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %58 = shufflevector <16 x i8> %57, <16 x i8> %56, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %59 = bitcast <16 x i8> %58 to <2 x i64>
  %60 = icmp slt <8 x i16> %46, %38
  %61 = sext <8 x i1> %60 to <8 x i16>
  %62 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %61, <8 x i16> undef) #11
  %63 = icmp slt <8 x i16> %50, %38
  %64 = sext <8 x i1> %63 to <8 x i16>
  %65 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %64, <8 x i16> undef) #11
  %66 = shufflevector <16 x i8> %62, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %67 = shufflevector <16 x i8> %66, <16 x i8> %65, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %68 = bitcast <16 x i8> %67 to <2 x i64>
  %69 = icmp ule <16 x i8> %23, %36
  %70 = sext <16 x i1> %69 to <16 x i8>
  %71 = bitcast <16 x i8> %70 to <2 x i64>
  %72 = xor <2 x i64> %59, <i64 -1, i64 -1>
  %73 = and <2 x i64> %71, %72
  %74 = and <2 x i64> %73, %40
  %75 = and <16 x i8> %67, %20
  %76 = bitcast <16 x i8> %75 to <2 x i64>
  %77 = xor <2 x i64> %68, <i64 -1, i64 -1>
  %78 = and <2 x i64> %9, %77
  %79 = or <2 x i64> %78, %76
  %80 = xor <2 x i64> %73, <i64 -1, i64 -1>
  %81 = and <2 x i64> %79, %80
  %82 = or <2 x i64> %81, %74
  %83 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %82, <2 x i64>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %0, i64 %1
  %85 = shufflevector <16 x i8> %31, <16 x i8> undef, <16 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %86 = shufflevector <16 x i8> %31, <16 x i8> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %87 = zext <8 x i8> %86 to <8 x i16>
  %88 = shufflevector <16 x i8> %28, <16 x i8> undef, <16 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %89 = bitcast <16 x i8> %88 to <2 x i64>
  %90 = shufflevector <16 x i8> %28, <16 x i8> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %91 = zext <8 x i8> %90 to <8 x i16>
  %92 = add <8 x i16> %34, %91
  %93 = sub <8 x i16> zeroinitializer, %92
  %94 = icmp slt <8 x i16> %92, zeroinitializer
  %95 = select <8 x i1> %94, <8 x i16> %93, <8 x i16> %92
  %96 = add <8 x i16> %35, %91
  %97 = sub <8 x i16> zeroinitializer, %96
  %98 = icmp slt <8 x i16> %96, zeroinitializer
  %99 = select <8 x i1> %98, <8 x i16> %97, <8 x i16> %96
  %100 = icmp slt <8 x i16> %95, %25
  %101 = sext <8 x i1> %100 to <8 x i16>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %101, <8 x i16> undef) #11
  %103 = icmp slt <8 x i16> %99, %27
  %104 = sext <8 x i1> %103 to <8 x i16>
  %105 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %104, <8 x i16> undef) #11
  %106 = shufflevector <16 x i8> %102, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %107 = shufflevector <16 x i8> %106, <16 x i8> %105, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %108 = bitcast <16 x i8> %107 to <2 x i64>
  %109 = icmp slt <8 x i16> %95, %87
  %110 = sext <8 x i1> %109 to <8 x i16>
  %111 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %110, <8 x i16> undef) #11
  %112 = icmp slt <8 x i16> %99, %87
  %113 = sext <8 x i1> %112 to <8 x i16>
  %114 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %113, <8 x i16> undef) #11
  %115 = shufflevector <16 x i8> %111, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %116 = shufflevector <16 x i8> %115, <16 x i8> %114, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %117 = bitcast <16 x i8> %116 to <2 x i64>
  %118 = icmp ule <16 x i8> %23, %85
  %119 = sext <16 x i1> %118 to <16 x i8>
  %120 = bitcast <16 x i8> %119 to <2 x i64>
  %121 = xor <2 x i64> %108, <i64 -1, i64 -1>
  %122 = and <2 x i64> %121, %120
  %123 = and <2 x i64> %122, %89
  %124 = and <16 x i8> %116, %20
  %125 = bitcast <16 x i8> %124 to <2 x i64>
  %126 = xor <2 x i64> %117, <i64 -1, i64 -1>
  %127 = and <2 x i64> %9, %126
  %128 = or <2 x i64> %127, %125
  %129 = xor <2 x i64> %122, <i64 -1, i64 -1>
  %130 = and <2 x i64> %128, %129
  %131 = or <2 x i64> %130, %123
  %132 = bitcast i8* %84 to <2 x i64>*
  store <2 x i64> %131, <2 x i64>* %132, align 1
  %133 = getelementptr inbounds i8, i8* %84, i64 %1
  %134 = shufflevector <16 x i8> %31, <16 x i8> undef, <16 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %135 = shufflevector <16 x i8> %31, <16 x i8> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %136 = zext <8 x i8> %135 to <8 x i16>
  %137 = shufflevector <16 x i8> %28, <16 x i8> undef, <16 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %138 = bitcast <16 x i8> %137 to <2 x i64>
  %139 = shufflevector <16 x i8> %28, <16 x i8> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %140 = zext <8 x i8> %139 to <8 x i16>
  %141 = add <8 x i16> %34, %140
  %142 = sub <8 x i16> zeroinitializer, %141
  %143 = icmp slt <8 x i16> %141, zeroinitializer
  %144 = select <8 x i1> %143, <8 x i16> %142, <8 x i16> %141
  %145 = add <8 x i16> %35, %140
  %146 = sub <8 x i16> zeroinitializer, %145
  %147 = icmp slt <8 x i16> %145, zeroinitializer
  %148 = select <8 x i1> %147, <8 x i16> %146, <8 x i16> %145
  %149 = icmp slt <8 x i16> %144, %25
  %150 = sext <8 x i1> %149 to <8 x i16>
  %151 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %150, <8 x i16> undef) #11
  %152 = icmp slt <8 x i16> %148, %27
  %153 = sext <8 x i1> %152 to <8 x i16>
  %154 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %153, <8 x i16> undef) #11
  %155 = shufflevector <16 x i8> %151, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %156 = shufflevector <16 x i8> %155, <16 x i8> %154, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %157 = bitcast <16 x i8> %156 to <2 x i64>
  %158 = icmp slt <8 x i16> %144, %136
  %159 = sext <8 x i1> %158 to <8 x i16>
  %160 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %159, <8 x i16> undef) #11
  %161 = icmp slt <8 x i16> %148, %136
  %162 = sext <8 x i1> %161 to <8 x i16>
  %163 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %162, <8 x i16> undef) #11
  %164 = shufflevector <16 x i8> %160, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %165 = shufflevector <16 x i8> %164, <16 x i8> %163, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %166 = bitcast <16 x i8> %165 to <2 x i64>
  %167 = icmp ule <16 x i8> %23, %134
  %168 = sext <16 x i1> %167 to <16 x i8>
  %169 = bitcast <16 x i8> %168 to <2 x i64>
  %170 = xor <2 x i64> %157, <i64 -1, i64 -1>
  %171 = and <2 x i64> %170, %169
  %172 = and <2 x i64> %171, %138
  %173 = and <16 x i8> %165, %20
  %174 = bitcast <16 x i8> %173 to <2 x i64>
  %175 = xor <2 x i64> %166, <i64 -1, i64 -1>
  %176 = and <2 x i64> %9, %175
  %177 = or <2 x i64> %176, %174
  %178 = xor <2 x i64> %171, <i64 -1, i64 -1>
  %179 = and <2 x i64> %177, %178
  %180 = or <2 x i64> %179, %172
  %181 = bitcast i8* %133 to <2 x i64>*
  store <2 x i64> %180, <2 x i64>* %181, align 1
  %182 = getelementptr inbounds i8, i8* %133, i64 %1
  %183 = shufflevector <16 x i8> %31, <16 x i8> undef, <16 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %184 = shufflevector <16 x i8> %31, <16 x i8> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %185 = zext <8 x i8> %184 to <8 x i16>
  %186 = shufflevector <16 x i8> %28, <16 x i8> undef, <16 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %187 = bitcast <16 x i8> %186 to <2 x i64>
  %188 = shufflevector <16 x i8> %28, <16 x i8> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %189 = zext <8 x i8> %188 to <8 x i16>
  %190 = add <8 x i16> %34, %189
  %191 = sub <8 x i16> zeroinitializer, %190
  %192 = icmp slt <8 x i16> %190, zeroinitializer
  %193 = select <8 x i1> %192, <8 x i16> %191, <8 x i16> %190
  %194 = add <8 x i16> %35, %189
  %195 = sub <8 x i16> zeroinitializer, %194
  %196 = icmp slt <8 x i16> %194, zeroinitializer
  %197 = select <8 x i1> %196, <8 x i16> %195, <8 x i16> %194
  %198 = icmp slt <8 x i16> %193, %25
  %199 = sext <8 x i1> %198 to <8 x i16>
  %200 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %199, <8 x i16> undef) #11
  %201 = icmp slt <8 x i16> %197, %27
  %202 = sext <8 x i1> %201 to <8 x i16>
  %203 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %202, <8 x i16> undef) #11
  %204 = shufflevector <16 x i8> %200, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %205 = shufflevector <16 x i8> %204, <16 x i8> %203, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %206 = bitcast <16 x i8> %205 to <2 x i64>
  %207 = icmp slt <8 x i16> %193, %185
  %208 = sext <8 x i1> %207 to <8 x i16>
  %209 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %208, <8 x i16> undef) #11
  %210 = icmp slt <8 x i16> %197, %185
  %211 = sext <8 x i1> %210 to <8 x i16>
  %212 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %211, <8 x i16> undef) #11
  %213 = shufflevector <16 x i8> %209, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %214 = shufflevector <16 x i8> %213, <16 x i8> %212, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %215 = bitcast <16 x i8> %214 to <2 x i64>
  %216 = icmp ule <16 x i8> %23, %183
  %217 = sext <16 x i1> %216 to <16 x i8>
  %218 = bitcast <16 x i8> %217 to <2 x i64>
  %219 = xor <2 x i64> %206, <i64 -1, i64 -1>
  %220 = and <2 x i64> %219, %218
  %221 = and <2 x i64> %220, %187
  %222 = and <16 x i8> %214, %20
  %223 = bitcast <16 x i8> %222 to <2 x i64>
  %224 = xor <2 x i64> %215, <i64 -1, i64 -1>
  %225 = and <2 x i64> %9, %224
  %226 = or <2 x i64> %225, %223
  %227 = xor <2 x i64> %220, <i64 -1, i64 -1>
  %228 = and <2 x i64> %226, %227
  %229 = or <2 x i64> %228, %221
  %230 = bitcast i8* %182 to <2 x i64>*
  store <2 x i64> %229, <2 x i64>* %230, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth16x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %2 to <2 x i64>*
  %6 = load <2 x i64>, <2 x i64>* %5, align 1
  %7 = bitcast i8* %3 to i64*
  %8 = load i64, i64* %7, align 1
  %9 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %8, i32 0
  %10 = getelementptr inbounds i8, i8* %2, i64 -1
  %11 = load i8, i8* %10, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114WritePaeth16x8EPvlhDv2_xS4_(i8* %0, i64 %1, i8 zeroext %11, <2 x i64> %6, <2 x i64> %9)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth16x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to <2 x i64>*
  %6 = load <2 x i64>, <2 x i64>* %5, align 1
  %7 = bitcast i8* %2 to <2 x i64>*
  %8 = load <2 x i64>, <2 x i64>* %7, align 1
  %9 = getelementptr inbounds i8, i8* %2, i64 -1
  %10 = load i8, i8* %9, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %0, i64 %1, i8 zeroext %10, <2 x i64> %8, <2 x i64> %6)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth16x32_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to <2 x i64>*
  %6 = load <2 x i64>, <2 x i64>* %5, align 1
  %7 = bitcast i8* %2 to <2 x i64>*
  %8 = load <2 x i64>, <2 x i64>* %7, align 1
  %9 = getelementptr inbounds i8, i8* %2, i64 -1
  %10 = load i8, i8* %9, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %0, i64 %1, i8 zeroext %10, <2 x i64> %8, <2 x i64> %6)
  %11 = getelementptr inbounds i8, i8* %3, i64 16
  %12 = bitcast i8* %11 to <2 x i64>*
  %13 = load <2 x i64>, <2 x i64>* %12, align 1
  %14 = shl i64 %1, 4
  %15 = getelementptr inbounds i8, i8* %0, i64 %14
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %15, i64 %1, i8 zeroext %10, <2 x i64> %8, <2 x i64> %13)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth16x64_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = shl i64 %1, 4
  %6 = bitcast i8* %3 to <2 x i64>*
  %7 = load <2 x i64>, <2 x i64>* %6, align 1
  %8 = bitcast i8* %2 to <2 x i64>*
  %9 = load <2 x i64>, <2 x i64>* %8, align 1
  %10 = getelementptr inbounds i8, i8* %2, i64 -1
  %11 = load i8, i8* %10, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %0, i64 %1, i8 zeroext %11, <2 x i64> %9, <2 x i64> %7)
  %12 = getelementptr inbounds i8, i8* %0, i64 %5
  %13 = getelementptr inbounds i8, i8* %3, i64 16
  %14 = bitcast i8* %13 to <2 x i64>*
  %15 = load <2 x i64>, <2 x i64>* %14, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %12, i64 %1, i8 zeroext %11, <2 x i64> %9, <2 x i64> %15)
  %16 = getelementptr inbounds i8, i8* %12, i64 %5
  %17 = getelementptr inbounds i8, i8* %3, i64 32
  %18 = bitcast i8* %17 to <2 x i64>*
  %19 = load <2 x i64>, <2 x i64>* %18, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %16, i64 %1, i8 zeroext %11, <2 x i64> %9, <2 x i64> %19)
  %20 = getelementptr inbounds i8, i8* %16, i64 %5
  %21 = getelementptr inbounds i8, i8* %3, i64 48
  %22 = bitcast i8* %21 to <2 x i64>*
  %23 = load <2 x i64>, <2 x i64>* %22, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %20, i64 %1, i8 zeroext %11, <2 x i64> %9, <2 x i64> %23)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_116Paeth32x8_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast i8* %2 to <2 x i64>*
  %9 = load <2 x i64>, <2 x i64>* %8, align 1
  %10 = getelementptr inbounds i8, i8* %2, i64 -1
  %11 = load i8, i8* %10, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114WritePaeth16x8EPvlhDv2_xS4_(i8* %0, i64 %1, i8 zeroext %11, <2 x i64> %9, <2 x i64> %7)
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to <2 x i64>*
  %14 = load <2 x i64>, <2 x i64>* %13, align 1
  %15 = getelementptr inbounds i8, i8* %0, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114WritePaeth16x8EPvlhDv2_xS4_(i8* %15, i64 %1, i8 zeroext %11, <2 x i64> %14, <2 x i64> %7)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth32x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to <2 x i64>*
  %6 = load <2 x i64>, <2 x i64>* %5, align 1
  %7 = bitcast i8* %2 to <2 x i64>*
  %8 = load <2 x i64>, <2 x i64>* %7, align 1
  %9 = getelementptr inbounds i8, i8* %2, i64 -1
  %10 = load i8, i8* %9, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %0, i64 %1, i8 zeroext %10, <2 x i64> %8, <2 x i64> %6)
  %11 = getelementptr inbounds i8, i8* %2, i64 16
  %12 = bitcast i8* %11 to <2 x i64>*
  %13 = load <2 x i64>, <2 x i64>* %12, align 1
  %14 = getelementptr inbounds i8, i8* %0, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %14, i64 %1, i8 zeroext %10, <2 x i64> %13, <2 x i64> %6)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth32x32_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to <2 x i64>*
  %6 = load <2 x i64>, <2 x i64>* %5, align 1
  %7 = bitcast i8* %2 to <2 x i64>*
  %8 = load <2 x i64>, <2 x i64>* %7, align 1
  %9 = getelementptr inbounds i8, i8* %3, i64 16
  %10 = bitcast i8* %9 to <2 x i64>*
  %11 = load <2 x i64>, <2 x i64>* %10, align 1
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to <2 x i64>*
  %14 = load <2 x i64>, <2 x i64>* %13, align 1
  %15 = getelementptr inbounds i8, i8* %2, i64 -1
  %16 = load i8, i8* %15, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %0, i64 %1, i8 zeroext %16, <2 x i64> %8, <2 x i64> %6)
  %17 = getelementptr inbounds i8, i8* %0, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %17, i64 %1, i8 zeroext %16, <2 x i64> %14, <2 x i64> %6)
  %18 = shl i64 %1, 4
  %19 = getelementptr inbounds i8, i8* %0, i64 %18
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %19, i64 %1, i8 zeroext %16, <2 x i64> %8, <2 x i64> %11)
  %20 = getelementptr inbounds i8, i8* %19, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %20, i64 %1, i8 zeroext %16, <2 x i64> %14, <2 x i64> %11)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth32x64_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to <2 x i64>*
  %6 = load <2 x i64>, <2 x i64>* %5, align 1
  %7 = bitcast i8* %2 to <2 x i64>*
  %8 = load <2 x i64>, <2 x i64>* %7, align 1
  %9 = getelementptr inbounds i8, i8* %3, i64 16
  %10 = bitcast i8* %9 to <2 x i64>*
  %11 = load <2 x i64>, <2 x i64>* %10, align 1
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to <2 x i64>*
  %14 = load <2 x i64>, <2 x i64>* %13, align 1
  %15 = getelementptr inbounds i8, i8* %3, i64 32
  %16 = bitcast i8* %15 to <2 x i64>*
  %17 = load <2 x i64>, <2 x i64>* %16, align 1
  %18 = getelementptr inbounds i8, i8* %3, i64 48
  %19 = bitcast i8* %18 to <2 x i64>*
  %20 = load <2 x i64>, <2 x i64>* %19, align 1
  %21 = getelementptr inbounds i8, i8* %2, i64 -1
  %22 = load i8, i8* %21, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %0, i64 %1, i8 zeroext %22, <2 x i64> %8, <2 x i64> %6)
  %23 = getelementptr inbounds i8, i8* %0, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %23, i64 %1, i8 zeroext %22, <2 x i64> %14, <2 x i64> %6)
  %24 = shl i64 %1, 4
  %25 = getelementptr inbounds i8, i8* %0, i64 %24
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %25, i64 %1, i8 zeroext %22, <2 x i64> %8, <2 x i64> %11)
  %26 = getelementptr inbounds i8, i8* %25, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %26, i64 %1, i8 zeroext %22, <2 x i64> %14, <2 x i64> %11)
  %27 = getelementptr inbounds i8, i8* %25, i64 %24
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %27, i64 %1, i8 zeroext %22, <2 x i64> %8, <2 x i64> %17)
  %28 = getelementptr inbounds i8, i8* %27, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %28, i64 %1, i8 zeroext %22, <2 x i64> %14, <2 x i64> %17)
  %29 = getelementptr inbounds i8, i8* %27, i64 %24
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %29, i64 %1, i8 zeroext %22, <2 x i64> %8, <2 x i64> %20)
  %30 = getelementptr inbounds i8, i8* %29, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %30, i64 %1, i8 zeroext %22, <2 x i64> %14, <2 x i64> %20)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth64x16_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to <2 x i64>*
  %6 = load <2 x i64>, <2 x i64>* %5, align 1
  %7 = bitcast i8* %2 to <2 x i64>*
  %8 = load <2 x i64>, <2 x i64>* %7, align 1
  %9 = getelementptr inbounds i8, i8* %2, i64 16
  %10 = bitcast i8* %9 to <2 x i64>*
  %11 = load <2 x i64>, <2 x i64>* %10, align 1
  %12 = getelementptr inbounds i8, i8* %2, i64 32
  %13 = bitcast i8* %12 to <2 x i64>*
  %14 = load <2 x i64>, <2 x i64>* %13, align 1
  %15 = getelementptr inbounds i8, i8* %2, i64 48
  %16 = bitcast i8* %15 to <2 x i64>*
  %17 = load <2 x i64>, <2 x i64>* %16, align 1
  %18 = getelementptr inbounds i8, i8* %2, i64 -1
  %19 = load i8, i8* %18, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %0, i64 %1, i8 zeroext %19, <2 x i64> %8, <2 x i64> %6)
  %20 = getelementptr inbounds i8, i8* %0, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %20, i64 %1, i8 zeroext %19, <2 x i64> %11, <2 x i64> %6)
  %21 = getelementptr inbounds i8, i8* %0, i64 32
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %21, i64 %1, i8 zeroext %19, <2 x i64> %14, <2 x i64> %6)
  %22 = getelementptr inbounds i8, i8* %0, i64 48
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %22, i64 %1, i8 zeroext %19, <2 x i64> %17, <2 x i64> %6)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth64x32_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to <2 x i64>*
  %6 = load <2 x i64>, <2 x i64>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %3, i64 16
  %8 = bitcast i8* %7 to <2 x i64>*
  %9 = load <2 x i64>, <2 x i64>* %8, align 1
  %10 = bitcast i8* %2 to <2 x i64>*
  %11 = load <2 x i64>, <2 x i64>* %10, align 1
  %12 = getelementptr inbounds i8, i8* %2, i64 16
  %13 = bitcast i8* %12 to <2 x i64>*
  %14 = load <2 x i64>, <2 x i64>* %13, align 1
  %15 = getelementptr inbounds i8, i8* %2, i64 32
  %16 = bitcast i8* %15 to <2 x i64>*
  %17 = load <2 x i64>, <2 x i64>* %16, align 1
  %18 = getelementptr inbounds i8, i8* %2, i64 48
  %19 = bitcast i8* %18 to <2 x i64>*
  %20 = load <2 x i64>, <2 x i64>* %19, align 1
  %21 = getelementptr inbounds i8, i8* %2, i64 -1
  %22 = load i8, i8* %21, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %0, i64 %1, i8 zeroext %22, <2 x i64> %11, <2 x i64> %6)
  %23 = getelementptr inbounds i8, i8* %0, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %23, i64 %1, i8 zeroext %22, <2 x i64> %14, <2 x i64> %6)
  %24 = getelementptr inbounds i8, i8* %0, i64 32
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %24, i64 %1, i8 zeroext %22, <2 x i64> %17, <2 x i64> %6)
  %25 = getelementptr inbounds i8, i8* %0, i64 48
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %25, i64 %1, i8 zeroext %22, <2 x i64> %20, <2 x i64> %6)
  %26 = shl i64 %1, 4
  %27 = getelementptr inbounds i8, i8* %0, i64 %26
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %27, i64 %1, i8 zeroext %22, <2 x i64> %11, <2 x i64> %9)
  %28 = getelementptr inbounds i8, i8* %27, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %28, i64 %1, i8 zeroext %22, <2 x i64> %14, <2 x i64> %9)
  %29 = getelementptr inbounds i8, i8* %27, i64 32
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %29, i64 %1, i8 zeroext %22, <2 x i64> %17, <2 x i64> %9)
  %30 = getelementptr inbounds i8, i8* %27, i64 48
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %30, i64 %1, i8 zeroext %22, <2 x i64> %20, <2 x i64> %9)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_117Paeth64x64_SSE4_1EPvlPKvS5_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #3 {
  %5 = bitcast i8* %3 to <2 x i64>*
  %6 = load <2 x i64>, <2 x i64>* %5, align 1
  %7 = getelementptr inbounds i8, i8* %3, i64 16
  %8 = bitcast i8* %7 to <2 x i64>*
  %9 = load <2 x i64>, <2 x i64>* %8, align 1
  %10 = getelementptr inbounds i8, i8* %3, i64 32
  %11 = bitcast i8* %10 to <2 x i64>*
  %12 = load <2 x i64>, <2 x i64>* %11, align 1
  %13 = getelementptr inbounds i8, i8* %3, i64 48
  %14 = bitcast i8* %13 to <2 x i64>*
  %15 = load <2 x i64>, <2 x i64>* %14, align 1
  %16 = bitcast i8* %2 to <2 x i64>*
  %17 = load <2 x i64>, <2 x i64>* %16, align 1
  %18 = getelementptr inbounds i8, i8* %2, i64 16
  %19 = bitcast i8* %18 to <2 x i64>*
  %20 = load <2 x i64>, <2 x i64>* %19, align 1
  %21 = getelementptr inbounds i8, i8* %2, i64 32
  %22 = bitcast i8* %21 to <2 x i64>*
  %23 = load <2 x i64>, <2 x i64>* %22, align 1
  %24 = getelementptr inbounds i8, i8* %2, i64 48
  %25 = bitcast i8* %24 to <2 x i64>*
  %26 = load <2 x i64>, <2 x i64>* %25, align 1
  %27 = getelementptr inbounds i8, i8* %2, i64 -1
  %28 = load i8, i8* %27, align 1
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %0, i64 %1, i8 zeroext %28, <2 x i64> %17, <2 x i64> %6)
  %29 = getelementptr inbounds i8, i8* %0, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %29, i64 %1, i8 zeroext %28, <2 x i64> %20, <2 x i64> %6)
  %30 = getelementptr inbounds i8, i8* %0, i64 32
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %30, i64 %1, i8 zeroext %28, <2 x i64> %23, <2 x i64> %6)
  %31 = getelementptr inbounds i8, i8* %0, i64 48
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %31, i64 %1, i8 zeroext %28, <2 x i64> %26, <2 x i64> %6)
  %32 = shl i64 %1, 4
  %33 = getelementptr inbounds i8, i8* %0, i64 %32
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %33, i64 %1, i8 zeroext %28, <2 x i64> %17, <2 x i64> %9)
  %34 = getelementptr inbounds i8, i8* %33, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %34, i64 %1, i8 zeroext %28, <2 x i64> %20, <2 x i64> %9)
  %35 = getelementptr inbounds i8, i8* %33, i64 32
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %35, i64 %1, i8 zeroext %28, <2 x i64> %23, <2 x i64> %9)
  %36 = getelementptr inbounds i8, i8* %33, i64 48
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %36, i64 %1, i8 zeroext %28, <2 x i64> %26, <2 x i64> %9)
  %37 = getelementptr inbounds i8, i8* %33, i64 %32
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %37, i64 %1, i8 zeroext %28, <2 x i64> %17, <2 x i64> %12)
  %38 = getelementptr inbounds i8, i8* %37, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %38, i64 %1, i8 zeroext %28, <2 x i64> %20, <2 x i64> %12)
  %39 = getelementptr inbounds i8, i8* %37, i64 32
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %39, i64 %1, i8 zeroext %28, <2 x i64> %23, <2 x i64> %12)
  %40 = getelementptr inbounds i8, i8* %37, i64 48
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %40, i64 %1, i8 zeroext %28, <2 x i64> %26, <2 x i64> %12)
  %41 = getelementptr inbounds i8, i8* %37, i64 %32
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %41, i64 %1, i8 zeroext %28, <2 x i64> %17, <2 x i64> %15)
  %42 = getelementptr inbounds i8, i8* %41, i64 16
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %42, i64 %1, i8 zeroext %28, <2 x i64> %20, <2 x i64> %15)
  %43 = getelementptr inbounds i8, i8* %41, i64 32
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %43, i64 %1, i8 zeroext %28, <2 x i64> %23, <2 x i64> %15)
  %44 = getelementptr inbounds i8, i8* %41, i64 48
  tail call fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* %44, i64 %1, i8 zeroext %28, <2 x i64> %26, <2 x i64> %15)
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore4_SSE4_1IXadL_ZNS4_17WriteDuplicate4x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = bitcast i8* %3 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> undef, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %10 = bitcast <16 x i8> %9 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %12 = bitcast <8 x i16> %11 to <4 x i32>
  %13 = extractelement <4 x i32> %12, i32 0
  %14 = bitcast i8* %0 to i32*
  store i32 %13, i32* %14, align 1
  %15 = getelementptr inbounds i8, i8* %0, i64 %1
  %16 = extractelement <4 x i32> %12, i64 1
  %17 = bitcast i8* %15 to i32*
  store i32 %16, i32* %17, align 1
  %18 = getelementptr inbounds i8, i8* %15, i64 %1
  %19 = extractelement <4 x i32> %12, i64 2
  %20 = bitcast i8* %18 to i32*
  store i32 %19, i32* %20, align 1
  %21 = getelementptr inbounds i8, i8* %18, i64 %1
  %22 = extractelement <4 x i32> %12, i64 3
  %23 = bitcast i8* %21 to i32*
  store i32 %22, i32* %23, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_17WriteDuplicate4x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to i64*
  %7 = load i64, i64* %6, align 1
  %8 = insertelement <2 x i64> undef, i64 %7, i32 0
  %9 = bitcast <2 x i64> %8 to <16 x i8>
  %10 = shufflevector <16 x i8> %9, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %11 = bitcast <16 x i8> %10 to <8 x i16>
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = extractelement <4 x i32> %13, i32 0
  %15 = bitcast i8* %0 to i32*
  store i32 %14, i32* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 %1
  %17 = extractelement <4 x i32> %13, i64 1
  %18 = bitcast i8* %16 to i32*
  store i32 %17, i32* %18, align 1
  %19 = getelementptr inbounds i8, i8* %16, i64 %1
  %20 = extractelement <4 x i32> %13, i64 2
  %21 = bitcast i8* %19 to i32*
  store i32 %20, i32* %21, align 1
  %22 = getelementptr inbounds i8, i8* %19, i64 %1
  %23 = extractelement <4 x i32> %13, i64 3
  %24 = bitcast i8* %22 to i32*
  store i32 %23, i32* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 %5
  %26 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %27 = bitcast <8 x i16> %26 to <4 x i32>
  %28 = extractelement <4 x i32> %27, i32 0
  %29 = bitcast i8* %25 to i32*
  store i32 %28, i32* %29, align 1
  %30 = getelementptr inbounds i8, i8* %25, i64 %1
  %31 = extractelement <4 x i32> %27, i64 1
  %32 = bitcast i8* %30 to i32*
  store i32 %31, i32* %32, align 1
  %33 = getelementptr inbounds i8, i8* %30, i64 %1
  %34 = extractelement <4 x i32> %27, i64 2
  %35 = bitcast i8* %33 to i32*
  store i32 %34, i32* %35, align 1
  %36 = getelementptr inbounds i8, i8* %33, i64 %1
  %37 = extractelement <4 x i32> %27, i64 3
  %38 = bitcast i8* %36 to i32*
  store i32 %37, i32* %38, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_17WriteDuplicate4x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to <16 x i8>*
  %7 = load <16 x i8>, <16 x i8>* %6, align 1
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %9 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %10 = bitcast <16 x i8> %8 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %12 = bitcast <8 x i16> %11 to <4 x i32>
  %13 = extractelement <4 x i32> %12, i32 0
  %14 = bitcast i8* %0 to i32*
  store i32 %13, i32* %14, align 1
  %15 = getelementptr inbounds i8, i8* %0, i64 %1
  %16 = extractelement <4 x i32> %12, i64 1
  %17 = bitcast i8* %15 to i32*
  store i32 %16, i32* %17, align 1
  %18 = getelementptr inbounds i8, i8* %15, i64 %1
  %19 = extractelement <4 x i32> %12, i64 2
  %20 = bitcast i8* %18 to i32*
  store i32 %19, i32* %20, align 1
  %21 = getelementptr inbounds i8, i8* %18, i64 %1
  %22 = extractelement <4 x i32> %12, i64 3
  %23 = bitcast i8* %21 to i32*
  store i32 %22, i32* %23, align 1
  %24 = getelementptr inbounds i8, i8* %0, i64 %5
  %25 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %26 = bitcast <8 x i16> %25 to <4 x i32>
  %27 = extractelement <4 x i32> %26, i32 0
  %28 = bitcast i8* %24 to i32*
  store i32 %27, i32* %28, align 1
  %29 = getelementptr inbounds i8, i8* %24, i64 %1
  %30 = extractelement <4 x i32> %26, i64 1
  %31 = bitcast i8* %29 to i32*
  store i32 %30, i32* %31, align 1
  %32 = getelementptr inbounds i8, i8* %29, i64 %1
  %33 = extractelement <4 x i32> %26, i64 2
  %34 = bitcast i8* %32 to i32*
  store i32 %33, i32* %34, align 1
  %35 = getelementptr inbounds i8, i8* %32, i64 %1
  %36 = extractelement <4 x i32> %26, i64 3
  %37 = bitcast i8* %35 to i32*
  store i32 %36, i32* %37, align 1
  %38 = getelementptr inbounds i8, i8* %24, i64 %5
  %39 = bitcast <16 x i8> %9 to <8 x i16>
  %40 = shufflevector <8 x i16> %39, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %41 = bitcast <8 x i16> %40 to <4 x i32>
  %42 = extractelement <4 x i32> %41, i32 0
  %43 = bitcast i8* %38 to i32*
  store i32 %42, i32* %43, align 1
  %44 = getelementptr inbounds i8, i8* %38, i64 %1
  %45 = extractelement <4 x i32> %41, i64 1
  %46 = bitcast i8* %44 to i32*
  store i32 %45, i32* %46, align 1
  %47 = getelementptr inbounds i8, i8* %44, i64 %1
  %48 = extractelement <4 x i32> %41, i64 2
  %49 = bitcast i8* %47 to i32*
  store i32 %48, i32* %49, align 1
  %50 = getelementptr inbounds i8, i8* %47, i64 %1
  %51 = extractelement <4 x i32> %41, i64 3
  %52 = bitcast i8* %50 to i32*
  store i32 %51, i32* %52, align 1
  %53 = getelementptr inbounds i8, i8* %38, i64 %5
  %54 = shufflevector <8 x i16> %39, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %55 = bitcast <8 x i16> %54 to <4 x i32>
  %56 = extractelement <4 x i32> %55, i32 0
  %57 = bitcast i8* %53 to i32*
  store i32 %56, i32* %57, align 1
  %58 = getelementptr inbounds i8, i8* %53, i64 %1
  %59 = extractelement <4 x i32> %55, i64 1
  %60 = bitcast i8* %58 to i32*
  store i32 %59, i32* %60, align 1
  %61 = getelementptr inbounds i8, i8* %58, i64 %1
  %62 = extractelement <4 x i32> %55, i64 2
  %63 = bitcast i8* %61 to i32*
  store i32 %62, i32* %63, align 1
  %64 = getelementptr inbounds i8, i8* %61, i64 %1
  %65 = extractelement <4 x i32> %55, i64 3
  %66 = bitcast i8* %64 to i32*
  store i32 %65, i32* %66, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore4_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = bitcast i8* %3 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> undef, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %10 = bitcast <16 x i8> %9 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %12 = bitcast <8 x i16> %11 to <4 x i32>
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = extractelement <2 x i64> %14, i32 0
  %18 = bitcast i8* %0 to i64*
  store i64 %17, i64* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = bitcast <4 x i32> %13 to <4 x float>
  %21 = shufflevector <4 x float> %20, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %22 = bitcast i8* %19 to <2 x float>*
  store <2 x float> %21, <2 x float>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %19, i64 %1
  %24 = extractelement <2 x i64> %16, i32 0
  %25 = bitcast i8* %23 to i64*
  store i64 %24, i64* %25, align 1
  %26 = getelementptr inbounds i8, i8* %23, i64 %1
  %27 = bitcast <4 x i32> %15 to <4 x float>
  %28 = shufflevector <4 x float> %27, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %29 = bitcast i8* %26 to <2 x float>*
  store <2 x float> %28, <2 x float>* %29, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to i64*
  %7 = load i64, i64* %6, align 1
  %8 = insertelement <2 x i64> undef, i64 %7, i32 0
  %9 = bitcast <2 x i64> %8 to <16 x i8>
  %10 = shufflevector <16 x i8> %9, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %11 = bitcast <16 x i8> %10 to <8 x i16>
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %17 = bitcast <4 x i32> %16 to <2 x i64>
  %18 = extractelement <2 x i64> %15, i32 0
  %19 = bitcast i8* %0 to i64*
  store i64 %18, i64* %19, align 1
  %20 = getelementptr inbounds i8, i8* %0, i64 %1
  %21 = bitcast <4 x i32> %14 to <4 x float>
  %22 = shufflevector <4 x float> %21, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %23 = bitcast i8* %20 to <2 x float>*
  store <2 x float> %22, <2 x float>* %23, align 1
  %24 = getelementptr inbounds i8, i8* %20, i64 %1
  %25 = extractelement <2 x i64> %17, i32 0
  %26 = bitcast i8* %24 to i64*
  store i64 %25, i64* %26, align 1
  %27 = getelementptr inbounds i8, i8* %24, i64 %1
  %28 = bitcast <4 x i32> %16 to <4 x float>
  %29 = shufflevector <4 x float> %28, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %30 = bitcast i8* %27 to <2 x float>*
  store <2 x float> %29, <2 x float>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %0, i64 %5
  %32 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %33 = bitcast <8 x i16> %32 to <4 x i32>
  %34 = shufflevector <4 x i32> %33, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %35 = bitcast <4 x i32> %34 to <2 x i64>
  %36 = shufflevector <4 x i32> %33, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %37 = bitcast <4 x i32> %36 to <2 x i64>
  %38 = extractelement <2 x i64> %35, i32 0
  %39 = bitcast i8* %31 to i64*
  store i64 %38, i64* %39, align 1
  %40 = getelementptr inbounds i8, i8* %31, i64 %1
  %41 = bitcast <4 x i32> %34 to <4 x float>
  %42 = shufflevector <4 x float> %41, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %43 = bitcast i8* %40 to <2 x float>*
  store <2 x float> %42, <2 x float>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %40, i64 %1
  %45 = extractelement <2 x i64> %37, i32 0
  %46 = bitcast i8* %44 to i64*
  store i64 %45, i64* %46, align 1
  %47 = getelementptr inbounds i8, i8* %44, i64 %1
  %48 = bitcast <4 x i32> %36 to <4 x float>
  %49 = shufflevector <4 x float> %48, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %50 = bitcast i8* %47 to <2 x float>*
  store <2 x float> %49, <2 x float>* %50, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to <16 x i8>*
  %7 = load <16 x i8>, <16 x i8>* %6, align 1
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %9 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %10 = bitcast <16 x i8> %8 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %12 = bitcast <8 x i16> %11 to <4 x i32>
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = extractelement <2 x i64> %14, i32 0
  %18 = bitcast i8* %0 to i64*
  store i64 %17, i64* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = bitcast <4 x i32> %13 to <4 x float>
  %21 = shufflevector <4 x float> %20, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %22 = bitcast i8* %19 to <2 x float>*
  store <2 x float> %21, <2 x float>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %19, i64 %1
  %24 = extractelement <2 x i64> %16, i32 0
  %25 = bitcast i8* %23 to i64*
  store i64 %24, i64* %25, align 1
  %26 = getelementptr inbounds i8, i8* %23, i64 %1
  %27 = bitcast <4 x i32> %15 to <4 x float>
  %28 = shufflevector <4 x float> %27, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %29 = bitcast i8* %26 to <2 x float>*
  store <2 x float> %28, <2 x float>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %0, i64 %5
  %31 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %32 = bitcast <8 x i16> %31 to <4 x i32>
  %33 = shufflevector <4 x i32> %32, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %34 = bitcast <4 x i32> %33 to <2 x i64>
  %35 = shufflevector <4 x i32> %32, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %36 = bitcast <4 x i32> %35 to <2 x i64>
  %37 = extractelement <2 x i64> %34, i32 0
  %38 = bitcast i8* %30 to i64*
  store i64 %37, i64* %38, align 1
  %39 = getelementptr inbounds i8, i8* %30, i64 %1
  %40 = bitcast <4 x i32> %33 to <4 x float>
  %41 = shufflevector <4 x float> %40, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %42 = bitcast i8* %39 to <2 x float>*
  store <2 x float> %41, <2 x float>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %39, i64 %1
  %44 = extractelement <2 x i64> %36, i32 0
  %45 = bitcast i8* %43 to i64*
  store i64 %44, i64* %45, align 1
  %46 = getelementptr inbounds i8, i8* %43, i64 %1
  %47 = bitcast <4 x i32> %35 to <4 x float>
  %48 = shufflevector <4 x float> %47, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %49 = bitcast i8* %46 to <2 x float>*
  store <2 x float> %48, <2 x float>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %30, i64 %5
  %51 = bitcast <16 x i8> %9 to <8 x i16>
  %52 = shufflevector <8 x i16> %51, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %53 = bitcast <8 x i16> %52 to <4 x i32>
  %54 = shufflevector <4 x i32> %53, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %55 = bitcast <4 x i32> %54 to <2 x i64>
  %56 = shufflevector <4 x i32> %53, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %57 = bitcast <4 x i32> %56 to <2 x i64>
  %58 = extractelement <2 x i64> %55, i32 0
  %59 = bitcast i8* %50 to i64*
  store i64 %58, i64* %59, align 1
  %60 = getelementptr inbounds i8, i8* %50, i64 %1
  %61 = bitcast <4 x i32> %54 to <4 x float>
  %62 = shufflevector <4 x float> %61, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %63 = bitcast i8* %60 to <2 x float>*
  store <2 x float> %62, <2 x float>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %60, i64 %1
  %65 = extractelement <2 x i64> %57, i32 0
  %66 = bitcast i8* %64 to i64*
  store i64 %65, i64* %66, align 1
  %67 = getelementptr inbounds i8, i8* %64, i64 %1
  %68 = bitcast <4 x i32> %56 to <4 x float>
  %69 = shufflevector <4 x float> %68, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %70 = bitcast i8* %67 to <2 x float>*
  store <2 x float> %69, <2 x float>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %50, i64 %5
  %72 = shufflevector <8 x i16> %51, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %73 = bitcast <8 x i16> %72 to <4 x i32>
  %74 = shufflevector <4 x i32> %73, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %75 = bitcast <4 x i32> %74 to <2 x i64>
  %76 = shufflevector <4 x i32> %73, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %77 = bitcast <4 x i32> %76 to <2 x i64>
  %78 = extractelement <2 x i64> %75, i32 0
  %79 = bitcast i8* %71 to i64*
  store i64 %78, i64* %79, align 1
  %80 = getelementptr inbounds i8, i8* %71, i64 %1
  %81 = bitcast <4 x i32> %74 to <4 x float>
  %82 = shufflevector <4 x float> %81, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %83 = bitcast i8* %80 to <2 x float>*
  store <2 x float> %82, <2 x float>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %80, i64 %1
  %85 = extractelement <2 x i64> %77, i32 0
  %86 = bitcast i8* %84 to i64*
  store i64 %85, i64* %86, align 1
  %87 = getelementptr inbounds i8, i8* %84, i64 %1
  %88 = bitcast <4 x i32> %76 to <4 x float>
  %89 = shufflevector <4 x float> %88, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %90 = bitcast i8* %87 to <2 x float>*
  store <2 x float> %89, <2 x float>* %90, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to <16 x i8>*
  %7 = load <16 x i8>, <16 x i8>* %6, align 1
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %9 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %10 = bitcast <16 x i8> %8 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %12 = bitcast <8 x i16> %11 to <4 x i32>
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = extractelement <2 x i64> %14, i32 0
  %18 = bitcast i8* %0 to i64*
  store i64 %17, i64* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = bitcast <4 x i32> %13 to <4 x float>
  %21 = shufflevector <4 x float> %20, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %22 = bitcast i8* %19 to <2 x float>*
  store <2 x float> %21, <2 x float>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %19, i64 %1
  %24 = extractelement <2 x i64> %16, i32 0
  %25 = bitcast i8* %23 to i64*
  store i64 %24, i64* %25, align 1
  %26 = getelementptr inbounds i8, i8* %23, i64 %1
  %27 = bitcast <4 x i32> %15 to <4 x float>
  %28 = shufflevector <4 x float> %27, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %29 = bitcast i8* %26 to <2 x float>*
  store <2 x float> %28, <2 x float>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %0, i64 %5
  %31 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %32 = bitcast <8 x i16> %31 to <4 x i32>
  %33 = shufflevector <4 x i32> %32, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %34 = bitcast <4 x i32> %33 to <2 x i64>
  %35 = shufflevector <4 x i32> %32, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %36 = bitcast <4 x i32> %35 to <2 x i64>
  %37 = extractelement <2 x i64> %34, i32 0
  %38 = bitcast i8* %30 to i64*
  store i64 %37, i64* %38, align 1
  %39 = getelementptr inbounds i8, i8* %30, i64 %1
  %40 = bitcast <4 x i32> %33 to <4 x float>
  %41 = shufflevector <4 x float> %40, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %42 = bitcast i8* %39 to <2 x float>*
  store <2 x float> %41, <2 x float>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %39, i64 %1
  %44 = extractelement <2 x i64> %36, i32 0
  %45 = bitcast i8* %43 to i64*
  store i64 %44, i64* %45, align 1
  %46 = getelementptr inbounds i8, i8* %43, i64 %1
  %47 = bitcast <4 x i32> %35 to <4 x float>
  %48 = shufflevector <4 x float> %47, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %49 = bitcast i8* %46 to <2 x float>*
  store <2 x float> %48, <2 x float>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %30, i64 %5
  %51 = bitcast <16 x i8> %9 to <8 x i16>
  %52 = shufflevector <8 x i16> %51, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %53 = bitcast <8 x i16> %52 to <4 x i32>
  %54 = shufflevector <4 x i32> %53, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %55 = bitcast <4 x i32> %54 to <2 x i64>
  %56 = shufflevector <4 x i32> %53, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %57 = bitcast <4 x i32> %56 to <2 x i64>
  %58 = extractelement <2 x i64> %55, i32 0
  %59 = bitcast i8* %50 to i64*
  store i64 %58, i64* %59, align 1
  %60 = getelementptr inbounds i8, i8* %50, i64 %1
  %61 = bitcast <4 x i32> %54 to <4 x float>
  %62 = shufflevector <4 x float> %61, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %63 = bitcast i8* %60 to <2 x float>*
  store <2 x float> %62, <2 x float>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %60, i64 %1
  %65 = extractelement <2 x i64> %57, i32 0
  %66 = bitcast i8* %64 to i64*
  store i64 %65, i64* %66, align 1
  %67 = getelementptr inbounds i8, i8* %64, i64 %1
  %68 = bitcast <4 x i32> %56 to <4 x float>
  %69 = shufflevector <4 x float> %68, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %70 = bitcast i8* %67 to <2 x float>*
  store <2 x float> %69, <2 x float>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %50, i64 %5
  %72 = shufflevector <8 x i16> %51, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %73 = bitcast <8 x i16> %72 to <4 x i32>
  %74 = shufflevector <4 x i32> %73, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %75 = bitcast <4 x i32> %74 to <2 x i64>
  %76 = shufflevector <4 x i32> %73, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %77 = bitcast <4 x i32> %76 to <2 x i64>
  %78 = extractelement <2 x i64> %75, i32 0
  %79 = bitcast i8* %71 to i64*
  store i64 %78, i64* %79, align 1
  %80 = getelementptr inbounds i8, i8* %71, i64 %1
  %81 = bitcast <4 x i32> %74 to <4 x float>
  %82 = shufflevector <4 x float> %81, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %83 = bitcast i8* %80 to <2 x float>*
  store <2 x float> %82, <2 x float>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %80, i64 %1
  %85 = extractelement <2 x i64> %77, i32 0
  %86 = bitcast i8* %84 to i64*
  store i64 %85, i64* %86, align 1
  %87 = getelementptr inbounds i8, i8* %84, i64 %1
  %88 = bitcast <4 x i32> %76 to <4 x float>
  %89 = shufflevector <4 x float> %88, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %90 = bitcast i8* %87 to <2 x float>*
  store <2 x float> %89, <2 x float>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %71, i64 %5
  %92 = getelementptr inbounds i8, i8* %3, i64 16
  %93 = bitcast i8* %92 to <16 x i8>*
  %94 = load <16 x i8>, <16 x i8>* %93, align 1
  %95 = shufflevector <16 x i8> %94, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %96 = shufflevector <16 x i8> %94, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %97 = bitcast <16 x i8> %95 to <8 x i16>
  %98 = shufflevector <8 x i16> %97, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %99 = bitcast <8 x i16> %98 to <4 x i32>
  %100 = shufflevector <4 x i32> %99, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %101 = bitcast <4 x i32> %100 to <2 x i64>
  %102 = shufflevector <4 x i32> %99, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %103 = bitcast <4 x i32> %102 to <2 x i64>
  %104 = extractelement <2 x i64> %101, i32 0
  %105 = bitcast i8* %91 to i64*
  store i64 %104, i64* %105, align 1
  %106 = getelementptr inbounds i8, i8* %91, i64 %1
  %107 = bitcast <4 x i32> %100 to <4 x float>
  %108 = shufflevector <4 x float> %107, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %109 = bitcast i8* %106 to <2 x float>*
  store <2 x float> %108, <2 x float>* %109, align 1
  %110 = getelementptr inbounds i8, i8* %106, i64 %1
  %111 = extractelement <2 x i64> %103, i32 0
  %112 = bitcast i8* %110 to i64*
  store i64 %111, i64* %112, align 1
  %113 = getelementptr inbounds i8, i8* %110, i64 %1
  %114 = bitcast <4 x i32> %102 to <4 x float>
  %115 = shufflevector <4 x float> %114, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %116 = bitcast i8* %113 to <2 x float>*
  store <2 x float> %115, <2 x float>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %91, i64 %5
  %118 = shufflevector <8 x i16> %97, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %119 = bitcast <8 x i16> %118 to <4 x i32>
  %120 = shufflevector <4 x i32> %119, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %121 = bitcast <4 x i32> %120 to <2 x i64>
  %122 = shufflevector <4 x i32> %119, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %123 = bitcast <4 x i32> %122 to <2 x i64>
  %124 = extractelement <2 x i64> %121, i32 0
  %125 = bitcast i8* %117 to i64*
  store i64 %124, i64* %125, align 1
  %126 = getelementptr inbounds i8, i8* %117, i64 %1
  %127 = bitcast <4 x i32> %120 to <4 x float>
  %128 = shufflevector <4 x float> %127, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %129 = bitcast i8* %126 to <2 x float>*
  store <2 x float> %128, <2 x float>* %129, align 1
  %130 = getelementptr inbounds i8, i8* %126, i64 %1
  %131 = extractelement <2 x i64> %123, i32 0
  %132 = bitcast i8* %130 to i64*
  store i64 %131, i64* %132, align 1
  %133 = getelementptr inbounds i8, i8* %130, i64 %1
  %134 = bitcast <4 x i32> %122 to <4 x float>
  %135 = shufflevector <4 x float> %134, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %136 = bitcast i8* %133 to <2 x float>*
  store <2 x float> %135, <2 x float>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %117, i64 %5
  %138 = bitcast <16 x i8> %96 to <8 x i16>
  %139 = shufflevector <8 x i16> %138, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %140 = bitcast <8 x i16> %139 to <4 x i32>
  %141 = shufflevector <4 x i32> %140, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %142 = bitcast <4 x i32> %141 to <2 x i64>
  %143 = shufflevector <4 x i32> %140, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %144 = bitcast <4 x i32> %143 to <2 x i64>
  %145 = extractelement <2 x i64> %142, i32 0
  %146 = bitcast i8* %137 to i64*
  store i64 %145, i64* %146, align 1
  %147 = getelementptr inbounds i8, i8* %137, i64 %1
  %148 = bitcast <4 x i32> %141 to <4 x float>
  %149 = shufflevector <4 x float> %148, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %150 = bitcast i8* %147 to <2 x float>*
  store <2 x float> %149, <2 x float>* %150, align 1
  %151 = getelementptr inbounds i8, i8* %147, i64 %1
  %152 = extractelement <2 x i64> %144, i32 0
  %153 = bitcast i8* %151 to i64*
  store i64 %152, i64* %153, align 1
  %154 = getelementptr inbounds i8, i8* %151, i64 %1
  %155 = bitcast <4 x i32> %143 to <4 x float>
  %156 = shufflevector <4 x float> %155, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %157 = bitcast i8* %154 to <2 x float>*
  store <2 x float> %156, <2 x float>* %157, align 1
  %158 = getelementptr inbounds i8, i8* %137, i64 %5
  %159 = shufflevector <8 x i16> %138, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %160 = bitcast <8 x i16> %159 to <4 x i32>
  %161 = shufflevector <4 x i32> %160, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %162 = bitcast <4 x i32> %161 to <2 x i64>
  %163 = shufflevector <4 x i32> %160, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %164 = bitcast <4 x i32> %163 to <2 x i64>
  %165 = extractelement <2 x i64> %162, i32 0
  %166 = bitcast i8* %158 to i64*
  store i64 %165, i64* %166, align 1
  %167 = getelementptr inbounds i8, i8* %158, i64 %1
  %168 = bitcast <4 x i32> %161 to <4 x float>
  %169 = shufflevector <4 x float> %168, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %170 = bitcast i8* %167 to <2 x float>*
  store <2 x float> %169, <2 x float>* %170, align 1
  %171 = getelementptr inbounds i8, i8* %167, i64 %1
  %172 = extractelement <2 x i64> %164, i32 0
  %173 = bitcast i8* %171 to i64*
  store i64 %172, i64* %173, align 1
  %174 = getelementptr inbounds i8, i8* %171, i64 %1
  %175 = bitcast <4 x i32> %163 to <4 x float>
  %176 = shufflevector <4 x float> %175, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %177 = bitcast i8* %174 to <2 x float>*
  store <2 x float> %176, <2 x float>* %177, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore4_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = bitcast i8* %3 to i32*
  %6 = load i32, i32* %5, align 1
  %7 = insertelement <4 x i32> undef, i32 %6, i32 0
  %8 = bitcast <4 x i32> %7 to <16 x i8>
  %9 = shufflevector <16 x i8> %8, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %10 = bitcast <16 x i8> %9 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %12 = bitcast <8 x i16> %11 to <4 x i32>
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %17, <2 x i64>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %21 = bitcast i8* %19 to <2 x i64>*
  store <2 x i64> %20, <2 x i64>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %19, i64 %1
  %23 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> zeroinitializer
  %24 = bitcast i8* %22 to <2 x i64>*
  store <2 x i64> %23, <2 x i64>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %22, i64 %1
  %26 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %27 = bitcast i8* %25 to <2 x i64>*
  store <2 x i64> %26, <2 x i64>* %27, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to i64*
  %7 = load i64, i64* %6, align 1
  %8 = insertelement <2 x i64> undef, i64 %7, i32 0
  %9 = bitcast <2 x i64> %8 to <16 x i8>
  %10 = shufflevector <16 x i8> %9, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %11 = bitcast <16 x i8> %10 to <8 x i16>
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %17 = bitcast <4 x i32> %16 to <2 x i64>
  %18 = shufflevector <2 x i64> %15, <2 x i64> undef, <2 x i32> zeroinitializer
  %19 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %19, align 1
  %20 = getelementptr inbounds i8, i8* %0, i64 %1
  %21 = shufflevector <2 x i64> %15, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %22 = bitcast i8* %20 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %20, i64 %1
  %24 = shufflevector <2 x i64> %17, <2 x i64> undef, <2 x i32> zeroinitializer
  %25 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %24, <2 x i64>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %23, i64 %1
  %27 = shufflevector <2 x i64> %17, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %28 = bitcast i8* %26 to <2 x i64>*
  store <2 x i64> %27, <2 x i64>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %0, i64 %5
  %30 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %31 = bitcast <8 x i16> %30 to <4 x i32>
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %33 = bitcast <4 x i32> %32 to <2 x i64>
  %34 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %35 = bitcast <4 x i32> %34 to <2 x i64>
  %36 = shufflevector <2 x i64> %33, <2 x i64> undef, <2 x i32> zeroinitializer
  %37 = bitcast i8* %29 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %29, i64 %1
  %39 = shufflevector <2 x i64> %33, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %40 = bitcast i8* %38 to <2 x i64>*
  store <2 x i64> %39, <2 x i64>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %38, i64 %1
  %42 = shufflevector <2 x i64> %35, <2 x i64> undef, <2 x i32> zeroinitializer
  %43 = bitcast i8* %41 to <2 x i64>*
  store <2 x i64> %42, <2 x i64>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %41, i64 %1
  %45 = shufflevector <2 x i64> %35, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %46 = bitcast i8* %44 to <2 x i64>*
  store <2 x i64> %45, <2 x i64>* %46, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to <16 x i8>*
  %7 = load <16 x i8>, <16 x i8>* %6, align 1
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %9 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %10 = bitcast <16 x i8> %8 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %12 = bitcast <8 x i16> %11 to <4 x i32>
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %17, <2 x i64>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %21 = bitcast i8* %19 to <2 x i64>*
  store <2 x i64> %20, <2 x i64>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %19, i64 %1
  %23 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> zeroinitializer
  %24 = bitcast i8* %22 to <2 x i64>*
  store <2 x i64> %23, <2 x i64>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %22, i64 %1
  %26 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %27 = bitcast i8* %25 to <2 x i64>*
  store <2 x i64> %26, <2 x i64>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 %5
  %29 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %30 = bitcast <8 x i16> %29 to <4 x i32>
  %31 = shufflevector <4 x i32> %30, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %32 = bitcast <4 x i32> %31 to <2 x i64>
  %33 = shufflevector <4 x i32> %30, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %34 = bitcast <4 x i32> %33 to <2 x i64>
  %35 = shufflevector <2 x i64> %32, <2 x i64> undef, <2 x i32> zeroinitializer
  %36 = bitcast i8* %28 to <2 x i64>*
  store <2 x i64> %35, <2 x i64>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %28, i64 %1
  %38 = shufflevector <2 x i64> %32, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %39 = bitcast i8* %37 to <2 x i64>*
  store <2 x i64> %38, <2 x i64>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %37, i64 %1
  %41 = shufflevector <2 x i64> %34, <2 x i64> undef, <2 x i32> zeroinitializer
  %42 = bitcast i8* %40 to <2 x i64>*
  store <2 x i64> %41, <2 x i64>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %40, i64 %1
  %44 = shufflevector <2 x i64> %34, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %45 = bitcast i8* %43 to <2 x i64>*
  store <2 x i64> %44, <2 x i64>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %28, i64 %5
  %47 = bitcast <16 x i8> %9 to <8 x i16>
  %48 = shufflevector <8 x i16> %47, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %49 = bitcast <8 x i16> %48 to <4 x i32>
  %50 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %51 = bitcast <4 x i32> %50 to <2 x i64>
  %52 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %53 = bitcast <4 x i32> %52 to <2 x i64>
  %54 = shufflevector <2 x i64> %51, <2 x i64> undef, <2 x i32> zeroinitializer
  %55 = bitcast i8* %46 to <2 x i64>*
  store <2 x i64> %54, <2 x i64>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %46, i64 %1
  %57 = shufflevector <2 x i64> %51, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %58 = bitcast i8* %56 to <2 x i64>*
  store <2 x i64> %57, <2 x i64>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %56, i64 %1
  %60 = shufflevector <2 x i64> %53, <2 x i64> undef, <2 x i32> zeroinitializer
  %61 = bitcast i8* %59 to <2 x i64>*
  store <2 x i64> %60, <2 x i64>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %59, i64 %1
  %63 = shufflevector <2 x i64> %53, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %64 = bitcast i8* %62 to <2 x i64>*
  store <2 x i64> %63, <2 x i64>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %46, i64 %5
  %66 = shufflevector <8 x i16> %47, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %67 = bitcast <8 x i16> %66 to <4 x i32>
  %68 = shufflevector <4 x i32> %67, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %69 = bitcast <4 x i32> %68 to <2 x i64>
  %70 = shufflevector <4 x i32> %67, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %71 = bitcast <4 x i32> %70 to <2 x i64>
  %72 = shufflevector <2 x i64> %69, <2 x i64> undef, <2 x i32> zeroinitializer
  %73 = bitcast i8* %65 to <2 x i64>*
  store <2 x i64> %72, <2 x i64>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %65, i64 %1
  %75 = shufflevector <2 x i64> %69, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %76 = bitcast i8* %74 to <2 x i64>*
  store <2 x i64> %75, <2 x i64>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %74, i64 %1
  %78 = shufflevector <2 x i64> %71, <2 x i64> undef, <2 x i32> zeroinitializer
  %79 = bitcast i8* %77 to <2 x i64>*
  store <2 x i64> %78, <2 x i64>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %77, i64 %1
  %81 = shufflevector <2 x i64> %71, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %82 = bitcast i8* %80 to <2 x i64>*
  store <2 x i64> %81, <2 x i64>* %82, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to <16 x i8>*
  %7 = load <16 x i8>, <16 x i8>* %6, align 1
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %9 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %10 = bitcast <16 x i8> %8 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %12 = bitcast <8 x i16> %11 to <4 x i32>
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %17, <2 x i64>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %21 = bitcast i8* %19 to <2 x i64>*
  store <2 x i64> %20, <2 x i64>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %19, i64 %1
  %23 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> zeroinitializer
  %24 = bitcast i8* %22 to <2 x i64>*
  store <2 x i64> %23, <2 x i64>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %22, i64 %1
  %26 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %27 = bitcast i8* %25 to <2 x i64>*
  store <2 x i64> %26, <2 x i64>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 %5
  %29 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %30 = bitcast <8 x i16> %29 to <4 x i32>
  %31 = shufflevector <4 x i32> %30, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %32 = bitcast <4 x i32> %31 to <2 x i64>
  %33 = shufflevector <4 x i32> %30, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %34 = bitcast <4 x i32> %33 to <2 x i64>
  %35 = shufflevector <2 x i64> %32, <2 x i64> undef, <2 x i32> zeroinitializer
  %36 = bitcast i8* %28 to <2 x i64>*
  store <2 x i64> %35, <2 x i64>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %28, i64 %1
  %38 = shufflevector <2 x i64> %32, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %39 = bitcast i8* %37 to <2 x i64>*
  store <2 x i64> %38, <2 x i64>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %37, i64 %1
  %41 = shufflevector <2 x i64> %34, <2 x i64> undef, <2 x i32> zeroinitializer
  %42 = bitcast i8* %40 to <2 x i64>*
  store <2 x i64> %41, <2 x i64>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %40, i64 %1
  %44 = shufflevector <2 x i64> %34, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %45 = bitcast i8* %43 to <2 x i64>*
  store <2 x i64> %44, <2 x i64>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %28, i64 %5
  %47 = bitcast <16 x i8> %9 to <8 x i16>
  %48 = shufflevector <8 x i16> %47, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %49 = bitcast <8 x i16> %48 to <4 x i32>
  %50 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %51 = bitcast <4 x i32> %50 to <2 x i64>
  %52 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %53 = bitcast <4 x i32> %52 to <2 x i64>
  %54 = shufflevector <2 x i64> %51, <2 x i64> undef, <2 x i32> zeroinitializer
  %55 = bitcast i8* %46 to <2 x i64>*
  store <2 x i64> %54, <2 x i64>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %46, i64 %1
  %57 = shufflevector <2 x i64> %51, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %58 = bitcast i8* %56 to <2 x i64>*
  store <2 x i64> %57, <2 x i64>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %56, i64 %1
  %60 = shufflevector <2 x i64> %53, <2 x i64> undef, <2 x i32> zeroinitializer
  %61 = bitcast i8* %59 to <2 x i64>*
  store <2 x i64> %60, <2 x i64>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %59, i64 %1
  %63 = shufflevector <2 x i64> %53, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %64 = bitcast i8* %62 to <2 x i64>*
  store <2 x i64> %63, <2 x i64>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %46, i64 %5
  %66 = shufflevector <8 x i16> %47, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %67 = bitcast <8 x i16> %66 to <4 x i32>
  %68 = shufflevector <4 x i32> %67, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %69 = bitcast <4 x i32> %68 to <2 x i64>
  %70 = shufflevector <4 x i32> %67, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %71 = bitcast <4 x i32> %70 to <2 x i64>
  %72 = shufflevector <2 x i64> %69, <2 x i64> undef, <2 x i32> zeroinitializer
  %73 = bitcast i8* %65 to <2 x i64>*
  store <2 x i64> %72, <2 x i64>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %65, i64 %1
  %75 = shufflevector <2 x i64> %69, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %76 = bitcast i8* %74 to <2 x i64>*
  store <2 x i64> %75, <2 x i64>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %74, i64 %1
  %78 = shufflevector <2 x i64> %71, <2 x i64> undef, <2 x i32> zeroinitializer
  %79 = bitcast i8* %77 to <2 x i64>*
  store <2 x i64> %78, <2 x i64>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %77, i64 %1
  %81 = shufflevector <2 x i64> %71, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %82 = bitcast i8* %80 to <2 x i64>*
  store <2 x i64> %81, <2 x i64>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %65, i64 %5
  %84 = getelementptr inbounds i8, i8* %3, i64 16
  %85 = bitcast i8* %84 to <16 x i8>*
  %86 = load <16 x i8>, <16 x i8>* %85, align 1
  %87 = shufflevector <16 x i8> %86, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %88 = shufflevector <16 x i8> %86, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %89 = bitcast <16 x i8> %87 to <8 x i16>
  %90 = shufflevector <8 x i16> %89, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %91 = bitcast <8 x i16> %90 to <4 x i32>
  %92 = shufflevector <4 x i32> %91, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %93 = bitcast <4 x i32> %92 to <2 x i64>
  %94 = shufflevector <4 x i32> %91, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %95 = bitcast <4 x i32> %94 to <2 x i64>
  %96 = shufflevector <2 x i64> %93, <2 x i64> undef, <2 x i32> zeroinitializer
  %97 = bitcast i8* %83 to <2 x i64>*
  store <2 x i64> %96, <2 x i64>* %97, align 1
  %98 = getelementptr inbounds i8, i8* %83, i64 %1
  %99 = shufflevector <2 x i64> %93, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %100 = bitcast i8* %98 to <2 x i64>*
  store <2 x i64> %99, <2 x i64>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %98, i64 %1
  %102 = shufflevector <2 x i64> %95, <2 x i64> undef, <2 x i32> zeroinitializer
  %103 = bitcast i8* %101 to <2 x i64>*
  store <2 x i64> %102, <2 x i64>* %103, align 1
  %104 = getelementptr inbounds i8, i8* %101, i64 %1
  %105 = shufflevector <2 x i64> %95, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %106 = bitcast i8* %104 to <2 x i64>*
  store <2 x i64> %105, <2 x i64>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %83, i64 %5
  %108 = shufflevector <8 x i16> %89, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %109 = bitcast <8 x i16> %108 to <4 x i32>
  %110 = shufflevector <4 x i32> %109, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %111 = bitcast <4 x i32> %110 to <2 x i64>
  %112 = shufflevector <4 x i32> %109, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %113 = bitcast <4 x i32> %112 to <2 x i64>
  %114 = shufflevector <2 x i64> %111, <2 x i64> undef, <2 x i32> zeroinitializer
  %115 = bitcast i8* %107 to <2 x i64>*
  store <2 x i64> %114, <2 x i64>* %115, align 1
  %116 = getelementptr inbounds i8, i8* %107, i64 %1
  %117 = shufflevector <2 x i64> %111, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %118 = bitcast i8* %116 to <2 x i64>*
  store <2 x i64> %117, <2 x i64>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %116, i64 %1
  %120 = shufflevector <2 x i64> %113, <2 x i64> undef, <2 x i32> zeroinitializer
  %121 = bitcast i8* %119 to <2 x i64>*
  store <2 x i64> %120, <2 x i64>* %121, align 1
  %122 = getelementptr inbounds i8, i8* %119, i64 %1
  %123 = shufflevector <2 x i64> %113, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %124 = bitcast i8* %122 to <2 x i64>*
  store <2 x i64> %123, <2 x i64>* %124, align 1
  %125 = getelementptr inbounds i8, i8* %107, i64 %5
  %126 = bitcast <16 x i8> %88 to <8 x i16>
  %127 = shufflevector <8 x i16> %126, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %128 = bitcast <8 x i16> %127 to <4 x i32>
  %129 = shufflevector <4 x i32> %128, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %130 = bitcast <4 x i32> %129 to <2 x i64>
  %131 = shufflevector <4 x i32> %128, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %132 = bitcast <4 x i32> %131 to <2 x i64>
  %133 = shufflevector <2 x i64> %130, <2 x i64> undef, <2 x i32> zeroinitializer
  %134 = bitcast i8* %125 to <2 x i64>*
  store <2 x i64> %133, <2 x i64>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %125, i64 %1
  %136 = shufflevector <2 x i64> %130, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %137 = bitcast i8* %135 to <2 x i64>*
  store <2 x i64> %136, <2 x i64>* %137, align 1
  %138 = getelementptr inbounds i8, i8* %135, i64 %1
  %139 = shufflevector <2 x i64> %132, <2 x i64> undef, <2 x i32> zeroinitializer
  %140 = bitcast i8* %138 to <2 x i64>*
  store <2 x i64> %139, <2 x i64>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %138, i64 %1
  %142 = shufflevector <2 x i64> %132, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %143 = bitcast i8* %141 to <2 x i64>*
  store <2 x i64> %142, <2 x i64>* %143, align 1
  %144 = getelementptr inbounds i8, i8* %125, i64 %5
  %145 = shufflevector <8 x i16> %126, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %146 = bitcast <8 x i16> %145 to <4 x i32>
  %147 = shufflevector <4 x i32> %146, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %148 = bitcast <4 x i32> %147 to <2 x i64>
  %149 = shufflevector <4 x i32> %146, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %150 = bitcast <4 x i32> %149 to <2 x i64>
  %151 = shufflevector <2 x i64> %148, <2 x i64> undef, <2 x i32> zeroinitializer
  %152 = bitcast i8* %144 to <2 x i64>*
  store <2 x i64> %151, <2 x i64>* %152, align 1
  %153 = getelementptr inbounds i8, i8* %144, i64 %1
  %154 = shufflevector <2 x i64> %148, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %155 = bitcast i8* %153 to <2 x i64>*
  store <2 x i64> %154, <2 x i64>* %155, align 1
  %156 = getelementptr inbounds i8, i8* %153, i64 %1
  %157 = shufflevector <2 x i64> %150, <2 x i64> undef, <2 x i32> zeroinitializer
  %158 = bitcast i8* %156 to <2 x i64>*
  store <2 x i64> %157, <2 x i64>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %156, i64 %1
  %160 = shufflevector <2 x i64> %150, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %161 = bitcast i8* %159 to <2 x i64>*
  store <2 x i64> %160, <2 x i64>* %161, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore64_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %88, %6 ]
  %8 = phi i8* [ %0, %4 ], [ %87, %6 ]
  %9 = getelementptr inbounds i8, i8* %3, i64 %7
  %10 = bitcast i8* %9 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = shufflevector <16 x i8> %11, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %13 = shufflevector <16 x i8> %11, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %14 = bitcast <16 x i8> %12 to <8 x i16>
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %16 = bitcast <8 x i16> %15 to <4 x i32>
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %18 = bitcast <4 x i32> %17 to <2 x i64>
  %19 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %20 = bitcast <4 x i32> %19 to <2 x i64>
  %21 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> zeroinitializer
  %22 = bitcast i8* %8 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %8, i64 %1
  %24 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %25 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %24, <2 x i64>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %23, i64 %1
  %27 = shufflevector <2 x i64> %20, <2 x i64> undef, <2 x i32> zeroinitializer
  %28 = bitcast i8* %26 to <2 x i64>*
  store <2 x i64> %27, <2 x i64>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %26, i64 %1
  %30 = shufflevector <2 x i64> %20, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %31 = bitcast i8* %29 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %8, i64 %5
  %33 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %34 = bitcast <8 x i16> %33 to <4 x i32>
  %35 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %36 = bitcast <4 x i32> %35 to <2 x i64>
  %37 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %38 = bitcast <4 x i32> %37 to <2 x i64>
  %39 = shufflevector <2 x i64> %36, <2 x i64> undef, <2 x i32> zeroinitializer
  %40 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %39, <2 x i64>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %32, i64 %1
  %42 = shufflevector <2 x i64> %36, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %43 = bitcast i8* %41 to <2 x i64>*
  store <2 x i64> %42, <2 x i64>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %41, i64 %1
  %45 = shufflevector <2 x i64> %38, <2 x i64> undef, <2 x i32> zeroinitializer
  %46 = bitcast i8* %44 to <2 x i64>*
  store <2 x i64> %45, <2 x i64>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %44, i64 %1
  %48 = shufflevector <2 x i64> %38, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %49 = bitcast i8* %47 to <2 x i64>*
  store <2 x i64> %48, <2 x i64>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %32, i64 %5
  %51 = bitcast <16 x i8> %13 to <8 x i16>
  %52 = shufflevector <8 x i16> %51, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %53 = bitcast <8 x i16> %52 to <4 x i32>
  %54 = shufflevector <4 x i32> %53, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %55 = bitcast <4 x i32> %54 to <2 x i64>
  %56 = shufflevector <4 x i32> %53, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %57 = bitcast <4 x i32> %56 to <2 x i64>
  %58 = shufflevector <2 x i64> %55, <2 x i64> undef, <2 x i32> zeroinitializer
  %59 = bitcast i8* %50 to <2 x i64>*
  store <2 x i64> %58, <2 x i64>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %50, i64 %1
  %61 = shufflevector <2 x i64> %55, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %62 = bitcast i8* %60 to <2 x i64>*
  store <2 x i64> %61, <2 x i64>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %60, i64 %1
  %64 = shufflevector <2 x i64> %57, <2 x i64> undef, <2 x i32> zeroinitializer
  %65 = bitcast i8* %63 to <2 x i64>*
  store <2 x i64> %64, <2 x i64>* %65, align 1
  %66 = getelementptr inbounds i8, i8* %63, i64 %1
  %67 = shufflevector <2 x i64> %57, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %68 = bitcast i8* %66 to <2 x i64>*
  store <2 x i64> %67, <2 x i64>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %50, i64 %5
  %70 = shufflevector <8 x i16> %51, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %71 = bitcast <8 x i16> %70 to <4 x i32>
  %72 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %73 = bitcast <4 x i32> %72 to <2 x i64>
  %74 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %75 = bitcast <4 x i32> %74 to <2 x i64>
  %76 = shufflevector <2 x i64> %73, <2 x i64> undef, <2 x i32> zeroinitializer
  %77 = bitcast i8* %69 to <2 x i64>*
  store <2 x i64> %76, <2 x i64>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %69, i64 %1
  %79 = shufflevector <2 x i64> %73, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %80 = bitcast i8* %78 to <2 x i64>*
  store <2 x i64> %79, <2 x i64>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %78, i64 %1
  %82 = shufflevector <2 x i64> %75, <2 x i64> undef, <2 x i32> zeroinitializer
  %83 = bitcast i8* %81 to <2 x i64>*
  store <2 x i64> %82, <2 x i64>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %81, i64 %1
  %85 = shufflevector <2 x i64> %75, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %86 = bitcast i8* %84 to <2 x i64>*
  store <2 x i64> %85, <2 x i64>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %69, i64 %5
  %88 = add nuw nsw i64 %7, 16
  %89 = icmp ult i64 %88, 64
  br i1 %89, label %6, label %90

90:                                               ; preds = %6
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to i64*
  %7 = load i64, i64* %6, align 1
  %8 = insertelement <2 x i64> undef, i64 %7, i32 0
  %9 = bitcast <2 x i64> %8 to <16 x i8>
  %10 = shufflevector <16 x i8> %9, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %11 = bitcast <16 x i8> %10 to <8 x i16>
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %13 = bitcast <8 x i16> %12 to <4 x i32>
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %17 = bitcast <4 x i32> %16 to <2 x i64>
  %18 = shufflevector <2 x i64> %15, <2 x i64> undef, <2 x i32> zeroinitializer
  %19 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %19, align 1
  %20 = getelementptr inbounds i8, i8* %0, i64 16
  %21 = bitcast i8* %20 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %0, i64 %1
  %23 = shufflevector <2 x i64> %15, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %24 = bitcast i8* %22 to <2 x i64>*
  store <2 x i64> %23, <2 x i64>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %22, i64 16
  %26 = bitcast i8* %25 to <2 x i64>*
  store <2 x i64> %23, <2 x i64>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %22, i64 %1
  %28 = shufflevector <2 x i64> %17, <2 x i64> undef, <2 x i32> zeroinitializer
  %29 = bitcast i8* %27 to <2 x i64>*
  store <2 x i64> %28, <2 x i64>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %27, i64 16
  %31 = bitcast i8* %30 to <2 x i64>*
  store <2 x i64> %28, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %27, i64 %1
  %33 = shufflevector <2 x i64> %17, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %34 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %33, <2 x i64>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %32, i64 16
  %36 = bitcast i8* %35 to <2 x i64>*
  store <2 x i64> %33, <2 x i64>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %0, i64 %5
  %38 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %39 = bitcast <8 x i16> %38 to <4 x i32>
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %41 = bitcast <4 x i32> %40 to <2 x i64>
  %42 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %43 = bitcast <4 x i32> %42 to <2 x i64>
  %44 = shufflevector <2 x i64> %41, <2 x i64> undef, <2 x i32> zeroinitializer
  %45 = bitcast i8* %37 to <2 x i64>*
  store <2 x i64> %44, <2 x i64>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %37, i64 16
  %47 = bitcast i8* %46 to <2 x i64>*
  store <2 x i64> %44, <2 x i64>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %37, i64 %1
  %49 = shufflevector <2 x i64> %41, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %50 = bitcast i8* %48 to <2 x i64>*
  store <2 x i64> %49, <2 x i64>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %48, i64 16
  %52 = bitcast i8* %51 to <2 x i64>*
  store <2 x i64> %49, <2 x i64>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %48, i64 %1
  %54 = shufflevector <2 x i64> %43, <2 x i64> undef, <2 x i32> zeroinitializer
  %55 = bitcast i8* %53 to <2 x i64>*
  store <2 x i64> %54, <2 x i64>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %53, i64 16
  %57 = bitcast i8* %56 to <2 x i64>*
  store <2 x i64> %54, <2 x i64>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %53, i64 %1
  %59 = shufflevector <2 x i64> %43, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %60 = bitcast i8* %58 to <2 x i64>*
  store <2 x i64> %59, <2 x i64>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %58, i64 16
  %62 = bitcast i8* %61 to <2 x i64>*
  store <2 x i64> %59, <2 x i64>* %62, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to <16 x i8>*
  %7 = load <16 x i8>, <16 x i8>* %6, align 1
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %9 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %10 = bitcast <16 x i8> %8 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %12 = bitcast <8 x i16> %11 to <4 x i32>
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %17, <2 x i64>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 16
  %20 = bitcast i8* %19 to <2 x i64>*
  store <2 x i64> %17, <2 x i64>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %0, i64 %1
  %22 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %23 = bitcast i8* %21 to <2 x i64>*
  store <2 x i64> %22, <2 x i64>* %23, align 1
  %24 = getelementptr inbounds i8, i8* %21, i64 16
  %25 = bitcast i8* %24 to <2 x i64>*
  store <2 x i64> %22, <2 x i64>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %21, i64 %1
  %27 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> zeroinitializer
  %28 = bitcast i8* %26 to <2 x i64>*
  store <2 x i64> %27, <2 x i64>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %26, i64 16
  %30 = bitcast i8* %29 to <2 x i64>*
  store <2 x i64> %27, <2 x i64>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %26, i64 %1
  %32 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %33 = bitcast i8* %31 to <2 x i64>*
  store <2 x i64> %32, <2 x i64>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %31, i64 16
  %35 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %32, <2 x i64>* %35, align 1
  %36 = getelementptr inbounds i8, i8* %0, i64 %5
  %37 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %38 = bitcast <8 x i16> %37 to <4 x i32>
  %39 = shufflevector <4 x i32> %38, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %40 = bitcast <4 x i32> %39 to <2 x i64>
  %41 = shufflevector <4 x i32> %38, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %42 = bitcast <4 x i32> %41 to <2 x i64>
  %43 = shufflevector <2 x i64> %40, <2 x i64> undef, <2 x i32> zeroinitializer
  %44 = bitcast i8* %36 to <2 x i64>*
  store <2 x i64> %43, <2 x i64>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %36, i64 16
  %46 = bitcast i8* %45 to <2 x i64>*
  store <2 x i64> %43, <2 x i64>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %36, i64 %1
  %48 = shufflevector <2 x i64> %40, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %49 = bitcast i8* %47 to <2 x i64>*
  store <2 x i64> %48, <2 x i64>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %47, i64 16
  %51 = bitcast i8* %50 to <2 x i64>*
  store <2 x i64> %48, <2 x i64>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %47, i64 %1
  %53 = shufflevector <2 x i64> %42, <2 x i64> undef, <2 x i32> zeroinitializer
  %54 = bitcast i8* %52 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %52, i64 16
  %56 = bitcast i8* %55 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %52, i64 %1
  %58 = shufflevector <2 x i64> %42, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %59 = bitcast i8* %57 to <2 x i64>*
  store <2 x i64> %58, <2 x i64>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %57, i64 16
  %61 = bitcast i8* %60 to <2 x i64>*
  store <2 x i64> %58, <2 x i64>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %36, i64 %5
  %63 = bitcast <16 x i8> %9 to <8 x i16>
  %64 = shufflevector <8 x i16> %63, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %65 = bitcast <8 x i16> %64 to <4 x i32>
  %66 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %67 = bitcast <4 x i32> %66 to <2 x i64>
  %68 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %69 = bitcast <4 x i32> %68 to <2 x i64>
  %70 = shufflevector <2 x i64> %67, <2 x i64> undef, <2 x i32> zeroinitializer
  %71 = bitcast i8* %62 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %71, align 1
  %72 = getelementptr inbounds i8, i8* %62, i64 16
  %73 = bitcast i8* %72 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %62, i64 %1
  %75 = shufflevector <2 x i64> %67, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %76 = bitcast i8* %74 to <2 x i64>*
  store <2 x i64> %75, <2 x i64>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %74, i64 16
  %78 = bitcast i8* %77 to <2 x i64>*
  store <2 x i64> %75, <2 x i64>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %74, i64 %1
  %80 = shufflevector <2 x i64> %69, <2 x i64> undef, <2 x i32> zeroinitializer
  %81 = bitcast i8* %79 to <2 x i64>*
  store <2 x i64> %80, <2 x i64>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %79, i64 16
  %83 = bitcast i8* %82 to <2 x i64>*
  store <2 x i64> %80, <2 x i64>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %79, i64 %1
  %85 = shufflevector <2 x i64> %69, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %86 = bitcast i8* %84 to <2 x i64>*
  store <2 x i64> %85, <2 x i64>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %84, i64 16
  %88 = bitcast i8* %87 to <2 x i64>*
  store <2 x i64> %85, <2 x i64>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %62, i64 %5
  %90 = shufflevector <8 x i16> %63, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %91 = bitcast <8 x i16> %90 to <4 x i32>
  %92 = shufflevector <4 x i32> %91, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %93 = bitcast <4 x i32> %92 to <2 x i64>
  %94 = shufflevector <4 x i32> %91, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %95 = bitcast <4 x i32> %94 to <2 x i64>
  %96 = shufflevector <2 x i64> %93, <2 x i64> undef, <2 x i32> zeroinitializer
  %97 = bitcast i8* %89 to <2 x i64>*
  store <2 x i64> %96, <2 x i64>* %97, align 1
  %98 = getelementptr inbounds i8, i8* %89, i64 16
  %99 = bitcast i8* %98 to <2 x i64>*
  store <2 x i64> %96, <2 x i64>* %99, align 1
  %100 = getelementptr inbounds i8, i8* %89, i64 %1
  %101 = shufflevector <2 x i64> %93, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %102 = bitcast i8* %100 to <2 x i64>*
  store <2 x i64> %101, <2 x i64>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %100, i64 16
  %104 = bitcast i8* %103 to <2 x i64>*
  store <2 x i64> %101, <2 x i64>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %100, i64 %1
  %106 = shufflevector <2 x i64> %95, <2 x i64> undef, <2 x i32> zeroinitializer
  %107 = bitcast i8* %105 to <2 x i64>*
  store <2 x i64> %106, <2 x i64>* %107, align 1
  %108 = getelementptr inbounds i8, i8* %105, i64 16
  %109 = bitcast i8* %108 to <2 x i64>*
  store <2 x i64> %106, <2 x i64>* %109, align 1
  %110 = getelementptr inbounds i8, i8* %105, i64 %1
  %111 = shufflevector <2 x i64> %95, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %112 = bitcast i8* %110 to <2 x i64>*
  store <2 x i64> %111, <2 x i64>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %110, i64 16
  %114 = bitcast i8* %113 to <2 x i64>*
  store <2 x i64> %111, <2 x i64>* %114, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %120, %6 ]
  %8 = phi i8* [ %0, %4 ], [ %119, %6 ]
  %9 = getelementptr inbounds i8, i8* %3, i64 %7
  %10 = bitcast i8* %9 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = shufflevector <16 x i8> %11, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %13 = shufflevector <16 x i8> %11, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %14 = bitcast <16 x i8> %12 to <8 x i16>
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %16 = bitcast <8 x i16> %15 to <4 x i32>
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %18 = bitcast <4 x i32> %17 to <2 x i64>
  %19 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %20 = bitcast <4 x i32> %19 to <2 x i64>
  %21 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> zeroinitializer
  %22 = bitcast i8* %8 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %8, i64 16
  %24 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %8, i64 %1
  %26 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %27 = bitcast i8* %25 to <2 x i64>*
  store <2 x i64> %26, <2 x i64>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %25, i64 16
  %29 = bitcast i8* %28 to <2 x i64>*
  store <2 x i64> %26, <2 x i64>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %25, i64 %1
  %31 = shufflevector <2 x i64> %20, <2 x i64> undef, <2 x i32> zeroinitializer
  %32 = bitcast i8* %30 to <2 x i64>*
  store <2 x i64> %31, <2 x i64>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %30, i64 16
  %34 = bitcast i8* %33 to <2 x i64>*
  store <2 x i64> %31, <2 x i64>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %30, i64 %1
  %36 = shufflevector <2 x i64> %20, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %37 = bitcast i8* %35 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %35, i64 16
  %39 = bitcast i8* %38 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %8, i64 %5
  %41 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %42 = bitcast <8 x i16> %41 to <4 x i32>
  %43 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %44 = bitcast <4 x i32> %43 to <2 x i64>
  %45 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %46 = bitcast <4 x i32> %45 to <2 x i64>
  %47 = shufflevector <2 x i64> %44, <2 x i64> undef, <2 x i32> zeroinitializer
  %48 = bitcast i8* %40 to <2 x i64>*
  store <2 x i64> %47, <2 x i64>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %40, i64 16
  %50 = bitcast i8* %49 to <2 x i64>*
  store <2 x i64> %47, <2 x i64>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %40, i64 %1
  %52 = shufflevector <2 x i64> %44, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %53 = bitcast i8* %51 to <2 x i64>*
  store <2 x i64> %52, <2 x i64>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %51, i64 16
  %55 = bitcast i8* %54 to <2 x i64>*
  store <2 x i64> %52, <2 x i64>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %51, i64 %1
  %57 = shufflevector <2 x i64> %46, <2 x i64> undef, <2 x i32> zeroinitializer
  %58 = bitcast i8* %56 to <2 x i64>*
  store <2 x i64> %57, <2 x i64>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %56, i64 16
  %60 = bitcast i8* %59 to <2 x i64>*
  store <2 x i64> %57, <2 x i64>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %56, i64 %1
  %62 = shufflevector <2 x i64> %46, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %63 = bitcast i8* %61 to <2 x i64>*
  store <2 x i64> %62, <2 x i64>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %61, i64 16
  %65 = bitcast i8* %64 to <2 x i64>*
  store <2 x i64> %62, <2 x i64>* %65, align 1
  %66 = getelementptr inbounds i8, i8* %40, i64 %5
  %67 = bitcast <16 x i8> %13 to <8 x i16>
  %68 = shufflevector <8 x i16> %67, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %69 = bitcast <8 x i16> %68 to <4 x i32>
  %70 = shufflevector <4 x i32> %69, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %71 = bitcast <4 x i32> %70 to <2 x i64>
  %72 = shufflevector <4 x i32> %69, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %73 = bitcast <4 x i32> %72 to <2 x i64>
  %74 = shufflevector <2 x i64> %71, <2 x i64> undef, <2 x i32> zeroinitializer
  %75 = bitcast i8* %66 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %66, i64 16
  %77 = bitcast i8* %76 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %66, i64 %1
  %79 = shufflevector <2 x i64> %71, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %80 = bitcast i8* %78 to <2 x i64>*
  store <2 x i64> %79, <2 x i64>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %78, i64 16
  %82 = bitcast i8* %81 to <2 x i64>*
  store <2 x i64> %79, <2 x i64>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %78, i64 %1
  %84 = shufflevector <2 x i64> %73, <2 x i64> undef, <2 x i32> zeroinitializer
  %85 = bitcast i8* %83 to <2 x i64>*
  store <2 x i64> %84, <2 x i64>* %85, align 1
  %86 = getelementptr inbounds i8, i8* %83, i64 16
  %87 = bitcast i8* %86 to <2 x i64>*
  store <2 x i64> %84, <2 x i64>* %87, align 1
  %88 = getelementptr inbounds i8, i8* %83, i64 %1
  %89 = shufflevector <2 x i64> %73, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %90 = bitcast i8* %88 to <2 x i64>*
  store <2 x i64> %89, <2 x i64>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %88, i64 16
  %92 = bitcast i8* %91 to <2 x i64>*
  store <2 x i64> %89, <2 x i64>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %66, i64 %5
  %94 = shufflevector <8 x i16> %67, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %95 = bitcast <8 x i16> %94 to <4 x i32>
  %96 = shufflevector <4 x i32> %95, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %97 = bitcast <4 x i32> %96 to <2 x i64>
  %98 = shufflevector <4 x i32> %95, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %99 = bitcast <4 x i32> %98 to <2 x i64>
  %100 = shufflevector <2 x i64> %97, <2 x i64> undef, <2 x i32> zeroinitializer
  %101 = bitcast i8* %93 to <2 x i64>*
  store <2 x i64> %100, <2 x i64>* %101, align 1
  %102 = getelementptr inbounds i8, i8* %93, i64 16
  %103 = bitcast i8* %102 to <2 x i64>*
  store <2 x i64> %100, <2 x i64>* %103, align 1
  %104 = getelementptr inbounds i8, i8* %93, i64 %1
  %105 = shufflevector <2 x i64> %97, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %106 = bitcast i8* %104 to <2 x i64>*
  store <2 x i64> %105, <2 x i64>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %104, i64 16
  %108 = bitcast i8* %107 to <2 x i64>*
  store <2 x i64> %105, <2 x i64>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %104, i64 %1
  %110 = shufflevector <2 x i64> %99, <2 x i64> undef, <2 x i32> zeroinitializer
  %111 = bitcast i8* %109 to <2 x i64>*
  store <2 x i64> %110, <2 x i64>* %111, align 1
  %112 = getelementptr inbounds i8, i8* %109, i64 16
  %113 = bitcast i8* %112 to <2 x i64>*
  store <2 x i64> %110, <2 x i64>* %113, align 1
  %114 = getelementptr inbounds i8, i8* %109, i64 %1
  %115 = shufflevector <2 x i64> %99, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %116 = bitcast i8* %114 to <2 x i64>*
  store <2 x i64> %115, <2 x i64>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %114, i64 16
  %118 = bitcast i8* %117 to <2 x i64>*
  store <2 x i64> %115, <2 x i64>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %93, i64 %5
  %120 = add nuw nsw i64 %7, 16
  %121 = icmp ult i64 %120, 32
  br i1 %121, label %6, label %122

122:                                              ; preds = %6
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore64_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %120, %6 ]
  %8 = phi i8* [ %0, %4 ], [ %119, %6 ]
  %9 = getelementptr inbounds i8, i8* %3, i64 %7
  %10 = bitcast i8* %9 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = shufflevector <16 x i8> %11, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %13 = shufflevector <16 x i8> %11, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %14 = bitcast <16 x i8> %12 to <8 x i16>
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %16 = bitcast <8 x i16> %15 to <4 x i32>
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %18 = bitcast <4 x i32> %17 to <2 x i64>
  %19 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %20 = bitcast <4 x i32> %19 to <2 x i64>
  %21 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> zeroinitializer
  %22 = bitcast i8* %8 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %8, i64 16
  %24 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %8, i64 %1
  %26 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %27 = bitcast i8* %25 to <2 x i64>*
  store <2 x i64> %26, <2 x i64>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %25, i64 16
  %29 = bitcast i8* %28 to <2 x i64>*
  store <2 x i64> %26, <2 x i64>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %25, i64 %1
  %31 = shufflevector <2 x i64> %20, <2 x i64> undef, <2 x i32> zeroinitializer
  %32 = bitcast i8* %30 to <2 x i64>*
  store <2 x i64> %31, <2 x i64>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %30, i64 16
  %34 = bitcast i8* %33 to <2 x i64>*
  store <2 x i64> %31, <2 x i64>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %30, i64 %1
  %36 = shufflevector <2 x i64> %20, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %37 = bitcast i8* %35 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %35, i64 16
  %39 = bitcast i8* %38 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %8, i64 %5
  %41 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %42 = bitcast <8 x i16> %41 to <4 x i32>
  %43 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %44 = bitcast <4 x i32> %43 to <2 x i64>
  %45 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %46 = bitcast <4 x i32> %45 to <2 x i64>
  %47 = shufflevector <2 x i64> %44, <2 x i64> undef, <2 x i32> zeroinitializer
  %48 = bitcast i8* %40 to <2 x i64>*
  store <2 x i64> %47, <2 x i64>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %40, i64 16
  %50 = bitcast i8* %49 to <2 x i64>*
  store <2 x i64> %47, <2 x i64>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %40, i64 %1
  %52 = shufflevector <2 x i64> %44, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %53 = bitcast i8* %51 to <2 x i64>*
  store <2 x i64> %52, <2 x i64>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %51, i64 16
  %55 = bitcast i8* %54 to <2 x i64>*
  store <2 x i64> %52, <2 x i64>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %51, i64 %1
  %57 = shufflevector <2 x i64> %46, <2 x i64> undef, <2 x i32> zeroinitializer
  %58 = bitcast i8* %56 to <2 x i64>*
  store <2 x i64> %57, <2 x i64>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %56, i64 16
  %60 = bitcast i8* %59 to <2 x i64>*
  store <2 x i64> %57, <2 x i64>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %56, i64 %1
  %62 = shufflevector <2 x i64> %46, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %63 = bitcast i8* %61 to <2 x i64>*
  store <2 x i64> %62, <2 x i64>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %61, i64 16
  %65 = bitcast i8* %64 to <2 x i64>*
  store <2 x i64> %62, <2 x i64>* %65, align 1
  %66 = getelementptr inbounds i8, i8* %40, i64 %5
  %67 = bitcast <16 x i8> %13 to <8 x i16>
  %68 = shufflevector <8 x i16> %67, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %69 = bitcast <8 x i16> %68 to <4 x i32>
  %70 = shufflevector <4 x i32> %69, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %71 = bitcast <4 x i32> %70 to <2 x i64>
  %72 = shufflevector <4 x i32> %69, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %73 = bitcast <4 x i32> %72 to <2 x i64>
  %74 = shufflevector <2 x i64> %71, <2 x i64> undef, <2 x i32> zeroinitializer
  %75 = bitcast i8* %66 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %66, i64 16
  %77 = bitcast i8* %76 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %66, i64 %1
  %79 = shufflevector <2 x i64> %71, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %80 = bitcast i8* %78 to <2 x i64>*
  store <2 x i64> %79, <2 x i64>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %78, i64 16
  %82 = bitcast i8* %81 to <2 x i64>*
  store <2 x i64> %79, <2 x i64>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %78, i64 %1
  %84 = shufflevector <2 x i64> %73, <2 x i64> undef, <2 x i32> zeroinitializer
  %85 = bitcast i8* %83 to <2 x i64>*
  store <2 x i64> %84, <2 x i64>* %85, align 1
  %86 = getelementptr inbounds i8, i8* %83, i64 16
  %87 = bitcast i8* %86 to <2 x i64>*
  store <2 x i64> %84, <2 x i64>* %87, align 1
  %88 = getelementptr inbounds i8, i8* %83, i64 %1
  %89 = shufflevector <2 x i64> %73, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %90 = bitcast i8* %88 to <2 x i64>*
  store <2 x i64> %89, <2 x i64>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %88, i64 16
  %92 = bitcast i8* %91 to <2 x i64>*
  store <2 x i64> %89, <2 x i64>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %66, i64 %5
  %94 = shufflevector <8 x i16> %67, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %95 = bitcast <8 x i16> %94 to <4 x i32>
  %96 = shufflevector <4 x i32> %95, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %97 = bitcast <4 x i32> %96 to <2 x i64>
  %98 = shufflevector <4 x i32> %95, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %99 = bitcast <4 x i32> %98 to <2 x i64>
  %100 = shufflevector <2 x i64> %97, <2 x i64> undef, <2 x i32> zeroinitializer
  %101 = bitcast i8* %93 to <2 x i64>*
  store <2 x i64> %100, <2 x i64>* %101, align 1
  %102 = getelementptr inbounds i8, i8* %93, i64 16
  %103 = bitcast i8* %102 to <2 x i64>*
  store <2 x i64> %100, <2 x i64>* %103, align 1
  %104 = getelementptr inbounds i8, i8* %93, i64 %1
  %105 = shufflevector <2 x i64> %97, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %106 = bitcast i8* %104 to <2 x i64>*
  store <2 x i64> %105, <2 x i64>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %104, i64 16
  %108 = bitcast i8* %107 to <2 x i64>*
  store <2 x i64> %105, <2 x i64>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %104, i64 %1
  %110 = shufflevector <2 x i64> %99, <2 x i64> undef, <2 x i32> zeroinitializer
  %111 = bitcast i8* %109 to <2 x i64>*
  store <2 x i64> %110, <2 x i64>* %111, align 1
  %112 = getelementptr inbounds i8, i8* %109, i64 16
  %113 = bitcast i8* %112 to <2 x i64>*
  store <2 x i64> %110, <2 x i64>* %113, align 1
  %114 = getelementptr inbounds i8, i8* %109, i64 %1
  %115 = shufflevector <2 x i64> %99, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %116 = bitcast i8* %114 to <2 x i64>*
  store <2 x i64> %115, <2 x i64>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %114, i64 16
  %118 = bitcast i8* %117 to <2 x i64>*
  store <2 x i64> %115, <2 x i64>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %93, i64 %5
  %120 = add nuw nsw i64 %7, 16
  %121 = icmp ult i64 %120, 64
  br i1 %121, label %6, label %122

122:                                              ; preds = %6
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_18WriteDuplicate64x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to <16 x i8>*
  %7 = load <16 x i8>, <16 x i8>* %6, align 1
  %8 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %9 = shufflevector <16 x i8> %7, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %10 = bitcast <16 x i8> %8 to <8 x i16>
  %11 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %12 = bitcast <8 x i16> %11 to <4 x i32>
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> zeroinitializer
  %18 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %17, <2 x i64>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 16
  %20 = bitcast i8* %19 to <2 x i64>*
  store <2 x i64> %17, <2 x i64>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %0, i64 32
  %22 = bitcast i8* %21 to <2 x i64>*
  store <2 x i64> %17, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %0, i64 48
  %24 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %17, <2 x i64>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %0, i64 %1
  %26 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %27 = bitcast i8* %25 to <2 x i64>*
  store <2 x i64> %26, <2 x i64>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %25, i64 16
  %29 = bitcast i8* %28 to <2 x i64>*
  store <2 x i64> %26, <2 x i64>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %25, i64 32
  %31 = bitcast i8* %30 to <2 x i64>*
  store <2 x i64> %26, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %25, i64 48
  %33 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %26, <2 x i64>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %25, i64 %1
  %35 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> zeroinitializer
  %36 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %35, <2 x i64>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %34, i64 16
  %38 = bitcast i8* %37 to <2 x i64>*
  store <2 x i64> %35, <2 x i64>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %34, i64 32
  %40 = bitcast i8* %39 to <2 x i64>*
  store <2 x i64> %35, <2 x i64>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %34, i64 48
  %42 = bitcast i8* %41 to <2 x i64>*
  store <2 x i64> %35, <2 x i64>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %34, i64 %1
  %44 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %45 = bitcast i8* %43 to <2 x i64>*
  store <2 x i64> %44, <2 x i64>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %43, i64 16
  %47 = bitcast i8* %46 to <2 x i64>*
  store <2 x i64> %44, <2 x i64>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %43, i64 32
  %49 = bitcast i8* %48 to <2 x i64>*
  store <2 x i64> %44, <2 x i64>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %43, i64 48
  %51 = bitcast i8* %50 to <2 x i64>*
  store <2 x i64> %44, <2 x i64>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %0, i64 %5
  %53 = shufflevector <8 x i16> %10, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %54 = bitcast <8 x i16> %53 to <4 x i32>
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %56 = bitcast <4 x i32> %55 to <2 x i64>
  %57 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %58 = bitcast <4 x i32> %57 to <2 x i64>
  %59 = shufflevector <2 x i64> %56, <2 x i64> undef, <2 x i32> zeroinitializer
  %60 = bitcast i8* %52 to <2 x i64>*
  store <2 x i64> %59, <2 x i64>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %52, i64 16
  %62 = bitcast i8* %61 to <2 x i64>*
  store <2 x i64> %59, <2 x i64>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %52, i64 32
  %64 = bitcast i8* %63 to <2 x i64>*
  store <2 x i64> %59, <2 x i64>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %52, i64 48
  %66 = bitcast i8* %65 to <2 x i64>*
  store <2 x i64> %59, <2 x i64>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %52, i64 %1
  %68 = shufflevector <2 x i64> %56, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %69 = bitcast i8* %67 to <2 x i64>*
  store <2 x i64> %68, <2 x i64>* %69, align 1
  %70 = getelementptr inbounds i8, i8* %67, i64 16
  %71 = bitcast i8* %70 to <2 x i64>*
  store <2 x i64> %68, <2 x i64>* %71, align 1
  %72 = getelementptr inbounds i8, i8* %67, i64 32
  %73 = bitcast i8* %72 to <2 x i64>*
  store <2 x i64> %68, <2 x i64>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %67, i64 48
  %75 = bitcast i8* %74 to <2 x i64>*
  store <2 x i64> %68, <2 x i64>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %67, i64 %1
  %77 = shufflevector <2 x i64> %58, <2 x i64> undef, <2 x i32> zeroinitializer
  %78 = bitcast i8* %76 to <2 x i64>*
  store <2 x i64> %77, <2 x i64>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %76, i64 16
  %80 = bitcast i8* %79 to <2 x i64>*
  store <2 x i64> %77, <2 x i64>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %76, i64 32
  %82 = bitcast i8* %81 to <2 x i64>*
  store <2 x i64> %77, <2 x i64>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %76, i64 48
  %84 = bitcast i8* %83 to <2 x i64>*
  store <2 x i64> %77, <2 x i64>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %76, i64 %1
  %86 = shufflevector <2 x i64> %58, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %87 = bitcast i8* %85 to <2 x i64>*
  store <2 x i64> %86, <2 x i64>* %87, align 1
  %88 = getelementptr inbounds i8, i8* %85, i64 16
  %89 = bitcast i8* %88 to <2 x i64>*
  store <2 x i64> %86, <2 x i64>* %89, align 1
  %90 = getelementptr inbounds i8, i8* %85, i64 32
  %91 = bitcast i8* %90 to <2 x i64>*
  store <2 x i64> %86, <2 x i64>* %91, align 1
  %92 = getelementptr inbounds i8, i8* %85, i64 48
  %93 = bitcast i8* %92 to <2 x i64>*
  store <2 x i64> %86, <2 x i64>* %93, align 1
  %94 = getelementptr inbounds i8, i8* %52, i64 %5
  %95 = bitcast <16 x i8> %9 to <8 x i16>
  %96 = shufflevector <8 x i16> %95, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %97 = bitcast <8 x i16> %96 to <4 x i32>
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %99 = bitcast <4 x i32> %98 to <2 x i64>
  %100 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %101 = bitcast <4 x i32> %100 to <2 x i64>
  %102 = shufflevector <2 x i64> %99, <2 x i64> undef, <2 x i32> zeroinitializer
  %103 = bitcast i8* %94 to <2 x i64>*
  store <2 x i64> %102, <2 x i64>* %103, align 1
  %104 = getelementptr inbounds i8, i8* %94, i64 16
  %105 = bitcast i8* %104 to <2 x i64>*
  store <2 x i64> %102, <2 x i64>* %105, align 1
  %106 = getelementptr inbounds i8, i8* %94, i64 32
  %107 = bitcast i8* %106 to <2 x i64>*
  store <2 x i64> %102, <2 x i64>* %107, align 1
  %108 = getelementptr inbounds i8, i8* %94, i64 48
  %109 = bitcast i8* %108 to <2 x i64>*
  store <2 x i64> %102, <2 x i64>* %109, align 1
  %110 = getelementptr inbounds i8, i8* %94, i64 %1
  %111 = shufflevector <2 x i64> %99, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %112 = bitcast i8* %110 to <2 x i64>*
  store <2 x i64> %111, <2 x i64>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %110, i64 16
  %114 = bitcast i8* %113 to <2 x i64>*
  store <2 x i64> %111, <2 x i64>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %110, i64 32
  %116 = bitcast i8* %115 to <2 x i64>*
  store <2 x i64> %111, <2 x i64>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %110, i64 48
  %118 = bitcast i8* %117 to <2 x i64>*
  store <2 x i64> %111, <2 x i64>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %110, i64 %1
  %120 = shufflevector <2 x i64> %101, <2 x i64> undef, <2 x i32> zeroinitializer
  %121 = bitcast i8* %119 to <2 x i64>*
  store <2 x i64> %120, <2 x i64>* %121, align 1
  %122 = getelementptr inbounds i8, i8* %119, i64 16
  %123 = bitcast i8* %122 to <2 x i64>*
  store <2 x i64> %120, <2 x i64>* %123, align 1
  %124 = getelementptr inbounds i8, i8* %119, i64 32
  %125 = bitcast i8* %124 to <2 x i64>*
  store <2 x i64> %120, <2 x i64>* %125, align 1
  %126 = getelementptr inbounds i8, i8* %119, i64 48
  %127 = bitcast i8* %126 to <2 x i64>*
  store <2 x i64> %120, <2 x i64>* %127, align 1
  %128 = getelementptr inbounds i8, i8* %119, i64 %1
  %129 = shufflevector <2 x i64> %101, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %130 = bitcast i8* %128 to <2 x i64>*
  store <2 x i64> %129, <2 x i64>* %130, align 1
  %131 = getelementptr inbounds i8, i8* %128, i64 16
  %132 = bitcast i8* %131 to <2 x i64>*
  store <2 x i64> %129, <2 x i64>* %132, align 1
  %133 = getelementptr inbounds i8, i8* %128, i64 32
  %134 = bitcast i8* %133 to <2 x i64>*
  store <2 x i64> %129, <2 x i64>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %128, i64 48
  %136 = bitcast i8* %135 to <2 x i64>*
  store <2 x i64> %129, <2 x i64>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %94, i64 %5
  %138 = shufflevector <8 x i16> %95, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %139 = bitcast <8 x i16> %138 to <4 x i32>
  %140 = shufflevector <4 x i32> %139, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %141 = bitcast <4 x i32> %140 to <2 x i64>
  %142 = shufflevector <4 x i32> %139, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %143 = bitcast <4 x i32> %142 to <2 x i64>
  %144 = shufflevector <2 x i64> %141, <2 x i64> undef, <2 x i32> zeroinitializer
  %145 = bitcast i8* %137 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %145, align 1
  %146 = getelementptr inbounds i8, i8* %137, i64 16
  %147 = bitcast i8* %146 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %147, align 1
  %148 = getelementptr inbounds i8, i8* %137, i64 32
  %149 = bitcast i8* %148 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %149, align 1
  %150 = getelementptr inbounds i8, i8* %137, i64 48
  %151 = bitcast i8* %150 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %151, align 1
  %152 = getelementptr inbounds i8, i8* %137, i64 %1
  %153 = shufflevector <2 x i64> %141, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %154 = bitcast i8* %152 to <2 x i64>*
  store <2 x i64> %153, <2 x i64>* %154, align 1
  %155 = getelementptr inbounds i8, i8* %152, i64 16
  %156 = bitcast i8* %155 to <2 x i64>*
  store <2 x i64> %153, <2 x i64>* %156, align 1
  %157 = getelementptr inbounds i8, i8* %152, i64 32
  %158 = bitcast i8* %157 to <2 x i64>*
  store <2 x i64> %153, <2 x i64>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %152, i64 48
  %160 = bitcast i8* %159 to <2 x i64>*
  store <2 x i64> %153, <2 x i64>* %160, align 1
  %161 = getelementptr inbounds i8, i8* %152, i64 %1
  %162 = shufflevector <2 x i64> %143, <2 x i64> undef, <2 x i32> zeroinitializer
  %163 = bitcast i8* %161 to <2 x i64>*
  store <2 x i64> %162, <2 x i64>* %163, align 1
  %164 = getelementptr inbounds i8, i8* %161, i64 16
  %165 = bitcast i8* %164 to <2 x i64>*
  store <2 x i64> %162, <2 x i64>* %165, align 1
  %166 = getelementptr inbounds i8, i8* %161, i64 32
  %167 = bitcast i8* %166 to <2 x i64>*
  store <2 x i64> %162, <2 x i64>* %167, align 1
  %168 = getelementptr inbounds i8, i8* %161, i64 48
  %169 = bitcast i8* %168 to <2 x i64>*
  store <2 x i64> %162, <2 x i64>* %169, align 1
  %170 = getelementptr inbounds i8, i8* %161, i64 %1
  %171 = shufflevector <2 x i64> %143, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %172 = bitcast i8* %170 to <2 x i64>*
  store <2 x i64> %171, <2 x i64>* %172, align 1
  %173 = getelementptr inbounds i8, i8* %170, i64 16
  %174 = bitcast i8* %173 to <2 x i64>*
  store <2 x i64> %171, <2 x i64>* %174, align 1
  %175 = getelementptr inbounds i8, i8* %170, i64 32
  %176 = bitcast i8* %175 to <2 x i64>*
  store <2 x i64> %171, <2 x i64>* %176, align 1
  %177 = getelementptr inbounds i8, i8* %170, i64 48
  %178 = bitcast i8* %177 to <2 x i64>*
  store <2 x i64> %171, <2 x i64>* %178, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_18WriteDuplicate64x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %184, %6 ]
  %8 = phi i8* [ %0, %4 ], [ %183, %6 ]
  %9 = getelementptr inbounds i8, i8* %3, i64 %7
  %10 = bitcast i8* %9 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = shufflevector <16 x i8> %11, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %13 = shufflevector <16 x i8> %11, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %14 = bitcast <16 x i8> %12 to <8 x i16>
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %16 = bitcast <8 x i16> %15 to <4 x i32>
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %18 = bitcast <4 x i32> %17 to <2 x i64>
  %19 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %20 = bitcast <4 x i32> %19 to <2 x i64>
  %21 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> zeroinitializer
  %22 = bitcast i8* %8 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %8, i64 16
  %24 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %8, i64 32
  %26 = bitcast i8* %25 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %8, i64 48
  %28 = bitcast i8* %27 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %8, i64 %1
  %30 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %31 = bitcast i8* %29 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %29, i64 16
  %33 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %29, i64 32
  %35 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %35, align 1
  %36 = getelementptr inbounds i8, i8* %29, i64 48
  %37 = bitcast i8* %36 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %29, i64 %1
  %39 = shufflevector <2 x i64> %20, <2 x i64> undef, <2 x i32> zeroinitializer
  %40 = bitcast i8* %38 to <2 x i64>*
  store <2 x i64> %39, <2 x i64>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %38, i64 16
  %42 = bitcast i8* %41 to <2 x i64>*
  store <2 x i64> %39, <2 x i64>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %38, i64 32
  %44 = bitcast i8* %43 to <2 x i64>*
  store <2 x i64> %39, <2 x i64>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %38, i64 48
  %46 = bitcast i8* %45 to <2 x i64>*
  store <2 x i64> %39, <2 x i64>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %38, i64 %1
  %48 = shufflevector <2 x i64> %20, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %49 = bitcast i8* %47 to <2 x i64>*
  store <2 x i64> %48, <2 x i64>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %47, i64 16
  %51 = bitcast i8* %50 to <2 x i64>*
  store <2 x i64> %48, <2 x i64>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %47, i64 32
  %53 = bitcast i8* %52 to <2 x i64>*
  store <2 x i64> %48, <2 x i64>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %47, i64 48
  %55 = bitcast i8* %54 to <2 x i64>*
  store <2 x i64> %48, <2 x i64>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %8, i64 %5
  %57 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %58 = bitcast <8 x i16> %57 to <4 x i32>
  %59 = shufflevector <4 x i32> %58, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %60 = bitcast <4 x i32> %59 to <2 x i64>
  %61 = shufflevector <4 x i32> %58, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %62 = bitcast <4 x i32> %61 to <2 x i64>
  %63 = shufflevector <2 x i64> %60, <2 x i64> undef, <2 x i32> zeroinitializer
  %64 = bitcast i8* %56 to <2 x i64>*
  store <2 x i64> %63, <2 x i64>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %56, i64 16
  %66 = bitcast i8* %65 to <2 x i64>*
  store <2 x i64> %63, <2 x i64>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %56, i64 32
  %68 = bitcast i8* %67 to <2 x i64>*
  store <2 x i64> %63, <2 x i64>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %56, i64 48
  %70 = bitcast i8* %69 to <2 x i64>*
  store <2 x i64> %63, <2 x i64>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %56, i64 %1
  %72 = shufflevector <2 x i64> %60, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %73 = bitcast i8* %71 to <2 x i64>*
  store <2 x i64> %72, <2 x i64>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %71, i64 16
  %75 = bitcast i8* %74 to <2 x i64>*
  store <2 x i64> %72, <2 x i64>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %71, i64 32
  %77 = bitcast i8* %76 to <2 x i64>*
  store <2 x i64> %72, <2 x i64>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %71, i64 48
  %79 = bitcast i8* %78 to <2 x i64>*
  store <2 x i64> %72, <2 x i64>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %71, i64 %1
  %81 = shufflevector <2 x i64> %62, <2 x i64> undef, <2 x i32> zeroinitializer
  %82 = bitcast i8* %80 to <2 x i64>*
  store <2 x i64> %81, <2 x i64>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %80, i64 16
  %84 = bitcast i8* %83 to <2 x i64>*
  store <2 x i64> %81, <2 x i64>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %80, i64 32
  %86 = bitcast i8* %85 to <2 x i64>*
  store <2 x i64> %81, <2 x i64>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %80, i64 48
  %88 = bitcast i8* %87 to <2 x i64>*
  store <2 x i64> %81, <2 x i64>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %80, i64 %1
  %90 = shufflevector <2 x i64> %62, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %91 = bitcast i8* %89 to <2 x i64>*
  store <2 x i64> %90, <2 x i64>* %91, align 1
  %92 = getelementptr inbounds i8, i8* %89, i64 16
  %93 = bitcast i8* %92 to <2 x i64>*
  store <2 x i64> %90, <2 x i64>* %93, align 1
  %94 = getelementptr inbounds i8, i8* %89, i64 32
  %95 = bitcast i8* %94 to <2 x i64>*
  store <2 x i64> %90, <2 x i64>* %95, align 1
  %96 = getelementptr inbounds i8, i8* %89, i64 48
  %97 = bitcast i8* %96 to <2 x i64>*
  store <2 x i64> %90, <2 x i64>* %97, align 1
  %98 = getelementptr inbounds i8, i8* %56, i64 %5
  %99 = bitcast <16 x i8> %13 to <8 x i16>
  %100 = shufflevector <8 x i16> %99, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %101 = bitcast <8 x i16> %100 to <4 x i32>
  %102 = shufflevector <4 x i32> %101, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %103 = bitcast <4 x i32> %102 to <2 x i64>
  %104 = shufflevector <4 x i32> %101, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %105 = bitcast <4 x i32> %104 to <2 x i64>
  %106 = shufflevector <2 x i64> %103, <2 x i64> undef, <2 x i32> zeroinitializer
  %107 = bitcast i8* %98 to <2 x i64>*
  store <2 x i64> %106, <2 x i64>* %107, align 1
  %108 = getelementptr inbounds i8, i8* %98, i64 16
  %109 = bitcast i8* %108 to <2 x i64>*
  store <2 x i64> %106, <2 x i64>* %109, align 1
  %110 = getelementptr inbounds i8, i8* %98, i64 32
  %111 = bitcast i8* %110 to <2 x i64>*
  store <2 x i64> %106, <2 x i64>* %111, align 1
  %112 = getelementptr inbounds i8, i8* %98, i64 48
  %113 = bitcast i8* %112 to <2 x i64>*
  store <2 x i64> %106, <2 x i64>* %113, align 1
  %114 = getelementptr inbounds i8, i8* %98, i64 %1
  %115 = shufflevector <2 x i64> %103, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %116 = bitcast i8* %114 to <2 x i64>*
  store <2 x i64> %115, <2 x i64>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %114, i64 16
  %118 = bitcast i8* %117 to <2 x i64>*
  store <2 x i64> %115, <2 x i64>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %114, i64 32
  %120 = bitcast i8* %119 to <2 x i64>*
  store <2 x i64> %115, <2 x i64>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %114, i64 48
  %122 = bitcast i8* %121 to <2 x i64>*
  store <2 x i64> %115, <2 x i64>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %114, i64 %1
  %124 = shufflevector <2 x i64> %105, <2 x i64> undef, <2 x i32> zeroinitializer
  %125 = bitcast i8* %123 to <2 x i64>*
  store <2 x i64> %124, <2 x i64>* %125, align 1
  %126 = getelementptr inbounds i8, i8* %123, i64 16
  %127 = bitcast i8* %126 to <2 x i64>*
  store <2 x i64> %124, <2 x i64>* %127, align 1
  %128 = getelementptr inbounds i8, i8* %123, i64 32
  %129 = bitcast i8* %128 to <2 x i64>*
  store <2 x i64> %124, <2 x i64>* %129, align 1
  %130 = getelementptr inbounds i8, i8* %123, i64 48
  %131 = bitcast i8* %130 to <2 x i64>*
  store <2 x i64> %124, <2 x i64>* %131, align 1
  %132 = getelementptr inbounds i8, i8* %123, i64 %1
  %133 = shufflevector <2 x i64> %105, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %134 = bitcast i8* %132 to <2 x i64>*
  store <2 x i64> %133, <2 x i64>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %132, i64 16
  %136 = bitcast i8* %135 to <2 x i64>*
  store <2 x i64> %133, <2 x i64>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %132, i64 32
  %138 = bitcast i8* %137 to <2 x i64>*
  store <2 x i64> %133, <2 x i64>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %132, i64 48
  %140 = bitcast i8* %139 to <2 x i64>*
  store <2 x i64> %133, <2 x i64>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %98, i64 %5
  %142 = shufflevector <8 x i16> %99, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %143 = bitcast <8 x i16> %142 to <4 x i32>
  %144 = shufflevector <4 x i32> %143, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %145 = bitcast <4 x i32> %144 to <2 x i64>
  %146 = shufflevector <4 x i32> %143, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %147 = bitcast <4 x i32> %146 to <2 x i64>
  %148 = shufflevector <2 x i64> %145, <2 x i64> undef, <2 x i32> zeroinitializer
  %149 = bitcast i8* %141 to <2 x i64>*
  store <2 x i64> %148, <2 x i64>* %149, align 1
  %150 = getelementptr inbounds i8, i8* %141, i64 16
  %151 = bitcast i8* %150 to <2 x i64>*
  store <2 x i64> %148, <2 x i64>* %151, align 1
  %152 = getelementptr inbounds i8, i8* %141, i64 32
  %153 = bitcast i8* %152 to <2 x i64>*
  store <2 x i64> %148, <2 x i64>* %153, align 1
  %154 = getelementptr inbounds i8, i8* %141, i64 48
  %155 = bitcast i8* %154 to <2 x i64>*
  store <2 x i64> %148, <2 x i64>* %155, align 1
  %156 = getelementptr inbounds i8, i8* %141, i64 %1
  %157 = shufflevector <2 x i64> %145, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %158 = bitcast i8* %156 to <2 x i64>*
  store <2 x i64> %157, <2 x i64>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %156, i64 16
  %160 = bitcast i8* %159 to <2 x i64>*
  store <2 x i64> %157, <2 x i64>* %160, align 1
  %161 = getelementptr inbounds i8, i8* %156, i64 32
  %162 = bitcast i8* %161 to <2 x i64>*
  store <2 x i64> %157, <2 x i64>* %162, align 1
  %163 = getelementptr inbounds i8, i8* %156, i64 48
  %164 = bitcast i8* %163 to <2 x i64>*
  store <2 x i64> %157, <2 x i64>* %164, align 1
  %165 = getelementptr inbounds i8, i8* %156, i64 %1
  %166 = shufflevector <2 x i64> %147, <2 x i64> undef, <2 x i32> zeroinitializer
  %167 = bitcast i8* %165 to <2 x i64>*
  store <2 x i64> %166, <2 x i64>* %167, align 1
  %168 = getelementptr inbounds i8, i8* %165, i64 16
  %169 = bitcast i8* %168 to <2 x i64>*
  store <2 x i64> %166, <2 x i64>* %169, align 1
  %170 = getelementptr inbounds i8, i8* %165, i64 32
  %171 = bitcast i8* %170 to <2 x i64>*
  store <2 x i64> %166, <2 x i64>* %171, align 1
  %172 = getelementptr inbounds i8, i8* %165, i64 48
  %173 = bitcast i8* %172 to <2 x i64>*
  store <2 x i64> %166, <2 x i64>* %173, align 1
  %174 = getelementptr inbounds i8, i8* %165, i64 %1
  %175 = shufflevector <2 x i64> %147, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %176 = bitcast i8* %174 to <2 x i64>*
  store <2 x i64> %175, <2 x i64>* %176, align 1
  %177 = getelementptr inbounds i8, i8* %174, i64 16
  %178 = bitcast i8* %177 to <2 x i64>*
  store <2 x i64> %175, <2 x i64>* %178, align 1
  %179 = getelementptr inbounds i8, i8* %174, i64 32
  %180 = bitcast i8* %179 to <2 x i64>*
  store <2 x i64> %175, <2 x i64>* %180, align 1
  %181 = getelementptr inbounds i8, i8* %174, i64 48
  %182 = bitcast i8* %181 to <2 x i64>*
  store <2 x i64> %175, <2 x i64>* %182, align 1
  %183 = getelementptr inbounds i8, i8* %141, i64 %5
  %184 = add nuw nsw i64 %7, 16
  %185 = icmp ult i64 %184, 32
  br i1 %185, label %6, label %186

186:                                              ; preds = %6
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_12low_bitdepth12_GLOBAL__N_117ColStore64_SSE4_1IXadL_ZNS4_18WriteDuplicate64x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %184, %6 ]
  %8 = phi i8* [ %0, %4 ], [ %183, %6 ]
  %9 = getelementptr inbounds i8, i8* %3, i64 %7
  %10 = bitcast i8* %9 to <16 x i8>*
  %11 = load <16 x i8>, <16 x i8>* %10, align 1
  %12 = shufflevector <16 x i8> %11, <16 x i8> undef, <16 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3, i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %13 = shufflevector <16 x i8> %11, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 9, i32 9, i32 10, i32 10, i32 11, i32 11, i32 12, i32 12, i32 13, i32 13, i32 14, i32 14, i32 15, i32 15>
  %14 = bitcast <16 x i8> %12 to <8 x i16>
  %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %16 = bitcast <8 x i16> %15 to <4 x i32>
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %18 = bitcast <4 x i32> %17 to <2 x i64>
  %19 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %20 = bitcast <4 x i32> %19 to <2 x i64>
  %21 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> zeroinitializer
  %22 = bitcast i8* %8 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %8, i64 16
  %24 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %8, i64 32
  %26 = bitcast i8* %25 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %8, i64 48
  %28 = bitcast i8* %27 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %8, i64 %1
  %30 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %31 = bitcast i8* %29 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %29, i64 16
  %33 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %29, i64 32
  %35 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %35, align 1
  %36 = getelementptr inbounds i8, i8* %29, i64 48
  %37 = bitcast i8* %36 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %29, i64 %1
  %39 = shufflevector <2 x i64> %20, <2 x i64> undef, <2 x i32> zeroinitializer
  %40 = bitcast i8* %38 to <2 x i64>*
  store <2 x i64> %39, <2 x i64>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %38, i64 16
  %42 = bitcast i8* %41 to <2 x i64>*
  store <2 x i64> %39, <2 x i64>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %38, i64 32
  %44 = bitcast i8* %43 to <2 x i64>*
  store <2 x i64> %39, <2 x i64>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %38, i64 48
  %46 = bitcast i8* %45 to <2 x i64>*
  store <2 x i64> %39, <2 x i64>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %38, i64 %1
  %48 = shufflevector <2 x i64> %20, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %49 = bitcast i8* %47 to <2 x i64>*
  store <2 x i64> %48, <2 x i64>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %47, i64 16
  %51 = bitcast i8* %50 to <2 x i64>*
  store <2 x i64> %48, <2 x i64>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %47, i64 32
  %53 = bitcast i8* %52 to <2 x i64>*
  store <2 x i64> %48, <2 x i64>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %47, i64 48
  %55 = bitcast i8* %54 to <2 x i64>*
  store <2 x i64> %48, <2 x i64>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %8, i64 %5
  %57 = shufflevector <8 x i16> %14, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %58 = bitcast <8 x i16> %57 to <4 x i32>
  %59 = shufflevector <4 x i32> %58, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %60 = bitcast <4 x i32> %59 to <2 x i64>
  %61 = shufflevector <4 x i32> %58, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %62 = bitcast <4 x i32> %61 to <2 x i64>
  %63 = shufflevector <2 x i64> %60, <2 x i64> undef, <2 x i32> zeroinitializer
  %64 = bitcast i8* %56 to <2 x i64>*
  store <2 x i64> %63, <2 x i64>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %56, i64 16
  %66 = bitcast i8* %65 to <2 x i64>*
  store <2 x i64> %63, <2 x i64>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %56, i64 32
  %68 = bitcast i8* %67 to <2 x i64>*
  store <2 x i64> %63, <2 x i64>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %56, i64 48
  %70 = bitcast i8* %69 to <2 x i64>*
  store <2 x i64> %63, <2 x i64>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %56, i64 %1
  %72 = shufflevector <2 x i64> %60, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %73 = bitcast i8* %71 to <2 x i64>*
  store <2 x i64> %72, <2 x i64>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %71, i64 16
  %75 = bitcast i8* %74 to <2 x i64>*
  store <2 x i64> %72, <2 x i64>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %71, i64 32
  %77 = bitcast i8* %76 to <2 x i64>*
  store <2 x i64> %72, <2 x i64>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %71, i64 48
  %79 = bitcast i8* %78 to <2 x i64>*
  store <2 x i64> %72, <2 x i64>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %71, i64 %1
  %81 = shufflevector <2 x i64> %62, <2 x i64> undef, <2 x i32> zeroinitializer
  %82 = bitcast i8* %80 to <2 x i64>*
  store <2 x i64> %81, <2 x i64>* %82, align 1
  %83 = getelementptr inbounds i8, i8* %80, i64 16
  %84 = bitcast i8* %83 to <2 x i64>*
  store <2 x i64> %81, <2 x i64>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %80, i64 32
  %86 = bitcast i8* %85 to <2 x i64>*
  store <2 x i64> %81, <2 x i64>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %80, i64 48
  %88 = bitcast i8* %87 to <2 x i64>*
  store <2 x i64> %81, <2 x i64>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %80, i64 %1
  %90 = shufflevector <2 x i64> %62, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %91 = bitcast i8* %89 to <2 x i64>*
  store <2 x i64> %90, <2 x i64>* %91, align 1
  %92 = getelementptr inbounds i8, i8* %89, i64 16
  %93 = bitcast i8* %92 to <2 x i64>*
  store <2 x i64> %90, <2 x i64>* %93, align 1
  %94 = getelementptr inbounds i8, i8* %89, i64 32
  %95 = bitcast i8* %94 to <2 x i64>*
  store <2 x i64> %90, <2 x i64>* %95, align 1
  %96 = getelementptr inbounds i8, i8* %89, i64 48
  %97 = bitcast i8* %96 to <2 x i64>*
  store <2 x i64> %90, <2 x i64>* %97, align 1
  %98 = getelementptr inbounds i8, i8* %56, i64 %5
  %99 = bitcast <16 x i8> %13 to <8 x i16>
  %100 = shufflevector <8 x i16> %99, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %101 = bitcast <8 x i16> %100 to <4 x i32>
  %102 = shufflevector <4 x i32> %101, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %103 = bitcast <4 x i32> %102 to <2 x i64>
  %104 = shufflevector <4 x i32> %101, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %105 = bitcast <4 x i32> %104 to <2 x i64>
  %106 = shufflevector <2 x i64> %103, <2 x i64> undef, <2 x i32> zeroinitializer
  %107 = bitcast i8* %98 to <2 x i64>*
  store <2 x i64> %106, <2 x i64>* %107, align 1
  %108 = getelementptr inbounds i8, i8* %98, i64 16
  %109 = bitcast i8* %108 to <2 x i64>*
  store <2 x i64> %106, <2 x i64>* %109, align 1
  %110 = getelementptr inbounds i8, i8* %98, i64 32
  %111 = bitcast i8* %110 to <2 x i64>*
  store <2 x i64> %106, <2 x i64>* %111, align 1
  %112 = getelementptr inbounds i8, i8* %98, i64 48
  %113 = bitcast i8* %112 to <2 x i64>*
  store <2 x i64> %106, <2 x i64>* %113, align 1
  %114 = getelementptr inbounds i8, i8* %98, i64 %1
  %115 = shufflevector <2 x i64> %103, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %116 = bitcast i8* %114 to <2 x i64>*
  store <2 x i64> %115, <2 x i64>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %114, i64 16
  %118 = bitcast i8* %117 to <2 x i64>*
  store <2 x i64> %115, <2 x i64>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %114, i64 32
  %120 = bitcast i8* %119 to <2 x i64>*
  store <2 x i64> %115, <2 x i64>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %114, i64 48
  %122 = bitcast i8* %121 to <2 x i64>*
  store <2 x i64> %115, <2 x i64>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %114, i64 %1
  %124 = shufflevector <2 x i64> %105, <2 x i64> undef, <2 x i32> zeroinitializer
  %125 = bitcast i8* %123 to <2 x i64>*
  store <2 x i64> %124, <2 x i64>* %125, align 1
  %126 = getelementptr inbounds i8, i8* %123, i64 16
  %127 = bitcast i8* %126 to <2 x i64>*
  store <2 x i64> %124, <2 x i64>* %127, align 1
  %128 = getelementptr inbounds i8, i8* %123, i64 32
  %129 = bitcast i8* %128 to <2 x i64>*
  store <2 x i64> %124, <2 x i64>* %129, align 1
  %130 = getelementptr inbounds i8, i8* %123, i64 48
  %131 = bitcast i8* %130 to <2 x i64>*
  store <2 x i64> %124, <2 x i64>* %131, align 1
  %132 = getelementptr inbounds i8, i8* %123, i64 %1
  %133 = shufflevector <2 x i64> %105, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %134 = bitcast i8* %132 to <2 x i64>*
  store <2 x i64> %133, <2 x i64>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %132, i64 16
  %136 = bitcast i8* %135 to <2 x i64>*
  store <2 x i64> %133, <2 x i64>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %132, i64 32
  %138 = bitcast i8* %137 to <2 x i64>*
  store <2 x i64> %133, <2 x i64>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %132, i64 48
  %140 = bitcast i8* %139 to <2 x i64>*
  store <2 x i64> %133, <2 x i64>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %98, i64 %5
  %142 = shufflevector <8 x i16> %99, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %143 = bitcast <8 x i16> %142 to <4 x i32>
  %144 = shufflevector <4 x i32> %143, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %145 = bitcast <4 x i32> %144 to <2 x i64>
  %146 = shufflevector <4 x i32> %143, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %147 = bitcast <4 x i32> %146 to <2 x i64>
  %148 = shufflevector <2 x i64> %145, <2 x i64> undef, <2 x i32> zeroinitializer
  %149 = bitcast i8* %141 to <2 x i64>*
  store <2 x i64> %148, <2 x i64>* %149, align 1
  %150 = getelementptr inbounds i8, i8* %141, i64 16
  %151 = bitcast i8* %150 to <2 x i64>*
  store <2 x i64> %148, <2 x i64>* %151, align 1
  %152 = getelementptr inbounds i8, i8* %141, i64 32
  %153 = bitcast i8* %152 to <2 x i64>*
  store <2 x i64> %148, <2 x i64>* %153, align 1
  %154 = getelementptr inbounds i8, i8* %141, i64 48
  %155 = bitcast i8* %154 to <2 x i64>*
  store <2 x i64> %148, <2 x i64>* %155, align 1
  %156 = getelementptr inbounds i8, i8* %141, i64 %1
  %157 = shufflevector <2 x i64> %145, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %158 = bitcast i8* %156 to <2 x i64>*
  store <2 x i64> %157, <2 x i64>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %156, i64 16
  %160 = bitcast i8* %159 to <2 x i64>*
  store <2 x i64> %157, <2 x i64>* %160, align 1
  %161 = getelementptr inbounds i8, i8* %156, i64 32
  %162 = bitcast i8* %161 to <2 x i64>*
  store <2 x i64> %157, <2 x i64>* %162, align 1
  %163 = getelementptr inbounds i8, i8* %156, i64 48
  %164 = bitcast i8* %163 to <2 x i64>*
  store <2 x i64> %157, <2 x i64>* %164, align 1
  %165 = getelementptr inbounds i8, i8* %156, i64 %1
  %166 = shufflevector <2 x i64> %147, <2 x i64> undef, <2 x i32> zeroinitializer
  %167 = bitcast i8* %165 to <2 x i64>*
  store <2 x i64> %166, <2 x i64>* %167, align 1
  %168 = getelementptr inbounds i8, i8* %165, i64 16
  %169 = bitcast i8* %168 to <2 x i64>*
  store <2 x i64> %166, <2 x i64>* %169, align 1
  %170 = getelementptr inbounds i8, i8* %165, i64 32
  %171 = bitcast i8* %170 to <2 x i64>*
  store <2 x i64> %166, <2 x i64>* %171, align 1
  %172 = getelementptr inbounds i8, i8* %165, i64 48
  %173 = bitcast i8* %172 to <2 x i64>*
  store <2 x i64> %166, <2 x i64>* %173, align 1
  %174 = getelementptr inbounds i8, i8* %165, i64 %1
  %175 = shufflevector <2 x i64> %147, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %176 = bitcast i8* %174 to <2 x i64>*
  store <2 x i64> %175, <2 x i64>* %176, align 1
  %177 = getelementptr inbounds i8, i8* %174, i64 16
  %178 = bitcast i8* %177 to <2 x i64>*
  store <2 x i64> %175, <2 x i64>* %178, align 1
  %179 = getelementptr inbounds i8, i8* %174, i64 32
  %180 = bitcast i8* %179 to <2 x i64>*
  store <2 x i64> %175, <2 x i64>* %180, align 1
  %181 = getelementptr inbounds i8, i8* %174, i64 48
  %182 = bitcast i8* %181 to <2 x i64>*
  store <2 x i64> %175, <2 x i64>* %182, align 1
  %183 = getelementptr inbounds i8, i8* %141, i64 %5
  %184 = add nuw nsw i64 %7, 16
  %185 = icmp ult i64 %184, 64
  br i1 %185, label %6, label %186

186:                                              ; preds = %6
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #1

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8>, <16 x i8>) #6

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.pmadd.ub.sw.128(<16 x i8>, <16 x i8>) #6

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16>, <8 x i16>) #6

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #6

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16>, <8 x i16>) #6

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16>, <8 x i16>) #6

; Function Attrs: nounwind readnone
declare <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8>, <16 x i8>) #6

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16>, <8 x i16>) #6

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.usub.sat.v16i8(<16 x i8>, <16 x i8>) #7

; Function Attrs: inlinehint nounwind ssp uwtable writeonly
define internal fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_114WritePaeth16x8EPvlhDv2_xS4_(i8* nocapture, i64, i8 zeroext, <2 x i64>, <2 x i64>) unnamed_addr #8 {
  %6 = bitcast <2 x i64> %3 to <16 x i8>
  %7 = shufflevector <16 x i8> %6, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %8 = zext <8 x i8> %7 to <8 x i16>
  %9 = shufflevector <16 x i8> %6, <16 x i8> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %10 = zext <8 x i8> %9 to <8 x i16>
  %11 = zext i8 %2 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = insertelement <16 x i8> undef, i8 %2, i32 0
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> zeroinitializer
  %15 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %6, <16 x i8> %14) #11
  %16 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %14, <16 x i8> %6) #11
  %17 = or <16 x i8> %16, %15
  %18 = shufflevector <16 x i8> %17, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %19 = zext <8 x i8> %18 to <8 x i16>
  %20 = shufflevector <16 x i8> %17, <16 x i8> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %21 = zext <8 x i8> %20 to <8 x i16>
  %22 = bitcast <2 x i64> %4 to <16 x i8>
  %23 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %22, <16 x i8> %14) #11
  %24 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %14, <16 x i8> %22) #11
  %25 = or <16 x i8> %24, %23
  %26 = shl <8 x i16> %12, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %27 = shufflevector <8 x i16> %26, <8 x i16> undef, <8 x i32> zeroinitializer
  %28 = sub <8 x i16> %8, %27
  %29 = sub <8 x i16> %10, %27
  %30 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> zeroinitializer
  %31 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> zeroinitializer
  %32 = zext <8 x i8> %31 to <8 x i16>
  %33 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> zeroinitializer
  %34 = bitcast <16 x i8> %33 to <2 x i64>
  %35 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> zeroinitializer
  %36 = zext <8 x i8> %35 to <8 x i16>
  %37 = add <8 x i16> %28, %36
  %38 = sub <8 x i16> zeroinitializer, %37
  %39 = icmp slt <8 x i16> %37, zeroinitializer
  %40 = select <8 x i1> %39, <8 x i16> %38, <8 x i16> %37
  %41 = add <8 x i16> %29, %36
  %42 = sub <8 x i16> zeroinitializer, %41
  %43 = icmp slt <8 x i16> %41, zeroinitializer
  %44 = select <8 x i1> %43, <8 x i16> %42, <8 x i16> %41
  %45 = icmp slt <8 x i16> %40, %19
  %46 = sext <8 x i1> %45 to <8 x i16>
  %47 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %46, <8 x i16> undef) #11
  %48 = icmp slt <8 x i16> %44, %21
  %49 = sext <8 x i1> %48 to <8 x i16>
  %50 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %49, <8 x i16> undef) #11
  %51 = shufflevector <16 x i8> %47, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %52 = shufflevector <16 x i8> %51, <16 x i8> %50, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %53 = bitcast <16 x i8> %52 to <2 x i64>
  %54 = icmp slt <8 x i16> %40, %32
  %55 = sext <8 x i1> %54 to <8 x i16>
  %56 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %55, <8 x i16> undef) #11
  %57 = icmp slt <8 x i16> %44, %32
  %58 = sext <8 x i1> %57 to <8 x i16>
  %59 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %58, <8 x i16> undef) #11
  %60 = shufflevector <16 x i8> %56, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %61 = shufflevector <16 x i8> %60, <16 x i8> %59, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %62 = bitcast <16 x i8> %61 to <2 x i64>
  %63 = icmp ule <16 x i8> %17, %30
  %64 = sext <16 x i1> %63 to <16 x i8>
  %65 = bitcast <16 x i8> %64 to <2 x i64>
  %66 = xor <2 x i64> %53, <i64 -1, i64 -1>
  %67 = and <2 x i64> %66, %65
  %68 = and <2 x i64> %67, %34
  %69 = and <16 x i8> %61, %14
  %70 = bitcast <16 x i8> %69 to <2 x i64>
  %71 = xor <2 x i64> %62, <i64 -1, i64 -1>
  %72 = and <2 x i64> %71, %3
  %73 = or <2 x i64> %72, %70
  %74 = xor <2 x i64> %67, <i64 -1, i64 -1>
  %75 = and <2 x i64> %73, %74
  %76 = or <2 x i64> %75, %68
  %77 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %76, <2 x i64>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %0, i64 %1
  %79 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %80 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %81 = zext <8 x i8> %80 to <8 x i16>
  %82 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %83 = bitcast <16 x i8> %82 to <2 x i64>
  %84 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %85 = zext <8 x i8> %84 to <8 x i16>
  %86 = add <8 x i16> %28, %85
  %87 = sub <8 x i16> zeroinitializer, %86
  %88 = icmp slt <8 x i16> %86, zeroinitializer
  %89 = select <8 x i1> %88, <8 x i16> %87, <8 x i16> %86
  %90 = add <8 x i16> %29, %85
  %91 = sub <8 x i16> zeroinitializer, %90
  %92 = icmp slt <8 x i16> %90, zeroinitializer
  %93 = select <8 x i1> %92, <8 x i16> %91, <8 x i16> %90
  %94 = icmp slt <8 x i16> %89, %19
  %95 = sext <8 x i1> %94 to <8 x i16>
  %96 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %95, <8 x i16> undef) #11
  %97 = icmp slt <8 x i16> %93, %21
  %98 = sext <8 x i1> %97 to <8 x i16>
  %99 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %98, <8 x i16> undef) #11
  %100 = shufflevector <16 x i8> %96, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %101 = shufflevector <16 x i8> %100, <16 x i8> %99, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %102 = bitcast <16 x i8> %101 to <2 x i64>
  %103 = icmp slt <8 x i16> %89, %81
  %104 = sext <8 x i1> %103 to <8 x i16>
  %105 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %104, <8 x i16> undef) #11
  %106 = icmp slt <8 x i16> %93, %81
  %107 = sext <8 x i1> %106 to <8 x i16>
  %108 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %107, <8 x i16> undef) #11
  %109 = shufflevector <16 x i8> %105, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %110 = shufflevector <16 x i8> %109, <16 x i8> %108, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %111 = bitcast <16 x i8> %110 to <2 x i64>
  %112 = icmp ule <16 x i8> %17, %79
  %113 = sext <16 x i1> %112 to <16 x i8>
  %114 = bitcast <16 x i8> %113 to <2 x i64>
  %115 = xor <2 x i64> %102, <i64 -1, i64 -1>
  %116 = and <2 x i64> %115, %114
  %117 = and <2 x i64> %116, %83
  %118 = and <16 x i8> %110, %14
  %119 = bitcast <16 x i8> %118 to <2 x i64>
  %120 = xor <2 x i64> %111, <i64 -1, i64 -1>
  %121 = and <2 x i64> %120, %3
  %122 = or <2 x i64> %121, %119
  %123 = xor <2 x i64> %116, <i64 -1, i64 -1>
  %124 = and <2 x i64> %122, %123
  %125 = or <2 x i64> %124, %117
  %126 = bitcast i8* %78 to <2 x i64>*
  store <2 x i64> %125, <2 x i64>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %78, i64 %1
  %128 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %129 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %130 = zext <8 x i8> %129 to <8 x i16>
  %131 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %132 = bitcast <16 x i8> %131 to <2 x i64>
  %133 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %134 = zext <8 x i8> %133 to <8 x i16>
  %135 = add <8 x i16> %28, %134
  %136 = sub <8 x i16> zeroinitializer, %135
  %137 = icmp slt <8 x i16> %135, zeroinitializer
  %138 = select <8 x i1> %137, <8 x i16> %136, <8 x i16> %135
  %139 = add <8 x i16> %29, %134
  %140 = sub <8 x i16> zeroinitializer, %139
  %141 = icmp slt <8 x i16> %139, zeroinitializer
  %142 = select <8 x i1> %141, <8 x i16> %140, <8 x i16> %139
  %143 = icmp slt <8 x i16> %138, %19
  %144 = sext <8 x i1> %143 to <8 x i16>
  %145 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %144, <8 x i16> undef) #11
  %146 = icmp slt <8 x i16> %142, %21
  %147 = sext <8 x i1> %146 to <8 x i16>
  %148 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %147, <8 x i16> undef) #11
  %149 = shufflevector <16 x i8> %145, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %150 = shufflevector <16 x i8> %149, <16 x i8> %148, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %151 = bitcast <16 x i8> %150 to <2 x i64>
  %152 = icmp slt <8 x i16> %138, %130
  %153 = sext <8 x i1> %152 to <8 x i16>
  %154 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %153, <8 x i16> undef) #11
  %155 = icmp slt <8 x i16> %142, %130
  %156 = sext <8 x i1> %155 to <8 x i16>
  %157 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %156, <8 x i16> undef) #11
  %158 = shufflevector <16 x i8> %154, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %159 = shufflevector <16 x i8> %158, <16 x i8> %157, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %160 = bitcast <16 x i8> %159 to <2 x i64>
  %161 = icmp ule <16 x i8> %17, %128
  %162 = sext <16 x i1> %161 to <16 x i8>
  %163 = bitcast <16 x i8> %162 to <2 x i64>
  %164 = xor <2 x i64> %151, <i64 -1, i64 -1>
  %165 = and <2 x i64> %164, %163
  %166 = and <2 x i64> %165, %132
  %167 = and <16 x i8> %159, %14
  %168 = bitcast <16 x i8> %167 to <2 x i64>
  %169 = xor <2 x i64> %160, <i64 -1, i64 -1>
  %170 = and <2 x i64> %169, %3
  %171 = or <2 x i64> %170, %168
  %172 = xor <2 x i64> %165, <i64 -1, i64 -1>
  %173 = and <2 x i64> %171, %172
  %174 = or <2 x i64> %173, %166
  %175 = bitcast i8* %127 to <2 x i64>*
  store <2 x i64> %174, <2 x i64>* %175, align 1
  %176 = getelementptr inbounds i8, i8* %127, i64 %1
  %177 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %178 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %179 = zext <8 x i8> %178 to <8 x i16>
  %180 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %181 = bitcast <16 x i8> %180 to <2 x i64>
  %182 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %183 = zext <8 x i8> %182 to <8 x i16>
  %184 = add <8 x i16> %28, %183
  %185 = sub <8 x i16> zeroinitializer, %184
  %186 = icmp slt <8 x i16> %184, zeroinitializer
  %187 = select <8 x i1> %186, <8 x i16> %185, <8 x i16> %184
  %188 = add <8 x i16> %29, %183
  %189 = sub <8 x i16> zeroinitializer, %188
  %190 = icmp slt <8 x i16> %188, zeroinitializer
  %191 = select <8 x i1> %190, <8 x i16> %189, <8 x i16> %188
  %192 = icmp slt <8 x i16> %187, %19
  %193 = sext <8 x i1> %192 to <8 x i16>
  %194 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %193, <8 x i16> undef) #11
  %195 = icmp slt <8 x i16> %191, %21
  %196 = sext <8 x i1> %195 to <8 x i16>
  %197 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %196, <8 x i16> undef) #11
  %198 = shufflevector <16 x i8> %194, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %199 = shufflevector <16 x i8> %198, <16 x i8> %197, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %200 = bitcast <16 x i8> %199 to <2 x i64>
  %201 = icmp slt <8 x i16> %187, %179
  %202 = sext <8 x i1> %201 to <8 x i16>
  %203 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %202, <8 x i16> undef) #11
  %204 = icmp slt <8 x i16> %191, %179
  %205 = sext <8 x i1> %204 to <8 x i16>
  %206 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %205, <8 x i16> undef) #11
  %207 = shufflevector <16 x i8> %203, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %208 = shufflevector <16 x i8> %207, <16 x i8> %206, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %209 = bitcast <16 x i8> %208 to <2 x i64>
  %210 = icmp ule <16 x i8> %17, %177
  %211 = sext <16 x i1> %210 to <16 x i8>
  %212 = bitcast <16 x i8> %211 to <2 x i64>
  %213 = xor <2 x i64> %200, <i64 -1, i64 -1>
  %214 = and <2 x i64> %213, %212
  %215 = and <2 x i64> %214, %181
  %216 = and <16 x i8> %208, %14
  %217 = bitcast <16 x i8> %216 to <2 x i64>
  %218 = xor <2 x i64> %209, <i64 -1, i64 -1>
  %219 = and <2 x i64> %218, %3
  %220 = or <2 x i64> %219, %217
  %221 = xor <2 x i64> %214, <i64 -1, i64 -1>
  %222 = and <2 x i64> %220, %221
  %223 = or <2 x i64> %222, %215
  %224 = bitcast i8* %176 to <2 x i64>*
  store <2 x i64> %223, <2 x i64>* %224, align 1
  %225 = getelementptr inbounds i8, i8* %176, i64 %1
  %226 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4>
  %227 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4>
  %228 = zext <8 x i8> %227 to <8 x i16>
  %229 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4>
  %230 = bitcast <16 x i8> %229 to <2 x i64>
  %231 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4>
  %232 = zext <8 x i8> %231 to <8 x i16>
  %233 = add <8 x i16> %28, %232
  %234 = sub <8 x i16> zeroinitializer, %233
  %235 = icmp slt <8 x i16> %233, zeroinitializer
  %236 = select <8 x i1> %235, <8 x i16> %234, <8 x i16> %233
  %237 = add <8 x i16> %29, %232
  %238 = sub <8 x i16> zeroinitializer, %237
  %239 = icmp slt <8 x i16> %237, zeroinitializer
  %240 = select <8 x i1> %239, <8 x i16> %238, <8 x i16> %237
  %241 = icmp slt <8 x i16> %236, %19
  %242 = sext <8 x i1> %241 to <8 x i16>
  %243 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %242, <8 x i16> undef) #11
  %244 = icmp slt <8 x i16> %240, %21
  %245 = sext <8 x i1> %244 to <8 x i16>
  %246 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %245, <8 x i16> undef) #11
  %247 = shufflevector <16 x i8> %243, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %248 = shufflevector <16 x i8> %247, <16 x i8> %246, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %249 = bitcast <16 x i8> %248 to <2 x i64>
  %250 = icmp slt <8 x i16> %236, %228
  %251 = sext <8 x i1> %250 to <8 x i16>
  %252 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %251, <8 x i16> undef) #11
  %253 = icmp slt <8 x i16> %240, %228
  %254 = sext <8 x i1> %253 to <8 x i16>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %254, <8 x i16> undef) #11
  %256 = shufflevector <16 x i8> %252, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %257 = shufflevector <16 x i8> %256, <16 x i8> %255, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %258 = bitcast <16 x i8> %257 to <2 x i64>
  %259 = icmp ule <16 x i8> %17, %226
  %260 = sext <16 x i1> %259 to <16 x i8>
  %261 = bitcast <16 x i8> %260 to <2 x i64>
  %262 = xor <2 x i64> %249, <i64 -1, i64 -1>
  %263 = and <2 x i64> %262, %261
  %264 = and <2 x i64> %263, %230
  %265 = and <16 x i8> %257, %14
  %266 = bitcast <16 x i8> %265 to <2 x i64>
  %267 = xor <2 x i64> %258, <i64 -1, i64 -1>
  %268 = and <2 x i64> %267, %3
  %269 = or <2 x i64> %268, %266
  %270 = xor <2 x i64> %263, <i64 -1, i64 -1>
  %271 = and <2 x i64> %269, %270
  %272 = or <2 x i64> %271, %264
  %273 = bitcast i8* %225 to <2 x i64>*
  store <2 x i64> %272, <2 x i64>* %273, align 1
  %274 = getelementptr inbounds i8, i8* %225, i64 %1
  %275 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %276 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %277 = zext <8 x i8> %276 to <8 x i16>
  %278 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %279 = bitcast <16 x i8> %278 to <2 x i64>
  %280 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %281 = zext <8 x i8> %280 to <8 x i16>
  %282 = add <8 x i16> %28, %281
  %283 = sub <8 x i16> zeroinitializer, %282
  %284 = icmp slt <8 x i16> %282, zeroinitializer
  %285 = select <8 x i1> %284, <8 x i16> %283, <8 x i16> %282
  %286 = add <8 x i16> %29, %281
  %287 = sub <8 x i16> zeroinitializer, %286
  %288 = icmp slt <8 x i16> %286, zeroinitializer
  %289 = select <8 x i1> %288, <8 x i16> %287, <8 x i16> %286
  %290 = icmp slt <8 x i16> %285, %19
  %291 = sext <8 x i1> %290 to <8 x i16>
  %292 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %291, <8 x i16> undef) #11
  %293 = icmp slt <8 x i16> %289, %21
  %294 = sext <8 x i1> %293 to <8 x i16>
  %295 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %294, <8 x i16> undef) #11
  %296 = shufflevector <16 x i8> %292, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %297 = shufflevector <16 x i8> %296, <16 x i8> %295, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %298 = bitcast <16 x i8> %297 to <2 x i64>
  %299 = icmp slt <8 x i16> %285, %277
  %300 = sext <8 x i1> %299 to <8 x i16>
  %301 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %300, <8 x i16> undef) #11
  %302 = icmp slt <8 x i16> %289, %277
  %303 = sext <8 x i1> %302 to <8 x i16>
  %304 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %303, <8 x i16> undef) #11
  %305 = shufflevector <16 x i8> %301, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %306 = shufflevector <16 x i8> %305, <16 x i8> %304, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %307 = bitcast <16 x i8> %306 to <2 x i64>
  %308 = icmp ule <16 x i8> %17, %275
  %309 = sext <16 x i1> %308 to <16 x i8>
  %310 = bitcast <16 x i8> %309 to <2 x i64>
  %311 = xor <2 x i64> %298, <i64 -1, i64 -1>
  %312 = and <2 x i64> %311, %310
  %313 = and <2 x i64> %312, %279
  %314 = and <16 x i8> %306, %14
  %315 = bitcast <16 x i8> %314 to <2 x i64>
  %316 = xor <2 x i64> %307, <i64 -1, i64 -1>
  %317 = and <2 x i64> %316, %3
  %318 = or <2 x i64> %317, %315
  %319 = xor <2 x i64> %312, <i64 -1, i64 -1>
  %320 = and <2 x i64> %318, %319
  %321 = or <2 x i64> %320, %313
  %322 = bitcast i8* %274 to <2 x i64>*
  store <2 x i64> %321, <2 x i64>* %322, align 1
  %323 = getelementptr inbounds i8, i8* %274, i64 %1
  %324 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %325 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %326 = zext <8 x i8> %325 to <8 x i16>
  %327 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %328 = bitcast <16 x i8> %327 to <2 x i64>
  %329 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %330 = zext <8 x i8> %329 to <8 x i16>
  %331 = add <8 x i16> %28, %330
  %332 = sub <8 x i16> zeroinitializer, %331
  %333 = icmp slt <8 x i16> %331, zeroinitializer
  %334 = select <8 x i1> %333, <8 x i16> %332, <8 x i16> %331
  %335 = add <8 x i16> %29, %330
  %336 = sub <8 x i16> zeroinitializer, %335
  %337 = icmp slt <8 x i16> %335, zeroinitializer
  %338 = select <8 x i1> %337, <8 x i16> %336, <8 x i16> %335
  %339 = icmp slt <8 x i16> %334, %19
  %340 = sext <8 x i1> %339 to <8 x i16>
  %341 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %340, <8 x i16> undef) #11
  %342 = icmp slt <8 x i16> %338, %21
  %343 = sext <8 x i1> %342 to <8 x i16>
  %344 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %343, <8 x i16> undef) #11
  %345 = shufflevector <16 x i8> %341, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %346 = shufflevector <16 x i8> %345, <16 x i8> %344, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %347 = bitcast <16 x i8> %346 to <2 x i64>
  %348 = icmp slt <8 x i16> %334, %326
  %349 = sext <8 x i1> %348 to <8 x i16>
  %350 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %349, <8 x i16> undef) #11
  %351 = icmp slt <8 x i16> %338, %326
  %352 = sext <8 x i1> %351 to <8 x i16>
  %353 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %352, <8 x i16> undef) #11
  %354 = shufflevector <16 x i8> %350, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %355 = shufflevector <16 x i8> %354, <16 x i8> %353, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %356 = bitcast <16 x i8> %355 to <2 x i64>
  %357 = icmp ule <16 x i8> %17, %324
  %358 = sext <16 x i1> %357 to <16 x i8>
  %359 = bitcast <16 x i8> %358 to <2 x i64>
  %360 = xor <2 x i64> %347, <i64 -1, i64 -1>
  %361 = and <2 x i64> %360, %359
  %362 = and <2 x i64> %361, %328
  %363 = and <16 x i8> %355, %14
  %364 = bitcast <16 x i8> %363 to <2 x i64>
  %365 = xor <2 x i64> %356, <i64 -1, i64 -1>
  %366 = and <2 x i64> %365, %3
  %367 = or <2 x i64> %366, %364
  %368 = xor <2 x i64> %361, <i64 -1, i64 -1>
  %369 = and <2 x i64> %367, %368
  %370 = or <2 x i64> %369, %362
  %371 = bitcast i8* %323 to <2 x i64>*
  store <2 x i64> %370, <2 x i64>* %371, align 1
  %372 = getelementptr inbounds i8, i8* %323, i64 %1
  %373 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %374 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %375 = zext <8 x i8> %374 to <8 x i16>
  %376 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %377 = bitcast <16 x i8> %376 to <2 x i64>
  %378 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %379 = zext <8 x i8> %378 to <8 x i16>
  %380 = add <8 x i16> %28, %379
  %381 = sub <8 x i16> zeroinitializer, %380
  %382 = icmp slt <8 x i16> %380, zeroinitializer
  %383 = select <8 x i1> %382, <8 x i16> %381, <8 x i16> %380
  %384 = add <8 x i16> %29, %379
  %385 = sub <8 x i16> zeroinitializer, %384
  %386 = icmp slt <8 x i16> %384, zeroinitializer
  %387 = select <8 x i1> %386, <8 x i16> %385, <8 x i16> %384
  %388 = icmp slt <8 x i16> %383, %19
  %389 = sext <8 x i1> %388 to <8 x i16>
  %390 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %389, <8 x i16> undef) #11
  %391 = icmp slt <8 x i16> %387, %21
  %392 = sext <8 x i1> %391 to <8 x i16>
  %393 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %392, <8 x i16> undef) #11
  %394 = shufflevector <16 x i8> %390, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %395 = shufflevector <16 x i8> %394, <16 x i8> %393, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %396 = bitcast <16 x i8> %395 to <2 x i64>
  %397 = icmp slt <8 x i16> %383, %375
  %398 = sext <8 x i1> %397 to <8 x i16>
  %399 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %398, <8 x i16> undef) #11
  %400 = icmp slt <8 x i16> %387, %375
  %401 = sext <8 x i1> %400 to <8 x i16>
  %402 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %401, <8 x i16> undef) #11
  %403 = shufflevector <16 x i8> %399, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %404 = shufflevector <16 x i8> %403, <16 x i8> %402, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %405 = bitcast <16 x i8> %404 to <2 x i64>
  %406 = icmp ule <16 x i8> %17, %373
  %407 = sext <16 x i1> %406 to <16 x i8>
  %408 = bitcast <16 x i8> %407 to <2 x i64>
  %409 = xor <2 x i64> %396, <i64 -1, i64 -1>
  %410 = and <2 x i64> %409, %408
  %411 = and <2 x i64> %410, %377
  %412 = and <16 x i8> %404, %14
  %413 = bitcast <16 x i8> %412 to <2 x i64>
  %414 = xor <2 x i64> %405, <i64 -1, i64 -1>
  %415 = and <2 x i64> %414, %3
  %416 = or <2 x i64> %415, %413
  %417 = xor <2 x i64> %410, <i64 -1, i64 -1>
  %418 = and <2 x i64> %416, %417
  %419 = or <2 x i64> %418, %411
  %420 = bitcast i8* %372 to <2 x i64>*
  store <2 x i64> %419, <2 x i64>* %420, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable writeonly
define internal fastcc void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_115WritePaeth16x16EPvlhDv2_xS4_(i8* nocapture, i64, i8 zeroext, <2 x i64>, <2 x i64>) unnamed_addr #9 {
  %6 = bitcast <2 x i64> %3 to <16 x i8>
  %7 = shufflevector <16 x i8> %6, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %8 = zext <8 x i8> %7 to <8 x i16>
  %9 = shufflevector <16 x i8> %6, <16 x i8> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %10 = zext <8 x i8> %9 to <8 x i16>
  %11 = zext i8 %2 to i16
  %12 = insertelement <8 x i16> undef, i16 %11, i32 0
  %13 = insertelement <16 x i8> undef, i8 %2, i32 0
  %14 = shufflevector <16 x i8> %13, <16 x i8> undef, <16 x i32> zeroinitializer
  %15 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %6, <16 x i8> %14) #11
  %16 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %14, <16 x i8> %6) #11
  %17 = or <16 x i8> %16, %15
  %18 = shufflevector <16 x i8> %17, <16 x i8> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %19 = zext <8 x i8> %18 to <8 x i16>
  %20 = shufflevector <16 x i8> %17, <16 x i8> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %21 = zext <8 x i8> %20 to <8 x i16>
  %22 = bitcast <2 x i64> %4 to <16 x i8>
  %23 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %22, <16 x i8> %14) #11
  %24 = tail call <16 x i8> @llvm.usub.sat.v16i8(<16 x i8> %14, <16 x i8> %22) #11
  %25 = or <16 x i8> %24, %23
  %26 = shl <8 x i16> %12, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %27 = shufflevector <8 x i16> %26, <8 x i16> undef, <8 x i32> zeroinitializer
  %28 = sub <8 x i16> %8, %27
  %29 = sub <8 x i16> %10, %27
  %30 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> zeroinitializer
  %31 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> zeroinitializer
  %32 = zext <8 x i8> %31 to <8 x i16>
  %33 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> zeroinitializer
  %34 = bitcast <16 x i8> %33 to <2 x i64>
  %35 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> zeroinitializer
  %36 = zext <8 x i8> %35 to <8 x i16>
  %37 = add <8 x i16> %28, %36
  %38 = sub <8 x i16> zeroinitializer, %37
  %39 = icmp slt <8 x i16> %37, zeroinitializer
  %40 = select <8 x i1> %39, <8 x i16> %38, <8 x i16> %37
  %41 = add <8 x i16> %29, %36
  %42 = sub <8 x i16> zeroinitializer, %41
  %43 = icmp slt <8 x i16> %41, zeroinitializer
  %44 = select <8 x i1> %43, <8 x i16> %42, <8 x i16> %41
  %45 = icmp slt <8 x i16> %40, %19
  %46 = sext <8 x i1> %45 to <8 x i16>
  %47 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %46, <8 x i16> undef) #11
  %48 = icmp slt <8 x i16> %44, %21
  %49 = sext <8 x i1> %48 to <8 x i16>
  %50 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %49, <8 x i16> undef) #11
  %51 = shufflevector <16 x i8> %47, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %52 = shufflevector <16 x i8> %51, <16 x i8> %50, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %53 = bitcast <16 x i8> %52 to <2 x i64>
  %54 = icmp slt <8 x i16> %40, %32
  %55 = sext <8 x i1> %54 to <8 x i16>
  %56 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %55, <8 x i16> undef) #11
  %57 = icmp slt <8 x i16> %44, %32
  %58 = sext <8 x i1> %57 to <8 x i16>
  %59 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %58, <8 x i16> undef) #11
  %60 = shufflevector <16 x i8> %56, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %61 = shufflevector <16 x i8> %60, <16 x i8> %59, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %62 = bitcast <16 x i8> %61 to <2 x i64>
  %63 = icmp ule <16 x i8> %17, %30
  %64 = sext <16 x i1> %63 to <16 x i8>
  %65 = bitcast <16 x i8> %64 to <2 x i64>
  %66 = xor <2 x i64> %53, <i64 -1, i64 -1>
  %67 = and <2 x i64> %66, %65
  %68 = and <2 x i64> %67, %34
  %69 = and <16 x i8> %61, %14
  %70 = bitcast <16 x i8> %69 to <2 x i64>
  %71 = xor <2 x i64> %62, <i64 -1, i64 -1>
  %72 = and <2 x i64> %71, %3
  %73 = or <2 x i64> %72, %70
  %74 = xor <2 x i64> %67, <i64 -1, i64 -1>
  %75 = and <2 x i64> %73, %74
  %76 = or <2 x i64> %75, %68
  %77 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %76, <2 x i64>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %0, i64 %1
  %79 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %80 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %81 = zext <8 x i8> %80 to <8 x i16>
  %82 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %83 = bitcast <16 x i8> %82 to <2 x i64>
  %84 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %85 = zext <8 x i8> %84 to <8 x i16>
  %86 = add <8 x i16> %28, %85
  %87 = sub <8 x i16> zeroinitializer, %86
  %88 = icmp slt <8 x i16> %86, zeroinitializer
  %89 = select <8 x i1> %88, <8 x i16> %87, <8 x i16> %86
  %90 = add <8 x i16> %29, %85
  %91 = sub <8 x i16> zeroinitializer, %90
  %92 = icmp slt <8 x i16> %90, zeroinitializer
  %93 = select <8 x i1> %92, <8 x i16> %91, <8 x i16> %90
  %94 = icmp slt <8 x i16> %89, %19
  %95 = sext <8 x i1> %94 to <8 x i16>
  %96 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %95, <8 x i16> undef) #11
  %97 = icmp slt <8 x i16> %93, %21
  %98 = sext <8 x i1> %97 to <8 x i16>
  %99 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %98, <8 x i16> undef) #11
  %100 = shufflevector <16 x i8> %96, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %101 = shufflevector <16 x i8> %100, <16 x i8> %99, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %102 = bitcast <16 x i8> %101 to <2 x i64>
  %103 = icmp slt <8 x i16> %89, %81
  %104 = sext <8 x i1> %103 to <8 x i16>
  %105 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %104, <8 x i16> undef) #11
  %106 = icmp slt <8 x i16> %93, %81
  %107 = sext <8 x i1> %106 to <8 x i16>
  %108 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %107, <8 x i16> undef) #11
  %109 = shufflevector <16 x i8> %105, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %110 = shufflevector <16 x i8> %109, <16 x i8> %108, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %111 = bitcast <16 x i8> %110 to <2 x i64>
  %112 = icmp ule <16 x i8> %17, %79
  %113 = sext <16 x i1> %112 to <16 x i8>
  %114 = bitcast <16 x i8> %113 to <2 x i64>
  %115 = xor <2 x i64> %102, <i64 -1, i64 -1>
  %116 = and <2 x i64> %115, %114
  %117 = and <2 x i64> %116, %83
  %118 = and <16 x i8> %110, %14
  %119 = bitcast <16 x i8> %118 to <2 x i64>
  %120 = xor <2 x i64> %111, <i64 -1, i64 -1>
  %121 = and <2 x i64> %120, %3
  %122 = or <2 x i64> %121, %119
  %123 = xor <2 x i64> %116, <i64 -1, i64 -1>
  %124 = and <2 x i64> %122, %123
  %125 = or <2 x i64> %124, %117
  %126 = bitcast i8* %78 to <2 x i64>*
  store <2 x i64> %125, <2 x i64>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %78, i64 %1
  %128 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %129 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %130 = zext <8 x i8> %129 to <8 x i16>
  %131 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %132 = bitcast <16 x i8> %131 to <2 x i64>
  %133 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %134 = zext <8 x i8> %133 to <8 x i16>
  %135 = add <8 x i16> %28, %134
  %136 = sub <8 x i16> zeroinitializer, %135
  %137 = icmp slt <8 x i16> %135, zeroinitializer
  %138 = select <8 x i1> %137, <8 x i16> %136, <8 x i16> %135
  %139 = add <8 x i16> %29, %134
  %140 = sub <8 x i16> zeroinitializer, %139
  %141 = icmp slt <8 x i16> %139, zeroinitializer
  %142 = select <8 x i1> %141, <8 x i16> %140, <8 x i16> %139
  %143 = icmp slt <8 x i16> %138, %19
  %144 = sext <8 x i1> %143 to <8 x i16>
  %145 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %144, <8 x i16> undef) #11
  %146 = icmp slt <8 x i16> %142, %21
  %147 = sext <8 x i1> %146 to <8 x i16>
  %148 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %147, <8 x i16> undef) #11
  %149 = shufflevector <16 x i8> %145, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %150 = shufflevector <16 x i8> %149, <16 x i8> %148, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %151 = bitcast <16 x i8> %150 to <2 x i64>
  %152 = icmp slt <8 x i16> %138, %130
  %153 = sext <8 x i1> %152 to <8 x i16>
  %154 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %153, <8 x i16> undef) #11
  %155 = icmp slt <8 x i16> %142, %130
  %156 = sext <8 x i1> %155 to <8 x i16>
  %157 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %156, <8 x i16> undef) #11
  %158 = shufflevector <16 x i8> %154, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %159 = shufflevector <16 x i8> %158, <16 x i8> %157, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %160 = bitcast <16 x i8> %159 to <2 x i64>
  %161 = icmp ule <16 x i8> %17, %128
  %162 = sext <16 x i1> %161 to <16 x i8>
  %163 = bitcast <16 x i8> %162 to <2 x i64>
  %164 = xor <2 x i64> %151, <i64 -1, i64 -1>
  %165 = and <2 x i64> %164, %163
  %166 = and <2 x i64> %165, %132
  %167 = and <16 x i8> %159, %14
  %168 = bitcast <16 x i8> %167 to <2 x i64>
  %169 = xor <2 x i64> %160, <i64 -1, i64 -1>
  %170 = and <2 x i64> %169, %3
  %171 = or <2 x i64> %170, %168
  %172 = xor <2 x i64> %165, <i64 -1, i64 -1>
  %173 = and <2 x i64> %171, %172
  %174 = or <2 x i64> %173, %166
  %175 = bitcast i8* %127 to <2 x i64>*
  store <2 x i64> %174, <2 x i64>* %175, align 1
  %176 = getelementptr inbounds i8, i8* %127, i64 %1
  %177 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %178 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %179 = zext <8 x i8> %178 to <8 x i16>
  %180 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %181 = bitcast <16 x i8> %180 to <2 x i64>
  %182 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3>
  %183 = zext <8 x i8> %182 to <8 x i16>
  %184 = add <8 x i16> %28, %183
  %185 = sub <8 x i16> zeroinitializer, %184
  %186 = icmp slt <8 x i16> %184, zeroinitializer
  %187 = select <8 x i1> %186, <8 x i16> %185, <8 x i16> %184
  %188 = add <8 x i16> %29, %183
  %189 = sub <8 x i16> zeroinitializer, %188
  %190 = icmp slt <8 x i16> %188, zeroinitializer
  %191 = select <8 x i1> %190, <8 x i16> %189, <8 x i16> %188
  %192 = icmp slt <8 x i16> %187, %19
  %193 = sext <8 x i1> %192 to <8 x i16>
  %194 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %193, <8 x i16> undef) #11
  %195 = icmp slt <8 x i16> %191, %21
  %196 = sext <8 x i1> %195 to <8 x i16>
  %197 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %196, <8 x i16> undef) #11
  %198 = shufflevector <16 x i8> %194, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %199 = shufflevector <16 x i8> %198, <16 x i8> %197, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %200 = bitcast <16 x i8> %199 to <2 x i64>
  %201 = icmp slt <8 x i16> %187, %179
  %202 = sext <8 x i1> %201 to <8 x i16>
  %203 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %202, <8 x i16> undef) #11
  %204 = icmp slt <8 x i16> %191, %179
  %205 = sext <8 x i1> %204 to <8 x i16>
  %206 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %205, <8 x i16> undef) #11
  %207 = shufflevector <16 x i8> %203, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %208 = shufflevector <16 x i8> %207, <16 x i8> %206, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %209 = bitcast <16 x i8> %208 to <2 x i64>
  %210 = icmp ule <16 x i8> %17, %177
  %211 = sext <16 x i1> %210 to <16 x i8>
  %212 = bitcast <16 x i8> %211 to <2 x i64>
  %213 = xor <2 x i64> %200, <i64 -1, i64 -1>
  %214 = and <2 x i64> %213, %212
  %215 = and <2 x i64> %214, %181
  %216 = and <16 x i8> %208, %14
  %217 = bitcast <16 x i8> %216 to <2 x i64>
  %218 = xor <2 x i64> %209, <i64 -1, i64 -1>
  %219 = and <2 x i64> %218, %3
  %220 = or <2 x i64> %219, %217
  %221 = xor <2 x i64> %214, <i64 -1, i64 -1>
  %222 = and <2 x i64> %220, %221
  %223 = or <2 x i64> %222, %215
  %224 = bitcast i8* %176 to <2 x i64>*
  store <2 x i64> %223, <2 x i64>* %224, align 1
  %225 = getelementptr inbounds i8, i8* %176, i64 %1
  %226 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4>
  %227 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4>
  %228 = zext <8 x i8> %227 to <8 x i16>
  %229 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4>
  %230 = bitcast <16 x i8> %229 to <2 x i64>
  %231 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4>
  %232 = zext <8 x i8> %231 to <8 x i16>
  %233 = add <8 x i16> %28, %232
  %234 = sub <8 x i16> zeroinitializer, %233
  %235 = icmp slt <8 x i16> %233, zeroinitializer
  %236 = select <8 x i1> %235, <8 x i16> %234, <8 x i16> %233
  %237 = add <8 x i16> %29, %232
  %238 = sub <8 x i16> zeroinitializer, %237
  %239 = icmp slt <8 x i16> %237, zeroinitializer
  %240 = select <8 x i1> %239, <8 x i16> %238, <8 x i16> %237
  %241 = icmp slt <8 x i16> %236, %19
  %242 = sext <8 x i1> %241 to <8 x i16>
  %243 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %242, <8 x i16> undef) #11
  %244 = icmp slt <8 x i16> %240, %21
  %245 = sext <8 x i1> %244 to <8 x i16>
  %246 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %245, <8 x i16> undef) #11
  %247 = shufflevector <16 x i8> %243, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %248 = shufflevector <16 x i8> %247, <16 x i8> %246, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %249 = bitcast <16 x i8> %248 to <2 x i64>
  %250 = icmp slt <8 x i16> %236, %228
  %251 = sext <8 x i1> %250 to <8 x i16>
  %252 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %251, <8 x i16> undef) #11
  %253 = icmp slt <8 x i16> %240, %228
  %254 = sext <8 x i1> %253 to <8 x i16>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %254, <8 x i16> undef) #11
  %256 = shufflevector <16 x i8> %252, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %257 = shufflevector <16 x i8> %256, <16 x i8> %255, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %258 = bitcast <16 x i8> %257 to <2 x i64>
  %259 = icmp ule <16 x i8> %17, %226
  %260 = sext <16 x i1> %259 to <16 x i8>
  %261 = bitcast <16 x i8> %260 to <2 x i64>
  %262 = xor <2 x i64> %249, <i64 -1, i64 -1>
  %263 = and <2 x i64> %262, %261
  %264 = and <2 x i64> %263, %230
  %265 = and <16 x i8> %257, %14
  %266 = bitcast <16 x i8> %265 to <2 x i64>
  %267 = xor <2 x i64> %258, <i64 -1, i64 -1>
  %268 = and <2 x i64> %267, %3
  %269 = or <2 x i64> %268, %266
  %270 = xor <2 x i64> %263, <i64 -1, i64 -1>
  %271 = and <2 x i64> %269, %270
  %272 = or <2 x i64> %271, %264
  %273 = bitcast i8* %225 to <2 x i64>*
  store <2 x i64> %272, <2 x i64>* %273, align 1
  %274 = getelementptr inbounds i8, i8* %225, i64 %1
  %275 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %276 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %277 = zext <8 x i8> %276 to <8 x i16>
  %278 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %279 = bitcast <16 x i8> %278 to <2 x i64>
  %280 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5, i32 5>
  %281 = zext <8 x i8> %280 to <8 x i16>
  %282 = add <8 x i16> %28, %281
  %283 = sub <8 x i16> zeroinitializer, %282
  %284 = icmp slt <8 x i16> %282, zeroinitializer
  %285 = select <8 x i1> %284, <8 x i16> %283, <8 x i16> %282
  %286 = add <8 x i16> %29, %281
  %287 = sub <8 x i16> zeroinitializer, %286
  %288 = icmp slt <8 x i16> %286, zeroinitializer
  %289 = select <8 x i1> %288, <8 x i16> %287, <8 x i16> %286
  %290 = icmp slt <8 x i16> %285, %19
  %291 = sext <8 x i1> %290 to <8 x i16>
  %292 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %291, <8 x i16> undef) #11
  %293 = icmp slt <8 x i16> %289, %21
  %294 = sext <8 x i1> %293 to <8 x i16>
  %295 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %294, <8 x i16> undef) #11
  %296 = shufflevector <16 x i8> %292, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %297 = shufflevector <16 x i8> %296, <16 x i8> %295, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %298 = bitcast <16 x i8> %297 to <2 x i64>
  %299 = icmp slt <8 x i16> %285, %277
  %300 = sext <8 x i1> %299 to <8 x i16>
  %301 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %300, <8 x i16> undef) #11
  %302 = icmp slt <8 x i16> %289, %277
  %303 = sext <8 x i1> %302 to <8 x i16>
  %304 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %303, <8 x i16> undef) #11
  %305 = shufflevector <16 x i8> %301, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %306 = shufflevector <16 x i8> %305, <16 x i8> %304, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %307 = bitcast <16 x i8> %306 to <2 x i64>
  %308 = icmp ule <16 x i8> %17, %275
  %309 = sext <16 x i1> %308 to <16 x i8>
  %310 = bitcast <16 x i8> %309 to <2 x i64>
  %311 = xor <2 x i64> %298, <i64 -1, i64 -1>
  %312 = and <2 x i64> %311, %310
  %313 = and <2 x i64> %312, %279
  %314 = and <16 x i8> %306, %14
  %315 = bitcast <16 x i8> %314 to <2 x i64>
  %316 = xor <2 x i64> %307, <i64 -1, i64 -1>
  %317 = and <2 x i64> %316, %3
  %318 = or <2 x i64> %317, %315
  %319 = xor <2 x i64> %312, <i64 -1, i64 -1>
  %320 = and <2 x i64> %318, %319
  %321 = or <2 x i64> %320, %313
  %322 = bitcast i8* %274 to <2 x i64>*
  store <2 x i64> %321, <2 x i64>* %322, align 1
  %323 = getelementptr inbounds i8, i8* %274, i64 %1
  %324 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %325 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %326 = zext <8 x i8> %325 to <8 x i16>
  %327 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %328 = bitcast <16 x i8> %327 to <2 x i64>
  %329 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %330 = zext <8 x i8> %329 to <8 x i16>
  %331 = add <8 x i16> %28, %330
  %332 = sub <8 x i16> zeroinitializer, %331
  %333 = icmp slt <8 x i16> %331, zeroinitializer
  %334 = select <8 x i1> %333, <8 x i16> %332, <8 x i16> %331
  %335 = add <8 x i16> %29, %330
  %336 = sub <8 x i16> zeroinitializer, %335
  %337 = icmp slt <8 x i16> %335, zeroinitializer
  %338 = select <8 x i1> %337, <8 x i16> %336, <8 x i16> %335
  %339 = icmp slt <8 x i16> %334, %19
  %340 = sext <8 x i1> %339 to <8 x i16>
  %341 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %340, <8 x i16> undef) #11
  %342 = icmp slt <8 x i16> %338, %21
  %343 = sext <8 x i1> %342 to <8 x i16>
  %344 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %343, <8 x i16> undef) #11
  %345 = shufflevector <16 x i8> %341, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %346 = shufflevector <16 x i8> %345, <16 x i8> %344, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %347 = bitcast <16 x i8> %346 to <2 x i64>
  %348 = icmp slt <8 x i16> %334, %326
  %349 = sext <8 x i1> %348 to <8 x i16>
  %350 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %349, <8 x i16> undef) #11
  %351 = icmp slt <8 x i16> %338, %326
  %352 = sext <8 x i1> %351 to <8 x i16>
  %353 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %352, <8 x i16> undef) #11
  %354 = shufflevector <16 x i8> %350, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %355 = shufflevector <16 x i8> %354, <16 x i8> %353, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %356 = bitcast <16 x i8> %355 to <2 x i64>
  %357 = icmp ule <16 x i8> %17, %324
  %358 = sext <16 x i1> %357 to <16 x i8>
  %359 = bitcast <16 x i8> %358 to <2 x i64>
  %360 = xor <2 x i64> %347, <i64 -1, i64 -1>
  %361 = and <2 x i64> %360, %359
  %362 = and <2 x i64> %361, %328
  %363 = and <16 x i8> %355, %14
  %364 = bitcast <16 x i8> %363 to <2 x i64>
  %365 = xor <2 x i64> %356, <i64 -1, i64 -1>
  %366 = and <2 x i64> %365, %3
  %367 = or <2 x i64> %366, %364
  %368 = xor <2 x i64> %361, <i64 -1, i64 -1>
  %369 = and <2 x i64> %367, %368
  %370 = or <2 x i64> %369, %362
  %371 = bitcast i8* %323 to <2 x i64>*
  store <2 x i64> %370, <2 x i64>* %371, align 1
  %372 = getelementptr inbounds i8, i8* %323, i64 %1
  %373 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %374 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %375 = zext <8 x i8> %374 to <8 x i16>
  %376 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %377 = bitcast <16 x i8> %376 to <2 x i64>
  %378 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %379 = zext <8 x i8> %378 to <8 x i16>
  %380 = add <8 x i16> %28, %379
  %381 = sub <8 x i16> zeroinitializer, %380
  %382 = icmp slt <8 x i16> %380, zeroinitializer
  %383 = select <8 x i1> %382, <8 x i16> %381, <8 x i16> %380
  %384 = add <8 x i16> %29, %379
  %385 = sub <8 x i16> zeroinitializer, %384
  %386 = icmp slt <8 x i16> %384, zeroinitializer
  %387 = select <8 x i1> %386, <8 x i16> %385, <8 x i16> %384
  %388 = icmp slt <8 x i16> %383, %19
  %389 = sext <8 x i1> %388 to <8 x i16>
  %390 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %389, <8 x i16> undef) #11
  %391 = icmp slt <8 x i16> %387, %21
  %392 = sext <8 x i1> %391 to <8 x i16>
  %393 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %392, <8 x i16> undef) #11
  %394 = shufflevector <16 x i8> %390, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %395 = shufflevector <16 x i8> %394, <16 x i8> %393, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %396 = bitcast <16 x i8> %395 to <2 x i64>
  %397 = icmp slt <8 x i16> %383, %375
  %398 = sext <8 x i1> %397 to <8 x i16>
  %399 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %398, <8 x i16> undef) #11
  %400 = icmp slt <8 x i16> %387, %375
  %401 = sext <8 x i1> %400 to <8 x i16>
  %402 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %401, <8 x i16> undef) #11
  %403 = shufflevector <16 x i8> %399, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %404 = shufflevector <16 x i8> %403, <16 x i8> %402, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %405 = bitcast <16 x i8> %404 to <2 x i64>
  %406 = icmp ule <16 x i8> %17, %373
  %407 = sext <16 x i1> %406 to <16 x i8>
  %408 = bitcast <16 x i8> %407 to <2 x i64>
  %409 = xor <2 x i64> %396, <i64 -1, i64 -1>
  %410 = and <2 x i64> %409, %408
  %411 = and <2 x i64> %410, %377
  %412 = and <16 x i8> %404, %14
  %413 = bitcast <16 x i8> %412 to <2 x i64>
  %414 = xor <2 x i64> %405, <i64 -1, i64 -1>
  %415 = and <2 x i64> %414, %3
  %416 = or <2 x i64> %415, %413
  %417 = xor <2 x i64> %410, <i64 -1, i64 -1>
  %418 = and <2 x i64> %416, %417
  %419 = or <2 x i64> %418, %411
  %420 = bitcast i8* %372 to <2 x i64>*
  store <2 x i64> %419, <2 x i64>* %420, align 1
  %421 = getelementptr inbounds i8, i8* %372, i64 %1
  %422 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8>
  %423 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8>
  %424 = zext <8 x i8> %423 to <8 x i16>
  %425 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8>
  %426 = bitcast <16 x i8> %425 to <2 x i64>
  %427 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8>
  %428 = zext <8 x i8> %427 to <8 x i16>
  %429 = add <8 x i16> %28, %428
  %430 = sub <8 x i16> zeroinitializer, %429
  %431 = icmp slt <8 x i16> %429, zeroinitializer
  %432 = select <8 x i1> %431, <8 x i16> %430, <8 x i16> %429
  %433 = add <8 x i16> %29, %428
  %434 = sub <8 x i16> zeroinitializer, %433
  %435 = icmp slt <8 x i16> %433, zeroinitializer
  %436 = select <8 x i1> %435, <8 x i16> %434, <8 x i16> %433
  %437 = icmp slt <8 x i16> %432, %19
  %438 = sext <8 x i1> %437 to <8 x i16>
  %439 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %438, <8 x i16> undef) #11
  %440 = icmp slt <8 x i16> %436, %21
  %441 = sext <8 x i1> %440 to <8 x i16>
  %442 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %441, <8 x i16> undef) #11
  %443 = shufflevector <16 x i8> %439, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %444 = shufflevector <16 x i8> %443, <16 x i8> %442, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %445 = bitcast <16 x i8> %444 to <2 x i64>
  %446 = icmp slt <8 x i16> %432, %424
  %447 = sext <8 x i1> %446 to <8 x i16>
  %448 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %447, <8 x i16> undef) #11
  %449 = icmp slt <8 x i16> %436, %424
  %450 = sext <8 x i1> %449 to <8 x i16>
  %451 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %450, <8 x i16> undef) #11
  %452 = shufflevector <16 x i8> %448, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %453 = shufflevector <16 x i8> %452, <16 x i8> %451, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %454 = bitcast <16 x i8> %453 to <2 x i64>
  %455 = icmp ule <16 x i8> %17, %422
  %456 = sext <16 x i1> %455 to <16 x i8>
  %457 = bitcast <16 x i8> %456 to <2 x i64>
  %458 = xor <2 x i64> %445, <i64 -1, i64 -1>
  %459 = and <2 x i64> %458, %457
  %460 = and <2 x i64> %459, %426
  %461 = and <16 x i8> %453, %14
  %462 = bitcast <16 x i8> %461 to <2 x i64>
  %463 = xor <2 x i64> %454, <i64 -1, i64 -1>
  %464 = and <2 x i64> %463, %3
  %465 = or <2 x i64> %464, %462
  %466 = xor <2 x i64> %459, <i64 -1, i64 -1>
  %467 = and <2 x i64> %465, %466
  %468 = or <2 x i64> %467, %460
  %469 = bitcast i8* %421 to <2 x i64>*
  store <2 x i64> %468, <2 x i64>* %469, align 1
  %470 = getelementptr inbounds i8, i8* %421, i64 %1
  %471 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9>
  %472 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9>
  %473 = zext <8 x i8> %472 to <8 x i16>
  %474 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9>
  %475 = bitcast <16 x i8> %474 to <2 x i64>
  %476 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9>
  %477 = zext <8 x i8> %476 to <8 x i16>
  %478 = add <8 x i16> %28, %477
  %479 = sub <8 x i16> zeroinitializer, %478
  %480 = icmp slt <8 x i16> %478, zeroinitializer
  %481 = select <8 x i1> %480, <8 x i16> %479, <8 x i16> %478
  %482 = add <8 x i16> %29, %477
  %483 = sub <8 x i16> zeroinitializer, %482
  %484 = icmp slt <8 x i16> %482, zeroinitializer
  %485 = select <8 x i1> %484, <8 x i16> %483, <8 x i16> %482
  %486 = icmp slt <8 x i16> %481, %19
  %487 = sext <8 x i1> %486 to <8 x i16>
  %488 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %487, <8 x i16> undef) #11
  %489 = icmp slt <8 x i16> %485, %21
  %490 = sext <8 x i1> %489 to <8 x i16>
  %491 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %490, <8 x i16> undef) #11
  %492 = shufflevector <16 x i8> %488, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %493 = shufflevector <16 x i8> %492, <16 x i8> %491, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %494 = bitcast <16 x i8> %493 to <2 x i64>
  %495 = icmp slt <8 x i16> %481, %473
  %496 = sext <8 x i1> %495 to <8 x i16>
  %497 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %496, <8 x i16> undef) #11
  %498 = icmp slt <8 x i16> %485, %473
  %499 = sext <8 x i1> %498 to <8 x i16>
  %500 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %499, <8 x i16> undef) #11
  %501 = shufflevector <16 x i8> %497, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %502 = shufflevector <16 x i8> %501, <16 x i8> %500, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %503 = bitcast <16 x i8> %502 to <2 x i64>
  %504 = icmp ule <16 x i8> %17, %471
  %505 = sext <16 x i1> %504 to <16 x i8>
  %506 = bitcast <16 x i8> %505 to <2 x i64>
  %507 = xor <2 x i64> %494, <i64 -1, i64 -1>
  %508 = and <2 x i64> %507, %506
  %509 = and <2 x i64> %508, %475
  %510 = and <16 x i8> %502, %14
  %511 = bitcast <16 x i8> %510 to <2 x i64>
  %512 = xor <2 x i64> %503, <i64 -1, i64 -1>
  %513 = and <2 x i64> %512, %3
  %514 = or <2 x i64> %513, %511
  %515 = xor <2 x i64> %508, <i64 -1, i64 -1>
  %516 = and <2 x i64> %514, %515
  %517 = or <2 x i64> %516, %509
  %518 = bitcast i8* %470 to <2 x i64>*
  store <2 x i64> %517, <2 x i64>* %518, align 1
  %519 = getelementptr inbounds i8, i8* %470, i64 %1
  %520 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10>
  %521 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10>
  %522 = zext <8 x i8> %521 to <8 x i16>
  %523 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10>
  %524 = bitcast <16 x i8> %523 to <2 x i64>
  %525 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10, i32 10>
  %526 = zext <8 x i8> %525 to <8 x i16>
  %527 = add <8 x i16> %28, %526
  %528 = sub <8 x i16> zeroinitializer, %527
  %529 = icmp slt <8 x i16> %527, zeroinitializer
  %530 = select <8 x i1> %529, <8 x i16> %528, <8 x i16> %527
  %531 = add <8 x i16> %29, %526
  %532 = sub <8 x i16> zeroinitializer, %531
  %533 = icmp slt <8 x i16> %531, zeroinitializer
  %534 = select <8 x i1> %533, <8 x i16> %532, <8 x i16> %531
  %535 = icmp slt <8 x i16> %530, %19
  %536 = sext <8 x i1> %535 to <8 x i16>
  %537 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %536, <8 x i16> undef) #11
  %538 = icmp slt <8 x i16> %534, %21
  %539 = sext <8 x i1> %538 to <8 x i16>
  %540 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %539, <8 x i16> undef) #11
  %541 = shufflevector <16 x i8> %537, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %542 = shufflevector <16 x i8> %541, <16 x i8> %540, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %543 = bitcast <16 x i8> %542 to <2 x i64>
  %544 = icmp slt <8 x i16> %530, %522
  %545 = sext <8 x i1> %544 to <8 x i16>
  %546 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %545, <8 x i16> undef) #11
  %547 = icmp slt <8 x i16> %534, %522
  %548 = sext <8 x i1> %547 to <8 x i16>
  %549 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %548, <8 x i16> undef) #11
  %550 = shufflevector <16 x i8> %546, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %551 = shufflevector <16 x i8> %550, <16 x i8> %549, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %552 = bitcast <16 x i8> %551 to <2 x i64>
  %553 = icmp ule <16 x i8> %17, %520
  %554 = sext <16 x i1> %553 to <16 x i8>
  %555 = bitcast <16 x i8> %554 to <2 x i64>
  %556 = xor <2 x i64> %543, <i64 -1, i64 -1>
  %557 = and <2 x i64> %556, %555
  %558 = and <2 x i64> %557, %524
  %559 = and <16 x i8> %551, %14
  %560 = bitcast <16 x i8> %559 to <2 x i64>
  %561 = xor <2 x i64> %552, <i64 -1, i64 -1>
  %562 = and <2 x i64> %561, %3
  %563 = or <2 x i64> %562, %560
  %564 = xor <2 x i64> %557, <i64 -1, i64 -1>
  %565 = and <2 x i64> %563, %564
  %566 = or <2 x i64> %565, %558
  %567 = bitcast i8* %519 to <2 x i64>*
  store <2 x i64> %566, <2 x i64>* %567, align 1
  %568 = getelementptr inbounds i8, i8* %519, i64 %1
  %569 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11>
  %570 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11>
  %571 = zext <8 x i8> %570 to <8 x i16>
  %572 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11>
  %573 = bitcast <16 x i8> %572 to <2 x i64>
  %574 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11, i32 11>
  %575 = zext <8 x i8> %574 to <8 x i16>
  %576 = add <8 x i16> %28, %575
  %577 = sub <8 x i16> zeroinitializer, %576
  %578 = icmp slt <8 x i16> %576, zeroinitializer
  %579 = select <8 x i1> %578, <8 x i16> %577, <8 x i16> %576
  %580 = add <8 x i16> %29, %575
  %581 = sub <8 x i16> zeroinitializer, %580
  %582 = icmp slt <8 x i16> %580, zeroinitializer
  %583 = select <8 x i1> %582, <8 x i16> %581, <8 x i16> %580
  %584 = icmp slt <8 x i16> %579, %19
  %585 = sext <8 x i1> %584 to <8 x i16>
  %586 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %585, <8 x i16> undef) #11
  %587 = icmp slt <8 x i16> %583, %21
  %588 = sext <8 x i1> %587 to <8 x i16>
  %589 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %588, <8 x i16> undef) #11
  %590 = shufflevector <16 x i8> %586, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %591 = shufflevector <16 x i8> %590, <16 x i8> %589, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %592 = bitcast <16 x i8> %591 to <2 x i64>
  %593 = icmp slt <8 x i16> %579, %571
  %594 = sext <8 x i1> %593 to <8 x i16>
  %595 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %594, <8 x i16> undef) #11
  %596 = icmp slt <8 x i16> %583, %571
  %597 = sext <8 x i1> %596 to <8 x i16>
  %598 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %597, <8 x i16> undef) #11
  %599 = shufflevector <16 x i8> %595, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %600 = shufflevector <16 x i8> %599, <16 x i8> %598, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %601 = bitcast <16 x i8> %600 to <2 x i64>
  %602 = icmp ule <16 x i8> %17, %569
  %603 = sext <16 x i1> %602 to <16 x i8>
  %604 = bitcast <16 x i8> %603 to <2 x i64>
  %605 = xor <2 x i64> %592, <i64 -1, i64 -1>
  %606 = and <2 x i64> %605, %604
  %607 = and <2 x i64> %606, %573
  %608 = and <16 x i8> %600, %14
  %609 = bitcast <16 x i8> %608 to <2 x i64>
  %610 = xor <2 x i64> %601, <i64 -1, i64 -1>
  %611 = and <2 x i64> %610, %3
  %612 = or <2 x i64> %611, %609
  %613 = xor <2 x i64> %606, <i64 -1, i64 -1>
  %614 = and <2 x i64> %612, %613
  %615 = or <2 x i64> %614, %607
  %616 = bitcast i8* %568 to <2 x i64>*
  store <2 x i64> %615, <2 x i64>* %616, align 1
  %617 = getelementptr inbounds i8, i8* %568, i64 %1
  %618 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12>
  %619 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12>
  %620 = zext <8 x i8> %619 to <8 x i16>
  %621 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12>
  %622 = bitcast <16 x i8> %621 to <2 x i64>
  %623 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12, i32 12>
  %624 = zext <8 x i8> %623 to <8 x i16>
  %625 = add <8 x i16> %28, %624
  %626 = sub <8 x i16> zeroinitializer, %625
  %627 = icmp slt <8 x i16> %625, zeroinitializer
  %628 = select <8 x i1> %627, <8 x i16> %626, <8 x i16> %625
  %629 = add <8 x i16> %29, %624
  %630 = sub <8 x i16> zeroinitializer, %629
  %631 = icmp slt <8 x i16> %629, zeroinitializer
  %632 = select <8 x i1> %631, <8 x i16> %630, <8 x i16> %629
  %633 = icmp slt <8 x i16> %628, %19
  %634 = sext <8 x i1> %633 to <8 x i16>
  %635 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %634, <8 x i16> undef) #11
  %636 = icmp slt <8 x i16> %632, %21
  %637 = sext <8 x i1> %636 to <8 x i16>
  %638 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %637, <8 x i16> undef) #11
  %639 = shufflevector <16 x i8> %635, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %640 = shufflevector <16 x i8> %639, <16 x i8> %638, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %641 = bitcast <16 x i8> %640 to <2 x i64>
  %642 = icmp slt <8 x i16> %628, %620
  %643 = sext <8 x i1> %642 to <8 x i16>
  %644 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %643, <8 x i16> undef) #11
  %645 = icmp slt <8 x i16> %632, %620
  %646 = sext <8 x i1> %645 to <8 x i16>
  %647 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %646, <8 x i16> undef) #11
  %648 = shufflevector <16 x i8> %644, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %649 = shufflevector <16 x i8> %648, <16 x i8> %647, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %650 = bitcast <16 x i8> %649 to <2 x i64>
  %651 = icmp ule <16 x i8> %17, %618
  %652 = sext <16 x i1> %651 to <16 x i8>
  %653 = bitcast <16 x i8> %652 to <2 x i64>
  %654 = xor <2 x i64> %641, <i64 -1, i64 -1>
  %655 = and <2 x i64> %654, %653
  %656 = and <2 x i64> %655, %622
  %657 = and <16 x i8> %649, %14
  %658 = bitcast <16 x i8> %657 to <2 x i64>
  %659 = xor <2 x i64> %650, <i64 -1, i64 -1>
  %660 = and <2 x i64> %659, %3
  %661 = or <2 x i64> %660, %658
  %662 = xor <2 x i64> %655, <i64 -1, i64 -1>
  %663 = and <2 x i64> %661, %662
  %664 = or <2 x i64> %663, %656
  %665 = bitcast i8* %617 to <2 x i64>*
  store <2 x i64> %664, <2 x i64>* %665, align 1
  %666 = getelementptr inbounds i8, i8* %617, i64 %1
  %667 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13>
  %668 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13>
  %669 = zext <8 x i8> %668 to <8 x i16>
  %670 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13>
  %671 = bitcast <16 x i8> %670 to <2 x i64>
  %672 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13, i32 13>
  %673 = zext <8 x i8> %672 to <8 x i16>
  %674 = add <8 x i16> %28, %673
  %675 = sub <8 x i16> zeroinitializer, %674
  %676 = icmp slt <8 x i16> %674, zeroinitializer
  %677 = select <8 x i1> %676, <8 x i16> %675, <8 x i16> %674
  %678 = add <8 x i16> %29, %673
  %679 = sub <8 x i16> zeroinitializer, %678
  %680 = icmp slt <8 x i16> %678, zeroinitializer
  %681 = select <8 x i1> %680, <8 x i16> %679, <8 x i16> %678
  %682 = icmp slt <8 x i16> %677, %19
  %683 = sext <8 x i1> %682 to <8 x i16>
  %684 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %683, <8 x i16> undef) #11
  %685 = icmp slt <8 x i16> %681, %21
  %686 = sext <8 x i1> %685 to <8 x i16>
  %687 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %686, <8 x i16> undef) #11
  %688 = shufflevector <16 x i8> %684, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %689 = shufflevector <16 x i8> %688, <16 x i8> %687, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %690 = bitcast <16 x i8> %689 to <2 x i64>
  %691 = icmp slt <8 x i16> %677, %669
  %692 = sext <8 x i1> %691 to <8 x i16>
  %693 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %692, <8 x i16> undef) #11
  %694 = icmp slt <8 x i16> %681, %669
  %695 = sext <8 x i1> %694 to <8 x i16>
  %696 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %695, <8 x i16> undef) #11
  %697 = shufflevector <16 x i8> %693, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %698 = shufflevector <16 x i8> %697, <16 x i8> %696, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %699 = bitcast <16 x i8> %698 to <2 x i64>
  %700 = icmp ule <16 x i8> %17, %667
  %701 = sext <16 x i1> %700 to <16 x i8>
  %702 = bitcast <16 x i8> %701 to <2 x i64>
  %703 = xor <2 x i64> %690, <i64 -1, i64 -1>
  %704 = and <2 x i64> %703, %702
  %705 = and <2 x i64> %704, %671
  %706 = and <16 x i8> %698, %14
  %707 = bitcast <16 x i8> %706 to <2 x i64>
  %708 = xor <2 x i64> %699, <i64 -1, i64 -1>
  %709 = and <2 x i64> %708, %3
  %710 = or <2 x i64> %709, %707
  %711 = xor <2 x i64> %704, <i64 -1, i64 -1>
  %712 = and <2 x i64> %710, %711
  %713 = or <2 x i64> %712, %705
  %714 = bitcast i8* %666 to <2 x i64>*
  store <2 x i64> %713, <2 x i64>* %714, align 1
  %715 = getelementptr inbounds i8, i8* %666, i64 %1
  %716 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14>
  %717 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14>
  %718 = zext <8 x i8> %717 to <8 x i16>
  %719 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14>
  %720 = bitcast <16 x i8> %719 to <2 x i64>
  %721 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14, i32 14>
  %722 = zext <8 x i8> %721 to <8 x i16>
  %723 = add <8 x i16> %28, %722
  %724 = sub <8 x i16> zeroinitializer, %723
  %725 = icmp slt <8 x i16> %723, zeroinitializer
  %726 = select <8 x i1> %725, <8 x i16> %724, <8 x i16> %723
  %727 = add <8 x i16> %29, %722
  %728 = sub <8 x i16> zeroinitializer, %727
  %729 = icmp slt <8 x i16> %727, zeroinitializer
  %730 = select <8 x i1> %729, <8 x i16> %728, <8 x i16> %727
  %731 = icmp slt <8 x i16> %726, %19
  %732 = sext <8 x i1> %731 to <8 x i16>
  %733 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %732, <8 x i16> undef) #11
  %734 = icmp slt <8 x i16> %730, %21
  %735 = sext <8 x i1> %734 to <8 x i16>
  %736 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %735, <8 x i16> undef) #11
  %737 = shufflevector <16 x i8> %733, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %738 = shufflevector <16 x i8> %737, <16 x i8> %736, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %739 = bitcast <16 x i8> %738 to <2 x i64>
  %740 = icmp slt <8 x i16> %726, %718
  %741 = sext <8 x i1> %740 to <8 x i16>
  %742 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %741, <8 x i16> undef) #11
  %743 = icmp slt <8 x i16> %730, %718
  %744 = sext <8 x i1> %743 to <8 x i16>
  %745 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %744, <8 x i16> undef) #11
  %746 = shufflevector <16 x i8> %742, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %747 = shufflevector <16 x i8> %746, <16 x i8> %745, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %748 = bitcast <16 x i8> %747 to <2 x i64>
  %749 = icmp ule <16 x i8> %17, %716
  %750 = sext <16 x i1> %749 to <16 x i8>
  %751 = bitcast <16 x i8> %750 to <2 x i64>
  %752 = xor <2 x i64> %739, <i64 -1, i64 -1>
  %753 = and <2 x i64> %752, %751
  %754 = and <2 x i64> %753, %720
  %755 = and <16 x i8> %747, %14
  %756 = bitcast <16 x i8> %755 to <2 x i64>
  %757 = xor <2 x i64> %748, <i64 -1, i64 -1>
  %758 = and <2 x i64> %757, %3
  %759 = or <2 x i64> %758, %756
  %760 = xor <2 x i64> %753, <i64 -1, i64 -1>
  %761 = and <2 x i64> %759, %760
  %762 = or <2 x i64> %761, %754
  %763 = bitcast i8* %715 to <2 x i64>*
  store <2 x i64> %762, <2 x i64>* %763, align 1
  %764 = getelementptr inbounds i8, i8* %715, i64 %1
  %765 = shufflevector <16 x i8> %25, <16 x i8> undef, <16 x i32> <i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15>
  %766 = shufflevector <16 x i8> %25, <16 x i8> undef, <8 x i32> <i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15>
  %767 = zext <8 x i8> %766 to <8 x i16>
  %768 = shufflevector <16 x i8> %22, <16 x i8> undef, <16 x i32> <i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15>
  %769 = bitcast <16 x i8> %768 to <2 x i64>
  %770 = shufflevector <16 x i8> %22, <16 x i8> undef, <8 x i32> <i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15>
  %771 = zext <8 x i8> %770 to <8 x i16>
  %772 = add <8 x i16> %28, %771
  %773 = sub <8 x i16> zeroinitializer, %772
  %774 = icmp slt <8 x i16> %772, zeroinitializer
  %775 = select <8 x i1> %774, <8 x i16> %773, <8 x i16> %772
  %776 = add <8 x i16> %29, %771
  %777 = sub <8 x i16> zeroinitializer, %776
  %778 = icmp slt <8 x i16> %776, zeroinitializer
  %779 = select <8 x i1> %778, <8 x i16> %777, <8 x i16> %776
  %780 = icmp slt <8 x i16> %775, %19
  %781 = sext <8 x i1> %780 to <8 x i16>
  %782 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %781, <8 x i16> undef) #11
  %783 = icmp slt <8 x i16> %779, %21
  %784 = sext <8 x i1> %783 to <8 x i16>
  %785 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %784, <8 x i16> undef) #11
  %786 = shufflevector <16 x i8> %782, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %787 = shufflevector <16 x i8> %786, <16 x i8> %785, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %788 = bitcast <16 x i8> %787 to <2 x i64>
  %789 = icmp slt <8 x i16> %775, %767
  %790 = sext <8 x i1> %789 to <8 x i16>
  %791 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %790, <8 x i16> undef) #11
  %792 = icmp slt <8 x i16> %779, %767
  %793 = sext <8 x i1> %792 to <8 x i16>
  %794 = tail call <16 x i8> @llvm.x86.sse2.packsswb.128(<8 x i16> %793, <8 x i16> undef) #11
  %795 = shufflevector <16 x i8> %791, <16 x i8> undef, <16 x i32> <i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %796 = shufflevector <16 x i8> %795, <16 x i8> %794, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %797 = bitcast <16 x i8> %796 to <2 x i64>
  %798 = icmp ule <16 x i8> %17, %765
  %799 = sext <16 x i1> %798 to <16 x i8>
  %800 = bitcast <16 x i8> %799 to <2 x i64>
  %801 = xor <2 x i64> %788, <i64 -1, i64 -1>
  %802 = and <2 x i64> %801, %800
  %803 = and <2 x i64> %802, %769
  %804 = and <16 x i8> %796, %14
  %805 = bitcast <16 x i8> %804 to <2 x i64>
  %806 = xor <2 x i64> %797, <i64 -1, i64 -1>
  %807 = and <2 x i64> %806, %3
  %808 = or <2 x i64> %807, %805
  %809 = xor <2 x i64> %802, <i64 -1, i64 -1>
  %810 = and <2 x i64> %808, %809
  %811 = or <2 x i64> %810, %803
  %812 = bitcast i8* %764 to <2 x i64>*
  store <2 x i64> %811, <2 x i64>* %812, align 1
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_137DirectionalIntraPredictorZone1_SSE4_1EPvlPKviiib(i8* nocapture, i64, i8* nocapture readonly, i32, i32, i32, i1 zeroext) #10 {
  %8 = bitcast i8* %2 to i16*
  %9 = bitcast i8* %0 to i16*
  %10 = lshr i64 %1, 1
  %11 = zext i1 %6 to i32
  %12 = icmp eq i32 %5, 64
  br i1 %12, label %13, label %70

13:                                               ; preds = %7
  %14 = icmp eq i32 %4, 4
  br i1 %14, label %18, label %15

15:                                               ; preds = %13
  %16 = sext i32 %3 to i64
  %17 = shl nsw i64 %16, 1
  br label %31

18:                                               ; preds = %13
  %19 = getelementptr inbounds i8, i8* %2, i64 2
  %20 = sext i32 %3 to i64
  %21 = shl nsw i64 %20, 1
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %0, i8* align 2 %19, i64 %21, i1 false) #11
  %22 = getelementptr inbounds i16, i16* %9, i64 %10
  %23 = bitcast i16* %22 to i8*
  %24 = getelementptr inbounds i8, i8* %2, i64 4
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %23, i8* align 2 %24, i64 %21, i1 false) #11
  %25 = getelementptr inbounds i16, i16* %22, i64 %10
  %26 = bitcast i16* %25 to i8*
  %27 = getelementptr inbounds i8, i8* %2, i64 6
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %26, i8* align 2 %27, i64 %21, i1 false) #11
  %28 = getelementptr inbounds i16, i16* %25, i64 %10
  %29 = bitcast i16* %28 to i8*
  %30 = getelementptr inbounds i8, i8* %2, i64 8
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %29, i8* align 2 %30, i64 %21, i1 false) #11
  br label %745

31:                                               ; preds = %31, %15
  %32 = phi i16* [ %66, %31 ], [ %9, %15 ]
  %33 = phi i64 [ %67, %31 ], [ 1, %15 ]
  %34 = phi i32 [ %68, %31 ], [ %4, %15 ]
  %35 = bitcast i16* %32 to i8*
  %36 = getelementptr inbounds i16, i16* %8, i64 %33
  %37 = bitcast i16* %36 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %35, i8* align 2 %37, i64 %17, i1 false) #11
  %38 = getelementptr inbounds i16, i16* %32, i64 %10
  %39 = bitcast i16* %38 to i8*
  %40 = getelementptr inbounds i16, i16* %36, i64 1
  %41 = bitcast i16* %40 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %39, i8* align 2 %41, i64 %17, i1 false) #11
  %42 = getelementptr inbounds i16, i16* %38, i64 %10
  %43 = bitcast i16* %42 to i8*
  %44 = getelementptr inbounds i16, i16* %36, i64 2
  %45 = bitcast i16* %44 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %43, i8* align 2 %45, i64 %17, i1 false) #11
  %46 = getelementptr inbounds i16, i16* %42, i64 %10
  %47 = bitcast i16* %46 to i8*
  %48 = getelementptr inbounds i16, i16* %36, i64 3
  %49 = bitcast i16* %48 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %47, i8* align 2 %49, i64 %17, i1 false) #11
  %50 = getelementptr inbounds i16, i16* %46, i64 %10
  %51 = bitcast i16* %50 to i8*
  %52 = getelementptr inbounds i16, i16* %36, i64 4
  %53 = bitcast i16* %52 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %51, i8* align 2 %53, i64 %17, i1 false) #11
  %54 = getelementptr inbounds i16, i16* %50, i64 %10
  %55 = bitcast i16* %54 to i8*
  %56 = getelementptr inbounds i16, i16* %36, i64 5
  %57 = bitcast i16* %56 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %55, i8* align 2 %57, i64 %17, i1 false) #11
  %58 = getelementptr inbounds i16, i16* %54, i64 %10
  %59 = bitcast i16* %58 to i8*
  %60 = getelementptr inbounds i16, i16* %36, i64 6
  %61 = bitcast i16* %60 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %59, i8* align 2 %61, i64 %17, i1 false) #11
  %62 = getelementptr inbounds i16, i16* %58, i64 %10
  %63 = bitcast i16* %62 to i8*
  %64 = getelementptr inbounds i16, i16* %36, i64 7
  %65 = bitcast i16* %64 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %63, i8* align 2 %65, i64 %17, i1 false) #11
  %66 = getelementptr inbounds i16, i16* %62, i64 %10
  %67 = add nuw nsw i64 %33, 8
  %68 = add nsw i32 %34, -8
  %69 = icmp eq i32 %68, 0
  br i1 %69, label %745, label %31

70:                                               ; preds = %7
  %71 = select i1 %6, <2 x i64> <i64 506097522914230528, i64 1084818905618843912>, <2 x i64> <i64 361417177271763200, i64 650777868624069892>
  %72 = icmp eq i32 %3, 4
  br i1 %72, label %73, label %181

73:                                               ; preds = %70
  %74 = select i1 %6, i32 5, i32 6
  %75 = add nsw i32 %4, 3
  %76 = shl i32 %75, %11
  %77 = trunc i32 %76 to i16
  %78 = insertelement <8 x i16> undef, i16 %77, i32 0
  %79 = shufflevector <8 x i16> %78, <8 x i16> undef, <8 x i32> zeroinitializer
  %80 = sext i32 %76 to i64
  %81 = getelementptr inbounds i16, i16* %8, i64 %80
  %82 = load i16, i16* %81, align 2
  %83 = insertelement <8 x i16> undef, i16 %82, i32 0
  %84 = shufflevector <8 x i16> %83, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %85 = ashr i32 %5, %74
  %86 = icmp sgt i32 %85, 1
  %87 = select i1 %86, i32 %85, i32 1
  %88 = sdiv i32 %76, %87
  %89 = icmp sgt i32 %88, %4
  %90 = select i1 %89, i32 %4, i32 %88
  %91 = icmp sgt i32 %90, 0
  br i1 %91, label %92, label %94

92:                                               ; preds = %73
  %93 = bitcast <2 x i64> %71 to <16 x i8>
  br label %120

94:                                               ; preds = %120, %73
  %95 = phi i32 [ 0, %73 ], [ %90, %120 ]
  %96 = phi i16* [ %9, %73 ], [ %153, %120 ]
  %97 = icmp slt i32 %95, %4
  br i1 %97, label %98, label %745

98:                                               ; preds = %94
  %99 = sub i32 %4, %95
  %100 = xor i32 %95, -1
  %101 = add i32 %100, %4
  %102 = and i32 %99, 3
  %103 = icmp eq i32 %102, 0
  br i1 %103, label %116, label %104

104:                                              ; preds = %98, %104
  %105 = phi i16* [ %112, %104 ], [ %96, %98 ]
  %106 = phi i32 [ %113, %104 ], [ %95, %98 ]
  %107 = phi i32 [ %114, %104 ], [ %102, %98 ]
  %108 = load i16, i16* %81, align 2
  store i16 %108, i16* %105, align 2
  %109 = getelementptr inbounds i16, i16* %105, i64 1
  store i16 %108, i16* %109, align 2
  %110 = getelementptr inbounds i16, i16* %105, i64 2
  store i16 %108, i16* %110, align 2
  %111 = getelementptr inbounds i16, i16* %105, i64 3
  store i16 %108, i16* %111, align 2
  %112 = getelementptr inbounds i16, i16* %105, i64 %10
  %113 = add nuw nsw i32 %106, 1
  %114 = add i32 %107, -1
  %115 = icmp eq i32 %114, 0
  br i1 %115, label %116, label %104, !llvm.loop !26

116:                                              ; preds = %104, %98
  %117 = phi i16* [ %96, %98 ], [ %112, %104 ]
  %118 = phi i32 [ %95, %98 ], [ %113, %104 ]
  %119 = icmp ult i32 %101, 3
  br i1 %119, label %745, label %156

120:                                              ; preds = %92, %120
  %121 = phi i16* [ %153, %120 ], [ %9, %92 ]
  %122 = phi i32 [ %154, %120 ], [ %5, %92 ]
  %123 = phi i32 [ %152, %120 ], [ 0, %92 ]
  %124 = ashr i32 %122, %74
  %125 = shl i32 %122, %11
  %126 = lshr i32 %125, 1
  %127 = trunc i32 %126 to i16
  %128 = and i16 %127, 31
  %129 = insertelement <8 x i16> undef, i16 %128, i32 0
  %130 = shufflevector <8 x i16> %129, <8 x i16> undef, <8 x i32> zeroinitializer
  %131 = sub <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 undef, i16 undef, i16 undef, i16 undef>, %130
  %132 = shufflevector <8 x i16> %131, <8 x i16> %130, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %133 = trunc i32 %124 to i16
  %134 = insertelement <8 x i16> undef, i16 %133, i32 0
  %135 = shufflevector <8 x i16> %134, <8 x i16> undef, <8 x i32> zeroinitializer
  %136 = add <8 x i16> %135, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %137 = sext i32 %124 to i64
  %138 = getelementptr inbounds i16, i16* %8, i64 %137
  %139 = bitcast i16* %138 to <16 x i8>*
  %140 = load <16 x i8>, <16 x i8>* %139, align 1
  %141 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %140, <16 x i8> %93) #11
  %142 = bitcast <16 x i8> %141 to <8 x i16>
  %143 = mul <8 x i16> %132, %142
  %144 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %143, <8 x i16> %143) #11
  %145 = lshr <8 x i16> %144, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %146 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %145, <8 x i16> zeroinitializer) #11
  %147 = icmp sgt <8 x i16> %136, %79
  %148 = select <8 x i1> %147, <8 x i16> %84, <8 x i16> %146
  %149 = bitcast <8 x i16> %148 to <2 x i64>
  %150 = extractelement <2 x i64> %149, i32 0
  %151 = bitcast i16* %121 to i64*
  store i64 %150, i64* %151, align 1
  %152 = add nuw nsw i32 %123, 1
  %153 = getelementptr inbounds i16, i16* %121, i64 %10
  %154 = add nsw i32 %122, %5
  %155 = icmp slt i32 %152, %90
  br i1 %155, label %120, label %94

156:                                              ; preds = %116, %156
  %157 = phi i16* [ %178, %156 ], [ %117, %116 ]
  %158 = phi i32 [ %179, %156 ], [ %118, %116 ]
  %159 = load i16, i16* %81, align 2
  store i16 %159, i16* %157, align 2
  %160 = getelementptr inbounds i16, i16* %157, i64 1
  store i16 %159, i16* %160, align 2
  %161 = getelementptr inbounds i16, i16* %157, i64 2
  store i16 %159, i16* %161, align 2
  %162 = getelementptr inbounds i16, i16* %157, i64 3
  store i16 %159, i16* %162, align 2
  %163 = getelementptr inbounds i16, i16* %157, i64 %10
  %164 = load i16, i16* %81, align 2
  store i16 %164, i16* %163, align 2
  %165 = getelementptr inbounds i16, i16* %163, i64 1
  store i16 %164, i16* %165, align 2
  %166 = getelementptr inbounds i16, i16* %163, i64 2
  store i16 %164, i16* %166, align 2
  %167 = getelementptr inbounds i16, i16* %163, i64 3
  store i16 %164, i16* %167, align 2
  %168 = getelementptr inbounds i16, i16* %163, i64 %10
  %169 = load i16, i16* %81, align 2
  store i16 %169, i16* %168, align 2
  %170 = getelementptr inbounds i16, i16* %168, i64 1
  store i16 %169, i16* %170, align 2
  %171 = getelementptr inbounds i16, i16* %168, i64 2
  store i16 %169, i16* %171, align 2
  %172 = getelementptr inbounds i16, i16* %168, i64 3
  store i16 %169, i16* %172, align 2
  %173 = getelementptr inbounds i16, i16* %168, i64 %10
  %174 = load i16, i16* %81, align 2
  store i16 %174, i16* %173, align 2
  %175 = getelementptr inbounds i16, i16* %173, i64 1
  store i16 %174, i16* %175, align 2
  %176 = getelementptr inbounds i16, i16* %173, i64 2
  store i16 %174, i16* %176, align 2
  %177 = getelementptr inbounds i16, i16* %173, i64 3
  store i16 %174, i16* %177, align 2
  %178 = getelementptr inbounds i16, i16* %173, i64 %10
  %179 = add nuw nsw i32 %158, 4
  %180 = icmp eq i32 %179, %4
  br i1 %180, label %745, label %156

181:                                              ; preds = %70
  %182 = icmp sgt i32 %3, 31
  %183 = select i1 %6, i32 5, i32 6
  %184 = add i32 %3, -1
  %185 = add i32 %184, %4
  %186 = shl i32 %185, %11
  %187 = shl i32 8, %11
  br i1 %182, label %188, label %518

188:                                              ; preds = %181
  %189 = ashr i32 %5, %183
  %190 = icmp sgt i32 %189, 1
  %191 = select i1 %190, i32 %189, i32 1
  %192 = sdiv i32 %186, %191
  %193 = icmp sgt i32 %192, %4
  %194 = select i1 %193, i32 %4, i32 %192
  %195 = shl i32 %3, %11
  %196 = sub nsw i32 %186, %195
  %197 = shl i32 %196, %183
  %198 = sdiv i32 %197, %5
  %199 = icmp sgt i32 %198, %4
  %200 = select i1 %199, i32 %4, i32 %198
  %201 = icmp sgt i32 %200, 0
  br i1 %201, label %202, label %250

202:                                              ; preds = %188
  %203 = shl i32 4, %11
  %204 = zext i32 %203 to i64
  %205 = zext i32 %187 to i64
  %206 = sext i32 %3 to i64
  %207 = bitcast <2 x i64> %71 to <16 x i8>
  br label %208

208:                                              ; preds = %245, %202
  %209 = phi i16* [ %9, %202 ], [ %247, %245 ]
  %210 = phi i32 [ %5, %202 ], [ %248, %245 ]
  %211 = phi i32 [ 0, %202 ], [ %246, %245 ]
  %212 = ashr i32 %210, %183
  %213 = shl i32 %210, %11
  %214 = lshr i32 %213, 1
  %215 = trunc i32 %214 to i16
  %216 = and i16 %215, 31
  %217 = insertelement <8 x i16> undef, i16 %216, i32 0
  %218 = shufflevector <8 x i16> %217, <8 x i16> undef, <8 x i32> zeroinitializer
  %219 = sub <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 undef, i16 undef, i16 undef, i16 undef>, %218
  %220 = shufflevector <8 x i16> %219, <8 x i16> %218, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %221 = sext i32 %212 to i64
  br label %222

222:                                              ; preds = %222, %208
  %223 = phi i64 [ %243, %222 ], [ 0, %208 ]
  %224 = phi i64 [ %242, %222 ], [ %221, %208 ]
  %225 = getelementptr inbounds i16, i16* %8, i64 %224
  %226 = bitcast i16* %225 to <16 x i8>*
  %227 = load <16 x i8>, <16 x i8>* %226, align 1
  %228 = getelementptr inbounds i16, i16* %225, i64 %204
  %229 = bitcast i16* %228 to <16 x i8>*
  %230 = load <16 x i8>, <16 x i8>* %229, align 1
  %231 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %227, <16 x i8> %207) #11
  %232 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %230, <16 x i8> %207) #11
  %233 = bitcast <16 x i8> %231 to <8 x i16>
  %234 = mul <8 x i16> %220, %233
  %235 = bitcast <16 x i8> %232 to <8 x i16>
  %236 = mul <8 x i16> %220, %235
  %237 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %234, <8 x i16> %236) #11
  %238 = lshr <8 x i16> %237, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %239 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %238, <8 x i16> zeroinitializer) #11
  %240 = getelementptr inbounds i16, i16* %209, i64 %223
  %241 = bitcast i16* %240 to <8 x i16>*
  store <8 x i16> %239, <8 x i16>* %241, align 1
  %242 = add i64 %224, %205
  %243 = add nuw nsw i64 %223, 8
  %244 = icmp slt i64 %243, %206
  br i1 %244, label %222, label %245

245:                                              ; preds = %222
  %246 = add nuw nsw i32 %211, 1
  %247 = getelementptr inbounds i16, i16* %209, i64 %10
  %248 = add nsw i32 %210, %5
  %249 = icmp slt i32 %246, %200
  br i1 %249, label %208, label %250

250:                                              ; preds = %245, %188
  %251 = phi i32 [ 0, %188 ], [ %200, %245 ]
  %252 = phi i32 [ %5, %188 ], [ %248, %245 ]
  %253 = phi i16* [ %9, %188 ], [ %247, %245 ]
  %254 = trunc i32 %186 to i16
  %255 = insertelement <8 x i16> undef, i16 %254, i32 0
  %256 = shufflevector <8 x i16> %255, <8 x i16> undef, <8 x i32> zeroinitializer
  %257 = sext i32 %186 to i64
  %258 = getelementptr inbounds i16, i16* %8, i64 %257
  %259 = load i16, i16* %258, align 2
  %260 = insertelement <8 x i16> undef, i16 %259, i32 0
  %261 = shufflevector <8 x i16> %260, <8 x i16> undef, <8 x i32> zeroinitializer
  %262 = trunc i32 %187 to i16
  %263 = insertelement <8 x i16> undef, i16 %262, i32 0
  %264 = shufflevector <8 x i16> %263, <8 x i16> undef, <8 x i32> zeroinitializer
  %265 = icmp slt i32 %251, %194
  br i1 %265, label %266, label %271

266:                                              ; preds = %250
  %267 = shl i32 4, %11
  %268 = zext i32 %267 to i64
  %269 = zext i32 %187 to i64
  %270 = bitcast <2 x i64> %71 to <16 x i8>
  br label %288

271:                                              ; preds = %434, %250
  %272 = phi i32 [ %251, %250 ], [ %194, %434 ]
  %273 = phi i16* [ %253, %250 ], [ %436, %434 ]
  %274 = icmp slt i32 %272, %4
  br i1 %274, label %275, label %745

275:                                              ; preds = %271
  %276 = sext i32 %3 to i64
  %277 = icmp eq i32 %3, 0
  %278 = add nsw i64 %276, -16
  %279 = lshr i64 %278, 4
  %280 = add nuw nsw i64 %279, 1
  %281 = icmp ult i32 %3, 16
  %282 = and i64 %276, -16
  %283 = and i64 %280, 7
  %284 = icmp ult i64 %278, 112
  %285 = sub nsw i64 %280, %283
  %286 = icmp eq i64 %283, 0
  %287 = icmp eq i64 %282, %276
  br label %439

288:                                              ; preds = %434, %266
  %289 = phi i16* [ %253, %266 ], [ %436, %434 ]
  %290 = phi i32 [ %252, %266 ], [ %437, %434 ]
  %291 = phi i32 [ %251, %266 ], [ %435, %434 ]
  %292 = ashr i32 %290, %183
  %293 = shl i32 %290, %11
  %294 = lshr i32 %293, 1
  %295 = trunc i32 %294 to i16
  %296 = and i16 %295, 31
  %297 = insertelement <8 x i16> undef, i16 %296, i32 0
  %298 = shufflevector <8 x i16> %297, <8 x i16> undef, <8 x i32> zeroinitializer
  %299 = sub <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 undef, i16 undef, i16 undef, i16 undef>, %298
  %300 = shufflevector <8 x i16> %299, <8 x i16> %298, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %301 = sub nsw i32 %186, %292
  %302 = ashr i32 %301, %11
  %303 = add nsw i32 %302, 7
  %304 = icmp slt i32 %303, %3
  %305 = select i1 %304, i32 %303, i32 %3
  %306 = and i32 %305, -8
  %307 = icmp sgt i32 %306, 0
  br i1 %307, label %308, label %344

308:                                              ; preds = %288
  %309 = trunc i32 %292 to i16
  %310 = insertelement <8 x i16> undef, i16 %309, i32 0
  %311 = shufflevector <8 x i16> %310, <8 x i16> undef, <8 x i32> zeroinitializer
  %312 = add <8 x i16> %311, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %313 = sext i32 %306 to i64
  %314 = sext i32 %292 to i64
  br label %315

315:                                              ; preds = %315, %308
  %316 = phi i64 [ %314, %308 ], [ %339, %315 ]
  %317 = phi i64 [ 0, %308 ], [ %338, %315 ]
  %318 = phi <8 x i16> [ %312, %308 ], [ %340, %315 ]
  %319 = getelementptr inbounds i16, i16* %8, i64 %316
  %320 = bitcast i16* %319 to <16 x i8>*
  %321 = load <16 x i8>, <16 x i8>* %320, align 1
  %322 = getelementptr inbounds i16, i16* %319, i64 %268
  %323 = bitcast i16* %322 to <16 x i8>*
  %324 = load <16 x i8>, <16 x i8>* %323, align 1
  %325 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %321, <16 x i8> %270) #11
  %326 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %324, <16 x i8> %270) #11
  %327 = bitcast <16 x i8> %325 to <8 x i16>
  %328 = mul <8 x i16> %300, %327
  %329 = bitcast <16 x i8> %326 to <8 x i16>
  %330 = mul <8 x i16> %300, %329
  %331 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %328, <8 x i16> %330) #11
  %332 = lshr <8 x i16> %331, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %333 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %332, <8 x i16> zeroinitializer) #11
  %334 = icmp sgt <8 x i16> %318, %256
  %335 = select <8 x i1> %334, <8 x i16> %261, <8 x i16> %333
  %336 = getelementptr inbounds i16, i16* %289, i64 %317
  %337 = bitcast i16* %336 to <8 x i16>*
  store <8 x i16> %335, <8 x i16>* %337, align 1
  %338 = add nuw nsw i64 %317, 8
  %339 = add i64 %316, %269
  %340 = add <8 x i16> %318, %264
  %341 = icmp slt i64 %338, %313
  br i1 %341, label %315, label %342

342:                                              ; preds = %315
  %343 = trunc i64 %338 to i32
  br label %344

344:                                              ; preds = %342, %288
  %345 = phi i32 [ 0, %288 ], [ %343, %342 ]
  %346 = zext i32 %345 to i64
  %347 = getelementptr inbounds i16, i16* %289, i64 %346
  %348 = load i16, i16* %258, align 2
  %349 = sub nsw i32 %3, %345
  %350 = sext i32 %349 to i64
  %351 = icmp eq i32 %349, 0
  br i1 %351, label %434, label %352

352:                                              ; preds = %344
  %353 = icmp ult i32 %349, 16
  br i1 %353, label %427, label %354

354:                                              ; preds = %352
  %355 = and i64 %350, -16
  %356 = insertelement <8 x i16> undef, i16 %348, i32 0
  %357 = shufflevector <8 x i16> %356, <8 x i16> undef, <8 x i32> zeroinitializer
  %358 = insertelement <8 x i16> undef, i16 %348, i32 0
  %359 = shufflevector <8 x i16> %358, <8 x i16> undef, <8 x i32> zeroinitializer
  %360 = add nsw i64 %355, -16
  %361 = lshr exact i64 %360, 4
  %362 = add nuw nsw i64 %361, 1
  %363 = and i64 %362, 7
  %364 = icmp ult i64 %360, 112
  br i1 %364, label %412, label %365

365:                                              ; preds = %354
  %366 = sub nsw i64 %362, %363
  br label %367

367:                                              ; preds = %367, %365
  %368 = phi i64 [ 0, %365 ], [ %409, %367 ]
  %369 = phi i64 [ %366, %365 ], [ %410, %367 ]
  %370 = getelementptr inbounds i16, i16* %347, i64 %368
  %371 = bitcast i16* %370 to <8 x i16>*
  store <8 x i16> %357, <8 x i16>* %371, align 2
  %372 = getelementptr inbounds i16, i16* %370, i64 8
  %373 = bitcast i16* %372 to <8 x i16>*
  store <8 x i16> %359, <8 x i16>* %373, align 2
  %374 = or i64 %368, 16
  %375 = getelementptr inbounds i16, i16* %347, i64 %374
  %376 = bitcast i16* %375 to <8 x i16>*
  store <8 x i16> %357, <8 x i16>* %376, align 2
  %377 = getelementptr inbounds i16, i16* %375, i64 8
  %378 = bitcast i16* %377 to <8 x i16>*
  store <8 x i16> %359, <8 x i16>* %378, align 2
  %379 = or i64 %368, 32
  %380 = getelementptr inbounds i16, i16* %347, i64 %379
  %381 = bitcast i16* %380 to <8 x i16>*
  store <8 x i16> %357, <8 x i16>* %381, align 2
  %382 = getelementptr inbounds i16, i16* %380, i64 8
  %383 = bitcast i16* %382 to <8 x i16>*
  store <8 x i16> %359, <8 x i16>* %383, align 2
  %384 = or i64 %368, 48
  %385 = getelementptr inbounds i16, i16* %347, i64 %384
  %386 = bitcast i16* %385 to <8 x i16>*
  store <8 x i16> %357, <8 x i16>* %386, align 2
  %387 = getelementptr inbounds i16, i16* %385, i64 8
  %388 = bitcast i16* %387 to <8 x i16>*
  store <8 x i16> %359, <8 x i16>* %388, align 2
  %389 = or i64 %368, 64
  %390 = getelementptr inbounds i16, i16* %347, i64 %389
  %391 = bitcast i16* %390 to <8 x i16>*
  store <8 x i16> %357, <8 x i16>* %391, align 2
  %392 = getelementptr inbounds i16, i16* %390, i64 8
  %393 = bitcast i16* %392 to <8 x i16>*
  store <8 x i16> %359, <8 x i16>* %393, align 2
  %394 = or i64 %368, 80
  %395 = getelementptr inbounds i16, i16* %347, i64 %394
  %396 = bitcast i16* %395 to <8 x i16>*
  store <8 x i16> %357, <8 x i16>* %396, align 2
  %397 = getelementptr inbounds i16, i16* %395, i64 8
  %398 = bitcast i16* %397 to <8 x i16>*
  store <8 x i16> %359, <8 x i16>* %398, align 2
  %399 = or i64 %368, 96
  %400 = getelementptr inbounds i16, i16* %347, i64 %399
  %401 = bitcast i16* %400 to <8 x i16>*
  store <8 x i16> %357, <8 x i16>* %401, align 2
  %402 = getelementptr inbounds i16, i16* %400, i64 8
  %403 = bitcast i16* %402 to <8 x i16>*
  store <8 x i16> %359, <8 x i16>* %403, align 2
  %404 = or i64 %368, 112
  %405 = getelementptr inbounds i16, i16* %347, i64 %404
  %406 = bitcast i16* %405 to <8 x i16>*
  store <8 x i16> %357, <8 x i16>* %406, align 2
  %407 = getelementptr inbounds i16, i16* %405, i64 8
  %408 = bitcast i16* %407 to <8 x i16>*
  store <8 x i16> %359, <8 x i16>* %408, align 2
  %409 = add i64 %368, 128
  %410 = add i64 %369, -8
  %411 = icmp eq i64 %410, 0
  br i1 %411, label %412, label %367, !llvm.loop !27

412:                                              ; preds = %367, %354
  %413 = phi i64 [ 0, %354 ], [ %409, %367 ]
  %414 = icmp eq i64 %363, 0
  br i1 %414, label %425, label %415

415:                                              ; preds = %412, %415
  %416 = phi i64 [ %422, %415 ], [ %413, %412 ]
  %417 = phi i64 [ %423, %415 ], [ %363, %412 ]
  %418 = getelementptr inbounds i16, i16* %347, i64 %416
  %419 = bitcast i16* %418 to <8 x i16>*
  store <8 x i16> %357, <8 x i16>* %419, align 2
  %420 = getelementptr inbounds i16, i16* %418, i64 8
  %421 = bitcast i16* %420 to <8 x i16>*
  store <8 x i16> %359, <8 x i16>* %421, align 2
  %422 = add i64 %416, 16
  %423 = add i64 %417, -1
  %424 = icmp eq i64 %423, 0
  br i1 %424, label %425, label %415, !llvm.loop !29

425:                                              ; preds = %415, %412
  %426 = icmp eq i64 %355, %350
  br i1 %426, label %434, label %427

427:                                              ; preds = %425, %352
  %428 = phi i64 [ 0, %352 ], [ %355, %425 ]
  br label %429

429:                                              ; preds = %427, %429
  %430 = phi i64 [ %432, %429 ], [ %428, %427 ]
  %431 = getelementptr inbounds i16, i16* %347, i64 %430
  store i16 %348, i16* %431, align 2
  %432 = add nuw i64 %430, 1
  %433 = icmp eq i64 %432, %350
  br i1 %433, label %434, label %429, !llvm.loop !30

434:                                              ; preds = %429, %425, %344
  %435 = add nuw nsw i32 %291, 1
  %436 = getelementptr inbounds i16, i16* %289, i64 %10
  %437 = add nsw i32 %290, %5
  %438 = icmp slt i32 %435, %194
  br i1 %438, label %288, label %271

439:                                              ; preds = %514, %275
  %440 = phi i16* [ %273, %275 ], [ %515, %514 ]
  %441 = phi i32 [ %272, %275 ], [ %516, %514 ]
  %442 = load i16, i16* %258, align 2
  br i1 %277, label %514, label %443

443:                                              ; preds = %439
  br i1 %281, label %507, label %444

444:                                              ; preds = %443
  %445 = insertelement <8 x i16> undef, i16 %442, i32 0
  %446 = shufflevector <8 x i16> %445, <8 x i16> undef, <8 x i32> zeroinitializer
  %447 = insertelement <8 x i16> undef, i16 %442, i32 0
  %448 = shufflevector <8 x i16> %447, <8 x i16> undef, <8 x i32> zeroinitializer
  br i1 %284, label %494, label %449

449:                                              ; preds = %444, %449
  %450 = phi i64 [ %491, %449 ], [ 0, %444 ]
  %451 = phi i64 [ %492, %449 ], [ %285, %444 ]
  %452 = getelementptr inbounds i16, i16* %440, i64 %450
  %453 = bitcast i16* %452 to <8 x i16>*
  store <8 x i16> %446, <8 x i16>* %453, align 2
  %454 = getelementptr inbounds i16, i16* %452, i64 8
  %455 = bitcast i16* %454 to <8 x i16>*
  store <8 x i16> %448, <8 x i16>* %455, align 2
  %456 = or i64 %450, 16
  %457 = getelementptr inbounds i16, i16* %440, i64 %456
  %458 = bitcast i16* %457 to <8 x i16>*
  store <8 x i16> %446, <8 x i16>* %458, align 2
  %459 = getelementptr inbounds i16, i16* %457, i64 8
  %460 = bitcast i16* %459 to <8 x i16>*
  store <8 x i16> %448, <8 x i16>* %460, align 2
  %461 = or i64 %450, 32
  %462 = getelementptr inbounds i16, i16* %440, i64 %461
  %463 = bitcast i16* %462 to <8 x i16>*
  store <8 x i16> %446, <8 x i16>* %463, align 2
  %464 = getelementptr inbounds i16, i16* %462, i64 8
  %465 = bitcast i16* %464 to <8 x i16>*
  store <8 x i16> %448, <8 x i16>* %465, align 2
  %466 = or i64 %450, 48
  %467 = getelementptr inbounds i16, i16* %440, i64 %466
  %468 = bitcast i16* %467 to <8 x i16>*
  store <8 x i16> %446, <8 x i16>* %468, align 2
  %469 = getelementptr inbounds i16, i16* %467, i64 8
  %470 = bitcast i16* %469 to <8 x i16>*
  store <8 x i16> %448, <8 x i16>* %470, align 2
  %471 = or i64 %450, 64
  %472 = getelementptr inbounds i16, i16* %440, i64 %471
  %473 = bitcast i16* %472 to <8 x i16>*
  store <8 x i16> %446, <8 x i16>* %473, align 2
  %474 = getelementptr inbounds i16, i16* %472, i64 8
  %475 = bitcast i16* %474 to <8 x i16>*
  store <8 x i16> %448, <8 x i16>* %475, align 2
  %476 = or i64 %450, 80
  %477 = getelementptr inbounds i16, i16* %440, i64 %476
  %478 = bitcast i16* %477 to <8 x i16>*
  store <8 x i16> %446, <8 x i16>* %478, align 2
  %479 = getelementptr inbounds i16, i16* %477, i64 8
  %480 = bitcast i16* %479 to <8 x i16>*
  store <8 x i16> %448, <8 x i16>* %480, align 2
  %481 = or i64 %450, 96
  %482 = getelementptr inbounds i16, i16* %440, i64 %481
  %483 = bitcast i16* %482 to <8 x i16>*
  store <8 x i16> %446, <8 x i16>* %483, align 2
  %484 = getelementptr inbounds i16, i16* %482, i64 8
  %485 = bitcast i16* %484 to <8 x i16>*
  store <8 x i16> %448, <8 x i16>* %485, align 2
  %486 = or i64 %450, 112
  %487 = getelementptr inbounds i16, i16* %440, i64 %486
  %488 = bitcast i16* %487 to <8 x i16>*
  store <8 x i16> %446, <8 x i16>* %488, align 2
  %489 = getelementptr inbounds i16, i16* %487, i64 8
  %490 = bitcast i16* %489 to <8 x i16>*
  store <8 x i16> %448, <8 x i16>* %490, align 2
  %491 = add i64 %450, 128
  %492 = add i64 %451, -8
  %493 = icmp eq i64 %492, 0
  br i1 %493, label %494, label %449, !llvm.loop !32

494:                                              ; preds = %449, %444
  %495 = phi i64 [ 0, %444 ], [ %491, %449 ]
  br i1 %286, label %506, label %496

496:                                              ; preds = %494, %496
  %497 = phi i64 [ %503, %496 ], [ %495, %494 ]
  %498 = phi i64 [ %504, %496 ], [ %283, %494 ]
  %499 = getelementptr inbounds i16, i16* %440, i64 %497
  %500 = bitcast i16* %499 to <8 x i16>*
  store <8 x i16> %446, <8 x i16>* %500, align 2
  %501 = getelementptr inbounds i16, i16* %499, i64 8
  %502 = bitcast i16* %501 to <8 x i16>*
  store <8 x i16> %448, <8 x i16>* %502, align 2
  %503 = add i64 %497, 16
  %504 = add i64 %498, -1
  %505 = icmp eq i64 %504, 0
  br i1 %505, label %506, label %496, !llvm.loop !33

506:                                              ; preds = %496, %494
  br i1 %287, label %514, label %507

507:                                              ; preds = %506, %443
  %508 = phi i64 [ 0, %443 ], [ %282, %506 ]
  br label %509

509:                                              ; preds = %507, %509
  %510 = phi i64 [ %512, %509 ], [ %508, %507 ]
  %511 = getelementptr inbounds i16, i16* %440, i64 %510
  store i16 %442, i16* %511, align 2
  %512 = add nuw i64 %510, 1
  %513 = icmp eq i64 %512, %276
  br i1 %513, label %514, label %509, !llvm.loop !34

514:                                              ; preds = %509, %506, %439
  %515 = getelementptr inbounds i16, i16* %440, i64 %10
  %516 = add nuw nsw i32 %441, 1
  %517 = icmp eq i32 %516, %4
  br i1 %517, label %745, label %439

518:                                              ; preds = %181
  %519 = mul nsw i32 %5, %4
  %520 = ashr i32 %519, %183
  %521 = shl i32 %3, %11
  %522 = add nsw i32 %520, %521
  %523 = icmp slt i32 %522, %186
  br i1 %523, label %524, label %572

524:                                              ; preds = %518
  %525 = shl i32 4, %11
  %526 = zext i32 %525 to i64
  %527 = bitcast <2 x i64> %71 to <16 x i8>
  %528 = zext i32 %187 to i64
  %529 = sext i32 %3 to i64
  br label %530

530:                                              ; preds = %524, %567
  %531 = phi i32 [ %569, %567 ], [ %5, %524 ]
  %532 = phi i32 [ %570, %567 ], [ %4, %524 ]
  %533 = phi i16* [ %568, %567 ], [ %9, %524 ]
  %534 = ashr i32 %531, %183
  %535 = shl i32 %531, %11
  %536 = lshr i32 %535, 1
  %537 = trunc i32 %536 to i16
  %538 = and i16 %537, 31
  %539 = insertelement <8 x i16> undef, i16 %538, i32 0
  %540 = shufflevector <8 x i16> %539, <8 x i16> undef, <8 x i32> zeroinitializer
  %541 = sub <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 undef, i16 undef, i16 undef, i16 undef>, %540
  %542 = shufflevector <8 x i16> %541, <8 x i16> %540, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %543 = sext i32 %534 to i64
  br label %544

544:                                              ; preds = %544, %530
  %545 = phi i64 [ %565, %544 ], [ 0, %530 ]
  %546 = phi i64 [ %564, %544 ], [ %543, %530 ]
  %547 = getelementptr inbounds i16, i16* %8, i64 %546
  %548 = bitcast i16* %547 to <16 x i8>*
  %549 = load <16 x i8>, <16 x i8>* %548, align 1
  %550 = getelementptr inbounds i16, i16* %547, i64 %526
  %551 = bitcast i16* %550 to <16 x i8>*
  %552 = load <16 x i8>, <16 x i8>* %551, align 1
  %553 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %549, <16 x i8> %527) #11
  %554 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %552, <16 x i8> %527) #11
  %555 = bitcast <16 x i8> %553 to <8 x i16>
  %556 = mul <8 x i16> %542, %555
  %557 = bitcast <16 x i8> %554 to <8 x i16>
  %558 = mul <8 x i16> %542, %557
  %559 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %556, <8 x i16> %558) #11
  %560 = lshr <8 x i16> %559, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %561 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %560, <8 x i16> zeroinitializer) #11
  %562 = getelementptr inbounds i16, i16* %533, i64 %545
  %563 = bitcast i16* %562 to <8 x i16>*
  store <8 x i16> %561, <8 x i16>* %563, align 1
  %564 = add i64 %546, %528
  %565 = add nuw nsw i64 %545, 8
  %566 = icmp slt i64 %565, %529
  br i1 %566, label %544, label %567

567:                                              ; preds = %544
  %568 = getelementptr inbounds i16, i16* %533, i64 %10
  %569 = add nsw i32 %531, %5
  %570 = add nsw i32 %532, -1
  %571 = icmp eq i32 %570, 0
  br i1 %571, label %745, label %530

572:                                              ; preds = %518
  %573 = trunc i32 %186 to i16
  %574 = insertelement <8 x i16> undef, i16 %573, i32 0
  %575 = shufflevector <8 x i16> %574, <8 x i16> undef, <8 x i32> zeroinitializer
  %576 = sext i32 %186 to i64
  %577 = getelementptr inbounds i16, i16* %8, i64 %576
  %578 = load i16, i16* %577, align 2
  %579 = insertelement <8 x i16> undef, i16 %578, i32 0
  %580 = shufflevector <8 x i16> %579, <8 x i16> undef, <8 x i32> zeroinitializer
  %581 = trunc i32 %187 to i16
  %582 = insertelement <8 x i16> undef, i16 %581, i32 0
  %583 = shufflevector <8 x i16> %582, <8 x i16> undef, <8 x i32> zeroinitializer
  %584 = ashr i32 %5, %183
  %585 = icmp sgt i32 %584, 1
  %586 = select i1 %585, i32 %584, i32 1
  %587 = sdiv i32 %186, %586
  %588 = icmp sgt i32 %587, %4
  %589 = select i1 %588, i32 %4, i32 %587
  %590 = icmp sgt i32 %589, 0
  br i1 %590, label %591, label %598

591:                                              ; preds = %572
  %592 = icmp sgt i32 %3, 0
  %593 = shl i32 4, %11
  %594 = zext i32 %593 to i64
  %595 = bitcast <2 x i64> %71 to <16 x i8>
  %596 = sext i32 %3 to i64
  %597 = zext i32 %187 to i64
  br label %615

598:                                              ; preds = %634, %572
  %599 = phi i32 [ 0, %572 ], [ %589, %634 ]
  %600 = phi i16* [ %9, %572 ], [ %636, %634 ]
  %601 = icmp slt i32 %599, %4
  br i1 %601, label %602, label %745

602:                                              ; preds = %598
  %603 = sext i32 %3 to i64
  %604 = icmp eq i32 %3, 0
  %605 = add nsw i64 %603, -16
  %606 = lshr i64 %605, 4
  %607 = add nuw nsw i64 %606, 1
  %608 = icmp ult i32 %3, 16
  %609 = and i64 %603, -16
  %610 = and i64 %607, 7
  %611 = icmp ult i64 %605, 112
  %612 = sub nsw i64 %607, %610
  %613 = icmp eq i64 %610, 0
  %614 = icmp eq i64 %609, %603
  br label %666

615:                                              ; preds = %591, %634
  %616 = phi i16* [ %9, %591 ], [ %636, %634 ]
  %617 = phi i32 [ 0, %591 ], [ %635, %634 ]
  %618 = phi i32 [ %5, %591 ], [ %637, %634 ]
  %619 = ashr i32 %618, %183
  %620 = shl i32 %618, %11
  %621 = lshr i32 %620, 1
  %622 = trunc i32 %621 to i16
  %623 = and i16 %622, 31
  %624 = insertelement <8 x i16> undef, i16 %623, i32 0
  %625 = shufflevector <8 x i16> %624, <8 x i16> undef, <8 x i32> zeroinitializer
  %626 = sub <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 undef, i16 undef, i16 undef, i16 undef>, %625
  %627 = shufflevector <8 x i16> %626, <8 x i16> %625, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  br i1 %592, label %628, label %634

628:                                              ; preds = %615
  %629 = trunc i32 %619 to i16
  %630 = insertelement <8 x i16> undef, i16 %629, i32 0
  %631 = shufflevector <8 x i16> %630, <8 x i16> undef, <8 x i32> zeroinitializer
  %632 = add <8 x i16> %631, <i16 1, i16 2, i16 3, i16 4, i16 5, i16 6, i16 7, i16 8>
  %633 = sext i32 %619 to i64
  br label %639

634:                                              ; preds = %639, %615
  %635 = add nuw nsw i32 %617, 1
  %636 = getelementptr inbounds i16, i16* %616, i64 %10
  %637 = add nsw i32 %618, %5
  %638 = icmp slt i32 %635, %589
  br i1 %638, label %615, label %598

639:                                              ; preds = %628, %639
  %640 = phi i64 [ %633, %628 ], [ %663, %639 ]
  %641 = phi i64 [ 0, %628 ], [ %662, %639 ]
  %642 = phi <8 x i16> [ %632, %628 ], [ %664, %639 ]
  %643 = getelementptr inbounds i16, i16* %8, i64 %640
  %644 = bitcast i16* %643 to <16 x i8>*
  %645 = load <16 x i8>, <16 x i8>* %644, align 1
  %646 = getelementptr inbounds i16, i16* %643, i64 %594
  %647 = bitcast i16* %646 to <16 x i8>*
  %648 = load <16 x i8>, <16 x i8>* %647, align 1
  %649 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %645, <16 x i8> %595) #11
  %650 = tail call <16 x i8> @llvm.x86.ssse3.pshuf.b.128(<16 x i8> %648, <16 x i8> %595) #11
  %651 = bitcast <16 x i8> %649 to <8 x i16>
  %652 = mul <8 x i16> %627, %651
  %653 = bitcast <16 x i8> %650 to <8 x i16>
  %654 = mul <8 x i16> %627, %653
  %655 = tail call <8 x i16> @llvm.x86.ssse3.phadd.w.128(<8 x i16> %652, <8 x i16> %654) #11
  %656 = lshr <8 x i16> %655, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %657 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %656, <8 x i16> zeroinitializer) #11
  %658 = icmp sgt <8 x i16> %642, %575
  %659 = select <8 x i1> %658, <8 x i16> %580, <8 x i16> %657
  %660 = getelementptr inbounds i16, i16* %616, i64 %641
  %661 = bitcast i16* %660 to <8 x i16>*
  store <8 x i16> %659, <8 x i16>* %661, align 1
  %662 = add nuw nsw i64 %641, 8
  %663 = add i64 %640, %597
  %664 = add <8 x i16> %642, %583
  %665 = icmp slt i64 %662, %596
  br i1 %665, label %639, label %634

666:                                              ; preds = %741, %602
  %667 = phi i16* [ %600, %602 ], [ %742, %741 ]
  %668 = phi i32 [ %599, %602 ], [ %743, %741 ]
  %669 = load i16, i16* %577, align 2
  br i1 %604, label %741, label %670

670:                                              ; preds = %666
  br i1 %608, label %734, label %671

671:                                              ; preds = %670
  %672 = insertelement <8 x i16> undef, i16 %669, i32 0
  %673 = shufflevector <8 x i16> %672, <8 x i16> undef, <8 x i32> zeroinitializer
  %674 = insertelement <8 x i16> undef, i16 %669, i32 0
  %675 = shufflevector <8 x i16> %674, <8 x i16> undef, <8 x i32> zeroinitializer
  br i1 %611, label %721, label %676

676:                                              ; preds = %671, %676
  %677 = phi i64 [ %718, %676 ], [ 0, %671 ]
  %678 = phi i64 [ %719, %676 ], [ %612, %671 ]
  %679 = getelementptr inbounds i16, i16* %667, i64 %677
  %680 = bitcast i16* %679 to <8 x i16>*
  store <8 x i16> %673, <8 x i16>* %680, align 2
  %681 = getelementptr inbounds i16, i16* %679, i64 8
  %682 = bitcast i16* %681 to <8 x i16>*
  store <8 x i16> %675, <8 x i16>* %682, align 2
  %683 = or i64 %677, 16
  %684 = getelementptr inbounds i16, i16* %667, i64 %683
  %685 = bitcast i16* %684 to <8 x i16>*
  store <8 x i16> %673, <8 x i16>* %685, align 2
  %686 = getelementptr inbounds i16, i16* %684, i64 8
  %687 = bitcast i16* %686 to <8 x i16>*
  store <8 x i16> %675, <8 x i16>* %687, align 2
  %688 = or i64 %677, 32
  %689 = getelementptr inbounds i16, i16* %667, i64 %688
  %690 = bitcast i16* %689 to <8 x i16>*
  store <8 x i16> %673, <8 x i16>* %690, align 2
  %691 = getelementptr inbounds i16, i16* %689, i64 8
  %692 = bitcast i16* %691 to <8 x i16>*
  store <8 x i16> %675, <8 x i16>* %692, align 2
  %693 = or i64 %677, 48
  %694 = getelementptr inbounds i16, i16* %667, i64 %693
  %695 = bitcast i16* %694 to <8 x i16>*
  store <8 x i16> %673, <8 x i16>* %695, align 2
  %696 = getelementptr inbounds i16, i16* %694, i64 8
  %697 = bitcast i16* %696 to <8 x i16>*
  store <8 x i16> %675, <8 x i16>* %697, align 2
  %698 = or i64 %677, 64
  %699 = getelementptr inbounds i16, i16* %667, i64 %698
  %700 = bitcast i16* %699 to <8 x i16>*
  store <8 x i16> %673, <8 x i16>* %700, align 2
  %701 = getelementptr inbounds i16, i16* %699, i64 8
  %702 = bitcast i16* %701 to <8 x i16>*
  store <8 x i16> %675, <8 x i16>* %702, align 2
  %703 = or i64 %677, 80
  %704 = getelementptr inbounds i16, i16* %667, i64 %703
  %705 = bitcast i16* %704 to <8 x i16>*
  store <8 x i16> %673, <8 x i16>* %705, align 2
  %706 = getelementptr inbounds i16, i16* %704, i64 8
  %707 = bitcast i16* %706 to <8 x i16>*
  store <8 x i16> %675, <8 x i16>* %707, align 2
  %708 = or i64 %677, 96
  %709 = getelementptr inbounds i16, i16* %667, i64 %708
  %710 = bitcast i16* %709 to <8 x i16>*
  store <8 x i16> %673, <8 x i16>* %710, align 2
  %711 = getelementptr inbounds i16, i16* %709, i64 8
  %712 = bitcast i16* %711 to <8 x i16>*
  store <8 x i16> %675, <8 x i16>* %712, align 2
  %713 = or i64 %677, 112
  %714 = getelementptr inbounds i16, i16* %667, i64 %713
  %715 = bitcast i16* %714 to <8 x i16>*
  store <8 x i16> %673, <8 x i16>* %715, align 2
  %716 = getelementptr inbounds i16, i16* %714, i64 8
  %717 = bitcast i16* %716 to <8 x i16>*
  store <8 x i16> %675, <8 x i16>* %717, align 2
  %718 = add i64 %677, 128
  %719 = add i64 %678, -8
  %720 = icmp eq i64 %719, 0
  br i1 %720, label %721, label %676, !llvm.loop !35

721:                                              ; preds = %676, %671
  %722 = phi i64 [ 0, %671 ], [ %718, %676 ]
  br i1 %613, label %733, label %723

723:                                              ; preds = %721, %723
  %724 = phi i64 [ %730, %723 ], [ %722, %721 ]
  %725 = phi i64 [ %731, %723 ], [ %610, %721 ]
  %726 = getelementptr inbounds i16, i16* %667, i64 %724
  %727 = bitcast i16* %726 to <8 x i16>*
  store <8 x i16> %673, <8 x i16>* %727, align 2
  %728 = getelementptr inbounds i16, i16* %726, i64 8
  %729 = bitcast i16* %728 to <8 x i16>*
  store <8 x i16> %675, <8 x i16>* %729, align 2
  %730 = add i64 %724, 16
  %731 = add i64 %725, -1
  %732 = icmp eq i64 %731, 0
  br i1 %732, label %733, label %723, !llvm.loop !36

733:                                              ; preds = %723, %721
  br i1 %614, label %741, label %734

734:                                              ; preds = %733, %670
  %735 = phi i64 [ 0, %670 ], [ %609, %733 ]
  br label %736

736:                                              ; preds = %734, %736
  %737 = phi i64 [ %739, %736 ], [ %735, %734 ]
  %738 = getelementptr inbounds i16, i16* %667, i64 %737
  store i16 %669, i16* %738, align 2
  %739 = add nuw i64 %737, 1
  %740 = icmp eq i64 %739, %603
  br i1 %740, label %741, label %736, !llvm.loop !37

741:                                              ; preds = %736, %733, %666
  %742 = getelementptr inbounds i16, i16* %667, i64 %10
  %743 = add nuw nsw i32 %668, 1
  %744 = icmp eq i32 %743, %4
  br i1 %744, label %745, label %666

745:                                              ; preds = %741, %567, %514, %116, %156, %31, %598, %94, %271, %18
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi2EXadL_ZNS0_13high_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi4EEEvPvlDv2_xEELi0ELi0EE5DcTopES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readnone) #4 align 2 {
  %5 = bitcast i8* %2 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <8 x i16>
  %9 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #11
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = shufflevector <16 x i8> %10, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %12 = bitcast <16 x i8> %11 to <4 x i32>
  %13 = add <4 x i32> %9, <i32 2, i32 2, i32 2, i32 2>
  %14 = add <4 x i32> %13, %12
  %15 = lshr <4 x i32> %14, <i32 2, i32 2, i32 2, i32 2>
  %16 = bitcast <4 x i32> %15 to <8 x i16>
  %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %18 = bitcast <8 x i16> %17 to <2 x i64>
  %19 = extractelement <2 x i64> %18, i32 0
  %20 = bitcast i8* %0 to i64*
  store i64 %19, i64* %20, align 1
  %21 = getelementptr inbounds i8, i8* %0, i64 %1
  %22 = bitcast i8* %21 to i64*
  store i64 %19, i64* %22, align 1
  %23 = getelementptr inbounds i8, i8* %21, i64 %1
  %24 = bitcast i8* %23 to i64*
  store i64 %19, i64* %24, align 1
  %25 = getelementptr inbounds i8, i8* %23, i64 %1
  %26 = bitcast i8* %25 to i64*
  store i64 %19, i64* %26, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi2EXadL_ZNS0_13high_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi4EEEvPvlDv2_xEELi0ELi0EE6DcLeftES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %3 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <8 x i16>
  %9 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #11
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = shufflevector <16 x i8> %10, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %12 = bitcast <16 x i8> %11 to <4 x i32>
  %13 = add <4 x i32> %9, <i32 2, i32 2, i32 2, i32 2>
  %14 = add <4 x i32> %13, %12
  %15 = lshr <4 x i32> %14, <i32 2, i32 2, i32 2, i32 2>
  %16 = bitcast <4 x i32> %15 to <8 x i16>
  %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %18 = bitcast <8 x i16> %17 to <2 x i64>
  %19 = extractelement <2 x i64> %18, i32 0
  %20 = bitcast i8* %0 to i64*
  store i64 %19, i64* %20, align 1
  %21 = getelementptr inbounds i8, i8* %0, i64 %1
  %22 = bitcast i8* %21 to i64*
  store i64 %19, i64* %22, align 1
  %23 = getelementptr inbounds i8, i8* %21, i64 %1
  %24 = bitcast i8* %23 to i64*
  store i64 %19, i64* %24, align 1
  %25 = getelementptr inbounds i8, i8* %23, i64 %1
  %26 = bitcast i8* %25 to i64*
  store i64 %19, i64* %26, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_118DcPredFuncs_SSE4_1ILi2ELi2EXadL_ZNS0_13high_bitdepth12_GLOBAL__N_113DcSum4_SSE4_1EPKvEEXadL_ZNS4_13DcSum4_SSE4_1ES6_EEXadL_ZNS4_17DcStore4xH_SSE4_1ILi4EEEvPvlDv2_xEELi0ELi0EE2DcES8_lS6_S6_(i8* nocapture, i64, i8* nocapture readonly, i8* nocapture readonly) #4 align 2 {
  %5 = bitcast i8* %2 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <8 x i16>
  %9 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #11
  %10 = bitcast <4 x i32> %9 to <16 x i8>
  %11 = shufflevector <16 x i8> %10, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %12 = bitcast <16 x i8> %11 to <4 x i32>
  %13 = bitcast i8* %3 to i64*
  %14 = load i64, i64* %13, align 1
  %15 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %14, i32 0
  %16 = bitcast <2 x i64> %15 to <8 x i16>
  %17 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #11
  %18 = bitcast <4 x i32> %17 to <16 x i8>
  %19 = shufflevector <16 x i8> %18, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %20 = bitcast <16 x i8> %19 to <4 x i32>
  %21 = add <4 x i32> %9, <i32 4, i32 4, i32 4, i32 4>
  %22 = add <4 x i32> %21, %17
  %23 = add <4 x i32> %22, %12
  %24 = add <4 x i32> %23, %20
  %25 = lshr <4 x i32> %24, <i32 3, i32 3, i32 3, i32 3>
  %26 = bitcast <4 x i32> %25 to <8 x i16>
  %27 = shufflevector <8 x i16> %26, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef>
  %28 = bitcast <8 x i16> %27 to <2 x i64>
  %29 = extractelement <2 x i64> %28, i32 0
  %30 = bitcast i8* %0 to i64*
  store i64 %29, i64* %30, align 1
  %31 = getelementptr inbounds i8, i8* %0, i64 %1
  %32 = bitcast i8* %31 to i64*
  store i64 %29, i64* %32, align 1
  %33 = getelementptr inbounds i8, i8* %31, i64 %1
  %34 = bitcast i8* %33 to i64*
  store i64 %29, i64* %34, align 1
  %35 = getelementptr inbounds i8, i8* %33, i64 %1
  %36 = bitcast i8* %35 to i64*
  store i64 %29, i64* %36, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore4_SSE4_1IXadL_ZNS4_17WriteDuplicate4x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = bitcast i8* %3 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> undef, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <8 x i16>
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %10 = bitcast <8 x i16> %9 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = extractelement <2 x i64> %12, i32 0
  %14 = bitcast i8* %0 to i64*
  store i64 %13, i64* %14, align 1
  %15 = getelementptr inbounds i8, i8* %0, i64 %1
  %16 = bitcast <4 x i32> %11 to <4 x float>
  %17 = shufflevector <4 x float> %16, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %18 = bitcast i8* %15 to <2 x float>*
  store <2 x float> %17, <2 x float>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %15, i64 %1
  %20 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %21 = bitcast <4 x i32> %20 to <2 x i64>
  %22 = extractelement <2 x i64> %21, i32 0
  %23 = bitcast i8* %19 to i64*
  store i64 %22, i64* %23, align 1
  %24 = getelementptr inbounds i8, i8* %19, i64 %1
  %25 = bitcast <4 x i32> %20 to <4 x float>
  %26 = shufflevector <4 x float> %25, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %27 = bitcast i8* %24 to <2 x float>*
  store <2 x float> %26, <2 x float>* %27, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_17WriteDuplicate4x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = bitcast i8* %3 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 1
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %8 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %9 = bitcast <8 x i16> %7 to <4 x i32>
  %10 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %11 = bitcast <4 x i32> %10 to <2 x i64>
  %12 = extractelement <2 x i64> %11, i32 0
  %13 = bitcast i8* %0 to i64*
  store i64 %12, i64* %13, align 1
  %14 = getelementptr inbounds i8, i8* %0, i64 %1
  %15 = bitcast <4 x i32> %10 to <4 x float>
  %16 = shufflevector <4 x float> %15, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %17 = bitcast i8* %14 to <2 x float>*
  store <2 x float> %16, <2 x float>* %17, align 1
  %18 = getelementptr inbounds i8, i8* %14, i64 %1
  %19 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %20 = bitcast <4 x i32> %19 to <2 x i64>
  %21 = extractelement <2 x i64> %20, i32 0
  %22 = bitcast i8* %18 to i64*
  store i64 %21, i64* %22, align 1
  %23 = getelementptr inbounds i8, i8* %18, i64 %1
  %24 = bitcast <4 x i32> %19 to <4 x float>
  %25 = shufflevector <4 x float> %24, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %26 = bitcast i8* %23 to <2 x float>*
  store <2 x float> %25, <2 x float>* %26, align 1
  %27 = shl i64 %1, 2
  %28 = getelementptr inbounds i8, i8* %0, i64 %27
  %29 = bitcast <8 x i16> %8 to <4 x i32>
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %31 = bitcast <4 x i32> %30 to <2 x i64>
  %32 = extractelement <2 x i64> %31, i32 0
  %33 = bitcast i8* %28 to i64*
  store i64 %32, i64* %33, align 1
  %34 = getelementptr inbounds i8, i8* %28, i64 %1
  %35 = bitcast <4 x i32> %30 to <4 x float>
  %36 = shufflevector <4 x float> %35, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %37 = bitcast i8* %34 to <2 x float>*
  store <2 x float> %36, <2 x float>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %34, i64 %1
  %39 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %40 = bitcast <4 x i32> %39 to <2 x i64>
  %41 = extractelement <2 x i64> %40, i32 0
  %42 = bitcast i8* %38 to i64*
  store i64 %41, i64* %42, align 1
  %43 = getelementptr inbounds i8, i8* %38, i64 %1
  %44 = bitcast <4 x i32> %39 to <4 x float>
  %45 = shufflevector <4 x float> %44, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %46 = bitcast i8* %43 to <2 x float>*
  store <2 x float> %45, <2 x float>* %46, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_17WriteDuplicate4x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to <8 x i16>*
  %7 = load <8 x i16>, <8 x i16>* %6, align 1
  %8 = shufflevector <8 x i16> %7, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %9 = shufflevector <8 x i16> %7, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %10 = bitcast <8 x i16> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = extractelement <2 x i64> %12, i32 0
  %14 = bitcast i8* %0 to i64*
  store i64 %13, i64* %14, align 1
  %15 = getelementptr inbounds i8, i8* %0, i64 %1
  %16 = bitcast <4 x i32> %11 to <4 x float>
  %17 = shufflevector <4 x float> %16, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %18 = bitcast i8* %15 to <2 x float>*
  store <2 x float> %17, <2 x float>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %15, i64 %1
  %20 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %21 = bitcast <4 x i32> %20 to <2 x i64>
  %22 = extractelement <2 x i64> %21, i32 0
  %23 = bitcast i8* %19 to i64*
  store i64 %22, i64* %23, align 1
  %24 = getelementptr inbounds i8, i8* %19, i64 %1
  %25 = bitcast <4 x i32> %20 to <4 x float>
  %26 = shufflevector <4 x float> %25, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %27 = bitcast i8* %24 to <2 x float>*
  store <2 x float> %26, <2 x float>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %0, i64 %5
  %29 = bitcast <8 x i16> %9 to <4 x i32>
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %31 = bitcast <4 x i32> %30 to <2 x i64>
  %32 = extractelement <2 x i64> %31, i32 0
  %33 = bitcast i8* %28 to i64*
  store i64 %32, i64* %33, align 1
  %34 = getelementptr inbounds i8, i8* %28, i64 %1
  %35 = bitcast <4 x i32> %30 to <4 x float>
  %36 = shufflevector <4 x float> %35, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %37 = bitcast i8* %34 to <2 x float>*
  store <2 x float> %36, <2 x float>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %34, i64 %1
  %39 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %40 = bitcast <4 x i32> %39 to <2 x i64>
  %41 = extractelement <2 x i64> %40, i32 0
  %42 = bitcast i8* %38 to i64*
  store i64 %41, i64* %42, align 1
  %43 = getelementptr inbounds i8, i8* %38, i64 %1
  %44 = bitcast <4 x i32> %39 to <4 x float>
  %45 = shufflevector <4 x float> %44, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %46 = bitcast i8* %43 to <2 x float>*
  store <2 x float> %45, <2 x float>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %28, i64 %5
  %48 = getelementptr inbounds i8, i8* %3, i64 16
  %49 = bitcast i8* %48 to <8 x i16>*
  %50 = load <8 x i16>, <8 x i16>* %49, align 1
  %51 = shufflevector <8 x i16> %50, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %52 = shufflevector <8 x i16> %50, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %53 = bitcast <8 x i16> %51 to <4 x i32>
  %54 = shufflevector <4 x i32> %53, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %55 = bitcast <4 x i32> %54 to <2 x i64>
  %56 = extractelement <2 x i64> %55, i32 0
  %57 = bitcast i8* %47 to i64*
  store i64 %56, i64* %57, align 1
  %58 = getelementptr inbounds i8, i8* %47, i64 %1
  %59 = bitcast <4 x i32> %54 to <4 x float>
  %60 = shufflevector <4 x float> %59, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %61 = bitcast i8* %58 to <2 x float>*
  store <2 x float> %60, <2 x float>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %58, i64 %1
  %63 = shufflevector <4 x i32> %53, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %64 = bitcast <4 x i32> %63 to <2 x i64>
  %65 = extractelement <2 x i64> %64, i32 0
  %66 = bitcast i8* %62 to i64*
  store i64 %65, i64* %66, align 1
  %67 = getelementptr inbounds i8, i8* %62, i64 %1
  %68 = bitcast <4 x i32> %63 to <4 x float>
  %69 = shufflevector <4 x float> %68, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %70 = bitcast i8* %67 to <2 x float>*
  store <2 x float> %69, <2 x float>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %47, i64 %5
  %72 = bitcast <8 x i16> %52 to <4 x i32>
  %73 = shufflevector <4 x i32> %72, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %74 = bitcast <4 x i32> %73 to <2 x i64>
  %75 = extractelement <2 x i64> %74, i32 0
  %76 = bitcast i8* %71 to i64*
  store i64 %75, i64* %76, align 1
  %77 = getelementptr inbounds i8, i8* %71, i64 %1
  %78 = bitcast <4 x i32> %73 to <4 x float>
  %79 = shufflevector <4 x float> %78, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %80 = bitcast i8* %77 to <2 x float>*
  store <2 x float> %79, <2 x float>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %77, i64 %1
  %82 = shufflevector <4 x i32> %72, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %83 = bitcast <4 x i32> %82 to <2 x i64>
  %84 = extractelement <2 x i64> %83, i32 0
  %85 = bitcast i8* %81 to i64*
  store i64 %84, i64* %85, align 1
  %86 = getelementptr inbounds i8, i8* %81, i64 %1
  %87 = bitcast <4 x i32> %82 to <4 x float>
  %88 = shufflevector <4 x float> %87, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %89 = bitcast i8* %86 to <2 x float>*
  store <2 x float> %88, <2 x float>* %89, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore4_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = bitcast i8* %3 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> undef, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <8 x i16>
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %10 = bitcast <8 x i16> %9 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> zeroinitializer
  %16 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %15, <2 x i64>* %16, align 1
  %17 = getelementptr inbounds i8, i8* %0, i64 %1
  %18 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %19 = bitcast i8* %17 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %19, align 1
  %20 = getelementptr inbounds i8, i8* %17, i64 %1
  %21 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> zeroinitializer
  %22 = bitcast i8* %20 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %20, i64 %1
  %24 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %25 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %24, <2 x i64>* %25, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = bitcast i8* %3 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 1
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %8 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %9 = bitcast <8 x i16> %7 to <4 x i32>
  %10 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %11 = bitcast <4 x i32> %10 to <2 x i64>
  %12 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %13 = bitcast <4 x i32> %12 to <2 x i64>
  %14 = shufflevector <2 x i64> %11, <2 x i64> undef, <2 x i32> zeroinitializer
  %15 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %14, <2 x i64>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 %1
  %17 = shufflevector <2 x i64> %11, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %18 = bitcast i8* %16 to <2 x i64>*
  store <2 x i64> %17, <2 x i64>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %16, i64 %1
  %20 = shufflevector <2 x i64> %13, <2 x i64> undef, <2 x i32> zeroinitializer
  %21 = bitcast i8* %19 to <2 x i64>*
  store <2 x i64> %20, <2 x i64>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %19, i64 %1
  %23 = shufflevector <2 x i64> %13, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %24 = bitcast i8* %22 to <2 x i64>*
  store <2 x i64> %23, <2 x i64>* %24, align 1
  %25 = shl i64 %1, 2
  %26 = getelementptr inbounds i8, i8* %0, i64 %25
  %27 = bitcast <8 x i16> %8 to <4 x i32>
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %29 = bitcast <4 x i32> %28 to <2 x i64>
  %30 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %31 = bitcast <4 x i32> %30 to <2 x i64>
  %32 = shufflevector <2 x i64> %29, <2 x i64> undef, <2 x i32> zeroinitializer
  %33 = bitcast i8* %26 to <2 x i64>*
  store <2 x i64> %32, <2 x i64>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %26, i64 %1
  %35 = shufflevector <2 x i64> %29, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %36 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %35, <2 x i64>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %34, i64 %1
  %38 = shufflevector <2 x i64> %31, <2 x i64> undef, <2 x i32> zeroinitializer
  %39 = bitcast i8* %37 to <2 x i64>*
  store <2 x i64> %38, <2 x i64>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %37, i64 %1
  %41 = shufflevector <2 x i64> %31, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %42 = bitcast i8* %40 to <2 x i64>*
  store <2 x i64> %41, <2 x i64>* %42, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to <8 x i16>*
  %7 = load <8 x i16>, <8 x i16>* %6, align 1
  %8 = shufflevector <8 x i16> %7, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %9 = shufflevector <8 x i16> %7, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %10 = bitcast <8 x i16> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> zeroinitializer
  %16 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %15, <2 x i64>* %16, align 1
  %17 = getelementptr inbounds i8, i8* %0, i64 %1
  %18 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %19 = bitcast i8* %17 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %19, align 1
  %20 = getelementptr inbounds i8, i8* %17, i64 %1
  %21 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> zeroinitializer
  %22 = bitcast i8* %20 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %20, i64 %1
  %24 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %25 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %24, <2 x i64>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %0, i64 %5
  %27 = bitcast <8 x i16> %9 to <4 x i32>
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %29 = bitcast <4 x i32> %28 to <2 x i64>
  %30 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %31 = bitcast <4 x i32> %30 to <2 x i64>
  %32 = shufflevector <2 x i64> %29, <2 x i64> undef, <2 x i32> zeroinitializer
  %33 = bitcast i8* %26 to <2 x i64>*
  store <2 x i64> %32, <2 x i64>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %26, i64 %1
  %35 = shufflevector <2 x i64> %29, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %36 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %35, <2 x i64>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %34, i64 %1
  %38 = shufflevector <2 x i64> %31, <2 x i64> undef, <2 x i32> zeroinitializer
  %39 = bitcast i8* %37 to <2 x i64>*
  store <2 x i64> %38, <2 x i64>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %37, i64 %1
  %41 = shufflevector <2 x i64> %31, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %42 = bitcast i8* %40 to <2 x i64>*
  store <2 x i64> %41, <2 x i64>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %26, i64 %5
  %44 = getelementptr inbounds i8, i8* %3, i64 16
  %45 = bitcast i8* %44 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 1
  %47 = shufflevector <8 x i16> %46, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %48 = shufflevector <8 x i16> %46, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %49 = bitcast <8 x i16> %47 to <4 x i32>
  %50 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %51 = bitcast <4 x i32> %50 to <2 x i64>
  %52 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %53 = bitcast <4 x i32> %52 to <2 x i64>
  %54 = shufflevector <2 x i64> %51, <2 x i64> undef, <2 x i32> zeroinitializer
  %55 = bitcast i8* %43 to <2 x i64>*
  store <2 x i64> %54, <2 x i64>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %43, i64 %1
  %57 = shufflevector <2 x i64> %51, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %58 = bitcast i8* %56 to <2 x i64>*
  store <2 x i64> %57, <2 x i64>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %56, i64 %1
  %60 = shufflevector <2 x i64> %53, <2 x i64> undef, <2 x i32> zeroinitializer
  %61 = bitcast i8* %59 to <2 x i64>*
  store <2 x i64> %60, <2 x i64>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %59, i64 %1
  %63 = shufflevector <2 x i64> %53, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %64 = bitcast i8* %62 to <2 x i64>*
  store <2 x i64> %63, <2 x i64>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %43, i64 %5
  %66 = bitcast <8 x i16> %48 to <4 x i32>
  %67 = shufflevector <4 x i32> %66, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %68 = bitcast <4 x i32> %67 to <2 x i64>
  %69 = shufflevector <4 x i32> %66, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %70 = bitcast <4 x i32> %69 to <2 x i64>
  %71 = shufflevector <2 x i64> %68, <2 x i64> undef, <2 x i32> zeroinitializer
  %72 = bitcast i8* %65 to <2 x i64>*
  store <2 x i64> %71, <2 x i64>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %65, i64 %1
  %74 = shufflevector <2 x i64> %68, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %75 = bitcast i8* %73 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %73, i64 %1
  %77 = shufflevector <2 x i64> %70, <2 x i64> undef, <2 x i32> zeroinitializer
  %78 = bitcast i8* %76 to <2 x i64>*
  store <2 x i64> %77, <2 x i64>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %76, i64 %1
  %80 = shufflevector <2 x i64> %70, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %81 = bitcast i8* %79 to <2 x i64>*
  store <2 x i64> %80, <2 x i64>* %81, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_17WriteDuplicate8x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to <8 x i16>*
  %7 = load <8 x i16>, <8 x i16>* %6, align 1
  %8 = shufflevector <8 x i16> %7, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %9 = shufflevector <8 x i16> %7, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %10 = bitcast <8 x i16> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> zeroinitializer
  %16 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %15, <2 x i64>* %16, align 1
  %17 = getelementptr inbounds i8, i8* %0, i64 %1
  %18 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %19 = bitcast i8* %17 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %19, align 1
  %20 = getelementptr inbounds i8, i8* %17, i64 %1
  %21 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> zeroinitializer
  %22 = bitcast i8* %20 to <2 x i64>*
  store <2 x i64> %21, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %20, i64 %1
  %24 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %25 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %24, <2 x i64>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %0, i64 %5
  %27 = bitcast <8 x i16> %9 to <4 x i32>
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %29 = bitcast <4 x i32> %28 to <2 x i64>
  %30 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %31 = bitcast <4 x i32> %30 to <2 x i64>
  %32 = shufflevector <2 x i64> %29, <2 x i64> undef, <2 x i32> zeroinitializer
  %33 = bitcast i8* %26 to <2 x i64>*
  store <2 x i64> %32, <2 x i64>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %26, i64 %1
  %35 = shufflevector <2 x i64> %29, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %36 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %35, <2 x i64>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %34, i64 %1
  %38 = shufflevector <2 x i64> %31, <2 x i64> undef, <2 x i32> zeroinitializer
  %39 = bitcast i8* %37 to <2 x i64>*
  store <2 x i64> %38, <2 x i64>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %37, i64 %1
  %41 = shufflevector <2 x i64> %31, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %42 = bitcast i8* %40 to <2 x i64>*
  store <2 x i64> %41, <2 x i64>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %26, i64 %5
  %44 = getelementptr inbounds i8, i8* %3, i64 16
  %45 = bitcast i8* %44 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 1
  %47 = shufflevector <8 x i16> %46, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %48 = shufflevector <8 x i16> %46, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %49 = bitcast <8 x i16> %47 to <4 x i32>
  %50 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %51 = bitcast <4 x i32> %50 to <2 x i64>
  %52 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %53 = bitcast <4 x i32> %52 to <2 x i64>
  %54 = shufflevector <2 x i64> %51, <2 x i64> undef, <2 x i32> zeroinitializer
  %55 = bitcast i8* %43 to <2 x i64>*
  store <2 x i64> %54, <2 x i64>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %43, i64 %1
  %57 = shufflevector <2 x i64> %51, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %58 = bitcast i8* %56 to <2 x i64>*
  store <2 x i64> %57, <2 x i64>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %56, i64 %1
  %60 = shufflevector <2 x i64> %53, <2 x i64> undef, <2 x i32> zeroinitializer
  %61 = bitcast i8* %59 to <2 x i64>*
  store <2 x i64> %60, <2 x i64>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %59, i64 %1
  %63 = shufflevector <2 x i64> %53, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %64 = bitcast i8* %62 to <2 x i64>*
  store <2 x i64> %63, <2 x i64>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %43, i64 %5
  %66 = bitcast <8 x i16> %48 to <4 x i32>
  %67 = shufflevector <4 x i32> %66, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %68 = bitcast <4 x i32> %67 to <2 x i64>
  %69 = shufflevector <4 x i32> %66, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %70 = bitcast <4 x i32> %69 to <2 x i64>
  %71 = shufflevector <2 x i64> %68, <2 x i64> undef, <2 x i32> zeroinitializer
  %72 = bitcast i8* %65 to <2 x i64>*
  store <2 x i64> %71, <2 x i64>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %65, i64 %1
  %74 = shufflevector <2 x i64> %68, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %75 = bitcast i8* %73 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %73, i64 %1
  %77 = shufflevector <2 x i64> %70, <2 x i64> undef, <2 x i32> zeroinitializer
  %78 = bitcast i8* %76 to <2 x i64>*
  store <2 x i64> %77, <2 x i64>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %76, i64 %1
  %80 = shufflevector <2 x i64> %70, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %81 = bitcast i8* %79 to <2 x i64>*
  store <2 x i64> %80, <2 x i64>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %65, i64 %5
  %83 = getelementptr inbounds i8, i8* %3, i64 32
  %84 = bitcast i8* %83 to <8 x i16>*
  %85 = load <8 x i16>, <8 x i16>* %84, align 1
  %86 = shufflevector <8 x i16> %85, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %87 = shufflevector <8 x i16> %85, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %88 = bitcast <8 x i16> %86 to <4 x i32>
  %89 = shufflevector <4 x i32> %88, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %90 = bitcast <4 x i32> %89 to <2 x i64>
  %91 = shufflevector <4 x i32> %88, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %92 = bitcast <4 x i32> %91 to <2 x i64>
  %93 = shufflevector <2 x i64> %90, <2 x i64> undef, <2 x i32> zeroinitializer
  %94 = bitcast i8* %82 to <2 x i64>*
  store <2 x i64> %93, <2 x i64>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %82, i64 %1
  %96 = shufflevector <2 x i64> %90, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %97 = bitcast i8* %95 to <2 x i64>*
  store <2 x i64> %96, <2 x i64>* %97, align 1
  %98 = getelementptr inbounds i8, i8* %95, i64 %1
  %99 = shufflevector <2 x i64> %92, <2 x i64> undef, <2 x i32> zeroinitializer
  %100 = bitcast i8* %98 to <2 x i64>*
  store <2 x i64> %99, <2 x i64>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %98, i64 %1
  %102 = shufflevector <2 x i64> %92, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %103 = bitcast i8* %101 to <2 x i64>*
  store <2 x i64> %102, <2 x i64>* %103, align 1
  %104 = getelementptr inbounds i8, i8* %82, i64 %5
  %105 = bitcast <8 x i16> %87 to <4 x i32>
  %106 = shufflevector <4 x i32> %105, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %107 = bitcast <4 x i32> %106 to <2 x i64>
  %108 = shufflevector <4 x i32> %105, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %109 = bitcast <4 x i32> %108 to <2 x i64>
  %110 = shufflevector <2 x i64> %107, <2 x i64> undef, <2 x i32> zeroinitializer
  %111 = bitcast i8* %104 to <2 x i64>*
  store <2 x i64> %110, <2 x i64>* %111, align 1
  %112 = getelementptr inbounds i8, i8* %104, i64 %1
  %113 = shufflevector <2 x i64> %107, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %114 = bitcast i8* %112 to <2 x i64>*
  store <2 x i64> %113, <2 x i64>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %112, i64 %1
  %116 = shufflevector <2 x i64> %109, <2 x i64> undef, <2 x i32> zeroinitializer
  %117 = bitcast i8* %115 to <2 x i64>*
  store <2 x i64> %116, <2 x i64>* %117, align 1
  %118 = getelementptr inbounds i8, i8* %115, i64 %1
  %119 = shufflevector <2 x i64> %109, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %120 = bitcast i8* %118 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %104, i64 %5
  %122 = getelementptr inbounds i8, i8* %3, i64 48
  %123 = bitcast i8* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 1
  %125 = shufflevector <8 x i16> %124, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %126 = shufflevector <8 x i16> %124, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %127 = bitcast <8 x i16> %125 to <4 x i32>
  %128 = shufflevector <4 x i32> %127, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %129 = bitcast <4 x i32> %128 to <2 x i64>
  %130 = shufflevector <4 x i32> %127, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %131 = bitcast <4 x i32> %130 to <2 x i64>
  %132 = shufflevector <2 x i64> %129, <2 x i64> undef, <2 x i32> zeroinitializer
  %133 = bitcast i8* %121 to <2 x i64>*
  store <2 x i64> %132, <2 x i64>* %133, align 1
  %134 = getelementptr inbounds i8, i8* %121, i64 %1
  %135 = shufflevector <2 x i64> %129, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %136 = bitcast i8* %134 to <2 x i64>*
  store <2 x i64> %135, <2 x i64>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %134, i64 %1
  %138 = shufflevector <2 x i64> %131, <2 x i64> undef, <2 x i32> zeroinitializer
  %139 = bitcast i8* %137 to <2 x i64>*
  store <2 x i64> %138, <2 x i64>* %139, align 1
  %140 = getelementptr inbounds i8, i8* %137, i64 %1
  %141 = shufflevector <2 x i64> %131, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %142 = bitcast i8* %140 to <2 x i64>*
  store <2 x i64> %141, <2 x i64>* %142, align 1
  %143 = getelementptr inbounds i8, i8* %121, i64 %5
  %144 = bitcast <8 x i16> %126 to <4 x i32>
  %145 = shufflevector <4 x i32> %144, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %146 = bitcast <4 x i32> %145 to <2 x i64>
  %147 = shufflevector <4 x i32> %144, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %148 = bitcast <4 x i32> %147 to <2 x i64>
  %149 = shufflevector <2 x i64> %146, <2 x i64> undef, <2 x i32> zeroinitializer
  %150 = bitcast i8* %143 to <2 x i64>*
  store <2 x i64> %149, <2 x i64>* %150, align 1
  %151 = getelementptr inbounds i8, i8* %143, i64 %1
  %152 = shufflevector <2 x i64> %146, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %153 = bitcast i8* %151 to <2 x i64>*
  store <2 x i64> %152, <2 x i64>* %153, align 1
  %154 = getelementptr inbounds i8, i8* %151, i64 %1
  %155 = shufflevector <2 x i64> %148, <2 x i64> undef, <2 x i32> zeroinitializer
  %156 = bitcast i8* %154 to <2 x i64>*
  store <2 x i64> %155, <2 x i64>* %156, align 1
  %157 = getelementptr inbounds i8, i8* %154, i64 %1
  %158 = shufflevector <2 x i64> %148, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %159 = bitcast i8* %157 to <2 x i64>*
  store <2 x i64> %158, <2 x i64>* %159, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore4_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = bitcast i8* %3 to i64*
  %6 = load i64, i64* %5, align 1
  %7 = insertelement <2 x i64> undef, i64 %6, i32 0
  %8 = bitcast <2 x i64> %7 to <8 x i16>
  %9 = shufflevector <8 x i16> %8, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %10 = bitcast <8 x i16> %9 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> zeroinitializer
  %16 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %15, <2 x i64>* %16, align 1
  %17 = getelementptr inbounds i8, i8* %0, i64 16
  %18 = bitcast i8* %17 to <2 x i64>*
  store <2 x i64> %15, <2 x i64>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %21 = bitcast i8* %19 to <2 x i64>*
  store <2 x i64> %20, <2 x i64>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %19, i64 16
  %23 = bitcast i8* %22 to <2 x i64>*
  store <2 x i64> %20, <2 x i64>* %23, align 1
  %24 = getelementptr inbounds i8, i8* %19, i64 %1
  %25 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> zeroinitializer
  %26 = bitcast i8* %24 to <2 x i64>*
  store <2 x i64> %25, <2 x i64>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %24, i64 16
  %28 = bitcast i8* %27 to <2 x i64>*
  store <2 x i64> %25, <2 x i64>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %24, i64 %1
  %30 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %31 = bitcast i8* %29 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %29, i64 16
  %33 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %33, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = bitcast i8* %3 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 1
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %8 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %9 = bitcast <8 x i16> %7 to <4 x i32>
  %10 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %11 = bitcast <4 x i32> %10 to <2 x i64>
  %12 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %13 = bitcast <4 x i32> %12 to <2 x i64>
  %14 = shufflevector <2 x i64> %11, <2 x i64> undef, <2 x i32> zeroinitializer
  %15 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %14, <2 x i64>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 16
  %17 = bitcast i8* %16 to <2 x i64>*
  store <2 x i64> %14, <2 x i64>* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 %1
  %19 = shufflevector <2 x i64> %11, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %20 = bitcast i8* %18 to <2 x i64>*
  store <2 x i64> %19, <2 x i64>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %18, i64 16
  %22 = bitcast i8* %21 to <2 x i64>*
  store <2 x i64> %19, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %18, i64 %1
  %24 = shufflevector <2 x i64> %13, <2 x i64> undef, <2 x i32> zeroinitializer
  %25 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %24, <2 x i64>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %23, i64 16
  %27 = bitcast i8* %26 to <2 x i64>*
  store <2 x i64> %24, <2 x i64>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %23, i64 %1
  %29 = shufflevector <2 x i64> %13, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %30 = bitcast i8* %28 to <2 x i64>*
  store <2 x i64> %29, <2 x i64>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %28, i64 16
  %32 = bitcast i8* %31 to <2 x i64>*
  store <2 x i64> %29, <2 x i64>* %32, align 1
  %33 = shl i64 %1, 2
  %34 = getelementptr inbounds i8, i8* %0, i64 %33
  %35 = bitcast <8 x i16> %8 to <4 x i32>
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %37 = bitcast <4 x i32> %36 to <2 x i64>
  %38 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %39 = bitcast <4 x i32> %38 to <2 x i64>
  %40 = shufflevector <2 x i64> %37, <2 x i64> undef, <2 x i32> zeroinitializer
  %41 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %40, <2 x i64>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %34, i64 16
  %43 = bitcast i8* %42 to <2 x i64>*
  store <2 x i64> %40, <2 x i64>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %34, i64 %1
  %45 = shufflevector <2 x i64> %37, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %46 = bitcast i8* %44 to <2 x i64>*
  store <2 x i64> %45, <2 x i64>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %44, i64 16
  %48 = bitcast i8* %47 to <2 x i64>*
  store <2 x i64> %45, <2 x i64>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %44, i64 %1
  %50 = shufflevector <2 x i64> %39, <2 x i64> undef, <2 x i32> zeroinitializer
  %51 = bitcast i8* %49 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %49, i64 16
  %53 = bitcast i8* %52 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %49, i64 %1
  %55 = shufflevector <2 x i64> %39, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %56 = bitcast i8* %54 to <2 x i64>*
  store <2 x i64> %55, <2 x i64>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %54, i64 16
  %58 = bitcast i8* %57 to <2 x i64>*
  store <2 x i64> %55, <2 x i64>* %58, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to <8 x i16>*
  %7 = load <8 x i16>, <8 x i16>* %6, align 1
  %8 = shufflevector <8 x i16> %7, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %9 = shufflevector <8 x i16> %7, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %10 = bitcast <8 x i16> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> zeroinitializer
  %16 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %15, <2 x i64>* %16, align 1
  %17 = getelementptr inbounds i8, i8* %0, i64 16
  %18 = bitcast i8* %17 to <2 x i64>*
  store <2 x i64> %15, <2 x i64>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %21 = bitcast i8* %19 to <2 x i64>*
  store <2 x i64> %20, <2 x i64>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %19, i64 16
  %23 = bitcast i8* %22 to <2 x i64>*
  store <2 x i64> %20, <2 x i64>* %23, align 1
  %24 = getelementptr inbounds i8, i8* %19, i64 %1
  %25 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> zeroinitializer
  %26 = bitcast i8* %24 to <2 x i64>*
  store <2 x i64> %25, <2 x i64>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %24, i64 16
  %28 = bitcast i8* %27 to <2 x i64>*
  store <2 x i64> %25, <2 x i64>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %24, i64 %1
  %30 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %31 = bitcast i8* %29 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %29, i64 16
  %33 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %0, i64 %5
  %35 = bitcast <8 x i16> %9 to <4 x i32>
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %37 = bitcast <4 x i32> %36 to <2 x i64>
  %38 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %39 = bitcast <4 x i32> %38 to <2 x i64>
  %40 = shufflevector <2 x i64> %37, <2 x i64> undef, <2 x i32> zeroinitializer
  %41 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %40, <2 x i64>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %34, i64 16
  %43 = bitcast i8* %42 to <2 x i64>*
  store <2 x i64> %40, <2 x i64>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %34, i64 %1
  %45 = shufflevector <2 x i64> %37, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %46 = bitcast i8* %44 to <2 x i64>*
  store <2 x i64> %45, <2 x i64>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %44, i64 16
  %48 = bitcast i8* %47 to <2 x i64>*
  store <2 x i64> %45, <2 x i64>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %44, i64 %1
  %50 = shufflevector <2 x i64> %39, <2 x i64> undef, <2 x i32> zeroinitializer
  %51 = bitcast i8* %49 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %49, i64 16
  %53 = bitcast i8* %52 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %49, i64 %1
  %55 = shufflevector <2 x i64> %39, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %56 = bitcast i8* %54 to <2 x i64>*
  store <2 x i64> %55, <2 x i64>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %54, i64 16
  %58 = bitcast i8* %57 to <2 x i64>*
  store <2 x i64> %55, <2 x i64>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %34, i64 %5
  %60 = getelementptr inbounds i8, i8* %3, i64 16
  %61 = bitcast i8* %60 to <8 x i16>*
  %62 = load <8 x i16>, <8 x i16>* %61, align 1
  %63 = shufflevector <8 x i16> %62, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %64 = shufflevector <8 x i16> %62, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %65 = bitcast <8 x i16> %63 to <4 x i32>
  %66 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %67 = bitcast <4 x i32> %66 to <2 x i64>
  %68 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %69 = bitcast <4 x i32> %68 to <2 x i64>
  %70 = shufflevector <2 x i64> %67, <2 x i64> undef, <2 x i32> zeroinitializer
  %71 = bitcast i8* %59 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %71, align 1
  %72 = getelementptr inbounds i8, i8* %59, i64 16
  %73 = bitcast i8* %72 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %59, i64 %1
  %75 = shufflevector <2 x i64> %67, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %76 = bitcast i8* %74 to <2 x i64>*
  store <2 x i64> %75, <2 x i64>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %74, i64 16
  %78 = bitcast i8* %77 to <2 x i64>*
  store <2 x i64> %75, <2 x i64>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %74, i64 %1
  %80 = shufflevector <2 x i64> %69, <2 x i64> undef, <2 x i32> zeroinitializer
  %81 = bitcast i8* %79 to <2 x i64>*
  store <2 x i64> %80, <2 x i64>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %79, i64 16
  %83 = bitcast i8* %82 to <2 x i64>*
  store <2 x i64> %80, <2 x i64>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %79, i64 %1
  %85 = shufflevector <2 x i64> %69, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %86 = bitcast i8* %84 to <2 x i64>*
  store <2 x i64> %85, <2 x i64>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %84, i64 16
  %88 = bitcast i8* %87 to <2 x i64>*
  store <2 x i64> %85, <2 x i64>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %59, i64 %5
  %90 = bitcast <8 x i16> %64 to <4 x i32>
  %91 = shufflevector <4 x i32> %90, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %92 = bitcast <4 x i32> %91 to <2 x i64>
  %93 = shufflevector <4 x i32> %90, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %94 = bitcast <4 x i32> %93 to <2 x i64>
  %95 = shufflevector <2 x i64> %92, <2 x i64> undef, <2 x i32> zeroinitializer
  %96 = bitcast i8* %89 to <2 x i64>*
  store <2 x i64> %95, <2 x i64>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %89, i64 16
  %98 = bitcast i8* %97 to <2 x i64>*
  store <2 x i64> %95, <2 x i64>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %89, i64 %1
  %100 = shufflevector <2 x i64> %92, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %101 = bitcast i8* %99 to <2 x i64>*
  store <2 x i64> %100, <2 x i64>* %101, align 1
  %102 = getelementptr inbounds i8, i8* %99, i64 16
  %103 = bitcast i8* %102 to <2 x i64>*
  store <2 x i64> %100, <2 x i64>* %103, align 1
  %104 = getelementptr inbounds i8, i8* %99, i64 %1
  %105 = shufflevector <2 x i64> %94, <2 x i64> undef, <2 x i32> zeroinitializer
  %106 = bitcast i8* %104 to <2 x i64>*
  store <2 x i64> %105, <2 x i64>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %104, i64 16
  %108 = bitcast i8* %107 to <2 x i64>*
  store <2 x i64> %105, <2 x i64>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %104, i64 %1
  %110 = shufflevector <2 x i64> %94, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %111 = bitcast i8* %109 to <2 x i64>*
  store <2 x i64> %110, <2 x i64>* %111, align 1
  %112 = getelementptr inbounds i8, i8* %109, i64 16
  %113 = bitcast i8* %112 to <2 x i64>*
  store <2 x i64> %110, <2 x i64>* %113, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to <8 x i16>*
  %7 = load <8 x i16>, <8 x i16>* %6, align 1
  %8 = shufflevector <8 x i16> %7, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %9 = shufflevector <8 x i16> %7, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %10 = bitcast <8 x i16> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> zeroinitializer
  %16 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %15, <2 x i64>* %16, align 1
  %17 = getelementptr inbounds i8, i8* %0, i64 16
  %18 = bitcast i8* %17 to <2 x i64>*
  store <2 x i64> %15, <2 x i64>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 %1
  %20 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %21 = bitcast i8* %19 to <2 x i64>*
  store <2 x i64> %20, <2 x i64>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %19, i64 16
  %23 = bitcast i8* %22 to <2 x i64>*
  store <2 x i64> %20, <2 x i64>* %23, align 1
  %24 = getelementptr inbounds i8, i8* %19, i64 %1
  %25 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> zeroinitializer
  %26 = bitcast i8* %24 to <2 x i64>*
  store <2 x i64> %25, <2 x i64>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %24, i64 16
  %28 = bitcast i8* %27 to <2 x i64>*
  store <2 x i64> %25, <2 x i64>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %24, i64 %1
  %30 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %31 = bitcast i8* %29 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %29, i64 16
  %33 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %30, <2 x i64>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %0, i64 %5
  %35 = bitcast <8 x i16> %9 to <4 x i32>
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %37 = bitcast <4 x i32> %36 to <2 x i64>
  %38 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %39 = bitcast <4 x i32> %38 to <2 x i64>
  %40 = shufflevector <2 x i64> %37, <2 x i64> undef, <2 x i32> zeroinitializer
  %41 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %40, <2 x i64>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %34, i64 16
  %43 = bitcast i8* %42 to <2 x i64>*
  store <2 x i64> %40, <2 x i64>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %34, i64 %1
  %45 = shufflevector <2 x i64> %37, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %46 = bitcast i8* %44 to <2 x i64>*
  store <2 x i64> %45, <2 x i64>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %44, i64 16
  %48 = bitcast i8* %47 to <2 x i64>*
  store <2 x i64> %45, <2 x i64>* %48, align 1
  %49 = getelementptr inbounds i8, i8* %44, i64 %1
  %50 = shufflevector <2 x i64> %39, <2 x i64> undef, <2 x i32> zeroinitializer
  %51 = bitcast i8* %49 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %49, i64 16
  %53 = bitcast i8* %52 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %49, i64 %1
  %55 = shufflevector <2 x i64> %39, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %56 = bitcast i8* %54 to <2 x i64>*
  store <2 x i64> %55, <2 x i64>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %54, i64 16
  %58 = bitcast i8* %57 to <2 x i64>*
  store <2 x i64> %55, <2 x i64>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %34, i64 %5
  %60 = getelementptr inbounds i8, i8* %3, i64 16
  %61 = bitcast i8* %60 to <8 x i16>*
  %62 = load <8 x i16>, <8 x i16>* %61, align 1
  %63 = shufflevector <8 x i16> %62, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %64 = shufflevector <8 x i16> %62, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %65 = bitcast <8 x i16> %63 to <4 x i32>
  %66 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %67 = bitcast <4 x i32> %66 to <2 x i64>
  %68 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %69 = bitcast <4 x i32> %68 to <2 x i64>
  %70 = shufflevector <2 x i64> %67, <2 x i64> undef, <2 x i32> zeroinitializer
  %71 = bitcast i8* %59 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %71, align 1
  %72 = getelementptr inbounds i8, i8* %59, i64 16
  %73 = bitcast i8* %72 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %59, i64 %1
  %75 = shufflevector <2 x i64> %67, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %76 = bitcast i8* %74 to <2 x i64>*
  store <2 x i64> %75, <2 x i64>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %74, i64 16
  %78 = bitcast i8* %77 to <2 x i64>*
  store <2 x i64> %75, <2 x i64>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %74, i64 %1
  %80 = shufflevector <2 x i64> %69, <2 x i64> undef, <2 x i32> zeroinitializer
  %81 = bitcast i8* %79 to <2 x i64>*
  store <2 x i64> %80, <2 x i64>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %79, i64 16
  %83 = bitcast i8* %82 to <2 x i64>*
  store <2 x i64> %80, <2 x i64>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %79, i64 %1
  %85 = shufflevector <2 x i64> %69, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %86 = bitcast i8* %84 to <2 x i64>*
  store <2 x i64> %85, <2 x i64>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %84, i64 16
  %88 = bitcast i8* %87 to <2 x i64>*
  store <2 x i64> %85, <2 x i64>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %59, i64 %5
  %90 = bitcast <8 x i16> %64 to <4 x i32>
  %91 = shufflevector <4 x i32> %90, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %92 = bitcast <4 x i32> %91 to <2 x i64>
  %93 = shufflevector <4 x i32> %90, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %94 = bitcast <4 x i32> %93 to <2 x i64>
  %95 = shufflevector <2 x i64> %92, <2 x i64> undef, <2 x i32> zeroinitializer
  %96 = bitcast i8* %89 to <2 x i64>*
  store <2 x i64> %95, <2 x i64>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %89, i64 16
  %98 = bitcast i8* %97 to <2 x i64>*
  store <2 x i64> %95, <2 x i64>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %89, i64 %1
  %100 = shufflevector <2 x i64> %92, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %101 = bitcast i8* %99 to <2 x i64>*
  store <2 x i64> %100, <2 x i64>* %101, align 1
  %102 = getelementptr inbounds i8, i8* %99, i64 16
  %103 = bitcast i8* %102 to <2 x i64>*
  store <2 x i64> %100, <2 x i64>* %103, align 1
  %104 = getelementptr inbounds i8, i8* %99, i64 %1
  %105 = shufflevector <2 x i64> %94, <2 x i64> undef, <2 x i32> zeroinitializer
  %106 = bitcast i8* %104 to <2 x i64>*
  store <2 x i64> %105, <2 x i64>* %106, align 1
  %107 = getelementptr inbounds i8, i8* %104, i64 16
  %108 = bitcast i8* %107 to <2 x i64>*
  store <2 x i64> %105, <2 x i64>* %108, align 1
  %109 = getelementptr inbounds i8, i8* %104, i64 %1
  %110 = shufflevector <2 x i64> %94, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %111 = bitcast i8* %109 to <2 x i64>*
  store <2 x i64> %110, <2 x i64>* %111, align 1
  %112 = getelementptr inbounds i8, i8* %109, i64 16
  %113 = bitcast i8* %112 to <2 x i64>*
  store <2 x i64> %110, <2 x i64>* %113, align 1
  %114 = getelementptr inbounds i8, i8* %89, i64 %5
  %115 = getelementptr inbounds i8, i8* %3, i64 32
  %116 = bitcast i8* %115 to <8 x i16>*
  %117 = load <8 x i16>, <8 x i16>* %116, align 1
  %118 = shufflevector <8 x i16> %117, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %119 = shufflevector <8 x i16> %117, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = shufflevector <4 x i32> %120, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %122 = bitcast <4 x i32> %121 to <2 x i64>
  %123 = shufflevector <4 x i32> %120, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %124 = bitcast <4 x i32> %123 to <2 x i64>
  %125 = shufflevector <2 x i64> %122, <2 x i64> undef, <2 x i32> zeroinitializer
  %126 = bitcast i8* %114 to <2 x i64>*
  store <2 x i64> %125, <2 x i64>* %126, align 1
  %127 = getelementptr inbounds i8, i8* %114, i64 16
  %128 = bitcast i8* %127 to <2 x i64>*
  store <2 x i64> %125, <2 x i64>* %128, align 1
  %129 = getelementptr inbounds i8, i8* %114, i64 %1
  %130 = shufflevector <2 x i64> %122, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %131 = bitcast i8* %129 to <2 x i64>*
  store <2 x i64> %130, <2 x i64>* %131, align 1
  %132 = getelementptr inbounds i8, i8* %129, i64 16
  %133 = bitcast i8* %132 to <2 x i64>*
  store <2 x i64> %130, <2 x i64>* %133, align 1
  %134 = getelementptr inbounds i8, i8* %129, i64 %1
  %135 = shufflevector <2 x i64> %124, <2 x i64> undef, <2 x i32> zeroinitializer
  %136 = bitcast i8* %134 to <2 x i64>*
  store <2 x i64> %135, <2 x i64>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %134, i64 16
  %138 = bitcast i8* %137 to <2 x i64>*
  store <2 x i64> %135, <2 x i64>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %134, i64 %1
  %140 = shufflevector <2 x i64> %124, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %141 = bitcast i8* %139 to <2 x i64>*
  store <2 x i64> %140, <2 x i64>* %141, align 1
  %142 = getelementptr inbounds i8, i8* %139, i64 16
  %143 = bitcast i8* %142 to <2 x i64>*
  store <2 x i64> %140, <2 x i64>* %143, align 1
  %144 = getelementptr inbounds i8, i8* %114, i64 %5
  %145 = bitcast <8 x i16> %119 to <4 x i32>
  %146 = shufflevector <4 x i32> %145, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %147 = bitcast <4 x i32> %146 to <2 x i64>
  %148 = shufflevector <4 x i32> %145, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %149 = bitcast <4 x i32> %148 to <2 x i64>
  %150 = shufflevector <2 x i64> %147, <2 x i64> undef, <2 x i32> zeroinitializer
  %151 = bitcast i8* %144 to <2 x i64>*
  store <2 x i64> %150, <2 x i64>* %151, align 1
  %152 = getelementptr inbounds i8, i8* %144, i64 16
  %153 = bitcast i8* %152 to <2 x i64>*
  store <2 x i64> %150, <2 x i64>* %153, align 1
  %154 = getelementptr inbounds i8, i8* %144, i64 %1
  %155 = shufflevector <2 x i64> %147, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %156 = bitcast i8* %154 to <2 x i64>*
  store <2 x i64> %155, <2 x i64>* %156, align 1
  %157 = getelementptr inbounds i8, i8* %154, i64 16
  %158 = bitcast i8* %157 to <2 x i64>*
  store <2 x i64> %155, <2 x i64>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %154, i64 %1
  %160 = shufflevector <2 x i64> %149, <2 x i64> undef, <2 x i32> zeroinitializer
  %161 = bitcast i8* %159 to <2 x i64>*
  store <2 x i64> %160, <2 x i64>* %161, align 1
  %162 = getelementptr inbounds i8, i8* %159, i64 16
  %163 = bitcast i8* %162 to <2 x i64>*
  store <2 x i64> %160, <2 x i64>* %163, align 1
  %164 = getelementptr inbounds i8, i8* %159, i64 %1
  %165 = shufflevector <2 x i64> %149, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %166 = bitcast i8* %164 to <2 x i64>*
  store <2 x i64> %165, <2 x i64>* %166, align 1
  %167 = getelementptr inbounds i8, i8* %164, i64 16
  %168 = bitcast i8* %167 to <2 x i64>*
  store <2 x i64> %165, <2 x i64>* %168, align 1
  %169 = getelementptr inbounds i8, i8* %144, i64 %5
  %170 = getelementptr inbounds i8, i8* %3, i64 48
  %171 = bitcast i8* %170 to <8 x i16>*
  %172 = load <8 x i16>, <8 x i16>* %171, align 1
  %173 = shufflevector <8 x i16> %172, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %174 = shufflevector <8 x i16> %172, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %175 = bitcast <8 x i16> %173 to <4 x i32>
  %176 = shufflevector <4 x i32> %175, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %177 = bitcast <4 x i32> %176 to <2 x i64>
  %178 = shufflevector <4 x i32> %175, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %179 = bitcast <4 x i32> %178 to <2 x i64>
  %180 = shufflevector <2 x i64> %177, <2 x i64> undef, <2 x i32> zeroinitializer
  %181 = bitcast i8* %169 to <2 x i64>*
  store <2 x i64> %180, <2 x i64>* %181, align 1
  %182 = getelementptr inbounds i8, i8* %169, i64 16
  %183 = bitcast i8* %182 to <2 x i64>*
  store <2 x i64> %180, <2 x i64>* %183, align 1
  %184 = getelementptr inbounds i8, i8* %169, i64 %1
  %185 = shufflevector <2 x i64> %177, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %186 = bitcast i8* %184 to <2 x i64>*
  store <2 x i64> %185, <2 x i64>* %186, align 1
  %187 = getelementptr inbounds i8, i8* %184, i64 16
  %188 = bitcast i8* %187 to <2 x i64>*
  store <2 x i64> %185, <2 x i64>* %188, align 1
  %189 = getelementptr inbounds i8, i8* %184, i64 %1
  %190 = shufflevector <2 x i64> %179, <2 x i64> undef, <2 x i32> zeroinitializer
  %191 = bitcast i8* %189 to <2 x i64>*
  store <2 x i64> %190, <2 x i64>* %191, align 1
  %192 = getelementptr inbounds i8, i8* %189, i64 16
  %193 = bitcast i8* %192 to <2 x i64>*
  store <2 x i64> %190, <2 x i64>* %193, align 1
  %194 = getelementptr inbounds i8, i8* %189, i64 %1
  %195 = shufflevector <2 x i64> %179, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %196 = bitcast i8* %194 to <2 x i64>*
  store <2 x i64> %195, <2 x i64>* %196, align 1
  %197 = getelementptr inbounds i8, i8* %194, i64 16
  %198 = bitcast i8* %197 to <2 x i64>*
  store <2 x i64> %195, <2 x i64>* %198, align 1
  %199 = getelementptr inbounds i8, i8* %169, i64 %5
  %200 = bitcast <8 x i16> %174 to <4 x i32>
  %201 = shufflevector <4 x i32> %200, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %202 = bitcast <4 x i32> %201 to <2 x i64>
  %203 = shufflevector <4 x i32> %200, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %204 = bitcast <4 x i32> %203 to <2 x i64>
  %205 = shufflevector <2 x i64> %202, <2 x i64> undef, <2 x i32> zeroinitializer
  %206 = bitcast i8* %199 to <2 x i64>*
  store <2 x i64> %205, <2 x i64>* %206, align 1
  %207 = getelementptr inbounds i8, i8* %199, i64 16
  %208 = bitcast i8* %207 to <2 x i64>*
  store <2 x i64> %205, <2 x i64>* %208, align 1
  %209 = getelementptr inbounds i8, i8* %199, i64 %1
  %210 = shufflevector <2 x i64> %202, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %211 = bitcast i8* %209 to <2 x i64>*
  store <2 x i64> %210, <2 x i64>* %211, align 1
  %212 = getelementptr inbounds i8, i8* %209, i64 16
  %213 = bitcast i8* %212 to <2 x i64>*
  store <2 x i64> %210, <2 x i64>* %213, align 1
  %214 = getelementptr inbounds i8, i8* %209, i64 %1
  %215 = shufflevector <2 x i64> %204, <2 x i64> undef, <2 x i32> zeroinitializer
  %216 = bitcast i8* %214 to <2 x i64>*
  store <2 x i64> %215, <2 x i64>* %216, align 1
  %217 = getelementptr inbounds i8, i8* %214, i64 16
  %218 = bitcast i8* %217 to <2 x i64>*
  store <2 x i64> %215, <2 x i64>* %218, align 1
  %219 = getelementptr inbounds i8, i8* %214, i64 %1
  %220 = shufflevector <2 x i64> %204, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %221 = bitcast i8* %219 to <2 x i64>*
  store <2 x i64> %220, <2 x i64>* %221, align 1
  %222 = getelementptr inbounds i8, i8* %219, i64 16
  %223 = bitcast i8* %222 to <2 x i64>*
  store <2 x i64> %220, <2 x i64>* %223, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore64_SSE4_1IXadL_ZNS4_18WriteDuplicate16x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %64, %6 ]
  %8 = phi i8* [ %0, %4 ], [ %63, %6 ]
  %9 = getelementptr inbounds i8, i8* %3, i64 %7
  %10 = bitcast i8* %9 to <8 x i16>*
  %11 = load <8 x i16>, <8 x i16>* %10, align 1
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %13 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %14 = bitcast <8 x i16> %12 to <4 x i32>
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %18 = bitcast <4 x i32> %17 to <2 x i64>
  %19 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> zeroinitializer
  %20 = bitcast i8* %8 to <2 x i64>*
  store <2 x i64> %19, <2 x i64>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %8, i64 16
  %22 = bitcast i8* %21 to <2 x i64>*
  store <2 x i64> %19, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %8, i64 %1
  %24 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %25 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %24, <2 x i64>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %23, i64 16
  %27 = bitcast i8* %26 to <2 x i64>*
  store <2 x i64> %24, <2 x i64>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %23, i64 %1
  %29 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> zeroinitializer
  %30 = bitcast i8* %28 to <2 x i64>*
  store <2 x i64> %29, <2 x i64>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %28, i64 16
  %32 = bitcast i8* %31 to <2 x i64>*
  store <2 x i64> %29, <2 x i64>* %32, align 1
  %33 = getelementptr inbounds i8, i8* %28, i64 %1
  %34 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %35 = bitcast i8* %33 to <2 x i64>*
  store <2 x i64> %34, <2 x i64>* %35, align 1
  %36 = getelementptr inbounds i8, i8* %33, i64 16
  %37 = bitcast i8* %36 to <2 x i64>*
  store <2 x i64> %34, <2 x i64>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %8, i64 %5
  %39 = bitcast <8 x i16> %13 to <4 x i32>
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %41 = bitcast <4 x i32> %40 to <2 x i64>
  %42 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %43 = bitcast <4 x i32> %42 to <2 x i64>
  %44 = shufflevector <2 x i64> %41, <2 x i64> undef, <2 x i32> zeroinitializer
  %45 = bitcast i8* %38 to <2 x i64>*
  store <2 x i64> %44, <2 x i64>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %38, i64 16
  %47 = bitcast i8* %46 to <2 x i64>*
  store <2 x i64> %44, <2 x i64>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %38, i64 %1
  %49 = shufflevector <2 x i64> %41, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %50 = bitcast i8* %48 to <2 x i64>*
  store <2 x i64> %49, <2 x i64>* %50, align 1
  %51 = getelementptr inbounds i8, i8* %48, i64 16
  %52 = bitcast i8* %51 to <2 x i64>*
  store <2 x i64> %49, <2 x i64>* %52, align 1
  %53 = getelementptr inbounds i8, i8* %48, i64 %1
  %54 = shufflevector <2 x i64> %43, <2 x i64> undef, <2 x i32> zeroinitializer
  %55 = bitcast i8* %53 to <2 x i64>*
  store <2 x i64> %54, <2 x i64>* %55, align 1
  %56 = getelementptr inbounds i8, i8* %53, i64 16
  %57 = bitcast i8* %56 to <2 x i64>*
  store <2 x i64> %54, <2 x i64>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %53, i64 %1
  %59 = shufflevector <2 x i64> %43, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %60 = bitcast i8* %58 to <2 x i64>*
  store <2 x i64> %59, <2 x i64>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %58, i64 16
  %62 = bitcast i8* %61 to <2 x i64>*
  store <2 x i64> %59, <2 x i64>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %38, i64 %5
  %64 = add nuw nsw i64 %7, 16
  %65 = icmp ult i64 %64, 128
  br i1 %65, label %6, label %66

66:                                               ; preds = %6
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_116ColStore8_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = bitcast i8* %3 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 1
  %7 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %8 = shufflevector <8 x i16> %6, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %9 = bitcast <8 x i16> %7 to <4 x i32>
  %10 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %11 = bitcast <4 x i32> %10 to <2 x i64>
  %12 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %13 = bitcast <4 x i32> %12 to <2 x i64>
  %14 = shufflevector <2 x i64> %11, <2 x i64> undef, <2 x i32> zeroinitializer
  %15 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %14, <2 x i64>* %15, align 1
  %16 = getelementptr inbounds i8, i8* %0, i64 16
  %17 = bitcast i8* %16 to <2 x i64>*
  store <2 x i64> %14, <2 x i64>* %17, align 1
  %18 = getelementptr inbounds i8, i8* %0, i64 32
  %19 = bitcast i8* %18 to <2 x i64>*
  store <2 x i64> %14, <2 x i64>* %19, align 1
  %20 = getelementptr inbounds i8, i8* %0, i64 48
  %21 = bitcast i8* %20 to <2 x i64>*
  store <2 x i64> %14, <2 x i64>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %0, i64 %1
  %23 = shufflevector <2 x i64> %11, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %24 = bitcast i8* %22 to <2 x i64>*
  store <2 x i64> %23, <2 x i64>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %22, i64 16
  %26 = bitcast i8* %25 to <2 x i64>*
  store <2 x i64> %23, <2 x i64>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %22, i64 32
  %28 = bitcast i8* %27 to <2 x i64>*
  store <2 x i64> %23, <2 x i64>* %28, align 1
  %29 = getelementptr inbounds i8, i8* %22, i64 48
  %30 = bitcast i8* %29 to <2 x i64>*
  store <2 x i64> %23, <2 x i64>* %30, align 1
  %31 = getelementptr inbounds i8, i8* %22, i64 %1
  %32 = shufflevector <2 x i64> %13, <2 x i64> undef, <2 x i32> zeroinitializer
  %33 = bitcast i8* %31 to <2 x i64>*
  store <2 x i64> %32, <2 x i64>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %31, i64 16
  %35 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %32, <2 x i64>* %35, align 1
  %36 = getelementptr inbounds i8, i8* %31, i64 32
  %37 = bitcast i8* %36 to <2 x i64>*
  store <2 x i64> %32, <2 x i64>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %31, i64 48
  %39 = bitcast i8* %38 to <2 x i64>*
  store <2 x i64> %32, <2 x i64>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %31, i64 %1
  %41 = shufflevector <2 x i64> %13, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %42 = bitcast i8* %40 to <2 x i64>*
  store <2 x i64> %41, <2 x i64>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %40, i64 16
  %44 = bitcast i8* %43 to <2 x i64>*
  store <2 x i64> %41, <2 x i64>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %40, i64 32
  %46 = bitcast i8* %45 to <2 x i64>*
  store <2 x i64> %41, <2 x i64>* %46, align 1
  %47 = getelementptr inbounds i8, i8* %40, i64 48
  %48 = bitcast i8* %47 to <2 x i64>*
  store <2 x i64> %41, <2 x i64>* %48, align 1
  %49 = shl i64 %1, 2
  %50 = getelementptr inbounds i8, i8* %0, i64 %49
  %51 = bitcast <8 x i16> %8 to <4 x i32>
  %52 = shufflevector <4 x i32> %51, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %53 = bitcast <4 x i32> %52 to <2 x i64>
  %54 = shufflevector <4 x i32> %51, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %55 = bitcast <4 x i32> %54 to <2 x i64>
  %56 = shufflevector <2 x i64> %53, <2 x i64> undef, <2 x i32> zeroinitializer
  %57 = bitcast i8* %50 to <2 x i64>*
  store <2 x i64> %56, <2 x i64>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %50, i64 16
  %59 = bitcast i8* %58 to <2 x i64>*
  store <2 x i64> %56, <2 x i64>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %50, i64 32
  %61 = bitcast i8* %60 to <2 x i64>*
  store <2 x i64> %56, <2 x i64>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %50, i64 48
  %63 = bitcast i8* %62 to <2 x i64>*
  store <2 x i64> %56, <2 x i64>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %50, i64 %1
  %65 = shufflevector <2 x i64> %53, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %66 = bitcast i8* %64 to <2 x i64>*
  store <2 x i64> %65, <2 x i64>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %64, i64 16
  %68 = bitcast i8* %67 to <2 x i64>*
  store <2 x i64> %65, <2 x i64>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %64, i64 32
  %70 = bitcast i8* %69 to <2 x i64>*
  store <2 x i64> %65, <2 x i64>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %64, i64 48
  %72 = bitcast i8* %71 to <2 x i64>*
  store <2 x i64> %65, <2 x i64>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %64, i64 %1
  %74 = shufflevector <2 x i64> %55, <2 x i64> undef, <2 x i32> zeroinitializer
  %75 = bitcast i8* %73 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %73, i64 16
  %77 = bitcast i8* %76 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %73, i64 32
  %79 = bitcast i8* %78 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %73, i64 48
  %81 = bitcast i8* %80 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %73, i64 %1
  %83 = shufflevector <2 x i64> %55, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %84 = bitcast i8* %82 to <2 x i64>*
  store <2 x i64> %83, <2 x i64>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %82, i64 16
  %86 = bitcast i8* %85 to <2 x i64>*
  store <2 x i64> %83, <2 x i64>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %82, i64 32
  %88 = bitcast i8* %87 to <2 x i64>*
  store <2 x i64> %83, <2 x i64>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %82, i64 48
  %90 = bitcast i8* %89 to <2 x i64>*
  store <2 x i64> %83, <2 x i64>* %90, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  %6 = bitcast i8* %3 to <8 x i16>*
  %7 = load <8 x i16>, <8 x i16>* %6, align 1
  %8 = shufflevector <8 x i16> %7, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %9 = shufflevector <8 x i16> %7, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %10 = bitcast <8 x i16> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> zeroinitializer
  %16 = bitcast i8* %0 to <2 x i64>*
  store <2 x i64> %15, <2 x i64>* %16, align 1
  %17 = getelementptr inbounds i8, i8* %0, i64 16
  %18 = bitcast i8* %17 to <2 x i64>*
  store <2 x i64> %15, <2 x i64>* %18, align 1
  %19 = getelementptr inbounds i8, i8* %0, i64 32
  %20 = bitcast i8* %19 to <2 x i64>*
  store <2 x i64> %15, <2 x i64>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %0, i64 48
  %22 = bitcast i8* %21 to <2 x i64>*
  store <2 x i64> %15, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %0, i64 %1
  %24 = shufflevector <2 x i64> %12, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %25 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %24, <2 x i64>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %23, i64 16
  %27 = bitcast i8* %26 to <2 x i64>*
  store <2 x i64> %24, <2 x i64>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %23, i64 32
  %29 = bitcast i8* %28 to <2 x i64>*
  store <2 x i64> %24, <2 x i64>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %23, i64 48
  %31 = bitcast i8* %30 to <2 x i64>*
  store <2 x i64> %24, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %23, i64 %1
  %33 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> zeroinitializer
  %34 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %33, <2 x i64>* %34, align 1
  %35 = getelementptr inbounds i8, i8* %32, i64 16
  %36 = bitcast i8* %35 to <2 x i64>*
  store <2 x i64> %33, <2 x i64>* %36, align 1
  %37 = getelementptr inbounds i8, i8* %32, i64 32
  %38 = bitcast i8* %37 to <2 x i64>*
  store <2 x i64> %33, <2 x i64>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %32, i64 48
  %40 = bitcast i8* %39 to <2 x i64>*
  store <2 x i64> %33, <2 x i64>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %32, i64 %1
  %42 = shufflevector <2 x i64> %14, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %43 = bitcast i8* %41 to <2 x i64>*
  store <2 x i64> %42, <2 x i64>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %41, i64 16
  %45 = bitcast i8* %44 to <2 x i64>*
  store <2 x i64> %42, <2 x i64>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %41, i64 32
  %47 = bitcast i8* %46 to <2 x i64>*
  store <2 x i64> %42, <2 x i64>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %41, i64 48
  %49 = bitcast i8* %48 to <2 x i64>*
  store <2 x i64> %42, <2 x i64>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %0, i64 %5
  %51 = bitcast <8 x i16> %9 to <4 x i32>
  %52 = shufflevector <4 x i32> %51, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %53 = bitcast <4 x i32> %52 to <2 x i64>
  %54 = shufflevector <4 x i32> %51, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %55 = bitcast <4 x i32> %54 to <2 x i64>
  %56 = shufflevector <2 x i64> %53, <2 x i64> undef, <2 x i32> zeroinitializer
  %57 = bitcast i8* %50 to <2 x i64>*
  store <2 x i64> %56, <2 x i64>* %57, align 1
  %58 = getelementptr inbounds i8, i8* %50, i64 16
  %59 = bitcast i8* %58 to <2 x i64>*
  store <2 x i64> %56, <2 x i64>* %59, align 1
  %60 = getelementptr inbounds i8, i8* %50, i64 32
  %61 = bitcast i8* %60 to <2 x i64>*
  store <2 x i64> %56, <2 x i64>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %50, i64 48
  %63 = bitcast i8* %62 to <2 x i64>*
  store <2 x i64> %56, <2 x i64>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %50, i64 %1
  %65 = shufflevector <2 x i64> %53, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %66 = bitcast i8* %64 to <2 x i64>*
  store <2 x i64> %65, <2 x i64>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %64, i64 16
  %68 = bitcast i8* %67 to <2 x i64>*
  store <2 x i64> %65, <2 x i64>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %64, i64 32
  %70 = bitcast i8* %69 to <2 x i64>*
  store <2 x i64> %65, <2 x i64>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %64, i64 48
  %72 = bitcast i8* %71 to <2 x i64>*
  store <2 x i64> %65, <2 x i64>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %64, i64 %1
  %74 = shufflevector <2 x i64> %55, <2 x i64> undef, <2 x i32> zeroinitializer
  %75 = bitcast i8* %73 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %73, i64 16
  %77 = bitcast i8* %76 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %73, i64 32
  %79 = bitcast i8* %78 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %73, i64 48
  %81 = bitcast i8* %80 to <2 x i64>*
  store <2 x i64> %74, <2 x i64>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %73, i64 %1
  %83 = shufflevector <2 x i64> %55, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %84 = bitcast i8* %82 to <2 x i64>*
  store <2 x i64> %83, <2 x i64>* %84, align 1
  %85 = getelementptr inbounds i8, i8* %82, i64 16
  %86 = bitcast i8* %85 to <2 x i64>*
  store <2 x i64> %83, <2 x i64>* %86, align 1
  %87 = getelementptr inbounds i8, i8* %82, i64 32
  %88 = bitcast i8* %87 to <2 x i64>*
  store <2 x i64> %83, <2 x i64>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %82, i64 48
  %90 = bitcast i8* %89 to <2 x i64>*
  store <2 x i64> %83, <2 x i64>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %50, i64 %5
  %92 = getelementptr inbounds i8, i8* %3, i64 16
  %93 = bitcast i8* %92 to <8 x i16>*
  %94 = load <8 x i16>, <8 x i16>* %93, align 1
  %95 = shufflevector <8 x i16> %94, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %96 = shufflevector <8 x i16> %94, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %97 = bitcast <8 x i16> %95 to <4 x i32>
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %99 = bitcast <4 x i32> %98 to <2 x i64>
  %100 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %101 = bitcast <4 x i32> %100 to <2 x i64>
  %102 = shufflevector <2 x i64> %99, <2 x i64> undef, <2 x i32> zeroinitializer
  %103 = bitcast i8* %91 to <2 x i64>*
  store <2 x i64> %102, <2 x i64>* %103, align 1
  %104 = getelementptr inbounds i8, i8* %91, i64 16
  %105 = bitcast i8* %104 to <2 x i64>*
  store <2 x i64> %102, <2 x i64>* %105, align 1
  %106 = getelementptr inbounds i8, i8* %91, i64 32
  %107 = bitcast i8* %106 to <2 x i64>*
  store <2 x i64> %102, <2 x i64>* %107, align 1
  %108 = getelementptr inbounds i8, i8* %91, i64 48
  %109 = bitcast i8* %108 to <2 x i64>*
  store <2 x i64> %102, <2 x i64>* %109, align 1
  %110 = getelementptr inbounds i8, i8* %91, i64 %1
  %111 = shufflevector <2 x i64> %99, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %112 = bitcast i8* %110 to <2 x i64>*
  store <2 x i64> %111, <2 x i64>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %110, i64 16
  %114 = bitcast i8* %113 to <2 x i64>*
  store <2 x i64> %111, <2 x i64>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %110, i64 32
  %116 = bitcast i8* %115 to <2 x i64>*
  store <2 x i64> %111, <2 x i64>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %110, i64 48
  %118 = bitcast i8* %117 to <2 x i64>*
  store <2 x i64> %111, <2 x i64>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %110, i64 %1
  %120 = shufflevector <2 x i64> %101, <2 x i64> undef, <2 x i32> zeroinitializer
  %121 = bitcast i8* %119 to <2 x i64>*
  store <2 x i64> %120, <2 x i64>* %121, align 1
  %122 = getelementptr inbounds i8, i8* %119, i64 16
  %123 = bitcast i8* %122 to <2 x i64>*
  store <2 x i64> %120, <2 x i64>* %123, align 1
  %124 = getelementptr inbounds i8, i8* %119, i64 32
  %125 = bitcast i8* %124 to <2 x i64>*
  store <2 x i64> %120, <2 x i64>* %125, align 1
  %126 = getelementptr inbounds i8, i8* %119, i64 48
  %127 = bitcast i8* %126 to <2 x i64>*
  store <2 x i64> %120, <2 x i64>* %127, align 1
  %128 = getelementptr inbounds i8, i8* %119, i64 %1
  %129 = shufflevector <2 x i64> %101, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %130 = bitcast i8* %128 to <2 x i64>*
  store <2 x i64> %129, <2 x i64>* %130, align 1
  %131 = getelementptr inbounds i8, i8* %128, i64 16
  %132 = bitcast i8* %131 to <2 x i64>*
  store <2 x i64> %129, <2 x i64>* %132, align 1
  %133 = getelementptr inbounds i8, i8* %128, i64 32
  %134 = bitcast i8* %133 to <2 x i64>*
  store <2 x i64> %129, <2 x i64>* %134, align 1
  %135 = getelementptr inbounds i8, i8* %128, i64 48
  %136 = bitcast i8* %135 to <2 x i64>*
  store <2 x i64> %129, <2 x i64>* %136, align 1
  %137 = getelementptr inbounds i8, i8* %91, i64 %5
  %138 = bitcast <8 x i16> %96 to <4 x i32>
  %139 = shufflevector <4 x i32> %138, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %140 = bitcast <4 x i32> %139 to <2 x i64>
  %141 = shufflevector <4 x i32> %138, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %142 = bitcast <4 x i32> %141 to <2 x i64>
  %143 = shufflevector <2 x i64> %140, <2 x i64> undef, <2 x i32> zeroinitializer
  %144 = bitcast i8* %137 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %144, align 1
  %145 = getelementptr inbounds i8, i8* %137, i64 16
  %146 = bitcast i8* %145 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %137, i64 32
  %148 = bitcast i8* %147 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %137, i64 48
  %150 = bitcast i8* %149 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %150, align 1
  %151 = getelementptr inbounds i8, i8* %137, i64 %1
  %152 = shufflevector <2 x i64> %140, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %153 = bitcast i8* %151 to <2 x i64>*
  store <2 x i64> %152, <2 x i64>* %153, align 1
  %154 = getelementptr inbounds i8, i8* %151, i64 16
  %155 = bitcast i8* %154 to <2 x i64>*
  store <2 x i64> %152, <2 x i64>* %155, align 1
  %156 = getelementptr inbounds i8, i8* %151, i64 32
  %157 = bitcast i8* %156 to <2 x i64>*
  store <2 x i64> %152, <2 x i64>* %157, align 1
  %158 = getelementptr inbounds i8, i8* %151, i64 48
  %159 = bitcast i8* %158 to <2 x i64>*
  store <2 x i64> %152, <2 x i64>* %159, align 1
  %160 = getelementptr inbounds i8, i8* %151, i64 %1
  %161 = shufflevector <2 x i64> %142, <2 x i64> undef, <2 x i32> zeroinitializer
  %162 = bitcast i8* %160 to <2 x i64>*
  store <2 x i64> %161, <2 x i64>* %162, align 1
  %163 = getelementptr inbounds i8, i8* %160, i64 16
  %164 = bitcast i8* %163 to <2 x i64>*
  store <2 x i64> %161, <2 x i64>* %164, align 1
  %165 = getelementptr inbounds i8, i8* %160, i64 32
  %166 = bitcast i8* %165 to <2 x i64>*
  store <2 x i64> %161, <2 x i64>* %166, align 1
  %167 = getelementptr inbounds i8, i8* %160, i64 48
  %168 = bitcast i8* %167 to <2 x i64>*
  store <2 x i64> %161, <2 x i64>* %168, align 1
  %169 = getelementptr inbounds i8, i8* %160, i64 %1
  %170 = shufflevector <2 x i64> %142, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %171 = bitcast i8* %169 to <2 x i64>*
  store <2 x i64> %170, <2 x i64>* %171, align 1
  %172 = getelementptr inbounds i8, i8* %169, i64 16
  %173 = bitcast i8* %172 to <2 x i64>*
  store <2 x i64> %170, <2 x i64>* %173, align 1
  %174 = getelementptr inbounds i8, i8* %169, i64 32
  %175 = bitcast i8* %174 to <2 x i64>*
  store <2 x i64> %170, <2 x i64>* %175, align 1
  %176 = getelementptr inbounds i8, i8* %169, i64 48
  %177 = bitcast i8* %176 to <2 x i64>*
  store <2 x i64> %170, <2 x i64>* %177, align 1
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %96, %6 ]
  %8 = phi i8* [ %0, %4 ], [ %95, %6 ]
  %9 = getelementptr inbounds i8, i8* %3, i64 %7
  %10 = bitcast i8* %9 to <8 x i16>*
  %11 = load <8 x i16>, <8 x i16>* %10, align 1
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %13 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %14 = bitcast <8 x i16> %12 to <4 x i32>
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %18 = bitcast <4 x i32> %17 to <2 x i64>
  %19 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> zeroinitializer
  %20 = bitcast i8* %8 to <2 x i64>*
  store <2 x i64> %19, <2 x i64>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %8, i64 16
  %22 = bitcast i8* %21 to <2 x i64>*
  store <2 x i64> %19, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %8, i64 32
  %24 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %19, <2 x i64>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %8, i64 48
  %26 = bitcast i8* %25 to <2 x i64>*
  store <2 x i64> %19, <2 x i64>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %8, i64 %1
  %28 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %29 = bitcast i8* %27 to <2 x i64>*
  store <2 x i64> %28, <2 x i64>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %27, i64 16
  %31 = bitcast i8* %30 to <2 x i64>*
  store <2 x i64> %28, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %27, i64 32
  %33 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %28, <2 x i64>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %27, i64 48
  %35 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %28, <2 x i64>* %35, align 1
  %36 = getelementptr inbounds i8, i8* %27, i64 %1
  %37 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> zeroinitializer
  %38 = bitcast i8* %36 to <2 x i64>*
  store <2 x i64> %37, <2 x i64>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %36, i64 16
  %40 = bitcast i8* %39 to <2 x i64>*
  store <2 x i64> %37, <2 x i64>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %36, i64 32
  %42 = bitcast i8* %41 to <2 x i64>*
  store <2 x i64> %37, <2 x i64>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %36, i64 48
  %44 = bitcast i8* %43 to <2 x i64>*
  store <2 x i64> %37, <2 x i64>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %36, i64 %1
  %46 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %47 = bitcast i8* %45 to <2 x i64>*
  store <2 x i64> %46, <2 x i64>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %45, i64 16
  %49 = bitcast i8* %48 to <2 x i64>*
  store <2 x i64> %46, <2 x i64>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %45, i64 32
  %51 = bitcast i8* %50 to <2 x i64>*
  store <2 x i64> %46, <2 x i64>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %45, i64 48
  %53 = bitcast i8* %52 to <2 x i64>*
  store <2 x i64> %46, <2 x i64>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %8, i64 %5
  %55 = bitcast <8 x i16> %13 to <4 x i32>
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %57 = bitcast <4 x i32> %56 to <2 x i64>
  %58 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %59 = bitcast <4 x i32> %58 to <2 x i64>
  %60 = shufflevector <2 x i64> %57, <2 x i64> undef, <2 x i32> zeroinitializer
  %61 = bitcast i8* %54 to <2 x i64>*
  store <2 x i64> %60, <2 x i64>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %54, i64 16
  %63 = bitcast i8* %62 to <2 x i64>*
  store <2 x i64> %60, <2 x i64>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %54, i64 32
  %65 = bitcast i8* %64 to <2 x i64>*
  store <2 x i64> %60, <2 x i64>* %65, align 1
  %66 = getelementptr inbounds i8, i8* %54, i64 48
  %67 = bitcast i8* %66 to <2 x i64>*
  store <2 x i64> %60, <2 x i64>* %67, align 1
  %68 = getelementptr inbounds i8, i8* %54, i64 %1
  %69 = shufflevector <2 x i64> %57, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %70 = bitcast i8* %68 to <2 x i64>*
  store <2 x i64> %69, <2 x i64>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %68, i64 16
  %72 = bitcast i8* %71 to <2 x i64>*
  store <2 x i64> %69, <2 x i64>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %68, i64 32
  %74 = bitcast i8* %73 to <2 x i64>*
  store <2 x i64> %69, <2 x i64>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %68, i64 48
  %76 = bitcast i8* %75 to <2 x i64>*
  store <2 x i64> %69, <2 x i64>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %68, i64 %1
  %78 = shufflevector <2 x i64> %59, <2 x i64> undef, <2 x i32> zeroinitializer
  %79 = bitcast i8* %77 to <2 x i64>*
  store <2 x i64> %78, <2 x i64>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %77, i64 16
  %81 = bitcast i8* %80 to <2 x i64>*
  store <2 x i64> %78, <2 x i64>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %77, i64 32
  %83 = bitcast i8* %82 to <2 x i64>*
  store <2 x i64> %78, <2 x i64>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %77, i64 48
  %85 = bitcast i8* %84 to <2 x i64>*
  store <2 x i64> %78, <2 x i64>* %85, align 1
  %86 = getelementptr inbounds i8, i8* %77, i64 %1
  %87 = shufflevector <2 x i64> %59, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %88 = bitcast i8* %86 to <2 x i64>*
  store <2 x i64> %87, <2 x i64>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %86, i64 16
  %90 = bitcast i8* %89 to <2 x i64>*
  store <2 x i64> %87, <2 x i64>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %86, i64 32
  %92 = bitcast i8* %91 to <2 x i64>*
  store <2 x i64> %87, <2 x i64>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %86, i64 48
  %94 = bitcast i8* %93 to <2 x i64>*
  store <2 x i64> %87, <2 x i64>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %54, i64 %5
  %96 = add nuw nsw i64 %7, 16
  %97 = icmp ult i64 %96, 64
  br i1 %97, label %6, label %98

98:                                               ; preds = %6
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore64_SSE4_1IXadL_ZNS4_18WriteDuplicate32x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %96, %6 ]
  %8 = phi i8* [ %0, %4 ], [ %95, %6 ]
  %9 = getelementptr inbounds i8, i8* %3, i64 %7
  %10 = bitcast i8* %9 to <8 x i16>*
  %11 = load <8 x i16>, <8 x i16>* %10, align 1
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %13 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %14 = bitcast <8 x i16> %12 to <4 x i32>
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %18 = bitcast <4 x i32> %17 to <2 x i64>
  %19 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> zeroinitializer
  %20 = bitcast i8* %8 to <2 x i64>*
  store <2 x i64> %19, <2 x i64>* %20, align 1
  %21 = getelementptr inbounds i8, i8* %8, i64 16
  %22 = bitcast i8* %21 to <2 x i64>*
  store <2 x i64> %19, <2 x i64>* %22, align 1
  %23 = getelementptr inbounds i8, i8* %8, i64 32
  %24 = bitcast i8* %23 to <2 x i64>*
  store <2 x i64> %19, <2 x i64>* %24, align 1
  %25 = getelementptr inbounds i8, i8* %8, i64 48
  %26 = bitcast i8* %25 to <2 x i64>*
  store <2 x i64> %19, <2 x i64>* %26, align 1
  %27 = getelementptr inbounds i8, i8* %8, i64 %1
  %28 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %29 = bitcast i8* %27 to <2 x i64>*
  store <2 x i64> %28, <2 x i64>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %27, i64 16
  %31 = bitcast i8* %30 to <2 x i64>*
  store <2 x i64> %28, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %27, i64 32
  %33 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %28, <2 x i64>* %33, align 1
  %34 = getelementptr inbounds i8, i8* %27, i64 48
  %35 = bitcast i8* %34 to <2 x i64>*
  store <2 x i64> %28, <2 x i64>* %35, align 1
  %36 = getelementptr inbounds i8, i8* %27, i64 %1
  %37 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> zeroinitializer
  %38 = bitcast i8* %36 to <2 x i64>*
  store <2 x i64> %37, <2 x i64>* %38, align 1
  %39 = getelementptr inbounds i8, i8* %36, i64 16
  %40 = bitcast i8* %39 to <2 x i64>*
  store <2 x i64> %37, <2 x i64>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %36, i64 32
  %42 = bitcast i8* %41 to <2 x i64>*
  store <2 x i64> %37, <2 x i64>* %42, align 1
  %43 = getelementptr inbounds i8, i8* %36, i64 48
  %44 = bitcast i8* %43 to <2 x i64>*
  store <2 x i64> %37, <2 x i64>* %44, align 1
  %45 = getelementptr inbounds i8, i8* %36, i64 %1
  %46 = shufflevector <2 x i64> %18, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %47 = bitcast i8* %45 to <2 x i64>*
  store <2 x i64> %46, <2 x i64>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %45, i64 16
  %49 = bitcast i8* %48 to <2 x i64>*
  store <2 x i64> %46, <2 x i64>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %45, i64 32
  %51 = bitcast i8* %50 to <2 x i64>*
  store <2 x i64> %46, <2 x i64>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %45, i64 48
  %53 = bitcast i8* %52 to <2 x i64>*
  store <2 x i64> %46, <2 x i64>* %53, align 1
  %54 = getelementptr inbounds i8, i8* %8, i64 %5
  %55 = bitcast <8 x i16> %13 to <4 x i32>
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %57 = bitcast <4 x i32> %56 to <2 x i64>
  %58 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %59 = bitcast <4 x i32> %58 to <2 x i64>
  %60 = shufflevector <2 x i64> %57, <2 x i64> undef, <2 x i32> zeroinitializer
  %61 = bitcast i8* %54 to <2 x i64>*
  store <2 x i64> %60, <2 x i64>* %61, align 1
  %62 = getelementptr inbounds i8, i8* %54, i64 16
  %63 = bitcast i8* %62 to <2 x i64>*
  store <2 x i64> %60, <2 x i64>* %63, align 1
  %64 = getelementptr inbounds i8, i8* %54, i64 32
  %65 = bitcast i8* %64 to <2 x i64>*
  store <2 x i64> %60, <2 x i64>* %65, align 1
  %66 = getelementptr inbounds i8, i8* %54, i64 48
  %67 = bitcast i8* %66 to <2 x i64>*
  store <2 x i64> %60, <2 x i64>* %67, align 1
  %68 = getelementptr inbounds i8, i8* %54, i64 %1
  %69 = shufflevector <2 x i64> %57, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %70 = bitcast i8* %68 to <2 x i64>*
  store <2 x i64> %69, <2 x i64>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %68, i64 16
  %72 = bitcast i8* %71 to <2 x i64>*
  store <2 x i64> %69, <2 x i64>* %72, align 1
  %73 = getelementptr inbounds i8, i8* %68, i64 32
  %74 = bitcast i8* %73 to <2 x i64>*
  store <2 x i64> %69, <2 x i64>* %74, align 1
  %75 = getelementptr inbounds i8, i8* %68, i64 48
  %76 = bitcast i8* %75 to <2 x i64>*
  store <2 x i64> %69, <2 x i64>* %76, align 1
  %77 = getelementptr inbounds i8, i8* %68, i64 %1
  %78 = shufflevector <2 x i64> %59, <2 x i64> undef, <2 x i32> zeroinitializer
  %79 = bitcast i8* %77 to <2 x i64>*
  store <2 x i64> %78, <2 x i64>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %77, i64 16
  %81 = bitcast i8* %80 to <2 x i64>*
  store <2 x i64> %78, <2 x i64>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %77, i64 32
  %83 = bitcast i8* %82 to <2 x i64>*
  store <2 x i64> %78, <2 x i64>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %77, i64 48
  %85 = bitcast i8* %84 to <2 x i64>*
  store <2 x i64> %78, <2 x i64>* %85, align 1
  %86 = getelementptr inbounds i8, i8* %77, i64 %1
  %87 = shufflevector <2 x i64> %59, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %88 = bitcast i8* %86 to <2 x i64>*
  store <2 x i64> %87, <2 x i64>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %86, i64 16
  %90 = bitcast i8* %89 to <2 x i64>*
  store <2 x i64> %87, <2 x i64>* %90, align 1
  %91 = getelementptr inbounds i8, i8* %86, i64 32
  %92 = bitcast i8* %91 to <2 x i64>*
  store <2 x i64> %87, <2 x i64>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %86, i64 48
  %94 = bitcast i8* %93 to <2 x i64>*
  store <2 x i64> %87, <2 x i64>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %54, i64 %5
  %96 = add nuw nsw i64 %7, 16
  %97 = icmp ult i64 %96, 128
  br i1 %97, label %6, label %98

98:                                               ; preds = %6
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore16_SSE4_1IXadL_ZNS4_18WriteDuplicate64x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %160, %6 ]
  %8 = phi i8* [ %0, %4 ], [ %159, %6 ]
  %9 = getelementptr inbounds i8, i8* %3, i64 %7
  %10 = bitcast i8* %9 to <8 x i16>*
  %11 = load <8 x i16>, <8 x i16>* %10, align 1
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %13 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %14 = bitcast <8 x i16> %12 to <4 x i32>
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %18 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> zeroinitializer
  %19 = bitcast i8* %8 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %19, align 1
  %20 = getelementptr inbounds i8, i8* %8, i64 16
  %21 = bitcast i8* %20 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %8, i64 32
  %23 = bitcast i8* %22 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %23, align 1
  %24 = getelementptr inbounds i8, i8* %8, i64 48
  %25 = bitcast i8* %24 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %8, i64 64
  %27 = bitcast i8* %26 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %8, i64 80
  %29 = bitcast i8* %28 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %8, i64 96
  %31 = bitcast i8* %30 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %8, i64 112
  %33 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %33, align 1
  %34 = bitcast <4 x i32> %17 to <2 x i64>
  %35 = getelementptr inbounds i8, i8* %8, i64 %1
  %36 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %37 = bitcast i8* %35 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %35, i64 16
  %39 = bitcast i8* %38 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %35, i64 32
  %41 = bitcast i8* %40 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %35, i64 48
  %43 = bitcast i8* %42 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %35, i64 64
  %45 = bitcast i8* %44 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %35, i64 80
  %47 = bitcast i8* %46 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %35, i64 96
  %49 = bitcast i8* %48 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %35, i64 112
  %51 = bitcast i8* %50 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %35, i64 %1
  %53 = shufflevector <2 x i64> %34, <2 x i64> undef, <2 x i32> zeroinitializer
  %54 = bitcast i8* %52 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %52, i64 16
  %56 = bitcast i8* %55 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %52, i64 32
  %58 = bitcast i8* %57 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %52, i64 48
  %60 = bitcast i8* %59 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %52, i64 64
  %62 = bitcast i8* %61 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %52, i64 80
  %64 = bitcast i8* %63 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %52, i64 96
  %66 = bitcast i8* %65 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %52, i64 112
  %68 = bitcast i8* %67 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %52, i64 %1
  %70 = shufflevector <2 x i64> %34, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %71 = bitcast i8* %69 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %71, align 1
  %72 = getelementptr inbounds i8, i8* %69, i64 16
  %73 = bitcast i8* %72 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %69, i64 32
  %75 = bitcast i8* %74 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %69, i64 48
  %77 = bitcast i8* %76 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %69, i64 64
  %79 = bitcast i8* %78 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %69, i64 80
  %81 = bitcast i8* %80 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %69, i64 96
  %83 = bitcast i8* %82 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %69, i64 112
  %85 = bitcast i8* %84 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %85, align 1
  %86 = getelementptr inbounds i8, i8* %8, i64 %5
  %87 = bitcast <8 x i16> %13 to <4 x i32>
  %88 = shufflevector <4 x i32> %87, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %89 = bitcast <4 x i32> %88 to <2 x i64>
  %90 = shufflevector <4 x i32> %87, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %91 = shufflevector <2 x i64> %89, <2 x i64> undef, <2 x i32> zeroinitializer
  %92 = bitcast i8* %86 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %86, i64 16
  %94 = bitcast i8* %93 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %86, i64 32
  %96 = bitcast i8* %95 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %86, i64 48
  %98 = bitcast i8* %97 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %86, i64 64
  %100 = bitcast i8* %99 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %86, i64 80
  %102 = bitcast i8* %101 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %86, i64 96
  %104 = bitcast i8* %103 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %86, i64 112
  %106 = bitcast i8* %105 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %106, align 1
  %107 = bitcast <4 x i32> %90 to <2 x i64>
  %108 = getelementptr inbounds i8, i8* %86, i64 %1
  %109 = shufflevector <2 x i64> %89, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %110 = bitcast i8* %108 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %108, i64 16
  %112 = bitcast i8* %111 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %108, i64 32
  %114 = bitcast i8* %113 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %108, i64 48
  %116 = bitcast i8* %115 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %108, i64 64
  %118 = bitcast i8* %117 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %108, i64 80
  %120 = bitcast i8* %119 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %108, i64 96
  %122 = bitcast i8* %121 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %108, i64 112
  %124 = bitcast i8* %123 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %124, align 1
  %125 = getelementptr inbounds i8, i8* %108, i64 %1
  %126 = shufflevector <2 x i64> %107, <2 x i64> undef, <2 x i32> zeroinitializer
  %127 = bitcast i8* %125 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %127, align 1
  %128 = getelementptr inbounds i8, i8* %125, i64 16
  %129 = bitcast i8* %128 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %129, align 1
  %130 = getelementptr inbounds i8, i8* %125, i64 32
  %131 = bitcast i8* %130 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %131, align 1
  %132 = getelementptr inbounds i8, i8* %125, i64 48
  %133 = bitcast i8* %132 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %133, align 1
  %134 = getelementptr inbounds i8, i8* %125, i64 64
  %135 = bitcast i8* %134 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %135, align 1
  %136 = getelementptr inbounds i8, i8* %125, i64 80
  %137 = bitcast i8* %136 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %137, align 1
  %138 = getelementptr inbounds i8, i8* %125, i64 96
  %139 = bitcast i8* %138 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %139, align 1
  %140 = getelementptr inbounds i8, i8* %125, i64 112
  %141 = bitcast i8* %140 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %141, align 1
  %142 = getelementptr inbounds i8, i8* %125, i64 %1
  %143 = shufflevector <2 x i64> %107, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %144 = bitcast i8* %142 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %144, align 1
  %145 = getelementptr inbounds i8, i8* %142, i64 16
  %146 = bitcast i8* %145 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %142, i64 32
  %148 = bitcast i8* %147 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %142, i64 48
  %150 = bitcast i8* %149 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %150, align 1
  %151 = getelementptr inbounds i8, i8* %142, i64 64
  %152 = bitcast i8* %151 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %152, align 1
  %153 = getelementptr inbounds i8, i8* %142, i64 80
  %154 = bitcast i8* %153 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %154, align 1
  %155 = getelementptr inbounds i8, i8* %142, i64 96
  %156 = bitcast i8* %155 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %156, align 1
  %157 = getelementptr inbounds i8, i8* %142, i64 112
  %158 = bitcast i8* %157 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %86, i64 %5
  %160 = add nuw nsw i64 %7, 16
  %161 = icmp ult i64 %160, 32
  br i1 %161, label %6, label %162

162:                                              ; preds = %6
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore32_SSE4_1IXadL_ZNS4_18WriteDuplicate64x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %160, %6 ]
  %8 = phi i8* [ %0, %4 ], [ %159, %6 ]
  %9 = getelementptr inbounds i8, i8* %3, i64 %7
  %10 = bitcast i8* %9 to <8 x i16>*
  %11 = load <8 x i16>, <8 x i16>* %10, align 1
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %13 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %14 = bitcast <8 x i16> %12 to <4 x i32>
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %18 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> zeroinitializer
  %19 = bitcast i8* %8 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %19, align 1
  %20 = getelementptr inbounds i8, i8* %8, i64 16
  %21 = bitcast i8* %20 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %8, i64 32
  %23 = bitcast i8* %22 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %23, align 1
  %24 = getelementptr inbounds i8, i8* %8, i64 48
  %25 = bitcast i8* %24 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %8, i64 64
  %27 = bitcast i8* %26 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %8, i64 80
  %29 = bitcast i8* %28 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %8, i64 96
  %31 = bitcast i8* %30 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %8, i64 112
  %33 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %33, align 1
  %34 = bitcast <4 x i32> %17 to <2 x i64>
  %35 = getelementptr inbounds i8, i8* %8, i64 %1
  %36 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %37 = bitcast i8* %35 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %35, i64 16
  %39 = bitcast i8* %38 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %35, i64 32
  %41 = bitcast i8* %40 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %35, i64 48
  %43 = bitcast i8* %42 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %35, i64 64
  %45 = bitcast i8* %44 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %35, i64 80
  %47 = bitcast i8* %46 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %35, i64 96
  %49 = bitcast i8* %48 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %35, i64 112
  %51 = bitcast i8* %50 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %35, i64 %1
  %53 = shufflevector <2 x i64> %34, <2 x i64> undef, <2 x i32> zeroinitializer
  %54 = bitcast i8* %52 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %52, i64 16
  %56 = bitcast i8* %55 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %52, i64 32
  %58 = bitcast i8* %57 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %52, i64 48
  %60 = bitcast i8* %59 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %52, i64 64
  %62 = bitcast i8* %61 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %52, i64 80
  %64 = bitcast i8* %63 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %52, i64 96
  %66 = bitcast i8* %65 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %52, i64 112
  %68 = bitcast i8* %67 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %52, i64 %1
  %70 = shufflevector <2 x i64> %34, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %71 = bitcast i8* %69 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %71, align 1
  %72 = getelementptr inbounds i8, i8* %69, i64 16
  %73 = bitcast i8* %72 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %69, i64 32
  %75 = bitcast i8* %74 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %69, i64 48
  %77 = bitcast i8* %76 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %69, i64 64
  %79 = bitcast i8* %78 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %69, i64 80
  %81 = bitcast i8* %80 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %69, i64 96
  %83 = bitcast i8* %82 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %69, i64 112
  %85 = bitcast i8* %84 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %85, align 1
  %86 = getelementptr inbounds i8, i8* %8, i64 %5
  %87 = bitcast <8 x i16> %13 to <4 x i32>
  %88 = shufflevector <4 x i32> %87, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %89 = bitcast <4 x i32> %88 to <2 x i64>
  %90 = shufflevector <4 x i32> %87, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %91 = shufflevector <2 x i64> %89, <2 x i64> undef, <2 x i32> zeroinitializer
  %92 = bitcast i8* %86 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %86, i64 16
  %94 = bitcast i8* %93 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %86, i64 32
  %96 = bitcast i8* %95 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %86, i64 48
  %98 = bitcast i8* %97 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %86, i64 64
  %100 = bitcast i8* %99 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %86, i64 80
  %102 = bitcast i8* %101 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %86, i64 96
  %104 = bitcast i8* %103 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %86, i64 112
  %106 = bitcast i8* %105 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %106, align 1
  %107 = bitcast <4 x i32> %90 to <2 x i64>
  %108 = getelementptr inbounds i8, i8* %86, i64 %1
  %109 = shufflevector <2 x i64> %89, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %110 = bitcast i8* %108 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %108, i64 16
  %112 = bitcast i8* %111 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %108, i64 32
  %114 = bitcast i8* %113 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %108, i64 48
  %116 = bitcast i8* %115 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %108, i64 64
  %118 = bitcast i8* %117 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %108, i64 80
  %120 = bitcast i8* %119 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %108, i64 96
  %122 = bitcast i8* %121 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %108, i64 112
  %124 = bitcast i8* %123 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %124, align 1
  %125 = getelementptr inbounds i8, i8* %108, i64 %1
  %126 = shufflevector <2 x i64> %107, <2 x i64> undef, <2 x i32> zeroinitializer
  %127 = bitcast i8* %125 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %127, align 1
  %128 = getelementptr inbounds i8, i8* %125, i64 16
  %129 = bitcast i8* %128 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %129, align 1
  %130 = getelementptr inbounds i8, i8* %125, i64 32
  %131 = bitcast i8* %130 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %131, align 1
  %132 = getelementptr inbounds i8, i8* %125, i64 48
  %133 = bitcast i8* %132 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %133, align 1
  %134 = getelementptr inbounds i8, i8* %125, i64 64
  %135 = bitcast i8* %134 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %135, align 1
  %136 = getelementptr inbounds i8, i8* %125, i64 80
  %137 = bitcast i8* %136 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %137, align 1
  %138 = getelementptr inbounds i8, i8* %125, i64 96
  %139 = bitcast i8* %138 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %139, align 1
  %140 = getelementptr inbounds i8, i8* %125, i64 112
  %141 = bitcast i8* %140 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %141, align 1
  %142 = getelementptr inbounds i8, i8* %125, i64 %1
  %143 = shufflevector <2 x i64> %107, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %144 = bitcast i8* %142 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %144, align 1
  %145 = getelementptr inbounds i8, i8* %142, i64 16
  %146 = bitcast i8* %145 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %142, i64 32
  %148 = bitcast i8* %147 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %142, i64 48
  %150 = bitcast i8* %149 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %150, align 1
  %151 = getelementptr inbounds i8, i8* %142, i64 64
  %152 = bitcast i8* %151 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %152, align 1
  %153 = getelementptr inbounds i8, i8* %142, i64 80
  %154 = bitcast i8* %153 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %154, align 1
  %155 = getelementptr inbounds i8, i8* %142, i64 96
  %156 = bitcast i8* %155 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %156, align 1
  %157 = getelementptr inbounds i8, i8* %142, i64 112
  %158 = bitcast i8* %157 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %86, i64 %5
  %160 = add nuw nsw i64 %7, 16
  %161 = icmp ult i64 %160, 64
  br i1 %161, label %6, label %162

162:                                              ; preds = %6
  ret void
}

; Function Attrs: nofree norecurse nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12_GLOBAL__N_127DirectionalPredFuncs_SSE4_1IXadL_ZNS0_13high_bitdepth12_GLOBAL__N_117ColStore64_SSE4_1IXadL_ZNS4_18WriteDuplicate64x4EPvlDv2_xEEEEvS6_lPKvEEE10HorizontalES6_lS9_S9_(i8* nocapture, i64, i8* nocapture readnone, i8* nocapture readonly) #5 align 2 {
  %5 = shl i64 %1, 2
  br label %6

6:                                                ; preds = %6, %4
  %7 = phi i64 [ 0, %4 ], [ %160, %6 ]
  %8 = phi i8* [ %0, %4 ], [ %159, %6 ]
  %9 = getelementptr inbounds i8, i8* %3, i64 %7
  %10 = bitcast i8* %9 to <8 x i16>*
  %11 = load <8 x i16>, <8 x i16>* %10, align 1
  %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %13 = shufflevector <8 x i16> %11, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %14 = bitcast <8 x i16> %12 to <4 x i32>
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %18 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> zeroinitializer
  %19 = bitcast i8* %8 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %19, align 1
  %20 = getelementptr inbounds i8, i8* %8, i64 16
  %21 = bitcast i8* %20 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %21, align 1
  %22 = getelementptr inbounds i8, i8* %8, i64 32
  %23 = bitcast i8* %22 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %23, align 1
  %24 = getelementptr inbounds i8, i8* %8, i64 48
  %25 = bitcast i8* %24 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %25, align 1
  %26 = getelementptr inbounds i8, i8* %8, i64 64
  %27 = bitcast i8* %26 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %27, align 1
  %28 = getelementptr inbounds i8, i8* %8, i64 80
  %29 = bitcast i8* %28 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %29, align 1
  %30 = getelementptr inbounds i8, i8* %8, i64 96
  %31 = bitcast i8* %30 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %31, align 1
  %32 = getelementptr inbounds i8, i8* %8, i64 112
  %33 = bitcast i8* %32 to <2 x i64>*
  store <2 x i64> %18, <2 x i64>* %33, align 1
  %34 = bitcast <4 x i32> %17 to <2 x i64>
  %35 = getelementptr inbounds i8, i8* %8, i64 %1
  %36 = shufflevector <2 x i64> %16, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %37 = bitcast i8* %35 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %37, align 1
  %38 = getelementptr inbounds i8, i8* %35, i64 16
  %39 = bitcast i8* %38 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %35, i64 32
  %41 = bitcast i8* %40 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %41, align 1
  %42 = getelementptr inbounds i8, i8* %35, i64 48
  %43 = bitcast i8* %42 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %43, align 1
  %44 = getelementptr inbounds i8, i8* %35, i64 64
  %45 = bitcast i8* %44 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %45, align 1
  %46 = getelementptr inbounds i8, i8* %35, i64 80
  %47 = bitcast i8* %46 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %47, align 1
  %48 = getelementptr inbounds i8, i8* %35, i64 96
  %49 = bitcast i8* %48 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %49, align 1
  %50 = getelementptr inbounds i8, i8* %35, i64 112
  %51 = bitcast i8* %50 to <2 x i64>*
  store <2 x i64> %36, <2 x i64>* %51, align 1
  %52 = getelementptr inbounds i8, i8* %35, i64 %1
  %53 = shufflevector <2 x i64> %34, <2 x i64> undef, <2 x i32> zeroinitializer
  %54 = bitcast i8* %52 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %54, align 1
  %55 = getelementptr inbounds i8, i8* %52, i64 16
  %56 = bitcast i8* %55 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %56, align 1
  %57 = getelementptr inbounds i8, i8* %52, i64 32
  %58 = bitcast i8* %57 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %58, align 1
  %59 = getelementptr inbounds i8, i8* %52, i64 48
  %60 = bitcast i8* %59 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %60, align 1
  %61 = getelementptr inbounds i8, i8* %52, i64 64
  %62 = bitcast i8* %61 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %62, align 1
  %63 = getelementptr inbounds i8, i8* %52, i64 80
  %64 = bitcast i8* %63 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %64, align 1
  %65 = getelementptr inbounds i8, i8* %52, i64 96
  %66 = bitcast i8* %65 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %52, i64 112
  %68 = bitcast i8* %67 to <2 x i64>*
  store <2 x i64> %53, <2 x i64>* %68, align 1
  %69 = getelementptr inbounds i8, i8* %52, i64 %1
  %70 = shufflevector <2 x i64> %34, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %71 = bitcast i8* %69 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %71, align 1
  %72 = getelementptr inbounds i8, i8* %69, i64 16
  %73 = bitcast i8* %72 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %73, align 1
  %74 = getelementptr inbounds i8, i8* %69, i64 32
  %75 = bitcast i8* %74 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %75, align 1
  %76 = getelementptr inbounds i8, i8* %69, i64 48
  %77 = bitcast i8* %76 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %77, align 1
  %78 = getelementptr inbounds i8, i8* %69, i64 64
  %79 = bitcast i8* %78 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %79, align 1
  %80 = getelementptr inbounds i8, i8* %69, i64 80
  %81 = bitcast i8* %80 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %81, align 1
  %82 = getelementptr inbounds i8, i8* %69, i64 96
  %83 = bitcast i8* %82 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %83, align 1
  %84 = getelementptr inbounds i8, i8* %69, i64 112
  %85 = bitcast i8* %84 to <2 x i64>*
  store <2 x i64> %70, <2 x i64>* %85, align 1
  %86 = getelementptr inbounds i8, i8* %8, i64 %5
  %87 = bitcast <8 x i16> %13 to <4 x i32>
  %88 = shufflevector <4 x i32> %87, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %89 = bitcast <4 x i32> %88 to <2 x i64>
  %90 = shufflevector <4 x i32> %87, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %91 = shufflevector <2 x i64> %89, <2 x i64> undef, <2 x i32> zeroinitializer
  %92 = bitcast i8* %86 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %92, align 1
  %93 = getelementptr inbounds i8, i8* %86, i64 16
  %94 = bitcast i8* %93 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %94, align 1
  %95 = getelementptr inbounds i8, i8* %86, i64 32
  %96 = bitcast i8* %95 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %96, align 1
  %97 = getelementptr inbounds i8, i8* %86, i64 48
  %98 = bitcast i8* %97 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %98, align 1
  %99 = getelementptr inbounds i8, i8* %86, i64 64
  %100 = bitcast i8* %99 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %100, align 1
  %101 = getelementptr inbounds i8, i8* %86, i64 80
  %102 = bitcast i8* %101 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %102, align 1
  %103 = getelementptr inbounds i8, i8* %86, i64 96
  %104 = bitcast i8* %103 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %104, align 1
  %105 = getelementptr inbounds i8, i8* %86, i64 112
  %106 = bitcast i8* %105 to <2 x i64>*
  store <2 x i64> %91, <2 x i64>* %106, align 1
  %107 = bitcast <4 x i32> %90 to <2 x i64>
  %108 = getelementptr inbounds i8, i8* %86, i64 %1
  %109 = shufflevector <2 x i64> %89, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %110 = bitcast i8* %108 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %110, align 1
  %111 = getelementptr inbounds i8, i8* %108, i64 16
  %112 = bitcast i8* %111 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %112, align 1
  %113 = getelementptr inbounds i8, i8* %108, i64 32
  %114 = bitcast i8* %113 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %114, align 1
  %115 = getelementptr inbounds i8, i8* %108, i64 48
  %116 = bitcast i8* %115 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %108, i64 64
  %118 = bitcast i8* %117 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %118, align 1
  %119 = getelementptr inbounds i8, i8* %108, i64 80
  %120 = bitcast i8* %119 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %120, align 1
  %121 = getelementptr inbounds i8, i8* %108, i64 96
  %122 = bitcast i8* %121 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %122, align 1
  %123 = getelementptr inbounds i8, i8* %108, i64 112
  %124 = bitcast i8* %123 to <2 x i64>*
  store <2 x i64> %109, <2 x i64>* %124, align 1
  %125 = getelementptr inbounds i8, i8* %108, i64 %1
  %126 = shufflevector <2 x i64> %107, <2 x i64> undef, <2 x i32> zeroinitializer
  %127 = bitcast i8* %125 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %127, align 1
  %128 = getelementptr inbounds i8, i8* %125, i64 16
  %129 = bitcast i8* %128 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %129, align 1
  %130 = getelementptr inbounds i8, i8* %125, i64 32
  %131 = bitcast i8* %130 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %131, align 1
  %132 = getelementptr inbounds i8, i8* %125, i64 48
  %133 = bitcast i8* %132 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %133, align 1
  %134 = getelementptr inbounds i8, i8* %125, i64 64
  %135 = bitcast i8* %134 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %135, align 1
  %136 = getelementptr inbounds i8, i8* %125, i64 80
  %137 = bitcast i8* %136 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %137, align 1
  %138 = getelementptr inbounds i8, i8* %125, i64 96
  %139 = bitcast i8* %138 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %139, align 1
  %140 = getelementptr inbounds i8, i8* %125, i64 112
  %141 = bitcast i8* %140 to <2 x i64>*
  store <2 x i64> %126, <2 x i64>* %141, align 1
  %142 = getelementptr inbounds i8, i8* %125, i64 %1
  %143 = shufflevector <2 x i64> %107, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %144 = bitcast i8* %142 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %144, align 1
  %145 = getelementptr inbounds i8, i8* %142, i64 16
  %146 = bitcast i8* %145 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %146, align 1
  %147 = getelementptr inbounds i8, i8* %142, i64 32
  %148 = bitcast i8* %147 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %148, align 1
  %149 = getelementptr inbounds i8, i8* %142, i64 48
  %150 = bitcast i8* %149 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %150, align 1
  %151 = getelementptr inbounds i8, i8* %142, i64 64
  %152 = bitcast i8* %151 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %152, align 1
  %153 = getelementptr inbounds i8, i8* %142, i64 80
  %154 = bitcast i8* %153 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %154, align 1
  %155 = getelementptr inbounds i8, i8* %142, i64 96
  %156 = bitcast i8* %155 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %156, align 1
  %157 = getelementptr inbounds i8, i8* %142, i64 112
  %158 = bitcast i8* %157 to <2 x i64>*
  store <2 x i64> %143, <2 x i64>* %158, align 1
  %159 = getelementptr inbounds i8, i8* %86, i64 %5
  %160 = add nuw nsw i64 %7, 16
  %161 = icmp ult i64 %160, 128
  br i1 %161, label %6, label %162

162:                                              ; preds = %6
  ret void
}

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16>, <8 x i16>) #6

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nofree norecurse nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nounwind readnone }
attributes #7 = { nounwind readnone speculatable }
attributes #8 = { inlinehint nounwind ssp uwtable writeonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #9 = { nounwind ssp uwtable writeonly "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #11 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = distinct !{!2, !3}
!3 = !{!"llvm.loop.unroll.disable"}
!4 = distinct !{!4, !3}
!5 = distinct !{!5, !3}
!6 = distinct !{!6, !3}
!7 = distinct !{!7, !3}
!8 = distinct !{!8, !3}
!9 = distinct !{!9, !3}
!10 = distinct !{!10, !3}
!11 = distinct !{!11, !3}
!12 = distinct !{!12, !3}
!13 = distinct !{!13, !3}
!14 = distinct !{!14, !3}
!15 = distinct !{!15, !3}
!16 = distinct !{!16, !3}
!17 = distinct !{!17, !3}
!18 = distinct !{!18, !3}
!19 = distinct !{!19, !3}
!20 = distinct !{!20, !3}
!21 = distinct !{!21, !3}
!22 = distinct !{!22, !3}
!23 = distinct !{!23, !3}
!24 = distinct !{!24, !3}
!25 = distinct !{!25, !3}
!26 = distinct !{!26, !3}
!27 = distinct !{!27, !28}
!28 = !{!"llvm.loop.isvectorized", i32 1}
!29 = distinct !{!29, !3}
!30 = distinct !{!30, !31, !28}
!31 = !{!"llvm.loop.unroll.runtime.disable"}
!32 = distinct !{!32, !28}
!33 = distinct !{!33, !3}
!34 = distinct !{!34, !31, !28}
!35 = distinct !{!35, !28}
!36 = distinct !{!36, !3}
!37 = distinct !{!37, !31, !28}
