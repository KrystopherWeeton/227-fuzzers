; ModuleID = '../../third_party/libvpx/source/libvpx/vp9/common/x86/vp9_highbd_iht16x16_add_sse4.c'
source_filename = "../../third_party/libvpx/source/libvpx/vp9/common/x86/vp9_highbd_iht16x16_add_sse4.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nounwind ssp uwtable
define hidden void @vp9_highbd_iht16x16_256_add_sse4_1(i32* nocapture readonly, i16* nocapture, i32, i32, i32) local_unnamed_addr #0 {
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = alloca [16 x <2 x i64>], align 16
  %8 = alloca [16 x <2 x i64>], align 16
  %9 = alloca [4 x [16 x <2 x i64>]], align 16
  %10 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %10) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 -86, i64 256, i1 false)
  %11 = icmp eq i32 %4, 8
  br i1 %11, label %12, label %440

12:                                               ; preds = %5
  %13 = bitcast [16 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %13) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 -86, i64 256, i1 false)
  %14 = bitcast [16 x <2 x i64>]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %14) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %14, i8 -86, i64 256, i1 false)
  %15 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  %16 = icmp ult i32 %3, 2
  %17 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %8, i64 0, i64 0
  br label %38

18:                                               ; preds = %264
  %19 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %20 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %21 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %22 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %23 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %24 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %25 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %26 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %27 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %28 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %29 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %30 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %31 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %32 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %33 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %34 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %35 = and i32 %3, -3
  %36 = icmp eq i32 %35, 0
  %37 = sext i32 %2 to i64
  br label %268

38:                                               ; preds = %264, %12
  %39 = phi <2 x i64>* [ %15, %12 ], [ %17, %264 ]
  %40 = phi i32 [ 0, %12 ], [ %266, %264 ]
  %41 = phi i32* [ %0, %12 ], [ %265, %264 ]
  %42 = bitcast i32* %41 to <4 x i32>*
  %43 = load <4 x i32>, <4 x i32>* %42, align 16
  %44 = getelementptr inbounds i32, i32* %41, i64 4
  %45 = bitcast i32* %44 to <4 x i32>*
  %46 = load <4 x i32>, <4 x i32>* %45, align 16
  %47 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %43, <4 x i32> %46) #6
  %48 = bitcast <2 x i64>* %39 to <8 x i16>*
  store <8 x i16> %47, <8 x i16>* %48, align 16
  %49 = getelementptr inbounds i32, i32* %41, i64 16
  %50 = bitcast i32* %49 to <4 x i32>*
  %51 = load <4 x i32>, <4 x i32>* %50, align 16
  %52 = getelementptr inbounds i32, i32* %41, i64 20
  %53 = bitcast i32* %52 to <4 x i32>*
  %54 = load <4 x i32>, <4 x i32>* %53, align 16
  %55 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %51, <4 x i32> %54) #6
  %56 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 1
  %57 = bitcast <2 x i64>* %56 to <8 x i16>*
  store <8 x i16> %55, <8 x i16>* %57, align 16
  %58 = getelementptr inbounds i32, i32* %41, i64 32
  %59 = bitcast i32* %58 to <4 x i32>*
  %60 = load <4 x i32>, <4 x i32>* %59, align 16
  %61 = getelementptr inbounds i32, i32* %41, i64 36
  %62 = bitcast i32* %61 to <4 x i32>*
  %63 = load <4 x i32>, <4 x i32>* %62, align 16
  %64 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %60, <4 x i32> %63) #6
  %65 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 2
  %66 = bitcast <2 x i64>* %65 to <8 x i16>*
  store <8 x i16> %64, <8 x i16>* %66, align 16
  %67 = getelementptr inbounds i32, i32* %41, i64 48
  %68 = bitcast i32* %67 to <4 x i32>*
  %69 = load <4 x i32>, <4 x i32>* %68, align 16
  %70 = getelementptr inbounds i32, i32* %41, i64 52
  %71 = bitcast i32* %70 to <4 x i32>*
  %72 = load <4 x i32>, <4 x i32>* %71, align 16
  %73 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %69, <4 x i32> %72) #6
  %74 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 3
  %75 = bitcast <2 x i64>* %74 to <8 x i16>*
  store <8 x i16> %73, <8 x i16>* %75, align 16
  %76 = getelementptr inbounds i32, i32* %41, i64 64
  %77 = bitcast i32* %76 to <4 x i32>*
  %78 = load <4 x i32>, <4 x i32>* %77, align 16
  %79 = getelementptr inbounds i32, i32* %41, i64 68
  %80 = bitcast i32* %79 to <4 x i32>*
  %81 = load <4 x i32>, <4 x i32>* %80, align 16
  %82 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %78, <4 x i32> %81) #6
  %83 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 4
  %84 = bitcast <2 x i64>* %83 to <8 x i16>*
  store <8 x i16> %82, <8 x i16>* %84, align 16
  %85 = getelementptr inbounds i32, i32* %41, i64 80
  %86 = bitcast i32* %85 to <4 x i32>*
  %87 = load <4 x i32>, <4 x i32>* %86, align 16
  %88 = getelementptr inbounds i32, i32* %41, i64 84
  %89 = bitcast i32* %88 to <4 x i32>*
  %90 = load <4 x i32>, <4 x i32>* %89, align 16
  %91 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %87, <4 x i32> %90) #6
  %92 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 5
  %93 = bitcast <2 x i64>* %92 to <8 x i16>*
  store <8 x i16> %91, <8 x i16>* %93, align 16
  %94 = getelementptr inbounds i32, i32* %41, i64 96
  %95 = bitcast i32* %94 to <4 x i32>*
  %96 = load <4 x i32>, <4 x i32>* %95, align 16
  %97 = getelementptr inbounds i32, i32* %41, i64 100
  %98 = bitcast i32* %97 to <4 x i32>*
  %99 = load <4 x i32>, <4 x i32>* %98, align 16
  %100 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %96, <4 x i32> %99) #6
  %101 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 6
  %102 = bitcast <2 x i64>* %101 to <8 x i16>*
  store <8 x i16> %100, <8 x i16>* %102, align 16
  %103 = getelementptr inbounds i32, i32* %41, i64 112
  %104 = bitcast i32* %103 to <4 x i32>*
  %105 = load <4 x i32>, <4 x i32>* %104, align 16
  %106 = getelementptr inbounds i32, i32* %41, i64 116
  %107 = bitcast i32* %106 to <4 x i32>*
  %108 = load <4 x i32>, <4 x i32>* %107, align 16
  %109 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %105, <4 x i32> %108) #6
  %110 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 7
  %111 = shufflevector <8 x i16> %47, <8 x i16> %55, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %112 = shufflevector <8 x i16> %64, <8 x i16> %73, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %113 = shufflevector <8 x i16> %82, <8 x i16> %91, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %114 = shufflevector <8 x i16> %100, <8 x i16> %109, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %115 = shufflevector <8 x i16> %47, <8 x i16> %55, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %116 = shufflevector <8 x i16> %64, <8 x i16> %73, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %117 = shufflevector <8 x i16> %82, <8 x i16> %91, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %100, <8 x i16> %109, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %111 to <4 x i32>
  %120 = bitcast <8 x i16> %112 to <4 x i32>
  %121 = shufflevector <4 x i32> %119, <4 x i32> %120, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %122 = bitcast <4 x i32> %121 to <2 x i64>
  %123 = bitcast <8 x i16> %113 to <4 x i32>
  %124 = bitcast <8 x i16> %114 to <4 x i32>
  %125 = shufflevector <4 x i32> %123, <4 x i32> %124, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %126 = bitcast <4 x i32> %125 to <2 x i64>
  %127 = bitcast <8 x i16> %115 to <4 x i32>
  %128 = bitcast <8 x i16> %116 to <4 x i32>
  %129 = shufflevector <4 x i32> %127, <4 x i32> %128, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %130 = bitcast <4 x i32> %129 to <2 x i64>
  %131 = bitcast <8 x i16> %117 to <4 x i32>
  %132 = bitcast <8 x i16> %118 to <4 x i32>
  %133 = shufflevector <4 x i32> %131, <4 x i32> %132, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %134 = bitcast <4 x i32> %133 to <2 x i64>
  %135 = shufflevector <4 x i32> %119, <4 x i32> %120, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %136 = bitcast <4 x i32> %135 to <2 x i64>
  %137 = shufflevector <4 x i32> %123, <4 x i32> %124, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %138 = bitcast <4 x i32> %137 to <2 x i64>
  %139 = shufflevector <4 x i32> %127, <4 x i32> %128, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %140 = bitcast <4 x i32> %139 to <2 x i64>
  %141 = shufflevector <4 x i32> %131, <4 x i32> %132, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %142 = bitcast <4 x i32> %141 to <2 x i64>
  %143 = shufflevector <2 x i64> %122, <2 x i64> %126, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %143, <2 x i64>* %39, align 16
  %144 = shufflevector <2 x i64> %122, <2 x i64> %126, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %144, <2 x i64>* %56, align 16
  %145 = shufflevector <2 x i64> %136, <2 x i64> %138, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %145, <2 x i64>* %65, align 16
  %146 = shufflevector <2 x i64> %136, <2 x i64> %138, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %146, <2 x i64>* %74, align 16
  %147 = shufflevector <2 x i64> %130, <2 x i64> %134, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %147, <2 x i64>* %83, align 16
  %148 = shufflevector <2 x i64> %130, <2 x i64> %134, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %148, <2 x i64>* %92, align 16
  %149 = shufflevector <2 x i64> %140, <2 x i64> %142, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %149, <2 x i64>* %101, align 16
  %150 = shufflevector <2 x i64> %140, <2 x i64> %142, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %150, <2 x i64>* %110, align 16
  %151 = getelementptr inbounds i32, i32* %41, i64 8
  %152 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 8
  %153 = bitcast i32* %151 to <4 x i32>*
  %154 = load <4 x i32>, <4 x i32>* %153, align 16
  %155 = getelementptr inbounds i32, i32* %41, i64 12
  %156 = bitcast i32* %155 to <4 x i32>*
  %157 = load <4 x i32>, <4 x i32>* %156, align 16
  %158 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %154, <4 x i32> %157) #6
  %159 = bitcast <2 x i64>* %152 to <8 x i16>*
  store <8 x i16> %158, <8 x i16>* %159, align 16
  %160 = getelementptr inbounds i32, i32* %41, i64 24
  %161 = bitcast i32* %160 to <4 x i32>*
  %162 = load <4 x i32>, <4 x i32>* %161, align 16
  %163 = getelementptr inbounds i32, i32* %41, i64 28
  %164 = bitcast i32* %163 to <4 x i32>*
  %165 = load <4 x i32>, <4 x i32>* %164, align 16
  %166 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %162, <4 x i32> %165) #6
  %167 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 9
  %168 = bitcast <2 x i64>* %167 to <8 x i16>*
  store <8 x i16> %166, <8 x i16>* %168, align 16
  %169 = getelementptr inbounds i32, i32* %41, i64 40
  %170 = bitcast i32* %169 to <4 x i32>*
  %171 = load <4 x i32>, <4 x i32>* %170, align 16
  %172 = getelementptr inbounds i32, i32* %41, i64 44
  %173 = bitcast i32* %172 to <4 x i32>*
  %174 = load <4 x i32>, <4 x i32>* %173, align 16
  %175 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %171, <4 x i32> %174) #6
  %176 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 10
  %177 = bitcast <2 x i64>* %176 to <8 x i16>*
  store <8 x i16> %175, <8 x i16>* %177, align 16
  %178 = getelementptr inbounds i32, i32* %41, i64 56
  %179 = bitcast i32* %178 to <4 x i32>*
  %180 = load <4 x i32>, <4 x i32>* %179, align 16
  %181 = getelementptr inbounds i32, i32* %41, i64 60
  %182 = bitcast i32* %181 to <4 x i32>*
  %183 = load <4 x i32>, <4 x i32>* %182, align 16
  %184 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %180, <4 x i32> %183) #6
  %185 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 11
  %186 = bitcast <2 x i64>* %185 to <8 x i16>*
  store <8 x i16> %184, <8 x i16>* %186, align 16
  %187 = getelementptr inbounds i32, i32* %41, i64 72
  %188 = bitcast i32* %187 to <4 x i32>*
  %189 = load <4 x i32>, <4 x i32>* %188, align 16
  %190 = getelementptr inbounds i32, i32* %41, i64 76
  %191 = bitcast i32* %190 to <4 x i32>*
  %192 = load <4 x i32>, <4 x i32>* %191, align 16
  %193 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %189, <4 x i32> %192) #6
  %194 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 12
  %195 = bitcast <2 x i64>* %194 to <8 x i16>*
  store <8 x i16> %193, <8 x i16>* %195, align 16
  %196 = getelementptr inbounds i32, i32* %41, i64 88
  %197 = bitcast i32* %196 to <4 x i32>*
  %198 = load <4 x i32>, <4 x i32>* %197, align 16
  %199 = getelementptr inbounds i32, i32* %41, i64 92
  %200 = bitcast i32* %199 to <4 x i32>*
  %201 = load <4 x i32>, <4 x i32>* %200, align 16
  %202 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %198, <4 x i32> %201) #6
  %203 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 13
  %204 = bitcast <2 x i64>* %203 to <8 x i16>*
  store <8 x i16> %202, <8 x i16>* %204, align 16
  %205 = getelementptr inbounds i32, i32* %41, i64 104
  %206 = bitcast i32* %205 to <4 x i32>*
  %207 = load <4 x i32>, <4 x i32>* %206, align 16
  %208 = getelementptr inbounds i32, i32* %41, i64 108
  %209 = bitcast i32* %208 to <4 x i32>*
  %210 = load <4 x i32>, <4 x i32>* %209, align 16
  %211 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %207, <4 x i32> %210) #6
  %212 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 14
  %213 = bitcast <2 x i64>* %212 to <8 x i16>*
  store <8 x i16> %211, <8 x i16>* %213, align 16
  %214 = getelementptr inbounds i32, i32* %41, i64 120
  %215 = bitcast i32* %214 to <4 x i32>*
  %216 = load <4 x i32>, <4 x i32>* %215, align 16
  %217 = getelementptr inbounds i32, i32* %41, i64 124
  %218 = bitcast i32* %217 to <4 x i32>*
  %219 = load <4 x i32>, <4 x i32>* %218, align 16
  %220 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %216, <4 x i32> %219) #6
  %221 = getelementptr inbounds <2 x i64>, <2 x i64>* %39, i64 15
  %222 = shufflevector <8 x i16> %158, <8 x i16> %166, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %223 = shufflevector <8 x i16> %175, <8 x i16> %184, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %224 = shufflevector <8 x i16> %193, <8 x i16> %202, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %225 = shufflevector <8 x i16> %211, <8 x i16> %220, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %226 = shufflevector <8 x i16> %158, <8 x i16> %166, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %227 = shufflevector <8 x i16> %175, <8 x i16> %184, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %228 = shufflevector <8 x i16> %193, <8 x i16> %202, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %229 = shufflevector <8 x i16> %211, <8 x i16> %220, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %230 = bitcast <8 x i16> %222 to <4 x i32>
  %231 = bitcast <8 x i16> %223 to <4 x i32>
  %232 = shufflevector <4 x i32> %230, <4 x i32> %231, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %233 = bitcast <4 x i32> %232 to <2 x i64>
  %234 = bitcast <8 x i16> %224 to <4 x i32>
  %235 = bitcast <8 x i16> %225 to <4 x i32>
  %236 = shufflevector <4 x i32> %234, <4 x i32> %235, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %237 = bitcast <4 x i32> %236 to <2 x i64>
  %238 = bitcast <8 x i16> %226 to <4 x i32>
  %239 = bitcast <8 x i16> %227 to <4 x i32>
  %240 = shufflevector <4 x i32> %238, <4 x i32> %239, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %241 = bitcast <4 x i32> %240 to <2 x i64>
  %242 = bitcast <8 x i16> %228 to <4 x i32>
  %243 = bitcast <8 x i16> %229 to <4 x i32>
  %244 = shufflevector <4 x i32> %242, <4 x i32> %243, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %245 = bitcast <4 x i32> %244 to <2 x i64>
  %246 = shufflevector <4 x i32> %230, <4 x i32> %231, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %247 = bitcast <4 x i32> %246 to <2 x i64>
  %248 = shufflevector <4 x i32> %234, <4 x i32> %235, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %249 = bitcast <4 x i32> %248 to <2 x i64>
  %250 = shufflevector <4 x i32> %238, <4 x i32> %239, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %251 = bitcast <4 x i32> %250 to <2 x i64>
  %252 = shufflevector <4 x i32> %242, <4 x i32> %243, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %253 = bitcast <4 x i32> %252 to <2 x i64>
  %254 = shufflevector <2 x i64> %233, <2 x i64> %237, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %254, <2 x i64>* %152, align 16
  %255 = shufflevector <2 x i64> %233, <2 x i64> %237, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %255, <2 x i64>* %167, align 16
  %256 = shufflevector <2 x i64> %247, <2 x i64> %249, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %256, <2 x i64>* %176, align 16
  %257 = shufflevector <2 x i64> %247, <2 x i64> %249, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %257, <2 x i64>* %185, align 16
  %258 = shufflevector <2 x i64> %241, <2 x i64> %245, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %258, <2 x i64>* %194, align 16
  %259 = shufflevector <2 x i64> %241, <2 x i64> %245, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %259, <2 x i64>* %203, align 16
  %260 = shufflevector <2 x i64> %251, <2 x i64> %253, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %260, <2 x i64>* %212, align 16
  %261 = shufflevector <2 x i64> %251, <2 x i64> %253, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %261, <2 x i64>* %221, align 16
  br i1 %16, label %262, label %263

262:                                              ; preds = %38
  call fastcc void @idct16_8col(<2 x i64>* %39, <2 x i64>* %39)
  br label %264

263:                                              ; preds = %38
  call void @vpx_iadst16_8col_sse2(<2 x i64>* %39) #6
  br label %264

264:                                              ; preds = %263, %262
  %265 = getelementptr inbounds i32, i32* %41, i64 128
  %266 = add nuw nsw i32 %40, 1
  %267 = icmp eq i32 %266, 2
  br i1 %267, label %18, label %38

268:                                              ; preds = %18, %435
  %269 = phi i64 [ 0, %18 ], [ %437, %435 ]
  %270 = phi i16* [ %1, %18 ], [ %436, %435 ]
  %271 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 %269
  %272 = bitcast <2 x i64>* %271 to <8 x i16>*
  %273 = load <8 x i16>, <8 x i16>* %272, align 16
  %274 = getelementptr inbounds <2 x i64>, <2 x i64>* %271, i64 1
  %275 = bitcast <2 x i64>* %274 to <8 x i16>*
  %276 = load <8 x i16>, <8 x i16>* %275, align 16
  %277 = shufflevector <8 x i16> %273, <8 x i16> %276, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %278 = getelementptr inbounds <2 x i64>, <2 x i64>* %271, i64 2
  %279 = bitcast <2 x i64>* %278 to <8 x i16>*
  %280 = load <8 x i16>, <8 x i16>* %279, align 16
  %281 = getelementptr inbounds <2 x i64>, <2 x i64>* %271, i64 3
  %282 = bitcast <2 x i64>* %281 to <8 x i16>*
  %283 = load <8 x i16>, <8 x i16>* %282, align 16
  %284 = shufflevector <8 x i16> %280, <8 x i16> %283, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %285 = getelementptr inbounds <2 x i64>, <2 x i64>* %271, i64 4
  %286 = bitcast <2 x i64>* %285 to <8 x i16>*
  %287 = load <8 x i16>, <8 x i16>* %286, align 16
  %288 = getelementptr inbounds <2 x i64>, <2 x i64>* %271, i64 5
  %289 = bitcast <2 x i64>* %288 to <8 x i16>*
  %290 = load <8 x i16>, <8 x i16>* %289, align 16
  %291 = shufflevector <8 x i16> %287, <8 x i16> %290, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %292 = getelementptr inbounds <2 x i64>, <2 x i64>* %271, i64 6
  %293 = bitcast <2 x i64>* %292 to <8 x i16>*
  %294 = load <8 x i16>, <8 x i16>* %293, align 16
  %295 = getelementptr inbounds <2 x i64>, <2 x i64>* %271, i64 7
  %296 = bitcast <2 x i64>* %295 to <8 x i16>*
  %297 = load <8 x i16>, <8 x i16>* %296, align 16
  %298 = shufflevector <8 x i16> %294, <8 x i16> %297, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %299 = shufflevector <8 x i16> %273, <8 x i16> %276, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %300 = shufflevector <8 x i16> %280, <8 x i16> %283, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %301 = shufflevector <8 x i16> %287, <8 x i16> %290, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %302 = shufflevector <8 x i16> %294, <8 x i16> %297, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %303 = bitcast <8 x i16> %277 to <4 x i32>
  %304 = bitcast <8 x i16> %284 to <4 x i32>
  %305 = shufflevector <4 x i32> %303, <4 x i32> %304, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %306 = bitcast <4 x i32> %305 to <2 x i64>
  %307 = bitcast <8 x i16> %291 to <4 x i32>
  %308 = bitcast <8 x i16> %298 to <4 x i32>
  %309 = shufflevector <4 x i32> %307, <4 x i32> %308, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %310 = bitcast <4 x i32> %309 to <2 x i64>
  %311 = bitcast <8 x i16> %299 to <4 x i32>
  %312 = bitcast <8 x i16> %300 to <4 x i32>
  %313 = shufflevector <4 x i32> %311, <4 x i32> %312, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %314 = bitcast <4 x i32> %313 to <2 x i64>
  %315 = bitcast <8 x i16> %301 to <4 x i32>
  %316 = bitcast <8 x i16> %302 to <4 x i32>
  %317 = shufflevector <4 x i32> %315, <4 x i32> %316, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %318 = bitcast <4 x i32> %317 to <2 x i64>
  %319 = shufflevector <4 x i32> %303, <4 x i32> %304, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %320 = bitcast <4 x i32> %319 to <2 x i64>
  %321 = shufflevector <4 x i32> %307, <4 x i32> %308, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %322 = bitcast <4 x i32> %321 to <2 x i64>
  %323 = shufflevector <4 x i32> %311, <4 x i32> %312, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %324 = bitcast <4 x i32> %323 to <2 x i64>
  %325 = shufflevector <4 x i32> %315, <4 x i32> %316, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %326 = bitcast <4 x i32> %325 to <2 x i64>
  %327 = shufflevector <2 x i64> %306, <2 x i64> %310, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %327, <2 x i64>* %19, align 16
  %328 = shufflevector <2 x i64> %306, <2 x i64> %310, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %328, <2 x i64>* %20, align 16
  %329 = shufflevector <2 x i64> %320, <2 x i64> %322, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %329, <2 x i64>* %21, align 16
  %330 = shufflevector <2 x i64> %320, <2 x i64> %322, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %330, <2 x i64>* %22, align 16
  %331 = shufflevector <2 x i64> %314, <2 x i64> %318, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %331, <2 x i64>* %23, align 16
  %332 = shufflevector <2 x i64> %314, <2 x i64> %318, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %332, <2 x i64>* %24, align 16
  %333 = shufflevector <2 x i64> %324, <2 x i64> %326, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %333, <2 x i64>* %25, align 16
  %334 = shufflevector <2 x i64> %324, <2 x i64> %326, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %334, <2 x i64>* %26, align 16
  %335 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %8, i64 0, i64 %269
  %336 = bitcast <2 x i64>* %335 to <8 x i16>*
  %337 = load <8 x i16>, <8 x i16>* %336, align 16
  %338 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 1
  %339 = bitcast <2 x i64>* %338 to <8 x i16>*
  %340 = load <8 x i16>, <8 x i16>* %339, align 16
  %341 = shufflevector <8 x i16> %337, <8 x i16> %340, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %342 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 2
  %343 = bitcast <2 x i64>* %342 to <8 x i16>*
  %344 = load <8 x i16>, <8 x i16>* %343, align 16
  %345 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 3
  %346 = bitcast <2 x i64>* %345 to <8 x i16>*
  %347 = load <8 x i16>, <8 x i16>* %346, align 16
  %348 = shufflevector <8 x i16> %344, <8 x i16> %347, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %349 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 4
  %350 = bitcast <2 x i64>* %349 to <8 x i16>*
  %351 = load <8 x i16>, <8 x i16>* %350, align 16
  %352 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 5
  %353 = bitcast <2 x i64>* %352 to <8 x i16>*
  %354 = load <8 x i16>, <8 x i16>* %353, align 16
  %355 = shufflevector <8 x i16> %351, <8 x i16> %354, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %356 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 6
  %357 = bitcast <2 x i64>* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 7
  %360 = bitcast <2 x i64>* %359 to <8 x i16>*
  %361 = load <8 x i16>, <8 x i16>* %360, align 16
  %362 = shufflevector <8 x i16> %358, <8 x i16> %361, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %363 = shufflevector <8 x i16> %337, <8 x i16> %340, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %364 = shufflevector <8 x i16> %344, <8 x i16> %347, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %365 = shufflevector <8 x i16> %351, <8 x i16> %354, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %366 = shufflevector <8 x i16> %358, <8 x i16> %361, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %367 = bitcast <8 x i16> %341 to <4 x i32>
  %368 = bitcast <8 x i16> %348 to <4 x i32>
  %369 = shufflevector <4 x i32> %367, <4 x i32> %368, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %370 = bitcast <4 x i32> %369 to <2 x i64>
  %371 = bitcast <8 x i16> %355 to <4 x i32>
  %372 = bitcast <8 x i16> %362 to <4 x i32>
  %373 = shufflevector <4 x i32> %371, <4 x i32> %372, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %374 = bitcast <4 x i32> %373 to <2 x i64>
  %375 = bitcast <8 x i16> %363 to <4 x i32>
  %376 = bitcast <8 x i16> %364 to <4 x i32>
  %377 = shufflevector <4 x i32> %375, <4 x i32> %376, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %378 = bitcast <4 x i32> %377 to <2 x i64>
  %379 = bitcast <8 x i16> %365 to <4 x i32>
  %380 = bitcast <8 x i16> %366 to <4 x i32>
  %381 = shufflevector <4 x i32> %379, <4 x i32> %380, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %382 = bitcast <4 x i32> %381 to <2 x i64>
  %383 = shufflevector <4 x i32> %367, <4 x i32> %368, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %384 = bitcast <4 x i32> %383 to <2 x i64>
  %385 = shufflevector <4 x i32> %371, <4 x i32> %372, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %386 = bitcast <4 x i32> %385 to <2 x i64>
  %387 = shufflevector <4 x i32> %375, <4 x i32> %376, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %388 = bitcast <4 x i32> %387 to <2 x i64>
  %389 = shufflevector <4 x i32> %379, <4 x i32> %380, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %390 = bitcast <4 x i32> %389 to <2 x i64>
  %391 = shufflevector <2 x i64> %370, <2 x i64> %374, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %391, <2 x i64>* %27, align 16
  %392 = shufflevector <2 x i64> %370, <2 x i64> %374, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %392, <2 x i64>* %28, align 16
  %393 = shufflevector <2 x i64> %384, <2 x i64> %386, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %393, <2 x i64>* %29, align 16
  %394 = shufflevector <2 x i64> %384, <2 x i64> %386, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %394, <2 x i64>* %30, align 16
  %395 = shufflevector <2 x i64> %378, <2 x i64> %382, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %395, <2 x i64>* %31, align 16
  %396 = shufflevector <2 x i64> %378, <2 x i64> %382, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %396, <2 x i64>* %32, align 16
  %397 = shufflevector <2 x i64> %388, <2 x i64> %390, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %397, <2 x i64>* %33, align 16
  %398 = shufflevector <2 x i64> %388, <2 x i64> %390, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %398, <2 x i64>* %34, align 16
  br i1 %36, label %399, label %400

399:                                              ; preds = %268
  call fastcc void @idct16_8col(<2 x i64>* nonnull %19, <2 x i64>* nonnull %19)
  br label %401

400:                                              ; preds = %268
  call void @vpx_iadst16_8col_sse2(<2 x i64>* nonnull %19) #6
  br label %401

401:                                              ; preds = %400, %399
  br label %402

402:                                              ; preds = %402, %401
  %403 = phi i64 [ 0, %401 ], [ %433, %402 ]
  %404 = mul nsw i64 %403, %37
  %405 = getelementptr inbounds i16, i16* %270, i64 %404
  %406 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %403
  %407 = bitcast <2 x i64>* %406 to <8 x i16>*
  %408 = load <8 x i16>, <8 x i16>* %407, align 16
  %409 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %408, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #6
  %410 = ashr <8 x i16> %409, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %411 = bitcast i16* %405 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %412, <8 x i16> %410) #6
  %414 = icmp sgt <8 x i16> %413, zeroinitializer
  %415 = select <8 x i1> %414, <8 x i16> %413, <8 x i16> zeroinitializer
  %416 = icmp slt <8 x i16> %415, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %417 = select <8 x i1> %416, <8 x i16> %415, <8 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  store <8 x i16> %417, <8 x i16>* %411, align 16
  %418 = or i64 %403, 1
  %419 = mul nsw i64 %418, %37
  %420 = getelementptr inbounds i16, i16* %270, i64 %419
  %421 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %418
  %422 = bitcast <2 x i64>* %421 to <8 x i16>*
  %423 = load <8 x i16>, <8 x i16>* %422, align 16
  %424 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %423, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #6
  %425 = ashr <8 x i16> %424, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %426 = bitcast i16* %420 to <8 x i16>*
  %427 = load <8 x i16>, <8 x i16>* %426, align 16
  %428 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %427, <8 x i16> %425) #6
  %429 = icmp sgt <8 x i16> %428, zeroinitializer
  %430 = select <8 x i1> %429, <8 x i16> %428, <8 x i16> zeroinitializer
  %431 = icmp slt <8 x i16> %430, <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  %432 = select <8 x i1> %431, <8 x i16> %430, <8 x i16> <i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255, i16 255>
  store <8 x i16> %432, <8 x i16>* %426, align 16
  %433 = add nuw nsw i64 %403, 2
  %434 = icmp eq i64 %433, 16
  br i1 %434, label %435, label %402

435:                                              ; preds = %402
  %436 = getelementptr inbounds i16, i16* %270, i64 8
  %437 = add nuw nsw i64 %269, 8
  %438 = icmp ult i64 %437, 16
  br i1 %438, label %268, label %439

439:                                              ; preds = %435
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %14) #6
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %13) #6
  br label %729

440:                                              ; preds = %5
  %441 = bitcast [4 x [16 x <2 x i64>]]* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %441) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %441, i8 -86, i64 1024, i1 false)
  %442 = icmp ult i32 %3, 2
  br label %463

443:                                              ; preds = %593
  %444 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %445 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %446 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %447 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %448 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %449 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %450 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %451 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %452 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %453 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %454 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %455 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %456 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %457 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %458 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %459 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %460 = and i32 %3, -3
  %461 = icmp eq i32 %460, 0
  %462 = sext i32 %2 to i64
  br label %597

463:                                              ; preds = %593, %440
  %464 = phi i64 [ 0, %440 ], [ %595, %593 ]
  %465 = phi i32* [ %0, %440 ], [ %594, %593 ]
  %466 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 0
  %467 = bitcast i32* %465 to <2 x i64>*
  %468 = load <2 x i64>, <2 x i64>* %467, align 16
  store <2 x i64> %468, <2 x i64>* %466, align 16
  %469 = getelementptr inbounds i32, i32* %465, i64 4
  %470 = bitcast i32* %469 to <2 x i64>*
  %471 = load <2 x i64>, <2 x i64>* %470, align 16
  %472 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 1
  store <2 x i64> %471, <2 x i64>* %472, align 16
  %473 = getelementptr inbounds i32, i32* %465, i64 16
  %474 = bitcast i32* %473 to <2 x i64>*
  %475 = load <2 x i64>, <2 x i64>* %474, align 16
  %476 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 2
  store <2 x i64> %475, <2 x i64>* %476, align 16
  %477 = getelementptr inbounds i32, i32* %465, i64 20
  %478 = bitcast i32* %477 to <2 x i64>*
  %479 = load <2 x i64>, <2 x i64>* %478, align 16
  %480 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 3
  store <2 x i64> %479, <2 x i64>* %480, align 16
  %481 = getelementptr inbounds i32, i32* %465, i64 32
  %482 = bitcast i32* %481 to <2 x i64>*
  %483 = load <2 x i64>, <2 x i64>* %482, align 16
  %484 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 4
  store <2 x i64> %483, <2 x i64>* %484, align 16
  %485 = getelementptr inbounds i32, i32* %465, i64 36
  %486 = bitcast i32* %485 to <2 x i64>*
  %487 = load <2 x i64>, <2 x i64>* %486, align 16
  %488 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 5
  store <2 x i64> %487, <2 x i64>* %488, align 16
  %489 = getelementptr inbounds i32, i32* %465, i64 48
  %490 = bitcast i32* %489 to <2 x i64>*
  %491 = load <2 x i64>, <2 x i64>* %490, align 16
  %492 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 6
  store <2 x i64> %491, <2 x i64>* %492, align 16
  %493 = getelementptr inbounds i32, i32* %465, i64 52
  %494 = bitcast i32* %493 to <4 x i32>*
  %495 = load <4 x i32>, <4 x i32>* %494, align 16
  %496 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 7
  %497 = bitcast <2 x i64> %468 to <4 x i32>
  %498 = bitcast <2 x i64> %475 to <4 x i32>
  %499 = shufflevector <4 x i32> %497, <4 x i32> %498, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %500 = bitcast <4 x i32> %499 to <2 x i64>
  %501 = bitcast <2 x i64> %483 to <4 x i32>
  %502 = bitcast <2 x i64> %491 to <4 x i32>
  %503 = shufflevector <4 x i32> %501, <4 x i32> %502, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %504 = bitcast <4 x i32> %503 to <2 x i64>
  %505 = shufflevector <4 x i32> %497, <4 x i32> %498, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %506 = bitcast <4 x i32> %505 to <2 x i64>
  %507 = shufflevector <4 x i32> %501, <4 x i32> %502, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %508 = bitcast <4 x i32> %507 to <2 x i64>
  %509 = bitcast <2 x i64> %471 to <4 x i32>
  %510 = bitcast <2 x i64> %479 to <4 x i32>
  %511 = shufflevector <4 x i32> %509, <4 x i32> %510, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %512 = bitcast <4 x i32> %511 to <2 x i64>
  %513 = bitcast <2 x i64> %487 to <4 x i32>
  %514 = shufflevector <4 x i32> %513, <4 x i32> %495, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %515 = bitcast <4 x i32> %514 to <2 x i64>
  %516 = shufflevector <4 x i32> %509, <4 x i32> %510, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %517 = bitcast <4 x i32> %516 to <2 x i64>
  %518 = shufflevector <4 x i32> %513, <4 x i32> %495, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %519 = bitcast <4 x i32> %518 to <2 x i64>
  %520 = shufflevector <2 x i64> %500, <2 x i64> %504, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %520, <2 x i64>* %466, align 16
  %521 = shufflevector <2 x i64> %500, <2 x i64> %504, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %521, <2 x i64>* %472, align 16
  %522 = shufflevector <2 x i64> %506, <2 x i64> %508, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %522, <2 x i64>* %476, align 16
  %523 = shufflevector <2 x i64> %506, <2 x i64> %508, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %523, <2 x i64>* %480, align 16
  %524 = shufflevector <2 x i64> %512, <2 x i64> %515, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %524, <2 x i64>* %484, align 16
  %525 = shufflevector <2 x i64> %512, <2 x i64> %515, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %525, <2 x i64>* %488, align 16
  %526 = shufflevector <2 x i64> %517, <2 x i64> %519, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %526, <2 x i64>* %492, align 16
  %527 = shufflevector <2 x i64> %517, <2 x i64> %519, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %527, <2 x i64>* %496, align 16
  %528 = getelementptr inbounds i32, i32* %465, i64 8
  %529 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 8
  %530 = bitcast i32* %528 to <2 x i64>*
  %531 = load <2 x i64>, <2 x i64>* %530, align 16
  store <2 x i64> %531, <2 x i64>* %529, align 16
  %532 = getelementptr inbounds i32, i32* %465, i64 12
  %533 = bitcast i32* %532 to <2 x i64>*
  %534 = load <2 x i64>, <2 x i64>* %533, align 16
  %535 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 9
  store <2 x i64> %534, <2 x i64>* %535, align 16
  %536 = getelementptr inbounds i32, i32* %465, i64 24
  %537 = bitcast i32* %536 to <2 x i64>*
  %538 = load <2 x i64>, <2 x i64>* %537, align 16
  %539 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 10
  store <2 x i64> %538, <2 x i64>* %539, align 16
  %540 = getelementptr inbounds i32, i32* %465, i64 28
  %541 = bitcast i32* %540 to <2 x i64>*
  %542 = load <2 x i64>, <2 x i64>* %541, align 16
  %543 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 11
  store <2 x i64> %542, <2 x i64>* %543, align 16
  %544 = getelementptr inbounds i32, i32* %465, i64 40
  %545 = bitcast i32* %544 to <2 x i64>*
  %546 = load <2 x i64>, <2 x i64>* %545, align 16
  %547 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 12
  store <2 x i64> %546, <2 x i64>* %547, align 16
  %548 = getelementptr inbounds i32, i32* %465, i64 44
  %549 = bitcast i32* %548 to <2 x i64>*
  %550 = load <2 x i64>, <2 x i64>* %549, align 16
  %551 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 13
  store <2 x i64> %550, <2 x i64>* %551, align 16
  %552 = getelementptr inbounds i32, i32* %465, i64 56
  %553 = bitcast i32* %552 to <2 x i64>*
  %554 = load <2 x i64>, <2 x i64>* %553, align 16
  %555 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 14
  store <2 x i64> %554, <2 x i64>* %555, align 16
  %556 = getelementptr inbounds i32, i32* %465, i64 60
  %557 = bitcast i32* %556 to <4 x i32>*
  %558 = load <4 x i32>, <4 x i32>* %557, align 16
  %559 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 %464, i64 15
  %560 = bitcast <2 x i64> %531 to <4 x i32>
  %561 = bitcast <2 x i64> %538 to <4 x i32>
  %562 = shufflevector <4 x i32> %560, <4 x i32> %561, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %563 = bitcast <4 x i32> %562 to <2 x i64>
  %564 = bitcast <2 x i64> %546 to <4 x i32>
  %565 = bitcast <2 x i64> %554 to <4 x i32>
  %566 = shufflevector <4 x i32> %564, <4 x i32> %565, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %567 = bitcast <4 x i32> %566 to <2 x i64>
  %568 = shufflevector <4 x i32> %560, <4 x i32> %561, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %569 = bitcast <4 x i32> %568 to <2 x i64>
  %570 = shufflevector <4 x i32> %564, <4 x i32> %565, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %571 = bitcast <4 x i32> %570 to <2 x i64>
  %572 = bitcast <2 x i64> %534 to <4 x i32>
  %573 = bitcast <2 x i64> %542 to <4 x i32>
  %574 = shufflevector <4 x i32> %572, <4 x i32> %573, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %575 = bitcast <4 x i32> %574 to <2 x i64>
  %576 = bitcast <2 x i64> %550 to <4 x i32>
  %577 = shufflevector <4 x i32> %576, <4 x i32> %558, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %578 = bitcast <4 x i32> %577 to <2 x i64>
  %579 = shufflevector <4 x i32> %572, <4 x i32> %573, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %580 = bitcast <4 x i32> %579 to <2 x i64>
  %581 = shufflevector <4 x i32> %576, <4 x i32> %558, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %582 = bitcast <4 x i32> %581 to <2 x i64>
  %583 = shufflevector <2 x i64> %563, <2 x i64> %567, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %583, <2 x i64>* %529, align 16
  %584 = shufflevector <2 x i64> %563, <2 x i64> %567, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %584, <2 x i64>* %535, align 16
  %585 = shufflevector <2 x i64> %569, <2 x i64> %571, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %585, <2 x i64>* %539, align 16
  %586 = shufflevector <2 x i64> %569, <2 x i64> %571, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %586, <2 x i64>* %543, align 16
  %587 = shufflevector <2 x i64> %575, <2 x i64> %578, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %587, <2 x i64>* %547, align 16
  %588 = shufflevector <2 x i64> %575, <2 x i64> %578, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %588, <2 x i64>* %551, align 16
  %589 = shufflevector <2 x i64> %580, <2 x i64> %582, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %589, <2 x i64>* %555, align 16
  %590 = shufflevector <2 x i64> %580, <2 x i64> %582, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %590, <2 x i64>* %559, align 16
  br i1 %442, label %591, label %592

591:                                              ; preds = %463
  call void @vpx_highbd_idct16_4col_sse4_1(<2 x i64>* %466) #6
  br label %593

592:                                              ; preds = %463
  call fastcc void @highbd_iadst16_4col_sse4_1(<2 x i64>* %466)
  br label %593

593:                                              ; preds = %592, %591
  %594 = getelementptr inbounds i32, i32* %465, i64 64
  %595 = add nuw nsw i64 %464, 1
  %596 = icmp eq i64 %595, 4
  br i1 %596, label %443, label %463

597:                                              ; preds = %443, %724
  %598 = phi i64 [ 0, %443 ], [ %726, %724 ]
  %599 = phi i16* [ %1, %443 ], [ %725, %724 ]
  %600 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 0, i64 %598
  %601 = bitcast <2 x i64>* %600 to <4 x i32>*
  %602 = load <4 x i32>, <4 x i32>* %601, align 16
  %603 = getelementptr inbounds <2 x i64>, <2 x i64>* %600, i64 1
  %604 = bitcast <2 x i64>* %603 to <4 x i32>*
  %605 = load <4 x i32>, <4 x i32>* %604, align 16
  %606 = shufflevector <4 x i32> %602, <4 x i32> %605, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %607 = bitcast <4 x i32> %606 to <2 x i64>
  %608 = getelementptr inbounds <2 x i64>, <2 x i64>* %600, i64 2
  %609 = bitcast <2 x i64>* %608 to <4 x i32>*
  %610 = load <4 x i32>, <4 x i32>* %609, align 16
  %611 = getelementptr inbounds <2 x i64>, <2 x i64>* %600, i64 3
  %612 = bitcast <2 x i64>* %611 to <4 x i32>*
  %613 = load <4 x i32>, <4 x i32>* %612, align 16
  %614 = shufflevector <4 x i32> %610, <4 x i32> %613, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %615 = bitcast <4 x i32> %614 to <2 x i64>
  %616 = shufflevector <4 x i32> %602, <4 x i32> %605, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %617 = bitcast <4 x i32> %616 to <2 x i64>
  %618 = shufflevector <4 x i32> %610, <4 x i32> %613, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %619 = bitcast <4 x i32> %618 to <2 x i64>
  %620 = shufflevector <2 x i64> %607, <2 x i64> %615, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %620, <2 x i64>* %444, align 16
  %621 = shufflevector <2 x i64> %607, <2 x i64> %615, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %621, <2 x i64>* %445, align 16
  %622 = shufflevector <2 x i64> %617, <2 x i64> %619, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %622, <2 x i64>* %446, align 16
  %623 = shufflevector <2 x i64> %617, <2 x i64> %619, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %623, <2 x i64>* %447, align 16
  %624 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 1, i64 %598
  %625 = bitcast <2 x i64>* %624 to <4 x i32>*
  %626 = load <4 x i32>, <4 x i32>* %625, align 16
  %627 = getelementptr inbounds <2 x i64>, <2 x i64>* %624, i64 1
  %628 = bitcast <2 x i64>* %627 to <4 x i32>*
  %629 = load <4 x i32>, <4 x i32>* %628, align 16
  %630 = shufflevector <4 x i32> %626, <4 x i32> %629, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %631 = bitcast <4 x i32> %630 to <2 x i64>
  %632 = getelementptr inbounds <2 x i64>, <2 x i64>* %624, i64 2
  %633 = bitcast <2 x i64>* %632 to <4 x i32>*
  %634 = load <4 x i32>, <4 x i32>* %633, align 16
  %635 = getelementptr inbounds <2 x i64>, <2 x i64>* %624, i64 3
  %636 = bitcast <2 x i64>* %635 to <4 x i32>*
  %637 = load <4 x i32>, <4 x i32>* %636, align 16
  %638 = shufflevector <4 x i32> %634, <4 x i32> %637, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %639 = bitcast <4 x i32> %638 to <2 x i64>
  %640 = shufflevector <4 x i32> %626, <4 x i32> %629, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %641 = bitcast <4 x i32> %640 to <2 x i64>
  %642 = shufflevector <4 x i32> %634, <4 x i32> %637, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %643 = bitcast <4 x i32> %642 to <2 x i64>
  %644 = shufflevector <2 x i64> %631, <2 x i64> %639, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %644, <2 x i64>* %448, align 16
  %645 = shufflevector <2 x i64> %631, <2 x i64> %639, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %645, <2 x i64>* %449, align 16
  %646 = shufflevector <2 x i64> %641, <2 x i64> %643, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %646, <2 x i64>* %450, align 16
  %647 = shufflevector <2 x i64> %641, <2 x i64> %643, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %647, <2 x i64>* %451, align 16
  %648 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 2, i64 %598
  %649 = bitcast <2 x i64>* %648 to <4 x i32>*
  %650 = load <4 x i32>, <4 x i32>* %649, align 16
  %651 = getelementptr inbounds <2 x i64>, <2 x i64>* %648, i64 1
  %652 = bitcast <2 x i64>* %651 to <4 x i32>*
  %653 = load <4 x i32>, <4 x i32>* %652, align 16
  %654 = shufflevector <4 x i32> %650, <4 x i32> %653, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %655 = bitcast <4 x i32> %654 to <2 x i64>
  %656 = getelementptr inbounds <2 x i64>, <2 x i64>* %648, i64 2
  %657 = bitcast <2 x i64>* %656 to <4 x i32>*
  %658 = load <4 x i32>, <4 x i32>* %657, align 16
  %659 = getelementptr inbounds <2 x i64>, <2 x i64>* %648, i64 3
  %660 = bitcast <2 x i64>* %659 to <4 x i32>*
  %661 = load <4 x i32>, <4 x i32>* %660, align 16
  %662 = shufflevector <4 x i32> %658, <4 x i32> %661, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %663 = bitcast <4 x i32> %662 to <2 x i64>
  %664 = shufflevector <4 x i32> %650, <4 x i32> %653, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %665 = bitcast <4 x i32> %664 to <2 x i64>
  %666 = shufflevector <4 x i32> %658, <4 x i32> %661, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %667 = bitcast <4 x i32> %666 to <2 x i64>
  %668 = shufflevector <2 x i64> %655, <2 x i64> %663, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %668, <2 x i64>* %452, align 16
  %669 = shufflevector <2 x i64> %655, <2 x i64> %663, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %669, <2 x i64>* %453, align 16
  %670 = shufflevector <2 x i64> %665, <2 x i64> %667, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %670, <2 x i64>* %454, align 16
  %671 = shufflevector <2 x i64> %665, <2 x i64> %667, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %671, <2 x i64>* %455, align 16
  %672 = getelementptr inbounds [4 x [16 x <2 x i64>]], [4 x [16 x <2 x i64>]]* %9, i64 0, i64 3, i64 %598
  %673 = bitcast <2 x i64>* %672 to <4 x i32>*
  %674 = load <4 x i32>, <4 x i32>* %673, align 16
  %675 = getelementptr inbounds <2 x i64>, <2 x i64>* %672, i64 1
  %676 = bitcast <2 x i64>* %675 to <4 x i32>*
  %677 = load <4 x i32>, <4 x i32>* %676, align 16
  %678 = shufflevector <4 x i32> %674, <4 x i32> %677, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %679 = bitcast <4 x i32> %678 to <2 x i64>
  %680 = getelementptr inbounds <2 x i64>, <2 x i64>* %672, i64 2
  %681 = bitcast <2 x i64>* %680 to <4 x i32>*
  %682 = load <4 x i32>, <4 x i32>* %681, align 16
  %683 = getelementptr inbounds <2 x i64>, <2 x i64>* %672, i64 3
  %684 = bitcast <2 x i64>* %683 to <4 x i32>*
  %685 = load <4 x i32>, <4 x i32>* %684, align 16
  %686 = shufflevector <4 x i32> %682, <4 x i32> %685, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %687 = bitcast <4 x i32> %686 to <2 x i64>
  %688 = shufflevector <4 x i32> %674, <4 x i32> %677, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %689 = bitcast <4 x i32> %688 to <2 x i64>
  %690 = shufflevector <4 x i32> %682, <4 x i32> %685, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %691 = bitcast <4 x i32> %690 to <2 x i64>
  %692 = shufflevector <2 x i64> %679, <2 x i64> %687, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %692, <2 x i64>* %456, align 16
  %693 = shufflevector <2 x i64> %679, <2 x i64> %687, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %693, <2 x i64>* %457, align 16
  %694 = shufflevector <2 x i64> %689, <2 x i64> %691, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %694, <2 x i64>* %458, align 16
  %695 = shufflevector <2 x i64> %689, <2 x i64> %691, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %695, <2 x i64>* %459, align 16
  br i1 %461, label %696, label %697

696:                                              ; preds = %597
  call void @vpx_highbd_idct16_4col_sse4_1(<2 x i64>* nonnull %444) #6
  br label %698

697:                                              ; preds = %597
  call fastcc void @highbd_iadst16_4col_sse4_1(<2 x i64>* nonnull %444)
  br label %698

698:                                              ; preds = %697, %696
  %699 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>, i32 %4) #6
  %700 = add <8 x i16> %699, <i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1, i16 -1>
  br label %701

701:                                              ; preds = %701, %698
  %702 = phi i64 [ 0, %698 ], [ %722, %701 ]
  %703 = mul nsw i64 %702, %462
  %704 = getelementptr inbounds i16, i16* %599, i64 %703
  %705 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %702
  %706 = bitcast <2 x i64>* %705 to <4 x i32>*
  %707 = load <4 x i32>, <4 x i32>* %706, align 16
  %708 = add <4 x i32> %707, <i32 32, i32 32, i32 32, i32 32>
  %709 = ashr <4 x i32> %708, <i32 6, i32 6, i32 6, i32 6>
  %710 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %709, <4 x i32> %709) #6
  %711 = bitcast i16* %704 to i64*
  %712 = load i64, i64* %711, align 1
  %713 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %712, i32 0
  %714 = bitcast <2 x i64> %713 to <8 x i16>
  %715 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %714, <8 x i16> %710) #6
  %716 = icmp sgt <8 x i16> %715, zeroinitializer
  %717 = select <8 x i1> %716, <8 x i16> %715, <8 x i16> zeroinitializer
  %718 = icmp slt <8 x i16> %717, %700
  %719 = select <8 x i1> %718, <8 x i16> %717, <8 x i16> %700
  %720 = bitcast <8 x i16> %719 to <2 x i64>
  %721 = extractelement <2 x i64> %720, i32 0
  store i64 %721, i64* %711, align 1
  %722 = add nuw nsw i64 %702, 1
  %723 = icmp eq i64 %722, 16
  br i1 %723, label %724, label %701

724:                                              ; preds = %701
  %725 = getelementptr inbounds i16, i16* %599, i64 4
  %726 = add nuw nsw i64 %598, 4
  %727 = icmp ult i64 %726, 16
  br i1 %727, label %597, label %728

728:                                              ; preds = %724
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %441) #6
  br label %729

729:                                              ; preds = %728, %439
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %10) #6
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: inlinehint nounwind ssp uwtable
define internal fastcc void @idct16_8col(<2 x i64>* nocapture readonly, <2 x i64>* nocapture) unnamed_addr #2 {
  %3 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %4 = bitcast <2 x i64>* %3 to <8 x i16>*
  %5 = load <8 x i16>, <8 x i16>* %4, align 16
  %6 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %7 = bitcast <2 x i64>* %6 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = shufflevector <8 x i16> %5, <8 x i16> %8, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10 = shufflevector <8 x i16> %5, <8 x i16> %8, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #6
  %12 = add <4 x i32> %11, <i32 8192, i32 8192, i32 8192, i32 8192>
  %13 = ashr <4 x i32> %12, <i32 14, i32 14, i32 14, i32 14>
  %14 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #6
  %15 = add <4 x i32> %14, <i32 8192, i32 8192, i32 8192, i32 8192>
  %16 = ashr <4 x i32> %15, <i32 14, i32 14, i32 14, i32 14>
  %17 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %13, <4 x i32> %16) #6
  %18 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #6
  %19 = add <4 x i32> %18, <i32 8192, i32 8192, i32 8192, i32 8192>
  %20 = ashr <4 x i32> %19, <i32 14, i32 14, i32 14, i32 14>
  %21 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #6
  %22 = add <4 x i32> %21, <i32 8192, i32 8192, i32 8192, i32 8192>
  %23 = ashr <4 x i32> %22, <i32 14, i32 14, i32 14, i32 14>
  %24 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %20, <4 x i32> %23) #6
  %25 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %26 = bitcast <2 x i64>* %25 to <8 x i16>*
  %27 = load <8 x i16>, <8 x i16>* %26, align 16
  %28 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %29 = bitcast <2 x i64>* %28 to <8 x i16>*
  %30 = load <8 x i16>, <8 x i16>* %29, align 16
  %31 = shufflevector <8 x i16> %27, <8 x i16> %30, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %32 = shufflevector <8 x i16> %27, <8 x i16> %30, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %33 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %31, <8 x i16> <i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394>) #6
  %34 = add <4 x i32> %33, <i32 8192, i32 8192, i32 8192, i32 8192>
  %35 = ashr <4 x i32> %34, <i32 14, i32 14, i32 14, i32 14>
  %36 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> <i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394>) #6
  %37 = add <4 x i32> %36, <i32 8192, i32 8192, i32 8192, i32 8192>
  %38 = ashr <4 x i32> %37, <i32 14, i32 14, i32 14, i32 14>
  %39 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %35, <4 x i32> %38) #6
  %40 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %31, <8 x i16> <i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665>) #6
  %41 = add <4 x i32> %40, <i32 8192, i32 8192, i32 8192, i32 8192>
  %42 = ashr <4 x i32> %41, <i32 14, i32 14, i32 14, i32 14>
  %43 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> <i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665>) #6
  %44 = add <4 x i32> %43, <i32 8192, i32 8192, i32 8192, i32 8192>
  %45 = ashr <4 x i32> %44, <i32 14, i32 14, i32 14, i32 14>
  %46 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %42, <4 x i32> %45) #6
  %47 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %48 = bitcast <2 x i64>* %47 to <8 x i16>*
  %49 = load <8 x i16>, <8 x i16>* %48, align 16
  %50 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %51 = bitcast <2 x i64>* %50 to <8 x i16>*
  %52 = load <8 x i16>, <8 x i16>* %51, align 16
  %53 = shufflevector <8 x i16> %49, <8 x i16> %52, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %54 = shufflevector <8 x i16> %49, <8 x i16> %52, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %53, <8 x i16> <i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449>) #6
  %56 = add <4 x i32> %55, <i32 8192, i32 8192, i32 8192, i32 8192>
  %57 = ashr <4 x i32> %56, <i32 14, i32 14, i32 14, i32 14>
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %54, <8 x i16> <i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449>) #6
  %59 = add <4 x i32> %58, <i32 8192, i32 8192, i32 8192, i32 8192>
  %60 = ashr <4 x i32> %59, <i32 14, i32 14, i32 14, i32 14>
  %61 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %57, <4 x i32> %60) #6
  %62 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %53, <8 x i16> <i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723>) #6
  %63 = add <4 x i32> %62, <i32 8192, i32 8192, i32 8192, i32 8192>
  %64 = ashr <4 x i32> %63, <i32 14, i32 14, i32 14, i32 14>
  %65 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %54, <8 x i16> <i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723>) #6
  %66 = add <4 x i32> %65, <i32 8192, i32 8192, i32 8192, i32 8192>
  %67 = ashr <4 x i32> %66, <i32 14, i32 14, i32 14, i32 14>
  %68 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %64, <4 x i32> %67) #6
  %69 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %70 = bitcast <2 x i64>* %69 to <8 x i16>*
  %71 = load <8 x i16>, <8 x i16>* %70, align 16
  %72 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %73 = bitcast <2 x i64>* %72 to <8 x i16>*
  %74 = load <8 x i16>, <8 x i16>* %73, align 16
  %75 = shufflevector <8 x i16> %71, <8 x i16> %74, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %76 = shufflevector <8 x i16> %71, <8 x i16> %74, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %77 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %75, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #6
  %78 = add <4 x i32> %77, <i32 8192, i32 8192, i32 8192, i32 8192>
  %79 = ashr <4 x i32> %78, <i32 14, i32 14, i32 14, i32 14>
  %80 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %76, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #6
  %81 = add <4 x i32> %80, <i32 8192, i32 8192, i32 8192, i32 8192>
  %82 = ashr <4 x i32> %81, <i32 14, i32 14, i32 14, i32 14>
  %83 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %79, <4 x i32> %82) #6
  %84 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %75, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #6
  %85 = add <4 x i32> %84, <i32 8192, i32 8192, i32 8192, i32 8192>
  %86 = ashr <4 x i32> %85, <i32 14, i32 14, i32 14, i32 14>
  %87 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %76, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #6
  %88 = add <4 x i32> %87, <i32 8192, i32 8192, i32 8192, i32 8192>
  %89 = ashr <4 x i32> %88, <i32 14, i32 14, i32 14, i32 14>
  %90 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %86, <4 x i32> %89) #6
  %91 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %92 = bitcast <2 x i64>* %91 to <8 x i16>*
  %93 = load <8 x i16>, <8 x i16>* %92, align 16
  %94 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %95 = bitcast <2 x i64>* %94 to <8 x i16>*
  %96 = load <8 x i16>, <8 x i16>* %95, align 16
  %97 = shufflevector <8 x i16> %93, <8 x i16> %96, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %98 = shufflevector <8 x i16> %93, <8 x i16> %96, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %99 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %97, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %100 = add <4 x i32> %99, <i32 8192, i32 8192, i32 8192, i32 8192>
  %101 = ashr <4 x i32> %100, <i32 14, i32 14, i32 14, i32 14>
  %102 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %98, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %103 = add <4 x i32> %102, <i32 8192, i32 8192, i32 8192, i32 8192>
  %104 = ashr <4 x i32> %103, <i32 14, i32 14, i32 14, i32 14>
  %105 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %101, <4 x i32> %104) #6
  %106 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %97, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %107 = add <4 x i32> %106, <i32 8192, i32 8192, i32 8192, i32 8192>
  %108 = ashr <4 x i32> %107, <i32 14, i32 14, i32 14, i32 14>
  %109 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %98, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %110 = add <4 x i32> %109, <i32 8192, i32 8192, i32 8192, i32 8192>
  %111 = ashr <4 x i32> %110, <i32 14, i32 14, i32 14, i32 14>
  %112 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %108, <4 x i32> %111) #6
  %113 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %114 = bitcast <2 x i64>* %113 to <8 x i16>*
  %115 = load <8 x i16>, <8 x i16>* %114, align 16
  %116 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %117 = bitcast <2 x i64>* %116 to <8 x i16>*
  %118 = load <8 x i16>, <8 x i16>* %117, align 16
  %119 = shufflevector <8 x i16> %115, <8 x i16> %118, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %120 = shufflevector <8 x i16> %115, <8 x i16> %118, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %121 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %119, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %122 = add <4 x i32> %121, <i32 8192, i32 8192, i32 8192, i32 8192>
  %123 = ashr <4 x i32> %122, <i32 14, i32 14, i32 14, i32 14>
  %124 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %120, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %125 = add <4 x i32> %124, <i32 8192, i32 8192, i32 8192, i32 8192>
  %126 = ashr <4 x i32> %125, <i32 14, i32 14, i32 14, i32 14>
  %127 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %123, <4 x i32> %126) #6
  %128 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %119, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %129 = add <4 x i32> %128, <i32 8192, i32 8192, i32 8192, i32 8192>
  %130 = ashr <4 x i32> %129, <i32 14, i32 14, i32 14, i32 14>
  %131 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %120, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %132 = add <4 x i32> %131, <i32 8192, i32 8192, i32 8192, i32 8192>
  %133 = ashr <4 x i32> %132, <i32 14, i32 14, i32 14, i32 14>
  %134 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %130, <4 x i32> %133) #6
  %135 = add <8 x i16> %39, %17
  %136 = sub <8 x i16> %17, %39
  %137 = sub <8 x i16> %83, %61
  %138 = add <8 x i16> %83, %61
  %139 = add <8 x i16> %90, %68
  %140 = sub <8 x i16> %90, %68
  %141 = sub <8 x i16> %24, %46
  %142 = add <8 x i16> %46, %24
  %143 = bitcast <2 x i64>* %0 to <8 x i16>*
  %144 = load <8 x i16>, <8 x i16>* %143, align 16
  %145 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %146 = bitcast <2 x i64>* %145 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = shufflevector <8 x i16> %144, <8 x i16> %147, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %149 = shufflevector <8 x i16> %144, <8 x i16> %147, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %150 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %148, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %151 = add <4 x i32> %150, <i32 8192, i32 8192, i32 8192, i32 8192>
  %152 = ashr <4 x i32> %151, <i32 14, i32 14, i32 14, i32 14>
  %153 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %149, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %154 = add <4 x i32> %153, <i32 8192, i32 8192, i32 8192, i32 8192>
  %155 = ashr <4 x i32> %154, <i32 14, i32 14, i32 14, i32 14>
  %156 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %152, <4 x i32> %155) #6
  %157 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %148, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %158 = add <4 x i32> %157, <i32 8192, i32 8192, i32 8192, i32 8192>
  %159 = ashr <4 x i32> %158, <i32 14, i32 14, i32 14, i32 14>
  %160 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %149, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %161 = add <4 x i32> %160, <i32 8192, i32 8192, i32 8192, i32 8192>
  %162 = ashr <4 x i32> %161, <i32 14, i32 14, i32 14, i32 14>
  %163 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %159, <4 x i32> %162) #6
  %164 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %165 = bitcast <2 x i64>* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %168 = bitcast <2 x i64>* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = shufflevector <8 x i16> %166, <8 x i16> %169, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %171 = shufflevector <8 x i16> %166, <8 x i16> %169, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %172 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %170, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %173 = add <4 x i32> %172, <i32 8192, i32 8192, i32 8192, i32 8192>
  %174 = ashr <4 x i32> %173, <i32 14, i32 14, i32 14, i32 14>
  %175 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %171, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %176 = add <4 x i32> %175, <i32 8192, i32 8192, i32 8192, i32 8192>
  %177 = ashr <4 x i32> %176, <i32 14, i32 14, i32 14, i32 14>
  %178 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %174, <4 x i32> %177) #6
  %179 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %170, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %180 = add <4 x i32> %179, <i32 8192, i32 8192, i32 8192, i32 8192>
  %181 = ashr <4 x i32> %180, <i32 14, i32 14, i32 14, i32 14>
  %182 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %171, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %183 = add <4 x i32> %182, <i32 8192, i32 8192, i32 8192, i32 8192>
  %184 = ashr <4 x i32> %183, <i32 14, i32 14, i32 14, i32 14>
  %185 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %181, <4 x i32> %184) #6
  %186 = shufflevector <8 x i16> %141, <8 x i16> %136, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %187 = shufflevector <8 x i16> %141, <8 x i16> %136, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %188 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %186, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %189 = add <4 x i32> %188, <i32 8192, i32 8192, i32 8192, i32 8192>
  %190 = ashr <4 x i32> %189, <i32 14, i32 14, i32 14, i32 14>
  %191 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %187, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %192 = add <4 x i32> %191, <i32 8192, i32 8192, i32 8192, i32 8192>
  %193 = ashr <4 x i32> %192, <i32 14, i32 14, i32 14, i32 14>
  %194 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %190, <4 x i32> %193) #6
  %195 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %186, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %196 = add <4 x i32> %195, <i32 8192, i32 8192, i32 8192, i32 8192>
  %197 = ashr <4 x i32> %196, <i32 14, i32 14, i32 14, i32 14>
  %198 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %187, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %199 = add <4 x i32> %198, <i32 8192, i32 8192, i32 8192, i32 8192>
  %200 = ashr <4 x i32> %199, <i32 14, i32 14, i32 14, i32 14>
  %201 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %197, <4 x i32> %200) #6
  %202 = shufflevector <8 x i16> %137, <8 x i16> %140, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %203 = shufflevector <8 x i16> %137, <8 x i16> %140, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %204 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %202, <8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>) #6
  %205 = add <4 x i32> %204, <i32 8192, i32 8192, i32 8192, i32 8192>
  %206 = ashr <4 x i32> %205, <i32 14, i32 14, i32 14, i32 14>
  %207 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %203, <8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>) #6
  %208 = add <4 x i32> %207, <i32 8192, i32 8192, i32 8192, i32 8192>
  %209 = ashr <4 x i32> %208, <i32 14, i32 14, i32 14, i32 14>
  %210 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %206, <4 x i32> %209) #6
  %211 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %202, <8 x i16> <i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137>) #6
  %212 = add <4 x i32> %211, <i32 8192, i32 8192, i32 8192, i32 8192>
  %213 = ashr <4 x i32> %212, <i32 14, i32 14, i32 14, i32 14>
  %214 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %203, <8 x i16> <i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137>) #6
  %215 = add <4 x i32> %214, <i32 8192, i32 8192, i32 8192, i32 8192>
  %216 = ashr <4 x i32> %215, <i32 14, i32 14, i32 14, i32 14>
  %217 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %213, <4 x i32> %216) #6
  %218 = sub <8 x i16> %105, %127
  %219 = add <8 x i16> %127, %105
  %220 = sub <8 x i16> %112, %134
  %221 = add <8 x i16> %134, %112
  %222 = add <8 x i16> %185, %163
  %223 = add <8 x i16> %178, %156
  %224 = sub <8 x i16> %156, %178
  %225 = sub <8 x i16> %163, %185
  %226 = shufflevector <8 x i16> %220, <8 x i16> %218, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %227 = shufflevector <8 x i16> %220, <8 x i16> %218, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %228 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %226, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %229 = add <4 x i32> %228, <i32 8192, i32 8192, i32 8192, i32 8192>
  %230 = ashr <4 x i32> %229, <i32 14, i32 14, i32 14, i32 14>
  %231 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %227, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %232 = add <4 x i32> %231, <i32 8192, i32 8192, i32 8192, i32 8192>
  %233 = ashr <4 x i32> %232, <i32 14, i32 14, i32 14, i32 14>
  %234 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %230, <4 x i32> %233) #6
  %235 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %226, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %236 = add <4 x i32> %235, <i32 8192, i32 8192, i32 8192, i32 8192>
  %237 = ashr <4 x i32> %236, <i32 14, i32 14, i32 14, i32 14>
  %238 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %227, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %239 = add <4 x i32> %238, <i32 8192, i32 8192, i32 8192, i32 8192>
  %240 = ashr <4 x i32> %239, <i32 14, i32 14, i32 14, i32 14>
  %241 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %237, <4 x i32> %240) #6
  %242 = add <8 x i16> %138, %135
  %243 = add <8 x i16> %217, %194
  %244 = sub <8 x i16> %194, %217
  %245 = sub <8 x i16> %135, %138
  %246 = sub <8 x i16> %142, %139
  %247 = sub <8 x i16> %201, %210
  %248 = add <8 x i16> %210, %201
  %249 = add <8 x i16> %139, %142
  %250 = add <8 x i16> %222, %221
  %251 = add <8 x i16> %241, %223
  %252 = add <8 x i16> %234, %224
  %253 = add <8 x i16> %225, %219
  %254 = sub <8 x i16> %225, %219
  %255 = sub <8 x i16> %224, %234
  %256 = sub <8 x i16> %223, %241
  %257 = sub <8 x i16> %222, %221
  %258 = shufflevector <8 x i16> %247, <8 x i16> %244, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %259 = shufflevector <8 x i16> %247, <8 x i16> %244, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %260 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %258, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %261 = add <4 x i32> %260, <i32 8192, i32 8192, i32 8192, i32 8192>
  %262 = ashr <4 x i32> %261, <i32 14, i32 14, i32 14, i32 14>
  %263 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %259, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %264 = add <4 x i32> %263, <i32 8192, i32 8192, i32 8192, i32 8192>
  %265 = ashr <4 x i32> %264, <i32 14, i32 14, i32 14, i32 14>
  %266 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %262, <4 x i32> %265) #6
  %267 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %258, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %268 = add <4 x i32> %267, <i32 8192, i32 8192, i32 8192, i32 8192>
  %269 = ashr <4 x i32> %268, <i32 14, i32 14, i32 14, i32 14>
  %270 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %259, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %271 = add <4 x i32> %270, <i32 8192, i32 8192, i32 8192, i32 8192>
  %272 = ashr <4 x i32> %271, <i32 14, i32 14, i32 14, i32 14>
  %273 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %269, <4 x i32> %272) #6
  %274 = shufflevector <8 x i16> %246, <8 x i16> %245, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %275 = shufflevector <8 x i16> %246, <8 x i16> %245, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %274, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %277 = add <4 x i32> %276, <i32 8192, i32 8192, i32 8192, i32 8192>
  %278 = ashr <4 x i32> %277, <i32 14, i32 14, i32 14, i32 14>
  %279 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %275, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %280 = add <4 x i32> %279, <i32 8192, i32 8192, i32 8192, i32 8192>
  %281 = ashr <4 x i32> %280, <i32 14, i32 14, i32 14, i32 14>
  %282 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %278, <4 x i32> %281) #6
  %283 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %274, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %284 = add <4 x i32> %283, <i32 8192, i32 8192, i32 8192, i32 8192>
  %285 = ashr <4 x i32> %284, <i32 14, i32 14, i32 14, i32 14>
  %286 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %275, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %287 = add <4 x i32> %286, <i32 8192, i32 8192, i32 8192, i32 8192>
  %288 = ashr <4 x i32> %287, <i32 14, i32 14, i32 14, i32 14>
  %289 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %285, <4 x i32> %288) #6
  %290 = add <8 x i16> %250, %249
  %291 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %290, <8 x i16>* %291, align 16
  %292 = add <8 x i16> %251, %248
  %293 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %294 = bitcast <2 x i64>* %293 to <8 x i16>*
  store <8 x i16> %292, <8 x i16>* %294, align 16
  %295 = add <8 x i16> %273, %252
  %296 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %297 = bitcast <2 x i64>* %296 to <8 x i16>*
  store <8 x i16> %295, <8 x i16>* %297, align 16
  %298 = add <8 x i16> %289, %253
  %299 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %300 = bitcast <2 x i64>* %299 to <8 x i16>*
  store <8 x i16> %298, <8 x i16>* %300, align 16
  %301 = add <8 x i16> %282, %254
  %302 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %303 = bitcast <2 x i64>* %302 to <8 x i16>*
  store <8 x i16> %301, <8 x i16>* %303, align 16
  %304 = add <8 x i16> %266, %255
  %305 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %306 = bitcast <2 x i64>* %305 to <8 x i16>*
  store <8 x i16> %304, <8 x i16>* %306, align 16
  %307 = add <8 x i16> %256, %243
  %308 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %309 = bitcast <2 x i64>* %308 to <8 x i16>*
  store <8 x i16> %307, <8 x i16>* %309, align 16
  %310 = add <8 x i16> %257, %242
  %311 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %312 = bitcast <2 x i64>* %311 to <8 x i16>*
  store <8 x i16> %310, <8 x i16>* %312, align 16
  %313 = sub <8 x i16> %257, %242
  %314 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %315 = bitcast <2 x i64>* %314 to <8 x i16>*
  store <8 x i16> %313, <8 x i16>* %315, align 16
  %316 = sub <8 x i16> %256, %243
  %317 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %318 = bitcast <2 x i64>* %317 to <8 x i16>*
  store <8 x i16> %316, <8 x i16>* %318, align 16
  %319 = sub <8 x i16> %255, %266
  %320 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %321 = bitcast <2 x i64>* %320 to <8 x i16>*
  store <8 x i16> %319, <8 x i16>* %321, align 16
  %322 = sub <8 x i16> %254, %282
  %323 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %324 = bitcast <2 x i64>* %323 to <8 x i16>*
  store <8 x i16> %322, <8 x i16>* %324, align 16
  %325 = sub <8 x i16> %253, %289
  %326 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %327 = bitcast <2 x i64>* %326 to <8 x i16>*
  store <8 x i16> %325, <8 x i16>* %327, align 16
  %328 = sub <8 x i16> %252, %273
  %329 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %330 = bitcast <2 x i64>* %329 to <8 x i16>*
  store <8 x i16> %328, <8 x i16>* %330, align 16
  %331 = sub <8 x i16> %251, %248
  %332 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %333 = bitcast <2 x i64>* %332 to <8 x i16>*
  store <8 x i16> %331, <8 x i16>* %333, align 16
  %334 = sub <8 x i16> %250, %249
  %335 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %336 = bitcast <2 x i64>* %335 to <8 x i16>*
  store <8 x i16> %334, <8 x i16>* %336, align 16
  ret void
}

declare void @vpx_iadst16_8col_sse2(<2 x i64>*) local_unnamed_addr #3

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

declare void @vpx_highbd_idct16_4col_sse4_1(<2 x i64>*) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define internal fastcc void @highbd_iadst16_4col_sse4_1(<2 x i64>* nocapture) unnamed_addr #0 {
  %2 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %3 = bitcast <2 x i64>* %2 to <4 x i32>*
  %4 = load <4 x i32>, <4 x i32>* %3, align 16
  %5 = bitcast <2 x i64>* %0 to <4 x i32>*
  %6 = load <4 x i32>, <4 x i32>* %5, align 16
  %7 = shufflevector <4 x i32> %4, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %8 = bitcast <4 x i32> %7 to <2 x i64>
  %9 = shufflevector <4 x i32> %4, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %10 = bitcast <4 x i32> %9 to <2 x i64>
  %11 = shufflevector <4 x i32> %6, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = shufflevector <4 x i32> %6, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = shl <2 x i64> %8, <i64 32, i64 32>
  %16 = ashr exact <2 x i64> %15, <i64 32, i64 32>
  %17 = mul nsw <2 x i64> %16, <i64 65456, i64 65456>
  %18 = shl <2 x i64> %10, <i64 32, i64 32>
  %19 = ashr exact <2 x i64> %18, <i64 32, i64 32>
  %20 = mul nsw <2 x i64> %19, <i64 65456, i64 65456>
  %21 = shl <2 x i64> %12, <i64 32, i64 32>
  %22 = ashr exact <2 x i64> %21, <i64 32, i64 32>
  %23 = shl <2 x i64> %14, <i64 32, i64 32>
  %24 = ashr exact <2 x i64> %23, <i64 32, i64 32>
  %25 = mul nsw <2 x i64> %16, <i64 3216, i64 3216>
  %26 = mul nsw <2 x i64> %19, <i64 3216, i64 3216>
  %27 = mul nsw <2 x i64> %22, <i64 3216, i64 3216>
  %28 = mul nsw <2 x i64> %24, <i64 3216, i64 3216>
  %29 = add nsw <2 x i64> %27, %17
  %30 = add nsw <2 x i64> %28, %20
  %31 = mul nsw <2 x i64> %22, <i64 -65456, i64 -65456>
  %32 = add nsw <2 x i64> %31, %25
  %33 = mul nsw <2 x i64> %24, <i64 -65456, i64 -65456>
  %34 = add nsw <2 x i64> %33, %26
  %35 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %36 = bitcast <2 x i64>* %35 to <4 x i32>*
  %37 = load <4 x i32>, <4 x i32>* %36, align 16
  %38 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %39 = bitcast <2 x i64>* %38 to <4 x i32>*
  %40 = load <4 x i32>, <4 x i32>* %39, align 16
  %41 = shufflevector <4 x i32> %37, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %42 = bitcast <4 x i32> %41 to <2 x i64>
  %43 = shufflevector <4 x i32> %37, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %44 = bitcast <4 x i32> %43 to <2 x i64>
  %45 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %46 = bitcast <4 x i32> %45 to <2 x i64>
  %47 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %48 = bitcast <4 x i32> %47 to <2 x i64>
  %49 = shl <2 x i64> %42, <i64 32, i64 32>
  %50 = ashr exact <2 x i64> %49, <i64 32, i64 32>
  %51 = mul nsw <2 x i64> %50, <i64 63572, i64 63572>
  %52 = shl <2 x i64> %44, <i64 32, i64 32>
  %53 = ashr exact <2 x i64> %52, <i64 32, i64 32>
  %54 = mul nsw <2 x i64> %53, <i64 63572, i64 63572>
  %55 = shl <2 x i64> %46, <i64 32, i64 32>
  %56 = ashr exact <2 x i64> %55, <i64 32, i64 32>
  %57 = shl <2 x i64> %48, <i64 32, i64 32>
  %58 = ashr exact <2 x i64> %57, <i64 32, i64 32>
  %59 = mul nsw <2 x i64> %50, <i64 15924, i64 15924>
  %60 = mul nsw <2 x i64> %53, <i64 15924, i64 15924>
  %61 = mul nsw <2 x i64> %56, <i64 15924, i64 15924>
  %62 = mul nsw <2 x i64> %58, <i64 15924, i64 15924>
  %63 = add nsw <2 x i64> %61, %51
  %64 = add nsw <2 x i64> %62, %54
  %65 = mul nsw <2 x i64> %56, <i64 -63572, i64 -63572>
  %66 = add nsw <2 x i64> %65, %59
  %67 = mul nsw <2 x i64> %58, <i64 -63572, i64 -63572>
  %68 = add nsw <2 x i64> %67, %60
  %69 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %70 = bitcast <2 x i64>* %69 to <4 x i32>*
  %71 = load <4 x i32>, <4 x i32>* %70, align 16
  %72 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %73 = bitcast <2 x i64>* %72 to <4 x i32>*
  %74 = load <4 x i32>, <4 x i32>* %73, align 16
  %75 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %76 = bitcast <4 x i32> %75 to <2 x i64>
  %77 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %78 = bitcast <4 x i32> %77 to <2 x i64>
  %79 = shufflevector <4 x i32> %74, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %80 = bitcast <4 x i32> %79 to <2 x i64>
  %81 = shufflevector <4 x i32> %74, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %82 = bitcast <4 x i32> %81 to <2 x i64>
  %83 = shl <2 x i64> %76, <i64 32, i64 32>
  %84 = ashr exact <2 x i64> %83, <i64 32, i64 32>
  %85 = mul nsw <2 x i64> %84, <i64 59244, i64 59244>
  %86 = shl <2 x i64> %78, <i64 32, i64 32>
  %87 = ashr exact <2 x i64> %86, <i64 32, i64 32>
  %88 = mul nsw <2 x i64> %87, <i64 59244, i64 59244>
  %89 = shl <2 x i64> %80, <i64 32, i64 32>
  %90 = ashr exact <2 x i64> %89, <i64 32, i64 32>
  %91 = shl <2 x i64> %82, <i64 32, i64 32>
  %92 = ashr exact <2 x i64> %91, <i64 32, i64 32>
  %93 = mul nsw <2 x i64> %84, <i64 28020, i64 28020>
  %94 = mul nsw <2 x i64> %87, <i64 28020, i64 28020>
  %95 = mul nsw <2 x i64> %90, <i64 28020, i64 28020>
  %96 = mul nsw <2 x i64> %92, <i64 28020, i64 28020>
  %97 = add nsw <2 x i64> %95, %85
  %98 = add nsw <2 x i64> %96, %88
  %99 = mul nsw <2 x i64> %90, <i64 -59244, i64 -59244>
  %100 = add nsw <2 x i64> %99, %93
  %101 = mul nsw <2 x i64> %92, <i64 -59244, i64 -59244>
  %102 = add nsw <2 x i64> %101, %94
  %103 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %104 = bitcast <2 x i64>* %103 to <4 x i32>*
  %105 = load <4 x i32>, <4 x i32>* %104, align 16
  %106 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %107 = bitcast <2 x i64>* %106 to <4 x i32>*
  %108 = load <4 x i32>, <4 x i32>* %107, align 16
  %109 = shufflevector <4 x i32> %105, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %110 = bitcast <4 x i32> %109 to <2 x i64>
  %111 = shufflevector <4 x i32> %105, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %112 = bitcast <4 x i32> %111 to <2 x i64>
  %113 = shufflevector <4 x i32> %108, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %114 = bitcast <4 x i32> %113 to <2 x i64>
  %115 = shufflevector <4 x i32> %108, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %116 = bitcast <4 x i32> %115 to <2 x i64>
  %117 = shl <2 x i64> %110, <i64 32, i64 32>
  %118 = ashr exact <2 x i64> %117, <i64 32, i64 32>
  %119 = mul nsw <2 x i64> %118, <i64 52640, i64 52640>
  %120 = shl <2 x i64> %112, <i64 32, i64 32>
  %121 = ashr exact <2 x i64> %120, <i64 32, i64 32>
  %122 = mul nsw <2 x i64> %121, <i64 52640, i64 52640>
  %123 = shl <2 x i64> %114, <i64 32, i64 32>
  %124 = ashr exact <2 x i64> %123, <i64 32, i64 32>
  %125 = shl <2 x i64> %116, <i64 32, i64 32>
  %126 = ashr exact <2 x i64> %125, <i64 32, i64 32>
  %127 = mul nsw <2 x i64> %118, <i64 39040, i64 39040>
  %128 = mul nsw <2 x i64> %121, <i64 39040, i64 39040>
  %129 = mul nsw <2 x i64> %124, <i64 39040, i64 39040>
  %130 = mul nsw <2 x i64> %126, <i64 39040, i64 39040>
  %131 = add nsw <2 x i64> %129, %119
  %132 = add nsw <2 x i64> %130, %122
  %133 = mul nsw <2 x i64> %124, <i64 -52640, i64 -52640>
  %134 = add nsw <2 x i64> %133, %127
  %135 = mul nsw <2 x i64> %126, <i64 -52640, i64 -52640>
  %136 = add nsw <2 x i64> %135, %128
  %137 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %138 = bitcast <2 x i64>* %137 to <4 x i32>*
  %139 = load <4 x i32>, <4 x i32>* %138, align 16
  %140 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %141 = bitcast <2 x i64>* %140 to <4 x i32>*
  %142 = load <4 x i32>, <4 x i32>* %141, align 16
  %143 = shufflevector <4 x i32> %139, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %144 = bitcast <4 x i32> %143 to <2 x i64>
  %145 = shufflevector <4 x i32> %139, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %146 = bitcast <4 x i32> %145 to <2 x i64>
  %147 = shufflevector <4 x i32> %142, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %148 = bitcast <4 x i32> %147 to <2 x i64>
  %149 = shufflevector <4 x i32> %142, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %150 = bitcast <4 x i32> %149 to <2 x i64>
  %151 = shl <2 x i64> %144, <i64 32, i64 32>
  %152 = ashr exact <2 x i64> %151, <i64 32, i64 32>
  %153 = mul nsw <2 x i64> %152, <i64 44012, i64 44012>
  %154 = shl <2 x i64> %146, <i64 32, i64 32>
  %155 = ashr exact <2 x i64> %154, <i64 32, i64 32>
  %156 = mul nsw <2 x i64> %155, <i64 44012, i64 44012>
  %157 = shl <2 x i64> %148, <i64 32, i64 32>
  %158 = ashr exact <2 x i64> %157, <i64 32, i64 32>
  %159 = shl <2 x i64> %150, <i64 32, i64 32>
  %160 = ashr exact <2 x i64> %159, <i64 32, i64 32>
  %161 = mul nsw <2 x i64> %152, <i64 48560, i64 48560>
  %162 = mul nsw <2 x i64> %155, <i64 48560, i64 48560>
  %163 = mul nsw <2 x i64> %158, <i64 48560, i64 48560>
  %164 = mul nsw <2 x i64> %160, <i64 48560, i64 48560>
  %165 = add nsw <2 x i64> %163, %153
  %166 = add nsw <2 x i64> %164, %156
  %167 = mul nsw <2 x i64> %158, <i64 -44012, i64 -44012>
  %168 = add nsw <2 x i64> %167, %161
  %169 = mul nsw <2 x i64> %160, <i64 -44012, i64 -44012>
  %170 = add nsw <2 x i64> %169, %162
  %171 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %172 = bitcast <2 x i64>* %171 to <4 x i32>*
  %173 = load <4 x i32>, <4 x i32>* %172, align 16
  %174 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %175 = bitcast <2 x i64>* %174 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = shufflevector <4 x i32> %173, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %178 = bitcast <4 x i32> %177 to <2 x i64>
  %179 = shufflevector <4 x i32> %173, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %180 = bitcast <4 x i32> %179 to <2 x i64>
  %181 = shufflevector <4 x i32> %176, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %182 = bitcast <4 x i32> %181 to <2 x i64>
  %183 = shufflevector <4 x i32> %176, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %184 = bitcast <4 x i32> %183 to <2 x i64>
  %185 = shl <2 x i64> %178, <i64 32, i64 32>
  %186 = ashr exact <2 x i64> %185, <i64 32, i64 32>
  %187 = mul nsw <2 x i64> %186, <i64 33692, i64 33692>
  %188 = shl <2 x i64> %180, <i64 32, i64 32>
  %189 = ashr exact <2 x i64> %188, <i64 32, i64 32>
  %190 = mul nsw <2 x i64> %189, <i64 33692, i64 33692>
  %191 = shl <2 x i64> %182, <i64 32, i64 32>
  %192 = ashr exact <2 x i64> %191, <i64 32, i64 32>
  %193 = shl <2 x i64> %184, <i64 32, i64 32>
  %194 = ashr exact <2 x i64> %193, <i64 32, i64 32>
  %195 = mul nsw <2 x i64> %186, <i64 56212, i64 56212>
  %196 = mul nsw <2 x i64> %189, <i64 56212, i64 56212>
  %197 = mul nsw <2 x i64> %192, <i64 56212, i64 56212>
  %198 = mul nsw <2 x i64> %194, <i64 56212, i64 56212>
  %199 = add nsw <2 x i64> %197, %187
  %200 = add nsw <2 x i64> %198, %190
  %201 = mul nsw <2 x i64> %192, <i64 -33692, i64 -33692>
  %202 = add nsw <2 x i64> %201, %195
  %203 = mul nsw <2 x i64> %194, <i64 -33692, i64 -33692>
  %204 = add nsw <2 x i64> %203, %196
  %205 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %206 = bitcast <2 x i64>* %205 to <4 x i32>*
  %207 = load <4 x i32>, <4 x i32>* %206, align 16
  %208 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %209 = bitcast <2 x i64>* %208 to <4 x i32>*
  %210 = load <4 x i32>, <4 x i32>* %209, align 16
  %211 = shufflevector <4 x i32> %207, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %212 = bitcast <4 x i32> %211 to <2 x i64>
  %213 = shufflevector <4 x i32> %207, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %214 = bitcast <4 x i32> %213 to <2 x i64>
  %215 = shufflevector <4 x i32> %210, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %216 = bitcast <4 x i32> %215 to <2 x i64>
  %217 = shufflevector <4 x i32> %210, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %218 = bitcast <4 x i32> %217 to <2 x i64>
  %219 = shl <2 x i64> %212, <i64 32, i64 32>
  %220 = ashr exact <2 x i64> %219, <i64 32, i64 32>
  %221 = mul nsw <2 x i64> %220, <i64 22080, i64 22080>
  %222 = shl <2 x i64> %214, <i64 32, i64 32>
  %223 = ashr exact <2 x i64> %222, <i64 32, i64 32>
  %224 = mul nsw <2 x i64> %223, <i64 22080, i64 22080>
  %225 = shl <2 x i64> %216, <i64 32, i64 32>
  %226 = ashr exact <2 x i64> %225, <i64 32, i64 32>
  %227 = shl <2 x i64> %218, <i64 32, i64 32>
  %228 = ashr exact <2 x i64> %227, <i64 32, i64 32>
  %229 = mul nsw <2 x i64> %220, <i64 61704, i64 61704>
  %230 = mul nsw <2 x i64> %223, <i64 61704, i64 61704>
  %231 = mul nsw <2 x i64> %226, <i64 61704, i64 61704>
  %232 = mul nsw <2 x i64> %228, <i64 61704, i64 61704>
  %233 = add nsw <2 x i64> %231, %221
  %234 = add nsw <2 x i64> %232, %224
  %235 = mul nsw <2 x i64> %226, <i64 -22080, i64 -22080>
  %236 = add nsw <2 x i64> %235, %229
  %237 = mul nsw <2 x i64> %228, <i64 -22080, i64 -22080>
  %238 = add nsw <2 x i64> %237, %230
  %239 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %240 = bitcast <2 x i64>* %239 to <4 x i32>*
  %241 = load <4 x i32>, <4 x i32>* %240, align 16
  %242 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %243 = bitcast <2 x i64>* %242 to <4 x i32>*
  %244 = load <4 x i32>, <4 x i32>* %243, align 16
  %245 = shufflevector <4 x i32> %241, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %246 = bitcast <4 x i32> %245 to <2 x i64>
  %247 = shufflevector <4 x i32> %241, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %248 = bitcast <4 x i32> %247 to <2 x i64>
  %249 = shufflevector <4 x i32> %244, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %250 = bitcast <4 x i32> %249 to <2 x i64>
  %251 = shufflevector <4 x i32> %244, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %252 = bitcast <4 x i32> %251 to <2 x i64>
  %253 = shl <2 x i64> %246, <i64 32, i64 32>
  %254 = ashr exact <2 x i64> %253, <i64 32, i64 32>
  %255 = mul nsw <2 x i64> %254, <i64 9616, i64 9616>
  %256 = shl <2 x i64> %248, <i64 32, i64 32>
  %257 = ashr exact <2 x i64> %256, <i64 32, i64 32>
  %258 = mul nsw <2 x i64> %257, <i64 9616, i64 9616>
  %259 = shl <2 x i64> %250, <i64 32, i64 32>
  %260 = ashr exact <2 x i64> %259, <i64 32, i64 32>
  %261 = shl <2 x i64> %252, <i64 32, i64 32>
  %262 = ashr exact <2 x i64> %261, <i64 32, i64 32>
  %263 = mul nsw <2 x i64> %254, <i64 64828, i64 64828>
  %264 = mul nsw <2 x i64> %257, <i64 64828, i64 64828>
  %265 = mul nsw <2 x i64> %260, <i64 64828, i64 64828>
  %266 = mul nsw <2 x i64> %262, <i64 64828, i64 64828>
  %267 = add nsw <2 x i64> %265, %255
  %268 = add nsw <2 x i64> %266, %258
  %269 = mul nsw <2 x i64> %260, <i64 -9616, i64 -9616>
  %270 = add nsw <2 x i64> %269, %263
  %271 = mul nsw <2 x i64> %262, <i64 -9616, i64 -9616>
  %272 = add nsw <2 x i64> %271, %264
  %273 = add nsw <2 x i64> %29, <i64 32768, i64 32768>
  %274 = add nsw <2 x i64> %273, %165
  %275 = bitcast <2 x i64> %274 to <16 x i8>
  %276 = shufflevector <16 x i8> %275, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %277 = add nsw <2 x i64> %30, <i64 32768, i64 32768>
  %278 = add nsw <2 x i64> %277, %166
  %279 = bitcast <2 x i64> %278 to <16 x i8>
  %280 = shufflevector <16 x i8> %279, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %281 = add nsw <2 x i64> %32, <i64 32768, i64 32768>
  %282 = add nsw <2 x i64> %281, %168
  %283 = bitcast <2 x i64> %282 to <16 x i8>
  %284 = shufflevector <16 x i8> %283, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %285 = add nsw <2 x i64> %34, <i64 32768, i64 32768>
  %286 = add nsw <2 x i64> %285, %170
  %287 = bitcast <2 x i64> %286 to <16 x i8>
  %288 = shufflevector <16 x i8> %287, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %289 = add nsw <2 x i64> %63, <i64 32768, i64 32768>
  %290 = add nsw <2 x i64> %289, %199
  %291 = bitcast <2 x i64> %290 to <16 x i8>
  %292 = shufflevector <16 x i8> %291, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %293 = add nsw <2 x i64> %64, <i64 32768, i64 32768>
  %294 = add nsw <2 x i64> %293, %200
  %295 = bitcast <2 x i64> %294 to <16 x i8>
  %296 = shufflevector <16 x i8> %295, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %297 = add nsw <2 x i64> %66, <i64 32768, i64 32768>
  %298 = add nsw <2 x i64> %297, %202
  %299 = bitcast <2 x i64> %298 to <16 x i8>
  %300 = shufflevector <16 x i8> %299, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %301 = add nsw <2 x i64> %68, <i64 32768, i64 32768>
  %302 = add nsw <2 x i64> %301, %204
  %303 = bitcast <2 x i64> %302 to <16 x i8>
  %304 = shufflevector <16 x i8> %303, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %305 = add nsw <2 x i64> %97, <i64 32768, i64 32768>
  %306 = add nsw <2 x i64> %305, %233
  %307 = bitcast <2 x i64> %306 to <16 x i8>
  %308 = shufflevector <16 x i8> %307, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %309 = add nsw <2 x i64> %98, <i64 32768, i64 32768>
  %310 = add nsw <2 x i64> %309, %234
  %311 = bitcast <2 x i64> %310 to <16 x i8>
  %312 = shufflevector <16 x i8> %311, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %313 = add nsw <2 x i64> %100, <i64 32768, i64 32768>
  %314 = add nsw <2 x i64> %313, %236
  %315 = bitcast <2 x i64> %314 to <16 x i8>
  %316 = shufflevector <16 x i8> %315, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %317 = add nsw <2 x i64> %102, <i64 32768, i64 32768>
  %318 = add nsw <2 x i64> %317, %238
  %319 = bitcast <2 x i64> %318 to <16 x i8>
  %320 = shufflevector <16 x i8> %319, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %321 = add nsw <2 x i64> %131, <i64 32768, i64 32768>
  %322 = add nsw <2 x i64> %321, %267
  %323 = bitcast <2 x i64> %322 to <16 x i8>
  %324 = shufflevector <16 x i8> %323, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %325 = add nsw <2 x i64> %132, <i64 32768, i64 32768>
  %326 = add nsw <2 x i64> %325, %268
  %327 = bitcast <2 x i64> %326 to <16 x i8>
  %328 = shufflevector <16 x i8> %327, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %329 = add nsw <2 x i64> %134, <i64 32768, i64 32768>
  %330 = add nsw <2 x i64> %329, %270
  %331 = bitcast <2 x i64> %330 to <16 x i8>
  %332 = shufflevector <16 x i8> %331, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %333 = add nsw <2 x i64> %136, <i64 32768, i64 32768>
  %334 = add nsw <2 x i64> %333, %272
  %335 = bitcast <2 x i64> %334 to <16 x i8>
  %336 = shufflevector <16 x i8> %335, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %337 = sub nsw <2 x i64> %273, %165
  %338 = bitcast <2 x i64> %337 to <16 x i8>
  %339 = shufflevector <16 x i8> %338, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %340 = sub nsw <2 x i64> %277, %166
  %341 = bitcast <2 x i64> %340 to <16 x i8>
  %342 = shufflevector <16 x i8> %341, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %343 = sub nsw <2 x i64> %281, %168
  %344 = bitcast <2 x i64> %343 to <16 x i8>
  %345 = shufflevector <16 x i8> %344, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %346 = sub nsw <2 x i64> %285, %170
  %347 = bitcast <2 x i64> %346 to <16 x i8>
  %348 = shufflevector <16 x i8> %347, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %349 = sub nsw <2 x i64> %289, %199
  %350 = bitcast <2 x i64> %349 to <16 x i8>
  %351 = shufflevector <16 x i8> %350, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %352 = sub nsw <2 x i64> %293, %200
  %353 = bitcast <2 x i64> %352 to <16 x i8>
  %354 = shufflevector <16 x i8> %353, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %355 = sub nsw <2 x i64> %297, %202
  %356 = bitcast <2 x i64> %355 to <16 x i8>
  %357 = shufflevector <16 x i8> %356, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %358 = sub nsw <2 x i64> %301, %204
  %359 = bitcast <2 x i64> %358 to <16 x i8>
  %360 = shufflevector <16 x i8> %359, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %361 = sub nsw <2 x i64> %305, %233
  %362 = bitcast <2 x i64> %361 to <16 x i8>
  %363 = shufflevector <16 x i8> %362, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %364 = sub nsw <2 x i64> %309, %234
  %365 = bitcast <2 x i64> %364 to <16 x i8>
  %366 = shufflevector <16 x i8> %365, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %367 = sub nsw <2 x i64> %313, %236
  %368 = bitcast <2 x i64> %367 to <16 x i8>
  %369 = shufflevector <16 x i8> %368, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %370 = sub nsw <2 x i64> %317, %238
  %371 = bitcast <2 x i64> %370 to <16 x i8>
  %372 = shufflevector <16 x i8> %371, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %373 = sub nsw <2 x i64> %321, %267
  %374 = bitcast <2 x i64> %373 to <16 x i8>
  %375 = shufflevector <16 x i8> %374, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %376 = sub nsw <2 x i64> %325, %268
  %377 = bitcast <2 x i64> %376 to <16 x i8>
  %378 = shufflevector <16 x i8> %377, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %379 = sub nsw <2 x i64> %329, %270
  %380 = bitcast <2 x i64> %379 to <16 x i8>
  %381 = shufflevector <16 x i8> %380, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %382 = sub nsw <2 x i64> %333, %272
  %383 = bitcast <2 x i64> %382 to <16 x i8>
  %384 = shufflevector <16 x i8> %383, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %385 = bitcast <16 x i8> %276 to <4 x i32>
  %386 = bitcast <16 x i8> %280 to <4 x i32>
  %387 = shufflevector <4 x i32> %385, <4 x i32> %386, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %388 = shufflevector <4 x i32> %385, <4 x i32> %386, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %389 = shufflevector <4 x i32> %387, <4 x i32> %388, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %390 = bitcast <16 x i8> %284 to <4 x i32>
  %391 = bitcast <16 x i8> %288 to <4 x i32>
  %392 = shufflevector <4 x i32> %390, <4 x i32> %391, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %393 = shufflevector <4 x i32> %390, <4 x i32> %391, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %394 = shufflevector <4 x i32> %392, <4 x i32> %393, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %395 = bitcast <16 x i8> %292 to <4 x i32>
  %396 = bitcast <16 x i8> %296 to <4 x i32>
  %397 = shufflevector <4 x i32> %395, <4 x i32> %396, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %398 = shufflevector <4 x i32> %395, <4 x i32> %396, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %399 = shufflevector <4 x i32> %397, <4 x i32> %398, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %400 = bitcast <16 x i8> %300 to <4 x i32>
  %401 = bitcast <16 x i8> %304 to <4 x i32>
  %402 = shufflevector <4 x i32> %400, <4 x i32> %401, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %403 = shufflevector <4 x i32> %400, <4 x i32> %401, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %404 = shufflevector <4 x i32> %402, <4 x i32> %403, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %405 = bitcast <16 x i8> %308 to <4 x i32>
  %406 = bitcast <16 x i8> %312 to <4 x i32>
  %407 = shufflevector <4 x i32> %405, <4 x i32> %406, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %408 = shufflevector <4 x i32> %405, <4 x i32> %406, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %409 = shufflevector <4 x i32> %407, <4 x i32> %408, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %410 = bitcast <16 x i8> %316 to <4 x i32>
  %411 = bitcast <16 x i8> %320 to <4 x i32>
  %412 = shufflevector <4 x i32> %410, <4 x i32> %411, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %413 = shufflevector <4 x i32> %410, <4 x i32> %411, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %414 = shufflevector <4 x i32> %412, <4 x i32> %413, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %415 = bitcast <16 x i8> %324 to <4 x i32>
  %416 = bitcast <16 x i8> %328 to <4 x i32>
  %417 = shufflevector <4 x i32> %415, <4 x i32> %416, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %418 = shufflevector <4 x i32> %415, <4 x i32> %416, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %419 = shufflevector <4 x i32> %417, <4 x i32> %418, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %420 = bitcast <16 x i8> %332 to <4 x i32>
  %421 = bitcast <16 x i8> %336 to <4 x i32>
  %422 = shufflevector <4 x i32> %420, <4 x i32> %421, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %423 = shufflevector <4 x i32> %420, <4 x i32> %421, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %424 = shufflevector <4 x i32> %422, <4 x i32> %423, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %425 = bitcast <16 x i8> %339 to <4 x i32>
  %426 = bitcast <16 x i8> %342 to <4 x i32>
  %427 = shufflevector <4 x i32> %425, <4 x i32> %426, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %428 = shufflevector <4 x i32> %425, <4 x i32> %426, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %429 = shufflevector <4 x i32> %427, <4 x i32> %428, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %430 = bitcast <16 x i8> %345 to <4 x i32>
  %431 = bitcast <16 x i8> %348 to <4 x i32>
  %432 = shufflevector <4 x i32> %430, <4 x i32> %431, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %433 = shufflevector <4 x i32> %430, <4 x i32> %431, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %434 = shufflevector <4 x i32> %432, <4 x i32> %433, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %435 = bitcast <16 x i8> %351 to <4 x i32>
  %436 = bitcast <16 x i8> %354 to <4 x i32>
  %437 = shufflevector <4 x i32> %435, <4 x i32> %436, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %438 = shufflevector <4 x i32> %435, <4 x i32> %436, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %439 = shufflevector <4 x i32> %437, <4 x i32> %438, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %440 = bitcast <16 x i8> %357 to <4 x i32>
  %441 = bitcast <16 x i8> %360 to <4 x i32>
  %442 = shufflevector <4 x i32> %440, <4 x i32> %441, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %443 = shufflevector <4 x i32> %440, <4 x i32> %441, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %444 = shufflevector <4 x i32> %442, <4 x i32> %443, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %445 = bitcast <16 x i8> %363 to <4 x i32>
  %446 = bitcast <16 x i8> %366 to <4 x i32>
  %447 = shufflevector <4 x i32> %445, <4 x i32> %446, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %448 = shufflevector <4 x i32> %445, <4 x i32> %446, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %449 = shufflevector <4 x i32> %447, <4 x i32> %448, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %450 = bitcast <16 x i8> %369 to <4 x i32>
  %451 = bitcast <16 x i8> %372 to <4 x i32>
  %452 = shufflevector <4 x i32> %450, <4 x i32> %451, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %453 = shufflevector <4 x i32> %450, <4 x i32> %451, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %454 = shufflevector <4 x i32> %452, <4 x i32> %453, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %455 = bitcast <16 x i8> %375 to <4 x i32>
  %456 = bitcast <16 x i8> %378 to <4 x i32>
  %457 = shufflevector <4 x i32> %455, <4 x i32> %456, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %458 = shufflevector <4 x i32> %455, <4 x i32> %456, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %459 = shufflevector <4 x i32> %457, <4 x i32> %458, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %460 = bitcast <16 x i8> %381 to <4 x i32>
  %461 = bitcast <16 x i8> %384 to <4 x i32>
  %462 = shufflevector <4 x i32> %460, <4 x i32> %461, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %463 = shufflevector <4 x i32> %460, <4 x i32> %461, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %464 = shufflevector <4 x i32> %462, <4 x i32> %463, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %465 = add <4 x i32> %409, %389
  %466 = add <4 x i32> %414, %394
  %467 = add <4 x i32> %419, %399
  %468 = add <4 x i32> %424, %404
  %469 = sub <4 x i32> %389, %409
  %470 = sub <4 x i32> %394, %414
  %471 = sub <4 x i32> %399, %419
  %472 = sub <4 x i32> %404, %424
  %473 = shufflevector <4 x i32> %429, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %474 = bitcast <4 x i32> %473 to <2 x i64>
  %475 = shufflevector <4 x i32> %429, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %476 = bitcast <4 x i32> %475 to <2 x i64>
  %477 = shufflevector <4 x i32> %434, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %478 = bitcast <4 x i32> %477 to <2 x i64>
  %479 = shufflevector <4 x i32> %434, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %480 = bitcast <4 x i32> %479 to <2 x i64>
  %481 = shl <2 x i64> %474, <i64 32, i64 32>
  %482 = ashr exact <2 x i64> %481, <i64 32, i64 32>
  %483 = mul nsw <2 x i64> %482, <i64 64276, i64 64276>
  %484 = shl <2 x i64> %476, <i64 32, i64 32>
  %485 = ashr exact <2 x i64> %484, <i64 32, i64 32>
  %486 = mul nsw <2 x i64> %485, <i64 64276, i64 64276>
  %487 = shl <2 x i64> %478, <i64 32, i64 32>
  %488 = ashr exact <2 x i64> %487, <i64 32, i64 32>
  %489 = shl <2 x i64> %480, <i64 32, i64 32>
  %490 = ashr exact <2 x i64> %489, <i64 32, i64 32>
  %491 = mul nsw <2 x i64> %482, <i64 12784, i64 12784>
  %492 = mul nsw <2 x i64> %485, <i64 12784, i64 12784>
  %493 = mul nsw <2 x i64> %488, <i64 12784, i64 12784>
  %494 = mul nsw <2 x i64> %490, <i64 12784, i64 12784>
  %495 = add nsw <2 x i64> %493, %483
  %496 = add nsw <2 x i64> %494, %486
  %497 = mul nsw <2 x i64> %488, <i64 -64276, i64 -64276>
  %498 = add nsw <2 x i64> %491, %497
  %499 = mul nsw <2 x i64> %490, <i64 -64276, i64 -64276>
  %500 = add nsw <2 x i64> %492, %499
  %501 = shufflevector <4 x i32> %439, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %502 = bitcast <4 x i32> %501 to <2 x i64>
  %503 = shufflevector <4 x i32> %439, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %504 = bitcast <4 x i32> %503 to <2 x i64>
  %505 = shufflevector <4 x i32> %444, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %506 = bitcast <4 x i32> %505 to <2 x i64>
  %507 = shufflevector <4 x i32> %444, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %508 = bitcast <4 x i32> %507 to <2 x i64>
  %509 = shl <2 x i64> %502, <i64 32, i64 32>
  %510 = ashr exact <2 x i64> %509, <i64 32, i64 32>
  %511 = mul nsw <2 x i64> %510, <i64 36408, i64 36408>
  %512 = shl <2 x i64> %504, <i64 32, i64 32>
  %513 = ashr exact <2 x i64> %512, <i64 32, i64 32>
  %514 = mul nsw <2 x i64> %513, <i64 36408, i64 36408>
  %515 = shl <2 x i64> %506, <i64 32, i64 32>
  %516 = ashr exact <2 x i64> %515, <i64 32, i64 32>
  %517 = shl <2 x i64> %508, <i64 32, i64 32>
  %518 = ashr exact <2 x i64> %517, <i64 32, i64 32>
  %519 = mul nsw <2 x i64> %510, <i64 54492, i64 54492>
  %520 = mul nsw <2 x i64> %513, <i64 54492, i64 54492>
  %521 = mul nsw <2 x i64> %516, <i64 54492, i64 54492>
  %522 = mul nsw <2 x i64> %518, <i64 54492, i64 54492>
  %523 = add nsw <2 x i64> %521, %511
  %524 = add nsw <2 x i64> %522, %514
  %525 = mul nsw <2 x i64> %516, <i64 -36408, i64 -36408>
  %526 = add nsw <2 x i64> %519, %525
  %527 = mul nsw <2 x i64> %518, <i64 -36408, i64 -36408>
  %528 = add nsw <2 x i64> %520, %527
  %529 = shufflevector <4 x i32> %454, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %530 = bitcast <4 x i32> %529 to <2 x i64>
  %531 = shufflevector <4 x i32> %454, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %532 = bitcast <4 x i32> %531 to <2 x i64>
  %533 = shufflevector <4 x i32> %449, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %534 = bitcast <4 x i32> %533 to <2 x i64>
  %535 = shufflevector <4 x i32> %449, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %536 = bitcast <4 x i32> %535 to <2 x i64>
  %537 = shl <2 x i64> %530, <i64 32, i64 32>
  %538 = ashr exact <2 x i64> %537, <i64 32, i64 32>
  %539 = mul nsw <2 x i64> %538, <i64 12784, i64 12784>
  %540 = shl <2 x i64> %532, <i64 32, i64 32>
  %541 = ashr exact <2 x i64> %540, <i64 32, i64 32>
  %542 = mul nsw <2 x i64> %541, <i64 12784, i64 12784>
  %543 = shl <2 x i64> %534, <i64 32, i64 32>
  %544 = ashr exact <2 x i64> %543, <i64 32, i64 32>
  %545 = shl <2 x i64> %536, <i64 32, i64 32>
  %546 = ashr exact <2 x i64> %545, <i64 32, i64 32>
  %547 = mul nsw <2 x i64> %538, <i64 64276, i64 64276>
  %548 = mul nsw <2 x i64> %541, <i64 64276, i64 64276>
  %549 = mul nsw <2 x i64> %544, <i64 64276, i64 64276>
  %550 = mul nsw <2 x i64> %546, <i64 64276, i64 64276>
  %551 = add nsw <2 x i64> %549, %539
  %552 = add nsw <2 x i64> %550, %542
  %553 = mul nsw <2 x i64> %544, <i64 -12784, i64 -12784>
  %554 = add nsw <2 x i64> %547, %553
  %555 = mul nsw <2 x i64> %546, <i64 -12784, i64 -12784>
  %556 = add nsw <2 x i64> %548, %555
  %557 = shufflevector <4 x i32> %464, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %558 = bitcast <4 x i32> %557 to <2 x i64>
  %559 = shufflevector <4 x i32> %464, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %560 = bitcast <4 x i32> %559 to <2 x i64>
  %561 = shufflevector <4 x i32> %459, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %562 = bitcast <4 x i32> %561 to <2 x i64>
  %563 = shufflevector <4 x i32> %459, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %564 = bitcast <4 x i32> %563 to <2 x i64>
  %565 = shl <2 x i64> %558, <i64 32, i64 32>
  %566 = ashr exact <2 x i64> %565, <i64 32, i64 32>
  %567 = mul nsw <2 x i64> %566, <i64 54492, i64 54492>
  %568 = shl <2 x i64> %560, <i64 32, i64 32>
  %569 = ashr exact <2 x i64> %568, <i64 32, i64 32>
  %570 = mul nsw <2 x i64> %569, <i64 54492, i64 54492>
  %571 = shl <2 x i64> %562, <i64 32, i64 32>
  %572 = ashr exact <2 x i64> %571, <i64 32, i64 32>
  %573 = shl <2 x i64> %564, <i64 32, i64 32>
  %574 = ashr exact <2 x i64> %573, <i64 32, i64 32>
  %575 = mul nsw <2 x i64> %566, <i64 36408, i64 36408>
  %576 = mul nsw <2 x i64> %569, <i64 36408, i64 36408>
  %577 = mul nsw <2 x i64> %572, <i64 36408, i64 36408>
  %578 = mul nsw <2 x i64> %574, <i64 36408, i64 36408>
  %579 = add nsw <2 x i64> %577, %567
  %580 = add nsw <2 x i64> %578, %570
  %581 = mul nsw <2 x i64> %572, <i64 -54492, i64 -54492>
  %582 = add nsw <2 x i64> %575, %581
  %583 = mul nsw <2 x i64> %574, <i64 -54492, i64 -54492>
  %584 = add nsw <2 x i64> %576, %583
  %585 = add nsw <2 x i64> %495, <i64 32768, i64 32768>
  %586 = add nsw <2 x i64> %585, %554
  %587 = bitcast <2 x i64> %586 to <16 x i8>
  %588 = shufflevector <16 x i8> %587, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %589 = add nsw <2 x i64> %496, <i64 32768, i64 32768>
  %590 = add nsw <2 x i64> %589, %556
  %591 = bitcast <2 x i64> %590 to <16 x i8>
  %592 = shufflevector <16 x i8> %591, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %593 = add nsw <2 x i64> %498, <i64 32768, i64 32768>
  %594 = add nsw <2 x i64> %593, %551
  %595 = bitcast <2 x i64> %594 to <16 x i8>
  %596 = shufflevector <16 x i8> %595, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %597 = add nsw <2 x i64> %500, <i64 32768, i64 32768>
  %598 = add nsw <2 x i64> %597, %552
  %599 = bitcast <2 x i64> %598 to <16 x i8>
  %600 = shufflevector <16 x i8> %599, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %601 = add nsw <2 x i64> %523, <i64 32768, i64 32768>
  %602 = add nsw <2 x i64> %601, %582
  %603 = bitcast <2 x i64> %602 to <16 x i8>
  %604 = shufflevector <16 x i8> %603, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %605 = add nsw <2 x i64> %524, <i64 32768, i64 32768>
  %606 = add nsw <2 x i64> %605, %584
  %607 = bitcast <2 x i64> %606 to <16 x i8>
  %608 = shufflevector <16 x i8> %607, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %609 = add nsw <2 x i64> %526, <i64 32768, i64 32768>
  %610 = add nsw <2 x i64> %609, %579
  %611 = bitcast <2 x i64> %610 to <16 x i8>
  %612 = shufflevector <16 x i8> %611, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %613 = add nsw <2 x i64> %528, <i64 32768, i64 32768>
  %614 = add nsw <2 x i64> %613, %580
  %615 = bitcast <2 x i64> %614 to <16 x i8>
  %616 = shufflevector <16 x i8> %615, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %617 = sub nsw <2 x i64> %585, %554
  %618 = bitcast <2 x i64> %617 to <16 x i8>
  %619 = shufflevector <16 x i8> %618, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %620 = sub nsw <2 x i64> %589, %556
  %621 = bitcast <2 x i64> %620 to <16 x i8>
  %622 = shufflevector <16 x i8> %621, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %623 = sub nsw <2 x i64> %593, %551
  %624 = bitcast <2 x i64> %623 to <16 x i8>
  %625 = shufflevector <16 x i8> %624, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %626 = sub nsw <2 x i64> %597, %552
  %627 = bitcast <2 x i64> %626 to <16 x i8>
  %628 = shufflevector <16 x i8> %627, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %629 = sub nsw <2 x i64> %601, %582
  %630 = bitcast <2 x i64> %629 to <16 x i8>
  %631 = shufflevector <16 x i8> %630, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %632 = sub nsw <2 x i64> %605, %584
  %633 = bitcast <2 x i64> %632 to <16 x i8>
  %634 = shufflevector <16 x i8> %633, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %635 = sub nsw <2 x i64> %609, %579
  %636 = bitcast <2 x i64> %635 to <16 x i8>
  %637 = shufflevector <16 x i8> %636, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %638 = sub nsw <2 x i64> %613, %580
  %639 = bitcast <2 x i64> %638 to <16 x i8>
  %640 = shufflevector <16 x i8> %639, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %641 = bitcast <16 x i8> %588 to <4 x i32>
  %642 = bitcast <16 x i8> %592 to <4 x i32>
  %643 = shufflevector <4 x i32> %641, <4 x i32> %642, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %644 = shufflevector <4 x i32> %641, <4 x i32> %642, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %645 = shufflevector <4 x i32> %643, <4 x i32> %644, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %646 = bitcast <16 x i8> %596 to <4 x i32>
  %647 = bitcast <16 x i8> %600 to <4 x i32>
  %648 = shufflevector <4 x i32> %646, <4 x i32> %647, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %649 = shufflevector <4 x i32> %646, <4 x i32> %647, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %650 = shufflevector <4 x i32> %648, <4 x i32> %649, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %651 = bitcast <16 x i8> %604 to <4 x i32>
  %652 = bitcast <16 x i8> %608 to <4 x i32>
  %653 = shufflevector <4 x i32> %651, <4 x i32> %652, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %654 = shufflevector <4 x i32> %651, <4 x i32> %652, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %655 = shufflevector <4 x i32> %653, <4 x i32> %654, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %656 = bitcast <16 x i8> %612 to <4 x i32>
  %657 = bitcast <16 x i8> %616 to <4 x i32>
  %658 = shufflevector <4 x i32> %656, <4 x i32> %657, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %659 = shufflevector <4 x i32> %656, <4 x i32> %657, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %660 = shufflevector <4 x i32> %658, <4 x i32> %659, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %661 = bitcast <16 x i8> %619 to <4 x i32>
  %662 = bitcast <16 x i8> %622 to <4 x i32>
  %663 = shufflevector <4 x i32> %661, <4 x i32> %662, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %664 = shufflevector <4 x i32> %661, <4 x i32> %662, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %665 = shufflevector <4 x i32> %663, <4 x i32> %664, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %666 = bitcast <16 x i8> %625 to <4 x i32>
  %667 = bitcast <16 x i8> %628 to <4 x i32>
  %668 = shufflevector <4 x i32> %666, <4 x i32> %667, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %669 = shufflevector <4 x i32> %666, <4 x i32> %667, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %670 = shufflevector <4 x i32> %668, <4 x i32> %669, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %671 = bitcast <16 x i8> %631 to <4 x i32>
  %672 = bitcast <16 x i8> %634 to <4 x i32>
  %673 = shufflevector <4 x i32> %671, <4 x i32> %672, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %674 = shufflevector <4 x i32> %671, <4 x i32> %672, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %675 = shufflevector <4 x i32> %673, <4 x i32> %674, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %676 = bitcast <16 x i8> %637 to <4 x i32>
  %677 = bitcast <16 x i8> %640 to <4 x i32>
  %678 = shufflevector <4 x i32> %676, <4 x i32> %677, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %679 = shufflevector <4 x i32> %676, <4 x i32> %677, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %680 = shufflevector <4 x i32> %678, <4 x i32> %679, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %681 = shufflevector <4 x i32> %469, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %682 = bitcast <4 x i32> %681 to <2 x i64>
  %683 = shufflevector <4 x i32> %469, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %684 = bitcast <4 x i32> %683 to <2 x i64>
  %685 = shufflevector <4 x i32> %470, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %686 = bitcast <4 x i32> %685 to <2 x i64>
  %687 = shufflevector <4 x i32> %470, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %688 = bitcast <4 x i32> %687 to <2 x i64>
  %689 = shl <2 x i64> %682, <i64 32, i64 32>
  %690 = ashr exact <2 x i64> %689, <i64 32, i64 32>
  %691 = mul nsw <2 x i64> %690, <i64 60548, i64 60548>
  %692 = shl <2 x i64> %684, <i64 32, i64 32>
  %693 = ashr exact <2 x i64> %692, <i64 32, i64 32>
  %694 = mul nsw <2 x i64> %693, <i64 60548, i64 60548>
  %695 = shl <2 x i64> %686, <i64 32, i64 32>
  %696 = ashr exact <2 x i64> %695, <i64 32, i64 32>
  %697 = shl <2 x i64> %688, <i64 32, i64 32>
  %698 = ashr exact <2 x i64> %697, <i64 32, i64 32>
  %699 = mul nsw <2 x i64> %690, <i64 25080, i64 25080>
  %700 = mul nsw <2 x i64> %693, <i64 25080, i64 25080>
  %701 = mul nsw <2 x i64> %696, <i64 25080, i64 25080>
  %702 = mul nsw <2 x i64> %698, <i64 25080, i64 25080>
  %703 = add nsw <2 x i64> %701, %691
  %704 = add nsw <2 x i64> %702, %694
  %705 = mul nsw <2 x i64> %696, <i64 -60548, i64 -60548>
  %706 = add nsw <2 x i64> %699, %705
  %707 = mul nsw <2 x i64> %698, <i64 -60548, i64 -60548>
  %708 = add nsw <2 x i64> %700, %707
  %709 = shufflevector <4 x i32> %472, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %710 = bitcast <4 x i32> %709 to <2 x i64>
  %711 = shufflevector <4 x i32> %472, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %712 = bitcast <4 x i32> %711 to <2 x i64>
  %713 = shufflevector <4 x i32> %471, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %714 = bitcast <4 x i32> %713 to <2 x i64>
  %715 = shufflevector <4 x i32> %471, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %716 = bitcast <4 x i32> %715 to <2 x i64>
  %717 = shl <2 x i64> %710, <i64 32, i64 32>
  %718 = ashr exact <2 x i64> %717, <i64 32, i64 32>
  %719 = mul nsw <2 x i64> %718, <i64 25080, i64 25080>
  %720 = shl <2 x i64> %712, <i64 32, i64 32>
  %721 = ashr exact <2 x i64> %720, <i64 32, i64 32>
  %722 = mul nsw <2 x i64> %721, <i64 25080, i64 25080>
  %723 = shl <2 x i64> %714, <i64 32, i64 32>
  %724 = ashr exact <2 x i64> %723, <i64 32, i64 32>
  %725 = shl <2 x i64> %716, <i64 32, i64 32>
  %726 = ashr exact <2 x i64> %725, <i64 32, i64 32>
  %727 = mul nsw <2 x i64> %718, <i64 60548, i64 60548>
  %728 = mul nsw <2 x i64> %721, <i64 60548, i64 60548>
  %729 = mul nsw <2 x i64> %724, <i64 60548, i64 60548>
  %730 = mul nsw <2 x i64> %726, <i64 60548, i64 60548>
  %731 = add nsw <2 x i64> %729, %719
  %732 = add nsw <2 x i64> %730, %722
  %733 = mul nsw <2 x i64> %724, <i64 -25080, i64 -25080>
  %734 = add nsw <2 x i64> %727, %733
  %735 = mul nsw <2 x i64> %726, <i64 -25080, i64 -25080>
  %736 = add nsw <2 x i64> %728, %735
  %737 = shufflevector <4 x i32> %665, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %738 = bitcast <4 x i32> %737 to <2 x i64>
  %739 = shufflevector <4 x i32> %665, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %740 = bitcast <4 x i32> %739 to <2 x i64>
  %741 = shufflevector <4 x i32> %670, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %742 = bitcast <4 x i32> %741 to <2 x i64>
  %743 = shufflevector <4 x i32> %670, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %744 = bitcast <4 x i32> %743 to <2 x i64>
  %745 = shl <2 x i64> %738, <i64 32, i64 32>
  %746 = ashr exact <2 x i64> %745, <i64 32, i64 32>
  %747 = mul nsw <2 x i64> %746, <i64 60548, i64 60548>
  %748 = shl <2 x i64> %740, <i64 32, i64 32>
  %749 = ashr exact <2 x i64> %748, <i64 32, i64 32>
  %750 = mul nsw <2 x i64> %749, <i64 60548, i64 60548>
  %751 = shl <2 x i64> %742, <i64 32, i64 32>
  %752 = ashr exact <2 x i64> %751, <i64 32, i64 32>
  %753 = shl <2 x i64> %744, <i64 32, i64 32>
  %754 = ashr exact <2 x i64> %753, <i64 32, i64 32>
  %755 = mul nsw <2 x i64> %746, <i64 25080, i64 25080>
  %756 = mul nsw <2 x i64> %749, <i64 25080, i64 25080>
  %757 = mul nsw <2 x i64> %752, <i64 25080, i64 25080>
  %758 = mul nsw <2 x i64> %754, <i64 25080, i64 25080>
  %759 = add nsw <2 x i64> %757, %747
  %760 = add nsw <2 x i64> %758, %750
  %761 = mul nsw <2 x i64> %752, <i64 -60548, i64 -60548>
  %762 = add nsw <2 x i64> %755, %761
  %763 = mul nsw <2 x i64> %754, <i64 -60548, i64 -60548>
  %764 = add nsw <2 x i64> %756, %763
  %765 = shufflevector <4 x i32> %680, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %766 = bitcast <4 x i32> %765 to <2 x i64>
  %767 = shufflevector <4 x i32> %680, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %768 = bitcast <4 x i32> %767 to <2 x i64>
  %769 = shufflevector <4 x i32> %675, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %770 = bitcast <4 x i32> %769 to <2 x i64>
  %771 = shufflevector <4 x i32> %675, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %772 = bitcast <4 x i32> %771 to <2 x i64>
  %773 = shl <2 x i64> %766, <i64 32, i64 32>
  %774 = ashr exact <2 x i64> %773, <i64 32, i64 32>
  %775 = mul nsw <2 x i64> %774, <i64 25080, i64 25080>
  %776 = shl <2 x i64> %768, <i64 32, i64 32>
  %777 = ashr exact <2 x i64> %776, <i64 32, i64 32>
  %778 = mul nsw <2 x i64> %777, <i64 25080, i64 25080>
  %779 = shl <2 x i64> %770, <i64 32, i64 32>
  %780 = ashr exact <2 x i64> %779, <i64 32, i64 32>
  %781 = shl <2 x i64> %772, <i64 32, i64 32>
  %782 = ashr exact <2 x i64> %781, <i64 32, i64 32>
  %783 = mul nsw <2 x i64> %774, <i64 60548, i64 60548>
  %784 = mul nsw <2 x i64> %777, <i64 60548, i64 60548>
  %785 = mul nsw <2 x i64> %780, <i64 60548, i64 60548>
  %786 = mul nsw <2 x i64> %782, <i64 60548, i64 60548>
  %787 = add nsw <2 x i64> %785, %775
  %788 = add nsw <2 x i64> %786, %778
  %789 = mul nsw <2 x i64> %780, <i64 -25080, i64 -25080>
  %790 = add nsw <2 x i64> %783, %789
  %791 = mul nsw <2 x i64> %782, <i64 -25080, i64 -25080>
  %792 = add nsw <2 x i64> %784, %791
  %793 = add <4 x i32> %467, %465
  %794 = add <4 x i32> %466, %468
  %795 = sub <4 x i32> %465, %467
  %796 = sub <4 x i32> %466, %468
  %797 = add nsw <2 x i64> %703, <i64 32768, i64 32768>
  %798 = add nsw <2 x i64> %797, %734
  %799 = bitcast <2 x i64> %798 to <16 x i8>
  %800 = shufflevector <16 x i8> %799, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %801 = add nsw <2 x i64> %704, <i64 32768, i64 32768>
  %802 = add nsw <2 x i64> %801, %736
  %803 = bitcast <2 x i64> %802 to <16 x i8>
  %804 = shufflevector <16 x i8> %803, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %805 = add nsw <2 x i64> %706, <i64 32768, i64 32768>
  %806 = add nsw <2 x i64> %805, %731
  %807 = bitcast <2 x i64> %806 to <16 x i8>
  %808 = shufflevector <16 x i8> %807, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %809 = add nsw <2 x i64> %708, <i64 32768, i64 32768>
  %810 = add nsw <2 x i64> %809, %732
  %811 = bitcast <2 x i64> %810 to <16 x i8>
  %812 = shufflevector <16 x i8> %811, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %813 = sub nsw <2 x i64> %797, %734
  %814 = bitcast <2 x i64> %813 to <16 x i8>
  %815 = shufflevector <16 x i8> %814, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %816 = sub nsw <2 x i64> %801, %736
  %817 = bitcast <2 x i64> %816 to <16 x i8>
  %818 = shufflevector <16 x i8> %817, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %819 = sub nsw <2 x i64> %805, %731
  %820 = bitcast <2 x i64> %819 to <16 x i8>
  %821 = shufflevector <16 x i8> %820, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %822 = sub nsw <2 x i64> %809, %732
  %823 = bitcast <2 x i64> %822 to <16 x i8>
  %824 = shufflevector <16 x i8> %823, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %825 = bitcast <16 x i8> %800 to <4 x i32>
  %826 = bitcast <16 x i8> %804 to <4 x i32>
  %827 = shufflevector <4 x i32> %825, <4 x i32> %826, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %828 = shufflevector <4 x i32> %825, <4 x i32> %826, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %829 = shufflevector <4 x i32> %827, <4 x i32> %828, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %830 = bitcast <16 x i8> %808 to <4 x i32>
  %831 = bitcast <16 x i8> %812 to <4 x i32>
  %832 = shufflevector <4 x i32> %830, <4 x i32> %831, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %833 = shufflevector <4 x i32> %830, <4 x i32> %831, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %834 = shufflevector <4 x i32> %832, <4 x i32> %833, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %835 = bitcast <16 x i8> %815 to <4 x i32>
  %836 = bitcast <16 x i8> %818 to <4 x i32>
  %837 = shufflevector <4 x i32> %835, <4 x i32> %836, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %838 = shufflevector <4 x i32> %835, <4 x i32> %836, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %839 = shufflevector <4 x i32> %837, <4 x i32> %838, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %840 = bitcast <16 x i8> %821 to <4 x i32>
  %841 = bitcast <16 x i8> %824 to <4 x i32>
  %842 = shufflevector <4 x i32> %840, <4 x i32> %841, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %843 = shufflevector <4 x i32> %840, <4 x i32> %841, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %844 = shufflevector <4 x i32> %842, <4 x i32> %843, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %845 = add <4 x i32> %645, %655
  %846 = add <4 x i32> %660, %650
  %847 = sub <4 x i32> %645, %655
  %848 = sub <4 x i32> %650, %660
  %849 = add nsw <2 x i64> %759, <i64 32768, i64 32768>
  %850 = add nsw <2 x i64> %849, %790
  %851 = bitcast <2 x i64> %850 to <16 x i8>
  %852 = shufflevector <16 x i8> %851, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %853 = add nsw <2 x i64> %760, <i64 32768, i64 32768>
  %854 = add nsw <2 x i64> %853, %792
  %855 = bitcast <2 x i64> %854 to <16 x i8>
  %856 = shufflevector <16 x i8> %855, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %857 = add nsw <2 x i64> %762, <i64 32768, i64 32768>
  %858 = add nsw <2 x i64> %857, %787
  %859 = bitcast <2 x i64> %858 to <16 x i8>
  %860 = shufflevector <16 x i8> %859, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %861 = add nsw <2 x i64> %764, <i64 32768, i64 32768>
  %862 = add nsw <2 x i64> %861, %788
  %863 = bitcast <2 x i64> %862 to <16 x i8>
  %864 = shufflevector <16 x i8> %863, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %865 = sub nsw <2 x i64> %849, %790
  %866 = bitcast <2 x i64> %865 to <16 x i8>
  %867 = shufflevector <16 x i8> %866, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %868 = sub nsw <2 x i64> %853, %792
  %869 = bitcast <2 x i64> %868 to <16 x i8>
  %870 = shufflevector <16 x i8> %869, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %871 = sub nsw <2 x i64> %857, %787
  %872 = bitcast <2 x i64> %871 to <16 x i8>
  %873 = shufflevector <16 x i8> %872, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %874 = sub nsw <2 x i64> %861, %788
  %875 = bitcast <2 x i64> %874 to <16 x i8>
  %876 = shufflevector <16 x i8> %875, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %877 = bitcast <16 x i8> %852 to <4 x i32>
  %878 = bitcast <16 x i8> %856 to <4 x i32>
  %879 = shufflevector <4 x i32> %877, <4 x i32> %878, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %880 = shufflevector <4 x i32> %877, <4 x i32> %878, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %881 = shufflevector <4 x i32> %879, <4 x i32> %880, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %882 = bitcast <16 x i8> %860 to <4 x i32>
  %883 = bitcast <16 x i8> %864 to <4 x i32>
  %884 = shufflevector <4 x i32> %882, <4 x i32> %883, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %885 = shufflevector <4 x i32> %882, <4 x i32> %883, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %886 = shufflevector <4 x i32> %884, <4 x i32> %885, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %887 = bitcast <16 x i8> %867 to <4 x i32>
  %888 = bitcast <16 x i8> %870 to <4 x i32>
  %889 = shufflevector <4 x i32> %887, <4 x i32> %888, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %890 = shufflevector <4 x i32> %887, <4 x i32> %888, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %891 = shufflevector <4 x i32> %889, <4 x i32> %890, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %892 = bitcast <16 x i8> %873 to <4 x i32>
  %893 = bitcast <16 x i8> %876 to <4 x i32>
  %894 = shufflevector <4 x i32> %892, <4 x i32> %893, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %895 = shufflevector <4 x i32> %892, <4 x i32> %893, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %896 = shufflevector <4 x i32> %894, <4 x i32> %895, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %897 = add <4 x i32> %796, %795
  %898 = sub <4 x i32> %795, %796
  %899 = add <4 x i32> %839, %844
  %900 = sub <4 x i32> %844, %839
  %901 = add <4 x i32> %847, %848
  %902 = sub <4 x i32> %848, %847
  %903 = add <4 x i32> %896, %891
  %904 = sub <4 x i32> %891, %896
  %905 = shufflevector <4 x i32> %897, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %906 = bitcast <4 x i32> %905 to <2 x i64>
  %907 = shufflevector <4 x i32> %897, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %908 = bitcast <4 x i32> %907 to <2 x i64>
  %909 = shl <2 x i64> %906, <i64 32, i64 32>
  %910 = ashr exact <2 x i64> %909, <i64 32, i64 32>
  %911 = mul nsw <2 x i64> %910, <i64 -46340, i64 -46340>
  %912 = shl <2 x i64> %908, <i64 32, i64 32>
  %913 = ashr exact <2 x i64> %912, <i64 32, i64 32>
  %914 = mul nsw <2 x i64> %913, <i64 -46340, i64 -46340>
  %915 = shufflevector <4 x i32> %898, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %916 = bitcast <4 x i32> %915 to <2 x i64>
  %917 = shufflevector <4 x i32> %898, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %918 = bitcast <4 x i32> %917 to <2 x i64>
  %919 = shl <2 x i64> %916, <i64 32, i64 32>
  %920 = ashr exact <2 x i64> %919, <i64 32, i64 32>
  %921 = mul nsw <2 x i64> %920, <i64 46340, i64 46340>
  %922 = shl <2 x i64> %918, <i64 32, i64 32>
  %923 = ashr exact <2 x i64> %922, <i64 32, i64 32>
  %924 = mul nsw <2 x i64> %923, <i64 46340, i64 46340>
  %925 = shufflevector <4 x i32> %899, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %926 = bitcast <4 x i32> %925 to <2 x i64>
  %927 = shufflevector <4 x i32> %899, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %928 = bitcast <4 x i32> %927 to <2 x i64>
  %929 = shl <2 x i64> %926, <i64 32, i64 32>
  %930 = ashr exact <2 x i64> %929, <i64 32, i64 32>
  %931 = mul nsw <2 x i64> %930, <i64 46340, i64 46340>
  %932 = shl <2 x i64> %928, <i64 32, i64 32>
  %933 = ashr exact <2 x i64> %932, <i64 32, i64 32>
  %934 = mul nsw <2 x i64> %933, <i64 46340, i64 46340>
  %935 = shufflevector <4 x i32> %900, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %936 = bitcast <4 x i32> %935 to <2 x i64>
  %937 = shufflevector <4 x i32> %900, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %938 = bitcast <4 x i32> %937 to <2 x i64>
  %939 = shl <2 x i64> %936, <i64 32, i64 32>
  %940 = ashr exact <2 x i64> %939, <i64 32, i64 32>
  %941 = mul nsw <2 x i64> %940, <i64 46340, i64 46340>
  %942 = shl <2 x i64> %938, <i64 32, i64 32>
  %943 = ashr exact <2 x i64> %942, <i64 32, i64 32>
  %944 = mul nsw <2 x i64> %943, <i64 46340, i64 46340>
  %945 = shufflevector <4 x i32> %901, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %946 = bitcast <4 x i32> %945 to <2 x i64>
  %947 = shufflevector <4 x i32> %901, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %948 = bitcast <4 x i32> %947 to <2 x i64>
  %949 = shl <2 x i64> %946, <i64 32, i64 32>
  %950 = ashr exact <2 x i64> %949, <i64 32, i64 32>
  %951 = mul nsw <2 x i64> %950, <i64 46340, i64 46340>
  %952 = shl <2 x i64> %948, <i64 32, i64 32>
  %953 = ashr exact <2 x i64> %952, <i64 32, i64 32>
  %954 = mul nsw <2 x i64> %953, <i64 46340, i64 46340>
  %955 = shufflevector <4 x i32> %902, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %956 = bitcast <4 x i32> %955 to <2 x i64>
  %957 = shufflevector <4 x i32> %902, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %958 = bitcast <4 x i32> %957 to <2 x i64>
  %959 = shl <2 x i64> %956, <i64 32, i64 32>
  %960 = ashr exact <2 x i64> %959, <i64 32, i64 32>
  %961 = mul nsw <2 x i64> %960, <i64 46340, i64 46340>
  %962 = shl <2 x i64> %958, <i64 32, i64 32>
  %963 = ashr exact <2 x i64> %962, <i64 32, i64 32>
  %964 = mul nsw <2 x i64> %963, <i64 46340, i64 46340>
  %965 = shufflevector <4 x i32> %903, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %966 = bitcast <4 x i32> %965 to <2 x i64>
  %967 = shufflevector <4 x i32> %903, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %968 = bitcast <4 x i32> %967 to <2 x i64>
  %969 = shl <2 x i64> %966, <i64 32, i64 32>
  %970 = ashr exact <2 x i64> %969, <i64 32, i64 32>
  %971 = mul nsw <2 x i64> %970, <i64 -46340, i64 -46340>
  %972 = shl <2 x i64> %968, <i64 32, i64 32>
  %973 = ashr exact <2 x i64> %972, <i64 32, i64 32>
  %974 = mul nsw <2 x i64> %973, <i64 -46340, i64 -46340>
  %975 = shufflevector <4 x i32> %904, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
  %976 = bitcast <4 x i32> %975 to <2 x i64>
  %977 = shufflevector <4 x i32> %904, <4 x i32> undef, <4 x i32> <i32 2, i32 2, i32 3, i32 3>
  %978 = bitcast <4 x i32> %977 to <2 x i64>
  %979 = shl <2 x i64> %976, <i64 32, i64 32>
  %980 = ashr exact <2 x i64> %979, <i64 32, i64 32>
  %981 = mul nsw <2 x i64> %980, <i64 46340, i64 46340>
  %982 = shl <2 x i64> %978, <i64 32, i64 32>
  %983 = ashr exact <2 x i64> %982, <i64 32, i64 32>
  %984 = mul nsw <2 x i64> %983, <i64 46340, i64 46340>
  %985 = add nsw <2 x i64> %911, <i64 32768, i64 32768>
  %986 = bitcast <2 x i64> %985 to <16 x i8>
  %987 = shufflevector <16 x i8> %986, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %988 = add nsw <2 x i64> %914, <i64 32768, i64 32768>
  %989 = bitcast <2 x i64> %988 to <16 x i8>
  %990 = shufflevector <16 x i8> %989, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %991 = add nsw <2 x i64> %921, <i64 32768, i64 32768>
  %992 = bitcast <2 x i64> %991 to <16 x i8>
  %993 = shufflevector <16 x i8> %992, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %994 = add nsw <2 x i64> %924, <i64 32768, i64 32768>
  %995 = bitcast <2 x i64> %994 to <16 x i8>
  %996 = shufflevector <16 x i8> %995, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %997 = add nsw <2 x i64> %931, <i64 32768, i64 32768>
  %998 = bitcast <2 x i64> %997 to <16 x i8>
  %999 = shufflevector <16 x i8> %998, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1000 = add nsw <2 x i64> %934, <i64 32768, i64 32768>
  %1001 = bitcast <2 x i64> %1000 to <16 x i8>
  %1002 = shufflevector <16 x i8> %1001, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1003 = add nsw <2 x i64> %941, <i64 32768, i64 32768>
  %1004 = bitcast <2 x i64> %1003 to <16 x i8>
  %1005 = shufflevector <16 x i8> %1004, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1006 = add nsw <2 x i64> %944, <i64 32768, i64 32768>
  %1007 = bitcast <2 x i64> %1006 to <16 x i8>
  %1008 = shufflevector <16 x i8> %1007, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1009 = add nsw <2 x i64> %951, <i64 32768, i64 32768>
  %1010 = bitcast <2 x i64> %1009 to <16 x i8>
  %1011 = shufflevector <16 x i8> %1010, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1012 = add nsw <2 x i64> %954, <i64 32768, i64 32768>
  %1013 = bitcast <2 x i64> %1012 to <16 x i8>
  %1014 = shufflevector <16 x i8> %1013, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1015 = add nsw <2 x i64> %961, <i64 32768, i64 32768>
  %1016 = bitcast <2 x i64> %1015 to <16 x i8>
  %1017 = shufflevector <16 x i8> %1016, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1018 = add nsw <2 x i64> %964, <i64 32768, i64 32768>
  %1019 = bitcast <2 x i64> %1018 to <16 x i8>
  %1020 = shufflevector <16 x i8> %1019, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1021 = add nsw <2 x i64> %971, <i64 32768, i64 32768>
  %1022 = bitcast <2 x i64> %1021 to <16 x i8>
  %1023 = shufflevector <16 x i8> %1022, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1024 = add nsw <2 x i64> %974, <i64 32768, i64 32768>
  %1025 = bitcast <2 x i64> %1024 to <16 x i8>
  %1026 = shufflevector <16 x i8> %1025, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1027 = add nsw <2 x i64> %981, <i64 32768, i64 32768>
  %1028 = bitcast <2 x i64> %1027 to <16 x i8>
  %1029 = shufflevector <16 x i8> %1028, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1030 = add nsw <2 x i64> %984, <i64 32768, i64 32768>
  %1031 = bitcast <2 x i64> %1030 to <16 x i8>
  %1032 = shufflevector <16 x i8> %1031, <16 x i8> <i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17>
  %1033 = bitcast <16 x i8> %987 to <4 x i32>
  %1034 = bitcast <16 x i8> %990 to <4 x i32>
  %1035 = shufflevector <4 x i32> %1033, <4 x i32> %1034, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1036 = shufflevector <4 x i32> %1033, <4 x i32> %1034, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1037 = shufflevector <4 x i32> %1035, <4 x i32> %1036, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1038 = bitcast <16 x i8> %993 to <4 x i32>
  %1039 = bitcast <16 x i8> %996 to <4 x i32>
  %1040 = shufflevector <4 x i32> %1038, <4 x i32> %1039, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1041 = shufflevector <4 x i32> %1038, <4 x i32> %1039, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1042 = shufflevector <4 x i32> %1040, <4 x i32> %1041, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1043 = bitcast <16 x i8> %999 to <4 x i32>
  %1044 = bitcast <16 x i8> %1002 to <4 x i32>
  %1045 = shufflevector <4 x i32> %1043, <4 x i32> %1044, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1046 = shufflevector <4 x i32> %1043, <4 x i32> %1044, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1047 = shufflevector <4 x i32> %1045, <4 x i32> %1046, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1048 = bitcast <16 x i8> %1005 to <4 x i32>
  %1049 = bitcast <16 x i8> %1008 to <4 x i32>
  %1050 = shufflevector <4 x i32> %1048, <4 x i32> %1049, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1051 = shufflevector <4 x i32> %1048, <4 x i32> %1049, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1052 = shufflevector <4 x i32> %1050, <4 x i32> %1051, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1053 = bitcast <16 x i8> %1011 to <4 x i32>
  %1054 = bitcast <16 x i8> %1014 to <4 x i32>
  %1055 = shufflevector <4 x i32> %1053, <4 x i32> %1054, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1056 = shufflevector <4 x i32> %1053, <4 x i32> %1054, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1057 = shufflevector <4 x i32> %1055, <4 x i32> %1056, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1058 = bitcast <16 x i8> %1017 to <4 x i32>
  %1059 = bitcast <16 x i8> %1020 to <4 x i32>
  %1060 = shufflevector <4 x i32> %1058, <4 x i32> %1059, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1061 = shufflevector <4 x i32> %1058, <4 x i32> %1059, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1062 = shufflevector <4 x i32> %1060, <4 x i32> %1061, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1063 = bitcast <16 x i8> %1023 to <4 x i32>
  %1064 = bitcast <16 x i8> %1026 to <4 x i32>
  %1065 = shufflevector <4 x i32> %1063, <4 x i32> %1064, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1066 = shufflevector <4 x i32> %1063, <4 x i32> %1064, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1067 = shufflevector <4 x i32> %1065, <4 x i32> %1066, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1068 = bitcast <16 x i8> %1029 to <4 x i32>
  %1069 = bitcast <16 x i8> %1032 to <4 x i32>
  %1070 = shufflevector <4 x i32> %1068, <4 x i32> %1069, <4 x i32> <i32 0, i32 4, i32 undef, i32 undef>
  %1071 = shufflevector <4 x i32> %1068, <4 x i32> %1069, <4 x i32> <i32 2, i32 6, i32 undef, i32 undef>
  %1072 = shufflevector <4 x i32> %1070, <4 x i32> %1071, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  store <4 x i32> %793, <4 x i32>* %5, align 16
  %1073 = sub <4 x i32> zeroinitializer, %845
  store <4 x i32> %1073, <4 x i32>* %240, align 16
  store <4 x i32> %881, <4 x i32>* %39, align 16
  %1074 = sub <4 x i32> zeroinitializer, %829
  store <4 x i32> %1074, <4 x i32>* %206, align 16
  store <4 x i32> %1047, <4 x i32>* %73, align 16
  store <4 x i32> %1067, <4 x i32>* %172, align 16
  store <4 x i32> %1057, <4 x i32>* %107, align 16
  store <4 x i32> %1037, <4 x i32>* %138, align 16
  store <4 x i32> %1042, <4 x i32>* %141, align 16
  store <4 x i32> %1062, <4 x i32>* %104, align 16
  store <4 x i32> %1072, <4 x i32>* %175, align 16
  store <4 x i32> %1052, <4 x i32>* %70, align 16
  store <4 x i32> %834, <4 x i32>* %209, align 16
  %1075 = sub <4 x i32> zeroinitializer, %886
  store <4 x i32> %1075, <4 x i32>* %36, align 16
  store <4 x i32> %846, <4 x i32>* %243, align 16
  %1076 = sub <4 x i32> zeroinitializer, %794
  store <4 x i32> %1076, <4 x i32>* %3, align 16
  ret void
}

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32>, <4 x i32>) #4

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16>, <8 x i16>) #5

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16>, i32) #4

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind readnone }
attributes #5 = { nounwind readnone speculatable }
attributes #6 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
