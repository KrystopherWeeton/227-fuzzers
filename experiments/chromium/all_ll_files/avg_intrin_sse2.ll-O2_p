; ModuleID = '../../third_party/libvpx/source/libvpx/vpx_dsp/x86/avg_intrin_sse2.c'
source_filename = "../../third_party/libvpx/source/libvpx/vpx_dsp/x86/avg_intrin_sse2.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @vpx_minmax_8x8_sse2(i8* nocapture readonly, i32, i8* nocapture readonly, i32, i32* nocapture, i32* nocapture) local_unnamed_addr #0 {
  %7 = bitcast i8* %0 to i64*
  %8 = load i64, i64* %7, align 1
  %9 = insertelement <2 x i64> undef, i64 %8, i32 0
  %10 = bitcast <2 x i64> %9 to <16 x i8>
  %11 = shufflevector <16 x i8> %10, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %12 = bitcast i8* %2 to i64*
  %13 = load i64, i64* %12, align 1
  %14 = insertelement <2 x i64> undef, i64 %13, i32 0
  %15 = bitcast <2 x i64> %14 to <16 x i8>
  %16 = shufflevector <16 x i8> %15, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %17 = bitcast <16 x i8> %11 to <8 x i16>
  %18 = bitcast <16 x i8> %16 to <8 x i16>
  %19 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %17, <8 x i16> %18) #6
  %20 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %19) #6
  %21 = icmp sgt <8 x i16> %19, %20
  %22 = select <8 x i1> %21, <8 x i16> %19, <8 x i16> %20
  %23 = sext i32 %1 to i64
  %24 = getelementptr inbounds i8, i8* %0, i64 %23
  %25 = bitcast i8* %24 to i64*
  %26 = load i64, i64* %25, align 1
  %27 = insertelement <2 x i64> undef, i64 %26, i32 0
  %28 = bitcast <2 x i64> %27 to <16 x i8>
  %29 = shufflevector <16 x i8> %28, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %30 = sext i32 %3 to i64
  %31 = getelementptr inbounds i8, i8* %2, i64 %30
  %32 = bitcast i8* %31 to i64*
  %33 = load i64, i64* %32, align 1
  %34 = insertelement <2 x i64> undef, i64 %33, i32 0
  %35 = bitcast <2 x i64> %34 to <16 x i8>
  %36 = shufflevector <16 x i8> %35, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %37 = bitcast <16 x i8> %29 to <8 x i16>
  %38 = bitcast <16 x i8> %36 to <8 x i16>
  %39 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %37, <8 x i16> %38) #6
  %40 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %39) #6
  %41 = icmp sgt <8 x i16> %39, %40
  %42 = select <8 x i1> %41, <8 x i16> %39, <8 x i16> %40
  %43 = icmp sgt <8 x i16> %22, %42
  %44 = select <8 x i1> %43, <8 x i16> %22, <8 x i16> %42
  %45 = icmp slt <8 x i16> %22, %42
  %46 = select <8 x i1> %45, <8 x i16> %22, <8 x i16> %42
  %47 = shl nsw i32 %1, 1
  %48 = sext i32 %47 to i64
  %49 = getelementptr inbounds i8, i8* %0, i64 %48
  %50 = bitcast i8* %49 to i64*
  %51 = load i64, i64* %50, align 1
  %52 = insertelement <2 x i64> undef, i64 %51, i32 0
  %53 = bitcast <2 x i64> %52 to <16 x i8>
  %54 = shufflevector <16 x i8> %53, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %55 = shl nsw i32 %3, 1
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds i8, i8* %2, i64 %56
  %58 = bitcast i8* %57 to i64*
  %59 = load i64, i64* %58, align 1
  %60 = insertelement <2 x i64> undef, i64 %59, i32 0
  %61 = bitcast <2 x i64> %60 to <16 x i8>
  %62 = shufflevector <16 x i8> %61, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %63 = bitcast <16 x i8> %54 to <8 x i16>
  %64 = bitcast <16 x i8> %62 to <8 x i16>
  %65 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %63, <8 x i16> %64) #6
  %66 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %65) #6
  %67 = icmp sgt <8 x i16> %65, %66
  %68 = select <8 x i1> %67, <8 x i16> %65, <8 x i16> %66
  %69 = icmp sgt <8 x i16> %44, %68
  %70 = select <8 x i1> %69, <8 x i16> %44, <8 x i16> %68
  %71 = icmp slt <8 x i16> %46, %68
  %72 = select <8 x i1> %71, <8 x i16> %46, <8 x i16> %68
  %73 = mul nsw i32 %1, 3
  %74 = sext i32 %73 to i64
  %75 = getelementptr inbounds i8, i8* %0, i64 %74
  %76 = bitcast i8* %75 to i64*
  %77 = load i64, i64* %76, align 1
  %78 = insertelement <2 x i64> undef, i64 %77, i32 0
  %79 = bitcast <2 x i64> %78 to <16 x i8>
  %80 = shufflevector <16 x i8> %79, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %81 = mul nsw i32 %3, 3
  %82 = sext i32 %81 to i64
  %83 = getelementptr inbounds i8, i8* %2, i64 %82
  %84 = bitcast i8* %83 to i64*
  %85 = load i64, i64* %84, align 1
  %86 = insertelement <2 x i64> undef, i64 %85, i32 0
  %87 = bitcast <2 x i64> %86 to <16 x i8>
  %88 = shufflevector <16 x i8> %87, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %89 = bitcast <16 x i8> %80 to <8 x i16>
  %90 = bitcast <16 x i8> %88 to <8 x i16>
  %91 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %89, <8 x i16> %90) #6
  %92 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %91) #6
  %93 = icmp sgt <8 x i16> %91, %92
  %94 = select <8 x i1> %93, <8 x i16> %91, <8 x i16> %92
  %95 = icmp sgt <8 x i16> %70, %94
  %96 = select <8 x i1> %95, <8 x i16> %70, <8 x i16> %94
  %97 = icmp slt <8 x i16> %72, %94
  %98 = select <8 x i1> %97, <8 x i16> %72, <8 x i16> %94
  %99 = shl nsw i32 %1, 2
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds i8, i8* %0, i64 %100
  %102 = bitcast i8* %101 to i64*
  %103 = load i64, i64* %102, align 1
  %104 = insertelement <2 x i64> undef, i64 %103, i32 0
  %105 = bitcast <2 x i64> %104 to <16 x i8>
  %106 = shufflevector <16 x i8> %105, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %107 = shl nsw i32 %3, 2
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds i8, i8* %2, i64 %108
  %110 = bitcast i8* %109 to i64*
  %111 = load i64, i64* %110, align 1
  %112 = insertelement <2 x i64> undef, i64 %111, i32 0
  %113 = bitcast <2 x i64> %112 to <16 x i8>
  %114 = shufflevector <16 x i8> %113, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %115 = bitcast <16 x i8> %106 to <8 x i16>
  %116 = bitcast <16 x i8> %114 to <8 x i16>
  %117 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %115, <8 x i16> %116) #6
  %118 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %117) #6
  %119 = icmp sgt <8 x i16> %117, %118
  %120 = select <8 x i1> %119, <8 x i16> %117, <8 x i16> %118
  %121 = icmp sgt <8 x i16> %96, %120
  %122 = select <8 x i1> %121, <8 x i16> %96, <8 x i16> %120
  %123 = icmp slt <8 x i16> %98, %120
  %124 = select <8 x i1> %123, <8 x i16> %98, <8 x i16> %120
  %125 = mul nsw i32 %1, 5
  %126 = sext i32 %125 to i64
  %127 = getelementptr inbounds i8, i8* %0, i64 %126
  %128 = bitcast i8* %127 to i64*
  %129 = load i64, i64* %128, align 1
  %130 = insertelement <2 x i64> undef, i64 %129, i32 0
  %131 = bitcast <2 x i64> %130 to <16 x i8>
  %132 = shufflevector <16 x i8> %131, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %133 = mul nsw i32 %3, 5
  %134 = sext i32 %133 to i64
  %135 = getelementptr inbounds i8, i8* %2, i64 %134
  %136 = bitcast i8* %135 to i64*
  %137 = load i64, i64* %136, align 1
  %138 = insertelement <2 x i64> undef, i64 %137, i32 0
  %139 = bitcast <2 x i64> %138 to <16 x i8>
  %140 = shufflevector <16 x i8> %139, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %141 = bitcast <16 x i8> %132 to <8 x i16>
  %142 = bitcast <16 x i8> %140 to <8 x i16>
  %143 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %141, <8 x i16> %142) #6
  %144 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %143) #6
  %145 = icmp sgt <8 x i16> %143, %144
  %146 = select <8 x i1> %145, <8 x i16> %143, <8 x i16> %144
  %147 = icmp sgt <8 x i16> %122, %146
  %148 = select <8 x i1> %147, <8 x i16> %122, <8 x i16> %146
  %149 = icmp slt <8 x i16> %124, %146
  %150 = select <8 x i1> %149, <8 x i16> %124, <8 x i16> %146
  %151 = mul nsw i32 %1, 6
  %152 = sext i32 %151 to i64
  %153 = getelementptr inbounds i8, i8* %0, i64 %152
  %154 = bitcast i8* %153 to i64*
  %155 = load i64, i64* %154, align 1
  %156 = insertelement <2 x i64> undef, i64 %155, i32 0
  %157 = bitcast <2 x i64> %156 to <16 x i8>
  %158 = shufflevector <16 x i8> %157, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %159 = mul nsw i32 %3, 6
  %160 = sext i32 %159 to i64
  %161 = getelementptr inbounds i8, i8* %2, i64 %160
  %162 = bitcast i8* %161 to i64*
  %163 = load i64, i64* %162, align 1
  %164 = insertelement <2 x i64> undef, i64 %163, i32 0
  %165 = bitcast <2 x i64> %164 to <16 x i8>
  %166 = shufflevector <16 x i8> %165, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %167 = bitcast <16 x i8> %158 to <8 x i16>
  %168 = bitcast <16 x i8> %166 to <8 x i16>
  %169 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %167, <8 x i16> %168) #6
  %170 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %169) #6
  %171 = icmp sgt <8 x i16> %169, %170
  %172 = select <8 x i1> %171, <8 x i16> %169, <8 x i16> %170
  %173 = icmp sgt <8 x i16> %148, %172
  %174 = select <8 x i1> %173, <8 x i16> %148, <8 x i16> %172
  %175 = icmp slt <8 x i16> %150, %172
  %176 = select <8 x i1> %175, <8 x i16> %150, <8 x i16> %172
  %177 = mul nsw i32 %1, 7
  %178 = sext i32 %177 to i64
  %179 = getelementptr inbounds i8, i8* %0, i64 %178
  %180 = bitcast i8* %179 to i64*
  %181 = load i64, i64* %180, align 1
  %182 = insertelement <2 x i64> undef, i64 %181, i32 0
  %183 = bitcast <2 x i64> %182 to <16 x i8>
  %184 = shufflevector <16 x i8> %183, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %185 = mul nsw i32 %3, 7
  %186 = sext i32 %185 to i64
  %187 = getelementptr inbounds i8, i8* %2, i64 %186
  %188 = bitcast i8* %187 to i64*
  %189 = load i64, i64* %188, align 1
  %190 = insertelement <2 x i64> undef, i64 %189, i32 0
  %191 = bitcast <2 x i64> %190 to <16 x i8>
  %192 = shufflevector <16 x i8> %191, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %193 = bitcast <16 x i8> %184 to <8 x i16>
  %194 = bitcast <16 x i8> %192 to <8 x i16>
  %195 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %193, <8 x i16> %194) #6
  %196 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %195) #6
  %197 = icmp sgt <8 x i16> %195, %196
  %198 = select <8 x i1> %197, <8 x i16> %195, <8 x i16> %196
  %199 = icmp sgt <8 x i16> %174, %198
  %200 = select <8 x i1> %199, <8 x i16> %174, <8 x i16> %198
  %201 = icmp slt <8 x i16> %176, %198
  %202 = select <8 x i1> %201, <8 x i16> %176, <8 x i16> %198
  %203 = bitcast <8 x i16> %200 to <16 x i8>
  %204 = shufflevector <16 x i8> %203, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %205 = bitcast <16 x i8> %204 to <8 x i16>
  %206 = icmp sgt <8 x i16> %200, %205
  %207 = select <8 x i1> %206, <8 x i16> %200, <8 x i16> %205
  %208 = bitcast <8 x i16> %207 to <2 x i64>
  %209 = lshr <2 x i64> %208, <i64 32, i64 32>
  %210 = bitcast <2 x i64> %209 to <8 x i16>
  %211 = icmp sgt <8 x i16> %207, %210
  %212 = select <8 x i1> %211, <8 x i16> %207, <8 x i16> %210
  %213 = bitcast <8 x i16> %212 to <2 x i64>
  %214 = lshr <2 x i64> %213, <i64 16, i64 16>
  %215 = bitcast <2 x i64> %214 to <8 x i16>
  %216 = icmp sgt <8 x i16> %212, %215
  %217 = select <8 x i1> %216, <8 x i16> %212, <8 x i16> %215
  %218 = extractelement <8 x i16> %217, i64 0
  %219 = zext i16 %218 to i32
  store i32 %219, i32* %5, align 4
  %220 = bitcast <8 x i16> %202 to <16 x i8>
  %221 = shufflevector <16 x i8> %220, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %222 = bitcast <16 x i8> %221 to <8 x i16>
  %223 = icmp slt <8 x i16> %202, %222
  %224 = select <8 x i1> %223, <8 x i16> %202, <8 x i16> %222
  %225 = bitcast <8 x i16> %224 to <2 x i64>
  %226 = lshr <2 x i64> %225, <i64 32, i64 32>
  %227 = bitcast <2 x i64> %226 to <8 x i16>
  %228 = icmp slt <8 x i16> %224, %227
  %229 = select <8 x i1> %228, <8 x i16> %224, <8 x i16> %227
  %230 = bitcast <8 x i16> %229 to <2 x i64>
  %231 = lshr <2 x i64> %230, <i64 16, i64 16>
  %232 = bitcast <2 x i64> %231 to <8 x i16>
  %233 = icmp slt <8 x i16> %229, %232
  %234 = select <8 x i1> %233, <8 x i16> %229, <8 x i16> %232
  %235 = extractelement <8 x i16> %234, i64 0
  %236 = zext i16 %235 to i32
  store i32 %236, i32* %4, align 4
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind readonly ssp uwtable
define hidden i32 @vpx_avg_8x8_sse2(i8* nocapture readonly, i32) local_unnamed_addr #2 {
  %3 = bitcast i8* %0 to i64*
  %4 = load i64, i64* %3, align 1
  %5 = insertelement <2 x i64> undef, i64 %4, i32 0
  %6 = bitcast <2 x i64> %5 to <16 x i8>
  %7 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8 = sext i32 %1 to i64
  %9 = getelementptr inbounds i8, i8* %0, i64 %8
  %10 = bitcast i8* %9 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> undef, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %15 = bitcast <16 x i8> %7 to <8 x i16>
  %16 = bitcast <16 x i8> %14 to <8 x i16>
  %17 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %15, <8 x i16> %16) #6
  %18 = shl nsw i32 %1, 1
  %19 = sext i32 %18 to i64
  %20 = getelementptr inbounds i8, i8* %0, i64 %19
  %21 = bitcast i8* %20 to i64*
  %22 = load i64, i64* %21, align 1
  %23 = insertelement <2 x i64> undef, i64 %22, i32 0
  %24 = bitcast <2 x i64> %23 to <16 x i8>
  %25 = shufflevector <16 x i8> %24, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %26 = bitcast <16 x i8> %25 to <8 x i16>
  %27 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %17, <8 x i16> %26) #6
  %28 = mul nsw i32 %1, 3
  %29 = sext i32 %28 to i64
  %30 = getelementptr inbounds i8, i8* %0, i64 %29
  %31 = bitcast i8* %30 to i64*
  %32 = load i64, i64* %31, align 1
  %33 = insertelement <2 x i64> undef, i64 %32, i32 0
  %34 = bitcast <2 x i64> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %36 = bitcast <16 x i8> %35 to <8 x i16>
  %37 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %27, <8 x i16> %36) #6
  %38 = shl nsw i32 %1, 2
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds i8, i8* %0, i64 %39
  %41 = bitcast i8* %40 to i64*
  %42 = load i64, i64* %41, align 1
  %43 = insertelement <2 x i64> undef, i64 %42, i32 0
  %44 = bitcast <2 x i64> %43 to <16 x i8>
  %45 = shufflevector <16 x i8> %44, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %46 = bitcast <16 x i8> %45 to <8 x i16>
  %47 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %37, <8 x i16> %46) #6
  %48 = mul nsw i32 %1, 5
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds i8, i8* %0, i64 %49
  %51 = bitcast i8* %50 to i64*
  %52 = load i64, i64* %51, align 1
  %53 = insertelement <2 x i64> undef, i64 %52, i32 0
  %54 = bitcast <2 x i64> %53 to <16 x i8>
  %55 = shufflevector <16 x i8> %54, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %56 = bitcast <16 x i8> %55 to <8 x i16>
  %57 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %47, <8 x i16> %56) #6
  %58 = mul nsw i32 %1, 6
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds i8, i8* %0, i64 %59
  %61 = bitcast i8* %60 to i64*
  %62 = load i64, i64* %61, align 1
  %63 = insertelement <2 x i64> undef, i64 %62, i32 0
  %64 = bitcast <2 x i64> %63 to <16 x i8>
  %65 = shufflevector <16 x i8> %64, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %66 = bitcast <16 x i8> %65 to <8 x i16>
  %67 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %57, <8 x i16> %66) #6
  %68 = mul nsw i32 %1, 7
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds i8, i8* %0, i64 %69
  %71 = bitcast i8* %70 to i64*
  %72 = load i64, i64* %71, align 1
  %73 = insertelement <2 x i64> undef, i64 %72, i32 0
  %74 = bitcast <2 x i64> %73 to <16 x i8>
  %75 = shufflevector <16 x i8> %74, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %76 = bitcast <16 x i8> %75 to <8 x i16>
  %77 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %67, <8 x i16> %76) #6
  %78 = bitcast <8 x i16> %77 to <16 x i8>
  %79 = shufflevector <16 x i8> %78, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %80 = bitcast <16 x i8> %79 to <8 x i16>
  %81 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %77, <8 x i16> %80) #6
  %82 = bitcast <8 x i16> %81 to <2 x i64>
  %83 = lshr <2 x i64> %82, <i64 32, i64 32>
  %84 = bitcast <2 x i64> %83 to <8 x i16>
  %85 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %81, <8 x i16> %84) #6
  %86 = bitcast <8 x i16> %85 to <2 x i64>
  %87 = lshr <2 x i64> %86, <i64 16, i64 16>
  %88 = bitcast <2 x i64> %87 to <8 x i16>
  %89 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %85, <8 x i16> %88) #6
  %90 = extractelement <8 x i16> %89, i64 0
  %91 = zext i16 %90 to i32
  %92 = add nuw nsw i32 %91, 32
  %93 = lshr i32 %92, 6
  ret i32 %93
}

; Function Attrs: nounwind readonly ssp uwtable
define hidden i32 @vpx_avg_4x4_sse2(i8* nocapture readonly, i32) local_unnamed_addr #2 {
  %3 = bitcast i8* %0 to i64*
  %4 = load i64, i64* %3, align 1
  %5 = insertelement <2 x i64> undef, i64 %4, i32 0
  %6 = bitcast <2 x i64> %5 to <16 x i8>
  %7 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8 = sext i32 %1 to i64
  %9 = getelementptr inbounds i8, i8* %0, i64 %8
  %10 = bitcast i8* %9 to i64*
  %11 = load i64, i64* %10, align 1
  %12 = insertelement <2 x i64> undef, i64 %11, i32 0
  %13 = bitcast <2 x i64> %12 to <16 x i8>
  %14 = shufflevector <16 x i8> %13, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %15 = bitcast <16 x i8> %7 to <8 x i16>
  %16 = bitcast <16 x i8> %14 to <8 x i16>
  %17 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %15, <8 x i16> %16) #6
  %18 = shl nsw i32 %1, 1
  %19 = sext i32 %18 to i64
  %20 = getelementptr inbounds i8, i8* %0, i64 %19
  %21 = bitcast i8* %20 to i64*
  %22 = load i64, i64* %21, align 1
  %23 = insertelement <2 x i64> undef, i64 %22, i32 0
  %24 = bitcast <2 x i64> %23 to <16 x i8>
  %25 = shufflevector <16 x i8> %24, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %26 = bitcast <16 x i8> %25 to <8 x i16>
  %27 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %17, <8 x i16> %26) #6
  %28 = mul nsw i32 %1, 3
  %29 = sext i32 %28 to i64
  %30 = getelementptr inbounds i8, i8* %0, i64 %29
  %31 = bitcast i8* %30 to i64*
  %32 = load i64, i64* %31, align 1
  %33 = insertelement <2 x i64> undef, i64 %32, i32 0
  %34 = bitcast <2 x i64> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %36 = bitcast <16 x i8> %35 to <8 x i16>
  %37 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %27, <8 x i16> %36) #6
  %38 = bitcast <8 x i16> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %40 = bitcast <16 x i8> %39 to <8 x i16>
  %41 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %37, <8 x i16> %40) #6
  %42 = bitcast <8 x i16> %41 to <2 x i64>
  %43 = lshr <2 x i64> %42, <i64 16, i64 16>
  %44 = bitcast <2 x i64> %43 to <8 x i16>
  %45 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %41, <8 x i16> %44) #6
  %46 = extractelement <8 x i16> %45, i64 0
  %47 = zext i16 %46 to i32
  %48 = add nuw nsw i32 %47, 8
  %49 = lshr i32 %48, 4
  ret i32 %49
}

; Function Attrs: nounwind readonly ssp uwtable
define hidden i32 @vpx_highbd_avg_8x8_sse2(i8*, i32) local_unnamed_addr #2 {
  %3 = ptrtoint i8* %0 to i64
  %4 = shl i64 %3, 1
  %5 = inttoptr i64 %4 to i16*
  %6 = inttoptr i64 %4 to <8 x i16>*
  %7 = load <8 x i16>, <8 x i16>* %6, align 2
  %8 = sext i32 %1 to i64
  %9 = getelementptr inbounds i16, i16* %5, i64 %8
  %10 = bitcast i16* %9 to <8 x i16>*
  %11 = load <8 x i16>, <8 x i16>* %10, align 2
  %12 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %7, <8 x i16> %11) #6
  %13 = shl nsw i32 %1, 1
  %14 = sext i32 %13 to i64
  %15 = getelementptr inbounds i16, i16* %5, i64 %14
  %16 = bitcast i16* %15 to <8 x i16>*
  %17 = load <8 x i16>, <8 x i16>* %16, align 2
  %18 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %12, <8 x i16> %17) #6
  %19 = mul nsw i32 %1, 3
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds i16, i16* %5, i64 %20
  %22 = bitcast i16* %21 to <8 x i16>*
  %23 = load <8 x i16>, <8 x i16>* %22, align 2
  %24 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %18, <8 x i16> %23) #6
  %25 = shl nsw i32 %1, 2
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds i16, i16* %5, i64 %26
  %28 = bitcast i16* %27 to <8 x i16>*
  %29 = load <8 x i16>, <8 x i16>* %28, align 2
  %30 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %24, <8 x i16> %29) #6
  %31 = mul nsw i32 %1, 5
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds i16, i16* %5, i64 %32
  %34 = bitcast i16* %33 to <8 x i16>*
  %35 = load <8 x i16>, <8 x i16>* %34, align 2
  %36 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %30, <8 x i16> %35) #6
  %37 = mul nsw i32 %1, 6
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds i16, i16* %5, i64 %38
  %40 = bitcast i16* %39 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 2
  %42 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %36, <8 x i16> %41) #6
  %43 = mul nsw i32 %1, 7
  %44 = sext i32 %43 to i64
  %45 = getelementptr inbounds i16, i16* %5, i64 %44
  %46 = bitcast i16* %45 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 2
  %48 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %42, <8 x i16> %47) #6
  %49 = shufflevector <8 x i16> %48, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %50 = shufflevector <8 x i16> %48, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %51 = bitcast <8 x i16> %50 to <4 x i32>
  %52 = bitcast <8 x i16> %49 to <4 x i32>
  %53 = add <4 x i32> %52, %51
  %54 = bitcast <4 x i32> %53 to <16 x i8>
  %55 = shufflevector <16 x i8> %54, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %56 = bitcast <16 x i8> %55 to <4 x i32>
  %57 = add <4 x i32> %53, %56
  %58 = bitcast <4 x i32> %57 to <16 x i8>
  %59 = shufflevector <16 x i8> %58, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %60 = bitcast <16 x i8> %59 to <4 x i32>
  %61 = add <4 x i32> %57, %60
  %62 = extractelement <4 x i32> %61, i32 0
  %63 = add i32 %62, 32
  %64 = lshr i32 %63, 6
  ret i32 %64
}

; Function Attrs: nounwind readonly ssp uwtable
define hidden i32 @vpx_highbd_avg_4x4_sse2(i8*, i32) local_unnamed_addr #2 {
  %3 = ptrtoint i8* %0 to i64
  %4 = shl i64 %3, 1
  %5 = inttoptr i64 %4 to i16*
  %6 = inttoptr i64 %4 to <2 x i64>*
  %7 = getelementptr inbounds <2 x i64>, <2 x i64>* %6, i64 0, i64 0
  %8 = load i64, i64* %7, align 2
  %9 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %8, i32 0
  %10 = sext i32 %1 to i64
  %11 = getelementptr inbounds i16, i16* %5, i64 %10
  %12 = bitcast i16* %11 to i64*
  %13 = load i64, i64* %12, align 2
  %14 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %13, i32 0
  %15 = bitcast <2 x i64> %9 to <8 x i16>
  %16 = bitcast <2 x i64> %14 to <8 x i16>
  %17 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %15, <8 x i16> %16) #6
  %18 = shl nsw i32 %1, 1
  %19 = sext i32 %18 to i64
  %20 = getelementptr inbounds i16, i16* %5, i64 %19
  %21 = bitcast i16* %20 to i64*
  %22 = load i64, i64* %21, align 2
  %23 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %22, i32 0
  %24 = bitcast <2 x i64> %23 to <8 x i16>
  %25 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %17, <8 x i16> %24) #6
  %26 = mul nsw i32 %1, 3
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i16, i16* %5, i64 %27
  %29 = bitcast i16* %28 to i64*
  %30 = load i64, i64* %29, align 2
  %31 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %30, i32 0
  %32 = bitcast <2 x i64> %31 to <8 x i16>
  %33 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %25, <8 x i16> %32) #6
  %34 = bitcast <8 x i16> %33 to <16 x i8>
  %35 = shufflevector <16 x i8> %34, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %36 = bitcast <16 x i8> %35 to <8 x i16>
  %37 = add <8 x i16> %33, %36
  %38 = bitcast <8 x i16> %37 to <16 x i8>
  %39 = shufflevector <16 x i8> %38, <16 x i8> undef, <16 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %40 = bitcast <16 x i8> %39 to <8 x i16>
  %41 = add <8 x i16> %37, %40
  %42 = extractelement <8 x i16> %41, i64 0
  %43 = zext i16 %42 to i32
  %44 = add nuw nsw i32 %43, 8
  %45 = lshr i32 %44, 4
  ret i32 %45
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @vpx_hadamard_8x8_sse2(i16* nocapture readonly, i64, i32* nocapture) local_unnamed_addr #0 {
  %4 = bitcast i16* %0 to <8 x i16>*
  %5 = load <8 x i16>, <8 x i16>* %4, align 16
  %6 = getelementptr inbounds i16, i16* %0, i64 %1
  %7 = bitcast i16* %6 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = getelementptr inbounds i16, i16* %6, i64 %1
  %10 = bitcast i16* %9 to <8 x i16>*
  %11 = load <8 x i16>, <8 x i16>* %10, align 16
  %12 = getelementptr inbounds i16, i16* %9, i64 %1
  %13 = bitcast i16* %12 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = getelementptr inbounds i16, i16* %12, i64 %1
  %16 = bitcast i16* %15 to <8 x i16>*
  %17 = load <8 x i16>, <8 x i16>* %16, align 16
  %18 = getelementptr inbounds i16, i16* %15, i64 %1
  %19 = bitcast i16* %18 to <8 x i16>*
  %20 = load <8 x i16>, <8 x i16>* %19, align 16
  %21 = getelementptr inbounds i16, i16* %18, i64 %1
  %22 = bitcast i16* %21 to <8 x i16>*
  %23 = load <8 x i16>, <8 x i16>* %22, align 16
  %24 = getelementptr inbounds i16, i16* %21, i64 %1
  %25 = bitcast i16* %24 to <8 x i16>*
  %26 = load <8 x i16>, <8 x i16>* %25, align 16
  %27 = add <8 x i16> %8, %5
  %28 = sub <8 x i16> %5, %8
  %29 = add <8 x i16> %14, %11
  %30 = sub <8 x i16> %11, %14
  %31 = add <8 x i16> %20, %17
  %32 = sub <8 x i16> %17, %20
  %33 = add <8 x i16> %26, %23
  %34 = sub <8 x i16> %23, %26
  %35 = add <8 x i16> %29, %27
  %36 = add <8 x i16> %30, %28
  %37 = sub <8 x i16> %27, %29
  %38 = sub <8 x i16> %28, %30
  %39 = add <8 x i16> %33, %31
  %40 = add <8 x i16> %34, %32
  %41 = sub <8 x i16> %31, %33
  %42 = sub <8 x i16> %32, %34
  %43 = add <8 x i16> %39, %35
  %44 = add <8 x i16> %40, %36
  %45 = add <8 x i16> %41, %37
  %46 = add <8 x i16> %42, %38
  %47 = sub <8 x i16> %35, %39
  %48 = sub <8 x i16> %36, %40
  %49 = sub <8 x i16> %37, %41
  %50 = sub <8 x i16> %38, %42
  %51 = shufflevector <8 x i16> %43, <8 x i16> %49, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %52 = shufflevector <8 x i16> %47, <8 x i16> %45, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %53 = shufflevector <8 x i16> %43, <8 x i16> %49, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %54 = shufflevector <8 x i16> %47, <8 x i16> %45, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %46, <8 x i16> %50, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %56 = shufflevector <8 x i16> %48, <8 x i16> %44, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %57 = shufflevector <8 x i16> %46, <8 x i16> %50, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %58 = shufflevector <8 x i16> %48, <8 x i16> %44, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %59 = bitcast <8 x i16> %51 to <4 x i32>
  %60 = bitcast <8 x i16> %52 to <4 x i32>
  %61 = shufflevector <4 x i32> %59, <4 x i32> %60, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %62 = bitcast <4 x i32> %61 to <2 x i64>
  %63 = bitcast <8 x i16> %55 to <4 x i32>
  %64 = bitcast <8 x i16> %56 to <4 x i32>
  %65 = shufflevector <4 x i32> %63, <4 x i32> %64, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %66 = bitcast <4 x i32> %65 to <2 x i64>
  %67 = shufflevector <4 x i32> %59, <4 x i32> %60, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %68 = bitcast <4 x i32> %67 to <2 x i64>
  %69 = shufflevector <4 x i32> %63, <4 x i32> %64, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %70 = bitcast <4 x i32> %69 to <2 x i64>
  %71 = bitcast <8 x i16> %53 to <4 x i32>
  %72 = bitcast <8 x i16> %54 to <4 x i32>
  %73 = shufflevector <4 x i32> %71, <4 x i32> %72, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %74 = bitcast <4 x i32> %73 to <2 x i64>
  %75 = bitcast <8 x i16> %57 to <4 x i32>
  %76 = bitcast <8 x i16> %58 to <4 x i32>
  %77 = shufflevector <4 x i32> %75, <4 x i32> %76, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %78 = bitcast <4 x i32> %77 to <2 x i64>
  %79 = shufflevector <4 x i32> %71, <4 x i32> %72, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %80 = bitcast <4 x i32> %79 to <2 x i64>
  %81 = shufflevector <4 x i32> %75, <4 x i32> %76, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %82 = bitcast <4 x i32> %81 to <2 x i64>
  %83 = shufflevector <2 x i64> %62, <2 x i64> %66, <2 x i32> <i32 0, i32 2>
  %84 = shufflevector <2 x i64> %62, <2 x i64> %66, <2 x i32> <i32 1, i32 3>
  %85 = shufflevector <2 x i64> %68, <2 x i64> %70, <2 x i32> <i32 0, i32 2>
  %86 = shufflevector <2 x i64> %68, <2 x i64> %70, <2 x i32> <i32 1, i32 3>
  %87 = shufflevector <2 x i64> %74, <2 x i64> %78, <2 x i32> <i32 0, i32 2>
  %88 = shufflevector <2 x i64> %74, <2 x i64> %78, <2 x i32> <i32 1, i32 3>
  %89 = shufflevector <2 x i64> %80, <2 x i64> %82, <2 x i32> <i32 0, i32 2>
  %90 = shufflevector <2 x i64> %80, <2 x i64> %82, <2 x i32> <i32 1, i32 3>
  %91 = bitcast <2 x i64> %83 to <8 x i16>
  %92 = bitcast <2 x i64> %84 to <8 x i16>
  %93 = bitcast <2 x i64> %85 to <8 x i16>
  %94 = bitcast <2 x i64> %86 to <8 x i16>
  %95 = bitcast <2 x i64> %87 to <8 x i16>
  %96 = bitcast <2 x i64> %88 to <8 x i16>
  %97 = bitcast <2 x i64> %89 to <8 x i16>
  %98 = bitcast <2 x i64> %90 to <8 x i16>
  %99 = add <8 x i16> %92, %91
  %100 = sub <8 x i16> %91, %92
  %101 = add <8 x i16> %94, %93
  %102 = sub <8 x i16> %93, %94
  %103 = add <8 x i16> %96, %95
  %104 = sub <8 x i16> %95, %96
  %105 = add <8 x i16> %98, %97
  %106 = sub <8 x i16> %97, %98
  %107 = add <8 x i16> %101, %99
  %108 = add <8 x i16> %102, %100
  %109 = sub <8 x i16> %99, %101
  %110 = sub <8 x i16> %100, %102
  %111 = add <8 x i16> %105, %103
  %112 = add <8 x i16> %106, %104
  %113 = sub <8 x i16> %103, %105
  %114 = sub <8 x i16> %104, %106
  %115 = add <8 x i16> %111, %107
  %116 = add <8 x i16> %112, %108
  %117 = add <8 x i16> %113, %109
  %118 = add <8 x i16> %114, %110
  %119 = sub <8 x i16> %107, %111
  %120 = sub <8 x i16> %108, %112
  %121 = sub <8 x i16> %109, %113
  %122 = sub <8 x i16> %110, %114
  %123 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %115, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %124 = shufflevector <8 x i16> %115, <8 x i16> %123, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %125 = shufflevector <8 x i16> %115, <8 x i16> %123, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %126 = bitcast i32* %2 to <8 x i16>*
  store <8 x i16> %124, <8 x i16>* %126, align 16
  %127 = getelementptr inbounds i32, i32* %2, i64 4
  %128 = bitcast i32* %127 to <8 x i16>*
  store <8 x i16> %125, <8 x i16>* %128, align 16
  %129 = getelementptr inbounds i32, i32* %2, i64 8
  %130 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %121, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %131 = shufflevector <8 x i16> %121, <8 x i16> %130, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %132 = shufflevector <8 x i16> %121, <8 x i16> %130, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %133 = bitcast i32* %129 to <8 x i16>*
  store <8 x i16> %131, <8 x i16>* %133, align 16
  %134 = getelementptr inbounds i32, i32* %2, i64 12
  %135 = bitcast i32* %134 to <8 x i16>*
  store <8 x i16> %132, <8 x i16>* %135, align 16
  %136 = getelementptr inbounds i32, i32* %2, i64 16
  %137 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %119, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %138 = shufflevector <8 x i16> %119, <8 x i16> %137, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %139 = shufflevector <8 x i16> %119, <8 x i16> %137, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %140 = bitcast i32* %136 to <8 x i16>*
  store <8 x i16> %138, <8 x i16>* %140, align 16
  %141 = getelementptr inbounds i32, i32* %2, i64 20
  %142 = bitcast i32* %141 to <8 x i16>*
  store <8 x i16> %139, <8 x i16>* %142, align 16
  %143 = getelementptr inbounds i32, i32* %2, i64 24
  %144 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %117, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %145 = shufflevector <8 x i16> %117, <8 x i16> %144, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %146 = shufflevector <8 x i16> %117, <8 x i16> %144, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %147 = bitcast i32* %143 to <8 x i16>*
  store <8 x i16> %145, <8 x i16>* %147, align 16
  %148 = getelementptr inbounds i32, i32* %2, i64 28
  %149 = bitcast i32* %148 to <8 x i16>*
  store <8 x i16> %146, <8 x i16>* %149, align 16
  %150 = getelementptr inbounds i32, i32* %2, i64 32
  %151 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %118, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %152 = shufflevector <8 x i16> %118, <8 x i16> %151, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %153 = shufflevector <8 x i16> %118, <8 x i16> %151, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = bitcast i32* %150 to <8 x i16>*
  store <8 x i16> %152, <8 x i16>* %154, align 16
  %155 = getelementptr inbounds i32, i32* %2, i64 36
  %156 = bitcast i32* %155 to <8 x i16>*
  store <8 x i16> %153, <8 x i16>* %156, align 16
  %157 = getelementptr inbounds i32, i32* %2, i64 40
  %158 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %122, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %159 = shufflevector <8 x i16> %122, <8 x i16> %158, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %160 = shufflevector <8 x i16> %122, <8 x i16> %158, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %161 = bitcast i32* %157 to <8 x i16>*
  store <8 x i16> %159, <8 x i16>* %161, align 16
  %162 = getelementptr inbounds i32, i32* %2, i64 44
  %163 = bitcast i32* %162 to <8 x i16>*
  store <8 x i16> %160, <8 x i16>* %163, align 16
  %164 = getelementptr inbounds i32, i32* %2, i64 48
  %165 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %120, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %166 = shufflevector <8 x i16> %120, <8 x i16> %165, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %167 = shufflevector <8 x i16> %120, <8 x i16> %165, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %168 = bitcast i32* %164 to <8 x i16>*
  store <8 x i16> %166, <8 x i16>* %168, align 16
  %169 = getelementptr inbounds i32, i32* %2, i64 52
  %170 = bitcast i32* %169 to <8 x i16>*
  store <8 x i16> %167, <8 x i16>* %170, align 16
  %171 = getelementptr inbounds i32, i32* %2, i64 56
  %172 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %116, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %173 = shufflevector <8 x i16> %116, <8 x i16> %172, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %174 = shufflevector <8 x i16> %116, <8 x i16> %172, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %175 = bitcast i32* %171 to <8 x i16>*
  store <8 x i16> %173, <8 x i16>* %175, align 16
  %176 = getelementptr inbounds i32, i32* %2, i64 60
  %177 = bitcast i32* %176 to <8 x i16>*
  store <8 x i16> %174, <8 x i16>* %177, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_hadamard_16x16_sse2(i16* nocapture readonly, i64, i32* nocapture) local_unnamed_addr #3 {
  %4 = alloca [256 x i16], align 32
  %5 = bitcast [256 x i16]* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %5) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 32 %5, i8 -86, i64 512, i1 false) #6
  br label %6

6:                                                ; preds = %6, %3
  %7 = phi i64 [ 0, %3 ], [ %151, %6 ]
  %8 = shl i64 %7, 2
  %9 = and i64 %8, 4294967288
  %10 = mul nsw i64 %9, %1
  %11 = getelementptr inbounds i16, i16* %0, i64 %10
  %12 = shl i64 %7, 3
  %13 = and i64 %12, 8
  %14 = getelementptr inbounds i16, i16* %11, i64 %13
  %15 = shl nsw i64 %7, 6
  %16 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 %15
  %17 = bitcast i16* %14 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 16
  %19 = getelementptr inbounds i16, i16* %14, i64 %1
  %20 = bitcast i16* %19 to <8 x i16>*
  %21 = load <8 x i16>, <8 x i16>* %20, align 16
  %22 = getelementptr inbounds i16, i16* %19, i64 %1
  %23 = bitcast i16* %22 to <8 x i16>*
  %24 = load <8 x i16>, <8 x i16>* %23, align 16
  %25 = getelementptr inbounds i16, i16* %22, i64 %1
  %26 = bitcast i16* %25 to <8 x i16>*
  %27 = load <8 x i16>, <8 x i16>* %26, align 16
  %28 = getelementptr inbounds i16, i16* %25, i64 %1
  %29 = bitcast i16* %28 to <8 x i16>*
  %30 = load <8 x i16>, <8 x i16>* %29, align 16
  %31 = getelementptr inbounds i16, i16* %28, i64 %1
  %32 = bitcast i16* %31 to <8 x i16>*
  %33 = load <8 x i16>, <8 x i16>* %32, align 16
  %34 = getelementptr inbounds i16, i16* %31, i64 %1
  %35 = bitcast i16* %34 to <8 x i16>*
  %36 = load <8 x i16>, <8 x i16>* %35, align 16
  %37 = getelementptr inbounds i16, i16* %34, i64 %1
  %38 = bitcast i16* %37 to <8 x i16>*
  %39 = load <8 x i16>, <8 x i16>* %38, align 16
  %40 = add <8 x i16> %21, %18
  %41 = sub <8 x i16> %18, %21
  %42 = add <8 x i16> %27, %24
  %43 = sub <8 x i16> %24, %27
  %44 = add <8 x i16> %33, %30
  %45 = sub <8 x i16> %30, %33
  %46 = add <8 x i16> %39, %36
  %47 = sub <8 x i16> %36, %39
  %48 = add <8 x i16> %42, %40
  %49 = add <8 x i16> %43, %41
  %50 = sub <8 x i16> %40, %42
  %51 = sub <8 x i16> %41, %43
  %52 = add <8 x i16> %46, %44
  %53 = add <8 x i16> %47, %45
  %54 = sub <8 x i16> %44, %46
  %55 = sub <8 x i16> %45, %47
  %56 = add <8 x i16> %52, %48
  %57 = add <8 x i16> %53, %49
  %58 = add <8 x i16> %54, %50
  %59 = add <8 x i16> %55, %51
  %60 = sub <8 x i16> %48, %52
  %61 = sub <8 x i16> %49, %53
  %62 = sub <8 x i16> %50, %54
  %63 = sub <8 x i16> %51, %55
  %64 = shufflevector <8 x i16> %56, <8 x i16> %62, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %65 = shufflevector <8 x i16> %60, <8 x i16> %58, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %66 = shufflevector <8 x i16> %56, <8 x i16> %62, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %67 = shufflevector <8 x i16> %60, <8 x i16> %58, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %68 = shufflevector <8 x i16> %59, <8 x i16> %63, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %69 = shufflevector <8 x i16> %61, <8 x i16> %57, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %70 = shufflevector <8 x i16> %59, <8 x i16> %63, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %71 = shufflevector <8 x i16> %61, <8 x i16> %57, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %72 = bitcast <8 x i16> %64 to <4 x i32>
  %73 = bitcast <8 x i16> %65 to <4 x i32>
  %74 = shufflevector <4 x i32> %72, <4 x i32> %73, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %75 = bitcast <4 x i32> %74 to <2 x i64>
  %76 = bitcast <8 x i16> %68 to <4 x i32>
  %77 = bitcast <8 x i16> %69 to <4 x i32>
  %78 = shufflevector <4 x i32> %76, <4 x i32> %77, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %79 = bitcast <4 x i32> %78 to <2 x i64>
  %80 = shufflevector <4 x i32> %72, <4 x i32> %73, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %81 = bitcast <4 x i32> %80 to <2 x i64>
  %82 = shufflevector <4 x i32> %76, <4 x i32> %77, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %83 = bitcast <4 x i32> %82 to <2 x i64>
  %84 = bitcast <8 x i16> %66 to <4 x i32>
  %85 = bitcast <8 x i16> %67 to <4 x i32>
  %86 = shufflevector <4 x i32> %84, <4 x i32> %85, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %87 = bitcast <4 x i32> %86 to <2 x i64>
  %88 = bitcast <8 x i16> %70 to <4 x i32>
  %89 = bitcast <8 x i16> %71 to <4 x i32>
  %90 = shufflevector <4 x i32> %88, <4 x i32> %89, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %91 = bitcast <4 x i32> %90 to <2 x i64>
  %92 = shufflevector <4 x i32> %84, <4 x i32> %85, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %93 = bitcast <4 x i32> %92 to <2 x i64>
  %94 = shufflevector <4 x i32> %88, <4 x i32> %89, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %95 = bitcast <4 x i32> %94 to <2 x i64>
  %96 = shufflevector <2 x i64> %75, <2 x i64> %79, <2 x i32> <i32 0, i32 2>
  %97 = shufflevector <2 x i64> %75, <2 x i64> %79, <2 x i32> <i32 1, i32 3>
  %98 = shufflevector <2 x i64> %81, <2 x i64> %83, <2 x i32> <i32 0, i32 2>
  %99 = shufflevector <2 x i64> %81, <2 x i64> %83, <2 x i32> <i32 1, i32 3>
  %100 = shufflevector <2 x i64> %87, <2 x i64> %91, <2 x i32> <i32 0, i32 2>
  %101 = shufflevector <2 x i64> %87, <2 x i64> %91, <2 x i32> <i32 1, i32 3>
  %102 = shufflevector <2 x i64> %93, <2 x i64> %95, <2 x i32> <i32 0, i32 2>
  %103 = shufflevector <2 x i64> %93, <2 x i64> %95, <2 x i32> <i32 1, i32 3>
  %104 = bitcast <2 x i64> %96 to <8 x i16>
  %105 = bitcast <2 x i64> %97 to <8 x i16>
  %106 = bitcast <2 x i64> %98 to <8 x i16>
  %107 = bitcast <2 x i64> %99 to <8 x i16>
  %108 = bitcast <2 x i64> %100 to <8 x i16>
  %109 = bitcast <2 x i64> %101 to <8 x i16>
  %110 = bitcast <2 x i64> %102 to <8 x i16>
  %111 = bitcast <2 x i64> %103 to <8 x i16>
  %112 = add <8 x i16> %105, %104
  %113 = sub <8 x i16> %104, %105
  %114 = add <8 x i16> %107, %106
  %115 = sub <8 x i16> %106, %107
  %116 = add <8 x i16> %109, %108
  %117 = sub <8 x i16> %108, %109
  %118 = add <8 x i16> %111, %110
  %119 = sub <8 x i16> %110, %111
  %120 = add <8 x i16> %114, %112
  %121 = add <8 x i16> %115, %113
  %122 = sub <8 x i16> %112, %114
  %123 = sub <8 x i16> %113, %115
  %124 = add <8 x i16> %118, %116
  %125 = add <8 x i16> %119, %117
  %126 = sub <8 x i16> %116, %118
  %127 = sub <8 x i16> %117, %119
  %128 = add <8 x i16> %124, %120
  %129 = add <8 x i16> %125, %121
  %130 = add <8 x i16> %126, %122
  %131 = add <8 x i16> %127, %123
  %132 = sub <8 x i16> %120, %124
  %133 = sub <8 x i16> %121, %125
  %134 = sub <8 x i16> %122, %126
  %135 = sub <8 x i16> %123, %127
  %136 = bitcast i16* %16 to <8 x i16>*
  store <8 x i16> %128, <8 x i16>* %136, align 32
  %137 = getelementptr inbounds i16, i16* %16, i64 8
  %138 = bitcast i16* %137 to <8 x i16>*
  store <8 x i16> %134, <8 x i16>* %138, align 16
  %139 = getelementptr inbounds i16, i16* %16, i64 16
  %140 = bitcast i16* %139 to <8 x i16>*
  store <8 x i16> %132, <8 x i16>* %140, align 32
  %141 = getelementptr inbounds i16, i16* %16, i64 24
  %142 = bitcast i16* %141 to <8 x i16>*
  store <8 x i16> %130, <8 x i16>* %142, align 16
  %143 = getelementptr inbounds i16, i16* %16, i64 32
  %144 = bitcast i16* %143 to <8 x i16>*
  store <8 x i16> %131, <8 x i16>* %144, align 32
  %145 = getelementptr inbounds i16, i16* %16, i64 40
  %146 = bitcast i16* %145 to <8 x i16>*
  store <8 x i16> %135, <8 x i16>* %146, align 16
  %147 = getelementptr inbounds i16, i16* %16, i64 48
  %148 = bitcast i16* %147 to <8 x i16>*
  store <8 x i16> %133, <8 x i16>* %148, align 32
  %149 = getelementptr inbounds i16, i16* %16, i64 56
  %150 = bitcast i16* %149 to <8 x i16>*
  store <8 x i16> %129, <8 x i16>* %150, align 16
  %151 = add nuw nsw i64 %7, 1
  %152 = icmp eq i64 %151, 4
  br i1 %152, label %153, label %6

153:                                              ; preds = %6
  %154 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 0
  br label %155

155:                                              ; preds = %153, %155
  %156 = phi i32* [ %209, %155 ], [ %2, %153 ]
  %157 = phi i16* [ %210, %155 ], [ %154, %153 ]
  %158 = phi i32 [ %211, %155 ], [ 0, %153 ]
  %159 = bitcast i16* %157 to <8 x i16>*
  %160 = load <8 x i16>, <8 x i16>* %159, align 16
  %161 = getelementptr inbounds i16, i16* %157, i64 64
  %162 = bitcast i16* %161 to <8 x i16>*
  %163 = load <8 x i16>, <8 x i16>* %162, align 16
  %164 = getelementptr inbounds i16, i16* %157, i64 128
  %165 = bitcast i16* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds i16, i16* %157, i64 192
  %168 = bitcast i16* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = add <8 x i16> %163, %160
  %171 = sub <8 x i16> %160, %163
  %172 = add <8 x i16> %169, %166
  %173 = sub <8 x i16> %166, %169
  %174 = ashr <8 x i16> %170, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %175 = ashr <8 x i16> %171, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %176 = ashr <8 x i16> %172, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %177 = ashr <8 x i16> %173, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %178 = add nsw <8 x i16> %176, %174
  %179 = add nsw <8 x i16> %177, %175
  %180 = sub nsw <8 x i16> %174, %176
  %181 = sub nsw <8 x i16> %175, %177
  %182 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %178, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %183 = shufflevector <8 x i16> %178, <8 x i16> %182, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %184 = shufflevector <8 x i16> %178, <8 x i16> %182, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %185 = bitcast i32* %156 to <8 x i16>*
  store <8 x i16> %183, <8 x i16>* %185, align 16
  %186 = getelementptr inbounds i32, i32* %156, i64 4
  %187 = bitcast i32* %186 to <8 x i16>*
  store <8 x i16> %184, <8 x i16>* %187, align 16
  %188 = getelementptr inbounds i32, i32* %156, i64 64
  %189 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %179, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %190 = shufflevector <8 x i16> %179, <8 x i16> %189, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %191 = shufflevector <8 x i16> %179, <8 x i16> %189, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %192 = bitcast i32* %188 to <8 x i16>*
  store <8 x i16> %190, <8 x i16>* %192, align 16
  %193 = getelementptr inbounds i32, i32* %156, i64 68
  %194 = bitcast i32* %193 to <8 x i16>*
  store <8 x i16> %191, <8 x i16>* %194, align 16
  %195 = getelementptr inbounds i32, i32* %156, i64 128
  %196 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %180, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %197 = shufflevector <8 x i16> %180, <8 x i16> %196, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %198 = shufflevector <8 x i16> %180, <8 x i16> %196, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %199 = bitcast i32* %195 to <8 x i16>*
  store <8 x i16> %197, <8 x i16>* %199, align 16
  %200 = getelementptr inbounds i32, i32* %156, i64 132
  %201 = bitcast i32* %200 to <8 x i16>*
  store <8 x i16> %198, <8 x i16>* %201, align 16
  %202 = getelementptr inbounds i32, i32* %156, i64 192
  %203 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %181, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %204 = shufflevector <8 x i16> %181, <8 x i16> %203, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %205 = shufflevector <8 x i16> %181, <8 x i16> %203, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %206 = bitcast i32* %202 to <8 x i16>*
  store <8 x i16> %204, <8 x i16>* %206, align 16
  %207 = getelementptr inbounds i32, i32* %156, i64 196
  %208 = bitcast i32* %207 to <8 x i16>*
  store <8 x i16> %205, <8 x i16>* %208, align 16
  %209 = getelementptr inbounds i32, i32* %156, i64 8
  %210 = getelementptr inbounds i16, i16* %157, i64 8
  %211 = add nuw nsw i32 %158, 8
  %212 = icmp ult i32 %211, 64
  br i1 %212, label %155, label %213

213:                                              ; preds = %155
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %5) #6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_hadamard_32x32_sse2(i16* nocapture readonly, i64, i32* nocapture) local_unnamed_addr #3 {
  %4 = alloca [256 x i16], align 32
  %5 = alloca [1024 x i16], align 32
  %6 = bitcast [1024 x i16]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 2048, i8* nonnull %6) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 32 %6, i8 -86, i64 2048, i1 false)
  %7 = bitcast [256 x i16]* %4 to i8*
  %8 = bitcast [256 x i16]* %4 to <8 x i16>*
  %9 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 64
  %10 = bitcast i16* %9 to <8 x i16>*
  %11 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 128
  %12 = bitcast i16* %11 to <8 x i16>*
  %13 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 192
  %14 = bitcast i16* %13 to <8 x i16>*
  %15 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 8
  %16 = bitcast i16* %15 to <8 x i16>*
  %17 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 72
  %18 = bitcast i16* %17 to <8 x i16>*
  %19 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 136
  %20 = bitcast i16* %19 to <8 x i16>*
  %21 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 200
  %22 = bitcast i16* %21 to <8 x i16>*
  %23 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 16
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 80
  %26 = bitcast i16* %25 to <8 x i16>*
  %27 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 144
  %28 = bitcast i16* %27 to <8 x i16>*
  %29 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 208
  %30 = bitcast i16* %29 to <8 x i16>*
  %31 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 24
  %32 = bitcast i16* %31 to <8 x i16>*
  %33 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 88
  %34 = bitcast i16* %33 to <8 x i16>*
  %35 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 152
  %36 = bitcast i16* %35 to <8 x i16>*
  %37 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 216
  %38 = bitcast i16* %37 to <8 x i16>*
  %39 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 32
  %40 = bitcast i16* %39 to <8 x i16>*
  %41 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 96
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 160
  %44 = bitcast i16* %43 to <8 x i16>*
  %45 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 224
  %46 = bitcast i16* %45 to <8 x i16>*
  %47 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 40
  %48 = bitcast i16* %47 to <8 x i16>*
  %49 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 104
  %50 = bitcast i16* %49 to <8 x i16>*
  %51 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 168
  %52 = bitcast i16* %51 to <8 x i16>*
  %53 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 232
  %54 = bitcast i16* %53 to <8 x i16>*
  %55 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 48
  %56 = bitcast i16* %55 to <8 x i16>*
  %57 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 112
  %58 = bitcast i16* %57 to <8 x i16>*
  %59 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 176
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 240
  %62 = bitcast i16* %61 to <8 x i16>*
  %63 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 56
  %64 = bitcast i16* %63 to <8 x i16>*
  %65 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 120
  %66 = bitcast i16* %65 to <8 x i16>*
  %67 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 184
  %68 = bitcast i16* %67 to <8 x i16>*
  %69 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 248
  %70 = bitcast i16* %69 to <8 x i16>*
  br label %71

71:                                               ; preds = %228, %3
  %72 = phi i64 [ 0, %3 ], [ %421, %228 ]
  %73 = shl i64 %72, 3
  %74 = and i64 %73, 4294967280
  %75 = mul nsw i64 %74, %1
  %76 = getelementptr inbounds i16, i16* %0, i64 %75
  %77 = shl i64 %72, 4
  %78 = and i64 %77, 16
  %79 = getelementptr inbounds i16, i16* %76, i64 %78
  %80 = shl nsw i64 %72, 8
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %7) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 32 %7, i8 -86, i64 512, i1 false) #6
  br label %81

81:                                               ; preds = %81, %71
  %82 = phi i64 [ 0, %71 ], [ %226, %81 ]
  %83 = shl i64 %82, 2
  %84 = and i64 %83, 4294967288
  %85 = mul nsw i64 %84, %1
  %86 = getelementptr inbounds i16, i16* %79, i64 %85
  %87 = shl i64 %82, 3
  %88 = and i64 %87, 8
  %89 = getelementptr inbounds i16, i16* %86, i64 %88
  %90 = shl nsw i64 %82, 6
  %91 = getelementptr inbounds [256 x i16], [256 x i16]* %4, i64 0, i64 %90
  %92 = bitcast i16* %89 to <8 x i16>*
  %93 = load <8 x i16>, <8 x i16>* %92, align 16
  %94 = getelementptr inbounds i16, i16* %89, i64 %1
  %95 = bitcast i16* %94 to <8 x i16>*
  %96 = load <8 x i16>, <8 x i16>* %95, align 16
  %97 = getelementptr inbounds i16, i16* %94, i64 %1
  %98 = bitcast i16* %97 to <8 x i16>*
  %99 = load <8 x i16>, <8 x i16>* %98, align 16
  %100 = getelementptr inbounds i16, i16* %97, i64 %1
  %101 = bitcast i16* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = getelementptr inbounds i16, i16* %100, i64 %1
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = getelementptr inbounds i16, i16* %103, i64 %1
  %107 = bitcast i16* %106 to <8 x i16>*
  %108 = load <8 x i16>, <8 x i16>* %107, align 16
  %109 = getelementptr inbounds i16, i16* %106, i64 %1
  %110 = bitcast i16* %109 to <8 x i16>*
  %111 = load <8 x i16>, <8 x i16>* %110, align 16
  %112 = getelementptr inbounds i16, i16* %109, i64 %1
  %113 = bitcast i16* %112 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = add <8 x i16> %96, %93
  %116 = sub <8 x i16> %93, %96
  %117 = add <8 x i16> %102, %99
  %118 = sub <8 x i16> %99, %102
  %119 = add <8 x i16> %108, %105
  %120 = sub <8 x i16> %105, %108
  %121 = add <8 x i16> %114, %111
  %122 = sub <8 x i16> %111, %114
  %123 = add <8 x i16> %117, %115
  %124 = add <8 x i16> %118, %116
  %125 = sub <8 x i16> %115, %117
  %126 = sub <8 x i16> %116, %118
  %127 = add <8 x i16> %121, %119
  %128 = add <8 x i16> %122, %120
  %129 = sub <8 x i16> %119, %121
  %130 = sub <8 x i16> %120, %122
  %131 = add <8 x i16> %127, %123
  %132 = add <8 x i16> %128, %124
  %133 = add <8 x i16> %129, %125
  %134 = add <8 x i16> %130, %126
  %135 = sub <8 x i16> %123, %127
  %136 = sub <8 x i16> %124, %128
  %137 = sub <8 x i16> %125, %129
  %138 = sub <8 x i16> %126, %130
  %139 = shufflevector <8 x i16> %131, <8 x i16> %137, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %140 = shufflevector <8 x i16> %135, <8 x i16> %133, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %141 = shufflevector <8 x i16> %131, <8 x i16> %137, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %142 = shufflevector <8 x i16> %135, <8 x i16> %133, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %143 = shufflevector <8 x i16> %134, <8 x i16> %138, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %144 = shufflevector <8 x i16> %136, <8 x i16> %132, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %145 = shufflevector <8 x i16> %134, <8 x i16> %138, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %146 = shufflevector <8 x i16> %136, <8 x i16> %132, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %147 = bitcast <8 x i16> %139 to <4 x i32>
  %148 = bitcast <8 x i16> %140 to <4 x i32>
  %149 = shufflevector <4 x i32> %147, <4 x i32> %148, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %150 = bitcast <4 x i32> %149 to <2 x i64>
  %151 = bitcast <8 x i16> %143 to <4 x i32>
  %152 = bitcast <8 x i16> %144 to <4 x i32>
  %153 = shufflevector <4 x i32> %151, <4 x i32> %152, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %154 = bitcast <4 x i32> %153 to <2 x i64>
  %155 = shufflevector <4 x i32> %147, <4 x i32> %148, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %156 = bitcast <4 x i32> %155 to <2 x i64>
  %157 = shufflevector <4 x i32> %151, <4 x i32> %152, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %158 = bitcast <4 x i32> %157 to <2 x i64>
  %159 = bitcast <8 x i16> %141 to <4 x i32>
  %160 = bitcast <8 x i16> %142 to <4 x i32>
  %161 = shufflevector <4 x i32> %159, <4 x i32> %160, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %162 = bitcast <4 x i32> %161 to <2 x i64>
  %163 = bitcast <8 x i16> %145 to <4 x i32>
  %164 = bitcast <8 x i16> %146 to <4 x i32>
  %165 = shufflevector <4 x i32> %163, <4 x i32> %164, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %166 = bitcast <4 x i32> %165 to <2 x i64>
  %167 = shufflevector <4 x i32> %159, <4 x i32> %160, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %168 = bitcast <4 x i32> %167 to <2 x i64>
  %169 = shufflevector <4 x i32> %163, <4 x i32> %164, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %170 = bitcast <4 x i32> %169 to <2 x i64>
  %171 = shufflevector <2 x i64> %150, <2 x i64> %154, <2 x i32> <i32 0, i32 2>
  %172 = shufflevector <2 x i64> %150, <2 x i64> %154, <2 x i32> <i32 1, i32 3>
  %173 = shufflevector <2 x i64> %156, <2 x i64> %158, <2 x i32> <i32 0, i32 2>
  %174 = shufflevector <2 x i64> %156, <2 x i64> %158, <2 x i32> <i32 1, i32 3>
  %175 = shufflevector <2 x i64> %162, <2 x i64> %166, <2 x i32> <i32 0, i32 2>
  %176 = shufflevector <2 x i64> %162, <2 x i64> %166, <2 x i32> <i32 1, i32 3>
  %177 = shufflevector <2 x i64> %168, <2 x i64> %170, <2 x i32> <i32 0, i32 2>
  %178 = shufflevector <2 x i64> %168, <2 x i64> %170, <2 x i32> <i32 1, i32 3>
  %179 = bitcast <2 x i64> %171 to <8 x i16>
  %180 = bitcast <2 x i64> %172 to <8 x i16>
  %181 = bitcast <2 x i64> %173 to <8 x i16>
  %182 = bitcast <2 x i64> %174 to <8 x i16>
  %183 = bitcast <2 x i64> %175 to <8 x i16>
  %184 = bitcast <2 x i64> %176 to <8 x i16>
  %185 = bitcast <2 x i64> %177 to <8 x i16>
  %186 = bitcast <2 x i64> %178 to <8 x i16>
  %187 = add <8 x i16> %180, %179
  %188 = sub <8 x i16> %179, %180
  %189 = add <8 x i16> %182, %181
  %190 = sub <8 x i16> %181, %182
  %191 = add <8 x i16> %184, %183
  %192 = sub <8 x i16> %183, %184
  %193 = add <8 x i16> %186, %185
  %194 = sub <8 x i16> %185, %186
  %195 = add <8 x i16> %189, %187
  %196 = add <8 x i16> %190, %188
  %197 = sub <8 x i16> %187, %189
  %198 = sub <8 x i16> %188, %190
  %199 = add <8 x i16> %193, %191
  %200 = add <8 x i16> %194, %192
  %201 = sub <8 x i16> %191, %193
  %202 = sub <8 x i16> %192, %194
  %203 = add <8 x i16> %199, %195
  %204 = add <8 x i16> %200, %196
  %205 = add <8 x i16> %201, %197
  %206 = add <8 x i16> %202, %198
  %207 = sub <8 x i16> %195, %199
  %208 = sub <8 x i16> %196, %200
  %209 = sub <8 x i16> %197, %201
  %210 = sub <8 x i16> %198, %202
  %211 = bitcast i16* %91 to <8 x i16>*
  store <8 x i16> %203, <8 x i16>* %211, align 32
  %212 = getelementptr inbounds i16, i16* %91, i64 8
  %213 = bitcast i16* %212 to <8 x i16>*
  store <8 x i16> %209, <8 x i16>* %213, align 16
  %214 = getelementptr inbounds i16, i16* %91, i64 16
  %215 = bitcast i16* %214 to <8 x i16>*
  store <8 x i16> %207, <8 x i16>* %215, align 32
  %216 = getelementptr inbounds i16, i16* %91, i64 24
  %217 = bitcast i16* %216 to <8 x i16>*
  store <8 x i16> %205, <8 x i16>* %217, align 16
  %218 = getelementptr inbounds i16, i16* %91, i64 32
  %219 = bitcast i16* %218 to <8 x i16>*
  store <8 x i16> %206, <8 x i16>* %219, align 32
  %220 = getelementptr inbounds i16, i16* %91, i64 40
  %221 = bitcast i16* %220 to <8 x i16>*
  store <8 x i16> %210, <8 x i16>* %221, align 16
  %222 = getelementptr inbounds i16, i16* %91, i64 48
  %223 = bitcast i16* %222 to <8 x i16>*
  store <8 x i16> %208, <8 x i16>* %223, align 32
  %224 = getelementptr inbounds i16, i16* %91, i64 56
  %225 = bitcast i16* %224 to <8 x i16>*
  store <8 x i16> %204, <8 x i16>* %225, align 16
  %226 = add nuw nsw i64 %82, 1
  %227 = icmp eq i64 %226, 4
  br i1 %227, label %228, label %81

228:                                              ; preds = %81
  %229 = getelementptr inbounds [1024 x i16], [1024 x i16]* %5, i64 0, i64 %80
  %230 = load <8 x i16>, <8 x i16>* %8, align 32
  %231 = load <8 x i16>, <8 x i16>* %10, align 32
  %232 = load <8 x i16>, <8 x i16>* %12, align 32
  %233 = load <8 x i16>, <8 x i16>* %14, align 32
  %234 = add <8 x i16> %231, %230
  %235 = sub <8 x i16> %230, %231
  %236 = add <8 x i16> %233, %232
  %237 = sub <8 x i16> %232, %233
  %238 = ashr <8 x i16> %234, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %239 = ashr <8 x i16> %235, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %240 = ashr <8 x i16> %236, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %241 = ashr <8 x i16> %237, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %242 = add nsw <8 x i16> %240, %238
  %243 = add nsw <8 x i16> %241, %239
  %244 = sub nsw <8 x i16> %238, %240
  %245 = sub nsw <8 x i16> %239, %241
  %246 = bitcast i16* %229 to <8 x i16>*
  store <8 x i16> %242, <8 x i16>* %246, align 32
  %247 = getelementptr inbounds i16, i16* %229, i64 64
  %248 = bitcast i16* %247 to <8 x i16>*
  store <8 x i16> %243, <8 x i16>* %248, align 32
  %249 = getelementptr inbounds i16, i16* %229, i64 128
  %250 = bitcast i16* %249 to <8 x i16>*
  store <8 x i16> %244, <8 x i16>* %250, align 32
  %251 = getelementptr inbounds i16, i16* %229, i64 192
  %252 = bitcast i16* %251 to <8 x i16>*
  store <8 x i16> %245, <8 x i16>* %252, align 32
  %253 = getelementptr inbounds i16, i16* %229, i64 8
  %254 = load <8 x i16>, <8 x i16>* %16, align 16
  %255 = load <8 x i16>, <8 x i16>* %18, align 16
  %256 = load <8 x i16>, <8 x i16>* %20, align 16
  %257 = load <8 x i16>, <8 x i16>* %22, align 16
  %258 = add <8 x i16> %255, %254
  %259 = sub <8 x i16> %254, %255
  %260 = add <8 x i16> %257, %256
  %261 = sub <8 x i16> %256, %257
  %262 = ashr <8 x i16> %258, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %263 = ashr <8 x i16> %259, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %264 = ashr <8 x i16> %260, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %265 = ashr <8 x i16> %261, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %266 = add nsw <8 x i16> %264, %262
  %267 = add nsw <8 x i16> %265, %263
  %268 = sub nsw <8 x i16> %262, %264
  %269 = sub nsw <8 x i16> %263, %265
  %270 = bitcast i16* %253 to <8 x i16>*
  store <8 x i16> %266, <8 x i16>* %270, align 16
  %271 = getelementptr inbounds i16, i16* %229, i64 72
  %272 = bitcast i16* %271 to <8 x i16>*
  store <8 x i16> %267, <8 x i16>* %272, align 16
  %273 = getelementptr inbounds i16, i16* %229, i64 136
  %274 = bitcast i16* %273 to <8 x i16>*
  store <8 x i16> %268, <8 x i16>* %274, align 16
  %275 = getelementptr inbounds i16, i16* %229, i64 200
  %276 = bitcast i16* %275 to <8 x i16>*
  store <8 x i16> %269, <8 x i16>* %276, align 16
  %277 = getelementptr inbounds i16, i16* %229, i64 16
  %278 = load <8 x i16>, <8 x i16>* %24, align 32
  %279 = load <8 x i16>, <8 x i16>* %26, align 32
  %280 = load <8 x i16>, <8 x i16>* %28, align 32
  %281 = load <8 x i16>, <8 x i16>* %30, align 32
  %282 = add <8 x i16> %279, %278
  %283 = sub <8 x i16> %278, %279
  %284 = add <8 x i16> %281, %280
  %285 = sub <8 x i16> %280, %281
  %286 = ashr <8 x i16> %282, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %287 = ashr <8 x i16> %283, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %288 = ashr <8 x i16> %284, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %289 = ashr <8 x i16> %285, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %290 = add nsw <8 x i16> %288, %286
  %291 = add nsw <8 x i16> %289, %287
  %292 = sub nsw <8 x i16> %286, %288
  %293 = sub nsw <8 x i16> %287, %289
  %294 = bitcast i16* %277 to <8 x i16>*
  store <8 x i16> %290, <8 x i16>* %294, align 32
  %295 = getelementptr inbounds i16, i16* %229, i64 80
  %296 = bitcast i16* %295 to <8 x i16>*
  store <8 x i16> %291, <8 x i16>* %296, align 32
  %297 = getelementptr inbounds i16, i16* %229, i64 144
  %298 = bitcast i16* %297 to <8 x i16>*
  store <8 x i16> %292, <8 x i16>* %298, align 32
  %299 = getelementptr inbounds i16, i16* %229, i64 208
  %300 = bitcast i16* %299 to <8 x i16>*
  store <8 x i16> %293, <8 x i16>* %300, align 32
  %301 = getelementptr inbounds i16, i16* %229, i64 24
  %302 = load <8 x i16>, <8 x i16>* %32, align 16
  %303 = load <8 x i16>, <8 x i16>* %34, align 16
  %304 = load <8 x i16>, <8 x i16>* %36, align 16
  %305 = load <8 x i16>, <8 x i16>* %38, align 16
  %306 = add <8 x i16> %303, %302
  %307 = sub <8 x i16> %302, %303
  %308 = add <8 x i16> %305, %304
  %309 = sub <8 x i16> %304, %305
  %310 = ashr <8 x i16> %306, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %311 = ashr <8 x i16> %307, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %312 = ashr <8 x i16> %308, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %313 = ashr <8 x i16> %309, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %314 = add nsw <8 x i16> %312, %310
  %315 = add nsw <8 x i16> %313, %311
  %316 = sub nsw <8 x i16> %310, %312
  %317 = sub nsw <8 x i16> %311, %313
  %318 = bitcast i16* %301 to <8 x i16>*
  store <8 x i16> %314, <8 x i16>* %318, align 16
  %319 = getelementptr inbounds i16, i16* %229, i64 88
  %320 = bitcast i16* %319 to <8 x i16>*
  store <8 x i16> %315, <8 x i16>* %320, align 16
  %321 = getelementptr inbounds i16, i16* %229, i64 152
  %322 = bitcast i16* %321 to <8 x i16>*
  store <8 x i16> %316, <8 x i16>* %322, align 16
  %323 = getelementptr inbounds i16, i16* %229, i64 216
  %324 = bitcast i16* %323 to <8 x i16>*
  store <8 x i16> %317, <8 x i16>* %324, align 16
  %325 = getelementptr inbounds i16, i16* %229, i64 32
  %326 = load <8 x i16>, <8 x i16>* %40, align 32
  %327 = load <8 x i16>, <8 x i16>* %42, align 32
  %328 = load <8 x i16>, <8 x i16>* %44, align 32
  %329 = load <8 x i16>, <8 x i16>* %46, align 32
  %330 = add <8 x i16> %327, %326
  %331 = sub <8 x i16> %326, %327
  %332 = add <8 x i16> %329, %328
  %333 = sub <8 x i16> %328, %329
  %334 = ashr <8 x i16> %330, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %335 = ashr <8 x i16> %331, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %336 = ashr <8 x i16> %332, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %337 = ashr <8 x i16> %333, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %338 = add nsw <8 x i16> %336, %334
  %339 = add nsw <8 x i16> %337, %335
  %340 = sub nsw <8 x i16> %334, %336
  %341 = sub nsw <8 x i16> %335, %337
  %342 = bitcast i16* %325 to <8 x i16>*
  store <8 x i16> %338, <8 x i16>* %342, align 32
  %343 = getelementptr inbounds i16, i16* %229, i64 96
  %344 = bitcast i16* %343 to <8 x i16>*
  store <8 x i16> %339, <8 x i16>* %344, align 32
  %345 = getelementptr inbounds i16, i16* %229, i64 160
  %346 = bitcast i16* %345 to <8 x i16>*
  store <8 x i16> %340, <8 x i16>* %346, align 32
  %347 = getelementptr inbounds i16, i16* %229, i64 224
  %348 = bitcast i16* %347 to <8 x i16>*
  store <8 x i16> %341, <8 x i16>* %348, align 32
  %349 = getelementptr inbounds i16, i16* %229, i64 40
  %350 = load <8 x i16>, <8 x i16>* %48, align 16
  %351 = load <8 x i16>, <8 x i16>* %50, align 16
  %352 = load <8 x i16>, <8 x i16>* %52, align 16
  %353 = load <8 x i16>, <8 x i16>* %54, align 16
  %354 = add <8 x i16> %351, %350
  %355 = sub <8 x i16> %350, %351
  %356 = add <8 x i16> %353, %352
  %357 = sub <8 x i16> %352, %353
  %358 = ashr <8 x i16> %354, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %359 = ashr <8 x i16> %355, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %360 = ashr <8 x i16> %356, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %361 = ashr <8 x i16> %357, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %362 = add nsw <8 x i16> %360, %358
  %363 = add nsw <8 x i16> %361, %359
  %364 = sub nsw <8 x i16> %358, %360
  %365 = sub nsw <8 x i16> %359, %361
  %366 = bitcast i16* %349 to <8 x i16>*
  store <8 x i16> %362, <8 x i16>* %366, align 16
  %367 = getelementptr inbounds i16, i16* %229, i64 104
  %368 = bitcast i16* %367 to <8 x i16>*
  store <8 x i16> %363, <8 x i16>* %368, align 16
  %369 = getelementptr inbounds i16, i16* %229, i64 168
  %370 = bitcast i16* %369 to <8 x i16>*
  store <8 x i16> %364, <8 x i16>* %370, align 16
  %371 = getelementptr inbounds i16, i16* %229, i64 232
  %372 = bitcast i16* %371 to <8 x i16>*
  store <8 x i16> %365, <8 x i16>* %372, align 16
  %373 = getelementptr inbounds i16, i16* %229, i64 48
  %374 = load <8 x i16>, <8 x i16>* %56, align 32
  %375 = load <8 x i16>, <8 x i16>* %58, align 32
  %376 = load <8 x i16>, <8 x i16>* %60, align 32
  %377 = load <8 x i16>, <8 x i16>* %62, align 32
  %378 = add <8 x i16> %375, %374
  %379 = sub <8 x i16> %374, %375
  %380 = add <8 x i16> %377, %376
  %381 = sub <8 x i16> %376, %377
  %382 = ashr <8 x i16> %378, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %383 = ashr <8 x i16> %379, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %384 = ashr <8 x i16> %380, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %385 = ashr <8 x i16> %381, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %386 = add nsw <8 x i16> %384, %382
  %387 = add nsw <8 x i16> %385, %383
  %388 = sub nsw <8 x i16> %382, %384
  %389 = sub nsw <8 x i16> %383, %385
  %390 = bitcast i16* %373 to <8 x i16>*
  store <8 x i16> %386, <8 x i16>* %390, align 32
  %391 = getelementptr inbounds i16, i16* %229, i64 112
  %392 = bitcast i16* %391 to <8 x i16>*
  store <8 x i16> %387, <8 x i16>* %392, align 32
  %393 = getelementptr inbounds i16, i16* %229, i64 176
  %394 = bitcast i16* %393 to <8 x i16>*
  store <8 x i16> %388, <8 x i16>* %394, align 32
  %395 = getelementptr inbounds i16, i16* %229, i64 240
  %396 = bitcast i16* %395 to <8 x i16>*
  store <8 x i16> %389, <8 x i16>* %396, align 32
  %397 = getelementptr inbounds i16, i16* %229, i64 56
  %398 = load <8 x i16>, <8 x i16>* %64, align 16
  %399 = load <8 x i16>, <8 x i16>* %66, align 16
  %400 = load <8 x i16>, <8 x i16>* %68, align 16
  %401 = load <8 x i16>, <8 x i16>* %70, align 16
  %402 = add <8 x i16> %399, %398
  %403 = sub <8 x i16> %398, %399
  %404 = add <8 x i16> %401, %400
  %405 = sub <8 x i16> %400, %401
  %406 = ashr <8 x i16> %402, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %407 = ashr <8 x i16> %403, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %408 = ashr <8 x i16> %404, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %409 = ashr <8 x i16> %405, <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>
  %410 = add nsw <8 x i16> %408, %406
  %411 = add nsw <8 x i16> %409, %407
  %412 = sub nsw <8 x i16> %406, %408
  %413 = sub nsw <8 x i16> %407, %409
  %414 = bitcast i16* %397 to <8 x i16>*
  store <8 x i16> %410, <8 x i16>* %414, align 16
  %415 = getelementptr inbounds i16, i16* %229, i64 120
  %416 = bitcast i16* %415 to <8 x i16>*
  store <8 x i16> %411, <8 x i16>* %416, align 16
  %417 = getelementptr inbounds i16, i16* %229, i64 184
  %418 = bitcast i16* %417 to <8 x i16>*
  store <8 x i16> %412, <8 x i16>* %418, align 16
  %419 = getelementptr inbounds i16, i16* %229, i64 248
  %420 = bitcast i16* %419 to <8 x i16>*
  store <8 x i16> %413, <8 x i16>* %420, align 16
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %7) #6
  %421 = add nuw nsw i64 %72, 1
  %422 = icmp eq i64 %421, 4
  br i1 %422, label %423, label %71

423:                                              ; preds = %228
  %424 = getelementptr inbounds [1024 x i16], [1024 x i16]* %5, i64 0, i64 0
  br label %425

425:                                              ; preds = %423, %425
  %426 = phi i32* [ %479, %425 ], [ %2, %423 ]
  %427 = phi i16* [ %480, %425 ], [ %424, %423 ]
  %428 = phi i32 [ %481, %425 ], [ 0, %423 ]
  %429 = bitcast i16* %427 to <8 x i16>*
  %430 = load <8 x i16>, <8 x i16>* %429, align 16
  %431 = getelementptr inbounds i16, i16* %427, i64 256
  %432 = bitcast i16* %431 to <8 x i16>*
  %433 = load <8 x i16>, <8 x i16>* %432, align 16
  %434 = getelementptr inbounds i16, i16* %427, i64 512
  %435 = bitcast i16* %434 to <8 x i16>*
  %436 = load <8 x i16>, <8 x i16>* %435, align 16
  %437 = getelementptr inbounds i16, i16* %427, i64 768
  %438 = bitcast i16* %437 to <8 x i16>*
  %439 = load <8 x i16>, <8 x i16>* %438, align 16
  %440 = add <8 x i16> %433, %430
  %441 = sub <8 x i16> %430, %433
  %442 = add <8 x i16> %439, %436
  %443 = sub <8 x i16> %436, %439
  %444 = ashr <8 x i16> %440, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %445 = ashr <8 x i16> %441, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %446 = ashr <8 x i16> %442, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %447 = ashr <8 x i16> %443, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %448 = add nsw <8 x i16> %446, %444
  %449 = add nsw <8 x i16> %447, %445
  %450 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %448, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %451 = shufflevector <8 x i16> %448, <8 x i16> %450, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %452 = shufflevector <8 x i16> %448, <8 x i16> %450, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %453 = bitcast i32* %426 to <8 x i16>*
  store <8 x i16> %451, <8 x i16>* %453, align 16
  %454 = getelementptr inbounds i32, i32* %426, i64 4
  %455 = bitcast i32* %454 to <8 x i16>*
  store <8 x i16> %452, <8 x i16>* %455, align 16
  %456 = getelementptr inbounds i32, i32* %426, i64 256
  %457 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %449, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %458 = shufflevector <8 x i16> %449, <8 x i16> %457, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %459 = shufflevector <8 x i16> %449, <8 x i16> %457, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %460 = bitcast i32* %456 to <8 x i16>*
  store <8 x i16> %458, <8 x i16>* %460, align 16
  %461 = getelementptr inbounds i32, i32* %426, i64 260
  %462 = bitcast i32* %461 to <8 x i16>*
  store <8 x i16> %459, <8 x i16>* %462, align 16
  %463 = sub nsw <8 x i16> %444, %446
  %464 = sub nsw <8 x i16> %445, %447
  %465 = getelementptr inbounds i32, i32* %426, i64 512
  %466 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %463, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %467 = shufflevector <8 x i16> %463, <8 x i16> %466, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %468 = shufflevector <8 x i16> %463, <8 x i16> %466, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %469 = bitcast i32* %465 to <8 x i16>*
  store <8 x i16> %467, <8 x i16>* %469, align 16
  %470 = getelementptr inbounds i32, i32* %426, i64 516
  %471 = bitcast i32* %470 to <8 x i16>*
  store <8 x i16> %468, <8 x i16>* %471, align 16
  %472 = getelementptr inbounds i32, i32* %426, i64 768
  %473 = tail call <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16> %464, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1, i16 1>) #6
  %474 = shufflevector <8 x i16> %464, <8 x i16> %473, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %475 = shufflevector <8 x i16> %464, <8 x i16> %473, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %476 = bitcast i32* %472 to <8 x i16>*
  store <8 x i16> %474, <8 x i16>* %476, align 16
  %477 = getelementptr inbounds i32, i32* %426, i64 772
  %478 = bitcast i32* %477 to <8 x i16>*
  store <8 x i16> %475, <8 x i16>* %478, align 16
  %479 = getelementptr inbounds i32, i32* %426, i64 8
  %480 = getelementptr inbounds i16, i16* %427, i64 8
  %481 = add nuw nsw i32 %428, 8
  %482 = icmp ult i32 %481, 256
  br i1 %482, label %425, label %483

483:                                              ; preds = %425
  call void @llvm.lifetime.end.p0i8(i64 2048, i8* nonnull %6) #6
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: nounwind readonly ssp uwtable
define hidden i32 @vpx_satd_sse2(i32* nocapture readonly, i32) local_unnamed_addr #2 {
  %3 = icmp sgt i32 %1, 0
  br i1 %3, label %4, label %74

4:                                                ; preds = %2
  %5 = add i32 %1, -1
  %6 = lshr i32 %5, 3
  %7 = add nuw nsw i32 %6, 1
  %8 = and i32 %7, 1
  %9 = icmp eq i32 %6, 0
  br i1 %9, label %50, label %10

10:                                               ; preds = %4
  %11 = sub nuw nsw i32 %7, %8
  br label %12

12:                                               ; preds = %12, %10
  %13 = phi i32* [ %0, %10 ], [ %47, %12 ]
  %14 = phi <4 x i32> [ zeroinitializer, %10 ], [ %46, %12 ]
  %15 = phi i32 [ %11, %10 ], [ %48, %12 ]
  %16 = bitcast i32* %13 to <4 x i32>*
  %17 = load <4 x i32>, <4 x i32>* %16, align 16
  %18 = getelementptr inbounds i32, i32* %13, i64 4
  %19 = bitcast i32* %18 to <4 x i32>*
  %20 = load <4 x i32>, <4 x i32>* %19, align 16
  %21 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %17, <4 x i32> %20) #6
  %22 = sub <8 x i16> zeroinitializer, %21
  %23 = icmp sgt <8 x i16> %21, %22
  %24 = select <8 x i1> %23, <8 x i16> %21, <8 x i16> %22
  %25 = shufflevector <8 x i16> %24, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %26 = shufflevector <8 x i16> %24, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = bitcast <8 x i16> %25 to <4 x i32>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = add <4 x i32> %14, %27
  %30 = add <4 x i32> %29, %28
  %31 = getelementptr inbounds i32, i32* %13, i64 8
  %32 = bitcast i32* %31 to <4 x i32>*
  %33 = load <4 x i32>, <4 x i32>* %32, align 16
  %34 = getelementptr inbounds i32, i32* %13, i64 12
  %35 = bitcast i32* %34 to <4 x i32>*
  %36 = load <4 x i32>, <4 x i32>* %35, align 16
  %37 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %33, <4 x i32> %36) #6
  %38 = sub <8 x i16> zeroinitializer, %37
  %39 = icmp sgt <8 x i16> %37, %38
  %40 = select <8 x i1> %39, <8 x i16> %37, <8 x i16> %38
  %41 = shufflevector <8 x i16> %40, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %42 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %43 = bitcast <8 x i16> %41 to <4 x i32>
  %44 = bitcast <8 x i16> %42 to <4 x i32>
  %45 = add <4 x i32> %30, %43
  %46 = add <4 x i32> %45, %44
  %47 = getelementptr inbounds i32, i32* %13, i64 16
  %48 = add i32 %15, -2
  %49 = icmp eq i32 %48, 0
  br i1 %49, label %50, label %12

50:                                               ; preds = %12, %4
  %51 = phi <4 x i32> [ undef, %4 ], [ %46, %12 ]
  %52 = phi i32* [ %0, %4 ], [ %47, %12 ]
  %53 = phi <4 x i32> [ zeroinitializer, %4 ], [ %46, %12 ]
  %54 = icmp eq i32 %8, 0
  br i1 %54, label %71, label %55

55:                                               ; preds = %50
  %56 = bitcast i32* %52 to <4 x i32>*
  %57 = load <4 x i32>, <4 x i32>* %56, align 16
  %58 = getelementptr inbounds i32, i32* %52, i64 4
  %59 = bitcast i32* %58 to <4 x i32>*
  %60 = load <4 x i32>, <4 x i32>* %59, align 16
  %61 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %57, <4 x i32> %60) #6
  %62 = sub <8 x i16> zeroinitializer, %61
  %63 = icmp sgt <8 x i16> %61, %62
  %64 = select <8 x i1> %63, <8 x i16> %61, <8 x i16> %62
  %65 = shufflevector <8 x i16> %64, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %66 = bitcast <8 x i16> %65 to <4 x i32>
  %67 = add <4 x i32> %53, %66
  %68 = shufflevector <8 x i16> %64, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %69 = bitcast <8 x i16> %68 to <4 x i32>
  %70 = add <4 x i32> %67, %69
  br label %71

71:                                               ; preds = %50, %55
  %72 = phi <4 x i32> [ %51, %50 ], [ %70, %55 ]
  %73 = bitcast <4 x i32> %72 to <16 x i8>
  br label %74

74:                                               ; preds = %71, %2
  %75 = phi <4 x i32> [ %72, %71 ], [ zeroinitializer, %2 ]
  %76 = phi <16 x i8> [ %73, %71 ], [ zeroinitializer, %2 ]
  %77 = shufflevector <16 x i8> %76, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %78 = bitcast <16 x i8> %77 to <4 x i32>
  %79 = add <4 x i32> %75, %78
  %80 = bitcast <4 x i32> %79 to <2 x i64>
  %81 = lshr <2 x i64> %80, <i64 32, i64 32>
  %82 = bitcast <2 x i64> %81 to <4 x i32>
  %83 = add <4 x i32> %79, %82
  %84 = extractelement <4 x i32> %83, i32 0
  ret i32 %84
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @vpx_int_pro_row_sse2(i16* nocapture, i8* nocapture readonly, i32, i32) local_unnamed_addr #0 {
  %5 = bitcast i8* %1 to <16 x i8>*
  %6 = load <16 x i8>, <16 x i8>* %5, align 1
  %7 = shufflevector <16 x i8> %6, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %8 = shufflevector <16 x i8> %6, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %9 = add nsw i32 %3, -1
  %10 = sext i32 %2 to i64
  %11 = getelementptr inbounds i8, i8* %1, i64 %10
  %12 = icmp sgt i32 %9, 1
  %13 = bitcast i8* %11 to <16 x i8>*
  %14 = load <16 x i8>, <16 x i8>* %13, align 1
  %15 = shufflevector <16 x i8> %14, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %16 = shufflevector <16 x i8> %14, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %17 = bitcast <16 x i8> %7 to <8 x i16>
  %18 = bitcast <16 x i8> %15 to <8 x i16>
  %19 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %17, <8 x i16> %18) #6
  %20 = bitcast <16 x i8> %8 to <8 x i16>
  %21 = bitcast <16 x i8> %16 to <8 x i16>
  %22 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %20, <8 x i16> %21) #6
  br i1 %12, label %23, label %49

23:                                               ; preds = %4, %23
  %24 = phi <8 x i16> [ %48, %23 ], [ %22, %4 ]
  %25 = phi <8 x i16> [ %46, %23 ], [ %19, %4 ]
  %26 = phi i8* [ %29, %23 ], [ %1, %4 ]
  %27 = phi i32 [ %38, %23 ], [ 1, %4 ]
  %28 = getelementptr inbounds i8, i8* %26, i64 %10
  %29 = getelementptr inbounds i8, i8* %28, i64 %10
  %30 = bitcast i8* %29 to <16 x i8>*
  %31 = load <16 x i8>, <16 x i8>* %30, align 1
  %32 = shufflevector <16 x i8> %31, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %33 = shufflevector <16 x i8> %31, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %34 = bitcast <16 x i8> %32 to <8 x i16>
  %35 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %25, <8 x i16> %34) #6
  %36 = bitcast <16 x i8> %33 to <8 x i16>
  %37 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %24, <8 x i16> %36) #6
  %38 = add nuw nsw i32 %27, 2
  %39 = getelementptr inbounds i8, i8* %29, i64 %10
  %40 = icmp slt i32 %38, %9
  %41 = bitcast i8* %39 to <16 x i8>*
  %42 = load <16 x i8>, <16 x i8>* %41, align 1
  %43 = shufflevector <16 x i8> %42, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %44 = shufflevector <16 x i8> %42, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %45 = bitcast <16 x i8> %43 to <8 x i16>
  %46 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %35, <8 x i16> %45) #6
  %47 = bitcast <16 x i8> %44 to <8 x i16>
  %48 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %37, <8 x i16> %47) #6
  br i1 %40, label %23, label %49

49:                                               ; preds = %23, %4
  %50 = phi <8 x i16> [ %19, %4 ], [ %46, %23 ]
  %51 = phi <8 x i16> [ %22, %4 ], [ %48, %23 ]
  switch i32 %3, label %53 [
    i32 64, label %54
    i32 32, label %52
  ]

52:                                               ; preds = %49
  br label %54

53:                                               ; preds = %49
  br label %54

54:                                               ; preds = %49, %52, %53
  %55 = phi <8 x i16> [ <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>, %52 ], [ <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>, %53 ], [ <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>, %49 ]
  %56 = ashr <8 x i16> %50, %55
  %57 = ashr <8 x i16> %51, %55
  %58 = bitcast i16* %0 to <8 x i16>*
  store <8 x i16> %56, <8 x i16>* %58, align 1
  %59 = getelementptr inbounds i16, i16* %0, i64 8
  %60 = bitcast i16* %59 to <8 x i16>*
  store <8 x i16> %57, <8 x i16>* %60, align 1
  ret void
}

; Function Attrs: nounwind readonly ssp uwtable
define hidden signext i16 @vpx_int_pro_col_sse2(i8* nocapture readonly, i32) local_unnamed_addr #2 {
  %3 = bitcast i8* %0 to <16 x i8>*
  %4 = load <16 x i8>, <16 x i8>* %3, align 1
  %5 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %4, <16 x i8> zeroinitializer) #6
  %6 = icmp sgt i32 %1, 16
  br i1 %6, label %7, label %49

7:                                                ; preds = %2
  %8 = add i32 %1, -17
  %9 = lshr i32 %8, 4
  %10 = add nuw nsw i32 %9, 1
  %11 = and i32 %10, 1
  %12 = icmp eq i32 %9, 0
  br i1 %12, label %35, label %13

13:                                               ; preds = %7
  %14 = sub nuw nsw i32 %10, %11
  br label %15

15:                                               ; preds = %15, %13
  %16 = phi <2 x i64> [ %5, %13 ], [ %32, %15 ]
  %17 = phi i8* [ %0, %13 ], [ %26, %15 ]
  %18 = phi i32 [ %14, %13 ], [ %33, %15 ]
  %19 = getelementptr inbounds i8, i8* %17, i64 16
  %20 = bitcast i8* %19 to <16 x i8>*
  %21 = load <16 x i8>, <16 x i8>* %20, align 1
  %22 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %21, <16 x i8> zeroinitializer) #6
  %23 = bitcast <2 x i64> %16 to <8 x i16>
  %24 = bitcast <2 x i64> %22 to <8 x i16>
  %25 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %23, <8 x i16> %24) #6
  %26 = getelementptr inbounds i8, i8* %17, i64 32
  %27 = bitcast i8* %26 to <16 x i8>*
  %28 = load <16 x i8>, <16 x i8>* %27, align 1
  %29 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %28, <16 x i8> zeroinitializer) #6
  %30 = bitcast <2 x i64> %29 to <8 x i16>
  %31 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %25, <8 x i16> %30) #6
  %32 = bitcast <8 x i16> %31 to <2 x i64>
  %33 = add i32 %18, -2
  %34 = icmp eq i32 %33, 0
  br i1 %34, label %35, label %15

35:                                               ; preds = %15, %7
  %36 = phi <2 x i64> [ undef, %7 ], [ %32, %15 ]
  %37 = phi <2 x i64> [ %5, %7 ], [ %32, %15 ]
  %38 = phi i8* [ %0, %7 ], [ %26, %15 ]
  %39 = icmp eq i32 %11, 0
  br i1 %39, label %49, label %40

40:                                               ; preds = %35
  %41 = bitcast <2 x i64> %37 to <8 x i16>
  %42 = getelementptr inbounds i8, i8* %38, i64 16
  %43 = bitcast i8* %42 to <16 x i8>*
  %44 = load <16 x i8>, <16 x i8>* %43, align 1
  %45 = tail call <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8> %44, <16 x i8> zeroinitializer) #6
  %46 = bitcast <2 x i64> %45 to <8 x i16>
  %47 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %41, <8 x i16> %46) #6
  %48 = bitcast <8 x i16> %47 to <2 x i64>
  br label %49

49:                                               ; preds = %40, %35, %2
  %50 = phi <2 x i64> [ %5, %2 ], [ %36, %35 ], [ %48, %40 ]
  %51 = bitcast <2 x i64> %50 to <16 x i8>
  %52 = shufflevector <16 x i8> %51, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %53 = bitcast <2 x i64> %50 to <8 x i16>
  %54 = bitcast <16 x i8> %52 to <8 x i16>
  %55 = tail call <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16> %53, <8 x i16> %54) #6
  %56 = extractelement <8 x i16> %55, i64 0
  ret i16 %56
}

; Function Attrs: nounwind readonly ssp uwtable
define hidden i32 @vpx_vector_var_sse2(i16* nocapture readonly, i16* nocapture readonly, i32) local_unnamed_addr #2 {
  %4 = shl i32 4, %2
  %5 = bitcast i16* %0 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 1
  %7 = bitcast i16* %1 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %6, <8 x i16> %8) #6
  %10 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9, <8 x i16> %9) #6
  %11 = icmp sgt i32 %4, 8
  br i1 %11, label %12, label %67

12:                                               ; preds = %3
  %13 = add i32 %4, -9
  %14 = lshr i32 %13, 3
  %15 = add nuw nsw i32 %14, 1
  %16 = and i32 %15, 1
  %17 = icmp eq i32 %14, 0
  br i1 %17, label %48, label %18

18:                                               ; preds = %12
  %19 = sub nuw nsw i32 %15, %16
  br label %20

20:                                               ; preds = %20, %18
  %21 = phi i16* [ %1, %18 ], [ %37, %20 ]
  %22 = phi i16* [ %0, %18 ], [ %36, %20 ]
  %23 = phi <4 x i32> [ %10, %18 ], [ %45, %20 ]
  %24 = phi <8 x i16> [ %9, %18 ], [ %43, %20 ]
  %25 = phi i32 [ %19, %18 ], [ %46, %20 ]
  %26 = getelementptr inbounds i16, i16* %22, i64 8
  %27 = getelementptr inbounds i16, i16* %21, i64 8
  %28 = bitcast i16* %26 to <8 x i16>*
  %29 = load <8 x i16>, <8 x i16>* %28, align 1
  %30 = bitcast i16* %27 to <8 x i16>*
  %31 = load <8 x i16>, <8 x i16>* %30, align 16
  %32 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %29, <8 x i16> %31) #6
  %33 = add <8 x i16> %32, %24
  %34 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> %32) #6
  %35 = add <4 x i32> %34, %23
  %36 = getelementptr inbounds i16, i16* %22, i64 16
  %37 = getelementptr inbounds i16, i16* %21, i64 16
  %38 = bitcast i16* %36 to <8 x i16>*
  %39 = load <8 x i16>, <8 x i16>* %38, align 1
  %40 = bitcast i16* %37 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 16
  %42 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %39, <8 x i16> %41) #6
  %43 = add <8 x i16> %42, %33
  %44 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %42, <8 x i16> %42) #6
  %45 = add <4 x i32> %44, %35
  %46 = add i32 %25, -2
  %47 = icmp eq i32 %46, 0
  br i1 %47, label %48, label %20

48:                                               ; preds = %20, %12
  %49 = phi <8 x i16> [ undef, %12 ], [ %43, %20 ]
  %50 = phi <4 x i32> [ undef, %12 ], [ %45, %20 ]
  %51 = phi i16* [ %1, %12 ], [ %37, %20 ]
  %52 = phi i16* [ %0, %12 ], [ %36, %20 ]
  %53 = phi <4 x i32> [ %10, %12 ], [ %45, %20 ]
  %54 = phi <8 x i16> [ %9, %12 ], [ %43, %20 ]
  %55 = icmp eq i32 %16, 0
  br i1 %55, label %67, label %56

56:                                               ; preds = %48
  %57 = getelementptr inbounds i16, i16* %52, i64 8
  %58 = getelementptr inbounds i16, i16* %51, i64 8
  %59 = bitcast i16* %57 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 1
  %61 = bitcast i16* %58 to <8 x i16>*
  %62 = load <8 x i16>, <8 x i16>* %61, align 16
  %63 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %60, <8 x i16> %62) #6
  %64 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %63, <8 x i16> %63) #6
  %65 = add <4 x i32> %64, %53
  %66 = add <8 x i16> %63, %54
  br label %67

67:                                               ; preds = %56, %48, %3
  %68 = phi <8 x i16> [ %9, %3 ], [ %49, %48 ], [ %66, %56 ]
  %69 = phi <4 x i32> [ %10, %3 ], [ %50, %48 ], [ %65, %56 ]
  %70 = bitcast <8 x i16> %68 to <16 x i8>
  %71 = shufflevector <16 x i8> %70, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %72 = bitcast <16 x i8> %71 to <8 x i16>
  %73 = add <8 x i16> %68, %72
  %74 = bitcast <8 x i16> %73 to <2 x i64>
  %75 = lshr <2 x i64> %74, <i64 32, i64 32>
  %76 = bitcast <2 x i64> %75 to <8 x i16>
  %77 = add <8 x i16> %73, %76
  %78 = bitcast <8 x i16> %77 to <4 x i32>
  %79 = lshr <4 x i32> %78, <i32 16, i32 16, i32 16, i32 16>
  %80 = bitcast <4 x i32> %79 to <8 x i16>
  %81 = add <8 x i16> %77, %80
  %82 = bitcast <4 x i32> %69 to <16 x i8>
  %83 = shufflevector <16 x i8> %82, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %84 = bitcast <16 x i8> %83 to <4 x i32>
  %85 = add <4 x i32> %69, %84
  %86 = bitcast <4 x i32> %85 to <2 x i64>
  %87 = lshr <2 x i64> %86, <i64 32, i64 32>
  %88 = bitcast <2 x i64> %87 to <4 x i32>
  %89 = add <4 x i32> %85, %88
  %90 = extractelement <8 x i16> %81, i64 0
  %91 = extractelement <4 x i32> %89, i32 0
  %92 = sext i16 %90 to i32
  %93 = mul nsw i32 %92, %92
  %94 = add nsw i32 %2, 2
  %95 = lshr i32 %93, %94
  %96 = sub nsw i32 %91, %95
  ret i32 %96
}

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.uadd.sat.v8i16(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.pmulh.w(<8 x i16>, <8 x i16>) #5

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32>, <4 x i32>) #5

; Function Attrs: nounwind readnone
declare <2 x i64> @llvm.x86.sse2.psad.bw(<16 x i8>, <16 x i8>) #5

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16>, <8 x i16>) #5

attributes #0 = { nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nounwind readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind readnone speculatable }
attributes #5 = { nounwind readnone }
attributes #6 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
